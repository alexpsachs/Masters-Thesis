{
    "swalkinshaw": "This playbook isn't designed to download WP. It's meant to work with an existing Bedrock-based project/repo that already has it. For a dev environment this means having your local project synced through Vagrant. See the example synced_folder in the Vagrantfile.\nFor  production environment, right now the best way is to set site_install to false, and then somehow deploy your site to the server. Bedrock comes with Capistrano by default which this playbook works with. Once the files are on the server, you can them manually install if you need to. Or import a database.\nSome of this process needs to be improved but it will always expect you to have a project/repo from the start.\n. Were you using Vagrant + a vagrant synced folder?\n. Things like this should be in a template driven by variables with good defaults. Which brings up the question of how to use different values based on environment. Came across this: https://groups.google.com/forum/#!msg/Ansible-project/7Lnf5uuCWCY/-JWECvkiyxMJ\nyaml\n - include_vars: \"defaults/{{ item }}.yml\"\n   with_first_found:\n     - \"{{ environment }}.yml\"\n     - main.yml\nNot entirely sure if we should be using the defaults or vars folder. Regardless, we need a better way of determining \"environment\" than just checking group_names since there's multiple in there.\n. I took a look at your branch and it's good. My only concern with keeping all these variables in group_vars is it could quickly get huge. I don't really know if that's a downside?\n. Closed via https://github.com/roots/bedrock-ansible/pull/44\n. Could you try adding import tempfile above/below this line? https://github.com/roots/bedrock-ansible/blob/master/library/dotenv#L21\nIf you're using the example Vagrantfile in this repo you'll need to edit the relative path for the synced folder. It would probably error if the path doesn't exist.\n. Haven't heard back but this should be fixed by edfbe926c536fed93c98e6054cec61f63c2d6fb2.\n. Can you try again after getting the latest commit? I've never seen this error but the task that caused it isn't even needed. Should be fixed by c2ddfc0583a8d5416194fb4a5573e4c6a3ebfa70.\n. Thanks for the compressive troubleshooting! The docs definitely need some work as a lot of people get confused at a few points.\nLooks like the issue is that your bedrock.dev folder is missing wp-cli.yml. This configs tells WP-CLI where the WP install is (web/wp) and without it, it can't find/detect WordPress.\nhttps://github.com/roots/bedrock/blob/master/wp-cli.yml\n. I don't think anything with bedrock-ansible is common knowledge right now unfortunately (mostly because of the lack of docs).\nThis playbook depends on Bedrock-based sites, so yeah you need a (mostly) complete site based on Bedrock somewhere on your local filesystem. Where that is depends on your Vagrantfile and where it is as well.\n. Never seen either of those errors unfortunately. Adding ansible.verbose = 'vvvv' to your Vagrantfile and re-provisioning might provide more debug information to help.\n. Could you ssh into the Vagrant box and see if /srv/www/example.dev/shared/.env exists? And if the other folders like current exist as well and the synced folder contents are there?\n. Oh of course... pretty sure Windows has problems by default with symlinks in synced folders.\nSome things to try here: https://coderwall.com/p/b5mu2w and http://stackoverflow.com/questions/13716012/vagrant-shared-folder-symlinks\nIf you Google that you'll find a lot of resources about it.\n. @starise I'm going to look into integrating your script as a documented option at least. Or by checking if the host is Windows in the Vagrantfile.\nI had just assumed Ansible could work on Windows until a few weeks ago.\n. @starise I've updated the README and linked to your solution for now. Thanks!\n. @mwalters @starise @ionutzp would be helpful to know if you're using the latest version/commit of this playbook. And also if you're using the (now) default base of roots/bedrock, or a default Ubuntu 14.04 Trusty, or the old Ubuntu 12.04.\nAlso what host you're running Ansible from (Linux or OSX) or if you're using it within a shell script from Windows.\n. This was a fairly dumb error looking back. Fixed as of a5962e96992ba2ac44d1945e5f8b609fa5f37413 and I also published a new 0.2.0 version.\napt-get upgrade was being run by default as part of the provision but it shouldn't be because it causes errors like this as packages get upgraded to different versions and could cause conflicts. Basically the goal of any project like this should be to have consistent/deterministic package states and upgrading them breaks that.\n. GitHub keys is a great idea.\nIdeally adding ssh keys would be a more general thing and taken out of the capistrano role. I'd like to be able to say: add these keys for these users.\n. GitHub SSH keys were added in #95.\n. When you're talking about a db import in this case, do you mean a non-complete one? As in just importing some users or posts for example but not the full tables necessary for a working install?\nThat's a good use case that I hadn't thought about at the time. Kind of just assumed you'd either be installing WP from scratch or importing the full db.\nI guess this also assumes that your sql file has drop if exists which they should.\n. I'll have to test it out but your assumption is correct.\n\"Installing\" WordPress is really just creating the tables. So wp core is-installed does just check if the tables are present. It's also correct in your example that the DB would be imported, is-installed will \"fail\" and will WP Install will be skipped as it should.\nHowever, the site should work after that since the tables are there. Shouldn't matter how they got there.\nFunny thing is I believe this PR is still valid for the use case of \"partial\" db imports.\n. @fullyint so the problem you ran into is because nginx reload is only notified on Install WP. So after I ran vagrant up with an import I just had to manually run sudo service nginx reload and it all worked.\nThis PR works because it schedules the db import handler, then the reload nginx one (it's kind of a side-effect).\n. So I've thought about this, and it's not really proper to have importing a database as a handler. Ansible docs say:\n\nHandlers are best used to restart services and trigger reboots\n\nThe simplest solution is just to add notify: reload nginx to the import db task. Want to make another PR with that change?\n. Private packages/repos are probably a common enough use case to include some sort of solution, but my main issue with this one is that it adds a lot of code without even documenting the easiest/recommend solution: SSH forwarding.\nThat being said, some other feedback if we go forward with this:\n- I don't love the var setup right now. Would be nice to group known_hosts and flush_known_hosts under some common key like deploy_keys.\n- There's some inconsistency when looping over wordpress_sites is used. For example it's used for uploading but not for flushing.\n- Relative paths with ~ shouldn't be used. Should be based on item.user.\n- I don't like making the role dependent on wordpress_sites.0.run_composer. What if you only have run_composer on another site other than the first?\n- Right now the private key path is just hardcoded to ~/.ssh/id_rsa. It could be added as an array var under deploy_keys (or whatever it's called):\nyaml\ndeploy_keys:\n  upload: true\n  users:\n    - deploy\n    - user2\n  keys:\n    - /Users/scott/keys/github.rsa\n    - /Users/scott/.ssh/id.rsa\n  known_hosts:\n    - github.com\n    - bitbucket.org\n  refresh: true\nOr maybe have all the above nested in the users array you want.\nSome of this is probably my fault since I still haven't figured out the best organization for the vars including  wordpress_sites. It encourages everything to be shoved under those or making you reference it from the outside.\n. Take a look at these two tasks:\n```\ncopy: src=id_rsa dest=~/.ssh/id_rsa owner={{ item.user | default(user) }} group=www-data mode=0600\nwith_items: wordpress_sites\nfile: state=touch path=~/.ssh/known_hosts owner={{ item.user | default(user) }} group=www-data mode=0600\nwith_items: wordpress_sites\n```\nThey loop over wordpress_sites using its user each time, but they always have the same destination path ~/.ssh/known_hosts and ~/.ssh/id_rsa.\nSo what will happen with 3 sites with users: user1, user2, and user3:\nFist run: \n1. id_rsa is copied to ~/.ssh/id_rsa with owner user1\n2. id_rsa is copied to ~/.ssh/id_rsa with owner user2\n3. id_rsa is copied to ~/.ssh/id_rsa with owner user3\nSo it just ends up with the 1 file (since the paths are always the same) owned by the user of the last wordpress site.\nGoing to close this as is but might re-visit some of it in the future.\n. It's a known error that I need to look into. It's just the theme and plugin update checks failing. The request takes longer tan 3 seconds to finish so it times out and gives that error (also makes your admin slow).\n. Add  this to your config:\nphp\ndefine('WP_HTTP_BLOCK_EXTERNAL', true);\n. Just fixed it. See the above commit for the fix to your Vagrantfile and run vagrant reload.\n. Thanks for noticing and fixing this bug.\n. Just hijacking this issue as a general feature request for proper PHP config management via a template and variables.\n. Mostly taken care of by https://github.com/roots/bedrock-ansible/pull/44\n. Those defaults are probably fine. We should probably all those variables as they're fairly common.\n. Looks like you're using a newer version of Ansible that introduced this regression. See https://github.com/ansible/ansible/issues/8173\nSolution is to downgrade to an older version for now.\n. Did you google that error? Lots of related answers including https://github.com/ansible/ansible/issues/4355\nSeems like whatever settings you're using you aren't connecting with a root/sudo user.\n. Well maybe but there's not much I can do with almost 0 debugging information. Some things that are helpful:\n1. Steps you did\n2. Setting you changed\n3. Paste/Gist config files\n4. Logs (Ansible can be run with verbose debugging)\n. Good find! Agreed this does look better anyway to separate it from the actual command line arguments.\nMinor thing but can you update to use single quotes for consistency purposes? And rebase/squash commits if you know how please.\n. Good point. I'll merge this as is and update the rest after.\n. @retlehs just mentioned this yesterday as well so good timing.\n. Glad to hear. Feel free to send any other fixes or improvements :)\n. Oops, thanks!\n. Forgot about this.\nI could be wrong about this, but I don't think there's much we can because the guest additions mismatch depends on someone's version of VirtualBox installed. One solution would be to constantly update the vagrant box with the newest guest additions but anyone with an older VB would still get errors.\n. WP-CLI for wp core is-installed will return 0 if its installed and 1 if not (Ansible also considers commands with a non-zero return as errors, so we ignore those).\nThen we only install WP if one of those sites returned 1 (ie: not installed) and you set site_install to True.\n. That's a great idea. I'll have to put some thought into what would work best for this. Obviously testing against actual production servers is useful and especially if you're going through their APIs.\nI think a good first step would at least some basic functional tests using a CI service like Travis. That way every commit could at least guarantee that it boots up and at minimum can successfully build a WP site.\nThen we could run tests against production servers more selectively maybe.\n. Yeah, I'm impressed with anything Hashicorp does.\nCoincidentally, tonight I spent some time starting to integrate building production servers in bedrock-ansible with Ansible's Digital Ocean module. I got it working but it's a bit clumsy right now since you have to run a local playbook to create the droplet, then edit the hosts file with the IP. Then run the actually site.yml playbook which fails at the end since deploying the site isn't built in.\nThe goal is to get seamless dev, staging, and prod servers all set up.\n. Found an example of testing Ansible playbooks on DO with TravisCI: https://github.com/analytically/hadoop-ansible/blob/master/.travis.yml\n. I'll push something up soon. Wasn't near complete or anything.\n. Should never have to reboot the server. That just means some service may need to be restarted (most likely Nginx or PHP-FPM).\n. Separate issue. But there's 2 solutions:\n1. Run PHP-FPM under the deploy user or a common group.\n2. Add deploy (or its group) to sudoers with access to the php5-fpm service.\n. @luandro site_name just controls the path where WP lives at like /srv/www/website.com/current. So if Composer is failing it means that either that path is wrong or the actual WP files aren't there. If this is for a dev server and you're using Vagrant, then your synced folder needs to be set up properly. If it's a remote server, then you somehow need to get the codebase onto the server in that path first.\n. @luandro this is for dev I assume? vagrant up should run the playbook automatically for one thing. You shouldn't have to manually do that. But you should edit the Vagrantfile and edit bedrock_path to point to a local relative directory that contains your WP project. Vagrant will sync that folder onto the VM so you don't need to actually deploy it.\n. Ah, then yes, you can use Capistrano if you want. Or really any method of deploying. You could just manually scp or git clone as well to get it there initially. It's a current workflow flaw right now. See https://github.com/roots/bedrock-ansible/issues/84\n. Main reason off the top of my head: a deploy process can often include other steps like running Grunt or whatever. Just running a git clone wouldn't take care of any of those extra steps. I don't really like the idea of some incomplete method. Ideally the entire deploy process would be done through Ansible so then you could just run the normal deploy role/task instead of duplicating functionality.\n. But again that's just a kind of hack to get around the actual problem that exists right now.\n. There's some of the H5BP configs that we probably don't want to include (or at least by default).\n. protect-system-files.conf seems useful by default as well.\nAnd some SSL related ones can wait until this playbook supports that.\n. I'm not sure about the expires one by default.\n. I'll try and do this tomorrow since it also involves updating the Vagrant box.\n. 0.3.0 was released. Base vagrant box didn't change.\n. I was actually working on an implementation to use password lookups to transparently generate and store passwords without the user having to do anything. I think I switched away from it when I realized that they were stored in plain text.\nThe only downside to recommending lookups is it changes the structure of the files a bit since there won't be any variables in group vars anymore. Just direct lookups in the roles.\n. You're right, they actually can be stored elsewhere. Never really considered that that would be wanted behaviour though. In one way it's good (no passwords in repo), in another it's bad since it wouldn't work well for teams sharing credentials.\n. Complete oversight since I was doing some manual testing before adding this. I'll get it added.\n. Sure :+1: \n. Not sure exactly. The not really well thought out plan was to at least make this playbook support a caching plugin out of the box since I think that's a requirement and don't want to leave it completely up the user.\nI personally hate W3TC and don't love Super Cache either. That left an Nginx based caching solution, but I wasn't sure about the maturity of the plugins, and Batcache. So I added memcached for the purpose of using Batcache. Obviously any Bedrock based WP would need a few tweaks like including the plugin, advanced-cache.php file (which is really annoying since it's not a normal plugin).\nIf you have thoughts pleas let me know!\n. I'm a Redis fan in general, but if you're not taking advantage of its data structures, I'd rather stick with memcached for just a dumb fast cache.\n. And thanks for mentioning your fork. Looks like it has some useful things in there I was eventually going to do like SSL support so I'll take a look at it.\n. @ckovey or @nathanielks is there an equivalent to Batcache that uses Redis? Without resulting to something like https://github.com/BenjaminAdams/wp-redis-cache. I don't like the idea of how it's setup with the index file changes.\n. Well there's object cache and page cache.\n@nathanielks theoretically an almost exact replica of Batcache but with some Redis changes could exist. There's no reason why you need that index file solution. Unless I'm just missing something. Batcache just takes advantage of of the Memcached Object Cache plugin/dropin, and since one exists for Redis now, it would work as well.\n. Let's just do Batcache for now. I'd only really consider a Redis based one if a Batcache-like plugin existed.\nAside: my personal preference is to use an Nginx based caching solution since 1) it's already installed, 2) it's good. Only issue is some of the Nginx caching plugins (which exist just to purge content) seem to have issues. There's potentially some more mature Varnish ones which would probably work fine since they all just do a purge http request.\nFurther aside: The bulk of most WP caching plugins are hooking into various events like \"updating a post\" and then purging the cache. This is a waste of time as everyone just duplicates efforts, has different bugs, or misses features like support custom types, etc. Smart thing to do would be to develop a base cache purging API which you could just implement in any plugin for cache front-ends like: Memcache, Redis, Nginx, Varnish, etc.\n. @mAAdhaTTah it's mostly just insanely bloated and does too many things. And most of the things it does there are better solutions meant specifically for them. W3TC is also made for people who 1) don't really know about caching and 2) are problem on a shared host or limited environment.\nWe can and should do better :)\n. Two things:\n1. Not sure about the sessions by default. Have to think about this.\n2. Installing php5-memcache should probably be based on the same conditional as including the memcached role. Which is currently just checking that it's not development. This may mean changing that to some explicit wp_cache var which people can toggle.\n. Oh haha, yes that's a much better and easier solution.\nIf we do keep sessions in memcached, that would need to use the memcached_port variable from its role. I always forget if that's possible with Ansible.\n. @austinpray yeah this might seem contradictory to what I always say. But certain things like caching I believe don't belong in development mostly because they can hide performance issues that you should be noticing.\nIn my opinion, caching falls into the same category as minifying/concatenating assets, using a CDN, etc.\n. Although memcached should probably be installed on development as well now that I think about it. As it would be helpful to be able to turn on a caching plugin to test it out before deploying. It's the caching that shouldn't actually be turned on by default.\n. To me it should really just be a matter of changing a constant like WP_CACHE in your env specific configs. If you want it on, just set it in config/development.php (for Bedrock).\n. Once the name is updated can you squash commits into 1? Then it's ready to go :+1: \n. http://gitready.com/advanced/2009/02/10/squashing-commits-with-rebase.html\nBasically you should be able to do this:\n1. git rebase -i HEAD~6 (replace 6 with however many commits appear in the PR)\n2. Change all pick words to f (fixup)\n3. git push -f (may need to add origin or whatever you do to push the branch)\nAll of the commits will be squashed into one and then you force push to your branch.\n. Thanks for noticing this. Just edited the URL and fixed it.\n@austinpray think it's fine on Dropbox for now :) it's actually always been on there.\n. Looks good other than the few minor formatting issues :+1: \n. I was going to comment about using copy then I looked up the docs, and yeah, only for local to remote. Linters are useful but only if they're correct!\n. One more thing. Can we add this? https://github.com/h5bp/server-configs-nginx/blob/master/sites-available/no-default. Something like:\nyml\n- name: Enable better default site to drop unknown requests\n  file: src=/tmp/server-configs-nginx/sites-available/no-default\n        dest=\"/etc/nginx/sites-enabled/no-default.conf\"\n        owner=root\n        group=root\n        state=link\nWe may want to copy that file to sites-available before linking.\n. @austinpray ^ :cat: \n. Looks like you did a rebase of some sort but can this be squashed into 1 commit as well?\n. @teohhanhui the downside is that you might not get the latest version of the files if you don't have cache busting in place. This comment still applies.\n. I don't think we should do anything by default. The warning in the README about passwords can be expanded to include SSL certs as well.\n. Yeah, don't worry about encrypting by default. We should come up with a standardized location for them though. I'm not sure off the top of my head where the best place is for those yet.\n. @rstormsf thanks for that.\nAn update to this issue: I've done most of the work necessary for this on https://roots.io. So it's just a matter of porting that over to here and cleaning it up a bit. And figuring out the best way to deal with certificates.\n. @rstormsf when a PR is created soon :)\n. @rstormsf that config looks mostly good. You have most of the good security and performance practices. Only thing missing is also adding the HSTS headers on the non SSL servers. Without it the redirects aren't fully secure.\nYou can also combine them:\nnginx\nserver {\n  listen *:80;\n  server_name rstormsf.dev www.rstormsf.dev;\n  add_header Strict-Transport-Security \"max-age=31536000; includeSubdomains; preload\";\n  return 301 https://rstormsf.dev$request_uri;\n}\nI'd use that version of HSTS header too above ^\nHere's a few more settings you'll probably want:\n``` nginx\nspdy_headers_comp 6;\nStaping\nssl_stapling on;\nssl_stapling_verify on;\nresolver 8.8.8.8 8.8.4.4 216.146.35.35 216.146.36.36 valid=60s;\nresolver_timeout 2s;\nlonger session cache\nssl_session_cache    shared:SSL:10m; # a 1mb cache can hold about 4000 sessions, so we can hold 40000 sessions\nssl_session_timeout  24h;\nSSL buffer size was added in 1.5.9\nssl_buffer_size      1400; # 1400 bytes to fit in one MTU\nssl_session_tickets off;\nUse a higher keepalive timeout to reduce the need for repeated handshakes\nkeepalive_timeout 300; # up from 75 secs default\nspdy_keepalive_timeout 300;\n```\nAnswers:\n1-3: Probably just let the paths to the key and crt be variables that need to be specified. I believe the file module is fine. It's only two files.\n4:  Ansible tasks are designed to be idempotent meaning they can be re-run with no side effects. Even for SSL it's fine. The SSL role I implemented for roots.io gets run every day and there's no problem.\nI'm thinking that I might just handle the SSL role since I already have most of it done. There's another one in https://github.com/roots/bedrock-ansible/pull/151 as well but it needs more comprehensive Nginx configs.\n. See https://github.com/roots/bedrock-ansible/pull/172\n. Agreed about a toggle and non-HHVM default. Some variable like php_engine (that's probably the wrong word to people who care, but whatever). Defaults to php and hhvm is supported as well.\n. Closed via https://github.com/roots/bedrock-ansible/pull/136\n. I should note that we don't want to use Vagrant to manage this. It should all be done through Ansible.\n. I'm okay with using something like Terraform since that its intended purpose if we can't use Ansible. Problem with Vagrant is its specifically meant for dev environments.\n. See https://github.com/bandwidthcom/terraform-inventory\nedit: this isn't that great\n. Just a note that dopy was updated to API v2 but Ansible still needs to be updated as well I believe. See https://github.com/ansible/ansible-modules-core/issues/209\n. Ansible still hasn't updated their DO module :(\nSee https://github.com/ansible/ansible-modules-core/pull/998 for a new attempt\n. @rossedman I agree that would probably be better but I'd rather keep this simple and within Ansible for now. We'll still keep it separate with an infrastructure.yml playbook which will only create a DO instance.\n. @mAAdhaTTah the DO module in Ansible is broken since DO retired V1 of their API. DO finally upgrade the module to V2 but we've been waiting on their next release to include it.\nThe actual work won't be difficult though. Just a simple playbook to create a droplet.\n. Still waiting :sob: They haven't bumped the DO module version in forever so whenever 2.0 is released it will be included.\n. We can finally start development on this now that Ansible 2.0 is released!\n. Thanks for sharing @nbyloff. I've done something pretty similar to this as well. My sticking point was trying to get dynamic inventories working but thinking about it again, I'm not sure it's needed.\nThe typical/default setup is probably a single server so a dynamic inventory isn't really needed. It's just nice to have to skip manually editing your hosts file.\n. Having a hard time picturing it, but it seems pretty brittle. Parsing an existing file and checking if names match via the DO API does not sound like fun.\n. I've had similar tasks in a local branch for a while, so thanks for sharing that. I guess the reason why this issue isn't done yet is the \"integration\" part.\nMeaning, is there a way to provide an optional DO playbook/inventory script which just works with the existing server.yml so it's opt-in?\nI guess these tasks are idempotent, could we just create a new playbook which runs those then imports server.yml?. www-data seems correct. Or I wonder what the settings are the default Nginx site which we disable.\n. Let's just keep it as root:root then for consistency I'd say.\n. Not at all. But it should only be included on development I think?\n. @JacobDorman no update. Any work on it would be appreciated since I'm not too familiar with it. I don't think there's any ongoing work which was interfere with this.\n. Closed via https://github.com/roots/bedrock-ansible/pull/176\n. Squash :+1: \n. Thanks!\n. Big :+1: for renaming the php role. I'll go over this again later but it looks mostly good.\n. Never trust Stack Overflow answers.\n. I should probably give this one a test first\n. Finally tried this out and I had one problem. Any nginx conf files like nginx-hhvm.conf and nginx-php-fpm.conf need to have their user/group set to root. Right now I just got vagrant:vagrant and only rw for owner so it wasn't working.\n. One other thing, what's the reasoning behind setting the implementation in the new vars/common.yml vs the normal group vars? I kind of forget if we discussed that somewhere.\n. Yeah, I think so. Just seems weird to have that one setting there and everything else in another place.\n. @nathanielks can you rebase + squash? Think this is good to go.\n. I'm wondering if nginx restart is needed in this case instead of just reload.\n. @nathanielks me too. I'm thinking we should just ditch separate php-fpm confs/sockets per WP site. Then HHVM and PHP-FPM can both be treated in the same way with 1 socket.\n. Closing in favour of https://github.com/roots/bedrock-ansible/pull/136\n. Did you update this repo/the playbook itself? The updated 0.3.0 Vagrant box is actually the same as 0.2.0 (just wanted to keep versions in sync) so nothing changed with that.\nMy first thought is something else is going on although I'm not sure what.\n. I thought we had this at some point. I think @nathanielks decided to keep everything consistent in the end, but you're right that we should disable it because of this in development.\nNo surprise you noticed it was about 60 seconds, since we have revalidate_freq set to 60 seconds! https://github.com/roots/bedrock-ansible/blob/master/roles/php-55/defaults/main.yml#L14\n@nathanielks not sure what your thoughts are, but simplest solution is to just override php_opcache_enable in group_vars/development.\n@vicvicvic you can also do that in meantime to disable it.\n. Definitely, they are production specific settings.\n. Fixed by #48. Thanks @nathanielks \n. Did you re-provision the box after the upgrade? If files have changed, the playbook would need to be re-run.\nAnd if there's a white screen, there's an error somewhere that can be found in a log file.\n. @mAAdhaTTah figured out what happened.\nPreviously Nginx included fastcgi_param\u2002SCRIPT_FILENAME $request_filename; in fastcgi_params which we include in wordpress.conf.\nUpgrade Nginx removes that lines and also adds a new fastcgi.conf file. So the solution is either to re-add that line to fastcgi_params or include fastcgi.conf instead.\nI'm going to choose one of these and fix this and bump the version/update base Vagrant box.\n. Fixed by 02879c28aab85d3c51bb9bba58db184e9c9c625a\n. Box has been upgraded as well: https://vagrantcloud.com/roots/boxes/bedrock/versions/3\n. http://stackoverflow.com/questions/8677493/php-fpm-doesnt-write-to-error-log\nTry adding catch_workers_output = yes to the php fpm template.\n. Don't we want to keep php_display_errors: 'On' for development? Does that also stop the logging?\nBecause in dev it's still useful to see them.\n. Just going to leave this on hold for a bit until I can test some combinations of this. Ideally it would log and display errors.\n. Closing in favour of https://github.com/roots/trellis/pull/278\n. Few things:\n1. This Ansible playbook doesn't do anything to Ruby. Whatever comes standard with Ubuntu is there. Which is version 1.9.3.\n2. Pretty much any solution to installing Ruby will tell you to use rbenv (or rvm) because of problems like you had. Without those you need to install gems globally and it leads to problems.\n3. The difference between hashicorp/precise64 and roots/bedrock boxes may just be that our base box has recently updated/upgraded all packages through apt-get upgrade and apt-get dist-upgrade.\nYou should probably just look into using an existing rbenv role like:\n- https://github.com/zzet/ansible-rbenv-role\n- https://github.com/leucos/ansible-rbenv-playbook\n. This playbook is supposed to be Bedrock specific, but not Roots. So I'd rather not add things unless required. Although it might grow into needing these things so we'll see.\n. It still does work straight out of the box for its intended default use case. How would adding a specialized Ruby role keep things simple? Especially when it wouldn't even be used by default.\nI understand this would make things easier for you, but just imagine if we added a role for everything someone wanted by default.\n. I'd be interested to know if you would run into the same issue with hashicorp/precise64 after running apt-get upgrade and apt-get dist-upgrade. Nothing else we're doing should be messing with Ruby packages.\n. @austinpray more or less. Maybe a few points of clarification:\n1. If you were to have your themes (Roots for example) as a separate repo, might as well make it a Composer package (with a type of wordpress-theme) and manage it through that.\n2. I don't blame @cibulka for wanting Ruby installed on the remote server. By default Bedrock uses Capistrano which is set up to run all build processes on the server during deploy. Cap doesn't easily let you build/compile things locally and then transfer. Example solution for doing it locally: https://gist.github.com/nateroling/22b51c0cfbe210b00698\n. Things like ufw and fail2ban, yeah. Better SSH defaults etc. These would only apply to non-dev environments.\n. I don't. Feel free to start :+1: \n. Ideally we'd avoid GPL licenses as its just easier.\n. I have no problem with READMEs in subdirectories. GitHub renders them nicely anyway.\n. Of course... any work based on another should correctly have attribution anyway. Especially if it includes a license.\n. You can always achieve this with an mu-plugin like Bedrock has: https://github.com/roots/bedrock/blob/53a5013e0b13754a94f8a9271d4ce809bbe3dc3c/web/app/mu-plugins/disallow-indexing.php\nNot sure I'd want passwording functionality included by default (even if disabled). For now that seems like a more specific use-case.\n. @QWp6t found this regarding your interpretation of the GPL with package managers: http://programmers.stackexchange.com/a/275998\n. This playbook isn't supposed to be Roots specific. We could have a separate repo/playbook for those roles if need be.\n. root ssh access should definitely be disabled in production. I'm not sure the \"general\" user should be deploy (it should still exist but just for deploys). We could go with the common ubuntu that services like AWS use or something generic like web. Not really sure if there's a more standard user name for this purpose.\n. :+1:  to admin\n. @nathanielks this is looking great. Finally got a chance to look over the READMEs. Just going to try and do some basic testing of this before merging it in since it's big.\n. More testing mainly so any help with that would be great.\n@nathanielks could we get a rebase on this?\n. Yep, no reason why they shouldn't be tagged.\n. Well I'd start with just tagging roles at least for a start. We can always add more as we go.\n. :+1: \n. :+1:\n. Taken care of in https://github.com/roots/bedrock-ansible/pull/95\n. Yeah, I thought about setting the cpus before as well so a PR for this is welcome.\n. Using all the cores you have is fairly standard. Although we may want to cap that 1/4 of memory at like 2GB. I do agree it's a little crazy to use 4GB of ram for a dev VM.\n. See https://github.com/roots/bedrock-ansible/pull/66\nDecided to just hardcode it since it's way simpler. Anyone can customize now but at least the setting is there to see.\n. Only one small thing. Maybe we should leave the old synced_folder line commented out with a note for Windows users that NFS won't work? After that and a squash we're good.\n. Make sure you aren't currently in a rebase so do git rebase --abort.\nThen git rebase -i HEAD~4 (since there's 4 commits in this branch). Then change the bottom 3 to f. Leaving the first (top) commit in the list intact. Not sure why that wouldn't work if that's what you did.\n. :+1: \n. Why do you run Capistrano from the vm?\n. @nathanielks it would belong in Bedrock itself, not here. I did recently add a note to Bedrock's README about it.\n. Added in 373fe77e90e5208fc96a9def301bb9e17b66f2ac\n. I forget if I ever actually had it running, this is a good catch though.\nWe could just do something like: cron: name=\"{{ item.site_name|replace('.', '-' }} WordPress cron\"\n. ~~Oh the way we're using Ansible's cron module doesn't create a file. It just adds a cron entry in the user's crontab so the name doesn't really matter.~~\n~~See: http://docs.ansible.com/cron_module.html~~\nedit: nevermind, we do use a file but it's specified lower.\ncron_file=\"wordpress_{{ item.site_name }}\" we'll need the replace in there.\n. Yeah, I've thought about this a few times. It's dumb to duplicate functionality when a better/more mature playbook might exist for it. If there are some good ones in galaxy that can be used for new roles, or in place of ones we have then we should look into it.\n. @MatthewMi11er Debops is awesome but our issue with it is the GPL license.\n. We're now doing as part of https://github.com/roots/bedrock-ansible/pull/95 and will be expanding to more roles.\n. :+1: \n. MariaDB already has the query cache on by default and it's set to 16MB which is a sane default (especially on a common 1GB server for example). I don't think there's really any common performance tuning to do I think we're good for default setups.\n. I was having the same issue and this got me past it:\nruby\n  config.vm.synced_folder '../bedrock', '/srv/www/example.dev/current', type: :nfs, linux__nfs_options: %q(no_subtree_check all_squash rw), map_uid: 0, map_gid: 0\n. Looks like linux__nfs_options is just the default so shouldn't need that part.\nhttps://github.com/mitchellh/vagrant/blob/efd1d5e11bfc5a72c7a1d1eae294b4751d841544/plugins/hosts/linux/cap/nfs.rb#L102-L104\n. Can you remove the linux__nfs_options: %q(no_subtree_check all_squash rw) part? It's default so don't want it confusing people. Also single quotes on nfs please. Then squash and we're good :+1: \n. You may be right about the default mysql_root_password being set. Building the base box isn't great right now since I just manually delete some tasks/roles and they could be forgotten.\nI know from experience that Ansible's mysql_db module had an issue with special characters in a database name, so maybe other modules have a similar issue. Not sure if that's been fixed but I should try to track it down.\n. In regards to the proposed README changes, I should fix the first issue so it works as people would expect. For the 2nd, I'd like to see if there's a method that will work (or an Ansible bug fix) for those characters before trying to document this limitation.\n. Yeah, I'll have to create a new base box version where the password isn't set by Ansible\n. Not valid anymore. See https://github.com/roots/trellis/pull/260.\n. Thanks, all good updates :+1: \n. PR etiquette is usually to just submit one up front when it's something smaller (and it fits with in with the project obviously). If it's a bigger change it should be discussed first as an issue to avoid potentially doing a lot of work that won't be accepted. No idea if anyone would want to avoid unmerged PRs, but I don't care.\n. I'm inclined to leave it as is for 2 reasons:\n1. Your passwords need to be stored somewhere. Even if you keep them locally, it's still ideal to have a backup somewhere on the internet. The reason why I don't recommend keeping passwords in a Bedrock repo is more because application projects shouldn't contain passwords rather than Git repos shouldn't contain them. For example, you could store a private Git repo on your private S3 account and it doesn't matter as much if there's passwords in there. A repo that contains your server configuration is the more appropriate place to store passwords. Obviously they should still ideally be encrypted though.\n2. Bedrock is just a base WP project repo. It doesn't offer any capabilities for encrypting passwords (other than Git encrypt). Since this one is used by Ansible though, it does offer the use of Ansible Vault.\nI hope that makes some sense.\n. I am closing this but don't just automatically defer in general :) Anyone can raise a valid point and I guarantee I have and will continue to do things wrong in this project (and others). Which is why other people helping out is always a good thing.\n. :+1: \n. That original code didn't make much sense looking back. Thanks!\n. :+1: \n. Surprised that Dropbox allowed it to go on that long!\n@austinpray still have hosting available?\n. @austinpray http://roots.io/media/bedrock-ansible-0.4.0.box\nThanks!\n. Vagrant Cloud works now thanks to new hosting by @austinpray.\n. Good catch :+1: \n. We probably do have to look into this. Someone else reported that NFS is messing up host permissions which isn't good.\n. @fullyint want to do a PR with this change?\n. Thought this didn't work for a bit then realized my local shared folder had its permissions previously changed by the normal NFS. Reset them back and it's all working as it should.\n@fullyint @austinpray @nathanielks hijacking this PR for a vacation notice. I'll be gone until Nov 10th or thereabouts with limited internet so apologies if PRs/Issues are stuck until then.\n. Yeah, it's definite lacking a complete solution for remote servers. Right now you basically have to run the playbook without the last few tasks, then deploy the codebase, then run the tasks. Obviously that's not ideal. I also don't really like the idea of Ansible trying to run Capistrano locally.\n. Closing this since it's a known issue that will be taking care of by #95\n. Dupe of #73 for tracking purposes\n. Do you have anything in your SQL file you're importing like creating views or procedures?\n. This is as simple as just updating the version to 1.0.0 I guess? I looked at the new commits and it doesn't look like that much.\n. Looks good. Want to do a PR?\n. Closed via https://github.com/roots/bedrock-ansible/pull/91\n. Yeah its a 404 just doing a manual wget too:\n\nwget http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/utopic/main/source/Sources\n--2014-11-10 12:51:37--  http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/utopic/main/source/Sources\nResolving nyc2.mirrors.digitalocean.com (nyc2.mirrors.digitalocean.com)... 192.241.164.26\nConnecting to nyc2.mirrors.digitalocean.com (nyc2.mirrors.digitalocean.com)|192.241.164.26|:80... connected.\nHTTP request sent, awaiting response... 404 Not Found\n2014-11-10 12:51:37 ERROR 404: Not Found.\n. It's the utopic part. Here are the dists that exist: http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.1/ubuntu/dists/\n. Utopic is Ubuntu 14.10. I'm guessing a dist upgrade recently happened which is causing this problem.\n\nhttps://github.com/roots/bedrock-ansible/blob/master/roles/mariadb/tasks/main.yml#L10\n. The solution is to just hardcode trusty as the dist for now I guess.\n. :+1: \n. @mAAdhaTTah nope, that's all part of the grand plan. Using Capistrano kind of blocks the full automated workflow so this will help us get there.\n. Not actively. Still partly blocked due to DO API v2 integration into Ansible.\n. That's still up for debate. Right now Bedrock and this project aren't really tied together. At least not from bedrock -> this.\nIt should be removed at some point though. Maybe to another repo if anyone wants to use it.\n. Right now the .env file is generated as part of the wordpress-sites role. It makes more sense to move this as part of the deployment process (so the role in this PR) since you want your config to be up to date on every deploy.\nhttps://github.com/nicolai86/ansible-prepare-release supports creating files from templates. This means the custom dotenv library would need to be modified to just generate some facts/variables that a template could use. I think this also makes more sense anyway since the dotenv library shouldn't be concerned with file creation. Should have been designed to use with Ansible's template to begin with :hankey: \n. Putting this mostly on hold because there's a new deploy_helper module that should be merged into Ansible core soon. The module takes care of things like: folder structure, releases, symlinks, etc. See https://github.com/ansible/ansible-modules-extras/pull/110\nThere's still other work to be done but I'd rather not use a 3rd party role when this will be built into Ansible soon.\n. @mAAdhaTTah yeah that's the plan. This will make it simpler because it's all Ansible which has a lot of advantages.\nedit: but it's basically the same, the deploy role/module that I'm using gives you same folder structure and deploy process as Capistrano (which is the best part of it).\n. @sugarskull there's still a few big issues to figure out before this is merged. I'll try and get a REAMDE update in the meantime to document the current workflow gap.\n. @fullyint pushed up a few little tweaks/fixes. Thanks for your help.\nOddly enough I never get a failure for ssh-known-hosts event without github_ssh_keys defined.\nBut I do need to document its usage. You guessed correctly at what it would look like.\n. @fullyint \n1. secure-root.yml is still kind of optional right now so we definitely need better integration with it.\n2. I ran into issues getting forward agent to work as well and I believe for roots.io we just ended up using a deploy key but that isn't really ideal. I added a todo about this but we need to figure out one complete method and document it.\n3. Yes, good find! Originally I was using the deploy_module role from Galaxy and ran into this issue so that known hosts role was needed. Now that I've just included the deploy role and customized it, it's no longer needed.\n. @mAAdhaTTah other people testing it would be great. I think the only known \"big\" issue right now is a solution for cloning private repos. So other than doing that manually (either via SSH keys or get SSH forwarding working), it should be mostly good.\nThe only thing I haven't really documented is that the new server.yml playbook won't actually install WordPress like dev.yml does. Obviously it can't until the site is deployed.\n. @fullyint thanks, that's good to know it's mostly working. I'll test out SSH forwarding as well and then just make the small change + document it.\nI agree that Ansible's extra-vars is clunky. I was thinking of just creating a simple bash wrapper script so you'd just do: deploy production example.com for example.\n. If it's hanging I'm guessing it's asking for a sudo password and waiting. Did you have the latest updates? Specifically this one: https://github.com/roots/bedrock-ansible/commit/6fc553e4057dcf041446da8ec2c06f8f9338300b\n. @mAAdhaTTah I think for now there will just be a script for deploying. Next step after merging this would be to merge secure-root.yml into server.yml. It's confusing to have it optional right now and leads to inconsistencies. Plus it's just a good practice anyway.\n@fullyint forgot to reply about your project setup. You didn't mention if your theme/plugin are being re-used across different projects. My recommendation is always to bundle your theme in your project repo. The only exception is if it's being across multiple sites/projets (and not just MU). And even then you're probably likely to have a base parent theme as a Composer dependency and then small site specific themes in their repos.\nAnd for @fullyint and @mAAdhaTTah this leads into the discussion about what will be included by default in deploys. @fullyint's rsync process is \"non-standard\" to me so it won't be included.\nWhat's currently missing from this project (and the new deploys) is a solution for asset compilation. There's a couple of options:\n1. Add packages like Node.js + npm + bower + gulp/grunt globally by default and make project_post_build_commands more flexible to accept a chdir for each command (I'll probably do this anyway).\n2. Include a way for people to easily run local actions during the deploy to generate assets and then copy/upload them to the remote server.\n3. Let the two options above be toggable. Although I'd rather stick to one.\n. @fullyint @mAAdhaTTah added better pre/post commands in https://github.com/roots/bedrock-ansible/commit/2623132b0d5f7e3258c5f3e88b223d69b2808d98. Now you can pass an optional sub directory to run the command in :)\n. Added the wrapper script.\nUsage: ./deploy production example.com\n. Renamed deploy_user to web_user. Default user name is also now web.\n. @fullyint I think I might leave the variables in deploy.yml as is for now. I don't know why but in my mind it maps more directly to a Capistrano config. Which I realize is probably irrational. We can always clean it up after.\nre: log file. Another thing that's needed but won't hold up this PR.\nre: compiling assets. Funny that by advocating the use of a VM for development makes it harder to locally compile assets. Tools like Node, npm, gulp, etc should be running on the VM. But you run Ansible from your host machine which won't have access to them. That being said, your solution is very simple anyway.\n. @fullyint I was talking with @retlehs and I think we'll just go with the locally compiling by default. I don't want to get into installing Node, npm, Gulp etc. It's also really slow on a VM. Your suggestion looks great. Do you want to do a PR against this branch?\n. @austinpray nope. I mostly meant the provisioning process (compiling latest Node from source).\n. Took forever but thanks for all the help. @mAAdhaTTah @fullyint @austinpray @retlehs :+1: \n. @el-rotny yes ideally the Capistrano configs will be removed from Bedrock and probably just put into their own separate one.\nDocs will be updated in Bedrock as well. We'll also have to document how you can use the deploy.yml playbook without using the rest of this project if someone only wants deploys.\n. I'm wondering if trying to re-use any variable in bedrock_path_server is just more trouble than it's worth. I personally can't use the default right now when I test. I just use ../bedrock locally and example.dev on VM.\n. Not missing anything. You're correct that it would work in my case. I agree that config.vm.hostname is better than what's there.\nI guess my only concern was people with multiple sites but they'd have to do more updates to the Vagrantfile anyway. So if you want to do a PR for this change we'll get it in.\n. I'm not sure any README changes are needed. I assume people are already setting config.vm.hostname since it's in the default Vagrantfile.\n. You usually aren't missing anything. I agree it won't hurt to add a note to make our lives easier :+1: \n. :+1: \n. The Vagrantfile isn't really in a specific order that I know of. You can add most things anywhere.\nHere's the Windows changes integrate into our newer Vagrantfile: https://gist.github.com/swalkinshaw/5266b6869fcbbedf074d\nI'm not sure the following is needed if you run VB as administrator:\nruby\nconfig.vm.provider \"virtualbox\" do |vb|\n  vb.customize [\"setextradata\", :id, \"VBoxInternal2/SharedFoldersEnableSymlinksCreate/vagrant\", \"1\"]\n  vb.customize [\"setextradata\", :id, \"VBoxInternal2/SharedFoldersEnableSymlinksCreate/current\", \"1\"]\nend\n. @fullyint \n1) site_name doesn't need to be a domain name. Just used as an identifier\n2) sure, think it's clearer\n3) config.vm.hostname I've added but I'm not sure how to handle config.vm.network\n4) we can add that too\n. @fullyint good catch, added that change.\n. The issue with basing config.vm.network on a site is that it really has nothing to do with a singular site. Every site would have the same private Vagrant IP for example.\nI think we can solve it by removing 192.168.50.5 from site_hosts by default. It makes no sense to hardcode it in there. Should probably just use site_hosts and also add on ansible_hostname to dynamically include it.\nThen config.vm.network can just remain in the Vagrantfile and most people will never need to change or reference it.\n. :-1: from me for now, or at least really low priority\n. I'm guessing you're using the hostsupdater plugin? Might be a bug in that.\nedit: I know a few other people have seen this as well.\n. There was a problem. Fixed in the commit above.\n. Ditto\n. @s3w47m88 docs page sounds useful \ud83d\udc4d . @austinpray is crazy, he didn't add this one. but @emaildano this still needs to have the formatting fixed + rebase please.\n. It's fine having different values in development, but what's the rationale between the difference? As in why would it be 5k on dev, and 1k everywhere else?\n. Thanks!\n. Try adding require 'yaml' at the top of your Vagrantfile\n. Vagrant version?\n@austinpray Vagrant bundles its own Ruby.\n. There's tons of results for that issue:\nhttps://github.com/mitchellh/vagrant/issues/1941\nhttps://github.com/mitchellh/vagrant/issues/1744\nI can add the require 'yaml' by default but it's strange that it errors for you.\n. @rstormsf we definitely need some better docs which will come as this project matures a little. It does assume you know some Ansible basics for now.\n. @rstormsf improved the README in https://github.com/roots/bedrock-ansible/commit/8880ec4cce92a01269797f32659b10053baa1ccf\n. @rstormsf that's a good suggestion, I'll probably start one up.\n. Ah stupid error. Thanks and fixed.\n. Finally getting back to this.\nI'm thinking the best solution might just to be to keep the necessary subdomain changes but leave the hosts/DNS up to the user?\n. Yeah just add a note about it or they can always just manually add the hosts they need. Odds are it won't be many subdomains.\n. It's definitely possible there's a bug but I'm having a hard time thinking of what could cause this. I've also never used DHCP in Vagrant so can't be much either. If you want to do further debugging you could start with ubuntu/trusty64 and selectively run each role one a time and check when DHCP breaks maybe?\n. @rstormsf just confirming that I'm getting the same issue. Looks like WP 4.1 update changed something about loading themes. Bedrock registers the built-in theme directory location and it can't find those themes anymore.\nI'm looking into this further.\nedit: this is most likely a Bedrock/WP bug though.\n. Figured out the problem.\nThere was a short period of time when Bedrock changed its .gitignore to deal with empty directories like web/app/themes (see https://github.com/roots/bedrock/pull/128). You must have cloned/downloaded Bedrock during this time period. This change caused web/app/themes to not exist which was exposing a flag in WP's theme loading. If you get Bedrock again, or just manually create web/app/themes (with a real theme or with a .gitkeep file in there) and update your .gitignore to match up with master, everything will work.\n. @rstormsf glad you got it working. Not really sure what's causing that. Capistrano only deploys what's in your repository though so if a theme is on the server it must be in your repo too.\n. We haven't installed any SMTP clients because we're in favour is using a 3rd party service like Mandrill, Sendgrid, Mailgun etc.\nBut I do think we should still provide a simple client by default that's only for sending. msmtp and ssmtp both seem simple so I'll leave this issue open until I check them out. \n. All of those services are very similar and usually work in 2 ways: either via their API (raw HTTP calls or a PHP client library), or via SMTP (which you'd need a client like you mentioned).\nTo hook into WP mail there's various plugins. Here's an example of one: https://wordpress.org/plugins/wpmandrill/\nThis one uses curl in the background for their API so not SMTP needed at all.\nIn general you should always use an email service for sending external email. It's very hard and not really worth the trouble to setup your own. If it's just for \"internal\" emails like signups/resets for developers/admin then you don't need to worry.\n. What doesn't? The Mandrill plugin would work for example.\nBut as I said I'm leaving this issue open and we'll add an SMPT client which will fix this problem as well. Then emails will work regardless of what solution people use.\n. Closing this. Realized this solution isn't enough since email should work out of the box on development too without requiring a 3rd party SMTP service.\n. and we're back! Going to stick with as anyone can use their Gmail (for example) in development.\n. Bedrock and hence this playbook has nothing to do with Roots/Sage. I think the proper solution is for us to create another repo under the Roots org which would be a role to install what's necessary for deploying our theme.\n. Keep in mind that the only thing required for Sage is Node and maybe globally installing some packages. Everything else will be part of the deployment process which is already in progress at https://github.com/roots/bedrock-ansible/pull/95.\nThere's also the debate about doing the compiles locally and uploading assets which wouldn't make any of this necessary.\n. @mAAdhaTTah yeah exactly. Ansible can run tasks locally or do local actions and then copy/upload the files.\n. ansible-playbook -i hosts/production site.yml --tags \"nginx\"\n. It's outdated in many other ways as well :( I'll work on getting it updated soon and this will be part of it.\n. Not valid anymore. See https://github.com/roots/trellis/pull/260.\n. What @fullyint covers this issue so I'm locking this.\n. We'll need to see your group vars file for this environment in order to help debug. Just filter out any passwords or sensitive info.\n. @intelligence oops forgot about this. site_name can't  contain a subdirectory like /project. It's just a descriptive name, not an actual URI.\nsite_hosts also can't  contain a subdirectory.\nedit: here's what you should have:\n```\nmysql_root_password: xxx\nwordpress_sites:\n  - site_name: project\n    site_hosts:\n      - sub.domain.com\n      - x.x.x.x (my droplet ip)\n    user: deploy\n    group: www-data\n    site_install: true\n    site_title: Staging\n    admin_user: admin\n    admin_password: xxx\n    admin_email: admin@sub.domain.com\n    system_cron: true\n    multisite:\n      enabled: false\n    env:\n      wp_home: http://sub.domain.com/project\n      wp_siteurl: http://sub.domain.com/project/wp\n      wp_env: staging\n      db_name: xxx\n      db_user: xxx\n      db_password: xxx\n```\n. Any proposals for new files?\n. We'll revisit this once the deploys PR and some cleanup is done. Roles/playbooks are changing due to deploys anyway but I think it makes sense to have the vars split up more.\n. See https://github.com/roots/bedrock-ansible/pull/159\n. Thanks for this debugging log. Seems like there's at least a new bug with fail2ban and I'll look into.\nAnother update that will be included with the Ansible deploys is sudoers access for the deploy user to reload php-fpm and Nginx.\nNote that you should almost always prefer reload over restart for both those commands although doesn't matter much when the site wasn't working to begin with.\n. One more thing, it seems you're using the develop user for deploying in Cap? You can change the deploy_user var to match that and avoid that issue.\n. I've increased the default limit to 20 as well.\n. @louim good catch. Tough to tell how pervasive this problem is but I'm more inclined to include a nightly cron job by default since the memory leak source has been found. And obviously this won't change anytime soon since WP won't switch to anonymous functions.\n. @louim added the daily restart cron job\n. @louim yep, I'll try and do it tonight.\n. If you use bedrock-ansible you basically don't need to generate the .env through Composer. It's really two separate methods which is a bit confusing. I might just get rid fo the .env generation via Composer all together soon.\n. Is there anything changed from the galaxy role? Or is it a straight up copy?\nIf so we should just switch to requiring installing galaxy roles as part of the install process.\n. I'm thinking of adding a requirements.yml or galaxy.yml or whatever (is there a consensus name?).\nThere's a couple candidates:\n- this one\n- ntp (https://github.com/bennojoy/ntp)\n- mariadb (https://github.com/PCextreme/ansible-role-mariadb)\n- memcached (https://github.com/bennojoy/memcached)\n- ssmtp (https://github.com/brisho/ansible-ssmtp)\n. @fullyint I was just looking at that. Problem is our logfiles for WP sites are dynamically defined :(\n. @JacobDorman I'd rather just switch to using Galaxy roles now. The first one can be for this role and including the version number would be good :+1: \nWe'll need README changes as well to update requirements/install process and a note on Galaxy roles.\n. @JacobDorman we're now requiring installing galaxy roles as part of installation so this PR can be redone safely now. See https://github.com/roots/bedrock-ansible/blob/dd74bc493f812e1fe017c86997164482b7009b0e/requirements.yml.\n. You'd need to do two things:\n1. vagrant reload\n2. vagrant provision\nOr just re-create the Vagrant box.\n. It could but check to make your WP url settings are correct here: https://github.com/roots/bedrock-ansible/blob/master/group_vars/development#L19-L20\nClosing this as the original issue is not related to this project in itself.\n. @fullyint if we target the entire directory we could use a Galaxy role. I hadn't thought of doing it by a wildcard.\n. 1. I'd rather not wait on deploys right now. I'm fine with any feature\n   being the first to use Galaxy roles on its own.\n2. Let's go with yml. 1.8 is no big deal.\n3.  requirements.yml sounds good to me\n4. Good idea.  I've run into the same problem before on DO.\nJust a note that we'll require some README updates for using Galaxy roles.\nOn Saturday, March 21, 2015, Phil Nelson notifications@github.com wrote:\n\n@swalkinshaw https://github.com/swalkinshaw I could try a PR adding the\nnickhammond.logrotate https://galaxy.ansible.com/list#/roles/1117\ngalaxy role. But maybe you'll want to finish/merge the deploys branch\nfirst, given that it too begins using galaxy roles (and maybe moves logs to\nsrv/www/example.com/shared/logs). Or, I could submit the PR against the\ndeploys branch.\n.yml vs .txt. If I do a PR, is it ok if I use a .yml file to make\npossible features\nhttp://docs.ansible.com/galaxy.html#advanced-control-over-role-requirements-files\nnot available to .txt files (e.g., choose versions, install from repos\nother than galaxy, etc.)? Using .yml would mean bumping the ansible\nrequirement to 1.8 (Nov 24, 2014), up from 1.6 (May 5, 2014).\nFilename: requirements.yml vs. galaxy-roles.yml. Given the potential of\nroles from remote repos (not galaxy), I'm inclined to omit galaxy from\nthe filename, going with requirements.yml as in the docs\nhttp://docs.ansible.com/galaxy.html#advanced-control-over-role-requirements-files\n.\nSwapfile. As an aside, any interest in a PR adding kamaln7.swapfile\nhttps://galaxy.ansible.com/list#/roles/1262? DigitalOcean's Ubuntu\ndroplets lack a swapfile. MySQL is a routine victim of the oom-killer (see\ncomments\nhttps://www.digitalocean.com/community/tutorials/how-to-add-swap-on-ubuntu-12-04),\nleaving sites displaying nothing but \"Error establishing a database\nconnection.\" I need to learn to tune my system better, but a swapfile seems\nlike a reasonable precaution. I'm not sure of implications for hosts other\nthan DigitalOcean.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/roots/bedrock-ansible/issues/141#issuecomment-84412786\n.\n. @fullyint still want to do a PR for this?\n. I'd definitely run it on your Vagrant VM first to test it out. If it breaks you can always just re-create it.\n\nBut I'm pretty bad about keeping my stuff out to date. Unless I hear about a major vulnerability I usually don't update anything unless I need a new feature.\n. Apologies for the trouble.\n73 is a known bug obviously which should just be fixed. Basically I never wanted to document the bug because that's just silly when I told myself I'd fix it long ago... :(\nThe HHVM bug was a perfect storm of timing. When I developed and tested the feature it worked perfectly. In the few days between that and actually merging it in, HHVM released a new version which has a bug. See https://github.com/roots/bedrock-ansible/pull/145 for details.\n. We're going to be recommending compiling assets locally so none of this software will get installed on the VM.\n. @dstrunk it would be great if you could try this with the deploys brach from #95 \n. Closing this but feel free to re-open if it still occurs now that #95 has been merged in.\n. More errors about this reported:\nhttps://bugs.launchpad.net/ubuntu/+source/ssmtp/+bug/582191\nhttps://bugs.debian.org/cgi-bin/bugreport.cgi?bug=611302\nKind of hesitant to add this by default but there might be a more straightforward way. Could have a variable to define the main hostname and add that if necessary.\n. @louim did you end up using your method to fix this? I'm now thinking it's not a bad idea to always ensure there's a FQDN hostname.\n. @louim feel free to re-open this if you want.\n. Thanks\n. I believe it's still a problem :(\nI looked into this at the time and it was more complicated than it seems unfortunately. Forgot about it since then because we don't use HHVM though.\n. @QWp6t yeah just the standard HHVM install.\n. See https://github.com/roots/trellis/issues/431\n. @enricodeleo thanks so much for getting this started again. I wanted to this to handle this myself though since there's a lot more Nginx configuration needed.\nSee https://github.com/roots/bedrock-ansible/pull/172\n. @enricodeleo do you want to re-do this PR using https://github.com/kamaln7/ansible-swapfile from Ansible Galaxy?\nTake a look at it and let me know if we can use it or if there's a reason not to.\n. @enricodeleo thanks for all this work. Most of this is needed and is good but I'm going to hold on these changes until the deploys branch is merged (hopefully very soon).\n. @enricodeleo I kind of ruined this PR with a lot of updates and rebases in #95 :(\nDo you mind submitting a new PR with just the changes to HHVM and php-fpm? I already commented on the swap PR and we'll handle the SSL one separately as well.\n. :+1: \n. Let's remove the commented out variables in deploy.yml for now. It exists in defaults and will be in the README as well.\nAbout synchronize, for the existing copy task, rsync is only needed on the remote server I assume? If so, that's fine since it's already installed on the VM.\n. But it shouldn't be needed locally for a completely remote operation? I'm hoping :(\nedit: oh this is local to remote of course. Ignore me\n. No, I think it's fine. I realized the same thing about Windows users so it's not as big a deal as I originally thought.\n. :+1: \n. Wow that with_items was kind of useless without this. Thanks :+1: \n. @Telemakhos have you verified your /etc/hosts file to make sure the host got added correctly with the right IP?\nedit: I commented here too: https://discourse.roots.io/t/bedrock-ansible-dev-environment-nginx-timeout/3436/8\nFrom now on you can keep the comments in this issue thread until we know it's not an actual bug. No need to have two separate discussions.\n. @Telemakhos did you install the hostupdater plugin? vagrant plugin install vagrant-hostsupdater\nThe Vagrantfile suggests it but we should add it to README. If you do have that installed there may be a bug auto adding the host.\n. @Telemakhos and the contents of your /etc/hosts file?\n. @Telemakhos it just seems like the host is not being added automatically.\nI see output like this during vagrant up:\n==> default: adding to (/etc/hosts) : 192.168.50.5  example.dev  # VAGRANT: cae2efc8cd65ea67be3ec4b4ae73f3fd (default) / 6f2eb34f-c659-4052-aeb7-5871821154e2\n==> default: adding to (/etc/hosts) : 192.168.50.5  test.dev  # VAGRANT: cae2efc8cd65ea67be3ec4b4ae73f3fd (default) / 6f2eb34f-c659-4052-aeb7-5871821154e2\n==> default: adding to (/etc/hosts) : 192.168.50.5  foo.dev  # VAGRANT: cae2efc8cd65ea67be3ec4b4ae73f3fd (default) / 6f2eb34f-c659-4052-aeb7-5871821154e2\nYou can try re-installing the plugin and maybe Vagrant? Or clear out the local .vagrant folder and try again. Closing this issue though and the original problem is fixed.\n. No longer valid after https://github.com/roots/bedrock-ansible/pull/247\n. @fullyint not really :)\nI've left this here for a bit because it is complicated. It's just a lot of code to go through. But yeah I agree that a library/module would be better suited for a lot of this.\nLet me know what you want to do with this in the short term. Is there anything smaller to break out of it first?\n. Good catch. There was definitely a little bug/gap in logic with that. It was also pretty confusing and you made me realize there's a much simpler solution. I've just updated it in . Thanks!\nFYI: main_site, *other_sites = wordpress_sites\nJust means assign the first element of the array/hash to main_site, and all the others to other_sites:\n``` ruby\n\n\nfirst, *rest = [1,2,3,4]\nfirst\n=> 1\nrest\n=> [2, 3, 4]\n```\n. I figured why not and went through the process. But unfortunately Sourcegraph requires read and write access for hooks and commit statuses. For some reason GitHub also includes that access for my private organizations which for some reason allow 3rd party access (and I don't manage them). For that reason I'm not comfortable giving Sourcegraph access.\n\n\nHopefully I'm not mistaken about this:\n\n. Perfect :+1: thanks.\n. It's failing on this line.\nIt means something is misconfigured in your group_vars/development (regarding wordpress_sites) file. It should look something like this https://github.com/roots/bedrock-ansible/blob/238ca2790e90b39944228a2cc10050a8f9bba8d9/group_vars/development\n. Yeah this makes sense. Want to do a PR?\n. Closed via https://github.com/roots/bedrock-ansible/pull/175\n. Thanks!\n. :+1: \n. Thanks!\n. It's already in the Installation part of the README: https://github.com/roots/bedrock-ansible#installation\n. re: pre_build_commands_local\nI realized why it was before copy project files, I just thought it was more consistent to have pre_build_commands there as well. Although the f500 role has it after.\nre: post_build_commands_local\nThe only use case I had in mind was deploy notifications for services like Hipchat and Slack. But I realized those would have to be done after finalize anyway.\nAlso I'm not even sure how to nicely do this because ideally a user could just specify some simple role/playbook but as far as I know there isn't a nice way to dynamically include these.\nGoing to close this.\n. But doesn't pre_build_commands_local need to be after the deploy_helper init and before \"Copy project files\"? As you said it's dependent on that due to the use of synchronize.\n. Nope, I was just conflating the two separate commands. I'll give it some thought but I'm less concerned without the equivalent post_build_commands_local as well.\n. @fullyint good point about the path names. Updated them all to example.com.\nI'm going to leave the Composer command as is simply because it lets us keep it under project_post_build_commands.\n. @fullyint took your advice and finally moved more variables into defaults.\nAlso added a little message at the end of deploys:\nTASK: [deploy | debug ] *******************************************************\nok: [vagrant] => {\n    \"msg\": \"master@e0f47a8 deployed as release 20150412053432\"\n}\n. Did some naming updates + git commit.\n. @mAAdhaTTah yeah that would be quite easy via the Vagrantfile. I'm not sure I'll include it in this repo but I'll take a look at what it would take.\n. @mAAdhaTTah oh you're right actually. For some reason I was only thinking about it from Vagrant's point of view (as in skipping synced dirs). Didn't think about the Ansible side.\nOne alternative solution: use one BA repo + multiple Vagrant's. You could set a different group name and then create more group_vars/<group> for them. \n. If you want it a little simpler:\n``` ruby\n-- mode: ruby --\nvi: set ft=ruby :\nrequire 'yaml'\nANSIBLE_PATH = '.' # path targeting Ansible directory (relative to Vagrantfile)\nSet Ansible roles_path relative to Ansible directory\nENV['ANSIBLE_ROLES_PATH'] = File.join(ANSIBLE_PATH, 'vendor', 'roles')\nSITE_GROUP = ENV.fetch('VSITE', 'development')\nconfig_file = File.join(ANSIBLE_PATH, 'group_vars', SITE_GROUP)\n...\n  config.vm.provision :ansible do |ansible|\n    ansible.playbook = File.join(ANSIBLE_PATH, 'dev.yml')\n    ansible.extra_vars = { ansible_ssh_user: 'vagrant' }\nansible.groups = {\n  'web' => ['default'],\n  SITE_GROUP => ['default']\n}\nend\n\n```\nGood work :+1: \n. Judging from the errors it seems like your Ansible doesn't like the requirements.yml format which leads me to believe it's an issue with your Ansible version.\nWhat version are you running? We require at least 1.8 now.\n. Finally remembered to look into rkhunter. It's interesting but not something I'm comfortable having in Trellis by default. It needs to be run on a schedule and constantly updated. Just like antivirus software it also wouldn't catch the latest root kits. Thanks for bringing it to our attention though.\n. Updated, thanks.\n. Those repos failing aren't the main ones. We are adding the correct ones here.\nmariadb_dist = trusty set here.\nThose failures you get are \"sub\" repos that are fetched after the main ones are added. I've actually had those errors before as well once or twice but they went away on their own. Have you tried again since then? Or maybe another mirror?\n. This will require some more thought since there's way more WP specific things in this project.\n. @nathanielks I don't really know how to deal with this right now since it involves a lot of other things so I'm gonna punt on it for now :(\n. @rstormsf It's failing because of a sudoers issue. You can customize this variable: https://github.com/roots/bedrock-ansible/blob/5f97284dff3079563f5dcd811b9f27611a627135/roles/deploy/defaults/main.yml#L85-L86\nyaml\nproject_post_finalize_commands:\n  - sudo service hhvm restart\nAnd this is needed too:\nyaml\nweb_sudoers:\n  - \"/usr/sbin/service php5-fpm *\"\n  - \"/usr/sbin/service hhvm *\"\n(or just remove php5-fpm if you aren't using it).\nhttps://github.com/roots/bedrock-ansible/blob/5f97284dff3079563f5dcd811b9f27611a627135/group_vars/all#L17-L18\n. Fixed by https://github.com/roots/trellis/pull/378\n. We can't do this by default though since out of the box this Vagrantfile wouldn't work anymore.\n. :+1: \n. I'd be fine with that change but I'm curious why it fixes the issue. Also skeptical that it really fixes the underlying bug across different use cases (hosts/inventory/hostnames etc).\nAlthough it seems like ansible_hostname is a little strange and not documented well: https://github.com/ansible/ansible/issues/9971\nSo maybe we should just change this anyway and hopefully it also fixes this issue for everyone.\n. @merchantguru want to do a PR with these changes?\n. Fixed by https://github.com/roots/bedrock-ansible/pull/210\n. It's the standard WP salts: https://codex.wordpress.org/Editing_wp-config.php#Security_Keys\nWP has a page to generate them: https://api.wordpress.org/secret-key/1.1/salt/\n. Closed by https://github.com/roots/bedrock-ansible/pull/196\n. This playbook is designed for password-less SSH keys.\nSo this isn't an issue with the github-ssh-keys role. It simply just adds public keys to user accounts. Anything beyond that is your SSH key set up or SSH forwarding.\n. @rstormsf thanks the posting your solution :+1: \nedit: we should probably link to a page about SSH forwarding in the docs/Wiki. I'll try and find a good page but I think GitHub's is the best:\nhttps://developer.github.com/guides/using-ssh-agent-forwarding/\n. I doubt it. It's not something I like to have built into deploys by default. I'd rather people just use WP-CLI or WP Migrate DB when they need it.\nYou can always run something by adding to project_post_build_commands (or pre-build).\n. Thanks!\n. You just need to update server.yml with your sudoers user (which I think you did) and add the following:\nsudo: True\n. What exactly is the issue? The uploaded files don't appear on the remote server?\nJust asking since it completes without errors.\nIn your verbose output you can see the exact command it's running:\nrsync --delay-updates -F --compress --archive --rsh 'ssh  -S none -o StrictHostKeyChecking=no' --out-format='<<CHANGED>>%i %n%L' \\\"/home/ciarl\nill/Development/environments/bedrock/main-site.dev/web/app/themes/wordpress-base-theme/dist\\\" \\\"ciarlill@staging:/home/ciarlill/main-site/releases/20150428143149/web/app/themes/wo\nrdpress-base-theme\\\nAt first glance this looks correct to me (assuming those paths are correct).\n. changed: [staging -> 127.0.0.1] is normal since it's running a local command as you guessed.\n. You can try running that command manually to see what the output is:\nrsync --delay-updates -F --compress --archive --rsh 'ssh -S none -o StrictHostKeyChecking=no'  \\\"/home/ciarlill/Development/environments/bedrock/main-site.dev/web/app/themes/wordpress-base-theme/dist\\\" \\\"ciarlill@staging:/home/ciarlill/main-site/releases/20150428143149/web/app/themes/wordpress-base-theme\\\"\n. I actually think it's working (at least partly). Ansible probably just escapes those strings for internal usage.\nBut if you notice in your last working example of the manual command, you see output like:\n<<CHANGED>>cd+++++++++ dist/\n<<CHANGED>>cd+++++++++ dist/fonts/\nAnd if you look at your original Ansible logs, you see the same type of output for each individual file.\nIt definitely seems like rsync is uploading the files. Maybe something is happening after that?\n. If you have a web console or something where you can access the server, you can run ferm --flush /etc/ferm/ferm.conf\n. @louim yeah it might be best to remove it. I assume that's the default anyway?\n. @louim good point about the branch. Agreed that moving into the project is ideal. That way you'll almost never have to specify the branch depending on your workflow.\nWould you like to do a PR for this?\nLet's keep this issue going for now and we can determine what to document/Wiki depending on what comes out of this discussion.\n. Not sure it's really possible to determine this dynamically without DHCP.\nFrom Vagrant docs:\n\nIt is up to the users to make sure that the static IP doesn't collide with any other machines on the same network.\n\nSo it's still up to the user to ensure this. We'd just be setting one at random.\n. Regarding deploys: rather them just SSH in and run commands.\n. Wondering if we should just set branch by default in staging and production (to staging and master respectively)?\n. I meant in the group var files explicitly. Just so it's visible and people know. We go by the assumption that you're using Vagrant for dev and not deploying so develop wouldn't apply then?\n. Sure :+1: \n. @louim I think the other changes still apply though as well. I'm nitpicking but can you fix the casing on \"git\" and \"Wordpress\" to \"Git\" and \"WordPress\" as well please? :)\n. @austinpray I don't really. That's why it's explicit so it's easy to customize in there. We could just default to master in there as well?\n. Thanks!\n. Leaving this open since it's technically a bug, just not ours. But we'll keep track of it through here.\n. Closing this since it's been fixed in next Ansible release. 1.9.1 will forever be broken and that note about it will need to be left in the README for a little bit.\n. People occasionally get the timed out problem but I don't think it's anything to do with our playbooks specifically. Seems to be some Ubuntu/Ansible/connectivity issue.\nGoing to close this for now unless it can be reproduced.\n. What exactly does your folder structure look like (at a high level)?\n. Looks correct. Is your Vagrantfile like this one: https://github.com/roots/roots-example-project.com/blob/master/Vagrantfile?\n. Oh I see the problem. You edited ansible.playbook instead of the top level constant ANSIBLE_PATH.\nFollow the link I posted above for the correct solution. I'll be adding a fix soon to make Vagrantfile detect your ansible path automatically which will eliminate the need to manually change it.\n. Thanks!\n. Thanks!\n. @chriszarate this is a lot better. Never liked that loop before.\nCould you rebase this since the template has changed?\n. Thanks :+1: \n. :+1: squash\n. 1. I suggest reading through http://docs.ansible.com/intro_inventory.html\n2. Yes that's how it's designed. wordpress_sites is an dictionary and you can define more than one.\n. Fixed by 8f14013\n. Thanks for the report\n. Fixed in:\n- df091c5\n- 41dc1c0\n- aa02388\nThere should be only 1 task remaining which isn't idempotent which is due to an Ansible bug.\n. Thanks!\n. @slackday thanks, should be fixed in 07047a2. No point in having the default anymore.\n. @davekiss can you try with this patch:\ndiff\n- project_subtree: \"{{ project.subtree }}\"\n+ project_subtree: \"{{ project.subtree | default(omit) }}\"\nFound here: https://github.com/roots/bedrock-ansible/blob/4e93afbcd8ecafac76f2eeb41580dcea407b1056/roles/deploy/defaults/main.yml#L4\n. @davekiss oops that makes sense. I'll figure it out.\n. @davekiss thanks, updated in 56045fc\n. Closed by df091c5\n. Think this was just a regression that happened during the big deploy refactor. Shouldn't be there twice though.\n. Closed via https://github.com/roots/bedrock-ansible/pull/224\n. Those are actually different paths:\ncp -rp {{ deploy_helper.current_path }}/{{ item.item }} {{ deploy_helper.new_release_path }}/{{ item.item }}\nNote deploy_helper.current_path and deploy_helper.new_release_path. \"current\" in this case during the deploy is the last deploy. So it's coping the folders from the last/current release to the new release.\n. Ah that's different. I'll look into it.\n. @metaarts I can't duplicate this. Tried deploys on a test VM and on roots.io. You're using Ubuntu 14.04 I assume?\n. Closing since there's no update\n. Won't this break things?\nRight now login_password is using mysql_root_password in a bunch of places. Which I think would just result in failures.\n. I'm good with this :+1: \n. Yeah unfortunately it was on purpose. But mostly because the combination of supporting strip_www and https redirects was getting really complicated in the template. Pre-https support it was fine.\nIf there's a clean/good way of implementing this again I'm open to re-adding it.\n. Re-added in https://github.com/roots/bedrock-ansible/pull/248\n. The only reason we require Ubuntu is because the playbooks are designed for it (as you found it). It just requires more work (and testing) to get it working on Debian and potentially others like CentOS so we just avoid that by going Ubuntu only.\nI'd be open to supporting Debian though if it doesn't require too many changes.\n. @saturday thanks!\nYeah I'd be interested in seeing the changes. Maybe you could push your fork and then potentially do a PR.\n. @JacobDorman does the above work? I'd rather avoid this. I like that you made it development only but it's always good to avoid lineinfile when possible too.\n. Closing for now until there's a reason why an SSH connection can't be used.\n. Not sure why the ansible PPA is defaulting to an unreleased version of Ansible. But thanks for posting your fix :+1: \n. @sebastianneubauer @bbatsche see https://github.com/ansible/ansible/issues/13419\nDowngrade to 1.9.4 for now or follow the manual fix in https://github.com/ansible/ansible/issues/13419#issuecomment-170979499\n. @louim thanks for this. It's looking mostly good. For your questions:\n1. I'm okay with just making it globally enabled for now and not per-site.\n2. I think I'd prefer /var/run. I don't mind that the cache won't be persisted across restarts since it's just a temporary micro cache anyway. Does this directory really need to be created? I think Nginx just handles it automatically. But there's a bigger problem with /var/run. I think it's set to 10% of RAM which means that the Nginx cache would need to be set as less than that. So might just be best to avoid all this.\n3. Let's pick a good default and make it a variable. I'd probably go with less than 1GB though. \n4. I'll have to think about making it default.\n5. Mentioned in README as a feature + explained in Wiki I think.\n. @louim:\n1. per site would be better so let's do that :+1:. Maybe the keys_zone should have the site name in it too?\n2. - \n3. 250MB is a good default\n4. Yep, agreed.\n5. -\n. @louim this looks great. Want to squash and update readme/wiki?\n. @louim it's public now\n. Tested this out and it's working great. Thanks @louim \n. I don't know why but I've never been a huge pagespeed fan. It's mostly just because I've never used it but also unsure but it's reliability.\n. Might want to hold off on the PR.\nWe don't see how this is an issue with the /wp/ sub-directory. Putting WP in a sub-directory is an old, well-known practice which isn't Bedrock specific (see https://codex.wordpress.org/Giving_WordPress_Its_Own_Directory and https://github.com/markjaquith/WordPress-Skeleton).\n. @roosterpark-porch I don't see how that code that would cause any issues.\njs\ndocument.getElementById( 'wp-admin-canonical' ).href\n=> \"https://roots.io/wp/wp-admin/index.php\"\nAnd $_SERVER['REQUEST_URI'] would also include the /wp/ subdirectory.\nAm I missing something?\n. Closing as we can't see a bug with this.\n. This a known, long-standing issue as seen here. Basically I ran that role while creating the base box and I shouldn't have. I've been lazy and haven't updated the base box in forever but I'll put that on my list for this week.\n. Not valid anymore. See https://github.com/roots/trellis/pull/260.\n. Well that was a terrible bug. Thanks!\n. I'll take a better look at this tomorrow but two quick points:\n- I think mysql_user was there for people who wanted to use an external database like RDS for instance (which doesn't use root). Ideally the playbook supports both internal/external DBs.\n- The current password solution was designed not to write a config file on the server with a plain text password in it. Not sure how important this is but it was at least done on purpose.\n. @louim my original idea wasn't to actually create remote databases. I just wanted it flexible that if someone manually made an RDS database they could just enter the credentials under the sites env property and it would just work.\nSo the two options would be:\n1. Everything is local and it creates the databases/user/etc.\n2. Everything is remote and it just uses those DB credentials to connect through WP.\nSo there might be a less confusing way of achieving those options.\n. Going to close this since it doesn't really apply after https://github.com/roots/trellis/pull/260. If there's any separate changes for the remote DB option, then another PR would be better :+1: \n. @louim oh yeah good point. I got all these issues/PRs confused a bit. Let's re-open this. The remote user option still needs to be addressed though.\n. Thanks. This makes sense to me :+1: \n. This is definitely needed and I like this solution a lot.\nThanks :+1: \n. @louim good question that I overlooked too. You'll always need to customize the tasks I guess but at least with this you can leave the base template alone. I'm not sure how much more we can do beyond that.\nWe could have a task that copies over templates/files into the includes.d folder although it would have to be aware of which site it belonged to somehow.\n@chriszarate any ideas on this?\n. @louim's solution is good but I'd do both files and templates. No need for the option as with_fileglob should just work.\n. @chriszarate I'll check if I can think of a better method of doing this without the regex_replace.\n. @chriszarate I got nothing. basename is useful but no way to get the parent directory alone. Think I'm okay with the regex_replace solution. The regex itself isn't too bad.\n. @chriszarate I get failures on this because the subdirectories of /etc/nginx/includes aren't created first:\nDestination directory /etc/nginx/includes.d/example.dev does not exist\n. Makes sense to me :+1: \n. @davenaylor I had already made a change so see here: 9a77834\n. :+1: \n. :+1: much better and clearler\n. Thanks!\n. @zamber would you be up for doing a PR to change this configuration?\n. We already have the sshd role but it's currently only run from the secure-root.yml playbook. What should we do is always run the sshd role and just toggle the sshd_permit_root_login variable to remain at yes unless the user wants secure root. I believe that's the only default (and maybe sshd_password_authentication) that we won't want by default. Then we can add a variable to set UseDNS to no.\n. Of course. It would be nice to have and should be a pretty simple role to add. Would you be interested in doing this?\n. :+1: to what @louim said\n. It is basically objectively wrong to use a library such as PHPUnit globally. The reason why is as everyone mentioned: it's a dependency like anything else and should be treated as such.\nI'm fine with adding vendor/bin to $PATH to the vagrant user's /etc/bash.bashrc.\n. Good find. Definitely a recent update as the current config used to get A+.\n. Awesome :+1:. Think that \"Create SSL directory\" is better in the Nginx role anyway.\n. @louim I also suggested we just don't run it on development. Simplifies the logic.\n. @fullyint let's just go with when: true in [dynamically-created list of booleans]\n. getenv always returns a string anyway. So you'd need to check the variable contents if its True or 1. Is that correct @nathanielks?\n. @nathanielks but is that because of the context you're using it in? Since PHP does a lot of auto coercion.\nBecause http://php.net/manual/en/function.getenv.php says string\n. Interesting but doesn't matter right now:\n\ntemplate code now retains types for bools and Numbers instead of turning them into strings If you need the old behaviour, quote the value and it will get passed around as a string\n\nThat's for Ansible 2.0 in development\n. @nathanielks I did some tests:\nyaml\nenv:\n  foo1: true\n  foo2: True\n  foo3: 1\n  foo4: 0\n  foo5: 'true'\nphp\nvar_dump(getenv('FOO1'));\nvar_dump(getenv('FOO2'));\nvar_dump(getenv('FOO3'));\nvar_dump(getenv('FOO4'));\nvar_dump(getenv('FOO5'));\nResults in:\nstring(4) \"True\"\nstring(4) \"True\"\nstring(1) \"1\"\nstring(0) \"\"\nstring(4) \"true\"\n. Going to close this since tests that both myself and @louim did show that PHP always loads env vars as strings. \n. ansistrano looks interesting and there might be some stuff we can copy from it. But the deploy role we already have is using https://github.com/f500/ansible-project_deploy_module which is actually going to be merged into Ansible modules: https://github.com/ansible/ansible-modules-extras/pull/110\n. Also our current deploy role is pretty close to Capistrano anyway. The f500 project is also modelled after the Capistrano workflow.\n. @getdave thanks for this work.\nI'd actually say this work itself is fine and up to our \"standards\". Nothing stands out as being wrong or anything. So while the implementation itself is good, it's the functionality I'm not sure about.\nAs a few others mentioned, this might be better as an external role. But at the same time I think there's more we should be doing to make testing easier and encourage it with Trellis since it's important.\nI personally hate the default method of testing WP. It's pretty awful that we need to use SVN to pull down this other library which contains the testing library and use a completely different config file for it. \nA better method in my opinion is using something like http://giuseppe-mazzapica.github.io/BrainMonkey (see http://giuseppe-mazzapica.github.io/BrainMonkey/docs/wordpress-why-bother.html also).\nProblem of course is that it doesn't test integration with WP core. You'd still need to do what this PR has.\n. @getdave summary seems correct. What I could be in favour of is automatically creating a test db in development. This could be done based on the db_name though and just append _test.\n. Good idea! Thanks.\n. Looks good. Can you do a squash first?\n. Thanks :+1: \n. Thanks @bezko. Went with https://github.com/roots/trellis/pull/269\n. :100: good work @fullyint \n. Thanks\n. :watermelon: \n. @louim I just assumed you still needed forwarding enabled on the host machine on top of the Ansible config setting. Is that not the case?\n. @louim good to know.\nI agree we can remove that then and add a mention somewhere about ssh-add.\n. @louim good idea about checking git ls-remote with a custom error message. There's probably a few other places we can do that as well but out of scope for this PR.\n. This should be good to go. Squash commits :+1: \n. Great work, thanks @fullyint \n. :+1: assuming @austinpray's test is good\n. These certs can be \"wildcard\" ones and support multiple domains. Common name should be the \"main\" domain (first one I guess) and then the others can be set under Alternate Names.\nExample: http://blog.endpoint.com/2014/10/openssl-csr-with-alternative-names-one.html\n. Tested and works for me :+1: \n. This is great :+1: \nIt would also be nice to detect beta versions since we've had a few people get errors because homebrew (I think) installs the version 2 beta by default for some reason. But I'm not sure if there's a consistent way to detect that.\n. @louim shouldn't this be the very first task to run?\n. This PR is so good it prevents me from using Trellis:\n\nYour Ansible version is too old. Trellis require at least 1.9.2. Your version is 1.9.0.1\n\n:joy: \n. Closed via 302\n. @CFXd I'm trying to think of another solution to this so just leaving this open for a bit.\n. Closing since this will change base on #305.\n. @alan-c good catch on the wp is-installed task. I'm good with removing it after looking at the WP-CLI source :+1:. Do you want to do this?\n. This works but it results in the task always being reported as \"Changed\". Would be nice to tweak change_when to fix this. It shouldn't be changed if stdout contains \"WordPress is already installed.\"\n. Trellis doesn't user Bower anywhere. Maybe this error came from following https://github.com/roots/roots-example-project.com?\nIf so, the bower install command that is run is a local command run on your machine. You have a permissions problem but there's nothing we can do about that unfortunately.\n@ptibbetts :+1: \n. @fullyint looks good. Want to do a PR?\n. I've never run into this either or had any other bug reports of it. If you have any more details we can re-visit this.\n. Closed via https://github.com/roots/trellis/pull/313\n. Stouts looks good. It would be nice to see what kind of configuration would be needed to support Trellis by default.\n. Closing this as per @austinpray above\n. Think it's good as is. Thanks :+1: \n. We're only going to support core/native WordPress functionality here. We made that a default variable so it could easily be overwritten.\nJust re-define nginx_skip_cache_uri in group_vars/all.\n. See http://docs.ansible.com/ansible/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable\n. :+1: \n. I don't think omit works in this case. I believe the problem is that Ansible evaluates the lookup before it's actually used in the module argument.\nWe've bene making progress in making Trellis more user-friendly with better errors. So instead of commenting this out I'd rather we do a check if keys exist and fail with a helpful error message if not.\n. I'm going to close this for now because I'm not comfortable adding this kind of complexity. I think this feature would be great but just not liking the solutions it requires.\n@evanfuture thanks for sharing these.\n. Closing this since it's an upstream Vagrant issue.\n. @JacobDorman not sure would have to test this again. If you're able to that would be great as well.\n. squash and we're good\n. Thanks :+1: \n. If we did an option it would probably look like:\nyaml\ncache:\n  enabled: true\n  backend: redis\nOr something like (since that conflicts with current microcaching variable).\nSometime in the future I'd like to find a better default caching recommendation and include that by default.\n. @rohmann not too complicated at all. That's easily achievable right now with Trellis.\nProblem I have with most caching plugins (including Batcache), is there's a lot of common scenarios where cache invalidation does not happen.\n. Closing this since memcached might not even stay by default. We either have \"official\" caching (non-microcache) solution or just let people do whatever they want via custom roles.\n. It's probably not needed but it's still a different type of cache which might provide additional benefits.\nTrellis' micro-caching is \"full page\" caching, but it's very short lived. So requests still get through to WP even if the page hasn't changed/cache not busted. Those requests would still benefit from object caching persisted to something like Memcached or Redis.. PHP 5.5+ has built-in opcaching which kind of eliminates the need for APC. I can't really speak to APCu. There might be some additional optimizations?\nBut you're correct that with singe server setups there's not much point in using Memcached/Redis for an object cache.. This is great :+1:. Just a few minor suggestions. I really like the helpful error message as well.\n. Tested and works great. Thanks!\n. Anyone who wants to help on this PR can run this command and paste the results:\nNote: you may need to adjust the name/path of access.log.\nbash\necho $(( `awk '($9 ~ /200/)' access.log | awk '{print $10}' | awk '{s+=$1} END {print s}'` / `awk '($9 ~ /200/)' access.log  | wc -l` ))\nIt will output the average size in bytes of your responses.\n. @BrandonShutter fyi going back to the original Discourse thread you had set 32 32k as the value. This actual results in 32 * 32k = 1024KB = 1MB which is huge.\n. @brocheafoin thanks! Interesting results.\nAccording to that gist you may actually want to set fastcgi_buffer_size which is specifically for HTTP header size. Your error message leads me to believe it's only talking about the header size and not the entire response size.\n. @brocheafoin I don't know that much about it so as long as it's fixed on your end :+1: \n. 8 8k seems like a safe default option so going to merge as is.\n. I don't think we should ever have local permissions being transferred over by default. I'd say it's just a bad practice since you wouldn't expect it and could lead to issues.\n644 should be good.\n. @fullyint looks good :+1: \n. Fixed by #309\n. Tested and working great. Want to squash?\n. Wow that's hilarious. They even named the dir hooks. I was just thinking earlier I should see if that project had been updated since I hadn't looked in a long time.\n. Fixed by https://github.com/roots/trellis/pull/378\n. Hmm I'm hesitant to add a plugin just to handle this. It also doesn't account for when updates are made to requirement.yml. You'd still need to manually run the command at that point.\n. @QWp6t  all is an Ansible concept for \"every group\" so we can't change it.\n. :+1: \n. If you want to deploy with Trellis then you'd use our deploy.yml playbook. But if you want to use Capistrano then don't use Trellis at all.\n. > Trellis is an end-to-end solution for WordPress environment management. \n\n\nReproducible development environments with Vagrant\nAutomate the configuration of high-performance production servers\nOne-command deploys for your WordPress sites\n. Yeah they key to redirecting from https -> http is that a cert is needed anyway as @louim said. So we don't care about that.\n\n\nThe www variable (with a better name) should be moved into a WP site wordpress_sites[site] as well.\n. Closed via https://github.com/roots/trellis/pull/452\n. Think I'm onboard with this :+1: \n. @fullyint can you do a PR for doc updates on https://github.com/roots/docs?\nWe should merge at the same time.\n. @fullyint this will need an update to windows.sh unfortunately\n. @fullyint squash + changelog entry? Ready to merge after that :+1: \n. @alan-c did you have a solution in mind for the initial log file permissions? I'm thinking they should be www-data for consistency.\n. @alan-c sorry just getting back to this. A Vagrant solution would only fix this in development though and it appears the bug is happening on remote servers as well. So I'm not exactly sure what we can do here.\n. If this bug still exists it's only on development which is fine /shrug\nOtherwise it's working as is:\nplain\ndrwxr-xr-x 2 web      www-data     4096 Apr  2 06:25 ./\ndrwxr-xr-x 5 web      www-data     4096 Mar 26 01:08 ../\n-rw-r----- 1 www-data www-data 23455918 Apr  8 21:04 access.log\n-rw-r----- 1 www-data www-data 21456006 Apr  2 06:25 access.log.1\n-rw-r----- 1 www-data www-data  2566684 Mar 27 06:25 access.log.2.gz\n-rw-r----- 1 www-data www-data  1982755 Mar 19 06:24 access.log.3.gz\n-rw-r----- 1 www-data www-data  2517788 Mar 13 06:24 access.log.4.gz\n-rw-r----- 1 www-data www-data  1938635 Mar  5 06:25 access.log.5.gz\n-rw-r----- 1 www-data www-data  2378826 Feb 27 06:25 access.log.6.gz\n-rw-r----- 1 www-data www-data  1985043 Feb 19 06:25 access.log.7.gz\n-rw-r----- 1 www-data www-data  2535391 Feb 13 06:25 access.log.8.gz\n-rw-r----- 1 www-data www-data   210423 Apr  8 20:38 error.log\n-rw-r----- 1 www-data www-data   175521 Apr  2 06:07 error.log.1\n-rw-r----- 1 www-data www-data    82301 Mar 27 05:29 error.log.2.gz\n-rw-r----- 1 www-data www-data    12458 Mar 19 04:56 error.log.3.gz\n-rw-r----- 1 www-data www-data    18068 Mar 13 06:22 error.log.4.gz\n-rw-r----- 1 www-data www-data    16574 Mar  5 04:15 error.log.5.gz\n-rw-r----- 1 www-data www-data    27157 Feb 27 06:06 error.log.6.gz\n-rw-r----- 1 www-data www-data    27647 Feb 19 05:15 error.log.7.gz\n-rw-r----- 1 www-data www-data    36021 Feb 13 05:46 error.log.8.gz. @fullyint no need for mysql_root_user to be vaulted.\n. @fullyint let's move forward with this :+1:\nCan you work on a new doc section?\n. @mxxcon not really. Keep in mind all of this data should still be kept in private repos. I only consider \"secrets\" as applicable for vault.\nI agree that vault_sudoer_passwords should probably be env dependent.\n. Good :eyes: \n. @louim any thoughts on this?\n. Good idea :+1: \n. @austinpray I can't find too much information on this beyond that Chrome and Safari enable it by default. But I'm not sure if their default has \"block\".\n. Closing this as discussed in https://github.com/roots/trellis/pull/324\n. @brocheafoin thanks for this. 16k is pretty huge though. I'm fine with adding this variable but I'd rather keep it at the default 4k and let people override it as they need.\n. Closing since there's been no updates. Feel free to re-open if you have time to update it.\n. Thanks that was a silly error.\n. I highly doubt we'll want to use the WP plugin. I'm assuming that's more for people without the benefit of tools like Ansible :)\n. @mxxcon we can implement a monthly cronjob\n. No one has actively started work on this yet. There's a few ansible modules that already exist for it but all of them are very lacking (from what I've seen). That one doesn't handle renewals yet which is a requirement since they expire every 90 days.\n. See https://github.com/roots/trellis/pull/518\n. @jsilence thanks for this bug report. I can reproduce the problem as well.\nI found that installing php5-mysqlnd manually fixed the issue. The entire php role is skipped when HHVM is enabled so we can't just add a package to roles/php/tasks/main.yml.\n. See https://github.com/roots/trellis/issues/431\n. Want to update the staging file as well?\n. Oh I see\n. Thanks!\n. See https://github.com/roots/trellis/pull/343\n. @ckovey thanks for this. Just had a couple minor style issues. Would you be able to squash commits once it's ready?\n. @ckovey looks great. We'll eventually need to add some documentation that we support other providers now but this is still good for now.\n. @ckovey could you rebase this? should be good to go after that.\n. @merchantguru it should.\n. @merchantguru awesome, thanks for testing.\nI agree about the networking error. Unless that error would happen on a standard first Trellis install then we shouldn't worry about it.\n. @ckovey thanks for this!\n. Thanks!\n. See https://github.com/roots/trellis/issues/431\n. Docs: https://github.com/roots/docs/pull/2\n. @fullyint squash + CHANGELOG update?\nLooks good :+1: \n. @storm2k just wanted to double check if you were using a recent version of Trellis on the server this occurs on?\n. Found out what's causing this. It was a regression caused by FastCGI caching.\nNginx add_header under a location wipes out the headers from the server block. So once we added a header for the PHP files, the other headers are no longer present. Working on a fix for this.\n. It wasn't named ansible because the project was bedrock-ansible.\nBut this does bring up a good point of whether this should be renamed to trellis anyway.\n. @dagobertrenouf thanks. Squash would be great :+1: \n. Thanks!\n. @redconfetti thanks for the detailed notes :+1: \n. @ckovey I realized this should probably only run once after the initial install. Someone might change the structure in the admin after and then a re-provision would overwrite it. Not exactly sure what the solution is yet.\n. @ckovey have you had a chance to look into the issue above or should we take it over?\n. @ckovey thanks, it's looking good. We'll test as well.\n. @ckovey just getting back to this now. Looks good except for the two small things :+1: \n. Thanks @ckovey :100: \n. There's a few options for Nginx but this looks like a simple one (untested):\nnginx\nlocation ~* /app/uploads/.*\\.php$ {\n    deny all;\n}\n@erikbelusic as you said this should probably live in https://github.com/roots/trellis/blob/master/roles/nginx/templates/wordpress.conf.j2\n. (?:uploads|files) just checks for either uploads or files. ?: means a \"non-capturing group\" as () usually captures the matching part.\nnginx\nlocation ~* /app/uploads/.*\\.php$ {\n    deny all;\n}\nThis is simplest/most direct check since that's the Bedrock path for uploads. We should figure out what the path would be for uploads on a network site though as well.\n. Looks like we only need that regexp. @erikbelusic want to test that and do a PR if it works? Should probably go here https://github.com/roots/trellis/blob/d8c655082de710f84a780e4b937a0688c57cbfab/roles/nginx/templates/wordpress.conf.j2#L2 above the main location.\n. MS would just look like app/uploads/sites/<id>/year/month/filename which is covered by ~* /app/uploads/.*\\.php$.\nThe rest of Trellis assumes a Bedrock structure so we only support that by default.\n. We use a separate cron file for this. See here.\nThe path it exists at is something like /etc/cron.d/wordpress-example_com.\nI just tested a default Trellis install and this file exists. Running your script says \"no crontab\" for all users though so I'm not sure that command finds files in cron.d.\nIs the cron actually not working? Or you just couldn't find it?\n. Try /var/log/syslog and grep for CRON. But yeah you can always do that test. Or schedule a post to be published.\n. @erikbelusic great debugging! @austinpray is correct that this needs to be fixed in Trellis. We'll need to check for SSL on development in here https://github.com/roots/trellis/blob/d8c655082de710f84a780e4b937a0688c57cbfab/roles/wordpress-setup/tasks/main.yml#L26.\nI renamed this issue to reflect the problem.\n. @austinpray also had a good idea to add the self-signed certificate as a root cert so it's recognized as valid.\n. Looking at this: http://unix.stackexchange.com/questions/90450/adding-a-self-signed-certificate-to-the-trusted-list\n@austinpray I'm not even sure that the curl command would support the \"trusted\" route.\n@erikbelusic it would be great if you could test out the two methods in that post. See if curl works after doing the ca-certificates method and also using the curl --cacert  /path/to/CA/cert.file https://... method.\n. @erikbelusic this is great. Thanks for testing these out.\nI agree that the best solution is the --cacert for curl for the reason you mentioned.\nYou can actually can use control structures/Jinja in the YML files. It just gets ugly and should ideally be avoided. Example: https://github.com/nickjj/ansible-ferm/blob/v0.1.2/tasks/main.yml#L33-L37\nThe solution is probably to duplicate the Cron task and modify the when conditional. Maybe register the Generate self-signed certificates task as a variable and check if its defined in the cron task. If its not, then there's no self-signed cert. If it is, then there is and use the --cacert option.\n. @erikbelusic the registration would be done where the task is done. Just by adding register: <var_name>.\nI believe that variable would be available during the cron task. See http://docs.ansible.com/ansible/playbooks_variables.html#registered-variables\nI suggested the variable method because as you figured out that conditional is quite messy.\n. @erikbelusic thanks for reporting and debugging this. Decided to go with the simple -k solution.\n. Correct. You'll just need to change the apt_repository and maybe the extension package names as well.\n. @erikbelusic yeah you probably have created a branch but it's not a big deal. You can always re-create your fork.\nOne more thing: we usually like to keep PRs to a single commit (unless there's a reason for more) to keep our Git history clean. Would you be able to squash these two commits into one? We can provide instructions if you haven't done it before.\nAlthough I just realized that's the best reason to do work on a feature branch since you need to force push after a rebase/squash and obviously you should avoid that on master :)\n. @erikbelusic perfect! Thanks.\n. @erikbelusic yep I'd definitely do that.\n. @chriszarate yeah I'm not sure about this. I might have a philosophical objection but also concerned about adding options like this vs a single way of doing it.\n. @BrandonShutter I personally find typing the password a strong reminder for what is actually going on.\nMight not actually be a valid reason though.\n. Closing this for now. @chriszarate feel free to re-open whenever you get a chance to work on this again.\n. @chriszarate good to go or not yet?\n. Closing this for now. @chriszarate feel free to re-open whenever you get a chance to work on this again.\n. I'm thinking we should keep this explicit for now. Maybe if we get better multisite handling in the future we can revisit it but I'd rather not silently set up hosts which could be confusing.\n. @QWp6t add CHANGELOG update\n. :+1: \n. This makes sense and is definitely better for security. Just needs some testing :+1: \n. Looking into this again...\n@kulturavashchi @louim could you provide some examples of plugins that write files outside of uploads? And when/how they write them?\nI know there's plugins like Batcache where you manually need to copy files but that wouldn't be changed with this PR.\n. Fixed by https://github.com/roots/trellis/pull/367\n. @austinpray PRs accepted\n. This has been removed. I don't know if the slight inconvenience warrants any solution but feel free to submit a better implementation.\n. @alan-c possible to get a squash? Looks good :+1: \n. Thanks!\n. Original: https://github.com/roots/trellis/pull/320\n. And toggle this: https://github.com/roots/bedrock/blob/6f0d96047d53c5552b4d68a1d9d1d20a235adffe/config/application.php#L66\nBut we could change this conditional as well to check for multisite: https://github.com/roots/trellis/blob/124dbc7252951cb21b3415380ff87cf0b891ba5d/roles/wordpress-setup/tasks/main.yml#L29\n. @starise I don't think we'll ever make this work seamlessly for multisite. If you have tons of sites then using system cron can actually be bad. Since you have to loop over ALL the sites some can take a long time.\n. @starise if you'd like to help our docs are on GitHub now: https://github.com/roots/docs/blob/master/trellis/multisite.md\n. @QWp6t pls add changelog entry.\n. Haven't used Docker so I have no idea. If you end up trying it then please let us know.\n. @austinpray changelog pls :watermelon: \n. :+1: \n. Yep and unfortunately it confirms that switching from SPDY to H2 should be held off as long as possible until those usage numbers even out. Or until Cloudflare open sources their custom Nginx version/path/extension which enables both.\n. See https://github.com/roots/trellis/pull/433\n. @mxxcon thanks. Possible to get the commits squashed into 1 if you're familiar with the process?\n/cc @fullyint as well\n. Thanks!\n. Only if you promise there's no bugs :)\nBut yeah this is a good idea for development only. See https://github.com/roots/trellis/pull/392\n. Unfortunately there's no way to link a specific version from the WP-CLI builds at https://github.com/wp-cli/builds/tree/gh-pages/phar.\n@danielbachhuber any suggestions? Maybe tags on that repo for versions?\n. @QWp6t somehow missed those. That can work :+1: \n. @austinpray just updated this to use nightly by default.\n. :sob: yes\n. @retlehs good now??\n. Thanks!\n. @fullyint good catch! Definitely need to remove those.\n. What about project_local_files in here as well?\n. @thiagotalma would you be able to squash these two commits into 1?\nGuide if you need it: https://github.com/ginatrapani/todo.txt-android/wiki/Squash-All-Commits-Related-to-a-Single-Issue-into-a-Single-Commit\n. Landed in 625ca3f1417476a29dc8bef85ba2d92044c0883e\n. I really should have look at the script. Of course it just determines the completions from wp-cli so it will be in sync.\nThanks a lot :)\n. Do you mean the name in VirtualBox? I thought the name always included \"default\" since we don't define it?\n. Confirmed but there's not much we can do.\n\"Setup Users\" is due to groups or password usage. See https://github.com/ansible/ansible-modules-core/issues/1118\n\"Add SSH keys\" seems to also be a core bug since we aren't doing much there.\nWe could potentially set changed_when but they are limited.\n. Obviously this seems counter to what we'd expect. I don't really have anything to say about this unless other people are also experiencing this.\n. Figured I'd test this out myself. I'm a bit dubious of how much these benchmarks matter and they definitely aren't rigorous or anything.\nI timed vagrant up and then the ab bench you posted:\nCPUS: 4 (sysctl -n hw.ncpu)\n\nvagrant up: 7:45.16\nab -n 20 -w http://example.dev/: ~3.3 req/s\n\nCPU: 1\n\nvagrant up: 9:17.21\nab -n 20 -w http://example.dev/: ~4.2 req/s\n\nI ran the ab bench a few times.\nFunny enough I also found this: https://github.com/rdsubhas/vagrant-faster/issues/5\nAnecdotal but I'm leaning towards removing this cpu configuration.\n. @primozcigler thanks for bringing this up. Finally went with 1 as the default.\n. This is looking good :+1: Probably will want to do some tests ourselves but it's pretty straightforward.\n. @mAAdhaTTah this is good to go. Can you squash commits?\n. Thanks!\n. @nbyloff thanks, do you want to create a PR for this? It should be the default in my opinion.\n. @nbyloff your branch got wiped out because you're using master on your fork :(\nWould you be able to restore this or open a new PR?\n. Thanks for sharing this. It's pretty cool and definitely simpler which is something we're trying to get better at.\nWe've just started on a roots-cli project at https://github.com/roots/roots-cli which will go a long way towards that goal. It will automated a lot of the boilerplate setup.\nI'm going to close this issue because of that, but feel free to continue some discussion in here if you want. There might be something in there that would work separate like Trellis. Maybe SSH keys/forwarding for WIndows? I don't know much about that process.\n. Closing this as it's not an issue with Trellis but with roots.io, but thanks for notifying us.\n. Thanks for reporting this + the numbers. Off the top of my head I don't know what the difference/problem could be. I assume Trellis does install and run more software than Homestead but I'm actually not sure from just looking at their list. Trellis is supposed to be as close to your staging/prod environments as possible while Homestead is for development only.\nIf anyone does any more investigation into this I'd be interested. @kalenjohnson might have some insight since he's used Laravel as well.\n. Wait I just noticed the queries and time.\nTrellis: 14 queries in 496ms - full page in 554ms\nHomestead: 11 queries in 143ms - full page in 169ms\nSo obviously this can't be directly compared.\n. @nickkuijpers not saying the queries will make a 300ms difference. But it makes the comparison less valid if they you aren't comparing the same things.\nThe latest query logs above still have different queries and more for Trellis.\n. I'm closing this issue since it's gone a little off the rails. Thanks for reporting this @nickkuijpers but without some reproducible projects/instructions and direct comparisons there's not much we can do.\nIf someone wants to do more thorough research into this I'd be open to any solutions that make Trellis faster.\n. Good catch. It definitely should. WP uses it in a few places to alter behaviour: https://github.com/WordPress/WordPress/search?utf8=%E2%9C%93&q=doing_wp_cron\n. @nbyloff good catch, think you're correct it's not needed.\n. I would say you should have separate DB users :)\nBut regardless, this seems like a good default to have anyway. Thanks!\n. @primozcigler would you be able to squash these commits?\n. Hooks in deploys make sense for a few reasons:\n- It follows a known pattern like Capistrano (and others)\n- It's a more isolated process so there's limited steps where hooks can exist\nI don't think I want to open up hooks to the provisioning process because the surface area is huge. For example, if we add a hook in the spot that your use case requires, how do we justify that one over others? How do we decide where or which ones to add?\nTrellis is still meant to be forked and customized when necessary. Yeah, it kind of sucks dealing with updates in some cases, but we try and make it extensible through the usual Ansible ways with variables.\n. Yeah, you can do that for now. We have some work in progress updates which remove the need for that altogether: https://github.com/roots/trellis/pull/343.\n. See https://github.com/roots/trellis/issues/431\n. Closed via https://github.com/roots/trellis/pull/432\n. @egamipeaks thanks. Updated that and some other old references too.\n. @andrewfrankel thanks for testing!\n. @andrewfrankel weird, I just tried it again fresh and it all worked. The PPA still exists: https://launchpad.net/~ondrej/+archive/ubuntu/php-7.0\nThe other one you used is slightly different: https://launchpad.net/~ondrej/+archive/ubuntu/php. It's for \"co-installable\" 7.0 and 5.6\n. @QWp6t want to add a note about HTTP2 support in README in the \"Whats Included\" list? \n. @QWp6t I'm not opposed to having it customizable as long as it's simple.\n. :tada: \n. https://github.com/roots/trellis/pull/440\n. closed by https://github.com/roots/trellis/pull/444\n. @austinpray proposals? Beyond issuing a warning is there anything we can do?\n. What about just replacing a lot of this cloning/moving subtrees with git archive?\n1. Still clone repo into source dir as usual\n2. Instead of copying files to new release path, run git archive\ngit archive {{ branch }} {{subtree_path}} | tar xf {{ deploy_helper.new_release_path }}\nThis is how Capistrano does it.\n. Closed via https://github.com/roots/trellis/pull/451\n. @austinpray well correct. This only applies to Vagrant so it's development only. But consider this workflow:\n1. User gets Trellis working on development\n2. User wants to provision/deploy to a remote server\n3. User now needs to figure out how to install Ansible and run it locally\nThis definitely simplifies things for development but might make it more confusing for remote servers.\n. @austinpray I'm in agreement that the improvement to the development workflow is worth it regardless. That's the first experience almost everyone has with Trellis anyway.\n@geerlingguy also a good idea :+1: \n. @coderholic it actually looks like we might use https://api.ipify.org instead. I appreciate you taking the time to reply on this repo but in Ansible 2.0 there's going to be a module for IP lookup and I figure it makes more sense to use the service they default to. Unless you know a reason why we shouldn't use that site.\nSee http://docs.ansible.com/ansible/ipify_facts_module.html\n. Closed in favour of https://github.com/roots/trellis/pull/444\n. docs updated :white_check_mark: \n. See https://github.com/roots/trellis/pull/443.\nCan you install the new plugin and see if it works as expected?\n. I believe the exports stuff is from Vagrant itself. We don't do anything special for it or for hosts either. We're just relying on the plugin.\n. Docs: https://github.com/roots/docs/pull/13\n. Tested and works great :+1: \nNeeds a docs update as well.\n. :+1: \n. :+1: \n. @QWp6t :+1: CHANGELOG pls\n. Depends on how long they take.\n$ time vagrant suspend\n==> default: Saving VM state and suspending execution...\nvagrant suspend  1.80s user 0.47s system 37% cpu 5.966 total\nPretty fast on my end. Trellis/Ansible doesn't even get run during either vagrant resume or vagrant suspend so if this is taking a long time it's not Trellis.\n. $ time vagrant resume                                                                                                                                                                                          \n==> default: Resuming suspended VM...\n==> default: Booting VM...\n==> default: Waiting for machine to boot. This may take a few minutes...\n    default: SSH address: 127.0.0.1:2200\n    default: SSH username: vagrant\n    default: SSH auth method: private key\n==> default: Machine booted and ready!\nvagrant resume  2.55s user 0.90s system 21% cpu 16.154 total\n. @itsazzad no, it shoudn't be running it in my experience. What version of Vagrant?\n. We're unable to reproduce this. If it's still happening I encourage you to troubleshoot with the generated Nginx config and see if anything changes by trial and error.\n. Looks good to me :+1: \n. What version of Python are you running? Seems like the solution is to be on >2.7.9\n. Just to confirm, you're using 2.7.10 and it's still not working?\n. Not exactly sure what else to recommend. We've never heard of anyone else having this problem unfortunately.\n. 2.0.0 won't work either. That comment meant they \"downgraded\" to the dev build.\nA workaround would be to remove the finalize task and manually do two things: https://github.com/stivio/ansible-modules-extras/blob/1dd62b13fa532b9335782f26c253495df6df1c1d/web_infrastructure/deploy_helper.py#L446-L447\n1. delete unfinished file\n2. create symlink\nIt's just 2 simple tasks. If you end up doing it maybe we'd add it to Trellis as a stop-gap.\n. @JohnKelty this has been fixed for a while in Trellis. The version requirements are in the README.\n. :+1: \n. It's just a warning actually. We can try and fix it but nothing is actually broken.\n. Thanks for the report.\nWere you toggling the cache setting and just running the playbook again? I just set cache: true on a fresh Vagrant box and everything worked fine.\n. Tested this by toggling the setting and trying with SSL on/off as well. Couldn't reproduce it at all.\n. Wondering if the retrieve and add known hosts tasks for Composer would be better suited for a simple module? Those piped shell commands get a little hairy for Ansible and it's also duplicated in two places.\n. @chetzof no\n. Thanks! Merging this should I agree we should definitely switch.\n. Was going to add this since it's easy (we already have that file), but on second thought, I don't think we should. CORS is an application concern so if someone needs it in production they can always do a custom include. Just enabling it by default in CORS might not be expected and isn't dev/prod parity.\n. See https://github.com/roots/trellis/pull/543\n. Of course it's possible. Google \"Ansible phpmyadmin\" or search for existing roles: https://galaxy.ansible.com/list#/roles?page=1&page_size=10&autocomplete=phpmyadmin\n. @Foxaii \n\nI believe this means that { and % cannot be doubled up i.e. {{ or %% will be parsed incorrectly.\n\nIt's supposed to mean that {% can't appear exactly like that as a combination/group. %% shouldn't be a problem. {{ obviously would though.\n. @dmgawel thanks!\n. :shipit: \n. Just to quickly chime in: I've never seen this particular error and Trellis 0.9.6 and master are both working out of the box. I don't have any guesses on what would cause it either :(\n. I purposely left the imap extension out for Trellis' purposes since we don't need it.\n. imap was really the only one not consciously added. There others were mostly left out since stock WP was working fine without them. I wanted the smallest subset possible but it seems like there's still common ones which should be re-added now. xml and zip being the two main ones.\n. Closed by #503 \nxml, xmlrpc, and zip were added\n. @BrandonShutter would you like to add zip and xmlrpc to this as well?\n. Thanks!\n. Thanks!\n. We'll consider this but in the meantime you can turn them off in your ansible.cfg confg: http://stackoverflow.com/questions/31318881/how-do-you-stop-ansible-from-creating-retry-files-in-the-home-directory\n. How did you install 2.0.1? I just upgraded my version via pip and it's working fine.\n. I'm not exactly sure what the solution is for you, but this isn't a Trellis issue. We've had a few people all try this and 2.0.1 works just fine if it's installed correctly.\nIf Ansible doesn't even detect its own core modules then something is wrong with the install.\n. :+1: I think that's a good idea to run the conf test and fail with a nicer message if it errors.\n. This was added during Let's Encrypt integration. We run Nginx config tests at a few points such as here: https://github.com/roots/trellis/blob/fefb73f20f2923050fc0fc956897038d0567f4d7/roles/wordpress-setup/tasks/nginx.yml#L66-L68\n. I'd be fine adding config.landrush.guest_redirect_dns = false to the Vagrantfile by default but I don't really know enough about it. It seems according to Landrush docs that this should only be done if something isn't working?. Would you mind doing a PR over here https://github.com/roots/docs with a mention of it? You probably know more about it than me :). Added a note to docs: https://github.com/roots/docs/commit/495f0d8ab3ea666dead59eb0c799230a1881679e. Thanks!\n. Good catch. Never noticed until now that those files are red in my terminal :unamused: \n. Can't reproduce\n. Updated this with ea20374 thanks to @fullyint so that the manual letsencrypt_enabled variable isn't needed anymore. We'll automatically detect if any WP sites use letsencrypt.\n. After looking into it, I'd be okay with disabling it by default. Anyone setting up MySQL replication will need to do a lot more manual work anyway so they could just re-enable it.\nIf you want to attempt the PR, this would be a good introduction to Ansible. It would look something like:\n1. Add a task in roles/mariadb/tasks/main.yml and use the template action to create a conf file in /etc/mysql/conf.d.\n2. Create the template in roles/mariadb/templates that the above action uses.\n3. Create a default variable in roles/mariadb/defaults/main.yml which would act as a toggle.\n4. Maybe just skip the task in 1 entirely using a when condition with the variable from 3.\n. Thanks @duncanjbrown. Looks good other than my one comment :+1: \n. Thanks :)\n. Sorry we didn't include many details on this.\nThere's 2 issues with deploying:\n\nDeploying from a branch different than the branch the site is set to (per environment)\nThe above branch being out of date\n\nA deploy does pull from the remote repo but there could be issues if your local branch is different and/or out of date. For example: the deploy role could have been updated since then and you wouldn't have those changes causing a broken deploy.\nSo there needs to be two checks:\n\nYour local branch corresponds to the site's branch (defaults to master)\nYour local branch is up to date\n\nFailure of either of those checks shouldn't abort the deploy. Instead it should require a prompt to manually override and proceed.\nExamples:\n\nWarning: you are deploying from  when the site is set to . Enter \"yes\" to continue if you know what you're doing.\nWarning: your  is not up to date. Enter \"yes\" to continue if you know what you're doing or stop and pull down the latest changes with git pull origin <branch>. Re: the WP-CLI link. We had discussion about it in https://github.com/roots/trellis/issues/391 and decided to lock the version down.\n. Fixed by https://github.com/roots/trellis/pull/525\n. Looks simple enough :+1: \n\nWould you be able to add a section about this to our Windows docs?\n. Some doc updates should accompany this.\n. I'd prefer this to be added to our docs. We have a vault page. Our docs are here: https://github.com/roots/docs/blob/master/trellis/vault.md\nMaybe a note at the end of the 2nd step \"Inform Ansible of vault password\"?\n. Sorry about that, missed a default. For now you can just re-add subdomains: false under multisite for your site and it will work again. I'll add a proper fix soon.\n. Hoping it was admin_user that gave you the error since I could replicate that.\nFixed in fc44e94d6f174792b00833d79a89dd92d4b1daf8\n. No there hasn't been any progress on this.\nWe're still looking for people to help out with it.. Thanks, this looks correct. I'm amazed we missed this and that it wasn't completely broken. I don't know even how an Nginx server block with listen 443 ssl http2 would even work without any SSL details (like certificate).\n. My only concern is duplicated configuration now. And there's still a few things like HSTS and tweaks missing from this server block that exist in the main one. It might be better to generate a separate https config and include it in both places. It would contain this:\n``` jinja\n{% if item.value.ssl is defined and item.value.ssl.enabled | default(false) -%}\n    include h5bp/directive-only/ssl.conf;\n    include h5bp/directive-only/ssl-stapling.conf;\nssl_dhparam /etc/nginx/ssl/dhparams.pem;\nssl_buffer_size 1400; # 1400 bytes to fit in one MTU\n\n{% set hsts_max_age = item.value.ssl.hsts_max_age | default(nginx_hsts_max_age) %}\n{% set hsts_include_subdomains = item.value.ssl.hsts_include_subdomains | default(nginx_hsts_include_subdomains) | ternary('includeSubdomains', None) %}\n{% set hsts_preload = item.value.ssl.hsts_preload | default(nginx_hsts_preload) | ternary('preload', None) %}\nadd_header Strict-Transport-Security \"max-age={{ [hsts_max_age, hsts_include_subdomains, hsts_preload] | reject('none') | join('; ') }}\";\n\n{% if item.value.ssl.provider | default('manual') == 'manual' and item.value.ssl.cert is defined and item.value.ssl.key is defined -%}\n  ssl_certificate         {{ nginx_path }}/ssl/{{ item.value.ssl.cert | basename }};\n  ssl_certificate_key     {{ nginx_path }}/ssl/{{ item.value.ssl.key | basename }};\n{%- elif item.value.ssl.provider | default('manual') == 'letsencrypt' -%}\n  ssl_certificate         {{ nginx_path }}/ssl/letsencrypt/{{ item.key }}-bundled.cert;\n  ssl_certificate_key     {{ nginx_path }}/ssl/letsencrypt/{{ item.key }}.key;\n{%- elif item.value.ssl.provider | default('manual') == 'self-signed' -%}\n  ssl_certificate         {{ nginx_path }}/ssl/{{ item.key }}.cert;\n  ssl_trusted_certificate {{ nginx_path }}/ssl/{{ item.key }}.cert;\n  ssl_certificate_key     {{ nginx_path }}/ssl/{{ item.key }}.key;\n{%- endif -%}\n\n{% endif %}\n```\nThen you'd just include it like:\n``` jinja\n{% for host in item.value.site_hosts if item.value.www_redirect | default(true) %}\nserver {\n  {% if item.value.ssl is defined and item.value.ssl.enabled | default(false) -%}\n    listen 443 ssl http2;\n    include https.conf;\n  {% else -%}\n    listen 80;\n  {% endif -%}\nserver_name {{ host | reverse_www(append=false) }};\n  return 301 $scheme://{{ host }}$request_uri;\n}\n{% endfor %}\n```\n. @swaincreates would you want to take a crack at this? It would just involve creating a new template like here: https://github.com/roots/trellis/blob/fc44e94d6f174792b00833d79a89dd92d4b1daf8/roles/wordpress-setup/tasks/nginx.yml#L50-L55\n. Oh yeah, good point. Okay let's just stick with your original code then for now at least. Could you just ensure it's the same as the main config? Think it's just this missing:\n```\n  ssl_dhparam /etc/nginx/ssl/dhparams.pem;\n  ssl_buffer_size 1400; # 1400 bytes to fit in one MTU\n{% set hsts_max_age = item.value.ssl.hsts_max_age | default(nginx_hsts_max_age) %}\n  {% set hsts_include_subdomains = item.value.ssl.hsts_include_subdomains | default(nginx_hsts_include_subdomains) | ternary('includeSubdomains', None) %}\n  {% set hsts_preload = item.value.ssl.hsts_preload | default(nginx_hsts_preload) | ternary('preload', None) %}\n  add_header Strict-Transport-Security \"max-age={{ [hsts_max_age, hsts_include_subdomains, hsts_preload] | reject('none') | join('; ') }}\";\n```\n. Thanks @swaincreates. Would you be able to squash these commits into 1?\n. :+1: to @fullyint's solution. Although the duplication isn't bad here I could easily see us updating one of these code blocks in the future and forgetting about the other one.\nThanks for being patient @swaincreates :)\n. Tested and working, thanks!\n. What was your issue? I tried a new server and tested main site + redirects and some other pages just now.\n. :+1: \n. Going by your last cert chain, it looks like this is the problem: https://github.com/roots/trellis/pull/534\nIt's been fixed but you'd need to update Trellis and re-issue your SSL certificates.\n. Yeah you'd need to manually delete the cert + key. Our role skips re-creating them if they exist since it would exhaust Let's Encrypt quotas.\n. You might need to delete the CSR in /var/lib/letsencrypt/csrs as well. So make sure that's deleted, the certificate, the bundled cert file and the key file.\n. In #489 @retlehs had said that adding $realpath_root didn't work. However in my tests, adding it to the cache key correctly resulted in a cache miss on the next request.\n. So much better :+1: \n. :100: \n. /cc @QWp6t\n. :+1: other than minor nitpick\n. Working for me :+1: \n. Thanks, got a proper fix here: https://github.com/roots/trellis/pull/551\n. @richvida that's an unrelated problem. I figured out what was wrong and added some more to our docs: https://roots.io/trellis/docs/multisite/\nYou need to set wp_home and wp_siteurl.\n. :100: \n. Also see the docs: https://roots.io/trellis/docs/wordpress-sites/#passwords-secrets\n. Can you try running both of these commands on your server and give the output:\nwp core is-installed --network\nwp core is-installed\n. It probably doesn't return anything if it succeeds. Would need to check the return code after each command with echo $?. 0 means success, anything else means failure.\n. Good improvement :+1: \n. :100: \n. development gets even simpler :dancers: \n. @aried3r that role looks decent from a quick glance. We could use something like that or just add our own changes to the sshd config.\nWe're actually already using another role that we imported: https://github.com/roots/trellis/tree/master/roles/sshd\nSo we could switch or just update that template. If you're interested in helping let us know \ud83d\udc4d \n. @aried3r sorry never replied to this. https://github.com/dev-sec/ansible-ssh-hardening looks good. Would you be interested in implementing it?\n. @isynergy-development yep \ud83d\udc4d \n. @RiFi2k got a PR up here: https://github.com/roots/trellis/pull/573\n. :+1: \n. Working great :+1: \n. Add changelog then merge :)\n. Sure, why not :+1: \n. :+1: \n. :+1: \n. Thanks for the awesome bug report!\nYour understanding of reverse_www is correct. I (now) very obviously broke this in https://github.com/roots/trellis/pull/525.\nJust opened a PR which should fix this: https://github.com/roots/trellis/pull/570\n. Docs have been updated: https://github.com/roots/docs/commit/ce8e5508ef49a947ec167e4052a5cd7b2fa99e19\nThanks\n. I responded on your Discourse thread: https://discourse.roots.io/t/error-on-the-install-the-ansible-galaxy-roles-step-of-trellis-installation-newbie/6611/3\nThis is not a Trellis issue.\n. Looks good \ud83d\udcaf \n. Yeah, just to be clear: your local /etc/hosts file overrides everything else. You can override a .com as well. It doesn't matter if it's a real domain, real TLD, whatever.\n. I've got a PR up to use WP-CLI but it needs to wait for a new release: https://github.com/roots/trellis/pull/583\n. \ud83d\udc4d \n. See https://github.com/roots/trellis/pull/602\n. Sorry for the delay on this. Make sense since we're doing this already in another place \ud83d\udc4d \n. I'm fine with adding this but the default is actually 4k on Ubuntu.\n\nBy default, the buffer size is equal to one memory page. This is either 4K or 8K, depending on a platform\n\nbash\n$ getconf PAGESIZE\n4096\n. Thanks :)\n. I just added a validation to catch when the vault config hasn't been updated to match wordpress sites: https://github.com/roots/trellis/pull/823\nSo people shouldn't run into this specific error anymore.. Thanks for reporting this. Got a PR up here: https://github.com/roots/trellis/pull/590. You can update that manually to try it out before I merge if you want.\n. Good eye, thanks.\n. I'm good with this but we can supposed those warnings \ud83d\udc4d \n. \ud83d\udcaf thanks\n. I think that sounds like a good idea.\n/cc @retlehs \n. Thanks \ud83d\udc4d \n. This thread should provide answers: https://discourse.roots.io/t/production-server-provision-configures-staging-envs-if-hosts-are-the-same-bug-or-intention/6090/6\n. Closing this since it will be fixed by switching to 16.04.\n. Thanks!\n. https://github.com/roots/trellis/pull/597 beat you to it :)\n. Thanks for proposing this @alexandcote but I don't think this is the proper solution yet.\n1. I just realized that deploy_build_before isn't even used in Trellis by default so this line should be removed which I'll do.\n2. If we were going to support hooks per site, we should enable it for all of them which is more complicated.\nIf you need to customize a hook in the meantime, I'd just use a when conditional on tasks within the hook file.\nyaml\n- name: site specific task\n  action: whatever\n  when: site == 'mysite.com'\n. Oops I was mistaken about my first point. That file does exist as an example file.\n. So you get this helpful error message:\n\nvagrant-hostmanager missing, please install the plugin with this command:\nvagrant plugin install vagrant-hostmanager\n\nIt tells you exactly what to do. Install the plugin by running this command: vagrant plugin install vagrant-hostmanager\n. Trellis docs list all the requirements needed as the very first thing: https://roots.io/trellis/docs/installing-trellis/. vagrant-hostmanager is in that list.\nYou're also using an incompatible version of Ansible. Our docs contain the required version.\n. @hintings we've had problems with 1.8.4 and even recommend 1.8.1 and less now. Maybe you just needed to re-install Vagrant.\n. cc @fullyint for the question about cli_options_ping.\n@ptibbetts thanks for this. I had actually tested this myself a few days and got it working with geerlingguy/ubuntu1604 as well.\nAll I had to change was adding python to common packages.\nThere's one issue that I realized with switching to 16.04 though. In our Vagrantfile we support vmware_workstation and parallels providers too. It would be nice to keep support for those if possible. They require different base boxes.\n. @ptibbetts at least there's a VMware box too: https://atlas.hashicorp.com/geerlingguy/boxes/ubuntu1604/\nI'd be okay dropping Parallels for now if we have to.\n. Couple things:\n1. We should probably wait until Vagrant 1.8.5 is out to switch to 16.04. 1.8.4 contains fixes necessary for Ubuntu Xenial but it also has NFS bugs.\n2. We should use https://atlas.hashicorp.com/bento/boxes/ubuntu-16.04 as the base boxes. Vagrant recommends these as the most official/canonical ones. And they have all 3 providers.\n. Vagrant 1.8.5 is out: https://releases.hashicorp.com/vagrant/1.8.5/\n. It looks like the ubuntu/xenial64 box has been updated and it all works.\nI think we should just switch to it for now. We'll worry about finding and testing VMWare and Parallels boxes after.\n. Here's the full diff for what I got working:\n``` diff\ndiff --git a/Vagrantfile b/Vagrantfile\nindex 08f3b3e..a5e1b50 100644\n--- a/Vagrantfile\n+++ b/Vagrantfile\n@@ -34,7 +34,7 @@ if !Dir.exists?(ENV['ANSIBLE_ROLES_PATH']) && !Vagrant::Util::Platform.windows?\n   fail_with_message \"You are missing the required Ansible Galaxy roles, please install them with this command:\\nansible-galaxy install -r requirements.yml\"\n end\n-Vagrant.require_version '>= 1.5.1'\n+Vagrant.require_version '>= 1.8.5'\nVagrant.configure('2') do |config|\n   config.vm.box = 'ubuntu/trusty64'\ndiff --git a/roles/remote-user/tasks/main.yml b/roles/remote-user/tasks/main.yml\nindex 440ad17..7a95686 100644\n--- a/roles/remote-user/tasks/main.yml\n+++ b/roles/remote-user/tasks/main.yml\n@@ -7,16 +7,15 @@\n         ansible-playbook server.yml -e env={{ env }} -u root --ask-pass\n     when: cli_ask_pass | default(false)\n\nlocal_action: command ansible {{ inventory_hostname }} -m ping -u root {{ cli_options | default('') }}\n\nlocal_action: command ansible {{ inventory_hostname }} -m raw -a whoami -u {{ ansible_user | default('root') }} {{ cli_options | default('') }}\n     failed_when: false\n     changed_when: false\n     register: root_status\n\n\nname: Set remote user for each host\n     set_fact:\n\nansible_user: \"{{ root_status | default({'failed':false}) | success | ternary('root', admin_user) }}\"\nansible_user: \"{{ ('root' in root_status.stdout_lines) | ternary(ansible_user | default('root'), admin_user) }}\"\n\nwhen: ansible_user is not defined\ndiff --git a/server.yml b/server.yml\nindex e422a67..9f27637 100644\n--- a/server.yml\n+++ b/server.yml\n@@ -9,6 +9,14 @@\n   roles:\n     - { role: remote-user, tags: [remote-user, always] }\n+- name: Install prerequisites\n+  hosts: web:&{{ env }}\n+  gather_facts: false\n+  become: yes\n+  pre_tasks:\n+    - name: Install Python 2.x\n+      raw: sudo apt-get -y install python-simplejson\n+\n - name: WordPress Server - Install LEMP Stack with PHP 7.0 and MariaDB MySQL\n   hosts: web:&{{ env }}\n   become: yes\n```\nsudo apt-get -y install python-simplejson is what Ansible itself recommends. The symlink wasn't needed either.\n. My testing all worked with the vagrant user. That was an older bug in the box so make sure you run vagrant box update to get the latest.\n. I just tried bento and it's working as well. Let's stick with it \ud83d\udc4d \n. Looks like this needs a rebase from master as well. Some of the changes are already in there.\n. This PR/branch has become a bit of a mess with all the changes.\n@ptibbetts I'm closing it in favour of https://github.com/roots/trellis/pull/626\nIt's all the necessary changes simplified (you remain as author \ud83d\ude04 )\n. Thanks \ud83d\udc4d \n. I think we were doing this for better security? Either way, this install task is only run during development so it doesn't really matter.. There's one more instance of current to change after #616\n. \ud83d\udc4d \n. \ud83d\udc4d \n. Yay awesome \ud83d\udc4d \n. \ud83d\ude4c \n. Really strange that it's only happening on development, but I figured out what's going on.\n@vercotux thanks for the good bug report but always remember to check logs too :)\nIn /srv/www/example.com/logs/error.log:\n\n2016/07/08 03:10:58 [error] 7744#7744: *100 upstream sent too big header while reading response header from upstream, client: 192.168.50.1, server: example.dev, request: \"POST /wp/wp-admin/admin-ajax.php HTTP/1.1\", upstream: \"fastcgi://unix:/var/run/php-fpm-wordpress.sock:\", host: \"example.dev\", referrer: \"https://example.dev/wp/wp-admin/widgets.php\"\n\nI tried bumping nginx_fastcgi_buffer_size to 8k and it fixed the issue.\nIt's a bit of a guessing game with these values but we might have to bump that value permanently.\n. Any ideas about encouraging the use of Ansible Vault? It becomes more important with this change.\nAt a minimum we should probably emphasize it more in the docs.\n. Trying this out and I get this:\n\n|password_hash requires the passlib python module to generate password hashes\non Mac OS X/Darwin\n. After a pip install password_hash everything worked great \ud83d\udc4d \n. \ud83d\udcaf \n. This is good but think I'd rather skip all the wildcard stuff for now. It's currently unused by default and not sure it's worth the potential hassle.\n. Works great \ud83c\udf89 \n. Sucks that this is needed but it's pretty straightforward \ud83d\udc4d \n. Add CHANGELOG entry please :)\n. \ud83c\udf89 \n. Going to close this. It will be replaced with a proper solution to come soon and we shouldn't rely on these network calls which could cause problems.\n. Looks like this was a regression in https://github.com/roots/trellis/pull/613.\n\nDo you want to do the PR to re-add it?\n. Doesn't matter too much but something like \"Re-add apt update to windows.sh\"\n. \ud83d\udcaf so much better\n. Thanks \ud83d\udc4d \n. Docs: https://github.com/roots/docs/pull/47\n. Will manually update https://roots.io/trellis/ after merge.\n. Big thanks to @ptibbetts and @fullyint for their work on this \ud83d\udc4f \n. \ud83d\udc4d \n. Let's go forward with this \ud83d\udc4d \nNeeds changelog + maybe docs?. Awesome work :shipit: . Tested on both 2.0.2.0 and 2.1.1.0. All good \ud83d\udc4d \n. \ud83d\udc4f \n. We mostly agree with you and have discussed this internally before. Couple points:\n1. Yes we should release more often.\n2. Breaking changes since 0.9.7 is fine even semantically speaking. All these updates have been to master without a release so there's nothing wrong with that (except that we should have done more releases in between).\nOur plan (which wasn't much of one), was to start enforcing sem ver as of 1.0. 1.0 has taken way too long as we've been trying to cram too much in before it happened. Something else always came up to move it back like Ubuntu 16.04.\nThe only thing I'd like done before 1.0 is #630 (or another version of it).\nDocs is a separate issue I guess that's harder to solve. We host the docs on https://roots.io and it's difficult to add proper versioning to it. We've looked into it a few times but nothing has happened yet :(\n. @runofthemill that's the plan!\nWe merged in a lot of changes lately so we're going to wait 1-2 weeks and see how stable they are. When they are, we'll be tagging 1.0.0.. 20 minutes is crazy.\nI've personally never seen this happen before. We've known about the xdebug warning for a while but never actually noticed it impacting performance.\nThat php_codesniffer timeout is probably the main problem. 300 seconds is 5 minutes alone and it might be doing other requests too.\nI just ran composer install on your version on a brand new Composer install with nothing cached and got this:\ncomposer install  14.27s user 5.89s system 38% cpu 52.718 total\nSo just under a minute.\nI'd be interested if you could run it on your local machine and compare the times vs the VM.\n. @fullyint this is done right?. See https://github.com/roots/trellis/issues/645 for the real problem. Anything related to this issue will happen over there.\n. You access your site at whatever host you set for it in wordpress_sites. The default is example.dev.\n. There's already issues open for this and it's not related to your original question.\n. \ud83d\udc4f \n. \ud83c\udf89 \n. \ud83d\udc4d  much better\n. I tested these on 4.5.3 and got the same thing.\nAnd it actually makes sense.  HTTP_HOST is a PHP constant so it only exists when it's evaluated as PHP code. WP-CLI is just displaying the raw string in the database.\nThere's something else going on here.\n. @runofthemill interesting solution. Check out #647 where I did something similar. I hadn't though of using ansible_fqdn.\n. Closing since both issues have been addressed and fixed.\n. Awesome \ud83d\udc4d  Yeah making it idempotent would be better\n. Thanks for this @guilro. I'm not opposed to adding a backup feature, but it will take us a bit to consider this and look it over.\n. This will likely be split out into its own role (via Galaxy I guess).\nIt's useful to have development happen here though for more visibility.\n@guilro I'm going to go through and review this. After we can figure out some logistics for integrations. Sound good?. @guilro separate role to start with at least. Thanks for all the work on this \ud83c\udf89 . @guilro looks good to me \ud83d\udc4d Role ended up being pretty simple in the end which is good.\nI'd encourage you to add to our https://github.com/roots/docs repo. Maybe a new page on Backups?. \ud83d\udc4d \n. It's something we'd potentially be interested in depending what the solution entails. If you already have prototypes then it would be great to see them. Either in the form of PRs or Gists.\n. @discopatrick interesting, I've never thought of doing that or heard about it before. I'd be in favour of it but I don't know the consequences.\nIt is pretty annoying to manually run the dev.yml against the Vagrant box right now since you need to use Vagrant's inventory file to ensure the proper settings and SSH key anyway.\nSo yes I'd be in favour of it if there aren't any downsides. Or things that would make Vagrant not work as people using it would expect it to.. Could you try SSHing into the VM and running this:\nsudo apt-get install build-essential libssl-dev libffi-dev python-dev\nThen run vagrant provision again\n. Reference: http://stackoverflow.com/questions/22073516/failed-to-install-python-cryptography-package-with-pip-and-setup-py\nhttp://stackoverflow.com/questions/35144550/how-to-install-cryptography-on-ubuntu\n. \ud83d\udc4f \n. I'm not sure we can just add this rule as a default. People get might cached files without realizing it if they don't have any cache invalidation mechanism.\nIf we did add this, we'd probably use the h5bp config since we already use the others.\n. @pacotole thanks for this but I'm going to close this for the time being due to the reasons mentioned above until you or we can come up with a better solution.\nThis is actually currently possible to add on a per-site basis via Nginx includes. We do this on https://roots.io.\nAdd a file like  roles/wordpress-setup/templates/includes.d/roots.io/assets-expiry.conf.j2:\n``` nginx\nMedia: images, icons, video, audio, HTC\nlocation ~* .(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ {\n  expires 1M;\n  access_log off;\n  add_header Cache-Control \"public\";\n  gzip_vary on;\n}\nCSS and Javascript\nlocation ~* .(?:css|js)$ {\n  expires 1y;\n  access_log off;\n  add_header Cache-Control \"public\";\n  gzip_vary on;\n}\n```\n. Does WP not read the default PHP timezone setting as a default?\n. @regularjack thanks for this contribution but I'm going to pass on this.\nThere's a lot of potential WP options we could set on install and I don't want to set a precedent about which to include or not. I know we already have permalinks but that doesn't mean we should keep adding more. So I'm kind of arbitrarily drawing the line here :(\nMaybe you/anyone else could just a custom post install role to run further customizations.\nRe: https://github.com/roots/trellis/pull/301. I'd actually consider removing it, but it's pretty hard to do. Just removing the code would change anyone's PHP settings back to the default without warning which is not nice.\n. Good catch on this.\nOne issue is that Trellis currently works on both Trusty and Xenial (as far as I know). We should definitely encourage and even require Xenial for new installs, but someone can re-provision an existing Trusty server right now without breaking anything.\nWith this PR as it is, it would update MariaDB to Xenial which might break Trusty?\nMaybe we have to conditionally set those default variables based on Ubuntu version?\n. Oops, I did kind of gloss over that. I was also worried about the task above it:\nyml\n- name: Add MariaDB MySQL apt-key\n  apt_key:\n    url: \"http://keyserver.ubuntu.com/pks/lookup?op=get&fingerprint=on&search={{ mariadb_keyserver_fingerprint }}\"\n    state: present\nSince mariadb_keyserver_fingerprint changed even for Trusty users, this might get run again and add the Xenial specific key? I'm just not sure what consequences would happen from that.\n. I'd lean towards just using the official Ubuntu package now. Unless we have a good reason not to, it's usually a good thing to default to that.\nEven that page says:\n\nFor these you can use the distribution's management system to install MariaDB.\n. @RiFi2k are you still able to take care of this, or want us to finish it?. @RiFi2k don't worry about this PR. You can just create a new one if you need to and reference this one. Thanks \ud83d\udc4d . Changelog? Then \ud83d\ude80 \n\nLooks way better \ud83d\udc4d \n. Thanks. We should at least update to 1.1.0 which fixes this I think. 2.0.0 looks better but might require some changes on our end.\n. Do you want to do a PR to update to 1.1.0?\n. @ssteinerx you're in luck, we don't have any tests! \ud83d\ude2d \nAll our test suite does is run Ansible's syntax check to ensure we at least don't commit completely broken code.\nWe'd love to get a proper test suite going it's just hard with Ansible/this project unfortunately.\n. This is Trellis, not Laravel Homestead.\n. Tested and works. Thanks \ud83d\udc4d \nFixes #662\n. Thanks for reporting this. Looks like an upstream issue with the box: https://github.com/chef/bento/issues/677\nI'll probably lock to 2.2.9 in the meantime.\n. Probably not. It's usually a good practice to specify a version whenever possible (see: package managers).\nWant to do a PR for this?\n. \ud83d\ude80  awesome thanks\n. Yeah I agree that would be an improvement. We'd obviously be open to a PR which addressed this if you're interested.\n. There's nothing Trellis can do about this unfortunately. It's an issue with Homebrew (I guess?).\nSee http://stackoverflow.com/questions/38670295/brew-refusing-to-link-openssl and http://stackoverflow.com/questions/37690054/python-and-openssl-version-reference-issue-on-os-x for potential solutions.\n. Makes sense. $http_origin should just be empty on non-CORS requests so cache key is still good in that case too.\nThanks \ud83d\udc4d \n. This makes sense if there's some good defaults we can set automatically. We just have to be careful that they make sense for the average (or most) sites/servers.\n. Looks mostly good. There's some firewall/ufw things in there that might conflict with our existing stuff though.. 1. I honestly kind of forget why we don't automatically install WP in non-dev envs. Maybe it's something we should revisit again. It does cause some confusion as we've had people complain Trellis isn't working properly.\n2. We prefer to stick with our own best practice recommendations which is why we compile locally. So we wouldn't want to have that example file compile remotely and then separately recommend doing it locally (such as in roots-example-project). I don't really think it's that inconsistent as asset compilation is a much different context than running composer install for example.\n. Compiling remotely adds more complexity to the server. A lot more packages and dependencies need to be installed to make that happen. And that isn't trivial these days with complicated JS stacks (node, npm/yarn, bower, babel, gulp, etc).\nSo you end up with a lot more software on the server that isn't needed to actually run your WP site. It's just a part of the build/deploy process.\n. Thanks for reporting this. We could just update the log level in https://github.com/roots/trellis/blob/1040828ba54d37b9a4095867067cefe4b5507c6c/roles/fail2ban/defaults/main.yml#L2.\nWould like to do that?\n. This probably needs docs changes as well\n. https://github.com/roots/docs/tree/master/trellis\n. Everything looks good \ud83d\udc4d \n. Makes sense :shipit: \n. Great idea with the import alias \ud83d\udc4d \n. Annoying \ud83d\ude14  but changes look good :shipit: \n. pr accepted\n. Awesome \ud83d\udc4d \nChangelog + :shipit: \n. @jasonmarlin that solution is interesting. I'd welcome a PR but is this an actual issue? @retlehs couldn't reproduce it.\nYou had the same issue?. :shipit: . These changes seem pretty minor so I'd be open to adding this. Can the duplication in the provider tasks be minimized? Maybe just include a task file for provider install which would only have the first ~4 tasks to actually install it.. I'll test this out but otherwise it should be good to go \ud83d\udc4d . @dlundgren I'm sorry about this but I've changed my mind about including this in Trellis :( Mostly I don't want to incur the overhead of supporting both MariaDB and Percona. It might not be much, but it's obviously more than just MariaDB alone and increases the support/maintenance burden. This is also the first request of Percona we've had in ~2 years and anyone who needs it can easily add it themselves.\nI also hadn't thought about what would happen once we switched to the official Ubuntu distro packages for Maria in https://github.com/roots/trellis/pull/693. Now that the custom apt repo is gone, these two database options diverge just a little more.\nThanks for the good work on this and sorry for not deciding this sooner before I got you to do additional work.\n. Good find :shipit: . This might be one of the best Trellis PRs yet \ud83d\ude04. Removes a bunch of code and improves things!. \ud83d\udc4f . Thanks for the detailed issue.\nThis is actually from https://github.com/geerlingguy/ansible-role-mailhog which we don't control. You could try opening an issue over there.\nI did take a quick look and it uses the get_url module which has a default timeout of 10 seconds (ref: http://docs.ansible.com/ansible/get_url_module.html). So maybe an option could be added to customie that.. Good catch. Makes sense since we have the log_format defined \ud83d\udc4d . \ud83d\udc4f . \ud83d\udc40  thanks. Makes sense \ud83d\udc4d . Thanks! \ud83d\udc4d . > Latest Ansible versions give a clear warning about the host key change, but older Ansible versions do not (unless -vvvv is added), so some users may be confused why the ssh connection fails when it worked previously.\nWhy don't we just bump Ansible requirements along with this PR?. See https://github.com/roots/trellis/pull/744. @mitramejia sorry about this but we realized we lacked some details in the original issue. I added more details in https://github.com/roots/trellis/issues/522.\nThese checks will need to be done in the deploy role/playbook in order to properly check a WP site's branch. I'll close this PR for now, you can re-open if you want to re-use this one or just open another PR.. Oh and thanks for the work on this :) If you want to continue that's appreciated, if not let us know and we can take over the work.. Is this 4.7 only?. :shipit: . :shipit: . \ud83d\udc4d . :shipit: . Thanks for reporting this. I agree we should change it and looking back it wasn't a great idea :(\nI'll switch it and try to figure out a migration path or some instructions.. Doc updates with much more information on this: https://github.com/roots/docs/pull/66. Excellent debugging \ud83d\udc4d \nWe might want to look into creating more custom filters/modules to deal with complex things like these. I'd have a little more confidence in them being pure python vs a mix of Jinja filters + Python functions.. Let's just go with what you have now. The trellis_users solution doesn't clean things up nearly as much as I'd hope.\n\ud83d\udc4d . I don't really understand the problem here. I'm going to close this unless you have more information @BrandonMathis. Feel free to re-open with more details, or you can post on https://discourse.roots.io/ if it's something specific to your setup.. @tmdk @akovalyov sorry this was a really bad bug on my part :( would either of your be able to test this as well?. Thanks for confirming \ud83d\ude03 . \ud83d\udc4d . Does Capistrano even use the bare option?\nhttps://github.com/capistrano/capistrano/blob/3d9800d977294c173b207cb99dda550c05966daa/lib/capistrano/scm/git.rb#L38-L44. It uses --mirror which the Ansible module doesn't seem to support. There is a difference though.. I don't think bare is good enough:\n\nSet up a mirror of the source repository. This implies --bare. Compared to --bare,\n    --mirror not only maps local branches of the source to local branches of the target,\n    it maps all refs (including remote-tracking branches, notes etc.) and sets up a\n    refspec configuration such that all these refs are overwritten by a git remote\n    update in the target repository.\n\nWe'd have to switch to using command and implementing the raw Git command.. Closing since it's stale. Feel free to re-open/update.. This should too: https://github.com/roots/trellis/pull/630. fwiw https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/#virtualbox works just fine for me.\nI'd rather link to that since the URL matters a bit in this case.. Yeah it's not great in Firefox. But Chrome is way higher in usage and the URL is correct anyway.. Thanks \ud83d\udc4d . Tested this out and it works great.\n:shipit: . We can change/improve this after but wanted the fix in ASAP.. \ud83d\udc4d . This looks good to go. Needs changelog entry as well \ud83d\udc4d . \ud83d\ude80 . > I'm not sure how we would store the salts after generating them the first deploy, but may not need to anyway. Worst case, users of the site get logged out and must log back in after each deploy.\nLogging users out on every deploy is not an option.\nThis means that any solution to this has to be persistent. These salts need to be stored somewhere and right now the easiest solution is in the files in source control. Any solution also needs to work across computers to support multiple deployers.\nThe simplest alternative to this is Trellis somehow generating the salts automatically at the start of a project.\nSee https://github.com/roots/trellis/tree/generate-vault-files/roles/vault for example of some in progress work.\n. ```bash\n~/d/trellis \u276f\u276f\u276f ./bin/deploy.sh\nUsage: deploy  \n is the environment to deploy to (staging, production, etc)\n is the WordPress site to deploy (name defined in wordpress_sites)\nAvailable environments:\ndevelopment\nproduction\nstaging\nExamples:\n  deploy staging example.com\n  deploy production example.com\n~/d/trellis \u276f\u276f\u276f gco extra-deploy-params\nSwitched to branch 'extra-deploy-params'\nYour branch is up-to-date with 'origin/extra-deploy-params'.\n~/d/trellis \u276f\u276f\u276f ./bin/deploy.sh\nPLAY [Ensure necessary variables are defined] ******\nTASK [Ensure environment is defined] *******\nskipping: [localhost]\nPLAY RECAP ***********\nlocalhost                  : ok=0    changed=0    unreachable=0    failed=0\n```. There's two separate changes here.\n\nRename files that require modification to .example\nRemove the destination files from Git\n\nThese aren't tied together either so I'd rather consider them separately. Let's just talk about the first one for now.\nIf the main benefit to this is to make tracking upstream changes easier, I'm not sure it's worth it. Ideally those files are pretty stable and don't change much. wordpress_sites.yml hasn't changed in 7 months for example.. Switching to .example files might be an improvement, but I'm going to pass on this for now. We still have plans to make a Trellis CLI tool for easily generating a project. This is something that would fit better in there instead of the project in Git.. See https://github.com/roots/trellis/issues/749. Good stuff \ud83d\ude80 . changelog and :shipit: . Much better \ud83d\udc4d . Would this help? http://wp-cli.org/commands/db/query/. This seems like a useful addition but I'm wary of adding this for every hook. There is a cost in terms of performance for all these tasks and it matters more for deploys which should be fast as possible.. This will be covered by https://github.com/roots/trellis/pull/815 as a nice bonus. I'll leave this open. It does seem like we can handle it a little better regardless.. \ud83d\udc4d  thanks. Changelog entry too please \ud83d\udc4d . \ud83d\udc4d . Shouldn't this use a vault var?. Oops, correct. Was just going by your example code which I assumed was from wordpress_sites.yml and not from vault.yml.\nI'd just update that to expand the example.. This looks good but can we do it without the two \"helper\" vars. They aren't needed and we should try and avoid them unless it really helps.. \ud83d\udc4f . :shipit: . Awesome \ud83d\ude80 . Is this good to go (other than conflict)?. :shipit: . Thanks for contributing @samkarpluk :)\nI realized that we can't default to secure though. This only works if someone is using HTTPS which isn't guaranteed. HttpOnly we can definitely keep as a default like this though.. Yeah, agreed. Still useful to be there. Want to change it to Off? We can maybe try and figure out a smart way of setting it automatically later.. Thanks \ud83c\udf89 . Good troubleshooting. Seems simple enough so I think it's good to merge without fully understanding the root cause \ud83d\udc4d . Thanks for the detailed issue.\nUnfortunately this is a very weird thing to run into because it shouldn't happen :( I'm not even sure what to say in terms of debugging.\nMaybe delete your vendor dir and manually run again ansible-galaxy install --force -r requirements.yml -p vendor/roles again?\nOr maybe re-install Ansible? Could try another version like 2.2.0. @strarsis did you ever figure this out? I'm still not sure what Trellis itself could do about it.. I guess we could modify the restart task to act as a handler.\nRight now it's:\nyaml\n  - name: Restart MySQL Server\n    service:\n      name: mysql\n      state: restarted\n      enabled: true\n/cc @fullyint . I'm hesitant to support this edge case since it's a useful check for everyone else.\nTrellis doesn't even support \"local\" repos anyway out of the box. I'd be okay with adding a variable that you could set to skip that check. Feel free to do a PR for it if you want.. :shipit: . Maybe try with another theme and see if it happens? You'd at least know if it's Sage or Trellis related issue.\nEither way, this is more a support question for https://discourse.roots.io/. Maybe someone else has experienced this and can help.. This was probably due to the AWS S3 outage today. Either way, that's a problem downloading from github's site, not a Trellis issue. We can't control every external site.. \ud83d\udc4d . I confirmed this does happen. The behaviour is \"correct\" but maybe not ideal.\nWe could just add\nyaml\n- include: \"{{ playbook_dir }}/roles/common/tasks/reload_nginx.yml\"\nat the end of roles/wordpress-setup/tasks/main.yml\n@fullyint thoughts on that?. A test that verifies a connection to the main site might be good. Get's a little weirder if you have multiple sites maybe?. CSP is awesome but I'm not sure Trellis is the right place for it. It's more of an application level concern. So if you're running a WP site, you'd control these headers through a WP plugin for example.. > And with that example you cannot do with WordPress plugins as they do not allow some of those directives. These plugins are usually set with  tags in which IE doesn't support.\nAre you talking about existing plugins? When I said plugins, I even just meant a custom plugin someone writes to set specific CSP directives they want.\nI agree the existing plugins are kind of crappy.\nI'm not necessarily against this as a way to quickly set some CSP rules. I just think once you start getting into more complex ones they belong in the application because you'll need some logic around it (or state that exists in the app).\nFor example: in a typical WP site you'll have embeds in posts/pages, with CSP in the app you could add some meta field for a single post only to allow it (instead of site wide).. @corbinhesse thanks for the work on this but we're going to pass on it. When we're really on the fence about something, we tend to default to not adding it.\nThis can easily be done through Nginx includes which we like to encourage. This might be something we'd do if we really thought it would encourage people to set CSP directives, but I don't think that will happen. Especially because we wouldn't want to have the csp dict in the configs by default anyway so they'd be discoverable by some docs.\nSo, if you're interested, we could definitely add a section to our docs explaining a little about CSP and how to set directives.\nDocs repo: https://github.com/roots/docs/tree/docs/trellis. Oh and simple Nginx includes confs can't vary by environment like this feature can, but you could use child templates to accomplish it. It's definitely not as simple or nice though.. Seems useful since we'd like to encourage people to have better setups with load balancers (even though in this case it seems ELB is kind of broken).\nWhat was your solution for the PR?\n@fullyint came up with an idea to add an additional nginx_sites_available_templates variable which is an array that we'd just call with_items on to generate templates. By default it would contain no-default.conf.\nAnyone could re-define that variable and add on their own templates or remove that one.. That solution is good also, but agreed the general one is probably more useful.\nDo you want to do a PR for it?. @medfreeman thanks for this.\nI'm really wary of adding this much overhead. Cleaning up the templates is a nice feature, but I don't know if we want to keep up that pattern in multiple places.\nHere's the minimal feature I had in mind: https://github.com/roots/trellis/compare/nginx-sites-available-templates?expand=1\nnote: I'm perfectly fine having the conf template in the repo. It hasn't changed since 2013.\nWhat do you think?. We'd have to verify it's the same on Ubuntu 16.04 as well.. Thanks \ud83d\udc4d . Looks great \ud83d\udc4d \nThanks for the work and patience on this. Thanks \ud83d\ude80 . This has come up before. That deprecation notice also hasn't changed since 2014. We didn't switch to new one because of GPL license although it might be fine if we just use it through Galaxy.. \ud83d\udc4d . \ud83d\ude80 good improvement. \ud83d\udc4d . \ud83d\ude80 . The original concern was that we can't guarantee assets that are included on a page contain cache busting information.\nI guess if anyone uses the wp_enqueue methods, then they contain the version by default? Not entirely sure how trust worthy this is, or if we can assume people alway use those functions or some other method.. Should be noted that anyone can add this config by using Nginx include/child templates.. Nope. My original concern still stands and this can easily be done by anyone that needs it.. Seems useful but Trellis can't depend on a specific WP plugin.. Seem good iirc \ud83d\ude80 . One concern with this was installs with a large number of sites. Confused as to why this is needed.\nThe only place nginx_includes_d_cleanup is used is within wordpress-setup which is where the default is.\n. Have you tried this?\nIn Ansible. Variables in group_vars take precedence over ones in a role defaults. See http://docs.ansible.com/ansible/playbooks_variables.html#variable-precedence-where-should-i-put-a-variable. I just tried the same thing:\n```diff\ndiff --git a/group_vars/all/main.yml b/group_vars/all/main.yml\nindex bcc0f88..d9d1492 100644\n--- a/group_vars/all/main.yml\n+++ b/group_vars/all/main.yml\n@@ -18,3 +18,5 @@ raw_vars:\n   - vault_users..password\n   - vault_users..salt\n   - vault_wordpress_sites\n+\n+nginx_includes_d_cleanup: false\ndiff --git a/roles/wordpress-setup/tasks/nginx-includes.yml b/roles/wordpress-setup/tasks/nginx-includes.yml\nindex a9859b0..8fc61a3 100644\n--- a/roles/wordpress-setup/tasks/nginx-includes.yml\n+++ b/roles/wordpress-setup/tasks/nginx-includes.yml\n@@ -41,6 +41,9 @@\n   register: nginx_includes_existing\n   when: nginx_includes_d_cleanup\n+- debug:\n+    var: nginx_includes_d_cleanup\n+\n - name: Remove unmanaged files from includes.d\n   file:\n     path: \"{{ item }}\"\n```\nplain\nTASK [wordpress-setup : debug] *************************************************\nok: [default] => {\n    \"nginx_includes_d_cleanup\": false\n}\nWhat's your Ansible version?. Same here. Interesting that yours outputs True (note uppercase). Mine is true :thinking: \nNo clue if that has anything to do with that's going on.\nPython version?. Sorry but I'm not entirely sure what's causing this issue but this won't be merged since 1) we can't replicate it, and more importantly 2) it's not how Ansible it supposed to work.. I'd be fine with this. Feel free to do a PR \ud83d\udc4d \nThere's more files we'd probably want to block:\n\ncomposer.json\nlicense.txt. We could add a variable of an array of filepaths to block access to and we'd only provide the defaults of wp/ ones.. Awesome thanks \ud83d\udc4d . Seems useful \ud83d\udc4d . \ud83d\ude80 . \ud83d\ude80 . @medfreeman can you take a look at https://github.com/roots/trellis/pull/818 as well? Solves some (all?) of the same problem.\n\nThe method of using an Openssl config might be a much nicer option than the shell command.. I think Phil's reply solves this?\n```diff\ndeploy.yml\n\ndeploy_build_after: \"{{ playbook_dir }}/roles/deploy/hooks/build-after.yml\"\ndeploy_build_after: \"{{ playbook_dir }}/deploy-hooks/build-after.yml\"\n```\n\n```yaml\ndeploy-hooks/build-after.yml\n\nname: some task\n  command: stuff\n\noriginal tasks\n\n\ninclude: \"{{ playbook_dir }}/roles/deploy/hooks/build-after.yml\"\n\n\nname: some task\n  command: more stuff\n```. I'll re-open so we can make that adjustment. Looks great \ud83d\ude80 . Seems useful \ud83d\udc4d  Makes more sense now that Trellis supports arbitrary Nginx sites too.. \ud83d\ude80 . \ud83d\ude80 . Right now this creates a needless extra synced folder. It probably needs some changes which were done specifically for Windows.\n\n\nplain\n    default: /vagrant => /Users/scott/dev/trellis\n    default: /home/vagrant/trellis => /Users/scott/dev/trellis\n    default: /home/vagrant/trellis/bin => /Users/scott/dev/trellis/bin. See https://github.com/roots/trellis/pull/630.\nIt basically acts like a normal cache busting fingerprint in an asset file. Whenever you change info associated with a cert like your site hosts, the id changes so a new cert will be generated.. @fullyint is it possible to easily create a file with a static filename each time?\n@strarsis the whole point for the cert ID was to easily support regenerating a certificate when the underlying context changes (like a domain).\n. \ud83d\udc4d . @mAAdhaTTah sure, makes sense \ud83d\udc4d . @mAAdhaTTah added, try it out \ud83d\udc7c . I'm not sure about this. For one thing, roles depend on order. The ugly solution to that is people naming roles like 1-whatever which is not cool \ud83d\ude14 \nOne goal of Trellis is to still expose Ansible. I think it's important for people to understand the basic playbooks and this abstracts that away a little bit too.. This just isn't on our list of priorities right now but if you want to do the work and put up a PR, then it could potentially move it along. I can't guarantee it would get merged though as I haven't thought much about it lately.. See https://github.com/roots/trellis/pull/882. I guess we'd have to define our own template for this then instead of just including h5bp's.. Not exactly sure how that solution applies here. Does it let us continue to use the h5bp config unmodified? If so, yeah that sounds like a good change.. Cool \ud83d\udc4d PR would appreciated. Vagrant + NFS is so hard to performance tune so I'd welcome anyone testing various options with benchmarks. Otherwise I'm hesitant to change defaults.. Well that was easier than I thought :)\nRest of the changes look good too \ud83d\udc4d . \ud83d\ude80 . I refreshed my memory a little and it seemed like @discopatrick had an idea:\n\nadd a dynamic inventory script called hosts/development which looks for the generated inventory file and, if it exists, outputs an exact copy of that inventory - otherwise, outputs an empty inventory. Writing dynamic inventory scripts is documented here: http://docs.ansible.com/ansible/dev_guide/developing_inventory.html. This solution will allow the feature to work in Trellis \"out of the box\" while avoiding the above error, and I think will provide the best user experience.\n\nIs this an alternative to that? What are the pros/cons?. Makes sense \ud83d\udc4d . That line is telling people that any future manually-run commands need to be done on the VM. It was a common mistake that people would try and run them on their host.\nI'm fine with improving the wording, but I think some form of it should stay.. thanks \ud83d\udc4d . Edge case but I think it makes sense \ud83d\udc4d  Thanks. > The Trellis server has been provisioned for this site approximately 2 months ago\nAlso meaning the version of Trellis you were using was about that old?\nThis seems strange to me since certificate expiry is 90 days. If renewal failed, the existing one should remain.\nConsidering that its ~2 months old, the message about being younger than 60 days seems correct?. Closing without any way to reproduce. Feel free to re-open if it happens again.. Good catch, thanks \ud83d\ude80 . :shipit: . We mostly agree with you and our end goal is to have something as close to a single command process as we can.\nReminder: this is an open-source project that we work on in our spare time for free.. Makes sense \ud83d\udc4d . These defaults might be better defined in roles/php/defaults/main.yml. This template already uses php_display_errors which is from there.\n@fullyint do you have an opinion on this?. Thanks @TangRufus \ud83d\udc4d . Thanks \ud83d\ude80 . Didn't know about this. Thanks \ud83d\udc4d . Will Vagrant even prompt to update the box with this logic?\n2.2.9 satisfies <= 2.3.8. Tried it out and works great. Thanks \ud83d\udc4d \n. Think this makes sense.\nWe do include includes.d/{{ item.key }}/*.conf; elsewhere.. This isn't really possible right now unfortunately. We don't compile Nginx from source so we can't add compiled modules like these.\nThere's been some threads on our forum about various modules. Here's an example: https://discourse.roots.io/t/trellis-build-nginx-from-source-ngx-pagespeed-enjoy/6391\nThe more basic feature request would be: support compiling Nginx from source. Then anyone could specify other modules they want.. Nginx just got support for customizing the ppa and package name: https://github.com/roots/trellis/pull/858/files\nSo you can easily try this yourself now :). Trellis isn't directly tied to Sage so not sure we can do this by default. But we could make it part of this example file: https://github.com/roots/trellis/blob/master/deploy-hooks/build-before.yml\nWe'd actually only need Ansible itself for this.\nSomething like:\nyaml\n- name: Gzip Sage assets\n  archive:\n    path: \"{{ item }}\"\n    format: gz\n  with_fileglob:\n    - \"{{ project_local_path }}/web/app/themes/sage/dist/**/*\". How could we now which files to gzip for plugins?\n\nDo all CDNs even support brotli/static gzip?\nGzip, yes I hope so.\nBrotli, I doubt it.\n\nBut that doesn't really matter since hen you gzip these files you always leave the originals.. I'm not really convinced we can or should do this (especially by default). Have you timed how long this takes?\nMy main concerns:\n\nhow long this takes\nhow inefficient it is since we're gzipping every static file and not only changed files. We can't. My second concern was really only valid if this task was slow. But 2 seconds seems pretty acceptable.\n\nStill going to think about this a bit more.. @TangRufus just to confirm, this is including Sage theme right? So gzipping all its assets?. Two things:\n\nshould be noted that a stock Sage theme is fairly light on theme files right? Would be nice to test with a slightly more asset heavy example.\nI don't think we can set this at the top level server directive.\n\nThis will require .gz for every static file but we only gzip based on certain extensions. This would probably need to be within a location block which only matches on the same file extensions.. No, the default we recommend right now is build-before.. Ansible has a built-in callback plugin to profile/time all tasks now: https://github.com/ansible/ansible/blob/devel/lib/ansible/plugins/callback/profile_tasks.rst\nCould give that a try also. @TangRufus not sure if you still have work to do on this or not, but there's still one issue to address (from https://github.com/roots/trellis/pull/865#issuecomment-322351361):\nWe can't set this at the top level server directive. It's needs to be within a location block for those same file extensions that we're gzipping.\n. We should probably update them as long as there's no breaking changes.\nBut we might just need to move h5bp stuff into our configs in order to support features like that. It will give us more control over location blocks. Those configs are pretty stable at this point so I don't think it's too bad to just move them into Trellis. We haven't updated in a while either.\nMaybe that could be a separate PR to start with.\n. Either I'm confused or missing something... but I think our original concern about duplicating the h5bp location blocks is overblown? The only location level conf we include is cross-domain-fonts.conf (which I guess has caching since fonts rarely change).\nCan't we simply remove all the other cache headers for now? We can worry about expires functionality after as it doesn't currently exist anyway.. @fullyint just pointed out that it was added in https://github.com/roots/trellis/pull/876. This should not have been added and needs to be removed in the meantime anyway.. > developers might want to add Cache-Control for gzip files which this patch doesn't help\nSure, but it's the same situation as before right?\nBefore you had no cache-control headers AND no static gzipping. At least we've added one feature for the time being?. That sounds bad \ud83d\ude09 . We definitely need to improve and enable better asset caching, I just mean it should be taken care of separately. This is still a useful PR on its own.\nI think this PR is good to go but I'm going to try and release 1.0.0 before merging new things (except maybe Ansible 2.4).. Still undecided on this one. But I'm on vacation so not really thinking about this \ud83d\ude09 . I was actually thinking more about this last night and I'm probably fine with it :)\nI'll re-open and review it soon. I wish this didn't require all the dynamic module support since Brotli is a nice improvement. So since it depends on the other, still thinking about it.. Not yet sorry. Have other priorities in Trellis to finish first.. Seems fairly simple and it's a generic Nginx setting.\nMy only concern is the downloading with force being set.\nAnsible docs say\n\nGenerally should be yes only for small local files. \n\nNot exactly sure what the alternative is though or how much it matters. Obviously Trellis \"downloads\" many things during a provision but this won't be idempotent.. No, I'm undecided on this one. I don't know if Trellis should have a Cloudflare specific option like this built-in.. Good question, I think it would use Child templates.\nRight now there's an https block. The new template would use that block and call {{ super() }} then just add the new certificate stuff after that.. @TangRufus thanks, took a quick look at that and it looks great.\nThis is one of the first 3rd party roles like this so it was interesting to see how the implementation went. Most of it looks fairly straightforward. Other than the playbook hack \ud83d\ude14 .\nSomething like https://github.com/roots/trellis/issues/830 might be able to help that.. Yeah I did notice that and thought it wasn't ideal either but honestly I'm not so sure how much it matters.\nIn any language with packages, it would be equivalent to include vendor/roles/TypistTech.trellis-cloudflare-origin-ca/templates/wordpress-site.conf.child which most languages would allow include TypistTech.trellis-cloudflare-origin-ca/templates/wordpress-site.conf.child. It's still coming from the same place /shrug. Good question. I'm just not sure we can reasonably expect a solution for that. . Up to you ultimately. Usually I wouldn't like regexp for things like this, but at least the template output is predictable since it's not a manually created file.. Thanks \ud83d\ude80 . Looks good, thanks \ud83c\udf89 . Just to confirm, you're saying Trellis should have a location block which matches versioned assets from WP sites?\nThis has come up here as well: https://github.com/roots/trellis/issues/800\nHowever I never really thought of only matching on a pattern like ?ver=x.x.x which I think should eliminate that concern.. > Question: How we can add Cache-Control: Immutable to assets that actually versioned?\nIt would have to be user supplied? They could provide an Nginx location formatted variable.. Rest looks good, thanks \ud83d\udc4d . Good eyes, thanks. Set php_extensions_custom in a group vars file (maybe group_vars/all/main.yml:\nyaml\nphp_extensions_custom:\n - php7.1-soap\nThen run vagrant provision.. Makes sense \ud83d\udc4d . > Question: When does a apt tasks need force: yes?\nbest I could find on it: https://forums.solydxk.com/viewtopic.php?t=6148. Still not exactly sure when we have to use it though.. Looks good overall. My only question is if we should keep the memcached and SSH related packages as a list? Maybe we should just split them out into individual tasks. It's only two packages each. Not sure we need to have them with the treatment of default + custom.. Interesting benefit with this is we get granular statuses per package.\nBefore:\nplain\nTASK [common : Checking essentials] ********************************************\nchanged: [default] => (item=[u'python-software-properties', u'python-pycurl', u'build-essential', u'python-mysqldb', u'curl', u'git-core', u'dbus', u'libnss-myhostname'])\nAfter:\nplain\nTASK [common : Checking essentials] ********************************************\nchanged: [default] => (item=python-software-properties)\nchanged: [default] => (item=build-essential)\nchanged: [default] => (item=python-mysqldb)\nchanged: [default] => (item=libnss-myhostname)\nok: [default] => (item=dbus)\nchanged: [default] => (item=git-core)\nok: [default] => (item=python-pycurl)\nok: [default] => (item=curl). Closing this after @fullyint's response which does a great job of explaining our stance.\n@nbyloff thanks for taking the time to do this and creating some discussion. Should always be noted that when we decline a PR like this, it's not because its \"wrong\". It's just not the solution we want at this time.\nI think we all agree we can provide some better guidance on how to do this \ud83d\udc4d . > Of course there is the roots discourse thread from December, but it has issues in different ways, either overwrites local changes or creates merge conflicts for every single change\nIf you make changes to Trellis as @TangRufus outlined, merge conflicts and overwritten local changes shouldn't happen too much.\nOne thing which I don't know has been mentioned on on Discourse is specifying merge strategies for specific sub paths.\nSo if you know that roles/ is free of local changes, you can run git merge -X theirs subtree=trellis/roles --squash trellis/master (or something like that).\n-X theirs means git will automatically pick every change from trellis/master without prompting for conflicts. ours does the reverse which can be useful for certain files/dirs.. We definitely need some guides/docs about:\n\nhow to properly customize/change Trellis\nhow to update Trellis. Correct, updated it. We can't really do that automatically. Just because you enable fast-cgi caching doesn't mean you have a proper setup with asset digests.. Thanks! This is a good improvement.. why not \ud83d\udc4d . We may even want to make dhcp the default. Seems simpler?. I think just vagrant reload works?. I like the sound of all of this \ud83d\udc4d  seems like a nice improvement with the separate roles\n\nBut I reserve the right to see it first \ud83d\ude1b . See https://github.com/roots/trellis/pull/37 for older discussion on this.. There's also two built-in Ansible modules which we could look into:\n\nhttp://docs.ansible.com/ansible/latest/openssl_certificate_module.html\nhttp://docs.ansible.com/ansible/latest/letsencrypt_module.html. If openssl_certificate actually helps/is simpler then we have no problem requiring 2.4 asap.\n\nOur current LE implementation is a little convoluted so I'm open to any solution which simplifies it. Although I do think we have some more unique requirements with it.. @TangRufus can this get a rebase?. Tested and working great \ud83d\udc4d \nOnly thing I ran into due to our current tags is if you want to enable SSL after, and only use a wordpress or wordpress-setup tag, Nginx will fail because dhparams weren't initially generated.\nSo if we want a common tag which would run all Nginx related tasks/roles, we might want to introduce a new one, or just apply wordpress-setup to nginx as well?. If someone has a VM running and merges this in, do we know what the behaviour is?. Okay thats about what I expected and I think it's fine \ud83d\udc4d \nOf course they can always keep the static IP instead.. @TangRufus did you mean to close this?. Want to add a changelog entry? Will merge after that.. Closed by https://github.com/roots/trellis/pull/913. Never heard of this setting before \ud83e\udd14 \nVB docs specially say:\n\nOn any host, you should enable the I/O APIC for virtual machines that you intend to use in 64-bit mode. This is especially true for 64-bit Windows VMs. See Section 3.3.2, \u201c\"Advanced\" tab\u201d. In addition, for 64-bit Windows guests, you should make sure that the VM uses the Intel networking device, since there is no 64-bit driver support for the AMD PCNet card; see Section 6.1, \u201cVirtual networking hardware\u201d.\n\nConsidering we only support Ubuntu 64bit guests... seems like a good default. Would be nice for a few other people to test this as well.. Gave this a quick test and everything seemed fine. Would still like some other people to test. Especially on Windows. @kalenjohnson @QWp6t hint hint. Thanks for this PR. Replacing it with https://github.com/roots/trellis/pull/913 which adds a few more config options too.. I just tried this again. The one additional step I did which I didn't before when testing was to delete the local .vagrant.\nTried twice and both times got stuck at Installing NFS client....\nI'm going to revert that PR for now.. Should note I'm using Vagrant 1.9.7. It's no big deal \ud83d\ude04 . I'm the one who merged them and supposedly tested too.\nI don't mind leaving dhcp support in there... but I guess if it's that broken it might be better to remove it. Let's wait a bit on it for now.\nI posted here too looking for input: https://github.com/geerlingguy/drupal-vm/pull/1559#issuecomment-334329486. re: #439, we did enable ansible-local by default \ud83d\ude04 \nI'm fine with adding this option regardless. Is there no better solution for APFS yet?. > Is that true for non-windows users?\nYep \ud83d\udc4d . Yeah, sorry I just meant it's the default for everyone. If someone follows our docs as of now, they'd get ansible local.. Is this PR useful as is?\nOr does it depend on:\n\nShould we implicitly set ansible_local when vagrant_prefer_nfs: false(like what we are doing for windows users)?. Thanks!. Makes sense :). Makes sense to default to this higher priority \ud83d\udc4d . \ud83d\ude80 . How come the version format changed \ud83e\udd14 . Thanks!. \ud83d\udc4d . Closed by https://github.com/roots/trellis/pull/921. Diff looks minimal which is good: https://github.com/diafygi/acme-tiny/compare/5a7b4e79bc9bd5b51739c0d8aaf644f62cc440e6...4ed13950c0a9cf61f1ca81ff1874cde1cf48ab32\n\nThanks \ud83d\udc4d . You need to reprovision. You can just run the letsencrypt tags to make it faster.. Small suggestion, but yeah I think we should update to 10.2 \ud83d\udc4d . Thanks!. Do we know why he recommends it?\nI'm not sure it matters in our case since we're on Ubuntu 16.04 and using the official Nginx PPA for the \"development\" version.. Yeah as far as I know that PPA was only needed in 14.04. We had looked at it before going to 16.04.. Are you currently running Trellis in production? Can you provide us with some specs you've been successfully using?\nOne reason this was never really spelled out is because we assume pretty low specs. $5-10 Digital Ocean server for example. But we can add that somewhere. It would also belongs in our docs as well.. > however if people are having scaling issues maybe we can have some general \"run these commands to find your bottleneck\" and then also what values to start adjusting.\nThis is very different from assumed server specs though. I'd welcome any contribution to our docs/README with a small note about baseline server specs.. I'll have to take your word for it :)\nThanks. Thanks!. Thanks!. >= makes it easier for people to keep their box up to date and should be fine, but I guess there's a small chance some update could break Trellis. I would assume the likelyhood of that happening would be very low though?. Going to merge this as is for now and we can see about flipping it after.. I agree \ud83d\udc4f . I'd rather avoid pip and other dependencies. Did the punycode-escaping work for you? I know you had another error in your discourse thread but not sure if that was unrelated or not.. I'd prefer to fix by encoding it properly if we can (something like I suggested in the thread), otherwise punycode-escaping seems correct since technically it's not a valid URI as is anyway.. I'll leave this open as we might be able to solve it, but manually using a punycode-escaped host name in the configs also works for now.. [Errno 2] No such file or directory is a really strange error to have during apt-get update \ud83e\udd14 \nYour other Trellis box had the same error? Or another one?. I'll close it since a remote Trellis server would never be on a Mac anyway.\nThanks for the details and glad it's working!. Probably, but it needs to be done properly which is hard. We talked about this internally a bit, and Ansible 2.5 should help us do this in a cleaner way.\nOff the top of my head, the optimal solution would probably look like:\n\nrenamed wordpress_sites to apps (as done in this PR)\nadd a type to an app\nconditionally load tasks/roles based on the type (we can't do this until 2.5). Just a heads up but the main feature needed is only available in Ansible 2.7.\n\nWe can likely become 2.7 compatibility without too much difficulty, but it needs testing most of all.. https://github.com/ansible/ansible/pull/41330\n\nP.S. I've added redis support for a project, would you accept a PR for that?\n\nProbably, but it would have to be optional.. > Let me know what testing can be done by Trellis fans like myself. I am up for it.\nAt a minimum people can install Ansible 2.7.x and test Trellis in development and ideally on a (test) production server and see if you run into any errors. And try to fix them if so \ud83d\ude04 . We ran into one issue with 2.7 but it's been fixed and we bumped the version test max in https://github.com/roots/trellis/pull/1045. \ud83d\udc4f . Oh I meant to do that. Added.\nAlso added changelog entry. This is technically a breaking change although I doubt anyone is actually using the UDP feature.. \ud83e\udd14  interesting.\nThis makes sense I think. FromLineOverride=Yes allows WordPress to easily set the From header which we'd want. But as you said, anything else on the server that sends email without explicitly setting the From will get a default like \"Fail2Ban <fail2ban>\" which isn't valid.\nI'm wondering if there's a better default though. What if we left  FromLineOverride=Yes and set these default aliases?. Thanks @valentinocossar . Thanks but we took care of this manually. See https://github.com/roots/trellis#gold-sponsors. Just the commits in this PR? Don't need to do anything other than merge.. Do you have a reference to the upstream issues?. Working for me too! Even deleted .vagrant to test like last time.\nmacOS 10.10.5\nansible 2.4.0.0\nVagrant 2.0.2\nvagrant-bindfs (1.1.0)\nvagrant-hostmanager (1.8.7). Thanks @oxyc. 2nd point doesn't seem like a big deal since I assume it would be rare. But the 1st point is more important since anyone with an existing VM who updates this code would get the DHCP default breaking their current VMs.\nWonder if there's a way to skip it for existing VMs.. Still on the fence about this.\nHere's a nice summary of potential issues: https://github.com/geerlingguy/drupal-vm/pull/1559#issuecomment-387200433. Sounds like a good idea.\nFor reference: http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache_background_update\nIs this something you could implement?. Closed by https://github.com/roots/trellis/pull/962. I wonder if there's any reason not to make this the default?. The better question is the opposite to me.\nRight now the cache is time based. Say it's 60s, and a client hits the site 60.1s after it was last cached. This would result in a cache miss and that client would incur the cost of a full request hitting WP.\nWith background updates, and the same scenario above, that client would still result in a cache hit, but the cache would be updated in the background. This means no actual client would ever incur a cache miss. They'd either get stale cached data, or the next cache hit. This is obviously preferable as long as it works as we'd expect. Meaning if we trust Nginx to properly update the cache in the background within a reasonable time frame, it's a better user experience with barely any more cache time added.\nHere's a good article on this: https://siipo.la/blog/never-miss-the-cache-with-nginx-microcaching. We already set those.\nTime is just a default, anyone can change it. Maybe we should only specific 200 though or make it a variable. I'm not really sure.. >  like I said in my initial suggestion - this isn't a perfect solution for all applications. \n@inthedeepend I'm still curious why you think this is the case. Is there a downside/con I'm missing?. Thanks everyone \u2764\ufe0f . We already have fastcgi_cache_use_stale updating error timeout invalid_header http_500; in the base Nginx conf.\nfastcgi_cache_use_stale updating should take care of background updates I assume?. This works I assume? \ud83d\ude04 I kind of assumed it might not and only files within a site name subdir would be copied over but looking at the code this might work.\nWhat about just putting these in the root include.d dir? And not all?. I'm fine either way. @fullyint does this make sense to you?. @partounian would you like to add a note to our docs about this?. I'm a little rusty on LE stuff, but I'm pretty sure this is exactly what Trellis is already doing.\n\nIf you\u2019re running a local webserver for which you have the ability to modify the content being served, and you\u2019d prefer not to stop the webserver during the certificate issuance process, you can use the webroot plugin to obtain a certificate by including certonly and --webroot on the command line.\nThe webroot plugin works by creating a temporary file for each of your requested domains in ${webroot-path}/.well-known/acme-challenge. Then the Let\u2019s Encrypt validation server makes HTTP requests to validate that the DNS for each requested domain resolves to the server running certbot. \n\nConfirmed, this is what Trellis does :)\nedit: we don't use certbot, but the process is the same.. I really can't speak to Cloudflare itself. All I know is that's the challenge method we use with LE and the general process. If you find out more specifics feel free to re-open the issue.. \ud83d\ude31 good find. Did this actually cause a bug or break something? I actually wonder if --subdomains=false works despite their docs.\nEither way, it's more accurate \ud83d\udc4d . I'm assuming CodeCommit doesn't work if you append the .git extension?. no_log can be ignored if you use the ANSIBLE_DEBUG=true env var.\nBut maybe removing no_log isn't so bad either. I'd have to see what the normal output was we were trying to suppress. You can try that out if you want.\nYour other idea is good as well though. That would go before the clone project files I assume? I'd be open to either change.. I'm wondering if this check is even useful at this point. There's later connection test to make sure we can connect to the Git repo.. Where is arg_customize_changeset_uuid from? Does that come from the customizer?\nThis looks good, but I think we should just move this out of the h5bp directory now and make it ours. If we customize these templates, they belong to us :). Makes sense to me \ud83d\udc4d . TIL, thanks \ud83c\udf89 . Agreed! Thanks. I'm not sure there's a good seamless upgrade path here. In the past I think we just merged changes like this and people worked around it? The validation definitely makes it harder to deal with though.\nIf someone is running 16.04 on a server and they pull the latest Trellis updates, they can't really use Trellis at all without modifications or upgrading to 18.04.\n@fullyint any thoughts?. Turns out that Python 3 is the default on 18.04 which causes problems with Trellis/Ansible right now. Default Trellis behaviour is to let Vagrant install Ansible on the VM (this also applies to Windows usage).\n\nwe have validation that prevents Trellis from running on python3.\nthings may actually be broken until Ansible 2.5+ is required.. Python 3 support is being worked on in https://github.com/roots/trellis/pull/1031. Done some updates to this. It should now work with either 16.04 (Xenial) or 18.04 (Bionic) and either Python 2 or 3 so it's quite flexible.\n\nThere's only two issues for people wanting to continue with 16.04:\n\nthey'll need to update the Vagrant config to switch back to the 16.04 box\nthey'll see a warning (but not error) that Trellis is built for 18.04 now. @partounian wouldn't this mostly just be running apt-get upgrade? This seems like something that should be run manually because it may need user intervention, or at least for the user to read the output before continuing. Usually for apt installs Trellis just silently agrees and continues on but this could be a dangerous operation.. Ah thanks. But still I'd worry about trying to run all those tasks unattended.. Just to confirm, you have this commit right: https://github.com/roots/trellis/commit/54a108e2a5d9a9e0cf2c9c7c13e136b256622460. \ud83d\udc4f . I think this makes and looks good.. Thanks \ud83d\udc4f . I'm reverting this for now until it's fixed.. @nathanielks have you run into this?. I think disabling by default is probably better since I assume most people don't use it?. Were you able to verify the behaviour? Or should we try and do that first?. Perfect, thank you \ud83d\udc4d . Closed by https://github.com/roots/trellis/pull/1001. Looks good, thanks \ud83d\udc4d . Can you give some background on this? I'm not exactly sure what it is or why it's needed.. Looks good, thanks!. \ud83d\udc4d . Thanks!. Just tried this and got:\n\n```plain\nTASK [wp-cli : Verify WP-CLI Phar Signature] *****\nSystem info:\n  Ansible 2.5.3; Vagrant 2.0.2; Darwin\n  Trellis version (per changelog): \"Update wp-cli to 2.0.0 and verify its PGP signature\"\n\nnon-zero return code\ngpg: Signature made Wed 08 Aug 2018 09:13:40 PM UTC using RSA key ID 26F0BC06\ngpg: failed to create temporary file\n'/root/.gnupg/.#lk0x000055e90fd40b50.example.8737': No such file or directory\ngpg: Fatal: can't create lock for '/root/.gnupg/trustdb.gpg'\nfatal: [default]: FAILED! => {\"changed\": false, \"cmd\": [\"gpg2\", \"--no-default-keyring\", \"--keyring\", \"/tmp/wp-cli.pgp.gpg\", \"--verify\", \"/tmp/wp-cli-2.0.0.phar.asc\", \"/tmp/wp-cli-2.0.0.phar\"], \"delta\": \"0:00:00.036512\", \"end\": \"2018-08-12 17:13:25.450247\", \"rc\": 2, \"start\": \"2018-08-12 17:13:25.413735\", \"stderr_lines\": [\"gpg: Signature made Wed 08 Aug 2018 09:13:40 PM UTC using RSA key ID 26F0BC06\", \"gpg: failed to create temporary file '/root/.gnupg/.#lk0x000055e90fd40b50.example.8737': No such file or directory\", \"gpg: Fatal: can't create lock for '/root/.gnupg/trustdb.gpg'\"], \"stdout\": \"\", \"stdout_lines\": []}\n```. I'm assuming this is \"breaking\" since it's a new major version for WP-CLI?. Makes sense. Thanks it's working for me too \ud83d\udc4d . There's already a PR in progress for this https://github.com/roots/trellis/pull/992. Thanks \ud83d\udc4d . Sorry for the last response, but I did look into this before and I don't have anything useful to report \ud83d\ude1e. This seems like your VM (and apt) got into a bad state for whatever reason and it's hard for Trellis/Ansible to deal with all those possible states.\nIf you ended up figuring this out or working around it somehow, please let us know.. Thanks for the great bug report! tmp_multisite_constants.php is a weird hack so I'm not surprised that the Bedrock configuration change didn't consider it (or remember it existed). The new config model should definitely stay since it's Trellis that's doing something weird anyway. \n766 explains why this is needed. More background in https://github.com/roots/trellis/pull/754 and https://github.com/roots/trellis/issues/554.\nBut I'm still not sure the best solution here.. I tend to agree. I think WP-CLI is just running into a WP bug as well since it's an issue loading WordPress itself, but its their command so ideally it's dealt with there.. @arusa thanks for posting your workaround. That's all it took it fix it? It was a one-step process?. This sounds like a good improvement. Want to do a PR for it?. I don't remember any great reason. Could just be an oversight so it's worth trying out.. Oh I remember now. In the past the copy module was for local -> remote. So often we'd use cp via command to just do a copy all on the remote machine.\ncopy only got the remote_src option in 2.0 and synchronize needs delegate_to: \"{{ inventory_hostname }}\" or something.\nThat warning about copy not scaling is because it assumes we're dealing with local -> remote (so copying over the network).\nSo basically, I'm in favour of using whatever makes it the easiest \ud83d\ude04 . I don't know about your specific use case, but I'm fine to add this variable as an option \ud83d\udc4d . Thank you!. Thanks, yeah I didn't see this explicitly mentioned so it's useful. . > Since deploy-hooks/build-before.yml is useless when you don't use sage and support for Laravel projects is planned #951, would it make sense if we extract build-before.yml into a separate ansible galaxy role?\nMight a good idea.\nAs is right now, I don't like having sage_themes leaked into wordpress_sites.yml by default (even if it's just a comment).\nI'm not sure how generic we can make this. Composer + Yarn install are common/generic. yarn build:production is more Sage specific, and then especially copying the dist folder.. Sounds like a good plan \ud83d\udc4d \nOnly question is if it makes sense for the wp sites property sage_themes or whatever to be more generic? Maybe just theme_builder or something like that?. Yeah that makes sense. Go for it \ud83d\udc4d . Yeah I think we should remove all mentions of it, except for maybe an updated default deploy-hooks/build-before.yml?\nMaybe deploy-hooks/build-before.yml could include a more generic simplified example with a npm install &&npm build` type thing. It could also mention the sage compiler and link to docs?\nEither way, we'd need to update our docs to include a page on Trellis + Sage I think. This would deserve more than an entry in the user contributed extensions page.\n@retlehs what do you think?. @retlehs had some thoughts before on this. Can you explain them?. Process now:\n* uncomment the example deploy hook\nProcess after:\n add new galaxy role (+ install)\n define deploy_build_before\n* update wordpress_sites\nIs that correct? Obviously it's more work, but it's done in a more extensible way.. Oh thanks, either I never knew about or forgot \ud83d\ude33 \nLooks like those changes are basically split 50/50 between Python on local and remote. This PR is definitely only for Python 3 on local machine.\nMost of the changes are similar in concept, but my branch didn't seem to need a lot of them? Keep in mind I didn't test deploys yet.. Going to merge this as is. We'll finish Ubuntu 18.04 separately this is useful on its own.\n@fullyint feel free to post any other notes you may have.. Interesting, thanks. Hadn't heard of this before.\n\nMaybe we could even look into their implementations and port them over.\n\nLooks like there's two parts to this:\n\nOpenLiteSpeed web server itself\nLSCache WP plugin\n\nThe plugin seems to have a ton of features and roughly equivalent with other popular caching plugins which Trellis doesn't use by default anyway. But it also has features which only work OpenLiteSpeed itself, so I'm not sure there's anything we can really borrow from it.. \ud83d\ude33 I've been testing Python 3 in combination with Ubuntu 18.04 so I missed this. Basically that change also needs some changes from https://github.com/roots/trellis/pull/992/files (specifically the first two file changes).. Yeah that's completely fine. I just meant I missed that those changes are needed for Python 2/3 support independently of the 18.04 work.. I'm fixing this in #1036 by removing the part in server.yml where we change the Python interpreter.. The main issue here is that Python 3 is actually installed on a Trellis Ubuntu 16.04 build. It's a dependency of some other package. So that interpreter change was only meant to take effect on 18.04, but it would also set the interpreter on 16.04 and then we'd have missing packages as you ran into.. Generally we just need to make sure that WordPress itself can support a new PHP version.\nFound this: https://make.wordpress.org/core/2018/10/15/wordpress-and-php-7-3/\nLooks like 5.0 should be compatible, but there's also one or two small issues assigned for 5.0.1. @designst that would fix it, but there's still an underlying problem/bug. software-properties-common just happens to exist on both Ubuntu versions.. Closing since https://github.com/roots/trellis/pull/1039 is the fix.. Should this be done via Ansible? \ud83e\udd14 . Oh I did mean to mention that. And it's the reason why I didn't merge this because it's a trade off.\nMaybe my experience with the default is so much more annoying because I constantly create/destroy VMs for testing whereas most users wouldn't do it as often?. >  it's normal/expected to run $ anisble-galaxy manually\nThat would match up with every package manager as well. If you're using npm, composer, etc, everyone is used to having to run them manually to pull in latest versions.. @connerbw fair points. To be honest, I forgot about the vagrant_skip_galaxy option \ud83d\ude33.\nI think overriding that in vagrant.local.yml is probably the better option here. Think I'll revert this.. The difference in output is due to a different colour used by success or changed status. We have changed_when: false on the task but maybe that isn't making it return \"success\" anymore.\nSo in 2.6 or 2.7, the task now reports as changed which changes the colour output.\nWe should ideally try and find a less brittle way of determining if root can connect if possible although I know @fullyint did a lot of work on this so maybe there isn't really.. Much better, thanks \ud83d\udc4f . Seems useful, thanks \ud83d\udc4d . Looks like this was causing an issue: https://discourse.roots.io/t/trouble-getting-trellis-setup/14375/3. Fixed in https://github.com/roots/trellis/pull/1051. \ud83e\udd14 trying out moving the client portion out of here so the role can be conditional. It makes it simpler to install mysql-client vs mariadb-client since that can be done without using the MariaDB PPA.\nmariadb-client ends up installing mysql-common as well anyway. And their official site says:\n\nThe mysql-client package (up to MySQL 5.7) also works with MariaDB server.\nAll client APIs, protocols and structs are identical.\n\nSo I'm not sure there's any downside to this?. Judging from the error the issue was with a non-compatible plugin with 7.3.\nTrellis defaults to 7.3, but it's up to you to ensure your WP version and plugins are compatible. What you did is likely the only solution in your situation for now \ud83d\udc4d . Sorry we missed this... not very good on my part \ud83d\ude14 \nThis all looks good although it does assume the python3 binary which may not exist on Ubuntu 16.04 installs. It would be nice to figure out a dynamic way of referring to the version. I'm looking into this now.. Thank you \ud83c\udf89 . @ouun looking at this again (and testing it), I ran into an error. Is this currently working for you?\npython\nbundled_file.write(b''.join(b[cert, intermediate_cert]))\nNameError: name 'b' is not defined\nThis makes sense since b only works for a string literal, not with an array. Got a new PR up: https://github.com/roots/trellis/pull/1059\n. @ouun no problem at all. It's our fault anyway so thanks for reporting these bugs.\nThis looks to be the same issue as in https://discourse.roots.io/t/successful-remote-provision-and-deploy-all-i-see-is-nginx-welcome-screen/14536/\nI think it's best if we move discussion there.. \ud83e\udd14 oh I think these tasks need remote_user: \"{{ web_user }}\" set.. Okay thanks, I'll have to properly test this later.. Closing since https://github.com/roots/trellis/pull/1061 was the real solution.. More background on this here: https://discourse.roots.io/t/task-letsencrypt-generate-the-certificates-usr-bin-env-python-no-such-file-or-directory/14493/8\ntl;dr we're going to ensure that python2 is an explicit dependency for now. Thanks for this. I agree and I think this makes the most sense at first thought.. > but it is still making the virtualbox:\nCan you on confirm what you did after changing that config value? Did you destroy + up again? Or reload?. The default comes from here: https://github.com/roots/trellis/blob/bd05a61d4c00e99db9332b431ead1cec248a7889/vagrant.default.yml#L4 and it's 1GB so I'm not sure where 4GB would be coming from.\nedit: do you have a vagrant.local.yml config file to override values?. Ah so looking at your output, it appears you're using a plugin called vagrant-faster and the setting is coming from there: https://github.com/rdsubhas/vagrant-faster.\nSo this isn't a Trellis issue.. @geekodour we have a variable which allows you to change it, but it's not done automatically. If you want to look into that it would be appreciated \ud83d\udc4d . > Up to 2x faster\n\"Up to\" being the key words here \ud83d\ude04 \nAnyway, MariaDB is mostly used because it's full open source and not owned by Oracle. Performance characteristics should be roughly equivalent I'd think for most WP sites.. I did. The first two graphs look very similar to me? Only the 3rd shows any difference but they're synthetic benchmarks anyway. I personally wouldn't put too much faith into them unless there was WP specific ones.. Just to confirm, mainline is the same as development right?. Thank you!. I would drop double quotes as well. https://roots.io/salts.html uses Ascii 33-1126 and drops ', \", \\\nBut we're a bit limited in what we can do I think. We do take advantage of Ansible \"raw\" feature.\n. https://github.com/roots/trellis/pull/1071 may help with this?. I didn't even know about vm.provider.driver.read_guest_ip. That does seem better...\nAlthough Trellis does technically support parallels and vmware. I searched Vagrant and read_guest_ip only appears in VB and HyperV. Not sure how much this matters though?. > However, It's been a loooong time since I used Trellis, I may not be aware of all the subtleties of the code and uses-case\nTo be honest I don't know too much about this specific functionality either. This looks good to me and seems much better with a cleaner implementation.\nMaybe @fullyint can chime in if he's around. If not, I'll merge this in a bit. Thanks for your testing attempts \ud83d\ude04 . @phox4ever thanks for the report, would you like to contribute this fix?. Since this isn't used I'm not sure we should include it by default yet.\nThis should ideally be identical to https://github.com/roots/bedrock-ansible/blob/master/roles/wordpress-sites/handlers/main.yml if we kept it in. Annoying that Ansible can't call handlers from another role.\n. I'm thinking it's better to just include nginx.conf as a template in this role and let people customize it with proper vars rather than using the more brittle replace.\n. I personally get rid of www but I don't think we should do this by default. It's more personal preference.\n. My thoughts as well :+1: \n. Double quotes. Remember that you're the one who convinced me to switch :)\n. Here as well\n. Just nitpicky stuff but can we get rid of the extra line breaks in here? Also wouldn't bother trying to have the proper spacing on *:80. Just do listen *:80.\n. This handle should be the same as https://github.com/roots/bedrock-ansible/blob/b859a967a0c08ce5eb3b2b899e35a189dc4bf197/roles/wordpress-sites/handlers/main.yml\nGenerally reload is preferred over restart for Nginx.\n\nReloading nginx is safer than restarting because before old process will be terminated, new configuration file is parsed and whole process is aborted if there are any problems with it.\n. Ansible has apt_key and apt_repository modules. We use them here: https://github.com/roots/bedrock-ansible/blob/master/roles/mariadb/tasks/main.yml\n\nThese two first tasks should be able to use those I assume.\n. I changed over recently to always wrapping args with variable in double quotes: pkg=\"{{ item }}\"\n. No quotes needed around the actual hhvm value here.\n. Shouldn't save_handler be memcached? (missing the d). http://php.net/manual/en/memcached.sessions.php\nI'd also prefer this variable name to be memcached_sessions for consistency.\n. Name? memcached_sessions\nBelow as well.\n. Needs to be 2 space indentation here. Other conf below is 2 and our others are as well.\n. Can we be consistent with formatting? Either no spaces around = or 1 before and after.\n. Should we prefix these variables with php? Seems to be more explicit and matches up with the above.\nPlus I realized that HHVM doesn't support this opcache stuff so it makes it easier to recognize that.\n. Can :virtualbox remain as a symbol?\n. Single quotes please :)\n. ruby\nbedrock_path_server = File.join('/srv/www', File.basename('../example.dev'), 'current')\nAnd can you add a blank line after this as well?\n. :+1: \n. Can you remove this? It's already implemented.\n. Yeah I can make that a method as well\n. Done\n. :+1: \n. Don't worry, you did. I copied it the plain text.\n. backtick DOMAIN_CURRENT_SITE\n. set php here\n. remove spaces before/after parens\n. This should still be false by default right? Not sure we want it true.\n. How about:\n``` ruby\nPRIVATE_IP = '192.168.50.5'\n...\nconfig.vm.network :private_network, ip: PRIVATE_IP\n...\nif Vagrant.has_plugin? 'landrush'\n  config.landrush.enabled = true\n  config.landrush.tld = config.vm.hostname\nhost_aliases = other_sites.flat_map { |site| site['site_hosts'] }\n  host_aliases = (host_aliases - [config.vm.hostname]).reject { |hostname| hostname.starts_with? '*' }\nhost_aliases.each do |hostname|\n    config.landrush.host hostname, PRIVATE_IP\n  end\nelse\n...\nend\n```\nThis way we're re-using the private IP and config.vm.hostname.\n. No need for with_items here. Just hardcore hhvm in there.\n. Yeah I probably can. That was left over since I needed those vars to be globally available.\n. Good catch, I removed these in a few other places but missed this one. I'll do a search for any other occurrences.\n. This is the main thing that still needs to be done before this is merged. Ran into issues with this on roots.io because of how Ansible runs sudo commands. Normally you could add a rule like deploy ALL=(root) NOPASSWD: /usr/sbin/php5-fpm and it would be fine.\nProblem is Ansible runs the command like sudo -k && sudo -H -S -p \"[sudo via ansible, key=qdpnqhzmilpnttuggtaksahbdfzzsstz] password: \" -u root /bin/sh -c '\"<command>'\".\nWhich is insane and I couldn't figure out how to do this.\n. Yeah good catch. Realized last night we may want to rename deploy_user to something a little more generic like web_user. Because in development there is no \"deploy\" and it's just the vagrant user.\n. That's really terrible. Wonder if there's a more direct way if you use shell or command and do:\nsudo service php5-fpm reload\n. I got it working with this:\nSudoers file:\nweb ALL=(root) NOPASSWD:/usr/sbin/service php5-fpm *\nAnsible:\nshell: \"sudo service php5-fpm reload\"\n. Removed\n. Thanks, fixed them all.\n. Thanks I'll fix these up. Just a note that I only use quotes when the value starts in {{.\nFrom their docs:\n\nFurther, Ansible uses \u201c{{ var }}\u201d for variables. If a value after a colon starts with a \u201c{\u201d, YAML will think it is a dictionary, so you must quote it, like so:\n\nIt actually doesn't matter too much right now we're using key=val everywhere. But once this is merged I'm going to convert all tasks to YAML.\nExample:\nBefore\nyaml\ndeploy_helper: path={{ project_root }} release={{ deploy_helper.new_release }} state=finalize\nAfter\nyaml\ndeploy_helper:\n  path: \"{{ project_root }}\"\n  release: \"{{ deploy_helper.new_release }}\"\n  state: finalize\n. A common setup including one that we use for roots.io is this dir tree:\nroots.io/\n  ansible/\n  roots.io/\nie: your repo has two top level folders: ansible/playbooks (customized bedrock-ansible), and your actual site/Bedrock project. So we have project_subtree: roots.io and it just moves that up a level.\n. I kind of want to keep this role as close as possible to the original. It's going to be included in Ansible core modules sometime soon and a few changes I've made might be done upstream as well.\n. Oh yeah good point. I completely forgot about this distinction. I probably will go through the deploy role and customize/clean it up a bit more then.\n. Ah didn't run into that since I've been mostly testing deploys lately with vagrant user which already has sudoers access. Fixed.\n. Think I'd rather this just be commented out in defaults for now as well.\n. user and group are gone\n. Gone as well\n. Opening paragraphs are a little jumbled.\nMaybe:\n\nbedrock-ansible is a set of Ansible playbooks to automatically configure servers and deploy WordPress sites. It easily creates development environments with Vagrant to help achieve development & production parity.\nConfigure complete Bedrock-based WordPress ready servers with a single command:\n. Should just expand this a little:\nThe secure-root.yml playbook is provided to help secure your remote servers including better SSH security.\n   See the Wiki for Locking down root.\n. Not until secure-root.yml is either explicitly added to our instructions or merged into server.yml though.\n. Updated!\n. Can we reference www_root here?\n. Could you move this up under ANSIBLE_PATH? Rather just have them grouped.\n\nAlso: File.join(ANSIBLE_PATH, 'vendor', 'roles')\n. Only site_hosts get added as hosts, not the key. I had staging as staging.example.com but it seems like the site name should be consistent across all the env files. After all it's the same project. It's just the settings that vary.\nThis name is only descriptive and is never used as an actual \"domain\". The project is called \"example.com\".\n. That's awesome. Never knew about before/after (which I swear aren't anywhere in the docs).\n. I reverted some naming updates after talking with @retlehs but it's still a little better now with more descriptive comments.\n@fullyint think of it in the context of deploying:\n./deploy.sh staging example.com\n./deploy.sh production example.com\nYou're still deploying the same project/site, just doing it to a different host.\nRather than: ./deploy.sh staging staging.example.com\n. Good catch, updated.\n. ruby\nconfig.vm.provision :shell do |sh|\n  sh.path = File.join(ANSIBLE_PATH, 'windows.sh')\n  sh.args = ANSIBLE_PATH\nend\n. I think this string (and the above for require uri) should be stored in defaults as a variable. Then they can easily be overridden.\n. Ensure cache folder exists\n. These times and sizes should also be in defaults as variables.\n. sudoer_passwords[item.name]\n. Just map here :)\n. :+1: \n. no need for quotes on these values?\n. might as well get rid of the unneeded quotes in this file\n. Rather remove them to be consistent with the rest of our codebase since it's in our repo.\n. wp core is-installed && wp eval 'wp_clean_themes_cache() && switch_theme(get_stylesheet());'\n. Spaces inside the {}\n. What about mysql_remote_database?\n. How about naming this timezone_path (since it might not be valid)?\n. when: not valid_timezone.stat.exists should work? Little nicer.\n. Extra blank line here\n. I agree with @louim in this case about small tasks. It's also better when failures happen since you'll know it's a problem with a single command instead of a part of a complex command.\n. Let's just disable it in development. This goes a little beyond dev/prod parity.\n. Is the defined check needed? Since the above task only runs when the git project exists, how would it never have stdout?\n. @fullyint yes that's more clear :+1: \n. I don't like that URL. It says to do 32 32k which is 1MB. They don't see to understand it multiplies them.\nShould add this one: https://gist.github.com/magnetikonline/11312172\n. not needed?\n. can you kill these blank lines?\n. can you restore this formatting/indentation to what it was?\n. single quotes here and above :)\n. yaml\nwhen: not sshd_permit_root_login and admin_user_status|failed\nThink that's the same\n. You re-used the variable name from above but this should probably be more descriptive for this task. Like wp_permalink_results\n. There might be a really obvious reason why I'm wrong, but can't this just be service nginx reload?\n. @dagobertrenouf are you able to update this?\n. @chriszarate just realized an alternative solution I think might be better. Just have a variable called sudo_group_permissions which defaults to (ALL:ALL) and then you could customize it to (ALL) NOPASSWD:\n. do we care how messy this is? If the variables were strings it could be:\nadd_header Strict-Transport-Security \"max-age={{ [hsts_max_age, hsts_include_subdomains, hsts_preload].join(';') }}\";\n. Shouldn't this be set to .vault_pass? It's one less thing to change if users want it enabled.\n. I had naively hoped that Ansible would just skip using vault_password_file if nothing was encrypted so that this could be set to .vault_pass.\n. could this be separated into its own playbook and included so it's DRY?\n. Can we actually move this further up? Maybe just before Requirements?\n. need to use new syntax here\n. no way to preserve key, value with this?\n. @thiagotalma little nitpick, but could the variable be called composer_github_oauth_token?\n. I think this should wait for #392 if we do it since there could be a disconnect between the completion commands.\n. We internally debated about whether we should be using a nightly version at all. Because then there's a difference between dev/prod.\n. These can all use when: wp_installed | success\nAlso shouldn't need last ==, so:\nwp_installed | success and not (project.multisite.enabled | default(false))\n. That would be great :)\n. oh and the parentheses aren't need either but it might be a subjective thing:\nwp_installed | success and not project.multisite.enabled | default(false)\n. yaml\ndebug:\n  msg:\n:)\n. vb.name = config.vm.hostname\n. @QWp6t update\n. Can you use yes instead of true? Matches up with Ansible docs.\n. Yeah that's inconsistent on their part :( But they always use yes/no in the options section of their docs.\n. single quotes\n. ditto\n. use provider as var\n. actually don't care much about the var name\n. when: item.value.site_install and not item.value.multisite.enabled | default(false)\n. Can we set a default here?\nitem.value.permalink_structure  | default(\"/%postname%/\")\n. admin_email shouldn't be in vault\n. ditto for db_name and db_user?\n. admin_user as well?\n. Not sure what idiomatic Python is but seems like this should be under the else condition.\n. Small thing but can the when condition be put after the template action? That way it's consistent with the rest of the codebase.\n. :fire: this blank line for consistency\n. Is this default needed? Seems it should be taken care of from within the else branach of cli_args_vault\n. :abc: order :angel: \n. nitpick but \ud83d\udd24  order these\n. We could. I kind of thought about that but figured there's no reason for anyone to put 127.0.0.1? Trellis configures localhost automatically.\nWant to do a PR?\n. warn: false\n. yaml\nargs:\n  warn: false\n. I don't think this is needed. It's an implementation detail.\n. no need for assignment here. just: \"/srv/www/#{site_name}/#{site['current_path'] || 'current'}\"\n. I'd probably just define this in roles/deploy/defaults/main.yml\n. I don't think project_current_path exists in rollback. You'd have to define it in its defaults as well.\n. I wonder if it's better to move the default vars into here.\nPros: users shouldn't have to worry about these too much so they are kept out of the way and harder to mess up.\nCons: to disable them would require  raw_vars: [] and maybe less visibility?\n. So this just prevent duplicate vars? Like in this case:\nyaml\nraw_vars:\n  - vault_foo.*\n  - valut_foo.*.bar\nThe 2nd one would be skipped?\n. python\nmatch = next((pattern for pattern in patterns if re.match(pattern, key_string)), None)\nThink that replaces the above 5 lines\n. Comprehension maybe?\npython\nreturn [self.raw_triage('.'.join([key_string, str(i)]), value, patterns) for i,value in enumerate(item)]\n. Could use a comprehension here as well\n. Unless this isn't the same thing, it's clearer to filter the list first:\n``` python\nraw_vars = set([var.split('.')[0] for key in raw_vars])\nfor var in raw_vars:\n    host.vars[key] = self.raw_triage(key, hostvars[key], patterns)\n. `possible`\n. ruby\n  site_hosts = wordpress_sites.flat_map { |(_name, site)| site['site_hosts'] }\nsite_hosts.each do |host|\n    if !host.is_a?(Hash) or !host.has_key?('canonical')\n      fail_with_message File.read(File.join(ANSIBLE_PATH, 'roles/common/templates/site_hosts.j2')).sub!('{{ env }}', 'development').gsub!(/com$/, 'dev')\n    end\n  end\nmain_hostname, *hostnames = site_hosts.map { |host| host['canonical'] }\n  config.vm.hostname = main_hostname\nredirects = site_hosts.flat_map { |host| host['redirects'] }.compact\nif Vagrant.has_plugin? 'vagrant-hostmanager'\n    config.hostmanager.enabled = true\n    config.hostmanager.manage_host = true\n    config.hostmanager.aliases = hostnames + redirects\n  else\n    fail_with_message \"vagrant-hostmanager missing, please install the plugin with this command:\\nvagrant plugin install vagrant-hostmanager\"\n  end\n``\n.when: item.value.site_hosts | map(attribute='canonical') | count != item.value.site_hosts | count`\nSame thing and any better?\n. Or when: site_hosts_canonical | count != item.value.site_hosts | count\n. scratch these, won't work :(\n. Let's get rid of this and consolidate the tasks into a single CSR one with the SAN feature. I tested it and it works:\nyaml\n- name: Generate CSRs\n  shell: \"openssl req -new -sha256 -key '{{ letsencrypt_keys_dir }}/{{ item.key }}.key' -subj '/' -reqexts SAN -config <(cat /etc/ssl/openssl.cnf <(printf '[SAN]\\nsubjectAltName=DNS:{{ site_hosts | join(',DNS:') }}')) > {{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  args:\n    executable: /bin/bash\n    creates: \"{{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n. Alternative:\nyaml\nsite_hosts_canonical: \"{{ item.value.site_hosts | map(attribute='canonical') | list }}\"\nsite_hosts_redirects: \"{{ item.value.site_hosts | selectattr('redirects', 'defined') | map(attribute='redirects') | map('first') | list }}\"\nsite_hosts: \"{{ site_hosts_canonical | union(site_hosts_redirects) }}\"\nThese have the advantage of making usage in other roles simpler. No need for looping or default.\n. Shouldn't this be before the line above it?:\nbash\nsudo apt-get -y update\nsudo apt-get -y install python-pip\n. Seems like it should be before. Are you testing from scratch to test? Anyway, let's put it before \ud83d\udc4d and we're good\n. Can this be site_hosts | join(' ')?\n. Not worth it, good as is \ud83d\udc4c \n. Thanks!\n. Can we be consistent about quotes throughout this file? Some have them, some don't without a noticeable pattern.\n. Is this needed? Thought we always required an explicit env\n. Think it's better to be explicit here with the open command?\nbash\n./xdebug-tunnel.sh example_com_prod open\n./xdebug-tunnel.sh example_com_prod close\nIs this better?\nbash\n./xdebug-tunnel.sh open example_com_prod\n./xdebug-tunnel.sh close example_com_prod\nReads better at least\n. Does this work? Redundant? It's being set in both branches\n. Maybe: # providers: mariadb or percona. While you're here, let's just simplify this to: \"WordPress Server: Install LEMP stack\". Same here. Let's use https here. And https here as well :). mysql_binary_logging_disabled. blank line after this please \ud83d\udc7c . Shouldn't we enforce the path here? Items set to absent aren't included here anyway.. Same with here. Think we can simplify this a bit more:\nbash\nBRANCH_NAME=\"$(git rev-parse --abbrev-ref HEAD)\"\nNothing else should be necessary since we're only checking if it's not master.. There's a bunch of these in the templates. Can they be converted to use ternary? I think it reads better:\nAddressFamily {{ network_ipv6_enable | ternary('any', 'inet') }}. Yes to all of those unfortunately :) the code is in Trellis so it should conform to our standards.. How about making this per site? \nyaml\nwordpress_sites:\n  example.com:\n    // blah blah\n    ssl:\n      enabled: false\n    load_balancer:\n      enabled: true\n      ssl_terminated: true\n      port: 8080\n    // blah blah. I've updated all the formatting \ud83c\udf89 . @fullyint just noticed this, could cause problems now?\nref: https://github.com/roots/trellis/pull/729. you snuck some of your custom ones in here :trollface: . I might rather duplicate this whole block at this point. What do you think? Meaning one for ssl_enabled and one for ssl_terminated . is shell needed for ENV vars?\nAnsible does support environment: http://docs.ansible.com/ansible/playbooks_environment.html. This can just be a plain file with a copy right?. Can both of these get spaces surrounding them like the others?. Blank above above this. Use the YAML format here\nyaml\npip:\n  name: paramiko\n  state: present. \"{{ site_purge_backup | ternary('purge_backup --force', 'backup') }}\". \"{{ site_purge_backup | ternary('purge_backup --force', 'backup') }}\". There ideally shouldn't be a default schedule here. Can this be omitted?\nschedule: \"{{ item.value.backup.schedule | default(omit) }}\"\nschedule will be skipped when item.value.backup.schedule is not defined. Omit this too is possible. We don't need all these defaults set right? They already have | default([]). \ud83d\udc4c updated. Don't need this changelog entry either anymore.. What about using deploy_helper.previous_release_path and just replace with deploy_helper.new_release_path?. Is this supposed to be ssl_client_cert_url in the first one? Just confused why it's checking the same variable. There's two spaces before { \ud83d\udc7e . ditto here too. Was this change from h5bp? I believe it should stay as /run. It's the \"newer\" location and /var/run is symlinked to it.. From what I can tell it is. So let's keep it as /run. Any reason for this?. I'd prefer explicit names for these: site_hosts_canonical. site_hosts_redirects. Small thing, but prefix resolving_vm with _ since it's unused. dig is awesome but only used in one method. Can we do without it for now?\nI'd rather bump this separately. It does involve a little discussion since triggers and landrush plugins won't work :( (annoying since they are dead plugins).. \"Add MariaDB APT key\". It's a little odd to hardcode this is a 2nd place especially since it's the production value only. Is this actually needed?. background_update not background_updates. yeah I'd prefer this to be grouped in cache_config \ud83d\udc4d . Just copied from Mariadb site but updated to hkps and it works \ud83d\udc4d . Can this be double quotes for consistency? \ud83d\udc7c . nfs is still a valid type. Why not just set it to that instead of this?. I think that's better anyway \ud83d\udc4d . There's no need for this file right? I'd prefer it removed from this PR.. I'd prefer a deploy_method variable with two options: archive and copy (or a better name).. It would be nicer to use block to separate the two methods, or even put them in their own files and use include based on the method variable.. This doesn't properly support repo_subtree_path does it?. Think I'd rather supply the defaults here then put them in the default config.. spaces missing after these commas. kwargs would make this a bit clearer:\nruby\nmount_options(mount_type, dmode:, fmode:). We could do something like to avoid the extra conditional branch:\n```ruby\nsynced_folder_options = {\n  mount_options: mount_options(vagrant_mount_type, 755, 644)\n}\nif vagrant_mount_type == 'smb'\n  synced_folder_options[:smb_username] = vconfig.fetch('vagrant_smb_username', 'vagrant)\n  synced_folder_options[:smb_password] = vconfig.fetch('smb_password', 'vagrant)\nend\nconfig.vm.synced_folder ANSIBLE_PATH, ANSIBLE_PATH_ON_VM, type: vagrant_mount_type, synced_folder_options\nconfig.vm.synced_folder File.join(ANSIBLE_PATH, 'bin'), bin_path, type: vagrant_mount_type, synced_folder_options\n```\nWould something like this work?. I've updated it to the latest \ud83d\udc4d . I switched this back to non-hkps because 16.04 doesn't support it. I'm fine with keeping this \"non-secure\" version since the official MariaDB instructions use this as well. It makes it way easier for people to stay on 16.04 for now.. This changed from 775 to 774, just a mistake or on purpose?. ~/.ssh/config is a safe assumption on Windows as well?. And if that file exists, we can safely assume it's the same format I'm guessing?. Let's do this separately after I merge this \ud83d\udc4d . I think we can do #!/usr/bin/env python{{ ansible_python_version[0] }}\nThen it would output either python2 or python3.. This is working from my testing. Here are all the Python binaries installed on 16.04:\npython      python2     python2.7   python3     python3.5   python3.5m  python3m\npython2 is just python2.7 which also happens to just be plain python.\nThat being said... I'm pretty sure all Trellis 16.04 installs get Python 3 installed as well (not explicitly but as a transitive dependency).\nSo I'm wondering if this is worth it or if we should just default to python3 as you had it.. That looks good. I tested and it works on 2.7 as well \ud83d\udc4d . Let's just leave this as you had it for now. Keep it simpler unless we need to make it more flexible.. Looks like we need to do the actual plain python package to get /usr/bin/python which is what Ansible needs.. ",
    "robfeldmann": "I see. Somehow I thought that the playbook would allow me to create/provision a new Bedrock-based Wordpress project from scratch. This makes sense though. \nThanks for the quick response!\n\nOn Apr 21, 2014, at 9:25 AM, Scott Walkinshaw notifications@github.com wrote:\nThis playbook isn't designed to download WP. It's meant to work with an existing Bedrock-based project/repo that already has it. For a dev environment this means having your local project synced through Vagrant. See the example synced_folder in the Vagrantfile.\nFor production environment, right now the best way is to set site_install to false, and then somehow deploy your site to the server. Bedrock comes with Capistrano by default which this playbook works with. Once the files are on the server, you can them manually install if you need to. Or import a database.\nSome of this process needs to be improved but it will always expect you to have a project/repo from the start.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "Foxaii": "Is your example.dev folder a Bedrock project or just empty?\n. Yes. The synced folder should be a Bedrock project or you will need to customise the roles.\n. Not yet.\nThe Ansible module requires dopy but that hasn't yet been updated for the v2 Digital Ocean API (issue here).\nI have been using the Digital Ocean Vagrant plugin instead, but haven't had the time to create a fully formed Vagrantfile.\n. See if you can log into the dashboard. If you can, deselect and reselect your theme.\n. Unless something has changed recently, Virtualbox is already the default Vagrant provider, so that shouldn't need to be stated (and afaik not stating it hasn't caused any issues to date). Can you expand on how it is \"failing out of the box\" for you?\nThe Roots example project documentation should show that if the Vagrantfile is moved, the Ansible path should be updated accordingly. This makes more sense than a customisation that would break every other usage.\n. I've not been able to replicate this.  Can you let us know what version of Ansible you are using?\n. Thanks for highlighting this as it can definitely be clarified, but I don't think that your wording is any more correct.\nThese CANNOT contain the characters \"{%\" in succession\nI believe this means that { and % cannot be doubled up i.e. {{ or %% will be parsed incorrectly.\nWhereas your wording could be interpreted as you cannot have {% or {{ in succession i.e. {%{% or  {{{{ or {%{{ or {{{% will be parsed incorrectly.\nWhatever the note gets changed to should include examples, that way you can leave out the semantics.\n. There's nothing wrong with the playbooks. The issue is the h5bp rules are attempting to write a log to a non-existent directory, so you just need to customise the rules to your requirements. \nThere is already a log folder available for each site installed by Trellis. You should just use that:\n```\ncache.appcache, your document html and data\nlocation ~* .(?:manifest|appcache|html?|xml|json)$ {\n  expires -1;\n  # access_log logs/static.log;\n  access_log {{ www_root }}/{{ item.key }}/logs/static.log\n}\n```\nYou can also create log files directly by adding the following to the Nginx role:\n- name: Create initial Nginx log for h5bp\n   file:\n     dest: /usr/share/nginx/logs/static.log\n     state: touch\n. You can see what changes were made to incorporate PHP 7 by looking at the commit 1c8cea31f878fc42f0c76ec40ba25fe1f1a9e529.\nReverting the commit may be enough to reinstate PHP 5.6 (ymmv) but it's not something we're able to support.\nIf the troublesome plugins are just spitting out errors, @retlehs's post about removing deprecated notices is worth a read.\nThe only other thing I would suggest, wherever possible, is opening issues (good) or PRs (better) to help bring the plugins up-to-date.\n. ",
    "peatfirestudios": "It was just empty. Should I have created the folder, cloned Bedrock into it first, then run Vagrant up?\n. Many thanks. Adjusting now.\n. ",
    "spdaly": "Yes. Vagrant 1.5.4. VirtualBox 4.3.10.\n-projects\n-- example.dev\n-- bedrock-ansible\n. I did a vagrant destroy and a vagrant up and I didn't get the same error.\n. ",
    "nathanielks": "Working on it\n. Considering the conversation we had the other day about memcache and having it enabled or disabled based on a boolean, do we want to do the same thing here, or just enable it always in php.ini?\n. I'm stopping for the night. You can follow along here: https://github.com/FightTheCurrent/bedrock-ansible/tree/feature/opcache\nI went ahead and put the default variables in roles/php-55/defaults/main.yml and overrode a few development ones in group_vars/development\n. I think checking for environment based on the group isn't that bad of an idea, though it can get hairy if there are a lot of groups. At this point though, there being only 3, so I don't see it as being that much of a problem. It's simple, it works, and it's easily understandable. Gets a :thumbsup: in my book\nFor shiggles and some good reading, could read up on variable precedence\n. I'm not sure either. The variables currently present are the differences between the production and development php.ini found here. The defaults are set to production values, that way there's no need to duplicate for staging and production.\nThe only other way I could think of doing it would be to use var_files and relegate it to a particular file, but I think that adds unnecessary complexity. I think this is a simple way of utilizing the groups we've defined. Perhaps we roll with this till we can come up with a better solution?\n. #16 is making me think more about this though... how much of php.ini are we wanting to customize? I can definitely see your point that group_vars/development has the ability to get huge if we're not careful. Though, I doubt a lot of people will be messing with these values anyway. Do we decide \"for the people\" what values should be easily customizable and have some place hidden in the recesses of the playbook where they can further customize everything? I'm starting to think var_files might be suitable in this situation like you mentioned earlier.\n. Or perhaps we have some sort of middle ground... we set what we think to be suitable defaults for all environments and then allow group_vars/{{ environment }} for fine-tuning. Here's what I'm thinking:\n- roles/php-55/defaults/main.yml - Have all defaults be set to production values, \n- vars/php-development.yml include development-environment overrides when: 'development' in group_names',\n- and finally group_vars/{{ environment }} for fine tuning\nIf we follow this model, do we follow it for other systems as well? Nginx and the like? I know for values such as max file size and timeouts we'll need to store those in a common location as well. Perhaps vars/common.yml?\n. I'm thinking the common values won't really change across environments so there doesn't have to be any sort of condition as to when it's loaded.\n. Just realized I didn't actually address file size. Shall I submit another pull? What would be a good default upload size be?\n. Actually, I could just implement what @jasonmarlin initially recommended.\n. #77\n. Any chance you could share the branch you're working on for DO? I'd love to see what you're doing and see if I can't weigh in at all too\n. I didn't have the composer error, but I did also have the .env issue. The order I followed was deploy:check, deploy (fails), provision(fails), deploy(succeeds), provision(succeeds) and that fills in the gaps.\u00a0\nEither way though, needs to get fixed.\u00a0\n\u2014\nSent from Mailbox\nOn Thu, Sep 18, 2014 at 12:19 AM, Austin Pray notifications@github.com\nwrote:\n\nFyi just spun up a DO server with a base ubuntu 14 install with the latest master. wordpress-sites failed on \nTASK: [wordpress-sites | Install Dependencies with Composer] ******************    \nstdout: Composer could not find a composer.json file in /srv/www/website.com/current\nAlso got this error:\nERRORlinked file /srv/www/website.com/shared/.env does not exist on serverip.com\nwhen I ran bundle exec cap staging deploy:check\nIt seems like the playbook is assuming the files are already there via the virtualbox synced folders.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/30#issuecomment-55995997\n. whaa? No, that doesn't sound right. Though I have noticed that I've needed to reload/restart the nginx/php to get it working sometimes. I've thought about adding a cleanup role or something to restart/reload particular services so everything is fresh.\n\n@swalkinshaw thoughts?\n. Aye, good point. It didn't occur to me the passwords would be stored within the repo, I thought they could be definited elsewhere ( which I think they can ). Either way, Vault or Git Encrypt are definitely the better options.\n. No worries. I can submit a patch if you like!\n. Also, what's the plan for memcached integration with roots/bedrock? Will there be any configuration added to that repo?\n. Well, another question I have is how sold are you on integrating Memcache as opposed to Redis?\n. In my fork, I was going to go with Redis but then saw y'all added the memcached route, so I diverted as well to stick as close to y'all as possible.\n. :thumbsup: works for me. I'm going to think more about what you asked earlier... I'll keep you posted!\n. Absolutely! And I'll preface SSL specifically: it's a slight hack. Currently, Ansible and ansible-vault don't have a way to decrypt files using the copy module, so I'm having to store certificates in a var file and encrypt the file. That feature is eventually going to be implemented, but until then...\n. @swalkinshaw @ckovey so far from what I've seen, no. There has to be some sort of interrupt because Redis will serve the page from memory, so it has to be loaded before WordPress is =\\\n. @swalkinshaw @ckovey there is this: https://github.com/ericmann/Redis-Object-Cache, though when I was doing Redis research a while ago, it was still under development. That may have changed.\n. Aha! it's not! It would appear they've reached a functional 1.0\n. @ckovey I'm biased, but I'm a fan ;)\n. I figure then continue using Memcache + Batcache until someone does make a Redis Batcache, yeah? Unless you're feeling adventurous =p\n. Wanted to check in here as I'll finish up Memcache or start on Redis. Any word on which direction we should go with?\n. 1) Totally cool. No biggie.\n2) It slipped my mind first time round, so I moved it to the memcache role. two birds with one stone, I figured.\n. Ha, I completely forgot myself! Updated to use variables\n. That's a great question @austinpray, one that I had myself, but wanted to stick with what foundation has already been laid. @swalkinshaw thoughts?\n. I dig it as well! :thumbsup: \n. After thinking about this more, I still think we'll need something on the ansible side to turn caching on and off though, yeah? Memcache won't cache anything because the WP caching plugins usually require WP_CACHE to be enabled, but what about a/the nginx cache?\n. Or shall we leave that a separate PR?\n. Also, I apologize, I goofed and worked off master, so my other PR's are based off this one. Will probably want to merge this first then #44 and #45 ( if I make the cut ;) )\n. Just to be clear, do you mind defining squash for me?\u2014\nSent from Mailbox\nOn Tue, Sep 2, 2014 at 7:16 PM, Scott Walkinshaw notifications@github.com\nwrote:\n\nOnce the name is updated can you squash commits into 1? Then it's ready to go :+1:\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/35#issuecomment-54236512\n. Done and done!\n. Any votes against including h5bp/location/expires.conf as well? Will help with browser caching of static assets.\n. Aye. It's built in to WP's wp_enqueue_anything, though it adds a query string to the end of the file with the version number, which this guy recommends against. Wufoo proposed another solution.\n\nEither way, by default we have a revving process built into WordPress. If we want to be more \"legit,\" we could also look into implementing another solution.\n. Totally agree. That'd be a great separate PR\n. Old issue in this thread, but worth bringing up again: completely forgot the Roots theme already has filename-based revving built in, so there's that.\n. I figure wait until #37 has been pulled in before starting on this one\n. Now that #37 has been implemented, how do we want to do this? In my load balancing fork, I put the ssl certs in a separate vars file and then then encrypt it. Ansible hasn't implemented https://github.com/ansible/ansible/issues/7298 yet, so we can't use Vault how I'd like to. What'd you like to do?\n. What about SSL cert location in the repo? Namely, how will Ansible know where and what to copy? Or are you saying don't worry about encrypting, just throw the certificate into a var file and leave it up to the end user.\n. I'd suggest vars/ssl.yml\n. Another option would be roles/nginx/vars/ssl.yml\n. que? What is this game you speak of @austinpray?\n. All about this too\n. Looking into this now. Would we want this to be the only option for bedrock-ansible, or be able to choose between php-fpm and hhvm via some variable?\n. Here's my HHVM branch\n. > \"wp-super-old-and-random-plugin-pro\"\n@austinpray lol.\n@swalkinshaw I was thinking something along the same lines.\n. G'day gents! You can check out my PR in #45 \n. Is there a branch I can follow for this?\n. @Foxaii brilliant. Looking forward to seeing what you have!\n. @austinpray Have you played around with it at all? I haven't had time to!\n. Until the DO ansible module is up to speed, using something like Terraform would be really helpful for my fork as well.\n. Looking that up now...\n. It's root:root\n. On my other servers, sites-enabled are all owned by root:root as well\n. Cool cool. I plan to work on #16 after we get #4 squared away.\n. I'll take care of Xdebug around that time\n. Ha, no, not yet. Figured I'd close it as we know it's going to happen. Was going to wait till #44 and #45 have been pulled so I can work off their foundation.\n. ( it makes more sense to leave it open, now that I think about it )\n. Github doesn't support gifs... so this will have to do\n\n. googles\n. mfw I try embedding gifs for the first time\n\n. lol. @austinpray I've enjoyed digging through the closed issues and seeing how many you've opened then subsequently closed yourself =p\n. ha! Look at you!\n. Curious your thoughts: should we keep the entirety of php.ini, or just keep the parts we're changing?\n. Done.\n. If this is looking good, I'll squash this one as well.\n. Okie doke, made all the requested changes. Also was able to figure out, we can throw all of our handlers in one file and have subsequent tasks utilize them, so I threw all the handlers thus far into roles/common/handers. Using ansible 1.7.1.\nSide note: am encountering a peculiar issue and curious your thoughts. On vanilla provision, at the end of the provision, restart php-fpm and reload nginx are both notified and is output in the terminal. This doesn't occur in subsequent provisions. Any idea why this may be happening?\nAnother note: On subsequent provisions where switching between implementations, a 502 is thrown until nginx has been reloaded or the box restarted.\n. To address the 502, should we reload nginx after wordpress-sites has done it's thing, just to be sure?\n. Ah, good catch! Done.\n. Though, after re-reading the docs, I'm not sure this is a super new feature... did it just not work before? The docs say once loaded, handlers apply across all playbooks. They also mention having a handlers/handlers.yml file, though just including it in roles/common does the same trick without extra configuration.\n. I rolled back my version of ansible to 1.5.4 and confirmed: this isn't a new feature. Turns out we've been duplicating our handlers for nothing =p\n. Silly @swalkinshaw :wink: \n. If this is looking good, I'll squash this one as well.\n. I'll get to the file permissions asap. As far as the vars/common.yml logic... to be honest, I'm don't really remember! group_vars/all would accomplish the same thing. Shall I make that switch?\n. Hey, I rebased and merged and started testing on a vanilla install and am running into some 502's. Will work on this some more and get back with you when it's ready.\n. Okie doke. Did some more testing and reporting some findings:\nProvisioning a php implementation in a way locks the server into that one implementation. Otherwise, reprovisioning with a different one results in 502 errors. Restarting the machine, however, resolves the 502.\nAfter some further testing, I was able to find something curious: initial provision of a php implementation works out fine. Reprovision with another results in a 502. I ssh'd into the machine, ran ps -waux | grep nginx and got this output:\nvagrant@example:~$ ps -waux | grep nginx\nroot      1475  0.0  0.2  90400  2532 ?        Ss   23:27   0:00 nginx: master process /usr/sbin/nginx\nwww-data  4715  0.0  0.5  93720  5156 ?        S    23:29   0:00 nginx: worker process\nwww-data  4716  0.0  0.5  94040  5872 ?        S    23:29   0:00 nginx: worker process\nvagrant   7352  0.0  0.0  10468   920 pts/0    S+   23:32   0:00 grep --color=auto nginx\nNow here's what's curious: I ran sudo service nginx status, and it gives me this:\nvagrant@example:~$ sudo service nginx status\n * nginx is not running\nAfter some more testing, I've found that 502's aren't consistent, but the above two conditions are. Going to keep testing and see what I can come up with.\n. I was wondering that too, but it doesn't do anything. The thing I find curious is nginx is running, but service doesn't have access to it. Found this,  so I'm wondering if bindfs may be mucking with things. Still testing a few other things.\n. Ah, gained some more insight. From example.dev.error.log:\n5877#0: *19 connect() failed (111: Connection refused) while connecting to upstream, client: 127.0.0.1, server: example.dev, request: \"GET /wp/wp-cron.php HTTP/1.1\", upstream: \"fastcgi://127.0.0.1:9000\", host: \"example.dev\"\n. This is while fpm has been provisioned. It should be connecting over a socket.\n. You know what, I'm wondering if the initial provision's nginx process is still running and somehow get's disconnected from service. I've been testing provisioning one implementation before another on a fresh box and it seems whichever one is provisioned first is the one nginx binds to.\n. Opa! I think I got it. There is no pid file set in /etc/nginx/nginx.conf, so the original process can't be stopped and a new process can't be reloaded. Testing now.\n. Shoot. I was wrong.\n. Okie doke. This can be safely merged now!\n. yerp, on it\n. boom.\n. Okie doke, ready for review.\n. just found out hhvm won't be supporting multiple worker pools, so we could only use one socket for one domain. The workaround is to have separate hhvm instances running on different ports. I know thus far bedrock-ansible has been developed with the ability to run multiple domains/sites, so how would we like to proceed on this one?\n. @swalkinshaw I forget where we landed on this... \n. Whoop whoop!\n. I've had the same thing happen to me as well. I believe I vagrant halt'd other vm's that were running and retried and it worked.\n. If remember correctly, it has to do with ip/portforwarding. Vagrant issue more than a bedrock-ansible one. Glad it's working now!\u2014\nSent from Mailbox\nOn Wed, Sep 10, 2014 at 7:40 PM, timiyay notifications@github.com wrote:\n\nThis issue seems to have resolved itself, though I have no idea why. I just vagrant destroyed my bedrock box, ignored it for a couple of days, then did vagrant up, and I'm back in action.\nI'll close this off...\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/46#issuecomment-55204871\n. @intelligence It has to do with how Vagrant manages multiple boxes running at the same time. Whenever there's an ip clash ( ie, more than one box ), it has to change the ports it uses to ssh into the server. Bringing down other running boxes and then bringing mine up cleared the issue for me. Might also want to open up VirtualBox and see if there are stray machines that were created but not halted/destroyed in the past. Could be your issue there. Hope this helps!\n. @intelligence yuck. sorry =\\\n. in whatever directory you have this project living in, what does your .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory file look like?\n. Aye, that's the right one. Have you ever been able to successfully provision this machine, or is this a vanilla one?\n\n\u2014\nSent from Mailbox\nOn Mon, Nov 17, 2014 at 3:49 PM, intelligence notifications@github.com\nwrote:\n\nIn my bedrock-ansible folder I have a .vagrant folder, it's only subfolder is \"machines\", is this the folder you mean, but that it lacks the provisioners subfolder?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/46#issuecomment-63382415\n. Is this immediately after a provision? Have you ssh'd in a few times before you weren't able to connect?\n\n\u2014\nSent from Mailbox\nOn Fri, Jan 23, 2015 at 6:14 PM, Alexandre Girard\nnotifications@github.com wrote:\n\nHi all,\nI've got the same kind of issue, and tried every mentionned in this thread without success.\nEverything is a fresh install on a debian wheezy.\nCould you help me debug this problem ?\nIn virtualbox GUI, the bedrock virtual machine is running.\nHere is a part of the VAGRAND_LOG=debug log : \nDEBUG ssh: == Net-SSH connection debug-level log START ==\nDEBUG ssh: D, [2015-01-24T00:56:57.428328 #24515] DEBUG -- net.ssh.transport.session[51c44cc]: establishing connection to 127.0.0.1:2222\nD, [2015-01-24T00:56:57.429399 #24515] DEBUG -- net.ssh.transport.session[51c44cc]: connection established\nI, [2015-01-24T00:56:57.429904 #24515]  INFO -- net.ssh.transport.server_version[51c7f8c]: negotiating protocol version\nDEBUG ssh: == Net-SSH connection debug-level log END ==\nHere trying with command line : \n$ ssh -vvv -p 2222 -i /home/alx/.vagrant.d/insecure_private_key vagrant@localhost \nOpenSSH_6.0p1 Debian-4+deb7u2, OpenSSL 1.0.1e 11 Feb 2013\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to localhost [::1] port 2222.\ndebug1: connect to address ::1 port 2222: Connection refused\ndebug1: Connecting to localhost [127.0.0.1] port 2222.\ndebug1: Connection established.\ndebug3: Incorrect RSA1 identifier\ndebug3: Could not load \"/home/alx/.vagrant.d/insecure_private_key\" as a RSA1 public key\ndebug1: identity file /home/alx/.vagrant.d/insecure_private_key type -1\ndebug1: identity file /home/alx/.vagrant.d/insecure_private_key-cert type -1\nThen if hangs...\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/46#issuecomment-71288796\n. @swalkinshaw yup, I'd recommend the same thing. Think we should disable this by default?\n. \ud83d\udc4d I'll submit a PR here in a sec. \n. PR #48 \n. Tried, failed. Also made sure permissions were correct. Nothing =\\\n\nFeeling like this guy\n\n. I had no luck getting any logs to function with that, so by changing the default to stderr, errors in all environments are sent to /srv/www/example.dev/logs/example.dev.error.log.\n. I'm going to get started on some if you don't have anything in the works!\n. :+1: \n. You can follow along here\n. Licensing question: there are a few repo's I'd like to borrow from, a few under MIT and the others under GPLv3. How would that work with us? I know we're MIT, so should we include the appropriate licenses with each role or skip them?\nRepos in question:\nhttps://github.com/nickjj/ansible-security ( MIT )\nhttps://github.com/debops/ansible-sshd ( GPLv3, and a few others )\n. Teamwork :clap: \n. :thumbsup: \n. Curious: do we want to have role-based readme's? The roles I'm using from @nickjj have readme's that could be useful for those looking to tweak information. Could be useful for our other roles as well!\n. Would you be ok if HT the original author in the readme?\n. :thumbsup: \n. @nickjj very interested, and the work done is fantastic, but licensing is the issue. We're already MIT and sticking to that ( as opposed to GPLv3 ) will just be easier.\nThanks for stopping by and saying hi!\n. @nickjj :thumbsup: \n. @QWp6t wonderful use of 'opine' ;)\n. Interesting. The gist is really helpful, now I'm wondering how to incorporate filename revving... hrrrmmmm\n. Revving is fine, but because it's not included in the repo I'm trying to figure out how to get from client to server. The gist lists moving main.min.css, but the version grunt task adds a hash to the file name, so the name won't match. I wonder if it'll accept a pattern? I'm referencing this: https://gist.github.com/nateroling/22b51c0cfbe210b00698#file-deploy-addendum-rb-L24\n. I tip my \ud83c\udfa9, @austinpray!\n. Alrighty, have a few things to work out. In the latest commit, c73a4a5, I had to allow root access in /etc/ssh/sshd_config in order for ansible to continue to be able to provision the server. Do we want to create another user that has sudo access and restrict root ssh login? deploy perhaps? Or continue to allow root ssh login?\n. hrm... my only problem with web is that does it really describe the user's purpose. How about admin? It'll be a user with sudo privileges, so that makes a little more sense to me.\n. Done and done.\n. I'm starting to write the documentation for the README and am realizing it's getting pretty huge. Should I continue writing the documentation in the README file, or write it in a separate readme, like SECURE-ROOT.md or perhaps a wiki?\n. After second thought, maybe not. The other roles I'd be writing documentation for already have readme's in their role directories. How do we want to let the user know they exist?\n. @swalkinshaw The admin users are set up using 2 different variables: sudoers and sudoer_passwords. More in the documentation\n. NP @swalkinshaw!\n. I sure hope so @mAAdhaTTah! I'll need to squash everything before we merge, but afaik it should be ok.\n. yup, I'll get that done now.\n. Okie doke. Rebasing is all done. Once I get the :+1: I'll squash! I did a quick provision on a vanilla server and everything seems to be checking out. Test away @mAAdhaTTah!\n. @mAAdhaTTah aye, you're right. Looking into that.\n. The one I'm pursuing is defining the user in the playbooks as opposed to the inventory files. Vagrant disregards the remote user, so in this case I think we'd be good to go.\nWas that what you were thinking?\n. sweet!\n. Squashed and ready to go.\n. How would we like to go about doing this? I've seen individual tasks be tagged as well as the role itself being tagged in the playbook. The latter would definitely be DRY-er.\n. Will do. I was thinking of using the following syntax:\nroles:\n    - { role: somerole, tags: [role] }\nSavvy?\n. If anything, that section could be commented out or something. At the very least, NFS will improve performance dramatically. Or people can change the values to something more appropriate per project. Or perhaps have default config files they could import? I have a 13\" mbp, so 1/4 mem and all cpus is a base DO box. I know while I'm cranking things out, I don't like waiting on my development machine. I'd prefer to have faster results and then tweak later. Thoughts?\u2014\nSent from Mailbox\nOn Sun, Sep 28, 2014 at 3:23 PM, Austin Pray notifications@github.com\nwrote:\n\n\ngive VM 1/4 system memory & access to all cpu cores on the host\nA bit conflicted about this. Especially if you are working with a team. I have a beefy computer:\n\nSo my box is going to be running 8 cores and 4gb of memory. I feel I would be developing and a completely different environment  with completely different constraints than someone with a macbook air or some other less beefy laptop. \nThen again production is cached anyway. What do you guys think?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/62#issuecomment-57098656\n. I can get behind 1gb || 2gb cap. @swalkinshaw?\n. Side note: sudo password will be requested whenever it attempts to mount the nfs point, so sudo password will need to be entered twice instead of once. NBD imo.\n. Done!\n. Sure thing! Btw, have you ever seen this git error?\nCannot 'fixup' without a previous commit\n. *doh. Fixed!\n. hrm... maybe we should write our own. Before this I was using some Cap tasks I wrote and was able to sync the DB without having to do what you're talking about ( see this repo )\n. :+1:\n\n\nI'd say let's support it. It'd be a simple addition to common or something.\n. Also, fwiw, that tool is really helpful. Was looking for something to sync upload directories and this is totally boss. @swalkinshaw, what would you think of including this in the project?\n. :+1: \n. Sweet! :+1: \n. Shooting from the hip here as I'm AFK: directories.yml should execute before all the Wordpress related tasks, yes? Especially considering its ensuring the existence of the www-data user which the WordPress related tasks rely on?\n. The article I read used the latter. I'll submit a PR!\u2014\nSent from Mailbox\nOn Thu, Oct 2, 2014 at 10:18 PM, Austin Pray notifications@github.com\nwrote:\n\nVagrant docs recommend\nVagrant.configure(\"2\") do |config|\n  # ...\n  config.vm.synced_folder \".\", \"/vagrant\", type: \"nfs\"\nend\nWhy are we using \nconfig.vm.synced_folder '../example.dev', '/srv/www/example.dev/current', nfs: true\nthen?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/71\n. Good teamwork everybody!\n. What error is it throwing?\n. Just a guess, have you already provisioned the machine? Is this from a vanilla install or one that already exists?\n. I really appreciate your writing ability @fullyint ;)\n\nI hear what you're saying, though I'm inclined to agree with @swalkinshaw. I wonder if there's a happy medium? I do think there needs to be a way that people can pull from upstream and not have to do all sorts of crazy edits just to get everything working again, especially considering if they're encrypting their var files ( I'm under the persuasion passwords should be stored in their own file, separate from non-sensitive data ).\n. \n. Bravo\n\u2014\nSent from Mailbox\nOn Mon, Oct 13, 2014 at 8:39 PM, Scott Walkinshaw\nnotifications@github.com wrote:\n\nI am closing this but don't just automatically defer in general :) Anyone can raise a valid point and I guarantee I have and will continue to do things wrong in this project (and others). Which is why other people helping out is always a good thing.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/76#issuecomment-58979273\n. I'd lean on adding warnings. Most likely will end up lessening debug'ing time for those who may not have it. Yeah, they can refer to the README, or we can just nudge them in the right direction straight from the console :)\n. I'll need to test this out, but at first glance it looks alrighty @fullyint. Definitely concur with not doing the heavy-handed approach. Need to give the user the option to install, not force them into it.\n. \n. Hrm, root shouldn't be used past setting up the database. Was this on a fresh install?\n\n\u2014\nSent from Mailbox\nOn Tue, Nov 4, 2014 at 10:41 AM, Austin Pray notifications@github.com\nwrote:\n\nFixed by using the root user to do the import:\n- name: Import database\n  mysql_db: name=\"{{ item.env.db_name | default(item.site_name) }}\"\n            state=import\n            target=\"/tmp/{{ item.db_import | basename }}\"\n            login_host=\"{{ item.env.db_host | default('localhost') }}\"\n            login_user=\"root\"\n            login_password=\"{{ mysql_root_password }}\"\n  with_items: magento_sites\n  when: item.db_import|default(False)\n  notify: reload nginx\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/88#issuecomment-61691553\n. Because we\u2019d be teaching a bad practice ;)\n\n\u2014\nSent from Mailbox\nOn Tue, Nov 4, 2014 at 10:54 AM, Austin Pray notifications@github.com\nwrote:\n\n\nroot shouldn't be used past setting up the database. Was this on a fresh install?\nI agree that this is a \"smelly\" way to do things and I too don't want this to make it to the master of this project. However for educational purposes why is this a problem?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/88#issuecomment-61693488\n. Ah! Forgive me. Security reasons primarily. From what I understand, you want to remove any ability to log into or use any sort of root account, be it Linux, SQL, etc, immediately after setup so no one else can fuddle with your stuff. \n\n\n\u2014\nSent from Mailbox\nOn Tue, Nov 4, 2014 at 11:22 AM, Austin Pray notifications@github.com\nwrote:\n\nOh yeah I totally agree:\n\nI agree that this is a \"smelly\" way to do things and I too don't want this to make it to the master of this project.\nMy question was the reason for it being considered a bad practice.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/88#issuecomment-61698155\n. @swalkinshaw hath returned! the world rejoices\n\n\n\n. @BrandonShutter few questions for you:\n1. Did you run secure-root.yml on a vanilla install, or was the server already provisioned?\n2. Are you running the secure-root.yml playbook first?\nThere are a few assumptions behind how this is setup:\n1. The server hasn't been provisioned\n2. secure-root.yml is performed prior to running site.yml.\n. @BrandonShutter no, it says:\n\nwhenever the server is initially created\n\nThat implies before any provisioning takes place.\n. I'm going to look into that, actually. I don't see why it wouldn't work, but apparently it's a little temperamental.\n. Mind keeping us posted as to if it gives you any more problems?\n. OH. Did you run secure-root.yml in vagrant or a server?\n. Y'all are so smart =D\n. @fullyint for load balancing and stuff I chose to just use the domain name in my fork, site hosts isn't even used. \n. @fullyint you're welcome :)\n. @fullyint SSL will be a bit different sadly as its terminated at the load balancer. Haproxy manages all the SSL handshake stuff and nginx just receives an http connection over the private network\n. @fullyint also looks like I'm full of crap. I do in fact use site_name, but with the assumption there aren't any ip's being used ( I always deleted it )\n. Im of the same mindset. Plenty of plugins that'll handle that for us. \n. I've discovered this as well. It shouldn't be too hard but I've been distracted by other stuff so I haven't had time to address it.\n. @rstormsf the admin user is added to the sudoers group, that's why it's not included in the file.\n@fullyint good catch. I assumed people would understand that as common practice, but my bad.\n. @rstormsf  such a boss! that'll be very helpful for others, thanks for sharing that!!\n. Also, a limitation to be aware of. vagrant reload sadly doesn't work with landrush. The only vagrant commands compatible are halt, destroy, and up. I've opened a ticket with them requesting reload support.\n. Was researching other vagrant dns plugins and found that they all support *nix machines only. We'd have to figure out another solution if we want to include Windows support :disappointed:. Thoughts?\n. mmm that could be a solid option. and maybe have landrush be an optional thing? \"suggested default\"?\n. :+1: \n. When in doubt, make sure wp_config and display_errors are set to true when you get a WSOD.\n. This is something we've talked about before in https://github.com/roots/bedrock-ansible/issues/76 we opted against. We definitely don't want to ignore any files in group_vars because that's what makes this so portable. I can just check out my repo and deploy. As far as security is concerned in that regard, that's what ansible-vault and git-encrypt are for. As this is a repo meant for you to modify, we leave encrypting group_vars and whatever else up to the end user.\n. Thanks for taking the time to make the modifications!\n. Nope. The idea would be those files would be encrypted in the repo, so the data is safe. You would encrypt/decrypt whenever you want to edit or access the files. ansible-playbook has a --ask-vault-pass parameter, for instance.\n. Can I vote against it? SMTP would feel more like an awkward dongle that will probably fall behind in maintenance. Reason I say this is it appears everyone uses an external service, so why bake it in?\n. What if we had a create-your-own-adventure role, a role that's run specifically for whatever theme you're looking to use? We could create one for Roots/Sage as a demo. Two birds with one stone.\n. Could also be a separate Ansible Galaxy module.\n. @heyalbert how did you install ansible on your machine? Homebrew? From source?\n. So does that mean you haven't installed ansible on your machine? Try running which ansible and see if it returns anything.\n. Ah, ok. You haven't installed Ansible yet. Per the Readme, Ansible 1.6 or greater is required. Here's how to install it. After that, you should be good to go!\n. @austinpray LOL.\n@swalkinshaw I've been thinking about this and have a few different ideas. First would be the simplest, have a main.yml and an encrypted.yml. Store everything you don't mind in plaintext in main, everything that needs to be secure in encrypted ( could solve our nginx ssl storage issue? ). Second would be scope it based on roles. If a role doesn't need vars overridden, don't add another file. Examples below.\nFirst:\ngroup_vars/development/main.yml\ngroup_vars/development/encrypted.yml\nSecond:\ngroup_vars/development/wordpress-sites.yml\ngroup_vars/development/php.yml\ngroup_vars/development/nginx.yml\n. If I remember correctly, this has to do with vagrant and system using different ruby binaries. Are you using RVM or rbenv?\n\u2014\nSent from Mailbox\nOn Sun, Mar 8, 2015 at 9:24 PM, Brendan Griffiths\nnotifications@github.com wrote:\n\nYes - vagrant plugin install vagrant-bindfs\nAfter running the above I get:\nInstalling the 'vagrant-bindfs' plugin. This can take a few minutes...\nBundler, the underlying system Vagrant uses to install plugins,\nreported an error. The error is shown below. These errors are usually\ncaused by misconfigured plugin installations or transient network\nissues. The error from Bundler is:\nAn error occurred while installing nokogiri (1.6.6.2), and Bundler cannot continue.\nMake sure that gem install nokogiri -v '1.6.6.2' succeeds before bundling.\nThanks again for your help!\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/140#issuecomment-77791041\n. @swalkinshaw want me to update the wordpress-install and wordpress-setup roles to be app-install and app-setup?\n. \n. @louim I know this isn't the permanent answer you're looking for, but a temporary solution in the mean time is to reboot the server. That'll clear the IPTables rule blocking your specific IP.\n. squashed, good sir\n. In this event, it also helps to restart the php process. vagrant ssh and execute sudo service php7.0-fpm restart\n. :+1: \n. PR incoming\n. Man Phil, you write some of the best documentation. Its seriously a pleasure to read what you write. Bravo, sir, bravo.\u00a0\n\n\u2014\nSent from Mailbox\nOn Mon, Jun 22, 2015 at 11:11 PM, Phil Nelson notifications@github.com\nwrote:\n\nClosed #246.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/246#event-337408881\n. PATH could also be updated to include ./vendor/bin.\n\n\u2014\nSent from Mailbox\nOn Mon, Jun 29, 2015 at 12:07 PM, Kalen Johnson notifications@github.com\nwrote:\n\nThe benefit of installing globally is not needing phpunit required in your composer.json file, although if you have tests for each project it doesn't hurt. I would also say it's much easier to type phpunit than ./vendor/bin/phpunit every time :joy:\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/251#issuecomment-116763138\n. Yup! That way wherever you\u2019re at you\u2019re using that\u00a0projects dependencies and not what\u2019s available globally.\n\n\u2014\nSent from Mailbox\nOn Mon, Jun 29, 2015 at 12:09 PM, Kalen Johnson notifications@github.com\nwrote:\n\nSo it'll always work where your composer.json file is which has phpunit installed? I suppose that's an option too\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/251#issuecomment-116763506\n. > You want to lock down the version just like any other package installed via composer.\n\nThis.\n. @austinpray just comparing another popular project ;)\nI'm with Austin though. Just because they do it doesn't mean we should. He brought up a great point earlier that composer should be managed as a project dependency just as any other composer package your project requires.\n. @getdave we welcome PR's! Why not try your hand? Good learning experience.\n. Herp derp. I meant PHPUnit. Good catch!\n\u2014\nSent from Mailbox\nOn Tue, Jun 30, 2015 at 11:50 AM, James DiGioia notifications@github.com\nwrote:\n\n\nI'm with Austin though. Just because they do it doesn't mean we should. He brought up a great point earlier that composer should be managed as a project dependency just as any other composer package your project requires.\nWait, composer itself should be a project dependency? Or did you mean PHPUnit?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/251#issuecomment-117253280\n. Hmmmm. The method I'm using at the moment is actually setting values in an ini using their env syntax:\n\n\nsome_value = ${SOME_ENV}\nThe value derived from that, if its True, is a string. If its 1, its interpolated as a Boolean.\u00a0\nOn Mon, Jun 29, 2015 at 7:33 PM, Scott Walkinshaw\nnotifications@github.com wrote:\n\ngetenv always returns a string anyway. So you'd need to check the variable contents if its True or 1. Is that correct @nathanielks?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/254#issuecomment-116888009\n. :+1: \n. >  So whatever test runner, test helper, etc. a dev wants to use should be permitted as long as there's no real reason not to allow it.\n\n:clap: :clap: :clap: :clap: \n. I concur. I actually do this on my own anyway =X\n\u2014\nSent from Mailbox\nOn Mon, Jul 6, 2015 at 12:22 PM, Kalen Johnson notifications@github.com\nwrote:\n\nWe've been enjoying quick vagrant provisions using the roots/bedrock box, however it does have it's downfalls\n1) Maintenance, a few things need to be manually updated like wp-cli\n2) Dev/Prod parity - while this may not be a huge difference, using a stock Ubuntu box will ensure that all the same steps are being taken while provisioning both the Vagrant box and staging/production servers\n3) roots/bedrock is the wrong name, and this is a big problem for me :troll:\nSo while initial vagrant up will take an extra few minutes, the trade-offs should be more than worth it.\nYou can view, comment on, or merge this pull request online at:\n  https://github.com/roots/trellis/pull/260\n-- Commit Summary --\n- Change base box to stock Ubuntu 14.04\n  -- File Changes --\n  M Vagrantfile (2)\n  -- Patch Links --\n  https://github.com/roots/trellis/pull/260.patch\n  https://github.com/roots/trellis/pull/260.diff\n\nReply to this email directly or view it on GitHub:\n  https://github.com/roots/trellis/pull/260\n. I can always count on @kalenjohnson to have my back :+1: \n. Not sure about that @austinpray fellow though...\n. Hey @jasperf! For clarities sake, curious where you thought it would be run?\n. Woohoo!\n. Could you outline a few more benefits?\n. And/or, more specifically, what problem(s) does this solve?\n. I use https://github.com/oscar-stack/vagrant-auto_network in my projects. I'm a fan.\n. Batcache only works with Memcache.\n. wait wait wait... insert foot in mouth. Batcache just uses whatever you have set for your object cache. Derp.\n. \n. authenticated sessions cough\n. A \ud83d\udc4e  for APCu is that it's not distributed, so if Trellis ever goes multi-server, caches would be limited to per-instance. That said, APCu is very fast and good at what it does!. @partounian wp-lcache looks legit!. I don't like that it uses the database for the persistent cache, though... I'd be interested to see if they wrote the persistent layer in a pluggable way. I'd much rather use a persistent cache like Redis than a database for that. It also expects Vagrant to have run before your other environments. Likely, yes, but it doesn't really solve the issue imo.\n. We just need a generator that'll run these commands automatically ( \u0361\u00b0 \u035c\u0296 \u0361\u00b0)\n\ntrellis new boogers_project\n(half joking, half serious)\n. I dig it!\n. Only thing I'd caution against is storing variables in a vaulted hash as opposed to a prefix. Unless things are changing in 2.0, Ansible doesn't do any sort of merging, so if you want to modify that value (for whatever reason) you'll have to rewrite the entire hash instead of the one variable.\n. @louim herp derp. You're totally right. Back to the drawing board...\n. @partounian I've done this on a couple projects, actually, but I can't reveal source. First task would be to update the Vagrant file to spin up multiple servers resembling database, cache, and web servers. This would help to enforce the boundary rather than try to guess how interacting with separate servers would behave. After that, set up a playbook that installs common configuration on all the servers (common, ntp, ssh, etc) and then focus on installing the specific roles on each server. From there, you run the playbook, break something, fix it, and repeat!\nThis would be a great project to get familiar with how everything is set up. Definitely diving into the deep end, but worth it \ud83d\udc4d . I believe this is occurring because Ansible loads all the hosts and then parses them out by combining the two groups, web and whatever the environment is, but because the web is using the same ip address, I actually wonder if this is a bug in ansible itself. Do you have any insight @fullyint?\n. (I think ansible doesn't treat ip addresses with different ssh ports as unique hosts, I think it's treating them as the same and grabbing whichever one is on top)\n. herp derp, thanks @fullyint!\n. Oh, they've been added with their default values in XDebug, so no behavior has been changed.\n. Though now that I think of it, I've got a few more changes to make. WIP\n. Okie doke, I've also added a script that will create an ssh tunnel to a configured remote environment. The way it's used is this:\nbin/xdebug-tunnel.sh production some_host_prod\nsome_host_prod corresponds to a defined host in a hosts file, like so:\n```\nlet's pretend hosts/production\nsome_host_prod ansible_ssh_host=12.34.56.78\n[production]\nsome_host_prod\n[web]\nsome_host_prod\n```\nIt will create a tunnel using a control socket which enables the tunnel to persist as long as the socket is open. The socket is created at /tmp/trellis-xdebug-{{ host }}, in this case it would be /tmp/trellis-xdebug-some_host_prod. The tunnel routes local port 9000 to remote port 9000 on the host.\nTo close the connection, run\nbin/xdebug-tunnel.sh production some_host_prod close\n. @swalkinshaw @fullyint any thoughts here?\n. Notes from a conversation with @fullyint \n- [x] Replace instances of ansible_ssh_* with ansible_*\n- [x] Remove reference to xdebug_tunnel\n- [x] Remove env requirement, as well as the variable-check.yml playbook\n- [x] Replace connection: local with hosts: localhost\n- [ ] Simplify to new xdebug playbook:\n1. define these vars github.com/roots/trellis/blob/master/group_vars/development/php.yml#L8-L15 somewhere NOT in group_vars/development\n2. run server.yml --tags php\n3. run bin/xdebug-tunnel.sh production some_host_prod\n4. play\n5. run bin/xdebug-tunnel.sh production some_host_prod close\n6. change back to php_xdebug_remote_enable: false\n7. run server.yml --tags php\nIf so, consider this attempt to eliminate steps 1,2,6,7:\n- A new xdebug role includes the vars from step 1 in a roles/xdebug/defaults/main.yml file\n- The xdebug-tunnel.yml playbook runs the new xdebug role, thus handling steps 2 and 7\n- Running the playbook implicitly sets php_xdebug_remote_enable: true and running it with the close flag implicitly sets the var back to php_xdebug_remote_enable: false (handling step 6\n. Separating this into different PR's. First: https://github.com/roots/trellis/pull/676\n. @fullyint this is ready for you mate!\n. @fullyint updated!\n. Closing in favor of https://github.com/roots/trellis/pull/678\n. @fullyint okie doke, this is up too!\n. Closing in favor of https://github.com/roots/trellis/pull/678\n. Corresponding docs: https://github.com/roots/docs/pull/56\n. @swalkinshaw is there a separate repo for that? You're talking about roots.io, yeah?\n. @swalkinshaw \ud83d\udc4d \n. Updated docs: https://github.com/roots/docs/pull/55\n. @phil was about to create  a PR adding some support for trellis living behind a server that does SSL termination, but I remembered this existed and was curious where we're at with this getting merged?. Nevermind! I was able to do it pretty simply.. Unnecessary. https://discourse.roots.io/t/to-deploy-a-second-site/5229/6 accomplishes what I wanted to do. > jinja template inheritance\n\ud83d\ude0d . you muh boy, @jac-firemancreative . My only vote against that would be having apt_packages_install allows the user to override all the apt packages if they so choose. It's a case of \"I don't know why they would want to, but it's at least nice to have the option\". Though I suppose they could also override apt_packages_default as well... sure! It gets a \ud83d\udc4d  from me!. @swalkinshaw updated \ud83d\udc4d . Good work, @fullyint \ud83d\udc4d . I've also run into this. My hack was to install WP in the finalize-before step. I do believe so as command is not run in a shell environment. You have to\npass them into the task itself\nOn Feb 19, 2017 9:44 AM, \"Scott Walkinshaw\" notifications@github.com\nwrote:\n\n@swalkinshaw commented on this pull request.\nIn roles/deploy/hooks/finalize-after.yml\nhttps://github.com/roots/trellis/pull/754#discussion_r101923990:\n\n@@ -1,6 +1,6 @@\n\n\n\nname: WordPress Installed?\ncommand: wp core is-installed {{ project.multisite.enabled | default(false) | ternary('--network', '') }}\nshell: MULTISITE=false SUBDOMAIN_INSTALL=false wp core is-installed\n\nis shell needed for ENV vars?\nAnsible does support environment: http://docs.ansible.com/\nansible/playbooks_environment.html\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/pull/754#pullrequestreview-22664899,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AATKmRan542vQrmd3yqz-iiGnXq6yRpnks5reH-ZgaJpZM4L_CLS\n.\n. yup, forgot to add that \ud83d\udc4d . The idea would be:\nwordpress_sites:\n  example.com:\n    packagist_token: \"{{ vault_example_com_packagist_token }}\"\n  foobar.com:\n    packagist_token: \"{{ vault_foobar_com_packagist_token }}\". Description updated!. I updated it so the setting can change per-user. Hmm, just realized an issue. If we set the user's passwords to on_create, then https://github.com/roots/trellis/blob/master/roles/remote-user/tasks/main.yml#L25-L29 will cause problems when the user's password is different and ansible will fail. Should I add a provision in that conditional if the user's update_password != 'always'?. I'll test to verify \ud83d\udc4d . Conflicts resolved!. I've added a Skip-Cache header with the value of the $skip_cache variable. Technically, the Fastcgi-Cache header will tell me if the cache is enabled or disabled (it'll read bypass if it's disabled), but I added Skip-Cache for giggles.\n\nWhat's particularly curious is the Skip-Cache header isn't being sent on subsites? \ud83e\udd14  Fastcgi-Cache is being sent, but why not Skip-Cache?. You know, I wonder if nginx doesn't send headers with falsey values.... @greatislander I don't think so because /wp-admin/network/ gets the caching applied just fine \ud83e\udd14 \nAnother way to test this theory is to look at a subdirectory install I think.... The real kicker is https://github.com/roots/trellis/blob/master/roles/wordpress-setup/templates/wordpress-site.conf.j2#L93-L95 should cause caching to be disabled because the logged in cookie is present. That's the primary reason why I don't think it's rewrite-related.. re the /wp-admin/network/ comment: this gets rewritten to /wp/wp-admin/network/ behind the scenes. Ok, doubly weird: $skip_cache isn't being set for subdomains at all. I tested this using a very scientific method:\nmap $skip_cache $boogers {\n  0 aw-poo;\n  1 hooray;\n}\nserver {\n// skip some stuff\nadd_header Boogers $boogers;\n// rest of the config\nI then moved $skip_cache before and after the conditionals to see how it would behave on the root multisite network I knew it was working on. I was able to get the Boogers header to read both hooray and aw-poo. I was not able to get this to work on a subdomain. It's almost as if it's reading another config file, but there isn't one? \ud83e\udd14 . Tested against a subdirectory site and it's applying the cache where it shouldn't either \ud83d\ude10 . Current acting theory: fastcgi_cache is always applied when the uri ends in .php. Testing on a vanilla single-site install, everything works as expected \ud83d\ude1e . PHEW, I'm not crazy. Vanilla multisite install and the cache is hitting when it shouldn't \ud83d\udc4d . The .php theory isn't 100% accurate... they work on the root blog, but not on sub-blogs.. More specifically, I tested /wp/wp-admin/edit.php on the root blog and it sends Fastcgi-Cache: BYPASS, but not on sub-blogs. Still trying to make sense of the logic behind which urls get cached and not:\nhttp://example.dev/wp/wp-admin/: BYPASS\nhttp://example.dev/wp/wp-admin/edit.php: BYPASS\nhttp://example.dev/wp-admin/edit.php: HIT\nhttp://example.dev/boogers/wp-admin/edit.php: HIT\nhttp://example.dev/wp-admin/network/themes.php: HIT\nhttp://example.dev/wp-admin/testing.php: HIT\nhttp://example.dev/wp/wp-admin/testing.php: BYPASS\nhttp://example.dev/boogers/wp-admin/testing.php: MISS\nthe testing.php file is to remove WordPress as a possible culprit:\n```php\n<?php\necho 'testing';\n```. To reiterate: this doesn't make any sense because the WordPress logged in cookie is present, so none of these should be hitting a cache.. turns out @greatislander was on to something! I moved the conditionals before the rewrite block and it made a subdirectory install work as expected! Now to test a subdomain install. yup, that fixed it for subdomains as well!. @fullyint for the love... you're amazing.. I tried another approach of changing the development URL to see what would happen. This has nginx start after a provision. Unfortunately, nginx still isn't enabled so it doesn't survive restarts.\nvagrant@example:~$ sudo service nginx status\n\u25cf nginx.service - A high performance web server and a reverse proxy server\n   Loaded: loaded (/lib/systemd/system/nginx.service; disabled; vendor preset: enabled)\n   Active: inactive (dead)\n     Docs: man:nginx(8). What's super weird is that I've looked at older installations of Trellis on my machine and it doesn't look like the nginx service was ever enabled. Not since Sep 2016, anyway! Something else must have been enabling the service.. How do you want to go about testing this, @fullyint?. @fullyint my apologies, this got buried in my inbox. Thanks for the assist!. @swalkinshaw Changelog added. Apologies for the late reply, I've been having email issues. I can't say I've observed this, though I've only tested on vanilla WordPress installs. @connerbw do you have any tests to show remote autostart is indeed causing the issue? As I understand it, Remote Autostart will attempt a connection to the debugging server, and if the connection fails, move on with the request.\nIn the meantime, you can set it to 0 here: https://github.com/roots/trellis/blob/master/group_vars/development/php.yml#L10. Even with that said, I don't think it'd hurt to have xdebug disabled by default and manually opt in. What do you think @swalkinshaw?. We'll disable it by default, @connerbw. Just remember to add the following back whenever you want to debug:\nxdebug_remote_enable: 1\nxdebug_remote_connect_back: 1\nIf you don't want to use remote connect back, you could change the remote host to the host-only network root ip. If you're using default trellis where the Vagrant machine's ip is 192.168.50.5, the root ip would be 192.168.50.1. If you're using a different ip, change the final value to 1 and it'll point to the host machine.\n```\nxdebug_remote_host: 192.168.50.1\nor for example, if the ip is 10.0.0.5\nxdebug_remote_host: 10.0.0.1\n``. Fixed in https://github.com/roots/trellis/pull/1008. fwiw we reverted removing those two parameters. Thanks for bringing this to our attention!. Yup, my bad. Fixed.\n. Done.\n. Done.\n. I concur\n. I set it totruefor now just so others can test easily by just pulling the branch\n. unfortunately not as dictsort converts it to 0, 1\n. 1) That actually wouldn't be the case because the php cli evaluates the configuration on each run separate from the FPM service, so all good there \ud83d\udc4d \n2) I like it \ud83d\udc4d \n. \ud83d\udc4d \n. \ud83d\udc4d \n. @swalkinshaw not necessarily. For the deploy command I believe we do, though now I'm wondering if we don't... At the very least, the xdebug-tunnel.sh script does not require it because you have to specify which host you want to establish the ssh tunnel with. Because the host is specified, we don't need to do theweb:&{{env}}` deal to select which hosts we want to run the playbook on.\n. ah, yeah, the deploy command does require it because otherwise it wouldn't be able to do a subsection of hosts\n. I like the second syntax, I'll make that update \ud83d\udc4d \n. @swalkinshaw I do believe the latest resolves this!. The DRYist in me is like \"nah\" because most of it is duplicated, but extra verbosity doesn't usually hurt anyone. @fullyint what's your feeling on this?. good eye though @JulienMelissas!. nah!. ",
    "emeasee": "Works like a charm.\nStange indeed. Thanks for that.\n. ",
    "rkoberg": "One last thing. I did modify the composer.json from the original roots/bedrock version. Here is my modified version:\n{\n  \"name\": \"roots/bedrock\",\n  \"type\": \"project\",\n  \"license\": \"MIT\",\n  \"description\": \"A modern WordPress stack\",\n  \"homepage\": \"http://roots.io/wordpress-stack/\",\n  \"authors\": [\n    {\n      \"name\": \"Scott Walkinshaw\",\n      \"email\": \"scott.walkinshaw@gmail.com\",\n      \"homepage\": \"https://github.com/swalkinshaw\"\n    },\n    {\n      \"name\": \"Ben Word\",\n      \"email\": \"ben@benword.com\",\n      \"homepage\": \"https://github.com/retlehs\"\n    }\n  ],\n  \"keywords\": [\n    \"wordpress\", \"stack\", \"capistrano\", \"composer\", \"vagrant\", \"wp\"\n  ],\n  \"support\": {\n    \"issues\": \"https://github.com/roots/bedrock/issues\",\n    \"forum\": \"http://discourse.roots.io/category/bedrock\"\n  },\n  \"config\": {\n    \"preferred-install\": \"dist\",\n    \"generate-salts\": true\n  },\n  \"autoload\": {\n    \"psr-0\": {\"Bedrock\\\\Installer\": \"scripts\"}\n  },\n  \"scripts\": {\n    \"post-root-package-install\": [\"Bedrock\\\\Installer::addSalts\"]\n  },\n  \"repositories\": [\n    {\n      \"type\": \"composer\",\n      \"url\": \"http://wpackagist.org\"\n    },\n    {\n      \"type\": \"composer\",\n      \"url\" : \"http://rarst.net\"\n    },\n    {\n      \"type\": \"package\",\n      \"package\": {\n        \"name\": \"wordpress/wordpress\",\n        \"version\": \"3.9\",\n        \"type\": \"webroot\",\n        \"dist\": {\n          \"type\": \"zip\",\n          \"url\": \"https://wordpress.org/wordpress-3.9.zip\"\n        },\n        \"require\" : {\n          \"fancyguy/webroot-installer\": \"1.1.0\"\n        }\n      }\n    },\n    {\n      \"type\": \"package\",\n      \"package\": {\n        \"name\": \"roots/roots-sass\",\n        \"type\": \"wordpress-theme\",\n        \"version\": \"6.5.0\",\n        \"dist\": {\n          \"type\": \"zip\",\n          \"url\": \"https://github.com/roots/roots-sass/archive/master.zip\"\n        }\n      }\n    }\n  ],\n  \"require\": {\n    \"php\": \">=5.3.2\",\n    \"wordpress/wordpress\": \"3.9\",\n    \"fancyguy/webroot-installer\": \"1.1.0\",\n    \"composer/installers\": \"v1.0.12\",\n    \"vlucas/phpdotenv\": \"~1.0.6\",\n    \"roots/roots-sass\": \"6.5.*\",\n    \"wpackagist/advanced-custom-fields\": \"4.3.*\"\n  },\n  \"require-dev\": {\n    \"rarst/laps\": \"~1.0\",\n    \"wpackagist/a-fresher-cache\": \"*\",\n    \"wpackagist/core-control\": \"*\",\n    \"wpackagist/monster-widget\": \"*\",\n    \"wpackagist/regenerate-thumbnails\": \"*\",\n    \"wpackagist/debug-bar\": \"0.8.*\",\n    \"wpackagist/dynamic-hostname\": \"0.4.*\",\n    \"wpackagist/plugin-check\": \"*\",\n    \"wpackagist/theme-check\": \"*\"\n  },\n  \"extra\": {\n    \"installer-paths\": {\n      \"web/app/plugins/{$name}/\": [\"type:wordpress-plugin\"],\n      \"web/app/mu-plugins/{$name}/\": [\"type:wordpress-muplugin\"],\n      \"web/app/themes/{$name}/\": [\"type:wordpress-theme\"]\n    },\n    \"webroot-dir\": \"web/wp\",\n    \"webroot-package\": \"wordpress/wordpress\"\n  }\n}\n. That still was not enough. The only thing that worked for me was to copy over the https://github.com/roots/bedrock project to be at the same level as bedrock-ansible. It was not clear from the docs that this should be done, or perhaps it is common knowledge?\nI renamed bedrock to bedrock.dev. And inside of bedrock-ansible, I renamed all occurences of example.dev to bedrock.dev. Then the install completed without error (the TASK: [wordpress-sites | WP installed?] was ignored and TASK: [wordpress-sites | Install WP] completed successfully).\nFor this to work, you need the roots/bedrock copied over as the stub site (or something very similar).\nThere is a minor error (having to do with the VM?) when logging in as admin:\nWarning: An unexpected error occurred. Something may be wrong with WordPress.org or this server\u2019s configuration. If you continue to have problems, please try the support forums. (WordPress could not establish a secure connection to WordPress.org. Please contact your server administrator.) in /srv/www/bedrock.dev/current/web/wp/wp-includes/update.php on line 435\nI should also say I am new to WP, vagrant, ansible, capistrano. What is setup does seem very similar to a rails project using EngineYard.\n. ",
    "starise": "Ok, i should have to say that, 'cause i'm using a Windows host and Ansible doesnt works on Windows, i have modified your Vagrantfile to redirect the Ansible call on the guest using a little shell script. I'll hope you'll be so kind to take a look: https://gist.github.com/starise/e90d981b5f9e1e39f632\nI tried to add the --verbose parameter in the ansible-playbook call but the output is almost the same. The problem seems to be related on the missed \".env\" file, if you take a look at the output above, it says:\n\"path\": \"/srv/www/example.dev/current/.env\", \"state\": \"absent\"\nand actually there's no listed file in that directory.\n. You were right! it was a symlink creation problem, but not on the vagrant side, because the problem is already solved: https://github.com/mitchellh/vagrant/commit/387692f9c8fa4031050646e2773b3d2d9b2c994e\nInfact my .vbox config files had the Extravalue right setting inside. For some strange motivation, even if the Windows user is in the administrator's group and has right privileges to run mklink, remains impossible to create symlink using the normal user (even disabling UAC). The only way to have symlinks to work is to run vagrant up and vagrant provision in an elevated command prompt.\nI tested your latest master build with my script for windows and seems to run perfectly without any kind of error ;) if someone is interested in this, here are my setup: http://git.io/WD7KYQ\nThanks for your help.\n. No problem, thanks for your great work! ;)\n. Looks like the same dependency problem i'd here: https://github.com/roots/bedrock-ansible/issues/8\nTry to use this command in the guest (using vagrant ssh):\nsudo apt-get install -f\nthen restart provisioning using vagrant provision\n. Thanks Scott! :+1:\n. I'm sorry, i can't see any reference in the documentation about that issue. I know it can be 'optionally' disabled, but I don't like how wp-cron works. The cron can be also manually added, anyway because actually Trellis expected to work on a multisite setup, it should automatically configure the system cron, isn't it? ;)\n. @louim yes, i was thinking about the same thing: something like that as mu-plugin.\n@swalkinshaw i got your point. I think a manual solution is needed in this case. Adding a conditional should be an idea. Anyway, considering that system_cron is \"true\" by default, but in fact broken on multsite, it should be at least mentioned in the readme.\n. ",
    "hojinni": "thank you for the great work!! I'm just new to this but how to install ansible in window or did you install in vm running vagrant? My system is window and running vm with vagrant. want to use ansible & vagrant combination. \nThank you!!\n. ",
    "Idealien": "Ansible within the vagrant.\nAlso - If you use the following format for rsync to sync folders you don't get the permissions issue for trying to use the hosts file (as executable)\nconfig.vm.synced_folder \".\", \"/vagrant\", type: \"rsync\", rsync__exclude: \".git/\", \n        rsync__args: [\n          \"--verbose\", \"--archive\", \"--delete\", \"-z\",\n          \"--chmod=Du=rwx,Dgo=rx,Fu=rw,Fgo=r\"\n        ]\n. @hatelove85911 Run your IDE (or whatever method you use to open terminal / command line) as admin and vagrant inherits.\n. ",
    "chetzof": "EDIT: I guess i haven't read the https://github.com/roots/bedrock-ansible/issues/8#issuecomment-43346116 comment attentively :) Thanks to @starise\nIf you're using windows and want to get symlinks working, make sure you run vagrant as administrator, because using \nvb.customize [\"setextradata\", :id, \"VBoxInternal2/SharedFoldersEnableSymlinksCreate/vagrant\", \"1\"]\n    vb.customize [\"setextradata\", :id, \"VBoxInternal2/SharedFoldersEnableSymlinksCreate/current\", \"1\"]\nwas not enough in my case, symlinks still weren't working until i run vagrant as admin.\n. Hey, was that implemented? \n. ",
    "hatelove85911": "@chetzof , how to run vagrant as administrator?? \n. ",
    "mwalters": "Thanks @starise this got me going in the right direction to get past this.  I actually had to vagrant halt then vagrant up again, and then was able to vagrant ssh and run sudo apt-get install -f then exit out of SSH and run vagrant provision and it finally got it to provision correctly.  Would definitely be nice to not have to do the extra steps though.  Figured I'd leave my comment in case someone else comes across here with the same problem though.\n. @swalkinshaw Sorry for the lack of detail in my previous post, hope this helps:\n- I'm using OSX\n- I just installed for the first time today, so I cloned the repository around 1-2 hours ago.  Only changes I made to it were for setting the domain to testing.dev.  I'm going super vanilla with this and the roots/bedrock repo just to learn how it works before I try implementing it.\n- I am using roots/bedrock for the default base box.\nNot sure if it would help/matter, but I am on Vagrant 1.6.1.  I also had to install Ansible on the host machine to get this all working, so that was just installed today as well and is on version 1.6.1.\nWhen I initially ssh'd in to the VM to run sudo apt-get install -f I noticed it was saying a system restart was required, so that's why I halted and re-up'd.  After the box came back up I tried to reprovision it before SSH'ing in, in case that fixed it, but it failed with the same error that @ionutzp mentions above.  I then ssh'd in, ran the apt-get install, and then was able to successfully provision.\n. ",
    "ionutzp": "same as @mwalters here: osx, latest version, default roots/bedrock box\n. ",
    "austinpray": "If we want to be super cool it could automatically grab public keys based on github usernames as an additional configuration option.\nhttps://github.com/austinpray.keys\nI have set up servers to use curl to grab my github public keys before, it's pretty simple to do with ansible as well.\n. Anything I can do?\nMakes WP CLI a bit slow for certain things as well.\n. Oh yes, that too. However, I meant was there anything I can do to help diagnose the issue?\n. :beer: :beer: :beer: :beer: :beer: :beer: :beer: :beer: :beer: :beer: :beer: :beer: \n. Just applied this patch to two of my bedrock-ansible builds. Definitely a ton faster and got rid of the error messages.\n. It fails with the message: \nmsg: cannot change to directory '/home/vagrant/'/srv/www/austinpray.com/current/'': path does not exist\nso obviously the new version of ansible is interpreting:\ncommand: wp core install\n           --allow-root\n           --url='{{ item.item.env.wp_home }}'\n           --title='{{ item.item.site_title | default(item.item.site_name) }}'\n           --admin_user='{{ item.item.admin_user }}'\n           --admin_password='{{ item.item.admin_password }}'\n           --admin_email='{{ item.item.admin_email }}'\n           chdir='{{ www_root }}/{{ item.item.site_name }}/current/'\nin a weird way\n. Related? http://docs.ansible.com/playbooks_variables.html#hey-wait-a-yaml-gotcha\n. Alright I think I have a patch...\nTesting on ansible 1.6.8:\ngit clone git@github.com:roots/bedrock-ansible.git\ncomposer create-project roots/bedrock example.dev\ncd bedrock-ansible/\nvagrant up\nthis gives this error: \nmsg: cannot change to directory '/home/vagrant/'/srv/www/example.dev/current/'': path does not exist\nNow let me apply my patch:\nhttps://github.com/roots/bedrock-ansible/pull/22\nEverything works just fine now. The way chdir was passed along before was hacky anyway.\n. If we are talking from a maintainability standpoint it really should be the other way around. Conventionally in a lot of languages variables inside of single quotes will not get interpolated. Putting a template variable inside of single-quotes makes my brain hurt.\nAnsible in their docs respects this convention as well: http://docs.ansible.com/YAMLSyntax.html#gotchas\n. Thanks :D\n. It's my pleasure! This repo is super useful\n. Yeah you are right. There are plugins you can install to sync them but this seems to be a non-issue anyway. \n. I have been playing with http://www.terraform.io/\nMight be a really slick way to automate standing up servers on Digital Ocean at least.\n. Ooo this might be useful: http://docs.ansible.com/list_of_cloud_modules.html\n. Fyi just spun up a DO server with a base ubuntu 14 install with the latest master. wordpress-sites failed on \n```\nTASK: [wordpress-sites | Install Dependencies with Composer] ******    \nstdout: Composer could not find a composer.json file in /srv/www/website.com/current\n```\nAlso got this error:\nERRORlinked file /srv/www/website.com/shared/.env does not exist on serverip.com\nwhen I ran bundle exec cap staging deploy:check\nIt seems like the playbook is assuming the files are already there via the virtualbox synced folders.\n. Oh okay so the composer install error was because I had an incorrect site_name (lol) but once i corrected that I got the exact behavior you just described.\n. Just wrote a shell script that looks like this:\nbash\ncd site.com\ndeploy:check\ndeploy\ncd ../bedrock-ansible\nprovision\ncd ../site.com\ndeploy\ncd ../bedrock-ansible\nprovision\nayy lmao it works\n. Also note that I had to reboot the server to get nginx to serve the site. Is rebooting the whole server something ansible should be doing?\n. Yeah I was probably getting lazy and just decided to kill the whole thing rather than hunt. Each service should have a notify that restarts itself after provisioned doesn't it?\nAlso related: \nAfter each deploy with capistrano I have to restart PHP-FPM to clear the opcode cache or something. I want to do this as a capistrano task on the after deploy hook, but deploy does not have the proper permissions. Is this something the admin user will fix? How do you guys do automatic restarts on deploy?\nSeparate issue?\n. https://github.com/roots/bedrock-ansible/issues/61\n. Why don't we manually git clone or scp for all environments other than dev?\n. *on the first provisioning run\n. What about just SCPing the composer file?\n\u2014\nSent from my iPhone\nOn Mon, Nov 10, 2014 at 5:45 PM, Scott Walkinshaw\nnotifications@github.com wrote:\n\nMain reason off the top of my head: a deploy process can often include other steps like running Grunt or whatever. Just running a git clone wouldn't take care of any of those extra steps. I don't really like the idea of some incomplete method. Ideally the entire deploy process would be done through Ansible so then you could just run the normal deploy role/task instead of duplicating functionality.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/issues/30#issuecomment-62477667\n. Question: use how?\n. Asking because I will actually implement this for you if I am on the same page with your plans.\n\nIf I am understanding you correctly you want to use the H5BP static defaults such as nginx.conf and mime.types because those are good to have. And then you want to base our templates off of their templates\nLet me know what you want and I'll make it happen :beer: \n. I already have this basically implemented on my production bedrock ansible installs, so I just need to translate it to the latest master.\nFor instance here is the template I use for my projects that are based off bedrock-ansible:\n``` j2\ncat roles/wordpress-sites/templates/wordpress-site.conf.j2 | pbcopy\nserver {\n  set $site_name {{ item.site_name }};\nlisten       *:80;\n  server_name  {{ item.site_hosts | join(' ') }};\n  access_log   {{ www_root }}/{{ item.site_name }}/logs/{{ item.site_name }}.access.log;\n  error_log    {{ www_root }}/{{ item.site_name }}/logs/{{ item.site_name }}.error.log;\nroot  {{ www_root }}/{{ item.site_name }}/current/web;\n  index index.php;\n{% if item.env.wp_env | default('development') -%}\n    # See Virtualbox section at http://wiki.nginx.org/Pitfalls\n    sendfile off;\n  {%- endif %}\n{% if item.multisite.enabled | default(false) -%}\n    include wordpress_multisite_subdirectories.conf;\n  {%- endif %}\ninclude wordpress.conf;\n}\n{% for host in item.site_hosts %}\nserver {\n  server_name  www.{{ host }};\n  rewrite ^(.*) http://{{ host }}$1 permanent;\n}\n{% endfor %}\n```\n. > There's some of the H5BP configs that we probably don't want to include \nMy whitelist so far is \n- nginx.conf\n- mime.types\n- basically the same template that I posted above\n. https://github.com/h5bp/server-configs-nginx/blob/master/h5bp/basic.conf looks good\n. Makes sense. It's easy enough to exclude it. \n. Here is what I came up with: https://github.com/roots/bedrock-ansible/pull/37\n. :beers:\n. Redis is more clever, but if batcache works not sure if there is a great reason to try and find a more complicated alternative.\n. Why does it discriminate between development and production? The whole point of Vagrant is to get development as close to production as possible. \n. > Although memcached should probably be installed on development as well now that I think about it. As it would be helpful to be able to turn on a caching plugin to test it out before deploying.\nYes I agree. There are two use-cases the \"development\" environment has to account for: \n- the initial development where you are actually building the site\n- the infrequent maintenance tasks that occur after the site is stable\nWhen developing initially, yeah I can see why caching would be a huge hastle. Having to bust the cache every time you make a change would get super tedious. So during initial development turn caching off altogether. However, later on down the line when making small changes I would definitely want the site to be as close as possible to what is running on production and staging. So after the site is stable the developer turns caching on and manually busts the cache whenever their small changes are being made.\nSo:\n- ability to toggle the cache when provisioning vagrant (default off in development, default on on everything else).\n- ability to bust the cache easily with one command (make cachebust or something)\nDoes that sound right?\n. > To me it should really just be a matter of changing a constant like WP_CACHE in your env specific configs.\nThis this this :+1: \n. Uh oh. @swalkinshaw is there a way we can host this on a roots AWS account instead of dropbox? I would gladly chip in some $$guap$$ to cover hosting costs.\n. How about now?\n. If we enable caching wouldn't we need to implement some sort of revving process?\n. Provided we bake in the Wufoo solution by default I don't see a problem with it. \nBut enabling caching might have to be another issue separate from my basic integration PR here. \n. Fixed the formatting issues. Thanks for keeping my ass in line ;).\n. FYI: http://stackoverflow.com/questions/25576871/ansible-best-practice-to-copy-directories\n. Sure thing\n. gonna add that thing @swalkinshaw requested tonight\n. Good to go.\n. welp. I think I borked it.\n. okay fixed lol\n. @mAAdhaTTah is on that hacker news game\n. This would be very dope. \n. Ability to toggle would be nice. I am not sure how practical that would be though. \nBeing able to toggle would be nice because I already get weird looks for using MariaDB, some of the people I work with would shit a brick if I started spinning up servers with HHVM. \n. In any case it should definitely default to php-fpm. The people who turn on HHVM are also going to be the people who understand the benefits and limitations. Otherwise we are going to get inundated with people complaining about bedrock not working with \"wp-super-old-and-random-plugin-pro\". \n. If it is not possible to do with Ansible due to what @Foxaii mentioned, it my be a great time to try http://www.terraform.io/\n. I have only used it to stand up multiple digital ocean servers kind of like AWS CloudFormation, not much else. The real value would be to be able to run \"terraform apply\" and then your ansible hosts file is updated with IP addresses or something. Or have ansible pull them dynamically from a manifest file. Haven't gotten that far as usually these wordpress sites are just 1 server.\n. > edit: this isn't that great \nYeah looks like it's not working for DO either\n. @luandro I would recommend reading up a bit on how ansible and Capistrano works. This stack already works out of the box with digital ocean.\ncurrently you have to manually create a digital ocean droplet, then run ansible, then deploy with Capistrano. The scope of this issue is to automatically create the digital ocean droplet then automatically provision it. \n. Oh yes please\n. Oh cool is this done?\n. it's ya boii Austin Pray comin at you live with some project management\n. mfw i hacked github to allow me to post gifs \n. Example:\nAustins-MacBook-Pro:bedrock-ansible austinpray$ ansible-lint site.yml \n[ANSIBLE0006] cp used in place of copy module\n/Users/austinpray/Dropbox/DEV/opensauce/bedrock-ansible/roles/nginx/tasks/main.yml:0\nTask/Handler: Copy over h5bp configuration\n. Nevermind this linter is dumb\n. It looks like my issue with this linter might turn into a feature! https://github.com/willthames/ansible-lint/issues/21\n. I would keep just the parts that we are operating on. It is kind of overwhelming to see the whole thing. As a user of this repo I only want to know what bedrock-ansible is doing special. If I wanted to see what the default options were set as I could just look it up elsewhere.\n. Also that is what we do with our nginx.conf (only include relevant bits).\n. ( \u0361\u00b0 \u035c\u0296 \u0361\u00b0) \n. (\u25d5\u203f\u25d5\u273f) \n. Be sure to update the readme ansible version if you are using newer Ansible features. (\u25d5\u203f\u25d5\u273f)\u00a0\u2014\nSent from my iPhone\nOn Tue, Sep 2, 2014 at 12:00 AM, Nathaniel notifications@github.com\nwrote:\n\nOkie doke, made all the requested changes. Also was able to figure out, we can throw all of our handlers in one file and have subsequent tasks utilize them, so I threw all the handlers thus far into roles/common/handers. Using ansible 1.7.1.\nSide note: am encountering a peculiar issue and curious your thoughts. On vanilla provision, at the end of the provision, restart php-fpm and reload nginx are both notified and is output in the terminal. This doesn't occur in subsequent provisions. Any idea why this may be happening? On subsequent provisions where switching between implementations, a 502 is thrown until nginx has been reloaded or the box restarted.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/45#issuecomment-54109703\n. I blame @swalkinshaw \n. Gonna put this issue on my radar. Needs to get squashed.\n. As I understand the default way to handle a bedrock full stack:\n- You have your host system, this is whatever physical computer you have in front of you.\n- Bedrock-ansible provisions the environments your site runs in. Dev, Test, Prod, etc.\n- Bedrock provides an opinionated default wordpress scaffold.\n- Roots is a base theme (this is where grunt/gulp and compass are relevant).\n\nTechnically you can have three different repositories for a project:\n- trendysite.io repos\n  - trendysite-bedrock-ansible\n  - trendysite-bedrock\n  - trendysite-roots\nWhere trendysite-bedrock has trendysite-roots symlinked, git-submoduled, etc. I usually do not get this fancy (separating bedrock from roots). However, it can be very advantageous for people working on teams to be able to divide their effort into ops, backend, and theming. Separation of concerns. It also becomes advantageous when you want to update your bedrock-ansible or bedrock setup from the upstream master.\nbedrock-ansible and bedrock do not really have much to do with the theme's build process. The theme is built by the host machine. Say you built a theme from scratch and it's dependencies were like Ruby 2+ and Node 0.11 because you have some super strange build process. It is the responsibility of the host machine to have these dependencies. You could make ansible provision the vagrant VM to have the build dependencies but I personally would rather have the full power of my host machine with no VM imposed overhead slowing down my build. \nSo all in all, installing ruby and node seems out of scope for bedrock-ansible, as it's job is to just be the best LEMP server provisioner possible. It should not care what type of build process you are using and what the dependencies are.\nIf you want to have very consistent builds among a large group of developers (seems really excessive and unlikely for wordpress of all things), set up a CI server and have that run all the builds that make it to production.\n@swalkinshaw does all that sound correct? This is how I understand things after working with this for a while.\n. > If you were to have your themes (Roots for example) as a separate repo, might as well make it a Composer package (with a type of wordpress-theme) and manage it through that.\nI want to learn more about how this is done. Perhaps I will make a thread over on the roots forum.\n\nI don't blame @cibulka for wanting Ruby installed on the remote server. By default Bedrock uses Capistrano which is set up to run all build processes on the server during deploy.\n\nWell yes because Capistrano was built originally for working with ruby on rails where ruby is the only dependency and all the assets are compiled via asset pipeline. If you want to use bower with rails you pretty much are stuck checking files into source control or using the gist you described. Same exact situation. \n\nhttps://gist.github.com/nateroling/22b51c0cfbe210b00698\n\nYeah this is exactly what I do in order to avoid checking assets into version control. Wish I knew about this gist when I wrote that feature.\n. dude you guys are so freaking on point I was JUST thinking about this.\n. https://github.com/nickjj/ansible-fail2ban MIT\nhttps://github.com/nickjj/ansible-ferm MIT\n. > search engines indexing and showing the staging site higher in the SERPs than the production site\nJesus. Been there done that.\n. Ehhh. I prefer compiling on the client or CI. No reason to triple the time it takes to provision a server when you have a quad core, 16gb host machine that has been compiling the assets all day long. Especially when compiling images and such, that could shut servers with low memory down (mysql running out of memory and such).\nTouched on this here:\nhttps://github.com/roots/bedrock-ansible/issues/53#issuecomment-55810837\nHave cap upload your dist folder with all the compiled assets\nhttps://gist.github.com/nateroling/22b51c0cfbe210b00698\nIf we must install node on the server I usually use the heroku buildpack for that: https://github.com/heroku/heroku-buildpack-nodejs\n. Which part of filename revving is tripping you up? I have filename revving working right now in gulp and roots.\n. Oh. Yeah you are going to run into trouble trying to do stuff like that. Compiled assets go in a dist folder and you just upload the dist folder. Mixing compiled files with source files is madness. \nSet your project up like this:\nhttps://github.com/roots/roots/pull/1138#issuecomment-55362107\nAnd everything will be fine\n. Oh i guess that comes in \nhttps://github.com/austinpray/bedrock-ansible/blob/H5BPserverconfigs/roles/nginx/templates/nginx.conf.j2\n. > something generic like web\nThis sounds good\n\nWe could go with the common ubuntu\n\nEhh not great for folks that like to use Debian\n. brilliant\n. You can link them up with relative links.\u00a0\nI have never seen a well maintained wiki on GH, it seems they always fall behind.\u00a0\n\u2014\nSent from my iPhone\nOn Tue, Sep 23, 2014 at 8:17 PM, Nathaniel notifications@github.com\nwrote:\n\nAfter second thought, maybe not. The other roles I'd be writing documentation for already have readme's in their role directories. How do we want to let the user know they exist?\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/58#issuecomment-56613205\n. yall are ballers\n. Boom\n. > give VM 1/4 system memory & access to all cpu cores on the host\n\nA bit conflicted about this. Especially if you are working with a team. I have a beefy computer:\n\nSo my box is going to be running 8 cores and 4gb of memory. I feel I would be developing and a completely different environment  with completely different constraints than someone with a macbook air or some other less beefy laptop. \nThen again production is cached anyway. What do you guys think?\n. Capping at 2GB or even 1GB is reasonable. My sites barely reach 1GB of usage. Why not just set a cap at 1GB without doing the platform specific math? That is a fairly beefy linode/DO box and more memory isn't going to make a wordpress site only using 512mb faster. The NFS and CPU will be nice performance enhancers.\nAustinMacbookPro:bedrock-ansible austinpray$ vagrant ssh -c 'cat /proc/meminfo'\nMemTotal:         501776 kB\nMemFree:           56992 kB\n...\n. Also using 4GB of ram for a dev vm for me is a no-go because I usually have other VMs running such as modern.ie and friends that take their fair share.\n. sick\n. The database is in the VM, so doing any db syncing must be done from inside the box. I have been using those wpcli Capistrano tasks you recommended. \n. This is pretty full featured: https://github.com/lavmeiker/capistrano-wpcli\nThe two way syncing is what I am looking for. You just have to have ssh access through the VM. \n. Actually just realized:\nconfig.ssh.forward_agent = true\nIn the vagrant file gives you full SSH access. So you can push and pull the db, clone private git repos. Perhaps we should add this for ease of use.\n. :beer:\n. Well first merge in my html5 boilerplate stuff so we can have gzip haha. Low hanging fruit and all.\n. Weird.\nvagrant@example:/srv/www$ ls -l\ntotal 4\ndrwxr-xr-x 3 root root 4096 Oct  3 02:50 example.dev\nvagrant@example:/srv/www/example.dev$ ls -l\ntotal 4\ndrwxr-xr-x 19 501 dialout 646 Oct  3 02:49 current\nvagrant@example:/srv/www/example.dev/current$ ls -l\ntotal 76\n-rw-r--r-- 1 501 dialout   380 Oct  3 02:49 Capfile\n-rw-r--r-- 1 501 dialout  1173 Oct  3 02:49 CHANGELOG.md\n-rw-r--r-- 1 501 dialout  1868 Oct  3 02:49 composer.json\n-rw-r--r-- 1 501 dialout  6921 Oct  3 02:49 composer.lock\ndrwxr-xr-x 6 501 dialout   204 Oct  3 02:49 config\n-rw-r--r-- 1 501 dialout  3978 Oct  3 02:49 CONTRIBUTING.md\n-rw-r--r-- 1 501 dialout    86 Oct  3 02:49 Gemfile\n-rw-r--r-- 1 501 dialout   471 Oct  3 02:49 Gemfile.lock\n-rw-r--r-- 1 501 dialout  1044 Oct  3 02:49 LICENSE.md\n-rw-r--r-- 1 501 dialout 17506 Oct  3 02:49 README.md\ndrwxr-xr-x 3 501 dialout   102 Oct  3 02:49 scripts\ndrwxr-xr-x 3 501 dialout   102 Oct  3 02:49 vendor\ndrwxr-xr-x 5 501 dialout   170 Oct  3 02:49 web\n-rw-r--r-- 1 501 dialout    13 Oct  3 02:49 wp-cli.yml\nwhat's up with dialout?\n. Good discussion here: https://coderwall.com/p/uaohzg\n. we might have to use this: https://github.com/gael-ian/vagrant-bindfs\n. Yeah for some reason that worked\n. https://github.com/roots/bedrock-ansible/pull/72\n. hold off until we get the bigger issue diagnosed: \nhttps://github.com/roots/bedrock-ansible/issues/70\n. linux__nfs_options: %q(no_subtree_check all_squash rw) fixes the issue though.\n. oh wait nevermind I get it.\ntesting now.\n. verified working and squash'd.\n. (\u25d5\u203f\u25d5\u273f) \n. Yes! I guess send me the file and I will throw it on my s3\n. Sweet, I'll get it running in a moment.\n. @swalkinshaw feel free to SSH into the server and so whatever you feel necessary.\nssh root@bedrock-ansible.corelaunch.com -i ~/.ssh/id_rsa\nI added your keys: https://github.com/swalkinshaw.keys\nso you should be able to ssh.\nedit\nor this if the domain name is not propagated yet\nssh root@104.131.67.95 -i ~/.ssh/id_rsa\n. Ish ya boiii :beer:\n. @swalkinshaw all is lost, glorious leader has abandoned us.\n. @fullyint \n\nI omitted warnings for missing vagrant-bindfs plugin, a la if !Vagrant.has_plugin? 'vagrant-binfs'\n\nwhy?\n. def wall_of_text\n\nPresumably a user would see that and think, \"Huh, what's this 'bindfs'? Let me go double-check the README.\" But, admittedly, it would be clearer if we provided a custom warning, \"You need to install the vagrant-bindfs plugin.\" What do you think?\n\nThat sounds like something that, in your head, sounds like a fine idea. However, once you actually type it out and explain to someone else it very clearly sounds like a bad idea. If we can catch an error and provide helpful error messages, we should do it.\nOne thing we should keep in mind is that we should do everything in our power to keep the perceived complexity of the roots stack to an absolute minimum. I will clarify what I mean by \"perceived complexity\". \nAs a consultant I am often presenting the bedrock/12 factor app way to do things to people who think \"web development\" means \"edit in sublime text and ftp to production to see if it works\". A comment I often get is \"geez this way of doing things is really complex\". When I get comments like that I have NO idea what they are talking about. The bedrock/12 factor app way of doing things is incredibly predictable and easy to manage. People are saying bedrock is \"really complex\" while completely forgetting the world of hurt you run into when FTPing things to production crossing your fingers and hoping it works. Where the \"really complex\" comment comes from is from people who are trying to set things up for the first time and run into trouble. Every time they have to take a trip to the readme they get closer and closer to quitting.\nPersonally, if I got the error message\nThere are errors in the configuration of this machine. Please fix\nthe following errors and try again:\nVagrant:\n* Unknown configuration section 'bindfs'.\nI would right away know how to fix it. In fact I wouldn't even need to look up the vagrant command to install the plugin. Even if I didn't know how to fix it a quick google search or just looking at the source would fix it.\nHowever some people just immediately fire off an email to their boss and or me saying \"yeah the thing isn't working, this is frustrating and I can't get any work done\". I then say \"well it says right here in the instructions that you need to have this installed\". Now that guy feels dumb (rightfully so perhaps) and has an adversarial relationship with the tools. This actually happens haha. Twice in the past two months. \nNow I am not saying we should dumb down anything to pander to dummies, but we could avoid all of the above with an extra two lines of code. The CLI is our \"interface\", so it should be as friendly as possible so more people can use bedrock. The more people use bedrock, perhaps the more people put pressure on wordpress to support our methodologies out of the box.\nend\n. Fixed by using the root user to do the import:\n```\n\nname: Import database\n  mysql_db: name=\"{{ item.env.db_name | default(item.site_name) }}\"\n            state=import\n            target=\"/tmp/{{ item.db_import | basename }}\"\n            login_host=\"{{ item.env.db_host | default('localhost') }}\"\n            login_user=\"root\"\n            login_password=\"{{ mysql_root_password }}\"\n  with_items: magento_sites\n  when: item.db_import|default(False)\n  notify: reload nginx\n```\n. Yeah lemme set up a test environment to replicate.\n. > root shouldn't be used past setting up the database. Was this on a fresh install?\n\nI agree that this is a \"smelly\" way to do things and I too don't want this to make it to the master of this project. However for educational purposes why is this a problem?\n. Oh yeah I totally agree:\n\nI agree that this is a \"smelly\" way to do things and I too don't want this to make it to the master of this project.\n\nMy question was the reason for it being considered a bad practice. \n. Ah I see. Are we currently disabling the root account? I don't see a task for that. Would it even make sense to? What if you want to reprovision a server to add a new db or something?\n. Yeah it looks fine:\nhttps://github.com/h5bp/server-configs-nginx/compare/3db5d61f81d7229d12b89e0355629249a49ee4ac...master\ni'm updating and testing now.\n. I'll try this on my own droplet and see if it fails. As far as I can tell it isn't your fault and it looks like a problem with the mariadb mirror. \n. Why aren't we using the digital ocean mirror?\n. @swalkinshaw \nbash\nsudo apt-get install software-properties-common\nsudo apt-key adv --recv-keys --keyserver hkp://keyserver.ubuntu.com:80 0xcbcb082a1bb943db\nsudo add-apt-repository 'deb http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main'\n``` bash\nMariaDB 10.0 repository list - created 2014-11-10 17:18 UTC\nhttp://mariadb.org/mariadb/repositories/\ndeb http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main\ndeb-src http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main\n```\nfrom https://downloads.mariadb.org/mariadb/repositories/\n. Yessiree. Almost done testing it now.\n. @BrandonShutter are you on the latest version of the vagrant box? I'm on the latest version and it's working on a fresh clone\n. Yeah here is an example of my /etc/apt/sources.list.d/mirrors_coreix_net_mariadb_repo_10_0_ubuntu.list from a working server.\ndeb http://mirrors.coreix.net/mariadb/repo/10.0/ubuntu trusty main\ndeb-src http://mirrors.coreix.net/mariadb/repo/10.0/ubuntu trusty main\nAnsible is automatically injecting the distribution details:\nhttps://github.com/roots/bedrock-ansible/blob/256248620d04fbe74879119ff22741d5f2e025d3/roles/mariadb/tasks/main.yml#L9\n. @swalkinshaw or add an override variable that defaults to the ansible distribution thing\nedit: or everybody just use 14.04 for now. It's probably better that way since mariadb hasn't provided a release tested against 14.10. Also the vagrant box is 14.04 so you are gonna want to dev like your prod anyway.\n. This isn't a great way to do things. \n. Yeah exactly. Sweet. I suppose we can stop defining that variable by default once mariadb has a 14.10 release.\n. So when this is live we are gonna remove capistrano from bedrock?\n. > It's also really slow on a VM.\nCare to share your test results aka numberzz aka hard data? :sunglasses: \n. Also: agree with locally compiling. You need to be compiling from production with the same process you are using to dev. It would not make sense to do all of your dev on local and then hope it works inside the VM when deploying. If you are working with a team then you should be using some sort of CI process/compiling on the server.\n. Siqqqqq\n. :sunglasses: \n. lol :beers:\n. @fullyint it could contain \n- www.example.dev\n- example.dev\n- ip address \n. Good job team\n. I would say new relic support would be out of scope. There are already some great playbooks for setting up new relic: https://github.com/sivel/ansible-newrelic\n. Critical issue with your PR:\nPlease change:\nyml\nwhen: item.db_create|default(True)\nto \nyml\nwhen: item.db_create | default(True)\n:stuck_out_tongue: \n. The problem is worse than I thought! Don't worry about this one or the others, I will clean them up\nedit: https://github.com/roots/bedrock-ansible/pull/108\n. Wait why was this closed?\n. @swalkinshaw @emaildano No I only did formatting for everything except your line you added. I didn't want to take credit for your PR idea!\n. ran a vagrant up to test, works the same.\n. increasing this on development and not any other stage is asking for trouble. \n. So the current options that are set in development:\nCurrent vars set in development\nphp_error_reporting: 'E_ALL'\nphp_display_errors: 'On'\nphp_display_startup_errors: 'On'\nphp_track_errors: 'On'\nphp_mysqlnd_collect_memory_statistics: 'On'\nphp_opcache_enable: 0\nError and Verbosity Settings\nphp_error_reporting: 'E_ALL'\nphp_display_errors: 'On'\nphp_display_startup_errors: 'On'\nphp_track_errors: 'On'\nphp_mysqlnd_collect_memory_statistics: 'On'\nThese settings do not affect the way the application works, they merely notify you of errors and warnings. It would not be wise to turn these on in any stage other than development because it might leak privileged information useful to attackers. Also just looks really dirty to users to see php errors and warnings strewn about the page.\nCaching\nphp_opcache_enable: 0\nDisable opcode caching in development. This is a compromise that must be made and is a fairly benign compromise. You can't dev if you have to clear your opcode cache every time you make a change. Luckily, by the nature of what an opcode is, if the source doesn't change the opcode caching shouldn't change the runtime behavior of your application.\nVars that should not deviate between production and dev\nIf I set php_max_input_vars: 5000 in development and then php_max_input_vars: 1000 everywhere else, I run the risk of having my app run in dev and then fail in prod. The runtime constraints and settings should be as identical as possible between development and production.\n. What platform are you on? Ruby version?\n. Your gitignore for bedrock should look like this: https://github.com/roots/bedrock/blob/master/.gitignore\n. @nathanielks SMTP should be opt-out and not opt-in. We should definitely recommend people use an external service but email not working out of the box by default is unacceptable. \n. Gonna try this out on one of my servers to test\n. :sunglasses: \n. I agree with @swalkinshaw. Perhaps I can create a teeny tiny buildpack for Sage themes that gives you everything you need + a standard process to follow.\n. That was fast. Have you tried it out yet?\n. I thought WP CLI was installed when ansible runs? Why is it included in the box?\n. @heyalbert what's your group_vars/development look like? This is erroring on development right?\n. As a note: this is necessary to run WP on an AWS micro instance. \nSecondary note: Never run WP on an AWS micro instance.\n. @enricodeleo don't do it man. It's like comically not worth it.\n. hahaha\n. > solution was a cronjob to restart mysql every 15 minutes...\nI need an adult\n. Include. If I'm rolling back something has gone terribly wrong and I need a fast command. \n. Yes\n. Wait actually hold on\n. For debugging: what is your server setup?\n. @rstormsf https://help.github.com/articles/using-pull-requests/\n. > SSH in and run the same script everyone else does\nThis\n. Yep. Reduces the surface area we need to test. \n. Why would you assume the person has a \"Staging\" branch? \n. Yeah default to master \ud83d\udc4d\ud83c\udffb\n. Yep I'm seeing this as well with the latest roots-example-project.\n\n. https://github.com/roots/trellis/pull/270 fixes it on this specific production example I am working with but have yet to test on trellis master.\n. I am definitely in favor of making things more cross platform.\nOne idea to solve the PHP problem is to use https://github.com/CHH/phpenv to install PHP rather than relying on package managers.\n@saturday what issue were you having with installing MariaDB? I've never had a problem installing MariaDB on debian. I'm not sure what bedrock-ansible does different than the instructions on the website.\nedit: Yes share code please :sunglasses: \n. Compile from sauce \n. Someone just had me evaluate ngx_pagespeed: I don't really want to support this after some thought and research. \nI definitely want to see this as a user contributed extension however. I don't see why it couldn't be one.\n. - [ ] update base box\n- [ ] transfer from Austin's DO box to roots DO box\n. Gonna do some testing to see if I can make this backwards compatible\n. So I went ahead and tested:\ngit checkout master\nvagrant up\ngit checkout -b louim-mysql_root_password master\ngit pull https://github.com/louim/bedrock-ansible.git mysql_root_password\nvagrant provision\nwhich gives\nTASK: [mariadb | Set root user password] **************************************\nfailed: [default] => (item=default) => {\"failed\": true, \"item\": \"default\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=127.0.0.1) => {\"failed\": true, \"item\": \"127.0.0.1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=::1) => {\"failed\": true, \"item\": \"::1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=localhost) => {\"failed\": true, \"item\": \"localhost\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nI tried fooling around with doing things like moving the copy .my.cnf block above the set root user password and registering a variable as to what was previously there (or not there). I'm sure we could get it to work but seeing as though the current implementation is broken: let's just let this be a breaking change. \nA user wishing to patch their servers can just temporarily change their mysql root user role:\ndiff\n - name: Set root user password\n   mysql_user: name=root\n               host=\"{{ item }}\"\n               password=\"{{ mysql_root_password }}\"\n               check_implicit_admin=yes\n               state=present\n+              login_user=\"root\"\n+              login_password=\"{{ mysql_root_password }}\"\nAnd then remove those lines when the server is patched. Either that or destroy their server and re-provision. \nThis is good to merge as far as I am concerned.\n. I'm good with merging this today unless you have any reservations @louim \n. @chriszarate :watermelon: :watermelon: :watermelon: \nI second @fullyint on that wiki being well written. Great job.\n. @zamber is this fixed now that we are using ubuntu/trusty64?\n. You definitely want to install it locally. The phpunit binary should be available in ./vendor/bin\n. > The benefit of installing globally is not needing phpunit required in your composer.json file\nRight, but phpunit can have breaking changes that affect your tests. You want to lock down the version just like any other package installed via composer.\n. What does VVV have to do with anything?\n. We shouldn't hardcode the development exclusion. Just make it a config option that perhaps we set to \"off\" by default in the development vars.\nEdit: that way people if people want to speed up remote droplet creation for testing they can do so.\n. I'm with @louim as far as making this into an Ansible Galaxy role. I definitely want to keep the core functionality of Trellis as general and decoupled as possible. As a maintainer I want to keep this repo focused on its primary mission: spinning up a rock solid WordPress server environments. Further setup inside this environment should be userland stuff. \n@swalkinshaw perhaps we should create a section in the README for these user contributed Galaxy addons. \nAlso as a by-the-way: Curious to see how this setup compares with @johnpbloch's setup. \n. :clap: \n. @nathanielks Yeah I do this as well. \n. Yeah we should overwrite it each time. Especially seeing that bedrock gitignores it\n. @alan-c \n\n\n\"*.example.dev\" in site_hosts leads to fatal DNS config issues when used to attempt a setup of development environment with Landrush - details here.\n\n\nYep I ran into this and it completely killed my dev environment until I manually removed them from landrush.\n. bash\nmkdir tmp\ncd tmp\ngit clone git@github.com:roots/trellis.git\ngit clone git@github.com:roots/bedrock.git site\ncd trellis\nansible-galaxy install -r requirements.yml\nvagrant up\ncat ../site/.env\ngives the following in .env\nWP_ENV=development\nDB_USER=example_dbuser\nDB_PASSWORD=example_dbpassword\nWP_SITEURL=http://example.dev/wp\nDB_NAME=example_dev\nWP_HOME=http://example.dev\n\nbash\nsed -i -e 's/example\\.dev/myexample.dev/g' group_vars/development\nvagrant provision\ncat ../site/.env\ngives the following in .env\nWP_ENV=development\nDB_USER=example_dbuser\nDB_PASSWORD=example_dbpassword\nWP_SITEURL=http://example.dev/wp\nDB_NAME=example_dev\nWP_HOME=http://example.dev\n\nuhoh! Not working! Let's try @fullyint's\nbash\ngit reset --hard\ngit pull https://github.com/fullyint/bedrock-ansible.git env\nsed -i -e 's/example\\.dev/myexample.dev/g' group_vars/development\nvagrant provision\ncat ../site/.env\nthis gives the following in .env\nWP_ENV=development\nDB_USER=example_dbuser\nDB_PASSWORD=example_dbpassword\nWP_SITEURL=http://example.dev/wp\nDB_NAME=example_dev\nWP_HOME=http://example.dev\nNot working :(\nTASK: [wordpress-install | Copy .env file into web root] **********************\nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'admin_user': 'admin', 'local_path': '../site', 'system_cron': True, 'cache': {'duration': '30s', 'enabled': False}, 'repo': 'git@github.com:roots/bedrock.git', 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'Example Site', 'admin_password': 'admin', 'env': {'db_name': 'example_dev', 'wp_env': 'development', 'db_user': 'example_dbuser', 'db_password': 'example_dbpassword', 'wp_home': 'http://myexample.dev', 'wp_siteurl': 'http://myexample.dev/wp'}, 'site_hosts': ['myexample.dev'], 'admin_email': 'admin@myexample.dev'}})\n\nMaybe it was some sort of weird thing relating to before your patch? Let's change the env vars again.\nbash\nsed -i -e 's/myexample\\.dev/mycoolexample.dev/g' group_vars/development\nvagrant provision\n```\nTASK: [wordpress-install | Create .env file] ******\nchanged: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'admin_user': 'admin', 'local_path': '../site', 'system_cron': True, 'cache': {'duration': '30s', 'enabled': False}, 'repo': 'git@github.com:roots/bedrock.git', 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'Example Site', 'admin_password': 'admin', 'env': {'db_name': 'example_dev', 'wp_env': 'development', 'db_user': 'example_dbuser', 'db_password': 'example_dbpassword', 'wp_home': 'http://mycoolexample.dev', 'wp_siteurl': 'http://mycoolexample.dev/wp'}, 'site_hosts': ['mycoolexample.dev'], 'admin_email': 'admin@mycoolexample.dev'}})\nTASK: [wordpress-install | Copy .env file into web root] ****\nchanged: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'admin_user': 'admin', 'local_path': '../site', 'system_cron': True, 'cache': {'duration': '30s', 'enabled': False}, 'repo': 'git@github.com:roots/bedrock.git', 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'Example Site', 'admin_password': 'admin', 'env': {'db_name': 'example_dev', 'wp_env': 'development', 'db_user': 'example_dbuser', 'db_password': 'example_dbpassword', 'wp_home': 'http://mycoolexample.dev', 'wp_siteurl': 'http://mycoolexample.dev/wp'}, 'site_hosts': ['mycoolexample.dev'], 'admin_email': 'admin@mycoolexample.dev'}})\n```\nOh okay!\nWP_ENV=development\nDB_USER=example_dbuser\nDB_PASSWORD=example_dbpassword\nWP_SITEURL=http://mycoolexample.dev/wp\nDB_NAME=example_dev\nWP_HOME=http://mycoolexample.dev\nNeat! It works. \nSo it looks like ansible doesn't look at the content of the file but instead looks at when the actual ansible variable file was changed?\n\nLet's experiment for science\n``` bash\npwd\n=> /Users/austinpray/Desktop/tmp/trellis\nsed -i -e 's/mycoolexample.dev/uhohbogus.dev/g' ../site/.env\n```\nSo now our group vars are out of sync with the actual contents of the files.\nThe .env file:\nWP_ENV=development\nDB_USER=example_dbuser\nDB_PASSWORD=example_dbpassword\nWP_SITEURL=http://uhohbogus.dev/wp\nDB_NAME=example_dev\nWP_HOME=http://uhohbogus.dev\nThe group vars:\nenv:\n      wp_home: http://mycoolexample.dev\n      wp_siteurl: http://mycoolexample.dev/wp\n      wp_env: development\n      db_name: example_dev\n      db_user: example_dbuser\n      db_password: example_dbpassword\nLet's see what happens. \n```\nTASK: [wordpress-install | Create .env file] ******\nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'admin_user': 'admin', 'local_path': '../site', 'system_cron': True, 'cache': {'duration': '30s', 'enabled': False}, 'repo': 'git@github.com:roots/bedrock.git', 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'Example Site', 'admin_password': 'admin', 'env': {'db_name': 'example_dev', 'wp_env': 'development', 'db_user': 'example_dbuser', 'db_password': 'example_dbpassword', 'wp_home': 'http://mycoolexample.dev', 'wp_siteurl': 'http://mycoolexample.dev/wp'}, 'site_hosts': ['mycoolexample.dev'], 'admin_email': 'admin@mycoolexample.dev'}})\nTASK: [wordpress-install | Copy .env file into web root] ****\nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'admin_user': 'admin', 'local_path': '../site', 'system_cron': True, 'cache': {'duration': '30s', 'enabled': False}, 'repo': 'git@github.com:roots/bedrock.git', 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'Example Site', 'admin_password': 'admin', 'env': {'db_name': 'example_dev', 'wp_env': 'development', 'db_user': 'example_dbuser', 'db_password': 'example_dbpassword', 'wp_home': 'http://mycoolexample.dev', 'wp_siteurl': 'http://mycoolexample.dev/wp'}, 'site_hosts': ['mycoolexample.dev'], 'admin_email': 'admin@mycoolexample.dev'}})\n```\nUhoh! It's not reading the actual file to see the state! It only watches the variables! I'm not sure this matters but this sure is interesting. This PR solves the problem but I really would be interested to see if there was a solution that actually checked the contents of the .env file for parity.\n. :100: \n. baller\n. \ud83d\ude0e\ud83c\udf49\u2728\n. @louim yep that's in the pipe\n. Testing: \n``` bash\ncreate do droplet then set ip to variable\nexport $DO_IP=xx.xx.xx.xxx\n```\n``` bash\ngit checkout -b fullyint-merge-secure-root master\ngit pull https://github.com/fullyint/trellis.git merge-secure-root\nsed -i 's/sshd_permit_root_login: \"yes\"/sshd_permit_root_login: \"no\"/g' group_vars/all\nsed -i \"s/192.168.50.5/$DO_IP/g\" hosts/staging\nansible-playbook -i hosts/staging server.yml\nsuccess\n./deploy.sh staging example.com\nsuccess\nssh root@$DO_IP\nPermission denied (publickey).\nssh web@$DO_IP\nWelcome to Ubuntu 14.04.2 LTS (GNU/Linux 3.13.0-52-generic x86_64)\n```\nCool beans\n. @fullyint maybe I am misunderstanding, but if root is disabled shouldn't it never try to connect as root ever?\n. FWIW some of the only problems I've had setting people up with ansible deploys has been improperly configured SSH evironments. People not having their key added to their agent etc. Not trellis' fault, but still good to have that stuff documented. \n. Ah you know what? I was running into this yesterday. Will give this a try. \n. Works beautifully. We had this in our previous deploy strategy: https://github.com/roots/bedrock-capistrano/blob/b4893fda905728602356e287164569aca4815a84/config/deploy.rb#L37-L56 so it's good to have it again!\n. Ok let's do it with @louim's command and call it \"self-signed\"\n. > I would make it so that when you turn ssl on in the config bit don't pass a cert / key option, the snake-oil is used.\n:+1: That would be completely badass.  \n\nI'll do it manually with openssl.\n\nIs it possible to leave out all this stuff: /C=CA/ST=Quebec/L=Quebec/O=O2?\n. Great job @louim!\n. > I think it's more to help debug the https problems in the code like assets being loaded on http or other commons problems than to provide real security (because the certs are self-signed anyway).\nI risk being pedantic here but this only half correct. A self-signed cert will absolutely provide increased security, just not trust. For instance: say you have a staging server with a self-signed cert. If you try and login to that site in a coffee shop with people snooping the traffic: they will not be able to see your traffic. \nThe crypto is exactly the same as a CA cert. However the chain of trust is not there. But since it's only for development and staging servers, you and your team can just know to trust it.\n. In casual testing locally:\n```\nset ssl enabled: true\nvagrant destroy -f\nvagant up\n```\nYields: \n```\nTASK: [wordpress-setup | Get existing self-signed certificates] **\nfailed: [default] => {\"changed\": false, \"cmd\": \"ls _self_signed.pem\", \"delta\": \"0:00:00.003916\", \"end\": \"2015-07-21 04:55:12.301727\", \"rc\": 2, \"start\": \"2015-07-21 04:55:12.297811\", \"stdout_lines\": [], \"warnings\": []}\nstderr: ls: cannot access *_self_signed.pem: No such file or directory\nFATAL: all hosts have already failed -- aborting\n```\nPerhaps we have to ensure the /etc/nginx/ssl/ directory exists before we make the check.\nEdit: my bad the ssl directory exists but ls *_self_signed.pem throws errors.\n\nFixed the ls issue and now running into this:\n```\nTASK: [wordpress-setup | Get existing self-signed certificates] ***\nok: [default]\nTASK: [wordpress-setup | Get self-signed certificates domains] ****\nskipping: [default]\nTASK: [wordpress-setup | Generate self-signed certificates] ***\nfatal: [default] => error while evaluating conditional: item.value.ssl.enabled and item.value.site_hosts | first not in self_signed_domains.results | map(attribute='stdout') | list\n```\nMy branch is over here: https://github.com/austinpray/bedrock-ansible/tree/louim-add-snake-oil-certs\nhttps://github.com/austinpray/bedrock-ansible/commit/c5a65509053c00ebf4c8da75ed26fe102bfca253\n. Tested and this works great for vagrant! I tried provisioning a staging instance with it and chrome would not let me visit it at all:\n\nNo option to bypass the message.\nI'm not super heartbroken about this due to the fact that https://letsencrypt.org/ is so close. We can just get a legit certificate for staging and non-production environments here in september.\n\nOn June 16, 2015, the final launch schedule for the service was announced, with the first certificate expected to be issued sometime in the week of July 27, 2015, followed by a limited issuance period to test security and scalability. General availability of the service is expected to begin sometime in the week of September 14, 2015, provided everything goes as planned.\n\nhttps://letsencrypt.org/2015/06/16/lets-encrypt-launch-schedule.html\nSo should we add a note about self-signed being only for development? We could also provide instructions on how to add the snakeoil cert to your trusted certificates but this might be too much trouble.\n. Ah you know what? That was it. If I try it with austinpray.com it works fine.\n. :+1: This is great. Glad 1.9.2 is finally out as well.\n. Will test this soon.\nTest cases I can think of off the top of my head:\n- [ ] Fresh subdomain multisite\n- [ ] Fresh subdirectory multisite\n- [ ] Subdomain export database, vagrant destroy, vagrant up with imported database\n- [ ] Subdirectory export database, vagrant destroy, vagrant up with imported database\n- [ ] Deploy subdomain to remote DO\n- [ ] Deploy subdirectory to remote DO\nWhat other edgecases would there be?\n. Rebased and fixed up over here https://github.com/roots/trellis/pull/319\n. Can you guys create an issue with some info on how to reproduce?\n. Haven't run into this, on what kind of setup does this occur for you?\n. It looks like this is pretty easy to include as a drop-in solution. I don't really see much benefit in rolling this into stock trellis. \nI would much rather have a trellis supported wiki entry about this than being on the hook for maintaining the actual code.\n. I don't have any problems with adding a section about application specific configs over on the wiki.\n. > Not sure what the best course of action here is. This seems like it should be affecting more people than just me. Or does everyone still have ~/.ssh/id_rsa.pub so they never run into this?\nPretty much everyone I have ever worked with and set up on trellis for followed this guide and copypasta'd the heck out of the commands. Also ssh-keygen defaults to id_rsa as well.\nThat said: I do agree this is an issue. Basically the only way the ssh keys will work in the current implementation in a large team, many maintainers situation:\n1. All the maintainers have an id_rsa\n2. All the maintainers have a github account with their keys configured\n3. You add the list of public keys to a file in the repo\n4. You maintain a list of public keys on your own server exposed via http\nYou should definitely technically be able to do:\n- \"{{ lookup('file', '~/.ssh/id_rsa.pub') | default(omit) }}\"\n- \"{{ lookup('file', '~/.ssh/special_snowflake.pub') | default(omit) }}\"\nBut won't this lead to a tug of war? Every time each individual maintainer provisions a server the other maintainers will lose access right?\nFor complicated situations like this adding a list of public keys to the repo sounds pretty ideal actually.\nRelated https://github.com/roots/trellis/issues/294\n. Also getting weird stuff like\n```\nThere was an error loading a Vagrantfile. The file being loaded\nand the error message are shown below. This is usually caused by\na syntax error.\nPath: /Users/austinpray/DEV/roots.io/Vagrantfile\nLine number: 11\nMessage: RuntimeError: group_vars/development file not found. Please set ANSIBLE_PATH in Vagrantfile\n. yaml\ncache:\n  enabled: true\n  provider: redis\n```\n@swalkinshaw-- for bad naming\n. On a couple installs:\n- 3508\n- 5425\n- 28391\n- 26684\n64KB looks about right\n. Lol @qwp6t\n. :shipit: :shipit: My body is ready, let's get this show on the road :shipit: :shipit: \n. @BrandonShutter yes\n. @cibulka @swalkinshaw correction: Don't use trellis for remote deployments. I don't see a problem with using Trellis for your local environment with vagrant.\n. ## Sentences\n\nTrellis is an end-to-end solution for WordPress environment management. Easily create development environments, automate the configuration of high-performance production servers, and deploy your sites.\n\nBulleted\n\nTrellis is an end-to-end solution for WordPress environment management. \n- Reproducible development environments with Vagrant\n- Automate the configuration of high-performance production servers\n- Automate the deployment process for your WordPress sites\n. \n. Going to try this out tonight\n. This fails for me:\n\n```\nPLAY [Prepare Ansible SSH Config] *********\nTASK: [ansible-ssh | Remove prior ssh config info] ****\nok: [vagrant-vm -> 127.0.0.1]\nTASK: [ansible-ssh | Gather ssh config info for Vagrant VM] ***\nok: [vagrant-vm -> 127.0.0.1]\nTASK: [ansible-ssh | Gather user-specified ssh config files] ******\nok: [vagrant-vm -> 127.0.0.1] => (item=~/.ssh/config)\nTASK: [ansible-ssh | Update ssh config file] ******\nfailed: [vagrant-vm -> 127.0.0.1] => {\"changed\": false, \"cmd\": [\"rsync\", \"-acv\", \"/tmp/ansible-ssh-config\", \"roles/ansible-ssh/files/config\"], \"delta\": \"0:00:00.031313\", \"end\": \"2015-08-27 20:57:59.052043\", \"rc\": 12, \"start\": \"2015-08-27 20:57:59.020730\", \"stdout_lines\": [\"building file list ... done\"], \"warnings\": [\"Consider using synchronize module rather than running rsync\"]}\nstderr: rsync: push_dir#3 \"/Users/austinpray/Desktop/trellis/roles/ansible-ssh/files\" failed: No such file or directory (2)\nrsync error: errors selecting input/output files, dirs (code 3) at /SourceCache/rsync/rsync-45/rsync/main.c(580) [receiver=2.6.9]\nrsync: connection unexpectedly closed (8 bytes received so far) [sender]\nrsync error: error in rsync protocol data stream (code 12) at /SourceCache/rsync/rsync-45/rsync/io.c(453) [sender=2.6.9]\nstdout: building file list ... done\nPLAY [WordPress Server - Install LEMP Stack with PHP 5.6 and MariaDB MySQL] ***\nGATHERING FACTS *********\nFATAL: no hosts matched or all hosts have already failed -- aborting\nTASK: [common | Validate Ansible version] *******\nFATAL: no hosts matched or all hosts have already failed -- aborting\nPLAY RECAP **********\n           to retry, use: --limit @/Users/austinpray/dev.retry\nvagrant-vm                 : ok=3    changed=0    unreachable=0    failed=1\nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\n```\nTree of the ansible-ssh directory:\n```\nroles/ansible-ssh\n\u2514\u2500\u2500 tasks\n    \u2514\u2500\u2500 main.yml\n1 directory, 1 file\n. diff\ndiff --git a/roles/ansible-ssh/tasks/main.yml b/roles/ansible-ssh/tasks/main.yml\nindex bd5d04e..8768674 100644\n--- a/roles/ansible-ssh/tasks/main.yml\n+++ b/roles/ansible-ssh/tasks/main.yml\n@@ -3,6 +3,10 @@\n   local_action: file path=/tmp/ansible-ssh-config state=absent\n   changed_when: false\n+- name: Ensure ansible-ssh/files exists \n+  local_action: file path=roles/ansible-ssh/files/config state=directory\n+  changed_when: false\n+\n - name: Gather ssh config info for Vagrant VM\n   local_action: shell vagrant ssh-config --host {{ inventory_hostname }} >> /tmp/ansible-ssh-config\n   when: \"'development' in group_names\"\n```\nWorks for me\n. > We don't have to rename the VM but it might be nice to have the names be consistent. Changing the name is a breaking change of sorts, but it seems better to do it now, while pre v1.0.\nI'm good with this, vagrant-vm makes much more sense as to what the name is actually for. default is incredibly cryptic.\nAlso more errors:\n\nThis is after vagrant destroy -f && vagrant up. Investigating.\n. \npls fix asap tyvm\nedit: this server tracks bleeding edge trellis\n. @louim yep. That fixes it.\nhttps://codex.wordpress.org/Nginx#URL_Rewrites_.2F_Permalinks\nSo the question is: do we care?\n. I agree with the approach @mxxcon suggests. You should not have to look at two files to get the full picture.\n. @alan-c was the one who made this commit. I just squashed it for him\n. Tested and working for provisioning a remote server and for Vagrant\n. https://www.owasp.org/index.php/List_of_useful_HTTP_headers and http://blogs.msdn.com/b/ie/archive/2008/07/02/ie8-security-part-iv-the-xss-filter.aspx\n\nThis header enables the Cross-site scripting (XSS) filter built into most recent web browsers. It's usually enabled by default anyway, so the role of this header is to re-enable the filter for this particular website if it was disabled by the user. This header is supported in IE 8+, and in Chrome (not sure which versions). The anti-XSS filter was added in Chrome 4. Its unknown if that version honored this header.\n\nSo we don't need to specify X-Xss-Protection\n. I'll look into it\n. > Internet Explorer will display a dialog box if reflective XSS was detected and sanitized or blocked. Chrome will hide the output of the reflective XSS attack in the response when it is set to 1. When it is set to 1; mode=block, Chrome will redirect the user-agent to an empty data:, URL. sauce\nSo it looks like the default for chrome is to sanitize and not to block. It only enables the blocking when the header is parsed:\nhttps://code.google.com/p/chromium/codesearch#chromium/src/third_party/WebKit/Source/platform/network/HTTPParsers.cpp&cl=GROK&rcl=1440948402&l=420\n\nhttps://code.google.com/p/chromium/codesearch#chromium/src/third_party/WebKit/Source/core/html/parser/XSSAuditor.cpp&cl=GROK&l=415&ct=xref_jump_to_def&gsn=didBlockEntirePage\n\n\"If the mode is set to block and a script contained bad stuff: render a console error and return an empty page to the browser\"\n. Added a note about this to https://github.com/roots/trellis/wiki/Multisite so it's 100% clear.\n. git-subtree uses \"prefix\" instead of \"path\".\nWhat about dropping \"subtree\" entirely and making it something more intuitive?\n. Wanna add VMware fusion while we are at it? I have a license I can test with. \n. @ckovey I see! I'll test it tomorrow then\n. Something isn't right:\n\nThe virtualbox provider should be using ubuntu/trusty64 right? \n. @erikbelusic this looks like it needs to be fixed in the upstream. I'm guessing we need to add -k for all self-signed cert users. I don't think you are the only person to be susceptible to this bug.\nedit: or we could add the self-signed cert to the machine's root CAs.\n. I'd prefer to keep curl. php-cli scripts do not timeout. So if WordPress or a plugin does something horrible you can possibly get stuck with a hung process. Also curl runs the code through fpm.\n. Couple things here:\n1. I don't like that we are disabling the max request size. Perhaps a more seasoned sysadmin can chime in, but as far as I know this opens you up to low effort DDOS attacks. \n2. Maybe you could accomplish this for your site by using https://github.com/roots/trellis/blob/57e9d3902ffeb708a7264df228d21dfa140becba/roles/wordpress-setup/tasks/nginx.yml#L19-L24 and create a site-specific conf? That would be the \"correct\" solution. \nI would definitely recommend making the client_max_body_size configurable by the user via a variable such as nginx_client_max_body_size. For those php files it should equal the PHP max upload size.\n. Yeah I'm fine with this compromise. This should actually be better than what we had before where we totally disabled the check. @louim @fullyint any objections?\n. @louim yep it appears to be working. Here is a DO instance that I just provisioned with this PR to test: ssh root@159.203.71.235\n. Out of the box \n```\nAnsible managed: /Users/austinpray/Desktop/trellis/roles/nginx/templates/wordpress.conf.j2 modified on 2015-09-24 19:05:56 by austinpray on AustinMacbookPro\nPrevent PHP scripts from being executed inside the uploads folder.\nlocation ~ /app/uploads/..php$ {\n  deny all;\n}\nlocation / {\n  try_files $uri $uri/ /index.php?$args;\n}\nSet the max body size equal to PHP's max POST size.\nclient_max_body_size 25m;\ninclude h5bp/directive-only/x-ua-compatible.conf;\ninclude h5bp/location/cross-domain-fonts.conf;\ninclude h5bp/location/protect-system-files.conf;\n```\nBumping up to 100M\n```\nAnsible managed: /Users/austinpray/Desktop/trellis/roles/nginx/templates/wordpress.conf.j2 modified on 2015-09-24 19:05:56 by austinpray on AustinMacbookPro\nPrevent PHP scripts from being executed inside the uploads folder.\nlocation ~ /app/uploads/..php$ {\n  deny all;\n}\nlocation / {\n  try_files $uri $uri/ /index.php?$args;\n}\nSet the max body size equal to PHP's max POST size.\nclient_max_body_size 100m;\ninclude h5bp/directive-only/x-ua-compatible.conf;\ninclude h5bp/location/cross-domain-fonts.conf;\ninclude h5bp/location/protect-system-files.conf;\n```\nlooks like it's working!\n. Haven't run into this but maybe I didn't test rigorously enough. I'll check this out. \n. Always turn this on as well. Dunno how one would do dev without it. \n. @nathanielks suggested \"just check for the existence of a vendor directory\". I say :+1: to that technique.\n. Thank you for this. Looks like this was introduced in https://github.com/kulturavashchi/trellis/commit/6088df50056fa5a2b6ca1f61a54bee4212f6fb0d\n. Do'oh! Sorry Windows folks!\n@louim yeah that's the simplest fix. Windows folks have their stuff installed for them automatically anyway, so yeah no sense in checking.\n@EinArzt delete these lines for now: https://github.com/roots/trellis/blob/6905e128d07a20690e777f33b0ba4a621ccc0acf/Vagrantfile#L24-L26 so you can be up and running.\n. You could PR Scott's branch and it would apply your change to his code\n. You can also PR people's forks \ud83d\ude0e\n. @mss thank you so much for your detailed issue!\nMy possible solution:\n1. Drop the regex. Simply do make sure this line exists in the file: PATH=$PATH:/path/to/bin\n2. Explicitly declare the full path to the vendor bin directory. Instead of ./vendor/bin do /srv/www/example.com/current/vendor/bin.\nWould that be enough?\n. To clarify: the solution was to do 1 and 2 in sequence. So Drop the regex and declare the full path. \n\nwould probably be a bit complicated with multiple installations on a single machine\n\nYeah you are definitely right here. I have no clue how this would work if you had two different sites running on a box with two different versions of composer and such.\nPerhaps we should just remove this feature. I don't see it being used anywhere in the codebase. @louim why did you put this here in the first place?\n. Only enabling in development as a convenience method is a good compromise. \nSo:\n1. Drop the regex. Simply do make sure this line exists in the file: PATH=$PATH:./vendor/bin\n3. Only enable in development\nThe only gripe would be that this might cause scripts that work on development not work on production. Is there any easy way we can warn the user if they are relying on this development-only behavior? Should we even worry about it? The person isn't supposed to be SSHing into production anyway.\n. Yep so let's enable this for development only and simplify the regex to a lineinfile for PATH=$PATH:./vendor/bin.\n. This is sick\n. I would just disable the system cron:\n\nhttps://github.com/roots/trellis/blob/124dbc7252951cb21b3415380ff87cf0b891ba5d/README.md#wordpress-sites\n. If you have multiple people provisioning a box or you provision a box from two different locations, does it remove the old entries? I will test but if anyone can get to it faster than me go ahead.\n. I'm okay with each deployment overwriting the IP addresses as long as it doesn't leak ips such that every single place you have ever provisioned from (or every person who has ever provisioned) is whitelisted.\n. @louim if you need to refresh your settings you might need to set max_age to 0 temporarily\n\nWhenever the Strict-Transport-Security header is delivered to the browser, it will update the expiration time for that site, so sites can refresh this information and prevent the timeout from expiring. Should it be necessary to disable Strict Transport Security, setting the max-age to 0 (over a https connection) will immediately expire the Strict-Transport-Security header, allowing access via http.\n\nhttps://developer.mozilla.org/en-US/docs/Web/Security/HTTP_strict_transport_security\nAlso, mind as well keep them configurable since these are potentially site-breaking options\n. @roots/trellis-contributors gimme a couple extra go-aheads and I'll merge.\n. Probably just use nightly everywhere, right? I test my scripts on development and then promote them to production. I don't want my script failing due to it relying on nightly behavior when production has an earlier release.\n. Oh shoot. Ben is totally right.\n. Gonna spin it up in Intellij to make sure xdebug is good to go\n. xdebug works \n\n. @coderholic what's the HTTPS situation? It looks like HTTPS works for free users but on the website it says that you have to pay for HTTPS.\n. https://ipinfo.io/ip Seems to work fine, however \n. Yeah I've already fixed this I'll PR soon. \nInstead of current I just have it do\nmv {{ deploy_path }} {{ deploy_path }}-temp\nmv {{ deploy_path }}-temp/{{ subtree }} {{ deploy_path }}\nrm -rf {{ deploy_path }}-temp\n. @QWp6t is way ahead of you! We've been waiting for this. We should go ahead and use it on all platforms.\n. I haven't looked into it, but does using the ansible_local provisioner preclude one from running the server.yml playbook against hosts/development?\nI'm confused as to what we are losing if we switch to ansible_local for all platforms. \n. I disagree that it is making things more confusing for remote servers. The user needs to figure out how to install Ansible and run it locally at some point. Installing the dependencies is not the hurdle, it's understanding the ansible-playbook command and configuring the environment group_vars.\n1. We all agreed that we recommend Trellis even for people that are just using it for local development. Why not make it extremely easy for these people to get up and running? These people can \"graduate\" to provisioning remote servers once they are delighted with how easy it was to get up and running with Trellis locally.\n2. Teams are made up of people with differing roles. On any given team I'm assuming that the amount of devops people is smaller than the people working on themes/plugins locally day-to-day. These day-to-day front-end developers and such never run the ansible-playbook command, so why do they need ansible installed on the host? Deploys should be happening from a central deployment server in a team environment anyway.\n@joshrickert only the initial provisioning time will take a long time. If you are making config changes and testing locally you should be running ansible-playbook -i hosts/development server.yml --tags \"whatever,you,changed\". \n. Using this exact same config in other projects with success :+1: \nAs long as @coderholic says he's not gonna pull the plug on free HTTPS I'm good to go with this\n. What version of the Ubuntu vagrant box are you on?\n. Doesn't the fixed IP have to be there for hostsupdater to work?\n. Making issues like this should be against the law.\n. @reverbsoul I edited the original post and made a madlibs for you. Seems it's an upstream issue though\n. Not really enough information here to reproduce. Try and get it sorted over on http://discourse.roots.io. If we can reproduce the issue there then we will log it here as a bug.\n. This bit strips off www so it is doing what you are describing. \nLet's get more opinions on this being included by default. For my purposes (and most people who just want to follow the readme instructions and be done with it) This functionality is going to be used pretty much every time. I will go ahead and add a toggle though. \n. Yeah I agree. I don't think this will change over on h5bp often enough to benefit from being pulled directly from git. \n. I'll remove it \n. ( \u0361\u00b0 \u035c\u0296 \u0361\u00b0) \n. 1 before and after\u2014\nSent from my iPhone\nOn Wed, Sep 3, 2014 at 4:09 PM, Scott Walkinshaw notifications@github.com\nwrote:\n\n\n+error_reporting = {{ php_error_reporting }}\n+display_errors = {{ php_display_errors }}\n+display_startup_errors = {{ php_display_startup_errors }}\n+track_errors = {{ php_track_errors }}\n+\n+[mysqlnd]\n+mysqlnd.collect_memory_statistics = {{ php_mysqlnd_collect_memory_statistics }}\n+\n+[opcache]\n+opcache.enable={{ opcache_enable }}\n+opcache.enable_cli={{ opcache_enable_cli }}\n+opcache.memory_consumption={{ opcache_memory_consumption }}\n+opcache.interned_strings_buffer={{ opcache_interned_strings_buffer }}\n+opcache.max_accelerated_files={{ opcache_max_accelerated_files }}\n+opcache.revalidate_freq={{ opcache_revalidate_freq }}\n+opcache.fast_shutdown={{ opcache_fast_shutdown }}\nCan we be consistent with formatting? Either no spaces around = or 1 before and after.\nReply to this email directly or view it on GitHub:\nhttps://github.com/roots/bedrock-ansible/pull/44/files#r17080308\n. maybe I'm nitpicking here but wouldn't it be more clear to just call it wordpress_sites instead of wp_sites? Just keep the same name as what is in the config file?\n. it would make sense to grab this from group_vars as well. The advantage being keeping 100% of the config vars in a separate file so updating the vagrant file is easier.\n. This too, this could easily be set from the group_vars file. Even if it's just a property just like 'local_path' keeping hardcoded values out of the vagrantfile is a goodthing.\n. \"Vagrant is set up to automatically read group_vars/development and created a synced folder for each of the sites.\"\n\n\n\"Vagrant automatically reads group_vars/development and creates a synced folder for each of the sites.\"\n. They had some hickups: https://status.digitalocean.com/\nDef change it back though.\n. I think your logic is backwards. The caching methods should be a whitelist\n. In other words: you should only be caching GET calls. \n. I don't like hardcoding all these values. Just add a line that is like PATH=\"$PATH:./vendor/bin\"\n. Don't agree with this. The wording is pretty clunky.\nRun ansible-galaxy install -r requirements.yml inside your Trellis directory to install external Ansible roles/packages.\n. I don't agree with \"for better\". Either keep as-is or change entirely:\nTrellis is a set of Ansible playbooks for creating and deploying WordPress server environments. Use Trellis to create local development environments with Vagrant as well as robust production and staging environments on remote servers.\nOr something close to that.\n. > development, staging, and production; in YAML format\nThe semicolon is not needed here\n. > For example, to configure the sites on your Vagrant development VM, edit group_vars/development.\nFor example needs a colon instead of comma\nFor example: configure the sites on your Vagrant development VM by editing group_vars/development.\n. > For each WordPress site, the wordpress_sites dictionary defines the variables below.\nReally confusing sentence. The original was better here.\n. :+1: \n. > You can also auto-generate self-signed certificates for development purpose.\nTrellis will also auto-generate self-signed certificates for development purposes.\n. should this be {{ mysql_root_user }} ?\n. :sunglasses: @fullyint @louim do you see any better way to do this? I came up with this under pressure and obviously it looks kinda dirty.\n. Add a comment with a link to https://rtcamp.com/tutorials/nginx/tweaking-fastcgi-buffers/ ?\n. > they should add their the subdomain wildcard version to the list of site_hosts\nThis causes catastrophic failure with landrush on development. Dunno why though. \n. While we are at it: \n\"Your version of this repo (renamed to just trellis)\" :arrow_right: \"Your clone of this repo\"\n. The reason why I did the manual \"; \" prefix is because I was trying to follow the format:\n\nhttps://developer.mozilla.org/en-US/docs/Web/Security/HTTP_strict_transport_security#Enabling_Strict_Transport_Security\nOther formatting examples\nhttps://tools.ietf.org/html/draft-hodges-strict-transport-sec-02#page-14\nhttps://www.owasp.org/index.php/HTTP_Strict_Transport_Security\n. results in add_header Strict-Transport-Security \"max-age=31536000; includeSubdomains; preload\";\n. I would actually list out the things we ask for here like \nAnsible version: X\nOS: X\nVagrant Version: X\n. ",
    "fullyint": "Hopefully I'm not making a newbie mistake. I believe it's a full wp db. I see the DROP TABLE IF EXISTS for every table in the sql file. My steps to produce the problem: \n1. I created the sql file by running a vanilla 'vagrant up' (without db_import in group_vars/all). Then I changed a couple words in a post and exported all tables with what appeared to be the default sequel-pro sql dump. \n2. I did a 'vagrant destroy' and cleaned out any dependencies installed by Composer (e.g., removed files from web/app/wp).\n3. I put the sql dump file path in db_import in group_vars/all and did a 'vagrant up'. The db is successfully copied into /tmp and later imported, but after that the 'Install WP' play shows that it has skipped. \nWhen my site didn't load, I assumed the problem was that ansible skipped the 'wp core install', as shown in the log. My best guess was that 'wp core is-installed' somehow saw the full (imported) wp db and interpreted its presence to mean wp was already installed. So, my pull request shifts the import to happen after the 'wp core is-installed' check.\nDo the steps above not reproduce the problem on your end? Maybe there is a problem somehow with how I left db names the same throughout the process (haven't tested changing db names).\n. Unintended use cases. Benefits via side-effects. Thanks for your patience with the circus. :smile: \nLet me know what actions to take on this, if any.\n. I should have posted this on roots discourse as a feedback request instead of here as a pull request. Sorry. I wasn't familiar with ssh forwarding, which indeed looks far simpler. I'm that new.\nI guess this PR should be closed. No obligation to respond to anything below, of course. You've given me plenty to go study. I'm grateful for your time in giving a thoughtful reply, and for your incredible work with roots projects.  \n\nYour feedback bullets 1 and 5 look great, improving the var setup I had proposed.\nTrying to understand your feedback bullet 3, I'm guessing the problem with relative paths (with ~) is that despite how I've so far had only a single user vagrant (the default), we actually need to accommodate other users such as deploy for Capistrano (I haven't added Capistrano to my workflow yet). So I suspect that each user's home dir must have an ssh key, whereas my relative paths uploaded a key for only the vagrant user. If this was in fact my misunderstanding, that would account for bullet 2, why I didn't use wordpress_sites for flushing. I assumed only the known_hosts for the vagrant user needed to be flushed, achievable with a relative path, and with no need for item.user.\nThat leaves bullet 4. You guessed it, I don't quite understand. If in group_vars/all run_composer: false, I'm not aware of any need for deploy keys, known_hosts files, etc., at least not for the initial vagrant up. Maybe the keys/hosts are used for Capistrano later. I used wordpress_sites.0.run_composer as the only way I could find to check the value of run_composer in group_vars/all. Maybe my lack of understanding is that my perspective is limited to only having run this playbook with a single site at a time (e.g., one bedrock-ansible repo per client site), whereas you mentioned the possibility of \"another site other than the first.\" Or maybe my problem is with how I'm a ruby/jinja/yaml newbie. \n. Thank you for this explanation. It clears things up for me. \nThe README clearly mentions the scenario of multiple sites, but I failed to consider some obvious implications...\n- relative paths could be problematic\n- wordpress_sites array could contain more than one site\n- having multiple users may require multiple ssh keys\n- etc.\nI regret that I was overeager in submitting the PR.\nYou've been generous.\n. @intelligence If you haven't done it already, you could get more info by running VAGRANT_LOG=info vagrant up or VAGRANT_LOG=debug vagrant up then search for SSH auth method: private key.\nAlso, although it probably won't solve your SSH trouble, see #96. Your Vagrantfile at SO shows bedrock_path = '../bedrock'. I think you'll need to rename your bedrock folder to a hostname like example.dev and change bedrock_path = '../example.dev' for provisioning to succeed (after you resolve the SSH problem above).\n. I think that should work, so long as you set site_name: zahnarzt-altena.de in the group_vars/development file (see how site_name is used in places like roles/wordpress-sites/tasks/directories.yml and elsewhere).\nAlternatively, you could just leave bedrock_path_server as the new default introduced in #97 since the time of my last comment (bedrock_path_server = File.join('/srv/www', config.vm.hostname, 'current')). However, I'm realizing now that this default requires site_name (in group_vars/development) and config.vm.hostname (in Vagrantfile) to have the same value (e.g., zahnarzt-altena.dev in your case).\n. I'm not that familiar with SSH matters, but here's what comes to mind. \n1) You asked:\n\nauthorized_keys in guest should have the content of id_rsa.pub on the host?\n\nVagrant's key pair. I'm pretty sure authorized_keys in the vm just needs the vagrant insecure public key, not the host's id_rsa.pub. When you vagrant ssh in to the vm, then run less /home/vagrant/.ssh/authorized_keys, I think you should see the same key as https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub. If you don't see that key, I don't know how vagrant ssh would even work. But anyway, here are ideas for missing public key.\n2) Have you run VAGRANT_LOG=debug vagrant up yet? I'm guessing you'll find the most relevant portion of the resulting log by searching for the final instance of beginning authentication ofvagrant'and inspect the next 20-odd lines, probably ending withall authorization methods failed (tried none, publickey, password)`. Consider sharing it here and maybe someone will make sense of it.\nHere's my log after SSH auth fails due to an intentionally corrupted insecure_private_key:\n```\nLOG: When SSH Auth Fails (due to corrupted insecure_private_key)...\n...\nD, [date] DEBUG -- net.ssh.authentication.session[806c98fc]: beginning authentication of vagrant'\nD, [date] DEBUG -- tcpsocket[80acc9cc]: queueing packet nr 4 type 5 len 28\nD, [date] DEBUG -- tcpsocket[80acc9cc]: sent 52 bytes\nD, [date] DEBUG -- tcpsocket[80acc9cc]: read 52 bytes\nD, [date] DEBUG -- tcpsocket[80acc9cc]: received packet nr 4 type 6 len 28\nD, [date] DEBUG -- net.ssh.authentication.session[806c98fc]: trying none\nD, [date] DEBUG -- tcpsocket[80acc9cc]: queueing packet nr 5 type 50 len 44\nD, [date] DEBUG -- tcpsocket[80acc9cc]: sent 68 bytes\nD, [date] DEBUG -- tcpsocket[80acc9cc]: read 68 bytes\nD, [date] DEBUG -- tcpsocket[80acc9cc]: received packet nr 5 type 51 len 44\nD, [date] DEBUG -- net.ssh.authentication.session[806c98fc]: allowed methods: publickey,password\nD, [date] DEBUG -- net.ssh.authentication.methods.none[806cdeac]: none failed\nD, [date] DEBUG -- net.ssh.authentication.session[806c98fc]: trying publickey\nE, [date] ERROR -- net.ssh.authentication.key_manager[806c8060]: could not load private key file/Users/fullyint/.vagrant.d/insecure_private_key': ArgumentError (Could not parse PKey: no start line)\nD, [date] DEBUG -- net.ssh.authentication.agent[806d1818]: connecting to ssh-agent\nD, [date] DEBUG -- net.ssh.authentication.agent[806d1818]: sending agent request 1 len 61\nD, [date] DEBUG -- net.ssh.authentication.agent[806d1818]: received agent packet 2 len 5\nD, [date] DEBUG -- net.ssh.authentication.agent[806d1818]: sending agent request 11 len 0\nD, [date] DEBUG -- net.ssh.authentication.agent[806d1818]: received agent packet 12 len 317\nD, [date] DEBUG -- net.ssh.authentication.session[806c98fc]: trying password\nE, [date] ERROR -- net.ssh.authentication.session[806c98fc]: all authorization methods failed (tried none, publickey, password)\n```\nFor comparison, here's my log when SSH succeeds:\n```\nLOG: When SSH Auth Succeeds...\n...\nD, [date] DEBUG -- net.ssh.authentication.session[80669358]: beginning authentication of `vagrant'\nD, [date] DEBUG -- tcpsocket[8062c4a8]: queueing packet nr 4 type 5 len 28\nD, [date] DEBUG -- tcpsocket[8062c4a8]: sent 52 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: read 52 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: received packet nr 4 type 6 len 28\nD, [date] DEBUG -- net.ssh.authentication.session[80669358]: trying none\nD, [date] DEBUG -- tcpsocket[8062c4a8]: queueing packet nr 5 type 50 len 44\nD, [date] DEBUG -- tcpsocket[8062c4a8]: sent 68 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: read 68 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: received packet nr 5 type 51 len 44\nD, [date] DEBUG -- net.ssh.authentication.session[80669358]: allowed methods: publickey,password\nD, [date] DEBUG -- net.ssh.authentication.methods.none[8067a090]: none failed\nD, [date] DEBUG -- net.ssh.authentication.session[80669358]: trying publickey\nD, [date] DEBUG -- net.ssh.authentication.agent[806760bc]: connecting to ssh-agent\nD, [date] DEBUG -- net.ssh.authentication.agent[806760bc]: sending agent request 1 len 61\nD, [date] DEBUG -- net.ssh.authentication.agent[806760bc]: received agent packet 2 len 5\nD, [date] DEBUG -- net.ssh.authentication.agent[806760bc]: sending agent request 11 len 0\nD, [date] DEBUG -- net.ssh.authentication.agent[806760bc]: received agent packet 12 len 317\nD, [date] DEBUG -- net.ssh.authentication.methods.publickey[806763c8]: trying publickey (d:3b:b8:2e:85:04:06:e9:ab:ff:a8:0a:c0:04:6e:d6)\nD, [date] DEBUG -- tcpsocket[8062c4a8]: queueing packet nr 6 type 50 len 348\nD, [date] DEBUG -- tcpsocket[8062c4a8]: sent 372 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: read 324 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: received packet nr 6 type 60 len 300\nD, [date] DEBUG -- tcpsocket[8062c4a8]: queueing packet nr 7 type 50 len 620\nD, [date] DEBUG -- tcpsocket[8062c4a8]: sent 644 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: read 36 bytes\nD, [date] DEBUG -- tcpsocket[8062c4a8]: received packet nr 7 type 52 len 12\nD, [date] DEBUG -- net.ssh.authentication.methods.publickey[806763c8]: publickey succeeded (dd:3b:b8:2e:85:04:06:e9:ab:ff:a8:0a:c0:04:6e:d6)\n```\n3) Might you have anything in your ~/.ssh/config file that would be interfering?\n4) Of course, if you haven't do so already, you might completely uninstall and reinstall Vagrant.\n. I'd be inclined to reinstall vagrant at this point. But here are some reactions to the log you posted.\nNote. My understanding is that you really do need to use vagrant's public/private key pair \"since that is what public boxes use\", unless \"you make your own custom box with a custom SSH key\" (quoting from config.ssh.private_key_path section of Vagrant docs).\n1) Comparing the key fingerprint in our logs, google shows mine (dd:3b:b8:2e:85:04:06:e9:ab:ff:a8:0a:c0:04:6e:d6) as associated with the vagrant public key, as expected, but I find no google results for yours. Do you see the fingerprint from your log above (19:8a:49:fa:7c:64:11:3c:61:57:05:1c:ce:85:1c:0f) listed when you run ssh-add -l on your host/mac (listed perhaps for ~/.ssh/id_rsa)? If so, here are some ideas...\n2) I assume you've removed config.ssh.private_key_path = \"~/.ssh/id_rsa\" from your Vagrantfile, right? If present, that would cause ssh to try your personal key instead of vagrant's.\n3) It's a long shot, but do you have any environment variables that might cause vagrant to use something other than its typical key pair? You might run printenv to check your environment variables.\n4) Your SO thread mentioned that you tried replacing the contents of insecure_private_key with contents from ~/.ssh/id_rsa. Maybe something got messed up in the process of changing insecure_private_key back to its original value. You could just delete the insecure_private_key file -- vagrant should create a new one on the next vagrant up.\n5) Considering the \"Load Order and Merging\" section in the Vagrant docs, maybe you could try adding config.ssh.private_key_path = \"~/.vagrant.d/insecure_private_key\" to your Vagrantfile. That is the default value, but maybe somehow in your case an override config is being merged in.\n6) Otherwise, I don't know if it is an issue that our logs differ occasionally on packet length.\n7) Also, it seems like a long shot, but could the missing the backtick and single quote on beginning authentication ofvagrant'` in your log suggest that it is trying a different ssh username than mine?\n. That's great news! I'm glad it worked out.\n. Is there wide enough interest in basic_auth for the staging site to warrant including it as an option in your feature/security branch? (Sorry if the functionality is there and I missed it.) Ansible has a related htpasswd module.\nI use basic_auth on my staging site, not for security per se, but to prevent...\n- people from stumbling upon it\n- duplicate content penalties (SEO)\n- search engines indexing and showing the staging site higher in the SERPs than the production site\n- etc.\nThanks for your awesome work on this!\n. Ah, ok. Looking around more, I see that people use basic_auth less frequently than no-index. It's not a cowpath, so it shouldn't be paved here in this project.\nI think I'll continue using authentication on my staging site (with bedrock's no-index setting as backup for times when I break basic_auth). My rationale is that a while back, Matt Cutts suggested using passwords to prevent the occasional problems of no-index. Example others prefering authentication: 1, 2. Thanks!\n. Update: I ran into the issues above while testing after updating the tools in my dev environment. Today I discovered that my updates somehow failed to include Ansible. Now, after moving Ansible from 1.5.4 to 1.7.2, I can no longer reproduce the problem I had with special characters in Ansible's mysql_db module.\nI apologize for wasting your time with such a newbie mistake.\nSo the only remaining issue is that provisioning still fails when I change mysql_root_password while using the roots/bedrock box.\n. Below is the error when changing mysql_root_password from devpw to devpassw while using the roots/bedrock box. \n- Totally vanilla install of bedrock-ansible etc.\n- OSX 10.9.5\n- Vagrant 1.6.5\n- Ansible 1.7.2\nDefault verbosity for ansible:\n```\nTASK: [mariadb | Set root user password] ******** \nfailed: [default] => (item=example) => {\"failed\": true, \"item\": \"example\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=127.0.0.1) => {\"failed\": true, \"item\": \"127.0.0.1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=::1) => {\"failed\": true, \"item\": \"::1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=localhost) => {\"failed\": true, \"item\": \"localhost\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nFATAL: all hosts have already failed -- aborting\n```\nOr, ansible.verbose = 'vvvv'\n```\nTASK: [mariadb | Set root user password] ******** \n<127.0.0.1> ESTABLISH CONNECTION FOR USER: vagrant\n<127.0.0.1> REMOTE_MODULE mysql_user name=root password=VALUE_HIDDEN check_implicit_admin=yes login_user=root login_password=VALUE_HIDDEN state=present\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', \"/bin/sh -c 'mkdir -p $HOME/.ansible/tmp/ansible-tmp-1413419246.56-127616040927023 && echo $HOME/.ansible/tmp/ansible-tmp-1413419246.56-127616040927023'\"]\n<127.0.0.1> PUT /var/folders/8s/fk0hnnsd19x3_r_3x3vsq_4c0000gn/T/tmpXEosuA TO /home/vagrant/.ansible/tmp/ansible-tmp-1413419246.56-127616040927023/mysql_user\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', u'/bin/sh -c \\'sudo -k && sudo -H -S -p \"[sudo via ansible, key=ysimsrfemwuplanombmbdhlhaaczvloy] password: \" -u root /bin/sh -c \\'\"\\'\"\\'echo SUDO-SUCCESS-ysimsrfemwuplanombmbdhlhaaczvloy; LANG=en_US.UTF-8 LC_CTYPE=en_US.UTF-8 /usr/bin/python /home/vagrant/.ansible/tmp/ansible-tmp-1413419246.56-127616040927023/mysql_user; rm -rf /home/vagrant/.ansible/tmp/ansible-tmp-1413419246.56-127616040927023/ >/dev/null 2>&1\\'\"\\'\"\\'\\'']\nfailed: [default] => (item=example) => {\"failed\": true, \"item\": \"example\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\n<127.0.0.1> ESTABLISH CONNECTION FOR USER: vagrant\n<127.0.0.1> REMOTE_MODULE mysql_user name=root password=VALUE_HIDDEN check_implicit_admin=yes login_user=root login_password=VALUE_HIDDEN state=present\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', \"/bin/sh -c 'mkdir -p $HOME/.ansible/tmp/ansible-tmp-1413419247.07-41646157237100 && echo $HOME/.ansible/tmp/ansible-tmp-1413419247.07-41646157237100'\"]\n<127.0.0.1> PUT /var/folders/8s/fk0hnnsd19x3_r_3x3vsq_4c0000gn/T/tmpeSRdRw TO /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.07-41646157237100/mysql_user\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', u'/bin/sh -c \\'sudo -k && sudo -H -S -p \"[sudo via ansible, key=pixzzvksalwsrxafmqbdhrdwaxvpdvuv] password: \" -u root /bin/sh -c \\'\"\\'\"\\'echo SUDO-SUCCESS-pixzzvksalwsrxafmqbdhrdwaxvpdvuv; LANG=en_US.UTF-8 LC_CTYPE=en_US.UTF-8 /usr/bin/python /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.07-41646157237100/mysql_user; rm -rf /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.07-41646157237100/ >/dev/null 2>&1\\'\"\\'\"\\'\\'']\nfailed: [default] => (item=127.0.0.1) => {\"failed\": true, \"item\": \"127.0.0.1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\n<127.0.0.1> ESTABLISH CONNECTION FOR USER: vagrant\n<127.0.0.1> REMOTE_MODULE mysql_user name=root password=VALUE_HIDDEN check_implicit_admin=yes login_user=root login_password=VALUE_HIDDEN state=present\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', \"/bin/sh -c 'mkdir -p $HOME/.ansible/tmp/ansible-tmp-1413419247.5-106366143609470 && echo $HOME/.ansible/tmp/ansible-tmp-1413419247.5-106366143609470'\"]\n<127.0.0.1> PUT /var/folders/8s/fk0hnnsd19x3_r_3x3vsq_4c0000gn/T/tmp3sZOIr TO /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.5-106366143609470/mysql_user\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', u'/bin/sh -c \\'sudo -k && sudo -H -S -p \"[sudo via ansible, key=nowozpfcgpjylkxgvnhyrunseqrarzpu] password: \" -u root /bin/sh -c \\'\"\\'\"\\'echo SUDO-SUCCESS-nowozpfcgpjylkxgvnhyrunseqrarzpu; LANG=en_US.UTF-8 LC_CTYPE=en_US.UTF-8 /usr/bin/python /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.5-106366143609470/mysql_user; rm -rf /home/vagrant/.ansible/tmp/ansible-tmp-1413419247.5-106366143609470/ >/dev/null 2>&1\\'\"\\'\"\\'\\'']\nfailed: [default] => (item=::1) => {\"failed\": true, \"item\": \"::1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\n<127.0.0.1> ESTABLISH CONNECTION FOR USER: vagrant\n<127.0.0.1> REMOTE_MODULE mysql_user name=root password=VALUE_HIDDEN check_implicit_admin=yes login_user=root login_password=VALUE_HIDDEN state=present\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', \"/bin/sh -c 'mkdir -p $HOME/.ansible/tmp/ansible-tmp-1413419248.07-31752069762875 && echo $HOME/.ansible/tmp/ansible-tmp-1413419248.07-31752069762875'\"]\n<127.0.0.1> PUT /var/folders/8s/fk0hnnsd19x3_r_3x3vsq_4c0000gn/T/tmp3FZzjT TO /home/vagrant/.ansible/tmp/ansible-tmp-1413419248.07-31752069762875/mysql_user\n<127.0.0.1> EXEC ['ssh', '-C', '-tt', '-vvv', '-o', 'ControlMaster=auto', '-o', 'ControlPersist=60s', '-o', 'ControlPath=/Users/fullyint/.ansible/cp/ansible-ssh-%h-%p-%r', '-o', 'StrictHostKeyChecking=no', '-o', 'Port=2222', '-o', 'IdentityFile=\"/Users/fullyint/.vagrant.d/insecure_private_key\"', '-o', 'KbdInteractiveAuthentication=no', '-o', 'PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey', '-o', 'PasswordAuthentication=no', '-o', 'User=vagrant', '-o', 'ConnectTimeout=10', '127.0.0.1', u'/bin/sh -c \\'sudo -k && sudo -H -S -p \"[sudo via ansible, key=mycuzpanthsrxbjhwmybzrbznsniljxi] password: \" -u root /bin/sh -c \\'\"\\'\"\\'echo SUDO-SUCCESS-mycuzpanthsrxbjhwmybzrbznsniljxi; LANG=en_US.UTF-8 LC_CTYPE=en_US.UTF-8 /usr/bin/python /home/vagrant/.ansible/tmp/ansible-tmp-1413419248.07-31752069762875/mysql_user; rm -rf /home/vagrant/.ansible/tmp/ansible-tmp-1413419248.07-31752069762875/ >/dev/null 2>&1\\'\"\\'\"\\'\\'']\nfailed: [default] => (item=localhost) => {\"failed\": true, \"item\": \"localhost\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nFATAL: all hosts have already failed -- aborting\n``\n. This is avagrant upfrom scratch, using the partly-provisioned (as I understand it) roots/bedrock vagrant box (config.vm.box = 'roots/bedrock'inVagrantfile). My guess was that this box hadmysql_root_password` already set. \nAssuming mysql_root_password had to be set in this box, I was thinking we could just add a note to the README for people to just leave the default mysql_root_password when using config.vm.box = 'roots/bedrock'. However, when @swalkinshaw said \n\nI should fix the first issue so it works as people would expect.\n\nit made me think he intended to adjust the roots/bedrock box so people could still change mysql_root_password.\n. Thank you for being so helpful to someone who is not as far down the path. I see you do it all the time.\n. Yes, I'm a fount. And although I'm high on character count, I'm low on experience. So, I defer to your judgment, both of you. I'm happy for what I learn here. Thanks for being so generous with your time and work. Close at will, @swalkinshaw.\n. PR in #83\nIt uses the options u: 'vagrant', g: 'www-data' instead of the chgrp_ignore option above.\n. @austinpray Glad you asked. I mentioned omitting the check/warnings so others could share feedback. I wasn't sure about it. My rationale:\n- the README now lists vagrant-bindfs in the Requirements section\n- it's maybe not justified to add the extra code, given that vagrant itself will provide this warning:\nThere are errors in the configuration of this machine. Please fix\nthe following errors and try again:\nVagrant:\n* Unknown configuration section 'bindfs'.\nPresumably a user would see that and think, \"Huh, what's this 'bindfs'? Let me go double-check the README.\" But, admittedly, it would be clearer if we provided a custom warning, \"You need to install the vagrant-bindfs plugin.\" What do you think?\n. Awesome! I'm convinced! Thank you so much @nathanielks and @austinpray.\nI have no ruby experience, so set me straight with the code below.\n- Detects platform like this (inspiration) -- no more manual uncommenting for windows.\n- People may find the bedrock_path variable simpler than hunting for multiple places to edit path.\n- The \"forward slash\" thing is required by basename.\n``` ruby\nDefine path to bedrock directory on your local host machine\n- relative to Vagrantfile\n- use forward slashes (\"/\") regardless of your OS\nbedrock_path = '../example.dev'\nSync bedrock directory\nbedrock_path_server = '/srv/www/' + File.basename(bedrock_path) + '/current'\nif Vagrant::Util::Platform.windows?\n  config.vm.synced_folder bedrock_path, bedrock_path_server, owner: 'vagrant', group: 'www-data', mount_options: ['dmode=776', 'fmode=775']\nelse\n  if !Vagrant.has_plugin? 'vagrant-bindfs'\n    puts 'vagrant-bindfs missing, please install the plugin:'\n    puts 'vagrant plugin install vagrant-bindfs'\n    abort\n  else\n    config.vm.synced_folder bedrock_path, '/vagrant-nfs', type: 'nfs'\n    config.bindfs.bind_folder '/vagrant-nfs', bedrock_path_server, u: 'vagrant', g: 'www-data'\n  end\nend\n```\nAlternatively, we could auto-install the missing vagrant-bindfs like this, but that feels heavy handed.\n. Seems better with Vagrant's error handling...\nDiff\n if !Vagrant.has_plugin? 'vagrant-bindfs'\n-  puts 'vagrant-bindfs missing, please install the plugin:'\n-  puts 'vagrant plugin install vagrant-bindfs'\n-  abort\n+  raise Vagrant::Errors::VagrantError.new,\n+    \"vagrant-bindfs missing, please install the plugin:\\nvagrant plugin install vagrant-bindfs\"\n else\n. @richardsession Thank you!\nI failed to clearly document the bind_folder when I added it (#83). If merged, PR #86 should resolve this.\n. @RonHoffmannn The errors look similar to this, produced when config.vm.box = 'roots/bedrock' (in Vagrantfile) and mysql_root_password is not equal to the default: devpw (in group_vars/development).\nIf this applies to you, you might try setting mysql_root_password back to the default. Alternatively, you could adjust config.vm.box to use a different vagrant box, like 'ubuntu/trusty64'.\n. Great!\n. Now that you've removed all instances of default(user), I'm pretty sure you can remove user: 'vagrant' from ansible.extra_vars = {} in the Vagrantfile. I don't see user used anywhere else.\n. I can't find where github_ssh_keys is defined. Maybe it's not defined so as to not trigger the github-ssh-keys role. How about defining it (in group_vars/all?), but commenting it out, just so people have an example demonstrating structure? Or maybe you'd prefer the example to be in the README. \n. Most importantly, THANK YOU so much for all your work on this @swalkinshaw !\nWhen github_ssh_keys is not defined...\n1. github-ssh-keys | Add SSH keys task fails. Despite the when condition on the github-ssh-keys role: \nfatal: [192.168.50.5] => subelements lookup expects a dictionary, got 'github_ssh_keys'. Try this:\nyaml\n  with_subelements:\n     - github_ssh_keys | default([])\n     - authorized\n2. ssh-known-hosts role fails. I think it's because the /home/deploy/.ssh directory doesn't yet exist:\nIOError: [Errno 2] No such file or directory: '/home/deploy/.ssh/known_hosts' \nI suppose you could create the .ssh directory at the end of roles/users/tasks/main.yml:\nyaml\n- name: Create deploy user .ssh directory\n  file: path=\"/home/{{ deploy_user }}/.ssh\"\n        owner=\"{{ deploy_user }}\"\n        group=\"{{ deploy_group }}\"\n        mode=0700\n        state=directory\nOr, make the ssh-known-hosts role also conditional on when: github_ssh_keys is defined, but maybe that wouldn't fit with your plans.  \nI assume group_vars/all may end up including something like this?\nyaml\ngithub_ssh_keys:\n  - username: myGithubUser\n    authorized:\n      - deploy\n. Staging/production lack logs directory, maybe because d49beb4 removed logs directory from project_shared_children. Could move 'Create logs folder of sites' task from\nroles/wordpress-install/tasks/directories.yml to\nroles/wordpress-setup/tasks/main.yml.\n. 1. remote_user: root in server.yml. Won't it fail to connect? (secure-root.yml sets PermitRootLogin no)\n2. Private repos. Cloning private repos via https, Ansible hangs waiting for password. Clone via ssh?\ndiff\nwordpress_sites:\n  staging.example.com:\n-    repo: https://github.com/roots/bedrock.git\n+    repo: git@github.com:roots/bedrock.git\nSome seem to need this in bedrock-ansible/ansible.cfg (I seem to). Maybe worth mentioning. \ndiff\n   [ssh_connection]\n-  ssh_args = -o  ForwardAgent=yes\n+  ssh_args = -o ForwardAgent=yes -o ControlMaster=auto -o ControlPersist=60s\n(Edit: I had replaced ssh_args defaults, but \"Leaving off ControlPersist will result in poor performance.\" For me, it caused TASK: [mariadb | Install MariaDB MySQL server] to fail.) \nCould also maybe note ForwardAgent yes in ~/.ssh/config.\n3. known_hosts as root:root. I think I noticed the deploy_user's known_hosts file as root:root. If so, would the deploy user ever need to add known_hosts independently but not be able to? \n(Edit: Is the only purpose for the ssh-known-hosts role so 'Clone project files' task won't hang on a hidden prompt to accept the repo's host key? If so, I think you can just add accept_hostkey=yes to the 'Clone project files' task and drop the ssh-known-hosts role altogether.)\n. Rsyncing compiled assets. I plan to compile my theme locally and will probably add a custom rsync task instead of specifying project_files for the \"Copy project files\" task. That way I can use filename matching patterns. I haven't checked whether the copy module can do that. I suspect my approach doesn't belong in the official project, but just to share...\n1. Add rsync_theme to group_vars/<staging|production>. It's optional, fine to omit.\ndiff\n  wordpress_sites:\n    staging.example.com:\n      repo: git@github.com:roots/bedrock.git\n+     rsync_theme: ../mytheme # path targeting local theme directory (relative to bedrock-ansible root)\nI don't store/commit the theme in my bedrock repo. They have separate repos. I ~~symlink~~ use an extra vagrant sync folder to get my local theme into local bedrock ~~and Vagrant is none the wiser~~. I do the same with the client's custom plugin. \n\u251c\u2500\u2500 sites\n    \u251c\u2500\u2500 client_name\n        \u251c\u2500\u2500 example.dev (bedrock)\n        \u251c\u2500\u2500 bedrock-ansible\n        \u251c\u2500\u2500 mytheme\n        \u2514\u2500\u2500 myplugin\nThere are probably better ways. Feedback welcome.\n2. Add custom rsync task. Right after \"Copy project files\" task (roles/deploy/tasks/main.yml):\n- name: Rsync theme files\n  synchronize: src=\"{{ project.rsync_theme }}\"\n               dest=\"{{ deploy_helper.new_release_path }}/web/app/themes\"\n               rsync_timeout=30\n               archive=no\n               recursive=yes\n               delete=yes\n               rsync_opts=\"--include-from={{ project.rsync_theme }}/.rsync\"\n  when: project.rsync_theme is defined\nMaybe I'll precede this with a task to compile theme assets locally with a local_action.\n3. Add .rsync file to mytheme root. A bunch of exclude rules, followed by \"include all the rest\" (+*).\n```\n- .git\n- assets\n- bower_components\n- node_modules\n- .bowerrc\n- .editorconfig\n- .jshintrc\n- .jscsrc\n- .travis.yml\n- bower.json\n- composer.json\n- CONTRIBUTING.md\n- package.json\n- .gitignore\n- .gitkeep\n- .DS_Store\n\n*\n```\n. @swalkinshaw These steps work for me in cloning a private bitbucket repo. Don't they work for you?\n\n1. Switch wordpress_sites to clone via ssh: repo: git@github.com:roots/my-private-bedrock.git\n2. Amend bedrock-ansible/ansible.cfg file (my comment above about this was muddled):\n[ssh_connection]\nssh_args = -o ForwardAgent=yes -o ControlMaster=auto -o ControlPersist=60s\n3. And maybe you need something like this in your ~/.ssh/config locally:\nHost example.com\n  User myusername\n  ForwardAgent yes\n@mAAdhaTTah The sync task I mentioned (for theme assets compiled locally) is working using the steps I mentioned. If you beat me to writing a task to compile theme locally, I won't complain.\nNotes for Testing\nThis PR seems totally testable. I've only tested on DigitalOcean (not vagrant), and not yet with commits since d49beb4. For me, testing a staging site looks about like this:\n- ansible-galaxy install -r requirements.yml\n- In server.yml switch to sudo: yes and remote_user: admin\n- Adjust various group_vars ~~(leave deploy_user: deploy for now, but var may change to web-user)~~\n- Add github_ssh_keys to group_vars/all (formatted like bottom of this comment) \n- do ~~numbers 1, 2, 3~~ number 3 above re: private repos\n- ~~optional: add the rsync task I mentioned for locally compiled theme (see steps above)~~ \n- Spin up DO droplet. Clear IP from known_hosts. Add IP to hosts/staging and wordpress_sites.\n- ansible-playbook secure-root.yml -i hosts/staging -vvvv\n- ansible-playbook server.yml -i hosts/staging -vvvv -K (-K is short for --ask-sudo-pass)\n- ./deploy staging staging.example.com    (or to get debug info: ansible-playbook deploy.yml -i hosts/staging -vvvv -e \"site=staging.example.com\"  the -e is --extra-vars)\nI wonder if a prompt would be a convenient alternative to specifying that site variable for the deploy.yml playbook (vs. using the --extra-vars \"site=example.com\"). \n. The theme and other files can currently be synced using the deploy role's \"Copy project files\" task. However, I don't think it allows syncing only files matching filename patterns . Maybe the task could add options like those in that rsync task (merging the tasks). That might mean using the synchronize module instead of the copy module. I need to refresh my memory on the differences between the two modules.\n. @mAAdhaTTah Uh oh. I was wrong again! I originally had played with symlinking the theme into bedrock. Looks like I actually create additional vagrant sync folders. I gotta run (can't write much, or carefully), but I replace the sync stuff in my Vagrantfile with something like this:\n``` ruby\nSync bedrock directory\nconfig.vm.synced_folder '../example.dev', '/vagrant-nfs/bedrock', type: 'nfs'\n  config.bindfs.bind_folder '/vagrant-nfs/bedrock', '/srv/www/example.dev/current', u: 'vagrant', g: 'www-data'\n# Optionally sync plugin on host INSTEAD of having Composer install it on guest from remote repo.\n  config.vm.synced_folder '../example', '/vagrant-nfs/plugin', type: 'nfs'\n  config.bindfs.bind_folder '/vagrant-nfs/plugin', '/srv/www/example.dev/current/web/app/plugins/example', u: 'vagrant', g: 'www-data'\n# Optionally sync theme on host INSTEAD of having Composer install it on guest from remote repo.\n  config.vm.synced_folder '../exampletheme', '/vagrant-nfs/theme', type: 'nfs'\n  config.bindfs.bind_folder '/vagrant-nfs/theme', '/srv/www/example.dev/current/web/app/themes/exampletheme', u: 'vagrant', g: 'www-data'\n```\nEdit: An alternative using one bindfs mount instead of three.\n``` ruby\nSync bedrock directory, then sync into it a custom theme and plugin\nconfig.vm.synced_folder '../example.dev', '/vagrant-nfs', type: 'nfs'\nconfig.vm.synced_folder '../exampletheme', '/vagrant-nfs/web/app/themes/exampletheme', type: 'nfs'\nconfig.vm.synced_folder '../exampleplugin', '/vagrant-nfs/web/app/plugins/exampleplugin', type: 'nfs'\ncreate bindfs mount\nconfig.bindfs.bind_folder '/vagrant-nfs', '/srv/www/example.dev/current', force_user: 'vagrant', force_group: 'www-data'\n``\n. @swalkinshaw Any deploy history log file built in?\n. I don't have as wide of perspective as you do @swalkinshaw, but thevarsindeploy.ymlfeel a little out of place to me. If they're variables that won't change all that much, maybe they'd fit better indeploy/defaults/main.yml. Or, If they will change, presumably they may change on a site-by-site basis, so maybe they fit inwordpress_sites(vs having users editdeploy.yml` per deployment).\nAlso, I'd be tempted to drop a few vars that feel like unnecessary middlemen to other vars: project, project_root, project_git_repo, project_version. For example, {{ project_git_repo }} is only used once, only as alternative to {{ wordpress_sites[site].repo }} (not much advantage). \n. > Tools like Node, npm, gulp, etc should be running on the VM.\nYou install and run those tools in a Vagrant VM? Huh, I've only put them on my host machine, so I hadn't considered that a person's Ansible host might not have the tools installed. I see that in roles/deploy/defaults/main.yml you gave an example of installing the tools and compiling on the remote server (using project_pre_build_commands). I think I'll compile locally though.\n. ### Major congratulations!!! \ud83c\udf86\nThank you for the tons of work you've put in!\nminor things\n- maybe define/describe github_ssh_keys somewhere (did I miss it?)\n- could drop the first 17 lines of roles/deploy/defaults/main.yml. It includes project_version, but you've got that defined in deploy.yml.\n. @mAAdhaTTah I edited my comment above (re: bindfs mount) to use one instead of three. \n. @mAAdhaTTah Nice! I like how easily that integrates with the official project. I was too hasty when I replaced the official slick sync stuff with my hardcoded stuff. Thanks.\n. If I understood of what you described of your setup, the proposed change would be a new default that would work for you. You could have bedrock_path = '../bedrock' and bedrock_path_server would automatically pick up the example.dev name from config.vm.hostname. Sorry if I'm missing something.\nDo you foresee scenarios in which users would give config.vm.hostname a value other than something like example.dev, a value that wouldn't work in this: bedrock_path_server = File.join('/srv/www', config.vm.hostname, 'current')? I just don't see the 'big picture' well enough to be able to answer that.\n. Thanks. I'll do a PR. Do you want it to include that edit to the README, adding the instruction to edit config.vm.hostname?\n. Right, I should have been clear that the README edit is separate from what we just discussed. Imagine a totally new github issue saying...\n\n\"Hey, users are expected to edit the config.vm.hostname variable, but the README never says to do so. Most users will figure it out, but if the README is already telling users that setup requires editing variables like bedrock_path, why leave out mention of config.vm.hostname?\"\n\nAgain, sorry if I missed something, if somehow users are already given this instruction. \n. This looks really great! I haven't yet run multiple sites with a single Vagrantfile or tested what you have here, but here are some very minor comments.\n1) If someone sets site_name to something that isn't a domain name, the server could end up with paths like /srv/www/not-a-domain-name/current/. I'm too inexperienced to know if that could be a problem.\n2) Meaning of \"path to\" vs. \"path relative to\".\n- At top of Vagrantfile, how about saying \"ANSIBLE_PATH = '.' # path targeting Ansible directory (relative to Vagrantfile)\"\n- In group_vars/development, how about saying \"local_path: '../example.dev' # path targeting local bedrock directory (relative to root/Vagrantfile)\"\n3) Sounds like a good idea, @austinpray, for the new wp_sites object (or wordpress_sites, whichever) to populate config.vm.hostname and config.vm.network.\n4) Once the code crystalizes and you're updating the README, we could warn that the full path to the local bedrock directory must not have spaces, or else provisioning will fail.\n. Want this?\nDIFF\n- ansible.playbook = './site.yml'\n+ ansible.playbook = File.join(ANSIBLE_PATH, 'site.yml')\n. > 3) config.vm.hostname I've added but I'm not sure how to handle config.vm.network\nWould there ever be a scenario in which site_hosts has more than just the hostname and IP? If not, my first thought was to replace the site_hosts array with two separate variables, such as hostname and host_ip (obviously corresponding to config.vm.hostname and config.vm.network, respectively). This change would require editing wordpress-site.conf.j2 -- the only place I see site_hosts is used. \nEdit: Hmm... I guess maybe you'd only ever have one IP on your vagrant vm, but using ansible and load-balancing a site across multiple IPs would give you multiple IPs under site_hosts? That's beyond my experience.\n. Aw, right. Thanks @austinpray. What if config.vm.hostname were to use the first item of a new hostnames array (instead of the first item of site_hosts) and config.vm.network were to use the first item of a new host_ips array? Again, we'd have to adjust wordpress-site.conf.j2, which uses site_hosts. \n. Thank you @nathanielks! I'm really happy to learn of your layer-4-bedrock-ansible. I'll study it in prep to set up SSL shortly, and also if/when setting up load balancing. \n. @nathanielks Thanks! \ud83d\ude0a\n. Yeah, congrats!\nYou guys do so much work on these roots projects. It makes my life so much better. Thank you!\n. I add --ask-sudo-pass to avoid that error: \nansible-playbook -i hosts/production site.yml --ask-sudo-pass\n...then I type the password example_password or whatever password you've created for the admin user in vars/sudoer_passwords.yml (because the site.yml playbook uses admin as the remote_user).\nAnsible docs:\n\nUse --ask-sudo-pass (-K) if you are not using passwordless sudo. This will interactively prompt you for the password to use. Use of passwordless sudo makes things easier to automate, but it\u2019s not required.\n\nI don't know if somehow others don't have to use --ask-sudo-pass, but if it is always needed, we might add it to the README.\n. Development server using vagrant. Too obvious maybe, but have you confirmed that the composer.json is where you expect on the dev server? (e.g., using vagrant ssh, cd /srv/www/example.dev/current and ll -- that path assumes site_name: example.dev in group_vars/development) \nIf composer.json is not in that directory, and the other bedrock contents aren't either, it suggests a problem with the vagrant sync folder (syncs your bedrock project folder into vagrant vm). In this case, you could review whether your site_name and local_path definitions from group_vars/development will work with the config.vm.synced_folder logic in the Vagrantfile. To be safe, avoid using spaces or unusual characters in site_name and local_path.\nStaging/Production server on remote host. The bedrock contents, including composer.json, won't be on the server the first time you run the site.yml playbook. See composer-related discussion in #84, #30, #135 etc.\n. Maybe logrotate as another candidate galaxy role (#141)\n. Just to double-check, did you attempt to install the vagrant-bindfs plugin using this command: vagrant plugin install vagrant-bindfs? I ask because I can't think of why Bundler would be involved in the install process (as noted in the error message). \n. I'm new to it all, but this seems to rotate logs in /srv/www/example.com/logs. \nAdd to roles/wordpress-sites/tasks/nginx.yml, after \"Create WordPress configuration for Nginx\": \nyaml\n- name: Enable logrotate for WordPress logs\n  template: src=\"logrotate.j2\"\n            dest=\"/etc/logrotate.d/nginx-wordpress\"\n  with_items: wordpress_sites\nDoes it need a notify: reload nginx?\nAnd a new template roles/wordpress-sites/templates/logrotate.j2:\n{{ www_root }}/{{ item.site_name }}/logs/*.log {\n        weekly\n        missingok\n        rotate 52\n        compress\n        delaycompress\n        notifempty\n        create 0640 {{ item.user | default(user) }} www-data\n        sharedscripts\n        prerotate\n                if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\\n                        run-parts /etc/logrotate.d/httpd-prerotate; \\\n                fi \\\n        endscript\n        postrotate\n                invoke-rc.d nginx rotate >/dev/null 2>&1\n        endscript\n}\n. @swalkinshaw I could try a PR adding the nickhammond.logrotate galaxy role. But maybe you'll want to finish/merge the deploys branch first, given that it too begins using galaxy roles (and maybe moves logs to srv/www/example.com/shared/logs). Or, I could submit the PR against the deploys branch.\n.yml vs .txt. If I do a PR, is it ok if I use a .yml file to make possible features not available to .txt files (e.g., choose versions, install from repos other than galaxy, etc.)? Using .yml would mean bumping the ansible requirement to 1.8 (Nov 24, 2014), up from 1.6 (May 5, 2014).\nFilename: requirements.yml vs. galaxy-roles.yml. Given the potential of roles from remote repos (not galaxy), I'm inclined to omit galaxy from the filename, going with requirements.yml as in the docs.\nSwapfile. As an aside, any interest in a PR adding kamaln7.swapfile? DigitalOcean's Ubuntu droplets lack a swapfile. MySQL is a routine victim of the oom-killer (see comments), leaving sites displaying nothing but \"Error establishing a database connection.\" I need to learn to tune my system better, but a swapfile seems like a reasonable precaution. I'm not sure of implications for hosts other than DigitalOcean.\n. Yeah! I ought to be able to do it mid day tomorrow. I'm fine if someone beats me to it though.\n. @swalkinshaw you're knocking out a ton of stuff quickly. Don't let me hold you up on this logrotate thing. If you want to just kill it quick, that's great.\n. I can't find any evidence of this merge on the deploys branch. Any ideas of what I'm missing? \n. \ud83d\ude0a Thanks! Makes sense now.\n. Swap suits my needs. There's been some discussion of switching some existing roles to galaxy roles. There's a kamaln7.swapfile galaxy role, but perhaps this PR fits better. The current deploys branch shows the anticipated structure (with a requirements.yml file and galaxy roles installing into vendor/roles dir).\n. I started wondering if this role isn't needed because the symlink can be changed in a single command:\nsudo ln -sfn releases/20150401173849 current\nBut there are still a few advantages to the role:\n- doesn't require sudo\n- reduces chance errors by preventing current from being symlinked to\n  - non-existent release (e.g., due to error while typing release name)\n  - a faulty release (e.g., a release that still has the DEPLOY_UNFINISHED file)\n- doesn't require entering a release name (when using default of rolling back to previous)\n- will write the rollback to deploy history log (once it exists)\n. As requested, I removed the vars from deploy.yml. They appear commented out in defaults.  \nAnsible re: synchronize:\n\nrsync must be installed on both the local and remote machine. \n. I understood that message to mean that because synchronize is rsyncing files from your local machine to remote, the local machine in fact needs rsync in order to pull it off.\n\nI'm not certain, but I think all nix machines will have rsync (ref). I think our Windows users will be running their Ansible from a nix machine somewhere (probably in their Vagrant VM), so they should be fine too.\nI can switch it back to the copy module if you want. Maybe that's safest. The project doesn't need to support my non-standard usage plans with the beloved .rsync-filter, or my being suckered by comments like these:\n\nNot sure why copy fails, but the solution was to use synchronize instead. (ref)\nThe \u201ccopy\u201d module recursively copy facility does not scale to lots (>hundreds) of files. For alternative, see synchronize module, which is a wrapper around rsync. (ref)\nIt is really amazing how bad copy is compared to synchronize. For bulk copies the difference is orders of magnitude. (ref)\n. (see edit further down in this comment)\nI think the problem could be the discrepancy between example.com vs example.dev. I think you've named your bedrock directory example.com, but your group_vars/development probably has this...\n\nyaml\nwordpress_sites:\n  example.dev:\n    site_hosts:\n      - example.dev\n    local_path: '../example.com'\nThings might work if you change the two instances of example.dev above to example.com. Or, switch the name of your bedrock directory to example.dev and also switch the value for local_path above. Let us know if that fixes it. I see that the README suggests naming your bedrock directory example.com, so it would be easy to run into this issue.\nEdit: To correct my error and avoid spreading misinformation:\nHostnames need to match each other, otherwise your VM will be confused   \nyaml\nwordpress_sites:\n  example.dev:\n    site_hosts:\n      - example.dev\nPaths need to match each other. Name your bedrock directory to whatever you want, just be sure to update local_path to match.\nI replied too quickly without checking my thinking. I was vaguely thinking that ALL the above needed to match. Nope. Your paths don't need to match your hostnames because the vagrant sync folder will make the connection anyway. \n. @workerdem Sorry I was wrong. I think your setup was actually fine. I've edited my comment above to hopefully not confuse too many people.\n. I think this is on the right track in terms of features, but not in terms of implementation. The scripting type issues ought to be handled in a module, not in a maze of jinja filters in defaults/main.yml. I started with jinja, not anticipating how it all would keep growing and growing. So, I could learn a little python, and take another stab at it, doing it right, but I'm guessing you already have your own plans for implementing these features.\n. As it's your project/repo, I respect anything you decide. Part of me thinks the features and logic are super smart, but part of me fears that it could be just a beginner's silly contraption in code. I simply don't have broad enough experience and perspective to know.\nI'll have to rely on your judgment as to whether this has merit, or any place in your project. My view is that it works, and is really convenient, and I like the logs. I did enough testing to share it for others to respond to, but I didn't hammer on it hard, so I expect we'd find bugs.\n\nIt's just a lot of code to go through.\n\nThat's the fault of my bad implementation. Had I put all the logic in a python-based library/module, it'd be easier (of course). I bet that it'd be easiest to evaluate while test driving, trying to stump it, then looking at the code to see its strategy.\n\nIs there anything smaller to break out of it first?\n\nIt could be merged as is and require zero change in how people use bedrock-ansible. It uses the same commands for deploy and rollback as at present. It just automatically creates deploy logs and has the extra features available in the --extra-vars and in the error-checking. I'm not sure why break out a smaller piece of it, unless you see pieces in my description above that you know you'd never want to include in the final version anyway.\nA big argument for not including ANY of it would be if you expect that a next iteration/implementation would be totally different. In that case, maybe there's no reason to add something you'll just turn around and rip out. Another reason not to include it might be to avoid having its weird jinja implementation in your repo history, kind of like, \"don't ever ship code that is doing it wrong.\"\nSome notes I have to myself of what I would add/change, if it's worth pursuing:\n- add a dry-run option showing what the new log entry would be (status, release name, etc.)\n- rename logs/revisions.log to logs/{{site}}.revisions.log (like the access and error logs) and assign a custom logrotate rule, not rotating as frequently as other logs, if at all.\n- use multiline variables for the messages, like I did in the logrotate_scripts variable\n- maybe write a bash wrapper script\n. Closing. A PR is not the place for \"hey, what do you think of my poorly-implemented idea?\" Wish I had time right now to re-do it with a library/module, but it'll have to wait. Anyone is welcome to beat me to it.\n. ok, updated to path: \"{{ www_root }}/**/logs/*.log\"\n. Congrats on getting it running!\nYou can use discourse.roots.io for support requests, rather than the issue tracker here.\n\nhow do I see my site locally on my Mac?\n\nYou should be able to see your site in your browser at example.dev, or whatever site name you entered in group_vars/development. If it doesn't load, you might double-check that your site is in your etc/hosts file, and consider using the vagrant-hostsupdater plugin.\n\nWhere do I make changes?\n\nYou can edit your files like normal on your local machine. Vagrant shares those files/folders, so your changes will show up in the VM and in your browser on refresh. \n. I've invited stefanlindberg (who tracked down the issue) to submit the PR. I'll submit it after a while if no response. If it starts to feel urgent, let me know.\n. @rmartin I believe that in the original issue of this thread, the uploads directory had the expected ownership of web:www-data but the php process was running as the user www-data, and thus not having permission to upload things on users' behalf.\nYour situation sounds different. Apparently your uploads directory doesn't have the expected ownership of web:www-data, but has root:root instead.\nCan you help me replicate? Here's what I tried and I still got web:www-data. I also was able to upload an image via wp-admin/media-new.php. (roots/trellis@737b930, roots/bedrock@5dc485e)\n```\ncreate DO droplet then set ip to variable\nexport DO_IP=xx.xx.xx.xxx\nalso add IP and staging.example.com to /etc/hosts\ncreate project dir\ncd /tmp\nmkdir example.com\ncd example.com\nadd bedrock\ngit clone --depth=1 git@github.com:roots/bedrock.git site\nadd trellis\ngit clone --depth=1 git@github.com:roots/trellis.git ansible\ncd ansible\nansible-galaxy install -r requirements.yml\nsed -i '' \"s/192.168.50.5/$DO_IP/g\" hosts/staging\nprovision and deploy\nansible-playbook -i hosts/staging server.yml\n./deploy.sh staging example.com\ncheck owner:group\nssh root@$DO_IP 'ls -al /srv/www/example.com/current/web/app'\nlrwxrwxrwx 1 web www-data   35 Sep  1 00:39 uploads -> /srv/www/example.com/shared/uploads\nssh root@$DO_IP 'ls -al /srv/www/example.com/shared'\ndrwxr-xr-x 3 web www-data 4096 Sep  1 00:43 uploads\n```\n. > Local/remote commands should be together\n@swalkinshaw I was thinking of pre_build_commands_local as primarily used to compile theme assets locally, which would need to happen before sending those assets to the remote via the \"Copy project files\" task, which is the next task, at present. And, I figured it might typically be best to run pre_build_commands on the remote after you've copied up any files, and maybe after you've placed templates. That rationale would argue for keeping the current task sequence. But you're probably thinking of scenarios that I've failed to anticipate.\n\nAdd local post build commands\n\nI considered local post build commands, but deliberately left them out because I couldn't think of any examples of what they might be... but I'm guessing you can. \n. @swalkinshaw I hadn't thought of moving pre_build_commands earlier (before the sync), to be next to pre_build_commands_local. Sounds fine, and has that consistent feel. I guess the downside would just be that it wouldn't accommodate the person who, for some reason, wants to run pre_build_commands (remote) using files they plan to sync up (sync wouldn't have happened yet).\nHere's a potentially good alternative approach: We could make the very first and very last tasks local tasks, kind of like a round trip. You start with pre_deploy_local_commands, then go remote (deploy_helper init through deploy_helper finalize), then return home to local and do your post_deploy_local_commands.\nThat might be conceptually intuitive for people. It also ensures they have these tasks to \"hook\" into if they want. (And I can rest assured that future support questions about the missing post deploy hook won't have the sad answer, \"Well @fullyint couldn't really think why you'd want the hook, so it isn't there.\")\n. I can't think of any reason why the pre_build_commands_local can't come before deploy_helper init. There's no dependency I can think of. The pre_build_commands_local task doesn't use any of the deploy_helper dict's attributes/data.\nOf course, the sync task (\"Copy project files\") must come after both tasks above, so that assets are compiled and ready to sync, and because the sync task uses  deploy_helper.new_release_path. I figured the sync task could stay where it is.\nSo, I was just thinking you give a hook for local commands at the very beginning, before anything else, then a final hook for local commands at the very end, after everything else. Sorry if I'm missing something. \n. Ok cool. \nI'll obsess on it more, though... If you keep the pre-build local hook task after the deploy_helper init, people's local commands would have available to them the deploy helper data/variables, like release name. \nAnd related, if you add a registered variable to the \"Clone project files\" task, it would make available the before and after SHA for the project in the shared/source path (e.g., registered_var.before and registered_var.after). People's pre-build local commands could have this info available too, obviously so long as the pre-build local hook task comes after the cloning.\nOk, I'll stop this and go look at your latest commit.\n. smart stuff, man\n. I like how you folded the composer install into project_post_build_commands. I'd keep it there.\nNote, however, that there is an ansible composer module which you'll be forgoing, and ansible galaxy advises \"How To Review Roles You\u2019ve Tested -> Code Quality:\" \n\nDoes it use relevant ansible modules as opposed to relying on the \u2018shell\u2019, \u2018command\u2019, or \u2018script\u2019 tasks?\n\nYou can decide whether that's a concern. I like it  the way you have it now.\n. Yesterday I secretly spent time (then aborted after failure) trying to pull values out of ARGV inside Vagrantfile, pass them to a var in ansible.extra_vars (in Vagrantfile), grab the values in group_vars/<environment> and use them to subset the wordpress_sites dict. No luck. \nAn alternative might have been to use those ARGV values is a var selected_sites and add something to the conditional for each task using the with_dict option, a la\nwith_dict: wordpress_sites\nwhen: item.key in selected_sites\nNot sure if there's actually potential there. It's all still a little hazy to me.\n. I think we have a few people for whom things are working for private repos with bitbucket (i.e., deploy.yml can clone a private repo). I'm not aware of any extra steps needed. You'll need ssh forwarding enabled, of course. \nBut if what you're saying is that the github-ssh-keys role can't grab a public key from bitbucket, that's right. Any extra info to help me understand?\n. looks like the destination is resolving to a path in the home directory for some reason\nciarlill@staging:/home/ciarlill/main-site/releases/20150428143149/web/app/themes/wo rdpress-base-theme\\\nbut probably ought to resolve to a path in something like /srv/www/main-site/etc.\n. @louim This is probably a question for the forums at https://discourse.roots.io/ rather than this bug tracker, but here are some comments.\nYes, in typical usage, repo should be your bedrock project (most likely with your roots/sage theme included), in a remote repo such as at github, bitbucket, etc. See these additional comments regarding repo.\nYou can deploy a specific branch. To deploy a branch named \"production\", for example: \nansible-playbook -i hosts/production deploy.yml --extra-vars \"site=example.com branch=production\"\nYou'll see that the branch variable provides a value to the project_version variable, which normally defaults to master. Then, the project_version variable specifies the desired branch at the moment of cloning.\n. Good points @louim. I'd be inclined to have the project.branch optional so it could be left out of group_vars/<environment> files and default to master. You could adjust this line to be \nproject_version: \"{{ project.branch | default('master') }}\"\nI imagine you'd also add a note about the project.branch option to the README, and you might want to mention that this branch option accepts not just branch name, but also tags or SHAs (ref: git_module). \n. Thanks @chriszarate. This solved some issues for me.\n. somewhat related discussion of splitting variables files in #133 \n@JacobDorman I realize you've already worked out a theme variable per site, but here's one approach to compare: https://discourse.roots.io/t/modified-deploy-sh-to-accept-a-third-argument-ansible-fails/4127/3\n. @JacobDorman I was thinking about this thread here while replying to this other thread about varying build commands per site (on deploy): https://discourse.roots.io/t/how-can-selectively-run-build-commands-per-site/4557\nYou said:\n\nThere's still some overlap between sites-install and deploy roles (dev/staging)\n\nDon't hesitate to point out some specifics if you think fixes would be of general use for Trellis. Thanks!\n. I've had a similar seed of a thought about whether there would be merit in trying to combine the dev.yml and server.yml playbooks so dev could share a little more with staging/production.\nTesting Deploys on Dev VM Might be Nice\nWithout having developed my thoughts much, I see one main benefit being to somehow test deploys on local dev, vs. requiring a staging server to test deploys, or just deploying with hope to production, being ready to rollback. But as you mentioned, the resulting multiple releases subdirectories on dev would be probably not be synced with the VM's host machine. That's fine for testing a deploy, but we'd need a command to reset the current directory back to the synced folders so that when the developer edits code, those edits show up immediately in the dev environment/browser etc., vs. requiring a new deploy.\nI first thought about all this when btamm said this\n\nwould it make sense to build out the deploy ability for development environment in Trellis to mirror the same processes for users (so the deploy process is the same across environments?) I realize it isn't technically a 'deploy,' but maybe the development deploy just runs the composer part of the deploy process?\n\nConflicting Purposes between Dev and Staging/Production\nOne reason not to merge dev.yml and server.yml are that some roles are unique to dev.yml (e.g., php5-xdebug role), but I guess that could be handled with a conditional. But maybe the bigger drawback is the difference that the purpose of the dev environment may be to show the results of edits in real-time, as the the developer works, whereas the purpose of staging and production is to show stable snapshots (releases) of the code. The first corresponds to the synced folders on dev and the latter corresponds to deploy releases on staging/production. Maybe those separate purposes justify separate playbooks/roles.\nThese conflicting purposes may to apply to your third bullet \"no custom commands to run after install in sites_install\". On dev, you might be running and re-running some such commands constantly (e.g., gulp commands), whereas on a deploy to staging/production, you'd want to run the command only once to produce a static release.\nI didn't try to articulate that very carefully, sorry. If you see a strong argument for creating more overlap between dev and staging/production and want to articulate it in a new issue, I imagine people would be interested in your thoughts.\n. Here's an approach inspired by @louim's with_pipe. It passed some minimal testing.\nyaml\n- name: Copy templates/includes to includes.d\n  template: src=\"{{ item }}\" dest=\"/etc/nginx/{{ item[:-3] }}\"\n  with_lines: \"cd ../templates && find includes.d -type f 2>/dev/null || :\"\nNotes:\n- Still a bit messy.\n- One task only. I figured the template module could also handle regular files, so long as all filenames end in .j2. See any problems with this?\n- If there are no templates, the template task just skips.\nPotential problems: \n- Fails on incorrectly named path: wordpress-setup/templates/includes.d/NOT-A-SITE/myconf.conf.j2.\n- Removing a template from local wordpress-setup/templates/includes.d does not remove from remote server. Rather than remove a local template file, users may have to update the file's contents to be empty so that that template module would pick up on the changes.\n. @chriszarate if you're interested, I'd love your feedback on this revised approach. By the way, thanks for mentioning wordpress_sites.keys(). I didn't even know that was possible.\nFeatures\n- no need to list templates in configs, just add template to local templates/includes.d/example.com/\n- no problem if local machine is missing templates/includes.d directory or subdirectories\n- no problem if template names have spaces\n- skips files not matching *.conf.j2 (e.g., doesn't process your .DS_Store as template)\n- if you remove a template from local, the corresponding conf file will be removed from remote\n- only adds or removes templates corresponding to sites active in wordpress_sites. So, if for some reason your local machine had templates/includes.d/extra-site.com/myconf.conf.j2 but extra-site.com was not active in your wordpress_sites, this template wouldn't be processed. You don't need to remove templates or directories for inactive sites.\n- reloads Nginx if a conf file is added or removed\n- fully idempotent\n``` yaml\nroles/wordpress-setup/tasks/nginx.yml\n\u22ee\n- name: Template files out to includes.d\n  template: src=\"includes.d/{{ item }}\" dest=\"/etc/nginx/includes.d/{{ item[:-3] }}\"\n  with_lines: \"cd ../templates/includes.d && find {{ template_paths }} -type f 2>/dev/null || :\"\n  register: includes\n  notify: reload nginx\n\n\nname: Retrieve list of existing files in includes.d\n  shell: \"find {{ include_paths }} -type f 2>/dev/null || :\"\n  args:\n    chdir: /etc/nginx/includes.d\n  register: includes_existing\n  changed_when: false\n\n\nname: Remove undesired files from includes.d\n  file: path=\"/etc/nginx/includes.d/{{ item }}\" state=absent\n  with_items: includes_existing.stdout_lines | difference(includes_to_keep)\n  notify: reload nginx\n\u22ee\n```\n\n\nSeveral supporting variables:\n``` yaml\nroles/wordpress-setup/defaults/main.yml\n\u22ee\ntemplate_paths: \"{% for site in wordpress_sites.keys() %}{{ site }}/*.conf.j2 {% endfor %}\"\ninclude_paths: \"{{ template_paths | regex_replace('(.j2)', '') }}\"\nincludes_to_keep: '{% if includes.results is defined -%}\n                     [{% for item in includes.results %}\n                       \"{{ item.item[:-3] }}\",\n                     {% endfor %}]\n                   {%- else -%}\n                     []\n                   {%- endif %}'\n```\n\nThe last two tasks could have been combined in one. I chose against it because it might look more complicated and not print to the output exactly which files it removed. Roughly, the task would have been\nyaml\n- name: Remove undesired files from includes.d\n  shell: for file in */*; do case \"$file\" in {{ includes_to_keep }}) ;; *) rm \"$file\" && echo \"$file was removed\";; esac; done\n  args:\n    chdir: /etc/nginx/includes.d\n  register: includes_removed\n  changed_when: includes_removed.stdout != ''\nIt would need a variable like this in the defaults file:\nyaml\nincludes_to_keep: \"{% for item in includes.results %}'{{ item.item[:-3] }}' | {% endfor %}''\"\n. @chriszarate Smart! Lots of superior solutions in here, especially eliminating the supporting variables. I finally understand the map() filter after seeing your demonstration. There were a couple issues I noticed.\n\"Remove unmanaged files\" with_items\nResults undefined. Suppose you remove all templates in order to remove all conf files. With no templates, the template module skips and nginx_includes_managed.results is undefined. This causes the with_items logic to fail in the \"Remove unmanaged files\" task. The task skips and existing files are not removed. To resolve this, you could set a default empty list for nginx_includes_managed.results:\ndiff\n- with_items: nginx_includes_existing.stdout_lines | difference(nginx_includes_managed.results | map(attribute='path') | list)\n+ with_items: nginx_includes_existing.stdout_lines | difference(nginx_includes_managed.results | default([]) | map(attribute='path') | list)\nMissing path attribute. The path attribute is only present for items in nginx_includes_managed.results for which \"changed\": false. So, if the current run of the playbook has files that were templated, those \"changed\": true items will lack the path attribute and the with_items logic will fail for the \"Remove unmanaged files\" task. Unmanaged files are not removed.\nAlthough the \"changed\": true items lack path, they do have dest, which has the path value we desire. It's possible to have an instance of nginx_includes_managed.results where some items have only path and others have only dest (mix of changed true/false). Maybe we could dynamically pick path or dest, but it might be easier to use the item attribute that is present for all items. This item attribute lists the relative path to template items, so we could use regex_replace to make it a full path and strip the .j2.\ndiff\n- with_items:     nginx_includes_existing.stdout_lines | difference(nginx_includes_managed.results | default([]) | map(attribute='path') | list)\n+ with_items: \"{{ nginx_includes_existing.stdout_lines | difference(nginx_includes_managed.results | default([]) | map(attribute='item') | map('regex_replace', '(.*)\\\\.j2', '/etc/nginx/includes.d/\\\\\\\\1') | list) }}\"\nI haven't yet figured out why it only works enclosed in \"{{ ... }}\". I tried Ansible v1.9.0.1 and v1.9.2.\n\"Supporting variable\" option. I was happy that you'd freed us from \"supporting variables,\" but we could abstract the long convoluted look by creating a supporting variable nginx_includes_managed_paths:\nyaml\nwith_items: nginx_includes_existing.stdout_lines | difference(nginx_includes_managed_paths)\nor just put everything in nginx_includes_unmanaged:\nyaml\nwith_items: nginx_includes_unmanaged\nOther Notes\nwhen: item.startswith('/etc/nginx/includes.d/'). I didn't understand the need for this conditional. Could it be removed after adding the default() and regex_replace() changes described above?\nFolder depth. I'm not opposed to the folder depth of 1 limitation, but I don't understand why it would be a concern. In fact, my first inclination would have been a recursive approach. I haven't used Nginx includes, so I don't know what comes up.\nThanks again for your work on this!\n. Nice! I agree: Looks ready to merge. I just ran it again against the tests I could think of.\n- No problem if roles/wordpress-setup/templates has no includes.d dir\n- No problem if roles/wordpress-setup/templates/includes.d exists but is empty\n- Templates added on control machine are successfully added as conf files on server\n- Templates removed from control machine are successfully removed from server\n- Skips template files that don't match *.conf.j2\n- No problem if template filenames have spaces\n- Reloads Nginx if conf file added, or if conf file removed\n- Ignores templates/includes.d/not-in-wordpress-sites-list\n- No problem if all templates are removed -- all conf file includes will be removed from server\n@chriszarate Thanks for this!\nCould I interest you in adding a simple wiki for this? Might be nice for people to know of this feature. A few points that came to mind for me were just versions of testing points above:\n- a phrase or two about why nginx conf includes\n- place template files at roles/wordpress-setup/templates/includes.d/site-key/filename.conf.j2 (could clarify that site-key corresponds to wordpress-sites)\n- template filenames must match *.conf.j2 (ok to have non-template files in there, named otherwise, they'll just be ignored)\n- etc.\n. @chriszarate That wiki reads so well, with great info. Thank you!\nAnd thanks again for the great work and time spent on this PR.\n. I've revised the PR to omit the whitespace formatting changes (with the #jinja2: lstrip_blocks: True, etc.). The reason was that by removing indentation in the template, I made the templates less friendly to the developer, and templates are where the developer works. So, now I'm thinking of it like this: \"Templates are to the conf files they create, as other source files are to uglified dist files they create.\"\n. After some discussion with @swalkinshaw I see that it will be better to process these changes as separate pull requests, one that combines the github_ssh_keys role with the users role, and another that handles the potential merge of the secure-root.yml playbook into the server.yml playbook. So, I'll close now and prepare the revised PRs.\n. @zamber Do I understand correctly that you'd see the same timeouts and failed connection/provisioning if your Vagrantfile were to use config.vm.box = 'ubuntu/trusty64' instead of config.vm.box = 'roots/bedrock' because UseDNS defaults to yes? If so, are you suggesting that the roots/bedrock box be set up with UseDNS set to no?\nIf so, that makes me wonder if the sshd role could be run always (not just as part of the secure-root.yml playbook), but only setting PermitRootLogin to no on an opt-in basis. The point would be for the sshd role to always set UseDNS to no. There might be some other adjustments required to accommodate vagrant, such as Port set to 2222 instead of 22, I think.\n. If we were still using the roots/bedrock box, we could have pre-provisioned it with UseDNS no. But it seems the ubuntu/trusty64 box we use now will default UseDNS yes. So, the problem is upstream and needs to be addressed there. I think we can close this issue.\n. Thank you for the Diffie-Hellman! Any interest in a when: conditional like this?\nwhen: true in [{% for key, value in wordpress_sites.iteritems() %}{{ value.ssl.enabled }},{% endfor %}]\nWhile developing Trellis, it's an all the time operation (destroying and recreating servers constantly). I groan when provisioning churns on the Diffie-Hellman task because I forgot to comment it out. \n. Without doing formal tests, my recollection is that the Diffie-Hellman task varies widely in the time it takes, from 5 seconds to 5 minutes or more. I think others notice the slowness too. I am on a rather old system however, so maybe it's affecting me more: OSX 10.9.5, 3.6 GHz Intel Core 2 Duo (64 bit), 8 GB RAM, SSD (a little low on space).\n. No one needs to engage with me on this, but I don't understand why we'd limit the conditional to development. In standard use on staging/production, users should have SSL enabled and the Diffie should run. But some users won't have SSL enabled. Additionally, the process of testing non-ssl features in staging/production could be faster if the Diffie were conditional.\nIt's normal to avoid running slow processes when they aren't needed. Of course, it's not worth it if the conditional logic involved crosses the line into being too complex, risking development confusion or errors. Where you draw that \"line\" is probably a subjective matter. \nThis conditional doesn't strike me as too complex, nor as a hack in purpose or implementation:\nwhen: true in [dynamically-created list of booleans]\nI think I'd even prefer the combination:\nwhen: \"'development' not in group_names and true in [dynamically-created list of booleans]\"\nIt gets closer to crossing the line into risky complexity, but doesn't cross it for me.\nI'd rather use this so that our code does all the things we want, and then just put a comment next to it:\n# when not development and at least one site has ssl.enabled: true\nThe above conditional could be altered to accommodate @austinpray's suggestion for a config option instead of hardcoding the development exclusion.\nPerhaps the strongest argument against it is \"The conditional would only serve edge cases so it's not worth it. Users should always use SSL. People testing Trellis can just comment out the Diffie task instead expecting complex conditionals built in just for dev purposes.\"\nAgain, no pressure to respond, but if one of you more-seasoned devs wants an eager pupil, I'm ready.\n. There's something different in how vagrant handles the filesystem on Windows. The \"Create .env file\" task was failing on Windows hosts. Here's one example discussion.\nEdit: Here's another example.\n. @austinpray and science have prevailed, transforming this PR from \"seems right,\" to \"yeah, that's it.\"\nDebrief. The above test results mystified me till I caught my mistaken assumption that the template module would check the env vars against the .env file in the web root. But of course, the template module only checks the env vars against the file it creates, which is actually in /tmp. \n- Tests above start by provisioning: create original .env file (correct env values), copy it to web root\n- Change env values, reprovision: create works, but copy never runs -- the original problem to solve\n- Switch to original PR code, reprovision: create skips because .env in /tmp already matches modified env vars (leftover from steps above), copy skips too -- PR made it conditional on create\n- Change to completely new env values, reprovision: PR code runs both the create and copy\n- For science, directly edit web root .env so it differs from env vars, reprovision: create doesn't run because env vars still match the .env file in /tmp, and thus copy doesn't run. Problem persists.\nMoving on. I revised the PR to run copy any time the env vars differ from the .env file in the web root. The tasks will continue to ensure that /tmp always has a .env file matching the env vars (creating one if necessary), and now will always copy it to the web root if it differs from what is in the web root.\nIn the beginning, @swalkinshaw casually said: \"could do a local rsync,\" and that's where I ended up. I switched the copy task to use rsync, but it still uses the command module because I couldn't manage to adapt the synchronize or copy modules to have both src and dest on the remote server. The command module always runs, but the task remains idempotent, only changed_when the file is actually synced.\n. Thanks @jasperf. Added this note to the README in #272\n. Thanks for the time and feedback @austinpray. I applied all your suggestions. I opted to drop the \"for better,\" reverting to the original:\n\nTrellis is a set of Ansible playbooks ... to help achieve development & production parity.\n. Improved handling of remote_user fact. With prompting from @swalkinshaw, I revised the PR to no longer use a registered variable across the two plays. Now the remote-user role in the first play sets the ansible_ssh_user fact for each host to use in the second play. Here are the benefits:\n- playbook can now handle a group of hosts who differ on whether or not they PermitRootLogin\n- the remote-user task can switch from the questionable-looking root@{{ groups.web.0 }} to the natural-looking root@{{ inventory_hostname }}\n- the main play in server.yml can drop the remote_user parameter altogether, which is good news because my recent iteration of this PR had it looking a little ugly, like this:\n\nremote_user: \"{{ hostvars.localhost.remote_user.stdout }}\"\nWhy two plays instead of one? The remote-user role must be in its own separate play with the parameter gather_facts: false. It can't connect to the remote hosts to \"gather facts\" without potentially failing because it doesn't know the proper user for the connection. Yet, the main play needs gather_facts: true to access some of the variables it uses. Examples:\n- ansible_distribution (xdebug role)\n- ansible_os_family (ntp role)\n- ansible_pkg_mgr (logrotate role)\nRemote user variable precedence. The ansible_ssh_user fact set in the remote-user role will override:\n- remote_user parameter for the play (if set)\n- ansible_ssh_user defined for each host in the inventory\n- --user argument passed via CLI\nI suppose users wanting finer grain control could just comment out the remote-user role and set their users in their inventory, etc.\nHere is some discussion over at Ansible about dynamically setting ansible_ssh_useror remote_user.\n. (Edit: This whole comment is inapplicable. I reverted these changes below.)\nMy initial comment said...\n\nfail2ban. If someone disables root login then quickly and repeatedly runs server.yml, fail2ban could ban them due to failed test connections for root (remote-user role). Users could adjust fail2ban defaults.\n\nI've modified the PR to give users the option to set admin_user.try_root: false, if they prefer. That way, a dev can have sshd_permit_root_login: \"no\", yet still avoid failed root connections and potential fail2ban jail time while running and re-running the playbook (e.g., during initial setup or repeated testing). The Security wiki can mention this option when addressing the option for sshd_permit_root_login: \"no\".\nHere are the changes that I applied:\n``` diff\ngroup_vars/all\n\nadmin_user: admin\nadmin_user:\nname: admin\ntry_root: true # If true, server.yml will first attempt to connect as root\n```\n\n``` diff\nroles/remote_user/tasks/main.yml\n\nname: Determine whether to connect as root or admin_user\nlocal_action: shell ssh -o PasswordAuthentication=no root@{{ inventory_hostname }} \"echo root\" || echo {{ admin_user }}\nlocal_action: shell ssh -o PasswordAuthentication=no root@{{ inventory_hostname }} \"echo root\" || echo {{ admin_user.name }}\n    changed_when: false\n\nwhen: admin_user.try_root\n    register: remote_user\n\n\nname: Set remote user for each host\n    set_fact:\n\nansible_ssh_user: \"{{ remote_user.stdout }}\"\nansible_ssh_user: \"{{ admin_user.try_root | ternary(remote_user.stdout, admin_user.name) }}\"\n```\n\nAt one point I had hoped to skip the root connection test when users specify --user <name> on the CLI (ansible-playbook command). I gave up on that because although we can access the ansible_ssh_user variable, I don't see how we can know whether it was set via the CLI. In any case, the admin_user.try_root: false approach has the advantage that the user wouldn't have to add the --user arg on the CLI every time.\n. root must be used on the first run of server.yml, given that root is the only user than can connect on new DigitalOcean droplets. The soonest the PermitRootLogin no could be in effect is after that first run.\nThat was the most challenging issue to handle in this PR, and if there is anything people will resist in this PR, it is the attempt to dynamically determine the remote user. This attempt is not uncommon, however (example), and I think this PR's implementation is pretty decent. All this is why so many of my comments in this thread talk about remote_user, to give rationale. \nThe \"Determine Remote User\" play in server.yml dynamically determines the user so that users don't have to take a manual action related to user. Before, users had to run the separate secure-root.yml playbook (as remote_user: root), and then edit the remote_user in server.yml to be admin. Now, all the user stuff just works for the majority of use cases.\nFor the less common case of someone setting PermitRootLogin no then pounding on server.yml till they wind up with fail2ban jail time, they can set admin_user.try_root: false to tell server.yml from now on, \"never try to connect as root ever.\" Or, temporarily while testing, they could set sshd_permit_root_login: \"yes\", or adjust fail2ban settings, but then they'd have to remember to set these back to the more secure setting. Setting admin_user.try_root: false seems easiest.\nAs I described in my comment opening the PR, I think this PR offers better user experience for all users. All that said, I'd love it if anyone would suggest a better implementation. \n. Managing fail2ban via ignoreip. I revised the PR to dynamically append the control machine's external public IP to fail2ban's ignoreip list. This seems better than admin_user.try_root, which I've reverted.\nIP lookup. The IP is retrieved using a dig dns lookup with the Ansible pipe lookup plugin. The Ansible dig lookup plugin would require users to install an extra python package: dnspython. For a one-time simple lookup, I didn't want to add a dependency.\nforce_handlers. The fail2ban role runs before the sshd role, so the control machine's IP should make it into fail2ban's ignoreip list before PermitRootLogin no takes effect. I've added force_handlers = True in ansible.cfg to ensure the \"restart fail2ban\" handler will run and ignoreip will take effect, even if the playbook fails before completion. We could have added a force_handlers: True parameter in server.yml but that doesn't seem better necessarily, and it would cause Ansible < 1.9.1 to fail. Older versions don't fail if it is specified in ansible.cfg.\nBumping Ansible requirement. force_handlers is only available in Ansible >= 1.9.1. I bumped the Ansible requirement in the README to >=1.9.2 (from 1.9), skipping 1.9.1 because of this bug. If you prefer to leave it at 1.9 that would work, but the force_handlers wouldn't be in effect for people on < 1.9.1.\n\"Remote server setup\" section in README. Many support requests boil down to users not having configured SSH or SSH agent forwarding. I added explicit mention of each to the \"Remote server setup\" section in the README. You can review my wording.\n. @louim Thanks for tip about only adjusting the PR via new commits, keeping incremental changes clear.\nSSH agent forwarding. Also, thanks for pointing out that ForwardAgent yes is not required in ssh-config. This led me to review discourse threads regarding problems with SSH agent forwarding. People didn't always report a specific fix, but when they did, it was mac users needing to add their ssh key password to Keychain.\nThe SSH keys wiki mentions the Keychain issue, but not prominently. We can make it more prominent there in the wiki. Personally, I'm still inclined to make it explicit in the README so that users isolate and fix as many non-Trellis problems as possible before running their first Ansible command.\nWould the following feel acceptable, or do others feel it would clutter up the README?\ndiff\n3. Configure SSH\n  * Ensure you can SSH to your server, e.g., by running `ssh root@server_ip_or_domain`\n- * Ensure you can clone a private repo from your remote server using [SSH agent forwarding](https://developer.github.com/guides/using-ssh-agent-forwarding/).\n+ * Mac OS X users must have added their SSH key password to Keychain by running `/usr/bin/ssh-add -K /path/to/private/key`.\n  * Specify public SSH keys for `users` in `group_vars/all`. See the [SSH Keys wiki](https://github.com/roots/trellis/wiki/SSH-Keys).\n  * Consider setting `sshd_permit_root_login: \"no\"` in `group_vars/all`. See the [Security wiki](https://github.com/roots/trellis/wiki/Security).\nIP lookup on Windows.\n\nwill the DNS resolver work from inside the VM when run from windows user?\n\nI'm afraid it'll be a few days before I can set up tests for this. It would be super helpful if one of our Windows users could check this. After you run server.yml from this PR's branch, does your /etc/fail2ban/jail.local include your IP at the end of the ignoreip parameter?\n. @louim Thanks for helping me recognize that the note about Mac users adding their SSH key password to Keychain would be too specific for the general users' README. It struck me as common, but stepping back, I see that it is \"common\" only when looking at specific users in a specific situation: when trellis fails to clone a repo. So, I agree it seems better to address it in an error message specific to that situation.\nI've added a commit trimming back the changes I made to the README. I also removed the README section about secure-root.yml, which I had forgotten to remove initially. Future PRs can address how to help users with SSH problems.\n. Thank you for all your great help @louim !\n. squashed\n. @franzliedke Good job finding the --user=root workaround and digging in to what must have been a frustrating issue. As it turns out, I don't think it's a bug. So, could we continue any discussion at https://discourse.roots.io so our messages don't ping subscribers to the bug tracker?\nTrellis and Ansible do not remember the user across runs. You'll notice this PR introduces a task Determine whether to connect as root or admin_user. If root can connect, the rest of the playbook tries to run as root. If root fails, it tries admin_user instead.\nIf the playbook suddenly seemed to only try admin instead of root for new servers, and you hadn't changed anything with Trellis, naturally you'd figure that Trellis was remembering the admin user from a previous server (e.g., where root login had been disabled). However, I suspect what happened was you updated your Ansible version, e.g., to 2.3.\nThere have been a couple Ansible updates that have \"broken\" the Trellis feature of choosing root vs. admin_user based on a connection test. \n #631 (Aug 6, 2016) fixed a problem in response to the release of Ansible 2.1.1.0\n #813 (Apr 15, 2017) fixed a problem in response to the release of Ansible 2.3\nI suggest you update your Trellis version and see if Trellis then is able to correctly choose the root user. Note that the latest Trellis requires the recently released Ansible 2.4 in order to accommodate revised code required to not cause deprecation warnings in 2.4. If you prefer to stay on Ansible 2.3, only update your Trellis to 8a4677c\nPlease don't respond here. If you have any trouble, post at https://discourse.roots.io and someone will try to offer support. Post your Ansible version (ansible-playbook --version), your Trellis version (e.g., post the topmost entry in your Trellis CHANGELOG.md), and your verbose log output  from running ansible-playbook server.yml -e env=production -vvvv. If it turns out to be a bug, we'll gladly try to fix it here in the GitHub bug tracker.. Thanks for reporting this, @BrandonShutter \nBack in roots/trellis#274 I didn't anticipate the scenario that a failed connection for root could still give a return code of 0, but it does on an Ubuntu box on AWS.\nThe following changes to roles/remote-user/tasks/main.yml work for me when I test on an AWS EC2 instance. Would you mind testing whether they work for you?\n``` diff\n\n\nname: Determine whether to connect as root or admin_user\nlocal_action: shell ssh -o PasswordAuthentication=no root@{{ inventory_hostname }} \"echo root\" || echo {{ admin_user }}\nlocal_action: shell ssh -o PasswordAuthentication=no root@{{ inventory_hostname }} \"echo can_connect\"\nfailed_when: false\n   changed_when: false\nregister: remote_user\n\nregister: root_status\n\n\nname: Set remote user for each host\n   set_fact:\n\nansible_ssh_user: \"{{ remote_user.stdout }}\"\nansible_ssh_user: \"{{ (root_status.stdout == 'can_connect') | ternary('root', admin_user) }}\"\n```\n\nThe changes above assume that if root can connect, the echo can_connect command will run as expected. I'd love someone to suggest a more reliable indicator of success/failure in root SSH connection, given that we can't rely on return codes.\n. PR in #290. I appreciate your time reviewing this @BrandonShutter @louim @swalkinshaw \n. @nathanielks Thank you for looking this over and helping me think it through.\n@louim Thank you so much for reviewing this and for explaining the benefits so well. I'll emphasize one you already mentioned. Currently, users can only access development hosts via vagrant commands, or by creating/editing host files. The proposed changes make it possible to access any host, using the default host file and Ansible commands.\nAbandoned Approaches\nSymlinks. When I vagrant up two different Vagrant VMs from different Trellis projects, each has the Trellis default IP 192.168.50.5. The first VM has port 22 => 2222 and the second has port 22 => 2200. The .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory shows ansible_ssh_port=2222 for both VMs, so a symlinked host file won't resolve the dynamic port issue. One inventory should show port 2200, but shows incorrect port 2222. Edit: When vagrant runs the Ansible provisioner, it will update the port values in the inventory file. The problem is this: If vm A is running, and you vagrant up a halted vm B, this vm B may have its port reassigned. However, vm B's port won't be updated in the inventory file because vagrant doesn't run the Ansible provisioner on a vagrant up for a machine that has already been provisioned. So, we can't just rely on the vagrant_ansible_inventory. We must go get the latest ssh-config info each time we want to run ansible-playbook on a dev vm directly (vs indirectly via vagrant provision).\nOmitting port from host file. @nathanielks and @austinpray helped me understand that if/when there is only one VM, there is no need to specify the port. An SSH connection is still possible to example.dev because the /etc/hosts connects this domain to 192.168.50.5 and the default port 22 will forward fine. In my basic testing, the SSH connection became unreliable when I added a second VM on the same IP, with different domain name and port forwarding. We could tell users who want multiple VMs to change the config.vm.network :private_network, ip: '192.168.50.5' in the Vagrantfile, but I'd rather not require users to change anything.\nNew Approach: Create SSH Config from vagrant ssh-config\nI decided to grab all ssh config info provided by the command vagrant ssh-config (initial inspiration). In addition to capturing the correct dynamic port, it also includes other useful settings like UserKnownHostsFile /dev/null and StrictHostKeyChecking no, which seem acceptable for the local vm. Users wanting these will no longer have to add them manually to their ~/.ssh/config.\nI made a preliminary consolidate-hosts branch I'll use for testing. It demonstrates\n- a single host file named hosts\n- modified hosts parameters for playbooks\n- ansible.cfg specifying default hosts file\n- ansible.cfg adds a ssh-config file for dev hosts (in ssh_args)\n- new ssh-config-dev role populates ssh config file for dev hosts. It isn't meant to be touched by users, so it is tucked away at roles/ssh-config-dev/files/config (but whatever)\nAlternatives I Turned Down \n- Too bad it's not possible to specify ansible_ssh_config nor ssh_args by host or group.\n- ANSIBLE_SSH_ARGS can only be set globally, not using the environment keyword.\n- There are ideas out there to cat multiple ssh config files, ruby gems to assemble files in .ssh/config.d/, and ansible galaxy roles to build an ssh config file from your inventory, but I think the ssh-config-dev role requires less from users and doesn't mess with their existing ~/.ssh/config.\nReview: How this New Approach Affects Users\n- This approach has all the benefits described\n- The negative is still that existing users have the one-time task of transfering hosts to new hosts file\n- The slightly negative is that users have to remember to switch their server.yml command:\ndiff\n- ansible-playbook server.yml -i hosts/staging\n+ ansible-playbook server.yml -e env=staging\nHosts File vs. Hosts Directory\nMy test branch uses a single file named hosts. There are few enough hosts listed that it still looks very manageable, and I like seeing all hosts at once. If prefered, hosts could be a directory, either with that single file, or separate files per environment.\n@nathanielks pointed out to me that one traditional argument for separate host files per environment is that Ansible would only ever know about the hosts in the host file specified, avoiding risk of changes in one environment accidentally spilling over to another. This proposed consolidation makes all hosts available, if desired, but the existing playbooks isolate hosts via the hosts parameter in each playbook. \nFor example, dev.yml has hosts: web:&development indicating that it can only ever run on a host that appears in both the web and development groups (no environment spillage). Similarly, server.yml and deploy.yml have hosts: web:&{{ env }}, so they can only ever run on the env the user specifies. There is no default for env in this case, so if the user fails to specify env from the CLI, the playbook will error and halt, affecting zero environments.\nWeb servers vs. DB Servers\nAt present, the Trellis default has the web server and db server on a single box. So, for now, the host file could omit the [db] group in the example above, or just list dummy example hosts for [db] (like I did in my test branch). Although at present the hosts parameter in the playbooks could omit the web group (e.g., dev.yml could have hosts: development), keeping web in there (e.g., hosts: web:&development) could make Trellis more easily extensible for users wanting to incorporate db servers.\nOther Notes\n@louim thanks for pointing out the Ansible static inventory section in the vagrant docs. I hadn't remembered that. Perhaps it will come in handy in all of this.\nI also liked your idea for naming the separate host files local and remote. Of course! Why didn't I think of that? In this case, I think we can get away with a single host file however. With these updated thoughts, do you have preference for a single file or separate files per environment?\nA number of your comments addressed running server.yml on a development host. I would have only expected server.yml to be run on staging or production hosts, and only dev.yml on development hosts. Thank you for pointing out that if we decide to accommodate development hosts with server.yml, we may need to do things like\n- accommodate port in \"Determine whether to connect as root or admin_user\" task\n- add admin_user: vagrant to group_vars/development\n- maybe more\n. I'm also inclined to keep the default key because I'm guessing that would help Trellis work out of the box for most users.\nI like the default(omit) filter @louim. It looks like it would resolve the issue here, and more...\nPerhaps Trellis users who will not use deploy.yml shouldn't have to supply a key for web_user. In this case, dev.yml and server.yml don't need to load the key on the server and default(omit) would prevent them from failing due to a missing key. \ndefault(omit) could apply to admin_user too, with caution. Suppose a user disables root login for a remote VPS and has no pub key file for admin_user. server.yml would finish without loading a pub key on the server for admin_user. Neither root nor admin_user could connect via SSH.\nTo deal with this, we could finish the users role with a fail task causing server.yml to fail when all these conditions are met:\n- not vagrant vm\n- sshd_permit_root_login = \"no\"\n- server has no key for admin_user\n. @chriszarate \n\nPiping to default(omit) doesn't work. The lookup throws an error (as opposed to just an undefined value)\n\nThis led me to test. Despite using default(omit), I still got the lookup error for missing local key files, causing the playbook to fail. Maybe you've found a way around it?\nWith just preliminary testing, the idea below\n- successfully skips if  local key file is missing (see when: statement on task)\n- spares Trellis users from having to see lookup(stuff) in group_vars/all\n``` yaml\ngroup_vars/all\nusers:\n  \u22ee\n    keys:\n      - path: ~/.ssh/id_rsa.pub\n      - url: https://github.com/username.keys\n```\n``` yaml\nroles/users/tasks/main.yml\n\nname: Add SSH keys\n  authorized_key: user=\"{{ item.0.name }}\"\n                  key=\"{% if item.1.url is defined %}{{ item.1.url }}{% else %}{{ lookup('file', item.1.path) }}{% endif %}\"\n  with_subelements:\nusers | default([])\nkeys\n  when: item.1.url is defined or lookup('pipe', '[ -f ' + item.1.path + ' ] && echo \"file_exists\" || :') == 'file_exists'\n```\n\n\n\nNot super pretty.\nStill could use an additional task (or something) to check that the server has a pub key for admin_user if root login will be disabled.\n@austinpray \n\nBut won't this lead to a tug of war? Every time each individual maintainer provisions a server the other maintainers will lose access right?\n\nI'd have to double-check, but I think authorized_key just concatenates keys into ~/.ssh/authorized_keys on server, only removing a key if the parameter state=absent.\n. Here's an instance of the problem.\n. Thanks @louim! That's good news. I should have researched this more thoroughly.\nI like your idea better, especially because it will avoid altering the structure of the shared/source directory for existing Trellis projects. So, I switched the PR to just be a task to run git remote set-url. We can remove the task when Ansible core is updated.\n. Thanks for the additional feedback @louim and @swalkinshaw. I've revised the PR. Now the git remote url is only updated if necessary. \n. Thanks @swalkinshaw. I adjusted the when: statement for the \"Update git remote URL\" task.\n. squashed\n. @austinpray pointed out that \"the synchronize module uses the -a flag by default.\"\n\"This is equivalent to -rlptgoD\" (man page).\n-r, --recursive: (keep)\n-l, --links: (keep) copy symlinks as symlinks\n-p, --perms: (drop) this is the problem, so we'll set the parameter perms=no\n-t, --times: (keep) preserve modification times\n-g, --group: (drop) preserve group. We'll set the parameter group=no.\n-o, --owner: (drop) preserve owner (super user only). We'll set the parameter owner=no just to be safe (?).\n-D The -D option is equivalent to --devices --specials\n--devices: (keep?) \"transfer character and block device files to the remote system to recreate these devices\"\n--specials: (keep?) \"transfer special files such as named sockets and fifos\"\nIn my tests source permissions were synced over, but the owner:group seemed to always end up web:www-data. I tried adding perms=no group=no owner=no to our synchronize task and the read and write permissions were no longer synced. I don't understand, however, why the executability was always synced, even if I ran the rsync command manually. Maybe it's just my machine or something I'm not understanding. \nI'm pretty inexperienced with permissions and I'm left wondering whether some people would actually want their local files' custom permissisons to sync over (?). \nIf we want to explicitly set permissions, adding the following would set directories to 755 and files to 644:\nrsync_opts=--chmod=Du=rwx,--chmod=Dg=rx,--chmod=Do=rx,--chmod=Fu=rw,--chmod=Fg=r,--chmod=Fo=r\n(I didn't have to repeat the --chmod= on a manual rsync, but it seemed necessary with the Ansible synchronize module.)\nWould we want to set permissions explicitly? Are those the permissions we'd want (D755,F644)?\n. Here's where I'm headed, in case anyone has feedback: \ndiff\n - name: Copy project local files\n-  synchronize: src=\"{{ item.src }}\" dest=\"{{ deploy_helper.new_release_path }}/{{ item.dest }}\"\n+  synchronize: src=\"{{ item.src }}\"\n+               dest=\"{{ deploy_helper.new_release_path }}/{{ item.dest }}\"\n+               group=no\n+               owner=no\n+               rsync_opts=--chmod=Du=rwx,--chmod=Dg=rx,--chmod=Do=rx,--chmod=Fu=rw,--chmod=Fg=r,--chmod=Fo=r\n   with_items: project_local_files\n- perms=no is unnecessary when the --chmod= options are included\n- group=no should be necessary, but on my setup, owner and group never get synced, so I'm unsure.\n- owner=no seems less critical because it applies only if super user.\nAt this point, I'd play it safe and include both group=no and owner=no. Feedback and testing welcome.\n. I really like this! \nThis vault branch demos moving some variables to group_vars/<environment>/vault.yml files.\nTo start using Ansible Vault, users would just \n- copy .vault_pass.example to .vault_pass, edit the password, and probably chmod 600 .vault_pass\n- remove .example from the end of vault_password_file = .vault_pass.example in  ansible.cfg\n- encrypt vault.yml files by running ansible-vault encrypt group_vars/all/vault.yml group_vars/development/vault.yml group_vars/staging/vault.yml group_vars/production/vault.yml\n/cc @nathanielks\n. A few more comments about that Ansible vault branch.\nIt's optional\nThe playbooks will still run fine if users choose not to encrypt the vault.yml files.\nFinding variable definitions\nIf you're looking at an ansible task, see a variable, then search for where the variable was defined in your code/project, your search won't find that definition if it is in a file encrypted by Ansible vault. \nQuoting Raphael Campardou:\n\nLeaf encryption was (is) a feature request, but in the meantime, there is an elegant way of keeping it both readable and secure: nested variables. For every sensitive variable, you create a prefixed double that goes in an encrypted file.\n\n``` yaml\nvar_file\ndb_password: {{ vaulted_db_passord }}\nand for a dctionnary\naws: \n  - \"access_key_id='abcdefgh'\"\n  - \"secret_access_key='{{ vaulted_aws_secret_access_key }}'\"\nvault_file\nvaulted_db_passord: a_super_secret\nvaulted_aws_secret_access_key: the_aws_secret\n```\nIn the example above, you might be searching for where db_password was defined and your search would find it. And there you'd realize that it's real value is defined in vaulted_db_passord.\nI tried that but ran into trouble with the wordpress_sites dict (can't remember enough to explain). However, my \"vaulted\" variables are prefixed by vault. An example is password=\"{{ vault.mysql_root_password }}\". At least that prefix lets you know that the variable is defined in one of the encrypted vault.yml files.\nThe exception in my branch is group_vars/all/vault.yml which has just mail_password and sudoer_passwords. We optionally could give those prefixes: vaulted_mail_password and vaulted_sudoer_passwords.\nAvoiding committing unencrypted vault files\nThe README or wiki could mention the option for users to avoid committing unencrypted passwords using this script:\n\nI wrote a simple pre-commit hook that checks if a file called \"vault-something\" is encrypted before committing. If not, it displays a helpful message.\n -- Raphael Campardou\n. @nathanielks Yeah, there's a real argument for trying to minimize the use of hashes. Ansible does allow a ansible.cfg setting hash_behaviour=merge but it appears that variable precedence creates some gotchas around when hashes will be merged vs. entirely overwritten. Here are a couple examples: one, two. The ansible project has a number of issues and PRs about it, so I'm not sure the current state.\n\nI need to use a hash for variables I extracted from wordpress_sites because the \"site key\" in the vault hash allows me to connect the variable to the \"site key\" in wordpress_sites hash. Here's an example:\nyaml\nmysql_db: name=\"{{ vault[item.key].db_name | default(item.key) }}\"\n\u22ee\nwith_dict: wordpress_sites\n(I didn't try it, but maybe setting hash_behaviour=merge would allow a second wordpress_sites hash in vault.yml to merge with the original wordpress_sites hash. That might be asking for trouble.)\nThe only way I see around using a hash for these wordpress_sites variables is to require users to manually add a site key prefix for each, which doesn't seem like a good idea: \nyaml\nexample.com_db_name: example_staging\nexample.com_db_user: example_dbuser\nexample.com_db_password: example_dbpassword\n\u22ee\nmysql_root_password was the only variable not originally from wordpress_sites that I put in the vault hash. Seems fine to pull it out of the hash and prefix it: \nvaulted_mysql_root_password\n. I hadn't thought we'd want any N - by design because it seems like a site would simply fail to load under conditions such as these:\n- we use the N - by design for https://  -->  http://\n- someone has their site listening only on port 80 at http://example.com\n- a user erroneously navigates to https://example.com but we're not listening on port 443\nI like the idea of thinking of it like toggles.\nwww = true/false forces www or non-www\nwordpress_sites[site].ssl.enabled = true/false forces https or http\nEdit: I know there's plenty I don't understand about SSL, Strict-Transport-Security, etc.\n. I see, thanks! Downgrading connections is bad practice and brings logistical problems with certs.\n. We could automatically redirect the opposite of each item in wordpress_sites[site].site_hosts (referring to www and non-www as opposites). This avoids requiring users to toggle anything.\nyaml\nhost: www.example.com\nhas_www: \"{{ host | match('^www\\\\.(.*)') }}\" # returns true/false\nwww_removed: \"{{ host | regex_replace('^www\\\\.(.*)', '\\\\\\\\1') }}\" # returns hostname without www\nhost_to_redirect: \"{{ has_www | bool | ternary(www_removed, 'www.' + host ) }}\"\nWe can't just put those variables in roles/wordpress-setup/default/main.yml because host will not be defined. So, if you string all of them into one long logic, it's not pretty but it works. It should redirect all the target bold Ns from above.\n``` diff\nroles/wordpress-setup/templates/wordpress-site.conf.j2\n\n{% for host in item.value.site_hosts if strip_www %}\n{% for host in item.value.site_hosts if www_redirect %}\n  server {\n    {% if item.value.ssl is defined and item.value.ssl.enabled | default(false) -%}\n      listen 443 ssl spdy;\n    {% else -%}\n      listen 80;\n    {% endif -%}\nserver_name www.{{ host }};\nserver_name {{ host | match('^www\\.(.)') | ternary(host | regex_replace('^www\\.(.)', '\\1'), 'www.' + host ) }};\n      return 301 $scheme://{{ host }}$request_uri;\n  }\n  {% endfor %}\n```\n\nUsers can turn off the automatic redirect by setting www_redirect: false\nBackreferences are escaped differently in the two examples (\\\\\\\\1 vs. \\\\1). Also, bool filter is not needed in 2nd example.\n. docs in roots/docs#4\nAfter this PR, commands will use -e env=<environment> instead of -i hosts/<environment>. This PR initiates playbooks with a task to \"Ensure environment is defined,\" giving a helpful message if not. Otherwise, omitting the new -e env would produce the message skipping: no hosts matched, which is less clear. We can remove this task in the future once most users have transitioned to the new command.\n. @swalkinshaw Re: updating windows.sh, I figure the ansible-playbook command is the only candidate for consideration.\nInventory. This PR removes the -i everywhere except in windows.sh. When ansible runs dev.yml within a Vagrant VM on Windows, I think it must use the chmod -x ${TEMP_HOSTS}/* copy made by windows.sh. So, I think windows.sh must retain the -i to override ansible.cfg's new default inventory = hosts.\nenv variable. windows.sh runs the dev.yml playbook which is actually the only playbook that doesn't use the env variable introduced in this PR. Instead, dev.yml specifies the environment group directly: \nhosts: web:&development\nSo, I don't think windows.sh needs to add the -e option for defining env.\nI don't notice anything else that might need adjustment in windows.sh. Let me know if I missed anything.\n. Added changelog entry and squashed\n. @scherii \nSetting the stage\n./deploy.sh<group><site>\nBy specifying the group in your command, you select a subset of all the hosts in your hosts directory, specifically the hosts subset that are both in the group (or env) you specified and  the web group.\nThe Ensure site is valid task/error checks that the site in your command is listed in the wordpress_sites that are applicable to the group specified.\nFor example, the default command ./deploy staging example.com checks that example.com is in the staging group's wordpress_sites (i.e., in group_vars/staging/wordpress_sites.yml). \nThe error you saw\nIf you ran the command ./deploy.sh alpha alpha.domain.tld and it gave the message Site```alpha.domain.tld```is not valid, that indicates that the alpha group's wordpress_sites didn't include the site name alpha.domain.tld. To try to help, it reports the sites it can find for the alpha group: Available sites to deploy: beta.domain.tld.\n(sounds like you've already solved things, but...)\nTo fix this, there are several ways you could associate a list of wordpress_sites to the alpha group (to be sure that alpha.domain.tld is in the list). You could define them in group_vars/alpha/wordpress_sites.yml. Alternatively, you could leave them defined in group_vars/staging/wordpress_sites.yml but adjust your hosts/staging like this:\n```\n[alpha]\n111.xxx.xxx.xxx\n[beta]\n122.xxx.xxx.xxx\n[web]\n111.xxx.xxx.xxx\n122.xxx.xxx.xxx\n[staging]\nalpha\nbeta\n```\nThere are probably other possible approaches too. Check out hosts and groups at Ansible docs.\nUsing IP vs domain\nAs for IP vs domain, I think you're saying that you used to be able to use IPs in hosts/staging but now it appears you must use domain names. \nI think you can still use IPs in your hosts file. Given the example hosts file above, if you were to issue the command ./deploy.sh alpha example.com it will deploy the example.com site to the host 111.xxx.xxx.xxx. And of course ./deploy.sh beta example.com will deploy to 122.xxx.xxx.xxx.\nYou might also be able to use those same commands with this simplified hosts file (untested):\n```\nalpha ansible_ssh_host=111.xxx.xxx.xxx\nbeta ansible_ssh_host=122.xxx.xxx.xxx\n[staging]\nalpha\nbeta\n[web]\nalpha\nbeta\n```\n\nI hope that addresses your point. If you feel there is a bug or fix that is needed, feel free to respond here. If you have questions or would like assistance troubleshooting, check out Roots discourse.\n. Thank you @austinpray. I've added your patch. On an earlier version I had committed a default config file to the repo, so its parent directory existed: roles/ansible-ssh/files. But I ultimately added the config file to the .gitignore so, then the files directory never made it into the repo. \nI've added the task you suggested, but immediately before the rsync task that would require the directory be present.\n. Problem: The remote-user manual ssh test could inappropriately show that root cannot connect under this combination of conditions: \n- a host appears in the ansible hosts file as a nickname only, with no ansible_ssh_host (no IP)\n- the host's IP is in a HostName parameter in one of the ssh_config_files \"includes\", but not in the default ~/.ssh/config\n- the local action ssh test runs ssh root@nickname using default ~/.ssh/config (no entry for nickname)\n- connection fails with stderr ssh: Could not resolve hostname nickname\nResolution: I added a commit with ~~two changes~~ one change to resolve this.\n- I moved the ansible-ssh role before the remote-user role. This assembles the ssh_config_files into one file at roles/ansible-ssh/files/config. Now the nickname host's HostName (IP) is available. \n- Edit: #321 was merged, so this second step was not necessary. ~~I adjusted the manual ssh root connection test to use this custom ssh config file by adding -F roles/ansible-ssh/files/config. Instead of adding -F, I'd rather just rebase this on top of #321 (if/when it's merged), which seems superior to the manual ssh check.~~\n. Closing. The proposed role is cool if and when you need it. However, only a small minority of users would need it. Anyone is welcome to turn it into a galaxy role.\n. It's a bit over my head, but I suspect nginx starts its master process as root and uses that user to write the first log, despite our nginx_user: www-data. The access.log seems like it should be the active log, but strangely has file size 0, probably because current traffic is actually being written to acccess.log.1, as I watched happen with my logs. Perhaps this is the same issue:\n\nnginx logging to access.log.1 instead of access.log\nThe problem was that nginx was not releasing the file handle to the log file upon receiving the -USR1 signal from kill. Long story short, the reason it was not reloading the log files was because the /var/log/nginx folder was not owned by the same user as the nginx worker processes.  I have no idea how that changed (perhaps because this server was remade recently), but changing the folder to be owned by the same user as the nginx worker processes (and fixing the logrotate file to make new logs as web) fixed the issue.\n-- Ben Torell\n\nWe could change ownership and permissions of the new logs created by logrotate:\ndiff\n-       - create 0640 {{ web_user }} {{ web_group }}\n+       - create 0644 root root\nBut that's actually the default, so we could just omit the create.\nThat doesn't solve the potential problem that the logs directory has different ownership than the nginx worker processes. Maybe the logs folder will have to be owned by root?\n\nLogs should be controlled by root and handled by the master process.\n-- nginx Ubuntu\n\nI tried forcing the logrotate by running /usr/sbin/logrotate -f /etc/logrotate.conf with the logs dir set to root:root, then again as root:www-data. Each time I had matching values for the create parameter. However, real time logging still happened in access.log.1 instead of access.log. The first time I ran the manual logrotate per server build, I got this error: error: error running shared postrotate script for '\"/srv/www/**/logs/*.log\" '. Each time I ran the command again and it appeared to rotate logs without error (?).\nDo I understand correctly that all the logging is actually happening, just with different file ownership/permissions and different file naming than we expect? \n. @mxxcon I like that approach but I couldn't implement it directly because wordpress_sites is a hash. \nThere would be no problem with variables such as vaulted_db_name for a Trellis project with a single site. When there are multiple sites, that variable must somehow account for which site it corresponds to. The big challenge is how to loop over multiple sites in wordpress_sites when some values are vaulted. \nYou'll see how I approached the issue by searching this PR's diff for wordpress_sites_vault[item.key].\nI'd be delighted if anyone would offer a better working implementation. \n. Docs at roots/docs#5. I think this is ready. Thank you, @mxxcon, your comments inspired good revisions.\nA Few Updates\nI made two changes for better discoverability and to provide the full picture in wordpress_sites.yml.\n1) I switched to using the structure @mxxcon suggested (pseudo leaf, recommended by ansible) for scalar variables (not used in loops), e.g., mail_password: \"{{ vault_mail_password }}\".\n2) For the hash variables (used in loops), I added their names in comments where the variables would have appeared in the hash if left unencrypted. That way the unencrypted file shows the full picture and the variables still show up in searches.\nyaml\nwordpress_sites:\n  example.com:\n    \u22ee\n    env:\n      wp_home: http://example.dev\n      wp_siteurl: http://example.dev/wp\n      wp_env: development\n      # Define the following variables in group_vars/development/vault.yml\n      # db_name:\n      # db_user:\n      # db_password:\n      \u22ee\nOne other change worth noting was that I removed the .vault_pass.example file and the related example default in ansible.cfg, changing my position on this decision.\nVault with Variables in a Hash\nI believe I've used a good strategy for handling the encrypted variables from the wordpress_sites hash. I don't believe the pseudo leaf structure can be applied effectively to a hash that will be used in tasks that loop. Here are a few examples of failed or suboptimal implementations of the pseudo leaf structure to the wordpress_sites hash.\n``` yaml\n1 - Fail: If all sites use vault_db_password, they all have the same password\nwordpress_sites:\n  site-1.com:\n    db_password: \"{{ vault_db_password }}\"\n  site-2.com:\n    db_password: \"{{ vault_db_password }}\"\n2 - Suboptimal: Requiring users to edit variable names means more work and more risk for error\nwordpress_sites:\n  site-1.com:\n    db_password: \"{{ vault_db_password_1 }}\"\n  site-2.com:\n    db_password: \"{{ vault_db_password_2 }}\"\n3 - Fail: The item.key variable is only defined in the scope of the looping task and will be undefined in the more global scope of the example below\nwordpress_sites:\n  site-1.com:\n    db_password: \"{{ vault_wordpress_sites[item.key].env.db_password }}\"\n  site-2.com:\n    db_password: \"{{ vault_wordpress_sites[item.key].env.db_password }}\"\n``\n. As @swalkinshaw suggested, I removed a few vars from the vault: \n- WP'sadmin_userandadmin_email- env vars:db_useranddb_name`\nAs @mxxcon suggested, I split out vault_sudoer_passwords into the separate group_vars/<environment>/vault.yml files.\nI updated the docs PR to reflect the above changes.\n. This works in my tests. That custom error message will be helpful.\n. I added a commit with adjustments to handle this scenario:\nImagine root login was disabled on a previous run of server.yml. Now someone removes sudo from their admin_user's groups and reprovisions. The \"Setup users\" task would remove the admin_user from the sudo group and now Ansible has no sudoers. To prevent that, we need to verify that sudo is in groups (and potentially fail) before running \"Setup users\". \nHowever, the check for whether admin_user can connect to the server must be run later, after the \"Add SSH keys\" task.\nSo, our checks for sudo and general connectivity are necessarily separated within the users role.\nNote that it might be more convenient to users if the sudo group check were performed sooner, perhaps in the common role, instead of unnecessarily waiting so far into the playbook to check and fail. Conceptually, however, the check fits in the users role, so that's where I left it. \n. updated CHANGELOG and squashed\n. Afraid I don't know enough about it to be helpful. Except I did notice that although supposedly you can set client_max_body_size in the http, server, or location blocks, some say you must set it in all three (doubtful). I bring it up just to comment that I believe this switches client_max_body_size from a location block to a server block. If you've tested that this works and solves the problem, @chriszarate, then sounds good to me. Thanks for your work on it!\n. Could this PR also remove the the existing \"Copy project local files\" task and the corresponding project_local_files default variable? They seem obsolete now that this PR's \"Copy project local files\" task demonstrates the new recommended approach of using deploy hooks.\n. Good idea. I removed project_local_files and the sync task that used it. #397 will demonstrate the recommended method of syncing via deploy hooks.\n. #435 offers one option for making the ip lookup customizable.\n. @pacotole would love to have you test the proposed fix in #692 if you're interested. Thanks @retlehs. I adjusted to allow redirects for subdomains:\ndiff\n- {% for host in item.value.site_hosts if item.value.www_redirect | default(true) and host.split('.') | difference('www') | count <= 2 %}\n+ {% for host in item.value.site_hosts if item.value.www_redirect | default(true) %}\n. Closing. #455 provides a better solution.\n@swalkinshaw pointed out that by adding ansible_connection=local for development, this PR could interfere with the SSH connection needed to run dev.yml manually via ansible-playbook commands.\n. This PR simplifies the command at the end of windows.sh:\ndiff\n- ansible-playbook ${ANSIBLE_PATH}/dev.yml -i ${TEMP_HOSTS}/development --sudo --user=vagrant --connection=local\n+ ansible-playbook dev.yml\n- can use relative path to dev.yml because script already changed to that directory\n- -i - can use default hosts file now that hosts are synced into place with the right permissions\n- --sudo - already indicated as play parameter in dev.yml\n- --user=vagrant - already indicated as play parameter in dev.yml\n- --connection=local - I moved this to hosts/development which is only used for Windows anyway\n. This PR originally synced the hosts directory over the top of the vm's hosts directory, just so it would have specific mount_options (i.e., no execute bit set for hosts files). The latest commit removes that sync folder and instead applies these mount_options to the primary vagrant sync folder that is already there.\n. @QWp6t correctly pointed out that mount_options: ['dmode=776', 'fmode=664'] on the primary vagrant sync folder would cause deploy.sh to not execute. I added a commit switching back to the approach of syncing the hosts directory with the needed permissions.\n. Good idea! Docs in roots/docs#14\n. right on @remailednet \nI've removed the ternary that accommodated Ansible 1.9. This is thankfully much simpler now.\n. Closing. I will resubmit a revision that omits the option of auto-detecting and adding hostkeys for hosts in composer.json. It seems like a bad idea do a lot of extra work to create a feature that makes people vulnerable to MITM attacks (while running ssh-keyscan -t to collect hostkeys during provision). Better to just stay secure. The revision will allow users to manually list hostkeys in a new known_hosts list variable, then Trellis will load them.\n. Edit: A slightly different version Implemented in #751\nI no longer plan to revise and resubmit. Instead, users can implement this using Trellis deploy hooks. \n1 - Define known_hosts in group_vars/all/main.yml (or maybe deploy.yml), e.g., \n```\nHost keys to add to known_hosts, e.g.,\n- git host for Bedrock-based project (repo variable in wordpress_sites)\n- git hosts in Bedrock project's composer.json\nknown_hosts:\n  - name: github.com\n    key: github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A7hRGmdnm9tUDbO9IDSwBK6TbQa+PXYPCPy6rbTrTtw7PHkccKrpp0yVhp5HdEIcKr6pLlVDBfOLX9QUsyCOV0wzfjIJNlGEYsdlLJizHhbn2mUjvSAHQqZETYP81eFzLQNnPHt4EVVUh7VfDESU84KezmD5QlWpXLmvU31/yMf+Se8xhHTvKSCZIFImWwoG6mbUoWf9nzpIoaSjB+weqqUUmpaaasXVal72J+UX2B+2RPW3RcT0eOzQgqlJL3RKrTJvdsjE3JEAvGq3lGHSZXy28G3skua2SmVi/w4yCE6gbODqnTWlg7+wC604ydGXA8VJiS5ap43JXiUFFAaQ==\n  - name: bitbucket.org\n    key: bitbucket.org ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAubiN81eDcafrgMeLzaFPsw2kNvEcqTKl/VqLat/MaB33pZy0y3rJZtnqwR2qOOvbwKZYKiEO1O6VqNEBxKvJJelCq0dTXWT5pbO2gDXC6h6QDXCaHo6pOHGPUy+YBaGQRGuSusMEASYiWunYN0vCAI8QaXnWMXNMdFP3jHAJH0eDsoiGnLPBlBp4TNm6rYI74nMzgz3B9IikW4WVK+dc8KZJZWYjAuORU3jc1c/NPskD2ASinf8v3xnfXeukU0sJ5N6m5E8VLjObPEO+mN2t/FZTMZLiFqPWc/ALSqnMnnhwrNi2rbfg/rd/IpL8Le3pSBne8+seeFVBoGqzHM9yXw==\n```\n2 - Define the deploy hook variable under vars: in deploy.yml:\ndeploy_update_before: \"{{ playbook_dir }}/deploy-hooks/update-before.yml\"\n3 - Create a new file: deploy-hooks/update-before.yml with these contents:\n```\n\nname: Add known_hosts\n  known_hosts:\n    name: \"{{ item.name }}\"\n    key: \"{{ item.key | default(omit) }}\"\n    path: \"{{ item.path | default('/home/' + web_user + '/.ssh/known_hosts') }}\"\n    state: \"{{ item.state | default('present') }}\"\n  with_items: \"{{ known_hosts | default([]) }}\"\n```\n\nNotes:\n- This deploy hook approach will only affect remote servers, not the known_hosts on the local dev VM. \n- This demos name and key options but will accommodate other options if defined.\n- You could set accept_hostkey: no (description) so that the clone task won't run a ssh-keyscan which could be vulnerable to a MITM attack.\n. Looks good to me!\nProvision and deploy worked for me on 2.0.0.2, even with space in path to Ansible files.\nExcited for this!\n. Additional commit\n- code style better resembles python and Ansible conventions\n- filter now accommodates one or more host names\n- filter provides informative error message if input value is not string or list of strings\nPros of new filter\n- makes the wordpress-site.conf.j2 template much more readable, sparing most users from seeing elaborate jinja filter sequences\n- initiates the use of custom filters, bringing their power to Trellis\nCons of new filter\n- adds far more lines of code overall than if we stick to existing filters\n- probably wouldn't be used anywhere but in this instance, so it is not a benefit to DRY code \nBelow is an alternative to this PR's reverse_www filter. It may be the better solution for the www redirects issue at hand.\n``` diff\n {% if item.value.ssl is defined and item.value.ssl.enabled | default(False) %}\n server {\n   listen 80;\n-  server_name {{ item.value.site_hosts | join(' ') }};\n+  server_name {{ item.value.site_hosts | join(' ') }}{% for host in item.value.site_hosts %} {{ (host[:3] == 'www.') | ternary(host[4:], 'www.' + host) }}{% endfor %};\n   return 301 https://$host$request_uri;\n }\n {% endif %}\n{% for host in item.value.site_hosts if item.value.www_redirect | default(true) %}\n server {\n   {% if item.value.ssl is defined and item.value.ssl.enabled | default(false) -%}\n     listen 443 ssl http2;\n   {% else -%}\n     listen 80;\n   {% endif -%}\n\nserver_name {{ host | match('^www\\.(.)') | ternary(host | regex_replace('^www\\.(.)', '\\1'), 'www.' + host ) }};\nserver_name {{ (host[:3] == 'www.') | ternary(host[4:], 'www.' + host) }};\n   return 301 $scheme://{{ host }}$request_uri;\n }\n {% endfor %}\n``\n. @wassimdotis I'm testing a fix and plan to post a PR in the next 48 hours.\n. Thank you @henkler for helping catch that thisenv.j2template in thedeployrole must be different from theenv.j2template in thewordpress-install` role.\n\nYour edit works. There is a bit of convention in the deploy role to prefer using the project dict, which is only slightly different:\n{{ wordpress_env_defaults | combine(project.env, vault_wordpress_sites[site].env) | to_env }}\n. @henkler Would you be interested in submitting a pull request for this?\n. Thank you @henkler !\n. I am closing this and will break it into smaller chunks instead. The first is in #538.\n. @swaincreates I recently learned about Ansible's template lookups. What do you think about...\n- moving this https config to a new template roles/wordpress-setup/templates/https.conf.j2\n- replacing the 1) existing https config and 2) your proposed new https config with the following:\n{{ lookup('template', 'https.conf.j2') }}\n. Closing as \"a feature that was explored but discontinued.\" At present, there is no consensus that the \"nice-to-have\" benefits to output format outweigh risks: \n- Different output could confuse users (\"Why does this output look different from usual Ansible?\").\n- Relying on a possibly unstable Ansible API may mean accepting that Ansible updates could \"break\" Trellis for features that are not \"must-have.\" \nThe original intention was to follow this PR with another PR enabling templating and colors so that Ansible output might feel accessible to users. I loaded a demo branch output-options into the roots/trellis repo so that anyone interested can review the potential features/implementation. The corresponding docs are in a trellis-output-options branch. Roots can discard these branches in a few weeks.\nHere is a screenshot of output demonstrating the templating and colors.\n\nHere is the playbook to create the output above.\n``````\n- name: Colors\n  gather_facts: false\n  hosts: localhost\n  tasks:\n    - name: Show available Ansible colors and current color settings\n      debug:\n        msg: |\n          AVAILABLE COLORS\n          --------------------\n          {{ ansible_colors }}\n      CURRENT COLOR SETTINGS\n      --------------------\n      {{ color_settings }}\n\n- name: Demonstrate a few colors in context\n  debug:\n    msg: |\n      Here is the default color for all tasks <error>except failed tasks which use this color_error.</error> Also, here is <warn>the warning color,</warn> and the <ok>ok color</ok>.\n\n      When a color setting is 'None' the string won't be colorized. For example, if `color_ok = None` in `ansible.cfg`, then the string won't be colorized (but the color tag will still be stripped).\n\n      When there is `code in backticks`, the backticks will be stripped and the text colorized. However, if `color_code = None` (in `ansible.cfg`) then the backticks will just display and no change in color will be applied.\n\n      URLs look nice in a slightly different shade, e.g., <bold>https://roots.io/trellis/docs/ssl/</bold>\n\n- name: Demonstrate the failure output\n  fail:\n    msg: |\n      Please specify SSL `provider`:\n      ```\n      wordpress_sites:\n        example.com:\n          ssl:\n            enabled: true\n            provider: <ok>letsencrypt</ok>\n\n      `Backticks` always display inside fenced code blocks and are not colorized. Codeblocks do not wrap, which is good for displaying commands users may copy/paste.\n      ```\n\n``````\n. closed by #744. Thanks for reporting this. I don't think we noticed this because we assume users have set up SSH keys to connect to their remotes. That's unfortunate that your VPS provider doesn't allow you to load an SSH key at VPS creation time, thus requiring your first connection to use a password.\nThis is one instance of a broader issue: The remote-user role's ping command doesn't currently pass all the cli options that users might pass to the primary ansible-playbook command.\nAs a partial solution to that broader issue, #564 added detection for vault-related cli options, passing the options to the remote-user role's ping command. It demonstrates a technique that could be used for other cli options that may be relevant to the ping command, e.g., --ask-pass, --limit, --private-key/--key-file, --user (should replace root in ping command). I'm unsure whether --ssh-common-args and --ssh-extra-args would also be relevant. I believe these can all be detected in cli options.\nConsidering adding support for the above cli options may feel like a hassle and raise the question of whether the remote-user role could be scrapped or replaced. The role has had its share of troubles, but I think they've all been fixed so far (aside from the current issue) and I think the role solves a number of challenges and makes life for users much simpler on the whole (see what the role resolved when it was born in #274). \nMy guess is that the solution is to expand the cli_args_vault variable to a more general all-encompassing cli_args variable.\n. @aried3r would love it if you would test #578 for whether it fixes the issue. No obligation.\n. Closing. Resolved in #578\n. Brilliant, thanks!\nI added warn: false and a CHANGELOG entry.\n. Short\nI think you'd want to keep cli_options_ping but rename it to just cli_options (also rename in users role).\nLong\nI understand how cli_options_ping could appear unnecessary after the switch to the raw module:\n- Without the variable, a project with the Trellis defaults works. However, if users add options to the primary ansible-playbook command (e.g., a custom --private-key), the proposed ad hoc raw command would not receive the information and could inappropriately fail to connect.\n- The substring 'ping' in the variable name implies that the options apply to just the ping module. However, the cli options would also apply to the connection made by any ansible ad hoc command. When I named the original variable, I failed to consider its use beyond just the ping module.\nThe var cli_options_ping was introduced in #578 to be sure that any critical options users could pass to the ansible-playbook command would be recorded and passed to the ad hoc ping command. As a local_action, the ad hoc ping was otherwise a completely separate connection, unaware of connection settings passed via the cli.\nFor example, suppose users pass --inventory because their inventory is in a custom location. The ad hoc raw command must also be informed of that location. Similarly, if users must pass options such as --ask-pass or --private-key to the primary ansible-playbook command, presumably the info of these options will be indispensable in testing a remote-user's ability to connect via the ad hoc raw command.\n\nTesting\nThis switch to the raw module should probably also test that it functions properly in ...\n\nthe scenario that a failed connection for root could still give a return code of 0 [as] it does on an Ubuntu box on AWS (ref)\n\nThe ping module gave the correct return code, so hopefully the raw module will too.\n. @ptibbetts Thank you for your time and work on this.\nYou mentioned...\n\nI've just tried appending the cli_options to the raw module and had no luck.\n\nWhat did you run into? Here's a demo branch where cli_options seems to work for me.\nReturn codes. Whereas the ping module returns failure for root on AWS (when it worked on 14.04), the raw module apparently still returns rc=0 for AWS when connecting as root, e.g.,\n$ ansible ip.xxx.xxx.xx -m raw -a whoami -u root -i hosts/<environment>\nip.xxx.xxx.xx | SUCCESS | rc=0 >>\nPlease login as the user \"ubuntu\" rather than the user \"root\".\n(I don't know much about AWS. I tested using the community AMI\nubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-20160516.1 - ami-06b94666.)\nThe remote-user role currently uses the return code in a ternary conditional to dynamically define ansible_user. It looks like the return code won't be reliable, so my demo branch changes the conditional from root_status | success to ('root' in root_status.stdout_lines). That just checks if the user is actually echoed to stdout on its own line, which is false in the AWS output above). There might be a smarter approach.\n. @ptibbetts thanks for the log. I responded over there. I think the different results we see are attributable to the different cli_options we tested and not attributable to different hosts. I tested both DO and AWS.\nThe whoami seems fitting. Before ping it was echo can_connect. Whatever is consistent across hosts to\n- diagnose the root user's ability to connect, and\n- yield consistent stdout that we can capture in a registered variable and evaluate (given that it seems we can't just rely on the return code from connections to AWS).\nI think we need to retain the failed_when: false. As I understand it, if we ever let the ansible task with the whoami fail (as distinct from the whoami command inside the task), the playbook will halt. Of course, we don't want the playbook to halt; we just want to test whether the root user can connect.\nThe conditional ('root' in root_status.stdout_lines) works on DO and AWS but maybe someone with more experience will suggest that we can't trust the whoami stdout to be consistent on other hosts.\n. @ptibbetts thank you for helping me see how the --ask-pass option was not working with cli_options. I think I've arrived at an acceptable solution (discussion and code).\n. Thanks for working on this.\nThis is unfamiliar territory for me, so I don't know if this is the time/place to address the potential dependency problems I see during the install, e.g., \n- fatal error: Python.h: No such file or directory (goes away if python-dev installed prior)\n- fatal error: ffi.h: No such file or directory (goes away if libffi-dev installed prior)\n- etc.\nWe could consider some additional dependencies as in in geerlingguy/drupal-vm windows.sh\nP.S. Note that you have an instance of sudo sudo\n. > Tested the ansible to setup a server and deploy a release, with this patched version, and everything works as expected.\nWorks for me too. Thanks!\n. > Any ideas about encouraging the use of Ansible Vault?\nI have a \"tips\" role largely worked out, following the pattern of #562's proposed \"validations\" role. Tips print to the end of playbook stdout. One is conditional on a custom unencrypted_vault_files bool created using is_encrypted from VaultLib:\n\nTip: Some vault files are not encrypted. Set up Ansible Vault following the guide at ... [etc]\n\nUsers can disable tips and/or validations with a simple toggle in group_vars or --extra-vars.\nNot wanting to overload, I was waiting to finalize/submit the \"tips\" PR till after the \"validations\" PR had been considered.\nThere could certainly be other ideas for encouraging Vault usage.\n. @swalkinshaw pointed out that the playbook fails if vault_users is not defined. It does not need to be defined when sshd_permit_root_login: true (current default).\nI added a few instances of vault_users | default([]) to prevent unnecessary failure.\n. Thanks for testing! I squashed in a test and message at the top of vars.py suggesting:\n\nAnsible on OS X requires the python passlib module to create user password hashes.\nsudo easy_install pip\npip install passlib\n. We wouldn't want the wildcard functionality to become a wildcard of its own. Surprises not welcome.\n\nBut to explain, the wildcard functionality stemmed from development on #614 with its new var:\nvault_users:\n  - name: \"{{ admin_user }}\"\n    password: example_password\n    salt: \"generateme\"\nThis var would require the wildcard, a la:\nraw_vars:\n  - vault_users.*.password\n  - vault_users.*.salt\n. I incorporated @swalkinshaw's suggested comprehensions; a remarkable streamlining of the code.\n\nI added a commit to raise an error if raw_vars is not defined as a list.\n\nThe vars.py plugin accesses vars before they are templated. This is what enables us to wrap vars in {% raw %} before a templating problem occurs. \nHowever, this means that the raw_vars variable will not be templated/expanded here unless we do it ourselves. I added a commit to template the raw_vars variable before working with it.\n``` yaml\nsome_var:\n  - vault_mail_password\n  - vault_mysql_root_password\n  - vault_wordpress_sites\nraw_vars: \"{{ some_var }}\"\n```\nIf a user were to create the unlikely scenario above, I think it would be a baffling surprise/mystery why some_var wasn't being templated/expanded in the definition of raw_vars. I introduce some code to avoid such a problem. I don't think the code has too high of a price.\n- The Templar params seem relatively stable, unchanged during history of Ansible 2.x\n- The Templar.template() params have had only one minor irrelevant change during history of 2.x\n- DataLoader has been around all of 2.x\nI put self.loader in __init__ so it is accessible to other methods to use for templating in the future.\n. I believe the options listed at this forum discussion may be relevant:\nhttps://discourse.roots.io/t/production-server-provision-configures-staging-envs-if-hosts-are-the-same-bug-or-intention/6090/2\n. replaced by #629\n. After generous and painstaking review from @swalkinshaw, I think this is ready.\nThis PR originally intended to solve the problem that CSRs and certs would not detect changes in site_hosts and would fail to update.\nUpon further review, I see that other crucial changes would go undetected, but should trigger cert regeneration, i.e., changes in any of the following:\n\nvar: site_hosts (the original issue of this PR)\nvar: letsencrypt_intermediate_cert_sha256sum\nvar: acme_tiny_commit\nvar: letsencrypt_ca\nfile: /etc/nginx/ssl/letsencrypt/{{ site }}.key\nfile: /var/lib/letsencrypt/account.key\n\nThe revised 2nd commit hashes the combination of the above, per site, inserting a corresponding 7-digit ID into CSR and cert filenames. If any item above changes, the required filename will change, triggering creation of new CSRs and certs (if they don't already exist with this ID).\nEdit: I edited the 2nd commit, adjusting this line in defaults/main.yml to accommodate a wordpress_sites list with a mix of SSL enabled/disabled sites:\ndiff\n-letsencrypt_cert_ids: \"{ {% for item in generate_cert_ids.results %}'{{ item.item.key }}':'{{ item.stdout }}', {% endfor %} }\"\n+letsencrypt_cert_ids: \"{ {% for item in generate_cert_ids.results if not item | skipped %}'{{ item.item.key }}':'{{ item.stdout }}', {% endfor %} }\" \n\nHow to update\nNew servers\nNew servers provisioned with Trellis (after this PR is merged) will accommodate changes to site_hosts or any of the above items.\nExisting servers that do NOT need to add hosts to site_hosts\n\nUpdate trellis (get changes from this PR)\nRun ansible-playbook server.yml -e env=<environment> --tags letsencrypt\n\nThen, any future changes to site_hosts etc. will work no problem for this project.\nThese steps should also work for existing servers that need to REMOVE hosts from site_hosts.\nExisting servers that DO need to add hosts to site_hosts\n\nUpdate trellis (get changes from this PR)\nSet ssl enabled: false for all sites in group_vars/<environment>/wordpress_sites.yml\nRun ansible-playbook server.yml -e env=<environment> --tags wordpress\nSet ssl enabled: true for applicable sites in group_vars/<environment>/wordpress_sites.yml\nRun ansible-playbook server.yml -e env=<environment> --tags letsencrypt\n\nThen, any future changes to site_hosts etc. should work no problem for this project.\nExisting servers that use non-Let's Encrypt certs and are transitioning to Let's Encrypt certs will probably need to use these 5 steps.. Please see if applying the update in #631 will fix this for you.\n. Thank you. If you're interested, could you let us know whether #630 resolves the issue for you?\n. @vercotux: Thank you for testing. \ud83d\udc4d \nI'm not sure what the wp-cli issue was, but it sounds like you've handled it. \n630 didn't adjust deploys and deploys don't affect SSL certs, so you did the right thing by ultimately running the server.yml playbook (for provisioning) with the letsencrypt tag.\nThe returned 6 error with the curl -4 -s https://api.ipify.org command is quite unexpected, given that its use in the ip_whitelist variable only comes into play in the ferm and fail2ban roles that you did not run. I don't recall ever seeing returned 6 but I'm guessing it is a connectivity issue with curl, in which case trying again later is often the solution, as dissatisfying as that may be. #630 didn't adjust any related code, but if that particular error persists, you could add -vvvv to the end of the ansible-playbook command to get more verbose debug output. \nMost importantly, I notice this line in your system info:\nTrellis at \"Require Ansible 2.0.2 and remove deploy_helper\"\nThere have been many updates to Trellis since that particular CHANGELOG entry. Testing #630 would probably only be worthwhile on top of a fully up-to-date version of Trellis.\n. You are under no obligation to test further, of course, and I realize you've resolved your initial problem. In any case, here are some ideas for how to update Trellis.\nTest on staging. First, I would set up a staging site for testing, using a new separate server in hosts/staging and set up your group_vars/staging similar to your group_vars/production. I would avoid Let's Encrypt rate limits by specifying the staging letsencrypt_ca in group_vars/staging/main.yml. This allows you to update Trellis (see below) and get server.yml running without errors. However, it is not a real certificate authority, so your browser will post a warning when you visit the staging site.\nAfter you've updated Trellis and tested that the playbook completes without errors, you will know what changes your production site will need to accommodate the Trellis updates. Make a backup of your production server/files, then make the changes to production and run server.yml and everything should work (because you've practiced on staging).\nGit. If you originally git cloned Trellis and have been committing your changes, you can use git to merge in updates from upstream Trellis. If your Trellis git project only includes Trellis, you may find some guidance at https://discourse.roots.io/t/2440/12. Alternatively, if your project is set up like roots/roots-example-project.com (includes roots/bedrock and roots/sage), you may find some guidance at https://discourse.roots.io/t/best-practices-to-update-trellis/5386.\nManually. I strongly recommend using git, but I've heard that some people update Trellis by just getting a fresh copy of Trellis and pasting in their edited hosts and group_vars files. Using this approach, you would need to check upstream Trellis for updates to group_vars and manually apply the changes (e.g., #622 added a new group_vars/all/helpers.yml file and adjusted formatting for site_hosts, etc.). Of course, if you have customized files outside of the hosts and group_vars directories, you would need to add your customizations to the corresponding new files as well.\n. Yep! Should be resolved by #630.. Suppose a user setting up a new DO droplet doesn't customize the hostname to be the fqdn, leaving some default value like this:\n\nThen hostname --fqdn and ansible_fqdn are both ubuntu-512mb-sfo1-01. Trellis could add a task to set the hostname, but I'd be inclined to stick with {{ site_hosts_canonical | first }}.\n. @discopatrick I'm not up to speed on the entirety of this thread, but on the topic of making it easier to run dev.yml, I see that you're considering configuring vagrant access to use ~/.ssh/id_rsa.pub.\nYour mind is fresh on the topic and will know whether there are any helpful strategies in the alternative I considered once in #314, largely intended to facilitate syncing DBs between environments.\nMy memory was that #314 told Ansible to use a specific SSH config that was auto-updated with the latest from vagrant ssh-config (e.g., because ports can change to avoid port collisions when there are multiple VMs). So, it's an alternative of still using the vagrant ssh key, but automating its use, to spare users the hassle of manually specifying vagrant's key or inventory.. @thisolivier Thanks for the report!\nWould love it if you could test #661 given that you are so familiar with this particular issue.\n. Thank you @nathanielks !\n. PR and docs look good to me. \nWould need new CHANGELOG entry, probably prefixed with [BREAKING].\nThe change to the deploy command maybe calls for a new tagged release.\n. I rebased to resolve merge conflicts that arose from the recently merged #692. Both PRs involve(d) caching stuff in Nginx confs.\nI used the rebase as an opportunity to add a few tags: nginx-includes on tasks involving the new nginx hooks.. closed and replaced by the better solution in #740. fixed in #696\nbut let us know if that didn't resolve it for you. While you wait for action over at the mailhog upstream, you could manually perform the task that failed. Once you've curled the files in place, the get_url task in question will probably succeed and not cause your playbook to fail because I don't think it tries to download those files if they already exist on the machine.\nSo, specifically, you'd vagrant ssh into the VM and run something like ...\n```\ncurl -4Ls https://github.com/mailhog/MailHog/releases/download/v0.2.0/MailHog_linux_amd64 /opt/mailhog/mailhog\ncurl -4Ls https://github.com/mailhog/mhsendmail/releases/download/v0.2.0/mhsendmail_linux_amd64 /opt/mailhog/mhsendmail\n```\nThen exit out of SSH connection to VM and run vagrant provision . @RiFi2k Thanks for all this work. This will be great.\nTL;DR I propose the following:\n- @RiFi2k: you squash the first 3 commits described below into your branch, if you like them :wink:\n- we merge your PR into the new ssh-hardening branch I've created as the base branch for this PR\n- I'll add 3 more commits and make a PR to merge the branch into master\n- people focus their review efforts on that latter PR as the complete revised sshd implementation\n\nI've added a ssh-hardening-demo branch with changes that make sense to me. I've tested it quite thoroughly. Here are the commits:\n\nSwitch roles for more secure defaults in ssh (@RiFi2k's original commit)\nStreamline ssh-hardening role to Ubuntu, OpenSSH_6.6+\nEnable AllowAgentForwarding, UsePAM; Restore MaxAuthTries 6\nUse lineinfile to make moduli task more succinct and idempotent\nUse stronger sshd HostKeys and ssh client HostKeyAlgorithms (see stribika article)\nFix ssh config to handle custom options per Host (see dev-sec/ansible-ssh-hardening#83)\nList only one Port in ssh config (see dev-sec/ansible-ssh-hardening#84)\n\nIf you approve of commits 1-3, I think it'd be great if you would squash them into your original commit. The commits are reviews/changes I could have tried to put into the thread here but preferred to code up and test first. Now it's easiest for me to just share the test branch itself.\n1. Streamline ssh-hardening role to Ubuntu, OpenSSH_6.6+\nYou already removed the non-Ubuntu stuff from the original role's tasks. This commit does the same for the templates. I also removed some variables whose names included 53 59 and 66. These refer to OpenSSH versions 5.3, 5.9, 6.6. Given that Ubuntu 14.04 and 16.04 both include > 6.6, we can just use the 66 variables, which I renamed with the 66 omitted.\nAccording to stribika and https://wiki.mozilla.org/Security/Guidelines/OpenSSH I added umac-128@openssh.com to the list of MACs. However, I added it to the ssh_macs_weak instead of ssh_macs_default, just to be safe, because it was not mentioned by the authors at https://bettercrypto.org/static/applied-crypto-hardening.pdf\n2. Enable AllowAgentForwarding, UsePAM; Restore MaxAuthTries 6\nI changed AllowAgentForwarding to yes for a successful git clone on deploy.\nI changed UsePAM to yes to avoid Debian bug #751636 with openssh-server. We can change to UsePAM no once the Canonical Main repository (openssh 1:7.2p2-4) includes openssh 1:7.2p2-6. Trellis users haven't encountered this because we've had UsePAM yes so far.\nI changed MaxAuthTries from 2 back to the 6 that has been in Trellis so far. If someone has 3-6 SSH keys and Trellis has managed to try them all till now, I want to avoid suddenly having Trellis try only 2 keys then fail. That could be challenging for people to debug if they don't think to run ssh -v to see which keys are being tried and not tried. I'm not aware of MaxAuthTries 6 being particularly risky, but correct me if I'm wrong.\nI added SendEnv and AcceptEnv (empty by default) in case someone might need them.\n3. Use lineinfile to make moduli task more succinct and idempotent\nThis change is in the spirit of Ansible's recommendation to use an Ansible module instead of the command or shell modules, where possible. This implementation using the lineinfile module makes the task idempotent, so it isn't marked 'changed' every time.\nAny line in /etc/ssh/moduli that matches the regex will be removed. An example line to remove:\n```\nTime Type Tests Tries Size Generator Modulus\n20150522025931 2 6 100 1535 5 F4EE15F22E5F49997A027769656D...\n``\nThe fifth column (Sizeof1535`) is less than 2000 so we need to remove the line.\nExplaining the regex: ^(\\d+\\s){4}1\n- ^  -- the line must start with the pattern that follows\n- (\\d+\\s){4}  -- 4 occurrences of one or more digits followed by a space (matches columns for Time Type Tests Tries)\n- 1  -- next column (Size) starts with 1 (i.e., is in range of 1000-1999)\nModuli Size on DigitalOcean Ubuntu 12.04, 14.04, and 16.04 is always a 4-digit number 1000 or higher, so the last bullet above should work: just matching a Size that starts with 1.\nIf for some reason we believe moduli Size could occasionally be less than 4 digits, we would need regex like ^(\\d+\\s){4}(\\d{1,3}|[0-1]\\d{3})\\s where \n- (\\d{1,3}|[0-1]\\d{3})\\s  -- matches Size less than 2000\n  - \\d{1,3}  -- a number of 1-3 digits (i.e., less than 1000)\n  - |[0-1]\\d{3} -- OR a 4-digit number starting with 0 or 1\n  - \\s  -- a space after the 1-4 digit number, to ensure we don't match a 5+ digit number\n. :sparkles::christmas_tree:DDoS:christmas_tree::sparkles:\nThanks for the quick reply!\nGood point about the moduli being outside the original role's scope. I'd be happy for you to do the lineinfile moduli task in a separate commit of your own, still in this same PR.\n\nSo, I'd say definitely squash commit 1 - Streamline ssh-hardening role to Ubuntu, OpenSSH_6.6+ into your original commit, just so the initial appearance of the role omits the non-Ubuntu stuff.\nThen maybe squash 2 -  Enable AllowAgentForwarding, UsePAM; Restore MaxAuthTries 6 in as well, or keep it a separate commit, given that it changes settings from the original role. Your choice. But I'd like that to be your commit. It's just some revisions I'm requesting on your PR.\nThen yeah, add the lineinfile moduli task in a separate commit from you. Again, it's yours, but just includes some revisions suggested in this PR.\nThen we'll probably merge and I'll add commits 4-6, then open a PR to master, etc.\n\nThanks!. Looks great! Thanks for all your work in making this happen.. @arashohadi Thank you for testing. Your information is very helpful. After updating my vagrant-bindfs plugin, I too get the '/vagrant/bin' is part of a reserved subtree error.\nIf vagrant-bindfs won't allow a mountpoint in /vagrant, one option could be to put the mountpoint in the vagrant user's home directory, changing the PR to something like this:\n```diff\n- bin_path = File.join(ANSIBLE_PATH.sub(dir, '/vagrant'), 'bin')\n+ bin_path = File.join(ANSIBLE_PATH.sub(dir, '/home/vagrant/trellis'), 'bin')\nif Vagrant::Util::Platform.windows? and !Vagrant.has_plugin? 'vagrant-winnfsd'\n  wordpress_sites.each_pair do |name, site|\n    config.vm.synced_folder local_site_path(site), remote_site_path(name, site), owner: 'vagrant', group: 'www-data', mount_options: ['dmode=776', 'fmode=775']\n  end\n\n\nconfig.vm.synced_folder '.', '/vagrant', mount_options: ['dmode=755', 'fmode=644']\nconfig.vm.synced_folder '.', '/home/vagrant/trellis', mount_options: ['dmode=755', 'fmode=644']\n      config.vm.synced_folder File.join(ANSIBLE_PATH, 'bin'), bin_path, mount_options: ['dmode=755', 'fmode=755']\n    else\n      if !Vagrant.has_plugin? 'vagrant-bindfs'\n        fail_with_message \"vagrant-bindfs missing, please install the plugin with this command:\\nvagrant plugin install vagrant-bindfs\"\n      else\n        wordpress_sites.each_pair do |name, site|\n          config.vm.synced_folder local_site_path(site), nfs_path(name), type: 'nfs'\n          config.bindfs.bind_folder nfs_path(name), remote_site_path(name, site), u: 'vagrant', g: 'www-data', o: 'nonempty'\n        end\nconfig.vm.synced_folder '.', '/vagrant-nfs', type: 'nfs'\nconfig.vm.synced_folder '.', '/vagrant', type: 'nfs'\nconfig.bindfs.bind_folder '/vagrant-nfs', '/vagrant', o: 'nonempty', p: '0644,a+D'\n\nconfig.bindfs.bind_folder '/vagrant', '/home/vagrant/trellis', o: 'nonempty', p: '0644,a+D'\n        config.bindfs.bind_folder bin_path, bin_path, perms: '0755'\n      end\n    end\nprovisioner = Vagrant::Util::Platform.windows? ? :ansible_local : :ansible\n-   provisioning_path = Vagrant::Util::Platform.windows? ? ANSIBLE_PATH.sub(dir, '/vagrant') : ANSIBLE_PATH\n+   provisioning_path = Vagrant::Util::Platform.windows? ? ANSIBLE_PATH.sub(dir, '/home/vagrant/trellis') : ANSIBLE_PATH\n```\n\n\nThis change would require users to cd ~/trellis after vagrant up (instead of cd /vagrant).\nI don't know if that will resolve the winnfsd crashing problem, however.\nI will set myself up with a Windows box for testing, but I can't get to it for a few days.\nAgain, thank you very much for testing!\n. I added a commit based on the diff above. It works on my Windows 10 with encrypted vault.yml files and .vault_pass.\nOn the VM, the /vagrant directory will still exist with the same content as before but there will be a new /home/vagrant/trellis directory with the needed permissions on files and directories.\nWindows users would switch to running Ansible commands from ~/trellis. Although non-Windows users could continue with /vagrant, we might as well make it the general rule to say, \"find your Trellis files on the VM in ~/trellis.\" I augmented the post_up_message to that effect.\nDoes anyone see any problem with this change to /home/vagrant/trellis?\nNote that if the Vagrantfile is moved to the parent directory on the host machine, /vagrant on the VM will have the site and trellis subdirectories like in the past, but ~/trellis on the VM will still have just the Trellis files, \nI think only the Windows docs would need a few minor updates.. Thank you @swalkinshaw for pointing out that the symlink creation will fail if the parent directory of project_shared_children[*].path doesn't exist in the new_release_path. I added a commit to create the parent directory.\nI also added the lower filter to prevent the file module from failing if a user defines type: File. \nI also added a comment in roles/deploy/defaults/main.yml...\nUse `type: absent` to remove an item from `/shared`.\nI also made it explicit that the mode value should be quoted to avoid the potential confusion around how \"python and yaml (pyyaml) work with each other in regards to octal values\" (discussion). . Latest commit Simplify handling ...\n- removes the absent feature\n- splits the first \"ensure shared directories are present\" task in two:\n   - first create directories for items with type: directory\n   - next create parent directories for items with type: file\nThese changes favor \"more tasks that are simple\" over \"fewer tasks that are complex.\" I routinely have to fight my inclination toward the latter.\nIf/when merged, probably ought to be a \"squash and merge.\" . Thanks for spotting this! \ud83d\udc4d . @daBONDi could you see if these steps resolve it?\n- update your Trellis to include #705\n- vagrant reload to refresh the vagrant sync dirs\n- vagrant ssh\n- cd ~/trellis and run your various Ansible commands from there. After wrestling to simplify, trying many different options, I decided to revert my original commit, then add a commit to just remove the instances of loop.first. We can write a validation somewhere else that checks for duplicate users (e.g., in #562). The logic could look like this:\n\"{{ (users | map(attribute='name') | sort) != (users | map(attribute='name') | unique | sort) }}\"\nIn addition to removing loop.first, the new commit adjusts the set_fact task that defines ansible_become_pass, adding {% raw %} around the value. Although the raw_vars feature enables a user.password to be templated in the task even if it contains chars like {{, once templated, if we don't re-add the {% raw %} like I've done here, the task's variable definition would read like this:\nansible_become_pass: examp{{le_password\nThat moment of definition doesn't fail, but the templating failure occurs later, when Ansible uses the ansible_become_pass during the setup task of the next play. So, as the jinja docs mention is possible, I've added the {% raw %} tags inside {{ }} in order to escape and include them in the definition:\n\"{{ '{% raw %}' }}{{ user.password | default('') }}{{ '{% endraw %}' }}\"\n\n@swalkinshaw  mentioned this:\n\nWe might want to look into creating more custom filters/modules to deal with complex things like these. I'd have a little more confidence in them being pure python vs a mix of Jinja filters + Python functions.\n\nAs a viable alternative to the commit described above, I created a trellis-users-magic-var demo branch with a new trellis_users var built from the combination of users and vault_users. Example:\ntrellis_users:\n  admin:\n    groups: [...]\n    keys: [...]\n    password: '...'\n    password_hash: '...'\n  web:\n    groups: [...]\n    keys: [...]\n    password: '...'\n    password_hash: '...'\nIt's more code, thus more liability, but it simplifies some things. Example from the \"Setup users\" task:\ndiff\n- password: '{% for user in vault_users | default([]) if user.name == item.name and user.password is defined %}{{ user.password | password_hash(\"sha512\", user.salt | default(\"\") | truncate(16, true, \"\") | regex_replace(\"[^\\.\\/a-zA-Z0-9]\", \"x\")) }}{% else %}{{ None }}{% endfor %}'\n+ password: \"{{ trellis_users[item.name].password_hash }}\"\nLet me know if you'd prefer this trellis_users alternative. It is tested and ready to go.. @jac-firemancreative @nathanielks \nWhat do you think about dropping the apt_packages_install var from defaults then making this change to the task?\ndiff\n - name: Checking essentials\n   apt:\n     name: \"{{ item }}\"\n     state: present\n     update_cache: true\n     cache_valid_time: \"{{ apt_cache_valid_time }}\"\n-  with_items: \"{{ apt_packages_install }}\"\n+  with_items:\n+    - \"{{ apt_packages_default }}\"\n+    - \"{{ apt_packages_custom }}\"\nThis feels a tiny bit more \"ansible-like\" to me, but either way works.. Major thanks to @RiFi2k and @swalkinshaw for a ton of work and review!. Coming back to this after a couple weeks, with fresh eyes, I still think it is a good idea and I'm comfortable with the implementation.\nDon't worry that the pythonic .replace() and ansible filter regex_replace() risk failures. If the strings they try to match are absent, there is no failure. The task would just print all the output, instead of a selected portion.\nIn any case, the matching strings have been stable in OpenSSH for roughly 5+ years.\n6.0 (Apr 19, 2012) -- 7.4 (Dec 18, 2016)\n 6.0 -- 7.4 host key for %.200s has changed\n 6.0 -- 7.4 REMOTE HOST IDENTIFICATION HAS CHANGED\n 6.0 -- 7.4 Please contact your system administrator.\n 6.0 -- 7.4 The fingerprint for the\n* 6.0 -- 7.4 Host key verification failed.\n. @swalkinshaw prompted me to take a second look at the ipify_facts module.\nI added a commit changing from the command module with curl to the ipify_facts module.  I also added connection: local to ensure it retrieves the IP for the local machine IP, not the remote host.. The problem is that we can't use WP-CLI because it can't even load. Under these conditions WordPress fails to load before WP-CLI can do anything.. I've updated this PR but also posted an alternative in #765. Both follow @QWp6t's suggestion:\n\nif those were environment variables (i.e., in .env), you could easily override by setting the env var before loading wp-cli since phpdotenv doesn't override existing environment variables.\nthen the user's directory structure wouldn't matter, but the user wouldn't be able to hard-code those values.\n\nBoth PRs expect that users have added these lines to site/config/application.php:\ndefine('MULTISITE', env('MULTISITE') ?? true);\ndefine('SUBDOMAIN_INSTALL', env('SUBDOMAIN_INSTALL') ?? true); // Set to false if using subdirectories\nThis PR retains the regular multisite.enabled and multisite.subdomains settings in wordpress_sites, using those values to create corresponding default env vars. #765 drops the former settings, consolidating all multisite config in the env vars only.\nThis PR added a default path_current_site env var based on multisite.base_path because it looked like those two values should be aligned.. Thank you @swalkinshaw and others for the review, and @swalkinshaw for the idea that wp-cli could --require a file with temporary overrides for the multisite constants. This require loads before WP loads, so it prevents the problem that WP won't load when multisite constants are true.\nI've reverted again \ud83d\ude05  and added a commit with just this --require strategy. Of course, we'll need to squash before merging. \nI added error_reporting(E_ALL & ~E_NOTICE); to the --require file to avoid having the is-installed task show in red PHP Notice:  Constant MULTISITE already defined (even though task status is ok).. Latest edits submitted in fresh uncluttered PR: #766. Closed by better solution in #766.\nIn my subconscious, I had this misconception:\n\nTrellis now controls WP's configs/constants. And if env vars are the means of controlling WP configs, why not avoid the indirection of multisite.enabled and just use env vars directly?\n\nAfter internal discussion, I realize that Trellis is not in the business of controlling WP's constants, of course. Rather, the constants and env vars came up just as part of an attempted workaround, a workaround that #766 renders unnecessary.. When people run server.yml with an out-of-date admin_user password in group_vars/production/vault.yml, I believe they will be forced to use -K, --ask-become-pass and manually enter a password at the prompt, causing cli_ask_become_pass to be true. The conditional for the task you pointed out already includes not cli_ask_become_pass, so I believe that task will skip in this scenario.. Thanks @t0mk \nWould love it if you would test #769 \nTill #769 (or other) is merged, you could disable the ssh client validation:\n```yml\ngroup_vars/all/main.yml\nvalidate_ssh: false\n. @strarsis I believe the problem stems from this entry in one of your hosts files:\n[development]\nweb\n```\nEach of the Trellis hosts files lists a [web] group. This group name web should not be nested within (listed under) an [<environment>] group name like [development].\nYou're running server.yml with env=staging. The implied hosts: web:&staging mean that Ansible will load group_vars corresponding to the web and staging groups. In normal Trellis, there are no group_vars for web. In your example, however, by nesting web within development, I believe you've caused web to inherit the group_vars of development.\nYou pointed out the problematic definition of php_sendmail_path from group_vars/development/mail.yml. That file's vars would not normally load for -e env=staging, and thus would not cause this issue, but I suppose that file's vars do load in your case because you've nested web under development.\nHere is a somewhat related discussion that could shed light on the conflicts that can arise from inadvertently loading group_vars from multiple envs.\nI'm not sure what goal led to nesting web under development, but you could propose to discuss unusual customizations at https://discourse.roots.io/. However, given that this appears to be a misconfiguration and not a bug for this GitHub bug tracker, I'm closing the issue.\n. tl;dr -- if we decide to change anything, just including reload_nginx.yml and/or \"always reloading/restarting all the things\" may be most pragmatic, despite being non-idempotent. \n\nI like this excerpt discussing how Ansible is \"Goal-oriented, Not Scripted\"...\n\nAnsible features an state-driven resource model that describes the desired state of computer systems and services, not the paths to get them to this state. No matter what state a system is in, Ansible understands how to transform it to the desired state. -- reference\n\nTrellis performs adequately from a script perspective, warning about the initial Nginx test/reload failure.\nHowever, it could be argued that Trellis fails from the perspective of the \"desired state\" goal being Nginx running, with the latest configs in effect. With current Trellis, a playbook run (other than the first) would not be aware of a past failure, would not be aware that Nginx needs to be started (if not running), and would not be aware that a reload was needed (if the latest Nginx confs were not yet in effect).\nQuoting above, I like this goal: \"No matter what state a system is in, [Trellis] understands how to transform it to the desired state.\" Taking Nginx as an example, we could indeed always include the reload_nginx.yml file to test and reload Nginx. This achieves the goal, the \"desired state.\" The only downside is that it would not be idempotent (state: reloaded always yields changed).\nWe can maintain idempotence while ensuring that Nginx is running because the service module's state: started is idempotent.\nHowever, idempotence is more challenging while ensuring that Nginx has the latest confs in effect. I don't know of any related option built-in to Ansible. Suppose the playbook managed to template new confs on the server but there was a failure or user-interrupt before Nginx reloaded and applied the new confs. We could compare the Nginx process date (e.g., ps -eo cmd,lstart | grep nginx) with the modified date on the relevant Nginx conf files. If the process is older than the confs, the process needs a restart. \nThe challenge is that this issue may also apply to other services such as php7.1-fpm, mysql, ssh, ferm, fail2ban, memcached, etc. I haven't dug in enough to see if there are established methods for Ansible to handle a concern such as this (e.g., to detect whether a service is loaded with the latest configs, vs. just running). Perhaps the most effective approach would be to write a module that accepts parameters for processes and their configs, comparing age, then reloading/restarting processes when applicable.\nIf there were a clean implementation of such a module, it strikes me as worthwhile, but it may be most pragmatic to either instruct users that \"If you see an error, you must deal with it, e.g., fix your Nginx conf and reload\" (the current implicit expectation), or just always reload/restart services, choosing pragmatism over idempotence. \n. The relevant commit: b24f074\nHere is what happens if we do not specify HostKeyAlgorithms in ansible.cfg:\n1. On first SSH connection with bare Ubuntu 16.04 box from DigitalOcean, server offers ECDSA key.\n2. During provisioning, the sshd role limits server to offering ED25519 or RSA keys (not ECDSA).\n3. On the next SSH connection (as different user, e.g., web for deploy, or admin_user after ControlPersist has timed out), server offers non-ECDSA host key, causing SSH client to warn of host key change.\nThe host key change issue is inevitable for servers provisioned prior to #744. Local known_hosts will have the ECDSA host key type but a Trellis updated with #744 causes the server to no longer offer ECDSA (because ECDSA is less secure). With servers provisioned prior to #744, the only way to avoid the host key change issue is to re-add the insecure ECDSA key to sshd_host_keys, but it's better to just deal with the host key change. \nThe good news is that the host key change issue IS avoidable for NEW servers if we tell the server to offer the ED25519 or RSA keys from the very beginning, as is done by specifying HostKeyAlgorithms in ansible.cfg. This works if your first SSH connection the new server is using Trellis. Of course, if you manually SSH first (without HostKeyAlgorithms), the server will default to offering the ECDSA key, loading your known_hosts with the ECDSA type, and you'll have to deal with the host key change later.\nIn summary, if bare servers default to offering the weak ECDSA type that we end up disabling, users will always have to deal with the host key change unless we can make the server offer the right key type from the beginning, which we try to do by specifying HostKeyAlgorithms in ansible.cfg.\nI think the rationale is solid so I'm closing this issue, but if you see an error in my understanding, or a possible improvement, please let us know.. Looks good to me. That will definitely be a helpful option. . Is there an important reason you are manually running server.yml with development, or have you perhaps added the users role to dev.yml? The suggestion is that you use dev.yml for development.\nThis validation and error message is in the users role. The users role is not in dev.yml, used for development. The users role is only in server.yml which is intended for staging and production. . Closing because the stated desired behavior of \"Ansible playbook successfully runs through in development environment\" is achievable by running the playbook intended for the dev VM (dev.yml).\nRegarding your followup comment, I didn't fully understand if you were stating a problem, a question, or a suggestion. Here are a few comments nonetheless.\nRegarding the hosts/development file's comment \"This file is only used for Windows hosts,\" that is because in default or basic Trellis operations, Windows is the only host OS that uses the ansible_local provisioner, and only the ansible_local provisioner uses the hosts/development inventory. For users on other host OSs, Vagrant will create and use its own inventory (as mentioned later in the notes in hosts/development).\nOf course, if you're on a non-Windows host, you're welcome to run dev.yml from the host OS using the dev.yml playbook and the Vagrant inventory, as mentioned in later in the notes in hosts/development. You're also welcome to vagrant ssh then run dev.yml from the guest VM, where a simple cd ~/trellis && ansible-playbook dev.yml should be all you need to provision the VM using a \"local connection.\" That command will end up using hosts/development (an example of how it could be used by a non-Windows host) but only because you are issuing a command other than the basic vagrant up or vagrant provision. So, in other words, feel free to use hosts/development however you please.\n\nAs for your statement that one may want to use mailhog on Linux, I'm not sure which machine you're wanting to provision with mailhog.\n- Trellis is designed to provision Ubuntu machines (Vagrant VMs or remote servers) and vagrant up will run dev.yml and set up mailhog (or you can use steps described above to manually run dev.yml).\n- If instead you mean you're running Linux as your host machine OS and you want to use the Trellis dev.yml playbook and its mailhog role to set up mailhog on your local host machine (i.e., not a Vagrant VM and not a remote server), that's outside the intended use of Trellis, but feel free to adapt the role into your own side project for that purpose.\n- Here are notes about (or discouraging) running mailhog on a staging server (vs. the typical dev VM), but that doesn't seem to be at all what you were talking about. \n. @medfreeman You've done a ton of work and great thinking on this. Thank you! I know it can be really tedious to think through all the implementation and potentialities. You and @swalkinshaw have done the vast majority of the work here, and I'll just add a small percentage of brainstorming in the form of another example branch.\nYour response to @swalkinshaw's example branch was to seek an option that removed out-of-date confs from the server, to avoid the requirement for manual SSH connections to clean them up later. My example augments @swalkinshaw's example to pursue your goal.\n\nrenamed nginx_sites_available_templates list to nginx_sites_confs, where each conf...\nhas a src attribute (template local path)\nhas an optional enabled attribute (default true)\nswitched to templating the confs to sites-available instead of sites-enabled\nadded task that links or unlinks confs based on enabled attribute\nadded task that removes from sites-available the confs that are enabled=false (I don't think this task is necessary given that confs are unlinked, but maybe you desire to remove confs altogether?)\n\nConsider this example a user could place in group_vars/all/main.yml:\nnginx_sites_confs:\n  - src: no-default.conf.j2\n  - src: nginx-includes/some-outdated-site.conf.j2\n    enabled: false\n  - src: nginx-includes/some-site.conf.j2\nGiven that enabled defaults to true, no-default.conf and some-site.conf will be templated to sites-available and linked in sites-enabled. Given that some-outdated-site.conf is enabled=false (imagine a conf used previously, but now we want it gone), it will be unlinked and removed. This feature would probably need a paragraph in the Nginx includes docs.\nI think my example has a few advantages.\n- The example avoids attempting the magic detection and cleanup of confs on the server that have no counterpart on the local control machine. This \"cleanup\" in the regular nginx-includes feature made sense to me given that users never have to manually list out the templates to be processed. But this proposed nginx-sites feature requires users to manually list out of templates. So, my example branch takes advantage of that manual listing, giving users the chance to specify the enabled status, and allowing us to avoid the magical find and remove.\n- The example requires just one config in defaults/main.yml (the templates list), avoiding the need for extra configs like nginx_default_site_enabled and nginx_sites_enabled_cleanup. Of course, my proposed nginx_sites_confs has the downside of being more complex than just a regular list.\n- The example gets around the scenario of having a task to \"Enable better default site\" followed by a task to \"Disable better default site\".\n- The example avoids what looks like non-idempotence in having the \"Remove Nginx extra enabled sites\" task apparently remove all the sites-enabled/extras/* every time then having the next task add some back, every time.\nYour work is really good. What I've written here is just to share ideas and brainstorming, not negativity. My sentiment is 100% positive. However, I'm going to avoid the potential for burnout by not taking the extra time to finess the tone above to avoid what could come off as overbearing and critical.\n\nThe four options, in my view.\n1. Minimal. There's a big part of me that leans toward not adding anything other than the option to prevent the no-default.conf from being enabled. The rationale would be that all this extra nginx-sites stuff falls in the category of \"extra server setup that a small minority of users might want,\" and thus could/should be handled by users' own custom playbooks.\n2. Lean and consistent. However, if we do add something, I'm very sympathetic with @swalkinshaw's statement\n\nCleaning up the templates is a nice feature, but I don't know if we want to keep up that pattern in multiple places.\n\nAside from cleaning up nginx-includes, Trellis doesn't clean up site-specific confs or dirs after a site is removed from wordpress_sites, or remove old ssl certs, etc.\n3. Include cleanup. If we do want to enable cleanup, it seems fine to me to leave confs in sites-availble after they are unlinked from sites-enabled. That would allow removing the \"Remove disabled confs from sites-available\" task from my example.  Part of my rationale is that servers built using Trellis are quite disposable because they're so easy to rebuild, so I doubt there would be a ton of old outdated confs that would build up in sites-available before the server is just destroyed/rebuilt.\n4. Extra-thorough cleanup. But it's only one extra task to clean out sites-available and maybe there's an argument for it.. Thanks @medfreeman. Good arguments. This convinces me regarding adding cleanup:\n\nnot cleaning site specific confs or dirs wouldn't create side effects, whereas this feature without cleaning could\n\nOption 3 looks good to me. :+1: . Works in my tests (and it unearthed #795 :+1:).\nThanks for this!\nFor the docs, yeah, I think some-name.conf.site.j2 is fine to suggest as a convention. You understood it all, that the child template convention of *.child is just to avoid the default templating to includes.d. People can use the convention or not. It is harmless to template extra files to includes.d that aren't part of the sitename subdirs.. Regarding SSL termination, the only prior discussion I recall was partial accommodation in #732. We ultimately figured child templates could handle the particular changes of #732, as implemented in \"Child template example \u2013 complex.\". This is a good improvement. Thank you @slackday! :+1: . >This would probably be good for most multisite installations.\n\nWe could put it behind a flag, something like enable_multisite_cron and have it true by default. Then when their site grows, they can switch it to false ezpz.\n\nI don't have experience on the topic, but the default of true sounds fine to me. If true, then the cron: false that this PR adds to the group_vars files should be true.\nBut actually, my inclination would be to not add this new cron setting to the group_vars files at all, in keeping with the trend toward streamlining the configs in these files. Instead, the existing item.value.multisite.cron | default(true) in the new cron_enabled helper would handle the default and the multisite docs could mention the cron option.. I don't understand why you would want the primary site in the network to be example.com (domain_current_site: example.com) if you're redirecting traffic away from example.com via:\nsite_hosts:\n      - canonical: www.example.com\n        redirects:\n          - example.com\nAny chance the revised config below makes the site behave the way you desire?\ndiff\n  wordpress_sites:\n    example.com:\n      site_hosts:\n-       - canonical: www.example.com\n+       - canonical: example.com\n          redirects:\n-           - example.com\n+           - www.example.com\n      local_path: ../site\n      repo: git@github.com:nickname/example_com.git\n      repo_subtree_path: site\n      branch: production\n      multisite:\n        enabled: true\n        subdomains: true\n      env:\n        domain_current_site: example.com\n-       wp_home: http://www.example.com\n-       wp_siteurl: http://www.example.com/wp\n      ssl:\n        enabled: false\n      cache:\n        enabled: false. Great research!\nI think understand now. Maybe something like this?\n```diff\nroles/wordpress-setup/templates/wordpress-site.conf.j2\n\nserver_name  {% for host in site_hosts_canonical %}{{ host }} {% if item.value.multisite.subdomains | default(false) %}*.{{ host }} {% endif %}{% endfor %};\nserver_name  {% for host in site_hosts_canonical %}{{ host }} {% if item.value.multisite.subdomains | default(false) %}.{{ host | regex_replace('^(www\\.)?(.)$', '\\2') }} {% endif %}{% endfor %};\n...\nserver_name {{ site_hosts | join(' ') }}{% if item.value.multisite.subdomains | default(false) %} .{{ site_hosts_canonical | join(' .') }}{% endif %};\nserver_name {{ site_hosts | join(' ') }}{% if item.value.multisite.subdomains | default(false) %} .{{ site_hosts_canonical | map('regex_replace', '^(www\\.)?(.)$', '\\2') | join(' .') }}{% endif %};\n``\nIt just removes thewww.from the domain base (if present) when applying the.wildcard.. Looks likeregex_replace('^www.', '')works great :+1:. I don't see a necessity for the form I used. The form I used was just what I remembered using in some recentregex_replacecontext. I like your form better. . When I posted my exampleregex_replace`, I hadn't seen your #808 from 2 minutes prior. Sorry.\n\nYou asked:\n\naren't the double backslashes only needed for back references, but not warranted for special characters escape ?\n\nThis was another context difference. I had been testing regex_replace in a debug task context, (vs. template context). Suppose you have a template test.j2 like this in your Trellis project root:\nsingle works:           {{ 'www.example.com' | regex_replace('^www\\.', '') }}\ndouble ineffective: {{ 'www.example.com' | regex_replace('^www\\\\.', '') }}\nThen these tasks:\n```\n    - name: Template context\n      debug:\n        msg: \"{{ lookup('template', 'test.j2') }}\"\n- name: double works in debug context\n  debug:\n    msg: \"double works: {{ 'www.example.com' | regex_replace('^www\\\\.', '') }}\"\n\n# - name: single fails in debug context\n#   debug:\n#     msg: \"single fails: {{ 'www.example.com' | regex_replace('^www\\.', '') }}\"\n\n```\n Resulting output:\n```\nTASK [Template context] ********\nsingle works:           example.com\ndouble ineffective: www.example.com\nok: [test]\nTASK [double works in debug context] *******\ndouble works: example.com\nok: [test]\n```\nIf you uncomment the task \"single fails in debug context\": \n```\nERROR! Syntax Error while loading YAML.\nThe offending line appears to be:\n  debug:\n    msg: \"single fails: {{ 'www.example.com' | regex_replace('^www\\.', '') }}\"\n                                                                  ^ here\n\n``. This looks like an appropriate fix to match WP's default of stripping thewww.` for multisite subdomains. These edits work in my tests. Thank you! :+1:. @medfreeman Such valuable research and explanation. Thank you.\nThis isn't my area of expertise so I'll defer to @swalkinshaw, but after considering your notes, I'd vote \"yes\" for a PR adding all domains/subdomains to SAN for self-signed certs.\nI also agree with your latest implementation note:\n\nBetter to use site_hosts with an union of wildcard entries generated\nfrom canonical hosts, without the www. prefix, as in my previous issue.. I'm only a novice on the topic but tried to thoroughly review. @medfreeman I really appreciate your exceptionally thorough research and explanation. This works in my tests and I don't have any requested changes.\n\nheredoc vs. config file. I slightly prefer the here document approach here in #812 over the templated openssl config file approach in #818. I find @medfreeman's concern about #818's approach to be convincing (especially for projects with 10\u201320+ sites): \n\n[by creating openssl config files, #818] duplicates the cert task and will produce additional files... and i don't like duplicating a common config with args that can be passed in the command-line  --ref\n\nextensions. The other main difference I noticed was that #818 has additional config file sections:\n- req_extensions = v3_req\n- x509_extensions = v3_ca\nAs best I could tell these extensions are considered optional for webservers and probably of no additional benefit to non-CA self-signed certs aimed at local development. @scherii perhaps you can correct me if I've misunderstood.\n#812 appears preferable and ready. I'm not opposed to #818 but I lean toward #812 for the reasons above and because I think #818 needs more discussion:\n- I think #818 should include multisite subdomains (wildcard) in SANs like #812 does (and probably also include redirects hosts, as discussed in #818 comments).\n- I'm uncertain about the value of some of the extensions in #818's config file, as discussed above.\n- #818's commonName should perhaps be the first canonical host instead of {{ item.key }}, just because site keys in wordpress_sites aren't required to be host names. But I'm not sure how much commonName matters anymore or if I'm understanding it.\nHuge thanks to @scherii and @medfreeman for such awesome work. Having to discuss which of two excellent PRs to pick is a great problem to have.. Thank you again @medfreeman @scherii @heyfletch \nThis is a great improvement to Trellis! . This PR works with today's official release of Ansible 2.3. . @strarsis thanks for your work on this. Building on your approach, this seems to work:\n- include: \"{{ item }}\"\n  with_items: \"{{ deploy_build_after | default([]) }}\"\n  tags: deploy-build-after\ndeploy_build_after can be defined as a list but can also left alone as a simple string. So, fortunately users would not have to change their hook definitions into lists (unless they want to).\nIf you're interested in submitting a PR adopting this implementation for deploy hooks, I'd support it.. Fixed/merged in #815 \nThanks @strarsis . Great work @strarsis. Thank you!\nMy prior test was with the deploy_build_after hook only.\nNow that I test ALL hooks via this PR, I get a warning on one task:\nTASK [deploy : Update WP theme paths] ******************************************\n [WARNING]: The loop variable 'item' is already in use.\nYou should set the `loop_var` value in the `loop_control` option for the task\nto something else to avoid variable collisions and unexpected behavior.\nAs the warning suggests, it goes away after using a custom loop_var:\n```diff\nroles/deploy/tasks/finalize.yml\n\n\n\ninclude: \"{{ item }}\"\n\n\n\n\ninclude: \"{{ include_path }}\"\n    with_items: \"{{ deploy_finalize_after | default([]) }}\"\n\n\nloop_control:\nloop_var: include_path\n    tags: deploy-finalize-after\n``\nAlthough there may be some setting to disable the warning, it looks like we should add the customloop_varto every deploy hook, enabling users to employwith_itemsin their custom includes without potentialvariable collisions and unexpected behavior` mentioned in the warning.\n\n\nI created #817 to fix the new warning caused by using loop_var on include tasks:\nTASK [deploy : include] ********************************************************\n [WARNING]: Failure using method (v2_runner_item_on_ok) in callback plugin\n(<ansible.plugins.callback.output.CallbackModule object at 0x104893f90>): 'item'. @strarsis Thank you for all your work and patience making this great improvement to Trellis!. @pySilver Given that there are no per-site hooks by default, could you help me try to replicate the issue by posting the steps you've taken in setting up your per-site hook? Could you post your definition of the hook (example) and mention in which file you defined it? Also, post the filepath to the file you want included. Do the included tasks never run or do they show errors? If errors, could you post your tasks for review?. @pySilver Thanks for the clear example. \ud83d\udc4d \nThis raises the question of whether in this context we should override Ansible's default behavior of failing when a specified include file is missing. I tend to think the default behavior is worth keeping.\nI certainly understand the desire to only include files if they exist, particularly in this context. I wish there were such an option built-in as standard in Ansible (not requiring the extra stat task).\nYour approach above is very straightforward. Here are a few alternatives that would avoid modifying Trellis core files. These ideas build on the fact that Ansible's with_items does nothing with an item that is an empty list: []\n```\noutput is ONLY \"one\"\n\ndebug:\n    msg: \"{{ item }}\"\n  with_items:\none\n[]\n```\n\n\n\nSpecify include in wordpress_sites\nCapitalizing on how a site's variables are loaded into a project variable, you could indicate the include file per site in wordpress_sites:\nwordpress_sites:\n  a.com:\n    build_before_include: \"{{ playbook_dir }}/deploy-hooks/build-before/a.j2\"\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before.yml\"\n  - \"{{ project.build_before_include | default([]) }}\"\nCheck site name\nAn alternative would be to use a ternary filter to check site name then return the include file or [].\n```\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before.yml\"\n  - \"{{ (site == 'theONE.com') | ternary(playbook_dir + '/deploy-hooks/xyz/' + site + '.j2', []) }}\"\nor\n\n\"{{ (site in ['theONE.com', 'otherone.com']) | ternary(playbook_dir + '/deploy-hooks/xyz/' + site + '.j2', []) }}\"\n```\n\nCheck file existence\nThe above approaches require manual adjustment over time if you add/remove include files. A method to achieve your original intent of only including a file if it exists avoids that extra work, but is a little more complex. Suppose you use a pipe lookup to check the file's existence: if exists return file path, else return []. Based on the following bash command:\n[ -f path/to/file ] && echo path/to/file || echo []\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before.yml\"\n  - \"{{ lookup('pipe', '[ -f '+ playbook_dir + '/deploy-hooks/xyz/' + site + '.j2 ] && echo ' + playbook_dir + '/deploy-hooks/xyz/' + site + '.j2 || echo []') }}\"\n. closed by #812\nThank you @scherii for your excellent work on this PR and improving the self-signed certs for Trellis!. Works in my tests!\n\ud83c\udfc6  So many will be spared the frustration.. I just tested this latest 3ca2d19 and it works great. Gets around that pyenv issue I had with a previous iteration.\nThe only other thing I can think of is that the README \"Requirements\" section could say that Ansible is optional.. option in #834. :+1: Looks great to me!. Works for me! Tested on Vagrant 1.8.5, 1.9.1, and 1.9.3. I added a commit that changes the focus, while still removing the ID from the bundled cert filename.\nThe new focus is to expand renew-certs.py to handle a greater variety of potential starting points, system states. For example, it accommodates the possibility that users will try to run only --tags wordpress after making changes to site_hosts and/or deleting Let's Encrypt files that would require running --tags letsencrypt.\nThis new approach also adds a tag to the task that executes renew-certs.py, such that --tags wordpress will execute renew-certs.py to create the new non-ID-in-filename bundled cert. This is a more broadly applicable implementation than the two extra rsync tasks in this PR's former commit. I've removed those rsync tasks.\nWith so many edits to renew-certs.py, the diff view isn't too helpful. It's probably more worthwhile to simply view the new file instead.\n@strarsis, The bundled cert's path is now stable (no ID). Is that enough, or is it a problem that the root cert filename and CSR filename will each still have changing IDs? (#286). My error in saying \"root cert.\" I meant to refer to the \"end-entity cert\" or \"leaf certificate\" that Let's Encrypt issues for the server. This filename WILL have the changing ID, but I suspect other programs wouldn't use this file.\nWhen I mentioned \"bundled cert\" I meant the chained certificate that browsers care about: the concatenation of our server's end-entity cert and the Let's Encrypt intermediate cert. It is the only cert file we serve and will NOT have an ID (after this PR). . Looks good to me!. thank you!. @strarsis That cron file is puzzling and I wasn't able to reproduce: my cron file is not created with the superfluous line: day: \"{{ letsencrypt_cronjob_daysofmonth }}\"\nGiven the presence of 1,11,21 in the first line of the job,  it appears that the letsencrypt_cronjob_daysofmonth variable is being interpolated as part of the day parameter.\nOf course, the strange part is the superfluous line: day: \"{{ letsencrypt_cronjob_daysofmonth }}\". It looks a lot like somehow the newline that should be at the end of the job is not being interpreted such that the job value is including the next line day, with its four spaces of indentation. When I glance at the module code for your version 2.3.0.0, I don't see any obvious questionable portion that could associated.\nAny chance your text editor has added unusual or hidden characters or encodings in your file at roles/letsencrypt/tasks/main.yml? Perhaps you could turn on any \"show hidden characters\" options for this file in your text editor and investigate (especially in the area of the newline between job and day), or pull a fresh clone for testing.\nPerhaps you could try removing /etc/cron.d/letsencrypt-certificate-renewal from the server and run the playbook again to see if the new cron file still has the problem. I only suspect it could be different this time if the cron file creation task was actually skipping in your recent retries.. The third commit Accommodate child themes: Update WP stylesheet_root separately addresses https://discourse.roots.io/t/template-root-not-updated-by-env/9724\nWhen a child theme is in Bedrock web/app/themes and its parent theme is in different directory (e.g., web/wp/wp-content/themes), stylesheet_root must be /themes while template_root should be updated with the latest deploy releases_path. Prior to this commit, stylesheet_root was always updated with template_root, causing problems for some child themes.. The fourth commit Deploys: --skip-themes when updating WP template_root addresses https://discourse.roots.io/t/deploy-failing-at-task-deploy-get-wp-theme-template-root/10017\nSome WP themes may throw errors if loaded in this context, e.g., some PHP classes may not be available with --skip-plugins. It is not necessary to load themes when updating WP options for template_root and stylesheet_root, so it is safer to --skip-themes.\nTrellis already uses --skip-themes in conjunction with --skip-plugins in the WordPress Installed? task.. Closing. Will split into small chunks for easier testing and review.. diff\n  vault_wordpress_sites:\n    other-site.com\n      admin_password: XXX\n      env:\n        db_password: XXX\n    nest.cz:\n      admin_password: XXX\n-     end:\n+     env:\n        db_password: XXX\n\ud83d\ude0e \n\nNote that Trellis will create the .env file for you (probably overwriting the one you manually created by copying the Bedrock .env.example). See default env values in the docs or in trellis.\nYou can override the default env values using your existing env section of vault_wordpress_sites (for secrets) or add an env section to the regular wordpress_sites for non secret values, e.g., \nwordpress_sites:\n  nest.cz:\n    ...\n    env:\n      db_name: nest\n      db_user: nest. I added two commits:\nDeploys: Minimize delay in updating WP theme paths\nAfter a new release path is symlinked, sites that need WP theme paths updated won't load until updated, a window of 1-10+ seconds. Thanks @karex for pointing this out.\nThis commit shuffles tasks so the update task runs as quickly as possible after symlink change.\nRemove WP transient _site_transient_theme_roots during deploys\nWP options template_root and stylesheet_root will not exist for a site when no theme has been activated explicitly, when a site defaults to a theme like twentyseventeen. In this case, WP consults the _site_transient_theme_roots transient for the path to the theme. This transient contains release paths that do not update on deploy, leading to WSOD due to various instances of \"No such file or directory.\" Original examination in #275 (comment).\nThis commit avoids the problem by removing the _site_transient_theme_roots transient immediately after the new release path is symlinked. WP regenerates the transient with correct paths as needed.. I tend to think that these variable defaults are appropriate here in the wordpress-setup role given that the vars are used in wordpress-setup role and not in the php role. In contrast, it appears that php_display_errors is used in both roles. \nAlthough users could intuit that roles/php/defaults/main.yml holds all the php configs, I think the real function of a role's default/main.yml is to hold defaults for variables used in the role, not to hold configs for a service generally (e.g., php generally).\nFor comparison, I added some nginx-related vars to roles/wordpress-setup/defaults in the past with the justification that the vars were only used in the wordpress-setup role.. Idempotent reporting. I was delightfully surprised that even with force, the get_url task reporting shows ok if the file is unchanged, versus always showing changed. I believe that to force download of the temp file every time enables calculating and comparing checksums.\nCopy module more flexible? Could users want a ssl_client_certificate that is not accessible via URL? Using the copy module may accommodate more scenarios. We could let users specify a local path to their own origin-pull-ca.pem they've previously downloaded to their machine, as is done with the provider: manual certs and keys. Using the copy module would avoid downloading every time and the related potential for playbook failure due to network connectivity issues.\nCapturing updates via partial hash in dest filename. If you stick with get_url, I assume the intent in using force is to detect and incorporate changes in the content at the URL. I think we could still capture updates even when force: no by appending to the dest filename a few characters from a hash of the URL. Ansible would detect that dest does not exist and proceed to get_url.\nThis assumes that the update would be at a new URL, NOT the same URL. The source URL doesn't strike me as official/canonical being in Cloudflare's support article_attachments: https://support.cloudflare.com/hc/en-us/article_attachments/201243967/origin-pull-ca.pem. I couldn't find any other URL. I suspect any updates to origin-pull-ca.pem could likely appear at a new URL.. Wonderful! Thank you @TangRufus!. Thanks! I see only benefits from this addition.\nIf people find that this addition causes trouble for their use case, they could use a child template to remove the {{ self.includes_d() -}} from the redirects_https and redirects_domains blocks. . Thanks for this! I agree that for new servers, we essentially always want the latest version.\nHowever, always updating existing servers' packages to the latest version could be an unwanted surprise, particularly in the rare case that the updates break something (like this thread about php?).\nOk, package updates rarely break things, but if playbooks occasionally update packages, users could develop general unease around the unpredictability of what may happen when they run Trellis playbooks. For instance, a user could modify one php param in group_vars and think: \"I want to apply this php change by running server.yml but I'm scared of what else could change and break.\"\nHow about making apt module tasks use variables for the name and state parameters? (untested)\n state would default to present but if users want the always-update behavior, they may define nginx_package_state: latest\n nginx_package_name: nginx=1.13.3-0 would lock down the version but users could redefine it to a different version, or some variant like nginx/stable, or just nginx if using state: latest. Trellis would have to constantly update these default version numbers \ud83d\ude41  but it would create a more predictable experience for users than an always-update default of state: latest.\n- name: Install Nginx\n  apt:\n    name: \"{{ nginx_package_name }}\"\n    state: \"{{ nginx_package_state | default('present') }}\"\n    update_cache: true\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n  notify: reload nginx\nIt would get a little more complicated for apt tasks that use with_items. For example, we could convert the apt_packages list into a dict:\n```\npackage-name=version: state\napt_packages_default:\n  python-software-properties=0.96.20.7: present\n  python-pycurl=7.43.0-1: present\n  build-essential=12.1: present\n  python-mysqldb=1.3.7-1: present\n  curl=7.47.0-1: present\n  git-core=1:2.7.4-0: present\n  dbus=1.10.6-1: present\n  libnss-myhostname=229-4: present\napt_packages_custom: {}\napt_packages: \"{{ apt_packages_default | combine(apt_packages_custom) }}\"\n```\nThen the related \"Checking essentials\" install task would use with_dict:\n- name: Checking essentials\n  apt:\n    name: \"{{ item.key }}\"\n    state: \"{{ item.value }}\"\n    update_cache: true\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n  with_dict: \"{{ apt_packages }}\"\nEdit: Changing the various apt_packages variables from lists to dicts would be a breaking change for people who have defined custom values for such variables. Locking down versions is probably worth it nonetheless. We could consider detecting the old list format and print a helpful message.\n  in vars.py or\n using type_debug in a fail task (requires bumping Ansible version_requirement from 2.2 to 2.3). @TangRufus Thanks again for all your work on this!\nThis PR adds to the php role a couple tasks verifying the dict format for php_extensions_custom and php_extensions. I wonder if it would be preferred to move these validations into the common role because it runs at the beginning of the playbook. Some users have expressed frustration with validation tasks that occur and fail late in the playbook. Strictly conceptually, the tasks belong in the php role but maybe they're better for users in the common role.\nI tried to produce a single task to verify the dict format of all the vars at once, but it wasn't as simple as I hoped.\nI think I see why you used a second separate task to validate vars like apt_packages that use the combine filter. If one of the component vars combined isn't a dict, Ansible fails with |combine expects dictionaries, got u'text_string'. Thus Ansible's error message hijacks your ability to print out the help message in time. So, the first step checks the format of component vars, then the second checks the combined vars.\nJust for brainstorming sake...\n```\nroles/common/tasks/main.yml\n\n\nname: Verify dict format for apt package component variables\n  fail:\n    msg: \"{{ package_vars_wrong_format_msg }}\"\n  when: package_vars_wrong_format | count\n  vars:\n    package_vars:\n      apt_packages_default: \"{{ apt_packages_default }}\"\n      apt_packages_custom: \"{{ apt_packages_custom }}\"\n      memcached_packages_default: \"{{ memcached_packages_default }}\"\n      memcached_packages_custom: \"{{ memcached_packages_custom }}\"\n      php_extensions_default: \"{{ php_extensions_default }}\"\n      php_extensions_custom: \"{{ php_extensions_custom }}\"\n      sshd_packages_default: \"{{ sshd_packages_default }}\"\n      sshd_packages_custom: \"{{ sshd_packages_custom }}\"\n    package_vars_wrong_format: \"[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' %}'{{ k }}',{% endfor %}]\"\n\n\nname: Verify dict format for apt package combined variables\n  fail:\n    msg: \"{{ package_vars_wrong_format_msg }}\"\n  when: package_vars_wrong_format | count\n  vars:\n    package_vars:\n      apt_packages: \"{{ apt_packages }}\"\n      memcached_packages: \"{{ memcached_packages }}\"\n      php_extensions: \"{{ php_extensions }}\"\n      sshd_packages: \"{{ sshd_packages }}\"\n    package_vars_wrong_format: \"[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' %}'{{ k }}',{% endfor %}]\"\n```\n\n\n```\nroles/common/defaults/main.yml\npackage_vars_wrong_format_msg: |\n  The following variables must be formatted as dicts:\n    {{ package_vars_wrong_format | to_nice_yaml | indent(2) }}\nSee: https://github.com/roots/trellis/pull/881\n```\nThe example above checks a few more vars. Your validations checked the vars that were essential to check. My extra vars shouldn't need to be checked, but I've learned to never assume what users will and won't do. Still, maybe it's overkill to check all the vars I listed above.. > Question: How to ensure common role is ran when users provision with Ansible tags?\nIf we want the two validation tasks I proposed in the common role to also run when a user specifies --tags other-role, we can just assign to those two tasks the tags corresponding to the relevant roles, like how the \"Validate format of site_hosts\" task uses tags: [letsencrypt, wordpress]. The two example tasks I posted would have the extra parameter \ntags: [sshd, memcached, php] \nThe simplicity of two new tags parameters seems preferable to the new commit \"Include dict format checks in common role\" which adds 6 new tasks and 4 new include files.\n\n\nWhen required variable is undefined, error message is also ugly.\n\nGiven that all these vars are defined in role defaults, it seems very unlikely any of these vars would ever be undefined. Although users sometimes fail to update group_vars when updating Trellis, I don't remember any reports of people failing to update a role's defaults/main.yml.\n\nbut I've learned to never assume what users will and won't do\n\nI'm skeptical that we must be ready for undefined in this case, but here's an adjustment to the example tasks I posted (untested).\n```diff\nroles/common/tasks/main.yml\n\nname: Verify dict format for apt package component variables\n    fail:\nmsg: \"{{ package_vars_wrong_format_msg }}\"\nmsg: |\nThe following variables must be formatted as dicts:\n{{ package_vars_wrong_format | to_nice_yaml | indent(2) }}\n\nSee: https://github.com/roots/trellis/pull/881\n    when: package_vars_wrong_format | count\n    vars:\n      package_vars:\napt_packages_default: \"{{ apt_packages_default }}\"\napt_packages_default: \"{{ apt_packages_default | default({}) }}\"\napt_packages_custom: \"{{ apt_packages_custom }}\"\n\napt_packages_custom: \"{{ apt_packages_custom | default({}) }}\"\n        ... (etc.)\n      package_vars_wrong_format: \"[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' %}'{{ k }}',{% endfor %}]\"\n\n\nname: Verify dict format for apt package combined variables\n    fail:\n\nmsg: \"{{ package_vars_wrong_format_msg }}\"\nmsg: |\nThe following variables must be defined and formatted as dicts:\n{{ package_vars_wrong_format | to_nice_yaml | indent(2) }}\n\nSee: https://github.com/roots/trellis/pull/881\n    when: package_vars_wrong_format | count\n    vars:\n    package_vars:\napt_packages: \"{{ apt_packages }}\"\napt_packages: \"{{ apt_packages | default({}) }}\"\nmemcached_packages: \"{{ memcached_packages }}\"\nmemcached_packages: \"{{ memcached_packages | default({}) }}\"\n        ... (etc.)\npackage_vars_wrong_format: \"[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' %}'{{ k }}',{% endfor %}]\"\npackage_vars_wrong_format: \"[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' or vars[k] is not defined %}'{{ k }}',{% endfor %}]\"\n```\n\n. @TangRufus Let me say again, THANK YOU for all your patient work on this! \ud83d\udc9a \nAs I scrutinize it a bit more, I have a couple more comments. \nupdate_cache parameter\nThis PR normalizes the apt module tasks to always use both the parameters update_cache and cache_valid_time. Regarding cache_valid_time I just noticed this docs note: \n\nAs of Ansible 2.4, this implicitly sets update_cache\n\nAs I tested with -vvv, if the cache is not older than cache_valid_time, the task outputs \"cache_updated\": false even when update_cache: yes. This seems good. If the cache was older than cache_valid_time, the task outputs \"cache_updated\": true. Also good. In any case, the update_cache seems superfluous.\nGiven the recent Trellis requirement of Ansible 2.4, I think we can drop all instances of update_cache: yes for the apt module tasks (but don't remove it for the two apt_repository module tasks). What do you think?\npackage name indicates package version\nThe dict format for vars such as apt_packages_default makes it possible for users to redefine the dicts in a manner that specifies package versions, however uncommon the scenario may be: \napt_packages_default:\n  # package_name: state\n  # package_name_and_version: state\n  python-software-properties=0.96.20.7: present\n  python-pycurl=7.43.0-1: present\n  ...\nThe above formatting takes advantage of how the apt module uses the name parameter to set the package version:\n\nNAME: A package name, like foo, or package specifier with version, like foo=1.0\n\nHowever, some the apt tasks \"hard code\" the name parameter. Contrast the nginx-related name: \"{{ nginx_package }}\" with the fail2ban-related name: fail2ban. In the case that a user wants a specific version of nginx, the user may redefine the nginx_package variable. However, the user would not be able to define the package name/version for the following:\n ferm\n mariadb-client\n mariadb-server\n fail2ban\n ssmtp\n php-xdebug\nI honestly don't know the answer to the following question: Would it be desirable to make vars such as ferm_package for each of these additional packages so that users could potentially specify versions, or would that be over-developing things?\n. Awesome, @TangRufus!\nLooks good to me! :+1:. @nbyloff Thanks for your time and effort on this. You've provided valuable engagement with Trellis on GitHub and discourse over the longterm.\nTL;DR\n\nInstead of merging this PR, I suspect users could achieve greater benefit by running \nansible-playbook custom.yml -e env=production\nwhere custom.yml uses import_playbook: server.yml and any desired custom tasks, includes, etc.\nI think this PR's feature needs to be preceded by a broader discussion of whether and how to enable users to extend Trellis (esp server.yml).\n\n\nDelayed response\n\nI can't help but notice this is the only PR with no activity. Is it safe to assume this, or anything similar won't make it?\n\nAlthough this PR is simple in terms of changed LOC, I think this PR is complex in its implications for big picture strategy. I'm afraid complex PRs often sit open longer because of the time investment they will require. That's no excuse for neglecting to offer feedback, of course. It's just part of the challenge of volunteer OSS. We need to do better.\nHow could it hurt?\n\nIt seems harmless to me; if you are new or not comfortable with Ansible yet, this update would go unnoticed.\n\nAlthough this PR would be harmless for basic users, I'm concerned with the affect on users who do use this PR's functionality. If Trellis begins providing means to extend the provisioning of server.yml, I think the effort should explore a more general and versatile implementation. If such were implemented, it would likely mean removing this PR's specific code, breaking functionality for users who have already begun relying on it.\nAn alternative\nIt may seem that my hope for perfect is the enemy of the good, that any continued delay robs users of this PR's better-than-nothing option that is ready to use now. However, I think users have a superior option already available:\n\nI suspect users could achieve greater benefit by running \nansible-playbook custom.yml -e env=production\nwhere custom.yml uses import_playbook: server.yml and any desired custom tasks, includes, etc. \n\nI believe this alternative would offer users even more flexibility than trying to work within the specific implementation of this PR. For example:\n It enables users to also add tasks before server.yml.\n Suppose users decide they don't want the \"always include everything\" approach of with_fileglob which could require filenames like 1-name-x and 2-name-y. Instead, uses could choose an include_tasks approach of looping over a variable's list of include files.\n  * This is more explicit on which files will be included and in what sequence. The list order determines include sequence, obviating the need for numeric prefixes to filenames.\n  * In addition, disabling an include is a matter or merely omitting a filename from the list (or commenting it out), whereas the with_fileglob method requires removing the file altogether (or perhaps renaming the file). \nI think this alternative strategy of a custom.yml playbook that uses import_playbook: server.yml achieves the desired benefits you listed:\n\n\nWith the example code, a user can introduce new code in multiple ways. They could (1) have a single YAML file that references other YAML files (or complete roles) in the order they should be executed, (2) number the files like suggested in order of execution.\nI think this would actually encourage people to understand ansible and trellis more. I would imagine in most scenarios, once you're to the point you want to add custom functionality to provisioning, you have basic understanding of how things are working.\nMerging into your project from trellis master become a lot less painful (this cannot be understated how nice it will be)\n\n\nTrellis: Positioning and scope\nThe above is part of why \"I think this PR is complex in its implications for big picture strategy.\" Another part is the discussion of whether this PR would be a step in the direction of Trellis becoming more of a framework or at least able to provision and deploy a wider range of web apps (maybe related: #914). Such could be a shift in emphasis and possibly a dramatic change of scope. I'm not saying it shouldn't be considered or discussed. Rather, I'm saying that this PR may look simple on its face but it may actually be a huge deal, with commensurate time investment.\nHook inconsistencies?\nK cool, but what about this...\n\nWe have deploy-hooks, why not provision-hooks?\n\nI'm sympathetic to the implied argument of this question. I don't totally disagree but I'll try to play devil's advocate and offer a rebuttal.\nIn the context of \"what is it?\" one could say, \"server.yml and deploy.yml are both playbooks with roles, right? So, the presence or lack of hooks seems inconsistent.\" This is random, but what if we were talking about a private home's entryway door vs. a building's entryway revolving door. They are both doors and the presence or lack of a door knob may seem inconsistent. The different implementation of the door or playbook only makes sense when considering the broader context and purpose. Ok, now forget about doors (my hasty and inapplicable dilution to discussion).\nThe WordPress sites that users may deploy could vary quite a bit, driving a need for deploy hooks to facilitate customization. In contrast the \"WordPress app server\" itself (the stuff handled by server.yml) may differ much less between users. Most app server differences are configurable via existing play and role variables. Of course, app server differences would far more vast if Trellis were to position itself as a framework.\nThe belabored point is that although some users will desire to customize server.yml, the desire will probably be much less common than with deploy.yml. In addition, provision and deploy are conceptually different, which is part of the reason for the separation into distinct playbooks. I think these factors weaken the implied argument of \"We have deploy-hooks, why not provision-hooks?\"\nShould Trellis run your custom stuff, or should your custom stuff run Trellis?\nUsers will have custom stuff to run, as in your example:\n\nI always add a custom backup job that zips and pushes the DB and uploads directory to an Amazon s3 bucket nightly.\n\nOne angle on the issue of running custom stuff is to ask the question:\n\ud83d\udd34  Should Trellis run users' custom stuff or\n\ud83d\udd35  should users' custom stuff run Trellis?\nAs a concrete example,\n\ud83d\udd34  should Trellis provide hooks in server.yml or\n\ud83d\udd35  should users create a custom.yml playbook that uses import_playbook: server.yml. \nAlternatively, a more decoupled custom playbook could run only select Trellis roles.\nI acknowledge that \n\ud83d\udd34  for a certain chunk of the task of deploying, Trellis runs your custom stuff (i.e., in Trellis deploy-hooks).\n\ud83d\udd35  However, maybe your custom stuff (like CI tools) actually run Trellis deploys.\nAs examples for server.yml and provisioning,\n\ud83d\udd34  Trellis could expand to initiating your infrastructure (e.g., via DigitalOcean API, terraform, etc.) and creating your S3 backups.\n\ud83d\udd35  Or maybe you build out other tools to execute those tasks, and one step in your tool is to run Trellis server.yml. \nI'm rambling and am going to trail off without a strong opinion or recommendation on this particular issue. I think it's worth considering building more of this functionality into Trellis, or at least aggregating guides for extending Trellis and for setting up workflows that run Trellis at certain points.\nAgain, thank you!\nClarification, rebuttals and feedback welcome.. I added a commit with the change that @TangRufus \ud83d\udc9a suggested in the discussion above:\n\nThose other directives ~are~ could be absent even with this patch. Edge case: All sites using third party ssl providers. The if/else conditions never matched.\nPossible solution: Always generate self-signed cert for ssl.no-default.conf as h5bp/server-configs-nginx#177 suggested.\n\nThus ssl-related third party roles need not be cognizant of ssl.no-default.conf.\nImplementation notes:\n if no sites create a self-signed cert, this creates one for throw-away example.com\n ssl.no-default.conf uses the first existing self-signed cert, if any, else the example.com cert\ngit logistics:\n Had to rebase for travis to succeed. Branch was old, not compatible with Ansible 2.4.\n Commits should be squashed upon merge.. tags. I replaced some long tags lists with always. This way the diffie-hellman and letsencrypt cert IDs tasks will always run despite any --tags, but still only if the task's when condition is true. This seems better than trying to track and add any tags that these tasks would need as things evolve over time, as we've been doing. Using the always tag is also a little more conservative in case third-party roles might need those tasks to run even when users specify --tags galaxy_role_only.\nno_default.cert I changed to always using a new no_default.cert instead of only using it when no real site's cert is available. My original goal was to avoid creating an extra cert if we could just use an existing one. This was an example of me falling victim to a pattern of complicating things while trying to enable Trellis to potentially run fewer tasks.\nCreating this self-signed no_default.cert is not costly, taking less than one second. It makes for slightly more understandable ansible code. Users will find it more straightforward that ssl.no-default.conf always uses the no_default.cert instead of sometimes using a real site's cert.. I reverted the tags from always back to lists of tag names. Sorry I didn't reflect much before making that change. I hadn't considered the implications of tagging always and I realize that in fact, I really don't want these tasks to run always.\nExample. Suppose a user has a fresh server and runs --tags common for some reason. The Diffie-Hellman task will try to run due to its tag always but its relevant /etc/nginx/ssl dir won't exist yet and the task will fail. \nAdded changelog entry. I think this one is finally good to go. Should be squashed.. Future readers: Related issues are most likely support questions more applicable for discussion at https://discourse.roots.io/ rather than issues for this GitHub bug tracker. \n\n@pawelkleczek The error you posted appears different than the original issue. Note:\n\n\"detail\": \"Error creating new authz :: Issuance for IP addresses not supported\"\n\nIf using SSL enabled: true and provider: letsencrypt you must not use an IP in site_hosts. If your reason for using an IP is that you're still in development and don't yet have public DNS set up, you could omit the IP from site_hosts (use domain names instead) and fake DNS using your local machine's /etc/hosts file. Or if you must use an IP in site_hosts during development, you may need to use provider: self-signed or disable SSL.\n\n@jrgd It appears your Trellis needs the update in #921 as mentioned above.\n\nClosed by #921. Looks good to me.\n\n\nIPv6-related notes from  #885:\n\nTesting IPv6\nOf course, to test IPv6, one's local machine and server must both enable IPv6. For Trellis to make IPv6 SSH connections (e.g., to run a playbook), adjust the ListenAdresses and AddressFamily:\n```diff\n sshd_listen_addresses:\n   - 0.0.0.0\n+  - '::'\n\n-sshd_address_family: inet\n+sshd_address_family: any\n```\n\n\u26a0\ufe0f Trellis is not ready for IPv6 in production. There are no ip6tables settings.. I think the issue could have to do with running xdebug-tunnel.sh with local development, whereas I think it is only needed for remotes like staging or production.\n\nThe docs mention:\n\nWhile we default to installing Xdebug in development, installing it in any other environment is \"opt-in.\" It is not recommended to use Xdebug in production, but ... [if you must] ... This is where bin/xdebug-tunnel.sh comes in.. Thank you for the initiative to look into this. However, the last I looked (in #895) the problematic includes were in an upstream dependency:\n- update include to import_tasks, include_tasks or import_playbook (docs and docs).\n This avoids deprecation warning. However, server.yml will still show deprecation warning till the composer galaxy role changes these two includes.\n\nThe upstream has an open issue: geerlingguy/ansible-role-composer#42. I forgot to mention (or notice?) another upstream:\n Issue: geerlingguy/ansible-role-ntp#44\n PR: geerlingguy/ansible-role-ntp#46. @geerlingguy :star2: Thanks so much!. Works for me. Thanks!. Hi @claridgeandco! I'm closing because this looks like the \"incomplete updates\" scenario discussed on the support forum at https://discourse.roots.io/t/package-vars-wrong-format-error-with-ansible-trellis/10659/2. Could you try out the steps at that link?\nIf you'd like to discuss further, feel free to post a topic over at discourse.roots.io\nIf this starts looking more like a bug instead, we can reopen this issue here on the bug tracker. . @partounian When I get time, I'll create a demo of one potential implementation. It relies on Ansible's include_role module, which has a few issues still being resolved upstream, hopefully to be fixed in Ansible 2.5. The two of the more relevant issues in my opinion: ansible/ansible#35167 and ansible/ansible#36372.. \ud83d\ude04 Good job solving it (according to your edit to title, adding \"Solved\").\nYep, I think this was handled in #948\nRemember to search issues before posting, as suggested by the issue template checkbox:\n\n\n[ ] This request isn't a duplicate of an existing issue. lgtm\n\n\nOptionally could make it a default var memcached_port_udp: 0 but maybe it'd never be used.. @inthedeepend This is great. Thank you!\nIt works as is, but more style opinions incoming! :scream:\nFor the sake of consistency with existing Trellis caching options, I think there are two patterns this new fastcgi_cache_background_update option should follow.\nWhere defaults are defined. Notice that the cache options in the docs are absent from wordpress_sites (except enabled) which works because they are in the role defaults. This keeps wordpress_sites streamlined.\nHow defaults are defined. The cache directives in wordpress-site.conf.j2 follow this pattern:\ndirective {{ item.value.cache.directive | default(nginx_cache_directive) }};\nA user could define nginx_cache_directive as a global override and/or set a per-site override by defining the cache.directive in wordpress_sites.\n:star: To be consistent with these patterns, could you...\n remove background_update setting from wordpress_sites\n add nginx_cache_background_update: on to Fastcgi cache params defaults\n* drop all changes from wordpress-site.conf.j2 (including the new blank lines, comments, and {% if %} blocks), leaving only the following:\n  diff\n    fastcgi_no_cache $skip_cache;\n  + fastcgi_cache_background_update {{ item.value.cache.background_update | default(nginx_cache_background_update) }};\nI'm inclined to drop the explanatory comment because no other Fastcgi cache settings have comments, but I don't feel too strongly about it.\nI'm inclined to not add the extra blank lines because then the templated conf on the server would have double blank lines in some spots. Of course, it could be argued that the goal should be readability in the Trellis wordpress-site.conf.j2 template (hence your new blank lines) rather than perfect formatting in the conf on the server (the current focus).\nhttp codes. \n\nshould we specify 200 301 302 404 and possibly increase caching to 1m? (comment above)\n\nLooks like 200, 301, and 302 are covered by default (nginx docs). I don't know much about why and when to also include 404, but I'm inclined to continue with the default because desire for an alternative hasn't ever come up that I remember. Users could change it using child templates.. @TangRufus thanks for pointing out the article update regarding 404 pages. I haven't tested the need nor the solution, but the description makes sense to me. Do you envision a change like this?\ndiff\n- fastcgi_cache_valid {{ item.value.cache.duration | default(nginx_cache_duration) }};\n+ fastcgi_cache_valid 200 301 302 404 {{ item.value.cache.duration | default(nginx_cache_duration) }};\nOr we could do shorter expiration for 404s, but I doubt it makes a big difference:\ndiff\n  fastcgi_cache_valid {{ item.value.cache.duration | default(nginx_cache_duration) }};\n+ fastcgi_cache_valid 404 1s;. #### Validate SSL provider name\nI'm inclined to fold the question of validating SSL provider names into the Trellis project goal of improving organization of SSL-related ansible roles and extensibility (e.g., #893, #896).\nI think this validation is more complex than simply checking whether ssl.provider in ['letsencrypt', 'manual', 'self-signed'] (built in providers) because we likely want to accommodate third-party SSL roles offering additional provider names.\nFor example, typisttech/trellis-cloudflare-origin-ca role uses provider: cloudflare-origin-ca. If such roles were to use the same name for the role and the provider, Trellis could validate ssl.provider in role_names (role_names is an Ansible magic var).\n--tags letsencrypt\n\nAlso running tags letsencrypt doesn't work alone, it requires you to run nginx if you have not previously dhparams\n\nThanks for catching this. The letsencrypt tag for the dhparams task is long overdue. Fixed in #964.\n. \ud83d\udc4d Looks good to me. I lean toward keeping the all directory. Thanks @partounian!. Closed in #975 \nThanks @newloong!. Any chance you have in your group_vars an override definition of nginx_sites_confs? If so, be sure to include the ssl.no-default.conf.j2 added  in #888 \nIn default Trellis, /etc/nginx/ssl/no_default.cert is created during the wordpress-setup role when at least one site in wordpress_sites has ssl enabled. If no site has ssl enabled, the ssl.no-default.conf should be disabled/unlinked and thus an Nginx start/restart/reload shouldn't try looking for the no_default.cert. \nIn other words, I don't know how the reported scenario could occur unless you have an (incomplete) override of nginx_sites_confs, or you applied an incomplete set of Trellis updates, or you ran an unusual subset of tasks (and with playbook failure).\nMaybe you could share the output of \nansible-playbook server.yml -e env=production --tags wordpress -vvv\nIf you choose to excerpt the output, be sure to include these tasks:\n Generate self-signed certificates\n Create Nginx available sites\n Enable or disable Nginx sites\n Create WordPress configuration for Nginx\n the two nginx handler tasks at the end of the playbook\n any final error output at the end. @newloong Thanks for this. We discussed internally and agree we should enable the ssh:// form.\nBackground. I think #459 added the regexp validation to quickly warn users against the http(s):// format that often doesn't allow connection to private repos during later deploy tasks. I think #516 adjusted the regexp to ensure users had the : in their repo's git format (:x: git@github.com/roots/bedrock but \u2705 git@github.com:roots/bedrock).\nYour regexp. Could you revise your regexp to disallow the http(s) repo format? See proposed revision in example below. Does that regexp work for your CodeCommit repo?\nExample revision. Maybe the fail msg could give the ssh:// format as an example too, e.g.,\n- name: Ensure repo is valid\n      connection: local\n      fail:\n        msg: |\n          Invalid Git repository format.\n          Ensure that your site's `repo` variable is defined in\n          `group_vars/{{ env }}/wordpress_sites.yml` and uses an SSH format.\n          Examples:\n            - git@github.com:roots/bedrock.git\n            - ssh://git@github.com/roots/bedrock\n          More info:\n          > https://roots.io/trellis/docs/deploys/\n      when: project.repo is not defined or not project.repo | match(\"(^ssh:|.+@.+:.+)\")\n. @newloong Thanks for the revised regexp. I like how you got rid of the unnecessary ( ) from my suggested example.\n.git I should have mentioned it explicitly, but given that git clone git@github.com:roots/bedrock succeeds without the .git at the end, could you remove the regexp's requirement that repo values in \\.git? I realize the original regexp in trellis had the .git so it made sense that you kept it.\nslashes. Your pattern requires ssh:\\/\\/. I don't think it is necessary to escape the slashes. I don't think slashes are special/control characters in this context (a la https://docs.python.org/2/library/re.html#regular-expression-syntax) and aren't being used as pattern delimiters. Could you use the visually simpler ssh://? \n.* vs .+ This last comment is trivial and you can ignore it if you want. I think each instance of .* truly needs \"one or more\" characters (.+); it would be an incorrect format if a user were to specify zero characters in any of those locations of the pattern, a la the \"zero or more\" of .*. Once again, I realize the original regexp used .*, but I think it'd be nice to get the extra accuracy given that it comes at no additional characters/cost.\nsummary. So, altogether I'm proposing:\ndiff\n- match(\"^ssh:\\/\\/.*@.*|.*@.*:.*\\.git\")\n+ match(\"^ssh://.+@.+|.+@.+:.+\")\nThanks again! Your help with this PR brings Trellis a good improvement.. ### arg_customize_changeset_uuid\n\nWhere is arg_customize_changeset_uuid from? Does that come from the customizer?\n\nYep, from the Customizer's embedded content:\n<iframe src=\"https://example.com/?customize_changeset_uuid=8c0f9f64-2daf...\"></iframe>\nNginx supports variables such as $arg_name for the \"argument name in the request line.\" Nginx allows checking the presence of query parameters with if ($arg_name) {}.\nI figured the presence of that query parameter was the most convenient indicator of whether a request was for the Customizer's embedded content. Although a malicious embed could spoof this strategy by adding a fake customize_changeset_uuid query parameter, it should fail. \n An attempt to embed a real customize_changeset_uuid on some other domain should fail because WP code adds X-Frame-Options and frame-ancestors headers for embedded content. Also, embed content will fail with non existing changeset UUID unless the embed and parent ORIGIN are the same, and the user is logged in to wp-admin. Discussion at trac-39128.\n An attempt to use a fake customize_changeset_uuid query parameter outside the Customizer context just to fool this PR's proposed conditional X-Frame-Options will fail for most modern browsers because this PR's added Content-Security-Policy: frame-ancestors 'self' usually overrides X-Frame-Options anyway.\nMove from h5bp to Trellis core\n\nI think we should just move this out of the h5bp directory now and make it ours.\n\nI added a commit commenting out the X-Frame-Options in the h5bp file to prevent duplication, then adding this PR's revised headers to a new {% block embed_security -%} in wordpress-site.conf.j2. The headers restricting embeds are enabled by default but users could define nginx_embed_security: false globally in a group_vars file or per site in wordpress_sites, the latter location taking precedence.\nMy choice of wordpress-site.conf.j2 as the home for these headers, vs. a new include file, was in spirit of \"Fewer templates/includes, but still DRY,\" a section in #740's comments. I chose against trying to add the headers as a new Trellis core file in includes.d because I suspect users see nginx-includes and includes.d as exact parallels, and the user's province only. I also didn't want to figure out coordination with the includes.d cleanup feature.\nIf Trellis begins to have or desire multiple Trellis core Nginx include files, perhaps the Copy h5bp configs task could become Copy Nginx configs and use with_items: [h5bp, trellis] where h5bp is the same directory as currently and trellis is a new directory with Trellis core confs such as embed-security-headers.conf. In such a case of non-templated files (copied only), these directories could be in a roles/nginx/files directory instead of roles/nginx/templates where h5bp is currently.\n. Wow, thanks for bringing more attention to this. \nAlso at https://discourse.roots.io/t/nginx-restart/12287\nOn server just a few months old I see that nginx is enabled to start on reboot.\n```\n$ lsb_release -a\nDescription:    Ubuntu 16.04.3 LTS\n$ sudo systemctl is-enabled nginx\nenabled\n```\nOn a new VM and a new server at DigitalOcean I see that nginx is no longer enabled to start on reboot.\n```\n$ lsb_release -a\nDescription:    Ubuntu 16.04.4 LTS\n$ sudo systemctl is-enabled nginx\ndisabled\n```\nI believe adding this to the end of roles/nginx/tasks/main.yml would resolve it:\n- name: Enable Nginx to start on boot\n  service:\n    name: nginx\n    enabled: yes\n    state: started\n    use: service\nansible/ansible-modules-core#3764 led me to ansible/ansible#22303.\nRelated: geerlingguy/ansible-role-nginx#151\n\u26a0\ufe0f  Needs testing (e.g., on older Ubuntu 16.04.x and on various Ansible versions)\nAs for the failed curl 192.168.50.5 I think it's just because site_hosts doesn't include the IP.\n. I added a commit to cover Ansible 2.5.2. Its release was fast-tracked (changelog). It works fine.\n@runofthemill I suppose making 2.5.x the minimum requirement would avoid this PR's detection and warning about 2.5.0. I haven't thought through other benefits. I imagine you have some in mind.\nI've become wary of bumping the minimum Ansible requirement unless absolutely necessary because of complicating things for users with multiple Trellis projects on multiple Ansible versions (examples: one, two).. I added a commit to cover Ansible 2.5.3. It works fine.. @glopena The server.yml playbook for provisioning is not running xdebug. The System info: section of the output indicates version for Ansible, OS, and Trellis. I realize it could appear that Trellis at \"Some CHANGELOG entry\" could appear to be an indication of where the error occured, but the intended message is \"Trellis at version, indicated by latest entry in the CHANGELOG.md\". That is background to explain that the error you ran into is not actually related to this old merged PR.\nI am able to reproduce the Bad SSH2 mac spec message if I run Trellis on Ubuntu 18.04, which apparently comes with OpenSSH_7.6p1 in which the the hmac-ripemd160 MAC is no longer supported (props to this investigation into the error). \nAlthough we'll soon offer support for the recently released Ubuntu 18.04, Trellis is only intended for 16.04 at this time. This is indicated in the README.md and docs.\nI'd recommend using Ubuntu 16.04 for the sake of proven Trellis compatibility. If you are using 18.04 and want to continue with it, you could avoid the Bad SSH2 mac spec error by overriding the sshd_macs_default variable, omitting the two ripemd160 entries. For example, add the following to group_vars/all/main.yml:\nsshd_macs_default:\n  - hmac-sha2-512-etm@openssh.com\n  - hmac-sha2-256-etm@openssh.com\n  - umac-128-etm@openssh.com\n  - hmac-sha2-512\n  - hmac-sha2-256\nThen rerun the server.yml playbook.. Hi @vesper8! That would be a really frustrating situation. Glad you figured it out. \nI suspect this was an unfortunate glitch you'll never encounter again, but if you can share steps to help me reliably reproduce the problem, I'd love to get it resolved.\nIf that letsencrypt-mydomain.com.conf was indeed the cause, I suspect this was a rare glitch because\n1) I don't recall ever seeing this issue before\n2) I know that I and others often run the letsencrypt role before DNS has been set up or propagated, requiring nothing more than rerunning server.yml with --tags letsencrypt once DNS is ready\n3) a few details about the letsencrypt-mydomain.com.conf file...\n    * If ever the conf is enabled, Trellis notifies a task that should always run later to disable the conf (a \"handler\"). This handler's cleanup would only fail if the playbook were manually interrupted (e.g., CTRL+c) or if the playbook were to experience some other abnormal failure that prevents handlers from running.\n    * The wordpress-setup role always imports and runs that same task to disable temporary challenge sites. You ran the wordpress-setup role when you disabled SSL temporarily, so I don't know why it wouldn't have disabled the conf for you.\nOne potential source of the problem: If after first failed playbook run, the site key was changed such that subsequent cleanup attempts wouldn't look for nor find the filename to clean up (filename includes site key).\n\n\nI don't understand why deleting this file made the problem go away. Also, this file was NOT re-created when it finally fixed the issue\n\nIf the letsencrypt-mydomain.com.conf file had the same server_name value as your primary /etc/nginx/sites-available/mydomain.com.conf then Nginx would only pick one or the other server {} blocks, probably leading to something unexpected. When you removed the conf, you perhaps removed the competing server block (if somehow that sites-available/letsencrypt-mydomain.com.conf you removed was still symlinked over to sites-enabled/letsencrypt-mydomain.com.conf). \nThe letsencrypt-mydomain.com.conf file's purpose is just to include acme-challenge-location.conf; if /etc/nginx/sites-available/mydomain.com.conf doesn't already exist with that include directive, which is typically only the case on your very first run of server.yml. Subsequent runs usually don't need this include directive added, so the letsencrypt-mydomain.com.conf file is usually not needed nor created.\n\nI'm going to close this because I doubt it's very reproducible, but feel free to post back with more info or share steps to help me reliably reproduce the problem and we'll reopen.. I haven't reviewed yet. There may be some ideas in the old python-3-compat branch, e.g., in 9e83883\nHere are some hastily pasted related notes I had from months ago...\n- Users can override the dynamic determination of interpreter by simply defining somewhere ansible_python_interpreter var (e.g., per host, or more globally in group_vars). See https://github.com/ansible/ansible/issues/21311\n- httplib (letsencrypt test acme challenges) taken from https://github.com/ansible/ansible/blob/e4efc191c5be078ead687553538f92d035946f1f/lib/ansible/module_utils/urls.py#L45-L49\nI'll try to make time to review my old PY3 to-do notes and add them here.. Works in my basic testing. I don't anticipate any problems.\nLooks like a solid solution to a difficult to debug issue.\nThank you @louim! . As suggested, revised to use File.join().\nNote: I assumed you meant File.basename(bedrock_path) instead of File.basename('../example.dev').\n. If remote_site_path(site) will be defined at the bottom of the Vagrantfile, would it make sense to also define nfs_path(site) at the bottom? Might make this part feel cleaner.\n. (editing the two lines above...)\n\"Whenever you move or copy the Vagrantfile somewhere else, you need to make sure to adjust ANSIBLE_PATH (in Vagrantfile) and local_path (in group_vars/development).\"\n. (editing lines above to omit any mention of \"step 1 above\"...)\nTip: See the vagrant docs section \"Root Privilege Requirement\" for how to avoid having to type your password with every vagrant up (assuming you leave the default type: 'nfs' for config.vm.synced_folder in Vagrantfile).\n. The phrase \"and created\" reads a little funny. Maybe \"and will create\" or \"and creates\"? \n. (this might be a good spot for a note like this, if you want it)\n\"The full paths to these directories must not contain spaces or else Ansible will fail.\"\n(could include link to bug report over at ansible: issue 8555) \n. I probably should have enclosed local_path in backticks\n. If deploy_user etc. are defined in group_vars/all, could you remove roles/users/defaults/main.yml?\n. I'm pretty sure item.value.user and item.value.group will be undefined now that user and group are now removed from the wordpress_sites dict in group_vars/development.\n. Does deploy user need to be granted passwordless sudo for service php5-fpm reload? Or maybe you want to add sudo_user: admin and users will include --ask-sudo-pass? Sorry if I'm missing something.\n. I wonder if you actually want this:\nremote_user: \"{{ deploy_user }}\"\nbut I may be getting ahead of myself.\n. Oh. DeHaan (Apr '14): \"I'm sorry, you can't define sudo access to do specific commands this way.\" \n. I was just trying to figure that out. :smile: Some people store a sudo password in ansible vault, but seems less than ideal.\n. :tada: :tada: :tada: \n. I think this repo variable is only referenced in the deploy.yml playbook, and deploy.yml isn't used for development. Development continues using Vagrant sync folders for its bedrock.\nThis means there is a little less parity between development and production environments, in how they are provisioned. But I'm guessing it's better than problems that might arise by trying for parity on this issue. \n. Sorry @mAAdhaTTah  I didn't read your comment carefully. I had thought repo was already missing from development and you were asking why. I was wrong about what you were saying, and wrong about what was in the code.\n. gulp --productino\n. Want quotes on \"{{ vars }}\" in \"Finalize the deploy\"? Some possible others...\n- above in \"Copy vendor dir if exists to speed up composer\".\n- roles/deploy/defaults/main.yml (in comments for project_finalize)\n- roles/ferm/tasks/main.yml (various)\n- roles/nginx/tasks/main.yml (in \"Copy over h5bp configuration\")\n. Ah ha! I get it now. I was hazy on when quotes were needed. \n. I don't understand this \"Move site into root\" task. For me, it just skips because project_subtree is not defined.\n. Thanks. That makes sense. I hadn't imagined the cloned repo would be anything but bedrock alone (vs. including ansible etc.). Thanks for this additional insight into project setup, and for your comments earlier re: committing theme to bedrock repo. I need to digest what you said, and reread  the various discourse threads on that because I feel drawn to modularity of keeping them separate (even though I'm not reusing across multiple sites/projects).  \n. I'll think about it more carefully in a bit, but could you just clone the project straight into deploy_helper.new_release_path instead of cloning to one dir then copying to another? I think f500's version may have cloned to project_source_path just to coordinate with project_deploy_strategy: \"synchronize\", but you've omitted that.\n. I understand that f500/ansible-project_deploy_module is the proposed deploy_helper module for ansible-modules-extra. However, the tasks in question (Clone project files, Copy files to new build dir) come from f500/ansible-project_deploy.\nI wasn't under the impression that this latter was also destined for ansible-modules-extra. But even if not, perhaps you'd like to maintain similarity (perhaps because it's a galaxy role). If in fact you're not concerned with similarity, you may want to prune a lot of unused stuff out of /roles/deploy/defaults/main.yml (which isn't part of 'deploy_helper').\n. The deploy role's \"Reload php-fpm\" task only works for me if run as root instead of ROOT.\n@mAAdhaTTah This task was hanging for you too. Does this change resolve the issue?\ndiff\n- {{ web_user }} ALL=(ROOT) NOPASSWD: {{ service }}\n+ {{ web_user }} ALL=(root) NOPASSWD: {{ service }}\n@swalkinshaw If somehow capitalization could vary from system to system (I don't get how), maybe we could let each system name its own correct root by omitting user (root is the default when no user is specified):\n{{ web_user }} ALL= NOPASSWD: {{ service }}\n. #### Optional compile locally\nThis works for me, right before the \"Copy project files\" task.\nyaml\n- name: Run pre_build_commands_local on Ansible host\n  local_action: \"command {{ item.cmd }}\"\n  args:\n    chdir: \"{{ item.path }}\"\n  with_items: project_pre_build_commands_local\n...with the following example definition in defaults or wordpress_sites\nyaml\nproject_pre_build_commands_local:\n  - path: ../example.dev/web/app/themes/sage\n    cmd: gulp --production\nSwitch \"Copy project files\" to rsync\nI'd like to switch \"Copy project files\" to synchronize to use its .rsync-filter:\nyaml\n- name: Copy project files\n  synchronize: src=\"{{ item.src }}\" dest=\"{{ deploy_helper.new_release_path }}/{{ item.dest }}\"\n  with_items: project.sync_files  | default([])\n...used with this optional specification in wordpress_sites:\nyaml\nwordpress_sites:\n  example.com:\n    sync_files:\n      - name: compiled_theme_assets\n        src: ../example.dev/web/app/themes/sage/dist\n        dest: web/app/themes/sage\n@mAAdhaTTah this could replace the rsync task discussed earlier. \n. I asked \n\ncould you just clone the project straight into deploy_helper.new_release_path instead of cloning to one dir then copying to another?\n\nI now see the benefit of idempotence in cloning into project_source_path (example.com/shared/source). It will skip the cloning task if it already has the specified version. If cloning straight into the new release path as I proposed, it would perform the cloning every time.\n. I anticipated you'd change this to sudo: yes and remote_user: admin, given that secure-root.yml blocks ssh access for root.\n. <<<<<<< HEAD\n. oh! of course. Sorry.\n. The README installation section implies naming your Bedrock directory example.com, so maybe this could avoid potential confusion if it were.com instead of .dev. Same for other group_vars files, especially group_vars/development because it is the one that new users will encounter first.\n. However, for group_vars/development, I think site name should remain .dev because maybe you do have a live .com even while working with a dev VM. You wouldn't want vagrant-hostsupdater messing with the hosts file entry for .com. So, in group_vars/development, I'd suggest the defaults be site name example.dev but local path example.com (or my-bedrock).\n. Instead of adding a new task to \"Get current git commit\", try just adding the register: git_commit to the existing \"Clone project files\" task. Then get the SHA with something like {{ git_commit.after | truncate(7, true, '') }}.\n. Thinking about it more, I realize I'm still sometimes confused about the required name for my bedrock directory. Of course, the bedrock directory doesn't require any name in particular, so long as local_path matches.\nIt may minimize confusion to refer to my-bedrock. So, in group_vars/<environment>:\nlocal_path: '../my-bedrock# path targeting localbedrockdirectory'\nand in the README:\nproject/                   - Primary folder for the project\n\u251c\u2500\u2500 my-bedrock-ansible/    - This repo\n\u2514\u2500\u2500 my-bedrock/            - A Bedrock-based site (could name it 'example.com')\nI realize that the bedrock directory is no longer just bedrock, it is a full-on \"bedrock-based site\", as you've called it, because of customizations, installations, etc. So, technically you've been more accurate in calling it a 'bedrock-based site' or 'local project directory'. But I'm not sure that those phrases will always immediately translate in people's minds to 'my bedrock directory'. You're abstract and correct, but when I'm new, I need concrete.\n. quotes\n. \ud83d\ude0a I tried it one day, just out of sheer hope. Haven't seen it documented.\n. Ah I see. Man, I still have some things to sort out in my mind on this. Maybe this confusion is my personal problem, not a general problem. If so, it may annul my other comment re: my-bedrock. \n. Ok, yeah, this discussion gives me clarity on the distinction between site name and host names in group_vars. I had them all in one hazy mental mess.\n. So, this now will drop the staging subdomain and be...\ndeploy staging example.com\n. Was copy-pasted from sudoers role, but I'll leave that one alone instead of changing it too.\n. sorry for writing ruby without knowing ruby :-1: \n. Without quotes, my Ansible 1.9.2 templating treats yes/no values as boolean, so sshd_config would have PermitRootLogin True, which caused my ansible playbook connections to fail when I tested it. Using quotes, ansible gives us the needed PermitRootLogin yes\n. We could remove quotes (except for yes/no values). Or we could leave them, figuring this is kind of an external role: nickjj/ansible-sshd\n. The goal of this task is to determine the appropriate remote_user for server.yml's main play. That play will run on hosts: web, so this task tests whether root can connect to the first host in the web group. The hosts in this group are accessible in the ansible variable groups.web. \nI will replace root@{{ groups.web.0 }} with root@{{ groups.web | first }} to switch from a hard-coded feel to something that may communicate the concept more intuitively. Suggestions welcome.\nAside: There's a rare potential that the web group could consist of multiple hosts, added at different times, some permitting root login while others forbid it. I commented on this scenario in #246 (\"Conditional remote_user\" section).\n. I've adjusted this to check all hosts instead of just the first. It sets the ansible_ssh_user fact for each host. Now the playbook can handle variability in whether or not hosts permit root login. \n. Smart, thanks! I'll merge into one command, but I'll keep the if then so it doesn't return 1, which would cause playbook to fail/halt.\n. @louim you always help me improve. Thank you. Consider this task:\nyaml\n- name: Update git remote URL\n  shell: \"cd {{ project_source_path }} && git config --get remote.origin.url && git remote set-url origin {{ project_git_repo }} || :\"\n  register: original_remote\n  changed_when: original_remote.stdout not in ['', project_git_repo]\nOn the surface, the task appears idempotent. It reports \"changed\" only if the new url differs from the old url and if the clone already exists. However, technically the set-url command always runs if the clone exists. If that is unacceptable, I could add an if-then into the shell command to conditionally run the set-url command. Or more likely, I could just let go of my drive to handle this in a single task and do three tasks like those you suggested. \n. If the git project doesn't yet exist, \"Get current git remote URL\" skips, and its registered value is\n\"remote_origin_url\": {\n  \"changed\": false,\n  \"skipped\": true\n}\nIn this scenario, remote_origin_url.stdout is not defined, so without the defined check,\nwhen: remote_origin_url.stdout != project_git_repo\nwould cause the task to fail.\nMy conditional states \"if there is a remote url available to compare,\" but maybe a more intuitive alternative would be \"if a git clone/project exists,\" like this: \nwhen: git_project.stat.exists and remote_origin_url.stdout != project_git_repo.\n. Without having followed the bigger picture of the multisite discussion (I might be missing something), I think what you have is the best way to handle it. \nEdit: I'm told this fails: One (untested) alternative that comes to mind is just to tell users that if they're using multisite, they should add their the subdomain wildcard version to the list of site_hosts:\nyaml\nsite_hosts:\n  - site1.com\n  - *.site1.com\n  - site2.com\n  - *.site2.com\nThen you could just keep the original \nserver_name  {{ item.value.site_hosts | join(' ') }};\nThe other idea is pretty bad and I haven't tested: \nserver_name  {{ item.value.site_hosts | join(' ') }} {% if item.value.multisite.subdomains %} *.{{ item.value.site_hosts | join(' *.') }} {% endif %};\n. @louim I haven't been told why the wildcard in site_hosts fails, and I'm afraid I haven't looked into it. Here is an example of it failing, but here's an example of a trellis fork where it doesn't fail.\n. Looks good to me @alan-c. Thanks for all the work you've done on this.\n. This task must be ready to skip for staging/production hosts for whom we don't want to run vagrant ssh-config. I had to run this ansible-ssh role run in server.yml too because once ansible.cfg specifies a ssh config file, the file must be present and only that config file will be used. This doesn't mean you'll be without info from your regular ~/.ssh/config, however, because this new config file will suck in whatever ssh config \"includes\" files you specify in ssh_config_files (defined in group_vars/all/main.yml).\n. Nice. Thanks. I'll use that instead.\n. Consider an Ansible inventory like this:\n[web]\nnickname ansible_ssh_host=127.0.0.1\nThe variable inventory_hostname would be nickname and wouldn't be captured by your addition to the when: conditional. You could check ansible_ssh_host first, and fallback to inventory_hostname. Credit here.\n. If staging or production hosts files are like the Trellis default files and list only IP and do not explicitly define ansible_ssh_host, I'm pretty sure ansible_ssh_host is defined will return false. If so, this task will sometimes not run for staging/production but should run (a problem). Do I understand that correctly?\nAnyone aware of an ansible variable to check whether --connection=local was passed? That strikes me as a more direct test of the issue at hand. @chriszarate What specifically fails when Packer runs this? Is it that the ping module run on a local connection always fails? Just fails for admin user? Ideally we test for whatever the specific problem is instead of anything overly general that allows \"false positives\", makes the task not run, and potentially allows users to lock themselves out of their servers.\n. When I first saw your PR a while back I placed my hope in being able to test the ansible_connection variable, but in my tests it never seemed defined unless the hosts file (inventory file) explicitly declared it for a host (e.g., 127.0.0.1 ansible_connection=local). I don't think it will be defined when --connection=local is passed, nor if connection: local is a playbook parameter. It is maddening.\nSo, I fear the best option still is something like (untested):\nwhen: not sshd_permit_root_login and '127.0.0.1' != ansible_ssh_host | default(inventory_hostname)\nIt's hard to believe there isn't some ansible fact to access that indicates that the connection is local, but I've looked a medium amount, to no avail. There's still a chance it's out there, buried.\n. The results you are seeing seem like what is expected. My results seem unexpected (Ansible 1.9.2 & 1.9.3). So, I'd trust yours. I'm guessing my problem is that I'm not testing via Packer, but on my local mac. Or I simply may not be understanding how things work. \nI create an entry in my hosts/staging file that shouldn't be able to connect via SSH because there's no IP to help the connection succeed. So, ansible_connection should remain local. It shouldn't be set back to undefined due to a successful SSH connection.\n[web]\nfake\nThen I run ansible-playbook server.yml -i hosts/staging --connection=local. I've made the first couple tasks check the value of the variable: \n- debug: var=ansible_connection\n- local_action: debug msg=\"{{ ansible_connection }}\"\nThey both come out undefined. I'm probably missing something.\n. The playbook fails if vault_password_file refers to a missing file. The file .vault_pass will be missing by default because it is .gitignored. Users who don't want ansible vault would have to remove this line or create the .vault_pass file. I explain below why I didn't just omit this line and require vault users to add it.\nTo enable vault, we could have users create new stuff: add vault_password_file line to ansible.cfg and create the .vault_pass file. I chose the alternative of having users edit example versions of each (steps 1 and 2 in this PR's first comment) because I speculate that users would be more likely to try vault if they could edit example stuff instead of create new stuff.\nAn added bonus of having the examples present in the repo is that one can actually skip steps 1 and 2, and do only step 3 (run the ansible-vault encrypt command). That means one can test how easy it is to use ansible vault by just running that single command.\n. I originally assumed it would skip. That's what I would have preferred.\n. Great idea.\nI added a commit to include the new variable-check.yml playbook. It's DRY but also a bit more complex to look at. The messages needed to differ slightly per playbook.\nYou'll see that I went with yaml:\n- include: variable-check.yml\n  vars:\n    playbook: server.yml\neven though it could have been more succinct:\n- include: variable-check.yml playbook=server.yml\n. @ckovey if the \"Check Existing Permalink Structure\" task skips, the variable wp_permalink_check_results.results.0.stderr is undefined, resulting in the following error for the \"Setup Permalink Structure\" task (example):\nTASK: [wordpress-install | Setup Permalink Structure] *************************\nfatal: [default] => error while evaluating conditional: 'No rewrite rules' in wp_permalink_check_results.results.0.stderr\nThis error could be avoided with a more elaborate when: condition for the \"Setup Permalink Structure\" task:\nwhen: item.value.site_install and not item.value.multisite.enabled | default(false) and 'No rewrite rules' in wp_permalink_check_results.results.0.stderr\nThe above prepends the conditional logic from the \"Check Existing Permalink Structure\", which is probably preferable by being more intuitive than the shorter option below:\nwhen: wp_permalink_check_results.results.0.stderr is defined and 'No rewrite rules' in wp_permalink_check_results.results.0.stderr\n. @ckovey Thanks for your reply and for adding the permalink setup to Trellis. I think this issue is resolved by #466 and #467. You could see if the implementation in #467 looks good to you. \nIn your branch, I liked how you simplified conditionals:\n- dropping the unnecessary == True\n- using not instead of == False\nIf interested, you could PR those changes here, here and here. I'm happy to add them if you prefer.\n. Excellent, thank you. I see this in PEP 08:\n``` python\nNo\ndef bar(x):\n    if x < 0:\n        return\n    return math.sqrt(x)\nYes\ndef foo(x):\n    if x >= 0:\n        return math.sqrt(x)\n    else:\n        return None\n```\nAnother improvement is that although re.match() will...\n\nReturn None if the string does not match the pattern\n\nI should probably change the evaluation to if match is not None: because PEP 8 also says this:\n\nbeware of writing if x when you really mean if x is not None -- e.g. when testing whether a variable or argument that defaults to None was set to some other value. The other value might have a type (such as a container) that could be false in a boolean context!\n. There's another sudo apt-get -y update in the following conditional that installs Ansible. I suspect that both conditionals would typically run on the same occasion.\n\nWhat do you think about combining the two conditionals with something like this?\nif [ ! -f /usr/bin/add-apt-repository ] || [ ! -f /usr/bin/ansible ]; then\nThen you could have the sudo apt-get -y update just once at the top of the combined conditional.\n. Ah, I see. Excellent. Thanks!\n. I added default as a safety in case vars_plugins ever happened to be disabled, in which case the var would be undefined.\n. The primary purpose of recursing only once through each top-level key is to avoid having multiple lists or dicts to merge for keys at various depths. No variable value is touched more than once. Each top-level key needs only one instance of the following and avoids merges:\nhost.vars[key] = self.raw_triage(key, hostvars[key], patterns)\nA prior iteration had the potential to produce multiple dicts and lists per key, which I tried to merge using Ansible's merge_hash. There were edge-case merge failures, with nested values inappropriately overwitten (particularly for lists).\nIt is only a secondary benefit that we do no more work than for the simplest equivalent:\nyaml\nraw_vars:\n  - vault_foo\n. That \"visibility\" was my focus. My overarching goal was to transition this functionality from \"hidden\" -- which for users is possibly surprising and certainly non-configurable -- to \"out in the open\" and easy to use.\nI agree most users won't understand it and won't touch it, in which case they won't mess it up. In that sense, I think it is like neighboring obscure vars in group_vars/all/main.yml, such as wordpress_env_defaults or site_env. \nFor users who do try to use it, actually adding patterns versus merely disabling it, I think they'll have the easiest time if they readily see the full list of raw_vars default patterns right there in a group_vars file.\nWould users really want to adjust patterns? I think a conceivable example would be that someone wants to add an env var in vault_wordpress_sites that should not be wrapped in {% raw %}. They'd need to adjust the raw_vars to be more specific, just wrapping the right parts, such as:\nraw_vars:\n  - vault_wordpress_sites.*.*_password       # for `admin_password` (dev only) and `db_password`\n  - vault_wordpress_sites.*.*_salt\n  - vault_wordpress_sites.*.*_key\nOn the other hand, if we decide that visibility and configurability aren't the goal or aren't worth it, then I suppose moving the defaults into vars.py makes sense. In that case, we could consider whether the python code would be \"safer\" being more targeted to those defaults, not supporting the wildcard stuff and being more \"hard-coded\" like it has been for WP keys and salts.\n. @swalkinshaw Will use your superior suggestion of \nwhen: item.value.site_hosts | rejectattr('canonical', 'defined') | list | count\nQuite beautiful. Thank you.\n. Your refactor of site_hosts mapping is sooo much better. Thanks!\n. The disappointment here is that it uses item.item.value.site_hosts.\nWe would need just item.value.site_hosts in order to use site_hosts from helpers.yml.\nI tried opening the template with {% set item = item.item %} but it doesn't work.\nIf it feels cleaner or more consistent, we could open the template with\n{% set canonical = ... [something] %}\n{% set redirects = ... [something] %}\n{% set site_hosts = ... [something with union] %}\nand then do the site_hosts | join(' ')\n. I'm going to push a commit that changes the two instances of wordpress_sites[item.item.key] to item.item.value. That should be simpler and more closely resemble the existing code. We'll want to squash before merging.\nI failed to consider that the values needed were contained in the registered variable, so we don't need to call on the wordpress_sites dict.\n. re: this Disable xdebug CLI task, here are two nitpicks to handle unexpected rare cases...\n1) I'm guessing it would be most technically correct for the task to also notify: reload php-fpm. It would matter only in the rare case that the prior xdebug configuration file task did not notify the reload, perhaps because that prior task didn't produce a status of 'changed'.\n2) What do you think about removing the when condition and just letting this task always run? It would typically just produce status of 'unchanged'. It might not hurt to ensure this 20-xdebug.ini is absent even if xdebug_install is false.\n. nitpick: It might be nice if the Display Settings above were in the same order as they appear in the xdebug.ini.j2 template. \n. nitpick: These booleans could be 0 or 1 like the other boolean vars. Whichever you choose, could make consistent with corresponding vars in group_vars/development/php.yml. If you stick with false, could drop quotes.\n. I'm guessing the quotes are unnecessary and could be removed from the values for...\nxdebug_remote_port\nxdebug_trace_output_dir\nxdebug_trace_output_name\nxdebug_profiler_output_dir\nxdebug_profiler_output_name\n. I think this string value should probably have quotes:\nxdebug.remote_log=\"{{ xdebug_remote_log }}\"\n. The absent option allows an easy way for someone to remove something from /shared if it will no longer be used in the next deployment(s). Although it is not necessary to remove items, and although people could remove them manually, facilitating this absent option requires no extra tasks, so I thought it was convenient.\nHowever, the absent option does require the the two tasks you've marked to include when conditions and item.path | default(''). Yes these two tasks will skip for items set to absent, but Ansible still attempts to template all the variables in the task. So, without a default for item.path, the task would fail when people omit path for items set to absent. \nIf we keep this absent option, I would like people to be able to omit path because an item to be removed from /shared will have no path in the release directory, so the path parameter doesn't make sense to include.. Although I prefer ternary as well (for consistency with the rest of Trellis), I refrained from implementing Trellis coding conventions, trying leave the original dev-sec/ansible-ssh-hardening role as intact as possible for simpler comparison with upstream.\nIf we choose to apply Trellis conventions, we could consider the following:\n1. use ternary filter in place of pythonic if/else, as you suggested\n2. break list var values out into multiline yaml, e.g., instead of var: ['val', 'val2']\n3. add space around var names, e.g.,  {{port}} becomes {{ port }}\n4. align the various # ssh and # sshd comments in defaults/main.yml\n5. edit code comments for succinctness, grammar, capitalization consistency\n6. either parameterize or remove the IdentityFile entries in openssh.conf.j2 template\n7. maybe simplify a handful of templating chunks using this pattern:\ndiff\n-{% if ssh_allow_users -%}\n-AllowUsers {{ssh_allow_users}}\n-{% endif %}\n+AllowUsers {{ ssh_allow_users | default('')}}\nI believe it's ok -- and has the same effect -- to have empty parameters, e.g., to fall back to default of empty string. I could test it. \n. Given the with_items loop (not with_dict), I believe it should just be\nitem.update_password\n(vs. item.value.update_password). How about using default(omit) instead?\npath: \"{{ item.path | default(omit) }}\"\nIt should default to ~/.ssh/known_hosts (docs and src). This works in my tests (but I didn't test custom home dir). I probably should have used omit in #751.\nIf this works for your user's custom home directory, we could use omit for both tasks' path and no longer need a new home_root variable.. If you go with default(omit) for path, let's add become: no right above with_items (this task only). This will make the task run as vagrant (vs. root), adding to known_hosts in $HOME for vagrant. This is good because the subsequent composer install task that needs the known_hosts will run as vagrant (also uses become: no).. Could you add back the ending newline for these various files?. @strarsis Your adjustments to these vars in deploy.yml were helpful in initiating internal discussion and the decision to move the deploy role's vars into roles/deploy/defaults/main.yml. This will help deploy.yml be more concise. It will be more consistent with how other roles have their vars in their respective defaults/main.yml files.\nCould you help us take the first step toward this goal in this PR by moving just the deploy hook vars out of deploy.yml to a new section at the end of roles/deploy/defaults/main.yml? I think you could start the section with a link to the deploy hooks docs, where all hooks are listed in sequence. Then I think it would be preferable to omit the unused/commented hook variables here in roles/deploy/defaults/main.yml, unless there's a strong argument for duplication.\nExample\n```yml\nroles/deploy/defaults/main.yml\n...\nDeploy hooks\nFor list of hooks and explanation, see https://roots.io/trellis/docs/deploys/#hooks\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before.yml\"\ndeploy_build_after:\n  - \"{{ playbook_dir }}/roles/deploy/hooks/build-after.yml\"\n  # - \"{{ playbook_dir }}/deploy-hooks/sites/{{ site }}-build-after.yml\"\ndeploy_finalize_before:\n  - \"{{ playbook_dir }}/roles/deploy/hooks/finalize-before.yml\"\ndeploy_finalize_after:\n  - \"{{ playbook_dir }}/roles/deploy/hooks/finalize-after.yml\"\n``.ansible.tags = ENV['ANSIBLE_TAGS']`. Here's an issue that you may figure should be addressed by the user, not by Trellis.\nI use pyenv to manage python versions on my machine. Even after uninstalling Ansible, a shim remains at /usr/local/var/pyenv/shims/ansible-playbook, causing an incorrect return value from this which(cmd).\nHere's a potential change that resolves it on my machine (dev/null handling from here):\ndiff\n- return exe if File.executable?(exe) && !File.directory?(exe)\n+ return system(\"#{exe} --help\", [:out, :err] => File::NULL) if File.executable?(exe) && !File.directory?(exe)\nThis appeals to me because it tests whether the ansible-playbook command actually works rather than just whether it should work, the latter being assumed based on the presence of the exe. I don't know whether this revised approach would be good practice or acceptable ruby.\nIt the change above is applied, it returns true, false, or nil, if I recall correctly (instead of exe path). So, maybe the name which() should change to something like cmd_valid(cmd).. This could be used for nfs path names in the vagrant_synced_folders loop:\ndiff\n- def nfs_path(site_name)\n-   \"/vagrant-nfs-#{site_name}\"\n+ def nfs_path(path)\n+   \"/vagrant-nfs-#{File.basename(path)}\"\n  end. When using vagrant-bindfs, the convention appears to be...\n1. do a regular vagrant folder sync from somedir to /vagrant/somedir-nfs\n2. do a bindfs sync from /vagrant/somedir-nfs to /final_path_on_vm/somedir\nCombined with the File.basename() adjustment to nfs_path() proposed in a separate comment, the following seems to handle it.\n```diff\n+ destination_folder = folder.fetch('bindfs', true) ? nfs_path(folder['destination']) : folder['destination']\n\nconfig.vm.synced_folder folder['local_path'], folder['destination'], options\nconfig.vm.synced_folder folder['local_path'], destination_folder, options\n\nif folder.fetch('bindfs', true)\n-   config.bindfs.bind_folder folder['local_path'], folder['destination'], options\n+   config.bindfs.bind_folder destination_folder, folder['destination'], folder.fetch('bindfs_options', {})\n``\nThe other piece to this is thebindfs_options, which are different from a regular vagrant sync diroptions` and must be treated differently. The above appears to successfully handle the following example \n```\nvagrant.local.yml\nvagrant_synced_folders:\n  - local_path: ../db\n    destination: /home/vagrant/db\n    create: false\n    type: nfs\n    bindfs: true\n    bindfs_options:\n      o: 'nonempty'\n      p: '0644,a+D'\n  - local_path: ../test\n    destination: /home/vagrant/test\n    create: false\n    type: virtualbox\n    bindfs: false\n    mount_options:\n      - 'dmode=755'\n      - 'fmode=644'\n. nitpick: double quotes are only necessary if the `{{ jinja }}` begins the variable value, so this could just bediff\n- command: \"wp package install {{ item }}\"\n+ command: wp package install {{ item }}\n``\nI realize Trellis is not always consistent on this, but the general goal has been to use quotes only when absolutely needed.. While testing, I noticed that in some casesstdoutfor already-installed packages did not include ['Nothing to install or update'](https://github.com/composer/composer/blob/9aadbe27283bda0ed0f149fa4304c245f517c369/src/Composer/Installer.php#L490) but instead included ['Package operations: 0 installs, 0 updates, 0 removals'](https://github.com/composer/composer/blob/9aadbe27283bda0ed0f149fa4304c245f517c369/src/Composer/Installer.php#L520). This meant that sometimes Ansible inaccurately reportedchanged` for packages that were already installed.\nHow does this modification look to you?\ndiff\n- changed_when: \"'Nothing to install or update' not in wp_cli_packages_installed.stdout\"\n+ changed_when:\n+   - \"'Nothing to install or update' not in wp_cli_packages_installed.stdout\"\n+   - \"'Package operations: 0 installs, 0 updates, 0 removals' not in wp_cli_packages_installed.stdout\"\nI would have preferred to be more concise by checking for a string that is unique to when packages are freshly installed but I didn't observe any such string.. I figured users could have template_root values with release paths different from previous_release_path but that still needed to be replaced. One example might be if a user imports a DB from staging where the previous_release_path was different than here in production. Or, perhaps the prior release was failed and template_root never updated but deploy helper has that failed path as previous_release_path? I didn't test if this latter could happen.. Should these each have this change?\ndiff\n- {{ self.includes_d() -%}\n+ {{ self.includes_d() -}}. Two minor requests:\n Could you move this include task right after the other similar include tasks in tasks/main.yml? That placement strikes me as more consistent. I like the idea of avoiding nested includes when it's easy.\n Let's omit the notify here. Nginx only needs to reload if the conf file produced by our wordpress-site.conf.j2 changes. A change in the \"Download client cert\" task produces a new or renamed client cert, which in turn will trigger a changed template task which already has notify: reload nginx.. I think a user who happens upon the server's nginx_ssl_path contents would find the filename more intuitive as client-4c1d4cc.crt instead of 4c1d4ccad291c1ac1f230ad263c4196c.\nCould we make this change?\ndiff\n- dest: \"{{ nginx_ssl_path }}/{{ item.value.ssl.client_cert_url | hash('md5') }}\"\n+ dest: \"{{ nginx_ssl_path }}/client-{{ (item.value.ssl.client_cert_url | hash('md5'))[:7] }}.crt\"\nA similar filename change would be needed in wordpress-site.conf.j2.. With the global option removed, I presume users would no longer disable client verification by setting client_cert_url: false. Rather, they simply wouldn't define client_cert_url for the relevant site.\nIf we don't need to check the bool interpretation of client_cert_url, could we make this change?\ndiff\n- {% if item.value.ssl.client_cert_url is defined and item.value.ssl.client_cert_url -%}\n+ {% if item.value.ssl.client_cert_url is defined -%}. Excellent! Thanks @TangRufus!. If a user runs server.yml with --tags <any tag above>, Trellis may template Nginx confs that use the letsencrypt_cert_ids variable (e.g., in this PR's ssl.no-default.conf.j2 or in wordpress-site.conf.j2). The letsencrypt_cert_ids variable definition relies on the above task's registered var generate_cert_ids. If the task above does not also run for the tags above, letsencrypt_cert_ids will be malformed and the Nginx conf templating tasks will fail.. >By default, it will pick the cert and key from one of the ssl-enabled sites. However, users may specify which site's cert and key to use in group_vars:\nssl_default_cert_site: example.com\nSo, users can specify which site's cert and key to use from wordpress_sites. But it seems that you anticipate that users or third-party roles may want to specify a cert and key other than any in wordpress_sites. I guess it's possible. I hadn't considered it.\nMy first idea to accommodate this scenario would be add to this PR the vars ssl_certificate_default and ssl_certificate_key_default for users or roles to define. In that case, this ssl.no-default.conf could use those values if defined or fall back on the cert and key for a site from wordpress_sites, as in the code above.\nConsiderations for integration with third-party roles are important but are not fresh in my mind. Would vars ssl_certificate_default and ssl_certificate_key_default be sufficient? Or does the include includes.d/... approach seem superior? \nMy first inclination is to avoid adding include includes.d/... to this ssl.no-default.conf. Given that this server block is filling requests for unknown hosts, my sense is that it should just get rid of the request with as little processing as possible (i.e., avoid all the potential processing of confs in includes.d). If there are examples of strong use cases for includes here, perhaps we should give users the option to specify includes paths:\n```\nsome group_vars location\ncorresponding templates in local nginx-includes directory\nnginx_no_default_include_paths:\n  - includes.d/no-default/foo.conf\n```\n```\nin no-default.conf.j2 and ssl.no-default.conf.j2\n{% for path in nginx_no_default_include_paths | default([]) %}\ninclude {{ path }};\n{% endfor %}\n```\nI'm reluctant to add all this complexity unless it is likely to be used. But if likely, then :+1:. Given the Nginx default ssl_verify_client off;, does it help to add the explicit directive?\nWhen those other directives were absent, the real ssl-enabled wordpress_sites seemed to fail:\n\nWithout ssl_certificate and ssl_certificate_key in the default server block, https sites fail:\n * in browser: \"The connection was reset\" ERR_CONNECTION_RESET\n * curl: curl: (35) Server aborted the SSL handshake\n\nIn any case, I don't think those other server blocks would match an unknown host.\nIf there were only one site, never a need for different certs/keys for different hosts, then we could specify the cert and key just once in an http block. But I assume we want to enable multiple ssl-enabled wordpress_sites with separate certs.\nThese issues are new to me however, so I'm eager for suggestions.. > Is it good to enable ssl.no-default.conf even no site using SSL?\nI imagine the answer is \"no,\" which is why this PR adds ssl.no-default.conf.j2 to the nginx_sites_confs list with the option enabled: \"{{ sites_using_ssl != [] }}\". The result is that ssl.no-default.conf is only symlinked into sites-enabled when at least one of the wordpress_sites has SSL enabled.\nI hadn't considered the edge case that someone would get a third party cert and key on the server through means other than the Trellis built-in Let's Encrypt, manual, or self-signed options. If it were common, perhaps always adding a self-signed cert to ssl.no-default.conf would be good, or it could be an argument for adding the ssl_certificate_default and ssl_certificate_key_default vars mentioned above.\nI figure that such would be a rare edge case, however, and this PR in its current form still allows users to customize the list of nginx_sites_confs, optionally replacing the default ssl.no-default.conf.j2 with some-custom-no-default.conf.j2.. I think this include_tasks is no longer needed, right? (there's no more validate.yml). I'd prefer that this package_vars_wrong_format_msg var were defined in roles/common/defaults/main.yml, where users won't have to think about it unless they are really digging in. I think of this var as more of a helper/utility than a variable users are likely to want to modify. This change would keep group_vars/all/main.yml more streamlined.\nAn alternative that may be more consistent with other validation tasks could be to put the message in a template lookup (example).. this one should be lookup('template'... too?. (comment was addressed in internal discussion). ",
    "carbontwelve": "Thanks for this, really helps.\n. ",
    "Serumo": "Hello Mr. swalkinshaw  Please Help me. \nI have a problem when installed theme woodpress. This is the error message : \nWarning: An unexpected error occurred. Something may be wrong with WordPress.org or this server\u2019s configuration. If you continue to have problems, please try the support forums. (WordPress could not establish a secure connection to WordPress.org. Please contact your server administrator.) in C:\\xampp\\htdocs\\serumpun media\\wp-includes\\update.php on line 130\nWarning: An unexpected error occurred. Something may be wrong with WordPress.org or this server\u2019s configuration. If you continue to have problems, please try the support forums. (WordPress could not establish a secure connection to WordPress.org. Please contact your server administrator.) in C:\\xampp\\htdocs\\serumpun media\\wp-includes\\update.php on line 320\nWarning: An unexpected error occurred. Something may be wrong with WordPress.org or this server\u2019s configuration. If you continue to have problems, please try the support forums. (WordPress could not establish a secure connection to WordPress.org. Please contact your server administrator.) in C:\\xampp\\htdocs\\serumpun media\\wp-includes\\update.php on line 500\n. ",
    "mAAdhaTTah": "Nevermind, the problem is Ansible is offering a bunch of my other private keys first, and the host is cutting me off for Too many authentication failures.\n. @swalkinshaw FYI, this issue can be closed, but before you do, I am curious why you hate W3TC. I've never used it, but I was getting New Relic set up on my sever (maybe something worth scripting in?), and I saw W3TC's NR integration, which reminded me that you didn't like it. Any reason why?\n. Makes sense, thanks!\n. I know this is a brand new development, but Let's Encrypt looks like it could be an easy way to deploy certificates during the provisioning process. It's not online yet, so I don't know how good compat w/ Ansible will be @ launch, but worth keeping an eye on.\n. lol I actually found it in Newsblur's \"The People Have Spoken\" shared feed.\n. Can we use this module now anyway? Might help them get it merged if we tested it. \n. Is this in the works? Happy to test! \n. Has there been any movement on this/are we still waiting on a new Ansible release for this to work?\n. The wait is over!\n. Re-provisioned and no change. Nothing in the nginx error logs stored in /srv/www/sitename.tld/logs that seem to point to anything. There also doesn't appear to be any errors with WordPress itself - when I enable logging, nothing show. I've also redeployed it vis capistrano, so it has the latest working code. Where are the error logs for MariaDB saved?\n. I can't access that either (same white screen). I'm pretty sure the issue is in the server software, not WordPress.\n. If no one else has experienced this, I'm going to just destroy and re-provision the droplet. I have everything backed up, I was just hoping to avoid re-uploading all those pictures. Thanks for your help guys!\n. Errr, so that didn't work. Still getting a white screen.\nFWIW, if I load up the Vagrant box and update all the software via apt-get, I get the same issue. Is this reproducible on your end?\n. Great! Thanks for your help.\n. Would it be possible to set the general user via a variable (like with the MySQL root pw) or does it have to be hard-coded somewhere?\n. Is this PR good to go? Does it need more testing? I'm going to be provisioning some things tonight so wondering if I can help w/ this.\n. Don't know if this is a huge deal, but in the hosts/production file, ansible_ssh_user=admin needs to be removed when running the initial secure-root.yml playbook.\n. I think I have a solution. Gimme a few to test.\n. Yup! Got it working for me too.\n. FWIW, I had to add remote_user: admin to both plays in the site.yml playbook.\n. This looks like the changes I made. I'll pull down and do one more test, but otherwise, :+1: \n. :+1: \n. WOO!\n. Would it be thinking too big to combine this with #40 for a complete provision/deploy solution? I may be deploying/provisioning a few sites and would be happy to help test & contribute.\n. Awesome - is anyone currently working on the DigitalOcean part of it?\n. Maybe moving it to another repo, but don't remove it completely. I use capistrano to deploy my website when I update plugins and such; don't make it go away! (though I would definitely support migrating to a php-based solution)\n. Wait, so is the idea to deploy with ansible rather than capistrano? Did I misunderstand the first time around?\n. Yeah, and I don't have to edit as much stuff if I need to reprovision a new server. That's awesome, actually. Feel free to rip out capistrano then :+1: \n. @swalkinshaw Is this PR at a testable state? I've got a side-project website that I am going to be deploying soon, which would be a good opportunity to test the full deployment and provisioning process on a non-mission critical server.\n@fullyint I could use something like that for the same side-project actually, so if you want any help, I'd love to pitch in.\n. I ran through a deploy and everything is looking pretty good overall, although I'm getting a hang on the Reload php-fpm step of the deploy process.\n. @swalkinshaw Yeah, I just pulled it down this morning, so I've got that. I ran it with -vvvv and didn't see anything.\n. Besides that, everything works very well. The bash wrapper would be a plus, as there are a lot of commands to run. Using that to combine secure-root.yml then server.yml for provisioning and run deploy production example.com for deployment would make this perfect.\n. One more thing: @fullyint's solution does work for cloning private repos, with the addition to ansible.cfg.\n. @fullyint Also, the rsync task works as well. Is that definitely not being included in core?\n. > I symlink local theme into local bedrock and Vagrant is none the wiser.\nThis doesn't work for me; did you do anything to make Vagrant follow the symlinks?\n. @fullyint The mount bind works, thanks.\n@swalkinshaw:\n\nMy recommendation is always to bundle your theme in your project repo. \n\nAll the themes I use on my personal sites are open-sourced, so if there was a way to do this such that it's not bundled with the project, that would be awesome.\nDefinitely prefer option 2. I think the less we can install on the server, the better (even that's what I ended up doing for one of my sites).\n. This is siiiiiick!\n. @fullyint That's awesome, thanks. Personally, I think the only significant thing missing from Bedrock-Ansible is the DO integration. Then every time we make changes to BA, I can just spin up a new server, no hassle. :) Thanks for all the hard work!\n. @fullyint Made a slight mod given the new Vagrantfile:\nruby\nconfig.vm.synced_folder '../themes/sage', File.join(nfs_path(name), 'web/app/themes/sage'), type: 'nfs'\n. Maybe I'll spend some time looking at it. I don't know ansible at all yet.\n. Yeah, you need something. I think there was one instance where I added a user, not realizing there was no mail system installed, and the adding process timed out (it worked, the user was added, but it was a very odd experience).\n. > I agree with @swalkinshaw. Perhaps I can create a teeny tiny buildpack for Sage themes that gives you everything you need + a standard process to follow.\nAwesome. Really excited about 8.0.0!\n\nThere's also the debate about doing the compiles locally and uploading assets which wouldn't make any of this necessary.\n\nHow would you deploy if this was the methodology? Can Ansible copy it up?\n. Oh, I was wondering why I was having issues with that...\n. Faster provisioning, I think? There's a couple things included by default in the box.\n. Bedrock-ansible creates that file when you provision the VM. It's not necessary to save it because when you destroy your VM and run vagrant up again, it'll create a new one.\n. Related: #124 & #126. I think the Sage build stuff is going to be fixed once the deploy branch is merged.\n. god dammit i thought i put that whole episode out of my mind...\n. yeah, i should've realized it was a mistake when the solution was a cronjob to restart mysql every 15 minutes...\n. +1 for including, imo. Both capistrano and rocketeer (a php-based deployment solution I've also used with Bedrock) have rollback commands, which would be a lot easier than trying to go in and symlink things yourself.\n. derp\n. This is nice; that naming conversation makes me wonder: right now I have one BA repo for each website, but maybe it makes more sense to just have one repo. However, I found in the past that multiple sites on a single server made it run slow, but if I can run vagrant up --site=example.com and it only provisions the one site, that would make things a lot easier. Is it possible to only bring up one site at a time for vagrant? Thoughts?\n. Yeah, not really doable, I don't think, because ansible provisions all of the sites by default, and you can't provision a site by a flag (unless you know something I don't). You could do a big find->replace to make the sites swappable, but then it's either one site at a time or all sites all the time.\n. I got it working with @swalkinshaw's group name and an environment variable (suggested here). Run with VSITE=example.com vagrant up.\n``` ruby\n-- mode: ruby --\nvi: set ft=ruby :\nrequire 'yaml'\nANSIBLE_PATH = '.' # path targeting Ansible directory (relative to Vagrantfile)\nSet Ansible roles_path relative to Ansible directory\nENV['ANSIBLE_ROLES_PATH'] = File.join(ANSIBLE_PATH, 'vendor', 'roles')\nif ENV['VSITE'].nil?\n  config_file = File.join(ANSIBLE_PATH, 'group_vars/development')\nelse\n  config_file = File.join(ANSIBLE_PATH, 'group_vars', ENV['VSITE'])\nend\n...\n  config.vm.provision :ansible do |ansible|\n    ansible.playbook = File.join(ANSIBLE_PATH, 'dev.yml')\n    ansible.extra_vars = { ansible_ssh_user: 'vagrant' }\nif ENV['VSITE'].nil?\n  ansible.groups = {\n    'web' => ['default'],\n    'development' => ['default']\n  }\nelse\n  ansible.groups = {\n    'web' => ['default'],\n    ENV['VSITE'] => ['default']\n  }\nend\n\n```\n. @kalenjohnson @alexciarlillo That's good to know; I have my themes set up as composer dependencies currently but haven't moved everything over to ansible deployments. Will have to remove that. So are you guys copying up the entire theme folder with ansible or how are you handling it?\n(Assuming you're not committing your theme files to your site bedrock repo?)\n. @kalenjohnson This conversation might help.\n. googles \"idempotent\"\n. Oh awesome. Can't say I was ever a huge fan of the name \"bedrock-ansible\"\n. :+1: \n. > I'm not aware of what you mean by this. Can you elaborate?\nSome people write javascript assuming the admin folder is located in /wp-admin/. On the BE, you have get_admin_url to provides the correct url, but there's no equivalent on the FE. However, assuming the location of the admin dir is _doing_it_wrong.\n. > Well the same thing can happen with poorly coded plugins written in PHP that don't use the correct functions.\nYes, except there are built in WP functions for dealing with this in PHP, but nothing (that I've seen) for doing in JS.\n\nIMO it's not really a reason to add rewrites to the project.\n\nAgreed.\n. @swalkinshaw if you're updating the base box: #126 \n. > PATH could also be updated to include ./vendor/bin.\n+1 for including this as an update. Might be a good start for someone new to Ansible (like me :) ).\n. > I'm with Austin though. Just because they do it doesn't mean we should. He brought up a great point earlier that composer should be managed as a project dependency just as any other composer package your project requires.\nWait, composer itself should be a project dependency? Or did you mean PHPUnit?\n. Something like WP_Mock could also do this: https://github.com/10up/wp_mock\n. Yeah, I haven't used the base box in a while because of the WP-CLI issue.\n. FWIW, it feels like WP-CLI shouldn't do that, or at least have a flag to stop it from doing so. Worth opening an issue over there?\n. I think the term is \"self-signed certificate.\" Otherwise, :+1: \n. Try again? That site might have just been down at the time.\n. Trellis is for provisioning servers, you wouldn't use it to provision a shared host. It does also do deployments, but you wouldn't use \"Trellis with Capistrano.\" You're also better off posting your questions over on Discourse:\nhttps://discourse.roots.io/\n. Looks like someone is developing a wp-cli command: https://github.com/tollmanz/lets-encrypt-wp\nMaybe we should use that, and add the related cronjob so it auto-renews every 90 days?\n. @kalenjohnson that was my source for the plugin :D\n. @retlehs If that's the case, maybe changing the name to server (so it's server & site) might make more sense?\n. @austinpray Only thing I can think of is if the user is using composer scripts in their deployment process.\n. @louim Oh right. In that case, I think this should probably just be development only. If that affects someone, they can move their deployment-required script into composer scripts without any loss.\n. Wouldn't that be preferable, actually? Presumably, only developers or people associated with the project are deploying, so wouldn't you want all of their IPs whitelisted?\n. @louim Right, that looks like the behavior @austinpray prefers. I was just suggesting the other way might preferable, though if it's not feasible, it doesn't really matter :).\n. FWIW, Ansible suggests Docker pairs well with it: http://www.ansible.com/docker I'm actually interested in looking into this more, so if anyone here makes this a project, please email me :).\n. > you can even script the provisioning directly with Docker Machine.\nBut some provisioning needs to occur, correct? Whether if it occurs w/ Docker Machine or Ansible, nginx needs to configured (for example). So even if it's \"better\" to use Docker Machine (which I don't know anything about), we should be able to use these Ansible provisioning scripts to provision a set of Docker containers and reap the benefits of the work on Trellis for a Docker-based implementation.\n. @etcook Thank you. This was enlightening. I'll probably pass on dealing with Docker + Trellis then, since it sounds like you'd have to do this from scratch, essentially.\n. It doesn't look like the task is currently locked to a version as it is. If someone provisions their remote machine and their local env between wp-cli version releases, they'll have different versions.\n. Tested and working now.\n. @swalkinshaw done!\n. The number of queries could be different if one has caching set up properly and the other doesn't.\n. Yes! Looking forward to testing this.\n. YES! Gonna test this weekend.\n. Just wanted to drop a line here, since we were looking at using ansible_local for Windows support in one of our projects: There's a known bug in Vagrant 1.8.1 w/ the 2.0 version of ansible: https://github.com/mitchellh/vagrant/issues/6793\nSo you're not going to be able to switch until that all gets sorted :(.\n. So this is to prevent hostupdater from doing anything if it's already installed?\n. I've seen it take a long-ish time on my coworker's Windows machine compared to my Mac. Are you on Windows?\n. That doesn't look like the correct path. themes/assets should be themes/<themename>/assets. Are you sure they're enqueued correctly?\n. Wait, seriously? They made .dev a real TLD?\n. > I guess if anyone uses the wp_enqueue methods, then they contain the version by default?\nYes, version of WP if nothing is set, otherwise the string provided to the version parameter.. Can I make a suggestion: I edit my local Vagrantfile to mount WP plugins I'm working on into the VM. Can the configuration be edited to allow one to include a src/dest array:\nmount_dirs:\n    - src: 'path/to/plugin'\n      dest: 'path/to/wp-content/plugins/plugin'\n    - src: 'path/to/plugin2'\n      dest: 'path/to/wp-content/plugins/plugin2'\nor something like this?. It is possible to change the prefix programmatically with a filter in WordPress. Does that need to be taken into consideration here?. Does the repo need to be included in development?\n. This has to be item.value.db_import or it'll never fire. It appears a couple places in this file.\n. @fullyint lol that explains why I was so confused. No worries.\n. Was this intended to be committed?\n. Musta gotten lost in a copy/paste.\nAdded a message. Let me know if you have a preference on the copy.\n. Will do. I pulled wp_installed.rc == 0 from line 14; should I fix that too?\n. Done and done.\n. Done!\n. ",
    "craigedmunds": "I figured out what the issue was here. When a multisite is provisioned, my wp-config.php looks like:\nphp\n/**\n- Do not edit this file. Edit the config files found in the config/ dir instead.\n- This file is required in the root directory so WordPress can find it.\n- WP is hardcoded to look in its own directory or one directory up for wp-config.php.\n  */\n  require_once(dirname(**DIR**) . '/vendor/autoload.php');\n  require_once(dirname(**DIR**) . '/config/application.php');\n  require_once(ABSPATH . 'wp-settings.php');\n  define('MULTISITE', true);\n  define('SUBDOMAIN_INSTALL', 'false');\n  $base = '/';\n  define('DOMAIN_CURRENT_SITE', 'site');\n  define('PATH_CURRENT_SITE', '/');\n  define('SITE_ID_CURRENT_SITE', 1);\n  define('BLOG_ID_CURRENT_SITE', 1);\n\n<p/* That's all, stop editing!\nThe wp-settings.php checks if multisite has been set, and if not sets it to false.\nMoving the require of wp-settings.php to after these defines, solved the problem. Not sure if there will be any other side affects.\n. ",
    "nroca": "Thanks! I'll report back if that was the case. \n. ",
    "mendelk": "Thanks @swalkinshaw \nHowever that issue seem to point to issues in the way the Vagrantfile / ansible playbook are set up, things that are handled by this repo.\nOf course, I could be totally missing their point, as I'm not that strong on unix permissioning.\n. ",
    "luandro": "\nOh okay so the composer install error was because I had an incorrect site_name (lol) but once i corrected that I got the exact behavior you just described.\n\n@austinpray I'm having this same problem. I've tried changing the site_name to every possible variable I could think of. How did u do it?\n```\nTASK: [wordpress-sites | Install Dependencies with Composer] ******    \nstdout: Composer could not find a composer.json file in /srv/www/website.com/current\n``\n. After cloning bedrock and bedrock-ansible to my directory I immediatelyvagrant up`. After that is complete I try to run the ansible playbook which fails. So the correct workflow should be to deploy my wordpress folder with Capistrano before running the playbook?\nSorry for the newbie questions, I'm still trying to wrap my head around how to use these tools.\n. Oh sorry, it's for deploying actually. The local dev is working fine. But when I try to deploy it to Digital Cloud I get that composer error. From what you said I assume I have to put the wordpress folder in the server somehow, but how? Manually or use a tool for that?\n. Got it. Thanks!\n. I've been cheking the issues the Ansible module has with Digital Ocean's new API. What is the suggested way to deploy to DO? Capistrano?\n\nI have been using the Digital Ocean Vagrant plugin instead\n\nHow would I go about using the Digital Ocean Vagrant plugin to deploy what I've created with Ansible-Bedrock since DO doesn't have an image quite like the bedrock setup?\nI'm new to automated deployments, the best way I figure is copying my local Wordpress folder to a  previously created LEMP droplet on DO through SFTP. Any suggestions? \n. @austinpray Thanks for the heads up. I'll look into it.\n. The playbook looks for Mariadb in this url: \nhttp://mirrors.coreix.net/mariadb/repo/10.0/ubuntu/dists/utopic/main/binary-i386/packages\nIn the website I can find this url, which seems should be right:\nhttp://mirrors.coreix.net/mariadb/repo/10.0/ubuntu/dists/trusty/main/binary-i386/packages\nWhen I tried to hard edit the main.ylm vagrant crashed. I tried vagrant destroy && vagrant up but it fails:\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Importing base box 'roots/bedrock'...\n==> default: Matching MAC address for NAT networking...\n==> default: Checking if box 'roots/bedrock' is up to date...\n==> default: Setting the name of the VM: bedrock-ansible_default_1415627192151_27496\n==> default: Destroying VM and associated drives...\n/Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/mixin_synced_folders.rb:112:in `block in synced_folders': Internal error. Report this as a bug. Invalid: NFS (RuntimeError)\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/mixin_synced_folders.rb:100:in `each'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/mixin_synced_folders.rb:100:in `synced_folders'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/synced_folder_cleanup.rb:19:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/synced_folders/nfs/action_cleanup.rb:25:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/prepare_nfs_valid_ids.rb:12:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/provisioner_cleanup.rb:24:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/destroy_unused_network_interfaces.rb:18:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/clean_machine_folder.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/destroy.rb:14:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/forced_halt.rb:20:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/discard_state.rb:15:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/env_set.rb:19:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/import.rb:48:in `recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:67:in `block in recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:64:in `each'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:64:in `recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:61:in `recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:67:in `block in recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:64:in `each'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:64:in `recover'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:53:in `rescue in call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:28:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/box_check_outdated.rb:68:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/config_validate.rb:25:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/match_mac_address.rb:16:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/import.rb:32:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/customize.rb:40:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_accessible.rb:18:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/config_validate.rb:25:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/handle_box.rb:56:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:95:in `block in finalize_action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builtin/call.rb:53:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/plugins/providers/virtualbox/action/check_virtualbox.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Users/luandrito/.vagrant.d/gems/gems/vagrant-triggers-0.4.2/lib/vagrant-triggers/action/trigger.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Users/luandrito/.vagrant.d/gems/gems/vagrant-triggers-0.4.2/lib/vagrant-triggers/action/trigger.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Users/luandrito/.vagrant.d/gems/gems/vagrant-triggers-0.4.2/lib/vagrant-triggers/action/trigger.rb:17:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/warden.rb:34:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/builder.rb:116:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `block in run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/util/busy.rb:19:in `busy'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/action/runner.rb:66:in `run'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/machine.rb:196:in `action_raw'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/machine.rb:173:in `block in action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/environment.rb:474:in `lock'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/machine.rb:161:in `call'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/machine.rb:161:in `action'\n    from /Applications/Vagrant/embedded/gems/gems/vagrant-1.6.5/lib/vagrant/batch_action.rb:82:in `block (2 levels) in run'\nI'll try a fresh start soon.\n. ",
    "retlehs": "not sure what you mean by 'use how', but an example can be found here: https://serversforhackers.com/editions/2014/08/26/getting-started-with-ansible/\n. :thumbsup: spot on @austinpray - if you wanna knock this out it would be much appreciated! i'll buy you some beers, too\n. going to leave this here https://github.com/seven1m/do-install-button\n. what was the problem?\n. thanks a lot @austinpray :blue_heart: \n. :shipit: \n. :shipit:\n:shipit:\n:shipit:\n:shipit:\n. :blue_heart: \n. :eyes: \n. https://github.com/roots/bedrock-ansible/wiki/Multisite\n. see #168 \n. haha. @swalkinshaw accidentally force pushed the deloys branch the other day and overwrote this\ni'll let him figure it out :rage1:\n. i mentioned this to @swalkinshaw the other day. :+1: \nbedrock box is long overdue for an update\n. nice man! \n. squashed\n. https://github.com/roots/bedrock-ansible/wiki/Vagrant-box\nhttps://github.com/roots/bedrock-ansible/wiki/Windows\nhttps://github.com/roots/bedrock-ansible/wiki/Passwords\nhttps://github.com/roots/bedrock-ansible/wiki/Vagrantfile\nhttps://github.com/roots/bedrock-ansible/wiki/Mail\n. fixed by #167 \n. thanks!\n. thanks for bringing this up, we are open to this! @swalkinshaw might follow up later with some more details.\n. thanks!\n. i was able to reproduce this when trying to provision a DO server as well\n. thanks, just some minor nitpicks:\n- commit message should be along the lines of \"Add note about generating keys from the WordPress API\"\n- this PR description itself should contain more info than just \"#192 close\"\n- PR title should also reflect the commit message\ni also think the change made to README should be dropped. see inline note above\n. the wiki is temporary until the docs are moved onto the roots.io site. that discussion can happen off of github and on our discourse.\n. \n. :rocket: \n. why did you need this in order for your IDE to connect to the DB?\nwhat's your IDE / does it not support SSH connections?\n\n. https://github.com/roots/guidelines/blob/master/CONTRIBUTING.md#using-the-issue-tracker\n\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse).\n. bedrock-ansible 0.4.0 doesn't have any deploy functionality or a deploy.yml file... \n. this is a personal support request. you're trying to deploy incorrectly. post on discourse (or read the readme) \u2014 i'm locking this thread.\n\nthe whole point of using discourse is so that we don't have to back-and-forth on github since lots of people are getting email notifications for these comments.\n. \n. this just happened to a colleague of mine running ansible 2.3 and vagrant 1.9.1.\nthe relevant fix:\n\nI had to login to the virtual machine in the VirtualBox app (couldn't SSH into the machine using the terminal) using the username/password vagrant.\nI also removed all references to the particular site in /etc/hosts/ as I noticed there were two references to the same site.\n\n/via \n https://discourse.roots.io/t/cannot-vagrant-up-virtualbox-machine-already-exists/6417/3\n http://magento.stackexchange.com/a/76501. nice. @kalenjohnson also mentioned http://mailcatcher.me/\n. https://github.com/geerlingguy/ansible-role-mailhog\n. closed by #304 \n. from production server logs:\n28576\n42900\n44937\n. another prod server:\n23478\n. didn't like this at first but i dig it now!\n. sounds great\n. add_www/strip_www should also be ignored for subdomains\n. > Do I understand correctly that all the logging is actually happening, just with different file ownership/permissions and different file naming than we expect?\nyup\n. @kalenjohnson++\n. seems like permalinks should be enabled by default as of 4.2: https://core.trac.wordpress.org/ticket/6481\n. if anyone hears or sees anything about beta signups, please let us know!\n\nAccording to https://letsencrypt.org/2015/08/07/updated-lets-encrypt-launch-schedule.html72, the Let's Encrypt CA is planning for general availability of its services in the week of November 16, 2015. If you use the client before then (except as part of a beta test program), you would receive a test certificate that is not signed by a publicly-trusted CA, and that is not accepted by browsers.\n\nrelated discussion: https://community.letsencrypt.org/t/is-there-a-beta-test-program-i-can-sign-up-for/119\n. https://github.com/thefinn93/ansible-letsencrypt\n. we haven't made a decision to use that project yet, and probably won't use it. from the project owner on the issue you linked:\n\nI initially made this for personal use\n\nwhat's best for the ecosystem isn't necessarily just to start hacking away at something just because there's some groundwork put in...\n. please stop using github for support. this also didn't need to be multiple issues. reference step 2 of the installation: https://github.com/roots/trellis#installation\n. please stop using github for support. this also didn't need to be multiple issues. reference step 2 of the installation: https://github.com/roots/trellis#installation\n. so after i closed your first two threads...\nhttps://github.com/roots/trellis/issues/335#issuecomment-138215386\nhttps://github.com/roots/trellis/issues/336#issuecomment-138215417\nyou open this and #337?\nstop.\n. also seeing this on a recent version of trellis (9 days old)\n. i'm not sure at what point this changed, but i'm pretty sure this is happening on all trellis installs now. it's resulting in the A rating instead of an A+ on SSL labs. (related: #416) \n. if it's changed to trellis then it seems like site should be renamed to bedrock\ni say keep it as is right now\n. something failed during your provision - this shouldn't be necessary. unable to reproduce on latest trellis (master)\nvagrant@example:/srv/www/example.com/current$ wp option get home\nhttp://example.dev\nplease open a thread on our discourse if you still have problems figuring this out\n. something failed during your provision - this shouldn't be necessary. unable to reproduce on latest trellis (master)\nvagrant@example:/srv/www/example.com/current$ wp option get home\nhttp://example.dev\nplease open a thread on our discourse if you still have problems figuring this out\n. thanks for the PR. default structure should be %postname%\n. what about wp rewrite list?\nno permalink structure set:\nvagrant@example:/srv/www/example.com/current$ wp rewrite list\nWarning: No rewrite rules.\n+-------+-------+--------+\n| match | query | source |\n+-------+-------+--------+\n+-------+-------+--------+\n/%postname%/ looks like:\nvagrant@example:/srv/www/example.com/current$ wp rewrite list\n+--------------------------------------------------------+---------------------------------------------------------+-------------+\n| match                                                  | query                                                   | source      |\n+--------------------------------------------------------+---------------------------------------------------------+-------------+\n| category/(.+?)/feed/(feed|rdf|rss|rss2|atom)/?$        | index.php?category_name=$matches[1]&feed=$matches[2]    | category    |\n| category/(.+?)/(feed|rdf|rss|rss2|atom)/?$             | index.php?category_name=$matches[1]&feed=$matches[2]    | category    |\n| category/(.+?)/page/?([0-9]{1,})/?$                    | index.php?category_name=$matches[1]&paged=$matches[2]   | category    |\n| category/(.+?)/?$                                      | index.php?category_name=$matches[1]                     | category    |\n| tag/([^/]+)/feed/(feed|rdf|rss|rss2|atom)/?$           | index.php?tag=$matches[1]&feed=$matches[2]              | post_tag    |\n| tag/([^/]+)/(feed|rdf|rss|rss2|atom)/?$                | index.php?tag=$matches[1]&feed=$matches[2]              | post_tag    |\n| tag/([^/]+)/page/?([0-9]{1,})/?$                       | index.php?tag=$matches[1]&paged=$matches[2]             | post_tag    |\n| tag/([^/]+)/?$                                         | index.php?tag=$matches[1]                               | post_tag    |\n| type/([^/]+)/feed/(feed|rdf|rss|rss2|atom)/?$          | index.php?post_format=$matches[1]&feed=$matches[2]      | post_format |\n| type/([^/]+)/(feed|rdf|rss|rss2|atom)/?$               | index.php?post_format=$matches[1]&feed=$matches[2]      | post_format |\n| type/([^/]+)/page/?([0-9]{1,})/?$                      | index.php?post_format=$matches[1]&paged=$matches[2]     | post_format |\n| type/([^/]+)/?$                                        | index.php?post_format=$matches[1]                       | post_format |\n| robots\\.txt$                                           | index.php?robots=1                                      | other       |\n| .*wp-(atom|rdf|rss|rss2|feed|commentsrss2)\\.php$       | index.php?feed=old                                      | other       |\n| .*wp-app\\.php(/.*)?$                                   | index.php?error=403                                     | other       |\n| .*wp-register.php$                                     | index.php?register=true                                 | other       |\n| feed/(feed|rdf|rss|rss2|atom)/?$                       | index.php?&feed=$matches[1]                             | root        |\n| (feed|rdf|rss|rss2|atom)/?$                            | index.php?&feed=$matches[1]                             | root        |\n| page/?([0-9]{1,})/?$                                   | index.php?&paged=$matches[1]                            | root        |\n| comments/feed/(feed|rdf|rss|rss2|atom)/?$              | index.php?&feed=$matches[1]&withcomments=1              | comments    |\n| comments/(feed|rdf|rss|rss2|atom)/?$                   | index.php?&feed=$matches[1]&withcomments=1              | comments    |\n| search/(.+)/feed/(feed|rdf|rss|rss2|atom)/?$           | index.php?s=$matches[1]&feed=$matches[2]                | search      |\n| search/(.+)/(feed|rdf|rss|rss2|atom)/?$                | index.php?s=$matches[1]&feed=$matches[2]                | search      |\n| search/(.+)/page/?([0-9]{1,})/?$                       | index.php?s=$matches[1]&paged=$matches[2]               | search      |\n| search/(.+)/?$                                         | index.php?s=$matches[1]                                 | search      |\n| author/([^/]+)/feed/(feed|rdf|rss|rss2|atom)/?$        | index.php?author_name=$matches[1]&feed=$matches[2]      | author      |\n| author/([^/]+)/(feed|rdf|rss|rss2|atom)/?$             | index.php?author_name=$matches[1]&feed=$matches[2]      | author      |\n| author/([^/]+)/page/?([0-9]{1,})/?$                    | index.php?author_name=$matches[1]&paged=$matches[2]     | author      |\n| author/([^/]+)/?$                                      | index.php?author_name=$matches[1]                       | author      |\n| ([0-9]{4})/([0-9]{1,2})/([0-9]{1,2})/feed/(feed|rdf|rs | index.php?year=$matches[1]&monthnum=$matches[2]&day=$ma | date        |\n| s|rss2|atom)/?$                                        | tches[3]&feed=$matches[4]                               |             |\n| ([0-9]{4})/([0-9]{1,2})/([0-9]{1,2})/(feed|rdf|rss|rss | index.php?year=$matches[1]&monthnum=$matches[2]&day=$ma | date        |\n| 2|atom)/?$                                             | tches[3]&feed=$matches[4]                               |             |\n| ([0-9]{4})/([0-9]{1,2})/([0-9]{1,2})/page/?([0-9]{1,}) | index.php?year=$matches[1]&monthnum=$matches[2]&day=$ma | date        |\n| /?$                                                    | tches[3]&paged=$matches[4]                              |             |\n| ([0-9]{4})/([0-9]{1,2})/([0-9]{1,2})/?$                | index.php?year=$matches[1]&monthnum=$matches[2]&day=$ma | date        |\n|                                                        | tches[3]                                                |             |\n| ([0-9]{4})/([0-9]{1,2})/feed/(feed|rdf|rss|rss2|atom)/ | index.php?year=$matches[1]&monthnum=$matches[2]&feed=$m | date        |\n| ?$                                                     | atches[3]                                               |             |\n| ([0-9]{4})/([0-9]{1,2})/(feed|rdf|rss|rss2|atom)/?$    | index.php?year=$matches[1]&monthnum=$matches[2]&feed=$m | date        |\n|                                                        | atches[3]                                               |             |\n| ([0-9]{4})/([0-9]{1,2})/page/?([0-9]{1,})/?$           | index.php?year=$matches[1]&monthnum=$matches[2]&paged=$ | date        |\n|                                                        | matches[3]                                              |             |\n| ([0-9]{4})/([0-9]{1,2})/?$                             | index.php?year=$matches[1]&monthnum=$matches[2]         | date        |\n| ([0-9]{4})/feed/(feed|rdf|rss|rss2|atom)/?$            | index.php?year=$matches[1]&feed=$matches[2]             | date        |\n| ([0-9]{4})/(feed|rdf|rss|rss2|atom)/?$                 | index.php?year=$matches[1]&feed=$matches[2]             | date        |\n| ([0-9]{4})/page/?([0-9]{1,})/?$                        | index.php?year=$matches[1]&paged=$matches[2]            | date        |\n| ([0-9]{4})/?$                                          | index.php?year=$matches[1]                              | date        |\n| .?.+?/attachment/([^/]+)/?$                            | index.php?attachment=$matches[1]                        | page        |\n| .?.+?/attachment/([^/]+)/trackback/?$                  | index.php?attachment=$matches[1]&tb=1                   | page        |\n| .?.+?/attachment/([^/]+)/feed/(feed|rdf|rss|rss2|atom) | index.php?attachment=$matches[1]&feed=$matches[2]       | page        |\n| /?$                                                    |                                                         |             |\n| .?.+?/attachment/([^/]+)/(feed|rdf|rss|rss2|atom)/?$   | index.php?attachment=$matches[1]&feed=$matches[2]       | page        |\n| .?.+?/attachment/([^/]+)/comment-page-([0-9]{1,})/?$   | index.php?attachment=$matches[1]&cpage=$matches[2]      | page        |\n| (.?.+?)/trackback/?$                                   | index.php?pagename=$matches[1]&tb=1                     | page        |\n| (.?.+?)/feed/(feed|rdf|rss|rss2|atom)/?$               | index.php?pagename=$matches[1]&feed=$matches[2]         | page        |\n| (.?.+?)/(feed|rdf|rss|rss2|atom)/?$                    | index.php?pagename=$matches[1]&feed=$matches[2]         | page        |\n| (.?.+?)/page/?([0-9]{1,})/?$                           | index.php?pagename=$matches[1]&paged=$matches[2]        | page        |\n| (.?.+?)/comment-page-([0-9]{1,})/?$                    | index.php?pagename=$matches[1]&cpage=$matches[2]        | page        |\n| (.?.+?)(/[0-9]+)?/?$                                   | index.php?pagename=$matches[1]&page=$matches[2]         | page        |\n| [^/]+/attachment/([^/]+)/?$                            | index.php?attachment=$matches[1]                        | post        |\n| [^/]+/attachment/([^/]+)/trackback/?$                  | index.php?attachment=$matches[1]&tb=1                   | post        |\n| [^/]+/attachment/([^/]+)/feed/(feed|rdf|rss|rss2|atom) | index.php?attachment=$matches[1]&feed=$matches[2]       | post        |\n| /?$                                                    |                                                         |             |\n| [^/]+/attachment/([^/]+)/(feed|rdf|rss|rss2|atom)/?$   | index.php?attachment=$matches[1]&feed=$matches[2]       | post        |\n| [^/]+/attachment/([^/]+)/comment-page-([0-9]{1,})/?$   | index.php?attachment=$matches[1]&cpage=$matches[2]      | post        |\n| ([^/]+)/trackback/?$                                   | index.php?name=$matches[1]&tb=1                         | post        |\n| ([^/]+)/feed/(feed|rdf|rss|rss2|atom)/?$               | index.php?name=$matches[1]&feed=$matches[2]             | post        |\n| ([^/]+)/(feed|rdf|rss|rss2|atom)/?$                    | index.php?name=$matches[1]&feed=$matches[2]             | post        |\n| ([^/]+)/page/?([0-9]{1,})/?$                           | index.php?name=$matches[1]&paged=$matches[2]            | post        |\n| ([^/]+)/comment-page-([0-9]{1,})/?$                    | index.php?name=$matches[1]&cpage=$matches[2]            | post        |\n| ([^/]+)(/[0-9]+)?/?$                                   | index.php?name=$matches[1]&page=$matches[2]             | post        |\n| [^/]+/([^/]+)/?$                                       | index.php?attachment=$matches[1]                        | post        |\n| [^/]+/([^/]+)/trackback/?$                             | index.php?attachment=$matches[1]&tb=1                   | post        |\n| [^/]+/([^/]+)/feed/(feed|rdf|rss|rss2|atom)/?$         | index.php?attachment=$matches[1]&feed=$matches[2]       | post        |\n| [^/]+/([^/]+)/(feed|rdf|rss|rss2|atom)/?$              | index.php?attachment=$matches[1]&feed=$matches[2]       | post        |\n| [^/]+/([^/]+)/comment-page-([0-9]{1,})/?$              | index.php?attachment=$matches[1]&cpage=$matches[2]      | post        |\n+--------------------------------------------------------+---------------------------------------------------------+-------------+\n. please use https://discourse.roots.io/ for questions like this in the future\nthx @louim!\n. :+1: looks good & tested, update changelog then merge this\n. maybe in the future\n. assigned to @swalkinshaw to setup security.yml with fail2ban_services rules. thanks!\n. i ran into an issue today where includeSubDomains affected subdomains and made them inaccessible, had to remove it and set the max-age to 0\nhttps://shrikantadhikarla.wordpress.com/2013/02/18/anatomy-of-includesubdomains-directive-in-http-strict-transport-security-policy/\n. should we use nightly at all? if we want parity then we should be defining specific versions of wp-cli to use across all environments.\nif we switch to nightly, someone could very easily wind up with one nightly version of wp-cli on dev that doesn't match up with remote (or vice-versa). \n. https://roots.io/twelve-factor-10-dev-prod-parity/\nyou could end up in a situation where dev works but prod doesn't\nfor instance - isn't wp-cli going to require a new min version once wp 4.4 is out? what if your remote server has the older version? we need dev and remote to be the same\n\nOn Nov 25, 2015, at 7:00 AM, Daniel Bachhuber notifications@github.com wrote:\nif we switch to nightly, someone could very easily wind up with one nightly version of wp-cli on dev that doesn't match up with remote (or vice-versa).\nWhy not use nightly for dev, and the latest stable everywhere else?\n\u2014\nReply to this email directly or view it on GitHub.\n. correct, #392 should be updated to specify a version\n. shouldn't disable_db_cron be replaced with disable_wp_cron?\n. what about not doing this for multisite? \n. another benefit is that this also provides an example of how to use a deploy hook along with where to put it\n. ^^ update-db instead of upgrade-db\n. some details on what this is for would be helpful for people coming to look at this pull request\n. you sure those settings & credentials work for sending email? wordpress falls back to using php's mail() which is configured based off those settings in mail.yml\n. for virtualbox, it shows the directory name (trellis) followed by the name of the virtual machine (default). i'm not sure about other providers\n\n\n```\n\u279c  ~  vagrant global-status\nid       name    provider   state        directory\n\n0107ce1  default virtualbox poweroff     /Users/ben/Sites/roots-example-project.com/trellis\n``\n. the roots.io box is on a pretty old bedrock-ansible version that was prior to the strong DH key implementation in trellis i believe. need to migrate it to the latest trellis :) \n. anyone know if we need to use/should usewp-cron.php?doing_wp_croninstead of justwp-cron.php`?\n. @pacotole unable to reproduce. please use https://discourse.roots.io/ if you still need support.\n\n. fwiw i have also seen ipinfo.io become inaccessible in the past (unrelated to the API limitations)\n. this will also need an update: https://roots.io/trellis/docs/installing-trellis/\n. @jawngee well, you shouldn't be using git submodules. not sure why you're commenting on this considering you already opened a thread on discourse and haven't replied to my question on there.\nhttps://discourse.roots.io/t/submodules-weirdness/5981\n. > However, I wonder if some people would actually want www.sub.example.com to redirect to sub.example.com\n:+1: (ignore my previous comment)\n. :+1: should also add to https://roots.io/trellis/docs/local-development-setup/\nedit: https://github.com/roots/docs/pull/14\n. PR's accepted\nSent from my iPhone\n\nOn Feb 3, 2016, at 1:35 PM, Lucas Andersson notifications@github.com wrote:\nStill not fixed?\n\u2014\nReply to this email directly or view it on GitHub.\n. as stated in our contributing guidelines (that are linked at the top when you go to create a new issue), please don't use github issues for personal support requests.\n\nhttps://discourse.roots.io/\n. adding $realpath_root doesn't work, different solution pending\n. it'll work fine. also see https://roots.io/disable-php-7-deprecated-notices-from-wordpress-plugins/\n. as stated in our contributing guidelines (that are linked at the top when you go to create a new issue), please don't use github issues for personal support requests.\nhttps://discourse.roots.io/\n. the error msg you provided seems unrelated to anything multisite related...\n\nCould not resolve 'archive.ubuntu.com'\n\ndid you try again? seems like a connectivity problem\n. we recommend you run those on the host machine, not on the vagrant development box\n. it's also possible to deploy from master without pulling down the latest changes\n. @mockey WP-CLI 0.23.0 came out yesterday, can you please update this PR to use that version?\nthen squash the commits and this is good to go :+1: \n. thanks!\n. should be fixed soon: https://github.com/oerdnj/deb.sury.org/issues/315#issuecomment-204030883\n. https://discourse.roots.io/search?q=%27dict%20object%27%20has%20no%20attribute%20\n. please use https://discourse.roots.io/ for personal support requests\n. - https://github.com/roots/docs/blob/master/trellis/installing-trellis.md\n. what's in your hosts file? on chrome 50 i'm able to use .dev without any issues\nnot to say we're not open to switching to something such as .test, just curious as to what's going on with your chrome\n. reopened because of https://ma.ttias.be/chrome-force-dev-domains-https-via-preloaded-hsts/. please don't use github for personal support requests, use https://discourse.roots.io/\n. please don't use github for personal support.\n. 1. this is not a trellis specific error.\n2. you've already been asked once to not use issues for personal support requests.\n3. you already posted this on our discourse. i'm assuming you created this issue because you haven't received help there yet? please don't do that.\nif you search google for the error message you've provided there's a lot of results.\n. i'm scared to think about how many more support threads we would deal with by not requiring this up front due to lots of confusion already with ssh keys when it comes to provisioning remote servers \ud83d\ude48 \n. purge seems important to have on by default, similar to how we rotate log files. the issue with putting something like this directly into trellis is that it's going to have to be opinionated. it's hard to try to account for different types of setups - such as multisite, media libraries that are on CDNs, etc.\ni've added trellis-db-push-and-pull from @hamedb89 to the https://roots.io/trellis/docs/user-contributed-extensions/\ncould also potentially make a new section of the docs for this\n. @valentinocossar added, thank you!. it would be pretty dope if we could have an option to enable h5bp's expires conf for each wordpress site. sage based themes for example wouldn't have to worry about cache invalidation\nat the least we can add some documentation\n. thanks for the PR! we discussed this briefly the other day \u2014 consensus was that the best practice is to keep the server at UTC and to modify the timezone in the WP admin for what you'd like to display\nthere's some good discussion here as well: http://stackoverflow.com/questions/2532729/daylight-saving-time-and-time-zone-best-practices\n. i don't have an answer for you, but we can revisit that and possibly remove that code...\n. dupe #637\nfixed by #643\n. > Connection reset by peer\nyou posted this when there was that large attack going on the internet the other day. probably fine now. if not, post on https://discourse.roots.io/ since this is a connectivity issue and not a bug\n. not able to reproduce on a dev site with SSL + HSTS enabled - was able to go to mailhog without https\nclosing out as this is a year old and a lot of moving parts have changed since this report. > Would appreciate Windows people testing, as well as OSX/Linux people to make sure I didn't break anything \ud83d\ude0a\nstill works as expected on OS X :+1: . please post on https://discourse.roots.io/c/trellis for support. most likely an issue with your setup rather than an issue with the codebase. it's best to do the back-and-forth on discourse instead of github so that everyone watching this repo isn't notified.. when a deploy occurs, the sidebars_widgets setting gets updated & the theme is re-activated. > Without this, all requests to /wp-.php files 404.\nthat shouldn't be happening. is there something that you maybe have changed on your trellis setup that's causing this?. you can try reverting https://github.com/roots/trellis/pull/720 in the meantime. * default_apt_packages -> apt_packages_default\n custom_apt_packages -> apt_packages_custom\n install_apt_packges -> apt_packages_install. please don't ignore the whole issue template when you go to create a new issue. this is a personal support request that should be posted on https://discourse.roots.io/\n\n. :+1: ran into this with the woocommerce subscriptions plugin activated on a site. see #187 for previous initial attempt by @nathanielks . thanks, and especially thanks for the changelog update :D . > xdebug 2.6.0 for PHP 7.x and xdebug 2.5.x for PHP 5.x has been published in the PPA.\nhttps://github.com/oerdnj/deb.sury.org/issues/751#issuecomment-363094638. > Fresh installation of the newest Trellis and bedrock\nyou're missing the newest trellis which has this fixed (#923)\nyou can also simply enable SSL on your local dev to get .dev working. ^^ yeah i was totally wrong with that statement, thanks for following up :) . sorry, i don't understand why you cleared out the issue template where you would have noted where to go for support. please head over to https://discourse.roots.io/.. dupe #804. thank you!. the message is accurate, i've updated the local dev docs with a couple sentences\nit's not possible to run wp-cli commands from your host machine that are affecting your dev site on the VM unless you're using wp-cli aliases...\nbut please avoid using github for questions and open up a topic on roots discourse if you'd like to discuss things further. thank you!. i would prefer to close this PR entirely and just add the sage 9 compiler to the user contributed roles docs for if they want to use it...\nwe can't make it harder/more confusing to use sage out of the box with trellis. if we're going to do this, there needs to be a theme agnostic ansible role that we can include in trellis by default\nthere shouldn't be anything specific to sage 8, sage 9, or even a theme - since plugins should be allowed to take advantage of this too\nideally there's some simple way to configure this in trellis (maybe more inline with how a CI config looks?), but i don't have a better idea of what that could be right now. related discourse topic: https://discourse.roots.io/t/depreciating-tls-1-0-and-1-1/14905. oops\n. this is confusing. generateme is a value\ncould probably just remove this change to the README \n. nice\n. looks like it got merged thanks to you! :+1: \n. this seems like a core bug since xmlrpc breaks when WP is installed in a subdirectory. i'm not sure this is something that we should add to trellis, but it's something we could at least cover in the wiki/docs.\n. needs \" instead of single quotes\n. needs \" instead of single quotes\n. use 2 spaces instead of 4\n. tiny nitpick, but while you're at it please change PHP to uppercase\n. missing --network here?\nshould we note that this could take a really long time for larger networks?\n. ",
    "ckovey": "Sorry to butt in, but isn't Redis as fast/faster than memcached?  Only chimed in because you both expressed preference for Redis\n. I'm a WP novice.  We do Symonfy2 projects currently but I've been keeping my eye on roots for our company website.. so I'll leave the choice up to you as I'm not familiar with the ins and outs of wordpress plugins/compatibility with redis.\n. Fixed style issues and squashed everything up, sorry about that @swalkinshaw !\n. @austinpray would you mind trying it as is?  Supposedly the different VMware provider names were unified into vmware_desktop\nhttps://github.com/mitchellh/vagrant/issues/5227#issuecomment-75825995\n. I changed the box url to use the override way of doing things in their example: https://docs.vagrantup.com/v2/providers/configuration.html.  \nThen it seemed like vmware_desktop only applies to boxes and not Vagrant configs as my windows machine would try and load the virtualbox ubuntu/trusty64 using the override method.  I guess somehow before it was simply taking the last config.vm.box defined as that would explain how mac was still trying to load the puppetlabs box.  I added vmware_workstation and vmware_fusion blocks.\nFinally DRY'd the memory setting out to be with CPU setting.\nTested this on my Win 8 VMware and MBP with Virtualbox.  I don't have fusion if you want to try again\n. @swalkinshaw rebased, thanks.  Looks like someone figured out how to get Windows CPU count, nice!\n. Thanks @merchantguru, I did not have Parallels to test so I just made an assumption with the box.  I've updated the commit with the parallels/ubuntu-14.04 base you found if you want to try again fresh.\nre the IP error.  This I believe is because you have multiple Trellis installations going or some other device/VM on that IP in your network.  The master version of Vagrantfile specified the IP https://github.com/roots/trellis/blob/master/Vagrantfile and I have not changed that here.  You should get the same error if you closed the master repo twice and tried to vagrant up on each.  So I believe this part would be \"out of scope\" for this PR\n. Changed!  Looks like I needed the / in there /%postname%/ on my site, that work?\n. Fixed quotes\n. Thanks for catching that.  Updated variable to wp_permalink_results\n. @swalkinshaw  Regarding \n\nthis should probably only run once after the initial install. \n\nI've not found a way to ensure this doesn't get changed.  Best guess was to see if wp-cli could report the current structure and only change if if it was the default (which hopefully no one would need/user).  However I could not find a way to do that with wp-cli\nOther option I thought was to set a file on the server and check if that exists, if not set the permalinks?  Not sure how I felt about that.  I could explore if you like\nYou are welcome to take over if you have something in mind already.\n. @retlehs @swalkinshaw @QWp6t thank you for the suggestions.  I found that wp rewrite list will send a warning to stderr when the default is enabled.  I broke this up into two commands to first check for that warning then apply the permalink structure when it is found.\nI tested with a vagrant destroy && vagrant up followed by changing the permalink structure in the admin and doing vagrant provision.\n. Thanks for the improvements @swalkinshaw.  I updated the commit\n. @fullyint sorry for the delay, I was out on vacation.  Thanks for pointing that error and providing some suggestions.  I've added your more elaborate one in my fork: https://github.com/roots/trellis/compare/master...ckovey:permalink-structure\nWhat is protocol on something already merged?  Should I open a new PR?\n. @fullyint ah, I did not see those other PRs.  I'll let those handle it.\nAlso, it was actually you who simplified the conditionals :) I just copied your suggestion from the first comment here.  Previously, I was just trying to follow the same format (at the time) as the other tasks.\nI'll stay out of this kind of detail and leave it up to you collaborators. \nThanks for Trellis and I will keep an eye out for future issues I think I could help solve!\n. I had thought about that, because they both do indeed run as you suspect on first vagrant up and adds to your initial provisioning time.\nWhat I couldn't figure out was how to do both in one shot avoiding two update's.  I needed the first one so I could first install software-properties-common (this problem is what started the linked discoure thread).  After adding the ansible repository you have to run update again to then install ansible itself.\nI will push a change adding -y to the command to match the below one\n. ",
    "teohhanhui": "Would be good to have the expires issue sorted out... Is there any downside when including it?\n. ",
    "rstormsf": "just heads up - don't forget to use latest OpenSSL http://securityaffairs.co/wordpress/34991/security/openssl-announce-new-releases.html\nand use nginx config generator: https://mozilla.github.io/server-side-tls/ssl-config-generator/?server=nginx-1.6.1&openssl=1.0.1f&hsts=yes&profile=modern\nhttps://cipherli.st/\nanother bad option is to give it up to cloudflare and create single point of failure.\n. @swalkinshaw where can I see instructions for SSL setup? \n. I mean -  can you share some steps? \n. Here is how I did it:\ncd /etc/nginx\nmkdir ssl\ncd ssl\nopenssl dhparam -out /etc/nginx/ssl/dhparam.pem 2048\ncopy/paste your cert and private key to /etc/nginx/ssl/\ncd /etc/nginx/sites-available\nthere should be config related to your domain name\nhere is the config file.\nChange rstormsf.dev to your server name\n```\nserver {\n  set $site_name rstormsf.dev;\nlisten 443 ssl spdy;\n  ssl_certificate /etc/nginx/ssl/nginx.crt;\n  ssl_certificate_key /etc/nginx/ssl/nginx.key;\n  ssl_session_timeout 5m;\n  ssl_session_cache shared:SSL:50m;\nssl_dhparam /etc/nginx/ssl/dhparam.pem;\n  ssl_protocols TLSv1.1 TLSv1.2;\n  ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK';\n  ssl_prefer_server_ciphers on;\n  add_header Strict-Transport-Security max-age=15768000;\n  ssl_stapling on;\n  ssl_stapling_verify on;\n  resolver 8.8.8.8;\n  ssl_trusted_certificate /etc/nginx/ssl/nginx.crt;\nserver_name  rstormsf.dev;\n  access_log   /srv/www/rstormsf.dev/logs/rstormsf.dev.access.log;\n  error_log    /srv/www/rstormsf.dev/logs/rstormsf.dev.error.log;\nroot  /srv/www/rstormsf.dev/current/web;\n  index index.php;\ncharset utf-8;\ninclude wordpress.conf;\n}\nserver {\n  listen *:80;\n  server_name www.rstormsf.dev;\n  return 301 https://rstormsf.dev$request_uri;\n}\nserver {\n listen *:80;\n server_name rstormsf.dev;\n return 301 https://rstormsf.dev$request_uri;\n}\n```\nMy next steps is to make it in ansible way and also update mysql(mariadb) configs to use over ssl connection (is it a good idea? )\n. @swalkinshaw \nPlease take a look\nhttps://github.com/rstormsf/bedrock-ansible/commit/ac207281808282bfc79e8508a136cefcce0b8ede\nI'm still newbie with ansible, so I think I should also add commands to copy/paste actual certs which is provided in\nhttps://github.com/rstormsf/bedrock-ansible/blob/master/roles/wordpress-setup/templates/wordpress-site.conf.j2#L6-L7\nand also read file paths where to get it from, so a user can define it in group_vars \nLet me know your feedback, I can add those things to my second commit and can create PR to close this ticket.\n1)How do we want to copy certs? Private key and public one.\n2)How do we want to specify paths for our certs\n3)What method should we use to send them? What is the best ansible task for that? Should we use file module?\n4)How can existing users of playbook safely run those tasks which they already ran. Is it safe to run again with added ssl stuff? I hope so.\n. I see @swalkinshaw  - thank you very much for your detailed response. I'll continue working on it and will compare with the ssl role when you PR it to the repo. \n. I'm very new to ansible, so, I didn't know about it\nI also didn't find in Readme docs that I have to ansible-playbook -i hosts/ENV site.yml \n@fullyint thank you very much for your help! Now it works like a charm\nI also went into some problems with debian 7, so please mention that it has to be ubuntu \n```\nASK: mariadb | Add MariaDB MySQL deb and deb-src >\n\n    \\   ^__^\n     \\  (oo)\\_______\n        (__)\\       )\\/\\\n            ||----w |\n            ||     ||\n\nchanged: [yoursite.com] => (item=deb http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main)\n```\n. No problem, I understand it\nI created a gist when I was setting it up\nhttps://gist.github.com/rstormsf/8d674e800ebe21cb74e5\n. it would be great, if you could all collaborate on https://gitter.im Many repo owners leave forums/IRC to Gitter\n. Great! Thank you! I hope newcomers will get it right.  @swalkinshaw I will monitor periodically to see if https://github.com/roots/bedrock comes in on Gitter\n. Rebuilt the DO box using ubuntu-14.04x64 image\ngit clone bedrock-ansible\ncomposer create-project roots/bedrock mysite.com\ncd bedrock-ansible\nchanged in group-vars/production from example.com to mysite.com\nrun\nansible-playbook -i hosts/production secure-root.yml\ncd ../mysite.com\nbundle install\nchange in config/deploy.rb \nset :application, 'mysite.com'\nset :repo_url, 'git@bitbucket.org:username/mysite.git'\nthen in config/deploy/production.rb\nserver 'mysite.com', user: 'deploy', roles: %w{web app db}\ngit init\ngit add .\ngit commit -m \"init\"\ngit remote add origin git@bitbucket.org:username/mysite.git\ngit push origin master\nthen\ncd ../bedrock-ansible\nansible-playbook -i hosts/production site.yml\nwait until I get error for composer.json not found\ncd ../mysite.com\nbundle exec cap production deploy:check\nbundle exec cap production deploy\nall success\ncd ../bedrock-ansible\nansible-playbook -i hosts/production site.yml\nopen up http://mysite.com \n502 Bad Gateway\nPlease WHAT AM I DOING WRONG?\nDNS Setup(DIGITALOCEAN):\nA record: \n@ IP_OF_MY_DROPLET\nCNAME: * @\n. did\nsudo service nginx restart\nsudo service php5-fpm restart\nMy bad, I went to http://mysite.com/wp/wp-admin was able to login and now under appearance I see\nERROR: The theme directory \"twentyfifteen\" does not exist. \ngoing to investigate further.\nsshed into the box and see that\n/srv/www/mysite.com/current/web/wp/wp-content/themes should have all the themes, but for some reason it doesn't show them\nnow it makes sense why main page doesn't show up\n. where is wp_config variable?\ndo you mean this? \nini_set('display_errors', 1);\ndefine('WP_DEBUG_DISPLAY', true);\ndefine('SCRIPT_DEBUG', true);\nJust enabled it\nWhere should I inspect the logs?\n. Aha!! let me see. \nI didn't clone the bedrock, I used composer to create project\nand FYI - it does have .gitkeep and themes folder\nLet me put some theme there and see if it fixes the issue\n. Still nothing :-( I do have web/app/themes folder just tried to put some theme there and did deploy.\nverified by sshing into the box and checked that /srv/www/mysite.com/current/web/app/themes does exists\nDidn't work :-(\nAm I missing some config?\nWhere should I check logs?\n. here is my gitignore\n```\nWordPress\nweb/wp\nweb/.htaccess\nWP-CLI\ndb-sync\nsql-dump-*.sql\nDotenv\n.env\n.env.*\n!.env.example\nApplication\nweb/app/plugins\n!web/app/plugins/.gitkeep\nweb/app/mu-plugins\n!web/app/mu-plugins/.gitkeep\nweb/app/upgrade\nweb/app/uploads\n!web/app/uploads/.gitkeep\n!web/app/mu-plugins/disallow-indexing.php\n!web/app/mu-plugins/register-theme-directory.php\n!web/app/mu-plugins/bedrock-autoloader.php\nVendor (e.g. Composer)\nvendor\n!vendor/.gitkeep\nNode Package Manager\nnode_modules\nVagrant\nbin\n.vagrant\n``\n. JS console output when I'm on http://mysite.com/wp/wp-admin/themes.php\nResource interpreted as Image but transferred with MIME type text/html: \"http://mysite.com/wp/wp-admin/undefined/\".. Feels likewp-contentis not read at all from/srv/www/mysite.com/current/web/wp/wp-content`\n. @swalkinshaw  if you are curious send me your email address, I will send you server info and provide ssh access to https://github.com/swalkinshaw.keys for Repo, and DO box\n. from nginx logs:\n69.181.203.85 - - [26/Dec/2014:15:44:00 -0500] \"GET /wp/wp-admin/undefined HTTP/1.1\" 301 5 \"http://mysite.com/wp/wp-admin/themes.php\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2256.0 Safari/537.36\"\n69.181.203.85 - - [26/Dec/2014:15:44:00 -0500] \"GET /wp/wp-admin/undefined/ HTTP/1.1\" 200 31 \"http://mysite.com/wp/wp-admin/themes.php\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2256.0 Safari/537.36\"\n. Ok, I've changed my gitignore to add * wildcards to paths, deployed the app via capistrano + restarted nginx, - still the same result @austinpray \n. Ok, here is what I did and it started to work! \nInstead of using composer create-project I just cloned bedrock repo and setup deploy configs\ndid a deploy and all is working now.\nBUT\nI don't understand 1 thing: \nin my first setup I had uploaded a theme to app/themes folder\nin my second setup I didn't have any theme\nAfter deploy I see that the uploaded theme exists.\nHow come? \n. I see why. Because even thought I did new private repo when I cloned bedrock, the capistrano /srv/www/repo still have all the configs from old repo. and when I did deploy it actully cloned the old repo not the new one. So I assume gitignore commit worked, just not immediately\n. I will repeat this process again tonight, so I will record everything and publish as gist\n. @swalkinshaw check gitignore on composer repo since that the issue it caused having old gitignore\nEDIT: \nnever mind I thought it's getting from somewhere not directly from github\n. Do you mind to explain briefly how do you integrate it? Are you using any plugin? How do you reset password from wp-admin?\n. but it doesn't solve the problem for reset password link\n. :+1: \n. Awesome! Thank you for the speed @QWp6t \n. Could you guys tell me if there is a command line to update my instance only for particular role in Ansible? (so I don't have to run the whole book, just those updates on my server)\n. Awesome! @swalkinshaw \n. confirmed - face the same issue\n. FIX:\nhttps://github.com/roots/bedrock-ansible/blob/master/roles/deploy/defaults/main.yml#L85-L86\nhandle if/else if hhvm is true \nrun \nsudo service hhvm restart\nkeep in mind that hhvm doesn't have reload only restart\n. For some reason, it just hangs there and is not ran. \nI had to manually ssh into and run\nsudo service hhvm restart\n. Great! Thanks! Please add it to the comments.\n. I do have the same keys there both in Bitbucket and Github.\nThe issue is probably in passphrase that I don't remember and ssh-add can't load it\n. Figured it out.\n1)Make sure the key is added via ssh-add on your LOCAL machine, not instance. \n2)in ~/.ssh/config make sure you provide Forward Yes\nHost example.com\n  ForwardAgent yes\nthen it started working!\nshould it be mentioned anywhere ? @swalkinshaw let me know what you think\n. @swalkinshaw that's the exact link that I personally followed to solve the issue\n. @retlehs Sorry about that\n. aha!\n. ",
    "Telemakhos": "It has been merged... =)\n. Not fixed yet... I've got the same problem :trollface:. Either the install section in the readme is wrong, or there's a mistake anywhere in the code. I've also raised this bug in the forums...\n. Ok, I've narrowed down the error to the connection from the host (outside vagrant) to the guest (inside vagrant). Everything inside vagrant works ok. I installed lynx and navigated to mydomain.dev and the wordpress site is displayed (in the terminal). So nginx, php-fpm, etc seem to be working, but somewhat the connections are not forwarded so it looks like a networking misconfiguration... \u00bf?\n. Damn! that was it... manually adding the domain to /etc/hosts file fixes the issue...\nI thought that the domain was being added automatically like in vaprobash. What I can't understand is why with the domain example.dev it works without adding it to hosts! :sweat:\n. Yes, this is my plugin list right now:\n$ vagrant plugin list\nvagrant-bindfs (0.4.0)\nvagrant-cachier (1.2.0)\nvagrant-hostsupdater (0.0.11)\nvagrant-share (1.1.3, system)\nAs I've commented, with vaprobash works like a charm and I don't have to add the domain to /etc/hosts\n. Just the typical localhost stuff...\n$ cat /etc/hosts\n127.0.0.1       localhost\n0.0.0.0         localhost\n255.255.255.255 broadcasthost\n::1             localhost\nfe80::1%lo0     localhost\nand few domains for dev... but any of the IPs is conflicting with the 192.168.50.5 that bedrock-ansible uses...\n. @Foxaii or @swalkinshaw Because of some plugins and themes I need to run on PHP V5.6 before the maintainers include full PHP7 support...\nIf I install the repo at the previous commit before PHP 5.6 removal (this one).. do you think that bedrock will work without major issues?\n. ",
    "rossedman": "I think launching infrastructure and provisioning it are two different things. Terraform would be a better choice. Pass a local-exec command from terraform to provision with ansible. This would allow swapping out of whole server cluster and configuration files if you wanted master-->slave databases and whatever.... My two cents.\n. @swalkinshaw I understand. I just deployed some test servers last night with Terraform and could see it working beautifully with Ansible because it keeps the concerns separated. Defining infrastructure vs Provisioning. Hopefully the DO module will update soon enough so you can do it all through Ansible.\n. ",
    "landerss0n": "Glad to hear\n. I would love to see this!\n. Still not fixed?\n. ",
    "nbyloff": "Not exactly polished, but I thought I would take a swing at it. Here's a simple, working instance of creating a droplet and printing the IP address. 84221e0dfbd7275160c83fb6f27c5e6574aad46d\nWith the add_host command from the inventory module, the created droplet can immediately launch into the typical trellis server provisioning. The one thing I had to change your_server_hostname to localhost ansible_connection=local in the host file I was using. Until I did that, it would spit out an error. Don't know why.\nEventually I'd like to get it to where multiple DB, web, load balancers, etc. will all be configured. But for now, a single droplet will do. I'd like to hear what expectations on how you expect this to work and be configured. (IE: how do you want this simple demo to change in order to make it into master). This would be a great feature to have in the core. \nPlease note, dopy 0.3.7 is broken right now. Install with 0.3.5\nsudo pip install 'dopy=0.3.5'\n. @swalkinshaw what about using a template to accomplish writing to the hosts file? The most difficult part would be to make sure you read the hosts file correctly to capture any pre-configured servers. But you could:\n- Read single environment host file and collect groups & servers\n- Check DO to see if the server name in inventory matches a droplet name via api\n- Create droplet that doesn't exist\n- write new hosts file with template using new IP addresses in memory as well as ones loaded from the first step\nThat might require the default hosts file to look something like this:\n```\nproduction_host ansible_host=XXX.XXX.XXX.XXX\n[production]\nlocalhost ansible_connection=local\nproduction_host \n[web]\nlocalhost ansible_connection=local\nproduction_host \n```\nBut that will also leave the door open for updates in the future for simple configuration changes to create clusters like:\n```\nweb1 ansible_host=XXX.XXX.XXX.XXX\nweb2 ansible_host=XXX.XXX.XXX.XXX\ndb1 ansible_host=XXX.XXX.XXX.XXX\ndb2 ansible_host=XXX.XXX.XXX.XXX\ndb3 ansible_host=XXX.XXX.XXX.XXX\nlb1 ansible_host=XXX.XXX.XXX.XXX\n[production]\nlocalhost ansible_connection=local\nweb1\nweb2\ndb1\ndb2\ndb3\nlb\n[web]\nlocalhost ansible_connection=local\nweb1\nweb2\n[database]\ndb1\ndb2\ndb3\n[load_balancer]\nlb\n```\n. Yes, while I have an idea how to keep the hosts files updated programmatically it's probably not necessary. Time could be better spent creating a playbook that builds a cluster of servers for a large website.\nThe only other update I would make is notify a handler or something to provision the new droplet once created. The user could take the new IP address and paste it into their host file manually. \n. I am using terraform as well with the dynamic inventory in ansible; I think terraform would be great to be project. However it's possible to create the server and begin provisioning immediately strictly with ansible. This could work with a large amount of cloud providers, not just digital ocean. Here's the full list of dynamic inventory options that comes with ansible. \nThen for a pure ansible solution, you could do something like:\n````\n\nhosts: localhost\n  connection: local\n  gather_facts: False\n\ntasks:\n    - name: Create Digital Ocean Server\n      digital_ocean:\n        state: present\n        command: droplet\n        name: trellis-test\n        image_id: ubuntu-16-04-x64\n        region_id: nyc1\n      register: do\n- name: Add host to inventory\n  add_host:\n    name: \"{{ do.droplet.ipv4_address }}\"\n    groups: web\n  when: do.droplet is defined\n\n\nhosts: web:&{{ env }}\n  remote_user: \"{{ admin_user }}\"\n  gather_facts: False\n\ntasks:\n   # something to wait until SSH is available and we can start the server.yml playbook\n    - name: Wait for ssh\n      local_action: \"wait_for port=22 host={{ inventory_hostname }}\"\n````\nThen you can keep the single server setup or allow YAML configuration options that would build a private cloud with a LB, dedicated DB server, or however the user wants it. It also allows for things like tagging your droplets so we can grab servers by identifiers so you know what should be installed on each machine.. Currently in my projects I modify the wordpress_sites.yml keys for backups like this. What if there was an optional server attribute? (Non-working psuedo code below)\nssl:\n  enabled: true\n  provider: letsencrypt\ncache:\n  enabled: false\nbackup:\n  enabled: true\n  cron:\n    hour: 6\n    minute: 0\nserver:\n  enabled: true\n  provider: \"{{ cloud_servers.provider }}\"\n  name: \"{{ web_server }}\" # this is the name of the server; should be unique\n  single: true  # single server that has DB, nginx, etc. all on one server like the current default setup\n\nThen in like group_vars/all/something.yml  you could have configuration options for the droplet:\ncloud_servers:\n  web_server: www-1  #unique name\n  provider: digital_ocean\n  image_id: ubuntu-16-04-x64\n  region_id: nyc1\n  ...\n\nI added the single: true but might beyond the scope of this project. I mention that b/c I modified an environment and have 11 wordpress sites on 4 servers (1 LB, 2 web servers, and 1 DB server). If single were false, then options could be expanded to allow a much more dynamic environment and your users could begin building their own private clouds, especially if the community started adding playbook examples in the wiki.\nA setup similar to his would allow for optional droplet creation and linking a server dynamically by a unique name vs. manually pasting the IP address in the hosts file.\nAlso, In the OP of this issue, @swalkinshaw mentioned updating DNS entries, which would be huge. I had mentioned a few weeks ago about Lets Encrypt and DNS validation via API on the forums. You could go end to end without any manual intervention. Exciting options!. @swalkinshaw sure thing. added.\n. Fair enough. I saw that project but posted here for now for visibility. Majority of my team is Mac, but I stress environment agnostic code before making it in the master. So I test everything in Windows.\nI got all the bullet points above working in my local Trellis install, but i'll look at options on roots-cli and contribute where I can. \nThe SSH forwarding on Windows was a necessary monster for instances where the IT manager for specific vendors preferred that. \n. Mac/Linux SSH forwarding should work just fine the way the default project is. I have just included the necessary files to make it work on Windows, and only loads them on Windows machines. I think it's worth while including the main Trellis project. All the other configuration makes more sense in roots-cli. \nI needed a reason to get back into go. :)\n. I can create a pull request for sure. Is it supposed to work for Windows in 1.8? I didn't see anything in the changelog. \nRegardless, I will submit the PR. The only requirement for Windows users outside of including these scripts in Trellis is to have Pageant running with their key added before vagrant up\nhttp://www.chiark.greenend.org.uk/~sgtatham/putty/download.html\n. FWIW, I just tested an ecommerce site I did with Trellis about a month ago, and it still reports an A+.\n. I created this PR on the wrong commit; it removes the cron email. Should we delete this one and I recommit so it doesn't affect the cron email PR?\nSorry :\\\n. I will just close it, and do it right.\n. If this makes it into master, when you write docs, you might also include steps on how to auto load pageant and the user keys on Windows at boot up so it's not a manual process. I could write them up, but this is essentially it:\nhttp://blog.shvetsov.com/2010/03/making-pageant-automatically-load-keys.html\nIt also expects keys to be in .ssh folder in the user directory, so on Windows, the user will need to put their keys in a folder called C:\\Users\\username\\.ssh. By default the names need to be id_rsa.pub and id_rsa.ppk. \n. @mullnerz I was annoyed by that issue too. I created PR #418 for SSH forwarding, but also includes this fix.\n. Don't they automatically set it if it's not provided? \ndoing_cron section\nEspecially since this is set: define('DISABLE_WP_CRON', true);\nFrom what I understand, that makes it so the transients aren't even used?\n. I got this error, then tried to dowgrade to 1.9.4. When running the deploy script, I get\nERROR: fail is not a legal parameter in an Ansible task or handler\nThis is from a brand new trellis checkout from earlier this week. I am going to just use the current Ansible release and try @baptistmarchand suggestion\n. Ah ok @swalkinshaw. Can I do that by just deleting the old keys in my /etc/nginx/ssl/letsencrypt folder? I just re-provisioned the server with the trellis update on the letsencrypt main.yml file, but still get the error.\n. @swalkinshaw, Have you seen this error when I deleted the key & cert in that folder? It's on the test nginx.conf role/task. I keep rebooting and trying to reprovision. Then I switched it to http, rebooted, and back to https. Keep getting the error below.\njavascript\nSSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch\n. For anyone that finds this issue, Deleting the files above worked,  but I had to do the following. Let's encrypt ping test kept failing until I rolled the site back to http for some reason.\nSet the wordpress_sites.yml vars wp_home and wp_siteurl back to http. I also set ssl enabled: to false in the same file. Reprovisioning the production server, rebooted, then changed the above back to true and https, reprovisioned again. \nOriginal issue gone, as well as my key values mismatch. Thanks!\n. That could be ugly, a bunch of numbered files. But that's left to people's dev patterns too. Personally, I would create a custom-main.yml in that folder, and have a bunch of sub-folders that have each of my roles and custom-main.yml has all my tasks ordered appropriately. Just an extension of how server.yml works. But if I only had a couple extra tasks, I might just put them all in the custom-main.yml. I suppose some may not like that either, but it would do wonders for maintenance on customized client environments. \nThe abstraction can also be good too, especially as the user base matures and understands Ansible more.  My impression would be that the users who intend on adding customizations to Trellis have some understanding of how Ansible works. In order for someone to use the provision-hooks task, they'd have to. The trellis documentation is already really good so with a couple extra paragraphs for provision-hooks I think that's sufficient for most users. It could even contain a couple commented out examples like in the deploy-hooks folder.. I see this is still not dead, but discussion stopped. This would be huge for me. Here's my input:\n\nWith the example code, a user can introduce new code in multiple ways. They could (1) have a single YAML file that references other YAML files (or complete roles) in the order they should be executed, (2) number the files like suggested in order of execution.\nI think this would actually encourage people to understand ansible and trellis more. I would imagine in most scenarios, once you're to the point you want to add custom functionality to provisioning, you have basic understanding of how things are working.\nMerging into your project from trellis master become a lot less painful (this cannot be understated how nice it will be)\n. I'll make a PR for this for sure; it will be 100% optional and only available as people might need it.. I can't help but notice this is the only PR with no activity. Is it safe to assume this, or anything similar won't make it?\n\nIt seems harmless to me; if you are new or not comfortable with Ansible yet, this update would go unnoticed. But adds a lot of flexibility. We have deploy-hooks, why not provision-hooks?. I really appreciate your thorough response. I have been using separate custom.yml files like you suggest, and most likely the most reasonable solution currently. I have been using the initial method for a while now only because it forces me to not forget specific files or setups if I need them in the future.\nBut that most likely be solved with better documentation on individual projects. Again, thank you for the response.. ",
    "davisonio": "Any update on this? Would be a cool feature. at the moment I'm doing this with terraform in the repo. ",
    "cibulka": "Any news on XDebug inclusion please? :)\n. OK, switching boxes from roots/bedrock-ansible to hashicorp/precise64 seems to work for me (although everything seems to be significantly slower).\nAlso, even on hashicorp/precise64 I can install Ruby gems by a method mentioned in this SO answer: http://stackoverflow.com/questions/22115936/install-bundler-gem-using-ansible\n\nThe problem is that, when running gem install bundler via ansible, you're not initializing rbenv properly, since rbenv init is run in .bashrc or .bash_profile. So the gem command used is the system one, not the one installed as a rbenv shim. So whenever you install a gem, it is installed system-wide, not in your rbenv environment.\n\nExample Ansible role:\n- name: Install Bundler\n  command: bash -lc \"gem install bundler\"\nIf there was a way how to resolve Ruby conflict (if the problem with Compass is there) and get back from precise64 to roots/bedrock as it's ...\n1) very fast \n2) an official box to use with your awesome stack\n... it would be rad. \n. Thanks for quick response! I will definitely take a look at rbenv playlists. \nOne last thing - Would you maybe consider to add Grunt & Compass Ansible role to Roots/Bedrock-Ansible with recommended Ruby setup? It seems, that other project of yours are quite Grunt-oriented, so I would guess that majority of your users would appreciate that. And all server noobs like I am would be spared from the multiple Rubies arcane! :)\n. If your approach is to keep things simple and not adding anything not-required, what about to just include RBENV/RVM for us and normalize the Ruby enviroment? One thing I loved about Bedrock-Ansible was the fact it worked straight out of the box. It would be nice, if same thing would apply for gem installation by Ansible ... \n. Okay, I get how adding optional Grunt/Compass installation to the stack is too localized. But errors happening after (only some, not all) gem installs otherwise fully supported by Ansible due to conflicting versions of Ruby sound like a bug to me. Or at least unexpected behaviour for the user. Even more so, if the problem is \"fixed\" by replacing roots/bedrock-ansible box with default hashicorp/precise64. \nIf all of that is easily fixable by some sort of package, that resolves which Ruby is used when (and which one is used by default), is sounds to me like a win-win for everyone.\nBut then again, I really don't know much about LAMP dependency management and Ruby, so maybe this really is an unreasonable request ...\n. Right now I need to finally focus on actual development and not potentially blowing up my local enviroment (again) :), but once I'll have some time in my hands, I will try to do that and let you know!\n. Nice, thanks for solving the problem superquickly!\n. The error above is the result of ansible-playbook -i hosts/production server.yml command. So yes, I want to deploy with Trellis, sorry for wrong choice of words.\nSo, to rephrase my question - would usage of deploy.yml work on any server I have SSH access to? Or is there any list of requirements the shared hosting has to meet?\nAnd should we move this discussion to Discourse, as @mAAdhaTTah suggested?\n. Anyway, I phrased my question hopefully a little better on Roots's Discourse: https://discourse.roots.io/t/requirements-of-shared-hosting-for-staging-production-with-trellis/4540/1\nThank you!\n. Weirdly enough, when I'm trying to run Composer locally, it hangs also on cloning squizlabs/php_codesniffer:\n```\n  - Installing squizlabs/php_codesniffer (dev-master 71945d9)\n    Cloning 71945d90d2735aa7cc466aa099674d011ee6ad17\nFailed to download squizlabs/php_codesniffer from source: The process \"git clone --no-checkout 'https://github.com/squizlabs/PHP_CodeSniffer.git' '/Users/cibulka/Web/divnamista.dev/vendor/squizlabs/php_codesniffer' && cd '/Users/cibulka/Web/divnamista.dev/vendor/squizlabs/php_codesniffer' && git remote add composer 'https://github.com/squizlabs/PHP_CodeSniffer.git' && git fetch composer\" exceeded the timeout of 300 seconds.\n    Now trying to download from dist\n```\nCould that be related in any way? \nHere is my Composer.json, if that helps in any way: https://gist.github.com/cibulka/167194786221953c3d2dab66484420d3\n. It would seem, that on my new machine the issue is gone. Thanks & sorry for late confirmation!\n. Oh god. Thank you. :) Maybe the provisioning script could look for those kinds of stupid user errors (such as checking the existence of variables)? Or maybe not, I should probably just sleep more.\nAbout .env - thanks for clarification, I wasn't sure about that. The overwriting feature is pretty cool! Thanks for a very quick reply.. ",
    "JacobDorman": "Any update on this? I could have a crack at it, or are we waiting on other changes to be merged?\n. Yep, that was a mistake. I've changed the user to 'deploy'.\nThe last provision and deploy went smoothly. \n- didn't run into the issue with fail2ban, but did increase the ferm dport_limit for ssh to hits: \"20\". \n- changed run_composer: false and site_install: false\n- ran secure-root.yml playbook before deploy\n. It's a straight-up copy. The other roles aren't installed from galaxy so I didn't want to introduce a new requirement / install step.\nAre you thinking requirements.yml, or just adding a \"To use xdebug, ansible-galaxy install MaximeThoonsen.php5-xdebug \"?\nAre any of the other roles able be be installed from or replaced by ansible galaxy roles?\n. Re-using roles from galaxy wherever possible is definitely a good thing. Do you want to merge this in the meantime, and create a new issue for switching to a requirements.yml ? or should we introduce it along with this role?\nNot sure if there is a consensus on naming, i'm just going off http://docs.ansible.com/galaxy.html#advanced-control-over-role-requirements-files.\nIt looks like you can specify version numbers in the yml, but not version constraints like npm/composer/bundler. Should be enough. Anything else we need to know?\n. okay, sounds good. I'll have a crack at it if this is still open in a couple of weeks.\n. Ahh, sorry about that. Haven't done much Ruby.\n. I've been running into this too... needing to set variables for the deploy role per site (for example a different theme name in project_local_files). \nI can add things to the wordpress_sites dictionary... but is there any reason we couldn't have a structure like @developdaly expected? \nLooking at http://docs.ansible.com/ansible/intro_inventory.html#splitting-out-host-and-group-specific-data it seems the structure could be:\ngroup_vars/\n- example.com\n- otherexample.com\nhost_vars/\n- production\n- staging\nhosts/\n- production\n- staging\n. I've been running into this with variables for deploy role per site. (eg, theme directory for project_local_files and project_pre_build_commands_local).\nIf I'm understanding http://docs.ansible.com/ansible/intro_inventory.html#splitting-out-host-and-group-specific-data correctly, couldn't we have something like:\ngroup_vars/\n- example.com\n- otherexample.com\nhost_vars/\n- development\n- production\n- staging\nhosts/\n- development\n- production\n- staging\n. Thanks @fullyint, that's actually the method I ended up going with. There's still some overlap between sites-install and deploy roles (dev/staging) but it's working fairly well. \n113 & #308 look great.\n. Yep, that's closer to what I ended up with. Default/Common config for post_build_commands in deploy role default vars, merged with project_post_build_commands from sites (wordpress_sites) dict.\nI've been playing around with adapting trellis for other platforms, mainly magento, which has been a good learning experience. Some overlaps between sites_install (dev) and deploy (staging/prod) are currently:\n- shared folders / project_shared_children\n- Create .env file / Copy project templates\n- no custom commands to run after install in sites_install\nDev on vagrant with synced folders is obviously a different situation than a deploy, but might be possible to share more than currently.\nThat ansible vault branch looks good btw, would like to see that included.\n. I think you've covered the benefits and challenges well. I hadn't thought about the releases directory on dev. \nInstead of combining server.yml & dev.yml playbooks, maybe we should look at wordpress-install and deploy roles instead? \nI'll have another look next time i'm at that end of a project and report back if I come up with something useful.\n. Sorry for the delay... SSH tunnel is a better solution. Here are the docs for IntelliJ is case anyone needs.\n. would changing those lines to php_flag break anything?\n. ",
    "timiyay": "This issue seems to have resolved itself, though I have no idea why. I just vagrant destroyed my bedrock box, ignored it for a couple of days, then did vagrant up, and I'm back in action.\nI'll close this off...\n. ",
    "intelligence": "I've tried all of the above with no resolution. Also tried switching from the bedrock box to regular trusty64, no luck with that either.\nAlso tried this: http://stackoverflow.com/a/23554973/562747\nI just updated Vagrant to latest version, thought that might be it, but my old box still works.\nWould be really helpful if you could figure out what you did @nathanielks \n. Unfortunately not, I've halted all machines.. Really annoying this.\n. As I can get in manually via ssh -p 2222 vagrant@localhost should I just run the playbook on it's own or will it fail due to stuff not getting provisioned as it should via the initial vagrant up?\n```\nvagrant-hostsupdater missing, please install the plugin:\nvagrant plugin install vagrant-hostsupdater\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Checking if box 'roots/bedrock' is up to date...\n==> default: Clearing any previously set forwarded ports...\n==> default: Clearing any previously set network interfaces...\n==> default: Preparing network interfaces based on configuration...\n    default: Adapter 1: nat\n    default: Adapter 2: hostonly\n==> default: Forwarding ports...\n    default: 22 => 2222 (adapter 1)\n==> default: Running 'pre-boot' VM customizations...\n==> default: Booting VM...\n==> default: Waiting for machine to boot. This may take a few minutes...\n    default: SSH address: 127.0.0.1:2222\n    default: SSH username: vagrant\n    default: SSH auth method: private key\n    default: Warning: Connection timeout. Retrying...\n    default: Warning: Remote connection disconnect. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\n    default: Warning: Authentication failure. Retrying...\nTimed out while waiting for the machine to boot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.boot_timeout\" value) time period.\nIf you look above, you should be able to see the error(s) that\nVagrant had when attempting to connect to the machine. These errors\nare usually good hints as to what may be wrong.\nIf you're using a custom box, make sure that networking is properly\nworking and you're able to connect to the machine. It is a common\nproblem that networking isn't setup properly in these boxes.\nVerify that authentication configurations are also setup properly,\nas well.\nIf the box appears to be booting properly, you may want to increase\nthe timeout (\"config.vm.boot_timeout\") value.\n```\n. In my bedrock-ansible folder I have a .vagrant folder, it's only subfolder is \"machines\", is this the folder you mean, but that it lacks the provisioners subfolder?\n. Nope, it's vanilla. First time trying out bedrock-ansible, last project I worked on I used vagrant with bedrock setup manually, the ansible playbook wasn't finished yet.\nRe the SSH trouble, here's a SO thread about what I've tried: http://stackoverflow.com/questions/26978426/vagrant-warning-authentication-failure-retrying\n. Ah, nice heads up.\nconfig.vm.network :private_network, ip: '192.168.50.5'\nconfig.vm.hostname = 'zahnarzt-altena.dev'\nbedrock_path = '../bedrock'\nbedrock_path_server = '/srv/www/zahnarzt-altena.de/current'\nShould work, right? (Please note it's a german TLD, not dev misspelled ;-))\n. Thanks!\nRegarding authentication failure, anything I can check up on with the ssh keys that might be in disorder (although they should not be I suppose).\nauthorized_keys in guest should have the content of id_rsa.pub on the host?\n. Thanks for your thorough steps!\n1) Just went through a diff checker, the keys are identical.\n2) Log don't seem to tell me much, besides it's failing\n```\nDEBUG virtualbox_4_3:   - [1, \"ssh\", 2222, 22]\nDEBUG ssh: Checking key permissions: /Users/intelligence/.vagrant.d/insecure_private_key\n INFO ssh: Attempting SSH connection...\n INFO ssh: Attempting to connect to SSH...\n INFO ssh:   - Host: 127.0.0.1\n INFO ssh:   - Port: 2222\n INFO ssh:   - Username: vagrant\n INFO ssh:   - Password? false\n INFO ssh:   - Key Path: [\"/Users/intelligence/.vagrant.d/insecure_private_key\"]\nDEBUG ssh: == Net-SSH connection debug-level log START ==\nDEBUG ssh: D, [2014-11-19T10:44:41.387605 #43783] DEBUG -- net.ssh.transport.session[808a0b44]: establishing connection to 127.0.0.1:2222\nD, [2014-11-19T10:44:41.389095 #43783] DEBUG -- net.ssh.transport.session[808a0b44]: connection established\nI, [2014-11-19T10:44:41.389868 #43783]  INFO -- net.ssh.transport.server_version[808a12b0]: negotiating protocol version\nD, [2014-11-19T10:44:41.410979 #43783] DEBUG -- net.ssh.transport.server_version[808a12b0]: remote is SSH-2.0-OpenSSH_6.6.1p1 Ubuntu-2ubuntu2\nD, [2014-11-19T10:44:41.411277 #43783] DEBUG -- net.ssh.transport.server_version[808a12b0]: local is SSH-2.0-Ruby/Net::SSH_2.9.1 universal.x86_64-darwin12.5.0\nD, [2014-11-19T10:44:41.415391 #43783] DEBUG -- tcpsocket[808a1c74]: read 1648 bytes\nD, [2014-11-19T10:44:41.416179 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 0 type 20 len 1644\nI, [2014-11-19T10:44:41.416735 #43783]  INFO -- net.ssh.transport.algorithms[808a5eb4]: got KEXINIT from server\nI, [2014-11-19T10:44:41.417995 #43783]  INFO -- net.ssh.transport.algorithms[808a5eb4]: sending KEXINIT\nD, [2014-11-19T10:44:41.419187 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 0 type 20 len 2020\nD, [2014-11-19T10:44:41.419527 #43783] DEBUG -- tcpsocket[808a1c74]: sent 2024 bytes\nI, [2014-11-19T10:44:41.419710 #43783]  INFO -- net.ssh.transport.algorithms[808a5eb4]: negotiating algorithms\nD, [2014-11-19T10:44:41.420342 #43783] DEBUG -- net.ssh.transport.algorithms[808a5eb4]: negotiated:\n kex: diffie-hellman-group-exchange-sha1\n host_key: ssh-rsa\n encryption_server: aes128-cbc\n encryption_client: aes128-cbc\n hmac_client: hmac-sha1\n hmac_server: hmac-sha1\n compression_client: none\n compression_server: none\n language_client: \n language_server: \nD, [2014-11-19T10:44:41.420512 #43783] DEBUG -- net.ssh.transport.algorithms[808a5eb4]: exchanging keys\nD, [2014-11-19T10:44:41.421362 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 1 type 34 len 20\nD, [2014-11-19T10:44:41.421588 #43783] DEBUG -- tcpsocket[808a1c74]: sent 24 bytes\nD, [2014-11-19T10:44:41.427700 #43783] DEBUG -- tcpsocket[808a1c74]: read 152 bytes\nD, [2014-11-19T10:44:41.428150 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 1 type 31 len 148\nD, [2014-11-19T10:44:41.433375 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 2 type 32 len 140\nD, [2014-11-19T10:44:41.433610 #43783] DEBUG -- tcpsocket[808a1c74]: sent 144 bytes\nD, [2014-11-19T10:44:41.439865 #43783] DEBUG -- tcpsocket[808a1c74]: read 720 bytes\nD, [2014-11-19T10:44:41.440195 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 2 type 33 len 700\nD, [2014-11-19T10:44:41.443724 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 3 type 21 len 20\nD, [2014-11-19T10:44:41.443939 #43783] DEBUG -- tcpsocket[808a1c74]: sent 24 bytes\nD, [2014-11-19T10:44:41.444290 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 3 type 21 len 12\nD, [2014-11-19T10:44:41.445285 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: beginning authentication of vagrant\nD, [2014-11-19T10:44:41.445781 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 4 type 5 len 28\nD, [2014-11-19T10:44:41.446026 #43783] DEBUG -- tcpsocket[808a1c74]: sent 52 bytes\nD, [2014-11-19T10:44:41.446999 #43783] DEBUG -- tcpsocket[808a1c74]: read 52 bytes\nD, [2014-11-19T10:44:41.447305 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 4 type 6 len 28\nD, [2014-11-19T10:44:41.447607 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: trying none\nD, [2014-11-19T10:44:41.447997 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 5 type 50 len 44\nD, [2014-11-19T10:44:41.448164 #43783] DEBUG -- tcpsocket[808a1c74]: sent 68 bytes\nD, [2014-11-19T10:44:41.453258 #43783] DEBUG -- tcpsocket[808a1c74]: read 68 bytes\nD, [2014-11-19T10:44:41.453648 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 5 type 51 len 44\nD, [2014-11-19T10:44:41.453971 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: allowed methods: publickey,password\nD, [2014-11-19T10:44:41.454231 #43783] DEBUG -- net.ssh.authentication.methods.none[808cce38]: none failed\nD, [2014-11-19T10:44:41.454449 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: trying publickey\nD, [2014-11-19T10:44:41.455237 #43783] DEBUG -- net.ssh.authentication.agent[808d0bb4]: connecting to ssh-agent\nD, [2014-11-19T10:44:41.455623 #43783] DEBUG -- net.ssh.authentication.agent[808d0bb4]: sending agent request 1 len 61\nD, [2014-11-19T10:44:41.455983 #43783] DEBUG -- net.ssh.authentication.agent[808d0bb4]: received agent packet 2 len 5\nD, [2014-11-19T10:44:41.456159 #43783] DEBUG -- net.ssh.authentication.agent[808d0bb4]: sending agent request 11 len 0\nD, [2014-11-19T10:44:41.456431 #43783] DEBUG -- net.ssh.authentication.agent[808d0bb4]: received agent packet 12 len 681\nD, [2014-11-19T10:44:41.457544 #43783] DEBUG -- net.ssh.authentication.methods.publickey[808d0e34]: trying publickey (19:8a:49:fa:7c:64:11:3c:61:57:05:1c:ce:85:1c:0f)\nD, [2014-11-19T10:44:41.458114 #43783] DEBUG -- tcpsocket[808a1c74]: queueing packet nr 6 type 50 len 348\nD, [2014-11-19T10:44:41.458373 #43783] DEBUG -- tcpsocket[808a1c74]: sent 372 bytes\nD, [2014-11-19T10:44:41.460564 #43783] DEBUG -- tcpsocket[808a1c74]: read 68 bytes\nD, [2014-11-19T10:44:41.460877 #43783] DEBUG -- tcpsocket[808a1c74]: received packet nr 6 type 51 len 44\nD, [2014-11-19T10:44:41.461137 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: allowed methods: publickey,password\nD, [2014-11-19T10:44:41.461254 #43783] DEBUG -- net.ssh.authentication.session[808c8900]: trying password\nE, [2014-11-19T10:44:41.461415 #43783] ERROR -- net.ssh.authentication.session[808c8900]: all authorization methods failed (tried none, publickey, password)\nDEBUG ssh: == Net-SSH connection debug-level log END ==\n INFO ssh: SSH not ready: #\n```\n3) Content of config is:\nHost 127.0.0.1\n  StrictHostKeyChecking no\n  UserKnownHostsfile=/dev/null\n  IdentitiesOnly yes\n4) I guess that's what's left to do.\n. And there we have it. As simple as just deleting insecure_private_key.\nWow I feel stupid, but I had a hunch it was a problem created by myself. Thanks for being patient with me, and hopefully somebody else can get something out of this as well :)\n. Ah, yes, sorry. The staging group vars file contains:\n```\nmysql_root_password: xxx\nwordpress_sites:\n  - site_name: sub.domain.com/project\n    site_hosts:\n      - sub.domain.com/project\n      - x.x.x.x (my droplet ip)\n    user: deploy\n    group: www-data\n    site_install: true\n    site_title: Staging\n    admin_user: admin\n    admin_password: xxx\n    admin_email: admin@staging.example.com\n    system_cron: true\n    multisite:\n      enabled: false\n    env:\n      wp_home: http://sub.domain.com/project\n      wp_siteurl: http://sub.domain.com/project/wp\n      wp_env: staging\n      db_name: xxx\n      db_user: xxx\n      db_password: xxx\n``\n. Changing wordpress version to 4.5 in composer.json before runningvagrant up` does the trick.\n. ",
    "alx": "Hi all,\nI've got the same kind of issue, and tried every mentionned in this thread without success.\nEverything is a fresh install on a debian wheezy.\nCould you help me debug this problem ?\nIn virtualbox GUI, the bedrock virtual machine is running.\nHere is a part of the VAGRAND_LOG=debug log : \nDEBUG ssh: == Net-SSH connection debug-level log START ==\nDEBUG ssh: D, [2015-01-24T00:56:57.428328 #24515] DEBUG -- net.ssh.transport.session[51c44cc]: establishing connection to 127.0.0.1:2222\nD, [2015-01-24T00:56:57.429399 #24515] DEBUG -- net.ssh.transport.session[51c44cc]: connection established\nI, [2015-01-24T00:56:57.429904 #24515]  INFO -- net.ssh.transport.server_version[51c7f8c]: negotiating protocol version\nDEBUG ssh: == Net-SSH connection debug-level log END ==\nHere trying with command line : \n$ ssh -vvv -p 2222 -i /home/alx/.vagrant.d/insecure_private_key vagrant@localhost \nOpenSSH_6.0p1 Debian-4+deb7u2, OpenSSL 1.0.1e 11 Feb 2013\ndebug1: Reading configuration data /etc/ssh/ssh_config\ndebug1: /etc/ssh/ssh_config line 19: Applying options for *\ndebug2: ssh_connect: needpriv 0\ndebug1: Connecting to localhost [::1] port 2222.\ndebug1: connect to address ::1 port 2222: Connection refused\ndebug1: Connecting to localhost [127.0.0.1] port 2222.\ndebug1: Connection established.\ndebug3: Incorrect RSA1 identifier\ndebug3: Could not load \"/home/alx/.vagrant.d/insecure_private_key\" as a RSA1 public key\ndebug1: identity file /home/alx/.vagrant.d/insecure_private_key type -1\ndebug1: identity file /home/alx/.vagrant.d/insecure_private_key-cert type -1\nThen it hangs...\n. Yes, it appears on the first time I'm setting up the vm with vagrant up command.\nI've tried a few vagrant destroy/up with info from comments on this thread, but still get this same error.\n. ",
    "phpanos": "For me the files existed in /etc/ssh but were empty (Check /var/log/auth.log for the errors). So I removed all ssh_host* files and ran:\nvagrant halt\nvagrant destroy\nvagrant up --provision\nAnd that solved it for me.\n. ",
    "mmikeww": "I was having this same problem.\nMy issue was, I was trying a VM inside of a VM.  I am on a Windows laptop. I installed Ubuntu guest into a VirtualBox VM on the Windows host. Then, inside that Ubuntu, I attempted to install trellis/vagrant/anothervirtualbox. And I ran into this SSH error. \nThis link recommended I turn on the vb.gui setting to debug, which showed me that it wasn't really an SSH problem, but some virtualization error:\nhttps://discourse.roots.io/t/timed-out-while-waiting-for-the-machine-to-boot/5943/\nSome more googling brought me to this link:\nhttp://stackoverflow.com/questions/24620599/error-vt-x-not-available-for-vagrant-machine-inside-virtualbox\nThat link explained that the problem was the nested VM attempt. Apparently VirtualBox doesn't support nested 64-bit VMs. Installing VMWare Player on my Windows host, allowed me to nest the VMs successfully, and get past that \"SSH\" error.\n. ",
    "JJ": "I just had the same problem. It stopped after a while with the message:\ndefault: SSH auth method: private key\nTimed out while waiting for the machine to boot. This means that\nVagrant was unable to communicate with the guest machine within\nthe configured (\"config.vm.boot_timeout\" value) time period.\nHowever, checked VB and the machine seemed to be running, although it was not responding to ssh. I tried vagrant up again and it up and started without an (apparent) problem, although it required to enter the sudo password.. OK, but what if that sshd_port option is not set? Any idea?. ",
    "at-thuytran": "I checked folder .vagrant\\machines\\default\\virtualbox, I saw don't have file private_key. I added that and ran vagrant reload it ok.\n. ",
    "aaroneaton": "Oh hey, it's confirmed.\nI'm an idiot.\nCarry on.\n. I had messed up the site URL variables.\n. ",
    "cam5": "I did the same thing. Being overenthusiastic, I removed /wp from the site_url\n. ",
    "nickjj": "@nathanielks \nYou may be interested in using DebOps. Every role I released (except fail2ban) is available in DebOps and is more polished than my soon to be deprecated roles.\nhttp://debops.org\n. @nathanielks, thanks. No problem.\nJust be warned that I don't plan to support them in the future. In fact they will likely be removed from Github/Galaxy in a few weeks.\nFail2ban will stick around for a while though, as it's the only role not currently in DebOps.\n. ",
    "QWp6t": "I'd say that you can use GPL if it's a Composer dependency because the source codes aren't distributed together. That is, the viruslike legalese of GPL is effective only when GPL code is distributed with other code. Pulling it in as a dependency resolves this issue. There's still a question of what constitutes \"derived works,\" of course, something on which I'm not qualified enough to opine.\nEdit: Just to clarify, in case I may have given someone the wrong idea, this is my own personal opinion. Not an official position regarding this repo. I'm simply throwing this out there as part of the discussion to see what folks think.\n. Sounds like all of this could be easily resolved with ACL.\n. You should use setfacl to mask the default permissions for the users and/or groups to whom you wish to grant access, whether that's the web_user or www-data or whomever. There is almost never a need to mess with chmod or chown. ACL is far more flexible.\nI'll see if I can reproduce this issue. How do you guys run into it? Just simply enabling hhvm results in this issue?\n. I share the same opinion as the @10up guys. The WP Unit Tests are for testing WP core during core development. If you're not developing core, then it's unnecessary. There is no reason to use it for testing themes and plugins. For themes and plugins, you should mock the core components that are used by the theme/plugin.\n. Wildcard host is definitely the way to go. Otherwise a multisite network that allows public signups (such as wordpress.com) would not be possible.\nI don't see a simple option for developers on Windows, however. Windows hosts file does not allow wildcards. \n. There is no /etc/hosts on Windows (it's %SystemRoot%\\System32\\drivers\\etc\\hosts) so I'm guessing that would cause Vagrant to shit its pants. But I think you're on the right track.\n. While we doing this, I submit that we should rename all to common.\n. I'm still cool.\n... right?\n. :+1:\n. We should keep an eye on dis, esp if we still gon switch 2 debops.\nhttps://github.com/debops/ansible-pki/pull/33\n. @retlehs wp rewrite list --format=count might be easier to work with\nOr wp option get permalink_structure\n. :+1: \n. I modified this slightly from the initial commit. I moved the line to the top so that the environment variable is checked first. This is to allow users on any platform to set that variable as an easy means of automatically setting the number of CPUs used in their VMs.\n. This will probably break WordPress update functionality as well as the plugin installer in the admin panel. We should definitely test that, and if we do accept this, it should coincide with some documentation for how to change permissions to restore this WordPress functionality.\nIf WordPress core functionality breaks as I'm predicting, then I'm undecided on this PR. Part of me wants to follow security best practices of granting least privilege and establishing secure defaults. To that extent, I'm in favor of accepting this PR. But then there's a pragmatic argument to be made that naive developers/users might grant too many permissions to PHP or WordPress in an attempt to restore functionality. (For example, when WordPress can't update itself, it will prompt administrators to enter FTP credentials, which we probably don't want.) So we might consider making this more hardened approach opt-in instead of opt-out.\n. We did it! We made it to the future!. This is good for Windows users who use Ansible with Babun/Cygwin. By default, Cygwin includes curl but not dig. So yay!\n. @swalkinshaw why not just use https://github.com/wp-cli/wp-cli/releases ?\nhttps://github.com/wp-cli/wp-cli/releases/download/v0.20.4/wp-cli-0.20.4.phar\nhttps://github.com/wp-cli/wp-cli/releases/download/v0.21.1/wp-cli-0.21.1.phar\nhttps://github.com/wp-cli/wp-cli/releases/download/v0.21.0/wp-cli-0.21.0.phar\netc.\n. Please use https://discourse.roots.io/c/trellis for support questions. This issue tracker is for Trellis development.\n. @wassimdotis have you been following roots-example-project.com?\nIf so, then that would explain the issue you're having. We moved the Vagrantfile from the project root into the newly created trellis folder. So the parent directory of the Vagrantfile is now trellis, whereas before it was roots-example-project.com. \n. Intel or AMD?\n. Let me know if this is an issue with other providers too. I don't have any others to test.\nBut it's basically the same process for all of them.\nVMWare Workstation/Fusion\nvmw.vmx['displayName'] = config.vm.hostname\nParallels\nprl.name = config.vm.hostname\n. SSH forwarding on Windows was a pain in the ass for me as well.\nWith upcoming Vagrant 1.8, I'll be working on getting Trellis to not be as hostile toward Windows developers. SSH forwarding might not even be a problem at that point, but I haven't tested yet to be sure.\nIf you want to submit a PR with just the stuff you did to resolve SSH forwarding, or maybe open an issue with an overview of what you're doing to resolve it, that would probably be something worth considering for Trellis. If you don't feel like doing that, I'll do it this weekend when I test vagrant 1.8.\n. I got a chance to review this, and I don't really understand why the keys are being copied to the vagrant box. The whole point of SSH forwarding is to avoid having to copy keys to intermediate servers. The keys are made available throughout the SSH connection chain when forwarding is enabled.\nI put the following in my %USERPROFILE%\\.ssh\\config file and SSH forwarding works fine for me...\nHost *\n        ForwardAgent yes\nIf you want to be more explicit, you can set it on a per-host basis. Either way, this has worked for me; SSH forwarding works on my end, which brings me back to my first sentence: I don't really understand why the keys are being copied to the vagrant box.\nI'll leave this open for now in case there's something I'm missing.\n. I've added some docs for SSH forwarding to assist Windows users.\nhttps://roots.io/trellis/docs/windows/#ssh-forwarding\nI've tested all of the methods noted in the docs. They all work without having to copy any keys to the Vagrant guest.\nThis isn't as much of an issue for non-Windows users since the Ansible controller is the host machine, not the guest.\nI'm going to go ahead and close this for now. You're still free to let me know if there's something I'm missing and if we should revisit this PR.\n. Shouldn't use caching in dev.\n. According to that table you posted, it looks like you're using hhvm with homestead. Is that correct? And did you enable hhvm in trellis?\n. Homestead is using more aggressive compression. Look at transfer sizes.\nThat's probably the main difference.\n. This is working for me. :+1:\nvagrant@example:~$ php -v\nPHP 7.0.1-4+deb.sury.org~trusty+1 (cli) ( NTS )\nCopyright (c) 1997-2015 The PHP Group\nZend Engine v3.0.0, Copyright (c) 1998-2015 Zend Technologies\n    with Zend OPcache v7.0.6-dev, Copyright (c) 1999-2015, by Zend Technologies\n    with Xdebug v2.4.0RC3, Copyright (c) 2002-2015, by Derick Rethans\n. Does this work?: {{ lookup('pipe', 'dig +short myip.opendns.com @resolver1.opendns.com') }}\nThat's what we used to have, but some networks disallow UDP connections to external DNS servers, which caused it to fail.\nGive it a shot to see if it works for you.\nOtherwise, you can certainly use any of the others mentioned on the site you linked; this worked for me, for example: {{ lookup('pipe', 'curl -4 https://ipinfo.io/ip') }}.\nInstead of coding in a fallback, we could probably give users the ability specify their own external IP lookup mechanism. @fullyint @swalkinshaw thoughts?\n. This might have been what was going on in #434 as well.\nAs mentioned in that discussion, this worked for me: \n{{ lookup('pipe', 'curl -4 https://ipinfo.io/ip') }}\n\nYou are limited to 1,000 API requests per day.\n\nhttp://ipinfo.io/developers\n. Yeah, I think there are a few hangups for Windows users, though.  I'll revisit it and submit a PR when time permits (probably not until January). If someone else wants to tackle it before then, feel free. Just keep in mind that the trellis directory name can change, the Vagrantfile can be moved, and users can specify multiple site folders. (The first two we're aware of when in the Vagrantfile, but become less aware of inside the VM.)\nI'd really like to get @fullyint or @swalkinshaw to weigh in as well since they're our resident experts on all things related to Ansible. \nThere are also some issues with Windows that I still want to tackle in Trellis, but I'll wait until after this transition before I bring them up.\n. I personally think we should drop ansible provisioner and only use ansible_local. It's easier to maintain.\n. Oops. My bad. I did that. :flushed: \nI'll go ahead and merge this. Thanks for the PR.\n. :+1:\nI'd be in favor of completely switching to vagrant-hostmanger. It seems like vagrant-hostsupdater is dying a slow death.\n. Looks like we're gonna go ahead and switch off of vagrant-hostsupdater. See #443\n. Thanks @dblencowe!\n. Just tested it. It works.\n==> default: Checking for host entries\n==> default: Skipping adding host entries (config.vm.network hostsupdater: \"skip\" is set)\n. Yeah, exactly. vagrant-hostsupdater automatically updates hosts files regardless of whether your Vagrantfile explicitly tells it to. This PR opts out of it.\n. Just tested this. It works. :+1:\n. Thanks for this. A few people have had this issue with multisite and I think we were working on figuring out a way to resolve it. I'm kind of an idiot when it comes to Ansible, so I'll defer to @swalkinshaw to merge this PR. Just wanted to say thanks. :+1:\n. I'd love to see this as well since I'm a big fan of Laravel. But like you, I don't know enough about ansible. Have you looked into Laravel Homestead? That might hold you over until one of us can figure out Ansible well enough to write an ansible role for trellis. lol\n. You can use a single VM per project with Homestead too, just in case you didn't know that. (just search for \"per project installation\" on this page)\nNot that I'm trying to steer you away from Trellis. Just letting you know in case you need a solution to hold you over for now. If I wasn't so dumb with Ansible, I'd tell you how to get Laravel going with Trellis. ;o\n. @BrandonShutter did you add any extensions to php7? My list differs from yours.\n. hostsupdater: 'skip' was added because we switched to hostmanager. https://github.com/roots/trellis/pull/458\n. Oh cool. Just purchase .dev domain and point it at 192.168.x.x, avoid hosts file iirc :trollface: \n. You're free to use whatever TLD you want. We'll stick with .dev in our examples for now.. This isn't a Trellis issue. You should take this to the forums or report it upstream to the Vagrant guys if you think it's a bug with Vagrant. Regardless, it's not a bug on our end.\n. https://discourse.roots.io/c/trellis\n. Have you tested provisioning with mariadb and then provisioning the same server with percona, and vice versa? Should one be completely uninstalled before installing the other?. Should prob change the npm stuff to yarn too while we're at it.\nnpm install -> yarn\nnpm run xxxx -> yarn run xxxx. if those were environment variables (i.e., in .env), you could easily override by setting the env var before loading wp-cli since phpdotenv doesn't override existing environment variables.\nthen the user's directory structure wouldn't matter, but the user wouldn't be able to hard-code those values.\n:thinking: . Does this do anything that can't be done with our current nginx includes solution?. For those sites, they can modify it accordingly.\nThis would probably be good for most multisite installations.\nWe could put it behind a flag, something like enable_multisite_cron and have it true by default. Then when their site grows, they can switch it to false ezpz.. For those who were using this to populate production server with local data, check out this post and discussion instead:\n- post: https://roots.io/leveraging-wp-cli-aliases-in-your-wordpress-development-workflow/\n- discussion: https://discourse.roots.io/t/leveraging-wp-cli-aliases-in-your-wordpress-development-workflow/8414. This isn't actually necessary. Not saying I'm against it, but it's not required. I develop exclusively on Windows, and I've never had an issue with SSH forwarding, nor do I have to add anything to VM's local authentication agent.\nSee also: https://roots.io/trellis/docs/windows/#ssh-forwarding. It's not needed in the VM for Sage, regardless of the host machine.\nAlso, I don't think BrowserSync would work right from within the VM.. @swalkinshaw That doesn't completely avoid the issue with the config class throwing an error when it encounters a constant that's already defined. If a user defines WPMU_PLUGIN_DIR or WP_PLUGIN_DIR (or anything else defined in tmp_multisite_constants.php) within application.php using the config class, then it will similarly throw an error.. Doesn't this mean that deploy.sh won't execute now?\n. Comma isn't necessary here.. This shouldn't be a new bullet point. (replace asterisk * with space ). Shouldn't this be enabled on Windows now that it no longer relies on bash? \ud83e\udd14. %userprofile%/.ssh/config in windows parlance, where userprofile is an environment variable to the user's home directory. while not all versions of windows come with openssh (windows 10 comes with it since earlier this year), git requires ssh, and so most windows users who are using trellis will probably have openssh and this is a safe assumption in those cases. . Yeah, it follows the same format, but one thing that would concern is me is whether the path to the private key is in the windows (e.g., d:\\Sites\\example.com\\trellis\\etc...) or unix (e.g., /mnt/d/Sites/example.com/trellis/etc...) format. There's probably not an easy way to handle this, but I'm thinking we could rely on Ruby/Vagrant to figure it out.\nMy Ruby is terrible, but I can test whatever you wanna send me.. Shouldn't the . be escaped? blade\\.php? Or does it not matter?. ",
    "Alan01252": "Yes....\nWhat I've done here is frankly half a job of figuring out why this wasn't working!\nI'll close this pull request and have another crack at tidying it up properly tonight.\n. ",
    "MatthewMi11er": "@swalkinshaw if you haven't seen it already you should look into the Debops project. It has an excellent set of extremely thorough and well thought out Ansible roles for configuring a server. Personally, I would love to see bedrock integrated as an application into that stack.\n. @swalkinshaw It's a shame that's an issue. Dealing with licenses can be a pain. Anyway, keep up the good work on this.\n. ",
    "030": "@swalkinshaw Thank you. It is possible to execute chown now in the box. The problem we have now is that the user that runs vagrant is not set, but appstore. How could the be solved for all users?. ",
    "thiagodebastos": "Is this still supposed to be happening? I arrived here because I faced the same issue.\nEDIT this issue occurs when hhvm is set to true in group_vars - all\nhttps://discourse.roots.io/t/cannot-connect-to-database/3299/11\n. Ah thanks for that! It's that looming shadow over our heads :+1: \nI don't think any of us realise that a developer/designer is acually a modern cleaner, just in the digital world hehe. I think I do more cleaning things than I do designing. I keep hoping the ratio will drop with experience. \n. ",
    "iamra": "Similar issue here when changing the Development mysql_root_password: from devpw to non special character one (Just upper case lower case custom pass), however, reverting the file to the devpw password seemed to allow the provisioning correctly.\nThis is the error output on vagrant provision / up:\nTASK: [mariadb | Set root user password] ******** \nfailed: [default] => (item=dev) => {\"failed\": true, \"item\": \"dev\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=127.0.0.1) => {\"failed\": true, \"item\": \"127.0.0.1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=::1) => {\"failed\": true, \"item\": \"::1\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nfailed: [default] => (item=localhost) => {\"failed\": true, \"item\": \"localhost\"}\nmsg: unable to connect to database, check login_user and login_password are correct or ~/.my.cnf has the credentials\nFATAL: all hosts have already failed -- aborting\n. Scott, spot on, sorry I missed this, as I thought my installation was pulling from the ansible ppa, looks like it was not and instead I am installed off the OS repo (v1.7.2). Thanks for your time brother. And thank you for creating such a wonderful software!\n. ",
    "louim": "I just wanted to chime in, I just helped one of my coworker with this problem. It happens because the base box already have a password. I believe the temporary fix would be to hide mysql_root_password  option from the development config, as someone seeing this setting may try to change it seeing it exposed.\n. Reading trough HHVM issues, I came across: facebook/hhvm#4398. I'm not currently using HHVM, but I'm looking into it for performance reason. Do you think such mechanism (reloading HHVM automatically when memory usage is high or juste in the middle of the night) should be added? Maybe just a comment in the readme or an option to enable it?\nThoughts? \n. :+1: for the nightly cronjob.\n. @swalkinshaw Excellent, do you plan to merge this into the project soon?\n. @enricodeleo I just set-up a bedrock-ansible using the HHVM option, and I have the same problem as you for the uploads. The owner of the the folder is : deploy www-data but the permissions are 755instead of 775 so the webserver (nginx) can't write to the folders.\nps aux | egrep nginx give me : \nubuntu   12614  0.0  0.0   8160   916 pts/2    S+   16:39   0:00 egrep --color=auto nginx\nroot     15906  0.0  0.1  91256  2856 ?        Ss   Mar27   0:00 nginx: master process /usr/sbin/nginx\nwww-data 28052  0.0  0.3  94576  6272 ?        S    Mar30   0:02 nginx: worker process\nwww-data 28053  0.0  0.3  94576  6280 ?        S    Mar30   0:04 nginx: worker process\nFor your second problem (the bad gateway and HHVM), I didn't experience that. Did you check the logs for any info that might be useful? Did you try to restart HHVM and NGINX manually before switching to a tcp socket? \nI wonder if that has hanything to do with HHVM at all. Since I'm doing a talk about Bedrock this evening, I going to experiment this afternoon with clean installs with HHVM and PHP-FPM. I'll report back. @swalkinshaw, what the permissions should be on the folders? \n. I believe this can be closed :smile: \n. @CFXd would you be interested doing a pull request? This should be easy to fix. \n. @fabianhenzler That's not the same problem.\nThere was a change made to Trellis: https://github.com/roots/trellis/pull/239 to allow users to change the root password after a first provisioning. If you provisioned your server before the change was merged, and you juste rebased you code to the latest Trellis version, you will need to do: https://github.com/roots/trellis/pull/239#issuecomment-133954971\nNote that you only need to do this one time, after the provisioning complete correctly, you can remove the two lines and it will work correctly from now on. You shouldn't encounter this problem on newly provisioned server, because the .my.cnf will be created from the start.\n. Yeah, this is not to change the password. The two line temporary fix is to migrate to the new way of storing the root MySQL password. \n. @nathanielks I tried rebooting the instance, but alas, that didn't clear the iptable rules. @swalkinshaw Since the instance is locked (SSH key access only), the web console trick didn't work. I ended up rebuilding the instance.\nSo, what would be the best option? Maybe remove the option from the allfile, and keep it documented so people changing this parameter will really know what they're doing?\n. @swalkinshaw it's indeed the case. Since this is one of the more important rule (allowing SSH connection), and it normally default to false, I made pull request #211 to remove the option.\n. I think this can be closed, as Ferm is already well documented in it's role folder and #211 has been merged.\n. @fullyint I agree that the question seems a little more forum oriented, however, I believe it has its place here, to keep track of how to improve the documentation. I think that settings like these should be documented, so people can use the project without having to dig in the roles. I'll gladly create a wiki page or a pull request to the main readme to document those things. Which one is the perferred way?\nSpeaking of the branch setting, I think that the branch variable would be more appropriate as project.branch so it could be set site by site in the config, and it  would be less confusing. I believe most of the use case involve setting a specific branch per environment, instead of specifying it at deploy time.\n. Pull request opened. While we are discussing documentation, I would like to discuss something: The wiki. Personnally, I find the information it contain really great, but I prefer having that information right in the project. This has three main advantages:\n- All the documentation is kept with the project, so once you have cloned, you have all you need in the repo without the need to go to github to find something.\n- When you fork the project, you donc get the wiki. So If I want to fork Bedrock-Ansible, all the information follows the project without having to copy the wiki or to refer to the original one.\n- Having the information in the project makes it more up to date and keeps it in sync with the code, since when you add a new feature / modify something you dont have to go to a separate place to document.\nI think the wiki is best suited to complementary information, tips and tricks, examples and general informations. The core documentation should stay with the project. A readme in the related role (for example the Fail2ban readme), referenced from the main readme so you can easily navigate in the documentation would be the best I think. \n. @swalkinshaw do you mean in the config files (explicitly) or in the deploy role (implicitly)? What about develop then?\n. That's fine by me, I think it will be more obvious to people if it's written in the config when they start a new project. Do you want me to update the pull request?\n. Done!\n. Hold on, Ill squash those commits together.\n. you are right, I juste checked a site deployed. I have the nested vendor as well. I get one \"nest\" for each deploy, More than 75 in my case. Last commit I have from Trellis is 5f97284dff3079563f5dcd811b9f27611a627135. \n. My bad, I assumed there was a default set somewhere in the role. I plan on submitting a PR to make the mysql role idempotent. \n. I have this working from another project, but our use case is different. When more than one dev work on the same site, we use a remote database (usually the staging database). We allow remote access and we use the database with the local Vagrant setup.\nit allow to pass a list of host to open the database to. ex:\ndb_allowed_hosts:\n  - localhost\n  - \"123.123.123.123\"\n  - \"%\"\nit is database dependant, so I think it is more elegant and allow finer grained control if you have many sites on the same server. I could prepare a pull request if it is something that you might consider adding. My intention was to release it as a Galaxy playbook like I did with https://galaxy.ansible.com/list#/roles/3714, but I haven't checked if that's actually doable.\n. It appear from your error that you are running Ansible 2.0. I believe it is still in development. The preferred way to install Ansible assuming you are on a Mac is via Pip: http://docs.ansible.com/intro_installation.html#latest-releases-via-pip\ni also think the latest stable release still has a bug in it #205 so I recommend installing 1.9.0.1\nsudo pip install ansible=1.9.0.1 should do the trick. Check if you still have the error after.\n. @swalkinshaw thanks for the comments, I updated the PR to fix what you mentioned. Just to follow up on you answers:\n1. It would actually be easy to add as per site if that's what you think is best. Juste need to add a key in the config dict to turn it on, and tweak the global condition for the nginx.conf\n2. I would too prefer /var/run for performances reason. But I tested it and no folder are persisted in /var/run. Most Deamon create their own folders when starting. See http://askubuntu.com/questions/303120/how-folders-created-in-var-run-on-each-reboot. The solution would imply having the directory creation added to the init script. As you mentioned, the size is also an issue. For small VPS with 1GB RAM, this could be an issue as the cache will be really small.\n3. 250MB would be good I think. HTML doesn't really take much space.\n4. I actually pondered about it and I think it should not be enabled by default. Even if the cache is only a small period of time, It can make people not aware of it wonder why their modifications don't appear right away. Best leave the choice to the user to knowingly enable it.\n5. :+1: \n. @swalkinshaw I made the config site specific. It required me to move the location ~ \\.php$ block from the generic include to the site-specific file since I the content now change depending of the sites.\nSettings can be used like : \nyml\n...\nssl:\n  enabled: false\ncache:\n  enabled: true\n  duration: 30s\n  skip_cache_uri: \"some string here\"\n  skip_cache_cookie: \"some other string here\"\nsystem_cron: true\n...\nAll params will take the default global value when not specifically defined in a site. I also added fastcgi_cache_lock on; so only one request hit the backend when generating a new cache.\nJust let me know if everything looks good to you, and Ill write the documentation and squash my commits. \nAs a side note, If we one day decide to compile NGINX from source (saw that mentioned in #235), it would be interesting to compile it with https://github.com/FRiCKLE/ngx_cache_purge, so the setup can be used with longer cache time. This would allow people to use plugin like https://wordpress.org/plugins/nginx-helper/ to purge their cache from the wordpress admin.\n. @swalkinshaw I'm unable to edit / create new page to the wiki. Would you mind opening the wiki for public edit or adding me as a collaborator so I can edit it?\n. @swalkinshaw Updated the wiki and the readme, rebased against the current master. Should be good to go! :+1: \n. mysql_user as it was implemented wasn't working because it was referenced in the Set root user password task of the MariaDB playbook. The task will fail if the value of mysql_user is not root. I think creating mysql_use_remote and completely skipping the playbook when set to true would be the best solution.\nI see your point. But it has the major flaw of only allowing you to set the password once. It will work the first time because of the check_implicit_admin. Any change after that will fail because it will try to log in as root with the new password that you want to set, instead of the old one that you want to replace. \nI also think that a file with 600permission in the root home is pretty safe. It seems like this the standard procedure for doing it.\nI will fix a couple of things tomorrow, including the remote database access. :+1: \n. I had a look during the weekend, and there are a couple of things that need need to be fixed, before the remote user work. Currently when the MySQL users are created, they are created only with localhost, and not remote ip access. It means that the web server wouln't be able to connect to the database server (RDS for example). Ill have a look this week. \n@swalkinshaw do you have a preference on how should I go about that? Wildcard the host to '%', grab the webserver IP or allow user to set the list themselves?\n. @swalkinshaw #260 didn't really fix the underlying problem that currently the root mysql password cannot be changed once set for the first time.\nAs I explained in #237, this caused problem on the Vagrant environment due to the already provisioned role, but it also affected staging and production. #260 fixed the first provisioning of the password, but not the subsequent ones. \nYou can try it for yourself by provisioning locally, then changing mysql_root_password and trying to provision again. \n. @swalkinshaw Like you said, I opted for the simple route. When mysql_enable_remote is true, user and database creation will not occur (globally, not at site level). MariaDB role will not be run.\nIf running for the first time with an already provisioned VM / Server, it will fail because no ~/.my.cnf will be found for the root user. Solution is to create one manually, or just destroy the VM and recreate it. \nIf provisioning a brand new server, it will work correctly from the start without the need to create the file manually.\n. @swalkinshaw rebased against current master, renamed the variable and squashed. \n. @BrandonShutter Mysql is not needed for Remote connection. This is handled by the mysqli (or PDO) php extension. Note that when using mysql_remote_database, the remote database / users wont be created. It's left to the user to configure his remote instance.\n. You have my blessing :+1: \n. How would you provide such files to be loaded?\n. I'm thinking a task that would grab the content of the files/includes.d/[site]/* and copy it to the machine. It would be the users responsibility to name the folder the same way that the site key for it to be picked. It should be pretty easy to do in Ansible. Or maybe the same way the SSL file are loaded, and leave the option to the user? \nI prefer option one.\n. You are right, there is no way to currently do that. For the files, you could go with the synchronize module, but that wouldn't work for the templates. You cloud try with with_pipe. Something like (untested):\nyml\n- template: src=\"{{ item }}\" dest=\"/etc/nginx/includes.d/{{ item }}\"\n  with_pipe: find ../templates/includes/ -type f\nIf that works, I would find that more easy to understand than the regex, but that may be just a personal preference. :wink: \n. Shouldn't this just be added as a dev dependency of the project you want to run test on? I may be wrong since I never used phpunit. I would do it like this: composer require-dev \"phpunit/phpunit=4.7.*\". What is the benefit of installing it globally?\n. @getdave it should be set globally. On Ubuntu the recommended file to set global environment variable is /etc/environment. More info here: https://help.ubuntu.com/community/EnvironmentVariables#System-wide_environment_variables. Be aware that it is not a script file, so you would have to print the whole path in here to append the vendor bin path. (You can't use $PATH in this file). \nAnother alternative even if it's not suggested as the best way to do it would be to use the /etc/bash.bashrc which allow variable expansion. \n. Yeah, it's really recent: https://blog.cloudflare.com/logjam-the-latest-tls-vulnerability-explained/\n. PR is up: #253 \n. I see your point. I wasn't aware a condition like that worked. It must be because I have an SSD, or maybe that I just don't check the vagrant when it is building, that I never noticed it take much time. \nOut of curiosity, how many time does generating the group take on your machine?\n. @swalkinshaw that would be the better option I think. \n. Testing:\ndevelopment.yml\ntrue_text: true\nfalse_text: false\ntrue_numeric: 1\nfalse_numeric: 0\nGive me (.env):\nFALSE_TEXT=False\nTRUE_TEXT=True\nTRUE_NUMERIC=1\nFALSE_NUMERIC=0\nWhich are loaded in PHP (var_dumping) with dotenv 1.x:\nstring(4) \"True\"\nstring(5) \"False\"\nstring(1) \"1\"\nstring(0) \"\"\nWith dotenv 2.x\nstring(4) \"True\"\nstring(5) \"False\"\nstring(1) \"1\"\nstring(1) \"0\"\nI don't see problem on my end with the way the variable are loaded, unless I'm mistaken. But I think I will prepare a PR for Bedrock to use Dotenv v2.\nAnsible version:\nansible 1.9.0.1\n  configured module search path = None\n. Such deploy mechanism is already implemented in bedrock-ansible (Trellis) using https://github.com/f500/ansible-project_deploy. It provides roughly the same functionalities. \n. I feel like this would be nice as an Ansible Galaxy role that could just be added to the projet if one need to develop plugin or add test unit to his project. However, I believe it is a little bit too \"opinionated\" to fit in the standard bedrock-ansible use case. I would just set the path in bedrock-ansible like discussed in #251 and move the rest of the code to an Ansible Galaxy role. I did the same with https://github.com/louim/bedrock-site-protect \nMy 2 cents.\n. I created a Wiki page https://github.com/roots/trellis/wiki/User-contributed-extensions so people that developed extensions could list them here. Maybe we could put a link in the readme to that page. \n. @kalenjohnson Not exactly, it just evaluate as the full path to the folder where the Vagrantfile is. This doesn't change the current way this works. It just make it work correctly with Vagrant global commands. To do what you are trying to do you just have to use: vagrant global-status to get the id of the VM and you can run vagrant (up | provision | halt | whathever) your_vm_id from any folder.\n. Oh, my bad, you are totally right, I hadn't see that the vagrantfile was out of the bedrock-ansible directory. Then yes it work like you mentioned. \n. I had more time to poke around with the regex. Updated so it doesn't require keeping the full path in the role.\n. @swalkinshaw done!\n. I agree this is a strange behaviour, but I think it's made that way because the file is synced between the bedrock folder on the vagrant machine and the code folder locally. \nI think we should put a comment in the .env file telling users to only change it via the development file.  and overwrite it on each provision. \n. Woops, that's my fix.\n@kalenjohnson you have pioneered most of the windows compatibility, is there a reason the Ansible need to use ANSIBLE_PATH inside the VM? \n. I had a look at what could be done to fix this, while retaining the feature of finding the provisioning folder when it is nested.\nCompletely remove the sh.args parameter from the Vagrantfile.\nReplace line https://github.com/roots/trellis/blob/master/windows.sh#L8 with:\nANSIBLE_PATH=\"$(find -name 'windows.sh' -printf '%h' -quit)\"\nThis will look up the tree and find the windows.sh file. it will then assign the parent folder path to the ANSIBLE_PATH variable. The -quit parameter is to stop the lookup after a match has been found.\nI  don't have a windows machine handy to test it at the moment, @bezko, would you be interested testing   ?\n. Ahah yeah I think you are right! English is not my primary language :grin: \n. Why is the .env file created in /tmp instead of being copied directly? It seems to have been done with the Windows compatibility patch: https://github.com/fullyint/bedrock-ansible/commit/3d328563858518e75ee0ce60c6f34237f0c5bae0#diff-6dbc78b8392771e0501227e09777c762L6\n@kalenjohnson do you remember what was the rationale behind this change?\n. Wow, thanks, I didn't know that!\n. :+1: \n. :clap:\nAs a side note I think well need to have some kind of server spec testing soon because it's hard to \"evaluate\" a PR like this without testing it on a real environment. \n. @fullyint will the DNS resolver work from inside the VM when run from windows user? \nAlso just a friendly tip, please don't rebase your pull request until it is fully ready, it makes it harder to see the incremental changes you talk about. :)\n. Also, is the point about SSH forwarding really needed in the readme? I never had problems with it since the ansible.cfg already enable agent forwarding. I find the doc hard to understand for people who don't have a lot of knowledge with SSH. \nWould it be enough to just mention that users shouldn't forget to load their SSH key(s) in the ssh agent with ssh-add? (And maybe add the link to the wiki)\n. @swalkinshaw if you want to have SSH forwarding enabled when manually ssh-ing to the destination server, then yes you need to have ssh-config file specifying ForwardAgent yes or you can do it manually each connection by adding -o ForwardAgent=yes to ssh command. \nBut all SSH connexion handled by Ansible (including all playbook run and the deploy process) do not need  additional configuration other than what's already in ansible.cfg. You still need to load your SSH key in the ssh-agent if you haven't already done so. This could be automated / validated in the deploy.sh script.\nFor windows users, i don't know if your key is forwarded when using vagrant ssh to run the ansible commands. \n. @fullyint \nSSH agent forwarding. I think that the part: \n\nMac OS X users must have added their SSH key password to Keychain by running /usr/bin/ssh-add -K /path/to/private/key\n\nis still oddly specific. What if you don't use a key with a password?  Why Mac OS X users only (and not Linux)? Why /usr/bin/ssh-add instead of ssh-add? In fact, ssh-add -K would suffice unless using a custom named SSH key.\nI think that we could also prevent most of the problem with custom error messages. Like we could use git ls-remote to validate we are able to connect to the specified remote, and if not the case, print a helpful error message and bail out.\nSomething like:\n\n\"We were unable to connect to the specified git repo (git repo url here) from your server. Double check that the SSH key you use normally is correctly loaded in the ssh agent by using the command ssh-add -L. If you don't see your key, add it by running ssh-add. For more info, check the Trellis wiki at: https://github.com/roots/trellis/wiki/SSH-Keys\"\n\nIP lookup on Windows.: I'll try to check out on my windows machine tonight. \n. @fullyint Tested it on Windows and the DNS resolved correctly :+1: \n. Plus plus one for this! As @mAAdhaTTah said, self-signed might be a better name.\nI'm currently using this snippet, and committing the fake certs to the repo under files/example.com/\n```\nThis command will generate a new self-signed certificate and a new private key.\nSimply create a folder with the required domain name and run this command inside it.\nFor example, running this command inside an \"example.com\" folder would create an \"example.com\" self-signed certificate.\nopenssl req -subj \"/C=CA/ST=Quebec/L=Quebec/O=O2 Web/OU=DevOps/CN=${PWD##/}\" -new -newkey rsa:2048 -days 365 -nodes -x509 -sha256 -keyout ${PWD##/}.key -out ${PWD##*/}.crt\n```\nAutomating this with ssl-cert would be awesome. :+1: \n. @austinpray I think going with your solution (ssl-cert) would be better. Mine is a one liner if you want to generate them yourself, but having them installed and already ready to use without committing them would be the best I think. It will allow to easily toggle on and off without additional config which is a big plus IMHO.\nI would make it so that when you turn ssl on in the config bit don't pass a cert / key option, the snake-oil is used. \n. I just tested it locally. It's kinda working with ssl-cert. Problem is that it trie to guess the domain based on the hostname -f command. So it's bound to errors. also it would need to be regenerated if the hostname is changed. I'll do it manually with openssl. PR incoming.\n. @austinpray sure ahah, I just pasted the snippet litterally like I use it, I'll make it more agnostic :smile:\n. @swalkinshaw I don't know if it's really needed. Because the certificate is self signed, it will always show as not valid in browsers. So I don't think it would add much to include the other domains. I think it's more to help debug the https problems in the code like assets being loaded on http or other commons problems than to provide real security (because the certs are self-signed anyway). \n. Thanks for test @austinpray! I know what the problem is, I'll fix it asap. :smile: \n. @austinpray if you want to try it again, the errors should be fixed!\n. @swalkinshaw squashed and ready to go.\n. @austinpray This is really weird, I have staging sites protected by self-signed certs with Trellis currently and I dont get the warning. \nI think it's because roots.io is in the hsts preload list. \n. @swalkinshaw ansible_version looks like this:\n\"ansible_version\": {\n            \"full\": \"1.9.2\",\n            \"major\": 1,\n            \"minor\": 9,\n            \"revision\": 2,\n            \"string\": \"1.9.2\\n  configured module search path = /usr/share/ansible\"\n        }\nWe could search the string for things like \"devel\" or \"beta\", but that's sketchy at best. I don't think there is a surefire way of detecting beta currenty.\n. @swalkinshaw you are right, I was thinking that those task were required to be run for windows users, but all that is required for Ansible to run is installed in the windows.sh.\n. If like me you where intrigued how they did get this to work, they actually allow connection as the root user. They just execute the command and then close the connection. This is the content of the /root/.ssh/authorized_keys:\nno-port-forwarding,no-agent-forwarding,no-X11-forwarding,command=\"echo 'Please login as the user \\\"ec2-user\\\" rather than the user \\\"root\\\".';echo;sleep 10\" ssh-rsa AAAA<more public key content>EAhdTX AWS\n. Totally in for this! @nathanielks, as @fullyint said, the main benefit is that it will be easy to write cross environment scripts, like database and file sync as we were able to do with capistranowp-cli. Even this alone is enough to warrant the change IMO. Other benefits include shortened ansible-playbook command, the possibility of using options like -vvvv without having to change the vagrantfile, and running specific roles (via --tags) on the VM. \n@fullyint have you looked into http://docs.vagrantup.com/v2/provisioning/ansible.html, specifically the Static Inventory section? If it work (I think we will lose the ansible_ssh_port dynamic feature), it would allow to use only one inventory file, because with 2 inventory file, we are still unable to run playbook from live environment to the VM.\nIf it's impossible to have only one inventory file, would go for the symlink. Git supports it without problem, and I can't imagine an OS where symlinks wouldn't work. I would name the files local and remote in that case. However, I think it doesn't do much more than the original 3 separates inventory files.\n. I checked a couple of things to better understand what you wanted to do @fullyint. Here are my opinion (after research).\nThings I like in this:\n- Using the host directory and putting in inside the ansible.cfg\n- The possibility of running cross environments playbooks (more on that later)\n- refactor the host grouping\nThings i would leave like they are:\n- Keeping one file per environment. I think it makes it easier to understand and more structured.\nI tested the symlink locally. The concept work, but other files will need tweaking to make it functional.\nIn the remote-user role, inventory_hostname is used. This will fail currently because the VM has the inventory hostname of default. see below for result of the command:\n```\nansible-playbook server.yml -i hosts/development -v                                                                                                     \u23ce master \u2731\nPLAY [Determine Remote User] ********\nTASK: [remote-user | Determine whether to connect as root or admin_user] **\nok: [default -> 127.0.0.1] => {\"changed\": false, \"cmd\": \"ssh -o PasswordAuthentication=no root@default \\\"echo root\\\" || echo admin\", \"delta\": \"0:00:00.011059\", \"end\": \"2015-08-04 00:46:52.094944\", \"rc\": 0, \"start\": \"2015-08-04 00:46:52.083885\", \"stderr\": \"ssh: Could not resolve hostname default: nodename nor servname provided, or not known\", \"stdout\": \"admin\", \"stdout_lines\": [\"admin\"], \"warnings\": []}\nTASK: [remote-user | Set remote user for each host] *****\nok: [default] => {\"ansible_facts\": {\"ansible_ssh_user\": \"admin\"}}\nPLAY [WordPress Server - Install LEMP Stack with PHP 5.6 and MariaDB MySQL] ***\nGATHERING FACTS *********\nfatal: [default] => SSH Error: Permission denied (publickey).\n    while connecting to 127.0.0.1:2222\nIt is sometimes useful to re-run the command using -vvvv, which prints SSH debug output to help diagnose the issue.\nTASK: [common | Validate Ansible version] *******\nFATAL: no hosts matched or all hosts have already failed -- aborting\nPLAY RECAP **********\n           to retry, use: --limit @/Users/louim/server.retry\ndefault                    : ok=2    changed=0    unreachable=1    failed=0\n```\nadmin_user: vagrant should also be set in the development file and the ansible.group set correctly to  to make this work. (the example below is using the current syntax).\ndiff\n       ansible.playbook = File.join(ANSIBLE_PATH, 'dev.yml')\n       ansible.groups = {\n         'web' => ['default'],\n-        'development' => ['default']\n+        'development:children' => ['web']\n       }\n@fullyint check https://github.com/louim/bedrock-ansible/commit/4b4ff3365b254eaa941c37febf3fbc673f8b5c51 to see what I had to change. Still needed to implement is the groups refactor that will be needed to use a host folder.\n. I'm not quite sure how someone without a key would use trellis, but in my opinion, I think having the user key set by default is a good option. I'm also wondering why it would be harder to override?\nI would rather see:\n\"{{ lookup('file', '~/.ssh/id_rsa.pub') | default(omit) }}\" than having the key commented out. \n. Seems like if would be feasible using vagrant-hostmanager instead of vagrant-hostupdater.\nchanging the line referencing the ip in the Vagrantfile to : \nconfig.vm.network \"private_network\", type: \"dhcp\"\nand implementing this in the Vagrantfile:\ncached_addresses = {}\nconfig.hostmanager.ip_resolver = proc do |vm, resolving_vm|\n  if cached_addresses[vm.name].nil?\n    if hostname = (vm.ssh_info && vm.ssh_info[:host])\n      vm.communicate.execute(\"/sbin/ifconfig eth0 | grep 'inet addr' | tail -n 1 | egrep -o '[0-9\\.]+' | head -n 1 2>&1\") do |type, contents|\n        cached_addresses[vm.name] = contents.split(\"\\n\").first[/(\\d+\\.\\d+\\.\\d+\\.\\d+)/, 1]\n      end\n    end\n  end\n  cached_addresses[vm.name]\nend\nThis is stolen from: https://github.com/smdahlen/vagrant-hostmanager/issues/86. I haven't tested, so you may need to fiddle a bit with this to get it working. \nPull request is appreciated if you get it working! :smile: \n. @evanfuture vagrant-hostupdater doesn't seems to be maintained anymore (last commit is from 31 Oct 2013). I think it's all for the best to switch to hostmanager.\n. This is because the command is run in one \"pass\" over each vagrant environments, so the first definition of ANSIBLE_PATH is kept for the whole run. \nChanging it to a variable instead of a constant would work only if vagrant global-status --prune does not run in parallel, because it doesn't seems that vagrantfile are scoped. \n. Looking more into this, it seems the issue is upstream: https://github.com/mitchellh/vagrant/issues/5253. Current milestone is set to Vagrant 1.8\n. Better option should be to use Mailhog in the development environment by default to catch all mails.\n. In fact Mailhog is directly inspired from mailcatcher and do the same work, but being in Go, it is self contained, and doesn't need Ruby to be run. It provides binary for all platforms https://github.com/mailhog/MailHog/releases\n. Note that it's actually gonna be fixed in ansible core module soon https://github.com/ansible/ansible-modules-core/pull/721. I would prefer a task that just run git remote set-url origin {{the_specified_url}} before running the git module, but your solution work as well until it is patched in core. \n. Thanks to the speedy merge on the Mailhog Ansible role, the PR is now updated and ready to go. I added some information on the readme about how to access Mailhog in development. Feel free to find better wording to explain it! :+1: \n. @swalkinshaw done!\n. That is an excellent Idea. Moreover, project_deploy_module got a refactor and it got renamed to project_deploy: https://github.com/f500/ansible-project_deploy. They now include hook like you propose. With a little refactor we could use theses. \nQuick example from the docs: project_deploy_hook_on_perform_build: \"{{ playbook_dir }}/deploy_hooks/perform-build.yml\"\n. @fabianhenzler try to vagrant ssh in the VM, and try to see if you can reach it from there. Also, questions like that are better fit for the forum: https://discourse.roots.io/ :wink: \n. I think we want the strip_www to act like a toggle, either forcing no www or forcing the www. I don't think we want to redirect from https to http. The bold N are the case we would like to work.\n|  | http:// | https:// | http://www | https://www |\n| --- | --- | --- | --- | --- |\n| http:// | - | Y | N | N |\n| https:// | N - by design | - | N   - by design | N |\n| http://www | Y | Y | - | Y |\n| https://www | N - by design | Y | N - by design | - |\n. I still think we should be pushing our users towards HTTPS, and not allow the opposite. With https://letsencrypt.org/ around the corner, I think offering to downgrade connexions is not a good idea. \nAlso, you would still need a Certificate to listen on the HTTPS port, because the redirect kick in only after the connexion is established. So it's a bad idea IMHO.\n. > -rw-r----- 1 web  www-data         0 Aug 23 06:45 error.log\nThis one is matching. When the rotation occur, the new log are set correctly. Seem's like the initial log doesn't have the right owner / permissions\n. Seen this before. I believe it is due to how Nginx rewrite are made. Changing the Wordpress permalink setting to \"post\" make it work correctly.\n. @kalenjohnson I don't believe it makes a difference, or maybe the wp-cli has some hack to install without using the install method of WordPress? This is the function used to check if permalinks can be enabled: https://developer.wordpress.org/reference/functions/wp_install_maybe_enable_pretty_permalinks/\n. @swalkinshaw, looks great to me, it will really help making the deploy process more customizable (and easier to maintain). :+1:\n. I like this! \n. I'm not familiar with jetpack, but to me it looks like some kind of error, cookie should never contain that much data, and it seems like something wrong is going on there. This is like 50 cookies mostly relating to error messages. I don't know if that's the normal way jetpack operate, but it so, something in jetpack is fundamentally flawed. \n. The cleanest way is to create your own Ansible-Galaxy role with the tasks you want to run, and add it to the requirements.yml and to the server.yml and /or the dev.yml playbooks. \nSee for example this role that I made to add htpasswd protection to sites. \n. :+1: :heart_eyes: \n. I think the point is to allow Ansible to setup the ACME client, which will take care of the auto-renewal by itself. \nFWIW, I don't think the WordPress plugin will ever work, because it would need to have elevated access (aka Root) to be able to edit Nginx configuration.\n. :tada: :+1: \nThis will be much cleaner!\n. Don't forget that the default cron is set to run each 15 minutes. So there may be a delay of up to 15 minutes after the time you set you post to be published before it actually is processed. \n. Haven't tried, but can't we call php directly without making an http request?\nSomething like \n*/15 * * * * php /srv/website/current/web/wp/wp-cron.php\n. @erikbelusic No need to delete.\nAssuming you named the upstream (this remote) upstream:\ngit fetch --all\ngit reset --hard upstream/master\ngit push -f\n. The services are reloaded / restarted when related tasks are run by ansible. You can sometime get the problem you described if the nginx and php-fpm tasks run correctly, but the provisioning fail on a subsequent task. Because the provisioning failed, the handlers aren't run. \nOn subsequent run, since the task were already ok, ansible see them as already done, and it doesn't call the handler. \nIf that was your case, you can always SSH like you did, or you can just vagrant reload to restart the machine, which will have the same effect. \n. Good for me.  The lower filter work correctly even when the are numbers?\n. Unless I'm mistaken, those functionalities are already disabled because we disable filemod in bedrock. \n. But thinking about it, it will break the many plugins that write elsewhere than the upload folder. I don't know if it's a good idea\u2026\n. It could also be implemented as a boolean, disabled by default. Calling it harden or something like that. People who who want the most secure environment and know they won't install plugins that needs write permissions outside the uploads folder could enable it. Like the cache setting which isn't on by default, because it may not fit for everyone. \n. What galaxy_roles value do you get? Maybe include config_file just to compare.\nYou can print it directly by doing puts galaxy_roles\n. Oh I get it now. Since those roles are installed in the VM on windows, They are not present when the VM is started, hence the fail.\n@austinpray we could make the check conditional to the platform, and add a similar check in the window.sh file.\n. @austinpray true, I forgot collaborators can create branch directly on the main repo :sweat_smile: \n. @austinpray yeah I know, but then it's hard to keep track on the main repo.\n. @austinpray it was done in https://github.com/roots/trellis/pull/259 to use phpunit and al. Best solution would be to just add it to the users .bashrc. Or maybe to enable it only on development?\n. @mAAdhaTTah Composer scripts do not need the ./vendor/bin to be in the path to work. This is just a convenience method so the user doesn't have to do ./vendor/bin phpunit and can just use phpunit. \n. @starise, it wouldn't be possible to really do it on the system level for multisite. The reason being that the sites creation is dynamic, and not tied to the deploy process. Once multisite is setup, you can create as much site as you want in the admin panel without ever deploying again if you wish. \nThe list of cron to run would need to be dynamic and updated on each site creation. Your best bet in that case is to create a mu-plugin that will query the database for all multisite domain and will curl them from the script. You would then refer to this single script in your cronjob. \n. Yeah one problem with this is that it will only use the most recent deployer's ip. (Each deployment would overwrite the ip). Not ideal for organization I think. \n. @mAAdhaTTah it's in the config files. There nothing preventing your to edit the file to make the rule like so:\n- type: dport_accept\n    dport: [ssh]\n    saddr: [\"my.first.dev.ip\", \"my.second.dev.ip\", \"my.third.dev.ip\"]\nit wouldn't be easily feasible to generate this list dynamically, because of the way the role is made.\n. Check the readme:\nexample.com/    - Primary folder for the project\n\u251c\u2500\u2500 trellis/    - Your clone of repository\n\u2514\u2500\u2500 site/       - A Bedrock-based site (suggested to name this the generic `site` since your project name is already at the top level)\nlocal_path needs to point to the Bedrock folder. If you cloned this repo as is, your local Ansible root is this repo folder. To navigate from this folder to your Bedrock folder, that would be ../site assuming you have named your Bedrock clone folder: site and you have them in the same containing folder as per the example in the readme. \n. Any particular reason why we would want these options to be configurable vs enforcing them as sane defaults?\n. :+1:\n. This would require switching from the Stable PPA to the Mainline PPA. (I'm not against it at all, just need  to remember this when we do the switch).\nAlso note that HTTP/2 require TLS to be taken advantage of. Else the connection will be downgraded. (the spec \"support\" HTTP/2 unencrypted, but no browser or web server implementation have made it work without TLS).\nhttps://www.nginx.com/blog/nginx-1-9-5/\n. Probably should be done there too? https://github.com/roots/trellis/blob/b3f322b5a22735f0c654c9ff5e7b7ae0f0f478b9/group_vars/all/security.yml#L7\n. @swalkinshaw I forgot you don't get a notification when something is pushed. :sweat_smile: I moved the documentation up. Let me know if this is good to go!\n. http://jinja.pocoo.org/docs/dev/templates/#dictsort\nIt wont keep the original declaration order, but it will sort them alphabetically by key. Unless there is something that I'm missing, this wouldn't really help your case (except if your variables are named alphabetically).\n. This is being worked on: https://github.com/roots/trellis/pull/317\n. @austinpray You are totally right, in fact it is not even used as Nginx default cached method are only GET and HEAD. http://nginx.org/en/docs/http/ngx_http_fastcgi_module.html#fastcgi_cache_methods\nI updated accordingly.\n. Sadly, that wouldn't work, this file is not evaluated, so variables are not expanded. I'll refine the regex so it just add at the end of the string instead of rewriting whole. \n. You could also do the same with initctl list | grep -Fq 'hhvm' or php5-fpm, which will return the status of the service (and its state). I think its a little bit cleaner too.\n. As it is right now, the task will always be marked as changed, and will alway update the remote url, even if it hasn't changed. Something like this would prevent that and would only update the url if the project has already been created and the remote changed:\n```\n- name: Check if project folder exists\n  stat: path={{ project_source_path }}\n  register: git_project_path\n\n\nname: Get remote URL\n  cmd: git config --get remote.origin.url \n  args:\n    chdir: {{ project_source_path }}\n  register: remote_origin_url\n  when: git_project_path.stat.exists\n\n\nname: Update git remote URL\n  cmd: git remote set-url origin {{ project_git_repo }}\n  args:\n    chdir: {{ project_source_path }}\n  when: remote_origin_url is defined and remote_origin_url != project_git_repo\n```\n\n\nI just wrote that on top of my head, so there may be syntax errors that slipped by.\n. @fullyint I think it's just a matter of preference at this point. I usually prefer smaller, easier to understand tasks and offloading the logic as much as possible to Ansible. I think using the builtin function of Ansible over shell (when possible) improve long term maintainability and readability.\n. This will not be needed once https://github.com/geerlingguy/ansible-role-mailhog/pull/6 is merged in.\n. This block is mostly a copy of the one in the all settings. Because it is not possible to append to a list in Ansible its not possible to only add the rule to open port 8025, I have to override the whole list.\nAnother option would be to put ferm_enabled: false for development by default. what do you guys think?\n. I'm using the fork of the pull request until https://github.com/geerlingguy/ansible-role-mailhog/pull/2 in merged, because the role install ssmtp by default and we do it too, so it would conflict.\n. We could do that, but it wouldn't work if the user changer the value afterward, because MySQL save the users in the database, we would need to implement a way to modify the root user via a MySQL command. I looked around, and this is not recommended. (Places like Amazon RDS that lets you set the root user won't let you change afterwards. So the mysql_root_user is only used on external installs. )\n. @austinpray this seems the most logical way to handle it. \n\nI'm told this fails \n\n@fullyint  have you been told why it fails?\nI'm not sure if I understand this correctly (haven't tested), but to me it looks like using:\nsite_hosts:\n  - site1.com\n*.site.com would automatically be routed correctly to the IP of the vagrant box?\n. @alan-c is right. This is the recommendend way for Nginx to handle log file reopening. See: http://nginx.org/en/docs/control.html\nAlan, you should do $(<\"/var/run/nginx.pid\"). See : http://stackoverflow.com/questions/21432883/pid-cat-pidfile-or-read-pid-pidfile\n. @alan-c I just tested kill -USR1 $(<\"/var/run/nginx.pid\") outside the script, and it seems to work correctly (with root privilege as expected). Is it working for you outside the script? I didn't want to make it more complicated for you. If it doesn't work inside the script, we could use cat as in your initial commit. the performance difference is minimal anyway.\n. I just looked a little bit more into it. nginx service actually have a rotate which seems to be exactly what we want. @alan-c want to try it?\n. Yep, I checked what the rotate command does:\nrotate_logs() {\n    # Rotate log files\n    start-stop-daemon --stop --signal USR1 --quiet --pidfile $PID --name $NAME\n    return 0\n}\n. Sure thing!\n. ",
    "30suns": "I ended up testing vagrant-bindfs previously and found that it only slightly improved things. There's still a need to map the gid and uid between guest and host which gets messy. It would be great if there were a more general solution.\n. ",
    "mattstratton": "Heh. I spent a couple hours last night rewriting the playbook as a Chef cookbook (for a couple reasons; not the least of them being that I know Chef and don't know Ansible at all), and got it about 95% of the way there (the cookbook does some other things I want on my servers, so it isn't terribly reusable). I did eventually get my staging server in Azure up using a combo of the playbook, deploy, playbook, manual steps, crossing fingers, etc...but at least I can keep working on this particular project that I was using Bedrock until I finish the cookbook :)\nI noticed that there is a group_vars setting for \"run composer\" so I see how you can turn those steps on and off at least. That's cool.\n. ",
    "ghost": "\nIf this applies to you, you might try setting mysql_root_password back to the default.\n\nYap. The default way works great for me. Thanks! \n. Solution/workaround for directory permissions in Vagrantfile when using HHVM:\nChange:\nconfig.bindfs.bind_folder nfs_path(name), remote_site_path(name), u: 'vagrant', g: 'www-data'\nto:\nconfig.bindfs.bind_folder nfs_path(name), remote_site_path(name), u: 'vagrant', g: 'www-data', :'create-as-user' => true, :perms => \"u=rwx:g=rwx:o=rx\", :'create-with-perms' => \"u=rwx:g=rwx:o=rx\", :'chown-ignore' => true, :'chgrp-ignore' => true, :'chmod-ignore' => true\nThat lets group write to directories. Probably not the best solution, would love to hear opinions for something better.\n. I am currently using Honestead, but it got kinda clogged now. I think I have 50ish projects on it. But this is not the point I wanted to make earlier. \nUsing Trellis we'd have the same server configuration on the local VM, in production and staging. Plus the deploy is a piece of cake.\nPersonally I don't care about hard drive space. I can, actually I'd like to, have single VMs per project.\n. Gotcha! \nSome day a new pull request will appear. Some day :d \nThanks for your time.\nI think we could close this. I just wanted to throw an idea out there :) \n. @alexandcote ofc i'm interested :D\n. Sorry for unnecessary issue. It turns out ansible was reading backup files created by vim ( eg 'wordpress-sites.yml~' ).\n. ",
    "BrandonShutter": "The mirror on coreix.net was removed and a redirect was added for some reason.\n. Beat me to it.  Thank you @austinpray .\n. I\u2019m still running into issues.  The mirror it\u2019s trying to load from is wrong.\nW: Failed to fetch http://mirrors.coreix.net/mariadb/repo/10.0/ubuntu/dists/utopic/main/binary-i386/Packages  404  Not Found [IP: 85.13.241.50 80]\nFresh clone.  Why is not using nyc2?\nEdit: This is from apt still having the coreix repo mirrors in it, and when you try to update it fails (obviously.)  \nNeed to remove the coreix repos from existing server, or use spinup a new box.\n. @austinpray see above edit.\n. Brand new DO Box.\napt.cache.FetchFailedException: W:Failed to fetch http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/utopic/main/source/Sources  404  Not Found\n, W:Failed to fetch http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/utopic/main/binary-amd64/Packages  404  Not Found\n, W:Failed to fetch http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/utopic/main/binary-i386/Packages  404  Not Found\n, E:Some index files failed to download. They have been ignored, or old ones used instead.\n. Keep in mind that we want to use 10.0 for now as well ^^\nhttp://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu/dists/\nWhat's causing utopic?\n. So in the meantime until mariadb updates their mirrors, people cannot use 14.10?\n. See https://github.com/roots/bedrock-ansible/pull/93\nEdit: PR removed, but could we do something like that?\n. I agree.  I'll remove the PR.  Only issue I see now is that Digital Ocean defaults to Ubuntu 14.10\n. Tested and it works.\n. Woo!\n. So I spun up a new instance, installing this from scratch.\nIf I leave the users as 'admin' in site.yml, it errors out from the get go.\nThe moment I set the users as 'root' it runs the full server configuration.  What am I missing here?  I even ssh'd into the server before running ansible-playbook, and created the user 'admin' and added it to the sudoers group.\n. 1.  The server was already provisioned (via bedrock-ansible)\n2.  No, I was not.\nAccording to the docs, it specifically says run after server has been provisioned.\nThis playbook should be run on remote hosts and is designed to be run once whenever the server is initially created\n. I read it wrong then.  That explains the issues then.  Thank you.\nSo just to reiterate, if we already have a server provisioned, we can't go back and run secure-root.yml ?\n. Server.  And for now I'm not going to run secure-root.yml - maybe sometime during the week I'll boot up a new server and play with it.\n. Note, this doesn't install mysql at all, so you automatically get a database error.  I could be wrong, but don't we need to install it for the remote connection to work?\n. Woo!\n. Awesome.\n. See https://discourse.roots.io/t/aws-ubuntu/4371/19 for conversation leading up to this issue.\n. @fullyint That fix did indeed work.\n. Thanks.  I need to learn more about ansible default variables obviously.\n. 24757\n. @swalkinshaw I've since downsized to 64kb.  Thanks!\n. I know this is closed, by why are we not adding the ability to set the buffer_size?\nIn my main.yml I have nginx_fastcgi_buffer_size: 32k and in my nginx.conf i have fastcgi_buffer_size {{ nginx_fastcgi_buffer_size }};\n. Are we merging this soon?\n. I agree with @swalkinshaw.  We use variables for overwriting cache, directories, etc, we shouldn't have an explicit variable to support a plugin, Jetpack or not.\n. I would use this.\n. Humor me, please.  Why is this a bad idea?  I personally have been using this.\n. Cloudflare just released this today: https://www.cloudflare.com/http2/\n. This is with php7.0-xml added.\n| PHP5 | PHP7 |\n| --- | --- |\n| bcmath |  |\n| bz2 |  |\n| calendar | calendar |\n| Core | Core |\n| ctype | ctype |\n| curl | curl |\n| date | date |\n| dba |  |\n| dom | dom |\n| ereg |  |\n| exif | exif |\n| fileinfo | fileinfo |\n| filter | filter |\n| ftp | ftp |\n| gd | gd |\n| gettext | gettext |\n| hash | hash |\n| iconv | iconv |\n|  | igbinary |\n| imap |  |\n| json | json |\n| libxml | libxml |\n| mbstring |  |\n| mcrypt | mcrypt |\n| memcached | memcached |\n|  | msgpack |\n| mhash |  |\n| mysql |  |\n| mysqli | mysqli |\n| mysqlnd | mysqlnd |\n| openssl | openssl |\n| pcntl | pcntl |\n| pcre | pcre |\n| PDO | PDO |\n| pdo_mysql | pdo_mysql |\n| Phar | Phar |\n| posix | posix |\n| readline | readline |\n| Reflection | Reflection |\n| session | session |\n| shmop | shmop |\n| SimpleXML | SimpleXML |\n| soap |  |\n| sockets | sockets |\n| SPL | SPL |\n| standard | standard |\n| sysvmsg | sysvmsg |\n| sysvsem | sysvsem |\n| sysvshm | sysvshm |\n| tokenizer | tokenizer |\n| wddx | wddx |\n| xml | xml |\n| xmlreader | xmlreader |\n| xmlrpc |  |\n| xmlwriter | xmlwriter |\n|  | xsl |\n| Zend OPcache | Zend OPcache |\n| zip |  |\n| zlib | zlib |\n. Yes I added php7.0-xml, and I added that notation now in the original reply, must have been removed when I copied and pasted the table in there.\n. Going and installing all the packages that are available here: https://packages.debian.org/search?keywords=php7.0\nThe packages that I installed are: \n- php7.0-bcmath\n  - php7.0-bz2\n  - php7.0-imap\n  - php7.0-soap\n  - php7.0-xml\n  - php7.0-xmlrpc\n  - php7.0-zip\nLeaves me with this comparison:\n| PHP5 | PHP 7 |\n| --- | --- |\n| bcmath | bcmath |\n| bz2 | bz2 |\n| calendar | calendar |\n| Core | Core |\n| ctype | ctype |\n| curl | curl |\n| date | date |\n| dba |  |\n| dom | dom |\n| ereg |  |\n| exif | exif |\n| fileinfo | fileinfo |\n| filter | filter |\n| ftp | ftp |\n| gd | gd |\n| gettext | gettext |\n| hash | hash |\n| iconv | iconv |\n|  | igbinary |\n| imap | imap |\n| json | json |\n| libxml | libxml |\n| mbstring |  |\n| mcrypt | mcrypt |\n| memcached | memcached |\n|  | msgpack |\n| mhash |  |\n| mysql |  |\n| mysqli | mysqli |\n| mysqlnd | mysqlnd |\n| openssl | openssl |\n| pcntl | pcntl |\n| pcre | pcre |\n| PDO | PDO |\n| pdo_mysql | pdo_mysql |\n| Phar | Phar |\n| posix | posix |\n| readline | readline |\n| Reflection | Reflection |\n| session | session |\n| shmop | shmop |\n| SimpleXML | SimpleXML |\n| soap | soap |\n| sockets | sockets |\n| SPL | SPL |\n| standard | standard |\n| sysvmsg | sysvmsg |\n| sysvsem | sysvsem |\n| sysvshm | sysvshm |\n| tokenizer | tokenizer |\n| wddx | wddx |\n| xml | xml |\n| xmlreader | xmlreader |\n| xmlrpc | xmlrpc |\n| xmlwriter | xmlwriter |\n|  | xsl |\n| Zend OPcache | Zend OPcache |\n| zip | zip |\n| zlib | zlib |\nNote, that installed php7.0-zip fixes the Composer issues found here: https://discourse.roots.io/t/composer-wp-packagist-failure-to-download-on-trellis-deploy/6018/11\n. I figured there was some reason why some weren't added, and that's why I didn't open this up in a PR.  This is as close as to the 'same' as php5 was, using available debian packages.\n. I nominate we add xmlrpc as well, due to people using the Wordpress app.\n. Sure\n. Mobile, so I added a new PR.  Closing this one.\n. Editing via web.  Sorry.\n\nBrandon Shutter\nBrandon Shutter LLC\n813.863.5870\nOn Sunday, September 6, 2015 at 2:52 PM, Scott Walkinshaw wrote:\n\nIn group_vars/production/wordpress_sites.yml (https://github.com/roots/trellis/pull/331#discussion_r38824750):\n\nsecure_auth_salt: \"generateme\" > + logged_in_salt: \"generateme\" > + nonce_salt: \"generateme\" > + > +\ncan you kill these blank lines?\n\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/roots/trellis/pull/331/files#r38824750).\n. \n",
    "el-rotny": "@swalkinshaw, is there a possible merge happening here? Also, seems to me that the Readme file needs to be modified to include a note that composer will be failing at this point and that the user should deploy using capistrano before proceeding. Seems like having the task included for production doesn't make sense... errr why have a production script that we know will fail? Thanks for the hard work in keeping this repo up.\nStill getting (when using the master branch):\n```TASK: [wordpress-sites | Install Dependencies with Composer] ******    \nstdout: Composer could not find a composer.json file in /srv/www/website.com/current```\n. Good job!\n. @swalkinshaw , what does this mean for the rest for Bedrock w/ Capistrano based deploys? Will that be deprecated at some point. (probably a better forum for Q&A. Apologies in advance).\n. ",
    "emaildano": "This is a game changer! Even without configuring multiple sites this direction is much simpler and easier to debug.\n@swalkinshaw, awesome job!\n. @austinpray: My previous request does work. It also matches the existing formatting in the database.yml file.\nShould the others be updated as-well?\n. @austinpray: I thought your edit #108 resolved this issue?\n. Sorry guys! I didn't have this setup locally at the time, so I went with the github editor. I've submitted a new PR. #109 \n. @austinpray: Is there a reason why the other php_... options aren't listed in production and staging?\nThe settings in development go against the defaults just like my suggestion.\nIf this is a problem, how about I remove the option from development, but leave it as var so people can have the ability to change it?\n. @austinpray @swalkinshaw: Valid point on varying the number between environments.\nRemoving the option from /group_vars/* would leave it as the default 1000 and give anyone the ability to alter it in dev, production, staging or all. But currently there is no variable to do so.\nI've removed the 5k option from dev for this PR. Personally I will be adding this to group_vars/all based on your feedback. I think other people should have this option as-well.\n. @swalkinshaw: That gets my past the first part, now I'm getting something else. Any suggestions here?\n```\n...\n==> default: Mounting NFS shared folders...\nThe following SSH command responded with a non-zero exit status.\nVagrant assumes that this means the command failed!\nmount -o 'vers=3,udp' 192.168.50.1:'/Users/danielolson/dev/roots/example.dev' /vagrant-nfs-example.dev\nStdout from the command:\nStderr from the command:\nstdin: is not a tty\nmount.nfs: requested NFS version or transport protocol is not supported\n```\nSame results on vagrant reload as-well.\n. Here's what I'm currently running\nOS X 10.10.1\nVirtual Box 4.3.20\nVagrant 1.7.1\nruby 2.1.5\nVagrant Plugins\nvagrant-bindfs (0.3.2)\nvagrant-hostsupdater (0.0.11)\nvagrant-share (1.1.4, system)\n. Thanks, @swalkinshaw! I tried a few fixes and here's what worked in case anyone has the same issue.\n\nWhile testing Bedrock-Ansible I ran vagrant up quite a few time which resulted in what looked like duplicate entries in my local hosts file.\nClearing those entries out (in my case I wasn't running any other VMs so they all went) fixed the issue.\nCurrently my hosts file looks like this:\n```\n127.0.0.1   localhost\n192.168.50.5  example.dev  # VAGRANT: 1a484a8818e7e5572eb83c4e182292c9 (default) / 23dd1dac-7276-4bbd-ac9c-ac998884caa1\n192.168.50.5  example.dev  # VAGRANT: 1a484a8818e7e5572eb83c4e182292c9 (default) / 23dd1dac-7276-4bbd-ac9c-ac998884caa1\n```\nThe last two entries are from running vagrant up for this test.\nThanks!\n. Getting better all the time. :beers: :\n. @nathanielks, would ansible-vault or git-encrypt affect the ability to push / pull with the original repo as it's updated?\n. ",
    "callerc1": "To save you some time just add: shell=/bin/bash or whatever shell you prefer to the main sudoers task:\n- name: Setup sudo users\n  user: name=\"{{ item.user }}\"\n        group=\"{{ item.groups[0] }}\"\n        groups=\"{{ item.groups | join(',') }}\"\n        password=\"{{ sudoer_passwords[ item.user ] }}\"\n        update_password=always\n        shell=/bin/bash\n        state=present\n  with_items: sudoers\nAnsible docs are pretty awesome so check them out.\n. same issue as @dstrunk using wp-cli-ssh as a workaround works well.\n. @swalkinshaw That would be cool. Especially helpful when working with a CI tool that automates deploys or even working on other projects etc.\n. ",
    "s3w47m88": "While I understand and respect there are Ansible Playbooks already setup for this. Monitoring servers is an essential best-practice for managing the health and security of a server IMO. So would adding a reference, of some kind, in the docs be within scope?\nEx. Heading for \"Server Monitoring\" subtext says something like \"While this is currently beyond the scope of Trellis, we recommend New Relic for server monitoring software. You can find existing Ansible Playbooks for including it here: {link to somewhere}.\". I'm glad to hear! I will contribute this and submit it as a PR when I'm done. To those who care: I'll try to do it in the next few days but no promises. :). I experienced this as well. Thank you for creating the thread.\nI would be willing to submit a patch for this but I'm brand new to Trellis / Bedrock / Sage. So I'll add this to a list of things I want to revisit in coming weeks as I learn my way around a bit more and then try to take a stab at this if no one else has by then.. ",
    "JulienMelissas": "I love the Mandrill plugin and service, but :+1: for for SMPT client just in case.\n. did we mean for this to be changed?. durp, sorry guys I'll shut up. ",
    "heyalbert": "just vagrant up\n. ==> default: Setting hostname...\n==> default: Configuring and enabling network interfaces...\n==> default: Exporting NFS shared folders...\n==> default: Preparing to edit /etc/exports. Administrator privileges will be required...\n==> default: Mounting NFS shared folders...\n==> default: Mounting shared folders...\n    default: /vagrant => /Users/als/Sites/PRO/bedrock-ansible\n==> default: Bindfs seems to not be installed on the virtual machine\n==> default: Fuse kernel module seems to be not loaded, trying to load it\n==> default: Creating bind mounts for selected devices\n==> default: Creating bind mount from /vagrant-nfs-.......dev to /srv/www/.......dev/current\n==> default: Running provisioner: ansible...\nPYTHONUNBUFFERED=1 ANSIBLE_FORCE_COLOR=true ANSIBLE_HOST_KEY_CHECKING=false ANSIBLE_SSH_ARGS='-o UserKnownHostsFile=/dev/null -o ControlMaster=auto -o ControlPersist=60s' ansible-playbook --private-key=/Users/als/Sites/PRO/bedrock-ansible/.vagrant/machines/default/virtualbox/private_key --user=vagrant --connection=ssh --limit='default' --inventory-file=/Users/als/Sites/PRO/bedrock-ansible/.vagrant/provisioners/ansible/inventory --extra-vars={\"ansible_ssh_user\":\"vagrant\",\"user\":\"vagrant\"} ./site.yml\nThe executable 'ansible-playbook' Vagrant is trying to run was not\nfound in the PATH variable. This is an error. Please verify\nthis software is installed and on the path.\nUSER@MAC:~/Sites/PRO/bedrock-ansible$ which anisble\nUSER@MAC:~/Sites/PRO/bedrock-ansible$\n. ",
    "jurajk": "@heyalbert how did you solve this? having the same exact problem...\n. ",
    "deschet": "@heyalbert I'm also having this issue.  Please let us know how you solved this.  Thanks in advance for sharing!\n. ",
    "chredd": "Having the some problem here. Any solutions yet?\n. Solved for me. My problem was that github.com wasn't among known_hosts and that I install som packages from there. Adding github.com to known hosts for root in the box solved my problem.\n. ",
    "jeffstieler": "Whoops - haven't updated a fork in a while. Sorry.\n. Argh. Sorry.\n. ",
    "alexciarlillo": "I see. That is what I get for jumping into Bedrock and bedrock-ansible in the same go. Kind of got myself confused. Thanks\n. Sorry I should have clarified that the uploaded files are not appearing. And also should have noted that it is going to the home directory because I am just testing out the deployment process before I blow up my existing staging site and re-deploy with ansible.\n. Yes I just did try that and it does work, but only if I remove the escaped double quotes on everything...\nOtherwise I get:\n```\n$> rsync --delay-updates -F --compress --recursive --rsh 'ssh  -S none -o StrictHostKeyChecking=no' --out-format='<>%i %n%L' \\\"/home/ciarlill/Development/environments/bedrock/main-site.dev/web/app/themes/wordpress-base-theme/dist\\\" \\\"ciarlill@staging:/home/ciarlill/main-site/releases/20150428150024/web/app/themes/wordpress-base-theme\\\"\n\"ciarlill@lib-web-lp001.mgt.private's password: \n```\nlib-web-lp001.mgt.private being the internal network name of the server I am targeting. \nSo if I remove the escaped quotes from the last argument:\n```\n$> rsync --delay-updates -F --compress --recursive --rsh 'ssh  -S none -o StrictHostKeyChecking=no' --out-format='<>%i %n%L' \\\"/home/ciarlill/Development/environments/bedrock/main-site.dev/web/app/themes/wordpress-base-theme/dist\\\" ciarlill@staging:/home/ciarlill/main-site/releases/20150428150024/web/app/themes/wordpress-base-theme \nrsync: change_dir \"/home/ciarlill/Development/environments/bedrock/bedrock-ansible//\"/home/ciarlill/Development/environments/bedrock/main-site.dev/web/app/themes/wordpress-base-theme\" failed: No such file or directory (2)\nrsync error: some files/attrs were not transferred (see previous errors) (code 23) at main.c(1183) [sender=3.1.0]\n$> pwd\n/home/ciarlill/Development/environments/bedrock/bedrock-ansible\n```\nAnd lastly, removing all escaped double quotes:\n$> rsync --delay-updates -F --compress --recursive --rsh 'ssh  -S none -o StrictHostKeyChecking=no' --out-format='<<CHANGED>>%i %n%L' /home/ciarlill/Development/environments/bedr\nock/main-site.dev/web/app/themes/wordpress-base-theme/dist ciarlill@staging:/home/ciarlill/main-site/releases/20150428150024/web/app/themes/wordpress-base-theme                   \n<<CHANGED>>cd+++++++++ dist/\n<<CHANGED>>cd+++++++++ dist/fonts/\n... [cut rest of output] ....\nWorks like a charm... seems like this may be an ansible thing, not bedrock-ansible. Very strange all around.\n. Good point. I think I know what the problem is... I declare my themes as a composer dependency from a git repo with the 'dist' directory gitignored, so running 'composer install' is probably destroying the entire directory and the synchronized files along with it... doh.\nI know somewhere in the docs you guys DO NOT recommend making themes a dependency of bedrock projects. Now I understand why. I will close this once I verify this is the case.\n. Yes that was the problem. Resolved for my use case by moving \"Copy project local file\" to run after the \"Run post_build_commands\" task. Apologies for raising an issue related to something you specifically suggest NOT to do in the documentation. :grimacing: \n. @mAAdhaTTah I just modified the ansible deploy task to copy up the assets after running 'composer install'. Because of the way our team is setup it makes most sense to have themes as their own repo. The others on my team mostly do styling specific work or change a bit of PHP here and there, but are not \"ops\" (or even full time devs) by any means. Since I am the only person who touches that stuff I like to keep them separate. \nI think on my personal site (when I get to updating it) or small freelance stuff I would be fine setting up the project and building the theme directly in the bedrock repo and think of it more as a unified \"app\". \n. ",
    "griffiths": "Yes - vagrant plugin install vagrant-bindfs\nAfter running the above I get:\nInstalling the 'vagrant-bindfs' plugin. This can take a few minutes...\nBundler, the underlying system Vagrant uses to install plugins,\nreported an error. The error is shown below. These errors are usually\ncaused by misconfigured plugin installations or transient network\nissues. The error from Bundler is:\nAn error occurred while installing nokogiri (1.6.6.2), and Bundler cannot continue.\nMake sure that gem install nokogiri -v '1.6.6.2' succeeds before bundling.\nThanks again for your help!\n. RVM\n. Hi --\nReinstalling Vagrant seemed to fix the issue for me.\nOne more question -- It seems like every page is returning the WordPress home page (even linked JS/CSS files come back with the default page). Is there something I'm missing in the configuration? I assume this has something to do with the nginx config?\nThanks again for your help!\n. ",
    "jcroll": "If I did open a pr would you be ok with using Ansible Galaxy roles? If yes I imagine your readme would have to get updated with instructions on how to install an ansible galaxy role and additionally I'm not sure how well that would work with your windows ansible script.\nMight make more sense just to find a node ansible galaxy role and copy and paste from it.\nAdditionally I don't see much harm in including these dependencies in your default provisioning.\nWhat do you think?\n. ",
    "enricodeleo": "I think it is the same issue as my #150 \nThe workaround you mentioned works but the drawback is that you cannot use wp-cli from the host (I use https://github.com/xwp/wp-cli-ssh) since the www-data user isn't allowed to ssh into the machine (and is right to leave it as is).\n. @louim I tried a fresh install and both php-fpm and hhvm gave me the same issue (bad gateway). I digged a little bit in and I found that switching from the unix socket to tcp solve this problem but not that of the directory permissions.\nThen I decided to switch to the deploys branch where, among other changes, php-fpm is executed as web_user (eg vagrant on development). This config gives back directory permissions to php but not to hhvm (even with the correct user set in server.ini). I found another solution I'm going to submit as PR to the deploys branch so keep in touch :)\n. @swalkinshaw thanks to your attention and your great work! I'll try to contribute further in the near future since as I said before I am an heavy user of Bedrock :)\n. During the day I decided to give to deploys branch a try and in fact I implemented swap from the  kamaln7's repo on galaxy.\nI'm also doing some other job on top of this branch (like porting the SSL support I PRed for the master branch and other things, you can see it as improvements branch in my fork. \n. @austinpray  You read my mind, I was going to test my new project on a micro instance lol\n. @mAAdhaTTah @austinpray ok, I'm scared, everything seems cold and windy out there :fearful:\n. I already used kamaln7's role within the other PR I submitted, I'll try to redo that as you requested in the other 3d ;)\n. @swalkinshaw my pleasure, I'm a big fan of Bedrock Ansible, I thought I should help in some way :)\nSomething I'd find useful would be to optionally reintroduce Capistrano for deployment. I loved the ansible-way idea at the beginning but now I find that in some cases Capistrano would be a more reliable solution and it has definitively more features. Dunno, the current solution seems too bash-ish.\n. Thank you for your reply @louim I was wondering it that was better or not since I personally chosen to stay with Capistrano when the project included ansible deploys at first. Maybe I need to try the last implementation of bedrock-ansible :)\n. I had to change the mirror this morning due to an error, but I think this could be left as it was, it was probably a temporary downtime of the DO's mirror.\n. ",
    "kalenjohnson": "Just received this on a DO droplet and fresh Trellis clone....\nSetting up ssmtp (2.64-7) ...\nhostname: Name or service not known\n. Ok, keeping this closed. Hostname in /etc/hosts and /etc/hostname did not match up, the DO box had been brought up and then the name changed.\n\n. Not necessary as the README was updated today.\n. You need the same key registered with both Bitbucket and Github in order for github-ssh-keys to work.\n. I've had this issue as well when installing the theme as a Composer dependency and not part of the Bedrock project. I wonder if \"Copy project local file\" could be placed underneath \"Run post_build_commands\" for this reason.\n. Yeah I see that can be an issue. I would say maybe it could be a modifiable environment variable so the Vagrantfile could be under version control but be able to change the IP address, but I'm not sure how that works in Ruby/Vagrant.\n. That is helpful, thanks @mAAdhaTTah \n. I think the final issue is actually a bug in Ansible: https://github.com/ansible/ansible/issues/10675\nPeople are experiencing an issue starting php5-fpm with version 1.9.1, which happens to be the latest version that gets installed on box, which also happens to be Ubuntu 14.04.\n. Ok I think we all agree on SSH in and follow the same instructions to deploy on Windows\n. Squashed\n. Fully squashed\n. I bet you're on Ansible 1.9.1\n. Nope, this: https://github.com/ansible/ansible/issues/10675\nEither downgrade to 1.9.0.1 or remove these lines: https://github.com/roots/bedrock-ansible/blob/master/roles/php/tasks/main.yml#L20-21\n. \n. > This is a relatively major issue as the wp-admin javascripts aggressively use javascript to rewrite URLs based on source / host values.\nI'm not aware of what you mean by this. Can you elaborate?\n. > Some people write javascript assuming the admin folder is located in /wp-admin/. On the BE, you have get_admin_url to provides the correct url, but there's no equivalent on the FE. However, assuming the location of the admin dir is _doing_it_wrong.\nWell the same thing can happen with poorly coded plugins written in PHP that don't use the correct functions.\nIMO it's not really a reason to add rewrites to the project. @roosterpark-porch also alluded to the fact that JavaScript in WordPress itself relies on having WP in the root directory, which I have never seen personally and wanted some clarification.\n. The benefit of installing globally is not needing phpunit required in your composer.json file, although if you have tests for each project it doesn't hurt. I would also say it's much easier to type phpunit than ./vendor/bin/phpunit every time :joy: \n. So it'll always work where your composer.json file is which has phpunit installed? I suppose that's an option too\n. :+1: haven't tested this, but I did miss being able to vagrant up and vagrant halt from whatever child directory I was in.\nHow would this work with using something like the roots-example-project.com project? just __dir__ + '/site' ?\n. Whoops, I mean __dir__ + '/ansible'\n. @louim actually it must be a nice side-effect, because Vagrant does traverse up folders to see if it can find a Vagrantfile. I just tested this and it does in fact work. Following this type of project: https://github.com/roots/roots-example-project.com\nAnd changing https://github.com/roots/roots-example-project.com/blob/master/Vagrantfile#L6 to ANSIBLE_PATH = __dir__ + '/ansible', does in fact allow you to issue vagrant commands from the site folder or any child folder of the project.\nSo.... :+1: :+1: :+1: :+1: :+1: \n. I'll also note, this should take care of these issues:\nhttps://github.com/roots/trellis/issues/126\nhttps://github.com/roots/trellis/issues/73\n. I actually proposed this for you @nathanielks , I want to save you as much time as possible on all future projects :+1: \n. Hmm... yeah, I see how that's an issue now. I unfortunately don't work in Windows so I forgot about that.\nThe only reason we're passing the Ansible path to the windows script is to account for the example project modified directory structure.\nSo, it seems to me that perhaps we should simply have a bash variable set up in windows.sh, which points to /vagrant, if the Vagrantfile is in the topmost folder with the Ansible playbooks, then fine, it works out of the box. If you are following the project example, having the playbooks in an ansible folder and the Vagrantfile in the root directory, you would have to modify the variable in windows.sh to point to /vagrant/ansible.\n. I'm not sure if I'm reading this correctly, but wouldn't passing in a blank string cause all references in windows.sh to also error? Like https://github.com/roots/trellis/blob/master/windows.sh#L26 , wouldn't that become /vagrant//vendor ?\nPerhaps sh.args = ANSIBLE_PATH should become sh.args = '.' like how it would have been before the full directory update, and if Trellis is installed to a subfolder, then this should be changed to the subfolders name.\nThat seems better actually than what I had proposed here\n. Wouldn't it be, um... down, the tree, from the Vagrantfile?\n. Haha no worries, just wanted to make sure :wink: \n. Ok so I just ran through this process again. Here's what worked for me:\n- Set up a project in the same way Austin describes in OP.\n- ONLY add define('WP_ALLOW_MULTISITE', true); to bedrock/config/application.php\n- vagrant up\n- Everything finishes, multisite installs.\n- WP generally adds a bunch of defines to the end of bedrock/web/wp-config.php\n  - Remove these constants\n- Add the rest of the constants to bedrock/config/application.php\nBingo.\nStill seems like a few steps too many. Originally, I believe changing the Trellis configs for multisite, adding the constants to Bedrock, and adding the landrush lines to the Vagrantfile was enough. It still will get stuck where Austin mentioned with the \"wp installed?\" task.\n. @fabianhenzler the fixes are still rather in development, but they seem to be working ok at the pull request here: https://github.com/roots/trellis/pull/283\nI think a little more testing will be done, but it should be committed to Trellis soon with an update to the wiki.\n. - [x] Fresh subdomain multisite\n- [x] Fresh subdirectory multisite\n- [x] Subdomain export database, vagrant destroy, vagrant up with imported database\n- [x] Subdirectory export database, vagrant destroy, vagrant up with imported database\n- [x] Deploy subdomain to remote DO\n- [x] Deploy subdirectory to remote DO\n:100: Awesome work @alan-c, everything's working. I took the majority of the evening tonight testing each of these.\nPretty happy to see Multisite working again :joy: \n. Just did a regular site install as well, no multisite, just to make sure that's working as well. Should be good!\n. @ascottmccauley there should be no constants defined in wp-config.php, they should all be in config/application.php\n. I've added this:\n\nIf you have specific pages you don't want cached, feel free to override skip_cache_uri in group_vars/all or the specific environment, and add the page names:\nyml\nskip_cache_uri: /wp-admin/|/xmlrpc.php|wp-.*.php|/feed/|index.php|sitemap(_index)?.xml|checkout|cart\n. Confirmed, although I haven't used that vagrant command so I haven't noticed.\n. I don't think we can just swap this constant for a local variable. So not really sure how exactly to fix this.\n. Mailhog's catchline: \"Inspired by MailCatcher, easier to install.\"\n\nSounds good\nBuilt in Go. Sorry Mailhog\n. I'd be up to give it a try. Ruby isn't installed on a Trellis box by default, so if something works just as well, no need to have it installed.\n. I like the sounds of this, although I would assume there are some Redis playbooks in Ansible Galaxy.\nIs there a lot of extra configuration when using Batcache with Redis? I haven't thought of trying that, really. I've played with using Redis for the object and transient cache, but that's as far as I've taken it. But we probably wouldn't want to restrict it to just Batcache, since there are other uses for Redis as well. Even with Trellis, Memcached is installed but it's not really in use by default.\n. Well this is embarrassing for someone, cough cough\n. So I just checked a prod server where I'm getting this: https://github.com/roots/trellis/issues/315\nBut access.log.1 is 74886\n. I vote for the first, much better. list elements work too, but I don't think they're required for the intro blurb.\n. fullyint++ for nice graph\n. I'm also seeing this:\n-rw-r----- 1 deploy www-data       0 Aug 26 06:35 access.log\n-rw-r----- 1 deploy www-data 2651252 Aug 27 23:03 access.log.1\n-rw-r----- 1 deploy www-data  213008 Aug 25 10:42 access.log.2.gz\n-rw-r----- 1 deploy www-data  240942 Aug 19 09:40 access.log.3.gz\n-rw-r----- 1 deploy www-data  288319 Aug 11 13:31 access.log.4.gz\n-rw-r----- 1 deploy www-data  262321 Aug  5 12:27 access.log.5.gz\n-rw-r----- 1 deploy www-data  803570 Jul 30 20:15 access.log.6.gz\n-rw-r--r-- 1 root   root      283252 Jul 15 19:10 access.log.7.gz\n. actually looks like @austinpray is user error\n. ty for success case :100: \n. Perhaps we could add a WP-CLI command to set the site to pretty permalinks by default. I mean, who doesn't turn those on anyways?\n. I'm betting it's because WP is installed with wp-cli. I would assume that installing WP via the 5-minute installer would have pretty permalinks enabled.\nMan, it's been a while since I did it that way :joy: \n. @louim yep I've been looking at it. I'm not sure if the permalink testing works from the command line though... could be completely off base, that was just my assumption.\nI'm also going off memory, but I'm pretty sure in the last few months, definitely post-4.2 release, I've had to enable pretty permalinks on a Trellis site. Should probably just give it a try again though to confirm.\n. Applicable: https://deliciousbrains.com/http2-https-lets-encrypt-wordpress/\n. :+1: from me, I always turn this on anyways\n. @austinpray we also don't know if people are already using this on staging/production servers either.\n. To be clear, it's not on html files, it's if you navigate to say example.dev/example/ when you are expecting that to automatically check for the index.html file, but instead nginx thinks you are trying to open a folder, correct?\n. Can you tell us what the differences between the queries are? It's pretty hard for and of us to guess at the differences\n. How about https://wordpress.org/plugins/query-monitor/\n. Don't worry Austin, I gots it. xdebug confirmed installed and working\n. I am noticing that on re-provisions this task still is set to 'changed', might need to check if xdebug is actually activated in the CLI before running this command\n. Idempotent\n. > how would you feel about configuring the vagrant box to also use this key, instead of the key generated by the vagrant ansible provisioner?\nI would suggest we use the user's key in conjunction with the generated key. I assume many people are using the generated key to be able to connect to the database using Sequel Pro, PHPStorm, etc.. I'll test this again with Phil's updates and report back. Please don't clear out the guidelines for contributing. We have set up a template to fill out for a reason. This is a personal request, not a bug with Trellis, and belongs on Discourse:\n\nThis is not a personal support request that should be posted on the Roots Discourse forums. Much better, you are my hero wilkinsin. Mounting an encrypted folder, AFAIK, is an issue with NFS and not Trellis itself. It seems like something that's been an issue for years: https://serverfault.com/questions/200759/exportfs-warning-home-user-share-does-not-support-nfs-export#comment962193_392232\n\nYou can try modifying the Vagrantfile to mount everything with the standard Vagrant share instead: https://github.com/roots/trellis/blob/be0cd6baf3f90e8cb825d23ad6713bc3f814523f/Vagrantfile#L73-L78. You can use a site's actual URL generally for Sequel Pro, IE example.dev.\nOriginally the hard coded IP's were necessary to make NFS sharing possible. I haven't checked in quite a while but I assume that's still the case.\nWith the vagrant.local.yml file you can change the box's IP, I generally assign a random IP for each project I work on.. This really hasn't been a requested feature. Generally you want the staging server to be available at least to more people than just a sole developer as well for testing before pushing live. It's fine if you want to have this setup, but I don't think this needs to be part of Trellis itself. Thank you for the PR though!. Made some suggested updates. This probably isn't going to work as expected, many users will have both hostmanager and landrush installed.. https://github.com/roots/trellis/pull/767/commits/061b8fb92cbf04394f9f758327a40d26980a4cfb\n. ",
    "anthonysexton": "Is this a problem for anyone else or just me these days?\n. ",
    "fabianhenzler": "Yeah, really struggling with it, because the workaround seems not to work :(\n. Any tipps on where to look to debug it and then help with the solution?\nIs php7 planned soon?\n. OK @QWp6t ... any suggestion how I could help? :)\n. having the same issue with the recent master\n. seems like this issue occurs again\n\n. actually I don't want to change the root password - i just want to be able to set the system up and then be able to continuously update it with trellis\n. Ok... Any recommendations on how I should save my configurations in order to be able to easily pull from the repo without having to do all the config again?\nIntroducing .example files instead if the real config files could be a valid option\n. ok... is there any step-by-step guide or any example project of trellis with bedrock and a MultiSite yet? Could anyone assist me? :)\n. what can I do? please help =)\n. seems not \b:( also i can reach it manually.\n```\n==> default: Mounting shared folders...\n    default: /vagrant => /Users/fabianhenzler/Development/local.matrix42.com\n==> default: Bindfs seems to not be installed on the virtual machine\nThe following SSH command responded with a non-zero exit status.\nVagrant assumes that this means the command failed!\napt-get install -y bindfs\nStdout from the command:\nReading package lists...\nBuilding dependency tree...\nReading state information...\nThe following NEW packages will be installed:\n  bindfs\n0 upgraded, 1 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 25.1 kB of archives.\nAfter this operation, 89.1 kB of additional disk space will be used.\nErr http://archive.ubuntu.com/ubuntu/ trusty/universe bindfs amd64 1.12.3-1\n  Could not resolve 'archive.ubuntu.com'\nStderr from the command:\nstdin: is not a tty\nE: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/universe/b/bindfs/bindfs_1.12.3-1_amd64.deb  Could not resolve 'archive.ubuntu.com'\nE: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n```\n. ok thanks - i'll go for the forum\n. injecting the Multisite config into development.php seems to work pretty well\n. in combination with bedrock -- forgot to mention\n. The issue seems to be logrotate\n\u279c  ansible git:(master) \u2717 ansible-galaxy -r install requirements.yml --force\n    - downloading role 'project_deploy_module', owned by f500\n    - downloading role from https://github.com/f500/ansible-project_deploy_module/archive/v1.0.3.tar.gz\n    - extracting f500.project_deploy_module to vendor/roles/f500.project_deploy_module\n    - f500.project_deploy_module was installed successfully\n    - downloading role 'ntp', owned by resmo\n    - downloading role from https://github.com/resmo/ansible-role-ntp/archive/0.3.0.tar.gz\n    - extracting ntp to vendor/roles/ntp\n    - ntp was installed successfully\n    - downloading role 'logrotate', owned by nickhammond\n    - downloading role from https://github.com/nickhammond/ansible-logrotate/archive/master.tar.gz\n    - error: failed to download the file.\n    - logrotate was NOT installed successfully.\n    - you can use --ignore-errors to skip failed roles.\n. yes please share you main.yml :) Please @soderlind \n. ",
    "strarsis": "This also would help dockerizing Trellis as a whole, ansible can be used for provisioning docker images, too.. This would also make containers possible, e.g. with docker-compose because each container/instance can use its own separate playbook (or have it provisioned, e.g. using packer.io with docker - or have the config mounted that is copied otherwise).. Things tried:\n\n\nRemoved vendor folder and repulled using ansible-galaxy.\nSeems to reproduce the roles nicely, but still ends with same error.\n\n\nRe-installed with a different version of ansible (2.2.0.0) and tried again.\nSame error.\n\n\nVagrantfile for reproducing the issue:\nVagrant.configure(\"2\") do |config|\n  config.hostmanager.enabled = true\n  config.hostmanager.manage_host = true\n  config.hostmanager.manage_guest = true\n  config.hostmanager.ignore_private_ip = true\n  config.hostmanager.include_offline = false\n  config.vm.hostname = \"web\"\n  config.hostmanager.ip_resolver = proc do |machine|\n    result = \"\"\n    machine.communicate.execute(\"ifconfig enp0s8\") do |type, data|\n        result << data if type == :stdout\n    end\n    (ip = /inet addr:(\\d+\\.\\d+\\.\\d+\\.\\d+)/.match(result)) && ip[1]\n  end\n  config.vm.box = \"ubuntu/xenial64\"\n  config.vm.network \"public_network\", bridge: \"ens33\"\nend\n'~/.ssh/config':\nHost web\n  HostName web\n  User ubuntu\n  Port 22\n  UserKnownHostsFile /dev/null\n  StrictHostKeyChecking no\n  PasswordAuthentication no\n  IdentityFile /home/build/test/.vagrant/machines/default/virtualbox/private_key\n  IdentitiesOnly yes\n  LogLevel FATAL\n'trellis/hosts/...':\n```ini\n[development]\nweb\n````\nEdit: The authorized keys were OK, no need to update them.\nIn the trellis folder of a web app, the ansible-playbook is ran:\n$ ansible-playbook server.yml -e env=staging -e 'ansible_ssh_user=ubuntu' -e 'ansible_user=ubuntu'. @swalkinshaw: Apparently the issue is caused by a line in \ndevelopment default config that uses the mailhog_install_dir variable at https://github.com/roots/trellis/blob/2773baa313a496227eafbe294ca5b30d484c232a/group_vars/development/mail.yml#L2\n```yml\n[...]\nphp_sendmail_path: \"{{ mailhog_install_dir }}/mhsendmail\"\nWhen this line is commented out, the error goes away.\nIt seems to be an issue with the mailhog role and how its variables are available outside.. The reason was that the Ubuntu installation wasn't actually clean/minimal, \nthere were already apache, mysql and other servers installed and configured and \nthis collided with the provisioning - provisioning worked after reimaging using a minimal image.. Maybe a simple smoke test would already suffice that just tries to connect to each site (HTTP/HTTPS)?\nEdit: This would indicate an issue with nginx, but isn't an elegant solution.. @fullyint: I just noticed there is also a comment in the [hosts/development file](https://github.com/roots/trellis/blob/master/hosts/development#L1):\nThis file is only used for Windows hosts.\n[...]\n```\nBut one also may want to use mailhog on Linux, too, hence using development environment/hosts.. Are there any plans for adding this in near future? It is also a handy way improving the PageSpeed score.. One way to solve this could be by using a plugin that enforces adding the necessary \ncache busting parameter to all resources like [Busted](https://wordpress.org/plugins/busted/) .. I agree with this and include the h5bp config file myself.. There are also other plugins that store data in theuploads/` directory by default.\nOther files/folders that are optional or shouldn't even be requestable.\nCore stuff:\n- wp/composer.json\n- wp/composer.lock\n- wp/license.txt\n- wp/readme.html\nPlugins:\n- app/uploads/sucuri\n- app/uploads/updraft-plus\n- app/uploads/wp-security-audit-log\n- (more?)\nMany plugins add a .htaccess file for denying access - which nginx doesn't use.. An opt-in/opt-out feature could be a nice addition.\nEither listing the folders in uploads/ folder that should be accessible to public with all others being blocked or listing the folders that should be blocked with all others being accessible.. Now should the access just be denied or rather handed to the WordPress app (for custom 404) so it isn't possible to know whether the file exists or not from the outside?. @swalkinshaw: The YAML doesn't work and Trellis config has to be further modified, see \nhttps://discourse.roots.io/t/best-practices-extend-an-occupied-hook/9253/6\nSo this issue should be reopened.. A new approach that fixes the issue, is more elegant, \nadds the built-in hook and allows to specify multiple hooks as list - \nexample for deploy_build_after hook:\nyml\n- include: \"{{ item }}\"\n  with_items: \"['{{ playbook_dir }}/roles/deploy/hooks/build-after.yml'] + {{ deploy_build_after }}\"\n  tags: deploy-build-after\n````\nDefaults:yml\ndeploy_build_after: []\n````\nHooks can be specified as list like so, the Trellis built-in hook, if one exists, is automatically prepended:\n```yml\ndeploy_build_after:\n      - \"{{ playbook_dir }}/deploy-hooks/sites/{{ site }}-build-after.yml\"\n      - \"{{ playbook_dir }}/roles/deploy/hooks/build-after.yml\"\n````\nOne could argue whether the customizing Trellis user should be able to add their own hooks before or after the built-in Trellis hook - this shouldn't be necessary because this kind of granularity is already available by the existing _before, _after hook structure in Trellis.. PR: https://github.com/roots/trellis/pull/815 - First tests look good.. @swalkinshaw: The yet empty hooks are now shown as commented out examples.\nAlso a commented out example for using site-specific hooks is kept because it can be very useful for site-specific deploys (like rsyncing the build artifacts, I use it for every site myself).\n@fullyint: Learned something :). @fullyint: Done. @pySilver: From the related discussion on \nhttps://discourse.roots.io/t/deploy-build-before-for-multiple-site-boxes/5274/3:\n``yml\n[...]\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before/{{ site }}.yml\"\n[...]\n````\nSo in this example,{{ site }}` is interpolated and ansible tries to find that hook yml file - for all sites, regardless whether there is a hook file intended for the site or not.. @swalkinshaw: Thanks!\nSome programs only support a path to a single file which is a problem when the cert ID changes in the file name. It would be a nice addition to add a \"-current\" cert file which is just a copy of the current cert. A soft symlink also doesn't always work (some programs don't support resolving soft symlinks either).. Numbered files (for ordering) are often used in configs in distributions like Debian/Ubuntu but also \nin Docker config folders. I actually like this pattern, it also makes pulling from Trellis master much easier.. Related issue: https://github.com/h5bp/server-configs-nginx/issues/176\nAlso related (404 from app): https://github.com/roots/trellis/issues/804. @swalkinshaw, @fullyint: \nFrom the related issue (https://github.com/h5bp/server-configs-nginx/issues/176#issuecomment-299652588):\n\n[...]\nRe the problem that brought you here - I suggest using a 404 front controller - it's much less intrusive and matches how wordpress (or almost any cms) actually works.\n\nSuch a setup is described in the h5bp nginx docs: https://github.com/h5bp/server-configs-nginx/blob/master/doc/common-problems.md#change-to-use-a-404-front-controller\nserver {\n    [...]\n    try_files $uri $uri/ @app;\n    error_page 404 = @app;\n    [...]\n    location @app {\n        include fastcgi_params;\n        [...]\n    }\n}\nDoes it make sense to create a new issue for this, changing the current config to 404 font controller style?. Yes, with this 404 frontcontroller setup the original h5bp config files wouldn't have to be modified.. @fullyint: The CSR is rarely/never used by TLS configurations and I don't need it for my use case either.\nThe root cert is the CA cert of Let's Encrypt? The bundled certs already contain the CA cert, right?. @fullyint: Most programs require fullchain cert (=bundled) and private key, hence both files should have constant file names.. @swalkinshaw:\nRelated discussion: https://discourse.roots.io/t/certbot-instead-acme-tiny/9051/6\nSo I had a similar certificate expire issue and I found out that in the cronfile for calling the renewal script, the days field value is still uninterpolated ansible variable!\n````\nAnsible: letsencrypt certificate renewal\n30 4 1,11,21 * * root cd /var/lib/letsencrypt && ./renew-certs.py && /usr/sbin/service nginx reload\n    day: \"{{ letsencrypt_cronjob_daysofmonth }}\"\n````\nI just re-run the playbook but this still persists - it probably won't work with incorrect day field value.\nansible 2.3.0.0. @TangRufus: Wouldn't this be included in ngx_pagespeed?. @TangRufus: Can I use this for building the nginx pagespeed extension, too?. Could https://github.com/ANXS/nginx somehow be re-used for this?. Couldn't we make a \"child config\" from the base roots config?\nIt works so well with themes \ud83d\ude04 . Maybe one should just use the already punycode-escaped IDNs in wordpress_sites config?. I escaped the domain myself and then use it that way (escaped) in config file. This works fine.. @kalenjohnson: That's OK, I just thought it may be useful, even unmerged. \ud83d\ude04 . Yes, nginx_sites_confs was modified in main.yml and ssl.no-default.conf.j2 was still missing.. Is it useful to leave them commented out with comments from the documentation about when each hook is called?. ",
    "workerdem": "@fullyint You are right about my configuration. I changed all example.dev instances to example.com and got the following configuration:\n``` yaml\nmysql_root_password: devpw\nweb_user: vagrant\nwordpress_sites:\n  example.com:\n    site_hosts:\n      - example.com\n    local_path: '../example.com' # path targeting local project directory (relative to root/Vagrantfile)\n    site_install: true\n    site_title: Example Site\n    admin_user: admin\n    admin_password: admin\n    admin_email: admin@example.com\n    system_cron: true\n    multisite:\n      enabled: false\n    env:\n      wp_home: http://example.com\n      wp_siteurl: http://example.com/wp\n      wp_env: development\n      db_name: example_dev\n      db_user: example_dbuser\n      db_password: example_dbpassword\nphp_error_reporting: 'E_ALL'\nphp_display_errors: 'On'\nphp_display_startup_errors: 'On'\nphp_track_errors: 'On'\nphp_mysqlnd_collect_memory_statistics: 'On'\nphp_opcache_enable: 0\n```\nHowever, I still get the same error. After that, I changed all instances of example.com to example.dev, renamed bedrock directory example.com to example.dev and changed local_path accordingly, but still get the same error.\n. ",
    "slackday": "Cool, and thanks for explaining that. \n. This doesn't seem to work for me. As I read it subtree defaults to False so it will always be defined?\nI get this output:\n```\n=> {\"changed\": true, \"cmd\": \"mv /mnt/persist/www/example.com/releases/20150517190042/False/ /mnt/persist/www/example.com/releases/20150517190042\", \"delta\": \"0:00:00.010619\", \"end\": \"2015-05-17 19:00:56.686640\", \"rc\": 1, \"start\": \"2015-05-17 19:00:56.676021\", \"warnings\": []}\nstderr: mv: cannot stat \u2018/mnt/persist/www/example.com/releases/20150517190042/False/\u2019: No such file or directory\nFATAL: all hosts have already failed -- aborting\n```\nIt seems to always output /False/* as the folder no matter what I change the variable to. I'm not so handy with Ansible but am trying to fiddle around a bit..\n. Awesome! Not a awesome bug but awesome that I am not alone with this bug. \ud83d\ude06 \nHave had this issue for a while (on different sites but with the same environment/version. I have failed for some time to find the cause of the issue. But it seems to be related to some plugins running on development (Vagrant) box.\nFor me it happens in wp-admin on all pages that has the grid view of the media gallery. I.e. under Media or every edit screen where I attach/upload/edit images.\nIt happens if both Advanced Custom Fields and Query Monitor plugins are activated. If I deactivated either of these plugins the issue stop. This bug does not appear on staging/production environment with the same plugin configuration.\nAre you using any of these plugins as well or any other plugins that's causing this issue for you? \nI hope this information helps someone reproduce this issue and find a solution.\n. Another approach would be to skip landrush all together and add each site domain to wordpress_sites.yml and applying them with host-manager.\nI'm in favour of this since it's much easier and keeps the dependencies limited. landrush seems to work differently depending on OS and can be incompatible with different version of Vagrant. I got it working. If I install landrush plugin vagrant doesn't fail on the IF ELSE check.\nI don't have to use landrush it's just there to pass the check. I can then add the hosts to my hosts file. \nYou can close this issue if you want. I still think there is room for improvement like adding multiple domains for host-manager to add for multiple sites instead of adding the manually.\nBut this works for me now.. sorry for taking your time :) . I just tried default(omit) with custom home dir and it works the same as my home_root group_var.\nI removed it and update the PR to use default(omit) instead.\nThanks!. Thank you :) I just got my deploys working again! Happy weekend \ud83c\udf89 . Hi, a few of us have had the same problem and the solution is posted here https://discourse.roots.io/t/johnpbloch-wordpress-moved-to-a-new-configuration-and-wp-goes-missing/9124/45\nTry it and I hope it works for you too. Sorry this is a bedrock issue and I was going to make a PR fixing it when I realized I created the issue in wrong project.... ",
    "tremby": "I had the same thing with a badly-formatted yaml file. This case could do with a better error message.\n. Green in mine. Always bothers me. \u263a\n. ",
    "jfrux": "I assumed this much, I think I\u2019m getting closer to debugging the issue.\nThanks for your help and the recommendation for the roots discourse.\nVery helpful.\n\nOn Apr 9, 2015, at 10:21 AM, Phil Nelson notifications@github.com wrote:\nCongrats on getting it running!\nYou can use discourse.roots.io/ for support requests, rather than the issue tracker here.\nhow do I see my site locally on my Mac?\nYou should be able to see your site in your browser at example.dev, or whatever site name you entered in group_vars/development. If it doesn't load, you might double-check that your site is in your etc/hosts file, and consider using the vagrant-hostsupdater https://github.com/cogitatio/vagrant-hostsupdater plugin.\nWhere do I make changes?\nYou can edit your files like normal on your local machine. Vagrant shares those files/folders, so your changes will show up in the VM and in your browser on refresh.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/roots/bedrock-ansible/issues/173#issuecomment-91246359.\n. \n",
    "rmartin": "Confirming that we're seeing this issue as well with the latest version of Trellis. On our end the owner:group was root:root for the uploads folder. Manually changing that to web:www-data worked but I was unclear how to adjust the changes in the new users.yml file to account for that in the initial provision step. \n. ",
    "mohsinr": "Wow @swalkinshaw  thank you for hinting about version. I installed on Ubuntu 14.04 and default version they installed was outdated. \nI upgraded the Ansible version and those errors go away. Thank you!\nPS. For anyone facing same issue I added following repo for latest version:\nsudo apt-add-repository ppa:ansible/ansible\n. ",
    "cfxd": "This is still an issue (bump)\n. @louim not at this time\u2014I only know enough to be dangerous :-/\n. Make the red part look like the green part in this file: https://github.com/roots/trellis/pull/590/files \ud83d\udc4d\ud83c\udffb\n. If you open Virtualbox do you see any VMs running? You should be able to see if there's one running with an address that matches your config file. Make sure that's the one you're visiting and that the VM is actually powered up.\n. If you ssh onto the remote and run these manually:\n$ cd /var/lib/letsencrypt\n$ service nginx reload\nwhat's the output?\n. Tried that cmd directly on the box itself with poor/unreliable results so will leave this PR as is for now.\n. This is the fix for the rollback role\n. ",
    "heyfletch": "What do you recommend to fix it? Both those points will make the Roots Example fail out of the box as is.\n. The provider definition is a simple fix for users who have a different default provider specified in their own environment. For example, I have parallels defined as my default provider. (I think Parallels did this to me). When I run vagrant up, it dies because vagrant up relies on an assumption that you will use the default provider unless you give it the --provider=virtualbox flag. This will help make the project work wherever. \nIt's fine with me if the ansible path solution is to have it done in the Example project, but that creates another step in that project. \n. Removed/withdrew the ansible path change from this pull request. Just suggesting the Vagrantfile change. (I didn't mean to mix the 2 commits in the first place)\n. Stock Digital Ocean Ubuntu 14.04 x64 vmlinuz-3.13.0-43-generic 512mb. Everything else I left to bedrock-ansible.\n. ansible 1.9.0.1\n  configured module search path = None\n. I found a solution that works for me. If this sounds right and doesn't raise other issues, I will test on another fresh DO Droplet and create a PR.\nFor whatever reason, ansible fails when trying to set the root password for the $ansible_hostname on subsequent runs. The $ansible_hostname is the machine name set by Digital Ocean when creating the Droplet. E.g., Raven.\nIf I switch ansibile_hostname to inventory_hostname in roles/mariadb/tasks/main.yml, it will initially and subsequently create a mysql user 'root'@'inventory_hostname' with no problems, e.g., 'root'@'104.787.999.99'.  Not only does this work, but this seems more useful to have a root user with the ip address than the machine name.\nThoughts?\n. So, my suggestion is to replace\nyaml\n- name: Set root user password\n  mysql_user: name=root\n              ...\n  with_items:\n    - \"{{ ansible_hostname }}\"\n    - 127.0.0.1\n    - ::1\n    - localhost\nwith\nyaml\n- name: Set root user password\n  mysql_user: name=root\n              ...\n  with_items:\n    - \"{{ inventory_hostname }}\"\n    - 127.0.0.1\n    - ::1\n    - localhost\n. There are 2 tasks for removing anonymous users. We could convert those to one task and include the inventory_hostname for good measure. \nReplace:\n``` yaml\n- name: Delete anonymous MySQL server user for current hostname\n  mysql_user: user=\"\"\n              host=\"{{ ansible_hostname }}\"\n              state=absent\n              login_user=\"{{ mysql_user }}\"\n              login_password=\"{{ mysql_root_password }}\"\n\nname: Delete anonymous MySQL server user for localhost\n  mysql_user: user=\"\"\n              state=absent\n              login_user=\"{{ mysql_user }}\"\n              login_password=\"{{ mysql_root_password }}\"\n```\n\nwith\nyaml\n- name: Delete anonymous MySQL server users\n  mysql_user: user=\"\"\n              host=\"{{ item }}\"\n              login_user=\"{{ mysql_user }}\"\n              login_password=\"{{ mysql_root_password }}\"\n              state=absent\n  with_items:\n    - localhost\n    - \"{{ inventory_hostname }}\"\n    - \"{{ ansible_hostname }}\"\n. Agreed! I first spent several hours trying to understand the underlying issue / fix and couldn't find a solution... until I came across someone who switched to inventory_hostname and it \"just worked\" for him. \n. Thanks for merging! \n. Does this mean Trellis can work with Parallels?\n. Parallels works with a few tweaks. Errors I got:  \n1) \"The box you're attempting to add doesn't support the provider you requested. Please find an alternate box....\"\nUsing parallels/ubuntu-14.04 instead of ubuntu/trusty64 worked.\n2) \"The specified host network collides with a non-hostonly network! This will cause your specified IP to be inaccessible. Please change the IP or name of your host only network so that it no longer matches that of a bridged or non-hostonly network.\"\nI changed \nconfig.vm.network :private_network, ip: '192.168.50.5' to \nconfig.vm.network :private_network, ip: '192.168.1.200'\nNot sure if you'd want to make a change like that to the default Trellis Vagrantfile or what. \n. OK @ckovey, @swalkinshaw, I've retested and Parallels works flawlessly. Thanks for making this provider agnostic!\n. @soderlind how did PHP7 work for you? Can you share your tasks/main.yml?\n. Nice catch Scott. Shows actual H2 support is only ~25%. Without SPDY fallback, doesn't make sense to switch yet. Bummer.\n. Totally agree! \n. I got this to work. Didn't try #818.  This has become critical now that Chrome 58 will not load the local https site without Subject Alternative Name. \nI had a rough go of this, so reiterating some points here for others:\n\nStart with @medfreeman's testing procedure and be sure the certs and keys are gone (those commands didn't clear them for me, so the reprovisioning was not working)\nThe ansible-playbook provision line didn't work either, so did: vagrant reload --provision instead\n\nIf sudo security add-trusted-cert on macOS doesn't work, do it manually by opening dev site, viewing certificate, dragging to desktop, dragging into keychain. \n. My cheatsheet for new site with https/SSL with Subject Alternative Name on a local Mac:\n\n\nIncorporate this pull request's changes: \n\nCreate and trust the local certificate:\n\nbash\nopenssl s_client -connect example.localdev:443 < /dev/null > example.raw\nopenssl x509 -inform PEM -in example.raw -text -out example.localdev.crt\nsudo security add-trusted-cert -d -k /Library/Keychains/System.keychain example.localdev.crt\nrm -f example.raw example.localdev.crt\nHaven't tried this on multisite.\nCurious, anything else we need to do to merge this?  Any way I can help?. ",
    "riveramauro": "Yes I am.... and I just notice \"Ansible >= 1.8\" in the documentation -_-\nCould that be the reason?\n. Can confirm. Downgraded to 1.9.0.1 and working as expected. Thanks!\n. ",
    "fredriksundstrom": "Bah. I forgot to run the vendor command.. My bad :(\n. No worries and thank you!\nI hopped back a few commits. Did you see the part on other missing defaults showing up, though?\nMy hunch at the time was, also, that even though I had multisite: false, it tried to install as multisite. Maybe I should have been clearer on that, but I had nothing but the default wordpress_site.yml.\nSo, multisite: false, still gave that error. But perhaps that is normal and will be fixed, also, by adding that default. :)\n. ",
    "developdaly": "example.com/\n- ansible/\n- site/\n- Vagrantfile\n. Same issue as @kalenjohnson -- local is fine, remote breaks. cc/ @bbttxu\n. ",
    "chriszarate": "Done. Thanks!\n. Oops: Added item.value.ssl is defined check to match the template revisions you recently pushed.\n. I may be an outlier, but I provide my own roles that live alongside bedrock-ansible. These roles provide additional services (logging, monitoring) and files (site restores, scripts, dotfiles, and now these nginx site-level includes) that we need in our environment.\nThen I copy bedrock-ansible's dev.yml and add my own roles, and that becomes the playbook I run. That way everything provided by bedrock-ansbile stays \"stock.\"\nEdited after seeing reply by @louim: That's essentially what I do in my own role, with a file task + with_fileglob option.\n. Happy to code up @louim's option 1 as a built-in method if that seems like the way to go\u2014let me know.\n. Thanks. I checked a few angles, and the problem is that anything that globs is going to pass the full local path. :(\n. Ok, let me take another pass at this. I also want to improve the regex to leave less room for error,\n. I'll take a look at this today!\n. This is great! Thanks right back at you for mentioning with_lines\u2014I hadn't seen that before. It looks like an alias for lookup('lines' ...)? Makes inline templating easier.\nWorks great. I was inspired to simplify the supporting variables, and I was eventually able to eliminate them altogether. I also removed the regexes and restricted the templates to a folder depth of 1 (e.g., templates/includes.d/foo/bar/include.conf.j2 will be ignored, and /etc/nginx/includes.d/foo/bar/include.conf will not be deleted). \nI'll push that here in a minute, but feel free to open your own pull request if you like your approach better. I was just tinkering.\n. Sorry for the long delay in circling back to this. I wasn't able to do testing until recently. Thanks for following up and catching those problems. \nI removed the maxdepth option at your suggestion. Nginx will not recursively include files, but we should leave the option to the user to potentially enumerate includes in subdirectories.\nI added when: item.startswith('/etc/nginx/includes.d/') as a failsafe because Ansible's file module with state: absent will delete recursively. I wanted to make extra sure we weren't deleting anything we weren't supposed to. After extensive testing, though, I feel comfortable removing it.\nThanks again! I'd welcome more feedback but it feels ready to merge from my perspective.\n. Yes! Thanks!\nTook a stab at a Wiki page at Nginx-includes.\n. I'm using Trellis for a production subdomain multisite site. I use it as a dependency (via requirements.yml) for our own Ansible project. \n1. I also ran into the wp installed and multisite issues\u2014however, it turned out that the wordpress_install role was too oriented towards new installs for our needs, so I supply my own wordpress_install role which overrides. Caveat: Our role is oriented towards creating AMIs/Vagrant boxes and not in having a WP instance up and ready. Take a look if you'd like. \n2. We have exactly your need for wildcard subdomains, but we simply list them in site_hosts:\nsite_hosts:\n  - \"example.dev\"\n  - \"*.example.dev\"\nThis doesn't cause any problems for us, but perhaps I'm missing something\n. It's not that we don't use public key auth at all, it's that we don't want public key auth for web_user (or even admin_user in some circumstances, if we're accessing via another account).\nI have Ansible's hash_behaviour set to merge and was having trouble getting Trellis to not try copying a key from that default location (which doesn't exist on my system).\nI'll test default(omit).\n. Piping to default(omit) doesn't work. The lookup throws an error (as opposed to just an undefined value) and stops playbook execution. I'll try some other strategies to override the opinionated default public key path and report back here.\n. I take it back. I think piping to default(omit) should work. Further, overriding users should be fairly easy (it's a list, not a hash, duh).\nI was confused by some very strange behavior which appears to be caused by this Ansible bug:\nhttps://github.com/ansible/ansible/issues/9944\nBasically, even if I override the users variable entirely, Ansible is still trying to template the lookup in group_vars/all and throws an error when it can't find ~/.ssh/id_rsa.pub\u2014even though it does nothing with it.\nNot sure what the best course of action here is. This seems like it should be affecting more people than just me. Or does everyone still have ~/.ssh/id_rsa.pub so they never run into this?\n. @austinpray This has been awhile, but can I ask what \"fix trailing slash issue\" addresses? I had added it in #240 and it addresses a redirect loop situation. I haven't had problems but am curious what you ran into.\n. Fair enough. Feel free to close. \n. Nice! That's much more flexible than the Boolean and ternary. I'll revise. \n. Still testing this.\n. @swalkinshaw, Not yet. I'll get back to it this weekend.\n. Good point. Disabling Nginx's max body size isn't a good approach. I've updated this PR to raise it to PHP's mast POST size. However, I do think that only raising it for URIs that end in .php will run counter to quite a few users' expectations.\nFor example, a default BuddyPress install has at least one rewritten upload URLs (for avatars) that will get hit with Nginx's default 1 MB limit. Many stock form plugins will have the same issue. \nI think what's happening is that Nginx applies the default client_max_body_size whenever rewritten URLs hit try_files. It returns 413 and never hits the higher one in the fastcgi block.\nI moved the modified client_max_body_size to wordpress.conf.j2, since it's really a WordPress-specific change. As a WordPress-centric project, there's not much use case for increasing the limit for non-PHP files, so I didn't add a nginx_client_max_body_size to apply more broadly.\n. Thanks, y'all!\n. Automatically adding the wildcard in the main server block was relatively recent (8e3ae15). Before that, I explicitly listed the wildcard subdomain in site_hosts. Perhaps you did, too. (It causes no harm if you still do that, just a little redundant.)\n. To be clear, the 444 behavior only happens if you use SSL and multisite subdomains.\n. Thanks! Checking whether ansible_ssh_host is defined should be enough\u2014it isn't when playbook are running locally.\n. For clarity (this was confusing to me initially): Ansible's --connection=local flag means that the playbook is run on the local machine (i.e., on your Mac, were you so inclined). There is no SSH involved at all. In the context of Packer, this means that the playbooks, roles, group_vars, host_vars, etc., are uploaded to the guest machine (whether local VM or cloud) and run on the guest with --connection=local. This task fails on Packer because we are not connecting via SSH.\nHuge thanks for pointing out that defining hosts by IP means that ansible_ssh_host will be undefined. That was unexpected! And, of course, a different search term of the docs turns up ansible_connection. It is defined when the --connection flag is passed. Sheesh. I'll push an update.\n. I've tested it a few different ways, and ansible_connection is defined and set to local when I (or Packer) pass --connection=local. Ansible 1.9.3.\n. It does seem that actually connecting over SSH to a host overrides ansible_connection. Ansible seems to prefer connecting over SSH if it can, even when --connection=local is set. So if Ansible knows how to SSH to 127.0.0.1, it will, and will \"undefine\" ansible_connection accordingly. That seems like good behavior, even if Ansible perhaps should alert you that it's not using your preferred connection. Not sure if that's what is happening for you.\n. Very strange. It seems like an entry in your Ansible hosts file implies \"connect to this host via SSH,\" which Ansible does no matter what you pass with --connection. And it sets ansible_connection accordingly, whether or not it is actually able to connect. It does this even for inventories passed as string with -i (e.g., -i \"[web] 127.0.0.1,\"\u2014that comma is important). This is especially strange because this is how Packer does it.\nIf, however, you set the host to 127.0.0.1 in the playbook via hosts: 127.0.0.1, it works. I'll take another look this weekend.\n. @fullyint, I'm able to replicate your issue now. Thanks again. This is a bit of a bummer. I don't see any clear way forward except (1) trying to make intelligent guesses based on related connection variables or (2) requiring ansible_connection to be set via inventory or extra vars. I suppose the latter is best and can be documented.\n. ",
    "evanfuture": "Just a quick thought, but shouldn't the \"snapshot\" role be left to the git branch that's being deployed?  Using the git-flow method, at least, your master branch is always meant to be working and stable, and your development branch is for working off of with live changes.  So, if the environments were as identical as possible, it would still leave room to develop without damaging production flow...  I'm not articulating very well either...\n. Yeah!  Works well!  Will we be seeing that in the roots.io menu bar soon?\n. I've run into this as well.  I think it just has to do with saving files.  I'm used to a quick: Save, Cmd+Tab, Cmd+R, and I must be moving faster than the VM can fnter than the VM can finish saving the file.  Goes away if you wait or if you refresh the browser again.\n. I found that before, but I wasn't sure what would be lost by removing vagrant-hostupdater from trellis.\n. Ok, having looked at both plugins, I'm not sure its actually necessary to have a new dependency.  After all, the vagrantfile is in Ruby.  So, I did this:\n```\nnext lines are commands to retrieve the latest ip address used of our prefered pattern from your etc/hosts file.\nlatest_ip = File.read(\"/etc/hosts\").scan(/192.168.50.\\d{1,3}/).sort.last.delete(\"192.168.50.\").to_i\nlatest_ip = latest_ip + 1\nlatest_ip = \"192.168.50.#{latest_ip}\"\nconfig.vm.network :private_network, ip: latest_ip\n```\nThat's using the root's convention for ip's.\nMajor caveat:  It breaks if there is no ip of that pattern.  I'm not sure how to fix that.  If someone lets me know, I can submit a pull request.\n. Yes, and as well, my ruby script doesn't work for ip's of more than one character!  I'll get it eventually.\n. Ok, here's the next iteration:\n```\nnext lines are commands to retrieve the latest ip address used of our prefered pattern from your etc/hosts file.\nrequire 'ipaddr'\nif Vagrant::Util::Platform.windows?\n  hostsfile = \"#{ENV['WINDIR']}\\System32\\drivers\\etc\\hosts\"\nelse\n  hostsfile = \"/etc/hosts\"\nend\nip = File.read(hostsfile).scan(/192.168.50.\\d{1,3}/).sort_by! {|ip| ip.split('.').map{ |octet| octet.to_i} }.last\nips = [ip]\nips << IPAddr.new(ips.last).succ.to_s\nlatest_ip = ips.last\nconfig.vm.network :private_network, ip: latest_ip\n```\nI have no idea if the Windows bit works, but that's the basic idea of it.  Again, if anyone wants to fix it up, I think this is shaping up well!\n. It does still break if no ip's match the string, but that's only a single line to fix it.\n. Yes, before I did it this way, I had it run as part of a bash script that set up eveything for the project, moved files around, and filled in variables for me.  Alright, keep it in the back of your minds anyway, I'll close this for now so we don't clutter the repo.\n. On a live server, I've had no trouble setting up my certs (well, with Apache anyway).  The trouble comes in development, when I'm using a non-existent url, site_slug.dev, and it won't complete.  Other than that, it seems easy enough to ansible-ize the whole process... (he says confidently, then, weeks later, shakes his head in shame)\n. Might be as simple as the domain name taking a bit to be resolved? That happens to me sometimes, even outside of Trellis. Can you test it on the bare ip address maybe?\n. ",
    "davekiss": "I'm getting this now with no subtree defined:\nTASK: [deploy | Move project subtree into root folder] ************************ \nfatal: [ip.address] => One or more undefined variables: 'dict object' has no attribute 'subtree'\n. @swalkinshaw no go.\nstderr: mv: cannot stat \u2018/srv/www/domain.com/releases/20150520132106/__omit_place_holder__0fae024f264debcf4f2677c603f189bd98dae9c8/*\u2019: No such file or directory\n. For now, I reverted https://github.com/roots/bedrock-ansible/commit/07047a23840dd6da83acff3bee27ef67efd91d91 and added this condition instead:\nwhen: not project_subtree == 'False'\n. No idea here.... destroyed and reinstantiated the vagrant box and it went away\n. Whoops! Thanks.\n. ",
    "MikeiLL": "Nice!\n. ",
    "ptibbetts": "Just a heads up, the Discourse menu bar also needs updating\n. Hey @elimc ,\nThe team use GitHub issues for bug reporting and pull requests and the forums for support requests like this, so you're more likely to get help (in the future) by going to the forums first.\nHaving said that, this error looks like bower wasn't able to create the bower_components folder for you:\nError: EACCES, mkdir '/Applications/AMPPS/www/example.com/site/web/app/themes/sage/bower_components'\nIf you create it manually and rerun bower install it should work. \nIf not, check out this thread on the forums or you could create your own thread.\n. I've noticed that the roots-example-project.com, docs, and soil repos are missing a CONTRIBUTING.md file (in either ./ or .github).\nWould you be open to some PRs that direct people to the guidelines repo? I was thinking of putting them all in .github/CONTRIBUTING.md (same contents as Sage & Trellis) and also adding a contributing link in the readme that points to the guidelines repo, like Sage goes.\nI could add the issue template to those repos whilst I'm at it.\nWhaddaya think?\n. Replacing Ubuntu Trusty with Xenial would remove the need for PR https://github.com/roots/trellis/pull/596 as Ubuntu 16.04 ships with OpenSSL 1.0.2g-fips\nvagrant@example:~$ openssl version\nOpenSSL 1.0.2g-fips  1 Mar 2016\nwhich has ALPN support:\n- HTTP/2 Enabled: true\n- SPDY/3.1 Enabled: false\n- Use Alternative Service: false\n- ALPN Protocols: h2,http/1.1\n- NPN Protocols: undefined\n- HTTP/2 sessions\n| Host | Proxy | ID | Protocol Negotiated |\n| --- | --- | --- | --- |\n| xxx.xxx.xxx.xxx:443 | direct:// | 4918 | h2 |\n| clients4.google.com:443 | direct:// | 5076 | h2 |\n| secure.gravatar.com:443 | direct:// | 5032 | h2 |\n| clients4.google.com:443 | direct:// | 5061 | h2 |\n. Just checking, the cli_options_ping var was only used to find out which user to connect as wasn't it? Running a raw command returns a success if the command is passed in the same way* that ping did. \nIt wasn't used for anything else?\nEdit * yes it is used for other things and it doesn't\n. This PR also assumes Roots wants to drop Ubuntu 14.04 and support one OS at a time, instead of adding support for choosing/automatically detecting which OS you're using.\n. > All I had to change was adding python to common packages.\nI've rolled back, added python to the with_items list and it works fine with Vagrant but gives me the following on a DO server:\n```\n\u279c  trellis (feature/ubuntu1604) \u2717 ansible-playbook server.yml -e env=staging -vvvv\nUsing /Users/paul/GitHub/trellis/ansible.cfg as config file\nLoaded callback output of type stdout, v2.0\nPLAYBOOK: server.yml ***********\n3 plays in server.yml\nPLAY [Ensure necessary variables are defined] ******\nTASK [Ensure environment is defined] *******\ntask path: /Users/paul/GitHub/trellis/variable-check.yml:8\nskipping: [localhost] => {\"changed\": false, \"skip_reason\": \"Conditional check failed\", \"skipped\": true}\nPLAY [Determine Remote User] *********\nTASK [remote-user : Determine whether to connect as root or admin_user] **\ntask path: /Users/paul/GitHub/trellis/roles/remote-user/tasks/main.yml:2\nESTABLISH LOCAL CONNECTION FOR USER: paul\nlocalhost EXEC /bin/sh -c '( umask 22 && mkdir -p \"echo $HOME/.ansible/tmp/ansible-tmp-1467039055.03-78956122214624\" && echo \"echo $HOME/.ansible/tmp/ansible-tmp-1467039055.03-78956122214624\" )'\nlocalhost PUT /var/folders/g4/db69vlp163s1fzhldrwdyh9m0000gn/T/tmpTbeKqv TO /Users/paul/.ansible/tmp/ansible-tmp-1467039055.03-78956122214624/command\nlocalhost EXEC /bin/sh -c 'LANG=en_GB.UTF-8 LC_ALL=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 /usr/bin/python /Users/paul/.ansible/tmp/ansible-tmp-1467039055.03-78956122214624/command; rm -rf \"/Users/paul/.ansible/tmp/ansible-tmp-1467039055.03-78956122214624/\" > /dev/null 2>&1'\nok: [xxx.xxx.xxx.xxx -> localhost] => {\"changed\": false, \"cmd\": [\"ansible\", \"xxx.xxx.xxx.xxx\", \"-m\", \"ping\", \"-u\", \"root\", \"--connection=smart\", \"--timeout=10\", \"--inventory-file=hosts\"], \"delta\": \"0:00:00.782153\", \"end\": \"2016-06-27 15:50:55.897881\", \"failed\": false, \"failed_when_result\": false, \"invocation\": {\"module_args\": {\"_raw_params\": \"ansible xxx.xxx.xxx.xxx -m ping -u root --connection='smart' --timeout='10' --inventory-file='hosts'\", \"_uses_shell\": false, \"chdir\": null, \"creates\": null, \"executable\": null, \"removes\": null, \"warn\": true}, \"module_name\": \"command\"}, \"rc\": 2, \"start\": \"2016-06-27 15:50:55.115728\", \"stderr\": \"\", \"stdout\": \"\\u001b[0;31mxxx.xxx.xxx.xxx | FAILED! => {\\n    \\\"changed\\\": false, \\n    \\\"failed\\\": true, \\n    \\\"module_stderr\\\": \\\"\\\", \\n    \\\"module_stdout\\\": \\\"/bin/sh: 1: /usr/bin/python: not found\\r\\n\\\", \\n    \\\"msg\\\": \\\"MODULE FAILURE\\\", \\n    \\\"parsed\\\": false\\n}\\u001b[0m\", \"stdout_lines\": [\"\\u001b[0;31mxxx.xxx.xxx.xxx | FAILED! => {\", \"    \\\"changed\\\": false, \", \"    \\\"failed\\\": true, \", \"    \\\"module_stderr\\\": \\\"\\\", \", \"    \\\"module_stdout\\\": \\\"/bin/sh: 1: /usr/bin/python: not found\\r\\n\\\", \", \"    \\\"msg\\\": \\\"MODULE FAILURE\\\", \", \"    \\\"parsed\\\": false\", \"}\\u001b[0m\"], \"warnings\": []}\nTASK [remote-user : Set remote user for each host] *****\ntask path: /Users/paul/GitHub/trellis/roles/remote-user/tasks/main.yml:8\nok: [xxx.xxx.xxx.xxx] => {\"ansible_facts\": {\"ansible_user\": \"admin\"}, \"changed\": false, \"invocation\": {\"module_args\": {\"ansible_user\": \"admin\"}, \"module_name\": \"set_fact\"}}\nTASK [remote-user : Announce which user was selected] ****\ntask path: /Users/paul/GitHub/trellis/roles/remote-user/tasks/main.yml:12\nNote: Ansible will attempt connections as user = admin\nok: [xxx.xxx.xxx.xxx] => {}\nPLAY [WordPress Server - Install LEMP Stack with PHP 7.0 and MariaDB MySQL] ****\nTASK [setup] *************\n ESTABLISH SSH CONNECTION FOR USER: admin\n SSH: EXEC ssh -C -vvv -o ForwardAgent=yes -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o User=admin -o ConnectTimeout=10 -o ControlPath=/Users/paul/.ansible/cp/ansible-ssh-%h-%p-%r xxx.xxx.xxx.xxx '/bin/sh -c '\"'\"'( umask 22 && mkdir -p \"echo $HOME/.ansible/tmp/ansible-tmp-1467039056.13-64090783706207\" && echo \"echo $HOME/.ansible/tmp/ansible-tmp-1467039056.13-64090783706207\" )'\"'\"''\nSystem info:\n  Ansible 2.0.2.0; Darwin\n  Trellis at \"Upgraded Ubuntu from 14.04 Trusty to 16.04 Xenial\"\n\nFailed to connect to the host via ssh.\nfatal: [xxx.xxx.xxx.xxx]: UNREACHABLE! => {\"changed\": false, \"unreachable\": true}\n    to retry, use: --limit @server.retry\nPLAY RECAP ***********\nxxx.xxx.xxx.xxx               : ok=3    changed=0    unreachable=1    failed=0\nlocalhost                  : ok=0    changed=0    unreachable=0    failed=0\n```\nwhich makes me think the geerlingguy/ubuntu1604 box has been patched to add the python package. I've tried using the ubuntu/xenial64 box before but Ansible tries to connect with ubuntu as the user using a password so I quickly switched back to the geerlingguy version.\n\nIn our Vagrantfile we support vmware_workstation and parallels providers too\n\nI'd completely overlooked these as I don't use them,  I could give the parallels one a go using their 14 day trial but I'd have to ask someone else to help with the vmware one\n. Thanks @fullyint , I can see why cli_options definitely needs to stay. I'll also check the return codes.\nI've just tried appending the cli_options to the raw module and had no luck. I might have to rethink how to install python on the first run.\n. Thanks both.\n@fullyint it was late and I wasn't sure if I was doing something wrong but the remote user role fails for me when I add cli_options to the raw command. I've added my log to the commit on your branch. I tested it on a droplet from DO whereas you mentioned AWS, could that have anything to do with it? I'm using Ansible 2.0.2.0.\nThere was no real reason I chose whoami other than needing a command to give to the raw module and it seemed fitting. I'm just about to give it a test (using AWS instead of DO) but is this a good use-case for failed_when? Either way I'm happy using ('root' in root_status.stdout_lines) if you both are (I have very little experience with AWS).\nI've started a checklist in the first comment \u2714\n. https://github.com/roots/trellis/pull/604/commits/c4a161788a65dab8c618d8cac9bf4b11c2d8493a switches to the bento/ubuntu-16.04 box and updates Vagrant requirements to 1.8.5 \nThe symlink for current isn't working so the site doesn't get installed\nfailed: [default] (item=example.com) =>\n {\"changed\": true, \"cmd\": [\"composer\", \"install\"], \"delta\": \"0:00:00.128909\", \"end\": \"2016-07-24 18:30:49.013855\", \"failed\": true, \"item\": \"example.com\", \"rc\": 1, \"start\": \"2016-07-24 18:30:48.884946\", \"stderr\":\n\"You are running composer with xdebug enabled. This has a major impact on runtime performance. See https://getcomposer.org/xdebug\nDo not run Composer as root/super user! See https://getcomposer.org/root for details\nComposer could not find a composer.json file in /srv/www/example.com/current\nTo initialize a project, please create a composer.json file as described in the https://getcomposer.org/ \\\"Getting Started\\\" section\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\nvagrant@example:~$ ls /srv/www/example.com/current/\nweb\nvagrant@example:~$ ls /srv/www/example.com/current/web/\nvagrant@example:~$\nSwitching from nfs to rsync (https://github.com/roots/trellis/pull/604/commits/9d96d54e2078198359f05b0c5c71965b4486ed9a) completes the site installation so there's an issue with NFS and vm.synced_folder \nI'll keep looking into it\n. I'm on the latest box \nvagrant box update\n ==> default: Box 'ubuntu/xenial64' (v20160725.0.0) is running the latest version\nRunning vagrant up works until\n==> default: Bindfs seems to not be installed on the virtual machine, installing now\n==> default: Creating bind mounts for selected devices\n==> default: Cannot bind to user 'vagrant' because it doesn't exist\n==> default: Updating /etc/hosts file on active guest machines...\n==> default: Updating /etc/hosts file on host machine (password may be required)...\nPassword:\n==> default: Running provisioner: ansible...\n    default: Running ansible-playbook...\nhowever the script carries onto the end and displays\n```\nTASK [wordpress-setup : Create web root] *********\nSystem info:\n  Ansible 2.0.2.0; Darwin\n  Trellis at \"Upgraded Ubuntu from 14.04 Trusty to 16.04 Xenial\"\n\nchown failed: failed to look up user vagrant\nfailed: [default] (item=example.com) => {\"failed\": true, \"gid\": 0, \"group\": \"root\", \"item\": \"example.com\", \"mode\": \"0755\", \"owner\": \"root\", \"path\": \"/srv/www\", \"size\": 4096, \"state\": \"directory\", \"uid\": 0}\n```\n```\nPLAY RECAP ***********\ndefault                    : ok=91   changed=66   unreachable=0    failed=1\nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\n```\n\ud83d\ude15 \nedit I was using VirtualBox Version 5.0.22, I'm updating to 5.0.26 now\n. It looks like the ubuntu/xenial64 box is missing the vagrant user. I've switched to geerlingguy/ubuntu1604 again and it's working fine with the vagrant user (https://github.com/roots/trellis/pull/604/commits/828e48a64232724396c47d12a8b0dca60f77ed25).\nHaving updated VirtualBox from 5.0.22 to 5.0.26 and pulled from trellis/master the bento/ubuntu-16.04 box is working without any issues for me (https://github.com/roots/trellis/pull/604/commits/40c0ce3106fc4dc13d325312af9eb7187264bc8b).\nI could\n- [ ] tidy this up and use the geerlingguy box\n- [ ] tidy this up and use the bento/ubuntu-16.04 (has parallels and vmware boxes)\n- [ ] add the vagrant user to the ubuntu/xenial64 user (somehow)\nMy preference is the bento box\n. Thanks @swalkinshaw, I was also making a mess of rebasing it last night \ud83d\ude05  so I pushed what I had with the intention of trying again today \n. ",
    "chriscarr": "Thanks for the note @ptibbetts, I got that added in there on Discourse.\n. ",
    "metaarts": "In my case it's coping the folder from the current release into the existent folder to the new release.\nexample:\ncp path_to_current/vendor path_to_new/vendor\ncreates path_to_new/vender/vendor/\n. ",
    "johnvh": "I'm seeing this too. I've got lots of nested vendor directories, 1 for every deploy I've made it seems:\nroot@tw-wp-prod-web-1:/srv/www/thrivewire/current/vendor# pwd\n/srv/www/thrivewire/current/vendor\nroot@tw-wp-prod-web-1:/srv/www/thrivewire/current/vendor# find . -iname vendor -type d\n./vendor\n./vendor/vendor\n./vendor/vendor/vendor\n./vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\n./vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor/vendor\nI copied bedrock-ansible into my project a while ago - several weeks at least - so it's possible this has since been fixed.\n. I'm seeing exactly what OP @metaarts saw. Here's the output from an ansible deploy with -vvv:\nbash\nTASK: [deploy | Copy project folders] *****************************************\n<111.111.111.1> ESTABLISH CONNECTION FOR USER: web\n<111.111.111.1> REMOTE_MODULE command cp -rp /srv/www/thrivewire/current/vendor /srv/www/thrivewire/releases/20150710152511/vendor\nThis results in /srv/www/thrivewire/releases/20150710152511/vendor/vendor.\nMy version of Copy project folders step in roles/deploy/tasks/main.yml hasn't changed from what's in master now - https://github.com/roots/trellis/blob/8679312194dca96b3271fc1a1a886989e6bdde26/roles/deploy/tasks/main.yml\n. ",
    "saturday": "Would you like me to share the work I've done once I complete whatever is required to support Debian 7? By the way, I enjoyed the Changelog interview. It was timely for me.\n. @austinpray All I really did was change the mirror to mariadb.mirror.rafal.ca and updated the package url in roles/mariadb/main.yml to use debian instead of ubuntu:\ndeb http://{{ mirror }}//repo/{{ version }}/debian {{ mariadb_dist | default(ansible_distribution_release) }} main\nRegarding PHP, I'm using deb http://packages.dotdeb.org wheezy-php56 all instead of the ppa; however I'm running into an unmet dependency issue that I still need to look at.\n. I managed to get it working with Debian 7.6 with a one relatively major exception. I ran into an issue with xdebug and simply commented out that vendor role. I did all of this in a non-forked private repository, so I'll have to share the code at a later date (it's a relatively simple process).\nHere are the high-level steps without specific details:\n1. Update the MariaDB mirror and URL\n2. Update the php55-6 PPA to a deb package.\n3. Remove the xdebug role entirely - I'm going to revisit this issue shortly.\n4. Update Nginx PPA to use deb package.\n5. Create /etc/nginx/site-enabled\n6. Get composer via curl and move to /usr/local/bin. Remove default apt based install.\n7. Add apt_repository: repo=\"deb http://ftp.hosteurope.de/mirror/packages.dotdeb.org/ wheezy all\" update_cache=yes to the Memcache main.yml. Also, add force = yes to Memcache install task.\n8. Create /etc/nginx/sites-available\n9. Changephp5-fpm-wordpress.socktophp5-fpm.sock` in the wordpress.conf.j2 and php-fpm.conf.j2 files.\n. @retlehs This isn't a personal support request. Out of the box bedrock-ansible's deploy playbook expects the existence of a variable called 'site', which appears to never be declared anywhere.\n. My apologies. I meant the most recent commit from the master branch (I assumed they were related).\n. Perhaps the site variable should have a default value?\n. ",
    "dhuyvetter": "I am getting the same eror. \nI am using Ansible 2.0 (compiled from source using make deb, 2.0 is current unstable version) because if I install using the ppa:ansible/ansible repository, it only has version 1.9.1 which has a bug. When I try sudo apt-get install ansible=1.9.0.1 it doesn't have that version. And the official Ubuntu repository has 1.7.2, which is too old. Where can I find Ansible 1.9.0.1?\n. I tried sudo pip install ansible=1.9.0.1 but it throws an error: \n\nValueError: ('Expected version spec in', 'ansible=1.9.0.1', 'at', '=1.9.0.1')\n\nI got 1.9.0.1 source with git clone git://github.com/ansible/ansible.git -b v1.9.0-1 --recursive and built with make deb and that worked.\n. That should be git clone git://github.com/ansible/ansible.git -b v1.9.0.1-1 to get 1.9.0.1.\nhttps://github.com/ansible/ansible/releases/tag/v1.9.0.1-1\n. ",
    "sebastianneubauer": "I get this same error with the newly released version 2.0.0.0 on pypi...\n. ",
    "bbatsche": "Same. Fresh installs of Ansible 2.0 stable are giving me this error on both OS X 10.10 and Ubuntu 14.04\n. ",
    "roosterpark-porch": "Here's an example of where wordpress rewrites the url in the browser window. This can cause authors to be unable to create new posts in the event that there is a forward proxy rewriting URLs. \nThat issue is unrelated, but it is an example of the case I was indicating above\n/wp-admin/includes/misc.php\n``` php\nfunction wp_admin_canonical_url() {\n. \n.\n.\n    // Ensure we're using an absolute URL.\n    $current_url  = set_url_scheme( 'http://' . $_SERVER['HTTP_HOST'] . $_SERVER['REQUEST_URI'] );\n    $filtered_url = remove_query_arg( $removable_query_args, $current_url );\n    ?>\n    \n        if ( window.history.replaceState ) {\n            window.history.replaceState( null, null, document.getElementById( 'wp-admin-canonical' ).href + window.location.hash );\n        }\n    \n<?php\n}\nadd_action( 'admin_head', 'wp_admin_canonical_url' );\n```\nFull method for posterity:\n``` php\nfunction wp_admin_canonical_url() {\n    $removable_query_args = array(\n        'message', 'settings-updated', 'saved',\n        'update', 'updated', 'activated',\n        'activate', 'deactivate', 'locked',\n        'deleted', 'trashed', 'untrashed',\n        'enabled', 'disabled', 'skipped',\n        'spammed', 'unspammed',\n    );\n/**\n * Filter the list of URL parameters to remove.\n *\n * @since 4.2.0\n *\n * @param array $removable_query_args An array of parameters to remove from the URL.\n */\n$removable_query_args = apply_filters( 'removable_query_args', $removable_query_args );\n\nif ( empty( $removable_query_args ) ) {\n    return;\n}\n\n// Ensure we're using an absolute URL.\n$current_url  = set_url_scheme( 'http://' . $_SERVER['HTTP_HOST'] . $_SERVER['REQUEST_URI'] );\n$filtered_url = remove_query_arg( $removable_query_args, $current_url );\n?>\n<link id=\"wp-admin-canonical\" rel=\"canonical\" href=\"<?php echo esc_url( $filtered_url ); ?>\" />\n<script>\n    if ( window.history.replaceState ) {\n        window.history.replaceState( null, null, document.getElementById( 'wp-admin-canonical' ).href + window.location.hash );\n    }\n</script>\n\n<?php\n}\nadd_action( 'admin_head', 'wp_admin_canonical_url' );\n```\n. ",
    "zamber": "Would if I could. The problem is that no matter what authentication you would use (secure/insecure), you can't SSH to the VM to provision it. Tried changing timeouts on my side to no avail.\nFixing this requires changing the base box.\n. Had similar issues with VVV earlier but I didn't have time to investigate then. Soon after a friend recommended roots so I switched and hit the same issue again.\nI tested with different config.ssh.insert_key on ubuntu/trusty64 to be 100% sure, here's the log for both: https://gist.github.com/zamber/0a0acb6d3a01246b714a\n~~I'm not sure if this is because my machine does not advertise it's hostname.~~ It didn't advertise it correctly. I could ping it without issues but for some reason the DNS resolver on Ubuntu wasn't able to discover it, possibly due to port forwarding but I also tried to SSH to example.dev:22 and got the same symptoms. Had to fiddle around with dhcpcd and avahi to fix it. For future generations:\nhttps://bbs.archlinux.org/viewtopic.php?id=158609\nhttps://unix.stackexchange.com/questions/43762/how-do-i-get-to-use-local-hostnames-with-arch-linux\nRestarting dbus froze my machine and I had to manually remove duplicated NFS mounts, though this can be due to the fast that I copied over the repo for testing.\nhttps://wiki.archlinux.org/index.php/Avahi#Hostname_resolution this is probably the most concise and up to date steps to take on Arch.\nGetting back to this issue, setting this on every playbook seems reasonable. Also PermitRootLogin set to no is something that should be done by default on exposed servers. If you're pre-provisioning the roots/bedrock vagrant box with then I would skip it and just set UseDNS no. Vagrant logs in as root to the box on first run to set locally generated keys for SSH.\nChanging ports is not required as current configuration correctly forwards 22 to 2222 and aut0magically resolves any possible conflicts, so setting it manually could cause issues with that.\nMoreover this probably is a non-issue for other distributions (and MacOS) that are ready OOTB to use. Nevertheless having SSH by default rely on clients advertising their hostname is quite odd.\nNot sure if I should close this issue or if you guys want to take action on this?\n. How will this help when you can't ssh to the instance for provisioning when your host does not have its name advertised properly and UseDNS is defaulted to no? Or do you pre-provision the roots/bedrock box with ansible?\n. Can't test as I fixed the underlying issue with my environment. \n. ",
    "ltarasiewicz": "I'm sorry, I should have installed the dependancises specified in requirements.yml first - an oversight on my part:\nansible-galaxy install -r requirements.yml\n. ",
    "getdave": "That's great. Interested yes but not quite up to speed on Ansible. Could you outline the approach you would take so I can absorb the workflow?\nAlso noticed this can be installed via Composer now so maybe this approach would work?\nUpdate: it did work. Managed to get a Unit test running against \"Hello Dolly\". Questions:\n1. Best way to get composer to auto update/install on Ansible provision\n2. Best way to auto run the WordPress Unit Test setup steps on Ansible provision\n3. Best way to alias the PHPUnit inside of the Composer /vendor/ dir to be accessible via just phpunit\n. Agree with keeping it as a local dependency and updating PATH to include ./vendor/bin. Makes more sense. \nAnsible pros - what's the best method for updating PATH?\n. Ok possible change of plan. VVV seems to install Composer globally and updating on provision. This is also how PHPUnit recommends handling installation via Composer\nhttps://github.com/Varying-Vagrant-Vagrants/VVV/blob/develop/provision/provision.sh#L213\n. > What does VVV have to do with anything?\nJust an observation. Apologies if this was inappropriate.\n@swalkinshaw consider me convinced. I think perhaps it's better for you guys to handle this though.\nThanks\n. @nathanielks Ok i'm working on a PR\n. Ok opened a PR at\nhttps://github.com/roots/bedrock-ansible/pull/256\nProbably not up to your standards so please feel to tell me it's rubbish or make changes. Probably won't be able to look at this again for a few days.\nCheers\n. Hi both\nOk that's fine. I've raised this only on encouragement from others in the Issue tracker.\nIs there a general consensus that WordPress Unit Tests shouldn't be a core part of a setup for WordPress websites? \nMore than happy to move to a plugin role. If that's the case then I'd suggest we definately need a recommended plugins section in the README.\nAlso would someone consider adding a commit to the PR which adds phpunit to PATH? Couldn't wrap my head around it yesterday for some reason.\n. Ok thanks for the input everyone. So basically the consensus is\n1. We don't want this in core Trellis - move to a Ansible plugin\n2. We don't actually want WP Core Unit Testing FW at all\n3. We want flexibility to use whatever testing FW we want to use.\nIs that fair?\nAs a result of the above I'm not convinced this pull request is of any value beyond a proof of concept. \nOnly exception might be if there's some base configuration regarding having a out of the box \"test\" environment config that's separate from the application config? \n. ",
    "johnpbloch": "Since @austinpray was interested esoterically in my thoughts on this, I figured I'd weigh in, albeit a bit late to the thread.\nI tend to agree, personally, with @swalkinshaw regarding the use of the core testing framework to run plugin and theme unit tests. The tests may be called unit tests, and the SUT for any given test may be a \"Unit\", but they're really integration tests at heart. For true blue unit tests, you need to isolate your code as much as possible and both Brain Monkey and WP Mock are built for that purpose (disclosure: I help maintain and develop WP Mock as part of my role at 10up).\nThat being said, I think as much as possible we should be in the habit of not enforcing specific tools that we don't absolutely need to enforce. So whatever test runner, test helper, etc. a dev wants to use should be permitted as long as there's no real reason not to allow it. I don't think an environment management tool like trellis should be opinionated about such matters, personally. That's more in the purview of a CI server or plugin package.\nMy setup isn't really all that much to behold, but there's not a whole lot of intersection of concerns between deployment/environments and testing. Code that doesn't pass tests doesn't make it into master and code that's not on master doesn't get deployed. Plugin/theme tests run when I'm developing the plugin/theme, not when I'm editing the package versions in the site's composer.json.\nKeep on keeping on with the tests, though\u2014regardless of what anybody says about one method versus another. :fireworks: \n. ",
    "bezko": "sh.args = '.' works too , not sure which one is less ugly /vagrant//vendor or /vagrant/./vendor\nThis is just a band-aid, I think windows.sh is broken , $ANSIBLE_PATH is always an absolute path  ( as defined in the Vagrantfile) so /vagrant/${ANSIBLE_PATH}/vendor doesn't make much sens\n. @louim I'm not sure I understand the goal of this, windows.sh is looking for the location of itself relative to itself, isn't that always goint to be '.'?\nAnyone I've got an error : \n$ find -name 'windows.sh' -printf '%h' -quit\nfind: invalid predicate `-quit'\n. ",
    "mathew-c": "Some things I wanted to pass along:\n1. @austinpray WP-CLI will add those lines at the end of the wp-config.php file when executing the wp core multisite-install command. Unfortunately that doesn't work with the file structure put in place by Bedrock, without a way to pass the path to application.php along with the command -- something I don't believe exists in WP-CLI. A play with a shell script shouldn't have any issue cleaning it up.\n2. - \"*.example.dev\" in site_hosts leads to fatal DNS config issues when used to attempt a setup of development environment with Landrush - details here.\n3. --url=\"{{ item.value.env.wp_home }}\" is required to eliminate the HTTP_HOST errors.\n. @mAAdhaTTah Admittedly I've been working on the process without manually placing define('MULTISITE', true); or the other lines in config/application.php. I'll look over at WP-CLI, but your comment jogged something in my brain. I thought they had a scenario where they checked that constant or something similar when working on a multisite install, but I had thought it was further downstream.\n. Sure, I'll pull it out and tweak the references accordingly on the next two plays.\n. Thanks, glad to help. This afternoon/evening I've got a tweak on the changed_when as suggested by @swalkinshaw which i'll add in.\nEdit: sry, ran into some personal issues that delayed my tweak. Working to finish up.\n. There are two main issues involved here. One is the ownership/permissions of the first access.log and error.log files. The second is the failure of log rotation.\nInitial Log Ownership/Permissions\nWith examples from a clean install of Bedrock/Trellis/Sage/Soil, changing only the domain from example.com to logs.dev...\nThese are as expected. Immediately following vagrant up and vagrant ssh, \nvagrant@logs:~$ cd /srv/www/logs.dev/logs/ && ls -al\ntotal 8\ndrwxr-xr-x 2 vagrant www-data 4096 Oct  7 19:35 .\ndrwxr-xr-x 5 vagrant www-data 4096 Oct  7 19:35 ..\n-rw-r--r-- 1 root    root        0 Oct  7 19:35 access.log\n-rw-r--r-- 1 root    root        0 Oct  7 19:35 error.log\nThen poking the server via web browser a couple times...\nvagrant@logs:/srv/www/logs.dev/logs$ ls -al\ntotal 12\ndrwxr-xr-x 2 vagrant www-data 4096 Oct  7 19:35 .\ndrwxr-xr-x 5 vagrant www-data 4096 Oct  7 19:35 ..\n-rw-r--r-- 1 root    root     2799 Oct  7 19:36 access.log\n-rw-r--r-- 1 root    root        0 Oct  7 19:35 error.log\nFollowed by looking at the relevant running processes...\nvagrant@logs:/srv/www/logs.dev/logs$ ps -eo \"%U %G %a\" | grep nginx\nroot     root     nginx: master process /usr/sbin/nginx -g daemon on; master_process on;\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: worker process\nwww-data www-data nginx: cache manager process\nvagrant  vagrant  grep --color=auto nginx\nThe master process starts as root, so the logs are as well. There are ways to change this, both before and after the fact, obviously, but there is nothing unexpected here - although it may be unwanted in your eyes.\nlogrotate Not Functioning as desired\nContinuing with the same dev setup...\nForcing a logrotate with the original files results in \n...\nrunning postrotate script\nerror: error running shared postrotate script for '\"/srv/www/**/logs/*.log\" '\nSo I changed the postrotate script to\n[ -f /var/run/nginx.pid ] && kill -USR1 `cat /var/run/nginx.pid`\nas per this commit https://github.com/roots/trellis/pull/377.\nResults from forced logrotate...\n```\nvagrant@logs:/srv/www/logs.dev/logs$ sudo logrotate -vf /etc/logrotate.d/wordpress-sites\nreading config file /etc/logrotate.d/wordpress-sites\nHandling 1 logs\nrotating pattern: \"/srv/www/*/logs/.log\"  forced from command line (8 rotations)\nempty log files are not rotated, log files >= 52428800 are rotated earlier, old logs are removed\nconsidering log /srv/www/logs.dev/logs/access.log\n  log needs rotating\nconsidering log /srv/www/logs.dev/logs/error.log\n  log does not need rotating\nrotating log /srv/www/logs.dev/logs/access.log, log->rotateCount is 8\ndateext suffix '-20151007'\nglob pattern '-[0-9][0-9][0-9][0-9][0-9][0-9][0-9][0-9]'\nprevious log /srv/www/logs.dev/logs/access.log.1 does not exist\nrenaming /srv/www/logs.dev/logs/access.log.8.gz to /srv/www/logs.dev/logs/access.log.9.gz (rotatecount 8, logstart 1, i 8),\nold log /srv/www/logs.dev/logs/access.log.8.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.7.gz to /srv/www/logs.dev/logs/access.log.8.gz (rotatecount 8, logstart 1, i 7),\nold log /srv/www/logs.dev/logs/access.log.7.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.6.gz to /srv/www/logs.dev/logs/access.log.7.gz (rotatecount 8, logstart 1, i 6),\nold log /srv/www/logs.dev/logs/access.log.6.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.5.gz to /srv/www/logs.dev/logs/access.log.6.gz (rotatecount 8, logstart 1, i 5),\nold log /srv/www/logs.dev/logs/access.log.5.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.4.gz to /srv/www/logs.dev/logs/access.log.5.gz (rotatecount 8, logstart 1, i 4),\nold log /srv/www/logs.dev/logs/access.log.4.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.3.gz to /srv/www/logs.dev/logs/access.log.4.gz (rotatecount 8, logstart 1, i 3),\nold log /srv/www/logs.dev/logs/access.log.3.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.2.gz to /srv/www/logs.dev/logs/access.log.3.gz (rotatecount 8, logstart 1, i 2),\nold log /srv/www/logs.dev/logs/access.log.2.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.1.gz to /srv/www/logs.dev/logs/access.log.2.gz (rotatecount 8, logstart 1, i 1),\nold log /srv/www/logs.dev/logs/access.log.1.gz does not exist\nrenaming /srv/www/logs.dev/logs/access.log.0.gz to /srv/www/logs.dev/logs/access.log.1.gz (rotatecount 8, logstart 1, i 0),\nold log /srv/www/logs.dev/logs/access.log.0.gz does not exist\nlog /srv/www/logs.dev/logs/access.log.9.gz doesn't exist -- won't try to dispose of it\nrunning prerotate script\nrenaming /srv/www/logs.dev/logs/access.log to /srv/www/logs.dev/logs/access.log.1\ncreating new /srv/www/logs.dev/logs/access.log mode = 0640 uid = 1000 gid = 33\nrunning postrotate script\n```\nTaking a look at the files immediately after...\nvagrant@logs:/srv/www/logs.dev/logs$ ls -al\ntotal 12\ndrwxr-xr-x 2 vagrant  www-data 4096 Oct  7 19:38 .\ndrwxr-xr-x 5 vagrant  www-data 4096 Oct  7 19:35 ..\n-rw-r----- 1 www-data www-data    0 Oct  7 19:38 access.log\n-rw-r--r-- 1 root     root     2799 Oct  7 19:36 access.log.1\n-rw-r--r-- 1 www-data root        0 Oct  7 19:35 error.log\nThen poke the server some more...\nvagrant@logs:/srv/www/logs.dev/logs$ ls -al\ntotal 16\ndrwxr-xr-x 2 vagrant  www-data 4096 Oct  7 19:38 .\ndrwxr-xr-x 5 vagrant  www-data 4096 Oct  7 19:35 ..\n-rw-r----- 1 www-data www-data 4025 Oct  7 19:39 access.log\n-rw-r--r-- 1 root     root     2799 Oct  7 19:36 access.log.1\n-rw-r--r-- 1 www-data root        0 Oct  7 19:35 error.log\nDestroyed and rebuilt the vagrant machine, seeing the same successful results using the changed Trellis file.\n. Sorry for so much text, but I wasn't sure really sure on which things you'd find obvious and which you'd want to see more. Not intending to be pedantic at all.\n. Yes, the one I was going to suggest is to have Vagrant handle it. I'll test it and put in a pull request if you'd like. To my knowledge, there is no configuration that can be set in nginx to change the initial log file ownership and permissions. So, short of running nginx as a different user - and all the changes that would involve - Vagrant seems a straightforward approach to a fix.\n. I'll look at my notes, but as I recall the trailing slash was creating a redirect loop that was interfering with admin access to the primary site (only) for logged-in users with a subdirectory (only) multisite install.\n. Are you using the latest Trellis and following the instructions in the multisite wiki?\nYou need to add the multisite constants into config/application.php. If they are not added and Bedrock is in use, WP-CLI will stick the constants at the end of the wp-config.php file, which can lead to the error you are seeing.\n. UUOC award presented to the first commit. I humbly accept on it's behalf. :smirk: See above convo on the outdated diff.\n. Squashed it.\n. @louim Yes, that IP routing behavior is what I have been seeing/using.  \n@fullyint Landrush does not allow this config with a wildcard host:\nconfig.landrush.host host, PRIVATE_IP\nWhy? No idea. I didn't find anything in a cursory look through the Landrush docs or issues.\nThe fork where it doesn't fail that you linked configures Landrush/the Vagrant box in a different manner versus the method presented in the wiki. Among several things, it doesn't use site_hosts to generate the subdomains for Landrush/the Vagrant box - and therefore doesn't encounter the DNS armageddon that results. Instead it uses configuration code that seems more specifically adapted to its environments/needs.\nWhen I was testing things, it seemed to me that the most basic choice was between removing the wildcard from site_hosts and leaving the wiki as is on one hand or using the wildcard and significantly reworking the Landrush configuration code on the other. As my Landrush experience is minimal, I went with the former - but perhaps another approach is better/more elegant?\n. No, if you use service nginx reload won't work completely. The new worker processes will log to the correct file(s), but the old worker processes won't. They'll continue to use the old log file(s) as long as they hang around.\nIt won't be much of a discrepancy, but it is there. The busier the site, the bigger the discrepancy.\n. Thanks for the reference @louim. I'll clean up the syntax.\n. Or..... I can ask for input. strace does indicate a performance benefit to read pid < file versus cat file. However, after trying everything I can think of to get the command working inside /etc/logrotate.d/wordpress-sites, I'm stuck with variations along the lines of this...\nPIDfile=\"/var/run/nginx.pid\"\n    if test ! -f $PIDfile\n    then\n      read nginxPID < $PIDfile\n      kill -USR1 $nginxPID\n    fi\nor other similar. All attempts I've tried to get $(<\"/var/run/nginx.pid\") working with the kill command haven't found success. Not sure if it's an issue with syntax or what, but only works if I split it into two lines (read then kill) and explicitly use read. Depending on what I've tried I get either nothing at all (no error/no successful kill command) or permission denied errors.\nAny thoughts?\n. @louim Thanks for looking at it. I can get it to work outside ok, but for some reason that is eluding me it's failing inside, including on fresh installs. FWIW, a simple echo as opposed to kill fails inside as well - no output.\n. I'll test it out. I had seen a minor reference to it at Stack Exchange when I initially looked at the issue, but I stuck with the kill command based-solution I'd used before.\nAccording to Nginx Essentials [ that's a clean link, not an affiliate one ] on p.40, rotate sends a USR1 signal, so it should be good. \n. Tests work nicely. Good catch, @louim. Command even adds brings a nice message to logrotate -d: * Re-opening nginx log files nginx.\n. ",
    "rohmann": "I was having similar issues working with Bedrock a while back (when it still came with Capistrano ).\nThe problem is that both the WordPress multisite installation process AND wp-cli rely heavily on the is_multisite function. Have a look, and you can get an idea why setting the constants in advance is problematic: https://github.com/WordPress/WordPress/blob/master/wp-includes/load.php#L721-L736\nUnfortunately, because WordPress uses them for decision making during the install process, we need a way to control that. I'd propose updating the wiki, (and possibly even Bedrock) to something like:\ndefine('WP_ALLOW_MULTISITE', true);\nif (getenv('MULTISITE_INSTALLED')) {\n  define('MULTISITE', true);\n  define('SUBDOMAIN_INSTALL', getenv('SUBDOMAIN_INSTALL'));\n  define('DOMAIN_CURRENT_SITE', getenv('DOMAIN_CURRENT_SITE'));\n  define('PATH_CURRENT_SITE', '/');\n  define('SITE_ID_CURRENT_SITE', 1);\n  define('BLOG_ID_CURRENT_SITE', 1);\n}\nThe trick would be fact-checking for the MULTISITE_INSTALLED env variable. The  wp core is-installed command has a --network flag, but it's not much use because it relies on the is_multisite function which will not be returning true at this point.\nWe could check for the presence of any of the multisite tables though. For example, running...\nwp db tables | grep -i sitemeta\n...should give output if the {$prefix}_sitemeta table exists, proving Multisite has installed it's tables.\nI'm still getting familiarized with Ansible, so I don't have a working example. If I have time in the next few weeks I'll explore further, but definitely wanted to share my thoughts so far in case it helps anyone in their experimenting.\nEDIT: Oh, and this still doesn't solve the issue with wp-cli adding those wp-config.php statements....\n. haha sorry @alan-c I'm just now seeing your PR. Great stuff.\n. @kalenjohnson \nBatcache itself doesn't require any additional configuration. It just wants a working object-cache.php. Last time I used this one (https://github.com/ericmann/Redis-Object-Cache) it worked fine out of the box. I've also used this one (https://github.com/tillkruss/Redis-Object-Cache) but needed to modify it slightly.\n. @swalkinshaw \nMaybe this is too complicated, but what I prefer is having the micro cache at around 5s just as a frontline DOS protection. Then having batcache at around 30 minutes,  because the pages can be properly invalidated by actions like saving posts etc.\n. Indeed, and the severity of failure to invalidate varies from project to project. I've found it more useful than not just to keep those homepages nice and snappy.\n. What's nice about Batcache is that WP gets a chance to load first, so it aborts any caching if an authentication cookie is present. Then many plugins like WooCommerce make use of the constant DONOTCACHEPAGE popularized by W3TC and WP Super Cache. I've added that to Batcache manually to round things out a bit. Too bad WP doesn't really have a one size fits all solution (yet).\n. 4788\n3964\n. ",
    "jasperf": "Hey @nathanielks !  For people who are just getting started they would just run it in site.com and not site.com/trellis following the manual. Been using the script for a while now - and Linux  for years - so I move to the Trellis or Ansible directory. An extra clarification is nice I would say.\n. It would be good, but I do not have enough Ansible knowledge yet to know whether it would be hard to check for example that you forget to replace the example domain. Would be great to suggest in the error message that that might be at. But yeah, would be even greater to check whether there are any leftover example.coms. One thing I can see being an issue though is that I do not always use staging and that you would probably need to check all files loaded example.com data and in my case it would then stop as I did not change anything in the staging folder.. Looking for a great backup solution I finally bumped into this pull request. Seems like an awesome addition. Hope we can merge it soon. @MWDelaney 's suggestion for a category playbooks on Roots would be a great opportunity too. And a way to keep Trellis core clean while at the same time allowing playbooks to be displayed and supported at the same time.. Would really love to see this happening. Been working on a basic Ansible Playbooks package myself, but always considered using Trellis for Laravel as well. Seems like it is going to be possible now for Laravel as well as other CMS especially since Ansible 2.5 is out.. @fullyint Hope you will be able to give this implementation a spin soon. Would really be awesome to have Laravel implemented with Trellis. Sage and Laravel have more and more in common. Would be great to move Laravel further into the Trellis fold as well.. > Just a heads up but the main feature needed is only available in Ansible 2.7.\n\nWe can likely become 2.7 compatibility without too much difficulty, but it needs testing most of all.\n\nLet me know what testing can be done by Trellis fans like myself. I am up for it.. ",
    "franzliedke": "Sorry to re-raise a dead thread, but I traced my issue back to this change...\nI recently spent multiple days trying to find out why I could not re-provision a new server with the command from the documentation, after I had successfully provisioned another server before. (This was when we were experimenting with moving our existing WordPress site to Trellis & Bedrock.)\nThe SSH authentication for the admin user would fail. It took me a long time to find out that I could rerun the command with the --user=root argument, which would then work.\nI have no clue about how Ansible works, but apparently it remembers \"facts\" across playbook runs (?). I assume that once it had set up the admin user for the original server, it remembered the fact that it could now use admin for logging in. For the new server, that user was not yet available, though.\nIs there anything that can be done about this? IMO, these facts should not be retained when provisioning a new server (with a new IP). At the very least, this should be mentioned in the documentation.... Great work. :+1:\nA silent upgrade to Ansible 2.4 means we can not deploy our site anymore. Took us a while to find out that the Ansible upgrade was the problem.. Great, thanks! Can we get a new release as well? :innocent: . ",
    "builtbylane": "for those stumbling in late, roots trellis now supports letsencrypt : https://roots.io/trellis/docs/ssl/#lets-encrypt\n. ",
    "ascottmccauley": "I incorporated the changes here, and am still getting the error: Notice: Constant MULTISITE already defined in /srv/www/test.com/current/web/wp-config.php on line 11, because of the is_multisite problem. Is there something else that I might be missing?\n. @kalenjohnson, Right. Forgot that was a holdover from trying everything else under the sun to get multisite to work.\n. ",
    "drumba": "@kalenjohnson I tested the multisite subdirectory deployment to remote DO and it is not working for me. I always get a Database Connection error. The tables are created. On the VM everything is working fine. I think there is still some strange thing in the configuration.\n. ",
    "MWDelaney": "Just a quick note for anyone who found this issue from Google like I did! I put this together last night. It's preliminary and probably ugly, but it works. Contributions are welcome!\nhttps://github.com/MWDelaney/trellis-backup\n. That error looks more like a yml formatting issue than a configuration issue. Does it work with a simpler target like local?\n. I had a server eat itself recently because I didn't have purge working correctly and it used up all the free space. I think purge is important. Maybe daily backups until there's a werk's worth, and then weekly until there's a month, and then monthly for... however long? Purging as you go after each checkpoint is reached?. I know @swalkinshaw said they'd be willing to look at this as a feature, but I wonder if it would make sense to maintain the backup playbook as a sort of \"recommended\" or semi-official add-on to the Trellis core project. \nThere are other projects that could fit in such a category --playbooks that are widely useful but not strictly within Trellis' project scope. I'm thinking here of Ben's database push/pull scripts, and media push/pull scripts I've seen around. There might be an opportunity to \"make official\" (and focus development and support time on) a list of add-ons for Trellis, the way Gravity Forms and WooCommerce officially promote 3rd party add-ons.\nJust a thought. . Roots has an aesthetic theme to its naming, so additional playbooks could be called \"seeds\", and \"how-to\" recipe type info could be called \"guides\".. Is it feasible to, by default, allow access to directories that follow WP's \"year\" naming scheme and deny access, except from the current site's referrer, to all others? Presumably this would solve some of the injection issues without breaking, say, Sage caching of Blade templates. \nThis issue got me in big trouble today when Formidable Forms cheerfully let me know that its upload directory was protected when, in fact, it wasn't. \nBlocking access except from by the site itself at least resolves the majority of file and URL injection issues presented. \nI would love to contribute to a PR but this stuff is way over my head :(. The most wordpressy way to handle it would seem to be custom 404. Google prefers that, too. . No method is described in this thread. This is a pull request which was merged into Trellis a year ago.\nLikewise no error is described in this thread so I don\u2019t know what you mean by \u201csame error\u201d. What error are you receiving?\nIf you need technical support, please post on our forum. . ",
    "partounian": "I apologize for asking a question on this closed issue, but does object caching even make sense when full page caching is in use already? Without distribution I don't believe it makes sense, but maybe I don't understand it fully.. I see. Wouldn't it make sense to be using APCu since this is a single server setup?. APCu is object caching, and it's just as fast as Redis. This is an interesting WP specific project with APCu as its base. https://github.com/lcache/wp-lcache/blob/master/readme.md. Lcache uses APCu, also if multi-server setup is allowed for Trellis, there would still need an option for single server. I think it would make sense to have APCu/Lcache for single server, and Redis for multi-server.. Hey @swalkinshaw , I would love to help take on this project. To be completely honest, I have never used config management until this project, but I'd love to learn and this would be a great task. \nHow can we start?. Thanks for the pointers! I'm excited, but that's also partially the redbull, I'll take a stab at this when I can and report back progress. Also, have you guys considered a Slack?.  I thought for docker it would be best to use docker machine and whatnot. Anyhow, I'm currently in the middle of a big project, but when I finish (July 1st-ish) I will start work on this.\nUpdate: Sorry for not working on this, I just haven't seen a usage yet after using Trellis for over a year. . I've done this with a few recent projects, really straightforward actually.\nI could write a tutorial or something.\nOn Mon, Feb 25, 2019, 5:58 AM pepijn-vanvlaanderen notifications@github.com\nwrote:\n\nThere is a forked setup for Laravel which I have used once where the\nplaybooks are separated and also a redis role is added. It is a bit\noutdated now compared to the current version of trellis, but worked\nproperly.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/536#issuecomment-467020595, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG_2pPm3iEHHnoQqkhr0VnnIlV0m0ks5vQ-wWgaJpZM4H7AjN\n.\n-- \n\nThank you,\nPatrick Artounian\n. Sorry to bother you, can you take a moment to review @guilro's updates? @swalkinshaw. Hey @discopatrick , any chance you could put in a PR for what's working so far, as you've mentioned. That way we can all appreciate and use the functionality you've added.. I found this https://github.com/10up/wp-hammer it might be useful for this task. Well I was thinking using this might make sense if we wanted to implement production to downstream sync we can use this tool to cleanup after export. @dheerajbhaskar. I would love to have this is in. @swalkinshaw How does that look?. Thank you both for the quick feedback. I have updated the commit accordingly.\n@swalkinshaw @QWp6t . @perifer Just to confirm the only changes you made were having an empty username in group_vars/all/mail.yml and empty password in group_vars/all/vault.yml?  Or did you also change ssmtp_auth_method: in roles/ssmtp/defaults/main.yml etc?\nIf you did something to that maybe we should wrap AuthMethod={{ ssmtp_auth_method }} also.. @pySilver Close this issue if it's fixed. Also,  \n\nThis is not a personal support request that should be posted on the Roots Discourse forums. This is very helpful as I was going to modify the values directly myself. Quick question, what is the reason we use a 3rd party PHP 7.1 repo instead of the official one?. Any reason this wasn't merged?. This guide has some great tips and on top #2 it links a PPA you can use and dynamically link the brotli module which seems like a better idea than compiling. Note: I did not verify the PPA so there may be better alternatives.\nhttps://certsimple.com/blog/nginx-brotli\n\nEDIT: I feel dumb, somehow missed that he had this link listed in OP.. Yup I wrote that comment with that PR in mind but I never thought to link it, oops.. Do all CDNs even support brotli/static gzip? I feel this is probably the biggest issue to think about.. I think it would be good idea to only gzip updated files if that's easy to implement. While this doesn't seem standard and may seem weird, I think it's a solid idea. . By the way thank you for your work, if this gets merged I would definitely try it out for my current project.. One more thing, sage's build scripts run in build after right? That is run\nafter the trellis default build after and therefore wouldn't gzip compiled\njs and css files, we should probably do that at a later step.\n. Sorry dumb mistake on my part, just checked repo and it's set to build\nbefore. I have a relatively heavy repo, especially when it comes to css so\nI can run a test. \nEdit: I was also going to make that suggestion about the location block.. Sure, I can do it tonight, should I use a stopwatch or is there a more\naccurate method? Also we should probably have your function use gitignore\nfiles, maybe also support .ignore files.\nEDIT: Sorry can't do a time test today, I will have to look at that maybe this weekend. The site have other issues and can't throw this trial on top of it.. I am definitely a fan of profiling, maybe we should even have a separate PR to enable overall profiling as part of a debug mode.. This didn't work for me, I made the appropriate changes and it failed. Error message is so big it does not fit into terminal for me to say what it is. Only thing I can see is some errors like \ngzip: a: No such file or directory\\ngzip: friend.svg: No such file or directory\", \"stderr_lines\": [\"gzip: /srv/www/[redacted]/releases/20170817050730/web/app/plugins/agile-crm-lead-management/images/refer: No such file or directory\", \"gzip: a: No such file or directory\", \"gzip: friend.svg: No such file or directory\"\nScreenshots of git diffs: (only change besides this is turning on gzip_static)\nroles/deploy/defaults/main.yml\n\ntrellis/roles/deploy/hooks/build-after.yml\n\n. I ran this twice, first time is too 3 seconds, and second time 4 seconds. I opened the server and the .gz files are there. How can I confirm the server is serving these files?\nEdit: Sorry just realized deployment didn't provision nginx to allow gzip_static, but still don't see proof of it working. I tried this https://stackoverflow.com/a/3972634/5106821 \nEdit 2: Also the gzip_static should be enabled only in location tag for the specific file types as Scott mentioned earlier.. I suggest removing the dynamic module from this PR but just leaving your statement that is depends on #866. Also, if we are making gzip static why not brotli? . Just wanted to say Cloudflare has brotli on by default.. This is great! You are on a roll @TangRufus , this would be so useful for people like me who hopped on CloudFlare and realized they needed to add SSL for one more domain. I had to wait to propagate back to the original DNS, run commands, make sure everything is okay, then back over to CloudFlare. This might be a stupid question, but what happens if you move off CloudFlare, does your cert expire?\nEDIT: You should probably not make issues/feature requests if you will be creating PRs though, don't want to add clutter. \ud83d\udc4d . I see, looking over it again at the end it says.\n\nWhen pausing CloudFlare or gray-clouding individual zones, be aware that you and your visitors may receive errors in their browsers until you orange-cloud (reverse proxy) them again.. Any update @swalkinshaw ?. No worries, really appreciate your updates through!. Commenting on the PHP issue, is there a reason we use 7.1 instead of official 7? . Imo replace memcached with redis and/or APCu.. @TangRufus I actually don't use Redis. I use wp-lcache.. @TangRufus You have been doing some great work recently, any ideas? Or how did you setup your project(s)?. And just to confirm you create a second repo just for bedrock and the\nactual WP related stuff?. I believe it is -X ours not yours, I'll definitely follow Tang's plan\nin the future, it'd probably be a headache for my pre-existing ones.. @TangRufus Hey Tang, I've almost wrapped up a setup according to your specs, except I'm stuck on a nginx-includes situation. Basically I want to add location blocks to remote servers, in my case one file to do browser caching and another to disable logging for the favicon. \n\nI feel like browser caching should be added into Trellis and enabled when we enable cache. Thoughts? @swalkinshaw . Super sorry @swalkinshaw I was just reading other the tickets about browser caching, forgot that you have some concerns with browser caching.. @TangRufus I've been using your method for a current project and it works great. Two notes though. \nIt can be slightly simplified by your project's trellis having two remotes not three, one being origin and the second being your user's trellis. You would just keep project-template up-to-date and rebase off of that instead of roots remote.\nAnd the second one is a question. Any idea how to keep bedrock up-to-date without having to deal with merge conflicts for composer.lock?. Yup that's what I do. I know it's best practice to keep composer.lock in\nvc, but I wonder if it'll work fine without it being in vc. Especially\nsince it's wp packages and not anything with other Composer dependencies.\nOn Sun, Dec 3, 2017, 7:01 PM Tang Rufus notifications@github.com wrote:\n\ndeal with merge conflicts for composer.lock?\nYou don't. First resolve conflicts in composer.json, then $ composer\nupdate. Let composer generate a new composer.lock for you.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/883#issuecomment-348848791, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG0vR9isVNOYp62U5IAn_8HuayeBmks5s82CMgaJpZM4PSJjF\n.\n-- \n\nThank you,\nPatrick Artounian\n. Yup, that is what I thought. I actually always specify the exact version, as not all minor versions can be without breaking changes.. Why was this done?\nAsking for genuine curiosity, not_dev seems like a nice setup as everyone should have browser cache unless you have an edge case situation.. I think node and/or gulp are also missing from the Trellis VM.. I would love this as I am currently tearing up trellis to support my php app.. Done :). He doesn't mention it, and I assume they're just built with newer openssl\nversions with support for ALPN. But I haven't seen his reasoning.\nOn Sat, Dec 9, 2017, 8:58 AM Scott Walkinshaw notifications@github.com\nwrote:\n\nDo we know why he recommends it?\nI'm not sure it matters in our case since we're on Ubuntu 16.04 and using\nthe official Nginx PPA for the \"development\" version.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/928#issuecomment-350488955, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG8Cm2rCq2BfQWF3ZMEQWvFgA8X4zks5s-rwygaJpZM4Q1l2e\n.\n-- \n\nThank you,\nPatrick Artounian\n. But yes it is possible it doesn't matter because we're on 16.04 + mainline\nnginx.\nOn Sat, Dec 9, 2017, 9:00 AM Patrick Artounian partounian@gmail.com wrote:\n\nHe doesn't mention it, and I assume they're just built with newer openssl\nversions with support for ALPN. But I haven't seen his reasoning.\nOn Sat, Dec 9, 2017, 8:58 AM Scott Walkinshaw notifications@github.com\nwrote:\n\nDo we know why he recommends it?\nI'm not sure it matters in our case since we're on Ubuntu 16.04 and using\nthe official Nginx PPA for the \"development\" version.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/928#issuecomment-350488955, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG8Cm2rCq2BfQWF3ZMEQWvFgA8X4zks5s-rwygaJpZM4Q1l2e\n.\n--\n\nThank you,\nPatrick Artounian\n-- \n\nThank you,\nPatrick Artounian\n. Yes I am running it in production. I have run Trellis on multiple servers on different packages of DO, $5, $10, $15 and $20. Though haven't benchmarked or load tested anything though. They are client servers that I only work on every so often. \nHonestly, I might be overcomplicated/overthinking things as I have that bad habit, however if people are having scaling issues maybe we can have some general \"run these commands to find your bottleneck\" and then also what values to start adjusting.. Because it doesn't work with DNSCrypt, ipify is supposed to check the client's IP, but they block connections through DNSCrypt, or at least AdGuard's DNSCrypt servers.. @swalkinshaw Thoughts? We got 2 diff errors, but both are for using DNSCrypt, should we mention this in a troubleshooting section of some kind?. I would also love to help with this project as I've just converted another PHP (X-Cart 4) project to work with Trellis.\nA few things I'd like to know if we can implement are:\n1. Configurable PHP version\n2. WordPress as subdirectory\n3. Changing php try_files from $uri index.php; to $uri =404; \n4. Variable to main index and try_files. Example X-Cart 4 uses home.php and dispatcher respectively.. Is support for non-WP CMSes/custom projects something you are interested in @swalkinshaw?. What needs to wait until 2.5?\nCan't we do check using when or something else?\nThank you for considering this.. Ansible 2.5 is now available \ud83c\udf89 . @swalkinshaw link to main feature? I'm definitely interested in having with this. \nP.S. I've added redis support for a project, would you accept a PR for that? . Do you have a high level idea of how to implement such features? I'm down\nto take a stab at it all.\nOn Tue, Dec 11, 2018, 5:18 AM Scott Walkinshaw notifications@github.com\nwrote:\n\nansible/ansible#41330 https://github.com/ansible/ansible/pull/41330\nP.S. I've added redis support for a project, would you accept a PR for\nthat?\nProbably, but it would have to be optional.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/pull/951#issuecomment-446198842, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG1JGqHcJgLEDEUc7jqVIGBADdbqeks5u37CTgaJpZM4SW44g\n.\n-- \n\nThank you,\nPatrick Artounian\n. I've been running 2.7 without issues.. To implement the past few commits, do we just need to run deploy or do we need reconfigure the server with the ansible-playbook command?. In what cases does it make sense to enable background_update?. Then according to that article should we also consider the following?\nfastcgi_cache_lock on;\nfastcgi_cache_use_stale updating;\nAlso, currently fastcgi_cache_valid is set to 30s, should we specify 200 301 302 404 and possibly increase caching to 1m?. My mistake I only checked site config file and not the general nginx.conf. I vote for it being default behavior and replacing if item.value.cache.background_update with setting the value as {{ item.value.cache.background_update | default(true) }}. Even if we set it false we want an if check but a {{ value | default(false) }}. Hey @inthedeepend any chance you can update this with the fixes? I would love for this to be merged. \nIf you are not able to, I wonder what is etiquette for me to apply these changes.. I personally prefer all, or to just check in the root without any sitename. I kind of accidentally found it myself haha, but yes it works.. I don't think so as I've trouble with Cloudflare and Trellis unless it\nchanged recently?\nOn Tue, Mar 13, 2018, 6:03 PM Scott Walkinshaw notifications@github.com\nwrote:\n\nI'm a little rusty on LE stuff, but I'm pretty sure this is exactly what\nTrellis is already doing.\nIf you\u2019re running a local webserver for which you have the ability to\nmodify the content being served, and you\u2019d prefer not to stop the webserver\nduring the certificate issuance process, you can use the webroot plugin to\nobtain a certificate by including certonly and --webroot on the command\nline.\nThe webroot plugin works by creating a temporary file for each of your\nrequested domains in ${webroot-path}/.well-known/acme-challenge. Then the\nLet\u2019s Encrypt validation server makes HTTP requests to validate that the\nDNS for each requested domain resolves to the server running certbot.\nConfirmed, this is what Trellis does :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/967#issuecomment-372870131, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACbIG9lr5E0FU1JWjAk2gYf9ELoS9gS8ks5teGxngaJpZM4SpYPS\n.\n-- \n\nThank you,\nPatrick Artounian\n. @mikaelwedemeyer I currently use the self-signed solution also, but an LE cert would with Full (Strict) on CloudFlare would warm my heart. I am currently looking into how things are/how a fix would be implemented and one thing I noticed so far is the repo we copied has changed from using acme-tiny to using dehydrated which supposedly has more features, is strongly recommended and can remove(?) python as a dependency. \nhttps://github.com/andreaswolf/ansible-role-letsencrypt\nhttps://github.com/andreaswolf/ansible-role-letsencrypt/commit/83d9710043ef54727ab5495d4355469dd40cbf08\nEdit: I think it is appropriate as this isn't personal support but rather fixing LE for all CloudFlare users.\nEdit 2: This might be why CF doesn't work \ud83d\ude43  https://github.com/diafygi/acme-tiny/pull/68 and https://github.com/diafygi/acme-tiny/issues/11\nIn short, problem is because acme-tiny doesn't send a User Agent and CF blocks that, you can disable that security feature, it is called Browser Integrity Check. We can also selectively disable it by using a Page Rule, I will test this on the URL /.well-known/acme-challenge which should fix it. Would love if others can test this also.. I think self-signed is better because it doesn't involve going to CloudFlare and you can't Origin CA enforcement is per domain right? So if there is a subdomain that doesn't want to use origin CA you can't do origin ca verification.\nThough I do plan on looking into a solution for support CloudFlare with Trellis & LE.. > Question: Why do you prefer using letsencrpyt rather than cloudflare origin ca?\n@TangRufus \nOn a high level if LE worked with CF then it would be easier to use than adding the origin-ca module, and it would be a \"real\" cert.\n. Just an update for others, I have been using CF Origin CA for some time now thanks to @tangrufus's trellis package.. Don't break master @swalkinshaw \ud83d\ude09 haha . Maybe we should add a little command to run dist upgrades?. @swalkinshaw\nbash\nsudo apt update \nsudo apt upgrade\nsudo apt dist-upgrade\nsudo apt autoremove\nsudo apt install update-manager-core\nsudo do-release-upgrade. Seems like a good thing to merge. @swalkinshaw did you look at the post in the edit?. I feel like there must be better script for this, specifically the first part. \nThese links might help https://stackoverflow.com/a/9067042/5106821 , and https://unix.stackexchange.com/a/47987/210518 . Also, does it make sense to use --force for gzip?. Misspelling, it should be \"quoted,\" but I feel like we should just remove the comments and nginx_gzip_static option. Simply set gzip_static to on if gzip_static_assets_on_deploy is set to true. Thoughts?. PPA is already set to this at the top of this file. So I would just remove any of your work for adding adding a deb-src but the rest looks okay.. Sorry I didn't actually test these.. Indentation is off . forgot the semi-colon at the end. Also should this be in the cache_config block?. ; is still missing . \ud83d\udc4d . ",
    "Kimisyl": "@swalkinshaw Fixed and rebased.\n. ",
    "brocheafoin": "@swalkinshaw :\n\nAnyone who wants to help on this PR can run this command and paste the results\n\nAs is mentioned in https://gist.github.com/magnetikonline/11312172, which you referenced later:\n\nNote these are going to report on all access requests with a 200 return code, you might want to split out just FastCGI requests into a seperate Nginx access log for reporting\n\nFWIW, here's the result on a site I'm currently working on:\n\n6520\n\nOn said site, some requests were failing with: upstream sent too big header while reading response header from upstream until I set the fastcgi_buffers to 8 8k.\n. @swalkinshaw That's what I tried at first, but I got this error:\n\"fastcgi_busy_buffers_size\" must be less than the size of all \"fastcgi_buffers\" minus one buffer in /etc/nginx/nginx.conf:128\nso I also changed fastcgi_buffers and things worked. I then completely removed the fastcgi_buffer_size directive and only kept  fastcgi_buffers 8 8k; and things kept working. I'm a bit over my head with this kind of configuration, but I can run various tests if you think it will help.\n. > State is passed via cookies from one request to the next, but never to subsequent requests.\nSource: https://github.com/Automattic/jetpack/blob/60e10e5a9964773bc307bb5893a507c36d30b158/class.jetpack.php#L5082\nI guess it's just that there is a lot of state to pass at the end of this particular process.\n. Fair enough. I'll amend the PR as soon as I find the time to test it correctly.\n. > you can also simply enable SSL on your local dev to get .dev working\nIn case anyone reads this later on, I don't think this would work. SSL on your dev machine will be self-signed. HSTS errors on Chrome 63+ don't allow you to \"continue anyway\". In theory, you could add the self-signed certificate in your trust store, but I haven't been able to get Chrome to agree with my trust settings when an HSTS error occurs. So your best bet is still to stop using .dev as a TLD for local development.. I added the following line here:\nrewrite ^/(xmlrpc.php)$ /wp/$1 last;\nor else XML-RPC-dependent stuff (Jetpack authentication, in my case) was not working. Can submit a PR if you want. Thanks for all your hard work!\n. Yeah, probably not exactly related to fixing multisite, then. Please disregard.\n. ",
    "rposborne": "+1\n. ",
    "scherii": "Please feel free to tell me that I should open a new issue if this doesn't belong here:\nWith this change we now have to enter the domain name instead of the server's IP.\n./deploy.sh alpha alpha.domain.tld\nTASK: [Ensure site is valid] **************************************************\nfailed: [XXX.XXX.XXX.XXX] => {\"failed\": true}\nmsg: Site `alpha.domain.tld` is not valid. Available sites to deploy: beta.domain.tld\n(Our staging stages are named alpha and beta.)\nSo our host files look like this:\n```\n[beta]\nbeta.domain.tld\n[web]\nbeta.domain.tld\n```\nAfter replacing the IP with the domain name it works again.\n. I think .test is the best available option.\nOthers (like .localhost or .local) all have some sort of conflict.\n. Please excuse me for asking, but have you checked these two resources?\n- [ ] https://roots.io/trellis/docs/deploys/#ssh-keys\n- [ ] https://roots.io/trellis/docs/ssh-keys/#cloning-remote-repo-using-ssh-\n  agent-forwarding\nIt seems to me like this is a (local) configuration error \u2013 and not a Trellis bug.\n. Could close #809 . @TangRufus With this method you'd specify the canonical domains in the wordpress_sites dict. And if I understood your question correctly you'd put the redirects in there as well. But this depends on the use case and has nothing to do with generating self-signed certificates. \ud83d\ude42 . In this case I'd propose to add both site.com and www.example.com to the canonical domains.\nI might be wrong \u2013 any other opinions?. Please use https://discourse.roots.io/c/trellis for support. GitHub issues are for bug reports and feature requests only, as stated in the template you deleted. \ud83d\ude0f \ud83d\ude09 . ",
    "mxxcon": "I'm sorry if this was discussed somewhere earlier, but why are you completely moving some variables into vaults?\nI'm sure many of you already read https://www.reinteractive.net/posts/167-ansible-real-life-good-practices Why not use structure similar to shown there?\nFor example: in group_vars/production/wordpress_sites.yml you remove almost every single record related to database info.\nWhy not instead keep the current structure but assign variables to their vaulted counterparts:\ndb_name: {{ vaulted_db_name }}\n      db_user: {{ vaulted_db_user }}\n      db_password: {{ vaulted_db_password }}\nAnd then your vault.yml will contain\nvaulted_db_name: wp_myblog\n   vaulted_db_user: wp_myblog_user\n   vaulted_db_password: password123\nThis has the benefit of minimizing change to playbooks and keeps existence of variables more discoverable, while still getting the benefit of ansible-vault. And if a user decides not to use vault, they can just simply replace {{ }} values with plain text.\n. I see. I have not fully grokked trellis yet, so I'll defer to you guys since you are more familiar with its challenges. :smiley: \n. @swalkinshaw why not? Do you not consider these to be sensitive?\nSpeaking of sensitive info, unless I'm misunderstanding this, is it proper for group_vars/all/vault.yml to contain vault_sudoer_passwords.admin variable? Shouldn't it be unique per environment(dev/stage/prod), if not even unique per host?\n. According to https://letsencrypt.org/2015/11/12/public-beta-timing.html\n\nLet\u2019s Encrypt will enter Public Beta on December 3, 2015. Once we\u2019ve entered Public Beta our systems will be open to anyone who would like to request a certificate. There will no longer be a requirement to sign up and wait for an invitation.\n. @swalkinshaw however, that got me thinking...if letsencrypt renewal process will happen only with Ansible, it won't renew if I don't have any deploys during the lifetime of a cert. Don't forget that these certs are only 30-90 days in age.\n. Thank you @louim. Missed that one.\n. @swalkinshaw squashed as requested. :dancer: \n. \n",
    "joshrickert": "Seems more practical to use LetsEncrypt for the live server and a self-signed cert for the development VM.\n. It's probably better for the ecosystem to submit a PR addressing the related issue in ansible-letsencrypt and then integrate that project as a dependency here.\n. I gave it another shot today (with the default config) and Ansible ran successfully. It's probably an intermittent connectivity issue, either on the provider's end or mine.\nI couldn't get any of the alternative services I mentioned working consistently either yesterday. If I spammed the curl command into my console I saw failures in maybe 1/10 cases.\nI'll close this for now, but at least it's documented in case anyone else has issues in the future.\n. Nice work on the quick fix, gentlemen.\n. @austinpray I hope you mean all platforms as a fallback. It's still convenient to use the host Ansible as the primary provisioner.\n@geerlingguy also noticed that there are is a minor downside to the new ansible_local provisioner: Since it re-runs ansible-galaxy install every time it runs, it makes the provisioning process take a bit longer. This issue would address that.\n. Also since Ansible on the host is a dependency anyway for the staging/production deployments.\n. To avoid the issue that @swalkinshaw points out, it may be better to continue the current workflow where the user installs Ansible on their host machine during the setup process, but it could become an optional step for those who don't intend to deploy using Trellis.\nSo, the pros of switching to the ansible_local provisioner exclusively:\n1. We simplify the Vagrantfile and improve maintainability.\n2. Installing Ansible on the host may become an optional step for those who aren't using it to deploy\nThe downsides are:\n1. Longer provisioning time while ansible-galaxy install runs, though we could mitigate that by continuing to run ansible-galaxy install on the host during the setup process (instead of on the guest), but then we have to add some extra configuration to make those roles available to Ansible on the guest. Unfortunately, that nullifies both of the pros above. The permanent solution would be to help Ansible make that command idempotent so that it runs quickly after the first installation.\n2. Ansible becomes extra software installed on the Vagrant VM, which some power users may not like. This personally doesn't bother me too much, for what it's worth.\n. @cfxd Access denied as my admin_user account. If I log into the root account, both commands run without issue.\n. ",
    "erikbelusic": "hey all,\ni was just thinking about this a bit. i am a laravel forge user, and the way taylor seemed to attack this is that he has a monthly cron that updates the cert. maybe we can add a flag to one of the configuration files for \"usesLetsEncrypt\" and when set to true it provisions with an additional cronjob that can go out and renew + install the new SSL cert\n. ive used the following block before on a laravel app without issue:\nnginx\nlocation ~* /uploads/.*\\.php$ {\n    deny all;\n}\nsome other resources suggest the following:\nnginx\nlocation ~* /(?:uploads|files)/.*\\.php$ {\n    deny all;\n}\ni am not a regex person, so im not exactly sure what (?:uploads|files) does....\nthoughts on which of the three is the best?\n. yup! im not familiar with multisite setups too much, so im not sure if something else is needed. does (does bedrock/trellis support multsite fully?).\nlastly, do we want to just do /app/uploads/ or do we want to also consider the case where a user is not using bedrock (if this is even possible with trellis)\n. i do not believe that the cron is working. i have a backup plugin thats supposed to run once a day and it hasn't ran. it could be a plugin issue.\ni have found the file in the cron.d folder and it looks to be set up correctly. is there a log for the cron that i can look at to see if its being run successfully or not? or should i write something dumb in a wordpress plugin that sends me an email when the cron runs?\n. i have found the issue! i am using a self signed certificate and the curl request is failing. is there an appropriate way to add the -k flag to my cron via trellis, rather than editing the cron directly?\n. Which route do you think you want to go? I have no problem helping out. Especially since u guys did all this awesome work for the community this far =]\n. @swalkinshaw @austinpray - my findings thus far...\nWORKING: (same command)\ncurl --insecure https://mysite.com/wp/wp-cron.php\nOR\ncurl -k https://mysite.com/wp/wp-cron.php\nALSO WORKING:\ncurl --cacert  /etc/nginx/ssl/mysite.com_self_signed.pem https://mysite.com/wp/wp-cron.php\nNOT WORKING:\ncp /etc/nginx/ssl/mysite.com_self_signed.pem /usr/share/ca-certificates\nfollowed by\ndpkg-reconfigure ca-certificates\nfollowed by choosing \"ask\" presents a list of certificates, however the self signed certificate does not appear. i may have did something wrong though... not sure\nout of the two above options, the --cacert flag looks like the best option because it explicitly allowing our self signed certificate whereas the other --insecure or -k flag will allow any connection with an untrusted certificate.\nwe should check for a self signed cert and alter cron command to include the --cacert flag with the path to the self signed cert.\ni am not exactly sure how to do this. i know control structures aren't supported in .yml files, but i see you can trigger different tasks conditionally using the when directive within ansible. i could use some guidance here....\n. ill give it a shot and see if i can make it work.\n. i am not completely understanding register the Generate self-signed certificates task as a variable and check if its defined in the cron task. where would that be done? in the group_vars or else where?\nwhat i am currently thinking is that in the existing cron task, we can check if ssl: true and key and cert are both undefined and add on the --cacert flag that way, but it does look quite messy.\nruby\n{% if item.value.ssl is defined and item.value.ssl and item.value.ssl.key is not defined and item.value.ssl.cert is not defined %}\njob=\"curl -s --cacert /etc/nginx/ssl/{{ item.key }}_self_signed.pem {{ item.value.env.wp_siteurl }}/wp-cron.php\"\n{% else %}\njob=\"curl -s {{ item.value.env.wp_siteurl }}/wp-cron.php\"\n{% endif %}\ncurrently untested\n. done and done! i shouldn't have did this on my master branch though....right? i should have made a feature branch?\n. @swalkinshaw i have not done it before. please provide guidance =]\n. @swalkinshaw i think i got it. let me know if it turned out correctly.\n. @swalkinshaw  now that this has been merged, can i delete and refork to make any additional contributions on feature branches without messing this up?\n. ",
    "mattmcgiv": "Was looking into this issue this morning and came across a Digital Ocean article for using Let's Encrypt w/ nginx.\nFor anyone interested, this section in particular seems relevant to creating the cron job to renew the cert\n. ",
    "vdrnn": "I wonder if anyone is already working on this? \nOtherwise I could try to implement it. However, I'd need some guidance since I'm lacking of Ansible knowledge but eager to dig into it. \nI guess the way to go is to work with ansible-letsencrypt?\n. Yep, ran into the exact same issue after updating an existing installation. \nIt goes through with @henkler's proposition {{ wordpress_env_defaults | combine(wordpress_sites[site].env, vault_wordpress_sites[site].env) | to_env }}\n. Seems like this is a acme.sh specific problem. I stumbled upon this issue but doesn't get me any further for now https://github.com/Neilpang/acme.sh/issues/1112. ",
    "jnsq": "Reproduced too. I just added this task\n- name: Install php5-mysqlnd extension to fix Wordpress Installation \n  apt: name=php5-mysqlnd state=present force=yes\nafter the Install HHVM task in the hhvm role, and this also fixed the issue for me.\n. ",
    "storm2k": "The version is from July-ish, I cloned whatever was the latest version at the time, set it up following the example project structure.\n. ",
    "thedgbrt": "I remember in an earlier version of the repo the instructions said\nYou should now have the following directories at the same level somewhere:\n- bedrock-ansible/\n- example.dev/\nI think that's why I associate the folder name with the name of the repo.\nExample of previous readme here https://github.com/dagobertrenouf/trellis/blob/297d5bee4c225bdb3ea10d4912815518d23942a5/README.md\n. @swalkinshaw added @austinpray suggestion. Let me know if I need to do something more (like squish all commits in one? I'm not sure). \n. @swalkinshaw done ;)\n. Yep, will do over the weekend\n. Will only be able to do this week after all.\n. ",
    "redconfetti": "I think I just discovered a discrepancy.\n$ vagrant ssh -- -v\nOpenSSH_6.2p2, OSSLShim 0.9.8r 8 Dec 2011\ndebug1: Reading configuration data /Users/redconfetti/.ssh/config\ndebug1: Reading configuration data /etc/ssh_config\ndebug1: /etc/ssh_config line 20: Applying options for *\ndebug1: /etc/ssh_config line 102: Applying options for *\ndebug1: Connecting to 127.0.0.1 [127.0.0.1] port 2200.\nIt's using port 2200 when the 'sshd' role isn't applied. With the role applied, vagrant ssh attempts to use port 2222. I noticed that during the build that isn't failing it includes:\n==> default: Clearing any previously set forwarded ports...\n==> default: Fixed port collision for 22 => 2222. Now on port 2200.\nPerhaps there is some sort of port issue, collision with Mac OS X.\nI've updated Vagrant from v1.7.2 to v1.7.3 via Homebrew, and also updated Ansible to v1.9.3. Still not resolved. Works manually though on the alternative IP, but not on 127.0.0.1:\n```\nworks\n$ ssh vagrant@192.168.50.5 -p 2222 -i /Users/myuser/Projects/myproject/.vagrant/machines/default/virtualbox/private_key\nfails\n$ ssh vagrant@127.0.0.1 -p 2222 -i /Users/myuser/Projects/myproject/.vagrant/machines/default/virtualbox/private_key\nssh_exchange_identification: Connection closed by remote host\n```\n. Okay. I've found the solution to this issue.\nVagrant and/or Virtualbox sets up your workstations networking so that port 2222 is forwarded to port 22 of the virtual machine. If you explicitly add the configuration option sshd_port: 2222 to group_vars/development/main.yml, then SSHD is configured to answer on 192.168.50.5:2222 only, and the forwarder from 127.0.0.1:2222 to port 22 of the VM fails because SSH isn't listening on port 22 as expected.\nMake sure you do not configure your local development to use port 2222, the VM should answer on port 22 and let the virtualbox network configuration do the port forwarding.\n. @retlehs - You're right. I was using an outdated version of bedrock/web/wp-config. Thanks for pointing that out.\nvagrant@guesthost:/srv/www/mysite.dev/current$ wp option get home\nhttp://mysite.dev\nI'd recently copied over changes by hand for the files, must have missed that.\n. ",
    "soderlind": "Excellent, thank you!\n. ",
    "jameskraus": "A lot of plugins require write access to the web root to get full functionality. e.g. symlinking a db.php in place for query-monitor or W3TC. This might not work well for the majority of users. \n. ",
    "perifer": "Could it be an alternative to let security concerned users of Trellis opt out of having the web root owned by the same user that runs the PHP process?\n. @partounian only empty password and empty username!. ",
    "culturedsys": "You're right that the change I am proposing would interfere with plugins that want to write files outside of the uploads folder. What I've been doing myself in that situation is adding more entries to project_shared_children so that whatever directories the plugin needs get created with the right permissions at deploy time, but I can see that might be too low-level a solution make the default. \nQuite often, plugins that need to write files outside of the upload folder recommend that users temporarily give PHP write permissions to the wp-content (or, in Bedrock's case, app) directory, and then remove those permissions after the plugin has been activated and created whatever files or directories it needs. Perhaps this process could be automated, say with two additional ansible roles, one to relax permissions and one to tighten them up again. However, it might be difficult to get the tighten permissions role right; it couldn't just remove write permissions from the whole of the app folder, because of the case where a plugin creates a folder which it needs continued write permissions to (say, a cache folder).\n. ",
    "ismael-benitez": "Maybe you can get some errors with SEO plugins. E.g.: When it is generating the sitemap.xml or robots.txt.\n. ",
    "mindfullsilence": "EWWW Image Optimizer create a new folder in wp-content. \nWP Total Cache creates a new folder in wp-content\nMany redirect plugins write to htaccess, even WP core writes to htaccess under certain circumstances\nAs mentioned above, YEOST and others write to robots/sitemap\nCountless favicon generator plugins write favicon icons to the root dir, and if they write favicons elsewhere, they have to be able to write a manifest file to the root. (see real favicon generator as example).\nCan't think of others, but the above listed plugins are fairly heavily used in the community.\nPersonally I'm for @louim's suggestion of adding it as a configuration. Or add configuration options for creating exceptions to the hardening. Or both. Definitely foresee some pretty rough repercussions with setting it as default with no options to avoid hardening. . Confused as to why the ability to sync to production is off limits. Make a change in dev, test, sync dev to staging, test, sync staging to production. Is that the wrong approach? I suppose syncing via wp-sync-db to production is fine, but it's effectively the same as having a handy dandy terminal command to do the same from trellis. . I see where you're coming from. However it's pretty useful during the development stage when it comes time to launch, or when clients want to review prior to launch. Perhaps launching should be considered a separate concern as it only happens once in a blue moon (initial launch, and when changing servers or the like). \nI like the idea of having a variable for defining what is write-protected. This keeps the option of being able to rename what the production environment is called, or adding more environments should one ever need to. Or it could be as simple as a flag in the CI (thinking -f for \"force\" or similar). Spit balling here, but I'm certainly excited to see this playbook regardless.. Perfect! Thanks. What would the benefit of renaming each file with a .example extension be over renaming the folder group-vars-example or similar? Renaming the folder would be a lot less labor-intensive when kickstarting a project than renaming all group var files, though it does go slightly against the convention.. ",
    "visurel": "@austinpray I already did, thanks! :)\n. ",
    "mss": "I don't know if that PATH is required later on, if not I'd go for (1) and maybe put a file somewhere which user can source from their .bashrc. A full path would be better but could also be writable to non-root and would probably be a bit complicated with multiple installations on a single machine?\n. What about a feature flag/variable?\nI don't know how much backwards compatibility you need/want but the following should work:\n1. Introduce a variable, say trellis_add_vendor_bin_to_path\n2. fail with the condition when: trellis_add_vendor_bin_to_path is undefined\n3. Just before 1.0.0: Change the default to false, remove the fail\n. ",
    "cunningryan": "Good work, and thanks for the mention.\n. ",
    "etcook": "@DinisCruz Yes, but you'll have to do it the \"Docker\" way. Docker, to some extent, obviates the need for provisioning - so ansible is not really required. Instead, you build your stack with specific images - E.g. hhvm, mariadb, nginx, etc. The easiest way is to then deploy your code to your Docker nodes using Capistrano.\nIf you're trying to replicate the entire environment in a single image, it will work, but that's not the \"Docker way,\" you won't receive the benefits of Docker and you'll likely run into a number of challenges.\n. @mAAdhaTTah I'll be honest - based on how Docker is supposed to be used, I think it's Ansible's attempt at staying relevant in the age of containerization. You don't need Ansible to provision nodes - you can even script the provisioning directly with Docker Machine. Your nodes should be stateless, and if they aren't then you need to look into rearchitecting your stack and properly following 12 Factor principles.\nEven on the \"environment\" side, Ansible isn't the proper tool for orchestration.\nUltimately, you'd be using Ansible for no other reason than to use Ansible. It would not afford you any particular capability or value beyond the satisfaction of using it.\n. @mAAdhaTTah The provisioning I was referring to is merely bringing up a Docker node, nothing more. If you're actually configuring the node itself, it's not stateless and you're not architecting it properly. If you're actually using Docker as it is intended, you shouldn't be able to find an area within your workflow where Ansible adds value. All docker-machine does is use your api key to bring up a vps and install docker on it, period. It's a stateless node.\nAs well, you should be configuring nginx with environment variables (there are plenty of nginx images that'll even live configure based on live service discovery) or have a pre-built configuration that you've built into an image. Adding Ansible to the mix unnecessarily complicates the configuration.\nI think the impasse is that we're trying to force the old pre-containerization workflow into containerization and essentially treating a container as another VPS instance. If you approach it from this perspective, you're not actually utilizing containerization and Docker (E.g. single concern, statelessness, etc) as it was intended and might as well just stick with the old workflow. If not, you're just creating a hybrid of two approaches and not reaping the true benefits of either.\n. ",
    "landwire": "Thanks for the reply! Trying it as we speak. I still do not find it clear, but then I do not know ansible at all. But maybe a little note in brackets like \"trellis/    - Your clone of repository (this is the ansible root directory, if you followed the steps above)\" would help :-)\n. ",
    "danielbachhuber": "\nif we switch to nightly, someone could very easily wind up with one nightly version of wp-cli on dev that doesn't match up with remote (or vice-versa).\n\nWhy not use nightly for dev, and the latest stable everywhere else?\n. You can also pull releases programmatically from the Github API: https://api.github.com/repos/wp-cli/wp-cli/releases\nThough, note: the releases are sorted by publication date, and not version number.\n. You might want to consider wp core upgrade-db --network for upgrading the database across a network of sites.\n. ",
    "psymeon": "Great! Thanks.\n. ",
    "thiagotalma": "@swalkinshaw done!\n@retlehs I'm sorry I have not done before.\nI imagined that the title would be self-descriptive.\n. ",
    "chrisk2020": "Are you using the api key as password - or smtp credentials?\nhttps://help.mailgun.com/hc/en-us/articles/203380100-Where-can-I-find-my-API-key-and-SMTP-credentials-\n(I am having the same issue)\n. After I slept on it - I reprovisioned and for me it worked. I think my issue was that I was deploying to the server, but not reprovisioning.\nIf it helps here is the functioning mail.yml:\n\nmail_smtp_server: smtp.mailgun.org\nmail_admin: postmaster@mg.mydomain.com\nmail_hostname: mydomain.com\nmail_user: postmaster@mg.mydomain.com\nmail_password: mysmtpcredentialpassword\n\n. ",
    "dischord01": "I was using the Mailgun API key not SMTP password. I changed it to SMTP password and it worked. Thanks!\n. ",
    "primozcigler": "I'm glad to contribute to this project, sir! :smiley: \n. I hope other people try this out and let us know. If not, feel free to close the ticket, but at least you've been warned in case that someone else reports this in the future.\n. Intel. I hope to find some time to do consistent testing with Apache's ab tool this week on multiple machines to either confirm or decline this issue.\n. I benchmarked roots example project with Apache Benchmark and I can confirm this (OSX 10.10.5, VirtualBox 4.3.30).\nResults (run with command $ ab -n 20 -w http://roots-example-project.dev/):\nWith vb.customize ['modifyvm', :id, '--cpus', cpus]\n\nServer Software:nginx\nServer Hostname:roots-example-project.dev\nServer Port:80\nDocument Path:/\nDocument Length:6416 bytes\nConcurrency Level:1\nTime taken for tests:5.822 seconds\nComplete requests:20\nFailed requests:0\nTotal transferred:135000 bytes\nHTML transferred:128320 bytes\nRequests per second:3.44\nTransfer rate:22.64 kb/s received\nConnnection Times (ms)\n\u00a0 min avg max\nConnect:    0    0    3\nProcessing:  263  291  566\nTotal:  263  291  569\n\nWith vb.customize ['modifyvm', :id, '--cpus', 1]\n\nServer Software:nginx\nServer Hostname:roots-example-project.dev\nServer Port:80\nDocument Path:/\nDocument Length:6416 bytes\nConcurrency Level:1\nTime taken for tests:3.330 seconds\nComplete requests:20\nFailed requests:0\nTotal transferred:135000 bytes\nHTML transferred:128320 bytes\nRequests per second:6.01\nTransfer rate:39.59 kb/s received\nConnnection Times (ms)\n\u00a0 min avg max\nConnect:    0    0    2\nProcessing:  151  166  358\nTotal:  151  166  360\n\n\nMore real-world example (more complex theme, couple of plugins installed) was even more problematic:\nWith vb.customize ['modifyvm', :id, '--cpus', cpus]\n\nConnnection Times (ms)\n\u00a0 min avg max\nConnect:    0    0    2\nProcessing:  873  930 1194\nTotal:  873  930  1196\n\nWith vb.customize ['modifyvm', :id, '--cpus', 1]\n\nConnnection Times (ms)\n\u00a0 min avg max\nConnect:    0    0    2\nProcessing:  230  333  687\nTotal:  230  333  689\n\n. I pinged @swrobel over twitter. It would be great to have him elaborate on this, as AFAIK you guys added these Vagrantfile 'improvements' after this blogpost.\n. Moreover, I experience the same issues on linux machine as well.\n. @swrobel thanks for stopping by :smiley: \nI could use wrk as well, but I can tell the performance slowdown is noticeable even when developing - without benchmarks.\nSo there's no need for me to test this again. It would be great if anyone else takes couple of minutes of time and does independent test. Hopefully guys here at Roots, maybe this is particular to WP - I haven't bother to benchmark other stacks.\n. My pleasure.\n. @swalkinshaw indeed, my bad :+1: \n. @swalkinshaw it does not work. That's how I found the bug \ud83d\ude09 \nAnd I've also tested it and with my fix, it works as it's supposed to.. Agreed. That's why I splitted it into 2 commits. I don't know why #392 is not merged yet though?\n. I see. But bash completion is the same for both AFAIK (I think is the the same script since I started using WP-CLI some 2 years ago or so).\n. New commit coming within minutes. I was not sure, as if you see the same page I pasted above, the example has true. :confused: \n. ",
    "swrobel": "@primozcigler really interesting findings. I suppose in my post, I take for granted that more cpus = better performance, or at least that it won't cause worse performance. One thing to note is that you didn't test concurrency - not that is a typical concern in development contexts. I used wrk for my NFS vs VirtualBox sharing benchmarks because it's supposed to better emulate real-world traffic than ab but I still have no explanation for why you're seeing reduced performance.\n. ",
    "nickkuijpers": "Thanks for your responses!\n@evanfuture the domain names are both local with /etc/hosts so not difference ;(\n@swalkinshaw that's the weird thing, both fresh install and same activation of plugins. No difference so why the queries are different, i don't know ;( I've really installed them on like 4 different machines but the queries keep stays the same. Same on Trellis and then same on Homestead.\nAnd by that, 300ms can't be the change of 3 more queries aye? Or am i wrong?\nNew Relic Homestead:\n\n. The different queries was the language and timezone i have selected on the one with more queries than the other. I've selected the language and timezone on Trellis now and the load time is now 700ms.\nQuery logs:\nHomestead\n```\n//////////////////////////////////////////\nNovember 21, 2015, 12:40:58 pm\nSELECT option_name, option_value FROM wp_options WHERE autoload = 'yes' - (0.0013878345489502 s)\nSELECT option_value FROM wp_options WHERE option_name = 'gform_longtext_ready' LIMIT 1 - (0.00033998489379883 s)\nSELECT option_value FROM wp_options WHERE option_name = 'widget_gform_widget' LIMIT 1 - (0.00041103363037109 s)\nSELECT option_value FROM wp_options WHERE option_name = 'gravityformsaddon_gravityformswebapi_settings' LIMIT 1 - (0.0011332035064697 s)\nSELECT   wp_posts.* FROM wp_posts  WHERE 1=1  AND wp_posts.ID = 2 AND wp_posts.post_type = 'page'  ORDER BY wp_posts.post_date DESC  - (0.00034594535827637 s)\nSELECT post_id, meta_key, meta_value FROM wp_postmeta WHERE post_id IN (2) ORDER BY meta_id ASC - (0.00029110908508301 s)\nSELECT * FROM wp_users WHERE ID = '1' - (0.00035405158996582 s)\nSELECT user_id, meta_key, meta_value FROM wp_usermeta WHERE user_id IN (1) ORDER BY umeta_id ASC - (0.00040793418884277 s)\nSELECT * FROM wp_posts WHERE ID = 16 LIMIT 1 - (0.00030183792114258 s)\nSELECT post_id, meta_key, meta_value FROM wp_postmeta WHERE post_id IN (16) ORDER BY meta_id ASC - (0.0003821849822998 s)\nSELECT * FROM wp_posts  WHERE (post_type = 'page' AND post_status = 'publish')    AND post_parent = 2   ORDER BY wp_posts.post_title ASC LIMIT 0,1 - (0.00036311149597168 s)\n```\nTrellis:\n```\n//////////////////////////////////////////\nNovember 21, 2015, 12:41:00 pm\nSELECT option_name, option_value FROM wp_options WHERE autoload = 'yes' - (0.00034713745117188 s)\nSELECT option_value FROM wp_options WHERE option_name = 'widget_pages' LIMIT 1 - (0.00036406517028809 s)\nSELECT option_value FROM wp_options WHERE option_name = 'widget_tag_cloud' LIMIT 1 - (0.00026798248291016 s)\nSELECT option_value FROM wp_options WHERE option_name = 'widget_nav_menu' LIMIT 1 - (0.00031781196594238 s)\nSELECT option_value FROM wp_options WHERE option_name = 'widget_gform_widget' LIMIT 1 - (0.00023484230041504 s)\nSELECT option_value FROM wp_options WHERE option_name = 'gravityformsaddon_gravityformswebapi_settings' LIMIT 1 - (0.00022792816162109 s)\nSELECT option_value FROM wp_options WHERE option_name = 'rewrite_rules' LIMIT 1 - (0.00023818016052246 s)\nSELECT   wp_posts.* FROM wp_posts  WHERE 1=1  AND wp_posts.ID = 2 AND wp_posts.post_type = 'page'  ORDER BY wp_posts.post_date DESC  - (0.00019097328186035 s)\nSELECT post_id, meta_key, meta_value FROM wp_postmeta WHERE post_id IN (2) ORDER BY meta_id ASC - (0.0001981258392334 s)\nSELECT * FROM wp_users WHERE ID = '1' - (0.00030088424682617 s)\nSELECT user_id, meta_key, meta_value FROM wp_usermeta WHERE user_id IN (1) ORDER BY umeta_id ASC - (0.00021600723266602 s)\nSELECT option_value FROM wp_options WHERE option_name = 'site_icon' LIMIT 1 - (0.00024294853210449 s)\nSELECT * FROM wp_posts  WHERE (post_type = 'page' AND post_status = 'publish')    AND post_parent = 2   ORDER BY wp_posts.post_title ASC LIMIT 0,1 - (0.00021100044250488 s)\n```\n. @swalkinshaw Hmm, i see indeed. But i don't think this is the problem. There is something else in Homestead that gives that amount of performance. I don't think we need to dive too deep in the same WordPress environments because when i install the test bedrock, i get the same results. This was just an indication with a WP Installation with 5 active plugins. \nWhat could it be? The variable that makes such a difference? I think this is an performance issue that gives such a optimization that it needs to be figured out don't you think? From 500ms to 120ms. \n. Okay so how to setup caching to get that performance on trellis?\nHaven't activate caching or anything. Just install and run.\n. What happens when you install 2 vagrant boxed, one trellis, one homestead? Then you install Bedrock and see the loadtime. I dont think Homestead adds caching because its used for dev also. \nWhat would i need to do to get the same result in Trellis? Because 5 plugins can't get my Loaddtime to 600ms right? Thats insane and not workable..\n. Just some activated standard Widgets, further on nothing. The query's didn't take that long, as you can see in the second query log but there is something in Trellis that makes the time longer.. Do you know some tools i can check it with?\n. ",
    "craigpearson": "Forget Christmas and my birthday. This is the only thing I'm looking forward to in life!\n. +1 Same here\n. On one of our installs nginx was running on version 1.11.5, as this feature was added in 1.11.10 this causes an emergency log of:\nnginx: [emerg] unknown directive \"fastcgi_cache_background_update\" in /etc/nginx/sites-enabled/example.com.conf:78\nTo update nginx manually you can run:\nsudo add-apt-repository ppa:nginx/stable\nsudo apt-get update\nsudo apt-get install nginx\nNot opening this as issue as I presume it's an edge case, but may be helpful for others. ",
    "fgilio": "Super exited to try it out!\n. ",
    "egamipeaks": "https://github.com/roots/trellis/blob/php-7.0/roles/deploy/hooks/finalize-after.yml#L33-L36 should be restarting php7.0-fpm\n. ",
    "andrewfrankel": "Tested provisioning, deployments, xdebug, etc. All looks good to me!\n. Ran into an issue provisioning a new server on php7 today. Got the error below, and was able to resolve by changing the PPA to  repo: \"ppa:ondrej/php\" (removed 7.0)\n```\nTASK: [php | Install PHP 7.0] ******* \nfailed: [162.243.131.66] => (item=php7.0-common,php7.0-cli,php7.0-curl,php7.0-dev,php7.0-fpm,php7.0-gd,php7.0-mcrypt,php7.0-mysql,php7.0-opcache) => {\"failed\": true, \"item\": \"php7.0-common,php7.0-cli,php7.0-curl,php7.0-dev,php7.0-fpm,php7.0-gd,php7.0-mcrypt,php7.0-mysql,php7.0-opcache\"}\nstderr: E: Unable to correct problems, you have held broken packages.\nstdout: Reading package lists...\nBuilding dependency tree...\nReading state information...\nSome packages could not be installed. This may mean that you have\nrequested an impossible situation or if you are using the unstable\ndistribution that some required packages have not yet been created\nor been moved out of Incoming.\nThe following information may help to resolve the situation:\nThe following packages have unmet dependencies:\n php7.0-cli : Depends: php7.0-common (>= 7.0.2-2+deb.sury.org~trusty+1) but 7.0.2-1+deb.sury.org~trusty+1 is to be installed\n              Recommends: php-readline but it is not going to be installed\n php7.0-dev : Depends: php7.0-common (>= 7.0.2-2+deb.sury.org~trusty+1) but 7.0.2-1+deb.sury.org~trusty+1 is to be installed\n              Recommends: dh-php7.0 but it is not installable\n              Recommends: pkg-php-tools but it is not going to be installed\n php7.0-fpm : Depends: php7.0-common (>= 7.0.2-2+deb.sury.org~trusty+1) but 7.0.2-1+deb.sury.org~trusty+1 is to be installed\nmsg: '/usr/bin/apt-get -y -o \"Dpkg::Options::=--force-confdef\" -o \"Dpkg::Options::=--force-confold\" --force-yes  install 'php7.0-common' 'php7.0-cli' 'php7.0-curl' 'php7.0-dev' 'php7.0-fpm' 'php7.0-gd' 'php7.0-mcrypt' 'php7.0-mysql' 'php7.0-opcache'' failed: E: Unable to correct problems, you have held broken packages.\n```\n. @swalkinshaw, tried again today with the original PPA for dedicate 7.0 and worked fine.\nI noticed that yesterday (1/14/2016) the PPA packages were updated to version 7.0.2-2 from 7.0.2-1. Wonder if it was just really bad timing with all the dependancies being updated and when I ran the provision, because those are the exact versions that were throwing conflicts for me.\nAnyway, false alarm, thanks for checking!\n. ",
    "pacotole": "I have the same problem again with the last versions of Trellis.. @retlehs yes, in vagrant works as expected but in server (staging or production) somefile.php returns \"File not found\" instead of the WordPress 404.\nI'll try on a server with all the WP plugins disabled to discard that possibility.... @fullyint Problem solved!! Thanks =). ",
    "coderholic": "We (http://ipinfo.io) have had 100% uptime ever since we moved to AWS auto-scaling, load balanced servers in 3 different regions (several months ago), and we're hoping to maintain it for a long long time! As a result of the change our latency was also significantly improved, as now your request will automatically get routed to the lowest latency server, be that on the US east or west costs, or in the EU, which are the 3 locations that we currently have servers (more locations coming soon).\n. The website works via https, but the API is currently only available via https for subscribers.\n$ curl https://ipinfo.io/json\nSSL access is restricted to paid plans. See http://ipinfo.io/pricing for more details, or contact us via http://ipinfo.io/contact\n. Yeah that's right, /ip isn't limited to https, and we've got no plans to change that in the future. \nIf you do go head and use us we'd definitely appreciate the mention in the readme! :)\n. ",
    "geerlingguy": "@QWp6t - would be slightly easier, but for Ansible power users, it's a bit more painful, because you're requiring them to give up one of the major benefits of Ansible\u2014not having to install extra junk inside your VM/servers.\n. You can have it both ways, of course (which is what I'm doing for Drupal VM):\n# Provisioning. Use ansible if it's installed on host, ansible_local if not.\n  if which('ansible-playbook')\n    config.vm.provision \"ansible\" do |ansible|\n      ansible.playbook = \"#{dir}/provisioning/playbook.yml\"\n    end\n  else\n    config.vm.provision \"ansible_local\" do |ansible|\n      ansible.playbook = \"provisioning/playbook.yml\"\n      ansible.galaxy_role_file = \"provisioning/requirements.yml\"\n    end\n  end\nIf users install Ansible, it uses the ansible provisioner. If they don't install Ansible, it uses ansible_local.\n. @runofthemill - The composer role fix is merged, will be pushed to a new tag shortly!. @fullyint NTP is now updated as well; use the 1.6.0 release.. ",
    "dblencowe": "@QWp6t Agreed, it's definitely not as active as hostmanager, just didn't want to step on anyones toes!\n. ",
    "mockey": "OK, I installed vagrant-hostmanager (and unistalled vagrant-hostsupdater). hosts entries are written on up (if they are not there) and not touched on suspend or halt. As hostmanager appaently only hooks into up and destroy that seems to work as expected.\nI saw that var/exports gets updated on every up (after a halt). Is this intentional?\n. OK like this?\n. Yes, I got the update message on vagrant up here. I tested with 2.3.7 and then with 2.3.8.\nIt does not work with 2.3.8 straight. Even update doesn't work then.\nThat's why I went for <= 2.3.8. It' a bit strange, though, I agree.\nProbably better try it out on your box.... No idea. There suddenly was v201708.22.0 in August:\nhttps://app.vagrantup.com/bento/boxes/ubuntu-16.04\nThe <= comparison still works, though.\nI tested the current version, all my VMs are running on this box now.. @swalkinshaw, @TangRufus\nThe thing is I don't get any update mesages with this anymore, even if my version is lower.\nIt even seems to disable the update check.\nWith vagrant_box_version: '<= 201801.02.0' I get:\n==> default: Checking if box 'bento/ubuntu-16.04' is up to date...\n==> default: A newer version of the box 'bento/ubuntu-16.04' for provider 'virtualbox' is\n==> default: available! You currently have version '201710.25.0'. The latest is version\n==> default: '201801.02.0'. Run `vagrant box update` to update.\nWith vagrant_box_version: '>= 201801.02.0' I get none of this.\nBTW: Current version is: 201805.15.0. > vagrant box update doesn't pick up 201805.15.0\nConfirmed. That's weird.\nVagrant 2.1.1 here as well (on Linux Mint 17.3). > vagrant box update doesn't pick up 201805.15.0\n@TangRufus:\nThere is a new version v201806.08.0 available now, which isn't picked up as well.\nOnly v201803.24.0 is marked as the currently released version. Maybe that's why newer versions don't get picked?. As far as I see, >= just doesn't work for updating an older version, just like specifying the version without <= doesn't work. vagrant box update returns:\n==> default: Box 'bento/ubuntu-16.04' not installed, can't check for updates.\nif the version is higher than the installed one. Yes, I saw that, too. 201806.08.0 is now labelled currently released version.\nUpdate worked for me as well.\nMaybe I got it wrong because there were newer version that were not released. I don't know...\nThanks for checking anyway.. Sure, but I'm wondering: Wouldn't it be better to use the synchronize (or copy) ansible module here? Or is there a special reason for using cp -rp?\nThe code above with cp -rp doesn't work if the target folder already exists. E.g. when you have an empty web/app/languages in your deploy, you end up with web/app/languages/languages.\nI think synchronize or copy would work then if project_copy_folders ends with a /.. I'm not an ansible expert. The docs (https://docs.ansible.com/ansible/latest/modules/copy_module.html) say that synchronize (based on rsync) should be preferred to copy for folders with lots of files.\nI see trellis uses copy in a couple of places, synchronize is only used in the build-before deploy-hook. What do you think?\n. I see. I wasn't aware of that local -> remote scheme. But that makes sense for ansible of course. I think I'll try to get copy working then. It might be useful to be able to copy something to an existing folder.. ",
    "theorosendorf-chapel": "I have looked at all of the past issues on this but still can't find what's going on with mine. Here's the error code if it's helpful at all.\nIs anyone else having this issue?\nTASK: [wordpress-install | Install Dependencies with Composer] **** \nfailed: [default] => (item={'key': 'chapel.dev', 'value': {'site_install': True, 'admin_user': 'admin', 'site_name': 'chapel.dev', 'local_path': '../site/web', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': True, 'subdomains': False}, 'site_title': 'Chapel.io', 'admin_password': 'password', 'env': {'wp_env': 'development', 'db_user': 'wp', 'db_password': 'wp', 'disable_wp_cron': True, 'wp_siteurl': 'chapel.dev/wp', 'db_name': 'chapel_dev', 'wp_home': 'chapel.dev', 'domain_current_site': 'chapel.dev'}, 'site_hosts': ['chapel.dev'], 'admin_email': 'theo@chapel.io'}}) => {\"changed\": true, \"cmd\": [\"composer\", \"install\"], \"delta\": \"0:00:00.090521\", \"end\": \"2015-12-26 20:59:35.492879\", \"item\": {\"key\": \"chapel.dev\", \"value\": {\"admin_email\": \"theo@chapel.io\", \"admin_password\": \"password\", \"admin_user\": \"admin\", \"cache\": {\"duration\": \"30s\", \"enabled\": false}, \"env\": {\"db_name\": \"chapel_dev\", \"db_password\": \"wp\", \"db_user\": \"wp\", \"disable_wp_cron\": true, \"domain_current_site\": \"chapel.dev\", \"wp_env\": \"development\", \"wp_home\": \"chapel.dev\", \"wp_siteurl\": \"chapel.dev/wp\"}, \"local_path\": \"../site/web\", \"multisite\": {\"enabled\": true, \"subdomains\": false}, \"site_hosts\": [\"chapel.dev\"], \"site_install\": true, \"site_name\": \"chapel.dev\", \"site_title\": \"Chapel.io\", \"ssl\": {\"enabled\": false}}}, \"rc\": 1, \"start\": \"2015-12-26 20:59:35.402358\", \"stdout_lines\": [], \"warnings\": []}\nstderr: You are running composer with xdebug enabled. This has a major impact on runtime performance. See https://getcomposer.org/xdebug\nComposer could not find a composer.json file in /srv/www/chapel.dev/current\nTo initialize a project, please create a composer.json file as described in the https://getcomposer.org/ \"Getting Started\" section\n. Scratch this. I started over and was able to get up and running. One thing I failed to include in the first round was a wordpress theme. Not sure if that was causing the issue, but closing this issue. Thanks!\n. ",
    "jawngee": "This doesn't copy git submodules in your repo.\n. ",
    "itsazzad": "```\n$ time vagrant suspend\n==> default: Saving VM state and suspending execution...\nreal    0m44.719s\nuser    0m2.688s\nsys 0m0.670s\n.\n$ time vagrant resume\n==> default: Resuming suspended VM...\n==> default: Booting VM...\n==> default: Waiting for machine to boot. This may take a few minutes...\n    default: SSH address: 127.0.0.1:2222\n    default: SSH username: vagrant\n    default: SSH auth method: private key\n==> default: Machine booted and ready!\n==> default: Running provisioner: ansible...\n    default: Running ansible-playbook...\nPLAY [WordPress Server: Install LEMP Stack with PHP 5.6 and MariaDB MySQL] **** \nGATHERING FACTS ********* \nok: [default]\nTASK: [common | Validate Ansible version] ******* \nok: [default]\nTASK: [common | Update Apt] ********* \nok: [default]\nTASK: [common | Checking essentials] ****** \nok: [default] => (item=python-software-properties,python-pycurl,build-essential,python-mysqldb,curl,git-core)\nTASK: [common | Validate timezone variable] ***** \nok: [default]\nTASK: [common | Explain timezone error] ********* \nskipping: [default]\nTASK: [common | Get current timezone] ******* \nok: [default]\nTASK: [common | Set timezone] ******* \nskipping: [default]\nTASK: [fail2ban | ensure fail2ban is installed] ******* \nok: [default]\nTASK: [fail2ban | ensure fail2ban is configured] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      2      0  0:00:07  0:00:05  0:00:02     2\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default] => (item=jail.local)\nok: [default] => (item=fail2ban.local)\nTASK: [fail2ban | ensure fail2ban starts on a fresh reboot] *** \nok: [default]\nTASK: [ferm | ensure ferm status is in debconf] ******* \nok: [default]\nTASK: [ferm | ensure ferm is installed] ********* \nok: [default]\nTASK: [ferm | ensure configuration directories exist] ******* \nok: [default] => (item=/etc/ferm/ferm.d)\nok: [default] => (item=/etc/ferm/filter-input.d)\nTASK: [ferm | ensure firewall is configured] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default] => (item=etc/default/ferm)\nok: [default] => (item=etc/ferm/ferm.conf)\nTASK: [ferm | ensure iptables INPUT rules are removed] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nskipping: [default] => (item={'dport': ['http', 'https'], 'type': 'dport_accept', 'filename': 'nginx_accept'})\nskipping: [default] => (item={'dport': ['ssh'], 'type': 'dport_accept', 'saddr': [u'202.126.124.130']})\nskipping: [default] => (item={'dport': ['ssh'], 'seconds': 300, 'hits': 20, 'type': 'dport_limit'})\nTASK: [ferm | ensure iptables INPUT rules are added] **** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      6      0  0:00:02  0:00:02 --:--:--     6\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      4      0  0:00:03  0:00:03 --:--:--     4\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\nok: [default] => (item={'dport': ['http', 'https'], 'type': 'dport_accept', 'filename': 'nginx_accept'})\nok: [default] => (item={'dport': ['ssh'], 'type': 'dport_accept', 'saddr': [u'202.126.124.130']})\nok: [default] => (item={'dport': ['ssh'], 'seconds': 300, 'hits': 20, 'type': 'dport_limit'})\nTASK: [ferm | ensure iptables rules are enabled] ****** \nskipping: [default]\nTASK: [ferm | ensure iptables rules are disabled] ***** \nok: [default]\nTASK: [ntp | Add the OS specific variables] ***** \nok: [default]\nTASK: [ntp | Install the required packages in Redhat derivatives] *** \nskipping: [default]\nTASK: [ntp | Install the required packages in Debian derivatives] *** \nok: [default]\nTASK: [ntp | Copy the ntp.conf template file] ***** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default]\nTASK: [ntp | Start/stop ntp service] ****** \nok: [default]\nTASK: [sshd | ensure ssh server is installed] ***** \nok: [default]\nTASK: [sshd | ensure sshd is configured] ******** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      4      0  0:00:03  0:00:03 --:--:--     4\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\nok: [default]\nTASK: [mariadb | Add MariaDB MySQL apt-key] ***** \nok: [default]\nTASK: [mariadb | Add MariaDB MySQL deb and deb-src] ***** \nok: [default] => (item=deb http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main)\nok: [default] => (item=deb-src http://nyc2.mirrors.digitalocean.com/mariadb/repo/10.0/ubuntu trusty main)\nTASK: [mariadb | Install MariaDB MySQL server] ******** \nok: [default]\nTASK: [mariadb | Start MariaDB MySQL Server] ****** \nok: [default]\nTASK: [mariadb | Set root user password] ******** \nok: [default] => (item=default)\nok: [default] => (item=127.0.0.1)\nok: [default] => (item=::1)\nok: [default] => (item=localhost)\nTASK: [mariadb | Copy .my.cnf file with root password credentials.] ***** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      4      0  0:00:03  0:00:03 --:--:--     4\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default]\nTASK: [mariadb | Delete anonymous MySQL server users] ******* \nok: [default] => (item=localhost)\nok: [default] => (item=default)\nok: [default] => (item=example)\nTASK: [mariadb | Remove the test database] ****** \nok: [default]\nTASK: [ssmtp | Install ssmtp] ******* \nok: [default]\nTASK: [ssmtp | ssmtp configuration] ******* \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      1      0  0:00:15  0:00:10  0:00:05     2\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      7      0  0:00:02  0:00:01  0:00:01     7\nok: [default]\nTASK: [geerlingguy.daemonize | Download daemonize archive.] *** \nok: [default]\nTASK: [geerlingguy.daemonize | Expand daemonize archive.] *** \nok: [default]\nTASK: [geerlingguy.daemonize | Check if daemonize is installed.] ** \nok: [default]\nTASK: [geerlingguy.daemonize | Build daemonize.] ****** \nskipping: [default] => (item=./configure)\nskipping: [default] => (item=make prefix=/usr)\nskipping: [default] => (item=make prefix=/usr install)\nTASK: [mailhog | Ensure mailhog install directory exists.] **** \nok: [default]\nTASK: [mailhog | Download MailHog binary.] ****** \nok: [default]\nTASK: [mailhog | Copy mailhog init script into place.] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      6      0  0:00:02  0:00:02 --:--:--     6\nok: [default]\nTASK: [mailhog | Ensure mailhog is enabled and will start on boot.] ***** \nok: [default]\nTASK: [mailhog | Install sSMTP.] ********** \nskipping: [default]\nTASK: [mailhog | Install sSMTP.] ********** \nskipping: [default]\nTASK: [mailhog | Copy sSMTP configuration.] ***** \nskipping: [default]\nTASK: [php | Add PHP 5.6 PPA] ******* \nok: [default]\nTASK: [php | Install PHP 5.6] ******* \nok: [default] => (item=php5-common,php5-fpm,php5-mysqlnd,php5-xmlrpc,php5-mcrypt,php5-curl,php5-gd,php5-cli,php-pear,php5-dev,php5-imap)\nTASK: [php | Start php5-fpm service] ****** \nok: [default]\nTASK: [php | Create socket directory] ******* \nok: [default]\nTASK: [php | Disable default pool] ******** \nok: [default]\nTASK: [php | Add php.ini template] ******** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default]\nTASK: [php | Copy php-fpm configuration] ******** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\nok: [default]\nTASK: [hhvm | Add HHVM apt-key] ******* \nskipping: [default]\nTASK: [hhvm | Add HHVM deb] ********* \nskipping: [default]\nTASK: [hhvm | Install HHVM] ********* \nskipping: [default]\nTASK: [hhvm | Get HHVM path] ******** \nskipping: [default]\nTASK: [hhvm | Symlink HHVM as php] ******** \nskipping: [default]\nTASK: [hhvm | HHVM server.ini] ******** \nskipping: [default]\nTASK: [hhvm | HHVM php.ini] ********* \nskipping: [default]\nTASK: [hhvm | Symlink mysql.sock for HHVM] ****** \nskipping: [default]\nTASK: [hhvm | Start HHVM service] ********* \nskipping: [default]\nTASK: [hhvm | HHVM server.ini] ******** \nskipping: [default]\nTASK: [hhvm | Create cron job to restart HHVM service daily] ****** \nskipping: [default]\nTASK: [php5-xdebug | php5 - install xdebug] ***** \nok: [default]\nTASK: [php5-xdebug | Copy xdebug INI into mods-available folder.] *** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\nok: [default]\nTASK: [php5-xdebug | Copy xdebug INI into conf.d folder.] *** \nskipping: [default]\nTASK: [nginx | Add Nginx PPA] ******* \nok: [default]\nTASK: [nginx | Install Nginx] ******* \nok: [default]\nTASK: [nginx | Create SSL directory] ****** \nok: [default]\nTASK: [nginx | Generate strong unique Diffie-Hellman group.] ****** \nok: [default]\nTASK: [nginx | Grab h5bp/server-configs-nginx] ******** \nok: [default]\nTASK: [nginx | Move h5bp configs] ********* \nok: [default]\nTASK: [nginx | Create nginx.conf] ********* \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      4      0  0:00:03  0:00:03 --:--:--     4\nok: [default]\nTASK: [nginx | Disable default server] ****** \nok: [default]\nTASK: [nginx | Enable better default site to drop unknown requests] ***** \nok: [default]\nTASK: [nginx | Create base WordPress config] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default]\nTASK: [nginx | Create base WordPress subdirectory Multisite config] ***** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      4      0  0:00:03  0:00:03 --:--:--     4\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\nok: [default]\nTASK: [logrotate | nickhammond.logrotate | Install logrotate] ***** \nok: [default]\nTASK: [logrotate | nickhammond.logrotate | Setup logrotate.d scripts] * \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      8      0  0:00:01  0:00:01 --:--:--     8\nok: [default] => (item={'path': u'/srv/www//logs/*.log', 'scripts': {'postrotate': 'service nginx rotate', 'prerotate': 'if [ -d /etc/logrotate.d/httpd-prerotate ]; then \\\\n      run-parts /etc/logrotate.d/httpd-prerotate; \\\\n    fi \\\\n'}, 'options': ['weekly', 'maxsize 50M', 'missingok', 'rotate 8', 'compress', 'delaycompress', 'notifempty', u'create 0640 vagrant www-data', 'sharedscripts'], 'name': 'wordpress-sites'})\nTASK: [memcached | Install memcached] ******* \nok: [default] => (item=python-selinux,memcached,php5-memcached,libmemcached-tools)\nTASK: [memcached | Copy the client configuration file] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\nok: [default]\nTASK: [memcached | Set the max open file descriptors] ******* \nok: [default]\nTASK: [memcached | Start the memcached service] ******* \nok: [default]\nTASK: [composer | Add Composer PPA] ******* \nok: [default]\nTASK: [composer | Install Composer] ******* \nok: [default]\nTASK: [composer | Composer self update] ********* \nok: [default]\nTASK: [composer | Composer config github-oauth] ******* \nskipping: [default]\nTASK: [wp-cli | Install WP-CLI] ******* \nok: [default]\nTASK: [wp-cli | Install WP-CLI tab completions] ******* \nok: [default]\nTASK: [wordpress-setup | Create database of sites] **** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Create/assign database user to db and grant permissions] *** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Copy database dump] ****** \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Import database] ******* \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Get existing self-signed certificates] *** \nok: [default]\nTASK: [wordpress-setup | Get self-signed certificates domains] **** \nskipping: [default]\nTASK: [wordpress-setup | Generate self-signed certificates] *** \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Copy SSL cert] ********* \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Copy SSL key] ****** \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Create includes.d directories] ***** \nok: [default] => (item=example.com)\nTASK: [wordpress-setup | Template files out to includes.d] **** \n/bin/sh: line 0: cd: ../templates/includes.d: No such file or directory\nskipping: [default]\nTASK: [wordpress-setup | Retrieve list of existing files in includes.d] * \nok: [default]\nTASK: [wordpress-setup | Remove unmanaged files from includes.d] ** \nskipping: [default]\nTASK: [wordpress-setup | Create WordPress configuration for Nginx] ** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Enable WordPress site] ******* \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Create web root] ******* \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Create logs folder of sites] ******* \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-setup | Setup WP system cron] ******** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Create web root of sites] **** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Create shared folder of sites] *** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Change site owner to user] ******* \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Create .env file] ****** \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      9      0  0:00:01  0:00:01 --:--:--     9\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    15  100    15    0     0      5      0  0:00:03  0:00:02  0:00:01     5\nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Copy .env file into web root] **** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Install Dependencies with Composer] **** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Install WP] ****** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Check Existing Permalink Structure] **** \nok: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Setup Permalink Structure] ******* \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Install WP Multisite] ****** \nskipping: [default] => (item={'key': 'example.com', 'value': {'site_install': True, 'permalink_structure': '/%postname%/', 'admin_user': 'admin', 'local_path': '../site', 'cache': {'duration': '30s', 'enabled': False}, 'ssl': {'enabled': False}, 'multisite': {'enabled': False, 'subdomains': False}, 'site_title': 'example', 'env': {'db_name': 'example_dev', 'db_user': 'example_dbuser', 'wp_env': 'development', 'disable_wp_cron': True, 'wp_home': 'http://example.dev', 'wp_siteurl': 'http://example.dev/wp'}, 'site_hosts': ['example.dev'], 'admin_email': 'admin@example.dev'}})\nTASK: [wordpress-install | Restart HHVM] ******** \nskipping: [default]\nPLAY RECAP ********** \ndefault                    : ok=96   changed=0    unreachable=0    failed=0   \nreal    4m55.443s\nuser    0m12.027s\nsys 0m5.644s\n``\n. I am in Mac. Slow may be because it has only 4GB RAM.\nHowever its runningansible-playbookagain during resuming. Should it be so?\n. Very latest one.Vagrant 1.8.1`\n. Got it! Others also facing the issue. https://github.com/mitchellh/vagrant/issues/6787\n. ",
    "issunboshi": "Hi @mAAdhaTTah,\nThanks for replying so quickly. That was my error when copying the path. The actual path includes sage as the <themename>.\n. ",
    "miljan19": "No problem! I'm no Ansible expert myself, so it would be good if someone more experienced could glance over it before it's merged.\n. ",
    "craigmdennis": "This may be related: https://github.com/ansible/ansible/issues/11579\n. Running 2.7.10\n. That is correct.\n. ",
    "discopatrick": "Same problem here. Oddly, I didn't have the problem earlier today.\nTASK [wp-cli : Install WP-CLI tab completions] *********************************\nfatal: [default]: FAILED! => {\"changed\": false, \"failed\": true, \"msg\": \"Failed to validate the SSL certificate for raw.githubusercontent.com:443. Make sure your managed systems have a valid CA certificate installed.  If the website serving the url uses SNI you need python >= 2.7.9 on your managed machine.  You can use validate_certs=False if you do not need to confirm the server\\\\s identity but this is unsafe and not recommended Paths checked for this platform: /etc/ssl/certs, /etc/pki/ca-trust/extracted/pem, /etc/pki/tls/certs, /usr/share/ca-certificates/cacert.org, /etc/ansible\"}\n$ python --version\nPython 2.7.10\n. Oops - that was the python on my local machine. On my managed machine I actually have python 2.7.6.\nIf python >= 2.7.9 is a requirement of the 'Install WP-CLI tab completions' task, then perhaps this should be installed earlier in the playbook?\n. @swalkinshaw here's a quick Gist to give you a rough idea of my approach: https://gist.github.com/discopatrick/4e85d61ad9d692c06ca8d3bf0dd802ea\nSome notes:\n1. This playbook assumes you're syncing from staging to dev, and thus the playbook 'hosts' value is hardcoded, but this would eventually be replaced by what you pass in on the command line, e.g. `-e \"source=staging dest=dev site=mysite\"\n2. 'pre_tasks' and 'vars' are taken almost verbatim from the Trellis 'deploy.yml' playbook. Ideally these vars would be separated from and shared between both playbooks, so some refactoring of vars would be required to make this part of Trellis.\n3. search-replace tasks are listed one by one here, but these should be provided as a list and then performed by an ansible loop task.\n4. I have more working examples of syncing folders both remote-to-local and remote-to-remote:\n   https://github.com/discopatrick/ansible-pocs/blob/master/playbooks/rsync-remote.yml\n   https://github.com/discopatrick/ansible-pocs/blob/master/playbooks/rsync-vagrant.yml\n. @alexandcote some contribution may be helpful, thanks.\nThere would be a lot of shared vars between this playbook and Trellis core, so my feeling is that this should be part of Trellis core, rather than an external role, so that they are maintained and tested together.\nAlternatively, an external role could be written and tested to work with \"up to Trellis version x\". However, we would still need the currently in-playbook vars to be moved to a shared space (e.g. group_vars) so they were available to our sync playbook.\nSo either way, I think some refactoring of Trellis core is necessary.\n. Hi again - I'm going to have some time to work on this in the coming months. @swalkinshaw - are the above links enough to give you an idea of my approach?. Seems like there's a lot of interest in this feature, so while I've got the time, I'll go ahead and start working on a pull request.. Hi @mindfullsilence - that's a good question.\nSyncing the db and files from staging to production would not be desirable in some cases.\nThe main one I can think of is where your site has user-generated content, such as comments, a discussion forum, customer orders on an e-commerce site, etc. Copying your staging db to production would overwrite any recent content. This would be more common on a high traffic site.\nAnother reason is the purpose of dev and staging is for them to be testing grounds, and thus they may contain untested or dummy content that is not meant to be seen on production. If your client is a big brand name with a reputation to keep, accidentally displaying dummy content for even a few moments could be quite embarrassing for them.\nFor these reasons, I tend to view my production db as sacrosanct. It is itself the master copy, and should only be copied from, not to.\nIt does of course depend on the project. If the site is mostly static, then copying to production is fine.\nHowever, the purpose of Trellis seems (to me at least) to be an attempt to make WordPress a viable option for dynamic, high traffic, high profile sites. Therefore my feeling is that the default configuration should be that syncing to production is disallowed.\nHowever, there will be nothing to stop anyone from editing the playbooks to suit their own needs. We could even have a variable that allows us to set which environments should be \"write-protected\".. Hi all. I'm making good progress with this. There have been a few hurdles, but I'm confident I can make it work.\nI have a question for the core development team. I notice that Trellis uses the host OS's default ssh public key (~/.ssh/id_rsa.pub) when creating users on remote hosts - (https://github.com/roots/trellis/blob/master/group_vars/all/users.yml#L16). Seeing as Trellis already relies on this key as a fundamental requirement, how would you feel about configuring the vagrant box to also use this key, instead of the key generated by the vagrant ansible provisioner? (Documented here: http://ermaker.github.io/blog/2015/11/18/change-insecure-key-to-my-own-key-on-vagrant.html) Are there any arguments against doing this?\nThe reason I ask is that if the vagrant box and the remote boxes use the same ssh key, it may be possible for me to use the synchronise module between them using SSH key forwarding, and this might make the job a lot easier and tidier. At present, I'm having to use a few workarounds, and it's making the playbook look messy.\nNot sure who's attention I should be asking for here, or even if this is the best place to discuss. But I'm going to tag @swalkinshaw. If there is a mailing list, let me know. I'm also always available in the #roots IRC channel on chat.freenode.net.. Thanks for your input everyone.\n@fullyint thanks for directing me to your previous work on the subject. It seems that we have both considered the same problem of how to run playbooks against both development and other envs when their inventories are in different locations. And @swalkinshaw - I fully agree that adding the -i flag every time you run dev.yml is annoying.\nI feel we need to address this issue before we return to SSH keys. Let me explain my ideas on how to get around this, and see what you think.\nI am all for continuing to use vagrant's generated inventory file when connecting to the vagrant box, because It is automatically updated with port number, etc.\nThe problem is that the generated inventory file sits in the .vagrant folder, while the rest of the inventory files sit in the hosts folder - and ansible can only look at one folder at a time.\nOne solution is to add the -i flag to point to the generated file when needed, but as we've said this is a) annoying and b) my DB sync playbooks need to access all the inventories simultaneously in order to carry out their tasks.\nI have suggested 5 solutions to this issue here: https://github.com/mitchellh/vagrant/issues/7619. Of these solutions, I think the easiest for us are:\n\nadd a symlink at hosts/development pointing to .vagrant/provisioners/ansible/inventory/vagrant_ansible_inventory - this puts all our inventories in one place and removes the need for the -i flag. The downside is that if this symlink is in place before a vagrant up/provision (and hence the vagrant inventory is not yet generated), then ansible playbooks will fail, saying the file doesn't exist. So checking this symlink into Trellis source wouldn't be ideal. This leads me to an alternative:\nadd a dynamic inventory script called hosts/development which looks for the generated inventory file and, if it exists, outputs an exact copy of that inventory - otherwise, outputs an empty inventory. Writing dynamic inventory scripts is documented here: http://docs.ansible.com/ansible/dev_guide/developing_inventory.html. This solution will allow the feature to work in Trellis \"out of the box\" while avoiding the above error, and I think will provide the best user experience.\n\nOnce all our inventories are in one place, I think it should be possible to specify in the vagrantfile the SSH key to use in the vagrant box, and that this setting should be reflected in the generated file - but I'll have to test this.\n@kalenjohnson thanks for that heads-up. Would it be a major hassle to ask existing users to switch to using their id_rsa.pub key for connecting these various other apps to their vagrant box?. Hi all - here's an update on how things are going.\nSyncing files and db between two remote servers works perfectly.\nThe problem I'm having is getting the vagrant box to sync to a remote server. I've documented the problem on Stack Overflow and filed it as a bug at the Ansible GitHub repo, but there have been no replies on either yet.\nA workaround for this could be that we have a separate playbook for syncing the vagrant box to a remote server, that uses a slightly different method for syncing - i.e. copying the files to the shared directory via your control machine, instead of trying to use rsync from within the vagrant box. Using two different playbooks is not the neatest solution (I really wanted a single playbook for all scenarios), but perhaps someone else could come along and tidy it up afterwards.\nMy first step will be to issue a pull request that synchronises between remote hosts only, and try to get that merged into master, so that we at least have that functionality. Then I (or someone else) can go to work on a workaround for syncing to vagrant.. ",
    "conrman": "Do you recommend any kind of quick patch for this? This is happening to me on Ansible 2.0.0.1\nDowngrading to Ansible 2.0.0.0 supposedly resolves the issue for now. I'm wrestling with homebrew to see if that works but I wanted to know if you thought it would be better to comment out that task and manually symlink the current directory until the patch is included\n. ",
    "davenaylor": "I updated my OS last night and my package manager moved to Ansible 2.0.0.2.  Deploys are now failing due to unset subtree paths (not in use):\ntask path: <path>/trellis/roles/deploy/tasks/prepare.yml:18\nfatal: [<host>]: FAILED! => {\"changed\": false, \"failed\": true, \"invocation\": {\"module_args\": {\"msg\": \"subtree is set to 'False' but that path does not exist in the repo. Edit `subtree_path` for '<site>' in `wordpress_sites.yml`.\nI've moved back to 1.9.4 for now.\n. @16nsk Linux Arch.  Like I say though, I moved back to 1.9.4 for now.\n. ",
    "madalinignisca": "@davenaylor could you tell what OS and how you manage ansible on your system?\nExample:\n- OSX 10.11.x / Homebrew package manager\n- Linux/Ubuntu / Apt package manager\n- Linux/Arch / Source installation\nFor example using OSX with homebrew you can uninstall ansible and install homebrew/versions/ansible19 and use that until fix for 2.x is announced.\n. ",
    "baptistemarchand": "For people looking for a quick fix, it's super easy to just find the file deploy_helper.py on your system ( locate deploy_helper.py ) and edit those two lines manually:\nhttps://github.com/ansible/ansible-modules-extras/commit/1dd62b13fa532b9335782f26c253495df6df1c1d\n. ",
    "JohnKelty": "Hi.  What is a reliable workaround for this?  On Ansible 2 I get the error about 'vars_files' is not a valid attribute for a PlaybookInclude and on Ansible 1.9, the \"fail is not a legal parameter.\"  I tried the workaround in https://github.com/ansible/ansible-modules-extras/commit/1dd62b13fa532b9335782f26c253495df6df1c1d with no luck.\nIs there a version of Ansible that this works on, and/or a workaround that I could apply despite being quite new to Ansible usage?\n. Indeed it has.  I saw the error was the same as what I was working on and forgot to notice that the playbook in question was different, so please ignore my comment and sorry for the inconvenience  I'll follow this up in the right place.\n. ",
    "flurinduerst": "Well, the error stopped the provisioning. Today the error was gone miraculously (didn't change anything at all.)\n. ",
    "gitluwum": "This issue is showing up for me as well.  It looks as though it can only be fixed is by destroying the vm and then running vagrant up --provision again (#446) or disabling xdebug . A way to do this without  doing either would be very helpful. The error doesn't seem like it will magically disappear as in @flurinduerst case.\n. ",
    "toppetoppe": "I got this error on a fresh digital ocean droplet when running production. I'll send more info soon.\n\n28 jan. 2016 kl. 00:30 skrev Scott Walkinshaw notifications@github.com:\nThanks for the report.\nWere you toggling the cache setting and just running the playbook again? I just set cache: true on a fresh Vagrant box and everything worked fine.\n\u2014\nReply to this email directly or view it on GitHub.\n. Ok, tested with a fresh trellis / bedrock setup and could not reproduce. Guess something was wierd with our original setup, tried to enable cache and now it works.\n. \n",
    "remailednet": "Since ansible now requires 2.0.0.2 could the extra logic for deciding on the backslashes be dropped?\n. ",
    "pascallaliberte": "My mistake. It was actually not a vanilla install, I had downgraded to wordpress 3.8.12 in bedrock to test out that version.\n. ",
    "alexandcote": "@ionut-tanasa If you're still interested into a Laravel support for Trellis, I build a role for Laravel. Let me know if you want some cue.\n. Suggestion : May be run directly the PHP script instead of curl call ?\n. Maybe a external role ? \n@discopatrick I can contribute if you need. I want this feature \ud83d\ude3c\n. I think you can only add it if you need it \ud83d\ude04 . ",
    "oppiansteve": "@alexandcote I'd be interested in seeing what you've done\n. ",
    "richardjkeys": "@alexandcote @ionut-tanasa I'd also be interested in seeing anything you've done on this. Love the idea.\n. ",
    "deegs": "Thank you for this! This fixed issue #469 for me. Using Ansible 2.0.0.2\n. ",
    "richvida": "Currently running into this bug as well. Thanks for the temporary fix.\n. Great work!\n. Starting from a fresh VM I'm still getting this error when viewing site1.dev\nError establishing a database connection\nBut Trellis/Ansible provisioned the server without error! That's great work @swalkinshaw \n. ssh root@site1.com\ncd /srv/www/site1/current\nwp core is-installed --network --allow-root \u2014 no output\nwp core in-installed --allow-root \u2014 no output\nAm I missing something?\n. Return code for each command is 0. I hope that helps.\n. ",
    "gnowland": "This just happened to me on a brand new Linode... any tips on a smoother deploy?. ",
    "kenanfallon": "Thanks @Foxaii. It appears I was overlooking the error that Nginx was returning.\n. ",
    "chrisnx": "I'm going attempt a git bisect and see if I can find at what point the issue appeared, as I didn't have any problems with v0.4.0\n. Oh - this is my environment if that helps at all.\nansible 2.0.0.2\nvirtualbox 4.3.10\nVagrant 1.7.2\n. I read the guidelines, but wasn't sure this was a personal issue. My apologies for the misunderstanding!\n. ",
    "brazabr": "I tried to install it via apt-get using the PPA. Without success, I removed i, cleaned unnecessary packages and removed the PPA. Then I tried installing it via pip. Same results. I then uninstalled it via pip.\nI decided to try version 1.9.4 via pip, but then I got a lost dependency error on ansible.compat.six.string_types. I removed it again and tried the 2.0.0.2 via pip and it worked.\n. ",
    "o1y": "DNS resolution won't work only if a multisite is configured with landrush. archive.ubuntu.com is up and I can ping the server ip from the virtual machine without any problems:\n```\nvagrant@roots-example-project:~$ dig google.de\n; <<>> DiG 9.9.5-3ubuntu0.7-Ubuntu <<>> google.de\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: SERVFAIL, id: 56609\n;; flags: qr aa rd; QUERY: 0, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n;; Query time: 31 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: Mon Mar 07 13:53:41 UTC 2016\n;; MSG SIZE  rcvd: 12\nvagrant@roots-example-project:~$ dig archive.ubuntu.com\n; <<>> DiG 9.9.5-3ubuntu0.7-Ubuntu <<>> archive.ubuntu.com\n;; global options: +cmd\n;; Got answer:\n;; ->>HEADER<<- opcode: QUERY, status: SERVFAIL, id: 7967\n;; flags: qr aa rd; QUERY: 0, ANSWER: 0, AUTHORITY: 0, ADDITIONAL: 0\n;; WARNING: recursion requested but not available\n;; Query time: 4 msec\n;; SERVER: 10.0.2.3#53(10.0.2.3)\n;; WHEN: Mon Mar 07 13:59:44 UTC 2016\n;; MSG SIZE  rcvd: 12\n```\nvagrant@roots-example-project:~$ ping 91.189.91.13\nPING 91.189.91.13 (91.189.91.13) 56(84) bytes of data.\n64 bytes from 91.189.91.13: icmp_seq=1 ttl=63 time=115 ms\n64 bytes from 91.189.91.13: icmp_seq=2 ttl=63 time=146 ms\n64 bytes from 91.189.91.13: icmp_seq=3 ttl=63 time=127 ms\n64 bytes from 91.189.91.13: icmp_seq=4 ttl=63 time=149 ms\nI used a clean roots-example-project, and followed the multisite instructions. I only replaced the vagrant-hostmanager plugin with landrush.\n```\n  if Vagrant.has_plugin? 'landrush'\n    config.landrush.enabled = true\n    config.landrush.tld = config.vm.hostname\naliases.each do |host|\n  config.landrush.host host, ip\nend\n\nelse\n    fail_with_message \"landrush missing, please install the plugin with this command:\\nvagrant plugin install landrush\"\n  end\n```\n. Same for me, return code is the same after running the command:\nwp core multisite-install --allow-root --title=\"Site 1\" --admin_user=\"admin\" --admin_password=\"password\" --admin_email=\"admin@site1.com\"\nBefore I run into the database error mentioned above.\n. Thanks, I've checked and double checked all the resources :) Agent forwarding is in my opinion properly configured. And as I've already mentioned, there are no issues with the task when using older versions of Trellis or Ansible. I have lots of trellis projects in my environment and I'm running into this issue since upgrading to Ansible 2.0.2.0. \nWhen Ansible is cloning the project files, the task is running into a timeout in about 2 minutes. During processing the following git related processes are running on the remote server:\nroot@cms:~# ps aux | grep git\nweb       1602  0.0  0.1   4440   648 pts/0    Ss+  11:31   0:00 /bin/sh -c LANG=de_DE.UTF-8 LC_ALL=de_DE.UTF-8 LC_MESSAGES=de_DE.UTF-8 /usr/bin/python /home/web/.ansible/tmp/ansible-tmp-1464089467.55-97193409117311/git; rm -rf \"/home/web/.ansible/tmp/ansible-tmp-1464089467.55-97193409117311/\" > /dev/null 2>&1\nweb       1603  0.4  1.9  46272  9580 pts/0    S+   11:31   0:00 /usr/bin/python /home/web/.ansible/tmp/ansible-tmp-1464089467.55-97193409117311/git\nweb       1613  0.0  0.2  15168  1104 pts/0    S+   11:31   0:00 /usr/bin/git ls-remote git@mygitserver.url:dev/myrepo.git:dev/myrepo.git -t refs/tags/master\nweb       1614  0.0  0.5  46396  2672 pts/0    S+   11:31   0:00 ssh git@mygitserver.url:dev/myrepo.git git-upload-pack 'dev/myrepo.git'\nCould it be ansible and not trellis related? \n. ",
    "working-name": "@o1y I'm dealing with the same issue on Sierra 10.12.2 as host. My workaround is to quickly vagrant ssh while it is waiting to get bindfs, and sudo nano /etc/resolv.conf to replace whatever is there with 8.8.8.8 or your favorite DNS server.\nI have tried every combination of the following to no avail (these are in your Vagrantfile):\nvb.customize [\"modifyvm\", :id, \"--natdnsproxy1\", \"off\"]\nvb.customize [\"modifyvm\", :id, \"--natdnshostresolver1\", \"off\"]\nvb.customize [\"modifyvm\", :id, \"--natdnspassdomain1\", \"off\"]. ",
    "maiorano84": "Chiming in here, since I ran into the same issue with Multisite and Landrush installed. I came across this discussion that helped workaround the problem:\nhttps://discourse.roots.io/t/trellis-multisite-fresh-development-setup-not-working-at-all/7911/2\nAdding config.landrush.guest_redirect_dns = false to the Trellis Vagrant file fixed the issue for me as well.\nelsif Vagrant.has_plugin?('landrush') && multisite_subdomains?(wordpress_sites)\n    config.landrush.enabled = true\n    config.landrush.tld = config.vm.hostname\n    config.landrush.guest_redirect_dns = false # This line fixes the DNS error\n    hostnames.each { |host| config.landrush.host host, ip }\n\nThis leads me to believe that some networks don't play as nicely with Landrush. This is a known issue that has more to do with network settings itself than Landrush or Trellis. This above fix is probably the most appropriate.\nI would suggest highlighting it in the docs, or even making it a part of the Trellis Vagrantfile.. I would highlight it in the docs, first. I haven't seen too many people talking about it, so my guess is that this is affecting only a small number of people whose network firewall configurations are preventing Landrush from making outbound requests.\nI'll keep an eye on my own local installation to see if there are any unintended consequences, but so far I haven't see anything.. ",
    "nonameolsson": "I did try to have that same workflow, with node/gulp/bower, on a Vagrant machine once. My experience with the performance was awful! It was really slow.\nRunning those stuff on the host machine will give a much faster performance. @henkler What is the reason that you want those things to be installed in the Vagrantmachine if the host is running Windows? I'm just curious :)\n. @henkler great! :)\n. ",
    "henkler": "Actually, I didn't realize node/gulp/bower would actually build correctly without pulling in the entire php dev stack (composer, etc).\nTried it and it seems to be working.  Much less painful than doing it through Vagrant and mitigating symlink issues.  Thanks for pointing me in the right direction.\n. Just put in a PR for the Windows docs.  Thanks!\n. I think there may be an issue here with 'roles/deploy/templates/env.j2'.  Getting a failure on deploy.\nfailed: [staging.example.com] => (item={u'dest': u'.env', u'src': u'roles/deploy/templates/env.j2', u'name': u'.env config'}) => {\"failed\": true, \"item\": {\"dest\": \".env\", \"name\": \".env config\", \"src\": \"roles/deploy/templates/env.j2\"}, \"msg\": \"AnsibleUndefinedVariable: 'dict object' has no attribute 'value'\"}\n. Maybe this instead for env.j2?\n{{ wordpress_env_defaults | combine(wordpress_sites[site].env, vault_wordpress_sites[site].env) | to_env }}\n. Sure.  Let me run another deploy first and I'll get it submitted.\n. PR #530 submitted.\n. ",
    "urre": "Using Discourse instead\n. ",
    "wassim": "@swalkinshaw Could you reopen this? I'm getting the same error locally with Ansible 2.1.2.0\n. @swalkinshaw Could you reopen this please? I'm having the exact same issue so it seems that your commit hadn't fix anything.\n. ",
    "DavidSchargel": "My first PR ever\u2026hope I did this right.\n. As per https://www.vagrantup.com/docs/synced-folders/nfs.html, private_network is a prerequisite only due to a limitation of VirtualBox's built-in networking, not for VMware.\n. Hmmm\u2026 @austinpray\u2026I'm not even sure if that hostsupdater: 'skip' works any longer with the switch from vagrant-hostsupdater to vagrant-hostmanager a few months ago in #442. Since I'm not on VirtualBox, I can't test to see what happens definitively, but I would suspect that hostsupdater: 'skip' isn't working any longer anyway. \nHowever, for similar hostmanager functionality, I wonder if Virtualbox users should see the addition of config.hostmanager.ignore_private_ip = false to the config.hostmanager block of the VagrantFile as per the vagrant-hostmanager docs. I would think that VirtualBox users would have reported something earlier if this was the case.\n. Got it; I no longer have vagrant-hostsupdater installed. hostsupdater: 'skip' obviously needs to stay in place then. \nSince 1) that hostsupdater: \"skip\" line is only available when used on the config.vm.network :private_network entry I am moving, and 2) my PR is VMware-specific and only suppresses a warning message, let's not make that change. How do I withdraw/close this PR?\n. ",
    "duncanjbrown": "@swalkinshaw, thanks for your response. I will have a go at the approach you suggest. \n. Updated\n. ",
    "mitramejia": "Its usual to have more than one master branch as a deployment branch, for example:\ndevelop branch => deploys to staging site\nmaster branch   => deploys to production site\nreview branch    => deploys to testing environment\nMaybe read a [branch] section in each of  hosts/* files. Is it adequate to do this via ansible instead of baking this functionality into the deploy.sh script.?. @discopatrick this is a great idea, it would further improve trellis to a CI type workflow. As of now I use a ruby script  and  wp sync db to handle deploys.  . Great @swalkinshaw I'll look into it. \ud83d\udc4d \nAnd you're welcome! Thank you for making this project. Great. Thanks for pointing this out.. ",
    "matgargano": "It's your prerogative, I just know that this reads far clearer if its in the file itself and it's just 3 extra lines.\n. For prudence sake, the issue was I did not have a site_hosts defined in my config. @swalkinshaw the php.yml was copypasta afaik, i've removed it. @swalkinshaw thank you for maintaining this project!. ",
    "jalada": "With this change nothing works. All my Wordpress links etc. have literal ${WP_HOME} etc. in them. Confused... Am I doing something wrong?\nEdit: Disregard. Bad version of bedrock\n. ",
    "rhetthenckel": "I was curious if there has been any movement on this? I would LOVE to use trellis to test, provision, and deploy a multi server setup. The setup that I thought would be ideal would include:\n\nload balancer (with nginx or HAPROXY?)\n2+ web servers (scalable)\ndatabase (maybe with NFS volume mounted to all web servers webroot?)\n\nI found this tutorial on DreamCompute which uses this LAMP setup. I am no ansible expert, but maybe this is a good starting place to see how some of these things are achieved and could be incorporated into Trellis. For reference, here's another tutorial to achieve this setup manually without using ansible.. ",
    "pepijn-vanvlaanderen": "There is a forked trellis setup for Laravel (https://github.com/ptibbetts/anstead) which I have used once where the playbooks are separated and also a redis role is added. It is a bit outdated now compared to the current version of trellis, but worked properly. . Should be great to have a tutorial on this in the docs.. ",
    "swaincreates": "Sure, will give it a shot.\n. So, after taking a look at this can you maybe help me out? If we want a separate https.conf file it will have to be unique to each site right? Because they'll have unique cert names and paths. \nSo i'll have to create a site1.com-https.conf and a site2.com-https.conf and then include site1.com-https.conf if its ssl? And in that case its kind of not duplication.. more like a partial that we're including. In that case, do we still go this path? OR, do we create an https.conf file of only things that don't have unique info:\n```\n    include h5bp/directive-only/ssl.conf;\n    include h5bp/directive-only/ssl-stapling.conf;\nssl_dhparam /etc/nginx/ssl/dhparams.pem;\nssl_buffer_size 1400; # 1400 bytes to fit in one MTU\n\n{% set hsts_max_age = item.value.ssl.hsts_max_age | default(nginx_hsts_max_age) %}\n{% set hsts_include_subdomains = item.value.ssl.hsts_include_subdomains | default(nginx_hsts_include_subdomains) | ternary('includeSubdomains', None) %}\n{% set hsts_preload = item.value.ssl.hsts_preload | default(nginx_hsts_preload) | ternary('preload', None) %}\nadd_header Strict-Transport-Security \"max-age={{ [hsts_max_age, hsts_include_subdomains, hsts_preload] | reject('none') | join('; ') }}\";\n\n```\nand then just duplicate ssl cert paths/names? Thoughts?\n. Yup, coming right up\n. Sure will figure it out\n. Yea I was thinking about that as well when I was researching options... Guess thats just a matter of project style. I personally would rather not have to go look up the template, but other people aren't fond of duplication and lastly.. I'm not maintaining this thing :) You guys let me know if thats the direction you want to go and I'll recommit.\n. Tried to add line breaks appropriately based on current format - let me know if you want some formatting changes though.\n. Its working for you? I just tested it on something and I had a path issue. Was writing this post as you commented/merged.\n. Sweet! I am on ansible 1.9.3 when I tested so that could be part of problem. For me when I tried it I got this and you can see how the path is off:\nTASK: [wordpress-setup | Create WordPress configuration for Nginx] ************\nfatal: [default] => {'msg': 'AnsibleError: unable to read /Users/swain/ASPPH_Trellis/ansible/https.conf.j2', 'failed': True}\nfatal: [default] => {'msg': 'One or more items failed.', 'failed': True, 'changed': False, 'results': [{'msg': 'AnsibleError: unable to read /Users\n/swain/ASPPH_Trellis/ansible/https.conf.j2', 'failed': True}]}\n. Yup that appears to be the problem (being on lower version of Ansible) according to this issue https://github.com/ansible/ansible/issues/9551\n. Glad its working - thanks for helping me along. Love the project!\n. ",
    "reverbsoul": "Feel free to give me the proper way to create an issue and I'd be happy to do it.\n. Great, thanks for being helpful @retlehs \n. Not sure how that's much more descriptive, and it seems like other people perfectly understood what I was asking for (including yourself). But, there it is. Thanks for the assistance in professionalizing my Issue!\n. @retlehs That build went up, and I'm still getting the same error when I run 'vagrant up' - Is there perhaps a manual work-around to grab PHP7.0?\nEdit: I ran 'vagrant destroy' first to start over from scratch.\n. Third time's the charm I guess. 'vagrant destroy' => 'vagrant up' installed PHP 7 with no issues, but get a new error on TASK [wordpress-setup : Create database of sites]\nError\nfatal: [default]: FAILED! => {\"failed\": true, \"msg\": \"'dict object' has no attribute u'mysite.com'\"}\nBut ultimately this is fixed, so I'm going to close the thread. Thanks for the help in figuring out the PHP 7 and making more accustomed to how I should be reporting issues in the future.\n. ",
    "cmbirk": "I apologize, I think the server provisioning step errored out early causing this issue.  Closing.\n. ",
    "TheAggressive": "This is the error that it looks like it outputs durring installing\n==> default: TASK [wordpress-setup : Create database of sites] ******************************\n==> default: 'dict object' has no attribute u'theaggressive.com'\n==> default: fatal: [192.168.50.5]: FAILED! => {\"failed\": true}\n. I'm also having this issue. What is needed to correct?\n. OK I'll try that and report back!\n. Thanks @cadros that fixed the issue.\nI went a head and submitted the pull request for you to avoid any issues from cloning in the future. PR is here - #623 \n. It seems both ways work the same. I could change it to how you have it before installing pip.\n. I am testing from scratch to verify it's working correctly. I just made that change so its before.\n. ",
    "ofauno": "yep, I also followed the @richvida path, and the setup is green \ud83d\udc83 \n. @swalkinshaw that skips the tasks also if 127.0.0.1 is defined, that was confusing and time-consuming to see \ud83d\udc3c\n. guess we can put \"127.0.0.1\" also? \ud83d\ude04 \n. ",
    "michaelsalafia": "My deploys are working but I'm still getting 1 fail on the finalize-after.yml hook. \n```\nTASK [deploy : WordPress Installed?] *******\nSystem info:\n  Ansible 2.0.2.0; Darwin\nTrellis at \"Fix #468 - Use curl to install wp-cli tab completions\"\nPHP Warning:  Unterminated comment starting line 8 in\nphar:///usr/bin/wp/php/WP_CLI/Runner.php(792) : eval()'d code on line 8\nfatal: [127.0.0.1]: FAILED! => {\"changed\": false, \"cmd\": [\"wp\", \"core\", \"is-installed\", \"--network\"], \"delta\": \"0:00:00.250489\", \"end\": \"2016-08-15 22:47:13.498831\", \"failed\": true, \"failed_when_result\": true, \"rc\": 0, \"start\": \"2016-08-15 22:47:13.248342\", \"stderr\": \"PHP Warning:  Unterminated comment starting line 8 in phar:///usr/bin/wp/php/WP_CLI/Runner.php(792) : eval()'d code on line 8\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\n    to retry, use: --limit @deploy.retry\n```\n. ",
    "miklb": "Using master branch from trellis and bedrock, I received same error as originally reported, had to use @richvida tip of creating site with WP CLI in /srv/www/site/current for deploy task to complete.\n. Just encountered same thing setting up a new environment with an existing project.\n. ",
    "monotv": "Getting the same behaviour here as described in the issue with the current master branch from trellis and bedrock, after following all the setup steps in the docs  and with a DigitalOcean droplet.\n. ",
    "aried3r": "I'm very interested in this, any idea how is this going to be tackled? Using something like ansible-ssh-hardening or doing your own?\n. I'm interested. :)\nPersonally, I'd use ansible-ssh-hardening because it is maintained so changes there don't have to be reflected and implemented in your own config, especially with vulnerabilities showing up.\nWhat do you think?\n. Maybe as a side note: Unlike DigitalOcean, I cannot deploy a SSH key beforehand on my host (except, of course, manually). But I'd love to have the option to once use --ask-pass, then disable root login and password authentication altogether.\nI guess I can always add --ask-pass myself, once. But I was puzzled to see --ask-pass not being honored in the remote-user role and thus thought it's undesired behavior.\n. Thanks for the reply. The way I understand it, even with #564, is that I cannot pass arbitrary options at this point, correct?\nI agree, the remote-user role does indeed solve quite a few challenges (I also read all the git history of this file), and I love all the little sanity checks Trellis executes when provisioning. But I think, even though DO is quite appealing, there are many VPS hosters that just send your the root password for the initial setup. Sadly I'm bound to my hoster at this moment (also, I'm not inclined to switch hosters just because I can't pass --ask-pass ;)).\nI think for the time I'll go with manually adding --ask-pass to the remote-user role for initial setup and document that internally somewhere.\nI did not (or was unable to) find someone else with that problem, but maybe it's worth documenting somewhere, publicly?\n. Thanks, I'll check it out and report back during the week.\n. ",
    "isynergy-development": "@swalkinshaw Is this still something you want to see implemented? I never saw ansible-ssh-hardening before and now I'm most likely going to integrate it with my setup.\n. ",
    "RiFi2k": "@swalkinshaw I got this pretty much finished, I currently have tested it locally and have it deployed on my live staging server.\nJust need to test and verify sftp is still going to be working as expected because ssh-hardening is using internal-sftp with chroot directories (which is safer anyways) but obviously users that are used to using sftp will most likely want to access the web root instead of the user home folder which is default. I only use ssh in my normal day to day but I'm going to try and make a point to finish up this test and submit a PR soon.. Awesome addition right here. Got really busy but got a chance to test this branch out today in development and it worked out perfectly. Just may want to add in docs that you need to have the remote database already created in the proper format, example_com_development\nAs long as you have the database available to connect to on the remote server it will install WP for you on that database.\nThanks for the fix!\n. On chrome version 53 I get the collision message, same for 55 (unstable/dev)\nIs this something you all are still interested in getting done?\nPersonally I use .local\n. Good call, I don't use OSX so I didn't have any clue about that.\n. Without looking I'm 90% sure I worked that in. It only runs the repo update\nif user is using Xenial, if not then it stays as is.\nOn Sep 28, 2016 6:43 PM, \"Scott Walkinshaw\" notifications@github.com\nwrote:\n\nGood catch on this.\nOne issue is that Trellis currently works on both Trusty and Xenial (as\nfar as I know). We should definitely encourage and even require Xenial for\nnew installs, but someone can re-provision an existing Trusty server right\nnow without breaking anything.\nWith this PR as it is, it would update MariaDB to Xenial which might break\nTrusty?\nMaybe we have to conditionally set those default variables based on Ubuntu\nversion?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/pull/659#issuecomment-250323164, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AMEHA3lwp0pvVZ6oyaAfvFQL5THW6l18ks5quu2ggaJpZM4J_ef-\n.\n. Yeah, just took a look.\n\nwhen: ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'xenial'\nI'm running this on the step that changes the repo out and all the following steps related to upgrading all only when this step runs, so it should be 100% safe on Trusty setups because it simply will skip all my additions.\nAlthough it would probably be more elegant to set the repos based on your version of Ubuntu, I can make that change if you feel like it's better for long term support even past Xenial.\n. Good call on that.\nI'm gonna switch this around a bit and make it so it will be distribution dependent the whole way through. Add the keys and repo for trusty if you are on trusty, add the keys and repo for xenial if you are running that, and also upgrade from trusty to xenial if you are running the old trusty keys and repo on xenial.\nI'll commit the changes here and comment back when it's done.\n. Ok, so I added a check for the key based on which distribution and also for the repo to configure just using the ansible distribution variable instead of having a variable for it, to avoid confusion.\nAlso just hard coding the old trusty key as the important part is having the key for Xenial editable.\n. Seems the the versions are a match on the packages I checked.\nI guess at this point it's more about who you want maintaining your packages and updates for MariaDB and its deps.\nKeep it as is\nMariaDB Developers\nhttp://mirror.jmu.edu/pub/mariadb/repo/10.0/ubuntu/dists/xenial/main/binary-amd64/Packages\nRemove the repo completely (would probably just need to add a step for existing installs that removes the MariaDB repo and runs apt-get update, also side note would need tested to make sure after update and upgrade nothing breaks)\nUbuntu Developers\nhttp://packages.ubuntu.com/xenial/mariadb-server-10.0\nThoughts on the subject?\n. Oops, my fault for going MIA on you. I can for sure finish this up, but not thinking I got rid of my fork, doh!\nDid some research and even re-forking and pulling this pull request into the new fork won't let me make an update. I don't know if you care about losing this conversation if I had to submit a new pull request with the fix, also I'm quite sure you don't want this orphaned pull request hanging out just so it can be linked to the new one either.\nThen I saw the File System & Backups protocol from that Github blog so I already put in a support request to have it restored into my account. I would assume they would be able to take care of restoring it for me quickly and right after they do I'll shoot an update.. So while doing the ssh-hardening integration I stumbled on https://github.com/dev-sec/ansible-os-hardening which includes sysctl defaults plus some other good stuff.\nWhat would be the feeling on the possibility of adding that whole role in as well?. I saw that as well, I think if we just set\nufw_manage_defaults: false\nIt just bypasses their ufw settings altogether.. My man!\nIt seems like you put a bunch of time into research and improving this even more, from quickly reading over what you listed above I'm glad you took the time to really dig in even further.\n1. Streamline ssh-hardening role to Ubuntu, OpenSSH_6.6+\nGood call on that, stribika is super aggressive with his rules anyways, last time I tried using that whole set I couldn't barely do anything without work arounds.\n2. Enable AllowAgentForwarding, UsePAM; Restore MaxAuthTries 6\nGood catch on all these, I have my own system for deploys so I completely forgot to even test that. Also I can for sure see people having issues with the 2 keys, I don't see any reason that would affect the overall security, especially when it's all getting a huge upgrade anyways.\n3. Use lineinfile to make moduli task more succinct and idempotent\nThe moduli steps were actually secretly annoying me using shell commands, the lineinfile was an elegant solution for sure.\nJust wrapping up a fun filled DDoS attack mitigation so I'm gonna crash out but tomorrow I should have some free time, if you want me to just add those in it won't be a problem, unless you want me to just remove my moduli section and make the few small edits, then you could throw a commit on top adding in the moduli part. It is technically outside the scope of even the original ssh-hardening role.\nJust let me know, and thanks again for taking the time to do all this!. @fullyint Thanks for the revisions! Have a happy holiday!\nI think that push should take care of everything. Tested all these new additions using Fedora 25 as my desktop OS, working with no problems.\nAs for the docs it might not be a bad idea to reference using weak_hmac and weak_kex for wider support if people are having issues they can't resolve.. @fullyint thanks to you for getting it where it needed to be, I know you put in some hours on this.. I don't mind helping with one of the files so you don't have to do it all, I can just make a gist and then you can just copy paste and rebase in what helps clean it up. Let me know if you want to split it up a little.. https://gist.github.com/RiFi2k/41f3874f9747c9a5e611b105e373100a\nCleaned up and edited text on ssh-hardening/defaults/main.yml hopefully it saves a little time for you.. ",
    "ssnepenthe": "Glad to help in whatever little way I can, and thanks for the quick fix!\nI have known about this project for a while but only just trying it out for the first time now. You guys are doing some awesome work over here - thanks for this amazing tool!\n. ",
    "twinleafdev": "Or perhaps update the docs to  subdomains: false\n. ",
    "fredcerdeira": "Thanks for your support!\n. ",
    "bostondv": "Putting the domain in the hosts file works fine for me as well. The problem I have really is when running a subdomain multisite network with landrush. Landrush doesn't seem to overcome the name collision and I'd rather not have to put a host entry for every subdomain in the multisite network :)\n. Ah, thanks. I'll revise it to 4k.\nOn Fri, May 13, 2016, 8:14 PM Scott Walkinshaw notifications@github.com\nwrote:\n\nI'm fine with adding this but the default is actually 4k on Ubuntu.\nBy default, the buffer size is equal to one memory page. This is either 4K\nor 8K, depending on a platform\n$ getconf PAGESIZE\n4096\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/roots/trellis/pull/586#issuecomment-219187644\n. Revised!\n. \n",
    "iamjoshellis": "I think Apple uses .local for bonjour services on OSX, which could cause potential conflicts.\nhttps://support.apple.com/en-gb/HT203136\n. Yea, I'd agree with .test\n. @tylerfoulkes if you've changed the configuration after initializing the vagrant box you'll need to provision again with either:\nvagrant provision while it's running.\nOr vagrant up --provision when starting it up.\n. ",
    "pixeline": "We use *.loc  . ",
    "iDuuck": "Done! Forgot to add theluxuryjournal.com to the vault config.\n. ",
    "jerome-toole": "thanks @iDuuck exactly my mistake \ud83d\udc30 \n. I think that's a good idea. I've actually done this a couple of times since. :man_facepalming: . ",
    "corysimmons": "Same. There are a lot of places to remember to put this before provisioning for 10 minutes.\nRoots Team: It might be a good idea to test for these values to sync up before running the other provisioners. /shrug. ",
    "sw33tr": "yep, happened to me as well :1st_place_medal: . ",
    "ajithrn": "it happened to me as well and it took too long to fix it too :( . ",
    "apmarshall": "Had this happen as well, and after checking (and re-checking) that had the domain right everywhere, variables correct, no spelling mistakes, etc, still couldn't get to work. I'm an emacs user, and finally realized that when I first edited wordpress_sites.yml, emacs was creating a wordpress_sites.yml~ temporary file. The presence of this extra file, which didn't have the right domain name/variables in it, was throwing Ansible off, removing it fixed the problem right away. So if any other emacs users are struggling with this particular issue, hopefully this will save you some time and frustration. Not sure if there's a way to make Ansible be able to tell the difference between the two files and always choose the right one, but someday I'll get around to looking into that.. I hear what you are saying about these files not changing very often. I actually think that's an argument in favor of making this change: by renaming the files with .example, we ensure that no user will get surprised by pulling down changes from roots/trellis and discovering that a file that hasn't been updated in 7 months was updated yesterday and now conflicts with their local branch.. @mindfullsilence I would say there are probably two reasons to take the file approach instead of the directory approach:\nFirst, there are a number of things in the directory that are more in the \"application logic\" category rather than the \"strictly local configuration\" category. Those are things that are more likely to be updated routinely as new features are added and refined, so having to copy and paste over changes from the example directory after every update would in the long-run be a lot more labor intensive than having to deal with copying multiple files at project kickstart. These \"application logic\" files are also the sorts of files that if you are making changes that deviate from upstream, you are doing so very intentionally and probably want that committed into your own branch/fork, so removing from git doesn't seem that helpful here. Taking the individual file approach lets us keep our focus only on the files that contain strictly local configurations that you probably don't want in git to begin with.\nSecond, I'm not convinced it will be that labor intensive. My experience (admittedly not nearly as extensive as a lot of folks here, so perhaps not worth mentioning) is that you update the local configuration files piecemeal rather than all at once. For example, when I'm starting a project, I update the local wordpress_sites and vault configs, then do a lot of local development work before I want a staging server. Then I update the staging stuff, but it may still be a while (especially if staging is primarily for showcasing to a client before launch) before I care about the production configs. So probably I'm copying over two files from .example when I first start, then a few more at each stage of development. I was going to have to rewrite basically everything in those files anyway, so adding a \"copy from .example\" step first doesn't seem to be a big addition.. ",
    "kristofferse": "@swalkinshaw awesome! Thanks. And how would i go about do the update manually in the best manner? Sry, quiet new to git. :/\n. ",
    "vercotux": "Ok so I think the problem might be in the hosts file.\nI have defined the same IP addresses for both the production and the staging servers (because, obviously I want both of them to run on the same server).\n. For me it happens with WordPress Meta Data & Taxonomies Filter, when adding their widget.\nAnd indeed the bug does not occur on production & staging environments.\n. I am unsure whether it works, because the patch creates numerous other issues.\nFirst I had to ssh into the deployed server and manually update wp-cli to nightly (using wp --allow-root cli update --nightly), because deployment would crash otherwise.\nI was then able to run the deployment script (./deploy.sh production example.com), but nothing changed even after rebooting the server. The SSL issue is still there.\nI am now trying to run ansible-playbook server.yml -e env=production --tags \"letsencrypt\", however I get the following error:\n```\nTASK [letsencrypt : Create needed Nginx confs for challenges] ******\nSystem info:\n  Ansible 2.1.1.0; Linux\n  Trellis at \"Require Ansible 2.0.2 and remove deploy_helper\"\n\nlookup_plugin.pipe(curl -4 -s https://api.ipify.org) returned 6\nfatal: [example.com]: FAILED! => {\"failed\": true}\n```\nEDIT: It finally worked after I wiped all the letsencrypt related files (rm -rf /var/lib/letsencrypt /usr/local/letsencrypt /srv/www/letsencrypt /etc/nginx/ssl/letsencrypt /etc/ssl/certs/lets-encrypt-x3-cross-signed.pem) and re-provisioned the server (ansible-playbook server.yml -e env=production).\n. I am unsure how I can update trellis when it is bundled with a project that is already in production. This is not documented anywhere.\n. May I suggest adding this type of info to the main documentation page (perhaps under the topic called \"Updating Trellis\")? It would be enormously helpful to everyone! Thank you for all the amazing work!\n. ",
    "hintings": "@swalkinshaw I have done that already, it's part of trellis install instructions in the docs. \nI also tried that again when I received the error message.\nPlease, open the issue again.\n. @retlehs Why do say that it's personal support? It's an issue with Trellis\n. The Ansible version wasn't the problem. \nI don't remember how I installed Vagrant anymore but it turned out that I needed v1.8.4\nI also had to sudo apt-get install nfs-common nfs-kernel-server\n. @swalkinshaw well, that's really weird! Because I wasn't able to install any vagrant plugins until I updated to vagrant 1.8.4 instead of 1.8.1. \n. ",
    "danstefancu": "Well, it's not really an issue, as pip is only used to install ansible 2.0.2. Building the entire dependency tree for pip will just add time to the installation and nothing else.\nTested the ansible to setup a server and deploy a release, with this patched version, and everything works as expected.\n. Note: this patch is for short term usage (couple of weeks), and can be removed once ansible 2.1.1 is stable and published to launchpad, to be installed via apt-get. Without this, trellis is unusable from a windows host.\n. ",
    "cadros": "Sure, anything to make windows users' life easier. How do I better describe it, the message? \n. TheAggressive, sorry, didn't make it today (it's night where i am), will PR for re-adding the sudo apt-get -y update line tomorrow\nmeanwhile i guess you could just temporarily add it manually back to windows.sh file right before the point where it installs the pip\n. ",
    "gchaincl": "that was fast, and it worked, thanks!\n. ",
    "runofthemill": "Yeah, I realize sem versioning wouldn't eliminate breaking changes, I guess it's just that if it were used (along with more releases) it would be easier to know what can be merged with what sort of repercussions. \nI guess my concern is more about more comprehensive documentation and/or more frequent releases, and perhaps holding on publishing documentation changes to roots.io if they aren't part of a release? I'm not sure when the feature was added, but the WP<->GH sync plugin now supports publishing to WP even if the post doesn't exist beforehand. It indicates that only docs on the master branch will get published, so that could be used for the docs for the current release, and changes related to head could be branched, then merged when they get released - just a thought.\n. Here's a workflow that might help with the issues Trellis users are facing - https://www.thoughtworks.com/insights/blog/enabling-trunk-based-development-deployment-pipelines\n. Circling back on this - now that #630 has been merged, perhaps it's a good time to bump Trellis to 1.0 and start using semver? \ud83d\ude01. Closed by #1055 \ud83d\udc4f\ud83c\udffb\ud83c\udf89\ud83d\udcaf. Re: the first issue - I haven't done any testing beyond my system, but this works: \n- update geerlingguy.composer in requirements.yml to 1.4.2\n- in helpers.yml set wp_home to \"{{ item.value.ssl.enabled | default(false) | ternary('https', 'http') }}://{{ ansible_fqdn }}\"\nRunning the following:\nAnsible 2.0.2.0\nOSX 10.11.6\nVagrant 1.8.5\nSince deploy.yml also sets wp_home, that probably needs to be changed too, but I haven't provisioned/deployed to a remote server yet.\n. Continuing the conversation from #646 - Ansible provides easy access to system facts that can be used here and elsewhere: http://docs.ansible.com/ansible/playbooks_variables.html#information-discovered-from-systems-facts\nI think it may be good to use {{ ansible_fqdn }} instead of a filter - I think it was in this video where Jeff talks about the idea that Ansible roles/playbooks shouldn't attempt to use Ansible as a programming language (i.e. using lots of complex logic, filters, etc.) and as a whole Trellis could probably benefit from a reduction in complexity - this (IMO) is a good place to take advantage of that!\n. @thisolivier @fullyint I see your points - I was using it with vagrant in the context of the local dev server, which I mentioned in the other post (but not here); my only other thought is I'd just suggest leaving wp_siteurl as \"${WP_HOME}/wp\" to keep things DRY.\n. I've been dealing with some related issues, and wanted to note that MariaDB is available in Trusty Tahr 14.04 onwards - the first two tasks in trellis/roles/mariadb/tasks/main.yml (and accompanying variables in defaults/main.yml) can be removed without impacting the playbook, at least on a fresh installation on df376a0aec8aa273c85ea8dd3c8ac807bf4b0f3a.\n. agree with @swalkinshaw - keeps the code DRYer too\n. Makes sense. I plan on integrating the WP install into my current project's server.yml so perhaps when I'm done I'll submit a PR.\nRe: 2; for my own knowledge, what specifically do you guys find problematic (in practice or in theory) with compiling remotely?\n. this would be great to get merged - would allow Trellis to use https://github.com/masonicboom/ipscrub to reduce the surface area for GPDR issues. @strarsis that looks like it'd require a major refactor, since currently nginx is built & configured without an ansible-galaxy role, so highly unlikely, imo. did you try this PR with TangRufus' snippet to see if it works?. I'll try and submit a PR against this to fix in the next few days :). So it appears!\nI see there's an open PR for a partial fix (https://github.com/geerlingguy/ansible-role-composer/pull/43), so hopefully that gets merged soon. Apologies for not seeing your previous note in #895 - I did a search in the repo before submitting the issue, but somehow didn't catch that.. @abentley the warning is generated by Ansible, so not really a Trellis issue. You could try running a playbook with -v/-vv/-vvv and see if the verbose output identifies where the warning's being triggered?. woohoo! thanks @geerlingguy . Just ran into this - perhaps related to changes in the most recent bento box https://github.com/chef/bento/blob/master/CHANGELOG.md#201803240-2018-03-24\nThanks for the quick fix!. What do you think about making 2.5.1 the minimum requirement for the 1.0.0 milestone?. @fullyint I've had that issue too, working on an older project that needed Ansible 2.3.x, and it was definitely a complication, so I see your reservations there. \nHonestly I think it's just a good opportunity to get ahead of some issues that would require a minor version release that anyone with multiple Trellis projects will have to deal with eventually. If Trellis is going to follow sem-ver once it hits 1.0.0 (see #634) in my mind it makes sense to deal with sooner rather than later, to be able to take advantage of all the work that's gone into improving functionality & bug fixes in Ansible.\nOn the other hand, it'd probably be easy to do down the line too as a minor release, so take the above as me just thinking aloud :). ",
    "creativematter": "I am also getting this error (it only shows up for websites that are running WP 4.6, earlier versions work as expected). Here is one of the error outputs:\n`PHP Fatal error:  Uncaught Error: Call to undefined function apply_filters()\nin /srv/www/example.com/current/web/wp/wp-includes/load.php:317\nStack trace:\n0 phar:///usr/bin/wp/php/utils-wp.php(22): wp_debug_mode()\n1 phar:///usr/bin/wp/php/wp-settings-cli.php(59):\nWP_CLI\\Utils\\wp_debug_mode()\n2 phar:///usr/bin/wp/php/WP_CLI/Runner.php(807):\nrequire('phar:///usr/bin...')\n3 phar:///usr/bin/wp/php/WP_CLI/Runner.php(755):\nWP_CLI\\Runner->load_wordpress()\n4 phar:///usr/bin/wp/php/wp-cli.php(21): WP_CLI\\Runner->start()\n5 phar:///usr/bin/wp/php/boot-phar.php(5): include('phar:///usr/bin...')\n6 /usr/bin/wp(4): include('phar:///usr/bin...')\n7 {main}\nthrown in /srv/www/example.com/current/web/wp/wp-includes/load.php\non line 317\nfailed: [default] (item=example.com) => {\"changed\": true, \"cmd\": [\"wp\", \"core\", \"install\", \"--allow-root\", \"--url=http://${HTTP_HOST}\", \"--title=Website\", \"--admin_user=a\", \"--admin_password=b\", \"--admin_email=example@example.com\"], \"delta\": \"0:00:00.077265\", \"end\": \"2016-08-19 15:43:44.375947\", \"failed\": true, \"item\": \"example.com\", \"rc\": 255, \"start\": \"2016-08-19 15:43:44.298682\", \"stderr\": \"PHP Fatal error:  Uncaught Error: Call to undefined function apply_filters() in /srv/www/example.com/current/web/wp/wp-includes/load.php:317\\nStack trace:\\n#0 phar:///usr/bin/wp/php/utils-wp.php(22): wp_debug_mode()\\n#1 phar:///usr/bin/wp/php/wp-settings-cli.php(59): WP_CLI\\Utils\\wp_debug_mode()\\n#2 phar:///usr/bin/wp/php/WP_CLI/Runner.php(807): require('phar:///usr/bin...')\\n#3 phar:///usr/bin/wp/php/WP_CLI/Runner.php(755): WP_CLI\\Runner->load_wordpress()\\n#4 phar:///usr/bin/wp/php/wp-cli.php(21): WP_CLI\\Runner->start()\\n#5 phar:///usr/bin/wp/php/boot-phar.php(5): include('phar:///usr/bin...')\\n#6 /usr/bin/wp(4): include('phar:///usr/bin...')\\n#7 {main}\\n  thrown in /srv/www/example.com/current/web/wp/wp-includes/load.php on line 317\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\n`\n. @arashohadi Ahh thanks! I had checked my wp-cli version on the host, but not the virtual machine. Updating it on the virtual machine fixed it for me.\n. ",
    "arashohadi": "@kikandrew Updating WP_CLI on the server to the latest version fixed that error for me.\n. Hi @fullyint! \nI just tried implementing the changes from this pull request (was on https://github.com/roots/trellis/commit/8453c53213eb722e5293dded8cceff3ebf33a493).\nI am on a Windows host and using Winnfsd. On https://github.com/roots/trellis/commit/8453c53213eb722e5293dded8cceff3ebf33a493 everything works fine and Winnfsd is able to mount the shared folders that I have.\nBut when running vagrant up with the changes from this file, it seems the winnfsd.exe starts up but instantly crashes (noted in Task Manager).\nRunning vagrant up --debug gives me this information when trying to mount (which is not so strange considering the .exe has crashed).\n```\nset -e\nmkdir -p /vagrant-nfs\nmount -o vers=3,udp,vers=3,udp,nolock 192.168.50.1:/C/Projects/Trellis /vagrant-nfs\nif command -v /sbin/init && /sbin/init --version | grep upstart; then\n  /sbin/initctl emit --no-wait vagrant-mounted MOUNTPOINT=/vagrant-nfs\nfi\nStdout from the command:\nStderr from the command:\nmount.nfs: Connection timed out\n```\nJust let me know if you need more information from me to help you.. Some more information:\n\nTried upgrading vagrant-winnfsd from 1.3.0 to 1.3.1. Didn't help unfortunately, same behavior as above.\nI also tried upgrading vagrant-bindfs from 0.4.9 to 1.0.1. This gave another interesting error directly after running the vagrant up command.\n\nvagrant-bindfs:\n* Destination path '/vagrant/bin' is part of a reserved subtree for Vagrant use\nI looked at the repo and found this commit https://github.com/gael-ian/vagrant-bindfs/commit/f07ab7c18059e0f4e5c245577c8f6a4937d887f7. Especially this line is interesting \nRemember that Vagrant use `/vagrant` on guest side as a shared directory dedicated to provisioning and configuration. Binding a folder to `/vagrant` or one of its subfolders will fail.. I understand the concerns for performance. If I can help in any way, just let me know.. ",
    "peebeebee": "While this fixes @kikandrew 's issue, it does not resolve @runofthemill 's\nEDIT:\n.env did not have its http_host and wp_home variables filled in. It's still the placeholders.\nI see that in Bedrock modes have been changed from 755 to 644. Maybe it has to do with this?\n. ",
    "OezlemYi": "Still getting this error. Here is the error output:\n``TASK [wordpress-install : Install WP] ******\nSystem info:\n  Ansible 2.1.1.0; Vagrant 1.8.5; Darwin\n  Trellis at \"Fix #639 - WP 4.6 compatibility: update WP-CLI to 0.24.1\"\n\nPHP Fatal error:  Uncaught phpmailerException: Invalid address:\nwordpress@${http_host} in /srv/www/hangout.com/current/web/wp/wp-includes\n/class-phpmailer.php:946\nStack trace:\n0 /srv/www/hangout.com/current/web/wp/wp-includes/pluggable.php(352):\nPHPMailer->setFrom('wordpress@${htt...', 'WordPress')\n1 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(392):\nwp_mail('admin@hangout.d...', 'New WordPress S...', 'Your new WordPr...')\n2 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(95):\nwp_new_blog_notification('hangout.com', 'http://${HTTP_H...', 1, 'The\npassword yo...')\n3 phar:///usr/bin/wp/php/commands/core.php(763): wp_install('hangout.com',\n'admin', 'admin@hangout.d...', true, '', 'admin')\n4 phar:///usr/bin/wp/php/commands/core.php(573):\nCore_Command->_install(Array)\n5 [internal function]: Core_Command->install(Array, Array)\n6 phar:///usr/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67):\ncall_user_func(Array, Array, Array)\n7 [internal function]: WP_CLI\\Dispatcher\\CommandFactory::WP_C in\n/srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php on line\n946\nfailed: [default] (item=hangout.com) => {\"changed\": true, \"cmd\": [\"wp\", \"core\", \"install\", \"--allow-root\", \"--url=http://${HTTP_HOST}\", \"--title=hangout.com\", \"--admin_user=admin\", \"--admin_password=admin\", \"--admin_email=admin@hangout.dev\"], \"delta\": \"0:00:01.380342\", \"end\": \"2016-08-26 11:46:27.534314\", \"failed\": true, \"item\": \"hangout.com\", \"rc\": 255, \"start\": \"2016-08-26 11:46:26.153972\", \"stderr\": \"PHP Fatal error:  Uncaught phpmailerException: Invalid address: wordpress@${http_host} in /srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php:946\\nStack trace:\\n#0 /srv/www/hangout.com/current/web/wp/wp-includes/pluggable.php(352): PHPMailer->setFrom('wordpress@${htt...', 'WordPress')\\n#1 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(392): wp_mail('admin@hangout.d...', 'New WordPress S...', 'Your new WordPr...')\\n#2 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(95): wp_new_blog_notification('hangout.com', 'http://${HTTP_H...', 1, 'The password yo...')\\n#3 phar:///usr/bin/wp/php/commands/core.php(763): wp_install('hangout.com', 'admin', 'admin@hangout.d...', true, '', 'admin')\\n#4 phar:///usr/bin/wp/php/commands/core.php(573): Core_Command->_install(Array)\\n#5 [internal function]: Core_Command->install(Array, Array)\\n#6 phar:///usr/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67): call_user_func(Array, Array, Array)\\n#7 [internal function]: WP_CLI\\Dispatcher\\CommandFactory::WP_C in /srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php on line 946\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\nNO MORE HOSTS LEFT *********\nRUNNING HANDLER [common : restart memcached] *****\nchanged: [default]\nRUNNING HANDLER [common : reload php-fpm] ********\nchanged: [default]\nRUNNING HANDLER [common : reload nginx] ******\nchanged: [default]\nRUNNING HANDLER [common : perform nginx reload] ********\nchanged: [default]\nRUNNING HANDLER [fail2ban : restart fail2ban] ******\nchanged: [default]\nRUNNING HANDLER [ferm : restart ferm] ******\nskipping: [default]\nRUNNING HANDLER [ntp : restart ntp] ********\nchanged: [default]\nRUNNING HANDLER [sshd : restart ssh] *******\nchanged: [default]\n    to retry, use: --limit @/Users/Madlax/Websites/hangout/trellis/dev.retry\nPLAY RECAP ***********\ndefault                    : ok=102  changed=80   unreachable=0    failed=1   \nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\n`\n```\nWP-CLI, Vagrant and Ansible are up to date:\n```\nMadlax@Madlax-MacBook-Pro ~> vagrant version\nInstalled Version: 1.8.5\nLatest Version: 1.8.5\nYou're running an up-to-date version of Vagrant!\nMadlax@Madlax-MacBook-Pro ~> wp cli version\nWP-CLI 0.24.1\nMadlax@Madlax-MacBook-Pro ~> ansible --version\nansible 2.1.1.0\n  config file = /Users/Madlax/Websites/hangout/trellis/ansible.cfg\n  configured module search path = Default w/o overrides \n```\n. Downgraded my Ansible to 2.0.2.0. Still getting this error.\n``TASK [wordpress-install : Install WP] ******\nSystem info:\n  Ansible 2.0.2.0; Vagrant 1.8.5; Darwin\n  Trellis at \"Fix #639 - WP 4.6 compatibility: update WP-CLI to 0.24.1\"\n\nPHP Fatal error:  Uncaught phpmailerException: Invalid address:\nwordpress@${http_host} in /srv/www/hangout.com/current/web/wp/wp-includes\n/class-phpmailer.php:946\nStack trace:\n0 /srv/www/hangout.com/current/web/wp/wp-includes/pluggable.php(352):\nPHPMailer->setFrom('wordpress@${htt...', 'WordPress')\n1 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(392):\nwp_mail('admin@hangout.d...', 'New WordPress S...', 'Your new WordPr...')\n2 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(95):\nwp_new_blog_notification('hangout.com', 'http://${HTTP_H...', 1, 'The\npassword yo...')\n3 phar:///usr/bin/wp/php/commands/core.php(763): wp_install('hangout.com',\n'admin', 'admin@hangout.d...', true, '', 'admin')\n4 phar:///usr/bin/wp/php/commands/core.php(573):\nCore_Command->_install(Array)\n5 [internal function]: Core_Command->install(Array, Array)\n6 phar:///usr/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67):\ncall_user_func(Array, Array, Array)\n7 [internal function]: WP_CLI\\Dispatcher\\CommandFactory::WP_C in\n/srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php on line\n946\nfailed: [default] (item=hangout.com) => {\"changed\": true, \"cmd\": [\"wp\", \"core\", \"install\", \"--allow-root\", \"--url=http://${HTTP_HOST}\", \"--title=hangout.com\", \"--admin_user=admin\", \"--admin_password=admin\", \"--admin_email=admin@hangout.dev\"], \"delta\": \"0:00:01.333393\", \"end\": \"2016-08-29 08:27:58.312015\", \"failed\": true, \"item\": \"hangout.com\", \"rc\": 255, \"start\": \"2016-08-29 08:27:56.978622\", \"stderr\": \"PHP Fatal error:  Uncaught phpmailerException: Invalid address: wordpress@${http_host} in /srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php:946\\nStack trace:\\n#0 /srv/www/hangout.com/current/web/wp/wp-includes/pluggable.php(352): PHPMailer->setFrom('wordpress@${htt...', 'WordPress')\\n#1 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(392): wp_mail('admin@hangout.d...', 'New WordPress S...', 'Your new WordPr...')\\n#2 /srv/www/hangout.com/current/web/wp/wp-admin/includes/upgrade.php(95): wp_new_blog_notification('hangout.com', 'http://${HTTP_H...', 1, 'The password yo...')\\n#3 phar:///usr/bin/wp/php/commands/core.php(763): wp_install('hangout.com', 'admin', 'admin@hangout.d...', true, '', 'admin')\\n#4 phar:///usr/bin/wp/php/commands/core.php(573): Core_Command->_install(Array)\\n#5 [internal function]: Core_Command->install(Array, Array)\\n#6 phar:///usr/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67): call_user_func(Array, Array, Array)\\n#7 [internal function]: WP_CLI\\Dispatcher\\CommandFactory::WP_C in /srv/www/hangout.com/current/web/wp/wp-includes/class-phpmailer.php on line 946\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\nNO MORE HOSTS LEFT *********\nRUNNING HANDLER [common : restart memcached] *****\nchanged: [default]\nRUNNING HANDLER [common : reload php-fpm] ********\nchanged: [default]\nRUNNING HANDLER [common : reload nginx] ******\nincluded: /Users/Madlax/Websites/hangout/trellis/roles/common/tasks/reload_nginx.yml for default\nRUNNING HANDLER [common : command] *********\nchanged: [default]\nRUNNING HANDLER [common : service] *********\nchanged: [default]\nRUNNING HANDLER [fail2ban : restart fail2ban] ******\nchanged: [default]\nRUNNING HANDLER [ferm : restart ferm] ******\nskipping: [default]\nRUNNING HANDLER [ntp : restart ntp] ********\nchanged: [default]\nRUNNING HANDLER [sshd : restart ssh] *******\nchanged: [default]\n    to retry, use: --limit @/Users/Madlax/Websites/hangout/trellis/dev.retry\nPLAY RECAP ***********\ndefault                    : ok=108  changed=80   unreachable=0    failed=1   \nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\n`\n```\n. ",
    "ababra": "Solved this by downgrading my Ansible version from 2.1.1.0 to 2.0.2.0. On Mac:\nsudo -H pip uninstall ansible\nsudo pip install ansible==2.0.2.0\nVagrant: 1.8.5\nWP-CLI (inside of VM): 0.24.1\n. ",
    "solace": "For reference, I had this issue, updated WP-CLI on the VM. Fixed it.\nAdded another site, and the issue cropped up again. Downgraded Ansible. Fixed it.\nSo, can't tell if the fixes are fixes, or red herrings.\nOSX\nVagrant: 1.8.5\nWP-CLI (vm): 0.24.0\nAnsible: 2.0.2.0 (previously 2.1.1.0)\n. I was going to amend my comment in #639, but just wanted to add, even if you have updated WP-CLI, the error appears to be intermittent. Rerunning vagrant reload --provision occasionally succeeds. So if you're still seeing this error, try another couple of times and it might come good.\n. ",
    "tylerfoulkes": "Im getting a \"This site can\u2019t be reached\" error when I use the site address in my wordpress_sites file.\n. @cfxd Yes, it says its running fine and it matches my config file. I did however boot up a VM with the wrong address in my config file. I then changed the address and booted up the VM again. The current config file lists the correct address.\n. @iamjoshellis I tried running the vagrant up --provision command and it failed at TASK [wordpress-install : Install WP]. I checked out the Fix #639 and I checked my current trellis build and it includes the wp_cli_version: 0.24.1 line in the main.yml so it seems like everything is up to date. However it is still failing at TASK [wordpress-install : Install WP] and spits out the following error:\n```\nSystem info:\n  Ansible 2.1.1.0; Vagrant 1.8.5; Darwin\n  Trellis at \"Fix #639 - WP 4.6 compatibility: update WP-CLI to 0.24.1\"\n\nPHP Fatal error:  Uncaught phpmailerException: Invalid address:\nwordpress@${http_host} in /srv/www/msuexponent.com/current/web/wp/wp-includes\n/class-phpmailer.php:946\nStack trace:\n0 /srv/www/msuexponent.com/current/web/wp/wp-includes/pluggable.php(352):\nPHPMailer->setFrom('wordpress@${htt...', 'WordPress')\n1 /srv/www/msuexponent.com/current/web/wp/wp-\nadmin/includes/upgrade.php(392): wp_mail('tylerfoulkes10@...', 'New WordPress\nS...', 'Your new WordPr...')\n2 /srv/www/msuexponent.com/current/web/wp/wp-admin/includes/upgrade.php(95):\nwp_new_blog_notification('msuexponent.com', 'http://${HTTP_H...', 1, 'The\npassword yo...')\n3 phar:///usr/local/bin/wp/php/commands/core.php(763):\nwp_install('msuexponent.com', 'admin', 'tylerfoulkes10@...', true, '',\n'admin')\n4 phar:///usr/local/bin/wp/php/commands/core.php(573):\nCore_Command->_install(Array)\n5 [internal function]: Core_Command->install(Array, Array)\n6 phar:///usr/local/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67):\ncall_user_func(Array, Array, Array)\n7 [internal functio in /srv/www/msuexponent.com/current/web/wp/wp-includes\n/class-phpmailer.php on line 946\nfailed: [default] (item=msuexponent.com) => {\"changed\": true, \"cmd\": [\"wp\", \"core\", \"install\", \"--allow-root\", \"--url=http://${HTTP_HOST}\", \"--title=msuexponent.com\", \"--admin_user=admin\", \"--admin_password=admin\", \"--admin_email=tylerfoulkes10@gmail.com\"], \"delta\": \"0:00:06.093297\", \"end\": \"2016-08-30 23:45:25.713351\", \"failed\": true, \"item\": \"msuexponent.com\", \"rc\": 255, \"start\": \"2016-08-30 23:45:19.620054\", \"stderr\": \"PHP Fatal error:  Uncaught phpmailerException: Invalid address: wordpress@${http_host} in /srv/www/msuexponent.com/current/web/wp/wp-includes/class-phpmailer.php:946\\nStack trace:\\n#0 /srv/www/msuexponent.com/current/web/wp/wp-includes/pluggable.php(352): PHPMailer->setFrom('wordpress@${htt...', 'WordPress')\\n#1 /srv/www/msuexponent.com/current/web/wp/wp-admin/includes/upgrade.php(392): wp_mail('tylerfoulkes10@...', 'New WordPress S...', 'Your new WordPr...')\\n#2 /srv/www/msuexponent.com/current/web/wp/wp-admin/includes/upgrade.php(95): wp_new_blog_notification('msuexponent.com', 'http://${HTTP_H...', 1, 'The password yo...')\\n#3 phar:///usr/local/bin/wp/php/commands/core.php(763): wp_install('msuexponent.com', 'admin', 'tylerfoulkes10@...', true, '', 'admin')\\n#4 phar:///usr/local/bin/wp/php/commands/core.php(573): Core_Command->_install(Array)\\n#5 [internal function]: Core_Command->install(Array, Array)\\n#6 phar:///usr/local/bin/wp/php/WP_CLI/Dispatcher/CommandFactory.php(67): call_user_func(Array, Array, Array)\\n#7 [internal functio in /srv/www/msuexponent.com/current/web/wp/wp-includes/class-phpmailer.php on line 946\", \"stdout\": \"\", \"stdout_lines\": [], \"warnings\": []}\n```\n. ",
    "thisolivier": "@runofthemill Since ansible_fqdn relies on an external lookup, this could result in some very strange behaviour, see here.- I'm imagining if you're deploying the production version while the domain is still in use elsewhere. My apologies if that's not relevant here.\n. Not the same issue- not a multisite issue. The issue here is that permalink structure will not skip when it's supposed to. Apologies if I'm missing something. \n. I can't comment on the refactoring of the multisite install (which, very elegant btw, looks like django syntax, which I didn't know came into ansible at all), but the conditional now works as expected. Many thanks!\n. ",
    "mikaelwedemeyer": "You should be using the issue template:\nhttps://github.com/roots/trellis/blob/master/.github/ISSUE_TEMPLATE.md\nThat said it's due to how git is set by default on windows. You need it set to the following:\ngit config --global core.autocrlf input\nHere is the help article: https://help.github.com/articles/dealing-with-line-endings/#platform-mac\nNote, DON'T FOLLOW the windows directions as that is what is causing your issue, git is trying to be helpful.\nYou can set this on a repo or global level. Note, you need to Remove the repo, set it globally and then clone again, otherwise you'll likely have issues.\n. @partounian I'm not sure if this is helpful, and it probably isn't the appropriate forum for a discussion as opposed to on the Trellis discourse, but we have the same issue, so use self-signed certificates for Cloudflare sites on trellis, which is fine as long as you don't have strict SSL checking enabled in Cloudflare.\nI know I investigated the alternative Letsencrypt verification methods and considered making this modification ourselves, but the self-signed solution works.\nAlso, I saw Letencrypt has wildcard certificates and TXT based domain verification, so a change to support that in Trellis in the future as an alternate SSL provider from the current Letsencrypt approach is a way to do.. ",
    "ftrudeau": "Thanks for your help.\n. That did the trick, thanks.\n. ",
    "bradleyess": "This is great Guillaume, i've tried to use it and having some errors on provision. \nI can't seem to figure out where best to place\nbackup_target_user: \n  backup_target_pass:\nAs I'm trying to backup to S3. Currently my main.yml is like this :\n``---\n- name: Ensure python pip and paramiko dependencies are installed\n  apt:\n    name:\n      - python-pip\n      - python-dev\n      - libffi-dev\n    state: present\n- name: Ensure paramiko is installed\n  pip: name=paramiko state=present\n\n\nname: Create backup jobs\n  set_fact:\n    backup_user: \"{{ admin_user }}\"\n    backup_group: sudo\nbackup_mysql_user: \"{{ mysql_root_user }}\"\nbackup_mysql_pass: \"{{ mysql_root_password }}\"\n\n\nvars:\n    backup_target_user: OMITTED\n    backup_target_pass: OMITTED\n# Define the backup jobs\nbackup_profiles:\n# # Backup uploads\n#   - name: \"{{ item.key }}_uploads\"\n#     schedule: \"{{ '0 3 * * *' if site_auto_backup else '0 3 31 2 *' }}\" # At 3am every day or on February 31 if not auto\n#     source: \"{{ www_root }}/{{ item.key }}/shared/uploads\"\n#     target: \"{{ item.value.target }}/uploads\"\n\n# Backup database\n  - name: \"{{ item.key }}_database\"\n    schedule: \"{{ '0 4 * * *' if site_auto_backup else '0 4 31 2 *' }}\" # At 4am every day or on February 31 if not auto\n    source: \"mysql://{{ item.key | underscore }}_{{ env }}\"          # Backup prefixes: postgresql://, maysql://, mongo://\n    target: \"{{ item.value.target }}/database\"\n\nwhen: site_uses_backup\n  with_dict: \"{{ wordpress_sites }}\"\n  register: backup_jobs\nname: make a list\n  set_fact: backup_profiles=\"{{ backup_jobs.results | selectattr('ansible_facts', 'defined') | map(attribute='ansible_facts.backup_profiles.0') | list }} + {{ backup_jobs.results | selectattr('ansible_facts', 'defined') | map(attribute='ansible_facts.backup_profiles.1') | list }}\"\n`\n```\nI have tried without the vars title too.\n. Makes perfect sense @guilro but I'm having absolutely no luck getting this working with S3. \nI've tried every variation on the scheme I can think of and find and still get this error.\nthe field 'args' has an invalid value, which appears to include a variable\nthat is undefined. The error was: 'dict object' has no attribute 'target'\nHave you tried this with backends that require auth?\n. Just can't get this to work full stop regardless of the target\n. This thread is getting exciting! Can't wait to see this pan out.. I have a fork of Trellis working with Symfony - I'd be happy to contribute on this.. Yep - I'll submit PR shortly.. Updated PR with cache_config grouping and missing ;\nI don't know where I stand on making this default behaviour or not, I think it could lead to some confusion - like I said in my initial suggestion - this isn't a perfect solution for all applications. Which makes me think it should be opt in behaviour.. @swalkinshaw - maybe I'm missing something actually, I guess this works in conjunction to whatever the cache expiry is in the group_vars, and that's set at the discretion/requirements of the project. +1 for default. My bad.. Set to default to true. :). ",
    "guilro": "You can use scheme://[user:password@]host[:port]/[/]path, so you don't have to define backup_target_user and backup_target_pass.\nI think we should not rely on this variables for the backup feature, as they are global to all the stouts.backup role and not only to one specific backup role. That would mean having the same backup host for all websites managed by trellis.\n. Ok, I will try to look at it next week :)\n2016-11-18 11:18 GMT+01:00 Bradley notifications@github.com:\n\nJust can't get this to work full stop regardless of the target\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/pull/650#issuecomment-261497056, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AASbrqUEH8HmuW0hScS-y8L_RhhRK-ZSks5q_Xt3gaJpZM4JxkZ4\n.\n. Hello everyone. I just fixed the {{ item.value.backup.target }}, and now it is working.. Good suggestion. I thought it was impossible because backup_target_pass was a setting global to Stouts.Backup. But you can also set up target_pass per backup profile. Should be working now.\n\nSeveral caveats :\n with ssh backends, backup won't work out of the box because the target is not in .known_hosts. You first have to manually SSH from the server into your backup target,and validate the target private key.\n the cron time is hard-coded. It is not a good practice that every user backups at the same time. Working on that.. I agree such a feature would be usefull, but I don't think its a good idea to purge by default. So this would make one more setting.. @MWDelaney  Duply makes incremental backups, and only few full backups. So there is no gain at using grand-father/father/son model. As long as you have only one full backup, there is no duplicate data. Skipping a day only mean either having a bigger diff next day or creating a new full backup. This create \"chains\" of backups.\nPurge use a combination of MAX_FULL_BACKUPS and MAX_AGE to delete old backup \"chains\".\nMy point was that backups are not made locally so it should not be critical if your server fills up (you should have a dedicated server for backups), and you may want to keep your backup longer (that is the point of backups), but I am ok to work on it.. @greatislander just saw yours ! Actually I did exactly the same :). Suggestion added ! I also turned the purge setting to true by default.. @swalkinshaw thanks for your review and sorry for the delay.\nTell me what is your decision for integration, I can create a separated role if you ask for.\n. Does this seem correct ?. ",
    "newtonne": "@inthedeepend @guilro I haven't tested this but it looks like the issue with the target is that:\n{{ item.value.target }}\nshould be:\n{{ item.value.backup.target }}. @guilro @greatislander Instead of a separate cron for the purge, you could alternatively integrate the purge into the backup cron by adding the following to backup_profiles under the target_pass definition:\n\naction: \"{{ 'purge_backup --force' if site_purge_backup else 'backup' }}\"\n\nI have tested this and it works as expected. Note that the underscore between 'purge' and 'backup' is a neutral separator that tells duply to run a purge and then a backup. It is possible to tell it to only do the backup if the purge succeeds or only if it fails. See the section on separators in the duply docs.\nI also vote that purging should be on by default as that is the recommended way to use duplicity.. ~~One issue I did run into is that it fails when you do a manual restore logged in as the admin_user. Running something like:~~\n~~/usr/bin/duply /etc/duply/mysite_uploads restore~~\n~~will fail because the admin_user does not have permission to modify any of the files/directories under /srv/www, since they are owned by the web_user.~~\n~~Changing the backup_user to web_user does resolve this. The other alternative is to run the restore command through sudo. However, the downside of this is that the owner of the files is changed to root.~~\nEdit: not an issue. Running the restore under sudo works just fine, and does not modify the file/directory owners. Not sure why I thought it did.. ",
    "lucrussell": "Just to confirm, I had the same issue and tried {{ item.value.backup.target }} as suggested by @newtonne, this corrected the problem. \nI then received this error: \nthe field 'args' has an invalid value, which appears to include a variable that is undefined. The error was: 'mysql_root_user' is undefined\n\nI was able to resolve this by specifying the mysql_root_user variable in production/main.yaml. \nNot sure if this is the best approach, but it's working. Thanks all for the great work on this backup solution! . ",
    "greatislander": "@lucrussell Haven't tested myself but are you running the playbook with just the backup role? mysql_root_user is defined in  the MariaDB role so if you have that role commented out it will be undefined as you are reporting. See https://github.com/roots/trellis/blob/b299b331f2112c2cb5ee7fa2e7512a9e5a663821/roles/mariadb/defaults/main.yml#L2. One piece of feedback on this, @guilro: wouldn't it be better practice to put the credentials in /group_vars/<env>/vault.yml rather than inlining them as you suggest here?. Looks good. Another thought\u2014have you considered integrating a purge command as per @MWDelaney's role so that the backup server doesn't keep filling up over time?. My theory is that it has to do with this block:\nhttps://github.com/roots/trellis/blob/master/roles/wordpress-setup/templates/wordpress-site.conf.j2#L32-L48\nIf the caching configs are excluding the conventional (by Trellis standards) admin path of /wp/wp-admin/, would the rewrite to /wp-admin/ here break that configuration?. See:\nhttps://discourse.roots.io/t/safari-conflicting-multiple-x-frame-options/10077/5\nhttps://core.trac.wordpress.org/ticket/40020. It looks like you have not run ansible-playbook server.yml -e env=production. You can't deploy if you haven't provisioned the server. See: https://roots.io/trellis/docs/remote-server-setup/. Sorry \ud83d\ude33. Add to backup dict:\npurge: false # switch to true to enable automatic purging of old backups. Add to backup dict:\npurge: false # switch to true to enable automatic purging of old backups. Add:\nsite_purge_backup: \"{{ item.value.backup is defined and item.value.backup.purge | default(false) }}\". Add after the Configure task:\n```\n- name: Create uploads purge job\n  cron: name=\"Purge old uploads backups\" minute=\"0\" hour=\"1\"\n        cron_file=purge\n        user=\"{{ admin_user }}\" job=\"duply /etc/duply/{{ item.key }}_uploads purge --force\"\n  when:\n    - site_uses_backup\n    - site_purge_backup\n  with_dict: \"{{ wordpress_sites }}\"\n\nname: Create database purge job\n  cron: name=\"Purge old database backups\" minute=\"0\" hour=\"2\"\n        cron_file=purge\n        user=\"{{ admin_user }}\" job=\"duply /etc/duply/{{ item.key }}_database purge --force\"\n  when:\nsite_uses_backup\nsite_purge_backup\n  with_dict: \"{{ wordpress_sites }}\"\n```. \n\n\n",
    "nathobson": "Thanks for the work on this @guilro. I've had a good amount of time to test this now. I've successfully got backups running smoothly to Backblaze B2 (nice that Duplicity supports this). \nTwo questions:\n\nHow does purging work exactly? Is there some sort of max_age set?\nHow do restores work? I'm probably missing the obvious but haven't figured that one out.\n\nAgain, thanks for the time you've put into everything so far.. Scratch that, I've looked more into restores. However, facing an issue here. It seems (on my instance at least) that the duplicity-full-signatures for the example.com_database and example.com_uploads are the wrong way around, meaning the restores fail.\nFor example, my uploads backup has duplicity-full-signatures.20170310T160306Z.sigtar.gzand when I run duply example.com_uploads restore 1D I get:\n--- Start running command RESTORE at 17:48:23.131 ---\nSynchronizing remote metadata to local cache...\nCopying duplicity-full-signatures.20170310T160307Z.sigtar.gz to local cache.\nAttempt 1 failed. HTTPError: HTTP Error 404: Not Found\nHowever, it's my database that has duplicity-full-signatures.20170310T160307Z.sigtar.gz. Equally, my database restore fails in the same way in reverse.. Please do let me know if any testing is required. I've now had a good chance to experiment with several of the targets/backends including B2, S3 and SFTP... with varying success.. ",
    "medfreeman": ":+1:  for @MWDelaney 's suggestion for a category playbooks.\nI'd even add a 'recipes' category for the kinds of additions which don't belong in a playbook.\ni.e.: setup-health checks on amazon elb, redirect to https behind an elb, etc... Ok nice !\nIt seems @fullyint solution covers a wider range of uses, i think it would be better than mine.\nWhat i did:\n  - roles/nginx/defaults/main.yml -> add nginx_default_server_conf: no-default.conf.j2\n  - create roles/nginx/templates/no-default.conf.j2 -> based on h5bp no-default config\n```\n{{ ansible_managed }}\nDrop requests for unknown hosts\n\nIf no default server is defined, nginx will use the first found server.\nTo prevent host header attacks, or other potential problems when an unknown\nservername is used in a request, it's recommended to drop the request\nreturning 444 \"no response\".\nserver {\n  listen 80 default_server;\n{% block server_body %}{% endblock %}\n{% block http_return_code -%}\n  return 444;\n  {% endblock %}\n}\n```\n\nroles/nginx/tasks/main.yml -> replace 'Enable better default site to drop unknown requests'\n\n- name: Enable better default site to drop unknown requests\n  template:\n    src: \"{{ nginx_default_server_conf }}\"\n    dest: \"{{ nginx_path }}/sites-enabled/no-default.conf\"\n  notify: reload nginx\n  tags: nginx-includes\nHow i use it:\n  - group_vars/all/main.yml -> add nginx_default_server_conf: nginx-includes/no-default.conf.child.j2\n  - create nginx_includes/no-default.conf.child.j2 ->\n```\n{% extends 'roles/nginx/templates/no-default.conf.j2' %}\n{% block server_body -%}\n  root  {{ www_root }};\nlocation = /health-check.php {\n    # code to invoke php\n    # but no redirection code\n    try_files $uri =404;\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n    fastcgi_param DOCUMENT_ROOT $realpath_root;\n    fastcgi_pass unix:/var/run/php-fpm-wordpress.sock;\n  }\n{% endblock %}\n{% block http_return_code -%}\n  location ~ / {\n    return 444;\n  }\n{% endblock %}\n```\n\n\nIn this specific case, i also created a new role (referenced on server.yml) that creates the 'health-check.php' file from a template, into www_root ('/srv/www/' on remote hosts), but this is out of the scope of this enhancement.\n\n\nSet up the health check url on the elb to '/health-check.php'. Sure,\ni'll do this today or tomorrow.. Ok i managed to do something clean, basically @fullyint idea.\n\n\nBut i chose to have a 'nginx-sites-available' template folder, automatically copied to the host's sites-available folder, that auto cleans up in case you delete templates in the future.\nAnd a 'nginx_sites_enabled_templates' array that symlinks the requested sites, removes sites templates no more defined, and cleans broken symlinks.\nIt has the added benefit of having some available but not enabled sites for whatever needed reason.\nBut unfortunately this approach requires being able to find broken symlinks, but symlinks don't register to the path module in the current version.\nThe commit that would fix this is here, but won't be available until ansible 2.3 (as stated in the docs), which has no release date.\nShould i perhaps revert in the meantime to a simpler approach where the files are templated directly to sites_enabled without using symlinks ?. I meant broken symlinks are ignored by the 'find' module, not 'path'.\nEdit: precision. Finally i kept the announced behavior, but made sure to prune unmanaged sites-enabled files before pruning sites-available, thus avoiding the problem of broken symlinks not registering to ansible 'path' module.\nI find the whole code a bit long, but didn't know how to do it better while keeping things simple for the user.\nComments completely welcome on the approach.. So with the PR, here's the revised addition of an elb health check template:\n\ngroup_vars/all/main.yml -> add\n\nnginx_sites_enabled:\n  - default-elb-health-check\n\ncreate nginx-sites-available/default-elb-health-check.conf.j2 ->\n\n```\n{{ ansible_managed }}\nDrop requests for unknown hosts\n\nIf no default server is defined, nginx will use the first found server.\nTo prevent host header attacks, or other potential problems when an unknown\nservername is used in a request, it's recommended to drop the request\nreturning 444 \"no response\".\nserver {\n  listen 80 default_server;\nroot  {{ www_root }};\nlocation = /health-check.php {\n    # Amazon ELB php health check\n    # code to invoke php\n    # but no redirection code\n    try_files $uri =404;\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n    fastcgi_param DOCUMENT_ROOT $realpath_root;\n    fastcgi_pass unix:/var/run/php-fpm-wordpress.sock;\n  }\nlocation ~ / {\n    return 444;\n  }\n}\n```\n\n\nIn this specific case, i also created a new role (referenced on server.yml) that creates the 'health-check.php' file from a template, into www_root ('/srv/www/' on remote hosts), but this is out of the scope of this enhancement.\n\n\nSet up the health check url on the elb to '/health-check.php'. Usage didn't change with this PR.. So with this new PR, here's the revised addition of an elb health check template:\n\n\ngroup_vars/all/main.yml -> add\n\n\nnginx_default_site_enabled: false\nnginx_sites_enabled:\n  - nginx-includes/default-elb-health-check.conf.j2\n\ncreate nginx-includes/default-elb-health-check.conf.j2 ->\n\n```\n{{ ansible_managed }}\nDrop requests for unknown hosts\n\nIf no default server is defined, nginx will use the first found server.\nTo prevent host header attacks, or other potential problems when an unknown\nservername is used in a request, it's recommended to drop the request\nreturning 444 \"no response\".\nserver {\n  listen 80 default_server;\nroot  {{ www_root }};\nlocation = /health-check.php {\n    # Amazon ELB php health check\n    # code to invoke php\n    # but no redirection code\n    try_files $uri =404;\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n    fastcgi_param DOCUMENT_ROOT $realpath_root;\n    fastcgi_pass unix:/var/run/php-fpm-wordpress.sock;\n  }\nlocation ~ / {\n    return 444;\n  }\n}\n```\n\n\nIn this specific case, i also created a new role (referenced on server.yml) that creates the 'health-check.php' file from a template, into www_root ('/srv/www/' on remote hosts), but this is out of the scope of this enhancement.\n\n\nSet up the health check url on the elb to '/health-check.php'. side note about usage:\nperhaps name the file 'nginx-includes/default-elb-health-check.conf.site.j2' (adding '.site' extension) instead of 'nginx-includes/default-elb-health-check.conf.j2', thus avoiding the file being templated to nginx includes.d directory (trellis only templates files ending in .conf.j2 to the includes.d directory).. So with this new PR, here's the revised addition of an elb health check template:\n\n\ngroup_vars/all/main.yml -> add\n\n\nnginx_sites_confs:\n  - src: no-default.conf.j2\n    enabled: false\n  - src: nginx-includes/default-elb-health-check.conf.site.j2\n\ncreate nginx-includes/default-elb-health-check.conf.site.j2 ->\n\n```\n{{ ansible_managed }}\nDrop requests for unknown hosts\n\nIf no default server is defined, nginx will use the first found server.\nTo prevent host header attacks, or other potential problems when an unknown\nservername is used in a request, it's recommended to drop the request\nreturning 444 \"no response\".\nserver {\n  listen 80 default_server;\nroot  {{ www_root }};\nlocation = /health-check.php {\n    # Amazon ELB php health check\n    # code to invoke php\n    # but no redirection code\n    try_files $uri =404;\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n    fastcgi_param DOCUMENT_ROOT $realpath_root;\n    fastcgi_pass unix:/var/run/php-fpm-wordpress.sock;\n  }\nlocation ~ / {\n    return 444;\n  }\n}\n```\n\n\nIn this specific case, i also created a new role (referenced on server.yml) that creates the 'health-check.php' file from a template, into www_root ('/srv/www/' on remote hosts), but this is out of the scope of this enhancement.\n\n\nSet up the health check url on the elb to '/health-check.php'. Is it ok like this, by adding 'nginx-includes/default-elb-health-check.conf.site.j2' (adding '.site' extension before '.j2') in order for the conf file not to be also templated to 'nginx/includes.d' remote folder ?\n\n\nI'm asking this because i'd like to take a stab at adding the feature to the nginx-includes doc.\nIt is similar to the child configuration examples, where one has to add the '.child' suffix to the file names, in order for them not to be also templated to the includes.d folder.\nI know i shouldn't explain why, but just wanting to be consistent with the docs and previous features, while not complicating this line with each exception.. Ok, i reread the docs properly, and the thing with adding a suffix ('.child' for child templates) while using 'nginx-includes' folder OR using another folder to avoid files being templated to includes.d, is properly explained in the docs (here at the end of the line).\nSo my approach seems be ok, i'll base my doc addition on the actual one anyway.. It seems that the Remove unmanaged files from sites-available (https://github.com/medfreeman/trellis/blob/b0e2712d934f3b9223067889105accfd2d285bbd/roles/nginx/tasks/main.yml#L122) task will also prune let's encrypt nginx configurations (i've done my testing on a site with a freshly disabled let's encrypt config).\nTo avoid over-complicating the code, should i instead template the additional sites configurations to a subfolder of sites-available on the hosts ? So i don't need to manage every single exception (wordpress sites templates, let'sencrypt, etc...). Aww, i just realized i can create an 'extras' folder in sites-available and sites-enabled, add a directive to nginx.conf template to load files in sites-enabled/extras and manage things in a simple way..\nRestarting... This time i simply : \n  - remove h5bp's no-default.conf from sites-enabled (old behavior)\n  - create remote sites-available/extras and sites-enabled/extras folders\n  - copy h5bp's no-default.conf to sites-available/extras folder\n  - template *.conf.j2 files from local nginx_sites_available_templates_path to remote sites-available/extras folder\n  - prune non-enabled (not present in nginx_sites_enabled array) sites from sites-enabled/extras\n  - prune non-managed (not present in nginx_sites_available_templates_path except no-default.conf) files from sites-available/extras\n  - enable sites present in nginx_sites_enabled array by creating symlinks from their sites-available/extras counterparts. I completely understand, i also think that it is a bit heavy, as said before.\nIf doing this the simpler way, i think my original solution is eventually better.\nBecause not cleaning templates will fare better if the user has to override the no-default template ;\nwith your solution, you'd have to ssh onto the server to remove the no-default template while adding one with another name in certain cases, and i think that wouldn't be a good thing (in regards to automation).\nAnd if reverting, ssh would have to be used again.\nTyping this while thinking, the general one is also more useful..\nI'm trying to find a good middle ground.\nSo supplying a new PR.\nI hope it's simple yet flexible enough.. The overhead is very limited.\nAdded benefit: not changing where the default site has been since 2013.\nIn certain cases you'd want additional sites without disabling the default site also.\nI hope that keeps things simple yet flexible.\n. Thanks for your work and comments ! I can assure you nothing comes up as negativity !\nAs you could perhaps foresee, i'm leaning for option 3.\nBut i'll share my opinions about each option anyway.\n1) As @swalkinshaw stated\n\nSeems useful since we'd like to encourage people to have better setups with load balancers (even though in this case it seems ELB is kind of broken).\n\nAnd given that:\n  - this feature will save time, even for a small minority\n  - the overhead is really small\n  - there is already an nginx-includes feature that is complimentary to this one\n  - in specific cases (like mine), i'd need to child template / disable / overwrite the default configuration, and that involves editing trellis files (not only adding a playbook because overwriting a file in a subsequent playbook doesn't seem indepotent), that then complicates trellis' updates on client repositories\n  - we'll then can hopefully add simple guides for these kind of time consuming tasks (when you have to do the research and implementation the first time), also imo helping trellis' adoption by having clear ways of doing specific but possibly needed features\nI think this feature would be a great thing to add.\n2) I concur, but not cleaning site specific confs or dirs wouldn't create side effects, whereas this feature without cleaning could.\nAlso you could even template directly to sites-enabled the sites that are enabled, and remove the non-enabled sites just after, but the proposed approach feels better, having only one nginx reload statement.\n3) Seems good to me. And that removes a step that is not frankly useful. As long as the sites are unlinked, this achieves the same result.\n4) I share the opinion that this isn't needed, and even if it was, it would make more sense to template directly to sites-enabled in this case, because linking in the first place while removing the link and the linked file while enabled=false doesn't really make sense imo.. Thanks !. Thanks to you both ! @fullyint i finally commited your code, i hope you don't mind !\nTaking my time writing the doc, hope to be the clearest possible.\nNext proposition in a week or two, have something like an 'external' or 'proxy' ssl setting / proxy conf to handle ssl termination.\nRationale: it needs changes in a lot of places, is hard to maintain, but again not sure if it warrants a PR or something more like a recipe. I'll send a PR when back from lunch.. What i originally wanted:\nHaving a multisite subdomain installation on the root example.com domain, allowing subsites at sub1.example.com, sub2.example.com, etc..\nHaving the primary site on www.example.com, with example.com redirecting to www.example.com.\nWhat i thought:\nThat setting domain_current_site to example.com while having the site values set to www.example.com would achieve the results i wanted.\nBut that broke my network admin (only the network section, not single sites).\nWhat i didn't know:\nThat domain_current_site always has to match the primary site domain exactly.\nWhat i discovered:\nThat wordpress already handles by itself my specific case where one wants to have the primary multisite url set to www.example.com, and subsites set to subdomains of example.com (i.e. sub1.example.com), NOT subdomains of www.example.com (i.e. sub1.www.example.com).\nAs seen in Wordpress source's wp-admin/network/site-new.php (i know the entry was already there in 2010) and in wordpress network admin, wordpress handles this and creates subdomains of the root domain (example.com), NOT subdomains of the www subdomain (www.example.com), by removing the www prefix.\nWhat is wrong:\nTrellis will (as seen in roles/wordpress-setup/templates/wordpress-site.conf.j2 l.8) generate the wildcard server_name entry in nginx config using *.[canonical_host_name].\nIn this case the wildcard entry, which should be *.example.com, is in fact *.www.example.com, thus not allowing to view the subsites (i tested this locally).\nWhat i propose:\nHaving Trellis, like wordpress does, generate a correct wildcard entry by removing the www. prefix from the site's host canonical name.\nNote: i changed the issue's title to be more specific.. Thanks!\nYes, it seems your second form (using map regex_replace) is cleaner / shorter than mine, but is there a need for regex_replace('^(www\\\\.)?(.*)$', '\\\\2') instead of regex_replace('^www\\.', '') ?\nJust want to know if it is for style cohesion, or if i'm missing something.\nEdit: also aren't the double backslashes only needed for back references, but not warranted for special characters escape ?. Nice!\nI replaced the for loop by the map function, all clear with the PR !. I also replaced the first form with the second form, so it looks consistent and cleaner.. This solution is incorrect, due to a misunderstanding on wordpress multisite subdomains inner workings.. Thanks !. It seems it is better to duplicate Get list of hosts in current Nginx conf task since the when conditions are different.. It seems i was a bit fast on the method again.\nI now understand that the approach used in let's encrypt challenge generation is not relevant here, because it's sole use is to then make a difference with already existing challenge confs in a simple way.\nBetter to use site_hosts with an union of wildcard entries generated \n from canonical hosts, without the www. prefix, as in my previous issue.. @swalkinshaw sure.\nWhile #818 can solve the syntax problem, it only adds a second task for each site to achieve the same result (config file vs command-line virtual config via here-now document, since subjectAltName cannot directly passed as a command-line argument).\nAs is this pr won't also work with multiple site keys, because the last site will have overwritten previous openssl configurations.\nTo follow this path, two options are possible:\n  - Generate a specific openssl config file for each site\n    -> As stated that only duplicates the cert task and will produce additional files, is this really warranted ? Moreover the original config works already, and i don't like duplicating a common config with args that can be passed in the command-line\n\nGenerate a single openssl config for all sites in one go\n    -> I personally prefer having them separate for consistency, and keeps working as-is with one per-site (and subdomains) certificate pair\n\nI personaly am in favor of writing a simpler syntax for my PR, but perhaps it is because i have written it.\nPlease tell me what you think.. Ok, i made the syntax cleaner by avoiding unecessary quoting, including commonName in the configuration, and using single quotes for EOF.\nImo the only thing that goes in favor of #818 is that this PR will break when ansible/ansible/issues/12034 is resolved.\n. The change of command style was mandatory for a few reasons, first one is that the brackets characters (l.7-10) have to be escaped or ansible throws a syntax error.\nThe original Block scalar style using a > removes the newlines within the string, thus not allowing the config openssl section to work properly.\nThe choice of the Flow scalar style using a \" (double-quote) is the only style in yaml multi-line string allowing the use of inline newlines (\\n) and spaceless newlines (trailing \\) (c.f. http://stackoverflow.com/questions/3790454/in-yaml-how-do-i-break-a-string-over-multiple-lines#answer-21699210).\nI could have also used the Flow literal style using a |, but that would have forced all the dashed parameters of the \n openssl command to be written on the same line since a spaceless newline (trailing \\) can't be added in this mode.\nIn the chosen style, the double quotes \" and backslash \\ have to be escaped though.. The bash shell has to be used, since virtual files use the subshell operator () (l.5), which produces a syntax error using the default sh shell.\nPerhaps there is a way to make this work with sh, but i didn't find it.. Providing an empty dn section is mandatory, even with the subject provided in command-line (l.3), while using a config file, or openssl throws an error.. Ansible issues ansible/ansible#12856 and ansible/ansible#8512 prevent the use of EOF or -EOF as file delimiter, since a space character is inserted by ansible at the start of each line while parsing the shell string.\nIf found the solution here in the second issue.\nI don't know if you have a better understanding of the problem than me, but i couldn't find a better solution here or elsewhere.. Using the cmd shell parameter instead of providing the command directly to the shell module yields the same error while using EOF instead of \\\" EOF\\\".. The extensions parameter is mandatory to have openssl x509 key generation take into account the subjectAltName parameter (it references the req_ext section l.10).. Perhaps that can work with backticks, i didn't realise it until now. I'll try this during the afternoon.. https://github.com/ansible/ansible/issues/12034. ",
    "hamedb89": "hey guys, I had the same problem, maybe this will help you too.\nhttps://github.com/hamedb89/trellis-db-push-and-pull. I am having problems with this commit.\n``\nTASK [fail2ban : ensure fail2ban starts on a fresh reboot] *********************\nSystem info:\n  Ansible 2.0.2.0; Vagrant 1.8.6; Darwin\n  Trellis at \"Addapt_packages_custom` to customize Apt packages\"\n\nerror importing module in /usr/local/lib/python2.7/site-\npackages/ansible/modules/core/system/systemd.py, expecting format like 'from\nansible.module_utils. import *'\nfatal: [default]: FAILED! => {\"failed\": true}\nNO MORE HOSTS LEFT *********\n    to retry, use: --limit @/Users/hamedbahrami/vagrant/design-factory.de/trellis/dev.retry\nPLAY RECAP ***********\ndefault                    : ok=6    changed=0    unreachable=0    failed=1   \nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\n```. ",
    "valentinocossar": "Thank you so much for sharing it!. @discopatrick any updates about this playbook? Maybe a beta version with some workarounds to work? Thank you \ud83d\ude42. Thank you for all your work, I hope that Ansible team fixes the problem as soon as possible.\nAnyway, I think that the best approach to this functionality is to create a separate playbook and not merge this into Trellis, at least this was the approach for the Trellis backup feature (see #650). Am I wrong?. Yes, for me it's a good trick, thank you for sharing it. \ud83d\ude42. Hi @retlehs, I agree with you. Maybe someone could also be interested in this tool (it's based on the @hamedb89's tool).\nIs a good thing to add it to the same page you have linked?. I did a lot of test with sSMTP and found that if I left FromLineOverride=Yes the result would be dependent on which command the program uses to send the email.\nHere my /etc/ssmtp/revaliases file:\nroot:test@test@example.com:smtp.mailgun.org:587\nadmin:test@test@example.com:smtp.mailgun.org:587\nHere are some tests:\n1. Sent via mail with specified From:\nCommand: echo \"This is the message body\" | mail -s \"This is the subject\" info@example.com -aFrom:noreply@example.com\nResult: From:noreply@example.com\n2. Sent via mail with non-specified From:\nCommand: echo \"This is the message body\" | mail -s \"This is the subject\" info@example.com\nResult: From:admin@hostname, where the hostname is the same I have in the /etc/mailname file\n3. Sent via ssmtp with specified From:\nCommand: echo \"From:noreply@example.com\" | ssmtp info@example.com\nResult: noreply@example.com\n4. Sent via ssmtp with non-specified From:\nCommand: echo \"Subject:Test\" | ssmtp info@example.com\nResult: From:test@example.com, same as reported in the /etc/ssmtp/revaliases file\n5. Via sendmail the results are the same as the ssmtp because sendmail is a symlink of ssmtp.\nIf the service doesn't provide the From header and the mta is ssmtp or sendmail, the /etc/ssmtp/revaliases file works as expected, but the problems come out when the service overwrites the From header with a non-compliant custom one.\nMaybe changing the sender for Fail2Ban in some way could solve the problem but it's not a solution because it's not the only service that sends email from the server. That's why I specified that one of the solutions for the problem is to change the From for every service that sends emails, but I don't think it's easy. In fact, I've got other emails with the same problem reported in the log above but from other services that are not Fail2Ban.\nIn my opinion, this solution is more generic, it's not only to solve this specific problem but it's a more complete control over the sSMTP configuration if anyone needs it.. Hi @pySilver, thank you for the feedback, I already have /etc/mailname on my server with the default domain set by OVH and it's a valid domain name (vps112233.ovh.net) but this is not resolving the issue for me. The From header is overwritten by Fail2Ban (or other services) every time that sends an email and when it's not overwritten by a service the server sends the email with the default domain seen above.. @swalkinshaw at the end, what you think about the implementation of this feature? \ud83d\ude42. Thank you @swalkinshaw!. ",
    "antoscarface": "I would give you a hint about uploads sync. \nI use this nginx rule:\n```\n{% block location_uploads_proxy -%}\nAvoid to download upload contents from remote server\nlocation /app/ {\n  try_files $uri $uri/ @prod;\n}\nlocation @prod {\n  proxy_pass https://{{ item.key }};\n}\n{% endblock %}\n```\ninside wordpress-setup role and in the wordpress-site.conf.j2 template.\nIn this way, if the server is looking for http://mylocal.dev/app/uploads/file.png (and everything else under /app/) and it doesn't exist, this Nginx rule will replace http://mylocal.dev with the production URL as a proxy.\nThanks to this, you don't need to download each time the uploads folder that in some cases it would have very big size :) You may want to never download uploads folder, you don't need.\nIt saved my life so much!\nNote: I used {{ item.key }} to have the production URL and in my case, the key of the item corresponds to the production URL, I don't know if it is the same to the other. If no, we should found another way to get the production URL.\nI hope it can help.. ",
    "dheerajbhaskar": "\nI have a question for the core development team. I notice that Trellis uses the host OS's default ssh public key (~/.ssh/id_rsa.pub) when creating users on remote hosts - (https://github.com/roots/trellis/blob/master/group_vars/all/users.yml#L16). Seeing as Trellis already relies on this key as a fundamental requirement, how would you feel about configuring the vagrant box to also use this key, instead of the key generated by the vagrant ansible provisioner? (Documented here: http://ermaker.github.io/blog/2015/11/18/change-insecure-key-to-my-own-key-on-vagrant.html) Are there any arguments against doing this?\nThe reason I ask is that if the vagrant box and the remote boxes use the same ssh key, it may be possible for me to use the synchronise module between them using SSH key forwarding, and this might make the job a lot easier and tidier. At present, I'm having to use a few workarounds, and it's making the playbook look messy.\nNot sure who's attention I should be asking for here, or even if this is the best place to discuss. But I'm going to tag @swalkinshaw. If there is a mailing list, let me know. I'm also always available in the #roots IRC channel on chat.freenode.net.\n\nI just filed a feature request for a similar thing #839 and it was serendipity to find your comment \ud83d\ude04 . @partounian the tool is to clean up private info from DB. Not sure that relates to the issue here. Am I mistaken? . I can work on a pull request if a contributor /maintainer says this is in scope. Based on https://github.com/roots/trellis/issues/654#issuecomment-280079858 I guess this would be a welcome PR?\nPS: This was in reply to: https://github.com/roots/trellis/issues/654#issuecomment-279535314. ",
    "regularjack": "I don't understand: if the best practice is to keep the server in UTC, why does the default_timezone configuration exist? See #301 \n. @swalkinshaw The timezone_string option is by default NULL, which means it falls back to UTC.\n. Should be compatibility\n. ",
    "eshimischi": "mariadb_binary_logging_disabled: true\nmariadb_keyserver_fingerprint: \"0xf1656f24c74cd1d8\"\nmariadb_mirror: nyc2.mirrors.digitalocean.com\nmariadb_version: \"10.1\"\nmariadb_dist: xenial\nmysql_root_user: root\nfrom roles/mariadb/defaults/main.yml\n. Instead of all these way better to install PageSpeed and make a right configuration... @QWp6t BrowserSync will work within VM, i have my own trellis with node.js, yarn installation and all good. \n@MasonFI you should look to other ansible roles: node.js and yarn here\nnodejs-role\nyarn-role. Already updated to 201807.12.0  (18.04.1 Released). ",
    "ssteinerx": "@swalkinshaw Seems pretty trivial, but I'll do one just to make sure the tests pass.  Speaking of which, since I'm not particularly familiar with the Trellis code yet, can you tell me whether there any tests specifically related to MailHog that will catch any incompatibilities?\n. ",
    "stejmurphy": "We've done this locally with the above solution and it's working. \nIs there any benefit for trellis to always pull the latest vm? We're going to lock our stack to 2.2.9 for awhile.\n. Sure, I can do this later today\nHad time.\nhttps://github.com/roots/trellis/pull/667\n. ",
    "cheeseplus": "FYI, this is a virtualbox 5.1.6 issue less than a bento issue as per upstream ;)\n. ",
    "isvaljek": "But when I login to virtualbox with vagrant ssh, and do a wget to the same URL it works. So not sure about connectivity problem.\nAnd it's returning the same error today for the vagrant provision command.\nI did post to discourse before posting here, but no one replied.\n. ",
    "pelson": "Sorry for resurrecting. Just wanted to add, that I had a similar issue with fail2ban on homebrew (OSX, v0.8.14).\nIn my case, the message was caused by the default log location not being writable by the user running fail2ban. My solution (suitable for homebrew) was to change the log location (defined in /usr/local/etc/fail2ban/fail2ban.conf) to have logtarget = /usr/local/var/log/fail2ban.log. I was able to then fail2ban-client reload without seeing the Failed to change log target message that I was getting. (upon re-reading, I can see that this isn't the same message reported here, but hopefully will be helpful to others who find this thread).. ",
    "jasonmarlin": "To piggyback OP, this isn't really a port conflict, but that browsers want to redirect to HTTPS on an entire domain if HSTS is enabled. I propose that development environment could include a mailhog proxy in Nginx to ease both access to mailhog and eliminate any HSTS issues with HTTPS redirection. The following code added to wordpress-site.conf.j2 does the trick. Happy to add a PR:\n{% if env == 'development' -%}\n  {% block mailhog_proxy -%}\n  location /mailhog/ {\n    proxy_pass http://127.0.0.1:8025/;\n    proxy_set_header Host $host;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n  }\n  {%- endblock %}\n  {% endif -%}. I did have the same issue and have seen it in other projects. HSTS spec\nwants to redirect any http:// request to https:// across a domain,\nregardless of the port number. That said, my proposed fix via Nginx proxy\nisn't 100% as Nginx doesn't seem to know how to upgrade the web socket\nrequests to wss, and I ran out of time to research.\nAnother option could be to setup the mailhog server to work over https/wss,\nbut I couldn't find any quick solution for that either.\nOn Fri, Jan 19, 2018 at 11:27 AM, Scott Walkinshaw <notifications@github.com\n\nwrote:\n@jasonmarlin https://github.com/jasonmarlin that solution is\ninteresting. I'd welcome a PR but is this an actual issue? @retlehs\nhttps://github.com/retlehs couldn't reproduce it.\nYou had the same issue?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/issues/689#issuecomment-359016939, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ABB-5_YT2R4F1o7U4GmbhwXkUWPPQ64Oks5tMMJegaJpZM4K1yUA\n.\n. \n",
    "dlundgren": "I have not tested that particular scenario. MariaDB & Percona are mutually exclusive and replace/break each other.\nI should be able to take a look at having it detect which is installed, and handling that scenario, later this week.. I moved the block into the main task, and left the installers in their own files.\nI also noticed an issue with which release I was installing from when using percona_dist, I dropped that in favor of using ansible_distribution_release.. That's fine, would you consider the option to allow mysql vs maria using distro packages?. ",
    "gabrielgiordan": "Hey many thanks @fullyint I think this issue is fixed now! \ud83d\udc4d \nBut I'm having a problem with another issue on my encrypted vaults, it's related to this post. In the past, the only thing that worked is the @aoe answer\n==> default: You should consider upgrading via the 'pip install --upgrade pip' command.\n==> default: Running Ansible Playbooks\n==> default: ERROR! Problem running vault password script / v a g r a n t / v a u l t _ p a s s ([Errno 8] Exec format error). If this is not a script, remove the executable bit from the file.\nThe SSH command responded with a non-zero exit status. Vagrant\nassumes that this means the command failed. The output for this command\nshould be in the log above. Please read the output to determine what\nwent wrong.\nI've tried almost anything, using ask_vault_pass, changing chmod from cygwin, changing permission on file properties, creating the .vault_pass inside the vagrant box... but unfortunately I didn't find any solution to remove the executable bit from the .vault_pass and I think this is affecting only Windows users... may I open another issue for this?. ",
    "antonmarin": "posted.\nIsn't it an issue?. ",
    "daBONDi": "Got the same Problem.\nMounted my vagrantroot/ansible with \nvm_config.vm.synced_folder \"./ansible\", \"/opt/it-infra\", id: \"it-infra\", owner: \"vagrant\", group: \"vagrant\", mount_options: [\"dmode=775,fmode=664\"]\nTo workaround this issue.\nMaybe someone will help this. @fullyint i don't use the Trellis Runbooks. Was thinking i comment on a vagrant issue, sorry for my dumbness :-)\nYou can close it agan :-). ",
    "stephenconnolly1": "Building on Windows, running ansible from inside a docker container.\nMy password script is just a bash script that echoes an environment variable.\nWhen the script was multiline the script failed to execute because of the windows CRLF\nI removed all the line endings and made the script a single line command.\nNow I'm getting the error exec format error as above. The script is definitely executable as my command executes the file before running ansible vault decrypt (for debugging purposes). \nexpect the script to be a python script or any executable file? \n\nAagh, just got it all working by changing my file from a bash based \necho $ANSIBLE_VAULT_PASSWORD\nto \n!/usr/bin/env python\nimport os\nprint os.environ['ANSIBLE_VAULT_PASSWORD']\nPlease can someone update the docs so it's clear the password script needs to be a python script. ",
    "DrValani": "Thanks @stephenconnolly1.\nJust to add to this, if you are using WSL then store the file in a subdirectory /c/. ",
    "jvandijk": "@lgarron Wow! Thank you for taking action on my feedback! And @swalkinshaw thumbs up for the fast fix!. ",
    "milanvanschaik": "I've got the same problem. Thanks for the PR, would be great to see it merged soon. \ud83d\udc4d . ",
    "akovalyov": "I can confirm that I experience this bug. I have a custom theme in site/web/app/themes folder. Right now after each deployment I need to activate one of default themes and reactivate a custom one.  . @retlehs awesome, it worked! Thanks a lot! Probably the solution which was proposed via wp option is not complete.. @swalkinshaw no need to be sorry, thank you for quick fix of that. I will try that in next couple of hours. Let's make that part great again :). @swalkinshaw works for me as well. Thank you very much!. ",
    "emanuelet": "Deploying with the latest code from master I encountered a similar problem where apparently the option was pointing to web/wp-content/themes while I have my theme in web/app/themes and so I had to manually change the configuration in Update WP theme paths. ",
    "tmdk": "@swalkinshaw it's working for me! thanks \ud83d\udc4d . At the very least, consider turning off includeSubdomains as a default. I've been bitten by this (external service hosted on a subdomain that does not support https). ",
    "morrislaptop": "It uses the mirror option which implies bare. Is there a way to use the\nmirror optional with the Ansible git module?\nOn Wed, 18 Jan 2017 at 16:07 Scott Walkinshaw notifications@github.com\nwrote:\n\nDoes Capistrano even use the bare option?\nhttps://github.com/capistrano/capistrano/blob/3d9800d977294c173b207cb99dda550c05966daa/lib/capistrano/scm/git.rb#L38-L44\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/roots/trellis/pull/736#issuecomment-273518283, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AAEI3_2pUHCQ6XmfCF4z7N_zLNUWdS5bks5rTji_gaJpZM4LnCbn\n.\n. \n",
    "jbicha": "Hmm, similar issues have been reported. I guess there's a problem with my local NFS. Closing.. Specifically, my problem was that NFS does not work with ecryptfs. You have ecryptfs if you clicked the button in the Ubuntu installer to encrypt your home directory.\nThe solution is to move your trellis folder outside the ecryptfs directories.\nThe error messages I got were\nmount.nfs: access denied by server while mounting\n  192.168.50.1:/home/jeremy/example.com/site\nrpc.mountd: refused mount request from 192.168.50.1 for\n  /home/jeremy/example.com/site (/home/jeremy/example.com/site):\n  unmatched host\nexportfs: /home/jeremy/example.com/site does not support NFS export. @swalkinshaw Could you check in Firefox?\nIt worked for me in Chromium 55 but not on Firefox 51 Beta.. ",
    "TheSycamore": "Hello, After following through the installation instructions here: https://roots.io/trellis/docs/installing-trellis/\nI too get the following error when running \"vagrant up\" inside my trellis folder after configuring the relevant trellis files:\nAnsible failed to complete successfully. Any error output should be\nvisible above. Please fix these errors and try again.\nError Output:\n```\nTASK [wordpress-install : Install Dependencies with Composer] ******\nSystem info:\n  Ansible 2.4.1.0; Vagrant 2.0.0; Linux\n  Trellis at \"Update wp-cli to 1.4.0\"\n\nComposer could not find a composer.json file in\n/srv/www/example.com/current To initialize a project, please create a\ncomposer.json file as described in the https://getcomposer.org/ \"Getting\nStarted\" section\nfailed: [default] (item=example.com) => {\"changed\": false, \"failed\": true, \"item\": \"example.com\", \"stdout\": \"Composer could not find a composer.json file in /srv/www/example.com/current\\nTo initialize a project, please create a composer.json file as described in the https://getcomposer.org/ \\\"Getting Started\\\" section\\n\", \"stdout_lines\": [\"Composer could not find a composer.json file in /srv/www/example.com/current\", \"To initialize a project, please create a composer.json file as described in the https://getcomposer.org/ \\\"Getting Started\\\" section\"]}\n```\nMy hard drive scheme does use crypto_LUKS filesystem for the nvme0n1p3 partition as can be seen here:\n$ lsblk -f\n```\nNAME                    FSTYPE               MOUNTPOINT\nnvme0n1                                                                        \n\u251c\u2500nvme0n1p3             crypto_LUKS        \n\u2502 \u2514\u2500nvme0n1p3_crypt     LVM2_member     \n\u2502   \u251c\u2500ubuntu--vg-root   ext4              /\n\u2502   \u2514\u2500ubuntu--vg-swap_1 swap              [SWAP]\n\u251c\u2500nvme0n1p1             vfat              /boot/efi\n\u2514\u2500nvme0n1p2             ext2              /boot\n```\nSo am I experiencing the same problem as the above users -> that NFS does not work with ecryptfs??\nIs ecryptfs the same as crypto_LUKS fs which is what my partitions are using?\nThis is very upsetting as I would love to be able to utilise trellis as I do lots of work with Wordpress.\nIs there any alternative workaround for someone in my position: someone using an encrypted device?\nOr could this error be due to something else? Any help would be greatly appreciated.\nPlease describe your local environment:\nAnsible version: 2.4.1.0 on Ubuntu 16.04.1.\nWhere did the bug happen? Development or remote servers?\nDevelopment\nThank you for your time and any help!. Thanks for your reply!\nI am new to vagrant and am still learning the ins and outs. Do you know what I would need to change in the above Vagrantfile to mount to the following directory?\n/home/me/example.com/. ",
    "stevenmunro": "I'm getting this same error. I've followed the installation guide word for word. The volume I'm putting this on isn't even encrypted.\nAnsible version 2.6 on MacOS HS.. ",
    "samburgers": "I am having trouble deploying a multisite install. Ansible runs provision and deploy without error, but get a Error establishing a database connection on the server once complete. Local provision/install is fine.\nAre the steps in the docs here still valid, considering the above commit?\nhttps://roots.io/trellis/docs/multisite/\nCheers. ",
    "t0mk": "@fullyint thanks. I will for sure test the PR tomorrow, it's way less effort than upgrading my laptop to Ubuntu 16.04, haha.. I tried this, it works.. ",
    "samkarpluk": "@swalkinshaw right yeah, https is an option so that makes sense. It could still be set with as php_session_secure_cookie: 'Off' as a default, which gives folks the ability to set it to secure if they are https.. ",
    "corbinhesse": "The only difference this does compared to the nginx-includes directory is allow for setting different directives within each environment. Allowing for reporting to only be active on production environments or have no directives set on the development environment if it will be a simple policy.\nOnly reason I submitted a request is to help the generation of these policies. Trellis has made SSL automated, and thinking CSP is another security measure it would be nice to automate as well.\nOn complex policies they can get really difficult to read as an nginx header; therefore, each directive can be separated into a single line like the following:\nyml\ncsp:\n  enabled: true\n  directives:\n    - \"default-src 'none'\"\n    - \"script-src 'self' https://www.googletagmanager.com/gtm.js https://www.google-analytics.com 'sha256-lxi5DtuADDE7N15mfVx3ZWBrGUn/HD+MUoBiUE0cKxw='\"\n    - \"style-src 'self' 'unsafe-inline'\"\n    - \"block-all-mixed-content\"\n    - \"require-sri-for script style\"\nAnd with that example you cannot do with WordPress plugins as they do not allow some of those directives. These plugins are usually set with <meta> tags in which IE doesn't support.\nNo skin on my back if it's declined. Just wanted to help if it would be useful to the group. Thanks for taking the time to look at it!\n. > I agree the existing plugins are kind of crappy.\nYes, I was only referring to existing plugins.\n\nI'm not necessarily against this as a way to quickly set some CSP rules. I just think once you start getting into more complex ones they belong in the application because you'll need some logic around it (or state that exists in the app).\n\nYep, I agree. This proposal or including them in nginx-includes would not be satisfactory for complex page level directives.. Not a problem @swalkinshaw! No explanation necessary so I appreciate the response. I just want more sites to be secure.\nI also didn't intend on those csp dict in the wordpress_sites.yml file by default. It was more of a presentational purpose. It could be removed completely and act as false by default.\nRegardless, I'll look into the docs repository and see if I can write some quick notes on CSP in the security or nginx-includes file.\nThanks!. ",
    "kenbird": "I should maybe mention the OS was Ubuntu 14.04.5 x64. ",
    "dreamon11": "Hi @swalkinshaw,\nAs mention here : https://roots.io/trellis/docs/nginx-includes/, we can disable the file cleanup by defining nginx_includes_d_cleanup: false in group_vars/all/main.yml. \nHowever, when we define nginx_includes_d_cleanup: false in group_vars/all/main.yml, it is not taken into account because of nginx_includes_d_cleanup: true is defined in wordpress-setup defaults.. Yes I try again but same problem, with nginx_includes_d_cleanup: false defined in all/main.yml.\nI output nginx_includes_d_cleanup with ansible debug in wordpress-setup role: \nTASK [wordpress-setup : debug] *************************************************\nnginx_includes_d_cleanup: True. Strange :/\nI have ansible 2.2.0.0.. $ python --version\nPython 2.7.9\nI tried with ansible-playbook dev.yml --tags \"wordpress-setup\":\nTASK [wordpress-setup : debug] *************************************************\nok: [192.168.50.5] => {\n    \"nginx_includes_d_cleanup\": \"false\"\n}\nThen I tried with ansible-playbook dev.yml:\nTASK [wordpress-setup : debug] *************************************************\nok: [192.168.50.5] => {\n    \"nginx_includes_d_cleanup\": \"true\"\n}. Works great! Thanks a lot @slackday ! . Same problem here.\nFix this writing this code in nginx-includes/site.conf.child:\n{% block h5bp -%}\n  location ~* \\.(?:manifest|appcache|html?|xml|json)$ {\n    try_files $uri /index.php;\n  }\n  {{ super() }}\n{% endblock %}\nIn wordpress_sites.yml:\nnginx_wordpress_site_conf: nginx-includes/site.conf.child. ",
    "philippelarcher": "The linked solution is not solving it for me so far.. ",
    "pySilver": "per-site hooks aren't working as expected. in order to make it work you need to define hook for each and every website, otherwise it fails. @fullyint @strarsis ok to simplify things I'll break down the issue to an example.\nTypically you might want a per-site hook for some websites. Let's say you have a.com and b.com. The first one needs some specific build tasks to be executed, while latter b.com is fine with general build-before.yml (or even none).\nThere is no way to handle this easily at the moment.\nIf you define deploy_build_before this way:\nyaml\ndeploy_build_before:\n  - \"{{ playbook_dir }}/deploy-hooks/build-before.yml\"  # works for b.com\n  - \"{{ playbook_dir }}/deploy-hooks/build-before/{{ site }}.yml\" # works for a.com\nyou need to create both hook files:\ndeploy-hooks/build-before/a.com\ndeploy-hooks/build-before/b.com\nand one of them would be empty, since it's not required. If you omit any of them \u2013 your deployment playbook would fail once it will try to include non-existence yml.\nIt would be much easier if we first check file presence before inclusion. I did handle it this way:\n```yaml\n- name: Validate build before hooks\n  local_action: \"stat path={{ item }}\"\n  register: deploy_build_before_hooks\n  with_items: \"{{ deploy_build_before | default([]) }}\"\n  tags: deploy-build-before\n\ninclude: \"{{ item.item }}\"\n  with_items: \"{{ deploy_build_before_hooks.results | default([]) }}\"\n  when: item.stat.exists\n  tags: deploy-build-before\n```\n\nI imagine this could be accomplished to all hooks at once using some custom plugin.. which I had no time to create. . idk why, but fresh install fixed things up.. @partounian I thought I did it. Well my first guess what this is something related to recent Vagrantfile updates but it turned out it's something else.. I've had this issue some time ago and beside using revalises I've added\n- name: ssmtp configure default sending domain\n  template:\n    src: mailname.j2\n    dest: /etc/mailname\nwith \n```\nmailname.jd file:\n{{ mail_hostname }}\n```\n. ",
    "TangRufus": "Should we add redirect domains as well?. Consider this setup from the docs:\n```yaml\nmultiple hosts and redirects are possible\nexample.com:\n  site_hosts:\n    - canonical: example.com\n      redirects:\n        - www.example.com\n        - site.com\n```\nChrome stops www.example.com and site.com at the very beginning because of HTTPS error and would not redirect to example.com \n. I should have searched more keywords.\nDuplicated #818 \nSorry.. @mAAdhaTTah \nWhen changing wp api prefix with filters, they need to follow https://roots.io/trellis/docs/fastcgi-caching/\nyaml\ncache:\n  skip_cache_uri: <Change here>\nMaybe we need to update the docs?. When adding this to the docs, I think we should add links to tutorials about finding these php fpm pm values. Setting them too high would raise memory issues.. What is your command?\nTry $ git clone https://github.com/roots/trellis.git. Should we make apt repo customisable as well?\nyaml\n- name: Add Nginx PPA\n  apt_repository:\n    repo: \"ppa:nginx/development\" <------ this one\n    update_cache: yes. I mean gzipping  assets of WP core and plugins as well, for example:\n- web/wp/wp-admin/css/wp-admin.css\n- web/app/my-plugin/js/my.js\nShould we gzip them by default?. > How could we now which files to gzip for plugins?\nWe don't. In pull request #865, I just gzip common static file types (e.g.: css, js, txt, html, xml, svg, ttf, otf, eot, woff, woff2). Adding these 2 debug messages around gzip task:\n```yaml\n- debug:\n    msg: \"Before Gzip static assets: {{lookup('pipe', 'date')}}\"\n\n\nname: Gzip static assets\n  shell: \"for i in find . | grep -E \\\"\\\\.css$|\\\\.js$|\\\\.txt$|\\\\.html$|\\\\.xml$|\\\\.svg$|\\\\.ttf$|\\\\.otf$|\\\\.eot$|\\\\.woff|\\\\.woff2$\\\"; do gzip --best --keep --force \\\"$i\\\"; done\"\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n\n\ndebug:\n    msg: \"After Gzip static assets: {{lookup('pipe', 'date')}}\"\n```\n\n\nDeploying roots-example-project.com to a USD$ 5 digitalocean droplet, gzipping took 2 seconds.\n```bash\nTASK [deploy : debug] **********\nBefore Gzip static assets: Mon Aug 14 07:40:08 CST 2017\nok: [xxx.xx.xxx.xx]\nTASK [deploy : Gzip static assets] *********\nchanged: [xxx.xx.xxx.xx]\nTASK [deploy : debug] **********\nAfter Gzip static assets: Mon Aug 14 07:40:10 CST 2017\nok: [xxx.xx.xxx.xx]\n```\n. > how inefficient it is since we're gzipping every static file and not only changed files\nI don't think this is necessary because gzipping doesn't take long and copying non-changed gzip files could be tricky sometimes.\nAdded 2 kill switches:\n- gzip_static_assets_on_deploy\n- nginx_gzip_static. How can we find changed and unchanged files with ansible?. > this is including Sage theme right? \nYes. All css, js, txt, html, xml, svg, ttf, otf, eot, woff, woff2 files under deploy_helper.new_release_path are gzipped. Fixed a typo and rebased upon c8f91bf. I don't use sage. Does anyone can time the gzip task with a real world sage theme?\nNote: Exclude node_modules from gzipping. 1d7c3bf started to use ansible find module.\nCurrently, it gzip more files than necessary because I don't know how to exclude them, for example:\nreleases/XXXXXXXX/web/wp/wp-content/themes/twentyeleven\nFor sage, we only need to gzip compiled assets, i.e: web/app/themes/sage/dist <-- I guess...\nyaml\nstatic_asset_paths:\n  - 'web/wp'\n  - 'web/app/plugins'\n  - 'web/app/themes/sage/dist' # <-- I guess...\n@partounian, see this gist and this comment. This is because Agile CRM used spaces in the file names.. Added map('quote') to fix this. I got stuck in overriding h5bp's location block\nSeems no easy way to add gzip_static into these blocks without forking h5bp/server-configs-nginx. Help wanted!\nSide question: Is that any reason not to update h5bp/server-configs-nginx?\nDifference: https://github.com/h5bp/server-configs-nginx/compare/82181a672a7c26f9bc8744fead80318d8a2520b1...master\n. Location blocks added. They are forked from h5bp:\n\nhttps://github.com/h5bp/server-configs-nginx/blob/master/h5bp/location/expires.conf\nhttps://github.com/h5bp/server-configs-nginx/blob/master/h5bp/location/cross-domain-fonts.conf\n. One solution is:\nextract location_compression into roles/wordpress-setup/templates/includes.d, and\nchange template condition to{% if h5bp_expires_enabled and site_compression_enabled -%}\n\nHowever, this will trigger Warn about deprecated Nginx includes directory warning.\nIs there a better way do do it?. Cache-Control removed (except for fonts).\nNote: If enabling both gzip and h5bp expires, gzip location blocks take take precedence. Thus, no Cache-Control headers are given to files in ^/({{ site_compression_paths }})/(.*)\\.(?:{{ site_compression_normal_extensions }})(?:(\\?.*)*)$\nPerhaps this pull request is not suitable for merging because it:\n - makes Nginx config different in dev and production\n - developers might want to add Cache-Control for gzip files which this patch doesn't help. Well... Yes, adding gzip_static on is better than nothing at all.\nAny more changes needed?. Updated:\n- .so files should have 644 file permission. Will this be consider to be merged, or should I extract it to be a galaxy role?\nThanks!. Closing this and continue on #867 because this seems won't be merged without ngx_brotli. More changes to lure you into it:\n - rebased with 5e000e8\n - make use of #859 \n - don't copy .so files\n - removed tags: nginx-dynamic-modules\n - allow specific git version. These commands works on my machine, not sure why it fails on travis:\nbash\n$ ansible-playbook --syntax-check -e env=development deploy.yml\n$ ansible-playbook --syntax-check -e env=development dev.yml\n$ ansible-playbook --syntax-check -e env=development server.yml. > If you would like to build ngx_pagespeed as a dynamic module instead, use --add-dynamic-module= instead of --add-module=........\n\nPagespeed Doc\n\nI had trouble setting ngx_pagespeed as a dynamic module last August. It was a ngx_pagespeed  issue. But from the latest doc, it seems working now. You can give it a try.\n\nThis is untested and don't expect it will work without debugging:\n```\ngroup_vars/all/main.yml\nnginx_dynamic_modules:\n  ngx_pagespeed:\n    repo: https://github.com/apache/incubator-pagespeed-ngx.git\n    version: some_commit_hash\n    objs:\n      - ngx_pagespeed.so\n```. > Also, if we are making gzip static why not brotli?\nCompressing .br takes much longer than gzip. Better wait for #865 and think of a better way to do so.. Will this be consider to be merged, or should I extract it to be a galaxy role?\nThanks!. Dynamic module seems less intrusive because it doesn't require a custom Nginx package.\nAnother benefit is that it enable developers to use more Nginx modules if needed while keeping the official Nginx package intact. (Yes, i am talking about third party roles again...)\nLet me know how the Roots team think about it. This pull request needs rebase.. This pull request was made some time ago.\nCloudflare now uses gzip level 8 and brotli by default.\nIf you are using Cloudflare, you don't need this pull request.. > what happens if you move off CloudFlare, does your cert expire?\nExpires in 15 years. \nHowever, this cert is self-signed. When you move out of Cloudflare, you don't get green padlocks.. Extracted to https://github.com/TypistTech/trellis-cloudflare-origin-ca. Updated:\n- Using md5 hash as file name\n- Not using force anymore, only download at the first provision\n- Using ssl_client_cert_url as global default\nUsage 1:\nyaml\nwordpress_sites:\n  example.com:\n    ssl:\n      enabled: true\n      client_cert_url: 'https://example.com/origin-pull-ca.pem'\nUsage 2:\n```yaml\nssl_client_cert_url: 'https://another-example.com/origin-pull-ca.pem'\nwordpress_sites:\n  example.com:\n    ssl:\n      enabled: true\n```\nUsage 3:\n```yaml\nssl_client_cert_url: 'https://another-example.com/origin-pull-ca.pem'\nwordpress_sites:\n  example.com:\n    ssl:\n      enabled: true\n      client_cert_url: false\n```\nUsage 4:\n```yaml\nssl_client_cert_url: 'https://another-example.com/origin-pull-ca.pem'\nwordpress_sites:\n  example.com:\n    ssl:\n      enabled: true\n      client_cert_url: 'https://example.com/origin-pull-ca.pem'\n```\nAbout using ansible copy module: maybe another pull request for another time\nThanks!. Removed the global option.\n2 spaces before { because of alignment:\n\n. Will this be consider to be merged, or should I extract it to be a galaxy role?\nThanks!. All set. Thanks!. perhaps publish it to ansible galaxy is a better idea\nQuestion:\nWhat is the best practice for ansible galaxy role to change Trellis's Nginx template (wordpress-site.conf.j2)?. Extracted to https://github.com/TypistTech/trellis-cloudflare-origin-ca. Other than #830, we need better way for galaxy roles to override Nginx templates.\nTelling users use templats in vendor doesn't feel right:\nyaml\nnginx_wordpress_site_conf: vendor/roles/TypistTech.trellis-cloudflare-origin-ca/templates/wordpress-site.conf.child\nBut it the only way I could think of.\nAdding to includes.d/{{ item.key }}/ directory:\nIt doesn't get included for redirect domains..... :(. What to do when another galaxy role need to extend wordpress-site.conf.j2 as well?\n. For current state of Trellis, would it be better to use regexp replace instead of jinja2 template override?\nhttps://github.com/TypistTech/trellis-cloudflare-origin-ca/pull/8. Maybe native vagrant solution:\nhttps://www.vagrantup.com/docs/networking/public_network.html#using-the-dhcp-assigned-default-route\nHowever, using DHCP make box IP dynamic. Accessing vagrant machine via FTP/mysql become tricky: https://github.com/Chassis/SequelPro. Vagrant 1.4 fixed the DHCP and NFS issues\nSee: https://github.com/hashicorp/vagrant/pull/2560 and https://github.com/hashicorp/vagrant/pull/2674\nWould Trellis consider moving to DHCP (or something like that), so that we can run multiple Trellis vm at the same time?. > you're saying Trellis should have a location block which matches versioned assets from WP sites?\nYes\nAfter a second thought, matching ?ver=x.x.x won't resolve your concerns in #800 because WP adds its version number if wp_enqueue_script's $ver is false (this is default value)\n\nIf version is set to false, a version number is automatically added equal to current installed WordPress version.\nhttps://developer.wordpress.org/reference/functions/wp_enqueue_script/\n\nThis will be a problem if we use Cache-Control: Immutable\nQuestion: How we can add Cache-Control: Immutable to assets that actually versioned?. > How about making apt module tasks use variables for the name and state parameters? \nAgree\n\nnginx_package_name: nginx=1.13.3-0 would lock down the version... Trellis would have to constantly update these default version numbers \ud83d\ude41 but it would create a more predictable experience for users...\n\nDisagree. Main reason: We haven't taught developers to update with roots/Trellis (this repo). \nLeaving them hanging with outdated packages is dangerous.\n\nusing type_debug in a fail task\n\nAgree: Bumping Ansible requirement to v2.3 and fail if old old list format detected.\n. Normalize apt tasks so they look like this:\n```yaml\n- name: Install XXX\n  apt:\n    name: XXX\n    state: \"{{ XXX_package_state | default(apt_package_state) }}\"\n    update_cache: yes\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n\nname: Install XXX\n  apt:\n    name: \"{{ item.key }}\"\n    state: \"{{ item.value }}\"\n    update_cache: yes\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n  with_dict: \"{{ XXX_packages }}\"\n\nvaraiables\nXXX_packages_default:\n  YYY: \"{{ apt_package_state }}\"\n  ZZZ: \"{{ apt_package_state }}\"\nXXX_packages_custom: {}\nXXX_packages: \"{{ XXX_packages_default | combine(XXX_packages_custom) }}\"\n```\nCheck whether apt_packages and php_extensions are dicts:\nExample error message:\n``php_extensions` is a StrictUndefined not a dict. See:\nhttps://github.com/roots/trellis/pull/881\napt_packages is a list not a dict. See:\nhttps://github.com/roots/trellis/pull/881\n```\nIt doesn't change package versions, except:\n- bumps Ansible requirement to v2.3\n- always update_cache: yes and respects apt_cache_valid_time\n- requires apt_packages and php_extensions to be dicts\nUpdate: Also checks apt_packages_custom and php_extensions_custom\nQuestion: When does a apt tasks need force: yes?. # default + custom for memcached and SSH related packages\nThere is a actual use case for this:\nWhen I first using Trellis, I didn't add caching right from the beginning. Trellis installed php-memcached for me by default. Later on, I wanted to use wp-memcached which requires php-memcached(without ending d). \nTo do so, I have to run $sudo apt-get uninstall php-memcached by hand first.\nWith this patch, we can:\nmemcached_packages_custom:\n  php-memcached: absent\n  php-memcache: latest\nforce: yes on apt tasks\nI remove all force: yes from apt tasks. From @swalkinshaw's link, force: yes seems useful only when there are conflicts.\nReplace memcached with redis and/or APCu\nFor now, you can remove - { role: memcached, tags: [memcached] } from server.yml and dev.yml. Then add your own redis role.\nJust curious, which object cache backend do you use with redis?. > why you used a second separate task to validate vars like apt_packages that use the combine filter ... Ansible's error message hijacks your ability to print out the help message in time.\nCorrect!\nMove checking to common role: Good idea!\nExtra vars checks: Also good idea!\nQuestion: How to ensure common role is ran when users provision with Ansible tags?. Solution found: Run the checks twice.\nAbout that ugly fileglob with_items: ansible/ansible#23265\nWhen required variable is undefined, error message is also ugly. Tried adding mandatory filter, more less the same:\n```\nTASK [common : Verify dict format for apt package component variables] ***\nSystem info:\n  Ansible 2.4.0.0; Vagrant 2.0.0; Darwin\n  Trellis at \"Ansible 2.4 compatibility\"\n\nThe conditional check 'package_vars_wrong_format | count' failed. The error\nwas: error while evaluating conditional (package_vars_wrong_format | count):\n[{% for k,v in package_vars.iteritems() if v | type_debug != 'dict' %}'{{ k\n}}',{% endfor %}]: {u'apt_packages_custom': u'{{ apt_packages_custom }}',\nu'apt_packages_default': u'{{ apt_packages_default }}'}:\n'apt_packages_custom' is undefined\nThe error appears to have been in\n'/Users/tangrufus/Desktop/trellis/roles/common/tasks/validate.yml': line 2,\ncolumn 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\nThe offending line appears to be:\n\n\nname: Verify dict format for apt package component variables\n  ^ here\n```.  - rebased\nmoved checks into common\ntagged checks with [sshd, memcached, php] as @fullyint suggested\n\n. CHANGELOG.md entry added. > remove update_cache parameter\n\nWould it be desirable to make vars such as ferm_package for each of these additional packages so that users could potentially specify versions\n\nAll set. \nExtracted package names into variables so that users can specify versions.. # > How did you setup your projects?\nMore less the same as the subtrees method, but:\n- trellis and bedrock are 2 different git repos\n- keep .git despite the doc tells you to delete it\n- i also have a branch (tangrufus/trellis@project-template) to keep all my common customization to start a project\n- 3 git remotes for every project:\n  * roots/trellis\n  * tangrufus/trellis\n  * actual origin of the project\n```bash\n$ git clone -o roots https://github.com/roots/trellis.git www-example-com-trellis\n$ cd www-example-com-trellis\n$ git remote add tangrufus https://github.com/tangrufus/trellis.git\n$ hub create -p\n$ git remote -v\norigin  https://github.com/TangRufus/www-example-com-trellis.git (fetch)\norigin  https://github.com/TangRufus/www-example-com-trellis.git (push)\nroots   https://github.com/roots/trellis.git (fetch)\nroots   https://github.com/roots/trellis.git (push)\ntangrufus   https://github.com/tangrufus/trellis.git (fetch)\ntangrufus   https://github.com/tangrufus/trellis.git (push)\nMerge my project temaplate\n$ git fetch --all\n$ git merge tangrufus/project-template\nDo your job...\nCommit and push to origin as usual\nWhen roots/trellis has been updated...\nImportant: Reading change logs, commit messages and git diff are necessary\nTips: Make use of git branches\n$ git fetch --all\n$ git merge roots/master\n```\nDo I recommend everyone to use this method?\nNo. Use it only if you are comfortable with git. Otherwise, git gives you more headache than benefits.\nShould you always keep your forks update with roots/trellis?\nYes! Always!\nThis is actually missing from the doc: the doc tells you to delete .git but gives no instructions about updating. \nHowever, updating Trellis is challenging, I don't think of a good and easy way that suitable for everyone.\nEdit: By forks, I mean both origin and tangrufus remotes in the above example.\nAvoiding merge conflicts\nSince I use git a bit differently than the subtrees method, I got less merge conflicts.\nTips:\n- Whenever possible, don't change existing files in roles/*\n- When changing j2 templates, make use of variables\n- When changing variable values, define them in group_vars/<env>/xxx.yml\n- When a  j2 template doesn't allow customizing with variables, submit pull requests, example: #856 \n- When you need to add more tasks:\n  * Bad: change existing files in roles/*\n  * Good: make a new role and add it into dev.yml / server.yml\n  * Best: extract it to galaxy.ansible.com\n  * see also: #830, #882 \n- Whenever possible, don't use Nginx child templates because you lose all the benefits Trellis update gives you\nLet say you want to change something in sites-available/example.com.conf:\n- Best: define variables in group_vars/<env>/xxx.yml\n- Good: template out to {{ nginx_path }}/includes.d/{{ item.key }}/xxx.conf but beware Trellis might delete your files during this task, see how I do it\n- Bad:  use Nginx child templates is the last resort\n\u26a0\ufe0f\n\nReading change logs, commit messages and git diff are necessary\nNo merge conflict doesn't mean it won't break\nSame commit doesn't mean same server, see: https://github.com/roots/trellis/pull/881#issuecomment-328186152\n\nThe ultimate way to avoid merge conflict\nGet it merged into roots/trellis\n. Correct.\nFor every project, I have 2 git repo:\n- example-project-com-trellis\n- example-project-com-bedrock\nYou need to change group_vars/<env>/wordpress_sites.yml accordingly\nhttps://github.com/roots/trellis/blob/db89d49a18e60b5c9e1e8a1a4901080bfe871e26/group_vars/production/wordpress_sites.yml#L12-L13\n. > deal with merge conflicts for composer.lock?\nYou don't. First resolve conflicts in composer.json, then $ composer update. Let composer generates a new composer.lock for you.. It works without composer.lock. However, the deployment will be a little bit different. Trellis may silently upgrade your wp core / plugins / themes during deploy.\nReason\nTrellis runs $ composer install during deploy. \n$ composer install with .lock always install the exact versions listed.\n$ composer install without .lock works as $ composer update.\nWorkaround\nIf you really want to exclude .lock from git, always specify the exact package versions in composer.json. Otherwise, trellis will silently upgrade your wp core / plugins / themes during deploy.\nRecommendation\nCommiting your composer.lock is the best practice.\nUse the workaround only if you have a very strong reason.\nSee:\n - https://github.com/roots/trellis/blob/master/roles/deploy/hooks/build-after.yml\n - https://getcomposer.org/doc/01-basic-usage.md#installing-without-composer-lock\n - https://getcomposer.org/doc/articles/versions.md#exact-version-constraint. Can we apply the same patch to ssl.no-default as well? That file is currently ignored. . A more realistic example: https://github.com/TypistTech/vagrant-trellis-cert/blob/master/lib/vagrant_plugins/trellis_cert/trellis.rb. Duplicates #881 . Renamed. \ud83d\udc4d  for default\nHowever, if you already have a VM with static IP (running / poweroff doesn't matter), you need $ vagrant destroy before switching to DHCP.. I had trouble with vagrant reload. \nBut, it could cause by vagrant-triggers, didn't investigate.. I got more errors besides mount.nfs: access denied by server while mounting .... I guess they were from one of my vagrant plugins.\nJust curious: Do you work while travelling, @oxyc? I found it extremely hard to stay in front of the computer when everyone else in the hostel went out for sun and beach.. Besides, Certbot doesn't:\n\ndetect new hostnames like #630\nsupport --staging yet. The openssl_certificate_module requires ansiable 2.4. Is #895 going to be merged soon?\n\nThe letsencrypt_module requires us to change Nginx back and forth for acme challenge. Certbot handles it for us. I think Certbot simplifies everything.\n. openssl_certificate looks nice. Updated self-signed-certificate to use it.\nRemoved Certbot because:\n - it doesn't play well with pyOpenSSL which required foropenssl_certificate , see: https://github.com/certbot/certbot/issues/5111\n - it can't be used with letsencrypt role on the same server\nRebased upon d96a58f. Actual changes here: https://github.com/roots/trellis/compare/ansible-2.4...TangRufus:ssl-providers\n. Rebased. Note that I modified server.yml and dev.yml because ssl providers need to be tagged. Otherwise, wordpress-setup deletes their nginx config files.. I vote for applying wordpress-setup to nginx because this also helps when adding or removing sites, i.e.: Create Nginx available sites & Enable or disable Nginx sites tasks. It should continue working until they stop the VM.\nBest case scenario:\nEverything works. Normal vagrant halt && vagrant up / vagrant reload will pick up the new dynamic ip.\nNot so good scenario:\nThey need to run vagrant destory if any conflict happens. \nWorst case scenario:\nIf they are unlucky as me, having some buggy vagrant plugins and buggy custom scripts:\n1. vagrant halt all other VMs\n2. power off and destroy the problematic VM via VirtualBox GUI\n3. sudo rm /etc/exports\n4. remove related hosts from /etc/hosts\n5. vagrant up. No, mis-clicked. Sorry.. done.. Sorry guys, my instruction about vagrant destroy is incorrect. I have a buggy script \"cached\" the IP and changed DHCP's behaviour on initial vagrant up, making it works like static IP.\nIf vagrant halt && vagrant up or vagrant reload don't work for you, do not destroy the VM:\n1. power off the problematic VM via VirtualBox GUI\n2. (maybe) sudo rm /etc/exports\n3. (maybe) remove related hosts from /etc/hosts\n4. vagrant up. More info: If you have vagrant up previously, you won't encounter this issue.\nRelated vagrant issue: https://github.com/hashicorp/vagrant/issues/7070\nCurrent workaround: Use static IP on initial vagrant up, then change it back to dhcp. Culprit: Me not tested the PRs thoroughly. Third bug within a month, i feel ashamed of myself. Sorry guys.\nComplicity:\nINFO retryable: Retryable exception raised: #<Vagrant::Errors::VirtualBoxGuestPropertyNotFound: Could not find a required VirtualBox guest property:\n  /VirtualBox/GuestInfo/Net/1/V4/IP\nVagrant tries to read this property during before NFS mounting. However, this property is not set on new VM.\nRelated: https://github.com/hashicorp/vagrant/issues/3792\nShould we revert #892 as well? I don't find a good solution to use DHCP without vagrant up with static IP first.. > we did enable ansible-local by default\nIs that true for non-wondows users?\nhttps://github.com/roots/trellis/blob/master/lib/trellis/vagrant.rb#L40-L42\n\nIs there no better solution for APFS yet?\n\nI don't find one.\nPlease test this pull request on non-APFS Macs and other platforms.. ```ruby\nhttps://github.com/roots/trellis/blob/master/lib/trellis/vagrant.rb#L40-L42\ndef local_provisioning?\n  @local_provisioning ||= Vagrant::Util::Platform.windows? || !which('ansible-playbook') || ENV['FORCE_ANSIBLE_LOCAL']\nend\n```\n\nTo use Trellis for remote servers, we recommend installing Ansible locally on your host machine\nhttps://roots.io/trellis/docs/remote-server-setup/\n\nIf Ansible is installed as the doc suggests, ansiable_local is not used.. After moving to a SSD harddisk, trellis works out of the box. I think this pull request should not be merged and APFS on traditional harddisk users should manually disable NFS and use ansible_local. . Not sure why box automatic update checking doesn't kick in. I found a issue about bento/ubuntu-16.04's tagging:\nVersion 201805.15.0 is listed on https://app.vagrantup.com/bento/boxes/ubuntu-16.04. But vagrant box update doesn't pick up 201805.15.0.\n```bash\n\u279c vagrant box update\n==> default: Checking for updates to 'bento/ubuntu-16.04'\n    default: Latest installed version: 201803.24.0\n    default: Version constraints: >= 201801.02.0\n    default: Provider: virtualbox\n==> default: Box 'bento/ubuntu-16.04' (v201803.24.0) is running the latest version.\n\u279c vagrant version\nInstalled Version: 2.1.1\nLatest Version: 2.1.1\nYou're running an up-to-date version of Vagrant!\n```\nMaybe related:\n- VirtualBox Graphical User Interface\n  Version 5.2.12 r122591 (Qt5.6.3)\n- macOS High Sierra\n  Version 10.13.4\n. Box update checking resumes to work for me:\nWith vagrant_box_version: '>= 201801.02.0':\nbash\n\u279c vagrant up\nBringing machine 'default' up with 'virtualbox' provider...\n==> default: Importing base box 'bento/ubuntu-16.04'...\n==> default: Matching MAC address for NAT networking...\n==> default: Checking if box 'bento/ubuntu-16.04' is up to date...\n==> default: A newer version of the box 'bento/ubuntu-16.04' for provider 'virtualbox' is\n==> default: available! You currently have version '201803.24.0'. The latest is version\n==> default: '201806.08.0'. Run `vagrant box update` to update.\nBesides, $ vagrant box update now works as expected.. I tried DHCP out of curiosity and it suddenly worked. Not sure what fixed it.. > If I switch to DHCP on an existing VM using vagrant reload I get and error. Running vagrant halt; vagrant up works.\nRun $ vagrant hostmanager when this error show up:\nbash\nNFS requires a host-only network to be created.\nPlease add a host-only network to the machine (with either DHCP or a static IP) for NFS to work.\n$ vagrant hostmanager will clear the old /etc/hosts ~~~and /etc/exports~~~ entries and create the DHCP ones.\n~~~Not tested: i guess $ vagrant hostmanager might be a solution to the second point.~~~\n\nCorrection:\n$ vagrant halt && vagrant up seems the only way to update /etc/exports.\n. >Note that it is necessary to allow the usage of a stale cached response when it is being updated. \n\n--- https://nginx.org/en/doc/http/ngx_http_fastcgi_module.html#fastcgi_cache_background_update\n\nThe blog post @swalkinshaw linked also updated about the issues with 404 pages on 17 May 2018.\nDo we need to add fastcgi_cache_use_stale as well?. I vote for the second solution because it could prevent troubles when nginx_cache_duration is a unexpectedly high value.. Forcing the role name to be the same as ssl provider name could be an issue for galaxy roles because users could name the galaxy role to whatever they want.\nyml\n- src: TypistTech.trellis-cloudflare-origin-ca\n  version: 0.6.0\n  name: whatever-i-want\nNot so ideal solution:\nTag the role with wordpress-setup.\n```yml\nserver.yml\n- { role: TypistTech.trellis-cloudflare-origin-ca, tags: [cloudflare-origin-ca, wordpress-setup], when: sites_using_cloudflare_origin_ca | count }\n\n``. Trellis' deploy role already creating.env` file. What is your use case?\nhttps://github.com/roots/trellis/blob/f948df133c92cf13516c5f0cc00cdde773068e47/roles/deploy/defaults/main.yml#L19-L22\nhttps://github.com/roots/trellis/blob/5199022f772a729e79aa6838cddf1af3ff790579/roles/deploy/tasks/build.yml#L8-L13. I believe copying the 10 lines form Trellis to your playbook would be the easiest option. > I found it much easier to download CloudFlare's free SSL certificates, and set the Trellis SSL Provider to \"manual\"\nWhy not https://github.com/TypistTech/trellis-cloudflare-origin-ca ?. > I think self-signed is better because it doesn't involve going to CloudFlare and you can't Origin CA enforcement is per domain right?\nNot to confuse with Authenticated Origin Pulls.\n\ntrellis-cloudflare-origin-ca and @adleviton's \"manual\" way are the same thing. They install a self-signed certificate trusted by cloudflare (self refers to cloudflare here).\nThe letsencrpyt + cloudflare way install a \"real\" valid certificate. \nAll of the above allow you setting cloudflare's ssl level to \"Full (strict)\".\nAssuming you are not using the USD$200 plan, all of the above show cloudflare's cert to end users(web browsers).\nUsing a  self-signed certificate (not trusted by cloudflare), you need to lower cloudflare's ssl level to \"Full\" which is a bad thing (self refers to you here).\nYou could lower subdomain/path ssl level by page rules. However, I don't think of any legitimate use case. You should always use \"Full (strict)\".\nQuestion: Why do you prefer using letsencrpyt rather than cloudflare origin ca?\n. Update:\n- removed the task \"Ensure build directory present\" because it is unnecessary. Sorry @davebowker @thewhipster, my bad.\nQuestions:\n- What OS do you use?\n- What is the Sage theme directory name?\nPlease enable logging and deploy in verbose mode. Let's see what went wrong:\nEnable logging:\n```diff\ndeploy-hooks/build-before.yml\n\nname: Clone project files\n    git:\n      repo: \"{{ project_git_repo }}\"\n      version: \"{{ project_version }}\"\n      dest: \"{{ project_build_path }}\"\n      force: yes\nno_log: true\nno_log: false\n    connection: local\n```\n\nDeploy in verbose mode:\nbash\n$ ./bin/deploy.sh staging example.com -vvvv\n$ ./bin/deploy.sh production muchness.co -vvvv\n\nExample of a successful deploy:\n```\nTASK [deploy : Clone project files] ********\ntask path: /Users/tangrufus/Code/typist.tech/trellis/deploy-hooks/build-before.yml:10\nUsing module file /usr/local/Cellar/ansible/2.5.4/libexec/lib/python2.7/site-packages/ansible/modules/source_control/git.py\n<111.222.333.444> ESTABLISH LOCAL CONNECTION FOR USER: tangrufus\n<111.222.333.444> EXEC /bin/sh -c '/usr/bin/python && sleep 0'\nok: [111.222.333.444] => {\n    \"after\": \"13cae8adce0eda97bf22015ad2d06f2dc2c878cf\",\n    \"before\": \"13cae8adce0eda97bf22015ad2d06f2dc2c878cf\",\n    \"changed\": false,\n    \"invocation\": {\n        \"module_args\": {\n            \"accept_hostkey\": false,\n            \"archive\": null,\n            \"bare\": false,\n            \"clone\": true,\n            \"depth\": null,\n            \"dest\": \"/var/folders/pn/sy12cvg51ybg0fsjmw3vnv100000gn/T/trellis/typist.tech/production\",\n            \"executable\": null,\n            \"force\": true,\n            \"key_file\": null,\n            \"recursive\": true,\n            \"reference\": null,\n            \"refspec\": null,\n            \"remote\": \"origin\",\n            \"repo\": \"git@github.com:tangrufus/xxx.git\",\n            \"ssh_opts\": null,\n            \"track_submodules\": false,\n            \"umask\": null,\n            \"update\": true,\n            \"verify_commit\": false,\n            \"version\": \"master\"\n        }\n    },\n    \"remote_url_changed\": false\n}\nTASK [deploy : Install npm dependencies] *********\ntask path: /Users/tangrufus/Code/typist.tech/trellis/deploy-hooks/build-before.yml:19\nUsing module file /usr/local/Cellar/ansible/2.5.4/libexec/lib/python2.7/site-packages/ansible/modules/commands/command.py\n<111.222.333.444> ESTABLISH LOCAL CONNECTION FOR USER: tangrufus\n<111.222.333.444> EXEC /bin/sh -c '/usr/bin/python && sleep 0'\nchanged: [111.222.333.444] => {\n    \"changed\": true,\n    \"cmd\": [\n        \"yarn\"\n    ],\n    \"delta\": \"0:00:01.599661\",\n    \"end\": \"2018-06-20 04:08:14.691451\",\n    \"invocation\": {\n        \"module_args\": {\n            \"_raw_params\": \"yarn\",\n            \"_uses_shell\": false,\n            \"chdir\": \"/var/folders/pn/sy12cvg51ybg0fsjmw3vnv100000gn/T/trellis/typist.tech/production/web/app/themes/sage\",\n            \"creates\": null,\n            \"executable\": null,\n            \"removes\": null,\n            \"stdin\": null,\n            \"warn\": true\n        }\n    },\n    \"rc\": 0,\n    \"start\": \"2018-06-20 04:08:13.091790\",\n    \"stderr\": \"\",\n    \"stderr_lines\": [],\n    \"stdout\": \"yarn install v1.7.0\\n[1/5] Validating package.json...\\n[2/5] Resolving packages...\\nsuccess Already up-to-date.\\nDone in 0.92s.\",\n    \"stdout_lines\": [\n        \"yarn install v1.7.0\",\n        \"[1/5] Validating package.json...\",\n        \"[2/5] Resolving packages...\",\n        \"success Already up-to-date.\",\n        \"Done in 0.92s.\"\n    ]\n}\n. One thing I could think of is: if your file structure is same as the [official documents](https://roots.io/trellis/docs/installing-trellis/#create-a-project) one:\nexample.com/      # \u2192 Root folder for the project\n\u2514\u2500\u2500 .git/         # \u2192 One git repo to rule them all\n\u251c\u2500\u2500 trellis/      # \u2192 Your clone of this repository\n\u2514\u2500\u2500 site/         # \u2192 A Bedrock-based WordPress site\n    \u2514\u2500\u2500 web/\n        \u251c\u2500\u2500 app/  # \u2192 WordPress content directory (themes, plugins, etc.)\n        \u2514\u2500\u2500 wp/   # \u2192 WordPress core (don't touch!)\n```\nThe correct sage theme location would be: {{ project_build_path }}/site/web/app/themes/sage\nEdit: Update temporary solution.\nTemporary Solution: Adding /site before all /web/app/themes/sage in deploy-hooks/build-before.yml\n```diff\n- \"{{ project_build_path }}/web/app/themes/sage\"\n+ \"{{ project_build_path }}/site/web/app/themes/sage\"\n\n\"{{ project_build_path }}/web/app/themes/sage/dist\"\n\"{{ project_build_path }}/site/web/app/themes/sage/dist\"\n```. Tests changing between 2 repos(one with subtree and one without) back and forth. It looks good to me.\n\nDid anyone find any bugs?. Fixed by adding --lock-never to gpg verify command.\nAlso changed synchronize to copy so that sudo is not required.\n\nI'm assuming this is \"breaking\" since it's a new major version for WP-CLI?\n\nCorrect. You might need to change wp_cli_packages when upgrading wp cli to v2\nBesides, with this pull request, you can't \"downgrade\" to wp cli v1.x because wp_cli_phar_asc_url will break (in fact, 2.0.0 is the only release that comes with a .asc file). > I'm not sure how generic we can make this. Composer + Yarn install are common/generic. yarn build:production is more Sage specific, and then especially copying the dist folder.\nInstead of making compile steps (composer, yarn, copy, etc) generic, I suggest normalizing the way we complie frontend assets in deploy hooks; similar idea to #896 \nReasons:\n- provide a standard way for thirdy party roles to extend trellis\n- don't bunlde unnecessary tasks in trellis\n- generic roles exist (e.g: geerlingguy.composer), no point in reinventing the wheel\nFor example, this is what developers would do if they using both sage 8 and sage 9 themes on the same server.\n```diff\n  # requirements.yml\n\n\n\nsrc: XXX.trellis-sage-8-compiler\n\n\n\nversion: 1.2.3\n\n\n\nsrc: YYY.trellis-sage-9-compiler\n\n\nversion: 1.2.3\n```\n\n```diff\n  # group_vars/all/deploy-hooks.yml\n\ndeploy_build_before:\n\n\n\"{{ playbook_dir }}/vendor/roles/XXX.trellis-sage-8-compiler/tasks/main.yml\"\n\n\n\n\n\"{{ playbook_dir }}/vendor/roles/YYY.trellis-sage-9-compiler/tasks/main.yml\"\n```\n\n\n\n```diff\n  # group_vars//wordpress_sites.yml\nwordpress_sites:\n    example.com:\n+     sage_8_compiler:\n+       - my-sage-eight-theme\n    another-example.com:\n+     sage_9_compiler:\n+       - my-sage-nine-theme\n    multisite-example.com:\n+     sage_9_compiler:\n+       - my-sage-nine-theme\n+       - my-second-sage-nine-theme\n+     sage_8_compiler:\n+       - my-sage-eight-theme\n+       - my-second-sage-eight-theme\n```\nsame idea goes to Laravel mix\n\n\nAs is right now, I don't like having sage_themes leaked into wordpress_sites.yml by default (even if it's just a comment).\n\nHow about this:\n- extract build-before.yml into a separate ansible galaxy role\n- remove deploy-hooks/build-before.yml from trellis\n- remove the comments from wordpress_sites.yml\n- galaxy role documents instruct developers to define sage_themes (or sage_8_compiler / sage_9_compiler) in wordpress_sites.yml. > Only question is if it makes sense for the wp sites property sage_themes or whatever to be more generic? Maybe just theme_builder or something like that?\nI suggest not to make it generic to allow role authors to define whatever the structure(dict, array, string, boolean) they want. Only thing we expecting here is the property name should be unique.\nThis is because we don't want to limit role authors' flexibility. From the forum, I see people want to use Trellis on various frondend frameworks and static sites generator(e.g: Vue on top of Laravel, GatsbyJS, etc). They might require a very different kind of config in wordpress_sites.yml.\n\nLet me know if you want go for extracting sage compiler into a separate ansible galaxy role.. Help wanted\nAlthough I extracted to trellis-sage-9-compiler, there are some more tests and todos awaiting help.\nSee: https://github.com/ItinerisLtd/trellis-sage-9-compiler#todos-help-wanted\n\nQuestion:\n- Should I completely remove sage from trellis, i.e: remove those comments from wordpress_sites.yml and remove the role from requirements.yml?\n. > we should remove all mentions of it,\n\ndeploy-hooks/build-before.yml could include a more generic simplified example with a npm install &&npm build` type thing.\n\nDone.\n. ansible-galaxy won't install/upgrade existing roles without --force.\nExample:\n1. fork and use Trellis as ususal\n1. add my-role v1 to requirements.yml\n1. $ vagrant up\n1. my-role v1 is installed\n1. bump my-role to v2 in requirements.yml\n1. $ vagrant up --provision\n1. my-role won't be upgraded and stays v1 because of missing --force flag\nShould we warn users about this?\n. > Maybe my experience with the default is so much more annoying because I constantly create/destroy VMs for testing whereas most users wouldn't do it as often?\nAgree it is annoying. Somethimes I just copy and paste the vendor folder from another project. And, always set vagrant_skip_galaxy to true.\nPerphas a warning in the docs is enough?\nReasons:\n- it doesn't make any differences to first time users\n- whenever requirements.yml is changed, it's normal/expected to run $ anisble-galaxy manually. cc: @codepuncher. Yes, Nginx team is renaming development to mainline.\n\nThis PPA [development] contains the latest 'Mainline' Release version of the nginx web server software, up through 1.15.x, for Artful, Bionic, Cosmic, and Xenial.\nFor Mainline 1.17.x, once released, you will need to use the newer PPA at https://launchpad.net/~nginx/+archive/ubuntu/mainline.\n-- https://launchpad.net/~nginx/+archive/ubuntu/development\nThis PPA [mainline] contains the latest 'Mainline' Release version of the nginx web server software. This release was formerly tracked in the PPA located at https://launchpad.net/~nginx/+archive/ubuntu/development but for the purposes of naming this newer Mainline PPA is being provided with identical packages from there.\nMainline PPA uploads will now go here.\n-- https://launchpad.net/~nginx/+archive/ubuntu/mainline\n. > Why --force?\n\nIf .gz files already exist for whatever reason, gzip without --force would prompt for confirmation. Since we using --best, our .gz files are... the best. Therefore, overriding existing .gz files seems harmless.\nActually, I am not familiar with shell commands. What command do you suggest?\nBesides, we need to think about customization as well.. Separating gzip_static_assets_on_deploy and nginx_gzip_static:\n- enabling gzip_static globally gives performance penalty\n- allow developers to customize nginx config\nSee: https://github.com/roots/trellis/blob/c8f91bf808f1e5b4754c15e3d19ba5079ca0beb9/roles/nginx/templates/nginx.conf.j2#L165-L169. How come you don't get this error?\nbash\n$ sudo apt-get source nginx\nReading package lists... Done\nE: You must put some 'source' URIs in your sources.list. Seems $ add-apt-repository --enable-source {{ nginx_ppa }} is a better choice. ssl_client_cert_url was the global option, removed now.. it's from h5bp:\nhttps://github.com/h5bp/server-configs-nginx/blob/c5c6602232e0976d9e69d69874aa84d2a2698265/nginx.conf#L34. So /run is the correct one?. reverted. fixed. We need the --delete flag to remove deleted files from {{ nginx_path }}/h5bp\nWithout --delete:\n```bash\n$ tree src dest\nsrc\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\ndest\n\u251c\u2500\u2500 AAA.txt\n\u2514\u2500\u2500 BBB.txt\n$ rsync -ac --info=NAME ./src/ ./dest/\n./\nCCC.txt\n$ tree src dest\nsrc\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\ndest\n\u251c\u2500\u2500 AAA.txt\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\n```\nAAA.txt still there.\nWith --delete:\n```bash\n$ tree src dest\nsrc\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\ndest\n\u251c\u2500\u2500 AAA.txt\n\u2514\u2500\u2500 BBB.txt\n$ rsync -ac --delete --info=NAME ./src/ ./dest/\ndeleting AAA.txt\ndeleting .DS_Store\n./\nCCC.txt\n$ tree src dest\nsrc\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\ndest\n\u251c\u2500\u2500 BBB.txt\n\u2514\u2500\u2500 CCC.txt\nAAA.txt is gone.. Question: Why this task needs those tags?. Does it return `444` if we `include includes.d/{{ item.key }}/*.conf;` here? The goal is to allow third party roles to inject `ssl_certificate` and `ssl_certificate_key` here.\n  {% block includes_d -%}\n  include includes.d/{{ item.key }}/.conf;\n  {% endblock -%}\n```. Thanks!. I am over-concerned because this block only runs for unknown* domains. Thus, we can't give it a valid ssl certificate for most of the cases. \nThanks!. Questions:\n- why not ssl_verify_client off; explicitly?\n- why skipping ssl_certificate, ssl_trusted_certificate and ssl_certificate_key and let Nginx get them form  another server block?. About ssl_verify_client off;, over-concerned again, sorry.\n\nWhen those other directives were absent, the real ssl-enabled wordpress_sites seemed to fail\n\nThose other directives ~are~ could be absent even with this patch. Edge case: All sites using third party ssl providers. The if/else conditions never matched.\nPossible solution: Always generate self-signed cert for ssl.no-default.conf as https://github.com/h5bp/server-configs-nginx/pull/177 suggested.\nThis opens another question: Is it good to enable ssl.no-default.conf even no site using SSL?\n. Because of dig. It needs Ruby 2.3. Done. reverted. Removed. Moved into roles/common/templates/package_vars_wrong_format_msg.j2. done. Why not hkps://?. Looks like bento/ubuntu-18.04 is first added on 201803.24.0. Do we need to bump vagrant_box_version?\nhttps://github.com/chef/bento/blob/master/CHANGELOG.md. done. ### Side Effect\nBefore this pull request:\nIf /srv/www/XXXX/shared/source being modified, deploy will fail. And, no useful message printed because of no_log: true. Instead, a misleading Git repo {{ project.repo }} cannot be accessed will be printed on the next task.\nAfter this pull request:\nIf /srv/www/XXXX/shared/source being modified, the changes will be discarded during deploy because of force: yes.. Can we omit the block parameters?\ndiff\n- trigger.ruby do |_, _|\n+ trigger.ruby do. ",
    "umohpyro": "This works flawlessly, no need for the ssh keys issues\n. ",
    "reidab": "@TangRufus I think so. I almost did this initially \u2014\u00a0I'll update shortly.. ",
    "dalepgrant": "Not sure if this is still on the cards but I've just tried this and hit [Errno 7] Argument list too long. My trial site had a parent theme, child theme and 8 plugins. Nothing heavy except maybe the parent theme and Visual Composer combo, both of which do seem to have a lot of files. \nTested with Trellis 1.0.1.. ",
    "wilmardo": "Any update on this or #866 @swalkinshaw? In my humble opinion Brotli support would be an awesome addition to Trellis since it reduces load time by a bunch :). ",
    "oxyc": "\nI had trouble with vagrant reload.\n\nI tested this over at Drupal VM and same happened for me if you're referring to a mount.nfs: access denied by server while mounting ... error @TangRufus? vagrant halt; vagrant up fixed it though.. For reference the plugins I had were vagrant-vbguest and vagrant-hostmanager. Guess it might be triggers.\n@TangRufus Nah I never liked mixing work and travel, wouldn't do either at full capacity. I usually travel 4-6 months until I get sick of it, then find a place to work for 6-8 months until I miss it again, and repeat. Also I like signing off so I don't want to bring my laptop.\n. Seems vagrant-vbguest is the culprit https://github.com/dotless-de/vagrant-vbguest/issues/243\nSee my two comments at https://github.com/geerlingguy/drupal-vm/pull/1559#issuecomment-334756183. I tried this again over at Drupal VM. One earlier issue I had is now fixed but I still encounter a few annoyances:\n\nIf I switch to DHCP on an existing VM using vagrant reload I get and error. Running vagrant halt; vagrant up works.\n    > NFS requires a host-only network to be created.\n    > Please add a host-only network to the machine (with either DHCP or a static IP) for NFS to work.\nIf I try and switch back to an IP after having used DHCP it seems pretty impossible. It just gets stuck (this might be drupal vm related though as we also support vagrant-hostsupdater)\n    > drupalvm: Warning: Remote connection disconnect. Retrying...\n    > drupalvm: Warning: Connection reset. Retrying.... \n",
    "ztackett11": "How can I go about adding these changes to my trellis repo? i think i was able to update trellis to rc 2 (I think). ",
    "MasonFI": "Oh, I think this requirement is only for Window hosts, because if have Windows, you are running the deploy command from inside the Trellis VM machine.. ",
    "9585999": "@greatislander thx.. ",
    "jdevalk": "Of course this should be tested for breakage, we've tested this on a couple machines but they're all 64 bit macs :). ",
    "nextgenthemes": "Oh well thanks, I thought I already did that.. ",
    "nlemoine": "Would love to see that happen. There's not many differences between a WordPress and any other PHP application.. ",
    "pawelkleczek": "I got the same error today\nTASK [letsencrypt : Generate the certificates] *****\nSystem info:\n  Ansible 2.4.2.0; Darwin\n  Trellis at \"Bump Ansible version_tested_max to 2.4.2.0\"\n\nnon-zero return code\nfatal: [159.89.23.36]: FAILED! => {\"changed\": false, \"cmd\": [\"./renew-certs.py\"], \"delta\": \"0:00:01.432599\", \"end\": \"2018-01-16 14:42:40.194274\", \"rc\": 1, \"start\": \"2018-01-16 14:42:38.761675\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Generating certificate for 159.89.23.36\\nError while generating certificate for 159.89.23.36\\nTraceback (most recent call last):\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 198, in \\n    main(sys.argv[1:])\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 194, in main\\n    signed_crt = get_crt(args.account_key, args.csr, args.acme_dir, log=LOGGER, CA=args.ca)\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 104, in get_crt\\n    raise ValueError(\\\"Error requesting challenges: {0} {1}\\\".format(code, result))\\nValueError: Error requesting challenges: 400 {\\n  \\\"type\\\": \\\"urn:acme:error:malformed\\\",\\n  \\\"detail\\\": \\\"Error creating new authz :: Issuance for IP addresses not supported\\\",\\n  \\\"status\\\": 400\\n}\", \"stdout_lines\": [\"Generating certificate for 159.89.23.36\", \"Error while generating certificate for 159.89.23.36\", \"Traceback (most recent call last):\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 198, in \", \"    main(sys.argv[1:])\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 194, in main\", \"    signed_crt = get_crt(args.account_key, args.csr, args.acme_dir, log=LOGGER, CA=args.ca)\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 104, in get_crt\", \"    raise ValueError(\\\"Error requesting challenges: {0} {1}\\\".format(code, result))\", \"ValueError: Error requesting challenges: 400 {\", \"  \\\"type\\\": \\\"urn:acme:error:malformed\\\",\", \"  \\\"detail\\\": \\\"Error creating new authz :: Issuance for IP addresses not supported\\\",\", \"  \\\"status\\\": 400\", \"}\"]}. Thanks man, that was it!. ",
    "jrgd": "Same; receiving the below when provisioning with ssl: true and letsencrypt.\nProvided agreement URL [https://letsencrypt.org/documents/LE-SA-v1.1.1-August-1-2016.pdf] does not match current agreement URL [https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf]. ",
    "faheemrazaa": "Same error is happening on my website http://gulfday.com \nsee the attached screenshot.. \n\nAnybody up for the help ? . ",
    "ghettifish": "I was getting this error even after I changed my IP's to domains in my host file.\nWhere I went wrong: I had my CNAME record for www pointed to \"@\" in DNS.\nSolution: I deleted that CNAME record and created an A record that pointed to the server IP address, I was able to run ansible-playbook server.yml -e env=production --tags letsencrypt and all of the tasks completed successfully.\nTASK [letsencrypt : Generate the certificates] \nSystem info:\n  Ansible 2.6.1; Darwin\n  Trellis version (per changelog): \"Update xdebug tunnel configuration\"\nnon-zero return code\nfatal: [rampartls.com]: FAILED! => {\"changed\": false, \"cmd\": [\"./renew-certs.py\"], \"delta\": \"0:00:00.500485\", \"end\": \"2018-07-18 15:46:40.898560\", \"rc\": 1, \"start\": \"2018-07-18 15:46:40.398075\", \"stderr\": \"\", \"stderr_lines\": [], \"stdout\": \"Generating certificate for rampartls.com\\nError while generating certificate for rampartls.com\\nTraceback (most recent call last):\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 198, in <module>\\n    main(sys.argv[1:])\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 194, in main\\n  signed_crt = get_crt(args.account_key, args.csr, args.acme_dir, log=LOGGER, CA=args.ca)\\n  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 123, in get_crt\\n    wellknown_path, wellknown_url))\\nValueError: Wrote file to /srv/www/letsencrypt/D4atj0lwRWT0dOJ_mry49TvlkN-6T7do2ymZbrQC3-g, but couldn't download http://www.rampartls.com/.well-known/acme-challenge/D4atj0lwRWT0dOJ_mry49TvlkN-6T7do2ymZbrQC3-g\", \"stdout_lines\": [\"Generating certificate for rampartls.com\", \"Error while generating certificate for rampartls.com\", \"Traceback (most recent call last):\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 198, in <module>\", \"    main(sys.argv[1:])\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 194, in main\", \"    signed_crt = get_crt(args.account_key, args.csr, args.acme_dir, log=LOGGER, CA=args.ca)\", \"  File \\\"/usr/local/letsencrypt/acme_tiny.py\\\", line 123, in get_crt\", \"    wellknown_path, wellknown_url))\", \"ValueError: Wrote file to /srv/www/letsencrypt/D4atj0lwRWT0dOJ_mry49TvlkN-6T7do2ymZbrQC3-g, but couldn't download http://www.rampartls.com/.well-known/acme-challenge/D4atj0lwRWT0dOJ_mry49TvlkN-6T7do2ymZbrQC3-g\"]}\n. ",
    "tim-mortimer": "Thank you for the fix! This definitely had me scratching my head for a while.\nShould we reprovision our servers as a result of this fix, or will the renewals still work correctly?. ",
    "BlueBamboo1221": "hello,sir!\nI  tried as this method\nbut same error\ncan you help ?. ",
    "alwaysblank": "This is probably a result of Chrome (and eventually other browsers) no longer allowing .dev urls because that TLD belongs to google and they're forcing HSTS on it in the browser. More info here: https://medium.engineering/use-a-dev-domain-not-anymore-95219778e6fd\nIf that's the case, the fix is simple: Just change .dev to something else (.test seems to be a good choice) and re-provision your stuff.. ",
    "yudistiraAshadi": "Thank you, it solves my problem! It's weiird tho, i literally used .dev on another project like two days ago.. ",
    "knowler": "@swalkinshaw It was the same set of errors in the other Trellis box. I tried it with a box on Windows and it worked fine.\n@fullyint I see the error of my ways. I was thinking I had to enable it, but I see it\u2019s enabled by default for dev in group_vars/development/php.yml. With a fresh Trellis install, Xdebug works fine for development.\nI should have done a bit more research before opening this issue. Though something does seem to be breaking on macOS (still need someone else to confirm it's not just me), like @fullyint said, there isn\u2019t really a use case for this in development. I'll let one of you decide whether you want to close the issue or investigate further. Thanks for your help.. ",
    "abentley": "It would be really helpful if this message indicated where the includes were.. ",
    "87pancakes": "For reference, I've tried the following;\nvagrant reload & vagrant provision\nStill doesn't recognise the additional site.. Sorry, I don't understand why this was closed.\nI'd like to use trellis but if I'm unable to add additional sites and keep DB changes after the VM is created without destroying it and starting again, it doesn't work for what I need.\nHaving multiple VM's for each site is nonsensical. . ",
    "jedisct1": "\nyou need to disable DNSCrypt if you have that running\n\nWhy?. ",
    "artifex404": "Maybe adding a nicer error message mentioning DNSCrypt?\nI got an error message:\n\nFailed to connect to api.ipify.org at port 443: [Errno 8] nodename nor\nservname provided, or not known\nfatal: [101.37.64.228 -> localhost]: FAILED! => {\"changed\": false}. \n",
    "vesper8": "I too would love to see this merged in. I have just gone through 5 different Ansible Playbooks meant for Laravel in the past few days and have now found my way here. While it's tempting to use the package created by the author of this PR, and I thank him for the hard work he's put into both his package as well as this PR, I would much rather be tied to to Trellis simply because it's much more likely to be actively developed and contain the latest bug fixes / security fixes. It seems pretty straightforward to just use Trellis and make a few modifications to make it work with Laravel.. but having full support would definitely make this the # 1 playbook for Laravel/Ansible\nNow that 2.5 is out, and with the final 1.0 likely around the corner, I really hope this becomes a reality!. now that 1.0 has been officially released, it would be so lovely to finish this and add support for Laravel!\nI've been maintaining a fork for a while but it's incomplete and I would much prefer to use all the latest patches from 1.0\n@ptibbetts any chance you could verify if your PR still works against the latest 1.0?\nAlso, out of curiosity, did you go so far as to add other Laravel-specific things such as flags to set up Laravel Horizon with supervisor?. kudos to you @fullyint for the nicest, most detailed and sympathetic explanation of what might have gone wrong and why! seriously you should win an award for writing like this!\nI don't know what happened.. it might have been a coincidence in the end.. I was trying to figure out if letsencrypt has its own dns cache or something.. because the ping and dig commands could all confirm that the dns had already propagated but the letsencrypt kept failing\nperhaps it would be a nice addition to add a ping check prior to initiating the letsencrypt for a domain.. so that if the dns isn't yet pointing to the server, it skips it entirely?. ",
    "pajtai": "Looks like a vagrant plugin configuration issue. Resolved as follows:\n--- example.com/trellis \u00bb vagrant plugin list\nvagrant-bindfs (1.1.0)\nvagrant-exec (0.5.2)\nvagrant-hostmanager (1.8.7)\nvagrant-vbguest (0.15.1)\n--- example.com/trellis \u00bb vagrant plugin uninstall vagrant-vbguest\nNow vagrant up runs. Looks like it was looking for an older version.. ",
    "monkeywithacupcake": "I can't tell from the different sets of backers and one time sponsors that you have in the tiers on open collective if the groupings into backers and sponsors is reasonable for you. Please double check where people are aligned.. ",
    "drzraf": "I would like to deploy bedrock using my own Ansible playbooks (without Trellis).. Sure, I did. But using a role with ansible-container rather than a playbook, out-of-tree filter is something I'd prefer not to have in the long-run.. This works:\njinja\n- copy:\n    dest: \".env\"\n    content: |\n      {% for key, value in site_env %}\n          {{ key | upper }}='{{ value | string | replace(\"'\", \"\\'\") }}'\n      {% endfor %}\n. ",
    "straight-shoota": "You don't really need to ask here for adding something to ansible. Just suggest the feature there and if it gets included in ansible, the custom implementation can later be removed from trellis.. @dzraf it only works if no value contains an escaped \\'. ",
    "adleviton": "I found using Let's Encrypt with CloudFlare to be troublesome. Especially when it comes to the renewal process. I found it much easier to download CloudFlare's free SSL certificates, and set the Trellis SSL Provider to \"manual\", and it worked great.. ",
    "danielroe": "I can confirm with @partounian that adding a Page Rule matching *example.com/.well-known/acme-challenge* for which the Browser Integrity Check is set to Off makes LetsEncrypt certificate issuance work.. ",
    "newloong": "@swalkinshaw Yes, it doesn't work, both append .git extension and without .git extension. The URI of CodeCommit repo like:\nssh://Your-SSH-Key-ID@git-codecommit.us-east-2.amazonaws.com/v1/repos/MyDemoRepo\nSo we need to improve the regular expressions, see #975 . ",
    "davideprevosto": "Hi @fullyint,\nit seems you did the magic happens. It works:\nvagrant@blog:~$ sudo systemctl is-enabled nginx\nenabled. ",
    "chrisecostanza": "Thanks for the quick fix @fullyint!. ",
    "glopena": "Hi,\nI'm getting the trace below when running a production deployment.\nWhy is this running into the production deployment pipeline?\nTASK [sshd : Create a secure sshd_config] *****************\nSystem info:\n  Ansible 2.5.2; Darwin\n  Trellis at \"Add xdebug.remote_autostart to simplify xdebug sessions\"\n\nfailed to validate\n/root/.ansible/tmp/ansible-tmp-1525542800.36-18644436872727/source line 20:\nBad SSH2 mac spec 'hmac-sha2-512-etm@openssh.com,hmac-\nsha2-256-etm@openssh.com,hmac-\nripemd160-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-\nsha2-256,hmac-ripemd160'.\nfatal: [46.101.42.219]: FAILED! => {\"changed\": false, \"checksum\": \"b7d35e56697beb3eef26812f86f681f3e098045c\", \"exit_status\": 255, \"stderr_lines\": [\"/root/.ansible/tmp/ansible-tmp-1525542800.36-18644436872727/source line 20: Bad SSH2 mac spec 'hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-ripemd160-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,hmac-ripemd160'.\"], \"stdout\": \"\", \"stdout_lines\": []}\n. Thank you Phil.\nThat was exactly the issue.  Took me a few hours to figure it out on my own only to see I had your response awaiting to be read. Apologies for the rookie mistake. It's been a lot to take in.\nAgain, a huge thank you for your time and knowledge. Truly appreciated. ",
    "devotoare": "Huzzah!\nI missed that commit apparently. That fixes it. Thanks @swalkinshaw . ",
    "thewhipster": "Hi guys. I'm getting a deploy issue since commiting this. I made sure to uncomment the Clone project files task lines and that runs good until it tries to checkout to the temp directory. I've done a re-provision for good measure before deploy. SSH'ing in to the remote shows no temp folders created.\n`\nTASK [deploy : Install npm dependencies] *******************\ntask path: /Users/me/Documents/Workspace/Development/example/restage/trellis/deploy-hooks/build-before.yml:19\nUsing module file /usr/local/lib/python2.7/site-packages/ansible/modules/commands/command.py\n<67.205.132.199> ESTABLISH LOCAL CONNECTION FOR USER: adam\n<67.205.132.199> EXEC /bin/sh -c '/usr/bin/python && sleep 0'\nSystem info:\n  Ansible 2.4.2.0; Darwin\n  Trellis version (per changelog): \"build-before: Checkout project source code to local temporary directory\"\n\nMODULE FAILURE\nTraceback (most recent call last):\n  File \"/var/folders/c5/scvc3fbd2036wspzpfhg991r0000gn/T/ansible_xZC1YT/ansib\nle_module_command.py\", line 213, in \n    main()\n  File \"/var/folders/c5/scvc3fbd2036wspzpfhg991r0000gn/T/ansible_xZC1YT/ansib\nle_module_command.py\", line 152, in main\n    os.chdir(chdir)\nOSError: [Errno 2] No such file or directory: '/var/folders/c5/scvc3fbd2036ws\npzpfhg991r0000gn/T/trellis/example.com/staging/web/app/themes/sage'`. ",
    "davebowker": "Yeah, I'm getting a failure on this too. Been struggling with it for a couple of days now.\nEDIT: Opened up a discourse thread here for anyone else experiencing the same: https://discourse.roots.io/t/sage-9-deploy-error/12721\n`TASK [deploy : Install npm dependencies] *************\nSystem info:\n  Ansible 2.5.4; Darwin\n  Trellis version (per changelog): \"build-before: Checkout project source code to local temporary directory\"\n\nMODULE FAILURE\nTraceback (most recent call last):\n  File \"/var/folders/b3/qnqp7j4n331gy1gt089nbw6jcfypyr/T/ansible_fx8KGO/ansib\nle_module_command.py\", line 248, in \n    main()\n  File \"/var/folders/b3/qnqp7j4n331gy1gt089nbw6jcfypyr/T/ansible_fx8KGO/ansib\nle_module_command.py\", line 192, in main\n    os.chdir(chdir)\nOSError: [Errno 2] No such file or directory: '/var/folders/b3/qnqp7j4n331gy1\ngt089nbw6jcfypyr/T/trellis/muchness.co/production/web/app/themes/sage'\nAn exception occurred during task execution. To see the full traceback, use -vvv. The error was: OSError: [Errno 2] No such file or directory: '/var/folders/b3/qnqp7j4n331gy1gt089nbw6jcfypyr/T/trellis/muchness.co/production/web/app/themes/sage'\nfatal: [139.59.182.223]: FAILED! => {\"changed\": false, \"module_stdout\": \"\", \"rc\": 1}\n    to retry, use: --limit @/Users/debe/Sites/test/trellis/deploy.retry\n`. @swalkinshaw Thanks! I did a rebase(?) to update trellis, fixed all the conflicts with merging, tried again and it's good! :-). @TangRufus I have 2 folders/projects as I'm just experimenting with Roots, so I want to make sure something is actually wrong, and not me making mistakes, but...\nBoth are similar in structure. One I renamed the bedrock folder and the sage folder to custom names. One I kept it as 'site' and 'sage' so I could compare. Both have the same error. Since I updated trellis in the last hour to @swalkinshaw's revert, the 'site'/'sage' version I tested works perfectly.. ",
    "connerbw": "Thanks @nathanielks\n\ndo you have any tests to show remote autostart is indeed causing the issue\n\nHere's a page, reloaded 10 times to make sure caching is primed and yada yada, with xdebug.remote_autostart = 0\n\nTTFB: ~350 ms\nSame page, same server, same conditions, only config change is xdebug.remote_autostart = 1\n\nTTFB: ~1090 ms\nBest regards,\n. @nathanielks @swalkinshaw\n\nJust remember to add the following back whenever you want to debug:\n\nUhh OK?\nThis ticket was only supposed to be about: xdebug_remote_autostart: 1\nxdebug_remote_enable: 1 and xdebug_remote_connect_back: 1  were fine. \nSee previous comment.\nOh well.\n. Just got bitten by this today....\nhttps://roots.io/trellis/docs/windows/\n\nIf your host machine is running Windows, the workaround is to run Ansible on the VM (since it's running Ubuntu) and not locally. You do not need to install Ansible manually. When you run vagrant up, the Vagrantfile will detect Windows and run the ansible_local provisioner. This provisioner installs Ansible and the external Ansible roles/packages on the VM (so you can also skip manually running the ansible-galaxy install command).\n\nPer the docs. I don't have ansible installed Running anisble-galaxy, for me, in is non trivial.\n\nIf you're using npm, composer, etc, everyone is used to having to run them manually to pull in latest versions.\n\nIt's not the same? I think I ran ansible once in the last 3 months? I didn't even run it, it's just a side effect of vagrant --provision. I'm trying to understand the use case where this being slow matters. How many times is a dev supposed to run vagrant up --provision? And if this kind of slowness matters to them, then  why couldn't they switch vagrant_skip_galaxy: true in vagrant.default.yml  ?\n. ",
    "biinari": "Oops sorry, that was just meant for our fork. Doesn't need to be pushed upstream.. @swalkinshaw this needs to be set to nil when on a Windows platform without support for nfs to allow the vagrant driver to choose type automatically.. ",
    "roots-ladybug": "Hi @matgargano,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. Hi @vesper8,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. Hi @besrabasant,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. Hi @matgargano,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. Hi @aryaroudi,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. Hi @geekodour,\nIt looks like the issue template is missing from this issue. Please take a look at the Contribution Guidelines, which will tell you exactly what your ticket has to contain in order to be processable.\nPlease do not use the issue tracker for personal support requests (use the Roots Discourse to ask the Roots Community for help, or if you want the Roots Team to dedicate some time to your issue, we offer our services as well).. ",
    "adambrgmn": "Sorry for this, but I found out that this is already in the works (#985), even though it doesn't seem to be in master yet! Sorry for my bad research among the PR's \ud83d\ude2c\nAnd once again, thanks for your awesome works!. ",
    "stefanotorresi": "Maybe it's something worth fixing in upstream wp cli, because the way I see it now is that the is-installed command should not require such a hack in the first place.. @geekodour I don't think the presence of /srv/www/sitename/current is related to this particular issue I reported.\nTo get around the issue I described above, it is sufficient reverting to the usage of builtin define() function instead of the Config wrapper, at least for just the affected constants, i.e. MULTISITE and SUBDOMAIN_INSTALL. ",
    "geekodour": "@stefanotorresi how did you fix this?\nI am having the exact same issue, this fails at the point where /srv/www/sitename/current is not created it.\nI manually symlinked it  and did as mentioned in the  multisite docs.\nshell\n$ wp core multisite-install --title=\"site title\" --admin_user=\"username\" --admin_password=\"password\" --admin_email=\"you@example.com\"\nthen the site worked but the deploy script is still broken. How did #766 get merged when the process is still broken? #766 does solve one issue but creates another in my experience.. ",
    "ouun": "It took me a while to remember the existance of tmp_multisite_constants.php. After updating bedrock files to use \"roots/wp-config\" I faced the same issues ans was only able to go over that by using the default define() function for all the definitions listed in tmp_multisite_constants.php.\nI agree that this is quite confusing and it would be great to find a better solution for that.. No, thank you!. @swalkinshaw I'm not sure whether the following issue is related to the changes we did but I received the following error and didn't noticed that nginx is not running:\n```\nnginx.service - A high performance web server and a reverse proxy server\n   Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\n   Active: failed (Result: exit-code) since Tue 2019-01-08 16:31:24 UTC; 2min 4s ago\n     Docs: man:nginx(8)\n  Process: 4398 ExecStop=/sbin/start-stop-daemon --quiet --stop --retry QUIT/5 --pidfile /run/nginx.pid (code=exited, status=0/SUCCESS)\n  Process: 30426 ExecReload=/usr/sbin/nginx -g daemon on; master_process on; -s reload (code=exited, status=0/SUCCESS)\n  Process: 29348 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=0/SUCCESS)\n  Process: 6250 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=1/FAILURE)\n Main PID: 29352 (code=exited, status=0/SUCCESS)\nJan 08 16:31:24 stag1-www-ouun systemd[1]: Starting A high performance web server and a reverse proxy server...\nJan 08 16:31:24 stag1-www-ouun nginx[6250]: nginx: [emerg] SSL_CTX_use_PrivateKey_file(\"/etc/nginx/ssl/letsencrypt/dev.ouun.io.key\") failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)\nJan 08 16:31:24 stag1-www-ouun nginx[6250]: nginx: configuration file /etc/nginx/nginx.conf test failed\nJan 08 16:31:24 stag1-www-ouun systemd[1]: nginx.service: Control process exited, code=exited status=1\nJan 08 16:31:24 stag1-www-ouun systemd[1]: nginx.service: Failed with result 'exit-code'.\nJan 08 16:31:24 stag1-www-ouun systemd[1]: Failed to start A high performance web server and a reverse proxy server.\n```\n-- Unit nginx.service has begun starting up.\nJan 08 16:25:42 stag1-www-ouun nginx[4735]: nginx: [emerg] SSL_CTX_use_PrivateKey_file(\"/etc/nginx/ssl/letsencrypt/dev.ouun.io.key\") failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)\nJan 08 16:25:42 stag1-www-ouun nginx[4735]: nginx: configuration file /etc/nginx/nginx.conf test failed\nJan 08 16:25:42 stag1-www-ouun systemd[1]: nginx.service: Control process exited, code=exited status=1\nJan 08 16:25:42 stag1-www-ouun systemd[1]: nginx.service: Failed with result 'exit-code'.\nJan 08 16:25:42 stag1-www-ouun systemd[1]: Failed to start A high performance web server and a reverse proxy server.\n-- Subject: Unit nginx.service has failed\n-- Defined-By: systemd\n-- Support: http://www.ubuntu.com/support\n--\n-- Unit nginx.service has failed.\n--\n-- The result is RESULT.\nJan 08 16:25:47 stag1-www-ouun sshd[4757]: Unable to negotiate with 218.92.1.153 port 23962: no matching key exchange method found. Their offer: diffie-hellman-group14-sha1,diffie-hellman-group-exchange-sha1,diffie-hellman-group1-sha1 [preauth]\nThere was a mismatch (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch) and I am wondering if that could be related to my suggested changes.\nI'm very sorry that I'm coming up with so many issues, but they seem to be related somehow.\nBests. Thank you @swalkinshaw. That helps to come over the task \"connection\". However I'm not sue if this is related:\n```\nTASK [python_interpreter : Get Ubuntu release] **********************\nSystem info:\n  Ansible 2.7.5; Darwin\n  Trellis 1.0.0: December 27th, 2018\n\nFailed to connect to the host via ssh: philipp@116.203.1.137: Permission\ndenied (publickey).\nfatal: [xxx.xxx.xxx.xxx]: UNREACHABLE! => {\"changed\": false, \"unreachable\": true}\n```\nI now have problems with the deploy and I'm not sure why it connects with user \"philipp\" and not \"web\".\nHowever if I remove the block of Set ansible_python_interpreter from deploy.yml I do not face that issue as long as I keep gather_facts: false within the Deploy WP siteblock.\nBest,\nP. > \ud83e\udd14 oh I think these tasks need remote_user: \"{{ web_user }}\" set.\nAdding that returns:\n```\nTASK [python_interpreter : Get Ubuntu release] **********************\nSystem info:\n  Ansible 2.7.5; Darwin\n  Trellis 1.0.0: December 27th, 2018\n\nnon-zero return code\nShared connection to 116.203.1.137 closed.\nfatal: [xxx.xxx.xxx.xx]: FAILED! => {\"changed\": false, \"rc\": 1, \"stderr_lines\": [\"Shared connection to xxx.xxx.xxx.xx closed.\"], \"stdout\": \"sudo: a password is required\\r\\n\", \"stdout_lines\": [\"sudo: a password is required\"]}\n``\n. Looks good and seems to work fine at least as replacement forpython3. Not sure about the replacement forpython2as it is normally justpython`, isn't it?\n```suggestion\n!/usr/bin/env python{{ ansible_python_version[0] }}\n.suggestion\n    cmd = ('/usr/bin/env python{{ ansible_python_version[0] }} {{ acme_tiny_software_directory }}/acme_tiny.py '\n```. Here I'm also still facing an error:\nbundled_file.write(''.join([cert, intermediate_cert]))\", \"TypeError: sequence item 0: expected str instance, bytes found\"],\nhttps://stackoverflow.com/a/32071641 helped with the hint that the empty string ' ' should be defined as string via b' ':\nsuggestion\n            bundled_file.write(b''.join(b[cert, intermediate_cert])). OK, thanks for the feedback.. Let's keep it as python3 then. THX. ",
    "arusa": "As a new user of Trellis this problem is really annoying.\nFor the moment I would be happy if at least I knew how to do the workaround to be able to deploy successfully, but I don't know how to revert to the usage of define() because I don't know how this was managed before.. Finally I managed to deploy by commenting out two lines in trellis/roles/deploy/files/tmp_multisite_constants.php:\nerror_reporting(E_ALL & ~E_NOTICE);\n//define('MULTISITE', false);\n//define('SUBDOMAIN_INSTALL', false);\ndefine('WPMU_PLUGIN_DIR', null);\ndefine('WP_PLUGIN_DIR', null);\ndefine('WP_USE_THEMES', false);. Yes, everything else is like documented as far as I remember.\nEverything seems to work now, but commenting out the two lines was an act of desperation ;-)\napplication.php contains the following constants now:\nConfig::define('WP_ALLOW_MULTISITE', true);\nConfig::define('MULTISITE', true);\nConfig::define('SUBDOMAIN_INSTALL', true); // Set to true if using subdomains\nConfig::define('DOMAIN_CURRENT_SITE', env('DOMAIN_CURRENT_SITE'));\nConfig::define('PATH_CURRENT_SITE', env('PATH_CURRENT_SITE') ?: '/');\nConfig::define('SITE_ID_CURRENT_SITE', env('SITE_ID_CURRENT_SITE') ?: 1);\nConfig::define('BLOG_ID_CURRENT_SITE', env('BLOG_ID_CURRENT_SITE') ?: 1);\nand to be able to login to sites with different domains I also added the following:\nConfig::define('ADMIN_COOKIE_PATH', '/');\nConfig::define('COOKIE_DOMAIN', '');\nConfig::define('COOKIEPATH', '');\nConfig::define('SITECOOKIEPATH', '');. ",
    "Jensderond": "So the remote server now is 16.04 my local environment is 18.04.1. Just to confirm, once the first two files changes where added to my setup the provisioning worked again.. ",
    "kyleoliveiro": "Running into this error as well. Hotfix proposed by @Jensderond seems to work.. ",
    "designst": "I just replaced the apt-package python-software-properties with software-properties-common and it worked. So i don't think that you have to revert the whole changes.. ",
    "LeoColomb": "\nhalt using php 7.3 untill it is compatible\n\nWordPress is 100% compatible with php 7.3 without warning since v5.0 (in your case: https://github.com/WordPress/WordPress/commit/76ef0432c0ce8f560c9bf474fa52314697f7da68) and without notice since v5.0.2.\nAnyway this is nothing with Trellis.... ",
    "marko-bws": "I solved it by reverting back to php 7.2 - since this was a clean install (fresh server, fresh trellis clone) maybe it will appear again.... ",
    "aryaroudi": "Hi @swalkinshaw I asked the question in roots forum and true it was because of vagrant-faster and after uninstalling it, everything worked fine.. ",
    "phox4ever": "@swalkinshaw I realized that it probably needs a better solution than just updating the sec parameter. Best would be to provide an option to override the defaults. And it's missing a way to change the smb_host which is very handy if you are switching between LAN & Wi-Fi.\nAs a workaround I created my own Vagrantfile in the root folder of my project that expands trellis Vagrantfile, because trellis doesn't seem to support a local Vagrantfile. I've also switched to vers=3.0 because I occasionally get weird reading errors from the share in Wordpress, but I don't think this has fixed it though.\n````\ntrellis_vagrantfile = File.expand_path('../trellis/Vagrantfile', FILE)\nload trellis_vagrantfile if File.exists?(trellis_vagrantfile)\ndef mount_options_smb(dmode:, fmode:)\n    [\"vers=3.0\", \"mfsymlinks\", \"dir_mode=0#{dmode}\", \"file_mode=0#{fmode}\", \"sec=ntlmssp\"]\nend\ntrellis_config = Trellis::Config.new(root_path: ANSIBLE_PATH)\nvconfig = YAML.load_file(\"#{ANSIBLE_PATH}/vagrant.local.yml\")\nvagrant_mount_type = vconfig.fetch('vagrant_mount_type')\nVagrant.configure('2') do |config|\n  if vagrant_mount_type == 'smb'\nbin_path = File.join(ANSIBLE_PATH_ON_VM, 'bin')\n\nextra_options = {\n      smb_username: vconfig.fetch('vagrant_smb_username', 'vagrant'),\n      smb_password: vconfig.fetch('vagrant_smb_password', 'vagrant'),\n      smb_host: vconfig.fetch('vagrant_smb_host'),\n    }\n\ntrellis_config.wordpress_sites.each_pair do |name, site|\n   config.vm.synced_folder local_site_path(site), remote_site_path(name, site), owner: 'vagrant', group: 'www-data', mount_options: mount_options_smb(dmode: 776, fmode: 775), type: vagrant_mount_type, **extra_options\nend\n\nconfig.vm.synced_folder ANSIBLE_PATH, ANSIBLE_PATH_ON_VM, mount_options: mount_options_smb(dmode: 755, fmode: 644), type: vagrant_mount_type, **extra_options\nconfig.vm.synced_folder File.join(ANSIBLE_PATH, 'bin'), bin_path, mount_options: mount_options_smb(dmode: 755, fmode: 755), type: vagrant_mount_type, **extra_options\n\nend\nend\n````. ",
    "Log1x": "\nmight as well block twig files, too\n\nDone.. You're right, it should've been. Accidentally overlooked it and didn't catch it during testing due to the period matching any character.. ",
    "mvasin": "It will fail if ansible is >=2.0.2.0? That seems wrong for now.. "
}