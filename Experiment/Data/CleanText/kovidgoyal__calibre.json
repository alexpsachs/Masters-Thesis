{
    "kovidgoyal": "I tightened up the code a little when merging.\n. See L79, changed PDF is written to output.pdf, not input.pdf\n. You need to revert your previous commit for the pdf set_metadata() before I can merge this pull request.\n. I have committed a slightly different fix. Note that you can use the conversion framework to convert a document that is only a series of images (this is how the cbz/cbr conversion plugins work). You just need to set is_image_collection to True in the input plugin if you detect it is a collection of images and implement the get_images() method to return the images. \n. Sure, I like to take care of little details like that myself when I review a pull request :)\n. The source repository  glehmann:acrimed seems to have been deleted? Closing this pull request. If you deleted the source repo accidentally, please make a new pull request.\n. When I click the link you posted I get a Page Not Found error. Is you repository private?\n. I have merged this pull request, since it seems to be working now.\n. You seem to have forgotten to increment the store plugin numbers for dynamic update.\n. Wouldn't this be insanely expensive? If this column existed you'd essentially have to re-do every VL search every time any metadata changes. There are people that create VL's by the dozen.\nWhat's the use case for it?\n. Hmm, well given that it has no overhead (that I can see) if there is no such column, I am ok in principle. The only caveat is that this would have to be done on the new backend as well, I am finally getting close to finishing it. \nOne comment, does invalidating the VL cache actually require a full refresh()?\n. No, search results (of any kind, including VLs) are not cached. Neither is get_categories() data. However, the new backend keeps a normalised view in memory (essentially recreating the sql tables) which allows get_categories() to be much faster. \nNote that (IIRC) refresh() actually rereads data from for the disk, so it will likely be much slower (at least in the old backend, in the new backend refresh only discards non-table caches).\n. You would use a branch to separate commit sets, I've cherry picked the bug fix patch from this pull request, I'll review and merge it sometime later, when I have the time to integrate it into the new backend as well. You can create a clean pull request by doing something along the lines of:\ngit branch virt-lib upstream master\ngit checkout virt-lib\ngit merge master\ngit rebase\ngit push origin virt-lib\ngit checkout master\nThen close this pull request and create a new one from the virt-lib branch\n. I have implemented this for the new backend, a much cleaner implementation, see https://github.com/kovidgoyal/calibre/commit/cbf2bb0c4e58ad787d1a638fc48cc43bb515ac0f\nI haven't tested it, I leave that for you. It differs from this implementation, in that it does not use a function, instead directly allowing the use of {virtual_libraries} (I hope).\nI dont want to waste time reviewing/merging this into the odl backend, so I am closing this pull request. Feel free to followup by email if there are issues with my implementation :)\n. If you wish to test what happens when multiple db objects are created, simply do:\npython\nfrom calibre.library import db\ndb1 = db('/path/to/lib1')\ndb2 = db('/path2')\n. I have merged, making some changes to ensure things dont break while using olddb.\n. I have merged, changing the implementation to be faster and more robust.\n. I have merged, changing the config dialog UI.\n. Can you split this pull request up into separate ones, for each group of changes. i.e. one for the rtf stuff, one for bibtex and one for bulk metadata. \nA few comments:\n1) The empty strings in ENCODINGS are deliberate, to separate the common ones from the rest\n2) In metadata_bulk.py you should make the changes to both MyBlockingBusy and MyBlockingBusyNew so that it works with both old and new backend\n3) If you wish to be able to configure the trim amount, the best place would be in tweaks. Simply edit default_tweaks.py to add the setting.\nIf you need help with how to split up the commits, let me know. The basic idea is to create separate git branches for each group.\n. Because opts.input_encoding can be None\n. Some comments:\n1) You cannot specify % values to trim as far as I know, the Image.trim function accepts only numbers, the tweak help text should be ammended accordingly\n2) Export as jpg not png. set_cover() converts all non-jpg images to jpg anyway, so using png causes an unnecessary extra conversion. \n. See magick.c in the source code\n. http://www.imagemagick.org/api/magick-image.php#MagickTrimImage\n. The command line tool probably does some extra processing and is not directly equivalent to the API function. For example, a proper trim implementation should also detect borders without using the background color see MagickGetBorderColor However, I lacked the interest to implement a more full fledged algorithm.\n. Personally, I think this kind of thing should be implemented in its own window with various controls, like auto crop, border detect, crop by, select crop and resize. The window can be launched by a long click on the Trim cover button, just like the long click on the author to author sort arrow button.\nOf course, someone has to do the work to implement all those image editing functions.\n. Oh and I forgot, Undo.\n. I just committed a custom cover trimming algorithm that in my tests works much better than MagickTrimImage. Note that this required C code, so you will have to wait till the next release to try it (or build calibre from source). \n. You seem to have created the pull request from the wrong branch? All _ui.py files are auto-generated, so they are not in version control.\n. This pull request seems to have a lot of extra commits, can you clean it up?\n. It looks like your master branch has diverged from my master branch.\nI dont use the GitHub client software, but try the following command line to create clean branches from my master:\ngit remote add kovid https://github.com/kovidgoyal/calibre.git\ngit remote add me \ngit branch mybranch kovid/master\ngit checkout mybranch\ngit pull kovid master\nmake your changes\ngit commit\ngit push me mybranch (this will create the mybranch branch in GitHub)\nNow go to github web interface to create a pull request from mybranch.\nThe key idea is that you create branches from my master rather than your master. In the future you will need to do that everytime you want to cerate a pull request.\nAlternately, you can just delete your repo and re-create it on GitHub which should reset everything back (this is assuming your master does not actually contain anything that you want to keep). \nI could just cherrypick your commits, but then the same problem will happen everytime you submit a pull request, so lets fix it properly now. \n. The pull request looks good now. However, I am not convinced by the motivation for this change.\nIt can happen that some books I import have junk in their series metadata field so they all end up with the same wrong series name and incorrect series numbers. I then try to use the bulk metadata edit dialog to change the series for all those books. It will look like a rename, but it isn't actually, and in such a case I want the series numbers to change.\nIf you want to rename a series, you can always right click the series in the Tag Browser, and rename it, that will preserve series numbers. However, bulk metadata edit is the only way to change the series for a set of books, regardless of rename or not.\n. On Wed, Aug 21, 2013 at 06:51:32AM -0700, sengian wrote:\n\nI agree with you, that's why if the startnumber is given it will change the number.\nThe difference will be really if you add books to an existing serie.\n\nThe existing behavior should not change, as that will break people's\nworkflows. That means it has to be done via a new option/tweak.\n\nI prefer myself to use it as a rename as I don't find the tag editor so quick and easy to use.\nI could add another option to modify this behavior or a tweak maybe depending on how you like it.\nI didn't do it before as I prefered to avoid adding a button and the actual tweak 'no change' is not specific enough \n\nThere are four ways to rename a series currently:\n1) Use the manage series dialog via the tag browser (either right click\nthe series name or click the alter tag browser button below the tag\nbrowser\n2) Set the tweak to no change and use bulk metadata edit\n3) Use the metadata search and replace tab in the bulk edit dialog\n4) Sort by series, and then use the bulk metadata dialog, with auto re-number\nenabled and set the force numbering to start with to 1.\nIf you really feel the need to add yet another way to rename series\n(without sorting by series first), then it will have to be an extra\noption or tweak.\n. Closing this pull request -- no followup.\n. Is it necessary to do the same thing when removing formats by right clicking on the book details panel or with the remove books button?\n. Seems comprehensive, thanks.\n. Seems, comprehensive, thanks.\nKovid.\nOn Fri, Aug 23, 2013 at 08:05:54AM -0700, cbhaley wrote:\n\nNo. Tests I did:\n1) Delete format using edit metadata (single). No problem. Not a surprise..\n2) Delete formats using edit metadata (multiple), with and without the \"Refresh\" box checked. No problem.\n3) Delete format on book details. No problem\n4) Delete formats using the delete button -- delete specific format. No problem.\n5) Add format by dropping onto book details. No problem.\nI couldn't think of anywhere else to look.\nCharles\n\nOn 23/Aug/2013 16:08, Kovid Goyal notifications@github.com wrote:\nIs it necessary to do the same thing when removing formats by right clicking on the book details panel or with the remove books button?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/kovidgoyal/calibre/pull/68#issuecomment-23167405.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/kovidgoyal/calibre/pull/68#issuecomment-23169590\n!DSPAM:3,52178411281108772839759!\n\n\n\nDr. Kovid Goyal \nhttp://www.kovidgoyal.net\nhttp://calibre-ebook.com\n\n. There are a whole bunch of extra, unrelated commits in this pull request. This is likely because your master branch has diverged from mine. Can you generate a clean pull request, with only the changes you want merged in it. \nYou can reset your master to mine and then redo the changes (just copy out the single changed file and copy it back again after the reset making a new commit). Then create a new pull request with that new, single commit.\n. You reset your master like this\ngit reset --hard upstream/master\nNote that this will change your checkout of calibre to be exactly the same as mine, so you will lose any changes. \n. More info here: http://stackoverflow.com/questions/8134960/git-how-to-revert-master-branch-to-upstream\n. origin/master will reset it to your branch, not mine, so it will not\nhave any effect. What nickname do you use for my branch, if it is not\nupstream?\ngit remote -v\nwill show you all nicknames for remote branches.\nKovid.\nOn Sun, Sep 01, 2013 at 06:54:10AM -0700, GRiker wrote:\n\nPull request #73 posted.\nI actually needed to do:\ngit reset --hard origin/master\nThe other command was \"ambiguous\". :)\nG\nOn Sep 1, 2013, at 7:40 AM, Kovid Goyal notifications@github.com wrote:\n\nYou reset your master like this\ngit reset --hard upstream/master\nNote that this will change your checkout of calibre to be exactly the same as mine, so you will lose any changes.\n\u2014\nReply to this email directly or view it on GitHub.\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/kovidgoyal/calibre/pull/72#issuecomment-23625245\n!DSPAM:3,52234703281108039433640!\n\n\n\nDr. Kovid Goyal \nhttp://www.kovidgoyal.net\nhttp://calibre-ebook.com\n\n. I'm afraid this one still has the extra commits as well. For the moment, I've just taken the latest libimobiledevice.py from your repo and merged it. We can sort out the rest problem at our leisure.\n. This pull request still has lots of extraneous commits, so I've just taken libimobiledevice.py and merged it.\n. This pull request seems to be incomplete, did you forget to add some changes to the commit?\n. This is not going to merged. I have explained the reasons for not allowing non-ascii filenames on devices many times before. \n. Because I am not willing to shoulder the maintenance burden that will result from people turning on that option and then having files not appear on devices, or errors during send or character encoding issues in the filenames. Again, this is simply not going to happen.\n. I dont see the motivation for this. If you are worried about the security of your email account, simply create a dummy email account in gmail or hotmail or whatever and use it only for sending books by email from calibre. Much simpler than this and it works with automation as well. \n. No one if forcing you to use gmail, use whatever server you want. Hell set up your own smtp server. The point is to not use the same account as your main email account, thereby making the security implications of storing the email password, moot.\nIf you setup a dummy gmail account to send email then \na) google will not know who you are\nb) you will not be served ads based on whatever emails you send since google will have no idea who that dummy account belongs to\n. You appear to be completely missing the point. Again, \ncreate a dummy email account on your SMTP server, that you \nonly use for sending emails with calibre. So if that password is\nstolen, it does not matter, since that account is just a dummy account.\n. Any user is capable of creating a dummy email account, not just you. And\nsince that solution works with automation as well, it is preferable to\nnot storing passwords.\n. Sorry, but prompting for the same password on every calibre restart is not more user friendly than creating a dummy email account. And lazy or non security conscious people will just choose to store the password anyway rather than be prompted for it every time. So this proposal is at best security neutral. And it has a cost in UX confusion. \n. Sigh. Do I really need to spell out the obvious?\nMake that every time you send email after a calibre restart. You might only send email once in a blue moon, but there are plenty of users that use email for auto-delivery of periodicals, which means they send email pretty much every time calibre starts. \nAnd every option you add is one more option the user has to parse and understand, hence UX confusion.\nI am done commenting on this issue. \n. Sure, if I was a robot with nothing better to do that write polite responses to every person on the internet that wants to argue  with me, And note that posting comments on closed bug reports trying to change a busy project maintainer's mind on an issue is not contributing to a project, it is wasting time.\nAbout the only people I will take the time to argue with are people that have already contributed to calibre. That may seem unfair, but it is the only sane way to manage a project of this size. \nWhen contributing to a project, you have to be willing to accept that your ideas may not be aligned with those of the project maintainers. In that case, you need to just accept that and move on to something else or start your own project. \n. @AeroNotix  Don't let the door hit you on the way out. \n. Oops, serves me right for not looking at the diff's context :)\n. I have merged,making some changes:\n1) Mismatched composite columns are ignored\n2) Avoid loading the entire database just to check if the columns are the same.\nPlease review.\n. I also merged in the thumbnail quality changes. I bumped up the default quality to 75 as modern devices typically have higher res screens than the devices available when the old default was chosen.\n. The higher level API doesn't exist on the backend at all. Fortunately, the bits that are needed here (library_id, library_path,  field_metadata and create_custom_column) all exist. \nTo me, the purpose of this warning dialog is to prevent loss of book-level information by copying to a library where some columns are not present. A composite column contains no book level information, therefore it is ignored.\n. I'm ok with a default of 90. I suspect that the decrease in size is probably caused by removal of metadata exif info/comments and the like. Easily tested by repeating the process of the result from the first iteration. \n. Another option is to call pixmap_to_data with format='PNG' this will however cause the db backend to then perform a conversion to jpg with quality 90 via the save_corver_data_to function. I dont know if the end result is better that pixmap_to_data with jpeg@100\n. Hmm, well one option is to pass compression_quality=100 to save_cover_data_to in db/backend.py. This will not reprocess existing jpeg images and store all other formats like PNG with least artifacts. However, it is a bit of a performance killer since the file size blows up quite a bit. \n. Seems odd that decompression should be lossy.\nNote that setting the cover by browsing to the file avoids the roundtrip through Qt (IIRC). So there should be no need to directly manipulate the cover.jpg file.\n. I do seem to recall however, that compression of jpeg at q=100 is lossy. \n. This breaks rendering of a single icon, for me: See attached screen shots with and without this patch. Also rather than filling the pixmap, why not leave it transparent?\n\n\n. Much better, thanks :)\nSome more comments:\na) Might be good to have a couple of pixels gap between consecutive tiles\nb) Playing with this implementation a bit, it seems a little awkward to use when you want to assign icons as categories, for example:\nSuppose I want two have three possible icons displayed:\n1) A heart for books with rating > 4 stars\n2) A tick for books that have the tag read\n3) An emblem for books that are actually newspapers\nWith this patch as best as I can tell, I would need 3C3 + 3C2 + 3C1 = 8 exclusive rules to achieve this to cover the cases of books that meet all, any two and any one of these conditions. This scales very poorly with n = number of such categories.\nThe alternate implementation I talked about, of displaying icons from all matching rules would do this with a three rules only.  Of course, the case where you want to display n multiple icons for a given condition, would require n rules instead of one rule, which scales linearly with the number of icons.\n. Merged, I also changed the code to use ProxyMetadata, should be faster. If you see any problems with that, let me know.\n. As far as I can see, there should be no risks. All GUI stuff happens only in the main thread, so everything should remain well behaved. \n. I have changed the implementation to store the cache in the cache dir rather than the config dir.\n. I have committed code to only use the space when actual marked items exist. If you want to make the icon customizable, feel free to submit a new pull request for that. Though if you do so, I suggest changing the icon from the star to something else (I only used the star originally because I was lazy).\n. I decided to create my own icon for this -- a pushpin.\n. There appears to be an extra already merged commit for the ebookpint plugin in this pull request. Maybe you should generate the pull request directly from the amazon_ca branch.\n. Regarding the txt and pdf problem, I'd guess it is because those formats do not have metadata inside the files, so the original random filename is used. See the download_book() function in search/search.py\n. @user-none is the right person to comment on this,\n. Since @sengian maintains the bib output, he will have to sign off on this before I merge it.\n. I have merged, changing the strip function to not strip matched braces if both matched and unmatched braces are present.\n. merged, removing some unused names.\n. Dont use str() to convert QString, use unicode(). \nI cannot reproduce your problem. Apply, close, unapply, close, the tag remains in the available list when you next open. Make sure you are clicking apply on the notification that pops-up about the changed tags each time.\n. That's because available tags show all the tags in the database. When you unapply a tag that exists for only a single book, it is gone from the database.\n. This is not going to be merged, as I do not want the support headache that comes from allowing non-ascii filenames on devices. \n. I'm afraid not. If the option exists, people will use it, regardless of whether it defaults to off or not. And I will be left holding the support burden, which is not something I am willing to do. \nI suggest you find a device that reads metadata from inside PDF files. Or if you do want to use the Kindle, you could implement a PDF->AZW4 conversion, (AZW4 is just a simple wrapper around an embedded PDF file). The Kindle would then be able to read the emtadata from the azw4 file. \n. You're welcome :)\n. Some comments:\n1) What Kindle are you targeting. The different generations of the eink kindles have different browsers. You also probably want to exclude Fire's, since the normal content server view works fairly well on them. \n2) Kindles support more formats that just mobi and azw3 -- pdf, azw, azw4 and so on, see kindle/driver.py\n3) Rather than define a whole new module with lots of duplicated code, why not just specialize the markup returned by the existing mobile view if the browser identifies itself as a Kindle. \n. A general refactoring of the content server is on my TODO list, see http://www.mobileread.com/forums/showthread.php?t=219642\nAs part of that, the server will stop using server side html generation and instead use some kind of client side templating library along with the ajax endpoints in ajax.py. Hopefully, when this gets done, there will not need to be a mobile.py at all, and we can use a responsive/adaptive/whatever-the-current-buzzword is single design for all screen sizes.\nIn the meantime if you wish to make relatively small improvements to mobile.py, you are welcome to do so. \nRegarding 3) I dont see why it would be a lot more code. Can you elaborate?\n. There is nothing preventing a single view from hiding information depending on screen size. \nMy question about more code was why you think it is less code to create kindle.py rather than make mobile.py adapt its output based on user agent.\nthe server runs headless, always has. \n. The new server is more or less ready (currently it only has a cover grid view, but the views are modular so adding more views should be easy in the future)\ncalibre-debug --new-server\nto see it in action\nClosing this PR as it is no longer relevant. . You should put the set/restore cursor in an try: finally: block to ensure we dont get stuck with an override cursor. Also you could probably filter out the user input and socket notifier events when running process events, see QEventLoop::ProcessEventsFlags Though you will have to check if that still prevents windows from deciding that calibre has hung.\n. Setting the cursor ot the busy cursor implies the user must wait. Therefore, it makes sense to block user input.\nFiltering user input event shoudl not prevent the status line from being redrawn. \n. Merged using the BusyCursor class and removing a sleep (I could see no reason for the sleep to be there, if there is a reason, feel free to put it back). \n. I agree it makes sense for aspect ratio preservation and --wide to be separate, however, I'm not willing to change the meaning of an option that has existed for over five years. \nRegarding the output profile, if you need a specific size, use a precise size in the comic input conversion settings. I have stopped adding output profiles for every device, as there are now too many of them and modern devices tend to do a good job of resizing images themselves, so for most purposes it is best to just leave the images at original size using the Tablet profile. \n. 1. I have no problem with that\n2. I dont see the need for this. The only place image size is really important is comic processing and you can specify a custom size for that already. For everything else, just use the tablet profile and let the device do the image resizing.\n. You simply have to enter the size once, in Preferences->Input options and it will be used for all future conversions, so there is no looking up to do. That is actually more convenient than going through the bother of creating a custom output profile.\n. And I dont see how it defeat the purpose of --wide or --keep all specifying a custom size does is override comic_screen_size from the output profile with the specified size. So it is exactly like creating a custom profile.\n. You dnt need ot use a profile for this. You can specify an exact page size for the generated PDF under the PDF Output options. \nMy policy is to only create new device profiles if they are actually needed, as otherwise there would be too many, given the wide variety of screen sizes and resolutions available.\n. My judgement :) But basically, most profiles are from the early history of ebook reader devices when the devices were very poor at resizing images, and there calibre needed to do it for them.\n. Distorted images will typically have some markup int the HTML that causes them to be distorted like width=100% \n. I have implemented this, a little differently, making use of the syntax highlighter so that it handles nested tags robustly and is faster.\n. While I appreciate the enthusiasm, there are various problems that I can see after a quick look over the proposed icons\n1) The icon for bookmarks and ratings is the same, similarly for view book and search are the same and for series and toc \n2) The icon for scroll mode doesn't make much sense\n3) Various icons are not recognizable at the sizes theya re typically used in the UI: for example, network-server.png, series.png and news.png\n4) Some icons are used as application icons: such as tweak.png and view.png, converting them to flat style is not appropriate.\n5) the welcome-wizard.png image has to be the exact size and aspect ratio as the original (it is used in the installation wizard on windows).\nSacrificing color in order to rely only on shape is not a sensible tradeoff for a UI as complex and powerful as calibre's. I have no problem with improving consistency in the icons, but not at the expense of making them all monochrome. \nNot to mention that calibre allows the user to choose the colorscheme for the UI, which would make these icons completely unusable for people using a dark colorscheme.\nSo while I agree whole-heartedly that the calibre icon set could do with a lot of love, this is not quite there yet. \nIf you do want to contribute icons to calibre, here are some guidelines that I require the icons to follow:\n1) Do not use monochrome everywhere. You are welcome to \"flatten\" and simplify the icon shapes and remove 3d effects, but going the whole hog to monochrome is not appropriate in all contexts. Some icons can be monochrome, not all of them.\n2) Do not change the main application icons (the ones used for the viewer, calibre.exe, ebook-edit.exe and so on) These are part of how calibre is recognized by its users.\n3) Try to locate where in the UI a particular icon is used and see if the shape you are using is discernible in that location and size.\n4) I suggest you work on a few icons at a time, get my feedback and proceed step by step, that way you will not spend too much of your time working on something that might not be accepted. Start with the icons that can be placed into the main calibre toolbar. You can see them all by going to Preferences->Toolbars. Redesign them all to be a \"consistent\" theme. Note that they can also be placed into right click menus, so they have to be legible at small sizes as well. \n5) I would like to have the icons in svg format if possible, as that can serve as the master format if they need modification/tweaking in the future.\n. If you are making icons in the raster format (as bitmaps) then I prefer xcf but I can work with psd (I will convert them to xcf using gimp)\nIf you are making icons in the vector format, then I prefer SVG. \n. Note that if you are producing psd files, make sure they are using rgb colors and not cmyk as gimp does not support cmyk. \n. Another small tip: If you wish to modify an existing icon as opposed to re-creating from scratch, the source SVG files for most calibre icons are available in the imgsrc/ folder in the calibre source code.\n. I actually think calibre looks a lot more polished than iTunes, which I find to be an unuseable disaster, like most Apple software, but hey, each to their own. If you want to contribute, read the guidelines above and feel free to to submit new icons. \n. Take a moment to learn that the universe does not revolve around you. You dont like calibre's UI. You like Apple's UI. I like calibre's UI, I think Apple's UI is generally a joke. You are entitled to your opinion, I am entitled to mine. If you don't want to actually contribute, go waste somebody else's time with your opinions. \nAnd while you're about it write the following three thousand times on a blackboard:\nUI preferences are subjective, I will not assume that my opinion is shared by everybody else.\n. That you think design is not a subjective field tells me a lot about your competence as a designer. The idea that you can derive general principles about the interactions of systems as complex, and path dependent as a human beings and software interfaces, from correlation studies is utterly ridiculous.\nI suggest you step outside the \"designer\" bubble and learn a little about fields of human endeavor that are far less subjective, it might give you some much needed perspective.\nApproach your work with some humility, it will go a long way in improving your results.\n. I have pushed code to read all metadata from XMP, if available. No point doing things halfway. I have really looked into reading scientific paper identifiers, so you may need to add a little code for that. \n. Put it in consolidate_metadata(). basically there you will need to look through the \"normal\" metadata fields for any patterns that looklike ISBN/DOI/etc. and add those identifiers using mi.set_identifiers. But only add identifiers detected like that if they are not already detected by the XMP parsing code.\n. Not sure what you mean by the metadata parser is adding Unknown? In what context? You mean that if you run\nebook-meta file.pdf\nyou get a title of \"some title - Unknown\"?\n. I cannot replicate this, attach the pdf file that causes it.\n. I changed the implementation to be a little faster.\n. Yes, once you create a pull request from a particular branch, all future commits in the branch get added to the PR until the PR is merged.\n. If you want to change urls in the src for img tags and have the downloaded system process the changed URLs, you have to do it in \npreprocess_raw_html \nas that is what is called before link processing is done.\n. Ping me when you have done the changes, github does not notify me when commits are added to a Pull Request.\n. Works for me on editing in the book list or via edit metadata. book details is not updated via refresh_ids, but only if current_changed is called. See for example, L322 in edit_metadata.py\n. Ah you mean the popup window, not the panel. Fixed.\n. The reason for the date imports being moved into individual methods is that importing the dateutil module is very slow, so having it at the top level slows down worker process startup speed (device driver modules are always imported). So please move them back. If you want to only import them once import them in some initial method of the driver like open() and assign them to instance attributes. \n. It will be a little while before I have time to look at this.\n. It would be helpful to me if you could attach a docx file that contains Index entries. SO I can test with that and understand the code better. Ideally, it would be great if you could add sample index entries to the calibre docx demo file linked to here http://manual.calibre-ebook.com/conversion.html#convert-microsoft-word-documents\n. Thanks, I will play with it sometime this weekend.\n. I have merged your pull request into the index branch of my tree. I will do some cleanups and review the code in detail in that branch, and merge it into master when I am happy. \nWhere did you attach the docx file with the test index? It doesn't seem tohave made it to github. Could you email it to me directly. Thanks.\n. Some questions:\n1) Why have a separate option for this? I suggest that if the document contains an INDEX field, then you generate the INDEX at the location of the INDEX field, using some of the options for INDEX to format the generated index.\n2) I dont like the looks of the code you have for parsing the XE fields. You should instead use the infrastructure in docx.fields to parse the field. See for example parse_hyperlink() IIRC all DOCX fields have the same basic structure consisting of word and flag tokens. \n. Here is an IMO better parser for XE fields. It does not handle fields with multiple instructions as I need to see some examples of that. https://github.com/kovidgoyal/calibre/commit/4bede79eaefa7131e14ef42500f5385be371bfa6\n. I have merged into master, removing the option and temporarily disabling the generation of the index, pending a refactoring to use the new field parsing code and generate the index only where  the INDEX field is present. \n. I'll stop now until you send me the sample docx file. \n. It will be a few days before I can find the time to look at this.\n. The best solution is to simple create a new method add_custom_recipes and add all your recipes at once. Then you get only one call to get_custom_recipe_collection for each add of an OPML feed.\n. I have created such a method. https://github.com/kovidgoyal/calibre/commit/619792025666c9f5efcb6954adbad722be7a1d4d\n. Sorry, it's going to be a little while before I can get to this, I am completely swamped at the moment.\n. Can you split up the separate fixes into individual branches/pull requests. Other wise it makes it harder for me to merge, since I then have to review everything at once. Thanks.\n. Thanks, I will look at it in a few days as I am currently in the middle of building myself a new dev machine.\n. I'm somewhat confused. Opening the test document you sent me (Demo2.docx) in the calibre viewer (which runs the docx input plugin to get html to display) gives identical list output to Microsoft Word 2007. What are we trying to fix here?\n. Closing, as discussed by email.\n. calibre already has a full javascript based replacement for mechanize. See the  JavascriptRecipe class or the TIME magazine recipe for an example.\n. Do you still want me to merge this pull request or do you want to rtewrite it with JavascriptRecipe?\n. WHy are you doing xml_to_unicode(str(result))?\nThat is both unneccessary and can lead to errors is the system encoding is one that cannot handle all unicode characters present in the text. Since the result is already unicode, you just need to do this:\nfrom calibre.ebooks.chardet import strip_encoding_declarations\nhtml.fromstring(strip_encoding_declarations(result))\n. I have merged, making that change, please check that it still works.\n. @user-none This pull request appears to have all the commits, including the apnx ones. You probably forgot to create this branch from a point before the apnx code was committed.\nRegarding the problem of migrating the old setting, why not just leave the old setting in place, but hide the UI for it explicitly, and add a new setting. You can even add code to change the initialization of the new setting to use the old setting is the new setting is a special \"unset\" value. \n. I have merged, changing the implementation to migrate the old setting correctly and greatly simplify the handling of choice based options.\n. I dont really see this as a candidate for a tweak. You could add a control to change the font size to the dialog itself, there is space on the bottom right. Or add it to the context menu of the code editor. \n. Generally, calibre uses US English spellings for words. Catalog is the correct spelling in US English (see http://www.oxforddictionaries.com/words/british-and-american-spelling). As such do not change the strings. If you wish to fix 1262875 what you need to do is add a preference that allows the user to change the tag that is assigned to generated catalogs and then change the add_catalog() function in db/adding.py to use that preference. \nThe preference would need to be on the first tab of the create catalog dialog under catalog title\n. You really should discuss changes as large as this before starting work. \nFor one thing, you cannot have the server make changes to the database just like that. The server could be running in-process in the GUI or as a standalone. If it is in-process, then the GUI has to be updated when the user makes changes from the server interface and possibly vice-versa. And you'd need some inter-process locking semantics.\nSo at a minimum you'd need to setup IPC and notification to make this work. And you cannot remove the /ajax endpoints, since many third party apps depend on those. \nAlso, it is on my TODO list to redesign the server at which time it will likely become a single page app and also gain an in browser book reader. \n. Note that database.py is deprecated. The modern interface to the database lives in db/cache.py See the code layout section here: http://manual.calibre-ebook.com/develop.html#code-layout\nLeaving updates to conflict with the GUI will lead to data loss and is not acceptable to be merged into mainline calibre. You are of course welcome to continue maintaining your version of the server. \nYou can simply wait until I have time to work on this, then I will take care of the IPC and data integrity issues. At that time, you are welcome to contribute to the server frontend. Until then, I suggest you simply maintain your fork as the server code is very stable and will not change until I completely refactor it. \n. Thanks, but I'm afraid this recipe isn't appropriate for inclusion into calibre, since it integrates with an external tool and is meant to be run from the command line. \n. I'm somewhat confused. What's the use case for this function? Is it's output supposed to be parsed by other functions or displayed to the user. If the latter, then parseability of the separators is not important. If the former, then since parsing the output is non-trivial and requires a GPM function anyway, why cant that function just get the data from the metadata object itself?\n. Looks fine.\nJust FYI, the way I usually avoid urlencoding issues for internal APIs like this is to use hex encoding, simply hex encode the string you want to pass in decode it in the endpoint function. python's binascii.hexlify works well for this. Minimal effort, and fully robust. I suppose java has something equivalent.\n. I added the device_for_template parameter to ajax_books() as well.\n. hexlify always operates on bytes not on unicode and it is a trivial function to implement, one liner:\npython\ndef hexlify(x):\n    return b''.join(hex(ord(c))[2:] for c in x.encode('utf-8'))\nAll it does is encode the value of each individual byte as a two digit hex number. \n. I changed the if statement a little to make it more readable and faster, please check that it still does what you originally intended.\n. I made some minor changes to the code.\n. @rpspringuel Please rebase your branch on top of master as it seems to have picked up various unrelated commits from master. Something like this:\ngit checkout apnxfiles\ngit rebase upstream/master # you might need to change this depending on the alias you use for the calibre master branch\ngit push -f\nOnce you are done rebasing, dont pull any more commits from upstream into apnx files. \n. Generally speaking conflicting commits in master are very unlikely, but if you do wish to pull in commits from master, you do it via rebase, otherwise when your branch is merged, it will lead to messy history with the same commits being repeated twice, once from the original commit from master and once from the merged version in your branch. \n. I merged a slightly different fix, and yes I will be slipstreaming it.\n. I implemented a slightly modified version of this.\n. I am somewhat leery of having the calibre process hang around after quit for indeterminate amounts of time. Since calibre is a single instance app, if that thread hangs for any reason, or just takes a very long time, calibre will refuse to start again with no clue to the user as to what happened. \nI'm not sure  what the best solution is. The most user friendly one, would be to run a device job, calibre then automatically warns the user about existing jobs if she tries to quit. You can also make the cache update atomic by writing to a temp file and renaming it to the actual cache file once writing completes. See tweak_book/save.py for an example. \n. I'm not sure this is a good idea. Generally, speaking most fields in the book details panel are simply not shown if they have zero like values, for instance rating == 0 or no tags or no series. Is it actually useful to distinguish between zero and None for numeric custom columns? I note that there doesn't seem to be a way to clear a numeric field back to None after setting it once via the edit metadata dialog/book list edit widgets. It seems to me that if we are going to distinguish between None and 0 then there should be way to set either. Otherwise, there will just be a feature request for it in the future :)\n. I'm willing to merge, but there needs to be a better answer on how to clear the fields. Perhaps an entry in the right click menu to clear it. Should be easy to implement.\n. I added code for context menu entries to clear the spinboxes as well.\n. It's been a while since I looked at this code, so this is mostly of the top off my head, but it seems that  the least disruptive, would be to have user_categories_for_book() check if the field is composite itself, and if it is, call get_value_with_cache with a single PM instance common to all such calls, and otherwise use fast_field_for()\n. My logic for the above preventing recursion is that composite_getter() in db.lazy adds the current field into cache with a dummy value before calling the formatter, so it should not call user_cagtegories_for_books again, but I may be wrong.\n. I refactored your patch to:\n1) Make the API work for bulk retrieval of user categories\n2) Reduce the amount of changes in lazy.py \n3) Update the testsuite to reflect the fact that PM objects now return non-empty user_categories\nPlease check that everything still works.\n. Regarding (2) above, I agree that adding an extra param to all getters\nis faster for the case of getting user_categories, but it is slower for\ngetting all other attributes, and the latter is more common. It also\nmakes the patch footprint smaller.\nAlso, I'm not quite clear as to why constructing the PM object in\nuser_categories_for_books does not work. If that is indeed the case,\nthen the API should be changed to make proxy_metadata_map non-optional.\nEDIT: To expand on my confusion, if constructing the PM object in user_categories_for_books() does not work, it would imply that this sequence, works:\npm = db.get_proxy_metadata(book_id)\ndb.user_categories_for_books(book_id, pm)\nbut this one does not\ndb.user_categories_for_books(book_id)\nSince the first thing user_categories_for_books() does is construct the PM object, that doesn't make sense to me.\n. On Fri, Oct 24, 2014 at 11:14:35PM -0700, Charles Haley wrote:\n\nTwo issues here.\nFirst, constructing the PM object in user_categories_for_books(). This does not work because the caches are local to the PM instance. Consider the following sequence:\n- Formatter does mi._proxy_metadata.user_categories. This is using the PM instance embedded in the mi instance.\n- PM determines that the cache is empty for user_categories. It calls db.user_categories_for_books()\n- db.ucfb() must get the value for every custom column mentioned in a user category. Assume that the composite column being evaluated by the formatter is so mentioned.\n- db.ucfb creates a new instance of PM that has empty caches, then calls db.get_value_with_cache()\n- db.get_value_with_cache() invokes (eventually) the formatter, which invokes new_proxy_metadata.user_categories. The cache is empty, so the new_PM object recursively calls db.user_categories_for_books()\nInfinite recursion. There is no termination condition.\n\nThe part that confuses me, is how are these two calls different:\npm = db.get_proxy_metadata()\ndb.ucfb(pm)\nand\ndb.ucfb()\nThe latter constructs a new PM object at the start. So if the latter is\ngoing to recurse infinitely, the former must also recurse infinitely.\nIn other words, why does the use case of calling ucfb() from inside a\ntemplate formatter function not recurse infinitely.\n. Maybe I'm just being dense, but\nThe call chain involving the template function is\n1) pm = db.get_proxy_metadata()\n2) pm.get('#compositecol')  # where compsite call has the template {user_categories()}\n3) this calls pm.user_categories via some template evaluation calls that I wont trace here\n4) this calls db.user_categories_for_books() with the pm instance from (1)\nAt stage (4), the PM instance passed into ucfb() is exactly the same\nas one that would be created via a fresh call to db.get_proxy_metadata()\nTherefore, if instead, at this point no pm instance had been passed in,\nthere should be no problem. \nTo put it another way,\nThe template function has to pass in a PM instance, that much is clear.\nThe reason for it is that template functions can be called\nrecursively by each other.\nBut do other, non-recursive users of this API have to also pass in a PM\ninstance? If so, why? \n. In other words, can the following call ever lead to infinite recursion:\ndb.user_categories_for_books(book_id)\ngiven that the user_categories() template function is written so that it\npasses in a PM instance when it calls ucfb()\n. On Sat, Oct 25, 2014 at 12:42:30AM -0700, Charles Haley wrote:\n\nIt isn't true that the PM instance is exactly the same as a new one. Looking at pm.composite_getter() we see that the cache for the current pm instance is filled in with\n- cache[field] = 'RECURSIVE_COMPOSITE FIELD (Metadata) ' + field\n  and we also see that it passes itself (the current pm instance) to the formatter, meaning that the formatter will see the cached value. The next time that the column is evaluated, that text will be returned and db.user_categories_for_books() will not be called.\n\nThat I can buy, but if that is the explanation for why it does not\nrecurse, then wont it recurse even in the following case:\npm = db.proxy_metadata(book_id)\ndb.ucfb(book_id, pm)\nAnd that means this API effectively can only be used in a very special\ncircumstance, namely, when evaluating a composite column.\nAnd if that is the case, I dont think this API should be exposed in the\ncache object at all, as it is unsafe. Instead, it should be marked as\ninternal and used by the PM object.\nMakes sense?\n. Thinking about it, it cant even be used in the PM object, since\ndb.get_proxy_metadata(book_id).user_categories \ncan recurse infinitely. Some I guess it will have to be used only in the template function and the PM object will need to be changed back to returning an empty user_categories object. \n. Because, your explanation for why it does not recurse when called from the template function is that composite_getter() populates the cache\ndb.get_proxy_metadata(book_id).user_categories \nnever calls composite_getter\n. On Sat, Oct 25, 2014 at 01:07:51AM -0700, Charles Haley wrote:\n\nYes it does, assuming that the composite column is involved in the user category. field.get_value_with_cache() calls mi.get(colkey) which will call composite_getter.\n\nBut it does not call it at stage (4) of my function call trace above.\nAnyway, I think this discussion will be better served with an example\ndemonstrating infinite recursion, that way you wont have to convince me,\nI could just see for myself. Can you construct a metadata.db that\nrecurses infinitely when calling\ndb.ucfb(book_id)\n. On Sat, Oct 25, 2014 at 01:12:20AM -0700, Charles Haley wrote:\n\nThis program runs fine.\n\nAnd does\nfor id_ in cache.all_book_ids():\n    db.ucfb(id_)\nfail?\n. On Sat, Oct 25, 2014 at 01:33:29AM -0700, Charles Haley wrote:\n\nI have a metadata.db that fails if ucfb() creates a new PM instance instead of using the one passed in as an argument. I don't see a way to attach files here so I will email it separately.\n\nThat will help, thanks. That will allow me to investigate the cause an\ndecide the best place for the API accordingly, without pestering you :)\n. Oh and note,  my claim is that db.ucfb(book_id) will not recurse infintely. Not that db.ucfb(book_id, pm) will not recurse infinitely even if ucfb() ignores pm. I agree that the latter will recurse infinitely. \n. On Sat, Oct 25, 2014 at 01:42:32AM -0700, Charles Haley wrote:\n\nHow are the two different? If pm is not passed as an argument then ucfb must create an instance. If ucfb ignores the argument then it must create an instance.\n\nBecause, in one case subsequent calls to ucfb() from evaluating the\ntemplate all use the passed in PM, in the other case they do not.\nWith the metadata.db you sent me, I see no infinite recursions with the\nfollowing:\ncalibre-debug -c \"from calibre.library import db; db = db('/t').new_api; import pprint; pprint.pprint(db.user_categories_for_books(db.all_book_ids()))\"\nThis is with the code from my master branch.\nIf I change ucfb() to ignore proxy_metadata_map, I get an infinite\nrecursion.\nTherefore, I conclude that proxy_metadata_map can indeed be optional.\n. On Sat, Oct 25, 2014 at 01:52:24AM -0700, Charles Haley wrote:\n\nRe your latest comment: I think we are in agreement. \n\nSo are you OK with the code as is in master, or is there anything you\nwould like to see changed?\n. If you run \ncalibre-debug -c \"from calibre.db.lazy import getters; print getters.keys()\"\nyou will see that there are getters for almost all standard metadata fields, that means that moving the test for user_categories out of SIMPLE_GET will not buy you anything significant, since SIMPLE_GET is rarely reached. Moving the test for user_categories after the custom column test will likely buy some performance improvement. But note that, SIMPLE_GET should not be modified, since it is used in getattribute of the normal Metadata object, instead you'd need to create a copy with user_categories removed for ProxyMetadata.\n. Dont worry, I haven't forgotten. I will get to it when I can. Reviewing\nthese changes requires time and peace, as they impact fairly\nfundamental stuff :)\n. The change to get_categories makes me nervous. In particular, get_composite_categories calls get_value_with_cache with the passed in get_metadata function. But the ProxyMetadata object also calls get_value_with_cache via composite_for. Are we sure there is no recursion lurking there, in particular if one of the user categories is based on a composite column?\nThe changes to search.py look ok, though I dont want to increase the cache size. Using Virtual libraries as a tagging system is not a use case I want to encourage. I'm fine with increasing the limit to 50, but 100 seems excessive. \n. I'd rather not add another caching layer. The PM objects already take advantage of the global caches in db.fields (for the composite columns) and I dont think caching non-template vaules is worth the increase in complexity another caching layer brings. \nAs for the question at hand, I'm not saying that it will definitely recurse, just that it makes me nervous :) Let me spen a little more time thinking about it. In the meantime, if you want you can push the changes to search.py and I will merge them. \n. The global cache I was referring to is the per field _render_cache in fields.py. \n. True, it doesn't use the global cache. But thinking about it, it should not be using the global cache. A Metadata object, whether PM or regular is supposed to be a snapshot of the book's metadata. Using the global cache would mean that the value from mi.get() could change from invocation to invocation. \nThe PM objects already somewhat violate that contract, since the get() metadata does not return the metadata at the time the PM object was created, but at the time get() was called. Making it use the global cache would make that violation much worse. \n. Sounds ok to me. \n. Actually, there is a wrinkle with that. The Metadata objects have their own formatters, that could in theory be different from the formatter used by the db layer, I think that's why I originally designed it this way.\n. Sure if no one has done mi.formatters = something_else before calling mi.get() the formatter will be the standard SafeFormat. I think I am willing to live with that risk, since as far as I know, nothing does that and I dont think it is particularly likely. I've pushed a tentative implementation, see what you think.\n. I have marked the render APIs as internal. I'd rather not add\nanti-recursion guards smply to protect against future abuse of the API.\nThis API is pretty internal already and now marked clearly as being not\nfor general use. Adding a preventive guard would be overkill (and have\nsome performance cost, IMO).\n. I think I am OK with the change to get_categories now. I have\nimplemented it, but with an additional local PM object cache. This\nshould help performance a little bit and adds no significant API\ncomplexity.\n. Cool :)\n. @user-none You OK with this pull request to adda  new store to GetBooks?\n. This is by design, to make it clear to the user that a new question is being asked. Otherwise, if the successive dialogs are very similar, the user might think that nothing happened when they clicked the button, for example for two successive metadata downloaded notifications.\n. Ah, sorry, I misunderstood what you were saying.\n. I'm not particularly happy with this idea. Can you tell me a little more about the use case. What information are you trying to display in the notification popup, and why can that information not be better displayed in a separate dialog accessed by clicking the view log button on the popup, for instance. \nThe motivation behind the redesign of the popup is to not interrupt the user, making the popup minimal in size is part of that goal. \n. What are the performance implications of this. It seems like reset_only was an optimization. \n. But doesn't refresh_ondevice() in library.models do a resort and a research as well? For a few thousand books that likely wont matter, but it might for larger collections.\nIf the issue you are trying to solve is the on device column not being cleared on disconnect, then I suggest keeping reset_only, and emitting the dataChanged signal for the the on device cells before returning, so that the GUI is updated.\n. Also note that doing a resort/research can cause changes to the presented list of books, for instance if new books have been added since the last resort() (newly added books are always shown at the top). This would mean a behavior change on device disconnect.\n. Did you change the wrong reset_only? I'm guessing you meant to change the call in device_detected() not books_deleted(). \n. Also, my original objection remains. If you do change reset_only in device_detected() then the book list will be sorted there as well as after metadata downloads. It seems like one of those sorts is a waste. \n. Here's the diff I get when I try to merge your pull request\n```\ndiff --git a/src/calibre/gui2/device.py b/src/calibre/gui2/device.py\nindex b1381f3eaa..1dfd83bb95 100644\n--- a/src/calibre/gui2/device.py\n+++ b/src/calibre/gui2/device.py\n@@ -1079,6 +1079,10 @@ class DeviceMixin(object):  # {{{\n             self.location_manager.update_devices()\n             self.bars_manager.update_bars()\n             self.library_view.set_device_connected(self.device_connected)\n+            # Empty any device view information\n+            self.memory_view.set_database([])\n+            self.card_a_view.set_database([])\n+            self.card_b_view.set_database([])\n             self.refresh_ondevice()\n         device_signals.device_connection_changed.emit(connected)\n@@ -1183,7 +1187,7 @@ class DeviceMixin(object):  # {{{\n             self.upload_booklists(job)\n         # We need to reset the ondevice flags in the library. Use a big hammer,\n         # so we don't need to worry about whether some succeeded or not.\n-        self.refresh_ondevice(reset_only=False)\n+        self.refresh_ondevice()\n     try:\n         if not self.current_view().currentIndex().isValid():\n\n```\nThe only changed call site of refresh_ondevice() is in books_deleted. Which is fine, since as you say reset_only-=False is the default. But you are missing the change to the call in device_detected()\n. While I dont know anything about libimobiledevice, a couple of points:\n1) There is a potential infinite loop if afc_file_read returns bytes_read = 0, probably you should check that and terminate if it happens\n2) Shouldn't there be a similar change to afc_file_write, to ensure all bytes are written? \n. I have merged this (I rebased it because of the extra merge commit in your pull request).\n. I changed the API slightly to make it clear that it is a read_only_property (just so that future device driver writers are not tempted to write to it). \n. Some comments:\n1) You should store this in <cache_dir> not <config_dir> (since this is not config info)\n from calibre.constants import cache_dir\n2) Dont make _feed_hashes a class level variable, instead initialize it in __init__ Making it a class attr means recipe writers might modify it, which is not desired. \n3) _encode_fs_name/recipe_dir/get_feed_hash should be utility functions at module level in feeds/__init__.py There is no point in making them overridable by recipe writers.\n4) Article.fingerprint should use caching so that repeated attribute access does not have to compute the hash every time\n5) You might need to modify jsnews.py so that ignore_downloaded_articles works with the JavascriptRecipe class as well.\n6) I'm not comfortable with the scheme for mapping feed titles to filenames. \na) Feeds can be untitled, which means they have a default title, so you will get collisions\nb) There are various problems with filenames across platforms. The biggest one being that if a feed title + recipe title is very long, the filename might become too long on windows, especially since the cache or config directories are typically in a path whose length depends on the user account name. \nRegarding (6a), I think it is better to simply store all articles hashes regardless of what feed they come from, per recipe, in a single set, article_hashes. \nAs for (6b), I'm not sure what the best solution is. Possibly using sha1sum(recipe.title) as the file name. Or more robust, use a uuid and write a .json file mapping recipe titles to uuids in the recipe cache dir. If you choose this, remember to use file locking to protect access to the json file since multiple recipes can be downloaded simultaneously. You can get a file locking class from calibre.utils.lock\n7) In lines 1206/1207 I think you forgot to use the % formatting operator.\n. Actually now that I think of it, since it is theoretically possible (although unlikely) for the user to download the same recipe more than once at the same time (say using the command line). You should probably lock access to the cache file used to store article hashes as well. \n. Regarding (6a), if you do want to store them per feed, so as to allow the same article to be in multiple feeds, then the solution is probably to store a dictionary of {feed_title:set_of_article_hashes} in a single per-recipe cache file using the cPickle module.\n. no followup. This will not work if the person running the recipe is in a different time zone than the server. Instead you should use datetime.utcnow() + datetime.timedelta(hours=whatever the offset is for germany)\nOf course, if germany uses daylight savings time, then it gets more complicated.\n. This pull request does not merge cleanly, can you please resolve the conflicts. You can do that by merging in the master branch and making your changes on top of that.\n. Looks fine to me. A couple of suggestions:\n1) Have the quickview shortcut key toggle the panel visbility when it is embedded\n2) Have the quickview window auto close and re-open itself when using the \"Show as pane: checkbox, and make it a button instead of a check box. \n. On Sun, Feb 01, 2015 at 12:24:32AM -0800, Charles Haley wrote:\n\nOK for the button instead of the checkbox.\nAs for the QV shortcut, right now it either opens the pane/window or moves the focus to QV's booklist. I did this because of users like BetterRed who want to avoid the mouse at almost all costs. Couple this with ESC moving the focus to the main library view and it becomes easy to switch back and forth. I think this behavior is important, but I am open for alternate implementations.\n\nFunny, it was the same impulse that prompted my comment. Right now there\nis no way to close the QV panel without using the mouse :)\nPerhaps an additional shortcut, say Shift-Q to focus?\n\nWhile speaking of focus, I am worried about the accelerators on the checkbox and buttons. When QV is docked the main calibre shortcut mechanism comes into play, meaning it is easy to overload an accelerator. I am thinking of removing all accelerators when docked, instead making TAB and SHIFT-TAB move between them. Do you have any thoughts on this?\n\nGood point, there should indeed be no accelerators in a widget displayed\nas part of the main window, otherwise the widget will break existing\nusers keyboard shortcuts.\nDont TAB/SHITF_TAB already move between controls?\n. On Sun, Feb 01, 2015 at 12:40:32AM -0800, Charles Haley wrote:\n\n\nPerhaps an additional shortcut, say Shift-Q to focus?\n\nHow do I add additional shortcuts? Do I make a new action, or can I have a second shortcut in an existing action. As far as I can tell from looking at the code, I will need to make another action.\n\nYou can assign multiple shortcuts to an action, use a tuple, like this:\naction_spec = (..., ('Q', 'Shift+Q'))\nIn the action handling code, you then check QApplcation.modifiers() to see\nif shift is pressed and if so...\n\n\nDont TAB/SHITF_TAB already move between controls?\n\nYes, between all the controls on calibre's window. I want to 'trap' the tab key when the focus is in the QV pane, preventing TAB from moving out of the pane.\n\nHmm, I'm somewhat ambivalent on that. On one hand, it would break\ntabbing through the controls in the window, on the other hand, you\ncan't really tab through the controls anyway, since, the book list also\ntraps the tab key.\n. Make that Shift+Q\n. You can simply, parse the shortcuts assigned to the action with QKeySequence. Then check which one keyboardModifiers() matches. The only way that would break is if the user chose to use two different primary keys for the shortcut and the alternate shortcut.\nHowever, I am fine with using a second action. It's less fragile. I was just answering your question of whether one could assign multiple shortcuts :)\n. You dont need to create calibre level actions, instead in the genesis() method of the original QuickView action, just create a new QAction and register it, like this\npython\nself.focus_action = QAction(self.gui)\nself.gui.addAction(self.focus_action)\nself.gui.keyboard.register_shortcut(...) # see keyboard.py for how to use register_shortcut\n. Merged, with a few small fixes. Regarding focus highlighting, you mean you want to highlight the current cell that has focus in the table view? For that you would have to implement a custom delegate for the qheaderview and use setProperty('highlight_current_item', 150) on the table view.\n. Dont worry, semi-colons are harmless. I have an automated tool that runs every time I save a file in my editor that nukes them for me, anyway. \n. Wouldn't it be better to just add a function to the calibre poppler bindings to list the images in a PDF? That should have similar performance to pdfimages and avoid needing an extra binary. See podofo/doc.cpp. Or are you saying that poppler is much faster than podofo for this task?\n. Here you go: https://github.com/kovidgoyal/calibre/commit/bf152707b305359f69638f2c572cbba981077cff\n. I agree that it is nice to have the edges aligned, and that should be the case when there is enough space to the right, but when there is not, I prefer to use all available space.\n. I have merged. One thing I noticed is that when editing a yes/no type column, the editor now appears to the side of the existing column decoration, whereas it used to cover it before. Is that deliberate, or did you just forget to handle that case? I think I prefer the old behavior, as having two possibly conflicting icons next to each other is confusing.\n. FYI, I have tested the new code on both linux and OS X (not fully, only a couple of delegate types) it seems to work ok. \n. The \"correct\" way to handle this situation is to use the ngettext function, like this, \nngettext('{0} [{1} book]', '{0} [{1} books]', count).format(...)\nThis is needed for languages that can have different plural forms for 1,2,3 and many\n. I have merged this PR, but i missed the last commit, which I implemented myself, in a slightly different fashion. \n. All the other formats have at least some metadata stored, so to be consistent I added the title to TXT. Its only a few bytes. With even a collection of ten thousand books, the required storage would be ~ 300KB. Also note that title is written only if it is not unknown, so in your use case which was adding from the add empty books dialog, it wont be written. \n. There is already such an option, in the Preferences->Miscellaneous section of the viewer. It prevents the viewer from remembering last read position/bookmarks. \n. Then you should make an actual option for the viewer in the Preferences->Miscellaneous section that controls that behavior. Not an env var. Something like \"When vieweing EPUB files, store bookmarks in the file\" and default it to True. \n. Yes, that is correct.\n. And note that your patch is insufficient. You also have to deal with reading bookmarks. Think about what happens if the user uses the option to turn off in file bookmarks, but opens an epub file with an previously created calibre_bookmarks.txt\n. Instructions for setting up a calibre development environment are here: http://manual.calibre-ebook.com/develop.html\n. You dont need to build calibre from source, simply setup the development environment and run calibre, your changes will be picked up automatically.\n. I have committed an implementation of this, see above. It will be merged into master in a day or two. Feel free to post if you have any comments. \n. It is off by default because there is no way to reliably map URLs/hrefs to their canonical form. That bit of functionality will need to be implemented and tested in each individual recipe. \n. And incidentally you do not need to build calibre to run it from source, simply clone the source and set a single env var. http://manual.calibre-ebook.com/develop.html\n. I implemented a different solution for two reasons:\n1) Your approach resulted in icons that were much larger than before with the default settings (where there is considerable padding between rows). I dont know if this a good or bad thing, but people would notice and probably complain\n2) I'm not wild about calling build_data_convertors in set_row_height. Of course this can be trivially fixed by just changing build_data_convertors to not use a local reference to the icons, which is onlya  slight performance penalty.\n. I just added this recipe based on your post on mobileread, since I saw that first. In the future, just use Pull Requests, that way you will get \"credit\" for them on github. \n. No, I'm afraid not, that would create churn in the calibre commit history. Think of it as motivation to write another recipe :)\n. ALso just a note for the future, the recipe file naming convention in calibre is all lowercase with underscrores. So your recipe file should have been named mit_technology_reciew.recipe\n. Make some small improvement to the recipe, for example, adding extra_css to improve formatting and create a new pull request for it, I will be happy to merge that.\n. Your pull request conflicts with current master. Rebase your branch on master and then create the pull request. Something like\ngit fetch upstream/master\ngit rebase upstream/master\ngit push -f\n. Just reset your branch to master. Then copy over the changed recipe and make a new commit.\ngit reset --hard origin/HEAD\ncp changed.recipe recipes/mit_technology_review.recipe\ngit commit -am \"whatever\"\ngit push -f\nIf the first step does not work, you can either fix whatever problems it reports or simpler, just create a new fork.\n. Nope, you can check if you have resolved all conflicts by visiting the github page of the pull request. If it shows that the pull request can be automatically merged, you are good. At this point, I suggest you simply close this pull request, delete your fork, create a new fork and a new pull request. That way you will be starting from a clean base. \n. Dont read github tutorials, read git tutorials. You dont actually need to delete the fork and start over. You can recover using git commands, however, there is no canned solution for that, because the actions you need to take depend on the actions you took to get into this state. I dont have the time to handhold you through that, so I suggest deleting the fork and starting over. \n. Congratulations! :)\n. Merged. I have not looked at it, but it should not be too hard to have the tag editor optionally preserve order.\n. I usually use drag and drop for that, easier to implement and easier to use as well :)\n. Is there a reason for using SingleSelectionMode when enabling drag and drop?\n. That's because the .ui file sets selection mode to multiselect, I changed it back to extended select and it should be fine. Also the list setup code was not being run if the intialvalue of the field is empty, which, I think, is incorrect.\n. I'm happy to add the recipe for the blog itself, but archive style recipes are not suitable as builtin recipes. Also please add __author__ = 'your name' to the recipe.\n. It's harder to parse YYYY-mm-dd date format for humans. Don't rely on the date format to organize your library, use the date column, that's why it exists :)\n. It's simple, the the purpose of a date is two-fold. To enable sorting and to label an epoch. Humans mostly use dates for labelling. And the vast majority of humans do not  think of months and days in terms of numbers, so representing dates as numbers causes extra overhead for parsing them in humans. \nIf you need to mangle titles for limited functionality devices, use the metadata plugboards functionality, that's what it is there for. \n. It is customizable, you can customize it by customizing the recipe and adding your own timefmt to the customized version.\n. See http://manual.calibre-ebook.com/news.html\ninstead of creating a new recipe from scratch, simply use the \"Customize builtin recipe\" button in the dialog.\n. Hmm, db schema changes make me nervous. Shouldn't that be DROP TRIGGER IF EXISTS, just in case there are dbs out there where people have removed the trigger?\nAlso, while I haven't looked at the code to be sure, I have a vague memory that calibre calculates series sort based on the current language of the book. I know that is the case for title sort for certain, not sure for series sort. \n. I cherry picked the last commit so as to avoid having the various extra commits this pull request picked up. So you will likely need to rebase on master. \n. I am happy to merge some of those changes (the first two commits). But the latter two are likely to be controversial, and as such, you should get them signed off by the original recipe author. (https://bitbucket.org/khromov/calibre-instapaper)\n. I'm OK with changing the Find button to use a configurable shortcut. Mixing translated and configurable shortcuts in the same UI is not a good idea anyway. \n. You should probably have Shift+F2 clear the contents of any cell before editing it, not just date cells. Otherwise, sooner or later someone will open a bug report requesting that :)\n. Sorry, got you second message too late.\n. You should not use modifiers() == Qt.Ctrl_Modifier because on some platforms, modifiers might include other flags like a numlock, special keys, etc. in which case it will never match. Instead check int(modifiers() & Qt.Ctrl_Modifier)\n. uuid_id() already prepends with a u. See line 103 of oeb/base.py\n. The name for the calibre icon should be calibre-gui not calibre. This is the name used by the calibre binary installer when installing icons into the (default) hicolor theme. Also since icon themes are a  linux only thing, that code should be conditional \n``` py\nfrom calibre.constants import isosx, iswindows\nif not (iswindows or isosx):\n   ....\n```\n. It means I dont have to spend time making sure that it will work on those platforms. \n. My first, probably stupid, idea is, why not sort the top level nodes of\nthe tree after building the tree. It should not be a big performace hit,\nsince there are a relatively small number of top level nodes.\nI think one would have to be a little careful with handling\nhierarchical user categories, since IIRC they are sorted also\nby the initial sort?\nKovid.\nOn Fri, Nov 20, 2015 at 07:13:01AM -0800, Charles Haley wrote:\n\n\u2026Most of the complexity comes from the default node order putting search after the categories.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/kovidgoyal/calibre/pull/447\n-- Commit Summary --\n- Fix tag order tweak so that user categories are always at the end. Most of the complexity comes from the default node order putting search after the categories.\n-- File Changes --\nM src/calibre/gui2/tag_browser/model.py (21)\n-- Patch Links --\nhttps://github.com/kovidgoyal/calibre/pull/447.patch\nhttps://github.com/kovidgoyal/calibre/pull/447.diff\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/kovidgoyal/calibre/pull/447\n\n\n\nDr. Kovid Goyal \nhttp://www.kovidgoyal.net\nhttp://calibre-ebook.com\n\n. Another, perhaps easier, one is to change the loop at line 593 to iterate over nodes in a custom order instead of the sorted order (i.e. something like this, in pseudo code)\npy\nlast = []\nfor category in self.category_nodes:\n    if category.is_user_category:\n        last.append(category)\n    else:\n        process_one_node(category)\nfor uc in last:\n    process_one_node(uc)\n. Also, unrelated to this particular issue, currently the categories are sorted by the order in which they appear in field metadata, (modulo the tweak) should that perhaps be changed to be alphabetic? This would be a fairly noticeable behavior change, however. \n. Before I merge this, I'd like to understand process_one_node() a little better. In case you missed my email in the kerfuffle:\nI've been trying to follow process_one_node() in detail and I dont see\nwhere user categories reference nodes created in previous categories.\nprocess_one_node() seems to unconditionally call create_node() for all\ncategories, user or otherwise. The only thing that looks conditional is category_child_map and that is local to process_one_node(). What am I missing?\n. I've merged, but while playing around with it, I noticed that\nwhile hierarchical items in normal user categories do indeed show up as\nhierarchical, those in user categories created from grouped search terms\ndo not. Is there some reason for that?\nOn Sat, Nov 21, 2015 at 06:12:36AM -0800, Charles Haley wrote:\n\nAdding reusing the intermediate (generated) node data was easy.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/kovidgoyal/calibre/pull/448#issuecomment-158645385\n\n\n\nDr. Kovid Goyal \nhttp://www.kovidgoyal.net\nhttp://calibre-ebook.com\n\n. I've merged, your counting changes exposed a bug in\nget_categories() https://github.com/kovidgoyal/calibre/commit/6eb304c3be2a0b298a42c804eee5a26add6b71fe\nI'm not sure why your changes should have caused the reported counts of\nratings to change...but whatever :)\nKovid.\nOn Mon, Nov 23, 2015 at 07:23:36AM -0800, Charles Haley wrote:\n\n4 commits.\nIt turned out that to get the counts right I had to do something like you did with average rating.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/kovidgoyal/calibre/pull/449\n-- Commit Summary --\n- Fix GSTs to show the source categories of the items consolidated into the name, and to correct the average rating during consolidation\n- Only put a node into intermediate_nodes if it is involved in a hierarchy\n- Cache the computed average rating\n- Fix counting items. The old way misstated the counts for user categories because it was using the cumulative id_set from the original category.\n-- File Changes --\nM src/calibre/db/categories.py (27)\nM src/calibre/gui2/tag_browser/model.py (41)\n-- Patch Links --\nhttps://github.com/kovidgoyal/calibre/pull/449.patch\nhttps://github.com/kovidgoyal/calibre/pull/449.diff\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/kovidgoyal/calibre/pull/449\n\n\n\nDr. Kovid Goyal \nhttp://www.kovidgoyal.net\nhttp://calibre-ebook.com\n\n. The content server is currently in the process of being redesigned. \nRun the new server like this:\ncalibre-debug --new-server /path/to/calibre/library\nYou are welcome to contribute to the new server's code/design. \nWith regard to your design, the new server has support for multiple, responsive renderings of the book list -- currently I have only implemented a cover grid, but other views will be fairly easy to implement in the future. \nAlso note that the current server has a dedicated mobile view you can access via /mobile that is fairly useable on small screens.\n. It is deliberate and is not going to change. It comes from calibre's roots as a command line utility. \n. I'm somewhat confused by this pull request. What are you trying to achieve? You want labels to be the second column in the book details panel when the calibre user inteface language is a RTL langugae like Hebrew? \nThe correct way to do that is to change the the mi_to_html() function to generate the table with the desired layout when passed a parameter rtl=True.\nYou can detect when to set rtl=True by checking the value of get_lang() from calibre.utils.localization. You would need to chech for both hebrew and arabic language codes. \n. See https://github.com/kovidgoyal/calibre/commit/c33017583e4ac0663405276efd0f66b255af340c\n. You call QApplication::setLayoutDirection() However I would not recommend doing that, as it has very radical effects that are likely to break many things.\n. See #467\n. Changing the entire html data to right to left unconditionally is not correct. There is no guarantee that the text being displayed is actually right to left. The rest of the book details panel display metadata from the book, which could be in any language. You need to add that code to the HTML in the individual book comment to have it display RTL if appropriate.\n. If you want it aligned right then add the align right to the table not the overall html. Adding it to the overall html will also affect the comments, whose language is not known. \n. @media\\s.*?[{;] will need the dotall flag. And @media\\s[^{]*?[{;] will fail for empty media rules, for example it will match\n@media all;  @media screen {\n. There are a couple of problems with this:\n1) There needs to be some indication to the user that something is happening. Set the busy cursor and output some text in the log area saying, Sending mail, please wait...\n2) You have to handle the case that the dialog is closed while the thread is running. You might be lucky and nothing bad will happen, but if one of the Qt objects involved int he signal/slot interaction is deleted, you may get an unhandled exception. So better to override the reject() method of the dialog and prevent the dialog from closing while the test thread is working.\n. I modernized that dialog, which takes care of the ui blocking as well.\n. I'm afraid I dont like this change. It imposes a fair bit of work on calibre for no benefit to calibre itself. While I am generally willing to accommodate the needs of third party programs, I draw the line at changes that impose significant costs on core calibre.\nAlso, the idea of storing ephemeral data in the database just smells wrong to me. It increases database size, it makes backups slower/more resource intensive and there is no guarantee that the value stored at backup time is the correct value/current value, since backup is a async process. It is true that one could use the dirty table to check integrity, but that is not guaranteed to actually work -- for example if a composite column uses data from outside the db -- library name or existence of format files on the file system, etc.\nFinally making changes in the guts of the db layer requires fairly intensive review/testing -- I am particularly concerned about the changes in db.write. I am not sure that there is no code anywhere that relies on custom columns not touching the db even when set() is called.\n. Causes a random crash for me on linux with this traceback:\nTraceback (most recent call last):\n  File \"/home/kovid/work/calibre/src/calibre/gui2/cover_flow.py\", line 391, in cover_flow_do_sync\n    if (self.is_cover_browser_visible() and self.cf_last_updated_at is not None and time.time() - self.cf_last_updated_at > 0.5):\n  File \"/home/kovid/work/calibre/src/calibre/gui2/cover_flow.py\", line 365, in is_cover_browser_visible\n    return not self.cb_splitter.is_side_index_hidden\n  File \"/home/kovid/work/calibre/src/calibre/gui2/widgets.py\", line 1023, in is_side_index_hidden\n    sizes = list(self.sizes())\nRuntimeError: wrapped C/C++ object of type LibraryWidget has been deleted\nThinking about it, I dont mind changing the plugin semantics from run on close to run on backup of book. The plugin can store the composite field data in its external location, on every backup. That imposes no overhead for people who dont install the plugin and for people that do, it does not pollute the metadata.db. It also does not involve major changes to core calibre code. And it gets rid of the shutdown complications. \nI apologise for the run around, I should have thought of this before you did all the shutdown message work. \n. I'm ok with keeping it at shutdown. But I'd really rather not have it stored in metadata.db. At some point I plan to implement support for remote libraries in calibre. That will involve syncing metadata.db over the network -- unnecessary (from calibre perspective) data in there is not something I want to encourage.\nI suggest not showing the close notification at all if no shutdown plugins exist, that will minimize the impact if there remain crash possibilities. \n. Does not crash for me. Some notes:\n1) The minimum required version should be 2.54.0 not 2.0.0 after all, before that calibre release the plugins will not run, even if they are installed\n2) In db.cache.close() use except Exception: rather than except: \n3) if available_library_closed_plugins(): should be if tuple(available_library_closed_plugins()): or better create a dedicated has_library_shutdown_plugins() method in customize.ui that does not incur the performance cost of initializing the plugins. \nThe content server delay is indeed annoying -- it no longer exists in the new server :)\n. While I dont know anything about freebsd, I suspect that whether you have to lookup the parents paths or the device's paths varies per device. So it might be better if the code looked at the union of the paths from the device and those from the parent. \n. Since the wireless driver is currently the only consumer of set_library_info() I'd prefer changing the signature of that method even though it is backwards incompatible. IMO, the small risk of breaking a third party driver is outweighed by the benefits of not complicating the API. \n. I suggest waiting on removing it until you have decided whether you want to refactor to work without jsbrowser. Otherwise it will cause confusion if it disappears from some calibre releases and the re-appears. \n. I refactored the plugin to no longer use Qt WebKit. Take a look.\n. Hmm, I'm not entirely convinced by this. It breaks the documented behavior of parse_date() which states that default is assumed to be the current date. While I dont know if any code actually relies on that behavior, I'd rather avoid changing it, if possible. As an alternative, you could change the template functions to use parse_only_date() when the string being parsed contains only date information. However, I dont know if it is possible to do that. If not, then change the docstring of parse() to match the new behavior and I will merge. \n. After investigating, I decided to implement your fix. I could get the error to happen by setting day=31 in default and parsing the date '2016-04'. So presumably, dateutil does not fix invalid values in the default, at all. \n. I'm actually OK with just having that dialog remember its size always. \n. One size for all. \n. If you want to use potentially separate names, then I suggest modifying your original patch to have a fallback unique name if the unique name specified by the caller is None. Something like\nself.unique_name = unique_name or 'view-log-dialog'\n. Sorry, fixed.\n. The reason they are there is because in the past they were different. Deleting one means that people that have subscribed to it will have their subscriptions stop working on calibre update. Which is why they are not merged.\n. Please add the changes to both economist recipes.\n. In order to make this accurate you have to handle the case where more than one chapter is present in a single HTML file. See how it is done in viewer/toc.py (that allows the ToC to mark the section being currently read in bold). \n. Just open any epub file in the calibre book editor and right click all the individual files and select merge.\n. See anchor_positions() in indexing.coffee for how that value is\nobtained.\n. That implementation seems rather inefficient. Since the viewer is already iterating over the anchors and fetching their geometry once, in anchor_positions() in indexing.coffee -- why do it again? Especially since computing geometry is a very expensive operation (it causes a re-layout if the render tree is dirty). \nself.anchor_positions in documentview.py already contains a mapping of anchor names to positions -- use that. Note that in paged mode the first position is a column number not a x offset. So, in paged mode you can convert that into a fraction by dividing it by the total number of columns rather than the body width. \n. See page_dimensions in documentview.py\nNote that you probably need page_width rather than col_width as number of columns is document.body.scrollWidth / page_width\n. You have to make the code mode dependant -- in paged mode you use scrollWidth and page_width in flow mode you have to use scrollHeight (maybe you already handle that -- wasn't clear from just looking at the last commit). Also you should store scrollWidth only at the end of after_load() not in update_contents_size_for_paged_mode() as in can change until then. \n. You can change the gui_name but not the name variable (as the latter is used for device configuration). \n. Assuming the char encoding of the separator character is latin1 is probably wrong. More appropriate would be mbcs -- however, I just committed a function that gets the thousands_sep and decimal_point characters as unicode objects with no need to guess at encodings. You should probably use that in your patch -- more robust.\n. I went ahead an implemented a atof() based on my code -- please test it on your windows system\n. You might want to have the config dialog remember its size or at least have a larger default size.\n. IIRC, the default config dialog is simple enough that I never bothered implementing size storing for it. You'd need to implement it in there. No harm having it for all device config dialog types.\n. I'm afraid I'm an not going to merge this as it has performance implications for every calibre user to support a use case that is not actually supported. \n. Sure, a patch that has no negative side effects is acceptable. But, be aware that this is an extremely critical code path, so the bar for demonstrating that a patch has n negative side-effects is very high. \n. FYI, there is a calibre test suite, that you can run to check your patch for regressions, \npython setup.py test --test-module db\n. Or if you are running using CALIBRE_DEVELOP_FROM, the tests can be run as\ncalibre-debug -c \"from calibre.db.tests.main import *; run_tests(find_tests)\"\n. Let me note that on any filesystem that is not broken calibre is 100% data safe. There is nothing in the code base that is either fragile or that can cause data corruption, on a well behaved filesystem. \nNetwork filesystems are broken. Putting lipstick on that pig is not going to change its pucker. Filesystem semantics and network semantics simply do not fit together well.\nAnd note that calibre 3.0 is just around the corner which contains a rewritten content server that will be read/write (though the write part will not be turned on immediately for calibre 3.0) so you can stop relying on networked filesystems for syncing calibre libraries. Your efforts would be better spent contributing to that, rather than trying to make network filesystems work.\nHaving said all that, I'll re-iterate that I wont refuse a patch that has no negative side-effects on the standard use case but does improve the NFS use case. . I have pushed a commit to use & for authors\n. It is already merged. GitHub probably didn't pick up that it is merged because I rebased it to get rid of all those extra commits.\n. I implemented it slightly differently (i found show_on_left to be rather confusing). Also, the server logic was incorrect (the comments are pre-processed to always be HTML unless they are of type short-text). Finally, I removed the auto change of the checkboxes in the preferences dialog.\n. (1) Sounds good. make show_heading one of: 'above', 'side', and 'hide' and get rid of show_on_left\n(2) No not necessary, just easier in the original implementation. I have no problems with having show_heading gain exclusive control of heading position. \n(3) I'm ok with having the server also pre-process short-text, but thinking about it for both short and long text we should probably not use <pre>, but instead <pre style=\"white-space:pre-wrap\"> for long text and just a <span> for short-text. The idea being that we want line wrapping since book details can be displayed in fairly narrow spaces. \nGo ahead, and make the changes. \n. Looks fine, but you should add anote about it in edit.rst, otherwise no on will know it exists. \n. Its restructured text. THe format used for python's documentation.\n. I made a small change in how the value of ignore_collections_names is tested so that it does not blow up for None\n. Do you know when this firmware/devices with thi firmware will become generally available?\n. Incidentally, I am going to be travelling this weekend, so I am making this week's release tomorrow. If you have anything else you want included in the release, you have ~10 hrs left :)\n. Yes poppler >= 0.47 changed the output from pdfinfo in a non-backwards comaptible way, sigh.\n. Where are they loaded? If they are laoded in the db layer I see no problem with moving unloading intot he db layer as well. \n. gui2.save is used for save to disk, presumably the functions from the current db are passed to that code. I am OK with doing the close in backend.py\n. I have merged your commit manually (this pull request had merge conflicts, so I could not merge it directly).\n. Cool, thanks. It is likely though that some of the recipes will in general need more work than just replacing feeds. News websites often change their markup. And recipes that do not use auto_cleanup will likely need adjustment.\n. IMO, code to remove old cover images should not have the side-effect of also removing imgs with invalid URLs in the src attribute. SO I pushed a slightly different fix for this.\n. You're welcome :)\n. upstream html5lib is not suitable for calibre\n. This PR is breaking setup.py check on travis. https://travis-ci.org/kovidgoyal/calibre/jobs/181298343\nProbably you need to do from distutils.spawm import find_executable (as is done in build_environment.py. Closing this as both the pot and check commands are meant to be run only by me as part of releasing calibre -- so there is no real need to make them more general. . The calibre.library module is obsolete the db part is replaced by calibre.db and the server part by calibre.srv. It only exists because it is used by the tests in calibre.db to test for regressions against the old db API. As such, it's own test shoud not be run, in fact you can delete calibre.library.test instead of running it.. You'll need to install mock explicitly in .travis.yml (and probably appveyor.yml as well) otherwise the CI builds will fail. If I were you, I'd just add the bits of mock that you actually use to the calibre testing infrastructure, but it's up to you which approach you prefer. I'm OK with depedning on mock for the test suite.. I dont think you can (currently appveyor is only enabled on the vs2015 branch and I dont think PRs to branches are built). Dont worry about it, I'll take care of it. . Does it actually work? and if so could you add a couple of books to test it with at the bottom of the file, like there are for all the others.. No, those are for get books, not for metadata download. Series parsing happens in parse_series in amazon.py, you probably just need to adjust it a bit to handle whatever variation of markup amazon.ca uses.. It's fine to not have series information if the site does not have it. Many of the country specific sites dont have series info. . calibre has its own fork of html5lib (see src/html5lib), dont use the upstream version for it -- there is an issue in the html5lib bug tracker detailing the reasons for the fork. . Note that setting base font size in conversion_options is not a good idea as it makes it impossible for the user to override. If you need to rescale the font sizes, use extra_css instead. . load(qt_plugin) is needed for Qt < 5.8 it loads the qt_plugin.prf file without which the linker tries to look for main()\nI dont know if it is needed for Qt 5.8 or not since the Qt build system changed a lot for 5.8. Unfortunately, I dont currently have the time to setup a Qt 5.8 env to work on this.. Cool. The headless plugin is tested by test_qt() in test_build.py which you can run as follows:\npython setup.py test --test-name qt\n. Thanks, I was actually wondering what replaced load(qt_plugin) for Qt 5.8. For the locking you should try the default version, it might work on haiku. IIRC linux uses abstract network sockets which are not widely available outside of linux land. The default version uses fcntl file locking, I'd be surprised if haiku does not support that. . This PR is causing the building of calibre to fail, see https://travis-ci.org/kovidgoyal/calibre/jobs/195599049\npresumably one of the commits changed something in the way pkg-config is searched for. . Those are not needed. Basically you only need brackets if you are combing different boolean operators like and/or/not in one expression.. There are actually two nytimes recipes, nytimes.recipe and nytimes_sub.recipe, the changes should be made to both.. Again should be made to nytimes_sub.recipe as well. I have merged this, but I have a couple of questions:\n1) How are non-sideloaded kfx books still detected?\n2) Since you removed delete_single_book are non-sideloaded kfx books still deleted?. OK thanks.. On my system that results in message-ids of the form\n'148781614594.22889.14281208660896828881@localhost.localdomain'\nI would not be surprised if spam filters purposely reject mails with message-id domains of localhost. Might be better to replace it with a fake domain in that case. Something like\npy\nre.sub(r'@localhost[^>]+', '@{}.com'.format(random_string_of_ascii_letters), msg_id). Actually, rather than a random string, probably better to use the calibre installation uuid, like this\npy\nfrom calibre.utils.config_base import prefs\nhostname = prefs['installation_uuid'].replace('-', '')\nThat way it will stay the same for all emails sent from that calibre installation. . Another option is to use the domain specified in from_. UUID@from domain sounds fine to me. Just be careful when parsing out the from domain, IIRC that can be  of the form \"user name\"  or just address or anything really. So good to have a fallback for when parsing fails to UUID@installation_id.com. Maybe use https://docs.python.org/2/library/email.util.html#email.utils.getaddresses to get more robust extraction of domain embedded in from_?. The whole reason that I went to the trouble of creating my own system tray icon implementation for linux is because the Qt system tray icon implementation was buggy -- it would lead to missing or hidden or non-functional tray icons or crashes in various circumstances. https://bugreports.qt.io/browse/QTBUG-31762 or https://bugreports.qt.io/browse/QTBUG-55922 or many others, google QSystemTrayIcon and qtbug. Yes. Though there are plenty of light linux desktops that support statusnotifier. For example, I use one myself, qtlie. . You dont need a dev env to test recipes, see https://manual.calibre-ebook.com/news.html. Sorry make that https://manual.calibre-ebook.com/news.html#tips-for-developing-new-recipes. No need to revert since it wasn't working in the first place, no great loss. Just submit a new PR whenever you are ready.. If you want to specialize the handling of get_feeds in your recipe simply override it. The rest of the new download system relies on that method raising NotImplementedError when no feeds are available. . Hmm I'm somewhat sceptical about changing the default link from a public resource like wikipedia to a corporate website like Goodreads. What's the motivation for the change? Does goodreads have much more author information than wikipedia?. Yeah and if someday amazon goes under or decides to monetise goodreads, or decides that maintaing it is no longer profitable all that data will disappear. I am pretty scpetical of the longevity of commercially backed data.\nStill I am not adamantly opposed to changing the default template -- as for trying it out there is no need to run from source for that, simply change the tempate in Preferences->Look & Feel ->Book details. \nIn my experience wikipedia covers over 80% of the authors I read -- perhaps I dont read sufficiently obscure authors :). 1. The purpose of wikipedia is not too maximize its profits, neither is that the purpose of calibre. That is however, the purpose of Amazon (as it is of every publicly traded company)\n\nAs I said I am not adamantly opposed to changing the default, I just need more evidence that one is actually better than the other. I will check them out over the next few days and decide if making the change is worthwhile.\n\nRegarding my longevity concern, it is not a big deal in this context, since if goodreads does go under, the default can always be changed back.. I dont like the idea of compressing news images unconditionally in recipes. As time passes, screens become higher resolution. So having higher resolution images in the source is a good thing. About the only legitimate use for post-download image compression I can think of, is amazon's arbitrary file size limits for emailing books. Given that emailing news files also destroys periodical formatting, I am not particularly sympathetic to this use case. . What nonsense, the Kindle can handle 60MB files perfectly well. Just send it using a USB connection. . Who uses email delivery -- its a horrible feature that is limited in size, accepts only old style mobi files, causes periodical formatting to be destroyed, forces all books to show up as personal documents instead of books and fails randomly because of amazons spam controls. \nYou want wireless delivery use the content server the kindle browser can download mobi files from it just fine. . You seem to be confused. I have told you why I dont like the idea of forcing everyone to use lower quality images to accomodate amazon's brokenness, in the very first post. You are responding with telling me that it's amazon's fault. I know that already. Once again,\nI dont want to make all calibre users suffer for something that is amazon's fault. \nAnd there is no \"setup\" for a content server. It's a single button to click in calibre. . What I am willing to do is turn on the compression conditionally if the output profile is set to a kindle profile. . Dont worry, I'll take care of it :). It remains because removing it will break automated news download for people who have subscribed to that recipe in the past.. Since they produce identical output, it would be more misleading to change their titles, since if you name one (Free) and not the other, it would lead people to expect that the other is not free -- which is currently not true. . No, I dont. I have explained why above. . There's a whole bunch of other amazon plugins you should make similar changes to. See the parse_language() function in sources/amazon.py \nAlso I thing the language field should contain cacnonicalized langauge names whereever possible, so that the displayed language is the same from all stores. See the get_langauge() and canonicalize_lang() functions in localization.py\nThe plugins should return ISO lang codes and the GUI should display them as localized language names. . You should not need to maintain your own mapping of german to english language names, it should be there already, see langnames_to_langcodes() in localization.py\nUnless of course, libri.de uses different langnames than the ones in the german translation of calibre. . Though I suppose if you want it to work with non-german calibre, you have to maintain your own mapping. So feel free to ignore my previous comment :). Unfortunately, you cannot re-use code in that fashion for the amazon plugins. The reason is that store plugins are auto-updated and reloaded dynamically (to keep up with changes to websites). That means they cannot depend on each other. So you'd have to duplicate the code across all amazon plugins -- it's annoying, but.... I merged it with a slight change to simplify the set_global_state() function. vs2015 is periodically rebased on master -- I think the rebasing process nukes merge commits, something I forgot about. https://stackoverflow.com/questions/15915430/what-exactly-does-gits-rebase-preserve-merges-do-and-why\nI've recreated the changes as their own commit.\nThis pull request appears to be causing lots of test failures, see for instance, https://travis-ci.org/kovidgoyal/calibre/jobs/232732775. Dont you also need to bump the max firmware version?. The SVG assets are source files and should not be optimized (they are not included in calibre binary distributions). The PNG files are already optimized by optipng in the script that is used to generate them from the SVG files. See imgsrc/generate.py\nIf you can make a separate pull request for the changes in the recipes folder, then I'll be happy to merge that. . As I said, the svgs are not included in binary calibre releases.. I dont understand the point of this. Simply set the max split size to zero and you will never get split errors. IMO when splitting is enabled it is better to fail at conversion time rather than create a file that may not work on the reader device.. If it fails with max split size set to zero then it is a bug and should be fixed. If you can create a reproducer and open a bug report, I will fix it. \nI dont think simply ignoring split faliures is a good idea, as having overlarge files in the EPUB can cause the EPUB to not work on the device and it is very hard to know why a device is failing to open a file, since they typically have no error messages. One of the goals of calibre conversion is to get to a file that will work on as many devices as possible, automatically. . Conversion options should not be serialized with recipes. They are applied in the recipe input plugin, see line 122 recipe_input.py\nThey are read from the instantiated recipe class that is actually used to do the downloading, not from a static cache. . @cbhaley I've merged, but given that there are three buttons does there also need to be a dropdown? You could have a tick mark on the current value button, or a simple label showing the current value.. I should actually use button_order int he layout menu as well, I just used sort when it was a vertical menu, since then it made more sense, but I forgot to revert that when converting it to a horizontal menu. Dont replace the use of the classes() function. That matches elements that have more than one class also, unlike using attrs={'class':[]}.\nALso I am fine with including an option to turn of what's news, but it has to default to on. It is always better to have extra content than less content by default. And that section was included at user request. . Wouldn't it be easier to just connect to the changed() signal of the QAction and update the tooltip?. I pushed a patch using the changed signal, I haven't actually tested it though. Couple of preliminary comments:\n1) It is now my policy to insist on having SVG versions of all icons (see the imgsrc directory). PNG icons are generated from them using imgsrc/generate.py\n2) At least in wide layout, the layout button should probably be to the right of the cover grid, the rationale being that QV shows up in the cetral panel just like the cover grid and cover browser. You should probably also update the quickview section in the user manual (gui.rst) since it seems to be a little out-of-date. No idea, why this code is from time immemorial :). No, that's all that needs to be done, the rest is handles automatically.. You have to also increment the \nstore_version\nat the top of each plugin. No, changing the filename for the desktop file is fairly disruptive and not worth the cost. . I'm not aware of any other software that could call itself an e-book viewer on linux with a straight face. There are various bits of software that have varying levels of buggy support for EPUB, but that's about it. And since calibre has had an e-book viewer for over a decade, I think it is up to any such software to distinguish itself from calibre. . What's the motivation for this? . Sorry, I've injured my wrist so I have been mostly staying away from the keyboard. As a result I've skimmed over/skipped quite a few posts on MR in the last couple of weeks. So...\n1) Not sure what \"selecting VLs based on search queries associated with a username\" means. Is that something CC specific? Also isn't the way to limit a user to a VL, to just specify that VL in the server preferences? How does adding a vl prefix help with that?\n2) This makes sense to me. \nI've already merged the change to the mixin, since that is obviosuly a bug.. Oh sorry, I thought I had implemented a VL dropdown for filling in the search expression from current VL definitions, but I guess I was mis-remembering. OK, I'm ready to merge, but could you rebase and also add some documentation about the new prefix somewhere, probably in virtual_libraries.rst\nThanks, there's not much pain, but I was advised to rest the wrist, so I have been taking it easy. \n. Another thing that occurs to me is, since one of the purposes of the vl: prefix is to be used as a per user restriction, we need to handle the case of the restriction raising a ParseException gracefully (for example when a vl the restiction refers to is deleted). . Essentially, look in srv/handler.py for all calls to self.restriction_for() whereever the restriction expression is used, if it raises a PArseException it should return the empty set for the allowed books. . Looks good, but I decided to implement the error reporting slightly differently, because the browser client supports offline mode, there is no way to guarantee which function will be called first in any given session. So instead, the javascript function used to populate the book list will report a ParseError in the restriction expression directly.\nIf you rebase one more time, I'll merge the changes for the vl: prefix.. Whyare there two apparently identical pull requests? Also isn't unconditionally removing all  tags likely to remove some usefull content as well?. does this work with the code to enable/disable/re-order the  formats to send to the device?. I think you have to add your email addres to your github profile and also (maybe) setup GPG for email integration. . I decided to refactor this dialog to make it a little nicer.. I dont think this is a good idea. EPUB files in the wild have all sorts of media types in their spines. You want  to implement a media type check use OEB_DOCS at a minimum. Although I have to say that a lot more than spell check is going to break if you put non-html files in the spine, which although valid according to the spec, will not actually work in most places. . I fixed it slightly differently -- better to check for the expected type rather than not str since it could also be other types that will fail. . I am rather busy at the moment, it will be a little while before I can look at this, but thanks for the PR. . Released.. I decided to fix it slightly differently.. I tend to generally like less code, but I'm not really fussy. In my experience asset URLs are typically no more stable than UI, they are usually closely coupled. . The last time I checked, the higher resolution images served by the economist servers were just upscaled versions of the thumbnail cover, so it was pointless downloading them. Has that changed?. Hmm, well to me the 640 one looks better than the 1200 one. Less pixelated and large enough to serve as a thumbnail in most places. No point wasting all that bandwidth for higher than that. . Why is the change for the /get endpoint needed?. Support for that was deliberately removed from /get because it is ambiguous. I'm afraid I am not willing to restore it. But, the other part of your PR looks fine. . Thanks, and merry christmas to you too. A question: Are your changes applicable to all BSDs or only FreeBSD (aplogies I dont knwo much about the BSDs). If the latter, perhaps use isfreebsd rather than isbsd.. iff is short for if and only if. Wouldn't it be rather disconcerting to have the progress keep on resetting back to zero with every type of change? Instead calculate a number of tasks i.e. number of ids * number of things to do and update that smoothly. Also, dont change function calls that process multiple books into individual function calls, as that degrades performance (there are various internal optimizations the db can do when processing the same operation on  multiple books). . Yes, set_field is an example of such a function call. The reason I did not use a progress bar is because the various operations dont take equal amounts of time, so progress is not linear. Thinking about it, probably the best design is to have two bars, one for the current task, and one for overall progress. If there is only one task, hide the overall bar. If the task being executed is a single function call, then set the progress bar to \"indeterminate mode\" (IIRC by setting min and max values both to zero). . I have merged this. I think the bars should be made a little longer. @cbhaley comments?. As far as I know, the backlog argument is advisory, the kernel typically ignores it an uses a power of two backlog anyway. As per the listen man page:\nA backlog argument of 0 may allow the socket to accept connections, in which case the length of the listen queue may be set to an implementation-defined minimum value.. There is a whole bunch of other places you would need to make that tweak apply. Edit metadata dialogs, metadata writer plugins, content server, custom series columns, and quite a few I'm sure I'm forgetting. This change is far more complex than it appears.. Yeah, this is rather too big a change to merge without lots of work to make sure it does not break things in many places.. I manually applied your changes, since this pull request fails to merge.. Fixed, slightly differently.. You can do this already with\ncalibredb list --search id:whatever --fields formats --for-machine. I made some minor changes to the text for the new option and also some code changes in kobo/driver.py to comply with pep8 formatting. Have a look.. Could you add a test for this in search_query_parser_test.py. calibre needs to be buildable all the way back to Qt 5.6 with pre c++11 compilers. So I dont think the replacements of Q_NULLPTR and _DECL_OVERRIDE with C++11 versions will work. I've merged in the changes to specialLanguages. Let me knwo if anythong else needs to be done.\nAnd feel free to send a separate PR with your changes to INSTALL. I have merged, but there seems to be a mismatch metween max_supported_fw-version and clara_firmware_version (the latter is larger than the former). web_edition has to be different between the two recipes, they get different content. Also I dont want to limit the images to a fixed max size. That means large images will be pixelated while small images will be fine. The current algorithm scales the images as a fraction of their size.\nAlso why use a regexp to remove that rather than remove_tags?. The size is chosen per recipe for what works best with most images for that site. 25MB works fine on all readers I know of. file size is not an important consideration since no reader loads the entire file into memory at once. The only constraint on absolute file size is amazons send by email limit, which IIRC is 50MB. I have already added a fix for the extra li. As for gmail's limit, you really shouldn't be using gmali anyway, it has various other problems. Use GMX, which IIRC has a 50MB limit.. For me, the author of a recipe is free to do whatever she wants in a particular recipe. That way the chances are higher she will stick around to maintain that recipe. I only intervene on recipes I am the author of. . It would be nice to have a comment explaining the need for it for anybody needing to modify it in the future.. Preferences->tweaks->recognize numbers inside text when sorting\n. It is based on numeric sorting from the ICU library, I'd be very surprised if it does not know about chinese numbers, but if so, you should ask that the library add support for them. As for your problem, why are you embedding numbers inside a text column? Use a separate numeric column for that. Then you can sort it easily. . This has nothing to do with Qt. Sorting in calibre does not use Qt functionality. As I said before sorting is done via ICU. . Since calibre is open source you can do anything you want. The relevant function is sort_key() in icu.py. Simply add whatever path the package is installed into to sys.path before importing it.. I dont want to add a whole extra dependency just to rad metadata. calibre already has a djvu input plugin, it should be easy to modify that to also read metadata.. Once again: calibre already has a djvu input plugin, it should be easy to modify that to also read metadata.. I haven't imported them, the person that contributed the djvu code for it has imported them. And those are simply for decompression, the actual code to parse djvu file structues is all in python, IIRC.. application_id has a specific meaning in calibre and is meant for internal use. What are you actually trying to achieve?. no follwup. Typically, with these kinds of things, the content is loaded in an invisible part of the page (for search engine optimization) so you can extract it from there. Or alternately it is loaded via AJAX calls which you can simulate in mechanize. But if that is too much work, let me know and I will merge your PR.. Use the network inspector tool in the chrome devtools to see what request is being made by the JS to laod the content, then just duplicate that request in mechanize, no js knowledge needed at all.. I'm not familiar with requests -- never felt the need for it. But it likely has some way to dump the actual HTTP request it makes, use that and compare it with the one mechanize makes. You can get mechanize to dump http requests with\nbr.set_debug_http(True). Ambitious :) You will find that the GUI is relatively easy to get working as it mostly uses PyQt and unicode strings everywhere anyway.\nThe hard parts will be:\n1) the conversion subsystem (particularly some of the input/output plugins whose code is very old -- for example RTF input and ODT input). And also plugins like MOBI input/output which make extensive use of operations on bytes that py 3 does not support.\n2) The recipe system -- this requires either porting mechanize to py 3 or writing an mostly API equivalent replacement, I doubt MechanicalSoup will cut it as calibre allows custom recipes, so you cant just port the builtin ones and call it a day.\n3) The device subsystems: these contain lots of OS and device specific code that is impossible to test thoroughly, and when porting, for exmaple, the wpd C extension you will need to deal witht he fact that windows APIs expect UTF-16 which python 2 string are antively and python 3 strings are not.\n4) Interacting with the OS generally -- subprocesses, OS specific APIs sunch as winutil/usbobserver etc.\nMy current plan is to simply support python 2 myself, which I already do to some extent, see https://github.com/kovidgoyal/cpython  that is much less work and less potential for regressions. However, that is not to say I am opposed to trying to port calibre to py3 -- it's just a lot of work for very low return. I'd estimate it would take a couple of man-years and that is before all the regressions.. Some quick notes glancing through the commits:\n1) The icu module is broken (you cannot just remove the PY >= 3.3 checks) while it will compile with that, the actual logic will not work. You will need to implement proper fixes for it since the existing code is designed to work with either UCS2 or UCS4 python strings.\n2) Replacing ur'' with r'' is fine for python3 but it breaks in python2 since the strings are no longer unicode,\n3) Rather than eliminating xrange (since that is a performance regression in python 2) create a new xrange builtin for python 3\n4) Similarly replacing cStringIO with StringIO is a huge performance regression for python 2 Instead you would need to analyze the code where it is used and see if it can be replaced by BytesIO or StringIO\nThere are probably lots more issues. So if you are serious about proceeding with this, I suggest the following approach. \nStart by identifying relatively safe changes to the code base that make it compatible with both py2 and py3. Send PRs for those and I will review and merge them one by one. Get to the point where you can start running the test suite. Then start making changes to get the tests passing on py2 and py3.. Oh and another huge pain to port to python 3 will be the calibre server, since it relies on pretty deep integration with the python socket and ssl modules. In particular all the error handlers will need to be re-written since IIRC in python 3 the socket module has very different error semantics, that are also platform dependent.. I suggest you let bootstrap run under python 2 for the time being. Use a checkout that is already bootstrapped with python 3 (most of the things bootstrap does should be python version independent anyway). The first thing to get working would be python3 setup.py build to build at least a few C extensions that are widely used such as ICU, speedups, etc. \nYou would need to first make calibre python code importable under python 3. This means porting the simple things like print_function and ur'' etc. Make separate PRs for those and I will review and merge. \nAfter that I will see if I can get python3 setup.py build to run, once I have that done, you can work on porting individual C extensions, make PRs for each and I will review and merge. After that we can work on getting python3 setup.py test to run. Once that is done porting work for individual failing tests will need to be done step by step.\ncalibre used to use an HTTP framework for its server (cherrypy). It was removed and replaced with custom code in calibre 3 because it had various bugs and inadequacies and I wanted an async server -- none of the existing libraries for python 2 did that well. \nI would be very surprised if this porting effort took less than a man-year of effort. But, the only way to be sure is to try...\nAlso, just a note on general principles. I am not a big fan of six. It has burned me in the past with incompatible changes and it is very heavyweight. The calibre codebase does not doa  lot of fancy stuff, so what we need for compatibility is only a small subset of six. I would prefer if we create a dedicated module for it with just what we need, much lighter weight. For an example of such a module, see https://github.com/python-mechanize/mechanize/issues/9 where I wrote one for mechanize. Also, just to note, I am fine with requiring python >= 3.7 for the port, since by the time the port is done, 3.7 should be fairly old.. Link to mechanize's polyglot module: https://github.com/python-mechanize/mechanize/blob/master/mechanize/polyglot.py. it has not had a commit in three years, I dont think you can call that maintained. I prefer to just keep it inside calibre, reduces my workload -- dont have to maintain/provide support for yet another third party library. > EDIT: Not like this code is exactly high-maintenance though. Except for porting to python3...\nYeah but given that there exists an open PR and its been ignored for years.... Just FYI I finished porting mechanize to python3. . I suggest before attempting to run calibre, get all the tests to pass under py3. Sadly calibre has a pretty meager test suite, but given how large it is, even the meagre test suite does cover a lot fo code.. six is about a thousand lines of code that takes signficant time (several milliseconds) to import. polyglot is a hundred lines of code by contrast. But, my main issue with six is that in the past it has made backwards incompatible changes that broke working code for me. For something that requires so little code to write, and that is used so widely, I prefer not adding an eternal dependency. That way we are in control of the code.\nAs for removing it when dropping py2 support, that is esaily done with some help from pyflakes and a little cleanup script. It also has the advantage that it is both faster (avoid extra dict lookup) and more pleasant to use (less to type).\nHowever, I dont want you to have to do extra work for my preferences. So feel free to use six in your PRs that use the modernize library. I will take care of migrating them to polyglot.. Note that there is going to be a calibre release in a couple of days, I will review and merge this PR after that.. The release has been made. I have merged, with some minor corrections and removing the six module. Thanks.. As per roadmap above, I have ported the setup package to the extent that setup.py build now runs. Now it is over to you to port the C extensions. Please send a separate PR for each that I will review and merge.. Oh and just FYI you can build individual C extension using ./setup.py build --only\nsee ./setup.py build --help for details. On Wed, Sep 12, 2018 at 04:24:51PM -0700, Flaviu Tamas wrote:\n\n.foo = has been around since 1999, so I'm not really sure why the verbose and error-prone syntax was previously used here.\n\nBecause Visual Studio did not support C99 until 2015\n-- \n\nDr. Kovid Goyal \nhttps://www.kovidgoyal.net\nhttps://calibre-ebook.com\n\n. On Wed, Sep 12, 2018 at 07:13:24PM -0700, Flaviu Tamas wrote:\n\nflaviut commented on this pull request.\n\n     cflags.append('-I'+sysconfig.get_python_inc())\n\n\nldflags.append('-lpython'+sysconfig.get_python_version())\nldflags.extend(shlex.split(sysconfig.get_config_var('BLDLIBRARY')))\n\n\nI got -L. on most systems I tested this function on too, although it didn't seem to harm anything at this time.\nWhy getattr(sys, 'abiflags', '') instead of sys.abiflags?\n\npython2 has no abiflags\n. Doesn't py3 have a built in monotonic. You could just edit utils.monotinic and use that in py3. Closing as I dont think this is quite suitable, see further discussion on MR.. Nevermind, I looked at the py 3 source code and PyUnicodeFromKindAndData does makes a copy, sigh. Seems like a glaring hole in the python API. I suppose we either have to accept two allocs or mess with the unicode object internals ourselves.. If you use git blame on the file where it was used, you will see why calibre ships its own: https://github.com/kovidgoyal/calibre/commit/83151cc1f07d9bc070da3a65ac463771a1479ea6. Regarding this PR, I'd prefer it if we used ispy3 explictly and imported thebuiltin zlib module in that case and used the bundled one otherwise.. feel free to close this an open a new PR or add another commit. let me know when you are ready for merging.. Building is failing on windows, see https://ci.appveyor.com/project/kovidgoyal/calibre/builds/19419995/job/908t6ab0exr4gj81. I have merged making some efficiency improvements to python_to_icu32 (py3 version). just a heds up, I will likely be working on the two CHM related extensions in the near future, because of https://bugs.launchpad.net/bugs/1796889\nso skip porting those two until all the other extensions have been ported.. I have fixed the chm bug (which was caused by the code porting chm.py to python 3), here: https://github.com/kovidgoyal/calibre/commit/d517a8eb4fc8e0ddd74df9d871096eb3be87e341. seems to be segfaulting somewhere between lines 380 and 395 in setup.resources.py. I have ported all the code to be py2/py3 compatible. Didn't require that many defines.I haven't tested the py3 version.. ints take less space to store. No reson to cause a performancce\nregression (however minor) just to avoid an ifdef.\n. Also, I seriously doubt this will actually work on py3, the python bits as oppossed to the c bits are going to require refactoring most likely, because they currently work on bytes and the python 3 bytes type is much less capable, so if anybody does anything like slicing or regexes, thing are likely to break.. I decided to modernize the SWIG wrapper for chmlib. It now has no hand written C code an no swig generated python code, so it should be buildable on python 3 automatically.. The reason I prefer unpacked versions is that it makes unhandled tracebacks much easier to decipher. I like users being able to report meaningful error messages to me that I can often use to fix an issue without needing to first reproduce it. So I am afraid that is not going to change.. But isn't the system mathjax always packed? My point is I dont want to use packed versions of mathjax.. so while the existing viewer does indeed use an unmodified mathjax, it is going away in calibre 4 anyway. The replacement viewer uses the same mathjax as in-browser viewer which is in resources/content-server/mathjax.zip.xz\nSo if you really want calibre to use system mathjax you will need to actually replace get_mathjax_manifest() function to use the system mathjax. Which means finding some way of locating the system mathjax at runtime and then filtering it to only onclude the same set of files as setup/mathjax.py does.. github doesn't let me re-open the PR because the branch was force pushed and re-created, so open a new one.. Sorry I have no idea what this has to do with calibre.. I dont really see how this will work. One of the problems is that the directory layout in the resources mathjax dir is different from that in the upstream dir. The unpacked js is placed in the root, whereas upstream it is placed in the unpacked sub-directory. This is worked around in calibre explicitly by monkeypatching mathjax at runtime. Symlinking to system mathjax means that the directory layout will be different. Instead what you would need to do is symlink the entries inside resources/mathjax instead of resources/mathjax itself. This is more work, but will be less likely to break. You can use the filenames from the manifest to do the symlinking.. It would be nice to actually fix pthread_setname_np not working, can you catch the exception and print it out instead of ignoring it, so we have some idea of why it is failing?. Oh and in case you are not familiar with python, the way to do it would be:\npy\nexcept:\n   import traceback\n   traceback,print_exc(). Sorry, but this is not going to be merged. As I have explained before I am not willing to have this feature in calibre. There is simply too much prospect of symlinks breaking/books being lost. Even with the current design I regularly have to deal with a few \"calibre ate my books\" bug reports every week. I absolutely refuse to change the design of calibre to make such bug reports more likely.. You are welcome to your poinion, but, as I have said, this is not going to happen.. Simply importing the modules is not nearly enough, to make this work you'd need sys.,meta_path, see startup.py for an example. Not to mention that pre-importing modules is a performance killer.\nAlso, while I haven't looked at feedparser, markdown 3 seems to have removed various extensions, for example, there is no headerid.py in the source tarball.. what does this have to do with calibre?. How does it do that? All I can see is checkmodules.py and time.py neither of which do that. The reason I never upgraded the Liberation fonts is because the new ones have been know to cause problems, including kernel leve crashes in windows (blue screens). The ones in calibre I know work well, everywhere, the upstream packages, not so much.. Reference: https://bugs.documentfoundation.org/show_bug.cgi?id=62764. I vaguely recall there being other issues, which is why I originally looked up the referenced bug report, but I cant find references to them at the moment. I really dont think it is worth the risk.. The format string for PyArg_ParseTuple has to be y# on python3, I'll take care of it when merging. Nothing wrong I just decided to separate the trailing whitespace removal into its own commit.. Regarding beautiful soup:\nbs4 is API incompatible with bs3 which would mean it would break an unknown number of recipes. it should be trivial to port bs3. That is because in calibre bs3 is simply used as a tree API. All actual parsing is done by html5_parser. So we just need to make sure the tree API works on python3\nI tried pushing the changes to odfpy upstream many years ago, got nowhere. Maybe things will be different now. If they can be mostly upstreamed I am happy to drop it from the calibre tree.. Seems unneccessary work to me. Lets table bs3 for now. I will take a look at porting it when I have a moment. Given I managed to port mechanize, bs3 should be trivial in comparison. Especially since in calibre it is only used in unicode contexts already and not used for parsing at all. If I judge it too hard, then we can consider either switching to bs4 or maintaining dual APIs. . I have merged. Regarding the dynamically loaded parts (recipes/metadata plugins etc.) I prefer to not depend on poolyglot. Instead just replace unicode() with type(u'')()\nI doubt any of those use unichr() but if they do, just define codepoint_as_chr in the file itself.. yeah it has a different api to the python module.. I dont think it is going to be quite that simple -- unpickling python 2 data on python 3 is not at all straighforward see for instance https://stackoverflow.com/questions/28218466/unpickling-a-python-2-object-with-python-3. pickle is really a bad idea anyway. I'd like to instead excise it from the calibre codebase as much as possible. I've been meaning to do that, but been lazy since there is no overriding need apart from the general bad-ness of pickle.. I have migrated all uses of cPickle except for the ones in the config files, because of the afore-mentioned data portability issues, Will need to investigate how feasible moving the .py and .pickle config files to json is.. So the problem with BytesIO is that it does not accept unicode strings as input and auto-convert them to bytes. I'm pretty sure pieces of calibre code rely on this behavior of StringIO.  No doubt many if not most uses of StringIO can be safely replaced with BytesIO, but it is going to require careful review to avoid regressions. In situations where it cannot be guaranteed that unicode strings will not be used, it would be best to sub-class BytesIO to auto-convert unicode to bytes. Would require overriding the init and write methods in the sub-class.. Seems like adding isintance() checks or type conversions to ever call site of write() is much more disruptive than simply subclasing BytesIO, like this:\n```py\nclass PolyglotBytesIO(BytesIO):\ndef init(self, args, encoding='utf-8'):\n       BytesIO.init(self, args)\n       self.encoding = encoding\ndef write(self, x):\n        if isinstance(x, unicode_type):\n               x = x.encode(self.encoding)\n        BytesIO.write(self, x)\n```\nAnd similarly for StringIO in the other direction.. there is a typo in feeds.news (urlplit). I have removed devices/manager.py as it is indeed, unused.\n. You are missing brackets around islinux or ishaiku here. Left in a print() statement. Also I thinnk originally the buttons were sorted according to the layout mode (wide or narrow) so that they correspond more closely to the position of the widgets. Use button_orrder for that. . At least on my system, BLDLIBRARY insets both -L and -l flags. That could have unexpected side effects. A more direct replacement would be:\n```py\n'-lpython' + sysconfig.get_config_var('VERSION') + getattr(sys, 'abiflags', ''). should come before pyfile_fromfile not after it. Do we really need to allocate the buffer twice? Also I dont like up-converting all strings to UCS 4 internally. It would be bad for performance since most XML data will be either ascii or ucs 2 at worst.. The way I see it working is the following:\n1) Basically write three versions of the function for ascii string, ucs2 and ucs4. The character validity checks in the case of ascii are also much simpler, which should be a small speedup\n2) The vast majority of the time this function really does nothing, i.e.e there are no invalid chars in the XML. Therefore I think we should simply allocate a single buffer at the same size as the original string using PyMem_NEW(), fill it up and then create a unicode objet using PyUnicode_FromKindAndData. Wont this change prevent using unicode sub-classes?. ah well, probably best to leave it alone in that case, unless we have some actual reason to worry about unicode sub-classes. I confess I dont recall why I used checkexact there either :). cant we use sizeof(UChar) to check?. this looks wrong. as of VS 2015 (which calibre uses on windows, all these types should be defined anyway, so no need to redefine them here.. yeah but even then size_t is an unsigned type while int is signed. That cant be right.. ",
    "kfix": "Cool, thanks for that patch.\nI'll look into making my djvu converter work like the comic plugins.\nOn Jul 1, 2013, at 8:54 PM, Kovid Goyal notifications@github.com wrote:\n\nI have committed a slightly different fix. Note that you can use the conversion framework to convert a document that is only a series of images (this is how the cbz/cbr conversion plugins work). You just need to set is_image_collection to True in the input plugin if you detect it is a collection of images and implement the get_images() method to return the images.\n\u2014\nReply to this email directly or view it on GitHub.\n. I do see a class ImageExtractor that could be modified to only count images instead of extracting them. podofoimgextract appears to be as fast as pdfimages against a test PDF file.\n\nI am not fluent in C++ or pyx so it will take me some time to write PDFDoc_image_count() and make another patch. Thanks for the pointer.\n. It seems to work, I just published next version of my plugin. Thanks!\n. ",
    "t3d": "thanks for bumping up the plugin version for me. I realized I didn't do it when I went to bed, and when I got up it was fixed :D\n. Collapsing commits into single pull request is normal. You should have commits in different branches to keep pull requests intact.\n. That's great. The issue is gone.\nThanks a lot!\n. after all those changes in plugins I still tend to forget changing plugin version, and hence the second commit...\n. ok, there is another request submitted: https://github.com/kovidgoyal/calibre/pull/111 . I close this one\n. the issue is not limited to this plugin. I've seen the same behaviour when downloading mobi from project gutenberg. However the filename must get broken later on, as in the gui2/ebook_download.py's start_ebook_download() there is the name of dowloaded book in the status bar, and it is correct.\n. whoa, I was just digging through your ebook_download.py, when I realized the fix came (and browsing the github, not by getting the mail). Anyways thanks for the fix! I confirm it solves the issue mentioned in my pull request.\n. I should have noticed the changed class, when I fixed author detection recently...\nThanks for fixing it!\n. I've also tried to correctly replace links to images in <img> tags (currently I just overwrite them using address from a' href, leaving the obsolete <a> tag in soup), but in the generated file the images are not included. Instead they are downloaded on fly...\nThis is what I experimented with (in preprocess_html):\nr = soup.find(attrs={'class':'lightbox'})\n        if r:\n            r.replaceWith('<img src=\"http://gosc.pl' + r.get(r'href') + '>')\n. Maybe it would make sense to replace the mechanize-based browser by something more powerfull, like https://github.com/makinacorpus/spynner.git some day?\n. I'll try rewriting it.\nKovid Goyal notifications@github.com wrote:\n\nDo you still want me to merge this pull request or do you want to rtewrite it with JavascriptRecipe?\n\u2014\nReply to this email directly or view it on GitHub.\ufffc\n. So far no good:\nhttps://github.com/t3d/calibre/commit/ceda878ce68d9211811f05731120630ee60b4f8c#commitcomment-6261156\n. It still works :+1: \n. \n",
    "glehmann": "I'm not sure what went wrong - the branch is still there and the commit is there too https://github.com/glehmann/calibre/commits/acrimed\nI'm ok to open a new pull request, but I'm afraid it will not behave any differently...\n. Thanks :-)\n. ",
    "cbhaley": "You are right that if the user wants this info then the VL searches must be redone when the metadata changes. In the implementation I have they are done once for all the rows, then cached. In my tests on my 2000 book library it costs almost nothing - 20 milliseconds for a column that is a tag browser category (the most expensive). Of course, a library with 200 VLs and 50,000 books would cost more, probably more than the person would want to pay.\nI see the following use cases:\n1) there is currently no way to know what VLs a given book is in. You must go through the VLs and manually check, an error prone process. Knowing the VLs for a book can be important if you are using it in the content server or as a form of parental control.\n2) It would be very nice to create device collections based on VLs. This lets you do that assuming that the calibre can create collections.\n3) The VLs can become tag browser items, letting you manipulate them in interesting ways. For example, it becomes easy to see the intersection of VLs.\n. BTW: the new implementation cached the parsed search expressions, saving the \"recompile\" time.\n. Invalidate is used only when a VL is changed, in which case we have no idea whether a given book is affected. Any could gain or lose a VL. In the case where metadata changes on a single book, only that book is recomputed.\nI suppose it would be possible to loop through _data and tell each CacheRow instance to invalidate its VL cache. I am not convinced that this would be faster than a full refresh, but I will look at it.\nI haven't looked at the new backend. Are you caching the VL search results similarly to how you are caching get_categories data? If so, then the cost goes nearly to zero. In one of my tests I used a form of search that accepted one ID as the candidate. This scheme would work well to keep the VL cache up-to-date when a book's metadata changes.\n. Sorry, but I don't know how to separate the commit for [Bug 1200826] [NEW] Matching a library book to device search default from the virt lib changes.\n. No. Tests I did:\n1) Delete format using edit metadata (single). No problem. Not a surprise.\n2) Delete formats using edit metadata (multiple), with and without the \"Refresh\" box checked. No problem.\n3) Delete format on book details. No problem\n4) Delete formats using the delete button -- delete specific format. No problem.\n5) Add format by dropping onto book details. No problem.\nI couldn't think of anywhere else to look.\nCharles\n\nOn 23/Aug/2013 16:08, Kovid Goyal notifications@github.com wrote:\nIs it necessary to do the same thing when removing formats by right clicking on the book details panel or with the remove books button?\n\u2014\nReply to this email directly or view it on GitHub https://github.com/kovidgoyal/calibre/pull/68#issuecomment-23167405.\n. The dict um is already a new dict, and all the values in the dict are made using original.copy(). Would um.copy do something in addition?\n. I wasn't aware that one could open only the backend. I assume that any attempt to use a higher-level API will fail in some interesting way.\n\nWhy not copy composite columns? They contain as much data as standard columns and can be just as important to the user. If the user doesn't want them then s/he doesn't need to check the box. Granted that they are fairly easy to create by hand, but why force the user to do that?\n. Regarding size: you are probably right. When I added the new cover the size stayed very close to the same. However, more compression artifacts appeared, which means that the conversion chain jpg -> QPixMap -> jpg(quality=100) is more lossy than I think it should be. I would expect to get the same pixels out that went in.\nI will try the PNG experiment.\n. Going through PNG+90% results in a slightly worse image.\n. I suspect that the artifacts are introduced early on in the processing, perhaps when the file is decompressed into a QPixMap, because the JPG we get out is not the same as what went in even with lossless writing (100). If this is true then changing the compression value in the backend won't add anything useful.\nThe results are much better with what we have now, so I suggest leaving it as is. Of course, some people won't be happy with the results even though they are better, but these people can always put the cover file directly into the calibre folder to avoid any processing at all. (Yes, some people do this.)\n. According to the Qt docs, one must fill a new pixmap before painting on it. I changed it to fill with transparent instead of white.\nSorry about the min/max idiocy.\n. This last commit adds composition of rules. That should do it.\n. I tested it using ProxyMetadata before I submitted it, and it worked. I took it out because I wasn't sure what the risks were. However, if ProxyMetadata doesn't work, I suppose it is better to find out now instead of later.\n. And apparently I am the only user of this method.\n. Yes, it does make the row header bigger. Unfortunately, if that icon isn't included then the header isn't grown when one arrives. Correcting that would require repainting all the rows already painted.\nIn the end I decided that if the user wants the icon then the user is prepared to accept the space for it. If the user doesn't want the icon then s/he can turn it off (preferences -> look & feel), in which case the space isn't there.\nUsing a different indicator is possible but I think that there is benefit in using the same indicator in both the grid and table views.\n. Oh, and I have no strong opinion about whether the default for the new preference should be yes or no. I lean slightly toward no (although I coded yes) because the vast majority of people will have no idea why that icon is there on either view. The person who wants it can discover the feature.\n. Added code to update the status bar. Also made the loop process events, providing a sort-of multithreading and preventing OS \"not responding\" error messages.\nDuring testing I forced metadata update to true. Using my library of 1400 books and a cover quality of 85, it took 40 milliseconds per book to update the metadata. If this number is consistent with what other people see then the person with library of 8000 books might wait as much as long as 6 minutes.\n. I am not sure about the filtering of events. As it was, the user could actually get work done. As it is now, the system mostly \"hangs\". If (for example) the user is editing metadata, with the change the user suddenly cannot do anything, and also possibly cannot see the status line.\nOf course, if you think that the pseudo multi-threading that permitting all events enables will break something, then of course we must not allow the events. I suppose that I should say \"could break something\". :)\n. On 16/Jan/2014 14:01, Kovid Goyal notifications@github.com wrote:\n\nFiltering user input event shoudl not prevent the status line from being redrawn.\n\nIt doesn't prevent it. My point was that the edit metadata dialog covered the status line.\nThat said, what it does now is much better than what it used to do. I am happy to go with it as is.\n. Thanks for taking out that sleep. I meant to take it out, but suffered from the more and more frequent senior moments and forgot. :(\n. Ping. :) Changes pushed.\nYou were right about key_error, but for the set_field methods.\nQuestion: I note that an open book details window is not refreshed even if refresh_ids is called with the id of the displayed book and the current row. This is also true if I open a book display window then manually edit the data for that book either on the spreadsheet or using edit metadata single. Is this the behavior that you intend?\n. Re: Works for me on editing in the book list or via edit metadata. book details is not updated via refresh_ids, but only if current_changed is called. See for example, L322 in edit_metadata.py\nIt doesn't work for me. The steps I took:\n1) select a book on the spreadsheet\n2) Double_click on the cover shown in details to open the large book details window.\n3) Go back to the calibre window without changing the selection.\n4) Type 'E' to open edit metadata single\n5) Change a custom column (for me the yes/no column I am syncing with)\n6) Press OK.\nThe value is changed in the details pane but not in the details window.\n. Changed updateq and pushed\n. The import statements are now back being embedded.\nI took the opportunity to also fix several problems with syncing.\n. Added some more sanity checking, this time permitting the device to check the calibre version before allowing syncing.\n. Thanks!\n. This comment is here because I have a vague memory that you aren't notified about new pushes on a pull request. Apologies for the spam if you are notified.\n. Kovid, apologies for missing this use. You might want to make a slipstream release to avoid lots of chatter.\n. One use case is discussed in http://www.mobileread.com/forums/showthread.php?t=243258. Basically, the person wants to use the link column as a set of keywords.\nMy thought is that the output will be used on one of four ways:\n1) just as display, in which case the separators will be whatever the user wants to see.\n2) as a way to construct a link based on some condition. In this case the user will want to be able to split the link section away from the author name but will not parse the link.\n3) in the way that the person who started the above link wants, in which case the link contents must be parsable and separable from the author and from other author/link pairs.\n4) to indicate which authors have links, in which case the author/link pairs must be separable and the link text must be separable from the author.\nThe function supports all of these cases. I supplied a template in the thread that separates the links from the authors to get keywords, then merges the keywords into a list with no duplication.\nAs for GPM: it can't really do what you are suggesting. There is no way to access arbitrary metadata in GPM. Also, the lack of looping makes the kind of processing I think you are suggesting difficult. Custom template functions can certainly do so, but those are beyond the skill of most users.\n. I looked at that, but in the time I was willing to spend (half hour) I couldn't find a java api that guaranteed equivalence with python's hexlify. I was particularly worried about non-ascii strings and how they are encoded and whether the encoding would survive the experience. It seemed safer to stay inside calibre.\n. Patch with a new method pushed.\n. Thanks. I should have thought of that, given that I used a similar trick for the other arrays.\n. I thought of the temp file and can do that. The problem is that the changes will be lost if the daemon thread writing the file is killed. This is never catastrophic but it can be highly annoying, causing another exchange of metadata on the next connect.\nI didn't think of running a job. That will work if I can find a point where the job can be created. IIRC they must be created on the GUI thread?\n. I found an acceptable solution consisting of two parts. First, write the file whenever sync_booklists is called. This will ensure that the cache is \"almost correct\" at all times. Second, use the temp file scheme to ensure that the cache is never truncated.\n. I agree about rating because there isn't an explicit None value.\nGiven that numeric columns can be None, not showing an explicitly-set value of zero doesn't seem right to me. The example that finally got me to look at it was someone who had a column containing the price of a book. Free books have a price of 0,00, but one cannot distinguish this from a book that has no entered price. I can make a similar argument for integer columns, such as one containing the number of editors for a book. Zero editors is different from unknown number of editors.\nAs for resetting them, this has come up before. The way to do it us to enter -999999 (as many as will fit) and press the down-arrow on the spinner. It isn't the most obvious, I admit. :)\n. The on-spreadsheet is already detecting CTRL-space as clear (you must have added that?). I changed the custom column widgets to use the same class, so they now do as well.\n. I was wrong. It uses a naked space to clear. CTRL-space and SHIFT-space also work.\n. It works if I pass in the proxy_metadata object. It doesn't work if I create the proxy_metadata object in user_categories_for_books(). The reason is that the cache that composite_getter is using is not the cache of the new PM object, so it evaluates the template again.\nThe good thing about your suggestion is that no other API in cache.py is touched.\nI ended up adding the current PM object as a fourth parameter to all the getters. This adds a \"push\" of a single object instance onto the stack at call time, which is faster than any test to see if the getter is user_categories_getter.\n. Two issues here.\nFirst, constructing the PM object in user_categories_for_books(). This does not work because the caches are local to the PM instance. Consider the following sequence:\n- Formatter does mi._proxy_metadata.user_categories. This is using the PM instance embedded in the mi instance.\n- PM determines that the cache is empty for user_categories. It calls db.user_categories_for_books()\n- db.ucfb() must get the value for every custom column mentioned in a user category. Assume that the composite column being evaluated by the formatter is so mentioned.\n- db.ucfb creates a new instance of PM that has empty caches, then calls db.get_value_with_cache()\n- db.get_value_with_cache() invokes (eventually) the formatter, which invokes new_proxy_metadata.user_categories. The cache is empty, so the new_PM object recursively calls db.user_categories_for_books()\nInfinite recursion. There is no termination condition.\nPassing the pm instance prevents the recursion because that forces using a common cache between the various processing objects. So yes, proxy_metadata_map must not be optional.\nRegarding performance: an if requires 2 to 4 instructions (load, cmp, branch), where the instructions can be complex if the comparison is something like a string. A parameter requires a single instruction (push). Thus a parameter is faster if the if test is done for 50% of the accesses. Given your changes, I suspect that most accesses are of fields in SIMPLE_GETTER, so the if will be frequently executed.\nI think it would be better to remove \"user_categories\" from SIMPLE_GETTER and do the test before fetching field metadata. I will make that change so you can see what I mean. No problem if you use the change or not.\n. Currently it works like neither of your examples. Backing up a bit, we see that the formatter is handed a pm instance obtained from somewhere. It uses that pm instance to fetch user_categories. PM.user_categories_getter does not create a new pm instance but instead passes itself to db.ucfb. In the course of processing, db.ucfb will use this same pm instance to evaluate any composite columns, meaning that the cache in the pm object contains data, stopping the recursion. In effect we have this sequence:\n- create pm instance\n- formatter(pm)\n- pm.user_categories\n- db.ucfb(pm)\n- field.evaluate_custom_column(pm)\n- formatter(pm). return cached value from original pm instance.\nIt works because the pm is created outside the recursion.\nIt will infinitely recurse if a new PM instance is created and used anywhere inside the recursion cycle. Your examples create such an instance, so neither of them will work.\n. BTW: the cached value returned by the formatter is probably the recursive composite field text, but I haven't bothered to check that.\n. It isn't true that the PM instance is exactly the same as a new one. Looking at pm.composite_getter() we see that the cache for the current pm instance is filled in with\n- cache[field] = 'RECURSIVE_COMPOSITE FIELD (Metadata) ' + field\n  and we also see that it passes itself (the current pm instance) to the formatter, meaning that the formatter will see the cached value. The next time that the column is evaluated, that text will be returned and db.user_categories_for_books() will not be called.\nI am not sure what you mean by \"other, non-recursive users\".\nRegarding your second comment \"can the following call ever lead to infinite recursion?\", the answer is yes. If a user category makes reference to a composite column that uses the user_categories() template function then there will be infinite recursion unless the pm instance is passed along the chain. This happens because the check for recursive composite columns is defeated by creating a new pm instance.\n. Your example will not infinitely recurse. db.ucfb(pm) will attempt to evaluate the composite column. Further down we discover that the column has never been evaluated, which will recursively call db.ucfb(pm) where pm is the original pm. At this point the cache has been prepared and the new call to db.ucfb will not recurse again.\nI have no problem with marking db.ucfb as internal.\nRe last comment: I don't see why your example will infinitely recurse. The new PM instance will be passed to db.ucfb. Another new PM instance will not be created, so the cache will work.\n. Yes it does, assuming that the composite column is involved in the user category. field.get_value_with_cache() calls mi.get(colkey) which will call composite_getter.\n. This program runs fine.\ndef init_cache(library_path):\n    from calibre.db.backend import DB\n    from calibre.db.cache import Cache\n    backend = DB(library_path)\n    cache = Cache(backend)\n    cache.init()\n    return cache\nimport math\nfrom collections import defaultdict\ncache = init_cache(library_path = 'd:/cbh_data/calibre.git/library.test_small')\nseries_info = defaultdict(dict)\nfor id_ in cache.all_book_ids():\n    pm = cache.get_proxy_metadata(id_)\n    print(pm.get('user_categories'))\n. I have a metadata.db that fails if ucfb() creates a new PM instance instead of using the one passed in as an argument. I don't see a way to attach files here so I will email it separately.\n. How are the two different? If pm is not passed as an argument then ucfb must create an instance. If ucfb ignores the argument then it must create an instance.\n. Re: \"And does\nfor id_ in cache.all_book_ids():\n    db.ucfb(id_)\nfail?\"\nI think I see at least some of what you are saying. \nThe short answer is \"no, it doesn't fail\". The longer answer is that it doesn't fail because it only creates a new PMM if the one passed in is None, which will never happen except if ucfb() is called by someone other than proxy_metadata.\nRe your latest comment: I think we are in agreement. \n. I changed the latest pull request to contain only the changes to the formatter function. Those changes should be merged.\n. I reset it to how you did it, leaving making proxy_metadata_map not optional.\n. All changes backed out except the change to formatter_functions\n. Kovid: just a ping in case this stuff slipped out of view. :) No worries if you are up to \"there\" with other stuff.\nI think the changes are useful even ignoring the virtual_libraries() function problem. The one to categories.py prevent the evaluation of all composite columns every time any composite column value is needed. The one in search prevents constructing a set of all book ids if the value in the cache will be returned. For multi-thousand book libraries, constructing that set takes a while.\nUpping the cache size is less sure because of space/time tradeoffs. It should be set to the maximum number of virtual libraries that you think calibre should support fluidly.\n. I don't see the possibility for \"bad\" recursion there. Composite_for calls the formatter, handing it the current PM instance (itself). The formatter uses that instance to fetch all values, including composite columns. This will indeed cause composite_for to be called recursively, but it is the composite_for of the same PM instance so internal caching will be in play.\nEmpirical evidence supports the above. I have lots of categories made from composite columns in my test db and there was no (infinite) recursion. In addition, the \"tanjamuse\" problem was caused by a composite column used as a category.\nHowever ...\nThinking about this, we could take the next logical step and cache PM instances, which would make the recursion problem go away including the one we fought with last week. My thought is that you already maintain several \"global\" caches that are cleared when the underlying data changes (clear_caches). We could add another cache for PM instances that get_proxy_metadata checks and maintains. We would need to deal with the PM instance created by get_metadata, but that is straight forward.\n. Re: not adding another caching layer. The goal was to ensure that only one PM object is created for a given book_id. That would help everywhere because PM has its own caches for all custom columns, columns, format metadata, covers, virtual libraries(), and user categories, in addition to all the standard fields. Having the cache would mean that any composite column that uses another composite column would see the cached value instead of recomputing it.\nI don't see where PM uses the field caches for composites. Composite_getter uses its own per-instance cache. If the value is not in that cache then it calls the formatter, which will recompute the composite column. This means (I think) that any sub-composite is recomputed by the formatter whenever a using column is needed for display because get_value_with_cache creates a new PM instance.\nThe cache would also eliminate any problems with metadata calculation recursion because the code would always see the same instance.\nHowever, this isn't something I feel strongly about, so if you don't want me to try it that is fine.\n. Interesting data point: I tried an experiment, changing cache.get_metadata to return a ProxyMetadata object instead of populating a real mi instance. Startup time for Tanjamuse's library went from 96 seconds to 58 seconds.   My production library startup time (2500 books) went from 6.9 seconds to 2.8 seconds.\n. More on the \"interesting data point\". I undid the change to _get_metadata() so that it again returns a full metadata object (there is no way we could really make that change), removed all my PM cache test code, and changed line 143 in categories.py to use a proxy_metadata object instead of a full metadata object. I see almost the same time savings. Startup on the tanjamuse library goes from 96 seconds to 62 seconds.\n. My apologies for the above two comments. I was accidentally working in \"master\" and recreated the same change I proposed in this pull request (perf test). The numbers are valid, but they are the same numbers I had already determined.\n(embarrassed)\n. The problem is that ProxyMetadata.composite_getter() doesn't use the field() methods and therefore doesn't use _render_cache.\nAs a test, I changed CompositeField by adding methods to get and set the cache value, then changed ProxyMetadata to use that cache instead of the per-PM cache it currently has. On the Tanjamuse library using the changed categories.py in this pull request, tstartup time went from 62 seconds to 56 seconds.\n. Then perhaps the composite getter should do what all the other fields effectively do: fetch the value from local cache, if not there then fetch the value from _render_cache, recompute the value if render_cache is None, and store the resulting value into the local cache. If the value was computed, also store it into _render_cache.\n. Re the formatters: the PM object always uses the formatter from metadata.book. This is the same formatter embedded in the mi object used by db._get_metadata(). As get_proxy_metadata is standing in for db._get_metadata, I don't think we have a problem.\n. I pushed the changes for review to PM check the global composite cache before evaluating the composite.\n. Your changes look good, with one possible exception. There are the equivalent of what I did, but moving the evaluation of the column into \"field\" where I should have put it. The possible exception is the lack of an anti-recursion cache entry in render_composite_with_cache. If in the future the formatter manages to call render_composite_with_cache() directly (without going through PM) then it will recurse infinitely. You might want to make render_composite_with_cache an internal API.\nWe are now left with the change to categories: to use get_proxy_metadata instead of _get_metadata. It really improves performance. I think it is a safe change, made safer by your changes to PM and field because the possibility of recursion when evaluating composite fields is now zero (ignoring the hypothetical problem above).\n. Looking at the code, in addition to adding the recursion protection cache entry it might be better to change the lock to an Rlock and call the formatter with the lock set. That would ensure that the recursion protection entry in the cache (assuming it is added) would never be visible to another thread.\n. I have been following your commits. :)\nI am totally fine with marking it as an internal API. Doing so should be enough if a clue for someone to work back to find the right way to use it. (field_for, get_metadata, get_proxy_metadata).\n. The extra cache shaved 4 more seconds off the startup time for the tanjamuse library.\n. I looked into that. At one point it must have mattered, but it apparently no longer does. I tested it on a 2500 book library and couldn't detect any difference.\nMy guess is that the new db caching stuff works well. At the time that the call is made with the reset_only=True removed, the booklists are empty. This will make the first call to book_in_library scan empty booklists, taking no time. The same is true for every check thereafter. The loops to check the booklists finish immediately. Then the cache in fields takes over, returning False for all further checks for that book.\n. No, the change doesn't change behavior on disconnect. The reset_only parameter is used only on connect.\nHowever, my changes work with the parameter left in. I took it out under the guise of simplifying things, but I pushed a version with the parameter still there.\n. Note that the main behavior change is that as it currently is (reset_only param there), the ondevice column will appear only after metadata is loaded and analyzed. This can take many minutes. With the parameter out (or not used), the ondevice column appears when the device connects, then is populated when the analysis finishes. Either way works.\n. No. I did put the reset_only=True back in device_detected. The one in books_deleted was reset_only=False, which served no purpose because False is the default value.\n\nOn 06/Nov/2014 09:11, Kovid Goyal notifications@github.com wrote:\nDid you change the wrong reset_only? I'm guessing you meant to change the call in device_detected() not books_deleted().\n\u2014\nReply to this email directly or view it on GitHub https://github.com/kovidgoyal/calibre/pull/327#issuecomment-61941475.\n. I am getting confused. The source I committed has reset_only=True in device_detected. All of the other calls reset_only was unspecified or in the case of books_deleted was reset_only=False which matched the default.\n\nAre you seeing something else?\n. That is because in the end there isn't a change in device_detected. In the \"connecting\" arm the code is as it was, with reset_only=True. In the disconnect arm the only change was to add the emptying of the device databases.\n. Changes to remove \"ignore\" and call the superclass pushed.\n. OK for the button instead of the checkbox.\nAs for the QV shortcut, right now it either opens the pane/window or moves the focus to QV's booklist. I did this because of users like BetterRed who want to avoid the mouse at almost all costs. Couple this with ESC moving the focus to the main library view and it becomes easy to switch back and forth. I think this behavior is important, but I am open for alternate implementations.\nWhile speaking of focus, I am worried about the accelerators on the checkbox and buttons. When QV is docked the main calibre shortcut mechanism comes into play, meaning it is easy to overload an accelerator. I am thinking of removing all accelerators when docked, instead making TAB and SHIFT-TAB move between them. Do you have any thoughts on this?\n. > Perhaps an additional shortcut, say Shift-Q to focus?\nHow do I add additional shortcuts? Do I make a new action, or can I have a second shortcut in an existing action. As far as I can tell from looking at the code, I will need to make another action.\n\nDont TAB/SHITF_TAB already move between controls?\n\nYes, between all the controls on calibre's window. I want to 'trap' the tab key when the focus is in the QV pane, preventing TAB from moving out of the pane.\n. On 01/Feb/2015 09:02, Kovid Goyal notifications@github.com wrote:\n\nMake that Shift+Q\n\nIt seems that this technique \"hard codes\" the shift key, but there isn't any way in the shortcut editor to check that. In other words, the user can change the shortcuts to ('Q', 'R'), thus breaking it because the action won't see the SHIFT modifier.\nI think adding a second action will be safer, unless you know some way of ensuring that the \"alternate shortcut\" always has the SHIFT modifier attached to it.\n. Changes pushed.\n. Removed the calibre-level action.\nOne nit: I am not happy about how the focused item is shown in the QV widget. It is extremely hard to see (on my machine at least) which of the item box or the book list actually has the focus. The check box and buttons are easier to see. There is a slight change in the color, but it is so minor as to be indistinguishable. I tried to find a way to make it behave more like the library view (radical change of color), but I failed to figure it out. If you have the time to make a suggestion I will look further, otherwise it will have to stay like it is.\n. What I want to know is which widget (the items list or the table view) has the focus. As it is, there is almost no visual difference in either widget when the focus enters or leaves.\nPerhaps highlighting the current cell (or row) will do the job. I will try that.\nAnd sorry about leaving semicolons around. Comes with writing in both java and python. I also have no end of trouble remembering whether or not I should use camel case for identifiers. :)\n. BTW: see http://www.mobileread.com/forums/showthread.php?t=257283 for some explanation for why I attempted this.\n. Comment so you see the push ...\n. I prefer that the left edge of the editor widget be aligned with the left edge of the column. However, given that you don't and given that (I suspect) RtL language users would prefer it be aligned on the right edge, I will look at changing it.\n. New code pushed. See the comment in the commit.\n. Added a new commit, putting the list of valid empty formats along side the function that creates empty formats.\n. FWIW: I don't think that the title should be added to the txt file. In at least one use case what is desired is an empty file to avoid taking up space on devices. If someone wants to keep notes and wants the title in the file then the person can add it.\n. Preserving order isn't too hard, but that is only part the problem. It would also need buttons to change the order, especially important when new people are added, which is rather more work.\n. Yes. The behavior with multi-select and drag/drop (on WIndows) is strange. As far as I can tell there is no way to unselect everything. If I select a group of items then click on one of them to drag it, that item is unselected and the remain items are dragged. It is very hard to use.\nI figured that is_name columns usually didn't contain 100s of items, so the usability gained was worth the loss of multi-select.\n-- Charles\n. I pushed changes to do IF EXISTS.\nSeries sort is a bit of a mess. When you sort the book list the \"most common language\" is used to generate the series sort, which means that the sort can change from time to time depending on the books in the library. As far as I can tell that is the only place where language is used when generating series sort. For example, none of the tag browser, the smart_device driver, or the content server device compatible JSON function specify a language. Save_to_disk does not use a language when it writes the series sort into the OPF.\nThe title_sort() method uses the interface language and the tweaks, so even without the \"most common language\" stuff it gets close. It is certainly better for people who directly use the database than having nothing.\n. The problem I was trying to solve was that books sent via the sync mechanism had no thumbnail. Unfortunately I had my head somewhere where it shouldn't be. The fix I provided yesterday masked the problem but actually fixed nothing, and for the reasons you provided made things worse. Teach me to code when I am tired. (sigh)\nI have pushed the correct fix.\n. Kovid: ignore this pull request for the moment. I didn't do what BetterRed asked for. :(\n. Fixed to ignore all modifiers other than CTRL and SHIFT, which prevents ambiguity if both CTRL and SHIFT are pressed.\n. It turns on that things are a bit more complicated. Things don't work correctly if a user category contains a hierarchical item from some other category that is currently hidden, because the tree isn't built. I am thinking that the right approach is something like you suggested, but altered to build the complete tree then copy the top level nodes into the displayed list. I will look at that.\nIIRC the order in field metadata was chosen because that was the display order in the tag browser. In any event, I don't think it is a good idea to change the default order. There is no pressing reason to do so and there will be screams of anguish from those who don't like the change.\n-- Charles\n\nOn 21/Nov/2015 05:11, Kovid Goyal notifications@github.com wrote:\nAlso, unrelated to this particular issue, currently the categories are sorted by the order in which they appear in field metadata, (modulo the tweak is present) should that perhaps be changed to be alphabetic? This would be a fairly noticeable behavior change, however.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/kovidgoyal/calibre/pull/447#issuecomment-158588275.\n. I misspoke myself a bit in a previous comment.\n\nBuilding user categories does not reuse the node tree. It can't because then opening one node would play havoc wherever else that node appeared. What actually happens is that for leaf nodes the item data is reused (the \"data\" in the TagTreeItem). This allows marking a leaf in one place to mark it everywhere.\nThe reason that user categories must be last is that the processing depends on the tag data being already marked as hierarchical or not. For example, if a hierarchical tag appears in a user category then that tag must be hierarchical in the UC even though the UC is not itself hierarchical. The way for the UC to know this is that the shared tag data has already been so marked.\nReferring to the source as of my commit: line 533 is the main gateway. Processing will go to line 536 if the category is not hierarchical or the number of components == 1 (amongst other things). Assume that \"tags\" is a hierarchical category and the the item name is AA.BB. In this case processing will go to line 549 where the hierarchical node tree is generated and the tag is marked as hierarchical. In a subsequent call to process_one_node when a non-hierarchical user category is processed, the tag will have been marked so processing will go to line 549, building the intermediate node trees.\nPerhaps changing the test on lines 528 and 535 to check the base category if a user category is being processed could eliminate the problem. The goal would be to detect whether an item is in a hierarchical category even if the current category is not hierarchical.\nIt is also probably the case that the \"data\" for the generated intermediate nodes could be reused. As it is, clicking on a generated node does the correct search, but the equivalent generated nodes in other categories are not marked. Marking across categories only works for leaf nodes; nodes returned by get_categories. I will take a look at this, mostly out of curiosity.\n. Adding reusing the intermediate (generated) node data was easy.\n. Two reasons:\n1) GST nodes are clones of the nodes in the source categories, not references to the original nodes. A node can represent more than one category, e.g., the same series name appearing in two columns. It isn't clear what one should do if one source is hierarchical and another is not. It is perhaps worth noting that although this merging was intended, it didn't work until a few days ago,\n2) I wanted GSTs to \"feel\" more like a column. As part of that, they can be made hierarchical in settings, while \"real\" user categories cannot. The user adds hierarchy explicitly to a UC by creating sub-UCs, something that cannot be done for a GST.\n. That crash looks like another garbage collection problem. I can fix that, as at one point I had a working implementation that didn't replace the main widget.\nI prefer the work-on-close method over the backup method because it has much less chance of stale data. Unless you object, I am going to redo my other implementation so that no widgets are GCed.\nBTW: it would be so much nicer if I could put the composite value tables directly into metadata.db instead of in a lookaside DB. Calibre would be under no requirement to maintain the table or even keep it (e.g., restore). The table wouldn't have any foreign constraints so it couldn't affect calibre operation. One table could be named 'composite_column_values' and would have three columns (book_id, column_key, column_value). The other could be names 'composite_column_timestamps' and would have two columns (book_id, last_modified). Clearly since this work is done in a non-calibre plugin I could add the tables without asking, but I would rather discuss it instead of just doing it. :)\n-- Charles\n\nOn 28/Mar/2016 14:03, Kovid Goyal notifications@github.com wrote:\nCauses a random crash for me on linux with this traceback:\n|Traceback (most recent call last): File \"/home/kovid/work/calibre/src/calibre/gui2/cover_flow.py\", line 391, in cover_flow_do_sync if (self.is_cover_browser_visible() and self.cf_last_updated_at is not None and time.time() - self.cf_last_updated_at > 0.5): File \"/home/kovid/work/calibre/src/calibre/gui2/cover_flow.py\", line 365, in is_cover_browser_visible return not self.cb_splitter.is_side_index_hidden File \"/home/kovid/work/calibre/src/calibre/gui2/widgets.py\", line 1023, in is_side_index_hidden sizes = list(self.sizes()) RuntimeError: wrapped C/C++ object of type LibraryWidget has been deleted |\nThinking about it, I dont mind changing the plugin semantics from run on close to run on backup of book. The plugin can store the composite field data in its external location, on every backup. That imposes no overhead for people who dont install the plugin and for people that do, it does not pollute the metadata.db. It also does not involve major changes to core calibre code. And it gets rid of the shutdown complications.\nI apologise for the run around, I should have thought of this before you did all the shutdown message work.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/kovidgoyal/calibre/pull/489#issuecomment-202361924\n. I left in the messages for two reasons:\n1) I want to know if the changes fix the crash on Linux\n2) The content server shutdown has bothered me in the past. It can take minutes. The message helps, I think.\n\nI am not married to having them, should you want to remove them.\n. Changes pushed.\nI am not sure I did what you wanted with the has_... method. You said that having the method would not incur the performance of initialization, but the plugin in already on the initialized_plugin list. The change does avoid the customization stuff.\n. If you don't mind me adding an import of \"msprefs\" into the wireless driver then I don't need to change the API at all. As it (msprefs) is global and is currently used by worker processes, doing the import in a device driver doesn't seem to be out of line.\n. A commit just in case you accept the \"do it in the wireless driver\" idea. I used a revert commit to make it easier in the case you don't accept it.\n. Your changes work on Win10/64 with both UK (dot, comma) and French (comma, non-break-space) locales. I also tested numbers of the form 111.11 (dot) when in the French locale and it worked.\n. Note that the fix removes the current bracketing (the [] around the values). I did this because it is what the module csv_xml.py does for tags.\n. Also note that is_names will be separated by commas, because (again) that is what the module does for the built-in authors column.\n. BTW: I removed the inheritance of create_custom_column_ui but I did not remove the file. I _think it should go, but I am not sure.\n. Three comments:\n1) Given that only 3 of the possible 4 combinations of show_on_left and show_heading are meaningful, perhaps show_heading should be a 3-valued string set using a combo-box?\n2) As it is, short-text implies show_heading. Is this correct/necessary? I don't see any problem with showing short-text on the right if that is what the user wants to do. The new server behaves this way, showing short-text in the comments section if show_heading is not set.\n3) Another new-server issue: if a short-text is shown in the comments section then any html contained in that short-text is interpreted when it should not be. I think that the server-side preprocessor should do the same thing with short-text that it does for long-text. If this is done then the is_html parameter on add_row (line 205) would be set to True. I tested these two changes and the server seems to work correctly.\nLet me know if you want me to make these changes and push them with a new PR.\n. They are loaded in three places:\n- db.backend.init as long as load_user_formatter_functions is true\n- in gui2.preferences when template functions are defined or changed\n- in gui2.save (Saver). I am not sure why this is required. I would have thought they would be loaded when the db was opened but I don't know this code path.\nI am reasonably sure that moving the unload to close() is OK. One question is \"Which close\", cache.close() or backend.close(). As they are loaded in backend it seems reasonable to unload them there as well.\nBTW: there is no problem if the functions get unloaded more than once.\n. I pushed the changes.\nI am also working on BetterRed's bugs. I won't push those until this pull request is merged, to avoid mixing up the commits.\n. This fixes bug #1622757\n. Actually, there are three more ways one can write the saved search reference. The five (!) ways are:\nsearch:=\"fff\", search:\"=fff\", search:fff, search:=fff, search:\"fff\"\nThe pushed fix handles all 5.. Sorry about the print statement. I managed to remove the other 2.\nI originally used the button order, but I changed it to sorted the list because that is what you did for the layout button menu. Happy to remove the sort.. Pushed a small change to fix a potential problem with subclasses of LayoutButton. Very possibly. I didn't know that the action changed signal was emitted when shortcuts changed. I will investigate.. See the commit comments.. Small change to protect against the Quickview plugin being disabled.. My apologies for the last two commits. I think I am done now.. Push commit to make the UI deal with switching to empty libraries or VLs. Pushed a commit to make the focus-to-booklist action work when undocked. Also changed its shortcut to make it more consistent with the focus-to-quickview default shortcut. Two things.\n1) I frequently get queries about the content server and CC, asking how someone can use the search expression attached to the username to select one or more VLs. One answer, use the searches from the VLs, is correct but unsatisfactory because it won't keep track of changes to the VLs. The other answer, convert the VL searches into saved searches and use those is equally unsatisfactory because many people have no idea what a saved search is. The same questions arise in the calibre forum: how to limit a user to a particular VL. The change makes doing that easy and intuitive.\n2) From time to time I see queries on mobileread asking how to see things like\n- what books are in two virtual libraries\n- what books are in a combined virtual library\nand the like. Again, the current answer is to tell them to use saved searches in the VLs and then compose these however they want. The same problem applies; either they don't know what saved searches are or they don't want to use them.\nThe change to the mixin fixed a bug. I found that if I changed a VL search, that change didn't get reflected in the results until I restarted calibre.. Re selecting VL in the content server via username: no, this is a content server thing, not  just a CC thing. I see the question a lot because of CC's content server connection. People want to see books from only one VL.\nYou said \"Also isn't the way to limit a user to a VL, to just specify that VL in the server preferences?\" How do you do that? The only way I see is to enter a search expression. That search expression can't (currently) be a VL name (AFAIK), but can refer to a saved search. Is there something I am not seeing?\nHope your wrist improves. Pain is not fun.. Are you talking about in the content server? I agree that ParseException needs to be handled gracefully for all the ParseExceptions.\nDo you want me to look into doing that? I can certainly ensure that nothing bad happens (probably nothing happens :) ), but I don't know how I can tell the user about the exception, especially in OPDS.. I added some documentation.\nI also added some code to (try to) handle ParseExceptions intelligently. The problem with always ignoring them is that the user will not understand why s/he is getting those results. What I did should produce an exception message on initial connect but not break the other places restriction_for is used.. I see what you did and it makes sense for the standard browser. Unfortunately it doesn't handle the OPDS case. What you committed makes OPDS return an empty book list with no error or indication what went wrong. I pushed some changes in the same spirit as yours to make OPDS (http:/foo.bar.com/opds) return a HTTP 500 error when it sees a ParseException. I didn't change the behavior of other OPDS endpoints because a) the user shouldn't get there, and b) why take the risk.. (Hmmm... I commented by email yesterday but it didn't show up here.)\nA wireless device does its own reordering and sends that list back to calibre on every connect. Setting the order in calibre's preferences is disabled.. I have years of experience that listen(0) works fine on linux. What evidence is there that this change is needed?. I have no objection to the change except possibly triggering the law of unintended consequences.\nWhat I really want to know is whether some Linux kernel requires backlog to be greater than 0. TBH that would astonish me, but I have been astonished before. I know for a fact that Linux kernels exist that do not require backlog to be greater than 0.. Hmm... That snippet with listen(0) works fine for me with kernel \nLinux 4.14.12-x86_64-linode92 #1 SMP Fri Jan 5 15:34:44 UTC 2018 x86_64 GNU/Linux\n@Kovid: the above notwithstanding, I don't see how the change will actually break anything except possibly adding delays to multiple simultaneous connection error detection, I have no problem with you merging the change.. Done. I ran the test without the changes and it failed as expected (with an exception, not an assertion). I also ran it with incorrect info in the set of \"books\" and it failed as expected.. Kovid, this fix isn't right. I will make another push later.. Ooops, didn't mean to close the pull request.. OK, now it works.. ",
    "sengian": "May I ask you why you use the \"or 'cp1252'\"?\ngetattr if getting an empty chain send the default.\n. I have done the modifications. % was from ImageMagick doc but does not seem to be accepted by the bindings.\nHowever, could you tell me what python bindings you are using?\n. Yes I did indeed had a look at magick.c but your url is clearer.\nWell I don't understand why they didn't implemented it the same way as using the command line but Ok.\nThanks.\n. You are right but I personally don't need this as I am not such a purist. The tweak I introduced allowing to choose the fuzz parameter may or may not help as the influence is not huge.\nWhat you ask is only implementing a crop command in addition of trim but then you will need to add a parameter option and considering the cluter already in the metadata windows I am not sure it is a good thing. Maybe as a list button with dialog.\nWhat do you think Kovid?\n. Nice, I hope this will solve the problem as for me a full cover editor is not worth the effort. Thanks.\n. Yes, I am a total moron, I forgot I should modify the .ui. I have modified it and now all is as it should (I hope).\n. I have migrated this to another branch to clean it.\n. I am sorry bout the number of commits, only     86160c0  and    c807224  are relevant.\nI use GIthub on windows and it seems I still have some difficulties with merging with your branch.\n. If that's Ok with you I prefer to use the second method ie do a:\ngit reset --hard upstream/master\ngit push --force\nkeeping my master in sync with your last revision and not fetching changes like I was doing before:\ngit fetch upstream\ngit merge upstream/master\nYour method is not working well with my GUI (its one of its problems).\nI think this should work for you.\n. I agree with you, that's why if the startnumber is given it will change the number.\nThe difference will be really if you add books to an existing serie.\nI prefer myself to use it as a rename as I don't find the tag editor so quick and easy to use.\nI could add another option to modify this behavior or a tweak maybe depending on how you like it.\nI didn't do it before as I prefered to avoid adding a button and the actual tweak 'no change' is not specific enough \n. Yes, I didn't think of this.\nBut I need the split, so I have modified it following your suggestion and also remove an unneeded class structure in the xmp parser.\nHope this will be okay.\n. Yes from what I see you added xmp way better than what I did but I will have to redo the part about parsing the data and validating the fields to check if they are correct id's. \nAnd extract them from all fields as publishers apart from Elsevier are really lacking in good Metadata. \nWhere should I put functions looking/checking for identifiers? Directly in the module? \n. Yes more or less.\nI have a pdf without title in its metatadata but with a title defined in the title field.\nWhen I click on the button I (retrieve metadata or whatever, I don't know the exact name in English) in the modify metadata dialog, Unknown is added to the old title to give \"some title - Unknown\".\nSeems to me there is a check lacking in title but I am not sure exactly where.\n. See https://bugs.launchpad.net/calibre/+bug/1281235\n. No problem, I have a lot of other projects/ideas currently\n. ",
    "dny238": "Noticed people are working on trimming the image edges... \nI've always wanted to be able to hit 'trim' a 2nd time and have it remove like 4 pixels from around the edge. Hit it again, another 4 pixels. The magic api doesn't always do the job right.\n. Looking forward to it, the Magick one routinely leaves white space around the picture for some reason. Thanks!\n. ",
    "GRiker": "Pull request #73 posted.\nI actually needed to do:\ngit reset --hard origin/master\nThe other command was \"ambiguous\". :)\nG\nOn Sep 1, 2013, at 7:40 AM, Kovid Goyal notifications@github.com wrote:\n\nYou reset your master like this\ngit reset --hard upstream/master\nNote that this will change your checkout of calibre to be exactly the same as mine, so you will lose any changes.\n\u2014\nReply to this email directly or view it on GitHub.\n. OK, now that you have the changes, I'll do a fresh install and hopefully excise the crap.\n\nToday's my last day of freedom for awhile so I won't be making any more commits in the near future.\nG\nOn Sep 4, 2013, at 4:52 AM, Kovid Goyal notifications@github.com wrote:\n\nThis pull request still has lots of extraneous commits, so I've just taken libimobiledevice.py and merged it.\n\u2014\nReply to this email directly or view it on GitHub.\n. \n",
    "Cykooz": "Sorry, but I could not find of your explanations why this absolutely can not do. The fact that there are devices that do not support non-English characters does not mean that no devices that support them. In addition there are simple electronic books that show the name of the file (instead of the information from the metadata). For example this device - http://www.g-mini.ru/products/42 . Almost all Android phones and tablets sold in my country supports non-English characters in the file name.\nAlso, if Calibre cannot automatically detect that the device supports non-English characters, I would like to make his own decision about their use.\n. ",
    "oheil": "Hi Kovid,\ndo you mind if we discuss this here ?\nhttp://www.mobileread.com/forums/showthread.php?t=222265\nMy motivation for this in short, a few arguments:\n- What I read is part of my personal privacy. Maybe I do not want to\n  send my books over untrusted channels.\n- I do not like to see advertisements about horses and horse things\n  after sending an ebook titled \"The magical horse of Magicworld\" to\n  the Kindle for my kids using GMail.\n- I see your argument and it may be suitable to use gmail for many people.\n  But there maybe some small number of people, who just want to decide\n  on there own, which servers they want to use. Why not giving them the\n  possibility to do what they need or want?\nRegards,\nOli\nAm 12.09.2013 04:56, schrieb Kovid Goyal:\n\nI dont see the motivation for this. If you are worried about the \nsecurity of your email account, simply create a dummy email account in \ngmail or hotmail or whatever and use it only for sending books by \nemail from calibre. Much simpler than this and it works with \nautomation as well.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-24292051.\n. Hi Kovid,\n\nAm 12.09.2013 11:16, schrieb Kovid Goyal:\n\nNo one if forcing you to use gmail, use whatever server you want. Hell \nset up your own smtp server. The point is to not use the same \n/account/ as your main email account, thereby making the security \nimplications of storing the email password, moot.\nI am using my own SMTP server and I do not want to have the\npassword saved on my laptop and I do not want to have the password\nshowup in clear text. That is my principal concern and motivation for\nthe changes in the code. Laptops can get lost or could get stolen. In\nthis case I would probably bot thinking about a saved password in\nsome application on the lost laptop, leaving my mail server open for\nwhatever is possible with that.\n\nSecurity implications of storing the email password are never moot\nand security aware software should avoid this, whenever possible, or,\nat least, give the user the choice to avoid it and let the user decide,\nif he can live with the drawbacks of not storing the password in\nclear text. This is already possible, as I can edit the password all\nthe time I send an email and delete it again afterwards. But it\nis clear, that this should not be an argument :-)\nSetting up an own SMTP server is probably not possible for the most\nof calibres users besides that it costs money.\nMy main email account is also not suitable, as I have to change the\npassword on a regular basis. It would always annoy me, when I again\nforgot to change the password in calibre. Besides that this SMTP\nserver belongs to my employer, who let me sign that I do not\nsave passwords in unsecure manner (e.g. in my EMail client\nThunderbird).\n\nIf you setup a dummy gmail account to send email then\na) google will not know who you are\nThats true (in my special case).\nb) you will not be served ads based on whatever emails you send since \ngoogle will have no idea who that dummy account belongs to\nThats not true, as Google will connect the IP, from where the emails are \nsend\nto the IP adress, which requests ADs from googles Ad-Servers on the next \nWebpage.\n\nThere is one disadvantage I see in my suggestion: It may be more\ndifficult for the calibre user, to understand the implications of the\nnew chekbox. But I think that is not a big deal, because the user\nalways can ignore this option, if he has trouble to understand it.\nI am still hoping, that you might rethink your decision. Again the question:\ndo you mind discussing it on the developer discussion board of calibre?\nI would be very interested in other people opinions.\nRegards,\nOli\n\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-24304734.\n. Hi Kovid,\n\nI do not miss the point and I know of several methods to secure\nmy personal setup of using calibre.\nIts not only about me and my concerns, its more, that I tried\nto make calibre better (in security) and to help other users which\nmay have similar concerns. A can not tell if there are some others\nin the world who have the same concern like me, but again, it\nis not an argument to neglect security in applications, because\npeople dont ask for it. To stress the point: I do not say, your calibre\nis unsecure, i just say, it can be more secure on a little issue\nwithout major problems.\nAnyways, thanks for taking the time and thanks for calibre. It is great!\nRegards,\nOli\nAm 12.09.2013 12:18, schrieb Kovid Goyal:\n\nYou appear to be completely missing the point. Again,\ncreate a dummy email account on your SMTP server, that you\nonly use for sending emails with calibre. So if that password is\nstolen, it does not matter, since that account is just a dummy account.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-24307960.\n. Please stick to the point.\nI am also still not convinced of Kovids arguments and still I believe, that the password topic is currently not solved in the best way as it currently is (may solution may also not be the best way).\n\nBut Kovid has the last word and if he says \"No\" after all arguments are said than thats the decision.\nPlease don't hesitate to add NEW arguments or just a short word like \"I would like to see it integrated\". Anything else is contraproductive.\nOli\n. ",
    "naradae": "I love calibre so don't take this as empty nastiness. Oheil's solution is far far more user-friendly than making a new dummy mail account. Also, there will be a segment of lazy or non-security conscious users who will just give in and store their main gmail password unencrypted in calibre rather than set up a dummy mail account. So oheil's solution promotes security.\n. (I haven't checked out the code in the pull request) why not just prompt\nwhen sending email? No need to prompt on every calibre restart.\nAnd UX confusion? A \"remember password\" tickbox is not going to cause UX\nconfusion, anybody who uses the internet is familiar with the concept.\nOn Thu, Dec 12, 2013 at 6:41 PM, Kovid Goyal notifications@github.comwrote:\n\nSorry, but prompting for the same password on every calibre restart is not\nmore user friendly than creating a dummy email account. And lazy or non\nsecurity conscious people will just choose to store the password anyway\nrather than be prompted for it every time. So this proposal is at best\nsecurity neutral. And it has a cost in UX confusion.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-30394712\n.\n. You could have cut out your first and last lines and had a far superior\nresponse - very charming way to respond to somebody interested in\ncontributing to the project.\n\nOn Tue, Dec 17, 2013 at 12:10 AM, Kovid Goyal notifications@github.comwrote:\n\nSigh. Do I really need to spell out the obvious?\nMake that every time you send email after a calibre restart. You might\nonly send email once in a blue moon, but there are plenty of users that use\nemail for auto-delivery of periodicals, which means they send email pretty\nmuch every time calibre starts.\nAnd every option you add is one more option the user has to parse and\nunderstand, hence UX confusion.\nI am done commenting on this issue.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-30659213\n.\n. No I am absolutely willing to accept that my ideas will not be taken on\nboard, your objections to the pull request have merit, and obviously you\nhave more insight in to calibre's users than I.\n\nI was objecting to the way you phrased your response. Curt and direct\nresponses are to be expected - we all have limited time - but you wrote\nmore words than necessary just to show how stupid you thought the idea was.\nContributors don't spring from the void fully productive and aligned with\nproject objectives. They start as outsiders, and unnecessarily negative\nexperiences are a big turn off to an outsider.\nAnyway, I agree that this is a waste of both of our time. Happy holidays\nand good luck with the project.\nOn 23/12/2013 2:19 PM, \"Kovid Goyal\" notifications@github.com wrote:\n\nSure, if I was a robot with nothing better to do that write polite\nresponses to every person on the internet that wants to argue with me, And\nnote that posting comments on closed bug reports trying to change a busy\nproject maintainer's mind on an issue is not contributing to a project, it\nis wasting time.\nAbout the only people I will take the time to argue with are people that have\nalready contributed to calibre. That may seem unfair, but it is the only\nsane way to manage a project of this size.\nWhen contributing to a project, you have to be willing to accept that your\nideas may not be aligned with those of the project maintainers. In that\ncase, you need to just accept that and move on to something else or start\nyour own project.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/kovidgoyal/calibre/pull/81#issuecomment-31102776\n.\n. \n",
    "AeroNotix": "@naradae I wouldn't let it get to you. I think the success of the project has gone to @kovidgoyal's head. Seems like another open-source drama-queen.\n. ",
    "thoronaug": "This is not the first thread I read about this subject. And this is not the first time Goyal refuses to hear anything about protecting user passwords in calibre. When I read his responses I think he is very interested in NOT protecting our passwords. I wonder why.\nI can't believe he are so unconscious about users safety. And, of course, I'm pretty sure that he will never give his password or rely in an application that forces you to create a \"dummy account\".\n. ",
    "user-none": "Filename fix in #118.\n. Looks like I should have committed each item to a branch. Some store updates got put into this pull request after the fact...\n. Try my latest commit and see if that works as expected. if it does them we should be good to have it merged into master.\n. > With four possible algorithms now, it would be nice if these options could be consolidated into a single, user-orderable, priority list (kind of like the formats list in the dialog).\nI'm not sure that really works...\n- exact takes a page count. This will always work\n- pagecount will always work.\n- pagebreak can fail due to drm.\n- accurate can fail due to drm.\nThere are limited fallback situations both pagebreak and accurate can fallback due to drm but they can't fallback to each other. pagebreak can fail due to not having any pagebreaks in the file. Exact can't be a fallback because it requires a set page count.\nSo fallbacks can only be:\n- accurate -> pagecount\n- pagebreak -> pagecount (due to drm error)\n- pagebreak -> accurate (no drm error) -> pagecount\nSince the fallbacks are limited I think it's better to check if pagebreak returns no pages and then run accurate.\n. > This still leaves get_pages_exact overriding everything when a page count is given. That, however, may not be desired behavior. \nThis is the desired and intended behavior since APNX support was introduced. If the user says the book has X pages then that should be honored.\n\nIf I'm using the CountPages plugin\n\nAgain, the desired and intended behavior is to use the get_pages_exact when a page count is provided. Thats the whole point of setting a page count. Everything else is only an approximation of the page count when it is not known. In the case of the CountPages plugin it is known.\n. > This pull request appears to have all the commits, including the apnx ones. You probably forgot to create this branch from a point before the apnx code was committed.\nAll commits is intended. This is a settings change for the apnx code changes. The settings changes require the apnx changes. The apnx changes are complete and ready to merge. The config changes are not, hence the two different pull requests.\n\nRegarding the problem of migrating the old setting, why not just leave the old setting in place, but hide the UI for it explicitly, and add a new setting.\n\nHow? I don't see any way to hide settings explicitly... Also, I don't think this is a good way to go. If other settings change in the future we could end up with a lot of dead (hidden) settings code.\n\nYou can even add code to change the initialization of the new setting to use the old setting is the new setting is a special \"unset\" value.\n\nI've added code that attempts to convert the old setting to the new one. Not sure if it's right though.\n. The store code itself looks fine. I haven't tested it personally but it's clean and I don't see any red flags.\n. ",
    "ghost": "Thanks for the message.\n. Very well.\nBut I found a small bug in the final display of book details.\nThis can be remedied only a in the file \"book_details.py\".\nI'll upload the fixed code.\nBy the way, where I can convert the main window of the library (RTL), like you did here?\n. You can not display the text correctly without using this code.\nAlthough the text display in the right way, but not in the right place.\nSo that the text look like:\n\nInstead of:\n\n. By the way,\nfor LTR languages, the text is still displayed LTR (style=\"text-align:left\")\n. ",
    "tamasmajor": "\nChanged the GUI a little, but I used the old names, so it still works with other languages too  \nWhen you add a tag to the applied tags, save, then open again and unapply that tag (so it goes to the available tags) and save it again. Then when you open the Tag Editor again then that tag is disappeared. Is this the normal behavior?\n. Sorry, maybe I was unclear. Not when you apply a tag from the available tags, but when you add a new tag with the add input field and button. The new tag is saved into the applied tags, but when you unapply it and it goes to the available tags and reopen the tags (after you saved) the tag is disappeared from the available tags.\n. OK. Thanks.\n. \n",
    "comuttun": "@kovidgoyal Mmm, I'm very sad to hear that.\nI think Calibre is one of tool of the most very useful to manage ebooks.\nAlso, ebooks are increasing nowadays.\nBut the format of ebooks are restricted by publishers, that not provide the portable ebook (such as ePub).\nPDF is the very most platform-independent ebook format currently, and we often cannot convert it to ePub because of layout, or font or some problems.\nSo I want to manage PDF books with Calibre but the problem described in this pull request very inconvenience for me! (I think it's also for other persons in that use in any region of reading the non-ascii books).\nOn the other hand, I agree with \"Headache problem\" that regarding with this in some cases.\nSo I think that the option has NOT to be enabled by default, and this patch do not change any default behaviors.\nFor example if I added some warning message or tips to the option dialog it could be acceptable than now?\n. Thank you for merge!\n. ",
    "terwey": "@kovidgoyal thanks for the comments\n1) I developed it using my Kindle Paperwhite. I did not focus yet on excluding targets because it's of course still a development process which has to be reviewed :) I sadly do not have access to a Kindle Fire to see if that would be detected as the same device.\n2) Alright, that's a good place to take a look. I just found these 2 formats to be compatible according to Wikipedia\n3) I've thought of this, but this would've required a lot more coding.\nI would personally prefer to separate the representation layer from the logic and just have a normal template. I saw in the code that some parts of the Content Server already has this but this part doesn't yet.\nI don't know if this is on the roadmap...\nSome ideas from the Kindle view would be great I think to have in the Mobile view like the hyperlinks on the Author, tags, pre-filtered formats depending on the device browsing the page.\nThis however, would require more knowledge about the Calibre codebase.\nI was able to figure out some things and hack in some others but it's not necessary clean code.\nMaybe it's an idea to write down some ideas what else we (the users) would like to see so maybe we can figure out a way to implement this properly? It luckily didn't take me weeks to hack this together so a clean approach for a stable release would be :+1: for me\n. > As part of that, the server will stop using server side html generation and instead use some kind of client side templating library along with the ajax endpoints in ajax.py. Hopefully, when this gets done, there will not need to be a mobile.py at all, and we can use a responsive/adaptive/whatever-the-current-buzzword is single design for all screen sizes.\nIt sounds like a good idea to do everything from one view but my experience teaches me this is not a great approach. For a desktop you always want more information then for a Mobile (or even eInk view).\nThe Kindle Paperwhite happens to process -some- Javascript but other eReaders don't do any Javascript and sometimes only are able to render basic HTML with a Table.\nI would still recommend a refactor and we could take a look at integrating Django's Templating for this. It's very well documented and the logic can easily be separated from the view.\nReferring to the 'more code' this is what I meant :) On a Mobile view you don't need a giant Table like on an eInk device so you would probably want to serve two different views etc.\nI wouldn't mind looking at creating new views and using the internal Calibre Database for proper querying into a view.\nLet's keep this PR open and throw some ideas around.\nPS: is it already possible to run the Calibre Content Server completely Headless? Or is there still a GUI needed for the initial installation?\n. > There is nothing preventing a single view from hiding information depending on screen size.\nAs long as the View does that server side then indeed it's not much of an issue.\nStill not recommended for specialised views. A Desktop view will always have more information present then a Mobile view.\nAnd having a few hundred if statements vs. a desktop.tpl, mobile.tpl, eink.tpl is of course maintainability :) \n\nMy question about more code was why you think it is less code to create kindle.py rather than make mobile.py adapt its output based on user agent.\n\nThat was simply a duplicate, proof of concept. Also because for the Mobile View it has a different layout (div inside of a table vs 3 rows). But yes they can be merged just the lxml html builder is... ehr... not so nice ;)\n. ",
    "smartass101": "I understand and respect your reasons, so let me propose this compromise:\n1. keep the old --wide option and I'll put my code into a --wide-fill option and make a new pull request\n2. indeed there are too many to keep up. However, if you made it possible for the user to define his own profiles, it would be a very flexible solution for everyone. I would suggest this implementation (and I think I'd be able to implement it if you liked it): at the end of customize/profiles.py search for modules in some path like .config/calibre/lib/ in which the user could specify a list of additional profiles.\n. If I specify a custom size, that defeats the purpose of the --wide* and --keep* options. Those convenience options work well in conjunction with a profile, plus it's a lot easier to remember a profile name than to look up your screen size and calculate the right size for the image.\nIt's all about convenience.\n. You do have a point. However, I find the options a bit redundant. But if you don't see it that way, so be it. I think I actually won't implement the --wide-fill option, because it's easier and more flexible to just use a specific comic_screen_size.\nThank you for your time.\n. ",
    "LudwigX": "I'll look at using the PDF Output options.\nWhat are the criteria that determine whether a profile is needed? The\ncollection available in Calibre seems a bit idiosyncratic.\n\nFrom: Kovid Goyal [mailto:notifications@github.com] \nSent: Thursday, January 23, 2014 22:34\nTo: kovidgoyal/calibre\nCc: LudwigX\nSubject: Re: [calibre] Update profiles.py (#172)\nYou dnt need ot use a profile for this. You can specify an exact page size\nfor the generated PDF under the PDF Output options. \nMy policy is to only create new device profiles if they are actually needed,\nas otherwise there would be too many, given the wide variety of screen sizes\nand resolutions available.\n\nReply to this email directly or view\nhttps://github.com/kovidgoyal/calibre/pull/172#issuecomment-33194792 it on\nGitHub.\nhttps://github.com/notifications/beacon/6306447__eyJzY29wZSI6Ik5ld3NpZXM6Qm\nVhY29uIiwiZXhwaXJlcyI6MTcwNjA2NzI1MiwiZGF0YSI6eyJpZCI6MjQxMzcyODh9fQ==--0cea\n38bcace2424c6ea880a4bd4d1265761c2fcb.gif\n. Thank you. You were quite right of course. I was able to obtain the results\nI need with the PDF Output settings using the 4.23 x 6.77 inch custom page\nsize that results from the Samsung Tab 3 8's 800 x 1280 @ 189ppi specs and\nwithout adding an unnecessary new profile.\nInstead, I have been the using generic \"Tablet\" output profile because I\ndon't want images resized. Unfortunately, this doesn't seem in all cases to\nplay well with PDF output: occasionally images do get resized and their\naspect ratios distorted. It seems to affect particularly images at the top\nof a page, but I'm not sure if that's the determining factor. I can send an\nexample text and my conversion settings if you care to look at it, but it's\nnot a big problem for me and in any case I'd want to update to the latest\nversion to verify that it still occurs there (I stayed at 1.17 as I long as\nI was using a custom profiles.py and haven't completely cleaned up yet) .\nThanks again for your help.\nBest Regards.\nWill Kling\n\nFrom: Kovid Goyal [mailto:notifications@github.com] \nSent: Friday, January 24, 2014 09:38\nTo: kovidgoyal/calibre\nCc: LudwigX\nSubject: Re: [calibre] Update profiles.py (#172)\nMy judgement :) But basically, most profiles are from the early history of\nebook reader devices when the devices were very poor at resizing images, and\nthere calibre needed to do it for them.\n\nReply to this email directly or view\nhttps://github.com/kovidgoyal/calibre/pull/172#issuecomment-33227216 it on\nGitHub.\nhttps://github.com/notifications/beacon/6306447__eyJzY29wZSI6Ik5ld3NpZXM6Qm\nVhY29uIiwiZXhwaXJlcyI6MTcwNjEwNzA5NywiZGF0YSI6eyJpZCI6MjQxMzcyODh9fQ==--6b8a\n7c27f4b8f5509f81693c7f66426f9ea5a710.gif\n. ",
    "stano": "Ok, better work than mine :-)\n. ",
    "heysupratim": "Alright then \n1. Will make the additions a handful at a time \n2. Will try and differentiate the similar icons\n3. I guess i will be working on just flattened icons then, keeping monochrome where its appropriate\n4. The application icons will be kept as it is.\n5. size and distinct look across all areas of usage for the icons will be kept in mind\n6. Will psds do the work instead of the SVG ?\n. I have created the icons as raster as of now, i will be adding the psd files then . The files are in RGB only \n. ",
    "mtoensing": "Please don't let the overhaul of the icon set starve. The somewhat confusing existing icon set of calibre is one reason that I can not recommend it to for everyone. It is a long way to become the \"itunes for ebooks\" and Calibre has the feature set but not the polished looks of it. \nAnother idea would be to think about what are the most important buttons and show only a small subset on top of the menu and hide the other actions in a menu. \nOr is there another thread which is related to the layout of Calibre in general and I missed it? I would be glad to contribute to this project. \n. ",
    "pgarst": "Hi -\nI've attached a version of the docx demo document with inserted index\nentries (done on Word 2008/Mac), and also the resulting epub document with\nindex.\nI pushed a new version of index.py with some debugging and style\nimprovements. I'm new to Python, and appreciate the suggestions.\nLet me know what other suggestions you have, or information you'd like to\nsee.\nThanks -\nPeter\nOn Wed, Mar 26, 2014 at 9:29 PM, Kovid Goyal notifications@github.comwrote:\n\nIt would be helpful to me if you could attach a docx file that contains\nIndex entries. SO I can test with that and understand the code better.\nIdeally, it would be great if you could add sample index entries to the\ncalibre docx demo file linked to here\nhttp://manual.calibre-ebook.com/conversion.html#convert-microsoft-word-documents\n\nReply to this email directly or view it on GitHubhttps://github.com/kovidgoyal/calibre/pull/209#issuecomment-38768148\n.\n. I just made some changes to numbering.py to address a different issue.\nThe docx to epub translation was failing to pick up numbering when the numbering was part of the paragraph style. I'm not sure this is a totally correct fix, but there is a comment at the changed location which explains the issue.\n. Hi -\n\nI backed out the second push, so the repo should just have the one index\nfix which addresses the Demo1.docx example I sent.\nI'll do these things in separate branches in the future.\nThanks -\nPeter\nOn Fri, Apr 25, 2014 at 9:13 PM, Kovid Goyal notifications@github.comwrote:\n\nCan you split up the separate fixes into individual branches/pull\nrequests. Other wise it makes it harder for me to merge, since I then have\nto review everything at once. Thanks.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/kovidgoyal/calibre/pull/235#issuecomment-41459357\n.\n. \n",
    "ingkebil": "Fixed third bullet point already.\n. As for the slowness, this is the output of cProfile ran on the opml_import call only. 100 recipes were added:\n450904 function calls (447372 primitive calls) in 18.769 seconds\nOrdered by: cumulative time\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    1    0.023    0.023   19.868   19.868 user_profiles.py:365(opml_import)\n   94    0.006    0.000   15.547    0.165 user_profiles.py:64(add)\n   94    0.020    0.000   15.535    0.165 model.py:174(add_custom_recipe)\n   94    0.621    0.007   11.744    0.125 collection.py:101(get_custom_recipe_collection)\n   94    0.185    0.002    5.661    0.060 collection.py:61(serialize_collection)\n 4465    0.831    0.000    4.765    0.001 collection.py:38(serialize_recipe)\n 4559    2.034    0.000    4.267    0.001 __init__.py:24(compile_recipe)\n   94    0.038    0.000    3.770    0.040 collection.py:142(add_custom_recipe)\n   94    0.009    0.000    3.446    0.037 config.py:405(__setitem__)\n   94    0.027    0.000    3.437    0.037 config.py:344(commit)\nThe main bottlenecks are in add_custom_recipe and the get_custom_recipe_collection calls. There ain't a lot one can do about the first call, the recipe needs to be written to disk. But the second call, seems to build the whole custom_recipe_collection from disk each time we add or update a recipe.\nFor now I'll add a popup that shows something is happening so that the user doesn't panic when it takes an exponential time to load the recipes.\nI've got several suggestions (not pushed yet, just let me know if you prefer me digging in this code) as how to tackle the slowness problem:\n- I tested disabling the get_custom_recipe_collection calls while the OPML code is running. Once the code has finished, get_custom_recipe_collection is called. The cumulative time dropped from 20second to a bit over 7seconds. And when loading 400 recipes from 355seconds to 80seconds.\n  I do understand that keeping the custom_recipe_collection up to date is meant to check that no duplicates are being added. So this solution is not ideal.\n- we just ignore the wait and let it run as a job. (Is this actually possible?)\n- manipulate the lxml tree from get_custom_recipe_collection directly instead of rebuilding it from disk each time. this somehow seems the most logical way to go, but maybe there is a reason I am not understanding as to why the custom_recipe_collection is read from disk each time.\n.  Brilliant! Adding recipes now goes lightning fast :) ~1s for 400 recipes.\nI'll do the same for updating recipes tomorrow.\n. ",
    "rpspringuel": "I think I may be confusing my terminology so I'm going to use the actual function names here.  If I read you correctly you're saying the fallbacks are:\n\nget_pages_accurate -> get_pages_fast\nget_pages_pagebreak_tag -> get_pages_fast (due to drm error)\nget_pages_pagebreak_tag -> get_pages_accurate (no drm error) -> get_pages_fast\n\nThis still leaves get_pages_exact overriding everything when a page count is given.  That, however, may not be desired behavior.  If I'm using the CountPages plugin to estimate book sizes for some books, but manually entering the real number for others (which may or may not be marked in the book itself), then I might not want to default to get_pages_exact right away.  Now I could get around this by having two page count columns, one for CountPages and the other for apnx generation, but that strikes me as a bit awkward.\nAssuming just one page count column, I would order the fallback chains as follows:\n\nget_pages_accurate -> get_pages_exact (drm error) -> get_pages_fast (no page count given)\nget_pages_pagebreak_tag -> get_pages_exact (drm error) -> get_pages_fast (no page count given)\nget_pages_pagebreak_tag -> get_pages_accurate (pagebreak not found in file) -> get_pages_exact (drm error) -> get_pages_fast (no page count given)\n\nActually, looking at those, the first two chains are simply the last chain applied under certain circumstances (in the first chain the program has been told not to bother trying to find \"pagebreak\" in the files, in the second the drm error allows it to skip over get_pages_accurate, which would also fail due the the drm).  The last chain is what I called optimized for accuracy above.  The chain optimized for speed would be:\n\nget_pages_exact -> get_pages_fast (no page count given)\n\nIf I had to just put in place a small list of defined fallback chains (leaving a simple list of options, rather than a user-ordered list), I'd have the following 3:\n\nget_pages_pagebreak_tag -> get_pages_accurate (pagebreak not found in file) -> get_pages_exact (drm error) -> get_pages_fast (no page count given)\nget_pages_accurate -> get_pages_exact (drm error) -> get_pages_fast (no page count given)\nget_pages_exact -> get_pages_fast (no page count given)\n\nThe first chain could include a short circuit of step two in the case of drm errors, but I would put that in the code, not in the options list.  Further, I'm not sure the lack of the short would involve a significant performance hit.  How long does it take to open the file and find drm twice?\n. I see your point and have nothing further to add.\n. If that's a problem with this code (I don't have an up-to-date Touch with which to check), I believe that the problem predates my changes.  My code looks for the file in the same place that the existing code wants to write it to (designated by the variable apnx_path) and, if it writes an apnx, writes it too that location.  I haven't changed how the code determines that location in anyway.\n. I'm using a Kindle 4 with FW 4.1.1 (1813030025).\nCome to think of it though, I have a friend who has a Kindle Touch.  The device itself isn't brand new, but if the firmware has been updated then I might be able to check this out.  I'll talk to him and see if I can borrow it for some testing.\nDon't know that I'll be able to fix anything if I find there is a problem, but at least I'll be able to confirm or deny its existence.\n. Done.\nShould I not pull in commits from master in the future when writing contributions?  I did it in this case to make sure that my changes didn't conflict with any changes which had been made to calibre in the mean time.  Was this not an appropriate step?\n. Just checked on a Kindle Paperwhite running FW 5.4.4.2 (2323310003) and every thing seems to work fine.\n. Need to use \"==\" instead of \"=\"\n. Again, \"==\" instead of \"=\"\n. This line uses a mix of tabs and spaces in it's indentation.\n. In my testing I added print statements to track calibre's progress through this function, but could never get inside or beyond this loop.  Print statements before the loop appear as expected, but ones inside or after the loop never show up.  If I take the re.finditer call out of the for statement and give it its own line (e.g. test = re.finditer(...)) then that's the line that I can't get past, so something must be wrong with that statement.  However, no error is being raised so I'm not sure what's going on beyond the fact that no code after the re.finditer call is executed.  I'll try to get back to this and play with it more later to see if I can figure out something more helpful.\n. With four possible algorithms now, it would be nice if these options could be consolidated into a single, user-orderable, priority list (kind of like the formats list in the dialog).  Calibre would then start at the top, try one method if it failed (didn't produce a page mapping) try the next, and so forth.  As is, pagecount will always override if there is a non-zero value in the custom column and pagebreak and accurate are mutually exclusive.\nBarring that, I see two reasonable priority lists:\n1) optimized for accuracy: pagebreak, pagecount, accurate, fast\n2) optimized for speed: pagecount, fast (do not use pagebreak or accurate)\n. ",
    "talebook": "PS\uff1aplease add following files into POTFILES, to update the .pot tranlation files ( i guess on transifex ?)\nresource/content_server/.html\nresource/content_server//.html\nsrc/calibre/library/server/.py\n. PS2: a live site is http://beta.talebook.org/, please take a look\n. Sorry i am not aware of the wok flow.\nI tnink it's better to let the server(with edit mode) conflict to gui. Because I think the code around database.py is quite difficute, and IPC is heavy.\nSorry again about the ajax.py. These's no comments in the code to remind me about the third party apps. but ajax.py is easy to get back.\nI do these work because I need these new server sites. \n. ",
    "waiting-for-dev": "Yeah, I understand. In fact it can be run outside of the command line, and it would take all feeds. But it is true that it depends on an external tool.\n. ",
    "NiLuJe": "Keep in mind than on a few devices (anything running FW 5.x? Pretty sure the last time I checked this was on an up-to-date Touch, this came up recently in the KindleUnpack thread on MR), the .apnx is consumed by the framework, and a .azw (f? r? can't remember) is created in the sidecar folder instead, and I'm pretty sure the framework won't care about any new .apnx file you might drop in there if one has already been parsed ;).\n. Which device + FW version are you using?\nBut, yeah, the 'overwriting an existing apnx' being (possibly) 'broken' on FW 5.x isn't something new, looking at this PR just made me think about the possibility.\nThen again, if it's like thumbnails, even if we were to do it properly, there's no guarantee the framework won't do something stupid (it deals with 'sidecar' updates to an existing file in mysterious and broken ways).\n. ",
    "pft": "Thanks\n. Apparently created a false positive on logged in status.\n. ",
    "j-howell": "This is the sequence I am seeing. First I start two jobs that need to run for a while. Then the first completes and the pop up animates. I am looking that the results of the first job when the second completes. The popup then immediately re-animates with the results of the first job completion again. Once I click yes or no it then properly animates with the second job's results.\n. I see your point. After thinking about it some more, I withdraw the patch.\nI will change my plugin to make better use of the log to display the information that doesn't fit well within the popup.\n. 1. Non-sideloaded books are detected by looking for .kfx files that are not in a .sdr directory. The metadata is retrieved for them by locating the associated metadata.kfx file if the main book file is found to be encrypted.\n\nNon-sideloaded KFX books are now handled the same as any other kindle book. After the main book file is deleted the matching .sdr folder is also deleted by delete_extra_book_files in usbms/driver.py.. \n",
    "Polyfun": "Thanks for the comments:\n1) I have just committed a change for this.\n2) Yes, I have been considering fixing afc_file_write too, as a lower priority: a) I have not seen any bug reports related to it, and b) I won't get time to work on a fix until this weekend.\n. ",
    "rakyi": "Sorry, I am still new to git (and python). Hope it's ok now.\n. ",
    "gutenye": "@kovidgoyal \nThanks for quick replying, but that's not the case, I want the remember last read position feature, and I also want calibre does not modify epub file. So put the calibre_bookmarks.txt file out of epub is the best option.\n. OK, I'll give it a try.\nBy disable write calibre_booksmarks.txt to epub in line 84 , it'll automatically fallback to  write it somewhere else, just like it did with the .mobi file, Am I understand the code correctly? \nIf that is so, I just need to add an GUI option for it.\n. Indeed, thanks for the heads up, I'll fix it on my next PR.\nOn Fri, Apr 3, 2015 at 11:36 AM, Kovid Goyal notifications@github.com\nwrote:\n\nAnd note that your patch is insufficient. You also have to deal with\nreading bookmarks. Think about what happens if the user uses the option to\nturn off in file bookmarks, but opens an epub file with an previously\ncreated calibre_bookmarks.txt\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/378#issuecomment-89148569.\n\n\nLinux, Vim, Ruby, Go and Javascript\n- Guten.me  http://GutenYe.com\n- GitHub.com/GutenYe http://Github.com/GutenYe\n. I've read http://manual.calibre-ebook.com/develop.html, nothing there saied how to build calibre  from the source.\n. Thank you very much. \nI've tried a lot,  calibre distributed by Archlinux does not support CALIBRE_DEVELOP_FROM, and I have to download linux installer from calibre site, and .... \nYou just saved me a lot of time :)\n. @eli-schwartz \nThat's very nice, I totally forget about the calibre-git in the AUR. :+1:\n. ",
    "eli-schwartz": "CALIBRE_DEVELOP_FROM is only useful for a frozen calibre install (I suppose the theory is that if you install from source, you can update the install from the same source). And most distros have a habit of \"fixing\" program source code, so only the frozen binaries are officially supported.\nSpeaking of which, I don't recommend using the distro calibre, even on ArchLinux -- go check my still-open bugreport, they strip heavily-modified-from-upstream libs because Arch Purity.\nSo remind me, why do we use Arch again? Oh, right, because (partially): vanilla packages, unless changes are needed to compile/avoid breakage. Riiiiiiiiiiiiiiiiiiight.\nOh -- if you really want to, you can always use the AUR ;) they have a calibre-git package.\nYou can add patches and rebuild that (and the AUR package leaves modified libs alone, yay) and then you will have a patched calibre version that doesn't rely on source checkouts.\n. calibre conventions standardize the non-capitalization of the application name. Presumably Kovid had his reasons (and if it is deliberate, then it's probably not going to be changed...).\nRegardless, it seems somewhat odd to capitalize it in the linux desktop file but nowhere in the UI or the manual or in the OSX/Windows installers.\n. What is the point of this? It only changes the import paths...\nIf you are trying to build linux distro packages which use the latest version of upstream html5lib, don't. The version that calibre bundles was forked in order to apply certain fixes and changes that upstream html5lib didn't want (in addition to a couple things they recently merged). But in the current state of affairs, trying to use upstream html5lib in calibre leads to failing ebook conversions (which is kind of one of the main reasons to use calibre...).\nFor context and linked examples, a bug report I filed in Arch (which still hasn't upgraded python-html5lib because it \"breaks calibre\"): https://bugs.archlinux.org/task/43382\n. #583 was there before you (rejected for the same reason).\nSomeone probably tried to overzealously unbundle vendored dependencies, see:\n```\nLet's depend on the ones we have in pkgsrc instead of the bundled ones.\npre-configure:\n    cd ${WRKSRC} && rm -rf src/cherrypy src/pyPdf src/html5lib src/chardet\n```\nSimilarly, cherrypy upstream has open bug tickets (ancient, uncommented ones) for:\ne298f23781ffb0544bfe11a32ada02c906f1d0ca and later commits dealing with the same problem\nb117148241c0279c95b07637c3b6d7a27523b894\npyPdf was removed from calibre in b69fb230c5966f03a87058550574b102e18410ac (4.5 years ago)\n. That load(qt_plugin) removal thing was probably because keeping it there causes the build to error with:\n```\n# Building headless QPA plugin\nInfo: creating stash file /home/eschwartz/git/calibre/build/headless/.qmake.stash\nProject ERROR: Could not find feature reduce_exports.\nError while executing: /usr/bin/qmake-qt5 headless.pro\n```\nBut when removing it, it errors anyway with:\ng++ -pipe -O2 -march=i686 -mtune=generic -O2 -pipe -fstack-protector-strong -Wall -W -dM -E -o moc_predefs.h /usr/lib/qt/mkspecs/features/data/dummy.cpp\ng++ -c -pipe -O2 -march=i686 -mtune=generic -O2 -pipe -fstack-protector-strong -Wall -W -D_REENTRANT -fPIC -DQT_NO_DEBUG -DQT_THEME_SUPPORT_LIB -DQT_GUI_LIB -DQT_CORE_LIB -I. -isystem /usr/include/freetype2 -isystem /usr/include/libpng16 -isystem /usr/include/harfbuzz -isystem /usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -isystem /usr/include/qt -isystem /usr/include/qt/QtThemeSupport -isystem /usr/include/qt/QtThemeSupport/5.8.0 -isystem /usr/include/qt/QtThemeSupport/5.8.0/QtThemeSupport -isystem /usr/include/qt/QtGui/5.8.0 -isystem /usr/include/qt/QtGui/5.8.0/QtGui -isystem /usr/include/qt/QtGui -isystem /usr/include/qt/QtCore/5.8.0 -isystem /usr/include/qt/QtCore/5.8.0/QtCore -isystem /usr/include/qt/QtCore -I. -isystem /usr/include/libdrm -I/usr/lib/qt/mkspecs/linux-g++ -o headless_backingstore.o /home/eschwartz/git/calibre/src/calibre/headless/headless_backingstore.cpp\ng++ -c -pipe -O2 -march=i686 -mtune=generic -O2 -pipe -fstack-protector-strong -Wall -W -D_REENTRANT -fPIC -DQT_NO_DEBUG -DQT_THEME_SUPPORT_LIB -DQT_GUI_LIB -DQT_CORE_LIB -I. -isystem /usr/include/freetype2 -isystem /usr/include/libpng16 -isystem /usr/include/harfbuzz -isystem /usr/include/glib-2.0 -I/usr/lib/glib-2.0/include -isystem /usr/include/qt -isystem /usr/include/qt/QtThemeSupport -isystem /usr/include/qt/QtThemeSupport/5.8.0 -isystem /usr/include/qt/QtThemeSupport/5.8.0/QtThemeSupport -isystem /usr/include/qt/QtGui/5.8.0 -isystem /usr/include/qt/QtGui/5.8.0/QtGui -isystem /usr/include/qt/QtGui -isystem /usr/include/qt/QtCore/5.8.0 -isystem /usr/include/qt/QtCore/5.8.0/QtCore -isystem /usr/include/qt/QtCore -I. -isystem /usr/include/libdrm -I/usr/lib/qt/mkspecs/linux-g++ -o headless_integration.o /home/eschwartz/git/calibre/src/calibre/headless/headless_integration.cpp\nIn file included from /home/eschwartz/git/calibre/src/calibre/headless/headless_backingstore.cpp:2:0:\n/home/eschwartz/git/calibre/src/calibre/headless/headless_integration.h:6:62: fatal error: QtPlatformSupport/private/qgenericunixservices_p.h: No such file or directory\n #include <QtPlatformSupport/private/qgenericunixservices_p.h>\n                                                              ^\nIn file included from /home/eschwartz/git/calibre/src/calibre/headless/headless_integration.cpp:2:0:\n/home/eschwartz/git/calibre/src/calibre/headless/headless_integration.h:6:62: fatal error: QtPlatformSupport/private/qgenericunixservices_p.h: No such file or directory\n #include <QtPlatformSupport/private/qgenericunixservices_p.h>\n                                                              ^\ncompilation terminated.\nSo this still doesn't build on Qt 5.8 (currently in Arch Linux [testing] repo).\n@jelly's additional patch in https://git.archlinux.org/svntogit/community.git/log/trunk/calibre-qt-5.8.patch?h=packages/calibre seems to work though, the build goes through at least.. @jelly, did you actually try building it? Because you forgot to include the headless.pro additions from your stable patch, which tell qmake to look in the right include directories and treat it as a plugin library...\n@kovidgoyal,\ndiff\ndiff --git a/setup/build.py b/setup/build.py\nindex 16cb5b4b36..5380afec1a 100644\n--- a/setup/build.py\n+++ b/setup/build.py\n@@ -366,7 +366,9 @@ class Build(Command):\n             PLUGIN_CLASS_NAME = HeadlessIntegrationPlugin\n             QT += core-private gui-private\n             greaterThan(QT_MAJOR_VERSION, 5)|greaterThan(QT_MINOR_VERSION, 7): {{\n-                QT += theme_support-private\n+                TEMPLATE = lib\n+                CONFIG += plugin\n+                QT += theme_support-private fontdatabase_support_private service_support_private eventdispatcher_support_private\n             }} else {{\n                 load(qt_plugin)\n                 QT += platformsupport-private. Oh, good point I guess.. Current status on porting C extensions:\n\n[x] _patiencediff_c #907\n[x] bzzdec #932\n[ ] cPalmdoc #942\n[x] certgen #887\n[x] chm_extra #915\n[x] chmlib #915\n[x] freetype #936\n[x] headless #934\n[x] html #891\n[x] hunspell #872\n[x] icu #908\n[x] imageops  (not needed, autogenerated by sip)\n[x] libmtp #940\n[ ] libusb #942\n[ ] lzma_binding #942\n[x] lzx #914\n[x] matcher #889\n[x] monotonic #874\n[x] msdes #937\n[x] pictureflow  (not needed, autogenerated by sip)\n[x] podofo #940\n[x] progress_indicator (not needed, autogenerated by sip)\n[x] qt_hack #934\n[x] speedup #879\n[x] sqlite_custom #935\n[x] tokenizer #905\n[x] unicode_names #875\n[ ] usbobserver #942\n[ ] winfonts #942\n[ ] winutil #942\n[ ] wpd #942\n[x] zlib2 #881\n. @kovidgoyal looks like pychm (which is where chmlib and chmlib_extra come from) is technically maintained since 2014 at https://github.com/dottedmag/pychm/ (PyPI links it as the new homepage), although that does seem fairly inactive too...\n\nThere is a port to python3 which has not been merged, at https://github.com/dottedmag/pychm/pull/5\nWhat is the exact provenance of the version calibre includes? Are there any calibre-specific modifications to the original (unmaintained) code? I'm hoping that, like the regex module, this could be reduced to a thirdparty dependency, possibly by working to upstream any changes.\nAs far as I can tell, post inclusion, e69fc6b8b3c665c95611bf951376c98959526b0e is fixed upstream, and 1f2daebce60aa01438ddbe35b02746552a399114 could just as well be done in calibre and not in pychm.. Well, I've cp'ed things for now and it builds. I've attempted to preserve things, like commit 1f2daebce60aa01438ddbe35b02746552a399114, which seem to be modifications made by you.\nEDIT: Not like this code is exactly high-maintenance though. Except for porting to python3.... Just since March is not quite years :D but yeah.. #932 ports bzzdec, #931 added more compat layers for python code.. #934 ports two more plugins. #935 ports sqlite_custom. #936 ports freetype\n937 ports msdes. #940 should clean up a bunch more preliminaries for misc modules, and port libmtp/podofo.. #941 is a massive cleanup of unicode/unichr types for python3.\nSome bits missing for now:\n- recipes, stores, metadata plugins need a migration period because they get online updates\n- beautifulsoup, src/odf/ support python3 upstream and it would be preferable to migrate to a tested python3 port if possible.. #942 should be the last of the C extension bits.. Made some more progress on porting code that does not import on python3: #945 for c?StringIO, #944 for cPickle (but Kovid is probably just going to drop the pickle code in favor of things that, well, aren't pickle. :p)\nEDIT: pickle is mostly gone now and no longer an issue.\nAlso some fixes for xrange on master...\nAnyway, given it is now possible to \"build\" calibre, it is time to start attempting to import it, see how far it runs before crashing, and incrementally fix stuff. Let's see how soon we can start up a graphical interface. :). The changes included in the merge commit result in it failing to build:\n```\n# Building extension tokenizer\nCompiling tokenizer\ngcc -Wall -DNDEBUG -fno-strict-aliasing -pipe -fPIC -march=native -O2 -pipe -fstack-protector-strong -fno-plt -fdiagnostics-color=always -fvisibility=hidden -pthread -I/usr/include/python3.7m -O3 -DCALIBRE_MODINIT_FUNC= attribute ((visibility (\"default\"))) PyObject -c /home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c -o /home/eschwartz/git/calibre/py3/build/objects/tokenizer/tokenizer.o\nIn file included from /usr/include/python3.7m/Python.h:80,\n                 from /home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:10:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c: In function \u2018contains_char\u2019:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:37: error: \u2018kind\u2019 undeclared (first use in this function); did you mean \u2018_kind\u2019?\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                     ^~~~\n/usr/include/python3.7m/unicodeobject.h:507:7: note: in definition of macro \u2018PyUnicode_READ\u2019\n     ((kind) == PyUnicode_1BYTE_KIND ? \\\n       ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:37: note: each undeclared identifier is reported only once for each function it appears in\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                     ^~~~\n/usr/include/python3.7m/unicodeobject.h:507:7: note: in definition of macro \u2018PyUnicode_READ\u2019\n     ((kind) == PyUnicode_1BYTE_KIND ? \\\n       ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:43: error: \u2018data\u2019 undeclared (first use in this function); did you mean \u2018_data\u2019?\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                           ^~~~\n/usr/include/python3.7m/unicodeobject.h:508:28: note: in definition of macro \u2018PyUnicode_READ\u2019\n         ((const Py_UCS1 )(data))[(index)] : \\\n                            ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:49: error: \u2018i\u2019 undeclared (first use in this function)\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                                 ^\n/usr/include/python3.7m/unicodeobject.h:508:36: note: in definition of macro \u2018PyUnicode_READ\u2019\n         ((const Py_UCS1 )(data))[(index)] : \\\n                                    ^~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:193:11: warning: unused variable \u2018_data\u2019 [-Wunused-variable]\n     void _data = PyUnicode_DATA(unicode_object); \\\n           ^~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:192:9: warning: unused variable \u2018_kind\u2019 [-Wunused-variable]\n     int _kind = PyUnicode_KIND(unicode_object); \\\n         ^~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:209:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(haystack)\n     ^~~~~~~~~~~~~\nIn file included from /usr/include/python3.7m/Python.h:80,\n                 from /home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:10:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c: In function \u2018lowercase\u2019:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:37: error: \u2018kind\u2019 undeclared (first use in this function); did you mean \u2018_kind\u2019?\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                     ^~~~\n/usr/include/python3.7m/unicodeobject.h:507:7: note: in definition of macro \u2018PyUnicode_READ\u2019\n     ((kind) == PyUnicode_1BYTE_KIND ? \\\n       ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:238:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(x)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:43: error: \u2018data\u2019 undeclared (first use in this function); did you mean \u2018_data\u2019?\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                           ^~~~\n/usr/include/python3.7m/unicodeobject.h:508:28: note: in definition of macro \u2018PyUnicode_READ\u2019\n         ((const Py_UCS1 )(data))[(index)] : \\\n                            ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:238:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(x)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:195:49: error: \u2018i\u2019 undeclared (first use in this function)\n         Py_UCS4 ch = PyUnicode_READ(kind, data, i);\n                                                 ^\n/usr/include/python3.7m/unicodeobject.h:508:36: note: in definition of macro \u2018PyUnicode_READ\u2019\n         ((const Py_UCS1 )(data))[(index)] : \\\n                                    ^~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:238:5: note: in expansion of macro \u2018ITER_CODE_PTS\u2019\n     ITER_CODE_PTS(x)\n     ^~~~~~~~~~~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c: In function \u2018clone_unicode\u2019:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:263:104: error: expected \u2018;\u2019 before \u2018}\u2019 token\n     return PyUnicode_FromKindAndData(kind, data, PyUnicode_GET_LENGTH(src) - start_offset - end_offset)\n                                                                                                        ^\n                                                                                                        ;\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:267:1:\n }\n ~                                                                                                     \nIn file included from /usr/include/python3.7m/Python.h:80,\n                 from /home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:10:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c: In function \u2018tokenize_flat\u2019:\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:311:38: error: \u2018css_data\u2019 undeclared (first use in this function); did you mean \u2018css_value\u2019?\n         c = PyUnicode_READ(css_kind, css_data, pos);\n                                      ^~~~~~~~\n/usr/include/python3.7m/unicodeobject.h:508:28: note: in definition of macro \u2018PyUnicode_READ\u2019\n         ((const Py_UCS1 )(data))[(index)] : \\\n                            ^~~~\n/home/eschwartz/git/calibre/py3/src/tinycss/tokenizer.c:272:11: warning: variable \u2018css_source\u2019 set but not used [-Wunused-but-set-variable]\n     void css_source = NULL; int css_kind; Py_UCS4 c = 0, codepoint = 0;\n           ^~~~~~~~~~\n``. Also added installation option--mathjax-dir` which, if given, will make the viewer resources symlink to a system-provided copy instead of the bundled mathjax.. Two points:\n- could you merge the second commit?\n- I have pushed a commit that uses the unpacked resources if possible, but falls back on whatever is available. Would this be sufficient?. It might be, but not by default and not for the prebuilt binary releases. Looks like Debian at least debundles the viewer mathjax already, but their libjs-mathjax package does include the unpacked/ directory.\nFor the content-server zip, I'd only make use of this when bootstrapping from git master, not when building a stable release (so only with the AUR calibre-git package).\nFor the viewer, it would have the benefit of automatically upgrading to the latest mathjax version (calibre's copy appears to be unmodified) as well as resulting in somewhat smaller downloads and reduced disk usage when using other packages that also depend on mathjax... I would expect people reporting reader issues to first duplicate the issue using the official binaries anyway.. So I pushed an updated version that is based on the reworked resources/mathjax directory, which takes a mathjax directory that may or may not have the unpacked directory. And another commit adds an option to turn that into a symlink at install time, to some filesystem location.\nIf you re-open this PR I believe it will automatically detect and show my new commits.\nTested by verifying that the content server and ebook-viewer work on my machine with the symlink to system mathjax. It's assumed the system mathjax directory contains the final directory structure from the manifest.json (having additional files which calibre does not look for, should not cause any issues).\nI haven't attempted to do any more complex mappings.. #921. Switched to using per-file symlinks.. > Simply importing the modules is not nearly enough, to make this work you'd need sys.,meta_path, see startup.py for an example. Not to mention that pre-importing modules is a performance killer.\nI tested it out and it seemed to work just fine, e.g.\n$ calibre-debug -c 'import calibre.ebooks.markdown; print(calibre.ebooks.markdown)'\n<module 'markdown' from '/usr/lib/python2.7/site-packages/markdown/__init__.py'>\nHowever, the pre-importing modules being slow is a good point. As far as that goes, I did not know about PEP 302 import hooks, although I did know about manipulating sys.modules. So thank you, both for implementing this PR and for teaching me something new. :D \n\nAlso, while I haven't looked at feedparser, markdown 3 seems to have removed various extensions, for example, there is no headerid.py in the source tarball.\n\nIf you take a close look at my initial implementation, I actually added a check to filter the extensions based on pkgutil.iter_modules, so that calibre only tried to use the ones which were available.\nThis had the dubious advantage of allowing people to use an old version of markdown from before September, but I figured it would be best to allow you to make that decision rather than force it in the PR. Which, well, you did anyway so that is fine.. Ouch, that is one issue I completely did not expect.\nShould I assume there are other issues with the new fonts, besides for a Windows-specific BSOD? e.g. does it cause unpleasant issues with the Sony PRS? Because in theory I might want to devendor it downstream, but I obviously don't want to break ereaders just to save 4 MB...\nEspecially if there are other reports about this... apparently the LibreOffice bug is simply closed due to age.. Was there anything wrong with the first commit? Or was it just the missing PyArg_ParseTuple in the second commit?\nThanks anyway.. I see.. Test failures due to gettext having a function argument \"unicode=\" which, uh, should not be replaced with unicode_type.\nOTOH it also seems to be python2-specific.... What do you think about adding bs4 to the https://github.com/kovidgoyal/build-calibre base and porting official code and recipes over to it, then deprecating bs3 but retaining it for thirdparty recipes? If everything is just going through the tree API then hopefully this means recipes that use it directly as well as via calibre's own wrapper classes, should not be incompatible? Does bs4 generally have comparable updates to the handful of in-tree bs3 fixes?\nI guess that isn't immediately relevant, since regarding the py3 porting work it needs to be ported either way.... Well, the unicode wrappers are simple enough. In one case, the token \"unicode\" is not actually a type, but an attribute (renamed in bs4 for sanity), but we'll ignore that for now.. Awesome!\nThere are no uses of unichr in those locations, one way or another. Using type(u'') sounds interesting but I am in no rush on that front.. Python 3 has a lzma module, is lzma_binding still needed in this case?. Ugh.\nHaven't thought about data migration at all, really, was just trying to get it to start up (and currently a cPickle instance is the first error when trying to python3 -c 'init_paths(); import calibre'). :p Feel free to add a data migration hook or ignore this PR, whichever suits you best.. Great!. Or alternatively check what it isinstance() of and encode it before passing it into BytesIO()?\nAs far as safe things go, many of these are used when opening and saving images, when using open(somefile, 'rb').read() (actually, why is this copying data into a separate stream inside of a context manager?), or when consuming the output of struct.pack() and etree.tostring().\nI've tried to smoketest parts of the code this touched, did not catch any issues yesterday but now I notice src/calibre/ebooks/rtf/rtfml.py is not happy with either io.StringIO or io.BytesIO, because https://github.com/kovidgoyal/calibre/blob/d3ccd4369b7ff9c249559c32daba01c9a40b19c3/src/calibre/ebooks/rtf/rtfml.py#L84-L91 is returning a str(). Given the places where it is used, I believe this should just be calling unicode() every time it is written to an io.StringIO, and I've force-pushed an update to that effect (with which I can successfully convert and read an RTF file on the python2 build).. Rebased on top of master with only some of the relevant changes for now, essentially for cases where I believe it will be definitely a specific type.\nAlso for the cases being used in the recipes, I think we want to avoid wrappers anyway. ;)\nWill look into the rest at some point. Looking at e.g. the mobi code, it will need to be changed at the calling site regardless... currently there's a lot of cases where it adds strings and bytes together, then writes the combined string to a cStringIO, might as well change it to use b'' strings from the get-go. etc.. Indeed there is, fixed.\nAlso turns out src/calibre/devices/manager.py has code that does not seem to be used anywhere? But was trying to import Queue; Queue(0).. Perhaps https://github.com/dottedmag/pychm/pull/5 (which I copied this from) is meant to work on very old compilers.. Oops. I did not (yet) try to compile this (different environments for compiling with py3 vs the in-use py2 version)... time to stare at CI instead.. ",
    "april": "Hah, I'm honored to rate a whole new API.  Can I ask why it is set to False by default?  I understand that it's not the current behavior, but it seems like all upside to me.\n. I tried to have it work, and despite the dictionary containing:\n(u'www.thecodelesscode.com', u'/case/62'): set(['feed_0/article_57/index.html'])\nI still get:\nReferenced file u'/case/62' not found\nIt could just be that something is screwed up with my build environment.  I'm on a Mac, and Calibre builds horribly there.  I'll wait for the next full release, and then build my recipe against that.  If you want to cancel out this pull request, go ahead.\n. Ah ha!  Never mind; I figured it out.  The default resolve_internal_links should probably be smart enough to resolve them either by the path only or by the path + URI.  I had to update canonicalize_internal_url to remove the http://fqdn (to make it a relative URI), and that fixed it.\n. Okay, the pull request should be ready to go.  :)\n. ",
    "truth1ness": "Ah, ok. This was my first github submission so I wasn't sure if it would work or what the process was (still learning this part). Do you think you could use this one instead since I don't have anything else in my name on Github and to help me get familiarity with how Github submissions work? Thanks!\n. Aw, boo. Just one exception for a first timer? Does it really mess things up that bad? I'm OCD about keeping my stuff together! And this took me an embarrassing number of hours to figure out (was doing python and related courses all week). I also posted on the forum first because I thought you or other people might want to run/check it locally before allowing it to be added to Github. I really had no idea how Github works and if it had to be 'cleared' first before doing the pull request thing. \n. Ok, will do. Thanks!\n. Ok, I got the rebase upstream/master started but I'm not sure what to do when it gives me the conflict: \nboth added:      recipes/mit_technology_review.recipe\nI tried git checkout --ours src/MyFile.cs which is the only solution I could find on resolving this type of error but it didn't seem to do anything. How do I tell git to use my copy? \n. Ok, I did the reset, replace the file with a new copy of the recipe, and did the commit and push. Did that work? \n. Ok, will do. \nJust for my knowledge, did I do anything wrong to cause the repositories to get so hopelessly out of sync or is this normal to have to wipe out a fork just for one file? I've been reading up and watching videos about github for hours to try to understand this so I can fix/avoid it in the future and followed your commands to the letter and I'm still stumped by this one file commit. \n. Ok, thanks. Yes, I'll keep learning about the process, don't need handholding, just wanted to know if I had made any glaring errors. I have a longer course on Git I'll do next to get a better handle on this. \n. SUCESS! :)\n. ",
    "ned2": "Thanks for the feedback, I've changed my branch to reflect those changes. \n. ",
    "stanh": "I don't understand why this is hard for human. For many of us this is quite natural. People are requesting this format back from 2011. For mobile / iPad / tablets users, there is no such a date column.\n. Some news are published weekly, so the weekday is already irrelevant - what's important is which week.\nSince calibre is so widely used, is it more reasonable to make this an option that we can customize, instead of hard-coded?\n. Sorry someone says impossible in the forum. Could u advice how to do that please? Didn't get much on this from Google\n. Wow not entirely straightforward but finally solved my headaches!! thanks!\n. ",
    "khromov": "It looks like the article order change was added fairly recently, in 93b6d3997401733cc7c651b759d6796766e347eb\nPersonally, I am against that changeset, since:\n- The article order is not as on Instapaper.com (Like @Mno-hime points out)\n- If you have many articles, you won't get the latest ones, you'll get the oldest ones. That's not a very good user experience.\nSo I am definitely for merging that changeset to go back to the previous chronological order.\nI see the point in removing the Starred articles feed since they are more used for sharing and preserving for a longer period of time, so it doesn't make a lot of sense to keep downloading them every time.\nA GUI for recipe options are at the top of my wishlist for Calibre. :smile: \n. ",
    "Arkq": "As for the icon name, I will change that. However, I'm wondering why the linux condition is necessary. This code (fromTheme) should work (I've never done anything in the Python binding before, so I might be wrong) on all platforms, or am I missing something?\n. I've rebased the code according to your comment. I was trying to make this branching (platform condition) without much maintenance penalty (tray icon is not displayed until the visibility is set to true, so this code should work for Linux as fast as before), but if you like more normalized approach, please let me know.\n. OK, so basically it means, that there is a requirement for the StatusNotifier spec, and if it's not available (some light, Linux-based desktop) it is not possible to keep calibre on the tray (if System Tray is supported)?. ",
    "hazrpg": "It's been a long time since I used my own recipe, and this evening I noticed that the URLs were broken. So I decided to fix them so that others could benefit from it again.\nMy original post when I created the recipe was on mobileread.com here.\nI have since moved my original launchpad repo to github too.\n. Thank you for accepting the pull.\n. This is for the Arabic version of \"Egypt Independent\" (Al-Masry Alyoum). The version currently in the master branch with the same name is in English (Egypt).\nThe current version points to: egyptindependent.com and this PR points to: almasryalyoum.com\nAs a side note, it appears the English version is broken due to the recent change the newspaper did to their domains. Previously the English articles were published on almasryalyoum.com but all the old English RSS feed urls now point to the home directory of egyptindependent.com - causing the feeds to pull the wrong data.\n. Thank you for accepting the pull.\n. ",
    "madpilot78": "I just modified the code to search both in the originating device of the device itself and in the parent.\nIs this what you asked for?\n. > iff is short for if and only if\nI did not know.\nThanks for explaining!. ",
    "JimmXinu": "It was not my intention to also lump these Saved Search changes in the same Pull Request, but apparently that's how github works.  Sorry about that.\nSaved Search Changes:\n- Add an empty default entry to the Saved Search Editor drop down.  Otherwise, to see/edit the first saved search you have to select a different one and then select the first again.\n- Change Saved Search Editor add button tooltip: From the old tooltip ('Add the new saved search'), I expected to enter the new name and search and then hit 'Add'.  That would change the existing saved search (if one was selected), then create a new, empty one. 'Add a new, empty saved search with the name entered' makes that clear.\n- Fix for Saved Search Rename - would add new name, but not remove old name.\n- Reset Saved Search combo tooltip when search bars cleared.\n. > I'm actually OK with just having that dialog remember its size always. \nOne size for all ViewLog calls, or one size per log_viewer_title?\n. > self.unique_name = unique_name or 'view-log-dialog'\nDone.\n. You're still calling self.resize_dialog() which is removed.\n. This is literally a one line change.  Is there some objection to it?\nSo sorry about all the extra commits listed--I didn't realize it would do that.  If you want, I can make a different PR with just the one change in it.\n. Okay, thanks for explaining.  I'll try to avoid the extra commits in future.\n. ",
    "mourner": "cc @kovidgoyal \n. @kovidgoyal done!\n. ",
    "Xliff": "Thanks. Will do that.\n. Kovid,\nDo you know of an ePub file that has multiple chapters in a single HTML file? I've searched the web for examples, and I haven't had much luck. I have identified the part in toc.py that I need to emulate, but I don't have anything to test it against. It seems like most ePub authoring software depends on chapters to have split files.\nI have one other thing I can try in Sigil, and I'll see how that works.\nThanks!\n. Thank you! That's good to know. I am now looking at how things break down. Having multiple chapters in one page complicates things.\n. Kovid,\nThe nearest I've been able to get to directly comparing the page value to the TOC positional entries is to use TOCItem.start_src_offset. \nI then attempt to convert that into a fraction to compare against the page value by dividing it by the character count of the current page, and then multiplying that by the number of pages in the current page. \nHowever it appears that TOCItem.start_src_offset is not quite matching up to what I am expecting. What does TOCItem.start_src_offset measure?\nThanks.\n. Thanks. After looking at the CFI code, I think that is going in the wrong direction. Similarly, the code in toc.py uses the TOCItem to determine current chapter, but doesn't indicate position.\nI've since come up with another alternative. This is giving me better results, but they are still slightly off. Here is the relevant code:\npython\nif hasattr(self, 'current_page'):\n    page_anchors = []\n    for idx_e in self.current_page.index_entries:\n        if idx_e.start_anchor is not None:\n            we = self.view.document.mainFrame().findFirstElement(\n                \"#%s\" % idx_e.start_anchor)\n                if we is not None:\n                    g = we.geometry()\n                    cs = self.view.document.mainFrame().contentsSize()\n                    f = float(g.right()) / float(cs.width()) * \\\n                        self.iterator.pages[self.current_index]\n                    page_anchors.append(f + sum(self.iterator.pages[:self.current_index]))\n    self.page_anchors = page_anchors\n(This excerpt is placed at the end of viewer.main.update_indexing_state(), for the time being)\nWhat we are doing here is finding the element with the associated anchor. Locating its position in the page, then dividing that by the content size to determine its fractional position. We then turn that into a location in the current page, and then add all of the proceeding pages to come up with a final result. \nThe problem here is that the numbers are consistently coming out slightly lower than they should, but this is the closest result I have managed to obtain, so I am hoping I am on the right track.\nI will continue to try and refine this, but if you have some insight, I would appreciate the help.\nThanks.\n. Oddly enough, when I replaced this:\npython\npage_anchors.append(f + sum(self.iterator.pages[:self.current_index]))\nwith this:\npython\npage_anchors.append(f + self.current_page.start_page)\n...it works! \nI will make a new commit to the PR, shortly.\n. Well that explains it. \nMy first implementation tried using anchor_positions, but the values were always unexpectedly low. Now that I realize what anchor_positions actually measures, this makes more sense. \nYour suggestion to use the total number of columns may be the missing piece I was looking for, however I have yet to find this information. I will keep searching.\n. Kovid,\nNow implemented. \nI'm sure there are still issues with this implementation, but I've been up all night working on this. I finally had the \"Eureka!\" moment sometime around 8 o'clock this morning and crashed this out. I've tested it on my end, and it seems to work as well, if not better than the previous implementation, so thank you for your suggestions.\nPlease let me know if you have other issues with the PR. At this point, I am sure I can work everything else out. I will make more tests over the weekend, just to stress the implementation. I will let you know how things work out once that is done.\n. True enough. I haven't done that, yet. I wanted to get it working in paged\nmode before working on the others. Thanks for the hints for flow mode.\nOn Sun, May 22, 2016 at 12:04 AM, Kovid Goyal notifications@github.com\nwrote:\n\nYou have to make the code mode dependant -- in paged mode you use\nscrollWidth and page_width in flow mode you have to use scrollHeight (maybe\nyou already handle that -- wasn't clear from just looking at the last\ncommit). Also you should store scrollWidth only at the end of after_load()\nnot in update_contents_size_for_paged_mode() as in can change until then.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/506#issuecomment-220813137\n. You are correct, that change was necessary to get the code working in my debug environment. It does not belong in the PR.. Again, this PR is still under development, and I didn't want to have to mess with git to revert changes.. \n",
    "davidfor": "The configuration widget is contained inside the device configuration dialog. I have never noticed before that the size of this is not stored when it is opened from the \"Configure this device\" option. Should that be storing the size?\nFor a default size, I'll have to test on a lower resolution machine to see what's best.\n. It became available late yesterday. Probably about the time you were building 2.66. But, it is only being released to the two new devices. It might come out to the other devices, but I think Kobo will do another build in a month or so.\n. Not really. The driver is only testing the major and minor versions and ignoring the build number. I'm updating the build number mainly as a reminder of when some things changed. . I messed up and left two lines in that I used for testing. I've swapped the product ids for the Forma with one of mine so I can check the names and other things.. Close due to error in commit.. ",
    "NathanaelA": "@kovidgoyal If I benchmark it and create a patch that is either equal or faster; would that be acceptable?\n. Sweet; thanks for the pointers.   Yeah; I'm using CALIBRE_DEVELOP_FROM on my local box; because to me even if there is a speed hit here, it is totally worth it as I can now rename and fix books on my server, where before Calibre was totally corrupting any of the actual files involved.\n. I totally forgot to follow up last year; this patch has about a 30-40% speed hit while running all the tests.   So you are correct it does slow things down some; but I am willing to live with the speed hit and not have all my files corrupted when they get renamed.  ;-)     To me data safety is way more important. \nWhen I have spare time I might see if I can revamp that whole part of the code base as it has several things that are kinda fragile and can cause data corruption.. ",
    "Mymei2": "Well, this is actually the TODO I've mentined above. I didn't know that I can do it myself. :-)\n. Thanks. I'll plan to do it in the next two days. However, only in the english version. What about the other languages? How is that stuff maintained? Should I open some TODO somewhere?\n. Oops! I've just found in repository that you've already documented it, it's simply not online yet. Thanks once more. Now I can move to the second change. :-)\n. ",
    "aroig": "I've just realized that it may have nothing to do with arxiv pdfs. The timing coincides with an upgrade to poppler 0.47. pdfinfo may have changed its output.\nAnyway, thanks!\n. ",
    "marvil07": "Thank you for adding this upstream!\n. ",
    "MingcongBai": "Well if that's the case this is the end of my argument, sorry for the trouble.\n. ",
    "kiulkiel": "Thanks Janine\nOn Dec 3, 2016 6:23 AM, \"Miguel Castiblanco\" notifications@github.com\nwrote:\n\nFixed KoreaHerald's recipe to show the content of the articles again.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/kovidgoyal/calibre/pull/590\nCommit Summary\n\n[KoreaHerald] Fixed\n\nFile Changes\n\nM recipes/korea_herald.recipe\n   https://github.com/kovidgoyal/calibre/pull/590/files#diff-0 (16)\n\nPatch Links:\n\nhttps://github.com/kovidgoyal/calibre/pull/590.patch\nhttps://github.com/kovidgoyal/calibre/pull/590.diff\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/590, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AVXz2ytsqEyYD_sgcR1nPPcrU8JJpuyuks5rEXtvgaJpZM4LDThG\n.\n. What's ft. Yes user should have the ability to choose. \n",
    "jamesbroadhead": "Ok, will include with my other PR. How can I trigger an appveyor build? . ",
    "a10kiloham": "I suggest also deleting the Sunday Times recipe as that's no longer required. It may be preferable to include the Sunday times Magazine as a separate recipe, which I will do if desirable.. can I suggest renaming one of them then? it's v confusing to have two identical recipes. i'd propose naming this one \"The Economist (Free)\" for consistency w/ origins.. Don't you think it's ridiculous though to have duplicate names that require\ncode duplication?\nOn Fri, May 12, 2017 at 5:04 PM Kovid Goyal notifications@github.com\nwrote:\n\nSince they produce identical output, it would be more misleading to change\ntheir titles, since if you name one (Free) and not the other, it would lead\npeople to expect that the other is not free -- which is currently not true.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/663#issuecomment-301117815,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwaksJnvJPaCka5itirkp4wjpWZtyks5r5IMfgaJpZM4NZZ01\n.\n. financial times\n\nOn Sun, Jun 18, 2017 at 4:08 AM Drdestrgon notifications@github.com wrote:\n\nWhat's ft\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/699#issuecomment-309253764,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwbvpy9EYtqdePi2q9VrFYoVKicyiks5sFJTEgaJpZM4N9Y8V\n.\n. fair enough. it just feels like a weird section to have in there since it's old news and the new formatting makes the article titles unreadable (it just gives have sentences vs a proper title now on the site itself). i don't need to commit this since i can just edit it out of my own local recipe, but i was hoping others might prefer to not include that section by default..... one is for US and one is for UK recipe. Per your feedback ages ago they're duplicated recipes but kept for historical reasons. \n\nThe 'aside' tag seems to only be used for marketing purposes inside of articles, hence why adding it.. Kovid - can you suggest a couple reference recipes for your preferred\nstyles? In this case I chose to reference the underlying link as I presume\nthis will be less fragile than UI layer/CSS references to an object.\nAlso, the preferred date for download should remain Friday AM - the cover\ndate is Saturday but issue updates Thurs late evening GMT.\nOn Sun, Nov 26, 2017 at 3:18 AM Kovid Goyal notifications@github.com\nwrote:\n\nI decided to fix it slightly differently.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/777#issuecomment-346981112,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwRI4X7gFMx4YshvUGB_qDNyMJY0mks5s6NhygaJpZM4QqjYK\n.\n. It's definitely upscaling a bit but better than the 200px ones now. the\n200px doesn't even appear on the new Kindle Oasis weirdly presumably since\nit's too small.\n\nOn Thu, Dec 7, 2017 at 4:03 PM Kovid Goyal notifications@github.com wrote:\n\nThe last time I checked, the higher resolution images served by the\neconomist servers were just upscaled versions of the thumbnail cover, so it\nwas pointless downloading them. Has that changed?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/782#issuecomment-350012366,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwYmGmo3t1tW5LijSo8UqR4vqTzX1ks5s-AxFgaJpZM4Q5xZ8\n.\n. Fair enough - I'll edit now\n\nOn Thu, Dec 7, 2017 at 4:18 PM Kovid Goyal notifications@github.com wrote:\n\nHmm, well to me the 640 one looks better than the 1200 one. Less pixelated\nand large enough to serve as a thumbnail in most places. No point wasting\nall that bandwidth for higher than that.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/782#issuecomment-350017257,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwbaO8AC6WOvLByZrYst1TgtxWf7Sks5s-A_YgaJpZM4Q5xZ8\n.\n. Updated to 640px width per Kovid's comment. There seems to be a lot of recipe inconsistency in terms of image sizing.\nThis one produces 25mb+ Sunday editions which seems a bit much for eink\nreaders, but probably fine for tablet readers. What's your philosophy on\nthat? If using the current auto scaling, it's set to divide by 5, but other\nrecipes seem to be all over between 5-12.\n\nFor the remove tags, there are many list items on the page which seem to be\nnecessary, but in the header, when the social sharing is removed, it leaves\na remnant li tag that's empty. This seemed the best fix for that as the\npreceeding li tag contains the date and must remain.\nOn Thu, May 31, 2018 at 1:36 PM Kovid Goyal notifications@github.com\nwrote:\n\nweb_edition has to be different between the two recipes, they get\ndifferent content. Also I dont want to limit the images to a fixed max\nsize. That means large images will be pixelated while small images will be\nfine. The current algorithm scales the images as a fraction of their size.\nAlso why use a regexp to remove that rather than remove_tags?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/843#issuecomment-393515873,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwXMBk130Cs8lyl66f7i5eraEOwMBks5t3-PQgaJpZM4UU9Ul\n.\n\n\n-- \nrobk@robk.com\nMobile: +44 778 6066411\nWhen outside the UK: +1 415 935 3441\n. Most email providers such as Gmail cap at 25mb, so practically that's the\nmax for the many people I know who use send-to-kindle email automation.\nRegardless you probably want that regexp in there as it's useful in\nremoving a dangling li.\nOn Thu, May 31, 2018 at 1:51 PM Kovid Goyal notifications@github.com\nwrote:\n\nThe size is chosen per recipe for what works best with most images for\nthat site. 25MB works fine on all readers I know of. file size is not an\nimportant consideration since no reader loads the entire file into memory\nat once. The only constraint on absolute file size is amazons send by email\nlimit, which IIRC is 50MB\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/843#issuecomment-393519711,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwfxUIeIYVw8f-Gwak6KFngXPpSrRks5t3-dmgaJpZM4UU9Ul\n.\n\n\n-- \nrobk@robk.com\nMobile: +44 778 6066411\nWhen outside the UK: +1 415 935 3441\n. I'll check that out.\nFWIW, have you ever considered a style guide for recipes? There seems to be\na lot of inconsistency and would be nice for many authors to have guidance\nfrom you on how you like the code. I appreciate you're very flexible with\nfolks already, so i see it more as a way to improve my own consistency...\nanyways, just a thought. i use the NYTimes and a couple others as my\ngeneral own style guidelines as it stands.\nOn Thu, May 31, 2018 at 2:29 PM Kovid Goyal notifications@github.com\nwrote:\n\nI have already added a fix for the extra li. As for gmail's limit, you\nreally shouldn't be using gmali anyway, it has various other problems. Use\nGMX, which IIRC has a 50MB limit.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/kovidgoyal/calibre/pull/843#issuecomment-393529959,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AASBwf6S1L36wD3XsSmmGI15t--uuI4Nks5t3_AkgaJpZM4UU9Ul\n.\n\n\n-- \nrobk@robk.com\nMobile: +44 778 6066411\nWhen outside the UK: +1 415 935 3441\n. ",
    "botmtl": "I tought everything was perfect but the tests reveal that the series information, when available in the canadian counterpart, is not picked up.  I saw that /gui2/store/amazon_ca_plugin.py has existed for a while, any relation to what I'm trying to do here?. I cannot find a single book on amazon.ca that has series information in it, so closing for now.  . ",
    "kleink": "Thank you. I'll check why the external package got picked up during our build.. @eli-schwartz thank you for elaborating. That's the result of pkgsrc's policy having been applied very generously, which (among other things) aims at having to fix possible security issues once and spare maintainers from having to take care of each and every bundled instance of an issue. That being said, calibre obviously makes a case for such bundling.\nI'll sort these sort these out as time permits (as time permits; I'm not actually affiliated with the pkg), e.g. https://github.com/jsonn/pkgsrc/commit/a202978616045e1eb18e5c1b4369f989860a3a34.. ",
    "Kennyl": "Okay , in case of this, I will await users' feedback for any rollback/ enhancement.. remove_tags won't work for remove div with style criteria, so plaintext replace is done.. Thanks for prompted action.. ",
    "jelly": "I will provide a patch which fixes the old and new situation tonight hopefully.\nFor the include I can just #ifdef them, I just have to figure out how to handle the load(qt_plugin) conditionally.. ",
    "extrowerk": "@kovidgoyal : i'm sure there is a proper way to do this, but as i'm not a developer, i cannot provide much better code.\nI tested the different locking implementations, but had different strange errors, so i decided to go in this way.\nSorry :S . Now with disabled mtp and usb it starts fine, but the ebook-viewer crashing at start. I'll provide more info later.. @kovidgoyal : thanks for your help. I already pushed the changes, and some other brackets too, as i'm not sure if they needed actually or not. If not, we can easily revert the last commit.\nLet me know if you need any changes.. @kovidgoyal : Thank you.. ",
    "ThisIsADogHello": "Using the domain from from_ seems like the best option.\nLooks like the way that that Thunderbird (the mail client that I've been using) generates its message IDs is with a UUID@[from domain].  Using a UUID there seems like the easiest way to make sure that the ID is unique, too.. Alright, this should do a lot better for generating message IDs.  When the from address has a domain in it, they look more or less like any other legit mails', and it's using the safe_localhost function used for figuring out what to HELO with when it has nothing else to go on for a domain.\nAlthough when I was testing with sending emails from a username only, it was also breaking SPF and DKIM, so hopefully a less than ideal message ID in those situations would be the least of a user's problems.. I ended up using parseaddr instead of getaddresses, but it seems to be pretty robust now at parsing out the domain from some malformed inputs for From.  As long as it can make out a domain on the end, it does a pretty good job.  Had to handroll some fixes for it though, as getaddresses/parseaddr only split out the real name and email address parts of a domain, and couldn't find anything that would reliably pull out the domain itself.. ",
    "Sophist-UK": "Ok - have tested it and it doesn't work. the URL change was wrong - underscore has changed to hyphen, but even with that changed it still doesn't work.\nPlease revert and I will try to get it working and submit a new PR.. Goodreads has some commercial sides, but it is not Amazon.\nI would class Goodreads as being to books what MusicBrainz is to music - i.e. a definitive source of information about authors and their books.\nIn my experience, Wikipedia is missing the majority of authors - perhaps it has the most famous (say) 20%, but Goodreads has the vast majority of authors. Why not run from source and give it a try against some better and lesser known authors.. 1. Every large web site has costs - Goodreads is no different, so it shows paid adverts. That is a world of different cf. Amazon which is a sales site pure and simple. Of course things could change in the future. Goodreads might become more commercial, but then again so might Calibre. Amazon could be bought out by Wikipedia and turned into an information site about books and music - very unlikely perhaps, but it could possibly happen.\nI don't personally see the issue with linking to them.\n\nHowever I was unaware that you could change the link through user preferences - so please feel free to close this PR.. Thanks - I missed that. I will see how to fix the issue I have another way.. \n",
    "Steap": "OK, thanks for the tips! I'm going to drop the non-English stores for now, I'm more interested in pushing the new feature. I'll update the PR with a fix for all English Amazon stores.. ",
    "Volkthehunter": "Where is code that makes some text able to jump through pages when clicked? Thank you!\n. This is a code that count times elapsed when reading ebooks.. It needed to input times and after it's elapsed it will print something.\n. checkmodule.py is an accident.. ",
    "majouji": "Ah gotcha - I can do that. FWIW I think it would be worth it to separate the source files from the SVGs you use in the app bundles, but your call. Thanks!. ",
    "tbertels": "Wow, that was fast, thanks!. ",
    "brendoncrawford": "I did try to set max split size to 0, and the errors still occurred.  That is the reason I submitted this.  If you think this pull request is not a good idea, I understand.  I was just trying to scratch my own itch with this.. ",
    "Serized": "Sorry, I forgot to do it...\nI also changed the detection a bit since it showed a price of 0.00 followed with the real price when the book was available for kindle unlimited (it doesn't happen for french in which I did my testing). If you think another color would be better, let me know.. Actually I wanted to change only what's displayed in the global view. This way the data that is in the library isn't changed (if a book is saved as 1.11 before changing the tweak)\nI will look around to change the display in the other places.. It already works for custom column and I don't think I can call the tweak from the content server. And as for the metadata writer, I'm not sure it should be changed. This works for me and I'm not good enough at programming to make big changes ;)\nSo if you don't want to add the change just reject the pull request. Thanks for your time!. ",
    "norbusan": "Thanks for merging.\nChecking with appstreamcli validate ... I still get one warning about the naming of files:\nW - calibre-gui.appdata.xml:calibre-gui.desktop:3\n    The component ID is not a reverse domain-name. Please update the ID and that of \n    the accompanying .desktop file to follow the latest version of the Desktop-Entry \n    and AppStream specifications and avoid future issues.\nDo you want a pull request for this, too?\nNorbert. I thought so and thus refrained from it. Thanks for the quick answer.. ",
    "djh101": "FBReader comes to mind. Fair enough, though (though I'll still be editing my own .desktop files; I like having the brand name in my application names, if only for consistency). . ",
    "harcalion": "Thanks for the feedback @kovidgoyal . I will try to handle the type in read_words_from_html by checking the root variable which doesn't seem to break when it is a plain text file. . My funky EPUB file can be spell checked now. Thanks @kovidgoyal !!. ",
    "juampe": "As I see there are auto checks problems\n```\nFAIL: test_find_identical_books (calibre.db.tests.reading.ReadingTest)\nTest find_identical_books\n\nTraceback (most recent call last):\n  File \"C:\\calibre\\src\\calibre\\db\\tests\\reading.py\", line 694, in test_find_identical_books\n    self.assertEqual(books, find_identical_books(mi, data))\n```\nCertainly I modified some realated methods, but it passes my own test (insert same book, with same title in english and spanish) in my developmenp environment.\nSomeone have some light about this?. ",
    "vmiklos": "Updated patch avoids a code duplication.. ",
    "Geremia": "@kovidgoyal In case the full filename (and not just the book ID) is specified, such as with URLs like:\nhttps://mysite.com/calibre_prefix/get/epub/Name%20of%20Book%20-%20Last,%20First_4357.epub. @kovidgoyal I've taken out the src/calibre/srv/content.py file from the commit.. @kovidgoyal I was able to implement what you didn't decide to pull in my webserver easily:\nProxyPassMatch \"^/calibre_prefix/get/([^/]+)/.*_([0-9][0-9][0-9][0-9])\\..+$\" \"http://localhost:8080/calibre_prefix/get/$1/$2\". ",
    "cemeyer": "Also, merry Christmas \ud83c\udf84 and happy solstice \u2600\ufe0f!. py-sip: Definitely for FreeBSD and likely DragonflyBSD (shared ports collection).  Not sure about NetBSD.  (Those 3 seem to be the BSDs Calibre supports?)\nlibusb: Not sure.\nlibmtp: I think all the BSDs have the same ported libmtp.. I've updated the patch to only affect FreeBSD.. Thanks!. Tested with: FreeBSD CURRENT, Nook Glowlight+.. ",
    "oblongau": "Confirming that Calibre 3.15 in Linux Mint 18.3 64 bit MATE now works correctly. No error messages, and a Calibre icon now appears in the tray. Thanks to all who helped.. ",
    "remggo": "Reading your comments, I thought it would be best to maybe use a ProgressBar instead. That way, there would be no edits to the UI-strings necessary. The function calls that process multiple books are e.g. cache.set_field('author_sort', {bid:args.aus for bid in self.ids}) these? There the progress bar could just increase with self.ids after finishing. That would not look as smooth especially not when only the one of such fields is set, but I think it would be the best option.\nI will start implementing the changes tonight.. Your Idea with the two progress bars sounds very good and it keeps the user informed about the different steps. Will use that, thanks!. ",
    "jceb": "I searched the rest of the code base and found only listen(>0) being used.  In addition, the following didn't work for me with listen(0):\npython\nimport socket\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ns.bind((\"\", 9091))\ns.listen(0)\nFollowed by:\nbash\ntelnet localhost 9091\nI'm running Arch with Kernel 4.14.12-1-ARCH #1 SMP PREEMPT Fri Jan 5 18:19:34 UTC 2018 x86_64 GNU/Linux. ",
    "tenhow": "Hi, Kovid Goyal,  I have a difficult problem to solve, but I have not found a valid solution.\nI would like to sort the book names on the main view by their names.\nAs their names are Chinese, some Chinese numbers are included.\nthe matches are:\n\u4e00 == 1\n\u4e8c == 2\n\u4e09 == 3\n...\nbut the QT default sort is set as (PinYin)\n\u4e00 its 'PinYin'  is 'yi'\n\u4e8c its 'PinYin'  is 'er'\n\u4e09 its 'PinYin'  is 'san'\n...\nSo the numbers are sort using the first letter of the number's 'PinYin' when ascending :\n\u4e8c (2)\n\u4e09 (3)\n\u4e00 (1)\n...\nActually, it is not the right natural number order, I would like to use a custom order function to tell the program to know how to order them, but I failed to find an interface.\nDo you have any solutions on it?. I have tested this tweak just now.  Actually,  it is not for my problem, Although it can sort by Arabic numbers. As my problem is to sort text by Chinese numbers, the app does not know how the Chinese numbers work.. Actually, I have tried to convert Chinese numbers to Arabic numbers with a sequence of regular replace, and I have successfully done it. when I am adding new books, their name would be converted. But I think this is a trick, sometimes, looks not perfectly comfortable to Chinese text. If possible, by making the app knowing Chinese numbers, the text would be more beautiful.\nI found the sort action trigged QTableView's  sortByColumn() method to sort columns.\nAt same time,  I know that in C++ Qt could we can override the QTableView's  sortByColumn() method to custom the sorting,  but I have not found how to hook the PyQt's method. Maybe there are some other method for custom sorting in PyQt. . Thanks, can I hook it?. Thanks, I am reading the relevant codes now.. Hi, Kovid Goyal. I need some help. I need to add python package to Calibre, but I cannot find how to make it? Could you give some help? As Calibre is using an embedded Python interpreter.. No python bin can be found... so python -m pip install makes no sense..... . Thanks. I was not familiar with the mechanism for python import.. And I am adding djvu meta-data reading plugin on my own machine. I use 'djvused' from 'djvuLibre' for reading meta-data and 'ddjvu' for extract top page of djvu file to tiff. Then I use PIL to convert it \nto jpeg as cover data. Now it is working on my machine.\nDoes it possible to add this feature to Calibre master branch? Is it possible to bring 'djvused' and 'ddjvu' with Calibre?. emmm, can it read meta-data from djvu? Sometimes In my case, I modify books by python command in batch and add books in batch. If already exist this feature, can we enable this feature?. I am curious about why no one have added djvu metadata reader.. I have read djvu_input, and it is just calling calibre.*.ui.get_file_type_metadata to get metadata.\n# Set metadata from file.\n        from calibre.customize.ui import get_file_type_metadata\n        from calibre.ebooks.oeb.transforms.metadata import meta_info_to_oeb_metadata\n        mi = get_file_type_metadata(stream, file_ext)\n        meta_info_to_oeb_metadata(mi, oeb.metadata, log)\nas there is no djvu metadata reader.\nin calibre.ebooks.djvu I find you have import ZPCodec and BZZ from djvuLibre.V3.5, rewritten in C. And package in Python.\nSo I do not think it is easy to modify and read metadata for a djvu file without import more parts from djvuLibre.\n. ",
    "dkfurrow": "Hi Kovid;\nWell, I'd be happy to work to fix it, but I'm definitely out of my depth here with respect to the javascript involved.  In any case, if you might have feedback on how to do this, here's what I see.\n1. The link to parse is here\n2. I've attached the raw html I see from chrome, and the response from mechanize.\n3. It appears, based on the console feedback from  loading the link in 1. (which doesn't parse) and the link which created the articles earlier in the script here, which does parse, that the difference is a \"ServiceWorker\" script here, that's only invoked in the page that doesn't parse.  It appears that the function of the script is to 'register' with the main bloomberg.com page.\n4. I can't seem to find a resource on how to load that script as part of the mechanize call (again, little js experience here)..if you can point me to a resource that I haven't seen yet, I'd be happy to take a crack at it, otherwise, I guess the best thing would be to just delete the recipe.\nThanks,\nDale\nbbpage_orig.txt\nbbpage_response.txt\n. Okay, so I went into network inspector--it was a little difficult to see how the load request worked, but there was a specific header there associated with the js execution...so I thought, well, implement the header, see how that goes.\nNow this has taken a turn for the surreal...requests will work, but it doesn't appear that requests is included in calibre... \nso fine, try mechanize and urllib2.\nWell, with the following inputs...\nbb_link = \"http://www.bloomberg.com/view/articles/2018-08-13/ritholtz-s-reads-the-odds-aren-t-looking-good-for-the-economy\"\nheaders = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n                         \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36\"}\nThis works (returns full html)\nimport requests\nr = requests.get(bb_link, headers=headers)\nprint(r)\nprint(r.text)\nThis does not (returns violations of service terms page):\nimport urllib2\nr = urllib2.Request(url=bb_link)\nr.add_header(headers.keys()[0], headers.values()[0])\nresponse = urllib2.urlopen(r)\nprint(response.read())\nThis does not (returns violations of service terms page):\nbr = mechanize.Browser()\nbr.addheaders = headers.items()\nresponse = br.open(bb_link)\nprint(response.read())\nSo, I feel like I'm pretty close here, but very difficult to see what is going on with the website response...maybe some ideas on how to make urllib2 or mechanize respond in the same manner as requests?  I've tried various combinations, tried looking at other recipes, nothing seems to work.. ",
    "flaviut": "Thank you for your detailed comments:\n\n\nthe conversion subsystem (particularly some of the input/output plugins\n   whose code is very old -- for example RTF input and ODT input). And also\n   plugins like MOBI input/output which make extensive use of operations on\n   bytes that py 3 does not support.\n\n\nThe only difference between python2 & python3 that I've found wrt bytes is that\nstr[x] returns str in python2, and bytes[x] returns int in python3.\nI took a quick look at the mobi support, and didn't see anything that would be\na porting problem.\n\n\nThe recipe system -- this requires either porting mechanize to py 3 or\n   writing an mostly API equivalent replacement, I doubt MechanicalSoup will\n   cut it as calibre allows custom recipes, so you cant just port the builtin\n   ones and call it a day.\n\n\nThe way I'd see this being done would be a year-long deprecation\nperiod--convert all internal recipies to MechaincalSoup, and the plugin authors\ncan update their recipes as their target websites change code & require\nmodifications.\n\n\nThe device subsystems: these contain lots of OS and device specific code\n   that is impossible to test thoroughly, and when porting, for exmaple, the\n   wpd C extension you will need to deal witht he fact that windows APIs\n   expect UTF-16 which python 2 string are antively and python 3 strings are\n   not.\nInteracting with the OS generally -- subprocesses, OS specific APIs sunch\n   as winutil/usbobserver etc.\n\n\nI understand; thank you for the warning. I'm not looking forward to dealing\nwith this part.\n\nMy current plan is to simply support python 2 myself, which I already do to\nsome extent, see https://github.com/kovidgoyal/cpython that is much less work\nand less potential for regressions. However, that is not to say I am opposed\nto trying to port calibre to py3 -- it's just a lot of work for very low\nreturn.\n\nI disagree :)\nI believe that being able to share ideas and code with a wider community has\nimportant advantages, even if they are hard to quantify.\n\nI'd estimate it would take a couple of man-years and that is before all the\nregressions.\n\nI think (hope, at least) that this is one of the few instances where the time\ntaken to complete a software project is overestimated :)\n\n\nThe icu module is broken (you cannot just remove the PY >= 3.3 checks) while\n   it will compile with that, the actual logic will not work. You will need to\n   implement proper fixes for it since the existing code is designed to work\n   with either UCS2 or UCS4 python strings.\nReplacing ur'' with r'' is fine for python3 but it breaks in python2 since\n   the strings are no longer unicode,\n\n\nGood points; thank you.\n\n\nRather than eliminating xrange (since that is a performance regression in\n   python 2) create a new xrange builtin for python 3\n\n\nsix.moves.range is the same as xrange in py2 and range in\npy3\n\n\nSimilarly replacing cStringIO with StringIO is a huge performance regression\n   for python 2 Instead you would need to analyze the code where it is used and\n   see if it can be replaced by BytesIO or StringIO\n\n\nsix.moves.StringIO is the same as cStringIO in\npy2.\n\nThere are probably lots more issues. So if you are serious about proceeding\nwith this, I suggest the following approach.\nStart by identifying relatively safe changes to the code base that make it\ncompatible with both py2 and py3. Send PRs for those and I will review and\nmerge them one by one. Get to the point where you can start running the test\nsuite. Then start making changes to get the tests passing on py2 and py3.\n\nGot it.\n\nOh and another huge pain to port to python 3 will be the calibre server, since\nit relies on pretty deep integration with the python socket and ssl modules. In\nparticular all the error handlers will need to be re-written since IIRC in\npython 3 the socket module has very different error semantics, that are also\nplatform dependent.\n\nJust curious, why choose to create a custom HTTP framework? There's plenty of\nother choices for web frameworks in python.\n. Ok, one more question:\nThe logical starting point here seems to be porting setup.py bootstrap to work with python 3. However, setup.py depends on various modules in calibre, so it's not possible to do anything without first porting those portions of calibre.\nDo you have any suggestions on how to handle this situation, or maybe of a module that is more self-contained?. Only what you can see here: https://github.com/kovidgoyal/calibre/pulls?q=is%3Apr+author%3Aflaviut\nI've been busy with real-life stuff, but I should be able to get back into it this month.. > Also, just a note on general principles. I am not a big fan of six. It has burned me in the past with incompatible changes and it is very heavyweight.\nI haven't been using six for very long, so I haven't run into any issues. However, I did take a brief look at six.py, and I don't see anything particularly crazy.\n\nThe calibre codebase does not doa lot of fancy stuff, so what we need for compatibility is only a small subset of six.\n\nThis is definitely true.\n\nI would prefer if we create a dedicated module for it with just what we need, much lighter weight. For an example of such a module, see python-mechanize/mechanize#9 where I wrote one for mechanize\n\nI did take at polyglot.py, but there's a few things I like about six:\n\nonce py2 support is dropped, six makes it easy to just find-replace six.moves. -> <nothing>. polyglot.py imports everything into one namespace, so this is harder.\nhttps://python-modernize.readthedocs.io/en/latest/ uses the six module in its automated conversions to python3, which makes the conversion much easier.\n\n\nI bring this up here because six or a similar library is needed to replace raise JSError(e), None, sys.exc_info()[2] . Sounds good to me. Ping me once you make the release, and I'll be happy to rebase onto current master.. Good catch, I didn't realize that. PR updated to used time.monotonic() in py3.. console\n$ python3 -m timeit -s  'import speedup; v = u\"\ud83d\udca9\"*100000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 5: 367 msec per loop\n$ python3 -m timeit -s  'import speedup; v = u\"a\"*100000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 5: 199 msec per loop\n$ python2 -m timeit -s  'import speedup; v = u\"\ud83d\udca9\"*100000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 3: 586 msec per loop\n$ python2 -m timeit -s  'import speedup; v = u\"a\"*100000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 3: 152 msec per loop. Unicode strings in python 3.3+ are fixed width: see the PyUnicode_New(size, maxchar). maxchar is used to allocate strings with the appropriate character size so that no surrogate pairs are used. For more details, you can take a look at https://www.python.org/dev/peps/pep-0393/. > If you use git blame on the file where it was used, you will see why calibre ships its own: 83151cc\nI did take a look, but I guess I didn't fully understand what was going on. Using memoryviews does appear to be faster:\nconsole\n$ python3 -m timeit -s  'import test; f = test.ReadOnlyFileBuffer(open(\"./rand\", \"rb\").read())' -n 2 'list(test.compress_readable_output(f))'\n2 loops, best of 5: 1.37 sec per loop\n$ python2 -m timeit -s  'import test; f = test.ReadOnlyFileBuffer(open(\"./rand\", \"rb\").read())' -n 2 'list(test.compress_readable_output(f))'\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/timeit.py\", line 322, in main\n    r = t.repeat(repeat, number)\n  File \"/usr/lib/python2.7/timeit.py\", line 230, in repeat\n    t = self.timeit(number)\n  File \"/usr/lib/python2.7/timeit.py\", line 202, in timeit\n    timing = self.inner(it, self.timer)\n  File \"<timeit-src>\", line 6, in inner\n    list(test.compress_readable_output(f))\n  File \"./test.py\", line 67, in compress_readable_output\n    crc = zlib.crc32(data, crc)\nTypeError: crc32() argument 1 must be string or read-only buffer, not memoryview\n\nRegarding this PR, I'd prefer it if we used ispy3 explictly and imported thebuiltin zlib module in that case and used the bundled one otherwise.\n\nI've updated the PR to do this. Yup, and everywhere else too. I forgot to replace the matcher_methods entry with NULL after deleting that. The fixed builds finished just as you posted that.. (and my test script)\n```python\nfrom future import print_function\nfrom matcher import Matcher\nimport os\nDEFAULT_LEVEL1 = '/'\nDEFAULT_LEVEL2 = '-_ 0123456789'\nDEFAULT_LEVEL3 = '.'\nclass CScorer(object):\ndef __init__(\n        self,\n        items,\n        level1=DEFAULT_LEVEL1,\n        level2=DEFAULT_LEVEL2,\n        level3=DEFAULT_LEVEL3\n):\n    print(items)\n    self.m = Matcher(\n        items,\n        level1, level2, level3\n    )\n\ndef __call__(self, query):\n    scores, positions = self.m.calculate_scores(query)\n    for score, pos in zip(scores, positions):\n        yield score, pos\n\ndef get_items_from_dir(basedir, acceptq=lambda x: True):\n    relsep = os.sep != '/'\n    for dirpath, dirnames, filenames in os.walk(basedir):\n        for f in filenames:\n            x = os.path.join(dirpath, f)\n            if acceptq(x):\n                x = os.path.relpath(x, basedir)\n                if relsep:\n                    x = x.replace(os.sep, '/')\n                yield x\ndef main():\n    basedir = input('Enter directory to scan [%s]: ' % os.getcwd()).strip() or os.getcwd()\n    m = CScorer(list(get_items_from_dir(basedir)))\n    while True:\n        query = input('Enter query: ')\n        data = list(m(query))\n        print(data)\nmain()\n``. Hmm, interesting. I've re-run swig (swig -Wall -python swig_chm.i) on the input file, and that also seems to fix the bug--it's probably what I'll do when I do a PR for chm. The currentswig_chm.c` was generated using SWIG 1.3.18, released in 2003, so it's really no surprise that it's causing problems.. Yup, I noticed that and then got caught up in some other tasks. I'll ping you once I've fixed it.. @kovidgoyal should be fixed now, just have to wait for CI to run.\n. What's the rationale in doing\n```c\nif PY_MAJOR_VERSION < 3\ntemp = PyInt_FromLong((long)input_buf[i]);\n\nelse\ntemp = PyLong_FromLong((long)input_buf[i]);\n\nendif\n```\ninstead of\nc\ntemp = PyLong_FromLong((long)input_buf[i]);\n?. sysconfig.get_config_var('BLDLIBRARY') appears to work great in every OS except standard Windows & OSX: https://gist.github.com/flaviut/0e3f87d28583d713e7412c65a4ebce7f\nSince those aren't included under this if, there is no problem :). .foo = has been around since 1999, so I'm not really sure why the verbose and error-prone syntax was previously used here.. ... turns out it's because this is C++ code, and compilers didn't start supporting this until fairly recently. Neither MSVC 2015 or gcc 4.8 can use this syntax. Will revert.. I got -L. on most systems I tested this function on too, although it didn't seem to harm anything at this time.\nWhy getattr(sys, 'abiflags', '') instead of sys.abiflags?. dead code as far as I can tell--a grep shows that it isn't used anywhere.. unicodedata.name() exists in both python2  & 3, but it's way out of date in py2. In any case, I think it's best to use this library for both functions so that they don't fall out of sync.. I was debugging this right before I went to bed, I have no idea how I missed it :). > Do we really need to allocate the buffer twice?\nYes. PyUnicode_New() explicitly says that the objects created are not\nresizeable. Therefore 2 allocations are needed:\n\nthe scratch space in which the filtered data is written\nthe PyObject that is returned\n\nThe python 2 code above digs into cpython implementation details (ans->length\n= j; could be written as PyUnicode_GET_SIZE(ans) = j;).\nThere are a couple other options here:\n - do two passes over the array, first calculating the required length\n - ignore the docs and overwrite the PyUnicode length\n\nAlso I dont like up-converting all strings to UCS 4 internally. It would be\nbad for performance since most XML data will be either ascii or ucs 2 at\nworst.\n\nYou're right, there is significant performance impact:\npy3 gcc-4.8:\nconsole\n$ python -m timeit -s  'import speedup; v = \"a\"*1000000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 5: 2.81 sec per loop\npy2:\nconsole\n$ python -m timeit -s  'import speedup; v = u\"a\"*1000000000' -n 2 'speedup.clean_xml_chars(v)'\n2 loops, best of 3: 1.46 sec per loop\nHowever, most of this worse performance is inside clean_xml, and additional\ncopying is ~8% of the time. \nI'll see what I can do about this.\n. do_check was never anything but 1, so I removed it. I wasn't exactly sure why PyUnicode_CheckExact was used instead of PyUnicode_Check, but I figured that there was some reason, so I left it alone. I can change it to PyUnicode_Check. Yes, you're right. I even looked at the assembly, and was surprised to see that GCC-4.8 doesn't automatically switch to memcpy (although it does use a unrolled loop). you have a tiny typo here, but otherwise LGTM.. ",
    "ofek": "Has there been progress on this?. Keep up the excellent work, thank you!. ",
    "NotAFile": "I'd highly recommend not trying to do this all in one go. Trying to keep up with new changes is usually a relatively futile exercise. In my experience of porting a few projects, it is much more effective to require new code to be at least syntax-compatible with python3 and to then slowly grow out the number of files that are python2+python3 compatible, using tests to ensure anything that has been marked as working does not regress.. ",
    "kruk3t": "\nIt would be nice to actually fix pthread_setname_np not working, can you catch the exception and print it out instead of ignoring it, so we have some idea of why it is failing?\n\nCan't seem to get the exception name to show up. print_exc() always seems to print \"None\" and I don't have the Python extensions for GDB.\nWhile I'm running Calibre 3.38, I have tested Calibre 3.35 on two different systems, of which both are running glibc, and there were no issues. Comparing both versions, the same code remains. Comparing pthread_setname_np between both libc versions, shows that they are more or less identical. It's possible this could be an underlying issue with musl libc.\nFor reference, this is the musl libc's pthread_setname_np, and this is glibc's pthread_setname_np.\nThe exception happens when pthread_setname_np is called with name=0x7fffe2a397c4 \"AllIpAddressesG\" at src/thread/pthread_setname_np.c:20.\nGoing further with GDB, shows that errno was set:\n`(gdb) print ((int(*)())__errno_location)()\n$2 = 11\n(gdb) print (char*)strerror(11)\n$3 = 0x7ffff7fce590  \"Resource temporarily unavailable\" (EAGAIN)`\nI'll get back to you in a few days, when I have more time.. ",
    "artiomn": "\nAs I have explained before I am not willing to have this feature in calibre. There is simply too much prospect of symlinks breaking/books being lost.\n\nI have explained, why this options is useful. This is user's care, how to store his books. Experienced users can make better decision about it, because they know more about their data, than you.\n\nEven with the current design I regularly have to deal with a few \"calibre ate my books\" bug reports every week. I absolutely refuse to change the design of calibre to make such bug reports more likely.\n\nI think, experienced users don't send such bug reports, inexperienced will not use console tool.\nAnd this kind of bug report is a sign of incorrect design.. It's a pity. I think this is not very far-sighted of you. This option is useful, and its absence reduces system's scope of applicability.. > The Calibre structure has to be seen as a black box you shouldn't have to deal with directly, like regular RDBMS do.\nMaybe. If this \"black box\" doesn't double space of my library (I repeat: my current directory structure is necessary). And some interfaces, i.e. calibre-web, directly work with database.\n\nStoring books in a directory tree is simply an efficient way to take advantage of the underlying OS own file storage features.\n\nIt doesn't contradict to the my sentence.\n\nAnyway, you could always take the opposite point of view, and develop a plugin which let calibre do it's job when inserting books but once done, remove the original file and replace it with a symlink.\n\nThis is pervert way to do, what I want. And I will understand users (even experienced), which will write, that \"calibre ate my books\", in this case (i.e., after deleting or moving the database).\nDirect way is allow user to decide, what to do with books.\nI think, that it's difficult to do, by writing a plugin.\nAnd why do I need to write a plugin, where I can add one simple option to modify the general behavior?. ",
    "d-faure": "\nIt's a pity. I think this is not very far-sighted of you. This option is useful, and its absence reduces system's scope of applicability.\n\nThe Calibre structure has to be seen as a black box you shouldn't have to deal with directly, like regular RDBMS do. Storing books in a directory tree is simply an efficient way to take advantage of the underlying OS own file storage features.\nAnyway, you could always take the opposite point of view, and develop a plugin which let calibre do it's job when inserting books but once done, remove the original file and replace it with a symlink.. ",
    "grimreaper": "this seems not right - are you sure about this change?. not a fan of having commented code - likely to be stale and can't be automatically be checked.. "
}