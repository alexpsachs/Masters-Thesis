{
    "YorickPeterse": "Given the input <![CDATA[foo]]> the tokens should be as following:\n[:T_CDATA_START, '<!CDATA[']\n[:T_TEXT, 'foo']\n[:T_CDATA_END, ']]>']\nFor <![CDATA[]]]> this should be as following:\n[:T_CDATA_START, '<!CDATA[']\n[:T_TEXT, ']]']\n[:T_CDATA_END, ']]>']\n. Namespaces should also be supported:\n<fb:p>foo</p>\nThis should result in something like:\n[:T_SMALLER, '<']\n[:T_TEXT, 'fb']\n[:T_COLON, ':']\n[:T_TAG, 'p']\n. Some sketches that more closely resemble the current parsing setup:\n``` ruby\nparser = Oga::XML::Reader.new('bar')\nPull in all nodes.\nparser.each do |node|\nend\nPull in element nodes only.\nparser.each(Oga::XML::Element) do |node|\nend\nPull in element nodes with the name \"foo\"\nparser.each(Oga::XML::Element, 'foo') do |node|\nend\nPull in element nodes with a specific name and attribute\nparser.each(Oga::XML::Element, 'foo', 'class' => 'bar') do |node|\nend\n```\nUnlike Nokogiri the yielded values with be different classes. That is, Nokogiri gives back instances of Nokogiri::XML::Reader whereas Oga will use Oga::XML::Element, etc.\n. Extra note: hierarchy related attributes such as Oga::XML::Element#children won't be set when using this API. I might however add a method to convert a current node into a DOM tree.\n. My preference goes to solving this on lexer level using a flag. This would prevent the need of having a dedicated (or otherwise modified) parser.\n. This is mostly handled on lexer level. The lexer emits closing tags for HTML void elements when HTML lexing mode is enabled. The parser doesn't care about HTML, instead it only cares about valid XML.\n. Worth mentioning: Nokogiri seems to be capable of parsing 100MB of XML ok-ish. That is, it won't get OOM killed but will still use around 1GB of RAM.\n. Also worth mentioning: it seems that even when Oga::Lexer#add_token is a no-op that memory usage explodes. It seems like another part of the lexer is eating all my RAM.\n. First setup for this has been merged into the master branch. This setup makes the lexer return its output on a per token basis instead of returning the result as a whole. \n. While working on the streaming API I began to wonder what the value would be of keeping an AST layer around. \nIf you have a fully stream based setup then an AST doesn't make any sense since you're actively trying to avoid keeping large data structures in memory. To clarify, having a fancy XML pull parsing API doesn't help if your AST parser still builds a gigantic AST that it keeps around until the pull parser is done.\nAs a result I can think of the following two scenarios that take place when parsing XML, both apply to the Racc parser:\n1. The parser directly builds Oga::XML instances (e.g. Oga::XML::Element) instead of Oga::AST::Node instances. This would remove the need for Oga::XML::TreeBuilder and probably would be a bit more efficient as well.\n2. When streaming we still build Oga::XML instances but we don't keep them around. Instead of keeping them around they're sent to a block right away. To prevent Racc from building a tree any callbacks would have to return nil or some other kind of lightweight value.\nThere are two ways of doing this:\n1. Put both mechanisms in the same parser, possibly making it complex and confusing.\n2. Create two separate parsers, one for DOM parsing and one for stream parsing.\nThe benefit of approach 2 is that both parsers only do one thing, making them easier to understand. The downside is that both parsers would have to re-define quite a chunk of Racc related code such as the accepted tokens and the structure of input. I'm not aware of Racc having some kind of inheritance / importing feature similar to Ragel.\nSo to cut a long story short:\n- Should Oga keep an AST layer around if it's not going to be used in its raw form by the user?\n- Should Oga use a single parser for both DOM and stream parsing or two dedicated ones?\ncc @whitequark: I'd love an extra brain/opinion on this as I'm not really sure yet myself.\n. Personal, unrelated note to myself: the lexer is not actually stream based. If you give it a single blob of input the advance method will lex the entire thing instead of on a per token basis. I should use blocks/yield instead.\n. @dsisnero Hm that looks interesting, I'll take a look at it.\n. Note before I go to bed: hacking around with a buffer class that wraps around String#unpack using a sliding window. On a 100 MB XML file String#unpack uses around 890 MB of RAM. Using my buffer class it uses around 65 MB to iterate over every single byte. Downsides of the buffer class is that you can only move forward. For the lexer this shouldn't be a problem since it doesn't do any look-behinds.\n. Prototype of the above:\n`` ruby\ndef memory_usageps -o rss= #{Process.pid}`.strip.to_f\nend\nclass CodepointBuffer\n  SIZE = 1024\ndef initialize(input)\n    @input = input\n    @index = 0\nmove_window(@index)\n\nend\ndef move_window(index)\n    @maximum = index + SIZE\n    @window  = @input[index...@maximum].unpack('U*')\n  end\ndef \n    if index >= @maximum\n      move_window(index)\n    end\nreturn @window[index - SIZE]\n\nend\ndef length\n    return @input.length\n  end\nend\nxml       = File.read('/home/yorickpeterse/Downloads/big.xml')\nstart_mem = memory_usage\nnumbers = CodepointBuffer.new(xml)\nindex   = 0\nwhile index < numbers.length\n  numbers[index]\n  index += 1\nend\ndiff_mb = ((memory_usage - start_mem) / 1024).round(2)\nputs \"Usage: #{diff_mb} MB\"\n```\nThe big XML file in question can be found at http://www.ins.cwi.nl/projects/xmark/Assets/standard.gz (100 MB of compressed XML).\nFair warning: I wrote this while half asleep. I might regret that tomorrow.\n. Also worth mentioning: streaming the actual string input (the XML file in this case) is left out on purpose. I'm working with the assumption that streaming the raw input is not always possible (e.g. it's not always an option when dealing with HTTP). If you're reading from a file you can of course gain a lot by reading it in in chunks of N bytes instead of reading it as a whole.\n. Personal note: reducing the window size to 23 (http://patshaughnessy.net/2012/1/4/never-create-ruby-strings-longer-than-23-characters) even further reduces the memory usage. The total runtime is roughly the same as with any other amount.\n. Somewhat revised version of the buffer:\n`` ruby\ndef memory_usageps -o rss= #{Process.pid}`.strip.to_f\nend\nclass CodepointBuffer\n  SIZE = 23\ndef initialize(input)\n    @input = input\n    @index = 0\nmove_window(@index)\n\nend\ndef move_window(index)\n    @maximum = index + SIZE\n    @window  = @input[index...@maximum].codepoints\n  end\ndef \n    if index >= @maximum\n      move_window(index)\n    end\nreturn @window[index - SIZE]\n\nend\ndef length\n    return @input.length\n  end\nend\nxml        = File.read('/home/yorickpeterse/Downloads/big.xml')\nstart_mem  = memory_usage\nstart_time = Time.now.to_i\nnumbers = CodepointBuffer.new(xml)\nindex   = 0\nwhile index < numbers.length\n  numbers[index]\n  index += 1\nend\ndiff_mb   = ((memory_usage - start_mem) / 1024).round(2)\ndiff_time = Time.now.to_i - start_time\nputs \"Usage: #{diff_mb} MB\"\nputs \"Time:  #{diff_time} sec\"\n```\n. Extra personal note: I've decided to write a separate Racc parser for the pull parsing API. Seeing how this parser would completely ignore doctypes and XML declarations as well as not emitting document nodes [1] it doesn't make sense to slap this in the current DOM parser. \nThis will mean some of the grammar rules have to be re-defined but that's a trade-off I'm willing to make. Shared code will be moved into either a base class (yay base classes) or a mixin.\n[1]: None of these are useful when using a pull parser.\n. The streaming API has been implemented in the form of Oga::XML::PullParser. It's a rather low level pull parser that doesn't provide any fancy filtering as discussed in #6 but it's already miles better compared to what Nokogiri offers.\nI'll be making various tweaks but since the brass of the work has been done I'll be closing this issue.\n. Basic foundations for the DOM API are present. A DOM document/tree can be constructed using Oga::XML::TreeBuilder and these nodes can be iterated over. For example, you can request both the parent and child elements of an Oga::XML::Element instance.\nDocument modifications are also supported due to the corresponding attributes being writable from the outside world (thanks to attr_accessor). This is not yet tested explicitly. Converting a document back to XML is also supported. The resulting output will be slightly different than the input depending on whatever default values a certain XML node class might use. For example, Oga::XML::XmlDeclaration uses UTF-8 by default.\nXPath/CSS support is not yet included, I intend to start working on this very soon. When working on XPath/CSS support I'll most likely make some changes to the DOM structure/iteration setup where needed.\n. Personal note: In the bye-ast branch I added some logic to the parser for constructing DOM chains (parent, previous and next nodes). This should be moved out of the parser class into its own thing. \nI whipped together a basic NodeList class which would do this every time you'd add a new node to said list. However, I'm not really sure if such a class gives any benefits over a plain old Array. On the other hand, it might be nice to do something like this:\nruby\nnodes = Oga::XML::NodeList.new(...)\nnodes.attribute('class') # => [\"foo\", \"bar\"]\nCompared to:\nruby\nnodes = [...]\nnodes.map { |node| node.attribute('class') }\n. Personal note: NodeSet#remove doesn't always remove all nodes. This is most likely due to it modifying itself while also iterating over the values.\n. Extra note: I'll have to add various convenience methods to make it easier to inject nodes at specific places. Pseudo code example:\n```\nsome_node = document.xpath('foo/bar/baz')\nanother_node.insert_after(some_node) # puts another_node after some_node\n```\n. Closing this particular issue in favour of more specific ones, this one is far too abstract.\n. Note: Oga will support XPath 1.0 only. XPath 2.0 is a total clusterfuck of a language. It even has static typing for crying out loud. \nXPath 1.0 specification: http://www.w3.org/TR/xpath/\n. Wikipedia article on XPath 1.0 which is a bit easier to grok than the W3 specification: https://en.wikipedia.org/wiki/XPath_1.0#Syntax_and_semantics_.28XPath_1.0.29\n. Note: if possible the lexer/parser should operate on the full syntax elements (see https://en.wikipedia.org/wiki/XPath_1.0#Axis_specifiers) only. The abbreviated form would be converted to the full syntax first before being lexed. A simple string replacement would probably be enough for this.\n. Personal note for the XPath AST:\n```\n/div[@class=\"foo\"]/bar/parent::node()\n(xpath\n  (node-test\n    (name nil \"div\")\n    (predicates\n      (axis \"attribute\" \"class\" (string \"foo\"))))\n  (node-test\n    (name nil \"bar\"))\n  (node-test\n    (axis \"parent\" (call \"node\"))))\ncount(//foo)\n(xpath\n  (call \"count\"\n    (\"axis\" \"descendant-or-self\"\n      (node-test \"foo\"))))\n``\n. For the benchmarks I'll need to re-organize thebenchmark/andprofile/directories so that they are separated per category (xml, xpath and css).\n. It looks like I might have to reconsider my stance on supporting namespace URIs. I completely forgot about thenamespace-uri` function which Oga has to support. A problem with namespace URIs is that there will be a reference between the namespace definition and any references. Take the following XML as an example:\nxml\n<root xmlns:foo=\"bar\">\n  <foo:bar></foo:bar>\n</root>\nHere the <foo:bar> node would contain a reference to the \"foo\" namespace node. The tricky part here is that if the URI in <root> is changed it should also update the URI stored in <foo> and vice-versa. After all, one of the goals of Oga is to make it super easy to modify and re-serialize documents.\nA way to deal with this would be to only store the namespace name in elements. Actual XML::Namespace instances would only be stored in the node that defined the namespaces. Whenever you do something like some_element.namespace this would walk up the document tree to find whatever namespace is attached to the node (based on the namespace name). While this adds some extra overhead it makes modifying namespaces really easy. In other words, the following would work fine:\n``` ruby\nfoo.namespace.uri # => \"bar\"\nroot.namespaces[0].uri = 'baz'\nfoo.namespace.uri # => \"baz\"\n```\nThen calling to_xml on the document would result in the following XML:\nxml\n<root xmlns:foo=\"baz\">\n  <foo:bar></foo:bar>\n</root>\n. @razielgn While I really (really) do appreciate the interest in helping out, I think it might be a bit too early. Lots of parts of Oga will be moving around in the coming weeks most likely, making it rather difficult for others to contribute.  Second, I'm not sure yet what route to go down to with CSS selectors. There are basically two ways of approaching this:\n1. Write a full blown lexer, parser and XPath compiler\n2. Use regular expressions and good ol' String#gsub to compile CSS into XPath\nI'm currently leaning towards the second option as it's both faster (Racc is really slow) and CSS expressions are simple enough that I could probably permit this. From the top of my head, the conversions would be as following:\n```\ndiv a         => //div//a\n.container a  => //*[@class=\"container\"]//a\ncontainer a  => //*[@id=\"container\"]//a\na[href=\"foo\"] => //a[@href=\"foo\"]\n```\nThe only tricky one would be foo, bar as XPath doesn't let you match nodes using multiple names (the or operator returns a boolean, not one of the expressions you give it). Nokogiri appears to simply compile 2 XPath expressions and run them both:\n```\nrequire 'nokogiri'\nNokogiri::CSS.xpath_for('foo, bar') # => [\"//foo\", \"//bar\"]\n``\n. This is in place in the \"css\" branch.\n. My personal issues:\n- Nokogiri is very unstable on Rubinius, see https://github.com/sparklemotion/nokogiri/issues/1047\n- Nokogiri ships libxml and unless you set an environment variable will compile it upon Gem installation. On EC2 this takes around 10 minutes or so.\n- Nokogiri is written in C and a total pain to debug\n- Nokogiri caches a bunch of things (in particular CSS selectors) on class level and uses locks for this to make it \"thread safe\"\n- Nokogiri doesn't offer any sane APIs for parsing large HTML/XML documents. The pull parser only supports XML and the SAX API is a total train wreck\n- Nokogiri's documentation is limited and not very beginner friendly\n. @jrochkind Oga will support both XPath expressions and CSS selectors (these would be compiled into their XPath equivalents and evaluated). Most of the current work is happening on the [xpath](https://github.com/YorickPeterse/oga/tree/xpath) branch. There indeed is still a lot of work to be done.\n. @minad CSS selector support is a work in progress which I can hopefully release in 1-2 months. Progress is tracked at https://github.com/YorickPeterse/oga/issues/11 and https://github.com/YorickPeterse/oga/tree/css\n. Closing this one as I've migrated most of these points to the Wiki page https://github.com/YorickPeterse/oga/wiki/Problems-with-Nokogiri.\n. Moved this to https://github.com/YorickPeterse/oga/wiki/Reading-Material\n. This has been done in thenative-extbranch. Once I've finished testing a few things I'll merge this in into the master branch.\n. The JRuby extension doesn't do anything just yet since it doesn't call back into Ruby. As such the numbers are not really accurate. You're also running the Racc parser benchmark, not just the lexer benchmark. I typically runruby benchmark/lexer/big_xml_average.rbas I haven't taken a proper look at optimizing Racc yet.\n. TheOga::ASTerrors are interesting since I removed that class a while ago. In case you already had a local copy from before the native extension adventures it might be worth runninggit clone -dfxfollowed byrake` on MRI.\n. Looking at the changes I'm going to reject this pull request. The changes you've made undo what I was trying to accomplish by loading things in their current way. That is: no JRuby, Rubinius, Topaz or w/e implementation specific code in the Ruby side of things. By moving the bootstrapping of the JRuby classes to Ruby we now introduce JRuby specific bits where they don't belong. \nHaving to unshift the load path is not ideal but it's something I can live with as it's not strictly JRuby specific. That is, the C extension can be loaded in the exact same way.\n. Thanks! I'll give this a read.\n. Moved this to https://github.com/YorickPeterse/oga/wiki/Reading-Material\n. For this to work the following has to be done:\n- [x] Move %% write init to a separate function in the C/Java code\n- [x] Modify the advance_native methods so that they have their input passed as an argument instead of reading it from the instance\n- [ ] Return tokens instead of yielding them\n. @jrochkind That would be covered by the syntax error handling system.\n. @khoan Said XML parses fine when using the master branch and the latest Gem release (0.2.3). The particular problem wasn't caused due to lack of syntax error handling of sorts, but due to the problem described in #58.\n. @khoan Are these Windows line endings as in \\r\\n or just \\r? The lexer currently doesn't handle the latter (https://github.com/YorickPeterse/oga/blob/31764593070b29fcd16040a6a0bd553e464324cd/ext/ragel/base_lexer.rl#L49) so that might explain the problem. This however should be moved into a separate issue if this is the case.\n. @khoan Could you open a separate issue for this? \n. Closing this one as this should be taken care of (for the most part) by 13e2c3d82ffb9f32b863cb47f6808cf061e07095. Other cases not yet handled should be reported as a separate issue whenever they occur.\n. Worth noting, Chrome doesn't parse the following correctly (as expected):\nhtml\n<!DOCTYPE html>\n<html>\n    <head>\n        <script type=\"text/javascript\">\n            // </script>\n        console.log('Hello')\n        </script>\n    </head>\n    <body>\n        Hello\n    </body>\n</html>\nNokogiri also doesn't parse this properly. When parsing it and returning the result as a String the output is as following:\n``` html\n<!DOCTYPE html>\n\n\n\n\n            // \n\n\n\n        console.log('Hello')\n</p>\n    Hello\n\n\n\n```\nThis is not surprising as the only way to parse this properly would be to include a Javascript parser and use that for script tags. Either way, this means Oga won't cover the above example which should save me quite some work.\n. In other words, a basic Ragel setup would be something like the following:\n``` ragel\nscript := |*\n  ^'<'+ => { callback(\"on_text\", ...) };\n'<' => { fnext main; };\n*|;\nmain := |\n  '' =&gt; { fnext script; };\n</em>|;\n```\n. @jrochkind That would overcomplicate things. It would require a setup similar to the lexer where the grammar is shared and independent of the target language. It would then have to be connected to pure Ruby code to do some more complex handling of actions. I'd much rather fix Racc or replace it with other Ruby code rather than jumping into Antlr, Java and the whole mess that it brings with it.\n. Personal note: currently looking into fully replacing Racc with a custom LL(1) or LALR(1) parser. If I can put together a decent parser I'll also be moving over the CSS and XPath parsers.\n. I managed to hack together a LL(1) parser in C (no Java just yet) which is roughly 1,4x faster than a similar Racc based parser (grammar wise that is). While this isn't the 2x or even 3x I was hoping for, it's a step in the right direction. In the next week or so I aim to clean this up and turn it into a proper Gem (https://github.com/YorickPeterse/ruby-ll) which can then be used to replace the existing Racc parsers.\n. All parsers moved over to ruby-ll. While the performance benefits are relatively minor I'll consider this good enough for now. There are two ruby-ll issues related to performance which I'll be taking a look at:\n- https://github.com/YorickPeterse/ruby-ll/issues/11\n- https://github.com/YorickPeterse/ruby-ll/issues/10</p>\n<p>Other Oga parser performance related problems will get their own GH issues instead of tracking everything in one big issue.\n. This was fixed in 81edce2eb857306082d3a93695a70ce70a9a8b28\n. Two small notes:\n1. There's no need to use Markdown style code blocks (triple backticks) in Git commits, I prefer to keep them as plain text as possible.\n2. While appreciated, there's no need to sign commits with \"Cheers\", \"Enjoy\", etc</p>\n<p>Other than that I'm somewhat surprised this didn't show up earlier. rake-compiler should re-use the same file, thus I'd expect it to crap out during the testing procedure. My guess is that rake-compiler might do so magic for moving <code>.so</code> files around.\n. Could you edit (rebase, or amend since it's the only commit) the commit for those changes? Otherwise I'll rebase it myself later tonight.\n. Merged into commit 0b096dfe25d71115c50af3d7a6171728a21c42a2, thanks!\n. Resolved for the most part in the following commits:\n- ef03a12f99e138b6b44144bdeb50ac1107602fa6\n- 9f6035e7849048f6d0ef23677ebb7f7079e77ddc\n- 98984de5406be6d562144b8742d63f03fdaf831a</p>\n<p>I might in the future transform <code>//foo</code> into <code>descendant-or-self::foo</code> if possible (since the latter is a lot faster) but for now I'll leave things be.\n. &gt; HOWEVER. I recognize this might not be feasible to do (I would be surprised if it had a performance issue though, string.force_encoding is just setting a flag, and is cheap).</p>\n<p>Setting the actual string encoding isn't the biggest problem. The big issue is basically pulling out all String values of a document and setting their encodings correctly. That is: text nodes, element names, attribute names and values, namespace names and URIs, the list goes on. Basically every string ever created in a document would have to use the right encoding.</p>\n<p>The behaviour I'm thinking of (if I were to implement this) is as following:\n1. Get the encoding from the XML declaration tag\n2. For HTML documents, get it from the <code>&lt;meta charset&gt;</code> tag if it exists\n3. Get all String values that need to be encoded and encode them using the encoding found in step 1/2\n4. If this fails (e.g. Ruby doesn't recognize the encoding), fall back to either UTF8 or binary encoding. UTF8 is probably a more reasonable default</p>\n<blockquote>\n<p>Also, if you were interested and thought the code were in such a state where someone else could touch it, I would be willing to try and find time to help with this issue, whether now or later. I do have lots of experience dealing with char encoding in ruby.</p>\n</blockquote>\n<p>The first public release of Oga will be released this Saturday. For XML documents it should be mostly good to go, though I do expect various bugs to pop up. HTML documents require quite a bit more testing and a good error handling system (see #20) before it can be used to parse most HTML documents out there. The biggest helping factor here is for people to simply use Oga and report any bugs/problems they encounter. \n. &gt; Very exciting! With xpaths and everything (but prob not namespace support yet?)? Expect some pull requests from many probably eventually, I think there's interest.</p>\n<p>Both XPath and namespaces are fully supported out of the box.</p>\n<blockquote>\n<p>couldn't you just call force_encoding on the remainder of the input before you consume it, en toto, rather than have to call it on each individual element? That's what I was imagining.</p>\n</blockquote>\n<p>No, this is impossible without over-complicating the lexer. The lexer can read input from either a String or an IO, the latter would be used to stream larger files instead of loading them into memory at once. As a result of this I can't do a naive search for encoding tags in the input. Second, in order to accurately get the encoding from a meta/XML declaration tag you have to parse it. You <em>can</em> set the encoding the moment you bump into an encoding tag, but then you'd still have to re-encode everything that came before.</p>\n<p>I have some ideas on how to tackle this, but it will take some time of careful thinking on how to best approach this problem.\n. I've spent a few hours looking into this and I've decided that I won't implement this for the time being. Ensuring everything is in the same encoding (as specified in the document) is almost as complex as writing an XML parser itself. For example, say the document specifies UTF16 as the encoding, you now have to ensure that:\n- Every setter method (that sets string values, e.g. element names) encodes its values to UTF16\n- Every output method (<code>to_xml</code>, <code>inspect</code>, etc) uses the correct encoding. This is really painful since you can't do something like <code>\"foo\"</code> where <code>foo</code> returns a UTF16 encoded String. This is due to the outer string being UTF8, which can't embed UTF16. As a result you have to do something like <code>\"%s\".encode('UTF-16') % foo</code> which requires extra String allocations\n- Changing the encoding of a single node requires re-encoding the <em>entire</em> document. Considering  certain encodings might not be compatible this isn't something that you can ignore. For example, if 1 deeply nested node is converted to UTF16 you can no longer serialize the document back to XML <em>unless</em> you also convert everything else to UTF16.\n- Calling <code>String#encode</code> results in duplicate String allocations, further increasing memory usage. <code>String#encode!</code> can potentially fuck up user input thus Oga should not use it.</p>\n<p>In short, this is a real pain in the butt.</p>\n<p>UTF8 should be good enough for 99% of all use cases. In cases where one <em>has</em> to parse something in a different encoding they can use an IO instance that has the encoding set. For example:</p>\n<p><code>handle = File.open('/tmp/test.xml', 'rb', :encoding =&gt; 'KOI8-U')\ndoc = Oga.parse_xml(handle)\ndoc.at_xpath('root/text()').text.encoding # =&gt; #&lt;Encoding:KOI8-U&gt;</code>\n. This has been fixed in release 0.1.1:</p>\n<p><code>gem install oga -v 0.1.1</code>\n. I hijacked this into commit b8a82b2094ef9debf7861f246f9b68bd7b8e1081 so I can quickly release it. Thanks for the contribution, I'll put your name in the changelog and all that :)\n. No, this is a problem with Oga. It expects a path to follow the slash (on parser level). It seems I completely overlooked <code>/</code> being also valid on its own.\n. So for these elements that can omit the <code>/</code> I use a set of element names, which can be found here: https://github.com/YorickPeterse/oga/blob/master/lib/oga/xml/lexer.rb#L49. This list however is compared case sensitive, which causes the above problem. I'll fix this later today after I catch some sleep.\n. Argh, I forgot to push the JRuby Gem of 0.1.1. I pushed a version of the JRuby Gem so this should be working now.\n. General note: this pull-request updates the lexer so there should also be a test for this in https://github.com/YorickPeterse/oga/blob/master/spec/oga/xml/lexer/html_void_elements_spec.rb.\n. I'm not a fan of adding an alias just as syntax sugar. In the future I might add <code>to_html</code> if serializing to HTML requires extra bits of code, but until then I'd like to stick with only having <code>to_xml</code>.\n. Oga currently indeed doesn't have a SAX API, though it does have a pull parser (<code>Oga::XML::PullParser</code>). Implementing a SAX parser in a similar fashion shouldn't be too much of a problem.\n. For the time being what you can do is create a class that extends <code>Oga::XML::Parser</code> and overwrite methods such as <code>on_element</code>, <code>on_attribute</code>, etc. You can then use it as following:</p>\n<p>``` ruby\nclass SaxParser &lt; Oga::XML::Parser\n  def on_element(namespace, name, attributes = {})\n    # ...\n  end\nend</p>\n<p>parser = SaxParser.new('xml here')\nparser.parse\n```</p>\n<p>You'll have to make sure that the various <code>on_*</code> methods return <code>nil</code> so that Racc doesn't build a tree of random return values (see the PullParser class for some examples on this).\n. The XML parser does provide the method <code>after_element</code> (https://github.com/YorickPeterse/oga/blob/bd322e8716502cc7be24603db73b43eab93dc47e/lib/oga/xml/parser.y#L401) but it is overwritten by the pull-parser: https://github.com/YorickPeterse/oga/blob/bd322e8716502cc7be24603db73b43eab93dc47e/lib/oga/xml/pull_parser.rb#L173</p>\n<p>Probably the best way here is to not use the pull-parser directly but instead us the setup of the snippet in my previous comment, that way you don't have to re-enable the parts the pull-parser might disable. \n. @krasnoukhov I've just released this in Oga 0.1.2 so you can start playing around if you'd like.\n. @krasnoukhov That would be much appreciated.\n. I've looked into this in the past and did add some code that shows the offending input. For example:</p>\n<p>```\n2.1.2p95 &gt; Oga.parse_xml &lt;&lt;-EOF\n2.1.2p95 * <root>\n2.1.2p95 *   <foo>\n2.1.2p95 *    bar\n2.1.2p95 * </root>\n2.1.2p95 * EOF\nRacc::ParseError: Unexpected $end with value false on line 4:</p>\n<p>1: <root>\n   2: <foo>\n   3: bar\n=&gt; 4: </root>\nfrom /home/yorickpeterse/Private/Projects/ruby/oga/lib/oga/xml/parser.rb:86:in `on_error'\n```</p>\n<p>Sadly Racc's (the parser library that's used) error handling is a bit dodgy and the error messages cryptic. I'll see if I can at least make the error message a bit more clear.\n. cdfeeed85f1649675f26c9b47d9356044f03d65e should provide somewhat more meaningful error messages. It's still not as clear as one might want them to be, but probably as good as we can get it using Racc.\n. The <code>namespace-uri()</code> function itself works fine, Oga just completely ignores the <code>xmlns</code> attribute unless a prefix is given.\n. This is a bug in how Oga register namespaces. Currently it scans for attributes of which the prefix is <code>xmlns</code>. If an attribute has no prefix (in case of <code>xmlns=\"foo\"</code>) it's ignored. I should have a fix for this soon.\n. Argh, you're right. When Oga registers namespaces from attributes it removes them from the attributes list. This is kinda stupid and I'm not sure why I did this in the first place.\n. Regarding the closing tags, this is correct: Oga doesn't handle this. I would have to put some extra logic in to handle certain tags such as <code>script</code> when parsing HTML (<code>&lt;script /&gt;</code> is not valid), otherwise it's fairly easy to implement.</p>\n<blockquote>\n<p>Other discrepencies noticed while preparing this: nokogiri automatically always outputs the &lt;?xml&gt; declaration -- should oga?</p>\n</blockquote>\n<p>No, the rule I have with Oga is to not add any tags that were not present in the input. This means no automatic adding of XML declarations, doctypes, etc. The idea is that <code>raw_xml == Oga.parse_xml(raw_xml).to_xml</code> always returns <code>true</code>.</p>\n<blockquote>\n<p>Nokogiri also adds newlines and indents -- would it make sense for some kind of pretty-printing to be at least an optional feature in oga?</p>\n</blockquote>\n<p>Same here, Oga doesn't add any data for you. I can add a pretty-printer in the future, but it would not be something that would be enabled by default.\n. @jrochkind You can simply check if the document has the <code>xml_declaration</code> attribute set:</p>\n<p>``` ruby\ndocument = Oga.parse_xml('<foo></foo>')</p>\n<p>document.xml_declaration # =&gt; nil</p>\n<p>document.xml_declaration = Oga::XML::XmlDeclaration.new(:version =&gt; '9000')</p>\n<p>document.to_xml # =&gt; \"&lt;?xml version=\\\"9000\\\" encoding=\\\"UTF-8\\\" ?&gt;\\n<foo />\"\n```</p>\n<p>Note here that there <em>is</em> a slight difference between input/output due to the self closing tag. I don't store whether or not a tag is self-closing during parsing. Having said that, I doubt this will cause any problems.\n. @jrochkind The problem is actually quite stupid and easy to fix. There's this code: https://github.com/YorickPeterse/oga/blob/master/lib/oga/xml/attribute.rb#L84-L85</p>\n<p>When you register a namespace, the attribute still sticks around. In this case the attribute's <code>namespace_name</code> is <code>xmlns</code>. The corresponding namespace however is not registered by default (as there's no real benefit to doing this), thus <code>namespace.name</code> results in a nil error.</p>\n<p>There are two ways of solving this:\n1. Always register the <code>xmlns</code> namespace explicitly\n2. Modify the if statement to check if <code>namespace</code> is nil, instead of <code>namespace_name</code></p>\n<p>I'll most likely go with option 2 but I'll do some extra digging to see if that brings any downsides with it.\n. To further clarify, until you do something like <code>&lt;foo xmlns=\"bar\"&gt;</code> Oga doesn't know anything about the <code>xmlns</code> bits. This could be added to <code>XML::Element#available_namespaces</code> so that this method always at least returns the following (instead of an empty Hash):</p>\n<p><code>{'xmlns' =&gt; Namespace(....)}</code></p>\n<p>This however has some problems to it. For example, imagine no namespaces are explicitly defined anywhere. In this scenario every <code>Element#available_namespaces</code> call would return the above Hash. Considering this method recursively calls itself on parent elements, this would result in Oga trying to merge duplicate Hashes a whole bunch of times. This is already the case, but at least the hashes are empty.</p>\n<p>Another problem is that Oga would have to make sure that when a custom default namespace is defined <em>that</em> namespace is used instead of the embedded default one. It's much easier to just not use any default namespace and apply the change mentioned in item 1 above.</p>\n<p>So tl;dr: option 2 just saves quite a bit of work.\n. This has been released in Oga 0.1.3:</p>\n<p><code>gem install oga -v 0.1.3</code>\n. Worth mentioning: the <code>Enumerator</code> class does not define a <code>read</code> method, nor does it have <code>each_line</code>. Thinking of it, the lexer should also be changed not to read an entire line but instead read a small buffer.</p>\n<p>The different scenarios would be as following (in this order):\n- Input is a <code>String</code>? Just yield the whole thing, memory is already allocated anyway\n- Input responds to <code>read</code>? Use this in combination with a fixed buffer size\n- Last option: input responds to <code>each</code>? Use that instead</p>\n<p>The rationale for the 2nd and 3rd option is that reading an entire line can be in-efficient. For example, if a large XML file smacks everything on to a single line then the streaming process wouldn't be very efficient.</p>\n<p>Code wise this would look something like the following:</p>\n<p>``` ruby\nif @data.is_a?(String)\n  yield @data</p>\n<h1>StringIO/IO instances</h1>\n<p>elsif @data.respond_to?(:read)\n  yield @data.read(4) until @data.eof?</p>\n<h1>Enumerator and basically everything else</h1>\n<p>elsif @data.respond_to?(:each)\n  @data.each do |line|\n    yield line\n  end\nend\n```\n. @jrochkind Actually, I have my doubts about that. I'm not a fan of Oga randomly converting certain pieces of data because other libraries do the same (others seem to actually dislike this behaviour of Nokogiri: http://stackoverflow.com/questions/7756123/nokogiri-leaving-html-entities-untouched).</p>\n<p>It's not clear to me from reading the XML specification if this is required per spec, or whether libxml/Nokogiri just does it for the sake of doing it. For example, from the spec:</p>\n<blockquote>\n<p>[...] The ampersand character (&amp;) and the left angle bracket (&lt;) must not appear in their literal form, except when used as markup delimiters, or within a comment, a processing instruction, or a CDATA section. If they are needed elsewhere, they must be escaped using either numeric character references or the strings \" &amp; \" and \" &lt; \" respectively [...]</p>\n</blockquote>\n<p>This states a literal <code>&lt;</code> can not occur in text, except when used for tags. Now the above example basically wipes the floor with this. It takes the properly escaped input, parses it, and then suddenly turns it into something that is completely different. That is, <code>&lt;div&gt;</code> is <em>not</em> the same as <code>&amp;lt;div&amp;gt;</code>. The first one is a tag, the second one is raw text (and should not magically be turned into a tag).</p>\n<p>In other words, unless the spec clearly states the above behaviour of Nokogiri is <em>required</em> I'm not going to implement this. If my input is escaped nicely I expect the resulting output to be exactly the same.\n. Personal note: it seems both Nokogiri on JRuby and Google's Gumbo parser (https://github.com/nevir/ruby-gumbo) convert these particular entities. The latter only does it when you call <code>text</code>  on the text node:</p>\n<p>``` ruby\nrequire 'gumbo'</p>\n<p>content = Gumbo.parse('<content>&lt;div&gt;OMG&lt;/div&gt;</content>').children.first.children.last.children.first</p>\n<p>content.children.first # =&gt; &lt;div&gt;OMG&lt;/div&gt;\ncontent.children.first.text # =&gt; \"<div>OMG</div>\"\n```</p>\n<p>Ox also does this:</p>\n<p><code>ruby\nOx.parse('&lt;content&gt;&amp;lt;div&amp;gt;OMG&amp;lt;/div&amp;gt;&lt;/content&gt;').text =&gt; \"&lt;div&gt;OMG&lt;/div&gt;\"</code></p>\n<p>Still not really clear if this is library convenience, or a requirement of the spec.\n. The kicker seems to be the following:</p>\n<blockquote>\n<p>[Definition: Entity and character references may both be used to escape the left angle bracket, ampersand, and other delimiters. A set of general entities (amp, lt, gt, apos, quot) is specified for this purpose. Numeric character references may also be used; <strong>they are expanded immediately when recognized and must be treated as character data</strong>, so the numeric character references \" &#60; \" and \" &#38; \" may be used to escape &lt; and &amp; when they occur in character data.]</p>\n</blockquote>\n<p>This would suggest that the lexer/parser already has to escape this <em>but</em> treat the input as plain text and not a tag.\n. Looking at the resulting behaviour, it <em>might</em> be best to implement this in <code>Oga::XML::Text#text</code> and not the lexer/parser. Doing it on lexer/parser level would introduce a pretty annoying performance bottleneck as you'd have to loop through the entities to replace for <em>every</em> text node (including the ones you might never use). Second, this would mean that when calling <code>to_xml</code> you'd then have to re-escape the same data.</p>\n<p>So basically the patch that I'm thinking of would be the following:</p>\n<p>``` ruby\nrequire 'htmlentities'</p>\n<p>class Oga::XML::Text\n  def text\n    decoder = HTMLEntities.new</p>\n<pre><code>return decoder.decode(super)\n</code></pre>\n<p>end\nend\n```</p>\n<p>I do still have to look into the htmlentities Gem to see if it's thread-safe and not slow as sin. If so I can probably just steal their entity mapping and re-implement it.\n. &gt; Your quote in the your last comment suggests to me what I'm saying -- expanded immediately when recognized and treated as character data -- does it suggest the reverse to you? heh.</p>\n<p>You're misunderstanding what I wrote. I meant that that quote indicates that the spec indeed requires the entities to be converted.\n. As suspected (and feared), doing this in <code>Oga::XML::Text#initialize</code> pretty much wrecks performance.  I wrote the following benchmark:</p>\n<p>``` ruby\nrequire 'benchmark/ips'</p>\n<p>require_relative 'lib/oga'</p>\n<p>content = ''</p>\n<p>100.times do |n|\n  content &lt;&lt; \"&lt;foo&gt;&amp;#{n}&lt;/foo&gt;\\n\"\nend</p>\n<p>xml = \"<root>#{content}</root>\"</p>\n<p>Benchmark.ips do |bench|\n  bench.report 'converting entities' do\n    Oga.parse_xml(xml)\n  end\nend\n```</p>\n<p>Running this on the master branch yields the following results:</p>\n<p>```\nCalculating -------------------------------------\n converting entities      2443 i/100ms</p>\n<hr />\n<p>converting entities    25721.4 (\u00b11.7%) i/s -     129479 in   5.035509s\n```</p>\n<p>If I then modify the Text class as following:</p>\n<p>``` ruby\nmodule Oga\n  module XML\n    ##\n    # Class containing information about a single text node. Text nodes don't\n    # have any children, attributes and the likes; just text.\n    #\n    class Text &lt; CharacterNode\n      def initialize(options = {})\n        super</p>\n<pre><code>    DECODE_ENTITIES.each do |from, to|\n      @text = @text.gsub(from, to) if @text.include?(from)\n    end\n  end\nend # Text\n</code></pre>\n<p>end # XML\nend # Oga\n```</p>\n<p>Then we get the following instead:</p>\n<p>```\nCalculating -------------------------------------\n converting entities       468 i/100ms</p>\n<hr />\n<p>converting entities     4723.5 (\u00b13.5%) i/s -      23868 in   5.059702s\n```</p>\n<p>In other words, this is about 5,5 times slower than before. I'll have to look into potentially doing this on lexer C/Java level.\n. @billdueber Correct, it would have to be implemented for <code>T_TEXT</code> and <code>T_STRING</code> tokens.\n. @krasnoukhov What output do you <em>expect</em> in this case? I'd actually argue that Oga is doing the right thing here, since the Nokogiri output is fairly useless in this case. The behaviour happens due to Oga simply processing entities one by one. First it will replace <code>&amp;amp;</code> with <code>&amp;</code>, then it will replace <code>&amp;lt</code> with <code>&lt;</code>, etc. As a result the transformation is basically as following:</p>\n<p><code>&lt;content&gt;&amp;lt;pre&amp;gt;{ :foo =&amp;amp;gt; 3, :bar =&amp;amp;gt; 2 }&amp;lt;/pre&amp;gt;&lt;/content&gt;\n&lt;content&gt;&amp;lt;pre&amp;gt;{ :foo =&amp;gt; 3, :bar =&amp;gt; 2 }&amp;lt;/pre&amp;gt;&lt;/content&gt;\n&lt;content&gt;&lt;pre&amp;gt;{ :foo =&amp;gt; 3, :bar =&amp;gt; 2 }&lt;/pre&amp;gt;&lt;/content&gt;\n&lt;content&gt;&lt;pre&gt;{ :foo =&gt; 3, :bar =&gt; 2 }&lt;/pre&gt;&lt;/content&gt;</code>\n. This isn't actually related to SAX parsing on its own, it's just that Oga currently leaves XML/HTML entities completely untouched. I'll close this issue in favour of #49 since both revolve around the same subject.\n. @jrochkind The problem then is that your errors can potentially contain thousands of lines of XML. Right now the parser basically takes the current line number and shows the 5 lines before and after it: https://github.com/YorickPeterse/oga/blob/00579eaa8ade8890f73a71b67dd75230abb64b21/lib/oga/xml/parser.y#L267-L305\n. Alternative option: first check for the current element name as-is. If no match is found, <em>then</em> downcase it and check again. This should at least save unneeded allocations for tags such as <code>&lt;br /&gt;</code>.\n. Rescheduling this for 0.3 instead of 0.2. This will require some tweaking of the XML parser which I probably won't have time for in the next 2 weeks.\n. @cielavenir @krasnoukhov commit 57adabc068d3cf0c07633ad6d619442598aaa95c changes the behaviour of <code>after_element</code> so that it always takes a namespace and name (with actual values). This however breaks existing usage of this callback. As such, you'll need to change it so that instead of this:</p>\n<p>``` ruby\ndef after_element(name)</p>\n<p>end\n```</p>\n<p>You're using this:</p>\n<p>``` ruby\ndef after_element(namespace, name)</p>\n<p>end\n```</p>\n<p>Both arguments now also have meaningful values, instead of just <code>nil</code>.\n. @krasnoukhov Yes, I was going to release it this weekend but didn't get to that. I expect to push a new release this Monday evening.\n. @minad It's your PR. I have no problem hijacking it but I'd like to give people the opportunity to contribute code on their own. If it's too much of a fuzz I'll make the changes myself.\n. This indeed is a bug, Nokogiri returns an empty set in the last case.\n. Another case where this is problematic:</p>\n<p>``` ruby\nNokogiri::XML('<root><A></A><E></E><F>yes</F><F>nope</F></root>').xpath('root/A/following-sibling::*[1]') # =&gt; [#<Nokogiri::XML::Element:0x3fd3a245e858 name=\"E\">]</p>\n<p>Oga.parse_xml('<root><A></A><E></E><F>yes</F><F>nope</F></root>').xpath('root/A/following-sibling::*[1]') # =&gt; NodeSet(Element(name: \"E\"), Element(name: \"F\" children: NodeSet(Text(\"yes\"))), Element(name: \"F\" children: NodeSet(Text(\"nope\"))))\n```</p>\n<p>It looks like the predicate is applied to just the node test (\"*\" in this case, or \"a\" in the initial snippet) and not the entire axis.\n. The original issue was solved in b304b8b077059c31b55e782b050e993ce70b91a4, the issue described in my comment sadly still persists.\n. This is probably caused by the predicate being applied to the node test only, and not the entire predicate. That is, it's probably processed as <code>(following-sibling)::(*[1])</code> instead of <code>(following-sibling::*)[1]</code>.\n. This has been fixed on the \"css\" branch, which will be released this weekend.\n. @jrochkind While correct as far as I can tell from the spec, it's extremely confusing. I can guarantee I'll have to re-answer questions regarding this over and over again. Either I'll fix it code wise, or document it. I haven't decided yet.</p>\n<p>Personal note: when using an explicit, alternative default namespace the method <code>Namespace#name</code> returns \"xmlns\". As such one could also query a document using <code>xmlns:foo</code> instead of <code>*:foo</code>.\n. Personal note: since XPath predicates are applied <em>after</em> a node test one can not use something like <code>foo[namespace-uri() = \"...\"]</code> to get nodes with a different default namespace. The wildcard hack is exactly that: a hack, it should not be relied upon. In fact, it's actually a bug due to the way namespace matching currently works (default namespaces have the name/prefix \"xmlns\", meaning only a \"*\" or \"xmlns\" prefix would match).</p>\n<p>The only sane way to handle this is to allow the <code>xpath</code> method to set/change the default namespace used for a query. This namespace would <em>only</em> be used when handling nodes with an explicitly defined default namespace. That is, you'd do something like <code>xpath('foo', {}, 'bar')</code> (here \"bar\" is the default namespace). You would still be able to query non namespaced elements just fine, but elements with another default namespace would be matched only if said namespace matches the given one.\n. On second though, when setting a default namespace in the <code>xpath</code> method it should most likely <em>always</em> be applied, instead of only being applied to namespaced elements. The former is much more confusing and contradicts behaviour specified in the XPath/XML specifications.</p>\n<p>So basically <code>xpath('foo', {}, 'bar')</code> would mean \"Get all foo elements with a default namespace URI of \"bar\".\n. Tagging this as both a bug and a feature. It's a bug because there's currently no stable/sane way to query elements with a default namespace (the wildcard hack will be removed) and this is broken behaviour. It's a feature to allow users to set a default namespace when querying.\n. @jrochkind  You're missing the point of the change I'm discussing, at least I think so. The change I'll be making is as following:\n1. By default, querying elements with a different default namespace will work as it does right now. That is, it basically won't ever return results (this matches Nokogiri behaviour).\n2. If you want to query elements with a different default namespace, you'd be able to do so. This would <em>only</em> return the nodes inside that default namespace.\n3. Querying elements using namespace URIs still works just fine and can be done using the XPath <code>namespace-uri()</code> function. This will require either a namespace prefix wildcard or the name in the query, this matches Nokogiri behaviour.</p>\n<p>Code mockup of the above:</p>\n<p><code>ruby\nOga.parse_xml('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('foo')                                  # =&gt; NodeSet()\nOga.parse_xml('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('foo[namespace-uri() = \"bar\"]')         # =&gt; NodeSet()\nOga.parse_xml('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('foo', nil, 'bar')                      # =&gt; NodeSet(Element(name: \"foo\" ...))\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('foo')                            # =&gt; NodeSet()\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('x:foo')                          # =&gt; NodeSet(Element(name: \"foo\" ...))\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('foo[namespace-uri() = \"bar\"]')   # =&gt; NodeSet()\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('x:foo[namespace-uri() = \"bar\"]') # =&gt; NodeSet(Element(name: \"foo\" ...))\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('x:foo[namespace-uri() = \"baz\"]') # =&gt; NodeSet()\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('*:foo[namespace-uri() = \"bar\"]') # =&gt; NodeSet(Element(name: \"foo\" ...))\nOga.parse_xml('&lt;x:foo xmlns:x=\"bar\"&gt;&lt;/x:foo&gt;').xpath('*:foo[namespace-uri() = \"baz\"]') # =&gt; NodeSet()</code>\n. The namespace mapping is one way of doing it, but it's nothing you can't already solve using vanilla XPath, although it would be a bit verbose (that's an understatement):</p>\n<p>``` ruby\nxml = &lt;&lt;-EOF.strip\n<root xmlns=\"http://example.org/top\">\n  <node>top</node>\n  <container xmlns=\"http://example.org/bottom\">\n    <node>bottom</node>\n  </container>\n</root>\nEOF</p>\n<p>Oga.parse_xml(xml).xpath('<em>[local-name() = \"root\" and namespace-uri() = \"http://example.org/top\"]/</em>[local-name() = \"container\"]/*[local-name() = \"node\" and namespace-uri() = \"http://example.org/bottom\"]')\n```</p>\n<p>This would return the following:</p>\n<p><code>ruby\nNodeSet(Element(name: \"node\" namespace: Namespace(name: \"xmlns\" uri: \"http://example.org/bottom\") children: NodeSet(Text(\"bottom\"))))</code></p>\n<p>This is quite verbose but supported. While the Nokogiri API makes this a bit easier it gives the impression that you're somehow querying elements with a prefix when in reality it's a shortcut for the above XPath. One of the areas the Nokogiri API falls short in is the following:</p>\n<p>``` ruby\nxml = &lt;&lt;-EOF.strip\n<root xmlns:x=\"ns1\">\n  <first xmlns=\"ns2\">\n    <x:first>20</first>\n  </first>\n</root>\nEOF</p>\n<p>Nokogiri::XML(xml).xpath('root/x:first/x:first', 'x' =&gt; 'ns2')\n```</p>\n<p>In order to query the outer <code>&lt;first&gt;</code> element we use the mapping API, assigning the \"ns2\" prefix to \"x\". This however prevents you from querying the inner <code>&lt;x:first&gt;</code> element as its namespace is overwritten using the custom prefix. You <em>could</em> use a different prefix but then you'd always have to ensure it's unique to all the other prefixes you might query.</p>\n<p>I <em>could</em> leave the \"xmlns\" name hack I mentioned above in place, allowing you to query things using <code>*:root[namespace-uri() = \"http://example.org/top\"]</code> but I'm not sure about this. If I leave it I'll have to make sure it's very clearly documented as being an Oga specific feature.</p>\n<p>I won't be changing this in the next few days as I'm still working on CSS selector support, this should give me some time to think about it. Rest assured, I'll make sure that it's possible to perform strict querying of namespaced elements, one way or another. I'm however not a fan of the Nokogiri way of doing it.\n. &gt; You don't need to use the same prefixes as in the original document, you don't even need to know what the prefixes in the original document were, and it doesn't matter if you collide with them or not. You specify what namespace URI's you wish to query and you query them.</p>\n<p>You do, as shown in the example I gave above. Basically what the snippet does is assign \"virtual\" virtual namespace prefixes coupled to a given namespace URI. In my example this doesn't work if multiple steps use the same prefix in a query, but one of them is a virtual prefix. In such a case the virtual one would always take precedence. </p>\n<p>Lets go through some examples. To clarify what I'm talking about. First one:</p>\n<p><code>ruby\nNokogiri::XML('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('foo') # =&gt; []</code></p>\n<p>Due to <code>&lt;foo&gt;</code> having a different default namespace it's not returned, this is expected and all is well. Nokogiri allows you to do the following in case you <em>do</em> want it to be returned:</p>\n<p><code>ruby\nNokogiri::XML('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('bacon:foo', 'bacon' =&gt; 'bar') # =&gt; [#&lt;Nokogiri::XML::Element:0x3fc4063c5780 name=\"foo\" namespace=#&lt;Nokogiri::XML::Namespace:0x3fc4063c571c href=\"bar\"&gt;&gt;]</code></p>\n<p>Here we create a \"virtual\" namespace prefix called \"bacon\" and map it to the URI \"bar\", just for this query. We can then match all elements that share the same namespace URI. This is effectively the same as the following:</p>\n<p><code>ruby\nNokogiri::XML('&lt;foo xmlns=\"bar\"&gt;&lt;/foo&gt;').xpath('*[local-name() = \"foo\" and namespace-uri() = \"bar\"]') # =&gt; [#&lt;Nokogiri::XML::Element:0x3fc4063b90d4 name=\"foo\" namespace=#&lt;Nokogiri::XML::Namespace:0x3fc4063b9098 href=\"bar\"&gt;&gt;]</code></p>\n<p>The virtual namespace example becomes problematic in the following example:</p>\n<p><code>ruby\nNokogiri::XML('&lt;foo xmlns=\"bar\" xmlns:bacon=\"baz\"&gt;&lt;bacon:foo&gt;bacon!&lt;/bacon:foo&gt;&lt;/foo&gt;').xpath('bacon:foo/bacon:foo', 'bacon' =&gt; 'bar') # =&gt; []</code></p>\n<p>You can solve this by using a different virtual prefix:</p>\n<p><code>ruby\nNokogiri::XML('&lt;foo xmlns=\"bar\" xmlns:bacon=\"baz\"&gt;&lt;bacon:foo&gt;bacon!&lt;/bacon:foo&gt;&lt;/foo&gt;').xpath('spam:foo/bacon:foo', 'spam' =&gt; 'bar', 'bacon' =&gt; 'baz') # =&gt; [#&lt;Nokogiri::XML::Element:0x3fc4063722b0 name=\"foo\" namespace=#&lt;Nokogiri::XML::Namespace:0x3fc40637224c prefix=\"bacon\" href=\"baz\"&gt; children=[#&lt;Nokogiri::XML::Text:0x3fc406371cfc \"bacon!\"&gt;]&gt;]</code></p>\n<p>This however requires that the virtual prefixes you declare do not collide with any prefixes declared in the document. I'm not sure how realistic it is for somebody to run in this problem, but I'd rather not make it possible at all. As such I'm reluctant to add an API similar to this. I might not even add the default namespace API I mentioned earlier, I've yet to decide on this.\n. The tl;dr is: I'm not a fan of the Nokogiri API because it 1) re-implements what is already available 2) can cause unexpected behaviour. I'll see if I can come up with something better, or at the very least add some proper documentation on how to deal with this in user code.\n. You just stated exactly what I said above (though I suspect I phrased it in a confusing manner): that you need to make sure that whatever virtual/query-context prefix you use is unique. </p>\n<p>It collides with the document in the sense that if you define virtual prefix \"X\" it will take precedence over document prefix \"X\" in your query. I don't want to implement an API where one has to make sure their prefixes are unique and what not when XPath already provides a perfectly fine way of dealing with default namespaces.\n. @jrochkind Not to be rude, but this isn't really going anywhere. If you'd like we can further discuss this on IRC (<code>#rubinius</code> or <code>#ruby-lang</code> on Freenode) as I feel it might be a bit easier to discuss it there. I'm typically around between 09:00 and 20:00 UTC.\n. Shelving this one for the time being. While not as easy to read the XPath specification is sort of ok. The lexer, parser and evaluator of Oga should also provide some more insights for those wishing to learn more about XPath. In the future I might write some sort of alternative specification, but for now I'll leave it as it is.\n. This has been taken care of in the master branch.\n. No, this is not how the particular problem should be solved. For one, <code>DECODE_MAPPING</code> is meant to be a Hash and not an Array (Hash key order is guaranteed since &gt;= 1.9). Also, using <code>DECODE_MAPPING.reverse.map(&amp;:reverse)</code> just to invert things is a massive overkill. </p>\n<p>Last, simply changing the order of <code>DECODE_MAPPING</code> will alter the behaviour when serializing back to XML, though it seems none of the specs failed as a result (which means I need to write better specs).</p>\n<p>I'll take a look at this myself to see what's the best way of solving this, thanks for looking into it though.\n. <code>Hash#invert</code> swaps the keys with values, it doesn't re-order them in any way. For example:</p>\n<p><code>ruby\n{:a =&gt; 10, :b =&gt; 20}.invert # =&gt; {10=&gt;:a, 20=&gt;:b}</code></p>\n<p>This was intentional, the order of the keys was supposed to be fixed, they merely needed to be inverted with their values. If the actual order also has to be inverted I'm not sure about. I vaguely recall there was some cases where the current order was very important, but either that was fixed or I never added a test for it. Either way, I have to do some digging to see what exactly required this particular setup.\n. Right, that does clear things up a bit. I'll take a look at this before the upcoming release, considering the entity tests are pretty darn basic I need to take a good look at this anyway.\n. This is most likely the same problem as described in https://github.com/YorickPeterse/oga/issues/58 but for doctype/entity declarations. The culprit is probably the following line: https://github.com/YorickPeterse/oga/blob/f88df486bac076b0a1abeb3cfd544dbb8f2e6d2b/ext/ragel/base_lexer.rl#L195.</p>\n<p>Breaking up the doctype rules in a similar fashion as I did with attribute values should solve the problem. I'll take a look at this in the coming days.\n. Worth noting: this particular problem can in theory also occur on JRuby (or any other implementation for that matter), as it also did in #58. \n. This is due to <code>Element#inner_text=</code> only removing text nodes, instead of removing all nodes.\n. If you want to replace an entire node's content with <em>just</em> text, you should patch <code>#inner_text=</code> for this. Currently this replaces text nodes as following: https://github.com/YorickPeterse/oga/blob/cbb2815146a79805b8da483d2ef48d17e2959e72/lib/oga/xml/element.rb#L215-L217. The simplest way of fixing this is to simply remove the <code>if child.is_a?(Text)</code> condition. This can then, if needed, be extracted into <code>Oga::XML::NodeSet#clear</code>, which would basically do just that. Don't forget to update the tests accordingly.</p>\n<p>Regarding your snippets, what exactly are you trying to achieve? Are you trying to add a chunk of XML/HTML into an element using a String? I don't want an <code>inner_html=</code> method in the Element class as the name makes no sense for non HTML documents. However, I don't oppose the idea of being able to inject a String into an Element (by having the String parsed first), it just needs a good method name that indicates it takes a String and not an Element/NodeSet.\n. And regarding Text objects, you can't use these to inject HTML/XML as they indeed escape characters such as <code>&lt;</code> and <code>&amp;</code>. After all, they're text nodes and not elements.\n. On second thought, allowing elements to be updated using strings might be quite difficult. If an element was parsed using the HTML parser then this particular feature should use the HTML parser. On the other hand, if the regular XML parser was used then it should be used here as well. While <code>Document#type</code> returns <code>:xml</code> or <code>:html</code> based on the used parser, it's required that an Element always has an associated Document. This means the code not only has to choose the correct parser, but also fall back to the XML parser in case there was none. Code wise this roughly translates to the following:</p>\n<p>``` ruby\ndef inner_xml=(string)\n  root = root_node</p>\n<p>if root.is_a?(Document) and root.type == :html\n    parser = HTML::Parser\n  else\n    parser = Parser\n  end</p>\n<p>@children = parser.new(string).parse.children\nend\n```</p>\n<p>Note that the ownership of the new NodeSet in <code>@children</code> would have to be set correctly as otherwise removing nodes won't work properly.\n. @cj Do you want to tackle this, or shall I do this myself?\n. What exactly do you mean with manipulating the <code>&lt;body&gt;</code> element?\n. Well, there are two things with your example:\n1. You're not storing the document/elements anywhere (in a variable that is)\n2. You're not serializing things back to XML/HTML</p>\n<p>As an example:</p>\n<p><code>$ pry -r ./lib/oga\n2.1.4p265 &gt; document = Oga.parse_html('&lt;body&gt;foo&lt;/body&gt;')\n=&gt; Document(\n  children: NodeSet(Element(name: \"body\" children: NodeSet(Text(\"foo\"))))\n)\n2.1.4p265 &gt; document.at_css('body')\n=&gt; Element(name: \"body\" children: NodeSet(Text(\"foo\")))\n2.1.4p265 &gt; document.at_css('body').inner_text = 'bar'\n=&gt; \"bar\"\n2.1.4p265 &gt; document\n=&gt; Document(\n  children: NodeSet(Element(name: \"body\" children: NodeSet(Text(\"bar\"))))\n)\n2.1.4p265 &gt; puts document.to_xml\n&lt;body&gt;bar&lt;/body&gt;</code>\n. I'm still not following, the following works (except for the part where <code>inner_text</code> doesn't remove <em>all</em> nodes):</p>\n<p>``` ruby\nrequire_relative 'lib/oga'</p>\n<p>document = Oga.parse_html(DATA)</p>\n<p>document.at_css('body').inner_text = 'foo'</p>\n<p>puts document.to_xml</p>\n<p><strong>END</strong>\n&lt;!DOCTYPE html&gt;\n<html lang=\"en\"></p>\n<p><head></p>\n<pre><code>&lt;meta charset=\"utf-8\"&gt;\n&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt;\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;\n&lt;meta name=\"description\" content=\"\"&gt;\n&lt;meta name=\"author\" content=\"\"&gt;\n\n&lt;title&gt;Freelancer - Start Bootstrap Theme&lt;/title&gt;\n\n&lt;link href=\"http://fonts.googleapis.com/css?family=Montserrat:400,700\" rel=\"stylesheet\" type=\"text/css\"&gt;\n&lt;link href=\"http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic\" rel=\"stylesheet\" type=\"text/css\"&gt;\n\n&lt;!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --&gt;\n&lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt;\n&lt;!--[if lt IE 9]&gt;\n    &lt;script src=\"https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js\"&gt;&lt;/script&gt;\n&lt;![endif]--&gt;\n</code></pre>\n<p></head></p>\n<p><body>\n  <nav class=\"navbar navbar-default navbar-fixed-top\">\n      <div class=\"container\">\n          <div class=\"navbar-header page-scroll\">\n              <button type=\"button\" class=\"navbar-toggle\" data-toggle=\"collapse\" data-target=\"#bs-example-navbar-collapse-1\">\n                  <span class=\"sr-only\">Toggle navigation</span>\n                  <span class=\"icon-bar\"></span>\n                  <span class=\"icon-bar\"></span>\n                  <span class=\"icon-bar\"></span>\n              </button>\n              <a class=\"navbar-brand\" href=\"#page-top\">Start Bootstrap</a>\n          </div></p>\n<pre><code>      &lt;div class=\"collapse navbar-collapse\" id=\"bs-example-navbar-collapse-1\"&gt;\n          &lt;ul class=\"nav navbar-nav navbar-right\"&gt;\n              &lt;li class=\"hidden\"&gt;\n                  &lt;a href=\"#page-top\"&gt;&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#portfolio\"&gt;Portfolio&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#about\"&gt;About&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#contact\"&gt;Contact&lt;/a&gt;\n              &lt;/li&gt;\n          &lt;/ul&gt;\n      &lt;/div&gt;\n  &lt;/div&gt;\n</code></pre>\n<p></nav>\n</body></p>\n<p></html>\n<code>``\n. Whoops, the usage of</code>DATA<code>apparently is different depending on where you read from it. Saving the HTML in</code>/tmp/test.rb` and using the following script:</p>\n<p>``` ruby\nrequire 'oga'</p>\n<p>document = Oga.parse_html(File.open('/tmp/test.html', 'r'))</p>\n<p>document.at_css('body').inner_text = 'foo'</p>\n<p>puts document.to_xml\n```</p>\n<p>Outputs this:</p>\n<p>``` html\n&lt;!DOCTYPE html&gt;\n<html lang=\"en\"></p>\n<p><head></p>\n<pre><code>&lt;meta charset=\"utf-8\" /&gt;\n&lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" /&gt;\n&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" /&gt;\n&lt;meta name=\"description\" content=\"\" /&gt;\n&lt;meta name=\"author\" content=\"\" /&gt;\n\n&lt;title&gt;Freelancer - Start Bootstrap Theme&lt;/title&gt;\n\n&lt;link href=\"http://fonts.googleapis.com/css?family=Montserrat:400,700\" rel=\"stylesheet\" type=\"text/css\" /&gt;\n&lt;link href=\"http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic\" rel=\"stylesheet\" type=\"text/css\" /&gt;\n\n&lt;!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries --&gt;\n&lt;!-- WARNING: Respond.js doesn't work if you view the page via file:// --&gt;\n&amp;lt;!--[if lt IE 9]&amp;gt;\n    &lt;script src=\"https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js\"&gt;&lt;/script&gt;\n    &lt;script src=\"https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js\"&gt;&lt;/script&gt;\n&amp;lt;![endif]--&amp;gt;\n</code></pre>\n<p></head></p>\n<p><body>  <nav class=\"navbar navbar-default navbar-fixed-top\">\n      <div class=\"container\">\n          <div class=\"navbar-header page-scroll\">\n              <button type=\"button\" class=\"navbar-toggle\" data-toggle=\"collapse\" data-target=\"#bs-example-navbar-collapse-1\">\n                  <span class=\"sr-only\">Toggle navigation</span>\n                  <span class=\"icon-bar\"></span>\n                  <span class=\"icon-bar\"></span>\n                  <span class=\"icon-bar\"></span>\n              </button>\n              <a class=\"navbar-brand\" href=\"#page-top\">Start Bootstrap</a>\n          </div></p>\n<pre><code>      &lt;div class=\"collapse navbar-collapse\" id=\"bs-example-navbar-collapse-1\"&gt;\n          &lt;ul class=\"nav navbar-nav navbar-right\"&gt;\n              &lt;li class=\"hidden\"&gt;\n                  &lt;a href=\"#page-top\"&gt;&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#portfolio\"&gt;Portfolio&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#about\"&gt;About&lt;/a&gt;\n              &lt;/li&gt;\n              &lt;li class=\"page-scroll\"&gt;\n                  &lt;a href=\"#contact\"&gt;Contact&lt;/a&gt;\n              &lt;/li&gt;\n          &lt;/ul&gt;\n      &lt;/div&gt;\n  &lt;/div&gt;\n</code></pre>\n<p></nav>foo</body></p>\n<p></html>\n```</p>\n<p>In other words, <code>inner_text=</code> <em>does</em> add \"foo\" to the <code>&lt;body&gt;</code> element, it just doesn't remove <em>all</em> existing tags prior to doing so (which I've already stated is a bug).\n. I looked into this in the past, in fact it was one of my original ideas to use this Gem (see https://github.com/YorickPeterse/oga/issues/49#issuecomment-56546643). At that time I decided not to use it due to the sheer complexity of the library and the massive performance overhead it introduces. </p>\n<p>As an example, take the benchmark <code>benchmark/xml/lexer/string_average_bench.rb</code>. Running this on the current master branch produces the following timings:</p>\n<p>```\nIteration: 1: 0.677\nIteration: 2: 0.671\nIteration: 3: 0.671\nIteration: 4: 0.671\nIteration: 5: 0.674\nIteration: 6: 0.671\nIteration: 7: 0.67\nIteration: 8: 0.672\nIteration: 9: 0.675\nIteration: 10: 0.671</p>\n<p>Iterations: 10\nAverage:    0.672 sec\n```</p>\n<p>Applying your patch and re-running the benchmark in turn results in the following:</p>\n<p>```\nIteration: 1: 1.056\nIteration: 2: 1.051\nIteration: 3: 1.051\nIteration: 4: 1.054\nIteration: 5: 1.054\nIteration: 6: 1.08\nIteration: 7: 1.082\nIteration: 8: 1.079\nIteration: 9: 1.059\nIteration: 10: 1.085</p>\n<p>Iterations: 10\nAverage:    1.065 sec\n```</p>\n<p>In other words, the change makes Oga's lexer about 1,6 times slower than before. At least memory usage is still consistent (measured using <code>profile/xml/lexer/big_xml.rb</code>).</p>\n<p>Looking at all the things the htmlentities Gem is doing this isn't entirely surprising it slows things down. For example:\n- https://github.com/threedaymonk/htmlentities/blob/a68cc5ce9ad6ffaa06623a97d319ead4238bd1a0/lib/htmlentities/encoder.rb#L28-L34\n- https://github.com/threedaymonk/htmlentities/blob/a68cc5ce9ad6ffaa06623a97d319ead4238bd1a0/lib/htmlentities/encoder.rb#L73-L99</p>\n<p>For the last example I sure as hell hope those <code>instance_eval</code> calls are only executed once as its going to make performance suck.</p>\n<p>Considering I wanted the next release to be <em>faster</em> and not slower I'm not a huge fan of this PR.</p>\n<p>As an aside, there are two other things worth mentioning. </p>\n<p>First, the usage of <code>CODER = HTMLEntities.new</code> is not safe at all. While it <em>looks</em> like the <code>HTMLEntities</code> class is thread-safe (https://github.com/threedaymonk/htmlentities/blob/a68cc5ce9ad6ffaa06623a97d319ead4238bd1a0/lib/htmlentities.rb) there's no guarantee it will stay that way. Basically a requirement that I have with Oga, which I <em>should</em> add to the contributing guide, is <em>no</em> usage of global state/objects/whatever <em>unless</em> they are designed to be thread-safe (and can prove this). </p>\n<p>Second, <code>require</code> calls should always go in <code>lib/oga.rb</code> and not in other random files. This too I should add to the contributing guide.</p>\n<p>To summarize, if there was no extra overhead attached to this library I wouldn't really have any problems with it. I don't want to slow Oga down for everybody by default, especially if the feature in question is one I myself don't really rely on. </p>\n<p>Performance wise my goal is to get Oga running at about ~15 MB of XML per second (both lexing and parsing) with the theoretical maximum being 20MB at the moment (due to Ruby's baseline overhead). Until I've achieved that (or something close to it) I can't afford to add anything that slows Oga down. I'll keep this PR open for the time being as I might merge it given I can achieve the above.\n. Worth mentioning: the impact of this is huge due to HTML/XML entity decoding happening for <em>every</em> <code>T_TEXT</code> and <code>T_STRING_BODY</code> node the lexer produces. \n. I added the two notes mentioned above to the contributing guide in 81c49b5101c449a2ed6c33cd9a26860b23678315.\n. Checking if <code>&amp;</code> is indeed a trick that can speed things up when no entities are present. However, for input <em>with</em> entities I still expect a 1,5x decrease in performance. </p>\n<p>As a start we should add a benchmark for lexing data with XML and HTML entities, but I'm not sure how to get a fixture of a decent size (10MB) for this. The current XML fixture was generated using <a href=\"http://www.xml-benchmark.org/downloads.html\">xmlgen</a> but that tool has no option to randomly include entities as far as I know.</p>\n<p>An alternative to using the htmlentities Gem would be to simply rip the entity mapping from some website and use that similar to the existing entities (but <em>only</em> for HTML documents). This will still slow things down, but hopefully it's less than 1,5 times.\n. @jrochkind It's certainly possible, but it would have to be duplicated for both C and Java. An alternative would be to define Ragel rules for every entity and stitch things back together in Ruby, I however doubt this is going to be that much faster.\n. &gt; what do you mean by that? Why is it not used only for HTML documents now?</p>\n<p>What I meant is that HTML entity encoding/decoding should only occur in HTML documents, <em>not</em> XML documents.\n. @krasnoukhov XML only has 5 pre-defined entities listed here http://www.w3.org/TR/REC-xml/#sec-predefined-ent, of which apparently I've forgotten to add 2 to Oga (see #66). Oga is not going to decode/encode <em>HTML</em> entities in <em>XML</em> documents. However, encoding/decoding HTML entities in <em>HTML</em> documents is a different story.</p>\n<p>@jrochkind There being a library for it is one thing, it being usable in Oga's case is an entirely different story. Even then I prefer to <em>not</em> do this in C/Java as it further complicates the codebase. \n. @krasnoukhov This is described in http://www.w3.org/TR/REC-xml/#sec-references. Oga currently doesn't support this, though probably should in the future.\n. Note: according to Wikipedia <code>&amp;apos;</code> should be replaced with <code>'</code> (http://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Predefined_entities_in_XML).\n. Nokogiri deals with the last case as following:</p>\n<p><code>Nokogiri::XML('&lt;foo&gt;&amp;#38;#38;&lt;/foo&gt;').at('foo').text # =&gt; \"&amp;#38;\"</code></p>\n<p>So I suspect the RSpec example here is correct.\n. Other note, the extra <code>context</code> grouping isn't needed in these specs. The spec names are clear enough on their own.\n. I prefer a flat list in this case. I typically only use <code>context</code> when the behaviour of the associated examples is quite different <em>or</em> requires its own before/after blocks. In most cases the structure is as following:</p>\n<p>``` ruby\ndescribe SomeClass do\n  context '#some_method' do\n    before do\n      # ..\n    end</p>\n<pre><code>example 'some test using #some_method' do\n\nend\n</code></pre>\n<p>end\nend\n<code>``\n. Thanks! :+1:\n. Looking into this again as I need support for a bunch of entities (e.g.</code>&nbsp;`). The htmlentities Gem doesn't seem to support all entities so that's not really an option, for example:</p>\n<p><code>ruby\nHTMLEntities.new.decode('&amp;boxvr;') # =&gt; \"&amp;boxvr;\"</code></p>\n<p>which is supposed to give back:</p>\n<p><code>ruby\n[9500].pack('U') # =&gt; \"\u251c\"</code></p>\n<p>As an alternative I'll probably use this list: https://gist.github.com/YorickPeterse/fe37e80c271b3e94f3d7</p>\n<p>One downside is that this will likely slow down the parsing/serialization process quite a bit as the code has to iterate over every Hash value and at minimum check if a value is present (saving unneeded string allocations of <code>String#gsub</code>).\n. The big list in the Gist would indeed only be used for HTML documents. This ensures the performance penalty only applies to HTML documents, but I'd still prefer for it not to be that much slower than it currently is.\n. The fastest way would be to embed the conversion of entities to their \"true\" form in the lexer. This is one of the ideas I have, but since the lexer code is shared between C and Java it's not as trivial to implement as one might hope. The idea I have is basically as following:\n1. In the state machine used for processing text/attribute values a rule for every entity will be added\n2. Said rule will append the entity to some internal array\n3. When generating the tokens for attribute values and/or element text the Ruby code checks this array and <em>only</em> converts the entities that were found</p>\n<p>This process would remove the need for iterating over the entire set. The annoying part is that I'd have to duplicate the entity mapping in 3 places:\n1. In Ruby so certain characters can be converted back into entities\n2. In the XML lexer's \"text\" state machine (used for element text)\n3. In the XML lexer's \"string\" state machine (used for attribute values)</p>\n<p>I'm not sure if Ragel allows me to include other grammars into the body of a state machine, or only at the top level. If this is possible I could move the entity handling to a separate file and include it in both the mentioned state machines.\n. Note to self: this system should ensure that any entities that appear in a <code>&lt;style&gt;</code> or <code>&lt;script&gt;</code> tag are <em>not</em> converted. In other words, the input <code>&lt;style&gt;&amp;amp;&lt;/style&gt;</code> should stay as is and <em>not</em> be converted into <code>&lt;style&gt;&amp;&lt;/style&gt;</code>.\n. Thinking of this, it might actually make more sense to do this lazily in <code>Oga::XML::Text</code> and <code>Oga::XML::Attribute</code> instead of doing this on lexer/parser level. This has numerous benefits:\n1. No performance overhead in the lexer/parser\n2. Keeps the lexer as it is, making my life easier\n3. Code such as <code>Oga::XML::Text.new(:text =&gt; '&amp;quot;').text</code> would actually return <code>'\"'</code> and not <code>'&amp;quot;'</code></p>\n<p>Getting this to work on lexer level is quite painful due to the existing rules used for handling element text and attribute values.</p>\n<p>Doing this post-parsing can be done in two ways:\n1. Simply decode entities every time <code>Text#text</code> and/or <code>Text#to_xml</code> is called\n2. Decode entities once when needed, then cache the result (basically overwriting <code>#text</code>)</p>\n<p>The latter would have to be thread-safe as I do want to allow multiple-threads to read from a document/element without it blowing up. A mutex or a compare-and-swap operation should suffice, but it <em>shouldn't always</em> lock as that will most likely slow things down.\n. Commit regarding <code>rb_intern</code> caching: https://github.com/YorickPeterse/oga/commit/ffb939d48fdf3c00dd549b3adf7d69ac4af24024\n. This is primarily caused due to Racc being slow (see https://github.com/YorickPeterse/oga/issues/23). Besides that Oga also does a substantial amount of work in Ruby (opposed to purely doing it in C/Java like Nokogiri and Ox), meaning things will be a bit slower.\n. Closing this one. With the entities logic moved out of the lexer there's little I think I can do in the lexer itself for the time being. It's quite likely I'll actually have to spend time improving Ruby, or at least Rubinius, to make things go faster here. Having said that, ~480ms for 10MB of XML is not that bad.\n. The following snippet appears to trigger the above parsing error:</p>\n<p><code>html\n&lt;script type=\"text/javascript\"&gt;window.NREUM||(NREUM={});NREUM.info={\"beacon\":\"beacon-5.newrelic.com\",\"errorBeacon\":\"bam.nr-data.net\",\"licenseKey\":\"fcf8d519de\",\"applicationID\":\"13909,11792387,716468\",\"transactionName\":\"NTU0DRQNDwshOmIZBRM3dRAIBgYf\",\"queueTime\":0,\"applicationTime\":202,\"agent\":\"js-agent.newrelic.com/nr-476.min.js\",\"userAttributes\":\"DXgpEBIHQV1mHCUVHBMcNQsDERdFaGo+Ax1UYDwYChEGS2Y6KAEEEykuJhYQDBMrKyIcU0x4Mg0SEllIa2phUhgGeGBbV1pbSXV8f15AR2h0S1RXQUtmPT4VAyk7PRwIFkFdZgUiChgaNjtWU0xTR2wQfEFKVhYzFxMaQx98fhJGRV96GwkWDgYwISoGGQVZb2lOSFFVR2wDBSQ8OnZ6FQ8JBkcDLS4bHl96GREUDQ4Ca3t0XkFYaGtOV0xVUmQbLBYQBDN1TFVVTVRyamFSAxMsMwoPDQ1FfmosRhBCPGpLOgxBGg==\"}&lt;/script&gt;\n&lt;script type=\"text/javascript\"&gt;(window.NREUM||(NREUM={})).loader_config={xpid:\"VQcGQldQAQMJ\"};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o?o:e)},o,o.exports)}return e[n].exports}if(\"function\"==typeof __nr_require)return __nr_require;for(var o=0;o&lt;n.length;o++)r(n[o]);return r}({QJf3ax:[function(t,e){function n(t){function e(e,n,a){t&amp;&amp;t(e,n,a),a||(a={});for(var c=s(e),f=c.length,u=i(a,o,r),d=0;f&gt;d;d++)c[d].apply(u,n);return u}function a(t,e){f[t]=s(t).concat(e)}function s(t){return f[t]||[]}function c(){return n(e)}var f={};return{on:a,emit:e,create:c,listeners:s,_events:f}}function r(){return{}}var o=\"nr@context\",i=t(\"gos\");e.exports=n()},{gos:\"7eSDFh\"}],ee:[function(t,e){e.exports=t(\"QJf3ax\")},{}],3:[function(t){function e(t,e,n,i,s){try{c?c-=1:r(\"err\",[s||new UncaughtException(t,e,n)])}catch(f){try{r(\"ierr\",[f,(new Date).getTime(),!0])}catch(u){}}return\"function\"==typeof a?a.apply(this,o(arguments)):!1}function UncaughtException(t,e,n){this.message=t||\"Uncaught error with no additional information\",this.sourceURL=e,this.line=n}function n(t){r(\"err\",[t,(new Date).getTime()])}var r=t(\"handle\"),o=t(5),i=t(\"ee\"),a=window.onerror,s=!1,c=0;t(\"loader\").features.err=!0,window.onerror=e,NREUM.noticeError=n;try{throw new Error}catch(f){\"stack\"in f&amp;&amp;(t(1),t(4),\"addEventListener\"in window&amp;&amp;t(2),window.XMLHttpRequest&amp;&amp;XMLHttpRequest.prototype&amp;&amp;XMLHttpRequest.prototype.addEventListener&amp;&amp;t(3),s=!0)}i.on(\"fn-start\",function(){s&amp;&amp;(c+=1)}),i.on(\"fn-err\",function(t,e,r){s&amp;&amp;(this.thrown=!0,n(r))}),i.on(\"fn-end\",function(){s&amp;&amp;!this.thrown&amp;&amp;c&gt;0&amp;&amp;(c-=1)}),i.on(\"internal-error\",function(t){r(\"ierr\",[t,(new Date).getTime(),!0])})},{1:8,2:5,3:9,4:7,5:20,ee:\"QJf3ax\",handle:\"D5DuLP\",loader:\"G9z0Bl\"}],4:[function(t){function e(){}if(window.performance&amp;&amp;window.performance.timing&amp;&amp;window.performance.getEntriesByType){var n=t(\"ee\"),r=t(\"handle\"),o=t(2);t(\"loader\").features.stn=!0,t(1),n.on(\"fn-start\",function(t){var e=t[0];e instanceof Event&amp;&amp;(this.bstStart=Date.now())}),n.on(\"fn-end\",function(t,e){var n=t[0];n instanceof Event&amp;&amp;r(\"bst\",[n,e,this.bstStart,Date.now()])}),o.on(\"fn-start\",function(t,e,n){this.bstStart=Date.now(),this.bstType=n}),o.on(\"fn-end\",function(t,e){r(\"bstTimer\",[e,this.bstStart,Date.now(),this.bstType])}),n.on(\"pushState-start\",function(){this.time=Date.now(),this.startPath=location.pathname+location.hash}),n.on(\"pushState-end\",function(){r(\"bstHist\",[location.pathname+location.hash,this.startPath,this.time])}),\"addEventListener\"in window.performance&amp;&amp;(window.performance.addEventListener(\"webkitresourcetimingbufferfull\",function(){r(\"bstResource\",[window.performance.getEntriesByType(\"resource\")]),window.performance.webkitClearResourceTimings()},!1),window.performance.addEventListener(\"resourcetimingbufferfull\",function(){r(\"bstResource\",[window.performance.getEntriesByType(\"resource\")]),window.performance.clearResourceTimings()},!1)),document.addEventListener(\"scroll\",e,!1),document.addEventListener(\"keypress\",e,!1),document.addEventListener(\"click\",e,!1)}},{1:6,2:8,ee:\"QJf3ax\",handle:\"D5DuLP\",loader:\"G9z0Bl\"}],5:[function(t,e){function n(t){i.inPlace(t,[\"addEventListener\",\"removeEventListener\"],\"-\",r)}function r(t){return t[1]}var o=(t(1),t(\"ee\").create()),i=t(2)(o),a=t(\"gos\");if(e.exports=o,n(window),\"getPrototypeOf\"in Object){for(var s=document;s&amp;&amp;!s.hasOwnProperty(\"addEventListener\");)s=Object.getPrototypeOf(s);s&amp;&amp;n(s);for(var c=XMLHttpRequest.prototype;c&amp;&amp;!c.hasOwnProperty(\"addEventListener\");)c=Object.getPrototypeOf(c);c&amp;&amp;n(c)}else XMLHttpRequest.prototype.hasOwnProperty(\"addEventListener\")&amp;&amp;n(XMLHttpRequest.prototype);o.on(\"addEventListener-start\",function(t){if(t[1]){var e=t[1];\"function\"==typeof e?this.wrapped=t[1]=a(e,\"nr@wrapped\",function(){return i(e,\"fn-\",null,e.name||\"anonymous\")}):\"function\"==typeof e.handleEvent&amp;&amp;i.inPlace(e,[\"handleEvent\"],\"fn-\")}}),o.on(\"removeEventListener-start\",function(t){var e=this.wrapped;e&amp;&amp;(t[1]=e)})},{1:20,2:21,ee:\"QJf3ax\",gos:\"7eSDFh\"}],6:[function(t,e){var n=(t(2),t(\"ee\").create()),r=t(1)(n);e.exports=n,r.inPlace(window.history,[\"pushState\"],\"-\")},{1:21,2:20,ee:\"QJf3ax\"}],7:[function(t,e){var n=(t(2),t(\"ee\").create()),r=t(1)(n);e.exports=n,r.inPlace(window,[\"requestAnimationFrame\",\"mozRequestAnimationFrame\",\"webkitRequestAnimationFrame\",\"msRequestAnimationFrame\"],\"raf-\"),n.on(\"raf-start\",function(t){t[0]=r(t[0],\"fn-\")})},{1:21,2:20,ee:\"QJf3ax\"}],8:[function(t,e){function n(t,e,n){var r=t[0];\"string\"==typeof r&amp;&amp;(r=new Function(r)),t[0]=o(r,\"fn-\",null,n)}var r=(t(2),t(\"ee\").create()),o=t(1)(r);e.exports=r,o.inPlace(window,[\"setTimeout\",\"setInterval\",\"setImmediate\"],\"setTimer-\"),r.on(\"setTimer-start\",n)},{1:21,2:20,ee:\"QJf3ax\"}],9:[function(t,e){function n(){c.inPlace(this,d,\"fn-\")}function r(t,e){c.inPlace(e,[\"onreadystatechange\"],\"fn-\")}function o(t,e){return e}var i=t(\"ee\").create(),a=t(1),s=t(2),c=s(i),f=s(a),u=window.XMLHttpRequest,d=[\"onload\",\"onerror\",\"onabort\",\"onloadstart\",\"onloadend\",\"onprogress\",\"ontimeout\"];e.exports=i,window.XMLHttpRequest=function(t){var e=new u(t);try{i.emit(\"new-xhr\",[],e),f.inPlace(e,[\"addEventListener\",\"removeEventListener\"],\"-\",function(t,e){return e}),e.addEventListener(\"readystatechange\",n,!1)}catch(r){try{i.emit(\"internal-error\",[r])}catch(o){}}return e},window.XMLHttpRequest.prototype=u.prototype,c.inPlace(XMLHttpRequest.prototype,[\"open\",\"send\"],\"-xhr-\",o),i.on(\"send-xhr-start\",r),i.on(\"open-xhr-start\",r)},{1:5,2:21,ee:\"QJf3ax\"}],10:[function(t){function e(t){if(\"string\"==typeof t&amp;&amp;t.length)return t.length;if(\"object\"!=typeof t)return void 0;if(\"undefined\"!=typeof ArrayBuffer&amp;&amp;t instanceof ArrayBuffer&amp;&amp;t.byteLength)return t.byteLength;if(\"undefined\"!=typeof Blob&amp;&amp;t instanceof Blob&amp;&amp;t.size)return t.size;if(\"undefined\"!=typeof FormData&amp;&amp;t instanceof FormData)return void 0;try{return JSON.stringify(t).length}catch(e){return void 0}}function n(t){var n=this.params,r=this.metrics;if(!this.ended){this.ended=!0;for(var i=0;c&gt;i;i++)t.removeEventListener(s[i],this.listener,!1);if(!n.aborted){if(r.duration=(new Date).getTime()-this.startTime,4===t.readyState){n.status=t.status;var a=t.responseType,f=\"arraybuffer\"===a||\"blob\"===a||\"json\"===a?t.response:t.responseText,u=e(f);if(u&amp;&amp;(r.rxSize=u),this.sameOrigin){var d=t.getResponseHeader(\"X-NewRelic-App-Data\");d&amp;&amp;(n.cat=d.split(\", \").pop())}}else n.status=0;r.cbTime=this.cbTime,o(\"xhr\",[n,r,this.startTime])}}}function r(t,e){var n=i(e),r=t.params;r.host=n.hostname+\":\"+n.port,r.pathname=n.pathname,t.sameOrigin=n.sameOrigin}if(window.XMLHttpRequest&amp;&amp;XMLHttpRequest.prototype&amp;&amp;XMLHttpRequest.prototype.addEventListener&amp;&amp;!/CriOS/.test(navigator.userAgent)){t(\"loader\").features.xhr=!0;var o=t(\"handle\"),i=t(2),a=t(\"ee\"),s=[\"load\",\"error\",\"abort\",\"timeout\"],c=s.length,f=t(1);t(4),t(3),a.on(\"new-xhr\",function(){this.totalCbs=0,this.called=0,this.cbTime=0,this.end=n,this.ended=!1,this.xhrGuids={}}),a.on(\"open-xhr-start\",function(t){this.params={method:t[0]},r(this,t[1]),this.metrics={}}),a.on(\"open-xhr-end\",function(t,e){\"loader_config\"in NREUM&amp;&amp;\"xpid\"in NREUM.loader_config&amp;&amp;this.sameOrigin&amp;&amp;e.setRequestHeader(\"X-NewRelic-ID\",NREUM.loader_config.xpid)}),a.on(\"send-xhr-start\",function(t,n){var r=this.metrics,o=t[0],i=this;if(r&amp;&amp;o){var f=e(o);f&amp;&amp;(r.txSize=f)}this.startTime=(new Date).getTime(),this.listener=function(t){try{\"abort\"===t.type&amp;&amp;(i.params.aborted=!0),(\"load\"!==t.type||i.called===i.totalCbs&amp;&amp;(i.onloadCalled||\"function\"!=typeof n.onload))&amp;&amp;i.end(n)}catch(e){try{a.emit(\"internal-error\",[e])}catch(r){}}};for(var u=0;c&gt;u;u++)n.addEventListener(s[u],this.listener,!1)}),a.on(\"xhr-cb-time\",function(t,e,n){this.cbTime+=t,e?this.onloadCalled=!0:this.called+=1,this.called!==this.totalCbs||!this.onloadCalled&amp;&amp;\"function\"==typeof n.onload||this.end(n)}),a.on(\"xhr-load-added\",function(t,e){var n=\"\"+f(t)+!!e;this.xhrGuids&amp;&amp;!this.xhrGuids[n]&amp;&amp;(this.xhrGuids[n]=!0,this.totalCbs+=1)}),a.on(\"xhr-load-removed\",function(t,e){var n=\"\"+f(t)+!!e;this.xhrGuids&amp;&amp;this.xhrGuids[n]&amp;&amp;(delete this.xhrGuids[n],this.totalCbs-=1)}),a.on(\"addEventListener-end\",function(t,e){e instanceof XMLHttpRequest&amp;&amp;\"load\"===t[0]&amp;&amp;a.emit(\"xhr-load-added\",[t[1],t[2]],e)}),a.on(\"removeEventListener-end\",function(t,e){e instanceof XMLHttpRequest&amp;&amp;\"load\"===t[0]&amp;&amp;a.emit(\"xhr-load-removed\",[t[1],t[2]],e)}),a.on(\"fn-start\",function(t,e,n){e instanceof XMLHttpRequest&amp;&amp;(\"onload\"===n&amp;&amp;(this.onload=!0),(\"load\"===(t[0]&amp;&amp;t[0].type)||this.onload)&amp;&amp;(this.xhrCbStart=(new Date).getTime()))}),a.on(\"fn-end\",function(t,e){this.xhrCbStart&amp;&amp;a.emit(\"xhr-cb-time\",[(new Date).getTime()-this.xhrCbStart,this.onload,e],e)})}},{1:\"XL7HBI\",2:11,3:9,4:5,ee:\"QJf3ax\",handle:\"D5DuLP\",loader:\"G9z0Bl\"}],11:[function(t,e){e.exports=function(t){var e=document.createElement(\"a\"),n=window.location,r={};e.href=t,r.port=e.port;var o=e.href.split(\"://\");return!r.port&amp;&amp;o[1]&amp;&amp;(r.port=o[1].split(\"/\")[0].split(\":\")[1]),r.port&amp;&amp;\"0\"!==r.port||(r.port=\"https\"===o[0]?\"443\":\"80\"),r.hostname=e.hostname||n.hostname,r.pathname=e.pathname,\"/\"!==r.pathname.charAt(0)&amp;&amp;(r.pathname=\"/\"+r.pathname),r.sameOrigin=!e.hostname||e.hostname===document.domain&amp;&amp;e.port===n.port&amp;&amp;e.protocol===n.protocol,r}},{}],gos:[function(t,e){e.exports=t(\"7eSDFh\")},{}],\"7eSDFh\":[function(t,e){function n(t,e,n){if(r.call(t,e))return t[e];var o=n();if(Object.defineProperty&amp;&amp;Object.keys)try{return Object.defineProperty(t,e,{value:o,writable:!0,enumerable:!1}),o}catch(i){}return t[e]=o,o}var r=Object.prototype.hasOwnProperty;e.exports=n},{}],D5DuLP:[function(t,e){function n(t,e,n){return r.listeners(t).length?r.emit(t,e,n):(o[t]||(o[t]=[]),void o[t].push(e))}var r=t(\"ee\").create(),o={};e.exports=n,n.ee=r,r.q=o},{ee:\"QJf3ax\"}],handle:[function(t,e){e.exports=t(\"D5DuLP\")},{}],XL7HBI:[function(t,e){function n(t){var e=typeof t;return!t||\"object\"!==e&amp;&amp;\"function\"!==e?-1:t===window?0:i(t,o,function(){return r++})}var r=1,o=\"nr@id\",i=t(\"gos\");e.exports=n},{gos:\"7eSDFh\"}],id:[function(t,e){e.exports=t(\"XL7HBI\")},{}],loader:[function(t,e){e.exports=t(\"G9z0Bl\")},{}],G9z0Bl:[function(t,e){function n(){var t=p.info=NREUM.info;if(t&amp;&amp;t.agent&amp;&amp;t.licenseKey&amp;&amp;t.applicationID&amp;&amp;c&amp;&amp;c.body){p.proto=\"https\"===d.split(\":\")[0]||t.sslForHttp?\"https://\":\"http://\",a(\"mark\",[\"onload\",i()]);var e=c.createElement(\"script\");e.src=p.proto+t.agent,c.body.appendChild(e)}}function r(){\"complete\"===c.readyState&amp;&amp;o()}function o(){a(\"mark\",[\"domContent\",i()])}function i(){return(new Date).getTime()}var a=t(\"handle\"),s=window,c=s.document,f=\"addEventListener\",u=\"attachEvent\",d=(\"\"+location).split(\"?\")[0],p=e.exports={offset:i(),origin:d,features:{}};c[f]?(c[f](\"DOMContentLoaded\",o,!1),s[f](\"load\",n,!1)):(c[u](\"onreadystatechange\",r),s[u](\"onload\",n)),a(\"mark\",[\"firstbyte\",i()])},{handle:\"D5DuLP\"}],20:[function(t,e){function n(t,e,n){e||(e=0),\"undefined\"==typeof n&amp;&amp;(n=t?t.length:0);for(var r=-1,o=n-e||0,i=Array(0&gt;o?0:o);++r&lt;o;)i[r]=t[e+r];return i}e.exports=n},{}],21:[function(t,e){function n(t){return!(t&amp;&amp;\"function\"==typeof t&amp;&amp;t.apply&amp;&amp;!t[i])}var r=t(\"ee\"),o=t(1),i=\"nr@wrapper\",a=Object.prototype.hasOwnProperty;e.exports=function(t){function e(t,e,r,a){function nrWrapper(){var n,i,s,f;try{i=this,n=o(arguments),s=r&amp;&amp;r(n,i)||{}}catch(d){u([d,\"\",[n,i,a],s])}c(e+\"start\",[n,i,a],s);try{return f=t.apply(i,n)}catch(p){throw c(e+\"err\",[n,i,p],s),p}finally{c(e+\"end\",[n,i,f],s)}}return n(t)?t:(e||(e=\"\"),nrWrapper[i]=!0,f(t,nrWrapper),nrWrapper)}function s(t,r,o,i){o||(o=\"\");var a,s,c,f=\"-\"===o.charAt(0);for(c=0;c&lt;r.length;c++)s=r[c],a=t[s],n(a)||(t[s]=e(a,f?s+o:o,i,s,t))}function c(e,n,r){try{t.emit(e,n,r)}catch(o){u([o,e,n,r])}}function f(t,e){if(Object.defineProperty&amp;&amp;Object.keys)try{var n=Object.keys(t);return n.forEach(function(n){Object.defineProperty(e,n,{get:function(){return t[n]},set:function(e){return t[n]=e,e}})}),e}catch(r){u([r])}for(var o in t)a.call(t,o)&amp;&amp;(e[o]=t[o]);return e}function u(e){try{t.emit(\"internal-error\",e)}catch(n){}}return t||(t=r),e.inPlace=s,e.flag=i,e}},{1:20,ee:\"QJf3ax\"}]},{},[\"G9z0Bl\",3,10,4]);&lt;/script&gt;</code>\n. Lexer output of the above snippet:</p>\n<p><code>ruby\n[\n    [ 0] [\n        [0] :T_ELEM_START,\n        [1] nil,\n        [2] 1\n    ],\n    [ 1] [\n        [0] :T_ELEM_NAME,\n        [1] \"script\",\n        [2] 1\n    ],\n    [ 2] [\n        [0] :T_ATTR,\n        [1] \"type\",\n        [2] 1\n    ],\n    [ 3] [\n        [0] :T_STRING_DQUOTE,\n        [1] nil,\n        [2] 1\n    ],\n    [ 4] [\n        [0] :T_STRING_BODY,\n        [1] \"text/javascript\",\n        [2] 1\n    ],\n    [ 5] [\n        [0] :T_STRING_DQUOTE,\n        [1] nil,\n        [2] 1\n    ],\n    [ 6] [\n        [0] :T_TEXT,\n        [1] \"window.NREUM||(NREUM={});NREUM.info={\\\"beacon\\\":\\\"beacon-5.newrelic.com\\\",\\\"errorBeacon\\\":\\\"bam.nr-data.net\\\",\\\"licenseKey\\\":\\\"fcf8d519de\\\",\\\"applicationID\\\":\\\"13909,11792387,716468\\\",\\\"transactionName\\\":\\\"NTU0DRQNDwshOmIZBRM3dRAIBgYf\\\",\\\"queueTime\\\":0,\\\"applicationTime\\\":202,\\\"agent\\\":\\\"js-agent.newrelic.com/nr-476.min.js\\\",\\\"userAttributes\\\":\\\"DXgpEBIHQV1mHCUVHBMcNQsDERdFaGo+Ax1UYDwYChEGS2Y6KAEEEykuJhYQDBMrKyIcU0x4Mg0SEllIa2phUhgGeGBbV1pbSXV8f15AR2h0S1RXQUtmPT4VAyk7PRwIFkFdZgUiChgaNjtWU0xTR2wQfEFKVhYzFxMaQx98fhJGRV96GwkWDgYwISoGGQVZb2lOSFFVR2wDBSQ8OnZ6FQ8JBkcDLS4bHl96GREUDQ4Ca3t0XkFYaGtOV0xVUmQbLBYQBDN1TFVVTVRyamFSAxMsMwoPDQ1FfmosRhBCPGpLOgxBGg==\\\"}\",\n        [2] 1\n    ],\n    [ 7] [\n        [0] :T_ELEM_END,\n        [1] nil,\n        [2] 1\n    ],\n    [ 8] [\n        [0] :T_TEXT,\n        [1] \"\\n\",\n        [2] 1\n    ],\n    [ 9] [\n        [0] :T_ELEM_START,\n        [1] nil,\n        [2] 2\n    ],\n    [10] [\n        [0] :T_ELEM_NAME,\n        [1] \"script\",\n        [2] 2\n    ],\n    [11] [\n        [0] :T_ATTR,\n        [1] \"type\",\n        [2] 2\n    ],\n    [12] [\n        [0] :T_STRING_DQUOTE,\n        [1] nil,\n        [2] 2\n    ],\n    [13] [\n        [0] :T_STRING_BODY,\n        [1] \"text/javascript\",\n        [2] 2\n    ],\n    [14] [\n        [0] :T_STRING_DQUOTE,\n        [1] nil,\n        [2] 2\n    ],\n    [15] [\n        [0] :T_TEXT,\n        [1] \"(window.NREUM||(NREUM={})).loader_config={xpid:\\\"VQcGQldQAQMJ\\\"};window.NREUM||(NREUM={}),__nr_require=function(t,e,n){function r(n){if(!e[n]){var o=e[n]={exports:{}};t[n][0].call(o.exports,function(e){var o=t[n][1][e];return r(o?o:e)},o,o.exports)}return e[n].exports}if(\\\"function\\\"==typeof __nr_require)return __nr_require;for(var o=0;o\",\n        [2] 2\n    ],\n    [16] [\n        [0] :T_ELEM_START,\n        [1] nil,\n        [2] 2\n    ],\n    [17] [\n        [0] :T_ELEM_NAME,\n        [1] \"n\",\n        [2] 2\n    ]\n]</code>\n. The following part screw it all up:</p>\n<p><code>__nr_require;for(var o=0;o&lt;n.length;o++)</code></p>\n<p>Here Oga thinks <code>&lt;n</code> marks the start of a new element.\n. The rationale for this is stuff like this:</p>\n<p><img alt=\"screenshot - 241214 - 14 01 14\" src=\"https://cloud.githubusercontent.com/assets/86065/5548586/5b1794d0-8b75-11e4-9335-af6caf189960.png\" /></p>\n<p>Here the same set of expressions are re-evaluated (and thus re-parsed) in a loop. Since the actual expressions are static there's no point in re-parsing them every time.\n. Fixed in 2c4e490614528dc873f8275fe10c34ae489cfee5.\n. &gt; The only hook I see is the #parser_error method and I haven't been able to trigger it. Thoughts?</p>\n<p>This particular method is more meant for parser authors to either enhance error messages or add custom handling of errors. For example, https://github.com/YorickPeterse/oga/blob/098cd51ab730721c19bb4d7d172e3c203901a062/lib/oga/xml/parser.rll#L279-L295 is used to add some extra text to error messages to indicate what kind of data caused the error.</p>\n<p>Currently Oga's XML lexer is pretty lax and makes sure that most input can be processed. However, you can break it by using for example input such as this:</p>\n<p><code>Oga.parse_xml('&lt;!--') # =&gt; LL::ParserError: Unexpected end of input, expected T_COMMENT_END instead on line 1</code></p>\n<p>Does the AWS SDK actually require the parser to raise errors for invalid XML? In most cases one probably doesn't want to bother with this, hence Oga tries to parse as much as possible by default. Seeing how this is now the potential 3rd request for a \"strict\" option I can look into adding this if needed.\n. &gt; A strict mode would be useful, and maybe would have been a good default mode when working with XML</p>\n<p>I'll see if I can implement this, it won't be the default though as that would break compatibility with the existing 1.x releases, I can also imagine most would <em>want</em> it to be lax by default. Either way, once present I envision you can use this along the lines of <code>Oga.sax_parse_xml(handler, xml, :strict =&gt; true)</code> or maybe <code>Oga.sax_parse_xml!(handler, xml)</code>.\n. Tracking the strict parsing request in https://github.com/YorickPeterse/oga/issues/107.\n. multi_xml pull request: https://github.com/sferik/multi_xml/pull/47\n. Closing this in favour of the multi_xml pull request mentioned above.\n. Closing this \"meta\" issue to not clutter up the issue tracker. I'll have to find a different way to describe a roadmap of sorts without having to use Github milestones (perhaps the wiki).\n. I'm not really following, the following works fine:</p>\n<p>``` ruby\ndoc = Oga.parse_xml &lt;&lt;-EOF\n<parent>\n  dog <chow></chow> cow\n</parent>\nEOF</p>\n<p>puts doc.to_xml\n```</p>\n<p>This outputs:</p>\n<p><code>xml\n&lt;parent&gt;\n  dog &lt;chow /&gt; cow\n&lt;/parent&gt;</code></p>\n<p>Note that Oga <em>does</em> replace empty elements with self closing elements, but other than that the output is correct/expected behaviour.</p>\n<p>Do you have a way to reproduce whatever problem you're trying to describe?\n. @detomastah I'm sorry but I don't understand what is going on. If you could provide a small <em>Ruby script</em> that reproduces whatever problem you are experiencing that would greatly help.\n. @detomastah Ah, that particular problem has been solved in #64.\n. Most likely the actual logic would end up in a separate class called by the <code>to_xml</code> methods. I'm not sure yet if I want this to make the default/only behaviour, or if someone would have to call <code>to_xml</code> using something like <code>to_xml(:pretty =&gt; true)</code>. </p>\n<p>One of the tricky things is to get whitespace correct and making sure everything is indented properly, I'm not really sure yet how to handle this.\n. With the new <code>XML::Generator</code> class in place this should be easier to implement. To do so basically every  instance of <code>output &lt;&lt;</code> in the code would have to take into account any indentation to insert first. The indent level can be increased/decreased in the <code>to_xml</code> loop. Basically whenever the loop descends into a child node the indent level would be increased, whenever it moves back to the parent (just after calling <code>after_element</code>) it would decrease the level.</p>\n<p>Pretty printing XML should be disabled by default.\n. @SamSaffron Aha, very interesting! I <em>think</em> we could have 1 formatter for both XML and HTML since the indent rules (from the top of my head). Having said that I myself am super busy, so I'm not sure if I can commit to implementing this myself. However, I'm more than happy to mentor somebody with it and review their code. That way the bus factor also increases from 1 to hopefully 2-ish.. &gt;  I was thinking of a multiple formatters cause:</p>\n<p>I would personally prefer to either indent/format things based on XML, or HTML5; this is basically what Oga does now (sans indentation).</p>\n<blockquote>\n<p>btw... quick one, I noticed you decided on mpl 2 license, is there a technical reason you went with that vs the more common mit/bsd</p>\n</blockquote>\n<p>The MPL 2.0 covers more topics (e.g. patents and grants), it's explicit about not granting rights to trademarks. Finally it requires modifications to the code to be made public (when distributed), without going full on crazy like the GPL.</p>\n<p>I chose it because I'm fine with people making private modifications they keep to themselves, but I'm not OK with people also distributing those changes (under a different license). I also don't want to deal with nonsense such as contributor agreements for patents as a license should take care of this in my opinion.</p>\n<p>So in short, because I found it to be a better license.. &gt;  I will see how we go, I have a GSOC student I will be tasking at migrating Discourse to oga</p>\n<p>This sounds really cool! If they need any help, feel free to send them over.. This has been moved to https://gitlab.com/yorickpeterse/oga/issues/75. I prefer to keep the code blocks regular Markdown code blocks instead of GH's fenced code blocks. Regular code blocks are much more pleasant to read and don't require Github extensions.\n. This isn't really a bug, just a lack of a possible feature. Classes such as <code>Oga::XML::Document</code> and <code>Oga::XML::Element</code> don't define their own <code>==</code> methods, thus they use the default ones provided by <code>Object</code>.</p>\n<p>The tricky thing is that for two documents to be the same they both must have:\n- The exact same XML declaration\n- The exact same doctype\n- The exact same nodes (text, elements, etc)</p>\n<p>For elements two elements must have the following in common:\n- The same name\n- The same namespace\n- The same attributes\n- The same child nodes</p>\n<p>To get all this done the <code>==</code> operators would one way or another recurse into the child nodes of their containers, compare those, recurse further, compare, etc. This would make <code>==</code> quite a heavy operation, so I'm not really sure if it's worth implementing this.\n. Using <code>to_xml</code> is an option for the time being, and I can alias <code>to_s</code> to it in the future if needed. I'll give adding custom <code>==</code> operators some thought because relying on <code>to_xml</code> is a bit of a hack for this.\n. I'm scrapping this, for it could introduce serious bugs. To clarify, for this to\nwork I'd have to define a custom <code>==</code> method on most classes in the <code>Oga::XML</code>\nnamespace such as <code>XML::Text</code>, <code>XML::Attribute</code>, etc. This would allow you to do\nthe following:</p>\n<p>```\ntext1 = Oga::XML::Text.new(:text =&gt; 'foo')\ntext2 = Oga::XML::Text.new(:text =&gt; 'foo')</p>\n<p>text1 == text2 # =&gt; true\n```</p>\n<p>This becomes problematic when we add these instances to a NodeSet:</p>\n<p><code>text1 = Oga::XML::Text.new(:text =&gt; 'foo')\ntext2 = Oga::XML::Text.new(:text =&gt; 'foo')\nset   = Oga::XML::NodeSet.new([text2, text2])</code></p>\n<p>If we now request the indexes of <code>text1</code> and <code>text1</code> we'll get the following:</p>\n<p><code>set.index(text1) # =&gt; 0\nset.index(text2) # =&gt; 0</code></p>\n<p>This is due to <code>Array#index</code> comparing objects using <code>Object#==</code>. This can be\nworked around as following:</p>\n<p>```\ndef index(node)\n  @nodes.each_with_index do |current, index|\n    return index if node.equal?(current)\n  end</p>\n<p>return\nend\n```</p>\n<p>The next problem is that NodeSet relies on <code>Array#include?</code> in a bunch of\nplaces, and this method <em>also</em> relies on <code>Object#==</code> (basically any method\nsearching for values in an Array uses <code>#==</code>). This behaviour will in turn break\ncode such as <code>Node#next_element</code> (which uses <code>NodeSet#index</code> to find the index\nof <code>self</code>).</p>\n<p>Because there can be a lot of other cases where usage of a custom <code>#==</code> breaks\nthings I've decided to scrap this feature. It's too risky to implement compared\nto the (in my opinion) little benefit it brings.\n. For the XPath parser I'll most likely have to re-introduce the <code>+</code>, <code>*</code> and <code>?</code> operators in ruby-ll. By default everything is right-associative in an LL(1) parser and while I managed to make everything left-associative by default (using clever recursion tricks) there's currently no way to make things partially right-associative. For example, this:</p>\n<p><code>A or B and C</code></p>\n<p>Should be parsed as:</p>\n<p><code>(A or (B and C))</code></p>\n<p>While ruby-ll currently parses it as:</p>\n<p><code>((A or B) and C)</code></p>\n<p>If I were to implement the above operators using iteration in the ruby-ll driver (and not recursion) it <em>should</em> be possible to have them parsed using the correct precedence rules as specified by the XPath specification.\n. XPath parser done, moving on to the CSS parser.\n. CSS parser done, yay finally no more Racc.\n. One way of solving this would be to introduce <code>to_html</code> which, for certain elements (based on the name), would alter the behaviour of <code>to_xml</code>. That is, <code>to_html</code> would simply be an alias for <code>to_xml</code> in most cases, except for <code>XML::Element</code> nodes with the name set to <code>script</code>.</p>\n<p>Another way is to check if the root document is in <code>html</code> mode and if so apply the above behaviour. This has the benefit of the user not having to remember if they should call <code>to_html</code> or <code>to_xml</code>. The downside is that this will <em>only</em> work if you append elements to an existing <code>Oga::XML::Document</code> instance.\n. Super dirty patch for option 2:</p>\n<p><code>ruby\nmodule Oga\n  module XML\n    class Text &lt; CharacterNode\n      def to_xml\n        if parent.name == 'script' and root_node.type == :html\n          return super\n        else\n          return Entities.encode(super)\n        end\n      end\n    end # Text\n  end # XML\nend # Oga</code>\n. Note to self: the above snippet should take into account that text nodes can also be embedded into cdata nodes, in such a case it should continue traversing the document tree upwards until it finds the first parent element.\n. @jrochkind It's valid HTML, or at least HTML5. On top of that both Firefox and Chromium handle this case just fine, so does libxml/Nokogiri. As a result I kinda have to support this, that and I bumped into this specific problem in a production application of myself.\n. Having said that, including a literal <code>&lt;/script&gt;</code> tag inside another <code>&lt;/script&gt;</code> tag (e.g. as a string literal) is <em>not</em> valid and will indeed break various browsers and other existing parsing libraries. A Nokogiri example:</p>\n<p><code>2.2.0p0 &gt; Nokogiri::HTML.fragment('&lt;script&gt;\"&lt;/script&gt;\"&lt;/script&gt;')\n=&gt; #(DocumentFragment:0x3fdb99471210 {\n  name = \"#document-fragment\",\n  children = [ #(Element:0x3fdb99470f54 { name = \"script\", children = [ #(CDATA \"\\\"\")] }), #(Text \"\\\"\")]\n  })</code>\n. Fixed in 3b2055a30b128aa679a83332dfdfa68314271b24.\n. This seems to be caused by Reddit assigning an explicit namespace to the <code>&lt;html&gt;</code> element (using <code>&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"&gt;</code> to be exact). As far as I can tell <code>http://www.w3.org/1999/xhtml</code> is the default namespace URI for XHTML/HTML5 so I'll see how I Oga can support this more easily.</p>\n<p>Regarding the examples, there are a few already in the README (https://github.com/YorickPeterse/oga#examples) but I'll see if I can add any other useful ones.\n. Moving the namespace problem over to #85.\n. There's no need for separate tickets, simply adding the links to this issue is enough. Having said that, there's https://github.com/YorickPeterse/oga/issues/20 which, when resolved, should take care of these problems.\n. Using this script:</p>\n<p>``` ruby\nrequire 'oga'\nrequire 'httpclient'</p>\n<h1>silence HTTPClient warnings</h1>\n<p>class HTTPClient\n  def warn(*); end\nend</p>\n<p>module WebAgent::CookieUtils\n  def warn(*); end\nend</p>\n<p>http = HTTPClient.new</p>\n<p>urls = DATA.each_line do |line|\n  url  = line.strip\n  body = http.get(url, :follow_redirect =&gt; true).body</p>\n<p>begin\n    Oga.parse_html(body)</p>\n<pre><code>puts \"[OK]:    #{url}\"\n</code></pre>\n<p>rescue Exception =&gt; error\n    puts \"[ERROR]: #{url} =&gt; #{error.message}\"\n  end\nend</p>\n<p><strong>END</strong>\nhttp://google.com\nhttp://yahoo.com\nhttp://amazon.com\nhttp://yandex.ru\nhttp://linkedin.com\nhttp://www.ebay.com\nhttp://instagram.com\nhttp://vk.com\nhttp://reddit.com\nhttp://imgur.com\n```</p>\n<p>The output is as following:</p>\n<p>```</p>\n<p>[ERROR]: http://yahoo.com =&gt; Unexpected T_STRING_DQUOTE, expected element closing tag instead on line 87\n[ERROR]: http://amazon.com =&gt; Unexpected T_STRING_DQUOTE, expected element closing tag instead on line 1861\n[ERROR]: http://yandex.ru =&gt; Unexpected end of input on line 1\n[ERROR]: http://linkedin.com =&gt; Unexpected end of input on line 682\n[ERROR]: http://www.ebay.com =&gt; Unexpected end of input on line 18\n[ERROR]: http://instagram.com =&gt; Unexpected end of input on line 278\n[ERROR]: http://vk.com =&gt; Unexpected end of input on line 20</p>\n<p>```</p>\n<p>I've checked off the websites that pass, the other ones probably use some HTML not supported yet by Oga.\n. Parsing support for Yahoo (the problem that broke it to be specific) was added in 6b779d788384b89ba30ef60c17a156216ba5b333.\n. There are two things that need to be fixed here:\n- Oga should be able to evaluate documents that define the default XML namespace explicitly, currently this fails here: https://github.com/YorickPeterse/oga/blob/66fa9f62ef1f5e2e447cdc724b42f2e1d58b0753/lib/oga/xpath/evaluator.rb#L1656\n- Custom namespace prefixes used in HTML documents should be ignored (per Nokogiri/Chromium behaviour and the HTML5 spec), re-defining the default namespace has no effect either.\n. Nokogiri seems to completely ignore custom namespace declarations in HTML. For example:</p>\n<p><code>html\n&lt;!DOCTYPE html&gt;\n&lt;html xmlns=\"wtf\" xmlns:x=\"wat\"&gt;\n    &lt;head&gt;\n        &lt;title&gt;HTML Namespaces&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;p&gt;Hello&lt;/p&gt;\n        &lt;x:p&gt;Hello prefix&lt;/x:p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;</code></p>\n<p><code>Nokogiri::HTML(File.open('/tmp/test.html', 'r')).xpath('html/body/p')[1].namespaces\n=&gt; {\"xmlns:x\"=&gt;nil}</code>\n. In other words, for HTML Oga would completely disregard declarations of default <em>and</em> custom namespaces as well as ignoring namespace prefixes (when evaluating XPath). For XML documents the XPath evaluator should also match elements when they are in the default XML namespace when it's explicitly defined.\n. This has been taken care of in the master branch.\n. Fixed in the master branch, will be included in the next release.\n. Could you provide a sample XML file that produces this? Chances are that the XML file is big enough for XPath evaluation to take a while (it's currently quite slow). The reason this is likely slow is because <code>//</code> first retrieves all nodes and <em>then</em> filters them, try using <code>descendant-or-self::country/field/....</code> instead.\n. &gt; I think that css \"country field[ref='f2004']\" is similar to \"//country/field[@ref='f2004']\".</p>\n<p>No, this translates to <code>descendant::country/descendant::field[@ref=\"f2004\"]</code>.\n. @giuan The last few releases of Oga contain various performance improvements that should make XPath evaluation quite a bit faster. Could you give the latest release (0.3.3) a try to see how things perform now?\n. What is the output of the benchmark using the latest Oga? As far as I can tell it looks like you've shared the same output as mentioned in https://github.com/YorickPeterse/oga/issues/88#issuecomment-84624815.\n. Ah ok, I missed that. I'll keep this issue open since there are several more changes I'd like to apply to make things faster.\n. Correct, Rubinius performance is not yet where I want it to be. In general the XPath evaluator <em>is</em> quite slow with a lot of optimization possibilities. I can't make it faster than Nokogiri, but I can definitely make it faster than the current performance.\n. @lham As you found yourself, an unbreakable space is not the same as a regular space, thus <code>String#strip</code> won't actually remove it. The easiest way to remove it is as following:</p>\n<p><code>some_string.gsub(/#{Oga::HTML::Entities::DECODE_MAPPING['&amp;nbsp;']}$/, '')</code></p>\n<p>or:</p>\n<p><code>some_string.gsub(/#{[160].pack('U')}$/, '')</code></p>\n<p>@Arcovion You'll need at least version 0.3.0 for proper HTML/XML entity conversions. The output you're getting looks like something is going wrong with encodings, which might be a separate issue. Either way, the entity conversion code lives under <code>Oga::XML::Entities</code> and <code>Oga::HTML::Entities</code>. The docs can be found here:\n- http://code.yorickpeterse.com/oga/latest/Oga/XML/Entities.html#decode-class_method\n- http://code.yorickpeterse.com/oga/latest/Oga/HTML/Entities.html#decode-class_method\n. &gt; Thx, how about an encode method for HTML entities?</p>\n<p>What do you need this for? There's already <code>Oga::XML::Entities.encode</code> which can take an entity mapping to use for conversion.</p>\n<blockquote>\n<p>I think it would be better to use raw strings: \"\\u222A\\uFE00\"</p>\n</blockquote>\n<p>Why are you setting <code>Encoding.default_external</code> to ASCII? <code>Array#pack</code> requires <code>Encoding.default_external</code> to be set to UTF8 to work properly when using <code>pack('U')</code>.</p>\n<blockquote>\n<p>Failing that: '' &lt;&lt; 8746 &lt;&lt; 65024</p>\n</blockquote>\n<p>This doesn't produce the correct output either when the external encoding is set to ASCII. \n. &gt; Also the decoders behave slightly differently, so I assumed there would be two encoders - probably doesn't matter but from a usability perspective it makes sense I think:</p>\n<p>In the first line you're decoding a non existing XML entity, in the second line you're decoding an HTML entity. The entity <code>&amp;nbsp;</code> is only defined in HTML, not XML, thus you only get an unbreakable space when using <code>Oga::HTML::Entities</code>. There's currently no <code>Oga::HTML::Entities.encode</code> because Oga itself has no use case for such a method.</p>\n<blockquote>\n<p>Note these two are different, the latter is the correct conversion for &cups;. You can't see the difference because I turned off ASCII encoding...</p>\n</blockquote>\n<p>The difference you're seeing here is because while Oga uses <code>[8746, 65024].pack('U')</code> this doesn't actually produce a string that uses the exact same input codepoints:</p>\n<p><code>[8746, 65024].pack('U').codepoints # =&gt; [8746]</code></p>\n<p>As a result <code>Oga::HTML::Entities::DECODE_MAPPING['&amp;cups;']</code> will not be the same as <code>\"\\u222A\\uFE00\"</code>. I'm not sure why this is the case, but it's not something I can do much about other than replacing all <code>Array#pack</code> calls (which I'd rather not do unless absolutely necessary).\n. &gt;  I just think it would be a useful utility, for example the HTMLEntities gem isn't able to decode &cups; but your gem can - just add Oga::HTML::Entities.encode and you have a full converter!</p>\n<p>Oga isn't an HTML/XML entity conversion Gem, it just happens to have it because it's required by the XML/HTML specifications. I don't feel comfortable adding something Oga itself will never use. This method isn't needed because only a few special characters have to be encoded back to entities when generating XML (e.g. <code>&lt;</code> has to become <code>&amp;lt;</code> but <code>\u00a9</code> is perfectly valid as is).</p>\n<blockquote>\n<p>This is a bug, no? You can fix it with U* instead of U for all of the entities.</p>\n</blockquote>\n<p>Ah, then at least that should be easy to fix.</p>\n<blockquote>\n<p>Using pack is expensive compared to the other two ways I mentioned though, I think it's worth changing them. I can put together a PR to change them all to UTF-8 or ASCII strings, what do you think?</p>\n</blockquote>\n<p>This depends on the definition of \"slow\". The file containing these pack calls is loaded upon Gem load, not during runtime. The overhead added to the bootup process is fairly minor too:</p>\n<p>```\noga $ time ruby -e ''</p>\n<p>real    0m0.079s\nuser    0m0.067s\nsys     0m0.010s\noga $ time ruby -e ''</p>\n<p>real    0m0.077s\nuser    0m0.080s\nsys     0m0.000s\noga $ time ruby -e ''</p>\n<p>real    0m0.076s\nuser    0m0.060s\nsys     0m0.013s\noga $ time ruby -r ./lib/oga/html/entities.rb -e ''</p>\n<p>real    0m0.097s\nuser    0m0.083s\nsys     0m0.010s\noga $ time ruby -r ./lib/oga/html/entities.rb -e ''</p>\n<p>real    0m0.099s\nuser    0m0.080s\nsys     0m0.017s\noga $ time ruby -r ./lib/oga/html/entities.rb -e ''</p>\n<p>real    0m0.099s\nuser    0m0.090s\nsys     0m0.010s\n```</p>\n<p>So just loading that file adds about 20 ms. I'd much rather optimize the XPath evaluator or other parts than to shave of a few milliseconds that won't even affect your runtime. The list of entities isn't going to get bigger anytime soon either, so it's not like it one day will be exponentially slower than today.\n. @krasnoukhov Good catch, since this is handled in instances of <code>XML::Attribute</code> and not the parsers themselves the SAX parser currently doesn't decode entities. I'll sort this out so that users don't have to do this manually.\n. @krasnoukhov commit da62fcd75d0889e4539e7390777a906a914a78c0 adds decoding of XML/HTML entities in the SAX parser. Could you run sax-machine against this commit to see if this fixes the entity issues you were experiencing (it should, but it's worth double checking)?\n. This has been released in version 0.3.4.\n. @krasnoukhov Please report that as a separate issue as it's not directly related to this one.\n. @krasnoukhov Nevermind, this has been fixed in 853d804f3468c9f54c222568a7faedf736f8dc1a.\n. This appears to be a bug in the lexer that <em>only</em> originates when using <code>Oga.parse_xml</code> with an <code>IO</code> instance. In the mean time you can work around this as following:</p>\n<p><code>Oga.parse_xml(File.read('path/to/file'))</code></p>\n<p>This <em>will</em> read the entire file into memory first, but at least it's something.\n. This problem is specifically caused by the lack of proper streaming support when lexing CDATA, comments and XML processing instructions. The problem is similar to the one I solved in 24ae791f00380763134654a88c9d2b7a09168a95. To solve it here I'll need to apply a similar technique for:\n- [x] CDATA tags\n- [x] Comments\n- [x] XML processing instructions\n. This has been fixed by a combination of the following commits:\n- b2ea20ba615953254554565e0c8b11587ac4f59c\n- ea8b4aa92fe746a9da19e94c3edf68b41495d992\n- 8acc7fc743c9492eed2d9c885c22c1b5bec06d0f</p>\n<p>Until Oga 1.0 is released it's best to just read a file as a whole instead of passing an <code>IO</code> to <code>Oga.parse_xml</code> and <code>Oga.parse_html</code>.\n. These fixes for this have been released in version 0.3.2 so there's no need to wait for 1.0.\n. The problem is caused by the following snippet:</p>\n<p><code>&lt;a class=\"js-show-link comments-link dno\" title=\"expand to show all comments on this post, or add one of your own\" href=# onclick=\"\"&gt;&lt;/a&gt;</code></p>\n<p>Which can be further reduced to:</p>\n<p><code>&lt;a href=#&gt;&lt;/a&gt;</code></p>\n<p>HTML allows one to omit attribute quotes for certain values (e.g. those without spaces). I'll have to see how Oga can handle this in a reasonable way.\n. There's one small bug introduced by this where HTML such as <code>&lt;a href=\"foo\"/&gt;</code> (note the lack of a space before <code>/&gt;</code>) messes it up. I'll re-open this issue if I bump into more issues related to the StackOverflow HTML.\n. With d892ce97874ed0f1382df993c40a452530025f02 all problems regarding this particular HTML document should be fixed.\n. This has been released in version 0.3.2.\n. This is a different problem, caused by a doctype being broken onto separate lines. I've opened #95 for this.\n. I'll prepare a release for this later today.\n. @binaryplease This has been released as version 0.3.3 which is being pushed to RubyGems as we speak.\n. Thanks!\n. This seems to be described at http://www.w3.org/TR/html5/syntax.html#syntax-tag-omission.\n. Tags to take care of:\n- [x] html\n- [x] head\n- [x] body\n- [x] li\n- [x] dt \n- [x] dd\n- [x] p\n- [x] rb\n- [x] rt\n- [x] rtc\n- [x] rp\n- [x] optgroup\n- [x] option\n- [x] colgroup\n- [x] thead\n- [x] tbody\n- [x] tfoot\n- [x] tr\n- [x] td\n- [x] th\n. This is correct. In an initial revision of the HTML handling system the lexer <em>did</em> automatically insert html/head/body tags whenever needed. After thinking about this for a while I decided to remove this as ultimately it leads to unexpected behaviour. To explain this, when parsing XML/HTML there are two kinds of inputs:\n- Full blown documents (e.g. entire web pages)\n- Fragments of data (e.g. just a <code>&lt;form&gt;</code> tag)</p>\n<p>Nokogiri supports this distinction in the form of <code>Nokogiri.HTML()</code> and <code>Nokogiri::HTML.fragment()</code>. When using <code>Nokogiri.HTML()</code> any missing html/body/head tags as well as doctypes are inserted automatically, when using the <code>fragment</code> method this is not the case.</p>\n<p>The problem of this is that it complicates using the library. One has to think \"am I parsing a document or a fragment?\" every time they want to do something with HTML/XML. This distinction also complicates the lexing phase as the lexer now has to include extra support based on some sort of flag (e.g. <code>:document =&gt; true</code> or <code>:fragment =&gt; false</code>).</p>\n<p>If one were to not be aware (or simply not expect) the above distinction this would lead to unexpected behaviour. For example, say somebody is parsing the following snippet and wants to remove the <code>class</code> attribute:</p>\n<p><code>document = Oga.parse_html('&lt;p class=\"example\"&gt;Hello&lt;/p&gt;')\np = document.children[0]\np.unset('class')</code></p>\n<p>They then serialize the document back to XML and lo and behold they get this:</p>\n<p><code>&lt;html&gt;\n    &lt;body&gt;\n        &lt;p&gt;Hello&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;</code></p>\n<p>This is <em>very</em> different compared to just receiving <code>&lt;p&gt;Hello&lt;/p&gt;</code> as output.</p>\n<p>One of the goals I have is that Oga does not return unexpected output. For example, Oga does not automatically add doctypes (unlike Nokogiri) or XML declarations. For that exact same reason I opted to <em>not</em> automatically add html/body/head tags even if the HTML5 specification says otherwise. </p>\n<p>I intend to document this choice, but it seems you beat me to it before I could write it down :)\n. @abotalov This is currently not possible, and I don't think I'll be adding this any time soon. Oga only tracks the names of opening tags (https://github.com/YorickPeterse/oga/blob/7d9604fd932ac9a5f78e68908390f758e12ed543/lib/oga/xml/lexer.rb#L413 vs https://github.com/YorickPeterse/oga/blob/7d9604fd932ac9a5f78e68908390f758e12ed543/lib/oga/xml/lexer.rb#L479). Changing this will introduce a pretty hefty performance pentalty (due to extra string allocations) and I'd rather not do that any time soon.</p>\n<p>Besides this I can't really think of any use cases where this would be useful.\n. Correct, there are a bunch of context specific rules (e.g. <code>&lt;thead&gt;</code> only being allowed in <code>&lt;table&gt;</code>) that I haven't taken care of yet. Another example would be <code>&lt;html&gt;&lt;head&gt;bar&lt;body&gt;Foo&lt;/body&gt;&lt;/html&gt;</code>). I've yet to come up with a solution to this that doesn't require specific blocks (= if statements) of code for every possible element as such a solution is a total pain to maintain.\n. Bah, I overlooked the missing <code>&lt;/tr&gt;</code> elements in <code>&lt;thead&gt;</code> and such. I'll take another look at this.\n. @abotalov 1e0b7feb026d95f2b04706391a868d64b7e5de6e <em>should</em> properly take care of what was left. Could you throw some extra HTML at it to see if it now behaves as expected?\n. &gt; 1. caption element should be also automatically closed by colgroup or tr start tag</p>\n<blockquote>\n<ol>\n<li>colgroup element should be also automatically closed by colgroup or tr start tag</li>\n</ol>\n</blockquote>\n<p>Oh fantastic. Most of the work so far is based on the list of optional tags at http://www.w3.org/TR/html5/syntax.html#optional-tags, which doesn't list these two elements.</p>\n<blockquote>\n<p>Also there's an issue that seems a bit wider - elements don't always become closed when end tag is encountered:</p>\n</blockquote>\n<p>Hmpf, I suspect this is due to the changes made in 1e0b7feb026d95f2b04706391a868d64b7e5de6e, I'll take a look at this.</p>\n<blockquote>\n<p>Also look at code example in http://www.w3.org/TR/html51/semantics.html#the-optgroup-element. Here p element isn't closed and select element is followed after it. p element should be closed before select element start tag as:</p>\n</blockquote>\n<p>Same problem here as with the caption/colgroup elements, at least this one is fairly easy to fix.\n. I'm moving this to #101 as the problems above are not just limited to tables.\n. As discussed in https://github.com/YorickPeterse/oga/pull/76#issuecomment-74304329 I prefer to use regular Markdown code blocks as they're much more readable in their raw form.\n. Another case as per #99, consider the following HTML:</p>\n<p>``` html\n<table>\n    <tbody>\n        <tr>\n            <td>Ms Danus\n</table></p>\n<form id=f action=\"/auction.cgi\">\n    <input type=button name=add value=\"Submit\">\n</form>\n\n<p>```</p>\n<p>Because Oga doesn't really care about the name of closing tags it effectively lexes it as following:</p>\n<p>``` html\n<table>\n    <tbody>\n        <tr>\n            <td>Ms Danus\n</td></p>\n<form id=f action=\"/auction.cgi\">\n    <input type=button name=add value=\"Submit\">\n</form>\n\n<p>```</p>\n<p>When parsing this and serializing it back to HTML we get the following output:</p>\n<p>``` html\n<table>\n    <tbody>\n        <tr>\n            <td>Ms Danus\n</td></p>\n<form id=\"f\" action=\"/auction.cgi\">\n    <input type=\"button\" name=\"add\" value=\"Submit\" />\n</form>\n\n<p></tr></tbody></table>\n```</p>\n<p>The only sustainable way of resolving this problem is to add a hierarchy of all HTML5 elements and the elements that can be nested in them. Any element that is not in such a list results in left-open tags being closed automatically. </p>\n<p>In the example above we know that a <code>&lt;form&gt;</code> element can not reside in a <code>&lt;td&gt;</code>, <code>&lt;tr&gt;</code>, <code>&lt;thead&gt;</code> and <code>&lt;table&gt;</code> element, thus we'd first close all those tags before processing the opening <code>&lt;form&gt;</code> tag.</p>\n<p>An alternative would be to add a hook when processing closing tags to automatically close any left-open tags based on a heuristic similar to those used for open tags. This however would require a similar (if not the same) hierarchy of elements and their allowed child elements.\n. When using the hierarchy mentioned above the process of closing tags is basically as following:\n1. Take the name of the element we're currently in, get all the elements that are allowed to reside within it\n2. Check if the name of the opening element we're about to process is in this list\n3. If this is not the case close the element that was left open, jump back to step 1\n4. If this <em>is</em> the case just continue business as usual\n. @abotalov In the above example Oga doesn't know it's the <code>&lt;table&gt;</code> element that's being closed. In fact, it will treat this as closing the <code>&lt;td&gt;</code> element. A <code>&lt;tr&gt;</code>, <code>&lt;tbody&gt;</code> and <code>&lt;table&gt;</code> still can't contain a <code>&lt;form&gt;</code> as far as I'm aware of.\n. The procedure I'll be going with (unless I bump into any big problems) is as following:\n1. Build a Hash of all elements and their allowed child elements, elements not in this Hash (as the keys) are treated as elements that can't have any child elements (e.g. <code>&lt;title&gt;</code>).\n2. When we bump into a new open tag while we're still in an unclosed tag, check if said new tag is allowed inside the unclosed tag. If this is not the case the unclosed tag is closed first.</p>\n<p>The exception here is the <code>&lt;body&gt;</code> element. While officially only a subset of elements is allowed in a <code>&lt;body&gt;</code> (e.g. <code>&lt;body&gt;&lt;tr&gt;foo&lt;/tr&gt;&lt;/body&gt;</code> is invalid I believe) Oga will instead allow everything <em>except</em> another <code>&lt;body&gt;</code> or <code>&lt;head&gt;</code> tag. This ensures that HTML such as this:</p>\n<p><code>html\n&lt;body&gt;\n    &lt;tr&gt;foo</code></p>\n<p>is parsed as this:</p>\n<p><code>html\n&lt;body&gt;\n    &lt;tr&gt;foo&lt;/tr&gt;\n&lt;/body&gt;</code></p>\n<p>instead of this:</p>\n<p><code>html\n&lt;body&gt;&lt;/body&gt;\n&lt;tr&gt;foo&lt;/tr&gt;</code></p>\n<p>For the form example this would result in the following steps:\n1. <code>current_element</code> returns <code>tr</code>, the new element is <code>form</code>\n2. <code>form</code> is not allowed in <code>tr</code>, close <code>tr</code> first\n3. <code>form</code> is not allowed in <code>tbody</code>, close <code>tbody</code> first\n4. <code>form</code> is not allowed in <code>table</code>, close <code>table</code> first\n5. <code>form</code> <em>is</em> allowed in <code>&lt;body&gt;</code>, continue business as usual</p>\n<p>Steps 2-5 would basically be a <code>while</code> loop.\n. The bulk of this should be taken care of in commits https://github.com/YorickPeterse/oga/compare/3e337faa1d9708835aaf4e81d16910e01ed894d5...688a1fff0efb9e2405e0aab5b3a7164e78ec287e. I still have to add new specs for a bunch of HTML elements and verify if all is well now but so far it's looking quite promising.\n. @abotalov Could you give the latest master version a try with some HTML you might have around? As far as I can tell it <em>should</em> be taken care of now, but I want to be 100% sure it's good to go this time :)\n. Closing this as it should be fixed, feel free to re-open if needed.\n. &gt; I think that's because elements that appeared in HTML 5.1 spec haven't been added.</p>\n<p>Ah good point, those of the <code>p</code> element were still based on 5.0. This has been taken care of in 3c6263d8de30b91aac7c3b16b65f00407b88fc13</p>\n<p>Regarding the last example, I'm moving that to a separate issue.\n. The idea here is to replace the <code>XPath::Evaluator</code> class with a compiler that turns XPath ASTs into Ruby source code. Each block of source code is cached per expression (so it doesn't have to be recompiled every time) in an LRU. The generated code would simply take an input document/node and return whatever the expression dictates. This has numerous benefits such as:\n- Less object allocations as NodeSet instances don't have to be passed around as often as they are currently.\n- A JIT might have an easier time optimizing the code as it would basically be a <code>proc</code> with a bucket of code directly in it.\n- The ability to, if ever needed, generate implementation specific code (given this would further improve performance).\n. Personal notes:</p>\n<p>Add some kind of context class that responds to <code>&lt;&lt;</code> so I can get rid of all the <code>X.followed_by(Y)</code> calls. This should hopefully enhance readability. This context class would also have helper methods for creating common objects such as <code>nil</code>, <code>true</code>, <code>false</code>, etc instead of the compiler having to use <code>literal('nil')</code> all over the place. This in turn would also clean up the Compiler class itself.\n. More notes:\n- Make sure that generated code is wrapped in begin/end blocks where needed\n- Remove the use of <code>backup_variable</code> where it's not required\n- Use <code>unique_literal</code> whenever possible instead of just <code>literal</code>\n. I prefer not to have these in the README as they clutter them too much. I also find that simply showing the latest build status doesn't really help with anything (I already get Emailed to death when a build fails).\n. Once people actively refuse using Oga because I don't include a badge in the README I might reconsider it. Personally I find it a bit odd one would base their Gem choices on a build status, especially if one considers that any branch doesn't have to be stable. Either way, if I ever get to setting up a proper website for Oga that's probably the place to put these sort of badges.\n. This is due to the lexer treating this input as following:</p>\n<p><code>html\n&lt;object&gt;\n    &lt;ul&gt;\n        &lt;li&gt;Li&lt;/li&gt;\n    Inside object\n&lt;/ul&gt;\nOutside object</code></p>\n<p>After automatically inserting missing closing tags we're left with the following:</p>\n<p><code>html\n&lt;object&gt;\n    &lt;ul&gt;\n        &lt;li&gt;Li&lt;/li&gt;\n    Inside object\n&lt;/ul&gt;\nOutside object\n&lt;/object&gt;</code>\n. I have a fix for this on my computer, but it requires exposing element names to <code>XML::Lexer#on_element_end</code>. Because this will decrease performance a bit (only for HTML documents) I'll be giving this some extra thought to see how bad it is and if there's maybe not a way around this.\n. Fixed by 5182d0c488759efb96d85a399de29550faea3efe.\n. @muescha No idea, I don't use mechanize myself and I'm not sure how heavily it depends on Nokogiri specifics. Personally I usually use a mix of HTTPClient (https://github.com/nahi/httpclient) and Oga, though this requires a bit more manual tinkering.</p>\n<p>Having said that, feature requests such as these are probably best submitted to the mechanize repository itself, I can't do much about their choice of libraries.\n. @muescha I do not understand your question. Please keep in mind that I can't help you with any Mechanize related questions as I don't use Mechanize myself.\n. Looking at things the only difference in strict mode would be the removal of automatically inserting missing closing tags. Everything else is handled in the Ragel code and I don't want to litter it with more conditionals (as this is a pain to maintain). Just disabling the automatic insertion of closing tags is a bit pointless in my opinion.</p>\n<p>@trevorrowe: you mentioned the AWS SDK needs some sort of error handling due to services using chunked transfers without setting the chunk sizes. How exactly would you use error handling in this case?\n. @trevorrowe I added basic strict parsing support in 2c18a51ba905d46469170af7f071b068abe965eb, could you build from Git [1] and give that a try?</p>\n<p>[1]: <code>git clone</code> the repository, run <code>bundle install</code> followed by <code>rake</code>. You can then simply run <code>rake install</code> to install the Gem.\n. Fantastic! I'll push a new Gem release later today.\n. @trevorrowe This has been released in Oga 1.0.3 (http://code.yorickpeterse.com/oga/latest/file.CHANGELOG.html).\n. Yes, this is covered in the following documents:\n- http://code.yorickpeterse.com/oga/latest/#examples\n- http://code.yorickpeterse.com/oga/latest/file.manually_creating_documents.html</p>\n<p>The documentation of the various Node classes (e.g. http://code.yorickpeterse.com/oga/latest/Oga/XML/Element.html) and the NodeSet class (http://code.yorickpeterse.com/oga/latest/Oga/XML/NodeSet.html) covers the various methods you'd use for this.</p>\n<p>In short, adding elements is as easy as:</p>\n<p><code>some_element.children &lt;&lt; Oga::XML::Element.new(:name =&gt; 'div')</code></p>\n<p>Setting/getting attributes is done using:</p>\n<p><code>some_element.get('class')\nsome_element.set('class', 'foo')</code></p>\n<p>Removing elements:</p>\n<p><code>some_element.children.last.remove</code></p>\n<p>Setting the text of an element:</p>\n<p><code>some_element.inner_text = 'hello'</code>\n. As another note, Oga uses the RSpec 2 \"should\" syntax instead of the \"expect\" syntax. I really, <em>really</em> hate having to write <code>expect(x).to eq(y)</code> instead of just <code>x.should == y</code>. I've never run into a problem with RSpec's <code>should</code> colliding with some other library, until that time I want to continue using the \"should\" syntax. I'll document this in the CONTRIBUTING guide for future references.\n. I'm closing this pull request. Judging by your comments and disregard for my requests it seems you're not interest in putting any real effort into this. As such I have no real interest in merging this and then having to fix everything, I'll just fix this problem myself.\n. There are two ways of solving this that I can think of at the moment:\n1. Convert entities back to their encoded form when calling <code>to_xml</code>.\n2. Only escape a double quote using a <code>\\</code> (I believe this is valid in XML/HTML) as <code>to_xml</code> uses double quotes for attribute values.</p>\n<p>Personally I'm not a huge fan of option 1. \n. Thinking of it using a backslash probably won't work, at least Nokogiri doesn't really seem to like it. Nokogiri seems to URL encode the values, e.g. <code>\"</code> ends up as <code>%22</code>. Not sure if this the official way of doing it though.\n. That might also be an option and would remove the need for using the <code>URI</code> library. It would however require a way to whitelist the entities to encode as I don't think there's a need for encoding everything when re-generating attribute values.\n. What exactly is the supposed behaviour here? Both Nokogiri and Oga seem to parse this exactly the same:</p>\n<p>```\n$ cat test.rb\nrequire 'oga'\nrequire 'nokogiri'</p>\n<p>html = &lt;&lt;-EOF\n<script>\n  var example = 'Consider this string: <!-- <script>';\n  console.log(example);\n\n despite appearances, this is actually part of the script still! \n\n ... // this is the same script block still...\n\nEOF\noga_doc  = Oga.parse_html(html)\nnoko_doc = Nokogiri::HTML.fragment(html)\nputs <<-EOF\nOga:\n{oga_doc.to_xml}\nNokogiri:\n{noko_doc.to_html}\nEOF\n$ ruby test.rb\nOga:\n\n  var example = 'Consider this string: <!-- <script>';\n  console.log(example);\n\n despite appearances, this is actually part of the script still! \n\n ... // this is the same script block still...\n\nNokogiri:\n\n  var example = 'Consider this string: <!-- <script>';\n  console.log(example);\n\n despite appearances, this is actually part of the script still! \n\n ... // this is the same script block still...\n\n```\n\nI don't see how ` despite appearances, this is actually part of the script still! ` is supposed to be part of the first script tag. The first script tag is terminated correctly by the `\n, the occurrence of<!-- <code>has no influence as anything _except_</code>is valid in a",
    "dsisnero": "Have you seen vtd-xml? http://vtd-xml.sourceforge.net/  and http://www.infoq.com/articles/HIgh-Performance-Parsers-in-Java .\n. ",
    "whitequark": "@YorickPeterse Obviously, since the only point of a streaming API is to execute in constant-space (and linear-time), you must not keep any trees around.\nI suggest implementing just the streaming API, and then implementing DOM API on top of that.\n. what? if you can't stream, just wrap the input in StringIO.\n. ",
    "razielgn": "I wouldn't mind to pick this up! :smiley: What do you think?\n. > While I really (really) do appreciate the interest in helping out, I think it might be a bit too early. Lots of parts of Oga will be moving around in the coming weeks most likely, making it rather difficult for others to contribute.\nFair enough. :smile: \n\nSecond, I'm not sure yet what route to go down to with CSS selectors. There are basically two ways of approaching this:\n1. Write a full blown lexer, parser and XPath compiler\n2. Use regular expressions and good ol' String#gsub to compile CSS into XPath\n   I'm currently leaning towards the second option as it's both faster (Racc is really slow) and CSS expressions are simple enough that I could probably permit this.\n\nThe first option would probably be \"cleaner\".\nI'm not sure regexps can be used here. They could get very complex and hard to handle.\n. ",
    "slaught": "\n+1 to this being a big problem: sparklemotion/nokogiri#1047\nNot fully thread safe\nBad abstractions over libxml. \n. \n",
    "postmodern": "\nJRuby support, see sparklemotion/nokogiri#521\nThe weak detection of CSS-path vs. XPath. I prefer how jQuery differentiates between CSS-path and XPath.\nCannot use XPath/CSS-path with SAX. It should be possible to convert XPath/CSS-path into state machines that match each node incrementally.\nWhen parsing large and complex XML documents (+5Mb), Nokogiri will create Ruby objects for every libxml2 node. Would rather prefer an opaque lazy interface to the libxml2 document.\nNokogiri::HTML and libxml2's HTML support is not as forgiving of malformed HTML as Gecko or WebKit.\nNokogiri::XSLT, which requires libxslt1, should be a separate library.\nPoor documentation of XPath selectors and supported functions. Usually end up searching Nokogiri's Google Groups or StackOverflow.\nThe security risks of vendoring libxml2.\nThe name; oga isn't much better. Please stop with the cryptic names.\n. \n",
    "ryanstout": "2nded, the jruby version behaves completely differently. Namespaces also don't work in jruby. \n. ",
    "ddfreyne": "Nokogiri on JRuby is unusably buggy. Take a look at these issues I reported:\n- sparklemotion/nokogiri#1077\n- sparklemotion/nokogiri#1078\n- sparklemotion/nokogiri#1079\n- sparklemotion/nokogiri#1080\n- sparklemotion/nokogiri#1081\n- sparklemotion/nokogiri#1084\nAll of these issues were uncovered by the nanoc test cases.\n. ",
    "jrochkind": "Difficulty/slowness of compilation is my biggest painpoint for sure. In current variations that  can take minutes to compile. And on some servers I still have to go installing various supporting libraries at the right versions to get a succesful compile. \nNext painpoint would be nokogiri's inconsistency in some places in how it handles XML namespaces. The API is inconsistent and works different ways in different places. \nIt looks like oga is still under development and not yet mature. Very interested and plan on keeping an eye on it.  Nokogiri's support for CSS selectors (an idea it took from HPricot) are super useful, not sure if you're planning on doing those too. \n. To me (and I suspect others), handling actual syntax errors is not a super high priority. \nHowever what is higher priority is for HTML, handling things that actually are legal in html5, but are very un-xml-like.   Like the fact that technically in html5 you do not need to close <p> or <li> tags. Looks like oga can already handle the fact that you have a single <br> in HTML5 (not neccesarily <br />), but can't currently handle the fact that you don't need to explicitly close some tags. \nI suspect this is going to be quite difficult to handle, but without it it's maybe not quite a parser of even all legal html5, not quite a syntax error issue. \n. I wonder if it would be feasible to use Antlr, generating both Java and C parsers from the same antlr grammar. Use the generated Java parser from jruby, use the generated C parser in mri and rbx.  Antlr can, I think, generate both C and Java from the same parser. (I don't actually have experience with it myself)\n. I've spent a lot of time on char encoding issues in my ruby career. \nAnd I've run into LOTS of encoding related bugs with ruby gems, especially using gems that are taking third party input from somewhere and ignoring the char encoding that input advertises. (See, ruby http libraries that ignore the charset param in the Content-Encoding header!)\nSo that would lead me to suggest it would be really really good to automatically recognize and respect the encoding.  I am not sure what vocabulary XML uses for identifying char encodings, you might need to translate from XML char encoding to ruby's encoding vocabulary.  If there were an encoding that ruby could not represent, the right thing to do would be to use ruby's ASCII-8bit encoding -- aka 'binary', this is basically the 'null' encoding, no encoding. (Or, by default raise, but with the right option set, use ASCII-8bit). \nHOWEVER. I recognize this might not be feasible to do (I would be surprised if it had a performance issue though, string.force_encoding is just setting a flag, and is cheap). \nAnd, I have NOT run into very many encoding related issues with XML specifically -- because the vast majority of XML is in UTF-8, even though XML theoretically supports other encodings. (Although I don't know if this would be true for people working with XML in every country? It's def true for most of us in the English speaking world). \nThe trick is that ruby's \"default encoding\" is settable at runtime, and may NOT be UTF-8. \nIf you want to punt on encoding (for now anyway), I wonder if it might be better to force the assumption of a UTF-8 encoding, rather than simply taking whatever the ruby runtime is currently set to. You could do this simply with input.force_encoding(\"UTF-8\"), which ought to be quite cheap. But I'm not entirely sure if it would be the right thing to do or not. \n(Anyhow, I saw this ticket cause I'm watching this repo because I am VERY excited about your project. We desperately need a nokogiri replacement in rubydom, and your approach is looking great.)\n. Also, if you were interested and thought the code were in such a state where someone else could touch it, I would be willing to try and find time to help with this issue, whether now or later. I do have lots of experience dealing with char encoding in ruby. \n. > The first public release of Oga will be released this Saturday\nVery exciting! With xpaths and everything (but prob not namespace support yet?)?  Expect some pull requests from many probably eventually, I think there's interest. \nI need to read more into encoding standards for XML.  If any XML encoding neccesarily has to be ascii-compatible, so XML-syntactic chars like quote marks and angle-brackets are the same in all of those encodings -- couldn't you just call force_encoding on the remainder of the input before you consume it, en toto, rather than have to call it on each individual element?  That's what I was imagining. \nEven if you had to call force_encoding on every individual string element, it seems like it would be a pain in code, but it doesn't seem like it would be a performance issue. You should not actually need to \"encode\" the strings -- those strings are ALREADY in the encoding declared (or at least you're supposed to assume they are, and it's an error if they aren't), you don't need to convert them to any encoding, you just need to tag them properly with force_encoding. \nI think? Could be missing something. But this is how I've dealt with input with declared encodings in the past, in other formats. \n. > You can set the encoding the moment you bump into an encoding tag, but then you'd still have to re-encode everything that came before.\nMakes sense. Ordinarily, everything that came before won't be very much -- it needs to be in the very first line of XML (really not very much), and in the head of HTML (okay, could be something, but most HTML probably doesn't declare the encoding anyway. Is official-standards default for HTML UTF8 or Latin-1? Geez, I hope not latin-1). \nAnyway, cool. I am definitely interested in proper encoding recognition (which I don't think nokogiri really has), but failing this would prefer (at least optionally) a default of UTF-8 rather than binary. \n. I may be misunderstanding the spec though and maybe nokogiri is doing the wrong thing? This gets confusing. \nBut it is highly useful to have a way to say \"get the top-most node\" without knowing the tag name of it. Maybe I'm confused about what way (if any?) the xpath spec provides for this?\n. The way the spec describe the slash on it's own is confusing: \"/ selects the document root (which is always the parent of the document element)\"  -- the parent of the document element? I'm not actually sure what it means, is what I realized after posting. \n. Makes sense. Is this intended, or a bug that namespace-uri() does not find namespaces declared as default namespaces?\n. thanks! \n. You might find out if some of your tests fail when you add it back. xml namespaces really are a pain to deal with, I sympathize. \n. thanks!\n. Okay, makes sense.  Instructions for how to manually see if there's an <?xml> declaration and add one if not present might be helpful. \nA pretty-printer would definitely be a useful and I suspect popular feature. \n. Thanks!\nYeah, regarding empty elements, it was going to change in a round trip either way. I think this way is better, where empty tags are always output as self-closing regardless of how they were in input, vs the old way where they were always output as open/close pairs regardless of how they were in input. (The new way is also consistent with libxml/nokogiri for what it's worth). Great, thanks!\n. Seems to simply be the xmlns. This reproduces:\n``` ruby\ndoc = <\n\nEOS\noxml = Oga.parse_xml(doc)\noxml.to_xml\n```\nThis is an oga off of master, at, um, let me update to latest master... cdfeeed85f164 still reproduces. \n. Hi, would you be open to a pull request on this? I can take a look and see if I can figure anything out, but I won't spend my time if you aren't really interested in pull requests from other people right now!\nThis bug is preventing me from doing any further work with the 0.1.x releases, it stops me in my track for my use case. \n. Okay, thanks! I won't give you a pull request then, since it sounds like\nmostly you need to decide how you want to handle it, so me deciding and\ngiving you a PR won't help.\n(I too think #2 seems the cleaner option, and it doesn't seem like it's\nactually much more work than option 1.  \"xmlns\" isn't actually a\nnamespace, even if oga treats it internally like one for convenience, the\nless you do that the better, cause it's not really a namespace in the same\nway foo in \"xmlns:foo\" is.  The more code you write treating xmlns like\na namespace, the more I think it will lead to more side effects and bugs\ndown the line, since it doesn't really match XML's model, xmlns isn't\nactually a namespace. )\nI am definitely eager to see this in a release though, and sad that it\nwasn't in today's 0.1.x release. I'll go further with playing with oga and\nmaybe finding other issues once it's fixed! Thanks!\nOn Tue, Sep 23, 2014 at 11:41 AM, Yorick Peterse notifications@github.com\nwrote:\n\nTo further clarify, until you do something like  Oga\ndoesn't know anything about the xmlns bits. This could be added to\nXML::Element#available_namespaces so that this method always at least\nreturns the following (instead of an empty Hash):\n{'xmlns' => Namespace(....)}\nThis however has some problems to it. For example, imagine no namespaces\nare explicitly defined anywhere. In this scenario every\nElement#available_namespaces call would return the above Hash.\nConsidering this method recursively calls itself on parent elements, this\nwould result in Oga trying to merge duplicate Hashes a whole bunch of\ntimes. This is already the case, but at least the hashes are empty.\nAnother problem is that Oga would have to make sure that when a custom\ndefault namespace is defined that namespace is used instead of the\nembedded default one. It's much easier to just not use any default\nnamespace and apply the change mentioned in item 1 above.\nSo tl;dr: option 1 just saves quite a bit of work.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/YorickPeterse/oga/issues/47#issuecomment-56540188.\n. thanks!\n. I'd definitely consider that a bug. \"<\" is escaped as &lt; in an XML text node, but that's just how it's serialized.  \"&lt;\" means \"<\", and once parsed and I ask for the text node value, I should get \"<\" back. \n\n(And I should be able to set \"<\" in a text node value, and oga properly escape it when serializing to XML)\n. Yep -- if we were actually talking about \"HTML entities\", I'd agree with you that oga should leave them alone. And it gets a lot more confusing, becuase actual HTML entities (like &emdash;)  are not valid at all in XML without being declared somehow. \nBut if we're talking about the escaped form of literal < and '>` in a text node. I think it's pretty clear that an XML parser needs to unescape these, they are simply escaped forms in the XML serialization. In the internal form, they need to be turned into the literals they represent escaped in the serialization. \nAs a client of an XML parser, I need to know what the text node actually is, once it's been parsed, not see it's serialized/escaped form.   I count on the parser/serializer to take care of escaping issues for me, I should not need to deal with the rules for escaping/unescaping in my client code, that's the role of the parser/serializer. \nYour quote in the your last comment suggests to me what I'm saying -- expanded immediately when recognized and treated as character data -- does it suggest the reverse to you? heh. \nFor instance, people often complain that there's no way to tell the difference between these two things in nokogiri, but they're wrong to complain -- these two things are supposed to mean the exact same thing, and it's appropriate to represent them identically in the internal AST:\n```\n\n<![CDATA[\nx < y\n]]>\n\n\nx < y\n\n```\nThose should indeed be represented identically in the internal representation -- they are the exact same thing, just using different escaping mechanisms in the serialized form. People who ask for nokogiri/libxml to do it differently are mistaken. \n. > Second, this would mean that when calling to_xml you'd then have to re-escape the same data.\nI think that's actually totally appropriate, and the only sane way to implement this. \nI should be able to set a text node to \"x > y\", and the serializer should take care of escaping that for me. I should not have to know XML escaping semantics myself and set the escaped form in the AST, that's the job of the parser/serializer. \n. source code with no line number might still be useful, and better than no source code at all. \n. awesome, thanks for figuring out a way to leave line numbers in for parse error reporting!\nAs Mark Twain wrote, \"If I had more time, I would have written a shorter letter\", writing good code in fewer lines can definitely take longer!\n. I think the current behavior is actually correct semantics for XPath querying with namespaces. \nXML namespaces are a pain to deal with. When you don't really need them at all even though they were in the input doc, I think there's no shame in simply stripping them from your doc. Nokogiri has remove_namespaces!, I use it sometimes, it would be easy for client code to do the same with oga. The * wildcard is also super convenient for these times, I hadn't seen that before, not sure if you invented it or borrowed it from somewhere, but it's a great idea that goes beyond the spec while still leaving the strict semantics there when you do need them. \nBut when I do need querying based on namespaces, I need proper strict semantics.  I need a namespace to be handled exactly the same whether it was declared with a prefix, or as a 'default' namespace. \nI do find oga's API and semantics problematic for when I do need strict namespace semantics, as we argued about on reddit once. Fortunately, it was really easy for me to write my own simple extension to oga to provide the API that worked for me (one more like nokogiri, libxml, and other namespace-aware xml processors).  Thanks for the nice clean code in oga that made this so easy. My code is here: https://github.com/jrochkind/oga_ns\nWhen I want strict namespace semantics, I need a node to only be matched by a namespaced query; and a namespaced query to only match proper namespaced nodes;  and all of this to hold true regardless of whether any or all namespaces were declared with prefixes or as default. If future changes to oga make this impossible, it would be a blocker for me, and probably other people who need strict namespace semantics in some use cases. \n. Querying with \"xmlns:foo\" does definitely definitely not meet my needs. It is positively anti- meeting my needs. I need to query with the actual namespace URI that has been assigned to the element, as the spec suggests you should be able to do, not just query for \"an element that is in some namespace declared as a default, regardless of what actual namespace URI is in.\"\nNamespaces are confusing. I think there's no way around getting questions on it, it's going to confuse people no matter what. But at least if you stick to the spec there is a logical explanation for exactly how it works, as per spec.  Plus meet the needs of people who need a tool that works per spec. \nI also think there's nothing wrong with doing the equivalent of nokogiri's remove_namespaces! when you don't need them -- I do it myself when I don't need namespaces (and disagree with nokogiri's documentation that sort of implies some shame in it).  It could be built into oga, but either way it's easy to do with an oga AST yourself. \n. With the current API, I can do what I need, although I put my own API on top (using oga functionality underneath) to make it more convenient. If you change it, I and others who need strict namespace semantics may not be able to. shrug. \nIn my opinion, it's not a bug that the only way to query an element in a default namespace (or any other namespace) is to specify the namespace in your query. That's how XML namespaces are intended to work. If you don't want namespaces, post-process the AST to remove all the namespaces ala nokogiri remove_namespaces!. \nThe wildcard thing is nice, but it is an extra-spec feature, and if it's not feasible to implement reliably, ce la vie. But if you get rid of the ability to treat namespace semantics strictly, you will make it impossible for people who actually do need namespaces as they were intended by XML. \n. This does get confusing to talk about. (For me, using 'bar' as your example namespace makes things more confusing; namespaces will always be URI's, even if they aren't required to be).\nI get confused when you say \"querying elements with a different default namespace...  basically won't ever return results.\"  That is not true of nokogiri -- you just need to supply your namespace mapping with the query, to match elements in namespaces, always, whether default namespaces or not. \nTo make sure we're talking about the same thing: In nokogiri, if you want to match an element in a namespace, you need to supply the namespace mapping. This is true whether the namespace in question was declared as a default namespace or a prefixed namespace, and it works exactly the same way either way. \nHere's a particularly tricky example:\n```\n        \ntop\n\nbottom\n\n \ndoc.xpath(\"s:node\", \"s\" => \"http://example.org/bottom\")\n=>  returns the node inside the container with the default 'bottom' namespace,\nand NOT the upper-level node\n```\nSo I need that behavior, just like that.  With oga, I guess I'd have to use namespace-uri(), although now I'm confused if even that would work (if it doesn't, that's a bug, right?). \nHowever, I managed to write a ~dozen line extension to oga that makes it work just like that\nI guess as long as my extension can keep working, as long as oga doesn't change in a way that makes it impossible for me to extend to get the behavior I want, then it's all good with me. \nI am as bewildered as you that we don't seem to be able to understand each other on namespaces! To me, my mental model and requirements for namespaces seem the natural and clear way namespaces were intended, but you seem to have different ideas of how namespaces should be thought of and work and believe yours are the natural and clear way! It is confusing for us both to talk about it together. \n. I don't think it's confusing if you understand how XML namespaces work.  I think there's a reason that most every other namespace-aware XML processor takes this approach -- it's the one you need to have strictly correct XML namespace querying in a usable way. \nHowever, it's true that most people don't understand how XML namespaces work and find them confusing. But, I think trying to use XML namespaces without understanding how they work is a recipe for disaster (but you can always remove namespaces from your AST if you don't really need them). \nFor my example above, as long as it's possible to target both the top-level node in it's namespace (and not the bottom in the other); as well as the bottom-level node in it's namespace (without including the top in another) -- then I can probably write an extension to make it convenient.  \nThe namespace-uri approach gets so verbose and error-prone that I find it infeasible to use with my actual use cases. However, as long as it works, I can probably write a wrapper transforming from a more convenient api to a namespace-uri-containing query. (In my current extension I did not use namespace-uri, but just wrote code against the AST directly. It was quite straightforward to do in only a few lines of code with no chance of effecting oga behavior when not using my new methods.  My compliments again on how clean and easy to work with the oga code is). \nAs long as I can do what I need to do somehow, I can write a wrapper to give it a more convenient API. (Although I still think the out of th box API you are contemplating in an attempt to serve people who don't understand XML namespaces -- is not going to serve anyone very well, and is still going to confuse people on many edge cases).  What I was worried about from this ticket was that you were going to change oga in a way that made it impossible to target a particular namespace when defined as a default namespace nested in other namespaces, as per my example above. \n. I do want to clarify something -- I'm not sure if I'm beating a dead horse (sorry), or if we're still not understanding each other. You wrote:\n```\nxml = <<-EOF.strip\n\n\n20\n\n\nEOF\nNokogiri::XML(xml).xpath('root/x:first/x:first', 'x' => 'ns2')\n```\n\nIn order to query the outer <first> element we use the mapping API, assigning the \"ns2\" prefix to \"x\". This however prevents you from querying the inner <x:first> element as its namespace is overwritten using the custom prefix. You could use a different prefix but then you'd always have to ensure it's unique to all the other prefixes you might query.\n\nIt does not prevent you from querying anything. You just need to query based on the namespace URI's you want to query, completely ignoring whatever prefixes were used in the input document. The prefixes used in the input document are an implementation detail with no semantic content, the semantic content is the namespace URI's, and these are what you need to use for querying. This is my undestanding of how XML namespaces are meant to be used, why XML namespaces have URI's instead of just prefixes with no URI definitions, and how every other succesful namespace-aware XML processor I've used works. \nYou are not prevented from querying the inner <x:first>, you do it like this:\nxpath(\"ns1:first/ns2:first\", :ns1 => \"ns1\", :ns2 => \"ns2\")\n(I still suggest this would be a LOT less confusing to talk about if we used URIs for the namespace URIs, which is what is done, but I'm going with your example). \nYou don't need to use the same prefixes as in the original document, you don't even need to know what the prefixes in the original document were, and it doesn't matter if you collide with them or not. You specify what namespace URI's you wish to query and you query them. \nThese would also work:\nxpath(\"ns1:first/x:first\", :ns1 => \"ns1\", :x  => \"ns2\")\nxpath(\"x:first/ns2:first\", :x => \"ns1\", :ns2  => \"ns2\")\nxpath(\"ns1:first/ns2:first\", :ns1 => \"ns1\", :ns2  => \"ns2\", :x => \"http://example.org/other\")\nYou do not need to worry about colliding with prefixes used in the original document. The original document prefixes don't matter, you just need to specify what XML namespace URI's you want to query in your query, and what prefixes you'll be using for them in your query. This is how nokogiri works; it's also how my oga_ns convenience methods work. \n. You are simply mistaken, the nokogiri approach (and what I've implemented in oga_ns) does not require that the \"virtual prefixes\" (I would call them \"query context prefixes\") you declare do not collide with any prefixes declared in the document.  This is just not true. \nIn your example:\nNokogiri::XML('<foo xmlns=\"bar\" xmlns:bacon=\"baz\"><bacon:foo>bacon!</bacon:foo></foo>').xpath('bacon:foo/bacon:foo', 'bacon' => 'bar') # => []\nThe problem is not that bacon collides with a prefix in the original document. The problem is that you are trying to use one prefix (bacon) to apply to two different namespaces.  You need to choose a different prefix for each namespace, but it does not matter at all if they collide with prefixes used in the original document or not:\n(I'm going to change the XML namespace URIs in your example to be actual URIs, I think it makes it a lot more clear)\n``` ruby\n    doc = 'bacon!'\n# Either of these will work fine:\nNokogiri::XML(doc).xpath('bacon:foo/inner:foo', 'bacon' => 'http://example.org/top', 'inner' => 'http://example.org/inner') \nNokogiri::XML(doc).xpath('top:foo/bacon:foo', 'top' => 'http://example.org/top', 'bacon' => 'http://example.org/inner')\n\n```\nThere are two namespaces in the original document, to query involving them both you need to declare two namespaces in your query -- you can't do it with just one. But it does not matter at all whether one or both of your query context namespace prefixes collides with a prefix used in the original document, or not. \nThe prefixes used in the original document are completely irrelevant to your query, you have no access to them at all, and don't need to know anything about them, they have no effect on your query. You need to determine what namespaces you need in your query (by URI, not prefix), and define query context namespace prefixes for the ones you need.\n. No. There is no collision, and no precedence, and no need to make sure your prefixes are unique. You are mistaken about how it works. Perhaps I'm being confusing -- this stuff is very confusing to talk about. \nIn the nokogiri style you the prefixes defined in the source document are irrelevant. You can not simply use them without declaring them for your query. You always need to specify your query context namespaces, and it is completely irrelevant what prefixes were used in the original document, it doesn't matter at all if you use prefixes that were used in the source document already or not, and if they were used in the source document it doesn't matter if they referred to the same namespace URI as you are declaring for your query or not. \nThere is no collision, and no issues of precedence. There is no \"precedence\" at all. You do not need to make sure your prefixes are unique (except within your own query declerations). You don't need to pay any attention to the prefixes in the original document at all (only to the namespace URI's).  The prefixes defined in the original document are simply not used at all, ever, in querying.  \nI realize you don't like this API.  But I think it is the only approach that lets you use XML namespaces as they were intended, in a reliable way in all edge cases. I agree XML namespaces have proven to be inherently confusing for many developers, but an ambiguous API is not helpful. \nYou might want to consult with people other than me who make serious use of namespaces in their day to day work, I think they will agree with me. It's not just nokogiri. This is the way nearly every XML parsing library that supports namespaces works. \n- http://www.nokogiri.org/tutorials/searching_a_xml_html_document.html\n- http://xml.apache.org/xalan-j/xpath_apis.html#namespacecontext (it's horribly confusing in Java, but the same principle)\n- http://effbot.org/zone/element-namespaces.htm (python)\nYou are entitled to have a different opinion, of course! So long as it's still possible to get strict namespace semantics from oga, perhaps with custom code extending oga with a more convenient nokogiri/libxml/everything-else-like api, it will still be usable by me and other people who need strict non-ambiguous namespace semantics. \n. A simple example to illustrate, without even bringing default namespaces into it:\n``` ruby\n    doc = '\nhttp://example.org/one\nhttp://example.org/two\n'\nWill NOT work, you can NOT just automatically use a prefix\nfrom the source doc. Will return empty or even raise.\ndoc.xpath(\"one:node\")\nYes, you can do this, and get back the node with text \"http://example.org/one\"\ndoc.xpath(\"one:node\", \"one\" => \"http://example.org/one\")\nBut you can ALSO do this, you can re-use two as a prefix to mean whatever\nyou want; collisions with the prefixes used in the source document are fine, you\ndo not need to be aware of what prefixes were used in the source document at all\ndoc.xpath(\"two:node\", \"two\" => \"http://example.org/one\")\nAbove will return the node who's text is \"http://example.org/one\" -- NOT 'two',\nbecause you are querying for two=>http://example.org/one\nit does not matter\nthat \"two\" was used to mean something different in the source doc, there is no\nprecedence, no collision, and no need to make sure your prefixes are unique\nwith the ones used in the source document. The prefixes used in the source\ndocument have no effect whatsoever on the query -- only the namespace URIs.\n```\n. (edited the above comment, it had an important typo which completely messed it up, please consult the one on github not original sent out over email)\n. I wonder if this is something that makes sense to do with native code, in C and Java. HTML entity encoding/decoding is a very self-contained task, and a common enough one that there are probably high performance C and Java solutions. I don't know how/if that would fit into oga's codebase though. \n. Right, C and Java. \"translating HTML entities\" is a fairly well-defined problem, so I'm suspecting there is a high performance solution for both C and Java already existing, which both do the same thing. But I could be wrong. \n. @krasnoukhov For HTML data embedded in an XML document, you should not be expecting the parser to decode HTML entities. The parser has no way of knowing that that data is HTML.  The parser's job is giving back to you the exact string literal that was in the XML text node (with XML escaping undone, the literal text not the XML serialization), no more no less. \nIf you as the consumer know that that data is actually HTML, and may have HTML entities that need to be decoded -- you can use the htmlentities gem to decode it yourself, pretty easily. \nIf the parser were decoding HTML entities found in text nodes of an XML document, I would consider that a bug. \n. Can it be an option only by default turned on for HTML?  In XML, you can watch for fewer named entities... oh, but I guess you still need to handle numeric entities. Not sure if it'll actually be any faster to restrict to only what you need for XML. \nBut automatically un-escaping HTML named entities in XML might even be incorrect? Gets confusing to reason about, not sure. \n. Is there a way to turn the Hash into an actual parser/lexer, so you don't need to iterate over all the keys? In theory, if you encounter & followed by a letter that doesn't begin any of them, you can stop. Otherwise, continue with second letter, etc. \nCompiling it into a giant regexp union might  have the same effect, and also be faster than iterating through every key. \n. I'm not sure this is really true.... \nI think\n element.inner_text = '10 > 20'\nis actually invalid HTML, isn't it?  There is no special rule that says you can have un-escaped angle brackets inside a <script> block, I don't think?\nGoogling to try to figure it out, it gets confusing fast. Which is one reason people prefer linked script file instead of inline, I think! But here's one stackoverflow on it: http://stackoverflow.com/questions/8749001/escaping-html-entities-in-javascript-string-literals-within-the-script-block\n. ",
    "minad": "@YorickPeterse I don't like that Nokogiri adds some stuff everywhere (doctype, cdata in scripts, xmlns:lang attributes, ...). This is a pain point especially in combination with html5. However I like the Nokogiri API: For example element[:attribute] which is not supported by oga, there I have to write element.attribute(:attribute) which I don't like very much. I would suggest to make the API more or less compatible. I am also missing the css selector.\n. Lol, you know that you have these things fixed faster yourself than commenting on github :grinning: \n. ",
    "headius": "I tried to build and test this but there seems to be some changes in flight... Oga::XML::AST::Node class does not appear to exist.\n. Ok, after running \"rake\" it seems to load up right.\nNumbers for MRI 2.1.1 w/ ext and JRuby w/ ext. I'm not sure the MRI ext is loading right.\n```\nruby-2.1.1 ~/projects/oga $ ruby -Ilib benchmark/parser/big_xml_time.rb\n                           user     system      total        real\n10MB of XML            6.010000   0.100000   6.110000 (  6.112494)\n                           user     system      total        real\n10MB of XML            6.450000   0.050000   6.500000 (  6.500437)\n                           user     system      total        real\n10MB of XML            6.430000   0.100000   6.530000 (  6.536974)\n                           user     system      total        real\n10MB of XML            6.270000   0.040000   6.310000 (  6.315012)\n                           user     system      total        real\n10MB of XML            7.060000   0.090000   7.150000 (  7.158446)\njruby-1.7.12 ~/projects/oga $ ruby -Ilib benchmark/parser/big_xml_time.rb\n                           user     system      total        real\n10MB of XML            0.490000   0.010000   0.500000 (  0.307000)\n                           user     system      total        real\n10MB of XML            0.300000   0.000000   0.300000 (  0.235000)\n                           user     system      total        real\n10MB of XML            0.230000   0.000000   0.230000 (  0.229000)\n                           user     system      total        real\n10MB of XML            0.240000   0.000000   0.240000 (  0.235000)\n                           user     system      total        real\n10MB of XML            0.230000   0.000000   0.230000 (  0.230000)\n```\nI tried to get Rubinius numbers, but it crashed about 6 seconds into the benchmark run.\n. ",
    "khoan": "currently, failing for ill formatted feed (newline feed after <rss version=\"2.0\"). The same xml passes w3schools.com validator.\nmy 2cents, a good balance: whatever passes on w3school should pass as valid xml\n. @YorickPeterse, you're right. Looks like gist converted all the windows line feed characters into unix newline. I've now put a failing sample into git.\n``` ruby\n$ cat oga_test\n!/usr/bin/env ruby\nrequire 'oga'\nrequire 'open-uri'\nclass ElementNames\n  def on_element(namespace, name, attrs={})\n    puts namespace.inspect\n    puts name.inspect\n    puts attrs.each(&:to_xml)\n  end\nend\nhandler = ElementNames.new\nparser = Oga::XML::SaxParser.new(\n  handler, \n  open('https://raw.githubusercontent.com/khoan/rPad/master/googleshopping_1.xml').read\n)\nparser.parse\n``\n. According to [ascii table](http://ascii-table.com/control-chars.php) control+m is carriage return. So I believe it's\\r. Sorry, I got my terminology mixed up.\\n` is line feed.\nah, so in theory, all that's required is to add control+m as a newline in the lexer.\n. done: #89\n. ",
    "tak1n": "@YorickPeterse was too lazy to fork and commit, used the gh inline editor, sry for that\n. Done, sry again :)\n. ",
    "cielavenir": "What I had as the difficulty is attributes.\nI'm writing SAX wrappers.\nhttps://github.com/cielavenir/multisax/blob/master/lib/multisax.rb#L133\nMy library wrapper class receives attributes as Hash, so I had to read parser.y and I barely understood that I had to convert Array of Attributes.\nAnother concern is after_element handling. All I receive as argument is nil. I'd like to receive tag name instead.\n. ",
    "colindean": "Build failure on Travis, too.\nhttps://travis-ci.org/pittmesh/kismet-gpsxml/jobs/35231526\n. ",
    "ttasanen": "Hi, Thanks for your comments! I'll make the changes.\n. Fixed  ;) \n. Ok, I misunderstood the text part.\nBut yeah, I don't generally like the idea of a method accepting either XML::Node or String. This usually just adds unnecessary conditionals to a method. Like in methods that Rails is full of. eg.\nruby\ndef foo(id_or_hash_of_options, *args)\n  if id_or_hash_of_options.is_a?(Hash)\n    foo_with_hash(id_or_hash_of_options, *args)\n  else\n    foo_with_id(id_or_hash_of_options, *args)\n  end\nend\nBut on the other hand, this makes the API simpler for the user in some cases. Don't know if this is one. IMO it's always better to methods to do explicitly do one thing.\nShould there be two methods here? replace and replace_text or something similar?\n. Yeah, I updated the PR with the changes. \n. haha, good that someone is strict about the code consistency.. Fixed and squashed the commits. \n. ",
    "krasnoukhov": "Omg, thank you for the reply! I'll look if I can use PullParser for sax-machine then, and let you know.\n. Hey, thanks for the suggestions! Actually I can use PullParser, but the only thing it lacks is after_element callback, which would be quite useful. Do you think something like on(:after_element) can be added?\nIn a meantime, I hacked up a quick solution with class that inherits from PullParser: https://github.com/pauldix/sax-machine/commit/3ffdbdf5908031a8fb8c916b522292321bf5343a\nCheck out test suite results, there are 2 failing tests: https://travis-ci.org/pauldix/sax-machine/builds/35373044\nDo you think this is something we can deal with?\n. Thanks, new SAX interface seems exactly what I was looking for.\n. @YorickPeterse This is super cool, thanks! SAX is working like a charm. However, I found a few inconsistencies in parsing compared to Nokogiri and Ox. Is it ok if I report these as separate issues?\n. Thanks for tackling this!\n. I was making sure everything works as expected and found edge case related to the HTML unescape. Consider following snippet:\n``` ruby\nrequire 'nokogiri'\nrequire 'oga'\nxml = '<pre>{ :foo =&gt; 3, :bar =&gt; 2 }</pre>'\nputs '--- Nokogiri'\nputs Nokogiri::XML(xml).children.first.text\nputs '--- Oga'\nputs Oga.parse_xml(xml).children.first.text\n```\nAnd corresponding output:\n--- Nokogiri\n<pre>{ :foo =&gt; 3, :bar =&gt; 2 }</pre>\n--- Oga\n<pre>{ :foo => 3, :bar => 2 }</pre>\nAs you can see, Nokogiri does not transform the &amp;gt to the > symbol. Do you think Oga should do the same?\n. I believe that Nokogiri produces right output since < and > inside the HTML structure are escaped as &amp;lt; and &amp;gt; and thus should stay escaped in order to not break the HTML. I've added a PR that changes the order of transformations.\n. Hey, thanks, this looks good. Do you have plans on new version release?\n. No problem. Let me know if I can help.\n. BTW, appealing to your points:\n\nLast, simply changing the order of DECODE_MAPPING will alter the behaviour when serializing back to XML\n\nThis is not true. If you take a closer look, you'll see that reverse does the job, so the only change is that &lt; and &gt; are swapped up (compared to the current order), which is not significant.\n\nFor one, DECODE_MAPPING is meant to be a Hash and not an Array (Hash key order is guaranteed since >= 1.9). Also, using DECODE_MAPPING.reverse.map(&:reverse) just to invert things is a massive overkill.\n\nI see that it's easier to use Hash when you don't need to reverse its keys (when you just need invert). According to my logic, I want its keys reversed for ENCODE_MAPPING, and the easiest way to reverse the Hash keys is to transform it to Array and then back to Hash. It looks like a bigger overkill for me than just using Arrays everywhere, but it's up to you to decide.\n. And yes,\n\nAlso, using DECODE_MAPPING.reverse.map(&:reverse) just to invert things\n\nI'm not using this just to invert things. I'm using this to reverse the order of keys and to invert things. Maybe this is a root of confusion with my implementation.\n. I see what Hash#invert does, thanks. Actually the exact point of this PR is to have different order of keys for the decoding and encoding.\nFor decoding it should be: &lt;, &gt; and &amp;\nFor encoding: &amp;, &gt; and &lt;\nWhen transformations are applied in this order everything works correctly. Since decoded representation of &amp; (&) is a part of non-decoded &lt; and &gt; entities then &amp; should be applied last when decoding, don't you think?\nThat's my point and the goal of the PR, just to be clear.\n. Sure thing, thank you. Feel free to reopen & merge in case the overall approach is right, and add the syntax changes if any.\n. Hey, thank you for your time you're spending on this issue. I fully understand your concerns and appreciate that.\nThe reason why I'm working on this is that I want people to be able to use oga as a sax-machine handler. Actually I've already released a new version of it with oga support. There is another library, called feedjira which uses sax-machine and I believe it has users who could benefit from using oga as underlying handler.\nSo, while sax-machine specs are passing w/ oga, there are failing specs on feedjira repo and all of them are related to this issue. Please take a look on this Travis build for more details. Frankly speaking, current solution with html entities is not standard-compliant, so I'd consider it as a bug. Currently people can't rely on oga for correct HTML entities decoding/encoding, and this is quite bad. Sure, it works if they don't care about HTML inside the XML they parse. But are you sure that 100% of your users do that?\nOk, back to the issue. Here are string_average_bench.rb results on master on my machine:\n```\nIteration: 1: 0.928\nIteration: 2: 0.938\nIteration: 3: 0.934\nIteration: 4: 0.924\nIteration: 5: 1.312\nIteration: 6: 0.918\nIteration: 7: 0.925\nIteration: 8: 0.995\nIteration: 9: 1.045\nIteration: 10: 0.937\nIterations: 10\nAverage:    0.986 sec\n```\nAfter optimization with & is applied:\n```\nIteration: 1: 0.936\nIteration: 2: 0.934\nIteration: 3: 0.909\nIteration: 4: 0.939\nIteration: 5: 0.928\nIteration: 6: 0.971\nIteration: 7: 0.943\nIteration: 8: 0.926\nIteration: 9: 0.92\nIteration: 10: 1.043\nIterations: 10\nAverage:    0.945 sec\n```\nYou were right, we can benefit in speed greatly by using this simple trick!\nAfter removing global instance:\n```\nIteration: 1: 0.943\nIteration: 2: 0.972\nIteration: 3: 1.564\nIteration: 4: 1.001\nIteration: 5: 1.035\nIteration: 6: 0.946\nIteration: 7: 0.921\nIteration: 8: 0.999\nIteration: 9: 0.958\nIteration: 10: 0.929\nIterations: 10\nAverage:    1.027 sec\n```\nThis one slows things a bit comparing to the global instance option. However, it appears only about 4-5% slower than master. Let me know what you think!\n. Also, running profile/xml/lexer/big_xml.rb on master shows me constant 20.0 MB and 23.0 MB on this branch.\n. > and use that similar to the existing entities (but only for HTML documents)\n@YorickPeterse, what do you mean by that? Why is it not used only for HTML documents now?\nI agree with other suggestions. I'll try to do something in that regard this week.\n. I must disagree with that. The case I'm talking about is HTML data embedded (in encoded format) in XML document. If we change decoding occur only in HTML documents we'll loose even already existing basic support. Am I missing something?\n. I see, thanks for the explanation. However, I'm not sure why both nokogiri and ox actually do decoding. Ideas?\nHere is ox test that assures decoding: https://github.com/ohler55/ox/blob/3764d26ab44f3202508a0b5ef2f9944b68bfef75/test/tests.rb#L314-L319\nBut I wasn't able to find similar for nokogiri, however it still does that:\nruby\n2.1.5 :001 > Nokogiri::XML('<foo>&#8217;</foo>').at('foo').text\n => \"\u2019\"\n. Ok, now everything is clear. This PR indeed does not look like a good solution to the problem documented in #68, so I'm closing in favor of future effort.\n. @YorickPeterse Please take a look on this. This is an actual fix if I correctly understood the spec.\nHowever, I'm not sure about this particular spec:\nexample 'decode &#38;#38; into &' do\n  described_class.decode('&#38;#38;').should == '&#38;'\nend\nLooking at the spec, it might be that actual result should be just &. What do you think?\n. > extra context grouping isn't needed in these specs\nIt's just easier to visually distinguish logical blocks with different specs. Can I leave it or you still prefer flat structure?\n. I see, sure. I've amended my commit.\n. :heart: \n. Not sure if related/helps, but (lower is better):\n\nI've been running feedjira benchmarks on different sax-machine handlers. See this PR for the details: https://github.com/feedjira/feedjira-benchmarks/pull/1\nAs you can see, oga is slowest, for some reason. I'm actually a bit surprised, because its handler implementation is no different than ox or nokogiri and I expected to be at least the same performant as nokogiri.\nIdeas? Maybe you can spot the wrong part in handler implementation or benchmarks? Cheers :sparkles: \n. Ok, thanks for the clarification. Good luck with improvements anyway!\n. Good catch, I ran into this like yesterday, but forgot to report. See failing sax-machine build, if you're interested: https://travis-ci.org/pauldix/sax-machine/jobs/57151728\n. I still see non-decoded entities in attributes as well as text/cdata when using SAX parser. Does that mean that I have to decode these manually?\n. Thanks for the notice. In fact, everything works great, please proceed with new release!\n. Thanks! By the way, here is a small thing that I've noticed. Decoding an attribute with a &#038 in it throws the ArgumentError:\nlib/oga/xml/entities.rb:75:in `Integer': invalid value for Integer(): \"038\" (ArgumentError)\nI know that it's invalid use, but it might make sense to address this somehow.\n. Wow, that was fast! Thank you\n. ",
    "jwoertink": "Sweet! Yeah, that makes a difference. Easier to parse those and wrap if need be. Thanks!\n. ",
    "billdueber": "You mention implementing this on the Text node, but don't you also have to worry about entities in attributes, too? And of course at some point you'll need to worry about declared attributes, but maybe not right now.\n. ",
    "cj": "thanks for the quick response.  So I guess I'll do:\n``` ruby\nrequire 'oga'\nmodule Oga\n  module XML\n    class Element < Node\n      def inner_html=(text)\n        @children = NodeSet.new([], self)\n        @children << XML::Text.new(:text => text)\n      end\n    end\n  end\nend\n```\nas a quick fix for now.  also it appears that inner_text is also including the out dom element too.\n. so I ended up with this:\n``` ruby\nrequire 'oga'\nmodule Oga\n  module XML\n    class Element < Node\n      def inner_html\n        html = ''\n    children.each do |node|\n      html << node.to_xml\n    end\n\n    return html\n  end\n\n  def inner_html=(html)\n    @children = NodeSet.new([], self)\n    @children << XML::Text.new(:text => html)\n  end\nend\n\nend\nend\n```\nDo you want me to fork and send a pull request?\n. @YorickPeterse how would I add an html node, right now @children << XML::Text.new(:html => html) escapes the html.\n. so this hack seems to do the trick for now:\nruby\n      def inner_html=(html)\n        @children = HTML::Parser.new(html).parse.children\n      end\n. @YorickPeterse I can do it, I'm just trying to figure out right now why I can manipulate anything inside of body for https://gist.github.com/061a39e450d0fe7d0a4d\n. @YorickPeterse meaning doing HTML::Parser.new(html).parse.at_css('body').inner_text = 'moo' is doing nothing.\n. I'm sorry, I was just trying to write a quick example.  If you use the entire contents of Oga.parse_html https://gist.github.com/061a39e450d0fe7d0a4d and use your example, you'll see that you can't manipulate anything inside or the body.\n. ```\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4 require 'open-uri'\ntrue\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4 document = Oga.parse_html open('https://gist.githubusercontent.com/cj/061a39e450d0fe7d0a4d/raw/27ae44a7ae551b9223afe217429e496f43c4ab2d/index.html').read\nDocument(\n  doctype: Doctype(name: \"html\")\n  children: NodeSet(Text(\"\\n\"), Element(name: \"html\" attributes: [Attribute(name: \"lang\" value: \"en\")] children: NodeSet(Text(\"\\n\\n\"), Element(name: \"head\" children: NodeSet(Text(\"\\n\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"charset\" value: \"utf-8\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"http-equiv\" value: \"X-UA-Compatible\"), Attribute(name: \"content\" value: \"IE=edge\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"viewport\"), Attribute(name: \"content\" value: \"width=device-width, initial-scale=1\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"description\"), Attribute(name: \"content\" value: \"\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"author\"), Attribute(name: \"content\" value: \"\")]), Text(\"\\n\\n    \"), Element(name: \"title\" children: NodeSet(Text(\"Freelancer - Start Bootstrap Theme\"))), Text(\"\\n\\n    \"), Element(name: \"link\" attributes: [Attribute(name: \"href\" value: \"http://fonts.googleapis.com/css?family=Montserrat:400,700\"), Attribute(name: \"rel\" value: \"stylesheet\"), Attribute(name: \"type\" value: \"text/css\")]), Text(\"\\n    \"), Element(name: \"link\" attributes: [Attribute(name: \"href\" value: \"http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic\"), Attribute(name: \"rel\" value: \"stylesheet\"), Attribute(name: \"type\" value: \"text/css\")]), Text(\"\\n\\n    \"), Comment(\" HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries \"), Text(\"\\n    \"), Comment(\" WARNING: Respond.js doesn't work if you view the page via file:// \"), Text(\"\\n    \"), Comment(\"[if lt IE 9]>\\n        \\n        \\n    <![endif]\"), Text(\"\\n\"))), Text(\"\\n\\n\"), Element(name: \"body\" children: NodeSet(Text(\"\\n  \"), Element(name: \"nav\" attributes: [Attribute(name: \"class\" value: \"navbar navbar-default navbar-fixed-top\")] children: NodeSet(Text(\"\\n      \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"container\")] children: NodeSet(Text(\"\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"navbar-header page-scroll\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"button\" attributes: [Attribute(name: \"type\" value: \"button\"), Attribute(name: \"class\" value: \"navbar-toggle\"), Attribute(name: \"data-toggle\" value: \"collapse\"), Attribute(name: \"data-target\" value: \"#bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"sr-only\")] children: NodeSet(Text(\"Toggle navigation\"))), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n              \"))), Text(\"\\n              \"), Element(name: \"a\" attributes: [Attribute(name: \"class\" value: \"navbar-brand\"), Attribute(name: \"href\" value: \"#page-top\")] children: NodeSet(Text(\"Start Bootstrap\"))), Text(\"\\n          \"))), Text(\"\\n\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"collapse navbar-collapse\"), Attribute(name: \"id\" value: \"bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"ul\" attributes: [Attribute(name: \"class\" value: \"nav navbar-nav navbar-right\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"hidden\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#page-top\")]), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#portfolio\")] children: NodeSet(Text(\"Portfolio\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#about\")] children: NodeSet(Text(\"About\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#contact\")] children: NodeSet(Text(\"Contact\"))), Text(\"\\n                  \"))), Text(\"\\n              \"))), Text(\"\\n          \"))), Text(\"\\n      \"))), Text(\"\\n  \"))), Text(\"\\n\"))), Text(\"\\n\\n\"))), Text(\"\\n\"))\n)\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4  document.at_css('body')\nElement(name: \"body\" children: NodeSet(Text(\"\\n  \"), Element(name: \"nav\" attributes: [Attribute(name: \"class\" value: \"navbar navbar-default navbar-fixed-top\")] children: NodeSet(Text(\"\\n      \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"container\")] children: NodeSet(Text(\"\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"navbar-header page-scroll\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"button\" attributes: [Attribute(name: \"type\" value: \"button\"), Attribute(name: \"class\" value: \"navbar-toggle\"), Attribute(name: \"data-toggle\" value: \"collapse\"), Attribute(name: \"data-target\" value: \"#bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"sr-only\")] children: NodeSet(Text(\"Toggle navigation\"))), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n              \"))), Text(\"\\n              \"), Element(name: \"a\" attributes: [Attribute(name: \"class\" value: \"navbar-brand\"), Attribute(name: \"href\" value: \"#page-top\")] children: NodeSet(Text(\"Start Bootstrap\"))), Text(\"\\n          \"))), Text(\"\\n\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"collapse navbar-collapse\"), Attribute(name: \"id\" value: \"bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"ul\" attributes: [Attribute(name: \"class\" value: \"nav navbar-nav navbar-right\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"hidden\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#page-top\")]), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#portfolio\")] children: NodeSet(Text(\"Portfolio\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#about\")] children: NodeSet(Text(\"About\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#contact\")] children: NodeSet(Text(\"Contact\"))), Text(\"\\n                  \"))), Text(\"\\n              \"))), Text(\"\\n          \"))), Text(\"\\n      \"))), Text(\"\\n  \"))), Text(\"\\n\")))\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4 document.at_css('body').inner_text = 'bar'\n\"bar\"\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4 document\nDocument(\n  doctype: Doctype(name: \"html\")\n  children: NodeSet(Text(\"\\n\"), Element(name: \"html\" attributes: [Attribute(name: \"lang\" value: \"en\")] children: NodeSet(Text(\"\\n\\n\"), Element(name: \"head\" children: NodeSet(Text(\"\\n\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"charset\" value: \"utf-8\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"http-equiv\" value: \"X-UA-Compatible\"), Attribute(name: \"content\" value: \"IE=edge\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"viewport\"), Attribute(name: \"content\" value: \"width=device-width, initial-scale=1\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"description\"), Attribute(name: \"content\" value: \"\")]), Text(\"\\n    \"), Element(name: \"meta\" attributes: [Attribute(name: \"name\" value: \"author\"), Attribute(name: \"content\" value: \"\")]), Text(\"\\n\\n    \"), Element(name: \"title\" children: NodeSet(Text(\"Freelancer - Start Bootstrap Theme\"))), Text(\"\\n\\n    \"), Element(name: \"link\" attributes: [Attribute(name: \"href\" value: \"http://fonts.googleapis.com/css?family=Montserrat:400,700\"), Attribute(name: \"rel\" value: \"stylesheet\"), Attribute(name: \"type\" value: \"text/css\")]), Text(\"\\n    \"), Element(name: \"link\" attributes: [Attribute(name: \"href\" value: \"http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic\"), Attribute(name: \"rel\" value: \"stylesheet\"), Attribute(name: \"type\" value: \"text/css\")]), Text(\"\\n\\n    \"), Comment(\" HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries \"), Text(\"\\n    \"), Comment(\" WARNING: Respond.js doesn't work if you view the page via file:// \"), Text(\"\\n    \"), Comment(\"[if lt IE 9]>\\n        \\n        \\n    <![endif]\"), Text(\"\\n\"))), Text(\"\\n\\n\"), Element(name: \"body\" children: NodeSet(Element(name: \"nav\" attributes: [Attribute(name: \"class\" value: \"navbar navbar-default navbar-fixed-top\")] children: NodeSet(Text(\"\\n      \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"container\")] children: NodeSet(Text(\"\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"navbar-header page-scroll\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"button\" attributes: [Attribute(name: \"type\" value: \"button\"), Attribute(name: \"class\" value: \"navbar-toggle\"), Attribute(name: \"data-toggle\" value: \"collapse\"), Attribute(name: \"data-target\" value: \"#bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"sr-only\")] children: NodeSet(Text(\"Toggle navigation\"))), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n                  \"), Element(name: \"span\" attributes: [Attribute(name: \"class\" value: \"icon-bar\")]), Text(\"\\n              \"))), Text(\"\\n              \"), Element(name: \"a\" attributes: [Attribute(name: \"class\" value: \"navbar-brand\"), Attribute(name: \"href\" value: \"#page-top\")] children: NodeSet(Text(\"Start Bootstrap\"))), Text(\"\\n          \"))), Text(\"\\n\\n          \"), Element(name: \"div\" attributes: [Attribute(name: \"class\" value: \"collapse navbar-collapse\"), Attribute(name: \"id\" value: \"bs-example-navbar-collapse-1\")] children: NodeSet(Text(\"\\n              \"), Element(name: \"ul\" attributes: [Attribute(name: \"class\" value: \"nav navbar-nav navbar-right\")] children: NodeSet(Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"hidden\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#page-top\")]), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#portfolio\")] children: NodeSet(Text(\"Portfolio\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#about\")] children: NodeSet(Text(\"About\"))), Text(\"\\n                  \"))), Text(\"\\n                  \"), Element(name: \"li\" attributes: [Attribute(name: \"class\" value: \"page-scroll\")] children: NodeSet(Text(\"\\n                      \"), Element(name: \"a\" attributes: [Attribute(name: \"href\" value: \"#contact\")] children: NodeSet(Text(\"Contact\"))), Text(\"\\n                  \"))), Text(\"\\n              \"))), Text(\"\\n          \"))), Text(\"\\n      \"))), Text(\"\\n  \"))), Text(\"bar\"))), Text(\"\\n\\n\"))), Text(\"\\n\"))\n)\n\u201a\u00ef\u2260\u201a\u00ee\u00c4 Object\n\u201a\u00ef\u221e\u201a\u00ee\u00c4\u201a\u00c6\u00c4 puts document.to_xml\n<!DOCTYPE html>\n\n\n<meta charset=\"utf-8\" />\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n<meta name=\"description\" content=\"\" />\n<meta name=\"author\" content=\"\" />\n\n<title>Freelancer - Start Bootstrap Theme</title>\n\n<link href=\"http://fonts.googleapis.com/css?family=Montserrat:400,700\" rel=\"stylesheet\" type=\"text/css\" />\n<link href=\"http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic\" rel=\"stylesheet\" type=\"text/css\" />\n\n<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->\n<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->\n<!--[if lt IE 9]>\n    <script src=\"https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js\"></script>\n    <script src=\"https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js\"></script>\n<![endif]-->\n\n\n\n\n\n\nToggle navigation\n\n\n\n\nStart Bootstrap\n\n      <div class=\"collapse navbar-collapse\" id=\"bs-example-navbar-collapse-1\">\n          <ul class=\"nav navbar-nav navbar-right\">\n              <li class=\"hidden\">\n                  <a href=\"#page-top\"></a>\n              </li>\n              <li class=\"page-scroll\">\n                  <a href=\"#portfolio\">Portfolio</a>\n              </li>\n              <li class=\"page-scroll\">\n                  <a href=\"#about\">About</a>\n              </li>\n              <li class=\"page-scroll\">\n                  <a href=\"#contact\">Contact</a>\n              </li>\n          </ul>\n      </div>\n  </div>\n\nbar\n\nnil\n. as you can see the body never gets updated.\n. o nm, it did append it.... I'll have to push up the tests of the stuff I have as it's failing with that.\n. @YorickPeterse in your example above ^ `foo` isn't included in the body anywhere.........That's the issue I'm having.\n. if you change the body tag to say `test` or anything other than `body` it works.\n. The only way I can think of would be to `Oga.parse_html(your_inner_text)` and then append it to the node you were going to set the inner_text of.\n. ruby\nhtml = Oga.parse_html(some_html)\nhtml.css('#some_div').first.inner_text = 'foo'\n```\nsome_div is now &lt;h1&gt;test&lt;/h1&gt; instead of <h1>test</h1>\n. ",
    "trevorrowe": "@YorickPeterse I recently removed the dependency on multi_xml from v2 of the aws-sdk gem. It has been replaced with a sax/stack XML parser. It currently supports Ox, LibXML, and Nokogiri, with a REXML fallback.\nI removed multi_xml primarily for performance. XML responses are now parsed in a single pass, instead of parsing them into a document-like hash and then having to pass over the hash to generate response structures. Additionally, I ran into a small number of differences in the output of mult_xml from the different backends.\nI'd love to add support for Oga. I saw on your README that you support sax parsing. For reference, here are the current engines supported by the SDK:\nhttps://github.com/aws/aws-sdk-ruby/tree/master/aws-sdk-core/lib/aws-sdk-core/xml/parser/engines\nThe actual implementation tend to be very small, here is REXML's:\nhttps://github.com/aws/aws-sdk-ruby/blob/master/aws-sdk-core/lib/aws-sdk-core/xml/parser/engines/rexml.rb\nI just found the project, and was poking at the issues and saw this so I though I should comment.\n. @YorickPeterse I spent a few minutes working on adding Oga support. With very little code, I've got everything work except for errors. I can't seem to get the Oga.sax_parse_xml to emit errors for invalid XML. Looking at the xml parser docs here: http://code.yorickpeterse.com/oga/latest/frames.html#!file.README.html\nThe only hook I see is the #parser_error method and I haven't been able to trigger it.  Thoughts?\n. Currently it requires strict validation of the XML, this helps ensure the response body was not truncated. This is necessary as many services use chunked transfer encodings in the response and do not specify how many bytes to expect.\nA strict mode would be useful, and maybe would have been a good default mode when working with XML. I can probably work around this currently by simply ensuring that every opened element is closed in the correct order when handling the SAX events.\nMost of that code is for building the XML elements, but tracking the indentation of a child isn't too hard.\n. Did you have an idea of where you would like to hang the pretty formatter? Do you envision this as an extension of Oga::XML::Document#to_xml? I would be interested in contributing.\n. I would expect the default behavior to produce XML without any extra whitespace, preserving only whitespace inside text elements.\nI have experience building structured XML documents. I wrote this to be able to remove the aws-sdk's dependency on the builder gem: https://github.com/aws/aws-sdk-ruby/blob/version-2.1-refactor/aws-sdk-core/lib/aws-sdk-core/xml/doc_builder.rb\n. Sorry for the slow reply.\nIt is possible to receive truncated responses from a few services. When the service does not send a content length with the response, it is not possible to do a simple bytes received check. In these cases, I expect the XML or JSON parser to raise an error when the document is not well-formed. AWS services should only return strictly valid XML documents.\nIf the parser is inserting missing closing tags, that is sufficient for me to assert that something is wrong with the response. Currently the SDK has the ability to retry these failed responses.\n. @YorickPeterse Works great! I pushed a branch of aws-sdk that uses Oga which passes all of the SDK XML parser and protocol tests.\n. ",
    "detomastah": "Thanks for really quick response. I would like to fix the problem on my own, even peeked at the code and grammars...\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<?xml-stylesheet type=\"text/xsl\" href=\"../../../xml/stylesheets/page.xsl\"?>\n\n\n\n      W przypadku powy\u017cszego programu prawdopodobie\u0144stwo wy\u015bwietlenia wzrasta! S\u0142owo print po angielsku oznacza \"drukuj\". Jednak nadal nie wiesz czy na pewno tak b\u0119dzie. By\u0107 mo\u017ce s\u0142owo print w tym programie oznacza w\u0142\u0105czenie \u017car\u00f3wki o numerze 10. Nie dowiesz si\u0119 tego, dop\u00f3ki nie poznasz specyfikacji j\u0119zyka.\n    \n\n\n```\nThis is the xml which does not render correctly. On Nokogiri I have the other problem, after some processing when I call .to_s all the <exp></exp> tags are removed. That was my motive to use Oga. In oga, in the same example it puts all the exp's at the beginning of the content, so I got:\nxml\n<exp>print</exp><exp>print</exp>The rest of the text\n. Sorry for taking your time. I found the problem - it was my fault. One of the routines was doing something like this:\nruby\ndoc.xpath(\"//p\").each do |el|\n  el.inner_text = el.inner_text.strip\nend\nAfter that all the elements inside <p> are moved to the beginning as I described above.\n. Thanks!\n. ",
    "SamSaffron": "I started something tiny here (not production grade with many glitches, but something) \nhttps://github.com/discourse/discourse/blob/markdownit/lib/html_normalize.rb \nI think you need a separate normalizer for xml vs html4 vs html5 \nPretty and consistent formatting is super critical for test stability. For example we are switching markdown parsers and the new one generates equivalent html to the old on (semantically) though visually they look different. Figuring out a good strategy for interior spaces is huge. \nIn other news I am considering dropping nokogiri from Discourse \n. @YorickPeterse  I will see how we go, I have a GSOC student I will be tasking at migrating Discourse to oga after that we may be able to look at the formatter, I was thinking of a multiple formatters cause:\n```\n\n\n\nvs\n\n\n\n```\nbtw... quick one, I noticed you decided on mpl 2 license, is there a technical reason you went with that vs the more common mit/bsd? I do not think it creates any problems for us but it does make it harder for lawyers to reason about things. (I do not think we have any MPL 2 code in Discourse at the moment, all 3rd party deps are MIT/BSD) . ",
    "timshadel": "May I request something similar to Nokogiri's API,\nto_xml(indent: 7)\nI use this to format Apple PList files used in iOS apps for translation. I had never seen such an odd number used for indentation before working with those documents, but it'd make transitioning from Nokogiri to Oga remain really easy if the pretty printing options were similar as well. \ud83d\ude04 . ",
    "ImaginateWayne": "Thanks for the detailed response, it looks like you have put a lot of thought into it already, and if I'm honest I only wanted to make use of the equals operator for my rspec tests to make sure my document is getting parsed through a multi-parser method I've written...\nIn the spirit of solving problems because it's fun, I started thinking that equality through node comparison only becomes expensive in a large document with many nodes when the documents are actually equal because you could return false during the recursive comparison as soon as an element or structure (node count) is found to be unequal.\nAfter wondering how many people would do the whole document comparisons and coming to the conclusion that it's an unlikely uses case,  I discovered a way to cheat for my purposes and that's to use the .to_xml method which seems to print the document out as a string.\nIs there any reason the .to_s method doesn't do this? \nRegardless a .to_s method could be an easy way to get basic comparison though it has it's short comings also.\nLet me know if you would like me to take a look at it?\n. ",
    "Arcovion": "I see, it just so happens the other two sites I was trying to parse have this namespace attr too.\nFor the examples I was just thinking of larger documents and real URLs as opposed to small snippets of local text which are in your specs/readme. E.g. an oft-used example for web crawlers is downloading xkcd comics without using the API:\n``` ruby\nrequire 'oga'\nrequire 'open-uri'\nhomepage = open 'http://xkcd.com', &:read\nimg_url  = Oga.parse_html(homepage).at_xpath 'string(//*[@id=\"comic\"]/img/@src)'\nimg_name = File.basename img_url\nimg      = open img_url, &:read\nFile.write img_name, img, mode: 'wb'\n```\nThis doesn't serve to describe Oga's features, but it's showing how you might use it and presents a more complex XPath to show how powerful they are. I say this as some users may be unfamiliar with them - Python's popular Beautiful Soup library for example doesn't support XPaths! Personally I think they're the best way to parse HTML/XML and should be advertised as such.\nFurthermore, examples like this are self-contained so they can be copied and pasted straight from the Readme like Nokogiri's synopsis, this gives you a working example/walkthrough out of the box (which is what I looked for and found in your blog post).\n. Here's some from the top 100:\n- [x] https://google.com\n- [x] https://yahoo.com\n- [x] https://amazon.com\n- [ ] https://yandex.ru\n- [x] https://linkedin.com\n- [x] https://www.ebay.com\n- [x] https://instagram.com\n- [x] https://vk.com\nhttps://github.com/YorickPeterse/oga/issues/83#issuecomment-81768893 should address (not parse errors):\n- [x] https://reddit.com\n- [x] https://imgur.com\nLooks like the vast majority of websites are ok though!\n. I get \"hello&nbsp;&nbsp;\" for each of those, what happens if you try p str.chomp '&nbsp;&nbsp;'?\nEdit: I think my Oga version was out of date, now I get \"hello\\u00A0\\u00A0\" - easily changed with \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 p str.gsub ?\\u00A0, '&nbsp;'\nIt would be nice if Oga had utility methods for HTML entity encoding/decoding now that it can parse them. Otherwise we have to use separate libraries for entity conversion.\n. Thx, how about an encode method for HTML entities?\nMy encoding is alright: ?\\u00A0 == [160].pack('U') - it's not a problem with your gem. =]\nEdit: Some of the characters are not being packed correctly:\nruby\n$ irb -E ASCII\n2.2.1 :001 > [8746, 65024].pack 'U'\n => \"\\u222A\"\n2.2.1 :002 > [8764, 65024].pack 'U*'  # Must be U2 or U*\n => \"\\u223C\\uFE00\"\nI think it's better to use raw strings: \"\\u222A\\uFE00\"\nFailing that: '' << 8746 << 65024\nBoth are faster than using Array#pack\n. Yea I was thinking it wasn't encoding some things:\nruby\n$ irb -r oga\n2.2.1 :001 > Oga::XML::Entities.encode '\u00a9'\n => \"\u00a9\"\nBut actually it's not needed, HTMLEntities has a way to use named stuff for everything, hexadecimal and other things but that's beyond the scope of this gem:\nruby\n$ irb -r htmlentities\n2.2.1 :001 > HTMLEntities.new.encode '\u00a9'\n => \"\u00a9\"\n2.2.1 :002 > HTMLEntities.new.encode '\u00a9', :named\n => \"&copy;\"\nAlso the decoders behave slightly differently, so I assumed there would be two encoders - probably doesn't matter but from a usability perspective it makes sense I think:\nruby\n$ irb -r oga\n2.2.1 :001 > Oga::XML::Entities.decode '&nbsp;'\n => \"\"\n2.2.1 :001 > Oga::HTML::Entities.decode '&nbsp;'\n => \"\u00a0\"\nI'm only using ASCII for clarity, it shouldn't affect the behaviour of anything internally, just how the output is displayed. You get the same character regardless of how you construct the string or display it:\nruby\n$ irb -r oga\n2.2.1 :001 > Oga::HTML::Entities::DECODE_MAPPING['&cups;']\n => \"\u222a\"\n2.2.1 :002 > \"\\u222A\\uFE00\"\n => \"\u222a\ufe00\"\nNote these two are different, the latter is the correct conversion for &cups;. You can't see the difference because I turned off ASCII encoding...\n\nThis doesn't produce the correct output either when the external encoding is set to ASCII.\n\nI'm saying there's a bug in how Oga is decoding it, there should be two characters there - it's correct. What output are you seeing? Maybe I'm missing something, I haven't tried this on older rubies.\n. > There's currently no Oga::HTML::Entities.encode because Oga itself has no use case for such a method.\nIt would be nice to have this though, Oga could be both a HTML/XML parser and an entity converter. I just think it would be a useful utility, for example the HTMLEntities gem isn't able to decode &cups; but your gem can - just add Oga::HTML::Entities.encode and you have a full converter!\nEdit: By HTML encoding I simply mean: \"\\u222A\\uFE00\" \u2192 \"&#8746;&#65024;\", named entities aren't needed as browsers don't even support some of them like &cups;.\n\nOga uses [8746, 65024].pack('U') this doesn't actually produce a string that uses the exact same input codepoints\n\nThis is a bug, no? You can fix it with U* instead of U for all of the entities.\nUsing pack is expensive compared to the other two ways I mentioned though, I think it's worth changing them. I can put together a PR to change them all to UTF-8 or ASCII strings, what do you think?\n. xml_node.name.casecmp(name).zero? is faster/more efficient here\n. ",
    "giuan": "The XML is http://jmatchparser.sourceforge.net/factbook/data/factbook.xml.gz\n``` ruby\nrequire 'oga'\nrequire 'benchmark'\nhandle = File.open('factbook.xml')\ndoc = nil\nputs \"parse_xml\"\nputs Benchmark.measure {doc = Oga.parse_xml(handle)}\nputs \"factbook > region > country > field[ref='f2004']\"\nputs Benchmark.measure {\n  elems = doc.css(\"factbook > region > country > field[ref='f2004']\")\n  puts elems.size\n}\nputs \"css: country field[ref='f2004']\"\nputs Benchmark.measure {\n  elems = doc.css(\"country field[ref='f2004']\")\n  puts elems.size\n}\nputs \"/factbook/region/country/field[@ref='f2004']\"\nputs Benchmark.measure {\n  elems = doc.xpath(\"/factbook/region/country/field[@ref='f2004']\")\n  puts elems.size\n}\nputs \"//country/field[@ref='f2004']\"\nputs Benchmark.measure {\n  elems = doc.xpath(\"//country/field[@ref='f2004']\")\n  puts elems.size\n}\n```\nparse_xml\n  5.000000   0.140000   5.140000 (  5.209589)\ncss: factbook > region > country > field[ref='f2004']\n232\n  3.550000   0.140000   3.690000 (  3.715155)\ncss: country field[ref='f2004']}\n232\n  4.270000   0.100000   4.370000 (  4.419504)\n/factbook/region/country/field[@ref='f2004']\n232\n  1.090000   0.010000   1.100000 (  1.130438)\n//country/field[@ref='f2004']\nafter an hour no response\nI tried with jruby 1.7.16 same problem\nI think that css \"country field[ref='f2004']\" is similar to \"//country/field[@ref='f2004']\".\n. I tried with nokogiri.\nThe result:\nparse_xml\n  0.330000   0.070000   0.400000 (  0.410540)\nfactbook > region > country > field[ref='f2004']\n232\n  0.150000   0.000000   0.150000 (  0.144159)\n/factbook/region/country/field[@ref='f2004']\n232\n  0.120000   0.000000   0.120000 (  0.130721)\ndescendant::country/field[@ref='f2004']\n232\n  0.150000   0.000000   0.150000 (  0.150887)\n//country/field[@ref='f2004']\n232\n  0.150000   0.000000   0.150000 (  0.150868)\ncss country field[ref='f2004']\n232\n310.580000   1.670000 312.250000 (324.329383)\nNokogiri has the same problem with css\n. With 0.3.3   ruby 2.2.1.\nThe file is 9.1MB\n20%-30% better. Good!\n```\nparse_xml\n  4.290000   0.140000   4.430000 (  4.525548)   old (  5.209589)\nfactbook > region > country > field[ref='f2004']\n232\n  3.500000   0.070000   3.570000 (  3.601097)   old (  3.715155)\ncss country field[ref='f2004']\n232\n  3.000000   0.010000   3.010000 (  3.036254)  old (  4.419504)\n/factbook/region/country/field[@ref='f2004']\n232\n  0.870000   0.000000   0.870000 (  0.870964)  old (  1.130438)\ndescendant::country/descendant::field[@ref='f2004']\n232\n  3.020000   0.010000   3.030000 (  3.050675)\n//country/field[@ref='f2004']\nafter an hour no response\n```\n. parse_xml\n  4.290000   0.140000   4.430000 (  4.525548)   old (  5.209589)\nold (  5.209589) is the total time with oga 0.2.3\n. I think that it's difficult to make things a lot faster. Nokogiri is almost C (right?) and it's 10x faster than oga, but it's normal for C vs Ruby.\nI know that you work on Rubinius. The numbers are bad.\nAfter 3 iteration in version 2.5.2:\nparse_xml\n 19.324621   0.305672  19.630293 ( 20.220511)\nfactbook > region > country > field[ref='f2004']\n232\n 10.253330   0.101667  10.354997 ( 10.730601)\ncss country field[ref='f2004']\n232\n 11.223590   0.105031  11.328621 ( 11.514171)\n/factbook/region/country/field[@ref='f2004']\n232\n  2.036197   0.014075   2.050272 (  2.127982)\ndescendant::country/descendant::field[@ref='f2004']\n232\n  8.470855   0.059776   8.530631 (  8.921993)\n. ",
    "lham": "Well, some further investigation shows that &nbsp; is replaced by ASCII DEC 160 (which is a non-breaking space) and not by ASCII DEC 32 which is the normal space character. This makes sense when I think about it. \nSome googling gave me http://stackoverflow.com/questions/8653661/cant-split-strip-by-space-in-a-string-in-ruby-because-its-an-nbsp-character which points out why this happens in ruby. To quote:\n\n\\s matches only ASCII spaces, while [[:space:]] will match all unicode spaces\n\nso the solution would be to use str[/^[[:space:]]*(.*?)[[:space:]]*$/, 1] instead.\n. ",
    "skoona": "Ok, the workaround solved my issue.  I was able to make the switch to Oga with very little effort, for a great benefit to my project.    Thanks for creating this gem, is was sorely needed.\n. ",
    "binaryplease": "I see. \nLet me know if its fixed or there is a workaround. I would really like to use the gem for a crawler Project.\n. Thanks! \nCan I just upodate the gem using \"gem update\" ?\n. Still happening: \n``` ruby\nurl = \"http://eviemai.co.uk/\"\nc = HTTPClient.new\ncontent = c.get_content(url)\ndocument = Oga.parse_html(content)\n```\n```\nLL::ParserError: Unexpected end of input, expected doctype closing tag instead on line 1\n  parser_error at /home/binaryplease/.rvm/gems/jruby-1.7.19/gems/oga-0.3.2-java/lib/oga/xml/parser.rb:271\n    each_token at /home/binaryplease/.rvm/gems/jruby-1.7.19/gems/oga-0.3.2-java/lib/oga/xml/parser.rb:247\n         parse at org/libll/Driver.java:303\n         parse at /home/binaryplease/.rvm/gems/jruby-1.7.19/gems/oga-0.3.2-java/lib/oga/xml/parser.rb:278\n    parse_html at /home/binaryplease/.rvm/gems/jruby-1.7.19/gems/oga-0.3.2-java/lib/oga/oga.rb:25\n        (root) at test.rb:25\n```\n. When will this fix be released?\n. ",
    "abotalov": "I'd like to note that HTML 5.1 spec is has a bit more examples - http://www.w3.org/TR/html51/syntax.html#syntax-tag-omission\n. Do you think it makes sense to insert start tags if end tags are present? (in situations where it should be done according to HTML spec)\nruby\nOga.parse_html('</html>')\n. colgroup / tr / th elements are still closed in incorrect places.\nE.g.:\n``` ruby\n\nputs Oga.parse_html(File.read('file.html')).to_xml # file.html contains the first snippet from issue description\n```\n\nresults in:\n<table>\n <colgroup><col /><col /><col />\n <thead>\n  <tr> <th>Function                              </th><th>Control Unit     </th><th>Central Station\n <tbody>\n  <tr> <td>Headlights                            </td><td>\u2714                </td><td>\u2714\n  <tr> <td>Interior Lights                       </td><td>\u2714                </td><td>\u2714\n  <tr> <td>Electric locomotive operating sounds  </td><td>\u2714                </td><td>\u2714\n  <tr> <td>Engineer&apos;s cab lighting               </td><td>                 </td><td>\u2714\n  <tr> <td>Station Announcements - Swiss         </td><td>                 </td><td>\u2714\n</td>\n</tr></td></tr></td></tr></td></tr></td></tr></tbody></th></tr></thead></colgroup></table>\n. I made some checks.\nSome inconcistences with the current implementation (http://www.w3.org/TR/html51/semantics.html#the-table-element):\n1. caption element should be also automatically closed by colgroup or tr start tag\n2. colgroup element should be also automatically closed by colgroup or tr start tag\nAlso there's an issue that seems a bit wider - elements don't always become closed when end tag is encountered (if there is no more content in the parent element):\nhtml\n<table>\n <tbody>\n  <tr>\n   <td>Ms Danus\n</table>\n<form id=f action=\"/auction.cgi\">\n <input type=button name=add value=\"Submit\">\n</form>\nWhen this is parsed, table element is closed only after form element but it should really be closed before it.\nAlso look at code example in http://www.w3.org/TR/html51/semantics.html#the-optgroup-element. Here p element isn't closed and select element is followed after it. p element should be closed before select element start tag as:\n\nA p element's end tag may be omitted if the p element is immediately followed by an address, article, aside, blockquote, details, div, dl, fieldset, figcaption, figure, footer, form, h1, h2, h3, h4, h5, h6, header, hgroup, hr, main, menu, nav, ol, p, pre, section, table, or ul, element, or if there is no more content in the parent element and the parent element is an HTML element that is not an a, audio, del, ins, map, noscript, or video element.\n. > In the example above we know that a <form> element can not reside in a <td>, <tr>, <thead> and <table> element\n\nThat's not true.\nThe form element can be used where flow content is expected. The td element's content model is flow content so td element may contain form element.\nIn an example above form element doesn't belong to td because table element is closed and the series of rules:\n\nA tbody element's end tag may be omitted if ... there is no more content in the parent element.\nA tr element's end tag may be omitted if ... there is no more content in the parent element.\nA td element's end tag may be omitted if ... there is no more content in the parent element.\n. > When we bump into a new open tag while we're still in an unclosed tag, check if said new tag is allowed inside the unclosed tag. If this is not the case the unclosed tag is closed first.\n\nI don't think it's correct. New elements may appear in HTML spec and it's not correct to say that such new elements can't contain any content.\nAlso it's possible to use custom elements - http://stackoverflow.com/questions/9845011/are-custom-elements-valid-html5\n. I think the list of optional tags listed here is full. No other elements may have end tags that can be omitted.\n. https://github.com/w3c/web-platform-tests/blob/master/html/semantics/interactive-elements/the-details-element/details.html\nIn this example p tag should be closed prior to details tag.\n\nA p element's end tag can be omitted if the p element is immediately followed by an address, article, aside, blockquote, details, div, dl, fieldset, figcaption, figure, footer, form, h1, h2, h3, h4, h5, h6, header, hgroup, hr, main, menu, nav, ol, p, pre, section, table, or ul, element, or if there is no more content in the parent element and the parent element is an HTML element that is not an a, audio, del, ins, map, noscript, or video element.\n\nI think that's because elements that appeared in HTML 5.1 spec aren't supported.\n. One more example:\nhtml\n <object>\n  <ul>\n   <li>Li\n  </ul>\n  Inside object\n </object>\n Outside object\nis currently equivalent to:\nhtml\n <object>\n  <ul>\n   <li>Li\n  </li>\n  Inside object\n </ul>\n Outside object\n</object>\n. http://www.w3.org/TR/html51/syntax.html#attribute-value-(unquoted)-state\nHere it's said that such syntax leads to a parse error. But also it says that a quote should be considered part of the attribute value - \"Treat it as per the \"anything else\" entry below.\"\nGoogle Chrome parses the snippet as (behavior seems to be according to the spec):\nhtml\n<div width=\"97%&quot;\"></div>\n. I've found the following section in the spec - http://www.w3.org/TR/html51/syntax.html#serialising-html-fragments\nThe following part seems to be interesting:\nIf the algorithm was invoked in the attribute mode, replace any occurrences of the \"\"\" character by the string \"&quot;\".\nIf the algorithm was not invoked in the attribute mode, replace any occurrences of the \"<\" character by the string \"&lt;\", and any occurrences of the \">\" character by the string \"&gt;\".\nGoogle Chrome's behavior seems to be consistent with those rules:\nhtml\n<div a=\"&lt;&gt;&quot;\">&lt;&gt;&quot;</div>\nleads to the following HTML:\nhtml\n<div a=\"<>&quot;\">&lt;&gt;\"</div>\n. Actually, Nokogiri parses it as said in the spec:\nruby\nNokogiri::HTML.fragment(File.read('file.html'))\n => #<Nokogiri::HTML::DocumentFragment:0x822 name=\"#document-fragment\" children=[#<Nokogiri::XML::Element:0x820 name=\"script\" children=[#<Nokogiri::XML::Text:0x81e \"\\n  var example = 'Consider this string: <!-- <script>';\\n  console.log(example);\\n</script>\\n<!-- despite appearances, this is actually part of the script still! -->\\n<script>\\n ... // this is the same script block still...\\n\">]>]>\n. (Just a comment)\nThere are a number of symbols that might be contained in tag name:\nhttp://www.w3.org/TR/xml/#NT-Name\nOnly alphanumeric ASCII characters are allowed in HTML, however:\nhttp://www.w3.org/TR/html51/syntax.html#syntax-tag-name\n. Duplicate of https://github.com/YorickPeterse/oga/issues/126\n. The rules are actually different as the following series of examples shows:\n| Source | Result |\n| --- | --- |\n| <3 | <3 |\n| <unknown |  |\n| <12345 <unknown <strong | <12345 |\nIn Tag open state only letters can appear. So <3 should immediately lead to emitting &lt;.\n. In XML, though, numbers can appear in tag names - http://www.w3.org/TR/REC-xml/#NT-NameChar\n. In HTML the tag token is emitted only when > character occurs - http://www.w3.org/TR/html51/syntax.html#tag-name-state / http://www.w3.org/TR/html51/syntax.html#after-attribute-value-(quoted)-state\nAt the end of the document the nodes are just popped - http://www.w3.org/TR/html51/syntax.html#the-end\n. The following info from the HTML spec seems to be relevant:\n\nAttribute names must consist of one or more characters other than the space characters, U+0000 NULL, U+0022 QUOTATION MARK (\"), U+0027 APOSTROPHE ('), \">\" (U+003E), \"/\" (U+002F), and \"=\" (U+003D) characters, the control characters, and any characters that are not defined by Unicode\n\nSee also http://www.w3.org/TR/html51/syntax.html#attribute-name-state\nThe subset of symbols allowed in XML is smaller, however.\n. ",
    "pcasaretto": "Nokogiri was driving me crazy assuming too much either adding tags when using full docs or removing them when using fragments.\nThanks for this! \ud83c\udf7b . In any case, am I right to assume it should not raise an exception whatever the input is?\nWould checking what nokogiri does with this help?\n. Got it. How can I help?. > Oga does not guarantee it will never raise an exception when parsing input\nAre there known cases where this will happen?\n\nThis however is weird because doctypes can not have child nodes\n\nI understand that they should not, semantically. But from my (biased and limited) perspective, I expected Oga not to \"enforce\" that, the same way that it does not \"enforce\" valid html like automatically adding closing tags.. So I should always protect the parse call with a rescue clause when reading user input.\nAnd that makes total sense. Regardng this particular case, in my mind, a node is a node. Some nodes are expected not to have children but I don't think Oga should treat them differently than other nodes.\nBut like I said, I trust your judgement a lot more than mine.. Thanks! Sorry I could'nt make myself more useful.. ",
    "petergoldstein": "@YorickPeterse Ok.\nThat said, in my view the build tag isn't for you, it's for the consumers of the repo.  One of the first things I look for when I consider incorporating an open source library is the state of the tests.  The Travis build status is there for the people who swing by the repo, are considering using oga, and want to know that it's well tested and that the specs are maintained/green.\n. ",
    "davidcelis": "Someone would either need to fork mechanize to create a version that uses Oga, or submit a pull request to Mechanize that replaces the dependency. Given that Mechanize is another sparklemotion gem, my guess is they aren't interested in replacing Nokogiri as a dependency\n. ",
    "muescha": "i think the eazy form handling from mechanize i need to rebuild with httpclient/oga or are there some helper gems?\n. ",
    "yb66": "I've changed the regex. There was no need to add a new failure spec as one of the ones I'd already done catches it, which is nice ;-)\n. I prefer should too, but I wasn't going to arse around with using non-standard syntax like lambda to write a one line spec for failure. YMMV\n. It's fail because it's a failure, not a re-raise. I'm not raising the error, it's failing a contract.\ntry_decode does check for this (though I couldn't see a reason why it's structured this way, a comment would be nice) but that's the point - if it gets this fair it should fail. Hence why I didn't add anything to try_decode, even though it should probably have more argument checks.\n. ",
    "rubyjedi": "'Happy to put in a spec to test for inline dots -- should show up alongside this P/R in a few hours.\nAs for refactoring the lexer, I'd much prefer leaving that to your expertise. Thanks for all your great work, guys! Much appreciated!\n. .. remind me not to push code so late at night, nor early in the morning before coffee. :o)\nThis spec update should be much more appropriate.\n. ",
    "jakubpawlowicz": "Btw, happy to send a PR if you think it's a good idea.\n. Great, I'll come back with some code :+1: \n. There you go. I've also removed |match| as it's not used.\n. Thanks @YorickPeterse, looking forward to seeing it released!\n. :boom: that was quick, thanks!\n. Ah, it makes sense. Unfortunately the <param></param> is so common...\nLet's see if the change you suggested breaks other tests!\n. This should be it.\n. Yeah, I wasn't super happy about it either. Let's split it then.\n. Sure thing, I'll change the commit!\n. ",
    "gurgeous": "Can you just make them all case insensitive? This seems like the right choice for handling dirty input.\n. ",
    "omninonsense": "Oh, and I vote for &#xhhhh; as the numeric format, because it's easier to recognise (visually) those as unicode codepoints over the decimal counterparts.\nAlso because they might turn out a few bytes shorter than the decimal ones?\n. The use case could be the user is limited to outputting an ASCII-only stream\u2014for whatever reason.\nI don't find the first part of 1 to be that problematic (You can always shoot the roosters :wink:), however I do agree that it might case performance issues; 2 didn't cross my mind, actually.\nAbout second part of point 1, and point 2: the solution could be something along the lines of adding Node#encode, which accepts a block/Proc?\nDuring serialization, the node would be encoded using its own encoder.\nSet the default encoder for each node to the current encoder (encoding only HTML significant symbols). Setting the encoder on a Node makes all child nodes inherit that encoder.\nUsage example\nInput:\nhtml\n<span>\u304a\u304c <span class=\"entities\">\u2764</span> &#x30a8;&#x30f3;&#x30b3;&#x30fc;&#x30c7;&#x30a3;&#x30f3;&#x30b0;</span>\nRuby code:\n``` ruby\ndocument = Oga::parse_html(input)\nto_hex_entity = Proc.new do |cp|\n  if (ch = cp.chr Encoding::UTF_8).ascii_only? then ch else \"&#x#{cp.to_s 16};\" end\nend\ndocument.css('.entities').each do |element|\n  element.encode(&to_hex_entity)\nend\ndocument.to_xml\n```\nOutput:\nhtml\n<span>\u304a\u304c <span class=\"entities\">&#x2764;</span> \u30a8\u30f3\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0</span>\n\nI realise that a per-node encoding might be overkill, and that the user can encode the serialized string before sending it for further processing. More control isn't required, but nice and it can't hurt. I believe users shouldn't be forced into a single way of serializing the content (IHMO).\n. Browsers would treat this attribute simply as g:plusone:size and allow it, but it's technically not valid HTML5 (according to validator.w3.org):\n``` javascript\nvar div, a;\ndiv = document.createElement('div');\ndiv.innerHTML = '';\na = div.children[0];\na.getAttribute(\"g:plusone:size\"); // \"small\"\n``\n. +1 for Opt 1, too.\n. @bryanp Slightly offtopic, wouldn't it be wiser to send aContent-Type: text/html; charset=utf-8header&mdash;provided that you have control over the headers being sent&mdash;instead of having using ameta` tag. Since, the latter in some cases might cause the browser to discard the current DOM and start re-parsing the content all over again, although I forgot what triggers it specifically.\n. ",
    "0mega": "Correct it's the one I used. You are right, the #open() itself returns some unreadable result.\nThanks for your time.\n. ",
    "ascastro": "Thanks for replying so quickly.\nThere are lot of web pages using that syntax to generate Google +1 buttons, Facebook, ... I believe this comes from AddThis, but I can't be sure if it's the only place:\nhttp://support.addthis.com/customer/portal/articles/381237-third-party-button\nThe attribute name would be size, and the element g:plusone.\nAnother option would be to have a 'non-strict' mode when parsing HTML, so that we could swallow those exceptions and skip attributes that can't be parsed.\n. +1 for option 1!\n. ",
    "walro": "Thanks for getting back to me.\n\n@walro What kind of behaviour would you expect instead?\n\nIdeally, no error at all :-). If decode fails for a single character it could return the character as-is (undecoded).\nI started to investigate a bit, it seems like https://github.com/YorickPeterse/oga/blob/76b183e7abc78e42e4651cd3e37ced3e57b74cf3/lib/oga/xml/entities.rb#L77-L79 will convert &#2013266165; into an invalid character which later on causes the UTF-8 error. Maybe it's possible to test the validity before proceeding?\n\nI'm not a fan of catching ArgumentError and simply re-raising EncodingError as this doesn't help the user all that much\n\nI think it could be a bit helpful if an error pertaining to this library would be raised (say Oga::EncodingError) rather than the more generic ArgumentError. For instance, the end user could introduce a somewhat \"safer\", less broad, rescue.\nInterestingly enough I happened to notice that the reproduction steps does not trigger an error when using pry instead of irb, I can't figure out why. We have encountered the error in the wild though.\n. Thanks, seems to be working great!\n. ",
    "EHadoux": "Ok, I see, thanks.\nHowever, I want to have them in different variables so I guess the 'div/descendant-or-self::img | div/descendant-or-self::span' won't help me. My question was in fact: is it really better to get out the div scope and fetch what I want from that scope (if I was several stuffs to get) than to always fetch from doc and thus going all the way down in the html source each time?\nI mean, in my example 1, I take out the div 1 from the whole doc and make my query on it instead of on the whole doc.\nIn the other hand, I guess for my example 2 that the parser goes from the very beginning each time I call .css right?\n. Perfect, thanks!\n. ",
    "jbr": "Yeah, I was concerned about the overhead of method calls, was planning on benchmarking. As it is, Loofah likely has more overhead from this extension pattern than I would have expected anyone would be okay with. Dependency injection (providing a custom class) seems like a good solution to the problem, except for the fact that there is a whole class hierarchy involved.\nHere's my concern about classes-as-instance-variables-style dependency injection: If Loofah wants to extend a class in the middle of the class hierarchy, they'll need to subclass all descendant classes as well, which might entail a lot of boilerplate. If we want to add a method to all Node (or subclass of Node) instances, wouldn't they have to provide a custom subclass of Element, Node, CharacterNode, TextNode, Cdata, ProcessingInstruction, Comment, etc?\n``` ruby\nclass MyElement < Oga::XML::Element\n  include MyParser::SpecialNodeBehavior\nend\nclass MyCharacterNode < Oga::XML::CharacterNode\n  include MyParser::SpecialNodeBehavior\nend\n\u2026etc, for each of the classes\nclass MyParser < Oga::XML::Parser\n  def initialize\n    super\n    @element_class = MyElement\n    @character_node_class = MyCharacterNode\n    #\u2026 etc, for each of the necessary Node subclasses\n  end\nend\n``\n. Had another chance to look at this.  I think there might be a way for Loofah to get away with subclassingOga::XML::Parserand overriding each of theon_\u2026methods with only minimal changes to oga.  Is that a stable API / safe to build on? Additionally, loofah would need to overrideDocument#childrenandDocument#children=to return Loofah'sNodeSet`.  Do you prefer the ivar approach?\nThe changes that would be required in oga are along the lines of moving the majority of the on_\u2026 methods into the relevant initializers.\nFor example, in order to avoid repeating details in on_document,\n``` ruby\n      def on_document(children = [])\n        document = Document.new(:type => @lexer.html? ? :html : :xml)\n    children.each do |child|\n      if child.is_a?(Doctype)\n        document.doctype = child\n\n      elsif child.is_a?(XmlDeclaration)\n        document.xml_declaration = child\n\n      else\n        document.children << child\n      end\n    end\n\n    document\n  end\n\n```\nThe doctype/xml_declaration stuff would happen in Document's initializer. This simplifies overriding Oga::XML::Parser#on_document without adding another method call anywhere\n``` ruby\n--- in oga\nclass Oga::XML::Parser\n  def on_document(children = [])\n    Document.new(:html => @parser.html?, :children => children)\n  end\nend\n--- in loofah\nclass Loofah::XML::Document < Oga::XML::Document\n  include Whatever\nend\nclass Loofah::XML::Parser\n  def on_document(children = [])\n    Loofah::XML::Document.new(:html => @parser.html?, :children => children)\n  end\nend\n``\n. My guess is that this nokogiri api existed for extending document tree members, so loofah was built around it.  It's just a convenience entry-point though, since it's not used for traversal.  However, the single method added ontoNodes (and subclasses),NodeSets, andDocuments ([#scrub!`](https://github.com/flavorjones/loofah/blob/master/lib/loofah/instance_methods.rb#L30-L57)) is part of the public api and I'd be very surprised if Loofah's maintainers would be amenable to making that large a breaking change.  Without support for extending tree members, the best way to move rails from nokogiri to oga might actually be replacing Loofah with a sanitizer that is less tightly coupled to the underlying xml parser.  This would obviously be a significantly larger undertaking.\nI think there's a way oga could support some sort of decoration mechanism without adding more overhead than an instance variable check for users that don't use it.\n``` ruby\n  def on_text(text)\n    node = Text.new(:text => text)\n    if @parser_decorator\n      @parser_decorator.call(node)\n    else\n      node\n    end\n  end\ndef on_element(namespace, name, attributes = {})\n    element = Element.new(\n      :namespace_name => namespace,\n      :name           => name,\n      :attributes     => attributes\n    )\nif @parser_decorator\n  @parser_decorator.call(element)\nelse\n  element\nend\n\nend\n```\nEtc. Any slow extension would happen inside of @parser_decorator and would only impact loofah (which is already absorbing the cost of nokogiri's decorators).\n. I think this makes sense.  Loofah's API is fairly inextricably linked to nokogiri, and even consumers of Loofah have to interact with raw nokogiri objects, so there would be no easy migration path.  My guess is that the path forward would be to take rails-html-sanitizer and Loofah's tests and write a new sanitizer based on oga.  I'd be willing to work towards this goal, but it's a large undertaking.  Is oga fast enough and full-featured enough currently for this to be possible/feasible?\n. ",
    "bryanp": "Yeah, entities in Pakyow have never worked right to date. We're trying to finally get it right :-)\nWe use Oga (and previously Nokogiri) only to parse an HTML document. From it we create an instance of StringDoc, which exposes only \"significant\" nodes as mutable. A StringDoc represents a document as arrays of strings, so the resulting render is essentially flatten.join. This makes rendering really fast.\nThe issue is that when we read the text of an element from Oga, the entities are decoded and we have no way of encoding them when converting a StringDoc back to an HTML string.\nHowever, you're right that encoding 2,120 entities might hurt performance. Decoding doesn't do anything for us in 95% of use-cases. Give that, our best path forward (as far as Pakyow is concerned) might be to not decode and let the developer encode in cases where it's needed.\nSince AFAIK right now the only way to avoid decoding is to monkey-patch a couple methods, would you be open to building in support for disabling decoding? I still think it would be nice to be able to encode HTML entities as well as decode, but even if that was supported we'd likely avoid using it in Pakyow.\nThanks for your response; hope we can find a good solution here!\n. The reason is when the document is rendered in the browser we want the encoded entities (I think). What got me going this direction was the fact that some entities (specifically &copy;, &nbsp;) render incorrectly in the browser with out of the box Oga.\n\nThere's a no break space between the arrow and the text.\n. Huh, okay. Does Oga have its own encoding option? I set Ruby's encoding to UTF8 in this case :-/\n. Here's an example. Start the server with bundle exec pakyow s. This is the important code: https://github.com/bryanp/oga-pakyow/blob/master/app/lib/routes.rb\n\nI've bypassed all the StringDoc complexity to try and get to the heart of the issue.\n. Bleh, so it appears to be a browser issue. Explicitly setting the charset to UTF-8 makes it work.\n. It requires the user to explicitly add a meta tag. What I don't like about it is we're changing their markup, then requiring the user to take another step to work around it. Pakyow could add the tag automatically, but I don't know how I feel about that.\n. I think we'll move forward with Option 2. The user might find it odd that we're changing their markup, but the reason why seems pretty clear-cut and easy to explain. Generated apps will include the meta tag and we'll consider presenting a warning in development if the meta tag is missing. We're targeting less experienced users, so we have to make things really straight-forward.\nThanks for taking the time to discuss this, it was quite helpful!\n. @omninonsense Yep, you're probably right. I'll look into this a bit more. Thanks for pointing it out \ud83d\ude04\n. Awesome, thanks! \u2764\ufe0f \n. Fair enough, I just silenced the warnings since we only use Oga in one place.\n. ",
    "Zapotek": "That's fair enough, thanks for the clarification.\n. ",
    "sferik": "\nThe only solution that I can think of is to not have a Lexer instance reset its internal state after it has finished running. Since Lexer instances aren't re-used at the moment this shouldn't really impact users, though having an instance you can only use once feels a bit dirty.\n\nThis solution sounds good to me. A user could still manually reset a Lexer instance if they want to reuse it, right? Would you accept a pull request that makes this change?\n. @YorickPeterse Looks like tests pass on everything except Rubinius on OS X. I guess that\u2019s a spurious failure unrelated to this change.\n. > However, all Windows builds are failing as well.\n@YorickPeterse It looks like the Windows builds are only failing on Ruby 1.9 for the same reason that the Linux builds were failing on Ruby 1.9: incompatibility with version 2.0.0 or greater of the json gem.\n. @YorickPeterse Okay. All the tests seem to be passing now, even on Windows.\n. @YorickPeterse I\u2019ve moved the changes to .travis.yml into two separate pull requests. The build for this pull request is now failing for Rubinius on macOS but passing everywhere else:\n\n\n. Thank you for helping me put together the patch. I\u2019ve run the multi_xml test suite against oga@master and everything is green. \ud83d\udc9a \n. @YorickPeterse https://travis-ci.org/sferik/multi_xml/builds/144577237\n. Version of the json gem greater than or equal to 2.0.0 are not compatible with Ruby 1.9, causing a build error on the Travis CI. This allows Travis to get past the bundle phase and run the tests successfully on Ruby 1.9.\n. I originally removed this method but that caused test failures locally, so I added it back.\n. @YorickPeterse Removing this causes 6 tests to fail. I just pushed this change so you can see the tests failures on Travis CI.\n. That seems to have fixed it. I\u2019ve pushed these changes and the tests all pass now.\n. Unfortunately, Travis hasn\u2019t defined an rvm alias for 2.3, so specifying the full version is necessary.\n. Since Ruby 1.9.2 is no longer supported, I think it\u2019s better to be explicit about this version number. Specifying a teeny digit is also necessary for https://github.com/YorickPeterse/oga/pull/157, since Travis hasn\u2019t defined an rvm alias for 2.3.\n. I actually moved this change into https://github.com/YorickPeterse/oga/pull/157.\n. ",
    "Junyulive": "Thanks, I'll add this quick hack to my project and test it.\n. Just saw the new branch link.\nBTW: what's the best way to get inner_html (children.to_xml) with generator? Do you think add to_html/inner_html to generator that make sense? \n. Never mind, I just found out the xml branch has the full implementation of the new traversal algorithm, so I can just use node.children.map(&:to_xml).\nI did include the xml branch in my project, will let you know if these are more issues. Thanks for the quick response. \n. I didn't find it in the specification, I guess it added by microsoft when copy some office data to the html editor. \nBrowser and html editor will ignore these invalid tags, because of the html nature, is it possible to make Oga.parse_html more compatible for html.\n. I think it's the nature of html which doesn't have strict tag formation, so html may contains a xml declaration or other weird tags. \nBrowser and Nokogiri just parsed these html successfully, so I think we should have these compatibility when parse html specifically in Oga.\nThe known valid xml declaration doesn't work as well.\n<html>\n<head>\n</head>\n<body>\n  <h1> header </h1>\n  <p> \n    <h3> content </h3>\n    <?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\n  </p>\n</body>\n</html>\n. I found another example in my project. I was parsing various html from the internet.\n<span ;=\"\">content</span>\nWorks in Nokogiri, he just ignore these invalid attributes and let the parse through. Like you said above the way of their error handling make more sense in a parser app. You may provide an addition options allow the parser raise the error, but by default just ignore these invalid tags.\n. ",
    "scotchi": "I'll squash these all at the end, but for now I've handled the comments as separate commits for convenience.\n. I squashed the commits now.  The only things remaining where the attribute aliases, so I reworked the commit message accordingly.\n. Yes, it does seem to resolve the issue in the actual application.\n. Is allowing multiple roots intentional?  Mightn't it be better to either throw an exception on adding a second root element (since that's not allowed by the XML spec)?\n. So, first, I think there are two separate issues:\n- Should this be allowed for nodes?\n- Should this be allowed for nodes and text?\nI'll start by saying that I could argue against both of the above, but after thinking about it a bit, have a slight preference for keeping at least one of them.\nFor appending nodes to a parent, I'll note that all of REXML Nokogiri and libxml-ruby do support appending nodes to parents via the << operator.\nIn practice, I don't think it's ambiguous what the operator does.  Reading code from the other three libs doesn't cause any cognitive friction for me in this particular case.\nThe second question is I feel is harder -- my inclusion of text insertion wasn't so much out of a sense that the << operator was the right solution, but that the current method felt clunky for such a common operation.\nSince I wrote the code out to compare, I thought I'd include that here:\n```\nrequire 'rexml/document'\nputs 'rexml:'\ndoc = REXML::Document.new\nfoo = REXML::Element.new('foo')\nbar = REXML::Element.new('bar')\ndoc << foo\nfoo << bar\nbar.text = 'baz'\nputs doc.to_s\nrequire 'nokogiri'\nputs 'nokogiri:'\ndoc = Nokogiri::XML::Document.new\nfoo = Nokogiri::XML::Element.new('foo', doc)\nbar = Nokogiri::XML::Element.new('bar', doc)\ndoc << foo\nfoo << bar\nbar << 'baz'\nputs doc.to_s\nrequire 'libxml'\nputs 'libxml:'\ndoc = LibXML::XML::Document.new\nfoo = LibXML::XML::Node.new('foo')\nbar = LibXML::XML::Node.new('bar')\ndoc.root = foo\nfoo << bar\nbar << 'baz'\nputs doc.to_s\nrequire 'oga'\nputs 'oga:'\ndoc = Oga::XML::Document.new\nfoo = Oga::XML::Element.new(:name => 'foo')\nbar = Oga::XML::Element.new(:name => 'bar')\ndoc.children << foo\nfoo.children << bar\nbar.inner_text = 'baz'\nputs doc.to_xml\n``\n. Hmm, I hadn't looked into theHTML` module, but had assumed there was a parallel class tree there specialized for HTML-specific behavior.\nTo me it seems inevitable that some modality will be introduced (outside of just the parser) for the differences between XML and HTML.  It'd be simple enough for now to just set a field on the document from the parser, and then have methods like this do different things based on that field.  I get that that's not particularly elegant (but then, we're talking about parsing HTML), but leaving out behavior that everyone who's ever used an XML parser will expect because of HTML's quirks seems broken.\n. In more concrete terms, this means for users of other libraries:\ndoc << element\nHas to be replaced by this:\ndoc.children.last.children << element\nOr, more verbose, but at least readable:\nroot = doc.children.last\nroot.children << element\n. I'll stop pushing on Element#<<.  In that case, I agree that it's subjective, and as I stated at the beginning, I could argue either way on it.\nHowever, I believe not having an accessor for the root element of the document is literally an API bug.  I don't mean simply all of the other 3 major Ruby XML implementations support that, I've literally never seen an XML API in any language that did not.\n- Python: xml.dom.Document.documentElement\n- Java: org.w3c.dom.Document.getDocumentElement\n- PHP: DOMDocument::$documentElement\n- Scala: scala.xml.Document.docElem\nHowever, I'll roll that out to a separate pull request with some approximation of what I think the correct HTML and XML behavior would be.\n. Done.\n. ",
    "marcamillion": "Thanks for the reply @YorickPeterse. \nBefore you replied though, I actually discovered that out. So this solution worked for me:\nbody = Net::HTTP.get(URI.parse(@url)).force_encoding 'UTF-8'\nSimilar to yours, but a bit simpler. \nOut of curiosity, is there anything my version may miss that yours doesn't?\n. ",
    "mortonfox": "Thanks! I'll update my gems.. ",
    "PikachuEXE": "AppVeyor failed due to nokogiri installation issue, not related to spec. @YorickPeterse \nOk I updated the CHANGELOG\nIf you think the format is incorrect just fix after merging it :P. ",
    "leejarvis": "\nI'm thinking something like this could work:\n\nThe issue with a document wide alias list is that it presumes one knows these aliases upfront. This becomes an issue when you want to dynamically look up elements for a given namespace. An example might be when parsing a WSDL with namespace'd types:\nxml\n<x:root xmlns:x=\"http://example.com\">\n  <x:schema xmlns:foo=\"http://example.com/types\">\n    <x:complexType>\n      <x:element name=\"myElement\" type=\"foo:MyType\">\n        <!-- ... -->\n      </x:element>\n    </x:complexType>\n  </x:schema>\n  <x:schema targetNamespace=\"http://example.com/types\">\n    <x:simpleType name=\"MyType\">\n      <!-- ... -->\n    </x:simpleType>\n  </x:schema>\n</x:root>\nHere, element myElement references foo:MyType, which might be different to bar:MyType. We would pull out the correct type dynamically by looking up the referring targetNamespace. \n\nAn alternative would be to pass the aliases to every Proc compiled for an XPath query, then have the Proc do a Hash lookup to figure things out. This however is a bit hairy to implement, and will probably come with a runtime cost.\n\nThis is where I started too. I also presumed there would be some runtime cost. . Actually I just realised my previous example doesn't really make much sense, since it's different from namespace aliases. To retrieve MyType from myElement you would parse foo from type and then fetch the namespace from schema.namespaces which Oga already parses, and then MyType can be fetched by targeting targetNamespace.\nSo I think this is just about namespace aliases in static terms, and your suggestion of a document-wide  alias hash would actually be fine.\n\nThe WSDL/list of aliases is not available before parsing the document\n\nThis is technically correct. A full list of aliases isn't available until you parse the document (programatically or merely browsing it). But I think it doesn't really matter for the XPath parser. The parser only needs to know about aliases that we're already aware of, since those are what we'll use to parse the XML with static XPath queries. . ",
    "badeball": "For reference, the reason why I came across this was to solve the following case. I want to select a StsRsnInf if it directly follows a GrpSts. Normally, I would write such query as follows.\n//GrpSts/following-sibling::*[1][self::StsRsnInf]\nI've currently solved it with the following query.\nxpath\n//GrpSts/following-sibling::*[position() = 1 and local-name() = 'StsRsnInf']\n. I briefly looked at the code back there, but couldn't immediately figure it out. I think I will attempt to take another stab at it. Anyways, there's no hurry here, as I have a workaround.. ",
    "lloeki": "I totally agree with you, yet as you can see I did go all the way to a PR.\nThe issue here is that even though some of those warnings are silly in some cases, they're definitely helpful in keeping things in check many a time. The trouble is that the silly warnings therefore preclude the non-silly ones to be useful :/ Speaking broadly, the additional code e.g for method redefinition can be helpful when you stumble upon the method and \"forget\" to look for a redefinition, and not understand why the behavior differ (sometimes ever so slightly). In your code it's right below so hard to miss but in some other code it could be anywhere. The core problem is that when you enable ruby warnings, they're enabled globally, not just for the non-dependency code. Nonetheless, that's a very useful tool when developers are of varying caliber.. Indeed the only way would be to attempt to massage the generated code as a last step of rake generate. I'm trying to reach out to ragel maintainers to get this fixed upstream.. @YorickPeterse I think so too WRT Ragel.\nHaha I did run rubocop -a too! It completed but wouldn't fix everything anyway :/ BTW although I did not make use of it you can limit cops to be run with --only which makes it faster (but will not make use of cops that could be sort of co-dependent). I even had thoughts about going the brutal way with some perl -pie 's/^\\s+//' thing to strip all indents since it's way off anyway.\nInterestingly enough I just found about jeremyevans/ruby-warning but it's only usable starting with ruby 2.4.\nAnother strategy might be to implement something that wraps around the require of the ragel-generated files with some $VERBOSE save/set/restore, like Rails's Kernel.silence_warnings.. @YorickPeterse I just tested the following and it silenced the indentation mismatch warnings:\nperl -p -i -e 's/^\\s+//' lib/oga/css/lexer.rb\nperl -p -i -e 's/^\\s+//' lib/oga/xpath/lexer.rb\nTherefore those are the remaining ones:\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xpath/lexer.rb:2003: warning: assigned but unused variable - stack\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xpath/lexer.rb:2004: warning: assigned but unused variable - top\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xpath/lexer.rb:2021: warning: assigned but unused variable - testEof\n/Users/lloeki/Workspace/contrib/oga/lib/oga/css/lexer.rb:386: warning: assigned but unused variable - stack\n/Users/lloeki/Workspace/contrib/oga/lib/oga/css/lexer.rb:387: warning: assigned but unused variable - top\n/Users/lloeki/Workspace/contrib/oga/lib/oga/css/lexer.rb:404: warning: assigned but unused variable - testEof\nThey exist only once per lexer file and appear to be completely unused from a cursory look at the code (also noted by @mbj here). Excerpt:\nstack = []\ntop   = 0\ntestEof = false\nI deleted them with:\nfor d in css xpath; do for v in stack top testEof; do perl -n -i -e \"/^\\s*${v}\\s*=/ or print\" lib/oga/$d/lexer.rb; done; done\nAll tests are green and no more warnings when requiring the gem from another project :D\nLast step, I added $VERBOSE = true at the top of spec/spec_helper.rb and there are a couple more warnings that don't show up in my particular use case but may for others:\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xml/element.rb:149: warning: instance variable @namespace not initialized\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xml/node.rb:97: warning: instance variable @root_node not initialized\n/Users/lloeki/Workspace/contrib/oga/lib/oga/xml/node.rb:160: warning: instance variable @html_p not initialized\nAnd some last ones that muddy the output but don't affect the outside world since they're in *_spec files:\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:284: warning: assigned but unused variable - doc\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:306: warning: assigned but unused variable - doc\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:471: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:478: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:485: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:606: warning: assigned but unused variable - doc\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:627: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/element_spec.rb:635: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/generator_spec.rb:76: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/generator_spec.rb:86: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/generator_spec.rb:96: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_set_spec.rb:32: warning: assigned but unused variable - set\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_set_spec.rb:44: warning: assigned but unused variable - set\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_spec.rb:239: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_spec.rb:246: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_spec.rb:254: warning: assigned but unused variable - xml_doc\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_spec.rb:267: warning: assigned but unused variable - document\n/Users/lloeki/Workspace/contrib/oga/spec/oga/xml/node_spec.rb:274: warning: assigned but unused variable - document\nWe're getting close!. That's surprising, I grepped the whole thing, which returned only the assignments to those variables.\nAnyway, another less intrusive way that keeps the assignments around is to reference the local variables with a method call (else you'd get warning of variable use in void context), which I achieved with a harmless #nil? noop right next to the assignment:\nfor d in css xpath; do for v in stack top testEof; do perl -n -i -e \"/^(\\s*${v}\\s*=.*)$/ and \\$_ = \\\"\\$1; ${v}.nil?\\\\n\\\"; print\" lib/oga/$d/lexer.rb; done; done\nI'll fix the spec warnings and do a PR later.. Fantastic, thanks @YorickPeterse !. Should I shorten this line? Maybe use %i?. Good idea, and it indeed works!. ",
    "zumoshi": "I'm porting some jquery based web scraper code to ruby where those functions (or ones such as .prevAll) are used, I believe I can simulate most of the other ones if I have find and filter.\nbut the general idea is a multi-level search inside the page, imagine you have multiple sections on each page, where each of them has multiple tables, and each table has multiple rows.\nperhaps an example can help explain it better. the fiddle is a simple recreation of one of the codes I'm porting. basically, each level adds some meta data, so I can't get all of the rows with one selector because I need to distinguish them based on where they were.. perhaps not for the find method, since yesterday I've been working on a wrapper class that allows me to simulate jquery methods without needing to make any changes to oga itself, I have managed to simulate the original behavior this way:\nruby\n  def find(selector, n)\n    if n.is_a? Oga::XML::NodeSet\n      x = []\n      n.each do |e|\n        x += find(selector, e)\n      end\n      x\n    elsif n.is_a? Oga::XML::Document\n      n.css(selector)\n    elsif n.is_a? Oga::XML::Element\n      n.css(selector)\n    elsif n.is_a? Oga::XML::Text\n      nil\n    else\n      raise 'Invalid argument'\n    end\n  end\n(the original method lacks the n parameter and returns a new instance of the wrapper class to allow for a fluent API)\nbut I still have no idea how to implant filter, in the example (line 5 of js), I have used .prevAll to get the matching h4 for each table. for now, I have implanted it as:\nruby\n  def prev(selector)\n    x = @n.xpath './preceding-sibling::'+selector\n    self.class.new x[0]\n  end\nit works for h4 as a query because it's the same in css and xpath, but for a more complex query, I would like to be able to do something like this:\nruby\ndef prev(selector)\n  x = @n.xpath './preceding-sibling::*'\n  x.filter(selector) # or x.css(selector), it should work with any css3 query\nend\nwhich wouldn't work because x is a NodeSet, also my find method won't work here because it will only match children of nodes in the NodeSet, not the nodes themselves.\n\nside question: would you be interested to accept pull requests for jquery selectors not in css? (e.g. :has). I have implanted a very basic version (still needs some polishing but it works for simple cases). :eq and :contains are next on my list.. ",
    "mistergibson": "I was thinking of passing the output to a client web page where JavaScript would process the JSON\nI suppose I could just convert it to a Hash and then convert to JSON - but I was being lazy.. ",
    "dfockler": "@Arcovion Thanks, didn't realize that existed.\n. "
}