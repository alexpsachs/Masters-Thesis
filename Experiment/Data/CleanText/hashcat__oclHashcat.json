{
    "Xanadrel": "The error seems to happen only with wordlist based attacks, so all but -a 3.\n. Ok for merging.\n. Ok for merging.\n. Ok for merging.\n. Ok for merging.\n. Ok for merging.\n. No, fuck off.\n. This smells good, can be merged.\n. Ok for merging obviously.\n. Ok for merging.\n. Ok for merging.\n. Ok for merging.\n. Works for me with 1.36, 2.01, 2.10b32\nConfig:\nWindows 7\n1x Titan X\nDriver 361.43\n. Ok for merging.\n. Ok for merging.\n. Ok for merging.\n. I will kindly invite you to fuck off.. Seems to be fixed with latest driver as of now (411.63). ",
    "Wohn": "I got the same error :(\n. ok, with -a 3 i got GPU speed 0 H/s but its running 10 digits\n.  oclhashcat 2.0.1 released!!! :)\n. oclhashcat 2.0.1 released!!! :)\n. ",
    "philsmd": "The pull request above fixes the problem.\nThe problem doesn't seem to be specific to any particular nvidia driver. However, it seems to be a very recently introduced code and this problem somehow did remain undetected.\n. Also make sure that you did apply the timeout patch: https://hashcat.net/wiki/doku.php?id=timeout_patch\n. Yes, this is correct. The link is currently not correct (I think this problem was introduced because deps.sh was moved to /tools/ right before the source was released and the link somehow was not updated at all).\nPlease merge\n. Wait, is this a specific hash format ? I.e. is this a request for a generic sha1 ($salt . sha1 ($pass)) implementation or a request for a very specific hash algorithm used for a cms/forum etc?\nIf this is a request for a specific hash algorithm, what are the details about the limitations and input format etc ? min/max password length, min/max salt length, hash format used etc would be interesting for a specific cms/forum algorithm.\n. Are you sure this is related to md5 at all (the title says \"Md5 optimization\")?\nEven if just the title is wrong and it is all about SHA1, how did you test the speed gains? Did you benchmark it? (I know the optimization is by Jens aka atom, yeah this project leader!).\nOne of the main problems could be register pressure etc. Implementing optimizations only make sense if it leads to a general speedup. Not all optimizations work on all platforms (e.g. cpu/gpu). Do you have some benchmarking numbers?\n. Note: there was a request on the old (now obsolete and offlice) trac ticketing system of hashcat.net for exactly this algorithm: \"Would like to see support for PGP/GPG\"\none comment (by ryabkov) was:\n\"Some extra info about PGP WDE - SHA iterated up to 16000 with salt then decrypt with AES/CAST and check 8 byte\nmore details in source - \u200bsymantec - PGP (pgpSDAValidatePassphrase function)\nP.S. PGPZip may be also uses the same\"\nThe original reporter (OP), system32, said \"I know Passware has some support and [so] also jtr (through gpg2john).\"\n(This was just additional info from old trac, not sure if it helps)\n. I think we can close this ticket since both of these types of hashes can already be natively loaded:\nfor -m 1000\n$ cat 1000_3000.hash \nLabAccount:1012:299bd128c1101fd615c5627ce31416b2:d311c413a01dffad3ffd6f57bfe271d7:::\n$ ./hashcat -m 1000 -a 3 1000_3000.hash hashcat2014\nd311c413a01dffad3ffd6f57bfe271d7:hashcat2014\nfor -m 3000\n$ cat 1000_3000.hash \nLabAccount:1012:299bd128c1101fd615c5627ce31416b2:d311c413a01dffad3ffd6f57bfe271d7:::\n$ cat dict.xt\nHASHCAT2014\n$ ./hashcat -m 3000 1000_3000.hash dict.txt\n299bd128c1101fd6:HASHCAT\n15c5627ce31416b2:2014\nfor -m 5500\n$ ./hashcat -m 5500 -a 3 'test::LAB:76365E2D142B5612CD10E1B93D342334E8FD283ECD7B9170:8614B8A84404B1C0333C8875A22BC10690BBF6A7EDCF549D:1122334455667788' Password1\ntest::LAB:76365e2d142b5612cd10e1b93d342334e8fd283ecd7b9170:8614b8a84404b1c0333c8875a22bc10690bbf6a7edcf549d:1122334455667788:Password1\nThere is nothing that needs to be converted or changed, the formats are already detected by hashcat and can be cracked AS-IS.\nIs there anything missing here? Can we close this issue?. I had a further look @ NETLM and tried to understand how this related to the hashes/features requested within this issue (that was imported by me from the old trac).\nI came to the conclusion that the examples and description within the trac issue do not really correspond to the title of this issue, i.e. the description and examples are all about LM and NetNTLM which hashcat already support.\nNETLM instead is something that hashcat currently does not support. There are two versions:\n1. NETLM: LM Challenge/Response (see jtr code: https://github.com/magnumripper/JohnTheRipper/blob/8bcaddef35f703c47367fad612e473061459b156/src/NETLM_fmt_plug.c)\n2. NETLMv2: LMv2 Challenge/Response (see jtr code: https://github.com/magnumripper/JohnTheRipper/blob/8bcaddef35f703c47367fad612e473061459b156/src/NETLMv2_fmt_plug.c)\nSo my conclusion is that NETLM and NETLMv2 are different algorithms which hashcat currently does not support, but since the example and description within this issue is all about LM and NETNTLMv2, I would say we close this issue for now.\nIf somebody wants to requests NETLM and NETLMv2 in the future within a new github issue, she should also provide some examples of NETLM/NETLMv2 and example code (like the one from jtr).\nThanks. I would suggest that we close this issue.\nThere was no answer given by the OP for more than 1 year and 1/2.\n... or is there anybody knows if this is a common hashing scheme?\n. Attachment added on old trac ticketing system by initnull\n. Can anybody please provide some example hashes and detailed information about the scheme used? We need more info to implement this.\n. I would like to suggest that we close this ticket because in my opinion there is no clear benefit of switching the 2 MAC addresses. If anything, we could/should make it more clear in the wiki what the 2 MAC addresses + SSID are.\nWhat do you think?\n. I close this ticket because:\n1. on trac we didn't get a respond (after atom's question -- see comment)\n2. it is working on a system with titan x and the exact same test\nPlease reopen if this is still a problem (and you have more details on how to reproduce etc).\n. you need to quote the hash if you use it on the command line, e.g. '$DCC2$10240#tom#e4e938d12fe5974dc42a90120bd9c90f'\nWe should close this ticket. This is pebcak\n. also please do not report any problems while using --force.\nAnybody has something against closing this ticket? (IMO this is of course not a oclHashcat problem, but a shell escape miss-understanding, because $DCC2 and $1 are interpreted as variables by your shell interpreter)\n. I changed the text within the FAQ section to:\n\"-a 1 \u2013 number of words of the larger word list out of the 2 word lists specified (left_wordlist, right_wordlist)\"\nI will close this issue, because now it should be very clear.\n. we need much more information here. like max/min salt length (if exists), max/min password length (if exists) etc\n. Note: the -d limit (was previously limited to the range 0-8) was removed with the newest git/beta version (2.10).\nMaybe we can kindly ask for instance @epixoip or anybody who can setup a system with at least 9 GPUs to test if this is still a problem? (I don't have a setup like this :( )\n\nIt could also have something to do with (lack of enough) main memory (RAM)... but this should be pretty easy to see (and idealy it should even result in an error).\n. Thank you very much for the notice.\nI'm sorry that I'm not able to say/pinpoint which changes/commits fixed this problem... There were too many changes we made from the opening of the original trac ticket till today.\nBut it shouldn't really matter (and if someone really needs to - and is able to - find the commit that fixed it, one could just checkout the different commits and see which \"versions\" are still affected and which aren't). The only thing that matters is that it is fixed and there is no more such (known) strange bug.\nThank you again for reporting the current state of this problem, this allows us to close this ticket (because it really wasn't that easy to test for me etc, with that many GPUs ;) )\n:)\n. We should close this, please reopen a new ticket if you think there is another problem.\n(BTW: I can't reproduce the 0 H/s problem, please make sure you have a clean directory - new download, no cached kernels and that your command line is okay, test just -m 2100 -b for instance. If this is still a problem, please open a new issue, because this seems to be unrelated here)\n. this looks good. Can be merged :)\nNote: it's just a different notation. compilers will optimize the memset () anyway. so this is just a nice code re-write (no changes in logic or performance).\n. this PR seems good. Can be merged.\nThanks\nbtw: @yhfudev please stick to the formatting rules (line breaks, indentation etc). It would be also great if you write just a little bit more what your (future) commits do and in this case for instance if it contains really every switch case that OpenCL defines (and where we can find the complete list - that e.g. you used as a reference - to double-check etc). This PR is great, but some more description and explanation about how complete it is would also be a PLUS. Thx again\n. wow, this is really a great find.\nThx matrix\nBut we need to fix it a little bit differently. The facts:\n-  given the example hash 7b5n74kq8r441blc2c5qbbat19baj79r:.lvdsiqfj.net:33164473:1 (from hashcat.net/wiki), we know that the digest/hash is 32 base32 chars\n- within the nsec3_parse_hash () function we convert (base32 decode) the human readable hash like this: base32_decode (itoa32_to_int, (const u8 ) hashbuf_pos, 32, tmp_buf);  (see https://github.com/hashcat/oclHashcat/blob/master/src/shared.c#L13950 )\n- the result are 20 bytes because 32 / 8 * 5 = 20 (we can see that the 20 bytes are copied here: https://github.com/hashcat/oclHashcat/blob/master/src/shared.c#L13952)\n- this means, that our encode (the opposite of the decode in the parsing function) must convert 20 bytes to 32 human readable base32 chars\n- that means, the only problem within this line (the encoding within the ascii_digest () function): base32_encode (int_to_itoa32, (const u8 ) digest_buf, 32, (u8 *) digest_buf_c); (see https://github.com/hashcat/oclHashcat/blob/master/src/shared.c#L7116) is the number 32\n- we need to fix the value 32 to 20 (as input to the base32_encode () function ! (and not increase any buffer so it should stay char digest_buf_c[33]; because we want 32 + 1 additional byte for the NULL-byte\nIn other words, the fix should be as simple as this:\n-    base32_encode (int_to_itoa32, (const u8 *) digest_buf, 32, (u8 *) digest_buf_c);\n     +    base32_encode (int_to_itoa32, (const u8 *) digest_buf, 20, (u8 *) digest_buf_c);\n(within the hash_mode == 8300 section of the ascii_digest () function)\n@gm4tr1x could you please submit this change to this PR (just commit it to the same branch)\nThx (and again nice find ;) )\n. oh the extra 1 byte is for the padding character \"=\".\nThis is now okay to merge. thx\n. md5crypt uses the md5crypt_encode () and md5crypt_decode () functions\n. would it be okay if we just append the compile time to the version number information ?\nThere is a variable COMPTIME used within the Makefile for such purposes.\nWhy not git commit hash? Because somtimes (well, not that often, but rarely) it happens that betas will be compiled just for testing (even before every piece of new/changed code was committed) and therefore we do not know any git commit SHA1 hash at that time.\nOn the other hand, adding COMPTIME to the version number should be fine (in my opinion).\nWhat do you think ? @roycewilliams would that be okay?\n. @roo7break could you please provide the results of the --gpu-temp-disable test ? Does the crash also happen when ssh is not involved ? We need more information for this issue\n. We need an example of output to test what the problem really is.\n@anlx-sl can you please provide some lines of the file that showed you the error message ? (It's okay if you anonymize/mask it, as long as it is still of the same format and results in the same error).\nWithout any concret example it is difficult to guess what could be possibly going on here.\nThx\n. @anlx-sl we still need at least one sample to reproduce this problem. Unless we have a reproducible issue, we can't troubleshoot/fix this problem.\nCould you (@anlx-sl) please provide such an example \"hash\" file?\nThx\n. the output is utf-16 encoded. That means that for this particular file we have NULL-bytes every second byte and therefore several \"string functions\" don't work correctly (strlen etc) when we open/read it like we currently do (with utf-8 support).\nTo fix this problem, we need to add utf-16 file reading (and encoding detection) support... I'm not sure if this is really that important and common such that it is worth to add it.\nThe files also can easily be converted beforehand:\niconv -f utf-16 -t utf-8 FILE\nutf-16 encoded files start with the Byte Order Mark (BOM, 0xfffe) and the 4th byte is a NULL byte (if > 1 byte is needed), after that every second byte is a NULL-byte (if > 1 byte is needed to encode the character).\n. Can be merged!\n(BTW: it would be great if you @gm4tr1x update #63 (I guess we shouldn't close it yet) and mention the progress, what is currently not working yet e.g. --benchmark, for which algorithm the tests currently fail and also most importantly why you had to change some parts in this particular manner, e.g. why there is no --cpu-affinity etc. I mean, this are very critical changes and imply that we can't tell the users @ forum/irc that they can \"just use --cpu-affinity\" to just mention an example. We need some clues/documentation why it was changed like this and what is still missing).\nThx\n. @thesle3p could you please close the issue if you think this is not an issue anymore (because you fixed it with a clean install/download of deps)?\n. seems good, can be merged\n. can be merged, thx\n(Btw: some of these fixes only work because the mymalloc () function already calls memset () , these changes are just cosmetic, they shouldn't change any logic, performance etc... the compiler will always optimize these things, especially with the -O2 compiler option... so there should be no noticeable changes besides the optical ones for devs/contributors)\n. @gm4tr1x while you are trying to change this mymalloc () calls, let me suggest this fix too: here https://github.com/hashcat/oclHashcat/blob/master/src/oclHashcat.c#L10957 (user = (user_t ) malloc (sizeof (user_t));)  we have a call to just \"malloc ()\", we should probably call mymalloc here too... Can you fix that with a new pull request?\n. I don't understand what this --gpu-temp-disable change is trying to accomplish. The commit messages says something about OSX (\"Re-enable gpu-temp-disable argument for osx build\") but I don't see any OSX related changes (with #ifdef OSX or #ifndef OSX).\nWhen HAVE_HWMON is true, --gpu-temp-disable probably should be available, otherwise it should not be in the --help and not be available in general. I can't understand what this has to do with OSX.\nMaybe the problem is just that I only see \"No description provided.\" here and can't really figure out why it was changed the way it was... but without having more details and documentation of the reasons and goals of this change I can't understand and sign it.\n. this doesn't seem like a good solution for me, i.e. enabling the option just that the test.sh script runs without error and otherwise it shouldn't be used or if it is used it will be ignored.\nIt would make much more sense to either check within tools/test.sh if the option is available and only use it when it is available or, we need to discuss this, disable the option in test.sh completely.\nChanging it this way which is completely unlogical and which would suggest that --gpu-temp-disable would also be available for the OSX users and users that have HAVE_HWMON set to 0.\nIn general, it is much more important that the oclHashcat --help output and the options that the user can use are correct, than the tools/test.sh options (which only some devs will run).  Of course, both should be working and hence I suggest that we add --gpu-temp-disable in test.sh if and only if the binary allows that.\n. All I'm trying to say is that this makes no sense:\n```\n\"       --gpu-temp-disable            Disable temperature and fanspeed readings and triggers\",\nifdef HAVE_HWMON\n...\n```\nit should stay as it was:\n```\nifdef HAVE_HWMON\n\"       --gpu-temp-disable            Disable temperature and fanspeed readings and triggers\",\n...\n```\nwhy should --gpu-temp-disable be available when hardware monitoring was disabled?\nIf hardware monitoring was disabled, also --gpu-temp-disable should not be available (like it was before this strange changes).\n. > From that view it might make sense to add it back.\nNo. No. No.\nIt makes absolutely no sense to break the oclHashcat binary just that 2-3 devs can run tools/test.sh (which of course not every oclHashcat user uses 24/7) on OSX/without HWMON too. I don't support this idea to be that lazy and to not fix test.sh (instead) to use --gpu-temp-disable only when it is available... but instead break the binary with some very confusing changes that make no sense at all.\n. I still don't understand why @gm4tr1x  says HAVE_HWMON is directly related to OSX builds. The fact ist that users/maintainers can set HAVE_HWMON to 0 also on non-OSX builds. Therefore this is not a valid fix\nelif [ ${OPTARG} == \"osx\" ]; then\n+        OPTS=$(echo $OPTS | sed -e 's/--gpu-temp-disable //g')\nThe correct fix would check for the --gpu-temp-disable switch in the --help output for each platform (linux/windows/osx), as suggest previously here https://github.com/hashcat/oclHashcat/pull/156#issuecomment-174543275\n. this commit is evil !\nLabeling a commit as \"cosmetic fix\", providing no description (\"No desciption provided.\" is the message of this pull request), but changing the restore file format in a very significant way such that it breaks --restore support of .restore files without updating the file format (https://hashcat.net/wiki/doku.php?id=oclHashcat#parsing_the_restore-file ) and warning the user about the changes in docs/changes.txt ... is something we should not tolerate at all.\nMaybe it was \"just a mistake\", but as I said it broke a lot of things (analyze_hc_restore, some 3rd-party wrappers, the wiki documentation, ... etc.).\nI also had to troubleshoot/debug this a little bit until I figured out that the restore format was changed without any notice.\nCan you (@gm4tr1x) please explain how this could happen at all, what were the reasons for this significant change, why we really need it and most of all why you did change the restore file format without giving any meaningful explanation (or no explanation at all)?\nP.S. the change I am speaking about is  \"char cwd[256]\" -> \"char cwd[1024]\" of struct restore_data_t in types.h\nThx\n. It doesn't look like it works for me:\nstrace ./oclHashcat --keyspace -a 3 ?a?a?a?a?a?a?a?a 2>&1 | egrep 'libamd|libOpenCL'\nAs far as I understood, there should be no requirement for loading those (and maybe other) libs when running with --keypace option. Your fix doesn't change this.\n. If I try without the libraries I get this error:\n./oclHashcat --keyspace -a 3 ?a?a?a?a?a?a?a?a\n./oclHashcat: error while loading shared libraries: libOpenCL.so.1: cannot open shared object file: No such file or directory\nThis is what the issue #84 is trying to fix (in my opinion), i.e. using --keyspace also when the libraries are not present\n. the tool for calculating the --keyspace already exist in hashcat-utils: https://github.com/hashcat/hashcat-utils/blob/master/src/keyspace.c\nBut again the goal that issue #84 should solve is to allow the user to run --keyspace without loading those libraries that are not needed to show the --keyspace value.\n. Of course! In my opinion the user specified parameter should not silently be ignored when incorrect/not allowed/available. Otherwise, this could lead to very strange problems/missunderstandings etc. \n. > it's difficult to extract password lists from hash:salt:pass lists when salt is not constant\n@d2-d2 did you try to use this? :\noclHashcat -m [HASHTYPE] --show --outfile-format 2 [HASHLIST]\n(note: the .pot file must exist of course)\n. it works also directly, i.e. without using --show, e.g:\noclHashcat -m [HASHTYPE] -a [ATTACKTYPE] -o [OUTFILE] --outfile-format 2 [HASHLIST] [DICT/MASK/MASKFILE]\nI think the multi-byte delimiter could still be a good idea in some very special cases (i.e. if the hash list already has some weird delimiters and the user doesn't want or isn't able to batch modify each line within the file)...\n. Thank you very much for reporting this issue and especially in this very clear and understandable format (even with \"working\" examples).\nPull request #259 should fix this problem, by increasing the max. salt length to 28 (55 - 22 - 1 - 4 as explained in #259).\nThis should be enough to fit even the longest usernames.\nThanks again\n\nBTW: just to be very clear about the limits: we have 2 limits here\n- salt + 22 + pass must be less than 55\n- salt itself must now be less than 29 (up to 28 - included - is supported)\n. so long story short, we should pull this fix because it could happen that in very, very, very rare cases it could happen that:\nnon-unique \"salts\" were falsely considered as unique and therefore only 1 of those hashes were successfully loaded and cracked\nCan you please provide an (anonymized) sample (at least 2 *.hccap files?) such that we can verify this issue and keep those files as a kind of documentation here (to justify this change)?\nThank you very much\n\nNow that I'm thinking about it, also the opposite could be true... i.e. that unique salts were not recognized as unique (but they were considered as 2 distinct \"salts\"), even if they should be marked as unique... Still some examples would be good (for maybe both of these cases).\n. hmm, the pull request was already merged ... but what I asked you (@gpuhash) here https://github.com/hashcat/oclHashcat/pull/237#issuecomment-188227146 is still valid. Can you please provide some more information + samples such that we have some docs ?\nThx\n. I think I understood the problem you are describing above, but in your case if you want to just get the information on when exactly the mask changed etc it should be enough to just read/parse the oclHashcat.log file (or monitor it the same way you monitor the --status output).\nI'm not sure if it makes sense to print the mask/dictionary each and every time when the status timer (--status-timer) triggers and showing the change only when there was a change makes the format of the --status output much less easier to parse.\nOn the other hand, we probably shouldn't make too many changes in the output of --status-automat because some 3rd-party wrappers already use it heavily and changing it may break their parser. (of course when we really thing we need to change the format, we definitely should do so AND document it appropriately).\nI think the .log file is exactly what you are looking for, it tells you when exactly there was a change in mask/dict etc. The format of the .log file is also more appropriate for this kind of information, the status-automat is more or less just about the current speed/number of cracks etc.\nDo you think this (.log file reading/parsing/monitoring) works for you?\nThx\n. @AntonKuzminRussia Can you please close this issue if the solution with the (already available) .log file feature is working for you?\nThx \n. For your interest, I posted some POC perl code here: https://hashcat.net/forum/thread-6405-post-34457.html#pid34457 .\nIt would help a lot if some users can test my POC (because there was some other user claiming with proof-of-concept code on that forum thread that AES steps are needed etc).. We for sure need some more information here:\n1. does the example hash crack for you (https://hashcat.net/wiki/doku.php?id=example_hashes)\n2. there is no such commit \"55e339\", but there is this one (very similar but not the same SHA1 beginning):  https://github.com/hashcat/oclHashcat/commit/555e339\n3. if you mean the commit 555e339 I think it is very, very unlikely that it is the reason for this problem since it only touches kernels from -m 1100\n4. we need a full example on how to reproduce this: .hccap file, input wordlist/mask/mask file, the correct password, the full command that you've used, info about your setup (escpecially GPUs, nvidia / AMD...) and other relevant information\n5. please make sure that you have a clean build (no cached kernel files or obj etc), for instance under linux you might also need to remove ~/.nv/ etc\nBTW: I can't reproduce, the example hash works here\n. so you are saying that \"make DEBUG=2\" is working, but just \"make\" isn't. That's weird.\nCan you please test this again?\n. make DEBUG=2 should be \"equivalent\" to the Makefile that was used before 6636cc1 (with the additional debugging flags -g -ggdb).\nWell, you should be able to see the difference of the full gcc command on the command line. Maybe you can play a little bit with it and see which flag is responsible for failing to crack all hashes.\nWhat I mean is, when you run \"make\" you should see a/more \"gcc ....\" command(s). There should be a slight difference between what was set < 6636cc1 and the \"make\" of the master branch. Now, we need to find out, what (flag) is responsible for this problem.\nCan you test this?\n. First of all, this seems to be a different problem if you say that what you are experiencing now has nothing to do with commit 6636cc1 .\nSecondly, I don't think the way you are testing these problems is very clever, since you always mention this external pacman tool.\nWhat about the native build (without involving any external package manager etc) but instead just running \"make clean\", rm -rf ~/.nv/, \"make\" and \"./oclHashcat -m 2500...\" ?\n. Well, this is just a simple way to remove the binary file (actually /binary_file[.bin]) from the exec_path (which conists of path/binary_file[.bin]) such that the result is just the \"path\".\nYou can always debug this if you are not convinced before this line: https://github.com/hashcat/oclHashcat/blob/master/src/oclHashcat.c#L5633, e.g. something like\nprintf (\"%s vs %s\\n\", install_dir, resolved_install_folder);\n. Note: since the format is \"{SSHA}\" . base64 ($hash . $salt) we cannot make the assumption that base64_decode ($hash . $salt) == 20.\nWe only can make the check that it must be at least of length 20, but since there could be non-zero length salt, we can't test if != 20.\nBtw: With the above patch, I introduced both checks PARSER_HASH_LENGTH and PARSER_SALT_LENGTH even if one would be for sure enough. Why the first one is enough ? The answer is, whenever the decoded length is at least 20, the salt is either 0 or longer (which is perfectly fine!). But to make it more clear that both conditions should be satisfied, I added both checks to be safe and easier/clearer to understand (the compiler, especially with -O2 flag, will notice this \"dependency\" of these two checks and do its best to make only one check and therefore optimize it for us). \n. Hmm, maybe we shouldn't just ignore it. But instead print a warning about what happened!\nLet me know if this makes sense and you think that would be much better.\n. https://github.com/philsmd/oclHashcat/commit/169905751649b48cc5c47e4b6d2f81ac15567f0f adds the suggested warning messages. Check the entire changes here https://github.com/hashcat/oclHashcat/pull/270/files \n. this is a temporary unavoidable and well-known problem because of the refactoring/changes to new code for all kernels, see all the \"Cleanup -m xxx -a y kernel to latest standard\"  commits here: https://github.com/hashcat/oclHashcat/commits/master\nSoon the -m 4900 kernel will be changed too and working again.\nThanks anyway for noticing\n. Are you sure that you are reporting this problem to the correct project?\nThis is the OpenCL version (https://github.com/hashcat/oclHashcat).\nAll the errors mentioned in your output seem to be related to cpu hashcat (https://github.com/hashcat/hashcat).\nJust to make it very clear, you cannot build cpu hashcat with the instructions mentioned within the BUILD.md file of oclHashcat. These are 2 very different projects.\nFortunately, in the future we might not have to tell users that hashcat != oclHashcat, because the main goal for the near future is to have only 1 hashcat binary (1 for each supported platform), that supports all OpenCL compatible CPUs and GPUs.\nI would say, that this problem is completely unrelated to oclHashcat. Do you agree?\n. I'm not yet convinced if we should really add it like this \"CYGWIN_NT-10.0\".\nWhat about other windows versions where the uname changes (slightly), CYGWIN_NT-5.0, CYGWIN_NT-5.1, CYGWIN_NT-5.2, CYGWIN_NT-6.0, CYGWIN_NT-6.1, CYGWIN_NT-6.2, CYGWIN_NT-6.3, CYGWIN_NT-6.4, ... and all the WOW/WOW64 variants ?\nI think it should be at least as flexible as CYGWIN_NT-6* and CYGWIN_NT-10* such that it accepts all windows versions from vista/windows7 up to windows 10.\nThere shouldn't be any reason to exclude windows 7, 8, 8.1... because if it compiles correctly on windows 10, it also should compile without errors on those older windows operating system versions.\nDo you agree?\n. I guess something like this would work (i.e. just remove the windows version number from the UNAME variable):\n```\nUNAME := $(shell uname -s)\nUNAME := $(patsubst CYGWIN_NT-%,CYGWIN_NT-,$(UNAME))\nifeq (,$(filter $(UNAME),Linux Darwin CYGWIN_NT-))\n...\n```\n. oclHashcat-plus was replaced by (a new optimized version of) just \"oclHashcat\" a very long time ago (years!).\nThe newest release version of oclHashcat/cudaHashcat can always be downloaded from https://hashcat.net/oclhashcat/\nBtw, now even \"oclHashcat\" (and \"cudaHashcat\") will no longer exist and be replaced by just \"hashcat 3.0\" (or newer versions, depending on when you read this ;) ). So, it would make sense to just download the newest beta version from https://hashcat.net/beta/\nPlease don't forget to close this issue\nthx\n. also see our FAQ section for this (and yes it is indeed a frequently asked question, very easy to find thousands times within the forum/web): https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_is_a_keyspace\n(hashcat's definition of keyspace is not the same as \"number of all password candidate combinations\" as you might think)\n. Again, this is exactly as it is supposed to work.\nKeep in mind, --keyspace is a feature that allows one to obtain the correct numbers for distributed cracking, i.e. the maximum threshold for the --skip (-s) and --limit (-l) values.\n--keyspace, on the other hand, was never meant to be a \"calculate-the-total-number-of-password-candidates-for-me\" tool.\nIt is a special feature to be used before you set the -s and -l values.\nIf it would just calculate the total number of password candidates (without any particularities), it would be kind of useless, because everyone of us knows how to do the math (e.g. line_number * rule_number).\nSo the only thing you need to understand (and it was mentioned dozens of times on forum/irc/wiki/faq), is that hashcat's keyspace feature is NOT a general keyspace calculator (\"total number of password candidates\").\nYou can also see these difference by looking at the status output: basically the \"Restore.Point:\" line shows you how far we are in \"hashcat's keyspace\", while the \"Progress:\" line shows you how many password candidates of the total number of password candidates were already tried.\nThere are many reasons to make this distinction (and why the hashcat's keyspace value is not what you would expect), the most important one being that we can't really reach/set a restore point at every single password candidate try, GPUs try a huge amount of password candidates at once, billions of password candidates per second. Hashcat's keyspace can't be partitioned at an even finer grade than that value. So that is why the hashcat's --keyspace feature was introduced to make it clear how many \"restore points\" there are (think of it as an outer loop iteration count) and how a large cracking job can be distribution with -s/-l depending on the --keyspace value.\nI would say, that everything is exactly as intended. There could be 2 things we could think about here:\n1. let --keyspace run without setting --session (circumventing this particular safety-check)\n2. think/discuss (again) why people don't seem to understand/can deal with this \"keyspace\" definition and maybe think of a different name for this flag.\n(and yes, hashcat-legacy has a different way (i.e. it is finer-grained) to create \"restore points\" and yes, in some cases this matches with the \"total number of password candidates\")\n. As far as I understood this problem was solved by correctly installing the drivers/opencl-header dependency, right?\nIf this problem is fixed, please close this issue. Thank you very much\n. You need to clone the repo and compile it. As simple as that.\nAfter that you get a \"hashcat.app\" binary file that you can execute.\nThe reason why there is no .app file within the hashcat 3.00 release 7z is that there is no cross-compiler for linux to compile with -framework opencl (and the main devs don't really use OSX/Darwin system and aren't yet fully aware how to best  (let someone else) compile a release binary that works with most if not all the different OSX versions).\nI think it is easy enough to just clone and run make (consider reading the build instruction of course), please close this ticket if that worked for you.\nThank you very much \nUpdate: iirc there were a couple of people speaking of OSX-specific \"packages\" that can very easily be downloaded via brew etc (don't quote me on that because I'm not a OSX expert at all)... but again, we prefer users to use the tagged release versions directly from github and just compile it locally (or if you think nothing could be greater/better than the latest version, also the latest master from github, but of course that is a little bit \"dangerous\" because it might not always work correctly since it is a preview/development version with the latest changes)\n. 1. I think you should just use a modern text editor. Almost any text editor can format the output correctly (besides very old \"notepad\" etc). We also save some unneeded bytes etc.\n2. what version of windows is this ? Very old versions, like windows xp, might not work. I don't know. I think we also shouldn't support windows xp anymore, because no driver vendor, nor Microsoft itself officially support them anylonger.\n. Without a complete example hashes it's difficult to say what the problem could be.\nIt's always recommended to look at the example hashes page and compare with the hashes of the same hash type: https://hashcat.net/wiki/example_hashes\nDo you see any major difference?\nAre you sure that there are no leading/trailing spaces ?\n. Thanks for the offer to share your hash file such that we can investigate and maybe exclude/confirm any bugs/problems in hashcat.\nPlease use the contact info (mail) within the docs/changes.txt file for this: https://raw.githubusercontent.com/hashcat/hashcat/master/docs/contact.txt\n. Thank you very much for the instruction. Indeed, I didn't previously test (after you mentioned it on a forum post) to crack 2 different .hccap file and test to crack a third time one of the hashes.\nSeems to be fixed now.\nThanks again\n(and as always, please test to confirm, thx)\nSee https://github.com/hashcat/hashcat/pull/426\n(as of now, we still need to wait for a merge into master, will happen very soon!)\n. Great. Thanks for testing.\nDon't forget to close this issue! thx\n. I think the correct path could be programmatically found (w/ the Makefile) like this:\nlinux - 32 bit cross-compilation:\n$ i686-w64-mingw32-ld --verbose | grep -m 1 SEARCH_DIR | sed 's/.*\"\\([^\"]*\\)\".*/\\1/'                                                                         \n/usr/i686-w64-mingw32/lib\nlinux - 64 bit cross-compilation:\n$ x86_64-w64-mingw32-ld --verbose | grep -m 1 SEARCH_DIR | sed 's/.*\"\\([^\"]*\\)\".*/\\1/'\n/usr/x86_64-w64-mingw32/lib\nIt should work the same way under mingw too, we need just someone to test this. @neheb, can you try this ? The \"ld --verbose ...\" command should output the correct lib path even under mingw @ windows\nbtw: the grep ... | sed ... could also be replaced by:\ngrep -Po -m 1 'SEARCH_DIR\\(\"\\K.*?(?=\")'\nbut I'm not sure if mingw (and all other supported operating systems used to build from source) supports this\n. Are you sure that you are trying with the correct \"mingw32-ld\" command (i686-w64-mingw32-ld or x86_64-w64-mingw32-ld) ?\nUsing a different ld version (e.g. not the mingw32 provided one), also gives me different results. But this is ofc to be expected. We are trying to get the correct path from mingw32-ld after all.\n. maybe something more flexible would be this:\nx86_64-w64-mingw32-ld --verbose | grep 'SEARCH_DIR(.*mingw' | head -n 1 | sed \n's/SEARCH_DIR(\"=\\?//' | sed 's/\".*//'\ncan you try ?\n. Thanks, that should be the correct path we are looking for.\nThis also should be identical to the more compact version:\nx86_64-w64-mingw32-ld --verbose | grep -m 1 'SEARCH_DIR(.*mingw' | sed 's/SEARCH_DIR(\"=\\?\\([^\"]*\\)\".*/\\1/'\nThe most important thing now is: is this also working under cygwin (windows operating system) ?\nMaybe someone is able to test this\n. wait... shouldn't the output (the path) be:\n/usr/x86_64-w64-mingw32/sys-root/mingw/lib\nunder cygwin?\nSo not even the mingw32-ld --verbose output contains the correct path ?\n. okay. Thanks for testing.\nNext, I would suggest that (because the above ld mechanism didn't work) we need to apply a change similar to this one:\n```\ndiff --git a/src/Makefile b/src/Makefile\nindex 4e4da2d..3ded550 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -63,6 +63,7 @@ FIND                     := find\n INSTALL                  := install\n RM                       := rm\n SED                      := sed\n+EGREP                    := egrep\n ifeq ($(UNAME),Darwin)\n SED                      := gsed\n endif\n@@ -178,8 +179,30 @@ LINUX_32_OBJS            := obj/ext_OpenCL.LINUX.32.o obj/shared.LINUX.32.o obj/\n LINUX_64_OBJS            := obj/ext_OpenCL.LINUX.64.o obj/shared.LINUX.64.o obj/rp_kernel_on_cpu.LINUX.64.o obj/ext_ADL.LINUX.64.o obj/ext_nvml.LINUX.64.o obj/ext_nvapi.LINUX.64.o obj/ext_xnvctrl.LINUX.64.o\n## may need to adjust according to your mingw distribution\n-CRT_GLOB_32              := /usr/i686-w64-mingw32/lib/CRT_glob.o\n-CRT_GLOB_64              := /usr/x86_64-w64-mingw32/lib/CRT_glob.o\n+CRT_GLOB_LIB_PATH_32     := /usr/i686-w64-mingw32/lib/\n+CRT_GLOB_LIB_PATH_64     := /usr/x86_64-w64-mingw32/lib/\n+\n+CRT_GLOB_LIB_SYSROOT_32  := $(shell $(CC_WIN_32) --verbose 2>&1 | $(EGREP) -o '(with-sysroot=\"[^\"]\"|with-sysroot=[^ ])' | $(SED) 's/^with-sysroot=\"\\?([^\"])\"\\?$$/\\1/')\n+CRT_GLOB_LIB_SYSROOT_64  := $(shell $(CC_WIN_64) --verbose 2>&1 | $(EGREP) -o '(with-sysroot=\"[^\"]\"|with-sysroot=[^ ])' | $(SED) 's/^with-sysroot=\"\\?([^\"])\"\\?$$/\\1/')\n+\n+ifneq (,$(CRT_GLOB_LIB_SYSROOT_32))\n+CRT_GLOB_LIB_PATH_32     := $(CRT_GLOB_LIB_SYSROOT_32)\n+endif\n+\n+ifneq (,$(CRT_GLOB_LIB_SYSROOT_64))\n+CRT_GLOB_LIB_PATH_64     := $(CRT_GLOB_LIB_SYSROOT_64)\n+endif\n+\n+CRT_GLOB_32 := $(shell $(FIND) \"$(CRT_GLOB_LIB_PATH_32)\" -name CRT_glob.o)\n+CRT_GLOB_64 := $(shell $(FIND) \"$(CRT_GLOB_LIB_PATH_64)\" -name CRT_glob.o)\n+\n+ifeq (,$(CRT_GLOB_32))\n+$(error \"! The MinGW CRT GLOB library for 32-bit compilation was not found on your system. Please make sure that CRT_glob.o exists\")\n+endif\n+\n+ifeq (,$(CRT_GLOB_64))\n+$(error \"! The MinGW CRT GLOB library for 64-bit compilation was not found on your system. Please make sure that CRT_glob.o exists\")\n+endif\nWIN_32_OBJS              := obj/ext_OpenCL.WIN.32.o   obj/shared.WIN.32.o   obj/rp_kernel_on_cpu.WIN.32.o   obj/ext_ADL.WIN.32.o   obj/ext_nvml.WIN.32.o   obj/ext_nvapi.WIN.32.o   obj/ext_xnvctrl.WIN.32.o   $(CRT_GLOB_32)\n WIN_64_OBJS              := obj/ext_OpenCL.WIN.64.o   obj/shared.WIN.64.o   obj/rp_kernel_on_cpu.WIN.64.o   obj/ext_ADL.WIN.64.o   obj/ext_nvml.WIN.64.o   obj/ext_nvapi.WIN.64.o   obj/ext_xnvctrl.WIN.64.o   $(CRT_GLOB_64)\n```\n(the diff is attached to this post, you should be able to just run \"git apply crt_glob_Makefile_diff.txt\")\nThis makes sure, that if gcc was configured with a sys-root folder, that we respect this path and search for CRT_glob.o within this folder.\nCould I kindly ask you (again, I know!) that you test this with both (all?) your systems (fedora and cygwin would of course be most important, but we should make sure that it continues to work with \"different\" systems that do not use sys-root via --with-sysroot).\nThanks\ncrt_glob_Makefile_diff.txt\n. I did some further changes (shouldn't be significant to this testing but maybe important to stop \"error messages\" where not necessarily needed etc).\nPlease try with version 2 of the changes (attached):\ncrt_glob_Makefile_diff_v2.txt\nUpdate:\nBTW: an alternative to the list of \"IS_WIN_BUILD := 1\" sections would be something like this:\n```\nMG := $(MAKECMDGOALS)\nIS_WIN_BUILD := $(filter binaries,$(MG))$(filter win32,$(MG))$(filter win64,$(MG))$(filter hashcat32.exe,$(MG))$(filter hashcat64.exe,$(MG))\nifneq (,$(IS_WIN_BUILD))\n...\nendif\n```\nbut this is just a matter of how we decide to write that specific make target list filter\n. No, it's not ?a and it is listed within the wiki:\nhttps://hashcat.net/wiki/oclHashcat#default_values\n1. --custom-charset1    ?l?d?u\n2. --custom-charset2    ?l?d\n3. --custom-charset3    ?l?d*!$@_ \nand default mask: ?1?2?2?2?2?2?2?3?3?3?3?d?d?d?d\nThis is more like a question that belongs to the forum and not here as a (code) problem/issue (and even when you use the forum for such questions, it's recommended that you first search the wiki/--help/faq and use the forum's search function instead of just asking questions that were already answered).\nPlease don't forget to close this issue. thx\n. The main reasons why it is not just only ?a is that:\n1. using ?a is most of the times not the best choice and not very clever, passwords are still mostly user-defined (and not generated by passwords managers etc), mask attack is (see definition) a special position-for-position mechanism, using ?a?a?a?a?a?a?a?a?a?a (or even ?b?b?b?b?b?b...) is as we always say \"the last thing you should try\" (and indeed not very clever)\n2. the default mask in hashcat uses a \"pattern\" that should crack many/most of the user-defined passwords without taking too long. Note: there are of course also some other hash types supported by hashcat, not just md5/sha1/ntml etc... It is kind of a compromise for woking well and still not taking way too long \n3. the default mask also shows how to use mask attack in a more clever way. just \"brute-forcing\" shouldn't be the idea behind the example/default mask... it should show what is possible and what is reasonable/clever by using also the custom charset at different positions\n... (there are of course a huge set of additional reasons and probably there might also be some reasons against it)\nOne of the possible reasons against using this particular mask/custom charset (-1 ?l?d?u -2 ?l?d -3 ?l?d*!$@_ ?1?2?2?2?2?2?2?3?3?3?3?d?d?d?d), would be indeed that some new users might not immediately understand why some hashes \"were not cracked even if they should\" (but of course some hashes should not, since we use a reduced keyspace) and as you already noticed that the mask \"?1?2?2?2?2?2?2?3?3?3?3?d?d?d?d\" in the status display (without the wiki section) doesn't really tell much.\nThe answer to that is that we recommand that users learn to define and use their own mask (all the time!) as soon as possible and always specify a mask on the command line if you use the mask attack.\nAs you can see, there are some advantages and disadvantages about the current default mask, but in general it still seems to be a more reasonable mask than a \"just brute-force all possible chars\" mask.\n. @migroves do you think we should/could close this issue, because it is not in our hands to fix it? (only a new/better driver or fortunately the alternative driver helps here)\nIf so, please close the issue. Thanks\n. k, I will close this pull request for now ... and maybe reopen a new one when I have a (better) solution.\nThanks\n. I think this should answer the question about how the output can be formatted (and include the username/email etc):\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_can_i_show_previously_cracked_passwords_and_output_them_in_a_specific_format_eg_emailpassword\nThis is a question listed within the \"frequently asked question\" wiki for good reason, i.e. because it was answered already thousands of times within the forum/irc/pms etc.\nMaybe this kind of questions fits better on hashcat's forum, instead of a github issue, dunno.\n(and you need to use --show, because some users prefer not to have the username within the \"normal\" output even if --username was specified, they only want to get rid - quickly load - the hash lists)\n. Thanks for the confirmation. But YOU (or a github user with special priviledges for this repository) needs to close this ticket. Can you close it, please?\nThank you very much \n. There is no such concept implemented within hashcat such that \"hashes are remove from potfile\".\nThe hashes always get appended to the potfile (it won't get overridden, delteted etc)\nCan you provide a full example such that it is easier to understand how to reproduce this and what you mean in detail. A minimal step by step example would be perfect, including the content of the potfile after each cracking step.\nBTW: there is also the (new) --potfile-path parameter that allows you to specify a very specific potfile (if you have many .pot files, the default one is \"hashcat.pot\"). \n. That sounds about right. Nothing wrong about that.\nThis behaviour is exacly like it was intended and it seems that it is working correctly.\nBTW: you can use --show to display all the cracks (but this is nothing new, it was working exactly like this since years, e.g. already shown cracks won't be outputted again and again and again... which would be kind of useless - at least in most of the cases -), you can use --potfile-disable if you don't want to \"remove hashes that are part of the current cracking job but are present in the potfile because already cracked\" \n. Well, you would need to modify the kernel to make more than 1 transforms.\nThe best way would be to use the current kernel - the fastest - to run (as currently implemented) 1 single transform for all password + salts <= 55 ... but have a modified kernel to make exactly 2 transforms and only allow  a total length (password length+salt length) > 55.\nA different approach would be more flexible (but probably also much, much slower) is to use a random number of transforms (i.e. implement a single kernel which allows both 1 transform or 2 transforms).\nThe first approach should of course be prefered. In general, both modified approaches/kernels will be much slower as the current kernel (because more and - if you choose approach 2 - flexible amount of transforms, which of course is a performance killer).\nI don't think that this should be implemented by the hashcat devs and committed to this repository, since > 55 passwords are fortunately still kind of rare and because of the speed drop (which will be unavoidable even if the passwords are less than 56).\nIf the algorithm is used within a specific software/cms/forum software etc, the story is different because it can be implemented as a specific algorithm with specific limits and not as a general algorithm like -m 50 (were speed is the most important factor).\nThanks \n. For -a 3 (mask attack) you should always specify a mask: https://hashcat.net/wiki/mask_attack\nThe default mask (?1?2?2?2?2?2?2?3?3?3?3?d?d?d?d, see https://hashcat.net/wiki/oclHashcat#default_values) of course is not designed to crack each and every password (otherwise it wouldn't be a clever default mask, but indeed a brute-force attack which could take much, much longer instead).\nIf you want to test if a specific password/hash combination cracks, use word-based attack (-a 0) with the password within the dictionary or if you really want a mask like -a 3 \"appleappleapple\" instead.\nPlease don't forget to close this \"issue\".\nThanks\n. Because the default is: whenever a GPU is present, hashcat only uses the GPU because in general GPUs are much, much faster (and using both CPU and (dedicated) GPU at the same time are (1) not desired by the majority of the users because it could lead to lag/high CPU use and (2) in some very specific cases it could even slow the cracking process down because of a \"too busy\" CPU not able to feed the GPUs with enough work).\nYou can always play around with \"--opencl-device-types 1,2\" (without quotes) to allow both CPU and GPU devices. You can also select a platform (--opencl-platforms) or select a specific device with --opencl-device (or short -d). Don't forget to allow/whitelist them with --opencl-device-types.\nAgain, this is a frequently asked question and in my opinion doesn't really belong to a github issue (but should be very easy to find out by just looking at the forum and using the forum's search function @ https://hashcat.net/forum)\nThank you very much\n(don't forget to close the issue if you agree that this \"problem\" is \"solved\")\n. This seems to be a duplicate of these (closed) issues: #403, #430 \nPlease don't forget to close this issue\nThank you very much\n. I can't reproduce this at all.\nMaybe the lines have some trailing spaces etc?\nIf not, what is the command line (and content of the input files) you use ?\n. Since the algorithm of -m 21 = osCommerce, xt:Commerce is \"md5 ($salt . $pass)\" you need both the hash and the salt to recover the password. This means that the input hash line, like with most other salted hashes, needs to have a salt part, in this case delimited by a colon \":\".\nThe example on the wiki page clearly says that the input includes a salt (the \":36\" in this very particular case, meaning: delimiter \":\" followed by the salt \"36\"):\n21        osCommerce, xt:Commerce         374996a5e8a5e57fd97d893f7df79824:36\nThe \":36\" is not optional, instead is some crucial information, the salt, that is needed. You can't simply skip it and just say that hashcat doesn't accept it and that the example hash is wrong or hashcat has a bug.\nThe algo is md5 of the password and the salt, so hashcat needs both.\nI would say this should be close because I don't see any problem here (except this misunderstanding from your side), don't forget to close the ticket if you agree.\nThanks \n. Do you mean a custom hashing algorithm?\nWell, there is no documentation yet to guide you to all of the steps you need to do, but it should be quite easy to add a new custom algorithm if you have a glance at the most recently commits of \"new algorithms\".\nFor instance, atom even mentioned here https://github.com/hashcat/hashcat/issues/68#issuecomment-170273665 that this is kind of a \"guide\", expressed by a new hash-mode commit (these few lines of code should tell you more than thousands of lines of documentation, if you are into coding).\n. it's possible to specify a directory instead of several files (also for -a 6 and -a 7).\nThe reason why hashcat doesn't allow wildcards with attack type 6 and attack type 7, is that the format is:\n-a 6: dict/directory mask\n-a 7: mask disk/directory\nIf we allow the use of wildcards, we also need to allow much more command line parameters (and random number of those parameters) because the shells (in general) do the file globbing beforehand (even before the hashcat process starts).\nFor attack type -a 0 it is more or less straightforward, the user can append as many command line parameters (i.e. dicts/directories) as he wants to... but for -a 7 and especially -a 6 it is different, because somewhere the user needs to specify the mask too. In case of -a 6 the last parameter must be the mask.\nIn addition to that, what should happen if the user specifies several wildcards within the same command?\nE.g. -a 6 dir1/*.txt --increment dir2/*.dict ?a?a?a?a\nor something like this.... It makes the parsing of the command line much more complicated.\nI think the directory support should work in most cases, so just try to specify the path to the directory instead of using a wildcard.\n. I think this is totally not within the scope of what hashcat is intended to do.\nAfter all, hashcat is an \"advanced password recovery\" tool (as you can read on hashcat's website/github README etc etc).\nWhat you instead think hashcat should do (in the future) by encrypting/decrypting whole files etc has nothing to do with passwords, nor with hashes. Also, encryption is of course not the same as hashing. As you may know, hashcat focuses on recovering passwords by starting with a password hash (yeah, sometimes the hashing algorithm also has some encryption steps, also sometimes involving AES, but that are most of the times special cases of \"key derivation\" starting from passwords etc).\nI don't think that we should support something like this within hashcat.\nA different tool that maybe does not exist already (I didn't check it in detail) may be available in the future (I don't know, at least I can't exclude it at all). At least it isn't totally impossible. But it probably won't be called \"hashcat\" or a \"password recovery tool\".\nYou also need to consider that it's not the same procedure of hashing a few bytes compared to encrypting dozens or hundreds (or even thousands?) of megabytes. There might be other challenges that needs to be addressed, like transfer time bottlenecks etc  (if you transfer more bytes in both directions, to and away from your GPU, there could be some (speed) problems involved etc).\nI don't think something like this should be implemented in hashcat.\n. I think we need to fix the URL, it should be this one https://hashcat.net/files/hashcat-3.10.tar.gz.asc\n. This algorithm is not yet supported.\nI had a quick glance on the algorithm details and it seems that it is as simple as this:\n```\n!/usr/bin/env perl\nuse strict;\nuse warnings;\niWork\nthere exist two versions: iWork 09 and iWork 2013 (2014)\nuse Crypt::PBKDF2;\nuse Crypt::CBC;\nuse Digest::SHA qw (sha256);\nConstants\nmy $hash_version = 1; # or 2\nmy $file_version = 2; # or 1\nmy $format = 1;\nmy $iterations = 100000; # or 4000 for iWork version 2009\nExample\nmy $pass = \"hashcat\";\nmy $salt = pack (\"H\", \"e5eea8cf92ac364e3ba0e20be906e072\"); # RANDOM , can be also just 16 bytes long for 2009 version\nmy $iv   = pack (\"H\", \"55cf3deb5886390f919edf99e3ba40dd\"); # RANDOM\nmy $data = pack (\"H*\", \"c0f4a2a999d7eab7b2ab73e0f0673a26b2961166cda47a35f87b9bc98c54572\"); # RANDOM\nStart\nconcatenate data + hash (SHA-256) of data:\nmy $sha256_of_data = sha256 ($data);\nmy $output = $data . $sha256_of_data;\nPBKDF2-HMAC-SHA1 for the key (16 output bytes)\nmy $pbkdf2 = Crypt::PBKDF2->new\n(\n  hasher     => Crypt::PBKDF2->hasher_from_algorithm ('HMACSHA1'),\n  iterations => $iterations,\n  output_len => 16,\n);\nmy $key = $pbkdf2->PBKDF2 ($salt, $pass);\nAES-CBC\nmy $cipher = Crypt::CBC->new ({\n               key         => $key,\n               cipher      => \"Crypt::Rijndael\",\n               iv          => $iv,\n               literal_key => 1,\n               header      => \"none\",\n               keysize     => 16,\n               padding     => \"null\"\n             });\nmy $encrypted = $cipher->encrypt ($output);\nOutput\nmy $hash = sprintf (\"\\$iwork\\$%i\\$%i\\$%i\\$%i\\$%s\\$%s\\$%s\", $hash_version, $file_version, $format, $iterations, unpack (\"H\", $salt), unpack (\"H\", $iv), unpack (\"H*\", $encrypted));\nprint $hash . \"\\n\";\n```\nNote: the verification step should be very simple... just compare if the sha256 hash of the first 32 bytes of the decrypted blob is equal to the last 32 bytes. . @killswitch-GUI\nThis is clearly incorrect:\nhashcat -a 3 -m 0 test.txt ?a?a?a?a?a?a\nit should be something like this:\nhashcat -a 3 -m 7100 test.txt ?a?a?a?a?a?a\nThe hash mode was incorrect (you set it to MD5 instead of OSX v10.8+) in your command line arguments. This is a note for the devs: this algorithm is implemented as Sybase-PROP FEAL-8 in jtr (see generate_hash () in https://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/src/syb-prop_repro_plug.c). All in all, it seems to be a very \"strange\" and old algo.. I would say that we do not need to care about the PBKDF2-HMAC-SHA256 to validate the data.\nHere is a script on how to generate those hashes:\n```\n!/usr/bin/env perl\nEnpass - SQLCipher\nuse strict;\nuse warnings;\nuse Crypt::PBKDF2;\nuse Crypt::CBC;\nConstants\nmy $version = 0;\nmy $iterations = 24000;\nExample\nmy $pass = \"hashcat\";\nmy $salt = pack (\"H\", \"bf7ab8a455932bd6021f77b0a2cdd538\"); # RANDOM\nmy $iv   = pack (\"H\", \"1afbb25f0bd1b3d6b6cbff359e7071e9\"); # RANDOM\nmy $additional_data = \"\\x00\" x 32; # something that we do not care about\nproperties of the data:\n- the 4th byte should not be larger than 2 (check for <= 1)\n- needs to contain \"402020\" (3 bytes, starting at 6th byte)\n- first 2 bytes determine the page size (* 256): in our case 0x000400 = 1024\n- the page size must be less than SQLITE_MAX_PAGE_SIZE (65536) and larger than 256\n- page size must be a multiple of 8 (should be always the case if we multiply by 256?)\n- the usable size is determined by page size - 5th byte = 1024 - 0x30 = 976\n- usable size can't be less than 480\nmy $search_string = pack (\"H*\", \"0400010130402020\" . (\"00\" x 936)); # example of valid data\nStart\nmy $pbkdf2 = Crypt::PBKDF2->new                                                                                                                        \n(                                                                                                                                                      \n  hasher     => Crypt::PBKDF2->hasher_from_algorithm ('HMACSHA1'),                                                                                     \n  iterations => $iterations,                                                                                                                           \n  output_len => 32,                                                                                                                                    \n);                                                                                                                                                       \nmy $key = $pbkdf2->PBKDF2 ($salt, $pass);\nmy $cipher = Crypt::CBC->new ({\n               key         => $key,\n               cipher      => \"Crypt::Rijndael\",\n               iv          => $iv,\n               literal_key => 1,\n               header      => \"none\",\n               keysize     => 32\n             });\nmy $encrypted = $cipher->encrypt ($search_string);\nOutput\nmy $hash = sprintf(\"\\$enpass\\$%i\\$%i\\$%s%s%s%s\", $version, $iterations, unpack (\"H\", $salt), unpack (\"H\", $encrypted), unpack (\"H\", $iv), unpack (\"H\", $additional_data));\nprint $hash . \"\\n\";\n```\nJtr recently added this format: https://github.com/magnumripper/JohnTheRipper/blob/2a68d62e06905a6902c568260cf0f87f4ab133d9/src/enpass_fmt_plug.c\nThere is a tool to convert the .walltex files to the above hash format (enpass2john.py): https://github.com/magnumripper/JohnTheRipper/blob/6a58e5d01b388a931403e2448aca6eac6e6d1bd8/run/enpass2john.py. Sorry if I wasn't clear enough. I was just having a look at the algorithm details.\nOf course, this type of \"hashes\" are not yet supported by hashcat (especially because the AES-CBC decryption and validation part needs to be done too) and this needs to be implemented with a distinct hash type (-m x), parser, kernel + validation on GPU etc.\nSo currently you can't use hashcat for this type of \"hashes\". This is a new algorithm that needs to be implemented (it's for sure not just -m 12000, like one could believe, it's much more, as you can see from the POC above).\nThanks. This is an example hash:\n{PKCS5S2}OHyYon6Cl9y842mEUkgeCsH0HkipUYNNLjqotyOE0wF1oywazi6sm9kDASYw0xzF:hashcat\nit can be generated like this (perl):\n```\n!/usr/bin/env perl\nuse strict;\nuse warnings;\nuse MIME::Base64;\nuse Crypt::PBKDF2;\nmy $w = \"hashcat\";\nmy $s = pack (\"H*\", \"387c98a27e8297dcbce3698452481e0a\");\nmy $a = Crypt::PBKDF2->new\n(\n  hasher     => Crypt::PBKDF2->hasher_from_algorithm ('HMACSHA1'),\n  iterations => 10000,\n  output_len => 32,\n);\nmy $h = $a->PBKDF2 ($s, $w);\nmy $b = encode_base64 ($s. $h);\n$b =~ s/[\\r\\n]//g;\nprint \"{PKCS5S2}\" . $b . \"\\n\";\n```\npython (passlib method):\n```\n!/usr/bin/env python\nfrom passlib.hash import atlassian_pbkdf2_sha1\nfrom binascii import unhexlify\nw = \"hashcat\"\ns = unhexlify (\"387c98a27e8297dcbce3698452481e0a\")\na = atlassian_pbkdf2_sha1.using (salt=s)\nprint a.verify (w, \"{PKCS5S2}OHyYon6Cl9y842mEUkgeCsH0HkipUYNNLjqotyOE0wF1oywazi6sm9kDASYw0xzF\")\nprint a.hash (w);\n```\nTo convert it (manually) to the hashcat format (-m 12000 = PBKDF2-HMAC-SHA1):\n- we know we have always 10000 iteration\n- we know that the salt has a fixed length of 16\n- we need to base64 decode the whole string (lets say into hexadeximal):\n$ echo OHyYon6Cl9y842mEUkgeCsH0HkipUYNNLjqotyOE0wF1oywazi6sm9kDASYw0xzF | base64 -d | xxd -p\n387c98a27e8297dcbce3698452481e0ac1f41e48a951834d2e3aa8b72384d30175a32c1ace2eac9bd903012630d31cc5\n- use the first 32 hex chars (or 16 bytes) and base64 encode them:\n```\n$ echo 387c98a27e8297dcbce3698452481e0a | xxd -p -r | base64\nOHyYon6Cl9y842mEUkgeCg==\n- use the remaining bytes as input to base64 (they will form the actual \"hash\"):\n$ echo c1f41e48a951834d2e3aa8b72384d30175a32c1ace2eac9bd903012630d31cc5 | xxd -p -r | base64\nwfQeSKlRg00uOqi3I4TTAXWjLBrOLqyb2QMBJjDTHMU=\n```\n- and combine it all together:\nsha1:10000:OHyYon6Cl9y842mEUkgeCg==:wfQeSKlRg00uOqi3I4TTAXWjLBrOLqyb2QMBJjDTHMU=\n\nwe can try to crack it with hashcat:\n$ ./hashcat -m 12000 -a 3 'sha1:10000:OHyYon6Cl9y842mEUkgeCg==:wfQeSKlRg00uOqi3I4TTAXWjLBrOLqyb2QMBJjDTHMU=' ?lashcat\nsha1:10000:OHyYon6Cl9y842mEUkgeCg==:wfQeSKlRg00uOqi3I4TTAXWjLBrOLqyb2QMBJjDTHMU=:hashcat\n\nActually, it should be pretty easy to both convert the hashes manually (or with a simple script) or implement a simple parser into hashcat.\nIs anyone still interested in this support ? Should hashcat add a parser for this type of hashes?. @dibiloid could you please test with the current beta version (https://hashcat.net/beta/ , beta 3.40-rc12 or any later version)?   . Note: this is about -m 3300 = MD5(Sun) (example hash: $md5$rounds=904$iPPKEBnEkp3JV8uX$0L6m7rOFTVFn.SGqo2M9W1:hashcat).\nThis hash type was never implemented on GPU and was only available on hashcat-legacy (CPU only).\nAs far as I remember, this is kind of a strange/GPU-unfriendly algorithm.\nWe need to decide if it makes sense to implement it in hashcat.. for you interest, I confirmed here: https://hashcat.net/forum/thread-6233-post-33255.html#pid33255 that the algorithms used for owner password vs user password are just slightly different (the example was with revision 3 PDF 1.4 - 1.6).\nUnfortunately we probably have to do it for each and every PDF revision (+ write parser + new hash modes + kernels etc).... furthermore there is very little requests for this type of password recovery (probably because most of the users just simply work around the permission control of PDF and do not care about the owners password).\nWell, if you still think it is worth the effort, you should give at least some thumbs up on this issue and we will rethink if we should implement it ;). Some additional (nice-to-know) notes about the FileZilla Server algorithm (for devs):\nthe FileZilla Server source code is available here:\nsvn co https://svn.filezilla-project.org/svn/FileZilla%20Server/trunk filezilla_server\nIt seems that FileZilla Server used to MD5 ($pass) hash the user credentials in versions < v0.9.55, see \nhttps://svn.filezilla-project.org/filezilla/FileZilla%20Server/trunk/readme.htm?revision=7789&content-type=text%2Fplain : \n\nNewly set account passwords are now stored in form of salted SHA512 hashes\n\nFurthermore the SaveUser () function seems to be interesting:\nhttps://svn.filezilla-project.org/filezilla/FileZilla%20Server/trunk/source/Interface/UsersDlgGeneral.cpp?view=markup#l265\nand of course the generateSalt () function:\nhttps://svn.filezilla-project.org/filezilla/FileZilla%20Server/trunk/source/Accounts.cpp?view=markup#l471\nTo sum it up, the salt length seems to be hard-coded (to 64 bytes exactly) and the first version that supports this is v0.9.55, so we might add a format like -m 1712 = FileZilla Server >= v0.9.55. Well, it would be great if somebody can investigate what is going on here about the salt length...\nas far as we know Woltlab Burning Board 3 uses exactly 40 bytes salt.\nNewer versions of WBB (4.x) use a totally different algorithm: https://github.com/hashcat/hashcat/issues/73\n-m 8400 = WBB3 (Woltlab Burning Board) already supports the algorithm sha1($salt.sha1($salt.sha1($pass))), but of course (mostly because of optimizations) restricts the salt to exactly 40 bytes.\nSo why now the salt can be shorter? Is this restriction wrong? ... or is there even a third version of the WBB algorithm?\nWe can't just silently close this issue, something needs to be done (either we need to do some changes to -m 8400 or we need to add some additional hash type and information to the help such that other users can crack those hashes too).\nIt would be great if someone can do some reaseach/investigation about this missing information and resolve these doubts.\nThanks. I just wrote a proof of concept and realized that we miss some further information in the hash format:\n1. the length of the uncompressed data (needed to allocate the memory and tell LZMA how long the output will be)\n2. the length of the first \"stream\" (i.e. how many bytes of the start of the decompressed data will be needed to generate the CRC32). Note: if there are more files in the .7z file, the data of all files will be \"concatenated\" but the CRC32 checksum we need to check was generated by just the bytes of the first file.\n3. the attributes (lc, pb, lp and the dicSize) especially needed for LZMA1\n(all of this info should be easily available/accessible with 7z2hashcat.pl, but we probably need to adapt the hash format again!!!)\n@magnumripper \nHere is a proof of concept/test (feel free to use it): https://gist.github.com/philsmd/99aebdc722472b5322a4e0b0408d743a\nThank you very much. Yeah, maybe something like this:\nwhenever we have $7z$0$ hashes we use:\n...$[data]\nwhenever we have $7z$1$ or $7z$2$ hashes we use:\n...$[data]$[uncompressed_data_length]$[first_file_size]$[coder_attributes]\nWe just need to agree on the hash format and it shouldn't be too difficult to implement both in 7z2hashcat.pl and within the cracking tools.. update: we agreed to the format with (only) the optional crc_len and coder_attributes added.\nThe format should now be stable and hopefully doesn't need to be change anytime soon... therefore we could start to implement the parser and hook for hashcat.. This feature is now implemented, see: https://github.com/philsmd/hashcat/commit/6fe0173a79fa9afcaf74bd2385a85c93f92df5bc. I had the chance to investigate this \"issue\" a little bit here: https://github.com/Homebrew/homebrew-core/pull/8655#issuecomment-277308487 .\nMy conclusion: this is completely unrelated to hashcat, it is just an incorrect test which doesn't respect the sandboxing rules and therefore the sandbox blocks the file read/writes.\nAn example of a modified test was provided within the above issue (https://github.com/Homebrew/homebrew-core/pull/8655).\nI would say, that we can close this, since I don't see any misbehaving/problem from hashcat itself.. -m 14700 was added for versions < 10.0 and maybe -m 14800 will be added soon. In the meantime you can try to use -m 14700 (with beta versions or git versions) and maybe also this tool helps: https://github.com/philsmd/itunes_backup2hashcat\nThanks. Update: we now also implemented -m 14800 = iTunes Backup >= 10 , see https://github.com/hashcat/hashcat/commit/07c89833c922bd4980f9bee489fc0d73725380de. Could you please re-try with these changes: https://github.com/hashcat/hashcat/pull/982 ?\nThanks. This is a general limitation for password candidates, see https://hashcat.net/faq#what_is_the_maximum_supported_password_length\nThe reasons (in general) are that it is very difficult to crack (do not even mention brute-force) a password that is that long, the performance drop that would affect many algorithms if several transforms etc must be done because of the longer length and of course that the general user uses very short and easy to remember passwords (this might not be applicable for veracrypt, but definitely for most of the other algorithms).\nI would not call this an issue. This is a known limitation and it makes sense in almost all of the cases to prefer better performance instead of absurdly long passwords (at least in the perspective of an attacker which even has difficulties to crack passwords > 8 characters) that without knowing the password (or having it in the word list) you wouldn't crack in centuries.. Thanks for the report. I was able to reproduce this problem with the following (minimalized) steps:\n$ cat 1000_3000.hash \nAdministrator:500:0000000000000000299bd128c1101fd6:b4b9b02e6f09a9bd760f388b67351e2b:::\n$ cat dict.txt\nhashcat\n$ ./hashcat -m 3000 1000_3000.hash dict.txt\n299bd128c1101fd6:HASHCAT\n$ ./hashcat --username --show -m 3000 1000_3000.hash \nSegmentation fault (core dumped)\nSo what I understand from this is that it doesn't matter if you specify --potfile-path and it only happens if --username was specified (even if it wasn't necessary, because hashcat recognized the pwdump format).\nWe will investigate and hopefully fix this soon.\nThx. I had a quick glance at this problem and tested it, but I came to the conclusion that you just miss the --restore-file-path within the last command (the actual restore step).\nHashcat doesn't store the \"last-used-restore-path\" anywhere, so it doesn't have the information where the restore file that you wanted to run, is located.\nYou need to use something like this:\n./hashcat64.bin --session testsession --restore --restore-file-path /root/testsession\nTo sum it up, hashcat either can automatically look up for the file [session_restore].restore in the default directory, but whenever you use a custom path for the restore file (--restore-file-path), you need to specify that path on both runs (the actual start of the cracking and the restore step).\nDoes it work for you with --restore-file-path when restoring? Do you agree that this makes sense?\nPlease don't forget to close the issue if you agree that this is expected behaviour.\nThanks\n\nupdate: almost forgot about the first issue: hashcat doesn't work with the cwd, because users complained about files being created all over there file system, so it uses the path specified in the (profile directory: it is the home directory + \".hashcat/\" - aka ~/.hashcat/ - per default if you use make install, or the download directory otherwise). This is a duplicate of https://github.com/hashcat/hashcat/issues/68 . We should consider closing this issue as duplicate and keep #68 open, do you agree?. Since I can't reproduce, could you please recompile like this:\nmake clean\nDEBUG=1 make\nthe output if you run it afterwards already should be more verbose, if not enough, please use:\ngdb --args ./hashcat64.bin -m 3000 --username --show --outfile-format 2 --potfile-path ../hashcat/hashcat.potfile ../original_hashes.txt\nafter that type \"r\" to tun it under gdb, use \"bt\" to show the full backtrack (you can exit with \"q\" and \"yes\")\nThanks. note: this might also be related to this issue that was already fixed: https://github.com/hashcat/hashcat/issues/996\n... but if that would be the case, you shouldn't experience crashes with the newest version from github (or beta: https://hashcat.net/beta/). Please follow this guide (https://hashcat.net/faq#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this) if you want to request some new algorithm.\nEspecially the information about where this hash type is used would be very crucial for the devs to decide if this makes sense (for other users too) to add this new algorithm.\nThanks. This is one of those formats that were only present in hashcat-legacy (CPU version only).\nThere was never GPU support for -m 3910 = md5 (md5 ($pass) . md5 ($salt))\nSome example hash of this algo:\n250920b3a5e31318806a032a4674df7e:1234:hashcat\n462ae870f71e3926c2661f3fb9dee273:200027583:hashcat\n(note: just to clarify, the output of both inner MD5 () is in - lowercase - hexadecimal, not binary). This should be already supported by this hash type:\n-m 11400 = SIP digest authentication (MD5) \nDid you test with that hash type?. What do you mean by \"different parameters\" ? Different from what?\nHere is the explanation of the fields:\n$sip$*[URI_SERVER]*[URI_CLIENT]*[USERNAME]*[REALM]*[METHOD]*[URI_PREFIX]*[URI_RESOURCE]*[URI_SUFFIX]*[NONCE_SERVER]*[NONCE_CLIENT]*[NONCE_COUNT]*[QOP]*[DIRECTIVE]*[MD5]\n. I tried the hash you provided and it just works as it should (maybe you are just using an older version of hashcat?):\n./hashcat -m 11600 -a 3 --quiet mega.txt wetwilly20?d?d\n$7z$1$19$0$$8$f25e0c9dbe5f45910000000000000000$2892453778$512$510$e598324b3892f3774dcb7d5cb581ea341e86b103667c3b458e5e4351198c6efac3f6acfdd75311417653854f28652b6a5630ac9e4edaa809ffd5df9d0d3323fc18c27f5491795c58a8eacd01436e4b42b4ba868414598f29c1fdb42ce55a240c58df02fd01b9eff3e5c7c61db4e2deb802e7df17989f98895607741686acad12f6dee59d1efd0e0aaa19ee0b124d7f1c722e55b97e1929be26eee703cf3a6777a57219e1111390c069a8d74a44babcbd80eb0e6c92e67b743c3bdf03870b5486b1d4a1d89b3e01f49ffa12a1c738625eae3a5c7bd3106ef38eb4dd9deb1304f770563c049a9f732ed63eb752c384fbcab914caa9220c5e20cd9096c6fca29a3a088c07eb6d441295082e842154b522c6e54c0dbd25ef2294e2dc5bc718c733def90e15a7f7ee64dc7001720847216fd3f06f63b3f34331739b69afe2deb73844a0f424e387604090be88cb2d1328e56283ff0c63d150bb718a416ac155fe560812ecdcbb289377a9198d4551577aa6c2e8925227964c2e0035dece6045f54859fa03ab768b34e2444064bb413177c85a18950dc2cae40bfa1039f54432314e563fb6ea78f54363f118b172a62621f44636b93378536792208fcfb7e527ee08ff9e7d5bbe0e12dd97bd3851895a8bb8c58f0da2217719521b14f9ef2cf8cf1fc8cc523e117be753407f4574a5fa9399c8bde7da231dd8e3cd20dd34ab00885d36$922$5d00100000:wetwilly2016\nNote: the release version of course is not up-to-date here, because we made some changes recently, for instance this one: https://github.com/hashcat/hashcat/issues/965\nI would say we close this because for example the beta versions: https://hashcat.net/beta/ already supported this type of longer inputs for -m 11600 after we closed issue #965 \nRemember: only @lavanoid and the repository admins (or whoever have full permission) can close the issue. So please test and don't forget to close the issue if it was \"pebcak\".\n\nBTW: please consider giving the issues more meaningful names \"longer hash length\" could mean anything, If it still were a problem, which it is not, it would be something very specific to -m 11600 = 7-Zip and therefore you should mention it in the issue title. Thanks\n. For the time being it was just increased a little bit: https://github.com/philsmd/hashcat/commit/6fe0173a79fa9afcaf74bd2385a85c93f92df5bc#diff-e499f13732ab92b6ade223fa29cf9da3R1091 ( I actually also think we should make this a macro, not hard-code it). Yeah, it could be increased to whatever limit (or even no limit at all), but as we usually prefer to add some upper-limit in hashcat, the decision was to just increase it.\nbtw, 7z2hashcat.pl should always reflect this limit with the PASSWORD_RECOVERY_TOOL_DATA_LIMIT variable (I thought you were aware of this variable?).\nThanks. @neheb \nI'm just questioning if this is the right way to approach this problem, my concerns (I'm not trying to discourage you, I just want to fix this correctly or at least discuss this a little bit more):\n1. may this be related to this \"issue\" https://github.com/hashcat/hashcat/pull/1024 ? I see no clear reference to the issue but it seems to be related and I'm wondering if the chance to have a combination of an issue and PR at almost the same time about the very same problem should be too low such that it doesn't seem very likely that these are 2 distinct \"problems\". Maybe you just forgot to mention it, dunno... or we are very (un)lucky and it was all just a coincidence (anyway, if you fix an issue, you should reference it in the future)\n2. I don't think we should just disable file globbing like this\n3. There was a commit (by @atom, this one https://github.com/hashcat/hashcat/commit/cd3fae958dbf28b79ce190f5759c8e5ce3e46006 ?) that explicity made the changes to support file globbing with the native target. Essentially, the changes within your PR, kind of silently revert this. I think atom added the support on purpose (not by mistake)... we should be a little bit careful here what happened within previous commits, just saying (no offense! this is something that I find myself struggling with, e.g. understanding why somebody added something and to forget to check the file history etc)\n3. There is a whole separate section within win_file_globbing.mk labeled \"win native\" ... and a variable called IS_WIN_BUILD_NATIVE ... your changes kind of make this section useless and also the variable name now becomes kind of misleading (the result is no more \"all native windows builds\" as the variable name might suggest and it was previously).\n4. I think the right way to fix this is to detect the architecture of the native build and always enable file globbing on windows (no matter if it was native or a \"release\"/binary build)... whenever the correct CRT_glob.o (for the correct architecture) can be found\n5. btw: I also find this CRT_GLOB := $(shell $(FIND) / -name $(CRT_GLOB_FILE_NAME) -print -quit) a little bit too much ... at least when we look at where it tries to search i.e. the whole (mysys/cygwin/) file system which could be huge  (this has nothing to do with your PR, I just try to suggest/discuss some changes)... we should limit the search to the libs!\nTherefore my suggestion would be to try to fix the root of the problem (not just disable file globbing in general for all native builds just because it sometimes uses the wrong CRT_glob.o since that file might be of a different/incorrect architecture).\nI'm not saying that I fully grasp how all this cygwin/mysys differences work... but I suggest that we do not disable file globbing in general for native builds, because, as said, I think this was added on purpose.\nI would be happy to discuss this with all of you... maybe I'm just totally wrong about my conclusions and if so please explain it here why we need to disable file globbing like this. (yeah, I admit I'm more used to work with linux so that might limit my understand here a lot).\nAs said, would be great if we can somehow eliminate my concerns and find a solution that does not just work around the build problems, but instead fix the root of the problems...\nPlease discuss it with me... I'm sure we can find a good solution that is acceptable by all of us (and hopefully that \"just works\" - preferably with file globbing enabled ;) -).\nThanks\n\nBTW: I forgot to tell you that I really like your (past) contributions to hashcat and really appreciate them... I just think that here we need some \"room\" for discussion (at least to understand the main problem)\n. Thanks @neheb for explaining this. I didn't know this.\nI suggest that we document that (with some more comments in win_file_globbing.mk) such that we keep this information safe for the future.\nSo, if I'm not totally mistaken, file globbing should work with both cross-compiling (mingw) and non-cross-compiling, MYSYS and cygwin. For cygwin it's a little bit different and we should make this clear also in win_file_globbing.mk (by changing the code and/or adding comments).\nCould you do these changes, @neheb?\nThanks again. I just made some tests with appveyor (I didn't know this even existed before @stephengroat made his PR). See: https://ci.appveyor.com/project/philsmd/hashcat/build/1.0.2/job/0wcvyc7ncdh84o85#L597\nThere still are some errors with your latest code @neheb.\nSince I can't guarantee that my appveyor_test branch is always up-to-date, could I kindly ask you that you also test with appveyor and link your appveyor test builds here (with \"neheb\" in the URL, you need to sign in, e.g. with oauth to appveyor)?\nDo you know how these remaining errors can be correctly fixed?\nThank you very much for your contributions!. I'm not sure about this _dowildcard variable... but  if it really works (and the binary builds - cross-compilations - continue to work), then we should make changes to reflect this new approach also in the win globbing file (win_file_globbing.mk).\nFurthermore, I just found out that the mingw compiler allows this command line option: --enable-wildcard (which actually does something similar to _dowildcard = -1, but seems to be a little bit more intuitive).\nWe should definitevely document all this facts within win_file_globbing.mk:\n1. on which systems (mingw native, mingw cross-compile, mysys, cygwin, .... you name it!) we can use file globbing\n2. for each and every of this systems we should explain our approach: for instance in this case we could document it like this: \"for mingw builds, we can simply use --enable-wildcard, no need to find CRT_glob.o\" (this is just an example, I'm still not sure if this is correct, we need to test)\n3. of course we also need to change win_file_globbing.mk accordingly (or in some cases it might be needed to also change src/Makefile)\n\nFor what regards the tests: when I was mentioning \"hashcat-run tests\" with appveyor I was thinking about some (or even just a single one to start with) very quick tests after appveyor finished the building process. Not a full run of tools/test.sh ! this would be much too demanding. tools/test.sh is intended to test each and every hash type, this takes hours.\nInstead, I was thinking here about something similar to the \"test\" formula-sections which the hashcat.rb homebrew formula performs: just some quick tests after the build process.\nI found out (already yesterday when opening this issue), that appveyor allows to do exactly this: see https://www.appveyor.com/docs/appveyor-yml/ (search for \"test_script\").\nI'm not sure exactly what we need to write under that section, but it seems that it just tests for the exit code of the executable (is this correct?). Then it would be something as simple as this:\ntest_script:\n  - hashcat -m 0 --show *ple0.hash\nThis would, if everything works correctly, return exit code 0 (and therefore succeed, because the file should expand to example0.hash)\nIdeally, we would also test for the opposite (e.g. if we specify a file that shouldn't exit, it should throw an error e.g. \"hashcat -m 0 --show *file_not_found.hash\")\nBtw: if needed I saw some more elaborate examples of appveyor.yml test_script section, see \nhttps://github.com/Microsoft/bond/blob/master/appveyor.yml#L213-L243 (just a random example, but the throw statements look interesting, I'm also still not sure if we can use this \"ps\" (powershell?) accross all windows builds with appveyor, this needs to be tested). Something that might be needed is using this: if ($LastExitCode -ne 0) { $host.SetShouldExit ($LastExitCode)  } in case of the \"opposite/failing globbing test\" mentioned above etc, but this all needs to be double checked\n\nUpdate: it seems that --enable-wildcard does something different than I was thinking it would do.... it is just used to compile the mingw libraries themself, not the end-user binaries with gcc (so it seems we can't use --enable-wildcard, even if that would be some really nice feature of mingw, but it doesn't work like I was thinking). btw, these are the changes that are important for this issue here too (and about which @jsteube is talking about): https://github.com/hashcat/hashcat/commit/79513ce2265f0541142a4f1ee8989db594ebe537. Just that we avoid doing the same thing: I'm currently preparing 2 commits for badges and for the \"test_script\" session (2 PRs should be ready soon).\nAfter that we will see what is still missing to close this issue.. What is still confusing to me is this:\nMSYSTEM: MINGW32\nBASH: C:\\msys64\\usr\\bin\\bash\nMSYS_CACHE: C:\\msys64\\var\\cache\\pacman\\pkg\nWhy msys64 paths with MINGW32, is this even correct? mayeb you can explain, @stephengroat?. That was exactly what I was thinking about this strange inconsistency between paths vs MSYSTEM name (32 vs 64). Thanks for confirming it. I just wanted to make sure that we do not build 64bit mingw/msys binaries twice.\nBTW: the .appveyor.yml should now be working with test_script(s) runs... hope you can confirm that the file looks good .... and thanks again for your contributions!. Which version do you use?\nPlease re-try with the beta version (https://hashcat.net/beta/)\nThis might be a duplicate of these issues:\nhttps://github.com/hashcat/hashcat/issues/996\nhttps://github.com/hashcat/hashcat/issues/1010\n\nPS: do not forget to close the issue, if everything works with newest github source code version (or beta version). Strange, I can't reproduce with latest git version:\nPlease post the output (of your compiled binary from github) with:\n./hashcat -V\nThanks. good\nCould you please close this issue about the segfault and open a new one to request to add (back) the support for the LM part merging within the --show output ?\nAs a reference for devs you could add this commit ref https://github.com/hashcat/hashcat/commit/a460ab01b684eeb1d26c503df60d8654a57bf699 , which (unknowingly?) seems to have \"caused\" this feature removal (the important lines in code are around \"LM_MASKED_PLAIN\" etc).. Hey @gum0x, thx for your contribution.\nI think the formatting (indentation, tab vs spaces etc) got mixed up a little bit within these changes (it seems that you used tabs in places where we always use spaces etc).\nCould you please try to fix this?\nBTW: I think this variable name \"OSVERSION\" is a little bit confusing, because under linux the result seems to be just the first digit of the linux kernel number. Maybe we should add this variable to the Darwin section (because it is something specific to OSX?) and call it something like OSXVERSION ? (As you see, I'm not totally sure if my assumptions of this osxversion vs kernel version numbering are correct... maybe you can find this out too ? Thank you so much)\n\nUpdate: maybe we should make it even more generic and replace the check with a check for versions >= 16 ?. I played around with appveyor too, with this .appveyor.yml file:\n```\nenvironment:\n  CYG_MIRROR: http://cygwin.mirror.constant.com\n  CYG_PACKAGES: make,gcc-core,clang\n  matrix:\n    - MSYSTEM: MINGW64\n      BASH: C:\\msys64\\usr\\bin\\bash\n      MSYS_CACHE: C:\\msys64\\var\\cache\\pacman\\pkg\n      CC: gcc\n    - MSYSTEM: MINGW32\n      BASH: C:\\msys64\\usr\\bin\\bash\n      MSYS_CACHE: C:\\msys64\\var\\cache\\pacman\\pkg\n      CC: gcc\n    - CYG_ROOT: C:\\cygwin64\n      CYG_CACHE: C:\\cygwin64\\var\\cache\\setup\n      CYG_SETUP: setup-x86_64.exe\n      BASH: C:\\cygwin64\\bin\\bash\n      CC: gcc\n    - CYG_ROOT: C:\\cygwin\n      CYG_CACHE: C:\\cygwin\\var\\cache\\setup\n      CYG_SETUP: setup-x86.exe\n      BASH: C:\\cygwin\\bin\\bash\n      CC: gcc\n    - MSYSTEM: MINGW64\n      BASH: C:\\msys64\\usr\\bin\\bash\n      MSYS_CACHE: C:\\msys64\\var\\cache\\pacman\\pkg\n      CC: clang\n    - MSYSTEM: MINGW32\n      BASH: C:\\msys64\\usr\\bin\\bash\n      MSYS_CACHE: C:\\msys64\\var\\cache\\pacman\\pkg\n      CC: clang\n    - CYG_ROOT: C:\\cygwin64\n      CYG_CACHE: C:\\cygwin64\\var\\cache\\setup\n      CYG_SETUP: setup-x86_64.exe\n      BASH: C:\\cygwin64\\bin\\bash\n      CC: clang\n    - CYG_ROOT: C:\\cygwin\n      CYG_CACHE: C:\\cygwin\\var\\cache\\setup\n      CYG_SETUP: setup-x86.exe\n      BASH: C:\\cygwin\\bin\\bash\n      CC: clang\nclone_depth: 1\ninit:\n  # Don't try to convert line endings to Win32 CRLF\n  - git config --global core.autocrlf input\ninstall:\n  - ps: if (Test-Path Env:\\CYG_ROOT) { Start-FileDownload \"http://cygwin.com/$env:CYG_SETUP\" -FileName \"$env:CYG_SETUP\" }\n  - if defined CYG_ROOT (%CYG_SETUP% --quiet-mode --no-shortcuts --only-site --root \"%CYG_ROOT%\" --site \"%CYG_MIRROR%\" --local-package-dir \"%CYG_CACHE%\" --packages \"%CYG_PACKAGES%\" --upgrade-also)\n  - if defined MSYSTEM (%BASH% -lc \"pacman -Suuy --noconfirm\")\nbuild_script:\n  - if defined BASH (%BASH% -lc \"cd $(cygpath ${APPVEYOR_BUILD_FOLDER}) && git submodule init && git submodule update && make\")\ntest_script:\n  # some file globbing tests\n  #  1. hash file should not exist and therefore hashcat should complain (if it does not there might be a problem)\n  #  2. hash file should expand to example0.hash and succeed\n  - ps: >-\n      .\\hashcat -m 0 --show *file_not_found.hash 2>&1 | out-null\n  if ($LastExitCode -eq 0)\n  {\n    throw \"test failed\"\n  }\n\n  .\\hashcat -m 0 --show *ple0.hash\n\n```\nNote: you have a duplicate line (- if defined MSYSTEM (%BASH% -lc \"pacman -Suuy --noconfirm\"))\nthe problem is, the globbing still fails on cygwin, see https://ci.appveyor.com/project/philsmd/hashcat/build/1.0.38/job/vcqi2ole1nxvc1k2#L330\nCan you merge our files please @stephengroat ?. --custom-charset1 (or short -1) per definition only defines a custom charset.\nYou need to tell hashcat what your mask is, e.g something like this:\nhashcat64.exe -a 3 -m 9600 --increment --increment-min 1 --increment-max 7 --custom-charset1 0123456789 -o pass.txt doc.hash ?1?1?1?1?1?1?1\nAs you can see here, the mask \"?1?1?1?1?1?1?1\" (should always be at the end of the command line for -a 3), is needed and tells hashcat: at position one use the custom charset number 1 defined as all numbers from zero to nine, at position 2 also use the custom charset number 1, ...., at position 7 use the charset number 1. That output doesn't show anything interesting.\nYou need to use at least:\nmake clean\ngit pull\nmake DEBUG=1\ngdb --args hashcat ....\n(after gdb started, you need to type \"r\" to start the process, after it crashes you need to type \"bt\" for the backtrack, you can quit gdb with \"q\" and \"yes\")\nYou also forgot to mention what your command line looks like etc.\nBTW: it's probably something related to your GPU(s), drivers, OpenCL environment etc... does clinfo work without crash ? Are you sure that all drivers are correctly installed?. Hey,\nI'm wondering why:\n\nyour post is formatted like this, e.g. why do you not just use a github \"quote\"/\"code\" section and use actual newlines instead of the \"\\r\\n\" strings?\nwhy your output contains 2 errors and the topic is about the fan speed problem\ntherefore: are you sure that the \"No hashes loaded\" problem was expected and has nothing to do with your actual problem (it's just confusing why one would post 2 independent errors in a long line like this)?\n\nThe \"No hashes loaded\" should have something to do with your -m parameter and/or the format of the hashes (see https://hashcat.net/wiki/example_hashes).\nBack to the fan speed problem, yeah, sometimes we get reports like this, often it has to do with non-reference design GPU(s): custom fan design, watercooled etc.... can you give more details about your GPU(s)?  The problem most of the time is, the non-reference design cards sometimes do not report the functionality/features of the card correctly... they tell hashcat something like this: \"yeah, there is a fan and yeah you can monitor/control it\", but actually (sometimes) there is no fan and no support for monitoring/controlling a fan.\nMore information is needed here\nThanks. From reading the product description here: https://www.asus.com/Graphics-Cards/ROG-STRIX-RX470-O4G-GAMING/ (\"and outperform reference designs\", \"Gaming\" within the name etc), it seems that you are exactly in the situation described above, i.e. a non reference design with a custom cooler design... but probably they saved some cost on the firmware (and didn't change the feature list that the card supports).\nBTW (from the include/adl_defines.h file of the ADL SDK) :\n```\n// Function  not supported by the driver\ndefine ADL_ERR_NOT_SUPPORTED     -8\n```\nNot sure if we can do anything about it, besides ignoring the error.. Please retry with the beta versions (https://hashcat.net/beta), or compile the master branch from source.\nThis bug seems to be already fixed with the latest version.. This smells a lot like a faulty driver installation (OpenCL runtime, \"clGetDeviceIDs(): CL_DEVICE_NOT_FOUND\" wtf? It seems that not even \"clinfo\" works, right?).\nYeah, at least a gdb backtrack should be the very minimum, otherwise we do not even know where the crash occurs:\nmake clean\ngit pull\nmake DEBUG=1\ngdb --args hashcat -b -m 1000\nafter that type \"r\" to start the gdb run... after the crash occurs type \"bt\" (for backtrack). You can exit gdb by typing \"q\" and \"yes\".\nThanks. @Faiz009 it would be nice if you test both \"clinfo\" and give the gdb output. Otherwise, we don't even know about what problem we are talking about in here.. First, thank you for your contribution.\nPlease consider these (maybe seemingly unimportant) points for the future:\n1. give better names to the issue \"-m 2500 feature request\" and/or even \"hashcat\" within the title doesn't make much sense... the title should be something easily findable. Just name your problem/suggestion/feature request directly within the title: e.g. \"Output format for WPA should include the AP's MAC address\". Do you notice the difference? \"output format\" (or \"potfile format?) together with \"MAC\" address is something that we can find when searching for it in the future\n2. bug reports for hashcat-utils (or any separate project/repo) should not be mentioned between the lines here. There you go: https://github.com/hashcat/hashcat-utils/issues\n3. the same is true for feature requests (e.g. the change for possible values you are suggestion for the \"authenticated\" field)\n4. to fix the cap2hccapx problem you should also not forget to provide some examples and explain it in more details (but again, not here!)\nThanks\n. It seems that appveyor reports some errors related to these changes: https://ci.appveyor.com/project/jsteube/hashcat/build/1.0.211/job/po6xvvd8ootrkas0#L336 and https://ci.appveyor.com/project/jsteube/hashcat/build/1.0.211/job/6kay6311dhde3iie#L333\nI'm also wondering if we should change this \"_WIN64\" checks like this... I would prefer just adding the CYWIN support for now and discuss the macro problems (WIN32, WIN64, WIN etc) within a new issue/PR, or is my assumption wrong that the cygwin changes are/should be unrelated?. Hey @ZerBea,\nthank you for the report.\nCould I kindly ask you to share the .hccapx file with us (if you prefer privately), such that we can reproduce this.\nIt would be great if you also include all the commands that need to be run (step by step).\nBTW: I think @jsteube still expects an answer to the cap2hccapx problem (about the M1+M4 and M3+M4 problem mentioned here: https://github.com/hashcat/hashcat/issues/1113#issue-208649274 ), so please check your mail inbox ;). Thank you @LocutusOfBorg.\nAs you may have noticed, we did some further changes at the project's description, see: https://github.com/hashcat/hashcat/commit/d200b8493e30f25eaae441107f8d059c0f009a59\nMaybe you can do the same changes for the package description?\nThx\nupdate: hmm, the 200+ algo change might be only correct with the newest version... but the grammar correction should be applied already now to both (packages and README.md). From your output I can see that you are using an older revision (5ec763fa) and not the current one of hashcat (just to have the full picture the version update changes were made later: see 9b08d4af0fd92691779f3d624f2e071cdee914ca), use:\nmake clean\ngit pull\nmake\nto update to the newest version.\nBTW: you need to use the newest version of both hashcat and hashcat-utils. Since you use a dev version (the git version), it should be clear that many changes could be made each and every day without any announcement (since it's still a beta version). . Please be more specific, do you mean that your password is longer than the maximum supported password length (64 in your case?) ?\nsee https://hashcat.net/faq#what_is_the_maximum_supported_password_length for the maximum supported length of the password\nAlso, it seems that you are sometimes speaking about hmac-sha512 and sometimes about hmac-sha256... it's a little bit confusing.... and maybe your \"hash\" has the same problem.\nSee https://hashcat.net/wiki/example_hashes for example hashes for all hmac variants\nBTW: you always need to use hash:salt to the hash.txt file (depending on the hash type either the salt or the password is used as the hmac key). Note: for now (until next release if you really do not want to use upcomming beta versions or git versions), you could just work around this incorrect sanity check with the use of a mask file:\n$ cat a.hcmask \nefghijklmnop,?1?1?1\n$ hashcat --keyspace -a 3 a.hcmask\n144\nNote: it is not allowed to use .hcmask file with multiple lines in it whenever you use --keyspace. Therefore, this is just one possible dirty hack to trick hashcat to generate the keyspace value. You shouldn't get used to this mechanism, because devs might also decide to disable reading .hcmask completely whenever the --keyspace argument was used. So just use this dirty hack if you really need to and can't wait for the next release (or use git version/beta).. The current complete list of the codes is here: https://github.com/hashcat/hashcat/blob/89f8739ddeccd90ef60f0637cfa4a965f35e131a/include/types.h#L161-L171\nThe main problem is that not all of these values are valid status/exit codes (so there is that slight difference between status codes and \"device status\" value displayed in the machine readable output).\nMaybe @jsteube has an idea what we should do here: maybe a wiki section or a separate wiki page on hashcat.net should be sufficient to explain the values!?. Are you sure about the \"Line-length exception\" error?\nThat specific error would mean that the length of the line is not correct (it shouldn't matter if there is a = or an A at the end).\nPlease be more specific about the total length of the hashes, it should be 3 (signature) + 44 (hash + padding) = 47\nYou should only get a \"Line-length exception\" whenever the length is not 47. Can you please verify that?\nAfter we clarify that, we can double-check if the padding is correct (with \"=\" or not)...\nA (or preferably several) real-word example would be great, otherwise I can't really tell what is going on.\nThx. ah, see ?\nthis is a completely different error (at least when we look at what hashcat internally sees/reports)\nHash-length exception is different from Line-length exception\nNow the problem makes (just a little bit) more sense ;)\nwe need to investigate...\nThx. Well, I found some examples within the john the ripper code and it seems that you found an interesting bug that I can confirm with these examples: https://github.com/magnumripper/JohnTheRipper/blob/9737dea214b5e52e87fd5775acadc7839d0fcdee/src/FGT_fmt_plug.c#L78-L80\nSince -m 7000 = Fortigate (FortiOS) was ported from hashcat-legacy (and you also wrote/confirmed above that there is some inconsistency between input/output of hashes with hashcat-legacy)... we unfortunately also propagated that parsing/encoding/decoding bug to hashcat (see https://github.com/hashcat/hashcat-legacy/blob/master/src/engine.c#L2193).\nI have no clue, why this faulty code exists in hashcat-legacy, but I don't think it is worth patching hashcat-legacy... hashcat-legacy is kinda completely replaced by hashcat and we do not really change it a lot anymore.\nThank you and please test. No, this is the wrong place to ask question like this.\nThis is not a bug/issue at all (nor a feature request or anything related).\nThe answer was already given here: https://hashcat.net/forum/thread-6355-post-33892.html#pid33892\n . If you really want to know how it is generated, you should check the code (and take your time to understand it)... otherwise, you shouldn't bother at all about this checksum. There is no reason, why you should be that eager to force us to tell you bit-by-bit what this code does, do the reading yourself. There is absolutely no reason why you need to mess around with this checksums etc.. Again, this is not a hashcat issue... if you really want to implement some (external) wrapping code, then you should spend the time understanding how the checksum is generated.\nOtherwise, you could just use --show / --left / --remove options.. Nice find, I admit I missed that specific case when fixing #1153 . Yeah, it was kinda related.\nHopefully now we have covered all cases of custom charsets + command line switches.\nThanks. I think this is to be expected and normal behaviour. The GPUs didn't finish the huge set of password candidates earlier than @ 3.64%. If the checkpoint was not yet reached, the Checkpoint Quit feature can't terminate hashcat. The only way to stop earlier (and therefore have finer grained checkpoint goals) would be to have different/smaller -w (or -n/-u) settings, but this of course would also affect performance a lot.. This is an interesting report.\nThe problem is, that there are a lot of hashcat users out there that also use windows 10 and none of them reported problems like this recently (except the bug we found some weeks ago thanks to @d2-d2, but this was indeed a problem that was introduced with some refactoring and fixed very quickly).\nI've also done various testings with windows 10 (benchmarks, cracking jobs, I ran some tests etc)... but never experience any file permission problems. (note: I am normally a linux user, so I might not be the right guy for windows-specific stuff, but I was always able to start hashcat without any permission problems on windows).\nI therefore think that it's almost 100% a local issue and that the problem is not hashcat itself.\nYou should definitely do some more tests @alphastar868.\nI also do not understand why you use fat32. Is this an usb drive?\nMaybe the problem is due to the usb drive, some local permission problems (parent folders etc) or they are only affecting the way you extracted the archive or the GUI (3rd party tool!) is the culprit.\nThis are some test you should do to exclude that anything like this is part of the problem.\nSo I would suggest that (for these tests) you do not use fat32, you do not use external USB disks and that you download a fresh copy of hashcat from https://hashcat.net/hashcat and extract it with 7-Zip within a folder that you know is read/writable by your user (like C:\\users\\alphastar868\\Downloads\\hashcat\\ , replace alphastar868 with your windows user name) and try to run it with cmd.exe inside that particular folder.\nIt is also advisable that you first make sure that you can read/write files within C:\\users\\alphastar868\\Downloads\\hashcat\\ , so open something like notepad or notepad++ and try to write and read a file (e.g. test.txt).\nThanks. Could you also please post the full command you are using and the full output?\nDoes it also happen with something as simple as\nhashcat -b\n?\nDo you by any chance have a separate computer/notebook (preferably with similar setup, e.g. win 10 etc) to test if it happens there too ?\nAlso, you said that you only use cmd, right? Do you use additional terminals like mingw/cygwin/msys? Maybe it also has something to do with other programs you have installed or individual windows settings?\nIt could also be that the problem is not at all the read-only permission (those files/folders could also be just read-only, because hashcat only reads those files, it doesn't write to them), but the ownership (the user who can access/read them etc).\n. Please do not post bug reports if you use old versions of hashcat.\nhashcat 3.40 is the current release version. Please always use the latest versions (especially if you try to troubleshoot and/or report bugs).. I see 3 problems with this PR:\n1. why should we use the value 20 (hardcoded)? this doesn't make any sense to me\n2. why do you not increase the length within the  OUTFILE_FMT_CRACKPOS branch? The value should only be increased if that specific condition holds and therefore only if that branch was taken\n3. we should use snprintf () instead of sprintf () and check that we do not use more bytes than HCBUFSIZ_LARGE (this was not a problem with your PR, but we should fix this anyway)\nCan you please try to update your PR?\nthx\n\nupdate: forgot one important problem:\n4. we need to update docs/changes.txt too to mention the problem that versions <= 3.40 didn't work well with crackpos. For what regards docs/changes.txt, you just need to add something like this:\n\"- Fixed --outfile-format 11 up to --outfile-format 15: the crack position was not correctly outputted\"\nwithin the \"Bugs\" section:\n```\n\nBugs\n\n```\nFurthermore, I'm not sure if we really need this new numDigits () function (also: it should respect the coding standards, see README.md, e.g. num_digits () etc...), because snprintf already is able to tell us the number of bytes that are needed for the digits. That means, it is kind of useless to ignore the return value, but instead introduce a further function that does basically the same.\nThere is some further room of improvement that comes to my mind (but doesn't really affect only your PR): we shoud also make sure that whenever we do:\ntmp_buf[tmp_len] = 0;\nthat tmp_len is never greater or equal to HCBUFSIZ_LARGE, e.g something like this code should be used:\ntmp_len = MIN (tmp_len, HCBUFSIZ_LARGE - 1);\ntmp_buf[tmp_len] = 0;\nWhat do you think?\nBTW: thank you very much for your contributions, these are some great finds and fixes!. I don't understand this problem completely.\n--show should always be run independently form the actual cracking.\n--show/--left were designed to be used after your cracking job and not mix them up with the cracking itself.\nThere are basically always 2 steps involved (2-fold), like described here: https://hashcat.net/faq#how_can_i_show_previously_cracked_passwords_and_output_them_in_a_specific_format_eg_emailpassword\n--show/--left are just meant to be used after cracking to output the cracks (and if you want with a different --outfile-format)\nI don't know if this is just a missunderstanding from your side how --left/--show were designed or maybe I just didn't understand this \"issue\"!?. hashcat will output this line\nINFO: Removed x hashes found in potfile\nwhenever it has found some hashes within the potfile, but of course it won't print all the hashes again and again, each time.\nIf this is not enough information (just the number of hashes), then you need to start hashcat twice or have some other means to store the information externally that you need.\nI don't think that hashcat should change anything here, it works exactly as it was designed:\n1. crack only the hashes that are not yet cracked (whenever --show was not used)\n2. show all hashes that were cracked whenever --show was used (and show all hashes that were not cracked when --left was used). These commands should always be run independently, not in combination with the cracking job itself.. --show was always designed to only display what was already cracked (and the user can use different --outfile-format options to modify the output).\nMaybe it seems silly to you, but other users need exactly this option: e.g. display everything that was already cracked (and exit).\nBTW: it is very often the case that not 100% of the hashes are cracked, so --show would always need to start cracking and that is not what it should do (therefore the name \"show\", it only shows what was already cracked and exits).. To clarify things a little bit here: as far as I understood, this request is about a general change of the hccapx structure/format for this particular case:\n1. an external (3th party) tool could not (solely, or not at all!) rely on the replay counter because sometimes focusing only on the replay counter could fail (consider the case where M1 from the AP was captured ... after that a new M1 - the one that is needed! - was not captured, furthermore M2 - the response - was captured later on, in this case we could falsely ignore these sequence of good packets, even if replay counters do not match, but nonce-bruteforce would correct it)\n2. the external tool should be able to mark these messages such that the hccapx format knows if the replay counter was considered (and some filtering was done based on the replay counters of the messages from the AP and STA) or if it was ignored (and for instance only timestamps and the message order were considered for filtering)\n3. hashcat should, for the time being, just ignore the highest bit of the message_pair (bit 8), which could be used to indicate exactly this fact (replay counter ignored or not ignored)\n4. this additional bit could be used both for analysis/statistics, but also  (in the future) in some cases to trigger some further logic (e.g. related to nonce-bruteforce)\nCorrect?. Don't forget to suggest what should be an acceptable length in your opinion. Please discuss it here.... Wow, I would call this a really great example of a feature request description. Well done.\nSo, I already did all the preparation... host code (including parser etc).\nThis hash type should be ready soon (\"only\" OpenCL kernel missing).\nThx. Please provide more information:\n1. did you download hashcat from https://hashcat.net/ ?\n2. which version of hashcat do you use?\n3. how did you install the Nvidia GPU driver ?\n4. did you install the OpenCL ICD ?\netc. hashcat works on a byte-by-byte password length. Each position/char within your mask also determines the bytes that should be tried on that specific position.\nUnfortunately, this is exactly how encoding works (and yeah, sometimes encoding is a little bit counter-intuitive:\necho -n \u00e4 | xxd -p\nc3a4\n2 bytes -> a mask of length 2\nI don't think hashcat can and should do something here, because this is exactly how encoding works.\nIt's just a little bit confusing if users think their \"char is of length 1\" while it is not at all.. ISO-8859-1 is not the same as UTF8\nDifferent encoding also (could) imply different bytes (even for the same \"character\").\nThat's why the hex char 0xe4 in ISO-8859-1 and 0xc3a4 in UTF8 both represent the \"\u00e4\" character, but the hash of those bytes of course is different.. UTF8 encoding is the most common, straightforward to use and therefore there are no special charset files. You can always just convert the charset files with something like iconv (or similar software):\niconv -f ISO-8859-1 -t UTF-8 charsets/combined/German.hcchr > German-UTF8.hcchr\n... but keep in mind that different encoding could also imply different lengths for the same symbol/character, so you need to increase the mask length accordingly (or use --increment and a mask that is long enough).. 1. oclHashcat was superseded with just \"hashcat\" a long time ago (years!!!), please do not use oclHashcat (or at least do not use it if you want to report bugs)\n2. Kali linux unfortunately does everything wrong when it comes to packaging \"hashcat\", it uses completely incorrect dependencies etc\n3. you should first make sure that you have the correct OpenCL driver (and ICD) installed for your OpenCL devices, see the recommendations on https://hashcat.net, and after that download hashcat from https://hashcat.net/hashcat/ (version 3.40 or above)\n4. yeah, problems with drivers/setup/installations could result in \"crashes\", even if hashcat has nothing to do with them... the drivers might just not work correctly\n5. make sure that neither Mesa, nor pocl is installed (they often cause \"crashes\")\n6. if you want to debug something with hashcat, you need to compile it like this: make clean; git pull; make DEBUG=1; gdb --args hashcat -b\nMy guess is, that this has nothing to do with hashcat itself, it is just your installation that was not correctly configured/installed (including the hashcat version - always use the newest version - and the correct driver).\nBTW: it would also help a lot if you mention which OpenCL device(s) you have (the hardware) to reduce the amount of possible point of failures (at least a little bit). I think we should avoid having 2+ labels/names for the same algorithms. Therefore we should also change the names in https://github.com/hashcat/hashcat/blob/master/src/interface.c#L79-L302\nDo you agree?. What do you mean with this:\n-1 ?a?a?a?a?a\n?\n--custom-charset1 (or short -1) is used to define custom charsets.\nI think this is pebcak because you are mixing up custom charsets with masks. Can you please describe it a little bit better what needs to be done (in your opinion)?\nDo we need to make changes to the .hccapx structure (again)?\nDo we have this type of information somewhere ? I think the .cap file could know if the devices are using little/big endian, or? ... or do we always need to perform both, little and big endian brute-force?\nThx. This is not really a bug but just a known limitation (or let's call it optimization?).... and it has to do with how/when the final length of the password candidate is known and when it can be rejected... in most of the cases (with fast hashes) the final length is only known very late (when we speak about the GPU-based rule engine etc)... therefore the host can't really know the final length. Therefore every password from the dictionary that doesn't meet the min/max length will be rejected as soon as possible. This is true also for slow hashes.\nYou have 2 options:\n\nuse -j/-k (with single rules, not rule files!)\nuse a pipe and an external tool like e.g. from hashcat-utils (or hashcat itself, e.g. hashcat --stdout -a 6 dict.txt ?d?d?d?d | hashcat -m 2500 -a 0 -w 4 --status --status-timer 10 a.hccapx)\n\nBTW: this is a question that was answered dozens of times on the hashcat forum... please use the search function of the hashcat forum next time. it would be very great and helpful in the decision making if we discover some way on how .7z files like this can be generated (i.e. with a tool/archiver or sdk etc) and how wide-spread/rare they are. Maybe even more details like if the padding is really random or not... I'm just curious about why one tool/generator is using non-default padding (maybe it was even designed like this to circumvent cracking by jtr and hashcat, that would be funny or it has something to do with antivirus signature bypassing: \"let's use random bytes within the AES padding, such that the sha checksums are arbitrary for each malicious file\" etc)\nI agree, that especially with the standard cost of 2^19 of .7z, the final fast \"verify part\" (including aes+lzma+crc32) doesn't make much of a (speed) difference. . This looks more like -m 3710 than like 3910 (since the salt in your case should be prepended), furthermore as always we need more details like mentioned here: https://hashcat.net/faq#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\nIt would be interesting which software/cms etc uses this algorithm.\nFurthermore, this reminds me of this recent forum thread: https://hashcat.net/forum/thread-6558.html, where the algorithm turned out to not use just MD5(x) but a mix of raw MD5 and hex version of MD5 (e.g. only the final output was in hex).\nTherefore it is very important to get the algorithm details correct from the beginning, including max pass/salt length and hex/raw formats etc.\nAlso note: MD5($salt) is a very bad algorithm design, since this can be precomputed. I must admit that I was quite unmotivated when I saw this issue for the first time because I saw that the algorithm description by the OP uses genwallet (), privtopub () and therefore I thought about Elliptic-curves cryptography and whatnot.\nNow I just gave it another glance and it seems that all of this is not needed at all. The algorithm is very easy.\nsha3 (aes_256_cbc_decrypt (pbkdf2 ($pass, $pass, 2000), $iv, $encseed) . \"\\x02\")\nSo basically we just extract the first 16 bytes (0-15) from the \"encseed\" field which we use as the initialization vector (iv) for the AES-256-CBC decryption, the remaining bytes (starting from byte 16) we use as the encrypted seed.\nThe key for the AES-256-CBC decrytion is generated by using the user password as salt AND pass and use 2000 iterations of pbkdf2-hmac-sha256.\nThe final hash is just a sha3/keccak hash of the seed (the decrypted encseed from the AES decrytion mentioned above).\nTherefore the code is basically just this:\n```\n!/usr/bin/env perl\nAuthor: philsmd (for hashcat)\nDate: dec 2017\nLicense: CC0 (public domain)\nuse strict;\nuse warnings;\nuse Crypt::PBKDF2;\nuse Crypt::CBC;\nuse Digest::Keccak qw (keccak_256);\n\nAlgorithm can be found in: https://github.com/tagawa/website/blob/f784ca60be00ddd6fab9418307cb74289822f1eb/pyethtool/pyethtool.py#L53 (attention: the pbkdf2 settings are different, also the salt for pbkdf is different)\n\nAn example can be found here: https://github.com/hashcat/hashcat/issues/1279\n\nExample 1: (password is \"password\", without quotes):\n$ethereum$w0b2fa2c63a8b5603e1104fbada15a609aa9736ed41db1678d91a9b1a1f7c1628e711dbc250c4c289b06b0faa56cd499dc4af9daf878202db22cc61df1a91c918314c77ce92e5c8b1265580edd79a852acf40fe2138653ac16524c08247381d9802cf5ef3f8c4baf69fb869f2b7fb796bae853cfbdc3c5b788a14e75f39e0cf7df2e90779181a5dd45cce8e8df938af3c6b6c8a92ce123338e6ed87eb16ff11a02cd4a2a07aff8a3a57097fcf137501e07a941a7ce9bc19498252d98769125fbd2c9a14f1c56212a6bf2a7e374474c60e7a3a1cf443ce8194c4c960474472d6ca761ada075169fa8c7017bf1274b99df898deb65f51ed8eb29fbc0997d69c9800ad9b8351155bec5d8e7f73e7e2882a6e1b62883d0158c44fed8e4412fb18e75757e1355aaadd8a2dab50ae40c800d032dc77d3e84904085d628b5a13b60317d6f12ede26b7b38e7c6805bea1d2e11e3a7d7153b76ebfd99ae2536dfdd071ff8111a86fbd63e7b17155162263ef45471ac5b4c517520572cd19410cc4cbde77914fad12326fe5a4cbd5fc4a297740d6b5e64001196b0531e2464b7e4cee77136a38844b94dc59a9a72eec3ff49bca3d5bf0c29652ee6ff028e22f8936aac58fa3cf05ce4c8de8883204e43b57e4ebed922ad7b3a8953042033d34d7e94bc8ff393d1df4c8b062f5228b4f9dbc5d157af96772af1ef2c84f6562049b1c44f0359c07f193623a8b0f1b7e34b31481ddf54a24128e5a21b929f57fd07f8911ad8eb8d8bfe928ae9dfa2d35663764161094552a43b43a0a43dca687d4d04b79c8dbb2d4f87b7d8e0805a77adddfd5149741faa594009639fb730dccfbee1f99286aaf94052c06a1c68efc29dcd57a8b1a421ef9438b7121a15fd127ec0d8a72ee2b3e8da04a5a*74fdb879ece341dd590a769f2cd39d67\n\nmy $iv_and_encseed = pack (\"H*\", \"0b2fa2c63a8b5603e1104fbada15a609aa9736ed41db1678d91a9b1a1f7c1628e711dbc250c4c289b06b0faa56cd499dc4af9daf878202db22cc61df1a91c918314c77ce92e5c8b1265580edd79a852acf40fe2138653ac16524c08247381d9802cf5ef3f8c4baf69fb869f2b7fb796bae853cfbdc3c5b788a14e75f39e0cf7df2e90779181a5dd45cce8e8df938af3c6b6c8a92ce123338e6ed87eb16ff11a02cd4a2a07aff8a3a57097fcf137501e07a941a7ce9bc19498252d98769125fbd2c9a14f1c56212a6bf2a7e374474c60e7a3a1cf443ce8194c4c960474472d6ca761ada075169fa8c7017bf1274b99df898deb65f51ed8eb29fbc0997d69c9800ad9b8351155bec5d8e7f73e7e2882a6e1b62883d0158c44fed8e4412fb18e75757e1355aaadd8a2dab50ae40c800d032dc77d3e84904085d628b5a13b60317d6f12ede26b7b38e7c6805bea1d2e11e3a7d7153b76ebfd99ae2536dfdd071ff8111a86fbd63e7b17155162263ef45471ac5b4c517520572cd19410cc4cbde77914fad12326fe5a4cbd5fc4a297740d6b5e64001196b0531e2464b7e4cee77136a38844b94dc59a9a72eec3ff49bca3d5bf0c29652ee6ff028e22f8936aac58fa3cf05ce4c8de8883204e43b57e4ebed922ad7b3a8953042033d34d7e94bc8ff393d1df4c8b062f5228b4f9dbc5d157af96772af1ef2c84f6562049b1c44f0359c07f193623a8b0f1b7e34b31481ddf54a24128e5a21b929f57fd07f8911ad8eb8d8bfe928ae9dfa2d35663764161094552a43b43a0a43dca687d4d04b79c8dbb2d4f87b7d8e0805a77adddfd5149741faa594009639fb730dccfbee1f99286aaf94052c06a1c68efc29dcd57a8b1a421e\");\nmy $bkp = pack (\"H*\", \"74fdb879ece341dd590a769f2cd39d67\");\n\nStart:\n\nget the initialization vector for AES-256-CBC from the \"encseed\" field:\nmy $iv = substr ($iv_and_encseed, 0, 16);\nget the raw encrypted seed (encseed):\nmy $encseed = substr ($iv_and_encseed, 16);\nsetup pbkdf2 params:\nmy $pbkdf2 = Crypt::PBKDF2->new\n(\n  hasher     => Crypt::PBKDF2->hasher_from_algorithm ('HMACSHA2', 256),\n  iterations => 2000,\n  output_len => 16\n);\nmain loop:\nwhile (my $pass = <>)\n{\n  chomp ($pass);\nmy $key = $pbkdf2->PBKDF2 ($pass, $pass);\nmy $aes_cbc = Crypt::CBC->new ({\n    key         => $key,\n    cipher      => \"Crypt::Rijndael\",\n    iv          => $iv,\n    literal_key => 1,\n    header      => \"none\",\n    keysize     => 16\n  });\nmy $seed = $aes_cbc->decrypt ($encseed);\nmy $hash = keccak_256 ($seed. \"\\x02\");\nif (substr ($hash, 0, 16) eq $bkp)\n  {\n    print \"Password found: '$pass'\\n\";\nexit (0);\n\n}\n}\nexit (1);\n```\nAs you can see the algorithm is basically the same as -m 15600 = Ethereum Wallet, PBKDF2-HMAC-SHA256  (I say the same as -m 15600 because also 15600 uses a large number of iteration of pbkdf2 and a final keccak hashing step)... except that we need to AES decrypt the encseed field (with AES-256-CBC) to get the raw seed.\nI was suprised that this algorithm is actually so easy, because from the description above it seemed to me that much more was involved here... but as said it is basically just the same as -m 15600 (with an additional AES decrypt step and slightly different settings for pbkdf2).\nI think that this is really easy to add, not sure why nobody added it yet (maybe others were also confused about all this genwallet and pubtopriv stuff which is not used at all ... or it is just not that common to have these presale hashes anymore because they were just used for a very short time). Can anybody find out what the length of the seed normally is?\nI see that john the ripper has example hashes with 64-16 bytes seed and 624-16 bytes of seed (the 16 bytes are used for the initialization vector):\nhttps://github.com/magnumripper/JohnTheRipper/blob/4f7824e3e05120c9eb6735844f36867431997f6f/src/ethereum_common_plug.c#L25-L28\nOther source code files mention that it is a sha256 () hash over some entropy data:\nhttps://github.com/ethereum/pyethsaletool/blob/6fe7254d7109e7677c5fcafb7873cacff9d0e2a5/pyethsaletool.py#L213\nhttps://github.com/vbuterin/pybitcointools/blob/aeb0a2bbb8bbfe421432d776c649650eaeb882a5/bitcoin/main.py#L416\nI'm not sure which software generates the longer seed.\nWhat software do/did you use and what is/was the length of the seed? Is it of fixed length? Is it 608 bytes (624-16) long or just 48 bytes (64-16) long?\nIt's okay if you do not know the raw seed, it's enough if we know the normal length of the encseed (encrypted seed).. @branmcf yeah, thanks for the confirmation. That's also what I saw what most modern software for ethereum generates.... it seems that some time ago the encseed was much shorter, e.g. 128 hex chars (64 bytes)\nIt shouldn't matter too much because hashcat now supports all these lengths for the encseed decryption.\nAgain, you could just extract the \"hash\" from the json file with ethereum2john.py (and remove the file names and colons if any are present) and run it with -m 16300 with hashcat (betas are already up on https://hashcat.net/beta). @anormore\nHey,\nI don't think this is the right place to discuss how to get hashcat working.\nI would suggest that you go to https://hashcat.net/forum and https://hashcat.net/faq and https://hashcat.net/wiki/ to try to understand how you setup hashcat correctly.\nIt's not a good idea to start a discussion here on how to get hashcat working with hash mode -m 16300 to crack the presale ethereum wallets. This is a github issue (feature request) with the goal to implement this new algorithm in hashcat.\nAnyways, to get you started:\n1. for now you need to use the beta from (https://hashcat.net/beta)\n2. you need to install your OpenCL drivers correctly (for OpenCL CPU or OpenCL GPUs)\n3. you need to extract the beta version with 7-Zip\n4. you need to download ethereum2john.py from https://raw.githubusercontent.com/magnumripper/JohnTheRipper/bleeding-jumbo/run/ethereum2john.py .\n5. you need to install python2.7 (and setup the PATH environment variable under windows to get python working within cmd)\n6. run this command: python ethereum2john.py my_wallet.json\n7. you need to copy the output of ethereum2john.py to a file (e.g. hash.txt), make sure there are no file names within the hash. The hash should look similar to the one that you can find here: https://hashcat.net/wiki/example_hashes (search for 16300)\n8. you need to run hashcat something like this: hashcat -m 16300 -a 0 -w 3 hash.txt dict.txt\n  . \nCould you please perform a further test for us (just to double-check some of our most recent disoveries):\n```\nmake clean\ngit checkout 52c1e15f3f5b0f50c8ccce3b8b9c604941fe8a57\nmake\nhashcat -m 2500 -b\nnote down the speed1\n```\nand:\n```\nmake clean\ngit checkout 56dc8ae3598b059b9a7fe11859ebbec087d6cfab\nmake\nhashcat -m 2500 -b\nnote down the speed2\n```\nand finally:\nmake clean\ngit checkout master\nmake\nplease let us know about the speed1 and speed2 results. I fully agree with neheb. This is very annoying/confusing.\nFortunately, I remember that github user name \"emwinkler\" from this other github issue https://github.com/hashcat/hashcat/issues/1497 where I recently posted a comment.\nThe problem is, that you should always explicitly state what you are doing and why you are posting this benchmarks etc (my guess is that because I suspected that the other issue was a duplicate of this github issue, see https://github.com/hashcat/hashcat/issues/1497#issuecomment-362835124).\n... the context/explanation/description why you post a \"few benchmark numbers\" is very important... It's not always easy to keep track which user is affected by a (speed drop) problem and to guess why he is commenting/posting across different tickets.... so even I, who asked for this \"test\" in the other issue, was confused at the beginning and had to double check if the github user is the same across those 2 issues etc (and why s/he is posting this here).\nFurthermore, github allows you to use quoting/code markdown formatting... this would make all your post much more readable and understandable (otherwise it's difficult to see where the benchmark results start and where your description text is etc... it's just annoying extra work to see what is going on without the correct markdown formatting).\nIt seems at least for @emwinkler the 2 issues have the same root (unfortunately the original poster of #1497 , @guru431, is not the same github user and therefore it is just a guess that the s/he will have the same outcome/problem). I currently suspect that #1497 is a duplicate of this issue and that the speed drop was introduced by this commit 165380c454c80b3bcd428ba619a45893223585d0 but only on macOS AMD hardware (which is kind of strange and which should be investigated in detail).\nMaybe we can find someone, @emwinkler you ?, that helps us to interactively debug this problem for instance by running some tests together and chatting on the #hashcat IRC channel on freenode, because currently as far as I know not a single dev has a similar setup (macOS AMD hardware etc). That would probably help a lot. hmm, @soxrok2212 you should try the exact same version of hashcat that you used for your previous benchmark. Otherwise there could be too many factors that could influence the speed (besides new operating system, new driver ... also the changes for hashcat 4.1.0 etc).\n@emwinkler and/or @soxrok2212 could help us a lot by connecting to the freenode IRC channel and querying \"atom\" or me (\"philsmd\"). I think we can dig deeper to find the culprit. Again, I think it has to do with https://github.com/hashcat/hashcat/commit/165380c454c80b3bcd428ba619a45893223585d0 and especially the changes in the _loop kernel function (e.g. sha1_transform_V () vs sha1_transform_vector ()). With an enourmous help from @soxrok2212 we found out a couple of hours ago that also -m 12000 = PBKDF2-HMAC-SHA1 is affected by the same speed drop problem as -m 2500 = WPA/WPA2 (only with these AMD drivers/cards on macOS).\nMaybe someone here can confirm this too and test if the speed was changed a lot around the commit 729c5f09bcd00c3a6e51387d152346c609525e9d (would also help a lot if we found out if the commit that introduced the problem was exactly at 729c5f09bcd00c3a6e51387d152346c609525e9d or some commits slightly before/after that commit).\nMaybe we should close the duplicate issues and rename the title of this issue to make it PBKDF2-HMAC-SHA1 specific ?\nCould it help to extend our search to even more algorithms by comparing a larger set of hash types (maybe 2 full benchmarks before and after those WPA/PBKDF2 commits)?. update:\nwe identified and fixed the -m 12000 problem with this fix: https://github.com/hashcat/hashcat/commit/5391edca0d639f5dc330463b9505b7b8c1e4d063 (this change was the first to introduce the drop for -m 12000: 9de1e557bbf5172b60dbecfa22a45a29e562140d)\nThis \"sha1 problem\" was also affecting -m 2500 , but -m 2500 also seems to have heavily dropped in speed after this commit was merged: 165380c454c80b3bcd428ba619a45893223585d0 .\nWe currently suspect that the problem has to do with the fact that the macOS AMD driver (or OpenCL implementation) does not implement  amd_bytealign () and therefore the speed for instance of switch_buffer_by_offset_carry_be_S () is very slow). The driver does not report the device as \"AMD\" device the vendor id / platform is \"Apple\" and therefore hashcat sees it as a generic OpenCL device (which seems to be correct, because otherwise, i.e. if we mark it as AMD device, among others the amd_bytealign ()  function would be called, which is not available/implemented on macOS AMD systems).\nI think we still need to perform some further tests if we can somehow improve or work around the switch_buffer_by_offset_carry_be_S () problem.\nNote: switch_buffer_by_offset_carry_be_S () was not used with older version of hashcat for -m 2500, since older versions did not support very long passwords.\nThanks you again @soxrok2212 and @emwinkler for helping us to identify these problems. I think there is still a chance that we can somehow find a workaround... but it might require several further try-and-error-style tests.. Hmm, does a patch like the following fix the problem?\n```\ndiff --git a/OpenCL/inc_hash_sha1.cl b/OpenCL/inc_hash_sha1.cl\nindex 8caa33d..80b430e 100644\n--- a/OpenCL/inc_hash_sha1.cl\n+++ b/OpenCL/inc_hash_sha1.cl\n@@ -208,7 +208,9 @@ DECLSPEC void sha1_update_64 (sha1_ctx_t *ctx, u32 w0[4], u32 w1[4], u32 w2[4],\n     u32 c2[4] = { 0 };\n     u32 c3[4] = { 0 };\n\n\nifndef SKIP_SWITCH_BUFFER_WITH_CARRY\nswitch_buffer_by_offset_carry_be_S (w0, w1, w2, w3, c0, c1, c2, c3, pos);\n\n\nendif\nctx->w0[0] |= w0[0];\n ctx->w0[1] |= w0[1];\ndiff --git a/OpenCL/inc_hash_sha256.cl b/OpenCL/inc_hash_sha256.cl\nindex 49e1070..5375b9d 100644\n--- a/OpenCL/inc_hash_sha256.cl\n+++ b/OpenCL/inc_hash_sha256.cl\n@@ -193,7 +193,9 @@ DECLSPEC void sha256_update_64 (sha256_ctx_t *ctx, u32 w0[4], u32 w1[4], u32 w2[\n u32 c2[4] = { 0 };\n u32 c3[4] = { 0 };\n\n\nifndef SKIP_SWITCH_BUFFER_WITH_CARRY\n switch_buffer_by_offset_carry_be_S (w0, w1, w2, w3, c0, c1, c2, c3, pos);\n\n\n\nendif\nctx->w0[0] |= w0[0];\n ctx->w0[1] |= w0[1];\ndiff --git a/OpenCL/m02500.cl b/OpenCL/m02500.cl\nindex 468da9b..ee71042 100644\n--- a/OpenCL/m02500.cl\n+++ b/OpenCL/m02500.cl\n@@ -5,6 +5,8 @@\n\n\n#define NEW_SIMD_CODE\n+#define SKIP_SWITCH_BUFFER_WITH_CARRY\n+\n #include \"inc_vendor.cl\"\n #include \"inc_hash_constants.h\"\n #include \"inc_hash_functions.cl\"\n```\nTo test this:\n\nmake sure that you have a clean/unmodified version of hashcat\ncheck out the current master (git checkout 72fc708042a8b09900a1083f4333e14496d8ec28)\nstore the above code into a file called wpa.diff\nrun: \"make clean\" (just to make sure there are no cached kernel files)\nrun: \"git apply wpa.diff\"\nrun: \"make\"\ntest speed: hashcat -m 2500 -b\ntest if it still cracks: hashcat -m 2500 -a 3 hashcat.hccapx hashcat?s\n\n(hashcat.hccapx can be downloaded form the examle hashes page: https://hashcat.net/wiki/example_hashes)\nThx . It should be actually very easy to find out if other OpenCL tools work with your setup... e.g. just run \"clinfo\" and see if it works.\nIf neither hashcat nor clinfo works, it's very likely that your setup is not configured correctly (or in this specific case that wayland doesn't work correctly together with the drivers of your graphics card). My guess is that it's not really hashcat-related, but please test it.\nThx. dev note: it seems that the chdir () is somehow overridden at some point in time.\nMy guess is that the problem has to do that the original folder path is only stored at the very beginning here: https://github.com/hashcat/hashcat/blob/418341b5859cbd27ae5d6d536a5c8caad805b402/src/folder.c#L488 , after that with --restore the current working directory could be overridden here: https://github.com/hashcat/hashcat/blob/8abd7ae9d1b378485a750725927bdcf0ea334da8/src/restore.c#L137 ... but the problem might be that we use folder_config->cwd (and do not set/override it correctly when restoring with --restore) to change back to the \"original\" folder here: change from this folder https://github.com/hashcat/hashcat/blob/b847bbb2743f9e117e1db0f0288c8e427a36cd9e/src/opencl.c#L4161 back to https://github.com/hashcat/hashcat/blob/b847bbb2743f9e117e1db0f0288c8e427a36cd9e/src/opencl.c#L4738-L4740\nThis is just a guess, we need to verify this.\nIf true there might be 2 solutions: either always update folder_config->cwd when using --restore or always use getcwd () and do not rely on folder_config->cwd when using the chdir () function.. Hey @extended11 ,\nas you can see the above fix was merged and should solve the problem.\nCould you please test and close the issue if the problem is fixed?\nThank you very much. Oh! Ha!\nUnfortunately, one does not simply write optimized kernel code by just running something like sed 's/sha1/sha256/g'\nHint: there are also different input/output lengths e.g. for the hex conversation etc. To make it very clear, sha256 hashes/digests \"are longer\" compared to sha1 hashes... this is just an example what is completely wrong in your kernels.\nYou are also missing a lot of host code changes, like entries in src/usage.c etc, please look at previous commits which did add a new hash type to hashcat to see what is required.\n... and before I forget it (and actually the most important thing!): thank you very much for your contribution!!!. Could you give more details about:\n1. your shared folder settings and/or src/Makefile changes\n2. where the correct /OpenCL/ path is located (from your output above we can see that hashcat is trying to search for /usr/bin/OpenCL/ but that path doesn't exist)\n3. my assumption also is that you use \"make install\" or something similar. Is that assumption correct?\nI think this new problem has to do with this recent change https://github.com/hashcat/hashcat/commit/344d1a37dfe3ce4ed751b5f0d68fde4aa93221de , but this has to be verified.\nThe double free problem might come from the fact that the folder_config and pidfile_ctx are not set to NULL and therefore after the freeing of the original folder_config/pidfile_ctx the error will force a return, but since hashcat_session_destroy () (https://github.com/hashcat/hashcat/blob/4b2f3011e91e4aec7f3b088ed8167f664a902bca/src/main.c#L1059) will call folder_config_destroy () again and the pointer is not NULL, it will try to free () the folder_config a second time. This has to be double-checked and debugged.\nAs you might already know, the output you posted above is kind of useless if it comes to debugging, we need the output of a debug version of hashcat e.g. compiled with \"make clean && make DEBUG=1 && make install\" (again I'm not sure if you used the \"install\" target). Without the debug symbols, we do not know where the crash occurs exactly.\n... but again, this is not the actual problem (this is just a result of a problem with the correct paths). The root of the problem (the main problem) is the incorrect path. The side effect (and actually a second problem) is that hashcat tries to free it one more time (maybe because not reset to NULL?). the problem is that the define for the shared folder: -DSHARED_FOLDER=\\\"$(SHARED_FOLDER)\\\"\nis only applied to the compilation of src/main.c and not to src/restore.c\nhttps://github.com/hashcat/hashcat/blob/66f7590883bf96f39aef74213a5e6e3bab58adef/src/Makefile#L392-L393\nThis is the actual problem and to fix it we either need to use the defines for all .c files (or at least for main.c AND restore.c) or we somehow pass is from main.c to restore.c (within the source code and therefore without the macros/defines).\nThe other bug we found by accident is that shared_dir, profile_dir, session_dir might all point to the same memory buffer here:\nhttps://github.com/hashcat/hashcat/blob/4b2f3011e91e4aec7f3b088ed8167f664a902bca/src/folder.c#L393-L395\nand if the first one is getting deleted, we can't delete it again and again (double/tripple free):\nhttps://github.com/hashcat/hashcat/blob/4b2f3011e91e4aec7f3b088ed8167f664a902bca/src/folder.c#L437-L440\nSo we now know the 2 sources of the 2 distinct problems. Now we need to find a clean solution for both. Yeah, not dirty if possible.\nThx. Well, it wasn't merged yet. You should wait until both commits are merged and retry it afterwards.\nIf it still works after the 2 commits were merged, please report back and close the github issue if fixed.\nThx. dev note:\nit seems that we are ignoring the return code (for instance) here (but there are more places within the code where the return code after the overflow detection must be checked):\nhttps://github.com/hashcat/hashcat/blob/08fc0ec1fb404f1c3685f8984e169ed749a0bb03/src/hashcat.c#L120\nWe need to investigate what should be done in such a situation (e.g. clean buffers and proceed with the next \"iteration\").. I think the problem is that in very, very, very rare situations the password could start with $HEX[ and end with ] (and have only hex characters in between, the length must be a multiple of 2).\nIf this is the case, hashcat converts the $HEX[] string into the raw string. Sometimes this could not be wanted, therefore @roycewilliams suggested that we add a new flag to turn off this automatically conversion of $HEX[] strings within the word list.\nmy suggestion is to introduce a new flag called something like --wordlist-autohex-disable to disable the automatical conversion of $HEX[] strings whenever the words from the word lists are read in. The --stdout option neither needs the hash type nor the hash list:\n$ ./hc -a 0 -r bug.rule --stdout words.dic. maybe you had pulled/cloned the repo some time ago and didn't use \"make clean\".\nYou could also try to use the beta (https://hashcat.net/beta/) to see if the problem also happens with pre-compiled code (the beta binaries).. Thank you very much.\nI've updated the FAQ page (https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_is_a_potfile) according to your suggestions.\nI know that it could be easier if the wiki is somehow editable... but at the end it's not a big problem because even if it would be editable the amount of change request is not that high and therefore reporting it here or on the hashcat forum worked so far. I'm not against an editable wiki. I just think it is not currently possible with the mediawiki system that is in use (and if it was editable we would probably need to fight spam or malicious change requests etc).\nIf you think it was correctly fixed, please do not forget to close the issue.\nThank you very much. We need much more details to understand this problem.\nFor instance, what operating system do you use? What type of prompt/shell do you use? cmd.exe?\nWhat version of hashcat do you use?\nWhich GPUs do you have? Which driver do you have installed? How did you install the driver? Did you install the drivers cleanly, downloads from amd.com/nvidia.com?\netc, etc. Does it behave similar to the problem reported here: https://hashcat.net/forum/thread-6202-post-35411.html#pid35411 ? Does the problem only happen if the intel opencl driver is installed?\nDoes it also happen if you do not use putty (or do not remotely connect to the computer)?. If I'm not totally mistaken, there was some guy on the hashcat's IRC channel #hashcat that recently said that by deleting 1 of the files shipped by the intel package, he was able to still use the Intel OpenCL and AMD/Nvidia OpenCL devices without the problem with the non-interacting hashcat process.\nUnfortunately, I can't remember what file it was and how difficult it was to get it working.\nThe problem is that this seems to have nothing to do with hashcat and we can't do anything to fix it. It's a problem of the Intel driver.\nMaybe you can try to troubleshoot it and come up with a howto tutorial on how to fix it (even with working Intel CPUs)?\nI'm not sure what is going on with the driver and why it makes the hashcat process non-interactive.\nI can't think that it is hashcat's fault since it works flawlessly with all other setups.\nI'm not sure if it makes sense to keep this issue open... but a howto/tutorial on forum etc would be nice if we can find out how to fix it (while keeping the Intel OpenCL driver working and Intel CPUs useable).\nIt's not even clear if it only happens with Intel + AMD or if it is a general problem with Intel driver (but I also have the Intel OpenCL drivers installed on some systems and never experienced any problems with it, so there must be some combination of installed drivers that trigger this problem).. Thanks @roycewilliams for the relevant log line...\nUnfortuately, that sounds worse than I remembered: I thought it was working with both Intel/AMD after the user removed some files (but from the quote above it seems that the Intel driver wasn't working anymore i.e. \"without the driver ofcourse\")... Therefore, this \"fix\" is actually not better than removing the Intel OpenCL driver completely.\nI'm pretty sure there must be some culprit and some (hashcat-external) fix. Again, I don't think that this is hashcat's fault or that hashcat can do anything about it.. What's the version of hashcat that you use?\nWhat's your command line parameters?\nDid you try with other attack types? Did you try with different masks etc?\nBTW: some users make the mistake to use something like \"./hashcat -m 1000 hash -a 3 hashcat\"\nbut they forget that whenever there is a file called \"hashcat\" in this particular directory, the mask will be seen as a mask file\nFurthermore, newest versions of hashcat (beta, see https://hashcat.net/beta/) have self-tests enabled and therefore you will see a warning whenever there is a problem with the kernels (false negatives) etc. Hey,\nit is explained here https://hashcat.net/wiki/?id=mask_attack#hashcat_mask_files:\nIt is not allowed that a [mask] contains ?1,?2,?3 or ?4 references without those being set via [?1], [?2], [?3], [?4]. This will result in an error message. If you want to use a custom charset for your masks you must define it within the same line of the hcmask file by using the [?1], [?2], [?3], [?4] fields.\nThis means that you need to define the custom charset directly within the .hcmask file (only if you use  at least one out of ?1 ?2 ?3 ?4 within your mask).\nThis was actually recently changed (in the past it also worked with the custom charset defined on the command line) because users forgot to set the customer charset within the .hcmask line and where confused why hashcat uses \"a different custom charset\" etc... Furthermore, previous versions also used the \"default charsets\" whenever no charsets were defined and this made it even more confusing for the user which couldn't figure out what was going on.\nI think this change makes sense... the only problem is: whenever the user wants to use a set of (up to 4) custom charset for each and every mask within the .hcmask file... then the .hcmask file must be prepended with the same custom charsets on each and every line (but I guess this is a good compromise and doesn't make anything slower or something like this... it is just much more easier to troubleshoot and understand).\nso your mymask.hcmask file must look like this:\n-_.,?d?d?d?d?l?1\n-_.,?d?d?d?1?l?d\nand your command line must look like this:\n./hashcat64.bin -m 0 -a 7 --outfile results.txt --status mymask.hcmask mywordlist.txt\n. Glad it works for you now too (with the correct syntax).\nPlease do not forget to close the issue if you are sure the problem is fixed/resolved (only the repo owner or the OP can close github issues here).. your hash works perfectly fine if I put \"haha866:1b711e4b87c9a950d02594c4e7ff7ca5:|y<\" (without quotes) within a file hash.txt and use the command:\n./hashcat64.bin -m 2611 -a 0 --username hash.txt rockyou.txt\nto output the results in username:plain format, you can use this command:\n./hashcat64.bin -m 2611 --show --outfile-format 2 --username hash.txt\nTherefore, the single hash works... maybe you have a hash file that consist of several different hash types etc... so you need to clean it and find out which hashes are using -m 2611 and which hashes do not etc\nhashcat won't/can't do that job for you... the input must be correct. If it is not correct, you will see a warning.\nBTW: it's not a good idea to make 2 forum posts and one github issue about the exact same problem:  https://hashcat.net/forum/thread-6877.html , https://hashcat.net/forum/thread-6873-post-36693.html#pid36693 and https://github.com/hashcat/hashcat/issues/1362 . This type of eager behaviour actually should be punished (forum ban?) and you should be glad that nevertheless someone took there precious free time to answer you at all... don't be a d*ck.. As the wiki section that you linked already explains, to display all cracks with the corresponding username you need to run 2 commands (one after the other):\n1. crack with --username\n2. --show --username\nThe first one saves the results (cracks) to hashcat.potfile and the second one uses the hashcat.potfile and looks for all hashes that are present in both your original hash file and the pot file and combines it with the usernames.\nYou could try to use the beta (https://hashcat.net/beta/) which has different limits for -m 2611/2711.\nAt this point... I don't think that this problem is a code issue at all. You just need to read the wiki/forum and other resources to learn how to use hashcat correctly.\nThe github issues here are for code issues, not user questions.\nI would therefore say that you/we should close the issue here.\nThx. this is a duplicate of #69 . let's step back a little bit and discuss this:\ncan you please explain why you really need more output?\n20 bytes should be long enough to make sure that the password is indeed the correct one. From that perspective there is no need to have a longer output length.\nThe only valid reason for a longer output would be if you need to re-use the longer-than-20-byte output for further computation at later steps.\nSo what exactly is you reason you need to have longer output ? Do you need to do further computation with the output?\nI think this discussion is not really suitable here. This is not a hashcat issue. It might fit in the Developer section of the hashcat.net forum. I don't think this is a problem of hashcat. This is just a general question. It is not a hashcat issue.. When you see this prompt:\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nyou should press the key \"c\" (without quotes) and your status (to see it press \"s\", without quotes) should change to \nStatus...........: Running (Checkpoint Quit requested)\nafter that you need to wait until the next checkpoint was reached (could take some time depending on your attack type and number of hashes etc).\nBTW: this is not the correct place to ask questions. Github issues are only intended for problems/feature requests/development stuff. Please close the issue and (if you really can't figure it out at all with all the documentation wiki/faq/hashcat forums) you can open a new thread on the hashcat forum. Thx. This is confusing. We already have a hccalloc () function.. I think this problem was solved by using the --opencl-device-types (short -D) command line parameter.\n@globbergouhl can you please close the issue if you think this problem is solved?. could it be that this patch introduces some memory leaks?\nWhenever we use asprintf () we also should free () the buffer afterwards.\nThe problem only happens when there were buffers on the stack beforehand (where the buffers automatically wen't out of scope and therefore deleted) and now we use asprintf which uses the heap (where we do need to make sure to call free ()).. It should be easy to replace the:\n-r, --regexp-extended     use extended regular expressions in the script.\nwe currently use with a different regular expression for sed that does not need the \"-r\" option. are you sure that this old CPU (Core Duo) even supports OpenCL ?\nIt seems that the drivers do support only i3 or newer (or xeon CPUs).\nhttps://stackoverflow.com/questions/16647567/opencl-sdk-for-intel-core-2-due/16650270#16650270. This problem might be related to the recent patch for this issue: https://github.com/hashcat/hashcat/issues/1403\nThe patch was successfully tested on a mac mini.\nIt's also interesting to note that the format of the \"VERSION_EXPORT\" variable did change which would make this sed command behave incorrectly.\nThe replace from the \"git archive\" for version 3.6 was:\nVERSION_EXPORT          := tag: v3.6.0, refs/pull/1273/head\nwhile the format for the new source tar.gz is:\nVERSION_EXPORT          := HEAD -> master, tag: v4.0.0\nTherefore the sed which is looking for \"v\" + some numbers (and dots) + \",\" is not correct anymore.. reverting c6d7fc8 is not an option, because we do not want to have the hard coded \"4.0.0-rc6\" within the Makefile. My conclusion is, that since we have no more a tag like this:\n\": v4.0.0,\"\nbut only this substring:\n\": v4.0.0\"\n(without the comma \",\", and the tag information could be at the end)\n... my suggestion is that we replace this:\nsed 's/.*: v\\([\\.0-9]*\\),.*/v\\1/'\nby\nsed 's/.*: v\\([\\.0-9]*\\).*/v\\1/'\n(no comma needed). @ilovezfs could you please test with the newest git version? The above commit #1430 should fix the parallel build problem.\nThx. With which version of hashcat did you try it?\nHashcat 4.0 supports a length of up to 256 characters.\nThe hash file needs to contain hash:salt i.e\nhexhash:#XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX-\nIt's working perfectly fine here with a little test:\n$ cat hash.txt\n5f4cdf48b7579100ac9e0fe6ffe73ebf85b99200181033d371151cefab72190a:#12345678-1234-1234-1234-123456789abc-\n$ ./hashcat -m 1420 -a 3 hash.txt ?lashcat\n5f4cdf48b7579100ac9e0fe6ffe73ebf85b99200181033d371151cefab72190a:#12345678-1234-1234-1234-123456789abc-:hashcat. This is not an error, but just a notice/hint. It means, whenever you are trying to use optimized kernels (with the -O option) and the kernel itself only comes with one variant (instead of both: optimized and also a specialized kernel supporting lengths > 31 or > 55), it will display this hint/warning. It's not an error message.\nYou could just look at the OpenCL/ folder if there are many files starting with OpenCL/m02500* it means that there are 2 variants of the kernel (and therefore using -O and not using -O makes a difference).\nBTW:\n< sarcasm >\nthis seems to be a high quality issue: very appropriate, easy to find and clever title and an issue description that already speaks for itselfs and includes already the answer to the question\n< /sarcasm > I'm just kidding, ;)\nBut, jokes apart, maybe (\"noob\") questions like this shouldn't be posted on github since devs could use the time they spent to answer such question with more challenging and important things, like solving really important issues/bugs and/or implementing new hash types or features.\ndon't get me wrong... it's not only you that asks some very basic things like this on github... and it's totally fine to better ask to be sure. I can see your point of view too!!!\n...it's also a little bit annoying that for instance I can't close this issue right now. The current permission system only allows you (the original poster, OP), or the owner (atom, jsteube) to close this issue.\nSo we either need to wait that you close it or ask a further person to spent some time here, just to close the issue. I stop my rant here ;)\nHave a nice day.. Can you please explain with some descriptive text what the problem is that you are experiencing?\nIt's not clear from the title/picture what kind of problem you have.\nThx. Can you please tell us which version of hashcat you use? It should be at least 4.0 . Hey\nthanks for the report.\nI've suggested a fix here: https://github.com/hashcat/hashcat/pull/1436\nBTW: always make sure that whenever you report a problem with example hashes, that the passwords are also mentioned (especially in this case where one would need to have the hash:pass combination within the file hashcat.potfile) . I'm clever/experienced enough to work around this problem, by either generating a similar hash for which I know the password and/or just writting a wrong hash:pass combination into the hashcat.potfile (this works, because hashcat doesn't validate that the \"crack\" is correct, since it assumes that whatever is in the hashcat.potfile is always correct. It would be a waste of resources to crack/validate the hashes in the potfile again and again).\nFurthermore, we are not willing (or always able in a short amount of time) to crack the user's/reporter's hashes. In short, do not forget to post the password too in the future. Otherwise we might even need to assume that you do not know the password and just report a problem such that others crack hashes for you (this happened a lot in the past, I'm not saying that this is the case here, but other people are trying to trick people like this)\nThank you very much\nBest. I did some very quick research on this (I hope that everything mentioned below is correct, feel free to independently verify it and correct me):\nThis feature is also called (also internally in the keepass sources etc) as WUA = Windows User Account.\nThe main setting file of keepass (.xml) stores this setting as\n<UserAccount>true</UserAccount>\nSome information about WUA is also mentioned here https://keepass.info/help/base/keys.html#winuser and there you can find links to https://sourceforge.net/p/keepass/wiki/Recover%20Windows%20User%20Account%20Credentials/\nThe concept of this protected data is also known as the Data Protection application programming interface (DPAPI).\nWindows saves the WUA Master Key(s) here:\nWUA Master Key: %APPDATA%\\Microsoft\\Protect\\<SID>\\  (the long file, not the \"Preferred\" file)\nwhere %APPDATA% is just\n%APPDATA%: C:\\Users\\<username>\\AppData\\Roaming\\\nThe keepass specific ProtectedData (DPAPI) blob is stored in this file:\n%APPDATA%\\KeePass\\ProtectedUserKey.bin\nIf we look at the keepass source code, we can find a KeePassLib/Keys/KcpUserAccount.cs file that is responsible to write and read the ProtectedUserKey.bin.\nTo generate the data (if the file did not exist yet), it uses the following steps:\n- generate a 64-byte long byte array by using CryptoRandom.Instance.GetRandomBytes(64)\n- and use the windows API ProtectedData.Protect () (see https://msdn.microsoft.com/en-us/library/2fh8203k(v=vs.110).aspx) with the constant entropy (16 bytes):\nde135b5f18a34670b2572429698898e6\nMy conclusion is that what we need to do to add support for it is to have the 64-bytes of data from ProtectedData.Unprotect () somewhere within the hash (or command line option). These 64 bytes need to be appended to the sha256 ($pass) + keyfile (optional)\nIt seems the order is\n1. sha256 ($pass)\n2. 32 bytes for the keyfile settings (optional)\n3. 64 bytes unprotected-data for the WUA settings (optional)\nbtw: there seems to be also a new jtr issue with the same request of implementing this WUA feature: see https://github.com/magnumripper/JohnTheRipper/issues/2863\n\nupdate: I was interested enough to give this seemingly minor modification that needs to be done a try and here are some more info and code:\nI generateted a new Keepass Database (with newest Keepass 2.37, but the version shouldn't matter to much for now, it just should be at least 2.x I think).\nAfter selecting the \"User Account\" option when creating a new database, the %APPDATA%\\KeePass\\ folder containing the ProtectedUserKey.bin was created.\nThe content of the file in hex was in my case (this of course depends on the computer/user account, it's always different for a new account, it remains the same if you \"just\" change your windows password): \n01000000d08c9ddf0115d1118c7a00c04fc297eb010000000fdf04152eb77d41ae7573c264a446ba00000000020000000000106600000001000020000000d742af90ddc4428fd29e4d1a9d2611d47df223bad79a84413477978293d03c4e000000000e80000000020000200000005cb8caeb15d68fcda00637526d4584750776126af1d3847d5bb8c5e9da3839bd50000000171fa403753833691a362044609babb936d4be81dfa463e1fc292681a71db38e7d21394b13865aa40e6f91d3f73b468cb0fc968baacfaf7fb8267906c32a2a517296618cbf07c8f8db88c65c7fb52dba400000003bc90d6acde4fe764103d4d03bb087266b2bdb182d1e59442505ac60450fcdf1a78305d42f63df18ed8ea7a504c805becb38f6f0024bafb3a90a29e9b154b4b2\nI've used this code to convert it to the unprotected version:\n```#include \ninclude \ninclude \ndefine MY_ENCODING_TYPE  (PKCS_7_ASN_ENCODING | X509_ASN_ENCODING)\nint main ()\n{\n  DATA_BLOB DataIn;\n  DataIn.pbData = (BYTE *) \"\\x01\\x00\\x00\\x00\\xd0\\x8c\\x9d\\xdf\\x01\\x15\\xd1\\x11\\x8c\\x7a\\x00\\xc0\\x4f\\xc2\\x97\\xeb\\x01\\x00\\x00\\x00\\x0f\\xdf\\x04\\x15\\x2e\\xb7\\x7d\\x41\\xae\\x75\\x73\\xc2\\x64\\xa4\\x46\\xba\\x00\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x00\\x00\\x10\\x66\\x00\\x00\\x00\\x01\\x00\\x00\\x20\\x00\\x00\\x00\\xd7\\x42\\xaf\\x90\\xdd\\xc4\\x42\\x8f\\xd2\\x9e\\x4d\\x1a\\x9d\\x26\\x11\\xd4\\x7d\\xf2\\x23\\xba\\xd7\\x9a\\x84\\x41\\x34\\x77\\x97\\x82\\x93\\xd0\\x3c\\x4e\\x00\\x00\\x00\\x00\\x0e\\x80\\x00\\x00\\x00\\x02\\x00\\x00\\x20\\x00\\x00\\x00\\x5c\\xb8\\xca\\xeb\\x15\\xd6\\x8f\\xcd\\xa0\\x06\\x37\\x52\\x6d\\x45\\x84\\x75\\x07\\x76\\x12\\x6a\\xf1\\xd3\\x84\\x7d\\x5b\\xb8\\xc5\\xe9\\xda\\x38\\x39\\xbd\\x50\\x00\\x00\\x00\\x17\\x1f\\xa4\\x03\\x75\\x38\\x33\\x69\\x1a\\x36\\x20\\x44\\x60\\x9b\\xab\\xb9\\x36\\xd4\\xbe\\x81\\xdf\\xa4\\x63\\xe1\\xfc\\x29\\x26\\x81\\xa7\\x1d\\xb3\\x8e\\x7d\\x21\\x39\\x4b\\x13\\x86\\x5a\\xa4\\x0e\\x6f\\x91\\xd3\\xf7\\x3b\\x46\\x8c\\xb0\\xfc\\x96\\x8b\\xaa\\xcf\\xaf\\x7f\\xb8\\x26\\x79\\x06\\xc3\\x2a\\x2a\\x51\\x72\\x96\\x61\\x8c\\xbf\\x07\\xc8\\xf8\\xdb\\x88\\xc6\\x5c\\x7f\\xb5\\x2d\\xba\\x40\\x00\\x00\\x00\\x3b\\xc9\\x0d\\x6a\\xcd\\xe4\\xfe\\x76\\x41\\x03\\xd4\\xd0\\x3b\\xb0\\x87\\x26\\x6b\\x2b\\xdb\\x18\\x2d\\x1e\\x59\\x44\\x25\\x05\\xac\\x60\\x45\\x0f\\xcd\\xf1\\xa7\\x83\\x05\\xd4\\x2f\\x63\\xdf\\x18\\xed\\x8e\\xa7\\xa5\\x04\\xc8\\x05\\xbe\\xcb\\x38\\xf6\\xf0\\x02\\x4b\\xaf\\xb3\\xa9\\x0a\\x29\\xe9\\xb1\\x54\\xb4\\xb2\"  \"\\x00\";\n  DataIn.cbData = 294;\nDATA_BLOB entropy;\n  entropy.pbData = (BYTE *) \"\\xde\\x13\\x5b\\x5f\\x18\\xa3\\x46\\x70\\xb2\\x57\\x24\\x29\\x69\\x88\\x98\\xe6\"  \"\\x00\";\n  entropy.cbData = 16;\nDATA_BLOB DataOut;\n  LPWSTR pDescrOut = NULL;\nif (CryptUnprotectData (&DataIn, &pDescrOut, &entropy, NULL, NULL, 0, &DataOut))\n  {\n    // printf (\"The description of the data was: %S\\n\", pDescrOut);\nprintf (\"The decrypted data length is: %i\\n\", DataOut.cbData);\n\nprintf (\"The decrypted data is: \");\n\nunsigned int i = 0;\n\nfor (i = 0; i < DataOut.cbData; i++)\n{\n  printf (\"%02x\", DataOut.pbData[i]);\n}\n\nprintf (\"\\n\");\n\n}\n  else\n  {\n    fprintf (stderr, \"An error while decrypting the data. \\n\");\n  }\nreturn 0;\n}\nI compiled it like this:\nx86_64-w64-mingw32-g++ -m64 protected_data_unprotect.cpp -o protected_data_unprotect.exe -lcrypt32\n```\nNote: this program needs to be run on the correct windows computer where the DPAPI master key file etc is used to unprotect the content. Also note that DataIn.pbData could easily be read from a file (I just didn't bother too much to add the code for opening/reading the file for now). Furthermore, entropy.pbData seems to be constant/static and doesn't need to be changed. The user only needs to modify DataIn.pbData (or someone could add the code to read these bytes from the ProtectedUserKey.bin file).\nRunning the  protected_data_unprotect.exe program yielded this for me (this of course also depends on your data and windows account, it's different from you, but the length should be always 64):\nThe decrypted data length is: 64\nThe decrypted data is: 591674cc5fb167aa5f9e55c0a96cd66fadeb02366215d731364b19603a36b3b779c6e3b9dbf3027fd34c074b4c15c4a6efaf172933afd46dcaf2e6f9d911fcfc\nThis seems to be all what we need, i.e. the additional 64 bytes (unprotected version of the bytes from ProtectedUserKey.bin).\nI tested to crack my database with keepass2john + hashcat.\nThe current patch (that was successfully applied to this version fddb66eb1be99ea6cf2a01dfc1928a0e2de12437) is:\nhttps://gist.github.com/philsmd/36a38c1527293da3fb4848c3ef1d0aa9\nthere are a couple of todos for now:\n1. the protected_data_len needs to be read from the host code (it somehow needs to depend on the hash)\n2. the data after this if statement:  if (protected_data_len > 0) of course also needs to be dynamic and supplied by the user (and past by the host code)\nfor now this is just a POC and those TODOs need to be implemented by choosing a new hash format and implementing the modified parser (and passing the data to the GPU)\nI have these 2 hashes for you to test (I used keepass2john to convert the databases, both Databases used the same ProtectedUserKey.bin and therefore my patch with the currently hard-coded 64-bytes work for both):\n1. with \"Windows User Account\" setting but without keyfile (password is \"hashcat\", without quotes):\n$keepass$*2*60000*0*a4f18d89fe227b96fd435aa4da26d856b1a3f7951a85fd6350730bb84e8b6113*fbce34b2a9f882d27f02a16afd6e02133ca3681903715766e92e4738a2ca2341*10fd77ccb982b386ba91b52063d5bd22*657adcda06deb085367c6705d68f072156082ec8aefddfedce8501b44e1f9c5b*e7a2bc6acbd0c20945fffce5ff70c8f41e77eb3c5987cad431db69d0bc24bd9b\n2. with \"Windows User Account\" setting and with keyfile (password is \"hashcat!\", without quotes):\n$keepass$*2*60000*0*5e96fa939c3ca427c6afca68c865aebb3c98f5ea1c7e1e87e94c2042b7ed6376*2e1769b64f582de6252bd901975a19e59056275e4c79f3f14883f1e3fb90fa27*d2a38c754f6eff1fcdb667a967cf5fd5*25c76ba25e65e367597c98418c49cf66a10204c528f43a316b34fca5de896684*fe57adc05093db6c4d63c7923738e893c1e36d2dcfe04a95449e954180bce0e9*1*64*74eb49f8ec2e021d17b6b6a032cdb19e6f11c1acff670c232bfd53be9c07c94f\nboth crack perfectly fine.\nThis means it's actually very easy to add support for it.\nThe only bummers for now are:\n1. keepass2john needs to be modified to support reading the ProtectedUserKey.bin file and generate a different hash with these additional 64 bytes\n2. the unprotected data from ProtectedUserKey.bin needs, as said, be extracted on the actual machine it was first generated (and also with the correct user account that was used while the database was generated). This of course implies that in case of a hard disk failure you have to get back access to all this information (the WUA master key and the ProtectedUserKey.bin file). Just the access to the file  ProtectedUserKey.bin doesn't mean that you can somehow unprotect it. You also need to have the window's WUA master key.\n3. It doesn't seem that we can figure out from just the .kdbx file whether WUA was used or not. This means that you either have the original %APPDATA%/KeePass/KeePass.config.xml where this information could be recovered (because the default/last options are stored for convenience), or you need to test all combinations: pass, pass+keyfile, pass+WUA, pass+keyfile+WUA\nThx. Here is a slightly modified version of the extraction c++ file that uses the %APPDATA% environment variable and reads the file ProtectedUserKey.bin directly (using stat/fopen/fread/fclose):\n```\ninclude \ninclude \ninclude \ninclude \ndefine MY_ENCODING_TYPE  (PKCS_7_ASN_ENCODING | X509_ASN_ENCODING)\nint main ()\n{\n  char *appdata = getenv (\"APPDATA\");\nchar file_name[2049];\nsnprintf (file_name, 2049, \"%s\\Keepass\\ProtectedUserKey.bin\", appdata);\nstruct stat st;\nif (stat (file_name, &st) != 0)\n  {\n    fprintf (stderr, \"ERROR: Could not determine the file size of the file '%s'. Does the file exist?\\n\", file_name);\nexit (1);\n\n}\nsize_t file_size = st.st_size;\nFILE *fh = fopen (file_name, \"rb\");\nif (fh == NULL)\n  {\n    fprintf (stderr, \"ERROR: Could not open the file '%s'\\n\", file_name);\nexit (1);\n\n}\nBYTE file_content[file_size + 1];\nif (fread (file_content, 1, file_size, fh) != file_size)\n  {\n    fprintf (stderr, \"ERROR: Could not read %i bytes from file '%s'\\n\", file_size, file_name);\nfclose (fh);\n\nexit (1);\n\n}\nfclose (fh);\nDATA_BLOB DataIn;\n  DataIn.pbData = file_content;\n  DataIn.cbData = file_size;\nDATA_BLOB entropy;\n  entropy.pbData = (BYTE *) \"\\xde\\x13\\x5b\\x5f\\x18\\xa3\\x46\\x70\\xb2\\x57\\x24\\x29\\x69\\x88\\x98\\xe6\";\n  entropy.cbData = 16;\nDATA_BLOB DataOut;\n  LPWSTR pDescrOut = NULL;\nif (CryptUnprotectData (&DataIn, &pDescrOut, &entropy, NULL, NULL, 0, &DataOut))\n  {\n    // printf (\"The description of the data was: %S\\n\", pDescrOut);\nprintf (\"The decrypted data length is: %i\\n\", DataOut.cbData);\n\nprintf (\"The decrypted data is: \");\n\nunsigned int i = 0;\n\nfor (i = 0; i < DataOut.cbData; i++)\n{\n  printf (\"%02x\", DataOut.pbData[i]);\n}\n\nprintf (\"\\n\");\n\n}\n  else\n  {\n    fprintf (stderr, \"An error occurred while decrypting the data. \\n\");\n  }\nreturn 0;\n}\n```. Very good.\nI think that to make any progress here we need to ask @magnumripper / @kholia (and also CC: @Fist0urs ) what we should do about the hash format changes that are needed and what they plan to do to support this in jtr etc.\nOf course we could just invent a new hash format with 64 bytes added (64 bytes longer than the normal format), but I think it is a good idea to see if keepass2john will be changed in the future to support this and also to generate the new hash format etc.\nThe algorithm and kernel/code modification should be clear from the examples above. The extraction of the 64 bytes should also be no problem with the code provided above. It's now just a matter of when/if this will be supported also by keepass2john and if so are there several different types of hashes or just one hash format that contains the 64 bytes (or not if wua is not used etc).\nI think hashcat could adapt its parser to the output of keepass2john quite easily (if it changes in the future).\nThis jtr issue might be good to follow too since it might be re-opened in the future (we will see): https://github.com/magnumripper/JohnTheRipper/issues/2555. yes we could just add the 64 bytes.\nUnfortunately there are many variants possible:\n1. pass\n2. pass+keyfile\n3. pass+wua\n4. pass+keyfile+wua\nso maybe we should add an additional field at the end (always or just when wua is being used).\nIn theory we could differentiate if the additional data is for keyfile or for wua just depending on the length (keyfile are always 32 bytes, while wua always uses 64 bytes).\nWe could also think about always printing all fields or not ... or somehow add an identifier such that it is clear if the data is from the keyfile or from the unprotected data file.\nAn additional question is, does keepass2john plan to add both support for:\n1. adding the 64 bytes via a command line option (--wua 64-hex-bytes-here)\n2. using something like the source code above to automatically unprotect the data (if the user is using the machine were the protected data was generated).\nI think both cases would somehow make sense because without case number 2 the user might not know how to extract the data (if he didn't read the steps/examples above).\nAn additional problem would be that you only would be able to compile this code (case 2) on a windows machine or with some cross-compiler (mingw on linux) and of course it will only run on windows systems. Therefore case 2 is just for .exe files I think.. That's great.\nI just realized I didn't answer your question about the additional 64 bytes and if they can be seen as a longer keyfile. Yes this is absolutely true! We could think about it like this if we consider the cases above:\n1. pass  => 0 bytes\n2. pass+keyfile => 32 bytes\n3. pass+wua => 64 bytes\n4. pass+keyfile+wua => 32+64 = 96 bytes\nSo in theory for the crackers it doesn't matter if the additional data comes from a keyfile of from wua. The crackers just need to support 0 to 96 bytes (at the time of writing this, maybe this will be increased in the future, but I don't think anytime soon), possible values are 0, 32, 64 or 96 bytes for the additional data.. Unfortunately, the output you posted doesn't really help to troubleshoot this. We need to know what happened and where exactly it crashed, only having the stack pointer (sp), instruction pointer (ip) etc doesn't help much to see what happened.\nThe problem is that it could also be very independent from hashcat itself, i.e. it could be an ASIC hang a crash within the driver code (all external from hashcat) etc\nYes, a full run build with make DEBUG=1, maybe even with backtrack (but this would require running it with gdb), would help to see what happened here.. Is this a duplicate of https://github.com/hashcat/hashcat/issues/411 ?. you could just use -m 4700 = sha1(md5($pass)) and append the salt with rules etc. This of course only works sufficiently if the hash list is small (ideally only one hash is used).\nIf you really want that this new hashing algorithm gets implemented you need to provide much more information.\nImportant information that is required would be: where is this hash type used in? are there any limitations of salt length/password length etc. Hey\nThanks for the report\nI can confirm and reproduce this. It doesn't seem that the actual content (the hexadecimal characters within $HEX[]) has something to do with it. It happens all the time when $HEX[] is used within the potfile.\nThis problem might have to do with this recent patch https://github.com/hashcat/hashcat/commit/a4616e6c6d2b69aa4e4c39f6bccc339eea9a8655\nThe above patch fixed the situation that whenever the actual plain was using \"$HEX[\" and ending with \"]\" we had to hexify it.\nWell, for --show it is different because we do not apply this logic again (e.g. we do not need to hex $HEX[] passwords, because the potfile already has the correct version). We do not need to modify it at all when using --show.\nI think a special case must be added when using --show or (this needs to be tested) skip need_hexify () completely whenever the user used --show (because in theory the potfile handling/writing already hexified it, if needed).\nThanks again.. This is a known \"feature\". If you want to use shorter words mangled with rules, you should use this:\nhashcat --stdout -r rule.txt dict.txt | hashcat -m 2500 -a 0 hashes.hccapx. Hey,\nThank you very much for the report.\nThis patch is of course acceptable and seems to solve the problem reported on the hashcat forum: https://hashcat.net/forum/thread-7013.html\nI found a problem that could lead to random crashes when applying this patch. But this patch itself isn't responsible for the random crashes.\nI've investigated it a little bit and it seems that we need to increase the following buffers to allow cracking longer hashes:\n1) https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/include/types.h#L1931 (because copied here: https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/src/event.c#L50)\n2) https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/src/hashes.c#L1556 (because copied here: https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/src/outfile.c#L433)\n3) and finally the temp buffer for the out_buf: https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/src/hashes.c#L1562\nHCBUFSIZ_LARGE is currently \"only\" 20480 bytes large (see https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/include/common.h#L107) while for -m 11600 we need a hash buffer that is more than 655056 bytes large (see https://github.com/hashcat/hashcat/blob/c8819e6e8b2f1d82fb4dd22a98002886912fd0db/include/interface.h#L1211)\nHCBUFSIZ_TINY is of course even less than HCBUFSIZ_LARGE, therefore we might need to change char old_buf[MAX_OLD_EVENTS][HCBUFSIZ_TINY]; to use HCBUFSIZ_LARGE and increase HCBUFSIZ_LARGE?\nIt would make sense to fix this reason for possible crashes first and afterwards apply this patch.\nThx. @neheb thank you very much for the suggestion. The problem here is that scrypt is one of the GPU unfriendliest algorithm currenlty supported by hashcat.\nIt could make sense to run -m 15700 with a very fast CPU with OpenCL support. The problem mainly is memory usage with very high cost factors (yes, this has also to do with tmto).\nEven on a 1080ti (one of the best GPUs on the market) this hashing algorithm is kinda difficult to run. This doesn't depend much on hashcat, but on the algorithm itself. It is designed to be GPU unfriendly and those high cost factors make it even worse.. can't reproduce. Can you give more details about your system.\nIs this an apple system?\nWhat type of OpenCL device (CPU/GPU) and which make/model do you use?. Are there any other strange characters within the path?\nTry to download a fresh copy directly to C:\\ and extract it there such that you have this folder:\nC:\\hashcat-4.0.1\\OpenCL. Do you have any Intel CPU OpenCL driver installed?\nWhat does you setup look like (GPU / CPU)?\nWe saw some similar behaviour with intel drivers and AMD systems.\nI think the problem there was that whenever the Intel OpenCL driver was installed hashcat was not interactive anymore (no key presses where registered etc).\nIf you have the Intel OpenCL driver installed, please try to use only your GPU driver (if possible) and therefore uninstall the Intel OpenCL driver for testing this.\nThanks. good that this problem was kind of resolved.\nPlease note that only you - the original reporter OP - (or the project owner) can close issues.\nCould you please close the issue if you think that the problem is solved. thx . 1. uninstall mesa\n2. uninstall pocl (if both mesa and pocl were already pre-installed and you use Kali linux, make sure that you switch to a different operating system that makes it easier to work with OpenCL/hashcat, like ubuntu)\n3. make sure that the correct driver is installed from nvidia.com (as recommended on https://hashcat.net/hashcat)\n4. use hccapx for -m 2500 = WPA/WPA2 , the hccap file format is superseded since ages\n5. do not report user problems here. use the FAQ (https://hashcat.net/faq/ ) the wiki (https://hashcat.net/wiki/) and the forum search (https://hashcat.net/forum/) instead\n6. close this issue since it doesn't report a bug/problem or requests a new feature/algorithm\nIssues here are meant for development and bugs, not for problems where the user didn't install the drivers as recommended (https://hashcat.net/faq#i_may_have_the_wrong_driver_installed_what_should_i_do). Sorry, what do you want to do with android? cracking on a android device?\nI don't think that is a good idea if we think about the battery, the temperature issues, OpenCL support etc. Which cpu do you have?\nDo you also have a GPU (graphics card) which would be much faster? Intel GPUs are not recommended, use an modern Nvidia or AMD GPU\nThe drivers for the Intel CPU runtime can be found here: https://software.intel.com/en-us/articles/opencl-drivers#latest_CPU_runtime. You should use --opencl-device-types 1 (or short -D 1) to crack with your CPU.\nYour GPU has not enough resources (mainly the huge amount of VRAM memory needed for scrypt) to crack ethereum scrypt hashes (-m 15700 = Ethereum Wallet, Scrypt) . no an upgrade of the RAM (system volatile memory) doesn't help much if you want to use your GPUs. The VRAM (GPU memory) is much more important.\nThe hashing algorithm scrypt with those very high costs/settings is known to be GPU-unfriendly. I'm not totally sure if a 1080ti has enough VRAM to be able to run -m 15700 (fast enough). Everything below a 1080ti (which has 11GB, but only part of that can be used by OpenCL... but there is even a nice workaround that hashcat uses with multiple memory allocations) is probably not able to run -m 15700, I guess. Again, I'm not sure if a 1080ti (is able to run -m 15700 fast enough and) is much faster for -m 15700 as a modern high-end CPU.\nWhat also matters a lot are the cost settings for scrypt (but as far as I know for -m 15700 they are mostly the same for all hashes and .... very high settings)... therefore scrypt with a specific set of settings could be very different compared to scrypt with much higher cost settings.\nIt's actually not too difficult to calculate the memory needed for a specific set of settings (in general).... but since hashcat is able to do multiple allocation and also supports tmto (Time Memory Trade Off) it's actually a little bit more complicated to do the math... again, scrypt is known to use a lot of memory and is known to be GPU-unfriendly by design. As said, you could try with a GPU with much more memory (like the nvidia 1080ti), it won't show you the resource error, but it's probably only slightly faster than a modern (high-end) CPU... because it still needs to use a high tmto value and make multiple allocation.... these problems are not present with high-end CPUs.\nBut I've tested with a 1080ti and it runs -m 15700 just fine... so either you use at GPU with at least the memory available also for a 1080ti... or just crack with a very good CPU (and avoid high tmto and multiple memory allocation altogether).\nI think you should close this issue because it is not a hashcat problem/bug. This is just problem with your setup (very low amount of memory on your GPU).\n  . I don't see any problem of hashcat here, but...\n1. you should not crack with a laptop\n2. mobile GPUs are known to be slower, or at least that they do not reach the same speed as their non-mobile equivalent (even if their name is similar)\n3. you need to use -w 4 to reach maximum speed\n4. your laptop won't support that much heat/work and will risk to burn/damage\n5. it also matters a lot what type of attack you use (and what your input is, e.g. large-enough dictionary file with rules, large-enough mask etc)... Performance could be slower if you don't supply enough work to your GPUs. I think this problem was already discussed here: https://hashcat.net/forum/thread-7197.html\nThe main reason for this problem and a solution was also provided.\nPlease close this issue. The first \"problem\" is probably just a misunderstanding: if you combine 2 dicts with -a 1 and both use the same file path, then each and every line/password from the first dictionary will be combined with each and every line from the second dictionary and since the files are the same the words will also be combined with themselves.\nTherefore the full combinations basically are:\n11111111111111111111111111 (26 characters) + 11111111111111111111111111 (26 characters)\n111111111111111111111111111111111 (33 characters) + 11111111111111111111111111 (26 characters)\n11111111111111111111111111 (26 characters) + 111111111111111111111111111111111 (33 characters)\n111111111111111111111111111111111 (33 characters) + 111111111111111111111111111111111 (33 characters)\nand therefore: 26+26=52, 33+26=59, 26+33=59, 33+33=66 \nTherefore your statement about \"But 26 + 33 = 59, 59 != 52\" is not valid, since whenever hashcat makes all combinations of all passwords also the combination 26+26 = 52 will be tested.\nTherefore problem 1 is not a problem but just a misunderstanding.\nTo avoid that hashcat combines each and every word you could just create 2 distinct dictionary files (say dictionary_1.txt and dictionary_2.txt and combine those two dictionaries with -a 1).\nThe second problem is a little bit more difficult to understand and \"fix\" and I agree that it shouldn't be in the output like it currently is. The plain does not match the hash. I think that the GPU cracks it anyways and the host code won't output hashes with -O that are larger than 31 characters... therefore it probably will be truncated... This seems to be a bug and should be investigated. thx. Are we actually sure that this is not the same problem reported here: #1290 ?\n@emwinkler can you please make the test mentioned here: https://github.com/hashcat/hashcat/issues/1290#issuecomment-338306987\n. why is there no -a 3 within your command ?\nWhy do you use increment (-i) ? does the problem only happen if you use -i ?\nPlease try again with the correct length, with -i removed from the command and with -a 3 added to the command. The error message from your output says:\n/home/ubuntu/hashcat/hashcat.hcstat2: No such file or directory\nplease make sure that the hcstat2 file exists . If you have a working clone of the repository it should exist. The file in question is https://github.com/hashcat/hashcat/blob/master/hashcat.hcstat2  (but of course you should not just download the single file. but try to fix your installation problem).. Can you please describe the problem that you are experiencing ? What do you think is wrong?\nYou are using -m 2501 (1 iteration)... if you want to use the non-PMK version with 4k iterations you need to use -m 2500 instead. . That speed difference (between PMK and non-PMK, i.e. 2501 vs 2500), as said, is perfectly what we would expect. The ratio/factor is exactly the 4096 iterations i.e. the 2501 does not have the heavy _loop kernel function of 4k iterations.\nAgain, the speed (especially of 2500) is not what a R9 395 would normally achieve with a good driver... but that discussion is already taking place here: https://github.com/hashcat/hashcat/issues/1290\nI would suggest that we should close this issue, because it seems to be just a misunderstanding about the PMK-variant i.e. the fact that 2501 should be a factor of 4096 faster than 2500.\nThx. You probably need to install the library and headers of the iconv package first (libiconv etc).. under cygwin the package is called \"libiconv-devel\". Thanks for confirming that the problem was fixed.\nPlease do not forget to close the issue if the problem is fixed (since only you and the repository owner can do so).\nThx. salted hashes, like md5 ($salt.$pass) should be cracked with the correct hash type.\nHashcat supports:\n-m 20 = md5 ($salt.$pass)\nThe hash must be specified like this:\nhash:salt\ne.g. 8743b52063cd84097a65d1633f5c74f5:hash\n(since the characters \"hash\" form the salt in your case)\nsee https://hashcat.net/wiki/doku.php?id=example_hashes\nThe command to run would be \n./hashcat64 -m 20 -a 3 -w 3 -O --status 8743b52063cd84097a65d1633f5c74f5:hash  ?a?a?a?a?a?a?a?a\nalso do not forget to -w 3 or -w 4 if you want to achieve maximum speed.\nPlease do not forget to close the issue if the problem was fixed with these instructions. Try to use the hashcat's forum search function and use the forum for questions like this. Github is used for development purposes and to fix real bugs and implement new features.\nThx. some further problems: marvok is probably a typo for markov\nthe command line parameter is --markov-hcstat (2 dashes at the beginning)\nSome of the .hcstat2 files (as atom already mentioned) are not within the hcstat2s folder.\nAnother question is, should we add a note also within the docs/ folder? Or only use the docs/ folder for the documentation and use the hcstat2s folder for the compressed hcstat2 files only ? I'm not sure about this. Maybe we should use a considtent way for adding these extra files. This doesn't really depend on this PR, but maybe to make it more consistent we should also add README files to the rules, charset and masks folders too?\nAnother observation I made is that the files are about 14 MB (already compressed)... is this an acceptable grow in total file size of the release, @jsteube ? If needed we could maybe only pick the best ones !?. This could be a duplicate of https://github.com/hashcat/hashcat/issues/1290 and https://github.com/hashcat/hashcat/issues/1497 . For both issues the current impression is that the driver is just very bad on macos, not supporting byte_align () and furthermore doing weird optimizations that lead to bad speed while the non-macos drivers (windows/linux) have no propblem with the identical kernel code.. I do not have the same hardware but it should be easy to test if the same problems occur with these tests:\nhttps://github.com/hashcat/hashcat/issues/1290#issuecomment-338306987\nhttps://github.com/hashcat/hashcat/issues/1290#issuecomment-367243381\nIf the problem is the same as mentioned within the 2 other issues, it should be easy for you to find out and see why. Hint: the new feature of supporting password lengths of > 31 (or 55) bytes/characters lead to the introduction of new kernel functions. There was basically no performance loss with good drivers but for macos drivers without byte_align support etc, there seems to be a problem (and therefore the 2 other issues are still open and help/testers are wanted with this specific hardware... but if this is a duplicate, we probably should close it, because we do not need 3 github issues for the same problem).. It should be needless to say that whenever you use the git version (or use the git command) you need to use the git version.\nTo use the source code from git/github you need to clone the repo with this command:\ngit clone https://github.com/hashcat/hashcat\nyou also need to enter the newly created hashcat directory and fetch the submodules/dependencies:\ncd hashcat\ngit submodule update --init\nall of these setup instructions are mentioned within BUILD.md. To me it seems to be the exact same problem (because the same patches fix the speed problem also for you)\nThis issue should be marked as a duplicate and closed. The discussion about a possibe fix can continue here: https://github.com/hashcat/hashcat/issues/1290. Only the progress (and restore point value, dict position, mask position etc) will be larger if you restore a session.\nThe time started value will always indicate the time when this specific process started, it will not continue growing across runs. It's just the current value not the total amount of time.\nbtw. it is easy to calculate the total time because it should always be linear. so for instance if  you know that 10% are done in 5 hours you also know that 100% are done in 50 hours.\nThis is just how it was designed and it's not really a problem/bug in my opinion. . maybe a temperature issue?\nDid you try with lower workload/performance settings, e.g. with -w 1 ?\nIs this a macbook/notebook?. At least for older versions of skype (I didn't verify if this is still the case, probably yes) there was a hash stored within a config.xml file.\nRead some details here: https://web.archive.org/web/20161217080113/http://insecurety.net/?p=427\nBTW: you should use the forum for discussions like this. github is only used to request new features and report bugs/problems. Thx. I think that the only way something like this could work is a mechanism similar to the dictstat file (for wordlists): hashcat could remember that it already parsed and sorted these set of hashes and have some file timestamps to make sure that the files didn't change in the meantime. It could even dump the sorted (prepared) hash list to a separate file on disk and pick it up if the user uses the same hash list again and again.\nI don't think that hashcat could trust the user that it sorted the hash list correctly and that it wasn't changed afterwards :(  Therefore it needs to be done by hashcat and verified.\nThe disadvantage of this is that in the worse case hashcat would need to store at least a file as large as the original hash file (+ some metadata, like timestamps etc).. I assume that this involves elliptic curve cryptography that needs to be done on GPU ? not sure if something like this is easy to implement (feasible?)\nI'm also not sure how often it happens that you exactly know all the mnemonic words, but just do not know the optional password. I think this is kind of a rare situation (for the time being).. it's not clear what you mean by refresh.\nIf you are using the --status command line argument, you could just set the --status-timer to the number of seconds for your preferred interval. If you do not use --status, hashcat does not automatically refresh at all (you need to hit the s key on your keyboard or enter).\nQuestions like this should go to the hashcat forum (you can even use the search function and find some similar questions and answers). Is this request the same (a duplicate) of this: https://github.com/hashcat/hashcat/issues/1538 ?. The general format should be something like this:\n$sip$*[URI_SERVER]*[URI_CLIENT]*[USERNAME]*[REALM]*[METHOD]*[URI_PREFIX]*[URI_RESOURCE]*[URI_SUFFIX]*[NONCE_SERVER]*[NONCE_CLIENT]*[NONCE_COUNT]*[QOP]*[DIRECTIVE]*[MD5]\nsome fields are mandatory, some are optional.\nI'm a little bit confused about what you mean by \":\" within the nonce. It's normally just a number (used once, therefore nonce) that should be hexadecimal or decimal.\nMaybe it would be best if you post an example that does work and also an example that is slightly changed that does not  work anymore (and also explains what field you expect to trigger the problem).\nYou must also consider that \":\" is special within the SIP algorithm because it is used to concatenate some fields. I think you are trying to already put together the fields even if they should be separated, like URI prefix vs URI resource etc (see https://github.com/hashcat/hashcat/blob/7a408d98241afc74c7c1205a3de1651117a45998/src/interface.c#L12339-L12351). The same is true with nonce count and nonce (see https://github.com/hashcat/hashcat/blob/7a408d98241afc74c7c1205a3de1651117a45998/src/interface.c#L12410-L12413). You should not put them together manually, but instead specify them within the hash as separate fields. The algorithm is using the fields internally and concatenating them if needed, the user doesn't need (and should not!) do this manually.\nAll in all, I think that you are doing things that the authentication algorithm is already doing internally and therefore if you provide the wrong values (for instance nonce count + nonce vs long nonce including nonce count separated by colon) it will (and should) fail. However, it's difficult to troubleshoot it in detail without example... but I would suggest that you should try to understand ALL the fields and use the separate fields within the hash format if appropriate.. I've now investigated this problem a little bit and came to the conclusion that the \":\" is not the problem at all. Furthermore, it seems that you are still formatting the hashes incorrectly.\nIn my tests this hash:\n$sip$***4553*3CXPhoneSystem*REGISTER*sip*192.168.0.4*5066*414d535c1144225218:ef255fff6bbafa40147fbd960f128803****MD5*b3cd2617f79b96adad84706754ae91e6\ncracked, see:\n$sip$***4553*3CXPhoneSystem*REGISTER*sip*192.168.0.4*5066*414d535c1144225218:ef255fff6bbafa40147fbd960f128803****MD5*b3cd2617f79b96adad84706754ae91e6:ab1234\nwhen I modify the maximum nonce length supported by hashcat to > 51, e.g. changing https://github.com/hashcat/hashcat/blob/7a408d98241afc74c7c1205a3de1651117a45998/src/interface.c#L12257 to:\nif (nonce_len < 1 || nonce_len > 64) return (PARSER_SALT_LENGTH);\nto allow a nonce lenght of up to 64 bytes (for instance 414d535c1144225218:ef255fff6bbafa40147fbd960f128803 is 51 bytes long).\nI'm still not really convinced that 414d535c1144225218:ef255fff6bbafa40147fbd960f128803 is a number and a valid nonce, do you have more details on which system does use a colon within a number ? That isn't really a number, I think. I'm pretty sure the standard also says the same i.e. \"a number is a number\".\nI'm not sure if we should change this max length because I didn't see that long nonces before, but on the other hand it shouldn't have many disadvantages increasing this limit if needed in general.\nWhat do you think? does the change/fix work for you too?. are you sure that you have installed the OpenCL driver from intel as recommended on https://hashcat.net/hashcat ?\nWhat is the output of clinfo ?. that sounds interesting/good. Do you think you are able to send a pull request (PR) that can be reviewed by the devs ? you already have written the diff, therefore it should be easy to create/send a PR from it.\nI think the OpenCL headers download is not needed because we suggest that the submodules are initialized with git directly (git submodule update --init). This guarantees that you always use the correct/compatible/tested version of the headers.\nThanks for your contribution. why do you use --force?\nAre you sure that you are using the correct drivers as suggested on https://hashcat.net/hashcat ? What are the driver versions? Did you test this: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nDid you try using only the CPU? Did you try using the GPU? see --opencl-device-types from the help menu (--help).. Did you try using --opencl-devices (or short -d) to test the single GPU cracking? Why do you say it works with a single GPU ?\nfor instance you could use -d 1\nbtw you do not need to have the character \"w\" two times within the custom charset definition, it's enough to just specify it once like: -1 34afmw. are you able to crack the example hccapx file from https://hashcat.net/wiki/example_hashes with password \"hashcat!\" with a mask attack -a 3 ?\nbtw: the title seems to be not correct if it is not a multi-GPU problem (we already excluded that). It seems that this is now a 100% duplicate of #1611 (I think we should close this and if you are 100% sure it is not somehow hardware/driver related we might rethink to reopen the older one).... on the other hand, I don't think that it is hashcat's fault because it works with your self-test and we also have no other similar reports (it could still be a very specific vega+WPA related problem). Did the example hash work for you? Are you able to use -a 3 with other hash types?\nThe title is still missleading because it doesn't mention that this is (probably) a vega related problem with -m 2500 = WPA/WPA2. My guess is that your setup (hardware/driver) only have problem with WPA.\nDid you test using other/older driver versions ? Did you try rocm on linux ?. this \"problem\" is similar to this recent issue: https://github.com/hashcat/hashcat/issues/1603\nI also explained how to fix it (by changing the parsing code) here:\nhttps://github.com/hashcat/hashcat/issues/1603#issuecomment-400808910\nNow the question is that because we already got 2+ request for this, it might make sense to increase the maximum nonce length a little bit, e.g. to 64.\nI'm still not sure why these nonces (numbers used once) are that large for some implementations. If somebody has a clue and how large they could be (or even better the average and maximum length) it would help a lot in making a good decision here. I remember reading the standard/rfc for the last issue, but I didn't really came to a good conclusion... it just seems that the \"number\" can also be a non-number (e.g. could have colons or other characters in it) and could be of arbitrary length.\nI think a length of max 64 chars would make sense because in theory it should be a \"normal\" number, I guess... and therefore it should not be an extremly long arbitrary string.. I could not reproduce the --restore problem: my guess is that you are doing something wrong or have old files lying around (did you do a make clean etc). Anyway, I've now pushed a fix for the esalt/nonce length limitation: https://github.com/hashcat/hashcat/pull/1631. The new limit is about 1024 bytes.. @DasExperimentator hey, the problem with --restore should be fixed with latest code. This commit https://github.com/hashcat/hashcat/commit/cc8fa3ee8033e6258126ec17abbe476252532c5a should fix the problem of wrong hashes within the .restore file whenever the hash was a command line argument (instead of a hash file).\nThis problem was introduce very recently with the addition of the tokenizer within the parser. Thanks for reporting it. It seems completely unrelated with this issue and/or with SIP (but only -m 11400 = SIP used TOKEN_ATTR_TERMINATE_STRING therefore I admit it was somehow related, but just not related with the nonce/esalt problem).\nWould be great if you can test the latest master code. Thx. here is a recent example of a new hash type addition: https://github.com/hashcat/hashcat/commit/c28fdf7f44bf5d39f9078f6d82b52bdb052125e3. does it work with older drivers? i.e. did you only notice the problem after updating the driver?. I think questions like this should be first searched in the forum and if really no answer was provided it should be asked in the hashcat forum over here: https://hashcat.net/forum/\nThe github issues are more addressed at fixing problems, requesting new feature etc, not really user questions like this.\nIt's not even clear what you are trying to do in detail and what problem you are experiencing. My guess is that you want to crack a bitcoin wallet.dat file and that you want to run this with hashcat but get some error message. What error message did you get? What do you mean by \"unable to run\"? You should be more specific here.\nFor -m 11300 = Bitcoin/Litecoin wallet.dat you first need to convert the wallet.dat file with something like bitcoin2john.py to a \"hash\" that can be run with hashcat. The hash formats are mentioned here: https://hashcat.net/wiki/example_hashes (if bitcoin2john.py outputs the filenames too, you need to adapt the output hash to the format that hashcat expects, without the file names and colon).\nYou normally either run \"sudo make install\" or run hashcat with \"./hashcat [args]\". Not both.\nThat means, you either install it, or run it within the current folder. Not both.\nFurthermore, your hashcat command misses the attack type (mask attack, combinator, straight etc) , the hash file and the mask/dict etc.\na correct command would be something like this:\nhashcat -m 11300 -a 0 hash.txt dict.txt\nwhere the output of bitcoin2john.py (adapted to the hash format mentioned on the wiki) is stored within the file hash.txt and the dict.txt file contains your password candidates (one per line).\nThese are all very basic points in how to use hashcat, that are not really difficult to find in the wiki/faq/forum etc and furthermore, as said, not very suitable for this kind of issues on github. Maybe you have some other problems, but you need to mention the details. It's not easy to guess what your problem with using hashcat is when you just say \"I am unable to run\".\nPlease do not forget to close the issue if the problem was fixed or whenever you plan to ask the question on the hashcat forum with more details etc.\nThx. how to reproduce this? what is your command ? which version of hashcat ?\nbtw: you need to build hashcat with \"make DEBUG=1\" and for instance use gdb to get a meaningfull backtrace of the function/line in code that lead to the segfault. thx. The github issue tracker is meant to report problems/bug with hashcat and report feature request.\nUser questions (that were btw already answered elsewhere a couple of times) are more suitable for the hashcat forum (https://hashcat.net/forum). Many answers to user questions can also be found in the wiki and faq of hashcat.net\nHashcat uses so called attack modes (see --attack-mode or short -a) to try to crack a hash in a very particular way. e.g. by using a word list attack, a combinator attack (2 wordlists), or a brute-force/mask attack (no dict involved).\nThis attack modes sometimes (for fast hashes) need dedicated kernel source code, because of the way they can be optimized. _a0 stands for -a 0 (dict), _a1 stands for -a 1 (combinator, -a 1 dict1.txt dict2.txt) and -a 3 stands for mask attack (improved \"brute-force\", -a 3 ?u?a?a?a?a?d?d?d for instance).\nPlease close this issue and consider asking user questions (not related to bugs or feature requests) on the forum only if AFTER using the forum's search function (or googling for it) didn't return any results.\nThanks. -m 10900 = PBKDF2-HMAC-SHA256\nthis is an issue tracker for bugs/feature request. You can answer this type of question by looking at the example hashes here: https://hashcat.net/wiki/doku.php?id=example_hashes or using the --example-hashes paramter of hashcat\nhashcat -m 10900 --example-hashes\nplease close this issue and consider using the wiki/faq/forum next time (btw: it's not allowed to post hashes within the hashcat forum). can you please give more details? what do you mean by blockchain in this context? a wallet of blockchain.info/blockchain.com ?\nFurthermore, what do you mean by second password? Why second?\ndoes it have something to do with this: https://support.blockchain.com/hc/en-us/articles/207746383-Security (search for Second Wallet Password) ?. I did some research and posted my findings in a hashcat forum post (https://hashcat.net/forum/thread-8174-post-43904.html#pid43904) after some user showed some interest in this algorithm.\nThe algo is quite straight-forward, it's iterated sha256 (UUID/salt concatenated with password).\na POC is within the forum post\nThank you. This algorithm (the salted/iterated SHA256 second password hash) was added with https://github.com/hashcat/hashcat/commit/d0d4ce9f8c0e99806466457701f2cc75f98ef00a\n-m 18800 = Blockchain, My Wallet, Second Password (SHA256)\nexample hash is this:\nhashcat -m 18800 --example-hashes\nYnM6WYERjJfhxwepT7zV6odWoEUz1X4esYQb4bQ3KZ7bbZAyOTc1MDM3OTc1NjMyODA0ECcAAD3vFoc=\n(password: hashcat)\nThe hash format expects that the main passwords was already cracked and that the base64 encoded \"bs:\" data is provided, like the one of extract-scripts/extract-blockchain-second-hash.py from btcrecover.\nThe format of this hash/base64 string is also explained in the forum post linked above.\nAnyone wants to test it ?\nIt's already in beta : https://hashcat.net/beta/\nThanks. I can reproduce this, thanks for the report!\nWe should probably fix this soon.. How did you create the luks volume ?\nWe have seen some users reporting problems in the past: they did only create the volume but not really initialize i.e. write to it. Without this extra step of \"using\" the volume (e.g. formatting the volume with a file system and writing some files to it etc) it is just garbage data and can't be cracked.\nBTW: there are some example hashes/volumes on https://hashcat/wiki/example_hashes for luks. I'm pretty sure that whenever you get these to work, it shouldn't be a hashcat problem but just pebcak (not creating/initializing the volume correctly for instance).\nPlease test and close the issue if working. thx. well, it's easy to test. If for instance the tool\nclinfo\nreports the GPU correctly, hashcat should too.\nIf even clinfo does not show your GPU, we can be sure that it is not a problem within hashcat (but a problem with your installation/setup).\nAlso see https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nPlease test clinfo and report back. Don't forget to close the issue if it is starting to work and/or you found a solution. Thx . seems to be spam. please close. are you sure it doesn't depend on your code? did you free every buffer/struct you allocated memory for? Do you have some code we could test with?\nAre you sure it is hashcat that leaks memory or could it be the driver? You could use tools like valgrind and/or gcc sanitizer features to debug where the memory leak is.\nThx. If you search for \"OSX v10.8+ (PBKDF2-SHA512)\" here: https://hashcat.net/wiki/doku.php?id=example_hashes\nyou will see an example hash.\nThe length of the last field is 128 hex characters (or 64 bytes in binary).\nThe last field is:\n752351df64dd2ce9dc9c64a72ad91de6581a15c19176266b44d98919dfa81f0f96cbcb20a1ffb400718c20382030f637892f776627d34e021bad4f81b7de8222\nnote this can be seen by just searching for the last \"$\" character within the line.\nThis last field should not be longer than 128 characters (like the example above). If it is longer, you can just remove everything after the 128th character and try running hashcat with this new hash (where the last field was cut to 128 hex characters or 64 binary bytes).\nPlease close the issue if the problem was fixed. Thx. this is a quite old card (2012 ?). does the latest AMD driver even support it and is OpenCL officially supported with this GPU? You might want to try this: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nbut the best (and probably only working) solution would be to buy a more modern GPU like the Nvidia 1080 ti or if you want a new AMD GPU.\nPlease close this issue if you think this \"problem\" is solved because hashcat can't do anything here and only a hardware upgrade can fix it. . I agree, and furthermore both pocl and the kali distribution are not recommended by hashcat. I would suggest to use a distribution supported by the major hardware vendor (like Intel, Nvidia, AMD... i.e. ubuntu for instance) and use the native/proprietary driver that can be downloaded from the vendors web page. The recommended driver versions can be found here https://hashcat.net/hashca\n(I know that pocl is in the list too, but since pocl is still kind of experimental and very often leads to driver crashes, you should stick to the proprietary drivers of the hardware vendor).\nPlease do not forget to close the ticket if it works with the suggestions. I did try to reproduce this on windows 10 with both hashcat 4.2.0 and 4.2.1 and both worked correctly.\nI've tested it with\necho hashcat|hashcat64.exe -m 400 hashlist.txt\nand\ntype dict.txt | hashcat64.exe -m 400 hashlist.txt\nand\npp64.exe dict2.txt | hashcat64.exe -m 400 hashlist.txt\nall of these commands succeeded and cracked the hashes as expected.\nI'm not sure how to reproduce this. Did you test with a different version (non release versions)?\nif not, can you please test again with a different windows 10 system (maybe it's a problem with your driver/setup)?. Why do you use naive-hashcat.sh ? a third-party tool not developed/supported/maintained by hashcat ?\nPlease download the source code of the release version from https://hashcat.net/hashcat and extract it with \"7z x\". Enter the extracted folder and compile it according to the instructions (https://github.com/hashcat/hashcat/blob/master/BUILD.md), then run something like\n./hashcat -b -m 0\n(to benchmark the MD5 speed of your setup)\nMy guess is that it has something to do with naive-hashcat.sh and is not really a hashcat problem. You could also make sure that the file OpenCL/inc_vendor.cl exists within the extracted folder (from the downloaded file from https://hashcat.net/hashcat). Could you please test with the recommended proprietary driver from intel instead of the experimental (open source) pocl driver? I'm pretty sure it's a driver problem.\nrecommended driver versions: https://hashcat.net/hashcat (yeah, I know pocl is listed there too, but it's not recommended, see the dozens of bug reports on the hashcat forum and on github... the driver is not really production ready for OpenCL tasks). The base32 output is also a little bit special/confusing. I guess the format expects this base32 \"passwords\".\nIt's just confusing that the password candidates (e.g. \"Candidates.#1\") are different compared to the final output (which is base32 encoded).\nFurthermore, the -m 18100 --example output is \"hashcat\", but the final output is base32 (\"hashcat\") etc....\nI can live with it, but i guess if it is not really required to encode the password with base32, it could also make sense to skip this step to avoid confusion (does the user know that the output was not the raw output but the encoded output ? I guess, that experienced users can notice that). I actually think that @jsteube is correct @ memory leak.\nif we have this:\n```\n  u32 plain_buf[64] = { 0 };\nu8 plain_ptr = (u8 ) plain_buf;\n```\nand afterwards:\nplain_ptr = (u8 *) strdup ((const char *) temp_ptr);\nthis last \"plain_ptr = something\" is just a pointer assignment (plain_ptr now \"points\" to a new address). It's not a memcpy ().\nAccording to this https://en.cppreference.com/w/c/experimental/dynamic/strdup , we always need to use free () when we use strdup ().\nplain_ptr = (u8 ) strdup ((const char ) temp_ptr);\nwill just assign a new address to plain_ptr, but it won't replace the bytes allocated by plain_buf[64] = { 0 }, but instead strdup () will return a very new address (on heap) and this new memory block must be freed to avoid memory leaks.\n. what's your hardware and driver ?\nDo you see any warnings when launching hashcat ? (self test warnings?). Well, I didn't really look carefully at the hashes you posted.\nYou are using salts that are 32 characters long.\nThat's too long for the optimized -m 3710 = md5($salt.md5($pass)) , since as you can see we need to combine the 32 bytes of (hex) digest of the md5 ($pass) with the salt, which is more than 1 md5 transformation because of 32 (digest of md5 ($pass) + 32 salt > max bytes 55 for a MD5 transformation.\nI agree that this should be more obvious and we should reject those hashes (and only allow running them without -O ). This should be fixed in code (i.e. give a warning that salts greater than 55-32 = 23 can't be run with -m 3710 -O).\nThis problem could also affect other hash types, therefore I recommend that we should implement this -O hash rejection with other hash types too.. it's probably a driver issue. Did you try to reinstall the driver for instance by following this guide https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nFurthermore, did you try with different driver versions? Does it really depend only on the hashcat version or is that just a coincident (because the OpenCL kernel code changed for WPA between hashcat versions 3.6.0 and 4.2.1).\nYou say it is stuck... How long did you wait? Do you see any new files created within the kernels\\ folder while it is initializing ?\nDid you try to downloading a fresh version of hashcat (within a new folder) and try again ? Did you try using the beta version of hashcat from https://hashcat.net/beta/ ?. It seems you are compiling hashcat yourself by using \"make install\", is that right?\nAre you sure that you always used the \"make uninstall\" before you installed the new version ?\nWhat happens if you just use the normal \"make\" and try running hashcat like this\n./hashcat -b\ni.e. run it locally from the current working directory (cwd)\nFurhermore, please make sure that /usr/local/share/hashcat/OpenCL/inc_vendor.cl exists and contains the DECLSPEC declarations e.g.\n```\ndefine DECLSPEC inline\n```\netc\nI would say it makes sense to also try the latest beta and release versions and if all of them work I would assume it has something to do with your way that you've installed hashcat (or is this a package provided by a repo that misses some files ? did you manually compile it or not ?). Do you know what the original file system type was ?\n--keep-guessing might help, but you shouldn't get too many \"cracks\"\nHashcat detects a correct crack on luks by checking the entropy of the decrypted bytes. You shouldn't get too many incorrect results, because if the \"key\" was not correct the data should be gibberish and therefore the entropy threshold shouldn't be reached.\nsee https://hashcat.net/forum/thread-6225.html\nI wouldn't exclude other reasons, driver problems etc... but without more details (e.g. troubleshooting the entropy value etc), we probably can't say for sure.\nI would recommend to start testing with --keep-guessing and see how many results per minute/hour you get.\nThx. I think you should create an almost identical disk and format it with the same file system etc and use a known password and test hashcat with this sample instead.\n(do not forget to use this test disk before making the dd backup, because if you do not \"use\" it e.g. by formatting it, it can't be cracked, because it has random data) \nnote: hashcat doesn't guess any file system, it just uses an entropy check and only if the decrypted data has very low entropy, it's kind of guaranteed that the key was correct (because decrypting with the wrong key would result in \"very random\" data with a very high entropy).\nthere is no such thing as the \"old key check\", hashcat always used the data entropy check for the luks algorithm. btw I did some troubleshooting and my conclusion is that your data part seems to be not valid/encrypted.\nwhile the test from the wiki seems to have random data (and the cracking works):\ndd if=luks_tests/hashcat_sha1_aes_cbc-essiv_256.luks bs=1 count=64 skip=$((4096 * 512)) 2>/dev/null | xxd -g 1\n00000000: 8a c9 38 96 49 2a 73 6b f9 2f 19 a7 b3 bc 5e 00  ..8.I*sk./....^.\n00000010: 2b 7a 35 37 ca b0 bb 23 46 20 3a 5e 76 d1 6f 1a  +z57...#F :^v.o.\n00000020: 53 f0 9c 98 aa 5c 86 b9 b2 38 2a 43 18 41 53 0f  S....\\...8*C.AS.\n00000030: 45 67 64 4f 61 ad 16 95 71 f0 d1 5e dc c9 b1 3c  EgdOa...q..^...<\nthis is the data part of your luks file:\ndd if=luksheader.flash.image bs=1 count=64 skip=$((4096 * 512)) 2>/dev/null | xxd -g 1\n00000000: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff  ................\n00000010: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff  ................\n00000020: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff  ................\n00000030: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff  ................\nof course this is not random/valid data (and therefore low entropy)\nthe data offset comes from\ncryptsetup luksDump luksheader.flash.image\n...\nPayload offset: 4096\n...\nI'm pretty sure there is something wrong with your data part. I guess that a test with a properly formatted data/disk won't show all those 0xffffffff\n. One of the problems (I troubleshooted it a little bit), seems to be that when we start the server here:\nhttps://github.com/hashcat/hashcat/blob/b8eb7105dd596b6cb563f7cf61addd27d5add75d/src/main.c#L1052\nwe didn't setup WSAStartup () yet which is in user_options_check_files ()\nhttps://github.com/hashcat/hashcat/blob/b8eb7105dd596b6cb563f7cf61addd27d5add75d/src/user_options.c#L1873-L1890\ncalled after https://github.com/hashcat/hashcat/blob/b8eb7105dd596b6cb563f7cf61addd27d5add75d/src/main.c#L1083\nso the WSAStartup () needs to be done before the socket initialization (also for the server) on windows.\nI didn't yet confirm that the bind works... but that's probably the next step to do.\n\nupdate: it seems to work but I still get a \"Too many clients\" error, which is very weird o.O. The connection is correctly detected and if the firewall rule was correctly set (allow from public and/or private network) we see the connection attempt: \"Connection from 192.168.0.2:44245\"\n\nupdate2: it seems to work with the correct --brain-password parameter (and the WSA fix from above). gosh damnit!!! I'm still not sure why I got the \"Too many clients\" beforehand with an invalid password.. I'm pretty sure on ubuntu, for instance, it's called liblzma-dev and you can link it with -llzma (instead of -llzmasdk).\nOther distributions could use other names for the library of course (e.g. p7zip or 7z, 7zip related instead of lzma, lzma-sdk etc). note the fix here seems to be to check for:\nif ((brain_server_db_short->short_cnt + temp_cnt) > passwords_max)\n      {     \n        // not valid! don't accept the request\n      }\nit could happen that we overflow the brain_server_db_short->short_buf otherwise, because it only has passwords_max \"items\". This should of course not happen in a normal situation, but we should still catch it and reject it!?. Thank you very much for this report\nThe problem seems to have to do with the new brain feature and in particular with the computation of the checksum of the dictionaries.\nThe effect of this bug is that we kind of loop within this code section forever:\nhttps://github.com/hashcat/hashcat/blob/6b2c56118c1aaa976e380912808bd23a987afb33/src/brain.c#L543-L548\nwe would probably need at least a check like this:\nif (feof (fd)) break;. This \"new behaviour\" was introduced with this PR https://github.com/hashcat/hashcat/pull/1673 .\nI think we should first think about what is the correct behaviour and afterwards try to handle it accordingly.\nFirst, we have 2 options:\n--gpu-temp-disable\n--gpu-temp-abort\nAs far as I know, before we merged the PR mentioned above all fan and temp stuff was disabled with --gpu-temp-disable (also warnings/errors) etc.\nThe above PR changes this behaviour slightly and also allows fan/temp reads even if --gpu-temp-disable was specified.\nAccording to the description for --gpu-temp-disable (\"Disable temperature and fanspeed reads and triggers\") the old behaviour could be seen as more accurate/correct.\nAlso note that we have no option for fan, therefore it's always either fan & speed... or none (this would be also a little bit difficult to change because we only have 1 line for them in the status screen).\nThe question now is: should --gpu-temp-disable only affect the monitoring of the temp and if needed aborting hashcat.... or should it affect everything (as it did before the PR, i.e. also reading/displaying the fan speed and temperature)?\nIt's quite easy to come up with a fix, but I think the fix that @mastercracker1 wants is to basically revert the above mentioned PR (with maybe some further changes).\nI think that we should make hashcat behave according to the --gpu-temp-disable description (or if we decide otherwise we need to change this description too). What do you think ?\nIt would be great if @RAN1 could also join the discussion to see if we can come up with a solution we all are happy with.. Please make sure that you are using the latest version of hashcat (in this specific case the beta version, since we pushed some bug fixes).\nsee https://github.com/hashcat/hashcat/issues/1738\ndon't forget to close the issue if it's fixed. thx. what is the password for this example hash?\nThe format should be CHAP_R:CHAP_C:CHAP_I\n7f3d71b4c0c6569d2fa26f4c14ac3cf0:b73158a35a255d051758e95ed4abb2cdc69bb454110e827441213ddc8770e93ea141e1fc673e017e97eadc6b:02\nhashcat currently expects exactly 16 bytes for the challenge (note CHAP_C means chap challenge and CHAP_R means chap response, while CHAP_I is the chap_id - an incrementing counter -)\nthis means that the long challenge that you tried is not currently supported (length: 44 bytes, 88 hexadecimal characters)\n. yeah, the password seems to work:\n(echo -en \"\\x02\"; echo -n 'U$er1'; echo b73158a35a255d051758e95ed4abb2cdc69bb454110e827441213ddc8770e93ea141e1fc673e017e97eadc6b | xxd -r -p) | md5sum\n7f3d71b4c0c6569d2fa26f4c14ac3cf0\nthe problem, as we already suspected, is \"just\" the longer challenge length (44 vs 16 bytes).\nIn the meantime, you coud probably work around this limit by just using -m 10 = md5 ($pass . $salt)\ni.e. hashcat -m 10 -a 0 -j '^\\x02' --hex-salt hash.txt dict.txt\nwhere hash.txt contains the hash:\n7f3d71b4c0c6569d2fa26f4c14ac3cf0:b73158a35a255d051758e95ed4abb2cdc69bb454110e827441213ddc8770e93ea141e1fc673e017e97eadc6b. it's important that you know how your operating system does interpret the command line arguments. on windows for instance you might need to use \"^^\\x02\" or something like this (because of shell/dos escape rules).\nanyway, you can always just put the rules into a rule file e.g. myrule.rule with the file content\n^\\x02\nand use -r myrule.rule instead of -j ^\\x02 \nbtw: you can't remove the ^, that's the actual rule function ! (\\x02 is not a rule at all).\nI think this all is quite irrelevant to this issue and very basic usage of hashcat and/or general use/understanding of your shell/operating system.. Thanks for report.\nI can confirm -m 10700 problems but -m 12 should be fixed with 4d457ca141103a15cc8939089f5bff55a407d254\nplease try beta from https://hashcat.net/beta/ with -m 12 to confirm. good, we should still investigate the problem with -m 10700. it probably is a minor issue with the new parser/tokenizer code (limits too strict/wrong ?). I've tracked this problem back a little bit and noticed that this commit introduced the problem:\ncd552eb54dda8ab4c9729664b3aefcf4b0887b4a\nthis means that the conversion to the tokenizer interface has a bug for -m 10700\nI guess it should be easy to fix now with this knowledge and by making the tokenizer call work like it did before we introduced our new tokenizer functions.. This must have to do with your setup and how you installed hashcat.\nSince you use The-Distribution-Which-Does-Not-Handle-OpenCL-Well (Kali), you might have installed hashcat system-wide with packages etc.\nhashcat itself recommends using the binaries from https://hashcat.net/hashcat/ and use the tool directly within the extracted download folder, for instance:\n./hashcat --help\nan accepted/recommended alternative for more advanced users would be to use the git repository https://github.com/hashcat/hashcat (clone the repo, make (see BUILD.md), ./hashcat --help) and this also allows to use \"make install\" to install hashcat.\nIf you do this (make install) the folder ${HOME}/.hashcat/ and subfolders will be created automatically.\nMy guess is that on your system there is a problem (or conflict) with the installed hashcat version and/or the folder /home/cyberthereaper/.hashcat/ does not exist.\nIt's difficult/impossible for us to track all kali issues here, if the downloaded version (run it locally with ./hashcat, not just \"hashcat\") and/or the \"make install\" version (be aware that you might first need to uninstall all the hashcat packages etc, otherwise there could be further conflicts) works, it's not a hashcat problem.\nPlease test and do not forget to close the issue if the problem was fixed with these instructions.\nThank you\n\nupdate: do not forget the most important rule DO NOT EVER report a problem and use --force ;)\nthis --force flag tells us that your setup is broken and there is something you need to fix (e.g. install correct/proprietary drivers etc) before reporting (other?) problems. omg your command is completely wrong.\nyou are using a mask attack (-a 3 ) with a dictionary file (rockyou.txt)\ntry this:\n./hashcat -m 0 -a 0 -D 1 --session deneme1 /home/cyberthereaper/zzzzz/md5.txt /home/cyberthereaper/zzzzz/rockyou.txt. what is this issue all about? I have no clue what you mean by instagram hashing in the context of hashcat. Please give the algorithm details or link to source code and follow the instructions here:\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this. wait?\nthis has nothing to do with --keep-guessing.\nIf you want to test several masks with hashcat, you need to use the hashcat mask file feature (https://hashcat.net/wiki/doku.php?id=mask_attack#hashcat_mask_files).\nHashcat never allowed to specify a list of masks directly on the command line like you just tried with the command above. something like this is not allowed:\n-a 3 hash.txt ?u ?d ?u?u ?d?d ?u?u?u ?d?d?d ?u?u?u?u ?d?d?d?d\nhashcat only expects and accepts one single mask. Indeed, it should give an error otherwise. I guess it's because it's sometimes tricky to catch if there is some additional (not used) parameters in the command line (but it could be fixed indeed).\n--keep-guessing on the other hand does not care about if there are multiple masks or multiple dicts etc, it only does NOT mark the digests as \"done\" and therefore the GPU keeps working on this particular hash.\n. it should have something to do with the limitations mentioned here:\nhttps://github.com/hashcat/hashcat/blob/38e97bd89ada27dd07c74046889b102b34686781/docs/limits.txt#L25-L41\nnote: the limits.txt file says that all distinct passwords are guaranteed to be reported at least once, but I guess it's not always possible if the same kernel function call (should) find 2 correct hits (with a tiny keyspace like in your case). maybe @jsteube can confirm this. did you try running electrum2john.py ?\ndoes the output start with $electrum$2 or is it $electrum$3 ?\nHashcat supports salt type 1 and 2 currently, not sure if your type is not supported (3 ?). Hey.\nPlease search for questions like this on the hashcat forum/wiki/faq etc. These questions have been answered dozens of times and github issues are not really the right place to ask general questions  like this (which have been answered already couple of times) that have nothing to do with bugs/problems in the hashcat software.\nnote: you could use something like hashtopolis to distribute work across many cracking machines.\nbtw: do not forget to close this issue\nThx. Does this mean it is neither \"cbc-plain64\" nor \"cbc-essiv\" ? This is the cryptsetup luksDump output, right?\nAre you able to open this volume with the correct password?\nAre you able to create a similar (new) volume with cryptsetup? How do you create a volume with this cipher mode?\ndd if=/dev/zero bs=1M count=32 of=test.img >/dev/null 2>/dev/null\ncryptsetup luksFormat ./test.img -q --cipher aes-cbc\nI get\nFailed to setup dm-crypt key mapping for device ./test.img.\nCheck that kernel supports aes-cbc cipher (check syslog for more info).\nI think it should be either cbc-plain64 or cbc-essiv. Can you somehow generate a image with the same Cipher name, Cipher mode, Hash spec as the luksDump from above?. Did you install the drivers ? the recommended drivers are mentioned under https://hashcat.net/hashcat\nWhich hardware do you have? Which drivers have you installed?\nYou need to give more details about your setup.\nDoes clinfo work, if not even clinfo lists all your CL_DEVICE_TYPE_GPU and/or CL_DEVICE_TYPE_CPU , hashcat also won't work (because the drivers are not correctly installed). Therefore we recommend testing with clinfo first (such that we are sure it's not hashcat's fault).\nBTW: this type of questions are not really suitable for this type of bug/problem tracker (github issues). We recommend searching for the error on https://hashcat.net/forum/\nplease do not forget to close the issue if installing the driver fixed the problem (also see https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do).\nThx. This is a driver installation problem, please follow these steps: https://hashcat.net/faq/wrongdriver\n(also download a fresh copy of hashcat from https://hashcat.net/hashcat and install the recommended drivers mentioned there)\nPlease don't forget to close this issue if fixed. it's way too huge keyspace:\n[a-f0-9] (note you said a-z which is wrong !) is 16 different characters\nsha256 has length 64 in hexadecimal.\nTherefore your keyspace is:\n16^64 = 115792089237316195423570985008687907853269984665640564039457584007913129639936\ndo you even realize how large this is ? (hint: try to think about the amount of all atoms on the word, it's just incredible huge), therefore infeasible\nto answer your question see https://hashcat.net/wiki/doku.php?id=mask_attack : \n-a 3 hash.txt ?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h?h\nwould be the correct mask, but it's of course not accepted because it's an insane large mask that leads to insane large values of keyspace etc... (=> 64 bit variables can't hold such large values)\nAs you can see from https://hashcat.net/wiki/example_hashes sha256(sha256($pass)) is currently not supported, but might be possible to implement. Do you know if sha256(sha256($pass)) is the correct algorithm used in your case ?\nBTW: the github issues are not suitable for questions like this, please try finding a solution on wiki/forum/faq instead. If there is currently no answer to a question you have by looking at wiki/forum/faq, you might consider opening a new thread on the hashcat forum instead https://hashcat.net/forum/\ngithub is for issues/bugs/feature report only, not for general non-technical discussion/help requests.\nPlease do not forget to close this github issue as soon as possible (only the author of this github issue and owner of this repository have the right to close github issues).. hmm... it's strange that it seems that this is your project/repository. That's kind of \"fishy\" (this is no accusation, but it's strange/uncommon that the algorithm developer wants their algorithm to be easily crackable etc).\nWhere is this algorithm being used? Is this really a common hashing algorithm used in the wild for which the addition to hashcat would benefit a lot of hashcat users ? I have never heard of this algorithm in the past.\nIs this even considered a (secure?) password hashing algorithm (I didn't look at the code but already the project description \"encode ya message!\" doesn't really seem to indicate that this codeMKII algo is used to hash and store passwords).\nCould you please clarify why this should be added and where this algorithm is used ?\nFurther details are also needed, see: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\nThank you very much. sound like a driver issue.\ndoes -D 1 work for you ?\ndo you have problems with other hash types too?. -d is not the same as -D\nyou can't say that something didn't work, but at the same time you show that you tried something completely different\nagain:\n--opencl-devices (or short -d) is not the same as --opencl-device-types (or short -D)\nbut it doesn't really matter actually in this very specific case, because you just found out that the problem only happens with a very specific device (not device type !) and only together with a very specific driver... therefore I would classify this problem as a driver bug (of course there could be workarounds of any bugs, but you either need to convince the driver developers or try messing around with the OpenCL kernel code and see if any code change could prevent this problem to occur with this specific faulty driver version). should/could we close this issue?. you can use up to 31 rule functions (the amount of characters is not the problem) within one rule line, see https://hashcat.net/wiki/doku.php?id=rule_based_attack#limitations\nThis is of course a limitation that is well documented and is actually quite difficult to remove without breaking support for older GPUs etc which have less memory etc. (we once had support to up to 255 rule functions in a previous release, but of course it needs much more memory and therefore users complained a lot)\nPlease do not forget to close the issue, if this explains why there is this limit. I'm pretty sure that the problem is that the salt can't be more than 16*4 = 64 bytes, see:\nhttps://github.com/hashcat/hashcat/blob/471a8cccaf7feb79e08ee28e47a89bb479ab7504/include/interface.h#L349\nand\nhttps://github.com/hashcat/hashcat/blob/471a8cccaf7feb79e08ee28e47a89bb479ab7504/OpenCL/inc_types.cl#L1335\ntherefore either the salt buffers are \"too small\" or the checks for maximum salt lengths are wrong.\nThanks for the report.\nbtw: remember that backtraces are kind of useless if you do not use \"make DEBUG=1\" while compiling the code (non-optimized code with debug symbols), your whole output above kind of only tells us that /home/jku/hashcat-5.1.0/hashcat64.bin crashed LOL, no hint about why and where it crashed without debugging symbols\nThx. this might have to do with your cached dict stats (hashcat.dictstat2).\nCould you please try to make a backup of the dicstat2 file and delete the original file (hashcat.dictstat2) and try again ?\nIn the past all problems around this feof () error had either to do with your dict or dictstat2 file... this is just my educated guess... please test.\nBTW: what is the hash type you are trying to crack (-m xxx) ?. any updates here ?\nwe need an answer/confirmation. I can't reproduce it here.\nCould you please test/troubeshoot what I mentioned above @fakename12345cat ?\nThx. It's not supported currently, but there are already other example hash types like -m 5100 = Half MD5 that do basically the same (just in this case for MD5).\nOf course it wouldn't be impossible to implement, but the problem is that we need of course to have good performance in mind (and that's the difficult part and kind of impossible without implementing a dedicated OpenCL kernel for each and every substring of a hash). Also see https://github.com/hashcat/hashcat/issues/116 (that means that this issue is actually a duplicate of the older issue).\n. does aircrack-ng even use OpenCL ?\nI suspect that this is a driver/setup problem and your comparison is flawed because one software is using the intel OpenCL driver (hashcat), while the other one (aircrack-ng) is not using this package at all.\nbtw, we had all kind of strange issues like this and at the end it turned out that the users did something strange (like using hashcat within a very restricted vm with limited resources) or configured the system incorrectly (by for instance not using the official drivers from the vendor etc).\nI would also say that problems like these are better suited for the hashcat forum @ https://hashcat.net/forum/ and since these are probably not really software bugs (in hashcat) or feature requests, you might find more/better solutions and help on the forum instead of on the dev issue tracker.. sorry, but I didn't really understand what you did or what/why it is working now?\nDidn't you say that the speed was bad (compared to aircrack-ng) and that you see that only 1 CPU core was used ? What happened if this is no problem anymore ?\nI also noticed from your screenshots above that one is mentioning the \"i5-8400\" and the other is not (even if you used -D 1,2 in both of them). So there is maybe a little bit confusion and misunderstanding going on here that we need to clarify first.. oh, now I understand what is working and what wasn't working before. Thanks for clarifying and confirming.\nLet me explain the 2 options briefly.\n--opencl-device-types as explained within the --help output is needed to whitelist your CPU OpenCL device. The default for hashcat is that \"only\" GPUs are enabled/whitelisted by default (except if the system only has CPUs).\nWith the opencl-device-types 1 you enable the CPU device type and the value 2 means GPUs (see --help output under \"OpenCL Device Types\"), the option --opencl-device-types 1,2 of course enables both CPUs and GPUs.\n--force in this particular case is only needed because your GPU is a Intel GPU for which we know the driver has several bugs and speed problems. That is  why by default (without the --force command line switch) you get the error \"Intel's OpenCL runtime (GPU only) is currently broken.\" (as you can see it says that only GPUs are affected and therefore (as far as we know) the Intel OpenCL Runtime for CPU devices (Intel Core and Intel Xeon) is working perfectly fine.\nThis means that users without Intel GPUs won't need to set --force and the ones that only have Intel GPUs are guaranteed to see the error message that warns them from using this device/driver.\nThis also means that most of the hashcat users fortunately won't need to use the --force option i.e. if they do not have Intel GPUs (these GPUs for the time being are also not recommended, because they both are, among others, slower compared than both Nvidia and AMD GPUs).\nI hope that explains a little bit what is going on. I assume you already figured out most of what I just wrote, but it's always good to document it here just in case somebody else reads it and doesn't understand what is going on.\nIf you have any suggestion how to improve this (or the documentation forum/wiki/faq) it is of course very welcome. Unfortunately, in your case you had to use both options (and install the OpenCL runtime for your Intel Core correctly) but I don't see much we can do to improve the user experience here (the --force hint was in the output and the device that wasn't whitelisted yet, had the \"skipped\" warning in the output to notify the user that --opencl-device-types must be used to whitelist it).\nThanks for your explaination and feedback\nBTW: only the original poster in this github issue (author, you @gitxmax ) and the project owner (@jsteube) can close issues... so please don't forget to close it if we agree that we can't improve/do anything here\n. \"Killed\" as far as I know has most of the time to do with exhausting all RAM (memory) of the system and therefore the process is killed by the system.\nWith 8 times 4 GB you should have at least 32 GB available host memory, because the driver (not hashcat) will pre-allocate this.\nTry testing with only one card, e.g. by adding --opencl-devices 1 (or short -d 1, lowercase \"d\").\nThis sounds like a question more suitable for the hashcat forum: https://hashcat.net/forum , because the community over there will know what you have to do (or just use the forum search function). The github issues are meant for development (bug reports/new features etc) and therefore not the correct place for user questions like this.\nThanks\nBTW: do not forget to close the issue if fixed. What are you trying to do ? Where are you trying to build it ?\nDo you use a windows system ?\nThe usual way we compile the binary is (by following the BUILD.md instruction of course) using an ubuntu LTS system with mingw cross-compilers installed (of course make/gcc and other tools - e.g. built-essential on ubuntu - need to be installed too).\nWithout any more information it's very difficult for us to understand what you are trying to do and how you are compiling it (and therefore difficult to understand why it fails for you)?\nPlease give more details what you are doing and what this CreateProcess()/process_begin  etc has to do with hashcat compilation etc !\nThx\nBTW: I think this some kind of android stuff. Android is not officially supported by hashcat and therefore you shouldn't really report errors (and especially not reporting errors without mentioning that you are compiling for Android. This is very confusing for devs if they do not know what is going on and what you are trying to do). If you are trying to get hashcat working on Android you would probably need to make a lot of changes/patches... and even then it would probably just be extremely slow because the OpenCL support on mobile devices is just bad as far as I know (let alone the problem with heating/temperature and power consumption etc) . did you try with cygwin instead ?\nI think you would need several packages also for cygwin (like gcc, make, libiconv-devel etc) but it should work\nThe devs usually cross-compile the binary for windows under linux by using the x86_64-w64-mingw32-gcc cross-compiler and the win-iconv dependency.\nI'm pretty sure that several users managed to compile hashcat directly under windows. If the BUILD.md is not up to date and if it does not mention all the instruction steps, we should probably improve it.\nFor instance, I see that there is no mention of win-iconv within BUILD.md (needed for cross-compilation on a Linux host system) at all. That's not good.\nIf you can, please help to improve it.\nThat said, it should work with both mingw/cygwin/msys, because we tested this in the past (I personally didn't test it lately unfortunately).. maybe this helps: https://stackoverflow.com/questions/33674973/makefile-error-make-e-2-the-system-cannot-find-the-file-specified,  https://stackoverflow.com/questions/3848357/createprocess-no-such-file-or-directory etc\nyou are either missing some packages / libs or didn't setup mingw correctly.\nI would suggest trying the solutions suggested for the CreateProcess errors on stackoverflow.\nprobably gcc is not installed or not working (try to compile a hello world program for instance). Why are you emphasizing that this is a problem with benchmark ? I guess it's also not working during a \"normal' attack, right?\nI would suggest removing all drivers with this guide https://hashcat.net/faq/wrongdriver and only installing the Intel driver (as per https://hashcat.net/hashcat) from intel.com. if the plains contain a \":\" character, they should use the $HEX[] notation.\nI think it's more correct to use the last occurrence, because some hash types have \":\" within the hash line because of the salt etc\nI think your change breaks some other hash type support, doesn't it ?\nWhy do you have \":\" in the plain after alll ? hashcat should use $HEX[] to output those passwords. my response to this is that we shouldn't mix up outfiles with potfiles and that potfiles should (and do!) always use the $HEX[] notation, as it is also needed!\nI think it's only a problem on your site because you are using outfiles as potfiles, aren't you ?\n--outfile-autohex-disable shouldn't change the format of potfiles.\nI don't think changing the separator etc is a good idea.\nWe just should use potfiles (do not use --potfile-disable if you want to use --show/--left and profit from the speed improvement by avoiding duplicate work, i.e. cracking the same hashes and/or trying the same salts again and again) and those potfiles should (continue to) use $HEX[] if needed and the format should stay AS-IS.\nI think no changes are needed if you use the potfile correctly, or am I missing something here?\nThx. there are plenty of ways to convert $HEX[] to non-hex.\ne.g.\nhashcat --show -m 1000 --outfile-format 2 hash.txt | hashcat --stdout\nI think the problem with -m 3000 (which is very special) is that you could have two parts and hashcat (it seems) currently does not combine 2 $HEX[x],$HEX[y] parts correctly into 1 larger $HEX[x+y].\nThis could be improved indeed !. This algorithm was added recently with commit d0d4ce9 .\nsee https://github.com/hashcat/hashcat/issues/1650\n(this issue was basically a duplicate of #1650, asking for -m 18800 = Blockchain, My Wallet, Second Password (SHA256)). can't reproduce over here. that's a very weird problem.\nhow should it be always the second attempt. who is counting up to 2 ?\nbut jokes aside, do you have only problems with --stdout or is this also happening with \"normal\" runs ?\nwe might need to do a make DEBUG=1 run and get more debugging info about the kernel problem\nI guess it has to do with your macOS driver, maybe it's somehow unstable/broken etc. It seems also the current version still uses PBKDF2 (see https://github.com/aosp-mirror/platform_frameworks_base/blob/c1e55147c91f9be219f2dd824d3ab6f9b39d5c3b/services/backup/java/com/android/server/backup/BackupPasswordManager.java#L135-L136), older explanation https://nelenkov.blogspot.com/2012/06/unpacking-android-backups.html and https://forum.xda-developers.com/showthread.php?t=1730309\nWe would at least need some examples to confirm and a way to \"extract\" the data.\nI really thought that Android did move to SCRYPT completely/everywhere.\nDoes somebody know if this is true ? I mean the BackupPasswordManager.java is kind of very clear that it's \"just\" PBKDF2 with 10000 rounds (see https://github.com/aosp-mirror/platform_frameworks_base/blob/e80b45506501815061b079dcb10bf87443bd385d/services/backup/java/com/android/server/backup/utils/PasswordUtils.java#L37) and AES encryption\nI guess PBKDF2 is used because it's easier to combine with the AES encryption, but afaik the  on-device full disk encryption (FDE) is also done with scrypt, isn't it ?\nNote: this is the non-github link: https://android.googlesource.com/platform/frameworks/base.git/+/refs/heads/master/services/backup/java/com/android/server/backup/BackupPasswordManager.java\non googlesource.com. update: just checked if john the ripper (jtr) supports it already. and it seems it was recently added (summer 2018) in jtr:\n1. extractor: https://raw.githubusercontent.com/magnumripper/JohnTheRipper/27f51880a4daf1372a115a49c2e04b9fb2406209/run/androidbackup2john.py\n2. key derivation and pass check: https://github.com/magnumripper/JohnTheRipper/blob/27f51880a4daf1372a115a49c2e04b9fb2406209/src/androidbackup_fmt_plug.c#L195-L203\nThank you very much for the help/suggestion. Thanks for confirming.\nI think it makes sense because we have this patch from 2018/12/06 https://github.com/hashcat/hashcat/pull/1805 and latest hashcat version v5.1.0 was released 2018/12/02 (therefore about 4 days earlier than the fix).\nIn general the betas are kind of \"experimental\", but due to very hard work by the devs they are actually quite stable and reliable (most of the time). You can use it the same way you use the release version and after a new release version will be available, you should/could update to that one (it will be listed here https://hashcat.net/hashcat a version > 5.1.0 in the future).\nFor the time being, you should be able to use the beta without any major problems/disadvantages :)\n(you can read the always-changing changelog here https://raw.githubusercontent.com/hashcat/hashcat/master/docs/changes.txt if you are interested what is new and what was changed between the versions, including beta versions).\n@jsteube I think we can close this issue :). Please use the same format that we used for other hash modes i.e.:\n- Added hash-mode  1470 = sha256(sha256($pass))\n. hmm, could/should this be improved with something like this:\n```\n   hc_timer_t s;\ns.tv_sec  = hr_tmp.tv_sec  - a.tv_sec;\n   s.tv_usec = hr_tmp.tv_usec - a.tv_usec;\nif (s.tv_usec < 0)\n   {\n     s.tv_sec  -= 1;\n     s.tv_usec += 1000;\n   }\ndouble r = ((double) s.tv_sec * 1000) + ((double) s.tv_usec / 1000);\nreturn r;\n???\n( I didn't test it, but if I look at the other branch - the #else - it seems to be more consistent)\nwe could also perform the return after the branch (because it is common code to both branches) and the variable definition of hc_timer_t s before the branches (but this isn't too important, it just would emphasize where the main differences between the 2 cases are, i.e. the nsec vs usec etc). the format we normally use is\nswitch (otp_offset & 3)\n(spaces before the opening bracket and between the operators). idem (formatting). idem (add spaces). idem (missing spaces). formatting:\nplain_len = strlen ((const char ) temp_buf);\n. should be:\nplain_ptr = (u8 ) strdup ((const char ) temp_ptr);\n(with added space). idem (space before the opening bracket).\ntimestamp = hc_strtoul ((const char ) salt_pos, NULL, 10);\n.\nsalt->salt_buf[i] = byte_swap_32 (timestamp);\n.\nsnprintf (out_buf, out_len - 1, \"%06d:%d\", digest_buf[1], byte_swap_32 (salt.salt_buf[1]) * 30);\n.\nmy $paddedTime = sprintf (\"%016x\", int (int ($salt_buf) / 30));\n.\nmy $data = pack ('H', $paddedTime);\n.\n$tmp_hash = sprintf (\"%06d:%d\", $token, int ($salt_buf));\n. I think it doesn't make much sense to use a loop here. It's a little bit distracting/confusing.\nI would suggest to unroll it and therefore make it clearer how the single salt_buf[x] will look like (2 assignments).\nsalt->salt_buf[0] = byte_swap_32 (timestamp >> 32);\nsalt->salt_buf[1] = byte_swap_32 (timestamp >>  0);\n. ideally we would use this format:\nswitch (otp_offset & 3)\nadd a further space after \"switch\" on all instances of this switch(). minor formatting problem: there is a tab character here. compiler complains about the type incompatibility (int vs u32x), we probably need to use u32x types here and modify the switch () code accordingly. there is a bug here, must be:\n   u64 timestamp = hc_strtoull ((const char ) salt_pos, NULL, 10);\n(i.e. use hc_strtoull () for 64 bit, instead of hc_strtoul () which would only allow 32 bit). I found that the hashes can't be cracked multiple times this way (e.g. the output of hashcat can't be cracked again for certain hashes, e.g. \"hashcat\" -> 504267:85457442135216). My suggestion here is something like this:\n      u64 tmp = (((u64) byte_swap_32 (salt.salt_buf[0])) << 32) | ((u64) byte_swap_32 (salt.salt_buf[1]));\n  tmp *= 30;\n\n  snprintf (out_buf, out_len - 1, \"%06d:%lu\", digest_buf[1], tmp);\n\n```\n(and remove the comment about the 32 bit is enough)\nNote: we need 64 bit because the * 30 could also overflow etc. do we really need python code here?\nI didn't find anything that can't be done with perl directly in the code block below. Maybe I'm missing something.\nPlease explain why you use python here. in general (a general question/discussion): it would also make sense to use a single additional programming language if perl really has absolutely no way/modules to do it. I think using PHP and python is acceptable, but if we can avoid it and stick to 1 additional language it would be even better. (I think the reason why we added the PHP code was just that perl had no modules and we needed that mode during a cmiyc contest etc... therefore it was a quick \"hack\"). yeah, I figured that out. so my idea would be to convert the code of -m 11900 = PBKDF2-HMAC-MD5 to python too such that we only have the python dependency. Do you think that makes sense? hashlib.pbkdf2_hmac in python2 probably ?\nFurthermore, the base64 conversion of the words/salts (https://github.com/hashcat/hashcat/blob/master/tools/test.pl#L8226-L8227) should be done also for the python code. We do this to avoid any code injection and also to avoid any strange/special characters as input resulting in strange behaviour (this should be pretty easy to do in python too, just encode in perl and decode the strings in python).\nwe should also update tools/install_modules.sh if we need any additional/special python modules (btw: should we rename the file \"install_modules.sh\" into something that explains that this is needed for tests ? (install_test_modules.sh ? test_install_modules.sh ?) \nBTW: I do not think everything I mentioned here should be done within this commit/PR, the PHP->python could/should be a separate PR/issue (it's just something I noticed here and wanted to mention and ask if python is really the way to go here) . What I noticed here is that you allow the file names to be included within the hash. As you can see here https://hashcat.net/wiki/example_hashes , we never include the file names within the hashes.\nI think to be consistent, we also need to stick with -m 18400 to the standard format that hashcat doesn't use file names within the hashes (except if needed by the hashing algorithm). The problem is that if we add this \"suffix\" here, we would need to add it to many, many other formats too (like ms office, docx, pdf etc).\nIn my opinion the hash shouldn't be mixed with a file name (we could in theory use the --username feature to add some extra data/info at the beginning of the single lines of a hash file).. hmm, shouldn't these len_min == len_max all using TOKEN_ATTR_FIXED_LENGTH instead ?. minor consideration: we normally do not add any lines/entries for new tests in docs/changes.txt (except if the tests were missing in older releases and we finally managed to complete/add the tests). I think it is enough to just have the other line under Algorithms, because usually if we add a new algo it comes accompanied with tests (as in this case). Again, this is not really a problem. It's just a note and a hint to make it more consistent for other/future PRs ;). ",
    "jsteube": "Problem solved with PR https://github.com/hashcat/oclHashcat/pull/2\n. Thanks, that worked!\n. Sorry, I don't understand what you mean, could you please rephrase?\n. I see, that is indeed interessting especially for the CPU part, but definitly a long-term suggestion.\n. You're right. Now that we're not forced any longer to ship binary kernels we could allow other platforms than AMD to run the OpenCL kernels. Sure, some of the optimizations wouldn't work. However I'm absolutely positive about this, especially as it would give us an easy start into support CPU as well. I'll look into this in some time, but would also would be happy on any help on it\n. Yeah I'd like to do so, but the most important reason for using CUDA is that only with CUDA it's possible to cross-compile GPU code using nvcc's -arch option. So we'd have a strange situation in which we'd use OpenCL on Nvidia if the users chooses to use the JIT but for binary distribution we still need to use CUDA. That sounds very complicated. BTw, there was such an option back in earlier versions of NVidia OpenCL runtime, but it got dropped without any reason.\nAnd yes there's also the reason with the performance:\na) While this is just speculation, it seems NV isn't really happy with OpenCL. It's obvious that they try to push CUDA instead of OpenCL, for business reasons.\nb) I remember with driver change somewhere between 150.x and 200.x the speeds for the OpenCL began to drop by 15% without any reason or any change within the ptx. It's also speculation but I think they tried to artificially slow down OpenCL to make CUDA more interessting.\n. It seems we have alot of good reasons to fully switch to OpenCL. I've tried that yesterday but it's more complicated than one would think in the first place. We need to get rid of all of our C++ code (which is mostly only overloaded functions) because NVidias OpenCL runtime does not support C++. But there's no way around, since so many other tasks depend on this change.\n. For those interessted in development: https://github.com/hashcat/oclHashcat/tree/GetRidOfCUDA\n. @shellster The whole Jetson TK1 discussion makes no sense since they dropped the support for the board with CUDA 7.0: https://devtalk.nvidia.com/default/topic/805540/no-cuda-7-0-support-for-jetson-tk1-board/\n@magnumripper I'll drop CUDA completely not just because it's easier to maintain afterwards but also because it makes the host code easier to read. If I remove the code from the host, there's no sense in keeping the NV folder. If anyone really wants it simply checkout an older version. PS: The CUDA branch uses already an OpenCL/ folder\n. So far the GetRidOfCUDA branch works, all unit-tests passed. Now we have to focus on the performance, and there's a lot to do! I justed started a sheet for comparison:\nhttps://docs.google.com/spreadsheets/d/1B1S_t1Z0KsqByH3pNkYUM-RCFMu860nlfSsYEqOoqco/edit#gid=0\nDon't get shocked by those early numbers, I'm confident we'll stabilize them after optimizing each single kernel\n. FYI, first version working with pocl now\n. You can not, however the depencies were reduced to only a few which you can automatically install using tools/deps.sh -- see building.md\n. Just wanted to update the status on CPU here. It seems pocl works fine, but LLVM is buggy (even the latest LLVM 3.7).\nThe native AMD OpenCL CPU driver works really really good, all Unit-Tests pass. Speeds are almost the same as with pocl.\nThe native Intel OpenCL CPU driver also seem to work very good, but not all Unit-Tests pass (I'll have to look into that). But then the speeds are really good, much faster than with pocl.\n. I think we're finished with this issue. All OpenCL platforms from all the differen vendors that I've tested, on all OS, seem to work fine.\n. What about lowend GPU's? I'm not sure they could load all 4k kernels. But still interessting, how much was the startup time?\n. While implementing I just realized that there's no JIT support yet for NV in oclHashcat. Since I always start development on AMD I never really thought about. But luckily it seems with latest CUDA SDK they added support for JIT using the CUDA driver API (not the runtime). For example there is cuLinkCreate(). I have to play with that and see if it works for what we need.\n. This is getting annoying. So the cuLinkCreate() is not able to compile from source, only from .ptx. \nActually there's no easy solution to compile from source as you know it from OpenCL, but with CUDA SDK v7.0 NVidia added a library NVRTC which targets this missing feature. But then, NVRTC works only on 64 bit, but not 32 bit, for some unknown reason:\n\n2.1. System Requirements\nNVRTC requires the following system configuration:\nOperating System: Linux x86_64, Windows x86_64, or Mac OS X.\n\nAnother problem of this is, the user would need to install the CUDA SDK, because the library is not part of the driver distribution. OTOH, if one has installed the CUDA SDK then we can also simply call nvcc to compile from source to PTX and this will work for 32 bit and 64 bit. But run a system command to compile a kernel out of the program, how ugly is this, not to mention all the things that could possibly go wrong here. \nI'm a bit stuck here now.\n. Pushed https://github.com/hashcat/oclHashcat/commit/968265fffb8d9f929ec18862c461031e1a7b8e83 which enables this feature for AMD. Still unknown how to proceed with NV\n. Maybe we should really switch to OpenCL and obsolete CUDA?... \n. I've decide to switch to OpenCL fully, once we did this, we can finished this enhancement\n. Implemented :)\n. Just to note this here, the code is -not- tab indented. It's a 2-space indention.\n. Can you please send in a PR for this?\n. It's a good idea, but I'd suggest to start with a smaller goal. You still can extend it afterwards. Start with a more simple API version that works like the iptables API. You simply generate the commandline parameter as you'd call the binary and push that as a string to the API initialization call. Getops doesn't care where the array it works on is coming from. Is it really argc/argv or some artifical one, it doen't matter. Such a concept also minimize the changes required to the core code. We may need another wrapper function that you get the data for the status view unless you want to directly access the global data structure.\n. Hmm, I'm not sure if this is what we want. I think you're already one level too deep. \nIn code, my plan was that an integration would look something like this:\n``` C\nint main (int argc, char **argv) {\nhc = oclhashcat_init()\noptions.hash_file = \"example0.hash\"\noptions.markov_threshold = 32\noptions.words_files.append(\"example.dict\")\noptions.mask = \"?a?a?a?a\"\n\nchar **v;\nint c;\nrc = hc.generate_commandline (&c, &v);\n\nstatus = hc.start(c, v)\n}\n```\nGiven such a construct, the codechange to oclHashcat would be minimal, we'd end up in a very fast implementation. oclHashcat will have the both arguments as it would be the original ones from the commandline (argc and argv). That's how iptables works, too.\n. Well, that would work, but then I don't see any benefit. My Idea is going more into a direction like the following, what we can do is something like this:\n``` C\nifdef API_CALL\nint apimain (int argc, char **argv)\nelse\nint main (int argc, char **argv)\nendif\n```\nNow if you add -DAPI_CALL to the CFLAGS and compile oclHashcat.c with -c you should be able to call apimain (c, v); as a normal C function and integrate it that way into your library.\n. For example you could start list what else do you need. Invokation is one thing but I guess you also want a function to get stats and so on. For that I'd suggest making a new function that does nothing else than to return the values one could need, for example to read the speed, get the number of cracked hashes, and so on...\n. Not sure what you're saying now. Do you criticize that you have to add more code to work in C than in other languages? I think the getter/setter method is the cleanest.\n. That looks really cool so far. I didn't test in detail. A function to return a pointer to data structure should be easy to accomplish.\nNote that due to the issue #3 and #20 there have been tons of changes that also includes the rename of some of the variables and macros. Please update your proposal so that I can do a testrun, afterwards I'll add the function for you to access data\n. @Rich5 I think you're on the right track. Using the global data structure was what I had in mind as well. I'd recommend to simply add a function to oclHashcat.c which access and parses the data and returns it in some format you can work with from within your wrapper API. Note that this variable is global, so you need to have some sort of instance management, like doing a fork. Since you only read from that variable, there's no need for any kind of synchronization, like mutexes or so. You just need to run the main function in a seperate thread inside your wrapper (after the fork()) then you can call the newly added function in a seperate thread. \n. This is very interessting. If you merge it, would it still be possible to use hashcat as it is now? Like running from commandline. What are the exact changes you would do?\n. Looks goods, but I need a full PR to decide. Please send it in. Note I'm about to release hashcat 3 soon.\n. The refactoring into a library is more or less finished. I think it's safe to start.\n. Yes it's an alternative way to the events if you want to access the last\nerror occured (if any).\nOn 31.10.2016 20:06, Rich5 wrote:\n\nSounds good. I'll let you know if any issues comes up. One question is\n|hashcat_get_log| strictly for reporting errors?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/9#issuecomment-257389228,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OYuNoe8AaPxqvx0lkTNAP_e4ngpEks5q5jwjgaJpZM4GvzWS.\n. It seems you're doing some great progress over there! Very nice!\n\nI understand the problem you're having. I need to think a bit about a\ngood solution. I think it will be somehow related how we handle the make\ninstall case, but with special handling for library use. Give me some\ntime to think about and feel free to push some suggestions :)\nAnyway, great work so far. I've quickly overlooked the python bindings\nbut since I'm not used to write python I can't really tell this is what\nuser need. I just guess you're doing it right :)\nOn 15.12.2016 05:55, Rich5 wrote:\n\n@jsteube https://github.com/jsteube Ok so you can ignore my previous\ncomments. I tracked the issue down to\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L333\nSince |get_install_dir| always resolves to |resolved_exec_path| and\n|resolved_exec_path| is resolved using the cwd (|exec_path|) of the\ncurrent process here\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L33 I end\nup with an issue at this line\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L409\nbecause the current process is Python which runs out of /usr/bin by\ndefault.\nSo when hashcat tries to find the OpenCL folder it's prepended with\n/usr/bin and then throws and error here\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L415\nI tested my theory by just copying the OpenCL and hashcat.hctune to\n/usr/bin and the Python binding work as expected. This is not really a\ngood solution though. You can see the before an after in the image below.\npyhashcat_error\nhttps://cloud.githubusercontent.com/assets/7902735/21211934/e8287eac-c255-11e6-91d0-e4e02344f9f6.PNG\nThe easiest solution is to just change the compiler flags when the\nlibrary is built. So basically just change this line\nhttps://github.com/hashcat/hashcat/blob/master/src/Makefile#L362 to\n|$(CC) -o $@ $^ $(LFLAGS_NATIVE_SHARED) -shared\n-DINSTALL_FOLDER=\\\"$(INSTALL_FOLDER)\\\"\n-DSHARED_FOLDER=\\\"$(SHARED_FOLDER)\\\"\n-DDOCUMENT_FOLDER=\\\"$(DOCUMENT_FOLDER)\\\"|\nI'm not sure this is an issue with hashcat, but I wanted to provide\nfeedback since it was a big problem I was having.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/9#issuecomment-267238806,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdPwAE9JOLek2w0ZWCN2lVUyrChdks5rIMhQgaJpZM4GvzWS.\n\n\n. I think the best solution to do it the same way as hashcat does when using \"make install\". To do that, I need to patch the detection of libhashcat.so the same was as hashcat already does for the hashcat binary. That way, it expects the files at the following paths:\ninstall -m 755 -d                                    /usr/local/share/doc/hashcat\ninstall -m 755 -d                                    /usr/local/share/hashcat\ninstall -m 755 -d                                    /usr/local/bin\ninstall -m 755 -d                                    /usr/local/share/doc/hashcat/docs\ninstall -m 755 -d                                    /usr/local/share/doc/hashcat/extra\ninstall -m 755 -d                                    /usr/local/share/doc/hashcat/extra/tab_completion\ninstall -m 755 -d                                    /usr/local/share/hashcat/charsets\ninstall -m 755 -d                                    /usr/local/share/hashcat/masks\ninstall -m 755 -d                                    /usr/local/share/hashcat/OpenCL\ninstall -m 755 -d                                    /usr/local/share/hashcat/rules\ninstall -m 644 example.dict                          /usr/local/share/doc/hashcat/\ninstall -m 644 example0.hash                         /usr/local/share/doc/hashcat/\ninstall -m 644 example400.hash                       /usr/local/share/doc/hashcat/\ninstall -m 644 example500.hash                       /usr/local/share/doc/hashcat/\ninstall -m 755 example0.sh                           /usr/local/share/doc/hashcat/\ninstall -m 755 example400.sh                         /usr/local/share/doc/hashcat/\ninstall -m 755 example500.sh                         /usr/local/share/doc/hashcat/\ninstall -m 644 extra/tab_completion/hashcat.sh       /usr/local/share/doc/hashcat/extra/tab_completion/\ninstall -m 644 extra/tab_completion/howto.txt        /usr/local/share/doc/hashcat/extra/tab_completion/\ninstall -m 755 extra/tab_completion/install          /usr/local/share/doc/hashcat/extra/tab_completion/\ninstall -m 644 hashcat.hcstat                        /usr/local/share/hashcat/\ninstall -m 644 hashcat.hctune                        /usr/local/share/hashcat/\ninstall -m 755 hashcat                      /usr/local/bin/\nfind docs/     -type d -exec install -m 755 -d    /usr/local/share/doc/hashcat/{} \\;\nfind charsets/ -type d -exec install -m 755 -d    /usr/local/share/hashcat/{}   \\;\nfind masks/    -type d -exec install -m 755 -d    /usr/local/share/hashcat/{}   \\;\nfind OpenCL/   -type d -exec install -m 755 -d    /usr/local/share/hashcat/{}   \\;\nfind rules/    -type d -exec install -m 755 -d    /usr/local/share/hashcat/{}   \\;\nfind docs/     -type f -exec install -m 644 {}    /usr/local/share/doc/hashcat/{} \\;\nfind charsets/ -type f -exec install -m 644 {}    /usr/local/share/hashcat/{}   \\;\nfind masks/    -type f -exec install -m 644 {}    /usr/local/share/hashcat/{}   \\;\nfind OpenCL/   -type f -exec install -m 644 {}    /usr/local/share/hashcat/{}   \\;\nfind rules/    -type f -exec install -m 644 {}    /usr/local/share/hashcat/{}   \\;\nsed -i 's/\\.\\/hashcat/hashcat/'                      /usr/local/share/doc/hashcat/example0.sh\nsed -i 's/\\.\\/hashcat/hashcat/'                      /usr/local/share/doc/hashcat/example400.sh\nsed -i 's/\\.\\/hashcat/hashcat/'                      /usr/local/share/doc/hashcat/example500.sh\nSo that's basically /usr/local/share/ for the kernels and other static files and $HOME/.hashcat/ for everything related to user specific data like cached kernels. What do you think?. With latest commits I've\n\n\nFixed that _GNU_SOURCE problem you had and fixed as suggested.\n\n\n\nThis commit splits the native hashcat binary into the hashcat library and hashcat frontend.\nI've tested this with Linux and Msys2. I hope it will work on FreeBSD, OSX and Cygwin as well.\nThere's also four new dedicated makefile targets for install: install_library install_hashcat install_docs install_shared\nAlso the main_shared.c and its makefile target have been removed, as the main frontend is the best example possible\nIOW, once you ran \"make install\" on your linux box there will be a libhashcat.so copied to /usr/local/lib which you can access as usual. I suggest to read the followin sections from main.c\nhttps://github.com/hashcat/hashcat/blob/master/src/main.c#L911-L924\nand \nhttps://github.com/hashcat/hashcat/blob/master/src/main.c#L964\nThis shows how the new hashcat frontend gets the two important paths install_folder and shared_folder. I think in your case you can simply set them static to what's defined here:\nhttps://github.com/hashcat/hashcat/blob/master/src/Makefile#L45-L47\nBut this way it's your decision if you want you can do some own runtime logic or use the static paths (even if they do not neccessarily exist, which is the trick here).\n. OK, but the Idea would have been to call it like this:\n```\nself->rc_init = hashcat_session_init(self->hashcat_ctx, \"/usr/bin\",\n\"/usr/local/share/hashcat\", 0, NULL, 0);\n```\nI just changed the install_folder path to \"/usr/bin\", which is where\nPython is installed, right? If you do that, then it should work as we\nwant without any code change. At least I think so. Or, If you can find\nout the directory where Python is running out of, but in the runtime,\nthat would be the ideal solution.\nOn 30.12.2016 06:45, Rich5 wrote:\n\nActually, I'm not sure this fixed it. Unless I'm doing something\nwrong, but ultimately I'm initializing my module like this:\n|self->rc_init = hashcat_session_init(self->hashcat_ctx,\n\"/usr/local/lib\", \"/usr/local/share/hashcat\", 0, NULL, 0);|\nIs that the intended usage?\nWhen I do this the |install_dir| is eventually set as the\n|resolved_exec_path| here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L333\nSince the |resolved_exec_path| is taken from the current running\nprocess we still get |install_dir| resolved to |/usr/bin|(where Python\nis running out of).\nSo then this check fails:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L339\nand profile_dir, shared_dir, and session_dir are all set to\ninstall_dir (/usr/bin) here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L363-L365\nThen when we look for the OpenCl folder here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L409\nIt's looking for |/usr/bin/OpenCl|which is of course isn't there. I\nthink the root issue is that the |get_install_dir| function is\nassuming that libhashcat is being used in the same directory as the\nprogram loading it. That's not true in this type of use case.\nSo here's how I got it working. I inserted the following condition\nstarting here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L363\n|if (install_folder != NULL) { get_install_dir(install_dir,\nresolved_install_folder); struct passwd pw; struct passwd pwp; char\nbuf[HCBUFSIZ_TINY]; getpwuid_r (getuid (), &pw, buf, HCBUFSIZ_TINY,\n&pwp); const char home_dir = pwp->pw_dir; profile_dir = hcmalloc\n(HCBUFSIZ_TINY); session_dir = hcmalloc (HCBUFSIZ_TINY);\nget_profile_dir (profile_dir, home_dir); get_session_dir (session_dir,\nprofile_dir); shared_dir = hcstrdup (shared_folder); hc_mkdir\n(profile_dir, 0700); hc_mkdir (session_dir, 0700); } else {\nprofile_dir = install_dir; session_dir = install_dir; shared_dir =\ninstall_dir; } |\nI didn't have time to do extensive testing, but it's working at the\nmoment.\nworking\nhttps://cloud.githubusercontent.com/assets/7902735/21560201/380ad0f8-ce29-11e6-949e-fbc5492b8a8c.PNG\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/9#issuecomment-269734842,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OTMH5Lox2aFEuK0zMd92SyclksFYks5rNJqQgaJpZM4GvzWS.\n\n\n. Yeah I think it is overcomplicated, however I wasn't really clear in my description, too. Now that we know how it reacts exactky it's easier to deal with. Such things progress step-wise I think. Keep up your good work. I'm going to release v3.21 pretty soon unless there's some new bugs comming in.. OK, closing. Do you have any plan when to release the bindings?. That one is automatically calculated. No need to worry about.\nAm 05.01.2017 4:03 vorm. schrieb \"Rich5\" notifications@github.com:\n\nWhat is the use case for user_options_extra? Is it intended to be part of\nthe API?\nhttps://github.com/hashcat/hashcat/blob/1f266fb0f2ecfb4e1b94494f8f9b70\nacd020faf9/include/types.h#L1428\nI notice you're using it in some of the event functions like here:\nhttps://github.com/hashcat/hashcat/blob/1f266fb0f2ecfb4e1b94494f8f9b70\nacd020faf9/src/main.c#L212\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/9#issuecomment-270552214, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OZ5y6Gc2VYxTqF3r7hZANmgR-rH6ks5rPF2SgaJpZM4GvzWS\n.\n. So far so good, but I'm not an python expert. What I can't see from the\nexample python script is how the user can add his own callback functions\n(events). I think that's important, at least to retrieve cracked hashes\nwhile hashcat_session_execute() is blocking the script execution. Could\nbe useful also for him to get temperature warnings etc.\n\nOn 06.01.2017 06:14, Rich5 wrote:\n\nStill a work in progress, but my code is up in a development branch so\nothers can contribute if they want.\nhttps://github.com/Rich5/pyHashcat/tree/bindings\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/9#issuecomment-270833114,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUTqZULYQ8uJET3NLvdwhT_9mEN5ks5rPc3CgaJpZM4GvzWS.\n\n\n. OK, merged. Good work, thanks!\n. Merged, thanks!\n. @Xanadrel please fix your wording\nHowever, SL3 is not going to be re-implemented\n. The issues on GitHub are for development discussions only. Please use our Forum instead:\nhttps://hashcat.net/forum/\n. Maybe, yes. Please find out by trying: -b --benchmark-mode 0 -n 1 -u 1 --runtime 30\n. There's one more thing to think about. I just thought about this the first time this morning. Imagine we implement this proposed change, how would the binary distribution look like for linux?\nIt would either require an install script to move the files to the above folders or it should stay as it is now.\nTherefore we should come back to the proposal from @philsmd on the hashat forum. Maybe I just did not realize on the forum that this is what he had in mind when he wrote it. \n- If the tool is called from the cwd, then set Install folder, Profile Folder and Session folder to the cwd\n- Otherwise use the proposed changes\n. Wait, it's important not to confuse the two different binary package we have:\n- RPM/DEB \n- The .7z for the distribution on hashcat.net\nFor the source tree, the RPM and the DEB, of course the real paths that I mentioned in the first comment are part of the Makefile so that anyone can change them at compile time. So if the users chooses the install folder /opt/bin then, for example, the oclHashcat binary will move to /opt/bin/oclHashcat. Like you'd expect it.\nBut, more importantly, we also have to think about the .7z binary package. The most users will use this package. But we don't want to ship an install script for that. We want that the user just unpacks the .7z and is ready to use it. Same way as with windows. But we're looking for a way that we do not have to build two different binaries. So far the idea is that the binary itself finds out on startup that it is used out of the .7z package if the CWD == the folder where the binary itself is lying. We'd just set all the paths, Install folder, Profile folder and Session folder to the CWD.\n. Maybe later, currently I'm not planing to integrate a config file\n. Before we can finalize this enhancement we need to switch to OpenCL fully, also for NVidia. This way we can reduce the number of produced binaries and we do not need to add any code to the Makefile to find out which type of binary needs to be compiled.\n. I don't even know what this is, but I know that you know what you're doing. Still, need one more sign-off by the board members to merge.\n. Thanks!\n. Today I got an email from an User asking for support to run the Host code on a Big Endian architecture CPU. I'm not sure if it's worth patching, especially since this requires a huge effort. Why should someone want to do this? Is there any CPU that is BE architecture and so fast that it's really useful to run oclHashcat on it?\n. Thanks for testing!\n. From what I've seen the Jetson TK1 does not support OpenCL, only CUDA.\nSo the Error message would be OK. Not related to your compiling.\nOn 28.11.2016 08:22, 0xicl33n wrote:\n\nCompiled hashcat on a Jetson TK1 with Ubuntu 14.04 running, as\n@shellster https://github.com/shellster running hashcat on.\nIt compiled just fine but..\n|[root@turbine[~]$hashcat --opencl-info hashcat (v3.10-829-g646a472)\nstarting... clGetPlatformIDs(): CL_UNKNOWN_ERROR |\nNo opencl device detected, i cant confirm if any code was actually\nbuilt using |nvcc|. How can i take a better look to make sure i built\nthings correctly? Are there CFLAGS i should have used?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/27#issuecomment-263200155,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OS0sbR9_17rcZpvogQ7acUaVHdVUks5rCoEcgaJpZM4G4vVI.\n\n\n. Yes, Project switched to OpenCL\nOn 28.11.2016 08:55, 0xicl33n wrote:\n\nand my assumption is hashcat doesnt use cuda anymore?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/27#issuecomment-263205189,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OXHCGAv-d5fOMDfRzC9SlGnZT9ZAks5rCokGgaJpZM4G4vVI.\n\n\n. Yeah hashcat forum should be the correct platforms for this\n. Just added with commit https://github.com/hashcat/hashcat/commit/e0c3f447da5b6f22321ae1e0660c41e1d01611d1\n. Added to hashcat v3.10 thanks to @hops \n. There was alot of changes due to due Get rid of CUDA branch. Please send in a new PR based on the current master\n. Implemented with https://github.com/hashcat/hashcat/commit/87c24200da61ab5ca251b5e07af70ae6cd04297f. I just want to comment the real background of this issue here. AMD's Catalyst driver doesn't really install it's own 'libOpenCL.so' correctly in /usr/lib because it installs it as 'libOpenCL.so.1' and forgets to symlink back to 'libOpenCL.so'. NVidias ForceWare is more clever and installs it, so this problem never occurs in NV installations anyway. \n. As an alternative to all this we could think of using:\nhttps://github.com/KhronosGroup/OpenCL-Headers\nhttps://github.com/KhronosGroup/OpenCL-ICD-Loader\nThe first one provides the CL/cl.h and the second one the libOpenCL.so. This is the Khronos OSS reference implementation.\nOb Ubuntu/Debian (mayber others, too) those exist as installable packages. Both without any depencies:\nopencl-headers\nocl-icd-libopencl1\nWe should look into them and maybe switch. This would also enable us to drop the depency on amd-app-sdk which is weird anyway for NVidia users\n. While working on it it turns out on ubuntu 14.04 it needs another package:\nocl-icd-opencl-dev\nBut this package is somehow broken in 15.04 (wants to uninstall xorg-server and such). We need to make sure in deps.sh that this package is selected only in case the libOpenCL.so wasn't created\n. Replaced with https://github.com/hashcat/oclHashcat/commit/dc13c2fc71c8c9e3af66ceaa9dfc8ff34cb56bfb\n. You're right, it was just forgotten\n. I haven't used VCL for a long long while. Is it still maintained? But you're right, could be worth a look. There was specialized VCL code in old oclHashcat but it was mostly for handling binary kernel data instead of the source kernel data. It should (in theory) work out of the box once all OpenCL platforms are supported. I'm currently working on this\n. Yeah, I remember, that was some special \"helper\" function. The developer told me to use it for binary kernel. VCL is unable, if it's a binary kernel, to determine if some kernel argument was either a cl_mem or some other datatype.\nBTW, for the VCL tests, you can try to force the use of source kernel by setting force_jit_compilation variable to 1500 or so. This is just a hack but should do it for a test. If it turns out to help we could add a commandline option to do it.\n. With latest version on GitHub we've switched to device-vendor, as your suggested. I guess it should work now, of couse, you need to make sure the include files exist on all the nodes, as you wrote. Do you think we can close this issue?\n. Or, due to the changes related to platform and device vendor, can you simply try it again now? Maybe it will work out of the box now.\n. Hey @magnumripper any updates on this?\n. Yep, that would work for now and is the current state of the art of using prince with oclHashcat. \nHowever, now that we are not more limited by SIMD code in the kernel, we maybe can look again into adding this attack-mode. There's at least a few chances :) Any volunteers for implementing?\n. I think you're a tad bit late for this change. Please see the changes discussed here:\nhttps://github.com/hashcat/oclHashcat/issues/20\nThis issue addressed all the general problems maintainer could have when trying to build packages for oclHashcat and should solve it with current master branch.\nYou, as a package maintainer, are one of the people why we did that change. It would be really nice if you could please find out if this change helps you in integrating oclHashcat in your packaged version or if we are still missing something (like the the bool thing from above)\n. Patch 1) I liked some parts of your patch, especially the fix for the bool type. I've modified a bit and pushed to master as part of this patch:\nhttps://github.com/hashcat/oclHashcat/commit/0ff49c5b44bbe0eab4daa3b76389c66c306e4669\nPatch 2) I liked the idea of having a human-readable error message for the OpenCL error codes. Unfortionally the reference OpenCL API does not have something like strerror (), therefore I think we actually need to use such a switch () composition. However I'd like to have it in full, not just for clBuildProgram (). Maybe you can provide a full switch block and patch all the wrapped functions?\nPatch 2) I didn't like the idea of having an description which variable/option a failed fopen () belongs to. That's very untypical for unix-type tools, for example:\n$ cat x\ncat: x: No such file or directory\nPatch 3) With latest master version of oclHashcat and using the \"normal\" make install version of oclHashat there's no more need for such a parameter. The session folder will be somewhere in $HOME/.hashcat/sessions/xxx which is something a user should have write-permissions to.\n. Sure, why not. I just hope someone can provide patches for it since I do not have an apple computer so I can't code it.\n. Full OSX support is almost finished thanks to @gm4tr1x \nIt's all in master if you want to test\n. @gm4tr1x can we close the issue?\n. Update: Now that we removed SIMD code (vector-datatypes) from the kernel this attack becomes feasible again.\n. Update: Support for RAR3 (with header encryption) was added. RAR3 (without header encryption) and RAR5 is still missing\n. Cool, it was indeed easy to add. Pushed with https://github.com/hashcat/oclHashcat/commit/f0a84a2410fe5832ee120c3cbe62a84dca42b511\n(Also a good example of how to add new hashes, should do a writeup on it)\nNow it's just RAR3 without header encryption missing.\n. Almost, there's still a variant which is not supported: RAR3 + not-encrypted headers.\n. Since rar3-hp and rar5 was added, there's only rar3-p missing. Therefore this issue is continue on a dedicated issue for this mode: https://github.com/hashcat/hashcat/issues/1334. Note we've added WinZip support, PKZIP is still missing\n. Update: With latest versoin from GIT we opened oclHashcat in a way that all OpenCL compatible platforms should be able to work. Maybe this does work now, someone needs to test\n. I've patched those cases and for GCN and newer, MESA is now fully supported. And you're right, It's much slower than catalyst because of missing rotate() and bitselect(). Anyway that's beyond our scope. If they decide to map it to the hardware instruction we will automatically make use of it anyway.\n. please add more descriptions[:] like algorithm, example hashes, etc\n. support added with commit https://github.com/hashcat/hashcat/commit/7e5b8d3f25821c7c8707190f074739c9370554b4. https://github.com/hashcat/hashcat/issues/565\n. Done with https://github.com/hashcat/oclHashcat/pull/225\n. @neheb Is that somehow related to your patch?\n. I tested latest hashcat v3.00 inside a cygwin shell and it seems to work fine. OP : please reopen if it's not working for you\n. OK, i see. Well in that case there's no way without a true cygwin makefile target in order to set the macros to use the posix way of doing handling the user input.\n. sha-3 is now in FIPS 180-4 http://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.180-4.pdf\nwe should develop hash-mode according to this reference \n. Done with latest beta version\n. Please use the generic hash mode as philsmd described, this will work fine.. Added with https://github.com/hashcat/oclHashcat/commit/332b3c35e5b7023a681a3b42a296bc423077ff5d\nPlease test\n. yw :)\n. I've recently added KPA for DES. I'm thinking about doing the same for RC4 after the refactoring, but I'm thinking about a fixed 40 bit key length, not a variable one. Also I don't think about adding support for that DropN length, except if you would know a software or protocol that uses RC4 in 40 bit mode using this technique. The key range can be limited with -l (and offset with -s to allow distributed search).\n. Update: We do have bitslice now\n. Implemented as -m 14000 - have fun :)\n. implemented :)\n. https://github.com/hashcat/hashcat/issues/565\n. I agree to @philsmd here. I don't see a clear benefit of switching. Please reopen if you strongly believe we need to change this.\n. Continue here: https://github.com/hashcat/hashcat/issues/565\n. Continue here: https://github.com/hashcat/hashcat/issues/565\n. I think it's safe to use a fixed filename for the potfile. I don't see any good reason for a session-depending filename for the potfile. I've pushed the change to latest master.\n. Should be fixed with latest github version\n. @ OP if you read this, we think this is fixed with hashcat v3.00. If not, please reopen the ticket\n. Please retry with this version: https://hashcat.net/beta/\nOn 05.01.2017 17:15, darianf01 wrote:\n\nthis is not fixed on 3.10.\ntried with a gtx1060 and 550ti\nwhile running with -d 1 (e.g. 1060) i get the h/w monitor of the 550ti\nbut hashcat running on1060.\nwhile running with -d 2 (e.g. 550ti) i get stats for the 1060, while\nhashcat runs on 550ti.\nwindows 10 64 bit (and nvidia 373.06, although i belive this does not\nmatter)\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/102#issuecomment-270684034,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVXkETCvb4VS73Ws-EqVpA2-LktUks5rPRc5gaJpZM4HBf0N.\n\n\n. This is obviosly user-defined error, not a bug.\n. That's correct, the FAQ needs to be updated. This is some feature a while ago. It's as you said, it's always the bigger wordlist\n. This is the wrong project, you did post to the oclHashcat project. Please open the ticket again in hashcat.\n. Support was added with #453 . Support added to latest beta\n. Should be implemented with commit https://github.com/hashcat/hashcat/commit/9fc193ce47d5be59460fb00ee26c80bae84fab96. Please use -s and -l for distrubuted computing, it's really the best way to do is.\n. I just got another Idea. Can we maybe spawn a VM and just assign it like 24 CPU's? Since we now have support for CPU this could work...\n. @A-Circle-Zhang BF, even md5, with 256^8 is almost impossible, especially with multiple salts. If you otherwise do not intend to BF and use wordlists instead then the script from @epixoip should be fast enough. as an alternative you can also try to use md5-half kernel and simply and-out the unneccessary additional bits. See m00190 as an example for that, which had to deal with a similar problem\n. Hey, first for thinking of building a proper package for Kali. We really need this!\nMy comments on this so far:\n1) Why do you want to ship the SDK at all? You don't need to ship the SDK. All you need is the ADL library itself (the .so files) and those are part of the Catalyst driver package. That's why it's enough for endusers to simply install Catalyst and oclHashcat will work. Users really need this feature to avoid burning their hardware.\n2) With oclHashcat v2.10 there's no more CUDA at all. NVidia devices will use OpenCL runtime the same way as AMD devices. You don't need to worry about CUDA anymore! This also enabled us to use OpenCL CPU drivers. See here for details: https://github.com/hashcat/oclHashcat/issues/4 and https://github.com/hashcat/oclHashcat/issues/3\n3) There's no ./configure in oclHashcat because we do not use autotools. There are people working on it but I think it will take some time. Anyway even with autotools we'd need to change the code so that it accepts an build without hardware-management. But in regards to 1) I don't think we'd need such a solution.\n4) oclHashcat v2.10 had lots of changes to make it more easy for maintainer to integrate it into a packaging system. Basically you simply set the PREFIX in Makefile as you'd do it with ./configure and the files were installed on there after running make install. Files created for sessions or kernel cache are stored in home directory. See here for details: https://github.com/hashcat/oclHashcat/issues/20\n. Just to make this complete: Both you as the maintainer and the package endusers do not need any of those SDK:\n- CUDA SDK \n- AMD APP SDK\nThose actually create more problems than they do good. All you both need is the NVidia ForceWare driver or the AMD Catalyst driver. They include all the libraries oclHashcat need to run.\nOnly you as the maintainer who builds a native binary needs the following additional SDK:\n- ADL SDK\n- GDK\n. Well I don't know enough about package maintainance. All I can say is that you need the ADL SDK only for building the binary package. Using something like a build-depend package sounds good but in this case you need to avoid it. Again, you do not distribute the SDK you just use it for building. Therefore the license doesn't apply.\nDon't confuse the vendors ICD with the vendors OpenCL runtimes: Check out this post for a much more detailed explanation: http://wiki.tiker.net/OpenCLHowTo\nThe ICD's from NV and AMD should not be used. Ideally there's also a OSS ICD from Khronos Group. For example I'm using Ubuntu, such a package exist on there.\nYou will find out that for all the different OpenCL compatible devices they usually need a vendor driver. Intel has one for the GPU and CPU, AMD has one for their GPU and CPU and NV has  one for their GPU. There also exists other vendors that provide runtimes for FPGA, for example. \nThe User has to pick the right one for his hardware. For example if he installs the NVidia ForceWare because he has a NVidia GPU, the driver also ships an OpenCL runtime library. Also it will put a configuration for the OpenCL ICD folder in order to \"register\" it's own OpenCL runtime library. \nWhen oclHashcat starts up, it checks which drivers are registered at the ICD and loads all the available runtimes.\nNo magic here :)\n. @rhertzog What's the status? Do you need anything?\n. About the non-free thing. oclHashcat does not depend on catalyst by default. It's only required if you want to use AMD GPU. The same is true for Forceware + Nvidia.\nAnyway, with latest oclHashcat in theory you could run it with only pocl, which I'm not sure if it is completely free or not but I'd think so.\n. @rhertzog What exactly do we need to change to make you happy?\n. @rhertzog It should be possible now to compile oclHashcat without ADL/NVML/NVAPI completely. Do you think we can close this issue now or do we need to do additional changes?\n. @magnumripper sounds like a plan :+1: \n. I've tried to reproduce on my 750Ti but can not:\n1 hash: 162.7 MH/s\n15 hashes: 147.0 MH/s\nIs this with beta38 ?\n. Yes, please retry with the latest beta from https://hashcat.net/beta/\n. OK, the performance problem seems to be fixed. If there's some new error please open a new issue. 1 error = 1 issue, It's much easier this way.\n. Please retry with latest GitHub version, I think this change should solve it:\nhttps://github.com/hashcat/oclHashcat/commit/49d0767aa8118b60d4caba64ebd808b5e64baa4e\nYou can also try the latest beta build 44 from https://hashcat.net/beta/\n. Fixed\n. For me this sounds like a bad idea to compare FPGA/CPU with GPU using DES since DES is so extremely FPGA/CPU friendly. A comparison based on MD5 makes much more sense since this algorithms is friendly for both platforms.\nAnyway I think such an algorithm can make sense for known-plaintext based attacks since so many crypto schemes still base on raw DES but it should be mode-independant. You can anyway simply reverse the ECB from it before putting it to oclHashcat.\n. Wait, oclHashcat is neither +s nor it does run as a server process. I'm not getting it...\n. Two questions:\nWhich disadvantages does it have to add those flags? \nWill it work with all compilers we depend on like clang and mingw?\n. thanks!\n. Fixed with b55, thanks!\n. Also note that some algorithms, like md5crypt, they create some pseudo-base64. Good thing is their output size is fixed. It should be simple to overwrite some of the output, just in case they do not match the output length of the corrected base64 encoder (whenever you submit that patch).\n. In general I liked the idea, thanks! I'll push a patch to use \"git describe --tags --dirty=+\". \nBut, I don't want it to be shown on startup screen nor the --help menu. It will be shown when using the -V argument.\nIt's hard to explain my reasons for this, basically it goes back a mix of gut feelings, design and practical use reasons.\nI haven't decided if we'll change the filename convention as you suggested. It's possible that I'll add another push related to this issue, therefore I'll let it open for a while. Feel free to convince me if you really want it in startup screen and --help menu.\n. OK, we'll do that. My only concern is that beta tester need to understand that new output. For example at this time it will show v2.01 + X instead v2.10. This is very technical and even if this is more correct from a developing view it can be confusing for normal users, even beta testers.\n. The checksum in the version string from git describe --tags --dirty=+ is the first 7 chars from the commit hash that you can find git log. Note that I'm not commiting each beta I create therefore I can't add any tags\n. @roycewilliams do you think we can close this issue?\n. Thanks for that GDB dump. From there it looks like the crash is somewhere in the libamdocl12cl64.so which is part of the AMD catalyst drivers. The library is used the query fanspeed, and temperature from the device. Since it's not oclHashcat that crashes, we can't do anything to avoid it. But you can. From my experience this segfault is caused because you need to have X Authority and/or disable X11 ACLs with \"xhost +\". This can be a bit tricky if you run it over ssh.\nYou can also disable Hardware Monitoring --gpu-temp-disable.\n. Issue closes; OP not responding\n. Yes. Most texteditors have an option to select the CRLF. Also I know from some FTP tools to convert between CRLF depending on the selected Host OS so it's possible some scp tools inherited this behavior.\nAnyway I don't think this is an empty line problem. It's propably CRLF related.\n. @anlx-sl did the hint from @philsmd help? can we close the issue?\n. I made the same experience with the different OpenCL platforms. But I think it's the opposite direction we should go here:\n1) As sad as it sounds, I made the experience that it's the normal users that report back such warnings instead of the beta testers. I think it's because they're scared by it much more. Therefore I think it's better to no surpress them for the release version\n2) Such a verbose switch isn't too bad. Reason here is that if t's always the same warnings they becomes too \"normal\" and people (me included) tend to ignore/overlook them. This is bad because then it's hard to notice new warnings that could come up while changing the code which are actually important\n. https://github.com/hashcat/oclHashcat/commit/01a7adc12a86a516d848d286d8beb2fff6d01d36 should handle it\n. With commit https://github.com/hashcat/oclHashcat/commit/fc1be6bb85f597e36090506f12f7df9361c081eb the bug should be fixed, here's a log.\nroot@sf:~/hashcat# ./hashcat -m 8900 SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=====:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA= -a 3 hashca?1 -1 t -d 2\nhashcat (v3.00-beta-142-g9d2c24f) starting...\nDevice #1: AMD FX(tm)-6100 Six-Core Processor             , skipped\nDevice #2: Hawaii, 2858/4025 MB allocatable, 44MCU\nDevice #3: AMD FX(tm)-6100 Six-Core Processor, skipped\nDevice #4: GeForce GTX 750 Ti, skipped\nDevice #5: GeForce GTX 560 Ti, skipped\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n- Brute-Force\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nSCRYPT tmto optimizer value set to: 1, mem: 103809024\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA=:hashcat\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (hashca?1) [7]\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#2...:        0 H/s (16.68ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Mon Jun  6 00:30:50 2016\nStopped: Mon Jun  6 00:30:57 2016 \n. I also don't see what sense it makes to have --gpu-temp-disable if we have HAVE_HWMON. It may confuse the user because being able to disable something implies that it's turned on by default, which it is not since it's not supported.\nI think what's the real reason behind this is that we want to use --gpu-temp-disable in test.sh but if we would run test.sh on OSX oclHashcat would stop instantly because it would report --gpu-temp-disable as an unknown parameter. From that view it might make sense to add it back.\n. OK, that's correct. It's only a few users using tools/test.sh, even less on osx, and those could remove the flag from test.sh manually. Now I understand what @philsmd means with lazy and I agree. Please remove that one patch about --gpu-temp-disable but send in a new one for the other changes from this PR\n. I think the problem is this one:\nhttps://github.com/gm4tr1x/oclHashcat/commit/479327fc20b1678d8d25c9cd6f422bf685fef769\n. What happens to OSX when using the default values?\n. I'm mostly OK with this PR but there's a few things I don't like. \nPlease fix that first:\n- KERNEL_LOOPS_* and KERNEL_ACCEL_* macro names should stay as they are. Please use #ifdef and create a full set of all algorithms for OSX for both accel and loops\n- You can do the same for the benchmark list. Don't forget to update NUM_DEFAULT_BENCHMARK_ALGORITHMS if you remove some algorithms\n- Do not use something like _TUNED\n. I think what we really need to make it \"perfect\" is a dlopen() loader for OpenCL as we already do for ADL and NVML. That would be great!\n. WOW! Good work, you must have been busy. I'll merge it but maybe rename some variable names.\n. Don't forget to create a PR for it\n. There's some more of such parameters like --opencl-platforms and --opencl-device-types do we need the same fix for them?\n. I think patching this is easy. All we need to check is if the compilation was a success and store the cached kernel in that case.\n. There's b64 in https://hashcat.net/beta if you want to test\n. This one is not related to the PR. Please open a new Issue for it and I'll look into it\n. Do you think a total of 112 chars for both salt and password is enough?\n. You said in an other discussion the salt length is fixed. What is that fixed salt length?\n. Everything > 112 is a problem, we can't do that easily without creating a new hash-mode for it. To do that we'd need to know where it is used in so that we can decide if it worth the effort\n. Do you need it for -m 1710 or -m 1720 ?\n. I'm working on it. Send me example hash and plain please.\nFormat: \nhash:salt\n. Nevermind that. I just played around an temporarily added support to -m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The problem is that this would also affect other modes, like -m 1722 (OSX) and that's why we can't add it to generic -m 17xx. For this mode to work, we need to add a completely new one, ideally with esalt. But before I'm going to do this I want to know where it's used in.\n. Support for passwords and salts up to length 256 was added. Cool, many Thanks! I'll close #164\n. We should also use those headers for Windows so that we can totally get rid of the #ifneq stuff in Makefile. Can you do that?\n. The PR 171 should have fixed it, can you retry please? \n. OK, now it should work :)\n. That would be great. Will it work on Windows, too?\n. Excellent, thanks!\n. I'm fine with it, but we'll need to check all the algorithms again using test.sh and ideally also update performance on our v2.10 sheet\n. I'll  change some stuff after merge\n. @Fist0urs can you please try again with the registry patch and tell us if it worked?\n. if you want to mod -n in -b mode you need to use --benchmark-mode 0\n. @Fist0urs can we close this?\n. Great work!\n. great work :+1: \n. Thanks! And I agree, I wish we could switch to setenv()\n. Cool!\n. I'm wondering if 4294967295 is really the VENDOR_Id. I'd say it's probably a -1 return code and they want to say something like \"Parameter unknown/not supported\".\n. Is the algorithm changed somehow or just different length?\n. Please read this this:\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\nPlease answer on all the points listed\n. It seems we have a bigger problem related to this PR. All Intel CPU using Intels OpenCL runtime now return 1 as their preferred vector width. The only way of selecting the best vector width is to use the native one. Any Ideas?\ncc @philsmd \n. I think for hashcat that doesn't work, as we don't do any manual interlacing. OTOH, the PHI performance using CL_DEVICE_NATIVE_VECTOR_WIDTH_INT was pretty good. I'll switch back\n. WPA (-m 2500) is not converted to the new simd code yet. Actually none of the slow hashes is converted.  You can find out by looking on the kernel header for NEW_SIMD_CODE. I'll do that later. In the meanwhile you can test with all the -a 3 kernel, ideally -m 900. This one is converted and should beat JtR's speed on all device type.\n. With latest version from github, it should build out of the box by simplying running make. There's no more depencies now (unless you start cross compiling).\n. @Vladinator Any update here? \n. I've successfully build on RHEL 6.x with latest gihub version. It's simple as it can be. 1. git clone 2. make 3. fun\n. That feature is no longer required with the upcoming version hashcat v3.21 because of the following change:\n- Files: Use $HEX[...] in case the password includes the separater character...\n. In that case you can detect it by reading from right to left.\nOn 29.12.2016 12:34, d2-d2 wrote:\n\n@jsteube https://github.com/jsteube what if separator is also in salt?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/222#issuecomment-269617893,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OX2TEeP7k-TMPwQo5ludWnWgyin0ks5rM5regaJpZM4HZKRl.\n\n\n. @averagesecurityguy @magnumripper you tried in the middle of the autotune integration work, maybe that cause some errors. please retry with latest beta or git version\n. Our first full algorithm PR since we went OSS. Hurray! \n... And it looks pretty good :)\n. Btw, is this somehow related to: https://github.com/hashcat/oclHashcat/issues/81 ?\n. PR Merged, many thanks! Can we close #81 ?\n. Wait, if the function returns 0, then it's not cracked. Therefire I think the code, as it is, is fine. There's no need for extra checks with 12 bytes required.\n. Oh wait, maybe that's what the confusion is coming from:\nif (((out[2] & 0xff00ffff) != 0x30008163) && ((out[2] & 0x0000ffff) != 0x00008263)) return 0;\ndidn't you mean:\nif (((out[1] & 0xff00ffff) != 0x30008163) || ((out[2] & 0x0000ffff) != 0x00008263)) return 0;\n?\nAlso note the changed element number! Because if not, then there's actually only 5 bytes for check\n. Cool, is this for the PHI?\n. Support for hd6xxx series is getting dropped by AMD soon, so we'll not focus on them any longer. We'll optimize only for GPU's that are actually supported. I recommend upgrading your hardware.\n. Excellent, many thanks!\n. In theory, it should be easy to write that mode yourself. See -m 2610 if you need inspiration :)\n. Many thanks for the patch and the example data\n. I don't like the idea of a generic custom algo. JtR has such a \"language\" for CPU but it looks pretty complicated. There's alot of special cases that a user could need, or in other words, it can never be generic enough. Just an example: should the digest be in binary or encoded as ascii hex before hashing again, and if so, should it use lower or upper case. Do we need to truncate it at some point, etc. But the more complicated it becomes, the less useable it is.\nI think if you really need to crack such a special algorithm that is used only a single implementation you should use JtR or your own cracker and if the system that uses that algorithm becomes popular enough we will add it to hashcat anyway.\n. While there's a strong depency on it, that's not really a direct oclHashcat issue. @epixoip Please check this out\n. > I suggest that we should test with a modified/patched ADLODPerformanceLevels (with at least 2 array items) and see if that works without any problems/side effects.\nI think the same, we should do that\n. I agree we should have 2 debugging levels.\nThe first one should \"just\" enable -g, without optimizations and stripping. \nThe second one should be like the first, but additionally enable the sanitizer\nBtw, what about that \"-ggdb\" flag? Does that do any help?\n. There's two major problems in this report:\nA) Appears OP did you understand what --keyspace does. This is essential here.\nB) Parameter -s and -l is not supported in case -i is used.\n. That logfile exists and is build so that it can be parsed by a machine\n. @gm4tr1x can you please answer @philsmd question? Basically, what's the reason for increasing the size of cwd in the restore struct datatype from 256 to 1024\n. OK, change reverted. Thanks!\n. Fantastic, a raw and single iterated SHA1 hash to secure a file\n. Many thanks!\n. Split into #1227 and #1228, therefore closing here. I can't reproduce this. Tested with Ubuntu 15.04 nvidia driver 361.18, git version g94912b3\nroot@ht:~/oclHashcat# ./oclHashcat --weak-hash-threshold 0 --potfile-disable -m 2500 hashcat.hccap -a 3 '?l?lshcat!' --quiet\nhashcat.net:0025cf2db489:b0487ad676e2:hashcat!\nroot@ht:~/oclHashcat# ./oclHashcat --weak-hash-threshold 0 --potfile-disable -m 2500 hashcat.hccap -a 3 '?l?l?lhcat!' --quiet \nhashcat.net:0025cf2db489:b0487ad676e2:hashcat!\nYou maybe forgot to rm -rf ~/.nv and kernels after pull?\n. I think what you're missing here is that in -a 0 mode, oclHashcat supports only plaintext input up to length 32, see here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_is_the_maximum_supported_password_length\nAlso, you should have noticed the rejected counter, which tells you that this happend.\n. Password length for WPA is supported up to length 64\n. See here: https://github.com/hashcat/oclHashcat/blob/master/docs/BUILD.md\n. That's clever, I like it\n. Support for Electrum Bitcoin wallet was added. Only Salt-Type 1 is supported yet. I'll maybe add the other ones when I'm very bored ;). Fixed in latest beta\n. Cool!\n. @RolfHashcat Could you please try with beta 149 from https://hashcat.net/beta/ and close the issue if fixed. Thanks!\n. Thanks!\n. many thanks!\n. This is so hot, instant merge :)\nMany thanks!\n. @Fist0urs There's a new Intel OpenCL runtime version released. Should we retry if the problem still exist?\n. Any update here?. I've pushed a workaround. Tested on my local Intel CPU: https://github.com/hashcat/hashcat/commit/3baec81d90c6046e42a6d10a40adda770d525826. Awesome! Many thanks!\n. There's currently no tutorial on how to add new hash-modes (I really should do that at some point). But several people managed to do it without. Just checkout the commit logs to find some of them.\n. I just added sha1($salt1.$pass.$salt2) with commit https://github.com/hashcat/hashcat/commit/23917455efad1deba8c12516e192238f1609d8b7\nShould be easy enought to replace the sha1 with md5. Excellent! Many thanks\n. From all the documents I've found so far, the maximum password length for ArubaOS seem to be 64, not 32. This is confusing, what's the right value? I'm currently refactoring password length related kernels and therefore it's important ot have the correct value. I'll reject this as I don't see any advantage for hashcat. Also, in case of PasswordsPro updates it's default ruleset, who's going to update it then?\nThere's 2 things to consider:\n- Change JtR parsing/handling code for [ in case \"!! HashCat logic ON\" is used.\n- Change your default loading behavior for rules to what you call \"HashCat logic\" and create \"JtR-old logic\" you can use for your old default rulesets. That would make all rule handling of all tools compatible to each other. Background for this is that hashcat logic isn't hashcat logic, it's based on PasswordsPro.\n. It's good to know you were able to compile it from Windows directly. We actually use the win* targets only for cross compiling from linux. If you want to send in some PR, your change should affect the \"native\" target. That would be great!\n. What exactly do we have to do?\n. This is already supported with mode 4800:\n4800 | iSCSI CHAP authentication, MD5(CHAP)             | Network Protocols\nExamples:\nroot@ht:~/hashcat# ./hashcat -m 4800 9920418b3103652d3b80ffff04da5863:00000000000000000000000000000000:02 -a 3 ?l?l?l?l?l?l?l?l --quiet\n9920418b3103652d3b80ffff04da5863:00000000000000000000000000000000:02:bradtest\nroot@ht:~/hashcat#\nroot@ht:~/hashcat# cat hash\n1ffc6c2659bc5bb94144fd01eb756e37:d7ec2fff2ada437f9dcd4e3b0df44d50:02\nroot@ht:~/hashcat# ./hashcat -m 4800 hash -a 3 beaVIs --quiet\n1ffc6c2659bc5bb94144fd01eb756e37:d7ec2fff2ada437f9dcd4e3b0df44d50:02:beaVIs. > It say that \"Shader Model 1.0 - 1.3 Based GPU Detected\".. What version you recomend use?\nYou can not change the Shader Model, because it's a version tag of your Hardware. NVidia dropped support for those old cards, therefore it's not an issue with oclHashcat.\n. Please use hashcat forum for this kind of questions: https://hashcat.net/forum/\n. pocl works fine for me, both the version from ubuntu's repo as well as the self compiled one\n. Do I need a special version to reproduce, because if I can not reproduce this, I can not fix it. Since this is somehow related to CPU I think this is not related to the mesa thing discussed in the PR, right?\n. I'm having problems to build latest pocl github master on ubuntu 16.04. Too bad it doesn't have it's owne ubuntu package anyway.\n. I don't know, for example:\nA0`01`  orig: ^1 ^0\nA0`01`  orig: ^1^0\nThis would be invalid in hashcat.\n. What other types of rule removal does your script support? \nDid you check other rules files than dive.rule?\n. The logic behind the x and O rule changed recently, that may explains it\n. We just found something that is at least \"suspicious\". Can you please verify it's correct?\nHere's an example: You've removed the following both rules:\n^}\n^ }\nThe thing is that those are two complete different outcomes. The first is just one function calls and the second has two function calls. Funny :)\n. I'll revert the change on dive.rule regarding the sed issue. But I can't yet merge the new PR because it doesn't take into account that oclHashcat does not support all function hashcat (CPU) supports.\n. WOW this is getting compliated :) You've remove the PR, which is fine. Are you going to create a new one?\n. dive.rule was created automatically\n. OK, merged\n. What's the next step?\n. I'm a bit confused, do you plan to send in another PR?\n. While looking at some of the optimization, here's one type that I find a bit suspecious:\nsZEsEd  turned into sZd\nNow that looks fine at this point, but if you have a word in your wordlist which contains 'E' the results of the optimized rule is different to the original one.\nAnyway, I think this would be an edge case and I think I'll merge anyway. I'll think about\n. OK, please undo that specific undupe logic.\nDo you plan to  apply the fewest-function-calls-first optimization on all rules or just dive? If it's just dive, go for it. For other ones, especially the hand-written ones, it's maybe not ideal because the author maybe had a specific reason to sort it in the way it is.\n. I'll reject the PR as suggest. Please send in a new one when you have time\n. definitely  $6$6$6 and  $6$6$6$6\nall about easy to read :)\n. I full agree, such a script is not easy. Anyway, thanks for your effort. Please continue with it.\n. > There are many that simply have no op stuff in them, such as i0x$a[ ...\nI found the example interessting. Are you going to remove the useless work here?\n\n... and completed rule set so that you can look at it offline.\n\nHow would I check through 25% removed rules manually. I could do only a few random picks and I'd need to have something to compare, so I'd need at least 2 rules. However, you already said it's 100% correct above, I'll simply trust in that and going to merge.\n\nBut now, when this all gets done, there will be a little over 98k rules in dive. I think that's about 25% down from where it started. Still the same ruleset. \n\nGreat work, really\n. @jfoug What's the status with the issue? I think you've corrected all the \"generated\" rulesets, right?\n. I plan to release hashcat 3.00 somewhere within this month. Do you think it's the rules, as they are right now, are good to release or do you want to run some tests on them?\n. I think a solution based on the use of a reference wordlist can not be used to automatically remove duplicate rules, but it that doesn't mean it's not useful. Such a program can give good additional ideas how to find possible duplicate logic in a rule. It just requires a person to interpret the rule and to decide if this rule will work with all wordlist input or not. If yes, it can be added to @jfoug's tool.\n. @jfoug @0xbsec Are you planing to do any more changes to this or can we close this issue?\n. OK, I thought the same. Anyway, very good work on this and many thanks for your guys support!\n. That section looks like an incomplete refactorization of an older pre-OSS phase. There's two ways to fix it: Remove the branch or add the same branch to the unlock() a few lines below. Since I agree to OP here I'll remove it by commenting it and we'll see how it goes. If it turns out it was necessary we'll remove the comment and add another branch.\n. This looks almost good. Can you please try to put it into include/kernel_vendor.h instead? That's where the extensions usually are called from. If that's not possible, for whatever reason, please tell me and we'll merge it as it is\n. Thanks!\n. @neheb Can you please test if it's still working on LLVM\n. Cool! Thanks!\n. This seem not to be correct. For example, If you don't want to use amd_bfe(), why do you check for \"cl_clang_storage_class_specifiers\" and not simply \"amd_bfe\" ?\nThe or of cl_clang_storage_class_specifiers in combination with DEVICE_TYPE may work but is hard to understand. I think we have to find a cleaner way to handle this.\nCan you tell me how I can make use of LLVM like you do use it here? Maybe I can help finding a proper way.\n. Cool I really have to try that. How's the performance compared to fglrx?\n. I'm still not 100% happy. \nNote that rotate() is not part of cl_amd_media_ops, it's a basic OpenCL 1.0 standard: https://www.khronos.org/registry/cl/sdk/1.0/docs/man/xhtml/rotate.html\nIt's weird that an OpenCL runtime does not include it, it totally should!\nAnother thing is:\n```\nifdef cl_amd_media_ops\nreturn amd_bfe (a, b, c);\n\n```\nIt should be:\n```\nifdef amd_bfe\nreturn amd_bfe (a, b, c);\n\n```\nThen there's:\n(DEVICE_TYPE == DEVICE_TYPE_CPU) || !defined (cl_amd_media_ops)\nFirst thing is that we try to avoid NOT cases, so we try to avoid '!'. Another thing is that we try to avoid && and || in branches. This makes exception handling easier. Please rewrite it to have two seperate branches for this (use 2x if()).\n. All right yes I think that's good, many thanks! I should totally try to get the same setup running as you have so that we can make it compile by default.\n. Wait, they have a 130 byte long salt on start? hihihi I guess they didn't read my post about how not to salt a hash :) https://hashcat.net/forum/thread-4429.html\nPlease give us an exact number for the salt length range\n. The null byte shouldn't be a problem. You can encode the salt in hex and use --hex-salt or we're creating a special parser for the mode. I'd recommend the 2nd in case the different salts are not concatinated into a single long string.\n. you need to create a new kernel to make and because of this you can't use the -m 140 address space for it. use the next free -m\n. i can help you with the kernel details once you pushed the parser and kernel template\n. OK I've added kernel functionality and other host changes so that it should crack now: https://github.com/hashcat/oclHashcat/commit/aef8dc2b0181d865b8f684c9e3af4fd9dba81012\nWhat's still missing is the verify functionality in the test.pl. Please add it so that this kernel integration can be called \"finished\".\nHere's a screenshot seeing in action: http://pastebin.com/QzkVfCyh\n. It was just minor changes to your code, nothing to worry. The verify command is used to check an existing hash and a known password to be \"correct\". The important part here is that the verify command uses the salt (which usually changes per hash) is used as salt in the calculation of the hash. Otherwise you can't check for correctness. So if you want to know if your change worked correctly just create two files. 1 with just the hash, then another one with that hash with and the salt appended and then let run the verify command\n. If you send in a PR of what you've done so far i can finish it\n. OK, should be done now. Thanks for the PR. I also had to patch a small bug when running on AMD.\n. Wait, we can't really replace 'd' with 'M' because all memory store operations like 'M', '4' and '6' . They are not support in oclHashcat\n. Thanks, good work!\n. I'm pretty sure other user have the same problem then. We need to fix this before other users went into the same problem. My first try to fix would be to edit the tuning database. Please edit hashcat_tuning.hctab.\n- Find the line\n  Iris                                            *       1800    1       1       16\n(Note github throws out some spaces here, I hope it's clear what I mean)\nTry to set the '16' value to '1' and try if the problem still occurs\n. @gm4tr1x OP is not responding. Can you test please?\n. @gm4tr1x Do you think we can close this issue?\n. Problem fixed\n. You need to create a new hashmode and a new kernel for it. There's no way around. From my experience with new hashmode support you propably wont get much help unless the algorithm is used in a popular application or is important for some other reason. That's why you should always name the application where this algorithm is used in.\n. Buying such a kernel would cost you several thousand dollars because there's only a few people who can do that. But why buy it if you can get it for free. You just need to provide all the information behind your request and the system using it. This way everyone can use it afterwards.\n. OK so this isn't really about a new algorithm, it's generally more like you want to have a longer salt support. This is something people ask often, but not related to SHA512. It's not too hard to add but it's also not very high priority for me. Whoever wants to add this, feel free to do so.\n. Btw I've just added a new mode -m 13800 to crack Windows 8+ phone pins/password -- it's basically sha256 with a fixed 128 byte salt, so the same problem you have. You could hack it to do sha512 instead.\n. It's a good start, but we have to do some changes:\n- First I'd like to move the hashmode from 134 to 13500 (I'll reserver that for your hash-mode).\n- Then I've seen that you've used parse_and_store_salt() to store the salt. This is invalid in your case, as the salt is so long. Also note that the salt_buf in salt_t is limited to 64 byte, so you've propably already overwrote it.\n- To make this correctly, you first need to define a new esalt (external salt) and give it enough space to handle it. Like 512 byte. Note that you have to work with 32 bit integers so you need to create something like u32 buf[128].\n- After that you need to create the space for the salt, see other algorithms like 13400 in how to do that. \n- Next you need to store the salt into this esalt manually and without parse_and_store_salt. There's also plenty of examples in other parser functions. \n- Finally I'd suggest to copy at least 16 byte of that salt into the original salt_t salt_buf because based on that it will find if a hash is unique in some internal sorting routine\nAfter this is done we can start with the kernel code\n. That looks much better. Following things are missing:\n- Code in ascii_digest(). This function is responsible for generating the output string. It's very important to generate 1:1 the same output string as the input string is. \n- Add unit testing code in test.pl and test.sh.\n- You use memcpy for the salt buffer, but you'd actually have to decode the hex data first. something like this:\n  for (i = 0; i < salt_len / 2; i++)\n  {\n    out[i] = hex_to_u8 ((const u8 *) &salt_pos[i * 2]);\n  }\n- You marked the hash with the option OPTS_TYPE_ST_ADD80 but using OPTS_TYPE_ST_ADD80  makes sense only for schemes like sha1($pass.$salt) where the $salt comes after the $pass. I think what you want to use is OPTS_TYPE_PT_ADD80. But note this will work on -a3 kernel only automatically. For -a0 and -a1 you have to do it in the kernel.\n. If you want I can merge and finish the kernel\n. OK, waiting for your \"go\"\n. Please don't use * here\n```\ndefine DISPLAY_LEN_MIN_13500 40 + 1 + 16 * 2\ndefine DISPLAY_LEN_MAX_13500 40 + 1 + 512 * 2\n```\nSimply do:\n```\ndefine DISPLAY_LEN_MIN_13500 40 + 1 + 32\ndefine DISPLAY_LEN_MAX_13500 40 + 1 + 1024\n```\nSorting of this:\n13400,\n13500,\nShould be:\n133,\n13500,\nYou're still using an invalid option for the salt which you need to remove:\n| OPTS_TYPE_ST_ADDBITS15;\nThe following optimization is not possible since our data buffer is > length 55, you need to remove it:\n| OPTI_TYPE_PRECOMPUTE_MERKLE\nThis code:\nmemset(pstoken_tmp, 0, mysalt_len + 1);\nIs wrong in two ways. First you should use sizeof():\nmemset (pstoken_tmp, 0, sizeof (pstoken_tmp));\nAnother problem is that you're using a value which is unknown at compile time to declare a number of elements in an array.\nInstead of:\nu8 pstoken_tmp[mysalt_len + 1];\nYou should do:\nu8 pstoken_tmp[512 + 1];\nMore problems with snprintf():\nsnprintf((char *)(pstoken_tmp + i), (size_t)2, \"%02x\", pstoken->salt_buf[i]);\nProblem 1, the \"%02x\" does not match salt_buf[] which is 32 bit, not 8 bit. You propably need to something like this befoire you can use it:\n```\nu8 salt_buf_ptr = (u8 ) pstoken->salt_buf:\n... and then use salt_buf_ptr[i] in the snprintf()\n```\nProblem 2, the casting of pstoken_tmp from u8 * -> char * is not necessary. \nJust declare pstoken_tmp as char *.\nSuggestion:\nThe use of snprintf() is slow, take a look bin_to_hex_lower (). This is not always useful but sometimes it is.\nInside the parser you do:\n```\nu8 pstoken_tmp[DISPLAY_LEN_MAX_13500 - 40 - 1];\nmemset(pstoken_tmp, 0, DISPLAY_LEN_MAX_13500 - 40 - 1);\n```\nI'd recommend to use the same declaration as in ascii_digest instead:\n```\nu8 pstoken_tmp[512 + 1];\nmemset (pstoken_tmp, 0, sizeof (pstoken_tmp));\n```\nThis optimization does not work here, because we need a 2nd call to sha1_transform because of the length > 55. You need to remove it:\ndigest[0] -= SHA1M_A;\ndigest[1] -= SHA1M_B;\ndigest[2] -= SHA1M_C;\ndigest[3] -= SHA1M_D;\ndigest[4] -= SHA1M_E;\nThat was easy stuff so fow, but now in test.pl it's getting real problematic. From your original issue you said:\n\nWould love to see a new mode added for that. There is one for the application password, but if we could get a sha1($salt.utf16le($pass)) to break the SHA1 signature of the token, that would be great. The salt length is very long, 130-150bytes, so we can't really use any existing mode.\n\nWhat you totaly did not mention is the use of DES inside the algorithm. Now I'm very confused. Please explain in words how DES is involved in the process. It's important to write a proper kernel.\n. I'll now rewrite the kernel and inform you when I've pushed a working version\n. Another ~250 removed. Great work!\n. This is crazy. Can I merge? How many rules did you remove in total?\n. > However, before I proceed with this, we need to make a call on whether we should change all of the xNM commands to ONM I think so. \nI think changing the xNM to ONM is the right way as the dive.rule was created back when xNM what is today ONM. Go for it!\n\nYou might want to keep both flavors, in case there are people running older versions of HC, where the x still means omit.\n\nI'm not so much about supporting old rules. We don't need to care about that case.\n. Sounds like a lot of work. What's the default algorithm?\n. Not a bug, just use \"c\" instead of \"q\" when stopping a session\n. What hashcat deps are you talking about? There should be none left with latest version, see here: https://github.com/hashcat/oclHashcat/blob/master/docs/BUILD.md\nAnyway about your issue, this sounds like some local installation error or broken hardware. Please try again with our precompiled betas to be sure it's not a compilation (and depency) error on your host. You can find them on hashcat.net/beta\n. There's no such file anymore since a long time. I think you're also using an outdated github version\n. Does example400.sh work?\n. >  just did a clean install of Ubuntu 16.04, the nvidia driver 361.42 and\nI'm using the same setup and it works pretty good. I'm however using the .bin from Nvidia site and not the driver that comes with Ubuntu. There's a small chance that this creates problems.\n\nsudo apt-get install nvidia-opencl-dev\n\nI'm using the original one from Khronos but I don't think it will make any difference. But it's worth a try so purge nvidia-opencl-dev and add:\nocl-icd-dev\nocl-icd-opencl-dev\nopencl-headers\nocl-icd-libopencl1\n\nSame issue as well as with 500\n\nSo you're propably having problems with _a0 kernels. Does -a 3 work?\nAlso try this:\nrm -rf ~/.nv\nand in oclHashcat directory:\nrm -rf kernels\n. NVIDIA-Linux-x86_64-361.18.run\nMaybe try -d 1 too\n. Thanks :)\n. See Issue discussion\n. I can see a print in there, guess it's some debugging print. Will remove it afterwards. Thanks!\n. Thanks!\n. > I am not 100% sure for oclHashcat on the usage of rejection logic. \nFor GPU, there's no rejection rules. That's mostly because of the traditional goal to crack fast hashes instead of slow ones. The rule engine was simply faster not to create branches for rejections rather than to check them.\nPlease continue to send PR for the other rules.\n. I see what you mean, but it's actually correct like it is. The 8900 is the kernel used by both, 8900 and 9300. It's a bit confusing, tho\n. That's something :)\n. We can place a fixed umask inside hashcat, what you think?\n. @bjornfor That was my thinking actually. It wouldn't be too bad to affect all files. Do you see any files in which case it would create problems?\n. I still think about using umask(). It maybe is a \"big hammer\" but it's a fitting one. I don't see a reason why not apply umask on all created files. Anyone has an idea?\n. I've set the umask now. Let's see if someone complains :)\nhttps://github.com/hashcat/oclHashcat/commit/f5ee678bbeec0b4565ca23f3998977f5d3edf447\n. Thanks!\n. GMP is not required for hashcat 3.00 anymore\nSo with both of the other devices it works just not with the nvidia gpu ?\n. Please try to find out which paths are searched. I don't know how to do that on OSX, on Linux I'd use strace\n. Yeah but I can't fix it without being able to reproduce\n. I think the Problem discussed here is the same one as in https://github.com/hashcat/oclHashcat/issues/345\n\n... It's a bug in the OpenCL runtime of nvidia. We can't do anything on it. You can try reporting the problem to the vendor, but sadly from my experience they will ignore you if it's about GPGPU and not games.\n. Maybe some can please pull latest version from github and retry? I don't have much hopes that this one fixed it but it's worth a try.\n. This issue should be fixed, please make sure to use latest github version\n. Problem fixed\n. notice debug-mode is about rule debugging, not process debugging\n. So that means there's no problem? Self-Healing? Can we close this?\n. done https://github.com/hashcat/oclHashcat/commit/567fcfe176e17e7e9363742d15837d0092a6a8fe\n. What's the problem here?\n. try this one please:\n\nhttp://hashcat.net/misc/example_hashes/hashcat.hccap\npassword is hashcat!\n. Fixed:\nroot@sf:~/hashcat# ./hashcat -m 2500 hashcat.hccap -a 3 'hashcat!'\nhashcat (v3.00-beta-29-g18f05e9) starting...\nDevice #1: Hawaii, 2858/4025 MB allocatable, 1010Mhz, 44MCU\nDevice #2: AMD FX(tm)-8120 Eight-Core Processor, skipped\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n- Brute-Force\n- Slow-Hash-SIMD\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger set to 80c\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nhashcat.net:b0487ad676e2:0025cf2db489:hashcat!            \nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (hashcat!) [8]\nHash.Target....: hashcat.net (b0:48:7a:d6:76:e2 <-> 00:25:cf:2d:b4:89)\nHash.Type......: WPA/WPA2\nTime.Started...: Tue May 17 18:22:53 2016 (1 sec)\nSpeed.Dev.#1...:        0 H/s (0.64ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nHWMon.GPU.#1...:  0% Util, 37c Temp, 20% Fan\nStarted: Tue May 17 18:22:53 2016\nStopped: Tue May 17 18:22:56 2016 \n. I just removed this stuff with a previous commit: https://github.com/hashcat/oclHashcat/commit/c6e5ff2a68b21572d54c2577e415e74768465313\nWhy bring it back? I thought it's important to have the data output as plain as possible so that there's no need to cut away the header....\n. The goal is to have the users download it from Github, not from the website. I just removed them because we're soon to release hashcat v3.00 (fusion of hashcat and oclHashcat)\n. The reason for removing the tags is because we're using this in our Makefile:\ngit describe --tags --dirty=+\nWhen I've added a new tag 3.00-beta it was there, but it still was using 2.01. We need a solution for that (maybe misuse?).\n. I think you don't understood what I mean. I have to remove old tags to make the process using git describe --tags for compilation. That's why it's propably a bad idea to use this kind of information for packaging.\n. OK. Do you have any idea how to restore the deleted tags?\n. I've restored the old tags as you described, that worked fine, thanks for that!\nI then tried to reproduce the problem I had -- but I can't anymore. I'm sure it was like that it always showed the oldest tag. In this case that is 3.00-beta because from git's view it's the oldest at this moment. When I'm right, then that means when we'll move to 3.00 release it should still show 3.00-beta.\nI'm not getting fully the other idea you had. What I'm basically looking for is that it uses the latest git tag plus the git describe hash (important for beta versions)\n. Thanks for help. I think we can close this as the original issue with the deleted tags is close. Continue on PR\n. I'd think it's much more easy to create a hash-mode md5(md5($password).md5($salt) ); because this forces the length to exact 64.\n. > ... but this algorithm is already supported by 3910 , am i correct ? It will not work in this case.\nIn Hashcat maybe, but not in oclHashcat. Why isn't it working? It's exactly what you've described\n. @magnumripper you sure about that? He said:\n\nthe salt is a md5 like value, created from the surname\n\nIf we make it generic, and the length is known to be 32 or more, then the mode must be implemented with a second transformation. In such a case, the length of the salt always must be at least of length 32 which is too strange for a generic mode. Therefore I think it's better to have a named hash-type and then we need to know which appliation uses this.\n. @xinhuang You should be able to load this hash already with latest version when using mode 2611. Should work fine using -m 2611. Should be fixed, thanks for report\n. Yeah but it's a bug in the OpenCL runtime of nvidia. We can't do anything on it. You can try reporting the problem to the vendor, but sadly from my experience they will ignore you if it's about GPGPU and not games.\n. @arnaudsj is the problem fixed with latest github version? please retry\n. OP not responding, closing issue\n. So when I'll add the new tag \"3.00\" when we'll release, for that particular version, then it will use that and just use \"v3.00\" and not \"v3.00-1-gxxxxxxx\"?\n. Thanks for the PR!\n. It creates an error (on my Ubuntu install):\n/bin/sh: 1: Syntax error: \"(\" unexpected\nWith the result: -DVERSION_TAG=\\\"\\\" \n. It's from the git checkout. Had to revert\n. Thanks for your contribution!\n. This is not like DES or RC4 ciphers of which a complete search through the entire keyspace would be possible. Therefore there's no sense in this request. People don't use Passwords in combination with AES directly, there's always a KDF in between. KDF's are supported with hashcat.\n. But its clearly a problem inside the OpenCL runtime, so not hashcats fault. Do you think it's correct to place it here?\n. If you rename --status-automat to --machine-readable you'd rename the variable (and macro) from status_automat to machine_readable, but not status_machine_readable. Please fix.\n. Thanks!\n. Thanks!\n. Not hashcat's fault, it's crashing somewhere inside the OpenCL runtime. Make sure you have AMD driver 15.12 (not higher) installed.\n. > A warning should be added and --force required.\nOK, but how exactly can we recognize that case? Is there any OpenCL device-specific parameter?\n. @CthulhUzzz since I can not reproduce this error, can you please try to find out which initializer is creating the problem?\n. @CthulhUzzz Since the error is unknown, I can't give you any specific instructions. You need to find out yourself by change code in ther kernel.\n. I've fixed this so that shows a warning:\nDevice #1: Hawaii, skipped\nDevice #2: WARNING: not native intel opencl runtime, expect massive speed loss\n           You can use --force to override this but do not post error reports if you do so\nDevice #2: Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, skipped\nand with --force you should be able to use it. \nHowever, it's recommended to use intels opencl sdk, which is almost twice as fast. Please close the ticket if ok for you\n. I can't reproduce, don't have that card. \n. Basically everything looks good for me. Also the benchmark speed matches exactly the real speed (you have to use one hash of course, not many). If you do not create enough amplifier you can't get out enough speed. Please read this and the following sections: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n. I didn't plan to add this feature, sorry. You can easily rebuild it yourself using hashcat-utils combinator.bin \n. Thanks!\n. I'm confused. What is this doing and why. Are you saying you tried to build on windows with mingw and it worked?\n. Thanks!\n. Dynamic hash modes with hashcat is currently not planed. While such a thing is not impossible to do, I think kernels are easy enough to make a new custom mode if it's required.\n. I'm wondering what kind of invalid build option it complains about. Does anyone know it?\n. OK, to pack this together: This compiler error only occurs in case of OSX 10.9.5 and only for the Iris Pro, is that correct?\n. OK, but since I can't fix this because I don't have that device with that OSX and since it's an error that occurs only for old OS I can't do anything to fix this. I'll close the issue, but for everyone stumbling on it, feel free to reopen and fix it.\n. Try again with a single word in the wordlist\n. Can you please retry with latest version?\n. OK, pushed a new version with a dynamic tmp_t salt length. That one should fix it.\n. Thanks for reporting and testing :)\n. Thanks!\n. I always wondered what DESTDIR is used for, saw it couple of time. Makes sense, thanks!\n. Can you give us an example hash:salt:plaintext pair please? Ideally please also add the algorithm which is used with some pseudo-code like: md5(sha1($pass).$salt) or whatever it is.\n. Excellent Information, thanks! I think I understand the algorithm so far. \nDid you generate the attached pcap files yourself? If possible, could you please send me two more pcaps but with the following password: \"hashcat7hashcat7\" and \"hashcat7hashcat7Z\". I think i found another flaw, yet unknown, just by looking at the specs. If I'm right it will work for Oracle12+ as well.\n. Thanks! It works! See here:\ngithub.pcap:\n00001040: 0d0d 4155 5448 5f50 4153 5357 4f52 4401  ..AUTH_PASSWORD.\n00001050: 4040 3545 4343 3835 3545 3839 3430 3233  @@5ECC855E894023\n00001060: 3433 4437 3543 4138 3436 3330 3232 3245  43D75CA84630222E\n00001070: 4330 4236 3737 3932 3943 4646 4445 3931  C0B677929CFFDE91\n00001080: 4642 3046 3245 4133 4244 4345 4544 4141  FB0F2EA3BDCEEDAA\n00001090: 4539 0001 0d0d 4155 5448 5f54 4552 4d49  E9....AUTH_TERMI\nhashcat7hashcat7.pcap:\n00001040: 0d0d 4155 5448 5f50 4153 5357 4f52 4401  ..AUTH_PASSWORD.\n00001050: 60fe 4032 3636 3434 4339 4439 3636 3932  `.@26644C9D96692\n00001060: 3744 3130 4142 4138 3144 3636 3736 4642  7D10ABA81D6676FB\n00001070: 4243 3446 3238 4234 4434 3246 3033 4336  BC4F28B4D42F03C6\n00001080: 3842 3338 3534 3730 4342 4535 3744 3030  8B385470CBE57D00\n00001090: 3346 3120 3032 4432 4639 4144 3039 3643  3F1 02D2F9AD096C\n000010a0: 3333 3642 3635 3243 4344 4233 4433 3442  336B652CCDB3D34B\n000010b0: 4645 3533 0000 010d 0d41 5554 485f 5445  FE53.....AUTH_TE\nThat was exactly what I've expected. The flaw is the following: Because the client has to encrypt the plaintext passsword the size of the AUTH_PASSWORD will change whenever the password exceeds the length 16 or more. That is because AES works on 16 byte blocks. That way, we as an attacker, can tell that the password must have the length 0-15 for the first packet and 16-31 for second packet. This is worthy information because of the password is actually 16 or more, we know we can't brute-force attack it and save the time and power.\n. Now I'm wondering, if we can force the password to be utf16, it would make sense to create a fake oracle server responder. If we can force the client to convert the password to utf16 before encrypting, we can tell if the password has the length 0-7, 8-15, etc. that would be even more nice...\n. @magnumripper Yes format is excellent. \nWhat I'm wondering is if it will work with Oracle 12. Because if you do the check correctly, that means by not trying to exploit the 0x08080808... padding, then I see no reason why it's not working with Oracle 12. And the trick I found will also work for Oracle 12. Problem is I don't have any Oracle 12 Database to try...\n. I still found no one with Oracle 12 answer my questions, which is kind of important because it decides which way to go with the implementation. There's two ways, the first one, by testing the 0x08080808 padding, but that one works only for a very small range of version of ORacle 11g so I don't see any good reason to implement it. The other reason to implement it \"correctly\", that is including the double MD5 calls. I've written a poc in perl and it works fine. By doing it that way I think we can make the it work with Oracle 12, too. But that's something no one yet were able to approve or verify.\n. @jackpit110 Do you have a chance to create a pcap of a connection to a oracle 12 database?\n. OK cool it works. Wondering if Oracle felt back into some backward compatibility mode when using an oracle11 client. Can you please try, with this client, to connect to the server by using the password \"3\", \"C\" or \"D\"? It seems the protocol causes some false positives\n. Forget the last request, was my fault in my poc. Anyway I can successfully decrypt it so I'll start implementing this one next. \n@magnumripper I'll use  your format suggestion: $o5logon$  *  *  * \nI'm planing to call the format \"Oracle 11+ CRAM (o5logon)\"\n. @magnumripper While implementing it turns out there's a bug in your format. Instead of\n$o5logon$<server's AUTH_SESSKEY>*<AUTH_VFR_DATA>*<AUTH_PASSWORD>*<client's AUTH_SESSKEY>\nit should be:\n$o5logon$*<server's AUTH_SESSKEY>*<AUTH_VFR_DATA>*<AUTH_PASSWORD>*<client's AUTH_SESSKEY>\nShould be easier to parse and you already do it like that, for example with zip2\n. @jackpit110 I've posted it here: http://pastebin.com/Qb4PEVk0\n. Guys I didn't follow in detail, is this just about how to extract the username? And is this a \"true\" ORacle 12 connection (Oracle 12 client and server)?\n. @jackpit110 which pcap are you using? The oracle12 pcap you send me worked well for me with my perl\n. You're using a way too old hashcat host program. I can see it from the build options, which looks very different in current version. Pull master, make clean, make uninstall then try again\n. Please try again with latest master and close the issue if fixed. Thanks for reporting!\n. Try\n$ gcc -o libXNVCtrl.so -shared libXNVCtrl.a\nNot sure if it will work on arch, Ubuntu has its own package for that.\n. You can also turn it off by setting --gpu-temp-retain to 0\n. 361.42\n. Please try again with latest master and close the issue if fixed. Thanks for reporting!\n. please try again with hashcat 3 beta: https://hashcat.net/beta\n. Can not reproduce with my 290x:\nroot@sf:~/hashcat# cat word\npassword\nroot@sf:~/hashcat# cat rule\n$1 $2\nroot@sf:~/hashcat# ./hashcat -m 400 '$P$987518464/xFmp7w2mrJ9iZlX3eT1e0' -r rule word --potfile-disable --quiet\n$P$987518464/xFmp7w2mrJ9iZlX3eT1e0:password12\nPlease try with my command\n. yes please\n. atom@hashcat.net\n. Didn't get anything\n. ok got it, thanks. looking into it\n. OK, found the reason. It's not really a bug, it's a feature :) \nWPA has minimum password length of 8, but the word in dict.not.work.txt has length 7. That's why it's rejecting it. You can see it in status screen:\n\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 6/6 (100.00%)\nRejected.......: 6/6 (100.00%) <--- here\n. you can not disable it, but you can workaround, which is the best way to do this attack anyway:\n./hashcat --stdout -r 2digits.adding/test.rule 2digits.adding/dict.not.work.txt | ./hashcat -m 2500 2digits.adding/hash.hccap\n\nthis works on windows, too\n. You're welcome\n. Code was destroyed\n. Thanks!\n. Thanks!\n. Thanks!\n. It's a compiler error, not hashcat's fault. Ther error \"Error getting function data from server\" can be found numerous times on the web, it seems no one know about a workaround.\n@magnumripper I see JtR had to deal with this kind of error, too. Did you found a workaround?\n. So this is clearly some OSX OpenCL runtime issue. I don't see a way to workaround this, therefore closing the issue. Thanks @magnumripper for explanations.. This is a huge commit, many thanks! Actually there's not much I have to comment, just a few changes:\n\nmake win64API win32API linux64API linux32API\n\nDoes that mean that there's no support for the native and/or osx target?\n\ninclude/CL/*\n\nI saw you accidentially added the opencl-headers to the repository. Please remove them. We describe in BUILD.me how to install them.\n\nsrc/hashcatAPI.c\n\nTwo things here:\n1. Can you please rename it to hashcat_api.c\n2. Can you please use the format used describe in the contribution section on here? https://github.com/hashcat/oclHashcat That is like allman-style format etc.\n. OK, something is odd. I made two tests and both failed :(\n- Trying to run on windows. Compiled with win64API target. Result:\nd:\\tools\\hashcat-3.00>hashcat64API\n[*] Starting API Test.\n[!] hashcat starting in the background\nUSAGE: [q]uit [S]tatus\nsS\n[ERROR] status update not available\nEither hashcat has not fully started yet just wait a couple of seconds\n Or there is an arg error. Check your settings and use -DDEBUG flag.\nI then waited for around a minute but nothing changed\n- Compiling on linux fails:\n``\nroot@sf:~/hashcat# make nativeAPI\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/ext_OpenCL.NATIVE.o src/ext_OpenCL.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/shared.NATIVE.o src/shared.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/rp_kernel_on_cpu.NATIVE.o src/rp_kernel_on_cpu.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/ext_ADL.NATIVE.o src/ext_ADL.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/ext_nvapi.NATIVE.o src/ext_nvapi.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/ext_nvml.NATIVE.o src/ext_nvml.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON -c -o obj/ext_xnvctrl.NATIVE.o src/ext_xnvctrl.c\ngcc -D_POSIX -DLINUX -s -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -DHAVE_HWMON    -DAPI -lm -o hashcat src/hashcat.c src/hashcat_api.c obj/ext_OpenCL.NATIVE.o obj/shared.NATIVE.o obj/rp_kernel_on_cpu.NATIVE.o obj/ext_ADL.NATIVE.o obj/ext_nvapi.NATIVE.o obj/ext_nvml.NATIVE.o obj/ext_xnvctrl.NATIVE.o -lpthread -ldl -DCOMPTIME=1466620722 -DVERSION_TAG=\\\"v3.00-beta-253-g8e5004d\\\" -DINSTALL_FOLDER=\\\"/usr/local/bin\\\" -DSHARED_FOLDER=\\\"/usr/local/share/hashcat\\\" -DDOCUMENT_FOLDER=\\\"/usr/local/share/doc/hashcat\\\"\n/tmp/ccNqs8FF.o: In functionhcapi_generate_commandline':\nhashcat_api.c:(.text+0x2217): undefined reference to log10'\nhashcat_api.c:(.text+0x221c): undefined reference toceil'\nhashcat_api.c:(.text+0x2740): undefined reference to log10'\nhashcat_api.c:(.text+0x2745): undefined reference toceil'\nhashcat_api.c:(.text+0x2883): undefined reference to log10'\nhashcat_api.c:(.text+0x2888): undefined reference toceil'\nhashcat_api.c:(.text+0x296e): undefined reference to log10'\nhashcat_api.c:(.text+0x2973): undefined reference toceil'\nhashcat_api.c:(.text+0x2a4c): undefined reference to log10'\nhashcat_api.c:(.text+0x2a51): undefined reference toceil'\nhashcat_api.c:(.text+0x2bec): undefined reference to log10'\nhashcat_api.c:(.text+0x2bf1): undefined reference toceil'\nhashcat_api.c:(.text+0x2caa): undefined reference to log10'\nhashcat_api.c:(.text+0x2caf): undefined reference toceil'\nhashcat_api.c:(.text+0x2ed3): undefined reference to log10'\nhashcat_api.c:(.text+0x2ed8): undefined reference toceil'\nhashcat_api.c:(.text+0x2f91): undefined reference to log10'\nhashcat_api.c:(.text+0x2f96): undefined reference toceil'\nhashcat_api.c:(.text+0x337e): undefined reference to log10'\nhashcat_api.c:(.text+0x3383): undefined reference toceil'\nhashcat_api.c:(.text+0x3469): undefined reference to log10'\nhashcat_api.c:(.text+0x346e): undefined reference toceil'\nhashcat_api.c:(.text+0x3524): undefined reference to log10'\nhashcat_api.c:(.text+0x3529): undefined reference toceil'\nhashcat_api.c:(.text+0x35fd): undefined reference to log10'\nhashcat_api.c:(.text+0x3602): undefined reference toceil'\nhashcat_api.c:(.text+0x3767): undefined reference to log10'\nhashcat_api.c:(.text+0x376c): undefined reference toceil'\nhashcat_api.c:(.text+0x3822): undefined reference to log10'\nhashcat_api.c:(.text+0x3827): undefined reference toceil'\nhashcat_api.c:(.text+0x41ef): undefined reference to log10'\nhashcat_api.c:(.text+0x41f4): undefined reference toceil'\nhashcat_api.c:(.text+0x442f): undefined reference to log10'\nhashcat_api.c:(.text+0x4434): undefined reference toceil'\nhashcat_api.c:(.text+0x44ef): undefined reference to log10'\nhashcat_api.c:(.text+0x44f4): undefined reference toceil'\nhashcat_api.c:(.text+0x462f): undefined reference to log10'\nhashcat_api.c:(.text+0x4634): undefined reference toceil'\nhashcat_api.c:(.text+0x46ef): undefined reference to log10'\nhashcat_api.c:(.text+0x46f4): undefined reference toceil'\nhashcat_api.c:(.text+0x4baf): undefined reference to log10'\nhashcat_api.c:(.text+0x4bb4): undefined reference toceil'\nhashcat_api.c:(.text+0x4d6f): undefined reference to log10'\nhashcat_api.c:(.text+0x4d74): undefined reference toceil'\nhashcat_api.c:(.text+0x4e2f): undefined reference to log10'\nhashcat_api.c:(.text+0x4e34): undefined reference toceil'\nhashcat_api.c:(.text+0x4eef): undefined reference to log10'\nhashcat_api.c:(.text+0x4ef4): undefined reference toceil'\nhashcat_api.c:(.text+0x502f): undefined reference to log10'\nhashcat_api.c:(.text+0x5034): undefined reference toceil'\ncollect2: error: ld returned 1 exit status\nmake: *** [hashcatAPI] Error 1\n```\nI'm wondering. What's the reason to not pack it into a .so? I think that's what people expect from a true API and actually I should be pretty easy. \n. I'll reject this for now, but only because I want to have the repository clean when we fusion hashcat and oclHashcat into one. Otherwise this is getting more complicated than it needs to be. Don't worry, we'll add this after the release. This is great work.\n. The fusion is done and I've refactored hashcat basically into libhashcat. The goal is it to make it even easier to call hashcat from 3rd party applications.\nPlease check out the hashcat-as-library branch, especially this main_shared.c demo: https://github.com/hashcat/hashcat/blob/hashcat-as-library/src/main_shared.c\nDo you think you can modify your python bindings to this? I think your bindings should be easy to refactor, or at least I hope so. After that, you should create your own repository for the bindings. Maybe add some example code how to use it from python, like main_shared.c is.\n. > Is there a way to get all the same status info as pressing \"s\" during a normal run?\nAbsolutely, yes. As a proof you can see in main.c that the main.c itself is spawning the thread handling the prompt. I can see how important that it. There's always two ways to access the data. Either by accessing the hashcat_ctx data or by using an event. But for a status check (like speed and so on) an event would be unpractical, so you want to access it via hashcat_ctx. For example, if the user presses \"s\", it's the main thread handling it. You can follow it through main_outerloop_starting() -> thread_keypress() -> keypress() -> status_display() and from there, there's the code how to access the details\n\nAre events intended to be used in this way? \n\nNot for status. Events are useful for example if a hash was cracked.\n\nSeems like you have a well defined plan here so just let me know if you need me to work on some part or just test by adapting python bindings?\n\nFor the events, it's possible to add more event. At this point I've just add those which I needed to have the new main.c create the same output as original hashcat before refactoring. But it's possible you want some additional events. If you find some during your binding work, tell me and I'll add them. Note that everything is very new and it's possible I change this. Before you start writing the bindings you should wait for the release version. Or, if you start right now, I can't guarantee nothing changes.\nAnyway I should close this as the original hashcat API is not what it will be in the future, plus I expect it to be in your own repository, which makes much more sense.\n. Not yet, but we should develop a better version. What I'm talking is something like simplified getter functions for the status informations. For example get_device_speed(device_id) or so.  I'll write them, but can you tell me which type of getters are of use?\n. Hey @Rich5 \nI think the version now is close to what you'd expect from an api. First, there's the following methods to control a running process:\nint hashcat_session_pause (hashcat_ctx_t *hashcat_ctx)\nint hashcat_session_resume (hashcat_ctx_t *hashcat_ctx)\nint hashcat_session_bypass (hashcat_ctx_t *hashcat_ctx)\nint hashcat_session_checkpoint (hashcat_ctx_t *hashcat_ctx)\nint hashcat_session_quit (hashcat_ctx_t *hashcat_ctx)\nTaken from here: https://github.com/hashcat/hashcat/blob/hashcat-as-library/include/hashcat.h#L12-L17\nBasically the stuff you can see on the status prompt when you run the commandline. It's pretty self explaining I hope.\nNext, I've added the following helper methods to read the status:\nint     status_get_device_info_cnt            (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_device_info_active         (const hashcat_ctx_t *hashcat_ctx);\nbool    status_get_skipped_dev                (const hashcat_ctx_t *hashcat_ctx, const int device_id);\nchar   *status_get_session                    (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_status_string              (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_input_mode                 (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_input_base                 (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_input_mod                  (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_input_charset              (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_input_candidates_dev       (const hashcat_ctx_t *hashcat_ctx, const int device_id);\nchar   *status_get_hash_type                  (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_hash_target                (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_digests_done               (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_digests_cnt                (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_digests_percent            (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_salts_done                 (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_salts_cnt                  (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_salts_percent              (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_msec_running               (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_msec_paused                (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_msec_real                  (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_time_started_absolute      (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_time_started_relative      (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_time_estimated_absolute    (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_time_estimated_relative    (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_restore_point              (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_restore_total              (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_restore_percent            (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_progress_mode              (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_progress_finished_percent  (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_done              (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_rejected          (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_progress_rejected_percent  (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_restored          (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_cur               (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_end               (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_ignore            (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_skip              (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_cur_relative_skip (const hashcat_ctx_t *hashcat_ctx);\nu64     status_get_progress_end_relative_skip (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_hashes_msec_all            (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_hashes_msec_dev            (const hashcat_ctx_t *hashcat_ctx, const int device_id);\ndouble  status_get_hashes_msec_dev_benchmark  (const hashcat_ctx_t *hashcat_ctx, const int device_id);\ndouble  status_get_exec_msec_all              (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_exec_msec_dev              (const hashcat_ctx_t *hashcat_ctx, const int device_id);\nchar   *status_get_speed_sec_all              (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_speed_sec_dev              (const hashcat_ctx_t *hashcat_ctx, const int device_id);\nint     status_get_cpt_cur_min                (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_cpt_cur_hour               (const hashcat_ctx_t *hashcat_ctx);\nint     status_get_cpt_cur_day                (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_cpt_avg_min                (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_cpt_avg_hour               (const hashcat_ctx_t *hashcat_ctx);\ndouble  status_get_cpt_avg_day                (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_cpt                        (const hashcat_ctx_t *hashcat_ctx);\nchar   *status_get_hwmon_dev                  (const hashcat_ctx_t *hashcat_ctx, const int device_id);\nTaken from here: https://github.com/hashcat/hashcat/blob/hashcat-as-library/include/status.h#L19-L73\nAlso, I've rewritten the status_display() function (that is what the commandline tool uses which is why it's in terminal.c) to use the same helper functions. The refactored status_display is here and can be used as an example code:  https://github.com/hashcat/hashcat/blob/hashcat-as-library/src/terminal.c#L612-L783\nI'll refactor status_benchmark() and status_display_machine_readable() next, but that shouldn't interfere with your implementation. Note this stuff is still not in a released state, but your comments on this will be important, especially since you're actually writing the bindings and you will notice problems soon (if there are any).\n. Note that I've made a little change. The new typical call scenario is now this:\n- hashcat_init \n- hashcat_session_init \n- hashcat_session_execute\n- hashcat_session_destroy\n- hashcat_destroy\nSo I've added that middle layer session. The reason is that in case you do not want to actually execute some attack but only check for like OpenCL devices available, the call to session_init() is enough. \n. Done\n. Thanks\n. I think the problem here is the space character here: \"Px - Secu\". There's a -I without a quote following.  Since the entire string is already a workaround for OSX compilers, it would required to make a workaround inside a workaround. Any other solutions? Maybe using an environment variable?\n. I've pushed a maybe-workaround. Please pull latest version from github and reinstall it and try again\n. Thanks!\n. Try adding a --session\n. No, why should it? it should return the number of lines which are compatible to hashcat. In other words, a number that is equal or less than the number of lines in english_and_1_to_4.txt\n. I think you didn't read the FAQ:\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_is_a_keyspace\n. hmm maybe you're confused by the naming. hashcat will be renamed to hashcat-legacy soon and oclHashcat becomes hashcat which supports cpu and gpu. At that point, the way how oclHashcat handles this will be active for hashcat, too. there's no way to change this and no one ever had problems with it.\n. OK it seems you were testing old hashcat (CPU) cracker and then posting the error on the GPU version. That's confusing. However I used it for a test with the upcoming hashcat v3.00:\nroot@ht:~/hashcat# cat plains.txt \nabcdef\n\\\nabc\n/\neeeeee\nroot@ht:~/hashcat# cat rule.rule \n/e\nroot@ht:~/hashcat# ./hashcat --stdout plains.txt -r rule.rule \nWARNING: Cannot convert rule for use on device in file rule.rule on line 1: /e\nabcdef\n\\\nabc\n/\neeeeee\nThe error is correct, because the function / is not supported with -r, only with -j and -k. However, it should not print anything here, because there's no valid rules left.\nAnyway, if you run it with -j, it shows a valid result:\nroot@ht:~/hashcat# ./hashcat --stdout plains.txt -j /e\nabcdef\neeeeee\n. Kind of, see here: https://hashcat.net/wiki/doku.php?id=rule_based_attack\n- the rules marked with \"+\"\n- the full section \"Rules used to reject plains\"\n. Thanks!\n. I did some changes to scrypt memory handling again, please retry\n. Lots of stuff changed since this last test. Can you please retry with latest version from github?\n. Please retry! The commit https://github.com/hashcat/hashcat/commit/da93d216dad39436ceeb01a4e7054abafb1c0d30 could have an impact here. I've investigated the problem with the CL_OUT_OF_HOST_MEMORY. It turns out this is a false error message created by the OpenCL runtime when calling clBuildProgram(). The error itself occurs inside the vendors OpenCL runtime while compiling the OpenCL kernel. You have to know that with scrypt the OpenCL kernel is rebuild with every start because it requires the scrypt configuration parts to be hardcoded to run efficient. So, depending on the configuration settings, the code changes each time. The higher you set them, the more memory it takes the JIT compiler to optimize the kernel and that's the error where it's running into. The only thing I don't understand is why it runs into that error with the 750Ti while it does not run into it with the 1080. That could be becuase of the different instruction set of the chips or different optimization settings for them in the compiler. But in both cases we can not know, because that's some hidden logic inside the vendors OpenCL runtime. That also means we can not do anything to not run into this error and that's why I think this is not a hashcat issue anymore.. This is cool, many thanks!\n. No reponse from OP, so closed\n. No reponse from OP, so closed\n. Looks like a failure in the libc, at least it crashes on there, so this is not directly a hashcat problem. However it could be interesting how it was triggered. Please compile from source like this:\n$ make clean; DEBUG=1 make\nThen run hashcat as you did before:\n$ ulimit -c 999999999\n$ ./hashcat ...\nThen use gdb to find what happend before the crash:\n$ gdb ./hashcat core\nsome gdb out follow...\nenter \"bt\" at the prompt, then paste full output\n. Excellent report. I'll add some code to handle that later. Thanks!\n. Great work! Thanks! @Fist0urs Please check this out\n. > hashcat does not use cuda\nThat's correct, but unfortionally the CUDA SDK includes with OpenCL headers. However, they are standartized, they should be compatible.\n@initbar Nice Video! Regaring the error, I think your OpenCL installation is broken. The error clearly indicates this. So this is not a hashcat problem. You should find the same error when running \"clinfo\". Check out this blog post: https://wiki.tiker.net/OpenCLHowTo maybe it helps installing OpenCL correctly. BTW: which linux is that?\n. Which driver are you using? I need to know so that I can reproduce locally\n. I think it's the \" chars in the build options. This should be supported by AMD OpenCL runtime, since it part of the OpenCL specification, but it doesn't. All other vendors do it correctly. Anyway, since I don't have access to a amdgpu-pro compatible GPU, I can not reproduce it. You can try it yourself. Remove the \" char from the build options at both sides from the %s and recompile. It should work afterwards. Please give me feedback here if it worked so that we can try to think about a workaround for amdgpu-pro.\n. Implemented a workaround. Should work now. You can try with latest beta from hashcat.net/beta\n. Please retry with latest github version\n. Can you please post the output of \"clinfo\"\n. You can try follow this wiki article:\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nSee if it helps\n. OK, cool. Thanks for the PR and the explanation\n. Two things to mention here:\n- I never expected this install system to be run on OSX. There could be problems\n- The macro APPLE is kind of official? Reason is we're currently using DARWIN on the most spots. What the correct/better form?\n. Excellent. I think we should switch to that. /cc @unix-ninja \n. Can you guys retry please with latest version from github. So much changed....\n. Any updates here?. OP not responding for months and too old version. Closing.. Thanks for the detailed information. They are very clear.\nAbout the scrypt part, I don't see any technical problems. The computation of scrypt is the reason why we want to run the attack in hashcat anyway. Before I'm going to implement this, I want to do a make sure it's worth the effort. I mean in comparison to the attack on CPU. Therefore we should compare the performance between CPU and GPU. If GPU shows a largely better performance, we should continue. I need your assistance because I don't know exactly how I could meassure the performance of your python script. \nCan you please tell me how many keys per second it can compute for the settings \"N=32768, r=8, p=2\"? I think the both scrypts calls will have the same runtime, simply because the scrypt settings are the same. I also think (in comparison to the both scrypts) the RSA part will be like no time. In other words, your pythons scripts performance * 2 can be used to compare with hashcat benchmark result with the same scrypt settings. It's not very precise, but precise enough to make a decision.\nI made a benchmark of N=32768, r=8, p=2 on a 1080. This GPU shows currently the best hash cracking performance. Here it is:\nSpeed.Dev.#1...:       40 H/s (12665.65ms)\nThe scrypt settings forced a TMTO setting of 4 and a limited thread count of 32. That is 20 compute units with 32 warps, so a pysical power of 640. Each of them require a memory block of 128 * 8 * 32768 and then divide by 4 because of the TMTO. We end up in 5,368,709,120 bytes memory required. We can't go any higher because it would exceed the GPU pysical memory of \"only\" 8GB. I don't see much room for optimization.\nOne short note about the RSA part. With latest hashcat I've added support for a hook. That means you can fetch the current key state (for example the scrypt final key) from the GPU to the CPU and do something with it and then copy the results back to the GPU and run another kernel with that data. So my Idea would be to use that for the RSA computation. I never did that before, but I guess some license-compatiable crypto library could help here.\n. OK, I had to do some changes to my scrypt kernel so that it runs better on CPU, and I'm happy to report it does. On my i7-4770, I'm getting ~65H/s on a single scrypt, so roughly ~21H/s. per CPU. What you think, is it worth it?\n. Does this problem still exist with latest version from github? Please retry\n. @mire3212  I've pushed some experimental code, can you please retry with latest github version? Do not forget to remove the kernels/ caching folder\n. @leonklingele Did you do:\ngit clean -f\ngit reset --hard\ngit pull\nmake clean\nmake\n?\n. Of course. Since I do not have access to such a computer, maybe you can give some updated information for @matrix to check. This is confusing. If @leonklingele uses \"latest master\", then he should have the latest hashcat.hctune already. @matrix gotcha, thanks. Happy tuning!. @matrix Do we need to patch hctune for Lotus Notes/Domino 6?. @matrix can we close this issue?. OK, we should create a new issue if we need it because this one is for SHA3 only. Thanks!\n. Can you post output of clinfo please\n. Should be fixed, please test and close the issue\n. Try again please\n. I pushed some fix\n. How could we have missed that, thanks!\n. Lots of stuff changed since this last test. Can you please retry with latest version from github?\n. Any update here?. OP not responding for months and too old version. Closing.. Thanks for fix!\n. Should be fixed, binary betas here: https://hashcat.net/beta/\n. Nice find\n. We've gotten this error type alot since hashcat  v3.00, but we're certain it's not a problem in hashcat. It's a problem with the users OpenCL installation. To make sure he installed it correctly, please follow the following wiki article: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nCan you please try out and give us some feedback?\n. Thanks for the feedback\n. This is great, thanks! Too bad travis doesn't support FreeBSD, so I can't check if it's working.\n. @ZbigniewB Your points are incorrect, sorry. If you follow the BUILD.md 1:1 it will work. Install the missing ICD loader library is not part of hashcat. It's basic OpenCL stuff.\n. Yeah I was going to say you maybe just need to adjust the path. Problem is I don't know if it's possible to not use a path and let MinGW find the object itself. \n. @philsmd Any news with the patch? All you need is to push it into an external file and include it from Makefile\n. I remember someone reported the same problem with a GeForce device on Apple. There's no known workaround or fix. Also note that this is not a hashcat problem, it's a driver or runtime problem.\n. As you can see, crashes somewhere inside gallium\n\n0x00007fffd0cea8c8 in ?? () from /usr/lib/gallium-pipe/pipe_radeonsi.so\n\nNot hashcats fault, sorry.\n. https://www.phillips321.co.uk/2016/07/09/hashcat-on-os-x-getting-it-going/\nPlease close issue if it helps\n. Double post: https://github.com/hashcat/hashcat/issues/416\n. Should be fixed, thanks for report. Please reopen if it's not fixed.\n. It took me a while to make the Makefile as clean and easy to read as it is now, but with those changes it becomes hard to read again. Can we move that code section out to an external file and include it from within the Makefile?\n. Issue should be fixed. Don't forget to remove kernels folder before retry\n. There's also a new beta binary build on https://hashcat.net/beta/\n. weak-hash detection works only in attack-mode 0 and can't be easily ported to other attack-modes. please use the -a 0 mode first\n. Can't reproduce:\n```\nroot@ht:~/hashcat# ./hashcat -m 3000 hash -a 3 X\nhashcat (v3.10-25-gdc30176) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 499/1998 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Final-Permutation\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (X) [1]\nHash.Target....: aad3b435b51404ee\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (0.05ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Fri Sep  2 11:22:41 2016\nStopped: Fri Sep  2 11:22:44 2016 \n```\nYou sure you're using latest github version?\n. Re-added. You can use hashcat.net/beta if you want to play with it or wait for next release\n. So, can we close this?\n. No response here, closing\n. That's an integer overflow. A known issue since the total Keyspace (you can see it in the progress column in status view) is limited to 64 bit. however, it's nothing i'm going to fix soon because you can't search through such a range anyway, which is the reason why it is how it is.\n. If this requires a special kernel, we should name as such. Please open a new Ticket while following this: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\n. This issue makes no sense. If you don't know the salt, you can't crack it, whatever hashcat supports salt length 40 or not. Please re-explain\n. Continue here: https://github.com/hashcat/hashcat/issues/565\n. Cool, thanks!\n. OK so far, but please add a description to docs/changes\n. You can't have (null) output otherwise this crashes on Windows. Please check for NULL and handle it correctly.\n. Thanks!\n. This is not about a new hash mode, it's mode like a new program. That's not how cracking is done. If the programm is closed source you have to reverse engineer the algorithm. You can't have a tool to do that automatically because there's an unlimited number of possibilities.\n. beta is up here: http://hashcat.net/beta/\n. Such a feature makes the program unnecesarily complicated. Note that this needs to be maintained over time, too. It makes even less sense since you can do that yourself. Just do cat whatevermask* > outfile.txt and then use outfile.txt.\n. That's nice. Can you please create dedicated hash-modes for them, too? Please use 1510 -> 14000 and 1530 -> 14100. \nNote that I think you can do bitsliced DES for -a 3 kernel, which will increase the speed by a very large factor. In theory, benchmark speed for your DES kernel should match the LM kernel.\nAlso please add test.pl and test.sh target\n. @fransla please respond\n. Hey Frans, no worries, I'll add bitsliced stuff afterwards.\n. @mattames that's already supported since a long time. see here: https://hashcat.net/forum/thread-3047.html\n. @halexan No, hashcat abstracts this for you. Please the read forum post again.\n. I didn't want to wait anymore and rewrote it myself, fixed some smaller bugs, added unit-tests and added bitsliced kernel which makes it around 10 times faster. Here's the full commit: https://github.com/hashcat/hashcat/commit/71a8459d851d246945343ea59effa1d46b965bf8\nThanks for your help\n. Yes, a friends 6x1080 machine is doing 120GK/s. IOW: Cracks every DES key in 80 hours average\n. I think you just forgot to add --hex-charset\n. Excellent work, thanks!\n. There's no relation between the hashmode and the retain algorithm. It's more likely that your fans are unable to cool down the device fast enough, like the trigger starts at 75c and starts the fans but when the watchdog checks the temp its already 90c. \nIWO, This sounds like a cooling issue on user side. Please reopen the ticket if you're sure it's a bug\n. I could add this, but please answer the following questions first: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\n. Thanks @matrix for adding . That's very good information. I can confirm the same behaviour in my system. I'll look into this\n. OK, some update here, it seems that this is actually a bug in NVIDIAs OpenCL JIT compiler (OpenCL runtime). While this always sounds like some kind of excuse, you can proof pretty easy by installing any different OpenCL runtime and run it with that. I used AMD's CPU OpenCL runtime for my fx8120 CPU. Here's the output:\nNot working NV:\n```\nroot@ht:~/hashcat# ./hashcat -m 6223 hashcat_sha512_aes-twofish.tc -a 3 hashca?1 -1 t \nhashcat (v3.00-86-g6f8d3d8) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 499/1998 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Brute-Force\n* Uses-64-Bit\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (hashca?1) [7]\nCustom.Chars...: -1 t, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: File (hashcat_sha512_aes-twofish.tc)\nHash.Type......: TrueCrypt PBKDF2-HMAC-SHA512 + XTS 1536 bit\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (0.73ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Thu Aug 18 13:01:03 2016\nStopped: Thu Aug 18 13:01:09 2016 \n```\nWorking CPU:\n```\nroot@ht:~/hashcat# ./hashcat -m 6223 hashcat_sha512_aes-twofish.tc -a 3 hashca?1 -1 t -D 1              \nhashcat (v3.00-86-g6f8d3d8) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, skipped\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, 18056/18056 MB allocatable, 8MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Brute-Force\n* Uses-64-Bit\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nhashcat_sha512_aes-twofish.tc:hashcat                     \nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (hashca?1) [7]\nCustom.Chars...: -1 t, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: File (hashcat_sha512_aes-twofish.tc)\nHash.Type......: TrueCrypt PBKDF2-HMAC-SHA512 + XTS 1536 bit\nTime.Started...: Thu Aug 18 12:57:32 2016 (38 secs)\nSpeed.Dev.#2...:        0 H/s (0.46ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Thu Aug 18 12:57:32 2016\nStopped: Thu Aug 18 12:58:17 2016 \n```\nNote that with hashcat v2.01 we were using CUDA, not OpenCL. There's a good chance that the compiler settings in CUDA are different to OpenCL. This explains why it's working with cudaHashcat.\nReporting bugs to NVidia never helps btw, they always ignore reports, at least if it's regarding OpenCL. So the final question is how to workaround the problem. Trying to find this out is my next step.\n. I've pushed that workaround. Can you please run your script and check for results?\n. I think the issue is workarounded, so I'm closing this to enable the release of hashcat v3.10. Please reopen if needed.\n. Yes, that check sounds useful\n. I agree with @philsmd \n. Nice find actually, thanks! I think it's safe that there's no opposite case for this, like having COMPARE_S_SIMD in the multihash kernel, because this would require to have the search[] array declared, so it would cause a compile error.\n. It's good, -o should be used incase --stdout is used, also saves the redirect\n. We should setup an issue for that otherwise it's forgotten\n. We should close that issue then. Thanks!\n. Very good, thanks!! I'll close the #425 Issue as well\n. Thanks!\n. Note sure if I get this right. So the idea is it to use the potfile as previous wordlist input before running the actual wordlist? What if the user doesn't do wordlist attack, but hybrid-attack?\n. So check the potfile words only in case --loopback is used?\n. @mubix Also, this would work only for rule-based attacks, not BF. @mubix OK, pushed this: https://github.com/hashcat/hashcat/commit/1f756bf752f1fae16f50be57eb75d22c97639e6a\nPlease try. This feature went into hashcat v3.30, therefore closing the issue. If it's not working, please open up a new one.. There's a lot of potential in this, I like it. From a quick overview i found the following stuff very nice:\n- pragma once\n- config.h\n- have many small files\nBefore thinking about merging, I have to check this out in detail and you need to fix some stuff first:\n- Sync your branch with hashcat master, I got tons with conflicts. We're are hashcat v3.10 already, while you're at v3.00\n- Is it possible to make this without using cmake?\n- Does not compile on linux anymore:\nroot@ht:~/xy/hashcat/build# make\nScanning dependencies of target hashcat\n[  3%] Building C object CMakeFiles/hashcat.dir/src/status_display.c.o\nIn file included from /root/xy/hashcat/include/hc_device_param_t.h:5:0,\n                 from /root/xy/hashcat/include/shared.h:31,\n                 from /root/xy/hashcat/src/status_display.c:3:\n/root/xy/hashcat/include/ext_OpenCL.h:76:3: error: unknown type name \u2018OCL_LIB\u2019\n- What is a windows shim?\n- How can I cross-compile the windows binaries from Linux. Users expect that from us\n- What advantage is it to have those enum types over macro definitions?\n- Why did you add type naming after: typedef struct XXXX_t_ { ... } XXXX_t; ? Anonymous structs are fine aren't them?\n- The filenames have no real convention, for example: ext_OpenCL.h <- original, filenames_generators <- new type 1, hc_concurrency.h <- new type 2. So the question is, why having hc_* in front for some and for others not?\n. I've decide to reject this, even there's tons of good stuff in here.\nMajor reason is that, for me, it's too much changes at once to recognize all the implication.\nMinor reason is that it's not conflict free PR. A good PR's should be free of conflict.\nAnyway I want to use some of those changes. So what I'm asking here is to do the changes, but slowly. I'd suggest to create dedicated PR's where you only change one thing at a time. That would help me to understand the changes in detail and in depth.\nI know it's not always possible, especially when it comes to includes and depencies, but we could start with the easy changes first, for example moving the MACRO constants into the ENUM types. Since you made all the changes, you can evaluate the steps much better than I can. Ideally create a migration plan first.\nAbout cmake: If possible I'd like to not use cmake, because I'm not used to it. If there's really no way around it, then we do it. But in that case we should do it at the end of the migration process.\nAbout .gitmodules: The idea seems nice, however there also some problem with it. If there's any code included automatically from a different repository, than this repository could be used to inject code without any changes to hashcat. There created some concern from the more security aware developers and I can see their point. We should avoid this.\n. I'm not going to change the default, because there's too many workflows depending on that output-file format, as @redongh already mentioned. Therefore I'm going to close this issue. \nHowever, here's another approach that you might find useful, by adding --show into the mix:\nYour command, as however you do it or did it:\nroot@ht:~/hashcat# ./hashcat example0.hash example.dict\nNow create the wordlist:\n```\nroot@ht:~/hashcat# ./hashcat --show example0.hash -o outfile --outfile-format 2\nhashcat (v3.10-3-g13cbe42) starting...\nroot@ht:~/hashcat# cat outfile  \n13LEXON\n```\n. I don't like the idea mostly because I don't want to write a configfile parser. Is there any good libraries for pure C?\n. I was discussing with @philsmd about this. Here's some important argument collected:\n- The use for such a configfile could be worked around in linux using bashrc/alias, but that would reduce it to linux and maybe OSX. Windows users couldn't do it.\n- We often have reports like \"hashcat did not crack hash XY\", but in almost all cases it turns out the problem is the user, not hashcat. In case we have a user who changed for example --markov-threshold to 2 in the config and then wondering why hashcat isn't cracking the hash of which he knows the password, we couldn't see it from him posting only his commandline. We would need to have some \"display\" of the changes values in the config file on startup but that would only solve the problem if the user posts it. Most poeple will post only the commandline. It would be also ugly, from a design perspective.\n- The .restore system could be broken if the user changes the configfile. A theoretical solution to this would be to store some checksum of the config settings with the .restore file and check it in a restore case and complain if it doesn't match. but it's very likely the user can not restore the config file to exact the same one as it was before. We could also store all the settings but that would create some larger change to the restore system at all\n. This should be fixed, but note that to fix this, I had to move the source tarball to hashcat.net because GitHub didn't let me choose the download filename manually.\n. I can't reproduce this with on linux, because the linux driver is far behind the windows drivers. Without being able to reproduce it, I can't fix it. We need to wait till the AMD driver for linux is at that point\n. OK, I've added a workaround for this. You can try with latest beta from hashcat.net/beta\n. All right, will do :)\n. Done\n. Thanks for the fixes. Please do not forget to add your fixes to the docs/changes.txt\n. Great! Thanks!\n. Just noticed that you didn't add your changes to docs/changes\n. GitHub is for bugreports and feature requests or anything development related. Please use the hashcat forum for user questions.\n. GitHub is for bugreports and feature requests or anything development related. Please use the hashcat forum for user questions.\n. If you use --opencl-platforms 1, so that it uses your NVIDIA device, and it cracks, then it's propably as @Fist0urs said, an OpenCL runtime problem. Not a hashcat problem.\n. @MichalStaruch You said so, but you posted a quote where you used --opencl-platforms 2. This makes it pretty hard to understand because it's confusing. Please post the output of --opencl-platforms 1 as well.\n. I can not reproduce this, see here:\n```\nroot@ht:~/hashcat# echo admin1 | ./hashcat -m 13400 x --potfile-disable                                             \nhashcat (v3.10-10-g18d6a7a+) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 499/1998 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nStarting attack in stdin mode...         \n$keepass$26000222dd6d95d690fabcf88a664173f03d03b70af03d66274cdfb3d9af30d6e29fe7a6df2e5700e0a87349ce83409457f1aa93711083e372ab815285e784d720b5637923229838c8d9a788d90ff30e78117375fec0fddc19892aca5623f8d807c409b88b6894dfa7d56d1dc2d7f51447880a593e012dea9a6b440729db5d14e0fabe9dde8668ce3e2ce68e4087853d0b0b2043:admin1\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Pipe\nHash.Target....: $keepass$26000222dd6d95d690fabcf88a66...\nHash.Type......: Keepass 1 (AES/Twofish) and Keepass 2 (AES)\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (1.18ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1\nRejected.......: 0\nStarted: Mon Aug 29 20:17:52 2016\nStopped: Mon Aug 29 20:17:57 2016 \n```\nAlso it's strange that it says this in your output:\nCache-hit dictionary stats 10k_most_common.txt: 1953599 bytes, 20342 words, 20342 keyspace\nWhile in mine it says:\n... 73017 bytes, 10000 words, 10000 keyspace\nSo maybe \"admin1\" is just not in your wordlist?\n. Please close the issue if you think it's fixed.\n. OK, but now we're back on the following situation that @Fist0urs explained here: https://github.com/hashcat/hashcat/issues/479#issuecomment-243162405\nThis is a known error inside Intel's GPU OpenCL runtime, not a hashcat error. We can't do anything on it, that's why I'm closing this issue now.\nNote that we also do intensive unit tests, including for keepass and no error have been reported with it.\n. Of course I am sure, otherwise I wouldn't close the issue. However, because the experience I made in the past, vendors don't care about bugs in OpenCL runtime, because it affects too less users. Whenever I report a full bug report, including poc etc, the vendors never reponse to this. Maybe it's because it's \"hashcat\", I don't know. However, I'm tired of reporting bugs to them, so there's no one. Feel free to open one yourself.\n. Support for LUKS has been added. See this thread for details: https://hashcat.net/forum/thread-6225-post-33187.html#pid33187. Double post, please see https://github.com/hashcat/hashcat/issues/434\n. Double post: https://github.com/hashcat/hashcat/issues/481\n. I'm trying to process the single commits historically the same order you did and comment each commit how I handled them.\nhttps://github.com/hashcat/hashcat/pull/485/commits/d288608b85b4ded6010128c7ed40e9532a3ccc02\nThis commit is unacceptable for multiple reason:\nI just hope it's really only about formating to that I'm able to merge other changes i like\n- OpenCL/inc_hash_constants.h was changed in the meantime from myself into enum types\n- Removed comments, no need to reformat\n- \"int log_out_nn (...)\" is the correct format, \"int log_out_nn(...)\" is wrong, no need to change those\n- Code like this is easier to read if it's correctly aligned, no need to change those:\ntemp = (te2[(temp >> 16) & 0xff] & 0xff000000)\n          ^ (te3[(temp >>  8) & 0xff] & 0x00ff0000)\ntemp = (te2[(temp >> 16) & 0xff] & 0xff000000)\n      ^ (te3[(temp >>  8) & 0xff] & 0x00ff0000)\n- Same here, code like this is easier to read if it's correctly aligned, no need to change those:\ntd0[te1[(rdk[j + 1] >> 24) & 0xff] & 0xff] ^\n       td1[te1[(rdk[j + 1] >> 16) & 0xff] & 0xff] ^\n       td2[te1[(rdk[j + 1] >>  8) & 0xff] & 0xff] ^\n       td3[te1[(rdk[j + 1] >>  0) & 0xff] & 0xff];\ntd0[te1[(rdk[j + 1] >> 24) & 0xff] & 0xff] ^\n       td1[te1[(rdk[j + 1] >> 16) & 0xff] & 0xff] ^\n       td2[te1[(rdk[j + 1] >> 8) & 0xff] & 0xff] ^\n       td3[te1[(rdk[j + 1] >> 0) & 0xff] & 0xff];\n- This change looks like a bug in your automated replacement:\n-  char *block_ptr = (char *) block;\n-  char *plain_ptr = (char *) plain;\n+  char *block_ptr = (char *)block;\n+  char *plain_ptr = (char *)plain;\n- Not sure why people think #ifdef should not be aligned, it just makes it hard to read, will not change:\n-  #if defined (_WIN32) || defined (_WIN64)\n+#if defined (_WIN32) || defined (_WIN64)\n- Those are copies from ADK SDK, we better don't do changes if we want to maintain them over time:\n-  ADLODPerformanceLevel aLevels [2];\n+  ADLODPerformanceLevel aLevels[2];\n- Same goes for NVAPI and NVML\n- This just looks ugly:\n-static inline void CPU_ZERO  (cpu_set_t *cs)          { cs->count = 0; }\n-static inline void CPU_SET   (int num, cpu_set_t *cs) { cs->count |= (1 << num); }\n-static inline int  CPU_ISSET (int num, cpu_set_t *cs) { return (cs->count & (1 << num)); }\n+static inline void CPU_ZERO(cpu_set_t *cs) { cs->count = 0; }\n+static inline void CPU_SET(int num, cpu_set_t *cs) { cs->count |= (1 << num); }\n+static inline int  CPU_ISSET(int num, cpu_set_t *cs) { return (cs->count & (1 << num)); }\n. https://github.com/hashcat/hashcat/pull/485/commits/d26eef45ab95b414ff3bff19199f871ba4ea666c\nThis commit simply creates a folder \"hwmon\" and moves the code from the main src folder into that (same for include).\nIt's not like that would create any better view on the folder, because in the main src folder is 10 files anyway:\n-rw-r--r-- 1 root root  18024 Sep  5 10:10 ext_ADL.c\n-rw-r--r-- 1 root root   5626 Sep  5 10:10 ext_nvapi.c\n-rw-r--r-- 1 root root  13041 Sep  5 10:10 ext_nvml.c\n-rw-r--r-- 1 root root  13650 Sep  4 20:11 ext_OpenCL.c\n-rw-r--r-- 1 root root   4777 Sep  5 10:10 ext_xnvctrl.c\n-rw-r--r-- 1 root root 695854 Sep  4 21:53 hashcat.c\n-rw-r--r-- 1 root root  11151 Sep  4 20:11 Makefile\n-rw-r--r-- 1 root root  96535 Sep  4 20:11 rp_kernel_on_cpu.c\n-rw-r--r-- 1 root root 602378 Sep  4 21:53 shared.c\n-rw-r--r-- 1 root root   2015 Sep  4 20:11 win_file_globbing.mk\nIt's not like this creates alot of confusion. OTOH, it creates lots of problems with the Makefile. We'd need to rewrite it in a way so that it is able to handle the new folder structure. \nI don't see the benefit yet. Maybe this changes when I continue going through the other commits.\n. https://github.com/hashcat/hashcat/pull/485/commits/58b728230b666cabf7f5dee445dc3ece34e1068e\nI merged this, or better I took the idea and applied it to the oder cpu-*.c files as well. While doing this I find there's a lot of duplicated macros if you compare it with  OpenCL/inc_hash_functions.cl and  OpenCL/inc_hash_constants.cl we maybe want to change that at a later time.\n. https://github.com/hashcat/hashcat/pull/485/commits/75a3ab9d47bd7d929e08f1f93de4399909743ef7\nI merged this, or better I took the idea and applied it to constants that apply to this. I'm sure there will be more files that can be improved like this, whenever I see them I will fix them accordingly.\n. https://github.com/hashcat/hashcat/pull/485/commits/4323b4a70ad879b1a441449ff96143701647b087\nI merged this, or better I took the idea and applied it to constants that apply to this. I'm sure there will be more files that can be improved like this, whenever I see them I will fix them accordingly.\n. https://github.com/hashcat/hashcat/pull/485/commits/30df3c66c2d14b17ba314c71aa527b592f873145\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/555675f955eeef601ebed27399ca7cebf99b0b75\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/11f58ee7959b84ecbcbfed0c7d1a28ee3390eae4\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/5481c882931dd2e967ac81d693dbcbd3d3384a72\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/2351e8ec8f6d0872c1e1183d3bd5352e3c05e5da\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/f440897d442006705f9b28cc9f30fa6b03fc5168\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/7d4ab2ff331f78bab129e146de04b8d040a2e482\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/2a7723bab3af5ada61a2b726e2283d620cf470ec\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/8fc2437e951535c5a00a7ddc0783acc291fcf139\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/96ea03db72de1f1022de3ae11e0952ad8f9d83e6\nPartially merged:\n- Fixed unused typedefs for windows \"uint\" and \"uint64_t\" (double)\nTo fully merge, please explain:\n- What is BASETSD_H ?\n- Is BASETSD_H a pre-existing macro from vc or set from Makefile?\n. https://github.com/hashcat/hashcat/pull/485/commits/a55052cc66029a3a5ef76ae4bc1a216f812464f2\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/96ea03db72de1f1022de3ae11e0952ad8f9d83e6\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/135555f4572e4d6def1150eaf77800b665d7ed63\nCan not merge. \nDatatype switch to static is not possible because variable is used from different object via extern\n. https://github.com/hashcat/hashcat/pull/485/commits/d57d9245dbaaa2dca9135fde1a674548fb36b52e\nmerged\n. https://github.com/hashcat/hashcat/pull/485/commits/1aafa13e09973568ae58e4a539ce1d7772bd7e0b\nmerged, even created a new file for that, but since I'm this as an object, we can no longer inline it.\n. > There are dedicated instructions for this in cpus, so those functions are just compiler abstraction layer, they are really meant to be inlined.\n\nThe use of them is not time intensive, so it's fine\n. There's two reasons:\n- It's only faster in large quantities. But when we use those cpu algorithms, it's mostly just one call\n- The OpenCL devices are not initialized at this point and it makes no sense to move them\n. Just in case you're wonding. Currently doing pretty intensive refactoring so that it's easier to merge your changes. Takes some time\n. You can see it from the commits I do, there's a lot of work being done already. But I'm not finished yet. I think it will take a few more weeks to get to a point to merge this stuff. Note that alot of your changes are a result of the same refactoring I'm doing, like moving the code into seperate files. When I'm done with that, I'll go through your PR and compare it with my changes to find out what I'm missing.\n. Refactoring almost done; Integrated hand selected changes; Continue discussion on separate issue https://github.com/hashcat/hashcat/issues/520\n. Refactoring almost done; Integrated hand selected changes; Continue discussion on separate issue https://github.com/hashcat/hashcat/issues/520\n. All fine here, the salt is embedded into the mask as part of an optimization process.\n. This helped alot, thanks m8!\n. Of course not, that wouldn't make sense at all then. It depends on serveral factors, but the most important it the number of amplifier (for example rules). Note that a good attack uses large wordlists and a small number of rules, not the opposite. You can also use --stdout feature to pregenerate a large base and pipe it back into hashcat. Anyway, GitHub issues are for feature request and bug reports. For general hashcat use please use the hashcat forum.\n. - That makes no sense for masks, since hashcat uses position-dependant markov-chains anyway. IOW, it's not starting with AAA and ending with ZZZ. It could be G5! and next would be _T4, depending on the training data.\n- That makes no sense for wordlists, as they are not processed linearly. On GPU, they are run in parallel. The Host can not know which one is processed at time the user requests an status update.\n\nPlease close the issue.\n. Implemented, you can use github version for test or one of the precompiled beta on hashcat.net/beta with starting version > +607 or next release :)\n. Merged\n. Thanks!\n. The version string gets updated with release. Find the beta on https://hashcat.net/beta/ which are named 3.10+X\n. I've pushed something, please check if it's fixed now and close the issue if fixed\n. Lots of stuff changed since this last test. Can you please retry with latest version from github?\n. @fsociety79 any update?. OP not responding for months and too old version. Closing.. Works fine for me\n```\nroot@ht:~/hashcat# ./hashcat -m 2500 x.hccap -a 3 123456789012345678901234567890123\nhashcat (v3.10-118-gbc75ba7) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 499/1998 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Brute-Force\n* Slow-Hash-SIMD\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \n6454331:1c18d4ca52a7:62b9bdade67b:123456789012345678901234567890123\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (123456789012345678901234567890123) [33]\nHash.Target....: 6454331 (1c:18:d4:ca:52:a7 <-> 62:b9:bd:ad:e6:7b)\nHash.Type......: WPA/WPA2\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (0.43ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Wed Sep 14 17:06:42 2016\nStopped: Wed Sep 14 17:06:45 2016 \n```\nAlso works with -D 2 (CPU).\nI guess your hccap was somehow generated wrongly.\n. I also pushed a small patch in case you were using a wordlist:\n- Allow words of length > 32 in wordlists for -a 0 for slow hashes if no rules are in use or a \":\" rule is in the rulefile\nPlease close the issue if that's ok\n. OK, should be fixed, latest beta is up in hashcat.net/beta\nRejected.......: 1/1 (100.00%)\n. Can not reproduce:\n```\nroot@ht:~/hashcat# ./hashcat -m 14000 hashes.txt -o cracked.txt -a 3 -1 charsets/DES_full.charset --hex-charset ?1?1?1?1?1?1?1?1 -w 3\nhashcat (v3.10-136-g0eff6b7) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 499/1998 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Final-Permutation\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: Mask (?1?1?1?1?1?1?1?1) [8]\nCustom.Chars...: -1 charsets/DES_full.charset, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: 6a898d2b68603963:6761741651753428\nHash.Type......: DES (PT = $salt, key = $pass)\nTime.Started...: Fri Sep 16 18:57:54 2016 (1 sec)\nTime.Estimated.: Tue May 23 01:25:12 2017 (248 days, 6 hours)\nSpeed.Dev.#1...:  3359.3 MH/s (49.50ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 6207569920/72057594037927936 (0.00%)\nRejected.......: 0/6207569920 (0.00%)\nRestore.Point..: 0/34359738368 (0.00%)\nHWMon.Dev.#1...: Temp: 36c Fan: 33% Util: 99% Core:1189Mhz Mem:2700Mhz Lanes:2\n```\nPlease update nvidia driver to latest version and try again, also post update of \"clinfo\" util.  Also run benchmark for a few algorithms and post output. also do not use beta version for tests, use stable v3.10.\n. Do you think this error is related to cracking -m 14000? What I mean is, does it work with other modes?\n. OK, thanks\n. I can't reproduce this. How did you do it?\n. Nope, no way I can get it to crash. Maybe your version is broken. Please do a fresh pull and a make clean and try again\n. OK i pushed something, please try again and close issue if solved\n. Made some larger change related to that. Please try again\n. Again I'm unable to reproduce this. I think you need to exactly describe how I can reproduce this locally. Maybe I also need the files you're using.\n. Here's what I do:\n$ git reset --hard\n$ git pull\n$ make clean\n$ make uninstall\n$ rm -rf ~/.hashcat\n$ make\n$ valgrind ./hashcat -m 2500 hashcat.hccap example.dict\n....\n==13532== \n==13532== HEAP SUMMARY:\n==13532==     in use at exit: 327,658 bytes in 928 blocks\n==13532==   total heap usage: 281,382 allocs, 280,454 frees, 1,350,270,561 bytes allocated\n==13532== \n==13532== LEAK SUMMARY:\n==13532==    definitely lost: 818 bytes in 15 blocks\n==13532==    indirectly lost: 48 bytes in 3 blocks\n==13532==      possibly lost: 1,632 bytes in 12 blocks\n==13532==    still reachable: 325,160 bytes in 898 blocks\n==13532==         suppressed: 0 bytes in 0 blocks\n==13532== Rerun with --leak-check=full to see details of leaked memory\n==13532== \n==13532== For counts of detected and suppressed errors, rerun with: -v\n==13532== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\n. I've pushed something that was a race condition that has a high propably to have caused this issue. Please try if fixed and close if fixed.\n. Sure and please continue testing. This stuff is very important to me during refactoring.\n. Cool! Thanks!\n. Please retry with latest github version\n. The crack-per-seconds problem was fixed with latest github version. Please retry and close the issue if solved\n. Can you please retry with latest version on github? That debugging info was pretty good. Please update it for latest version\n. Can you please retry with latest commits?\n. CC solution - merged to upstream: https://github.com/hashcat/hashcat/commit/5c8d08d8ef68edf6c77691af7e669804a20691fd\n. Technically it's not much of a problem, because I could mark the number of duplicates per hash in the hashes_t structure. But what I think is confusing is that when hashcat cracks such a hash, what should it do. Should it print the hash N times? That could confuse new users here alot, because they wouldn't expect it. Also, hashcat is a cracking tool, not a statistics generator. As @roycewilliams already said, it should be trivial to do what you want to do from an external script.\n. This is a huge chaos with the -I parameter, because each runtime handles it differently. And by each runtime I mean even different versions. For example the AMD OpenCL runtime < 15.12 understood what a quote it, but the new one based on amd-gpu-pro does not longer. That's why the best workaround I found so far is to chdir() to the folder where the .cl sources are and that's what's hashat is doing atm. That's why I don't understand @andrewvaughan issue here unless he's using an older vresion. \n@andrewvaughan Please try with latest version from github and close the issue if fixed.\n. what do you think what i'm doing since thee weeks, lol\nOn 24.09.2016 12:16, Gabriele Gristina wrote:\n\nI thought the same thing yesterday, but this is not a migration, it\nshould be re-engineered.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/511#issuecomment-249357325,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Of5M3DQwpuKdJdxxV-f53vqyue2nks5qtPh4gaJpZM4KFfEK.\n. Actually, I can see how C++ can be useful in some cases, but I don't see it for hashcat atm. @KOLANICH can you name some of the advantages?\n\nWhat I can see when it comes to OOP approach is that the code usually results in a more ordered structure, but we can do that for C, too. That's what I meant with \"what i'm doing since thee weeks\". If you take a look at the commits from the last weeks you will see it.\n. @KOLANICH I understand the use for C++ in some projects, but why is it good for hashcat? What I meant is, can you make an example, but inside hashcat, where C++ would help us alot?\n. I still find no good reason why to switch to C++ yet.. Closing this issue because I see no real advantage in porting to any other language. Maybe because OpenCL is so close to C it feels just natural to stick with C in the host program, too. . Please close if fixed\n. When is it really long enough? 50 or 500 or 500000? @magnumripper what's the maximum in JtR?\n. Continue here: https://github.com/hashcat/hashcat/issues/565\n. Yes, tabs are supported. You just need to deal with your shell to not re-interpret it somehow, but that's not part of hashcat.\n. As @roycewilliams said, I'm not much less inclined to take it on as an internal feature if it's something that can easily be scripted externally. Therefore closing this issue.\n. DES mode is not broken, please provide some example key:value pairs so that we can reproduce here. Here's one, showing it's working fine. \nroot@ht:~/hashcat# echo -n hashcat1 | tools/test.pl passthrough 14000\ncd674507b21e5ebe:1435662222276461\nroot@ht:~/hashcat# ./hashcat -m 14000 cd674507b21e5ebe:1435662222276461 -a 3 hashcat1 --quiet \ncd674507b21e5ebe:1435662222276461:hashcat1\nroot@ht:~/hashcat# echo $?\n0\nroot@ht:~/hashcat#\nFeel free to reopen the issue in case you can provide such info.\n. @bigfella237 As you can see from my first post, the key for cd674507b21e5ebe:1435662222276461 is \"hashcat1\", or 6861736863617431. You can use --outfile-format to show it in hex, too:\nroot@et:~/hashcat# ./hashcat -m 14000 cd674507b21e5ebe:1435662222276461 -a 3 --quiet --hex-charset 6861736863617431 --outfile-format 5 --potfile-disable\ncd674507b21e5ebe:1435662222276461:6861736863617431\n@Forts117 Your example work pretty well. I tested them on with pocl OpenCL runtime, Intel OpenCL runtime, NVidia OpenCL runtime (amd-gpu-pro is known to be broken). Anyway, they all work fine:\nroot@et:~/hashcat# ./hashcat -m 14000 47DC9810ADE39295:A04AB36B33E34FF2 -a 3 --quiet --hex-charset --outfile-format 5 --potfile-disable 0101010101010101\n47dc9810ade39295:a04ab36b33e34ff2:0101010101010101\nHere's it again, with a little bit of search space:\nroot@et:~/hashcat# ./hashcat -m 14000 47DC9810ADE39295:A04AB36B33E34FF2 -a 3 --quiet --hex-charset --outfile-format 5 --potfile-disable ?1?101010101?1?1 -1 charsets/DES_full.charset\n47dc9810ade39295:a04ab36b33e34ff2:0101010101010101\nIf you try to reproduce, here's the version I'm using:\nroot@et:~/hashcat# uname -a\nLinux et 4.4.0-36-generic #55-Ubuntu SMP Thu Aug 11 18:01:55 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\nroot@et:~/hashcat# ./hashcat -V\nv3.10-339-gfb3e6ba+\nroot@et:~/hashcat# nvidia-smi \nSat Oct  1 08:52:02 2016       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 370.28                 Driver Version: 370.28                    |\n|-------------------------------+----------------------+----------------------+\n. In 3DES, the blocksize doesn't change compared to DES. Not sure what you\nmean with 32 character, maybe 3DES in combination with a block chaining\nmode?\nOn 25.11.2016 12:40, jamesthecat7 wrote:\n\njsteube's example works for me, but if i try a 32 character CT:PT I\nget \"no hashes loaded\" error. Can someone explain this?\nExample where PT=testingtesting11 and key = hashcat1:\n|hashcat64 -m 14100\n8d38b97dfad9ff21ffa6dcd7c2f78caf:74657374696e6774657374696e673131 -a 3\n--potfile-disable|\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/519#issuecomment-262939235,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OeocXS4X9l0ta28w4qD24ZiVV6-xks5rBslHgaJpZM4KJgf-.\n\n\n. You didn't specify a mask. Anyway that's not a hashcat issue, please ask on hashcat forum for correct hashcat usage.. > > Moving code into subfolders make the Makefile unneccary complicated\n\nNot moving makes directory content hard-to navigate. And I don't see much complication in it. Anyway, my cmake script did the globbing.\n\nI see, but we don't have cmake (yet) and with normale make it's harder to do.\nHowever, if you send a PR with only very basic cmake that works without any changes to the current structure and if I get a good understanding about how it works I may change to cmake.\nQuestion: Is cmake required to build on VS?\n\n\nNot sure why we should move this into a separate file.\n\nWhy not? Large files slow down IDEs.\n\nPlease add the related commit otherwise it's hard to understand the context.\nAt this time we only have one large file left (interface.c) which include the parsing and rebuilding of hashes of all the different modes in seperate functions. Splitting them into single files would make sense only if we have a plugin system that standartizes all loading and saving. If you're IDE can't handle large files it's not a problem of the project, it's a problem of the IDE. I don't use any IDE btw.\n\n\nhttps://github.com/hashcat/hashcat/commit/7fb6fce99473fabf93885c0baccbd2040536fe2b\nhttps://github.com/hashcat/hashcat/commit/6deede5037c84aee7192f65f936e9a392c614584\nhttps://github.com/hashcat/hashcat/commit/2f4dfdc6454f62dbf20e2d1ec26ff2574921e1c5\nhttps://github.com/hashcat/hashcat/commit/12e93659ed9d54fd9b1fef32d3c3af2b86bbcd5b\nDon't see a reason to do that.\nMakes it harder to read. Are there any technical advantages?\n\nSince C has no references we have to use pointers to replace macros with inlines. The addresses of operands are not params for macros\n\nThat's why wo do macros. They can be very useful because they make code easy to read.\n\nType safety and \"source-code safety\" (I mean that if you see the code you can expect that it is actual code, and if you see it valid, it's valid, and if you encounter a compilation error you can investigate the cause without dumping preprocessed output, and if you debug, you see the code corresponding to binary not tampered with macros) are always an advantage. Macros must be eliminated everywhere it is possible because they make the project unmanageable.\n\nI can see your point here and I can agree. OTOH in crypto universe macros are very common. People know how to deal with them. \nFor those, we should stick to macros.\n\nAnother problem is that I see that some defines in your code I've turned into consts/enums/inlines.\n\nYes, I liked that. I think I merged all of your changes related to them.\n\n\nhttps://github.com/hashcat/hashcat/commit/239dd7ef9529a584ae9a32301405716845c13d05\nhttps://github.com/hashcat/hashcat/commit/4db249206c33d3667ac21ead57e88973f0cdb8f5\nhttps://github.com/hashcat/hashcat/commit/4b4f7ac7dca1edbb721a6180ccc82755483e4f5c\nNot merged.\nI don't see any disadvantages.\n\ntheoretically using include guards instead of pragmas slowes the compilation: the preprocessor have to load a file and process it instead of checking its internal associative container to determine if the file was already used. We have to solve problem with pragmas on Mac.\n\nWe don't need to discuss here, I also like the pragma approach. But it's not a decission. We simply can't use it because if it doesn't work with OSX it's a no-go.\n\n\nThis section has been taken of from original ADL headers from AMD. I don't think we should change anything to them directly. Can we do this indirectly?\nThis section has been taken of from original NVML headers from Nvidia. I don't think we should change anything to them directly.\n\nWe should decide how do we use the headers: as black boxes or as white ones. If we use them as black boxes we don't touch them at all and even don't have them in repo by itself, using submodules and make system (first check predefined paths, if not present - using submodules). If we use them as white boxes we are free to modify them.\n\nUnfortionally there's no github repository for most of those. Some of the features, especially in NvAPI, isn't even documented. Till today it wasn't required to do any changes to those headers because the vendor didn't change them.\nThat means, technically I'd like to handle them as \"black box\". But adding those SDK's would create a lot of depencies for the compilation. We had this approach in v2.xx series, but too many people failed to build the project just because of them. It's hindering the package maintainer on linux to create hashcat binaries and that's bad for it's evolution. That's why we this middle way and that's why we should stick to it.\n\nAnother issue is manual libraries loading. We should consider not to load libraries manually but to rely on compiler/linker delay load feature. GCC and VS have it.\n\nI disagree. I always found it very problematic, especially on linux. Since there's no real standartized path where the shared libraries reside it often happens that they can't be found. Even worse, it can occur that they exist twice or more in different paths. Especially with OpenCL.so this creates a lot of problems. Therefore it's very nice for the binary to be able to predefine the path to search in the runtime.\n\n\nhttps://github.com/hashcat/hashcat/commit/31f45acc8f88aefd58bddcd8575e9ebf8e29a2f7 \nhttps://github.com/hashcat/hashcat/commit/ebea5c5102af95c8899e732d7b60d15e7849b26b\nhttps://github.com/hashcat/hashcat/commit/796bb055adade57a06e325833e270ac08de76588\nhttps://github.com/hashcat/hashcat/commit/693649fadb5ee6898a71d3b9d55e349e80385a16\nhttps://github.com/hashcat/hashcat/commit/b6d20be1229765aeb0e88ea0f8f72ac97c37395c\nhttps://github.com/hashcat/hashcat/commit/210ddd04b50a06d3573fc7d8101e11678f549009\nNot merged (yet).\nWill do this (typing) when refactoring is completely finished\n\nOK. Some commits' messages contain regexes or scripts used to do them.\n\nWhat I meant is the use of the enum datatypes instead of \"int\". Once the refactor is close to be finish, or when it's clear that we will not need to add more enum datatypes, I will merge those, too.\n\n\nhttps://github.com/hashcat/hashcat/commit/6c8e7020a9a6315298e50f4efaed98dcb558a0c9\nNot merged\nShould be fine as it is.\n\nDo you really consider buffer overflow possibility fine?\n\nI don't, I just don't like the way you fixed it. I think this can be done better.\n\n\nhttps://github.com/hashcat/hashcat/commit/72b91dc6a5fb32156a2912f2eb68c100635acc22\nNot merged\nWays too large, I think because of spaces/tabs. Not sure what changed\n\nReally?\n\nWhat I mean is that the diff was too large to see what actually changed, since there was a large mix with the space/tab changes.\n\nThis was just making C++ compiler happy about types.\n\nOK, type casting is useful. If you want, send them in as a single PR again (without the changes to spaces/tabs) and I'll merge them.\n\n\nhttps://github.com/hashcat/hashcat/commit/dd09ba60b2b55655d4656bf67dc8d9dc2fd49d35 \nNot merged\n\nWhy? Are you going to merge this later?\n\nThose code section do no longer exist \n\n\nhttps://github.com/hashcat/hashcat/commit/916c377ce3f7a7e55171c61e63f86d48cdc0a237\nNot merged\nSection no longer exist\n\nReally? thread.[hc] have this function declaration/definition unfixed\n\nYes, there's no more hc_signal() at all.\n\n\nhttps://github.com/hashcat/hashcat/commit/6622cb1526ea55aaceb9520adac47c40ec4f71c7\n\nit's some hwmon-related stuff\n\nI don't see what I missed here. You remove some hwmon code, yes. But you did not replace it with something new.\n\nAnd you'v missed\nhttps://github.com/hashcat/hashcat/commit/3a816a348e4dd29daaa4027560171dc56f6ef2c1\n\nThat file doesn't exist anymore\n\nhttps://github.com/hashcat/hashcat/commit/80cfc89f7025fa386f006adecd2415845d1f921d\n\nThat file doesn't exist anymore. Note that ascii_digest was moved to interface.c. We maybe should refactor it, so that we have the opposite of parse_* function for each hash-mode. That would also help to split interface.c into many files. But moving ascii_digest() as-is into a single file is not a good solution.\n\nhttps://github.com/hashcat/hashcat/commit/91767b8fa9ec3834643b2ab3e532df1c04c7d45f\n\nI merged that\n\nhttps://github.com/hashcat/hashcat/commit/0531df75e7c550df51d63b50465534957b19128b\n\nWe discussed that above, I don't think crypto related macros should be replaced with functions.\n\nhttps://github.com/hashcat/hashcat/commit/11f58ee7959b84ecbcbfed0c7d1a28ee3390eae4\n\nI merged that\n\nhttps://github.com/hashcat/hashcat/commit/3a816a348e4dd29daaa4027560171dc56f6ef2c1\n\nI don't see what I missed here.\nWhat I think of how we should continue:\n- I'd suggest you to clone hashcat repo as it is and to redo your work. That makes it easier for both of us to handle the required changes.\n- If you want, you can send in a PR with the changes from \"int\" to enum datatype\n- If you want, you can send in a PR with the type castings that I missed\n- I'm not a big fan of cmake. Please try to avoid it.\n- I like the idea that VS is able to compile the binaries, but not at all cost. If you can send in a single PR to handle this case, please do it. I'll decide if the changes to the code is too large.\n- We should stick to how we handle hwmon stuff like it is. That is not link it at compile-time, not change the headers as they come in from the SDK and compile all submodules for all OS and let the runtime decide how to handle this stuff.\n- For the large file interface.c I'm open to refactor. If you want, split them into single files and move them to a special folder.\n. > In any case I'm not going to fix anything untill someone solved the problems with the files violating c++ standard which make succesful build using VS impossible.\nI don't know about such a problem. Is it the ones with the datatypes? Can you make one example so that I can try to fix it?\n. @KOLANICH is there anything you'd like to change left?\n. OK, thanks!\n. Propably not enough host memory for mingw, so the process gets killed by the OS. Anyway, not a hashcat issue, so closed.\n. Propably power consumption issue. The RX480 is not pci compliant. It's known to suck more power from the board than allowed. Anyway, not a hashcat issue, so closed.\n. Your CPU needs an OpenCL runtime\n. Is that fnv1a32() the entire algorithm?\n. > Tried to do a mask attack(new to this) with ?l?l?l?l?lbut instead of a range of aaaaa -> zzzzz I got sange -> uqoql.. Can my .cl file affect that?\nThe .cl can not affect that, no worries. It's like @magnumripper said, it's the markov-chain optimization. You can disable it with --markov-disable if you want to make sure. You can also use --stdout to watch the full output, just to make sure all candidates were generated as expected.\n\nWhat is il?\n\nThe 'il' stands for inner loop and is the only way to make full use of the GPU power for fast hashes. Inside that loop, the first 1-4 byte of the password were replaced/iterated. \n\nIs cnt count?\n\nYes.  it's a value calculated by the autotune engine, but has an upper limit of 1024. That means it's not large enough to hold al possible combinations of 2^32 which w0 can hold, that's why the process is restarted again and again with an increased offset, but this one is set outside the algorighm kernel, it's used in the password candidate kernels.\n\nDoes the r/l in w0r/w0l mean right/left?\n\nYes it does. hashcat calculates how many letters (between 1 and 4).\n\nWhat is the difference between u32x to u32?\n\nu32x is the vector datatype variant of u32 to make use of VLIW/SSE*\n. You can use the device global memory to store such information but you have to allocate the memory range to hold that from outside the kernel. This is pretty limited to a max of 2GB on high end systems because of the 1/4 memory OpenCL specification limitation. Anyway as easy as it sounds, as complex it is in real world. The best way to deal with it would be to generate the innerloop part for the end of the password, not the beginning. In such a scenario you could simply precompute the prefix before entering the inner loop and get full speed, regardless of the length. Such a change isn't easy, because it's not compatible with hashcat's structure. You could also workaround this with a salt which you can preprocess, but in that case you'd need to know the salt before running hashcat which could be a bit uncomfortable. Anyway, the algorithm itself seems pretty bad. Maybe you get better results by exploiting the algorithm itself. You wouldn't be able to BF a string of length 30 anyway, so you'r best change is to build the \"password\" by appending known substrings like payday2.\n. If \"ene_\" is fixed, the il_cnt will become 1 and make the kernel inefficient. You need to workaround this. See the other issue on how to do that.\n. Note that v2 doesn't use OpenCL for CPU, but v3 does. Now it seems the OpenCL runtime for the NVC4 has some internal problems, hence the CL_BUILD_PROGRAM_FAILURE. Sorry, but not a hashcat issue\n. OK, what's wrong with simple Make?\n. 1) About crossplatform: Currently hashcat compiles natively on linux, freebsd, windows (using msys2) and osx. What's missing?\n2) About many toolchains: I personally prefer to have dedicated code for buildng and linking command line by hand for every compiler and platform than to have \"project files\". Such files always create a feeling of \"I have no clue what's going inside there\" and this gives me a bad feeling. Does CMAKE create such files?. I see no reason to keep this issue open. There's no real benefit using cmake. I was under the impression cmake is required to build hashcat from VS, but it seems that's not the case. @KOLANICH  If I'm wrong, please reopen. Looks like your OpenCL install is broken. Please continue on hashcat forum, github issues is for bugs and feature requests.\n. That's because with 7-zip there's a high chance of false positives. We can't be sure the password is really correct. That's why we have to mark it as NEVER_CRACK, which then leads to the fact that it can not increase the recovered status. Anyway, sharp eye you have, but it will not change here.\n. Please explain, what is that BEX error and which effects does it have?\n. Sounds like some mingw issue and not sure which compiler and linker flags you mean. Also, how did you notice this? hashcat runs normally on my Windows 7.\n. OK I've added it and created some new beta binaries. Can you test please and close the issue if fixed?\n. Binary beta can be found here: https://hashcat.net/beta/\nBut I make the change in the current master branch, too: https://github.com/hashcat/hashcat/blob/master/src/Makefile#L176\nYou can also try to compile from source on windows (Msys2 works fine).\n. @KOLANICH did it work?\n. Can we close this issue?. I've added that flags only for you. I guess I can close the ticket now.. There was a problem for large dictionaries related to u32 as word counter. I've changed this to u64. I think this was the real problem.\n. Why use MESA driver if you have a NVidia device. Please install correct OpenCL runtime.\n. Thanks!\n. There's no discussion needed about this behavior. It's a well known limitation and there's also a standard workaround. Therefore I'm closing this issue.\nHere's an explanation: Without a fixed w[0] the innerloop has nothing to iterate through, the il_cnt variable will be 1 and the kernel will finish too fast to run efficient. After that, hashcat will run the candidates generator to produce the next set of parallelized candidates. This kernel takes some serious time as it has to read and write to global memory.  This is not a problem usually because compared to the hashing kernel it's almost no time. The typical kernel with -w 3 will run at 100ms while the candidate generator kernel will run a 0.1ms, so the GPU utilization for actual cracking is very high. But if you set il_cnt to 1, the kernel will take 0.1ms as well and the GPU utilization for actual cracking drops massive. Note the numbers are not very accurate but help explaining this.\nThe best workaround is to have a prefix added to the hash as a salt. This way you can also make use of a precomputed intermediate hash for this static data before you enter the inner loop. You can see -m 20 on how to do that.\n. I need a way to reproduce, please provide the files required\n. Also, try with latest beta: hashcat.net/beta\n. I don't think so, because the MD5 kernel isn't involved in the potfile handling. Please pack the data I need to reproduce this, upload it somewhere (maybe password protect it before) and send me the link in an email to atom@hashcat.net\n. Please retry with latest beta version from https://hashcat.net/beta/ and close the issue if fixed\n. Where did you see that this algorithm is supported? It's not.\n. Done integrating back. Please try with latest beta: hashcat.net/beta and report back\n. I tested on Windows 7 64 bit and restore works fine. Can you do a screenshot of what's wrong?\n. OP did not respond and the issue can not be reproduced, so closed. Feel free to reopen and to provide more information I need to reproduce.\n. This looks like an OpenCL runtime installation problem. Please install latest driver and also try with a different OpenCL tool. If it still does not work, please use hashcat forum for report. GitHub is for bug reports and feature requests.\n. Useless site-specific algo. Makes no sense to add. Are you using a beta version?\n. Please retry with latest beta version from https://hashcat.net/beta/ and close the issue if fixed\n. Please retry with latest beta version from https://hashcat.net/beta/ and close the issue if fixed\n. With DES there can be many valid keys, because the keyspace is 56 bit not 64 bit. Each of them can be used to correctly decrypt the CT. See here:\nroot@ht:~# perl -e 'print pack (\"H*\", \"3132333435363738\")' | openssl enc -des-ecb -K 3132333435363738 | xxd\n00000000: 96d0 0288 78d5 8c89 feb9 59b7 d464 2fcb  ....x.....Y..d/.\nroot@ht:~# perl -e 'print pack (\"H*\", \"3132333435363738\")' | openssl enc -des-ecb -K 3132333435363639 | xxd                \n00000000: 96d0 0288 78d5 8c89 feb9 59b7 d464 2fcb  ....x.....Y..d/.\n. I can reproduce, thanks. Trying to fix...\n. Nice, thanks!\n. Invalid use of hashcat, please ask on forum for correct syntax\n. That solution slows down cracking massive, because allocating an setting memory to zero would be done for each cracked hashes. If you have a large unsalted hashlist, cracking speed will drop 1000th of times.\nA better way to handle this would be to preallocate that buffer somewhere and move it with the context. Can you please change?\n. @magnumripper That's a good question actually. When I saw this I thought about this is some OSX speciality I don't know about. This works fine for Linux/Windows usually.\n. @mouse07410 I've pushed https://github.com/hashcat/hashcat/commit/2a330122b4095506aa16fce1d2d83707e528c2cf which includes the changes you suggested\n. @matrix Good work. Looks like you found the root of the problem (stack size). The solution using the buffer in context is exactly what I was looking for. Big Thanks!\n. please close the issue then\nOn 30.10.2016 14:15, Mouse wrote:\n\n@matrix https://github.com/matrix and @jsteube\nhttps://github.com/jsteube thank you - it works now with the\nlatest/current master oclHashcat.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/552#issuecomment-257150308,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OduqaENa_IOQ58byu9q81Mh6TJjoks5q5JhVgaJpZM4KjIHD.\n. Thanks!\n. Implemented: https://github.com/hashcat/hashcat/commit/2bda020c83ea07e6b8d3f807a1deb3a784c86876\n. Good testing man, keep going\n. @neheb Can you fix those please: cc1: error: unrecognized command line option \u2018-Wfloat-conversion\u2019\n. There's also a technical reason for this. That is because hashcat can not now how fast an attack really is before actually running it. That is because in mask-mode, the mask has to be split in two parts internally and it depends on different factors at which position to split it. That means with a chaning mask (due to increment) the split point changes and if the split point changes, the performance changes. If the performance changes the time estimation changes.\n. Please don't use attribute ((const)) and attribute((pure)) it makes the code kind of hard to read.\nBut I liked the attribute ((format (printf, 2, 3))) and hand-merged it.\nI also hand-merged your changes related to fix the issue that are visible due to this.\nI had to use -Wformat-zero-length because the empty string in event_log_*() has a special meaning.\nThanks!\n. Hm, doesn't happend here. How do you compile?\n. Some more discussion material:\n\nFrom @magnumripper \n\nJtR core supports arbitrarily long salts but most optimized formats has a fairly tight limit just like Hashcat, to keep things in one or two Merkel Damgard blocks.\nThis particular format is supported in JtR as dynamic_2009 (only CPU) with salt lengths up to 200 (same format with max. 23 bytes salt is dynamic_9 and it's obviously faster).\n\nFrom https://github.com/hashcat/hashcat/issues/79\n\nA new limit on length to 35-40 on the most common algorithms\n\nFrom https://github.com/hashcat/hashcat/issues/95\n\nSaltLen = 130\n\nFrom https://github.com/hashcat/hashcat/issues/442\n\n... whatever hashcat supports salt length 40 or not.\n. There's such a system for the different passwords lengths (to make automatic use of zero-based optimizations). I think we can do the same for salt lengths.\n. I've made some experiments to find about what speed loss this will cause to the existing modes. Here's the results from my 750Ti using the same hash:salt combination for all 4 tests:\n\ncurrent sha1($salt.$pass):\n-a0: 734.4 MH/s\n-a3: 1047.2 MH/s\nmodified sha1($salt.$pass) with support for up to length 64 salt and length 64 password:\n-a0: 665.5 MH/s (10% loss)\n-a3: 864.5 MH/s (21% loss)\n. If you're interessted, I've pushed a branch which allows cracking of passwords and salts up to length 256 both here: https://github.com/hashcat/hashcat/tree/longer_passwords_and_salts\nThe drops are not that big as in previous attempts, but they are a bit more work intensive. Means each kernel would require a work intensive rewrite. For example, there would be a kernel that allows only combination of 16+16, 32+32 and all+all. This way the drop on MD5 (in -a 1 mode) is: 1451.5 MH/s -> 1374.6 MH/s. In -a 0 (rules) mode, the drop will be much bigger of course.\nIt is however only working with md5 and in -a 1 mode and it's more like an experiment. You can rewrite it to do sha256 if you have some programming experience. . Finished implementation with v4.0.0. Can reproduce, fixing\n. I think I can agree if we find a way to tell if a string is a valid UTF-8 string. For example $HEX[00003030] surely is not. In such a case we should stick to $HEX[...]. Is there any easy way to check this?\n. merged, thanks!\n. The output of a cracked hash to stdout, even in combination with --quiet, is the wanted behavior if you do not specify -o. The event of a cracked hash is too important to get lost/unnoticed. It also goes back to the time when we did not had --machine-readable, the --quiet option was used to help to reduce the number of output to skip/ignore in case output was used from a script. Anyway if you use -o the output should be totally quiet. I think we shouldn't do a change at this point.\nThe thing with the slowdown is different. There's a couple of things that need to be done when we have a cracked hash and they all slow down the process. I always thought that's ok, because a cracked hash is a rare event. For one, a mutex gets active and blocks all other threads to output more cracked hashes. But I think the biggest slowdown is that the output file is opened and closed every time a new password is cracked. Reason here is that we want to allow the user he can remove the output file safely while hashcat is running. If there's a better solution that allows us to keep the fd open I'm open to change this, but it should support the case that the user removes the outfile while hashcat runs.\n. I guess that must have been going under while I was refactoring everything, sorry. It didn't happen intentionally. \nI'm wondering, you're locking the files, but never unlock them. Do you think it's ok?\n. > You should ideally open your session file at start of run, then lock it and never close it (I think that's not the case right now) until actually exiting\nIf it's not the case, I will rewrite it to do that because that's the expected behaviour. I'll do that after the merge.\n\nAre you planing to add something to this or can I merge already?\n. OK I merged, the compiler complains about the following when compiling for windows:\nIn file included from src/logfile.c:11:0:\nsrc/logfile.c: In function \u2018logfile_append\u2019:\ninclude/locking.h:23:28: warning: statement with no effect [-Wunused-value]\n #define lock_file(dummy)   0\n                            ^\nsrc/logfile.c:54:3: note: in expansion of macro \u2018lock_file\u2019\n   lock_file (fp);\n   ^\nCan you try to find a different solution?\n. I'll merge this. I'll maybe change the check for LM and move it to here:\nhttps://github.com/hashcat/hashcat/blob/master/src/interface.c#L17428-L17443\nand add an option like OPTS_TYPE_PT_NO_UTF8 to mark those algorithms. Thanks for that check, saves me alot of headache checking for it :)\n. I don't like this alot, because it creates some inbalance. It would enable to set -s and -l for an iterated attack, but only for one special. For example, this would not work to set -s and -l for a folder full of wordlists, which hashcat supports and which is also an iterated attack.\nOTOH I don't see a reason how this helps in a distributed solution. In such a scenario, there should be no iterated attack at all, because it becomes hard to control. \n. Like, every attack that support wordlist also supports wordlist folders, except -a1. \nSee here:\nroot@sf:~/hashcat# cat hash\n7f306bca1a462127e59b9154599c443a\nroot@sf:~/hashcat# cat wordlist1.txt \nword1\nroot@sf:~/hashcat# cat wordlist2.txt \nword2\nroot@sf:~/hashcat# ./hashcat hash *.txt --quiet                       \n7f306bca1a462127e59b9154599c443a:word2 \nroot@sf:~/hashcat#\nThat means if we change support for -s and -l we should change it for all attack modes, otherwise this creates confusion. \nOn the other hand I still don't see why we should need this in case of a mask file. I see that loading a large hashlist will take time, and restarting hashcat will create some overhead then. But having a large hashlist means you're trying to crack a fast hash, not a list of scrypt hashes. But fast hashes and small masks - this is a waste of time anyway. What I means is there's a misconception here if you try to distribute workload of fast hashes with small masks. This would make sense only if you want to crack a slow hash, but for a slow hash you wouldn't try to crack a large hashlist. Currently, when you use a large mask, the total runtime of the session will take longer and then it will make sense to hashcat to restart and to reload the hashes.\nFinally, the implementation is kinda buggy. For example:\nline1: ?u?d?d?d?u?d?d?d|30000|20000\nThen how could a user create a mask that includes the prefix |30000|20000? Currently this mask would be a valid mask, for good reason. The currect implementation would either be to move those options to the left and create two special (optional) columns for it. Or as alternative, since hashcat has good support for escape characters, why not simply continue to use \",\" as separator character. If the user actually wanted to use \",\" as a fixed character in the mask he can escape it. Either way, that's just implementation. The main reason I don't want this is the one state above.\n. Hey, I can not reproduce. Can you please compile from source using\nDEBUG=1 and paste a bt from gdb?\nOn 06.11.2016 16:36, thesle3p wrote:\n\nHey it looks like hashcat core dumps at run time starting two commits\nago. Here is the coredump:\n|* Error in `./hashcat': munmap_chunk(): invalid pointer:\n0x000000000191c760 * ======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fc31feba7e5]\n/lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fc31fec6ae8]\n./hashcat[0x403409] ./hashcat[0x414846] ./hashcat[0x414b52]\n./hashcat[0x402581]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7fc31fe63830]\n./hashcat[0x4025d9] ======= Memory map: ======== 00400000-0048c000\nr-xp 00000000 fc:01 61213746 /home/bob/Toolz/hashcat/hashcat\n0068c000-0068d000 r--p 0008c000 fc:01 61213746\n/home/bob/Toolz/hashcat/hashcat 0068d000-0068e000 rw-p 0008d000 fc:01\n61213746 /home/bob/Toolz/hashcat/hashcat 017fe000-037bb000 rw-p\n00000000 00:00 0 [heap] 200000000-200100000 rw-s f19b98000 00:06 603\n/dev/nvidiactl 200100000-200104000 rw-s f1992a000 00:06 603\n/dev/nvidiactl 200104000-200120000 ---p 00000000 00:00 0\n200120000-200520000 rw-s f803e0000 00:06 603 /dev/nvidiactl\n200520000-200524000 rw-s d573de000 00:06 603 /dev/nvidiactl\n200524000-200540000 ---p 00000000 00:00 0 200540000-200940000 rw-s\nf1af62000 00:06 603 /dev/nvidiactl 200940000-200944000 rw-s dc0f31000\n00:06 603 /dev/nvidiactl 200944000-200960000 ---p 00000000 00:00 0\n200960000-200d60000 rw-s dc0f35000 00:06 603 /dev/nvidiactl\n200d60000-200d64000 rw-s dbec24000 00:06 603 /dev/nvidiactl\n200d64000-200d80000 ---p 00000000 00:00 0 200d80000-201180000 rw-s\ndbec28000 00:06 603 /dev/nvidiactl 201180000-201184000 rw-s dc0c3c000\n00:06 603 /dev/nvidiactl 201184000-2011a0000 ---p 00000000 00:00 0\n2011a0000-2015a0000 rw-s dc0d28000 00:06 603 /dev/nvidiactl\n2015a0000-2015a4000 rw-s dc0df7000 00:06 603 /dev/nvidiactl\n2015a4000-2015c0000 ---p 00000000 00:00 0 2015c0000-2019c0000 rw-s\nd5634f000 00:06 603 /dev/nvidiactl 2019c0000-2019c4000 rw-s dbf992000\n00:06 603 /dev/nvidiactl 2019c4000-2019e0000 ---p 00000000 00:00 0\n2019e0000-201de0000 rw-s dbf99e000 00:06 603 /dev/nvidiactl\n201de0000-201de4000 rw-s f1c66d000 00:06 603 /dev/nvidiactl\n201de4000-201e00000 ---p 00000000 00:00 0 201e00000-202200000 rw-s\nf1c67d000 00:06 603 /dev/nvidiactl 202200000-202204000 rw-s ee6d8e000\n00:06 603 /dev/nvidiactl 202204000-202220000 ---p 00000000 00:00 0\n202220000-202620000 rw-s ee6d9b000 00:06 603 /dev/nvidiactl\n202620000-202624000 rw-s dc33fa000 00:06 603 /dev/nvidiactl\n202624000-202640000 ---p 00000000 00:00 0 202640000-202a40000 rw-s\nd5674a000 00:06 603 /dev/nvidiactl 202a40000-202a44000 rw-s d57696000\n00:06 603 /dev/nvidiactl 202a44000-202a60000 ---p 00000000 00:00 0\n202a60000-202e60000 rw-s d576a2000 00:06 603 /dev/nvidiactl\n202e60000-202e64000 rw-s ee7795000 00:06 603 /dev/nvidiactl\n202e64000-202e80000 ---p 00000000 00:00 0 202e80000-203280000 rw-s\nf19e98000 00:06 603 /dev/nvidiactl 203280000-203284000 rw-s dc3b7d000\n00:06 603 /dev/nvidiactl 203284000-2032a0000 ---p 00000000 00:00 0\n2032a0000-2036a0000 rw-s dbf0a5000 00:06 603 /dev/nvidiactl\n2036a0000-2036a4000 rw-s ee9628000 00:06 603 /dev/nvidiactl\n2036a4000-2036c0000 ---p 00000000 00:00 0 2036c0000-203ac0000 rw-s\nee9634000 00:06 603 /dev/nvidiactl 203ac0000-203ac4000 rw-s f19cc7000\n00:06 603 /dev/nvidiactl 203ac4000-203ae0000 ---p 00000000 00:00 0\n203ae0000-203ee0000 rw-s f19cd3000 00:06 603 /dev/nvidiactl\n203ee0000-203ee4000 rw-s ee7062000 00:06 603 /dev/nvidiactl\n203ee4000-203f00000 ---p 00000000 00:00 0 203f00000-204300000 rw-s\nee706e000 00:06 603 /dev/nvidiactl 204300000-204400000 rw-s dc3509000\n00:06 603 /dev/nvidiactl 204400000-204500000 rw-s dc0023000 00:06 603\n/dev/nvidiactl 204500000-204600000 rw-s dc06a6000 00:06 603\n/dev/nvidiactl 204600000-204700000 rw-s f19da8000 00:06 603\n/dev/nvidiactl 204700000-204800000 rw-s ee6aac000 00:06 603\n/dev/nvidiactl 204800000-2048e0000 rw-s dbe8b4000 00:06 603\n/dev/nvidiactl 2048e0000-1700000000 ---p 00000000 00:00 0\n7fc2a8000000-7fc2a8021000 rw-p 00000000 00:00 0\n7fc2a8021000-7fc2ac000000 ---p 00000000 00:00 0\n7fc2ac000000-7fc2ac021000 rw-p 00000000 00:00 0\n7fc2ac021000-7fc2b0000000 ---p 00000000 00:00 0\n7fc2b0000000-7fc2b0021000 rw-p 00000000 00:00 0\n7fc2b0021000-7fc2b4000000 ---p 00000000 00:00 0\n7fc2b67f9000-7fc2ba7fb000 rw-p 00000000 00:00 0\n7fc2d8000000-7fc2d8021000 rw-p 00000000 00:00 0\n7fc2d8021000-7fc2dc000000 ---p 00000000 00:00 0\n7fc2de7fd000-7fc2de7fe000 ---p 00000000 00:00 0\n7fc2de7fe000-7fc2deffe000 rw-p 00000000 00:00 0\n7fc2deffe000-7fc2defff000 ---p 00000000 00:00 0\n7fc2defff000-7fc2df7ff000 rw-p 00000000 00:00 0\n7fc2e0000000-7fc2e0021000 rw-p 00000000 00:00 0\n7fc2e0021000-7fc2e4000000 ---p 00000000 00:00 0\n7fc2e4fc5000-7fc2e4fc6000 ---p 00000000 00:00 0\n7fc2e4fc6000-7fc2e57c6000 rw-p 00000000 00:00 0\n7fc300fc7000-7fc3026fd000 r-xp 00000000 fc:01 110627755\n/usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.375.10\n7fc3026fd000-7fc3028fc000 ---p 01736000 fc:01 110627755\n/usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.375.10\n7fc3028fc000-7fc303fd1000 rw-p 01735000 fc:01 110627755\n/usr/lib/x86_64-linux-gnu/libnvidia-compiler.so.375.10\n7fc303fd1000-7fc304000000 rw-p 00000000 00:00 0\n7fc304000000-7fc304021000 rw-p 00000000 00:00 0\n7fc304021000-7fc308000000 ---p 00000000 00:00 0\n7fc308737000-7fc308738000 ---p 00000000 00:00 0\n7fc308738000-7fc308f38000 rw-p 00000000 00:00 0\n7fc30a539000-7fc30ad03000 r-xp 00000000 fc:01 110627749\n/usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.375.10\n7fc30ad03000-7fc30af02000 ---p 007ca000 fc:01 110627749\n/usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.375.10\n7fc30af02000-7fc30aff5000 rw-p 007c9000 fc:01 110627749\n/usr/lib/x86_64-linux-gnu/libnvidia-ptxjitcompiler.so.375.10\n7fc30aff5000-7fc30affe000 rw-p 00000000 00:00 0\n7fc30affe000-7fc30afff000 ---p 00000000 00:00 0\n7fc30afff000-7fc30b7ff000 rw-p 00000000 00:00 0\n7fc30b7ff000-7fc30b800000 ---p 00000000 00:00 0\n7fc30b800000-7fc30c000000 rw-p 00000000 00:00 0\n7fc30c000000-7fc30c021000 rw-p 00000000 00:00 0\n7fc30c021000-7fc310000000 ---p 00000000 00:00 0\n7fc3101c6000-7fc3101c7000 ---p 00000000 00:00 0\n7fc3101c7000-7fc3109c7000 rw-p 00000000 00:00 0\n7fc3109c7000-7fc3109c8000 ---p 00000000 00:00 0\n7fc3109c8000-7fc3111c8000 rw-p 00000000 00:00 0\n7fc3111c8000-7fc3111c9000 ---p 00000000 00:00 0\n7fc3111c9000-7fc311a30000 rw-p 00000000 00:00 0\n7fc311a30000-7fc311a31000 ---p 00000000 00:00 0\n7fc311a31000-7fc312231000 rw-p 00000000 00:00 0\n7fc312231000-7fc312232000 ---p 00000000 00:00 0\n7fc312232000-7fc319c46000 rw-p 00000000 00:00 0\n7fc319c46000-7fc319c47000 ---p 00000000 00:00 0\n7fc319c47000-7fc31a447000 rw-p 00000000 00:00 0\n7fc31a447000-7fc31a44c000 r-xp 00000000 fc:01 110632565\n/usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0 7fc31a44c000-7fc31a64b000\n---p 00005000 fc:01 110632565\n/usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0 7fc31a64b000-7fc31a64c000\nr--p 00004000 fc:01 110632565\n/usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0 7fc31a64c000-7fc31a64d000\nrw-p 00005000 fc:01 110632565\n/usr/lib/x86_64-linux-gnu/libXdmcp.so.6.0.0 7fc31a64d000-7fc31a64f000\nr-xp 00000000 fc:01 110632554\n/usr/lib/x86_64-linux-gnu/libXau.so.6.0.0 7fc31a64f000-7fc31a84f000\n---p 00002000 fc:01 110632554\n/usr/lib/x86_64-linux-gnu/libXau.so.6.0.0 7fc31a84f000-7fc31a850000\nr--p 00002000 fc:01 110632554\n/usr/lib/x86_64-linux-gnu/libXau.so.6.0.0 7fc31a850000-7fc31a851000\nrw-p 00003000 fc:01 110632554\n/usr/lib/x86_64-linux-gnu/libXau.so.6.0.0 7fc31a851000-7fc31a872000\nr-xp 00000000 fc:01 110633932\n/usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0 7fc31a872000-7fc31aa71000\n---p 00021000 fc:01 110633932\n/usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0 7fc31aa71000-7fc31aa72000\nr--p 00020000 fc:01 110633932\n/usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0 7fc31aa72000-7fc31aa73000\nrw-p 00021000 fc:01 110633932\n/usr/lib/x86_64-linux-gnu/libxcb.so.1.1.0 7fc31aa73000-7fc31aba8000\nr-xp 00000000 fc:01 110632550\n/usr/lib/x86_64-linux-gnu/libX11.so.6.3.0 7fc31aba8000-7fc31ada8000\n---p 00135000 fc:01 110632550\n/usr/lib/x86_64-linux-gnu/libX11.so.6.3.0 7fc31ada8000-7fc31ada9000\nr--p 00135000 fc:01 110632550\n/usr/lib/x86_64-linux-gnu/libX11.so.6.3.0 7fc31ada9000-7fc31adad000\nrw-p 00136000 fc:01 110632550\n/usr/lib/x86_64-linux-gnu/libX11.so.6.3.0 7fc31adad000-7fc31aebe000\nr-xp 00000000 fc:01 110627735\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.375.10\n7fc31aebe000-7fc31b0bd000 ---p 00111000 fc:01 110627735\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.375.10\n7fc31b0bd000-7fc31b0ce000 rw-p 00110000 fc:01 110627735\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.375.10\n7fc31b0ce000-7fc31b0e3000 rw-p 00000000 00:00 0\n7fc31b0e3000-7fc31b7ad000 r-xp 00000000 fc:01 110627743\n/usr/lib/x86_64-linux-gnu/libcuda.so.375.10 7fc31b7ad000-7fc31b9ac000\n---p 006ca000 fc:01 110627743\n/usr/lib/x86_64-linux-gnu/libcuda.so.375.10 7fc31b9ac000-7fc31bac7000\nrw-p 006c9000 fc:01 110627743\n/usr/lib/x86_64-linux-gnu/libcuda.so.375.10 7fc31bac7000-7fc31bad4000\nrw-p 00000000 00:00 0 7fc31bad4000-7fc31bb16000 r-xp 00000000 fc:01\n110627748\n/usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.375.10\n7fc31bb16000-7fc31bd15000 ---p 00042000 fc:01 110627748\n/usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.375.10\n7fc31bd15000-7fc31bd1f000 rw-p 00041000 fc:01 110627748\n/usr/lib/x86_64-linux-gnu/libnvidia-fatbinaryloader.so.375.10\n7fc31bd1f000-7fc31bd20000 rw-p 00000000 00:00 0\n7fc31bd20000-7fc31c43b000 r-xp 00000000 fc:01 110627744\n/usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.375.10\n7fc31c43b000-7fc31c63a000 ---p 0071b000 fc:01 110627744\n/usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.375.10\n7fc31c63a000-7fc31c75b000 rw-p 0071a000 fc:01 110627744\n/usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.375.10\n7fc31c75b000-7fc31c767000 rw-p 00000000 00:00 0\n7fc31c767000-7fc31c7c5000 r-xp 00000000 fc:01 11272962\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcpu_device.so\n7fc31c7c5000-7fc31c9c5000 ---p 0005e000 fc:01 11272962\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcpu_device.so\n7fc31c9c5000-7fc31c9cc000 r--p 0005e000 fc:01 11272962\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcpu_device.so\n7fc31c9cc000-7fc31c9ce000 rw-p 00065000 fc:01 11272962\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcpu_device.so\n7fc31c9ce000-7fc31c9cf000 rw-p 00000000 00:00 0\n7fc31c9cf000-7fc31ca16000 r-xp 00000000 fc:01 11272969\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtbb.so.2\n7fc31ca16000-7fc31cb16000 ---p 00047000 fc:01 11272969\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtbb.so.2\n7fc31cb16000-7fc31cb1b000 rw-p 00047000 fc:01 11272969\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtbb.so.2\n7fc31cb1b000-7fc31cb1d000 rw-p 00000000 00:00 0\n7fc31cb1d000-7fc31cb33000 r-xp 00000000 fc:01 6820166\n/lib/x86_64-linux-gnu/libgcc_s.so.1 7fc31cb33000-7fc31cd32000 ---p\n00016000 fc:01 6820166 /lib/x86_64-linux-gnu/libgcc_s.so.1\n7fc31cd32000-7fc31cd33000 rw-p 00015000 fc:01 6820166\n/lib/x86_64-linux-gnu/libgcc_s.so.1 7fc31cd33000-7fc31ce3b000 r-xp\n00000000 fc:01 6820484 /lib/x86_64-linux-gnu/libm-2.23.so\n7fc31ce3b000-7fc31d03a000 ---p 00108000 fc:01 6820484\n/lib/x86_64-linux-gnu/libm-2.23.so 7fc31d03a000-7fc31d03b000 r--p\n00107000 fc:01 6820484 /lib/x86_64-linux-gnu/libm-2.23.so\n7fc31d03b000-7fc31d03c000 rw-p 00108000 fc:01 6820484\n/lib/x86_64-linux-gnu/libm-2.23.so 7fc31d03c000-7fc31d1ae000 r-xp\n00000000 fc:01 110626945 /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7fc31d1ae000-7fc31d3ae000 ---p 00172000 fc:01 110626945\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7fc31d3ae000-7fc31d3b8000 r--p 00172000 fc:01 110626945\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7fc31d3b8000-7fc31d3ba000 rw-p 0017c000 fc:01 110626945\n/usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.21\n7fc31d3ba000-7fc31d3be000 rw-p 00000000 00:00 0\n7fc31d3be000-7fc31d3c5000 r-xp 00000000 fc:01 6820487\n/lib/x86_64-linux-gnu/librt-2.23.so 7fc31d3c5000-7fc31d5c4000 ---p\n00007000 fc:01 6820487 /lib/x86_64-linux-gnu/librt-2.23.so\n7fc31d5c4000-7fc31d5c5000 r--p 00006000 fc:01 6820487\n/lib/x86_64-linux-gnu/librt-2.23.so 7fc31d5c5000-7fc31d5c6000 rw-p\n00007000 fc:01 6820487 /lib/x86_64-linux-gnu/librt-2.23.so\n7fc31d5c6000-7fc31d5e8000 r-xp 00000000 fc:01 11272960\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcl_logger.so\n7fc31d5e8000-7fc31d7e8000 ---p 00022000 fc:01 11272960\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcl_logger.so\n7fc31d7e8000-7fc31d7e9000 r--p 00022000 fc:01 11272960\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcl_logger.so\n7fc31d7e9000-7fc31d7ea000 rw-p 00023000 fc:01 11272960\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libcl_logger.so\n7fc31d7ea000-7fc31d82f000 r-xp 00000000 fc:01 11272965\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtask_executor.so\n7fc31d82f000-7fc31da2e000 ---p 00045000 fc:01 11272965\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtask_executor.so\n7fc31da2e000-7fc31da32000 r--p 00044000 fc:01 11272965\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtask_executor.so\n7fc31da32000-7fc31da33000 rw-p 00048000 fc:01 11272965\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libtask_executor.so\n7fc31da33000-7fc31db8a000 r-xp 00000000 fc:01 11272963\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libintelocl.so\n7fc31db8a000-7fc31dd8a000 ---p 00157000 fc:01 11272963\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libintelocl.so\n7fc31dd8a000-7fc31dda0000 r--p 00157000 fc:01 11272963\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libintelocl.so\n7fc31dda0000-7fc31dda2000 rw-p 0016d000 fc:01 11272963\n/opt/intel-opencl-icd-VERSION.MINOR/lib/libintelocl.so\n7fc31dda2000-7fc31dda4000 rw-p 00000000 00:00 0\n7fc31dda4000-7fc31ddaa000 r-xp 00000000 fc:01 11272205\n/opt/intel/intel-opencl-1.2-6.0.0.1049/opencl-1.2-6.0.0.1049/lib64/libOpenCL.so.1.2\n7fc31ddaa000-7fc31dfa9000 ---p 00006000 fc:01 11272205\n/opt/intel/intel-opencl-1.2-6.0.0.1049/opencl-1.2-6.0.0.1049/lib64/libOpenCL.so.1.2\n7fc31dfa9000-7fc31dfaa000 r--p 00005000 fc:01 11272205\n/opt/intel/intel-opencl-1.2-6.0.0.1049/opencl-1.2-6.0.0.1049/lib64/libOpenCL.so.1.2\n7fc31dfaa000-7fc31dfab000 rw-p 00006000 fc:01 11272205\n/opt/intel/intel-opencl-1.2-6.0.0.1049/opencl-1.2-6.0.0.1049/lib64/libOpenCL.so.1.2\n7fc31dfab000-7fc31fe43000 rw-p 00000000 00:00 0\n7fc31fe43000-7fc320002000 r-xp 00000000 fc:01 6820492\n/lib/x86_64-linux-gnu/libc-2.23.so 7fc320002000-7fc320202000 ---p\n001bf000 fc:01 6820492 /lib/x86_64-linux-gnu/libc-2.23.so\n7fc320202000-7fc320206000 r--p 001bf000 fc:01 6820492\n/lib/x86_64-linux-gnu/libc-2.23.so 7fc320206000-7fc320208000 rw-p\n001c3000 fc:01 6820492 /lib/x86_64-linux-gnu/libc-2.23.so\n7fc320208000-7fc32020c000 rw-p 00000000 00:00 0\n7fc32020c000-7fc32020f000 r-xp 00000000 fc:01 6820493\n/lib/x86_64-linux-gnu/libdl-2.23.so 7fc32020f000-7fc32040e000 ---p\n00003000 fc:01 6820493 /lib/x86_64-linux-gnu/libdl-2.23.so\n7fc32040e000-7fc32040f000 r--p 00002000 fc:01 6820493\n/lib/x86_64-linux-gnu/libdl-2.23.so 7fc32040f000-7fc320410000 rw-p\n00003000 fc:01 6820493 /lib/x86_64-linux-gnu/libdl-2.23.so\n7fc320410000-7fc320428000 r-xp 00000000 fc:01 6820491\n/lib/x86_64-linux-gnu/libpthread-2.23.so 7fc320428000-7fc320627000\n---p 00018000 fc:01 6820491 /lib/x86_64-linux-gnu/libpthread-2.23.so\n7fc320627000-7fc320628000 r--p 00017000 fc:01 6820491\n/lib/x86_64-linux-gnu/libpthread-2.23.so 7fc320628000-7fc320629000\nrw-p 00018000 fc:01 6820491 /lib/x86_64-linux-gnu/libpthread-2.23.so\n7fc320629000-7fc32062d000 rw-p 00000000 00:00 0\n7fc32062d000-7fc320653000 r-xp 00000000 fc:01 6820488\n/lib/x86_64-linux-gnu/ld-2.23.so 7fc320696000-7fc320697000 r--s\nf8009000 00:06 612 /dev/nvidia1 7fc3206b6000-7fc32082f000 rw-p\n00000000 00:00 0 7fc32082f000-7fc320830000 r--s fa009000 00:06 604\n/dev/nvidia0 7fc320830000-7fc320831000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc320831000-7fc320832000 rw-s dc3505000 00:06 603\n/dev/nvidiactl 7fc320832000-7fc320833000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc320833000-7fc320834000 rw-s ee7061000 00:06 603\n/dev/nvidiactl 7fc320834000-7fc320835000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc320835000-7fc320836000 rw-s f19cc6000 00:06 603\n/dev/nvidiactl 7fc320836000-7fc320837000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc320837000-7fc320838000 rw-s ee9627000 00:06 603\n/dev/nvidiactl 7fc320838000-7fc320839000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc320839000-7fc32083a000 rw-s dc3b7c000 00:06 603\n/dev/nvidiactl 7fc32083a000-7fc32083b000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc32083b000-7fc32083c000 rw-s dc2e2e000 00:06 603\n/dev/nvidiactl 7fc32083c000-7fc32083d000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc32083d000-7fc32083e000 rw-s d57694000 00:06 603\n/dev/nvidiactl 7fc32083e000-7fc32083f000 rw-s efde7000 00:06 604\n/dev/nvidia0 7fc32083f000-7fc320840000 rw-s dc33f9000 00:06 603\n/dev/nvidiactl 7fc320840000-7fc320841000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc320841000-7fc320842000 rw-s ee6d8c000 00:06 603\n/dev/nvidiactl 7fc320842000-7fc320843000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc320843000-7fc320844000 rw-s f1c66c000 00:06 603\n/dev/nvidiactl 7fc320844000-7fc320845000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc320845000-7fc320846000 rw-s dbf991000 00:06 603\n/dev/nvidiactl 7fc320846000-7fc320847000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc320847000-7fc320848000 rw-s dc0df6000 00:06 603\n/dev/nvidiactl 7fc320848000-7fc320849000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc320849000-7fc32084a000 rw-s dc0c3b000 00:06 603\n/dev/nvidiactl 7fc32084a000-7fc32084b000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc32084b000-7fc32084c000 rw-s dbec23000 00:06 603\n/dev/nvidiactl 7fc32084c000-7fc32084d000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc32084d000-7fc32084e000 rw-s dc0f30000 00:06 603\n/dev/nvidiactl 7fc32084e000-7fc32084f000 rw-s efde6000 00:06 604\n/dev/nvidia0 7fc32084f000-7fc320850000 rw-s d573dd000 00:06 603\n/dev/nvidiactl 7fc320850000-7fc320852000 rw-p 00000000 00:00 0\n7fc320852000-7fc320853000 r--p 00025000 fc:01 6820488\n/lib/x86_64-linux-gnu/ld-2.23.so 7fc320853000-7fc320854000 rw-p\n00026000 fc:01 6820488 /lib/x86_64-linux-gnu/ld-2.23.so\n7fc320854000-7fc320855000 rw-p 00000000 00:00 0\n7ffc7b050000-7ffc7b093000 rw-p 00000000 00:00 0 [stack]\n7ffc7b162000-7ffc7b164000 r--p 00000000 00:00 0 [vvar]\n7ffc7b164000-7ffc7b166000 r-xp 00000000 00:00 0 [vdso]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall]\n./example0.sh: line 1: 26497 Aborted (core dumped) ./hashcat -t 32 -a\n7 example0.hash ?a?a?a?a example.dict |\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/573, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oeu172OTM_tveARYjbR88SqmNkhYks5q7fPxgaJpZM4KqleA.\n. No so weird, I added some variables to some context. If you use github,\nalways do a make clean before running make again\n\nOn 06.11.2016 20:12, thesle3p wrote:\n\nClosed #573 https://github.com/hashcat/hashcat/issues/573.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/573#event-849165047, or\nmute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oe0Ek8BL4Ly1xJh8sMbA5i8QuNTbks5q7iaEgaJpZM4KqleA.\n. Can you please explain why do you need this feature at all?\n. See https://github.com/hashcat/hashcat/issues/572 for discussion\n. In theory yes. But this would create some coding effort that I don't really see the sense of it. There's absolutely no performance benefit here. The time it takes would simply multiple by the number of TC volumes you try to crack, like with every salted hash. The difference is that other salted hashes do not come in binary form. So the correct way to implement this would be to rewrite the truecrypt (and so also the veracrypt) parser so that it reads a hash by parsing a hashline, but that would also require some truecrypt2hashcat preloader. I mean this is all possible, but as I said it only creates effort without any benefit so why do it?\n. No response from OP, closing\n. Nice, thanks!\n. Good stuff! I think I fixed them all. Please verify and close the issue.\n. You need to quote, because of the $ char. The shell will try to interpret it as a variable otherwise:\n\n./hashcat64.bin -m 12500 '$RAR3$*0*45109af8ab5f297a*adbf6c5385d7a40373e8f77d7b89d317'\n. Thanks!\n. Thanks!\n. Good stuff, thanks!\n. Unbelieveable! Thanks :)\n. You mean, on the same hccap or a different one?\n. I'm not certain how the hashes are converted (using cap2hccap) exactly, so it could be like @magnumripper said. Only thing I can say is that hashcat does not longer change the ordering of the mac addresses since v3.00. Here's a snippet from the changes:\n\nFixed a bug in implementation of WPA/WPA2: MAC and nonce stay one their original position as in the hccap file\n\nAlso note that it's possible you have two handshakes (or more) with the same essid and mac addresses in your hccap dump. You should check if the file is of exactly 392 byte. If that's the case, please send me all data and commandline options I need to reproduce this case and I'll fix it.\n. Thanks!\n. So far, I've fixed everything (and more) that looked like a real problem. \nThere's two error types left that I find somehow invalid:\n\nObsolescent function 'usleep' called\n\nI really don't see any reason why to change that. There's no sign of deprecation or whatever. Also it's ideal for us, because both linux and windows have it.\n\nResource leak\n\nThis is kind of an error report. For example, the first one:\n[src/cpu_crc32.c:95]: (error) Resource leak: fd\nI've tracked this down. \n- It's totally not related to any FILE* so I don't know why it calls the variable \"fd\". This error repeats\n- It complains about the fact that some memory was allocated but the function returned without free() it. That would be ok to complain unless in an error case. We explicitely check with VERIFY_PTR if the memory allocation was successfull and only if not we return. I mean, what else can we do?\n\n[src/dispatch.c:434]: (style) The scope of the variable 'words_off' can be reduced.\n\nI could fix this pretty easy but I had a nice idea how to rewrite that entire section to be more easy to read. But not before the release, so let it here as kind of a marker.\n. OK, good to know. Any reason to let this issue open?\n. Can you please retry with 3.20 rc2 ? You can download it from\nhttps://hashcat.net/beta/\nOn 17.11.2016 21:05, Giovanni Natale wrote:\n\nWhen attempting to crack NTLM (1000) hashes from pwdump-style output,\nhashcat 3.10 returns BUG feof() and ends. Testing the same hashes in\n2.01 & same arguments works with no issues.\nCommand: hashcat64.bin -p --show --gpu-temp-disable -a3 -o outfile.txt\n-m 1000 --username --status hashes.hash\nSample hash which causes the problem (password is Secure123):\nusername:12345:aad3b435b51404eeaad3b435b51404ee:d6e18fd584c1569b1ba1a8c812ae8c68:::\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/597, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdCivgSHo1obNuUQsc6CBNRKyP-5ks5q_LN0gaJpZM4K1vvE.\n. There's no code to unset device_param->skipped = true after that specific hash-mode, I'll fix\n. I'll try to rephrase. Problem only occurs when not specifying -m in combination with -b. \n\nIf we set skipped = true, the -b mode will skip all hash-modes after the unstable hash-modes because skipped is never set back to false for the stables hash-modes. \nAfter fix, it will look like this:\n```\nroot@ht:~/hashcat# ./hashcat -b --mac\nhashcat (v3.10-757-g72e39a7+)\n1:900:1189:2700:7094485215\n1:0:1189:2700:3842697205\n1:5100:1189:2700:2374526360\n1:100:1189:2700:1307206881\n1:1400:1189:2700:464342317\n1:10800:1189:2700:149045586\n1:1700:1189:2700:152280385\n1:5000:1176:2700:138155729\n1:10100:1189:2700:4513826492\n1:6000:1189:2700:745232064\n1:6100:1189:2700:41219878\n1:6900:1189:2700:40451511\n1:11700:1189:2700:8174836\n1:11800:1189:2700:8178862\n Device #1: skipping unstable hash-mode 14000 for this specific device, use --force to override\n Device #1: skipping unstable hash-mode 14100 for this specific device, use --force to override\n1:400:1189:2700:992828\n1:8900:1189:2700:124326\n1:11900:1189:2700:1086006\n1:12000:1189:2700:522775\n```\n. Yes, working on it\n. Please verify https://github.com/hashcat/hashcat/commit/105513e3077d09126d5e0a6fef52998ba35a0909\n. Good stuff, thanks!\n. The python example attached is broken, please reupload.\n. Luckily I have 3x 1080FE for testing, but on my system everything is fine, see here:\n```\nroot@et:~/hashcat# ./hashcat /root/single -m 900 -w 3 -a 3 ?a?a?a?a?a?a\nhashcat (v3.10-762-g1321cbd) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2026/8106 MB allocatable, 20MCU\nDevice #2: GeForce GTX 1080, 2028/8113 MB allocatable, 20MCU\nDevice #3: GeForce GTX 1080, 2028/8113 MB allocatable, 20MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #4: Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\n* Raw-Hash\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted       \nSession..........: hashcat                              \nStatus...........: Exhausted\nHash.Type........: MD4\nHash.Target......: c919c165e21dce6dbc868377d1b10a39\nTime.Started.....: Fri Nov 18 16:19:45 2016 (6 secs)\nTime.Estimated...: Fri Nov 18 16:19:51 2016 (0 secs)\nInput.Mask.......: ?a?a?a?a?a?a [6]\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....: 44602.7 MH/s (58.39ms)\nSpeed.Dev.#2.....: 44164.4 MH/s (55.30ms)\nSpeed.Dev.#3.....: 44647.5 MH/s (56.36ms)\nSpeed.Dev.#*.....:   133.4 GH/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nRecovered/Time...: CUR:N/A,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.........: 735091890625/735091890625 (100.00%)\nRejected.........: 0/735091890625 (0.00%)\nRestore.Point....: 76021760/81450625 (93.33%)\nCandidates.#1....: 8'>~u->  ~sA-\"\nCandidates.#2....: 8' |G[ ->  ~zB'{\nCandidates.#3....: 8'xL^ ->  ~}z}~\nHWMon.Dev.#1.....: Temp: 45c Fan: 50% Util:100% Core:1885Mhz Mem:4513Mhz Lanes:1\nHWMon.Dev.#2.....: Temp: 48c Fan: 53% Util:100% Core:1809Mhz Mem:4513Mhz Lanes:1\nHWMon.Dev.#3.....: Temp: 46c Fan: 52% Util:100% Core:1835Mhz Mem:4513Mhz Lanes:1\nStarted: Fri Nov 18 16:19:42 2016\nStopped: Fri Nov 18 16:19:52 2016\n```\nNote that's very unusual to run GPU in sli/crossfire mode when doing GPGPU. If possible remove the bridge and retry. Btw this is Ubuntu 16.04 with NV drivers 375.10\n. @thesle3p any updates?. How can I reproduce this?\n. Yeah I kind of run into the same problems here. For example, I wanted to\nexamine the divide by zero problem reported (which in the html looks\nmore like a bug in scan-build itself) but when I'm selecting only\n\"alpha.core.TestAfterDivZero\" the problem disappears. We have to be very\ncareful with some of this stuff.\nOn 20.11.2016 18:22, neheb wrote:\n\ncan-build -enable-checker alpha.core.BoolAssignment -enable-checker\nalpha.core.CallAndMessageUnInitRefArg -enable-checker\nalpha.core.CastSize -enable-checker alpha.core.CastToStruct\n-enable-checker alpha.core.DynamicTypeChecker -enable-checker\nalpha.core.FixedAddr -enable-checker alpha.core.IdenticalExpr\n-enable-checker alpha.core.PointerArithm -enable-checker\nalpha.core.SizeofPtr -enable-checker alpha.core.TestAfterDivZero\n-enable-checker alpha.core.TestAfterDivZero -enable-checker\nalpha.deadcode.UnreachableCode -enable-checker\nalpha.security.ArrayBound -enable-checker alpha.security.ArrayBoundV2\n-enable-checker alpha.security.MallocOverflow -enable-checker\nalpha.security.ReturnPtrRange -enable-checker\nalpha.security.taint.TaintPropagation -enable-checker\nalpha.unix.cstring.BufferOverlap -enable-checker\nalpha.unix.cstring.NotNullTerminated -enable-checker\nalpha.unix.cstring.OutOfBounds -enable-checker alpha.unix.Stream\n-enable-checker alpha.unix.SimpleStream make\n. I've reduced what scan-build calls \"bugs\" to a short number. The remaining ones are files handles that need to stay open during the session, so this is not an error.\n\nPlease close the issue if that's fine for you.\nThanks for the input anyway, this is good stuff.\n. Yeah, I also think we can't do anything about the strtok_r() problem. \nI've merged the 3 changes on strncmp() from your PR. Be careful of this trap, it's actually not a bug. This is some weird AMD OpenCL runtime error, they actually want the size of the pointer address. Let's continue on https://github.com/hashcat/hashcat/issues/603\n. Checking, but did you notice 01411d?d?d?d?d?d is an invalid mask?\nOn 20.11.2016 13:56, diegodieguex wrote:\n\nhashcat (v3.10-776-g3b32ad0) starting...\nhashcat -a 3 -m 2500 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Cracked\n(WPA/WPA2 key: 01411862585)\nDevice ID # 2\nType : GPU\nVendor ID : 2147483648\nVendor : AMD\nName : AMD Radeon R9 M395 Compute Engine\nVersion : OpenCL 1.2\nProcessor(s) : 28\nClock : 834\nMemory : 512/2048 MB allocatable\nOpenCL Version : OpenCL C 1.2\nDriver Version : 1.2 (Sep 25 2016 23:31:16)\nhashcat -a 3 -m 2500 --opencl-vector=2 example.hccap 014_11_?d?d?d?d?d?d\nStatus...........: Cracked\nhashcat -a 3 -m 2500 --opencl-vector=2 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=4 example.hccap 01411?d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=4 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=8 example.hccap 01411d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=8 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=16 example.hccap 01411d?d?d?d?d?d\nStatus...........: Exhausted\nhashcat -a 3 -m 2500 --opencl-vector=16 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Exhausted\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OR5nON5Rhly2Cmd-JIJyJWU5W-2aks5rAEN2gaJpZM4K3h8_.\n. I've pushed some fix, can you please retry?\n\nOn 20.11.2016 14:24, diegodieguex wrote:\n\nno, sorry maybe It's a typing error. The truth is that the\nopencl-vector does not work\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261778203,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUps-AXVDWz9sB3gjVNOF6IqGl7Qks5rAEohgaJpZM4K3h8_.\n. OK, looks good, please close the issue if everything is fixed\n\nOn 20.11.2016 15:05, diegodieguex wrote:\n\nhashcat -a3 -m2500 -b\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 111.6\nkH/s (75.64ms)\nhashcat -a 3 -m 2500 --opencl-vector=2 -b\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 111.0\nkH/s (91.26ms)\nhashcat -a 3 -m 2500 --opencl-vector=4 -b\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 55900\nH/s (61.75ms)\nhashcat -a 3 -m 2500 --opencl-vector=8 -b\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 55610\nH/s (72.89ms)\nhashcat -a 3 -m 2500 --opencl-vector=16 -b\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 27886\nH/s (54.39ms)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261780251,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oet0Kx3V2fsCvBiwoFo6sVCquF7qks5rAFOVgaJpZM4K3h8_.\n. The goal was to fix the bug, which was that the password was not found.\nNow that bug is fixed, so we should close the issue.\n\nThe fact that the performance decreases when increasing the vector width\nis something else and is caused by the fact that the more wider the\nvector is, the more local variables (registers) are required to hold\nthem. Unless your hardware is designed to run best on a specific vector\nwidth, this always results in a performance loss.\nOn 20.11.2016 18:22, diegodieguex wrote:\n\nusing opencl-vector has decrease the performance. no looks good for me\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261791519,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OaFuhrEalUDjyrStXN9Bi19OvwO-ks5rAIHlgaJpZM4K3h8_.\n. It depends on GPU. Some GPU needs higher vector width to run at higher\nspeed, other's do not. Modern GPU do not need it and should stick to 1.\n\nOn 20.11.2016 18:45, diegodieguex wrote:\n\nok thanks\nhashcat -a 3 -m 2500 --opencl-vector=4 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Cracked\nSpeed.Dev.#2 https://github.com/hashcat/hashcat/pull/2.....: 72466\nH/s (11.81ms)\nslow... what is the improvement of opencl-vector?\nAt this point, I think than is better not use it\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261792928,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83ORMlBAJ1UiI24NTto9DACh-zMIsoks5rAIdIgaJpZM4K3h8_.\n. Yes, it's pretty good for a mobile GPU.\n\nOn 20.11.2016 18:49, diegodieguex wrote:\n\nAMD Radeon R9 M395 Compute Engine\nMemory : 512/2048 MB allocatable\nhashcat -a3 -m2500 -b\nSpeed.Dev.# 2.....: 111.6 kH/s (75.64ms)\ndo you think than is a good speed? or what should I do?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261793152,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OXBUgGiuX--qeT3Tf4fC1y_ZjN3qks5rAIg0gaJpZM4K3h8_.\n. If you want higher speed, you need better GPU. Not certain if you can\nsimply put in a different GPU into a Mac, maybe need to switch to PC.\n\nAnyway, bug is fixed, please close the issue.\nOn 20.11.2016 18:51, diegodieguex wrote:\n\nbut I have an iMac (Retina 5K, 27-inch, Late 2015)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/605#issuecomment-261793252,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83ObWZVggQ9XAOl3Bq6JkIPiIMMo5-ks5rAIiwgaJpZM4K3h8_.\n. Are you sure you're using the latest version from GitHub?\n\nThe mode 99999 works fine for me.\nPlease paste full commandline, version number, etc. whatever I need to\nreproduce locally\nOn 20.11.2016 23:10, recon-ng wrote:\n\nnvoke hashcat64.exe with \"-m 99999\" flag I get the following error: ERROR:\n. Binaries are here: https://hashcat.net/beta/\n\nOn 21.11.2016 22:25, recon-ng wrote:\n\nI was using the pre-compiled version 3.10 available through the\nhashcat website (binaries). I suppose the issue will go away once I\npull the latest and build from source. I'll let you know how that goes\nwhen I succeed.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/606#issuecomment-262071945,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OWAD_zJqt9chq6lIjixw1nqV2T27ks5rAgxXgaJpZM4K3rIZ.\n. There's no way to do a more fine grained control due to fast hashes\ncompatibility. What I'm trying to say is that we can not \"reject\" a\ncandidate in-kernel, therefore no such mechanism will work.\n\nOTOH, masks of length 13 are kind of bad, too (except if parts of them\nare static). You should try to optimize your attack.\nAlso note that you can use any markov generator of your choice, just\npipe it into hashcat. For slow hashes that should be fine, for fast\nhashes maybe add some rules.\nPlease close the issue.\nOn 20.11.2016 23:17, recon-ng wrote:\n\nThere currently seems to be no way to exert fine control over the\nnumber of candidates markov attacks test. At long mask lengths (13+) a\nchange of 1 in the value of -t results in many-fold differences in the\nnumber of candidates generated.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/607, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OcUS97CokKMmLAhhT4BTE81cU1xmks5rAMb_gaJpZM4K3rQV.\n. Please post ./hashcat -I output and clinfo output\n\nOn 21.11.2016 20:08, ZerBea wrote:\n\nAfter update from hashcat (v3.10-756-g1c82cc9) to hashcat\n(v3.10-800-g7ca6a45)\nhashcat crashes with this error:\nX Error of failed request: BadValue (integer parameter out of range\nfor operation)\nMajor opcode of failed request: 156 (NV-CONTROL)\nMinor opcode of failed request: 3 ()\nValue in failed request: 0x17\nSerial number of failed request: 15\nCurrent serial number in output stream: 16\nuname -r : 4.8.8-2-ARCH\nnvidia driver: 375.20-1\nBest regards\nZerBea\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/608, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUh-bGg4rn9k-jtijyt3hmYiRtUEks5rAew1gaJpZM4K4k6A.\n. I did some changes to xnvctrl handling with a recent version, however I've tested it on my local X11 installation. I'm using 375.20 as well, it's the latest stable version. \n\nThe nvmlDeviceSetPowerManagementLimit requires root permission, but it doesn't hurt if you don't use it. It's mostly important for modern high end GPU to disable over-aggressive powersave features.\nThe XNVCTRLQueryTargetAttribute() however is kind of suspicious. Do you run hashcat via ssh? Did you add the required access control to X11 so that an external program can query X11?. I've pushed some change. Since I can not reproduce your error (and I tried really hard) it's almost impossible to fix it. Please check if the error still occurs and, more important, if the program crashed. IF it crashes, how does it crash? Can you send me a corefile?. Can you please post xorg.conf\nOn 22.11.2016 17:03, ZerBea wrote:\n\nNo more crash, but\nhashcat (v3.10-801-gfe3398f) starting...\nXNVCTRLQueryTargetAttribute(NV_CTRL_GPU_COOLER_MANUAL_CONTROL) failed\nX Error of failed request: BadValue (integer parameter out of range\nfor operation)\nMajor opcode of failed request: 156 (NV-CONTROL)\nMinor opcode of failed request: 3 ()\nValue in failed request: 0x17\nSerial number of failed request: 15\nCurrent serial number in output stream: 16\nHashcat returncode: 1\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/608#issuecomment-262282235,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OXS8Glt4rtF30mNAW38YCDeIaJW_ks5rAxJrgaJpZM4K4k6A.\n. I see the problem, I'll write a patch\n\nOn 22.11.2016 17:44, ZerBea wrote:\n\narch is using xorg.conf.d:\n20-nvidia.conf :\nSection \"Device\"\nIdentifier \"Device0\"\nDriver \"nvidia\"\nVendorName \"NVIDIA Corporation\"\nOption \"NoLogo\" \"1\"\nOption \"Interactive\" \"False\"\nEndSection\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/608#issuecomment-262294442,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVCNbzyiz8jWb4DFm7HZklnCgKGQks5rAxv8gaJpZM4K4k6A.\n. OK, try again\n\nOn 22.11.2016 17:44, ZerBea wrote:\n\narch is using xorg.conf.d:\n20-nvidia.conf :\nSection \"Device\"\nIdentifier \"Device0\"\nDriver \"nvidia\"\nVendorName \"NVIDIA Corporation\"\nOption \"NoLogo\" \"1\"\nOption \"Interactive\" \"False\"\nEndSection\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/608#issuecomment-262294442,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVCNbzyiz8jWb4DFm7HZklnCgKGQks5rAxv8gaJpZM4K4k6A.\n. Thanks!. Hey and thanks for your report!\n\nI was really wondering about, because TrueCrypt is such an important algorithm. Anyway I tried to reproduce, but I can not. I'm using kind of the same system for tests:\nhashcat (v3.10-800-g7ca6a45)\nUbuntu 16.04 Server\n*Kernel 4.4\nI've run the tc.test.sh and it cracked all 30/30 files, here's the log:\ntrue_test/hashcat_ripemd160_aes.tc:hashcat\ntrue_test/hashcat_ripemd160_serpent.tc:hashcat\ntrue_test/hashcat_ripemd160_twofish.tc:hashcat\ntrue_test/hashcat_ripemd160_aes-twofish.tc:hashcat\ntrue_test/hashcat_ripemd160_aes-twofish-serpent.tc:hashcat\ntrue_test/hashcat_ripemd160_serpent-aes.tc:hashcat\ntrue_test/hashcat_ripemd160_serpent-twofish-aes.tc:hashcat\ntrue_test/hashcat_ripemd160_twofish-serpent.tc:hashcat\ntrue_test/hashcat_sha512_aes.tc:hashcat\ntrue_test/hashcat_sha512_serpent.tc:hashcat\ntrue_test/hashcat_sha512_twofish.tc:hashcat\ntrue_test/hashcat_sha512_aes-twofish.tc:hashcat\ntrue_test/hashcat_sha512_aes-twofish-serpent.tc:hashcat\ntrue_test/hashcat_sha512_serpent-aes.tc:hashcat\ntrue_test/hashcat_sha512_serpent-twofish-aes.tc:hashcat\ntrue_test/hashcat_sha512_twofish-serpent.tc:hashcat\ntrue_test/hashcat_whirlpool_aes.tc:hashcat\ntrue_test/hashcat_whirlpool_serpent.tc:hashcat\ntrue_test/hashcat_whirlpool_twofish.tc:hashcat\ntrue_test/hashcat_whirlpool_aes-twofish.tc:hashcat\ntrue_test/hashcat_whirlpool_aes-twofish-serpent.tc:hashcat\ntrue_test/hashcat_whirlpool_serpent-aes.tc:hashcat\ntrue_test/hashcat_whirlpool_serpent-twofish-aes.tc:hashcat\ntrue_test/hashcat_whirlpool_twofish-serpent.tc:hashcat\ntrue_test/hashcat_ripemd160_aes_boot.tc:hashcat\ntrue_test/hashcat_ripemd160_serpent_boot.tc:hashcat\ntrue_test/hashcat_ripemd160_twofish_boot.tc:hashcat\ntrue_test/hashcat_ripemd160_aes-twofish_boot.tc:hashcat\ntrue_test/hashcat_ripemd160_aes-twofish-serpent_boot.tc:hashcat\ntrue_test/hashcat_ripemd160_serpent-aes_boot.tc:hashcat\nI've noticed it's only 30 executes in the shellscript, not 34!\nI've successfully tested all of the following hardware/driver combinations with your script:\n\nGPU NVIDIA 750Ti + Driver 375.20\nGPU NVIDIA 1080FE * 3 + Driver 375.20\nCPU AMD fx6100 + AMDGPU-Pro 16.40\nCPU AMD fx8120 + pocl 0.14-pre, LLVM 3.8.0\nGPU AMD 290x + AMDGPU-Pro 16.40\nGPU AMD rx480 + AMDGPU-Pro 16.40\nCPU Intel 4770k + Intel OpenCL runtime 1.2 (Build 25)\n\nI've even run it on Win7 with a Msys2 environment:\n\nGPU NVIDIA 980 + Driver 375.95\nCPU Intel 6700 + Intel OpenCL runtime 6.4.0.25\n\nSo the question remains why isn't it working for you. Usually that's because of an broken OpenCL runtime / installation. Please add it to this issue, post the output of \"./hashcat -I\" and if possible also the output of \"clinfo\". Ideally do a fresh clone of hashcat and do not forget to run \"make clean\" before compiling because of the changed variables in global memory.\n. OK, good to know, thanks!\nPlease close the issue\nOn 22.11.2016 15:01, Zer0Tolerance wrote:\n\nHi\nIt was 3am so that's my excuse for the miscount :-)\nI've done what you suggested and scrubbed the hashcat dir and made a\nfresh build and yeah it has solved my issue, HC can now crack all 30.\nI should have done that before made a report! oh well.\nI haven't been messing around with anything within the hashcat dir so\ngoodness knows what happen.\nThanks for your time thought Atom.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/610#issuecomment-262247722,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Ofo71Mdk0OL7ecngKRwgAXaj9XBrks5rAvXEgaJpZM4K49ry.\n. I think you can simply convert this into -m 12000. Please retry with latest beta: https://hashcat.net/beta/ or compile from source using GitHub master.\n\nI've fixed something with this commit: https://github.com/hashcat/hashcat/commit/90f0aec707532ba6a9d96c54a46fa6a0f5d4d065\nPlease close the issue if fixed. Thanks for reporting!. Because with 7-Zip there's a chance hashcat emits a false positive. Therefore we must let hashcat continue to crack more passwords so you can try all the possible outputs.. Added with https://github.com/hashcat/hashcat/pull/1710. Yes, mode 3300 was not transported to hashcat v2.xx. No one yet noticed, you're the first. Use hashcat-legacy please or open a new issue requesting the addition.. Thanks!. Maybe rejects?\nOn 26.11.2016 15:56, ZerBea wrote:\n\nAfter update from hashcat (v3.10-809-g7fe575e) to hashcat\n(v3.10-820-g899413f)\nthe status display is very confusing\nhashcat (v3.10-820-g899413f) starting ...\nHash.Target......: test.hccap\nTime.Started.....: Sat Nov 26 15:44:08 2016 (1 sec)\nTime.Estimated...: Sat Nov 26 18:10:54 2016 (2 hours, 26 mins)\n...\nHash.Target......: test.hccap\nTime.Started.....: Sat Nov 26 15:44:08 2016 (9 secs)\nTime.Estimated...: Sat Nov 26 22:19:22 2016 (6 hours, 35 mins)\n...\nHash.Target......: test.hccap\nTime.Started.....: Sat Nov 26 15:44:08 2016 (31 secs)\nTime.Estimated...: Sat Nov 26 18:12:07 2016 (2 hours, 27 mins)\n...\nHash.Target......: test.hccap\nTime.Started.....: Sat Nov 26 15:44:08 2016 (1 min, 0 secs)\nTime.Estimated...: Sat Nov 26 15:45:08 2016 (0 secs)\nInput.Base.......: File (/tmp/tstsrt.tmp)\n...\nStarted: Sat Nov 26 15:44:08 2016\nStopped: Sat Nov 26 15:45:08 2016\nBest regards\nZerBea\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/616, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OcRI_KOetvtoXL3a1FvAXIHoPT7_ks5rCEiUgaJpZM4K86ZW.\n\n\n. I found some problem, please retry\nOn 26.11.2016 15:56, ZerBea wrote:\n\nhashcat (v3.10-809-g7fe575e) to hashcat (v3.10-820-g899413f)\n\n. Great! Thanks. do we need to remove the algo from \"fail algo\" list ?\nOn 26.11.2016 22:49, Gabriele Gristina wrote:\n\n$ wc -l true_test/tc_cracked.txt\n30 true_test/tc_cracked.txt\n\ud83d\udcaf\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/617#issuecomment-263087958,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OWKZLZKE6fZ15MH8rqdmU5p71i-lks5rCKlXgaJpZM4K8_4J.\n\n\n. Using this PR, it produces warnings on both linux and windows:\nsrc/opencl.c:4156:75: warning: format \u2018%lld\u2019 expects argument of type \u2018long long int\u2019, but argument 5 has type \u2018__off_t {aka long int}\u2019 [-Wformat=]\nI think, for the PRIu64, the correct format specifier would be to use %zu not %ld, since we use -std=c99 and size_t and not ssize_t. For the off_t, using lld is a problem on windows 32 bit machines, We should use %zd here.\nBut in both cases, mingw (i think windows in general because it uses printf() from msvcrt), doesn't like z* types.\nSo the only way out is to cast the variable to something. I've done that with commit: https://github.com/hashcat/hashcat/commit/e77c029dadd82d6f572ab2d94a1d8de1f182eed7\nThis seems to work pretty good on Linux and Windows. In theory, it should work on OSX as well. If not please open an issue for it.. I've tried exactly that, but didn't work. Warning still appears\nOn 27.11.2016 18:51, neheb wrote:\n\nIs there an issue with using MinGW's ANSI stdio feature? It removes\nthe PRI formats but adds \u2105z\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/618#issuecomment-263136134,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OW7LUKZcR96Qm4yZYvDK96ZcJ_GUks5rCcMGgaJpZM4K9Df_.\n\n\n. This PR is invalid, because this: \n\nif (CL_rc == -1 && build_log_size > 1)\n\nSome OpenCL runtime, when they have error, do not set CL_rc to -1, they only have build_log_size > 1\n. I can't reproduce locally. On my Ubuntu:\nmake win32 uses /usr/i686-w64-mingw32/lib/CRT_glob.o\nmake win64 uses /usr/x86_64-w64-mingw32/lib/CRT_glob.o\nWhich Host OS are you using?. I'm still not sure I've understand your issue correctly, but I did some change to the Makefile code with this commit: https://github.com/hashcat/hashcat/commit/cd3fae958dbf28b79ce190f5759c8e5ce3e46006\nPlease check if this works for you.. In theory not, because you need that 32-bit include directory to build a\n32 bit windows cross compiled .exe. So it's not an issue, it's correct\nto report an error.\nOn 28.11.2016 17:26, neheb wrote:\n\nSo the issue is that the find command fails to find the 32-bit include\ndirectory and thus disables the glob object. Probably just an issue\nwhere the Makefile can't handle the error\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263318009,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Od1mXKDumOkNF28g3NAluTqT0Jlwks5rCwDLgaJpZM4K9Tc4.\n\n\n. Also with the latest commit I've pushed?\nOn 28.11.2016 20:09, neheb wrote:\n\nRight. But the error shows on \"make win64\".\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263363794,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVO4XMyNHsxFv6vr2iCiTKF-RsbMks5rCyb4gaJpZM4K9Tc4.\n\n\n. Yes, I agree. It should not print that error when the users explicitly\nrequests for \"win64\". We need to fix that.\nBut if the users uses \"win32\" or \"binaries\" it should be shown.\nHowever my other commit should not break cygwin building. That would be\na much greater problem. I've tested it on Msys2 and it works fine. Can\nyou show how it breaks Cygwin?\nOn 28.11.2016 22:57, neheb wrote:\n\nThe \"fix\" does nothing but break cygwin building when it works just\nfine. Here's the beginning from my Fedora install.\nhttps://gist.github.com/neheb/11a5d8afd1ed7fd04892b0e306f73451\nstrictly speaking installing mingw32 fixes the issue but it should not\nfail like this.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263407468,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OTGN_Jh77u6AV7sstHFjqhduP_Ldks5rC05OgaJpZM4K9Tc4.\n\n\n. This commit should fix the problem showing 32 bit folder when trying to compile 64 bit windows: https://github.com/hashcat/hashcat/commit/72d0b272c27c7cb25f4fb0610ea678972ab11c76 Please test. Because it's no cross compiling anymore. You just need to run \"make\" on\nMsys2 to compile a native hashcat.exe and it should work the same way on\ncygwin.\nOn 29.11.2016 17:21, neheb wrote:\n\nThe whole point of cygwin is to easily cross compile using MinGW. It\njust errors that cross compiling is not supported. The commit should\nbe reverted.\nAs for the latest one, I will test when I get home.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263618168,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVsfnxCnXo2GGge9zxDHlaHhhuY6ks5rDFD2gaJpZM4K9Tc4.\n\n\n. I don't know either. Let's hope 32 bit OS will die soon :). Kind of looks like the NV gpu isn't the problem here but the Intel ones. Can you please post the full output of clinfo and hashcat -I . Hm, I can't say for sure but my gutfeeling tells me that this error is caused by some OpenCL installation error, not by hashcat. What's really strange here is that the same OpenCL runtime is called twice (Platform 1 and 3), as you can see on the clinfo output. I'd suggest to uninstall all OpenCL drivers from Intel and to uninstall the NVidia driver, too. \nIdeally, follow these steps: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do especially the part with driver fusion and the manual delete of opencl.dll is important. In case you had AMD drivers installed before, also remove them using driver fusion.\nAfter that, install nvidia drivers (but not the cuda sdk) and then intel opencl runtime (also, not the sdk).\n. @cclements Any update?. Is fixed, new betas up. Thanks for report!. Great going forward fix. Thanks!\nBut tell me more about cygOpenCL-1.dll\n\n\nWhy was it needed?\n\n\nIs OpenCL v1.2 compatible?\n\n\nWhich OpenCL runtimes did you test it with?\n\n\nOn 29.11.2016 23:23, neheb wrote:\n\nset_cpu_affinity was if'd out since cygwin has no cpu_set_t or\npthreads_setaffinity_np support.\nStill doesn't quite work(OpenCL kernels don't even run) but at least\nit gets to that point.\n\n    You can view, comment on, or merge this pull request online at:\n\nhttps://github.com/hashcat/hashcat/pull/891\n    Commit Summary\n\n\n\nFix compilation for native Cygwin\nFile Changes\n\n\n\nM include/affinity.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-0 (2)\n\nM include/common.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-1 (4)\nM include/ext_ADL.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-2 (2)\nM include/ext_OpenCL.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-3 (4)\nM include/ext_nvapi.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-4 (2)\nM include/ext_nvml.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-5 (2)\nM include/ext_xnvctrl.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-6 (2)\nM include/sort_r.h\n    https://github.com/hashcat/hashcat/pull/891/files#diff-7 (2)\nM src/affinity.c\n    https://github.com/hashcat/hashcat/pull/891/files#diff-8 (6)\nM src/dictstat.c\n    https://github.com/hashcat/hashcat/pull/891/files#diff-9 (2)\nM src/folder.c\n    https://github.com/hashcat/hashcat/pull/891/files#diff-10 (4)\nM src/opencl.c\n    https://github.com/hashcat/hashcat/pull/891/files#diff-11 (2)\n\nM src/terminal.c\n    https://github.com/hashcat/hashcat/pull/891/files#diff-12 (2)\nPatch Links:\n\n\n\nhttps://github.com/hashcat/hashcat/pull/891.patch\n\nhttps://github.com/hashcat/hashcat/pull/891.diff\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/891, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OeWVFfPF2MGkRr7uktqFV3d2q1SDks5rDKXegaJpZM4K_j9S.\n\n\n. Good fixes, thanks!. This is some effect that is related to the potfile file locking. You can see this through a strace:\nfcntl(3, F_SETLKW, {l_type=F_WRLCK, l_whence=SEEK_SET, l_start=0, l_len=0}\n^ blocking there\n@magnumripper Do you really think we need the potfile locking? Hashcat could handle this use case out of the box if the locking is not active\n. Many thanks! There's other files that do locking, too. For example\n\ndebugfile: filename must be given be the user, but would lock in case same file used: not sure if we need a fix at all in such a case, but I don't think so..\ndictstat: only uses locking for writing and instantly closes afterwards: no fix required\nhashfile: like dictstat, also requires --remove\nlogfile: like fixed loopback\nkernelfiles (cache): like dictstat\noutfile: like debugfile\nstdout: like debugfile\n\nIn general, should be fine as-is. OK, so the sysctl () call in FreeBSD returns the real path, not a link, right?. Nice, didn't know that. About the printf() leftover, I think there's no messages that are neither warnings nor errors that use strerror(). So it should be ok. Thanks!. Thanks for report and the analysis. You're absolutely right about how this works. However not a bug, it's a controlled compromise.\nThe reason for all this goes back to the problem that the format \"hash:password\" is a broken format itself, unless CSV would be handled correctly. But that's not the case. Even if hashcat could handle CSV correctly, other tools usually fail, and especially hashdumps you can find in the wild do. That's why I've never thought about adding true CSV parsing in here.\nFrom a technical view, a program can not decide if it parses the string \"hash:salt:pass:word\" which part of it is the hash, the salt and the password. There's two ways to interpret it:\n\n\"hash\" is the hash, \"salt\" is the salt, \"pass:word\" is the password\n\"hash\" is the hash, \"salt:pass\" is the salt, \"word\" is the password\n\nSo the question is, how should we process is. This becomes very complicated and there's event different approaches. In hashcat we decided to use a strategy that if we split the string, but from the right to the left and not from the left to the right, we iterate through all possible variants and accept the first that makes it through the hash parsing check. To not run through this for an unlimited time, we set a maximum number of so called \"MAX_CUT_TRIES\". You can find that in include/common.h and it's currently set to 4, which matches your report.\nWe could increase that value now to something higher, but to which? If we set it to 8, the same problem will occur again if a user runs into the same problem you have but with 8 colons. A much better solutions would be to make the parser more like a real CSV parser that understands escaping. But if we do that, the potfile will become incompatible with out tools like JtR or others.\nSo we end up in a situation where we can only try to find a compromise and that's what we did.\n. @magnumripper What do you think, should we add better RFC conform parsing of CSV to hashcat and JtR?. That seems to be an elegant solution to this problem, I think I'll add that.. With commit https://github.com/hashcat/hashcat/commit/1342cf2ce34eb7337605fa66cd81035e27b3fa1f we changed the logic to use $HEX[...]  in case the separator character is used in the password. This will solve the problem shown in the initial post but requires the potfile to be build up from scratch.. The problem here is that there's no unique id that we can use to match an OpenCL device with an ADL/NVML/NVAPI/SYSFS/XNVCTRL device, so we have to use some fuzzy logic which is likely to fail on complex setups with many different devices.\nTo understand at which point the matching fails I need to know more details about your system. Let's start with something simple. Please post a full output of both: \"hashcat -I\" and, more important,  \"clinfo\".  Also I don't know on which system this is, but the Drivers temperature threshold usually is a unique NVML feature, so I'd guess this is on a windows system.. I've pushed some change with https://github.com/hashcat/hashcat/commit/2c82e53d3852b15a99f14012d2af2893242f70b7 which uses pci ids to match NVML with OpenCL devices. The problem with your setup seems to be the mix of ADL and NVML, but using this patch it should be clever enough to handle it. There's also a new beta binary on here: https://hashcat.net/beta/\nPlease try if your issue is fixed and close the issue. Any updates here?. @ZerBea Can you confirm both issues fixed?\n@matrix Thanks for patch. Just a suggestion, why don't you just pair the Iris and Iris Pro into a group so that the tuning will work on both the same way? hashcat.hctune supports that.. OK, thanks for reporting. Can you please post a full output of \"clinfo\" tool. Also please post output of \"hashcat -I\" on hashcat v3.20. Thanks!. Looks like this is some AMD-and-only-on-Windows issue. Need to build such a system locally to reproduce. . No, give me some time so that I can build a new PC using the combination of Windows + AMD GPU otherwise I can not reproduce. Wait, is this from a notebook computer?. Since I don't have a Windows+AMD system for test I wrote some code change blindly. Can you please try this version: https://hashcat.net/beta/hashcat-3.20%2b59%2bADLTEST.7z and post what it's doing?\n. It's updated in the meanwhile, please manually pick latest version from here: https://hashcat.net/beta/. Press \"s\" and post the hwmon line please\nOn 29.12.2016 11:00, mad76e wrote:\n\nYeah.. that one works fine, however i got some error message for you\nas you see.\n123456\nhttps://cloud.githubusercontent.com/assets/24358047/21541358/ea4f0df2-cdb5-11e6-8e79-3769d672270f.png\nwell\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/904#issuecomment-269607249,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OSyrYL7Gx6453qSzj8yKKa_NezqZks5rM4SugaJpZM4LDXET.\n\n\n. Looks good, the error is because hashcat needs to find out which\noverdrive Version to use (5 or 6). Please close the issue if you think\nit's ok.\nOn 29.12.2016 11:18, mad76e wrote:\n\nOk!\n123456\nhttps://cloud.githubusercontent.com/assets/24358047/21541676/8eeddc10-cdb8-11e6-9032-4320cf3eb77d.png\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/904#issuecomment-269609385,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OZD_7cmXcoZGsuDkKTwUsu2cbM8oks5rM4kPgaJpZM4LDXET.\n\n\n. Please post full commandline used. Also post output of \"clinfo\" and \"hashcat -I\". Also try to narrow the problem to whatever it is related to the CPU or GPUs by trying different variants of -D. What about hardware monitor (Fan, Temp, etc) for the GTX1080's, is that working when you do not use the CPU?. Is this watercooled?. OK, I was just wondering about the 0% fan speed and that one:\nWatchdog: Temperature retain trigger disabled\nSo that's correct then.\nAbout that CPU error, does that occur only with WPA?. Both 2100 and 2500 are slow hashes. Maybe the runtime doesn't like long running kernels, like with OSX. Can you retry with -w 1?. I've tried to reproduce in my Intel CPU + NVIDIA GPU system but can't. It seems like you're using the correct Intel OpenCL runtime. For some reason however my clinfo shows the devices reversed, so the GPU first, then the CPU. I don't think this is the reason of the problem but indicates that there's some OpenCL installation difference between our versions. Anyway it doesn't seem to be a hashcat problem, so please let's continue to find the source of the problem on hashcat forum. The github is only for bugs and feature requests.. Did you run make clean before?. Great! Thanks!. Right, if you do > 100000 MH/s it will switch to GH/s. I find it easier to read that way. Is there a special reason to use \"MINGW32\" (32 bit only) mingw macro / was that done intentional?. I'm sorry I think this was lost during refactoring.. That's actually a problem in v3.10 which was undetected, but is now detected in v3.20. The problem is the command you're using. You need to remove the hashlist. If you used --keyspace in combination with a hashlist before, you always used it wrong.. No problem, I just don't see how we can handle both the old and the new commandline parsing configuration at once. So this will break old overlays and also many tutorials and forum help threads. I'll redirect complains to you :). I've changed my mind about this while implementing. It's really more disadvantages than advantages. Alternatively we could up a shortcut for both --increment-min and --increment-max, what you think?. --increment-range 4:8 with 'R' as shortcut? @blandyuk ?. Yes, but assigning 'R' to it would work. What I mean, if sticking to\n--increment-min and --increment-max, what would be the shortcut? It\nwouldn't be intuitive because both min and max start with 'm'.\nOn 10.12.2016 00:29, magnum wrote:\n\nSame problem. You'll need to type |--increment-r| before it gets\nunambigouous\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/915#issuecomment-266151588,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OaaLCWy59Fmp-F-tAvAvEB02Tv9kks5rGeRWgaJpZM4LHq1K.\n\n\n. I can't because I have no control over getops (the library handling the\ncommandline parameter) for such a specific case. I have to configure\neach option as it has a parameter or not, not both.\nOn 10.12.2016 16:33, blandyuk wrote:\n\nWhy can't you read the command-line parameter for -i and check if\nthere is a value present? If not, default to what hashcat does anyway\nbut, if say -i 4:8 was present, then apply the increment min/max\nvalues. I sure I could do this with my apps I have but not sure how\nhashcat is setup so it may not be possible :( if not, I'll just close\nthis issue.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/915#issuecomment-266216264,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OauOrLkvFBBDXut9QEVBrbph3FAPks5rGsYvgaJpZM4LHq1K.\n\n\n. I still prefer the way it is right now. Adding code for handling any backward compatiblity was never how hashcat worked. We can assume users follow the changes because the typical hashcat user is a more experienced user. Bundled with bash completion (which hashcat supports) it's typed really fast with --inc . I've add that with commit https://github.com/hashcat/hashcat/commit/ec5610271aae422cfe856bcf4870901baed35641\nPlease try and close the issue if that works for you.\nOutput looks like this:\n```\nroot@ht:~/hashcat# ./hashcat example0.hash -a 3 ?a?a?a?a?a?a?a?a -w 3 --progress-only --mac\nhashcat (v3.20-27-gf9ba949+) starting in progress-only mode...\n1:327680:112190.53\nStarted: Fri Dec  9 23:46:09 2016\nStopped: Fri Dec  9 23:46:12 2016\n```\nThe output is per device, ideal -l size and the time (in miliseconds). For example, if you want to calculate a runtime of ~ 10 Minutes, you'd do: \n\n(60 * 10 * 1000) / 112190.53 = 5,3480449731363244295218143634761\nRound the result down, so result = 5\n5 * 327680 = 1638400\nUse -l 1638400\n\n. Can you please to find out if this is related to the number of salts? I\nmean, try if it makes more sense if you use one salt or a non-salted\nalgorithm.\nOn 10.12.2016 11:23, Sein Coray wrote:\n\nThanks a lot for implementing.\nIt seems to work, but I'm not sure if the result makes sense in this case:\n|$ hashcat/hashcat --machine-readable --opencl-devices=3\n--hash-type=2711 hashlists/hl24 -a 0 files/wordlist.txt\n--progress-only hashcat (v3.20-29-gf424650+) starting in progress-only\nmode... 3:131072:9.86 Started: Sat Dec 10 11:10:19 2016 Stopped: Sat\nDec 10 11:10:34 2016 |\n|* Device #3: GeForce GT 650M, 256/1024 MB allocatable, 2MCU |\nI'm wondering a bit about the small time of 9.86 ms. If I use your\ncalculation there, it would give me a huge length number which is much\nbigger than the whole keyspace. The length on this task should be\nsomething around 250000 to take ~10 mins on this computer.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/916#issuecomment-266198037,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVlO9ntxbpyMce1HiKCY7AHi994-ks5rGn2PgaJpZM4LJBUN.\n\n\n. OK, new commit pushed, also new beta up. This should fix the multiple salt issue. It actually was just a multiple salt issue. With a single hash, salted or not, the number was already correct as I've expected. \nMore important, do not forget to add an amplifier (like rules) for fast hashes, otherwise you'll end up with bad numbers caused by pci-express overhead.. From what I can see from your output, the time to compute the ideal -l\nvalue is around 7 seconds. That also includes initializing OpenCL\ndevices, compiling the OpenCL kernel, creating the wordlist cache and\ndoing the autotuning. However, from what you can see in the output, the\nchunk will run 534 seconds, that's a lot more. than 7 seconds. I don't\nunderstand why you can say that this is almost the same time?!\nOne note about the startup time: It will startup faster once the OpenCL\nkernel and wordlist stat is cached. Basically each second time you call\na specific command. Anyway even 7 seconds for so much work is pretty\ngood I think.\nI fully agree that a keyspace value should be small, because it makes\nthe distribution easier. However, a keyspace progress value of 262144 is\nreally good, but that is because you didn't specify to use -w 3. If you\ndo not set -w 3, hashcat operates at -w 2 which is the default. It can\nbe even smaller if you use -w 1, but it will reduce the performance,\ntoo. That's the price of massive parallelized setups like GPU. You need\nto have enough work for them. But as I said 262144 is really good. There\nshouldn't be any problem with that value in a distributed setup.\nOn 10.12.2016 16:37, Sein Coray wrote:\n\nI tried now with the same salted hashlist again, it works as it should\nnow.\n|$ hashcat/hashcat --machine-readable --opencl-devices=3\n--hash-type=2711 hashlists/hl24 -a 0 files/wordlist.txt\n--progress-only hashcat (v3.20-30-g367024d+) starting in progress-only\nmode... 3:262144:534965.57 Started: Sat Dec 10 16:23:32 2016 Stopped:\nSat Dec 10 16:32:45 2016 |\nAs you see the benchmarking took quite some time, nearly as much as a\nchunk normally would be approximately. Is there a way that the number\nof keyspace progresses (like 262144 here) could be smaller?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/916#issuecomment-266216515,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUYqPN74rKgpkjQBEPzC1lUdRvXnks5rGsdCgaJpZM4LJBUN.\n\n\n. Nice, the first PR which adds a rule. The question is just why we would need such a rule. I know there's hash-modes that need zero byte padding, but in this case it's better to have a dedicated hash-mode added. Can you please explain what's the reason you put this into a rule?. I'd prefer to not have any collisions between hashcat and JtR rule\ncommands. Can you make a suggestion for an alternative name that is not\nin use by JtR currently?\nOn 17.12.2016 23:10, magnum wrote:\n\nJtR has 'P' for english grammar (eg. crack -> cracked). We've been\ntalking about trying to unify rules commands but in this case it's\nprobably not a problem since HC will likely never get the JtR version\nof 'P' anyway and on the other hand, JtR can't currently implement\n/this/ version of 'P' since it can not currently handle nulls within\nplains.\nSo, in short: No problem there.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/918#issuecomment-267790388,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdtIwrvuEl3h9mEm66-KkArLzJ1Dks5rJF3jgaJpZM4LOCLY.\n\n\n. I'm really happy to see a new rule function added via PR, but in this case I think the correct way to implement this logic into the hash mode kernel. Otherwise you can't do mask attacks and combinator attacks against such a hash mode because rules are not supported in those. If you need help in how to add a new hash-mode, contact me on IRC.. Very nice, didn't expect that :)\n2 things needs fixes:\n\nPlease add mode for test.pl and test.sh (and test them)\nI see you move SHA256 -> SHA2, which is ok, but you should also move SHA384 and SHA512 then, because they are SHA2 as well. Perfect!. hashcat v3.10 is outdated, please update to v3.20 and reopen if the issue still exists. Nice find, thanks for reporting. Should be fixed.. But that doesn't really solve the problem. The same problem will occur\nagain if the character selected for separator will be part of the debug\nline.\n\nWe've recently solved a similar problem for the output file by switching\nto $HEX[...] encoding if the separator character is part of the data.\nFor example, if the password is \"lala:\" (without quotes) then the output\nwith the latest hashcat version is:\n```\n757f75dc2ce17be3bb9ccc1f3f565b51:$HEX[6c616c613a]\n```\nand not\n```\n757f75dc2ce17be3bb9ccc1f3f565b51:lala:\n```\nThe same systematic could be done for debug mode line.\nOn 19.12.2016 03:37, recon-ng wrote:\n\nIf I have strings with \":\" in them, parsing debug files is hard since\nthe rule can't be easily distinguished from the source and result\nstrings (especially if the rule itself operates on the \":\" character.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/923, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OQftiVwpLPSDPrcYcQdmmc_gmqhRks5rJe3jgaJpZM4LQUm8.\n\n\n. I've pushed a patch for this with commit https://github.com/hashcat/hashcat/commit/fa5b5d298d89cf825ee7169f86e4de089418c5a0\nCan you please test if it's working for you and close the issue?\nI've also upload a new pre-compiled beta version to https://hashcat.net/beta/\n. Any update?. This feature went into hashcat v3.30, therefore closing the issue. If it's not working, please open up a new one.. Nice! Thanks. I'm getting tons of those now:\nwarning: ignoring return value of \u2018asprintf\u2019, declared with attribute warn_unused_result [-Wunused-result]. No, Ubuntu 16.04\nOn 22.12.2016 02:37, neheb wrote:\n\nIs this on OS X?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/925#issuecomment-268695701,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83ORj_PYhkzm2zyryEmAqtCWDIrTGrks5rKdRKgaJpZM4LRWWB.\n\n\n. Added a wrapping function: https://github.com/hashcat/hashcat/commit/6ece83760d3501ee34a8ee2076751edb8945dd81. For 2) it already does that. I've just pushed commit https://github.com/hashcat/hashcat/commit/72af615e8b9be2039341867fbe0f8775f8edee65\nIt's a better solution for the duplicate essid detection and should make use of it to increase performance. There's also a new binary beta on https://hashcat.net/beta/\nPlease try it out. Note if you compile from source to do a make clean. Please retry with -d 1 added\nOn 22.12.2016 14:40, Chris Clements wrote:\n\nI encounter a crash when trying to run the latest rev:\n|hashcat64.exe -b hashcat (v3.20-45-g72af615e+) starting in benchmark\nmode... OpenCL Platform #1: NVIDIA Corporation\n====================================== * Device #1: TITAN X (Pascal),\n2047/12288 MB allocatable, 28MCU OpenCL Platform #2: Intel(R)\nCorporation ======================================== * Device #2:\nIntel(R) HD Graphics 530, 2047/13041 MB allocatable, 24MCU * Device\n3: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped Hashtype: MD4\nclFinish(): CL_INVALID_COMMAND_QUEUE |\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/927, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Of8LkzCSMxlhqkz2GO2Un_7Kjricks5rKn3AgaJpZM4LT_Ts.\n\n\n. Does the same error occur when using 3.20 Release Version?\nAm 22.12.2016 5:02 nachm. schrieb \"Chris Clements\" <notifications@github.com\n\n:\nSame crash with -d 1 and with -d 2\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/927#issuecomment-268830367,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OS3TD7hlo-LKy0zYFbQaPZ5f3RU4ks5rKp8RgaJpZM4LT_Ts\n.\n. I've pushed a couple of changes. Please try again with latest version, do not forget to make clean if you build from source. No, mode 6400 is something else. He's looking for something like 1711, but for SHA256. \n\nBasically this requires only to write the parser, the kernel is already there. If anyone want to write it, see 1711 as an example.. It was never included in hashcat, it was only in hashcat-legacy.\nAm 27.12.2016 21:28 schrieb \"ZilentJack\" notifications@github.com:\n\nI just double tried to check on latest version (3.20) and it doesn't seem\nlike Hash-Mode 7000 is included anymore, not sure why?\n-m 7000 should be \"Fortigate (FortiOS)\" (https://hashcat.net/wiki/\ndoku.php?id=example_hashes), but I'm getting \"Unknown hash-type '7000'\nselected\".\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/930#issuecomment-269378430,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUdnMGERU1WehIKxg8bcwpoYTSrCks5rMXTngaJpZM4LVqai\n.\n. Excellent report, many thanks! Before I'm going to investigate, did you\nrun those on the latest github version? There was some patch I did a\nwhile ago:\nhttps://github.com/hashcat/hashcat/commit/72599fd10956179ee36df25d63fda27422cbe112\nit's possible that this was the bug and that it's already fixed. Please\ntry that first and report back. There's also a precompiled beta version\nif you do not want to build from sources: https://hashcat.net/beta/\n\nOn 28.12.2016 19:29, llamasoft wrote:\n\nWhen using a mask file as an input source, after a small mask (one\nwith a small keyspace) is encountered, future masks run considerably\nslower.\nI've put together a demo script and captured logs to help illustrate\nthe issue:\nhttps://gist.github.com/llamasoft/31fe66c07726c617eedbdab11d48f36a\nThe script does the following:\n\nGenerate 10k dummy hashes\nAs a single mask input, try |?d?d?d?d?d?d| (length 6)\n    Result: 530 MH/s (log\n    https://gist.github.com/llamasoft/31fe66c07726c617eedbdab11d48f36a#file-mask_6d-log)\nAs a single mask input, try |?d?d?d?d| (length 4)\n    Result: 5 MH/s (log\n    https://gist.github.com/llamasoft/31fe66c07726c617eedbdab11d48f36a#file-mask_4d-log),\n    pretty bad but understandable due to very small keyspace\nAs a single mask input, try |?d?d?d?d?d?d?d| (length 7)\n    Result: 525 MH/s (log\n    https://gist.github.com/llamasoft/31fe66c07726c617eedbdab11d48f36a#file-mask_7d-log),\n    pretty much the same as length 6\n\nHere's where the issue shows up:\n\nPut the three masks into a file, length 6, length 4, and length 7.\nUse the mask file as an input (log\n    https://gist.github.com/llamasoft/31fe66c07726c617eedbdab11d48f36a#file-mask_file-log)\n    Length 6 result: 550 MH/s, about the same as before\n    Length 4 result: 5 MH/s, about the same as before\n    Length 7 result: 55 MH/s, about /90% slower/ than before\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/931, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVN6Zs4O1_wbIxNcKlHDa69hVxFBks5rMqqjgaJpZM4LXGoF.\n\n\n. Thanks for your report!\nOn 28.12.2016 20:39, llamasoft wrote:\n\nLooks like that beta build fixes it! Thanks for the quick response.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/931#issuecomment-269528880,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OfYIOX4tLYV4Zvq8IJ3lWcrhYpgXks5rMrrcgaJpZM4LXGoF.\n\n\n. Should be fixed, also new beta up. Thanks again for reporting!. Thanks!. No worries, please keep opening good issues like that :). Please use Msys2 for building on windows. While you're absolutely right I prefer to let it as-is, only because it's what people (which doesn't have any experience with git) expect to see.. Ingenious! Thanks!. Thanks!. Thanks! So does that mean that the split into hashcat library and hashcat frontend works on FreeBSD?. No, I meant the yesterday change. There's two files produced by \"make\"\nnow. That is \"hashcat\" and \"libhashcat.so\".\nOn 30.12.2016 14:32, Nikolai Lifanov wrote:\n\nYes, it works. It has been working since release. I'm just trying to\nde-uglify the port.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/940#issuecomment-269771954,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OT7s5J4pjXvAIqNXPPgbaP_WbTB4ks5rNQfdgaJpZM4LYLun.\n\n\n. The first error is a bug in OpenCL headers, which is already fixed. Try: git submodule update --remote --recursive\nThe other error is not related. It simply looks like your (very old) CPU is not supported by AMDs OpenCL runtime. Reporting errors at AMD is time waste, so I'd suggest upgrade your CPU.. @usualwyy I think what @kholia wanted to say is that with JtR you can already crack this hash because it supports 64 bytes length (and more) salts.\nFor hashcat we need a special kernel to do that, therefore it's correct to open up this issue,. thanks!. Can you please post the full commandline you're using\nOn 31.12.2016 19:46, Marc Seguin wrote:\n\nHello,\nI am using the 3.20 release and tested the last beta (3.20 build 88)\nand I am cracking some hash over and over and they are written\nmultiple time to the potfile.\nHere's some of the hash :\n63ee9967dc9b571e746ecb52c9518455:.::H|CBO::.\nc3ee19ff73bcb2ebdf72188fd991aebe:.::Killthezoo::\n\nHere's a screenshot of the potfile\nscreenshot from 2016-12-31 13 45 01\nhttps://cloud.githubusercontent.com/assets/2931748/21578859/726c145a-cf5f-11e6-8807-958a7247764e.png\nRegards,\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/945, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OeuFgZsXVuQUYY51WVQq5QcUybNRks5rNqMDgaJpZM4LYmjJ.\n\n\n. Yes, that's what I think, too. But I'm unable to reproduce. For example\nthis:\n```\nroot@ht:~# echo -n .::Killthezoo:: | md5sum\n37fe8a5cff2cabefba9488e92617ddc8  -\n```\nBut in your paste, there's no such hash. I also need the hashlist and\nthe wordlist.\nIdeally reduce both lists to an absolute minimum so that you can\ntransfer it easily.\nAlso post hashcat version using hashcat -V and the output of hashcat -I.\nOn 01.01.2017 12:23, Marc Seguin wrote:\n\nHere we go :\n|./hashcat64.bin ../Hash/all.txt ../Dic/CT_Crackedv2.txt -D 1,2 -w 3\n--force -r rules/combinator.rule|\nAlso the show command doesn't show it :\n|./hashcat64.bin --show ../Hash/all.txt|\nAnd I grep the hashcat.potfile to find the result of the screenshot:\n|cat hashcat.potfile |grep \".::\"|\nIs it possible that the issue is related to the 4 colons like theissue\n889 https://github.com/hashcat/hashcat/issues/899 ?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/945#issuecomment-269899454,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Ob73Rvu7V7tPiuHL_1xIOWs0b2Q-ks5rN4y3gaJpZM4LYmjJ.\n\n\n. Hey, I still can reproduce it. See here:\n```\nroot@sf:~/hashcat# rm hashcat.potfile \nroot@sf:~/hashcat# ./hashcat hash --show\nroot@sf:~/hashcat# cat wl\n.::H|CBO::.\n.::Killthezoo::.\nmerhoussame:::::\n:d:d:d:d:d1\nroot@sf:~/hashcat# ./hashcat hash wl\nhashcat (v3.20-88-gd36cc4c) starting...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Ellesmere, 2047/4038 MB allocatable, 14MCU\nDevice #2: Hawaii, 2047/4043 MB allocatable, 14MCU\nDevice #3: AMD FX(tm)-6100 Six-Core Processor, skipped\n\nOpenCL Platform #2: The pocl project\n\nDevice #4: pthread-AMD FX(tm)-6100 Six-Core Processor, skipped\n\nHashes: 4 digests; 4 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nCache-hit dictionary stats wl: 58 bytes, 4 words, 4 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \n63ee9967dc9b571e746ecb52c9518455:$HEX[2e3a3a487c43424f3a3a2e]\nc3ee19ff73bcb2ebdf72188fd991aebe:$HEX[2e3a3a4b696c6c7468657a6f6f3a3a2e]\n30020acffe70e97f5672dbd144b74446:$HEX[6d6572686f757373616d653a3a3a3a3a]\n782d37d42ca81398be30be0540648b25:$HEX[3a643a643a643a643a6431]\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: MD5\nHash.Target......: hash\nTime.Started.....: Sun Jan  1 18:43:39 2017 (0 secs)\nTime.Estimated...: Sun Jan  1 18:43:39 2017 (0 secs)\nInput.Base.......: File (wl)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (0.03ms)\nSpeed.Dev.#2.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 4/4 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 4/4 (100.00%)\nRejected.........: 0/4 (0.00%)\nRestore.Point....: 0/4 (0.00%)\nCandidates.#1....: .::H|CBO::. -> :d:d:d:d:d1\nCandidates.#2....: [Copying]\nHWMon.Dev.#1.....: Temp: 80c Fan: 20% Core:1266Mhz Mem:1750Mhz Lanes:16\nHWMon.Dev.#2.....: Temp: 64c Fan: 26% Core:1010Mhz Mem:1250Mhz Lanes:16\nStarted: Sun Jan  1 18:43:38 2017\nStopped: Sun Jan  1 18:43:40 2017\nroot@sf:~/hashcat# ./hashcat hash --show\n63ee9967dc9b571e746ecb52c9518455:$HEX[2e3a3a487c43424f3a3a2e]\n30020acffe70e97f5672dbd144b74446:$HEX[6d6572686f757373616d653a3a3a3a3a]\n782d37d42ca81398be30be0540648b25:$HEX[3a643a643a643a643a6431]\nc3ee19ff73bcb2ebdf72188fd991aebe:$HEX[2e3a3a4b696c6c7468657a6f6f3a3a2e]\nroot@sf:~/hashcat# \n```\nMaybe remove old potfile (or raname) and then try again (with latest beta version). I don't understand. Do you mean it's not production ready?. I've just installed CYGWIN and added a few patches (for opencl.dll handling) but it works just fine. No problems with pthreads. Please verify!. Yep, I noticed the same and was wondering. Was it different before?\nOn 04.01.2017 22:06, neheb wrote:\n\nUpdate: alright this actually works great now. I ran cygwin through\nssh (ssh 127.0.0.1) and was able to use the s key to pull up the\nstatus. No winpty needed.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/946#issuecomment-270486517,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Of3yXWFkW3rHtHBnHKEa9ws838ohks5rPAnugaJpZM4LYtUk.\n\n\n. OK, closing this then. Yep, that's the wanted behavior. Using CPU can lower GPU speed. If there's no GPU detected, CPU is automatically activated.. Kind of, but you need to respect the platform hierarchy, means you have\nto able enable it with -D 1 first. After that, -d should be relevant. So\nplatform > device\nOn 01.01.2017 18:37, Wolfmandeny wrote:\n\nIs this wanted even when the user explicitly spesifies the devices to\nuse ?\nI can understand it's done when defaults are used, but don't think\nhashcat should overriding the users choices.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/947#issuecomment-269911920,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OT6eO-L8GcJgoGi50VK5iKdDXuDlks5rN-R2gaJpZM4LYvQf.\n\n\n. If you have 3 devices 1, 2 and 3 then you don't need to set them. If you\nwant all devices used all you need to do is -D 1,2\nOn 01.01.2017 19:19, Wolfmandeny wrote:\n\nI assume in that case it would have to be -D 1,2, since otherwise it\nwould be CPU only ?\nSo in this case -D 1,2 -d 1,2,3\n?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/947#issuecomment-269913480,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83ObmBKxL1u2WChhlF85U-_oeSWC6tks5rN-47gaJpZM4LYvQf.\n\n\n. I don't think so. If there's multiple levels of hierarchy there must be\nsome sort of hard logic two distinguish them otherwise it becomes\nuncontrollable. What I mean is there can not be some configuration\nparameter of hierarchy 1 that, if set, influences hierarchy 2.\nAnyway, this goes back to NVidia creating 100% CPU load. It's the root\nproblem. Otherwise there would be no need to disable CPU support at all.\nIf you want to track this, here's the forum post:\nhttps://devtalk.nvidia.com/default/topic/978985/opencl-busy-wait-still-not-fixed\nAfter that, I've also opened a bug at their bug trackers, but the bug\ntracker is not publicly available.\nAs soon this bug is resolved I will automatically re-enable CPU use.\nOn 02.01.2017 03:01, magnum wrote:\n\nFWIW I agree with OP. If user says |-d (...)| it would be logical to\nover-ride the default for |-D|.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/947#issuecomment-269929417,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdNSjClHMECQXEpMmvgvZDKZCXitks5rOFp4gaJpZM4LYvQf.\n\n\n. It's still in there. You can disable our workaround by using --nvidia-spin-damp 0 to reproduce locally. Please retry with github version (or binary version from https://hashcat.net/beta/ ) and reopen if needed.. Nice report, thanks for that. If only all reports would look like this :)\nHowever, I don't see any reason why this happens. You can try with -n1 -u1 --force. This will create terrible performance, but it's just to see if it's something related to workload.. Aha, I think the problem is the Intel GPU then. Remove -n1 -u1 --force\nand use -d 1.\nOn 03.01.2017 21:40, Enrico wrote:\n\nAhah, thank you for your fast response instead.\nBelow is the output of |hashcat64.exe -m 500 sample500.hashes\nexample.dict -n 1 -u 1 --force|.\nI pressed s a couple of times, out of curiosity.\nAt least it starts! /(But it doesn't finish?)/\nA couple of things to note:\n\n|clEnqueueReadBuffer(): CL_OUT_OF_RESOURCES| (first time I see this)\nProgress stuck at 96.6%\n\n|hashcat (v3.20) starting... nvmlDeviceGetFanSpeed(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n====================================== * Device #1: GeForce GTX 850M,\n512/2048 MB allocatable, 5MCU OpenCL Platform #2: Intel(R) Corporation\n======================================== * Device #2: Intel(R) HD\nGraphics 4600, 480/1921 MB allocatable, 20MCU * Device #3: Intel(R)\nCore(TM) i7-4710HQ CPU @ 2.50GHz, skipped Hashes: 1 digests; 1 unique\ndigests, 1 unique salts Bitmaps: 16 bits, 65536 entries, 0x0000ffff\nmask, 262144 bytes, 5/13 rotates Rules: 1 Applicable Optimizers: \nZero-Byte * Single-Hash * Single-Salt Watchdog: Temperature abort\ntrigger set to 90c Watchdog: Temperature retain trigger disabled\nCache-hit dictionary stats example.dict: 1080240 bytes, 129988 words,\n129988 keyspace Cracking performance lower than expected? Append -w 3\nto the commandline! INFO: approaching final keyspace, workload\nadjusted [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES clEnqueueReadBuffer():\nCL_OUT_OF_RESOURCES Session..........: hashcat Status...........:\nRunning Hash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS\nMD5 Hash.Target......: $1$ZdzWllz0$EbXFJKlLJ7A79po4QZETm1\nTime.Started.....: Tue Jan 03 21:31:56 2017 (10 secs)\nTime.Estimated...: Tue Jan 03 21:32:06 2017 (0 secs)\nInput.Base.......: File (example.dict) Input.Queue......: 1/1\n(100.00%) Speed.Dev.#1.....: 17315 H/s (0.01ms) Speed.Dev.#2.....: 0\nH/s (0.06ms) Speed.Dev.#.....: 17315 H/s Recovered........: 0/1\n(0.00%) Digests, 0/1 (0.00%) Salts Progress.........: 124868/129988\n(96.06%) Rejected.........: 0/124868 (0.00%) Restore.Point....:\n0/129988 (0.00%) Candidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....: -> HWMon.Dev.#1.....: Temp: 43c Util: 0% Core:\n901Mhz Mem: 900Mhz Lanes:8 Throttled HWMon.Dev.#2.....: N/A [s]tatus\n[p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES clEnqueueReadBuffer():\nCL_OUT_OF_RESOURCES Session..........: hashcat Status...........:\nRunning Hash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS\nMD5 Hash.Target......: $1$ZdzWllz0$EbXFJKlLJ7A79po4QZETm1\nTime.Started.....: Tue Jan 03 21:31:56 2017 (1 min, 11 secs)\nTime.Estimated...: Tue Jan 03 21:33:07 2017 (0 secs)\nInput.Base.......: File (example.dict) Input.Queue......: 1/1\n(100.00%) Speed.Dev.#1.....: 17315 H/s (0.01ms) Speed.Dev.#2.....: 0\nH/s (0.06ms) Speed.Dev.#.....: 17315 H/s Recovered........: 0/1\n(0.00%) Digests, 0/1 (0.00%) Salts Progress.........: 124868/129988\n(96.06%) Rejected.........: 0/124868 (0.00%) Restore.Point....:\n0/129988 (0.00%) Candidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....: -> HWMon.Dev.#1.....: Temp: 39c Util: 0% Core:\n901Mhz Mem: 900Mhz Lanes:8 Throttled HWMon.Dev.#2.....: N/A [s]tatus\n[p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES clEnqueueReadBuffer():\nCL_OUT_OF_RESOURCES Session..........: hashcat Status...........:\nRunning Hash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS\nMD5 Hash.Target......: $1$ZdzWllz0$EbXFJKlLJ7A79po4QZETm1\nTime.Started.....: Tue Jan 03 21:31:56 2017 (3 mins, 2 secs)\nTime.Estimated...: Tue Jan 03 21:34:58 2017 (0 secs)\nInput.Base.......: File (example.dict) Input.Queue......: 1/1\n(100.00%) Speed.Dev.#1.....: 17315 H/s (0.01ms) Speed.Dev.#2.....: 0\nH/s (0.06ms) Speed.Dev.#.....: 17315 H/s Recovered........: 0/1\n(0.00%) Digests, 0/1 (0.00%) Salts Progress.........: 124868/129988\n(96.06%) Rejected.........: 0/124868 (0.00%) Restore.Point....:\n0/129988 (0.00%) Candidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....: -> HWMon.Dev.#1.....: Temp: 38c Util: 0% Core:\n901Mhz Mem: 900Mhz Lanes:8 Throttled HWMon.Dev.#2.....: N/A [s]tatus\n[p]ause [r]esume [b]ypass [c]heckpoint [q]uit => ^C |\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/949#issuecomment-270218650,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OTjudamkE3kJczBrC0Ome7xGWH00ks5rOrJOgaJpZM4LZ_VG.\n\n\n. You can try latest beta, maybe it fixes the \"nvmlDeviceGetFanSpeed(): Not Supported\" error, but that's not guarenteed as not all mobile GPU do not allow fanspeed control via software. It should also remove the Throttled thing. Please do not forget to close the issue if that's fine for you.. I've added a patch to hashcat to automatically disable Intel GPU devices unless the user forces to enable it: https://github.com/hashcat/hashcat/commit/78d73e64fe969e2f3e8b9bed8fb11cd08ad9bbb5\nI've also put up a new binary beta to https://hashcat.net/beta/\nCan you please retest on your system if the device is automatically skipped and a warning message is presented to the user?. I think I could change this to return 3 for case 1 and 4 for case 2?. Implemented with https://github.com/hashcat/hashcat/commit/c7999c66bc289023917b2178cb981f2c47585f45. The next version of hashcat (v3.30) which will be released in the next days have an even better solution to this. \n- New option --progress-only: Quickly provides ideal progress step size and time to process on the user hashes and selected options, then quit\nThat means you can precompute how to set the -l value. If you want to, for example, let hashcat run for 10 minutes and stop afterwards.\nFor example:\n```\nroot@sf:~/hashcat# ./hashcat example0.hash -a 3 ?a?a?a?a?a?a?a?a --progress-only --mac\nhashcat (v3.20-96-gaa89b8b+) starting in progress-only mode...\n1:458752:59219.16\n```\nThat means setting -l to 458752 (in this case) takes 59219.16 ms to progress. The good thing is, if you stick to a multiple of 458752  (in this case) hashcat can guarantee you to always run in full speed. So, if you want it to run for 10 minutes, You'd do something like:\n\n((10 * 60 * 1000) / 59219.16) = 10,131...\nEither round up or down the result and multiple it with the 458752, ex: 10 * 458752\nUse -l 4587520 and hashcat should show you a Time.Estimated ~ 10 Minutes\nBecause you have control over -l, you can control -s as well\n\nPlease close the issue if this works for you.\n. Btw here's the issue with the details how it came to this (because it can be useful in distributed computing): https://github.com/hashcat/hashcat/issues/916. Which version is that? With latest beta it looks good:\n```\nroot@ht:~/hashcat# cat hash\nbad55dcf7cfb409bfd851a6dd876f52e:test1\ne609d54d973edf399356156c21da6a23:test2\ne609d54d973edf399356156c21da6a23\nroot@ht:~/hashcat# ./hashcat hash -a3 x\nhashcat (v3.20-102-ge5e97c6) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 507/2030 MB allocatable, 5MCU\n\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-AMD FX(tm)-8120 Eight-Core Processor, skipped\n\nHashfile 'hash' on line 1 (bad55dcf7cfb409bfd851a6dd876f52e:test1): Line-length exception\nHashfile 'hash' on line 2 (e609d54d973edf399356156c21da6a23:test2): Line-length exception\n```\n. Fixed with https://github.com/hashcat/hashcat/commit/0fe6db6839f9646124a5c6ae6f52111a573fe1ac\nThanks!. Fixed with https://github.com/hashcat/hashcat/commit/038b915e2da7951f2599b5894169e54c93142c19\nThanks!. I need the .hccap you're using to reproduce locally. OK, I got the file. Now I need one example of a duplicate which is not detected as duplicate. Please name me one.. Yeah I think I found the root problem. Need to think about a good solution. Prepare for testing :). OK, I've patched hashcat. There's also a new beta at https://hashcat.net/beta/\nIn an ideal world, the output of your file should look like this:\nHashes: 69295 digests; 66980 unique digests, 57302 unique salts\nThat is because your file has 11993 handshakes with the same ESSID. Now the problem is that there's a chance that some of those handshakes have the same ESSID, but they are actually from a different AP. There's no way for hashcat to know about this. Therefore we must check all the handshakes, even if they have the same ESSID. But we can still make use of the duplicate ESSID shortcut. I've patched hashcat, so don't get confused if you see this loading screen instead:\nHashes: 69295 digests; 69295 unique digests, 69295 unique salts\nIt will still make use of the duplicate PBKDF2 shortcut. You can find out if you meassure the time it takes to process a full wordlist. Simply ignore what the \"Time.Estimated\" in the status screen tells you.\n. This is important to help the not so advanced users to be able to compile a native hashcat binary and run it without using the install target or using LD_LIBRARY_PATH. The only practical way I see to handle this is to remove the RPATH when using the make install target. What do you think?. Teaching people how to use LD_LIBRARY_PATH is far too big of a goal for the hashcat project. The only solution is that we remove the rpath when the user uses make install target. How exactly did you do it? I see the tools \"patchelf\" and \"chrpath\" can do it. Which one would you suggest?. I kind of agree, but such an wrapper script would confuse new users.\nIt's not very intuitive, so it's not a good solution. Do you have any\nother ideas?\nOn 23.01.2017 16:33, Levente Polyak wrote:\n\nas said, you don't need to teach anyone about LD_LIBRARY_PATH if you\nhave a wrapper script that does so and uses explicitly the directory\nwhere the shared lib was built in. its still vulnerable for all people\nwho don't use the install target.\nThe only solution to this issue is to not use relative rpath at all\nand add a wrapper script to start hashcat when not being in a\n'installed' target, otherwise the users is always vulnerable to\nunintended code execution.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/956#issuecomment-274519690,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OU3WZCE8OXTYs0XHxBMAShdeCeisks5rVMgxgaJpZM4LdmIB.\n\n\n. Well as already discussed, the problem would occur only with the\nself-compiled version which then is not used with the make install\ntarget, because this target will have the rpath removed. That means that\nan attacker would need to convince the victim to compile hashcat with\n\"make\" but not to install it with \"make install\". After that, he need to\nconvince him to execute hashcat but before that, to change the cwd to a\ndifferent one first. This folder must be one that the attacker has\nwrite-permission to. Do you agree so far?\nIf that's the case, only the \"local\" compiled version is a problem. This\nversion has the target output file named \"hashcat\" for purpose. It's\nbecause it's the most intuitive output filename for the binary I can\nthink of what the user expect to have after the compilation. Now, as you\nsuggested, imagine we rename this binary to hashcat.bin and additionally\nadd a wrapper script called \"hashcat\" which then calls the\n\"hashcat.bin\". New and unexperienced users will call this script before\nthey would even think about they have to compile hashcat in the first\nplace. They will execute it and get an error message because hashcat\ndoes not exist. We can make it a good warning to inform the user to\ncompile the binary first, but most of them do not read. They will simply\nclose the shell, remove the hashcat folder and never try it again. The\nuser is probably lost forever. That's why I'm looking for a different\nsolution.\nOn 23.01.2017 16:37, Levente Polyak wrote:\n\nI don't see the difference, wherever you put you hashcat executable\ncould be the place to have the hashcat wrapper script. Nobody would\never notice the difference if you adjust the install target\naccordingly and distribute the non-wrapper version instead. I honestly\ndon't see where the problem is.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/956#issuecomment-274521027,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Of-x_Qo2LbGHDzSzdFSc7GcT9tgtks5rVMk9gaJpZM4LdmIB.\n\n\n. No absolutely not, I just want to find a good solution, that's all.\nAnother problem with such a wrapper script is that it needs to be\ncompatible with all the platforms where hashcat already works on. This\ncan be tricky to find a script which works for OSX, FreeBSD, Mingw,\nMSYS2, Cygwin and Linux all at once. If you want, please send in a\nscript as PR and I'll merge it.\nI also think of another solution. Maybe its better to step back to the\nway it was before (statically compiled) but also add the shared library\nusecase with a special \"shared\" Makefile target. Then we can remove the\nrpath because people that compile the shared library explicitely also\nknow how to handle LD_LIBRARY_PATH.\nOn 23.01.2017 16:56, Levente Polyak wrote:\n\nWhy would they get an error message? You can easily put the wrapper\nsomewhere else and handle it in the compilation step by moving it\nwhere the binary would be. No offense but I start having the feeling\nlike you just don't want to solve this at all for people that use a\nlocal copy of hashcat and just keep them vulnerable because of\n\"convenience\" (where I still disagree that it can't be transparently\nsolved if you really want to).\nThe concerns you mentioned are understandable, but as I pointed each\none can be solved individually while still not requiring any rpath.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/956#issuecomment-274526727,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUtUs_RSU2HAlWlWSw3ur2Ua_7ZVks5rVM2lgaJpZM4LdmIB.\n\n\n. I tend to the 2nd version but I need to think about it some more time.. OK, I've implemented as we discussed the 2nd solutions. So we've completely removed rpath :). Update 14000, 14100 and 14400.\nMode 1300 is not part of hashcat (only hashcat-legacy). Can you please rewrite so that it does not use a NOT. We try to stick to positive cases only for easier reading.. All systems (just not apple?). This feature was never a wanted feature in older version. It was \"just luck\" that it worked like that. Therefore not ported to new version. \nBut I can see how it can be useful. Have to think about how to re-add it with new architecture.\n. Support has been added. Note that the high performance will create tons of collisions, thus it's printing them all and not stopping after one has been found. We can change that if you want.. No, it's a bug, not wanted behaviour. I can reproduce.. Fixed, thanks for reporting. Yes, the --veracrypt-pim option is currently not supported, it has nothing to do with the selected cipher. Since I do not have OSX I can not reproduce. Did you make sure to run \"make clean\" before compiling?. Can you please retry with latest github version? It's doing some detailed file permissions checks on startup, maybe it will give us some more useful debugging output. Also, what is homebrew, maybe it's related?. Thanks! Great work. Can you please retry on Ubuntu? Kali is known to run a broken OpenCL runtime installation.. Should be fixed with https://github.com/hashcat/hashcat/commit/9005b6662663ebbfab7025d03aa661374d34bf31\nIf it's not working for you, please reopen the issue. Thanks for reporting!. Please do not run any OpenCL application inside a VM, the OpenCL runtimes are instable enough. Please retry on the host directly.. OpenCL is a nieche product and does not have many users giving feedback. Therefore you need to expect multiple bugs in the vendor's driver and their OpenCL runtimes. When we reports bugs, they are typically silenty ignored because from a vendors perspective there's not enough money in fixing those. That's why I said that you shouldn't use a VM.\nHowever, as @epixoid already mentioned, this is not a hashcat issue. We can't fix the vendors drivers. Also, when it comes to multiple GPU support, this is well tested by many hashcat users, even mixed types.. That's not what I'm saying and I think there's some misunderstand here.\nWe're not that kind of developer who ignore users feedback. We care\nabout and we feel no shame admitting bugs if there are any. You can see\nthat from hashcat's changelog, it's full with descriptions about fixed\nbugs.\nBut in your case, you are wrong. The observation with the TDR settings\nare just a fix to a symptom, but not the problem. The problem is that\nthe timing numbers from your SHA1 are ways too high (you can see it in\nthe screenshot after the speed). They should be around 90ms (in -w 3\nmode). Also, if single GPU's randomly drop in utilization that's\nsomething we've experienced in the past already, and it's always\nsomething wrong on a lower level, for example the OpenCL runtime or the\ndevice driver or on the hardware layer the MB or the PSU or even a\nbroken GPU. But all of this stuff is out of our reach to fix\nOn 18.02.2017 14:04, marukka wrote:\n\nSo basically what you're saying is that your code is infailable, and\nthat everyone else must be at fault. And that your programming skills\nmake you a god among men. We just confirmed that your code is timing\nout and triggering the TDR in Windows, yet you're blamining everyone\nelse. Whats next, when hashcat segfaults you're going to blame\neveryone else too for accessing an illegal address because the kernel\nshould simply let you access any memory address you desire? Wow you've\nbeen blown the fuck out.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/976#issuecomment-280844346,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVgjH7o3na4noIlu0Ej-6GMPC8bKks5rduxEgaJpZM4LpLah.\n\n\n. I don't think thhat's comparable. When it comes to the OS they have\nlarge access to the system hardware and can workaround a specific bug.\nIn OpenCL, all we have is an API and we have to follow the way the API\nhas to be used. If the path we are forced to use is broken, there's\nsimply no way for us to workaround.\nAgain, if this would be a problem that we could workaround, we'd do it.\nThe example you gave with modify the registry however is not possible.\nFor one it eventually requires administrative permissions and a user\nwould be confused if we ask for it. Since we're in the scope of security\nsoftware people are even more sharp about it. Another reason is that we\ncan not simply restart the driver because there might be other\napplications already running and using the OpenCL interface (or any\nother GPU related API) and we'd break those.\nI've personally reported bugs to nvidia but as I said, they are ignored.\nReason is, again, because OpenCL is a nieche product and they don't care\nif there are any bugs. But said so, feel free to report it yourself.\nOn 18.02.2017 14:44, marukka wrote:\n\nI apologize as I may have been a bit rash. But my point I think still\nstands. Take for instance the FDIV bug in old Intel Pentiums. When was\ndiscovered the entire x86 computing industry didnt throw its hands up\nin the air and say, oh well too bad, it isnt our problem its Intels.\nInstead they worked around it, companies like MathWorks implemented\nsoftware floating point routines for their products, and companies\nlike Microsoft added switches like /QIfdiv to their compilers to use\nsoftware floating point routines when it detected it was running on an\neffected chip.\nAnd although reporting a bug doesnt guarantee it will get fixed, a\nperfect example being my bug report right here, if /you/ never report\nit upstream then that is a guarantee that it will never be fixed.\nNow i'll play devils advocate for a moment and assume this is a\nproblem with a 3rd party you have no control over. You still can fix\nthis bug. As we've discovered here, changing the TDR timeout works\naround the problem. All you have to do is have hashcat set a registry\nkey and restart the driver or reboot the computer to make it take\neffect. As @epixoip https://github.com/epixoip said, hashcat used to\nat least display a warning in prior versions but this functionality\nwas removed. Well as my case demonstrates, and as you say this is\nsomething \"we've experienced in the past\", there clearly seems to be a\ndemand for this feature. Now of course this isnt the best fix as the\nGPU doesn't remain loaded constantly but some additional computing\npower is better than none.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/976#issuecomment-280846417,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdNPUxvuA1UvhEYl32eEqTueXe62ks5rdvW0gaJpZM4LpLah.\n\n\n. There's none, but you need to understand how NVML and OpenCL measures\nthese units. For NVML, it's unknown because it's closed source. For\nOpenCL, there's no function inside the API. We measure it simply by\ndividing the number of hashes calculated with the time it took from the\nstart of the OpenCL kernel till it's return (and eventual copy\ntransactions before). So this is a blocking function which means it's\neither finished or not. There's no way for us to know what's actually\ngoing on on the GPU.\nOn 18.02.2017 14:53, marukka wrote:\n\nAlso it would be nice if you could address hashcat incorrectly\nrecording device performance. Specifically it saying Speed.Dev.#2\nhttps://github.com/hashcat/hashcat/pull/2 has a non-zero value when\nthe load is 0% in my previous screenshot.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/976#issuecomment-280846916,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OS6hKcTANDOcTmkcbVh710_1YVISks5rdvfDgaJpZM4LpLah.\n\n\n. What I wanted to say is that there's simply no different path if you\nhave to navigate inside an API rather than a free environment like an OS\n(or Application context). Therefore a workaround is sometimes possible,\nbut not in this case.\nSuch an applications break by driver restart event will not occur if the\nerror itself would not occur. That's why it's more important to fix the\nproblem rather than to try to workaround. You also have no guarantee\nthat the workaround will work as wanted. Whenever some situation is out\nof control, everything can happen. That could be, for example, false\nnegatives and that's something you really don't want in a password\ncracking tool. It would be not maintainable for developers because each\nnew error could be caused by the workaround and you can not know or not\nknow.\nI don't think it makes sense to reimplement that error message. In the\npast it had confused people more than it helped, especially new and\nunexperienced users.\nIn case you don't know, but hashcat in the past was 50/50 OpenCL/CUDA.\nThere's multiple problems with CUDA from a technical perspective but the\nmost important difference is that CUDA does not support AMD GPU or Intel\nCPU while OpenCL does.\nOn 18.02.2017 15:38, marukka wrote:\n\nThe FDIV bug wasnt worked around at the OS level afaik. It was worked\naround either in programs specifically such as MathWorks, or at the\ncompiler level as with MS's VisualStudio compiler.\nIf you are concerned about user confusion regarding UAC prompts you\ncan present a prompt beforehand. And if people are that worried about\nsecurity then they'll be either running it in a VM like myself or on\ndedicated hardware which will be reimaged after use, which they wont\ncare about a registry change.\nRegarding other applications being broken by a driver restart, when\nthis bug occurs it will break them anyways when the driver is\nrestarted by TDR. And again if you are concerned about this, a prompt\ncan be displayed before making this change.\nIf you dont like my ideas then fine, its your product, not mine. But\nat least consider re implementing the message @epixoip\nhttps://github.com/epixoip said was in version 3.2. It at least will\nhelp some other people.\nAlthough this would be a much more time consuming (and thus a more\nunreasonable request), if you guys dont like OpenCL as much you can\nalways try adding support for CUDA which gives the impression has\nbetter support from Nvidia.\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/976#issuecomment-280849526,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oa4Z9HnbCW0IK1RnbvxovaHIijh1ks5rdwJegaJpZM4LpLah.\n\n\n. OK, added with commit: https://github.com/hashcat/hashcat/commit/ac5d2748451a3014ca6592eaf1d973f8a499a8c6\nPlease verify and close the issue\n. OK, added with commit: https://github.com/hashcat/hashcat/commit/84fcd8289fa70cb0a5bbd36126cb7b645d493e7f\nPlease verify and close the issue. Nice find, thanks!. AMD dropped support for your GPU using their driver, you can go to AMD and thank them. Anyway, not an hashcat issue, therefore closing.. See release notes from v3.30:\nFiles: Use $HEX[...] in case the password includes the separater character, increases potfile reading performance\nAnd release notes from v3.20:\nPassword candidates: Do not use $HEX[] if the password candidate is a valid UTF-8 string and print out as-is\nThere's no relation between --outfile-format and $HEX[...]. I know this is kind of confusing.\n. Great work, thanks!. Can you please paste the output of the clinfo program? Maybe limited shared memory is the problem.. Please retry with latest beta version from https://hashcat.net/beta/\nThere has been lots of changes. OP not responding but we believe this case be fixed with TDR patch which hashcat is warning the user now on startup, therefore closing. Thanks @ZerBea for reporting. The problem is the more ambiguation strings you allow (for whatever parameter) the lower the chance for getting help from non-developers. That is because most users, once they have an understanding of the option, do not care about changes that are added later to the option. \nIf a new users steps into hashcat universe and needs help but then uses such ambiguation the people that maybe could know the answer get confused by the ambiguation and stop thinking about helping them.. Not a bug this time. It's important to feed hashcat with enough words in the wordlist. In your case it's only ~100k words -> 43270828920  / (1000 * 418 ) = 103518\nIf your intention was to get enough traction by using -a 6 that's possible, but you need to do it differently.\nSo, instead of:\nhashcat -m 2500 -w 3 --remove --logfile-disable --potfile-disable --outfile-autohex-disable --outfile-format=3 -o found.list test.hccap -a 6 wordlist ?d?d?d\nDo this:\nhashcat --stdout -a 6 wordlist ?d?d?d | hashcat -m 2500 -w 3 --remove --logfile-disable --potfile-disable --outfile-autohex-disable --outfile-format=3 -o found.list test.hccap\nThis should give you full speed.. Great work, thanks!. Where is it used in?. For a quick hack it's very simple but for permanent use it's too much\nwork to do it without a good reason.\nOn 31.01.2017 19:08, lukasz1991a wrote:\n\nIt is a lot of interference in the system kernel to increase the salt\nto 500 characters?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1004#issuecomment-276443402,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OQGxpbZQ6oRwiwXc-DoHqHYrU3yhks5rX3isgaJpZM4Lx5Iw.\n\n\n. The programming language is C. I'm not going to do any code change here\nunless I know where this is used in and if other people could make use\nof it as well. Please close the issue otherwise as Github issues is for\nbugs and feature requests only.\nIf you want to patch it yourself: You only need to patch hash generation\nbefore the ipad[] and opad[] is stored. If you need to crack only one\nhash it should be pretty simple to do. Just push the salt as constants\nin the kernel. Not host code changes required.\nOn 31.01.2017 20:45, lukasz1991a wrote:\n\nI do not know the language in which it is written. I tried on\nintuition and I had a memory error. I could ask you how to do it for\nthis one mode?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1004#issuecomment-276470534,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OZ1sTkaFU7lG06BzO9DOmRCgVczHks5rX49kgaJpZM4Lx5Iw.\n\n\n. Please use latest beta version, the issue should be fixed. Closing this issue because there's a solution from @DoZ10 and at the same time there's no known frameworks/application that are using this. Feel free to reopen in case some frameworks/application will pop up.. We'd need to support ChaCha20 and Argon2 first.. Is that exactly what JtR does? I mean, is that all of it?. I agree with @magnumripper. The single mode, to be efficient, needs a different architecture which is kind of incompatible with devices (such as gpu) that require high parallelization (especially with mixed gpu types). There's a reason why hashcat limits the weak-hash-check (empty password) to a maximum of 100 salts. It would slow down the startup too much, especially with slow algorithms like LUKS or itunes. Adding more password candidates would not make a big difference in startup time for fast hashes, but for slow ones. There's also the problem of how to feed hashcat with a wordlist that is build out of data using --username. Such a logic could be implemented, but that's additional effort. \nMaybe in the future, when hashcat makes another refactorization that enables iterating through salts in the inner loop, this could be a thing to add, but I only see limited potential for this atm.... I have no experience with Android development. Maybe someone else can answer the questions. Thanks :). Nice, I can reproduce this on my Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, 2047/15999 MB allocatable, 8MCU. The -a 3 works, but the -a 0 fails\n. Should be fixed with https://github.com/hashcat/hashcat/commit/9005b6662663ebbfab7025d03aa661374d34bf31\nIf it's not working for you, please reopen the issue. Thanks for reporting!. I think it's fine as it is. Please reopen the issue if you can not live with it ;). I didn't know about appveyor. Do I need to \"activate\" it like with travis?. The PR caused multiple problems.\n\n\nThe globbing \"CRT_glob.o\" which is required to do globbing with mingw wasn't found anymore when compiling on Msys2, Cygwin or on linux using the cross compiler. This is caused by the change in win_file_globbing.mk\n\n\nThe change to main.c causes an compiler error when compiling on Linux:\n\n\n/usr/x86_64-w64-mingw32/lib/CRT_glob.o:CRT_glob.c:(.data+0x0): multiple definition of `_dowildcard'\n. @neheb The fix for IS_WIN_BUILD_NATIVE is ok, but the fix for cross-compilation is not. The cross-compilation targets are ment to be called from linux only and to generate the binary package. If we remove it its too confusing. Can you please modify the PR ?. Was the NVML initialization successfull? Does nvidia-smi work?. I've tested with Xanadrel. We had to update to latest driver, but after that the Titan X worked fine.. Support added with https://github.com/hashcat/hashcat/commit/c28fdf7f44bf5d39f9078f6d82b52bdb052125e3. Should be fixed. Please test. If not working, please reopen issue. Both changes look good to me. Not sure what's going on with AppVeyor but this seems to be a different issue. We should open an issue for it, but that's not related to this PR. Update:\nAfter some tests I found out that there's actually no more need for glob.o when using the _dowildcard variable. For me this variable was unknown, which is the only reason why I've always used the glob.o instead.\nI've tested cygwin, Msys2 and the cross-compilation from Linux. They all work fine, therefore I've also removed the win_file_globbing.mk include which makes the Makefile more easy to read.\nI hope this will also simplify the process with the appveyor integration.. @stephengroat I think the .yml PR was fine as it was before. All the other stuff has been dealt with. So if you create a new PR with just the .yml we can merge that.. @stephengroat I've merged the .yml. Do you think we should add the appveyor badge to README.md as we do with the travis one? Can you please create a PR for that.\n@stephengroat With your new PR you've changed the git submodule init behavior. While it's not problem related to this change, do you know who to tell travis to checkout the correct commit and not just the latest? We intentionally use an older version but travis seems to ignore this. @stephengroat @philsmd Guys, thanks for PR's!. Please use latest beta version, the issue should be fixed. @magnumripper Please do a suggestion on the character to use. @julioauto While I find your syntax more intuitive I also like the idea of using / and %. We should use the same approach to stay compatible with JtR ruleset.. Note that hashcat also inherited this function but from PasswordsPro,\nwhich I thought inherited from crack. Anyway I'd prefer to stay Crack\ncompatible. Is there any rule in Crack that does what hashcat is doing\nwith \"p\" rule function?\nOn 09.05.2017 17:07, Solar Designer wrote:\n\n\n@jsteube p rule is already taken in hashcat as: pN -> Append\nduplicated word N times.\n\nJtR's p discussed here is not a rule command, it is a character\nposition code, so hashcat should have no problem introducing that\nposition code as well.\nhashcat's different meaning of the p rule command is unfortunate (in\nJtR the p command means \"pluralize\", and we inherited it from Crack,\nso it's 20+ years old), but is irrelevant here.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1035#issuecomment-300194904,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OWIKWbdY51vdd3ISJ29693B-JFsBks5r4IFBgaJpZM4L7cLZ.\n\n\n. From your repository it seems you've overwritten your hashcat.exe by using the redirect operator > which then leads to Access Denied (not refused). Please learn how to use a commandline first.. I'll merge this now, because I'd like to see the compile process getting tested. If the tests in the post compilation process fail that's bad and you should remove or fix by creating a new PR. One step at a time!.  It's multiple threads writing to the same memory section. There's really no way to get rid of atomics.. OK, we can do that. Question is just how. I think it's better (for the user) if we abort hashcat with an error message and not try to fix his errors silently. I'd suggest abort hashcat with an appropriate error message if the user specifies a custom charset but does not specify a mask.. So much green :+1: . Thanks. The use of NULL for the format variable is something gcc doesn't like much. Given the code:\nprintf(NULL);\ngcc returns with:\nwarning: null argument where non-null required (argument 1) [-Wnonnull]\nSo this seems to be the wrong approach to me. But I can see the need for it. There's another way to do it. Instead of \nevent_log_info (hashcat_ctx, NULL);\none could do\nevent_log_info (hashcat_ctx, \"%s\", \"\");\nThis makes every compiler happy but not us coders, because that looks kind of strange.\nSo as another alternative I'll try to use the patch as you suggested and add a check for null pointer and then let's see how the compiler react. There's many different compilers and versions and it seems they all react different to this.\n. It's fine, the num_files++ can be remove. The only reason it's there is because of this:\n```\n    files[num_files] = hcstrdup (path);\nnum_files++;\n\n```\nBy using a code like this:\n```\n  files[num_files] = NULL;\nnum_files++;\n```\nIt's easier for the coders' eye to identify that there's some \"pattern\" in which two variables are involved, but it's not that important. \n. OK, what to do?. I've had to add it \"manually\" because the correct hashcat/hashcat project name is already claimed. That's kind of strange and causes us to not be able to link it. That's bad because we can not integrate it into Travis CI this way. But let's first try to fix the reported problems and then see how to continue. This is the current hashcat-utils path: https://scan.coverity.com/projects/hashcat-hashcat-utils. The hashcat/hashcat project is now linked inside Covertiy to this GitHub repository. We should be able to run it from within Travis. @neheb can you try to find out how?. Very nice, thanks!. As discussed, not a reference cooler. Please add some example pairs\nOn 13.02.2017 14:06, ratzrattillo wrote:\n\nJSON Web Tokens (JWTs) are an emerging technology in Authorizing users\nin the web.\nThe Format of these Authorization Token is defined here: https://jwt.io/\nThe algorithm used to create a token is most of the time HMAC-SHA256\n(HS256).\nHashcat actually already provides functionality to crack HMAC-SHA256,\nbut with a character limitation of the plaintext (50 characters) JSON\nWeb Tokens tend to be much longer though. The example on\nhttps://jwt.io/ has a plaintext-length of 105 characters.\nIs it possible to either:\n\nAllow a wider length for the plaintext\nImplement a dedicated JWT-Cracking mode?\n\nBest Greetings!\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1057, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OYyxA7Mqm4Zq0-V85VDYSXEYp4Fcks5rcFU-gaJpZM4L_LlE.\n\n\n. I'm about to add this hash-mode to hashcat finally. One question for @ratzrattillo : The hash line you posted\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ\nHow and where did you get it initially from? I guess this data must have been somehow sniffed from the wire? I'm asking because I'd like to stick to the original output as close as possible, so that there's no tool needed (like jwt2john) and hashcat can load it directly. However if this is just some data you've collected manually this wouldn't make sense then, thus I'm asking.. Format was added as hash-mode 16500. It supports cracking HS256, HS384 and HS512. You can compile from source or use the binary beta from https://hashcat.net/beta/. Yes, hashcat can resume at an arbitrary point in the keyspace, because of the markov mode that hashcat is using.\nThe request itself would be doable, but would not do what you think it does, except in --stdout mode maybe. OTOH it requires to rewrite some of the core kernel which is not so easy to do (and then from the host to select the correct one).\nIn GPGPU, because of the high parallelization, there's no difference in the ording when you have small masks as they are using hybrid modes. This mean, for your usecase 1, this will not work. There are all started within a single kernel invocation and then it's up to the OpenCL runtime which thread is executed at which time. That means, we do not have a direct control over it. \nFor large keyspace, like in BF, this is usecase 2, this would theoretically work, but for that case I don't see the advantage in this. It's not like the user runs hashcat with --stdout and then picks up the last password that comes out. And even if he would do that, it would be easier to make a wordlist of it and then hit it the same way.\nFor your usecase 3 I like that Idea if the markov mode would be a true markov mode. That is the total number of password candidates depend on the training data. But that's not the case in hashcat, because we can not reject candidates for fast hashes.. There's no way hashcat can do that, because it's the OpenCL runtime managing the thread count / cpu cores. Most OpenCL runtime however support an environment variable that lets you select a fixed number of core, that should help you.. Not sure if they are documented. Here's how I found them for AMD:\nroot@sf:~# strings /opt/amdgpu-pro/lib/x86_64-linux-gnu/libamdocl64.so | grep CPU\nCPU_WORKER_THREAD_STACK_SIZE\nCPU_MAX_COMPUTE_UNITS\nCPU_USE_ALIGNMENT_MAP\nCPU_MAX_WORKGROUP_SIZE\nCPU_MEMORY_GUARD_PAGES\nCPU_MEMORY_GUARD_PAGE_SIZE\n...\nThe CPU_MAX_COMPUTE_UNITS sounds good (for AMD).\n. I'm not sure if I like the changes to _WIN. It feels much better to read \"WIN\" instead of \"WIN32\" because \"WIN32\" could be misunderstand that a 64 bit compiler will not use this macro (even if it does, i've just verified). I think we should stick to the current _WIN.\nAlso what's confusing is this:\n+#if defined (__unix__) || defined (__APPLE__) || defined (__FreeBSD___)\nbut according to @magnumripper the FreeBSD should also use unix ?! since I don't have a BSD system I can not verify myself, I need a good recommendation.\nThe ADL on Cygwin sounds good.\nAnother thing I saw is that you've changed copy/paste headers from 3rd party sources, like ADL. I'd prefer to have them non-modified, even if they do not match our format settings. I know it happend before but I try to keep them as they are.. I'm closing this as it's already not longer auto-merging. Can you please resend in the ADL HW-Monitor support for cygwin? About the other stuff (Macros) we should discuss separate.. I think the problem here is a missing shared object which is part of the nvidia driver. @rhertzog Can you please make sure this file is part of Kalis nvidia drivers? Filename is \"libnvidia-ml.so\".\nOn my Ubuntu 16.04 this gets installed by the nvidia driver to \nroot@et:~# ls -l /usr/lib/x86_64-linux-gnu/libnvidia-ml.so\nlrwxrwxrwx 1 root root 17 Feb  2 11:01 /usr/lib/x86_64-linux-gnu/libnvidia-ml.so -> libnvidia-ml.so.1\nroot@et:~# ls -l /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1\nlrwxrwxrwx 1 root root 22 Feb  2 11:01 /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 -> libnvidia-ml.so.378.09\nroot@et:~# ls -l /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.378.09 \n-rwxr-xr-x 1 root root 1181216 Feb  2 11:01 /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.378.09\nThis file is important to manage temperature, fans, utilization etc.\n. I'll however add a check for this and output some warning message. I've added a new check to hashcat on startup to disable hardware monitoring in case NVML was not found even if XNVCTRL was found, because it depend on it. That's what happend in your case and lead to the segfault. \nI've pushed the fix to GitHub with commit: https://github.com/hashcat/hashcat/commit/0aca372ce8e8674dbdda1cc7ce3a6b684b7d118e\nThere's also a binary beta on: https://hashcat.net/beta/\nIt would be nice if you can test the fixes.\nAdditional I recommend to push libnvidia-ml.so to Kali because this library is really useful. After that, you'll find the following informations in your status screen:\nHWMon.Dev.#1.....: Temp: 42c Fan: 33% Util: 95% Core:1189Mhz Mem:2700Mhz Lanes:16\n. You're right, the hardware monitor library has no dependency to the OpenCL library.\nHowever, from my understanding the libnvidia-ml.so library shouldn't be a separate package. It is an official part of the nvidia-driver installer that you can download from their site. I think it should get installed to the user system whenever the user installs the nvidia driver package. This also solves the problems caused by mixing different versions of the library and the driver.\nIf you really don't want to do that, the suggested packages hashcat-nvidia, hashcat-intel and hashcat-amd are actually a nice idea. Make sure those package can be installed in parallel, that is because hashcat also supports mixed GPU types (different vendors) and mixed device types (GPU and CPU) to run in parallel. I'd think of them as a kind of additional packages to a hashcat base package.. Maybe the library is not in the search path? So that hashcat will not\nfind it on Kali Systems, whatever the package is installed or not?\nOn 16.02.2017 15:32, Rapha\u00ebl Hertzog wrote:\n\n@jsteube https://github.com/jsteube So the bug reporter already had\nlibnvidia-ml1 installed... the issue is somewhere else. He provided\nthis backtrace:\n|hashcat (v3.30) starting in benchmark mode... * Device\nhttps://bugs.kali.org/view.php?id=1: Old CUDA compute capability 3.0\ndetected, OpenCL performance is reduced. For ideal hashcat performance\non NVIDIA GPU you need CUDA compute capability 5.0 or higher (Maxwell)\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007ffff7b62484 in hm_NVML_nvmlDeviceGetPowerManagementLimit (\nlimit=0x7fffffffdfdc, device=0x0, hashcat_ctx=0x555555759010) at\nsrc/hwmon.c:1012 1012 src/hwmon.c: No such file or directory. (gdb) bt\n0 0x00007ffff7b62484 in hm_NVML_nvmlDeviceGetPowerManagementLimit (\nlimit=0x7fffffffdfdc, device=0x0, hashcat_ctx=0x555555759010) at\nsrc/hwmon.c:1012 #1\nhwmon_ctx_init(hashcat_ctx=hashcat_ctx@entry=0x555555759010) at\nsrc/hwmon.c:3894 #2 0x00007ffff7b5b504 in\nhashcat_session_init(hashcat_ctx=0x555555759010,\ninstall_folder=0x5555555565c6 \"/usr/bin\", shared_folder=0x5555555565b3\n\"/usr/share/hashcat\", argc=4, argv=0x7fffffffe2a8,\ncomptime=1484845219) at src/hashcat.c:1025 #3 0x0000555555555203 in\nmain (argc=4, argv=0x7fffffffe2a8) at src/main.c:975 (gdb) |\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1101#issuecomment-280345704,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OcKHt8tLKgG1v6TINjn998LzJJN3ks5rdF4XgaJpZM4MBcHg.\n\n\n. Do you mean that it's from version 304.x which is damn old? You really\nneed to update it.\nOn 01.03.2017 15:27, Rapha\u00ebl Hertzog wrote:\n\nThat seems wrong in general:\n|$ apt-file show libnvidia-ml1 libnvidia-ml1:\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so libnvidia-ml1:\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1 libnvidia-ml1:\n/usr/lib/x86_64-linux-gnu/libnvidia-ml.so.304.131 $ cat\n/etc/ld.so.conf.d/x86_64-linux-gnu.conf # Multiarch support\n/lib/x86_64-linux-gnu /usr/lib/x86_64-linux-gnu |\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1101#issuecomment-283353920,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Of9IT17AbZQetqeiq13lUPcvgxSQks5rhYBFgaJpZM4MBcHg.\n\n\n. Can you please try to find out (using strace) if hashcat is finding and\nloading the library successfully? From my perspective it still looks\nlike it wasn't found that's why the error occurs. Btw you should update\nto the latest v3.40 version which detects this kind of error and does\nnot segfault and just disables the not working hardware management.\nOn 07.03.2017 14:10, Rapha\u00ebl Hertzog wrote:\n\nNo, I wanted to show the precise location of the library. Actually the\nversion in Kali (and Debian Testing) is version 375.39-1 but it's in\nthe same location which is in the usual library search path. This was\njust a bad copy-paste because I picked the output that referred to an\nolder version of Debian.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1101#issuecomment-284716936,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oa3eW4MJbmlfqcAkKbukxmCa5XIaks5rjVc9gaJpZM4MBcHg.\n\n\n. I've send you 3 emails to your gmx address. Maybe check the spam folder?. Maybe. I've send you like 5 emails now. hashcat email is using gmail services and also has all kinds of SPF info in DNS. So probably blocking gmail incorrectly?. Come to IRC freenode #hashcat. OK I've pushed a a fix https://github.com/hashcat/hashcat/commit/2dd027af65b2fec951e9a9afb0b3959c55510b57 which is likely the root cause for your issue. Unfortionally this is the result of some uninitialized variable on start which means that your current potfile might contain invalid data. You need to rebuild the potfile from scratch to verify it's working. A new beta is up on https://hashcat.net/beta/. I've seen the CL_OUT_OF_RESOURCES only in combination with Win10, but never with Windows version lower than 10. If there's a problem with CUDA_ERROR_LAUNCH_TIMEOUT, then it's probably a combination of Windows 10 + CUDA_ERROR_LAUNCH_TIMEOUT. Also note that from the status screen:\nSpeed.Dev.#3.....: 430.3 kH/s (93.89ms)\nSpeed.Dev.#4.....: 402.2 kH/s (100.53ms)\nSpeed.Dev.#5.....: 395.1 kH/s (50.80ms)\nSpeed.Dev.#6.....: 438.0 kH/s (92.30ms)\nWe can clearly see the kernel timeout is less than 2 seconds.\n. Thanks for clarify! I've re-added the check for timeout patch. I think it needs an extraction utility first. After that, adding a mode is simple, since we already have GPU code for TrueCrypt and LUKS which ships all of the ciphers, hashes and modes we'd need.. If it's AES-XTS that would be nice, since we have this kind of kernel\nalready optimized and well tested.\nOn 22.02.2017 18:27, IncognitoEntity wrote:\n\nJust writing to add support a bitlocker feature within hashcat. I\nbelieve it uses AES-XTS. Will it be alike truecrypt striping out the\nfirst 512 bytes?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1117#issuecomment-281740176,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OR_zVx7UwSrJiMv2QbrdO5Iig5plks5rfHARgaJpZM4MFuDX.\n\n\n. I'll push this implementation to hashcat-utils soon. The only change I made is with the mapping. Here's the new enum:\n```\ntypedef enum\n{\n  MESSAGE_PAIR_M12E2 = 0,\n  MESSAGE_PAIR_M14E4 = 1,\n  MESSAGE_PAIR_M32E2 = 2,\n  MESSAGE_PAIR_M32E3 = 3,\n  MESSAGE_PAIR_M34E3 = 4,\n  MESSAGE_PAIR_M34E4 = 5,\n} message_pair_t;\n```\nI'll also update hccapx version to 4 and rename the \"authenticated\" attribute name to \"message_pair\".\n. OK, everything's updated. Please test. Can you please retry with --opencl-vector-width 1 also send me the header for debugging. Congratulations, I think you pulled the probably most unlikely bug I've ever seen in almost 20 years coding :)\nIt's related to the example.dict example wordlist, which has another bug. It has twice the password \"password\" in it and also directly following each other and this is also the password of your LUKS header. On top of that, it's exactly in the same workitem frame which is already as thin as possible because of the enforced -n 2 value. On top of that the buffer allocated for cracked passwords is bound to the number of hashes, which is just 1 for LUKS. But we're cracking it twice now, because the password is twice in the wordlist, leading the Kernel to write into uninitialized memory region, which then creates clEnqueueReadBuffer(), but I'm using a different GPU for testing, so that's fine.\nI'll fix this soon. In the meanwhile you can remove the 2nd password \"password\" in the example.dict.\n. Thanks!. I'll probably merge this after v3.40 release which is already in RC phase (so that it will go into v3.50). Great PR!. I've taken some time to look into this. I must admit I'm still not convinced using autoconf/automake.\nFirst of all when I run ./autogen.sh I get tons of warnings. From technical perspective this is usually not a problem, but from a user perspective it gives the impression that the developers did not even test their own tools and the first impression counts for software, too. The expectation of the entire toolset is lowered from the beginning.\nchmod: cannot access 'config.guess': No such file or directory\nchmod: cannot access 'config.rpath': No such file or directory\nchmod: cannot access 'config.status': No such file or directory\nchmod: cannot access 'config.sub': No such file or directory\nchmod: cannot access 'configure': No such file or directory\nchmod: cannot access 'depcomp': No such file or directory\nchmod: cannot access 'install-sh': No such file or directory\nchmod: cannot access 'missing': No such file or directory\nsrc/Makefile.am:137: warning: shell date +%s: non-POSIX variable name\nsrc/Makefile.am:137: (probably a GNU make extension)\nsrc/Makefile.am:139: warning: shell cd \"$(top_srcdir: non-POSIX variable name\nsrc/Makefile.am:139: (probably a GNU make extension)\nWhy is this GPL now? We're on MIT\nMakefile.am: installing './COPYING' using GNU General Public License v3 file\nMakefile.am:     Consider adding the COPYING file to the version control system\nMakefile.am:     for your code, to avoid questions about which license your project uses\nIt then completely failed because on my system there was no package \"libtool\" installed. So it called \"libtoolize\" (whatever that is)  but still tried to continue after it failed to locate it. Of course this did not work but for a user with no development experience he would never find out how to solve this. \nAfter that it automatically ran ./configure with tons of options we don't care at all. For example:\nchecking how to run the C++ preprocessor... g++ -E\nThis is a C source, not C++. Why is this check done at all? Can't we disable it?\nFinally it finished and I'm ending up with a mess created by tons of files that I have no clue what they are doing. None of these files existed before:\nAUTHORS\n    COPYING\n    ChangeLog\n    INSTALL\n    Makefile.am\n    Makefile.in\n    NEWS\n    aclocal.m4\n    ar-lib\n    autoclean.sh\n    autogen.sh\n    autom4te.cache/\n    compile\n    config.guess\n    config.h\n    config.h.in\n    config.h.in~\n    config.status\n    config.sub\n    configure\n    configure.ac\n    depcomp\n    hashcat-3.3.0.tar.gz\n    install-sh\n    libtool\n    ltmain.sh\n    missing\n    src/.deps/\n    src/Makefile.am\n    src/Makefile.in\n    src/libhashcat.pc\n    src/libhashcat.pc.in\n    src/lzma_sdk/.deps/\n    stamp-h1\nThis is ugly and confusing. Whenever there's a problem with it, I wouldn't even know where to start looking.\nI see that you tried to generate some sort of auto-documentation, but I'm really not a fan of this. Auto-generated documentation out of git's log can not be trusted because we can not force a good documentation of the changes verified from a technical system (git). Therefore changes should always be hand-written.\nI think there's also a misunderstanding of the package distribution. The script tools/package.sh is the one script which creates the files for distribution of Linux and Windows binaries. Especially Windows binaries. But there's no windows binary in the final package hashcat-3.3.0.tar.gz. With our hand writte Makefile we call \"make binaries\" to compile them using mingw GCC. But I do not see a single use of the substring \"mingw\" in autogenerated src/Makefile so there's defenitly a major feature missing. Does autoconf stuff even support cross compiler?\nI see some files/notices that references hashcat v3.3.0. We call that v3.30 but mean the same. We maybe change this to v3.3.0 notation in a later version.\nFinally I still don't see the need of all this. With our hand-written Makefile all the feature we want are working fine. There's no warnings, no errors and it works on multiple systems. Maybe not all but at least on such where the device drivers come with a working OpenCL runtime. All the others are not useable for us anyway?!\n. With my comment I hoped you maybe can convince me why it makes sense to replace our really good working hand-written Makefile with autoconf. The argument \"do some experience of packing binaries for various distributions(rpm,apt,pacman) if not sure.\" reads like \"because everyone is doing it\" which is something I don't care much about. Plus the Makefile as it is right now works pretty well for them. There's packages for many Linux distributions, even FreeBSD. \nAt this time I don't see why we should switch to autoconf and therefore I will close this PR. I'm not saying we'll never switch, but at this time I'm simply not convinced.\n@yhfudev @stephengroat I would like to thanks for your work involved. I just hope that rejecting this PR will not stop you from contributing to hashcat.. Thanks!. Thanks for PR! From what I've seen I think it's no longer required to do this:\n```\ninclude \ninclude \n```\nin both pidfile.h and restore.h. I think we can remove them. What you think?. It's hard to tell what the error is coming from. It looks like the AMDGPU OpenCL runtime but we need to be sure about that. Since I can not reproduce this locally with AMDGPU-Pro on Ubuntu 16.04, please create the following view for me on your system:\nmake clean\ngit pull\nmake DEBUG=1\ngdb --args ./hashcat -t 32 -a 7 example0.hash ?a?a?a?a example.dict\nafter that type \"r\" to start the gdb run... after the crash occurs type \"bt\" (for backtrack). You can exit gdb by typing \"q\" and \"yes\".\n. Note that this is intentional. AMDGPU-Pro is partially broken, the best AMDGPU-Pro is still 16.40. Details here: https://hashcat.net/forum/thread-6242-post-33291.html#pid33291. Right, see here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_is_the_maximum_supported_password_length\nAlso note that passwords with static components are better added as salts so that only the variable part of it is actualyl the password. In such a case, the password can be much longer than 64, theoretically unlimited, but it requries to write a special hash-mode for it.. I can not reproduce this on my 4x1080 box. Maybe it's because I'm running them on Ubuntu 16.04. Can you please try to reproduce this issue with Ubuntu 16.04? If it occur on there, too, maybe it's a local hardware problem. Your PCI-E lane configuration looks kind of weird and made me think that.. No response from OP after long time, therefore closing the issue. Feel free to reopen if needed.. hashcat tells me:\nHashfile 'NETGEAR68.hccapx': Invalid hccapx version\nMaybe you're using the old hccapx version 3. Can you please use latest versions and resend the hccapx. In the meanwhile I've patched hashcat to load the hccapx as so that I was able to reproduce it. The bug should be gone with this commit:  https://github.com/hashcat/hashcat/commit/d2e95d5e1b7e15f3d06407aaca2a7bf251b7012a\nHowever you need to recreate the hccapx with latest cap2hccapx or from online site. Thanks for reporting. Please provide all information stated here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this. No response from OP for some time plus the request itself doesn't make much sense. Feel free to reopen in case you provide the missing informations.. Please use the hashcat forum. There was actually a bug, I've fixed it with: https://github.com/hashcat/hashcat/commit/c47f9d4b3eddd25b79dee6e9562c4c9b2cd8fc03\nHowever, there was another bug reported here: https://github.com/hashcat/hashcat/issues/1137\nWhich requires a code change which can affect reuse PBKDF2 intermediate keys cracking performance but ONLY for a short time and ONLY if it's cracking the first of N handshake with the same ESSID, which is a very rare event in real life cases. If it's not cracking, performance is not changed. See here:\n1 handshake:\n$ echo -n hashcat1 | tools/test.pl passthrough 2500 | base64 -d > test.hccapx \n$ ./hashcat -m 2500 test.hccapx -w 3 opencrack_plains.txt\nStatus...........: Exhausted\nTime.Started.....: Tue Feb 28 10:03:37 2017 (43 secs)\n2 handshake:\n$ echo -n hashcat1 | tools/test.pl passthrough 2500 | base64 -d >> test.hccapx \n$ ./hashcat -m 2500 test.hccapx -w 3 opencrack_plains.txt\nStatus...........: Exhausted\nTime.Started.....: Tue Feb 28 10:05:23 2017 (42 secs)\nPlease test the bugfix and close the issue if fixed.. Did you test with non-cracking handshakes?\nAm 28.02.2017 10:30 vorm. schrieb \"ZerBea\" notifications@github.com:\n\nNot fixed using v3.30-374-gc47f9d4b\nSpeed.Dev.#1 https://github.com/hashcat/hashcat/issues/1.....: 166.9\nkH/s (4.88ms)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1141#issuecomment-282988333,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OXU6htaq76IOPKz7gWm17e_qgZ1Tks5rg-kdgaJpZM4MOHFO\n.\n. I think the ETA is just invalid for a short time (when it's cracking a\nhandshake). Can you please try to do a full run and measure time it\nactually takes?\n\nOn 28.02.2017 10:56, ZerBea wrote:\n\nYes, and no....\nOk. If there are non-cracking hashes inside, it works like you mentioned.\nBut if there is only 1 cracked hash inside, speed will drop and stay\non this level......\nLet's say, you af 100 different ap's, using the same essid called\n\"default\".\nThe used word list is about 1 GB.\nThe password for ten ap's is them same \"12345678\"\nSpeed drops from 10 minutes to a day.....\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1141#issuecomment-282994653,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OTgOco_08lU6fvLX-Qjx4W24btneks5rg-9bgaJpZM4MOHFO.\n\n\n. Yeah but that's ok because most of the time you don't really crack something. Also this is a fixed time added for each crack. That means if you do a crack in the first minute but there's still 3 hours to crack, it will only take 3 hours not 3 hours +X. I think that's ok or?. Please retry with commit https://github.com/hashcat/hashcat/commit/5f7c3590bab4ebae508443188ca2383997f1a14b. Thanks!. OK, should be fixed with https://github.com/hashcat/hashcat/commit/6b77606bdd71a39dec48f78db7bce1457eeb5cab\nNew beta is up. Please test and close the issue if fixed. Thanks for reporting!. @alaneuler see @magnumripper comment, that's the way to go.. Yes, please post on forum, doesn't sound like a bug from the description. hopefully will be fixed soon. I've tried to reproduce locally but can't. It cracks the first hash much sooner, that's right, but in the end both were cracked. \n```\nroot@et:~/xy/hashcat-3.40# ./hashcat64.bin -m 2500 test_new.hccapx -a 3 ?d?d?d?d?d?d?d?d -w 3\nhashcat (v3.40) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2026/8107 MB allocatable, 20MCU\nDevice #2: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\nDevice #3: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\nDevice #4: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #5: Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, skipped\n\nHashes: 2 digests; 2 unique digests, 2 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Brute-Force\n* Slow-Hash-SIMD\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\n3bc509f17d95e2fc515244b1a1c15003:4cf2bf2a4c94:44636afbbe9e:WiFi-29:00000995\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: test_new.hccapx\nTime.Started.....: Tue Mar  7 08:42:19 2017 (28 secs)\nTime.Estimated...: Tue Mar  7 08:43:11 2017 (24 secs)\nInput.Mask.......: ?d?d?d?d?d?d?d?d [8]\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   717.0 kH/s (96.09ms)\nSpeed.Dev.#2.....:   645.6 kH/s (51.03ms)\nSpeed.Dev.#3.....:   718.9 kH/s (94.78ms)\nSpeed.Dev.#4.....:   694.4 kH/s (95.27ms)\nSpeed.Dev.#*.....:  2775.9 kH/s\nRecovered........: 1/2 (50.00%) Digests, 1/2 (50.00%) Salts\nProgress.........: 80773120/200000000 (40.39%)\nRejected.........: 0/80773120 (0.00%)\nRestore.Point....: 819200/10000000 (8.19%)\nCandidates.#1....: 02185695 -> 06175027\nCandidates.#2....: 62630196 -> 66194796\nCandidates.#3....: 42194796 -> 46147432\nCandidates.#4....: 12147432 -> 16185695\nHWMon.Dev.#1.....: Temp: 54c Fan: 33% Util:100% Core:1809MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#2.....: Temp: 59c Fan: 33% Util: 99% Core:1797MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#3.....: Temp: 54c Fan: 33% Util:100% Core:1822MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#4.....: Temp: 60c Fan: 33% Util:100% Core:1809MHz Mem:4513MHz Lanes:1\nINFO: approaching final keyspace, workload adjusted       \n62c53e18a34a39ea1a5f6f417709c20a:4cf2bf2a4c94:44636afbbe9e:WiFi-29:00000994\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: test_new.hccapx\nTime.Started.....: Tue Mar  7 08:42:19 2017 (57 secs)\nTime.Estimated...: Tue Mar  7 08:43:16 2017 (0 secs)\nInput.Mask.......: ?d?d?d?d?d?d?d?d [8]\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   559.9 kH/s (73.69ms)\nSpeed.Dev.#2.....:   519.7 kH/s (51.69ms)\nSpeed.Dev.#3.....:   549.9 kH/s (77.40ms)\nSpeed.Dev.#4.....:   546.9 kH/s (97.24ms)\nSpeed.Dev.#*.....:  2176.4 kH/s\nRecovered........: 2/2 (100.00%) Digests, 2/2 (100.00%) Salts\nProgress.........: 164374720/200000000 (82.19%)\nRejected.........: 0/164374720 (0.00%)\nRestore.Point....: 3768320/10000000 (37.68%)\nCandidates.#1....: 72851946 -> 76309217\nCandidates.#2....: 82175027 -> 86901635\nCandidates.#3....: 02689217 -> 06691484\nCandidates.#4....: 02801635 -> 06921946\nHWMon.Dev.#1.....: Temp: 64c Fan: 33% Util:100% Core:1784MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#2.....: Temp: 69c Fan: 33% Util:100% Core:1771MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#3.....: Temp: 63c Fan: 33% Util:100% Core:1797MHz Mem:4513MHz Lanes:1\nHWMon.Dev.#4.....: Temp: 70c Fan: 38% Util:100% Core:1771MHz Mem:4513MHz Lanes:1\n```\nPlease post hashcat -I and the full commandline you're using. Maybe I then have better chances to reproduce.. Note I've just updated some of the WPA handling with this commit: https://github.com/hashcat/hashcat/commit/33a043ec63e65c5a497a73100d7243eda040fb86\nThere's also a precompiled beta on here: https://hashcat.net/beta/\nPlease retry with this latest version. Thanks for reporting. As @philsmd already mentioned, this is kind of irrelevant for users. It's only part of the potfile because it's required to mark the right handshakes as cracked when hashcat is starting up or in case the user uses --show or --left. However from a user perspective it shouldn't be important. The hash bases on MD5, but it's no a true MD5 because for our usecase it's good enough as it is now. If you really need to copy the procedure, simply copy the code out of interface.c and save yourself alot of headache.. The most important question: Where is it used in?. It's working as expected, see here:\nRejected.........: 1/1 (100.00%)\nYour input word was < length 8, so it's rejected because of WPA minimum length 8. If you want the behaviour the different way, like after rule to check apply to check for length 8 you need to use a pipe and run the first hashcat instance in --stdout mode.. The more modifier you use, the longer it takes to reach a checkpoint. That's true for both fast and slow hashes.. Looks legit to me, if the keyspace is too small then the speed drops. I'm sorry but since you did not add any additional information to clarify the situation there's nothing we can do.. Thanks, makes this easier to read. I'm not 100% certain, but the command \"-p *\" might cause your shell to incorrectly expand the command to something different and results in creating stuff like \"docs\" and \"charset\" to be a treated as a hashlist. Opening a folder as a file sometimes creates that typical invalid error message \"Permission denied\" produced by windows, which then leads to the false assumption this is something related to filesystem ACL's. IOW, remove the -p parameter and try again.\n. OP not responding plus I'm kind of sure it the problem is the -p usage error, therefore closing. Feel free to reopen if that wasn't the case.. Fixed with https://github.com/hashcat/hashcat/commit/963a9772ba532f8c6895a342ea443efd27f5b1a2\nThanks for reporting!. Please use something like: \ncat folder/*.rule > mega.rule\n. > It would be really beneficial to have an option to test commands (e.g. --test) and/or hashes instead of waiting for exception to be raised.\nHashcat is not starting up in case there's fundamental errors.\n\n\nChecking for existence and permissions of all required files and directories (both the ones specified on the command line, and the default/assumed ones)\n\n\nMaybe you missed it, but that already happend with hashcat v3.40: https://github.com/hashcat/hashcat/blob/master/docs/changes.txt#L115\n\n\nWhether or not the combinations of command line options and flags are compatible and sane\n\n\nAlready done on startup\n\n\nWhether or not the hashes in the file are the expected length and composition (I would like to have the default behavior be that as soon as a single hash is seen as obviously incorrect, the entire run aborts instead of trying to continue to load them all, and to have this check happen quickly up front instead of after all hashes are loaded, deduped, sorted, etc.)\n\n\nAlready done on startup\n\n\nIt would also be useful for an early rough guess for resources on the target platform.\n\n\nAlready done on startup\n\nTBH issues like this make me really angry. . Feel free to provide some example where hashcat can do something better and reopen the issue. No sorry, that would look kind of bloated. We already had such options in the past (not exactly those, but similar) to shutdown hashcat in case XY occurs and made some experience with them. They were mostly based on cracks-per-time but also time in general. It turned out that such options make sense only for a very few cases, like cracking LI or other mass data. In the real life when we only have to crack a single TrueCrypt volume it created more problems because users misused the flags. It raised lots of support questions that we wouldn't have to deal with if there are no such options, therefore we dropped them.. No response from OP after long time, therefore closing the issue. Feel free to reopen if needed.. I can see the problem with -a bogus (which atoi() translates to 0), but I can not reproduce the case with -a 9:\nroot@ht:~/hashcat# ./hashcat -m 100 -a 9 hash.txt\nInvalid attack-mode specified. Double post, please use: https://github.com/hashcat/hashcat/issues/371. I've pushed this with https://github.com/hashcat/hashcat/commit/6d66ff96c16992d32aa7fedc51e9b0cdf7ed19ae\nI've also remove 2x \".\" from the status labels, otherwise it wouldn't make much sense to compress the hash to length 79 and the HWmon line is still at 81.\nI've written a special function to do the compress in case we want to use it on a different place, too.\nPlease close the issue if fixed. I can only agree, very good description. If only all requests would look like that. Please test the implementation and close the issue if fixed.. Sounds like a complete misuse of hashcat. If you want to see only cracked hashes, use an outfile. If you need it as a stream, run tail -f on it. About the issue itself, I'll add an exception for special devices like /dev/null for outfiles.. Changed with commit: https://github.com/hashcat/hashcat/commit/c3e118f5ea1a67b6cf28db278ef0d86362d101da\nPlease close the issue if fixed. Thanks for reporting!. OpenCL installation error. Please ask on forum or see here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do. Style is acceptable. I've also added the short links to nginx.conf. Thanks!. While I was trying to implement this I've run into two major problems that needs to be discussed first. \n\n\nThe first problem is that hashcat is also available as a library. That means after executing hashcat_init() (done only one time) there is an unknown number of subsequent calls to hashcat_session_init() following. Reason here is because the hashcat_init() initializes the for example the OpenCL subsystem which doesn't change while the calling process lives, but it can also take some time to initialize, depending on the devices and runtimes. The main time is of course the hashcat_session_init() but I wanted to show that there's different layer types that both can create some time to execute but the given example output does not reflect that.\n\n\nThe second problem is that hashcat (both binary and library) support Queues that are used whenever the user chooses wordlist folders, mask files, the -i switch, etc. This adds another 4 more layers to the system (init, outer loop, inner loop 1, inner loop 2). Each of those layers can call time consuming functions. For example the outer loop initializes the hashes itself and everything that depends on the hashes like potfile comparisons and bitmaps, OpenCL kernels and weak hash check. in inner loop2 it runs the autotune and the final cracking loop. The given example output does not reflect that as well.\n\n\nAnd then there's another minor question: Do we want to export the values to hashcat_status_t or just to status_ctx_t? The hashcat_status_t is the \"normalized\" structure that can be used from the user API but it really creates more work.\n@roycewilliams The original request needs to be rewritten with respect due to the different layers. Any Idea?. I think @philsmd explained what to do. Since it turned out to be a usage issue and not a bug, please continue the discussion on hashcat forum. Github issues is only for bugs and feature requests.. Why run hashcat as binary, call the library instead.. There's no documentation in text form, but there's two examples in code. The first one that the hashcat binary itself is using the library, therefore everything the binary can do can be done from your application, too. See the main.c file for details and set the SHARED variable in Makefile. The other example is pyhashcat here: https://github.com/Rich5/pyHashcat. Many thanks!. OK, we should do that\nOn 05.04.2017 20:27, magnum wrote:\n\nI'm writing this as an issue instead of a patch because we might disagree.\nIn my humble opinion, |make clean| should absolutely not destroy any\npot files or session files. Instead, they should be listed in\n.gitignore so they don't turn up in eg. |git status| or accidentally\nget added in a commit.\nIf you really want to, you could have an alternative target |make\ndistclean| that actually does destroy such files, but in the world of\ngit it's not really needed. For example, you'd better create archives\n(eg. tar balls) using |git archive| instead of a \"manual\" zip command.\nThe former will never include anything not actually in the git tree.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1218, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OfspmSp6NCI5-Ad48whPGyf7tb3Rks5rs90GgaJpZM4M0ohk.\n\n\n. The .induct and .outfiles are temporary files which are no longer valid after the session terminates. We should clean them.. Just make the wordlist larger and you will get full speed. If you want to stick to a small wordlist you need to pipe, like:\nhashcat64 -a 6 dictionary.dict.txt ?a?a?a --stdout | hashcat64 -D 2 -m 11300 wallet.hash.dos  --status --status-timer 1\n. thanks!. You can debug a kernel using printf() in case you have a nvidia GPU.\nThere's a few things you should do additionally:\n\n\nSet DEBUG mode to 1 in Makefile\n\n\nRun you test with -u1 -n1 --force (this is a special condition that\nwill disable the autotuner which otherwise would confuse printf output)\n\n\nAdditionally use -d 1 in case you have multiple GPU\n\n\nUse --weak-hash-check 0 (also to reduce confusion of printf output)\n\n\nIn case you have an AMD GPU you need need to force hashcat to use the\nJiT kernel without caching, otherwise printf() fails. Find the line that\nsays:\nopencl_ctx->force_jit_compilation = -1;\nIn the opencl.c source and replace the -1 with your kernel number (600).\nOn 18.04.2017 04:18, DoZ10 wrote:\n\nOk might have found a way to tshoot this. All GPU debuggers failed on\nmy Ubuntu system, but I could probably return values in buffers of\nmark() call. Will look at this tomorrow.\nWhat you guys use for debugging ?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1226#issuecomment-294653082,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OSKZ0-yTArWUreRJcDv13D-pjlwFks5rxB1ggaJpZM4M-qXQ.\n. \nI don't know much about the feature of blake2b, but it seems it has some sort of built-in salting support. If that's the case, then the hash format need to have each salt somehow stored along with each hash. From your example hash, it doesn't seem to do so. \n\nOTOH, hashcats hash formats/encoding traditionally tries to stay compatible to jtrs. Since jtr already supports blake2b we should make the format 1:1 to the the one from jtr. That will also give a good inspiration about how to configure the different blake2b features (per hash).\nHere are some more things that looks suspicious in your code:\n\nThis can not be true if the hash is salted: \n\nhashconfig->salt_type      = SALT_TYPE_NONE;\n\nThis function seem to be just byte swaps:\n\nu64 load64(const void *src)\nu64 load64_reverse(const void *src)\nThere's swap64() in OpenCL/inc_common.h maybe you find a way to simply replace them with our functions.\n\nTry to avoid void * in the kernel, that is compatible to all OpenCL runtimes:\n\nu64 load64(const void *src)\n\nThis function seem is simple bit rotate:\n\n+u64 rotr64_w(const u64x w, const u32 c)\nWe already have rotr64() in the types.h. Please try to replace it, too.\nAbout your questions:\n\nFinally, a quick description of m04, m08 and m16 funcs ? Do they relate to different input dimensions or kernel threads dimensions ?\n\nthe \"m\" stands for multiple hashes, where \"s\" stands for single hash. With a single hash, we can do a single integer comparison at the end ofthe kernel, while with \"m\" the kernel has to run through a bloom filter and some binary tree. For you it's not so important, it basically the same code, but because of performance reasons it's not implemented in form of a branch. Just take a look at any other fast hash kernel, for example md5. The only different is that you do not have a search[] array and the COMPARE_S_SIMD() is replaced with COMPARE_M_SIMD().\n\nAlso, I am using the right params for the right kernel purpose or did I hack something in a useless way ? (I am not talking about optimizing my own code, but rather if I am using the right kernel parameters/macros/structs/functions.).\n\nI can't say too much about that as long as you do not full make use of the blake2 features because this changes some stuff in the code, you will find out when you do.\nAlso feel free to join #hashcat on freenode in case you need direct help. Please get test.sh and test.pl working first, it's important for tests\nOn 23.04.2017 14:22, DoZ10 wrote:\n\nOkay there is a problem with test.pl... will have to fix this first.\nIf anything else to look at comes to mind, please let me know.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1226#issuecomment-296439564,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OUhTp-z3tTcpM2fWwOppCQCTmIYDks5ry0KcgaJpZM4M-qXQ.\n\n\n. I can't check the test.pl unless the conflict is resolved. However, here's at least one odd thing i saw by watching the source:\nblake2b_compress(pw, pw_len, digest);\npw_len should be out_len for -a 0 kernel.\n. I've tested all modes (0, 1, 3, 6, 7) and they seem to work fine on the tested systems:\n\nnv 750ti\namd rx 480\namd r9 290x\n\nSome notes:\n\nIt would be nice to have a blake2b_transform function for _a0 and _a1 instead of having the code embedded into the most inner loop. reason here is that we need it in case we need to transport it to a new hash mode (one that is using blake2 interal, ex: pbkdf2-hmac-blake2b) -- Ignore this it already exist!\nFor this reason (1) it would be nice to have the salt and pepper supported by the function. Even for mode 600 we should use this function without suffering for performance drop, because the compiler are clever enough to recognize that the \"faked\" initial buffer we are all set to zero.\nI've noted that you use the vector-datatypes for the blake2b_state structure only in hash mode 0, but not in mode 1 and 3, example: --> u64x h[8]; in a0, u64 h[8]; in a1\nThe same for the blake2b_param struct, but here it makes sense, because we always handle the same salt within a single call of the kernel and therefore3 the parameters must be the same for all password candidates. therefore you should switch those to the scalar types, not the vector types\nFor performance reason you can try to move the blake2b_sigma[] array into the inner kernel as fixed data block, maybe it gives you a performance increase\nplease unroll the following section and do the assigns by hand:\n\nS->h[i] ^= *((u64x*)(p + sizeof(S->h[i]) * i));\n\nP->digest_length seems to be unused. I'm not familar with blake2b, is this some kind of feature like it is in pbkdf2 where you can specify a desired output length? However it seems not to be used, maybe you want to create blake2b_param_optimized structure instead and remove all the unneccessary elements\nIf you do not use a structure to hold the state but only the elements from it as single integer arrays you help the compiler because it does not require to hold the data in that particular order, its faster\nFor our source code convention, please replace code like this:\n\nu32 i;\n  ...\n  for (i = 0; i < 8; ++i)\nwith this:\nfor (int i = 0; i < 8; i++)\nIt's easier to read\n\nThis one looks suspicious:\n\nm[i] = swap32(pw[i * 2]);\n    m[i] <<= 32;\n    m[i] |= swap32(pw[i * 2 + 1]);\nI guess what you want to use instead is this:\nhl32_to_64() see OpenCL/inc_types.h\n\nPlease unroll this section by hand:\n\nfor (i = 0; i < 8; ++i)\n    v[i] = S->h[i];\nPlease do the above, then it will be easier for me to understand the code and to start debugging\n. If you take a look below, v[8] .. v[15] is initially set, too.\n```\nv[ 8] = blake2b_IV[0];\n v[ 9] = blake2b_IV[1];\n v[10] = blake2b_IV[2];\n v[11] = blake2b_IV[3];\n v[12] = blake2b_IV[4] ^ S->t[0];\n v[13] = blake2b_IV[5] ^ S->t[1];\n v[14] = blake2b_IV[6] ^ S->f[0];\n v[15] = blake2b_IV[7] ^ S->f[1];\n```\nIf everything is aligned in a picture-like format we have a clear visual\nrepresentation of how the algorithm organizes its data and how its\nstructured. This helps to better understand the algorithm in case we\nwant to optimize it afterwards\nOn 26.04.2017 10:27, magnum wrote:\n\n11. Please unroll this section by hand:\n\n|for (i = 0; i < 8; ++i) v[i] = S->h[i]; |\n\nWhy would you want things like that manually unrolled? Just curious.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1226#issuecomment-297288936,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83Oc8GjkUd-crzsIQKX8g-B30lcGMOks5rzv_3gaJpZM4M-qXQ.\n\n\n. \nSome (not so important) leftovers:\n\nThere's still some leftovers of \"blake2b_compress\", and \"blake2b_transform\" - Please make it \"transform\" everyhwere\nIs the vector cracking working now?\nHave you tried moving the blake2b_sigma to the inside of the kernel and compared if this gives a speed boost?\nYou can also try copying esalt_bufs->h[] to a local variable outside the inner loop, this way the innerloop does not need to try to access the global memory for each iteration. compare performance afterwards  but it's possible the compiler already auto-optimized it for you. either way you should do it. Same for t[] and f[]\nWhat's the reason for having blake2 as cpu function? I mean it's good to have it, just wondering what's the background\nIn case we want to have Blake2-256, what do we need to change? Simply truncate the output or is it more complex?\nThis section in the parser:\n\nfor (u8 i = 0; i < sizeof(blake2_params_t); i++)\n    ((u8 *)S)[i] ^= ((u8 *)P)[i];\nIs it really required to use a cast here? I'd prefer to see each attribute xor in a single for () loop. This greatly helps understand why we do this because it propably shows which values are set to zero at this point.\n\nAs you can see here:\n\ncase   600: hashconfig->esalt_size = sizeof (blake2_state_t);   break;\n    case  2500: hashconfig->esalt_size = sizeof (wpa_t);            break;\nThe convention of the type is always XXX_t. Can you please rename blake2_state_t to blake2_t\n. 9. One more thing. When running the benchmarks it shows:\nHashtype: Blake2b\nBut shouldn't it be Blake2b-512 or so?\n. Sometime, in the kernel, you use:\nfor (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE) \n{\nfor (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE) {\nThe latter is correct.. \nI think we're almost done. Here's some missing pieces left:\n\nPlease add mode 600 to extra/tab_completion/hashcat.sh to the HASH_MODES variable\nPlease add note about addition to docs/changes.txt\nFix following formating in the parser:\n\n```\n  blake2_t  S = (blake2_t ) hash_buf->esalt;\nmemset(S,  0, sizeof(blake2_t));\n```\nto:\n```\n  blake2_t S = (blake2_t ) hash_buf->esalt;\nmemset (S, 0, sizeof (blake2_t));\n```\n\nFix following formating in the parser:\n\nS->h[0] ^= 0x0000000001010040; // digest_lenght = 0x40, depth = 0x01, fanout = 0x01\nto:\nS->h[0] ^= 0x40 << 0; // digest_lenght = 0x40\n  S->h[0] ^= 0x01 << 4; // depth = 0x01\n  S->h[0] ^= 0x01 << 6; // fanout = 0x01\nBeware! Please verify I understood the positioning and comment correctly\n\nPlease do a global search on the substring \"Blake2\" - I think we should name it Blake2b. For example here in usage.c it says:\n\n\"    600 | Blake2-512                                       | Raw Hash\",\nBut maybe this is not neccessary, I just don't know what's the difference between Blake2 and Blake2b. You have to decide.\n\nSome notes:\n\nI've tested with test.sh and it worked for me as well. I've tested with AMD, NV and Intel. \nI've also added a default hash to wiki example hashes.\nThis is really great work!\n. I was playing a bit with the data you provided. Some notes:\n\nThe example hash \"$ethereum$p262144ae3cd4e7013836...\" provided does not crack with password \"testpassword\", at least not with JtR's mode (latest github master).\nThe AES part is not needed at all, neither in PBKDF2 nor in SCRYPT mode\nWe will need to rewrite the keccak GPU implementation to get this to work\n\nBy assuming the keccak part will be so fast that it doesn't change the cracking speed, the only relevant slowdown is the PBKDF2. I've tested this to run to approx. 4430 H/s on a single GTX1080. I was playing a bit with the data you provided. Some notes:\n\n\nThe AES part is not needed at all, neither in PBKDF2 nor in SCRYPT mode\n\nWe will need to rewrite the keccak GPU implementation to get this to work\nGPU's will not be able to crack this because of the memory requirement. Math behind: Mem per candidate: size_scrypt = (128 * scrypt_r) * scrypt_N = 256MB. But to make use of the GPU power, we need to spawn at least 1280 parallel computations, so we end up with a memory requirement of 320GB ram per GPU. It would require a minimum of a 256 divisions TMTO to get it working on a GTX1080, which drops the performance < 1 H/s.\nCPU cracking will run fine, tho. By assuming the keccak part will be so fast that it doesn't change the cracking speed, the only relevant slowdown is the SCRYPT. I've tested this to run to approx. 12-13 H/s on my 4770k. That is ~20% faster than JtRs native SCRYPT CPU code.\n. Yes\n\nAm 03.06.2017 4:20 nachm. schrieb \"ethtester\" notifications@github.com:\n\n@jsteube https://github.com/jsteube Thanks for the update. Is that\n12-13H/s achieved by using all 4 cores of the 4770k?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1228#issuecomment-305977893,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OdqizQ6yKreTJ0RjdC9QKUTPlBYiks5sAWuxgaJpZM4M-v3Y\n.\n. Yes. Note that Ethereum default is 256k:1:8 and not 256k:8:1. That may explain the difference between 17H/s and 13H/s. When I run JtR against a 1k Wordlist on my 4770k it takes 1m22s with 256k:1:8, but 1m12s with 256k:8:1. So that would be \"only\" 12H/s but there's some startup time involved that should be subtracted so I think 13H/s is correct for JtR. Also note that I am using MPI (mpirun -n 8) - not OpenMP. From my experience with JtR, MPI gives the best performance (it may be different with SCRYPT based algorithms). As a comparison, hashcat takes 1m18s to process the same system, same wordlist and the same hash. That is almost on par with JtR performance. \n\nThe reason why I wrote hashcat was ~20% (it was actually ~40% but I didn't want to overact because it was not fully finished) is because I compared hashcat performance when I was in the middle of the development and compared only the SCRYPT part but without the surrounding PBKDF2 and the Keccak round. From my perspective that was ok, because on GPU the PBKDF2 in SCRYPT (and in this case also including the raw Keccak round) take about no time compared to the SCRYPT part, I didn't even come on the idea it will be different on CPU. The same list was processed in only 57s. I think the large data part (1k of data) is it that bloats up the PBKDF2 around the SCRYPT.. There's too many unknown factors to make an estimation.. Yeah but then where's the advantage to cracking on CPU? The GPU is faster only because there's so many \"small\" CPU that can run in parallel.. Do you think we need to update parser code? /cc @Chick3nman. OK, please create a separate issue for this. That is because GPU are fast only when utilizing all of it's compute hardware in parallel. For todays AMD and NV GPU that is 64 threads per compute unit. For the GTX1080 example above: 1280 / 64 = 20, which is the number of compute units on a GTX1080. You can exchange this number with the number of compute units on your GPU. An alternative to this would be to not fulfil the threads minimum per compute unit but then you'd end up with an almost equal number of parallel computations as you have it on a CPU (my Ryzen 1700 for example shows 16 CPUs cores) and the advantage of a GPU is gone. Even worse since a CPU has much more advanced instructions that a GPU compute unit.. works fine for me:\nroot@et:~/hashcat# ./hashcat -m 15700 hash.txt -a 3 'P@ssw0rd1!' --quiet -D1 --self-test-disable\n$ethereum$s*1024*8*1*437964c9bd1b5f63bde56560808c894792f8f670694590b776e22381e32dd33b*7f5c865554d67604394ae54d7a4f9735bdb85c90e606a672d18add1d167d793b*96f2a849321cc04cb6c0fcee1bd4b195ca681ca28064dc45000f02e47230c5b6:P@ssw0rd1!\nroot@et:~/hashcat#. Should be fixed with commit https://github.com/hashcat/hashcat/commit/a93a143d1e2820e2fae5da11e4a9b3292d09e690\nPlease close if fixed. Thanks for reporting!. As @roycewilliams explained, this is a question for hashcat forums.. Yes that's a feature, it's actually the only feature why there's 9820 at all. The goal is to find as many colliding passwords as possible to use them for reuse cases. That's why it's never stopping once it has found a collision. I think what you're looking for is simply -m 9800. I tried on linux with all kind of strange utf-8 characters, seems to works. So it's perhaps the zero byte in the utf-16 causing the problems.. Since windows installations do not make use of \"make install\" we can switch back on windows to relative paths. I've pushed a fix for this issue with commit https://github.com/hashcat/hashcat/commit/8ec2af97ed6adeae0dab0cb479f13cdf3e2b0031\nI've also add a new beta to https://hashcat.net/beta/\nPlease test if the issue is fixed and close it. Thanks!. Nice, IIRC, the first contribution that adds a new rule function. Thanks!. IOS 10 needs 40,000,000 calls to sha1_transform and then followed by another 40,000 calls to sha1_transform. \nTo get 2348 H/s it means your CPU would need to do 94,013,920,000 H/s on raw sha1 which I find impossible.\nIt's much more likely what @roycewilliams commented, here's a benchmark of older IOS on CPU:\n```\n* Device #5: Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, 3999/15998 MB allocatable, 8MCU\nHashtype: iTunes backup < 10.0\nSpeed.Dev.#5.....:     5480 H/s (74.28ms)\n```\n@recon-ng There's no way to improve the attack as it is now, because it's simply PBKDF2 and we already have optimized it to the maximum. It's more likely the attack you're linking to does not use that PBKDF2 step2 and in this case we'd need what to do else and create a new hash mode. However, as @magnumripper mentioned, that bug is already fixed in IOS 10.1 so it wont help us much. \nFinally, we have to live with how stuff is.. Again, great contributions! Many thanks so far! Here are some comments:\n\nkernel code quality is very good, but maybe add some \"salt\" section to the initialization code by simply commenting it\n\n+  u32 iv[2]    = { 0 };\n+  u32 plain[2] = { 0 };\n+  u32 position[2] = { 0 };\n+ \n+  position[0] = esalt_bufs->position[0];\n+  position[1] = esalt_bufs->position[1];\n+\n+  u32 plain_length = esalt_bufs->plain_length;\n+\n+  iv[0] = esalt_bufs->iv[0];\n+  iv[1] = esalt_bufs->iv[1];\n+\n+  plain[0] = esalt_bufs->plain[0];\n+  plain[1] = esalt_bufs->plain[1];\n\n\nWhat's the reason to have a \"plain_length\" in the esalt? Isn't this a block cipher?\n\n\nIn the chacha20_parse_hash(), can you add some length verification checks to ensure iv length is actually 16. The best way to accomplish that is by using the code as we do it, for example see the itunes_backup_parse_hash() function. You will find out pretty easily the pattern and you will see how we do the tests for length.\n\n\nThe algorithm makes use of an esalt, but misses to set an artificial salt. While this is not a technical requirement, it's more a requirement of hashcat itself. In order to help hashcat to identify duplicate salts we have to create a unique (artificial) salt for each unique esalt. See pstoken_parse_hash() for example. I think it would be fine simply to copy all data from the esalt data into salt_buf[] array and set the salt_length to 32 or so-\n\n\nMost important. Please do not use mode 670. Please use mode 15400 instead. \n. \n\nPlease replace this:\n\nfor (u8 i = 0; i < 10; ++i)\nwith this:\nfor (u8 i = 0; i < 10; i++)\n\nPrepend for() loops with a fixed iteration count with #pragma unroll\n\nfor (u8 i = 0; i < 10; i++)\nto:\n```\n  #pragma unroll\n  for (u8 i = 0; i < 10; i++)\n```\n\n\nDrop w2[] and w3[] in the inner loop, they are not accessed\n\n\nLoad the base word outside the inner loop, that saves accessing the slow global memory, ex:\n\n\noutside:\n```\n  u32 w0[4];\n  u32 w1[4];\nw0[0] = pws[gid].i[0];\n  w0[1] = pws[gid].i[1];\n  w0[2] = pws[gid].i[2];\n  w0[3] = pws[gid].i[3];\n  w1[0] = pws[gid].i[4];\n  w1[1] = pws[gid].i[5];\n  w1[2] = pws[gid].i[6];\n  w1[3] = pws[gid].i[7];\n```\ninside (replace):\n```\n    u32x w0_t[4];\n    u32x w1_t[4];\nw0_t[0] = w0x;\nw0_t[1] = w0[1];\nw0_t[2] = w0[2];\nw0_t[3] = w0[3];\nw1_t[0] = w1[0];\nw1_t[1] = w1[1];\nw1_t[2] = w1[2];\nw1_t[3] = w1[3];\n...\nchacha20_transform (w0_t, w1_t, position, offset, iv, plain, digest);\n\n```\n. \n1. There's still remainings of this in the single hash kernels. \nposition[0] = esalt_bufs->position[0];\n  position[1] = esalt_bufs->position[1];\nEven if this is always just \"0\" please rewrite it, too. That makes it easier to copy/paste. It will have no impact on performance.\nposition[0] = esalt_bufs[digests_offset].position[0];\n  position[1] = esalt_bufs[digests_offset].position[1];\n\n\nHash mode 15400 is missing in extra/tab_completion/hashcat.sh in HASH_MODES variable\n\n\nTry to use more \"const\" keywords whenever possible, for example:\n\n\nu32 index  = offset / 4;\n  u32 remain = offset % 4;\nto:\nconst u32 index  = offset / 4;\n  const u32 remain = offset % 4;\n\nPlease fix alignment for spaces:\n\nu32 iv[2]    = { 0 };\n  u32 plain[2] = { 0 };\n  u32 position[2] = { 0 };\n  u32 offset = 0;\n\nThose do not need to be u32x in the outer loop, u32 is fine and saves some register:\n\nu32x w0[4];\n  u32x w1[4];\n  u32x w2[4];\n  u32x w3[4];\n\nThe tmp variable can be u32, no need to u32x here:\n\nu32x tmp[3];\n. Great work again! Many thanks!. Nice work. This really looks interessting for the pentesting community. Here some comments:\n\nPlease do not use char in a shared structure datatype (shared between host code an GPU code). Please use only u8, u16, u32 and u64.\n\n+  char cipher_algo[16];\n+  char hash_algo[16];\nTry to replace with u8 also in ascii_digest ()\n\n\nNote that whenever you use u8, the performance drops massively as GPU do not have 8 bit registers as CPU have. That's why you should try to always use u32. If you can rewrite your code so that it does not need to work with u8 you will increase the performance alot.\n\n\nWhat is the reason to have the password (userKey[]) in the tmps variable?\n\n\n+  u32 userKey[5];\nIf possible, please remove that. You should be able to access the password from within _loop() and _comp() kernels the same way as in _init().\n\nPlease align the following code. I tried to do it for you but then saw that there's a value missing:\n\n+  DISPLAY_LEN_MIN_15300 =  1 + 7 + 1 + 1 + 1 + 1 + 1 + 10 + 1 + 4 + 1 + 4 + 1 + 1 + 1 + 32 + 1 + 3 + 128,\n+  DISPLAY_LEN_MAX_15300 =  1 + 7 + 1 + 1 + 1 + 1 + 1 + 100 + 1 + 6 + 1 + 6 + 1 + 10 + 1 + 32 + 1 + 4 + 1 + 512,\nto (please find the ? mark):\n+  DISPLAY_LEN_MIN_15300 =  1 + 7 + 1 + 1 + 1 + 1 + 1 +  10 + 1 + 4 + 1 + 4 + 1 +  1 + 1 + 32 + 1 + 3 + ? + 128,\n+  DISPLAY_LEN_MAX_15300 =  1 + 7 + 1 + 1 + 1 + 1 + 1 + 100 + 1 + 6 + 1 + 6 + 1 + 10 + 1 + 32 + 1 + 4 + 1 + 512,\n\nIn the dpapimk_parse_hash() section, please move all converter code below the parser code. So for example this:\n\n+  cipher_algo_pos = (u8 *) strchr ((const char *) SID_pos, '*');\n+\n+  if (cipher_algo_pos == NULL) return (PARSER_SEPARATOR_UNMATCHED);\n+\n+  for (int i = 0; i < cipher_algo_pos - SID_pos; i++)\n+    dpapimk->SID_tmp[i] = SID_pos[i];\n+  dpapimk->SID_tmp[cipher_algo_pos - SID_pos] = '\\0';\nShoudl be limited to :\n+  cipher_algo_pos = (u8 *) strchr ((const char *) SID_pos, '*');\n+\n+  if (cipher_algo_pos == NULL) return (PARSER_SEPARATOR_UNMATCHED);\nAnd later, once you have did all the parsing and testing (for correct length) code do the converts.\n\nArtifical salt section:\n\n+  salt->salt_buf[0] = dpapimk->iv[0];\n+  salt->salt_buf[1] = dpapimk->iv[1];\n+  salt->salt_buf[2] = dpapimk->iv[2];\n+  salt->salt_buf[3] = dpapimk->iv[3];\n+\n+  salt->salt_len = 32;\nThis could lead to problems (in case you had an invalid hash parser before). If you set only 16 byte, set the salt_len to 16, not 32. Or set really 32 byte in salt_buf[]\n\nPlease replace all occurances of '\\0' with simply 0\n\n. Great work, thanks!. @magnumripper do you know how to reproduce such an archive locally? How much was the speed drop?. If there's no other disadvantage caused by this, we can drop the\nearly-reject based on the padding\nOn 17 May 2017 at 08:26, philsmd notifications@github.com wrote:\n\nit would be very great and helpful in the decision making if we discover\nsome way on how .7z files like this can be generated (i.e. with a\ntool/archiver or sdk etc) and how wide-spread/rare they are. Maybe even\nmore details like if the padding is really random or not... I'm just\ncurious about why one tool/generator is using non-default padding (maybe it\nwas even designed like this to circumvent cracking by jtr and hashcat, that\nwould be funny or it has something to do with antivirus signature\nbypassing: \"let's use random bytes within the AES padding, such that the\nsha checksums are arbitrary for each malicious file\" etc)\nI agree, that especially with the standard cost of 2^19 of .7z, the final\nfast \"verify part\" (including aes+lzma+crc32) doesn't make much of a\n(speed) difference.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1239#issuecomment-301997763,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OWyp37VJgzTP4t98SfPACD27p-Dyks5r6pMLgaJpZM4NXHoj\n.\n. Make sure to have hashcat and your display driver in the latest version, then it should work.. Problem was already fixed + no response from OP, therefore closed. Thanks for your contributions. Please see my comments below:\n\n\nIn the changes.txt:\n\n+- Rules: Support added for position 'p'\nThis should be modified to reflect this change will work only for the CPU rule enging by using -j and -k, but not on GPU\n\nThe macro name convention:\n\n#define RULE_OP_REJECT_EQUAL_AT         '=' // reject plains that do not contain char X at position N\n #define RULE_OP_REJECT_CONTAINS         '%' // reject plains that contain char X less than N times\n #define RULE_OP_REJECT_MEMORY           'Q' // reject plains that match the plain saved (see M), i.e. if unchanged\n-\n+#define RULE_REJECT_SAVED_POS           'p' // position of the character last found with '/' or '%'\nI'm wondering if the \"REJECT\" substring is correct, or is it really working only for reject cases?\n. 1. OK\n2. OK. RULE_LAST_REJECTED_SAVED_POS sounds good to me. . Yes, there is, since hashcat can optimize the addition of the 0x80 stopbit by simply adding it to each word in the wordlist. This save the branch in the innerloop of the kernel. I've noticed there's fundamental different that should be added to test_rules.pl. That is simply the fact that rules never get rejected on GPU. For example this:\ninput: test\nrule: '6\nexpected CPU: \nexpected GPU: test\nAlso I'd suggest to remove all checks that use rules that are not supported on GPU (reason here is the above reason) like /, <, >, etc\n. The format with expected_host and expected_gpu is good, but I'd use the wording expected_cpu and expected_opencl here, because this matches it better. Also not listing expected_opencl  in case it's not supported is really nice. So I'd say go for it!\nNote that I'd use the tool without specifying a mode to it. This is kind of confusion and should be used only optional. If no mode is selected by the user, do \"the right thing\" ;). Thanks for your report!\nI'm not sure if this issue should be assigned to hashcat. The root of this problem goes back to how the OS handles the dlopen() function because it's this logic in this function (or even deeper) which handles the search paths for the libraries. So this is basically a question related to OS or maybe how drivers copy the libraries and to where, depending on how you see it.. The proposed workaround sounds simple enought to me, I'll add it. I've pushed a fix with commit https://github.com/hashcat/hashcat/commit/bb2118a2906280b2c356c2b887c6a18cab98f5ba\nThere's also a new beta binary on https://hashcat.net/beta/\nPlease test the fix and close the issue if successfull. No response from OP but I think workaround is working. Nice tool, will try to find out if the reported errors are real errors or if we have to patch test_rules.pl script.. Use a distributing overlay like hashtopussy. Thanks for the contribtion, looks like a nice fix! Some (minor important) comments:\n\nThe function name status_status_destroy() isn't perfect but it's good enough for me now. We can rename it later if we see a need to do so.\nPlease add a note to docs/changes about your fix\nPlease fix format:\n\nhcfree(status_ctx->session);\nto \nhcfree (status_ctx->session);\nand \nif (NULL == status_ctx)\n    return;\nto\nif (NULL == status_ctx) return;. Sorry, I don't want to merge this experimental code with master yet. There's\u200b no such Thing\nAm 27.05.2017 06:21 schrieb \"deepubhullar\" notifications@github.com:\n\nwhere i can download compiled long password branch for windows operating\nsystem?\nOn Sun, May 21, 2017 at 4:38 PM, Jens Steube notifications@github.com\nwrote:\n\nSorry, I don't want to merge this experimental code with master yet\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-302929925,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AaO6ech_-\n3o5U11ToyMBmTzXgpFeygE6ks5r8BshgaJpZM4NhhQ6\n.\n\n\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-304426409, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OV6ZRacCLrpDj_diqye3xoieq8Qzks5r96S8gaJpZM4NhhQ6\n.\n. I think you're doing something wrong here. If you compile for Windows (on Windows by using MSYS2), you use the native makefile target. The windows target is only for cross compilation from linux which is used when I'm create the binary package for the site, which is not what you want. So simply use \"make\" without a target and it will not drop that error and you get the windows binary you're looking for.. I'm still getting errors when I run the script. I expected to get no errors, why is that?\n\n```\nok 1 - !a - mode 1\nnot ok 2 - $1$2 - mode 1\nFailed test '$1$2 - mode 1'\nat tools/test_rules.pl line 94.\n+---+-------------------------------------+---+----------+\n| Ln|Got                                  | Ln|Expected  |\n+---+-------------------------------------+---+----------+\n|  1|'abc12                               |  1|'abc12    |\n*  2|123456790abcdefghijklmnopqrstuvw12   *   |          |\n*  3|123456790abcdefghijklmnopqrstuvwx12  *   |          |\n|  4|'                                    |  2|'         |\n+---+-------------------------------------+---+----------+\n```. Indeed, I've used an older version. Working fine now, thanks!\nOn 24.05.2017 21:42, M. Hasbini wrote:\n\n@jsteube https://github.com/jsteube Can you please make sure that\nyou are running it against the updated |tools/rules-test-cases.yaml|?\n123456790abcdefghijklmnopqrstuvw12\n123456790abcdefghijklmnopqrstuvwx12\n\nThese cases shouldn't exists for |$1$2|:\nhttps://github.com/hashcat/hashcat/blob/2dcad3f0eea3d3e8dabb531dad3f838a9bf03f5a/tools/rules-test-cases.yaml#L203-L211\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1261#issuecomment-303830410,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OYXLlou2f4Kq_v89lu44eK8a4hPmks5r9IgdgaJpZM4NlL4J.\n\n\n. I think we discussed that often enought, it's working correctly. Words < length 8 get rejected because they do not match the WPA policy of being at least length 8. If you want your rules pre-processed, please use hashcats stdout and stdin features in combination by using a pipe.. Thanks fort reporting. This is an code snippet from @magnumripper - can you take a look please?. Thanks!. Exhausted is not an error. I know, but it's not a hashcat error, I've tested it. It cracked fine on my systems. Please fix your driver setup.. Just added self-test functionality. There's special code used in Office 2013 that differs from other algorithms but it's the kernel compiler who's responsible for creating the right byte code for the GPU out of it. This compiler is part of the drivers (one of the reasons why the GPU drivers are so huge these days). IOW: Just because all other algorithms worked but office 2013 doesn't mean it's not a driver issue. It is a driver issue!. I don't mind how it's written, as long everyone works with it afterwards. In case you want to change it again, please send in a PR, but do it fast because of the release on friday. I can see the problem, but tbh I don't like the fix. Can you please rewrite the code so that it matches the other parser functions? If you do, the problem will be fixed, too. See here for an example: https://github.com/hashcat/hashcat/blob/master/src/interface.c#L14965-L15043. I've accidentially sent my response to @rhertzog directly, so here it is:\nThe reason why hashcat changed this version number is simply because it was wrong before. When I meant 3.40 I've actually meant 3.4.0. I simply didn't know something like \"Semantic Versioning\" existed at that time. IOW, this was a bug and I've fixed it.\nFrom my perspective the problem you have is the following: Your package management system interprets something into the version numbering, in this case that\"40\" is a number. But when I released 3.40 it wasn't meant as such, your system just expected it to be so. Basically the same that happens if you want to sort a textfile using \"sort\" of numbers but not use the \"-n\" switch. The conclusion, in my perspective, is that you're now asking me to fix an error that you (not you in person, but the system) made in the past.\nI'm willing to help you to solve the problem, but only as long it's not on the cost of confusing hashcat users. I've did that change to normalize the versioning with a standard that I think is accepted by a large community. Herein is the problem. If I change it, for example to v4.0.0, I'm afraid hashcat users would lose confidence in it. Such a change would be a violation of the \"Semantic Versioning\" standard because there's no major change in the code.\n. Should be fixed now, thanks! There's no commandline option to show the max password length supported, but a relative good wiki article where the max lengths are listed.. Latest version on github can crack passwords up to length 256 and salts (in this case the domain name) up to length 256, also in combination: https://pastebin.com/8HkttUpy. Is # a valid character as username? I don't feel like changing this is required otherwise.. Question for forum, not github issue. cudaHashcat is outdated, use hashcat.. It's not too hard too implement, but it takes a few hours. I'd like to see\nmore requests for it in here, first\nOn 28 June 2017 at 16:36, sergiolover notifications@github.com wrote:\n\nanything ? I read yo can edit the sources, but I dunno anytging bout\ncompiling I do only PHP and Python and such ...\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1282#issuecomment-311679229,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83ORrwuUxYSN9Fy2OuGI4NVNd54kIGks5sImTYgaJpZM4OAmMA\n.\n. Double Issue: https://github.com/hashcat/hashcat/issues/293. Is the password always of length 16? I mean exactly 16? What if it password is length 15, does it need to be padded and if yes, which byte is used for padding?. I agree with @DoZ10 this is not really an algorithm that should be added to hashcat. Except your usecase  no one could make use of it. \n\nHowever I find the topic important, given the fact that it's used in a medical application. My question therefore would be, is a \"collision\" enough to exploit whatever type of issue you found or is it required to be the correct key?. @SandraK82 The magic \"service pwd\" is only 11 byte, including the 16 byte salt this makes 27. But your descriptions says 28 byte.. OK and what is the result? Because 07932f496a777a880b927b85b5b267a9 doesn't match.. hmac md5 of '736572766963652070776456d59e656abdc651294ab2afbbf21e0e' (in hex) with key 'u+5Fhz6G' = bec6cc8cafb4a5bd2750b8ccce274e63\nhmac sha1 of '736572766963652070776456d59e656abdc651294ab2afbbf21e0e' (in hex) with key 'w4j1Kkas' = 9e816ba5db708fd311a6830d9ffaf231\nbec6cc8cafb4a5bd2750b8ccce274e63 ^ 9e816ba5db708fd311a6830d9ffaf231 = 2047A72974C42A6E36F63BC151DDBC52. Indeed, it's double hmac! It worked now:\nb6c4fae33b7d5c2dcf843d4da0ce474b ^\nb157d5aa510a26a5c41646c8157c20e2 =\n07932f496a777a880b927b85b5b267a9\n. The reason why I was asking if a collision is \"ok\" was the following: What we can do is to precompute let's say a \"set\" of precomputed hashes (the SHA1 ones), but we're kind of limited in size here. I guess 10-50 million hashes max (means 10-50 million input candidates), depending on the GPU memory. This set can be used in multihash cracking mode as the salt is always the same. Now we can run the full 96^8 ascii charset against this list. On my 4*GTX1080 I expect this to run ~16 days. However, there's no guarantee it will crack at least one. But if not we can continue with another set that will run 16 days again, and so on.... Here's a patch that enables -m 50 to do the cracking:\n```\ndiff --git a/OpenCL/m00050_a3.cl b/OpenCL/m00050_a3.cl\nindex b5120e89..45af4de0 100644\n--- a/OpenCL/m00050_a3.cl\n+++ b/OpenCL/m00050_a3.cl\n@@ -296,6 +296,30 @@ void m00050m (u32 w0[4], u32 w1[4], u32 w2[4], u32 w3[4], const u32 pw_len, __gl\n hmac_md5_run (w0_t, w1_t, w2_t, w3_t, ipad, opad, digest);\n\n\nw0_t[0] = digest[0];\nw0_t[1] = digest[1];\nw0_t[2] = digest[2];\nw0_t[3] = digest[3];\nw1_t[0] = salt_buf0[0];\nw1_t[1] = salt_buf0[1];\nw1_t[2] = salt_buf0[2];\nw1_t[3] = salt_buf0[3];\nw2_t[0] = salt_buf1[0];\nw2_t[1] = salt_buf1[1];\nw2_t[2] = salt_buf1[2];\nw2_t[3] = salt_buf1[3];\nw3_t[0] = salt_buf2[0];\nw3_t[1] = salt_buf2[1];\nw3_t[2] = (64 + 16 + salt_len) * 8;\nw3_t[3] = 0;\n+\nhmac_md5_run (w0_t, w1_t, w2_t, w3_t, ipad, opad, digest);\n+\ndigest[0] ^= swap32 (0x07932f49);\ndigest[1] ^= swap32 (0x6a777a88);\ndigest[2] ^= swap32 (0x0b927b85);\n\ndigest[3] ^= swap32 (0xb5b267a9);\n+\n     COMPARE_M_SIMD (digest[0], digest[3], digest[2], digest[1]);\n   }\n }\n@@ -413,6 +437,30 @@ void m00050s (u32 w0[4], u32 w1[4], u32 w2[4], u32 w3[4], const u32 pw_len, __gl\nhmac_md5_run (w0_t, w1_t, w2_t, w3_t, ipad, opad, digest);\n\n\nw0_t[0] = digest[0];\n\nw0_t[1] = digest[1];\nw0_t[2] = digest[2];\nw0_t[3] = digest[3];\nw1_t[0] = salt_buf0[0];\nw1_t[1] = salt_buf0[1];\nw1_t[2] = salt_buf0[2];\nw1_t[3] = salt_buf0[3];\nw2_t[0] = salt_buf1[0];\nw2_t[1] = salt_buf1[1];\nw2_t[2] = salt_buf1[2];\nw2_t[3] = salt_buf1[3];\nw3_t[0] = salt_buf2[0];\nw3_t[1] = salt_buf2[1];\nw3_t[2] = (64 + 16 + salt_len) * 8;\nw3_t[3] = 0;\n+\nhmac_md5_run (w0_t, w1_t, w2_t, w3_t, ipad, opad, digest);\n+\ndigest[0] ^= swap32 (0x07932f49);\ndigest[1] ^= swap32 (0x6a777a88);\ndigest[2] ^= swap32 (0x0b927b85);\ndigest[3] ^= swap32 (0xb5b267a9);\n+\n     COMPARE_S_SIMD (digest[0], digest[3], digest[2], digest[1]);\n   }\n }\n```\n\nAnd here's a small perl program to precompute the SHA1 blocks:\n```\n!/usr/bin/perl\nuse strict;\nuse warnings;\nuse Digest::MD5  qw (md5);\nuse Digest::SHA  qw (sha1);\nuse Digest::HMAC qw (hmac);\nmy $seed = \"service pwd\";\nmy $salt = \"56d59e656abdc651294ab2afbbf21e0e\";\nwhile (my $line = <>)\n{\n  $line =~ s/\\n$//;\n  $line =~ s/\\r$//;\nmy $final_salt = $seed . pack (\"H*\", $salt);\nmy $hash_buf1 = hmac ($final_salt, $line, \\&md5, 64);\nmy $hash_buf2 = hmac ($hash_buf1 . $final_salt, $line, \\&md5, 64);\nmy $hash_buf1 = hmac ($final_salt, $line, \\&sha1, 64);\n  my $hash_buf2 = hmac ($hash_buf1 . $final_salt, $line, \\&sha1, 64);\nprintf (\"%s:%s\\n\", unpack (\"H\", substr ($hash_buf2, 0, 16)), unpack (\"H\", $final_salt));\n}\nmd5:  b6c4fae33b7d5c2dcf843d4da0ce474b\nsha1: b157d5aa510a26a5c41646c8157c20e2\n```\nNote that I've inlined the final hash (the one we want to compare) into both kernels (single and multi hash) by simply XOR the result of the double MD5 HMAC with it, because it doesn't matter which way we use it... since it's XOR! This way we can use hashcats fast bitmaps and binary tree searching on device.\nThe perl program just takes every input on stdin and creates the hash out of it. You can use maskprocessor to create a full BF-stylish attack if you want to do that and pipe it to the perl program. The list that comes out is the hashlist to feed hashcat with.\nExample:\nroot@et:~/hashcat# echo 'w4j1Kkas' | perl dict2hash.pl \nb157d5aa510a26a5c41646c8157c20e2:736572766963652070776456d59e656abdc651294ab2afbbf21e0e\nroot@et:~/hashcat#\nroot@et:~/hashcat# ./hashcat -m 50 hash.txt --hex-salt -w 3 -a 3 'u+5Fhz6G' --quiet\nb157d5aa510a26a5c41646c8157c20e2:736572766963652070776456d59e656abdc651294ab2afbbf21e0e:u+5Fhz6G\nroot@et:~/hashcat#\nIt's important to use -a 3 and --hex-salt here.\n. I'm sure there's many such false positives, but merging it, it doesn't hurt. Thanks!. It's not about parity at all. Simply the fact that DES shifts each byte by one bit to the left, thus keyspace is 2^56 not 2^64.. The reason of the charset file is just to create a 2^56 keyspace that doesn't include any duplicates, but from a BF perspective the odds and evens are of no relevance.\nYou can freely change the odds and the evens in the charset file in your PR as long as the upper 7 bits (LE) of each byte do not change and the charset file stays at the same file size.. Fixed with https://github.com/hashcat/hashcat/pull/1288. Thanks! I'll merge and afterwards move some of the files to a new folder, to avoid confusion.. Please retry with new github master version and make sure to have the kernels/ kernel cached removed first. Please retry with new github master version again and make sure to have the kernels/ kernel cached removed first. \nIt's really hard to debug this since this is some error only showing up on your system (I can't reproduce locally).. If you're on github master, is it possible you did miss to use the new -O parameter and therefore have the speed drop? \nThis could also solve the OPs problem because the problem here is not hashcat, it's the OpenCL driver/runtime for this particular device. Different vendors have different runtimes and therefore it works on some devices while on others it does not. We also have no influence on how the watchdog that causes this problem reacts from outside.. It's an Apple-only problem that I can not reproduce since I do not have such a device. Someone else need to find the root of the problem.\n. the issue should be fixed hopefully with commit https://github.com/hashcat/hashcat/commit/bf112870a30e84e3e3f66b247e1de6333cd137ca\nplease test and close the issue if fixed. Can you please post -I output?. Looks like the Vendor ID is fixed. It was 214... before, see here: https://imgur.com/0dw8qm9 \nNow it is \"1\" as it should be.\nIn theory the speed should be fixed now. Make sure your installation is clean, all the cached OpenCL kernels are removed, you're using the right version, etc...\nIf that doesn't help we're back to zero. You maybe want to come to IRC so we can do some interactive debugging.\n. I've add some more code to change certain parameters, another shot in the dark, since I do not have access to that system and can not reproduce locally. Can you please pull master, recompile and retry again?. Please retry with latest github master version. It's important to run make clean this time.. Please redo the test with latest github master. Had to do some change because this workaround made other hash-modes no longer working. But with a bit of luck the latest changes lead to the same result.. Pull again and retry please, don't forget to rm -rf kernels. Can you please retry with the latest version from GitHub master?. File is too large, GitHub doesn't like it. It will also increase package size. Anyway, this is a great piece of resource. You should create some dedicated repository for it.. In the patch I've hacked the kernel and this results in a final digest which does not match the expected one. That's good it does that, because it tells us the self-test is working. If it cracks with my example data provided you can assume it's fine.. Try --self-test-disable . It will take time. Cracking so many salted hashes is very unusual (unliked unsalted hashes), because it's expected to be all different salts. If that would be the case, no one would do it. So it's a special behavior caused by a special use case.. There's already the same data in here:\nhttps://github.com/hashcat/hashcat/blob/master/src/interface.c#L25-L266\nIt would make more sense to just print this data on user request (--example-hashes or so) otherwise there'd be two separate places to maintain the same data.. Implemented with https://github.com/hashcat/hashcat/commit/12d95fd22c7cab80e0e466946d5a3129eeb15b52. Fixed already, please pull latest master.. This is confusing. I just tried to crack it with both hashcat and jtr and both crack it. I was under the assumption that hashcat can not crack it because of the switched input data?. Closing the issue then. Feel free to reopen if needed.. Can't reproduce it locally on windows 7, same GPU, same driver. Please send all data I need to reproduce. I still can not understand how this would occur in -a 1, -a 6 and -a 7 mode. For -a 0 it's clear, that's just some missing feature which I haven't added, but it's giving me some real headache with -a 1, -a 6 and -a 7. Also I can not reproduce locally.. Please retry with latest version, I've also pushed a new binary beta to hashcat.net/beta. Latest version should support WPA2-PSK-SHA256-AES-CMAC with -m 2500. Please use wlancap2hcx to extract the hccapx for hashcat for testing. Please close the issue if it works. New beta up at https://hashcat.net/beta/. thanks!. Please change the order of the branch so that the test is testing a true case, not a false case. That makes it faster to read. \nThere's more options that can influence benchmark performance: -n, -u, --opencl-vector-width\nIf not set, they are handled by the tuning database. Great! Many thanks. Please post output of clinfo. Should be fixed with latest beta.. Appveyor still showing build failed. Is this safe to merge?. Thanks!. Can not reproduce on my NV system:\n```\nroot@ro:~/hashcat# ./hashcat -m 500 test_hashes test_passwords --potfile-disable \nhashcat (v3.6.0-354-g1759315) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: AMD Ryzen 7 1700 Eight-Core Processor, skipped.\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #2: GeForce GTX 750 Ti, 497/1991 MB allocatable, 5MCU\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled.\nDictionary cache hit:\n Filename..: test_passwords\n Passwords.: 2\n Bytes.....: 33\n Keyspace..: 2\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \n$1$12345678$4rRGiP0updDe4bIVYSafj/:abcdefghijklmno      \n$1$12345678$Sy0u0qLp5W1f/aNE5VcBp/:abcdefghijklmnop       \nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5)\nHash.Target......: test_hashes\nTime.Started.....: Mon Aug 14 12:22:49 2017 (0 secs)\nTime.Estimated...: Mon Aug 14 12:22:49 2017 (0 secs)\nGuess.Base.......: File (test_passwords)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:        0 H/s (0.29ms)\nRecovered........: 2/2 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 2/2 (100.00%)\nRejected.........: 0/2 (0.00%)\nRestore.Point....: 0/2 (0.00%)\nCandidates.#2....: abcdefghijklmno -> abcdefghijklmnop\nHWMon.Dev.#2.....: Temp: 37c Fan: 33% Util:100% Core:1189MHz Mem:2700MHz Bus:16\nStarted: Mon Aug 14 12:22:40 2017\nStopped: Mon Aug 14 12:22:49 2017\n```\nCan not reproduce on my Intel system:\n```\nroot@ro:~/hashcat# ./hashcat -m 500 test_hashes test_passwords --potfile-disable  -D1\nhashcat (v3.6.0-354-g1759315) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: AMD Ryzen 7 1700 Eight-Core Processor, 4014/16057 MB allocatable, 16MCU\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #2: GeForce GTX 750 Ti, skipped.\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled.\nDictionary cache hit:\n Filename..: test_passwords\n Passwords.: 2\n Bytes.....: 33\n Keyspace..: 2\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \n$1$12345678$4rRGiP0updDe4bIVYSafj/:abcdefghijklmno      \n$1$12345678$Sy0u0qLp5W1f/aNE5VcBp/:abcdefghijklmnop       \nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5)\nHash.Target......: test_hashes\nTime.Started.....: Mon Aug 14 12:22:58 2017 (0 secs)\nTime.Estimated...: Mon Aug 14 12:22:58 2017 (0 secs)\nGuess.Base.......: File (test_passwords)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (0.06ms)\nRecovered........: 2/2 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 2/2 (100.00%)\nRejected.........: 0/2 (0.00%)\nRestore.Point....: 0/2 (0.00%)\nCandidates.#1....: abcdefghijklmno -> abcdefghijklmnop\nHWMon.Dev.#1.....: N/A\nStarted: Mon Aug 14 12:22:57 2017\nStopped: Mon Aug 14 12:23:00 2017\n```\nProbably an AMD JiT compiler error, because all use the same kernel code source file\n. There's currently no AMD OpenCL runtime (or OpenCL \"Platform\") that supports the AMD Ryzen CPU. \nWe have to fall back to generic CPU support to utilize the Ryzen. This generic CPU support is only the Intel OpenCL runtime. That's what you see there.. I can also not reproduce on latest ROCm on Vega 64:\n```\nroot@ro:~/hashcat# cat > test_passwords\nabcdefghijklmno\nabcdefghijklmnop\nroot@ro:~/hashcat# ./hashcat -m 500 test_hashes test_passwords\nhashcat (v3.6.0-433-g2bc2137+) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: AMD Ryzen 7 1700 Eight-Core Processor, skipped.\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #2: gfx900, 6132/8176 MB allocatable, 64MCU\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Salt\nPassword length minimum: 0\nPassword length maximum: 256\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nDictionary cache built:\n Filename..: test_passwords\n Passwords.: 2\n Bytes.....: 33\n Keyspace..: 2\n* Runtime...: 0 secs\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \n$1$12345678$4rRGiP0updDe4bIVYSafj/:abcdefghijklmno      \n$1$12345678$Sy0u0qLp5W1f/aNE5VcBp/:abcdefghijklmnop       \nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5)\nHash.Target......: test_hashes\nTime.Started.....: Sat Aug 26 14:44:45 2017 (0 secs)\nTime.Estimated...: Sat Aug 26 14:44:45 2017 (0 secs)\nGuess.Base.......: File (test_passwords)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:        0 H/s (0.85ms)\nRecovered........: 2/2 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 2/2 (100.00%)\nRejected.........: 0/2 (0.00%)\nRestore.Point....: 0/2 (0.00%)\nCandidates.#2....: abcdefghijklmno -> abcdefghijklmnop\nHWMon.Dev.#2.....: Temp: 61c Fan: 13% Core:1630MHz Mem: 945MHz Bus:16\nStarted: Sat Aug 26 14:44:31 2017\nStopped: Sat Aug 26 14:44:46 2017\n```\nIn optimized mode it cracks the one of length 15 only\n```\nroot@ro:~/hashcat# ./hashcat -m 500 test_hashes test_passwords -O\nhashcat (v3.6.0-433-g2bc2137+) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: AMD Ryzen 7 1700 Eight-Core Processor, skipped.\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #2: gfx900, 6132/8176 MB allocatable, 64MCU\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Optimized-Kernel\n Zero-Byte\n* Single-Salt\nPassword length minimum: 0\nPassword length maximum: 15\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nDictionary cache hit:\n Filename..: test_passwords\n Passwords.: 2\n Bytes.....: 33\n Keyspace..: 2\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \n$1$12345678$4rRGiP0updDe4bIVYSafj/:abcdefghijklmno        \nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5)\nHash.Target......: test_hashes\nTime.Started.....: Sat Aug 26 14:47:04 2017 (0 secs)\nTime.Estimated...: Sat Aug 26 14:47:04 2017 (0 secs)\nGuess.Base.......: File (test_passwords)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:        0 H/s (0.40ms)\nRecovered........: 1/2 (50.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 2/2 (100.00%)\nRejected.........: 1/2 (50.00%)\nRestore.Point....: 2/2 (100.00%)\nCandidates.#2....: abcdefghijklmno -> abcdefghijklmno\nHWMon.Dev.#2.....: Temp: 61c Fan: 13% Core:1536MHz Mem: 945MHz Bus:16\nStarted: Sat Aug 26 14:47:02 2017\nStopped: Sat Aug 26 14:47:05 2017\n```\nBut that's how it's supposed to work, see here:\nPassword length minimum: 0\nPassword length maximum: 15\nand\nRejected.........: 1/2 (50.00%)\nPlease retry with latest version and close this issue. The mode number 1470 doesn't exactly fit into the numbering system (as bad as it is). Can you please use mode 15900 and rewrite the code.. I think there's still the mode 1470 used in the kernel sources. Did you remove the cached kernels before retrying ?. Any news here?. PR is a bit outdated (lots of conflicts with latest version). Please reopen when fixed, thanks!. Can you please retry with the following patch:\n```\ndiff --git a/src/restore.c b/src/restore.c\nindex 82a2e14..7fcbe8a 100644\n--- a/src/restore.c\n+++ b/src/restore.c\n@@ -158,16 +158,8 @@ static int read_restore (hashcat_ctx_t hashcat_ctx)\n      * updated folders\n      /\n\nconst char *install_folder = NULL;\n\nconst char *shared_folder  = NULL;\n\n\nif defined (INSTALL_FOLDER)\n\ninstall_folder = INSTALL_FOLDER;\n\nendif\n-\n\nif defined (SHARED_FOLDER)\n\nshared_folder = SHARED_FOLDER;\n\nendif\n\nconst char *install_folder = hcstrdup (folder_config->install_dir);\n\nconst char *shared_folder  = hcstrdup (folder_config->shared_dir);\nfolder_config_destroy (hashcat_ctx);\n```. Please be more specific about what algorithm is this, read \"New feature/algorithm\" here:\n\n\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this. Sounds like this is related to GSM. I am not interessted, especially not\nafter the SL3 disaster.\nAm 14.08.2017 6:05 nachm. schrieb \"rockymaster\" notifications@github.com:\n\nHello\nalgo is private i can share via email to you. if u can send me your email ?\nits 8 digit number sha256 its update with uniq id of 0xc byte and loop\nupdate for min 1048 also it have custom sha2update which use if data is not\n0x20 then its xor with F0 first byte.\ni have try to add u on google hangout if possible we can talk private ?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1318#issuecomment-322232691,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OQECupyZi6zMRnV12dMRccIjOlmPks5sYHBfgaJpZM4O0UJj\n.\n. Fixed with https://github.com/hashcat/hashcat/commit/f6fe5657a3905fb8e7a4f75f2ef983206f44f0f9\n\nI've checked the consequences of this return at this point in the code and it's ok.. The reading of $HEX[] strings from a wordlist is still supported in hashcat, but the output has changed. It's used only in case the string includes the separator char or if the output string is not a valid UTF8 string.\nI do not see the need for a fix. This strongly depends on version, please retry with latest beta.. Rejecting as discussed. Where is it used in?. Please retry with latest beta version: https://hashcat.net/beta/. Works fine on my Intel system:\n$ md5sum sample.tc \n38522d8d25446a34305d0ab58920b04a  sample.tc\n$ md5sum bug.rule \n2a513cd634c50bf02a8969b82c6c5a57  bug.rule\n$ md5sum words.dic \na39cce46f68858d14998c58f03aabdcf  words.dic\n$ ./hashcat  -a 0 -m 6211 -r bug.rule sample.tc words.dic -D 1 --quiet --potfile-disable \nsample.tc:simplePass\n$\nAlso on NVIDIA:\n$ ./hashcat  -a 0 -m 6211 -r bug.rule sample.tc words.dic -d 1 --quiet --potfile-disable  \nsample.tc:simplePass\n$\nI had to use -D and -d to select the specific OpenCL devices. Since I can't reproduce this I can't tell what the problem is.. No worries, you're right with the --help pattern error. We'll fix that, thanks!. Great! Thanks!. I'd think an ideal fix would be to limit the maximum allowed hashes. Cracking so many hashes at the same time really feels crazy.. Bug should be fixed with: https://github.com/hashcat/hashcat/commit/35a24df55e27b06fae93c0c34f78560c6fc22fc0\nThis is how it was created:\ncase   100:  hashconfig->hash_type      = HASH_TYPE_SHA1;\n...\n                 hashconfig->dgst_size      = DGST_SIZE_4_5;\nDGST_SIZE_4_5  = (5  * sizeof (u32)), // 20\nSo when you have \nHashes: 250000000 digests; 249977448 unique digests, 1 unique salts\nIt does:\nsize_t size_digests = hashes->digests_cnt * hashconfig->dgst_size;\nThen this is: 249977448  * 20 = 4.999.548.960\nFinally:\nCL_rc = hc_clCreateBuffer (hashcat_ctx, device_param->context, CL_MEM_READ_ONLY,   size_digests,            NULL, &device_param->d_digests_buf);    \n    if (CL_rc == -1) return -1;\nThis is not causing an error, because of an integer overflow here:\nsize_t size_digests = hashes->digests_cnt * hashconfig->dgst_size;\nBoth operands are u32, so it should be:\nsize_t size_digests = (size_t) hashes->digests_cnt * (size_t) hashconfig->dgst_size;\nThat explains the behavior. Smaller numbers of hashes can create more confusion than larger ones because of the size_digests & 0xffffffff created by the integer overflow. Depending on the hash numbers, the overflow results in a value that was smaller than \n2028/8114 MB allocatable\nTherefore it didn't catch any memory allocation errors (even such on the host computer).\n. Fixed with https://github.com/hashcat/hashcat/commit/1644ac30b50f4cc5fc38762bf93a6913ab1d0030. I can't reproduce with the latest github version. You sure you're in the right current working directory when executing?. As you can see in your backtrace, it's libamdocl64.so, so it's a amdgpu-pro problem. This doesn't really surprise as amdgpu-pro is full of OpenCL bugs.. It depends on what you mean exactly. In current release version 3.6.0 this is not possible at all. In current github master version (or beta from https://hashcat.net/beta/) it is possible if you guess it right. That means for example if you know 60 positions for sure and just want to iterate through the unknown 4, then it works.. There's currently no way known to do that, therefore no software can do it.. Please post all files/commandline/etc we need to reproduce locally. I think the same, we would need to reproduce this locally. We have some testfiles for luks here: https://hashcat.net/misc/example_hashes/hashcat_luks_testfiles.7z\nYou can try with those files locally? . No response from OP, closing. You're right, the both -j and -k option do not support rule files, just single rules. That is because they are applied on host (not on device) while the wordlist is loading. Therefore the only option would be to re-run hashcat itself multiple times each time with a new rule, but that is basically what you're doing already with your script. The only advantage would be that hashcat itself does not need to be re-run and eventual large hashlists do not need to sorted again. But for hashlists with less than a million entries this is just a matter of seconds anyway.\nThe other option would be to allow rule files and apply them for each word in the wordlist while it is loading. That means before hashcat continues with the next word in the wordlist, apply each rule from the rulefile with the current one and push the output to the queue instead. The problem is that this creates a complex logic with rejects and with the wordlist cache database. To know about the ETA in the status view we need to know the total number of words in the wordlist on startup. That's why hashcat loads the wordlist on start, scans for number of words and caches this number. Now if you apply rules to it, this number becomes unknown because there's rules than can cause a reject of the word based on the word itself. For example if you use the rule >N to reject plains of length greater than N some words would be rejected and others are not. Therefore you can not simply take the total number of words from the wordlist and multiply it with the number of rules on start and you'd end up with an unknown ETA.\nSo the conclusion is that you have two solutions. One that always works and that only create a disadvantage under rare conditions and one that definitely causes a disadvantage plus it makes the program logic more complex.\n. If you use the latest hashcat version then hashcat is doing a self-test on startup on which it cracks a known hash with a known password. If this fails, it gives you a warning message. If you do not see this, something else with your input data is wrong.. @kureeoffsec It turns out that there's a problem with AMD OpenCL runtime on OSX which leads to invalid results. However, to compare it with other cracking tools you need to use -D 1 and eventually -O, since hashcat does not use CPU by default.. We're short to release of v4.0.0 please do a check with latest github version.. I've add some code to disable code caching, a shot in the dark. Can you please pull master, recompile and retry?. System was tested by someone else with a R9 M370X. Error did not occur. Therefore I'll close the issue, feel free to reopen if still exists.. Since hashcat has to dispatch the password candidates to different devices in order to make use of parallelisation it's possible that you have one device in which hashcat works as expected and another where it doesn't, for whatever reason. This processes is quasi-random because it's unknown which device gets the candidates first. If you select the device using -d 2 and -d 3 directly and you rerun the test, it's possible one device will always crack and the other never. Also note that John the ripper uses your CPU, you can do that on hashcat by using -D 1 (notice the upper case). On there, it should crack the same way. Please report back when you tried all 3 variants. That's consistent with the behavior of many AMD devices in OSX. Their OpenCL runtime is kind of broken. We can only hope ROCm will be ported to OSX soon ;). That's not exactly correct because there's also some AMD devices that work fine. \nThe Trap 6 is when the OSX kernel watchdog sees a GPU kernel to long running. But that's what we do here, computation. So desktop response is not so important, but the driver doesn't know that. It therefore kills the running kernel. The best way to avoid this is to hold the kernel runtime as low as possible. The user can do that by reducing the workload. That means if you set -w 1, the chances are good you're not running into Trap 6. However, this is again not a hashcat problem. On Linux and on Windows there's the same type of watchdog, but there's ways to turn it off. On OSX, there's no such option. If -w 1 doesn't work, you can also try -u 1 -n 1 --force.. You can increase those numbers and see if they have an influence in performance. Also note that you can always use -O and fall back to optimized kernels. This gives you a great advantage in performance and perhaps allows you to not use to be forced to use -n and -u. It may also allows you to use -d 3. Anyway, this not a hashcat problem, we should close the issue.. Perhaps. Also note that this wasn't known until now since most users that run hashcat use Linux and Windows. OTOH what if they fix the drivers in the future. Then we'd tell the user not to use device even if it works.. As discussed and verified by @hubert3 it turns out the error is not within hashcat but in AMD OpenCL runtime for OSX, therefore closing.. I'm not certain here, because I'm not convinced that this is not also PEBKAC in some way. We'd add some warning that is maybe not required. Also, since I do not own any apple devices, I also can't write a patch because I can't test. You'd need to send in a PR.. This format is horrible broken. Note that the github issue is only for feature requests and bug reports. Please ask on forum. Not a bug, everything is working as expected (even when not intuitional). Note that masks are split into two parts internally to give hashcat something to work as amplifier to overcome PCI-E bottleneck.. Can reproduce, thanks for reporting. There's so much details here that can make this more complicated than one might think of in the first place.  For example, is the out used as binary or as requested by the OP as ascii hex encoded string. If that's the case, should the hex encoding always be lower case or upper case, etc.. Therefore I don't like that Idea to have dynamic modes.. I tried to reproduce this using 2 netntlmv2 hashes in my hashlist. One of them will crack during the run with the first wordlist, the other one will never crack. Anyway, the bug popped not up in on my system so I think this must be related to something else. Try to reduce the variables to an absolute minimum, then pack all files together and send them to me so that I can reproduce locally.\nAbout that thing with $ in the username - that has no effect. The first line in your hash would just not be loaded from hashcat, it will tell you something about line length exception.. OP, please send me the files I need to reproduce. Is this really related to the hashlist? That would explain why I can not reproduce it, but otoh this is very unexpected. Please try with some different hashes. Please retry with latest version (make sure to run make clean when building from source). Do you use a network filesystem for your hashcat installation or your wordlist? Don't do that, it will break hashcat functionality. \nAlso do not edit or copy or save dictstat cache database files, this will cause errors of that type \"BUG pw_add\". Maybe you do that?\n. I've upload RC2 to hashcat.net/beta this should eventuelly fix both problems. Please try.. I think I found the issue finally. Fix was pushed with this: https://github.com/hashcat/hashcat/commit/bfd3c57308c91de6e39e06fe1be4d05dfffa867d\nPlease retry with latest version from github or hashcat.net/beta (rc4) and close this issue if fixed. I've pushed https://github.com/hashcat/hashcat/commit/34c5eac5500dc921e50c7e6b3efcd7055b38726f in order to fix this. Can you please retry with latest version and close the issue if fixed? I can't test myself as you did not append an example header to reproduce.. It's on https://hashcat.net/beta/. Thanks for the files. I did a change to the veracrypt-pim handling. I hope it's fixed now. Please retry and close the issue if fixed.. Nice find, thanks!. Can not reproduce this locally:\nroot@ht:~/hashcat# md5sum rule\n428fd5dc0934356ab2868661da01a653  rule\nroot@ht:~/hashcat# md5sum list \n1b569d308539fce2854cc1a117293122  list\nroot@ht:~/hashcat# ./hashcat --stdout -r rule list >/dev/null\nroot@ht:~/hashcat#\nHow can I reproduce this?. I've pushed a fix with https://github.com/hashcat/hashcat/commit/7a278ef035fd061291062814541b1e6812890809 that could in theory create an overflow because max password length is no longer 64 (so it's less than the subtract 100), but now its 256. Please retry on your system as I do not run into this error (on Linux BUFSIZ is 8k, while on OSX its 1k).. Warnings are for GPU temperature control (fan etc). If you use --gpu-temp-disable  you should not see them anymore. The -m 9300 error isn't really one. Your device simply has too less memory (521977856). Make sure you're using latest hashcat beta, it includes some tricks to reduce memory required for SCRYPT based algorithms (for the cost of performance).. As the driver says, it's not supported. Just to be clear, this is not a hashcat problem, it's a driver installation problem.. Please try again on the same system without docker. GitHub issues are only for reporting bugs or feature requests. For usage questions please use the hashcat forum.. There's no official documentation about how to add a new algorithm to hashcat. I'd say find a similar algorithm in hashcat, then search for it in the source and write the new one accordingly.. It's a bit more complicated than that. However a github issue is the wrong place to ask for. This is only for bug reports and feature requests. Please use hashcat forum.. GitHub issues are for posting bugs and feature requests only. Please use hashcat forum for usage questsions please.. In theory that should be no problem. However I think it's the wrong approach. Using anything related to machine readable in combination with queued attack inputs doesn't fit together. Better run hashcat a several times but using only single attacks. Then you know the current mask. Another alternative would be to use the hashcat API, that gives you full control on everything. There's however no documentation on, but using main.c as reference in the perfect example because hashcat commandline frontend is basically just calling hashcat API functions.. I like the Idea, but can you please replace the calloc() with hccalloc() and add a note why we use calloc() inside the malloc() wrapper? This could be confusing otherwise.. It's not needed, that's right, but it also doesn't hurt.. I'll fix the missing free(). done https://github.com/hashcat/hashcat/pull/1955. I think we should stay tolerant. Unless you use some kernel code that can not be cached (scrypt based, cisco $9$, descrypt, lm) there's no way to improve startup time, at least not in hashcat. It's not hashcat hanging, it's the OpenCL runtime.. This seems clear, since there's no m05000_a3.cl any longer (there's only m05000_a3-optimized.cl). It means that you did either ran make install but not make uninstall first. Or, if you installed manually, you did not remove /usr/local/share/hashcat but overwrote it.. rules which apply on device can be of arbitrary size, therefore they cannot be checked at this point. the correct use would be to use a pipe, like this:\nhashcat wordlist.txt -r rule.txst --stdout | hashcat -m 2500 your.hccapx\ni'm closing this because this is not a hashcat bug and github issues are only for bugs and feature requests. please use hashcat forum for usage questions.. It's fine, GPU needs much more work to assign at once than a CPU.. ultra outdated version, please use latest and reopen if not fixed. Oh yeah, you may want to check the commit logs of the last 4 month ;). That looks much better (no more segfault). Still, the package maintainer seem to have it installed incorrectly, therefore the error message is correct. Not a hashcat error, therefore closing.. You need to make sure that the realpath of argv[0] matches the INSTALL_FOLDER, otherwise hashcat looks for it's local content in the realpath folder. IOW, you need so fix the path in the Makefile (which is job of the package maintainer from my perspective).. where is it used in?. Can you please retry with -w 4 (this enables 256 threads instead of 32). Also make sure to use the latest github version, I changed it several times today.. Then it's unknown what causes this. We need to interactively debug this. Please come to IRC freenode channel #hashcat and PM me (atom).. I've eventually found the issue and added some code to handle it with commit https://github.com/hashcat/hashcat/commit/2e85972ec55191d9050988571d3de29b8653e456\nPlease retry your test. please test and close the issue if fixed. Yeah and even if uintmax_t somewhere in the future becomes 128 bit, it would still work as expected. It's fine for me, thanks!. Somehow this breaks mingw cross compiled binaries on windows, result looks like this:\n* Device #2: GeForce GTX 980, ju/ju MB allocatable, 1024MCU\nTherefore have to revert the changes, sorry!. One does not simply do KPA on AES, it's more efficient to rebuild the KDF.. I can't say much on the SED_IN_PLACE behavior of macOS since I do not own a macOS compatible system.\nThe reason for VERSION_TAG being hardcoded is just temporarily due the RC phase and it will be switched back to the commented version when we do the release / normal work afterwards.. I think it depends on how much it breaks readability. If the changes done are minor I think we can live with a compromise. If you want, try to get as close as possible to original formating. We can then do a comparison and decide.. There's no up-to-date GUI. Also wrong channel, use hashcat forum.. Feel free to modify the output of the code. Shouldn't be too hard.. Added with https://github.com/hashcat/hashcat/commit/9aa9725b9104702355465fb4a778c4ef8420a250. Problem is there are algorithms that are \"dangerous\" because they are very resource intensive. While not being a problem with systems with a modern GPU, with older ones they can stop the entire process. This is while the benchmark mode currently is \"limited. Anyway I like the idea of having to \"sets\" of benchmarks and we can reduce the current (default) one to a more limited selection.. So the complicated question here is, which mode is important enough to be in the default selection?\nWe need to discuss this with a larger audience, so let's use the forum for that:\nhttps://hashcat.net/forum/thread-6970.html\n. Added with https://github.com/hashcat/hashcat/commit/1184ae1cddb3a1e801649b3f3ebda0b006c8de61. If you have a solution for the needed Makefile changes please send in a PR. Thanks!. A good question. I'd say go with the backport for now. Maybe I'll change my mind but currently I'd like to stay with 4.0.0.. but 4.0.1 fixed that already. Wordlists have to be local for ideal performance and to precalculate the ETA. It needs to know how many words are in the wordlist to do this, so it needs to have full access. The trick with wget seems nice, but needs a correction:\nwget -qO- http://example.com/list.txt | hashcat ...\nOtherwise it writes to file\n. Probably the --scrypt-tmto setting. Try values 1 to 8. Also note that's a thread difference between -w 3 and -w 4, so also try them. The kernel code itself wasn't changed (from 3.6) so it's somewhere in the default settings.. You're right, it's just PBKDF2. Forget what I said about the --scrypt-tmto. For PBKDF2 there's a change that enabled it to crack of passwords > length 32. However the -O is not required here, because PBKDF2 (the slow iteration part) is unchanged. That's why such a kernel is not implemented. There should be no performance loss, thus the confusion.. Yes, I'll close the issue. My recommendation is that you play around with the parameter -u, -n, --opencl-vector-width (try values 1,2,4,8) but always also set -w 4, because this let's the GPU access the high numbers of threads (but also large blocks of workload that lead to slower updates of restore checkpoints). It's a game of trade-off.. Can you please rephrase and in detail what this issue is about, I have no clue.. @magnumripper eventually relevant for jtr as well from rar_common.c \ncracked[index] = !memcmp(plain, \"\\xc4\\x3d\\x7b\\x00\\x40\\x07\\x00\", 7);\n. To fix this, we need to have rar2john to output the second 16 byte encrypted data in case $RAR3$0 is used.. I think yes, I'll just do both tests. Please send me output of clinfo, I need it for bugfix\n. Problem is here:\nDriver version:              2482.4 (PAL,HSAIL)\nHashcat thinks this is a ROCm installation and enables inline assembly. A good alternative would be to switch to ROCm (but afaik this also means switching to linux). You get some nice performance increase as reward.\nFor fixing this I hope AMD developer can support me, because currently I see no way to distinguish between \"normal\" AMD windows driver and ROCm. For amdgpu-pro there's no such problem, they do not have this substring.. These numbers are hard to get, because on Linux + Vega64 (my GPU) I can only use ROCm to run OpenCL. A good comparison would be to use Windows + official AMD drivers, but I don't have a Windows box with PCI3.0.\nI have this: https://docs.google.com/spreadsheets/d/1Xy0kkwB6Jkqo7CEprS-GtcUp3dZFWzV_FvZqWNHWmBM/edit#gid=785768233\nYou can compare it with your numbers from your Vega.\n. I've workaround the problem by disabling the check for ROCm on windows. Please retry with latest beta from https://hashcat.net/beta/ and give some feedback if it worked on your system. If positive, I'll push a 4.0.1 release.. There's many tools using exactly this architecture to protect some sort of data or to do some verification. For example TrueCrypt, LUKS, Office docs, RAR, etc. Hashcat maps a special hashmode to each of them. Same would be required for your software.\nSee here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this. Good stuff, thanks!. Benchmark looks good to me, speed is appropriate for PMK.. The performance of PMK version is mostly depending on how fast it is to copy data from host memory to GPU memory. If the GPU memory is shared with the host memory, there's almost no bottleneck. Therefore it's possible for slow GPU to be faster than a fast GPU.\nWPA PMK cracking is basically in no way faster than WPA cracking, because you still have to do the slow part. The only difference is that you can precompute the PMK for later use. That's useful if you're a pentester and you want to test a customers WPA and ask for the essid beforehand. So you can take the PMK with you while you're on site.\nTo understand how to precompute the PMK please ask on hcxtools page.. It's normal to have \"0\" here, because hashcat does not display floating point values only pure integers. So the speed is eventually somewhere between 0 and 1. If you run a true cracking task you should see the progress value increasing after some time. If it does, everything is fine. \nAlso note that using -b in combination with such a slow hash is bad because it utilizes -a 3 to do the benchmark. Using -a 3 in combination with -m 14800 is a really bad idea, therefore you should not use it. If you really need to use -a 3 for a real-life cracking task, you can use a pipe as a much better alternative like : \nhashcat -a 3 --stdout ?a?a?a | hashcat -m 14800 --status --status-timer 1 hash.txt\n. What's the reason for not changing atoi() in usage.c ?. I've merged it. Please retry with latest github master version. Please reopen if more informations are available. I see this is PIN only. For only PIN, it should be fast enough on CPU. What am I missing here?. I think we replaced the * to [] because of some recommendation of the coverity system. Can you make sure this change is ok? What are the variables creating the unused variable warnings?. OK, let's do the change and see if coverity complains again. For the other variables let's create a separate PR.. That's the way. It's supposed to have only a few candidates in this case, therefore it's not supposed to restore a piped session. You can however use the -s parameter directly on the first command.. Some things to notice is that:\n\nRemoving the default just for --show and --left would be hard to explain. If we do, it should be global.\nSome example scripts would be need to be patched, too (example0.cmd etc)\nRemoving the -m 0 default would also solve the missing default marker\nLot's of tutorials in the wild explain -m 0 to be the default (in case of critic on the change we can point to \"it's a new version\")\n\nThe \"Please specify a hashtype with -m.\" misses a hint on -h to get a list of all available modes\n. @roycewilliams feel free to send in a PR. There's three difference cases:\n\n\nIf the total data size to hash is larger than the blocksize of the hash (64 for SHA1), then the performance drops that many times by 100% as much of the blocksize fits into the total data size, where the last blocksize is also decreased by 9. For example a total data size of 55 creates 100% performance drop compared to 54.\n\n\nEach time you run sha1_update_* you create a branch caused by the switch() behind. GPU really do not like branches which creates a performance drop\n\n\nGPU do not have support for 8bit processing, therefore you can not do sha1_update_global_swap (\"foobar\"), you must use a 32 bit datatype array with the size of the hash blocksize, so W[16]. If you use an array smaller than that, the JiT creates buffer overruns that are not intercepted but create performance drops.\n\n\nAll cases can add up to create an even larger drop which is hard to predict. Howerver, this looks like a normal behavior, therefore closing issue\n. > Max length of $pass.$hash is >32, <64.\nWell that could be one (of multiple) reason, since 55 < 64\n\nI did try writing a new sha1_update_ function\n\nIt's already on the maximum of performance. The only way to improve performance is to workaround the call itself.\n\nBoth pass and salt are u32[64]\n\nIf you have 64 bit value the performance will drop massively since GPU are still 32 bit construct. There are no native 64 bit integers and they are just emulated by 2 times 32 bit integers. Typically this results in two or three times the number of instructions than on 32 bit values.. Invalid self-test message, fixed with https://github.com/hashcat/hashcat/commit/829ea605c514c457948a84487e7dbb51e18f5c36. done https://github.com/hashcat/hashcat/commit/e5ca2e2fcb06d6577564c0462c82cfe58f61e9ea. Thanks!. Maybe you did install the 4.0.0 files over an existing hashcat folder of an older version? That could cause the problem. Please run make uninstall first, then run make install.. Yeah, it does already. Everything here working as it should. GitHub issues are for bug reports and feature requests only. Please use the forum for usage questions. Please read https://hashcat.net/wiki/doku.php?id=mask_attack first. . Please use rule stack feature. If unclear how to do that, ask on hashcat forum. GitHub issues are for bug reports and feature requests only.. Not a bug. Sorry, not possible. Sounds like a bad idea indeed. It's much more clever to capture the handshake with the mobile device and then copy it to a remote site for cracking.. Great work, thanks!. Yes, we often do that.. It makes no sense to have a pure Kernel for this algorithm as it does not support password longer that 12. It's not a hashcat problem.. Is this some error that occurs only for older macOS systems?. @matrix Can you please fix the PR as described in the PR. Can I close the issue - is the fix working?. No response from OP, but should be fixed. Please reopen if turns out otherwise.. That's not how I'd have done that in src/timer.c (The other stuff in Makefile is ok). The use of static variables gives me some headache. Can you rewrite it do use this kind of code as used in v4.0.1?\ntypes.h:\ntypedef struct timeval    hc_timer_t;\ntimer.c:\n```\ninline void hc_timer_set (hc_timer_t* a)\n{\n  gettimeofday (a, NULL);\n}\ninline double hc_timer_get (hc_timer_t a)\n{\n  hc_timer_t hr_tmp;\nhc_timer_set (&hr_tmp);\nreturn (double) (((hr_tmp.tv_sec - (a).tv_sec) * 1000) + ((double) (hr_tmp.tv_usec - (a).tv_usec) / 1000));\n}\n```. Wait I wouldn't say don't run hashcat on laptops. You can do that like pentesters have to do it when they are on site. Just make sure you have an adequat setup and don't run it over several weeks in -w 3 or -w 4 mode.\nAnyway, adding the correct configuration settings to your xorg.conf and your Xsetup file is not a hashcat issue. It's clearly an installation issue. Therefore please use the hashcat forum as GitHub issues are for bugs and feature requests only.\n. As @philsmd and @Chick3nman have explained nicely before this is not an issue. A GPU can only work advantageous compared to CPU if the SCRYPT settings are low enough (like with litecoin computation). Therefore there's no way around adding more CPU power for your algorithm if you want more speed.. I wouldn't say don't crack with a laptop. It's required for pentesters that are required to use their own hardware on site. If you use an adequate notebook it's pretty fine to use it.\nEverything else is as @philsmd mentioned, especially the part with mobile GPU being slower than concrete GPU.\nAnyway this is not a hashcat issue and should not be discussed here. GitHub issues are for bugs and feature requests only.. The problem is that the algorithm puts in a fixed 0x80 byte at position 16. If the password (including the salt) is longer than 16, then I'm not exactly sure how to handle that.\n@magnumripper Any Idea? I see JtR is limiting to lenght 16 as well. Wondering what's the salt then. Is it \"admi\" instead of \"admin\" ?. I was lucky to find the change to the algorithm in order to crack passwords > 16. One simply needs to pad with zero bytes to a next segment of 16 bytes.\n@SilRo991 Thanks for the example hashes, that helped. If you want to play with it, clone latest hashcat version from github and build from source or use the binary beta from https://hashcat.net/beta/ to crack them.\n@magnumripper The change required is explained best way here: https://github.com/hashcat/hashcat/commit/e877c30ebcd250ec67074f56c651d72b11478bcf#diff-7687bc127baaaa448c5fc5e56f0c2133L5571. There's a DEBUG variable that you can set to 1 in src/Makefile. Please make clean before recompiling. Then retry with hashcat -b -m 1500 maybe we're lucky and get some better output. If there's nothing that helps, please try with strace -f -v -s 1000 ./hashcat -b -m 1500 . Can you please retry with the latest version from GitHub master or hashcat.net/beta/ ? I think the problem is solved now but needs confirmation.. Please retry after pulling latest version from github and close the issue if fixed.. Problem should be resolved. Thanks for reporting.. Cool stuff, thanks for the contribution! Can you please change the hash-mode from 10201 to 16400?. OK, thanks so far!\nThe next thing that's missing is the test.pl implementation. Usually we need it to do the unit tests but it's also used to create hashes with just a given password (for example to create the self-test hash). Please add the test.pl implementation.. Excellent contribution, thank you!. Can't reproduce this locally. It's all tabs for me.\nroot@ht:~/hashcat# ./hashcat example0.hash -a 3 ?a --mac --quiet | grep \" \" | wc -l\n0. Still can't reproduce :(\nroot@ht:~/hashcat# ./hashcat example0.hash -a 3 ?a --mac  | grep ^STATUS | grep \" \" | wc -l\n0. It seems like we're both wrong. Here's what's happening:\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => ^M                                                 ^MSTATUS    5       SPEED   0       1000    EXEC_RUNTIME    0.072939        CURKU   1       PROGRESS        95      95      RECHASH 12      6494    RECSALT 0       1       TEMP    35      REJECTED        0\nSo the ^M here is doing the carriage return, that's why grep ^STATUS isn't working. However, there are no spaces after the STATUS line, there's only some before. I'd suggest to add --quiet to the htp client. In that case, there will be no \"problematic\" spaces.. Well yeah, because from a technical perspective (since there's no newline) there's also the prompt part of the line and the prompt has spaces. From how hashcat should work it's correct that way. If you can add the --quiet to I think it's the cleanest solution.. From what I see there's like two different version for Electrum wallets. That's kind of confusing since you're talking only about a specific one in particular. If you want that algorithm added cleanly into hashcat, please provide all the data we need in full and everything described here: \nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_want_to_request_some_new_algorithms_or_features_how_can_i_accomplish_this\nThere more you stick to the data requested on there, the higher the chances to motivate me to add it.\nWhile looking at the JtR Code, I found that one example hash:\n{\"$electrum$1*d64ac297de09893a03bc540b346d5e97*0af493539c512e3ded466b4879b8a47b\", \"openwall123\"},\nThe above example, does this match the algorithm that you're talking about?\nThere's also many different Electrum versions listed. But when it comes to the wallet, it seems there's one for wallets and \"encrypted\" wallets. So from hashcat perspective, we should distinguish between wallet and encrypted wallets?\nThere's no need to pay. If I want to add it, I'll do it for free.\n. I'd estimate performance to be around 250MH/s on a single GTX1080. I've pushed the changes to hashcat with commit: https://github.com/hashcat/hashcat/commit/553668bb9f6311fb86991e4642cd8e0451e3ea52\nYou should be able to test with latest github master or binary beta from https://hashcat.net/beta/\nIf you really want to contribute, the salt-type 2 and 3 are not yet implemented. You can add a new branch for them in the kernels after the AES decryption part.\nI'll close the issue because it should be working now.. Sure, sounds good. Please send in a PR.. I can't reproduce with almost the same GPU (RX480).\nv4.1.0 (it's the RC1 of v4.0.1 - no kernel changes):\n```\nroot@sf:~/hashcat# ./hashcat -b -m 2500\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Ellesmere, 3254/4077 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#1.....:   173.8 kH/s (52.28ms)\nStarted: Thu Feb  1 09:19:45 2018\nStopped: Thu Feb  1 09:20:08 2018\nroot@sf:~/hashcat# ./hashcat -b -m 2500 -w 3\nhashcat (v4.1.0) starting in benchmark mode...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Ellesmere, 3254/4077 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--workload-profile=3\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#1.....:   174.0 kH/s (102.26ms)\nStarted: Thu Feb  1 09:20:15 2018\nStopped: Thu Feb  1 09:20:28 2018\n```\nv3.5.0:\n```\nroot@sf:~/hashcat# ./hashcat -b -m 2500 -w 3\nhashcat (v3.5.0) starting in benchmark mode...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Ellesmere, 3829/4077 MB allocatable, 36MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#1.....:   173.1 kH/s (105.89ms)\nStarted: Thu Feb  1 09:21:21 2018\nStopped: Thu Feb  1 09:21:32 2018\n```\nSame speed. Without being able to reproduce I can't fix it.. I've add some code to disable code caching, a shot in the dark. Can you please pull master, recompile and retry?. I've add some more code to change certain parameters, another shot in the dark, since I do not have access to that system and can not reproduce locally. Can you please pull master, recompile and retry again?. Please retry with latest github master version. It's important to run make clean this time.. Please redo the test with latest github master. Had to do some change because this workaround made other hash-modes no longer working. But with a bit of luck the latest changes lead to the same result.. Pull again and retry please. The issue should be fixed, can you please retry with the latest version from GitHub master and close this issue?. Why is there\nSONAME                  := 0.0\nIs that really what we want?. Bug: The target \"make clean\" does not remove the file:\nlibhashcat.so.0.0. What about this as an alternative to SONAME?\nSONAME_VERSION := $(shell git describe --tags --dirty=+ | sed 's/^v\\([\\.0-9]*\\).*/\\1/'). This is also wrong I think\ncd $(DESTDIR)$(LIBRARY_FOLDER) && ln -s $(HASHCAT_LIBRARY) $(HASHCAT_LIBNAME)\nInstead of doing the ln manually, ldconfig should be used:\nroot@ht:~/hashcat# ls -l libhashcat.so*\n-rwxr-xr-x 1 root root 817368 Jan 25 22:17 libhashcat.so.4.0.1\nroot@ht:~/hashcat# ldconfig -n .\nroot@ht:~/hashcat# ls -l libhashcat.so*\nlrwxrwxrwx 1 root root     19 Jan 25 22:30 libhashcat.so.4 -> libhashcat.so.4.0.1\n-rwxr-xr-x 1 root root 817368 Jan 25 22:17 libhashcat.so.4.0.1\nAnd then we should link to libhashcat.so.4. Not sure if they are really better, I'm just playing around with this. I have no real experience with it, therefore I was asking you to provide the PR.. Please send in an update PR, I'll review. The current PR does not apply cleanly and looks like something went terrible wrong. Please fix!. Looks good, I'll merge it. I'll do some small changes afterwards.. OK, I've pushed my changes. Btw I'm planing to release 4.1.0 soon. That should make it easier to use the changed code from your linux distribution.. I can't reproduce on my systems. \nPlease checkout 7a8239b4c1bb72ec963c841a1a53d96848cc547f and see if it still works on yours.\n. OK, thanks for update!. I think you just forgot to format the device. Please reopen if I'm wrong.. It's not that, it's more like I don't like the idea of it. If you want to switch cases for 9-16 you would write:\nT8 T9 TA.. and so on.\nWhen it comes to P@$$w0rd -> p244W)RD it's even worse as this depends on the keyboard layout. On my german keyboard the @ char would be translated to \" char.. No it's like that this rule was written without thinking of it's implications in the first place. There's a design error in it, why should I buy it.. Please ask on Forum. GitHub issues are only for bugs and feature requests.. I did a second thought on this. I don't think any longer this makes any sense for the most users (except you with your special case). It's the opposite, by adding two parameters outputting more or less the same data this will create confusion - especially for new users.\nTo solve your case I'd suggest to talk to @s3inlc and ask them to add the crackpos information to the hashtopussy database. From there you can easily access it. You also save the step to match it with the password. So this has multiple advantages and feels like the correct solution from a software design perspective.. The rule M and X can be used with -j and -k only.\nroot@ht:~/hashcat# echo p@ssW0rd | ./hashcat --stdout -j 'lMX428'\np@ssw0rdw0. Please ask on Forum. GitHub issues are only for bugs and feature requests.. @magnumripper We changes the x rule to be the O rule a while back to be JtR compatible. We just forgot to update the rule files, too. That's what this PR is doing.. I agree that type of error should be fatal. I've pushed a fix: https://github.com/hashcat/hashcat/commit/bb401c9cec9370b2e832ee175480da0b626f36b3\nThanks for reporting!. Please use the hashcat forums for usage questions. GitHub issues are for bugs and feature requests only.. Not supported. Use -O and/or -w 3. That's some nice work, but please create a smaller set (max. 10 files) and name it so that a user who has no Idea what this is get's an idea of your idea.. Done with https://github.com/hashcat/hashcat/commit/547025ec475c2aaa4edf16184e91c24fbefe08ff. As an alternative you can use a candidate generator which is doing what you're looking for and pipe it to hashcat. It does not matter which encoding the candidate generator is using, as hashcat has built-in support for iconv. However, this works only for slow hashes (like -m 500 is).\nBasically the trick is to use the single byte encoding for the mask processing and put it to --stdout, and then use hashcat internal iconv converter in a second hashcat instance. For example, in german it looks like this:\nexample password to crack with utf8 multibyte character:\n$ echo -n t\u00e4st | xxd\n00000000: 74c3 a473 74                             t..st\nexample hash in utf8 to crack:\n$ echo -n t\u00e4st | md5sum.exe\n109623cd486dccc1c2a2601b1144305f *-\ncreate your charset in utf8:\n$ echo -n abcdefghijklmnopqrstuvwxyz\u00e4 | xxd\n00000000: 6162 6364 6566 6768 696a 6b6c 6d6e 6f70  abcdefghijklmnop\n00000010: 7172 7374 7576 7778 797a c3a4            qrstuvwxyz..\nencode as 1 byte encoding:\n$ echo -n abcdefghijklmnopqrstuvwxyz\u00e4 | iconv -f utf-8 -t iso-8859-15 | xxd\n00000000: 6162 6364 6566 6768 696a 6b6c 6d6e 6f70  abcdefghijklmnop\n00000010: 7172 7374 7576 7778 797a e4              qrstuvwxyz.\nredirect into file:\n$ echo -n abcdefghijklmnopqrstuvwxyz\u00e4 | iconv -f utf-8 -t iso-8859-15 > umlaut.charset\ncrack md5 (will work for md5crypt, too):\n```\n$ ./hashcat -a 3 --stdout -1 umlaut.charset ?1?1?1?1 | ./hashcat -m 0 '109623cd486dccc1c2a2601b1144305f' --encoding-from iso-8859-15 --encoding-to utf-8\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz, skipped.\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #2: GeForce GTX 980, 1024/4096 MB allocatable, 16MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n* Raw-Hash\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nATTENTION! Pure (unoptimized) OpenCL kernels selected.\nThis enables cracking passwords and salts > length 32 but for the price of drastically reduced performance.\nIf you want to switch to optimized OpenCL kernels, append -O to your commandline.\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\n109623cd486dccc1c2a2601b1144305f:t\u00e4st\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: MD5\nHash.Target......: 109623cd486dccc1c2a2601b1144305f\nTime.Started.....: Tue Feb 20 09:49:43 2018 (0 secs)\nTime.Estimated...: Tue Feb 20 09:49:43 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#2.....: 25167.1 kH/s (5.61ms) @ Accel:128 Loops:1 Thr:512 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 531441\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#2....: sari -> \u00e4\u00e4\u00e4\u00e4\nHWMon.Dev.#2.....: Temp: 31c Fan: 26% Util:  1% Core:1240MHz Mem:3004MHz Bus:16\nStarted: Tue Feb 20 09:49:41 2018\nStopped: Tue Feb 20 09:49:43 2018\n```\nPlease continue the discussion on hashcat forum, as this is a usage question. hope it helped, tho.\n. I can reproduce this but only in -a 3 mode if using -O. All other combination seem to work fine. Can you confirm?. Issue should be fixed with commit https://github.com/hashcat/hashcat/commit/8079abffb015d1e000aa120670c1af7b2d7e8cbc\nIf not, please reopen the issue. Also note that in -O the maximum password length for is 27. This is also the case for -a 0.. I was trying to find a way to make this more generic so that it will work on other distributions than fedora but failed. For example, on Ubuntu, there's no package which provides Lzma2Dec.h header. I think the better way of handling this would be to use \"Lzma2Dec.h\" in the ext_lzma.h file as include, and then use a full path to the lzma sdk in the Makefile using -I. Can you rewrite your patch that way?. Please attach the hccapx file so we can reproduce locally. I can not reproduce this locally on my GTX 750Ti. I'm getting correct results.\nUsing wordlist:\nroot@ht:~/hashcat# rm hashcat.potfile \nroot@ht:~/hashcat# echo 12_08_1934 > wl1\nroot@ht:~/hashcat# echo 14 04 1977 > wl2\nroot@ht:~/hashcat# ./hashcat -m 2500 15786_1494403569.hccapx wl1 --quiet \nroot@ht:~/hashcat# ./hashcat -m 2500 15786_1494403569.hccapx wl2 --quiet  \ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nroot@ht:~/hashcat#\nUsing stdin:\nroot@ht:~/hashcat# rm hashcat.potfile \nroot@ht:~/hashcat# echo 12_08_1934 | ./hashcat -m 2500 15786_1494403569.hccapx --quiet \nroot@ht:~/hashcat# echo 14 04 1977 | ./hashcat -m 2500 15786_1494403569.hccapx --quiet \ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nroot@ht:~/hashcat#\nMaybe you're using an old potfile. Try with --potfile-disable or remove the potfile.\nCan someone else test please?\n. Did you try to reproduce the error using my commands?. Please provide that .txt you're talking about.. Still can not reproduce:\nroot@ht:~/hashcat# cat fechasdenacimiento.txt| ./hashcat64.bin -m 2500 15786_1494403569.hccapx  --quiet\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nYou maybe want to try --opencl-vector-width 1. The issue should be fixed with the latest version from GitHub master. Can you please retry and confirm and close the issue?. I think we can simply add sha256($salt . $pass . $salt), and add a loader on top of it. What's the native parser output of the hash and salt?. Thanks for the PR, looks very nice!\nTo merge there are some modifications needed:\n\nAdd the missing kernels. That is the -a1 and -a3 kernel.\nAdd the test.pl and test.sh entries so we can do unit tests.\nRemove the example77xx and 78xx files. Those are obsolte after (2) is implemented.\n. That's how it is expected to work.. There's a long discussion on this on a different issue and I'm afraid that's the only way of doing it. You need to cd to hashcat installation folder first. There's currently no way of working around that.. No response from OP for a long time, therefore closing the issue. Feel free to reopen if you have new insights.. Great work, thanks!. The host ram is an important factory, but in your case it should be sufficient. The problem in your case is the limited GPU memory (only 500MB). Note that the OpenCL runtime limits the accessible one-block allocation to 1/4 of the total memory. This is simply a limit that you've hit. Note that AMD GPU in combination with rocm do not have such a 1/4 limitation, but they have other problems. Anyway this is not a hashcat problem or bug,. I like the idea of the cached hashlist blob. However, this could create a mess in the hashcat installation folder. The question is in the details. Should we store such a blob in the same folder as the original hashlist or should we use a special blob folder to do that? I'd think the first one sounds better. We also need to have a different filename ideally with a special filename suffix (eg: .hcdump or so). \n\nWe'll also need some sort of header. Any ideas of the required attributes? \nOh and what about if the user changes the data in the original hashfile. We need to make sure that there's no change. We could, for example, store the original hashfile filestats (as @philsmd already said as we do in dictstat) and compare them before we allow hashcat to load the blob.\nFinally the question is: Is it worth having such a complex system and what's the benefit? The only affected users would be users with very large hashlists. But for hashlists < 1M hashes this creates almost no advantage. I'd think most of the hashlists load by hashcat are small hashlists and single hashes but I don't have any real statistics about that.\n. I was talking about the complexity this adds to the hashcat sources. There's simply not enough good reason to do this. Feel free to reopen if there are new arguments.. All cascades are supported for TrueCrypt.\n. Did I miss reading about the single quote somewhere ?\nNo, but it's the shell interpreting the $, not hashcat.\nOne thing I do not understand , the hash was obtained from 1.7 version 128 bit key , but we have to use -m 10500 which is for the lower version.\n(Guessing here): Probably the document was created with an older PDF version and then updated on a newer PDF version, which then sticks to the old encryption for backward compatibility.. The problem is that there's switches that can have influence on a mask/iterate it. That is for example when you use -i or if you use mask files instead of a mask. However, if both cases are false, we can auto-activate the switch. But then how do we disable that behavior if the user (for whatever reason) wants that?. After some thinking with @philsmd we found a major problem when it comes to automatic optimized kernel selection:\nIf the mask is small enough which would allow the use of optimized kernel, we can't say for sure if the salt length is. For example, we can not crack a salt of length 200 in optimized kernel mode, only in pure kernel. However the mask length has no influence here. One can say ok so you check on start the salt length as well, but what if it's a hashfile with multiple salts. And what if some of them are short enough for optimized kernels and others are not. Note that we can not switch between kernels as soon as hashcat has been initialized.\nThis complicates everything and it's even more complicated to explain it to the users because it requires some deep knowledge about hashcats architecture and optimization techniques being used.. Can not reproduce locally. Please reinstall hashcat and make sure to not reuse an existing folder for installation. Please feel free to reopen if you have more information in order how to reproduce this error:\nhash:\nroot@et:~/hashcat# cat test.hash \n$6$n.x8pyjJ$y/9YEn.7e3TrjfAmbvVK89rE9u5YlUBJyqWambc6wH4oAbk.ooVn4W8yEQijadbVgKLG9omTmVJBzX.CtMLTa1\non CPU:\nroot@et:~/hashcat# ./hashcat -a 3 -m 1800 --status test.hash 12345 -D1 --quiet --potfile-disable \n$6$n.x8pyjJ$y/9YEn.7e3TrjfAmbvVK89rE9u5YlUBJyqWambc6wH4oAbk.ooVn4W8yEQijadbVgKLG9omTmVJBzX.CtMLTa1:12345\non GPU:\nroot@et:~/hashcat# ./hashcat -a 3 -m 1800 --status test.hash 12345 -D2 --quiet --potfile-disable  \n$6$n.x8pyjJ$y/9YEn.7e3TrjfAmbvVK89rE9u5YlUBJyqWambc6wH4oAbk.ooVn4W8yEQijadbVgKLG9omTmVJBzX.CtMLTa1:12345\n. This algorithm is so slow that it usually takes up to 2 minutes to perform a full walkthrough of the workitem slice. It's not stuck, it's just very slow. After that time, it's able to update the status screen, but not before that.. This is pretty clear:\n0x00007fffe9528a8c in ?? () from /opt/AMDAPPSDK-3.0/lib/x86_64/libamdocl12cl64.so\nThe segfault occurs inside the amd library. We can't do anything to workaround this type of error. It's not a hashcat error.\nHowever, if you want to crack on CPU, please use the Intel OpenCL runtime (even for AMD CPU). . Please don't mix up different errors. \nThis error:\nLLVM ERROR: Cannot select: 0x55e546dad918: i32,ch = AtomicLoadAdd<Volatile LDST4[%arrayidx480.i(addrspace=1)]> 0x55e545c73aa0, 0x55e548903e50, Constant:i32<1>\nIs a typical error I see whenever MESA is involved. So this is a MESA error. Hashcat can't do anything to fix it.\n. Looks good to me. Your GPU simply does not have enough memory to do it. Note that there's a critical difference between CPU and GPU, it's the number of compute units. For a CPU we're talking about 16, for a GPU we're talking about 4096. This multiplier is it that need to be applied to memory, too. IOW, you need 256 times the total memory size on each GPU that you have on your host system. If you do not have it you need to stick to CPU.. There's no error. One just have to realize that --keyspace depends on -m.\nroot@et:~/hashcat# ./hashcat -O --keyspace -a 3 mask\n56800235584\nroot@et:~/hashcat# ./hashcat -O --keyspace -a 3 mask -m 1000\n3521614606208\n. I was thinking of that when I've added benchmark mode. However it's very likely benchmark number are post-processed either manually or automatically. The change would be easy, I'm just not sure if it creates more problems than not having it. The only reason why someone would like to see it is to be able to compare two or more entire systems to each other. But IMO that should be done on a different level (excel sheet or whatever).. What is this about?. Too many conflicts now.. Adding such an option feels wrong, it's a too specific request for most people. But I've made an example diff for you.\n```\ndiff --git a/OpenCL/m00000_a3-optimized.cl b/OpenCL/m00000_a3-optimized.cl\nindex 0c6b8657..d35d5e55 100644\n--- a/OpenCL/m00000_a3-optimized.cl\n+++ b/OpenCL/m00000_a3-optimized.cl\n@@ -295,37 +295,6 @@ DECLSPEC void m00000s (u32 w[16], const u32 pw_len, __global pw_t *pws, __global\n     digests_buf[digests_offset].digest_buf[DGST_R3]\n   };\n\n/**\n\n\nreverse\n\n\n\n*/\n\nu32 a_rev = digests_buf[digests_offset].digest_buf[0];\nu32 b_rev = digests_buf[digests_offset].digest_buf[1];\nu32 c_rev = digests_buf[digests_offset].digest_buf[2];\n\nu32 d_rev = digests_buf[digests_offset].digest_buf[3];\n\nMD5_STEP_REV (MD5_I_S, b_rev, c_rev, d_rev, a_rev, w[ 9], MD5C3f, MD5S33);\nMD5_STEP_REV (MD5_I_S, c_rev, d_rev, a_rev, b_rev, w[ 2], MD5C3e, MD5S32);\nMD5_STEP_REV (MD5_I_S, d_rev, a_rev, b_rev, c_rev, w[11], MD5C3d, MD5S31);\nMD5_STEP_REV (MD5_I_S, a_rev, b_rev, c_rev, d_rev, w[ 4], MD5C3c, MD5S30);\nMD5_STEP_REV (MD5_I_S, b_rev, c_rev, d_rev, a_rev, w[13], MD5C3b, MD5S33);\nMD5_STEP_REV (MD5_I_S, c_rev, d_rev, a_rev, b_rev, w[ 6], MD5C3a, MD5S32);\nMD5_STEP_REV (MD5_I_S, d_rev, a_rev, b_rev, c_rev, w[15], MD5C39, MD5S31);\nMD5_STEP_REV (MD5_I_S, a_rev, b_rev, c_rev, d_rev, w[ 8], MD5C38, MD5S30);\nMD5_STEP_REV (MD5_I_S, b_rev, c_rev, d_rev, a_rev, w[ 1], MD5C37, MD5S33);\nMD5_STEP_REV (MD5_I_S, c_rev, d_rev, a_rev, b_rev, w[10], MD5C36, MD5S32);\nMD5_STEP_REV (MD5_I_S, d_rev, a_rev, b_rev, c_rev, w[ 3], MD5C35, MD5S31);\nMD5_STEP_REV (MD5_I_S, a_rev, b_rev, c_rev, d_rev, w[12], MD5C34, MD5S30);\nMD5_STEP_REV (MD5_I_S, b_rev, c_rev, d_rev, a_rev, w[ 5], MD5C33, MD5S33);\nMD5_STEP_REV (MD5_I_S, c_rev, d_rev, a_rev, b_rev, w[14], MD5C32, MD5S32);\nMD5_STEP_REV (MD5_I_S, d_rev, a_rev, b_rev, c_rev, w[ 7], MD5C31, MD5S31);\n\nMD5_STEP_REV (MD5_I_S, a_rev, b_rev, c_rev, d_rev,     0, MD5C30, MD5S30);\n\n\nconst u32 pre_cd = c_rev ^ d_rev;\n\nMD5_STEP_REV1(MD5_H_S, b_rev, c_rev, d_rev, a_rev, w[ 2], MD5C2f, MD5S23);\n\nMD5_STEP_REV1(MD5_H_S, c_rev, d_rev, a_rev, b_rev, w[15], MD5C2e, MD5S22);\n   /**\nloop\n/\n@@ -338,11 +307,6 @@ DECLSPEC void m00000s (u32 w[16], const u32 pw_len, __global pw_t pws, __global\n\nconst u32x w0 = w0l | w0r;\n\n\nconst u32x pre_d = d_rev;\n\nconst u32x pre_a = a_rev - w0;\nconst u32x pre_b = b_rev - (pre_a ^ pre_cd);\n\nconst u32x pre_c = c_rev - (pre_a ^ pre_b ^ pre_d);\nu32x a = MD5M_A;\n u32x b = MD5M_B;\n u32x c = MD5M_C;\n@@ -395,15 +359,9 @@ DECLSPEC void m00000s (u32 w[16], const u32 pw_len, __global pw_t *pws, __global\n MD5_STEP0(MD5_H1, a, b, c, d,     H_wdc28, MD5S20);\n MD5_STEP (MD5_H2, d, a, b, c, w0, H_w0c29, MD5S21);\n MD5_STEP0(MD5_H1, c, d, a, b,     H_w3c2a, MD5S22);\n-\n\n\nif (MATCHES_NONE_VV (pre_c, c)) continue;\nMD5_STEP0(MD5_H2, b, c, d, a,     H_w6c2b, MD5S23);\n MD5_STEP0(MD5_H1, a, b, c, d,     H_w9c2c, MD5S20);\n MD5_STEP0(MD5_H2, d, a, b, c,     H_wcc2d, MD5S21);\n-\n\n\nif (MATCHES_NONE_VV (pre_d, d)) continue;\nMD5_STEP0(MD5_H1, c, d, a, b,     H_wfc2e, MD5S22);\n MD5_STEP0(MD5_H2, b, c, d, a,     H_w2c2f, MD5S23);\n\n\n@@ -424,6 +382,16 @@ DECLSPEC void m00000s (u32 w[16], const u32 pw_len, __global pw_t *pws, __global\n     MD5_STEP0(MD5_I , c, d, a, b,     I_w2c3e, MD5S32);\n     MD5_STEP0(MD5_I , b, c, d, a,     I_w9c3f, MD5S33);\n\na += MD5M_A;\nb += MD5M_B;\nc += MD5M_C;\nd += MD5M_D;\n+\na &= 0x1f1f1f1f;\nb &= 0x1f1f1f1f;\nc &= 0x00001f1f;\nd &= 0x00000000;\n+\n     COMPARE_S_SIMD (a, d, c, b);\n   }\n }\ndiff --git a/src/interface.c b/src/interface.c\nindex f8ebc578..418a87cf 100644\n--- a/src/interface.c\n+++ b/src/interface.c\n@@ -20847,7 +20847,6 @@ int hashconfig_init (hashcat_ctx_t *hashcat_ctx)\n                  hashconfig->parse_func     = md5_parse_hash;\n                  hashconfig->opti_type      = OPTI_TYPE_ZERO_BYTE\n                                             | OPTI_TYPE_PRECOMPUTE_INIT\n| OPTI_TYPE_PRECOMPUTE_MERKLE\n                                             | OPTI_TYPE_MEET_IN_MIDDLE\n                                             | OPTI_TYPE_EARLY_SKIP\n                                             | OPTI_TYPE_NOT_ITERATED\n@@ -20857,8 +20856,8 @@ int hashconfig_init (hashcat_ctx_t *hashcat_ctx)\n                  hashconfig->dgst_pos1      = 3;\n                  hashconfig->dgst_pos2      = 2;\n                  hashconfig->dgst_pos3      = 1;\nhashconfig->st_hash        = ST_HASH_00000;\nhashconfig->st_pass        = ST_PASS_HASHCAT_PLAIN;\nhashconfig->st_hash        = NULL;\n\nhashconfig->st_pass        = NULL;\n                  break;\ncase    10:  hashconfig->hash_type      = HASH_TYPE_MD5;\n```\n\n\nMake sure to recompile the host binary because of the changes to interface.c. \nYou can then use a command line this to crack it:\nroot@ht:~/hashcat# rm -rf kernels; ./hashcat -a 3 07031500030d04091a05000000000000 ?l?l?l?l?l?l?l -O --quiet --potfile-disable\n07031500030d04091a05000000000000:hashcat\nroot@ht:~/hashcat#. 1)\nThere's no easy way to add support for rules in hybrid attack. You can however do it manually pretty easy:\n$ hashcat words.txt -r rules/toggle.rule --stdout -o newwords.txt\n$ hashcat -a6 newwords.txt ?d?d?d\n2) This is a feature, not a bug. By not feeding hashcat with enough wordlist candidates it can not make use of the parallelization power of a GPU. Read this: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n. I can not reproduce this locally. Feel free to reopen the issue with additional informations/steps how to reproduce this.\nroot@et:~/hashcat# cat > hash\na3aa0ae2b4a102a9974cdf40edeabee0:242812778074\nroot@et:~/hashcat# cat > word\nhashcat\nroot@et:~/hashcat# ./hashcat -m 3710 --quiet hash word --potfile-disable\na3aa0ae2b4a102a9974cdf40edeabee0:242812778074:hashcat\nroot@et:~/hashcat# ./hashcat -m 3710 --quiet hash word --potfile-disable -O\na3aa0ae2b4a102a9974cdf40edeabee0:242812778074:hashcat. Something's strange here!\nWhile your example from JSON works, bit it seems to be using a client from Sep 22, 2015, but this is the latest version 0 (or 1?) on GitHub (did it move somewhere else?).\nNow if you take a look at JtR which support cracking BitShares.Setup.2.0.180115.exe it access a sqlite database. The KDF is the same, but no more password_checksum field. It now needs an additional AES descrypt (plus it became salted) this way to find out if the password is correct.\nThe question is now what's the right algorithm and if there's actually 3 different algorithms (including the one from the backup files).. As stated on the webpage and all documentation, please use the Intel OpenCL runtime. POCL still seem to create problems with complex kernel. Using Intel OpenCL runtime will fix all your problems.. Did you run make clean after changing the variable in Makefile?. Yesterday I did a workaround on a mac os system which produced the same output. The problem was that the OpenCL runtime does not support loading cached kernels. Can you please clone the latest hashcat and hack the src/opencl.c and find the line which says:\nbool cache_disable = false;\nand change it to:\nbool cache_disable = true;\nAnd then run make to compile it and then retry?. It seems the clGetProgramBuildInfo() does not return any output. Otherwise, you'd have seen it after running make clean and sett DEBUG=1 in the Makefile.\nThis is a typical behavior if some implementation in the OpenCL runtime is missing. Therefore there's nothing we can do from hashcat perspective.. You're talking about byte, not bit. I can assume that since vbull (mode 2611) has salts of length 3 byte and 30 byte. However there's no way to do that for 6 byte, the keyspace is simply too big. The only exception would be if you know the Password, in that case you can easily BF a 6 byte salt. However, that would require a different kernel.. -a 3 -1 ?l?d ?1?1?1?1?1?1. As some large IT company would say: It's a feature, not a bug. And it actually is. Note that rules are applied on GPU (to avoid PCI-E bottleneck), therefore the host code can not know that some password candidated with a rule applied is > 8 chars. \nOTOH, it doesn't need to do and that's the reason why hashcat works that way and not the other way. You can do the following command instead:\nhashcat64.exe ..\\password.txt -r rules\\my.rule --stdout | hashcat64.exe -m 2500 ..\\bad.hccapx -w 3 -O\nThis should result in the behaviour you're expecting.\n. That the error is pretty clear. You've installed hashcat 4.1 in C:\\hashcat-4.1.0, however, in the other command you call C:\\hashcat\\hashcat64.exe. The path is a different one, therefore you are using a different hashcat version. This explains the different output, the different speed and (as @roycewilliams noted) the different handling of the current working directory. Everything fine for me, but feel free to reopen.. Can you please add some examples? There's a lot different interpretations possible.. OK, so my basic understanding was the same\n$! would instead be $21\n$0 would instead be $30\nMy problem was, it's also possible that the function itself could be written in hex, we would end up in:\n$! would instead be 2421\n$0 would instead be 2430\nAnd what about rules that use an offset, like insert rule:\ni0! would instead be i021\ni10 would instead be i130\nSo basically --hex-rules would only change the rules that use a character. It's not touching the function name nor the offset. That would be ok.\nWhen it comes to multibyte characters, this is very different than hex rules. There's a special ticket for that. We should not mix up things here.\nIn the end of all, what do we get from it. The only advantage I can see is that it becomes possible to add 0x0a easily. But it was possible all the time (it's just a bit more tricky to do). What I mean is that if you add for example the character 0x01 after the function $ then hashcat will append 0x01.\nWe should also note that supporting such a syntax will also change the way people will write rules. If people start writing rules with --hex-rules syntax they become incompatible with JtR rules for example.\nAlso I can see problems with parsing. Mixed up rules for example, because many user simply cat * > new.rule sometimes. A rule like this:\n$3c\nWould be valid in both syntaxes. In the current one it means \"append a 3, then capitalize\" but it will be also valid for the --hex-rule in which it would mean \"append <\". \n. What I tried to explain is that there are users that simply \"throw everything at it\" mentality. So what they do is that they create one large ruleset out of all rules they have. They don't care what the rules do in detail. If we start having hex rules in default rules/ folder then they will end up in a mixed ruleset build out of hex rules and non hex rules. The problem is, as I described above, that some rules will be parsed as \"valid\" in both cases, but their meaning is a different one, depending if you use --hex-rules or not.\nHowever, what I don't really see is why do we need this. I don't see any case where you can not use the engine as it is today.. All right, if that makes us even more compatible that's an ideal change.. OK, should work now, see commit: https://github.com/hashcat/hashcat/commit/b88c956d9754a56a99f45ebfa95767b65f8bf4eb. Looks like an installation error. Since there's no more m03100_a0.cl in latest version the only explanation is that you've overwritten the files into an existing folder (which is not supported). If I'm right you can remove the OpenCL folder and unpack it from installation archive, that should fix it. However, it's better to not reuse an existing folder.. I can totally not reproduce this locally. Maybe you should use hashcat from hashcat site and not from Kali. Here's what I did:\n```\nroot@ht:~/hashcat# cat hashes\nAdmin:f5e6da01af01000097a42cf27356aef866ef545ac4b9a762aaef010ca29c37ae40f69ebb3a74ecdf00000000000000000000000000000000140541646d696e:aa42b3a4cccc9ed949c94794dd0cc046e10128ce\nadmin:c5a53db2d854061a5ae8c28acc2a077b85859ede6ea952be1d2a00005a0b0000a74800008247000035383339313447423830333334354a44140561646d696e:d82a44aa893b842ca9659f6877f3c5c46374d607\nroot@ht:~/hashcat# cat words \n123\n1234\ntest\npentest\n12345678\n123456\nqwerty\nroot@ht:~/hashcat# ./hashcat -m 7300 hashes words --username -o cracked\nhashcat (v4.1.0-22-g469fece1+) starting...\n...\nHashes: 2 digests; 2 unique digests, 2 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\n...\nDictionary cache hit:\n Filename..: words\n Passwords.: 7\n Bytes.....: 45\n Keyspace..: 7\n...\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: IPMI2 RAKP HMAC-SHA1\nHash.Target......: hashes\nTime.Started.....: Wed Jun 13 16:59:40 2018 (0 secs)\nTime.Estimated...: Wed Jun 13 16:59:40 2018 (0 secs)\nGuess.Base.......: File (words)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    19611 H/s (0.05ms) @ Accel:128 Loops:1 Thr:512 Vec:1\nRecovered........: 2/2 (100.00%) Digests, 2/2 (100.00%) Salts\nProgress.........: 14/14 (100.00%)\nRejected.........: 0/14 (0.00%)\nRestore.Point....: 0/7 (0.00%)\nCandidates.#1....: 123 -> qwerty\nHWMon.Dev.#1.....: Temp: 37c Fan: 33% Util: 13% Core:1032MHz Mem:2700MHz Bus:16\nStarted: Wed Jun 13 16:59:37 2018\nStopped: Wed Jun 13 16:59:41 2018\nroot@ht:~/hashcat# cat cracked \nc5a53db2d854061a5ae8c28acc2a077b85859ede6ea952be1d2a00005a0b0000a74800008247000035383339313447423830333334354a44140561646d696e:d82a44aa893b842ca9659f6877f3c5c46374d607:12345678\nf5e6da01af01000097a42cf27356aef866ef545ac4b9a762aaef010ca29c37ae40f69ebb3a74ecdf00000000000000000000000000000000140541646d696e:aa42b3a4cccc9ed949c94794dd0cc046e10128ce:pentest\n```. I've tested again on different hardware (NV, AMD and CPU). I still can not reproduce this. Please feel free to reopen if you have additional information to reproduce, but make sure to use the latest version.. Note that for WPA it's perfectly ok to crack invalid passwords IF the user has used the wrong password. The difference to regular hashes is that we're cracking a captured network handshake, not a fixed hash. But this is a wanted behaviour: https://hashcat.net/forum/thread-6273.html. Not sure what you mean. A salt of length 16 is already supported in -m 10900.. Feel free to reopen the issue if you think there's some change needed.. The -m 10900 format expect the data given in base64, not hex. So you have to recode your salt and hash to base64 first:\nroot@ht:~/hashcat# perl -e 'print pack (\"H*\", \"DBE4ECEF10CED715D83F4F8BE938BE3DFEAB1DB7CB57DD16514E5623BBFB2F0B\")' | base64\n2+Ts7xDO1xXYP0+L6Ti+Pf6rHbfLV90WUU5WI7v7Lws=\nroot@ht:~/hashcat# perl -e 'print pack (\"H*\", \"239AC14998913570FC0F2E25001CB6F5\")' | base64\nI5rBSZiRNXD8Dy4lABy29Q==\nYou've also confused salt and hash, you need to swap it. The resulting hash looks like this:\nsha256:5000:I5rBSZiRNXD8Dy4lABy29Q==:2+Ts7xDO1xXYP0+L6Ti+Pf6rHbfLV90WUU5WI7v7Lws=\nYou can then simply crack it as usual:\n```\nroot@ht:~/hashcat# ./hashcat -m 10900 -a 3 sha256:5000:I5rBSZiRNXD8Dy4lABy29Q==:2+Ts7xDO1xXYP0+L6Ti+Pf6rHbfLV90WUU5WI7v7Lws= ?d?d?d?d?d?d?d?d\nhashcat (v4.1.0-26-g60f2d413) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 500/2000 MB allocatable, 5MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Brute-Force\n* Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nWatchdog: Temperature abort trigger set to 90c\nsha256:5000:I5rBSZiRNXD8Dy4lABy29Q==:2+Ts7xDO1xXYP0+L6Ti+Pf6rHbfLV90WUU5WI7v7Lws=:00000000\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: PBKDF2-HMAC-SHA256\nHash.Target......: sha256:5000:I5rBSZiRNXD8Dy4lABy29Q==:2+Ts7xDO1xXYP0...v7Lws=\nTime.Started.....: Thu Jun 14 20:51:16 2018 (6 secs)\nTime.Estimated...: Thu Jun 14 20:51:22 2018 (0 secs)\nGuess.Mask.......: ?d?d?d?d?d?d?d?d [8]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    33498 H/s (9.51ms) @ Accel:32 Loops:16 Thr:640 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 204800/100000000 (0.20%)\nRejected.........: 0/204800 (0.00%)\nRestore.Point....: 0/10000000 (0.00%)\nCandidates.#1....: 02345678 -> 07689012\nHWMon.Dev.#1.....: Temp: 44c Fan: 33% Util: 97% Core:1189MHz Mem:2700MHz Bus:16\nStarted: Thu Jun 14 20:51:10 2018\nStopped: Thu Jun 14 20:51:23 2018\n```\nWhen it comes to Driver temperature threshold, it's usually set to 79c on nvidia on windows. If you stick below it, everything is fine, otherwise the driver clocks down the GPU a bit.\n. OK, thanks for reporting. That's one of the reason why I've added the self-test functionality, to find out invalid OpenCL drivers/runtimes. It's good to see it' s working. The reason you didn't see it in 3.5 is because this feature was added in 4.0.0\nThe suggestion to stop hashcat in such a case can be discussed. We could make it like that and only if the user specified --force hashcat will continue.. Added with commit https://github.com/hashcat/hashcat/commit/469fece141384e766739f88b4f4ddced6d927a51. Looks good to me. You have multiple handshakes, therefore you have a loss in speed. \nIf there's many handshakes, hashcat does not display the mac addresses since they could be all different. So this is just a display thing.\nIf you want full speed, select a single handshake.. To get the idea behind the hccapx format (which supports the multiple handshake cracking), you should read this: https://hashcat.net/forum/thread-6273.html\nThere's some advantages over single handshake cracking. Looks like the content of that file is not a hash, so the error is a correct one.. What's the size of the file?. If you use a maskfile you need to define the custom charset in the maskfile. See here for reference:\nhttps://hashcat.net/wiki/doku.php?id=mask_attack#hashcat_mask_files\nIn the past we had support for -1 to be used from a mask file, but it was kind of confusing. A user had multiple lines of masks in his maskfile (which is supported) but wanted to use different custom charsets for each of the masks.\nSince this is a topic for hashcat forum I'm closing it here.. Thanks for answer @DerBunteBall \nHowever this is a usage topic and therefore should be moved to hashcat forum and closing here.. Thanks! Indeed I've worked too close to how utf-8 defines a valid sequence. It's better to leave out 0x00 - 0x1f. Should be fixed with https://github.com/hashcat/hashcat/commit/60f2d413e04f67ab39fbf80e8f356a097f29919e. Right, this goes back to the problem that the format system of hashes and salts are flawed in the first place. The only way to solve this is to make sure to not have the colon character as part of the password, which is why we will autohex it. So this is a bug, but not a bug in hashcat and therefore there's no way to solve it.. This is a question better suited to the hashcat forums.. Hashcat support cracking WPA/WPA2 handshakes in -m 2500 mode.. That makes it even more easy. Just use -m 12000.. The good thing is, hashcat informs you about the invalid kernel processing on startup:\n* Device #2: ATTENTION! OpenCL kernel self-test failed.\nHowever, it's not a hashcat problem. I've traced the intermediate keys up to the comparison kernel (where AES comes into play). Both the AES key and the IV is correctly computed on rocm. \nThe next step would be to initialize the AES key scheduler array and on here (using the same shared library code) rocm start computing invalid values. All other tested OpenCL runtimes (NVidia, Intel, pocl, etc) compute it correctly.\nThe key scheduler access a shared memory region of the GPU to make it faster. You can however disable this behavior and make it access constant memory region. If we do this you can see how rocm starts to crack without changing any of the code portion. You can reproduce locally by commenting out line 24 in inc_vendor.cl and remove the kernel/ cache folder entirely. \nNote that the same shared AES function are used in many other kernels (truecrypt 6221 for example) and they work fine over there. This is not a problem in how shared memory is accessed.\nI was able to further track down the issue to this data copy from constant memory to shared memory in m11300_comp() function in m11300.cl:\ns_td0[i] = td0[i];\nSo basically there's nothing we can do to make this more easy. If this doesn't work it's for sure a JiT compiler problem.. Why, do you have new informations?. Probably a Mesa problem. Please retry with rocm.. I've heared about segfaults when using RX480/580 in combination with rocm on a non pcie-3.0 board. In that case, use amdgpu-pro in legacy mode.. Only the first slot seems to be PCIE 3.0. Anyway, if it fails inside rocm there's nothing we can do. It's an opencl runtime problem. Try the workaround I've suggested.. Please use ROCM (preferred) or AMDGPU driver for rx480/580 and uninstall the Mesa OpenCL runtime. IT will fix the problem. Feel free to reopen if it did not work.. I can't reproduce this locally either on GPU nor on CPU. Maybe you can give some details about the hardware and OpenCL driver being used.\nYou can also try using --opencl-vector-width 1. I don't have such a debugging gathering info. Let's start with output of clinfo and hashcat -I. I think I found the root cause of the problem, which is a problem in AMD OpenCL runtime. Luckily I was able to workaround the problem with this commit: https://github.com/hashcat/hashcat/commit/14c444fd47f9307e06dea0769c6060ac1ebec7a7\nIf you pull hashcat github master you should be able to crack it. Thanks for reporting!\n. Do not use pocl, use intel opencl runtime for xeon.. In theory yes, but that doesn't make much sense if you don't know the password. It could make sense if you know the password. However, in such a case a different tool would be more appropriate. \nHowever where did read about the maximum of 9999 for PIM?. Double request. Yeah, looks like OpenCL installation problem. Anyway, hashcat is not tested on android.. Thanks!. I don't get them with gcc 8 :(. Usually that's when there's the OpenCL runtime is load. Please make sure you have a clean OpenCL installation. Please send clinfo output.. Which driver are you using?. > same happens on hashcat64.exe -I command (i am using hashcat v3.6.0)\nThen it's clearly an opencl runtime installation problem. It's possible that nvidia made an error here, not you users. Pretty sure that no OpenCL application will run on your systems. Feel free to reopen if I'm wrong.. > Clearly should be fixed in hashcat.\nThis file is the OpenCL runtime from Intel Graphicscard (IG) driver (DR) for OpenCL (CL). It's automatically load by the OpenCL ICD in order to find out about existing OpenCL platforms. The ICD get's installed by your driver.\nThere's no relation to hashcat in any way. The same error would occur with any other OpenCL application. \nThere's also no way of checking this kind of (user installation) error on start because hashcat does not control this process.. You can try using your code by using this branch selection:\nuser_options_extra_t *user_options_extra  = hashcat_ctx->user_options_extra;\nif (user_options_extra->attack_kern == ATTACK_KERN_COMBI)\n{\n... your code\n}\nelse\n{\n  ... existing code\n}\nAdd some test cases and send in a PR. Any update on this?. If you think this is still valid please feel free to reopen. Please use https://github.com/hashcat/hashcat/issues/83. Please use https://github.com/hashcat/hashcat/issues/83. Do not confuse two different things.\nWhen it comes to the include headers use the original ones from KhronosGroup (see BUILD.md).\nWhen it comes to hashcat -I you better use rocm for AMD GPU on Linux and Intel OpenCL runtime for AMD CPU on any OS.\nAnyway this topic is not suited for github issues, please use hashcat forum for usage questions.\n. $ cd /usr/lib/llvm-6.0/lib/clang/\n$ ln -s 6.0.1 6.0.0\n. Works fine on my system.\n```\n78972e04454d4b2246a3957747806e37:94103ee1ac2c:f4a99785929c:belkin.c2c:3wafm3w4\n52340951edfa73c507c11dc2c44de3ed:94103ee1ac2c:5c521e9fa24c:belkin.c2c:3wafm3w4\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: test.hccapx\n```. No response from OP for two weeks, probably OpenCL runtime installation error. I've added this with commit https://github.com/hashcat/hashcat/commit/8903adb164ce6e6c554dc9cb9634a725dabcceb0\nThere's no new status flag, it's simply appended to the end of line. Let's see if there's anyone complaining, then we can add it with status flag.. No response from OP for too long. No response from OP, feel free to reopen. There's no workaround known. ROCm is still the best driver. amdgpu-pro drivers (both modes) are even worse (in other modes), thus we recommend ROCm.. You can not use hashcat without an OpenCL runtime, even if it's just stdout mode. The password candidate modificatinos (rules, combinator, etc) are still done inside an OpenCL kernel. You do not need a GPU. Every CPU should be fine by using Intel OpenCL runtime (even for non-Intel CPU).. Clearly OpenCL runtime error (uses LLVM). Which driver do you use?. No response from OP, feel free to reopen. We need some example data to work with (plus password).. Wait there's something wrong with your installation. I've tested with exact your command and it works fine. I've even tested the restore functionality which works fine. So for me it looks you're trying to restore from an incompatible file which has been created from an older version of hashcat. I think you really need to make sure you're using the latest version of hashcat. A good sign that you're not using the latest version is that you did not use ./ in front of hashcat and eventually executed an older 2nd installation of hashcat. Maybe you used \"make install\" or you have another hashcat installation from your OS repostory. Anyway, not a hashcat problem here.. I find it strange that there's a vendor specific function \"amd_bytealign\" in an Intel Graphic Card driver. However I've renamed some of the function in order to deal with this problem. If you can please retry with latest version from GitHub.. There's something horrible broken in your installation. For example, \"uchar\" is a basic datatype in OpenCL. There's no way an OpenCL JiT can not understand that. Not a hashcat problem.. Example sent. I'm fine with the .dylib change, the other ones I don't understand. Please explain what's going on there and why it is needed. Please send multiple PR for multiple changes.. Note that with commit https://github.com/hashcat/hashcat/commit/2530f83029da1f657ae54bea62f2a1d90a806b99 I've moved out the LZMA files from the include folder, therefore the change in the installation routines in your PR should no longer be neccessary. Looks like a good fix to me. Please send in a PR.. Thanks. Thanks!. Thanks!. Please explain why we need to do this and what's happening in case we do not merge this PR. \n. > Currently the first library pathname checked is the executing shell's $PWD/libhashcat.\nThis sounds really strange to me. In Linux, there's no library search path for \".\" because of the security implication this creates. Here's an older issue that dealt with the same problem: https://github.com/hashcat/hashcat/issues/956\n\nIf there isn't a libhashcat in $PWD, then the default library paths are checked. This can cause misbehavior\n\nWait here, what kind of misbehavior are you talking about?\n\nso the PR changes it to the executable path for the initial build (in case the library is used in place)\n\nOK, but wouldn't this create a relative path which is what we need to avoid (see the issue linked above)?. Why is this so different to Linux or Unix in general? Usually if you have a shared library you copy it to /usr/lib or whatever folder your distribution uses for this case. Done.\nIf you don't want to copy the shared library you set LD_LIBRARY_PATH to the folder where you did installed the library. This can be \".\", too. Is there no LD_LIBRARY_PATH on macOS?. OK, thanks!. Should be fixed with commit https://github.com/hashcat/hashcat/commit/9d431117309e51d0a29bb16daa8ac01ba15a77ee\nMany thanks for reporting!. Please use rli or rli2 from hashcat-utils. It makes no sense from a technical perspective:\nIf you want to crack fast hashes (MD5 etc) then a check between existing such an exclude wordlist would slow down the attack more than it would benfit from it. IOW, it's faster to check passwords even if they have been tested already.\nIf you want to crack slow hashes (TrueCrypt etc) it would eventually make sense, however you can also write the candidates first to a file (use --stdout) and then apply rli/rli2 on it.\n. Right, but the disk space required can not be that large for slow hashes (like WPA) because if it's really that large, the attack makes no sense anyway.. There's no problem with special characters in rules, you just need to know that rules work byte-wise. IOW, you need to encode your rule as ISO and not UTF-8. You can use iconv to convert. However, that's a question for hashcat forum, therefore closing this issue.. On my GTX750Ti I have very similar values to yours:\nGTX750Ti:\nGlobal memory size                              2098069504 (1.954GiB)\n  Max memory allocation                           524517376 (500.2MiB)\nGTX960:\nGlobal memory size 2064121856 (1.922GiB)\nMax memory allocation 516030464 (492.1MiB)\nYour Driver Version : 390.77 is fine, too.\nNo idea why this error occurs.. Sure, please install Ubuntu 16.04 or 18.04 on the box, then we can start debugging (as you know Kali is not supported).. Sorry man there's no way around Ubuntu.. Correct. See if the error still occurs. If yes, please come to IRC freenode channel #hashcat and msg me directly (atom) - then wait.. Any update here?. I was able to reproduce this on my development system, but it required me to have a second instance of hashcat running in parallel. The reason is that with OpenCL there's actually no way to check if the total available OpenCL device memory is free to use or not. That means if you have X11 running on the GPU (or any other application that requires GPU memory, miners, games, browser, etc) than this error will occur.\nPlease check if the error still exists with hashcat v4.2.0 and if yes, please execute nvidia-smi and post the output here.. All right, that's nice. Looks like we just identified another problem related to Kali. So it takes 640mb on your X11, for whatever reason. Can you please shutdown x11 and try to run hashcat from the console directly?. OK based on this information I tried to workaround the problem by checking for available memory before actually running a kernel. I've pushed a beta version of this workaround here: https://hashcat.net/beta/\nCan you please retry your tests with this beta version please.. OK, cool. The workaround is a bit hackish. We have to test it on all the different opencl runtimes, but I think I will let it stay as it is. Thanks for your report! No need to shutdown X11.. > I am seeing this error on Ubuntu 16.04 but with -m 1811\nPlease retry with latest beta version from https://hashcat.net/beta/ or github master and report if it fixes the error for you.. Fixed with commit https://github.com/hashcat/hashcat/commit/39af031ced759117fc7c067722950072f1827abd . That's only possible before applying rules (or any other form of amplifier).\nYou can use something like this:\n./hashcat --stdout example.dict -j '>B'\n007ambiorix\n007matthias\n01Neunauge10\n03chevrolet\n03coffeeman\n03liverpool\n03montessori\n03salvatore\n...\n. Yeah there's no useful way to do this on GPU since you have to spawn the thread anyway and then it has to wait for the others to complete, we can not request \"next\" in this case. For slow hashes you can use the method I've shown and pipe to hashcat.. This is great! Can you add test.sh and test.pl cases please?. Almost perfect, I'll merge this. There's three minor things missing for perfection:\n\nMissed entry in read docs/readme.txt\nMissed entry in read extra/tab_completion/hashcat.sh \nInstead of OPTS_TYPE_HASH_COPY add the missing/unused attributes to an extra attribute in esalt so you can rebuild the original string using sprintf in ascii_digest()\n\nThe perl stuff looks good, too.. Thanks!. Fixed with commit https://github.com/hashcat/hashcat/commit/afd1efd59c33cf6120cf9e9e97ddb8d7daf6587f\nYou can use latest github master or latest beta from https://hashcat.net/beta for testing\nThanks for report!. Perfect!. At least 1.5GB host memory per OpenCL device. Thanks!. Is there a reason why we developers have to do that? Usually it's done by package maintainers.. No reponse from OP, therefore closing the discussion. Feel free to reopen.. Fixed both problems. You can either rebuild using github master or use the binary from https://hashcat.net/beta/ or wait for the next release. Thanks for reporting!. Please retry with latest hashcat beta from https://hashcat.net/beta/ and post the entire output again using this version.. No response from OP for a long time and probably just a driver issue, therefore closing. Feel free to reopen if any new insights come in.. There's a special parsing module for 9700 called the native output format. If you select --username, the first column is skipped, therefore the native parser can no longer parse it and gives that specific error message.\nThere's not many hash-modes that support native output format, therefore you didn't face that problem with other hash-modes.\nThe only way to make this work is to either remove the native loader (which I think is a good thing) or to not use --username. Please tell @s3inlc to not automatically use --username in this case.. Not a hashcat error. Did you try the impact of the change on fast hash single hash brute-force? What's the speed loss or is it even faster?. I benchmark the changes you made and I can't find any differences. Therefore I'm not going to merge this. \nHowever, while I was checking the changes I came up with a different solution that actually increased the performance a lot (almost doubled):\n```\ndiff --git a/OpenCL/inc_hash_md4.cl b/OpenCL/inc_hash_md4.cl\nindex bce232d..17994c1 100644\n--- a/OpenCL/inc_hash_md4.cl\n+++ b/OpenCL/inc_hash_md4.cl\n@@ -1558,6 +1558,58 @@ DECLSPEC void md4_update_vector_utf16le_swap (md4_ctx_vector_t *ctx, const u32x\n   md4_update_vector_64 (ctx, w0, w1, w2, w3, (len - pos1) * 2);\n }\n+DECLSPEC void md4_update_vector_local (md4_ctx_vector_t ctx, __local u32 w, const int len, const u32x w0r)\n+{\n+  u32x w0[4];\n+  u32x w1[4];\n+  u32x w2[4];\n+  u32x w3[4];\n+\n+  w0[0] = w[ 0] | w0r;\n+  w0[1] = w[ 1];\n+  w0[2] = w[ 2];\n+  w0[3] = w[ 3];\n+  w1[0] = w[ 4];\n+  w1[1] = w[ 5];\n+  w1[2] = w[ 6];\n+  w1[3] = w[ 7];\n+  w2[0] = w[ 8];\n+  w2[1] = w[ 9];\n+  w2[2] = w[10];\n+  w2[3] = w[11];\n+  w3[0] = w[12];\n+  w3[1] = w[13];\n+  w3[2] = w[14];\n+  w3[3] = w[15];\n+\n+  int pos1;\n+  int pos4;\n+\n+  for (pos1 = 0, pos4 = 16; pos1 < len - 64; pos1 += 64, pos4 += 16)\n+  {\n+    md4_update_vector_64 (ctx, w0, w1, w2, w3, 64);\n+\n+    w0[0] = w[pos4 +  0];\n+    w0[1] = w[pos4 +  1];\n+    w0[2] = w[pos4 +  2];\n+    w0[3] = w[pos4 +  3];\n+    w1[0] = w[pos4 +  4];\n+    w1[1] = w[pos4 +  5];\n+    w1[2] = w[pos4 +  6];\n+    w1[3] = w[pos4 +  7];\n+    w2[0] = w[pos4 +  8];\n+    w2[1] = w[pos4 +  9];\n+    w2[2] = w[pos4 + 10];\n+    w2[3] = w[pos4 + 11];\n+    w3[0] = w[pos4 + 12];\n+    w3[1] = w[pos4 + 13];\n+    w3[2] = w[pos4 + 14];\n+    w3[3] = w[pos4 + 15];\n+  }\n+\n+  md4_update_vector_64 (ctx, w0, w1, w2, w3, len - pos1);\n+}\n+\n DECLSPEC void md4_final_vector (md4_ctx_vector_t ctx)\n {\n   MAYBE_VOLATILE const int pos = ctx->len & 63;\ndiff --git a/OpenCL/m00900_a3-pure.cl b/OpenCL/m00900_a3-pure.cl\nindex 5ca3027..9c93234 100644\n--- a/OpenCL/m00900_a3-pure.cl\n+++ b/OpenCL/m00900_a3-pure.cl\n@@ -19,10 +19,9 @@ __kernel void m00900_mxx (__global pw_t pws, __global const kernel_rule_t rule\n    * modifier\n    /\n\nconst u64 lid = get_local_id (0);\n   const u64 gid = get_global_id (0);\n-\nif (gid >= gid_max) return;\nconst u64 lid = get_local_id (0);\nconst u64 lsz = get_local_size (0);\n\n/\n    * base\n@@ -30,32 +29,30 @@ __kernel void m00900_mxx (__global pw_t pws, __global const kernel_rule_t rule\nconst u32 pw_len = pws[gid].pw_len;\n\nu32x w[64] = { 0 };\n\n__local u32 w[64];\n\n\nfor (int i = 0, idx = 0; i < pw_len; i += 4, idx += 1)\n\nfor (MAYBE_VOLATILE u32 i = lid; i < 64; i += lsz)\n   {\nw[idx] = pws[gid].i[idx];\n\nw[i] = pws[gid].i[i];\n   }\n\n\nbarrier (CLK_LOCAL_MEM_FENCE);\n+\n\nif (gid >= gid_max) return;\n+\n   /**\nloop\n*/\n\n\n\n-  u32x w0l = w[0];\nfor (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE)\n   {\n     const u32x w0r = words_buf_r[il_pos / VECT_SIZE];\n-    const u32x w0 = w0l | w0r;\n-    w[0] = w0;\n md4_ctx_vector_t ctx;\n\n md4_init_vector (&ctx);\n\n\nmd4_update_vector (&ctx, w, pw_len);\n\nmd4_update_vector_local (&ctx, w, pw_len, w0r);\nmd4_final_vector (&ctx);\n\n\n@@ -74,10 +71,9 @@ __kernel void m00900_sxx (__global pw_t pws, __global const kernel_rule_t rule\n    * modifier\n    */\n\nconst u64 lid = get_local_id (0);\n   const u64 gid = get_global_id (0);\n-\nif (gid >= gid_max) return;\nconst u64 lid = get_local_id (0);\nconst u64 lsz = get_local_size (0);\n\n/\n    * digest\n@@ -97,13 +93,17 @@ __kernel void m00900_sxx (__global pw_t pws, __global const kernel_rule_t rule\nconst u32 pw_len = pws[gid].pw_len;\n\nu32x w[64] = { 0 };\n\n__local u32 w[64];\n\n\nfor (int i = 0, idx = 0; i < pw_len; i += 4, idx += 1)\n\nfor (MAYBE_VOLATILE u32 i = lid; i < 64; i += lsz)\n   {\nw[idx] = pws[gid].i[idx];\n\nw[i] = pws[gid].i[i];\n   }\n\n\nbarrier (CLK_LOCAL_MEM_FENCE);\n+\n\nif (gid >= gid_max) return;\n+\n   /**\nloop\n/\n@@ -114,15 +114,11 @@ __kernel void m00900_sxx (__global pw_t pws, __global const kernel_rule_t *rule\n   {\n const u32x w0r = words_buf_r[il_pos / VECT_SIZE];\n\n\n\n-    const u32x w0 = w0l | w0r;\n-    w[0] = w0;\n md4_ctx_vector_t ctx;\n\n md4_init_vector (&ctx);\n\n\nmd4_update_vector (&ctx, w, pw_len);\n\nmd4_update_vector_local (&ctx, w, pw_len, w0r);\nmd4_final_vector (&ctx);\n\n\n```\nWith your PR you have shown a good understanding of the core functions for OpenCL kernels. I'd be happy to let you try to implement this optimization to the remaining kernels. If you do, please inform me so we don't do double work. If not, I'll maybe implement it when I find some time to do it.\n. Well that's typically a problem with AMD compiler. It works fine on my testing CPU. Retry with that.. I found the source of the problem. Here's a patch that should work:\n```\ndiff --git a/OpenCL/inc_hash_md4.cl b/OpenCL/inc_hash_md4.cl\nindex bce232d..81c3f57 100644\n--- a/OpenCL/inc_hash_md4.cl\n+++ b/OpenCL/inc_hash_md4.cl\n@@ -1558,6 +1558,55 @@ DECLSPEC void md4_update_vector_utf16le_swap (md4_ctx_vector_t *ctx, const u32x\n   md4_update_vector_64 (ctx, w0, w1, w2, w3, (len - pos1) * 2);\n }\n+DECLSPEC void md4_update_vector_local (md4_ctx_vector_t ctx, __local u32 w, const int len, const u32x w0r)\n+{\n+  u32x w0[4];\n+  u32x w1[4];\n+  u32x w2[4];\n+  u32x w3[4];\n+\n+  w0[0] = w[ 0] | w0r;\n+  w0[1] = w[ 1];\n+  w0[2] = w[ 2];\n+  w0[3] = w[ 3];\n+  w1[0] = w[ 4];\n+  w1[1] = w[ 5];\n+  w1[2] = w[ 6];\n+  w1[3] = w[ 7];\n+  w2[0] = w[ 8];\n+  w2[1] = w[ 9];\n+  w2[2] = w[10];\n+  w2[3] = w[11];\n+  w3[0] = w[12];\n+  w3[1] = w[13];\n+  w3[2] = w[14];\n+  w3[3] = w[15];\n+\n+  md4_update_vector_64 (ctx, w0, w1, w2, w3, min (len, 64));\n+\n+  for (int pos1 = 64, pos4 = 16; pos1 < len; pos1 += 64, pos4 += 16)\n+  {\n+    w0[0] = w[pos4 +  0];\n+    w0[1] = w[pos4 +  1];\n+    w0[2] = w[pos4 +  2];\n+    w0[3] = w[pos4 +  3];\n+    w1[0] = w[pos4 +  4];\n+    w1[1] = w[pos4 +  5];\n+    w1[2] = w[pos4 +  6];\n+    w1[3] = w[pos4 +  7];\n+    w2[0] = w[pos4 +  8];\n+    w2[1] = w[pos4 +  9];\n+    w2[2] = w[pos4 + 10];\n+    w2[3] = w[pos4 + 11];\n+    w3[0] = w[pos4 + 12];\n+    w3[1] = w[pos4 + 13];\n+    w3[2] = w[pos4 + 14];\n+    w3[3] = w[pos4 + 15];\n+\n+    md4_update_vector_64 (ctx, w0, w1, w2, w3, min (len - pos1, 64));\n+  }\n+}\n+\n DECLSPEC void md4_final_vector (md4_ctx_vector_t ctx)\n {\n   MAYBE_VOLATILE const int pos = ctx->len & 63;\ndiff --git a/OpenCL/m00900_a3-pure.cl b/OpenCL/m00900_a3-pure.cl\nindex 5ca3027..6f945cc 100644\n--- a/OpenCL/m00900_a3-pure.cl\n+++ b/OpenCL/m00900_a3-pure.cl\n@@ -28,11 +28,13 @@ __kernel void m00900_mxx (__global pw_t pws, __global const kernel_rule_t rule\n    * base\n    /\n\n\n__local u32 wx[64][64];\n+\n   const u32 pw_len = pws[gid].pw_len;\n\n\nu32x w[64] = { 0 };\n\n\n__local u32 *w = wx[lid];\n\n\nfor (int i = 0, idx = 0; i < pw_len; i += 4, idx += 1)\n\nfor (int idx = 0; idx < 64; idx++)\n   {\n     w[idx] = pws[gid].i[idx];\n   }\n@@ -41,21 +43,15 @@ __kernel void m00900_mxx (__global pw_t pws, __global const kernel_rule_t rule\nloop\n*/\n\n\n\n-  u32x w0l = w[0];\nfor (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE)\n   {\n     const u32x w0r = words_buf_r[il_pos / VECT_SIZE];\n-    const u32x w0 = w0l | w0r;\n-    w[0] = w0;\n md4_ctx_vector_t ctx;\n\n md4_init_vector (&ctx);\n\n\nmd4_update_vector (&ctx, w, pw_len);\n\nmd4_update_vector_local (&ctx, w, pw_len, w0r);\nmd4_final_vector (&ctx);\n\n\n@@ -95,11 +91,13 @@ __kernel void m00900_sxx (__global pw_t pws, __global const kernel_rule_t rule\n    * base\n    */\n\n\n__local u32 wx[64][64];\n+\n   const u32 pw_len = pws[gid].pw_len;\n\n\nu32x w[64] = { 0 };\n\n\n__local u32 *w = wx[lid];\n\n\nfor (int i = 0, idx = 0; i < pw_len; i += 4, idx += 1)\n\nfor (int idx = 0; idx < 64; idx++)\n   {\n     w[idx] = pws[gid].i[idx];\n   }\n@@ -108,21 +106,15 @@ __kernel void m00900_sxx (__global pw_t pws, __global const kernel_rule_t rule\nloop\n*/\n\n\n\n-  u32x w0l = w[0];\nfor (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE)\n   {\n     const u32x w0r = words_buf_r[il_pos / VECT_SIZE];\n-    const u32x w0 = w0l | w0r;\n-    w[0] = w0;\n md4_ctx_vector_t ctx;\n\n md4_init_vector (&ctx);\n\n\nmd4_update_vector (&ctx, w, pw_len);\n\nmd4_update_vector_local (&ctx, w, pw_len, w0r);\nmd4_final_vector (&ctx);\n\n\ndiff --git a/src/interface.c b/src/interface.c\nindex d85ddd8..e532578 100644\n--- a/src/interface.c\n+++ b/src/interface.c\n@@ -27664,7 +27664,8 @@ u32 hashconfig_forced_kernel_threads (hashcat_ctx_t *hashcat_ctx)\nu32 hashconfig_get_kernel_threads (hashcat_ctx_t hashcat_ctx, const hc_device_param_t device_param)\n {\n-  const hashconfig_t hashconfig = hashcat_ctx->hashconfig;\n+  const hashconfig_t   hashconfig   = hashcat_ctx->hashconfig;\n+  const user_options_t *user_options = hashcat_ctx->user_options;\n// a kernel can force a fixed value\n@@ -27720,6 +27721,20 @@ u32 hashconfig_get_kernel_threads (hashcat_ctx_t *hashcat_ctx, const hc_device_p\n     }\n   }\n\n// we can improve performance for pure fast-hash kernels in BF mode by using local memory\n// but therefore we have to limit the thread count\n+\nif (user_options->attack_mode == ATTACK_MODE_BF)\n{\nif (hashconfig->attack_exec == ATTACK_EXEC_INSIDE_KERNEL)\n{\nif ((hashconfig->opti_type & OPTI_TYPE_OPTIMIZED_KERNEL) == 0)\n{\nkernel_threads = MIN (kernel_threads, 64);\n}\n}\n}\n+\n   return kernel_threads;\n }\n\n```\nMake sure to run make clean before.\nThe problem is that the performance improvement now is not that much anymore. On my rx480 the speed only went up from 4.4GH/s to 5.1GH/s. However, on all my GTX cards it dropped by almost the half. Therefore I'm no longer going this path because there's much more NV users than there is AMD users.. Very likely to be a problem with the HD Graphics 520. Retry with -D1 too check if the CPU works. Please continue this thread on hashcat forum, this is not a hashcat problem and shouldn't discussed here.. Fixed with https://github.com/hashcat/hashcat/commit/a4ac370496d030777a5d5d65a894ac6bc2f953c6\nIf you don't want to wait for next release you can use latest github master or beta from https://hashcat.net/beta/\nThanks for reporting!. Please reinstall Intel OpenCL runtime for CPU. Do not install any SDK. Do not install GPU support.. Please retry with hashcat 5.0.0 and reopen if not fixed.. Not a hashcat issue. No response from OP for a long time plus probably driver error therefore closed. Feel free to reopen if you have no insights.. In this case the mask is longer than 16, because ?h gets expanded internally, plus the 8d so you'll end up with 9 characters. I can't see a problem here.. For me it looks like you are using a broken github clone. Ideally re-clone the entire hashcat source from scratch.. Since this algorithm is known to have a dynamic iteration count, I agree with @Chick3nman theory. Feel free to reopen this issue if you want, but please provide both hash lines so we can reproduce locally.. Memleaks come from OpenCL runtime not hashcat. Please inform driver vendors instead.. Fixed with https://github.com/hashcat/hashcat/commit/a4ac370496d030777a5d5d65a894ac6bc2f953c6\nIf you don't want to wait for next release you can use latest github master or beta from https://hashcat.net/beta/\nThanks for reporting!\n. Not a hashcat problem anyway. Looks nice, please send in PR with all functions affected. Ideally you can use tools/code_generators/ and add or modify a perl script. Those are responsible for doing the changes.. Based on the changes your did with your latest PR, are you going to add this change in form of a new code generator or did you do already? If yes, could please PR the changes to the inc_common.cl as well?. Implemented with commit https://github.com/hashcat/hashcat/commit/e1fe3e755b54c0dd8ccb5c6a0bc3a7f48f4c9693\nNot exactly the same way but performance improvement should be the same or better.. GPU is too old. If you want to make use of the CPU uninstall MESA and install Intel OpenCL runtime (works good with AMD CPU).. hashcat is reading wordlists bytewise, therefore it misinterprets the first bytes which ar part of the BOM header as part of the first password. \nAdditionally, new users try out hashcat just to see if it works and then they place a correct test password in the first line of the wordlist. If they do that including a BOM, then hashcat will not find the expected password and new users are disappointed.\nAnyway wordlists should not include BOM because the functionality is ignore anyway.. I can reproduce this with the following command:\n\ntype example.dict | hashcat64.exe -m 400 example400.hash\n\nBut it requires the latest github master version (or binary beta from hashcat.net/beta). Older versions 4.1.0, 4.2.0 and 4.2.1 seem not affected.\n. No response from OP and probably an error in a third party overlay, therefore closing issue. Feel free to reopen.. Good info for start, thanks. Looks doable :). Fixed with https://github.com/hashcat/hashcat/commit/a4ac370496d030777a5d5d65a894ac6bc2f953c6\nIf you don't want to wait for next release you can use latest github master or beta from https://hashcat.net/beta/\nThanks for reporting!\n. \nThis line:\n\notp_code = ((ctx.opad.h[otp_offset/4] & 0xffffff) << 8) | ((ctx.opad.h[otp_offset/4+1] % 0xffffff00) >> 24);\n\nYou do:\n\n(ctx.opad.h[otp_offset/4] & 0xffffff) << 8\n\nThis is fine, but then you do:\n\n(ctx.opad.h[otp_offset/4+1] % 0xffffff00) >> 24\n\nThis looks like some bytewise align, IF you'd have used & 0xffffff00 and not % 0xffffff00. \nThe outcome with both operators should be the same, but I think you can replace it with & and make it more logical than arithmetic.\nThis line:\n\ns[idx] = swap32_S (salt_bufs[salt_pos].salt_buf[idx]);\n\nYou can, if you want, do the swapping in the parser code. \nThis has the advantage that hashcat don't has to call swap32_S() again and again in the kernel. \nI doubt it will give alot of performance increase on GPU, but maybe on a slow CPU you can see the difference. Note that you will have to do another swap() in the ascii_digest() to synchronize it with the original salt.\n\nswitch(otp_offset%4)\n\nOn some systems, &3 is faster than %4 while the result is the same\nIf you write a mask like this \n\n0xffffff\n\nand also use a mask like this:\n\n0xffffff00\n\nIt's better to write 0x00ffffff instead of 0xffffff. This keeps the code aligned in width. While it's the same for the compiler, it's much easier for the human brain to figure out the idea if it does have to deal with alignment.\nOne more thing:\nWe can assume this mode to produce tons of collisions. Since this is the expected behavior, you can tell hashcat to enable --keep-guessing by setting it in the hash-mode switch case:\nopts_type |= OPTS_TYPE_PT_NEVERCRACK;\nThis will tell hashcat about to continue cracking\n. > Added hash-mode 18100 = TOTP (HMAC-SHA1)\nand this:\n\nstatic const char *HT_18100 = \"TOTP (HMAC-SHA1)\";\n\nand this:\n\n18100 | TOTP (HMAC-SHA1)  ...\n\nDidn't you want to change this to Onetime Token or something?\n\nunsigned long timestamp = 0;\n timestamp = hc_strtoul ((const char *) salt_pos, NULL, 10);\n\nTwo things here:\n\nDo we really want to use unsigned long? Using long datatypes is bad coding practise because it changes it's size depending on the 32 or 64 bit compilation. It's better to use u32 or u64 instead.\nIf both line should be put in the same line to make it easier to read:\n\nunsigned long timestamp = hc_strtoul ((const char *) salt_pos, NULL, 10);\n\nif (hashconfig->opts_type & OPTS_TYPE_ST_HEX)\n {\n   token.len_min[1] = 2;\n   token.len_max[1] = 2;\n   token.attr[1] |= TOKEN_ATTR_VERIFY_HEX;\n }\n\nIs there a reason to allow hex encoded salts? From what I've seen, the salt is already encoded.\n\nint otp_code = 0;\n for (int i = 0; i < 6; i++)\n\nFormatting:\nPlease put in a blank line here\n\notp_code = otp_code * 10 + itoa32_to_int (input_buf[i]);\n\nThis line is the same as with the hc_strtoul. Please don't do two steps at once, it makes it hard to read.\nPlease convert it first into a dedicated fixed size buffer and then use hc_strtoul to convert it to a number.\n\ntimestamp >> 32\n\nBy seeing this it means you probably want to use u64 for timestamp, not u32.\n\nsalt->salt_buf[1] = byte_swap_32 (timestamp);\nsalt->salt_buf[0] = byte_swap_32 (timestamp >> 32);\n\nPlease think on the easy read code again. In this case, we do this instead:\nsalt->salt_buf[1] = byte_swap_32 (timestamp >>  0);\nsalt->salt_buf[0] = byte_swap_32 (timestamp >> 32);\nI know it's kind of OCD but it actually has some meaning.\nHowever, you're about to assing a u64 to an u32 input of that function. \nIt's better to convert it down to 2 times u32 variables first. That makes it easier to understand.\n\n@@ -275,6 +275,21 @@ void check_hash (hashcat_ctx_t hashcat_ctx, hc_device_param_t device_param, pl\n\nCan you please explain why you need to add code to check_hash() function? That's kind of unusual. I'm not saying it's wrong, I just want to understand the reason behind/\n. \n\nconst int otp_offset = (int) ctx.opad.h[4] & 0xf;\n\nThis case is kind of strange. Since you commented out the vector macro I'd suggest to replace it with this:\nconst u32x otp_offset = ctx.opad.h[4] & 0xf;\n\nunsigned int otp_code = 0;\n\nWe never use \"unsigned int\" in the kernels. We either use just \"int\" or \"u32\" to hold some 32 bit data.\nIn this case I'd suggest replacing this to:\nu32 otp_code = 0;\n\nplain_ptr = (u8 ) strdup ((const char ) temp_ptr);\n\nThis one creates a new buffer but i can not see any free() for it. memleak?\nSince you're overwriting the original pointer value in plain_ptr which is not allocated memory you can not use free() on this variable unless you do the same branch again. However that's not very readable. I'd suggest to use a second fixed size plain_ptr2 the same way plain_ptr works and then you don't need to care anymore. you can then memcpy the new result into plain_ptr before leaving the block\n\nif (hashcat_ctx->hashconfig->hash_mode == KERN_TYPE_TOTP_HMACSHA1)\n\nWe're not using -> twice in the same variable. Please add something like this\nhashconfig_t   *hashconfig   = hashcat_ctx->hashconfig;\nto the check_hash() function and then use hashconfig->hash_mode in the branch line\n\n// now we need to reduce our hash into a token\n int otp_code = hc_strtoul ((const char *) input_buf, NULL, 10);\n\nThis section should come after the PARSER_OK check. Basically same like other parsers do.\n\ndigest[1] = otp_code;\n\nWhy are you using digest[1] here? that's kind of unnatural. I'd suggest to replace with:\ndigest[0] = otp_code;\ndigest[1] = 0;\ndigest[2] = 0;\ndigest[3] = 0;\nThe 1,2 and 3 helps when hashcat is sorting the hashes in memory, since you specified DGST_SIZE_4_5 in the switch case\nNote to make this work, you have to modify the switch case constants too:\nhashconfig->dgst_pos0      = 0;\nhashconfig->dgst_pos1      = 1;\nhashconfig->dgst_pos2      = 2;\nhashconfig->dgst_pos3      = 3;\n\nIt seems there's a major error here in the follow scenario. First i created a random hash (I guess there's not error so far, but please take a close look and verify)\n\n$ echo -n hashcat | tools/test.pl passthrough 18100\n504267:85457442135216\n\nThen I tried to crack it, but it did not work:\n\n./hashcat -m 18100 504267:85457442135216 hashca?1 -1 t -a 3 \nHowever, with smaller salts (less than 2^32) it works. So there seems to be a problem with larger salt values.\n. > snprintf (out_buf, out_len - 1, \"%06d:%llu\", digest_buf[1], tmp_salt_buf);\nthis needs to be written like this:\n\nsnprintf (out_buf, out_len - 1, \"%06d:%\" PRIu64, digest_buf[1], tmp_salt_buf);\n\nyou also need to add this to interface.h in order to enable PRIu64\ninclude \n\nbase32_encode (int_to_base32, (const u8 ) plain_ptr, plain_len, (u8 ) temp_buf);\n   plain_len = strlen ((const char *) temp_buf);\n\nI think you can rewrite this to just:\nplain_len = base32_encode (int_to_base32, (const u8 ) plain_ptr, plain_len, (u8 ) temp_buf);\n\n           hashconfig->dgst_pos0      = 1;\n           hashconfig->dgst_pos1      = 2;\n           hashconfig->dgst_pos2      = 3;\n           hashconfig->dgst_pos3      = 4;\n\n\nPlease rewrite it to use 0, 1, 2 and 3 instead. I see your point with staying stick to sha1-hmac\nbut in my view its not correct. The last one who touches the digest is not sha1,\nit's the algorithm you use. Therefore the compiler can create not auto optimized code by assuming\nthe second element is the first element.\nDon't forget to change the code in parser code, too\n\nDGST_SIZE_4_5\n\nI think you can set it to DGST_SIZE_4_4 afterwards and save some memory\n\n. I can reproduce this problem with 18.10.1 and latest hashcat. However, it's not a hashcat problem. \nThe same hashcat version on the same system runs fine on:\n\nLinux AMD rocm driver 1.9.211\nLinux AMD legacy driver 18.30-641594\n\nIf you think it's a problem related to Windows, that's not the case.\nThe same hashcat version runs fine on:\n\nWindows Intel driver 6.4.0.25\nWindows NVidia driver 416.34\n\nThe reason why hashcat 3.6 works is because it is missing some features especially in WPA kernel. For example cracking WPA2 + SHA256. \nAlso all other kernels work fine using Windows + AMD 18.10.1.\n. Please retry with hashcat 5.0.0 and reopen if not fixed.. It's pretty clear. There was an older version of hashcat installed, either by using \"make install\" or from a package. You can not mix old kernel and new hashcat binary.\nMake sure to use \"make uninstall\" and then run \"make install\" again.. Not by default, you have to alter a kernel and white-out the unneeded bits. Also with just 10 bits you will have tons of collisions. I think 10 bit is even fast enough to produce on slowest CPU you can think of.. For the above reason, I don't see a reason to have a issue in here for it.. Great! Thanks!. https://github.com/hashcat/hashcat/commit/d4123333c0a6f7836df8ce40b56b9dc308da2925 should help. You can either use hashcat github master and compile yourself, use the binary beta from https://hashcat.net/beta/ or wait for the next release version. I typical announce new releases on twitter.. I did some changes, please retry. If problem still exists, add some more details. Otherwise please close the issue.. No reponse from OP but I think its fixed now, therefore closing. Feel free to reopen if needed.. The default mask is not supposed to crack all LM password. Please use a full mask instead.. Please provide example hash and password. I can not reproduce this problem!!\nI used the same site to generate a token and it works fine. My token is 1589 bytes.\n```\nroot@et:~/hashcat# ./hashcat -m 16500 hash -a 3 Z9OLRgrBX39qIQ68WjmXLFEuerOcNNil -D 1\nhashcat (v5.0.0-15-g3b2c3f41) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, skipped.\nDevice #2: GeForce GTX 1080, skipped.\nDevice #3: GeForce GTX 1080, skipped.\nDevice #4: GeForce GTX 1080, skipped.\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #5: Intel(R) Core(TM) i7-4770K CPU @ 3.50GHz, 3998/15992 MB allocatable, 8MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Not-Iterated\n Single-Hash\n Single-Salt\n* Brute-Force\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nWatchdog: Temperature abort trigger set to 90c\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJPbmxpbmUgSldUIEJ1aWxkZXIiLCJpYXQiOjE1NDA5OTI1NDksImV4cCI6MTU3MjUyODU0OSwiYXVkIjoid3d3LmV4YW1wbGUuY29tIiwic3ViIjoianJvY2tldEBleGFtcGxlLmNvbSIsIkdpdmVuTmFtZSI6IkpvaG5ueSIsIlN1cm5hbWUiOiJSb2NrZXQiLCJFbWFpbCI6Impyb2NrZXRAZXhhbXBsZS5jb20iLCJSb2xlIjpbIk1hbmFnZXIiLCJQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3JQcm9qZWN0IEFkbWluaXN0cmF0b3IiXX0.PVZ_wlU7vUZSeeby0IdBuzO3EBNp75HJXLq2Stq44Ew:Z9OLRgrBX39qIQ68WjmXLFEuerOcNNil\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: JWT (JSON Web Token)\nHash.Target......: eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJPbm...tq44Ew\nTime.Started.....: Wed Oct 31 14:35:53 2018 (0 secs)\nTime.Estimated...: Wed Oct 31 14:35:53 2018 (0 secs)\nGuess.Mask.......: Z9OLRgrBX39qIQ68WjmXLFEuerOcNNil [32]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#5.........:     1959 H/s (0.09ms) @ Accel:512 Loops:1 Thr:1 Vec:8\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 1/1 (100.00%)\nRejected.........: 0/1 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nRestore.Sub.#5...: Salt:0 Amplifier:0-1 Iteration:0-1\nCandidates.#5....: Z9OLRgrBX39qIQ68WjmXLFEuerOcNNil -> Z9OLRgrBX39qIQ68WjmXLFEuerOcNNil\nHardware.Mon.#5..: N/A\nStarted: Wed Oct 31 14:35:51 2018\nStopped: Wed Oct 31 14:35:54 2018\n```. Note: the original issue was about 734 bytes and we support 2k byte. Therefore there is no issue or it was not described correctly. Note that there has to be an upper limit since there's no dynamic memory alloaction on GPU.. All problems solved, everything works as it should.. Which disk encryption are you talking about? Is that somehow different than the LUKS implementation we already have?. The error message tells you that the driver used (which ships the OpenCL runtime) is not the correct one. For Intel CPU, it's Intel OpenCL runtime. Make sure there's not OpenCL SDK installed. Also make sure that the GPU OpenCL driver part is broken in the Intel OpenCL runtime itself, so it can no be used. IOW, you can only use your CPU but you need to select the right OpenCL runtime. This one was updated to 18.x version recently and I added support for this in hashcat 5. Anyway, not a bug.. There's several things that the IPro rule-engine did different from JtR. When I wrote hashcat rule-engine I was under the impression the IPro rule-engine and the JtR rule-engine are 1:1 the same. Sometimes I used JtR for some functions and sometimes I use IPro. For example, in IPro positions for \"i\" for example, start with 1, not with 0. About the \"S\" I'm not sure what it is doing actually.\nSince both files do not change anymore (since they are not developed anymore) it would actually make sense to \"downgrade\" the content to hashcat/JtR syntax and remove the functions which are not supported.. Try with --opencl-vector-width 1 and post result please. We got rid completely of amd_bytealign(). I think it will work with the latest version from GitHub master.\n. Pretty sure \"So on\" is correct and \"Soon\" is not. We can only do it for -S so it will not work for -m 160. I guess it makes no sense then? Feel free to reopen.. I can confirm that the server is not running on Windows. The client should work. Please confirm.. I've pushed a fix and updated beta version here: https://hashcat.net/beta/ please check if fixed and close the issue. New beta up, please retry.. Not sure what to classify as mainstream distro, but Ubuntu does not (18.04).\nAnother problem is that only the library files xxhash.c and xxhash.h are BSD licensed.\nFinally we need the xxhash.c and xxhash.h to cross compile the windows binary.\n. Stop, I'll provide a more general solution, also for opencl headers. Never said that, just had not time to do it yet. That's simply a misunderstanding. I'll provide the patch in the next minutes.. OK I send in the path. @ZeroChaos- and @anthraxx can you please try if it works for your distributions? Maybe we need to change some of the system specific include paths?. Thanks, fixed!. There's a flag in the Makefile to enable the use of the system headers. OK I send in the path. @ZeroChaos- and @anthraxx can you please try if it works for your distributions? Maybe we need to change some of the system specific include paths?. > I'm pretty sure on ubuntu, for instance, it's called liblzma-dev and you can link it with -llzma (instead of -llzmasdk).\n\nOther distributions could use other names for the library of course (e.g. p7zip or 7z, 7zip related instead of lzma, lzma-sdk etc)\n\nI couldn't find the required headers in this ubuntu package. I think what we would also need is something like liblzma-sdk-dev (which doesn't exist). Mixing SDK headers with distribution libraries could cause problems.\nFor Ubuntu I'd therefore recommend to stick to our bundled LZMA SDK files. I don't see how we can improve this any further. If package maintainers want to use system libraries, they have to modify the path to the includes plus they may have to modify the name of the library to link. Since this can be different from distro to distro want can't do much on here.. Should be fixed, thanks!. Fixed with https://github.com/hashcat/hashcat/commit/175fea40942d91af2d79714b69e75b308da1b4c5\nThanks for reporting!. This is something that can occur pretty fast when it comes to scrypt. Almost all resources are heavily used. \nHashcat asks for free availability of resources on startup and the OpenCL runtime is responsible for the response. If the OpenCL runtime approves for enough resources to be available even if that is not the case, it's more like an OpenCL runtime problem, not a hashcat problem.\nAs a workaround try to use -D 1 (after installed intel opencl runtime for your CPU).\n. Thanks!. Great Idea! Added support with https://github.com/hashcat/hashcat/commit/d4dad3e1e304c34468eaab6661cde940793ceafb. make sure to git clone the repository. do not use the source package from the site. git requires git to be able to initialize the submodules.. continued on https://github.com/hashcat/hashcat/issues/1760. Please retry with latest beta from https://hashcat.net/beta/. Please post console output. We need to make sure that you're actually using the CPU device not the GPU device.. That's what I expected. Your are using the GPU, not the CPU. Please make sure to specify -D 1 (note the capital D, not d).. It depends on scrypt settings. For cryptocurrencies for example it works fine, but for data protections it's often too high to run on GPU. Only CPU.. Are you sure that this is really a bug? The \"Driver temperature threshold met warning...\" message was always displayed (also in 4.2) even if --gpu-temp-disable was specified. That's a wanted behaviour.\nMaybe the use of -S causes the GPU to create more heat (because of an eventual higher GPU utilization). In that case everything works as expected. Please verify.. I tend to agree with @philsmd to revert the changes (not really a git revert but restore the behavior as it was before the PR), but do an additional change. \nInstead of calling the parameter --gpu-temp-disable and --gpu-temp-abort we should rename them to --hwmon-disable and --hwmon-temp-abort. Note that even if there's no temperature reading for CPU today it doesn't mean we will never have it in the future.\nIt would be nice to have @RAN1 to comment in detail the reason for the changes. But as we want to release a bug-fix release soon we should not wait too long in case @RAN1 does not respond and just to the changes as discussed.. Since there was no response I did the modifications here: https://github.com/hashcat/hashcat/commit/2aff01b20ee3d56defea58fc573dd3340b435293\nNew beta is up on https://hashcat.net/beta/\nThanks for reporting!. Please add files to reproduce. I can crack it as well, but with a password which is not inside the wordlist provided by OP. Not sure what's the problem here, that's exactly how it works.. make sure to git clone the repository. do not use the source package from the site. git requires git to be able to initialize the submodules.. It requires an intense amount of system resources. One does not simply activate the brain :). Wrong project. I'm not sure what's the problem here. You ran into the typical bottleneck caused be feature type 1. Are you sure that you read the entire documentation carefully? It's all here:\nhttps://hashcat.net/forum/thread-7903.html\nFor fast attacks like yours you probably want to stick to --brain-client-features 2\n. Which driver exactly is it?. I tried to reproduce this locally using the latest AMD adrenalin edition drivers (both branches, that is 18.11.1-nov8 and 18.9.3-oct5). I tried with stable 5.0.0 as well as with latest 5.1.0 beta. In all combinations, it always worked perfect. Maybe you need to reinstall the drivers with a clean install.. Works fine for me:\n```\nd:\\download\\hashcat-5.0.0>hashcat64.exe -b -m 9600\nhashcat (v5.0.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz, skipped.\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #2: gfx900, 4048/8176 MB allocatable, 64MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 9600 - MS Office 2013 (Iterations: 100000)\nSpeed.#2.........:     8764 H/s (75.50ms) @ Accel:128 Loops:32 Thr:256 Vec:1\nStarted: Sun Nov 11 13:28:32 2018\nStopped: Sun Nov 11 13:29:12 2018\n```\n```\nd:\\download\\hashcat-5.0.0>hashcat64.exe -I\nhashcat (v5.0.0) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) CPU Runtime for OpenCL(TM) Applications\n  Version : OpenCL 2.1 WINDOWS\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz\n    Version        : OpenCL 2.1 (Build 0)\n    Processor(s)   : 8\n    Clock          : 3400\n    Memory         : 4082/16330 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 18.1.0.0920\nPlatform ID #2\n  Vendor  : Advanced Micro Devices, Inc.\n  Name    : AMD Accelerated Parallel Processing\n  Version : OpenCL 2.1 AMD-APP (2686.5)\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : gfx900\n    Version        : OpenCL 2.0 AMD-APP (2686.5)\n    Processor(s)   : 64\n    Clock          : 1630\n    Memory         : 4048/8176 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 2686.5 (PAL,HSAIL)\n```\nNote I'm using 2686.5 (PAL,HSAIL) freshly installed. I can not reproduce this as well. Tested systems:\nWindows 7 - AMD\nWindows 10 - Intel\nLinux native driver\nLinux rocm driver\nThis is probably just a driver installation issue, therefore please reopen if you are sure you did everything described here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nBut give more details in order to reproduce this locally.\n. Great work, thanks!. Replaced with https://github.com/hashcat/hashcat/commit/4177e1ee286f80c344f7bae6a65c40192f523e0a. That's the wanted behavior. Note that if you use the install target without copying/moving the binary after install, then hashcat assume to be installed system-wide and will write files to $HOME/.hashcat. I just tested 18.11.1 today and works fine. Your GPU is not too old, so I guess this is just a driver installation problem. Reinstall it and make sure the old driver was uninstalled cleanly. Check this: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\nFor CPU, you have to use the Intel OpenCL runtime, it's better than the AMD one (even for CPU).. - Can you please replace the smart match operator with a normal function which takes the array and the keyword instead, analogue to is_in_array() in the shellscript?\n- Is the pygost working with pip3 as well? In that case, everything is OK. Otherwise please replace the \"pip\" with \"pip2\" in the depency install shellscript\n- OCD error:\nVC_MODES=\"    13711 13712 13713 13721 13722 13723 13731 13732 13733 13751 13752\\\n  13753 13771 13772 13773\"\n. The -m 12 seems to be fixed.\nThe -m 10700 hash on the wiki page has been updated.\nThanks for reporting!. Great work again, thanks!\nThe parameter for hooks is currently set to void for all the macros. I assume you will push another some PR for the one kernel which is using the hooks.\n. It's important to know which version exactly you are using. In case of hashcat 5.1.0 from github master or from https://hashcat.net/beta/ then you are using the new behavior which sets the --brain-client-features to 2 (from 3) and therefore does not enable deep inspection required as you are describing. In that case, simply add --brain-client-features 3 to your commandline and it should work.\nIf you are using hashcat 5.0.0 release version, then it should do exactly as you said. If that is not that case, please retry with latest hashcat master or beta and report back. Don't forget to set --brain-client-features 3 in that case.\nIf this does not help you, please provide all files we need to reproduce locally.\n. Should be fixed with latest commit. You can use the beta from https://hashcat.net/beta/ if you want to try. Thanks for reporting!. It's a driver error, not hashcat error.. It's a driver error, not hashcat error. Also uninstall MESA, looks like a MESA JiT compiler error. Not a hashcat error.. As it says: NVAPI_ERROR is an error inside nvidias NVAPI library. Thanks for reporting, but not a hashcat problem.. That's correct since we usually dont have the a collision with up-to-date modes. It's also the correct answer to the questoin, therefore closing.. The problem with this is, if a user sets both --keep-guessing and --no-keep-guessing both at the same time, how should hashcat react. Additionally, having both options in --help menu is confusing, too.\nFor that reason, I've decided to not add this option. This will affect only 4 algorithms: 9720, 9820, 14900 and 18100.\nIf you really need to stop this behavior, you can change the setting easily with latest modularized hashcat version. Go to src/modules/module_09720.c and remove the OPTS_TYPE_PT_NEVERCRACK option or replace it with 0. Then run make to recompile.\n. My main concern is about how to deal with the confusion it creates having both options in the --help menu. It doesn't matter if there's a parameter available to the --keep-guessing option. The confusion is the same.\nAn alternative would be to remove the automatic activation of keep-guessing in the modes 9720, 9820, 14900 and 18100. For them, we could instead print a message with a suggestion to use the option --keep-guessing on the command line.\n. Done https://github.com/hashcat/hashcat/commit/111889d3fc63554382b99fe3893f63e58ba96b83. This is great, thanks! Exactly what I was looking for. I'll add the missing space and replace the spaces with the tab character.. Indeed :). Great work again, thanks!\nSome comments:\n\nPlease add a string substring (ODF) to the human readable descriptions for example in usage.c, interface.c, readme.txt and changes.txt. It's more likely people search for ODF instead of \"Open Document Format\"\nPlease add missing entries in docs/readme \nPlease add missing entries in tab_completion/install.sh\ntest.sh: Please add entry for 18400 to the SLOW_ALGOS array (it's possible there's some other modes missing as well)\ntest.pl: The mode 18400 should not be listed in COMMON_UNSALTED_MODES - at least since this a salted algorithm it creates confusion with the word UNSALTED?! please check previous PR as well\ninterface.c: This is ok since out_buf is a lot larger, but it still looks suspicious:\n\nsnprintf (&out_buf[159 + 2048], out_len - 1, \"%s\", odf12->suffix);\nI'd have expected something like:\nsnprintf (&out_buf[159 + 2048], out_len - (1 + 159 + 2048), \"%s\", odf12->suffix);\nbut even that looks a bit strange. Maybe theres even a different solution with a temporary buffer\n\ninterface.c:\n\nmissing hashconfig->hash_type      =  \n\ninterface.h:\n\nROUNDS_LIBREOFFICE should be ROUNDS_ODF12 ?\n\nkernel:\n\nplease replace:\n[16 * i + 0];\nwith:\nconst i16 = i * 16;\n[i16 +  0] (notice 2x space because aligning)\n\nkernel:\n\nplease replace:\npt1[0] = swap32_S (pt1[0] ^ iv[0]);\nwith:\npt1[0] ^= iv[0];\nDo all the swapping in a final block before hashing\n. Many thanks!. Good stuff, thanks! \nDo I understand it correctly that only version 1 was actually working and with your PR version 2 will be supported as well? In that case I think we need to modify interface.c a bit, too:\nIn electrum_wallet13_parse_hash:\nif ((salt_type == 1) || (salt_type == 2) || (salt_type == 3))\nIt should be just:\nif ((salt_type == 1) || (salt_type == 2)) ?\nCan you update the PR?\n. $electrum$5* is not supported. Many thanks!. I've never seen \"raw\" cbc mode in LUKS before. The low iteration count also gives a hint. It could be a very old system or a very slow system (embedded) since LUKS meassures the time it takes to do N iterations in a second and then setting this as the iteration count. \nBut I think it's just old. In that case it's possible that the algorithm is just not available anymore today, which is the reason why it's not in hashcat. While the kernel was developed, there was no such function to select from and therefore no one ever thought about having this.. Thanks s3inlc!\nThere's a few things missing:\n\nEntry in docs/readme.txt\nEntry in extra/tab_completion/hashcat.sh\nEntry in src/usage.c\n\nIf you want you can also try the optimized kernels. Especially for fast hashes like this one it has a serious impact.. Many thanks!. OpenCL runtime is not working or not existing. Either way, not a hashcat issue.. Not a hashcat error (it's a POCL error).. You maybe want to make sure your power management settings are in sync. It's possible that the default settings are changed between the different driver versions. For example, I use this script:\n```\nexport DISPLAY=:0\nnvidia-smi -pm 1\nnvidia-smi -acp 0\nnvidia-smi -pl 300\nnvidia-settings -a GPUPowerMizerMode=1 -a GPUFanControlState=1 -a GPUTargetFanSpeed=100 -a GPULogoBrightness=0\n```\nIn case you're on windows, you can use MSI AfterBurner to verify the power limits are in sync. I tried to verify on my local development system. This linux box only has a GTX750Ti installed and my other development box with the 1080 is currently unavailable. However I cannot see any difference for the GTX750Ti at last. If anything I'd say that there was some performance increase from 396.x -> 410.x.\nTested with hashcat v5.1.0: rm -rf kernels; ./hashcat64.bin -b -m 2500 -u 32 -n 128 -T 1024 --opencl-vector-width 1 --force \n384.130: 62381 H/s  \n390.87:  62414 H/s\n396.54:  62433 H/s      \n410.93:  63651 H/s\n415.25:  63532 H/s\nFeel free to reopen if you have new insights.\n. Which hash-mode is this?. I can reproduce this, but it's a driver problem, not a hashcat problem. IOW, we can't do anything about it. \nYou can try other modes in hashcat and you will see hashcat will work well. This explains why zcash and etherium work well. They do not use the same algorithm which WPA is using.\n. Great, thanks!. Perfect, many thanks!. Currently I see no way to do this.. OpenCL installation user error. Salt length constrains in -m 111 cannot be -1. In -m 112, if there's a fixed length  salt it should be fixed in both pure and optimized mode. No response from OP, feel free to reopen. Please retry with latest version from github master. Make sure to run \"make clean\" before recompiling.. I did some change with commit https://github.com/hashcat/hashcat/commit/ed7765d8fdca23d3eb71e8fd94ce25546ceacea3 which successfully worked around the same problem with AMDGPU driver on Linux by unrolling some AES function. It is possible that the same workaround will also work for macosx. Please clone latest github master version and retry.. Thanks, this looks like some good work. \nIt would be nice if we can have this not for zip but 7zip. This ensures higher compressing rates, cross platform availability and we even have support for 7zip library in the Makefile.\nPlease create a new PR in the hash-module-plugin branch instead since we're in the middle of a very deep refactorization.. Sorry, wrong wording. Of course I meant LZMA (as it is written in the Makefile).. As discussed, please use LZMA instead.. No that's the reason why I cannot accept the PR because I don't want the zlib SDK deps. For LZMA, currently it's just parts of the LZMA SDK. Please add the remaining files from original LZMA SDK which you need for decompression. If you do not want to update the current PR, please close it and create a new one for LZMA.. It's almost good. I think the OPTS_TYPE_PT_GENERATE_LE is wrong, should be OPTS_TYPE_PT_GENERATE_BE. See src/interface_migrate.c for original settings. After change, please update PR. I think you can 1:1 transfer it settings from interface_migrate.c. If 1:1 transfer is not possible, something else has to be changed first. Keep in mind the interface is very fresh :)\nIdeally also add the unit test tools/test_modules/m01700.pm then you can automate the check.\n. Please note https://github.com/hashcat/hashcat/commit/e453a9dc04ceabee9669e1d9eae3604218a1e3b6. Please note https://github.com/hashcat/hashcat/commit/31822a9bea0f503ef4c8a17e697ecacf38d0fa0d. Fixed with https://github.com/hashcat/hashcat/commit/dd293f7a938dc2188fef3b5e17fa8fdb9eabdc71. I just wanted to implement this but now I had some new thoughts. If we replace the fixed value 32 with a value which is the correct one for the current attack the user selected, then it's also possible the user gets a wrong impression. \nFor example, in md5crypt we are limited to Password length 15 in optimized mode. If we display the value 15 instead of the 32 in the warning message, the user (especially the new ones) maybe do not realize the 15 is valid only for the current attack, but generally for using -O.\nThe only way out I currently see is to not name any limits. For example, calling it like this:\nATTENTION! Pure (unoptimized) OpenCL kernels selected.\nThis enables cracking passwords and salts of shorter lengths but for the price of drastically reduced performance.\nIf you want to switch to optimized OpenCL kernels, append -O to your commandline.\nI'm not perfectly happy with this. Maybe there's a better way to explain? What do you think @s3inlc @roycewilliams ?. This looks even more complicated and overwhelming to new users. I'll use the generalized message type.. https://github.com/hashcat/hashcat/commit/4653447dfad1427d9c809529e49c9d0d72a656e9. Fixed with https://github.com/hashcat/hashcat/commit/5da1e4b87266dd893d334ae27852c0c29d802b9d. Probably the GPU driver. Please append -D 1 to try with the CPU driver. Please post results here. In your case you have to remove the -d.. Please retry with latest version from github master. Make sure to run \"make clean\" before recompiling.. The problem should be fixed with the latest GitHub master. Feel free to reopen if fixes did not work for you.. > Is it preferred to remove the code for the hashmode from interface.migrate.c ?\nAbsolutely. Also interface_migrate.h\n\nAnd does the hashmode need to be added anywhere else in the code?\n\nIn this case, no. For other conversion modules, we also need to add unit test module where it does not exist.\nFor the time after conversion when we add truely new modes we still need to edit the files:\ndocs/readme.txt\ndocs/changes.txt\n. There's a couple of errors in the module. I'll merge this now and fix the errors with the idea to make it easier to spot the changes needed.. Here's the commit which can be used to spot the missing changes: https://github.com/hashcat/hashcat/commit/3b9a26c9f609f20e1720b3b757bfb15c134b124d\n\nRemoved old code from interface_migrate.c\nFixed typo in HASH_NAME\nAdded OPTS_TYPE_STATE_BUFFER_LE (new option) which helps the decoder_apply_options() function to decide if it has work to do. Currently it is active only for OPTS_TYPE_STATE_BUFFER_BE\nRemoved salt_t *salt = hash_buf->salt; from old parser function. The variable is set as fixed parameter in the function declaration\nModified u32 digest = (u32 ) digest_buf; because digest_buf is now void *. This way we can easily switch between u32 and u64. The same goes for esalt and the hash-mode specific esalt structures\nFixed compiler warning related to input_tokenizer(). This is something I will maybe change in the future and switch it back to char * but for now let's stick to u8 *\nif (hashconfig->opti_type & OPTI_TYPE_PRECOMPUTE_MERKLE) { ... } : This branch is now handled inside the decoder_apply_optimizer() function and the opposite function for the encoder also exists.\nif (hashconfig->opts_type & OPTS_TYPE_ST_HASH_MD5) { ... } : I will remove this option type as it is relevant only for two or three hash-mode specific parser functions. For them we will add this branch directly into their decoder functions.\n\nPlease make sure the module compiles cleanly and and the self-test does not fail before sending the PR.\n. Probably the GPU driver. Please append -D 1 to try with the CPU driver. Please post results here.. Please retry with latest version from github master. Make sure to run \"make clean\" before recompiling.. Should be fixed with the latest GitHub master version. Feel free to reopen if fixes did not work for you.. Looks like all information required has been given. Please feel free to reopen if needed.. I think is happening to bitsliced kernels only. For example combination -a 3 and -m 1500. Other attack modes or other hash modes should not trigger it. Can you confirm?. I don't think this is related. MD5 and SHA1 are not bitsliced. Only DEScrypt (in -a 3 mode) is.. I tried all of the attacks on different development systems. It never occurred. Please retry with the latest version from GitHub master or https://hashcat.net/beta/\n. This is a bad Idea. The compiler will compile the code from for example src/shared.c into the module binary. The module size will grow and the they will have (eventual) different code from src/shared.c in case the module was compile for an older version of hashcat (this is a situation in the future). It's better to let modules use functions from host binary instead, which is why I've add -Wl,--export-dynamic in the first place. This concept works fine on linux using gcc and clang, so I hoped it also worked on OSX. It does not work on windows however, therefore I've add the exception on windows.\nOther fixes like dnclen please make them separate PR and I'll merge them.\n. Maybe you can find a different solution which does not involve compiling the code into the module. That would be great. I cannot check since I do not have OSX computer.. I'm not so happy to edit source code from other projects. Instead I pushed this this alternative solution:\nhttps://github.com/hashcat/hashcat/commit/05b71b6bc06e5dd811b0bbb06ea58a3946aa0d54\nI hope it works on OSX as well.. Please read https://github.com/hashcat/hashcat/blob/38e97bd89ada27dd07c74046889b102b34686781/docs/limits.txt#L25-L41. Thanks!. Thanks! There's a lot of invalid removals, probably because you confused sha2-224 with sha3-224? Please double check everything, especially if you actually used keccak_224_parse_hash(). This function usually does not have any optimizers like -= SHA224M_A therefore assume the wrong function was converted.. Perfect, thanks!. How is that possible that the problem is solved without us doing anything to the code?. Fixed with https://github.com/hashcat/hashcat/commit/e571b890e9175f6fbc0c52c86f534ed1f4f69d6c. Thanks!\nPlease note: https://github.com/hashcat/hashcat/commit/d266cb5834eea416a02f1f08db939b46b0a7a28f\nError was in original migrate file.\n. Yes, you are right. They are affected in the same way. We need to do the same fix for them.. Many thanks!. It exists, please ask on hashcat Forum.. Not sure why there's a conflict. I just merged the PR in the correct order.. Please fix the conflict first or close this PR and open a new one?. Nevermind I fixed the conflicts inline.\nThanks for PR!. Please ask on hashcat forum. Double post, please continue here: https://hashcat.net/forum/thread-8112-post-43528.html#pid43528. It's not a hashcat problem. The fan speed readings are not supported by the underlaying API (nvml) for your device. You might want to use something like afterburner to control them.. Almost OK. Two things:\n\nOPTS_TYPE_STATE_BUFFER_LE is missing\nWriting into existing buffers is unsafe. That's why it's defined as const salt_t *salt.\n\nsalt_buf_ptr[salt->salt_len - 8] = 0;\nPlease create new temporary buffer instead, copy the salt data, then do the modification on there.\n. Make sure to install the correct OpenCL runtime (Intel OpenCL runtime from their site!). Probably you have the wrong one (or two, and using the wrong one).. Thanks for clarify. The problem with the -m 1100 is that this mode does not require a comb mode to be set. \nThe comb mode is only to be set if the same buffer is kernel for both password and salt.\nFixed here: https://github.com/hashcat/hashcat/commit/b9365b89612320012632766e6ac3e51ca967897d. You can use -m 140:\nsha1($salt.utf16le($pass))\nMake sure to prepend the static 'PasswordCheckHash' to the PasswordSalt\n. See:\nroot@ht:~/hashcat# perl -e 'print \"PasswordCheckHash\" . pack (\"H*\", \"ec2a71fc6498810b\") . \"a\\0a\\0a\\0\"' | sha1sum  \n842d0bef6dbb0f060b337c6a9c7d6482a24978c0  -\nThis mean you need to do something like this:\n./hashcat -m 140 842d0bef6dbb0f060b337c6a9c7d6482a24978c0:50617373776f7264436865636b48617368ec2a71fc6498810b --hex-salt -a 3 aaa\n. Looks like the wrong mask, but a wrong mask is a user problem. Please ask on forum.. https://hashcat.net/forum. This is helping a lot, many thanks. @taliseen Can you please run the test which @philsmd was suggesting?. I just build hashcat (current master) on msys2. No problems.. I even tried using cygwin and hash-mode-plugin branch. It works without any problems. Please try harder.. I tried with the same OpenCL runtime (OpenCL for Intel CPU v18.1.0.013) on my i7-6700 CPU. It works fine.\nThe error 'CL_DEVICE_NOT_AVAILABLE' indicated that maybe this particular XEON CPU is not supported? Did you ever tried to run hashcat on this CPU before?\n. Yes, I agree. It should either work fine or not report back as valid OpenCL device.\nCan you try running any other OpenCL application on this CPU? If that fails, too it would be a strong indication that there's some sort of error in the Intel OpenCL runtime itself.\n. Good question actually. I just tried locally with this: https://github.com/krrishnarraj/clpeak and it worked fine. I'm pretty sure it will fail with the same error as hashcat did. Other than that I don't have any Idea what else to run.. Any Update here?. I've installed 18.10 Ubuntu using 4.18.0-15-generic and the Intel OpenCL runtime. No problems here! CPU is a Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. Maybe the CPU model is also relevant, not just the Kernel?. It turned out the problem is only with Ubuntu 18.10 in combination with 4.18.0 kernel and Intel OpenCL runtime and Intel(R) Xeon(R) Platinum 8168 CPU. Other OpenCL applications are affected as well. Not a hashcat error.. Please retry with latest version from github master. Make sure to run \"make clean\" before recompiling.. OK, but is the main problem fixed?. Did not see the trap: 6 curse for some time. Please try the same command but with -w 1 added.. You can also try if it's \"just\" the internal GPU and disable it. Use -d 3. With the latest version on GitHub master I added some workaround for option -d 1 and -d 2. At least the trap 6 should be avoided now automatically. Please confirm.. This is fixed with latest hashcat (you need to switch to the development branch during migration).\nmake clean\ngit checkout hash-mode-plugin\nmake. I'm merging this, just one note: The difference between the || and the // is if the value is \"0\". For || this is false, for // it is true. I had some problem with this in the past.. And thanks again, this really helps.. Please use hashtopolis issue, not hashcat.. Thanks again! Note: https://github.com/hashcat/hashcat/commit/a560b45705f4a2b9ed61d2ef27811cf7dea352fc\nIf there's no OpenCL/mxxxxx*optimized* kernel, then no need for optimized constraints.\nSame for OpenCL/mxxxxx*pure*, then no need for pure constraints.. Great! I'll add you to release notes for support, how do you want to be referenced?. Please create a new PR in that case.. I think it's also used in perl, not just Java. However the results are not matching. For example with the C code I do get 2163000881 (Decimal) as result for iceberg. Something is wrong, please verify everything again.. I found the reason. Your C code does not match the Java code. For example, the Java code does not have that initialization value 5381. Also the multiplier is 33, not 31.. What's the reason to have this in hashcat? It should be pretty easy to collide the hash. Please explain.. Wait, there's no way to reverse back the original string.\nFor example the strings:\nBA\nand \nA`\nthey both produce the same hash 0x0000083f. There's no way to tell which is the correct string.. OK, but then there are many collisions for the same hash possible. Do you have any plans on controlling the keyspace low enough so that the number of collisions is low enough to work with the result?\nCan you please give me a real life example where this obfuscation was used?. How about 64 bit version? How important would that be?. There's also a large number of possible optimizations. For example the last character can be detected automatically. How to handle that?. So I've pushed support for DJB (32 bit output) with commit https://github.com/hashcat/hashcat/commit/51eb9ebff7bd9d5020b570f0297361296b5e2515\nIf you do not want to build from source you can use the beta on https://hashcat.net/beta/\nSimply because it was so easy to add. Anyway, this implementation does not include any optimizations such as the last letter can be reversed etc. I hope it does what you want to do with it.\nYou maybe want to use the --keep-guessing flag to see all collisions if there are any.\nIf you want some fun, try: ./hashcat -m 18700 -O -w 3 ffffffff -a 3 ?l?l?l?l?l?l?l?l --keep-guessing. Please note that I'll rename this algorithm to \"Java Object hashCode()\". The original DJB algorithm uses * 33 and not *31 plus it has an initialization value. Just to avoid confusion.. Please ask on hashcat forum. No, the password must have exactly length 64. I think you want to use -m 16800 not 16801.. Should be fixed. Please test and close issue. Thanks for reporting.. This sounds like if the cached kernel binary which is generated by the opencl runtime and which is stored in kernels/ is not useable. In the first run we use the binary compiled by the JiT, which could explain that the first run is working. \nAnyway, this behavior was not changed in any recent version. IOW, this never has worked before, correct?. The problem was fixed with commit https://github.com/hashcat/hashcat/commit/b99d392e78c92cd9e624c04f4c72eb4cb6c55849\nFeel free to reopen if fixes did not work for you. Thank you for reporting. Added with commit https://github.com/hashcat/hashcat/commit/29fedf2c41bb54a982a270bf7bf754bee6496245\nYou can build from source or use the beta from here: https://hashcat.net/beta/. You can use the androidbackup2john.py from here https://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/run/androidbackup2john.py. I think is the wrong OpenCL runtime. In order to use AMD CPU you need to install the Intel OpenCL runtime (not a joke). Anyway this is not a hashcat problem.. Should be fixed with commit https://github.com/hashcat/hashcat/commit/761475b224c5054e71d63c84a0cdb6dee8c5ee15\nThanks for reporting!. Please fix OpenCL runtime. Not a hashcat problem.. Hashcat is used to guess passwords. How is ECC related?. Feel free to reopen if there are more concrete details available.. Thanks for info! CC @magnumripper . Fixed with commit https://github.com/hashcat/hashcat/commit/0b1169e523d9247821d07cfb783b3a43f20c7ae7\nNew beta on https://hashcat.net/beta/\nThanks for reporting!. Fixed with commit https://github.com/hashcat/hashcat/commit/f92ebc658691f629117e7c215c4d684fcd3bd8cb\nBinary beta was updated, too. Can you provide an example hash for each of the different decrypted data variants?. I've add the missing pattern with commit https://github.com/hashcat/hashcat/commit/a9bafb7edb49bbf40d097fecf19a5c4ee0620076. Which OS is this running on and which kernel?. I think the issue is that you using and AMD OpenCL runtime to the Intel CPU. If you'd use the Intel OpenCL runtime (this would be the correct one), how does it change?. Please retry with the latest version from GitHub master. Make sure to not use the \"install\" target and use ./hashcat instead. This ensures that hashcat will not search for (old) precompiled kernels in the $HOME/.hashcat folder structure.. Thanks for adding this mode. It was requested several times before! Some things need to be fixed first.\n\nThis mode differs from the original SHA256 raw hash implementation. Therefore it should get its own hash-mode number. I've reserved hash-mode 19800 for this. Please rewrite.\nI know that there's other applications than AuthMe using this mode. It would be therefore make more sense to have a general kernel and then use the 1980x number for the special applications using this mode.\nThe mode is raw and it is also salted at the same time. Therefore the kernel should get the name 19810, the Application AuthMe however should get the name 19811. You can call the 19810 from the 19811 module.\nA very similar structure can be found with the vbull mode (2611).  I recommend to use this mode as template.\nThe hash is doing only two iterations of SHA256. IOW, it's too fast to be marked as a slow hash (ATTACK_EXEC_OUTSIDE_KERNEL). It should use ATTACK_EXEC_INSIDE_KERNEL instead. This is required to achieve full GPU utilization. See mode 2611 as an example.\nYou can start writing the pure kernels only first. Hashcat accepts either pure kernels only, optimized kernels only, or both. In case you stick to pure kernel only, you can set the module constraints to 0,256 for both password and salt. However AuthMe seems to have a fixed 16 byte salt. In this case you can set the test module to 16,16. I just wanted to explain it generally.\nfor parsing the salt, please use the interface generic_salt_decode() and generic_salt_encode() in the module. See 2611 module as an example.\nThe DGST_SIZE      = DGST_SIZE_8_8; is invalid for 32 bit based hashes as SHA256. Use DGST_SIZE      = DGST_SIZE_4_8; instead. (The first 8 indicates that this is a 64 bit integer based hash)\nIf you configure DGST_POS0-DGST_POS3 correctly (see 1400 as an example) you can allow the JiT to auto optimize the early skip the last 3 steps in the last round of sha256. The marcros are transfered to the kernel automatically. If you stick to them in the kernel you dont need to care about them\n\n. So you've started using the same Kernel for \"19800\". This is fine so far! Does \"WIP\" mean work in progress?. Any updates here?. Any updates here?. The unit test successfully finished. Please change the code as requested in the two sections. I'll merge afterward.. Thanks!. Hi There. thanks for creating that issue. Please follow there following steps:\n\nRetry with the latest version either by compiling yourself from Github master or by using the binary beta from https://hashcat.net/beta/\nIf the problem still exists, please retry the same test with the JtR\nIf the problem still exists, please provide all the files we need to reproduce locally. It's normal. You can workaround using slow candidates mode. Use -S. OK, use this:\n\nhashcat64.exe -a 6 ../areacodes.txt ?d?d?d?d?d?d?d --stdout | hashcat64.exe -m 2500 hash.hccapx. Nothing to add here, we can do this.. I'm not sure if this is of any practical use. For example, if you have a hash list of two (or more) -salted- hashes. During the attack, one of them gets cracked. This means the estimated runtime will reduce by 50%.. OK, I understood that already. But the ETA would be wrong in the scenario I've described. How does it help?. Can you please explain what you mean with swapping and how to reproduce this?. This is interesting because the change is only relevant for AMD GPU:\nif (... && (device_param->platform_vendor_id == VENDOR_ID_AMD))\nThe memory check (which is done afterward) was already part of hashcat before. The change just moved it to a different position in the code execution chain. That's why I do not understand how hashcat 5.1.0 release version worked for you.\n. ok, will do after merge\n. should be fine, thanks for cross check @magnumripper \n. I've merged the original version from @matrix but it would be nice if you can send in a PR with the easier to read version you've posted in the comment, too.. not true. What is YMMV. If you do an example for example0.hash, the -m mode is always 0. Removing word-wrap please. OK, remove it.. The TOKEN_ATTR_FIXED_LENGTH is ideal for hashes when there is no separator character (like descrypt) while at the same time there are still different columns. The macro name maybe is not ideal to reflect that, but TOKEN_ATTR_VERIFY_LENGTH is correct use here.. The perl module does not work as expected, therefore we just set it to fixed zero. You can remove it and use sprintf (\"%08x:00000000\", $digest); . This should do it:\nconst int line_len = snprintf (line_buf, line_size, \"%08x:%08x\", digest[0], salt->salt_buf[0]);. All eventual errors which you get with this mode are because of some error in test.sh. However your math in the constraints is correct, you have the right understanding. Basically it always goes back to the kernel code. If you are unsure, use the single or passthrough to generate some examples and try them manually.. Please rephrase, I don't understand. The use of sha1_update_vector typically requires to use sha1_ctx_vector_t type not sha1_ctx_t type. In this case, it works because you disabled the SIMD by commenting out NEW_SIMD_CODE. I would switch it either to sha1_ctx_vector_t or sha1_update(). Up to you.. It's possible that this could be misunderstood by the OpenCL runtime and initialize all elements in the array with the value 0x2d2d0000 not just the first one. Please rewrite this as\nconst u32 glue[16] = { 0x2d2d0000, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };\nin all kernels.. You can increase the performance by another 50% in -a 3 mode (probably also -a0 and -a1) if you optimize the strategy of the kernel a bit.\nBefore entering the inner loop you can precompute the following:\n```\n  // precompute some stuff\nsha1_ctx_t ctx0;\nsha1_init (&ctx0);\nsha1_update (&ctx0, k, site_key_len);\n  sha1_update (&ctx0, glue, 2);\n  sha1_update (&ctx0, s, salt_len);\n  sha1_update (&ctx0, glue, 2);\n```\n. To make use of the precomputation you can do use instead:\n```\n    sha1_ctx_t ctx = ctx0;\nsha1_update (&ctx, w, pw_len);\nsha1_update (&ctx, glue, 2);\nsha1_update (&ctx, k, site_key_len);\n\nsha1_final (&ctx);\n\n```. At this position you can hardcode the glue, it will always be at exactly this point.\n```\n      ctx.w2[2] = glue[0];\n  ctx.len = 40 + 2;\n\n```. Here's a fully optimized kernel -a3. I'm sure you can backport most of the improvements to -a0 and -a1:\nhttps://pastebin.com/cHFu55ys. This would only change the behavior in case the user is using the --keep-guessing command line argument. \nThere are however modules which automatically enable the keep-guessing flag automatically, such as 9720 and 18100 and others. Those would not be covered with this test. Please replace this test with the following and we should be good:\nif (hashconfig->opts_type & OPTS_TYPE_PT_NEVERCRACK) return 0;\nThe reason why this will also cover the use of --keep-guessing on the command line is best explained here:\nhttps://github.com/hashcat/hashcat/blob/master/src/interface.c#L347-L350. Debugging leftover?. Debugging leftover?. In this case, salt->salt_len should be set to 8, since we only set salt->salt_buf[0] and salt->salt_buf[1]. This is only to make the unique salt sorting in hashcat working correctly to remove duplicate salts.. I think you should be able to move\nsha1_update_global_swap (&ctx, pws[gid].i, pws[gid].pw_len);\nto the outer loop (into ctx0). It doesn't change inside the inner loop.. ",
    "epixoip": "This has my signoff as well. @jsteube please merge to master if you approve.\n. Intel GPUs are not likely to be much if at all faster than CPU, which is one of the reasons we never bothered to support them.\n. That link doesn't really say anything of value.\nLet's look at it this way: current top-of-the-line Intel GPUs have up to 384 cores which run at up to 1100 Mhz, and lack instructions that help reduce instruction count for many hash functions (nothing similar to bitselect, bitalign, LOP3.LUT, etc.) So basically these will be almost identical in speed very low-end pre-Maxwell Nvidia GPUs.\nFor example, the Iris Pro 6200 would be about as fast as a GT 640, which yields a staggering 450 MH/s on raw MD5. And by \"staggering,\" I mean that's 23 times slower than a GTX 970. And that's for their top of the line GPU, if you have something like an HD4200 then it would be more like 50 times slower than a GTX 970. \nSo this is why we've never cared about adding Intel GPU support. Even their fastest GPUs are about the same speed as high-end CPUs. \n. 525 H/s @ 5W. Meanwhile a GTX 970 gets 180000 H/s @ 135W.  That's 105 H/W vs 1333 H/W. So that's both poor performance AND poor perf/Watt. \n. Sorry, all I saw was \"#1: 'CUDA-Device #1 'GK20A'': 525.1 PMKs/s (RTT 2.8)\". But even 6203 H/s falls short in the perf/W category, and well short in perf/$ as well. You'd need 29 of these boards to match the speed of one GTX 970 for a cost of $5600 vs $320.\nHistorically we've had zero interest in underpowered / poor-performing hardware. I suppose that's because in our view, Hashcat is for serious professionals, and serious professionals have real hardware. I know JtR aims to be compatible with pretty much anything and everything, but I personally do not see our focus shifting away from serious use cases.\n. JtR is the acronym we frequently use to refer to John the Ripper.\n. There's already another ticket open for Mesa (#71). And those failures appear to be Mesa's fault, not oclHashcat's. Remember that the state of Gallium is not at all mature and their OpenCL platform is not production-ready. Still a whole lot of red/orange on this chart, even for GCN https://dri.freedesktop.org/wiki/GalliumCompute/\n. Sure, I think what atom meant was all the work necessary to make oclHashcat work with any OpenCL library has already been done, and thus the ticket can be closed. \n. Only with -m 400 or other algorithms as well?\n. Ok to commit\n. Looks good, I'll provide my signoff for this\n. It's MIT license...\n. Benchmark uses the highest workload profile (-w 3). If you want low resource utilization you should use the lowest workload profile (-w 1) while actually cracking.\n. Looks sane, ok to merge.\n. This might be something to consider for the future as ARM pushes its way into the server market, but right now there's real no value in supporting ARM (not to say we would reject PRs from someone who adds ARM support, just not something we would likely focus on adding.) You're far more likely to see POWER support before ARM. \n. Oh, I'm sorry, for some reason I thought we were talking about Hashcat, not oclHashcat (probably because otherwise the topic makes no sense :wink:). I did indeed have NEON and AltiVec in mind when i wrote that comment. But yes you're of course correct, cross compiling oclHashcat for ARM should already be possible today. \n. As we've discussed on IRC a couple times, POWER is potentially worth supporting. I don't know if there will be a CPU OpenCL driver (would be really sweet if there were), but at the very least Nvidia have joined the OpenPOWER consortium, so you will see affordable POWER servers with Nvidia GPUs in the near future.\n. Way outside the scope of this project. If you want to work on this, go for it. But it doesn't even seem like something that would be desirable, let alone possible, for oclHashcat.\nFurther, these types of questions are better suited for the forums, not a Github Issue. \n. Ok to merge\n. Looks like you have more than one libOpenCL on your system, and oclHashcat is picking up the wrong one. Should only have one libOpenCL, and that should be the one installed by AMD Catalyst. \ndpkg -l | egrep -i 'nvidia|fglrx|opencl'\nfind / -name libOpenCL*\n. Ok to merge\n. Ok to merge \n. VCL hasn't been touched in almost 3 years. It's a dead project. \n. VCL is just a grad school project so I assume interest in it will peak and fade as students come and go. \n. You should be using prince_generated.rule or prince_optimized.rule when piping pp into oclHashcat.\n. There are several issues with this PR:\n1. You did not follow the \"Solve only one problem in each pull request\" rule.\n2. The --session-dir stuff is already obsolete based on other recent changes.\n3. Getting rid of the typedef bool is not the way to fix that problem. \n. You might want to double-check that attachment, you uploaded much more than just two samples of the same key.\n. Why would you open this bug report here, and not with ArchLinux? \n. Cracking NetLM is already supported via -m 3000 and -m 1000, this would be just adding support for this particular format string (like when we added pwdump format.) \n. To clarify, this ticket is only for recovering the MD4 hash from an MS-CHAP hash; if you're looking to just crack MS-CHAP directly, this algorithm is already supported via -m 5500. https://hashcat.net/forum/thread-5052.html\n. With that algorithm you do not need GPU acceleration, you can just use http://strcpy.io/md5substr.c  I've been working on adding this code to Hashcat, but you don't have to wait for that for what you're doing.\n. That's plenty fast enough for a 3-byte collision. You should have already found dozens of collisions at that rate.\nThis is on my laptop:\nTarget......:  a1b2c3\nOffset......:  0\nFound.......:  106\nSpeed/sec...:  25.60 MH/s current, 30.40 MH/s average\nProgress....:  1824000000/60170087060757 (0.00%)\nRunning.....:  60 sec\n106 collisions found in 60 seconds at 30 MH/s. At 6 MH/s you should find ~21 collisions per minute.\n. ADL SDK is needed to enable hardware monitoring and fan control for AMD GPUs. Without this you will not be able to see GPU temp or fan speed.\nIf you cannot simply build with ADL SDK without distributing ADL SDK, then my suggestion is to not distribute a source package, or to not build from source. Simply download the binary release from hashcat.net as you've done with other releases in the past. \n. This looks sane, ok to merge\n. Why do you feel this must be done upstream?\n. it is my opinion that downstream can compile with whatever flags they like, and an issue should only be opened with upstream if the build fails when enabling some compiler flag. Then upstream can evaluate if there is a bug that needs to be fixed in the code, or if downstream should simply not use that flag. \n. ^ that's the proper way to do it\n. I don't think it will be an issue. If anything it should be less confusing rather than more confusing.\n. Are you root?\n. I understand your concern @magnumripper, but I think you're conflating \"open source\" with \"community-driven.\" Hashcat is obviously open source; however, while contributions from the community are appreciated, Hashcat is not a community-driven project.\nThe Hashcat development model is top-down, with @jsteube functioning as the BDFL and the core team members (@philsmd, @gm4tr1x, @Xanadrel, @dropdeadfu, and myself) functioning as the project directors. Control of the development process and decision making authority are retained by the group of aforementioned individuals; they have neither been passed down nor delegated to the community. So it is only natural that this \"little club\" would have a place to meet and discuss the project in private.\nThe upside of this model should be quite obvious, magnum... please do not make me state it.\n. If you need more than one block of input and don't care about the speed loss, then you're probably just better off using OpenSSL on CPU.\n. Holy shit dude, do you intend to write a comment on this every day?\n. We probably need a timeout patch for Intel like we do with Nvidia. \n. Yes, this is already covered on our wiki: http://hashcat.net/wiki/doku.php?id=timeout_patch\n. Maybe if this has changed for CPU then it's also changed for MIC? If not, can we put something in the .hctab to fix this?\n. Yes, this can be overridden on the command line with --opencl-vector-width and also in the new .hctab file. \n. Cool, go ahead and make one and submit a PR.\n. Nicely done, this is ok to merge\n. Fantastic job, ok to merge!\n. Ouch, yeah, please merge!\n. What is the plaintext password for the above wallet?\nThe scrypt parameters used here are extremely unfriendly to GPUs, this would likely only be able to run on CPU.\n. Questions like this belong on the forums, not on Github. \n. Again, this is an issue for the Hashcat Forums, not Github. But this typically means your OpenCL environment is not set up correctly, or driver is not installed properly. See the Hashcat Wiki for help and if you still need assistance, ask on the forums.\n. I don't understand why you would open an issue on Github for this problem, especially when you're using the release version and didn't test against the code that's actually in Github (cudaHashcat doesn't even exist in this repository anymore.) Questions like this belong on the forums or IRC.\nAnyway this error is addressed in our FAQ, http://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_does_the_cumoduleload_301_error_mean\n. You have an old GPU that has been supported by oclHashcat for nearly 3 years now, so that is definitely not applicable in this case. \n301 == \"File Not Found\" so either you're not using \"7z x\" to extract the archive, or you're trying to run cudaHashcat from outside of its directory, or something along those lines. But either way it is an issue with your setup and not a bug in cudaHashcat, and therefore a bug report should not be opened for it -- especially when cudaHashcat doesn't even exist in this Github repository anymore.\nIRC channel is listed on our website.\n. Defining your own salt length isn't really possible because max salt length is hardcoded into the implementation of the algorithm, that's why jsteube said you'd have to write a new kernel to support this functionality. And generic algorithms with no length limitations are the antithesis of Hashcat.\n. You can't just change the salt length. You have to write a completely new SHA512 implementation that can support that large of an input. \n. Both are correct, those two statements are not mutually exclusive.\n. Github issues should only be opened against the code that's actually in Github. cudaHashcat no longer exists, so please try latest oclHashcat beta or build from source, and if the problem persists, open an issue at that time. Thanks!\n. This question is best asked on our forums\n. md5(md5(p).s) is already supported by -m 2711. Oh, but it expects a 30-char salt doesn't it. We could probably just add a generic md5(md5(p).s) mode that isn't optimized for vBull. \n. That's a cipher, not a hash, and you aren't going to crack a 256 bit AES key.\n. Ok but this is hashcat, not ciphercat\n. Hashcat targets the use of a password-based key derivation function in that algorithm, not AES itself.\n. This type of question also belongs on the forums, not on Github.\nNote that Github Issues is only for filing bug reports or requesting new features! If you need help or want to discuss a topic, please use the forums. Thanks!\n. This type of question belongs on the forums, not on Github. \n. This is not a bug report or a feature request, so this type of question belongs on the forums not on Github. Please close this issue.\n. Forums is a more appropriate place, but just real quick: you would be much better off installing the official Intel OpenCL runtime.\n. I've always used ''-o /dev/null'' to accomplish this ever since hashcat got potfile support. \n. Why are you filing a bug report for cudaHashcat 2.01? cudaHashcat doesn't even exist anymore.. This isn't a hashcat issue, there is nothing we can do to \"support virtualized environments.\" Your beef is either with ESXi's VGA passthrough, or with the Nvidia driver, or a combination of both. May even be a buggy IOMMU on your motherboard triggering a bug in either of those as well, or perhaps your IOMMU is not fully supported by ESXi. VGA passthrough is very experimental and only a handful of hardware support it properly, there are simply too many variables for us to attempt to help you troubleshoot your setup. Or, you know, you could actually just be out of resources (have you actually checked that?) Anyway, regardless of what is triggering this, it is emphatically not a hashcat issue. . VT-d has been around for a while, yes. But it is also broken on a lot of motherboards (BIOS doesn't implement it at all, or implements it incorrectly, or has corrupt/missing/incomplete IVRS tables), and even broken in some chipsets (e.g. broken interrupt remapping) and CPUs as well (Intel shipped an entire generation of CPUs with a bad VT-d implementation, and I don't think AMD-Vi has ever actually worked.) So while the concept isn't new, it's not something that's actually widely supported.\nThat said, I'm not aware of any issues with Ivy Bridge-E or C602, but there may be issues still with the BIOS on your board, I don't know. I do know that our Gen2 Brutalis platform had the same C602 chipset you have, and I remember experiencing constant ASIC hangs and Oopses. But that very well may have been a software issue, not a hardware issue.\nSorry, but VGA passthrough is indeed still in its infancy (and do not conflate PCI passthrough with VGA passthrough.) ESXi certainly has better support than Xen or KVM, but the last time I tried to use it (ESXi 5.5, Xen 4.2), it was either really buggy or entirely nonoperational on all of my boards.\n\"There are not 'too many variables'\" -> \"just a generic error message when any number of problems go wrong.\" Do I even need to comment on this?\nDon't accuse us of not consulting documentation. We practically have that entire documentation memorized.\nDriver timeout is hardly a bug in hashcat, the issue has been well-documented on our Wiki for several years, which even includes both a registry patch and an xorg.conf patch. ~~Hashcat even tries to warn you if this patch has not been applied.~~ Never mind, looks like we removed the warning in 3.20 as we didn't feel it was necessary any longer with autotuning.  I suppose it is possible that autotuning is not very accurate in a virtualized environment. You could always try using a lower -w value if the timeout patch doesn't resolve the issue and you're intent on using hashcat in a vm. But I'm still not convinced this will actually fix anything. I've not had a single positive experience with VGA passthrough so I'm still leaning toward the issue lying somewhere in there.\nRegardless, still not a bug in hashcat.. This is not an \"issue\", the topic is clearly more appropriate for the forums. Please start a thread there instead.. See if https://hashcat.net/wiki/doku.php?id=timeout_patch resolves this for you, and please report back to let us know if it did or did not work.\nWhen using CUDA we used to see error 702 (CUDA_ERROR_LAUNCH_TIMEOUT). Based on a few other people's reports, it appears Nvidia's OpenCL just returns -5 (CL_OUT_OF_RESOURCES ) for the same condition. Probably because OpenCL doesn't define any sort of timeout error code like CUDA does. I think -2 (CL_DEVICE_NOT_AVAILABLE) may have been a more appropriate equivalent, but I don't work at Nvidia so my opinion doesn't count ;). This is question is more appropriate for hashcat forums than github issues.. --pw-min and --pw-max have been renamed --increment-min and --increment-max. They never had any affect on any attack mode other than ''-a 3 -i'', so the new nomenclature is more correct.\n-k only works with -a 1 and -a 7. Maybe you want -r instead?. It would actually be '<8' not '>8'. But yeah now that you mention it, I don't think the reject rules have been ported to OpenCL because it's too slow. It's actually faster to hash unnecessary candidates than it is to try to reject them.. ",
    "ignatenkobrain": "Currently oclHashcat supports only AMD OpenCL SDK and CUDA, but we have OpenCL which is not part of those. I want to get support of it.\n. I am not interested in CPU part, I'm mostly interested in beignet part, because it works on Intel GPUs which is mostly everywhere.\n. It is faster (at least with beignet). https://01.org/beignet\n. I am very happy, that you are working on opencl support, but I have question. What is JtR?\n. Very cool, how I can compile it without having amd sdk, cuda and etc. ?\n. Unfortunately it does not work with Beignet (Intel implementation)\n```\n[brain@x1carbon oclHashcat]$ ./example400.sh \noclHashcat v2.01 (gc4e6ffc) starting...\nDevice #1: Intel(R) HD Graphics IvyBridge M GT2, 1024/2048 MB allocatable, 1000Mhz, 16MCU\nDevice #1: Kernel /home/brain/oclHashcat/kernels/m00400.25e54501.kernel (47756 bytes)\nDevice #1: Kernel /home/brain/oclHashcat/kernels/amp_a0.25e54501.kernel not found in cache! Building may take a while...\nASSERTION FAILED: insn2.header.opcode == GEN_OPCODE_NOP\n  at file /builddir/build/BUILD/Beignet-1.1.1-Source/backend/src/backend/gen_encoder.cpp, function virtual void gbe::GenEncoder::patchJMPI(uint32_t, int32_t, int32_t), line 1043\n./example400.sh: line 1: 21297 Broken pipe             cat example.dict\n     21298 Trace/breakpoint trap   (core dumped) | ./oclHashcat -m 400 example400.hash\n```\n. Other algorithms as well.\n. ",
    "magnumripper": "IMHO, regardless of Intel GPUs' current state there's really no reason for Hashcat not to \"work\" with just any OpenCL device. Instead you could just state that only AMD is actively \"supported\" and/or that the OpenCL code is optimized for AMD and YMMV.\nSo I think we should look into wrapping AMD-specific stuff (just guessing there is some) in #ifdef blocks and provide some alternative \"generic\" alternative. Once it builds and runs on nvidia (as an alternative to CUDA) it should also run fine on Iris or crappy AMD APU's - as well as on some really cool FPGA board with OpenCL abstraction layer...\nI haven't looked much at the code base yet so I'm mostly assuming things here.\n. In fact it might save you a lot of time and work if you (eventually) ditch all CUDA stuff and go all-in for OpenCL. Unless there are some clear cases where CUDA can be significantly faster?\n. In JtR we use function-like macros for \"overloading\". Too bad the typeof keyword is not mandatory in OpenCL - that would have been perfect. Most drivers support it though (including AMD, nvidia and Apple) but Intel does not (well some of their drivers do).\n. @shellster is that thing usable in real life? That is a sincere question, I'm not bashing. What's the performance?\nThere's no need to actually ditch the working CUDA code. Sure, the tree would be much easier to maintain without CUDA but you could keep the kernels for a while and just separate the builds: Stop calling them \"nvidia\" and \"amd\" and instead call them what they really are: \"cuda\" and \"opencl\". That is what we do in JtR although in that case, the CUDA stuff is mostly laughable.\n. I believe there are still plenty of bugs in Beignet. We've had issues in JtR about Beignet but as far as I can remember, all of them were their bugs, not ours. I expect these to be the same - it will eventually work better. BTW it got a LOT better just during last year.\nHaving said that, odd platforms like Beignet are good for finding \"edge cases\" or in our/your code that can be improved, or code that are actually \"undefined behavior\" but happen to work fine on many platforms.\n. According to http://hashcat.net/forum/thread-4761-post-26977.html#pid26977 it's 25-30% for 290X.\nI don't think the GPU memory is too small, we've run JtR like that (all 4096 kernels JIT compiled once using fake hashes, and obviously we cache them forever for re-use). The startup time for 4096 salts (even with cached kernels) is horrible though. We even experimented with threaded JIT compiles: Since make -sj32 for a normal C build is so much faster we figured we'd see the same, but apparently it ended up serialized anyway with most vendors' drivers (when it worked at all).\n. Some old notes from a contest says loading all 4096 salts in JtR took 40 minutes first time (compiling) and less than one minute after that (cached). That was on Tahiti.\nActually having that many salts is uncommon of course. Even Gawker was \"just\" 3,844 salts.\n. IMHO that is the way to go, sooner or later.\n. Clearly? I actually read it as we should use tabs, with tab width set to 2. But I noticed the existing code does not use tabs.\nI'd express it as \"Uses no tabs and 2-character indentations\" (disregarding the fact I would personally prefer use of tabs).\n. > could I do a fork with SL3 support (completely unlinked -except the author and license- from this project)?\nThis is a puzzling question. The only one able to answer it is you.\n. Is that thing LE or BE as is? If it's LE, it should be a walk in the park supporting it.\n. Assuming this thing runs Linux, I can't see anything needing changing at all? We already have a target for Linux (possibly assuming LE) and I see no SIMD intrinsics or assembler used anywhere.\n. You could obviously do something like this (given there is some macro(s) usable for selecting platforms where this does improve performance).\n``` c\nif this_or_that\nconst u32x w0s07___w0s12 = w0s07 ^ w0s12;\nelse\ndefine w0s07___w0s12 w0s07 ^ w0s12\nendif\n```\nIt'd still not be a 100% no-op for the else clause (due to different ordering) but that should not be much of a problem.\n. I'll do some experimenting, will report back.\n. I'm simply hoping the reason it's not been touched in years is that it works like a champ [for nvidia]. I'm assuming they just gave up on AMD's crappy drivers that introduce new bugs with every release. We'll see. The libOpenCL.so: no version information available is a benign warning that can be ignored.\nI had a look at SnuCL some time ago but it's much less transparent. IIRC you need to compile with MPI and I guess you'd need lots of special code in oclHashcat. For VCL, all magic is in the OpenCL layer, not the application.\n. That's worse. But using nvidia and latest oHC source, I guess it shouldn't be a problem.\n. I did some testing with VCL 1.22 with poor results. And then... wow, just as I was going to ask the developers whether they abandoned the project, they released VCL 1.23 - after 2.5 years of silence. Changelog:\n- Works with OpenCL 1.2 or higher.\n- Added the following functions of OpenCL version 1.2:\n  - clEnqueueFillBuffer()\n  - clEnqueueFillImage()\n  - clEnqueueMigrateMemObjects()\n  - clCreateImage() (no new image types yet beyond OpenCL 1.1)\n  - clCreateCommandQueueWithProperties() (no new options yet beyond OpenCL 1.1)\n  - clEnqueueMarkerWithWaitList()\n  - clEnqueueBarrierWithWaitList()\n- Deleted bypass code for some ATI bugs that were fixed.\n- Updated the instructions for connecting with Slurm.\n- Bug fixes.\nWho knows what \"Bug fixes\" might include, but anyway I will test this ASAP.\n. BTW @jsteube I think you mentioned clKernelArgIsMemoryObject in earlier VCL discussions. I can't remember the details and the trac discussion is gone now. Curiously enough Google hasn't heard of clKernelArgIsMemoryObject... what was that?\n. Several problems, mostly not dramatic:\n- VCL has a hard time sourcing header files from kernels. It's easy to understand why it's a problem and a variant of it is seen with JtR too. If you pass a path with -I in OpenCL build options, that path should be absolute and has to be valid from every node's viewpoint (eg. a shared directory for oclHashcat). Ultimately it's a problem with VCL and only for JIT compilation.\n- When run with NV devices (352.39), clCreateContext() fails \"CL_DEVICE_NOT_AVAILABLE\" after the node's VCL daemon (opencld) segfaults. This seems to be a pure VCL problem.\n- When run with AMD devices, Hashcat thinks vendor is \"generic\" so tries to define its own amd_bytealign() function. This clashes with the real one so the build aborts with error. The problem is you are using the platform vendor - using the device vendor would problably solve a bunch of problems.\nI tried a quick hack in oclHashcat so it assumed AMD vendor for VCL, and this introduced another problem: clGetDeviceInfo() -30 (CL_INVALID_VALUE). This is from using proprietrary AMD extension CL_DEVICE_WAVEFRONT_WIDTH_AMD that VCL doesn't support. Hacking that away (allowing failure and falling back to a hardcoded default), VCL basically \"works\" with AMD although I didn't really test it properly yet. Anyway you will probably need to keep track of platform vendor as well as device vendor and use the \"right\" one for each operation. For things like \"amd_bytealign\" you need to look at device vendor [per device], but for using proprietrary parameters you may need to keep using platform vendor (or simply handle errors and fall back to sane defaults).\nI may end up with a PR sooner or later. I emailed VCL developers about the -I and nvidia issues.\n. I'll try to test this within a week.\n. Nah, but please keep this open. VCL is evolving very very slowly but I do have some (even slower) communication with the authors. Rest assured I'm on this. VCL, when it works, is awesome.\n. A really fast implementation would have (at least) some inner loop on GPU... but like we discussed before it's certainly not trivial.\n. I'm extremely improductive at the moment but I'll have a look sooner or later unless someone beats me to it. The recent OpenCL changes have paved the way, should be very easy now.\nRight now though, Apple's OpenCL drivers are very crappy. They were perfectly fine with JtR prior to El Capitan but now we see segfaults, incorrect results and whatnot.\n. Sure, many combinations of formats/devices does work fine, but far from all of them. There was a major regression for El Capitan.\n. RAR5 is simpler than RAR3, it's standard PBKDF2-SHA256 and no UTF-16.\n. Have a look at JtR for complete code, including early-rejection code that is required for speed. You also need a lot of unrar-code, we nicked it from clamAV. You probably need to do all but the 256K SHA-1 on CPU side.\n. I whipped up a JtR plug today but didn't commit it yet: We should agree on an input format to use so we don't end up different. kirbi2john.py currently outputs this from the attached file:\n$ ./kirbi2john.py 1-40a00000-gtremblay@http~WIN-SS.ettic.ca~80-ETTIC.CA.kirbi \n$krb5tgs$unkown:3be794d602ed567c5fcd1b4cee7eb065$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\nThis is problematic in that it includes a :. Also, it puts checksum first and separated by $ from the other data. I don't mind that but it differs from krb5pa$23$.\nRight now my format use this instead (mimicing krb5pa$23$):\n$krb5tgs$23$$$$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\n(checksum now at the end, without any separator)\nAnother thing I'd need to know is whether the data portion (1076 bytes in this sample) can be smaller/larger? And if so, what is the maximum?\n. The best way to support this and other algorithms is to supply more samples! Ideally several per algorithm and from different networks and always with a known password of course.\nOh, and I've got another question (as long I only got the one sample a.zip attached above): I found the known plaintext 20............Z starting at cleartext[107] (while krb5pa has it at cleartext[14]). The latter is a fixed position but given only one sample I'm not 100% sure this one is? If it isn't, it probably will be faster not bothering with the known-plain optimization.\n. > Concerning AES, we could try to implement this ones too, but I don't know if this worths as this would be extremely slow and hard to implement using SIMD\nVectorized RC4 is also impossible to implement. But it's not a problem since it's so fast anyway and you can do parts of an algo vectorized and parts of it with scalar code.\n. @Fist0urs made me aware there is already a krb5tgs format in JtR (I didn't know/remember that). But that format is untagged, just <hex checksum>$<hex data>. I still think we should add some tag like krb5tgs$23$at minimum. Besides, the $23$ is relevant, isn't it? If we implement the other algos they will have other numbers, right?\n. FYI it turns out we've had reports (https://github.com/magnumripper/JohnTheRipper/issues/1838) that max size of eadata should be at least 20480.\nAlso, the \"known plain\" trick is unfeasible because the timestamp's offset does vary. I guess doing some variant of memmem() would be slower than just always doing a complete calculation.\n. We could establish some input syntax right now, for a starter. Something like\n```\n$RC4$*\neg.\n$RC4$40256deadcafe0531337cafebabeccbbaa00*08090a0b\n```\nWould that suffice? Do we need some more field(s)?. This is the same algorithm as the already implemented C/R NTLMv1 and has same opportunity to BF the 3rd DES and then run crazy fast. Only the input parsing differs.\n. @p1pkin not sure what you mean but see https://hashcat.net/forum/thread-2563.html (referenced in the thread epixoip mentioned). But if you're looking for finding a full 56-bit DES key I'm afraid 5500 wont help you at all.\n. Your 400MH/s figure is for descrypt, which is 25xDES. For cracking your DES key I think oclHashcat would do over 20 GH/s per GPU if someone wrote a format for it. With some help (volunteers) that key may well be cracked in a few days.\n. I think you should base it on m3000 (LM) for a starter.\n. Any number of CPU cores will still report as one single device (just like a GPU may have 3000 cores).\nI haven't given up on VCL just yet so I will test this sooner or later.\n. You already use dlopen() so I suppose you actually just need some ADL and NVML headers to be able to build. Redistributing [parts of] them ought to fall under fair use.\n. I just had a look at how it was done in JtR (two years ago, couldn't remember). For NV, we don't seem to have any whole file from their SDK, just a bunch of defines and declarations in our own header and that's it. Possibly copied from nvapi.h from their SDK but I really can't remember. I might have nicked it from https://github.com/gat3way/hashkill.\nFor AMD it looks like we simply provide straight copies of adl_structures.h, adl_sdk.h and adl_defines.h from whatever ADL SDK was released at the time. One could probably just pick the need-to-know from those files like we did for NV - but OTOH why bother.\n. I can't see any point of a plugin since you already use dlopen. The AMD/NV libs themselves should be the plugins!\nTo make that happen you'd just add the four needed headers (or select parts of them) to the tree and drop those SDKs from the build deps. Then you're set. If user doesn't have any non-free stuff, dlopen wont find them so they simply wont be used (even for AMD/NV, a failing dlopen should be a soft failure and behave just like --gpu-temp-disable after possibly emitting a warning). If it does find them, they will be used. Simple as that.\n. If I understand you correctly, you can't distribute JtR Jumbo at all because we currently do provide the AMD headers in our source tree, and have done so for two years.\nIf I were to create an independent header file with an MIT license (for use by both projects) that has all glue we need for NV and AMD, would that solve this problem? If not, I give up.\n. BTW I abandoned the idea of creating a single file shared between JtR and oclHashcat. I did try that idea first, but adding it to ext_ADL.h and ext_nvml.h ended up much cleaner IMHO.\n. Here's a wonderful way to produce a version string (here applied in oclHashcat master branch):\n$ git describe --tags --dirty=+\nv2.01-289-gcd430d5\nWhat it says is\n- Name of latest tag/release (v2.01)\n- Number of commits past that tag (289)\n- And finally a commit hash prepended with g (cd430d5).\nNote that a dirty tree (uncommitted changes) would show as \"v2.01-289-gcd430d5+\" so you would know that it was based upon cd430d5.\n. You could tag each beta (as in 2.10b61) and it would be reflected in the version string. Actually you should do that - how else are you going to find a particular beta in the Git history if needed?\nUnfortunately Github will list ANY tag as a \"release\". But it should not matter much.\n. Good stuff! Works fine on my macbook.\n. > if you want some details send me a mail or write me in private dev channel\nSo much for open source. Oh well.\n. Of course you should discuss some things OOB but if you keep the rationale for design decisions secret it only makes it harder for anyone outside your little club to contribute code. I can't see the upside, but never mind me.\n. That is very tedious to achieve but obviously has some advantages. Hashkill does that. I had a look (long ago) at nicking that code but opted not to.\n. I saw this too when trying to make VCL work. If compilation fails first time for whatever reason, it will later use the 0 byte cache file (with results as above guaranteed) instead of retrying a compile.\n. Breath through your nose, young jedi.\n. We need that test for nvapi.h anyway, because it also (sort of) tells us that nvapi.lib (or nvapi64.lib) is there. Until we dynamically load that lib, there's no point in changing that stuff.\n. I guess it could work fine with Cygwin but not with MinGW until someone contributes some Windows specific code. I wouldn't care about that, they still have O_APPEND which is enough for casual use.\n. This patch is essential!\n. Build verified on Linux, Windows and OSX. Actual functionality is verified on Linux. If the file is already locked by another process, we'll simply wait until we get the lock.\n. Does it crash on MD4 already or what format is causing the hang? My HD4000 works just fine until an Abort trap: 6 in SHA-3(Keccak) (and that may just as well be an Apple driver bug).\n. ```\n$ ./oclHashcat.app -d2 -b\noclHashcat v2.01 (gd544cdb) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz, skipped\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 1200Mhz, 16MCU\nDevice #3: GeForce GT 650M, skipped\nHashtype: MD4\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.:   290.2 MH/s\nHashtype: MD5\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.:   185.7 MH/s\nHashtype: Half MD5\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.:   111.8 MH/s\nHashtype: SHA1\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.: 68021.2 kH/s\nHashtype: SHA256\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.: 26484.3 kH/s\nHashtype: SHA384\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.:  8045.7 kH/s\nHashtype: SHA512\nWorkload: 16 loops, 256 accel\nSpeed.Dev.#2.:  7466.0 kH/s\nHashtype: SHA-3(Keccak)\nWorkload: 16 loops, 64 accel\nAbort trap: 6\n```\n. Yeah that works\n```\n$ ./oclHashcat.app -d2 -m 5000 -n 16 -b --benchmark-mode=0\noclHashcat v2.01 (g582378b) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz, skipped\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 1200Mhz, 16MCU\nDevice #3: GeForce GT 650M, skipped\nHashtype: SHA-3(Keccak)\nWorkload: 2 loops, 16 accel\nSpeed.Dev.#2.:   207.4 kH/s\nStarted: Thu Feb  4 23:44:23 2016\nStopped: Thu Feb  4 23:44:33 2016 \n```\n```\n$ ./oclHashcat.app -d2 -m 5000 -b --benchmark-mode=0 -u 8 -n 32\noclHashcat v2.01 (g582378b) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz, skipped\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 1200Mhz, 16MCU\nDevice #3: GeForce GT 650M, skipped\nHashtype: SHA-3(Keccak)\nWorkload: 8 loops, 32 accel\nSpeed.Dev.#2.:   213.6 kH/s\nStarted: Thu Feb  4 23:47:26 2016\nStopped: Thu Feb  4 23:47:35 2016 \n```\n. New, uglier but MinGW-compatible, version using putenv and a static.\n. Sorry I screwed up :-( That commit needs reverting/fixing.\nI thought I tested it, but I never tested it without any -w option... benchmark can now not be run at all.\n. I don't quite understand all these OSX ifdefs. Why are we doing anything special for OSX in this regard at all? It should be all about the target device and not about the OS: A Linux box might have a HD4000 and (at least theoretically) an OSX box might have a Titan X. Am I overlooking something obvious?\nOr put another way: If I boot my Macbook into Linux, why would the default loops/accel values change? The hardware did not.\n. I can now complete a benchmark of all formats with the HD4000, but it takes 45 minutes. And Bitcoin/Litecoin reports 0 H/s.\n. > @magnumripper everything is possible, look the reference link and propose a change :)\nMy proposition is to revert this commit. It was correct before, it's busted now.\n. > OpenCL devices are required to correctly track time across changes in device frequency and power states. The CL_DEVICE_PROFILING_TIMER_RESOLUTION specifies the resolution of the timer i.e. the number of nanoseconds elapsed before the timer is incremented.\nYou read it as \"after 80 ns, counter will increase by 1\". I am pretty sure the correct interpretetion is \"after 80 ns, counter will increase by 80\".\nA timer resolution of 80 merely says you can't measure smaller things - like 40 ns. It will go from 0 to 80 to 160.\n. We don't need it at all for our purposes. It's only there so you know what accuracy you are dealing with. My Macbook's GT650M has a resolution as bad as 1000 ns, so I simply can't measure anything smaller than a microsecond. My CPU device has the full 1 ns resolution.\n. @gm4tr1x you should have a \"revert\" button right here below. It will create a PR for revertion of this one.\n. And don't be sad, you made like a hundred damn good commits before this one ;-)\n. Like I said, if they return 1 as preferred width, they are virtually always performing best if you honor that. And like I said, they will auto-vectorize anyway.\nThis is the whole reason for the \"preferred\" query to exist.\n. Here's JtR with an AMD CPU driver, which has preferred width of 4 and is given that (note the 4x in the algorithm name within brackets):\n$ ../run/john -test -form:wpapsk-opencl -dev=3\nDevice 3: Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz\nBenchmarking: wpapsk-opencl, WPA/WPA2 PSK [PBKDF2-SHA1 OpenCL 4x]... DONE\nRaw:    21557 c/s real, 689 c/s virtual\nHere's an Intel driver instead. It has preferred width of 1 so is given scalar code:\n$ ../run/john -test -form:wpapsk-opencl -dev=4\nDevice 4: Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz\nBenchmarking: wpapsk-opencl, WPA/WPA2 PSK [PBKDF2-SHA1 OpenCL]... Build log: Compilation started\nCompilation done\nLinking started\nLinking done\nKernel <wpapsk_init> was successfully vectorized\nKernel <wpapsk_loop> was successfully vectorized\nKernel <wpapsk_pass2> was successfully vectorized\nKernel <wpapsk_final_md5> was successfully vectorized\nKernel <wpapsk_final_sha1> was successfully vectorized\nDone.\nDONE\nRaw:    21557 c/s real, 672 c/s virtual\nCuriously enough they end up exactly the same speed.\nHere's the result if disobeying the preferred vector size and using the native 4x anyway:\n$ ../run/john -test -form:wpapsk-opencl -dev=4 --force-vector=4\nDevice 4: Intel(R) Xeon(R) CPU E5-2670 0 @ 2.60GHz\nBenchmarking: wpapsk-opencl, WPA/WPA2 PSK [PBKDF2-SHA1 OpenCL 4x]... Build log: Compilation started\nCompilation done\nLinking started\nLinking done\nKernel <wpapsk_init> was not vectorized\nKernel <wpapsk_loop> was not vectorized\nKernel <wpapsk_pass2> was not vectorized\nKernel <wpapsk_final_md5> was not vectorized\nKernel <wpapsk_final_sha1> was not vectorized\nDone.\nDONE\nRaw:    21277 c/s real, 684 c/s virtual\n. JtR was just an example, it's very basic code with no interleaving (we do that only in non-OpenCL CPU code).\nThe thing I wrote above about \"auto-de-vectorizing and then auto-vectorizing\" was not something I made up, it's what Intel says will happen when you pass a vectorized kernel even though the device tells you not to. End result: longer build time, worse performance. In some odd cases the performance may end up slightly better by \"coincidence\" but that should be rare. I'm pretty sure I never saw it happen.\nAnyway, the best arbitrator is empirical data from testing oclHashcat of course. Is there a way to force scalar, or a certain width, from command line?\n. No matter what width I use or what accel/loops I try, oclHashcat is only doing 25% of JtR speed for WPA-PSK (eg. 5K vs. 21K) on same Intel CPU as the benchmarks mentioned above. This must be some unrelated issue. @jsteube that's the gear Solar gave you an account on btw.\n. OK that explains it. I will hold back my testing until we've got a really slow format supporting vector code, otherwise we'll just see interleaving effects that make the results very hard to draw conclusions from.\nMeanwhile I did find a new-ish whitepaper from Intel that contradicts things I've read and heard before. Perhaps the CPU drivers (as opposed to MIC/Phi ones) will auto-vectorize only if given scalar code and use already vectorized code as-is. I always thought that would be a better way to go even for the MIC. I really hate it when I give them pre-vectorized code and their compiler just ruins it. Anyway I can't imagine why the heck they would announce 1 if 4 or 8 is better.\n. This is good measure for generic device support. Perhaps it should be queried right after building kernel and cached, instead of querying for every call.\nYou should probably use it for the case of if ((data.opts_type & OPTS_TYPE_PT_BITSLICE) && (data.attack_mode == ATTACK_MODE_BF)) in line 2473 also, you just have to divide the result by 32 (which is done anyway).\n. No problem seen with latest code (g8af57d5), same hardware and OSX 10.11.13.\nAlso no problem seen with OP version (g952c20e), same hardware and OSX 10.11.13.\n. @averagesecurityguy try using -d2 and -d3 respectively, and see if problem is limited to a certain device.\n@jsteube @gm4tr1x perhaps a kernel build error could mention what device we were building for?\nEdit: it seems to be device 2 from OP.\n. You can't compile OpenCL code like that. But you could try running with --markov-disable and see if it works.\n. Building a compiler wouldn't change anything: oclHashcat would print the log if there was any. OSX' poor drivers often segfault while building, with no clue whatsoever as to why.\n. Yeah it's a bit hard to read. Here's the JtR CPU code (for accepting, not rejecting)\nc\nif (((!memcmp(ddata + 8, \"\\x63\\x82\", 2)) && (!memcmp(ddata + 16, \"\\xA0\\x07\\x03\\x05\", 4)))\n    ||\n    ((!memcmp(ddata + 8, \"\\x63\\x81\", 2)) && (!memcmp(ddata + 16, \"\\x03\\x05\\x00\", 3))))\n{\n    /* check the checksum to be sure */\n    (...)\n}\nSo worst case it's 5 bytes, best case is 6 bytes. That's far too small.\n. > But we have the case that \"header 1\" goes with \"footer 2\" and would say \"good boy\"\nThat can be avoided but we'd still only test five bytes worst case. It's pretty clear in the JtR code.\n. Not really, like I said in the other thread they auto-vectorize and is better given scalar code. This is for other devices, eg. CPUs with AVX-512 that doesn't auto-vectorize.\nPatch is complete but I will test some more before a PR.\n. You obviously need to run a version of jumbo built from the very same tree where you got electrum2john.py. Any older john version will just support punch card crypto and bit-sliced 6-bit hashes from the days of steam trains and hot air balloons.. Jim is on a road trip all over US. I think he's back next week.\n. @jsteube the salt here is already an MD5. So basically (in oclHashcat's view) the requested format is \nmd5(md5($pass).$salt) where $salt is 32 characters. For oclHashcat, the fact that the salt is an MD5 is more or less irrelevant except for the support of length.\n. > @magnumripper you sure about that? He said:\n\n\nthe salt is a md5 like value, created from the surname\n\n\nHe also said\n\n\nthe length is 32\n\n\nHis example hashes indicate the salt is stored as ready-to-use MD5:\nad1f95326d65ee793fa347ab7345b246:fc13de57255bed2c26fb5edaa3733640 takealunch\nf84dec8b20b7ea511cb0085f0ec0afcc:3e6affc692019dc8d476111d25872fa1 oscar1017\n5b4ea443ca4d325b60e9d95ce4c0943c:81599f2145e887463733f2810f6a8c72 N3V3R_m0r3\nIt's not 100% clear from the OP whether we know the surname so we can calculate the salt ourselves. @andreamoreto please clarify!\n. @jsteube JtR supports the padding attack using this format (given by Ettercap)\n$o5logon$22E8FA41826608560F0B2A713724689F3D28640577B511B9C36178418C138210D820F7800C14C579D5094F4BBB0E0EBD*A0F9FC5E0D992692AA35\nmeaning\n$o5logon$ <server's AUTH_SESSKEY> * <AUTH_VFR_DATA>\nThe above is enough when exploiting the padding weakness.\nFor this new case, we need to add fields. Something like:\n$o5logon$ <server's AUTH_SESSKEY> * <AUTH_VFR_DATA> * <AUTH_PASSWORD> * <client's AUTH_SESSKEY>\nI'm almost finished with Ettercap support that I'll push upstream once we agree on the format. Are you OK with the above? For the first example by OP it'd be:\n$o5logon$22E8FA41826608560F0B2A713724689F3D28640577B511B9C36178418C138210D820F7800C14C579D5094F4BBB0E0EBD*A0F9FC5E0D992692AA35*5ECC855E89402343D75CA84630222EC0B677929CFFDE91FB0F2EA3BDCEEDAAE9*0F8D4466C0B1A5B9FA68A63B94EB2BA23F222678D7969C2348ADF52C58D1D21DF290794A5208EDD12D0EF71A88687FF4\n. @jackpit110 do you know whether we can use some info from a pcap that tells us whether the padding trick is applicable or not? Like a server version figure or something?\n. > Because the client has to encrypt the plaintext passsword the size of the AUTH_PASSWORD will change whenever the password exceeds the length 16 or more.\nLooks like iphelix found this out in 2009, there's some notes on https://www.thesprawl.org/research/oracle-authentication about it. But the more interesting thing on that page is the server version number stuff. I'll try to parse that too in Ettercap, and add as yet another field. Eg. for version 10.2.0.1.0, the hash will be:\n$o5logon$22E8FA41826608560F0B2A713724689F3D28640577B511B9C36178418C138210D820F7800C14C579D5094F4BBB0E0EBD*A0F9FC5E0D992692AA35*5ECC855E89402343D75CA84630222EC0B677929CFFDE91FB0F2EA3BDCEEDAAE9*0F8D4466C0B1A5B9FA68A63B94EB2BA23F222678D7969C2348ADF52C58D1D21DF290794A5208EDD12D0EF71A88687FF4*0A200100\n. @jackpit110 so maybe the server version number I just mentioned is not very interesting. The LOGON_VERSION used in the authentication is what we need. I'll try to find it.\n. There's also a semantic question: Is it still called \"o5logon\" in Oracle 12? I think it is but I'm not sure.\n. > @magnumripper While implementing it turns out there's a bug in your format.\nUnfortunately it's been $o5logon$hash*hash for several years so we need to stick to it. For example, Ettercap will output it that way. Blame @kholia \ud83d\ude04 \nOn another note the current official Ettercap handles some pcaps poorly. There's a fixed version in my fork and it's also capable of outputting this longer format with all of the fields. I'll wait with pushing it upstream until I can see difference between protocol version 11 and 12. And I will add some kind of version field as the very last one.\n. The ekoparty pdf (page 19) mentions this:\nSQLNET.ORA config file:\nSQLNET.ALLOWED_LOGON_VERSION=12\nIdeally we'd need a pcap with this set to 12 and another with 11 (or whatever was before 12), all else equal. Then we might see a difference in negotiation.\n. @jackpit110 for that oracle 12 pcap, current Ettercap shows username as \"AUTH_TERMINALunknown\". I need to fix that. Looking into the data it looks like actual user was Administrator, is that correct?\n. > @magnumripper no. username is sys. and connected as sysdba\nToo bad, we don't seem to be able to find that in the pcap. This can make it hard to know what user you cracked. Best we can do is list client's IP (or DNS name).\n. Oh, right. I was lazy and just ran strings(1) on the pcap but since SYS is just three letters, it wouldn't show.  Using tshark -x is better. So while some change seem to be needed to Ettercap, the data is definitely available.\n. > jtr is not able to crack oracle 12 cap.\nSince June 22, it is (but only the CPU version for now). And you need to use Ettercap from my fork, or put it together manually. Also, JtR is much slower than it should be (it's not using SIMD) and the GPU version is a joke.\nMy take so far in JtR is that if the old two-field format is used, the padding trick is used (well that's the only thing we can do with that). And if all four fields is there, the padding trick is never used so Oracle 12 does crack with that format.\n. > so to detect presence of padding we should check client version, if version is 11.2.0.3/11.2.0.4 or above that we know there is not padding.\nI now have detection of client/server versions in a private fork of Ettercap (the 0xDEADBEEF ANO packet) but I'm not sure you are right with the details so I'm unsure how to use the information:\n- Several of my sample pcaps (available here) are client 11.2.0.3 and do use PKCS padding.\n- Your oracle12-zip is a client v. 10.2.0.0.0 talking to a server v. 12.1.0.1.0, right? And it does NOT use PKCS#7 padding.\n- That ekoparty pdf, page 19, says clients older than 11.2.0.3 can't use \"logon version 12\", which seems to translate to random padding. Again, your pcap seems to prove the opposite.\nI'm at a loss here. I can't see any particular parameter in the pcaps showing us whether we can safely exploit the padding trick or not.\nPerhaps if both the server and client are older than 11.2.0.3, we can safely assume PKCS padding. If both are between 11.2.0.3 and 11.2.0.4, we can only \"hope\" for PKCS padding (risking false negaitves).\nThere should be at the very least 2x performance gain with the padding exploit. We only need one SHA-1 + one block of AES. Without it, we need the SHA-1, two MD5's and eight or more blocks of AES.\n. \ud83d\udc4d great info, I'll try to complete my Ettercap patch and push it upstream. If we can find out actual fields that are safer to use than version numbers, we can change that later.\n\nso why those documents say 11.2.0 ?? may be those are before patch release.\n\nI guess that's the explanation.\nSo @jsteube do you have any preference for how Ettercap should treat a hash known to have the padding vulnerability? Should we simply output the old two-field o5logon syntax for those, or should we output all fields anyway and add some last flag field (eg. opening up for combining known plaintext length with known padding)? I'm not sure what I prefer. I think I prefer the latter. We could add a simple flag field where bit 1 means PKCS padding. So hashes will currently end with *00 or *01 although we'd reserve the other bits for future use so eg. *07 would also mean we can use the padding trick.\n. > now what is it??\nIs that from one of your posted pcaps? I'm not sure what you mean at all but my ettercap code has changed significantly.\nOn another note, I submitted my Ettercap fixes upstream in https://github.com/Ettercap/ettercap/pull/742\n. Perhaps it's actually fallling back to NTLMSSP? That's a whole different story. Ettercap doesn't recognize a single packet from that pcap. Or does it fall back to o3logon? We don't support that yet.\n. Yeah I've struggled with these for years. Early Maverick was very very poor, then it got better and better and right before Yosemite, all JtR formats worked fine (partly because of workarounds but also a lot better driver). Then for some idiot reason, Yosemite made it just as bad as Maverick in 2012 and that's about where we are still.\nHere are some outrageous examples:\n- Having two spaces in a row anywhere in in build options (as in -Dthis -Dthat  -Ipath) triggered a fatal error in some version(s)!\n- A header file that missed the last line's LF, when #included, was mixed with the sourcing file's next line, causing havoc!\n- Several times I've seen I needed some kind of barrier like this even though there is absolutely no reason AFAICS - and only Apple needed it:\n``` c\nif OS_X && gpu_nvidia(DEVICE_INFO)\n/*\n * Driver bug workaround. Halves the performance :-(\n * Bug seen with GT 650M version 10.6.47 310.42.05f01\n */\nbarrier(CLK_GLOBAL_MEM_FENCE);\n\nendif\n```\n...and sometimes there's not even any normal barrier that does the trick. Here's a crazy workaround actually in use in JtR in some place. Note that the condition is never true!\n``` c\nif OS_X && gpu_intel(DEVICE_INFO)\n/\n * Ridiculous workaround for Apple w/ Intel HD Graphics. I tried to\n * replace this with a barrier but that did not do the trick.\n \n * Yosemite, HD Graphics 4000, 1.2(Jul 29 2015 02:40:37)\n */\n    if (get_global_id(0) == 0x7fffffff) printf(\".\");\nendif\n```\n- The below replaces a function with more or less an exact copy of the same function. For some crazy reason that works around some bug:\n``` c\nifdef OS_X\n    /* This is the weirdest workaround. Using sha1_final()\n       works perfectly fine in the RarFinal() subkernel below. */\n    PUTCHAR_BE(tempin, pwlen + 11, 0x80);\n    for (i = pwlen + 12; i < 56; i++)\n        PUTCHAR_BE(tempin, i, 0);\n    tempin[14] = 0;\n    tempin[15] = (blocklen * (round + 1)) << 3;\n    sha1_block(tempin, tempout);\n\nelse\n    sha1_final(tempin, tempout, blocklen * (round + 1));\n\nendif\n```\n...and these were just some examples. In my darkest moments I deemed Apple even worse than AMD, but to be honest they are still not THAT bad \ud83d\ude04 \n. Oh, and many many other times (unfortunately not documented) I've had great success just shuffling code around in a way that shouldn't make any difference whatsoever. It's extremely frustrating to have to resort to \"throw things at it and see what sticks\".\n. On my machine (latest OSX) both the native and Homebrew's gcc define __APPLE__ by default, but not __DARWIN__\n```\n$ gcc -dM -E -x c /dev/null | egrep \"(APPLE|DARWIN)\"\ndefine APPLE_CC 1\ndefine APPLE 1\n$ /usr/bin/gcc -dM -E -x c /dev/null | egrep \"(APPLE|DARWIN)\"\ndefine APPLE_CC 6000\ndefine APPLE 1\n``\n. Perhaps you could open a PR with suggested improvements? It'd put you in the hall of fame!\n. Why would you not be able to exhaust?l?l?l?d?d?d?d?d?d? That's a tiny keyspace for NTLM.\n. I agree, 1. is what I would expect\n. FWIW: We had a similar problem with JtR recently, that was with-I /some/path` given to the OpenCL run-time compiler. We now simply enclose the whole path with quotes.\nEDIT: It seems that was handled differently in #432.\n. JtR core supports arbitrarily long salts but most optimized formats has a fairly tight limit just like Hashcat, to keep things in one or two Merkel Damgard blocks.\nThis particular format is supported in JtR as dynamic_2009 (only CPU) with salt lengths up to 200 (same format with max. 23 bytes salt is dynamic_9 and it's obviously faster).\n. Using a decent shell you should just escape an actual tab character. Normally that would be something like 'ctrl-v + tab' surrounded by quotes.\n. > Is it as simple as vram / size_of_hash?\nMy guess would be a quarter of that. For some (silly) reason, nearly all OpenCL implementations limit size of any single alloc to a quarter of total memory. You can see that figure when listing devices:\nDevice ID #2\n    Type           : Gpu\n    Vendor ID      : 2147483648\n    Vendor         : NVIDIA\n    Name           : GeForce GT 650M\n    Processor(s)   : 2\n    Clock          : 900\n    Memory         : 256/1024 MB allocatable\n    OpenCL Version : OpenCL C 1.2\nThe \"256/1024 MB allocatable\" is what I'm talking about. You can allocate all 1024 but only at most 256 MB at a time.\n. > Once I've got my intended algorithm working I'll look at contributing some documention for new users wanting to implement new algorithms using the FNV1a32 as a basic example.\nGreat \ud83d\udc4d \n. > instead of a range of aaaaa -> zzzzz I got sange -> uqoql\nThat is fine, they come in probability order instead of alphabetical.\n. Good info here. @polarathene I think your format will be a great \"template\" for how to write a format, since the actual format-specific logic is so simple. So how about extensively documenting things with inline comments, eg. everything @jsteube said about il, cnt and so on. This would be great for people like me who might implement one format a year or so. And from then on, we can always refer people who'd like to write a format from scratch to look at this format.\n. Also, what is the actual problem here? Why would you need to alloc/free at all? Why doesn't the stack variable do the job just fine?\n. > @magnumripper try example0.sh (without apply my patch) and check if you got a segmentation fault.\nYeah I do. I'll debug it a little.\n. Debug data is very strange. I think the real problem is something earlier, like a stack smash. But ASan doesn't help me. Did anyone try running with Valgrind (on Linux)?.\nProcess 7438 stopped\n* thread #5: tid = 0x65c6c, 0x00000001000485af hashcat`check_hash(hashcat_ctx=<unavailable>, device_param=<unavailable>, plain=<unavailable>) + 14 at hashes.c:225, stop reason = EXC_BAD_ACCESS (code=1, address=0x700000eb2718)\n    frame #0: 0x00000001000485af hashcat`check_hash(hashcat_ctx=<unavailable>, device_param=<unavailable>, plain=<unavailable>) + 14 at hashes.c:225\n   222  }\n   223  \n   224  void check_hash (hashcat_ctx_t *hashcat_ctx, hc_device_param_t *device_param, plain_t *plain)\n-> 225  {\n   226    debugfile_ctx_t *debugfile_ctx = hashcat_ctx->debugfile_ctx;\n   227    loopback_ctx_t  *loopback_ctx  = hashcat_ctx->loopback_ctx;\n   228  \n(lldb) print hashcat_ctx\nerror: Couldn't materialize: couldn't get the value of variable hashcat_ctx: read memory from 0x700000eb2718 failed (0 of 8 bytes read)\nerror: errored out in DoExecute, couldn't PrepareToExecuteJITExpression\nIt does happen on second call to check_hash().\n. Oh, right. But anyway I think the alloc/free just hides a problem still present. That stack size theory might be correct, is there a way to bump it?\n. Personally I like the current behaviour better. I even saw to it that JtR works the same way when using -mask with a length range. Just my two cents.\nSpecifically, it helps dealing with the \"exponential wall\" without calculating beforehand. If you are at eg. length 9 and see that it will complete within a day or two, you keep it running. If (using a slower hash) it says it will take three months, you quit and reduce the keyspace.\n. Does your core code allow launching different kernels for different salts? If so, you could have a kernel optimized for a single block, another for two blocks and a third (slower) for arbitrary length.\nIf this isn't possible with current code, perhaps it's not too hard to implement?\n. Sure, that's the base of the idea. I already have that code in use elsewhere and it's proven to work like a champ. For extremely short (eg. two bytes) passwords consisting of random binary data there's a slight chance of mis-interpreting - but actually there's not much harm there either. Once you realise this is the case you can always re-encode it. No data is lost! For lengths of 3-4 bytes already, the risk of mis-interpreting is really slim. For real-life passwords, it practically never happens.\nHaving said that, I think it's a good idea to \"blacklist\" LM from this default behaviour since we know it's never ever made of UTF-8 but from an \"OEM codepage\" like CP850. Same goes for 40-bit RC4 brute-force as in eg. oldoffice.\n. I didn't realize I could use -o for this (in fact I didn't realise the difference between output file and pot file). I'll try using -o /dev/null\n. Sure, closing a file implicitly unlocks it. In fact, unlocking before close would be a race condition unless you flush before unlocking.\n. In fact I think there's more room for improvement: You should ideally open your session file at start of run, then lock it and never close it (I think that's not the case right now) until actually exiting. This way there's no chance you accidentally start another session with same name (or default name) and end up with some one of them actually saved (the one that happened to write last). This is how JtR was made some 20 years ago and it has saved many many hours of cut/paste mistakes...\n. I realized I had missed one instance, added now.\n. > Are you planing to add something to this or can I merge already?\nI'm pretty sure it's fine right now. I haven't tested it as much as I did #177 though.\n. I don't do windows at all ever. What if you change it to\n``` c\ndefine lock_file(dummy) void dummy\n``\n. ...no that will probably not be better. Perhaps we should #ifdef all calls to (un)lock_file instead. Or just that call.\n. Yeah a format flag is the way to go, that'll be perfect.\n. What's the reason you ended up using|instead of,`? Just curious.\n. This is the silliest driver (or run-time) bug ever. It was present already in OS X Mavericks three years ago - we had a similar problem in JtR back then.\n. Sounds more like a cap2hccap problem\n. We absolutely need the locking. However, we're [supposedly] only locking during actual write so something seems to be amiss. I will look into this ASAP!. BTW another test would be to run two instances of HC using the same pot file. This is supposed to work just fine, with no noticable performance problem (unless of course both instances crack thousands of passwords per second - that would mean a little performance drop but the pot file will end up correct and not thrashed). . Apparently the --show and --left options use potfile_write_open which is a bit unintuitive as it's only supposed to read. My fix in #895 works around it.. Yes, I too reviewed all of them and hopefully it's all OK now.. Honestly I don't think it would end up being used a whole lot IRL. We both already have the workaround of using a different field separator and it's nearly always safe using TAB (but obviously there are exceptions).\nUnlike HC, JtR never ever *) use : as a salt delimiter, we usually use $ or *. I guess that simplifies it a bit for us. Our pot file will always have the first : regarded as a field separator and any remaining ones will be regarded part of the plaintext.\n*) Except for cases where eg. the user name field automatically is added as salt, but that's a different story.. Oh, and for salts containing a :, JtR has hex notation $HEX$dead3ababe for input files, similar to your plaintext $HEX[dead3ababe] for output files. I don't know if HC supports that?. Isn't \"weak hashes\" just your name for hashes of null string? They don't exist for WPA-PSK since the minimum length is 8. Perhaps some kernel code assumes a longer string and misbehaves with a null string? Just throwing out the idea.. I can reproduce this problem with OSX CPU device (works fine with GPU and Iris). I get CL_INVALID_COMMAND_QUEUE though.\nI tried disabling the weak hash check and it didn't help.. @dtest505 yes it is. At 100000 MH it will start saying 100 GH. I suppose the reason it doesn't do so earlier is you lose too much detail because there's just one decimal: 1423.4 MH would show as 1.4 GH.. The problem with --increment-min/max options is you can't abbreviate them except for the very last letter. How about --lengh-range=4,8, which can be abbreviated to just --len=4,8?. Same problem. You'll need to type --increment-r before it gets unambigouous. Interesting. OSX sed(1) sucks so I have GNU sed installed too. It has at least one option with optional parameter, -i [suffix], and that works just fine. Perhaps I should have a look at how they did that.. OK it turns out OSX getopt doesn't support optional arguments but getopt_long (which isn't POSIX anyway) does (just like GNU's). So as long as we use getopt_long, optional parameters should not be a problem.. JtR has 'P' for english grammar (eg. crack -> cracked). We've been talking about trying to unify rules commands but in this case it's probably not a problem since HC will likely never get the JtR version of 'P' anyway and on the other hand, JtR can't currently implement this version of 'P' since it can not currently handle nulls within plains.\nSo, in short: No problem there.. There already are many collisions. We have https://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/doc/RULES#L104-L303.\nRecently Jim added a \"hashcat rules mode\" where we behave differently and try to mimic hashcat (hashcat legacy even, I think) rules. https://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/doc/RULES-hashcat\n@solardiz @jfoug . > Note if you compile from source to do a make clean\nWith a perfect Makefile, this is never needed so some dependency must be missing. I've been meaning to audit that for a while (using some tools of mine) but then again it's not super important.. > that's why Im here asking for a new algorithm.\nAnd that's why @kholia pointed to some additional samples and example parsing code just in case it would spare Atom some work or research. You sound like a dumb kid.. FWIW I agree with OP. If user says -d (...) it would be logical to over-ride the default for -D.. That sample code is ancient and we no longer use that tag. This now corresponds to krb5pa-sha1 in current JtR. It's straightforward to implement and finally uses UTF-8 like anyone else IIRC.\nc\n{\"$krb5pa$18$user1$EXAMPLE.COM$$2a0e68168d1eac344da458599c3a2b33ff326a061449fcbc242b212504e484d45903c6a16e2d593912f56c93883bf697b325193d62a8be9c\", \"openwall\"},\n{\"$krb5pa$18$user1$EXAMPLE.COM$$a3918bd0381107feedec8db0022bdf3ac56e534ed54d13c62a7013a47713cfc31ef4e7e572f912fa4164f76b335e588bf29c2d17b11c5caa\", \"openwall\"},\n{\"$krb5pa$18$l33t$EXAMPLE.COM$$98f732b309a1d7ef2355a974842a32894d911e97150f5d57f248e1c2632fbd3735c5f156532ccae0341e6a2d779ca83a06021fe57dafa464\", \"openwall\"},\n{\"$krb5pa$18$aduser$AD.EXAMPLE.COM$$64dfeee04be2b2e0423814e0df4d0f960885aca4efffe6cb5694c4d34690406071c4968abd2c153ee42d258c5e09a41269bbcd7799f478d3\", \"password@123\"},\n{\"$krb5pa$18$aduser$AD.EXAMPLE.COM$$f94f755a8b4493d925094a4eb1cec630ac40411a14c9733a853516fe426637d9daefdedc0567e2bb5a83d4f89a0ad1a4b178662b6106c0ff\", \"password@12345678\"},\n{\"$krb5pa$18$aduser$AD.EXAMPLE.COM$AD.EXAMPLE.COMaduser$f94f755a8b4493d925094a4eb1cec630ac40411a14c9733a853516fe426637d9daefdedc0567e2bb5a83d4f89a0ad1a4b178662b6106c0ff\", \"password@12345678\"},    \n/* etype 17 hash obtained using MiTM etype downgrade attack */\n{\"$krb5pa$17$user1$EXAMPLE.COM$$c5461873dc13665771b98ba80be53939e906d90ae1ba79cf2e21f0395e50ee56379fbef4d0298cfccfd6cf8f907329120048fd05e8ae5df4\", \"openwall\"},. Yes I just realised this too. So perhaps we should just add new fields in the end (those fields shall be invalid for $7z$0$).. As discussed in https://github.com/philsmd/7z2hashcat/issues/6 I seem to do just fine with just the \"first file size\", aka. crc_length, eg:\n$7z$1 or 2$...$[data]$[crc_len]$[coder_attributes]. Sorry, that was meant for 7z2hashcat project. However, this will apply to HC if implemented so I'll leave it open.\nhttps://github.com/philsmd/7z2hashcat/issues/5. This can be handled within #965.. @DoZ10 don't you also need to comment out the early rejection of e? Eg. line 493 of m00100_a1.cl.. The really cool thing with Solar's single mode, is it will run near single-salt-speed with many salts. That's obviously because it only tries the things described above on the very user that had them (unless there are salt collisions, in which case all other hashes with same salt will be tested too). The bad news is this is all CPU, and would be very tricky to implement on GPU I guess. JtR \"can\" use single mode with GPU formats, but they perform like shit (if at all).. This applies to non-split vanilla archives too, the hash often ends up too long for Hashcat.. Oh, that's great! Wasn't mentioned in commit description so I had no idea it was fixed. So is there virtually no limit now? Just OS/FS limits?. I have wanted something similar. For what it's worth, 'S' is already taken in JtR. Ideally we should find some mnemonic compatible with both HC, JtR and possibly others.\nHeads-up @solardiz.. I'll try to create a wiki page listing all free or taken HC and JtR-jumbo mnemonics ASAP. That will come handy in the future too.. In JtR, 'a' is free but not 'A'.\nhttps://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/doc/RULES\nI really should create that wiki page.. This would work\n```\nOSDARWIN        := $(shell uname -s | grep -c Darwin)\n(...)\nifeq ($(OSDARWIN),1)\n    (...)\n``\n. ...but I see now there already is someifeq ($(UNAME),Darwin)` in there. So just moving the stuff around should do. But why limit it to 16 at all? Darwin <16 didn't have gsed either, yes?. I can see a little room for enhancement with that... How about allowing use of default custom charsets 1..4 with a specified non-default mask, and vice versa (as in OP)? Should be a trivial change in code. I have several times wanted that and been bitten by this unintuitive behavior.. > I'd suggest abort hashcat with an appropriate error message if the user specifies a custom charset but does not specify a mask.\nThat's definitely better than current behavior.. https://github.com/magnumripper/JohnTheRipper/issues/2318 is the longest sample I've seen. After that we use 5 MD blocks (311 bytes) for SHA-256 but we're apparently still at 2 blocks (239 bytes) for SHA-384/512.\nI can't recall what plaintext that sample had but it was cracked immediately so probably something like \"secret\".... Just out of curiosity, what is the use case? Hash collisions?. Strange, __unix__ should be defined on all BSDs except MacOS and _POSIX should be less safe to use. I think you updated your patch though.\n```\n-bash-4.4$ uname -mprsv\nOpenBSD 6.0 GENERIC.MP#116 amd64 amd64\n-bash-4.4$ cc -dM -E -x c /dev/null | grep -iE 'unix|posix'\ndefine unix 1\n-bash-4.4$ gcc -dM -E -x c /dev/null | grep -iE 'unix|posix'\ndefine unix 1\n```. I believe @e-ago will commit a utility and establish a hash format in https://github.com/magnumripper/JohnTheRipper/pull/2427 RSN. If you do so before her, I'll see to it that JtR uses the same hash format.. I think @e-ago mentioned somewhere AES-XTS is not needed for cracking, just normal AES.. A bunch of files (eg. autom4te.cache, config*.cache and config.status) should be added to .gitignore\n. Yeah, and it should be added to this PR. That doesn't make any sense. You would need a known plain or something.. OK that makes sense \ud83d\ude03 . You mean missing zeros in the hex representation? I think you'd be better off using a perl script (or something) that brute forces all possible full hashes from what you've got. That \"backwards\" way will run near full speed as opposed to a cracker that does it \"forwards\". At least unless you've got a really huge set of them.. Something like that, yes. If your hash is 31 characters, you'll end up with 31 versions of it. If your hash is only like 25 characters, there will be lots of alternatives but it will still not slow Hashcat down much.\nI bet @philsmd could write a script for it in five minutes if you could persuade him (it would take me longer because I tend to code first and think later and this is somewhat tricky). \nBut again, if you have lots and lots of them, it could be worthwhile creating a format. Is this a one-off? Where did you see it?. http://www.legic.com/en/products-and-services/507894/applications.html\nhttp://www.legic.com/en/products-and-services/smartcard-ic-s/507936/advant-on-credit-card.html. This could end up in lots of bloat but I can see some useful cases.\nJust FWIW, JtR has a KISS variant of it: Given a negative N for --max-runtime=N it will stop after that many seconds of not cracking anything.. > progressp - progress percentage (probably not useful)\nI can see a use case. Let's say you attacked 500 salts for a week and got 12.34% progress. Then you get a few more hashes. You could pause the first job, run the new hashes up to 12.34% and then resume the original job with the new hashes added to it.. Hard-coding 20 can't be right. It should be more like this\nc\n    if (outfile_ctx->outfile_format & OUTFILE_FMT_CRACKPOS)\n    {\n        tmp_len += sprintf (tmp_buf + tmp_len, \"%\" PRIu64, crackpos);\n    }\n(Edit: I see @philsmd already commented on #1195. snprintf should be used as well.). Not sure about .induct and .outfiles, should they too be moved to distclean?. > 11. Please unroll this section by hand:\n\nfor (i = 0; i < 8; ++i)\n    v[i] = S->h[i];\n\nWhy would you want things like that manually unrolled? Just curious.. According to the article (unless I misunderstand), the boost was 2500x and the speed on an i5 CPU was a whopping 6 MH/s. But Apple fixed it in IOS 10.1 so it's probably not a big deal (except I too am curious to know the details).\nIs hashcat really only getting 120 H/s on a GTX1080? That doesn't look right. JtR gets 2348 H/s on my (old) laptop CPU and that format isn't really optimised at all AFAIK.. The only archive I've seen is the non-public one we got from a user. Phil can send it to you (or I can). The performance drop is insignificant except for the case of attacking a lot of hashes at once (because we can re-use the KDF, but not the AES and verify, for each \"salt\" - are you doing that in hashcat too?).. It sure is shell wildcard expansion. I never saw that, it's a bit amusing. One workaround is to just wrap the mask in quotes. There's no way to fix this in hashcat as it happens even before hashcat starts. Try changing \"hashcat\" to \"echo\" and you'll see what happens.\n```\n$ touch al bl cl\n$ echo -m 3 -m 0 example0.hash -1 ?l ?1?1?1?1?1\n-m 3 -m 0 example0.hash -1 al bl cl ?1?1?1?1?1\n$ echo -m 3 -m 0 example0.hash -1 \"?l\" ?1?1?1?1?1\n-m 3 -m 0 example0.hash -1 ?l ?1?1?1?1?1\n. BTW another workaround is to use long option `--custom-charset1=?l`\n$ touch al bl cl\n$ echo -m 3 -m 0 example0.hash --custom-charset1=?l ?1?1?1?1?1\n-m 3 -m 0 example0.hash --custom-charset1=?l ?1?1?1?1?1\n``\n. The code is OK. We are deliberately using the fall-through feature of switch/case and apparently the-Walloption now comments on that. Just add-Wno-implicit-fallthroughto get rid of the warning.. Will still might want to add-Wno-implicit-fallthroughbefore most dists has a gcc that new.. I think-Wimplicit-fallthroughis a good option but it shouldn't be included in-Wall`. Is gcc 7.1.1 a mature release?\nPersonally, I really wouldn't want to bloat the code with non-portable attributes to work around silly compiler warnings for perfectly fine code. In JtR I will add -Wno-implicit-fallthrough when supported by compiler.\nBTW how would an older version of gcc react to __attribute__((fallthrough)) (which it won't recognize)? With a warning? Then we're back to square one.. > Personally, I really wouldn't want to bloat the code with non-portable attributes\nI take that back. #1266 solves this in a way that doesn't fail on other compilers, and that actually makes the code a bit more clear about what's happening.\nBTW it's not -Wall that turns this on, it's -Wextra.. IMHO, while the format name might better be ChaCha20, the tag (or signature) should be $chacha20$in all lower. Some tags are all upper (I think) but few ones should have a mix.. > @magnumripper, I'm not attached to either approach strongly, but just out of curiosity, other than historical trends, are there any practical or programmatic reasons why mixed case would be bad?\nIt's not the end of the world but I know for sure that mixed-case tags will lead to confused users. Tags aren't labels and they aren't clear-text. They are just... tags, and in the end of the day they are more like \"machine readable\" than \"human readable\". They should definitely be simple: Either all upper or all lower IMO.. Also, the real arbitrator is compatibility. If hashcat would have ended up having it as $cHaCha20$ before we implemented anyting else, we would have used that in JtR too, fugly or not.. > There's no commandline option to show the max password length supported, but a relative good wiki article where the max lengths are listed.\nWhere? Google let me down.. OK, git grep 'hashconfig->pw.max' is good enough for me \ud83d\ude06. Appveyor MINGW32 as well as MINGW64 (Cygwin 32/64 are fine):\nsrc/shared.c: In function 'get_random_num':\nsrc/shared.c:379:3: error: implicit declaration of function 'rand_s'; did you mean 'rand_r'? [-Werror=implicit-function-declaration]\n   rand_s(&r);\n   ^~~~~~\nThis function wasn't prototyped by MINGW headers some time ago - is it now? If not, just add this in some sensible place.\nextern errno_t rand_s (unsigned int *randomValue);\n...or maybe it is prototyped nowadays although Appveyor runs an older MINGW version where it isn't. Then you'll need a few gears to sort that out.... #68 \nIn order to check such RAR3 archives you need to implement loads and loads of deflating code on CPU side (it simply wont work on GPU), with very clever early-rejection stuff to keep speed up.. I'd be curious to understand exactly how/why it fails with no warning/error. Is there some error reported by GPU but not handled or what? I mean, if you successfully pushed everything to GPU it should work. If it didn't fit, you obviously should get some kind of error return.. All and any memory used are allocated and if you didn't get any error when allocating it I can't see what would break. Could this be something else?. Well it could theoretically be a bug in bitmap stuff or whatever. But 2^24 is not a huge deal. It's very strange that none of the hashes get cracked.. On another note, it's called hashcat, not hashtag \ud83d\ude02 \ud83d\ude02 . So we need a fix in rar2john (rar2hashcat) as well as in the crackers?. What use would a cracker have for that functionality? We're \"able to crack passwords using GPUs\" already, without vendor-specific stuff.. > The problem is that the algorithm puts in a fixed 0x80 byte at position 16. If the password (including the salt) is longer than 16, then I'm not exactly sure how to handle that.\n\n@magnumripper Any Idea? I see JtR is limiting to lenght 16 as well\n\nYeah it was 16 at the time we got the first version of our format. I guess we need to bump it in JtR too.\nSo, we'll need some samples with known plain, to determine how to terminate the longer passwords. Perhaps it's set at minimum pos 16 (with nulls or spaces as padding? Can't remember but easy to check source) but then follows normal termination? That would be backwards compatible. But there's no point in guessing - we need samples!. Off the top of my head, the S rule in JtR is simply hard-coded for a US keyboard. You could of course make custom rules for custom keyboards (not using S but eg. s1! s2\" s3# s4$ and so on) but it'd be slower.. I must have missed the original change in rules syntax. Where did that happen? Was it good or bad in terms of compatibility?. How long is that salt? Can you please provide a test vector with a known password?. Is it always 4 digits? A trivial CPU implementation or even a perl script exhausts that keyspace in a few seconds. Writing a GPU format for it would be a total waste of time.\nIf the key can be other characters, perhaps even Unicode ones, it makes a little more sense.. FWIW, most often when my macbook crashed good enough to reboot (which is very very rare), it was a \"watchdog timer\" issue. I have yet to find a way to turn that shite off on macOS.. What if you put single quotes around the hash as in\nhashcat -m 10400 -a 3 -w 3 '$pdf$4*4*128*-3904*1*16*8aaf9105962aaa4182602a81b9485e69*32*615bb2bf8976796e272a3ca130b417d76a6d4429f3a6c5f3ab574bf17a02ff7d*32*3add260c37d64307876f6f0168414109638d74600eeccb925d4d472ee462e4f0' ?b?b?b?b?b?b?b?b?b?b. >\"/home/motion/hashcat-4.1.0/OpenCL/inc_vendor.cl\", line 102: error: can't\n          enable all OpenCL extensions or unrecognized OpenCL extension\n  #pragma OPENCL EXTENSION cl_amd_media_ops2 : enable\nFWIW, the correct way to know whether a certain driver supports #pragma OPENCL EXTENSION cl_foo_bar is #ifdef cl_foo_bar per the OpenCL spec. This is quite handy.. Please note that JtR has supported \\xNN notation for many years. Eg. you can append a tab using $\\x09. I suggest implementing that (if anything) for compatibility.\nhttps://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/doc/RULES. I believe ce4858f7a broke this. These lines were removed:\ndiff\n-    // This line rejects unprintables. The rest of the function\n-    // reliably rejects invalid UTF-8 sequences.\n-    if (*buf < 0x20 || *buf == 0x7f) return false;. What does clinfo say? I'd guess the problem is the chroot and not anything missing in hashcat.. JtR can do that only because it's so slow/ineffective for this use case: It does all rules processing on CPU side and then has to transfer all resulting candidates, which is a bottleneck (for fast hashes like this).\nHashcat applies rules on GPU-side. This fact makes it more or less impossible to implement what you want. The upside is that it's WAY faster so the end result may still be a whole lot faster than JtR.. I can picture several use cases where this is definitely not wanted - we'll need an option to disable it!. He said it used to be the default, we're not suggesting it should be now.. @philsmd this gave me the idea you could possibly check entropy at loading stage, detecting this, right? At that time we're not even running hot code so it could be a really proper entropy test. Actually it should possibly be shared code because this could be used in other formats as well at loading (most any data blobs that ~are not compressed but~ should be encrypted and/or compressed) for ensuring input data quality.. https://github.com/hashcat/hashcat/pull/1719#issuecomment-430603088 \ud83d\ude09 . > only hex values, especially for ESSID\nAlso, IIRC when parsing the ESSID hex field we should store the length and never use strlen() on the resulting data. So an ESSID of 6d6167006e756d should have length set to 7.. > Hi magnum.\n\nAre you sure, we need an additional ESSID len field in the new hash line?\n\nNo, I meant when parsing that field we need to look at its length instead of doing a strlen on the result. So hashcat and JtR should have a len field in whatever struct is holding the data, but the input field doesn't need it.. This is more of an Android or ArchLinux issue that a hashcat one. It's better discussed on the hashcat forum but a good start would be to forget about hashcat for now and simply run clinfo. Once that works (or does it now?), you can return to hashcat.. The fact clinfo doesn't list your GPU at all shows that something is wrong with the OpenCL driver/runtime installation. There's no point in trying hashcat until this is resolved.. > hint: try to think about the amount of all atoms on the word\nOh, but there's only one Atom! \ud83d\ude04 . @jsteube this PR added support for gzip which is compression only. 7zip and zip are archive formats, and supporting them would likely open up a can of worms.. The warnings are benign, build works fine despite the warnings. I've been planning to fix them for quite some time but didn't get a round tuit[tm].. I can build just fine with Mojave/10.14.2. The only problem is a few benign warnings about LZMA-SDK enums.\nDid you install xcode and CLT?. Try this\n$ ls -l /usr/include/stdio.h\n-r--r--r--  1 root  wheel  16319 Jan 21  2018 /usr/include/stdio.h\nDo you have that file? If not, you probably need to (re-)install xtools and/or tweak some of its settings. You didn't answer my question though. Also, what's the output of which clang?\nAnyway this is not a hashcat issue at all.. The issue is on your end. I suggest you change your path to ensure /usr/bin/clang is used and not that foreign one.. This works fine, thanks!. > Thanks for info! CC @magnumripper\nThank you for the heads-up. passing it on (blindly) to @kholia : do we need to change something?. Perhaps you should also shorten it to OpenCL platform to use, in case multiple platforms are present\n. Sorry if I'm totally confused here, but is this really correct? I think it isn't.\nBefore this patch:\n- If a device with 1 ns resolution gave a time_end - time_start resulting in 8000, we know it took 8 microseconds +/- one nanosecond.\n- If a device with 80 ns resolution gave time_end - time_start resulting in 8000, we know it took 8 microseconds +/- 80 nanoseconds.\nBut after this patch, the latter will show up like... 8000*80 == 640000 meaning 640 microseconds? That's just not right.\n. Revisiting eg. https://www.khronos.org/registry/cl/sdk/1.0/docs/man/xhtml/clGetEventProfilingInfo.html I see it's a bit ambiguous but as far as I'm aware it's like I said above: The result is already nanoseconds and the resolution is only needed to know the accuracy.\nhttp://stackoverflow.com/questions/34276371/timer-resolution-in-opencl-profiling\n. @Fist0urs on what grounds do you deem it \"must be very rare\"? Are you checking as little as five bytes in some cases, or do I misread the code? If it's just five bytes, you will likely get a false positive even for just ?a?a?a?a?a?a?a and that is definitely not rare! That's why I asked you to add the extra check in JtR.\n. Are you sure about this?\n. Hence the need for the typecast you removed. I'm not saying you are wrong, I'm just asking if you actually understand what you are doing here.\n. Note that 0x7f is not printable!\n. ",
    "shellster": "While I'm all for OpenCL, there is potentially at least one reason not to.  I currently bought an NVIDIA Jetson TK1 with the hope of eventually getting oclHashCat running on it.  There is currently (and likely never will be) any OpenCL support.  We are stuck with CUDA.  There are other issues with running on this platform (ARM and no NVML support), but only OpenCL will add yet another hurdle.  This may or may not be enough of a reason to not go full OpenCL.  I predict that we will see more of this specialty boards in the near future, and they offer some really nice power to energy ratios for cracking.\n. @magnumripper That's a good question.  It's hard to know without being able to test it.  This guy is getting some pretty decent WPA cracking speeds with the board: https://devtalk.nvidia.com/default/topic/785084/jetson-for-pyrit-cpyrit-cuda-stats/\nThe killer feature is that the board only uses about 5W of power, so the potential power comes from clustering them.\n. @epixoip: I believe you are misreading the post.  The first benchmark at the top is after adjusting the clock speed: 6203.2 PMKs/s\nAlso, I don't really want to get too tied up about this particular board.  I'm just wondering if the trend of single purpose compute boards is likely to continue, and if that's enough of a reason to keep CUDA specific support around.  I wanted to bring it up if no one had considered it yet.\n. Well, I was asking about support of ARM platforms in general.  The Jetson TK1 is LE I believe (armv7l).\nIn the past (possible even present), ARM hasn't ever been powerful enough to really be worth the trouble, but that is likely on the cusp of changing.\n. ",
    "pjaaskel": "FYI, latest pocl versions support HSA, thus e.g. AMD Kaveri GPU and in the future hopefully more. Thus, not for commercial CPU-only devices anymore, but any HSA-supported devices should in principle work.\nWe'll try to take a look at   https://github.com/pocl/pocl/issues/290 as soon as possible. \n. ",
    "neheb": "mesa is still broken(clover).\n. point taken. just meant that not all platforms work.\n. I just compiled hashcat on android as well as an ARMv5 device. No real problems. Issue should be closed i think.\n. This is definitely an issue with the PKGFILE not with oclHashcat. FWIW, i can compile on arch just fine.\n. http://pastebin.com/M9F0MdZf\ncan't compile a kernel. no idea if it works otherwise.\n. error changed with the latest code a while back to\nERROR: clGetDeviceInfo() : -30 : CL_INVALID_VALUE\n. oh so CL_DEVICE_WAVEFRONT_WIDTH_AMD is unimplemented in Mesa? Hmm commenting that out and letting the build proceed results in a bunch of error: OpenCL does not support the 'static' storage class specifier\nAt least that's progress!\n. types_ocl.c needs \"#pragma OPENCL EXTENSION cl_clang_storage_class_specifiers : enable\" so that the kernels compile. Unfortunately, after that they all crash. Needs investigating.\n. alright, three issues left: \nCL_DEVICE_WAVEFRONT_WIDTH_AMD is not implemented and as such, some workaround is needed to get the device processor cores. \nsecond is that this needs to be tested. I believe Southern and Volcanic Island GPUs are supported. Evergreen and Northern islands are missing global atomics. Forget about earlier.\nThird issue is that oclHashcat complains that an unsupported version of Catalyst is used. The check should be used for less than HD7000 series I believe.\nAlso, assembly optimizations for amd_bit/bytealign and amd_bfe should be researched as those are unimplemented. I imagine it would be slow.\n. Oh my old issue that i completely forgot about. The problem is now that I've completely migrated to Linux and do not use Windows anywhere(good riddance). On the other hand since oclHashcat is now open source, this is probably not an issue any longer. If oclHashcat uses WIN32 to detect MinGW, then Cygwin(or maybe even MSYS2) should work fine since it does not define it. Well, I can't say I care really. Thinking of just closing this.\n. Oh this. Not exactly. When i originally posted it I used cygwin's sshd to ssh in to a windows computer and use screen to manage hashcat. I no longer do that but the issue where pressing keys does nothing remains. I have a feeling that it has to do with the way the windows shell interacts with hashcat vs. cygwin's bash.\n. works but pressing s does nothing. here's some pastebin to see the issue: http://pastebin.com/56KYZVRg\nnotice the row of s at the end. that was me pressing it.\nedit: i think the proper solution would be a native cygwin build. i feel that the issue is with the cygwin/win32 translation layer. a few things block that though:\nopencl libraries need to be loaded the windows way(ie not by using a linux style opencl icd loader).\nbuilding fails with shared.h i believe. there are a few functions that are not implemented.\n. The main issue probably arises from other tools that display AP MACs first and clients after. airodump-ng is the best example. This is just cosmetic though. Might as well just close it.\n. i mean just adding -fstack-protector-strong, -pie and other such stuff in the CFLAGS.\n. I don't really have an opinion on the matter. Just wondering what the consensus here is.\n. Some have a performance reduction. Some don't. I've tested with gcc and clang and it all seems to work. Not sure if it really matters since the OpenCL kernels(not impacted by the flags) are the ones doing the heavy lifting. I think i'll just close this. There's no point to this with a password cracker. Don't really want to lower performance in any way.\n. umm are you sure you need those CFLAGS? I can compile oclHashcat without them. I remember they used to be required but not anymore.\nedit: i just looked at the PKGBUILD. It makes assumptions that are not true anymore. amd-adl-sdk is not required anymore either.\n. the hashcat developers cross compile to windows from linux. hence the initial check.\npull requests always welcome.\n. the package from fedora's repo and my self compiled one from arch show the same problem. interestingly enough, the device name now shows \"pthread-\" + name of device. well w/e. this isn't really a priority.\n. It is not. Maybe a pocl bug instead.\nOn Fri, Apr 22, 2016, 00:17 Jens Steube notifications@github.com wrote:\n\nDo I need a special version to reproduce, because if I can not reproduce\nthis, I can not fix it. Since this is somehow related to CPU I think this\nis not related to the mesa thing discussed in the PR, right?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/300#issuecomment-213297701\n. looks like the problem is some incompatibility with clover...\n\nhttps://github.com/pocl/pocl/issues/217\n. closing since this is an upstream issue. just tried on an ubuntu install and it works fine.\n. ah that file looks to be a much better fit! I got a bit confused on where to place the statement. I believe LLVM's OpenCL support works on both AMD and Nvidia cards. I'm only testing AMD at the moment though. In any case the change has been force pushed.\n. yeah it's working. still doesn't compile right but that's a different issue.\n. Good point. I guess I was thinking of LLVM too much. I'll redo the commit when I get home.\nAs for LLVM, you mean to use it with hashcat? That requires ditching fglrx and installing mesa with its opencl package. Also commenting out the wavefront call since it will fail(unimplemented).\nOh also a 7000 or newer GPU is required. 6000 technically works but global atomics are not implemented.\n. Can't say since my card is a 6k series. The kernels compile now but they crash upon use of atomic_add or atomic_or.\n. Fixed up, Should be good now.\n. Another attempt. Not sure if the if statements are quite what you were looking for.\n. Oh I didn't test with the others. My bad!\n. You're using Mesa which doesn't support Northern Islands and below. A warning should be added and --force required. Actually, the second GPU should work. Try filtering it out with -d.\nGCN 1.0 support for AMDGPU is coming but it not there yet(HD 7000 series).\n. that error looks like it's for SHA3 not SHA512. SHA512 built successfully.\n. @jsteube maybe apply a blacklist based on the codename that appears(eg ARUBA).\n. Reports like these make me think Mesa should be blacklisted\n@jsteube ?. perfect\n. fixed by switching to the padoka PPA. seems the ubuntu packaged version is no good.\n. yeah. basically in cygwin you have \"gcc\" but you can also cross compile it with \"mingw64\". the difference is a cygwin build(does not currently work) uses cygwin.dll to emulate POSIX stuff while mingw does not.\n. yeah. i only did it like that since i have no idea how bash works. So can it be replaced with CYGWIN-NT-*?\n. i tested it, seems to work.\n. OpenCL is a requirement now.\n. hashcat does not use cuda\n. that's a linux binary AFAIK.\n. http://pastebin.com/UuuRicR1\n. almost ;). here's some weirdness: http://pastebin.com/TsQA0PFt\nbasically: original with pocl, beignet, and mesa works. remove pocl and it no longer works. another issue seems to be that the devices seem to show up multiple times. cosmetic issue i guess.\nat least it's the GPU that gets used.\n. fixed\n. 1: FWIW only notepad.exe has issues with missing CR = no newline. WordPad and Office do not have this issue. notepad.exe just like many other tools/components in Windows has code in it that has not been touched in at least a decade.\n2: The bug is in hashcat's single usage of the RegGetValue function which is supported starting XP 64-bit. The fix would be to use RegQueryValueEx but i'm not sure if anyone's interested in supporting XP.\n. both commands return /usr/lib on fedora 24. not sure on cygwin. replacing the grep | sed commands with the last one results in:\n=/usr/i686-w64-mingw32/lib\n=/usr/local/lib\n=/lib\n=/usr/lib\nand\n=/usr/x86_64-w64-mingw32/lib\n=/usr/local/lib\n=/lib\n=/usr/lib\nrespectively.\n. i am\n. /usr/x86_64-w64-mingw32/lib\n. same result with cygwin. path and behavior is the same as fedora 24.\n. it does not, no.\n. worked.\n. that bug should be fixed in the latest beta: https://hashcat.net/beta/\n. sounds like you need an opencl runtime then. supported ones by hashcat are:\nIf nvidia, the drivers should include it.\nif intel, beignet is probably your best bet.\n. You can try installing the Intel OpenCL runtime but that's a mess to do on Linux. Another alternative is pocl.\n. Bashrc is an option as well\n. Just tested on Windows. Loading the library fails.\n. Issue is that you need an OpenCL runtime.\n. My answer was accurate and concise. A simple Google search should suffice.\n. I remember a similar issue involving spaces in paths.\n. I just realized. You posted on GitHub but made no indication that you were using the beta. Try https://hashcat.net/beta\n. Recompile with DEBUG=1 and try again. Symbols are missing.\n. That sounds like a matter of opinion. Let me rephrase Jens' question.\nWhat problem exists with hashcat that C++ solves?. i cannot reproduce.  what windows version is this? DEP is set to always on on my machine.. Yes\nOn Sat, Nov 26, 2016, 02:11 KOLANICH notifications@github.com wrote:\n\nIs it forced? Do you he EMET?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/530#issuecomment-263055274,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACyJ2aFwVXv4mxpoCfGRk6nxbIgnGX_5ks5rCAXMgaJpZM4KQjNY\n.\n. I remember GCC warning me about another function that needs the printf but the call was to vsnprintf so I was unsure how to apply it.\n. Will do so when I get home. I think I'll run 3.9 just in case.\n\nAlso on this note, Coverity should be considered. Free for open source projects: https://scan.coverity.com\n. no bugs with 3.9. closing.\n. Man page says: \n4.3BSD, POSIX.1-2001. POSIX.1-2001 declares this function obsolete; use nanosleep(2) instead. POSIX.1-2008 removes the specification of usleep().\nBut yes I agree. It's not much of an issue. It's the std=POSIX parameter that checks that.\n. Closing when I get home.\n. Looks good\n. My full command line is,\nscan-build -enable-checker alpha.core.BoolAssignment -enable-checker alpha.core.CallAndMessageUnInitRefArg -enable-checker alpha.core.CastSize -enable-checker alpha.core.CastToStruct -enable-checker alpha.core.DynamicTypeChecker -enable-checker alpha.core.FixedAddr -enable-checker alpha.core.IdenticalExpr -enable-checker alpha.core.PointerArithm -enable-checker alpha.core.SizeofPtr -enable-checker alpha.core.TestAfterDivZero -enable-checker alpha.core.TestAfterDivZero -enable-checker alpha.deadcode.UnreachableCode -enable-checker alpha.security.ArrayBound -enable-checker alpha.security.ArrayBoundV2 -enable-checker alpha.security.MallocOverflow -enable-checker alpha.security.ReturnPtrRange -enable-checker alpha.security.taint.TaintPropagation -enable-checker alpha.unix.cstring.BufferOverlap -enable-checker alpha.unix.cstring.NotNullTerminated -enable-checker alpha.unix.cstring.OutOfBounds -enable-checker alpha.unix.Stream -enable-checker alpha.unix.SimpleStream make\nAs of now, 55 warnings show up. The last two checkers are responsible for the VERIFY_PTR issue. Interestingly enough, if those get disabled, other warnings such as unreachable code ones also disappear.\n. I actually left out a checker in that command line: alpha.core.PointerSub\nThe reason was that it complains on strtok_r. Given that nothing can really be done about it, there's no point in trying to \"fix\" it. However that checker also complains about 3 usages of strcmp. My fix was to switch to strncmp for those.\nOther than that, looks good. cppcheck complains less now as well.\n. solution is to enable CoolBits in xorg.conf. Is there an issue with using MinGW's ANSI stdio feature? It removes the PRI formats but adds \u2105z. So the issue is that the find command fails to find the 32-bit include directory and thus disables the glob object. Probably just an issue where the Makefile can't handle the error. Right. But the error shows on \"make win64\".. Oh I haven't tested. Will do so when I return home.\nOn Mon, Nov 28, 2016, 11:10 Jens Steube notifications@github.com wrote:\nAlso with the latest commit I've pushed?\nOn 28.11.2016 20:09, neheb wrote:\n\nRight. But the error shows on \"make win64\".\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263363794,\nor mute the thread\n<\nhttps://github.com/notifications/unsubscribe-auth/AJ83OVO4XMyNHsxFv6vr2iCiTKF-RsbMks5rCyb4gaJpZM4K9Tc4\n.\n\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/737#issuecomment-263364060, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACyJ2fqU6zLHqqUyhaEs_3u2TOTUw-Qxks5rCyc0gaJpZM4K9Tc4\n.\n. The \"fix\" does nothing but break cygwin building when it works just fine. Here's the beginning from my Fedora build.\nhttps://gist.github.com/neheb/11a5d8afd1ed7fd04892b0e306f73451\nstrictly speaking installing mingw32 fixes the issue but it should not fail like this. File globbing for 64-bit exists.. The whole point of cygwin is to easily cross compile using MinGW. It just errors that cross compiling is not supported. The commit should be reverted.\nAs for the latest one, I will test when I get home.. ...no cygwin is a Linux environment for Windows with a reimplemented POSIX. It's not the same as MSYS2 which is just a front-end for MinGW.\nMeaning running make with cygwin fails for reasons unrelated to this issue.\nIn any case, the 32-bit glob error is now gone. Closing.. It's the same thing as libOpenCL.so, just the cygwin flavor. pocl is the only supported runtime.\nedit: more directly,\n1: all of the other dlopen calls fail. Only this succeeds.\n2: I assume pocl is. yes.\n3: pocl.. Rebasing. Never mind. I really need to stop this.... Yeah I looked through the defines for 32 and 64 compilers and found they both share this one.. Is this on OS X?. agh this also seems to be a problem in 14.04. And only in Ubuntu.\nSo far I have been unable to reproduce in Fedora, MinGW, or Cygwin. This sounds like Ubuntu's version of glibc has a very specific patch to add warn_unused_result to asprintf. Hillarious since neither malloc nor snprintf do.\nI'd suggest adding -Wno-unused-result in the Makefile to silence the warning. . Nvidia GPUs under Mesa are not supported and probably never will be. Install the proprietary drivers.. Actually the first error might not be fixed if this is Ubuntu 14.04. I have a pull request waiting: https://github.com/KhronosGroup/OpenCL-Headers/pull/14/commits/d3efacb69d64c086d1a0508fa4656700e6bd4187. It compiles fine. Not sure if you want any runtime validation(pthreads is broken for some reason).. No. I'll try working on it later today.. My pthreads comment applies to SRC/affinity. Currently, I have it #if'd out to return 0. Cygwin doesn't provide any of the CPU_ functions, cpu_set_t or the pthreads function in that file.\nOriginally, I thought cyOpenCl failed to work properly because of that. But on closer inspection that code shouldn't have anything to do with it.\nWhen I get home, I will do some further testing. That's really interesting that you got the regular Windows runtime to work under cygwin though. My thinking was that you couldn't mix regular win32 DLLs and cygwin(POSIX).. Update: alright this actually works great now. I ran cygwin through ssh (ssh 127.0.0.1) and was able to use the s key to pull up the status. No winpty needed.. For some reason it doesn't actually work with cygOpenCL. Hashcat launches and exits shortly after. I was never able to find the cause.. Although, the : m error is a problem with hashcat since strerror is not used.. It's a clang issue. Try applying this patch: \n`diff --git a/OpenCL/inc_vendor.cl b/OpenCL/inc_vendor.cl\nindex dd11d8f..ff6356f 100644\n--- a/OpenCL/inc_vendor.cl\n+++ b/OpenCL/inc_vendor.cl\n@@ -63,6 +63,10 @@\n #pragma OPENCL EXTENSION cl_amd_media_ops2 : enable\n #endif\n+#ifdef cl_clang_storage_class_specifiers\n+#pragma OPENCL EXTENSION cl_clang_storage_class_specifiers : enable\n+#endif\n+\n /**\n  * Unrolling is generally enabled, for all device types and hash modes\n  * There's a few exception when it's better not to unroll\n`\nedit: unfortunately I can't test this but it should work. Expect slow speeds.\nedit2: actually this will not work either. Northern Islands and below are not supported.. make win32 or win64 makes use of it.. Not related to #1024 .\nThe real issue is that the CRT glob is being used for a non-windows platform (that includes Cygwin) even though it is a MinGW specific thing. Cygwin and MSYS2 (by default) do not generate windows binaries that are usable without Cygwin.dll.\nThe main use case of compiling hashcat with Cygwin is to get proper SSH support (MinGW binaries don't work correctly with Cygwin's sshd due to a difference in input handling).\nOh I also just remembered. I made this after I noticed 100% CPU usage in Cygwin's find command after running make. Although FWIW I've been commenting it out for a while.. Last I remember, MSYS2 creates several shortcuts. The regular MSYS2 is basically equivalent to Cygwin. The MinGW ones compile with MinGW and also change the uname.\nFile globbing only works with MinGW targets. Will do some testing on Windows and update the PR.\nedit: at least MSYS2 fails properly: \nfind: failed to read file names from file system at or below \u2018/\u2019: No such file or directory\nsrc//win_file_globbing.mk:117:\n! The MinGW CRT GLOB library was not found on your system. Please make sure that CRT_glob.o exists\n! ATTENTION: File globbing will be disabled\nActually this makes sense. /cygdrive is where regular drives get mounted. Must be trying to read the whole file system.. Going to resend. Something got messed up.. I'll need to test this again but I believe the MinGW shortcuts provided by MSYS2 change environment variables to help out configure scripts find the right binaries.\nNow, that's important to mention since the hashcat makefile just selects standard GCC under the MinGW environment and compiles a standard POSIX binary.\nI can't say I want to work on this since I'm not an MSYS2 user. They both have different use cases.. @philsmd Cygwin binaries are not meant to be ran from the windows command line. That's what MinGW is for. Pretty sure the tests pass under mintty (or w/e the default shell is called).. FWIW atom tested Mesa before. It's really slow. Plus to get better performance, assembly has to be written (no idea if even possible) since several AMD specific functions are missing in Clover (cl_amd_media_ops and 2).. Log in to https://scan.coverity.com , log in with GitHub account, add project.  Last I remember it took 2 days for them to accept it. After that  hashcat needs to be built and sent to them for analysis.. Ah yes. I remember that from long ago. Need to find out how to delete a\nproject...\nOn Tue, Feb 14, 2017, 06:42 Royce Williams notifications@github.com wrote:\n\nI found @neheb https://github.com/neheb's hashcat-utils integration\nalso:\nhttps://scan.coverity.com/projects/hashcat-utils\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1045#issuecomment-279725242,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ACyJ2VyIE_EoL9b8N0wMpOFGQ_eIhwSNks5rcb05gaJpZM4L-AaZ\n.\n. Since coverity support was added, closing.. info is here: https://scan.coverity.com/travis_ci. Aaaaaannnd the BSDs are where this fails. Closing for now.. You can't. I also have a card that errors on Nvapi. The issue is that your card is not a reference design. Using WIN32 was done for consistency purposes. The other relevant ones also have two __ on both sides. Anyway, I'll resend the ADL stuff.. fixed.. sounds like a windows issue. exfat as opposed to fat32 might help.\n\nCould also try using cygwin to change the permissions. or linux. . Why. You could work around that issue by using a pipe. eg.\ncombinator wordlist.dict 4digits.dict | hashcat -a 0 .... fopen fails since the path is UTF-16. Needs to be rewritten to use Windows APIs. I'm gonna close this just because I don't use unicode filenames. The original error is fixed.\nHaving said that, hashcat still cannot handle Unicode files under windows. Let's say you have a file with a unicode name. Hashcat will fail to open that with ??????.txt: No such file or directory. Might want to compile with -Og next time :). Adding attribute((fallthrough)) seems to be the recommended way to silence the warning.. honestly since you're the only one seeing this issue, I recommend bisecting.. Instead of randomly running tests, can you bisect the issue?. driver bug. closing.. cap file is here: https://mega.nz/#!mExTULzA!LD4wYQh8aMoHrWrISh-n3wUnYGdzQq_nA8IVKcRZypQ\npassword: bo$$password. Where is Sha 384 used? I only see it used for FILS which is implemented pretty much nowhere.. Fixed MinGW compile. Had no good solution to it since I would have had to modify lzma_sdk/Alloc.c. I tested the compile on Fedora 26. MinGW that is. It works fine(except for the iconv stuff). So it does work.\nI think I'll just revert to rand(). rand_s is nice since it returns an unsigned 32 bit integer but it looks like it's too much trouble.. Forget it then. done\nedit: One concern I have is that hcmalloc = malloc + memset. The memset zeroes the memory allocated, but I'm sure there's code that does not need this.\nWhich begs the question, is this patch correct or should the memset be removed? I don't think integer overflow is an issue unless we're talking about 32-bit systems. There's also existing code of the form \"void *p = hccalloc(foo, 1).. Add -D 1,2 to command line. Usually not a good idea. Nvidia has a runtime bug that causes 100% CPU usage. Additionally, overall speeds probably won't increase. I think the CPU slows the GPU down. You'll have to test.. Ah bummer. Currently it looks quite clean. It takes up the entire space on my monitor.\nOn Mon, Nov 13, 2017, 00:11 Jens Steube notifications@github.com wrote:\n\nWhat's the reason for not changing atoi() in usage.c ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1439#issuecomment-343842846, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/ACyJ2YRHoucDF7X4IUcVtIQwVDTZoGWSks5s1_mfgaJpZM4QaXIX\n.\n. There's a pull request already. The variables are in header files like opencl.h. Once converted they become unused variables since they are not used within the header file.\n\nThat coverity warning sounds bogus. Most if not all uses of the strings expect a char pointer. Currently those variables rely on array decay, which is an implicit(and unnecessary) conversion.\nQuick hashcat -b shows no problems, speed or otherwise.\nI also have another patch that fixes a bunch of cast-qual warnings, some a result of this patch.. Lol. @jsteube yes. So given that Apple doesn't seem to provide updates to old macOS versions, could justify doing the same here?. AFAIK, those errors come with GPUs where the EC manages the fan, not the GPU itself.\nSo yeah, no problem there.. Will be fixed soon. Consider upgrading OS X to 10.12 or newer.. Because Apple's drivers suck. Simple as that.. Let's see. You could virtualize the GPU. Maybe?\nssh into a system which is properly set up (Windows or Linux). \nI woudln't hold my breath for Apple to make proper drivers. One research area would be to see if Apple's OpenCL runtime allows inline assembly so that some of the more advanced features of Vega can be used. Don't hold your breath though.. I will kindly invite you to fuck off.. Don\u2019t use hashcat on a laptop.\nThat\u2019s a common error for laptops that says hashcat cannot control the fans.. Briefly looking at it, both variables seem to be uints.\n. Not really. I added a printf to see if anything changed after I removed the cast. Numbers were still the same.\nThe only issue I can potentially see is that dividing could cause a remainder to get thrown away. num_elements seems to end up being a multiple of 8 though.\n. ",
    "roycewilliams": "What is the potential performance improvement -- for single hashes, and for multiple hashes?\n. Maybe they have access to a large number of them?\n. Note apparent bug in QNX's implementation of SHA-512.\nhttp://www.openwall.com/lists/john-users/2015/12/31/1\n. Hey, fantastic !. Somewhat related to #1580. The rules syntax today assume that replacement rules are only one byte for their arguments (so0, etc.). Ideally, a rule syntax that allows delimiting of the two arguments (like /o/0, /oo/00, etc.) would be very valuable for use with multibyte rules and with hex rules. Otherwise, it is difficult to tell when one string argument ends and the next one begins.. https://github.com/hashcat/hashcat/commit/71a8459d851d246945343ea59effa1d46b965bf8\n. Thanks for the opportunity to weigh in. This may seem like a bit of trouble -- but once the effort is invested, it will benefit many future developers, testers, troubleshooters and researchers forever. :)\nI hadn't thought about the \"compile from uncommitted changes and publish that\" corner case -- good point.\nI agree that compile time alone is useful if commit hash is unavailable or there are uncommitted changes.  But the real value is in being able to compare apples to apples over time for a variety of code states -- and commit hash is almost always the best approximation of that.  IMO, it should be used if it's available. And even when there are betas compiled just for testing, knowing what commit they are derived from is useful.\nSo I'd like to propose always including the commit hash, and if there are uncommitted changes, appending a clean datestamp (and I see that COMPTIME is now based on date +%s, so that's perfect).  \nSo if it's possible (and I don't know if it is), maybe something like (pseudocode):\nVERSION_STAMP := $(shell git rev-parse HEAD | cut -b1-7)\nif (there_are_uncommitted_changes), then\n    VERSION_STAMP := $(VERSION_STAMP)_$(COMPTIME);\nThis would cover the somewhat rare test-compile case cleanly, and still enable future researchers and testers to compare known outputs. And at a glance, everyone can tell if it was based on a specific commit or a local compile (and if a local compile, the commit it was based on).\nThe Makefile would have to know to skip this step if git is not available, of course.  And I've never scripted a check for uncommitted changes, but this looks like a reasonable shell-based approach:\nhttp://stackoverflow.com/questions/3878624/how-do-i-programmatically-determine-if-there-are-uncommited-changes\nEDIT: changed separator to underscore, fixed some formatting.\n. Once this functionality is available, it would also be awesome if betas pushed to /beta/ had the version stamp appended to the base of the filename, as in:\noclHashcat-2.10b61-cd430d5.7z\nor \noclHashcat-2.10b61-cd430d5_1453306037.7z\nThis way, potential testers can tell at a glance if the code was at a point where testing is relevant for them, and exactly which changes are in play (to the extent feasible).\nRoyce\n. +1. Covers all of the bases reasonably, I think.\n. Awesome!  OK, here's my elevator pitch:\nPosted information about hashing speeds matter - for dev, for troubleshooting, for shopping for GPUs, for academic research, etc.  Now that hashcat is open source and people can be running arbitrary versions, knowing what version was used to create a given piece of output is important. The best way to ensure that all current (and future) uses of output -- most especially, benchmarks and cracking runs -- can be closely tied to what algorithms/code was in use is to include the commit information.\nIf leaving it out of --help is better, I've got no problem with that at all.  But I believe strongly that there is significant value in including it in the startup (so that it shows up in benchmarks and cracking runs).  Knowing which code they came from matters more than it used to.\n. Yes - done.\n. This is usually video driver-related.  Please see our FAQ for more information on how to return your video drivers to a known good state. The FAQ refers to AMD only in spots, but it applies to NVIDIA as well.\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#what_does_the_clgetplatformids_-1001_error_mean\n. https://www.google.com/search?q=bitcoin2john.py. Try deleting the ./kernels directory and ~/.nv/.  I had this symptom until I did so.\n. Great!  If you could close this ticket as resolved, that will make housekeeping easier.\n. It's a compromise. Same reasoning that I used when I requested the commit hash in the verbose version output -- historical comparison value. A set of stats, even automated stats, is much more useful when you have the context. If people are working with automated stats over time, they will need to know how they were generated. Better IMO to have that as part of the new automated file \"format\", and pay the simple price of cutting away the header (which is very easy, because it's prepended with the comment character).\n. It's the same reason why the performance comparison Google Docs spreadsheet lists which hashcat versions are being compared. I would even suggest expanding the automated format to include the device type as well as the device ID (which could be stripped if not needed) but that's probably too ambitious. :)\n. Please carefully read the link that @jsteube provided.  Depending on the type of hash, dictionary attacks will always be slower than bruteforce on GPU because dictionary attacks cannot take advantage of the parallel nature of the GPU. You can apply rules to your dictionary to achieve higher speeds, but if you are just looking to run through some dictionaries without applying rules, the speeds you are reporting are normal.\n. To reduce the complexity caused by positional parameters, could there be specific flags for dictionary files (--dict) and masks (--mask)? They could be specified more than once (just like -r for rules). Would that help?\nFor backwards compatibility, the default behavior today could be preserved, with the new flags just  disambiguating if needed.\n. Culturally, I suspect that it's left up to user to determine when to feed the entire backlog of discovered plains into an attack. \nThat being said, some kind of \"pre-loopback\" option might be convenient, IMO.\n. This is not as far-fetched as it might appear. https://sites.google.com/site/itstheshappening/\n. 1. I think that most users would expect pausing to trump (take priority over) the timer. That's what I would expect, anyway. :)\n. Per @FiloSottile and @kholia, this is the same hash. https://twitter.com/FiloSottile/status/771004722010554369\n. Same issue as  two months ago. See https://github.com/hashcat/hashcat/issues/436 .\n. Hmm - to clarify, as part of this feature, it sounds like you'd want hashcat to:\n1. Only attempt to crack one of the duplicates, ignoring the others but accumulating a count of them in some way (otherwise, there would be a massive waste of RAM and processing power), and ...\n2. After a hash is cracked, write all duplicate plains to the potfile, so that statistics could be derived directly from the potfile?\nI think this is probably not what @jsteube et al will want to do. Removing duplicates keeps the code simple, keeps GPU RAM usage low, etc.\nAlso, it is trivial to script taking an original hash frequency count and a potfile and generate the statistics. I don't know of a published script, though - it would be nice to have a reference implementation. \nWhat are you currently doing to get the statistics that you need?\n. I see the appeal. If hashcat optionally accumulated the duplicate count on intake, the duplicate count could be part of an output format, such as:\n16 | duplicatecount:hash[:salt]:plain:hex_plain\n@jsteube, would accumulating that duplicate count slow hash loading/dedupe much?\n. There isn't enough GPU memory to hold your attack. hashcat cannot handle this scenario - only you can (either by getting a card with more memory, getting more cards ... or as you said, by dividing up the job). \nUnless I'm misunderstanding your question. :) How could hashcat better handle this?\n. It's not a dumb suggestion at all -- but it is probably outside the hashcat project's current scope. If it's something that can easily be scripted externally, @atom is usually less inclined to take it on as an internal feature. But you're not crazy. :)\n. I think it's sometimes hash-dependent, but should always be pretty close to that ratio. Starting with that ratio, and then doing a bisect (binary walk) should narrow it down pretty quickly.\n. For future searchers, note that I did a survey of real-world memory allocation across multiple platforms.\nhttps://gist.github.com/roycewilliams/5ac28350023613c614034c7fb6ba715d\nSummary of findings:\n\nAt this writing, NVIDIA never exceeds 25%\nAMD, Intel, and pocl sometimes exceed 25%\npocl sometimes makes 100% available (or claims to in hashcat output, anyway)\n\nAnd if I learn any useful technical information, I'll post it to this NVIDIA forums thread:\nhttps://devtalk.nvidia.com/default/topic/992502/cuda-programming-and-performance/why-is-cl_device_max_mem_alloc_size-never-larger-than-25-of-cl_device_global_mem_size-only-on-nvidia-/\n. That is correct. Support for all platforms and devices has been centralized around OpenCL.\n. Can reproduce. Not sure how to produce useful debugging. Here's a try:\nbash-3.2# dtruss -f ./hashcat -b 2>&1 | tee macos.out\n[...]\nbash-3.2# cat macos.out\ndtrace: system integrity protection is on, some features will not be available\n    PID/THRD  SYSCALL(args)          = return\nhashcat (v3.10-541-g1c055a6) starting in benchmark mode...\n(null): No such file or directory\ndtrace: error on enabled probe ID 2149 (ID 454: syscall::pread:return): invalid kernel access in action #13 at DIF offset 44\ndtrace: error on enabled probe ID 2149 (ID 454: syscall::pread:return): invalid kernel access in action #13 at DIF offset 44\ndtrace: error on enabled probe ID 2158 (ID 552: syscall::sysctl:return): invalid kernel access in action #11 at DIF offset 40\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\ndtrace: error on enabled probe ID 2133 (ID 942: syscall::write_nocancel:return): invalid kernel access in action #13 at DIF offset 92\n 1724/0x2ce7:  thread_selfid(0x0, 0x0, 0x0)      = 11495 0\n 1724/0x2ce7:  open(\".\\0\", 0x0, 0x1)         = 3 0\n 1724/0x2ce7:  fstat64(0x3, 0x7FFF5981D810, 0x1)         = 0 0\n 1724/0x2ce7:  fcntl(0x3, 0x32, 0x7FFF5981DAB0)      = 0 0\n 1724/0x2ce7:  close(0x3)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/local/src/hashcat\\0\", 0x7FFF5981D780, 0x7FFF5981DAB0)        = 0 0\n 1724/0x2ce7:  issetugid(0x7FFF5981DAB0, 0x7FFF5981D780, 0x7FFF5981DAB0)         = 0 0\n 1724/0x2ce7:  csops(0x0, 0x0, 0x7FFF5981DAB0)       = 0 0\n 1724/0x2ce7:  shared_region_check_np(0x7FFF5981B0E8, 0x0, 0x7FFF5981DAB0)       = 0 0\n 1724/0x2ce7:  getpid(0x7FFF5981B0E8, 0x0, 0x7FFF5981DAB0)       = 1724 0\n 1724/0x2ce7:  proc_info(0x2, 0x6BC, 0x8)        = 1272 0\n 1724/0x2ce7:  stat64(\"/usr/lib/dtrace/libdtrace_dyld.dylib\\0\", 0x7FFF5981CF78, 0x8)         = 0 0\n 1724/0x2ce7:  open(\"/usr/lib/dtrace/libdtrace_dyld.dylib\\0\", 0x0, 0x0)      = 3 0\n 1724/0x2ce7:  fcntl(0x3, 0x61, 0x7FFF59814758)      = 0 0\n 1724/0x2ce7:  mmap(0x0, 0x620, 0x5, 0x1, 0x3, 0x7000)       = 0x1064D0000 0\n 1724/0x2ce7:  munmap(0x1064D0000, 0x620)        = 0 0\n 1724/0x2ce7:  mmap(0x1064D0000, 0x2000, 0x5, 0x12, 0x3, 0x7000)         = 0x1064D0000 0\n 1724/0x2ce7:  mmap(0x1064D2000, 0x1000, 0x3, 0x12, 0x3, 0x9000)         = 0x1064D2000 0\n 1724/0x2ce7:  mmap(0x1064D3000, 0x2E20, 0x1, 0x12, 0x3, 0xA000)         = 0x1064D3000 0\n 1724/0x2ce7:  close(0x3)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/dtrace/libdtrace_dyld.dylib\\0\", 0x7FFF5981D4D8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/libSystem.B.dylib\\0\", 0x7FFF5981CDA8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libcache.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libcommonCrypto.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libcompiler_rt.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libcopyfile.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libcorecrypto.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libdispatch.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libdyld.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libkeymgr.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/liblaunch.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libmacho.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libquarantine.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libremovefile.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_asl.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_blocks.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_c.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_configuration.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_coreservices.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_coretls.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_dnssd.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_info.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_kernel.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_m.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_malloc.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_network.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_networkextension.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_notify.dylib\\0\", 0x7FFF5981C9B8, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_platform.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_pthread.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_sandbox.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_secinit.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_symptoms.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libsystem_trace.dylib\\0\", 0x7FFF5981C9B8, 0x1)        = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libunwind.dylib\\0\", 0x7FFF5981C9B8, 0x1)      = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/system/libxpc.dylib\\0\", 0x7FFF5981C9B8, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/libobjc.A.dylib\\0\", 0x7FFF5981BC78, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/libauto.dylib\\0\", 0x7FFF5981BB58, 0x1)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/libc++abi.dylib\\0\", 0x7FFF5981BB58, 0x1)         = 0 0\n 1724/0x2ce7:  stat64(\"/usr/lib/libc++.1.dylib\\0\", 0x7FFF5981BB58, 0x1)      = 0 0\n 1724/0x2ce7:  open(\"/dev/dtracehelper\\0\", 0x2, 0x7FFF5981D980)      = 3 0\n 1724/0x2ce7:  ioctl(0x3, 0x80086804, 0x7FFF5981D908)        = 0 0\n 1724/0x2ce7:  close(0x3)        = 0 0\n 1724/0x2ce7:  thread_selfid(0x3, 0x80086804, 0x7FFF5981D908)        = 11495 0\n 1724/0x2ce7:  bsdthread_register(0x7FFFBCD7E224, 0x7FFFBCD7E214, 0x2000)        = 1073741919 0\n 1724/0x2ce7:  ulock_wake(0x1, 0x7FFF5981D02C, 0x0)      = -1 Err#2\n 1724/0x2ce7:  issetugid(0x1, 0x7FFF5981D02C, 0x0)       = 0 0\n 1724/0x2ce7:  mprotect(0x1064D8000, 0x88, 0x1)      = 0 0\n 1724/0x2ce7:  mprotect(0x1064DA000, 0x1000, 0x0)        = 0 0\n 1724/0x2ce7:  mprotect(0x1064F0000, 0x1000, 0x0)        = 0 0\n 1724/0x2ce7:  mprotect(0x1064F1000, 0x1000, 0x0)        = 0 0\n 1724/0x2ce7:  mprotect(0x106507000, 0x1000, 0x0)        = 0 0\n 1724/0x2ce7:  mprotect(0x106508000, 0x1000, 0x1)        = 0 0\n 1724/0x2ce7:  mprotect(0x1064D8000, 0x88, 0x3)      = 0 0\n 1724/0x2ce7:  mprotect(0x1064D8000, 0x88, 0x1)      = 0 0\n 1724/0x2ce7:  getpid(0x1064D8000, 0x88, 0x1)        = 1724 0\n 1724/0x2ce7:  stat64(\"/AppleInternal/XBS/.isChrooted\\0\", 0x7FFF5981CEE8, 0x1)       = -1 Err#2\n 1724/0x2ce7:  stat64(\"/AppleInternal\\0\", 0x7FFF5981CF80, 0x1)       = -1 Err#2\n 1724/0x2ce7:  csops(0x6BC, 0x7, 0x7FFF5981CA10)         = -1 Err#22\n 1724/0x2ce7:  csops(0x6BC, 0x7, 0x7FFF5981C2F0)         = -1 Err#22\n 1724/0x2ce7:  getrlimit(0x1008, 0x7FFF5981E428, 0x7FFF5981C2F0)         = 0 0\n 1724/0x2ce7:  fstat64(0x1, 0x7FFF5981E448, 0x7FFF5981C2F0)      = 0 0\n 1724/0x2ce7:  open_nocancel(\".\\0\", 0x0, 0x1)        = 3 0\n 1724/0x2ce7:  fstat64(0x3, 0x7FFF5981E3A0, 0x1)         = 0 0\n 1724/0x2ce7:  fcntl_nocancel(0x3, 0x32, 0x7FFF5981DF10)         = 0 0\n 1724/0x2ce7:  close_nocancel(0x3)       = 0 0\n 1724/0x2ce7:  stat64(\"/usr/local/src/hashcat\\0\", 0x7FFF5981E310, 0x7FFF5981DF10)        = 0 0\n 1724/0x2ce7:  stat64(\"/\\0\", 0x7FFF5981C830, 0x7FFF5981DF10)         = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)         = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local/bin\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = -1 Err#2\n 1724/0x2ce7:  getattrlist(\"/usr\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)         = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local/src\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local/src/hashcat\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = 0 0\n 1724/0x2ce7:  getattrlist(\"/usr/local/src/hashcat/hashcat\\0\", 0x7FFFBCC25B24, 0x7FFF5981E140)       = 0 0\n. Working great now - thanks!\n. Huh. I had no idea that only GNU getopts let you do this, and that \"optional options\" is not POSIX.\nhttp://stackoverflow.com/a/19604773/263879. Can replicate using v3.20-28-gec561027.\n$ cat example0.hash\n919509ee78ca3da484bd24e5d76def50\n$ cat dicts1\nWelCome\n$ ./hashcat -m 0 --loopback -a 0 example0.hash ./dicts* -r /var/local/rules/best64.rule --potfile-disable\nhashcat (v3.20-28-gec561027) starting...\nXOpenDisplay() failed\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #2: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #3: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #4: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #5: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #6: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #7: AMD FX(tm)-8350 Eight-Core Processor, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 77\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Raw-Hash\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nGenerated dictionary stats for ./dicts1: 8 bytes, 1 words, 77 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\n919509ee78ca3da484bd24e5d76def50:WelCome\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: MD5\nHash.Target......: 919509ee78ca3da484bd24e5d76def50\nTime.Started.....: Fri Dec  9 20:59:32 2016 (0 secs)\nTime.Estimated...: Fri Dec  9 20:59:32 2016 (0 secs)\nInput.Base.......: File (./dicts1)\nInput.Mod........: Rules (/var/local/rules/best64.rule)\nSpeed.Dev.#1.....:        0 H/s (0.00ms)\nSpeed.Dev.#2.....:        0 H/s (0.00ms)\nSpeed.Dev.#3.....:        0 H/s (0.00ms)\nSpeed.Dev.#4.....:        0 H/s (0.04ms)\nSpeed.Dev.#5.....:        0 H/s (0.00ms)\nSpeed.Dev.#6.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 9/77 (11.69%)\nRejected.........: 0/9 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nCandidates.#1....: [Copying]\nCandidates.#2....: [Copying]\nCandidates.#3....: [Copying]\nCandidates.#4....: WelCome -> WelCome4\nCandidates.#5....: [Copying]\nCandidates.#6....: [Copying]\nHWMon.Dev.#1.....: Temp: 62c Fan:  2% Util:  0% Core:1290Mhz Mem:3004Mhz Lanes:8\nHWMon.Dev.#2.....: Temp: 60c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#3.....: Temp: 54c Fan:  0% Util:  0% Core:1290Mhz Mem:3004Mhz Lanes:16\nHWMon.Dev.#4.....: Temp: 51c Fan:  0% Util:  0% Core:1366Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#5.....: Temp: 62c Fan:  0% Util: 77% Core:1379Mhz Mem:3004Mhz Lanes:1\nHWMon.Dev.#6.....: Temp: 61c Fan:  0% Util: 99% Core:1366Mhz Mem:3004Mhz Lanes:1\nGenerated dictionary stats for /usr/local/src/sec/crack/hashcat/github/hashcat/hashcat.induct/hashcat.loopback.1481349572_936: 8 bytes, 1 words, 77 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: MD5\nHash.Target......: 919509ee78ca3da484bd24e5d76def50\nTime.Started.....: Fri Dec  9 20:59:33 2016 (0 secs)\nTime.Estimated...: Fri Dec  9 20:59:33 2016 (0 secs)\nInput.Base.......: File (/usr/local/src/sec/crack/hashcat/github/hashcat/hashcat.induct/hashcat.loopback.1481349572_936)\nInput.Mod........: Rules (/var/local/rules/best64.rule)\nSpeed.Dev.#1.....:        0 H/s (0.00ms)\nSpeed.Dev.#2.....:        0 H/s (0.00ms)\nSpeed.Dev.#3.....:        0 H/s (0.00ms)\nSpeed.Dev.#4.....:        0 H/s (0.00ms)\nSpeed.Dev.#5.....:        0 H/s (0.00ms)\nSpeed.Dev.#6.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 77/77 (100.00%)\nRejected.........: 0/77 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nCandidates.#1....: [Copying]\nCandidates.#2....: el -> elCoel\nCandidates.#3....: [Copying]\nCandidates.#4....: [Copying]\nCandidates.#5....: [Copying]\nCandidates.#6....: [Copying]\nHWMon.Dev.#1.....: Temp: 63c Fan:  3% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:8\nHWMon.Dev.#2.....: Temp: 61c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#3.....: Temp: 55c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:16\nHWMon.Dev.#4.....: Temp: 51c Fan:  0% Util:  0% Core:1366Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#5.....: Temp: 62c Fan:  0% Util:100% Core:1379Mhz Mem:3004Mhz Lanes:1\nHWMon.Dev.#6.....: Temp: 61c Fan:  0% Util: 63% Core:1366Mhz Mem:3004Mhz Lanes:1\nCache-hit dictionary stats /usr/local/src/sec/crack/hashcat/github/hashcat/hashcat.induct/hashcat.loopback.1481349572_936: 8 bytes, 1 words, 77 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: MD5\nHash.Target......: 919509ee78ca3da484bd24e5d76def50\nTime.Started.....: Fri Dec  9 20:59:35 2016 (0 secs)\nTime.Estimated...: Fri Dec  9 20:59:35 2016 (0 secs)\nInput.Base.......: File (/usr/local/src/sec/crack/hashcat/github/hashcat/hashcat.induct/hashcat.loopback.1481349572_936)\nInput.Mod........: Rules (/var/local/rules/best64.rule)\nSpeed.Dev.#1.....:        0 H/s (0.00ms)\nSpeed.Dev.#2.....:        0 H/s (0.00ms)\nSpeed.Dev.#3.....:        0 H/s (0.00ms)\nSpeed.Dev.#4.....:        0 H/s (0.00ms)\nSpeed.Dev.#5.....:        0 H/s (0.00ms)\nSpeed.Dev.#6.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 77/77 (100.00%)\nRejected.........: 0/77 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nCandidates.#1....: [Copying]\nCandidates.#2....: el -> elCoel\nCandidates.#3....: [Copying]\nCandidates.#4....: [Copying]\nCandidates.#5....: [Copying]\nCandidates.#6....: [Copying]\nHWMon.Dev.#1.....: Temp: 63c Fan:  5% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:8\nHWMon.Dev.#2.....: Temp: 61c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#3.....: Temp: 55c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:16\nHWMon.Dev.#4.....: Temp: 51c Fan:  0% Util:  0% Core:1366Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#5.....: Temp: 63c Fan:  0% Util:100% Core:1379Mhz Mem:3004Mhz Lanes:1\nHWMon.Dev.#6.....: Temp: 63c Fan:  0% Util: 99% Core:1366Mhz Mem:3004Mhz Lanes:1\nCache-hit dictionary stats /usr/local/src/sec/crack/hashcat/github/hashcat/hashcat.induct/hashcat.loopback.1481349572_936: 8 bytes, 1 words, 77 keyspace\n^C\n. Yep, fixed for me. Exactly the same setup as before.\n$ ./hashcat -m 0 --loopback -a 0 example0.hash ./dicts* -r /var/local/rules/best64.rule --potfile-disable\nhashcat (v3.20-29-gf424650c) starting...\nXOpenDisplay() failed\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #2: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #3: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #4: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #5: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\nDevice #6: GeForce GTX 970, 1017/4068 MB allocatable, 13MCU\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #7: AMD FX(tm)-8350 Eight-Core Processor, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 77\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Raw-Hash\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nGenerated dictionary stats for ./dicts1: 8 bytes, 1 words, 77 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\n919509ee78ca3da484bd24e5d76def50:WelCome\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: MD5\nHash.Target......: 919509ee78ca3da484bd24e5d76def50\nTime.Started.....: Sat Dec 10 05:45:24 2016 (0 secs)\nTime.Estimated...: Sat Dec 10 05:45:24 2016 (0 secs)\nInput.Base.......: File (./dicts1)\nInput.Mod........: Rules (/var/local/rules/best64.rule)\nSpeed.Dev.#1.....:        0 H/s (0.00ms)\nSpeed.Dev.#2.....:        0 H/s (0.00ms)\nSpeed.Dev.#3.....:        0 H/s (0.25ms)\nSpeed.Dev.#4.....:        0 H/s (0.00ms)\nSpeed.Dev.#5.....:        0 H/s (0.00ms)\nSpeed.Dev.#6.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 77/77 (100.00%)\nRejected.........: 0/77 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nCandidates.#1....: [Copying]\nCandidates.#2....: [Copying]\nCandidates.#3....: WelCome -> elCoel\nCandidates.#4....: [Copying]\nCandidates.#5....: [Copying]\nCandidates.#6....: [Copying]\nHWMon.Dev.#1.....: Temp: 61c Fan:  2% Util:  0% Core:1290Mhz Mem:3004Mhz Lanes:8\nHWMon.Dev.#2.....: Temp: 62c Fan:  2% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#3.....: Temp: 56c Fan:  0% Util:  0% Core:1354Mhz Mem:3004Mhz Lanes:16\nHWMon.Dev.#4.....: Temp: 49c Fan:  0% Util:  0% Core:1366Mhz Mem:3004Mhz Lanes:4\nHWMon.Dev.#5.....: Temp: 68c Fan:  0% Util:100% Core:1379Mhz Mem:3004Mhz Lanes:1\nHWMon.Dev.#6.....: Temp: 66c Fan:  2% Util:100% Core:1366Mhz Mem:3004Mhz Lanes:1\nStarted: Sat Dec 10 05:45:07 2016\nStopped: Sat Dec 10 05:45:26 2016\n. I've added a thumbs up, but I have no real understanding of the level of effort required.. Tests as fixed for me - thanks!. Fantastic. This will really help with the learning curve for new users. Very happy to see this.. I've been using hashcat for a couple of years and I sometimes have to stop to think about it. :)  The current method is a relatively rare way to handle options.\nI wouldn't mind seeing something like --attack-mode [straight|combination|bruteforce|wordlist-mask|mask-wordlist], with minimum-disambiguation strings (s,c,b,w,m) allowed. The mode numbers would also still be allowed, of course.\nIt would also make the examples self-documenting, and easier for new users to understand.. Playing devil's advocate for a moment ...\nIf the usability problem that you're describing was widespread and considered to not be worth the tradeoff, more projects would use numeric commandline options.\nThe disambiguation problem that you're describing is one that every other mature command-line utility that I'm aware of (outside of the hashcat family) manages. I don't know of any other mature project outside of the hashcat family that relies solely on numeric options.. @DoZ10, you can check the closed PRs for recent examples of new algorithms - especially the ones that are all done in a single PR - so you can get a clean picture of the full scope of what needs to be done.. From http://www.openwall.com/john/doc/MODES.shtml:\n\nThis is the mode you should start cracking with. It will use the login names, \"GECOS\" / \"Full Name\" fields, and users' home directory names as candidate passwords, also with a large set of mangling rules applied. Since the information is only used against passwords for the accounts it was taken from (and against password hashes which happened to be assigned the same salt), \"single crack\" mode is much faster than wordlist mode. This permits for the use of a much larger set of word mangling rules with \"single crack\", and their use is always enabled with this mode. Successfully guessed passwords are also tried against all loaded password hashes just in case more users have the same password.. Examples are now documented here: https://hashcat.net/wiki/doku.php?id=rule_based_attack#using_p_nth_instance_of_a_character_with_positional_rules. @solardiz, @0xbsec - good points, both. The distinction is indeed important. I lacked the vocabulary to make it - thanks. Fixed.. I found @neheb's hashcat-utils integration also:\n\nhttps://scan.coverity.com/projects/hashcat-utils. Heh - I see what you did there, @ratzrattillo . :) http://cryto.net/~joepie91/blog/attachments/jwt-flowchart.png. @ratzrattillo Indeed :) I was acknowledging your wink. I could tell that you already knew why. :). I hadn't thought of that, but that seems interesting. I was thinking a few things, all of which basically boil down to \"least likely is also interesting\" :) :\n\n\nFor keyspaces small enough to exhaust on a given platform, the user can get a higher percentage of harder-to-crack plains first. Depending on your use case, that might be a feature.\n\n\nFor keyspaces too large to exhaust on a given platform, the user can explore parts of the \"Markov keyspace\" that would otherwise be inaccessible on that platform.\n\n\nNow that we have display of candidates, the user can learn more about the far end of Markov.\n\n\nNow that I think about it, \"start the attack at this part of the Markov/keyspace\" might be even better. It would provide a way to divide up the keyspace for distributed work, or a way to do a poor-man's resumption of work if the original work state was lost. If that would be easier than inverting it, that would be an interesting alternative.. I don't actually understand enough about Markov to know whether it can be started/resumed at an arbitrary point in the keyspace without other session information. If it can't, my later idea above is nonsensical.. I imagine that I could explore the far end of Markov for a given keyspace with the load-distribution features (--skip/--limit) and --stdout. I'll tinker with that. Thanks for the detailed explanation - should be informative for future searchers.. For the curious, here's what (I think?) appears to be the other end of the current default markov for some sets of ?a:\n```\n$ hashcat --version\nv3.5.0-76-gb924901b\n$ hashcat -a 3 --skip=81450624 --limit=1 ?a?a?a?a?a?a?a --stdout | tail\n'~}}~|~\n)~}}~|~\n:~}}~|~\n{~}}~|~\n\\~}}~|~\n]~}}~|~\n\n~}}~|~\n|y}}~|~\n}~}}~|~\n ~}}~|~\n\n$ hashcat -a 3 --skip=7737809374 --limit=1 ?a?a?a?a?a?a?a?a --stdout | tail\n'~}}~|~}\n)~}}~|~}\n:~}}~|~}\n{~}}~|~}\n\\~}}~|~}\n]~}}~|~}\n\n~}}~|~}\n|y}}~|~}\n}~}}~|~}\n ~}}~|~}\n\n$ hashcat -a 3 --skip=735091890624 --limit=1 ?a?a?a?a?a?a?a?a?a --stdout | tail\n'~}}~|~}~\n)~}}~|~}~\n:~}}~|~}~\n{~}}~|~}~\n\\~}}~|~}~\n]~}}~|~}~\n\n~}}~|~}~\n|y}}~|~}~\n}~}}~|~}~\n ~}}~|~}~\n```. FWIW, I also see this as an easy/lightweight way to get simple load-distribution effects without dividing up the keyspace, or in addition to dividing up the keyspace - even if only on a temporary basis, and quickly, since no calculations would be required. You can guess why I thought of this in the last 48 hours ;)\n\nHowever, I now also think that the same effect could be achieved by having an option to the tool that creates the Markov stats file, to tell it to invert the Markov while creating it. This would provide more flexibility (and be much easier) than telling Hashcat itself to try to \"invert\" the Markov (which might be hard and it might not be clear how that would work anyway).\nIf it were simply a matter of inverting a basic frequency table, this could be simulated by inverting that table and then getting statistics from it. But Markov is obviously more complex than just frequency. :). GitHub isn't the support path for hashcat - the forums are. Also, please don't cross-post to GitHub and the forums.. The PR is still pending at this writing, but this may be enough fodder for an extraction utility:\nhttps://github.com/e-ago/JohnTheRipper/blob/6fb90c306f420f179db3d143962dbc36daeebba2/src/bitlocker2john.c\nNot sure if this is just a staged copy, or something that's actually functional yet.\n. See also https://github.com/magnumripper/JohnTheRipper/pull/2728. This is more of a usage thing that's more appropriate for the forums if it needs to be addressed further, but you have a few options to truncate depending on context.\n\n\nYou can stack rulesets. So you can add a second ruleset with -r that just contains '8\n\n\nUsing  -j '8 or -k '8\n\n\nAppending '8 to all lines in your ruleset\n\n\nBut even then, you're likely to get duplicates, because all these do is truncate.\nAlso note that unless it's a pretty slow hash, or most of your rules result in strings longer than 8, there's no need to be worried about a few % of strings that are too long.. ~~ Ah, sorry. OK, then creating a rule file with '>8' in it, and then adding it as a second -r (so -r myrules.rule -r min8.rule) may do the trick.~~ Using > -in an -r ruleset doesn't work:\nCannot convert rule for use on OpenCL device in file /var/local/rules/min8.rule on line 1: >8\n-j / -k should skip post-rules plains without trying to hash them. You'll see plains less than 7 in --stdout output, but they'll show up in the \"Rejected\" status line.. It did checkpoint-quit at this point. Maybe I just don't understand well enough how to do back-of-the-napkin checkpoint calculations?\nSession..........: hashtest\nStatus...........: Aborted (Checkpoint)\nHash.Type........: SHA1\nHash.Target......: left.txt\nTime.Started.....: Fri Mar 10 14:11:50 2017 (2 hours, 6 mins)\nTime.Estimated...: Fri Mar 10 23:40:45 2017 (7 hours, 22 mins)\nInput.Base.......: File ([redacted])\nInput.Mod........: Rules (test.rule, ./hybrid/append_ds.rule)\nInput.Queue......: 4/74 (5.41%)\nSpeed.Dev.#1.....:  1755.1 MH/s (381.22ms)\nSpeed.Dev.#2.....:  1051.0 MH/s (413.80ms)\nSpeed.Dev.#3.....:  1100.5 MH/s (395.12ms)\nSpeed.Dev.#4.....:  1107.9 MH/s (392.49ms)\nSpeed.Dev.#5.....:  1117.1 MH/s (389.22ms)\nSpeed.Dev.#6.....:  1107.3 MH/s (392.67ms)\nSpeed.Dev.#*.....:  7238.9 MH/s\nRecovered........: 2612036/4579032 (57.04%) Digests, 0/1 (0.00%) Salts\nRecovered/Time...: CUR:0,61,N/A AVG:5,337,8111 (Min,Hour,Day)\nProgress.........: 60024845107200/252073359486120 (23.81%)\nRejected.........: 0/60024845107200 (0.00%)\nRestore.Point....: 851968/23393476 (3.64%)\nCandidates.#1....: 1Diluiate~ -> DSMEN7OMBU~\nCandidates.#2....: 5ascidian~ -> CICCULETSA~\nCandidates.#3....: 9Ombudsmen~ -> EUNDER9ST~\nCandidates.#4....: 1Steunders~ -> CIDIAN4AS~\nCandidates.#5....: BAAA-BBB~ -> LUIATE0DI~\nCandidates.#6....: letsaciccu~ -> KERDEN6MO~\nHWMon.Dev.#1.....: Temp: 60c Fan: 80% Util:100% Core:1873MHz Mem:4513MHz Lanes:8\nHWMon.Dev.#2.....: Temp: 24c Fan: 50% Util:  0% Core: 734MHz Mem:3004MHz Lanes:4\nHWMon.Dev.#3.....: Temp: 16c Fan: 50% Util:  0% Core:1164MHz Mem:3004MHz Lanes:16\nHWMon.Dev.#4.....: Temp: 19c Fan: 50% Util:  0% Core: 607MHz Mem:3004MHz Lanes:4\nHWMon.Dev.#5.....: Temp: 20c Fan: 50% Util:  0% Core: 822MHz Mem:3004MHz Lanes:1\nHWMon.Dev.#6.....: Temp: 23c Fan: 50% Util:  0% Core:1164MHz Mem:3004MHz Lanes:1\nStarted: Fri Mar 10 07:29:54 2017\nStopped: Fri Mar 10 16:18:38 2017\n. 1/4 of the way into a job, I wouldn't expect the restore point to only be at 3.64%.. For future searchers - my intuition is that for any given run, there would be roughly x restore points that are each 1/x percent of the total. If there's a quick way to capture why not, then it might head off future questions. I will add the answer to the FAQ.. More broadly, the deep symptom you're describing seems to be that it sometimes takes a long time to find out that syntax or inputs are obviously wrong.\nYou're definitely right that simple checks -- for the existence of files and directories, sanity/format of masks, etc. -- need to happen earlier in some cases. Moving them prior to expensive phases like checking for duplicates, sorting hashes, etc. would be a big win. The need for this becomes more obvious as the number of hashes goes up.\nThings that should happen up front or sooner (some of which may already be there, just listing them for completeness):\n\n\nChecking for existence and permissions of all required files and directories (both the ones specified on the command line, and the default/assumed ones)\n\n\nWhether or not the combinations of command line options and flags are compatible and sane\n\n\nWhether or not the hashes in the file are the expected length and composition (I would like to have the default behavior be that as soon as a single hash is seen as obviously incorrect, the entire run aborts instead of trying to continue to load them all, and to have this check happen quickly up front instead of after all hashes are loaded, deduped, sorted, etc.)\n\n\nIt would also be useful for an early rough guess for resources on the target platform. If each hash format hash a relatively well known memory requirement (or at least a rough upper bound), we can probably make a pretty good guess as to if the job will fit on the current platform. Even a rough check of size of hashes file and rule count against available OpenCL memory would go a long way to stopping a nonsensical command line very early.. @jsteube , my apologies for the potentially contentious feedback earlier. I recognize that hashcat has made huge advances in making sanity checks much earlier in a run than in the past. I know that a lot of work has gone into it, and it has helped me to learn hashcat because it is now more forgiving of my errors. :)\nThat being said, it's clear that the original poster has at least one use case where they are experiencing feedback later in the process than expected. I, too, would like to hear more from them about the exact syntax used, to address any issue.\nI myself encountered an issue recently where I thought that hashcat could have aborted much sooner. Unfortunately, I did not record it at the time. :( So I have tried to rediscover it today. In my testing, I discovered a few other cases where sanity checks for naive or unusual input may still be needed. \nI also suspect that any remaining delayed-feedback failure modes are probably now rare for experienced users. But they are more likely to be triggered by unusual or naive use cases. It is common for new users to try \"creative\" things that are more likely to result in typos or nonsensical combinations. I think that it is a good idea to be supportive of new and creative uses of hashcat, and I believe that a good way to support that is to provide extra sanity checking for syntax and inputs ... where time permits. :)\nPlease be gentle, as I do not mean to pile these on as an insult. I just wanted to capture the effort so that others could work from the list if needed. \n\n\nWhen an invalid attack mode (such as \"-a bogus\" or \"-a 9\") is specified, all hashes are loaded and the attack run begins, assuming stdin input. Solution: check for invalid attack modes early.\n\n\nSpecifying a directory as rules input (\"-r /var/tmp/dir\") is accepted. Hashcat pauses for a very long time at \"Generated bitmap tables\". (It appears that hashcat may be trying to parse the directory as a ruleset? This could have weird side effects we should avoid). Reading rules from a directory was a recent feature request, so naive users may try this. Solution: check if -r input is directory and reject.\n\n\nAn empty rules file (\"-r /var/tmp/emptyfile\") is not detected until after the expensive activities of loading all hashes, etc is completed. (This one may seem iffy, but this could happen if, for example, a script tried to combine rules files automatically but experienced an error, resulting in a zero-byte rules file). I think this may have been the one I encountered. Solution: Detect and reject empty rules files early.\n\n\nI also found some incidental ones that are not delayed-feedback issues, but may also need attention at some point:\n\n\nAn empty session name (\"--session=\") is accepted, resulting in a functional run, but using run files with an empty filename prefix, and just the bare file/dir names '.pid', '.outfiles', '.log', etc. Solution: explicitly reject empty session names.\n\n\nAn empty potfile path (\"--potfile-path=\") is accepted. This results in an immediate error, but the error is \"No such file or directory\". Solution: explicitly reject empty potfile paths \n\n\nAn empty restore-file path (\"--restore-file-path=\") is accepted. I am not sure if this is supposed to be interpreted the same as \"--restore-disable\" or not, but should probably return an error.\n\n\n(And really, any other cmdline options that are expecting a value should reject an empty one, which might be common when using scripts or environment variables)\nAll tests above were against v3.40-49-g20057d8.\nIf you prefer, I can create a new issue for the items that I found. \n\"Why the heck would anyone do that?\" is a reasonable response to many of these. :) However, note also that, beyond naive users, but not yet at the level of using the full API, there are also people who want to do simple scripting around hashcat work. Scripting errors can also cause unusual failure modes, like empty variables, files that are supposed to be directories and vice versa, etc. In other words, while naive users might do silly things on purpose, experienced users might do unexpected things as side effects of upstream processes like scripting, so weird corner cases are IMO worth pursuing.\nEven if the items that I found are not a high priority for the core team, if other people can submit PRs for them, it might be worth tracking.. Note also that the tags/names for these attributes were just enough to disambiguate but are otherwise pretty artless, so they could be changed to whatever is best, of course. :). That's interesting - bummer that it's a net loss from a support load perspective. FWIW, if an automatic bypass existed for average per hour and average per day, I would probably use them a lot.. Confirmed as non-reproducible on my side. I am not sure now how I got that case. \nI have a shell script with each test case in it to capture exactly what parameters I used, and this one now behaves as expected. \nIf I can determine that it really was happening, I will open a separate issue.. Problems with operating hashcat should probably be posted on the hashcat forum instead.\nhttps://hashcat.net/forum/\nYour problem is shown in the error:\n\"Intel's OpenCL runtime (GPU only) is currently broken\"\nThis may or may not be workaround for you:\n\"You can use --force to override this but do not post error reports if you do so\"\nAs the error says, this is a problem that Intel must fix in their GPU OpenCL driver. It's possible that if there is a version of Intel's GPU OpenCL driver that is newer than your version, that might work.\n. Rather than truncating, a compression notation (...) that leaves both beginning and end of the target hash might be better, as in:\n$7z$0$19$0$salt$8$f6196259a7326e3f0000000000000000$185065650$112$98$f3b...421cf2\n. Fair question!\nI suggest using the current maximum screen width for ordinary output (the HWMon lines), which appears to be 80, as a starting point (well, actually 81, if the number of lanes is 16!). My example above was intended to be aligned with that.\nThat being said, some native consoles (such as some used on FreeBSD) actually force an extra linewrap to appear if 80 characters are used, so 79 characters may be a better universal choice.\nI also personally like the idea of showing only the last 6 or 8 characters (or so), so that the maximum amount of non-digest material (before the last $) is shown. Most hash formats tend to prepend non-digest material, rather than appending it, so I think that would generally work.\nShould the compression itself be a user-configurable option? Or should we simply compress all hashes above a certain size (and if so, at what threshold? And should that threshold be user-configurable?) I don't want to bog down in too many options, but people may have strong and differing opinions that would be satisfied by making the compression and the length configurable.\n. That's fair.. Great call with tightening up the width overall - much appreciated!. Thanks! You and @jsteube were my primary target audience, so if it's a good writeup (and a successful one!), then mission accomplished. I also wanted to try to create a good example for others to use as a reference.\nMinor edit: I added a few more 'hashcat' NetBSD examples, to demonstrate the spread of the iteration counts.. Ah, indeed - I missed the mention of SHA-256 and SHA-512 from 3.13 onwards in the Juniper docs. Thanks, @sgerraty! (And good to hear from you. I'm a FreeBSD and Juniper fan - thanks for your work on both.). @philsmd, @jsteube - works like a charm - thanks! And quite impressive turnaround time!\nFor reference, this new mode (Juniper/NetBSD sha1crypt) is mode 15100, and was committed in d1b2fa0b31995c74b11bf1699a469ed4a513086d.. As expected, a pretty slow hash:\n```\n$ ./hashcat -m 15100 -a 4 '$sha1$17279$hdDR44dw$ww46F6oJlRk8g5HBsK05ApaiUcmL' ?b?b?b?b?b?b?b\n[snip]\n\nDevice #1: GeForce GTX 970, 1009/4037 MB allocatable, 13MCU\nDevice #2: GeForce GTX 750 Ti, 500/2000 MB allocatable, 5MCU\n\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: Juniper/NetBSD sha1crypt\nHash.Target......: $sha1$17279$hdDR44dw$ww46F6oJlRk8g5HBsK05ApaiUcmL\nTime.Started.....: Thu Mar 23 16:29:06 2017 (1 min, 10 secs)\nTime.Estimated...: Sun May 24 02:16:56 2020 (19992 years, 263 days)\nInput.Mask.......: ?b?b?b?b?b?b?b [7]\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    84017 H/s (298.67ms)\nSpeed.Dev.#2.....:    30195 H/s (318.16ms)\nSpeed.Dev.#*.....:   114.2 kH/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 7077888/72057594037927936 (0.00%)\nRejected.........: 0/7077888 (0.00%)\nRestore.Point....: 0/281474976710656 (0.00%)\nCandidates.#1....: $HEX[706172696e616e] -> $HEX[70ffff0c000000]\nCandidates.#2....: $HEX[7061726e657261] -> $HEX[70ffff11000000]\nHWMon.Dev.#1.....: Temp: 73c Fan: 52% Util:100% Core:1265MHz Mem:3004MHz Lanes:8\nHWMon.Dev.#2.....: Temp: 44c Fan: 32% Util:100% Core:1163MHz Mem:2700MHz Lanes:8\n```. @pavlinux - by any chance are you running without X11 on this system?\nThis may be related to devices getting created on non-X11 systems. I don't know a lot about it yet, but this thread may be informative:\nhttps://bugs.archlinux.org/task/39203. @jsteube - First of all, thanks for considering this!\nOK, I can't pretend to understand the underlying complexity. :) I'm fine with you changing the format from the original request into whatever works better. If we can skip some complexity of the layers in this pass, I would say go for it.\nNot knowing any better, I assume that we can easily know these things:\n\nLiteral start and stop time of hashcat itself\nLiteral start and stop time of dictionary caching\nLiteral start and stop time of guessing\n\nNaively, from these, I would think that we can calculate all of the values I was curious about:\nDictionary caching = dict stop - dict start\nOther setup = total setup - dictionary caching\nTotal setup = literal start - guessing start\nGuessing = guessing stop - guessing start\nTotal time = literal stop - literal start\nAs to how to export the values, is the additional work for using hashcat_status_t complex work, or just boring work? If it's boring work, I would expect that it would be useful to have this info from the API, and it would be worth the cost.\nI trust your judgment on the right balance between functionality and effort. . @philsmd - Concur 100%. I should have caught that. I think that I have them synced now. It was relatively easy to sync usage.c and interface.c (because I could automate comparing them), but docs/readme.txt is a whole other animal (significantly different names, multiple hash types rolled up into single entries, different sort order), so I just manually fixed the obvious things like case in readme.txt, but otherwise had to defer for time/consensus. \nI tried to research the conflicts -- such like exact version numbers in CMSes, etc where hashing methods changed -- but I may have made some errors, so a sanity check would be great.. Once this PR is stable and accepted, I'll also sync the names as shown in the example hashes page on the hashcat.net wiki.. Wiki is synced now, except for some differences due to specific hash examples being different even though the hash mode is the same (MD5 phpBB vs Joomla, etc.) or other such purpose-specific differences.. Something doesn't sound right. @XxoraxX, could you post your command line (with hashes redacted), including any errors that hashcat produces?. Are the whitespace differences a correction to follow the existing standard, or were they inadvertent?. This is really more a question for the hashcat forums.\nYour question isn't really whether this GPU is supported by hashcat, so much as whether there is OpenCL available for the GM45. From a brief search, it looks to me like there is no OpenCL for this chip. OpenCL is required for modern (GPU-based) hashcat. You can still use hashcat-legacy on CPU.\n. Stock 1080s, no overclocking, hashcat mode 14800 (iTunes backup >= 10.0):\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2028/8113 MB allocatable, 20MCU\nDevice #2: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\nDevice #3: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\nDevice #4: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\nDevice #5: GeForce GTX 970, 1009/4037 MB allocatable, 13MCU\nDevice #6: GeForce GTX 1080, 2028/8114 MB allocatable, 20MCU\n\nHashtype: iTunes backup >= 10.0\nSpeed.Dev.#1.....:       94 H/s (8.51ms)\nSpeed.Dev.#2.....:       94 H/s (8.60ms)\nSpeed.Dev.#3.....:       94 H/s (8.50ms)\nSpeed.Dev.#4.....:       94 H/s (8.50ms)\nSpeed.Dev.#5.....:       31 H/s (12.33ms)\nSpeed.Dev.#6.....:       94 H/s (8.47ms)\nSpeed.Dev.#*.....:      499 H/s\nCould there be some confusion with pre-10.0 iTunes (hashcat mode 14700)?\nHashtype: iTunes backup < 10.0\nSpeed.Dev.#1.....:   157.2 kH/s (53.24ms)\nSpeed.Dev.#2.....:   154.6 kH/s (54.13ms)\nSpeed.Dev.#3.....:   156.8 kH/s (53.32ms)\nSpeed.Dev.#4.....:   156.4 kH/s (53.48ms)\nSpeed.Dev.#5.....:    72598 H/s (74.92ms)\nSpeed.Dev.#6.....:   156.8 kH/s (53.39ms)\nSpeed.Dev.#*.....:   854.4 kH/s\n. Examples are now documented here: https://hashcat.net/wiki/doku.php?id=rule_based_attack#using_p_nth_instance_of_a_character_with_positional_rules. Nice!\nFor testers, here is a bash one-liner commandline test:\n$ (for item in a ab abc; do echo $item; done) | hashcat --stdout -j '_2'\nab. Appears to be fixed now - thanks!. That's fair. Of the tags from the hashcat examples, there's a definite trend:\n1\n2a\n5\n6\n7z\n8\n9\nB\nBLAKE2\nChaCha20\nDCC2\nDPAPImk\nH\nP\nPHPS\nRAR3\nS\napr1\naxcrypt\naxcrypt_sha1\nbitcoin\nblockchain\ncram_md5\necryptfs\nepiserver\nethereum\nitunes_backup\nkeepass\nkrb5pa\nkrb5tgs\nmd5\nml\nmysqlna\noffice\noldoffice\npdf\npostgres\nracf\nrar5\nsha1\nsip\nzip2\n@magnumripper, I'm not attached to either approach strongly, but just out of curiosity, other than historical trends, are there any practical or programmatic reasons why mixed case would be bad?. Indeed. I like the unified machine-readable and human-readable lower-case simplicity. As you can see, committed as such. Thanks for speaking up.. Up for me at this writing; still down for you, @shaunwarman ?. Totally understood. This has been debated quite a bit on IRC, and @jsteube has no plans to revert this. \nThe workaround in Kali that you're describing -- arbitrarily picking a different version number that never existed upstream -- is unusual and not recommended, as it can make things much worse.\nFortunately, for Debian/Ubuntu variants, there is a well-known way to handle this:\nhttps://www.debian.org/doc/debian-policy/ch-controlfields.html#s-f-Version\nepoch\nThis is a single (generally small) unsigned integer. It may be omitted, in which case zero is assumed. If it is omitted then the upstream_version may not contain any colons.\nIt is provided to allow mistakes in the version numbers of older versions of a package, and also a package's previous version numbering schemes, to be left behind.. As I said, @jsteube has made it very clear that this isn't going to change. And I do get exactly what you're saying, and I even personally agree a bit. But two release cycles have happened since, and they're not going to be reverted.. And that is why deciding to use arbitrary version numbers in the packages -- that match no existing upstream versioning and don't even match each other -- was ill-advised.\nThe most robust thing to have done would have been to make a one-time correction, just as @jsteube described. The best way to do this would have been with epoch.\nAnd at this point, even with the multiple unrelated version numbers in play, using epoch is still the best way to fix the situation and move on.\nBut please don't continue to change the downstream version numbers out of sync with the true version number. If you think that using epoch confuses users ... arbitrary, made-up version numbers will surely confuse everyone even more. The hashcat project will start getting bug reports for version numbers that have never existed and never will. It will be a nightmare.\nThe best thing, both for hashcat and the downstreams, is to bump everything to 1:3.6.0 ASAP, and move forward.. @sergiolover Do you have any info on how popular SunShop CMS might be, or what other platforms might use this algorithm? If I search for \"SunShop CMS\", I get almost no hits.. As a control group, the speeds are identical on my 2012 Macbook Air:\n```\n$ ./hashcat -m 2500 -b\nhashcat (v3.6.0-48-g52c1e15f) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     2954 H/s (85.57ms)\n\n$ ./hashcat -m 2500 -b\nhashcat (v3.6.0-51-g56dc8ae3) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i5-3317U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     2959 H/s (85.57ms)\n```. Interesting - could be handy.\n@usernamestaken, a related side note: \nMultiple search engines seem to suppress the example-hashes wiki page sometimes. We are not sure why. The page is still there, but is removed entirely from search results, even when using very specific search strings.. It may be useful to separate with tabs or pipes instead, to support various CSV-parsing systems. This will also sidestep any potential commas-in-the-hash-name parsing issues.. @usernamestaken - stray wrapping with leftover quoting around line 17:\n400|\"phpass, WordPress (MD5),\nJoomla (MD5)\"|$P$984478476IagS59wHZvyQMArzfx58u.. Closer ... but the GitHub CSV parser still sees an error (though I'm honestly not sure why yet):\nhttps://github.com/usernamestaken/hashcat/blob/f38fd0f47f2141fab97cfc265b086b4a543d98b0/docs/example_hashes.csv\nMaybe because it's the first record that actually contains commas. Maybe tab-separated would be more universally applicable. Kinda flying by the seat of my pants here. :). Fair. My only reason for citing the online viewer was that if its parser is happy, most other tools will probably also have no problem. Glad to have it, regardless. I hope it's accepted.. Ah, didn't realize that was there! A cmdline option to show them could be handy.. Will do. May be a few days before I can get to it.. Side question: what real-world systems allow '$' in the salt? That would have to be a pretty deliberate and specific modification to the algorithm without a lot of payoff.. @extended11 It's off-topic, but I'm very interested in descrypt in its historical context, so I'd love to confer with you offline in more detail. I'm quite Google-stalkable. :).  For what it's worth, I can reproduce this on the latest.\n```\n$ hashcat -V\nv3.6.0-328-ge6cb69e\n$ cat empty.pot\n$ cat testhashes\n1$ccccccccccc\n1$QQQQQQQQQQQ\n1qYYYYYYYYYYY\n1qwwwwwwwwwww\n1rwwwwwwwwwww\n1rsssssssssss\n$ hashcat -m 1500 --left --potfile-path=empty.pot testhashes\n1$ccccccccccc\n1$YYYYYYYYYYY\n1$QQQQQQQQQQQ\n1$wwwwwwwwwww\n1rsssssssssss\n1rwwwwwwwwwww\n```. Recent John the Ripper work is probably relevant:\nhttps://github.com/magnumripper/JohnTheRipper/issues/2658\nhttps://github.com/magnumripper/JohnTheRipper/pull/2659. John the Ripper has a working implementation now, with sample data - see https://github.com/magnumripper/JohnTheRipper/issues/2658. it's a pretty rare corner case, with a known workaround (HEX-ify, then convert that to hex and use --hex-wordlist (i've been calling this \"hexception\"):\nhttps://gist.github.com/roycewilliams/8f3bf8e3109f771b1b773265317c6c1c\n... so it won't hurt my feelings if this is a wontfix ... though there may be a better fix for the more general case.. The issue was apparently seen when using v3.6.0-345-g98b4aab. ... and is apparently no longer happening in the latest beta. Closing - thanks!. Good catch. I've added a link to the maskprocessor page, which in turn links to downloads thereof. If that's good enough, please close the issue; otherwise, we'll discuss. :). Done (ish).. (AKA the \"Troy Hunt 320M Passwords\" bug) :)\nThanks!. Huh - this was news to me, didn't realize there was a difference (or why hashcat's -m 12500 is listed as \"RAR3-hp\" - to distinguish from what I would expect would be called \"RAR3-p\"):\nhttp://blog.zorinaq.com/brute-forcing-rar-archives-encrypted-with-the-hp-option/\nhttps://stackoverflow.com/questions/44504313/rar3-hashing-algorithm\nhttp://openwall.info/wiki/john/sample-non-hashes#RAR\nThis thread suggests that support is planned, \"but don't ask when\": :)\nhttps://hashcat.net/forum/thread-5334-post-28950.html#pid28950. Admittedly, somewhat rare - but there are a few real-world scenarios where it's needed ... and I think that the number of such use cases is probably only going to increase.\nAm I crazy, or could a reasonable cap on maximum number of allowed hashes be dynamically calculated, based on hash type, allocated memory, and attack type ... maybe even just roughly?\n[Edit: or perhaps, whatever boundary condition is happening that is causing a silent failure could be detected, and used as part of the calculation of the maximum?]. Hmm, I don't see why not (as long as that something is something that varies directly with the number of SHA1 hashes (in this case)). What are the other possibilities?. If there is any value in narrowing the threshold down further, I'd be happy to binary walk it a bit.\nBut just using the information in the issue, should the \"no cracks but no errors\" case be trivial to reproduce?. An interesting find - thanks very much!. This should be closed as \"wontfix - maximum leetness already achieved\" (at least until we reach #31337). Confirmed - this addresses the issue. Thanks! (and credit/blame to @m33x, who noticed that the number was coming up). Perhaps the corollary of this is that \"^$HEX[...\" founds, along with non-ASCII-and-non-UTF-8 founds and colon-containing founds, should be HEX-ified?. Works for me - thanks for the quick turnaround!\n$ hashcat -a 0 -m 100 --quiet --potfile-path=./demo.potfile -r demo.rule demo.txt demo.pass\n9c79c2449dde111b5c5f330f522d8b9d88157a9c:$HEX[244845585b3632373536375d]\n. That IRC ref:\n2017-05-28 09:25:48    [redacted] after copying Intel OpenCL runtime (SRB4.1_linux64.zip) to / the status/pause/etc middle attack controls dont function. but after removing even only the files that got put in /etc/ everything goes to normal (without the drivers ofcourse)\n. There is currently no way to fix this within hashcat. Only Intel can provide a fix.\nYou can also add --force to your hashcat parameters, but it may not work well, and if it has errors, they are not hashcat's fault.. A warning to the user - similar to the one shown when using Intel's OpenCL runtime - may be warranted.. Fair. I have macOS, but I have no AMD with it. To determine whether or not it is PEBCAK, we'd need to find someone with this combination.. Latest GitHub has an interesting workaround for multiple OS' watchdog timeout at the 2-second or higher mark (macOS appears to be 5 seconds; MSDN says 2 seconds for Windows). This workaround promises to eliminate most \"abort trap 6\" errors. Please test.\nhttps://github.com/hashcat/hashcat/commit/73bba00286d815878b544d2d0aa6a79e6cf698ce\nSince \"abort trap 6\" kills hashcat and halts the benchmarking, this script may be useful for testing (it tests one algorithm at a time):\nhttps://gist.github.com/roycewilliams/a343489ed73a3b4e96d2df7e5201dbb4\nSome modes (10700, 15700) will still fail for a different set of reasons. In the future, they may be skipped entirely on platforms that prove to not be able to handle them.\n[Edit: you'll also be able to test when 4.0.0 is released :) ]. Your OpenCL is either broken, or your cards are not supported by the NVIDIA drivers themselves.\nhttps://hashcat.net/faq/wrongdriver/\nThis question should probably on the Hashcat forums instead, as this isn't a problem with hashcat itself. Github issues are only intended for problems/feature requests/development stuff. Please close the issue and (if you really can't figure it out at all with all the documentation wiki/faq/hashcat forums) you can open a new thread on the hashcat forum.. Hashcat requires a working installation of OpenCL for both CPU and GPU.\nPlease close this issue and open a forums thread instead.. Yes. But that is a question for the forums, too. :)\nPlease close this issue and open a forums thread instead.. This will not work the way that you think it will work.\nhttps://hashcat.net/forum/thread-6293.html. @Szeak, the point of that thread wasn't to show you how to generate random passwords. It was to demonstrate how useless it is.. Concur - unable to replicate, must have been install cruft. Closing, thanks!. From a downstream maintainer's perspective, \"outdated\" usually means \"there's a later release available\". :) 3.6.0 is indeed the most recent formal release. (Many changes have been made in preparation for the next release, but it is not yet released (but very close)).. Nice - thanks! This will provide a good UX safety net for new users.. Awesome - thanks!. The mask is A) far too large for hashcat to handle and B) even if it could would take thousands of years to complete. You will need to know more about your target plaintext in order to attack it.. This is a question for the forums, not for a GitHub issue.\nThis is informational only. If you ask for optimized kernels (with -O), but there is no separate optimized kernel needed (there is no speed difference), you get this warning. Either drop the -O for this format (if you don't want to see the error), or just ignore the warning, as it has no impact on performance.. For GPU-driven cracking like hashcat's ... for the effort of setting up 20 used and semi-outdated phones, you could probably get the same computational equivalent by picking up two GPUs.. Looks like OS versions below 9.7 support 32 characters or less? \nhttps://www.cisco.com/c/en/us/td/docs/security/asa/asa97/release/notes/asarn97.html\n(search for \"32 char\")\nTrying to find a volunteer to help me verify on a live system.\nIt's possible that the length 16 was extended some time even earlier than the predecessors of 9.7. According to this page (but references a dead link), in OS version 7.0, the maximum was increased from 16 to 32:\nhttps://github.com/stekershaw/asa-password-encrypt\nWayback Machine copy of \"Cisco ASA 5500 Series Release Notes, Version 7.0(5)\" at https://web.archive.org/web/20140215184559/https://www.cisco.com/c/en/us/td/docs/security/asa/asa70/release/notes/asarn705.html says:\n\"Username and enable password length limits increased from 16 to 32 in the LOCAL database\"\n. Some kind colleagues generated examples for us.\nHere's OS version 9.4(1), with plaintext lengths 8, 16, and 20:\n```\nciscoasa# show ver\nCisco Adaptive Security Appliance Software Version 9.4(1)\nDevice Manager Version 7.4(1)\n Compiled on Sat 21-Mar-15 11:42 PDT by builders\nSystem image file is \"disk0:/asa941-lfbff-k8.SPA\"\nciscoasa(config)# username admin password password\nciscoasa(config)# end\nciscoasa# show run | inc username admin\nusername admin password 7KKG/zg/Wo8c.YfN encrypted\nciscoasa(config)# username admin password hashcathashcat16\nciscoasa(config)# end\nciscoasa# show run | inc username\nusername admin password rC/YIoOgE2yy.A5Y encrypted\nciscoasa(config)# username admin password hashcathashcat16plus\nciscoasa(config)# end\nciscoasa# show run | inc username\nusername admin password UpSYutRKBYRFhl20 encrypted\n```\nAnd here's OS version 7.0(8):\nE.clJuqSbkeIrm25 (\"hashcathashcat16\")\nbnDHWJMbxGxyp4o3 (\"hashcathashcat16plus\"). I'd be curious to hear from @magnumripper about how this \"S\" rule is implemented in JtR, relative to keyboard and character sets. It would have to be a keyboard-specific lookup table of some kind, I guess? It sounds a bit complicated.. I am also interested in all hashes. ;). This is an extremely old version of hashcat. Please upgrade to the latest at hashcat.net.. Anything related to SL3 is verboten in the hashcat community. Long story (which predates my work with the project, but here are some breadcrumbs):\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_can_i_crack_sl3\nhttps://hashcat.net/forum/thread-1887.html\nFurther, any version of hashcat that supports SL3 is so old that it is no longer supported in any way.\nFurther, as I understand it, cudaHashcat-lite v0.9 shouldn't even work anymore unless you're running a cracked version that circumvents time controls.. Perhaps the blob could be created only if the hashlist is above a certain size in bytes, as presented by the filesystem.. This is a question that is better suited for the hashcat forums.\nBut yes, the Truecrypt 62xx family of hash types supports at least some of the possible cascades.. I don't understand the question. Can you give an example (that doesn't use a real/sensitive hash)?. This is probably not a use case for hashcat. In the passwords/crypto context, two hashes being \"less than\" or \"greater than\" each other is irrelevant - because they are randomly distributed by design.. Hi! The hashcat Github is for development of hashcat. This is a question better suited to the support section of the hashcat forums. Please post your question there.. If the version of hashcat in the prompt in your directory (3.30) is the version you're running, that's an extremely old version. Please download the latest (4.10) from hashcat.net and retest. \nYou may also want to make sure you're running the latest version of Kali, as I've heard that a number of OpenCL-related issues have been fixed there.. You appear to be using --force. What warnings is hashcat giving you that are prompting you to use --force?. If the above is a real hash, please delete it and replace it with a hash with a known plaintext (along with the plaintext).. This is a question better suited to the hashcat forums.. There was a change in 4.1.0 that made it necessary to change to the hashcat directory, instead of using full paths. I don't know enough about it to know if there's a better way.\n- Files: Switched back to relative current working directory on windows to work around problems with Unicode characters. I'm open to suggestions on the best way to approach it. Naively, I would say make any part of a rule that isn't the rule directive, but rather the rule argument, interpreted as hex.\nMaybe something like:\n$! would instead be $21\n$0 would instead be $30\nYou could then do a high-frequency newline append with $0a, for example.\nOne problem, of course, is that it would be very nice to be able to do multibyte substitutions, but the rules syntax today assume that replacement rules are only one byte for their arguments (so0, etc.). Ideally, a rule syntax that allows delimiting of the two arguments (like /o/0, /oo/00, etc.) would be very valuable for use with hex rules.\n. Yes, only using hex in the characters seems best.\nI do not intend to mix this up with multibyte, but I do think that we should keep multibyte in mind for the future for this. I will add my comment about multibyte to that other issue.\nTo avoid mixed up rules, we could simply not allow them. We could say that if --hex-rules is used, all rules will be interpreted as hex, and that if --hex-rules is not used, then no rules will be interpreted as hex. I can see how that would be a little bit inconvenient - it would mean that if you wanted to mix, you would have to convert all rules to hex rules. But I am not sure of a better way to resolve this.. Ah, I see. What I didn't realize is that single-byte printable ASCII can be handled natively by hashcat rule processing!\nI still see value in preparing to handle non-printable single-byte (linefeeds, control characters, etc.). Since rules syntax will need to be updated to handle multibyte, I recommend that the future update to rules syntax also have a way to specify hex, perhaps using 0x notation or similar. And IMO, that work could be done independently of the multibyte work (or at least in parallel).. Wow, that's fantastic! I should have searched for other implementations that could be compatible. Thanks very much! This won't get a high number of additional passwords - but the ones that it does get will be interesting!. ... and it works like a charm! \n(Hmm - note the extra newline in the output; should passwords with non-printable ASCII be automatically HEX-ified?)\n```\n$ echo \"passwordwithtrailingnewline\" | md5sum\nc35dd5862611090e628ebab5a25f21d9  -\n$ echo 'c35dd5862611090e628ebab5a25f21d9' >target.hash\n$ cat target.hash\nc35dd5862611090e628ebab5a25f21d9\n$ echo \"$\\x0a\" > test.rule\n$ cat test.rule\n$\\x0a\n$ echo \"passwordwithtrailingnewline\" > test.dict\n$ cat test.dict\npasswordwithtrailingnewline\n$ hashcat --quiet -a 0 -m 0 -r test.rule target.hash test.dict\nc35dd5862611090e628ebab5a25f21d9:passwordwithtrailingnewline\n$ tail -2 ~/.hashcat/hashcat.potfile \nc35dd5862611090e628ebab5a25f21d9:passwordwithtrailingnewline\n$\n```. * Please don't post unknown hashes.\n* Once the hashes are obfuscated, this is a question better suited to the hashcat forums.. I have seen this question from multiple users. It might be good to expand the error message from \"Custom-charset X is undefined\" to \"Custom-charset 1 is missing from the mask file\" or similar, to anticipate similar questions in the future.. Confirmed fixed, thanks for the speed!. IMO, since it's being appended to the end of the existing format, I would expect most implementations to be forward-compatible (or be OK with making a tweak to match it), rather than having its own flag. Just my $0.02.. What category/family should this be? It's not really a password manager per se, but it sort of is.. It would be good to have such an example. In the meantime, see: \nhttps://hashcat.net/wiki/doku.php?id=hashcat_utils#hcstat2gen\nThis wiki entry is very new, so it isn't showing up yet in Google search results for this problem.. Good alternative - added to the wiki. Thanks!. Also, don't forget to update changes.txt - this is a cool add to be able to brag about. :). If there are more than one OTP formats that could be eventually supported, giving them their own category could neatly solve the short-vs-long issue.. That seems perfect for the official algo. name. If the last column of the --help output (which currently has things like \"Operating Systems\", etc.) could use the category name of \"One-Time Passwords\", I think it would meet the rest of the\"findability\" goal.. Also a way to change the timeout period. Since the default used to be to never time out, maybe a --stdin-timeout=[seconds] option, and when the user uses \"0\" (zero) for [seconds], it is disabled?. JtR reference: https://github.com/magnumripper/JohnTheRipper/pull/3449. Confirmed - I was reading too fast and misread the netstat output.. Unable to reproduce.\n```\n$ cat sha1.hash\nca9b29bf69a2416bb90b6867fa1f6a16f326558c\n$ cat sha1.list\nsongcodondetienuongruouasdqwez\n$ hashcat --quiet -m 100 -a 0 sha1.hash sha1.list\nca9b29bf69a2416bb90b6867fa1f6a16f326558c:songcodondetienuongruouasdqwez\n```. For completeness, I would expect even deprecated schemes to be potential cracking targets.\nI have a set here (actual functional containers) that includes RIPEMD-160 - could they be used as a start?\nhttps://www.techsolvency.com/passwords/hashcat-veracrypt/\nThe password for each of them is 'hashcat'.. Hey, thanks back! :) And sorry my test cases weren't more obviously available - I never even noticed the .tc ones were there, and making the .vc ones part of the actual test suite never even occurred to me! I've now made my test cases public and discoverable.. You're using naive-hashcat, which is not managed by the hashcat project. Please either provide the hashcat commandline generated by naive-hashcat, or else start your inquiry with that project.\nPlease also note that the only driver/OpenCL combinations officially supported by hashcat are the ones listed at the top of hashcat.net. Analyzing such problems is better conducted on the hashcat forum.. Huh, I had no idea that multiple masks weren't allowed - just never tried it before! So that explains why my second example doesn't work, but I don't understand yet why my first example doesn't work.. That's unfortunate for my (admittedly unusual) use case - I was deliberately searching for collisions. \nBut isn't that what --keep-guessing is for - finding collisions? Otherwise, why need --keep-guessing at all?\nThis would also mean that limits.txt would need to be updated, because it's not only \"the same password twice for the same hash\", but also \"two different passwords for the same hash\".. Since hashcat's behavior varies depending on hash type (as it should), the user should IMO be able to control this behavior from the command line, or at least for hashcat to help with common user confusion.\nOne way to resolve this would be for --keep-guessing to take an optional parameter, so you could say \"--keep-guessing 0\" to turn it off.\nThis could make the help something like this:\n--keep-guessing            |      | Keep guessing after crack (some algos only); 0 = off |\nAnother way to help would be for the logic something like this:\n\nIf user asks for --keep-guessing but hash type is already NEVERCRACK, reject the commandline.\nIf user asks for --no-keep-guessing (or 0, whatever is chosen), but hash type is not NEVERCRACK, reject the commandline.\nIf user asks for --no-keep-guessing (or whatever), and --keep-guessing, reject the commandline.\n\n. Hey, that seems like a good idea!. To simplify and to conserve screen real estate, I suggest:\nLengths supported by kernel: passwords: 0  - 55; salts: 0 - 51. Maybe we could combine the output somehow, like always saying both:\nKernel type in use: [pure|optimized]\nPure kernels (no -O) allow longer lengths but are usually slower.\n    Pure lengths supported for this hashtype: passwords: 0 - X; salts: 0 - Y\nOptimized kernels (-O) are often faster, but only work with shorter lengths.\n    Optimized lengths supported for this hashtype: passwords: 0 - Z; salts: 0 - Q. That's fair, understood. Though I would also argue that it's the level of information that matches the actual complexity. Most users will ignore it. The ones who do not will be the ones who need to know it. :). ",
    "Rich5": "Interesting. I wasn't aware of an iptables API until now. I did find this link regarding IPTC - http://www.bani.com.br/2012/05/programmatically-managing-iptables-rules-in-c-iptc/\nIs this similar to what you were looking for?\nIf I understand you correctly would the functionality look something like this pseudocode? \n```\ninclude \"oclhashcat.h\"\nstruct hc_options {\n    ....\n} options\nstruct hc_statuc {\n    ....\n}status\nint main (int argc, char **argv) {\nhc = oclhashcat_init()\noptions.hash_file = \"example0.hash\"\noptions.markov_threshold = 32\noptions.words_files.append(\"example.dict\")\noptions.mask = \"?a?a?a?a\"\nstatus = hc.start(options)\n\n}\n```\nThe next step is I would write up a specification before putting any code down.\n. ok so this sounds somewhat similar to what I was doing with pyhashcat. Might be a dumb question, but in this case oclhashcat would remain an exe rather than a importable library correct? Seems like the oclhashcat_init, generate_commandline, and start functions would be in a separate library that's actually providing process handling to call the oclhashcat exe. If so, you're right, that's a much easier way to start. \n. Ok, this is way more clear to me now. How can I help?\n. Sounds good. I'll put together an overview document to get started.\n. I'm making incremental progress on this. One issue I'm running into is determining if an argument has been changed. For example, if the developer sets a variable like this,\nhc.option1 = 1\nhow do we know that option1 has been changed, and should be passed to the apimain function? If C had reflection this would be a bit easier.  The simplest way is to hard code checks of every possible arg and check if it's changed from it's default value defined at the top of oclhashcat.c which would result in a large series of \"if\" statements. \nThis isn't the most elegant approach, but should work. If this is the way you want to go I can finish a prototype of how invokcation would work fairly soon. The other option is to implement some sort of setter function that tracks what args have been set. Another option is to create a hash table for a dictionary lookup rather than a struct to hold the options. This would change the syntax of the API a little though. It wouldn't quite be as clean as using the dot operator as you mentioned above.\nI might be over complicating this though.\n. No, it was not meant to be criticism of C, just a side comment. I was going off our previous discussion about the  iptables api that used the dot operator to assign values, and trying to keep it close to that. I'll work towards the getter/setter method.  \n. Finally sat down to make some more progress on this. I have a prototype for invocation at the link below\nhttps://gist.github.com/Rich5/e01b94492fec048661e6\nIt's a work in progress, but there's enough there that I thought I'd stop and get some feedback. I've included comments through-out and some items that could be changed/improved upon. Any comments or critiques are welcome. C is not my everyday development language so I'm sure there are some practices that could/should be done differently. \n. I also started thinking about what data and stats I would want to pull as a developer. Correct me if I'm wrong, but it looks like the hc_global_data_t data structure holds most of the stats that people would want? If so, then an easy solution could be to have a function that returns a copy of data? That would give a developer access to the stats and maybe help prevent accidental corruption of the variable used to display stats. \n. Ok, should be all updated now with the recent updates included. Same link as above. Let me know if I missed something. I haven't hooked this into the current main function in oclHashcat.c to make sure it works just yet.  So far my tests show that it is generating the command line string correctly. \n. I just looked and I think I'm missing a variable for a second positional (dict) arg for combination attack. I'll update tomorrow.\n. Ok it's been updated again. The three positional args are hash_input, dictmaskdir_p1, dictmaskdir_p2 as shown in the example included in the code. \n. Updated to account for addition of --opencl-device-types option\n. Made some progress on integrating the API with the existing code base. You can review here https://github.com/Rich5/oclHashcat\nMajor edits are:\n- added oclHashcatAPI.c to src/\n- moved defaults from oclHashcat.c to common.h \n- updated make file so now you can just use, make win64API etc.\nStill a work in progress, but coming along. \n. @jsteube I have a design question that I'm struggling with. One of the most useful features of an API is to retrieve information about the program. In this case, it seems like the best data structure to retrieve status is the hc_global_data_t data structure, as I mentioned before. Currently I have a function that returns a pointer to this structure, and it works fine in basic testing. But, I'm assuming that most people will want to run oclHashcat in a background thread or process (e.g. GUI for front end, hashcat background). In that case we could run into a problem with shared memory across threads without mutex, and probably slight performance issues, which of course is unacceptable. \nDo you have any ideas as to a better way to do this without adding multiple lock/unlock calls to the core code base? I hope there is a better design I just haven't thought of yet. \nUPDATE: We might be able to get away with a mutex that locks data as oclhashcat is initializing everything. Then also locks at the beginning of the \"main loop\" (https://github.com/hashcat/oclHashcat/blob/master/src/oclHashcat.c#L15620), and then unlocks at each pass to allow other threads to safely read data. It's hard to say without a lot of testing though. \n. @jsteube Are you saying I should fork the process first? Or is calling the main function in a separate thread the instance management you were referring to? \nHere's a basic overview of what I have right now:\n1. Initialize and call main (renamed to hcapi_main) in a separate thread\n2. control returns to wrapper main while oclhashcat is working in the background\n3. call get_data which returns a pointer to the data global variable.\n4. access variables in hc_global_data_t struct to get running status\nFor example,\n```\nint main()\n{\nprintf(\"[*] Starting API Test.\\n\");\n\nOCLHASHCAT_CON hc = oclhashcat_init();\n\n\nhc.options.attack_mode = 0;\nhc.options.hash_mode = 1000;\nhc.options.hash_input = \"C:\\\\Users\\\\auser\\\\Desktop\\\\hashes.txt\";\nhc.options.append_dictmaskdir(&hc.options, \"C:\\\\Users\\\\auser\\\\Desktop\\\\Dicts\\\\dictionary.txt\");\nhc.options.append_rules(&hc.options, \"C:\\\\Users\\\\auser\\\\Desktop\\\\Rules\\\\somerulse.rule\");\nhc.options.append_rules(&hc.options, \"rules\\\\best64.rule\");\n\nhc.options.quiet = 1;\n\nint c;\nchar **v;\n\nhc.generate_commandline(hc.options, &c, &v);\nhc.start_thread(c, v);\nhc_global_data_t *output = malloc(sizeof(hc_global_data_t));\noutput = hc.get_data();\n\nprintf(\"install dir: %s\\n\\n\", output->install_dir);\n\nu64 all_done     = 0;\nu64 all_rejected = 0;\nu64 all_restored = 0;\nchar quit = 'r';\n\nwhile(1)\n{\n\n    for (uint salt_pos = 0; salt_pos < output->salts_cnt; salt_pos++)\n    {\n        all_done     += output->words_progress_done[salt_pos];\n        all_rejected += output->words_progress_rejected[salt_pos];\n        all_restored += output->words_progress_restored[salt_pos];\n\n        printf(\"all_done: %llu\\n\", all_done);\n        printf(\"all_rejected: %llu\\n\", all_rejected);\n        printf(\"all_restored: %llu\\n\\n\", all_restored);\n\n    }\n\n    quit = getchar();\n    if(quit == 'q') break;\n}\n\n\n// Lots of prints for testing. To be deleted upon release\nprintf(\"[!] BACK IN MAIN\");\ngetchar();\n\n}\n```\nOutput:\n```\n[*] Starting API Test.\n[+] Intializing\n[+] Called Append Dict, Mask, or Dir.\n[+] Called Append Rules.\n[+] Called Append Rules.\n[+] Calling thread\nargc = 7\nargv = oclHashcat --quiet -m 1000 C:\\Users\\auser\\Desktop\\hashes.txt\n C:\\Users\\asuer\\Desktop\\Dict\\Dictionary.txt -rC:\\Users\\auser\\Desktop\\Rules\\somerulse.rule -rrules\\best64.rule\n[+] Start Thread Called from Thread: 5832\ninstall dir: C:\\Users\\auser\\Desktop\\oclhashcat\\oclHashcat\nall_done: 0\nall_rejected: 0\nall_restored: 0\nall_done: 0\nall_rejected: 0\nall_restored: 0\nall_done: 0\nall_rejected: 0\nall_restored: 0\nall_done: 0\nall_rejected: 0\nall_restored: 0\nall_done: 322961408\nall_rejected: 0\nall_restored: 0\nall_done: 864550912\nall_rejected: 0\nall_restored: 0\nall_done: 1680343040\nall_rejected: 0\nall_restored: 0\nall_done: 2597060608\nall_rejected: 0\nall_restored: 0\nall_done: 3897294848\nall_rejected: 0\nall_restored: 0\nall_done: 5399379968\nall_rejected: 0\nall_restored: 0\nall_done: 7071334400\nall_rejected: 0\nall_restored: 0\nall_done: 8824029184\nall_rejected: 0\nall_restored: 0\nq\n[!] BACK IN MAIN\n```\n. @jsteube I'm almost finished with the initial version of the API. One last item I would like to include is a data structure that holds all the results (cracked hashes). Something like:\ntypedef struct {\nchar hash;\n char plain;\n}results;\nI'm defaulting the --quiet option to True to suppress most of the output, but the worker threads still print the hashes as they are cracked. \nIs this print to stdout action done at a single location like a central print function (similar to log_final), or is each thread just print to stdout as the results appear? \nI'm looking for a way to suppress that output and also hook the results to copy to an array. I know I could parse the POT file, but it would be nice to keep everything in memory is possible. \n. Ok, I'm done with the first cut at a beta version of the API. If you're interested in having it merged then I can get a pull request together and write up more formal documentation. Here's an example:\n```\n/ \n * API Test Main\n \n */\nint main ()\n{\nprintf (\"[*] Starting API Test.\\n\");\nhcapi_control_t hc = oclhashcat_init ();\nhc.options.attack_mode = 7;\n  hc.options.markov_threshold = 32;\n  hc.options.hash_input = \"C:\\Users\\rich\\Desktop\\hashes\\example0.hash\";\n  hc.options.append_dictmaskdir(&hc.options, \"?a?a?a?a\");\n  hc.options.append_dictmaskdir (&hc.options, \"C:\\Users\\rich\\Desktop\\hashes\\example.dict\");\nint c;\n  char **v;\nhc.generate_commandline (hc.options, &c, &v);\nhc.start_thread (c, v);\nchar quit = 'r';\nwhile (1)\n  {\nquit = getchar ();\nif (quit == 'q')\n{\n\n  hc.stop ();\n  break;\n}\n\nif(hc.status_update (&hc.status_data)){\n\n\n    printf(\"-----------------session : %s\\n\", hc.status_data.session);\n    printf(\"-----------------devices_status : %u\\n\", hc.status_data.devices_status);\n    printf(\"-----------------devices_status_str: %s\\n\", hc.status_data.devices_status_str);\n    printf(\"-----------------hash_type : %u\\n\", hc.status_data.hash_type);\n    printf(\"-----------------hash_type_str : %s\\n\", hc.status_data.hash_type_str);\n    printf(\"-----------------hash_mode : %u\\n\", hc.status_data.hash_mode);\n    printf(\"-----------------rp_files_cnt : %d\\n\", hc.status_data.rp_files_cnt);\n\n\n    for(uint i = 0; i < hc.status_data.rp_files_cnt; i++)\n    {\n\n      printf(\"-----------------Rules file %d: %s\\n\", i, hc.status_data.rp_files[i]);\n\n    }\n\n    printf(\"-----------------rp_gen : %u\\n\", hc.status_data.rp_gen);\n    printf(\"-----------------rp_gen_seed : %u\\n\", hc.status_data.rp_gen_seed);\n    printf(\"-----------------input_mode : %s\\n\", hc.status_data.input_mode);\n    printf(\"-----------------mask : %s\\n\", hc.status_data.mask);\n    printf(\"-----------------mask_cnt: %u\\n\", hc.status_data.mask_cnt);\n    printf(\"-----------------mask_pos: %u\\n\", hc.status_data.mask_pos);\n    printf(\"-----------------mask_len: %u\\n\", hc.status_data.mask_len);\n    printf(\"-----------------mask_len: %u\\n\", hc.status_data.mask_len);\n    printf(\"-----------------start: %s\\n\", hc.status_data.time_started->start);\n    printf(\"-----------------display_run: %s\\n\", hc.status_data.time_started->display_run);\n    printf(\"-----------------etc: %s\\n\", hc.status_data.time_estimated->etc);\n    printf(\"-----------------display_etc: %s\\n\", hc.status_data.time_estimated->display_etc);\n    printf(\"-----------------devices_cnt: %u\\n\", hc.status_data.devices_cnt);\n\n    for(uint device_id = 0; device_id < hc.status_data.devices_cnt; device_id++)\n    {\n\n      printf(\"-----------------Device %d: \\n\", hc.status_data.speed_dev[device_id].device_id);\n      printf(\"-----------------\\tdisplay_dev_cur: %s \\n\", hc.status_data.speed_dev[device_id].display_dev_cur);\n      printf(\"-----------------\\texec_all_ms: %0.2f \\n\", hc.status_data.speed_dev[device_id].exec_all_ms[device_id]);\n      printf(\"-----------------\\tutilization: %3u%% \\n\", hc.status_data.hwmon_gpu[device_id].utilization);\n      printf(\"-----------------\\ttemperature: %3uc \\n\", hc.status_data.hwmon_gpu[device_id].temperature);\n      printf(\"-----------------\\tfanspeed: %3uc \\n\", hc.status_data.hwmon_gpu[device_id].fanspeed);\n      printf(\"-----------------\\tcore: %4uMhz \\n\", hc.status_data.hwmon_gpu[device_id].corespeed);\n      printf(\"-----------------\\tmem: %4uMhz \\n\", hc.status_data.hwmon_gpu[device_id].memoryspeed);\n      printf(\"-----------------\\tlanes: %u \\n\", hc.status_data.hwmon_gpu[device_id].buslanes);\n      printf(\"-----------------\\tthrottle: %d \\n\", hc.status_data.hwmon_gpu[device_id].throttle);\n\n\n\n    }\n\n\n    printf(\"-----------------digests_cnt: %u\\n\", hc.status_data.recovered->digests_cnt);\n    printf(\"-----------------digests_done: %u\\n\", hc.status_data.recovered->digests_done);\n    printf(\"-----------------salts_cnt: %u\\n\", hc.status_data.recovered->salts_cnt);\n    printf(\"-----------------salts_done: %u\\n\", hc.status_data.recovered->salts_done);\n    printf(\"-----------------digests_percent: %.2f%%\\n\", hc.status_data.recovered->digests_percent*100);\n    printf(\"-----------------salts_percent: %.2f%%\\n\", hc.status_data.recovered->salts_percent*100);\n\n\n    printf(\"-----------------cpt_cur_min: %u\\n\", hc.status_data.recovered_time->cpt_cur_min);\n    printf(\"-----------------cpt_cur_hour: %u\\n\", hc.status_data.recovered_time->cpt_cur_hour);\n    printf(\"-----------------cpt_cur_day: %u\\n\", hc.status_data.recovered_time->cpt_cur_day);\n    printf(\"-----------------cpt_avg_min: %0.2f\\n\", hc.status_data.recovered_time->cpt_avg_min);\n    printf(\"-----------------cpt_avg_hour: %0.2f\\n\", hc.status_data.recovered_time->cpt_avg_hour);\n    printf(\"-----------------cpt_avg_day: %0.2f\\n\", hc.status_data.recovered_time->cpt_avg_day);\n\n\n    printf(\"-----------------progress_cur_relative_skip: %llu\\n\", hc.status_data.progress->progress_cur_relative_skip);\n    printf(\"-----------------progress_end_relative_skip: %llu\\n\", hc.status_data.progress->progress_end_relative_skip);\n    printf(\"-----------------percent_finished: %.2f%%\\n\", hc.status_data.progress->percent_finished*100);\n    printf(\"-----------------percent_rejected: %.2f%%\\n\", hc.status_data.progress->percent_rejected*100);\n    printf(\"-----------------all_rejected: %llu\\n\", hc.status_data.progress->all_rejected);\n\n\n\n} else {\n\n  printf(\"ERROR status update not available\\n\");\n}\n\n}\nprintf (\"[!] BACK IN MAIN\");\ngetchar ();\nreturn 0;\n}\n```\nOutput:\n\nCode is here:\nhttps://github.com/Rich5/oclHashcat\n. There are minimal changes to the core code base, and hashcat builds and functions exactly as it does currently with the API code merged. For example, make win64 works just fine. I tried to make it as unobtrusive as possible. \nThe main changes to the core code is the following:\n- Moved the variables from line https://github.com/hashcat/oclHashcat/blob/master/src/hashcat.c#L24 to\n  https://github.com/hashcat/oclHashcat/blob/master/src/hashcat.c#L152 to common.h\nI did this because hashcatAPI.c uses these variables to compare user input for changes when building the command line to pass to optparse \n- I've used the API macro for specific changes required for using the API. A couple of examples are here:\n  https://github.com/Rich5/oclHashcat/blob/master/src/hashcat.c#L208\n  https://github.com/Rich5/oclHashcat/blob/master/src/hashcat.c#L2043\n  https://github.com/Rich5/oclHashcat/blob/master/src/hashcat.c#L5346\nOther than that all the main API code base is located in hashcatAPI.c\nhttps://github.com/Rich5/oclHashcat/blob/master/src/hashcatAPI.c\n. Sounds good. I'll let you know if any issues comes up. One question is hashcat_get_log strictly for reporting errors? \n. I realize that I previously posted in the closed PR rather than here. See here for my update https://github.com/hashcat/hashcat/pull/382\nAs it turns out I can pass an rpath to the Python extension, but the problem still remains that the lib can't find the OpenCL dependencies.\nIf appears to fails here: https://github.com/hashcat/hashcat/blob/master/src/folder.c#L415 because the shared_dir variable resolves to the cwd of /usr/bin (where the Python interpreter is running). It looks like I should be able to pass the install directory to folder_config_init to fix this right? Something like this call:\nfolder_config_init(hashcat_ctx, \"/home/user/hashcat\", \"/home/user/hashcat\")\nbut shared_dir still seems to resolve to /usr/bin rather than '/home/user/hashcat' when I tried this. I'm pretty sure I'm just missing something small here. Any suggestions? \n . @jsteube Ok so you can ignore my previous comments. I tracked the issue down to https://github.com/hashcat/hashcat/blob/master/src/folder.c#L333\nSince get_install_dir always resolves to resolved_exec_path and resolved_exec_path is resolved using the cwd (exec_path) of the current process here https://github.com/hashcat/hashcat/blob/master/src/folder.c#L33 I end up with an issue at this line https://github.com/hashcat/hashcat/blob/master/src/folder.c#L409 because the current process is Python which runs out of /usr/bin by default. \nSo when hashcat tries to find the OpenCL folder it's prepended with /usr/bin and then throws and error here https://github.com/hashcat/hashcat/blob/master/src/folder.c#L415\nI tested my theory by just copying the OpenCL and hashcat.hctune to /usr/bin and the Python binding work as expected. This is not really a good solution though. You can see the before an after in the image below. \n\nThe easiest solution would to be able to pass in the install and shared directory at compile time just like with native install. \nI also had to cp hashcat.hctune over /usr/bin as well. Similarly, I end up having to run Python as root because libhashcat tries to write to  /usr/bin/hashcat.outfiles at this line https://github.com/hashcat/hashcat/blob/ec5610271aae422cfe856bcf4870901baed35641/src/outfile_check.c#L344 \nI'm not sure these are \"issues\" with hashcat, but I wanted to provide feedback.\n. \n I don't have a real good solution at the moment. We basically just need to be able to tell libhashcat where to find 3 items (from my testing so far):\n1. OpenCL directory\n2. hashcat.hctune\n3. Where to output any files (e.g. hashcat.outfiles, hashcat.log) so we're not trying to write to a protected folder like /usr/bin\nAlthough I'm not sure if it's better to set this at compile time or run time as an API call. \nI think if the user can overwrite anywhere it normally prepends the executable path with an install directory it might work. \nMaybe something as simple as:\n```\nifdef SHARED\ninstall_dir = user_defined_install_dir;\nsession_dir = user_defined_session_dir;\nelse\nget_install_dir (install_dir, resolved_exec_path);\nendif\n```\n. I agree that would be the best solution with two comments.\n\n\nI think libhashcat.so should be installed in /usr/local/lib. Python looks for libraries in the standard locations by default, and I'm sure other applications will as well. Otherwise anyone writing bindings would have to specify an rpath. Not a big deal to do, but it's less seamless for developers using libhashcat. \n\n\nIn the case of a shared library get_exec_path will not always return the path where libhashcat is located, but rather the directory of the parent process. For example, Python will return /usr/bin, but libhashcat may be in /usr/local/lib or somewhere else. So as long as we don't rely on that as the anchor point for paths it should work.  \n\n\nOne other issue that ran into, but forgot to mention was a redefine error caused by this line\nhttps://github.com/hashcat/hashcat/blob/master/include/common.h#L25\nPython already defined _GNU_SOURCE so compiling the module was giving an error. I'm not sure if this is really a hashcat issue, but I just changed line 25 in common.h to\n```\nifndef _GNU_SOURCE\n#define _GNU_SOURCE\n\nendif\n```\nThis could just be an issue with using Python, but I wanted to mention it because other bindings might have similar conflicts. . Awesome! I'll test this out tonight, and let you know if I run into anything else. I think this fixes everything at first glance. . Actually, I'm not sure this fixed it. Unless I'm doing something wrong, but ultimately I'm initializing my module like this:\nself->rc_init = hashcat_session_init(self->hashcat_ctx, \"/usr/local/lib\", \"/usr/local/share/hashcat\", 0, NULL, 0);\nIs that the intended usage?\nWhen I do this the install_dir is eventually set as the resolved_exec_path here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L333 \nSince the resolved_exec_path is taken from the current running process we still get install_dir resolved to /usr/bin(where Python is running out of). \nSo then this check fails: \nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L339\nand profile_dir, shared_dir, and session_dir are all set to install_dir (/usr/bin) here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L363-L365\nThen when we look for the OpenCl folder here:\nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L409\nIt's looking for /usr/bin/OpenClwhich is of course isn't there. I think the root issue is that the get_install_dir function is assuming that libhashcat is being used in the same directory as the program loading it. That's not true in this type of use case. \nSo here's how I got it working. I inserted the following condition starting here: \nhttps://github.com/hashcat/hashcat/blob/master/src/folder.c#L363\n```\nif (install_folder != NULL)\n    {\n      get_install_dir(install_dir, resolved_install_folder);\n      struct passwd pw;\n      struct passwd *pwp;\n  char buf[HCBUFSIZ_TINY];\n\n  getpwuid_r (getuid (), &pw, buf, HCBUFSIZ_TINY, &pwp);\n\n  const char *home_dir = pwp->pw_dir;\n\n  profile_dir = hcmalloc (HCBUFSIZ_TINY);\n  session_dir = hcmalloc (HCBUFSIZ_TINY);\n\n  get_profile_dir (profile_dir, home_dir);\n  get_session_dir (session_dir, profile_dir);\n\n  shared_dir = hcstrdup (shared_folder);\n\n  hc_mkdir (profile_dir, 0700);\n  hc_mkdir (session_dir, 0700);\n\n\n}\nelse\n{\n   profile_dir = install_dir;\n   session_dir = install_dir;\n   shared_dir  = install_dir;\n}\n\n```\nI didn't have time to do extensive testing, but it's working at the moment. \n\n. Ah, you know I didn't even think to try that last night. Maybe I over complicated this. I'll try again later tonight and see if that works. . I'll be able to verify tonight when I get some spare time. Thanks for your patience. I realize I've been bugging you for over a year on this now. . I just confirmed that this works with the install_dir set to /usr/bin.  No code changes necessarily like you said.  I have some more features to add to the bindings, but the PoC works.\nI think this feature request can be closed. \nThanks!!!. My plan is to have a release candidate ready at the end of next week. . What is the use case for user_options_extra? Is it intended to be part of the API?\nhttps://github.com/hashcat/hashcat/blob/1f266fb0f2ecfb4e1b94494f8f9b70acd020faf9/include/types.h#L1428\nI notice you're using it in some of the event functions like here:\nhttps://github.com/hashcat/hashcat/blob/1f266fb0f2ecfb4e1b94494f8f9b70acd020faf9/src/main.c#L212\n. \nStill a work in progress, but my code is up in a development branch so others can contribute if they want.\nhttps://github.com/Rich5/pyHashcat/tree/bindings. Agreed. Lots to do. A few people reached outa and wanted to help so this will allow for PRs and issue submissions. This way you can see the progress as it develops too if you want. Added eventing and libhashcat runs in a separate thread now. You can see how it works here\nhttps://github.com/Rich5/pyHashcat/blob/bindings/pyhashcat/test.py\nA little more to do and I'll release it as 2.0rc1. > Does that mean that there's no support for the native and/or osx target?\nI'll add support to the Make file for native install and do a few tests. This should be an easy addition.  \nAs for osx, I don't have access to a mac to do any testing. I don't think there is any reason why it wouldn't work though, but can't verify myself. \n\nI saw you accidentially added the opencl-headers to the repository. Please remove them. We describe in BUILD.me how to install them.\n\nOops. I'll get those removed. \n\nCan you please rename it to hashcat_api.c\n\nNo problem.\n\nCan you please use the format used describe in the contribution section on here? https://github.com/hashcat/oclHashcat That is like allman-style format etc.\n\nI'll run indent on it to make sure it's formatted correctly. \nShould have most of this done by tonight or tomorrow. \n. Doing some testing. I'll post here when it's ready.\n. Ok. I'm done testing. Checked out good for me on the following systems:\nWin7\nWin8\nDebian 3.16.7-ckt25-2 (2016-04-08) x86_64 GNU/Linux\n. Bah. Ok. The first error might be a result of the example I wrote. hc.status_update() returns 0 because of these checks:\nif (data.devices_status == STATUS_INIT)\n    return 0;\nif (data.devices_status == STATUS_STARTING)\n    return 0;\nif (data.devices_status == STATUS_BYPASS)\n    return 0;\nThe foreground thread seems to get hung because of getchar() I think. I'll have to write a better example. In the mean time if you give the hashcat process a chance to spin up and then try getting the status does it display? \nUPDATE: I also just thought of something. Check these lines starting at 3143 in the example. I bet they aren't pointing to the right example files: \nhttps://github.com/Rich5/oclHashcat/blob/master/src/hashcat_api.c#L3143\nThe second error is a result of the math library not being linked which I don't understand why that's happening. make nativeAPI should compile with this line that links the math library:\n```\nhashcatAPI:       src/hashcat.c src/hashcat_api.c $(NATIVE_OBJS)\n    $(CC) $(CFLAGS_NATIVE)    -DAPI -lm -o $(BINARY_NATIVE) $^ $(LFLAGS_NATIVE) -DCOMPTIME=$(COMPTIME) -DVERSION_TAG=\\\"$(VERSION_TAG)\\\" -DINSTALL_FOLDER=\\\"$(INSTALL_FOLDER)\\\" -DSHARED_FOLDER=\\\"$(SHARED_FOLDER)\\\" -DDOCUMENT_FOLDER=\\\"$(DOCUMENT_FOLDER)\\\"\n```\nI'll have to troubleshoot more on this one because it was working earlier (I'm away from my lab until tomorrow).\nLastly, I agree I think packing into an .so would be ideal. I'm probably going to need some help with that though. I'm not the best Linux dev. If you need to deny this pull that's ok. I'll work on it more in the next few days as I get time.\n. Sounds good. That makes sense. Let me know when you're ready to come back to this after the release.\n. After just briefly reviewing, this looks awesome! I'll be able to dig deeper in the next few days. I think it will be pretty straight forward to adapt the python bindings to this, but I'll know more next week when I get back from travel. Thanks for taking the time to do this.\n. The addition of events is really nice. Is there a way to get all the same status info as pressing \"s\" during a normal run? For example, I've seen people parse out the GPU temp to use as triggers in scripts. Are events intended to be used in this way? I'm my previous PR I was basically taking a snapshot of that type of information and storing for the user in a structure. Is that a feature that should be at this level? Seems like you have a well defined plan here so just let me know if you need me to work on some part or just test by adapting python bindings?\n. Thanks again for taking the time to do this. I'm looking forward to testing it out\n. I'm probably just missing this part, but one more question about accessing the status. It looks like all the information is stored in hashcat_ctx, and I understand that the status_display calculates and displays all the status, but how would that be accessed programmatically through the hashcatlib? Would I access hashcat_ctx directly? Previously, I ended up making a new function that copies the status and updates a structure when called. You can see it here:  https://github.com/Rich5/oclHashcat/blob/master/src/hashcat_api.c#L1897\nhcapi_status_update was basically just a modified version of status_display that calculated and copied values. Is there a better way to do this now?\n. I think developers would at least want to query for the information that is on the status screen. Here's a screenshot of the status info I thought would be useful previously. Maybe not all are necessary though for the first iteration.\n\nIs that helpful?  I can come up with a named list of those items if that's of more use.\n. Wow, thanks @jsteube \nWith this foundation in place I think I'm going to rewrite the python bindings as a native Python extension as opposed to using the ctypes library in Python. Should be pretty straight forward and faster, but I'll let you know as I get into it. My plan is to start this week. I'll post comments here as they come up. \n. @jsteube so I was finally able to make a lot of progress on the Python bindings. If fact, a lot of the work is done for a Python 2.7 extension (the main part of the code is here temporarily if you're interested - https://gist.github.com/Rich5/a97747b91e1066f5d273dc1a6d8fc51b), but the one issue I'm running into is dependencies for libhashcat.so.\nIt looks like, by default, hashcat looks for dependencies relative to it's current working directory. Is there an easy way to specific that is should look somewhere else? For example, we move libhashcat.so to /usr/lib, but it's configured to look for all dependencies in /usr/local/share or something like that?  \nUPDATE: Actually I think I may be able to specify an rpath when I compile the extension. If that works I'll have an branch up on the pyhashcat repo this week.\n. ",
    "halexan": "Wow! oclHashcat API is great function! @Rich5 did a really good jod. I'm looking forward to oclHashcat API being added. Thanks to @Rich5 and @jsteube !\n. Well, I posted that thread...I have the same question too.\nMaybe as roycewilliams said\n\ndictionary attacks cannot take advantage of the parallel nature of the GPU\n\nI think it is because dict attack cannot be calculated parallel in a CPU/GPU. Only after a password being calculated, the next password can be calculated. This leads to a performance drop.\nAnd why rule based attack makes performance better? I think it's because different rules in a rule file can be calculated in parallel...maybe..\nHowever, this condition likely does not happen on hashcat v2.00. I am confused!\nIs there any way to improve performance of dict-mode? I mean calculate different passwords parallel in a CPU/GPU. @jsteube @roycewilliams \n. How about the benchmark of DES-ECB on your own computer? @fransla \nI want to know the performance of GPU's DES-ECB and compare it with FPGA.\n. A german company http://www.sciengines.com/which are doing some cracking with FPGA\nThis is their benchmark http://prntscr.com/bm5net\nMaybe GPU really doesn't good at cracking DES.\nBut I think cracking DES-ECB should be added to hashcat,\n. As we know, DES only uses the MSB 7 bits out of each 8 of the password, so the key length is just 56 bits, the other 8 bits is useless. Hashcat don't need to consider the 8 bits and just set the password \"56 bits hex\" (like \"1A8D938F83920D\").\nUsing char password (like \"S3cr3ts1\") is not good, because different char password may equal to same key (like \"S3cr2ts0\" = \"S3cr3ts1\"), this may cause redundant calculation, so I think it's better to use hex password.\n. Thank you @jsteube ! Hastcat is a really huge software, it has so many functions, it's hard for everyone to master it.\nThis thread (https://hashcat.net/forum/thread-3047.html) does not support reply. Can I ask a question here?\nIf DES-ECB key is in 0x00000000000000-0x00000000000FFF, is the following command right?\nxml\n./hashcat.bin DES-ECB.txt -m 14000 -a 3 ?b?b?b?b?b?b?b?b?b?b?b?b?b?b -s 0 -l 4096\n. ",
    "0x2b3bfa0": "@Xanadrel: I think you should be more polite. I won't rant you (as I suppose that you're mature enough to know that your comment can be hurtful). However I think that you could explain your feelings with normal words.\n@jsteube: Ok, fully understood. Thanks for your patience (and your more polite explaination). However, could I do a fork with SL3 support (completely unlinked -except the author and license- from this project)?\n@both: My only interest in this is because I have a Nokia C5-03 phone with simlock and I don't want to use a external cracking service (DIY habits) ;-)\n. @magnumripper: I refer to licensing troubles. ;-)\n. @epixoip: Ok, I never knew what meant MIT license. I'm a bit lazy. Now I've read the license.txt file. If I have a bit of time I'll fork and implement. What about merging then? Will be accepted?\n. ",
    "dmitry-zakablukov": "@philsmd thank you! It helped me. Benchmark worked without any problem.\nBut I've thought that oclHashcat's feature is \"Low resource utilization, you can still watch movies or play games while cracking\". May be it is true, but in this case I don't understand why TDR stops benchmark's work. I haven't saw any message about driver hang up and/or recover.\n. ",
    "unix-ninja": "Binary distribution should be handled by package management. RPM and DEB will tell the OS where to put the actual files.\nPersonally, I think that the paths for these items should all be constants defined in a header. This way we have two interesting things that can happen:\n- Different paths can be used for different OSes (e.g., Windows vs Linux) without changing the main code\n- Also, if a package maintainer wants to override the paths for their specific distribution, they can make a patch for this one header and the likelihood of further code changes breaking their patch would be much less. This should make the package maintainers' lives easier.\nWe could then also make these paths configurable in the Makefile (this should make the BSD and Solaris folks happy)\n. Another option would be to have hashcat look for a config file on startup. If it finds the config, use the values in there. If it doesn't find the config (or the values aren't present) default to CWD.\n/etc/hashcat/hashcat.cfg on Linux, for example\n. BeetleChunks and noaht8um, do you guys have XCode installed?\n. Wow, OS X 10.9 is pretty old. For security and compatibility reasons, you should definitely not be running that. I would like to suggest upgrading to the latest 10.11 release (it's a free upgrade.)\nI have just tested this on my machine, and with OS X 10.11.5 and XCode 7.3.1 ( + XCode command line utils installed), all I need to do is clone oclhashcat and run make. Everything builds fine on my system.\nDo you have XCode installed? You should probably do so in order to make sure you have the proper headers that OS X expects to be present. Also, there may be some compatibility issues with 10.9, it has definitely not been thoroughly tested, so again I would recommend upgrading to the 10.11 branch.\n. why do you think the time is not tracked? I see it in your output. (Unless I misunderstand what you are looking for.)\n. Sure. If we wanted to remove the custom declaration then I am fine with using APPLE\n. That was supposed to be \n__APPLE__\n. @philsmd I made the changes you requested.\nAs for using the abbreviated form or expanding it, I don't feel strongly either way. People likely to care about this mode are probably going to recognize it, but if you really want to expand it that should be a trivial change.. Right now I list it as TOTP (HMAC-SHA1) to address the specific OTP algorithm. Do you think that covers it?. ok, I will add that and push in a little while.. @jsteube I changed the category in usage.c to \"One-Time Password\", which is what I thought Royce was talking about, to solve the find-ability issue. I didn't touch the name of the algorithm, though. This should actually be the proper way to address it, do you agree?\nI guess you have a point there. I will switch timestamp to u64.\nTOKEN_ATTR_VERIFY_HEX was boilerplate straight from m150. For this algorithm we prob want TOKEN_ATTR_VERIFY_DIGIT since this should be a timestamp. I will swap that.\nThe code in check_hash() was mostly off-loading base32 encoding of the founds to CPU. I didn't want to slow down the kernel with this. The result needs to display encoded, even though the keyspace we are searching is not.. @philsmd so, I struggled with that point myself. By the RFC, the secrets must be base32 encoded (this is the way you will input it to something like pyotp.) It seems weird to do that extra work inside the Hashcat kernel though, which would just needlessly slow down performance when you can just encode it at the end. So this way is faster, but I agree that it's confusing unless you know what's going on. I am writing a blog post to explain this attack, which I hope helps. In the end, I thought having that extra performance was probably worth it.. @jsteube ok, I have more commits coming in soon for some of these things. There are two things I wanted to discuss, though.\n\ndigest[1] = otp_code;\n\nSo, I used index 1 because the SHA1 boilerplate ignores index 0 when actually comparing hashes, and if I want to reuse that boilerplate without writing new code I need to start the values I care about at 1. I don't think it's worth reinventing the wheel for this since the algorithm is based on HMAC-SHA1. I'd like to keep using as much of that existing infrastructure as possible.\n\nplain_ptr = (u8 ) strdup ((const char ) temp_ptr);\n\nThere is no memory leak for this one. The buffer is locally scoped and destroyed at the end of the if block. You can't even use the reference outside of that block because it will cause a compiler error. I don't think there's any real value trying to manually manage the memory here.. @philsmd omg- thanks! that's definitely a time-saver!\nI will get these taken care of in a little while and push a new commit. This help is much appreciated.\n\ud83d\ude42. @philsmd I see. Apparently I misunderstood what strdup() was doing under the hood. In that case, I will amend as jens recommended. Thanks for the clarification!. @jsteube changed as requested. the smaller digest size made a small performance bump to my benches. It's not a whole like, just 50k-100k or so, that's still cool. thanks!. agh! I can't believe I missed that. sorry. Will fix it this morning.. wow- I am not sure how the tab got in there, because I have tab expansion set in vim, but it's fixed now. pushing soon.. I used an explicit cast for this. I think that should be good.. ",
    "jvoisin": "Arg, it's not oclHashcat, but hashcat, sorry.\n. ",
    "0xicl33n": "I just compiled hashcat on a Jetson TK1(Ubuntu 14.04)  as @shellster mentioned running hashcat on.\nIt compiled just fine but..\n[root@turbine[~]$hashcat --opencl-info\nhashcat (v3.10-829-g646a472) starting...\n\nclGetPlatformIDs(): CL_UNKNOWN_ERROR\n\nNo opencl device detected. How can i take a better look to make sure i built things correctly? Are there CFLAGS i should have used?\n. and my assumption is hashcat doesnt use cuda anymore?. ",
    "ghost": "Ported please!!. I added a $75 bounty for this and the AES decrypt routine should be executed on whatever is fastest between AES-NI (CPU) or GPU.\nThere's also a demo page for the library here: https://bitwiseshiftleft.github.io/sjcl/demo/. \n. Ok.\nIs there any possibility to use already implemented kernel as preprocessing commands? to implement custom algo without copy paste existing code?\n. I did this because on the code side, it's easier for one to see this has something to do with the status output, and that it is transforming it into machine readable code.\n. Do you have the intel/gt450m setup?  I am running at late 2013 MBP with kali rolling and do not see this issue.  Assuming you have the same hardware, the only difference is that I'm on 4.0.0 where you are on 4.6.0.\n. Which nvidia driver are you using on Kali?\n. Ok, try removing that and installing the latest driver from NVIDIA.\n. List the output of nvidia-smi -q -a please\n. I meant to tell you that I have tried numerous ways to reproduce this error and have not been able to.\n. Added additional output per #449.  The output probably needs work but does compile cleanly and did display properly in my tests.\n-a 3\n\nSession.Name...: hashcat\nStatus.........: Aborted\nInput.Mode.....: Mask (?1?1?1?1?1?1?1?1) [8]\nCustom.Chars...: -1 ?l?u, -2 ?s?d, -3 (null), -4 (null)\nHash.Target....: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nHash.Type......: MD5\n\n-a 6\n\nSession.Name...: hashcat\nStatus.........: Aborted\nInput.Left.....: File (../dicts/dict)\nInput.Right....: Mask (?1?2) [2]\nCustom.Chars...: -1 ?l?u, -2 ?s?d, -3 (null), -4 (null)\nHash.Target....: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nHash.Type......: MD5\n\n-a 7\n\nSession.Name...: hashcat\nStatus.........: Aborted\nInput.Left.....: Mask (?1?2) [2]\nInput.Right....: File (../dicts/dict)\nCustom.Chars...: -1 ?l?u, -2 ?s?d, -3 (null), -4 (null)\nHash.Target....: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nHash.Type......: MD5\n. Done.\n. Done.\n. If I understand this correctly you are looking for something like:\nSession.Name...: hashcat\nStatus.........: Aborted\nInput.Mode.....: Mask (?1?1?1?1?1?1?1?1) [8]\nCustom.Char..: -1 ?l?u -2 ?s?d\nHash.Target....: aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa\nHash.Type......: MD5\n. This is already output in the log file:\nTOP81ca1880   custom_charset_1    ?l?u\nTOP81ca1880 custom_charset_2    ?s?d\n\nI suppose I could see a use case but to me it seems like clutter in output.\n. I added it with that PR.  Feel free to build and try for yourself until it's merged.\n. It is better that this is done manually or you potentially have a bunch of duplicates being processed.\n. You can already do this using by specifying an output file (--outfile) and an outfile format as plain (--outfile-format 2).\n. I downloaded v3.10\n. I've just tried it and I get the same error.\n. I also get the following output:\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1:       Intel(R) Pentium(R) CPU  N3540  @ 2.16GHz, skipped\nDevice #2: Intel(R) HD Graphics, 343/1374 MB allocatable, 4MCU\n. http://pastebin.com/HTit03Vd\n. @neheb I've already moved the folder and all of it's contents to the root of my C drive and I still get the same error.\n\n@dropdeadfu I typed in hashcat64 -b. I have a PATH environment variable set to: C:\\Program Files\\hashcat\n. A clean install of El Capitan did not solve the issue\n. A clean install of 10.11.5 also did not help. \n. Solved the issue by creating the folder /usr/local/bin\n. I don't seem to be able to upload this, sorry for the inconvenience, here's a link: https://raw.githubusercontent.com/steffen9000/enpass-decryptor/master/Enpassant.py\nThis should be an easy and straight-forward algo to add. Thanks for considering it!\n. Agreed, ignoring PBKDF2-HMAC-SHA256 for stored data is fine. JtR's implementation works fine and finds the plaintext.\nConverted hashes are compatible with hashcat -m12000 once rounds are set...in the second delimited field? How do these need to be parsed so hashcat can intake them?\n. up. Should be good now, libreoffice doing weird stuff with newlines in the cells. Row 17 and row 19 are similar but no warning is thrown for it.  Maybe something with the parser, either way, the file is fine for reference regardless of whether they think its pretty or not.  Fact is, this isn't meant to be viewed online anyway, but grep'd, cat'd, less'd, more'd, (insert viewing method here).. One of the issues faced here is that initiating an attack can take a lot of time.\nUnless  you disable potfile it can take minutes to start a single attack. Not to mention hashes have to be loaded in every time as well as the wordlists.\nAll together running 1000-500000 commands, each taking a LONG time to complete is terrible.\nNot to mention keyspace and load. As a single command might not fully utilize the GPU's you'll end up with a huge decrease in speed for every, single, command.\nHaving it integrated into hashcat greatly reduces this and allows anyone to easily run a rule list against it.. \n15786_1494403569.hccapx.tar.gz\n. dictionary\nfechasdenacimiento.tar.gz\n. same bug in v4.1.1\naries@aries:/opt/hashcat-master$ '/opt/crack-keys/diccionarios/otros/fechasdenacimiento' | '/opt/hashcat-master/hashcat' -a 0 -m 2500 '/opt/crack-keys/handshake/15786_1494403569.hccapx' \nhashcat (v4.1.1) starting...\n\nDevice #1: This hardware has outdated CUDA compute capability (3.5).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #1: WARNING! Kernel exec timeout is not disabled.\n             This may cause \"CL_OUT_OF_RESOURCES\" or related errors.\n             To disable the timeout, see: https://hashcat.net/q/timeoutpatch\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\n\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Thu Mar  1 11:57:24 2018 (10 secs)\nTime.Estimated...: Thu Mar  1 11:57:34 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5909 H/s (10.70ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 32768\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 04/11/1965 -> 08/09/2000\nHWMon.Dev.#1.....: Temp: 54c Fan: 39%\nCracking performance lower than expected?\n\n\nAppend -w 3 to the commandline.\n  This can cause your screen to lag.\n\n\nUpdate your OpenCL runtime / driver the right way:\n  https://hashcat.net/faq/wrongdriver\n\n\nCreate more work items to make use of your parallelization power:\n  https://hashcat.net/faq/morework\n\n\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Thu Mar  1 11:57:24 2018 (20 secs)\nTime.Estimated...: Thu Mar  1 11:57:44 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5591 H/s (10.68ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 98304\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 56c Fan: 40%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:12_08_1934\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Thu Mar  1 11:57:24 2018 (25 secs)\nTime.Estimated...: Thu Mar  1 11:57:49 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5553 H/s (10.68ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 131072\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969 \nHWMon.Dev.#1.....: Temp: 58c Fan: 41%\nStarted: Thu Mar  1 11:57:03 2018\nStopped: Thu Mar  1 11:57:49 2018\n.  clinfo \nNumber of platforms                               1\n  Platform Name                                   NVIDIA CUDA\n  Platform Vendor                                 NVIDIA Corporation\n  Platform Version                                OpenCL 1.2 CUDA 9.1.84\n  Platform Profile                                FULL_PROFILE\n  Platform Extensions                             cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts cl_nv_create_buffer\n  Platform Extensions function suffix             NV\nPlatform Name                                   NVIDIA CUDA\nNumber of devices                                 1\n  Device Name                                     GeForce GT 710\n  Device Vendor                                   NVIDIA Corporation\n  Device Vendor ID                                0x10de\n  Device Version                                  OpenCL 1.2 CUDA\n  Driver Version                                  390.25\n  Device OpenCL C Version                         OpenCL C 1.2 \n  Device Type                                     GPU\n  Device Profile                                  FULL_PROFILE\n  Device Topology (NV)                            PCI-E, 01:00.0\n  Max compute units                               1\n  Max clock frequency                             954MHz\n  Compute Capability (NV)                         3.5\n  Device Partition                                (core)\n    Max number of sub-devices                     1\n    Supported partition types                     None\n  Max work item dimensions                        3\n  Max work item sizes                             1024x1024x64\n  Max work group size                             1024\n  Preferred work group size multiple              32\n  Warp size (NV)                                  32\n  Preferred / native vector sizes               \n    char                                                 1 / 1     \n    short                                                1 / 1     \n    int                                                  1 / 1     \n    long                                                 1 / 1     \n    half                                                 0 / 0        (n/a)\n    float                                                1 / 1     \n    double                                               1 / 1        (cl_khr_fp64)\n  Half-precision Floating-point support           (n/a)\n  Single-precision Floating-point support         (core)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  Yes\n  Double-precision Floating-point support         (cl_khr_fp64)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Address bits                                    32, Little-Endian\n  Global memory size                              2098921472 (1.955GiB)\n  Error Correction support                        No\n  Max memory allocation                           524730368 (500.4MiB)\n  Unified memory for Host and Device              No\n  Integrated memory (NV)                          No\n  Minimum alignment for any data type             128 bytes\n  Alignment of base address                       4096 bits (512 bytes)\n  Global Memory cache type                        Read/Write\n  Global Memory cache size                        \n  Global Memory cache line                        128 bytes\n  Image support                                   Yes\n    Max number of samplers per kernel             32\n    Max size for 1D images from buffer            134217728 pixels\n    Max 1D or 2D image array size                 2048 images\n    Max 2D image size                             16384x16384 pixels\n    Max 3D image size                             4096x4096x4096 pixels\n    Max number of read image args                 256\n    Max number of write image args                16\n  Local memory type                               Local\n  Local memory size                               49152 (48KiB)\n  Registers per block (NV)                        65536\n  Max constant buffer size                        65536 (64KiB)\n  Max number of constant args                     9\n  Max size of kernel argument                     4352 (4.25KiB)\n  Queue properties                              \n    Out-of-order execution                        Yes\n    Profiling                                     Yes\n  Prefer user sync for interop                    No\n  Profiling timer resolution                      1000ns\n  Execution capabilities                        \n    Run OpenCL kernels                            Yes\n    Run native kernels                            No\n    Kernel execution timeout (NV)                 Yes\n  Concurrent copy and kernel execution (NV)       Yes\n    Number of async copy engines                  1\n  printf() buffer size                            1048576 (1024KiB)\n  Built-in kernels                              \n  Device Available                                Yes\n  Compiler Available                              Yes\n  Linker Available                                Yes\n  Device Extensions                               cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts cl_nv_create_buffer\nNULL platform behavior\n  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  NVIDIA CUDA\n  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   Success [NV]\n  clCreateContext(NULL, ...) [default]            Success [NV]\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  No platform\nICD loader properties\n  ICD loader Name                                 OpenCL ICD Loader\n  ICD loader Vendor                               OCL Icd free software\n  ICD loader Version                              2.2.8\n  ICD loader Profile                              OpenCL 1.2\n    NOTE:   your OpenCL library declares to support OpenCL 1.2,\n        but it seems to support up to OpenCL 2.1 too.\n. \nvodafone28C6_2(00:25:69:86:B9:33)-02.cap.tar.gz\n. potfile version 4.1.0 & 4.1.1\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:01011930\npotfile version 3.5.0/3.6.0/4.0.0\ndc15d27e43bf34fca77d3665d8182121: 00256986b933: 88a73c8ec0f5: vodafone28C6_2: 14 04 1977\ncould it be for the nvidia driver? although if it were for the driver it would not work correctly in the previous versions to these last two, the 4.1.0 / 4.1.1\nthe installed nvidia driver is 390.25\nI'm going to change it to the previous one, 387.34 to check that it's not driver failure. aries@aries:~$ '/opt/crack-keys/diccionarios/otros/fechasdenacimiento' | '/opt/crack-keys/hashcat/hashcat32.bin' -a 0 -m 2500 '/opt/crack-keys/handshake/vodafone28C6_2(00:25:69:86:B9:33)-02.hccapx' -w 4 --force --status --potfile-disable\nhashcat (v4.0.1) starting...\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nPassword length minimum: 8\nPassword length maximum: 63\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled.\nStarting attack in stdin mode...\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:22:17 2018 (1 sec)\nTime.Estimated...: Sat Mar  3 22:22:18 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:        0 H/s (0.00ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: [Copying]\nHWMon.Dev.#1.....: Temp: 52c Fan: 40%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:22:17 2018 (11 secs)\nTime.Estimated...: Sat Mar  3 22:22:28 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     7624 H/s (267.61ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 01011930 -> 11081976\nHWMon.Dev.#1.....: Temp: 58c Fan: 41%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:22:17 2018 (21 secs)\nTime.Estimated...: Sat Mar  3 22:22:38 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     6955 H/s (264.02ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 90112\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 11/08/1976 -> 22/03/2022\nHWMon.Dev.#1.....: Temp: 60c Fan: 43%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:22:17 2018 (27 secs)\nTime.Estimated...: Sat Mar  3 22:22:44 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     7009 H/s (262.20ms)\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 180224\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 11/08/1976 -> 22/03/2022\nHWMon.Dev.#1.....: Temp: 60c Fan: 42%\nStarted: Sat Mar  3 22:21:37 2018\nStopped: Sat Mar  3 22:22:45 2018\naries@aries:~$ '/opt/crack-keys/diccionarios/otros/fechasdenacimiento' | '/opt/hashcat-master/hashcat' -a 0 -m 2500 '/opt/crack-keys/handshake/vodafone28C6_2(00:25:69:86:B9:33)-02.hccapx' -w 4 --force --status --potfile-disable\nhashcat (v4.1.1) starting...\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:23:58 2018 (8 secs)\nTime.Estimated...: Sat Mar  3 22:24:06 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     7486 H/s (271.25ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 57c Fan: 41%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:23:58 2018 (18 secs)\nTime.Estimated...: Sat Mar  3 22:24:16 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     7526 H/s (271.22ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 60c Fan: 41%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:01011930\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:23:58 2018 (19 secs)\nTime.Estimated...: Sat Mar  3 22:24:17 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     7479 H/s (271.20ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 131072\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 59c Fan: 42%\nStarted: Sat Mar  3 22:23:38 2018\nStopped: Sat Mar  3 22:24:18 2018\naries@aries:~$ \nno matter the version of the nvidia driver does the same in the last 2 versions. do it as I do if I do the normal command with .txt also happens the same, it remains stopped at the time of writing the password at the exit of the range in the first part.\nCandidates. # 1 ....: 01011930 -> 16_06_1969\ndc15d27e43bf34fca77d3665d8182121: 00256986b933: 88a73c8ec0f5: vodafone28C6_2: 01011930. \nfechasdenacimiento.txt.tar.gz\n. aries@aries:~$ '/opt/hashcat-master/hashcat' -m 2500 '/opt/crack-keys/handshake/vodafone28C6_2(00:25:69:86:B9:33)-02.hccapx' -w 4 --force --status --potfile-disable /opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt\nhashcat (v4.1.1) starting...\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nDictionary cache built:\n Filename..: /opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt\n Passwords.: 526008\n Bytes.....: 5362191\n Keyspace..: 526008\n* Runtime...: 0 secs\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => s\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:55:21 2018 (5 secs)\nTime.Estimated...: Sat Mar  3 22:56:36 2018 (1 min, 10 secs)\nGuess.Base.......: File (/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:     7459 H/s (271.22ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0/526008 (0.00%)\nRejected.........: 0/0 (0.00%)\nRestore.Point....: 0/526008 (0.00%)\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 53c Fan: 39%\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => \nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:55:21 2018 (9 secs)\nTime.Estimated...: Sat Mar  3 22:56:40 2018 (1 min, 10 secs)\nGuess.Base.......: File (/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:     7491 H/s (271.50ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 0/526008 (0.00%)\nRejected.........: 0/0 (0.00%)\nRestore.Point....: 0/526008 (0.00%)\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 55c Fan: 40%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:01011930\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 22:55:21 2018 (18 secs)\nTime.Estimated...: Sat Mar  3 22:55:39 2018 (0 secs)\nGuess.Base.......: File (/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:     7463 H/s (271.72ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 131072/526008 (24.92%)\nRejected.........: 0/131072 (0.00%)\nRestore.Point....: 0/526008 (0.00%)\nCandidates.#1....: 01011930 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 57c Fan: 41%\nStarted: Sat Mar  3 22:55:13 2018\nStopped: Sat Mar  3 22:55:41 2018\n. Well, it's strange. but it's what happens to me in the last two versions, whereas in none previous to 4.1.0 / 4.1.1, that does not happen to me. reproducing atom commands\naries@aries:/opt/hashcat-master$ echo 12_08_1934 | ./hashcat -m 2500 /opt/hashcat-master/15786_1494403569.hccapx\nhashcat (v4.1.1) starting...\n\nDevice #1: This hardware has outdated CUDA compute capability (3.5).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\n\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 00:50:42 2018 (0 secs)\nTime.Estimated...: Sun Mar  4 00:50:42 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:        9 H/s (0.17ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 1\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 12_08_1934\nHWMon.Dev.#1.....: Temp: 46c Fan: 34%\nStarted: Sun Mar  4 00:50:33 2018\nStopped: Sun Mar  4 00:50:42 2018\n\naries@aries:/opt/hashcat-master$ echo 14 04 1977 | ./hashcat -m 2500 /opt/hashcat-master/15786_1494403569.hccapx\nhashcat (v4.1.1) starting...\n\nDevice #1: This hardware has outdated CUDA compute capability (3.5).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\n\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 00:55:00 2018 (0 secs)\nTime.Estimated...: Sun Mar  4 00:55:00 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:        9 H/s (0.17ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 1\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 14 04 1977 -> 14 04 1977\nHWMon.Dev.#1.....: Temp: 47c Fan: 35%\nStarted: Sun Mar  4 00:54:53 2018\nStopped: Sun Mar  4 00:55:01 2018\n. VERSION 4.0.1 \"OK\"\naries@aries:/opt/crack-keys/hashcat$ '/opt/crack-keys/hashcat/hashcat32.bin' -V\nv4.0.1\naries@aries:/opt/crack-keys/hashcat$ cat '/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt' | ./hashcat32.bin -m 2500 '/opt/crack-keys/handshake/15786_1494403569.hccapx' --quiet \nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:08:26 2018 (10 secs)\nTime.Estimated...: Sun Mar  4 07:08:36 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5616 H/s (10.86ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 53248\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 07 04 1961 -> 07-07-1951\nHWMon.Dev.#1.....: Temp: 52c Fan: 38%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:08:26 2018 (20 secs)\nTime.Estimated...: Sun Mar  4 07:08:46 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5608 H/s (10.85ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 110592\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 14 01 1972 -> 14-04-1962\nHWMon.Dev.#1.....: Temp: 54c Fan: 39%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\n\nVERSION 4.1.0 \"failed\"\naries@aries:/opt/crack-keys/hashcat-4.1.0$ cat '/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt' | ./hashcat -m 2500 '/opt/crack-keys/handshake/15786_1494403569.hccapx' --quiet \nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:13:16 2018 (9 secs)\nTime.Estimated...: Sun Mar  4 07:13:25 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5903 H/s (10.68ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 32768\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 04/11/1965 -> 08/09/2000\nHWMon.Dev.#1.....: Temp: 54c Fan: 39%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:13:16 2018 (19 secs)\nTime.Estimated...: Sun Mar  4 07:13:35 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5851 H/s (10.69ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 98304\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 57c Fan: 40%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:12_08_1934\n\nVERSION 4.1.1 \"failed\"\naries@aries:/opt/hashcat-master$ cat '/opt/crack-keys/diccionarios/otros/fechasdenacimiento.txt' | ./hashcat -m 2500 '/opt/crack-keys/handshake/15786_1494403569.hccapx' --quiet \nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:20:58 2018 (10 secs)\nTime.Estimated...: Sun Mar  4 07:21:08 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5900 H/s (10.70ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 32768\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 04/11/1965 -> 08/09/2000\nHWMon.Dev.#1.....: Temp: 54c Fan: 40%\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sun Mar  4 07:20:58 2018 (20 secs)\nTime.Estimated...: Sun Mar  4 07:21:18 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5848 H/s (10.71ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 98304\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 57c Fan: 40%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:12_08_1934\nIt is very rare that this does not work correctly.\nI will return to version 3.6.0 if it does not work correctly.\nif it's any good I put data from uname\naries@aries:/opt/hashcat-master$ uname -a\nLinux aries 4.8.0-58-generic #63~16.04.1-Ubuntu SMP Mon Jun 26 17:59:49 UTC 2017 i686 i686 i686 GNU/Linux. been testing with the opencl file m02500.cl of version 3.6.0, 4.0.1 in 4.1.0 and does the same. so I think the bug could be in the code of the hashcat.c file. wifislax ~ # /root/Desktop/fechasdenacimiento | /root/Desktop/hashcat-4.1.0/hashcat32.bin -m 2500 --force /root/Desktop/659_1520470752.hccapx -w 3                         \nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Oland, 518/899 MB allocatable, 5MCU\nDevice #2: Intel(R) Core(TM)2 CPU          6600  @ 2.40GHz, skipped.\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nInitializing device kernels and memory...Violaci\u00f3n de \nsegmento. aries@aries:~$ git clone https://github.com/hashcat/hashcat.git\nClonar en \u00abhashcat\u00bb...\nremote: Counting objects: 35369, done.\nremote: Total 35369 (delta 0), reused 0 (delta 0), pack-reused 35368\nReceiving objects: 100% (35369/35369), 27.85 MiB | 441.00 KiB/s, done.\nResolving deltas: 100% (29473/29473), done.\nComprobando la conectividad\u2026 hecho.\naries@aries:~/hashcat$ git submodule update --init\nSubmodule 'deps/OpenCL-Headers/CL' (https://github.com/KhronosGroup/OpenCL-Headers.git) registered for path 'deps/OpenCL-Headers/CL'\nClonar en \u00abdeps/OpenCL-Headers/CL\u00bb...\nremote: Counting objects: 552, done.\nremote: Total 552 (delta 0), reused 0 (delta 0), pack-reused 552\nReceiving objects: 100% (552/552), 297.40 KiB | 301.00 KiB/s, done.\nResolving deltas: 100% (343/343), done.\nComprobando la conectividad\u2026 hecho.\nRuta de subm\u00f3dulo \u00abdeps/OpenCL-Headers/CL\u00bb: se extrajo \u00abbf0f43b76f4556c3d5717f8ba8a01216b27f4af7\u00bb\naries@aries:~/hashcat$ make\naries@aries:~/hashcat$ '/home/aries/hashcat/hashcat' -V\nv4.1.0-7-gf6cfcbb\naries@aries:~/hashcat$ '/opt/crack-keys/diccionarios/otros/fechasdenacimiento' | '/home/aries/hashcat/hashcat' -m 2500 '/opt/crack-keys/handshake/15786_1494403569.hccapx'\nhashcat (v4.1.0-7-gf6cfcbb) starting...\n\nDevice #1: This hardware has outdated CUDA compute capability (3.5).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\n\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GT 710, 500/2001 MB allocatable, 1MCU\n\nHashes: 2 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger set to 90c\nStarting attack in stdin mode...\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Mon Mar 12 11:57:34 2018 (9 secs)\nTime.Estimated...: Mon Mar 12 11:57:43 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5875 H/s (10.71ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 32768\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 04/11/1965 -> 08/09/2000\nHWMon.Dev.#1.....: Temp: 50c Fan: 37%\nCracking performance lower than expected?\n\n\nAppend -w 3 to the commandline.\n  This can cause your screen to lag.\n\n\nUpdate your OpenCL runtime / driver the right way:\n  https://hashcat.net/faq/wrongdriver\n\n\nCreate more work items to make use of your parallelization power:\n  https://hashcat.net/faq/morework\n\n\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Mon Mar 12 11:57:34 2018 (19 secs)\nTime.Estimated...: Mon Mar 12 11:57:53 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5590 H/s (10.67ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 98304\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 52c Fan: 38%\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:12_08_1934\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Mon Mar 12 11:57:34 2018 (24 secs)\nTime.Estimated...: Mon Mar 12 11:57:58 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:     5551 H/s (10.68ms) @ Accel:32 Loops:8 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 131072\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: 12_08_1934 -> 16_06_1969\nHWMon.Dev.#1.....: Temp: 54c Fan: 40%\nStarted: Mon Mar 12 11:57:11 2018\nStopped: Mon Mar 12 11:57:58 2018\naries@aries:~/hashcat$ \n. ",
    "sibero80": "@neheb , could you share any insights on the process? would love to compile it for ARM64 (LG G5). ",
    "d2-d2": "Thanks philsmd, so let me explain that a bit.\nSo this hash is used by PunBB forum, right? And as far as I can tell version 1.3.x version of that CMS is using following functions to produce hashes:\n$salt = random_key(12);\n$form_password_hash = forum_hash($form_password, $salt);\nThese two functions are as follow:\n```\nfunction random_key($len, $readable = false, $hash = false)\n{\n        $key = '';\n    $return = ($hook = get_hook('fn_random_key_start')) ? eval($hook) : null;\n    if ($return != null)\n            return $return;\n\n    if ($hash)\n            $key = substr(sha1(uniqid(rand(), true)), 0, $len);\n    else if ($readable)\n    {\n            $chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n\n            for ($i = 0; $i < $len; ++$i)\n                    $key .= substr($chars, (mt_rand() % strlen($chars)), 1);\n    }\n    else\n            for ($i = 0; $i < $len; ++$i)\n                    $key .= chr(mt_rand(33, 126));\n\n    ($hook = get_hook('fn_random_key_end')) ? eval($hook) : null;\n\n    return $key;\n\n}\n```\nand\n```\nfunction forum_hash($str, $salt)\n{\n        $return = ($hook = get_hook('fn_forum_hash_start')) ? eval($hook) : null;\n        if ($return != null)\n                return $return;\n    return sha1($salt.sha1($str));\n\n}\n```\nSo I think that's it for PunBB. Fixed salt length (12 characters) and sha1 function. But to be honest, if you could make two additional switches, one for PunBB and second one for any salt length that'd be great.\nDo you think these options are possible?\n. @philsmd that's the thing, instead of chaining different commands in hashcat I'd like to use one consistent that will allow me to write cracked passwords and shorten the left list easily. Then, having multibyte delimiter in output file, I can prepare whatever outputs I like without loosing any characters etc.\n. > I think the multi-byte delimiter could still be a good idea in some very special cases (i.e. if the hash list already has some weird delimiters and the user doesn't want or isn't able to batch modify each line within the file)\nExactly. Such delimiter would clearly tell you about number of fields and therefore ease further scripting.\n. @jsteube what if separator is also in salt?. OK thanks.. Before running hashcat, set your umask to: umask 027.\n. @jsteube I think it's the best and simplest solution. Hashcat (or user) will set umask prior running anything, thanks to that every file will be properly secured. Otherwise, if you decide to do it in per-file manner, there is a chance that one or another file will not be covered and another 'issue' will be raised.\n. Nevermind, it was a local issue (parent directory was created with wrong permissions). Sorry for that ;-). Hi again. I'm sorry to report this again but it turned out that this issue is still present. Some more info:\n- problem tested on windows7 64bit and windows10 64bit (different boxes)\n- whenever hashcat is starting, every file it touches (like potfile, stats, log outfile of cracked hashes) it is assigning +r flag to it\n- issue tested by another user (thanks Chick3nman) and confirmed\nSteps to reproduce:\n- download latest /beta, like https://hashcat.net/beta/hashcat-3.30%2b84.7z\n- uncompress with 7z x ..\n- run example.cmd and see what's happening on console. Last commit fixed this issue. Thanks!. Hi philsmd, actually I don't have any names of webapps that are using this scheme. To be honest, there are other variations of substr() function but the one listed here is most commonly used. I base that statement on what I've seen on forums so far (insidepro and hashkiller to say the least) and lists are very large (hundreds thousands of hashes). There is also very well known list of hashes mentioned by KoreLogic (https://www.korelogic.com/InfoSecSouthwest2012_Ripe_Hashes.html). There are many substr() in there too.. Thanks @DoZ10 it works :-) There are some trailing '0' visible in output but that's fine, I can delete them easily.\n46aef2f12cde0f185843a837a307669700000000:cvugvuhvbuh. @jsteube \n\nPlease do a suggestion on the character to use\n\nSince 's' is taken, how about 'a' (for alter)?. Hey, it looks as the same issue I reported and you linked to it, however, I tested latest official release and following two new versions from /beta/ on my Win10 x64 box.\nhashcat-3.40+38.7z                                 11-Mar-2017 08:17             2680799\nhashcat-3.40+43.7z                                 12-Mar-2017 10:19             2674053\nEverytime I tested I used 7z x archive.7z to extract files and then executed example0.cmd script to see what's going on. In my case, everything worked without issues.\nEDIT: I also checked permissions of docs and charsets folders before and after executing example0.cmd - I see read-only permissions. Even though, everything seems to be running fine.. ",
    "roo7break": "Awesome. thanks to dpkg -l | egrep -i 'nvidia|fglrx|opencl' i was able to locate ocl-icd-libopencl1 as the culprit. Purged it, and oclHashcat is working beautifully.\nThanks for your help.\n. Thanks for this. Happy to close. \nNikhil Sreekumar\n\nOn 22 Jul 2016, at 10:24, philsmd notifications@github.com wrote:\nI think this should answer the question about how the output can be formatted (and include the username/email etc):\nhttps://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_can_i_show_previously_cracked_passwords_and_output_them_in_a_specific_format_eg_emailpassword\nThis is a question listed within the \"frequently asked question\" wiki for good reason, i.e. because it was answered already thousands of times within the forum/irc/pms etc.\nMaybe this kind of questions fits better on hashcat's forum, instead of a github issue, dunno.\n(and you need to use --show, because some users prefer not to have the username within the \"normal\" output even if --username was specified, the only wanted to get rid - quickly load - the hash lists)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Hi,\n\nThe simplest way to reproduce is:\n- start with potfile-path, session, m 1000, a0, and a word list. \n- once word list is exhausted, add a rule to above command, -r toggle4.rule. \nJust before the \"Cache-hit dictionary stats\" comes up an info message is printed on screen saying \"Removed X hashes found in pot file\". \nThanks and Regards\nNikhil Sreekumar\n\nOn 22 Jul 2016, at 10:29, philsmd notifications@github.com wrote:\nThere is no such concept implemented within hashcat such that \"hashes are remove from potfile\".\nThe hashes always get appended to the potfile (it won't get overridden, delteted etc)\nCan you provide a full example such that it is easier to understand how to reproduce this and what you mean in detail. A minimal step by step example would be perfect, including the content of the potfile after each cracking step.\nBTW: there is also the (new) --potfile-path parameter that allows you to specify a very specific potfile (if you have many .pot files, the default one is \"hashcat.pot\").\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "kittinan": "i have same issue like @roo7break  after remove ocl-icd-libopencl1:amd64, oclHashcat work perfectly.\nsudo apt-get purge ocl-icd-libopencl1:amd64\n. ",
    "MilzoCSP": "I also have this problem after i installed wine.\nocl-icd-libopencl:amd64 is installed along with the wine package so i cannot used wine if i remove this library.\nany workaround?\n. Hi\nIt was 3am so that's my excuse for the miscount :-)\nI've done what you suggested and scrubbed the hashcat dir and made a fresh build and yeah it has solved my issue, HC can now crack all 30.  I should have done that before made a report! oh well.\nI haven't been messing around with anything within the hashcat dir so goodness knows what happened.\nThanks for your time thought Atom.\n. ",
    "matrix": "Hi, the \"Word Expansion / XOR groups\" optimization has been made by me 3 years ago.\nWhat @Merenon found is well known but it was not applied for problems related to the performance. As @philsmd say, please do some benchmarks and post the results here.\n. Hi @yhfudev, check it \nhttps://github.com/gm4tr1x/hashcat/tree/autotools\n. @yhfudev yes, what you see it's only the \"initial commit\".\nFirst I'd like to see if that work also on Windows, if you have time to test it ... you are welcome ;)\n. Beta is out, please test it ;)\nhttps://hashcat.net/beta/oclHashcat-2.10b2-osx.7z\n. Thanks @lloeki, seems that works.\n. Yes, we can\nOn Sunday, April 3, 2016, Jens Steube notifications@github.com wrote:\n\n@gm4tr1x https://github.com/gm4tr1x can we close the issue?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/63#issuecomment-204920349\n. @rhertzog @jsteube I found a way for do that (needed also for osx support).\nI'll show you shortly.\n. @philsmd, yes but we need also \"digest_buf_c[34]\"\nBye ;)\n. Thanks bro ;)\n. Thanks for the test :)\n. Most warning reports from GPU code will be resolved soon.\n. In my previous patch i removed this option for builds without HAVE_HWMON,\nwith that i re-enable (test.sh use this option by default).\n. You can find the ifdef here for example\nhttps://github.com/hashcat/oclHashcat/blob/master/src/oclHashcat.c#L5634\n. For now OSX don't use hwmon but in near future can so i don't understand what's your goal.\nMy is find a way to support all options, also for OSX :)\n. For now hwmon for OSX is disabled,\nalso a lot of algo for now are disabled on OSX due to uncommited change to kernel code.\nDo you want remove all code related because today is not ready/supported ?\n. The \"unknown parameter\" is the key, also because OSX support is under development and will be released if finally work else not.\nFor me is the same, tell me if re-enable --gpu-temp-disable globally or push another mod in test.sh\n\n@philsmd, i don't see any break \n. @philsmd when I add HAVE_HWMON i to for osx, not for fix the issue.\nI think you don't see what do in the code, before this PR 156 --gpu-temp-disable for OSX is disabled,\ni write in the comment \"Re-enable\" for that. If the initial commit for oclHashcat.c is correct why you write a lot of comment about that?\n\"The correct fix would check for the --gpu-temp-disable switch in the --help output for each platform (linux/windows/osx)\"\nThe correct fix is the fix I do before \"Keep disable --gpu-temp-disable on osx in oclHashcat.c\", the same that you want :)\n. Now I remove the last patch, tell me what is wrong now\n. I re-check the patch, if you see in master --gpu-temp-disable is not present if HAVE_HWMON is not defined. With that patch we can restore the parameter.\nOSX hwmon support is also under development ;)\n. Trap 6\n. @philsmd, if you want some details send me a mail or write me in private dev channel, as all the other team member do.\nBye.\n. @magnumripper if you want same details tell me.\nWe prefer speak in private when is possible (tell @jsteube, @epixoip, @Xanadrel, @dropdeadfu).\nBut if you are curious the response is around the getcwd() function usage.\n@philsmd, free to change back cwd[1024] to cwd[256].\nBetter than tell me some details no?\nIf I found a bug I usually proceed with the fix, not with 3000 comments on github.\nThats all and sorry for the \"evil commit\" ...\n. @magnumripper if I found something bad in @jsteube commits or something I like write @jsteube in private and talk with him about what I found.\nI'm coding with @jsteube for years without any public discussion and the quality of our code now is visible to all. \nIt's sufficient as explanation ?\n. Check here\nhttp://pastebin.com/pZNagJ1P\nOn Mon, Jan 25, 2016 at 4:04 PM, philsmd notifications@github.com wrote:\n\nIt doesn't look like it works for me:\nstrace ./oclHashcat --keyspace -a 3 ?a?a?a?a?a?a?a?a 2>&1 | egrep\n'libamd|libOpen'\nAs far as I understood, there should be no requirement for loading those\n(and maybe other) libs when running with --keypace option. Your fix doesn't\nchange this.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/pull/162#issuecomment-174535158.\n. You can't never build without OpenCL library but now you can use --keyspace switch without have a compatible hardware.\nI think is the max we can do without write another standalone tool for calculate only the keyspace.\n. I read that in original issue description:\n\n\"I would like to propose that when using [the] `keyspace' flag, oclHashcat should simply calculate & print the keyspace, then exit. No OpenCL checks or device enumeration should be performed, as OpenCL runtime & devices are not required for this functionality.\"\nIf you don't like that talk also with others team member about closing this pull request and also issue 84.\n. Very tedious but i like @jsteube idea.\nWork in progress\n. @jsteube look this patch ;)\n. i love @jsteube comments !\n. @thesle3p can you recheck if the dir name now is correct?\nThank you\n. It's not for change __local to something else, but exactly the inverse.\nThere's another way but require true code changes, because redefine only \"__local\" in include/kernel_vendor.h (like this example)\n```\nifdef IS_APPLE\ndefine __local\ndefine IS_GENERIC\nendif\n```\nis sufficient for compile the code but not for cracking password, because it not found\n$ ./tools/test.sh -o osx -m 6900 -t all -a all\n[ test_1454064633 ] > Init test for hash type 6900.\n[ test_1454064633 ] [ Type 6900, Attack 0, Mode single ] > Error : 31/31 not found, 0/31 not matched, 0/31 timeout\n[ test_1454064633 ] [ Type 6900, Attack 0, Mode multi  ] > Error : 1/1 not found, 0/1 not matched, 0/1 timeout\n[ test_1454064633 ] [ Type 6900, Attack 1, Mode single ] > Error : 30/30 not found, 0/30 not matched, 0/30 timeout\n[ test_1454064633 ] [ Type 6900, Attack 1, Mode multi  ] > Error : 1/1 not found, 0/1 not matched, 0/1 timeout\n[ test_1454064633 ] [ Type 6900, Attack 3, Mode single ] > Error : 7/8 not found, 0/8 not matched, 1/8 timeout\n[ test_1454064633 ] [ Type 6900, Attack 3, Mode multi  ] > Warning : 0/1 not found, 0/1 not matched, 1/1 timeout\n[ test_1454064633 ] [ Type 6900, Attack 6, Mode single ] > Error : 7/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454064633 ] [ Type 6900, Attack 6, Mode multi  ] > Error : 7/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454064633 ] [ Type 6900, Attack 7, Mode single ] > Error : 7/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454064633 ] [ Type 6900, Attack 7, Mode multi  ] > Error : 7/7 not found, 0/7 not matched, 0/7 timeout\n. @jsteube, got it with very little mods :)\n$ ./tools/test.sh -o osx -m 6900 -t all -a all\n[ test_1454072859 ] > Init test for hash type 6900.\n[ test_1454072859 ] [ Type 6900, Attack 0, Mode single ] > OK : 0/31 not found, 0/31 not matched, 0/31 timeout\n[ test_1454072859 ] [ Type 6900, Attack 0, Mode multi  ] > OK : 0/1 not found, 0/1 not matched, 0/1 timeout\n[ test_1454072859 ] [ Type 6900, Attack 1, Mode single ] > OK : 0/30 not found, 0/30 not matched, 0/30 timeout\n[ test_1454072859 ] [ Type 6900, Attack 1, Mode multi  ] > OK : 0/1 not found, 0/1 not matched, 0/1 timeout\n[ test_1454072859 ] [ Type 6900, Attack 3, Mode single ] > OK : 0/8 not found, 0/8 not matched, 0/8 timeout\n[ test_1454072859 ] [ Type 6900, Attack 3, Mode multi  ] > OK : 0/1 not found, 0/1 not matched, 0/1 timeout\n[ test_1454072859 ] [ Type 6900, Attack 6, Mode single ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454072859 ] [ Type 6900, Attack 6, Mode multi  ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454072859 ] [ Type 6900, Attack 7, Mode single ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1454072859 ] [ Type 6900, Attack 7, Mode multi  ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout\n. I've already checked, only 3000, 1500 and 10700 have some issue (trap 6).\n. @magnumripper probably HD4000 is not handled like Iris in oclHashcat now.\nCan you post the output ?\n. Try to decrease gpu accel:\n./oclHashcat.app -d2 -b --benchmark-mode 0 -m 5000 -u 16 -n 16\n. I tuned the benchmark-mode 1 for Iris card.\nHD Graphics 4000 is oldest :)\nYou can also try increasing from 16 to 64 if you want find the limit for your card.\n. @Fist0urs , please post oclHashcat output\n. @Fist0urs , yes please. I'm curious :)\n. try before\n-b -m 900 --opencl-device-type 1,2 -d 2\nand then \n-b -m 900 --benchmark-mode 0 -u 16 -n 1 --opencl-device-type 1,2 -d 1\nIf is possible, post the result here.\nThank you :)\n. after 8 or 17 seconds end.\nI don't understand why not on your system.\n. closed by PR #196 \n. :8ball: \n. Because OpenCL runtime on OSX is buggy. I will remove when i found a valid\nalternative.\nThank you,\nmatrix\nOn Feb 6, 2016 11:18, \"magnum\" notifications@github.com wrote:\n\nI don't quite understand all these OSX ifdefs. Why are we doing anything\nspecial for OSX in this regard at all? It should be all about the target\ndevice and not about the OS: A Linux box might have a HD4000 and (at least\ntheoretically) an OSX box might have a Titan X. Am I overlooking something\nobvious?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/pull/204#issuecomment-180731442.\n. @magnumripper, great news :+1: \n\nThank you for testing\n. All the clinfo output show 4294967295 as vendor id for Apple cpu, like here\n. @magnumripper everything is possible, look the reference link and propose a change :)\nBye,\nmatrix\n. @magnumripper from your link:\n\nOpenCL devices are required to correctly track time across changes in device frequency and power states. The CL_DEVICE_PROFILING_TIMER_RESOLUTION specifies the resolution of the timer i.e. the number of nanoseconds elapsed before the timer is incremented.\n. You're probably right, but what is the correct usage of CL_DEVICE_PROFILING_TIMER_RESOLUTION in profiling?\n. Now I agree :)\nFor the current usage it's not useful.\nMake happy @jsteube and do a new PR when you have time please :)\n. Why sad ? :)\nI'm happy, I just learned something new, one in \"OpenCL\" and the revert function of github, first time use :)\n\nTy,\nmatrix\n. @magnumripper @averagesecurityguy the issue is related to device 2, well known HD Graphics 4000 (old gpu device).\nIf @jsteube hint don't work you can temporarily skip by add \"--opencl-device-types 1,2 -d1,3\" to your cmdline.\nThe device name will be included without problem in the error output.\n. @jsteube @philsmd try change back the value to 256 but I think I changed something else related to restore. Tell me if work.\n. Thanks to you bros ;)\nOn Sunday, April 3, 2016, Jens Steube notifications@github.com wrote:\n\nOK, change reverted. Thanks!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/248#issuecomment-204963670\n. Hi @lalaithion,\nprobably the problem it's the device 3.\nTry with -d 2 or -d 1,2 to filter-out the device 3 and tell me if work.\n\nBye,\nmatrix\n. @lalaithion could you describe how you test it? Write here the cmdline please.\nThanks,\nmatrix\n. My Iris gpu card work (Iris, 384/1536 MB allocatable, 1200Mhz, 40MCU)\nhttp://pastebin.com/fWqsKuA5\n@lalaithion @jsteube \n. It's a simple problem ... we can remove the wrong permission without any\nproblem.\nThanks @bjornfor\nOn Tuesday, May 17, 2016, Bj\u00f8rn Forsman notifications@github.com wrote:\n\n@jsteube https://github.com/jsteube: I have no idea. (I've been using\nhashcat only a couple of days, I haven't looked at its source code yet.)\nBut even if using umask doesn't cause real problems, it feels a bit wrong.\nI don't think it conveys the right intent; \"~/.hashcat/hashcat.pot should\nbe private\". Instead it says, \"all files should be private\".\n(Isn't it equally trivial to create the file with the correct permission\nbits, as it is to use umask?)\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/331#issuecomment-219683726\n. @cclements , you run hashcat.app by root?\n. @cclements, could you paste the log of the execution by non-root user ?\nThanks\n. @lfaoro, probably you need tune your AMD Radeon R9 M370X Compute Engine\nby changing/adding config in hashcat.hctune file.\n\nLet me know,\nmatrix\n. @leonklingele @mire3212 now I think remain only the Iris Pro issue.\nCould you share here (pastebin link please) the output of hashcat --opencl-info ?\nThanks!\n. Nice, now look here\n\nIntel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\nMemory         : 2047/16384 MB allocatable\nIris Pro\nMemory         : 384/1536 MB allocatable\n\nThe Iris Pro GPU seems to have little available memory.\n. @mire3212 if you do a fresh clone without my patch merged ?\n. @mire3212 , try cloning my repository for test the fix\nhttps://github.com/matrix/hashcat.git\n. I don't think It's only a memory limitation and I can't debug because I don't have a macbook with an Iris Pro.. but now the build errors disappeared\n. @leonklingele check this link\nhttps://support.apple.com/en-us/HT202043\nHave you the \"Automatic graphics switching\" options in your \"Energy Saver\" menu?\nLet me know.. @leonklingele have you try custom tuning for your Iris Pro ?\nIf yes please paste here the hctune line.\nThanks. @leonklingele so it's time to do :)\nhttps://github.com/hashcat/hashcat/blob/master/hashcat.hctune. @jsteube the Iris Pro device have no custom tuning, Iris yes (different device name).\nProbably we need that but I don't have an Iris Pro device for test it\n. @leonklingele it work? Any other hash mode with \"Abort trap: 6\" ?. @jsteube yes.\n@schluk look hashcat.hctune , if you set a custom tuning values for 7100 like \"* 7100 1 1 8\" hashcat should work.\nLet me know. @leonklingele please try if the same setting for 7100 work also with 8700. @leonklingele if the custom setting for 7100 work please make a pull request.\nFor 8700 try change last value (8) with 4 or 2 or 1. @leonklingele you're right \ud83d\udc4d same trick for value 256, try 256/2=128, 128/2=64, etc ... until it works. @schluk try add the following line to hashcat.hctune and retry:\nATI_Radeon_HD_6490M                                        *       7100    1       1       8. If 256 is good no :)\nCould you do a pull request ?\nThanks!. If SHA-3 is working yes.\nI'm still curious to see the full benchmark output using Iris Pro GPU :)\nOn Sat, 31 Dec 2016 at 13:21 Jens Steube notifications@github.com wrote:\n\n@matrix https://github.com/matrix can we close this issue?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/412#issuecomment-269862722,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywZ4qRGPhJfMzXTE8tTRYJ5dYCpiDks5rNkjKgaJpZM4JD4Hf\n.\n. @TheAifam5 you need also with salt?. You can use a script for run hashcat with your custom parameter (see\nexamples).\nAdd a config parser is not a good idea (for me).\n\nBye,\nmatrix\nOn Thursday, August 25, 2016, thesle3p notifications@github.com wrote:\n\nhttps://github.com/benhoyt/inih inih might do the trick.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/469#issuecomment-242464070,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywYT9QTK_ypbpTP1pFpdYYb0iHSJ8ks5qjcpPgaJpZM4JqZKb\n.\n. I'm working on that :)\n\nOn Sun, 18 Dec 2016 at 06:10 Gnoxter notifications@github.com wrote:\n\nTo extract the key material from any LUKS header these four hash\nprimitives are needed: SHA1, SHA256, SHA512 and RIPEMD160\nI'm not particularly familiar with the hashcat code, but it is my\nunderstanding that hashcat does not offer these as simple to use primitives\non the host. This would be a prerequisite.\nFor the cracking and comparison it needs PBKDF2 with the primitives above\nand custom iteration count, the symmetric encryption cipher + mode that is\nused for the FDE. Additionally it needs the hash primitive used for key\nextraction again, which is always identical with the one used for the\nPBKDF2. By default this is aes-xts-plain64 with SHA256 as far as I know.\nFrom my brief code reading I learned that all the hash primitives and the\nspecified ciphers (aes256, serpent, twofish) are available as OpenCl kernel\neven as xts modes. But only as -plain not as -plain64 if I understand\ncorrectly.\nw.r.t hashkill I looked at the luks-plugin and its\nincomplete/nonfunctional and since its GPL code reuse would not be possible\ndue to License incompatibility.\nFor reference, the current LUKS specification can be found here:\nhttps://gitlab.com/cryptsetup/cryptsetup/wikis/LUKS-standard/on-disk-format.pdf\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/481#issuecomment-267803853,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywfFKYTz9tSdpTWf0Q03PFuNEzD0Kks5rJMA9gaJpZM4Jx18B\n.\n. \u270c\n\nOn Wednesday, September 7, 2016, Jens Steube notifications@github.com\nwrote:\n\nThis helped alot, thanks m8!\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/488#issuecomment-245203032, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywZ2komRcC4ljub4Q90Oq0cSVvHSxks5qnmzVgaJpZM4J2QPE\n.\n. Hey @mouse07410 \ncould you can try test with my hashcat repository for understand if also for you segfault is gone ?\n\nhttps://github.com/matrix/hashcat\nBefore last patch I got a segfault like your, if is fixed also for you\nI do a pull request and @jsteube can close this issue.\nThanks !\n. I thought the same thing yesterday, but this is not a migration, it should be re-engineered.\n. ahahahahahahahahaha :)\n. @jsteube, let me in :D\n. lol\nOn Tuesday, September 27, 2016, KOLANICH notifications@github.com wrote:\n\nC is simpler and easier to read.\n... when used for simple hello-world-level programs.\n\"Entities must not be multiplied beyond necessity\"\n[image: ocham]\nhttps://cloud.githubusercontent.com/assets/240344/18882184/3cde489a-84ef-11e6-8933-e579be2b67c1.jpg\nOn the picture in bubbles:\n-Don't multiply entities, b1tch! Don't multiply...\n-OK, Occam, just move your razor away!\nIn this case it seems to be necessary because hc is much more complex than\nhelloworld.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/511#issuecomment-249919732,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywWJDwiWXHDILfKWGVzqSZhgrFPBvks5quUSagaJpZM4KFfEK\n.\n. Hi,\nI try to debug this issue with lldb, reproducible by exec example0.sh,\nand at day 3 when I switch static allocation with dynamic hashcat stopped crash.\ninclude/common.h:#define HCBUFSIZ_LARGE      0x50000\n\nThere're a lot of static allocation with that size inside hashcat (called also \"scratch buffer\" in some comments), probably the stack is full.\n@magnumripper try example0.sh (without apply my patch) and check if you got a segmentation fault.\n@jsteube probably the best solution is not preallocate that buffer in hashcat_ctx struct, I think we should make better use of memory allocations.\n@mouse07410 if my patch slow down the cracking speed we can't use it, also if without got a segfault. If you need hashcat for some particular reason you can use my repo temporarily until we solve the bug in the best way possible or switch to linux solution.\nSorry all for later response but yesterday I woke up with fever :( I'm sick ... grrr\n. @magnumripper for print \"hashcat_ctx\" you need go back in previous frame (try \"bt\" command) and then print it with * like:\nprint *hashcat_ctx\nI do 3 days of debugging for understand the issue :)\n. You can try comment out some code in \"check_hash\" function, you will be redirect to another function call, \"potfile_write_append\". But as I say before the only way I found to mitigate the segfault has been switch the memory allocation.\nYou can also try the @jsteube hint about prealloc that buffer somewhere for check if the segfault still here or not.\n. Hi,\nWith DEBUG=2 we can confirm the stack overflow bug in OSX version.\nlook here http://pastebin.com/huHCVSKp\nI do some mods on thread handling, in details I get the thread stack size with pthread_attr_getstacksize, double it and set with pthread_attr_setstacksize.\nI think that could be one of the best mitigation :)\nHappy Halloween,\n~(=^\u2025^)\u30ce\u2606\n. I'm wrong with word \"mitigation\", I meant \"alternative\" :)\nAnother could be reduct the HCBUFSIZ_LARGE value, but I have absolutely no desire to test all the algorithms implemented to see if it crashes or not, i'm very lazy :)\nbut coding make me happy also in sick mode :D \nThanks for your time\n. @jsteube, version with preallocated buffer here\nhttps://github.com/matrix/hashcat/commit/1df6ca2a47307b8b8c15fcf4a0cce0bb7580fc5b\n. I do not understand but I trust you :P\nOn Fri, 18 Nov 2016 at 09:59 Jens Steube notifications@github.com wrote:\n\nThere's no code to unset device_param->skipped = true after that specific\nhash-mode, I'll fix\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/598#issuecomment-261481031, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywevn-GaqVgviyjvMrYkHumguteSbks5q_Wj4gaJpZM4K15Z2\n.\n. Ok, now I understand.\nCan you fix it?\n\nOn Fri, 18 Nov 2016 at 10:22 Jens Steube notifications@github.com wrote:\n\nI'll try to rephrase. Problem only occurs when not specifying -m in\ncombination with -b.\nIf we set skipped = true, the -b mode will skip all hash-modes after the\nunstable hash-modes because skipped is never set back to false for the\nstables hash-modes.\nAfter fix, it will look like this:\nroot@ht:~/hashcat# ./hashcat -b --mac\nhashcat (v3.10-757-g72e39a7+)\n1:900:1189:2700:7094485215\n1:0:1189:2700:3842697205\n1:5100:1189:2700:2374526360\n1:100:1189:2700:1307206881\n1:1400:1189:2700:464342317\n1:10800:1189:2700:149045586\n1:1700:1189:2700:152280385\n1:5000:1176:2700:138155729\n1:10100:1189:2700:4513826492\n1:6000:1189:2700:745232064\n1:6100:1189:2700:41219878\n1:6900:1189:2700:40451511\n1:11700:1189:2700:8174836\n1:11800:1189:2700:8178862\n- Device #1: skipping unstable hash-mode 14000 for this specific device, use --force to override\n- Device #1: skipping unstable hash-mode 14100 for this specific device, use --force to override\n  1:400:1189:2700:992828\n  1:8900:1189:2700:124326\n  1:11900:1189:2700:1086006\n  1:12000:1189:2700:522775\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/598#issuecomment-261485327, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywe5mRdFdFFlhudffliL9ZLm8Phpvks5q_W5AgaJpZM4K15Z2\n.\n. @neheb, \"sizeof(*binary)\" it's not good for me and not only ...\nHave you tried running hashcat after apply these patches?\n. $ wc -l true_test/tc_cracked.txt\n30 true_test/tc_cracked.txt\n\n\ud83d\udcaf . no, I had not inserted :). The bug is here, wrong usage of ctime_r()\nhttps://github.com/hashcat/hashcat/pull/898/commits/96591f3118e46fe449201a3125b4c2c777aed4cf#diff-b1e5020435e46f32362c9ddb87f83690\nThanks. @leonklingele, could you do a full benchmark only with Iris Pro device to identify eventually other problems?\nThanks. @jsteube I will see why Apple named it as \"Pro\" before set an alias in hctune :). I will do :)\nThanks\nOn Fri, 16 Dec 2016 at 17:21 Jens Steube notifications@github.com wrote:\n\nVery nice, didn't expect that :)\n2 things needs fixes:\n\n\nPlease add mode for test.pl and test.sh (and test them)\n\n\nI see you move SHA256 -> SHA2, which is ok, but you should also move\n   SHA384 and SHA512 then, because they are SHA2 as well\n\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/919#issuecomment-267631646, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywcEj1mzyOLxQnImZpIaDdtro1CvEks5rIrpsgaJpZM4LOv1_\n.\n. Done ;)\n\n$ ./tools/test.sh -m 1300 -T all -V 2 -a all\n[ test_1481997672 ] > Init test for hash type 1300.\n[ test_1481997672 ] [ Type 1300, Attack 0, Mode single, Device-Type Cpu + Gpu, Vector-Width 2 ] > OK : 0/31 not found, 0/31 not matched, 0/31 timeout\n[ test_1481997672 ] [ Type 1300, Attack 1, Mode single, Device-Type Cpu + Gpu, Vector-Width 2 ] > OK : 0/30 not found, 0/30 not matched, 0/30 timeout\n[ test_1481997672 ] [ Type 1300, Attack 3, Mode single, Device-Type Cpu + Gpu, Vector-Width 2 ] > OK : 0/8 not found, 0/8 not matched, 0/8 timeout\n[ test_1481997672 ] [ Type 1300, Attack 6, Mode single, Device-Type Cpu + Gpu, Vector-Width 2 ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout\n[ test_1481997672 ] [ Type 1300, Attack 7, Mode single, Device-Type Cpu + Gpu, Vector-Width 2 ] > OK : 0/7 not found, 0/7 not matched, 0/7 timeout. @Ysagi if ok please close the issue. Thanks :). Ok, is broken only in windows? . If only Apple is not affected the right code has already been written :)\nOn Mon, 16 Jan 2017 at 09:29 Jens Steube notifications@github.com wrote:\n\nAll systems (just not apple?)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/961#issuecomment-272800232, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywenfKDEzeR20hAJrp-C5ClhLfCPIks5rSypOgaJpZM4LhI6B\n.\n. Hey Iceman, nice to see you here ;)\n\nOn Sat, 14 Jan 2017 at 09:07 Iceman notifications@github.com wrote:\n\nTo implement a kernel for a generic Skip32 plainttext attack.\n\n\ntake input, known plaintext,\n\n\ncompare result bytes with specified user known-plaintext\n\n\n---if match, log result, break\n\nrepeat\n\nBackground\nSkip32 works with 10byte key, outputs 4bytes and is a simpler version of\nskipjack algo.\ninput: 1122334455667788\noutput: xxyyzzww\nRef:\nSkip32: Naive impl: https://github.com/nlenepveu/Skip32\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/967, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AOqywVaRmZgAS71SfnV8NdZzRHI7TKa4ks5rSIJFgaJpZM4Ljj53\n.\n. Hi @FireFart, personally I think it's more simple do it yourself by specifying the \"username\" as a single password than rewrite something in C.. Hi, check here #1480 . @jsteube done. Check if you like it :). Hi @Skybound1 \nI tried to reproduce your issue but it does not happen to me.\nCould you show us what are the full commands you use?\nPlease attach also hashcat -I output.\n\nThanks :)\n. > Thanks, this looks like some good work.\n\nIt would be nice if we can have this not for zip but 7zip. This ensures higher compressing rates, cross platform availability and we even have support for 7zip library in the Makefile.\nPlease create a new PR in the hash-module-plugin branch instead since we're in the middle of a very deep refactorization.\n\nOk, I will do it as soon as possible, then I will check how do the same thing with 7zip format.\nty. > As discussed, please use LZMA instead.\nI think to add also the LZMA support, but don't put in queue this pull request. It could become too big to review. . I need to push also the zlib github repository in deps ? (I see lzma SDK it's statically include into that folder). > The warnings are benign, build works fine despite the warnings. I've been planning to fix them for quite some time but didn't get a round tuit[tm].\nSame thing here, I tryed to update the sdk locally but it's the same. We need to modify the source but after the restyling . I got this error, also with -export-dynamic on OSX\n\nUndefined symbols for architecture x86_64:\n  \"_decoder_apply_optimizer\", referenced from:\n      _module_hash_decode in module_00000-6d3308.o\n  \"_decoder_apply_options\", referenced from:\n      _module_hash_decode in module_00000-6d3308.o\n  \"_encoder_apply_optimizer\", referenced from:\n      _module_hash_encode in module_00000-6d3308.o\n  \"_encoder_apply_options\", referenced from:\n      _module_hash_encode in module_00000-6d3308.o\n  \"_hex_to_u32\", referenced from:\n      _module_hash_decode in module_00000-6d3308.o\n  \"_input_tokenizer\", referenced from:\n      _module_hash_decode in module_00000-6d3308.o\n  \"_u32_to_hex\", referenced from:\n      _module_hash_encode in module_00000-6d3308.o\n. ... the important thing is to reach the end of this warnings :). \n",
    "Merenon": "Hi, of course, you're right, it's related to SHA1 (I changed the title).\nI will do some benchmark tests and post them. Thanks for your comments.\n. ",
    "szul1984": "https://github.com/magnumripper/JohnTheRipper/commit/e84a3eed61e32cdcfb5e6f4bb2907b1812797bd1\nthere is some info about what need to be change vs \"normal\" sha512 mode (some guy make special module for john the ripper) and explain what should be done\n. ",
    "th3mechanic": "I remember SnuCL was brought up in the forums before,  wasn't a fit then maybe it is now  http://snucl.snu.ac.kr/\n. amdgpu-pro-16.30   also tested on ubuntu 16.04  still failed\n. Sorry for needing the hand holding but in which file do i need to look for it ?   anything i changed so far either failed to build or seg faulted,  pretty much figuring i'm doing wrong.  With other issues i put on the forum it may be best to just hold for a driver update, the pro hasn't changed since the card release, no power draw fix, etc.  \n. ",
    "martiGIT": "VCL still works with oclHashcat 1.31. Never versions get /usr/lib/vcl/libOpenCL.so: no version information available\noclHashcat v2.10 will have support to utilize all OpenCL compatible platforms not just GPU, so possibly VCL too. \n. yep, but this information is followed by:\noclHashcat64.bin: relocation error: oclHashcat64.bin: symbol clCreateCommandQueueWithProperties, version OPENCL_2.0 not defined in file libOpenCL.so.1 with link time reference\n. ",
    "yhfudev": "What't the alternative method to get the session-dir work?\nThere's multiple definition of bool, what's your solution?\ninclude/ext_ADL.h:13:typedef int bool;\ninclude/shared.h:2243:typedef int bool;\n. github will combine the request even I post 3 times.\n. Thank you for your explain. Do you have any plan to use autoconf style make system to compile the source code? It can handle the dir problems easily, and it's cross platform and can lessens package maintainer's pain. I can try to create one if you're interest.\n. @gm4tr1x \nGreat job!\nAre you still developing the Makefile.am? It seems the other files not installed, for example the files in /usr/share/?\nAnd the bin name hashcatocl would be better so that he can use 'tab' key to explore which command he should use if he installed both hashcat and oclhashcat.\n. The error message is for locating errors quickly. I don't think it is just for 'good looking'. The problem of the error message is there're same message printed in different location in the source code. I met this during compile and use the software and have to dig into the source to find how to use it.\n. @stephengroat\nThanks! I updated the CI scripts so it can be compiled in cygwin, mingw, linux, and osx now.\n. @stephengroat\nThe user should use their own OpenCL-Headers, not this one, and we use it here is for compiling test.\n. @jsteube\nFrom your post above, my only fault is not create the files AUTHORS, COPYING for you. The other questions, please google by yourself, here's the hints,\n\nmost of the files are generated by autoscan/autoconf/automake\nthe start point for user is 'configure', not 'autogen.sh'\nit can be compiled in expected platforms (updated .travis.yml and appveyor.yml)\n'configure' is a 'API' for distributions.\ndo some experience of packing binaries for various distributions(rpm,apt,pacman) if not sure.\n. \n",
    "drSnuggl3s": "Thanks epixoip,\n/ Martin\n. The password is in the comment of the key: fake123\n/ Martin\n. What do you think, is this a very hard task to implement?\n. Ok I think you misunderstood the request but I respect your opinion.\n. ",
    "hawken93": "I have a proof of concept project that tries to crack passwords of password protected, symmetrically encrypted gpg files...\nI came here because I hoped there would be some efficient gpu implementations etc. waiting for me here but it seems like every hash algorithm is reimplemented for every kernel. This will be hard to handle as the new kernel needs to support many different hashing and encryption algorithm based on the data found in the specific gpg challenge..\nI want to ask if it could be possible to create more \"libraries\" (see inc_cipher_aes256.cl), but for cast5, aes128, sha1, sha256, and so on. Finally make an API that can return some algorithm agnostic structure that could be used.\nMy specific file uses sha1(salt+pw+salt+... 65536 bytes)+sha1(0x00+salt+pw+salt+... 65537 bytes) to create a 256 bit aes key.\nThis key is used to decrypt 16 random bytes, then another 2. Bytes 15-16 have to match bytes 17-18. Then you have a probable match. After that you need to decrypt another block to verify that your password is indeed correct (a valid gpg packet is to be expected)\nI'll upload what I have on request..\nPS: This is only for cracking password protected encrypted files. Who knows what else has to be done to decrypt RSA keys and so on..\n. ah, additionally the s2k algorithm uses exactly 8 random bytes for salt\n. Anyway.\nI'm trying to make a little something, but I have to work on a higher level than the hashing function internal operations.\nCheck out Openssl EVP. Something like that API could be insanely useful if it was ported to OpenCL.\nAdditionally, if all the kernels relied on such a library, performance improvements would immediately give advantage to all the kernels..\n. ",
    "unl1k3ly": "up. up. ",
    "dc3671": "Fine, my fault.\n. ",
    "lloeki": "\nThey were perfectly fine with JtR prior to El Capitan but now we see segfaults, incorrect results and whatnot.\n\nI admit I didn't write an OpenCL program myself since Mavericks, but I recently ran JtR on some Raw-SHA512-opencl task under El Cap. It was on an Intel card though, so maybe there's a flaky Nvidia or AMD driver down the line.\n. I was merely providing a data point :-) I'll keep this in mind anyway as I may need OpenCL for other things, thanks.\n. That's more work but maybe we can work around OpenCL: it seems Metal can be used for GPGPU computations but I don't know how convoluted it would be to call it from C.\n. Thanks @gm4tr1x. Cursory test on an Intel Iris (3GHz Core i7, Mid 2014 MBP 13\"):\n```\n$ ./example0.sh\noclHashcat v2.10 starting...\nDevice #1: skipped                    \nDevice #2: Iris, 384/1536 MB allocatable, 1200Mhz, 40MCU\nHashes: 6494 hashes; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 80c\nSource from '/Users/lloeki/Downloads/oclHashcat-2.10/./OpenCL/m00000_a1.cl'\nDevice #1: Kernel /Users/lloeki/Downloads/oclHashcat-2.10/./OpenCL/m00000_a1.cl (18825 bytes)\n:147:9: warning: unused variable 'tmp2'\n    u32 tmp2;\n        ^\n:375:9: warning: unused variable 'tmp2'\n    u32 tmp2;\n        ^\nDevice #1: Kernel /Users/lloeki/Downloads/oclHashcat-2.10/./kernels/markov_le.349421b0.kernel not found in cache! Building may take a while...\n------ 8< ------\nSession.Name...: oclHashcat\nStatus.........: Exhausted\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Fri Jan 15 23:05:14 2016 (13 mins, 5 secs)\nTime.Estimated.: 0 secs\nSpeed.Dev.#1...:   164.9 MH/s\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:30,N/A,N/A AVG:167.22,10033.42,240802.08 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nStarted: Fri Jan 15 23:05:14 2016\nStopped: Fri Jan 15 23:18:22 2016\n```\n. Built from master, and already put to good use!\nIs there a timeline for the next release? I'd like to create a Homebrew formula, and they require an official upstream release for a homebrew package to be built.\n. ",
    "Thireus": "@jsteube: Tested and working. However, performances are quite low compared to a Windows build.\nThank you for your work!\n. ",
    "Fist0urs": "@jsteube this issue can be closed then?\n. What kind of help do you need for this one? Details on algorithm or some more hands to code it?\n. @magnumripper \nWell kirbi2john relies on tickets created by one of the tools part of mimikatz suite, which requires to extract TGT from LSASS memory. So this parser is only for Windows oriented RC4 encrypted TGS whereas it is possible to have some using Linux (eg. using Samba).\nThat said, I think we shouldn't rely on a particular output format from one specific script but get a a common format, as you mentionned.\nTo answer your other question, size of encrypted data can vary (but I guess we can easily fix an upper bound as encrypted-fields should contains strings like domain name, SPN, etc. which are not supposed to be that long...).\n. > RC4_HMAC_NT is much used in UNIX world too ;)\nI was actually talking about kirbi2john parser, not the type of algorithm used :)\n\nDES_CBC_MD5 (3) -- the only one supported by all, but deprecated\n\nThis one is disabled by default, but if for an odd reason it was re-enabled, this could be an option yes (also, are you sure this one is still supported on Windows Server 2012?)\n. Well, they are automaticaly generated, either on workstation and DC, as AES ones, that is by design iirc. But using them or not is defined by DC, so I guess you got reject while try to authenticate even if you declare supporting only this algorithm.\nAnyway, that's not the subject. Concerning AES, we could try to implement this ones too, but I don't know if this worths as this would be extremely slow and hard to implement using SIMD...\n. > The best way to support this and other algorithms is to supply more samples! Ideally several per algorithm and from different networks and always with a known password of course.\nI'll provide you some :)\n\nVectorized RC4 is also impossible to implement. But it's not a problem since it's so fast anyway and you can do parts of an algo vectorized and parts of it with scalar code.\n\nYes of course.\nConcerning the feasability of actually cracking \"real-cases\" ciphers, fyi targeted ciphers are from accounts where a Service Principal Name (SPN) is given. These accounts are normally services accounts ie. random passwords... But when using an application requiring this type of account, sometimes Administrators provide user account, so a maybe non-random password... That's what interests us.\nI'll generate some user accounts like that for you, trying to make ciphered parts as long as possible :)\n. > Oh, and I've got another question (as long I only got the one sample a.zip attached above): I found the known plaintext 20............Z starting at cleartext107. The latter is a fixed position but given only one sample I'm not 100% sure this one is? If it isn't, it probably will be faster not bothering with the known-plain optimization.\nI'll try to generate some samples to check that, but I don't think there are some fixed position, even on pre-authentication case (I am not sure, I'll take a look).\n. Yes, 23 is the constant that specifies that RC4_HMAC_NT is used. This could indeed be the tag we are searching for, to identify the format (as DES_CBC_MD5 would be 3).\nFyi, \"AP-Req\" is the name of the process which consists in relaying a TGS ticket to the server which hosts the service we want to authenticate to. This TGS ticket is the result of the \"TGS-Rep\" obtained after doing a \"TGS-Req\" to the KDC.\nThat's why there is a bit of confusion AP-Req/TGS-Rep but they are the same tickets :) \n. @magnumripper \nActually, I think I found a way to get rid of the max size of edata, so as to the last hmac_md5 operation and get a known plain attack\n. My pleasure :). I actually needed this one too!\n. Yup it will be, when I have time ;). Actually this is not a trivial problem and both cygwin and msys2 have the problem when one wants to use hashcat through an ssh session (they both rely on mintty which does not adresses the problem).\nAfter many things tried (bash on Windows, OpenSSH on Windows by Microsoft Powershell team, etc.), I found a good solution:\nhttps://github.com/rprichard/winpty\nThis binary adresses the actual problems among others (unbuffered problematics and tty communications).\nAll you have to do is compile it on your cygwin\u00a7msys2 plateform and launch problematics binaries through this PE as follows:\nwinpty ./hashcat64.exe -m ...\nPrerequisites if you are using cygwin:\n- mingw64-i686-gcc-g++ or mingw64-x86_64-gcc-g++\n- gcc-g++\n- make\nPrerequisites if you are using msys2:\n- msys/gcc\n- mingw32/mingw-w64-i686-gcc or mingw64/mingw-w64-x86_64-gcc\n- make\nThen:\n./configure && make && make install\n. I tried and my screen freezes. I tried supplying just a single hash of known plain to see if it actually worked but it doesn't\n. > Does it crash on MD4 already or what format is causing the hang? My HD4000 works just fine until an Abort trap: 6 in SHA-3(Keccak) (and that may just as well be an Apple driver bug).\nIt does crash on MD4\nI'll test supplying --benchmark-mode=0 and decreasing gpu accel as soon as I can\n. @Zyntax3rror , what are your custom parameters in benchmark mode? (-u and -n) Because it keeps freezing even on -u 2 -n 2. Maybe my cpu is so weak that I can't get any low parameter to make it work?\n. @gm4tr1x quite difficult as my screen freezes and I have to hard-reboot (or maybe you just wanted the cpu specs?) ;-)\nAnw, it displays the prompt for MD4 then freezes 5 to 10 seconds after\n. Here they are (I had to write them on, as computer crashed):\n```\nDevice #1: Intel(R) HD Graphics 4400, 356/1425 MB allocatable, 400MHz, 20MCU\nDevice #2: Intel(R) Core(TM) i5-4300U CPU @ 1.90GHz, skipped\nHashtype: MD4\nWorkload: 2 loops, 2 accel \n```\n. > try before\n\n-b -m 900 --opencl-device-type 1,2 -d 2\n\nWow, this one worked! Well done :+1: \nAnd the 2nd failed\n. Did someone succeed in running oclhashcat on HD Graphics on Linux? Drivers provided by Intel apparently need to patch kernel and I would like to avoid that if possible...\n. @jsteube Yes we can\n. Thanks :)\nI forgot to mention that I implemented the input format the same I did in john the ripper. So that full compatibility either side ;)\n. Yes, it is (look at first post :-p )\nTGS-REP == AP-REQ concerning ciphered part and as it is name krb5tgs in john, I named it that way\n. Yes!\n. Indeed it is a bit hard to read, the first line is to check if any of first 16bytes contains headers. This was to avoid to compute next 16bytes and increase performances.\nBut we have the case that \"header 1\" goes with \"footer 2\" and would say \"good boy\" whereas it should not, so we have to add the last check to avoir false positives :)\n. Yes, this will be fixed tomorrow :+1: \n. Apparently, Xenforo default encryption scheme is using bcrypt. It also supports many different kind of encryption schemes, so these are particular cases. You must provide all schemes within this software\n. @AgelxNash I don't get what are supposed to be hash and salt in your examples, the two parts have either 20:20 bytes or 32:32 bytes\n. wow the salt is as long as the hash? oO\n. So in case of SHA1, it would be : sha1(sha1(password).sha1(salt)) with sha1(salt) as \"new\" salt?\n. I can't reproduce the output of the first hash:\nhashlib.new(\"sha1\", hashlib.new(\"sha1\", \"1\").digest()+\"824acdc9c2276bc1b7b9a9ec22684e6ac4b55eda\".decode(\"hex\")).hexdigest()\n'5218723a13afe0b988ec1c3dc2bb7699e2f7d2d2'\n. Oh that's odd, it's based on hexdigest. Thanks, I'll try to take a look\n. Seems good to me\n. We should try it yes, good idea. The problem is that I no longer have direct access to a HD4400 Graphics integrated GPU (which we experienced bugs). I'll try to get one to do some more tests\n. I'll ping back again my ex-coworker who has the problematic CPU. Where does this format is used? \nAnw, it is easy to implement this kind of format and there are plenty of new algorithms examples. You can pick one and implement it :)\n. @philsmd told me about that. Actually I knew there were some problems (not all them looking at the commits though) but I did not have time to fix stuff :/\nI'll take a closer look for the next algorithm, sorry about that\nGreat work! \n. Hi,\nI'll try to take a look this week-end. Could you give me some more information please: \n- is it using CPU, GPU or both\n- what is your driver version\n- have you tried with a password with another length/character class\nThank you\n. Actually I've experienced the same problems (password not cracked) using the exact same embeded GPU (issue #287 )\nI'll try to look this week-end but I don't know if I can find something about if it is really optimization related :/\n. I could do that when I find time... (also the KRB 5 TGS one). I'll implement this one soon :+1: . Windows username can contain anything but these characters:\n\" / \\ [ ] : ; | = , + * ? < >\nEven if # is very unlikely to be found, the implementation allows it (though I never saw this). I'll implement this one soon :+1: . Hi!\nI don't think that is related to hardware, 300k would be the maxium for you, right? I'll try to fix that ASAP. Hi there, I have quickly read what you did and nice job @philsmd! \nI've implemented the stuff in both jtr and hashcat for DPAPI and there is also a DPAPImk2john in the run/ in order to extract stuff related to it.\nUnfortunately I really don't have time to take a deeper look at it and implement stuff :/, but feel free to email me if you have any question about DPAPI internal mechanisms (also look at #1238), I'll answer it asap.\nCheers!. Hi @hycday,\nWindows offers a way to \"migrate\" between profiles that use DPAPI. Unfortunately at some point you will always have to rely on the masterkeys (usually in C:\\Users\\\\AppData\\Roaming\\Microsoft\\Protect\\\\, )  so if you've erased/overwritten it it will be quite complicated not to say impossible...\nAnw take a look at this blogpost from @HarmJ0y if you want to have a better understanding.. It is 6bytes not 5 but same problem. Mmmh you're right, it was 8bytes in my mind, don't know why haha. I'll implement the final stuff then, thanks for notifying it! :+1: \n. ",
    "japhar81": "I'd like to take a stab at the RAR3 + unencrypted headers, but I can not for the life of me find any info on what the algorithm is.. has anyone gotten anywhere in figuring out what actually needs to be done?\n. ",
    "DrDinosaur": "Any update? . ",
    "BTCBOY": "PKzip support would be really helpful. ",
    "ned-kelly": "+1. ",
    "RolfHashcat": "The request is still relevant.. Issue fixed, thanks.\n. ",
    "antimech": "Updates?. ",
    "TheWorkingDeveloper": "Would like to request this to be added as well.. ",
    "Devil-of-Chaos": "Would like to request too. ",
    "alpenseppl": "+1 (PKZIP2). ",
    "thehlopster": "+1 pkzip2. ",
    "kenshin33": "ERROR: clGetDeviceInfo() : param (4043) : -30 : CL_INVALID_VALUE\nI added something to get the param_name in my case it was 0X4043\nwhich seems to be an AMD thing.\nhttps://www.khronos.org/registry/cl/extensions/amd/cl_amd_device_attribute_query.txt\nthere's no mention of this in any header in /usr/include/CL/*\n. ",
    "julienbedard": "John jumbo added the code to his repo.\nhttps://fossies.org/dox/john-1.8.0-jumbo-1/keystore2john_8py_source.html\nhttps://fossies.org/dox/john-1.8.0-jumbo-1/keystore2john_8c.html\nAlgorith is SHA1\nExample hash are in attachment from john the ripper.\nhash_reference.zip\n. ",
    "bandrel": "+1\n. ",
    "gentilkiwi": "RC4_HMAC_NT is much used in UNIX world too ;)\nI would recommend to support:\n- DES_CBC_MD5 (3) -- the only one supported by all, but deprecated\n- RC4_HMAC_NT (23)\n- AES128_CTS_HMAC_SHA1_96 (17)\n- AES256_CTS_HMAC_SHA1_96 (18)\nBy the way, \"kirbi\" files are not really mimikatz related, it's the standard ASN.1 for KrbCred from RFC. And if you support extracting from \"kirbi\", it will be easy to support extracting from network capture too ;)\nI'm fan of your work guys :bowtie: !\n. Sure: not :)\nBut I often \"find\" keys in memory for this algorithm ;)\n. ",
    "gabtremblay": "Just wanted to say thanks. I was the initial reporter.\n. ",
    "edermi": "Just a short question: Has AES256_CTS_HMAC_SHA1_96 (Type 18) been implemented as suggested by @gentilkiwi? John Jumbo supports them.. ",
    "RorschachRev": "There are several implementations of Keccak and they are all different. Keccak256 is not SHA3, they both yield different results with \"\" empty string as the input. I need both implementations if at possible, and I can't tell which one you're using. Bitcoin uses SHA3, Ethereum uses Keccak256. Near the end of the NIST testing, they changed the padding settings.. ",
    "dummys": "Hello, I've tested the one I gave to you before and it's working. I will setup my android to create new one and test again.\nThanks for this feature.\nYou guy rocks !\n. ",
    "mattames": "This would be very handy for myself as well! \n. Yep. From what I understand, the GPU kernel with a fixed key length can be optimised thus making it faster, since it's not wasting clock cycles dynamically shifting things around...\n. Bigfella,\nEven though the effective search length between separate searches is 40 bits, the kernel would have to be written as such to accommodate the entire Key+IV as just a raw key, as this is how the cipher is really configured.\nWith one of the first known RC4 security issues being a weak key-schedule, many protocols that use RC4 as a base algorithm work around this weakness by taking a 40-bit \"key\" and concatenating this with a separate IV, (for example 64-bits in the case of the NICTA P25 paper) to give a 104-bit effective key length.\nOf course, writing many different kernels for obscure modes like this was never the intent of Hashcat, but it would be great to know and demonstrate, as when this was originally researched in 2010, we tested the RC4 on a large Nvidia Tesla cluster, and it was severely limited by the early architecture's lack of shared RAM.\nIf this could be taken into consideration, that would be greatly appreciated. The recent work in adding DES-ECB has been of great benefit as a base algo, and RC4 would be the cherry on top :)\nCheers,\nMatt\n. Yes, once the plaintext/ciphertext pair is extracted (easy to do) they can then be fed into oclHashcat. FPGA implementations are hard to come by, require experience with FPGAs, expensive software tools to be able to create the bitstreams on the larger devices ($5000 for one vendor), and can be time consuming to create an image and troubleshoot it.\nBy comparison, oclHashcat on GPU is fast, off the shelf and if you collaborate with a few friends with GPUs they can 'lend' you their spare cycles and it would be feasible to split the keyspace up into slices for a zero-cost solution using the GPUs that people already own...\n. Hi Guys,\nIs there any chance someone might be able to implement this one? \nCheers,\nMatt\n. Also, since it would be great to run many instances of this across several different PCs (I have access to a few at work with beefy GPUs) why not add a key start range..\nFor example, one PC can start at key 0x00001000000000, the next could be told to start searching at say 0x000F0000000000 and so on...\nSince password to DES input key is application specific, it really doesn't relate to DES-ECB at all, so as halexan commented, it would be best to just work with the raw DES keys in 56-bit hex format.\nThanks so much for this addition, it is really great to see this implemented!!!\n. @jsteube - my apologies, I should have looked harder. Thanks for the info!!\nCheers,\nMatt.\n. Awesome work jsteube!! Can you give an indication of how fast the bitsliced DES-ECB kernel runs on your machine?\nThanks again!\n. Hi guys, from talking to a few users, yes this is broken. Forts117 and bigfella237 - perhaps it would be useful if you ran Hashcat against some standard DES test vectors and some known keys to demonstrate that this is the case please?\n. After reviewing this thread, I believe all the troubles were due to the order of the PT and CT. Hashcat requires the 64 bit input and output blocks in the format Ciphertext:Plaintext, where as Fort's failed examples above are in the order of PT:CT.\nIn any case this mode has been confirmed working by many people at this stage so I'm sure this one can be closed off.\n. Hi Jens, \nYes - I understand that DES keys are only 56 bits in length, because the DES input register is only 56 bits wide.\nI don't understand what the charset is for however. DES itself doesn't do any bit shifting - it just simply takes a 56 bit input from a 64 bit key with odd parity applied. So every eighth bit (the parity bit) is simply ignored by the DES algorithm..\nI can see that 0xFF left shifted once gives 0xFE - this makes sense, but I don't see anywhere in the DES standards that the key is left shifted at all.\nRegards,\nMatt\n. Well this is slightly embarrassing - \"git pull\" and \"make clean\" fixed it. Looks like I compiled a broken build by leaving that out.\nOn another note - I tested the \"Time Estimated\" bug and its now working as expected! Thanks for the fix guys!\n. An example of the old style is:-\nv4.2.1-53-g77daf05d+\n. current hashcat -V \nv5.0.0. OK my mistake - the Makefile is still set to production = 1.\nClosing issue.\n. Cheers Jens!. ",
    "eintw1ck": "I'd like to look into this, how would I go about adding a module?\n. You could always have a few kernels, one 'dynamic' one, and then a few more-optimised ones for common combinations.\n. @anthraxx I spoke with a friend who uses linux, they are having the same issue. I think it's because hashcat isnt in the $(prefix)/bin folder which it was compiled with, and defaults to the binary dir, this if statement is to blame afaict.\nTry manually setting the PREFIX maybe?\n. This probably needs to be added to the README, or there needs to be a design change so that it doesn't fail like this. It was something I'd like to ask the hashcat guys: wouldn't it be better to check the relative resource directories (I.e. ../share) from the bin directory, and then if they don't exist check the current directory before describing an error if neither directories are writable so that a user can either fix permissions or change the prefix? It wouldn't create much overhead, and would reduce a lot of confusion IMO.\n. I was more thinking about /usr/local. Although in your case it didn't use ~/.hashcat even though it should have fallen back onto it. This was my main point really, implement a fallback (or fix the non-working one). Mind you, I haven't had too much time to look at the code though\n. ",
    "bigfella237": "+1 for me (and the other 160+ watchers), this would get a lot of use here!\nRC4 being a stream cipher utilizes variable key lengths with masking, as suggested in the original ticket, but the authors also suggested discarding the first portion of the generated keystream to avoid an inherent weakness. \nThis is what's known as \"DropN\" and is widely implemented in RC4 applications, so the Hashcat version would also need the user to specify the length of the keystream to be generated and the number of bytes to drop from the beginning before the XOR with the plaintext.\nIn summary, we would input:\n-     start key (with mask)\n-     key range (number of keys to search)\n-     keystream length*\n-     DropN length\n-     the \"target\" keystream portion (to compare with the keystream generated by each pass)\n*Alternately the keystream length could easily be calculated automatic by adding the DropN value entered to the Target length.\nThe Target keystream is derived from a known plaintext XOR the ciphertext. Once our Target matches the generated keystream we've found the key!\nPlease, someone, make my day and implement this in Hashcat?\n. My applications require either a 72-bit or 104-bit key length, the last 32 or 64 bits (respectively) of which are known but still must be included in the key, so a \"fixed\" 40 bit key length would be of no use.\nLikewise with DropN, I need to drop either the first 256 or 267 bits (depending on the application) of keystream to align the ciphertext with the correct portion of the stream that was originally used for the XOR.\nThe beauty of stream ciphers is that they are very flexible, allowing for varying key and output lengths, unlike a block cipher, which has fixed key and IV lengths. With so many different applications of RC4 it seems a pity to restrict Hashcat with a fixed key length.\nIs there any advantage to having a fixed key length?\n. @ joshdekock That is a great idea!\nOur project is revisiting some of the work done in the NICTA paper on \"Insecurity in Public-Safety Communications: APCO Project 25\" (found here: www.nicta.com.au/pub?doc=5076 ) but also extending the scope to include some communications platforms that weren't covered in the original research.\nWe have three separate platforms that utilize the RC4 algorithm, all have a 40-bit keyspace but also have a known \"Message Indicator\" concatenated to the key to pseudo-randomize the output. The length of this message indicator varies from one platform to the next.\nLikewise with the DropN value, obviously we need to XOR a known plaintext with a ciphertext to get a \"target\" keystream to test against, but we also need to align the result with the exact portion of the RC4 keystream used on the original XOR. All of these platforms drop the first 256 bytes of keystream, but one has an extra 11 bytes of data sent before our known plaintext that we need to ignore.\nSo in summary, we would need three variants to cover all three platforms, being:\n- 72-bit key with a DropN of 256 bytes;\n- 104-bit key with a DropN of 256 bytes;\n- 104-bit key with a DropN of 267 bytes.\nAs stated, all would still only have a 40-bit keyspace to search, but we do need to append the known message indicator as it forms part of the key.\n. Sorry if this is a \"newb\" question (and sorry for my impatience) but is there a way to tell if anyone is working on support for this?\nAs above, Hashcat already has some RC4 modules in place for other searches and, although I'm no programmer, it shouldn't be too much work to adapt something to suit our needs?\n. @philsmd any chance you could take a look at implementing these RC4 modules for us (in your spare time of course)?\nI'm guessing there's at least four or five different different \"modes\" involved depending on whether you can make the key length and/or DropN lengths variable:\n\n40-bit key with no DropN;\n40-bit key with a DropN of 256 bytes;\n72-bit key with a DropN of 256 bytes;\n104-bit key with a DropN of 256 bytes;\n104-bit key with a DropN of 267 bytes.\n\nAny help would be greatly appreciated!. We would just need to add a key mask as we only want to search the first 40 bits (the balance of the key is known), so something like:\nhashcat64.exe -m [mode] input.txt -o output.txt --outfile-format 5 -a 3 -1 charset --hex.charset ?1?1?1?1?1knownportion\nThe above assumes we have a different [mode] for the different variable and DropN lengths, otherwise, as you suggest, those values would also need to be specified in the command line.. Bumping this request for RC4 known-plaintext attack, it's coming up on 2 years old!\nIf anyone has the time this would still be very useful to us and shouldn't take long as RC4 is already used in other modes. I wish I knew how to add this myself but I just don't have the skills.\nAnyone?. Just checking-in to wish this request a happy birthday... three years old today!\nI would still get a lot of use out of these RC4 known-plaintext attacks, and I'm sure that what would take a CPU several weeks could be done in minutes with Hashcat. \nIf anyone has some spare time to look at this I would be eternally grateful, pretty please (with sugar on top)?. Even if this 3DES work-around works as above for a known key, that does not help when searching for an unknown key since we have nothing with which to populate the first two variables?\n. @fransla can you confirm that -m 14000 does not find the test key with the verified CT:PT?\nIs this a bug in the DES code and if so, how do we report it?\n. Could you tell us please, what is the correct key variable expected from this search?\ncd674507b21e5ebe:1435662222276461\n. Note that those key variables @Forts117 listed above all have odd-parity bytes, however there are some even-parity bytes in the default \"DES_full.charset\" file so the key you find may not be that exact variable, but the seven Most Significant Bits of each byte should still be the same.\nRemember that if you disregard parity that means there are 256 copies of every DES key (2^64 divided by 2^56), so we must only deal with odd-parity bytes.\n. I saw this myself when I first looked at it, the charset file supplied contains a mixture of odd & even parity bytes, but I just re-wrote my own odd-parity charset file.\n. ",
    "7805": "I have several applications similar to what bigfella237 describes. Many systems using RC4 (arc4) have the drop 256 bits before going on.  Ideally it would be nice to be able to set the DropN value as well as the key length. \n. yes that is along the lines of what I was thinking of doing. it should\nbe a simple thing to edit the code to accommodate the specifics of the\nRC4 system being looked at. Most are WIFI related so the actual setting\nare known.\nOn 9/13/2016 12:35 PM, Josh de Kock wrote:\n\nYou could always have a few kernels, one 'dynamic' one, and then a few more-optimised ones for common combinations.\n. \n",
    "thesle3p": "Any updates on this? \n. Any updates?\n. It works but I am now getting 0 hashes a second, which never happened\nbefore.\nOn 01/13/2016 04:25 PM, Jens Steube wrote:\n\nPlease retry with latest GitHub version, I think this change should\nsolve it:\n49d0767\nhttps://github.com/hashcat/oclHashcat/commit/49d0767aa8118b60d4caba64ebd808b5e64baa4e\nYou can also try the latest beta build 44 from https://hashcat.net/beta/\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/125#issuecomment-171439270.\n. It's solved, had the hash in a incorrect format (missing $10240)\n\nOn 01/13/2016 05:13 PM, philsmd wrote:\n\nWe should close this, please reopen a new ticket if you think there is\nanother problem.\n(BTW: I can't reproduce the 0 H/s problem, please make sure you have a\nclean directory - new download, no cached kernels and that your command\nline is okay, test just -m 2100 -b for instance. If this is still a\nproblem, please open a new issue, because this seems to be unrelated here)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/125#issuecomment-171453732.\n. I just did a fresh install of Ubuntu and Nvidia-352-updates drivers and this issue still persists.\n. Yes, though I found the issue, on the reinstall I had a bad download of\ngdk_linux_amd64_352_55_release.run , it works after a fresh download and\nrun of tools/deps.sh\n\nOn 01/23/2016 08:27 PM, Jeremi M Gosney wrote:\n\nAre you root?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/147#issuecomment-174240739.\n. ok, any idea what the time frame on this would be?\n\nOn 01/26/2016 12:16 PM, Jens Steube wrote:\n\nI think patching this is easy. All we need to check is if the\ncompilation was a success and store the cached kernel in that case.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/164#issuecomment-175125178.\n. Just rebuilt oclHashcat and now I get this error\n```Device #1: Kernel\n/home/user/.hashca/kernels/m01000_a0.c3417809.kernel not found in cache!\nBuilding may take a while...\nIn file included from :22:\n./OpenCL/rp.c:130:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[0] = __byte_perm (in0[0], in0[1], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:131:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[1] = __byte_perm (in0[1], in0[2], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:132:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[2] = __byte_perm (in0[2], in0[3], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:133:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[3] = __byte_perm (in0[3], in1[0], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:134:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[0] = __byte_perm (in1[0], in1[1], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:135:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[1] = __byte_perm (in1[1], in1[2], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:136:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[2] = __byte_perm (in1[2], in1[3], 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:137:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[3] = __byte_perm (in1[3],      0, 0x4321);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:155:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[3] = __byte_perm (in1[2], in1[3], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:156:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[2] = __byte_perm (in1[1], in1[2], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:157:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[1] = __byte_perm (in1[0], in1[1], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:158:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out1[0] = __byte_perm (in0[3], in1[0], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:159:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[3] = __byte_perm (in0[2], in0[3], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:160:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[2] = __byte_perm (in0[1], in0[2], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:161:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[1] = __byte_perm (in0[0], in0[1], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:162:11: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n  out0[0] = __byte_perm (     0, in0[0], 0x6543);\n          ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:191:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  1:  out0[0] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:192:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:193:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:194:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:195:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:196:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:197:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:198:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[3] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:200:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  2:  out0[0] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:201:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:202:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:203:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:204:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:205:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:206:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:207:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[3] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:209:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  3:  out0[0] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:210:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:211:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:212:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:213:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:214:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:215:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:216:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[3] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:227:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  5:  out0[0] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:228:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:229:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:230:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:231:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:232:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:233:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:236:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  6:  out0[0] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:237:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:238:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:239:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:240:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:241:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:242:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:245:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  7:  out0[0] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:246:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:247:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:248:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:249:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:250:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:251:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:263:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  9:  out0[0] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:264:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:265:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:266:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:267:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:268:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:272:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 10:  out0[0] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:273:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:274:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:275:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:276:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:277:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:281:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 11:  out0[0] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:282:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:283:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:284:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:285:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:286:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:300:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[0] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:301:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:302:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:303:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:304:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:309:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 14:  out0[0] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:310:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:311:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:312:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:313:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:318:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 15:  out0[0] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:319:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:320:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:321:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:322:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:336:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 17:  out0[0] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:337:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:338:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:339:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:345:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 18:  out0[0] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:346:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:347:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:348:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:354:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 19:  out0[0] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:355:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:356:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:357:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:372:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 21:  out0[0] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:373:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:374:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:381:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 22:  out0[0] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:382:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:383:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:390:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 23:  out0[0] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:391:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:392:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:408:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 25:  out0[0] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:409:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[3],      0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:417:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 26:  out0[0] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:418:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[3],      0, 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:426:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 27:  out0[0] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:427:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in1[3],      0, 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:444:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 29:  out0[0] = __byte_perm (in1[3],     0, 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:453:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 30:  out0[0] =  __byte_perm (in1[3],     0, 0x5432);\n                      ^  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:462:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 31:  out0[0] =  __byte_perm (in1[3],     0, 0x6543);\n                      ^  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:783:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  1:  out1[3] = __byte_perm (in1[2], in1[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:784:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:785:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:786:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:787:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:788:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:789:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:790:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[0] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:792:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  2:  out1[3] = __byte_perm (in1[2], in1[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:793:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:794:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:795:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:796:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:797:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:798:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:799:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[0] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:801:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  3:  out1[3] = __byte_perm (in1[2], in1[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:802:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:803:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:804:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:805:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:806:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:807:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:808:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[0] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:819:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  5:  out1[3] = __byte_perm (in1[1], in1[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:820:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:821:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:822:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:823:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:824:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:825:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:828:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  6:  out1[3] = __byte_perm (in1[1], in1[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:829:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:830:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:831:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:832:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:833:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:834:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:837:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  7:  out1[3] = __byte_perm (in1[1], in1[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:838:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:839:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:840:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:841:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:842:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:843:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[1] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:855:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case  9:  out1[3] = __byte_perm (in1[0], in1[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:856:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:857:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:858:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:859:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:860:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:864:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 10:  out1[3] = __byte_perm (in1[0], in1[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:865:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:866:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:867:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:868:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:869:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:873:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 11:  out1[3] = __byte_perm (in1[0], in1[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:874:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:875:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:876:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:877:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:878:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[2] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:891:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 13:  out1[3] = __byte_perm (in0[3], in1[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:892:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:893:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:894:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:895:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:900:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 14:  out1[3] = __byte_perm (in0[3], in1[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:901:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:902:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:903:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:904:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:909:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 15:  out1[3] = __byte_perm (in0[3], in1[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:910:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:911:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:912:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:913:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out0[3] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:927:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 17:  out1[3] = __byte_perm (in0[2], in0[3], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:928:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:929:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:930:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:936:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 18:  out1[3] = __byte_perm (in0[2], in0[3], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:937:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:938:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:939:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:945:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 19:  out1[3] = __byte_perm (in0[2], in0[3], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:946:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:947:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:948:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[0] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:963:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 21:  out1[3] = __byte_perm (in0[1], in0[2], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:964:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:965:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:972:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 22:  out1[3] = __byte_perm (in0[1], in0[2], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:973:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:974:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:981:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 23:  out1[3] = __byte_perm (in0[1], in0[2], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:982:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:983:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[1] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:999:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 25:  out1[3] = __byte_perm (in0[0], in0[1], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1000:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1008:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 26:  out1[3] = __byte_perm (in0[0], in0[1], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1009:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1017:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 27:  out1[3] = __byte_perm (in0[0], in0[1], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1018:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n              out1[2] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1035:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 29:  out1[3] = __byte_perm (     0, in0[0], 0x6543);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1044:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 30:  out1[3] = __byte_perm (     0, in0[0], 0x5432);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1053:23: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n    case 31:  out1[3] = __byte_perm (     0, in0[0], 0x4321);\n                      ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1425:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[0] = __byte_perm (src_l0[0], src_r0[0], 0x6540);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1426:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_r0[0], src_r0[1], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1427:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[1], src_r0[2], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1428:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[2], src_r0[3], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1429:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[3], src_r1[0], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1430:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r1[0], src_r1[1], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1431:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[1], src_r1[2], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1432:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[2], src_r1[3], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1436:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[0] = __byte_perm (src_l0[0], src_r0[0], 0x5410);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1437:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_r0[0], src_r0[1], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1438:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[1], src_r0[2], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1439:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[2], src_r0[3], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1440:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[3], src_r1[0], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1441:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r1[0], src_r1[1], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1442:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[1], src_r1[2], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1443:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[2], src_r1[3], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1447:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[0] = __byte_perm (src_l0[0], src_r0[0], 0x4210);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1448:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_r0[0], src_r0[1], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1449:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[1], src_r0[2], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1450:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[2], src_r0[3], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1451:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[3], src_r1[0], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1452:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r1[0], src_r1[1], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1453:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[1], src_r1[2], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1454:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[2], src_r1[3], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1468:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_l0[1], src_r0[0], 0x6540);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1469:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[0], src_r0[1], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1470:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[1], src_r0[2], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1471:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[2], src_r0[3], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1472:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r0[3], src_r1[0], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1473:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[0], src_r1[1], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1474:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[1], src_r1[2], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1478:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_l0[1], src_r0[0], 0x5410);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1479:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[0], src_r0[1], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1480:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[1], src_r0[2], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1481:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[2], src_r0[3], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1482:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r0[3], src_r1[0], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1483:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[0], src_r1[1], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1484:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[1], src_r1[2], 0x5432);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1488:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[1] = __byte_perm (src_l0[1], src_r0[0], 0x4210);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1489:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_r0[0], src_r0[1], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1490:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[1], src_r0[2], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1491:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[0] = __byte_perm (src_r0[2], src_r0[3], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1492:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[1] = __byte_perm (src_r0[3], src_r1[0], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1493:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[2] = __byte_perm (src_r1[0], src_r1[1], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1494:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst1[3] = __byte_perm (src_r1[1], src_r1[2], 0x4321);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1507:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[2] = __byte_perm (src_l0[2], src_r0[0], 0x6540);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n./OpenCL/rp.c:1508:15: error: assigning to 'u32' (aka 'unsigned int')\nfrom incompatible type 'u32x' (aka 'uint2')\n      dst0[3] = __byte_perm (src_r0[0], src_r0[1], 0x6543);\n              ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n. still persists.\n\nOn 01/27/2016 01:33 PM, Jens Steube wrote:\n\nThe PR 171 should have fixed it, can you retry please?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/170#issuecomment-175784555.\n. I now get Device #1: Kernel\n/home/user/.hashcat/kernels/m01000_a0.275f4b1e.kernel not found in\ncache! Building may take a while... and then the same error message.\n\nOn 01/27/2016 01:48 PM, gm4tr1x wrote:\n\n@thesle3p https://github.com/thesle3p can you recheck if the dir name\nnow is correct?\nThank you\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/170#issuecomment-175789369.\n. worked, thank you. :)\n\nOn 01/27/2016 02:02 PM, Jens Steube wrote:\n\nOK, now it should work :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/170#issuecomment-175795364.\n. That fixed it thanks.\n\nFrom: Royce Williams [mailto:notifications@github.com] \nSent: Monday, February 22, 2016 8:08 AM\nTo: hashcat/oclHashcat\nCc: thesle3p\nSubject: Re: [oclHashcat] ERROR: clFinish() : -36 : CL_INVALID_COMMAND_QUEUE error in the latest pull of OCLHashcat (#236)\nTry deleting the ./kernels directory and ~/.nv/. I had this symptom until I did so.\n\u2014\nReply to this email directly or view it on GitHub https://github.com/hashcat/oclHashcat/issues/236#issuecomment-187246887 .\n. Never mind I see it was changed to hashcat.pot from oclHashcat.pot .\n. I would think add to the .hccp format to support storing eap-md5 challenge\nresponses and a kernel to parse that and crack it.\nOn Apr 17, 2016 4:59 AM, \"Jens Steube\" notifications@github.com wrote:\n\nWhat exactly do we have to do?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/296#issuecomment-210982170\n. I saw the blog post you linked to(the twitter one) and that method is\nincredibly inflexible, you have to modify the wordlist each attempt and it\nis considerably slower then if done natively. Also I have seen it used for\nwireless and heavily for 802.1X (NAC)\nOn May 13, 2016 2:09 PM, \"wiire\" notifications@github.com wrote:\n\n@jsteube https://github.com/jsteube @thesle3p\nhttps://github.com/thesle3p\nA little write-up on EAP-MD5:\nCons:\n- Cannot be used for Wi-Fi as does not support key generation (only used\n  for allowing access)\n- Doesn't provide mutual authentication (vulnerable to MITM)\n- The challenge and response mechanism is in plaintext and goes over the\n  air unencrypted\n- Uses MD5 as hashing algorithm\n- Only available from Windows Vista and below, because considered\n  deprecated/unsecure\nPassive air sniffing is enough to perform an offline attack.\nPros:\n- Provides protection against replay attacks\nClient authentication process:\nClient           Access Point        Radius server\n   |    EAPoL-start    |                   |\n   |------------------>|                   |\n   |  EAP-Request/ID   |                   |\n   |<------------------|                   |\n   | EAP-Response/ID   |    Radius/ID      |\n   |------------------>|------------------>|\n   | EAP-MD5/Challenge | EAP-MD5/Challenge |\n   |<------------------|<------------------|\n   | EAP-MD5/Response  | EAP-MD5/Response  |\n   |------------------>|------------------>|\n   | EAP Success/Fail  | EAP Success/Fail  |\n   |<------------------|<------------------|\nAlgorithm (|| means concatenation):\nClient response hash [16 bytes] = md5(eapid || password || challenge)\neapid:     id of the EAP response frame [1 byte]\npassword:  user password\nchallenge: server challenge [16 bytes]\nAs I understood it, \"eapid\" should be a 1-byte session identifier, however\nin many cases it's fixed to the default value 0x02. It can be found in\nWireshark by selecting the EAP-MD5/Challenge (Request) packet (802.1X\nAuthentication > Extensible Authentication Protocol > Id)\nAs for the password I don't think there's a minimum or maximum length.\nRather than a .hccap file I'd suggest to use a simple string like:\n$eapmd5$id:challenge:hash\nIt's simplier and one could manually parse it.\nSample data provided with eapmd5pass (link in the sources):\nEAP Id:    02\nChallenge: 00000000000000000000000000000000\nResponse:  9920418b3103652d3b80ffff04da5863\nPassword:  bradtest\nMD5($HEX[02627261647465737400000000000000000000000000000000]) =\n9920418b3103652d3b80ffff04da5863\nSources:\nhttp://www.willhackforsushi.com/?page_id=67\nhttp://www.securitytube.net/groups?operation=view&groupId=9\nhttp://dl.ifip.org/db/conf/wistp/wistp2012/LiuX12.pdf\nAlso, while writing this I found:\nhttps://twitter.com/hashcat/status/425555173428064256\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/296#issuecomment-219133434\n. I ran tools/deps.sh, and I think you may be right as the beta version does not work either, weird that the benchmark still works.\n-----Original Message-----\nFrom: Jens Steube [mailto:notifications@github.com] \nSent: Thursday, April 28, 2016 10:20 PM\nTo: hashcat/oclHashcat\nCc: thesle3p; Author\nSubject: Re: [hashcat/oclHashcat] oclHashcat hangs at startup (#319)\nWhat hashcat deps are you talking about? There should be none left with latest version, see here: https://github.com/hashcat/oclHashcat/blob/master/docs/BUILD.md\nAnyway about your issue, this sounds like some local installation error or broken hardware. Please try again with our precompiled betas to be sure it's not a compilation (and depency) error on your host. You can find them on hashcat.net/beta\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/hashcat/oclHashcat/issues/319#issuecomment-215612582  https://github.com/notifications/beacon/AIqhyJrBEmgI2he9nGq_2QvS6P9FOKrnks5p8WrigaJpZM4IR2Ye.gif \n. I just did a clean install of Ubuntu 16.04, the nvidia driver 361.42 and \n```\ngit clone https://github.com/hashcat/oclHashcat.git\nsudo apt-get install nvidia-opencl-dev\ncd oclHashcat/\nmake \n```\nfollowed by \n./example0.sh\nwhich results in the following to hang indefinitely regardless of whether or not it's ran as root \n```\n./example0.sh \noclHashcat v2.01 (g1e3d843) starting...\nDevice #1: GeForce GTX 980 Ti, 1535/6143 MB allocatable, 1190Mhz, 22MCU\nDevice #2: GeForce GTX 980 Ti, 1535/6143 MB allocatable, 1190Mhz, 22MCU\n```\nI am able to do a full benchmark no problem it's only when I try and actually crack hashes this happens.\n. Same issue, as well as with 500\n-----Original Message-----\nFrom: Jens Steube [mailto:notifications@github.com] \nSent: Friday, April 29, 2016 1:54 PM\nTo: hashcat/oclHashcat\nCc: thesle3p; Author\nSubject: Re: [hashcat/oclHashcat] oclHashcat hangs at startup (#319)\nDoes example400.sh work?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/hashcat/oclHashcat/issues/319#issuecomment-215829689  https://github.com/notifications/beacon/AIqhyNbG_JBSQtjkl3sxSXuQvlUvhc32ks5p8kXVgaJpZM4IR2Ye.gif \n. Switched to the Khronos package and nuked ~/.nv ~/.hashcat.kernels and ~/oclHashcat/Kernels and still persists with -a3 and -a0, I'm about to try switching to the Nvidia .bin driver. Weird benchmarks work just fine.\n. Which version of the binary driver are you using by the way?\n. -d 1 is the same issue but it skips the second device, will try installing the .run driver and go from there.\n. Binary driver fixed it :) It's support like this that makes Hashcat My favorite tool to use the development version of.\n-----Original Message-----\nFrom: Jens Steube [mailto:notifications@github.com] \nSent: Friday, April 29, 2016 2:13 PM\nTo: hashcat/oclHashcat\nCc: thesle3p; Author\nSubject: Re: [hashcat/oclHashcat] oclHashcat hangs at startup (#319)\nNVIDIA-Linux-x86_64-361.18.run\nMaybe try -d 1 too\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub https://github.com/hashcat/oclHashcat/issues/319#issuecomment-215835276  https://github.com/notifications/beacon/AIqhyON99j8C_TKV2M-6Mg6akWMpzEKlks5p8ko0gaJpZM4IR2Ye.gif \n. NVM, I see issue 357 was the same thing but with AMD, which version of the Nvidia driver is working for linux?\n. Not sure how that happened, but a fresh git clone seems to have fixed it, thanks.\n. https://github.com/benhoyt/inih inih might do the trick.\n. Why not have it ignore config files unless otherwise told to? \n. Currently I Do as you suggested and count hash frequency in the hash list but it would be nice if I could --show --outfile-format 2 -o /path/to/file  a hashlist and pass that to pipal to get frequency count along with pipal's other stats .\n-----Original Message-----\nFrom: Royce Williams [mailto:notifications@github.com] \nSent: Thursday, September 22, 2016 9:41 AM\nTo: hashcat/hashcat\nCc: thesle3p; Author\nSubject: Re: [hashcat/hashcat] [feature request] option to crack duplicate hashes in list (#509)\nHmm - to clarify, as part of this feature, it sounds like you'd want hashcat to:\n1.  Only attempt to crack one of the duplicates, ignoring the others but keeping them in memory or accumulating a count of them in some way (otherwise, there would be a massive waste of RAM and processing power), and ...\n2 After a hash is cracked, write all duplicate plains to the potfile, so that statistics could be derived directly from the potfile?\nI think this is probably not what @jsteube https://github.com/jsteube  et al will want to do. Removing duplicates keeps the code simple, keeps GPU RAM usage low, etc.\nAlso, it is trivial to script taking an original hash frequency count and a potfile and generate the statistics. I don't know of a published one, though - it would be nice to have one. What are you currently doing to get the statistics that you need?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/509#issuecomment-248906384 , or mute the thread https://github.com/notifications/unsubscribe-auth/AIqhyORnuXFAsSEnVjv_o7nV-aS-TTvtks5qsoV4gaJpZM4KD05W . https://github.com/notifications/beacon/AIqhyMdAxATI_Us6aslooGQkmwIMnpAzks5qsoV4gaJpZM4KD05W.gif \n. Why not just make it a option that is not turned on by default? I am\njust asking that a feature be added to make generating output suitable\nfor generating statistics easier.\nOn 09/24/2016 08:33 AM, Jens Steube wrote:\n\nTechnically it's not much of a problem, because I could mark the\nnumber of duplicates per hash in the hashes_t structure. But what I\nthink is confusing is that when hashcat cracks such a hash, what\nshould it do. Should it print the hash N times? That could confuse new\nusers here alot, because they wouldn't expect it. Also, hashcat is a\ncracking tool, not a statistics generator. As @roycewilliams\nhttps://github.com/roycewilliams already said, it should be trivial\nto do what you want to do from an external script.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/509#issuecomment-249362537,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyA2aTS8t0papyZ-7CRi__rhL9L4vks5qtRiQgaJpZM4KD05W.\n. I was thinking something  more along the lines of a optional --no-dedupe\n(maybe change the name) that skips the duplicate check/removal process.\nRealistically you would only use this to compare potfile entries to a\nhashlist to output all plaintext values of that hashlist after you are\ndone cracking (maybe have the --help entry specify that if you are\nworried about people using that by accident)\n, for that wouldn't performance be irrelevant?\n\nOn 09/24/2016 02:49 PM, Royce Williams wrote:\n\nI see the appeal. If hashcat optionally accumulated the duplicate\ncount on intake, the duplicate count could be part of an output\nformat, such as:\n16 | duplicatecount:hash[:salt]:plain:hex_plain\n@jsteube https://github.com/jsteube, would accumulating that\nduplicate count slow hash loading/dedupe much?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/509#issuecomment-249381041,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyJh4RgACzNhLYhDREtNcQPqvoVhnks5qtXCwgaJpZM4KD05W.\n. Is there a email address I can send them to?\n\nOn 10/13/2016 04:16 AM, Jens Steube wrote:\n\nI need a way to reproduce, please provide the files required\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/535#issuecomment-253445657,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyAVVNFSPkE8NUIegLcWXkePPb5-7ks5qzejfgaJpZM4KS6s8.\n. Ok, further testing with both beta and git versions shows this only is the case with md5 hashes, I tested SHA-1 and NTLM and it detected and pruned entries from the potfile at run time.I also noticed that with md5 it displays the wrong amount of total hashes  as well as the cracked hashes (if including entries from the potfile) in the recovered field of console output. Could this be a issue in the md5 kernel issue?\n. Apparently a reclone and recompile fixed it, weird...\n. Resolved.. hashcat -D1,2 -m 2500 -a 3 --increment  ../../captures/hs/MRSHAH_2.hccap ?a?a?a?a?a?a?a?a?a?a?a?a?a?a\n```\nsudo clinfo\nNumber of platforms                               2\n  Platform Name                                   Intel(R) OpenCL\n  Platform Vendor                                 Intel(R) Corporation\n  Platform Version                                OpenCL 1.2 LINUX\n  Platform Profile                                FULL_PROFILE\n  Platform Extensions                             cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 \n  Platform Extensions function suffix             INTEL\n\nPlatform Name                                   NVIDIA CUDA\n  Platform Vendor                                 NVIDIA Corporation\n  Platform Version                                OpenCL 1.2 CUDA 8.0.0\n  Platform Profile                                FULL_PROFILE\n  Platform Extensions                             cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts\n  Platform Extensions function suffix             NV\nPlatform Name                                   Intel(R) OpenCL\nNumber of devices                                 1\n  Device Name                                     Intel(R) Core(TM) i7-5820K CPU @ 3.30GHz\n  Device Vendor                                   Intel(R) Corporation\n  Device Vendor ID                                0x8086\n  Device Version                                  OpenCL 1.2 (Build 25)\n  Driver Version                                  1.2.0.25\n  Device OpenCL C Version                         OpenCL C 1.2 \n  Device Type                                     CPU\n  Device Profile                                  FULL_PROFILE\n  Max compute units                               12\n  Max clock frequency                             3300MHz\n  Device Partition                                (core)\n    Max number of sub-devices                     12\n    Supported partition types                     by counts, equally, by names (Intel)\n  Max work item dimensions                        3\n  Max work item sizes                             8192x8192x8192\n  Max work group size                             8192\n  Preferred work group size multiple              128\n  Preferred / native vector sizes               \n    char                                                 1 / 32    \n    short                                                1 / 16    \n    int                                                  1 / 8     \n    long                                                 1 / 4     \n    half                                                 0 / 0        (n/a)\n    float                                                1 / 8     \n    double                                               1 / 4        (cl_khr_fp64)\n  Half-precision Floating-point support           (n/a)\n  Single-precision Floating-point support         (core)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 No\n    Round to infinity                             No\n    IEEE754-2008 fused multiply-add               No\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Double-precision Floating-point support         (cl_khr_fp64)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Address bits                                    64, Little-Endian\n  Global memory size                              67482628096 (62.85GiB)\n  Error Correction support                        No\n  Max memory allocation                           16870657024 (15.71GiB)\n  Unified memory for Host and Device              Yes\n  Minimum alignment for any data type             128 bytes\n  Alignment of base address                       1024 bits (128 bytes)\n  Global Memory cache type                        Read/Write\n  Global Memory cache size                        262144\n  Global Memory cache line                        64 bytes\n  Image support                                   Yes\n    Max number of samplers per kernel             480\n    Max size for 1D images from buffer            1054416064 pixels\n    Max 1D or 2D image array size                 2048 images\n    Max 2D image size                             16384x16384 pixels\n    Max 3D image size                             2048x2048x2048 pixels\n    Max number of read image args                 480\n    Max number of write image args                480\n  Local memory type                               Global\n  Local memory size                               32768 (32KiB)\n  Max constant buffer size                        131072 (128KiB)\n  Max number of constant args                     480\n  Max size of kernel argument                     3840 (3.75KiB)\n  Queue properties                              \n    Out-of-order execution                        Yes\n    Profiling                                     Yes\n    Local thread execution (Intel)                Yes\n  Prefer user sync for interop                    No\n  Profiling timer resolution                      1ns\n  Execution capabilities                        \n    Run OpenCL kernels                            Yes\n    Run native kernels                            Yes\n    SPIR versions                                 1.2\n  printf() buffer size                            1048576 (1024KiB)\n  Built-in kernels                              \n  Device Available                                Yes\n  Compiler Available                              Yes\n  Linker Available                                Yes\n  Device Extensions                               cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 \nPlatform Name                                   NVIDIA CUDA\nNumber of devices                                 2\n  Device Name                                     GeForce GTX 1080\n  Device Vendor                                   NVIDIA Corporation\n  Device Vendor ID                                0x10de\n  Device Version                                  OpenCL 1.2 CUDA\n  Driver Version                                  375.20\n  Device OpenCL C Version                         OpenCL C 1.2 \n  Device Type                                     GPU\n  Device Profile                                  FULL_PROFILE\n  Device Topology (NV)                            PCI-E, 01:00.0\n  Max compute units                               20\n  Max clock frequency                             1822MHz\n  Compute Capability (NV)                         6.1\n  Device Partition                                (core)\n    Max number of sub-devices                     1\n    Supported partition types                     None\n  Max work item dimensions                        3\n  Max work item sizes                             1024x1024x64\n  Max work group size                             1024\n  Preferred work group size multiple              32\n  Warp size (NV)                                  32\n  Preferred / native vector sizes               \n    char                                                 1 / 1     \n    short                                                1 / 1     \n    int                                                  1 / 1     \n    long                                                 1 / 1     \n    half                                                 0 / 0        (n/a)\n    float                                                1 / 1     \n    double                                               1 / 1        (cl_khr_fp64)\n  Half-precision Floating-point support           (n/a)\n  Single-precision Floating-point support         (core)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  Yes\n  Double-precision Floating-point support         (cl_khr_fp64)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Address bits                                    64, Little-Endian\n  Global memory size                              8541110272 (7.955GiB)\n  Error Correction support                        No\n  Max memory allocation                           2135277568 (1.989GiB)\n  Unified memory for Host and Device              No\n  Integrated memory (NV)                          No\n  Minimum alignment for any data type             128 bytes\n  Alignment of base address                       4096 bits (512 bytes)\n  Global Memory cache type                        Read/Write\n  Global Memory cache size                        327680\n  Global Memory cache line                        128 bytes\n  Image support                                   Yes\n    Max number of samplers per kernel             32\n    Max size for 1D images from buffer            134217728 pixels\n    Max 1D or 2D image array size                 2048 images\n    Max 2D image size                             16384x32768 pixels\n    Max 3D image size                             16384x16384x16384 pixels\n    Max number of read image args                 256\n    Max number of write image args                16\n  Local memory type                               Local\n  Local memory size                               49152 (48KiB)\n  Registers per block (NV)                        65536\n  Max constant buffer size                        65536 (64KiB)\n  Max number of constant args                     9\n  Max size of kernel argument                     4352 (4.25KiB)\n  Queue properties                              \n    Out-of-order execution                        Yes\n    Profiling                                     Yes\n  Prefer user sync for interop                    No\n  Profiling timer resolution                      1000ns\n  Execution capabilities                        \n    Run OpenCL kernels                            Yes\n    Run native kernels                            No\n    Kernel execution timeout (NV)                 No\n  Concurrent copy and kernel execution (NV)       Yes\n    Number of async copy engines                  2\n  printf() buffer size                            1048576 (1024KiB)\n  Built-in kernels                              \n  Device Available                                Yes\n  Compiler Available                              Yes\n  Linker Available                                Yes\n  Device Extensions                               cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts\nDevice Name                                     GeForce GTX 1080\n  Device Vendor                                   NVIDIA Corporation\n  Device Vendor ID                                0x10de\n  Device Version                                  OpenCL 1.2 CUDA\n  Driver Version                                  375.20\n  Device OpenCL C Version                         OpenCL C 1.2 \n  Device Type                                     GPU\n  Device Profile                                  FULL_PROFILE\n  Device Topology (NV)                            PCI-E, 02:00.0\n  Max compute units                               20\n  Max clock frequency                             1822MHz\n  Compute Capability (NV)                         6.1\n  Device Partition                                (core)\n    Max number of sub-devices                     1\n    Supported partition types                     None\n  Max work item dimensions                        3\n  Max work item sizes                             1024x1024x64\n  Max work group size                             1024\n  Preferred work group size multiple              32\n  Warp size (NV)                                  32\n  Preferred / native vector sizes               \n    char                                                 1 / 1     \n    short                                                1 / 1     \n    int                                                  1 / 1     \n    long                                                 1 / 1     \n    half                                                 0 / 0        (n/a)\n    float                                                1 / 1     \n    double                                               1 / 1        (cl_khr_fp64)\n  Half-precision Floating-point support           (n/a)\n  Single-precision Floating-point support         (core)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  Yes\n  Double-precision Floating-point support         (cl_khr_fp64)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Address bits                                    64, Little-Endian\n  Global memory size                              8540717056 (7.954GiB)\n  Error Correction support                        No\n  Max memory allocation                           2135179264 (1.989GiB)\n  Unified memory for Host and Device              No\n  Integrated memory (NV)                          No\n  Minimum alignment for any data type             128 bytes\n  Alignment of base address                       4096 bits (512 bytes)\n  Global Memory cache type                        Read/Write\n  Global Memory cache size                        327680\n  Global Memory cache line                        128 bytes\n  Image support                                   Yes\n    Max number of samplers per kernel             32\n    Max size for 1D images from buffer            134217728 pixels\n    Max 1D or 2D image array size                 2048 images\n    Max 2D image size                             16384x32768 pixels\n    Max 3D image size                             16384x16384x16384 pixels\n    Max number of read image args                 256\n    Max number of write image args                16\n  Local memory type                               Local\n  Local memory size                               49152 (48KiB)\n  Registers per block (NV)                        65536\n  Max constant buffer size                        65536 (64KiB)\n  Max number of constant args                     9\n  Max size of kernel argument                     4352 (4.25KiB)\n  Queue properties                              \n    Out-of-order execution                        Yes\n    Profiling                                     Yes\n  Prefer user sync for interop                    No\n  Profiling timer resolution                      1000ns\n  Execution capabilities                        \n    Run OpenCL kernels                            Yes\n    Run native kernels                            No\n    Kernel execution timeout (NV)                 Yes\n  Concurrent copy and kernel execution (NV)       Yes\n    Number of async copy engines                  2\n  printf() buffer size                            1048576 (1024KiB)\n  Built-in kernels                              \n  Device Available                                Yes\n  Compiler Available                              Yes\n  Linker Available                                Yes\n  Device Extensions                               cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts\nNULL platform behavior\n  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  No platform\n  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   No platform\n  clCreateContext(NULL, ...) [default]            No platform\n  clCreateContext(NULL, ...) [other]              Success [INTEL]\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  No platform\n```\nIt also seems to only be a issue when the Intel CPU is used.. Yup.\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: MRSHAH (c4:12:f5:95:f1:2c <-> 34:e2:fd:b7:90:71)\nTime.Started.....: Sun Dec  4 09:24:41 2016 (13 secs)\nTime.Estimated...: Sun Mar  5 17:06:58 2271 (254 years, 91 days)\nInput.Mask.......: ?a?a?a?a?a?a?a?a [8]\nInput.Queue......: 1/7 (14.29%)\nSpeed.Dev.#2.....:   427.7 kH/s (11.43ms)\nSpeed.Dev.#3.....:   399.2 kH/s (6.09ms)\nSpeed.Dev.#*.....:   826.9 kH/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 10362880/6634204312890625 (0.00%)\nRejected.........: 0/10362880 (0.00%)\nRestore.Point....: 0/69833729609375 (0.00%)\nCandidates.#2....: rarinane -> r#:zanan\nCandidates.#3....: 8&<FINAN -> 81;QUSAN\nHWMon.Dev.#2.....: Temp: 52c Fan:  0% Util: 98% Core:1974Mhz Mem:4513Mhz\nLanes:8\nHWMon.Dev.#3.....: Temp: 58c Fan:  0% Util: 97% Core:1936Mhz Mem:4513Mhz\nLanes:16\nOn 12/04/2016 09:40 AM, Jens Steube wrote:\n\nWhat about hardware monitor (Fan, Temp, etc) for the GTX1080's, is\nthat working when you do not use the CPU?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-264707667,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyK0MVOlRd6KUZqDawos7JPJZ3kpSks5rEtDegaJpZM4LDYBb.\n\n\n. yes but it still runs hot due to where the rig is. the temp data is\naccurate.\nOn 12/04/2016 10:00 AM, Jens Steube wrote:\n\nIs this watercooled?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-264708680,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyFdXw-i4D2gddnvd29EzzuHa5weOks5rEtWJgaJpZM4LDYBb.\n\n\n. Just wpa\nOn Dec 6, 2016 6:39 AM, \"Jens Steube\" notifications@github.com wrote:\n\nOK, I was just wondering about the 0% fan speed and that one:\n[quote]\nWatchdog: Temperature retain trigger disabled\n[/quote]\nSo that's correct then.\nAbout that CPU error, does that occur only with WPA?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-265129123,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyAnwXGENLweSDQlZu4k1TZ3hjmgpks5rFUlegaJpZM4LDYBb\n.\n. Just encountered it with 2100\nOn 12/06/2016 06:39 AM, Jens Steube wrote:\nOK, I was just wondering about the 0% fan speed and that one:\n[quote]\nWatchdog: Temperature retain trigger disabled\n[/quote]\nSo that's correct then.\nAbout that CPU error, does that occur only with WPA?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-265129123,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyAnwXGENLweSDQlZu4k1TZ3hjmgpks5rFUlegaJpZM4LDYBb.\n. same issue with -w 1\n\nOn 12/07/2016 06:39 AM, Jens Steube wrote:\n\nBoth 2100 and 2500 are slow hashes. Maybe the runtime doesn't like\nlong running kernels, like with OSX. Can you retry with -w 1?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-265425934,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyFb8Eul-D-RA5lFihAkl5_SMvuOhks5rFprwgaJpZM4LDYBb.\n\n\n. I am not sure it's a OpenCL issue as  version 3.20 does not have this issue.\nOn 12/09/2016 09:13 AM, Jens Steube wrote:\n\nI've tried to reproduce in my Intel CPU + NVIDIA GPU system but can't.\nIt seems like you're using the correct Intel OpenCL runtime. For some\nreason however my clinfo shows the devices reversed, so the GPU first,\nthen the CPU. I don't think this is the reason of the problem but\nindicates that there's some OpenCL installation difference between our\nversions. Anyway it doesn't seem to be a hashcat problem, so please\nlet's continue to find the source of the problem on hashcat forum. The\ngithub is only for bugs and feature requests.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/905#issuecomment-266023055,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyGV7fpCrTVW--4FgK0_xiDn0xellks5rGWIjgaJpZM4LDYBb.\n\n\n. Most recent commit seems to have fixed this. Looks like it's only with -a 0 tested 6 and 3 no problem. with WPA that is.. would be great to see this.. I am seeing this error on Ubuntu 16.04 but with -m 1811. my mistake 2811\nOn 08/05/2018 11:09 PM, w3soul wrote:\n\nAre you sure it's -m 1811 ?? I am not seeing 1811 hashmode, is it 1800 ?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1640#issuecomment-410576863,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AIqhyGbu50jySnYP7Yc3lpS6qQAYSuW-ks5uN7NzgaJpZM4Vne3O.\n\n\n. fixed. the command that led to this was \n```\nhashcat -m 2811 --username '/path/to/hashlist' /path/to/wordlist  \nHere is a backtrace from gdb\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7ffff71527e5]\n/lib/x86_64-linux-gnu/libc.so.6(__fortify_fail+0x5c)[0x7ffff71f415c]\n/lib/x86_64-linux-gnu/libc.so.6(+0x117160)[0x7ffff71f2160]\n/home/user/Toolz/hashcat/hashcat[0x431d78]\n/home/user/Toolz/hashcat/hashcat[0x431f48]\n/home/user/Toolz/hashcat/hashcat[0x469ff1]\n/home/user/Toolz/hashcat/hashcat[0x417ef4]\n/home/user/Toolz/hashcat/hashcat[0x418682]\n/home/user/Toolz/hashcat/hashcat[0x40400b]\n/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7ffff70fb830]\n/home/user/Toolz/hashcat/hashcat[0x4029d9]\n======= Memory map: ========\n00400000-004c2000 r-xp 00000000 fd:01 47320506                           /home/user/Toolz/hashcat/hashcat\n006c1000-006c2000 r--p 000c1000 fd:01 47320506                           /home/user/Toolz/hashcat/hashcat\n006c2000-006c3000 rw-p 000c2000 fd:01 47320506                           /home/user/Toolz/hashcat/hashcat\n006c3000-0fff0000 rw-p 00000000 00:00 0                                  [heap]\n10000000-20000000 ---p 00000000 00:00 0 \n200000000-400200000 ---p 00000000 00:00 0 \n10000000000-10200000000 ---p 00000000 00:00 0 \n7ffe00eab000-7ffefb7b6000 rw-p 00000000 00:00 0 \n7fffc2869000-7fffc9a69000 rw-p 00000000 00:00 0 \n7fffcf2ac000-7fffcf2c2000 r-xp 00000000 fd:01 58986935                   /lib/x86_64-linux-gnu/libgcc_s.so.1\n7fffcf2c2000-7fffcf4c1000 ---p 00016000 fd:01 58986935                   /lib/x86_64-linux-gnu/libgcc_s.so.1\n7fffcf4c1000-7fffcf4c2000 rw-p 00015000 fd:01 58986935                   /lib/x86_64-linux-gnu/libgcc_s.so.1\n7fffcf4c2000-7fffe5e25000 rw-p 00000000 00:00 0 \n7fffe5e25000-7fffe5e26000 ---p 00000000 00:00 0 \n7fffe5e26000-7fffe6626000 rw-p 00000000 00:00 0 \n7fffe6626000-7fffe6752000 r-xp 00000000 fd:01 117053769                  /usr/lib/nvidia-384/libnvidia-ml.so.384.130\n7fffe6752000-7fffe6952000 ---p 0012c000 fd:01 117053769                  /usr/lib/nvidia-384/libnvidia-ml.so.384.130\n7fffe6952000-7fffe6967000 rw-p 0012c000 fd:01 117053769                  /usr/lib/nvidia-384/libnvidia-ml.so.384.130\n7fffe6967000-7fffe6bfe000 rw-p 00000000 00:00 0 \n7fffe6bfe000-7fffe771e000 r-xp 00000000 fd:01 116921533                  /usr/lib/x86_64-linux-gnu/libcuda.so.384.130\n7fffe771e000-7fffe791d000 ---p 00b20000 fd:01 116921533                  /usr/lib/x86_64-linux-gnu/libcuda.so.384.130\n7fffe791d000-7fffe7a6e000 rw-p 00b1f000 fd:01 116921533                  /usr/lib/x86_64-linux-gnu/libcuda.so.384.130\n7fffe7a6e000-7fffe7a7c000 rw-p 00000000 00:00 0 \n7fffe7a7c000-7fffeda7c000 ---p 00000000 00:00 0 \n7fffeda7c000-7fffedabf000 r-xp 00000000 fd:01 117053795                  /usr/lib/nvidia-384/libnvidia-fatbinaryloader.so.384.130\n7fffedabf000-7fffedcbe000 ---p 00043000 fd:01 117053795                  /usr/lib/nvidia-384/libnvidia-fatbinaryloader.so.384.130\n7fffedcbe000-7fffedcc9000 rw-p 00042000 fd:01 117053795                  /usr/lib/nvidia-384/libnvidia-fatbinaryloader.so.384.130\n7fffedcc9000-7fffedcce000 rw-p 00000000 00:00 0 \n7fffedcce000-7fffee575000 r-xp 00000000 fd:01 116921544                  /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.384.130\n7fffee575000-7fffee774000 ---p 008a7000 fd:01 116921544                  /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.384.130\n7fffee774000-7fffee8ca000 rw-p 008a6000 fd:01 116921544                  /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.384.130\n7fffee8ca000-7fffee8d8000 rw-p 00000000 00:00 0 \n7fffee8d8000-7fffee8e1000 r-xp 00000000 fd:01 116921542                  /usr/lib/x86_64-linux-gnu/libOpenCL.so.1.0.0\n7fffee8e1000-7fffeeae1000 ---p 00009000 fd:01 116921542                  /usr/lib/x86_64-linux-gnu/libOpenCL.so.1.0.0\n7fffeeae1000-7fffeeae2000 r--p 00009000 fd:01 116921542                  /usr/lib/x86_64-linux-gnu/libOpenCL.so.1.0.0\n7fffeeae2000-7fffeeae3000 rw-p 0000a000 fd:01 116921542                  /usr/lib/x86_64-linux-gnu/libOpenCL.so.1.0.0\n7fffeeae3000-7ffff70db000 rw-p 00000000 00:00 0 \n7ffff70db000-7ffff729b000 r-xp 00000000 fd:01 58986897                   /lib/x86_64-linux-gnu/libc-2.23.so\n7ffff729b000-7ffff749b000 ---p 001c0000 fd:01 58986897                   /lib/x86_64-linux-gnu/libc-2.23.so\n7ffff749b000-7ffff749f000 r--p 001c0000 fd:01 58986897                   /lib/x86_64-linux-gnu/libc-2.23.so\n7ffff749f000-7ffff74a1000 rw-p 001c4000 fd:01 58986897                   /lib/x86_64-linux-gnu/libc-2.23.so\n7ffff74a1000-7ffff74a5000 rw-p 00000000 00:00 0 \n7ffff74a5000-7ffff75ad000 r-xp 00000000 fd:01 58986967                   /lib/x86_64-linux-gnu/libm-2.23.so\n7ffff75ad000-7ffff77ac000 ---p 00108000 fd:01 58986967                   /lib/x86_64-linux-gnu/libm-2.23.so\n7ffff77ac000-7ffff77ad000 r--p 00107000 fd:01 58986967                   /lib/x86_64-linux-gnu/libm-2.23.so\n7ffff77ad000-7ffff77ae000 rw-p 00108000 fd:01 58986967                   /lib/x86_64-linux-gnu/libm-2.23.so\n7ffff77ae000-7ffff77b5000 r-xp 00000000 fd:01 58987051                   /lib/x86_64-linux-gnu/librt-2.23.so\n7ffff77b5000-7ffff79b4000 ---p 00007000 fd:01 58987051                   /lib/x86_64-linux-gnu/librt-2.23.so\n7ffff79b4000-7ffff79b5000 r--p 00006000 fd:01 58987051                   /lib/x86_64-linux-gnu/librt-2.23.so\n7ffff79b5000-7ffff79b6000 rw-p 00007000 fd:01 58987051                   /lib/x86_64-linux-gnu/librt-2.23.so\n7ffff79b6000-7ffff79b9000 r-xp 00000000 fd:01 58986921                   /lib/x86_64-linux-gnu/libdl-2.23.so\n7ffff79b9000-7ffff7bb8000 ---p 00003000 fd:01 58986921                   /lib/x86_64-linux-gnu/libdl-2.23.so\n7ffff7bb8000-7ffff7bb9000 r--p 00002000 fd:01 58986921                   /lib/x86_64-linux-gnu/libdl-2.23.so\n7ffff7bb9000-7ffff7bba000 rw-p 00003000 fd:01 58986921                   /lib/x86_64-linux-gnu/libdl-2.23.so\n7ffff7bba000-7ffff7bd2000 r-xp 00000000 fd:01 58987043                   /lib/x86_64-linux-gnu/libpthread-2.23.so\n7ffff7bd2000-7ffff7dd1000 ---p 00018000 fd:01 58987043                   /lib/x86_64-linux-gnu/libpthread-2.23.so\n7ffff7dd1000-7ffff7dd2000 r--p 00017000 fd:01 58987043                   /lib/x86_64-linux-gnu/libpthread-2.23.so\n7ffff7dd2000-7ffff7dd3000 rw-p 00018000 fd:01 58987043                   /lib/x86_64-linux-gnu/libpthread-2.23.so\n7ffff7dd3000-7ffff7dd7000 rw-p 00000000 00:00 0 \n7ffff7dd7000-7ffff7dfd000 r-xp 00000000 fd:01 58986869                   /lib/x86_64-linux-gnu/ld-2.23.so\n7ffff7ed3000-7ffff7fd8000 rw-p 00000000 00:00 0 \n7ffff7ff6000-7ffff7ff7000 rw-p 00000000 00:00 0 \n7ffff7ff7000-7ffff7ffa000 r--p 00000000 00:00 0                          [vvar]\n7ffff7ffa000-7ffff7ffc000 r-xp 00000000 00:00 0                          [vdso]\n7ffff7ffc000-7ffff7ffd000 r--p 00025000 fd:01 58986869                   /lib/x86_64-linux-gnu/ld-2.23.so\n7ffff7ffd000-7ffff7ffe000 rw-p 00026000 fd:01 58986869                   /lib/x86_64-linux-gnu/ld-2.23.so\n7ffff7ffe000-7ffff7fff000 rw-p 00000000 00:00 0 \n7ffffffde000-7ffffffff000 rw-p 00000000 00:00 0                          [stack]\nffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0                  [vsyscall]\nThread 1 \"hashcat\" received signal SIGABRT, Aborted.\n0x00007ffff7110428 in __GI_raise (sig=sig@entry=6)\n    at ../sysdeps/unix/sysv/linux/raise.c:54\n54  ../sysdeps/unix/sysv/linux/raise.c: No such file or directory.\n(gdb) backtrace\n0  0x00007ffff7110428 in __GI_raise (sig=sig@entry=6)\nat ../sysdeps/unix/sysv/linux/raise.c:54\n\n1  0x00007ffff711202a in __GI_abort () at abort.c:89\n2  0x00007ffff71527ea in __libc_message (do_abort=do_abort@entry=2,\nfmt=fmt@entry=0x7ffff726a49f \"*** %s ***: %s terminated\\n\")\nat ../sysdeps/posix/libc_fatal.c:175\n\n3  0x00007ffff71f415c in __GI___fortify_fail (msg=,\nmsg@entry=0x7ffff726a430 \"buffer overflow detected\") at fortify_fail.c:37\n\n4  0x00007ffff71f2160 in __GI___chk_fail () at chk_fail.c:28\n5  0x0000000000431d78 in memcpy (__len=75, __src=0x7fffc287d5b0,\n__dest=0x7fffffffccc0) at /usr/include/x86_64-linux-gnu/bits/string3.h:53\n\n6  precompute_salt_md5 (\nsalt=salt@entry=0x7fffc287d5b0 \"$HEX[e0b9852f2de0b8a0e0b896e0b8b8e0b8b6e0b8cfd2b152f24efe599c04a0300b0ca4b3\", salt_len=75, \nsalt_pc=salt_pc@entry=0x7fffc287d6b0 \"\") at src/interface.c:2707\n\n7  0x0000000000431f48 in md5s_parse_hash (input_buf=,\ninput_len=<optimized out>, hash_buf=<optimized out>, hashconfig=0x6ce330)\nat src/interface.c:4336\n\n8  0x0000000000469ff1 in potfile_remove_parse (\nhashcat_ctx=hashcat_ctx@entry=0x6c3010) at src/potfile.c:643\n\n9  0x0000000000417ef4 in outer_loop (hashcat_ctx=hashcat_ctx@entry=0x6c3010)\nat src/hashcat.c:502\n\n10 0x0000000000418682 in hashcat_session_execute (\n---Type  to continue, or q  to quit--- \n    hashcat_ctx=hashcat_ctx@entry=0x6c3010) at src/hashcat.c:1207\n11 0x000000000040400b in main (argc=8, argv=0x7fffffffde88) at src/main.c:1060\n```. fixed. ",
    "p1pkin": "that information / data required ?\nif you mean input data format - I can provide chapcrack \"token\" description.\n. @magnumripper  can you please point to NTLMv1 input format ?\ncloudcracker have it base64 encoded 26bytes, 8bytes plain data and 2x DES encrypted data using 2x different keys, followed by least significant 2 bytes of MD4 hash recovered by chapcrack tool itself.\nactually I'm looking for the way to BF random unknown DES keys, having decrypted and encrypted data. can you plz give advice in what form input values must be feed to oclhashcat ?\n. @magnumripper thanks, you right, 5500 is not helpful at all for my task.\nas I see in 245301c9b444616aa083ef8fda83decbc690f4c1 on recent hardware DES BF speed is ~400M/s which is about 5 years for full run, right ? if so - it's not really acceptable for practical use.\npractical use in my case is recovering lost DES keys for various 10-15 year old software (for arcade machines, I'm member of MAME project)\nwe used cloudcracker's MS-CHAPv2 FPGA BF service for this task, but it's server is down during few last month, so we are looking for alternatives now.\nPS: sorry for out of topic\n. thanks for explanation. 20GH/s sounds pretty cool.\n\nif someone wrote a format for it\n\nwhat means format in this context, .cl module or just some input parser ?\n. >  I think oclHashcat would do over 20 GH/s per GPU \ndid some quick hack/editing, in m05500_a3.cl commented out such things: MD4 password increments, 2nd DES key schedule and decrypt, skip of non-ASCII passwords ... and (unsurprisingly) because of last change - BF becomes significantly slower.\nafter quick tests I got ~2.1GH/s on my HD6870, and about 2x faster on fellow's AMD 290\nany ideas why it is not even close to 20GH/s ?\nPS: used current git code selfcompiled using Msys64 on win32 x64\n. thank you very much!\nmay I ask about approximate speed on recent GPUs ?\n-b -m 14000 on old hd6870 gives only about 337.0 MH/s\n. ",
    "sebdotv": "I have a similar request here, except that I need to iterate on SHA1( $salt.$password )), where $salt is binary. I could probably emulate my needs if requested algorithm was implemented, by using an empty $salt and including my binary $salt into $password keyspace.\nAn example implementation of original request is class UsernameTokenUtil from Apache WSS4J.\n(https://svn.apache.org/repos/asf/webservices/wss4j/trunk/ws-security-common/src/main/java/org/apache/wss4j/common/util/UsernameTokenUtil.java).\nExample hash of original request:\npassword: hashcat(ascii)\nsalt: 2016(ascii)\niterations: 1000\nhash: ZjhhYPVDGgqaTSasfwFPZoejm6w= (base64)\n. ",
    "homes32": "http://keepass.info/help/base/security.html\nis a good place to start as it explains exactly how the 256-bit key for the block cipher is generated.\n. IMHO for this sort of thing its better to script using batch/bash/etc (you could even accept input before building the hashcat cmd line and executing) or use another tool like Hashacat-GUI (which remembers your options) then to build a config parser into hashcat at this point.\n. ",
    "darianf01": "this is not fixed on 3.10.\ntried with a gtx1060 and 550ti\nwhile running with -d 1 (e.g. 1060) i get the h/w monitor of the 550ti but hashcat running on1060.\nwhile running with -d 2 (e.g. 550ti) i get stats for the 1060, while hashcat runs on 550ti.\nwindows 10 64 bit (and nvidia 373.06, although i believe this does not matter). ",
    "hops": "The following has been tested with OpenCart 2.1.0.2 released on January 12, 2016.\nLength of the salt is always 9. The possible characters are:\nABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\nPasswords have to be in the range of 4 to 20 characters.\nThis is hardcoded and can't be changed in the settings.\nThe check uses mb_strlen() with UTF-8 as encoding so a multi-byte character will be counted as 1.\nThe password hashing scheme is still the same. sha1($salt.sha1($salt.sha1($pass)))\nAll of the above is true for both the customers and the admin users.\nHere are two example hash:salt pairs both having the password set to \"hashcat\".\n010a5d86210ea0b6a940d0d5ac0ef18a95eee3be:Xm4acCHwq\nacb2c573b2293673f1bc6f7a46bd929f7ce3be73:JN0tj1J2U\nIf you need more information let me know.\n. I'm pretty sure on the 3200 Mobility Controller running ArubaOS 6.1.1.0 (quite old) the limit is 32.\nI currently don't have access to that device, but can test it tomorrow evening.\nAlso I'll ask someone I know who has more up to date devices to test the limit.. @jsteube The maximum password lenght is definitely 32 characters.\nIt has been tested on a 3200 mobility controller running ArubaOS version 6.4.4.14 (compiled on 22th of June 2017) and a 7210 mobility controller running ArubaOS running 6.4.4.8 and 6.5.1.2.\nIn which documentation did you see the 64 characters limit? Maybe that was for different products?. This would be fairly easy to add.\nDo you know what software is using this scheme?\nIs there a min/max length of the salt?\n. That looks like hashes from OpenCart and is supported since hashcat v3.10\nhttps://github.com/hashcat/hashcat/blob/master/docs/changes.txt#L334. I was the one who added this to hashcat that's why I've noticed the scheme and especially the password length restriction.\nBtw. OpenCart uses PHP's mb_strlen() for the length check. This means that a multibyte UTF-8 encoded character counts only as one.\nThat's the reason I didn't enforce any length checks in hashcat for this hashmode.\nSince this has been resolved, please close this issue.. You will see the build log if you compile hashcat with make DEBUG=1.\nFor example:\n```\n Device #2: build_opts '-cl-std=CL1.2 -I OpenCL -I /home/hops/src/hashcat/OpenCL -D VENDOR_ID=32 -D CUDA_ARCH=601 -D AMD_ROCM=0 -D VECT_SIZE=2 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=1000 -D _unroll'\n Device #2: Kernel m01000_a3-optimized.f6f629d0.kernel not found in cache! Building may take a while...\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n:178:24: error: expected ';' at end of declaration\n  const u8 error = 0x23\n                       ^\n                       ;\n\nDevice #2: Kernel /home/hops/src/hashcat/OpenCL/m01000_a3-optimized.cl build failed - proceeding without this device.\n```. > there isn't any core-file present, where would I look for that?\n\nMost likely systemd \"hides\" that from you. Try coredumpctl debug. This will start gdb with the last coredump.\nIf you don't have systemd then I don't know where core file could be. However you could try this:\ngdb --args ./hashcat --opencl-platforms=2 -b and in the gdb prompt enter run. The crash happens inside Intel's OpenCL library. There's probably not much hashcat can do about this.\nIt works on my Ubuntu 16.04 machine with the same driver version though my CPU is a i7-6700K.\nI don't have a Xeon E5-2623. You could try with Ubuntu 16.04.. I only found the bug today and can't test it with older drivers.\nI added some debug printf's here: https://github.com/hashcat/hashcat/blob/master/OpenCL/m03000_a1-pure.cl#L800 (is there a better way?)\nprintf(\"w0[0]: %08x\\n\", w0[0]);\n    printf(\"w0[1]: %08x\\n\", w0[1]);\nNow running the self-test results in this:\nw0[0]: 68736168\nw0[1]: 00746163\nWhich is \"hashcat\"\n$ echo -n 68736168 | xxd -r -p | rev\nhash\n$ echo -n  746163 | xxd -r -p | rev\ncat\nSo it looks like the self-test plaintext is not converted to uppercase and therefore calculates the wrong hash.\nI hope this helps in resolving this bug.. I had a closer look and have a possible solution.\nThe problem is not LM specific but with all hashmodes having set the OPTS_TYPE_PT_UPPER.\nI've attached a diff and unless you find a better solution I'll create a pull requests shortly.\nselftest.diff.txt\n. @jsteube Yes I'm working on it. Unfortunately I can't finish this today, I'll continue tomorrow.\n@roycewilliams That's what I was asking myself and password manager was the category that fitted the most. I'm open to other suggestions.. I amended the commit including the changes to test.pl and test.sh.\nMy perl foo isn't the best so please double check my changes.\nHowever the tests pass on a GTX 1080 and a i7-6700K.. Looks like this got changed yesterday with commit ce9b56e.\nThe beta build available at https://hashcat.net/beta should already include this fix.. ",
    "TamtamHero": "That would be great :+1: . ",
    "cryptolovi": "I did ran the above tests again on a 24+ GPU machine with hashcat (v3.00-beta-44-g5d5d1a5) linux 64 bit compiled from sources. The problem described doesn't occur anymore, even with a dictionary containing 1 entry. Both modes 6 and 7 find the hash values now.\n. No worries, thank you guys for such a well made product. \n. Version: hashcat (v3.00-6-ge73f6f5)\n. ",
    "A-Circle-Zhang": "@epixoip Thank you! but I think it's too slow for me...\n6.40 MH/s current, 6.40 MH/s average\n. @epixoip \nI'm not trying to find some collisions, I'm trying to find a salt string.\nsubstr(md5(a1 + salt + b1), 0, 6) = hash1\nsubstr(md5(a2 + salt + b2), 0, 6) = hash2\nsubstr(md5(a3 + salt + b3), 0, 6) = hash3\n...\na1, a2, a3, b1, b2, b3, hash1, hash2, hash3 ... is known, I want to crack the salt. maybe 8 bytes or longer.\n. ",
    "claunia": "Interesting I was searching for substr(md5(md5($pass))).\n. ",
    "rhertzog": "Yes, I'm speaking specifically of ADL SDK, the one that can be downloaded here: http://developer.amd.com/tools-and-sdks/graphics-development/display-library-adl-sdk/ and that forces you to accept http://developer.amd.com/amd-license-agreement/ where it says that \u201c9.  Additional Licenses.  DISTRIBUTION OR USE OF THE SOFTWARE WITH AN OPERATING SYSTEM MAY REQUIRE ADDITIONAL LICENSES FROM THE OPERATING SYSTEM VENDOR.\" and also that you don't have the right to electronically transfer the software except for purposes allowed by the license (which amounts to backup purpose only as far I can see).\nA debian source package can \"build-depend\" on other packages to make anything needed available at build time. Thus if the ADL SDK is needed, it needs to be packaged, but this is not possible due to its license. :-| (And obviously I want a proper package that builds native binaries from source)\nFTR, I don't know much about usage of all those GPU SDK, but I\u00a0discovered that Debian has OpenCL and Installable Client Driver (ICD) for AMD/Nvidia and more:\nhttps://packages.debian.org/sid/amd-opencl-icd\nhttps://packages.debian.org/sid/nividia-opencl-icd\nAnd I was thus hoping that it would be possible to build oclHashcat relying only on OpenCL only and thus hide the hardware-specific code behind OpenCL. That's possibly what you explained in point 2... if yes, then it's great. But then why is ADL SDK still needed? Is it because OpenCL does not provide enough features to manage the hardware (you say \"avoid burning their hardware\") ?\n. I will give a try at bundling only the ADL SDK headers in my source package. That said if @magnumripper is correct that this falls under \"fair use\", then you might want to consider doing this direcly. Provide the header in your git repository (and release) so that users do not have to download the ADL SDK at all.\nThat said it would still be nice if oclHashcat was buildable without those headers since they are effectively a non-free dependency which will prevent the inclusion of oclHashcat in Debian main. But if we can build without it, it could be included and it would still provide value to users of non-AMD GPU... if we get to that point, maybe the hardware management layer that requires the non-free parts can then be externalized to a plugin that can be separately built (and provided in Debian contrib or non-free).\n. @magnumripper I built it successfully embedding only the header files (3\u00a0for ADL, 1 for Nvidia).\n@jsteube I understand but when you build a package for a distribution, you want it usable for all users, whatever their hardware. And you still want to keep the package in main if possible (instead of non-free). So the code that requires the non-free header files ought to be compilable separately from the main code (in a non-free package), building a plugin that the main code can dlopen() to handle hardware management. Or something similar.\n. @jsteube For the short term: include the 4\u00a0header files for ADL/NV directly in your git repository and update the bulid machinery to find them here (instead of /opt/something).\nIn the long term, enhance the project so that the parts requiring those headers can be compiled separately as a plugin that can then be loaded by oclhashcat. That way oclhashcat can be in Debian main, and non-free can have the plugin which need those files to be built.\n. @jsteube It's up to you to make that call. It's certainly nice to have achieved this but given that hardware monitoring is an important feature it would be even better if it could be enabled on a plain oclhashcat binary compiled without it just by intsalling a plugin that the main binary would then pick up automatically. And we should be able to build that plugin in a standalone way.\n. @magnumripper In general, I would agree with you and I would not object to this. But my suggestion is specifically to address the requirements of Debian. In Debian main, all files from the source package must be under a DFSG-compatible free license and the header files required for building hardware monitoring code for AMD/NV would thus be stripped from the source package. And it would thus not be possible to compile that feature in oclhaschat. Even if the user installs the required libs afterwards, it would not work. In that scenario, we should provide a second copy of oclhashcat in non-free that would replace/divert the one provided in main...\nTo avoid that duplication I was thus suggesting that the hardware monitoring code could be compiled separately and be used at run-time by the oclhashcat binary provided in the main package.\n. On Mon, 25 Jan 2016, magnum wrote:\n\nIf I understand you correctly, you can't distribute JtR Jumbo at all\nbecause we currently do provide the AMD headers in our source tree, and\nhave done so for two years.\n\nFYI JtR Jumbo is not in Debian, only in Kali.\n\nIf I were to create an independent header file with an MIT license (for\nuse by both projects) that has all glue we need for NV and AMD, would\nthat solve this problem? If not, I give up.\n\nYes, this would be enough I believe.\nCheers,\nRapha\u00ebl Hertzog \u25c8 Debian Developer\nSupport Debian LTS: http://www.freexian.com/services/debian-lts.html\nLearn to master Debian: http://debian-handbook.info/get/\n. @jsteube libnvidia-ml.so is available in the libnvidia-ml1 package but i'm not sure how to best get it installed... nvidia-opencl-icd has no functional dependency on that library so it doesn't look like the correct place. hashcat can work with multiple GPU so it's not the proper place either.\nMaybe we should create binary packages hashcat-nvidia, hashcat-intel, hashcat-amd that would have the correct dependency on each OpenCL module + additional requirements for hardware monitoring ?. @jsteube So the bug reporter already had libnvidia-ml1 installed... the issue is somewhere else. He provided this backtrace:\n```\nhashcat (v3.30) starting in benchmark mode...\n\nDevice https://bugs.kali.org/view.php?id=1: Old CUDA compute capability 3.0\ndetected, OpenCL performance is reduced.\n             For ideal hashcat performance on NVIDIA GPU you need CUDA compute\ncapability 5.0 or higher (Maxwell)\n\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007ffff7b62484 in hm_NVML_nvmlDeviceGetPowerManagementLimit (\n    limit=0x7fffffffdfdc, device=0x0, hashcat_ctx=0x555555759010)\n    at src/hwmon.c:1012\n1012    src/hwmon.c: No such file or directory.\n(gdb) bt\n0  0x00007ffff7b62484 in hm_NVML_nvmlDeviceGetPowerManagementLimit (\nlimit=0x7fffffffdfdc, device=0x0, hashcat_ctx=0x555555759010)\nat src/hwmon.c:1012\n\n1  hwmon_ctx_init(hashcat_ctx=hashcat_ctx@entry=0x555555759010)\nat src/hwmon.c:3894\n\n2  0x00007ffff7b5b504 in hashcat_session_init(hashcat_ctx=0x555555759010,\ninstall_folder=0x5555555565c6 \"/usr/bin\",\nshared_folder=0x5555555565b3 \"/usr/share/hashcat\", argc=4,\nargv=0x7fffffffe2a8, comptime=1484845219) at src/hashcat.c:1025\n\n3  0x0000555555555203 in main (argc=4, argv=0x7fffffffe2a8) at src/main.c:975\n(gdb)\n. That seems wrong in general:\n$ apt-file show libnvidia-ml1\nlibnvidia-ml1: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so\nlibnvidia-ml1: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1\nlibnvidia-ml1: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.304.131\n$ cat /etc/ld.so.conf.d/x86_64-linux-gnu.conf \nMultiarch support\n/lib/x86_64-linux-gnu\n/usr/lib/x86_64-linux-gnu\n```. No, I wanted to show the precise location of the library. Actually the version in Kali (and Debian Testing) is version 375.39-1 but it's in the same location which is in the usual library search path. This was just a bad copy-paste because I picked the output that referred to an older version of Debian.. I know of this but using epoch is just ugly... epoch makes sense when you switch from a date-based versioning scheme back to a traditional version number. But otherwise it's really just up to upstream to bump the version numbers appropriately. We are not short on numbers and going with 4.x to reset the versioning scheme is certainly fine.. History is history, I don't want to rewrite it but I'll wait @jsteube answer here for now before deciding to put an epoch. The epoch is completely non-revertable once used and changes the version number displayed in quite a few places. Instead of 3.6.0, users will see 1:3.6.0 and will wonder what this mean.. Blah, it's not my fault if you meant 3.4.0 and you used 3.40. 40 is a number and the error is not in the system... I understand 4.0.0 would be a violation of the semantic versioning but going backwards is also a violation of the semantic versioning. In that case you could just continue with 3.61.0, 3.62.0, 3.63.0... (I suggest this and not 3.41.0, 3.42.0, 3.43.0 because I used 3.50 in Kali and 3.60 in Debian to work around the lower version number).. ",
    "me-scotty": "HD6990 on v2.01\nPerhaps this is an AMD thing?\nOr fixed in beta?\nReally good news that NVidia okay.\nPast time that I updated anyways...\nMany thanks.\n. It's nice to be able to try current beta (alpha really) - to see what you guys are up to.\nAnybody who does should understand that this is a work-in-progress.\nSo...\nExact same launch parameters as above.\nWith this hardware at least, system becomes barely responsive.\nAnd temp control problems - didn't settle down until MSI Afterburner launched.\nBut now single salt performance nearly the same.\nThe bad news is that both are a fraction of the previous performance.\nNote below that utilization shows 0%, but system response acts like 100%\n\noclHashcat-2.10b44.7z\noclHashcat v2.10 starting...\nDevice #1: skipped\nDevice #2: Cayman, 512/2048 MB allocatable, 880Mhz, 24MCU\nDevice #3: Cayman, 512/2048 MB allocatable, 880Mhz, 24MCU\nDevice #4: skipped\nHashes: 13 hashes; 13 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n- Zero-Byte\n- Precompute-Final-Permutation\n- Not-Iterated\n- Single-Salt\n- Brute-Force\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger set to 80c\nDevice #1: Kernel C:\\utils\\unix-utils\\usr\\local\\console\\oclHashcat-2.10beta/OpenCL/m01500_a3.cl (128532 bytes)\nDevice #1: Kernel C:\\utils\\unix-utils\\usr\\local\\console\\oclHashcat-2.10beta/kernels/markov_le.13581e63.kernel (44956 bytes)\nDevice #2: Kernel C:\\utils\\unix-utils\\usr\\local\\console\\oclHashcat-2.10beta/OpenCL/m01500_a3.cl (128532 bytes)\nDevice #2: Kernel C:\\utils\\unix-utils\\usr\\local\\console\\oclHashcat-2.10beta/kernels/markov_le.13581e63.kernel (44956 bytes)\nSession.Name...: all\nStatus.........: Running\nInput.Mode.....: Mask (?1?1?1?1?1?1?1?1) [8]\nHash.Target....: xxxxxxxxxxxxx\nHash.Type......: descrypt, DES(Unix), Traditional DES\nTime.Started...: Wed Jan 13 15:24:39 2016 (1 min, 49 secs)\nTime.Estimated.: Fri Oct 20 00:11:34 2017 (1 year, 280 days)\nSpeed.Dev.#1...:  2186.9 kH/s\nSpeed.Dev.#2...:  2187.1 kH/s\nSpeed.Dev.#*...:  4374.1 kH/s\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 427819008/218340105584896 (0.00%)\nRejected.......: 0/427819008 (0.00%)\nRestore.Point..: 0/916132832 (0.00%)\nHWMon.GPU.#1...:  0% Util, 58c Temp, 69% Fan\nHWMon.GPU.#2...:  0% Util, 61c Temp, 30% Fan\nSession.Name...: all\nStatus.........: Running\nInput.Mode.....: Mask (?1?1?1?1?1?1?1?1) [8]\nHash.Target....: File (C:\\xxx\nHash.Type......: descrypt, DES(Unix), Traditional DES\nTime.Started...: Wed Jan 13 15:29:20 2016 (20 secs)\nTime.Estimated.: Fri Apr 06 19:50:01 2018 (2 years, 84 days)\nSpeed.Dev.#1...:  1763.8 kH/s\nSpeed.Dev.#2...:  1763.6 kH/s\nSpeed.Dev.#*...:  3527.5 kH/s\nRecovered......: 0/13 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 62914560/218340105584896 (0.00%)\nRejected.......: 0/62914560 (0.00%)\nRestore.Point..: 0/916132832 (0.00%)\nHWMon.GPU.#1...:  0% Util, 54c Temp, 69% Fan\nHWMon.GPU.#2...:  0% Util, 53c Temp, 30% Fan\n. ",
    "STUCK12": "Seconded. Is there any public software that can actually support 64-bit DES (CPU or GPU based)?\n. ",
    "Aspect9": "Im getting \"/usr/bin/menuexec: line 11:  4459 Segmentation fault      sudo $\" when i run oclhashcat - wassup wid that brothers? sisters?. where is the hashcat pot file located? beat me?. im tryna install hashcat here - not even cuda - anyone point me in the right direction?\n. ",
    "anlx-sl": "I will provide an example ASAP. One more detail: I prepared the lists using Neotepad++ v6.8.8 on Win 10 (removing empty lines etc.). Then i saved the files to the Desktop and copied them to the linux host using scp (mobaxterm). Maybe one of this steps may cause the problem? \n. @philsmd https://www.dropbox.com/s/55vki7bnah85skn/smpl3.zip?dl=0\n. @jsteube yes, thanks a lot guys!\n. ",
    "Zyntax3rror": "2\nCould be related to the above problem\nForcing the CPU to do the work fails too(used version 2.10b64)\n(I used a litecoin hash for the CPU (but this time I used my other computer))\n(hashcat is one of the words in the dictionary)\noclHashcat64.exe -m 8900 test1024c.hash example.dict --opencl-device-types 1\nDevice #1:        Intel(R) Core(TM) i7-3770S CPU @ 3.10GHz, 8113/32452 MB alloca\ntable, 3100Mhz, 8MCU\nDevice #2: Intel(R) HD Graphics 4000, skipped\nSession.Name...: oclHashcat\nStatus.........: Exhausted\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:1024:1:1:MDIwMzMwNTQwNDQyNQ==:5FW+...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nTime.Estimated.: 0 secs\nSpeed.Dev.#1...:        0 H/s\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 3/3 (100.00%)\nRejected.......: 0/3 (0.00%)\nHWMon.GPU.#1...: N/A Util, N/A Temp, N/A Fan\nStarted: Sun Jan 24 14:11:51 2016\nStopped: Sun Jan 24 14:11:54 2016\n. Done some further analysis (hash is hascat)\nproblem is that when r > 8 it fails!\nOK\nSCRYPT:64:1:1:dGVhbWhhc2hjYXQ=====:SDYBLsXIefUhSOacrgoZE2vEdduSyl+2uU+OTD8eUD8=\nSCRYPT:64:2:1:dGVhbWhhc2hjYXQ=====:5b9cH8RssHn8NQ4fA+40seHscB18Smy1SCgkkUDob0E=\nSCRYPT:64:3:1:dGVhbWhhc2hjYXQ=====:upfDMzSsnbPyA2wlogTBrIQPJe22ZJaDShPe+yyCt9I=\nSCRYPT:64:4:1:dGVhbWhhc2hjYXQ=====:ECIEORXh+CMWiIyTr8d1/Diln/BR757BA7+r1HqR9Ng=\nSCRYPT:64:5:1:dGVhbWhhc2hjYXQ=====:jwvgTggWAyo5P0XcvJiOADHq1WEQPxLJJMMVtZIhmEQ=\nSCRYPT:64:6:1:dGVhbWhhc2hjYXQ=====:G8sJ0Rm9V8aU8TQFw0kV0FMwlCuqD3x211y8kW6qaxA=\nSCRYPT:64:7:1:dGVhbWhhc2hjYXQ=====:Pqx8f55idB8H7IMN0K4Q4j95qkvbRBsnZk+zy6IqWNU=\nSCRYPT:64:8:1:dGVhbWhhc2hjYXQ=====:NsBlpyfWWxdEW1tNMPbWaiNOIrE5bet44Rms48iStQ0=\n\nFAILS (but works in hashcat (v2) for cpu)\nSCRYPT:64:9:1:dGVhbWhhc2hjYXQ=====:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA=\nSCRYPT:64:10:1:dGVhbWhhc2hjYXQ=====:Dg4kia42f4wcKIncQ3SJgoZqS9VwcjWPr9T4aqFOlh8=\nSCRYPT:64:11:1:dGVhbWhhc2hjYXQ=====:8oF2KntHkTwuwZKP/9ul7q7ttgGAWZYvk2akFvMFUH0=\nSCRYPT:64:12:1:dGVhbWhhc2hjYXQ=====:F24uymA1PihLJXWC6FAatdIpnz2daW3RtaHoC9lM7Fo=\nSCRYPT:64:13:1:dGVhbWhhc2hjYXQ=====:N+6OlDZ+4K+Ew0bTzvx+A4H73G1HcustCgTb4+fttSc=\nSCRYPT:64:14:1:dGVhbWhhc2hjYXQ=====:x1Fn+ug/J2PfbFejeOndDbnHKa8nVRFuKzPe4ZHfy6w=\nSCRYPT:64:15:1:dGVhbWhhc2hjYXQ=====:WO7N0gNHT6qMFN7BzjPRqj3wXpBYMEoYVKJRVkVyH+I=\nSCRYPT:64:16:1:dGVhbWhhc2hjYXQ=====:/6wTfDGtCuG6R/pBfVZmhHkTktEr0lg7O+e2qpGae7A=\nSCRYPT:64:32:1:dGVhbWhhc2hjYXQ=====:SAx6RFnHpo1OX4ZqGKAermpDpJsp0UksGkdlTjbqK3Y=\nSCRYPT:64:64:1:dGVhbWhhc2hjYXQ=====:TcTQSV30eLx/pgP2fm6C8g+4//gtujfURqkVoyJSjRE=\n. sorry but, dictionary attack is not working. Getting closer :)\nHashcat64.exe -m 8900 hash.txt example.dict\nhashcat (v3.00-beta-146-g106e781) starting...\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nSCRYPT tmto optimizer value set to: 2, mem: 2949120\nCache-hit dictionary stats example.dict: 28 bytes, 4 words, 4 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (15.76ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 4/4 (100.00%)\nRejected.......: 0/4 (0.00%)\nStarted: Mon Jun 06 23:11:16 2016\nStopped: Mon Jun 06 23:11:25 2016\n. again (but now only for dictionary attack)\nr = 1 -> 8 = works\nr >8 fails\nlog\n\nhashcat (v3.00-beta-146-g106e781+) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 2621440\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 28 bytes, 4 words, 4 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSCRYPT:64:8:1:dGVhbWhhc2hjYXQ=:NsBlpyfWWxdEW1tNMPbWaiNOIrE5bet44Rms48iStQ0=:hashcat\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:8:1:dGVhbWhhc2hjYXQ=:NsBlpyfWWx...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (14.09ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 4/4 (100.00%)\nRejected.......: 0/4 (0.00%)\nStarted: Tue Jun 07 17:55:46 2016\nStopped: Tue Jun 07 17:55:56 2016\n\nhashcat (v3.00-beta-146-g106e781+) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 2949120\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 28 bytes, 4 words, 4 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (16.55ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 4/4 (100.00%)\nRejected.......: 0/4 (0.00%)\nStarted: Tue Jun 07 17:55:56 2016\nStopped: Tue Jun 07 17:56:06 2016\n\nhashcat (v3.00-beta-146-g106e781+) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 3276800\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 28 bytes, 4 words, 4 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:10:1:dGVhbWhhc2hjYXQ=:Dg4kia42f...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (16.87ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 4/4 (100.00%)\nRejected.......: 0/4 (0.00%)\nStarted: Tue Jun 07 17:56:06 2016\nStopped: Tue Jun 07 17:56:16 2016\n. That patch changes registry TdrLevel from 3 to 0, so it should work on any card(did work on my hd4000). (If your computer hangs after the patch (after you have started oclHashcat64) then you have to use the reset button/power-button)\nTdrLevel\n0 - Detection disabled\n1 - Bug check on detected timeout, for example, no recovery.\n2 - Recover to VGA (not implemented).\n3 - Recover on timeout. This is the default value.\nthere is plenty of guides (just search for TdrLevel). This is one way of doing it:\npatch (create a file called patch.reg (not patch.reg.txt) and paste the following. Then save and double click the file(and answer yes  and then yes again) then reboot your computer)\nWindows Registry Editor Version 5.00\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\GraphicsDrivers]\n\"TdrLevel\"=dword:00000000\nto go back to default:\n(default.reg   copy/paste + save + double click +yes+yes+reboot)\nWindows Registry Editor Version 5.00\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\GraphicsDrivers]\n\"TdrLevel\"=dword:00000003\n. 11 minutes to complete the SHA-3(Keccak) benchmark  (version 2.10b79) on win 7\n(used oclhashcat64 -b)\n\nDevice  #1:        Intel(R) Core(TM) i7-3770S CPU @ 3.10GHz, skipped\nDevice  #2: Intel(R) HD Graphics 4000, 374/1496 MB allocatable, 350Mhz, 16MCU\nHashtype: SHA-3(Keccak)\nWorkload: 512 loops, 256 accel\nSpeed.Dev.#2.:        0 H/s\nStarted: Fri Feb 05 00:15:44 2016\nStopped: Fri Feb 05 00:25:40 2016\n\n\noclhashcat64 -d2 -b --benchmark-mode 0 -m 5000 -u 16 -n 16\ngot me this\n\noclHashcat v2.01 (g582378b) starting in benchmark-mode...\nDevice #1:        Intel(R) Core(TM) i7-3770S CPU @ 3.10GHz, skipped\nDevice #2: Intel(R) HD Graphics 4000, 374/1496 MB allocatable, 350Mhz, 16MCU\nHashtype: SHA-3(Keccak)\nWorkload: 16 loops, 16 accel\nSpeed.Dev.#2.:   218.1 kH/s\nStarted: Fri Feb 05 00:31:55 2016\nStopped: Fri Feb 05 00:32:04 2016\n\n. @Fist0urs \nI used default settings on benchmarks, but a shortcut would be:\n(takes 11 minutes!! and computer looks frozen (I can move the mouse, but that's it))\nHow long do you wait before you give up?\nMy computer is extremely slow when doing this so it looks like the screen freezes, but after you wait it comes back.\ncan you try this one and wait for at least 5 minutes and tell me if you get lucky or not?\n. version  b86\nTested on hd4600 on win 7 and it fails too (latest intel driver used win64_153628.4332)\ntried oclhashcat -b -m0  (waited 12 minutes) and then gave up (reset button)\n(Hd4000 works fine. result in 18 seconds )\n. a single word in wordlist worked. That does not make sense..\n\nhashcat (v3.00-beta-151-g1c695b1) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger disabled\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 2949120\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 7 bytes, 1 words, 1 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA=:hashcat\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (11.84ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Sat Jun 11 12:38:44 2016\nStopped: Sat Jun 11 12:38:54 2016\n. ok..did not work for r>8 (4 words in example.dict), r<9 worked fine.\nHashcat64.exe -m 8900 SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=====:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA= example.dict\nhashcat (v3.00-beta-232-g0e68b2a) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger set to 75c\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 23592960\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 28 bytes, 4 words, 4 keyspace\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (16.37ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 4/4 (100.00%)\nRejected.......: 0/4 (0.00%)\nHWMon.Dev.#1...: Temp: 41c Fan: 25% Util: 52% Core:1019Mhz Mem:2700Mhz Lanes:16\nStarted: Mon Jun 27 00:07:28 2016\nStopped: Mon Jun 27 00:07:38 2016\n. YES!!! mission accomplished :) \nThanks!!!\n\nhashcat (v3.00-beta-242-g4ed8977) starting...\nRemoving duplicate hashes...\nComparing hashes with potfile entries...\nStructuring salts for cracking task...\nGenerating bitmap tables with 16 bits...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger set to 75c\nInitializing device kernels and memory...\nSCRYPT tmto optimizer value set to: 2, mem: 188743680\nChecking for weak hashes...\nCache-hit dictionary stats example.dict: 1080247 bytes, 129989 words, 129989 keyspace\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => \nSCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyjp61QoQhb9Y8oYXLtJ2WZoZN0wSL6ta7eA=:hashcat\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: File (example.dict)\nHash.Target....: SCRYPT:64:9:1:dGVhbWhhc2hjYXQ=:IBNEidINyj...\nHash.Type......: scrypt\nTime.Started...: Tue Jun 28 00:40:52 2016 (4 secs)\nSpeed.Dev.#1...:    29590 H/s (40.13ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 129989/129989 (100.00%)\nRejected.......: 0/129989 (0.00%)\nStarted: Tue Jun 28 00:40:52 2016\nStopped: Tue Jun 28 00:41:07 2016\n. I used to download from your latest version's from here\nhttps://hashcat.net/beta/\nHave you moved your release candidates to another folder?\n. same error\n\nHashcat64.exe -m 8900 SCRYPT:512:256:1:Z200dHIxeGF0b20=====:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk= example.dict\nhashcat (v3.00-25-g69e3e39) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\n  Watchdog: Temperature abort trigger set to 90c\n  Watchdog: Temperature retain trigger set to 75c\nWARNING: Not enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nWARNING: Not enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nWARNING: Not enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nSCRYPT tmto optimizer value set to: 5, mem: 1342177280\n- Device #1: Kernel amp_a0.09b29f52.kernel not found in cache! Building may take a while...\nChecking for weak hashes...\nERROR: clEnqueueNDRangeKernel() : -6 : CL_OUT_OF_HOST_MEMORY\n. hashcat-3.10+611\\hashcat-3.10>Hashcat64.exe -m 8900 SCRYPT:512:256:1:Z200dHIxeGF0b20=====:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk= example.dict\nhashcat (v3.10-611-gf234f72) starting...\nnvmlDeviceSetPowerManagementLimit(): Insufficient Permissions\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n- Zero-Byte\n- Single-Hash\n- Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nNot enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nclEnqueueNDRangeKernel(): CL_OUT_OF_HOST_MEMORY\nStarted: Mon Oct 31 21:10:38 2016\nStopped: Mon Oct 31 21:12:03 2016\n. did say v3.30-382-g50b46d5 when i downloaded beta for 3.40\nI got CL_OUT_OF_HOST_MEMORY\nhashcat-3.40>Hashcat64.exe -m 8900 SCRYPT:512:256:1:Z200dHIxeGF0b20=====:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk= example.dict\nhashcat (v3.30-382-g50b46d5) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 750 Ti, 512/2048 MB allocatable, 5MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nNot enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nclEnqueueNDRangeKernel(): CL_OUT_OF_HOST_MEMORY\nStarted: Wed Mar 01 16:12:40 2017\nStopped: Wed Mar 01 16:14:17 2017. Tested and worked on GTX1080 (2048 mb used compared to 512mb on GTX 750Ti)\nHashcat64.exe -m 8900 SCRYPT:512:256:1:Z200dHIxeGF0b20=====:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk= example.dict\nhashcat (v3.30-382-g50b46d5) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2048/8192 MB allocatable, 20MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nNot enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nGenerated dictionary stats for example.dict: 29 bytes, 4 words, 4 keyspace\nThe wordlist or mask you are using is too small.\nTherefore, hashcat is unable to utilize the full parallelization power of your device(s).\nThe cracking speed will drop.\nWorkaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSCRYPT:512:256:1:Z200dHIxeGF0b20=:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk=:hashcat\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: scrypt\nHash.Target......: SCRYPT:512:256:1:Z200dHIxeGF0b20=:RLHfYNlTpELj0LAATTIMae5xEAOO2yMUTVFZivQhlzk=\nTime.Started.....: Thu Mar 02 21:26:40 2017 (14 secs)\nTime.Estimated...: Thu Mar 02 21:26:54 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (13461.61ms)\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 4/4 (100.00%)\nRejected.........: 0/4 (0.00%)\nRestore.Point....: 0/4 (0.00%)\nCandidates.#1....: 989386 -> hashcat\nHWMon.Dev.#1.....: Temp: 36c Fan: 92% Util:100% Core:  90MHz Mem:4513MHz Lanes:16\nStarted: Thu Mar 02 21:25:02 2017\nStopped: Thu Mar 02 21:26:55 2017. ",
    "thepaandu": "enough for some, not enough for some.\ncan you help?\n. 8 characters, so alpha num chars are 62^8 that is 2-00-000-billion\nWith a speed of 1-billion per sec, with your speed, it would break in 2\ndays.\nLength of total string varies from 60-160 characters\nOn Friday 29 January 2016, Jens Steube notifications@github.com wrote:\n\nYou said in an other discussion the salt length is fixed. What is that\nfixed salt length?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-176628995.\n. Anything that can be done sir?\n\nOn Friday 29 January 2016, Deepak Kapoor thepaandu@gmail.com wrote:\n\n8 characters, so alpha num chars are 62^8 that is 2-00-000-billion\nWith a speed of 1-billion per sec, with your speed, it would break in 2\ndays.\nLength of total string varies from 60-160 characters\nOn Friday 29 January 2016, Jens Steube notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');> wrote:\n\nYou said in an other discussion the salt length is fixed. What is that\nfixed salt length?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-176628995\n.\n. Can we do it on 112>\nIt will work for most of my problems.\nIt is being used at a place of high reputation.\nI won't be able to disclose everything but it is going to be worth it,\ntrust me.\nWe would be more than happy to add your name in the credits list and mark\nmy words, its a huge thing.\n\n\nOn Sunday 31 January 2016, Jens Steube notifications@github.com wrote:\n\nEverything > 112 is a problem, we can't do that easily without creating a\nnew hash-mode for it. To do that we'd need to know where it is used in so\nthat we can decide if it worth the effort\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-177304369.\n. i was using raw 1700 but it is going to be 1720 since first 8 characters\nare unknown.\n\nOn Sun, Jan 31, 2016 at 3:38 AM, Jens Steube notifications@github.com\nwrote:\n\nDo you need it for -m 1710 or -m 1720 ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-177317679.\n. What would be your solution , sir ?\n\nOn Sunday 31 January 2016, Deepak Kapoor thepaandu@gmail.com wrote:\n\ni was using raw 1700 but it is going to be 1720 since first 8 characters\nare unknown.\nOn Sun, Jan 31, 2016 at 3:38 AM, Jens Steube notifications@github.com\n<javascript:_e(%7B%7D,'cvml','notifications@github.com');> wrote:\n\nDo you need it for -m 1710 or -m 1720 ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-177317679\n.\n. Sir, any updates?\n\n\nOn Tuesday 2 February 2016, Deepak Kapoor thepaandu@gmail.com wrote:\n\nWhat would be your solution , sir ?\nOn Sunday 31 January 2016, Deepak Kapoor thepaandu@gmail.com\n<javascript:_e(%7B%7D,'cvml','thepaandu@gmail.com');> wrote:\n\ni was using raw 1700 but it is going to be 1720 since first 8 characters\nare unknown.\nOn Sun, Jan 31, 2016 at 3:38 AM, Jens Steube notifications@github.com\nwrote:\n\nDo you need it for -m 1710 or -m 1720 ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-177317679\n.\n. I am trying.\nNeed you.\n\n\n\nOn Saturday 6 February 2016, magnum notifications@github.com wrote:\n\nBreath through your nose, young jedi.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-180637089.\n. I am working with my partner who has successfully improved the hash collision theory and can be used to break hashes with  it.\nSo we need your help.\nThanks.\n\nSent from my iPhone\n\nOn 07-Feb-2016, at 3:47 AM, Jens Steube notifications@github.com wrote:\nNevermind that. I just played around an temporarily added support to -m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The problem is that this would also affect other modes, like -m 1722 (OSX) and that's why we can't add it to generic -m 17xx. For this mode to work, we need to add a completely new one, ideally with esalt. But before I'm going to do this I want to know where it's used in.\n\u2014\nReply to this email directly or view it on GitHub.\n. What do you say sir? Can you help me out with the solution?\n\"The power is in your hands, use it wisely\"\n\nOn 2/7/2016 3:47 AM, Jens Steube wrote:\n\nNevermind that. I just played around an temporarily added support to \n-m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The \nproblem is that this would also affect other modes, like -m 1722 (OSX) \nand that's why we can't add it to generic -m 17xx. For this mode to \nwork, we need to add a completely new one, ideally with esalt. But \nbefore I'm going to do this I want to know where it's used in.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-180874249.\n. Sir, I am awaiting your response.\nThanks.\n\nOn 2/7/2016 3:47 AM, Jens Steube wrote:\n\nNevermind that. I just played around an temporarily added support to \n-m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The \nproblem is that this would also affect other modes, like -m 1722 (OSX) \nand that's why we can't add it to generic -m 17xx. For this mode to \nwork, we need to add a completely new one, ideally with esalt. But \nbefore I'm going to do this I want to know where it's used in.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-180874249.\n. Hello sir, I am desperately waiting for your response.\n-Student.\n. I do not have your email id. and it is sort of urgent. and you are my \nlast hope. so i am taking my chances by irritating you.\n\nOn 2/12/2016 4:07 AM, Jeremi M Gosney wrote:\n\nHoly shit dude, do you intend to write a comment on this every day?\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/hashcat/oclHashcat/issues/166#issuecomment-183087850.\n. Happy valentine's day :|\n\nSent from my iPhone\n\nOn 07-Feb-2016, at 3:47 AM, Jens Steube notifications@github.com wrote:\nNevermind that. I just played around an temporarily added support to -m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The problem is that this would also affect other modes, like -m 1722 (OSX) and that's why we can't add it to generic -m 17xx. For this mode to work, we need to add a completely new one, ideally with esalt. But before I'm going to do this I want to know where it's used in.\n\u2014\nReply to this email directly or view it on GitHub.\n. Hey sir!\nAt Least tell me where to look for\nIf you have a solution , send in that and i wont disturb you ever \n\nSent from my iPhone\n\nOn 07-Feb-2016, at 3:47 AM, Jens Steube notifications@github.com wrote:\nNevermind that. I just played around an temporarily added support to -m 1720 and the speed instantly dropped from 620 MH/s to 440 MH/s. The problem is that this would also affect other modes, like -m 1722 (OSX) and that's why we can't add it to generic -m 17xx. For this mode to work, we need to add a completely new one, ideally with esalt. But before I'm going to do this I want to know where it's used in.\n\u2014\nReply to this email directly or view it on GitHub.\n. @kost123 @gituser Hey, can you add me on skype at deepak.affrevenue? \nNeed to talk about this dirty patch.\nthanks!\n. \n",
    "dropdeadfu": "at least on windows the latest beta doesn't cause a crash anymore.\nOn 17 February 2016 at 11:51, Fist0urs notifications@github.com wrote:\n\nDid someone succeed in running oclhashcat on HD Graphics on Linux? Drivers\nprovided by Intel apparently need to patch kernel and I would like to avoid\nthat if possible...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/191#issuecomment-185151317.\n. awesome!\n. Try to watch your clock speeds, maybe they can give a clue why that happens.\n\nOn 7 August 2016 at 04:30, Krytos notifications@github.com wrote:\n\nHey guys. So when I use hashcat for MD5 or MD4 etc, the retainer works as\nsupposed to and my GPU does not go above 75\u00b0. When I want to crack WPA2\nhowerver, using a 15GB wordlist, my GPU will go above 75\u00b0 up to 90\u00b0 and\nhashcat will stop. I tried using the minimum workload setting, which did\nnothing. I also tried setting the retain trigger to 65\u00b0, which did nothing\neither. Any tipps?\nSpecs:\nWindows 10 Pro x64\nCPU: Intel Core i5 4670k @ 4.5GHz\nRAM: G.Skill TridentX 16GB, DDR3-2400\nGPU: MSI Radeon R9 390\nMotherboard: ASrock Fatal1ty z87 Killer\nPSU: EVGA 650 GQ\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/454, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdoo42MJCcKIAB0Iqa4q7jj1tPVp_aks5qdUM8gaJpZM4JeaOi\n.\n. 1 - pause should also pause the timer\n. Which version did you download? The beta? On which OS are you?\n\nOn 13 September 2016 at 20:48, fsociety79 notifications@github.com wrote:\n\nI've just downloaded the hashcat binary and tried to run the benchmark\nwhich results in an error:\nERROR: inc_cipher_256aes.cl: fopen(): No such file or directory\nThe file it speaks of is in the same directory as the binary and I get the\nsame error using both 64 and 32-bit versions. It also results in the same\nerror if I run the example0 with a known hash file.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdohiFMRSAZ2_eTp5YqEjhEs0WBKQtks5qpvAZgaJpZM4J8A25\n.\n. Nevermind the OS question i've just seen the subject.\n\nOn 13 September 2016 at 20:56, Christoph Heuwieser dropdead@hashcat.net\nwrote:\n\nWhich version did you download? The beta? On which OS are you?\nOn 13 September 2016 at 20:48, fsociety79 notifications@github.com\nwrote:\n\nI've just downloaded the hashcat binary and tried to run the benchmark\nwhich results in an error:\nERROR: inc_cipher_256aes.cl: fopen(): No such file or directory\nThe file it speaks of is in the same directory as the binary and I get\nthe same error using both 64 and 32-bit versions. It also results in the\nsame error if I run the example0 with a known hash file.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdohiFMRSAZ2_eTp5YqEjhEs0WBKQtks5qpvAZgaJpZM4J8A25\n.\n. Ok, then there seems to be something wrong with your settings. My guess\nwould be that there is something strange with the UAC or something similar.\nDid you make sure the user you are starting it with also has read and write\npermissions on the directory? Did you try running the cmd-box as admin?\n\n\nOn 13 September 2016 at 20:58, fsociety79 notifications@github.com wrote:\n\nI downloaded v3.10\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499#issuecomment-246787473,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdoiKuXI3xqJvsH8cWV6nX3PqVz3J9ks5qpvJwgaJpZM4J8A25\n.\n. Is that all you get when you start the benchmark or do you at least get the\nother results leading up to it?\n\nOn 13 September 2016 at 21:10, fsociety79 notifications@github.com wrote:\n\nI've just tried it and I get the same error.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499#issuecomment-246791161,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdoghHd6ApC7rq-eEaum3-fvPLEeh7ks5qpvVDgaJpZM4J8A25\n.\n. Make a copy of the complete console you are trying this in, put it on\npastebin and send the link to the paste.\n\nOn 13 September 2016 at 21:22, fsociety79 notifications@github.com wrote:\n\nI also get the following output:\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1 https://github.com/hashcat/hashcat/issues/1:\nIntel(R) Corporation\n- Device #1 https://github.com/hashcat/hashcat/issues/1: Intel(R)\n  Pentium(R) CPU N3540 @ 2.16GHz, skipped\n- Device #2 https://github.com/hashcat/hashcat/pull/2: Intel(R) HD\n  Graphics, 343/1374 MB allocatable, 4MCU\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499#issuecomment-246794210,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdougWQ_BuWvm9nZT15gQMglNLbJuXks5qpvfYgaJpZM4J8A25\n.\n. I need to see the complete console, including everything you did before\nstarting hashcat\n\nOn 13 September 2016 at 21:33, fsociety79 notifications@github.com wrote:\n\nhttp://pastebin.com/HTit03Vd\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/499#issuecomment-246797298,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdotqq9emfu1pFuV--EKyMz9k0pwoZks5qpvp5gaJpZM4J8A25\n.\n. clinfo output please\n\nOn 14 September 2016 at 17:50, clfdhq notifications@github.com wrote:\n\n\nDevice #1 https://github.com/hashcat/hashcat/issues/1: Intel(R)\n\n## Core(TM) i5-3210M CPU @ 2.50GHz, skipped\nDevice #2 https://github.com/hashcat/hashcat/pull/2: Intel(R) HD\n  Graphics 4000, 324/1297 MB allocatable, 16MCU\nDevice #3 https://github.com/hashcat/hashcat/issues/3: GeForce GT\n  620M, 512/2048 MB allocatable, 2MCU\n  Device #3 https://github.com/hashcat/hashcat/issues/3: WARNING!\n  Kernel exec timeout is not disabled, it might cause you errors of code 702\n  See the wiki on how to disable it: https://hashcat.net/wiki/doku.\n  php?id=timeout_patch\nDevice #2 https://github.com/hashcat/hashcat/pull/2: Kernel\n  m02500.3d391022.kernel not found in cache! Building may take a while...\n  Device #2 https://github.com/hashcat/hashcat/pull/2: Kernel\n  markov_le.3d391022.kernel not found in cache! Building may take a while...\nDevice #2 https://github.com/hashcat/hashcat/pull/2: Kernel\n  amp_a3.3d391022.kernel not found in cache! Building may take a while...\nDevice #3 https://github.com/hashcat/hashcat/issues/3: Kernel\n  m02500.18d8b4cc.kernel not found in cache! Building may take a while...\n  Device #3 https://github.com/hashcat/hashcat/issues/3: Kernel\n  markov_le.18d8b4cc.kernel not found in cache! Building may take a while...\nDevice #3 https://github.com/hashcat/hashcat/issues/3: Kernel\n  amp_a3.18d8b4cc.kernel not found in cache! Building may take a while...\ni use Core-I5 321M, GPU: Ndvia GeFore GT 620M\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/501, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AKPdogoK0Nu4NEoZmAX_1rNKJMvq7rCkks5qqBfagaJpZM4J87tC\n.\n. Running win10 with nvidia 398.36 on a 1080ti and can run the example just fine.. \n",
    "01BTC10": "It is well explained here: http://bitcoin.stackexchange.com/questions/3059/what-is-a-compressed-bitcoin-key\nBasicly Bitcoin Core before 0.6 was using uncompressed pubkey format. They switched to compressed format and Hashcat doesn't understand the uncompressed format. The script bitcoin2john.py doesn't do any conversion and JackTheRipper support both format. When I got this issue I say many people complaining about the same problem. I looked carefully at the hash format and found the problem.\nUncompressed format start with 04 and has a length of 65 bytes. Compressed format start with 03 or 02  and is 33 bytes.\n```\n$ ku 04c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c4d92b0bbb8205521bd7b020db080b355acb75cf9ec04ebef0d2c3889f7369679\ninput                        : 04c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c\\\n                                 4d92b0bbb8205521bd7b020db080b355acb75cf9ec04ebef0d2c3889f7369679\nnetwork                      : Bitcoin mainnet\nnetcode                      : BTC\npublic pair x                : 90234338766489736260560541387516194814900220115552850975862447215427335274764\npublic pair y                : 35087268780626980418258611515549367557368934105453932834202777821135781664377\n x as hex                    : c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c\n y as hex                    : 4d92b0bbb8205521bd7b020db080b355acb75cf9ec04ebef0d2c3889f7369679\ny parity                     : odd\nkey pair as sec              : 03c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c\n uncompressed                : 04c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c\\\n                                 4d92b0bbb8205521bd7b020db080b355acb75cf9ec04ebef0d2c3889f7369679\nhash160                      : a3759ac93719b9a3ce91d57413af6f7fbc96a215\n uncompressed                : e53d032e405ce162fa75d054c453419051f053da\nBitcoin address              : 1FuJ2ajAGSTeeXkdS1gbv6oZUxYtcEBwao\nBitcoin address uncompressed : 1Mu6q9WdP3Jd7QHhkfkU4Qijhm6g2H1AiV\n```\nSo if you take this output fom bitcoin2john.py:\n$bitcoin$96$856e263a5c91fa5df09049153f9b3b889b3b5be0185b2ca95a352832e83dc519c63074a0bbc42615bae8b352149431f3$16$9dd95fb690bb7d5e$125989$96$0135a17e315d528da597892e4510d51971a4bb8b2da21f577620a294b8baabb88a0fe5aa4cb672ccdad575a9b9064fb1$130$04c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c4d92b0bbb8205521bd7b020db080b355acb75cf9ec04ebef0d2c3889f7369679\nIt won't work with Hashcat but it can be converted to the compressed format to make it work.\n$bitcoin$96$856e263a5c91fa5df09049153f9b3b889b3b5be0185b2ca95a352832e83dc519c63074a0bbc42615bae8b352149431f3$16$9dd95fb690bb7d5e$125989$96$0135a17e315d528da597892e4510d51971a4bb8b2da21f577620a294b8baabb88a0fe5aa4cb672ccdad575a9b9064fb1$66$03c77ed36b8f0affb1b434ef6975b2fa224131f42ab47df30b7c6b6dffe47cc10c\nBoth hash are equivalent in the Bitcoin network.\n. Same problem. I was thinking about implementing \"Multibit Classic\" aes256(scrypt(password, salt))  and was looking how hashcat implemented scrypt. The default scrypt parameter in that case are higher than the default benchmark.\n\nSCRYPT:16384:8:1:MDIwMzMwNTQwNDQyNQ==:5FW+zWivLxgCWj7qLiQbeC8zaNQ+qdO0NUinvqyFcfo=\n\n```\n$./hashcat  -m 8900 -w3 -a 0 -r rules/rockyou-30000.rule scrypt.txt rockyou.txt\nhashcat (v3.30) starting...\n\nDevice #1: Not a native Intel OpenCL runtime, expect massive speed loss\n             You can use --force to override this but do not post error reports if you do so\nDevice #2: Old CUDA compute capability 3.5 detected, OpenCL performance is reduced.\n             For ideal hashcat performance on NVIDIA GPU you need CUDA compute capability 5.0 or higher (Maxwell)\nnvmlDeviceGetCurrPcieLinkWidth(): Not Supported\n\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetClockInfo(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetTemperatureThreshold(): Not Supported\nnvmlDeviceGetUtilizationRates(): Not Supported\nOpenCL Platform #1: The pocl project\n\nDevice #1: pthread-Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz, skipped\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #2: GeForce GTX 780 Ti, 755/3020 MB allocatable, 15MCU\nDevice #3: GeForce GTX 950, 499/1996 MB allocatable, 6MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 30000\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nNot enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 5, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 2, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 3, increasing...\nNot enough single-block device memory allocatable to use --scrypt-tmto 4, increasing...\nChecking for weak hashes...clEnqueueNDRangeKernel(): CL_MEM_OBJECT_ALLOCATION_FAILURE\nStarted: Fri Feb 17 22:41:54 2017\nStopped: Fri Feb 17 22:41:59 2017\n```. ",
    "505Mike": "where can i find bitcoin2john.py\n. ",
    "truekonrads": "Algorithm name: NetWitness / RSA Security Analytics\nIn use for NetWitness and RSA Security Analytics, can be found in /etc/netwitness/nw/*.cfg. \nThere are a few variants, a SHA1 variant, SHA256 variant and also a challenge-response variant which hashes the salted password hash with a challenge.\nThe password hash can be created using this Python code:\npwdhash=sha256(sha256(password).hexdigest().upper()+gsalt.decode('base64')).hexdigest().upper()\nThe challenge-response mode can be created like so:\nsha256(\"netwitness\"+pwdhash+srvhash).hexdigest().upper()\n. Same:\n```\n~/hashcat$ ./hashcat -a 3 -O -m 13100 ~/ACME_tickets_grepped.txt ?a?a?a?a?a?a?a?a\nhashcat (v4.1.0) starting...\n\nDevice #1: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #2: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #3: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #4: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #5: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #6: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #7: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #8: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #9: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #10: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #11: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #12: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #13: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #14: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #15: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nDevice #16: This hardware has outdated CUDA compute capability (3.7).\n             For modern OpenCL performance, upgrade to hardware that supports\n             CUDA compute capability version 5.0 (Maxwell) or higher.\nnvmlDeviceGetFanSpeed(): Not Supported\n\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetFanSpeed(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #2: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #3: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #4: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #5: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #6: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #7: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #8: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #9: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #10: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #11: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #12: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #13: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #14: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #15: Tesla K80, 2859/11439 MB allocatable, 13MCU\nDevice #16: Tesla K80, 2859/11439 MB allocatable, 13MCU\n\n/home/ubuntu/hashcat/hashcat.hcstat2: No such file or directory\nHashes: 563 digests; 562 unique digests, 562 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Optimized-Kernel\n Zero-Byte\n Not-Iterated\n Brute-Force\nPassword length minimum: 0\nPassword length maximum: 55\nWatchdog: Temperature abort trigger set to 90c\nINFO: Removed 18 hashes found in potfile.\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nApproaching final keyspace - workload adjusted.\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: Kerberos 5 TGS-REP etype 23\nHash.Target......: /home/ubuntu/ACME_tickets_grepped.txt\nTime.Started.....: Wed Feb  7 14:37:12 2018 (0 secs)\nTime.Estimated...: Wed Feb  7 14:37:12 2018 (0 secs)\nGuess.Mask.......: ?a?a?a?a?a?a?a?a [8]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#2.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#3.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#4.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#5.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#6.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#7.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#8.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#9.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#10.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#11.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#12.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#13.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#14.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#15.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#16.....:        0 H/s (0.00ms) @ Accel:32 Loops:8 Thr:64 Vec:1\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 18/562 (3.20%) Digests, 18/562 (3.20%) Salts\nProgress.........: 0\nRejected.........: 0\nRestore.Point....: 0\nCandidates.#1....: [Generating]\nCandidates.#2....: [Generating]\nCandidates.#3....: [Generating]\nCandidates.#4....: [Generating]\nCandidates.#5....: [Generating]\nCandidates.#6....: [Generating]\nCandidates.#7....: [Generating]\nCandidates.#8....: [Generating]\nCandidates.#9....: [Generating]\nCandidates.#10....: [Generating]\nCandidates.#11....: [Generating]\nCandidates.#12....: [Generating]\nCandidates.#13....: [Generating]\nCandidates.#14....: [Generating]\nCandidates.#15....: [Generating]\nCandidates.#16....: [Generating]\nHWMon.Dev.#1.....: Temp: 51c Util: 12% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#2.....: Temp: 42c Util:  5% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#3.....: Temp: 56c Util: 40% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#4.....: Temp: 49c Util: 19% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#5.....: Temp: 49c Util:  5% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#6.....: Temp: 43c Util:  5% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#7.....: Temp: 55c Util: 13% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#8.....: Temp: 43c Util:  5% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#9.....: Temp: 49c Util: 28% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#10.....: Temp: 41c Util: 13% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#11.....: Temp: 50c Util:  5% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#12.....: Temp: 41c Util: 55% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#13.....: Temp: 49c Util: 54% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#14.....: Temp: 40c Util: 53% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#15.....: Temp: 49c Util:  0% Core: 562MHz Mem:2505MHz Bus:16\nHWMon.Dev.#16.....: Temp: 41c Util: 55% Core: 562MHz Mem:2505MHz Bus:16\nStarted: Wed Feb  7 14:35:45 2018\nStopped: Wed Feb  7 14:37:17 2018\n```.  @philsmd - restoring this file fixed the issue. I suppose it should be a fatal error.. ",
    "Vladinator": "No, sorry, I have had zero time to work on this. It is going to take me\nsome time, both because I am very unfamiliar with the project and it's\ncomponents, and because I have to do it off the clock in my personal time.\n\nW. Scott Lockwood III\nOn Sun, Feb 28, 2016 at 6:38 AM, Jens Steube notifications@github.com\nwrote:\n\n@Vladinator https://github.com/Vladinator Any update here?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/218#issuecomment-189862723.\n. Rock on! Thanks man!\nOn Apr 3, 2016 7:47 AM, \"Jens Steube\" notifications@github.com wrote:\nClosed #218 https://github.com/hashcat/oclHashcat/issues/218.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/218#event-612679751\n. \n",
    "averagesecurityguy": "Getting a similar error when trying to benchmark.\n```\n./oclHashcat.app --benchmark\noclHashcat v2.01 (g952c20e) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz, skipped\nDevice #2: HD Graphics 4000, 256/1024 MB allocatable, 1200Mhz, 16MCU\nDevice #3: GeForce GT 650M, 128/512 MB allocatable, 774Mhz, 2MCU\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Log (start) ===\nError: internal error.\n=== Build Log (end) ===\n```\n. Pulled down the latest code from Github. Still having trouble compiling the markov kernels for device 2\n```\nDevice #1: Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz, skipped            \nDevice #2: HD Graphics 4000, 256/1024 MB allocatable, 1200Mhz, 16MCU\nDevice #3: GeForce GT 650M, 128/512 MB allocatable, 774Mhz, 2MCU\nDevice #2: Kernel /Users/shaywood/nettest/oclHashcat/./kernels/m01000_a3.c7d3667b.kernel not found in cache! Building may take a while...\nDevice #2: Kernel /Users/shaywood/nettest/oclHashcat/./kernels/markov_le.c7d3667b.kernel not found in cache! Building may take a while...\n=== Build failed, retry with optimization disabled ===\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Options : -I/Users/shaywood/nettest/oclHashcat/./ -DVENDOR_ID=16925696 -DCUDA_ARCH=0 -DVECT_SIZE=1 -DDEVICE_TYPE=4 ===\n=== Build Log (start) ===\nError: internal error.\n=== Build Log (end) ===\nDevice #2: Kernel /Users/shaywood/nettest/oclHashcat/./OpenCL/markov_le.cl build failure. Proceed without this device.\n```\nHow do I configure Hashcat to not use the optimizations when building the kernels?\n. Attempting to compile the kernel manually to see if I can determine the issue. Using the following command.\nclang -framework OpenCL markov_le.cl -I../ -DVENDOR_ID=16925696 -DCUDA_ARCH=0 -DVECT_SIZE=1 -DDEVICE_TYPE=4\nand I'm getting a lot of errors like this:\nIn file included from markov_le.cl:10:\n../OpenCL/types_ocl.c:9:9: error: unknown type name 'uchar'; did you mean 'char'?\ntypedef uchar  u8;\n        ^~~~~\n        char\n../OpenCL/types_ocl.c:10:9: error: unknown type name 'ushort'; did you mean 'short'?\ntypedef ushort u16;\n        ^~~~~~\n        short\nIs there another way that I should be compiling?\n. Yep, figured out that's not the correct way to compile it. :) Would really like to figure out why it's not working. What is the proper way to attempt to compile the code? Make a wrapper that calls clBuildProgram and then compile the wrapper?\n. Using --markov-disable did not make a difference, I'm using -d3 to skip device 2 when necessary. I can use both devices when I'm using wordlist and rules.\n. Thanks. I'll just use -d3 as needed. This issue can be closed.\n. ",
    "jfoug": "For SRP, if you have a DB breach, you will obtain these items  (I, s and v)\n```\nx = H(s, p)               (s is chosen randomly)\nv = g^x %N                (computes password verifier)\nThe host then keeps {I, s, v} in its password database.  N and g publicly known for the site.\n```\nAll versions of SRP work about the same (other than they may compute x a bit differently).\nSo you see that you get v, but have no idea what x is. However you have been given H() and s and can try to 'guess' p, then plug that through through H() like   x' = H(s,p').  v'=g^x'  Then if v' matches the v from the db breach, you know that 'p is the unknown p\nNow like you mention, exp-mod.  You will find there is a HUGE reason why they have chosen that as the core of SRP. expmod is almost the definition of a serial function. You can not speed it up (much, there are some tweaks), since it is so serial iterative, and each step REQUIRES the prior step to be complete. This is due to carry logic (along with other issues).\nNow, that is not to say that there is not ability to do some parallelization.  You could compute m x' value (simply hashing here, hashcat is great on that), and then feed all of those different computed x' values into independent running expmod generators running on GPU.  Each of them will complete their part of the task in relatively close proximity of time, since most will have about the same number of set bits and clear bits in their x' values.\nSo yes, there 'is' possibility to gain on this problem with GPU coding, since g and N are fixed values.  But I do not know of any GPU coding that does parallel expmod work like this.  There may well be, but I am not aware.\nWhen I added the few known examples of SRP to john, I did so only in CPU code.  Almost the entire cost of execution is within the expmod calls.  The H() function plays almost no part (until somones implementation defines H() as pbkdf2, or scrypt, which they easily could do).\n. This is not rules 'loading'.  It is the config (.conf file) loading.  They are 2 totally separate items.  The config file loading loads the whole john.conf, and in jumbos case, anything that is .included.   It is this logic where the interpretation of the leading [ and . characters is the problem.\nI may be able to make that change, but it will be very hackish at best.\nThe advantage is for the users.  It allows usage of already made rulesets between more tools.  There is little or no downside to having some of the rules files have a few no-op commands added to them.\n. This was made to work without too much difficulty modifying the config.c file that parses a line, so the changes requested here, are not required to have john able to use these rulez files.\n. That was my own tool's output (it is not in the rule file).\nIn the rule file there are these 2 lines\n^1 ^0\n^1^0\nThey do exactly the same thing and this is 100% identical rule.\nSome of the other instances are not as apparent.\nss5 sa@ se3 si1 so0\nss5 sa@ se3 so0 si1\nss5 sa@ si1 se3 so0\nss5 sa@ si1 so0 se3\nss5 sa@ so0 se3 si1\nss5 sa@ so0 si1 se3\nss5 se3 sa@ si1 so0\nss5 se3 sa@ so0 si1\nss5 se3 si1 sa@ so0\nss5 se3 si1 so0 sa@\nss5 se3 so0 sa@ si1\nss5 se3 so0 si1 sa@\nss5 si1 sa@ se3 so0\nss5 si1 sa@ so0 se3\nss5 si1 se3 sa@ so0\nss5 si1 se3 so0 sa@\nss5 si1 so0 sa@ se3\nss5 si1 so0 se3 sa@\nss5 so0 sa@ se3 si1\nss5 so0 sa@ si1 se3\nss5 so0 se3 sa@ si1\nss5 so0 se3 si1 sa@\nss5 so0 si1 sa@ se3\nss5 so0 si1 se3 sa@\nAll of those lines are in the file, and there is only 1 rule.  The rest are duplicates.\nThere are literally 1000's of such lines (possibly 10's of 1000's).  They are absolutely wasted cycles when used.\n. One thing that would clean up a lot of them, is to first run the rules through a space removal code, to a temp file (preserving line order). Then do an in-place file unique (not a sort | uniq). Then using the original space trimmed file, and the in-place unique file, you can write a script to determine which lines from the original file need to be removed, and remove them (I assume people would want to keep the easier to read .rule file with the spaces separating each rule primative).\nOnce that clean(er) file is made, then the search for the harder to find dupes could be done (such as the leet dupliates).   There are many others which can be found without much problem. Those are:\n- order of mixing [ and ]\n- order of mixing ^ and $ in same rule\n- order of multiple s ops in same rule\n- etc\nIt will be about impossible to find all duplicates, especially in rule sets randomly generated.  But a large number of them can be found.  Some duplicates are very hard to spot, since they use different operations to do the same thing, OR have some operations which are no-op, thus hiding them.  Simple examples such as\n```\n$ ]xA3\nxA3\n$<$k]\n$<\n```\nThese are harder to find, but can be done.    The  ones that are almost impossible to fine, without running data through the rules engine are the ones using different operations to do the same thing.\nI do not have any ready examples from the rules file, but made up examples would be things such as:\n]]\n}[}[\n}}[[\n. $ wc ../dive.rule dive_dedupe.rule\n 123289  262282  973248 ../dive.rule\n 112552  244212  897871 dive_dedupe.rule\n 235841  506494 1871119 total\nThis was just pure easy to find duplicates, which simply were rules where there are spaces between rules difference.  This was an 'in-place' removal. Only the 2nd (or more) duplicate was removed.\nThis change in of itself, gives about a 10% overall throughput improvement, if using that ruleset.  There are still duplicates in there, btw. This is just the most easy write scripts to auto find and remove them.\n. Created PR #304 with the changes (only changes to dive.rule, and ONLY the pure white space identical rules).\nBut there are over 10k of them\n. Right now, the only thing 'automated' is the finding of extraneous white space.  No, I have not run that against other rule files, but easily could.  I image that most of the rule files which are accumulations of 'random' generated rules will have duplicates in them\nOne other thing about dive (and likely others), is that the xNM command likely should be changed to the ONM  I do not know if all of them should, but by looking at some of them, it is obvious that the logic for the current xNM was not right for the rule to find much.  Things like\nx42\n'8 x42\nare almost certainly supposed to be the logic for\nO42\n'8 O42\n. I found about 30 or so like this.  I have redone, just not pushed the changes.  For the 2nd test, I actually pull entire 'proper' rules based upon length, and any left over white space is removed. the first run (that is checked in right now), was simply cat x | sed 's/ //g' so yes, what happened above failed to be viewed as distinct, and does need to be reverted back.\n. This shows the changes, and yes, ,there are rules in dive.rule that need put back, since the spaces removed WERE part of valid commands (mostly $ or ^ rules)\nhttps://github.com/jfoug/oclHashcat/commit/7cb4ab0314444420826f9e262aba72d7d2634902\nI could do a PR now with what is there, but I was going to look for other dupes. I know there are a lot more in dive.rule, I just do not know how easily they can be 'auto' removed. I certainly do not want to do hand edits for 100's or 1000's of different lines.  That would take forever.\nSome I have ways to find, I just need to make changes so that I can auto remove them. Those are:\npure 's' commands (order).\ncycles in s commands   like sa4si1sa@  (made up).  The sa@ is no-op\nwhere things like $ and ]  or ^ and [ totally offset each other (i.e. become no-ops).\norder of blocks of [ and ] rules  i.e.   []  vs ][  or [[[] vs ][]], etc\nI have code to point out the above dupes, but nothing to auto-remove (yet).  I bet there are many more 'types' of duplicate rules, but i have not looked much deeper.\nIf you want me to, I could push for just the dive.rule line additions to get it corrected, and then wait on the rest until I have more done.\n. PR #307 adds back 30+ rules into dive.rule which were over aggressively removed with a brain dead sed space removal command. I used an intelligent space removal to do it the 2nd time which was based upon length of rule commands to remove spaces. The patch uploaded was the few items which were erroneously removed the first time. There are some other duplicate removals in that first patch, most (all?) were actually identical lines, not even space duplicates.\nThen the 2nd commit is a bunch of harder to find dupes.  In the commit, is a list of the exact lines removed from the dive.rule file.  I also listed the canonization rules I used.  I did things like sort blocks of 's' commands. Sort blocks of ^ and $ commands. sort blocks of [ and ] commands.  Remove pairs of $x] and ^x[ commands, etc. The comment in the commit lists them all.   I believe a lot of that duplication comes either from random generation of rules run at different times, OR possibly in someone making rulesets (in the case of s order) and not fully grasping what makes a covering set, or using some script to generate them, and having a busted permutation generator.\nI am sure I will think of other dupe things over time (  { and } pairs are a no-op, etc).  But some of the other dupes (there still are many), are much harder to find.  Some of them are not 100% duplicate either, just duplicates for words of certain length (  such as '5 and p2'5 and d'5 )\n. are some of the dupes there due to these issues?  That can be handled by changing the code to remove the duplicate which does not work on oclHashcat instead of simply removing the '2nd seen' duplicate.\n. Can you point me to documentation on which rules are not oclHashcat supported?\n. One thing I could do, is to simply provide the script files. There is nothing I am hiding in there.\nI do think that no matter what, we need to have separate commits for each type of duplication found.\nThese are:\n- pure duplication (i.e. exact same line appearing later in the rule file).\n- extraneous space duplication  (this is the worst offender with dive.rule)\n- other duplication rules 1 at a time\nThis way, it is much easier to validate that everything being removed fits the rule properly, and that ALL are really duplicates.\n. yes.  But I will do this step by step, since things are MUCH easier to see if only one type item is done.\nBy far the WORST offender, is the errant space duplicate problem in dive.rule  That one alone is huge.  The others do exist, but are not nearly as bad.  But some of those are much more complex to see that they are right\n. It is full of good rules, but is at least 15% slower (due to duplicates), than it should be.\n. #308 contains 2 commits.\nThe first is 100% 'pure' duplicate lines (i.e. lines that are already 100% the same as some prior line).\nThe 2nd is duplicates found by removal of superfluous white space (space characters).  This was done by first tokenizing the rules themselves into proper commands of the right length, then removing all extra white space.  This logic replaces the faulty  cat xxx.rule | sed 's/ //g' > xxx_missing_ws.rule logic which removed about 40 rules which were not duplicates.\nWithin comments in the PR, are all scripting code used to find these duplicates, and auto remove them from the rule files.\n. I will make no further PR about dupes, until these have been fully accepted.  I do not foresee any problem here, since these really are 100% 'pure' duplicate rules.\nOnce everything is happy here, I will start removing other duplicates, but only 1 'rule type' at a time, so that it is easier to validate only correct duplicate rule lines are removed.\n. I am going to work on it.  But I want to do it a step at a time, so we can more easily validate that the changes ARE valid.  There have been some missteps and finding them is not always easy when there are multiple types of duplication that is much more complex than what the diff program can find ;)\n. The next thing I am looking for is s 'reductions'.  This can remove some duplicates, but will also change some rules.\nThe 'reductions' are like this:\nsabsbc becomes sbc\nsabsac becomes sab\nThis will cause some duplicates, and also causes some rules to be reduced in number of operations.  This is required to be done before I start to reorder the order of the s commands. That reorder finds many duplicates.  but if these type no-ops, and cycles are there, then the reorder is not valid.\n. Unfortunately these are having to be dealt with by hand. I do not have an 'auto' fixer tool for these. I can find them however.  These are the rules in dive.rule that I have found:\nR0se5s5&  turned into R0se&\ns.hx13sh<  turned into s.<x13\nslOsOZ  turned into slZ\nsk@s@{oB8  turned into sk{oB8\n+8sPMsMW  turned into +8sPW\nsYfsfut  turned into sYut\nsTDo5OsT*  turned into sTDo5O\nso!$=s!=  turned into so=$=\nso!s!=$=  turned into so=$=\noA[s2dsdX  turned into oA[s2X\ns9Cs9W  turned into s9C\nsDJ*7AsD@  turned into sDJ*7A\ns7ys7)  turned into s7y\nsDk*20sDF  turned into sDk*20\ns^6s6I  turned into s^I\nsiNsNk  turned into sik\nsOusOG  turned into sOu\nsfusue  turned into sfe\nsZEsEd  turned into sZd\nsXcs^Us^`  turned into sXcs^U\ny2s|asaR  turned into y2s|R\nsVusV*o1{  turned into sVuo1{\nsyMsyP  turned into syM\nsaGsGE  turned into saE\n. Yes I do, but I sent you the big change off list.  I wanted to hear from you first, since this was a set of MUCH HARDER to spot duplication.  Some are trivial to see, some not so much.  I just thought you might want to run some testing yourself, before we accept this PR,\nBut I can get a PR done, no problem.\nBtw, that PR will be the last for dive (unless we go through and look for and remove no-op commands from some rules to speed them up).  Once that PR is done, there are NO more duplicates in dive.  The method of running data will flush out all of them.\n. I see your point, you are 100% correct.\nZERO\nsZEsEd == ddRO\nsZd        == dERO\nThat certainly is different.  That 'chain' optimization was one I 'saw' by hand, and then coded for it.  We certainly can undo them. There were some, but not a huge amount.  They should have all been in one of the earlier commits, so they should be easy to undo, and I certainly can get them back in.\nYou are not seeing these in the current dup set?  I would think not...  With the data provided I would find it hard to see anything like that not being seen as different.\n. One thing I 'should' have done, is with the last set of duplicates, to search the block that were all the same, and chosen the first one of the shortest number of operations.  It would have removed more of the 'non-optimal' rules.    A lot of them  early on were optimal  (some just 1 command).  But I am pretty sure that some of them were not the best of the group.   The program I wrote simply took the first rule of the group (i.e. earliest line number which that 'type' was found).\nIf you have not merged yet, I 'could' redo the commit, and change the logic to pick the rule with fewest commands.\n. I see you have not merged that yet, so if you want me to, I can certainly change the PR to behave that way.  It would make better, slightly quicker rules.\n. I fully agree there.. if something in hand written, unless it is wrong (like unforeseen duplicates), then it pretty much should stay intact.\nOn this last PR, why don't you reject it, and I will put some more time in on it. I will do the 'least' commands change, and will also spend some time looking for things that are not duplicates.  I did find some.\n```\nduplicate rules:\n(115)\n(53541)  'V\n(100438)  'Z\n(105211)  'W\nThese are not duplicates, but passed my random input data due to line lengths.  I thought I had long enough stuff, but I guess not.\nduplicate rules: (non-optimal)\n(185)  }[$e\n(186)  }$e[\n(410)  ]$e\nduplicate rules: (non-optimal)\n(225)  }o05\n(95882)  ]^5\nduplicate rules: (non-optimal)\n(226)  }o04\n(90399)  ^4]\n(95884)  ]^4\n```\nThe min-command logic would have caught the 2nd block.   But the optimal speed for block 3 and 4 is probably the last item, since ] and ^ are probably much faster than the } operator.\n. I will get the non-duplicate s-chain rules back in where they were removed. That will be quicker.   Then the de-dupe of dive.rule I will work on a bit.I am traveling for the next few days, so I may have down time to do this, and I may not, hard to say.\n. Which of these would you rather see in the rules:\n$6$6$6\n $6Z2\n$6$6$6$6\n $6Z3\nIn the 2nd set, I can really see using $6Z3  2 commands vs 4.  But in the other one, I am not sure how much time savings there is, vs ease of reading the rule by non-techies, OR does that matter at all ?\nI actually like the john rule of Az'666' or Az|6666| but that is not the question ;)  It gets much easier for pre-pending:    A0'123' vs ^3^2^1  but at this time, this is not in HC, due to lack of handling the z (or l, n, m) length values, or the A command.\nBut there are quite a few of these app/pre-pend the same character multiple times.  It may be best to use z or Z for any that are more than 2 same characters.  The pick least commands duplicate should catch a large percentage of these, since I bet many of them have been duplicated.\n. > all about easy to read :)\nSeriously ?  I thought it was about the fastest way to crack ;)\nBut I can certainly do $6$6$6....$6 if you want it that way, and leave these readable but non-optimal.\nNOTE, some of the reduction of command operations WILL make rules that are more obscure and harder to read, for sure. Many times they become 'better', but sometimes they are fewer commands, but more obscure  (like the $6Z3 vs $6$6$6$6)   And I know that some commands may be much slower 'in code' than others.   ] has to be pretty damn fast vs other commands that may be a bit slower.  I would also thing that $ and ^ would be faster than using i but that may not be the case.\nAre there any rules which are NOT supported by the GPU that I should NOT be using for some of these ruleset, or be on the lookout for in the rulesets?  I have looked in the wiki and other places, and i can not seem to find much about what is NOT in the GPU, other than 256 command limit (which is HUGE, btw).\n. #323 adds those rules that were NOT duplicates in all cases back in. Note, I did not remove the stripped down rules (just in case they also randomly crack something, lol).\nI will spend some time on the dive duplicates found submission. It may end up being more than 1 PR, I do not know.  It is huge, and NOT a simple 'rule' I found, but 100's if not 1000's of little things that can cause duplication    (like [ or D0 or O01 or {] or ^#[[ etc).  These can be trickier to make sure they are dupes (like I mention above, I HAVE found some that are not).  Also, getting an auto-written script/program to figure out which of a set of duplicates should be kept AS THE rule, is also not easy.  So instead of jamming something in, I will spend a bit of time, and try to get it right, or if still too hard, to break it up into more manageable sizes. But even if we say 1000 rule changes is 'manageable', that means 10 PR's and I think that in itself is a bit much.\n. I am glad we put off the prior work. There were problems with the script. I added much validity checking, making sure that everything matches perfectly. First off, there were 6 comment lines in the file I was not accounting for.  But I have to 'start' the adding of offsets at 7. Then about a third of the way through removing data, the matching line is only offset of 6. Somewhere there must be a rule line that is confusing my dupe finder, but for the life of me, I can not find it.  But now that I have the checking logic, that one line really should not matter.  (it is one line turning into 2 somehow, but I do not know which one, or why).\nIts amazing what can be done when your flight in arrives at 8:55 pm, and the layover departure is at 7:00 am ;)  Find all sorts of things to try to make the time pass.....\n. Ive been working on this the a bit over the weekend.  I think its now pretty solid and safe.  I do have it picking the smallest rule.  It chooses the lowest command count, and if 2 commands are same count, it chooses the shorter (character wise) of the 2.  The exception is for things like:  $x$x$x..$x  or ^x^x^x,..  Those are kept intact since you wanted them that way, instead of picking the shorter $xZ3 or whatever it is.  BUT using shorter length of same number of commands gets you things like ^a^b^c instead of i0ai0bi0c type ones, and i find the ^ to be easier to remember.\nI have dug down to a couple thousand lines, and all spot checks are 100% duplicate. There are no more 'hidden' non duplicates that I have seen at all.  There are certainly a lot of duplicates which would have been about 100% impossible to spot, without software to simply run the rules against wordlists made to try to flush out the duplication.  Rules that do not look ANYTHING close to being the same, but when you dig down and look, they certainly are.  There are many that simply have no op stuff in them, such as i0x$a[  That simply is $a due to everything else just being busy work, doing nothing towards the end result. Theres quite a bit of that.\nBut now, when this all gets done, there will be a little over 98k rules in dive.  I think that's about 25% down from where it started.  Still the same ruleset.  A good one.  It will just work that much faster now.  Also, I think it will work better, with the 25k x commands now being O commands, which is the 'proper' logic that originally cracked 'something' to get added to the ruleset.  You might put a notify out that people may actually want to re-run that ruleset if they  have used it since the logic change of x converting into O, or at least to grep the O rules out and run them again.\nI will certainly finish up dive this week, and will probably post it as a single PR, and send you offlist the list of work done, and completed rule set so that you can look at it offline.  I did re-run the entire ruleset before and after against a 6000 word generated list through john, capturing all output words, then uniquing them and sorting. There were about 100 words not generated after the processing sorting and uniquing, there were about 100 lines not in the new data, but they all had somewhat the same pattern, and all had the same binary garbage in them, and I think it is an issue within john's rule proccessing for some encoding aware case changing. I am not re-running, since it's about 4 hours or processing, and I have to have the laptop plugged in, since it chews up the battery when under that load.  I 'know' the rule files are equivalent (certainly for HC), it is just some nuanced issues in john that HC does not deal with (broken unicode letters in the random garbage I generated to find the duplicates).  Magnum did a lot of the encoding stuff, and there are times I would like to re-do some of it to better handle arbitrary binary data.  The encoding logic too easily screws up malformed input data, where I think we should simply leave it as original.    But 99.99% of the time, it does not matter at all.\nWell, once I get dive done, I will run my dupe finding code on some of the other rule sets, to see how clean they are.  The 2 generated might have some, as might d3ad.  The PWP likely has some in it.  Their other rule file seems very clean (hand done).  It usually is the random generated stuff that is bad about the duplicates, because just like writing code, there are 1000's of ways to say foo-bar, lol.\n. > >    There are many that simply have no op stuff in them, such as i0x$a[ ...\n\nI found the example interessting. Are you going to remove the useless work here?\n\nA lot (most?) of this was removed with the last update.  However, if a rule was unique in it's logic, but it still had no-op work in it (offsetting crap, or conditions that can never happen), then it would have  been left in.  However, the method I used in the script to choose the rule to keep out of the block of duplicate rules, would pretty much assure that all no-work commands were removed (most of the time).  The 'keep' rules were:\n1. if 2 rules had differing number of commands, then keep the rule with the fewer commands.\n2. exception to rule 1 was $x$x$x...   or ^y^y^y...  Those were kept over shorter count rules such as $xZ3\n3. if 2 rules had same number of commands, but different lengths (errant spaces removed for length checks), then the shorter length rule was kept.  This would keep things such as ^3^2^1 over i01i12i23\nSo because of the above 'keeper' rules, most rules that had offsetting or no-op work were scrubbed.  So things like i0x$a[ would always get scrubbed, since there was a duplicate $a in the data set.   However, if there was i0x$x[i3z$m and there was not a $x$mi3z rule, then the rule that had that extra no-op pair of commands would not have been removed. \nAre there any left?  I would say there almost certainly are.  However, there likely are few of them, being that if it was randomly generated and DID crack something (to get added to the ruleset at some point), then it is highly likely that a more canonical representation of the rule would also be generated and find something and also added to the ruleset at sometime later. This is how almost all of this duplication grew over time.  A good 'random' rule like sa4se3so0 was created and cracked a bunch. It gets added.  Later, so0sa4se3 gets random generated, and it also cracks a bunch, so it also gets added.  However, together, only 1 of those rules will crack something.  The other never will.\nSo to sum up your original question, no I have not specifically written code to look for these 'never can happen' commands (like usa4) or the offsetting work commands (like ^0[ ) .  But a large percentage HAVE been found and removed as a side effect of the duplication removal project.\n. Here is an interesting block of duplicate rules found in d3ad0ne ;)\nduplicate rules:\n(5687)  *63*63\n(8215)\n(14308)  ^>O01\n(14681)  ^QD0\n(21265)  kk\n(26422)  rr\n(29907)  tt\n(34360)  z3O13\n(34733)  z5O15\n(35307)  }{\nLots of cycles spinning on those, lol.\nAn interesting experiment would be to figure out how many 'make work' rules could be made that end up doing no work at all.   However, I think that there are infinite ways to use the rules engine to give no end change to word, so I do not think that 'experiment' would get very far.\n. It may not be bad to start to 'make' some canonical rules for some of these things.\nThings like all work on front of word should be first then all work on rear of word.\nSo  ^1$1  would be canonical, but $1^1 would not.\nOr, it may be better to claim that commands should be in ASCII sorted order, whenever there are commands which can switch around. (I like that definition better).\nThen things like:\nsa&se3so0  would be in canonical order, but se3so0sa& would not    l$1 would not be canonical, but $1l would   This would not be hard to do within a program.  A rule could be re-arranged, and then checked to make SURE it is still a duplicate.\nOther things:   all O01 should be D0  I0x should be ^x, etc.  Actually, all Ox1 should be replaced with Dx  Also, DxDyDz if xyz are contiguous, should be replaced with Ox3 (or Oy3, etc, whatever is compatible).   There are more of these type multiple ways but one way is better command blocks.\nI am not sure that the ROI is really worth it in this case.  Once we have reduced a rule set to all non-unique rules, then if they are i a canonical format or not may not matter all that much.  Now, if the rule set is being built (especially with random rules), then that would be a different story.  But I do not think there are any ongoing random rule accumulation projects.  If there are, then it might be smart to address them in some canonical manner, as that will help keep some of the duplication out of the mix.  Also, within your rand generation code, it may be possible to build a canonical 'filter' so that when new random rules are generated, at least they are 'standardized' in some manner.\n. I just got back in.  WONDERFUL cycle trip.  11k miles (17k+ km) over 15 days. \nI will pick up on this shortly, after I get my bearings again.\n. All the changes to this point have simply removed duplicates, so there is no harm. It simply speeds up running.  Yes, there are more duplicates AND there are rules that could be reduced  (such as the things like lc, or ^!{ type stuff)\nI do plan on getting back to looking for more duplication, especially now that I have a way to runtime test find the duplicates, but I am still playing catch up with 'real' work, and the long open road still is calling me, so a lot of my time right now is not being spent on OS coding.  But I do plan on picking it up at some point, and again, making the rules 'faster' by trimming off the duplication.\nHowever, your question about 3.0, yes the rules as they are now are 100% identical results, but just faster, and can be put into the release safely.\n. I used something like this, BUT I had to make a special wordlist that fully exercised all rules enough to get rid of many of the false positives.  There are a few rules that are identical to each other, EXCEPT for certain situations (like ending in the letters ck, or starting with a p, or 2nd letter a, or length > 12, etc, etc).\nHowever, finding duplicates automatically, then you can sit down and use your brain to see if something is or IS NOT a duplicate, and the ones not duplicate, make sure they are not removed.  Jens found several early on that my script was labeling as duplicates, and with improvements to the wordlist I was able to run check duplicates and was not seeing any false positives any more. \nI simply have been busy doing non OS coding stuff and have not picked this project back up.  However, a very large part of the duplication has already been flushed out.  But there certainly still is 'some' left in certain rule set files.\nMy tool is a add on (never checked in) used in the rules engine of JtR.  This rule worked by running each rule against my hand generated rule set, appending each output word (and a newline), into a buffer.  I then compute SHA1 on that buffer and simply kept that buffer.  Then on to the next rule. When checksums matched, those 2 rules were flagged as duplicate, and then output.  The scripts I had even took the original rule file, and spit out a rule file minimized.  Within that minimized rule file, it tried to output the line with the fewest rule commands and then if there were multiple rules that had the same number of commands, then the rule with the minimal length string was output.  I did put a couple of 'exceptions' to that logic, where Jens would rather have [[[[^a instead of O04^a even though it was 5 commands vs 2\n. That code is not checked in.  Just specialty stuff I did specifically to find these dupes.  It would not fit well into OS jtr code tree.\n. here is the 'rulez' code.  NOTE, there is lots of other scripts and things that glue this all together.\n``` diff\ndiff --git a/src/Makefile.in b/src/Makefile.in\nindex 6475436..96e9497 100644\n--- a/src/Makefile.in\n+++ b/src/Makefile.in\n@@ -117,7 +117,7 @@ JOHN_OBJS = \\\n    undrop.o \\\n    regex.o pp.o \\\n    c3_fmt.o \\\n-   unique.o putty2john.o gpg2john.o memdbg.o\n+   unique.o rulez.o putty2john.o gpg2john.o memdbg.o\nOCL_OBJS = common-opencl.o opencl_autotune.o bt.o bt_hash_type_64.o bt_hash_type_128.o bt_hash_type_192.o bt_twister.o\n@@ -133,7 +133,7 @@ GENMKVPWD_OBJS = \\\n    genmkvpwd.o mkvlib.o memory.o miscnl.o path.o memdbg.o\nPROJ = ../run/john@EXE_EXT@ ../run/unshadow@EXE_EXT@ ../run/unafs@EXE_EXT@ ../run/unique@EXE_EXT@ ../run/undrop@EXE_EXT@ \\\n-   ../run/rar2john@EXE_EXT@ ../run/zip2john@EXE_EXT@ \\\n+   ../run/rar2john@EXE_EXT@ ../run/zip2john@EXE_EXT@ ../run/rulez@EXE_EXT@  \\\n    ../run/genmkvpwd@EXE_EXT@ ../run/mkvcalcproba@EXE_EXT@ ../run/calc_stat@EXE_EXT@ \\\n    ../run/tgtsnarf@EXE_EXT@ ../run/racf2john@EXE_EXT@ ../run/hccap2john@EXE_EXT@ \\\n    ../run/raw2dyna@EXE_EXT@ ../run/keepass2john@EXE_EXT@ \\\n@@ -494,6 +494,8 @@ rpp.o:  rpp.c arch.h params.h config.h rpp.h common.h memory.h memdbg.h os.h os-a\nrules.o:   rules.c arch.h misc.h jumbo.h stdint.h autoconfig.h params.h common.h memory.h formats.h loader.h list.h logger.h rpp.h config.h rules.h options.h getopt.h john.h os.h os-autoconf.h unicode.h encoding_data.h memdbg.h\n+rulez.o:   rulez.c arch.h misc.h params.h memory.h jumbo.h rpp.h rules.h memdbg.h\n+\n sboxes.o:  sboxes.c nonstd.c\nsboxes-s.o:    sboxes-s.c\n@@ -681,6 +683,10 @@ kernels: @KERNEL_OBJS@\n    $(RM) ../run/unique\n    $(LN) john ../run/unique\n+../run/rulez: ../run/john\n+   $(RM) ../run/rulez\n+   $(LN) john ../run/rulez\n+\n #####################################################################\n # These targets MUST match ALL of the john targets that use ln -s\n # These are built for Win32, so that we have a 'native' symlink back\n@@ -749,6 +755,10 @@ kernels: @KERNEL_OBJS@\n    $(CC) symlink.c -o ../run/unique.exe\n    $(STRIP) ../run/unique.exe\n+../run/rulez.exe: symlink.c\n+   $(CC) symlink.c -o ../run/rulez.exe\n+   $(STRIP) ../run/rulez.exe\n+\n ########################################################\n # Not linked to symlink for a .exe file, so simply make\n # single targets, using the EXE_EXT macro\ndiff --git a/src/common.c b/src/common.c\nindex 5e00969..a912990 100644\n--- a/src/john.c\n+++ b/src/john.c\n@@ -169,6 +169,7 @@ extern struct fmt_main fmt_cuda_rawsha256;\n extern int unshadow(int argc, char argv);\n extern int unafs(int argc, char argv);\n extern int unique(int argc, char argv);\n+extern int rulez(int argc, char argv);\n extern int undrop(int argc, char **argv);\nextern int base64conv(int argc, char argv);\n@@ -1899,6 +1900,11 @@ int main(int argc, char argv)\n        return undrop(argc, argv);\n    }\n\nif (!strcmp(name, \"rulez\")) {\nCPU_detect_or_fallback(argv, 0);\nreturn rulez(argc, argv);\n}\n+\n    if (!strcmp(name, \"unique\")) {\n        CPU_detect_or_fallback(argv, 0);\n        return unique(argc, argv);\n```\n\nthis is rulez.c  (NOTE, this is NOT quality code, just a hack I was doing for this project)\n``` C\n/\n * This file is part of John the Ripper password cracker,\n * Copyright (c) 2016 Jim Fougeron\n \n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted.\n \n * There's ABSOLUTELY NO WARRANTY, express or implied.\n \n * stand alone rules tool for JtR.\n \n\n */\nif AC_BUILT\ninclude \"autoconfig.h\"\nelse\ndefine _POSIX_SOURCE / for fdopen(3) /\nendif\ninclude \ninclude \ninclude \ninclude \ninclude \"arch.h\"\ninclude \"misc.h\"\ninclude \"params.h\"\ninclude \"memory.h\"\ninclude \"jumbo.h\"\ninclude \"path.h\"\ninclude \"config.h\"\ninclude \"options.h\"\ninclude \"unicode.h\"\ninclude \"rpp.h\"\ninclude \"rules.h\"\ninclude \"md5.h\"\nifdef _MSC_VER\ninclude \"missing_getopt.h\"\nelse\ninclude \nendif\ninclude \"memdbg.h\"\nstatic struct list_main *inp_list;\ntypedef struct word_item {\n    char **candi;\n    char expected[128];\n    int num, hits;\n} word_item;\nvoid add_line(char line, int max_candi) {\n    char word, pos, c;\n    word_item item;\n    char user[128], pass, cp;\n    struct list_entry *link;\npass = strchr(line, ':');\nif (!pass)\n    return;\n*pass++ = 0;\nstrncpy(user, line, 128);\ncp = strstr(pass, \":$2a$\");\nif (!cp)\n    return;\n*cp = 0;\n\nitem = mem_alloc(sizeof(word_item));\nitem->num = item->hits = 0;\nitem->candi = mem_calloc(sizeof(char*), max_candi);\n\nstrcpy(item->expected, pass);\nitem->candi[0] = strdup(user);\n++item->num;\n\npos = user;\nwhile (item->num < max_candi) {\n    int j, bWanted=1;\n    word = pos;\n    while (*word && CP_isSeparator[ARCH_INDEX(*word)])\n        word++;\n    if (!*word)\n        break;\n\n    pos = word;\n    while (!CP_isSeparator[ARCH_INDEX(*pos)])\n        pos++;\n    c = *pos;\n    *pos = 0;\n    for (j = 0; j < item->num; ++j) {\n        if (!strcmp(item->candi[j], word))\n            bWanted = 0;\n    }\n    if (bWanted)\n        item->candi[item->num++] = strdup(word);\n    *pos++ = c;\n}\nlink = mem_calloc(sizeof(*link)+sizeof(item),1);\nmemcpy(link->data, &item, sizeof(item));\nlist_add_link(inp_list, link);\n\n}\nstatic int usage(char *name)\n{\n    fprintf(stderr, \"Usage: %s -m mode [-c config_path] -r ruleset [-i inputfile] [-s singlewords] [-d] [-q]\\n\"\n        \"  -m mode is one of:\\n\"\n        \"     single     (finds single rules, based upon user name and a rule set)\\n\"\n        \"     canonical  (tries to put into standard format, and optimizes, also helps find dupes where things are same but in different order)\\n\"\n        \"     searchdup  (finds dupes when rules are not exactly the same through running data, looking for identical results)\\n\"\n        \"\\n\"\n        \"     single [-i inputfile] [-s singlewords] [-d] \\n\"\n        \"        -d is deep (does not stop when first match is found)\\n\"\n        \"        -q is a bit more quiet\\n\"\n        \"\\n\"\n        \"     searchdup digs down, and tries to find duplicate rules.\\n\"\n        \"        requires -i for input wordlist\\n\"\n            \"\",\n            name);\n    return EXIT_FAILURE;\n}\nstatic void release(struct list_entry pl) {\n    word_item pi = ((word_item)pl->data);\n    char p = (char*)pl->data;\n    int i;\nfor (i = 0; i < pi->num; ++i)\n    MEM_FREE(pi->candi[i]);\nMEM_FREE(pi->candi);\nMEM_FREE(pi);\nMEM_FREE(p);\n\n}\nstatic int rulez_single(int argc, char argv)\n{\n    int c;\n    char rname=NULL, cdir=NULL, prerule, rule=NULL, word, iname=NULL, line[512];\n    struct rpp_context ctx;\n    int rule_count;\n    FILE in;\n    int hits, idx;\n    char  rule_text;\n    char ** not_used_txt;\n    int single=1;\n    int deep=0;\n    int quiet=0;\n    int total_words=0, found_words=0, tot_rules_used=0, idx_not_used=0;\n/* Parse command line */\nif (argc == 1)\n    return usage(argv[0]);\nwhile ((c = getopt(argc, argv, \"m:c:r:i:s:d!q!\")) != -1) {\n    switch (c) {\n    case 'm':\n        // do nothing.  Mode got us 'hear'.\n        break;\n    case 'c':\n        if (*optarg == '=') cdir = &optarg[1];\n        else                cdir = optarg;\n        break;\n    case 'r':\n        if (*optarg == '=') rname = &optarg[1];\n        else                rname = optarg;\n        break;\n    case 'i':\n        if (*optarg == '=') iname = &optarg[1];\n        else                iname = optarg;\n        break;\n    case 's':\n        if (*optarg == '=') single = atoi(&optarg[1]);\n        else                single = atoi(optarg);\n        break;\n    case 'd':\n        deep = 1;\n        break;\n    case 'q':\n        quiet = 1;\n        break;\n    case '?':\n    default:\n        return usage(argv[0]);\n    }\n}\n\nif (cdir != NULL)\n    path_init_ex(cdir);\nelse\n    path_init(argv);\ncfg_init(\"john.conf\", 1);\ncfg_init(CFG_FULL_NAME, 1);\ninitUnicode(UNICODE_UNICODE);\n\n\nif (rpp_init(&ctx, rname)) {\n    return fprintf(stderr, \"! No \\\"%s\\\" mode rules found\\n\", rname);\n}\nrules_init(125);\nrule_count = rules_count(&ctx, -1);\n//printf(\"Rules count == %d\\n\", rule_count);\nhits = mem_calloc(rule_count+1, sizeof(int));\nrule_text = mem_calloc(rule_count+1, sizeof(char*));\nnot_used_txt = mem_calloc(rule_count+1, sizeof(char*));\nin = fopen(iname, \"r\");\nif (!in) {\n    return fprintf (stderr, \"Unable to open file %s\\n\", iname);\n}\nlist_init(&inp_list);\nfgets(line, sizeof(line), in);\nwhile (!feof(in)) {\n    ++total_words;\n    add_line(line, single);\n    fgets(line, sizeof(line), in);\n}\n\nprerule = rpp_next(&ctx);\nidx = 0;\nwhile (prerule) {\n    struct list_entry *current, *prior=NULL;\n    int i;\n    word_item *pWord;\n\n    current = inp_list->head;\n    while (current) {\n        pWord = *((word_item**)current->data);\n        i = 0;\n        while (i < pWord->num) {\n            rule = rules_reject(prerule, -1, pWord->candi[i], NULL);\n            if (rule) {\n                word = rules_apply(pWord->candi[i], rule, -1, \"\\n\");\n                if (word && !strcmp(word, pWord->expected)) {\n                    if (!rule_text[idx]) {\n                        rule_text[idx] = strdup(rule);\n                        ++tot_rules_used;\n                    }\n                    hits[idx]++;\n                    pWord->hits++;\n                    if (pWord->hits == 1)\n                        found_words++;\n                    break;\n                }\n            }\n            ++i;\n        }\n        if (pWord->hits && !deep) {\n            struct list_entry *next = current->next;\n            release(current);\n            if (!prior)\n                inp_list->head = next;\n            else\n                prior->next = next;\n            current = prior;\n        }\n        prior = current;\n        if (current)\n        current = current->next;\n    }\n    if (!rule_text[idx] && rule)\n        not_used_txt[idx_not_used++] = strdup(rule);\n    prerule = rpp_next(&ctx);\n\n    ++idx;\n}\nfor (idx = 0; idx < rule_count; ++idx) {\n    if (hits[idx]) {\n        printf (\"%05d  %s\\n\", hits[idx], rule_text[idx]);\n        MEM_FREE(rule_text[idx]);\n    }\n}\nif (!quiet) {\n    fprintf(stderr, \"Rules count  == %d\\n\", rule_count);\n    fprintf(stderr, \"Rules used   == %d\\n\", tot_rules_used);\n    fprintf(stderr, \"total words  == %d\\n\", total_words);\n    fprintf(stderr, \"Found words  == %d\\n\", found_words);\n    fprintf(stderr, \"Missed words == %d\\n\", total_words-found_words);\n\n    fprintf(stderr, \"\\nThese rules were NEVER used!\\n----------------------------\\n\");\n    for (idx = 0; idx < idx_not_used; ++idx) {\n        fprintf(stderr, \"%s\\n\", not_used_txt[idx]);\n    }\n}\n// Clean up memory we have consumed.\nfor (idx = 0; idx < idx_not_used; ++idx)\n    MEM_FREE(not_used_txt[idx]);\nMEM_FREE(not_used_txt);\nfor (idx = 0; idx < tot_rules_used; ++idx) {\n    MEM_FREE(rule_text[idx]);\n}\n{\n    // this structure is a bit ugly. we have built a 'release'\n    // function to hide the under the hood crap.\n    struct list_entry *cur = inp_list->head;\n    while (cur) {\n        struct list_entry *next = cur->next;\n        release(cur);\n        cur = next;\n    }\n}\nMEM_FREE(rule_text);\nMEM_FREE(hits);\n\npath_done();\ncleanup_tiny_memory();\n\nMEMDBG_PROGRAM_EXIT_CHECKS(stderr);\n\nreturn 0;\n\n}\nint rulez_searchdup(int argc, char argv)\n{\n    int c;\n    char rname=NULL, iname, cdir=NULL, prerule, rule=NULL, word, tmp, cp;\n    struct rpp_context ctx;\n    int rule_count;\n    FILE in;\n    int hits, idx;\n    char rule_text;\n    char inwords;\n    unsigned char dgst;\n    MD5_CTX md5;\n    int  nwords, flen, i, first;\n/* Parse command line */\nif (argc == 1)\n    return usage(argv[0]);\nwhile ((c = getopt(argc, argv, \"m:c:r:i:\")) != -1) {\n    switch (c) {\n    case 'm':\n        // do nothing.  Mode got us 'hear'.\n        break;\n    case 'c':\n        if (*optarg == '=') cdir = &optarg[1];\n        else                cdir = optarg;\n        break;\n    case 'r':\n        if (*optarg == '=') rname = &optarg[1];\n        else                rname = optarg;\n        break;\n    case 'i':\n        if (*optarg == '=') iname = &optarg[1];\n        else                iname = optarg;\n        break;\n    case '?':\n    default:\n        return usage(argv[0]);\n    }\n}\nif (cdir != NULL)\n    path_init_ex(cdir);\nelse\n    path_init(argv);\nif (!rname)\n    return usage(argv[0]);\ncfg_init(\"john.conf\", 1);\ncfg_init(CFG_FULL_NAME, 1);\ninitUnicode(UNICODE_UNICODE);\n\n\nif (rpp_init(&ctx, rname)) {\n    return fprintf(stderr, \"! No \\\"%s\\\" mode rules found\\n\", rname);\n}\nrules_init(125);\nrule_count = rules_count(&ctx, -1);\nfprintf(stderr, \"Rules count == %d\\n\", rule_count);\nhits = mem_calloc(rule_count+1, sizeof(int));\nrule_text = mem_calloc(rule_count+1, sizeof(char*));\n\nin = fopen(iname, \"r\");\nif (!in) { fprintf (stderr, \"Could not open input wordlist file %s\\n\", iname); exit(0); }\nfseek(in, 0, SEEK_END);\nflen = ftell(in);\ntmp = mem_alloc_tiny(flen+1, 1);\nfseek(in, 0, SEEK_SET);\nfread(tmp, 1, flen, in);\ntmp[flen] = 0;\nnwords = 0;\ncp = strtok(tmp, \"\\r\\n\");\nwhile (cp) {\n    ++nwords;\n    cp = strtok(NULL, \"\\r\\n\");\n}\nfseek(in, 0, SEEK_SET);\nfread(tmp, 1, flen, in);\ninwords = mem_alloc_tiny(nwords*sizeof(char*), sizeof(char*));\nfprintf(stderr, \"Dict word count == %d\\n\", nwords);\ndgst = mem_alloc_tiny(rule_count*sizeof(char*), sizeof(char*));\nfor (i = 0; i < rule_count; ++i)\n    dgst[i] = mem_calloc_tiny(16,1);\nnwords = 0;\ncp = strtok(tmp, \"\\r\\n\");\nwhile (cp) {\n    if (*cp != '#')\n    inwords[nwords++] = cp;\n    cp = strtok(NULL, \"\\r\\n\");\n}\nfclose(in);\n\nprerule = rpp_next(&ctx);\nidx = flen = 0;\nwhile (prerule) {\n    int i;\n    rule = rules_reject(prerule, -1, inwords[0], NULL);\n    if (!rule) {\n        prerule = rpp_next(&ctx);\n        continue;\n    }\n    rule_text[idx++] = strdup(rule);\n    if (idx%10 == 0) {\n        fprintf (stderr, \"%*.*s\\r\", flen, flen, \" \");\n        flen = fprintf (stderr, \"(%d / %d), %s\\r\", idx, rule_count, rule);\n    }\n    MD5_Init(&md5);\n    for (i = 0; i < nwords; ++i) {\n        rule = rules_reject(prerule, -1, inwords[i], NULL);\n        if (rule) {\n            word = rules_apply(inwords[i], rule, -1, \"\\n\");\n            if (word) {\n                MD5_Update(&md5, &i, sizeof(i));\n                MD5_Update(&md5, word, strlen(word));\n            }\n            ++i;\n        }\n    }\n    MD5_Final(dgst[idx-1], &md5);\n    prerule = rpp_next(&ctx);\n}\nfprintf (stderr, \"%*.*s\\r\", flen, flen, \" \");\n// first off, scan for any null dgst's. These never had ANY word modified, and likely are nop only\nfirst = 1;\nfor (i = 0; i < idx; ++i) {\n    if (!memcmp(dgst[i], \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\", 16)) {\n        if (first) {\n            first = 0;\n            printf (\"Rules never used at all!\\n\");\n        }\n        printf(\"(%d)  %s\\n\", i, rule_text[i]);\n    }\n}\n\nfor (i = 0; i < idx-1; ++i) {\n    int j;\n    first = 1;\n    if (!memcmp(dgst[i], \"\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\\0\", 16))\n        continue;\n    for (j = i+1; j < idx; ++j) {\n        if (!memcmp(dgst[i], dgst[j], 16)) {\n            if (first) {\n                printf(\"duplicate rules:\\n(%d)  %s\\n\", i, rule_text[i]);\n                first = 0;\n            }\n            memset(dgst[j], 0, 16);\n            printf(\"(%d)  %s\\n\", j, rule_text[j]);\n        }\n    }\n}\nMEM_FREE(rule_text);\nMEM_FREE(hits);\n\npath_done();\ncleanup_tiny_memory();\n\nMEMDBG_PROGRAM_EXIT_CHECKS(stderr);\n\nreturn 0;\n\n}\nint rulez_canonical(int argc, char **argv)\n{\n    return 0;\n}\nint rulez(int argc, char **argv)\n{\n    // find the -m (should be first), and then call the right rulez() based upon the 'mode'\n    if (argc < 3 || strcmp(argv[1], \"-m\"))\n        return usage(argv[0]);\n    if (!strcasecmp(argv[2], \"single\"))\n        return rulez_single(argc, argv);\n    if (!strcasecmp(argv[2], \"searchdup\"))\n        return rulez_searchdup(argc, argv);\n    if (!strcasecmp(argv[2], \"canonical\"))\n        return rulez_canonical(argc, argv);\n    usage(argv[0]);\n    return 1;\n}\n```\n``` perl\n$ cat run/rulecanonize.pl\n!/usr/bin/perl\nscript to canonize (or try to) john/hc/crack rules\n\n1 move all validation to as early as possible.\nlength validations, move to start, or to just after prior length changing command\nis char validations.  Move to start (right after lenght validations), or right after or character modifiers.\ns rule, drop any 2nd usage of original letter (the first ate it).\ns rule, if target (2nd letter) of an s is later the first letter of another s, then merge the 2 rules.\nsort s rules by original letter (and pack back to back).\ns logic groupings are bounded by things like case or other changers.\nplace all adjacent [ before ] so [][][ becomes [[[]] and ][ becomes []\nif we find a [ and there was a prior prepend, then drop the most recent prepend and the [\nif we find a ] and there was a prior append, then drop most recent append and the ]\nNote for prior 2, seeing many rule objects has to remove knowledge of the prior prepend, append\nor both.  Things like d } { and many others make removing that prior  append/prepend not be\nsomething that can be done as a no-op any more.\n[ and ] are grouped with {} and possibly o O x v\nremove all : ops, UNLESS : is the entire rule.\nTODO: { in middle of } block can be removed (and one })  { in middle of } block likewise.\nTODO: (found with harder search)\nOrder of NM and MN do not matter.\ncase commands preceeding c (or l or C or u e E) are no op and can be removed, UNLESS something like $^[]{}rdf etc are seen.\nthe case noops are c, l, C, u, t, Tn e E\nZ1] no op, Z2]] no op, etc. z1[ z2[[ no ops. These can be removed just like ^x[ and $x] were.\nsl following a u is nop.  sU following a l is nop\nIf command is 'pure' T, then reorder into sorted by num.  If multiple T are same number, then remove them.\nuse strict;\nmy @ar = ();\nmy $hc = 0;\nmy %map = ();\nmy $lncnt = 0;\nto do raw hashcat rules, just do:    cat xxx.rule | ./rulecanonize -- hc\nif ($ARGV[0] eq '--') {\n        if (defined $ARGV[1] && $ARGV[1] eq 'hc') { $hc = 1; }\n        @ar = ();\n} else {\n        # we may need to control 'what' gets loaded.\n        use File::Basename;\n        use lib dirname(FILE).'/';\n        use lib dirname(FILE).'/../run';\n        require jtrconf;\n        jtrconf::load();\n        @ar = jtrconf::getsection('List.Rules:'.$ARGV[0]);\n}\nchomp @ar;\nmy $force_output_noop_removed = 0;\nforeach my $rule (@ar) {\n        my $cnt=20000;\n        ++$lncnt;\n        if (substr ($rule, 0, 1) eq '#' || length($rule) == 0) { print \"$rule\\n\"; next; }\n        my $rulepp = $rule;\n        if ($hc == 0) {\n                use File::Basename;\n                use lib dirname(FILE).'/';\n                use lib dirname(FILE).'/../run';\n                require jtr_rulez;\n                jtr_rulez::jtr_rule_pp_init($rule, 125, $cnt, $hc);\n        }\n        my $rule_cnt = 0;\n        while (defined ($rulepp) && length($rulepp)>0) {\n                my $canon = canonize($rulepp, $hc, 1);\n                if (!defined $map{$canon}) {\n                        $map{$canon} = $lncnt-1;\n                        if ($force_output_noop_removed == 1) {\n                                print \"$canon\\n\";\n                                print STDERR \"ln-$lncnt:  $rule  reduced to $canon\\n\";\n                        } else {\n                                print \"$rule\\n\";\n                        }\n                } else {\n                        print STDERR \"ln-$lncnt:  $rule  dup of ln-$map{$canon}: $ar[$map{$canon}]\\n\";\n                }\n            if ($hc == 0) {\n                    use File::Basename;\n                    use lib dirname(__FILE__).'/';\n                    use lib dirname(__FILE__).'/../run';\n                    require jtr_rulez;\n                    $rulepp = jtr_rulez::jtr_rule_pp_next();\n            } else {\n                    $rulepp = \"\";\n            }\n    }\n\n}\nsub ch { my ($r, $i) = @;\n        return substr($r,$i,1);\n}\nsub num_val { my ($p) = (@);\n        if (ord($p) >= ord(\"0\") && ord($p) <= ord('9')) {return ord($p)-ord('0');}\n        if (ord($p) >= ord(\"A\") && ord($p) <= ord('Z')) {return  ord($p)-ord('A')+10;}\n        return -1;\n}\nsub canonize { my ($rule, $hc, $sp) = @_;\n        my $rules = tokenize($rule, $hc);\n        my $mod = 1;\n        if (!defined $hc) { $hc = 0; }\n        $force_output_noop_removed = 0;\n# This block of code added SPECIFICALLY to switch all xNM to ONM\nfor (my $i = 0; $i < scalar @$rules; ++$i) {\nif (substr($$rules[$i], 0, 1) eq 'x') {\n$force_output_noop_removed = 1;\nsubstr($$rules[$i], 0, 1) = 'O';\n}\n}\nif ($force_output_noop_removed == 1) {\nmy $s = \"\";\nforeach my $c (@$rules) {\nif (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n$s .= $c;\n}\nreturn $s;\n}\nreturn $rule;\n    # if 'pure' T commands, then order by number, and remove same numbers\n    my $pure = 1;\n    for (my $i = 0; $i < scalar @$rules; ++$i) {\n            if (substr($$rules[$i], 0, 1) ne 'T') {\n                    $pure = 0;\n                    $i = scalar @$rules;\n            }\n    }\n    if ($pure == 1) {\n            my @ar = @$rules;\n            my $s = \"\";\n            while (scalar @ar) {\n                    my $min = 0; my $c = ch($ar[0],1); my $n = num_val($c);\n                    for (my $i = 1; $i < scalar @ar; ++$i) {\n                            if (num_val(ch($ar[$i],1)) < $n) {\n                                    $min = $i;\n                                    $c = ch($ar[$min],1);\n                                    $n = num_val($c);\n                            }\n                    }\n                    $s .= \"T$c\";\n                    splice(@ar, $min, 1);\n            }\n            return $s;\n    }\n    while ($mod == 1) {\n            $mod = 0;\n            my @ar = @$rules;\n            # remove all : and -: (unless it is the ONLY rule)\n            for (my $i = 0; $i < scalar @ar; ++$i) {\n                    if (scalar @ar > 1 && $ar[$i] eq ':') {\n                            splice(@ar, $i, 1);\n                            $force_output_noop_removed = 1;\n                            --$i;\n                    }\n                    if ($ar[$i] eq '-:') {\n                            splice(@ar, $i, 1);\n                            --$i;\n                    }\n            }\n            # remove all identical - rejection rules (keeping the first only.\n            if ($hc == 0) {\n            for (my $i = 0; $i < scalar @ar-1; ++$i) {\n                    if (length($ar[$i]) > 1 && ch($ar[$i],0) eq '-') {\n                            for (my $j = $i+1; $j < scalar @ar; ++$j) {\n                                    if ($ar[$i] eq $ar[$j]) {\n                                            splice(@ar, $j, 1);\n                                            --$j;\n                                    }\n                            }\n                    }\n            }}\n            # put all rejection rules (-) first.\n            if ($hc == 0) {\n            my $rej1 = 0;\n            for (my $i = 0; $i < scalar @ar-1; ++$i) {\n                    if (length($ar[$i]) > 1 && ch($ar[$i],0) eq '-' && $i != $rej1) {\n                            my $s = $ar[$i];\n                            splice(@ar, $i, 1);\n                            splice(@ar, $rej1, 0, $s);\n                            ++$rej1;\n                    }\n            }}\n\n# remove [ and ] if there were $ or ^ (or A[zl] or A0) Likely we should first convert\n# A[lz] into $ and A0 into ^ and then later they get converted back into Az/0\n# NOTE, { } will cause this to fail without adjustments, D may, as could i. as could most anything (such as d)\n# ITW, I did see d and $ad] $a$bd]] which are obviously 3 differnt rules.\n            my $h=-1; my $t=-1;\n            for (my $i = 0; $i < scalar @ar; ++$i) {\n                    my $c = ch($ar[$i],0);\n                    if ($c eq '$') { $t = $i; next; }\n                    if ($c eq '^') { $h = $i; next; }\n                    if ($c eq '[' && $h != -1) {\n                            splice(@ar, $i, 1);\n                            splice(@ar, $h, 1);             # need to handle Az here, and possibly in next line.\n                            $force_output_noop_removed = 1;\n                            $h = $t = $i = -1;\n                            next;\n                    }\n                    if ($c eq ']' && $t != -1) {\n                            splice(@ar, $i, 1);\n                            splice(@ar, $t, 1);             # need to handle A0 here, and possibly in next line.\n                            $force_output_noop_removed = 1;\n                            $h = $t = $i = -1;\n                            next;\n                    }\n                    if (index('dfpODPIxq{}', $c) != -1) {\n                            $h = $t = -1;\n                    } elsif ($c eq 'r') {\n                            my $tmp = $h; $h = $t; $t = $tmp;\n                    } elsif (index('kzy4,', $c) != -1) {\n                            $h = -1;\n                    } elsif (index('KZY6.\\'', $c) != -1) {\n                            $t = -1;\n                    }\n            }\n            # drop 'dupe' s values, or s where an output later becomes an s input.\n            for (my $i = 0; $i < scalar @ar - 1; ++$i) {\n                    if (ch($ar[$i],0) eq 's') {\n                            for (my $j = $i+1; $j < scalar @ar; ++$j) {\n                                    if (ch($ar[$j],0) eq 's') {\n                                            if (ch($ar[$i],1) eq ch($ar[$j],1)) {\n                                                    $mod = 1;\n                                                    splice(@ar, $j, 1);\n                                                    $force_output_noop_removed = 1;\n                                                    # before proceeding, remove ANY others like this\n                                                    for (my $k = $j; $k < scalar @ar; ++$k) {\n                                                            if (ch($ar[$i],1) eq ch($ar[$k],1)) {\n                                                                    splice(@ar, $k, 1);\n                                                                    --$k;\n                                                                    next;\n                                                            }\n                                                    }\n                                                    --$j;\n                                                    next;\n                                            }\n                                            if (ch($ar[$i],2) eq ch($ar[$j],1)) {\n                                                    $mod = 1;\n                                                    substr($ar[$i],2) = substr($ar[$j],2);\n                                                    my $c = substr($ar[$j],1,1);\n                                                    splice(@ar, $j, 1);\n                                                    $force_output_noop_removed = 1;\n                                                    # before proceeding, remove ANY others like this\n                                                    for (my $k = $j; $k < scalar @ar; ++$k) {\n                                                            if ($c eq ch($ar[$k],1)) {\n                                                                    splice(@ar, $k, 1);\n                                                                    --$k;\n                                                                    next;\n                                                            }\n                                                    }\n                                                    --$j;\n                                                    next;\n                                            }\n                                    }\n                            }\n                    }\n            }\n            # now that sCC has been 'reduced' removing dupes and cycles, canonize it by outputting groupings in sorted order\n            for(my $i = 0; $i < scalar @ar; ++$i) {\n                    if (ch($ar[$i],0) eq 's' && ch($ar[$i+1],0) eq 's' && ord(ch($ar[$i],1)) > ord(ch($ar[$i+1],1))) {\n                            my $s = $ar[$i];\n                            $ar[$i] = $ar[$i+1];\n                            $ar[$i+1] = $s;\n                            $mod = 1;\n                            next;\n                    }\n            }\n\n            # convert $ ^ blocks into A0'bbb' and Az'xxx' with A0 packed first.\n            for(my $i = 0; $i < scalar @ar; ++$i) {\n                    if (ch($ar[$i],0) eq '$' && ch($ar[$i+1],0) eq '$') {\n                            $ar[$i] .= substr($ar[$i+1],1);\n                            splice(@ar, $i+1, 1);\n                            --$i;\n                            $mod = 1;\n                            next;\n                    }\n                    if (ch($ar[$i],0) eq '$' && ch($ar[$i+1],0) eq '^') {\n                            my $s = $ar[$i];\n                            $ar[$i] = $ar[$i+1];\n                            $ar[$i+1] = $s;\n                            $mod = 1;\n                            next;\n                    }\n                    if (ch($ar[$i],0) eq '^' && ch($ar[$i+1],0) eq '^') {\n                            $ar[$i] = '^' . substr($ar[$i+1],1) . substr($ar[$i],1);\n                            splice(@ar, $i+1, 1);\n                            --$i;\n                            $mod = 1;\n                            next;\n                    }\n                    if ($ar[$i] eq ']' && $ar[$i+1] eq '[') {\n                            $ar[$i] = '[';\n                            $ar[$i+1] = ']';\n                            $mod = 1;\n                            next;\n                    }\n                    if (index('cClut', $ar[$i]) != -1 && $ar[$i+1] eq ']') {\n                            $ar[$i+1] = $ar[$i];\n                            $ar[$i] = ']';\n                            $mod = 1;\n                            next;\n                    }\n                    if (index('lut', $ar[$i]) != -1  && $ar[$i+1] eq '[') {\n                            $ar[$i+1] = $ar[$i];\n                            $ar[$i] = '[';\n                            $mod = 1;\n                            next;\n                    }\n                    # not sure these are right, so left out of code.\n                    #if (substr($ar[$i],0,1) eq '$' && $ar[$i+1] eq '[') {\n                    #       $ar[$i+1] = $ar[$i];\n                    #       $ar[$i] = '[';\n                    #       $mod = 1;\n                    #       next;\n                    #}\n                    #if (substr($ar[$i],0,1) eq '^' && $ar[$i+1] eq ']') {\n                    #       $ar[$i+1] = $ar[$i];\n                    #       $ar[$i] = ']';\n                    #       $mod = 1;\n                    #       next;\n                    #}\n            }\n\n            @$rules = @ar;\n    }\n    my $s = \"\";\n    foreach my $c (@$rules) {\n            if (length($c)>2 && ch($c,0) eq '$') {\n                    if ($hc > 0) {\n                            my $s = \"\";\n                            for (my $j = 1; $j < length($c); ++$j) {\n                                    if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n                                    $s .= '$'.substr($c,$j,1);\n                            }\n                            $c = $s;\n                    } else {\n                            $c = \"Az`\".substr($c,1).'`';\n                    }\n            }\n            if (length($c)>2 && ch($c,0) eq '^') {\n                    if ($hc > 0) {\n                            my $s = \"\";\n                            for (my $j = length($c)-1; $j > 0; --$j) {\n                                    if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n                                    $s .= '^'.substr($c,$j,1);\n                            }\n                            $c = $s;\n                    } else {\n                            $c = \"A0`\".substr($c,1).'`';\n                    }\n            }\n            if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n            $s .= $c;\n    }\n    return $s;\n\n}\nsub tokenize { my ($rule, $hc)=@;\n        my @ar = split //, $rule;\n        my @rules = ();\n        for (my $i = 0; $i < scalar @ar; ++$i) {\n                my $c = $ar[$i];\n                next if ($c eq ' ');\n                my $esc = 0;\n                # 1 byte rules.\n                if (index('E:lucCtrd{}f12[]PISVMQUkK46q', $c) != -1) { # 1 char rules\n                        push @rules, $c;\n                        next;\n                }\n                if ($hc == 0) {\n                        if ($c eq '-') {  # jtr rejections\n                                my $s = $c.$ar[++$i];\n                                if ($ar[$i] eq '<' || $ar[$i] eq '>') {\n                                        $s .= $ar[++$i];\n                                }\n                                push @rules, $s;\n                                next;\n                        }\n                        if (index('pRL', $c) != -1) { # 1 char rules\n                                # if next char is digit, then use HC pRL rules.\n                                if (ord($ar[$i+1]) < ord('0') || ord($ar[$i+1]) > ord('9')) {\n                                        push @rules, $c;\n                                        next;\n                                }\n                        }\n                }\n                if (index('T$^<>\\'DpRL+-zZ.,yY', $c) != -1) { # 2 char rules (pRL here is pN 2 char rule)\n                        my $s = $c.$ar[++$i];\n                        push @rules, $s;\n                        next;\n                }\n                if (index('xioO*', $c) != -1) { # 3 char rules\n                        my $s = $c.$ar[++$i]; $s .= $ar[++$i];\n                        push @rules, $s;\n                        next;\n                }\n                if (index('Xv', $c) != -1) { # 4 char rules\n                        my $s = $c.$ar[++$i]; $s .= $ar[++$i]; $s .= $ar[++$i];\n                        push @rules, $s;\n                        next;\n                }\n                if ($c eq 'A') {\n                        my $s = $c.$ar[++$i];\n                        $c = $ar[++$i];\n                        $s .= $c;\n                        while ($ar[$i+1] ne $c) {\n                                $s .= $ar[++$i];\n                        }\n                        $s .= $ar[++$i];\n                        push @rules, $s;\n                        next;\n                }\n                # handle rules that can use classes in JtR mode\n                if (index('@!/()e', $c) != -1) { # 2-3 char rules\n                        my $s = $c.$ar[++$i];\n                        if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n                        push @rules, $s;\n                        next;\n                }\n                if (index('s', $c) != -1) { # 3-4 char rule with ? 2nd char\n                        my $s = $c.$ar[++$i];\n                        if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n                        $s .= $ar[++$i];\n                        push @rules, $s;\n                        next;\n                }\n                if (index('=%', $c) != -1) { # 3-4 char rule with ? 3rd char\n                        my $s = $c.$ar[++$i]; $s .= $ar[++$i];\n                        if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n                        push @rules, $s;\n                        next;\n                }\n                print \"Error, unknown rule token at $c next char $ar[$i+1]  Orig: $rule\\nRules found so far : \";\n                foreach my $s (@rules) {\n                        print \" $s \";\n                }\n                print (\"\\n\");\n                exit 1;\n        }\n        return \\@rules;\n}\n```\nhere is the jtrconf.pm module (to read handle jtr config files)\n``` Perl\nhandles jtr .conf files (including the .include of files and sections)\npackage jtrconf;\nuse strict;\nuse warnings;\nuse Exporter;\nuse File::Basename;\nmy $basepath = dirname(FILE).'/';\nmy $confname = 'john.conf';\nmy %sections = ();\nour @ISA= qw( Exporter );\nthese CAN be exported.\nour @EXPORT_OK = qw( setbasepath setname load getsection getparam );\nthese are exported by default.\nour @EXPORT = qw( setbasepath setname getsection );\n'default' is ../run/  Call this function to change that.\nsub setbasepath {\n    $basepath = $_[0];\n    if (!defined $basepath || length($basepath) == 0) {\n        $basepath = './';\n    }\n    if (substr($basepath, length($basepath)-1) ne '/') {\n        $basepath .= '/';\n    }\n}\nset non-standard john.conf name\nsub setname { $confname = $_[0]; }\nthis inserts include data into the array 1 element past where we are (i.e. after the include line).\nsub handle_include { my ($line, $i) = @;\n    # there are 4 include flavors.\n    my $inc_name = substr($line, 10, length($line)-11);\n    if (substr($line, 0, 10) eq '.include [') {\n        # section\n        $inc_name = lc $inc_name;\n        splice @{$[2]}, $i+1, 0, @{$sections{$inc_name}};\n        return;\n    }\n    my $missing_ok = 0;\n    my $dirname = \"\";\n    if (substr($line, 0, 10) eq '.include <') {\n        # basepath - forced.\n        $dirname = $basepath;\n    } elsif (substr($line, 0, 10) eq '.include \"') {\n        # local dir - forced\n        $dirname = './';\n    } elsif (substr($line, 0, 10) eq '.include \\'') {\n        # local dir - missing OK.\n        $dirname = './';\n        $missing_ok = 1;\n    } else {\n        die print STDERR \"invalid . conf command $line\\n\";\n    }\n    if (-f $dirname.$inc_name) {\n        open (FILE, $dirname.$inc_name);\n        my @lines = ();\n        close (FILE);\n        splice @{$_[2]}, $i+1, 0, @lines;\n    } else {\n        if ($missing_ok != 0) { return; }\n        die print STDERR \"can not include file $dirname.$inc_name\\n\";\n    }\n}\nthis loads the .conf file.\nsub load {\n    open (FILE, $basepath.$confname) or die \"cant open $basepath$confname\\n\";\n    my @lines = ();\n    close (FILE);\n    my $hc = 0;\n    my @cur_section = ();\n    my $cur_section_name=\"\";\n    for (my $i = 0; $i < scalar @lines; ++$i) {\n        my $line = $lines[$i];\n        chomp $line;\n        if (length($line) == 0 || substr($line, 0, 1) eq '#') {next;}\n        if (substr($line, 0, 9) eq '.include ') {\n            handle_include($line, $i, \\@lines);\n            next;\n        }\n        if ($hc == 0 && substr($line, 0, 1) eq '[') {\n            if (length($cur_section_name) > 0) {\n                #if (@cur_section < 2) {\n                #   $sections{$cur_section_name} = $cur_section[0];\n                #} else {\n                    $sections{$cur_section_name} = [@cur_section];\n                #}\n            }\n            $cur_section_name = lc substr($line, 1, length($line)-2);\n            @cur_section = ();\n            next;\n        }\n        if (substr($line, 0, 3) eq \"!! \") {\n            if ($line eq \"!! hashcat logic ON\") { $hc = 1; }\n            if ($line eq \"!! hashcat logic OFF\") { $hc = 0; }\n        }\n        push @cur_section, \"$line\\n\";\n    }\n    $sections{$cur_section_name} = [@cur_section];\n}\nreturns a section's data.\nsub getsection { my ($section) = @_;\n    $section = lc $section;\n    my @a = ();\n    #if (@sections{$section} == 1) {\n    #   print \"$sections{$section}\\n\";\n    #   print \"@sections{$section}\\n\";\n    #   print \"@{$sections{$section}}\\n\";\n    #   push @a, $sections{$section};\n    #} else {\nno strict 'refs';\n    @a = @{$sections{$section}};\n\nuse strict;\n#}\nreturn @a;\n\n}\nreturns the data for a param (i.e. from Options).\nsub getparam { my ($section, $param) = @_;\n    $section = lc $section;\n    my @a = @{$sections{$section}};\n    foreach my $s (@a) {\n        my $pos = index($s, '=');\n        if ($pos > -1) {\n            my $p = substr($s, 0, $pos);\n            $p =~ s/\\s+$//g;\n            if (lc $param eq lc $p) {\n                $s = substr($s, $pos+1);\n                $s =~ s/^\\s+//g;\n                return $s;\n            }\n        }\n    }\n    return \"\";\n}\n1;\n```\nHere is jtr_rulez.pm  perl module\n``` Perl\npackage jtr_rulez;\nuse strict;\nuse warnings;\nuse Exporter;\nmy $debug = 0;\nmy $stdout_rules = 0;\nmy $failed = 0;\nmy $rejected = 0;\nmy $rules_max_length;\nmy $l_num; my $p_num;\nmy %nums;   # these hold variables a ... k (used in the v command, or in get_length)\nour @ISA= qw( Exporter );\nthese CAN be exported.\nour @EXPORT_OK = qw( debug stdout_rules failed jtr_run_rule jtr_dbg_level jtr_rule_pp_init jtr_rule_pp_next jtr_rule_rejected );\nthese are exported by default.\nour @EXPORT = qw( jtr_run_rule  jtr_dbg_level jtr_std_out_rules_set jtr_rule_pp_init jtr_rule_pp_next jtr_rule_rejected );\nmy $M=\"\";\nmy %cclass=(); load_classes();\nmy @pp_rules=();\nmy $pp_idx=-0;\nsub dbg {\n    my $d = shift;\n    if ($debug >= $d) {\n        foreach my $s (@) {\n            print $s;\n        }\n    }\n}\nsub jtr_dbg_level {\n    $debug = $[0];\n}\nsub jtr_rule_rejected {\n    my $r = $rejected;\n    $rejected = 0;\n    return $r;\n}\nsub jtr_std_out_rules_set {\n    $stdout_rules = $[0];\n}\nsub case_all_words { # turn john or \"JOHn THE ruppor$$abc\" into \"John The Ruppor$$Abc\"\n    my $w = lc $[0];\n    $w =~ s/\\b(\\w)/\\U$1/g;\n    return $w;\n}\nsub case { # turn john or JOHn into John or JOHn THE ruppor$$abc\" into \"John the ruppor$$abc\"\n    my $w = lc $_[0];\n    my $c = substr($w, 0, 1);\n    if (ord($c) >= ord('a') && ord($c) <= ord('z')) {\n        substr($w, 0, 1) = uc $c;\n    }\n    return $w;\n}\nsub toggle_case {  # turn jOhN into JoHn\n    my $w = $[0];\n    # found online, unicode toggle code. Need to test for speed.\n    $w =~ s/ (\\p{CWU}) | (\\p{CWL}) /defined $1 ? uc $1 : lc $2/gex;\n    #\n    # only valid for 7-bit ascii. Now using the unicode correct version.\n    #$w =~ tr/A-Za-z/a-zA-Z/;\n    return $w;\n}\nsub rev { # turn john into nhoj   (inlining reverse was having side effects so we function this)\n    my ($w) = (@);\n    $w = reverse $w;\n    return $w;\n}\nsub purge {  #  purge out a set of characters. purge(\"test123john\",\"0123456789\"); gives testjohn\n    my ($w, $c) = @;\n    $w =~ s/[$c]//g;\n    return $w;\n}\nsub replace_chars {\n    my ($w, $ch, $c) = @;\n    if ($c eq '^') { $c = '\\^'; }\n    if (substr($c,length($c)-1,1) eq '\\' && (length($c)==1 || substr($c,length($c)-2,2) eq '\\\\')) { $c .= '\\'; }\n    $w =~ s/[$c]/$ch/g;\n    return $w;\n}\nsub shift_case { # S    shift case: \"Crack96\" -> \"cRACK(^\"\n    my ($w) = @;\n    $w =~ tr/A-Za-z~0-9)!@#$%^&*(\\-_=+[{]}\\\\|;:'\",<.>\\/?/a-zA-Z~)!@#$%^&(0-9-+={[}]|\\:;\"'<,>.?\\//;\n    return $w;\n}\nsub vowel_case { # V    lowercase vowels, uppercase consonants: \"Crack96\" -> \"CRaCK96\"\n    my ($w) = @;\n    $w =~ tr/b-z/B-Z/;\n    $w =~ tr/AEIOU/aeiou/;\n    return $w;\n}\nsub keyboard_right { # R    shift each character right, by keyboard: \"Crack96\" -> \"Vtsvl07\"\n    my ($w) = @;\n    # same behavior as john1.8.0.3-jumbo. I do not think all on the far right are 'quite' right, but at least it matches.\n    # it's a very obsure rule, and not likely to have too many real world passwording implications.\n    # the only 'real' use is if someone sets a password,and then it does not work. Were their fingers 1 key\n    # to left, or 1 key to right?  If so, then they can guess with these rules\n    $w =~ tr/~1qaz!QAZ2wsx@WSX3edc#EDC4rfv$RFV5tgb%TGB6yhn^YHN7ujm&UJM8ik,*IK<9ol.(OL>0p;)P:\\-[_{+=?\\//1!2wsx@WSX3edc#EDC4rfv$RFV5tgb%TGB6yhn^YHN7ujm&UJM8ik,*IK<9ol.(OL>0p;\\/)P:?\\-['_{\"=]+}|\\\\|\\\\/;\n    return $w;\n}\nsub keyboard_left { # L shift each character left, by keyboard: \"Crack96\" -> \"Xeaxj85\"\n    my ($w) = @_;\n    # idential output as john1.8.0.3-jumbo\n    $w =~ tr/2wsx3edc4rfv5tgb6yhn7ujm8ik,9ol.0p;\\/@WSX#EDC$RFV%TGB^YHN&UJM*IK<(OL>)P:?1!\\-[_{=]+}'\"\\\\|/1qaz2wsx3edc4rfv5tgb6yhn7ujm8ik,9ol.!QAZ@WSX#EDC$RFV%TGB^YHN&UJM*IK<(OL>~0p)P-[_{;:=+/;\n    return $w;\n}\npluralize: \"crack\" -> \"cracks\", etc. (lowercase only)\nplural code is direct port from jtr rules.c\nsub pluralizes { my ($word) = (@_);\n    my $len = length($word);\n    if ($len<2) { return $word; }\n    my $last=substr($word, length($word)-1,1);\n    my $last2=substr($word, length($word)-2,1);\n    if (find_any_chars(\"sxz\", $last) > 0 ||\n        ($len > 1 && $last eq 'h' &&\n        ($last2 eq 'c' || $last2 eq 's'))) {\n        return $word . \"es\";\n    } elsif ($last eq 'f' && $last2 ne 'f') {\n        return $word . \"ves\";\n    } elsif ($len > 1 &&\n        $last eq 'e' && $last2 eq 'f') {\n        return $word . \"ves\";\n    } elsif ($len  > 1 && $last eq 'y') {\n        if (find_any_chars(\"aeiou\", $last2) > 0) {\n            return $word . \"s\";\n        }\n        return $word . \"ies\";\n    }\n    return $word . \"s\";\n}\n\"crack\" -> \"cracked\", etc. (lowercase only)\nsub pluralized { my ($word) = (@_);\n    my $len = length($word);\n    if ($len<2) { return $word; }\n    my $last=substr($word, length($word)-1,1);\n    my $last2=substr($word, length($word)-2,1);\n    if ($last eq 'd' && $last2 eq 'e')  { return $word; }\n    if ($last eq 'y') {\n        substr($word, length($word)-1,1) = 'i';\n    } elsif (find_any_chars(\"bgp\", $last) && !find_any_chars(\"bgp\", $last2)) {\n        $word .= $last;\n    }\n    if ($last eq 'e') {\n        $word .= 'd';\n    } else {\n        $word .= 'ed';\n    }\n    return $word;\n}\n\"crack\" -> \"cracking\", etc. (lowercase only)\nsub pluralizing { my ($word) = (@_);\n    my $len = length($word);\n    if ($len<3) { return $word; }\n    my $last=substr($word, length($word)-1,1);\n    my $last2=substr($word, length($word)-2,1);\n    my $last3=substr($word, length($word)-3,1);\n    if ($last eq 'g' && $last2 eq 'n' && $last3 eq 'i')  { return $word; }\n    if (find_any_chars(\"eaiou\", $last)) {\n        return substr($word,0,length($word)-1) . \"ing\";\n    }\n    if (find_any_chars(\"bgp\", $last) && !find_any_chars(\"bgp\", $last2)) {\n        $word .= $last;\n    }\n    return $word . \"ing\";\n}\nsub find_any_chars {\n    # this function probably could be optimized, but as written, it works\n    # well for all = / ? ( ) % type rejection rules.\n    my ($w, $c) = @_;\n    if (!defined ($c) || length($c) == 0) { return \"\"; }\n    if (substr($c,length($c)-1,1) eq '\\' && (length($c)==1 || substr($c,length($c)-2,2) eq '\\\\')) { $c .= '\\'; }\ndbg(3,\"find_any_chars: w=$w  c=$c  s/[^$c]*//g;\\n\");\n$w =~ s/[^$c]*//g;\nreturn length($w);\n\n}\nsub find_first_char {\n    # NOTE, this is used for / and % rejections, AND find_any_chars has already\n    # returned VALID information.  Now we simply want to know position offsets.\n    my ($off, $w, $c) = @;\n    my $v = 0;\n    if ($off >= length($w)) { return length($w); }\n    $w = substr($w, $off, length($w)-$off);\n    my @wa = split('', $w);\n    my @ca = split('', $c);\n    foreach my $wc (@wa) {\n        foreach my $cc (@ca) {\n            if ($wc eq $cc) { return $off+$v; }\n        }\n        ++$v;\n    }\n    return length($w);\n}\nsub jtr_run_rule { my ($rule, $word, $hc_logic) = @;\n    dbg(1, \"jtr_run_rule called with debug level $debug\\n\");\n    $M = $word;  # memory\n    if (!defined $hc_logic) { $hc_logic=0; }\n    $l_num = length($M);\n    %nums = ( 'a'=>0,'b'=>0,'c'=>0,'d'=>0,'e'=>0,'f'=>0,'g'=>0,'h'=>0,'i'=>0,'k'=>0 );\n    $failed = 0;\n    $rejected = 0;\n    dbg(2, \"checking word $word with rule $rule\\n\");\n    my @rc = split('', $rule);\n    dbg(2, \"after split\\n\");\n    for (my $i = 0; $i < scalar(@rc); ++$i) {\n        if (length($word) == 0) { return \"\"; } # in jtr, this is a 'reject'\n        my $c = $rc[$i];\n        next if ($c eq ' ' || $c eq ':');\n        if ($c eq 'l') { $word = lc $word; next; }\n        if ($c eq 'u') { $word = uc $word; next; }\n        if ($c eq 'c') { $word = case($word); next; }\n        if ($c eq 'C') { $word = toggle_case(case($word)); next; }\n        if ($c eq 't') { $word = toggle_case($word); next; }\n        if ($c eq 'd') { $word = $word.$word; next; }\n        if ($c eq 'r') { $word = rev($word); next; }\n        if ($c eq 'f') { $word = $word.rev($word); next; }\n        if ($c eq '$') { ++$i; $word .= $rc[$i];  next; } #if ($rc[$i] eq '\\' && defined $rc[$i+1]) {++$i;}\n        if ($c eq '^') { ++$i; $word = $rc[$i].$word; next; }\n        if ($c eq '{') { $word = rotl($word); next; }\n        if ($c eq '}') { $word = rotr($word); next; }\n        if ($c eq '[') { if (length($word)) {$word = substr($word, 1);} next; }\n        if ($c eq ']') { if (length($word)) {$word = substr($word, 0, length($word)-1);} next; }\n        if ($c eq 'D') { my $n=get_num_val_raw($rc[++$i],$word); if ($n') { my $n=get_num_val_raw($rc[++$i],$word); if(length($word)<=$n){$rejected=1; return \"\"; }    next; }\n        if ($c eq '<') { my $n=get_num_val_raw($rc[++$i],$word); if(length($word)>=$n){$rejected=1; return \"\"; }    next; }\n        if ($c eq '_') { my $n=get_num_val_raw($rc[++$i],$word); if(length($word)!=$n){$rejected=1; return \"\"; }    next; }\n        if ($c eq '\\''){ my $n=get_num_val_raw($rc[++$i],$word); if(length($word)> $n){ $word=substr($word,0,$n); } next; }\n        if ($c eq 'p') {\n            my $do_hc = 1;\n            my $n = 0;\n            if (length($rule) > $i+1) {$n=get_num_val_raw($rc[$i+1],$word,1);}\n            if ($hc_logic == 0 && ($n < 1 || $n > 9)) {\n                $word=pluralizes($word);\n                $do_hc = 0;\n            }\n            if ($hc_logic > 0 || $do_hc > 0) {\n                ++$i;\n                if ($n < 1) {$rejected=1; return \"\"; }\n                my $s = $word;\n                while ($n--) {\n                    $s .= $word;\n                }\n                $word = $s;\n            }\n            next;\n        }\n        if ($c eq 'P') { $word=pluralized($word); next; }\n        if ($c eq 'I') { $word=pluralizing($word); next; }\n        #\n        #   -c -8 -s -p -u -U ->N ->1);\n                }\n                next;\n            }\n            if ($c eq 'L') {\n                my $n=get_num_val_raw($rc[++$i],$word);\n                if ($n < length($word)) {\n                    substr($word,$n,1) = chr((ord(substr($word,$n,1))<<1)&0xFF);\n                }\n                next;\n            }\n            if ($c eq '-') {\n                my $n=get_num_val_raw($rc[++$i],$word);\n                if ($n < length($word)) {\n                    substr($word,$n,1) = chr(ord(substr($word,$n,1))-1);\n                }\n                next;\n            }\n        } else {\n            if ($c eq 'R') { $word = keyboard_right($word); next; }\n            if ($c eq 'L') { $word = keyboard_left($word); next; }\n        if ($c eq '-') {\n            ++$i;\n            $c = $rc[$i];\n            if ($c eq ':') {\n                next;   # this one actually is done and correct, lol.\n            }\n            # these are place holders now, until I can figure them out.\n            if ($c eq 'c') { next; }\n            if ($c eq '8') { next; }\n            if ($c eq 's') { next; }\n            if ($c eq 'p') { next; }\n            if ($c eq 'u') { next; }\n            if ($c eq 'U') { next; }\n            if ($c eq '>') { ++$i; next; }\n            if ($c eq '<') { ++$i; next; }\n            dbg(1, \"unknown length rejection rule: -$c character $c not valid.\\n\");\n            next;\n        }\n    }\n    if ($c eq 'o') { # oNX\n        my $n=get_num_val_raw($rc[++$i],$word);\n        ++$i;\n        dbg(2, \"o$n$rc[$i]\\n\");\n        if ($n < length($word)) { substr($word, $n, 1) = $rc[$i]; }\n        next;\n    }\n    if ($c eq 'i') { # iNX\n        my $n=get_num_val_raw($rc[++$i],$word);\n        ++$i;\n        if ($n > length($word)) { $word .= $rc[$i]; }\n        else { substr($word, $n, 0) = $rc[$i]; }\n        next;\n    }\n    if ($c eq 'x') { # xNM\n        my $n=get_num_val_raw($rc[++$i],$word);\n        my $m=get_num_val_raw($rc[++$i],$word);\n        if ($n>length($word)) { $rejected = 1; return \"\"; }\n        if ($n+$m>length($word)) { $m = length($word)-$n; }\n        $word = substr($word, $n, $m);\n        next;\n    }\n    if ($c eq 'O') { # ONM\n        my $n=get_num_val_raw($rc[++$i],$word);\n        my $m=get_num_val_raw($rc[++$i],$word);\n        if ($n>length($word)) { $rejected = 1; return \"\"; }\n        if ($n+$m>length($word)) { $m = length($word)-$n; }\n        substr($word, $n, $m) = \"\";\n        next;\n    }\n    if ($c eq 's') { #   sXY & s?CY\n        my $chars = \"\";\n        if ($rc[++$i] eq \"?\" && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        ++$i;\n        my $ch = $rc[$i];\n        $word=replace_chars($word, $ch, $chars);\n        next;\n    }\n    if ($c eq 'D') { # DN\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos >= 0 && $pos < length($word)+1) {\n            $word = substr($word, 0,$pos).substr($word, $pos+1,length($word));\n        }\n        next;\n    }\n    if ($c eq 'x') { # xNM\n        my $pos = get_num_val_raw($rc[++$i], $word);\n        my $len = get_num_val_raw($rc[++$i], $word);\n        if ($pos >= 0 && $pos <= length($word)) {\n            $word = substr($word, $pos, $len);\n        } else { return \"\"; } # this is how jtr does it but it is undefined.\n        next;\n    }\n    if ($c eq 'i') { # iNX\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos >= 0 && $pos <= length($word)) {\n            ++$i;\n            substr($word, $pos,0) = $rc[$i];\n        }\n        next;\n    }\n    if ($c eq 'M') { # M\n        $M = $word;\n        next;\n    }\n    if ($c eq 'Q') { # Q\n        if ($M eq $word) {\n            $rejected = 1;\n            return \"\";\n        }\n        next;\n    }\n    if ($c eq '!') { # !X  !?C  (rejection)\n        my $chars;\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        if (find_any_chars($word, $chars)) {\n            $rejected = 1;\n            return \"\";\n        }\n        next;\n    }\n    if ($c eq '/') { # /X  /?C  (rejection) reject UNLESS it contains.\n        my $chars;\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        if (!find_any_chars($word, $chars)) {\n            $rejected = 1;\n            $p_num = length;\n            return \"\";\n        }\n        $p_num = find_first_char(0, $word, $chars);\n        next;\n    }\n    if ($c eq '=') { # =NX  =N?C  (rejection)\n        my $chars;\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos >= 0 && $pos <= length($word)) {\n            my $w = substr($word, $pos, 1);\n            if ($rc[++$i] eq '?') { $chars = get_class($rc[++$i]); }\n            else { $chars = $rc[$i]; }\n            if (!find_any_chars($w, $chars)) {\n                $rejected = 1;\n                return \"\";\n            }\n        }\n        next;\n    }\n    if ($c eq '(') { # (X  (?C  (rejection)\n        my $chars;\n        if (length($word)==0) { $rejected = 1; return \"\"; }\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        if (!find_any_chars(substr($word,0,1), $chars)) {\n            $rejected = 1;\n            return \"\";\n        }\n        next;\n    }\n    if ($c eq ')') { # )X  )?C  (rejection)\n        my $chars;\n        if (length($word)==0) { $rejected = 1; return \"\"; }\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        if (!find_any_chars(substr($word,length($word)-1,1), $chars)) {\n            $rejected = 1;\n            return \"\";\n        }\n        next;\n    }\n    if ($c eq '%') { # %NX  %N?C  (rejection)\n        my $chars;\n        my $n = get_num_val($rc[++$i], $word);\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        if (find_any_chars($word, $chars) < $n) {\n            $rejected = 1;\n            $p_num = length;\n            return \"\";\n        }\n        my $fnd = 0;\n        $p_num = 0;\n        while ($fnd < $n) {\n            $p_num = find_first_char($p_num, $word, $chars);\n            ++$fnd;\n        }\n        next;\n    }\n    if ($c eq 'X') { # XNMI\n        my $posM = get_num_val($rc[++$i], $M);  # note using $M not $word.\n        my $len = get_num_val($rc[++$i], $M);\n        my $posI = get_num_val($rc[++$i], $word);\n        if ($posM >= 0 && $len > 0 && $posI >= 0) {\n            substr($word, $posI, 0) = substr($M, $posM, $len);\n        }\n        next;\n    }\n    if ($c eq 'o') { # oNX\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos >= 0 && $pos < length($word)) {\n            ++$i;\n            substr($word, $pos,1) = $rc[$i];\n        }\n        next;\n    }\n    if ($c eq 'T') { # TN  (toggle case of letter at N)\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos >= 0) {\n            my $c = substr($word, $pos, 1);\n            if (ord($c) >= ord('a') && ord($c) <= ord('z')) { substr($word, $pos, 1) = uc $c; }\n            elsif (ord($c) >= ord('A') && ord($c) <= ord('Z')) { substr($word, $pos, 1) = lc $c; }\n        }\n        next;\n    }\n    if ($c eq '@') {  # @X & @?C\n        my $chars = \"\";\n        if ($rc[++$i] eq \"?\" && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        $word=purge($word, $chars);\n        next;\n    }\n    if ($c eq 'A') { # AN\"STR\"  with de-ESC in STR\n        my $pos = get_num_val($rc[++$i], $word);\n        if ($pos < 0) {next;}\n        my $delim = $rc[++$i];\n        my $s = \"\";\n        while ($rc[$i+1] ne $delim) {\n            if ($rc[$i] eq '\\\\' && $rc[$i+1] eq \"x\") {\n                # \\xhh escape, replace with 'real' character\n                $i += 2;\n                my $s = $rc[++$i]; $s .= $rc[$i];\n                ($rc[$i]) = sscanf($s, \"%X\");\n                $rc[$i] = chr($rc[$i]);\n            }\n            $s .= $rc[++$i];\n        }\n        ++$i;\n        substr($word, $pos, 0) = $s;\n        next;\n    }\n    if ($c eq 'v') { # vVNM numeric handling\n        # first update $l_num\n        $l_num = length($word);\n        my $V = $rc[++$i];\n        my $N = get_num_val_raw($rc[++$i], $word);\n        my $M = get_num_val_raw($rc[++$i], $word);\n        $nums{$V} = $N-$M;\n        next;\n    }\n    # hashcat rules.\n    if ($c eq 'z') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if (length($word) > 0) {\n            while ($n-- > 0) {\n                $word = substr($word, 0, 1) . $word;\n            }\n        }\n        next;\n    }\n    if ($c eq 'Z') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if (length($word) > 0) {\n            while ($n-- > 0) {\n                $word .= substr($word, length($word)-1, 1);\n            }\n        }\n        next;\n    }\n    if ($c eq '6') {\n        $word = $M.$word;\n        next;\n    }\n    if ($c eq '4') {\n        $word .= $M;\n        next;\n    }\n    if ($c eq 'q') {\n        my $p;\n        my $s = \"\";\n        for ($p = 0; $p < length($word); $p++) {\n            $s .= substr($word, $p, 1).substr($word, $p, 1);\n        }\n        $word = $s;\n        next;\n    }\n    if ($c eq '.') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word)-1) {\n            substr($word,$n,1) = substr($word,$n+1,1);\n        }\n        next;\n    }\n    if ($c eq ',') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word) && $n > 0) {\n            substr($word,$n,1) = substr($word,$n-1,1);\n        }\n        next;\n    }\n    if ($c eq 'k') {\n        if (length($word)>1) {\n            substr($word,0,2) = substr($word,1,1).substr($word,0,1);\n        }\n        next;\n    }\n    if ($c eq 'K') {\n        if (length($word)>1) {\n            substr($word,length($word)-2) = substr($word,length($word)-1,1).substr($word,length($word)-2,1);\n        }\n        next;\n    }\n    if ($c eq '*') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        my $m=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word) && $m < length($word)) {\n            my $c = substr($word,$n, 1);\n            substr($word,$n, 1) = substr($word,$m, 1);\n            substr($word,$m, 1) = $c;\n        }\n        next;\n    }\n    if ($c eq '+') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word)) {\n            substr($word,$n,1) = chr((ord(substr($word,$n,1))+1)&0xFF);\n        }\n        next;\n    }\n    if ($c eq 'y') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word)) {\n            $word = substr($word,0,$n).$word;\n        }\n        next;\n    }\n    if ($c eq 'Y') {\n        my $n=get_num_val_raw($rc[++$i],$word);\n        if ($n < length($word)) {\n            $word .= substr($word,length($word)-$n);\n        }\n        next;\n    }\n    if ($c eq 'E') {\n        $word = lc $word;\n        substr($word, 0, 1) = uc substr($word, 0, 1);\n        my $pos = index($word, ' ');\n        while ($pos >= 0) {\n            ++$pos;\n            substr($word, $pos, 1) = uc substr($word, $pos, 1);\n            $pos = index($word, ' ', $pos);\n        }\n        next;\n    }\n    if ($c eq 'e') {\n        my $chars;\n        if ($rc[++$i] eq '?' && $hc_logic==0) { $chars = get_class($rc[++$i]); }\n        else { $chars = $rc[$i]; }\n        $word = lc $word;\n        substr($word, 0, 1) = uc substr($word, 0, 1);\n        for (my $i = 0; $i < length($chars); ++$i) {\n            my $c = substr($chars, $i, 1);\n            my $pos = index($word, $c);\n            while ($pos >= 0) {\n                ++$pos;\n                substr($word, $pos, 1) = uc substr($word, $pos, 1);\n                $pos = index($word, $c, $pos);\n            }\n        }\n        next;\n    }\n\n    print \"\\nDo not know how to handle character $c in $rule\\n\";\n    exit(-1);\n}\nif (length($word) > 125) { return substr($word, 0, 125); }\ndbg(2, \"resultant word after rule $rule is: $word\\n\");\nreturn $word;\n\n}\nsub rotl {\n    my $w = $[0];\n    $w = substr($w, 1, length($w)).substr($w, 0, 1);\n    return $w;\n}\nsub rotr {\n    my $w = $[0];\n    $w = substr($w, length($w)-1, 1).substr($w, 0, length($w)-1);\n    return $w;\n}\nsub get_class {\n    my ($c) = @;\n    if ($c eq '?') { dbg(2,\"Doing get class of ?\\n\"); return $cclass{'?'}; }\n    return $cclass{$c};\n}\nsub get_num_val_raw { my ($p, $w, $dont_warn) = (@);\n0...9  for 0...9\nA...Z  for 10...35\n*  for max_length\n-  for (max_length - 1)\n+  for (max_length + 1)\na...k  user-defined numeric variables (with the \"v\" command)\nl  initial or updated word's length (updated whenever \"v\" is used)\nm  initial or memorized word's last character position\np  position of the character last found with the \"/\" or \"%\" commands\nz  \"infinite\" position or length (beyond end of word)\nif (ord($p) >= ord(\"0\") && ord($p) <= ord('9')) {return ord($p)-ord('0');}\nif (ord($p) >= ord(\"A\") && ord($p) <= ord('Z')) {return  ord($p)-ord('A')+10;}\nif ($p eq '*') { return $rules_max_length; }\nif ($p eq '-') { return $rules_max_length-1; }\nif ($p eq '+') { return $rules_max_length+1; }\nif (index('abcdefghijk',$p)>-1) { return $nums{$p}; }\nif ($p eq 'z') {return length($w);}\nif ($p eq 'l') { return $l_num; }\nif ($p eq 'p') { return $p_num; }\nif ($p eq 'm') { my $m = length($M); if ($m>0){$m-=1;} return $m; }\nif (!defined $dont_warn || $dont_warn < 1) {\n    print \"ERROR, $p is NOT a valid length item\\n\";\n}\nreturn -1;\n\n}\nsub get_num_val { my ($p, $w) = (@);\n    $p = get_num_val_raw($p, $w);\n    if ($p > length($w)) { return -1; }\n    return $p;\n}\nsub esc_remove { my ($w) = (@);\n    my $s = \"\";\n    my $i = 0;\n    my @ch = split('', $w);\n    while ($i < scalar @ch) {\n        if ($ch[$i] eq '\\' && $i+1 < scalar @ch) {++$i;}\n        $s .= $ch[$i];\n        ++$i;\n    }\n    return $s;\n}\nsub get_items {\n    my ($s, $pos, $pos2, $esc_r) = (@);\n    $[2] = index($s, ']', $pos);\n    if ($[2] < 0) { return \"\"; }\n    while ($pos < $[2] && substr($s, $[2]-1, 1) eq \"\\\") {\n        $[2] = index($s, ']', $[2]+1);\n    }\n    if ($pos+2 > $[2])  { return \"\"; }\n    if ($pos+2 == $[2])  {\n        # handle a 1 byte group [x] should return \"x\";\n        $s = substr($s, $pos+1, 1);\n        return $s;\n    }\n    $s = substr($s, $pos+1, $[2]-$pos-1);\n    # remove escapes here \\v and \\xHH\n    my $idx = index($s, '\\x');\n    while ($idx > -1) {\n        my $n = substr($s, $idx+2, 2);\n        my $v = hex($n);\n        substr($s, $idx, 4) = chr($v);\n        $idx = index($s, '\\x', $idx+1);\n    }\n    $idx = index($s, '\\');\n    while ($idx > -1) {\n        # remove all \\C except for  -  We have to keep that one.\n        if (substr($s, $idx, 2) ne '\\-') {\n            substr($s, $idx, 2) = substr($s, $idx+1, 1);\n        } else { ++$idx; }\n        if (substr($s, $idx, 1) eq '\\') { ++$idx; }\n        $idx = index($s, '\\', $idx);\n    }\n# now $s is raw characters in the range, no escapes.\nmy @ch = split('', $s);\n\n# convert ranges into 'raw' values.  de-escape values (i.e. \\\\ or \\[ become \\ or [ )\n# note, we do not check for some invalid ranges, like [-b] or [ab-] or [z-a]\nmy $i = 0;\nmy $chars = \"\";\nfor ($i = 0; $i < length($s); ++$i) {\n    if ($i>0 && $ch[$i] eq '-') {\n        dbg(4, \"doing range fix for $ch[$i-1]-$ch[$i+1]\\n\");\n        if (ord($ch[$i-1]) > ord($ch[$i+1])) {\n            # jumbo john handles [6-0][9-0] also (i.e. count down).\n            # note, I do not think core handles this!!!\n            for (my $c = ord($ch[$i-1])-1; $c >= ord($ch[$i+1]); --$c) {\n                $chars .= chr($c);\n            }\n        } else {\n            # normal order\n            for (my $c = ord($ch[$i-1])+1; $c <= ord($ch[$i+1]); ++$c) {\n                $chars .= chr($c);\n            }\n        }\n        ++$i;\n    } else {\n        if ($ch[$i] eq '\\\\' && $ch[$i+1] eq '-') { ++$i; }\n        $chars .= $ch[$i];\n    }\n}\nif (defined($esc_r) && $esc_r) {\n    # if magic \\r was seen, we do NOT unique the group.\n    dbg(2, \"get_item returning (no-dedupe): chars=$chars\\n\");\n    return $chars;\n}\n# we must 'unique' this data.\n$chars = reverse $chars;\n$chars =~ s/(.)(?=.*?\\1)//g;\n$chars = reverse $chars;\ndbg(2, \"get_item returning: chars=$chars\\n\");\nreturn $chars;\n\n}\nsub hexify_space_in_groups { my ($w) = (@_);\n    if (index($w, ' ') == -1) { return $w; }\n    my $pos = index($w, '[');\n    while ($pos > -1) {\n        if ($pos > 0 && substr($w, $pos-1, 1) eq '\\') {\n            $pos = index($w, '[', $pos+1);\n            next;\n        }\n        my $pos2 = index($w, ']', $pos);\n        while ($pos2 > 0 && substr($w, $pos2-1, 1) eq '\\') {\n            $pos2 = index($w, ']', $pos2+1);\n            next;\n        }\n        if ($pos2 > 0) {\n            my $s = substr($w, $pos, $pos2-$pos);\n            $s =~ s/ /\\x20/g;\n            substr($w, $pos, $pos2-$pos) = $s;\n            $pos += length($s);\n            $pos = index($w, '[', $pos);\n        } else { $pos = -1; }\n    }\n    return $w;\n}\npreprocessor.  We have an array of rules that get built. Then\nwe keep count of which have been handled, so we eat them one\nat a time, in order.\nsub jtr_rule_pp_init { my ($pre_pp_rule, $len, $max_cnt, $hc_logic) = (@);\n    $pp_idx = 0;\n    if (defined $hc_logic && $hc_logic != 0) {\n        @pp_rules = ();\n        $[2] = 1;\n        if ($debug>2||$stdout_rules) {\n            foreach my $s (@pp_rules) {\n                print \"$s\\n\";\n            }\n            if ($debug>3||$stdout_rules==1) { exit(0); }\n        }\n        return $pre_pp_rule;\n    }\n    # removed all stray spaces. HOWEVER, we must preserve them within groups, so we\n    # first find all spaces in groups, and replace them with \\x20 and then purge spaces.\n    my $stripped = hexify_space_in_groups($pre_pp_rule);\n#$stripped = purge($stripped,' ');\n# They must ALSO need to be preserved for any character in character based commands $^ios@!/=()%e\nmy $p = index($stripped, ' ');\nwhile ($p != -1) {\n    if ($p > 0) {\n        if (index('$^s@!/()e', substr($stripped, $p-1, 1)) != -1) {\n            #substr($stripped, $p, 1) = '[\\\\x20]';\n            $p = index($stripped, ' ', $p+1);\n            next;\n        }\n    }\n    if ($p > 1) {\n        if (index('sio=%', substr($stripped, $p-2, 1)) != -1) {\n            #substr($stripped, $p, 1) = '[\\\\x20]';\n            $p = index($stripped, ' ', $p+1);\n            next;\n        }\n    }\n    substr($stripped, $p, 1) = '';\n    $p = index($stripped, ' ', $p);\n}\n#print \"stripped = $stripped\\n\";\n\n# normalize all \\r\\p[] or \\r\\px[] into \\p\\r[] and \\px\\r[]\n$stripped =~ s/\\\\r\\\\p\\[/\\\\p\\\\r\\[/g;\n$stripped =~ s/\\\\r\\\\p([0-9])\\[/\\\\p$1\\\\r\\[/g;\n# strip out \\\\ etc outside of groups []\nif (!defined($len) || $len==0) {$rules_max_length = 0;}\nelse {$rules_max_length = $len; }\n@pp_rules = ();\nif (defined $max_cnt) {\n    my $cnt = pp_rule_cnt($stripped);\n    if ($max_cnt && $cnt > $max_cnt) { $_[2] = $cnt; return \"\"; }\n}\ndbg(4, \"calling pp_rule() to prepare our rule:\\n\\n$pre_pp_rule\\n\\n\");\npp_rule($stripped, 0, 0);\ndbg(4, \"There were \".scalar @pp_rules.\" created\\n\");\n\n# do a final strip of all \\ values from the finished rule.\nmy @p=();\nforeach my $s (@pp_rules) {\n    dbg(3, \"   before esc_remove: $s\\n\");\n    $s = esc_remove($s);\n    dbg(3, \"   after  esc_remove: $s\\n\");\n    push(@p,$s);\n}\n@pp_rules = @p;\n\nif ($debug>2||$stdout_rules) {\n    foreach my $s (@pp_rules) {\n        print \"$s\\n\";\n    }\n    if ($debug>3||$stdout_rules==1) { exit(0); }\n}\n\nif (scalar @pp_rules > 0) {\n    return $pp_rules[0];\n}\nreturn \"\";\n\n}\nsub jtr_rule_pp_next { my () = (@);\n    if (scalar @pp_rules == $pp_idx) { return \"\"; }\n    return $pp_rules[++$pp_idx];\n}\nsub handle_backref { my ($gnum, $c, $s, $total, $idx) = (@);\n    my $i; my $i2; my $n;\n# find any \\$gnum and replace with $c\n$s =~ s/\\\\$gnum/$c/g;\n\n# find any \\p$gnum[] and replace with the $gnum from it's group\n$i = index($s, \"\\\\p$gnum\".\"[\");\nwhile ($i >= 0) {\n    my $chars = get_items($s, $i+3, $i2);\n    if ($i2 == -1) { print STDERR \"invalid \\\\p$gnum\".\"[..] found in rule\\n\"; die; }\n    my @a = split('', $chars);\n    my $c;\n    my $i3 = $idx;\n    $i3 %= scalar @a;\n    substr($s, $i, $i2-$i+1) = $a[$i3];\n    $i = index($s, \"\\\\p$gnum\".\"[\");\n}\n\n# find any \\p$gnum\\r[] and replace with the $gnum from it's non-dedup'd group\n$i = index($s, \"\\\\p$gnum\\\\r[\");\nwhile ($i >= 0) {\n    my $chars = get_items($s, $i+5, $i2, 1);\n    if ($i2 == -1) { print STDERR \"invalid \\\\p$gnum\\\\r[..] found in rule\\n\"; die; }\n    my @a = split('', $chars);\n    my $c;\n    my $i3 = $idx;\n    $i3 %= scalar @a;\n    substr($s, $i, $i2-$i+1) = $a[$i3];\n    $i = index($s, \"\\\\p$gnum\\\\r[\");\n}\n\n# now that all the stray ['s are gone, we can look for \\p[] \\p\\r[] and \\0\n# NOTE, there must not be ANY groups ahead of this, else we leave it for later.\n$i = index($s, \"\\\\p[\");\nwhile ($i >= 0) {\n    #print\"here $s : \".substr($s,$i).\"\\n\";\n    $i2 = index($s, '[');\n    if ($i > 0 && $i2 >= 0 && $i2 < $i) {\n        while ($i2 < $i) {\n            if ($i2 == 0) { $i = -1; }\n            elsif (substr($s, $i2-1, 1) eq '\\\\') {\n                $i2 = index($s, '[', $i2+1);\n            } else {\n                $i = -1;\n            }\n        }\n    }\n    if ($i > 0) {\n        my $chars = get_items($s, $i+2, $i2);\n        if ($i2 == -1) { print STDERR \"invalid \\\\p0[..] found in rule\\n\"; die; }\n        my @a = split('', $chars);\n        my $c;\n        my $i3 = $idx;\n        $i3 %= scalar @a;\n        substr($s, $i, $i2-$i+1) = $a[$i3];\n        $i = index($s, \"\\\\p[\");\n    }\n}\n\n# find any \\p\\r[ and step them. The step is $total\n$i = index($s, \"\\\\p\\\\r[\");\nwhile ($i >= 0) {\n    $i2 = index($s, '[');\n    if ($i > 0 && $i2 >= 0 && $i2 < $i) {\n        while ($i2 < $i) {\n            if ($i2 == 0) { $i = -1; }\n            elsif (substr($s, $i2-1, 1) eq '\\\\') {\n                $i2 = index($s, '[', $i2+1);\n            } else {\n                $i = -1;\n            }\n        }\n    }\n    if ($i >= 0) {\n        my $chars = get_items($s, $i+4, $i2, 1);\n        #print \"in \\\\p\\\\r[ and found $chars with total=$total\\n\";\n        if ($i2 == -1) { print STDERR \"invalid \\\\p\\\\r[] found in rule\\n\"; die; }\n        my @a = split('', $chars);\n        my $c;\n        $total %= scalar @a;\n        substr($s, $i, $i2-$i+1) = $a[$total];\n        $i = index($s, \"\\\\p\\\\r[\");\n    }\n}\n\n# find any \\0 before the next [  and replace with $c\n$i = index($s, \"\\\\0\");\n#print \"i for \\\\0 = $i  (s=$s)\\n\";\nwhile ($i >= 0) {\n    $i2 = index($s, '[');\n    if ($i > 0 && $i2 >= 0 && $i2 < $i) {\n        while ($i2 < $i) {\n            if ($i2 == 0) { $i = -1; }\n            elsif (substr($s, $i2-1, 1) eq '\\\\') {\n                $i2 = index($s, '[', $i2+1);\n            } else {\n                $i = -1;\n            }\n        }\n    }\n    if ($i >= 0) {\n        substr($s, $i, 2) = $c;\n        $i = index($s, \"\\\\0\");\n    }\n}\nreturn $s;\n\n}\nsub handle_rule_rej {\n    my $rule = $_[0];\n    dbg(3, \"Entering handle_rule_rej rule=$rule\\n\");\n    # remove our 3 hacks for problem letters\n    $rule =~ s/\\([ -~])``~/\\$1/g;\ndbg(3, \"Leaving  handle_rule_rej rule=$rule\\n\");\nif (substr($rule, 0, 1) ne '-') { return $rule;}\nmy $v = substr($rule,1,1);\nif ($v eq ':') { return substr($rule, 2); }\nif ($v eq 'c') { return substr($rule, 2); }\nif ($v eq '8') { return substr($rule, 2); }\nif ($v eq 's') { return substr($rule, 2); }\nif ($v eq 'p') { return substr($rule, 2); }\nif ($v eq 'u') { return substr($rule, 2); }\nif ($v eq 'U') { return substr($rule, 2); }\nif ($v eq '<') { return substr($rule, 3); }\nif ($v eq '>') { return substr($rule, 3); }\nreturn $rule;\n\n}\nsub is_pnum_r { my ($w) = (@);\n    if (substr($w, 0, 2) ne '\\p') { return 0; }\n    if (substr($w, 3) ne '\\r')    { return 0; }\n    return 1;\n}\nsub pp_rule { my ($rules, $which_group, $idx) = (@);\n    my $total = 0;\n    dbg(3, \" entered pp_rule($rules, $which_group, $idx, $total)\\n\");\n    my $pos = index($rules, '[');\n    if ($pos == -1) { $rules=handle_rule_rej($rules); dbg(3, \"* This rule being saved: $rules\\n\"); push(@pp_rules,$rules); return 0; }\n    while ($pos > 0 && substr($rules, $pos-1, 1) eq \"\\\" && ($pos == 1 || substr($rules, $pos-2, 2) ne \"\\\\\")) {\n        $pos = index($rules, '[', $pos+1);\n    }\n    if ($pos < 0)  { $rules=handle_rule_rej($rules); dbg(3, \"* This rule being saved: $rules\\n\"); push(@pp_rules,$rules); return 0;}\n    my $esc_r = 0;\n    if ($pos > 1 && substr($rules, $pos-2,2) eq \"\\r\") {\n        $esc_r = 1;\n        if ($pos > 3 && substr($rules, $pos-4,4) eq \"\\p\\r\") {\n            # we leave these alone \\p\\r  , they are needed for the handle-backref logic\n        } elsif ($pos > 4 && is_pnum_r(substr($rules, $pos-5,5))) {\n            # we leave these alone \\p1\\r , they are needed for the handle-backref logic\n        } else {\n            # remove the \\r we 'know' it is there, it now serves no purpose from here on.\n            substr($rules, $pos-2,2) = \"\";\n            $pos -= 2;\n        }\n    }\n    my $pos2;\n    dbg(3,\"calling get_items($rules, $pos, pos2, $esc_r);\\n\");\n    my $Chars = get_items($rules, $pos, $pos2, $esc_r);\n    if ($pos > $pos2)  { $rules=handle_rule_rej($rules); dbg(3, \"* This rule being saved: $rules\\n\"); push(@pp_rules,$rules); return 0;}\n    my @chars = split('', $Chars);\n    $idx = 0;\n    $which_group += 1;\n    dbg(2,\" * before foreach loop. rules=$rules Chars=$Chars\\n\");\n    foreach my $c (@chars) {\n        my $s = $rules;\n        # note handling \\ chars in a group is a bitch, since we remove them\n        # 1 at a time, and then continue to process the line. THUS, these\n        # 'look' like stray \\, so this [\\x][01] end up doing this\n        #    [01] during one level of recursion. Thus the crux of the problem.\n        # We change any \\ returned from a group, into \\~ and then later undo\n        # that problem (when the rule is complete), and the \\\\ is used as our\n        # signal that this is NOT part of any escaping.\n        #  We have to do same type shit with [ ] chars also :(\n        if (index('\\\\\\[\\]', $c) != -1)  { $c = \"\\\\\".$c.\"~\"; }\n        substr($s, $pos, $pos2-$pos+1) = $c;\n        my $s2 = handle_backref($which_group, $c, $s, $total, $idx);\n        if ($s2 ne $s) {dbg(3, \"before handle_backref($which_group, $c, $s, $total, $idx)\\nhandle_backref returned     $s2\\n\"); }\n        else { dbg(3, \"  handle_backref nothing changed ($which_group, $c, $s, $total, $idx)\\n\"); }\n        ++$total;\n        dbg(3, \" entering      recurse pp_rule($s2, $which_group, $idx, $total) pos=$pos pos2=$pos2\\n\");\n        if (pp_rule($s2, $which_group, $idx, $[6])) { return 1; }\n        $[6]++;\n        $idx++;\n        dbg(3, \"* returned from recurse pp_rule($s2, $which_group, $idx, $total) pos=$pos pos2=$pos2\\n\");\n    }\n    return 0;\n}\nwe simply find how many items are in each group, and multiply total, returning that total.\nsub pp_rule_cnt{ my ($rules) = (@_);\n    my $total = 1;\n    my $pos = index($rules, '[');\n    if ($pos == -1) { return 1; }\n    dbg(3, \"** entered pp_rule_cnt($rules)\\n\");\n    do {\n        while ($pos >= 0 && substr($rules, $pos-1, 1) eq \"\\\") {\n            $pos = index($rules, '[', $pos+1);\n        }\n        my $pos2;\n        my $esc_r = 0;\n        if ($pos > 1 && substr($rules, $pos-2,2) eq \"\\r\") {\n            $esc_r = 1;\n        }\n        my $Chars = get_items($rules, $pos, $pos2, $esc_r);\n    if ($pos > $pos2)  { dbg(3, \"** Returning pp_rule_cnt $total rules\\n\\n\"); return $total; }\n    my $skip = 0; # skip will be set to 1 for any parallel groups.\n    if (($pos > 1 && substr($rules, $pos-2,2) eq \"\\\\p\")) { $skip = 1; }  # skip \\p[]\n    if (($pos > 3 && substr($rules, $pos-4,4) eq \"\\\\p\\\\r\")) { $skip = 1; }  # skip \\p\\r[]\n    if (($pos > 2 && substr($rules, $pos-3,2) eq \"\\\\p\") && ord(substr($rules, $pos-1,1)) >= ord('0') && ord(substr($rules, $pos-1,1)) <= ord('9')) { $skip = 1; }  # skip \\p0[] to \\p9[]\n    if (($pos > 4 && substr($rules, $pos-5,2) eq \"\\\\p\") && ord(substr($rules, $pos-3,1)) >= ord('0') && ord(substr($rules, $pos-3,1)) <= ord('9')) { $skip = 1; }  # skip \\p0\\r[] to \\p9\\r[]\n    if ($skip==0) {\n        dbg(3, \"    This string part of count multiplier: $Chars\\n\\n\");\n        $total *= length($Chars);\n    }\n    $rules = substr($rules, $pos2);\n    $pos = index($rules, '[');\n} while ($pos > 0);\ndbg(3, \"** Returning pp_rule_cnt $total rules\\n\\n\");\nreturn $total;\n\n}\nsub load_classes {\n    my $i;\n    my $c_all;  for ($i = 1;    $i < 255; ++$i) { $c_all  .= chr($i); }\n    my $c_8all; for ($i = 0x80; $i < 255; ++$i) { $c_8all .= chr($i); }\n    $cclass{z}=$c_all;\n    $cclass{b}=$c_8all;\n    $cclass{'?'}='?';\n    $cclass{v}=\"aeiouAEIOU\";\n    $cclass{c}=\"bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ\";\n    $cclass{w}=\" \\t\";\n    $cclass{p}=\".,:;\\'\\?!`\\\"\";\n    $cclass{s}=\"\\$%^&*()-_+=|\\<>[]{}#@/~\";\n    $cclass{l}=\"abcdefghijklmnopqrstuvwxyz\";\n    $cclass{u}=uc $cclass{l};\n    $cclass{d}=\"0123456789\";\n    $cclass{a}=$cclass{l}.$cclass{u};\n    $cclass{x}=$cclass{l}.$cclass{u}.$cclass{d};\n    $cclass{o}=\"\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x0A\\x0B\\x0C\\x0D\\x0E\\x0F\\x10\\x11\\x12\\x13\\x14\\x15\\x16\\x17\\x18\\x19\\x1A\\x1B\\x1C\\x1D\\x1E\\x1F\\x7F\\x84\\x85\\x88\\x8D\\x8E\\x8F\\x90\\x96\\x97\\x98\\x9A\\x9B\\x9C\\x9D\\x9E\\x9F\";\n    $cclass{y}=\"\"; # note some types some chars are not valid (i.e. A..Z is not valid for a format where pass is lc(pass)\n    foreach my $c (split(\"\",\"bvcwpsludaxo\")) {\n        my $C = uc $c;\n        $cclass{$C}=purge($cclass{z}, $cclass{$c});\n    # some 'corrections' are needed to get a string to play nice in the reg-x we have\n    $cclass{$C} =~ s/\\\\/\\\\\\\\/g; # change \\ into \\\\\n    $cclass{$C} =~ s/\\^/\\\\\\^/g; # change ^ into \\^\n    $cclass{$C} =~ s/\\-/\\\\\\-/g; # change - into \\-\n    $cclass{$C} =~ s/\\]/\\\\\\]/g; # change ] into \\]\n}\n$cclass{Y}=$c_all;\n$cclass{Y} =~ s/\\\\/\\\\\\\\/g; # change \\ into \\\\\n$cclass{Y} =~ s/\\^/\\\\\\^/g; # change ^ into \\^\n$cclass{Y} =~ s/\\-/\\\\\\-/g; # change - into \\-\n$cclass{Y} =~ s/\\]/\\\\\\]/g; # change ] into \\]\n\n}\n1;\n```\nTo run, I use this launch script  (run is a symlink into JtR ./run directory for the perl script, and the rulez program)\n``` sh\n!/bin/sh\ncat $1.rule | run/rulecanonize.pl -- hc > $1_dedupe.rule\n```\nAgain, like I said this code is NOT user ready. It was simply code I worked up for this task, and will be using it for other things along the way.   If you want to play with it, have fun, but note, there is NO support, this is just my own toys hacked together.\n. I believe this can be closed.  The amount of duplication is very small now (and hard to find).  There are numerous that are 'almost' duplicate, but vary with specific input. \nThe biggest of the problems have been removed however.   \nNOTE, when new rule sets are submitted, it would be good to have them run through some peer review to make sure they are not full of duplicates (especially rule sets coming from auto-generated rules).\n. HOLD UP!\nI think I see some problems.  Let me validate.  I see some that I think should not be there:\n69544 : $1 $2 d ] ]\n68589 : $8 d ]\nI am pretty sure those were removed because of the d rule, and that is not valid.\nYup, validated, and that is wrong.\n```\n$ cat > x.rule\nd\n$a d ]\n$a$b d ]]\n$ ./a x\nTotal lines read 3 Unique lines written 1\n1 : $a d ]\n2 : $a$b d ]]\n```\n$ echo test | run/john -pipe -stdout -rule=:'d;$ad];$a$bd]]'\ntesttest\ntestatest\ntestabtest\n3p 0:00:00:00 0.00% 14.15p/s testabtest\n. Here is another dupe type (but hard to 'spot', and likely not used much)\n$x d ]   is dupe to M $x 6\n$x$y d ]] is dupe to M $x$y 6  (2nd is less steps)  Also, in JtR, the M can/should be skipped.\n$x$y$z d ]]] dupe to M$x$y$z6 or ^z^y^xd[[[\nNot sure this would show up often, I doubt it.  But it could in random rules.  But this is the type of duplicate finder I am 'trying' to work to find, in a rules emulator that would emulate the work being done, holistically view what was trying to be accomplished, and then see if there is a canonical more optimal way to do something.  So in the $xd] what we are trying to do is insert x into the middle of the word duplicated. So if M$x6 is emulated, it should also show that we are trying to insert x into the middle of the word duplicated, thus showing that $xd] and M$x6 are identical.  However, my script is nowhere to this level of intelligence yet, lol.\n. I had not started on any of the dupes listed in the last post, so do not worry.\nSo, if I did see a dupe of $x d ] and M$x6 I should remove the 2nd one, leaving the first, because we want to make sure that anything left works on more systems?\n. Please simply reject this PR and I will start over with new ones, that can be validated.\n. There is one more block of duplicates after this one.  But now the duplicates are getting fewer, and 'harder' to find and know they are really duplicates.\nAfter the next block, I think I am gonna call it quits for now.  What we have now is a great number of them removed.  Yes, there still are duplicates, but finding enough of them to make the ROI worthwhile is hard.\nI will however, do some rule 'auto re-write', once all of the dupes are in. I want to remove the true no-ops from the file. So far, I have preserved original data (with a couple of exceptions).  The no-ops are things like:     : ^x[ $x] and others.  But I will wait until all duplicate stuff is in, before doing those.  Those changes simply make the rules shorter (fewer steps and faster), by removing commands that play no part in the final word.\n. Well it looks like all recent comments were dumped into this PR, so I think it contains all of the work I have done so far.   That being the case, this is all of the duplicates I plan on right now, unless I spot something else which has a good ROI for the work it takes to find them.\n. This task is not being written off as completed!\n. Here is the entire script used for finding dupes (and finally to remove the no-op data).  NOTE, lots of lines were commented out to start, and then each step uncommented more and more blocks, so that only 1 'type' of duplicate finding was done at each step.  This script was made to run with either HC or john logic.  Also in the john side, we read data from the .conf files with multiple sections.\nIf run with -- hc as the 2 command line params, then only HC logic is used, also neither of the external perl module files will be required.  Those do nothing useful in HC mode.  In john mode, they load and process the .conf files, and perform the preprocessing logic to convert johns input rule (with rpp data in it), into the multiple rules that are used.  I can think of no way to script find duplicates within john's pre-processor extension.  It simply adds too much ambiguity to the work. Duplicates can easily be found with the pp, but it will have to be done by hand. This script works fine at showing the duplicates, BUT whoever is doing it will have to figure out where/how to hook it back into the pp code.  HC has no pp helper logic, so simplistic rule duplication logic is all that is required.\n``` Perl\n!/usr/bin/perl\nscript to canonize (or try to) john/hc/crack rules\n\n1 move all validation to as early as possible.\nlength validations, move to start, or to just after prior length changing command\nis char validations.  Move to start (right after lenght validations), or right after or character modifiers.\ns rule, drop any 2nd usage of original letter (the first ate it).\ns rule, if target (2nd letter) of an s is later the first letter of another s, then merge the 2 rules.\nsort s rules by original letter (and pack back to back).\ns logic groupings are bounded by things like case or other changers.\nplace all adjacent [ before ] so [][][ becomes [[[]] and ][ becomes []\nif we find a [ and there was a prior prepend, then drop the most recent prepend and the [\nif we find a ] and there was a prior append, then drop most recent append and the ]\nNote for prior 2, seeing many rule objects has to remove knowledge of the prior prepend, append\nor both.  Things like d } { and many others make removing that prior  append/prepend not be\nsomething that can be done as a no-op any more.\n[ and ] are grouped with {} and possibly o O x v\nremove all : ops, UNLESS : is the entire rule.\nTODO: { in middle of } block can be removed (and one })  { in middle of } block likewise.\nuse strict;\nmy @ar = ();\nmy $hc = 0;\nmy %map = ();\nmy $lncnt = 0;\nto do raw hashcat rules, just do:    cat xxx.rule | ./rulecanonize -- hc\nif ($ARGV[0] eq '--') {\n    if (defined $ARGV[1] && $ARGV[1] eq 'hc') { $hc = 1; }\n    @ar = ();\n} else {\n    # we may need to control 'what' gets loaded.\n    use File::Basename;\n    use lib dirname(FILE).'/';\n    use lib dirname(FILE).'/../run';\n    require jtrconf;\n    jtrconf::load();\n    @ar = jtrconf::getsection('List.Rules:'.$ARGV[0]);\n}\nchomp @ar;\nmy $force_output_noop_removed = 0;\nforeach my $rule (@ar) {\n    my $cnt=20000;\n    ++$lncnt;\n    if (substr ($rule, 0, 1) eq '#' || length($rule) == 0) { print \"$rule\\n\"; next; }\n    my $rulepp = $rule;\n    if ($hc == 0) {\n        use File::Basename;\n        use lib dirname(FILE).'/';\n        use lib dirname(FILE).'/../run';\n        require jtr_rulez;\n        jtr_rulez::jtr_rule_pp_init($rule, 125, $cnt, $hc);\n    }\n    my $rule_cnt = 0;\n    while (defined ($rulepp) && length($rulepp)>0) {\n        my $canon = canonize($rulepp, $hc, 1);\n        if (!defined $map{$canon}) {\n            $map{$canon} = $lncnt-1;\n            if ($force_output_noop_removed == 1) {\n                print \"$canon\\n\";\n                print STDERR \"ln-$lncnt:  $rule  reduced to $canon\\n\";\n            } else {\n                print \"$rule\\n\";\n            }\n        } else {\n            print STDERR \"ln-$lncnt:  $rule  dup of ln-$map{$canon}: $ar[$map{$canon}]\\n\";\n        }\n    if ($hc == 0) {\n        use File::Basename;\n        use lib dirname(__FILE__).'/';\n        use lib dirname(__FILE__).'/../run';\n        require jtr_rulez;\n        $rulepp = jtr_rulez::jtr_rule_pp_next();\n    } else {\n        $rulepp = \"\";\n    }\n}\n\n}\nsub ch { my ($r, $i) = @;\n    return substr($r,$i,1);\n}\nsub canonize { my ($rule, $hc, $sp) = @;\n    my $rules = tokenize($rule, $hc);\n    my $mod = 1;\n    if (!defined $hc) { $hc = 0; }\n    $force_output_noop_removed = 0;\n    while ($mod == 1) {\n        $mod = 0;\n        my @ar = @$rules;\n        # remove all : and -: (unless it is the ONLY rule)\n        for (my $i = 0; $i < scalar @ar; ++$i) {\n            if (scalar @ar > 1 && $ar[$i] eq ':') {\n                splice(@ar, $i, 1);\n                $force_output_noop_removed = 1;\n                --$i;\n            }\n            if ($ar[$i] eq '-:') {\n                splice(@ar, $i, 1);\n                --$i;\n            }\n        }\n        # remove all identical - rejection rules (keeping the first only.\n        if ($hc == 0) {\n        for (my $i = 0; $i < scalar @ar-1; ++$i) {\n            if (length($ar[$i]) > 1 && ch($ar[$i],0) eq '-') {\n                for (my $j = $i+1; $j < scalar @ar; ++$j) {\n                    if ($ar[$i] eq $ar[$j]) {\n                        splice(@ar, $j, 1);\n                        --$j;\n                    }\n                }\n            }\n        }}\n        # put all rejection rules (-) first.\n        if ($hc == 0) {\n        my $rej1 = 0;\n        for (my $i = 0; $i < scalar @ar-1; ++$i) {\n            if (length($ar[$i]) > 1 && ch($ar[$i],0) eq '-' && $i != $rej1) {\n                my $s = $ar[$i];\n                splice(@ar, $i, 1);\n                splice(@ar, $rej1, 0, $s);\n                ++$rej1;\n            }\n        }}\n# remove [ and ] if there were $ or ^ (or A[zl] or A0) Likely we should first convert\n# A[lz] into $ and A0 into ^ and then later they get converted back into Az/0\n# NOTE, { } will cause this to fail without adjustments, D may, as could i. as could most anything (such as d)\n# ITW, I did see d and $ad] $a$bd]] which are obviously 3 differnt rules.\n    my $h=-1; my $t=-1;\n    for (my $i = 0; $i < scalar @ar; ++$i) {\n        my $c = ch($ar[$i],0);\n        if ($c eq '$') { $t = $i; next; }\n        if ($c eq '^') { $h = $i; next; }\n        if ($c eq '[' && $h != -1) {\n            splice(@ar, $i, 1);\n            splice(@ar, $h, 1);     # need to handle Az here, and possibly in next line.\n            $force_output_noop_removed = 1;\n            $h = $t = $i = -1;\n            next;\n        }\n        if ($c eq ']' && $t != -1) {\n            splice(@ar, $i, 1);\n            splice(@ar, $t, 1);     # need to handle A0 here, and possibly in next line.\n            $force_output_noop_removed = 1;\n            $h = $t = $i = -1;\n            next;\n        }\n        if (index('dfpODPIxq{}', $c) != -1) {\n            $h = $t = -1;\n        } elsif ($c eq 'r') {\n            my $tmp = $h; $h = $t; $t = $tmp;\n        } elsif (index('kzy4,', $c) != -1) {\n            $h = -1;\n        } elsif (index('KZY6.\\'', $c) != -1) {\n            $t = -1;\n        }\n    }\n    # drop 'dupe' s values, or s where an output later becomes an s input.\n    for (my $i = 0; $i < scalar @ar - 1; ++$i) {\n        if (ch($ar[$i],0) eq 's') {\n            for (my $j = $i+1; $j < scalar @ar; ++$j) {\n                if (ch($ar[$j],0) eq 's') {\n                    if (ch($ar[$i],1) eq ch($ar[$j],1)) {\n                        $mod = 1;\n                        splice(@ar, $j, 1);\n                        $force_output_noop_removed = 1;\n                        # before proceeding, remove ANY others like this\n                        for (my $k = $j; $k < scalar @ar; ++$k) {\n                            if (ch($ar[$i],1) eq ch($ar[$k],1)) {\n                                splice(@ar, $k, 1);\n                                --$k;\n                                next;\n                            }\n                        }\n                        --$j;\n                        next;\n                    }\n                    if (ch($ar[$i],2) eq ch($ar[$j],1)) {\n                        $mod = 1;\n                        substr($ar[$i],2) = substr($ar[$j],2);\n                        my $c = substr($ar[$j],1,1);\n                        splice(@ar, $j, 1);\n                        $force_output_noop_removed = 1;\n                        # before proceeding, remove ANY others like this\n                        for (my $k = $j; $k < scalar @ar; ++$k) {\n                            if ($c eq ch($ar[$k],1)) {\n                                splice(@ar, $k, 1);\n                                --$k;\n                                next;\n                            }\n                        }\n                        --$j;\n                        next;\n                    }\n                }\n            }\n        }\n    }\n    # now that sCC has been 'reduced' removing dupes and cycles, canonize it by outputting groupings in sorted order\n    for(my $i = 0; $i < scalar @ar; ++$i) {\n        if (ch($ar[$i],0) eq 's' && ch($ar[$i+1],0) eq 's' && ord(ch($ar[$i],1)) > ord(ch($ar[$i+1],1))) {\n            my $s = $ar[$i];\n            $ar[$i] = $ar[$i+1];\n            $ar[$i+1] = $s;\n            $mod = 1;\n            next;\n        }\n    }\n\n    # convert $ ^ blocks into A0'bbb' and Az'xxx' with A0 packed first.\n    for(my $i = 0; $i < scalar @ar; ++$i) {\n        if (ch($ar[$i],0) eq '$' && ch($ar[$i+1],0) eq '$') {\n            $ar[$i] .= substr($ar[$i+1],1);\n            splice(@ar, $i+1, 1);\n            --$i;\n            $mod = 1;\n            next;\n        }\n        if (ch($ar[$i],0) eq '$' && ch($ar[$i+1],0) eq '^') {\n            my $s = $ar[$i];\n            $ar[$i] = $ar[$i+1];\n            $ar[$i+1] = $s;\n            $mod = 1;\n            next;\n        }\n        if (ch($ar[$i],0) eq '^' && ch($ar[$i+1],0) eq '^') {\n            $ar[$i] = '^' . substr($ar[$i+1],1) . substr($ar[$i],1);\n            splice(@ar, $i+1, 1);\n            --$i;\n            $mod = 1;\n            next;\n        }\n        if ($ar[$i] eq ']' && $ar[$i+1] eq '[') {\n            $ar[$i] = '[';\n            $ar[$i+1] = ']';\n            $mod = 1;\n            next;\n        }\n        if (index('cClut', $ar[$i]) != -1 && $ar[$i+1] eq ']') {\n            $ar[$i+1] = $ar[$i];\n            $ar[$i] = ']';\n            $mod = 1;\n            next;\n        }\n        if (index('lut', $ar[$i]) != -1  && $ar[$i+1] eq '[') {\n            $ar[$i+1] = $ar[$i];\n            $ar[$i] = '[';\n            $mod = 1;\n            next;\n        }\n        # not sure these are right, so left out of code.\n        #if (substr($ar[$i],0,1) eq '$' && $ar[$i+1] eq '[') {\n        #   $ar[$i+1] = $ar[$i];\n        #   $ar[$i] = '[';\n        #   $mod = 1;\n        #   next;\n        #}\n        #if (substr($ar[$i],0,1) eq '^' && $ar[$i+1] eq ']') {\n        #   $ar[$i+1] = $ar[$i];\n        #   $ar[$i] = ']';\n        #   $mod = 1;\n        #   next;\n        #}\n    }\n\n    @$rules = @ar;\n}\nmy $s = \"\";\nforeach my $c (@$rules) {\n    if (length($c)>2 && ch($c,0) eq '$') {\n        if ($hc > 0) {\n            my $s = \"\";\n            for (my $j = 1; $j < length($c); ++$j) {\n                if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n                $s .= '$'.substr($c,$j,1);\n            }\n            $c = $s;\n        } else {\n            $c = \"Az`\".substr($c,1).'`';\n        }\n    }\n    if (length($c)>2 && ch($c,0) eq '^') {\n        if ($hc > 0) {\n            my $s = \"\";\n            for (my $j = length($c)-1; $j > 0; --$j) {\n                if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n                $s .= '^'.substr($c,$j,1);\n            }\n            $c = $s;\n        } else {\n            $c = \"A0`\".substr($c,1).'`';\n        }\n    }\n    if (defined $sp && $sp != 0 && length ($s)) { $s .= ' '; }\n    $s .= $c;\n}\nreturn $s;\n\n}\nsub tokenize { my ($rule, $hc)=@;\n    my @ar = split //, $rule;\n    my @rules = ();\n    for (my $i = 0; $i < scalar @ar; ++$i) {\n        my $c = $ar[$i];\n        next if ($c eq ' ');\n        my $esc = 0;\n        # 1 byte rules.\n        if (index('E:lucCtrd{}f12[]PISVMQUkK46q', $c) != -1) { # 1 char rules\n            push @rules, $c;\n            next;\n        }\n        if ($hc == 0) {\n            if ($c eq '-') {  # jtr rejections\n                my $s = $c.$ar[++$i];\n                if ($ar[$i] eq '<' || $ar[$i] eq '>') {\n                    $s .= $ar[++$i];\n                }\n                push @rules, $s;\n                next;\n            }\n            if (index('pRL', $c) != -1) { # 1 char rules\n                # if next char is digit, then use HC pRL rules.\n                if (ord($ar[$i+1]) < ord('0') || ord($ar[$i+1]) > ord('9')) {\n                    push @rules, $c;\n                    next;\n                }\n            }\n        }\n        if (index('T$^<>\\'DpRL+-zZ.,yY', $c) != -1) { # 2 char rules (pRL here is pN 2 char rule)\n            my $s = $c.$ar[++$i];\n            push @rules, $s;\n            next;\n        }\n        if (index('xioO*', $c) != -1) { # 3 char rules\n            my $s = $c.$ar[++$i]; $s .= $ar[++$i];\n            push @rules, $s;\n            next;\n        }\n        if (index('Xv', $c) != -1) { # 4 char rules\n            my $s = $c.$ar[++$i]; $s .= $ar[++$i]; $s .= $ar[++$i];\n            push @rules, $s;\n            next;\n        }\n        if ($c eq 'A') {\n            my $s = $c.$ar[++$i];\n            $c = $ar[++$i];\n            $s .= $c;\n            while ($ar[$i+1] ne $c) {\n                $s .= $ar[++$i];\n            }\n            $s .= $ar[++$i];\n            push @rules, $s;\n            next;\n        }\n        # handle rules that can use classes in JtR mode\n        if (index('@!/()e', $c) != -1) { # 2-3 char rules\n            my $s = $c.$ar[++$i];\n            if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n            push @rules, $s;\n            next;\n        }\n        if (index('s', $c) != -1) { # 3-4 char rule with ? 2nd char\n            my $s = $c.$ar[++$i];\n            if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n            $s .= $ar[++$i];\n            push @rules, $s;\n            next;\n        }\n        if (index('=%', $c) != -1) { # 3-4 char rule with ? 3rd char\n            my $s = $c.$ar[++$i]; $s .= $ar[++$i];\n            if ($hc == 0 && $ar[$i] eq '?') { $s .= $ar[++$i]; }\n            push @rules, $s;\n            next;\n        }\n        print \"Error, unknown rule token at $c next char $ar[$i+1]  Orig: $rule\\nRules found so far : \";\n        foreach my $s (@rules) {\n            print \" $s \";\n        }\n        print (\"\\n\");\n        exit 1;\n    }\n    return \\@rules;\n}\n```\n. Yes, this can be merged. I validated every rule was a duplicate.  There are about 1100 more removed in this PR.\nNOTE, I wrote code to find the rest.  There are a couple of types that I can auto-remove.  The others may take hand looking.  There are roughly 12k more duplicates in dive, than have been removed as of now.\nThe code to find the rest simply built a dictionary file with some random character lines. I started with john's password.lst, then did Rock-You top 50k (which was slow), but in the end, I found the best wordlist simply to be the random character lines, where i have lines of varying lengths (3 to 32), and 50 lines of each length.    The method, is I run each rule over every word. I then hash all the outputs which are different than the input word (simply add them using MD5_Update).  Then when done, do an MD5_Final to a buffer FOR THAT RULE.  Then move on to the next rule against exact same wordlist.   When complete, I simply do a O(n^2) braindead search for rules that have the same hash value (i.e. rules which produced EXACTLY the same end result).  This is not 100% safe, the duplicates DO have to be looked at by hand.  BUT there can be no other rules in the entire set which do produce duplicates. The list I have now is ALL of them.\nBut I am going to wait for this one to be merged (this one has been validated).  If you want, you can look at each commit. There is a comment of exactly which rules were found to be duplicated with which other rules, to see that everything WAS done properly.  There were 2 rules where my script errantly removed a rule. I put them back in by hand.  It had to do with 2 parts of the script fighting with each other (the sorting of the s commands, and the cycle/noop remove code of the s commands)\n. Here is the first 'taste' of the duplicates found by running data:\nduplicate rules:\n(0)  c\n(1304)  T0tc\n(1761)  uc\n(2372)  lc\n(85293)  Ct\n(88696)  Ec\nduplicate rules:\n(1)  l\n(10231)  cl\n(18932)  l*B5*B5\n(33011)  ut\n(47389)  lsMF\n(108387)  ll\nduplicate rules:\n(2)  u\n(148)  uu\n(1138)  cu\n(14801)  Cu\n(27600)  lu\n(63926)  usa3\nAll of those are 100% duplicate.  There are some things that could be scripted for, but I think this will simply have to be looked at by hand, and then a script written to read in this log file and properly remove the lines from the rule file.\nI knew there were duplicates like this (in all, I think dive will end up with 25% or more of it removed, and still have 100% identical finding capability).\nHowever, before I proceed with this, we need to make a call on whether we should change all of the xNM commands to ONM   I think so.  Looking at the data, it really appears that when these rules were generated, that the logic of the ONM is what was wanted for these.  But I will leave that call up to you.  It does greatly impact the duplication finding logic. There are about 2500 fewer duplicates found of we switch from x to O, but most of all, I think there are about 5000 more rules that actually produce hits if we switch from x to O\nThat being the case, it is very likely that all rule files produced prior to when you made that switch should be changed. You might want to keep both flavors, in case there are people running older versions of HC, where the x still means omit.   But if the rules have not been updated since that logic change was done, then x almost certainly is wrong when run on the newer HC versions/\n. > I think changing the xNM to ONM is the right way as the dive.rule was created back when xNM what is today ONM. Go for it!\nI will do that as a stand alone commit, so it does not get 'confused' with anything else.\n\nI'm not so much about supporting old rules.\n\nOk, ONM it is.   A very easy change.  Were there other 'older' .rule files that would have this same issue?  Getting the rules working with proper logic will only help to improve their find rates.  If a rule was supposed to do the logic of Onm, but instead is now doing the extract logic, then it will match many fewer candidates. Actually, it becomes a sore point for duplicates, because often we strip the word down to just 1 or 2 bytes, instead of removing those 1 or 2 bytes.\n. There are some rules in the final dive.rule that are 'almost' duplicates, but have been kept. They may have only produced a couple of unique words on the 55k input file run, but they were kept intact none the less.  I do not see us being able to remove much more than what is removed, without starting to have 'some' affect on the end generated words.  Right now, it is 100% the 'same' as where we started, only 20-25% fewer duplicate words generated.\nThis ruleset still does generated a fairly large number of duplicates, that is mostly due to not using any rejection code.  Running the rules against the input file I have done, produces about 70% or so duplicates.  But this is almost all where the word is left unchanged most of the time.  I am not 100% sure for oclHashcat on the usage of rejection logic.  I now in john for most any salted hash, getting the rejection logic right helps things out. It can cause the speed to be 'less', BUT the overall time required to complete the work is less.  For slower hashes, rejection logic is critical.  That is also with the helper logic in john, that does a uniq logic for generated passwords, and only uses them if the word being generated is different that the last one generated.  That helps, but does not fully eliminated duplicates.   The 70% duplicates is USING the john logic. I bet the percentage is quite a bit higher than that when running the rules through HC.\n. It was a big difference waiting until the xNM were changed to ONM.  The differences were quite a few more before this, and they did not 'look right'.  But after the change, things lined up properly.  I did check the entire list, and all were easy to spot as being duplicates.\nIt looks like generated.rules (and generated2) also need to have the xNM to ONM logic done on them.  They also have quite a few dupes, that can be found using the tools I have.  I will get the x->O checked in first with only that change.  It makes it easier to later look over the duplicate finds, when you have only 1 thing to look at.  Helps to keep my mind focused.\n. ",
    "AntonKuzminRussia": "I'm not C coder, i cant do it myself :( \n. Hello. Thanks. I think it good solution because a log-file contains a \ndict, mask, rule information. Its all what i need for known current \nbrute step.\n02.03.2016 10:34, philsmd \u043f\u0438\u0448\u0435\u0442:\n\nI think I understood the problem you are describing above, but in your \ncase if you want to just get the information on when exactly the mask \nchanged etc it should be enough to just read/parse the oclHashcat.log \nfile (or monitor it the same way you monitor the --status output).\nI'm not sure if it makes sense to print the mask/dictionary each and \nevery time when the status timer (--status-timer) triggers and showing \nthe change only when there was a change makes the format of the \n--status output much less easier to parse.\nOn the other hand, we probably shouldn't make too many changes in the \noutput of --status-automat because some 3rd-party wrappers already use \nit heavily and changing it may break their parser. (of course when we \nreally thing we need to change the format, we definitely should do so \nAND document it appropriately).\nI think the .log file is exactly what you are looking for, it tells \nyou when exactly there was a change in mask/dict etc. The format of \nthe .log file is also more appropriate for this kind of information, \nthe status-automat is more or less just about the current speed/number \nof cracks etc.\nDo you think this (.log file reading/parsing/monitoring) works for you?\nThx\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/hashcat/oclHashcat/issues/247#issuecomment-191111395.\n. Yes. Big thanks! All information what i need i found in .log/.\n. \n",
    "AgelxNash": "XenForo kernel supports 2 encryption schemes:\nsha1(sha1($hash).$salt);\n\n8923d65394a85921b336e42ae89e93e28c5c381a:824acdc9c2276bc1b7b9a9ec22684e6ac4b55eda:1\nbc35e95b25b49ae6f8c7f903e16d339514585322:2661f4457c4d9ab6c4c5fffa539cfb7f12bdede0:123\nf14871a534e1b61211c39455c61acede6e588ea0:64269efd0831d0a031c8a98c8c090b6eb6124962:qweqwe\n\nsha256(sha256($hash).$salt);\n\nf92f8c9de94d3d581c022320c6d812f14e48e2c239c88c255d5acd63edd1fc3a:6f70c9b20542c519285aa7bfbb10ce94113046c3bd1d27b16708c30ffe552194:1\nfcd42e07f1cb80704e859e2a371598dac3288546fad759551a21ca432955ff4d:b436a8594e03c5c8094fefac24f2e69ef6891a8a78e2608fd3ecd65d18154beb:123\n697a718659641f5bd8235d56e2a77bf2fd68d081d3c78bb20653e1c239484f0a:c753530edd8c4fbab38bcb07daeeaa58e7f3011c1260859a91dd304c55e8da8d:qweqwe\n\nSource\n. @Fist0urs hash:salt:password\n. The original salt has a length of 10 characters. But it's not known, since in the database are stored encrypted by the selected method: sha1/sha256.\n. Yes\n. Regex to match original salt /^[a-f0-9]{10}$/\nIf this is important...\n``` Python\nimport hashlib\npassword = '1'\nsalt = '824acdc9c2276bc1b7b9a9ec22684e6ac4b55eda'\nprint hashlib.new(\"sha1\", hashlib.new(\"sha1\", password).hexdigest() + salt).hexdigest()\n```\n. algo>hash:salt:password\n. To hash adds 8 characters md5(md5($pass.$salt))\nAn example of the default algorithm in python\n``` python\nimport hashlib\nalgo = 'uncrypt>'\npassword = '123123'\nsalt = '1'\nsalt = hashlib.new(\"md5\", password + salt).hexdigest()\nprint algo + hashlib.new(\"md5\", salt + hashlib.new(\"sha1\", salt + password).hexdigest()).hexdigest() + hashlib.new(\"md5\", salt).hexdigest()[0:8]\n```\n. @jsteube uncrypt>. An example of the default algorithm in my previous post\n. @jsteube Happened?. ",
    "gpuhash": "OMG just realised we lost one line while commiting.\nhttps://github.com/gpuhash/oclHashcat/commit/541f231c23dc4f35f266600d8cfcec205a51beaf\n. We created three test hccap files, all contain 3 digests with 3, 2 and 1 unique \"salts\".\nWithout our patch it always recognized as 3 unique salts and thus 3x time wasted.\nAll 3 passwords were successfully found during our tests (Hint: all three passwords are 8-digit numbers)\nWe can't imagine unique WPA salts in the real world (WPA salt isn't only ESSID, it is ESSID, both MACs, ANonce and SNonce as well) but this approach will be very handy for developing proof-of-work algorithms for distributed crackers.\ntest_hccap.tar.gz\n. Your latest commit makes sense!\nTested precompiled beta vs multi-handshake hccapx with both GTX1080 and HD7850 (amdgpu-pro 16.60) and all passwords were found now. Also current speed reading is now consistent and number of salts shown is 1, thats good.\nAttaching another multi-handshake hccapx with 10 random ?d?d?d?d?d?d?d?d passwords for the same SSID if someone want to make more tests.\ntest_new.hccapx.gz. ",
    "RezaSR": "Yes, I didn't know about keyspace.\nExcuse me for the wrong report and thanks for your help.\n. ",
    "JasonJAyalaP": "(updated text above, excuse my sloppiness)\npassword is hashcat\n. ",
    "ethtester": "I thought the minimum password length for ethereum wallets is 8?  But yes, this would be a great feature to add to Hashcat. Hello Chick3nman, does this also work with Mist created keystores?. Hello Chick3nman,\nHere are a couple of test wallets generated from Mist 0.3.9 and myetherwallet.   I'm currently using a password cracker called ethcracker.  https://github.com/lexansoft/ethcracker   This tool can only test 2 passwords per second on Mist created wallets, but will do about 180 plus passwords per second on myetherwallet.com created wallets.  I think it has some to do with the \"n\" iterations value being much higher in Mist.  Would be great if we could leverage hashcat to speed things up.   Thank You.\nTest wallet passwords  = password123 \ntestkeys.zip\n. Hello Chick3nman,\nCorrect me if I'm wrong,  hashcat will require an update to add a new hash mode before we can use the hash format you listed above, right?. How long does it usually take for new modes to be coded after the initial request?. @jsteube Thanks for the update.  Is that 12-13H/s achieved by using all 4 cores of the 4770k?. If one were to build a rig with 320GB of ram per GPU, would this negate the need for 256 divisions TMTO?. Hello @jsteube , retail versions of the  Radeon Pro SSG cards with upto 1TB of on board nand memory should be shipping very soon.  Do you think this hardware development marks a game changer for scrypt hashing rates and what kind of hash rate would you estimate if hashcat were to run against this card?  I would be wiling to purchase a few of these units and donate access to them.  Thx\nhttps://youtu.be/vyKgT5QUU2Q?t=59m50s\nhttps://www.amd.com/Documents/Radeon-Pro-SSG-Technical-Brief.pdf\nhttp://www.amd.com/en-us/press-releases/Pages/amd-radeon-pro-2016jul25.aspx\n. Hello @jsteube, you stated above.    \"But to make use of the GPU power, we need to spawn at least 1280 parallel computations, so we end up with a memory requirement of 320GB ram per GPU\" \nWhy the 1280 computations number? could you not spawn just enough processes according to how much GPU ram there is?. ",
    "ZerBea": "I did some more tests on the latest commit (https://github.com/hashcat/oclHashcat/commit/8d83493f33041ed5b5deb23bcc47c941339fa980)\ncompiled with make linux64  PREFIX=/usr/  CFLAGS=\"-I/usr/include/nvidia/gdk/ -Iinclude generates this kernel during runtime of oclHashcat: amp_a0.ddd53fbb.kernel \ncompiled with make linux64  PREFIX=/usr  CFLAGS=\"-I/usr/include/nvidia/gdk/ -Iinclude generates this kernel during runtime of oclHashcat  amp_a0.7a8ffdfb.kernel\namp_a0.ddd53fbb.kernel works as expected\namp_a0.7a8ffdfb.kernel shows the issue in all amp-kernels\nSo I did a diff amp_a0.ddd53fbb.kernel amp_a0.7a8ffdfb.kernel\n    42c42\n    <   mul.wide.u32    %rd5, %r1, 80;\n    ---\n    >   mul.wide.u32    %rd5, %r1, 272;\n    44c44\n    <   ld.global.u32   %r10929, [%rd6+64];\n    ---\n    >   ld.global.u32   %r10929, [%rd6+256];\n    20931c20931\n    <   mul.lo.s64  %rd9, %rd12, 80;\n    ---\n    >   mul.lo.s64  %rd9, %rd12, 272;\n    20941c20941\n    <   st.global.u32   [%rd10+64], %r10929;\n    ---\n    >   st.global.u32   [%rd10+256], %r10929;\nI didn't use make install. I build a package and installed this using pacman.\ngcc:    5.3.0\nmake: 4.1\nPackage PKGBUILD:\n...\nbuild() {\n    cd \"$startdir\"\n    rsync -av --delete $_pkgname/ src\n    patch -p1 $srcdir/src/Makefile < Makefile.patch\n    cd \"$srcdir\"\n    make linux64 CFLAGS=\"-I/usr/include/nvidia/gdk/ -Iinclude\"\n}\npackage() {\n    cd \"$srcdir\"\n    install -d \"${pkgdir}/usr/share/oclHashcat/\"\n    install -d \"${pkgdir}/usr/share/doc/oclHashcat/\"\n    cp -ar charsets OpenCL include masks rules hashcat.hcstat hashcat_tuning.hctab extra \"${pkgdir}/usr/share/oclHashcat/\"\n    cp -ar docs/* \"${pkgdir}/usr/share/doc/oclHashcat/\"\n    install -Dm755 oclHashcat64.bin \"$pkgdir/usr/bin/oclHashcat\"\n}\n...\nMakefile.patch:\n-PREFIX                   ?= /usr/local\n+PREFIX                   ?= /usr/\nThis works fine for me, but I don't understand why there is a difference in the compliled amp-kernels depending on a tailing slash in the Makefile....\nBest regards\nZerBea\n. You're right. I patched the makefile before, and https://github.com/hashcat/oclHashcat/commit/6636cc144d35f2246b85c4b8bbe9b9f5bad5c799 reversed my patch.......\nI did some other tests.\nMy flags (I need this to compile oclHashcat successfully on ARCH)\nCFLAGS=\"-I/usr/include/nvidia/gdk/ -Iinclude\"\n- Native build works.\n- make install didn'work because hashcat_tuning.hctab wasn't installed automaticly by the makefile\n  /usr/local/share/oclHashcat/hashcat_tuning.hctab: No such file or directory\n  must copy this file by hand and the the build works \n- make PREFIX=/usr install didn't work \n  2013 segmetation fault\n- make PREFIX=/usr/ install works \n- Involving the arch package manager to install to /usr only works with the PREFIX=/user/\n- Involving the arch package manager to install to /usr/local works\nWell, it's not the ARCH package manager that causes the issue.\nIt seems, oclHashcat doesnt'l like to be installed in /usr\nBy the way...\nWhy do you not use the final suggestion (issue #20)\nsnip\nWe discussed the new \"layout\", this is the final suggestion:\n    /usr/bin/.bin\n    /usr/share/doc/oclHashcat/ (stuff from docs/ and example* files)\n    /usr/share/doc/oclHashcat/extra/\n    /usr/share/oclHashcat/hashcat.hcstat\n    /usr/share/oclHashcat/charsets/\n    /usr/share/oclHashcat/kernels/\n    /usr/share/oclHashcat/masks/\n    /usr/share/oclHashcat/rules/*\nsnip\nInstead of this,  Makefile uses:\nPREFIX                   ?= /usr/local\nbest regards\nZerBea\n. Hi neheb. Thank your for the information. Indeed, the flags are used no more.\nWhich PKGBUILD do you mean?\nI don't use AUR packages, I build my own packages (nvidia-gdk-352.79-1-x86_64.pkg / oclHashcat-git-r694.d7f8b35-1-x86_64.pkg). Both are working fine\nMy main questions are:\nWhy are there issues when compiling oclHashcat with /usr instead of /usr/local ?\n(/usr/local is obsolete in ARCH in future times).\nWhy are there no issues when compiling oclHashcat with /usr/?\nBy the way, you should think about an increase of exec_path_len from 1024 to PATH_MAX (4096) in shared.c\nchar get_exec_path ()\n  int exec_path_len = 1024;\n. Is it possible, that the detection of the of the install dir (shared.c) could cause this issue:\n  if ((last_slash = strrchr (install_dir, '/')) != NULL)\n    last_slash = 0;\n. Hi philsmd.\nTnx for your info. At least I think, I found the fault. The output of the compiler process on my machine was everytime \"oclHashcat64.bin\" (crosscompiled output).\nAfter a clean copy of the make file, now the end of the process is a native build (oclHashcat) and everthing's fine......\nBest regards\nZerBea \n. Additional information about EAP-MD5:\nThe attack is described here:\nhttp://www.willhackforsushi.com/?page_id=67\nsource code available here:\nhttp://www.willhackforsushi.com/code/eapmd5pass/1.4/eapmd5pass-1.4.tgz\nsample hash taken from the readme:\nusername:  jwright\nchallenge: d7ec2fff2ada437f9dcd4e3b0df44d50\nresponse:  1ffc6c2659bc5bb94144fd01eb756e37\npassword:  beaVIs\nCheers\nZerBea\n. I don't know. Did a update tomorrow from (v3.00-beta-11-gd0123e6+) to (v3.00-beta-25-gb5cb29a)\nand none of my testlist word are found.\nv3.00-beta-11-gd0123e6+:\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: File (testlist)\nHash.Target....: File (test.hccap)\nHash.Type......: WPA/WPA2\nTime.Started...: Tue May 17 10:21:44 2016 (3 mins, 8 secs)\nSpeed.Dev.#1...:    37612 H/s (15.31ms)\nRecovered......: 382/382 (100.00%) Digests, 382/382 (100.00%) Salts\nRecovered/Time.: CUR:120,N/A,N/A AVG:121.51,7290.55,174973.19 (Min,Hour,Day)\nProgress.......: 7026508/7026508 (100.00%)\nRejected.......: 0/7026508 (0.00%)\nHWMon.GPU.#1...:  0% Util, 57c Temp, N/A Fan\nbest regards\nZerBea\n. I'll check the git history to find the last working commit beetween beta 11 and beta 25 using hashcat.hccap\n. Last working commit (using hashcat.hccap and my my test.hccap) is:\nhttps://github.com/hashcat/oclHashcat/commit/1d797a1c3e980922b2c048fed24969bcff8c3efc\nUpdating to this version causes the error in both (hashcat.hccap and my test.hccap):\nhttps://github.com/hashcat/oclHashcat/commit/0ddb264a5ac0e9f09381062bb93f0b77fd099f3e\nIt seems, that packv() and unpackv() didn't work as expected.\nbest regards\nZerBea\n. Possible line 16188 in hashcat.c causes the fault:\nrc = set_fan_control (data.hm_xnvctrl, data.hm_device[device_id].xnvctrl, NV_CTRL_GPU_COOLER_MANUAL_CONTROL_TRUE);\nSome additional infos after running valgrind:\nWarning: set address range perms: large range [0x395da040, 0x499da040) (defined)\nInvalid read of size 8\n   at 0x45AC4B: ??? (in oclHashcat/hashcat)\n   by 0x418DDF: ??? (in oclHashcat/hashcat)\n   by 0x5277740: (below main) (in /usr/lib/libc-2.23.so)\n Address 0x0 is not stack'd, malloc'd or (recently) free'd\nProcess terminating with default action of signal 11 (SIGSEGV): dumping core\n Access not within mapped region at address 0x0\n   at 0x45AC4B: ??? (in oclHashcat/hashcat)\n   by 0x418DDF: ??? (in oclHashcat/hashcat)\n   by 0x5277740: (below main) (in /usr/lib/libc-2.23.so)\n If you believe this happened as a result of a stack\n overflow in your program's main thread (unlikely but\n possible), you can try to increase the size of the\n main thread stack using the --main-stacksize= flag.\n The main thread stack size used in this run was 8388608.\nValgrind also shows this warning:\nload XNVCTRL library failed, proceed without XNVCTRL HWMon enabled.\nbut  libxnvctrl-352.21 is installed.\nBest regards\nZerBea\n. Hi Jens.\nSegmentation fault is gone, and hashcat works like a charm,\nCheers\nZerBea\n. ...but \"Failed loading the XNVCTRL library\" still exists.\nUsing ARCH-Linux there is no dynamic library \"libXNVCtrl.so\".\nInstead we have a static library \"libXNVCtrl.a\" containing:\nNVCtrl.o\ng_stamp.o\nhttps://www.archlinux.org/packages/community/x86_64/libxnvctrl/files/\nIs it possible to link it to the calling code at compile time.\nBest Regards\nZerBea\n. I did this before, but compiling the lib doesn't work:\nXNVCTRLQueryTargetAttribute is missing from XNVCTRL shared library.\nWhich version of the lib is used by UBUNTU?\n. Thank you, got it.\nNow using version 367.27 of the lib.\nWill set \"flag out of date\" on arch package system right now.\n. works like a charm - good job.....\nissue closed\nregards\nZerBea\n. Hi Jens.\nAll generated hccap are ok. Running a mask attack the password was found on each generated hccap,\nbut running a dictionary attack using a wordlist hashcat fails if the word is greater than 32 chars:\nhashcat -m 2500 -w 3 --remove --logfile-disable --potfile-disable --outfile-format=3 --outfile-autohex-disable test.hccap testlist\nI think it's o problem of parsing the wordlist.\n. I'll try.....\n. Well, patch worked like a charm on dictionary attack if words > 32 chars.\nBest regards\nZerBea\n. Compiled latest commit hashcat (v3.10-138-gcaeedd5):\nWarning: set address range perms: large range [0x395d8028, 0x499d8058) (noaccess)\nInvalid read of size 4\nat 0x40EA11: main (hashcat.c:5418)\nAddress 0x56ac890 is 64 bytes inside a block of size 144 free'd\nat 0x4C2AD90: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\nby 0x46B719: myfree (memory.c:44)\nby 0x471AAE: opencl_ctx_destroy (opencl.c:1497)\nby 0x40EA09: main (hashcat.c:5416)\nBlock was alloc'd at\nat 0x4C29BBE: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\nby 0x46B6B6: mymalloc (memory.c:26)\nby 0x405896: main (hashcat.c:1700)\nHEAP SUMMARY:\nin use at exit: 183,821 bytes in 128 blocks\ntotal heap usage: 1,768,196 allocs, 1,768,068 frees, 2,062,921,184 bytes allocated\nLEAK SUMMARY:\ndefinitely lost: 467 bytes in 7 blocks\nindirectly lost: 27 bytes in 2 blocks\npossibly lost: 2,040 bytes in 15 blocks\nstill reachable: 181,287 bytes in 104 blocks\nof which reachable via heuristic:\nstdstring          : 55 bytes in 1 blocks\nsuppressed: 0 bytes in 0 blocks\nLatest working version:\nhashcat (v3.10-131-g70811aa)\nBest regards\nZerBea\n. It's just timing.....\nRunning a bash script that walks through a folder containing single hccap files:\nfor HCCAP in ls\ndo\nhashcat -m 2500 -w 3 --remove --logfile-disable --potfile-disable --outfile-format=3 --outfile-autohex-disable --weak-hash-threshold=0 -o founds $HCCAP wordlist\ndone\nThen press s if this line appears\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nor press s shortly before hashcat ends.\nIf your timing is really good, hashcat will crash in thread 2.\nBest regards\nZerBea\n. I try'd again, using different commits:\nLast working version was hashcat (v3.10-131-g70811aa). This version won't crash.\nI'm able to crash all newer versions.\nWell, I need some runs, before I got the right timing.......\nI think, it's a verry small time gap in which you must press s. Maybe right in the moment, when a threat ceased.\nRight now I'm testing hashcat (v3.10-143-g7f59a82)....fresh install and everything cleaned\nand crashed it again (9729 Speicherzugriffsfehler  (Speicherabzug geschrieben))\n. You did it.\nRunning some testfiles using different hashtypes.\nThe leak is closed, hashcat (v3.10-144-gcecf747) is running fine......\nGood night\nZerBea\n. Hi Jens.\nI reopened this issue, because I think you didn't hit the bug exactly. I took a look into your patch and saw that it's just a work around the bug - \"but no direct hit\".\nThere must went something wrong during the initialization of hashconfig or hashes.\nVersions before hashcat (v3.10-144-gcecf747) crashed because of the memory leak.\nNow, under the same conditions (pressing s key shortly after start of hashcat) no status is displayed untill hashcat ends:\n [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\n [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\n [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nBest regards\nZerBea\n. Doesn't work as expected....\n1,520,000 bytes in 1 blocks are possibly lost in loss record 1,420 of 1,431\n   at 0x4C2BA4A: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n   by 0x46B3B5: mycalloc (memory.c:12)\n   by 0x41F7AC: dictstat_init (dictstat.c:32)\n   by 0x406346: main (hashcat.c:2061)\n33,554,432 bytes in 1 blocks are possibly lost in loss record 1,422 of 1,431\n   at 0x4C29BBE: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n   by 0x46B3FC: mymalloc (memory.c:26)\n   by 0x408D49: main (hashcat.c:3090)\n272,629,760 bytes in 1 blocks are possibly lost in loss record 1,431 of 1,431\n   at 0x4C29BBE: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n   by 0x46B3FC: mymalloc (memory.c:26)\n   by 0x47802F: opencl_session_begin (opencl.c:3870)\n   by 0x408A0C: main (hashcat.c:2953)\nInitialization issue still exists\n. Some additional infos:\ni7-3930K CPU @ 3.20GHz\nGTX 970\nArch Linux\nKernel 4.7.4\nnvidia 370.28\n. There are a few more memory leaks, mostly opencl-stuff related. But this leaks won't crash hashcat like the above mentioned ones.\n. Running some more tests.\nStatus attempts to read from free'd memory and hashcat crashes:\nThread 2:\nInvalid read of size 4\n   at 0x48F65F: status_display (status.c:502)\n   by 0x49270F: thread_keypress (terminal.c:94)\n   by 0x4E3C453: start_thread (in /usr/lib/libpthread-2.24.so)\n Address 0x10 is not stack'd, malloc'd or (recently) free'd\nProcess terminating with default action of signal 11 (SIGSEGV): dumping core\n Access not within mapped region at address 0x10\n   at 0x48F65F: status_display (status.c:502)\n   by 0x49270F: thread_keypress (terminal.c:94)\n   by 0x4E3C453: start_thread (in /usr/lib/libpthread-2.24.so)\n The main thread stack size used in this run was 8388608.\nHEAP SUMMARY:\n  in use at exit: 924,640,286 bytes in 17,924 blocks\n  total heap usage: 143,491 allocs, 125,567 frees, 1,513,980,355 bytes allocated\nLEAK SUMMARY:\n   definitely lost: 0 bytes in 0 blocks\n   indirectly lost: 0 bytes in 0 blocks\n   possibly lost: 1,944,872 bytes in 1,877 blocks\n   still reachable: 922,695,414 bytes in 16,047 blocks\n   of which reachable via heuristic:\n   stdstring          : 196 bytes in 6 blocks\n   suppressed: 0 bytes in 0 blocks\n. Running more tests hashcat (v3.10-146-g57195b4):\nUsing option \"--status --status-timer=5\" will not crash hashcat.\nUsing debug environment slows down the processing and the bug appears a lot less.\n. git reset --hard\n$ git pull\n$ make clean\n$ make uninstall\n$ make\n$ rm -rf $HOME/.hashcat\n$ rm -rf $HOME/.nv\n... running bash script\nfor HCCAP in ls\ndo\n    valgrind --leak-check=full hashcat -m 2500 -w 3 --remove --logfile-disable --potfile-disable --outfile-autohex-disable --outfile-format=3 -o found $HCCAP wordlist\ndone\n...\nwithout pressing s:\n1,520,000 bytes in 1 blocks are possibly lost in loss record 1,420 of 1,431\nat 0x4C2BA4A: calloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\nby 0x46B3B5: mycalloc (memory.c:12)\nby 0x41F7AC: dictstat_init (dictstat.c:32)\nby 0x406346: main (hashcat.c:2061)\n33,554,432 bytes in 1 blocks are possibly lost in loss record 1,422 of 1,431\nat 0x4C29BBE: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\nby 0x46B3FC: mymalloc (memory.c:26)\nby 0x408D49: main (hashcat.c:3090)\n272,629,760 bytes in 1 blocks are possibly lost in loss record 1,431 of 1,431\nat 0x4C29BBE: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\nby 0x46B3FC: mymalloc (memory.c:26)\nby 0x47802F: opencl_session_begin (opencl.c:3870)\nby 0x408A0C: main (hashcat.c:2953)\nhashcat won't crash\nif I press s at the right time, hashcat crashes.\nMy test hccaps and my test wordlist are always the same. I used them to test every new commit. So they must be ok, because they worked before.\n. I'll try and I already want to thank you for your effort.......\n. Looking good...\nHEAP SUMMARY:\nin use at exit: 858,458,346 bytes in 16,625 blocks\ntotal heap usage: 2,884,276 allocs, 2,867,651 frees, 2,766,023,145 bytes allocated\nLEAK SUMMARY:\n definitely lost: 37,698 bytes in 17 blocks\nindirectly lost: 283 bytes in 3 blocks\npossibly lost: 309,504,580 bytes in 1,246 blocks\nstill reachable: 548,915,785 bytes in 15,359 blocks\nof which reachable via heuristic:\nstdstring          : 55 bytes in 1 blocks\nsuppressed: 0 bytes in 0 blocks\nERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)\n. Fixed:\n0 = Cracked\n1 = Exhausted\n2 = Aborted\n. fixed.\nBest regards\nZerBea\n. Problem is solved.\nIt seems to be an arch specific problem (using makepkg and PKGBUILD on a cloned working folder).\nI did an rsync -av --exclude=\".\"  hashcat src\nto clone the sourcecode to a \"working folder called src \", but excluded \".\" and got the version info via\necho \"r$(git rev-list --count HEAD).$(git rev-parse --short HEAD)\" from the git cloned hashcat folder.\nTo get the correct version info hashcat requires compiling direct form a git clone because it reads the tag from git info\nVERSION_TAG             := $(shell test -d .git && git describe --tags --dirty=+ || echo \"$(VERSION_EXPORT)\"|cut -d, -f2|$(SED) -r 's|.* (\\w+/)?([^ ]+)|\\2|')\nWell, compiling from a source folder without git info, results in an empty string......\nhashcat -V\normat:%D$\n. ./hashcat -I\nhashcat (v3.10-800-g7ca6a45) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : NVIDIA Corporation\n  Name    : NVIDIA CUDA\n  Version : OpenCL 1.2 CUDA 8.0.0\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : GeForce GTX 970\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 13\n    Clock          : 1228\n    Memory         : 1016/4065 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 375.20\n. ./clinfo:\nNumber of platforms                               1\n  Platform Name                                   NVIDIA CUDA\n  Platform Vendor                                 NVIDIA Corporation\n  Platform Version                                OpenCL 1.2 CUDA 8.0.0\n  Platform Profile                                FULL_PROFILE\n  Platform Extensions                             cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts\n  Platform Extensions function suffix             NV\nPlatform Name                                   NVIDIA CUDA\nNumber of devices                                 1\n  Device Name                                     GeForce GTX 970\n  Device Vendor                                   NVIDIA Corporation\n  Device Vendor ID                                0x10de\n  Device Version                                  OpenCL 1.2 CUDA\n  Driver Version                                  375.20\n  Device OpenCL C Version                         OpenCL C 1.2 \n  Device Type                                     GPU\n  Device Profile                                  FULL_PROFILE\n  Device Topology (NV)                            PCI-E, 01:00.0\n  Max compute units                               13\n  Max clock frequency                             1228MHz\n  Compute Capability (NV)                         5.2\n  Device Partition                                (core)\n    Max number of sub-devices                     1\n    Supported partition types                     None\n  Max work item dimensions                        3\n  Max work item sizes                             1024x1024x64\n  Max work group size                             1024\n  Preferred work group size multiple              32\n  Warp size (NV)                                  32\n  Preferred / native vector sizes               \n    char                                                 1 / 1     \n    short                                                1 / 1     \n    int                                                  1 / 1     \n    long                                                 1 / 1     \n    half                                                 0 / 0        (n/a)\n    float                                                1 / 1     \n    double                                               1 / 1        (cl_khr_fp64)\n  Half-precision Floating-point support           (n/a)\n  Single-precision Floating-point support         (core)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  Yes\n  Double-precision Floating-point support         (cl_khr_fp64)\n    Denormals                                     Yes\n    Infinity and NANs                             Yes\n    Round to nearest                              Yes\n    Round to zero                                 Yes\n    Round to infinity                             Yes\n    IEEE754-2008 fused multiply-add               Yes\n    Support is emulated in software               No\n    Correctly-rounded divide and sqrt operations  No\n  Address bits                                    64, Little-Endian\n  Global memory size                              4263182336 (3.97GiB)\n  Error Correction support                        No\n  Max memory allocation                           1065795584 (1016MiB)\n  Unified memory for Host and Device              No\n  Integrated memory (NV)                          No\n  Minimum alignment for any data type             128 bytes\n  Alignment of base address                       4096 bits (512 bytes)\n  Global Memory cache type                        Read/Write\n  Global Memory cache size                        212992\n  Global Memory cache line                        128 bytes\n  Image support                                   Yes\n    Max number of samplers per kernel             32\n    Max size for 1D images from buffer            134217728 pixels\n    Max 1D or 2D image array size                 2048 images\n    Max 2D image size                             16384x16384 pixels\n    Max 3D image size                             4096x4096x4096 pixels\n    Max number of read image args                 256\n    Max number of write image args                16\n  Local memory type                               Local\n  Local memory size                               49152 (48KiB)\n  Registers per block (NV)                        65536\n  Max constant buffer size                        65536 (64KiB)\n  Max number of constant args                     9\n  Max size of kernel argument                     4352 (4.25KiB)\n  Queue properties                              \n    Out-of-order execution                        Yes\n    Profiling                                     Yes\n  Prefer user sync for interop                    No\n  Profiling timer resolution                      1000ns\n  Execution capabilities                        \n    Run OpenCL kernels                            Yes\n    Run native kernels                            No\n    Kernel execution timeout (NV)                 No\n  Concurrent copy and kernel execution (NV)       Yes\n    Number of async copy engines                  2\n  printf() buffer size                            1048576 (1024KiB)\n  Built-in kernels                              \n  Device Available                                Yes\n  Compiler Available                              Yes\n  Linker Available                                Yes\n  Device Extensions                               cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts\nNULL platform behavior\n  clGetPlatformInfo(NULL, CL_PLATFORM_NAME, ...)  NVIDIA CUDA\n  clGetDeviceIDs(NULL, CL_DEVICE_TYPE_ALL, ...)   Success [NV]\n  clCreateContext(NULL, ...) [default]            Success [NV]\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CPU)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_GPU)  No platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ACCELERATOR)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_CUSTOM)  No devices found in platform\n  clCreateContextFromType(NULL, CL_DEVICE_TYPE_ALL)  No platform\nICD loader properties\n  ICD loader Name                                 OpenCL ICD Loader\n  ICD loader Vendor                               OCL Icd free software\n  ICD loader Version                              2.2.9\n  ICD loader Profile                              OpenCL 2.1\n. During startup of hashcat I got this 2 warnings:\nnvmlDeviceSetPowerManagementLimit(): Insufficient Permissions\nXNVCTRLQueryTargetAttribute(NV_CTRL_GPU_COOLER_MANUAL_CONTROL) failed\nThen hashcat runs awhile\n...\nTime.Started.......: Tue Nov 22 09:41:38 2016 (48 secs)\nTime.Estimated...: Tue Nov 22 09:42:37 2016 (11 secs)\n...\nand crashed\nX Error of failed request:  BadValue (integer parameter out of range for operation)\n  Major opcode of failed request:  156 (NV-CONTROL)\n  Minor opcode of failed request:  3 ()\n  Value in failed request:  0x17\n  Serial number of failed request:  15\n  Current serial number in output stream:  16\nBest regards\nZerBea\n. Installation is arch minimal xfce desktop.\nHashcat is not running via ssh.\nHashcat is able to connect and query X11.\nHashcat v3.10-800-g7ca6a45 runs awhile and crashed.\nTest conditions v3.10-756-g1c82cc9 <->  v3.10-800-g7ca6a45 are the same, each on a clean system.\nI'll go back in git history to see which commit causes the issue.\n. Everything is fine up to version v3.10-796-g9e1574a\nVersion v3.10-797-g06c1d4a and above crashed.. No more crash, but\nFirst run:\n./hashcat -m 2500 --benchmark\nhashcat (v3.10-801-gfe3398f) starting...\nXNVCTRLQueryTargetAttribute(NV_CTRL_GPU_COOLER_MANUAL_CONTROL) failed\nX Error of failed request: BadValue (integer parameter out of range for operation)\nMajor opcode of failed request: 156 (NV-CONTROL)\nMinor opcode of failed request: 3 ()\nValue in failed request: 0x17\nSerial number of failed request: 15\nCurrent serial number in output stream: 16\nSecond run:\n./hashcat -m 2500 --benchmark --gpu-temp-disable\nhashcat (v3.10-801-gfe3398f) starting in benchmark mode...\nnvmlDeviceSetPowerManagementLimit(): Insufficient Permissions\nOpenCL Platform #1: NVIDIA Corporation\nDevice #1: GeForce GTX 970, 1016/4065 MB allocatable, 13MCU\nHashtype: WPA/WPA2\nSpeed.Dev.#1.....: 172.9 kH/s (76.77ms)\nStarted: Tue Nov 22 17:09:14 2016\nStopped: Tue Nov 22 17:09:21 2016\n\nusing --gpu-temp-disable and everything works......\nMaybe a variable exceeded....\n. arch is using xorg.conf.d:\n20-nvidia.conf :\nSection \"Device\"\n    Identifier     \"Device0\"\n    Driver         \"nvidia\"\n    VendorName     \"NVIDIA Corporation\"\n    Option         \"NoLogo\" \"1\"\n    Option         \"Interactive\" \"False\"\nEndSection\n. Fixed....\nWell done.\nBest regards\n. Fixed.....\nTestfile doesn't contain \"words to be rejected\".\n. Both issues fixed.\nBest regards\nZerBea\n. For 2) seems to work not like expected.....\nhashcat\nSession..........: hashcat                              \nStatus...........: Exhausted\nHash.Type........: WPA/WPA2\nHash.Target......: test.hccap\nTime.Started.....: Wed Dec 21 08:46:34 2016 (4 mins, 45 secs)\nTime.Estimated...: Wed Dec 21 08:51:19 2016 (0 secs)\nInput.Base.......: File (testlist)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   158.1 kH/s (16.56ms)\nRecovered........: 0/537 (0.00%) Digests, 0/536 (0.00%) Salts\nProgress.........: 45209456/45209456 (100.00%)\nRejected.........: 81472/45209456 (0.18%)\nRestore.Point....: 84346/84346 (100.00%)\nCandidates.#1....: (*#&)&)()) -> zzkcorcipe420\nHWMon.Dev.#1.....: Temp: 75c Fan: 56% Util:100% Core:1277Mhz Mem:3004Mhz Lanes:16\nStarted: Wed Dec 21 08:46:30 2016\nStopped: Wed Dec 21 08:51:21 2016\njohn\nDevice 0: GeForce GTX 970\nLocal worksize (LWS) 64, global worksize (GWS) 1048576\nLoaded 537 password hashes with 537 different salts (wpapsk-opencl, WPA/WPA2 PSK [PBKDF2-SHA1 OpenCL])\nNote: minimum length forced to 8\nPress 'q' or Ctrl-C to abort, almost any other key for status\n0g 0:00:00:01 DONE (2016-12-21 08:51) 0g/s 54672p/s 30452Kc/s 30452KC/s GPU:64\u00b0C util:96% fan:48% \nSession completed\ntestfile: 537 different ap's using the same essid\nhashcat:     158.1 kH/s\njohn......: 30452 Kc/s\nRemarks:\nPlease don't wonder about the difference digest / salts.\nIn one set I switched ap and client to see how the progs will act...\nBest regards\nZerBea\n. Looking good (and faster than john...)\nSession..........: hashcat                              \nStatus...........: Exhausted\nHash.Type........: WPA/WPA2\nHash.Target......: test.hccap\nTime.Started.....: Thu Dec 22 07:58:30 2016 (1 sec)\nTime.Estimated...: Thu Dec 22 07:58:31 2016 (0 secs)\nInput.Base.......: File (testliste)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   145.3 MH/s (16.32ms)\nRecovered........: 0/537 (0.00%) Digests, 0/536 (0.00%) Salts\nProgress.........: 45209992/45209992 (100.00%)\nRejected.........: 81472/45209992 (0.18%)\nRestore.Point....: 84347/84347 (100.00%)\nCandidates.#1....: (*#&)&)()) -> zzkcorcipe420\nHWMon.Dev.#1.....: Temp: 46c Fan: 33% Util: 83% Core:1303Mhz Mem:3004Mhz Lanes:16\nStarted: Thu Dec 22 07:58:27 2016\nStopped: Thu Dec 22 07:58:32 2016\nIt was purely coincidental that I did this test.\nDuring the past weekend I did a refactroring of my programm\nand decided to run some tests using hashcat and john.\nDuring this test I found that bug. I didn't noticed that bug previously.\nBy this way, please stay using C (#511).....\nBoth, c and asm are fine. I'm to old to use c++ or c#......lol\nAgain, well done.....\np.s. I don't like binaries........lol\n. No problem for me. I use PKGBUILD....... Send you a pm........ Candidates.#1....: ~!@#$%^&* -> ZZZZZZZZZZ\n. So all founds on the same essid must be in a row.......\nbut they didn't.. It works on small hccap's < 100\nbut my test files a really big ....\nOk, I stay tuned......\n. Right now, I do a presort on the essid and run hashcat on this presorted hccap's.\nSpeed is above 179 M!\n. Maybe the idea of sorting by length of essid is not a good idea.\nIt could be a better way to sort by alphabetical order..... Well done. Now everything works like expected.\nAgain faster then john.........\nThe test file is one of my smallest.......\n. same behavior on hashcat (v3.30-65-g518983d3):\nfound.list: No such file or directory. Thank you for this information.\nIndeed I was very surprised, because if I use a very, vey small wordlist (only wordlistattack with tis testfile), speed is everytime obove 160 MH/s.\nNow I understand......\nBest Regards\n. Hi.\n1) title edited\n   I noticed the difference between pot and outputfile. I only use the outputfile for automated analyses.\n  (because the pot is \"owned\" by hashcat only....)\n2) please do not missunderstand me. That was only a remark, and not a bug report\n    (I don't use cap2hccapx - wrote my own tool instead.....)\n3) shall I open a new issue for this? It's only an idea of me.....\n4) example is on it's way to your pm\nIf you need more examples - please let me know....\n. Well, it's no longer a feature, it's a bug.\nI've send you a pm which contains a hccapx and the concomitant cap which is able to destroy the format of the pot and the -o output file.\nBest regards\nZerBea\n. Well, that's no problem, but the file is realy big. The dumps are downloaded from various sites of the www. So please give me a pm  (at) hashcat.net to send to....\nChecked my mails (jens got my pm address), nothing in there.....\nThe command was every time the same:\nhashcat -m 2500 -w 3 --remove --logfile-disable --potfile-path=$HOME/test/Potfiles/hashcat.pot --outfile-autohex-disable --outfile-format=2 -o $HOME/test/founds $HOME/test/test.hccapx $HOME/test/wordlist\nSame test.hccapx, same hashcat.pot, same wordlist\nFirst run:\nINFO: Removed 76018 hashes found in potfile\nSecond run (every time 264 hashes removed):\nINFO: Removed 264 hashes found in potfile\nThird run (every time 1 hash removed):\nINFO: Removed 1 hash found in potfile\nWell, it seems that hasccat doesn't remove all the founds in pot during the first run.\nhccapxinfo -i test.hccapx -I\nshows\n1286885 records readed from test.hccapx\nhccapx information:\ntotal.hashes.............: 1286885\nunique.nets..............: 94165\nunique.essids............: 71670\nunique.key.mics..........: 285292\nfalse.essids.............: 0\nfalse.nonces.............: 0\nfalse.eap.len............: 0\nkeytype.wpa1.............: 28457\nfalse.keytypes.wpa1......: 0\nkeytype.wpa2.............: 1258428\nfalse.keytypes.wpa2......: 0\neap.4way.type1...........: 0\neap.4way.type2...........: 1282932\neap.4way.type3...........: 0\neap.4way.type4...........: 3953\nWell, the file contains many, many duplicates (doing a cat *.hccapx > test.hccapx isn't such a good idea - but that's the recommended way -> hashcat wiki). On the other hand such a file is very usefull, to explore the boundaries of hashcat....\nWell, I didn't realyze that jsteube expects a bug report (cap2hccapx). But that's no problem, I can do it, if you want. And I can send you my own tools (c-source).\nThe M1+M4 / M3+M4 problem (cap2hccapx) isn't such a big problem, as you the see in the output of hccapxinfo above. Only 3953 hashes of that type dumped....\nThere is also no real need to expand the contence of the authenticated field, because the infos can be gathered from the eapol frame. On the other hand, if there is such a field, why don't we use it in the best manner....\nThat's why I didn't make a bug report.\nBest regards\nZerBea\n. Very strange......\nNo emails, nothing in spam...\nput you now in white list....\nMaybe gmx didn't accept mails from hashcat.net generally????\nPlease try again.\n. Send you a pm containing the testfiles....\nThree parts of 7z archive. None incoming mails. Could it be, that gmx blocked hashcat?. Never used freenode bevor, Must do some investigations how to use it....... on pidgin\n. Ok, works using pidgin....... Again great job.\nWorks like a charm...\nbest regards\nZerBea. Great. I hope that upcomming cap2hccapx converters use this agreement to.\nSo we will get no longer uncontrolled hccapx files in www :)\nThanks again......\n. Not fixed using v3.30-374-gc47f9d4b\nSpeed.Dev.#1.....:   166.9 kH/s (4.88ms)\n. Yes, and no....\nOk. If there are non-cracking hashes inside, it works like you mentioned.\nBut if there is only 1 cracked hash inside, speed will drop and stay on this level......\nLet's say, you have 100 different ap's inside the hccapx, using the same essid called \"default\" and\nthe used word list is about 1 GB.\nThe password for ten ore more ap's is them same \"12345678\"\nSpeed drops from 10 minutes to a day..... \nIf you have a theoretically successrate obove 50 % and many ap's, using the same essid and the same easy pw's, this case happens very often.....\n. No problem. I'll do some complete runs.....\nIt will take a time.....\n. First run:\nv3.30-374-gc47f9d4b\nHashes: 6050728 digests; 146376 unique digests, 146376 unique salts\nSmall wordlist (21197 words)\nall non-cracked\nIt seems to be ok, speed varies from 164.9 kH/s upt to 179 M/s.....\nv3.30-372-gd431874c was constant on ~ 166 kH/s. First run complete:\nStarted: Tue Feb 28 11:06:51 2017\nStopped: Tue Feb 28 11:24:43 2017\n. Second run:\nv3.30-356-g3fb433de (old version)\nStarted: Tue Feb 28 11:26:57 2017\nStopped: Tue Feb 28 11:44:59 2017\nSo far, so good.....\n. Third run:\nv3.30-374-gc47f9d4b\nwe replace 905 not found pw's by found pw's in our wordlist.....\npasswords are picked up randomly......\nStarted: Tue Feb 28 12:11:02 2017\nStopped: Tue Feb 28 12:29:30 2017\nAs you can see, already in this simple case we lose half a minute against the first run (17: 52 vs 18:28).\nThat means, the better the success rate the slower hashcat (that's a big time loss and it behaves like an e-function....).\n. Indeed, it's not a big problem and of course it's ok....\nMan can do some presorting and everything will be fine.\nI'll close this issue, because your fix did it (v3.30-374-gc47f9d4b). It works much better than v3.30-372-gd431874c.....\nAgain, great job, thank you for your effort.. Correct.\nWe are able to do weak point analysis using hccapx files. It's important to know, whether replaycount was disregarded or not, since hashcat had a build in anonce-corr.\nWell, it's not a big change in hashcat, but should be laid down in hccapx structure/format...\nBest regards\nZerBea. Thank you for the info. I know that the code is working well. It was just an information that there are some gcc warnings using the default options of gcc 7.1.1.\nBest regards\nMike\n. Well, it's a good idea to silence the warning, before gcc 7.1.1 reaches UBUNTU.\n. It's the default compiler on arch\nhttps://www.archlinux.org/packages/core/x86_64/gcc/\nand it's a major release, containing new features (as well as many other improvements) relative to GCC 6.x.\nhttps://gcc.gnu.org/gcc-7/\n. Seems to be working on other distro's:\nhttps://www.archlinux.org/packages/community/x86_64/hashcat/\nCheers\nZerBea\n. Well done.\nWorking like a charm.\nThank's\nZerBea. Please add uncleaned cap an password for included handshake.\nwpa_supplicant is able to handle this (wpa_supplicant.conf):\nkey_mgmt: list of accepted authenticated key management protocols\nWPA-PSK = WPA pre-shared key (this requires 'psk' field)\nWPA-EAP = WPA using EAP authentication\nIEEE8021X = IEEE 802.1X using EAP authentication and (optionally) dynamically\ngenerated WEP keys\nNONE = WPA is not used; plaintext or static WEP could be used\nWPA-PSK-SHA256 = Like WPA-PSK but using stronger SHA256-based algorithms\nWPA-EAP-SHA256 = Like WPA-EAP but using stronger SHA256-based algorithms\nIf not set, this defaults to: WPA-PSK WPA-EAP\n. Please add also the PBKDF2_HMAC_SHA256 plainmasterkey (PMK)\nor check if  wlangenpmk -e essid -p password is able to calculate the correct PMK\nhttps://github.com/ZerBea/hcxkeys\n. I did an analyse on the cap file.\nThe bad news:\nNeither the compare kernel nor the pbkdf kernel will work on this file.\nWe need a new compare kernel and a new PBKDF2-HMAC_SHA256 Kernel.\nThat means: hash-modes 2500 and 2501 will not work.\nThe good news:\nAction-, NULL- and 802.11 Block - Frames are transmitted unencrypted.\nWe are able to jam/spoof this frames.\nWe are able to detect 802.11w\nAuthentication Key Mangement bits are set in Beacon-, Proberequest-, Proberesponse-,\nAuthentication-, Association- and Reassociation-Frames:\nIeee8021 PSK (SHA256)\nManagement Frame Protection Required = TRUE\nManagement Frame Protection Capable = TRUE\nbits 1 and 2 are set in the Key Information Field of the EAP frame\nthat means.: AES Cipher, AES-128-CMAC MIC is used\ninstead of...: AES Cipher, HMAC-SHA1 MIC on wpa2\nor................: RC4 Cipher, HMAC-MD5 MIC on wpa1\nInformation on AES-128-CMAC\nhttps://tools.ietf.org/html/rfc4493\nhttp://dx.doi.org/10.6028/NIST.SP.800-38B-2005\nSample c-source (libopenssl):\nhttps://gist.github.com/ecerulm/90653daf2b808aea0837\n. Good news.\nWe are able to reproduce the algo:\nPMK for the hash is:\nfb57668cd338374412c26208d79aa5c30ce40a110224f3cfb592a8f2e8bf53e8\nPTK for the hash is:\n2c76dc592c3b671bac230f6c9e38a062a0ddc98f4ab4d6129022fc7f45fe9264\nAES-MIC for the hash is:\n2e13c40ca1c2e4e2037f99a2da18a46b\nthe following algos are used:\nfor calculating the PTK;\nsha256_prf(pmk, 32, \"Pairwise key expansion\", pkedata, 76, ptk, 48);\nthe calculation of PKE is different to PRF-SHA1.\nfor calculating the MIC:\nomac1_aes_128(ptk, zeigerhcx->eapol, zeigerhcx->eapol_len, mic);\nSource sha256_prf:\nhttps://github.com/digsrc/wpa_supplicant/blob/master/src/crypto/sha256-prf.c\nSource omac1_aes_128:\nhttps://github.com/digsrc/wpa_supplicant/blob/master/src/crypto/aes-omac1.c\nwe should keep in mind that there is another algo:\nsha384_prf, used in IEEE8021X_SUITE_B_192\nSource sha384_prf:\nhttps://github.com/digsrc/wpa_supplicant/blob/master/src/crypto/sha384-prf.c\n. Well, you're right. Indeed, it's implemented pretty much nowhere.\nBut IEEE8021X_SUITE_B and IEEE8021X_SUITE_B_192 are part of wpa_supplicant (and hostapd (?)).\nI found this during my analyse of wpa_supplicant and in the RFC 4868 documentation.\nThe implementation of PRF-256 works pretty good in cpu mode. After long, long talks with atom this weekend, we are now able to crack your hash.\nThe calculation of the PTK is different to PRF-SHA1 (atom found this), because my RFC-conform implementation wasn't able to calculate the correct PTK.\nI did allready an update on hcxtools to convert AES128 CMAC hashes to a separate hccapx for hashcat's upcoming hash-mode 15800 (wlancap2hcx -O option).\n. What are we talking about:\nWPA2 keyver 3 AES128-CMAC (this issue here)\nor\nWPA3 (will use Dragonfly - new feature request) \nThe Dragonfly protocol is specified in RFC 7664. It will use Diffie Hellman (DH) key exchange (implemented in WPS key exchange).\nTherefore we need a complete new attack (hcxtools) and a complete new hashmode for hashcat.\nBut first let's take a look at the first words of http://www.mathyvanhoef.com:\n\"The Wi-Fi Alliance made a press release where it announced WPA3. Unfortunately, this did not include many technical details. Nevertheless, we'll interpret the press release from a technical perspective. In particular, it mentions WPA3 will include four major new security features:\"\nMaybe it could be a good idea to wait for the final implementation.....\n. As you said:\nhashcat (v3.6.0-295-gc68191e4) running fine.\nhashcat (v3.6.0-296-g344d1a37) is the \"troublemaker\".\n. Here it goes:\nrunning hashcat from /usr/bin:\nhashcat (v3.6.0-296-g344d1a37) starting in restore mode...\nChanging current working directory to '/home/zerobeat/temp/stanev'\n/usr/bin/OpenCL/: No such file or directory\n==32600== Invalid free() / delete / delete[] / realloc()\n==32600==    at 0x4C2D16B: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AC14: hcfree (memory.c:75)\n==32600==    by 0x130D04: folder_config_init (folder.c:438)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\n==32600==  Address 0x5676550 is 0 bytes inside a block of size 4,096 free'd\n==32600==    at 0x4C2D16B: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AC14: hcfree (memory.c:75)\n==32600==    by 0x130CF5: folder_config_init (folder.c:437)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\n==32600==  Block was alloc'd at\n==32600==    at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AAB5: hcmalloc (memory.c:26)\n==32600==    by 0x130AC4: folder_config_init (folder.c:347)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\n==32600== \n==32600== Invalid free() / delete / delete[] / realloc()\n==32600==    at 0x4C2D16B: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AC14: hcfree (memory.c:75)\n==32600==    by 0x130D22: folder_config_init (folder.c:440)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\n==32600==  Address 0x5676550 is 0 bytes inside a block of size 4,096 free'd\n==32600==    at 0x4C2D16B: free (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AC14: hcfree (memory.c:75)\n==32600==    by 0x130CF5: folder_config_init (folder.c:437)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\n==32600==  Block was alloc'd at\n==32600==    at 0x4C2BE7F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)\n==32600==    by 0x19AAB5: hcmalloc (memory.c:26)\n==32600==    by 0x130AC4: folder_config_init (folder.c:347)\n==32600==    by 0x1B79C3: read_restore (restore.c:174)\n==32600==    by 0x1B8055: restore_ctx_init (restore.c:343)\n==32600==    by 0x132C79: hashcat_session_init (hashcat.c:980)\n==32600==    by 0x10FCF2: main (main.c:1033)\nPKGBUILD:\n....\nbuild() {\n    cd \"$startdir\"\n    rsync -av --delete $_pkgname/ src\n    cd \"$srcdir\"\n    make clean\n    make PREFIX=/usr DEBUG=1\n}\npackage() {\n    cd \"$srcdir\"\n    install -d \"${pkgdir}/usr/share/hashcat/\"\n    install -d \"${pkgdir}/usr/share/doc/hashcat/\"\n    cp -ar charsets OpenCL masks rules hashcat.hcstat2 hashcat.hctune \"${pkgdir}/usr/share/hashcat/\"\n    cp -ar docs/* \"${pkgdir}/usr/share/doc/hashcat/\"\ninstall -Dm755 libhashcat.so \"${pkgdir}/usr/lib/libhashcat.so\"\ninstall -Dm755 hashcat \"${pkgdir}/usr/bin/hashcat\"\n\n}\n....\n. I think the problem is located here (restore.c):\nconst char *shared_folder  = NULL;\n+\n+    #if defined (INSTALL_FOLDER)\n+    install_folder = INSTALL_FOLDER;\n+    #endif\n+\n+    #if defined (SHARED_FOLDER)\n+    shared_folder = SHARED_FOLDER;\n+    #endif\nand hc searches for OpenCL in /usr/bin\ninstead of /usr/share/hashcat/\nShould be no real problem, as I can define the shared folder in PKBUILD,\nbut that's only \"a quick and dirty solution\".\nCheers\nMike. That sounds good. I didn't see this. I noticed only the override in restore.c\nWell, good to hear that the PKGBUILD is not the cause.. working like a charm.\nThank you. additionally  to first request:\nhcxtools would like to use also bit 4 of the message_pair field to indicate an ap-less attack:\nbitmask for message_pair field:\n0: MP info\n1: MP info\n2: MP info\n3: x (unused)\n4: ap-less attack (set to 1) - no nonce-error-corrections neccessary\n5: LE router detected (set to 1) - nonce-error-corrections only for LE neccessary\n6: BE router detected (set to 1) - nonce-error-corrections only for BE neccessary\n7: not replaycount checked (set to 1) - replaycount not checked, nonce-error-corrections definitely neccessary\nusing bit 4 to 7, hcxtools are able to interact with hascat - that will increase speed for hashcat.\n. Confirmed, what you calculated, Atom:\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nhccapx contains only one handshake (M1M2 and M2M3 of the same authentication sequence):\n$ wlanhcxinfo -i 15786_1494403569.hccapx -a -e -s -A -S -p -M\n00256986b933:2194d028d04504baf38ea3c55bdac012f728c84ee4dba86a98a35259121f6573:88a73c8ec0f5:3e6bcf4f9d39d1a0cd8de83ecfd8bea46ee1f71add7239e56a33e42ef8c9e74d:eb73ba9864817398f817bf18a7c1d10c:00:vodafone28C6_2\n00256986b933:2194d028d04504baf38ea3c55bdac012f728c84ee4dba86a98a35259121f6573:88a73c8ec0f5:3e6bcf4f9d39d1a0cd8de83ecfd8bea46ee1f71add7239e56a33e42ef8c9e74d:eb73ba9864817398f817bf18a7c1d10c:02:vodafone28C6_2\nPlease attach the uncleaned cap file to do deep analysis.\n. Thanks.\ncap was converted correct.\nM2 was used for EAPOL frame\nM1 and M3 for  anonce.\nCorrect PSK is 14 04 1977\nCorrect PMK is: b36955550a93803539a509e6491e3510653f556d7c533faa13648622ff3e117a\nI can't see an issue in hashcat.\n-m 2500 an -m 2500 calculating correct result.\nYou need to check your potfile entries.\n. Very strange:\ncat fechasdenacimiento.txt | hashcat -m 2500 15786_1494403569.hccapx\nhashcat (v4.1.0-5-g4bd82dd2) starting...\nStarting attack in stdin mode...\ndc15d27e43bf34fca77d3665d8182121:00256986b933:88a73c8ec0f5:vodafone28C6_2:14 04 1977\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: vodafone28C6_2 (AP:00:25:69:86:b9:33 STA:88:a7:3c:8e:c0:f5)\nTime.Started.....: Sat Mar  3 23:48:40 2018 (1 sec)\nTime.Estimated...: Sat Mar  3 23:48:41 2018 (0 secs)\nGuess.Base.......: Pipe\nSpeed.Dev.#1.....:   502.3 kH/s (3.71ms) @ Accel:32 Loops:16 Thr:1024 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 526008\nRejected.........: 30906\nRestore.Point....: 0\nCandidates.#1....: 01011930 -> 31122030\nHWMon.Dev.#1.....: Temp: 52c Fan: 33% Util: 99% Core:1771MHz Mem:5005MHz Bus:16\nStarted: Sat Mar  3 23:48:37 2018\nStopped: Sat Mar  3 23:48:42 2018\nworking as expected\n. Why do we need another package manager? Every distribution has it's own (working package management system):\nhttp://kmkeen.com/maintainers-matter/. That is correct and it is neither a hashcat issue, nor a hcxtools/hcxdumptool issue. wifite2 added some \"new (state of the art)\" tools like hashcat, hcxtools and hcxdumptool. You must install them!\nRead more about this new wifite2 features here:\nhttps://github.com/derv82/wifite2\n. Please add a the pcapng file. If possible with a complete handshake, too.\n. 1) The password is not in your wordlist\n2) Way too much aircrack stuff inside your commands\n    Do not use aircrack tools and scripts in combination with hcxtools / hcxdumptool!\nLog:\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA-PMKID-PBKDF2\nHash.Target......: 8ea0f2915aa3f7a7d23aeca2001dae062c56dc54e2385ccf7...747479\nTime.Started.....: Mon Nov  5 10:29:01 2018 (5 mins, 35 secs)\nTime.Estimated...: Mon Nov  5 10:34:36 2018 (0 secs)\nGuess.Base.......: File (hashes.org-2017.txt)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#1.........:   405.9 kH/s (60.12ms) @ Accel:256 Loops:64 Thr:256 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 163595622/324023281 (50.49%)\nRejected.........: 27805030/163595622 (17.00%)\nRestore.Point....: 161485043/324023281 (49.84%)\nRestore.Sub.#1...: Salt:0 Amplifier:0-1 Iteration:0-1\nCandidates.#1....: gjghgf75 -> grapepocke\nHardware.Mon.#1..: Temp: 83c Fan: 71% Util:100% Core:1708MHz Mem:5005MHz Bus:16\n. @PcBlackbelt\nTo understand how the filterlist works, please read this:\nhttps://hashcat.net/forum/thread-7929-post-42699.html#pid42699\n. Hi magnum.\nAre you sure, we need an additional ESSID len field in the new hash line?\nFor example:\n * 6d6167006e756d * \nThe parser must do a validity check\n1: count characters between the 2 stars: 14\n2: ESSID len = chars /2\n3: Do we have hex values (%2 ==0) and are they valid (0..9, a..f, A..F)\nIt's similar to the 16800 hash line ESSID (which doesn't contain an ESSID len field).\n. ESSID \nThese SSIDs can be zero to 32 octets (32 bytes) long. \nThe 802.11 standards prior to the 2012 edition did not define any particular encoding/representation for SSIDs, which were expected to be treated and handled as an arbitrary sequence of 0\u201332 octets that are not limited to printable characters. The IEEE 802.11-2012 defines a tag that the SSID is UTF-8 encoded and when interpreting could contain any non-ISO basic Latin characters within it. Wireless network stacks must still be prepared to handle arbitrary values in the SSID field.\nThat is a good reason to use hex values instead of trying to convert an ESSID to printable characters in hash lines.\nEAPOL - we should allow oversized EAPOL len. Found this ones during wpa-sec analysis:\n256, 258, 262, 270, 278, 288, 294, 306, 310, 322, 326, 330, 334,  342, 358, 370, 374, 386, 390, 406, 422, 438, 484, 500, 502, 510\n$ hcxpcaptool -V --eapol-out=eapols caparchiv/2018*\n$ cat eapols | awk 'BEGIN { FS = \":\" } ; { print $NF }' | awk '{print length}' | sort | uniq\nBTW:\nI'm preparing to implement more analysis options to hcxtools. \nCONTROL FIELD:\nRight now we use pcapng comment field to parse additional informations from attacker/dumper to the conversion tool.\nIt would be great if we can use a CONTROL FIELD to parse additional informations from the conversion tool to the hash cracker.\nattack/dumptool --pcapng--> conversion tool --control field--> hash cracker\nAnd it would be awesome if we can use the potfile to parse additional information from hash cracker to the data base (but this will we another proposal: improved potfile line): \nattack/dumptool --pcapng--> conversion tool --control field--> hash cracker  --potfile--> data base\nThan, to complete the WPAx cycle,  we can think about a feed back from the data base to the attacker/ dumper:\ndata base --xxxxx--> attack/dumptool\n. We have no additional field for MIC and key ver, because we can retrieve them from EAPOL,\nas well as the length.\nPlease keep  in mind that we must expect more than the the allready implemented length:\nPMK_LEN_MAX 64 (32, as yet)\nWPA_EAPOL_KEY_MIC_MAX_LEN 32 (16, as yet)\nAlso please notice, that we have a new key descriptor value (0=AKM-defined instead of 1=wpa1, 2=wpa2 , 3=wpa2 key ver 3) on AKM-defined handshakes.\nExampel is here:\nhttps://hashcat.net/forum/thread-7717-post-42759.html#pid42759\nRight now hcxpcaptool will set this value to 3 (AES-128-CNC), so that hashcat is able to run hash mode 2501 on that handshakes (currently that works on SAE, but it's a really, really ugly hack). In future times we can use the control field to parse AKM-defined data to the cracker.\n. These are the 2 structs for an authentication frame and a wpa-key frame:\nstruct eapauthentication_frame\n{\n uint8_t    version;\n uint8_t    type;\ndefine EAP_PACKET 0\ndefine EAPOL_START 1\ndefine EAPOL_LOGOFF 2\ndefine EAPOL_KEY 3\ndefine EAPOL_ASF 4\ndefine EAPOL_MKA 5\nuint16_t   len;\n uint8_t    data[1];\n} attribute((packed));\ntypedef struct eapauthentication_frame eapauth_t;\ndefine EAPAUTH_SIZE offsetof(eapauth_t, data)\nstruct wpakey_frame\n{\n uint8_t    keydescriptor;\n uint16_t   keyinfo;\n uint16_t   keylen;\n uint64_t   replaycount;\n uint8_t    nonce[32];\n uint8_t    keyiv[16];\n uint64_t   keyrsc;\n uint8_t    keyid[8];\n uint8_t    keymic[16];\n uint16_t   wpadatalen;\n uint8_t    data[1];\n} attribute((packed));\ntypedef struct wpakey_frame wpakey_t;\ndefine WPAKEY_SIZE offsetof(wpakey_t, data)\nSo it's easy to lay the struct over the EAPOL frame, using bash commands.\nLet's take the example from above and get EAPOL data:\n$ hcxpcaptool -V sae4way.pcapng --eapol-out=example\nreading from sae4way.pcapng\nsummary:                                      \nfile name....................: sae4way.pcapng\nfile type....................: pcapng 1.0\nfile hardware information....: x86_64\nfile os information..........: Linux 4.18.16-arch1-1-ARCH\nfile application information.: hcxdumptool 5.0.0\nnetwork type.................: DLT_IEEE802_11_RADIO (127)\nendianess....................: little endian\nread errors..................: flawless\npackets inside...............: 15\nskipped packets..............: 0\npackets with GPS data........: 0\npackets with FCS.............: 0\nbeacons (with ESSID inside)..: 1\nprobe requests...............: 1\nprobe responses..............: 1\nassociation requests.........: 1\nassociation responses........: 1\nauthentications (SAE)........: 4\nEAPOL packets................: 7\nEAPOL PMKIDs.................: 1\nbest handshakes..............: 1 (ap-less: 0)\nNow let's get the MICs:\n$ cat example | cut -c 189-220\nc652368806f943802f8f57789e1a20d1\n60e5524831cfaff7438ae1c365b9a9e4\nan the key ver:\n$ cat example | cut -c 40-40\n8\n8\n8\na \na\nexplanation:\n8 = AKM-defined, pair wise key\na = WPA2, pair wise key (hcxpcaptool attack vector to downgrade to WPA2 - failed!)\nOr we can add some options to the conversion tool to extract this informations, additional for a data base.\nPlease keep in mind that we use only single EAPOL data for this tests, not a complete, new hash line.\nIf we need fix positions, we should change position from * ESSID * EAPOL * to * EAPOL * ESSID *\n. Maybe it's necessary to increase control field size ( * 00000000 * ) to parse more informations to cracker. Current informations:\nnonce error corrections needed on BE\nnonce error corrections needed on LE\nnonce error corrections needed on BE/LE\nno nonce error corrections needed (hash is a result of an AP-LESS attack vector - we should split this)\nInformation of message pair is not necessary, because we can retrieve this from EAPOL data\nnew :\nuse AKM-defined MIC / PMKID calculation (SHA_192, SHA384, SHA_512, AES-128-CNC for SAE/FILS/WPA3)\nuse PMK len 64\nPMKID received from AP or PMKID received from CLIENT (we got the first one of this kind)\nno nonce error corrections needed\nhash is a result of an AP-LESS attack vector\n. I am a little blinded, because I analyzed plenty of cap files during the last week to test the new hash line.  Reuse of PBKDF2 over EAPOL and PMKID makes cracking process really, really fast.\nThe same applies to reuse of PMK over EAPOL and PMKID.\nSo thanks for your explanation.\nBTW:\nFrom my point of view (hcxtools) a concerted hash line for hashcat and JtR would be fantastic!!!\n. Some early words about the potfile.\nIt would be great to retrieve a potfile line, containing main informations about the result, like this one: \nmac_ap * mac_sta * PMK * PMKID * control field * ESSID (in hex) : PSK\nParsing this kind of information, the hash cracker (hashcat) become part of the whole analysis process. It can add additional informations (for example: how the PSK was retrieved) to the control field and parse it to the data base.\n. More words about the potfile:\nRight now, hashcat use a md5_64 hash over EAPOL (and some other fields, like mac, anonce, ESSID) to make a hash unique and to remove duplicates. Unfortuneatelay an EAPOL message contains several values of counters and many flags, which changes from hash to hash. So hashcat calculates on every hash a new md5_64. A better way is to use the calculated PMK to make the network (and not the hash) unique. That will work, even if the incomming new hash has no ESSID or a damaged ESSID. That is a real benefit of a combined hash line (2500, 2501, 16800, 16801) and a combined potfile line ((2500, 2501, 16800, 16801). Also it will keep the potfile small.\n. How can we help?\n. Now everything is working like expected. Thanks.\n. ",
    "mutepigz": "thanks you!  But i have another problem when i run \"sh example0.sh\" :\nERROR: clGetPlatformIDs() : -1001 : CL_UNKNOWN_ERROR\nwhat'this!\n. ",
    "kost123": "+1 for this\n. @jsteube would somebody accept payment for this? I don't have the skills to do so.\n. Well, it's just sha512 but with a longer salt. I made the system but.. I have seen a few posts on hashcat forums and alike with the same problem. I'm not sure why but there seems to be quite a few sha512 128:128 going around.\n. It's fine, I hope it gets added at some point. I am using JTR at the moment, it's still on CPU but it works.\n. Any update on this guys?\nIt would be awesome if you could define your own salt length.\n. Can you point me in the direction of the code I need to be looking at to change the salt length for sha512(pass.salt) then please? I've been looking and I really don't know. ( I know it's more complicated than changing a number)\n. This can be closed then.\n. \"it's generally more like you want to have a longer salt support. This is something people ask often, but not related to SHA512. It's not too hard to add\"\nThen\n\"You have to write a completely new SHA512 implementation that can support that large of an input. \"\nWhich one is right?\n. Oh really... continue explaining a little please?\n. Actually.. won't I have the same problem trying to account for the hash length? or is it just a case of merging the two with the increased salt length?\n. Nope.. Don't think I can do it xD in 1710 the salt section is all seperate.. in 13800 you have the salt code mixed up seems like and involved with the carry switches and the memcat function?\nSeems so much more complicated than 1710 >.>\nEdit: well I have no idea.. if anybody could tell me the parts that need changing that would be great but for now I really don't know.\n. Found a better solution to my problems, credit to atom and phil :dancer: \nClose if u wish or keep it up, whatever.\n. Not related to hashcat..\nWouldn't mind hearing your 2 salt thing tho..\n. Yea I meant for hashcat CPU... I'd like to see and most likely will try to replicate on sha512. \nIn fact I don't even know if it would be simpler to change the salt length in CPU version.\n. I have a CPU program that does just that.\nWordlist attack ofcourse but still.\n. Hashcat already decrypts AES-256-cbc in a few algos, blockchain for instance.\n. I don't understand but I guess that is just my limited knowledge xD\nLike.. this decrypts my aes encryption..\nopenssl enc -d -aes-256-cbc -in hash.txt -a -k password\nSo if that can do it? hashcat can't? that is a directly encrypted password(cipher whatever) with aes no?\n. This is over a year old but yea.. I know this stuff by now :). +1 for this, longer salt length strikes again :D. Don't suppose this is easily upgradable to 128 salt length? not related to filezilla, just for an obscure software, but if its easy enough I'd just do it for myself.. Also have a strong interest in this.. I'm on windows 10, 16gb ram, can anybody else on windows 10 check? thanks.. Well, whatever you did it works fine across all modes now, good job.. I'd delete them if I was you. ",
    "neocogent": "Maybe a starting point could be Keepass 2 (m=13400)(which also uses AES and SHA256). I don't know enough about opencl coding. I think the AES mode may be CBC instead of ECB and I have no idea how that would change things for the existing the Keepass 2 code. Just thought since they both use same algos it may not need to be written from scratch.\nElectrum cracking would need only the \"xprv\" string from the wallet file to run on for a result. eg. the following xprv has password test12345 and the decrypted result is the master private key.\nVrqpJdrmN6AFuJhMMSkj0fTXMhhHZdV65R+5EZLC1cEF17PSTkDPy4PXqYqkoVdzvjfM1mURv0i5suIFjEk4IzVgR5BL8NwpRcc6rZyT9dCVlVzAE5pcRa1HaRQ/KxV8pGCoo3D8rKMgXCl01q5WP5UZGZAaYmTzZBhifLytY08=\n\n(base64 decode first). @marcushat \nYou might try vultr.com as they have much faster instances and take bitcoin. I've used them several times and found that processing ran much faster than on EC2 spot instances. Easy interface too and pay per hour. Should be able to do many times better than a t2.micro I'd guess. \nI'm playing around with an Arty7 FPGA dev board I have. I created an Electrum cracker engine to try it out. Still simulating and debugging but it actually may work. I thought I would get 24 Mpwds/sec but it looks like the timing is too tight. It uses dual sha256 hashers from an FPGA bitcoin miner and dual AES  decrypter (both open source cores), and my own pwd sequencer logic. It hooks to a pc via usb and you send the xprv and pwd gen mask by usb, and wait for result back. We'll see... if it works then concievably it would be not hard to make a board with many fpga chips on it running in parallel. This chip costs ~ $40 each.. Ya, the FPGA is just toying around for curiosity and practice as I happen to have it here. I've got a working design in simulation but at 10M pwds/sec it still raises timing errors. I'm probably not doing something right so it's good to figure the timing out. In simulation it actually hashes correct values and decrypts the hash to match xprv result - so that's pretty cool for me.. @marcushat \nDid it take all 18-19 days running to get it?. I guess the slow down was since micro instances aren't suited to ongoing cpu load and they limit you after a while. It's great to see that it actually worked out.. ",
    "marcushat": "Thanks I'll definitely look into it. My wallet is worth 4x what I bought it for so this is a great time to give it another go. I'll report back if I get something that works\nOn May 11, 2017, 1:15 PM -0400, neoCogent notifications@github.com, wrote:\n\nMaybe a starting point could be Keepass 2 (m=13400)(which also uses AES and SHA256). I don't know enough about opencl coding. I think the AES mode may be CBC instead of ECB and I have no idea how that would change things for the existing the Keepass 2 code. Just thought since they both use same algos it may not need to be written from scratch.\nElectrum cracking would need only the \"xprv\" string from the wallet file to run on for a valid result.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub (https://github.com/hashcat/hashcat/issues/273#issuecomment-300856349), or mute the thread (https://github.com/notifications/unsubscribe-auth/AHxawEbKdSUryLmxv_C_D4tI5bbfzsHiks5r40IZgaJpZM4Hzggh).\n\n. I ran electrum2john.py and it got default_wallet:$electrum$2*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX*XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\nXXX=hex string\nWhat do with this? I tried putting it in a file(hash.txt) and then ran john --format=bitcoin hash.txt and john --format=bitcoin hash.txt but it said \"unknown ciphertext format name requested\". Going to try it with the bleeding-jumbo version and see if that works. Ha. Yeah, I figured it out. Running it now! Getting around 1M attempts per sec on a t2.micro EC2 instance. Thanks so much. Probably not going to be worth it for my wallet. I already spent the entire initial value of the wallet trying to crack it on AWS about a year ago. Once I rule out 9 char passwords I'm probably gonna have to go the wordlist route. That did it! Haha. Got a paypal @se7enten?. 12 days! On the ec2 micro instance it slowed down to about 100k/sec after a day or so, so it only took about 100bn passwords it crack it. Glad I didn't make my pasword 1 char longer!\nOn Jun 5, 2017, 4:59 AM -0400, neoCogent notifications@github.com, wrote:\n\n@marcushat\nDid it take all 18-19 days running to get it?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "se7enten": "Looks like johntheripper has gotten support.  It's worth noting they created a electrum2john.py tool for extracting the hash.\nhttps://github.com/magnumripper/JohnTheRipper/pull/2541/files\nNo opencl support though.. no paypal but i'll take those bitcoin you just cracked.  :P\nif you feel inclined to make a small donation hook up magnumripper or hashcat or openwall or kholia since he actually coded the electrum support for jtr.\nglad you got in though!  and I'd still like to see GPU support with hashcat.. ",
    "1sammy": "Any recommendations you can make now that some time has passed? I'm in the same scenario and I've ended up running JtR on my R7 1700, 2 days in and 2M passwords/sec, just wondering if y'all had any new insight as I've used some crazy passwords in the past and am not sure if this will work.. ",
    "kholia": "Edit: Oops, I posted on the wrong GitHub thread. It is very early morning for me.. The algorithm is simply sha512($p.$s). The password for this particular hash is \"wyywyy\".\nhttps://github.com/magnumripper/JohnTheRipper/pull/2374 is relevant to this topic.. That version of bitlocker2john.c is unreliable at the moment and does not extract \"non-hashes\" properly.\nhttps://github.com/kholia/bitlocker2john is super reliable but it is a big project. Ideas from this project can be used to improve the former standalone bitlocker2john.c utility. This task is already on e-ago's list I believe.. @jsteube \nThe following hash is not correct,\n$ethereum$p*262144*ae3cd4e7013836a3df6bd7241b12db061dbe2c6785853cce422d148a624ce0bd*517ead924a9d0dc3124507e3393d175ce3ff7c1e96529c6c555ce9e51205e9b2*5318b4d5bcd28de64ee5559e671353e16f075ecae9f99c7a79a38af5f869aa46\nIt should be,\n$ethereum$p*262144*ae3cd4e7013836a3df6bd7241b12db061dbe2c6785853cce422d148a624ce0bd*5318b4d5bcd28de64ee5559e671353e16f075ecae9f99c7a79a38af5f869aa46*517ead924a9d0dc3124507e3393d175ce3ff7c1e96529c6c555ce9e51205e9b2\nThe last two fields are reversed in the first copy of the hash. This is why you couldn't crack it.\nhttps://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/run/ethereum2john.py generates the correct hash which cracks just fine with JtR.. @Chick3nman \nThe first asterisk character in the output hash $ether$*s*262144*... is a mistake and should be removed. This historical mistake started with my pdf2john output hash format. Instead the output hash should be $ether$s*262144*... (no starting stray asterisk character).\nI would like to use the full name ethereum instead of ether in the output hash format. I don't see any advantages of using the potentially ambiguous short name.. @Chick3nman Thank you! My hash extraction script can be seen at https://github.com/magnumripper/JohnTheRipper/pull/2525.. @Chick3nman Sure. I think that having one \"standard\" extraction script is a better option overall. Thanks.. @philsmd I haven't looked closely at this stuff recently. Can we treat this 64 bytes of \"CryptUnprotectData\" data like a keyfile? If a keyfile is being used, can we simply append this 64 bytes of data to that keyfile data? If these hacks are not possible at all, we can bump the version field to 3, and come up with a new hash format.\nI have opened the corresponding JtR issue now. Patches for keepass2john.c are highly welcome. Thanks!. Yes, I think support for both cases (manual specification of \"wua\" bytes, automatic extraction of those bytes) would be needed.\nYes, we already build JtR Jumbo with MinGW for Windows users. So adding this automatic extraction code (within some ifdef) to keepass2john.c should be doable without much problem.. Awesome! This hack should really simplify the changes required I think.. ",
    "sbtc1": "@jsteube \nHi Jens, great work on adding this. There seems to be an issue though with the new electrum support, it was running fine for a v1 example, but for this v2 hashcat does not find the password:\n$electrum$2*942782d00d632be27d54c1bac429a693*3b3c918cb07b4e08670ed4d2e8916b47\nI'm putting the password (\"blabla55\") in a wordlist, but hashcat does not detect it as being correct. (does get detected by JTR)\nkr. Oh, I was confused because of the \"Electrum Wallet (Salt-Type 1-3)\" label in the tool. Good to know. I'll add a new feature request for tracking. Thanks.. ",
    "teasider": "Is $electrum$2 really supported now?\nI ran a test on a new wallet (from an older electrum version, 2.6.4.) - hashed out the hash using electrum2john.py, put around 6 words in a password list (one of them is 123abc, the real password)\nand ran ./john --wordlist=wordlist.txt hashfile\nIt seems the program runs but no result.\nUsing default input encoding: UTF-8\nLoaded 1 password hash (electrum, Electrum Wallet [SHA256 AES / PBKDF2-SHA512 256/256 AVX2 8x])\nCost 1 (kdf [1:SHA256 2:PBKDF2-SHA512]) is 1 for all loaded hashes\nWarning: OpenMP is disabled; a non-OpenMP build may be faster\nPress 'q' or Ctrl-C to abort, almost any other key for status\nWarning: Only 2 candidates left, minimum 4 needed for performance.\n0g 0:00:00:00 DONE (2019-03-07 19:16) 0g/s 9.090p/s 9.090c/s 9.090C/s 123abc..abc123\nSession completed\nAnyone have any idea why is that?\n . > I've got a conference call with developers at AMD soon, but from the looks of our conversation so far it looks plausible:\n\n\u201cThe SSG API is intended to allow you to use the 2TB of SSD storage as a cache layer for the GPU, so it should appear effectively as GPU memory. At this point we\u2019re reaching the limits of what I can explain, and I would recommend getting a quick conference call scheduled between one of our developers and the customer \u2013 is that something you can arrange?\u201d\nOnce I've had the call with AMD and we've reached a conclusion, if it is possible to use the 2TB of SSG in that way, would you (hashcat developers) be able to implement that into your software?\n\nDid you manage to gather more information on the subject?\nI am very interested in the same thing.. Hi and thank you for your reply.\nUsing the beta version did work and I manage to 'crack' the test wallet.\nAny things i need to notice when\\if using the beta version as oppose to the latest release?\n. ",
    "ubuntutest": "Sorry if it is not the right place but i opened an issue on GitHub just because I read the FAQ and I have not solved\n\nIf the problem still exist:\nSolution: Open an issue on github. We will add your GPU with the next release.\n\nCould you tell me the address of IRC? thank you so much\n. Thanks for your help, I solved the problem, I had some wrong directory, browsing the web I have found no information that would make me think of a wrong path.\n. ",
    "JensTimmerman": "relevant for if you don't have john: https://gist.github.com/HarmJ0y/116fa1b559372804877e604d7d367bbc#file-keepass2john-py. Could the help also explain how to generate these new stats?\nI tried with hcstatgen.bin and hcstat2gen.bin, but both of these commands write out files that hashcat 4.2.1 then fails with: Could not uncompress data.\n. Thanks for that link, doesn't seem to work though, my lzma in fedora refuses to write to stdout for compressing, had to use \nlzma --compress --format=raw wpa --suffix=hcstat2 and this generated a wpa.hcstat2 file that could be used by hashcat.. ",
    "felipesalomao": "Hi, how i can run it using OpenCL driver ? I have macboor air I7 2014 and now i am running it slow speed (1.4 pass/sec).. Thank you\n. ",
    "Maxus777": "\nWhere does this format is used? \n\nSunShop Shopping Cart & Ecommerce Software\n\npick one and implement it\n\nFriend, I am not a programmer. I have no idea how to do it :)\n. No :(\n\n21 \u0438\u044e\u043d\u044f 2017 \u0433., \u0432 11:24, sergiolover notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nHey ! Did yo found a solution ? thx\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/293#issuecomment-310004393, or mute the thread https://github.com/notifications/unsubscribe-auth/ARFU4m-tFIS1GoRDcN06rjcSoLWhzzRfks5sGNNUgaJpZM4ID66H.\n\n\n. ",
    "sergiolover": "Hey ! Did yo found a solution ? thx. (it appears to be SunShop CMS). anything ? I read yo can edit the sources, but I dunno anytging bout compiling I do only PHP and Python and such .... not huge but still a real thing :+1: \ngoogle.com/search?q=powered.by.sunshop. and do you think of any alternative software to do so ?\nI could dev something in python but it would be a very basic loop wich won't be very efficient I guess. ",
    "JirkaV": "I actually were not able to compile it using a native compiler, I used https://github.com/msys2. The reported OS in Makefile was \"MSYS_NT-6.1\".\nI won't be submitting a pull request for this - I think this is an edge case and frankly, I'm not too experienced at neither WIndows nor cross compiling, so wouldn't trust the quality of my patch :/\nLeaving this here in case someone needs to compile on Windows. The MSys2 path works, but Makefile needs to be hacked a bit.\n. ",
    "wiire-a": "@jsteube @thesle3p \nA little write-up on EAP-MD5:\nCons:\n- Cannot be used for Wi-Fi as does not support key generation (only used for allowing access)\n- Doesn't provide mutual authentication (vulnerable to MITM)\n- The challenge and response mechanism is in plaintext and goes over the air unencrypted\n- Uses MD5 as hashing algorithm\n- Only available from Windows Vista and below, because considered deprecated/unsecure\nPassive air sniffing is enough to perform an offline attack.\nPros:\n- Provides protection against replay attacks\nClient authentication process:\nClient           Access Point        Radius server\n   |    EAPoL-start    |                   |\n   |------------------>|                   |\n   |  EAP-Request/ID   |                   |\n   |<------------------|                   |\n   | EAP-Response/ID   |    Radius/ID      |\n   |------------------>|------------------>|\n   | EAP-MD5/Challenge | EAP-MD5/Challenge |\n   |<------------------|<------------------|\n   | EAP-MD5/Response  | EAP-MD5/Response  |\n   |------------------>|------------------>|\n   | EAP Success/Fail  | EAP Success/Fail  |\n   |<------------------|<------------------|\nAlgorithm (|| means concatenation):\nClient response hash [16 bytes] = md5(eapid || password || challenge)\neapid:     id of the EAP response frame [1 byte]\npassword:  user password\nchallenge: server challenge [16 bytes]\nAs I understood it, \"eapid\" should be a 1-byte session identifier, however in many cases it's fixed to the default value 0x02. It can be found in Wireshark by selecting the EAP-MD5/Challenge (Request) packet (802.1X Authentication > Extensible Authentication Protocol > Id)\nAs for the password I don't think there's a minimum or maximum length.\nRather than a .hccap file I'd suggest to use a simple string like: $eapmd5$id:challenge:hash\nIt's simplier and one could manually parse it.\nSample data provided with eapmd5pass (link in the sources):\n```\nEAP Id:    02\nChallenge: 00000000000000000000000000000000\nResponse:  9920418b3103652d3b80ffff04da5863\nPassword:  bradtest\nMD5($HEX[02627261647465737400000000000000000000000000000000]) = 9920418b3103652d3b80ffff04da5863\n```\nSources:\nhttp://www.willhackforsushi.com/?page_id=67\nhttp://www.securitytube.net/groups?operation=view&groupId=9\nhttp://dl.ifip.org/db/conf/wistp/wistp2012/LiuX12.pdf\nAlso, while writing this I found: https://twitter.com/hashcat/status/425555173428064256\n. @thesle3p \nSorry when I wrote \"Cannot be used for Wi-Fi as does not support key generation\" I meant to say it doesn't provide key material for WEP or WPA (https://w1.fi/wpa_supplicant/).\nA quote from the book \"CWSP Certified Wireless Security Professional Official Study Guide\":\n\nEAP-MD5 has for a long time been used for port authentication on wired networks and therefore was one of the very first EAP types used with WLANs. Many organizations were already using EAP-MD5, and it was a logical progression to leverage it for WLANs because RADIUS servers already supported it.\n\nAlso I linked that article just for information. The ideal solution is obviously to have it natively implemented and since it's basically just MD5 (with salts) I reckon it shouldn't be too difficult.\n. ",
    "0xbsec": "I've been testing a methode to check duplicates by running each rule on a wordlist that contain plains with different charsets and length (an example wordlist is attached) then checking duplicates content. Here's the script used to generate a wordlist: hashcat-rules-generate-wordlist.pl. And to run the rules and check duplicates: hashcat-rules-uniq.pl. When being runned against rockyou-30000.rule:\n\nChecked 30000 rules in 42339.266s\nFound 29779 uniq rules from 30000 total (99.263%).\nFound duplicate o0a i1k with ^a o1k\nFound duplicate o0a i1u with ^a o1u\nFound duplicate ^3 ^4 o22 i31 r with ^4 o13 i22 i31 r\nFound duplicate o0p i1h with ^p o1h\n......\nFound duplicate se3 so0 with so0 se3\nFound duplicate o0j i1e with ^j o1e\nFound duplicate o0h i1u with ^h o1u\nFound duplicate ^b o1o with o0b i1o\n\n(Complete content)\nStill need more testing and improvement in performance.\n. @jsteube You have a point, I'll try to search more on it.\n@jfoug nice. Is there a way to find the lastest source code of the tool ?\n. Ok, some progress. I was experimenting with mapping rules operations to check duplicates.\nThink of it as you have a string which have any character and length (well .. from 1 to 52). Then each rule change is applied to this arbitrary string and saved. Then a rule is given a uniq id.\nAll GPU rules are supported except E rule.\nExample of duplicates found ( from generated.rule ) :\n\n-> RBx0B, x0B, 'B\n-> ^Dx45, x35, x35_97, o2px35, -Ax35, L1x35, L8x35, A8x35\n-> '8i0z, ^z'9\n-> ^sp1, i0sp1\n-> -9+8, +8-9\n-> 74_65, _47_65\n-> [$k, $k[\n-> $1z1, z1$1\n-> '8+6, +6'8\n-> ^ik, ^i_01\n-> L8x17, +8x17, x17\n-> ^m, i0m\n-> D3+0, +0D3\n-> D5_64, D5*46\ncomplete list.\n\n( current progress: here, perl dups.pl rule.rule )\nWhat do you think about this concept ?\nI'd like to know if there are any problems with this concept.\n. You are right, look like I was running it with an old version 2.00. Got same ouput as yours when I test it with version 3.00.\nBTW are there any documentation for rules that doesn't work with -r or work only with -j and -k ?\n. @jsteube p rule is already taken in hashcat as: pN -> Append duplicated word N times. . @solardiz Got it, thanks.\nThough, seems like / & % rules are only supported when using -j or -k with hashcat.\nSo while the combination of /, %, o & p will apply this functionality, it\u2019ll be limited to the usage with -j or -k (will not work as regular rules in a file loaded with -r).. @roycewilliams \n\n'p' becomes available automatically when using '%' (reject plains unless they have at least X characters) and '=' (reject plains that do not have a character in a specific position).\n\nI think you meant % and / rules?. @satmonkey Can you please reproduce the bug with a small dataset and attach them ?\n. @satmonkey Can you please add the command you are using with the mask, the expected and actual behaviour?. @jsteube Thanks for checking!\n\n\nIn the changes.txt:\n\n\nI'll update the changelog entry to be:\n\n\nRules: Support added for position 'p' in host mode (using -j or -k)\n\n\nWhat do you think?\n\n\nThe macro name convention\n\n\nI wasn't sure about the name.\np will only work if it's preceded by / or %, and will have the position of the last matched character as value.\nMaybe RULE_LAST_REJECTED_SAVED_POS or RULE_CONTAINS_SAVED_POS?\n. @jsteube \nYour proposed format look cleaner :+1:\nWhat do you think about the format bellow?\nShared rules:\n'6:\n    input: ...\n    expected_host: ...\n    expected_gpu: ...\nCPU rules:\n/e:\n    input: ...\n    expected_host: ...\n\nAlso I'd suggest to remove all checks that use rules that are not supported on GPU (reason here is the above reason) like /, <, >, etc\n\nI'm was adding mode: 1 for the cases that should run only on host. Maybe this won't be necessary with  the proposed format.\nI was basing on the assumption that a rule would produce the same output for any input on both host & GPU.\n. FTR current test run: http://termbin.com/euv7. @jsteube Can you please make sure that you are running it against the updated tools/rules-test-cases.yaml?\n\n123456790abcdefghijklmnopqrstuvw12\n123456790abcdefghijklmnopqrstuvwx12\n\nThese cases shouldn't exists for  $1$2: \n https://github.com/hashcat/hashcat/blob/2dcad3f0eea3d3e8dabb531dad3f838a9bf03f5a/tools/rules-test-cases.yaml#L203-L211. @jsteube What do you think about running the self-test on all target devices?\nSo that faulty devices can be found early.. @jsteube I've applied 7a278ef and it seems to fix it \ud83d\udc4d \nI'm on OSX, and I've noticed that the bug was dependent on the length of the plains and the order of applied rules.. Duplicate of #1057. Adding to @Chick3nman comment: You can also pipe the wordlist to hashcat. (e.g. wget http://example.com/list.txt | hashcat ...).\n. @testersz @wifislax-ng If possible, please attach a test case (.hccap & passphrase combo).. Thanks for checking! I confused sha2-224 with sha3-224 and used the wrong parsing function.\nI updated the PR.\n. @jsteube Thanks \ud83d\udc4d \nBTW are other 17X00 modes affected by the misconfiguration?\nI see for: \nMode | salt_type | opts_type\n------------ | ------------- | -------------\n17400 | SALT_TYPE_EMBEDDED | OPTS_TYPE_PT_GENERATE_LE OPTS_TYPE_PT_ADD06\n17500 | SALT_TYPE_EMBEDDED | OPTS_TYPE_PT_GENERATE_LE OPTS_TYPE_PT_ADD06\n17600 | SALT_TYPE_EMBEDDED | OPTS_TYPE_PT_GENERATE_LE OPTS_TYPE_PT_ADD06\n17800 | SALT_TYPE_EMBEDDED | OPTS_TYPE_PT_GENERATE_LE OPTS_TYPE_PT_ADD01\n17900 | SALT_TYPE_EMBEDDED | OPTS_TYPE_PT_GENERATE_LE OPTS_TYPE_PT_ADD01\nShould we update these modes configuration as-well?\n. \ud83d\udc4d . Thanks @jsteube, I pushed a fix to address your notes.. @jsteube Thanks. Your work is outstanding and on another level. Please keep it up \ud83d\udc4d . @jsteube TIL, thanks! I'll keep this in mind going further \ud83d\udc4d . \ud83d\udc4d Thanks.. @jsteube Thanks! You can add \"Mohammad Hasbini - twitter.com/0xbsec\".\nI'm really excited about these changes.\nThis simplify adding new modes. It's possible now to add a mode code generator \ud83d\ude01. @jsteube Thanks for your notes \ud83d\udc4d\nYep, I'm trying to get 19800 to pass self test then I'll add a1 & a3 modes. After this I'll add 19811 module. . @jsteube Sorry didn't have a chance to continue my work on this. Will try to work on it soon.. @jsteube digest[0] was originally byte_swap_32 (digest_buf[0]), but this produced erroneous hashes. e.g. for input 309273c2:00000000 it gave: c2739230:. Thus I removed the swap, although not sure if I'm missing something here.. @jsteube I'm not sure if I should concat $salt here or not.. Thanks :+1:. @jsteube Please let me know if this is fine.. @jsteube I'm trying to make sense of the combination constraint (26), I'm not sure if it's correct.\nThe digest is: md4_hex (md4 (encode (\"UTF-16LE\", $word)) . encode (\"UTF-16LE\", lc ($salt)));.\nHere's how I calculated the optimized constraints for password & salt:\nmd4 (encode (\"UTF-16LE\", $word)): limit $word to 27 (55 / 2) because of unicode. The result is 16 byte.\nFor md4 we have 55 bytes limit so encode (\"UTF-16LE\", lc ($salt)) must be limited to 55 - 16 = 39. $salt in this case will be limited to 19 (39 / 2) (because of unicode).\nThough I'm not sure how to calculate the combination constraint.. @jsteube sha256($pass) is computed in ctx0. What I'm trying to achieve in the above code block is to append the hex values of ctx0.h to s and compute sha256 for both of them. Probably there's something wrong in the above block.. ",
    "fgaudreault": "It will be hard to give you an exact bracket or a fixed number, the salt length will vary depending of variables such as the username, the node name, the date, etc. :/ The other thing is that the salt will contain null bytes.\n. Ok, that make sense. I actually created a new parser yesterday on a local copy, but now I have to figure out how to change the algorithm (which is almost identical to -m 140), except that the salt is bigger and the password is encoded in utf16le.\n. Ok, so I will prepare a pull for the parser code (which is basically a copy of 140, but with higher min/max salt length constants), and a copy of the 140 kernels as a base. My local test picked the salt, but the core was not able to crack the password. I believe that's normal nice the kernels are not able to handle that data yet. I used -m 134 since the PeopleSoft application passwords were -m 133.\n. Awesome!! Sorry you had to rewrite some of our code :/  For the verify, I added the mode 13500 to the hash:salt portion.. unless we have additional stuff to add? Let me run it and see whats missing.\n. Ill look at it this morning. When I tried yesterday, I couldnt get it to work.\n. Ok. I just added the missing portion. The rest was already there. I will do a pull request. Actually, the hash file had to be hash:salt, and the crack hash:salt:word in order for the script to work properly. Pull request is open.\n. We changed the mode to 13500, and added an esalt structure. I believe the buffers are populating the data according to your recommendations. So what are the next steps? :)\n. The tests are still missing, as well as the appropriate kernel code. But for the rest, we should have the base in place. More tests will be required afterward.\n. I think that would be great. I'll just make sure we have the tests in place, and remove the warning on compiling. Should be done in the next commit. Meanwhile, I will also fix the test.pl file for the new Digest::ECB versions, the constants are no longer exported.\n. I think we are good now. The test.pl results have been cross-checked using JtR, and it cracks properly. Unfortunately, I had to use a constant salt, but that should do the trick.\n. There is no DES in the algorithm. I fixed the use Crypt::ECB module only because the newer version is no longer using PADDING_NONE and PADDING_AUTO, you have to push the padding in the encrypt sub. That being said, we will fix the problems.\n. Aight. So at this point, we think we would need the kernels in order to test the full loop on our own and fix the remaining issues. Because it's the first time we touch the code base, having working kernels would help, and if you can help us with that, it would go much faster. Thanks for your patience btw ;)\n. ",
    "lalaithion": "You were close; the problem turned out to be device 2. Thanks.\n. Hey, sorry for no response.\nI changed that line, and I'm still getting the same error.\n. ",
    "hubert3": "Still happening for me, new MacBook Pro 15\" (2016), hashcat compiled from Github code today\nIt runs fine without -r but crashes with any larger rules file I try.\n16 hashes in the file\n```\n$ ./hashcat -m 5600 NTLMv2.txt ~/combined/combined_unique.txt -r rules/InsidePro-HashManager.rule\nhashcat (v3.6.0-455-g8fb583f0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6820HQ CPU @ 2.70GHz, skipped.\nDevice #2: Intel(R) HD Graphics 530, 384/1536 MB allocatable, 24MCU\nDevice #3: AMD Radeon Pro 455 Compute Engine, 512/2048 MB allocatable, 12MCU\n\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 16: z\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 17: Z\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1402: Sa@\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1403: So0\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1404: Si1\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1405: Su4\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1406: Se3\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1408: Si!\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1409: Ss5\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1410: Ss$\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1411: Sl1\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1412: Sg9\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1413: St7\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1414: Sb5\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1415: Sb8\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1416: Ss3\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1417: Sa4\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1419: Sa@So0\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1420: Sa@Si1\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1421: Sa@Su4\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1422: Sa@Se3\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1423: So0Si1\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1424: So0Su4\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1425: So0Se3\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1426: Si1Su4\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1427: Si1Se3\nSkipping invalid or unsupported rule in file rules/InsidePro-HashManager.rule on line 1428: Su4Se3\nHashes: 16 digests; 16 unique digests, 16 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 6470\nApplicable optimizers:\n Zero-Byte\n Not-Iterated\nPassword length minimum: 0\nPassword length maximum: 256\nWatchdog: Temperature abort trigger disabled.\nWatchdog: Temperature retain trigger disabled.\nINFO: Removed 2 hashes found in potfile.\nDictionary cache hit:\n Filename..: /Users/hubert/combined/combined_unique.txt\n Passwords.: 26897522\n Bytes.....: 271713531\n Keyspace..: 174026967340\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => Abort trap: 6\n```. Workaround is -D 1 (use CPU only)\nOr -d 2 -u 1 --force (use Intel GPU only with --kernel-loops 1, reduced performance)\nHigher -u values crash after a while on my system (5 after a few hours, 7+ soon after launch, 10 immediately on launch)\nThe crash also does not happen with -d 3 (selecting only the AMD Radeon Pro 455 device), however as per https://github.com/hashcat/hashcat/issues/1350, this is currently not a valid workaround as support for that AMD device seems to be broken. It looks like it's running normally but never finds any passwords.\nTL;DR Hashcat is not usable for full-speed GPU cracking on OSX right now, at least not on recent hardware like MacBook Pro (15-inch, 2016) running macOS Sierra 10.12.6 with the GPUs shown above.. See https://github.com/hashcat/hashcat/issues/1350\nPossibly related - I found that my AMD Radeon device on a new MacBook Pro fails to crack hashes that it should . @kureeoffsec would you be able to test the commands I posted in https://github.com/hashcat/hashcat/issues/1350 to confirm that your AMD GPU device on OSX is showing the same behaviour as mine? i.e. no warnings, but fails to find passwords that it should.. -D 1 always seems to work\n-d 2 always seems to work\n-d 3 never works.\nSo the culprit seems to be my \"AMD Radeon Pro 455 Compute Engine, 512/2048 MB allocatable, 12MCU\"\n. Ok good to know that the AMD device should not be used for now.\nHowever, I am also seeing crashes on launch (Abort Trap 6) when I'm using all devices or device 2 only (Intel(R) HD Graphics 530) in combination with larger wordlists and rulesets.\nI was running -d 3 to avoid these crashes but it appears cracking is broken with this device (no wonder I didn't crack anything the last few days).\nSee https://github.com/hashcat/hashcat/issues/309. Thanks\n-d 2 -w 1 with large wordlist/ruleset still gets Abort Trap 6 on launch\n-d 2 -w 1 -u 1 -n 1 --force runs, but the speed is 720 kH/s which is approximately John CPU only speed.. If \"AMD Radeon Pro 455 Compute Engine, 512/2048 MB allocatable, 12MCU\" is known not to work on OSX currently perhaps it should be auto-disabled or there should be a warning?. Same result with -O (optimized kernels) - Using the AMD Radeon Pro 455 device on OSX (-d 3) Hashcat doesn't display any warnings or errors but silently fails to find any passwords.\nDoes Hashcat v3.6.0-465-g0a0522cf contain the self-test mentioned in https://github.com/hashcat/hashcat/issues/1348? Should that catch it?\nIn my humble opinion, I think it would be a good idea to disable this particular AMD device on OSX as it seems broken, or at least explicitly document this issue.\nWhether it's a bug in the OpenCL runtime or Hashcat itself is an irrelevant distinction from the user's perspective.\nHashcat running on OSX on current Mac hardware with default options gives the user feedback that everything is working normally, but it will randomly fail to find some passwords (or never find any passwords, if selecting to run only on the buggy device, which I was doing to try to avoid the crashing issue documented in https://github.com/hashcat/hashcat/issues/309, which is also not resolved).\nSo Hashcat is giving the user false assurance about the strength of the hashes tested.. I'm as sure as I can be (as the reporter) that it's not PEBKAC.\nI gave the contents of the hash and wordlist files, and the exact commands used above.\nUsing both the Intel and AMD devices in my MacBook Pro (default behaviour), it fails to find the password randomly, which I also experienced during a real-world run with a large dictionary and bigger list of hashes.\nSpecifying only the AMD device, it never finds any passwords. This is 100% repeatable and consistent.\nI have asked the reporter of https://github.com/hashcat/hashcat/issues/1348 if he could try my commands, as he may be hitting the same issue also with an AMD device on OSX.. @0xbsec I think that would be a great idea. Would have saved me several days of running Hashcat on a non-working GPU device and not finding any passwords. ",
    "rejoinder": "\nWorkaround is -D 1 (use CPU only)\nOr -d 2 -u 1 --force (use Intel GPU only with --kernel-loops 1, reduced performance)\nHigher -u values crash after a while on my system (5 after a few hours, 7+ soon after launch, 10 immediately on launch)\nThe crash also does not happen with -d 3 (selecting only the AMD Radeon Pro 455 device), however as per #1350, this is currently not a valid workaround as support for that AMD device seems to be broken. It looks like it's running normally but never finds any passwords.\nTL;DR Hashcat is not usable for full-speed GPU cracking on OSX right now, at least not on recent hardware like MacBook Pro (15-inch, 2016) running macOS Sierra 10.12.6 with the GPUs shown above.\n\nThanks for this. Does anyone know if this has been addressed yet or if there is support yet?. ",
    "gituser": "You can split your salt to 2 if it's 128 chars.\nI don't know for oclHashcat, but for CPU hashcat this is possible.\nOf course you need to modify code.\n. What was a solution? :) Others might benefit from it.\n. > Wouldn't mind hearing your 2 salt thing tho..\nit's only for hashcat CPU.. oclhashcat got different architecture.\nbest is to study what @jsteube has added recently and compare to -m 1710\n. Here is a quick and dirty patch for hashcat-2.00 (release) it adjusts -m 1710 mode:\nhttps://gist.github.com/gituser/c6e9bc382c978123ed5c558e8639e576\n```\n$ ./hashcat-cliAVX.bin -m 1710 test.sha512 test.wordlist \nInitializing hashcat v2.00 with 4 threads and 32mb segment-size...\nAdded hashes from file test.sha512: 1 (1 salts)\nActivating quick-digest mode for single-hash with salt\n2bbc652c39d5e0bf8680b9ac8d795f0c449f84db52c594cab4d853c4926d21963f2def0475fb0976d296747351d3cb9a44f53a7a3cffd152ba7d078f854c4a3a:bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb:test\nAll hashes have been recovered\nInput.Mode: Dict (test.wordlist)\nIndex.....: 1/1 (segment), 1 (words), 5 (bytes)\nRecovered.: 1/1 hashes, 1/1 salts\nSpeed/sec.: - plains, - words\nProgress..: 1/1 (100.00%)\nRunning...: 00:00:00:01\nEstimated.: --:--:--:--\n```\n. @jsteube, why do you think it's normal?\n291.6 MH/s vs 50 MH/s (incremental vs wordlist) ?\nthat means for wordlist with rules speed is 6 times slower.\ni'm using 500k hashes (for incremental) with 400mb wordlist (for wordlist mode) and 200k rules, so I think there is enough 'work to do'.\n. @roycewilliams I did read this link, but I can't figure out how it applies to my case? All parameters (hash, wordlists, rules) are stated in my first post, please read. Also I'm not using GPU at all, I'm using Intel OpenCL SDK with Intel XEON E3, also stated in first post.\nI'm using 42M wordlist + >200000 rules, so what could be wrong?\nI've also tried piping old cpu hashcat version but it gives even worse performance.\nOn CPU hashcat (old version v2.00) speed is same for both cases - incremental / wordlist, that's why I filled an issue here, might be there some performance bug for wordlist / rules attack?\n. Is there any more clarification why speed jumps so much for wordlist attack vs incremental?\nThanks.\n. no worries.\njust thought it'd be useful for others, i'm just adding salt to hashfiles via sed.\n. OK, so I managed to add this algorythm to CPU hashcat (v2.00), oclHashcat is bit complicated for me with all these kernels. I'll post a patch later if anyone is interested.\nEDIT: I've updated first post to reflect the actual feature request for oclHashcat.\n. Is there some sort of documentation on kernels to understand how to write your own dynamic hash (e.g. the one I mentioned in my first comment)?\n. The reason why it doesn't work, because you probably made it with:\n$ echo apple|md5sum -\n30c6677b833454ad2df762d3c98d2409 -\nso it actually puts 'apple\\n' instead of 'apple'\nwhilst you should always use echo -n (so there will be no newline in your hash):\n$ echo -n apple|md5sum -\n1f3870be274f6c49b3e31a0c6728957f  -\n. there are multiple solutions to your problem\nyou can use https://bitbucket.org/seinlc/hashtopussy\n. @jsteube, I've tried that branch in both -m 0 and -m 2711 modes with -a 1 and it hashcat didn't find any of the long (>128) passwords candidates. I can see in hashcat's status that such passwords are enumerated but not found for some reason.\n-m 2711 isn't supporting salts bigger than 30 chars.\nI see that you've been adding commits to improve password length for other password hashes. \nSo guess we just have to wait a bit.\nThanks a lot once again for your work, highly appreciated.. ",
    "Crasha": "\"C\" doesn't do anything - there's also no option for \"c\" that states\nanything. There's only [S]Status, [P]ause, [R]esume, [B]ypass, [Q]uit.\nOn 27 Apr 2016 8:23 a.m., \"Jens Steube\" notifications@github.com wrote:\n\nNot a bug, just use \"c\" instead of \"q\" when stopping a session\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/hashcat/oclHashcat/issues/317#issuecomment-214992398\n. \n",
    "bjornfor": "My first thought is that setting umask is a \"big hammer\", it will affect the whole process and all files. Another option is to create the secret file with explicit permission bits.\nWhile at it, maybe the program should check on startup what the permission bits are, and complain a bit if it is group and/or world readable?\n. @jsteube: I have no idea. (I've been using hashcat only a couple of days, I haven't looked at its source code yet.)\nBut even if using umask doesn't cause real problems, it feels a bit wrong. I don't think it conveys the right intent; \"~/.hashcat/hashcat.pot should be private\". Instead it says, \"all files should be private\".\n(Isn't it equally trivial to create the file with the correct permission bits, as it is to use umask?)\n. Thanks! (Looking forward to the upcoming release, I plan to package it for Nix/NixOS.)\n. ",
    "cblack-r7": "Apologies for commenting on a massively dead thread, but I was digging into a problem and I did run into this (i.e. me complaining). I have a multi-user instance that uses a shared user group for hashcat, this causes the OCL kernels to be created without group writable permissions and I've had to do some pretty nasty hacks to get around that. Generally not forcing the umask unless in specific sensitive cases is generally considered polite.. ",
    "y0sh1": "The project still needs to be submitted on https://travis-ci.org to make use of the building for this repository. :smile_cat: \n. ",
    "cablebox": "Weird. I just ran 'make' again, and it compiled without issues (confirmed I was doing it in oclhashcat).\n. ",
    "lfaoro": "Make sure you have gmp available in the system, if you have brew it's a simple brew install gmp and have you downloaded the OpenCL-Headers dependency?\n. @jsteube you should specify that in the readme when you can\n. modified the Makefile build flags and it worked.\n. Actually I've looked into the system logs and found a crash log for hashcat, I don't know how to read it, hopefully it makes sense to someone for debugging/fixing the issue.\nhashcat.app_2016-05-16-011444_NB-IT-OSX-LFAORO.txt\n. thank you guys\n. the problem seem to be Device #2: Iris Pro, 384/1536 MB allocatable, 1200Mhz, 40MCU device\nif I exclude it from the ./hashcat -b - I complete the benchmark fine otherwise I get a crash at Hashtype: SHA-3(Keccak)\n. I think it broke or something happened to it as I was able to complete the benchmark before\n. if I run ./hashcat.app -b -d 3 I complete the benchmark no problem, no crash\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, skipped\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 300Mhz, 10MCU\n. yessir!\n. ",
    "BeetleChunks": "I have brew installed and have version gmp-6.1.0 installed. I have the OpenCL-Headers in the following directory, \"oclHashcat/deps/OpenCL-Headers/CL/\". I used the git clone method found in the BUILD.md file.\n. ",
    "noaht8um": "@BeetleChunks  I am having the same issues. I also have the include files in the proper place. I do not have gmp installed because I thought it was not required. I am running 10.11.5.\n. When I build and run hashcat.app, this is what I get. I am running bench using method 1000 (NTLM) as an example:\n\nComputer:oclHashcat username$ ./hashcat.app -d2 --bench -m1000\nhashcat (v3.00-beta-32-gde2074d) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-4790K CPU @ 4.00GHz, skipped\nDevice #2: GeForce GTX 970, 1024/4096 MB allocatable, 1253Mhz, 13MCU\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Options : -cl-std=CL1.1 -I\"/Users/username/Desktop/hashcat-build/oclHashcat/./\" -DVENDOR_ID=2 -DCUDA_ARCH=0 -DVECT_SIZE=2 -DDEVICE_TYPE=4 -DKERN_TYPE=1000 -D_unroll ===\n=== Build Log (start) ===\n:10:10: fatal error: 'include/constants.h' file not found\ninclude \"include/constants.h\"\n     ^\n\n=== Build Log (end) ===\nDevice #2: Kernel /Users/username/Desktop/hashcat-build/oclHashcat/./OpenCL/m01000_a3.cl build failure. Proceed without this device.\nHashtype: NTLM\nStarted: Tue May 17 17:28:12 2016\nStopped: Tue May 17 17:28:13 2016 \nComputer:oclHashcat username$\nIt does this for all different methods that I have tested. In the m01000_a3.cl file, it gets stuck at line 10 which is:\ninclude \"include/constants.h\"\nI don't know why it would get stuck here because that seems to be the right path. \n@arnaudsj I saw that you were able to fix the problem by hard-coding; where did you edit the path?\nSorry if this is long-winded, but I wanted to show as much data as possible.\n. I just tried it again with the latest GitHub version (git pull; make clean; make) and I went from about 35000 H/s to 40000 H/s using -w 4. Unfortunately this is still significantly less than the old version.. @jsteube Thanks for fixing this! Works great now. Tested on my hackintosh and my MacBook Pro with an NVIDIA card.. ",
    "arnaudsj": "Same here with 10.11.4\n. It works against CPU, and Intel Iris card, but not NVidia (device 3)\n. I confirmed that hardcoding the path in the *.cl files solves the problem. So it is definetly a problem with the search path.\nIt might be dumb, but should:\n-I\"/Users/beetle/Documents/ocltmp/oclHashcat/./\" not be -I\"/Users/beetle/Documents/ocltmp/oclHashcat\" instead?\nIf not, where is this path generated? It is obviously passed along dynamically in the JIT portion...\n. Nevermind, it appears to be a bug on NVidia GPU only.\nRunning the same mask attack on a different mac yields the proper results:\n```\n./hashcat.app -a 3 -m 100  \"a94a8fe5ccb19ba61c4c0873d391e987982fbbd3\" '?l?l?l?l' -opencl-device-types 1,2\nhashcat (v3.00-beta-32-gde2074d) starting...\nDevice #1: Intel(R) Core(TM) M-5Y71 CPU @ 1.20GHz, skipped\nDevice #2: Intel(R) HD Graphics 5300, 384/1536 MB allocatable, 900Mhz, 24MCU\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (?l?l?l?l) [4]\nHash.Target....: a94a8fe5ccb19ba61c4c0873d391e987982fbbd3\nHash.Type......: SHA1\nTime.Started...: 0 secs\nSpeed.Dev.#2...: 36304.7 kH/s (2.05ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 281216/456976 (61.54%)\nRejected.......: 0/281216 (0.00%)\nRestore.Point..: 0/17576 (0.00%)\n```\n. ",
    "cclements": "I'm getting the same constants.h file not found on intel only.  I tried hardcoding the path in the .cl files as arnaudsj suggested, but the build still fails:\n```\n./hashcat.app --opencl-device-types=1 -d1 -b -m1000\nhashcat (v3.00-beta-60-g35d7e67) starting in benchmark-mode...\nDevice #1: Intel(R) Core(TM) i7-4850HQ CPU @ 2.30GHz, 4096/16384 MB allocatable, 2300Mhz, 8MCU\nDevice #2: Iris Pro, skipped\nDevice #3: GeForce GT 750M, skipped\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Options : -cl-std=CL1.1 -I\"/private/var/root/tools/oclHashcat/./\" -DVENDOR_ID=2 -DCUDA_ARCH=0 -DVECT_SIZE=4 -DDEVICE_TYPE=2 -DKERN_TYPE=1000 -D_unroll ===\n=== Build Log (start) ===\n:10:10: fatal error: '/private/var/root/tools/oclHashcat/include/constants.h' file not found\ninclude \"/private/var/root/tools/oclHashcat/include/constants.h\"\n     ^\n\n=== Build Log (end) ===\nDevice #1: Kernel /private/var/root/tools/oclHashcat/./OpenCL/m01000_a3.cl build failure. Proceed without this device.\nHashtype: NTLM\nStarted: Tue May 24 08:12:30 2016\nStopped: Tue May 24 08:12:32 2016 \n```\nI am on a late 2013 rMBP with 10.11.5 installed.\n. yes.  I have also tried as a non-root user with the same results.\n. I neglected to change the paths in the .cl files back to the defaults after I moved the directory for the non-root user.  I changed them back and all is well with the non-nvidia devices.  Sorry for the confusion.\n. I take it the nvidia specific issue from https://github.com/hashcat/oclHashcat/issues/345 applies to Windows builds as well?  I ask because I am getting the same includes failure trying to run on nvidia on win10 x64 with the latest drivers now as well.  If this isn't expected let me know and I'll open a new issue.\n. ```\noclHashcat v2.01 (gc0d0ef6) starting...\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, 8173/32693 MB allocatable, 4000Mhz, 8MCU\nDevice #2: GeForce GTX 980, 1024/4096 MB allocatable, 1329Mhz, 16MCU\nHashes: 19 hashes; 19 unique digests, 19 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Not-Iterated\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nDevice #1: Kernel D:\\Downloads\\oclHashcat/kernels/m05600_a0.715b2085.kernel (475824 bytes)\nDevice #2: Kernel D:\\Downloads\\oclHashcat/kernels/m05600_a0.390aa4a0.kernel not found in cache! Building may take a while...\n=== Build failed, retry with optimization disabled ===\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Options : -I\"D:\\Downloads\\oclHashcat/\" -DVENDOR_ID=4318 -DCUDA_ARCH=502 -DVECT_SIZE=1 -DDEVICE_TYPE=4 ===\n=== Build Log (start) ===\n:10:10: fatal error: 'inc_hash_constants.h' file not found\ninclude \"inc_hash_constants.h\"\n     ^\n\n=== Build Log (end) ===\nDevice #2: Kernel D:\\Downloads\\oclHashcat/OpenCL/m05600_a0.cl build failure. Proceed without this device.\n```\n. Apologies, didn't notice that \"oclHashcat\" had been deprecated in favor of simply \"hashcat\".  Calling hashcat instead allowed the kernel to build without error.\n. OSX kernel compilation for nvidia works as of your last commit as well.  Thanks!\n. Here you go:\nhttps://gist.github.com/cclements/efb4e4690f3d1a755ffa82f4803bfeb0\n```\nhashcat (v3.10-1611-gd1fe054+) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) OpenCL\n  Version : OpenCL 2.0\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) HD Graphics 530\n    Version        : OpenCL 2.0\n    Processor(s)   : 24\n    Clock          : 1150\n    Memory         : 2047/13041 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 21.20.16.4534\nDevice ID #2\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n    Version        : OpenCL 2.0 (Build 359)\n    Processor(s)   : 8\n    Clock          : 4000\n    Memory         : 2047/32623 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 6.6.0.359\nDevice ID #4\n    Type           : GPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) HD Graphics 530\n    Version        : OpenCL 2.0\n    Processor(s)   : 24\n    Clock          : 1150\n    Memory         : 2047/13041 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 21.20.16.4534\nDevice ID #5\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n    Version        : OpenCL 2.0 (Build 359)\n    Processor(s)   : 8\n    Clock          : 4000\n    Memory         : 2047/32623 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 6.6.0.359\nPlatform ID #2\n  Vendor  : NVIDIA Corporation\n  Name    : NVIDIA CUDA\n  Version : OpenCL 1.2 CUDA 8.0.0\nDevice ID #3\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : TITAN X (Pascal)\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 28\n    Clock          : 1531\n    Memory         : 2047/12288 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 376.09\nPlatform ID #3\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) OpenCL\n  Version : OpenCL 2.0\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) HD Graphics 530\n    Version        : OpenCL 2.0\n    Processor(s)   : 24\n    Clock          : 1150\n    Memory         : 2047/13041 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 21.20.16.4534\nDevice ID #2\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n    Version        : OpenCL 2.0 (Build 359)\n    Processor(s)   : 8\n    Clock          : 4000\n    Memory         : 2047/32623 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 6.6.0.359\nDevice ID #4\n    Type           : GPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) HD Graphics 530\n    Version        : OpenCL 2.0\n    Processor(s)   : 24\n    Clock          : 1150\n    Memory         : 2047/13041 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 21.20.16.4534\nDevice ID #5\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n    Version        : OpenCL 2.0 (Build 359)\n    Processor(s)   : 8\n    Clock          : 4000\n    Memory         : 2047/32623 MB allocatable\n    OpenCL Version : OpenCL C 2.0\n    Driver Version : 6.6.0.359\n```. Jens, thanks for the follow up.  My cracking machine has been busy the past week, but I will try the steps you outlined soon.. Following those steps resolved the issue.  The intel driver installation utility did offer me two separate versions of the GPU driver, however, I chose to install only the latest version.. Same crash with -d 1 and with -d 2. The 3.20 release version works without issue. Sorry for the delay, I was away on vacation.  I see the same crash as of commit e5e97c6ff8771a047cff195bd0993a3a7d08d4b2. Ugh, forgot to make clean first.  After doing so it appears the crash has been resolved.  Thanks!. Sorry about that, I had indeed updated the hashcat version but when I uploaded it to my windows box I had forgotten I had the old bin paused in a background window.  File locking prevented the new version from being written.  After fixing this, everything works again.. ",
    "anthraxx": "Ok thats cool, but then i especially recommend to never delete tags, they don't really hurt and depending on distributions they don't always ship the newest version. Removing tags breaks building those packages or reproducibly building old packages.\n. Yeah we definitively need a solution that preserves all tags if you don't want to break any kind of user builds like arch AUR, gentoo etc etc :stuck_out_tongue: So I hope once we resolve this issue we could hopefully get back the old tags, plzzz :smile_cat: \nWell now I know the reason, what i'm using when I package GIT versions to have a meaningful string:\nprintf \"%s.%s.%s\" \"$(git tag|sort|tail -n1)\" \"$(git rev-list --count HEAD)\" \"$(git rev-parse --short HEAD)\"\nthis gets the semantically same output:\nv0.15.7.786.1dd1f3d%\n. I guess you did not really understand what i mean :smile: \nremoving tags is really a  bad habit, what i mean is that i offered an alternative approach to git describe that outputs you a usefull version string but uses the most current tag.\ngit tags should always be preserved, in my opinion its a failure on the code base if it requires to remove tags (really no offense, I try to find a solution that fits both sides)\nRemoving tags also removes the tarballs here: https://github.com/hashcat/oclHashcat/releases\nI also understand what you mean, but doing it that way destroys the whole possibility building from source tarballs. Also if you jump back to a commit that is equivalent to 2.01 version, then this git describe command will still show you version 3.00. I remember there was a way to extract the current git tag version into a file for the release tarballs, I think radare is doing, let me search a bit around and i can show you what I mean\n. That's great to hear... and please don't get me wrong, I really try to also solve your problem that you may face and I'm really not blaming or offending :smiley_cat: \n- restoring the old tags:\ngit tag v2.00 5065474b4e5ed59add2d5af6e2e9cf3857969fe3\n  git tag v2.01 490ff03fe18b3966ab591e859a79e29eab5ea386\n  git push --tags\nCan you help me trying to reproduce your problem why it still showed v2.01 for you? I have recreated the tags on a local checkout but i could not make git to output v2.01 for the current master HEAD when the v3.00-beta tag was in place :sob: \nI assume you want to avoid having a VERSION file in the root? It would of cause require to manually maintain that file, but that would solve some of the issues and the version in the Makefile could be a concat of that VERSION file + optionally (if its a git checkout and not a tarball extraction) a git describe without tags so the version will reflect also the git hash.\n. Ok, I have found what i meant. Its called export-subst and allows to set a file via .gitattributes where a git version identifier is exported into a marker in the file. This allows to have a switch for non git checkouts (tarballs). If you like this solution, I could create a pull request for that. This would solve that 'git describe' is not available for tarballs.\n. normally git describe should traverse the history graph and pick the latest tag that is linked to the current HEAD when using describe, that's why I'm quite confused. You can try a test repository and play around with tagging and describe, I'm pretty sure it uses the nearest tag to a specific commit.\nOk, I think I get your idea, I will create a pull request with the switch I explained and you can have a look at it.\nThe idea is that it then supports both, 'git describe' (like now) if the current directory is a git checkout (contains .git directory) or as a fallback (if it is a github release tarball) it uses a static version identifier that will be inserted into the Makefile automagically by git-archive.\nReally big thanks that you restored the old tags, I'm very thankful (and I'm sure a lot more people also).\nWill link the pull request when I have time.... maybe in some hours or the following days.\n. I have attached a pull-request with detailed explanation. This will allow to build from a release tarball again but will require that the tarball is either downloaded from github or created locally via 'git archive' command. However note that without such change the 'git describe' will fail in a non git-checkout.\nIf at any point your 'git describe' issues will reappear, feel free to ping me and I'm still willing to help solving that one for you.\n. Feel free to ask for any changes or clarification, I'm happy to explain or change my pull request :smile_cat: \nThis is related to https://github.com/hashcat/oclHashcat/issues/342\n. yes, for both, the git checkout and the exported tarball via 'git archive'. For the git checkout nothing is changed compared to what you had before: this is the normal behavior of 'git describe', it will only add \"-1-gxxxxxxx\" when there are newer commits on top of the last tag. So once new commits are pushed after the \"v3.00\" then it starts adding those suffixes.\nPS: if you want to always add the git hash for the git checkout and/or git archive (even if the current commit is in fact the current tag) then I can change that in the pull request for you.\n. worked on my test, is that a git checkout or the archive? let me check. sry\n. @jsteube sure my fault do worries. let me refix it and test properly, forgot the git checkout test and using git archive replaced the variable identifiers\n. @jsteube Big sorry for the previous failure, I will buy you a beer if we ever meet at a con (f.e. 33C3)! :beers: \nHave re-fixed the previous commit and tested all kind of combinations i could think of.\nTo avoid any possible failure before merging, feel free to clone my fork https://github.com/anthraxx/oclHashcat and run your test before accepting. Thank you very much for taking your time with this.\n. I can confirm this issue, but the provided patch does not help for me (running Linux).\n```\n\nstrace -e open,rmdir,mkdir hashcat --benchmark \n[...]\nmkdir(\"/usr/bin/kernels\", 0700)         = -1 EACCES (Permission denied)\nopen(\"/usr/bin/hashcat.restore\", O_RDONLY) = -1 ENOENT (No such file or directory)\nhashcat (v3.00) starting in benchmark-mode...\n\nrmdir(\"/usr/bin/hashcat.induct\")        = -1 ENOENT (No such file or directory)\nmkdir(\"/usr/bin/hashcat.induct\", 0700)  = -1 EACCES (Permission denied)\nERROR: /usr/bin/hashcat.induct: Permission denied\n+++ exited with 255 +++\n```\nit should use some world writable location like /tmp or cwd. Currently this issue keeps me from being able to move hashcat into the main distro packages.\neverything installed via make install\n. @joshdekock well I provided PREFIX but didn't thought it may be required for building and the install step that contained the PREFIX was separated. works, thx :smile_cat: \n. well, I agree with the documentation, however the /usr/share directory will never be writable to a user for a distro package. Luckily hashcat uses ~/.hashcat/ is such cases.\n. I see, valid point. ignore my comment :stuck_out_tongue_closed_eyes: \n. Consistency is nice but primarily my goal was to be able to get the signature file... where the other files are coming from did not really matter... thats the good part of a trusted signature, the source could be anywhere (like a dropbox :smile: )\nthanks a lot for clarification and fixing, works. Packaging it for my distro now :smile_cat: \n. @jsteube no problem, i was just wondering when observing it again :yum: . well advanced user here or there but this is a security issue and especially non-advanced users are even less aware of the security implication :smile: \nyes, right now i simply strip out the whole rpath to mitigate this threat. stripping it on install would work for those, but the thing is, technically the users not using the install target will still be vulnerable to this problem. in my opinion people need to learn to make things work without the relative rpath to not expose anyone to a potential threat.\nhow about some kind of simply shell script with a readme block that aids non-advanced users to run it locally without installing it into the system?. as said, you don't need to teach anyone about LD_LIBRARY_PATH if you have a wrapper script that does so and uses explicitly the directory where the shared lib was built in. Otherwise its still vulnerable for all people who don't use the install target.\nThe only solution to this issue is to not use relative rpath at all and add a wrapper script to start hashcat when not being in a 'installed' target, otherwise the users are always vulnerable to unintended code execution.. I don't see the difference, wherever you put you hashcat executable could be the place to have the hashcat wrapper script. Nobody would ever notice the difference if you adjust the install target accordingly and distribute the non-wrapper version instead. I honestly don't see where the problem is.. Why would they get an error message? You can easily put the wrapper somewhere else and handle it in the compilation step by moving it where the binary would be. No offense but I start having the feeling like you just don't want to solve this at all for people that use a local copy of hashcat and just keep them vulnerable because of \"convenience\" (where I still disagree that it can't be transparently solved if you really want to).\nThe concerns you mentioned are understandable, but as I pointed out, each one can be solved individually while still not requiring any rpath. I don't see why you can't have such wrapper and i don't see why it has to be there before having compiled the project.. @jsteube sometimes its hard to get intentions and thoughts of someone else over pure text, but i'm very happy to hear this, so excuse my interpretation :smile_cat: \nLuckily the script doesn't need anything complex, just resolving basedir of itself and use LD_LIBRARY_PATH or DYLD_LIBRARY_PATH before calling the real hashcat binary. While I don't have environments set up to test all those, I can help getting the script and Makefile working... you could then test it in your supported environments.\nThe latter solution sounds also fine. Is it correct when I would expect the 'shared' make target to produce both artifacts, the libhashcat.so and the hashcat binary that dynamically links to it and the 'default' make target that simply produces a statically linked version? Both solutions sound fine to mitigate the relative rpath... its all up to you're preference :smiley: . @jsteube cool, thanks :+1: . @jsteube yes please do, we on Arch definitively want to build unbundled. The problem goes even further as we are using the sources your provide that have detatched signature and its not possible currently to build 5.0.0.\nCan you please make it optionally work to build with system xxhash? this currently blocks the 5.0.0 update.. @ZeroChaos- you can take a sneak preview via #1772 :smile_cat: . It's a pretty basic solution you can still rework it afterwards. You didn't sound like you want to do it so I grabbed my editor and created a PR for your convenience \n. In your private mail my summary from what you wrote was like nothing will happen. And this got closed without such a statement as well, so I implemented it as it's simple to do. Was unaware and unintended this will hurt feelings and I had no ill will here just trying to help instead of only  complain  \ud83e\udd14 code is iterative nothing stops from doing a alternative solution later but I needed one right now to package it for Arch.\n. @jsteube well the Makefile is malformed f.e. $(LIBRARY_DEV_ROOT_FOLDER/ is src/Makefile:111: *** unterminated variable reference.  Stop.. @jsteube works fine over here, thanks for the work. This fixes #1741 . ",
    "andreamoreto": "\nI'd think it's much more easy to create a hash-mode md5(md5($password).md5($salt) )\n\n... but this algorithm is already supported by 3910 , am i correct ? It will not work in this case.\n. As I stated before, this is the 2nd time I face this algorithm.  On the first time the salt was a random md5.\nNow, due this curious salting method I can use the surname as salt and follow jsteube's suggestion. \nIn my opinion this algorithm,  if accepted,  should be a generic one, as I found it on 2 distinct applications. \n. ",
    "BoBeR182": "I also ran into a database that uses md5(md5($pass).$salt) but the salt was 3 characters so I cannot use -m 2711\nHow can I implement this by hand.\n. ",
    "xinhuang": "I also came across a case where the format is md5(md5($pass).$salt), in which the $salt is of 6 chars.\nIs it possible to have a generic mode for such cases by specifying the salt pattern? Thanks!. ",
    "Amblypygid": "The key difference here is that you are telling openssl to decrypt your AES ciphertext. You are giving it a key with the password variable. This is a simple process.\nYou are requesting of Hashcat that it break the AES cipher or guess the password. I can't tell which it is you want, but neither is possible.\nAs for breaking AES, the best cryptographers in the world have been trying since it was invented. It has been 20 years and it is still unbroken. With some knowledge of what you're attacking, password searches can be sped up about a factor of 4, but that's the best you can hope for.\nAs far as guessing the password, with a 256-bit key there are literally 2^256 possibilities, which is over 10^77. All the GPUs in the world won't guess it in ten billion years, and that is a generous estimate.\nIf you have good knowledge of the plaintext, good knowledge about the way the password was chosen, and are the NSA, then you have some hope.\nAll that aside, I hope you have solved the problem with that file.\n. ",
    "netro": "Any news or roadmap since may 2016 ?. ",
    "akiraaisha": "How about now?. ",
    "brannondorsey": "+1. ",
    "CthUlhUzzz": "Oh, thx. It works!) But i have next problem with sha3 kernel in benchmark mode:\nSpeed.Dev.#2.:  9050.8 kH/s (95.53ms)\nERROR: clBuildProgram() : -11 : CL_BUILD_PROGRAM_FAILURE\n=== Build Options : -I \"/home/test/Downloads/hashcat-3.00/OpenCL/\" -I '/home/test/Downloads/hashcat-3.00/OpenCL/' -I /home/test/Downloads/hashcat-3.00/OpenCL/ -I\"/home/test/Downloads/hashcat-3.00/OpenCL/\" -I'/home/test/Downloads/hashcat-3.00/OpenCL/' -I/home/test/Downloads/hashcat-3.00/OpenCL/ -DVENDOR_ID=2147483648 -DCUDA_ARCH=0 -DVECT_SIZE=2 -DDEVICE_TYPE=4 -DKERN_TYPE=5000 -D_unroll -cl-std=CL1.1 ===\n=== Build Log (start) ===\nunsupported initializer for address space in m05000_m04\n=== Build Log (end) ===\nDevice #2: Kernel /home/test/Downloads/hashcat-3.00/OpenCL/m05000_a3.cl build failure. Proceed without this device.\nHashtype: SHA-3(Keccak)\n. Of course. Message fixed.\n. Take me how i can do it)\n. @jsteube Unfortunately I do not have such skills. Can I help with verbose log or something like that?\n. CPU doesn't works too:\n```\nPlatform ID #2\n  Vendor  : Advanced Micro Devices, Inc.\n  Name    : AMD Accelerated Parallel Processing\n  Version : OpenCL 2.0 AMD-APP (1800.8)\nDevice ID #3\n    Type           : CPU\n    Vendor ID      : 1\n    Vendor         : AuthenticAMD\n    Name           : AMD A8-5545M APU with Radeon(tm) HD Graphics\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 4\n    Clock          : 1127\n    Memory         : 2048/5150 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1800.8 (sse2,avx,fma4)\n\nphoenix@phoenix-laptop:~$ hashcat -b -D1 --force\nhashcat (v4.0.1) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Mesa\n\nDevice #1: AMD ARUBA (DRM 2.50.0 / 4.15.0-13-generic, LLVM 6.0.0), skipped.\nDevice #2: AMD Radeon (TM) HD 8500M/8700M (OLAND / DRM 3.23.0 / 4.15.0-13-generic, LLVM 6.0.0), skipped.\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #3: AMD A8-5545M APU with Radeon(tm) HD Graphics, 2048/5150 MB allocatable, 4MCU\n\nBenchmark relevant options:\n\n--force\n--opencl-device-types=1\n--optimized-kernel-enable\n\nHashmode: 900 - MD4\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\nInternal error: Compilation init failed.\n* Device #3: Kernel /usr/share/hashcat/OpenCL/m00900_a3-optimized.cl build failed - proceeding without this device.\nStarted: Thu Apr 12 17:33:16 2018\nStopped: Thu Apr 12 17:33:18 2018\n. Another error for both GPUs:\nphoenix@phoenix-laptop:~$ hashcat -m0 -a3 -D2 -d2 --force 6ee22036a5c5b01f3bd0a989e10bbcda ?d?d?d?d?d?d?d \nhashcat (v4.0.1) starting...\nOpenCL Platform #1: Mesa\n\nDevice #1: AMD ARUBA (DRM 2.50.0 / 4.15.0-13-generic, LLVM 6.0.0), skipped.\nDevice #2: AMD Radeon (TM) HD 8500M/8700M (OLAND / DRM 3.23.0 / 4.15.0-13-generic, LLVM 6.0.0), 919/3070 MB allocatable, 6MCU\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #3: AMD A8-5545M APU with Radeon(tm) HD Graphics, skipped.\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\n Raw-Hash\nPassword length minimum: 0\nPassword length maximum: 256\nATTENTION! Pure (unoptimized) OpenCL kernels selected.\nThis enables cracking passwords and salts > length 32 but for the price of drastical reduced performance.\nIf you want to switch to optimized OpenCL kernels, append -O to your commandline.\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nWatchdog: Temperature retain trigger disabled.\n\nDevice #2: build_opts '-I /usr/share/hashcat/OpenCL -D VENDOR_ID=16 -D CUDA_ARCH=0 -D AMD_ROCM=0 -D VECT_SIZE=4 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=0 -D _unroll'\nDevice #2: Kernel m00000_a3.7211a723.kernel not found in cache! Building may take a while...\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n\nIn file included from input.cl:12:\n./inc_common.cl:192:19: warning: double precision constant requires cl_khr_fp64, casting to single precision\n:0:0: in function m00000_mxx void (%struct.pw addrspace(1), %struct.kernel_rule_t addrspace(1), %struct.pw addrspace(1), <4 x i32> addrspace(2), i8 addrspace(1), i8 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), %struct.plain_t addrspace(1), %struct.digest addrspace(1), i32 addrspace(1), %struct.salt addrspace(1), i8 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32 addrspace(1), i32, i32, i32, i32, i32, i32, i32, i32, i32, i32, i64): unsupported initializer for address space\n\nDevice #2: Kernel /usr/share/hashcat/OpenCL/m00000_a3.cl build failed - proceeding without this device.\n\nStarted: Thu Apr 12 18:25:22 2018\nStopped: Thu Apr 12 18:25:43 2018\n```. ",
    "PaveEvil": "Help pls!\n\nhashcat -b\nhashcat (v3.10) starting in benchmark-mode...\n\nOpenCL Platform #1: Mesa\n\nDevice #1: AMD REDWOOD (DRM 2.46.0 / 4.8.0-parrot-amd64, LLVM 3.9.1), 716/1024 MB allocatable, 5MCU\n\nLLVM ERROR: Cannot select: 0x56240bce25f0: i32,ch = AtomicLoadAdd 0x56240bacc3e0, 0x56240bcdf030, Constant:i32<1>\n  0x56240bcdf030: i32 = add 0x56240bce26d0, 0x56240bc87040\n    0x56240bce26d0: i32,ch = CopyFromReg 0x56240bacc3e0, Register:i32 %vreg304\n      0x56240bc86c50: i32 = Register %vreg304\n    0x56240bc87040: i32 = shl 0x56240bcb0500, Constant:i32<2>\n      0x56240bcb0500: i32 = add 0x56240bce3980, 0x56240bce39f0\n        0x56240bce3980: i32,ch = CopyFromReg 0x56240bacc3e0, Register:i32 %vreg46\n          0x56240bce24a0: i32 = Register %vreg46\n        0x56240bce39f0: i32,ch = CopyFromReg 0x56240bacc3e0, Register:i32 %vreg312\n          0x56240bce02c0: i32 = Register %vreg312\n      0x56240bd43b20: i32 = Constant<2>\n  0x56240bc8a520: i32 = Constant<1>\nIn function: m00900_m04\n. ",
    "Arno0x": "Yes, I do have XCode and all required stuff to compile. As I said hashcat.app was compiled properly.\nActually, the kernel for my GeForce GT 750M was properly compiled so I can use it, and it's OK since it's the fastest device.\nI was just wondering what could cause this build error...\n. Very true :)\n. Hi,\nI placed the OpenCL headers as per the installation instructions, ie under deps/OpenCL-Headers.\nCheers.\n. True. It goes like this for me:\nMacBook-Pro-de-arno-2:~ arno$ ls -la /Applications/Hashcat/deps/OpenCL-Headers/CL/\ntotal 368\ndrwxr-xr-x  13 arno  staff    442  8 jui 16:07 .\ndrwxr-xr-x   3 arno  staff    102  8 jui 16:07 ..\ndrwxr-xr-x  13 arno  staff    442  8 jui 16:07 .git\n-rw-r--r--   1 arno  staff  74542  8 jui 16:07 cl.h\n-rw-r--r--   1 arno  staff   5122  8 jui 16:07 cl_d3d10.h\n-rw-r--r--   1 arno  staff   5116  8 jui 16:07 cl_d3d11.h\n-rw-r--r--   1 arno  staff   5421  8 jui 16:07 cl_dx9_media_sharing.h\n-rw-r--r--   1 arno  staff   5358  8 jui 16:07 cl_egl.h\n-rw-r--r--   1 arno  staff  16368  8 jui 16:07 cl_ext.h\n-rw-r--r--   1 arno  staff   7583  8 jui 16:07 cl_gl.h\n-rw-r--r--   1 arno  staff   2869  8 jui 16:07 cl_gl_ext.h\n-rw-r--r--   1 arno  staff  43544  8 jui 16:07 cl_platform.h\n-rw-r--r--   1 arno  staff   1993  8 jui 16:07 opencl.h\n. ",
    "fmarquez": "Actually, I have the same problem, but my kernel is not even compiling... I have a Macbook Pro Retina 2015 with an AMD M370x clean 10.11.5 with latest Xcode. I clone https://github.com/hashcat/oclHashcat.git and the headers. Make works fine, but I have problems with compiling the kernel for the GPUs:\nashcat (v3.00-beta-209-gc172da1) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashes: 6494 hashes; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n- Zero-Byte\n- Precompute-Init\n- Precompute-Merkle-Demgard\n- Meet-In-The-Middle\n- Early-Skip\n- Not-Salted\n- Not-Iterated\n- Single-Salt\n- Raw-Hash\n- Device #2: Kernel m00000_a1.8b86d570.kernel not found in cache! Building may take a while...\n=== Build failed, retry with optimization disabled ===\nERROR: clBuildProgram() : -43 : CL_INVALID_BUILD_OPTIONS\n=== Build Options : -I \"/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/\" -I '/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/' -I /Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/ -I\"/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/\" -I'/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/' -I/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/ -DVENDOR_ID=4 -DCUDA_ARCH=0 -DVECT_SIZE=1 -DDEVICE_TYPE=4 -DKERN_TYPE=0 -D_unroll -cl-std=CL1.1 ===\n=== Build Log (start) ===\n=== Build Log (end) ===\n- Device #2: Kernel /Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/m00000_a1.cl build failure. Proceeding without this device.\n- Device #3: Kernel m00000_a1.360b6dd0.kernel not found in cache! Building may take a while...\n=== Build failed, retry with optimization disabled ===\nERROR: clBuildProgram() : -43 : CL_INVALID_BUILD_OPTIONS\n=== Build Options : -I \"/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/\" -I '/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/' -I /Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/ -I\"/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/\" -I'/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/' -I/Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/ -DVENDOR_ID=2147483648 -DCUDA_ARCH=0 -DVECT_SIZE=1 -DDEVICE_TYPE=4 -DKERN_TYPE=0 -D_unroll -cl-std=CL1.1 ===\n=== Build Log (start) ===\n=== Build Log (end) ===\n- Device #3: Kernel /Users/fmarquez/Documents/FM/Projects/Px - Security/tools/oclHashcat/./OpenCL/m00000_a1.cl build failure. Proceeding without this device.\n  Generated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#*...:        0 H/s\nRecovered......: 0/6494 (0.00%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:N/A,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 0/136302297088 (0.00%)\nHow did you manage to compile the kernel? Where exactly did you place the OpenCL headers?\n. deps/OpenCL-Headers is contained inside the oclHashcat directory ?\n. Then I don't get it at all... The process is simple, but there must be a difference somewhere:\n1.- I git clone https://github.com/hashcat/oclHashcat.git (that is the right repository, right?)\n2.-  I created inside oclHashcat folder mkdir -p deps/OpenCL-Headers\n3.- I get the openCL headers:  git clone https://github.com/KhronosGroup/OpenCL-Headers deps/OpenCL-Headers/CL\n4.- $ make\ngcc -D_POSIX -DOSX -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2    -o hashcat.app src/hashcat.c obj/ext_OpenCL.NATIVE.o obj/shared.NATIVE.o obj/rp_kernel_on_cpu.NATIVE.o -lpthread -DCOMPTIME=1466707535 -DVERSION_TAG=\\\"v3.00-beta-209-gc172da1+\\\" -DINSTALL_FOLDER=\\\"/usr/local/bin\\\" -DSHARED_FOLDER=\\\"/usr/local/share/hashcat\\\" -DDOCUMENT_FOLDER=\\\"/usr/local/share/doc/hashcat\\\"\nsrc/hashcat.c:13738:9: warning: unused variable 'need_nvapi' [-Wunused-variable]\n    int need_nvapi   = 0;\n        ^\nsrc/hashcat.c:13740:9: warning: unused variable 'need_xnvctrl' [-Wunused-variable]\n    int need_xnvctrl = 0;\n        ^\n2 warnings generated.\nBut hashcat.app is generated\nHowever when I try to run it, for example with example0.sh, I still get the same problem as in my previous post, and the kernels are not generated\nAny idea will be appreciated! I cannot see what I'm doing wrong here, and the compilation process seems simple enough...\n. Hi, your fix worked! I even pulled the modification over the same repository (with the space in the path) and it compiles the kernel for all the devices (The Iris and the Radeon).\nNow I'll try different scenarios with it :-)\nThanks a lot!\n. ",
    "mouse07410": "Here's what I get on Mac OS X 10.11.6 with Xcode-8.0 and Macports GCC-6.1, using the current master branch of hashcat.\nBuild was standard, except CFLAGS:\n$ make clean && CFLAGS=\"$CFLAGS -framework OpenCL\" LDFLAGS=\"$LDFLAGS -framework OpenCL\" make\nrm -f obj/*.o *.bin *.exe *.restore *.out *.pot *.log hashcat core\nrm -rf *.induct\nrm -rf *.outfiles\nrm -rf *.dSYM\nrm -rf kernels\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/affinity.NATIVE.o src/affinity.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/attack_mode.NATIVE.o src/attack_mode.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/autotune.NATIVE.o src/autotune.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/benchmark.NATIVE.o src/benchmark.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/bitmap.NATIVE.o src/bitmap.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/bitops.NATIVE.o src/bitops.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/common.NATIVE.o src/common.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/convert.NATIVE.o src/convert.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_aes.NATIVE.o src/cpu_aes.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_crc32.NATIVE.o src/cpu_crc32.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_des.NATIVE.o src/cpu_des.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_md5.NATIVE.o src/cpu_md5.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_sha1.NATIVE.o src/cpu_sha1.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/cpu_sha256.NATIVE.o src/cpu_sha256.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/data.NATIVE.o src/data.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/debugfile.NATIVE.o src/debugfile.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/dictstat.NATIVE.o src/dictstat.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/dispatch.NATIVE.o src/dispatch.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/dynloader.NATIVE.o src/dynloader.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/ext_ADL.NATIVE.o src/ext_ADL.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/ext_nvapi.NATIVE.o src/ext_nvapi.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/ext_nvml.NATIVE.o src/ext_nvml.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/ext_OpenCL.NATIVE.o src/ext_OpenCL.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/ext_xnvctrl.NATIVE.o src/ext_xnvctrl.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/filehandling.NATIVE.o src/filehandling.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/filenames.NATIVE.o src/filenames.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/folder.NATIVE.o src/folder.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/hash_management.NATIVE.o src/hash_management.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/hlfmt.NATIVE.o src/hlfmt.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/hwmon.NATIVE.o src/hwmon.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/induct.NATIVE.o src/induct.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/interface.NATIVE.o src/interface.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/locking.NATIVE.o src/locking.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/logfile.NATIVE.o src/logfile.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/logging.NATIVE.o src/logging.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/loopback.NATIVE.o src/loopback.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/memory.NATIVE.o src/memory.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/monitor.NATIVE.o src/monitor.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/mpsp.NATIVE.o src/mpsp.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/opencl.NATIVE.o src/opencl.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/outfile_check.NATIVE.o src/outfile_check.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/outfile.NATIVE.o src/outfile.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/potfile.NATIVE.o src/potfile.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/powertune.NATIVE.o src/powertune.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/remove.NATIVE.o src/remove.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/restore.NATIVE.o src/restore.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/rp_cpu.NATIVE.o src/rp_cpu.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/rp_kernel_on_cpu.NATIVE.o src/rp_kernel_on_cpu.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/runtime.NATIVE.o src/runtime.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/session.NATIVE.o src/session.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/shared.NATIVE.o src/shared.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/status.NATIVE.o src/status.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/stdout.NATIVE.o src/stdout.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/terminal.NATIVE.o src/terminal.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/thread.NATIVE.o src/thread.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/timer.NATIVE.o src/timer.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/tuningdb.NATIVE.o src/tuningdb.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/usage.NATIVE.o src/usage.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/version.NATIVE.o src/version.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/weak_hash.NATIVE.o src/weak_hash.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2 -c -o obj/wordlist.NATIVE.o src/wordlist.c\ngcc  -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -framework OpenCL -pipe -W -Wall -std=c99 -Iinclude/ -IOpenCL/ -Ideps/OpenCL-Headers/ -O2    -o hashcat src/hashcat.c obj/affinity.NATIVE.o obj/attack_mode.NATIVE.o obj/autotune.NATIVE.o obj/benchmark.NATIVE.o obj/bitmap.NATIVE.o obj/bitops.NATIVE.o obj/common.NATIVE.o obj/convert.NATIVE.o obj/cpu_aes.NATIVE.o obj/cpu_crc32.NATIVE.o obj/cpu_des.NATIVE.o obj/cpu_md5.NATIVE.o obj/cpu_sha1.NATIVE.o obj/cpu_sha256.NATIVE.o obj/data.NATIVE.o obj/debugfile.NATIVE.o obj/dictstat.NATIVE.o obj/dispatch.NATIVE.o obj/dynloader.NATIVE.o obj/ext_ADL.NATIVE.o obj/ext_nvapi.NATIVE.o obj/ext_nvml.NATIVE.o obj/ext_OpenCL.NATIVE.o obj/ext_xnvctrl.NATIVE.o obj/filehandling.NATIVE.o obj/filenames.NATIVE.o obj/folder.NATIVE.o obj/hash_management.NATIVE.o obj/hlfmt.NATIVE.o obj/hwmon.NATIVE.o obj/induct.NATIVE.o obj/interface.NATIVE.o obj/locking.NATIVE.o obj/logfile.NATIVE.o obj/logging.NATIVE.o obj/loopback.NATIVE.o obj/memory.NATIVE.o obj/monitor.NATIVE.o obj/mpsp.NATIVE.o obj/opencl.NATIVE.o obj/outfile_check.NATIVE.o obj/outfile.NATIVE.o obj/potfile.NATIVE.o obj/powertune.NATIVE.o obj/remove.NATIVE.o obj/restore.NATIVE.o obj/rp_cpu.NATIVE.o obj/rp_kernel_on_cpu.NATIVE.o obj/runtime.NATIVE.o obj/session.NATIVE.o obj/shared.NATIVE.o obj/status.NATIVE.o obj/stdout.NATIVE.o obj/terminal.NATIVE.o obj/thread.NATIVE.o obj/timer.NATIVE.o obj/tuningdb.NATIVE.o obj/usage.NATIVE.o obj/version.NATIVE.o obj/weak_hash.NATIVE.o obj/wordlist.NATIVE.o -lpthread -L/opt/local/lib -framework OpenCL -DCOMPTIME=1474327485 -DVERSION_TAG=\\\"v3.10-146-g57195b4+\\\" -DINSTALL_FOLDER=\\\"/usr/local/bin\\\" -DSHARED_FOLDER=\\\"/usr/local/share/hashcat\\\" -DDOCUMENT_FOLDER=\\\"/usr/local/share/doc/hashcat\\\"\nexample0.sh was modified:\ndiff --git a/example0.sh b/example0.sh\nindex 98ed7cf..3f8eba8 100755\n--- a/example0.sh\n+++ b/example0.sh\n@@ -1 +1 @@\n-./hashcat -t 32 -a 7 example0.hash ?a?a?a?a example.dict\n+./hashcat -D 2 -t 32 -a 7 example0.hash ?a?a?a?a example.dict\nHere are the results:\n```\n$ ./example0.sh\nhashcat (v3.10-146-g57195b4+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 6494 digests; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\n- Device #2: Kernel m00000_a1.094ff996.kernel not found in cache! Building may take a while...\n- Device #2: Kernel markov_le.094ff996.kernel not found in cache! Building may take a while...\nINFO: Removed 2190 hashes found in potfile\nGenerated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace           \n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Mon Sep 19 19:25:03 2016 (19 secs)\nTime.Estimated.: Mon Sep 19 19:42:13 2016 (16 mins, 47 secs)\nSpeed.Dev.#2...:   132.5 MH/s (8.31ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:N/A,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 2747596800/136302297088 (2.02%)\nRejected.......: 0/2747596800 (0.00%)\nRestore.Point..: 0/129988 (0.00%)\n. . . . .\nSession.Name...: hashcat\nStatus.........: Running\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Mon Sep 19 19:25:03 2016 (3 mins, 19 secs)\nTime.Estimated.: Mon Sep 19 19:45:57 2016 (17 mins, 31 secs)\nSpeed.Dev.#2...:   108.7 MH/s (10.10ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 22034841600/136302297088 (16.17%)\nRejected.......: 0/22034841600 (0.00%)\nRestore.Point..: 0/129988 (0.00%)\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Mon Sep 19 19:25:03 2016 (7 mins, 3 secs)\nTime.Estimated.: Mon Sep 19 19:44:40 2016 (12 mins, 30 secs)\nSpeed.Dev.#2...:   118.1 MH/s (9.33ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 47635660800/136302297088 (34.95%)\nRejected.......: 0/47635660800 (0.00%)\nRestore.Point..: 0/129988 (0.00%)\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Mon Sep 19 19:25:03 2016 (19 mins, 29 secs)\nSpeed.Dev.#2...:   117.0 MH/s (2.21ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nStarted: Mon Sep 19 19:25:03 2016\nStopped: Mon Sep 19 19:44:38 2016\n```\nIt appears to work OK, and the only concern is that the time is not tracked.\n. > why do you think the time is not tracked?\nBecause all the values remain zeroes. Unlike what they used to be before the refactoring of the last couple of days - see below.\n\nI see it in your output\n\nYes, the placeholders are certainly there - but the values placed in them are plain wrong (unless you are telling me that all the averages and all the other timing data are now supposed to be zero?).\n\nUnless I misunderstand what you are looking for.\n\nI'm looking for the real timing data, like this (look at what it shows for Min, Hour, Day):\n\n. This is not Iris Pro, but maybe it would be helpful (from MacBook Air with Intel HD Graphics 5000):\nCL_DEVICE_TYPE_GPU[0]\n    CL_DEVICE_NAME: HD Graphics 5000\n    CL_DEVICE_AVAILABLE: 1\n    CL_DEVICE_VENDOR: Intel\n    CL_DEVICE_PROFILE: FULL_PROFILE\n    CL_DEVICE_VERSION: OpenCL 1.2 \n    CL_DRIVER_VERSION: 1.2(Aug 29 2016 22:20:39)\n    CL_DEVICE_OPENCL_C_VERSION: OpenCL C 1.2 \n    CL_DEVICE_MAX_COMPUTE_UNITS: 40\n    CL_DEVICE_MAX_CLOCK_FREQUENCY: 1100\n    CL_DEVICE_MAX_WORK_GROUP_SIZE: 512\n    CL_DEVICE_ADDRESS_BITS: 64\n    CL_DEVICE_MEM_BASE_ADDR_ALIGN: 1024\n    CL_DEVICE_MAX_MEM_ALLOC_SIZE: 402653184\n    CL_DEVICE_GLOBAL_MEM_SIZE: 1610612736\n    CL_DEVICE_MAX_CONSTANT_BUFFER_SIZE: 65536\n    CL_DEVICE_GLOBAL_MEM_CACHE_SIZE: 0\n    CL_DEVICE_GLOBAL_MEM_CACHELINE_SIZE: 0\n    CL_DEVICE_LOCAL_MEM_SIZE: 65536\n    CL_DEVICE_PROFILING_TIMER_RESOLUTION: 80\n    CL_DEVICE_IMAGE_SUPPORT: 1\n    CL_DEVICE_ERROR_CORRECTION_SUPPORT: 0\n    CL_DEVICE_HOST_UNIFIED_MEMORY: 1\n    CL_DEVICE_EXTENSIONS: cl_APPLE_SetMemObjectDestructor cl_APPLE_ContextLoggingFunctions cl_APPLE_clut cl_APPLE_query_kernel_names cl_APPLE_gl_sharing cl_khr_gl_event cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_image2d_from_buffer cl_khr_gl_depth_images cl_khr_depth_images cl_khr_3d_image_writes \n    CL_DEVICE_PREFERRED_VECTOR_WIDTH_INT: 1\n    CL_DEVICE_PREFERRED_VECTOR_WIDTH_LONG: 1\n    CL_DEVICE_PREFERRED_VECTOR_WIDTH_FLOAT: 1\n    CL_DEVICE_PREFERRED_VECTOR_WIDTH_DOUBLE: 0\n    CL_DEVICE_NATIVE_VECTOR_WIDTH_INT: 1\n    CL_DEVICE_NATIVE_VECTOR_WIDTH_LONG: 1\n    CL_DEVICE_NATIVE_VECTOR_WIDTH_FLOAT: 1\n    CL_DEVICE_NATIVE_VECTOR_WIDTH_DOUBLE: 0\n. Perhaps you could point me at an explanation of (or just explain, if it's short enough not to trouble you too much) what these values\n. . . . .\nRecovered/Time.: CUR:N/A,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\n. . . . .\nsupposed to mean, especially when they're all zeroes and N/A?\n. Here's with the latest/current github version:\n```\n$ ./example0.sh \nhashcat (v3.10-363-g9413ed8) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 6494 digests; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: Kernel m00000_a1.12b70c18.kernel not found in cache! Building may take a while...\nDevice #2: Kernel markov_le.12b70c18.kernel not found in cache! Building may take a while...\n\nINFO: Removed 2190 hashes found in potfile\nGenerating dictionary stats for example.dict: 1080240 bytes (100.00%), 129988 words, 1363022                                                                                            Generated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\n. . . . .\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Sat Oct  1 21:08:48 2016 (18 mins, 37 secs)\nSpeed.Dev.#2...:   117.5 MH/s (2.21ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nStarted: Sat Oct  1 21:08:48 2016\nStopped: Sat Oct  1 21:27:32 2016\n$ ./example400.sh \nhashcat (v3.10-363-g9413ed8) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: Kernel m00400.12b70c18.kernel not found in cache! Building may take a while...\nDevice #2: Kernel amp_a0.12b70c18.kernel not found in cache! Building may take a while...\n\nINFO: Removed 1 hash found in potfile\nStarting attack in stdin mode...\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Pipe\nHash.Target....: $H$9y5boZ2wsUlgl2tI6b5PrRoADzYfXD1\nHash.Type......: phpass, MD5(Wordpress), MD5(phpBB3), MD5(Joomla)\nTime.Started...: 0 secs\nSpeed.Dev.#2...:        0 H/s (0.00ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 129988\nRejected.......: 0\nStarted: Sat Oct  1 21:36:07 2016\nStopped: Sat Oct  1 21:36:20 2016 \n$ ./example500.sh \nhashcat (v3.10-363-g9413ed8) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: Kernel m00500.12b70c18.kernel not found in cache! Building may take a while...\nINFO: Removed 1 hash found in potfile\n\nCache-hit dictionary stats example.dict: 1080240 bytes, 129988 words, 129988 keyspace\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: File (example.dict)\nHash.Target....: $1$uOM6WNc4$r3ZGeSB11q6UUSILqek3J1\nHash.Type......: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...:        0 H/s (0.00ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 129988/129988 (100.00%)\nRejected.......: 0/129988 (0.00%)\nStarted: Sat Oct  1 21:36:57 2016\nStopped: Sat Oct  1 21:37:01 2016 \n$\n```\nYou can see that when the timing is provided, it does not appear right (or I may not understand what those zeroes mean). Perhaps there's another test or example that would exercise those better?\nAlso, trying to find and run some tests (figuring that tools/test.sh is a likely candidate :), I'm getting this:\n$ tools/test.sh\n[ test_1475374305 ] > Init test for hash type 0.\n[ test_1475374305 ] [ Type 0, Attack 0, Mode single, Device-Type Gpu, Vector-Width 1 ] > OK : 0/31 not found, 0/31 not matched, 0/31 timeout\n[ test_1475374305 ] [ Type 0, Attack 0, Mode single, Device-Type Gpu, Vector-Width 4 ] > OK : 0/31 not found, 0/31 not matched, 0/31 timeout\ncat: illegal option -- A\nusage: cat [-benstuv] [file ...]\n$\n. First, it still does not provide crack-per-second info. I suspect it might be related to your tests, not necessarily the executable itself - please take a look at that.\nSecond - the current github version crashes on me:\n```\n$ ./example400.sh\nhashcat (v3.10-541-g1c055a6+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\nStarting attack in stdin mode...\n./example400.sh: line 1: 56608 Done                    cat example.dict\n     56609 Segmentation fault: 11  | ./hashcat -m 400 example400.hash\n$ \n```\nAlso, I see that your build recognizes Darwin (Mac OS), but it does not add flag -framework OpenCL to either CFLAGS or LDFLAGS. This flag is required for both compilation and linking phases on Mac OS. I wonder if there's a clash between KHRONOS_OPENCL include files you're pulling from GitHub and the native ones that Apple provides as part of OpenCL framework, since the OpenCL libraries the executable links against are definitely based on the Apple OpenCL files (which might have subtle differences from those at Khronos). oclHashcat successfully builds without that flag, but I don't know if it introduces some incompatibility/problem down the road...\nDebugging traces are in the next message.\nUpdate: \nIn case this matters: MacOS Sierra 10.12, Xcode-8.0.0 (also tried with Macports GCC-6.2.\n. Update 2\nAfter rebuilding in DEBUG mode:\n```\n$ make clean\nrm -f obj/.o .bin .exe .restore .out .pot .log hashcat hashcat_shared libhashcat.so core\nrm -rf .induct\nrm -rf .outfiles\nrm -rf .dSYM\nrm -rf kernels\n$ DEBUG=yes make\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/affinity.NATIVE.o src/affinity.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/autotune.NATIVE.o src/autotune.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/benchmark.NATIVE.o src/benchmark.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/bitmap.NATIVE.o src/bitmap.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/bitops.NATIVE.o src/bitops.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/combinator.NATIVE.o src/combinator.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/common.NATIVE.o src/common.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/convert.NATIVE.o src/convert.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpt.NATIVE.o src/cpt.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_aes.NATIVE.o src/cpu_aes.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_crc32.NATIVE.o src/cpu_crc32.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_des.NATIVE.o src/cpu_des.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_md5.NATIVE.o src/cpu_md5.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_sha1.NATIVE.o src/cpu_sha1.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/cpu_sha256.NATIVE.o src/cpu_sha256.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/debugfile.NATIVE.o src/debugfile.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/dictstat.NATIVE.o src/dictstat.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/dispatch.NATIVE.o src/dispatch.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/dynloader.NATIVE.o src/dynloader.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/event.NATIVE.o src/event.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/ext_ADL.NATIVE.o src/ext_ADL.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/ext_nvapi.NATIVE.o src/ext_nvapi.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/ext_nvml.NATIVE.o src/ext_nvml.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/ext_OpenCL.NATIVE.o src/ext_OpenCL.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/ext_xnvctrl.NATIVE.o src/ext_xnvctrl.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/filehandling.NATIVE.o src/filehandling.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/folder.NATIVE.o src/folder.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/hashcat.NATIVE.o src/hashcat.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/hashes.NATIVE.o src/hashes.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/hlfmt.NATIVE.o src/hlfmt.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/hwmon.NATIVE.o src/hwmon.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/induct.NATIVE.o src/induct.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/interface.NATIVE.o src/interface.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/locking.NATIVE.o src/locking.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/logfile.NATIVE.o src/logfile.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/loopback.NATIVE.o src/loopback.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -mclang: warning: -framework OpenCL: 'linker' input unused\nsse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/memory.NATIVE.o src/memory.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/monitor.NATIVE.o src/monitor.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/mpsp.NATIVE.o src/mpsp.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/opencl.NATIVE.o src/opencl.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/outfile_check.NATIVE.o src/outfile_checclang: warning: -framework OpenCL: 'linker' input unused\nk.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/outfile.NATIVE.o src/outfile.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/potfile.NATIVE.o src/potfile.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/restore.NATIVE.o src/restore.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/rp.NATIVE.o src/rp.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/rp_cpu.NATIVE.o src/rp_cpu.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/rp_kernel_on_cpu.NATIVE.o src/rp_kernel_on_cpu.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/shared.NATIVE.o src/shared.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/status.NATIVE.o src/status.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/stdout.NATIVE.o src/stdout.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUGclang:  -g -ggdb -Iinclude/ -IOpenCL/ -o obj/straight.NATIVE.o src/straight.c\nwarning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/terminal.NATIVE.o src/terminal.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/thread.NATIVE.o src/thread.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/timer.NATIVE.o src/timer.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/tuningdb.NATIVE.o src/tuningdb.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/usage.NATIVE.o src/usage.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/user_options.NATIVE.o src/user_options.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/weak_hash.NATIVE.o src/weak_hash.c\nclang -c -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o obj/wordlist.NATIVE.o src/wordlist.c\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nclang: warning: -framework OpenCL: 'linker' input unused\nsrc/autotune.c:286:5: warning: implicit declaration of function 'clear_prompt' is invalid in C99\n      [-Wimplicit-function-declaration]\n    clear_prompt ();\n    ^\nsrc/autotune.c:296:5: warning: implicit declaration of function 'send_prompt' is invalid in C99\n      [-Wimplicit-function-declaration]\n    send_prompt ();\n    ^\n2 warnings generated.\nclang    -framework OpenCL -maes -mpclmul -mrdrnd -msse2 -mssse3 -msse4.2 -mtune=native -Os -Ofast -pipe -W -Wall -std=c99 -DDEBUG -g -ggdb -Iinclude/ -IOpenCL/ -o hashcat obj/affinity.NATIVE.o obj/autotune.NATIVE.o obj/benchmark.NATIVE.o obj/bitmap.NATIVE.o obj/bitops.NATIVE.o obj/combinator.NATIVE.o obj/common.NATIVE.o obj/convert.NATIVE.o obj/cpt.NATIVE.o obj/cpu_aes.NATIVE.o obj/cpu_crc32.NATIVE.o obj/cpu_des.NATIVE.o obj/cpu_md5.NATIVE.o obj/cpu_sha1.NATIVE.o obj/cpu_sha256.NATIVE.o obj/debugfile.NATIVE.o obj/dictstat.NATIVE.o obj/dispatch.NATIVE.o obj/dynloader.NATIVE.o obj/event.NATIVE.o obj/ext_ADL.NATIVE.o obj/ext_nvapi.NATIVE.o obj/ext_nvml.NATIVE.o obj/ext_OpenCL.NATIVE.o obj/ext_xnvctrl.NATIVE.o obj/filehandling.NATIVE.o obj/folder.NATIVE.o obj/hashcat.NATIVE.o obj/hashes.NATIVE.o obj/hlfmt.NATIVE.o obj/hwmon.NATIVE.o obj/induct.NATIVE.o obj/interface.NATIVE.o obj/locking.NATIVE.o obj/logfile.NATIVE.o obj/loopback.NATIVE.o obj/memory.NATIVE.o obj/monitor.NATIVE.o obj/mpsp.NATIVE.o obj/opencl.NATIVE.o obj/outfile_check.NATIVE.o obj/outfile.NATIVE.o obj/potfile.NATIVE.o obj/restore.NATIVE.o obj/rp.NATIVE.o obj/rp_cpu.NATIVE.o obj/rp_kernel_on_cpu.NATIVE.o obj/shared.NATIVE.o obj/status.NATIVE.o obj/stdout.NATIVE.o obj/straight.NATIVE.o obj/terminal.NATIVE.o obj/thread.NATIVE.o obj/timer.NATIVE.o obj/tuningdb.NATIVE.o obj/usage.NATIVE.o obj/user_options.NATIVE.o obj/weak_hash.NATIVE.o obj/wordlist.NATIVE.o src/main.c -DCOMPTIME=1477255471 -DVERSION_TAG=\\\"v3.10-542-ge1010ff+\\\" -DINSTALL_FOLDER=\\\"/usr/local/bin\\\" -DSHARED_FOLDER=\\\"/usr/local/share/hashcat\\\" -DDOCUMENT_FOLDER=\\\"/usr/local/share/doc/hashcat\\\" -lpthread -framework OpenCL -L/opt/local/lib\n$ ./example400.sh \nhashcat (v3.10-542-ge1010ff+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: build_opts '-I /Users/uri/src/oclHashcat/OpenCL -D VENDOR_ID=4 -D CUDA_ARCH=0 -D VECT_SIZE=1 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=1 -D DGST_R2=2 -D DGST_R3=3 -D DGST_ELEM=4 -D KERN_TYPE=400 -D _unroll -cl-std=CL1.1'\nDevice #2: Kernel m00400.1443451c.kernel not found in cache! Building may take a while...\n:20:6: warning: no previous prototype for function 'md5_transform_S'\nvoid md5_transform_S (const u32 w0[4], const u32 w1[4], const u32 w2[4], const u32 w3[4], u32 digest[4])\n     ^\n:118:6: warning: no previous prototype for function 'md5_transform_V'\nvoid md5_transform_V (const u32x w0[4], const u32x w1[4], const u32x w2[4], const u32x w3[4], u32x digest[4])\n     ^\n:411:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n\nDevice #2: Kernel amp_a0.1443451c.kernel not found in cache! Building may take a while...\n\nDevice #2: autotuned kernel-accel to 20                 \nDevice #2: autotuned kernel-loops to 12\nStarting attack in stdin mode...\n\n./example400.sh: line 1: 60061 Done                    cat example.dict\n     60062 Segmentation fault: 11  | ./hashcat -m 400 example400.hash\n$ cat example0.sh\n./hashcat -t 32 -a 7 example0.hash ?a?a?a?a example.dict\n$ lldb hashcat\n(lldb) target create \"hashcat\"\nCurrent executable set to 'hashcat' (x86_64).\n(lldb) run -t 32 -a 7 example0.hash ?a?a?a?a example.dict\nProcess 60100 launched: '/Users/uri/src/oclHashcat/hashcat' (x86_64)\nhashcat (v3.10-542-ge1010ff+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 6494 digests; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: build_opts '-I /Users/uri/src/oclHashcat/OpenCL -D VENDOR_ID=4 -D CUDA_ARCH=0 -D VECT_SIZE=1 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=0 -D _unroll -cl-std=CL1.1'\nDevice #2: Kernel m00000_a1.1443451c.kernel not found in cache! Building may take a while...\n:23:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n:215:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n\nDevice #2: Kernel markov_le.1443451c.kernel not found in cache! Building may take a while...\nGenerated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\nGenerated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\n\nDevice #2: autotuned kernel-accel to 10                 \nDevice #2: autotuned kernel-loops to 12\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => hashcat was compiled with optimization - stepping may behave oddly; variables may not be available.\nProcess 60100 stopped\nthread #5: tid = 0x61ba3, 0x00000001000131ef hashcatcheck_hash(hashcat_ctx=0x0000000100304650, device_param=0x000000010203d2b0, plain=0x00000001007097c0) + 47 at hashes.c:222, stop reason = EXC_BAD_ACCESS (code=1, address=0x70000d09ea70)\n    frame #0: 0x00000001000131ef hashcatcheck_hash(hashcat_ctx=0x0000000100304650, device_param=0x000000010203d2b0, plain=0x00000001007097c0) + 47 at hashes.c:222 [opt]\n   219  void check_hash (hashcat_ctx_t hashcat_ctx, hc_device_param_t device_param, plain_t plain)\n   220  {\n   221    debugfile_ctx_t debugfile_ctx = hashcat_ctx->debugfile_ctx;\n-> 222    loopback_ctx_t  *loopback_ctx  = hashcat_ctx->loopback_ctx;\n   223\n   224    const u32 salt_pos    = plain->salt_pos;\n   225    const u32 digest_pos  = plain->digest_pos;  // relative\n(lldb) bt\nthread #5: tid = 0x61ba3, 0x00000001000131ef hashcat`check_hash(hashcat_ctx=0x0000000100304650, device_param=0x000000010203d2b0, plain=0x00000001007097c0) + 47 at hashes.c:222, stop reason = EXC_BAD_ACCESS (code=1, address=0x70000d09ea70)\nframe #0: 0x00000001000131ef hashcatcheck_hash(hashcat_ctx=0x0000000100304650, device_param=0x000000010203d2b0, plain=0x00000001007097c0) + 47 at hashes.c:222 [opt]\n    frame #1: 0x000000010001364e hashcatcheck_cracked(hashcat_ctx=, device_param=, salt_pos=) + 574 at hashes.c:365 [opt]\n    frame #2: 0x000000010004976e hashcatrun_cracker(hashcat_ctx=0x0000000100304650, device_param=<unavailable>, pws_cnt=<unavailable>) + 1838 at opencl.c:1835 [opt]\n    frame #3: 0x000000010000f983 hashcatthread_calc + 108 at dispatch.c:560 [opt]\n    frame #4: 0x000000010000f917 hashcatthread_calc(p=<unavailable>) + 2055 at dispatch.c:631 [opt]\n    frame #5: 0x00007fffa9b4dabb libsystem_pthread.dylib_pthread_body + 180\n    frame #6: 0x00007fffa9b4da07 libsystem_pthread.dylib_pthread_start + 286\n    frame #7: 0x00007fffa9b4d231 libsystem_pthread.dylibthread_start + 13\n(lldb) print hashcat_ctx\n(hashcat_ctx_t) $1 = {\n  bitmap_ctx = 0x00000001003063a0\n  combinator_ctx = 0x0000000100306400\n  cpt_ctx = 0x0000000100306430\n  debugfile_ctx = 0x0000000100304730\n  dictstat_ctx = 0x0000000100306460\n  event_ctx = 0x0000000101000a00\n  folder_config = 0x0000000100306480\n  hashcat_user = 0x00000001003064b0\n  hashconfig = 0x00000001003064c0\n  hashes = 0x0000000100306520\n  hwmon_ctx = 0x0000000100306590\n  induct_ctx = 0x00000001003065e0\n  logfile_ctx = 0x0000000100306600\n  loopback_ctx = 0x0000000100306620\n  mask_ctx = 0x0000000101001600\n  opencl_ctx = 0x0000000100306640\n  outcheck_ctx = 0x00000001003066b0\n  outfile_ctx = 0x00000001003066c0\n  potfile_ctx = 0x00000001003066e0\n  restore_ctx = 0x0000000100306700\n  status_ctx = 0x0000000100306730\n  straight_ctx = 0x00000001003068c0\n  tuning_db = 0x00000001003068f0\n  user_options_extra = 0x0000000100306920\n  user_options = 0x0000000100306950\n  wl_data = 0x0000000100306ad0\n  event = 0x00000001000699b0 (hashcat`event at main.c:785)\n}\n(lldb) print hashcat_ctx->loopback_ctx\n(loopback_ctx_t) $3 = {\n  enabled = true\n  fp = 0x0000000000000000\n  filename = 0x0000000100205d90 \n}\n(lldb) print *hashcat_ctx->loopback_ctx->filename\n(char) $4 = '\\0'\n(lldb) \n```\n. I observed no difference:\n\n```\nlldb hashcat\n(lldb) target create \"hashcat\"\nCurrent executable set to 'hashcat' (x86_64).\n(lldb) run -t 32 -a 7 example0.hash ?a?a?a?a example.dict\nProcess 41565 launched: '/Users/uri/src/oclHashcat/hashcat' (x86_64)\nhashcat (v3.10-556-g766a113+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 6494 digests; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: build_opts '-I /Users/uri/src/oclHashcat/OpenCL -D VENDOR_ID=4 -D CUDA_ARCH=0 -D VECT_SIZE=1 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=0 -D _unroll -cl-std=CL1.1'\nDevice #2: Kernel m00000_a1.41ca4564.kernel not found in cache! Building may take a while...\n:23:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n:215:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n\nDevice #2: Kernel markov_le.41ca4564.kernel not found in cache! Building may take a while...\nGenerated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\n\nDevice #2: autotuned kernel-accel to 10                 \nDevice #2: autotuned kernel-loops to 12\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => hashcat was compiled with optimization - stepping may behave oddly; variables may not be available.\nProcess 41565 stopped\nthread #5: tid = 0x3ddf8, 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100206ff0, device_param=0x000000010103d2b8, plain=0x0000000100514470) + 47 at hashes.c:220, stop reason = EXC_BAD_ACCESS (code=1, address=0x70000fb1ea70)\n    frame #0: 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100206ff0, device_param=0x000000010103d2b8, plain=0x0000000100514470) + 47 at hashes.c:220 [opt]\n   217  void check_hash (hashcat_ctx_t hashcat_ctx, hc_device_param_t device_param, plain_t plain)\n   218  {\n   219    debugfile_ctx_t debugfile_ctx = hashcat_ctx->debugfile_ctx;\n-> 220    loopback_ctx_t  loopback_ctx  = hashcat_ctx->loopback_ctx;\n   221\n   222    const u32 salt_pos    = plain->salt_pos;\n   223    const u32 digest_pos  = plain->digest_pos;  // relative\n(lldb) print hashcat_ctx->loopback_ctx\n(loopback_ctx_t ) $0 = 0x0000000100208e60\n(lldb) print *hashcat_ctx->loopback_ctx\n(loopback_ctx_t) $1 = {\n  enabled = true\n  unused = false\n  fp = 0x0000000000000000\n  filename = 0x000000010020d3c0 \n}\n(lldb)  bt\nthread #5: tid = 0x3ddf8, 0x0000000100012faf hashcat`check_hash(hashcat_ctx=0x0000000100206ff0, device_param=0x000000010103d2b8, plain=0x0000000100514470) + 47 at hashes.c:220, stop reason = EXC_BAD_ACCESS (code=1, address=0x70000fb1ea70)\nframe #0: 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100206ff0, device_param=0x000000010103d2b8, plain=0x0000000100514470) + 47 at hashes.c:220 [opt]\n    frame #1: 0x000000010001340e hashcatcheck_cracked(hashcat_ctx=, device_param=, salt_pos=) + 574 at hashes.c:363 [opt]\n    frame #2: 0x000000010004958e hashcatrun_cracker(hashcat_ctx=0x0000000100206ff0, device_param=<unavailable>, pws_cnt=<unavailable>) + 1838 at opencl.c:1835 [opt]\n    frame #3: 0x000000010000f733 hashcatthread_calc + 108 at dispatch.c:560 [opt]\n    frame #4: 0x000000010000f6c7 hashcatthread_calc(p=<unavailable>) + 2055 at dispatch.c:631 [opt]\n    frame #5: 0x00007fffe4f24aab libsystem_pthread.dylib_pthread_body + 180\n    frame #6: 0x00007fffe4f249f7 libsystem_pthread.dylib_pthread_start + 286\n    frame #7: 0x00007fffe4f24221 libsystem_pthread.dylibthread_start + 13\n(lldb)\n```\n. Another pull:\n\n```\n$ echo $DEBUG\nyes\n$ lldb ./hashcat\n(lldb) target create \"./hashcat\"\nCurrent executable set to './hashcat' (x86_64).\n(lldb) run -t 32 -a 7 example0.hash ?a?a?a?a example.dict\nProcess 45235 launched: './hashcat' (x86_64)\nhashcat (v3.10-559-g5accadb+) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\n\nHashes: 6494 digests; 6494 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n* Raw-Hash\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #2: build_opts '-I /Users/uri/src/oclHashcat/OpenCL -D VENDOR_ID=4 -D CUDA_ARCH=0 -D VECT_SIZE=1 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=0 -D _unroll -cl-std=CL1.1'\n\nDevice #2: Kernel m00000_a1.41ca4564.kernel not found in cache! Building may take a while...\n:23:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n:215:13: warning: unused variable 'lid'\n  const u32 lid = get_local_id (0);\n            ^\n\n\nDevice #2: Kernel markov_le.41ca4564.kernel not found in cache! Building may take a while...\n\n\nGenerated dictionary stats for example.dict: 1080240 bytes, 129988 words, 136302297088 keyspace\n\nDevice #2: autotuned kernel-accel to 10                 \nDevice #2: autotuned kernel-loops to 12\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => [s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => hashcat was compiled with optimization - stepping may behave oddly; variables may not be available.\nProcess 45235 stopped\nthread #5: tid = 0x563c0, 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100306d90, device_param=0x000000010203d2b8, plain=0x0000000100610ce0) + 47 at hashes.c:227, stop reason = EXC_BAD_ACCESS (code=1, address=0x700002a2ea70)\n    frame #0: 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100306d90, device_param=0x000000010203d2b8, plain=0x0000000100610ce0) + 47 at hashes.c:227 [opt]\n   224  void check_hash (hashcat_ctx_t hashcat_ctx, hc_device_param_t device_param, plain_t plain)\n   225  {\n   226    debugfile_ctx_t debugfile_ctx = hashcat_ctx->debugfile_ctx;\n-> 227    loopback_ctx_t  loopback_ctx  = hashcat_ctx->loopback_ctx;\n   228\n   229    const u32 salt_pos    = plain->salt_pos;\n   230    const u32 digest_pos  = plain->digest_pos;  // relative\n(lldb) print hashcat_ctx->loopback_ctx\n(loopback_ctx_t ) $0 = 0x0000000100308c60\n(lldb) print *hashcat_ctx->loopback_ctx\n(loopback_ctx_t) $1 = {\n  enabled = true\n  unused = false\n  fp = 0x0000000000000000\n  filename = 0x000000010030c980 \n}\n(lldb) bt\nthread #5: tid = 0x563c0, 0x0000000100012faf hashcat`check_hash(hashcat_ctx=0x0000000100306d90, device_param=0x000000010203d2b8, plain=0x0000000100610ce0) + 47 at hashes.c:227, stop reason = EXC_BAD_ACCESS (code=1, address=0x700002a2ea70)\nframe #0: 0x0000000100012faf hashcatcheck_hash(hashcat_ctx=0x0000000100306d90, device_param=0x000000010203d2b8, plain=0x0000000100610ce0) + 47 at hashes.c:227 [opt]\n    frame #1: 0x000000010001340e hashcatcheck_cracked(hashcat_ctx=, device_param=, salt_pos=) + 574 at hashes.c:370 [opt]\n    frame #2: 0x000000010004954e hashcatrun_cracker(hashcat_ctx=0x0000000100306d90, device_param=<unavailable>, pws_cnt=<unavailable>) + 1838 at opencl.c:1835 [opt]\n    frame #3: 0x000000010000f713 hashcatthread_calc + 108 at dispatch.c:560 [opt]\n    frame #4: 0x000000010000f6a7 hashcatthread_calc(p=<unavailable>) + 2055 at dispatch.c:631 [opt]\n    frame #5: 0x00007fffe4f24aab libsystem_pthread.dylib_pthread_body + 180\n    frame #6: 0x00007fffe4f249f7 libsystem_pthread.dylib_pthread_start + 286\n    frame #7: 0x00007fffe4f24221 libsystem_pthread.dylibthread_start + 13\n(lldb)\n```\n\nDo you want me to check any other values?\n. @matrix your fork seems to work just fine! Thank you!\n```\n. . . . .\nSession........: hashcat\nStatus.........: Quit\nHash.Type......: MD5\nHash.Target....: example0.hash\nTime.Started...: Thu Oct 27 19:43:15 2016 (5 mins, 29 secs)\nTime.Estimated.: Thu Oct 27 20:01:46 2016 (13 mins, 2 secs)\nInput.Base.....: File (example.dict), Right Side\nInput.Mod......: Mask (?a?a?a?a), Left Side\nSpeed.Dev.#2...:   122.9 MH/s (8.68ms)\nRecovered......: 1342/6494 (20.67%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:244.58,14675.01,352200.16 (Min,Hour,Day)\nProgress.......: 40110489600/136302297088 (29.43%)\nRejected.......: 0/40110489600 (0.00%)\nRestore.Point..: 0/129988 (0.00%)\nCandidates.#2..: rkv30 -> 4m4epocossi\nStarted: Thu Oct 27 19:43:11 2016\nStopped: Thu Oct 27 19:48:45 2016\n```\n(progress 29% because it outputs cracked hashes to stdout, and I stopped it pressing \"q\")\nThe original repo build of course still crashes. So @jsteube would do well to merge your changes, I think.\n. @jsteube here's result of git bisect:\n```\n$ git bisect good\n88565b4a5e3b162f5e891bb55e6b58f48f55080a is the first bad commit\ncommit 88565b4a5e3b162f5e891bb55e6b58f48f55080a\nAuthor: jsteube jens.steube@gmail.com\nDate:   Sat Oct 8 23:38:34 2016 +0200\nSwitch CPU affinity stuff to event_log_*\n\n:040000 040000 c7875c857ea288582e5e6b1237df245b034d243d d6458818bf8ad0d223e3b0e9f9ad71626f2726f3 M  include\n:040000 040000 7dea60bc385cb32356749478bb33d5b8a16a1e9c 7af190f6b1e6e368a31491543890a34440adc1b0 M  src\n$\n```\nSeveral commits after this one don't even compile on Mac OS X, and those subsequent ones that do - crash on execution.\nHere's an example of how compilation was failing:\n. . . . .\nsrc/affinity.c:32:12: note: expected 'size_t {aka long unsigned int}' but argument is of type 'cpu_set_t * {aka struct cpu_set *}'\n static int pthread_setaffinity_np (hashcat_ctx_t *hashcat_ctx, pthread_t thread, size_t cpu_size, cpu_set_t *cpu_set)\n            ^~~~~~~~~~~~~~~~~~~~~~\nsrc/affinity.c:115:7: error: too few arguments to function 'pthread_setaffinity_np'\n   if (pthread_setaffinity_np (thread, sizeof (cpu_set_t), &cpuset) == -1)\n       ^~~~~~~~~~~~~~~~~~~~~~\nsrc/affinity.c:32:12: note: declared here\n static int pthread_setaffinity_np (hashcat_ctx_t *hashcat_ctx, pthread_t thread, size_t cpu_size, cpu_set_t *cpu_set)\n            ^~~~~~~~~~~~~~~~~~~~~~\nmake: *** [obj/affinity.NATIVE.o] Error 1\nmake: *** Waiting for unfinished jobs....\nsrc/folder.c: In function 'scan_directory':\nsrc/folder.c:168:26: error: 'hashcat_ctx' undeclared (first use in this function)\n         event_log_error (hashcat_ctx, \"ERROR: readdir_r() failed\");\n                          ^~~~~~~~~~~\nsrc/folder.c:168:26: note: each undeclared identifier is reported only once for each function it appears in\nmake: *** [obj/folder.NATIVE.o] Error 1\n$ git status\nHEAD detached at 0f96c57\nYou are currently bisecting, started from branch '2d5c65f'\n. . . . .\nHope this helps.\nP.S. I'd like to know why on Apple you don't use -framework OpenCL but pull Khronos OpenCL headers instead.\n. # Timing comparison\noclHashcat commit 42677df\n```\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Left.....: Mask (?a?a?a?a) [4]\nInput.Right....: File (example.dict)\nHash.Target....: File (example0.hash)\nHash.Type......: MD5\nTime.Started...: Fri Oct 28 21:59:02 2016 (19 mins, 6 secs)\nCandidates.#2..: [Copying]\nSpeed.Dev.#2...:   101.9 MH/s (2.22ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:16,N/A,N/A AVG:93.43,5605.95,134542.81 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nStarted: Fri Oct 28 21:59:02 2016\nStopped: Fri Oct 28 22:18:11 2016 \n$ git status\nHEAD detached at 42677df\n```\nhashcat current master\n```\nSession........: hashcat\nStatus.........: Exhausted\nHash.Type......: MD5\nHash.Target....: example0.hash\nTime.Started...: Fri Oct 28 22:22:11 2016 (19 mins, 15 secs)\nTime.Estimated.: Fri Oct 28 22:41:26 2016 (0 secs)\nInput.Base.....: File (example.dict), Right Side\nInput.Mod......: Mask (?a?a?a?a), Left Side\nSpeed.Dev.#2...:   107.1 MH/s (2.22ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:44.04,2642.42,63418.05 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nRestore.Point..: 129988/129988 (100.00%)\nCandidates.#2..: i4xkpoczta115 -> z4xkzzzzzzzzzzz\nStarted: Fri Oct 28 22:22:09 2016\nStopped: Fri Oct 28 22:41:27 2016\n```\nUpdate - current master v2\nSession........: hashcat\nStatus.........: Exhausted\nHash.Type......: MD5\nHash.Target....: example0.hash\nTime.Started...: Sat Oct 29 19:15:48 2016 (19 mins, 9 secs)\nTime.Estimated.: Sat Oct 29 19:34:57 2016 (0 secs)\nInput.Base.....: File (example.dict), Right Side\nInput.Mod......: Mask (?a?a?a?a), Left Side\nSpeed.Dev.#2...:   111.0 MH/s (2.22ms)\nRecovered......: 2190/6494 (33.72%) Digests, 0/1 (0.00%) Salts\nRecovered/Time.: CUR:0,N/A,N/A AVG:0.00,0.00,0.00 (Min,Hour,Day)\nProgress.......: 136302297088/136302297088 (100.00%)\nRejected.......: 0/136302297088 (0.00%)\nRestore.Point..: 129988/129988 (100.00%)\nCandidates.#2..: i4xkpoczta115 -> z4xkzzzzzzzzzzz\nOnly three seconds longer than oclHashcat (last non-crashing commit).\n. > Can you please retry with latest commits?\nI just did - and everything (including Recovered/Time) seems to be working fine!  Thank you! Efforts of @matrix and @jsteube are much appreciated.\n. @jsteube one thing more: the current oclHashcat master cannot be compiled with Macports-installed gcc because of the assembler issues. Two possible solutions are:\n- For Darwin detect that GCC is Macports-installed, and then add -Wa,-q flag to CFLAGS. This is a bit cumbersome, among other reasons because Macports people insist that there must be no differentiator between \"standard\" GNU GCC and its Macports port.\n- For Darwin set the compiler to clang instead of gcc. This appears to be a much better solution - and it works (clang is the default Xcode compiler). That's what I compiled the master with.\nHere's the patch that I urge you to merge:\n```\ndiff --git a/src/Makefile b/src/Makefile\nindex 0b28ea5..2f7fd08 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -134,6 +134,7 @@ endif # FreeBSD\nifeq ($(UNAME),Darwin)\n export MACOSX_DEPLOYMENT_TARGET=10.9\n+CC                      := clang\n CFLAGS_NATIVE           := $(CFLAGS)\n CFLAGS_NATIVE           += -framework OpenCL\n CFLAGS_NATIVE           += -march=native\n```\n. @jsteube thank you!\n. > That solution slows down cracking massive...\nAs compared to crashing with SEGV...?\n. > > That solution slows down cracking massive...\n\nif my patch slow down the cracking speed we can't use it, also if without got a segfault\n\nAs my timing shows, that patch does slow things up, but by no means \"massive\". The difference appeared to be be between 19 minutes and 15 seconds, and 19 minutes and 6 seconds. Not overwhelming.\nNow trying your v2 (currently running :).\n\nIf you need hashcat for some particular reason you can use my repo temporarily until we solve the bug in the best way possible\n\nBoth are fine (waiting for the best solution, and using your repo for now). I am not in any rush. Initially I stumbled upon this project as a good way to exercise OpenCL.\n\nor switch to linux solution\n\nSorry, impractical for me. And I'm not that eager to run Linux in a virtual machine.\n\nSorry all for later response but yesterday I woke up with fever :( I'm sick ... grrr\n\nWish you to get healthy soon!\nAlso, I hope my findings (like, where the first Mac OS X-related failure came about) can be of use:\nhttps://github.com/hashcat/hashcat/issues/508#issuecomment-257064018\nUpdate\nThe current hashcut master (not oclHashcat) runs example0.sh in 19 minutes 9 seconds - only three seconds longer than the oclHashcat (when it doesn't crash :).\n. This is a change to accommodate Mac OS X OpenCL framework:\n```\ndiff --git a/src/Makefile b/src/Makefile\nindex 8c9f2d6..8b7cdd5 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -94,7 +94,7 @@ VERSION_TAG              := $(shell test -d .git && git describe --tags --dirty=\n ## Compiler flags\n ##\n-INCLUDE_PATHS            := -Iinclude/ -IOpenCL/ -I$(OPENCL_HEADERS_KHRONOS)/\n+INCLUDE_PATHS            := -Iinclude/ -IOpenCL/\nCFLAGS                   += -pipe -W -Wall -std=c99\n@@ -123,10 +123,12 @@ BINARY_NATIVE            := $(PROG_NAME)\nifeq ($(UNAME),Darwin)\n export MACOSX_DEPLOYMENT_TARGET=10.9\n-CFLAGS_NATIVE            :=\n+CFLAGS_NATIVE            := -framework OpenCL\n CFLAGS_NATIVE            += $(CFLAGS)\n-LFLAGS_NATIVE            := -lpthread\n+LFLAGS_NATIVE            := -lpthread -framework OpenCL\n LFLAGS_NATIVE            += $(LDFLAGS)\n+else\n+INCLUDE_PATHS            += -I$(OPENCL_HEADERS_KHRONOS)/\n endif # darwin\nifeq ($(UNAME),Linux)\n```\nI'd appreciate if you could merge it. I took care to make sure that neither Linux nor FreeBSD would be impacted by this change.\nAlso, 1df6ca2 works (just tested). Will provide timing later.\n. @matrix and @jsteube thank you - it works now with the latest/current master oclHashcat.\n. ",
    "hlein": "Sweet, thanks!\n. ",
    "jackpit110": "server to client auth_sesskey --> 22E8FA41826608560F0B2A713724689F3D28640577B511B9C36178418C138210D820F7800C14C579D5094F4BBB0E0EBD\nAUTH_VFR_DATA(salt) from server-->  A0F9FC5E0D992692AA35\ncllent to server password AUTH_PASSWORD  --> 5ECC855E89402343D75CA84630222EC0B677929CFFDE91FB0F2EA3BDCEEDAAE9\nclient to server AUTH_SESSKEY -->  0F8D4466C0B1A5B9FA68A63B94EB2BA23F222678D7969C2348ADF52C58D1D21D F290794A5208EDD12D0EF71A88687FF4\nusername: SCOTT\npassword: 123456\ngithub.zip\n. server to client  AUTH_SESSKEY -->  646D71DD423BBC488ECFFFE411469A723FC1FDB80538C3D8299ADAF96BDE50B1 213573DD50A561D83CE5E7AA91D31C10\nAUTH_VFR_DATA --> 5E1946B0BF37A4158734\nAUTH_PASSWORD--> 28C069AACF37276B170847367CF93899EDC0B99DAE0568B3BECDC944161DDF70\nAUTH_SESSKEY--> C7B41941339229F54399DCB8D82C820D02636416CA41ACC53CF4A6C423BD6F7D 35C382D6C913FAB6965105DF05FEB076\nusername:SCOTT\npass: scott\ngithub2.zip\n. The user creates his/her password hash, this hash is then used as the key to decrypt the AUTH_SESSKEY.\nAUTH_SESSKEY is 48 bytes long. It is sent in two parts. Every string in the packets begins with its length. The first part is 32 bytes long the second is 16 bytes. \nauth_sesskey encrption is  AES with 192 bits key. key is user password hash. so\nAUTH_SESSKEY from server = aes192(random number with padding)  with key sha1(password+salt)\nmemcpy(data,pwd,strlen((char_)pwd));\nmemcpy(data+strlen((char_)pwd),salt,10);\nSHA1(data,strlen((char*)pwd)+10,md);\nhash is sha1= hash is only 160 bits long, but four 0 bytes is added at the end of the hash\nwe can check successful decryption with checking padding in auth_sesskey that i think its not working for ver 12. and after successful decryption we can check again with other data(decrypt auth_password with both  AUTH_SESSKEY and check password)\nThe two  AUTH_SESSKEY  is combined by the client to generate the key for the password encryption.\n. i generated pcaps with your passwords\nalso attached password from db(sys.user$) may be help.\nhashcat.zip\n. wow. very good.\nyou are wonderfull. thanks\noracle protocol is not documented. so unfortunately manipulation is hard. unless reverse engineer or go with test and try. \n. @magnumripper \ncheck this(pages 19,20,21): \nhttp://www.ekoparty.org/archive/2012/PPT-Cryptographic_flaws_in_Oracle_Database_auth_protocol_v6.pdf\ni know that client  and server negotiate versions we can check them,  but may be there is a signature too.we need version 12 pcap to investigate for easier way to detect . with both forced ver 12 and without it.\n. @magnumripper   there is multiple packet containing version related info.\n1. packet contain supported versions. 2. client and server version 3. server banner 4.auth_version\nsome of the then is after successful authentication. we should consider them as a second option. because some of attacks that are not using full authentication.\n. @jsteube   when can we see o5logon in hashcat?\n. pass: hashcat\nold client connect to oracle12\noracle12.zip\n. @jsteube   could you please share your program for decrypting auth_sesskey?\ndid you see any difference between 11 and 12 pcap files?\n. @jsteube   thanks\n@magnumripper   i am installing different server version 8 - 12 . and also clients. i wiil upload cap files.good reference for researchers. \nhttp://dba.stackexchange.com/questions/69045/sqlnet-allowed-logon-version-12-and-jdbc-thin-client\n. @magnumripper   no. username is sys. and connected as sysdba\n. @magnumripper   i found sysdba byte \ndeleted\n. @magnumripper  username is always in packet containing AUTH_PASSWORD.\nin cap files that i saw, some times auth_password and auth_sesskey order is not same. some times it is auth_sesskey and then auth_password.\nand also before AUTH_TERMINAL is username.in oracle 12 pcap also you can see sys username.\n. @magnumripper   ok i checked again in my cap files.\nbefore auth_terminal we have different constant bytes\n0d 00 00 00 0d\nor\n01 0d 0d\ncheck each one and then before this bytes we can find username \n. jtr is not able to crack oracle 12 cap.\n@jsteube   i am not able to crack with your perl. \n. @magnumripper   i checked all possible version with ora 11 client\nSQLNET.ALLOWED_LOGON_VERSION=12\n there was no difference\nand then i tested client 9 and server 12. i was not able to connect to ora 12\nafter setting it to 8 it is ok\nso even after setting versions, oracle tends to use highest available version.\n. @jsteube  i was just curious about padding. i wrote a program for this . oracle 12 pcap dose not contain padding.\nso to detect presence of padding we should check client version, if version is  11.2.0.3/11.2.0.4  or above that we know there is not padding.\nyou guys need any more info?\n. check this:\noracle-12c-client-to-10g-server\noracle 10.2.0 can connect to 12 \noracle 10.1.0 can not connect to 12\nwe should check for which versions they released patch:\nCVE-2012-3137\noracle patch\nthis versions patched:\n10.2.0.3, 10.2.0.4, 10.2.0.5, 11.1.0.7, 11.2.0.2, 11.2.0.3\nso why those documents say 11.2.0 ?? may be those are before patch release.\nEdit: now with version 10.1 we know there is not random padding.\n i am connecting with same client to ver 11 and 12. one with random and another without. so how server knows use random padding?\nwe should check other bytes in communication.\n. now what is it??\n00000B37  01 0b 00 00 06 00 00 00  00 00 08 03 00 0c 00 00 ........ ........\n    00000B47  00 0c 41 55 54 48 5f 53  45 53 53 4b 45 59 40 00 ..AUTH_S ESSKEY@.\n    00000B57  00 00 40 45 45 45 44 44  37 43 33 37 33 38 38 46 ..@EEEDD 7C37388F\n    00000B67  35 30 39 33 45 30 36 32  36 44 34 35 35 32 35 31 5093E062 6D455251\n    00000B77  35 33 35 34 43 34 30 46  38 33 43 44 39 38 43 30 5354C40F 83CD98C0\n    00000B87  44 32 31 32 38 36 34 41  36 38 32 31 38 32 30 39 D212864A 68218209\n    00000B97  39 44 45 00 00 00 00 0d  00 00 00 0d 41 55 54 48 9DE..... ....AUTH\n    00000BA7  5f 56 46 52 5f 44 41 54  41 00 00 00 00 39 09 00 _VFR_DAT A....9..\n    00000BB7  00 1a 00 00 00 1a 41 55  54 48 5f 47 4c 4f 42 41 ......AU TH_GLOBA\n    00000BC7  4c 4c 59 5f 55 4e 49 51  55 45 5f 44 42 49 44 00 LLY_UNIQ UE_DBID.\nEdit: Oracle 10g TNS AES-128 authentication. client connecting to oracle 11.2.0 server\n@magnumripper  your ettercap cannot detect this, also has problem with client version.server version is ok on this pcap file.\n. @magnumripper  check this pcap. when you connect to oracle 12 server from unpatched client, server falls back to oracle 10 protocol. notice to salt and auth_sesskey length.\noracle_11_12.zip\n. @magnumripper   o3logon is in oracle 8. i dont know why it first uses ntlm. after that it is ora 10.\noracle 10 is more secure than oracle 11 with 0808 padding\nEdit: in my older pcaps i used sqldeveloper that it is using jdbc (java driver). in last one it is sqlplus.\n. yes it is fixed in hashcat-3.30+155.7z\nthx. @Fist0urs\nwe need more than 50k. could you give me a clue. i am in a hurry.\nhttps://github.com/hashcat/hashcat/pull/282\n.  OpenCL/types_ocl.c in old version is 50kb\nu32 contents[12500];\nand in new increased to 300000 bytes\nu32 contents[75000];\nAlso other parts like maxlen increased but below line in src/interface.c is still 50000. i think this part should be increased\nif (contents_len > 50000) return (PARSER_SALT_LENGTH);\nI increased these parts but hashcat still can not load large hash.. ok\ni have increased HCBUFSIZ_LARGE, now i can load my hash. problem is that i have not enough resources.\nEDIT: clEnqueueWriteBuffer(): CL_OUT_OF_RESOURCES\nso below line should be changed and warn based on HCBUFSIZ_LARGE or \"u32 contents\"\nif (contents_len > 50000) return (PARSER_SALT_LENGTH);\n50000 is 50 kb file that Fist0urs added.\nshould i buy new hardware?. Hi\nthanks i need maximum   600kb hash file, and 300kb is my kdb file.\ni have fixed input hash but i am getting that error about resources.\nmay be i did wrong.\n300k is in new version of hashcat, but this line should be fixed:\nif (contents_len > 50000) return (PARSER_SALT_LENGTH);. ",
    "ahmedeissa1": "thx\ni will close this issue\n. ",
    "derhornspieler": "For some reason I am getting compiler errors with the updated versions from github.\nCheers,\nJames\n. worked like a charm with the make command. Cheers!!\n. ",
    "emax73": "Same result:\nat adding 2 digits: Status: Exhausted\n. your variant are working,\ncan I sent by e-mail to you my not working variant? \n. your e-mail please?\n. sent to you not working variant\n. sent just one,\npassword to arhive: password\n. How avoid this feature?\nAfter adding rules to basis lenght of testing passwords becoming valid WPA\n. If I remember, CPU version of HashCat not have that feature\n. Thanks you for suggested spikes, now I know reason, why I not able pen-test self Wi-Fi\n. ",
    "devils-advocate213": "Well, that gets rid of the first error, but doesn't provide a correct calculation.\nHere's an example:\n./oclHashcat64.bin -m 2500 SSID.hccap english_and_1_to_4.txt -r /home/user/Desktop/oclHashcat-2.01/princeprocessor-master/rules/prince_optimized.rule --keyspace --session=keyspace\nShouldn't it multiply the number of lines in english_and_1_to_4.txt by the number of rules applied in the rule file and give a number?  It only provides the number of lines in english_and_1_to_4.txt.\n. Why should it?  Good question.  Answer: to provide a more accurate number for how many keys/passwords will be tried given the dictionary input and any rules that might be applied.\nThe problem is this. \"cat english_and_1_to_4.txt | wc -l\" gives the same number as this: \"./oclHashcat64.bin -m 2500 RB.hccap english_and_1_to_4.txt -r /home/user/Desktop/oclHashcat-2.01/princeprocessor-master/rules/prince_optimized.rule --keyspace --session=keyspace\"\nThe rules in the rule file aren't accounted for at all, it seems.\nI suppose this has to be done manually.  One of the above commands will do for a line count of the input dictionary file.\nSome command line will give me the other number.\ncat prince_optimized.rule | grep -v ^# | grep -v \"^[[:space:]]*$\" | wc -l\nIt is simple multiplication from there.  line_count_of_dictionary_file * number_of_rules\nAfter reading the FAQ, I notice that the CPU version of hashcat actually does exactly this.  Was that small feature going to make its way over to oclHashcat at some point?  It would be nice.\n. line 2 under hashcat says this:  -a 0 + rules \u2013 number of words in wordlist multiplied by number of rules in rule file\nIt seems hashcat already has it, but oclHashcat does not.\n. Admittedly, I am just going off the entries that are listed in the FAQ that was linked.  I was looking at line 2 for both hashcat and oclHashcat and noticed that difference between hashcat and oclHashcat.  Just going off the FAQ, it seems rules aren't factored in for oclHashcat.  I might go do a diff on the source between the two and see what I can find.\nThanks anyway.\n. ",
    "blazer2x": "update: It is the final exhausted status that is suppressed\n. ",
    "zimbatm": "Aha, thanks for guiding me trough this. So after running gdb with the gdb symbols enabled I get:\n```\n0  0x00007ffff76a50be in __strcmp_sse2_unaligned ()\nfrom /nix/store/763vw2zyc9434dj7rw6c2kczj0blvssy-glibc-2.23/lib/libc.so.6\n1  0x000000000040eef5 in main (argc=1, argv=0x7fffffffc578) at src/hashcat.c:6147\n```\nWhich is a strcmp to the install dir: https://github.com/hashcat/hashcat/blob/v3.00/src/hashcat.c#L6147\n```\n(gdb) up\n1  0x000000000040eef5 in main (argc=1, argv=0x7fffffffc578) at src/hashcat.c:6147\n6147    src/hashcat.c: No such file or directory.\n(gdb) print install_dir\n$1 = 0x8b2820 \"/nix/store/n3jkx4pn284c4063d0kks3z2v5si0whd-hashcat-3.00/bin\"\n(gdb) print resolved_install_folder\n$2 = 0x0\n```\nSo the issue is that realpath(INSTALL_FOLDER, NULL) returns null and if the folder doesn't exist, hashcat doesn't handle that case.\nThis was triggered by me first running make (so INSTALL_FOLDER would default to /usr/local/bin) and then make install PREFIX=$out where out=/nix/store/... and also because NixOS is unusual and that /usr/local/bin doesn't exist.\n. Thanks.\nDo you mind me asking if hashcat 3.0.0 is able to work without OpenCL? hashcat 2.0.0 was working fine but 3.0.0 fails with ERROR: clGetPlatformIDs() : -1001 : CL_UNKNOWN_ERROR. I did a bit of strace and it's trying to look into /etc/OpenCL/vendors which doesn't exist on my system. I tried various command-line options like switching the device type but no luck so far.\n. @initbar can you try running strace hashcat? Also what is the content of /etc/OpenCL/vendors?\n. ",
    "initbar": "@jsteube I think you were right - double checking OpenCL headers and recompiling hashcat from source raised fatal error: CL/cl.h: No such file or directory :sweat: From that point, I continue to install opencl-headers from the available packages and was able to successfully compile and run the benchmarks!\n\nBTW: which linux is that?\n\nI'm currently experimenting with Xubuntu 16.04 (Linux KAR0VD 4.4.0-28-generic #47-Ubuntu SMP Fri Jun 24 10:09:13 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux) before returning back to Debian.\n@zimbatm strace results:\nKAR0VD :: /tmp/sandbox/hashcat \u00bb strace -v ./hashcat\nexecve(\"./hashcat\", [\"./hashcat\"], [\"SESSION_MANAGER=local/KAR0VD:@/t\"..., \"XDG_SESSION_ID=c1\", \"XDG_SEAT=seat0\", \"DISPLAY=:0.0\", \"UPSTART_JOB=startxfce4\", \"GTK_OVERLAY_SCROLLING=0\", \"COLORTERM=gnome-terminal\", \"JOB=dbus\", \"GNOME_KEYRING_CONTROL=\", \"INSTANCE=\", \"DEFAULTS_PATH=/usr/share/gconf/x\"..., \"LOGNAME=kl1mn3tt0r\", \"SHELL=/usr/bin/zsh\", \"PATH=/usr/local/sbin:/usr/local/\"..., \"IM_CONFIG_PHASE=1\", \"QT4_IM_MODULE=xim\", \"CLUTTER_IM_MODULE=xim\", \"GLADE_MODULE_PATH=:\", \"XDG_SESSION_PATH=/org/freedeskto\"..., \"SESSION=xubuntu\", \"XDG_MENU_PREFIX=xfce-\", \"SSH_AUTH_SOCK=/run/user/1000/key\"..., \"XAUTHORITY=/home/kl1mn3tt0r/.Xau\"..., \"XDG_SESSION_DESKTOP=xubuntu\", \"GDMSESSION=xubuntu\", \"UPSTART_EVENTS=started xsession\", \"QT_IM_MODULE=ibus\", \"XMODIFIERS=@im=ibus\", \"XDG_CONFIG_DIRS=/etc/xdg/xdg-xub\"..., \"MANDATORY_PATH=/usr/share/gconf/\"..., \"UPSTART_SESSION=unix:abstract=/c\"..., \"XDG_RUNTIME_DIR=/run/user/1000\", \"DESKTOP_SESSION=xubuntu\", \"GTK_IM_MODULE=xim\", \"QT_STYLE_OVERRIDE=gtk\", \"IBUS_DISABLE_SNOOPER=1\", \"USER=kl1mn3tt0r\", \"PWD=/tmp/sandbox/hashcat\", \"TERMINATOR_UUID=urn:uuid:d067a90\"..., \"UPSTART_INSTANCE=\", \"GLADE_PIXMAP_PATH=:\", \"HOME=/home/kl1mn3tt0r\", \"QT_ACCESSIBILITY=1\", \"ORBIT_SOCKETDIR=/tmp/orbit-kl1mn\"..., \"XDG_SEAT_PATH=/org/freedesktop/D\"..., \"XDG_DATA_DIRS=/usr/share/xubuntu\"..., \"LANGUAGE=en_US.UTF-8\", \"XDG_GREETER_DATA_DIR=/var/lib/li\"..., \"CLUTTER_BACKEND=x11\", \"LANG=en_US.UTF-8\", \"GLADE_CATALOG_PATH=:\", \"GPG_AGENT_INFO=/home/kl1mn3tt0r/\"..., \"SHLVL=1\", \"WINDOWID=56623108\", \"XDG_VTNR=7\", \"GDM_LANG=en_US\", \"TERM=xterm-256color\", \"DBUS_SESSION_BUS_ADDRESS=unix:ab\"..., \"XDG_CURRENT_DESKTOP=XFCE\", \"SESSIONTYPE=\", \"GNOME_KEYRING_PID=\", \"QT_LINUX_ACCESSIBILITY_ALWAYS_ON\"..., \"XDG_SESSION_TYPE=x11\", \"OLDPWD=/tmp/sandbox\", \"EDITOR=emacs24-nox\", \"LC_ALL=en_US.UTF-8\", \"GREP_COLOR=97;45\", \"LESS_TERMCAP_mb=\\33[01;31m\", \"LESS_TERMCAP_md=\\33[01;35m\", \"LESS_TERMCAP_me=\\33[0m\", \"LESS_TERMCAP_se=\\33[0m\", \"LESS_TERMCAP_so=\\33[01;33m\", \"LESS_TERMCAP_ue=\\33[0m\", \"LESS_TERMCAP_us=\\33[04;36m\", \"LS_COLORS=:di=1;91::di=1;91:\", \"WPATH=/tmp/wine_sandbox/\", \"ZSH=/home/kl1mn3tt0r/.env/zsh/oh\"..., \"PAGER=less\", \"LESS=-R\", \"LSCOLORS=Gxfxcxdxbxegedabagacad\", \"_=/usr/bin/strace\"]) = 0\nbrk(NULL)                               = 0x2734000\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nmmap(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f44b12a9000\naccess(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/etc/ld.so.cache\", O_RDONLY|O_CLOEXEC) = 3\nfstat(3, {st_dev=makedev(252, 1), st_ino=22549634, st_mode=S_IFREG|0644, st_nlink=1, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=264, st_size=132096, st_atime=2016/07/01-15:15:17.205011903, st_mtime=2016/07/01-15:15:17.009014626, st_ctime=2016/07/01-15:15:17.057013960}) = 0\nmmap(NULL, 132096, PROT_READ, MAP_PRIVATE, 3, 0) = 0x7f44b1288000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/lib/x86_64-linux-gnu/libpthread.so.0\", O_RDONLY|O_CLOEXEC) = 3\nread(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\360`\\0\\0\\0\\0\\0\\0\"..., 832) = 832\nfstat(3, {st_dev=makedev(252, 1), st_ino=22151211, st_mode=S_IFREG|0755, st_nlink=1, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=272, st_size=138744, st_atime=2016/07/01-13:12:24.864745878, st_mtime=2016/04/14-18:16:58, st_ctime=2016/06/04-18:07:03.186384890}) = 0\nmmap(NULL, 2212904, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f44b0e69000\nmprotect(0x7f44b0e81000, 2093056, PROT_NONE) = 0\nmmap(0x7f44b1080000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x17000) = 0x7f44b1080000\nmmap(0x7f44b1082000, 13352, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f44b1082000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/lib/x86_64-linux-gnu/libdl.so.2\", O_RDONLY|O_CLOEXEC) = 3\nread(3, \"\\177ELF\\2\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0\\240\\r\\0\\0\\0\\0\\0\\0\"..., 832) = 832\nfstat(3, {st_dev=makedev(252, 1), st_ino=22151213, st_mode=S_IFREG|0644, st_nlink=1, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=32, st_size=14608, st_atime=2016/07/01-13:12:24.864745878, st_mtime=2016/04/14-18:16:46, st_ctime=2016/06/04-18:07:03.186384890}) = 0\nmmap(NULL, 2109680, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f44b0c65000\nmprotect(0x7f44b0c68000, 2093056, PROT_NONE) = 0\nmmap(0x7f44b0e67000, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x2000) = 0x7f44b0e67000\nclose(3)                                = 0\naccess(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory)\nopen(\"/lib/x86_64-linux-gnu/libc.so.6\", O_RDONLY|O_CLOEXEC) = 3\nread(3, \"\\177ELF\\2\\1\\1\\3\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0>\\0\\1\\0\\0\\0P\\t\\2\\0\\0\\0\\0\\0\"..., 832) = 832\nfstat(3, {st_dev=makedev(252, 1), st_ino=22151212, st_mode=S_IFREG|0755, st_nlink=1, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=3648, st_size=1864888, st_atime=2016/07/01-13:07:50.301129031, st_mtime=2016/04/14-18:16:46, st_ctime=2016/06/04-18:07:03.186384890}) = 0\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f44b1287000\nmmap(NULL, 3967488, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x7f44b089c000\nmprotect(0x7f44b0a5c000, 2093056, PROT_NONE) = 0\nmmap(0x7f44b0c5b000, 24576, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x1bf000) = 0x7f44b0c5b000\nmmap(0x7f44b0c61000, 14848, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x7f44b0c61000\nclose(3)                                = 0\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f44b1286000\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f44b1285000\nmmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f44b1284000\narch_prctl(ARCH_SET_FS, 0x7f44b1285700) = 0\nmprotect(0x7f44b0c5b000, 16384, PROT_READ) = 0\nmprotect(0x7f44b0e67000, 4096, PROT_READ) = 0\nmprotect(0x7f44b1080000, 4096, PROT_READ) = 0\nmprotect(0x7f44b12ab000, 4096, PROT_READ) = 0\nmunmap(0x7f44b1288000, 132096)          = 0\nset_tid_address(0x7f44b12859d0)         = 24201\nset_robust_list(0x7f44b12859e0, 24)     = 0\nrt_sigaction(SIGRTMIN, {0x7f44b0e6eb90, [], SA_RESTORER|SA_SIGINFO, 0x7f44b0e7a3d0}, NULL, 8) = 0\nrt_sigaction(SIGRT_1, {0x7f44b0e6ec20, [], SA_RESTORER|SA_RESTART|SA_SIGINFO, 0x7f44b0e7a3d0}, NULL, 8) = 0\nrt_sigprocmask(SIG_UNBLOCK, [RTMIN RT_1], NULL, 8) = 0\ngetrlimit(RLIMIT_STACK, {rlim_cur=8192*1024, rlim_max=RLIM64_INFINITY}) = 0\nbrk(NULL)                               = 0x2734000\nbrk(0x2755000)                          = 0x2755000\numask(077)                              = 02\nreadlink(\"/proc/24201/exe\", \"/tmp/sandbox/hashcat/hashcat\", 1023) = 28\nlstat(\"/usr\", {st_dev=makedev(252, 1), st_ino=24772609, st_mode=S_IFDIR|0755, st_nlink=13, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=8, st_size=4096, st_atime=2016/06/30-15:42:15.655338291, st_mtime=2016/06/22-01:52:51.771016067, st_ctime=2016/06/22-01:52:51.771016067}) = 0\nlstat(\"/usr/local\", {st_dev=makedev(252, 1), st_ino=24903953, st_mode=S_IFDIR|0755, st_nlink=15, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=8, st_size=4096, st_atime=2016/07/01-15:13:51.498203519, st_mtime=2016/06/30-12:28:06.879352659, st_ctime=2016/06/30-12:28:06.879352659}) = 0\nlstat(\"/usr/local/bin\", {st_dev=makedev(252, 1), st_ino=24903956, st_mode=S_IFDIR|0755, st_nlink=2, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=8, st_size=4096, st_atime=2016/06/30-21:42:15.690053343, st_mtime=2016/06/30-21:38:46.611144916, st_ctime=2016/06/30-21:38:46.611144916}) = 0\nlstat(\"/tmp\", {st_dev=makedev(0, 39), st_ino=2, st_mode=S_IFDIR|S_ISVTX|0777, st_nlink=18, st_uid=0, st_gid=0, st_blksize=4096, st_blocks=0, st_size=500, st_atime=2016/07/01-15:17:51.486871409, st_mtime=2016/07/01-15:21:38.843724989, st_ctime=2016/07/01-15:21:38.843724989}) = 0\nlstat(\"/tmp/sandbox\", {st_dev=makedev(0, 39), st_ino=19, st_mode=S_IFDIR|0700, st_nlink=3, st_uid=1000, st_gid=1000, st_blksize=4096, st_blocks=0, st_size=60, st_atime=2016/07/01-15:21:27.215885732, st_mtime=2016/07/01-15:20:10.016953355, st_ctime=2016/07/01-15:20:10.016953355}) = 0\nlstat(\"/tmp/sandbox/hashcat\", {st_dev=makedev(0, 39), st_ino=146, st_mode=S_IFDIR|0775, st_nlink=15, st_uid=1000, st_gid=1000, st_blksize=4096, st_blocks=0, st_size=720, st_atime=2016/07/01-15:25:23.436623088, st_mtime=2016/07/01-15:21:46.423620215, st_ctime=2016/07/01-15:21:46.423620215}) = 0\nlstat(\"/tmp/sandbox/hashcat/hashcat\", {st_dev=makedev(0, 39), st_ino=1159, st_mode=S_IFREG|0775, st_nlink=1, st_uid=1000, st_gid=1000, st_blksize=4096, st_blocks=1008, st_size=515520, st_atime=2016/07/01-15:21:44.175651291, st_mtime=2016/07/01-15:21:38.843724989, st_ctime=2016/07/01-15:21:38.843724989}) = 0\nmkdir(\"/tmp/sandbox/hashcat/kernels\", 0700) = -1 EEXIST (File exists)\nopen(\"/tmp/sandbox/hashcat/hashcat.restore\", O_RDONLY) = -1 ENOENT (No such file or directory)\ngetcwd(\"/tmp/sandbox/hashcat\", 255)     = 21\nfstat(1, {st_dev=makedev(0, 14), st_ino=4, st_mode=S_IFCHR|0620, st_nlink=1, st_uid=1000, st_gid=5, st_blksize=1024, st_blocks=0, st_rdev=makedev(136, 1), st_atime=2016/07/01-15:32:16.426204521, st_mtime=2016/07/01-15:32:16.426204521, st_ctime=2016/07/01-15:13:51.426204521}) = 0\nwrite(1, \"hashcat (v3.00-14-gb58f7a4) star\"..., 39hashcat (v3.00-14-gb58f7a4) starting...) = 39\nwrite(1, \"\\n\", 1\n)                       = 1\nwrite(1, \"\\n\", 1\n)                       = 1\nwrite(1, \"Usage: ./hashcat [options]... ha\"..., 84Usage: ./hashcat [options]... hash|hashfile|hccapfile [dictionary|mask|directory]...) = 84\nwrite(1, \"\\n\", 1\n)                       = 1\nwrite(1, \"\\n\", 1\n)                       = 1\nwrite(1, \"Try --help for more help.\", 25Try --help for more help.) = 25\nwrite(1, \"\\n\", 1\n)                       = 1\nexit_group(-1)                          = ?\n+++ exited with 255 +++\nand /etc/OpenCL/vendors:\nKAR0VD :: /tmp/sandbox/hashcat \u00bb ls -Q /etc/OpenCL/vendors \n\"intel64.icd\"@  \"nvidia.icd\"\n. ",
    "Tom4t0": "thank you\n. ",
    "rvn2p": "coredump is available at https://rvn.space/s/0jmhchfjw0Fmg5w  link pw is hashcatisgreat\n. build hashcat from github (commit 6ba0eb8b39a90484c4831075a18cbf890b106efe) and got a segfault running \"./hashcat -b --gpu-temp-disable\" . Coredump is at https://rvn.space/s/4O6K1Fn3PfZLYZ9 link pw is hashcatisgreat\n. Number of platforms:                 2\n  Platform Profile:              FULL_PROFILE\n  Platform Version:              OpenCL 2.0 AMD-APP (1912.5)\n  Platform Name:                 AMD Accelerated Parallel Processing\n  Platform Vendor:               Advanced Micro Devices, Inc.\n  Platform Extensions:               cl_khr_icd cl_amd_event_callback cl_amd_offline_devices \n  Platform Profile:              FULL_PROFILE\n  Platform Version:              OpenCL 1.2 LINUX\n  Platform Name:                 Intel(R) OpenCL\n  Platform Vendor:               Intel(R) Corporation\n  Platform Extensions:               cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 \nPlatform Name:                 AMD Accelerated Parallel Processing\nNumber of devices:               5\n  Device Type:                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                     1002h\n  Board name:                    AMD Radeon R9 200 Series\n  Device Topology:               PCI[ B#1, D#0, F#0 ]\n  Max compute units:                 40\n  Max work items dimensions:             3\n    Max work items[0]:               256\n    Max work items[1]:               256\n    Max work items[2]:               256\n  Max work group size:               256\n  Preferred vector width char:           4\n  Preferred vector width short:          2\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Native vector width char:          4\n  Native vector width short:             2\n  Native vector width int:           1\n  Native vector width long:          1\n  Native vector width float:             1\n  Native vector width double:            1\n  Max clock frequency:               800Mhz\n  Address bits:                  64\n  Max memory allocation:             2997116928\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           1024\n  Alignment (bits) of base address:      2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     No\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    16384\n  Global memory size:                4221140160\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Scratchpad\n  Local memory size:                 32768\n  Max pipe arguments:                16\n  Max pipe active reservations:          16\n  Max pipe packet size:              2997116928\n  Max global variable size:          2697405184\n  Max global variable preferred total size:  4221140160\n  Max read/write image args:             64\n  Max on device events:              1024\n  Queue on device max size:          8388608\n  Max on device queues:              1\n  Queue on device preferred size:        262144\n  SVM capabilities:\n    Coarse grain buffer:             Yes\n    Fine grain buffer:               Yes\n    Fine grain system:               No\n    Atomics:                     No\n  Preferred platform atomic alignment:       0\n  Preferred global atomic alignment:         0\n  Preferred local atomic alignment:      0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:          0\n  Unified memory for Host and Device:        0\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             No\n  Queue on Host properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Queue on Device properties:\n    Out-of-Order:                Yes\n    Profiling :                  Yes\n  Platform ID:                   0x7fed0a737a18\n  Name:                      Hawaii\n  Vendor:                    Advanced Micro Devices, Inc.\n  Device OpenCL C version:           OpenCL C 2.0 \n  Driver version:                1912.5 (VM)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 2.0 AMD-APP (1912.5)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_khr_gl_depth_images cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_subgroups cl_khr_gl_event cl_khr_depth_images cl_khr_mipmap_image cl_khr_mipmap_image_writes \nDevice Type:                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                     1002h\n  Board name:                    AMD Radeon R9 200 Series\n  Device Topology:               PCI[ B#4, D#0, F#0 ]\n  Max compute units:                 40\n  Max work items dimensions:             3\n    Max work items[0]:               256\n    Max work items[1]:               256\n    Max work items[2]:               256\n  Max work group size:               256\n  Preferred vector width char:           4\n  Preferred vector width short:          2\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Native vector width char:          4\n  Native vector width short:             2\n  Native vector width int:           1\n  Native vector width long:          1\n  Native vector width float:             1\n  Native vector width double:            1\n  Max clock frequency:               950Mhz\n  Address bits:                  64\n  Max memory allocation:             2999328768\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           1024\n  Alignment (bits) of base address:      2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     No\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    16384\n  Global memory size:                4221172928\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Scratchpad\n  Local memory size:                 32768\n  Max pipe arguments:                16\n  Max pipe active reservations:          16\n  Max pipe packet size:              2999328768\n  Max global variable size:          2699395840\n  Max global variable preferred total size:  4221172928\n  Max read/write image args:             64\n  Max on device events:              1024\n  Queue on device max size:          8388608\n  Max on device queues:              1\n  Queue on device preferred size:        262144\n  SVM capabilities:\n    Coarse grain buffer:             Yes\n    Fine grain buffer:               Yes\n    Fine grain system:               No\n    Atomics:                     No\n  Preferred platform atomic alignment:       0\n  Preferred global atomic alignment:         0\n  Preferred local atomic alignment:      0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:          0\n  Unified memory for Host and Device:        0\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             No\n  Queue on Host properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Queue on Device properties:\n    Out-of-Order:                Yes\n    Profiling :                  Yes\n  Platform ID:                   0x7fed0a737a18\n  Name:                      Hawaii\n  Vendor:                    Advanced Micro Devices, Inc.\n  Device OpenCL C version:           OpenCL C 2.0 \n  Driver version:                1912.5 (VM)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 2.0 AMD-APP (1912.5)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_khr_gl_depth_images cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_subgroups cl_khr_gl_event cl_khr_depth_images cl_khr_mipmap_image cl_khr_mipmap_image_writes \nDevice Type:                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                     1002h\n  Board name:                    AMD Radeon R9 200 Series\n  Device Topology:               PCI[ B#5, D#0, F#0 ]\n  Max compute units:                 40\n  Max work items dimensions:             3\n    Max work items[0]:               256\n    Max work items[1]:               256\n    Max work items[2]:               256\n  Max work group size:               256\n  Preferred vector width char:           4\n  Preferred vector width short:          2\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Native vector width char:          4\n  Native vector width short:             2\n  Native vector width int:           1\n  Native vector width long:          1\n  Native vector width float:             1\n  Native vector width double:            1\n  Max clock frequency:               950Mhz\n  Address bits:                  64\n  Max memory allocation:             2999328768\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           1024\n  Alignment (bits) of base address:      2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     No\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    16384\n  Global memory size:                4221172928\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Scratchpad\n  Local memory size:                 32768\n  Max pipe arguments:                16\n  Max pipe active reservations:          16\n  Max pipe packet size:              2999328768\n  Max global variable size:          2699395840\n  Max global variable preferred total size:  4221172928\n  Max read/write image args:             64\n  Max on device events:              1024\n  Queue on device max size:          8388608\n  Max on device queues:              1\n  Queue on device preferred size:        262144\n  SVM capabilities:\n    Coarse grain buffer:             Yes\n    Fine grain buffer:               Yes\n    Fine grain system:               No\n    Atomics:                     No\n  Preferred platform atomic alignment:       0\n  Preferred global atomic alignment:         0\n  Preferred local atomic alignment:      0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:          0\n  Unified memory for Host and Device:        0\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             No\n  Queue on Host properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Queue on Device properties:\n    Out-of-Order:                Yes\n    Profiling :                  Yes\n  Platform ID:                   0x7fed0a737a18\n  Name:                      Hawaii\n  Vendor:                    Advanced Micro Devices, Inc.\n  Device OpenCL C version:           OpenCL C 2.0 \n  Driver version:                1912.5 (VM)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 2.0 AMD-APP (1912.5)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_khr_gl_depth_images cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_subgroups cl_khr_gl_event cl_khr_depth_images cl_khr_mipmap_image cl_khr_mipmap_image_writes \nDevice Type:                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                     1002h\n  Board name:                    AMD Radeon R9 200 Series\n  Device Topology:               PCI[ B#6, D#0, F#0 ]\n  Max compute units:                 40\n  Max work items dimensions:             3\n    Max work items[0]:               256\n    Max work items[1]:               256\n    Max work items[2]:               256\n  Max work group size:               256\n  Preferred vector width char:           4\n  Preferred vector width short:          2\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Native vector width char:          4\n  Native vector width short:             2\n  Native vector width int:           1\n  Native vector width long:          1\n  Native vector width float:             1\n  Native vector width double:            1\n  Max clock frequency:               950Mhz\n  Address bits:                  64\n  Max memory allocation:             2999328768\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           1024\n  Alignment (bits) of base address:      2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     No\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    16384\n  Global memory size:                4221172928\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Scratchpad\n  Local memory size:                 32768\n  Max pipe arguments:                16\n  Max pipe active reservations:          16\n  Max pipe packet size:              2999328768\n  Max global variable size:          2699395840\n  Max global variable preferred total size:  4221172928\n  Max read/write image args:             64\n  Max on device events:              1024\n  Queue on device max size:          8388608\n  Max on device queues:              1\n  Queue on device preferred size:        262144\n  SVM capabilities:\n    Coarse grain buffer:             Yes\n    Fine grain buffer:               Yes\n    Fine grain system:               No\n    Atomics:                     No\n  Preferred platform atomic alignment:       0\n  Preferred global atomic alignment:         0\n  Preferred local atomic alignment:      0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:          0\n  Unified memory for Host and Device:        0\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             No\n  Queue on Host properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Queue on Device properties:\n    Out-of-Order:                Yes\n    Profiling :                  Yes\n  Platform ID:                   0x7fed0a737a18\n  Name:                      Hawaii\n  Vendor:                    Advanced Micro Devices, Inc.\n  Device OpenCL C version:           OpenCL C 2.0 \n  Driver version:                1912.5 (VM)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 2.0 AMD-APP (1912.5)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_khr_gl_depth_images cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_image2d_from_buffer cl_khr_spir cl_khr_subgroups cl_khr_gl_event cl_khr_depth_images cl_khr_mipmap_image cl_khr_mipmap_image_writes \nDevice Type:                   CL_DEVICE_TYPE_CPU\n  Vendor ID:                     1002h\n  Board name:\n  Max compute units:                 4\n  Max work items dimensions:             3\n    Max work items[0]:               1024\n    Max work items[1]:               1024\n    Max work items[2]:               1024\n  Max work group size:               1024\n  Preferred vector width char:           16\n  Preferred vector width short:          8\n  Preferred vector width int:            4\n  Preferred vector width long:           2\n  Preferred vector width float:          8\n  Preferred vector width double:         4\n  Native vector width char:          16\n  Native vector width short:             8\n  Native vector width int:           4\n  Native vector width long:          2\n  Native vector width float:             8\n  Native vector width double:            4\n  Max clock frequency:               3452Mhz\n  Address bits:                  64\n  Max memory allocation:             4190848000\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                8192\n  Max image 2D height:               8192\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           4096\n  Alignment (bits) of base address:      1024\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     Yes\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    32768\n  Global memory size:                16763392000\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Global\n  Local memory size:                 32768\n  Max pipe arguments:                16\n  Max pipe active reservations:          16\n  Max pipe packet size:              4190848000\n  Max global variable size:          1879048192\n  Max global variable preferred total size:  1879048192\n  Max read/write image args:             64\n  Max on device events:              0\n  Queue on device max size:          0\n  Max on device queues:              0\n  Queue on device preferred size:        0\n  SVM capabilities:\n    Coarse grain buffer:             No\n    Fine grain buffer:               No\n    Fine grain system:               No\n    Atomics:                     No\n  Preferred platform atomic alignment:       0\n  Preferred global atomic alignment:         0\n  Preferred local atomic alignment:      0\n  Kernel Preferred work group size multiple:     1\n  Error correction support:          0\n  Unified memory for Host and Device:        1\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             Yes\n  Queue on Host properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Queue on Device properties:\n    Out-of-Order:                No\n    Profiling :                  No\n  Platform ID:                   0x7fed0a737a18\n  Name:                      Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz\n  Vendor:                    GenuineIntel\n  Device OpenCL C version:           OpenCL C 1.2 \n  Driver version:                1912.5 (sse2,avx)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 1.2 AMD-APP (1912.5)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_ext_device_fission cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_spir cl_khr_gl_event \nPlatform Name:                 Intel(R) OpenCL\nNumber of devices:               1\n  Device Type:                   CL_DEVICE_TYPE_CPU\n  Vendor ID:                     8086h\n  Max compute units:                 4\n  Max work items dimensions:             3\n    Max work items[0]:               8192\n    Max work items[1]:               8192\n    Max work items[2]:               8192\n  Max work group size:               8192\n  Preferred vector width char:           1\n  Preferred vector width short:          1\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Native vector width char:          32\n  Native vector width short:             16\n  Native vector width int:           8\n  Native vector width long:          4\n  Native vector width float:             8\n  Native vector width double:            4\n  Max clock frequency:               3200Mhz\n  Address bits:                  64\n  Max memory allocation:             4190848000\n  Image support:                 Yes\n  Max number of images read arguments:       480\n  Max number of images write arguments:      480\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            480\n  Max size of kernel argument:           3840\n  Alignment (bits) of base address:      1024\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     Yes\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               No\n    Round to +ve and infinity:           No\n    IEEE754-2008 fused multiply-add:         No\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    262144\n  Global memory size:                16763392000\n  Constant buffer size:              131072\n  Max number of constant args:           480\n  Local memory type:                 Global\n  Local memory size:                 32768\n  Kernel Preferred work group size multiple:     128\n  Error correction support:          0\n  Unified memory for Host and Device:        1\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             Yes\n  Queue on Host properties:\n    Out-of-Order:                Yes\n    Profiling :                  Yes\n  Platform ID:                   0x123a830\n  Name:                      Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz\n  Vendor:                    Intel(R) Corporation\n  Device OpenCL C version:           OpenCL C 1.2 \n  Driver version:                1.2.0.10002\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 1.2 (Build 10002)\n  Extensions:                    cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 \n. I think i have an underlying opencl problem. After rebooting the system clinfo crashes as well:\nNumber of platforms:                             2\n  Platform Profile:                              FULL_PROFILE\n  Platform Version:                              OpenCL 2.0 AMD-APP (1912.5)\n  Platform Name:                                 AMD Accelerated Parallel Processing\n  Platform Vendor:                               Advanced Micro Devices, Inc.\n  Platform Extensions:                           cl_khr_icd cl_amd_event_callback cl_amd_offline_devices \n  Platform Profile:                              FULL_PROFILE\n  Platform Version:                              OpenCL 1.2 LINUX\n  Platform Name:                                 Intel(R) OpenCL\n  Platform Vendor:                               Intel(R) Corporation\n  Platform Extensions:                           cl_khr_icd cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_byte_addressable_store cl_khr_depth_images cl_khr_3d_image_writes cl_intel_exec_by_local_thread cl_khr_spir cl_khr_fp64 \nPlatform Name:                                 AMD Accelerated Parallel Processing\nNumber of devices:                               4\n  Device Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     1002h\n  Board name:                                    AMD Radeon R9 200 Series\n  Device Topology:                               PCI[ B#1, D#0, F#0 ]\n  Max compute units:                             40\n  Max work items dimensions:                     3\n    Max work items[0]:                           256\n    Max work items[1]:                           256\n    Max work items[2]:                           256\n  Max work group size:                           256\n  Preferred vector width char:                   4\n  Preferred vector width short:                  2\n  Preferred vector width int:                    1\n  Preferred vector width long:                   1\n  Preferred vector width float:                  1\n  Preferred vector width double:                 1\n  Native vector width char:                      4\n  Native vector width short:                     2\n  Native vector width int:                       1\n  Native vector width long:                      1\n  Native vector width float:                     1\n  Native vector width double:                    1\n  Max clock frequency:                           800Mhz\n  Address bits:                                  64\n  Max memory allocation:                         2929529856\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          64\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   1024\n  Alignment (bits) of base address:              2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     No\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    Read/Write\n  Cache line size:                               64\n  Cache size:                                    16384\n  Global memory size:                            4128142016\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Scratchpad\n  Local memory size:                             32768\n  Max pipe arguments:                            16\n  Max pipe active reservations:                  16\n  Max pipe packet size:                          2929529856\n  Max global variable size:                      2636576768\n  Max global variable preferred total size:      4128142016\n  Max read/write image args:                     64\n  Max on device events:                          1024\n  Queue on device max size:                      8388608\n  Max on device queues:                          1\n  Queue on device preferred size:                262144\n  SVM capabilities:\n    Coarse grain buffer:                         Yes\n    Fine grain buffer:                           Yes\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\nSegmentation fault\n. I followed the instructions and found that an old installation of AMDs APP sdk was still on the system.\nafter cleaning drivers, opencl runtime, app sdk and then reinstalling the driver the current github version of hashcat works:\nroot@hashcracker:/crack/tools/hashcat# ./hashcat -b --gpu-temp-disable\nhashcat (v3.00-56-ge56a4e9) starting in benchmark-mode...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Hawaii, 2858/4025 MB allocatable, 40MCU\nDevice #2: Hawaii, 2860/4025 MB allocatable, 40MCU\nDevice #3: Hawaii, 2860/4025 MB allocatable, 40MCU\nDevice #4: Hawaii, 2860/4025 MB allocatable, 40MCU\nDevice #5: WARNING: Not a native Intel OpenCL runtime, expect massive speed loss\n           You can use --force to override this but do not post error reports if you do so\nDevice #5: Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz, skipped\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #6: Intel(R) Core(TM) i5-4570 CPU @ 3.20GHz, skipped\n\nHashtype: MD4\nSpeed.Dev.#1.: 18522.2 MH/s (95.87ms)\nSpeed.Dev.#2.: 18577.6 MH/s (95.84ms)\nSpeed.Dev.#3.: 18579.0 MH/s (95.84ms)\nSpeed.Dev.#4.: 18527.4 MH/s (96.12ms)\nSpeed.Dev.#*.: 74206.3 MH/s\nHashtype: MD5\nSpeed.Dev.#1.:  9585.1 MH/s (95.60ms)\nSpeed.Dev.#2.:  9539.1 MH/s (96.01ms)\nSpeed.Dev.#3.:  9623.3 MH/s (95.77ms)\nSpeed.Dev.#4.:  9569.8 MH/s (96.31ms)\nSpeed.Dev.#*.: 38317.2 MH/s\nHashtype: Half MD5\nSpeed.Dev.#1.:  6170.7 MH/s (95.92ms)\nSpeed.Dev.#2.:  6220.1 MH/s (95.62ms)\nSpeed.Dev.#3.:  6190.0 MH/s (96.04ms)\nSpeed.Dev.#4.:  6216.5 MH/s (95.62ms)\nSpeed.Dev.#*.: 24797.2 MH/s\n...\nThank you for your time and congrats on the 3.0 rewrite  =DD\n. Driver is NVIDIA-Linux-x86_64-375.39.run. Bug dows not show up when using https://hashcat.net/files/hashcat-3.6.0.7z. I could corner it a bit more. The error happens if one of the pws gets cracked by the last wordlist and then it switches to the next one.\nThe last remaining hash is weirdly formatted. I can force the error by using this hash+ the default hash from the example page. I think the parser dies when parsing \"$\" as username for the NETNTLM hash.\n$::CUSTOMERDOMAIN:HASH\nadmin::N46iSNekpT:08ca45b7d7ea58ee:88dcbe4446168966a153a0064958dac6:5c7830315c7830310000000000000b45c67103d07d7b95acd12ffa11230e0000000052920b85f78d013c31cdb3b92f5d765c783030 . I tried to reduce it to a smaller pack (hashes, wordlists,rules) but couldn't reproduce it with it. I can't upload the original hashes do to customer NDAs.  The system is busy now with another set of hashes but I'll try to reproduce it using the original hashes on the weekend. I'll try to recreate the original run (same hashes, same lists, same rules with v3.6.0-479-gb169653 and latest. This will take a few hours. i currently have an unreleated problem that dictionary chaches are not being saved and therefore are created over and over. the wordlists and hashcat are on a local storage on a zfs volume. I see that hashcat.dictstat is being modified after each run. \nAre dictstats always saved in hashcat's working dir, or are they saved in the wordlist directory as well? would nuking the hashcat direcotry and pulling an building it again fix this issues?. could reproduce the original bug after 11 hours =(.\ndoing a 4.0.0-rc1 run now. I could also reproduce it with 4.0.0-rc1. But it takes me almost a day to reproduce the exact circumstances and I am unable to isolate it further =(\n\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nBUG pw_add()!!\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: NetNTLMv2\nHash.Target......: /tmp/hashes.txt\nTime.Started.....: Fri Sep 22 11:05:51 2017 (1 day, 20 hours)\nTime.Estimated...: Sun Sep 24 07:44:26 2017 (1 sec)\n\nSorry for wasting your time, should i close the bug?. Btw the not caching issue is in fact a zfs problem, when i put the wordlists on a local ext4 drive the caching works. could not reproduce bug with 4.0.0-rc4. ",
    "XeniaGabriela": "Dear hashcat team,\nI just downloaded the latest version and installed it in an Ubuntu 14.04 virtual machine on Windows7 by \n1. unzipping it to ~/.hashcat with p7zip\n2. copying hashcat64.bin to /usr/bin/\n3. making a symblic link hashcat to hashcat64.bin\n'hashcat --help' works fine ...\nBut I am getting the ERROR '/usr/bin/hashcat.hctune: No such file or directory' when I run the program.\nDid I do something wrong with the installation?\nRegards,\nXenia\n. ",
    "Kilonga": "I have the Intel/GT750m setup.  If I compile the same version of hashcat (v3.00) on OSX and run it there it works with no issues, but it will not work on Kali.\n. I installed the package nvidia-kernel-dkms\n. Installed latest drivers but still having the same issue.\nnvidia-smi output\nNVIDIA-SMI 367.27                 Driver Version: 367.27\n. Here is the output:\n\n==============NVSMI LOG==============\n\nTimestamp                           : Mon Jul  4 11:28:01 2016\nDriver Version                      : 367.27\nAttached GPUs                       : 1\nGPU 0000:01:00.0\n    Product Name                    : GeForce GT 750M\n    Product Brand                   : GeForce\n    Display Mode                    : N/A\n    Display Active                  : N/A\n    Persistence Mode                : Disabled\n    Accounting Mode                 : N/A\n    Accounting Mode Buffer Size     : N/A\n    Driver Model\n        Current                     : N/A\n        Pending                     : N/A\n    Serial Number                   : N/A\n    GPU UUID                        : GPU-faa35d8c-e3f1-0aef-1885-38a70dc1ed9b\n    Minor Number                    : 0\n    VBIOS Version                   : 80.07.C7.04.01\n    MultiGPU Board                  : N/A\n    Board ID                        : N/A\n    GPU Part Number                 : N/A\n    Inforom Version\n        Image Version               : N/A\n        OEM Object                  : N/A\n        ECC Object                  : N/A\n        Power Management Object     : N/A\n    GPU Operation Mode\n        Current                     : N/A\n        Pending                     : N/A\n    GPU Virtualization Mode\n        Virtualization mode         : N/A\n    PCI\n        Bus                         : 0x01\n        Device                      : 0x00\n        Domain                      : 0x0000\n        Device Id                   : 0x0FE910DE\n        Bus Id                      : 0000:01:00.0\n        Sub System Id               : 0x0130106B\n        GPU Link Info\n            PCIe Generation\n                Max                 : N/A\n                Current             : N/A\n            Link Width\n                Max                 : N/A\n                Current             : N/A\n        Bridge Chip\n            Type                    : N/A\n            Firmware                : N/A\n        Replays since reset         : 0\n        Tx Throughput               : N/A\n        Rx Throughput               : N/A\n    Fan Speed                       : N/A\n    Performance State               : P0\n    Clocks Throttle Reasons         : N/A\n    FB Memory Usage\n        Total                       : 1969 MiB\n        Used                        : 336 MiB\n        Free                        : 1633 MiB\n    BAR1 Memory Usage\n        Total                       : N/A\n        Used                        : N/A\n        Free                        : N/A\n    Compute Mode                    : Default\n    Utilization\n        Gpu                         : N/A\n        Memory                      : N/A\n        Encoder                     : N/A\n        Decoder                     : N/A\n    Ecc Mode\n        Current                     : N/A\n        Pending                     : N/A\n    ECC Errors\n        Volatile\n            Single Bit\n                Device Memory       : N/A\n                Register File       : N/A\n                L1 Cache            : N/A\n                L2 Cache            : N/A\n                Texture Memory      : N/A\n                Texture Shared      : N/A\n                Total               : N/A\n            Double Bit\n                Device Memory       : N/A\n                Register File       : N/A\n                L1 Cache            : N/A\n                L2 Cache            : N/A\n                Texture Memory      : N/A\n                Texture Shared      : N/A\n                Total               : N/A\n        Aggregate\n            Single Bit\n                Device Memory       : N/A\n                Register File       : N/A\n                L1 Cache            : N/A\n                L2 Cache            : N/A\n                Texture Memory      : N/A\n                Texture Shared      : N/A\n                Total               : N/A\n            Double Bit\n                Device Memory       : N/A\n                Register File       : N/A\n                L1 Cache            : N/A\n                L2 Cache            : N/A\n                Texture Memory      : N/A\n                Texture Shared      : N/A\n                Total               : N/A\n    Retired Pages\n        Single Bit ECC              : N/A\n        Double Bit ECC              : N/A\n        Pending                     : N/A\n    Temperature\n        GPU Current Temp            : 49 C\n        GPU Shutdown Temp           : N/A\n        GPU Slowdown Temp           : N/A\n    Power Readings\n        Power Management            : N/A\n        Power Draw                  : N/A\n        Power Limit                 : N/A\n        Default Power Limit         : N/A\n        Enforced Power Limit        : N/A\n        Min Power Limit             : N/A\n        Max Power Limit             : N/A\n    Clocks\n        Graphics                    : N/A\n        SM                          : N/A\n        Memory                      : N/A\n        Video                       : N/A\n    Applications Clocks\n        Graphics                    : N/A\n        Memory                      : N/A\n    Default Applications Clocks\n        Graphics                    : N/A\n        Memory                      : N/A\n    Max Clocks\n        Graphics                    : N/A\n        SM                          : N/A\n        Memory                      : N/A\n        Video                       : N/A\n    Clock Policy\n        Auto Boost                  : N/A\n        Auto Boost Default          : N/A\n    Processes                       : N/A\n. ",
    "laginimaineb": "I ran two benchmarks on my computer.\nThe CPU is a Core i5-4670 @ 3.40GHz. The tests were executed on a single core. \nBenchmarking scrypt with N=32768, r=8, p=2..........6 H/s\nBenchmarking the fde_bruteforce.py script..............2 H/s\nAs you can see, the fde_bruteforce is three times slower than just running scrypt, since it runs scrypt three times for each attempt (twice for the KDF, and another time to produce scrypted_intermediate_key from IK3).\nThat means that each 1080 can do about 13 full attempts per second, compared to the 2 done by my Core i5-4670. However, you could parallelise the script to run on all cores, which should give us ~8 attempts per second on the CPU.\nWhat do you think? Do you think it's worth it to continue?\nAlso, if we go ahead, hashcat's support for hooks sounds perfect, since all that's needed is one additional (fast) computation.\n. ",
    "voideater": "Was this ever implemented in hashcat? Working with a phone now and using the Python script @laginimaineb did, but with approx 1 pw/sec I assume this can take more lifetimes than I'd wish it did. 21H/s per CPU would be a quite good upgrade, IMO.. Just experienced this myself running \n./hashcat-4.0.0/hashcat64.bin -m 100 file_with_hashes.txt -a 6 wordlists.txt ?d?d?d?d -O --gpu-temp-retain=65 -o hashes_found.txt\nRunning hashcat-4.0.0-rc2.7z from 02-Oct-2017 13:53 on Ubuntu 16.04 w/ 3x GTX 970 Ti (w/ NVIDIA v384.90)\nWordlist I used was the crackstation.txt (700MB file that can be downloaded from various sources). Haven't been able to pin down for which words it happens, but it occurs near the end of the job every time.\nWordlist is located on the same drive for which I run hashcat from if that should have anything to say.\nUpdate; same scenario using other wordlists as well (same list of hashes but slightly different mask used in the attack).. ",
    "GrepItAll": "I'm also going to bump this; due to the stratification in Android versions that people are running, devices running this generation of fde are still encountered 'in the wild', so having a capability beyond a python script for dealing with these would be beneficial. I can provide additional sample data if required.. Ah ok, looks like 1d04de3 changed the number of kernel loops from 1000 to 250. I will test 4.0.0 with the --scrypt-tmto flag and different workload profiles.. Ok, so using a workload of 4 instead of 3 brings hashcat back up to comparable levels of performance, although it averages out at about 5% slower than under 3.6.0 - I know that this isn't much, but it's such a slow algorithm anyway that that 5% is quite noticeable in the long term.\nI experimented with the --scrypt-tmto setting in both 3.6.0 and 4.0.0 and it did not appear to make a difference to either of them. Does -m 14800 actually make use of this flag? I was under the impression that 14800 uses PBKDF2, not scrypt.. Ok, so I should just use -w 4 then under 4.0.0? If so, I guess this issue can be closed.. Just for reference: #1418 \nNot saying that these are necessarily related, but just be aware that -m 14800 is very slow at the best of times and may not be working as it should be in 4.0.0 anyway. Yeah, I didn't think it would shed much light on it, I was just being optimistic!\nI'll see if I can find time to run those tests properly (it occurred on a 'production' system). No, although key elements are similar. #411 deals with FDE on devices where hardware backed FDE is enabled, but where the hardware keys are leaked out of the processor in the case of Qualcomm devices. 4.4 FDE does not use hardware backing. Both use scrypt however.. You are correct that this PoC code is only for PINs. However, Android 4.4 lockscreens can have a password set instead, which is then used as the basis for the FDE encryption. So whilst most users would have PINs for which this script is sufficiently fast, it is not fast enough to use for passwords which are still frequent enough to cause problems when attempting to recover data from these devices.. Correct, apologies for the ambiguity. I meant that the device password can be non-numeric, whilst the python script will only handle numeric codes.. No, I didn't resolve this. I agree that executing from an arbitrary location doesn't seem to work, but executing from the hashcat root directory does work.. I'll try and validate, but I'm surprised that the output was crackable with FileVault 2. Thanks @jsteube! Excellent work as always. I have some disk images with known passwords that I am looking forward to trying this against.. ",
    "renukaraee": "How to fb password  hack. ",
    "kardipapa": "I have the same problem with Iris Pro graphics, i use mid 2015 MacBook Pro with OS X 10.11.6, hashcat version: v3.00-69-g804ee28, compiled from git source. But when i use dictionary attack with 10GB dict. files, just works fine with Iris Pro\n. ",
    "zrayburn": "I am unsure entirely but it may be the amount of VRAM the card can allocate. For instance in mining Ethereum you must have a card that has at least 1.5 gb of VRAM in the GPU to load the full operations buffer.\n. There is a certain amount of data that must be written into graphical VRAM in order to preform more complex functions like this. So if you have just Iris pro or the Intel 5000 series those cards don't have enough VRAM in order to preform this operation.\n. @mire3212 The graphics hardware does not have enough allocatable graphics ram to load the hash function into memory.\n. ",
    "mire3212": "I have the same issue with a MacBook Pro (Retina, 15-inch, Mid 2015).\n```\nhashcat -b -d 2\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\n...\nHashtype: SHA-3(Keccak)\nAbort trap: 6\n.\nhashcat (v3.10-611-gf234f72) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\nHashtype: SHA-3(Keccak)\nAbort trap: 6\n```\n. @jsteube I'm getting similar results as @leonklingele when running the following:\n```\n./hashcat -b -m 5000\nhashcat (v3.10-709-g8805ca1) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\nHashtype: SHA-3(Keccak)\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n...\n```\n```\n./hashcat -b -m 500 \nhashcat (v3.10-709-g8805ca1) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\nHashtype: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n...\n```\n. @matrix hashcat --opencl-info\n@jsteube Here's a link to the full output from hashcat -b -m 500 \nand to hashcat -b -m 5000\nAs of now, it seems that all functions are failing.\nEDIT: This is a from a fresh clone of the repo.\n. @matrix Sure. I see that, but why is that now I can't run ANY hashes? I used to be able to perform almost every hash except for a handful, now I can't even get past MD4.\n. @matrix If I checkout tag v3.10 it still runs. If I pull the existing repo as-is it's failing.\n. @matrix I cloned yours and it's working on MD5crypt but still failing on SHA-3(Keccak) (which I understand is currently a limitation of the GPU).\n. ",
    "leonklingele": "@jsteube Same error\n. ```\nhashcat (v3.10-705-g9f4c4dc) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, skipped\n\nHashtype: SHA-3(Keccak)\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n:11:1: error: expected identifier or '('\ninclude \"inc_hash_constants.h\"\n^\nIn file included from :13:\n/path/to/hashcat/OpenCL/inc_types.cl:720:3: error: unknown type name 'u8'\n  u8  orig_mac1[6];\n  ^\n/path/to/hashcat/OpenCL/inc_types.cl:721:3: error: unknown type name 'u8'\n  u8  orig_mac2[6];\n  ^\n/path/to/hashcat/OpenCL/inc_types.cl:722:3: error: unknown type name 'u8'\n  u8  orig_nonce1[32];\n  ^\n/path/to/hashcat/OpenCL/inc_types.cl:723:3: error: unknown type name 'u8'\n  u8  orig_nonce2[32];\n  ^\n:80:9: error: unknown type name 'u8'\n  const u8 keccakf_rotc[24] =\n        ^\n:86:9: error: unknown type name 'u8'\n  const u8 keccakf_piln[24] =\n        ^\n:243:9: error: unknown type name 'u8'\n  const u8 keccakf_rotc[24] =\n        ^\n:249:9: error: unknown type name 'u8'\n  const u8 keccakf_piln[24] =\n        ^\n\nDevice #2: Kernel /path/to/hashcat/OpenCL/m05000_a3.cl build failure. Proceeding without this device.\n\nStarted: Mon Nov 14 12:23:02 2016\nStopped: Mon Nov 14 12:23:03 2016\n. @jsteube Can this please be re-opened? It's still not fixed in latest master.. Automatic graphic switching is disabled.. @matrix I didn't tune anything. That file indeed does exists in my checkout. Does hashcat automatically use it?\n@matrix I can help you with testing :) Just tell me what to do. It still crashes when benchmarking Whirlpool:bash\n$ ./hashcat -d2 -b -m 6100\nhashcat (v3.20-12-gea5e75cf) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, skipped\n\nHashtype: Whirlpool\nAbort trap: 6\n. A segmentation fault for `Hashtype: phpass (400)`:\nHashtype: phpass, MD5(Wordpress), MD5(phpBB3), MD5(Joomla)\nSegmentation fault: 11\n.\nHashtype: Lotus Notes/Domino 6\nAbort trap: 6\n.\nhashcat (v3.20-71-gfd2ea078) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, skipped\n\nHashtype: OSX v10.8+\nSpeed.Dev.#2.....:      124 H/s (61.73ms)\nStarted: Fri Dec 30 00:11:57 2016\nStopped: Fri Dec 30 00:12:14 2016\n```\n```\nhashcat (v3.20-71-gfd2ea078) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, skipped\n\nHashtype: Lotus Notes/Domino 6\nAbort trap: 6\n.diff\ndiff --git a/hashcat.hctune b/hashcat.hctune\nindex aee02a51..bdd85671 100644\n--- a/hashcat.hctune\n+++ b/hashcat.hctune\n@@ -441,3 +441,4 @@ Iris                                            *       13000   1       1\nIris_Pro                                        *       5000    1       8       8\n Iris_Pro                                        *       6100    1       4       16\n+Iris_Pro                                        *       8700    1       1       256\n```\ndid the trick. 7100 works right out of the box for me. @schluk is not benchmarking on an Iris Pro.. @matrix well, it did work with 256. Should I try to find a lower number?. @matrix here you go:\n```\nhashcat (v3.20-88-gd36cc4c5) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, skipped\n\nHashtype: MD4\nSpeed.Dev.#2.....:   388.2 MH/s (53.00ms)\nHashtype: MD5\nSpeed.Dev.#2.....:   248.2 MH/s (83.07ms)\nHashtype: Half MD5\nSpeed.Dev.#2.....:   167.0 MH/s (62.46ms)\nHashtype: SHA1\nSpeed.Dev.#2.....: 87632.4 kH/s (58.65ms)\nHashtype: SHA256\nSpeed.Dev.#2.....: 36105.5 kH/s (72.14ms)\nHashtype: SHA384\nSpeed.Dev.#2.....: 10069.9 kH/s (64.64ms)\nHashtype: SHA512\nSpeed.Dev.#2.....: 10073.8 kH/s (64.65ms)\nHashtype: SHA-3(Keccak)\nSpeed.Dev.#2.....:   561.4 kH/s (1190.76ms)\nHashtype: SipHash\nSpeed.Dev.#2.....:   383.4 MH/s (53.63ms)\nHashtype: RipeMD160\nSpeed.Dev.#2.....: 52437.2 kH/s (49.66ms)\nHashtype: Whirlpool\nSpeed.Dev.#2.....:   645.8 kH/s (992.79ms)\nHashtype: GOST R 34.11-94\nSpeed.Dev.#2.....:  6161.7 kH/s (105.89ms)\nHashtype: GOST R 34.11-2012 (Streebog) 256-bit\nSpeed.Dev.#2.....:  1733.7 kH/s (93.97ms)\nHashtype: GOST R 34.11-2012 (Streebog) 512-bit\nSpeed.Dev.#2.....:  1736.2 kH/s (93.92ms)\nHashtype: DES (PT = $salt, key = $pass)\n\nDevice #2: skipping unstable hash-mode 14000 for this specific device, use --force to override\n\nHashtype: 3DES (PT = $salt, key = $pass)\n\nDevice #2: skipping unstable hash-mode 14100 for this specific device, use --force to override\n\nHashtype: phpass, MD5(Wordpress), MD5(phpBB3), MD5(Joomla)\nSpeed.Dev.#2.....:    75112 H/s (67.45ms)\nHashtype: scrypt\nSpeed.Dev.#2.....:    20641 H/s (120.79ms)\nHashtype: PBKDF2-HMAC-MD5\nSpeed.Dev.#2.....:    81830 H/s (59.07ms)\nHashtype: PBKDF2-HMAC-SHA1\nSpeed.Dev.#2.....:    34833 H/s (69.77ms)\nHashtype: PBKDF2-HMAC-SHA256\nSpeed.Dev.#2.....:    13891 H/s (88.06ms)\nHashtype: PBKDF2-HMAC-SHA512\nSpeed.Dev.#2.....:     4885 H/s (61.77ms)\nHashtype: Skype\nSpeed.Dev.#2.....:   158.7 MH/s (65.58ms)\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     4238 H/s (70.48ms)\nHashtype: IKE-PSK MD5\nSpeed.Dev.#2.....: 20309.1 kH/s (60.58ms)\nHashtype: IKE-PSK SHA1\nSpeed.Dev.#2.....:  8425.7 kH/s (76.97ms)\nHashtype: NetNTLMv1-VANILLA / NetNTLMv1+ESS\nSpeed.Dev.#2.....:   244.4 MH/s (84.02ms)\nHashtype: NetNTLMv2\nSpeed.Dev.#2.....: 18665.3 kH/s (65.95ms)\nHashtype: IPMI2 RAKP HMAC-SHA1\nSpeed.Dev.#2.....: 17596.5 kH/s (69.92ms)\nHashtype: Kerberos 5 AS-REQ Pre-Auth etype 23\nSpeed.Dev.#2.....:  2908.5 kH/s (55.86ms)\nHashtype: Kerberos 5 TGS-REP etype 23\nSpeed.Dev.#2.....:  3119.3 kH/s (52.01ms)\nHashtype: DNSSEC (NSEC3)\nSpeed.Dev.#2.....: 34575.4 kH/s (75.37ms)\nHashtype: PostgreSQL Challenge-Response Authentication (MD5)\nSpeed.Dev.#2.....: 77697.9 kH/s (66.25ms)\nHashtype: MySQL Challenge-Response Authentication (SHA1)\nSpeed.Dev.#2.....: 23820.4 kH/s (51.36ms)\nHashtype: SIP digest authentication (MD5)\nSpeed.Dev.#2.....: 46275.1 kH/s (56.21ms)\nHashtype: SMF > v1.1\nSpeed.Dev.#2.....: 72231.3 kH/s (71.20ms)\nHashtype: vBulletin < v3.8.5\nSpeed.Dev.#2.....: 80478.4 kH/s (63.86ms)\nHashtype: vBulletin > v3.8.5\nSpeed.Dev.#2.....: 51769.3 kH/s (50.01ms)\nHashtype: IPB2+, MyBB1.2+\nSpeed.Dev.#2.....: 55019.3 kH/s (93.60ms)\nHashtype: WBB3, Woltlab Burning Board 3\nSpeed.Dev.#2.....: 14350.7 kH/s (85.91ms)\nHashtype: OpenCart\nSpeed.Dev.#2.....: 22625.5 kH/s (54.29ms)\nHashtype: Joomla < 2.5.18\nSpeed.Dev.#2.....:   247.7 MH/s (83.16ms)\nHashtype: PHPS\nSpeed.Dev.#2.....: 80532.2 kH/s (63.86ms)\nHashtype: Drupal7\nSpeed.Dev.#2.....:      593 H/s (65.38ms)\nHashtype: osCommerce, xt:Commerce\nSpeed.Dev.#2.....:   158.6 MH/s (65.63ms)\nHashtype: PrestaShop\nSpeed.Dev.#2.....: 91775.1 kH/s (55.98ms)\nHashtype: Django (SHA-1)\nSpeed.Dev.#2.....: 72191.0 kH/s (71.22ms)\nHashtype: Django (PBKDF2-SHA256)\nSpeed.Dev.#2.....:      687 H/s (88.07ms)\nHashtype: Mediawiki B type\nSpeed.Dev.#2.....: 71830.8 kH/s (71.48ms)\nHashtype: Redmine Project Management Web App\nSpeed.Dev.#2.....: 22417.1 kH/s (54.86ms)\nHashtype: PostgreSQL\nSpeed.Dev.#2.....:   247.3 MH/s (83.05ms)\nHashtype: MSSQL(2000)\nSpeed.Dev.#2.....: 87222.3 kH/s (58.88ms)\nHashtype: MSSQL(2005)\nSpeed.Dev.#2.....: 87151.9 kH/s (58.90ms)\nHashtype: MSSQL(2012)\nSpeed.Dev.#2.....: 10004.3 kH/s (64.76ms)\nHashtype: MySQL323\nSpeed.Dev.#2.....:  1258.5 MH/s (66.08ms)\nHashtype: MySQL4.1/MySQL5\nSpeed.Dev.#2.....: 39087.5 kH/s (66.54ms)\nHashtype: Oracle H: Type (Oracle 7+)\nSpeed.Dev.#2.....:  6209.1 kH/s (104.96ms)\nHashtype: Oracle S: Type (Oracle 11+)\nSpeed.Dev.#2.....: 87474.1 kH/s (58.63ms)\nHashtype: Oracle T: Type (Oracle 12+)\nSpeed.Dev.#2.....:     1175 H/s (61.76ms)\nHashtype: Sybase ASE\nSpeed.Dev.#2.....:  4161.9 kH/s (73.34ms)\nHashtype: EPiServer 6.x < v4\nSpeed.Dev.#2.....: 72199.1 kH/s (71.20ms)\nHashtype: EPiServer 6.x > v4\nSpeed.Dev.#2.....: 33148.4 kH/s (78.57ms)\nHashtype: md5apr1, MD5(APR), Apache MD5\nSpeed.Dev.#2.....:   120.0 kH/s (81.63ms)\nHashtype: ColdFusion 10+\nSpeed.Dev.#2.....: 21166.8 kH/s (58.02ms)\nHashtype: hMailServer\nSpeed.Dev.#2.....: 33153.8 kH/s (78.57ms)\nHashtype: SHA-1(Base64), nsldap, Netscape LDAP SHA\nSpeed.Dev.#2.....: 87425.4 kH/s (58.66ms)\nHashtype: SSHA-1(Base64), nsldaps, Netscape LDAP SSHA\nSpeed.Dev.#2.....: 87533.2 kH/s (58.69ms)\nHashtype: SSHA-512(Base64), LDAP {SSHA512}\nSpeed.Dev.#2.....: 10056.9 kH/s (64.66ms)\nHashtype: LM\n\nDevice #2: skipping unstable hash-mode 3000 for this specific device, use --force to override\n\nHashtype: NTLM\nSpeed.Dev.#2.....:   386.9 MH/s (52.86ms)\nHashtype: Domain Cached Credentials (DCC), MS Cache\nSpeed.Dev.#2.....:   120.1 MH/s (86.78ms)\nHashtype: Domain Cached Credentials 2 (DCC2), MS Cache 2\nSpeed.Dev.#2.....:     3400 H/s (74.37ms)\nHashtype: MS-AzureSync PBKDF2-HMAC-SHA256\nSpeed.Dev.#2.....:   137.3 kH/s (64.05ms)\nHashtype: descrypt, DES(Unix), Traditional DES\n\nDevice #2: skipping unstable hash-mode 1500 for this specific device, use --force to override\n\nHashtype: BSDiCrypt, Extended DES\nSpeed.Dev.#2.....:    14128 H/s (124.77ms)\nHashtype: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nSpeed.Dev.#2.....:   119.7 kH/s (81.63ms)\nHashtype: bcrypt, Blowfish(OpenBSD)\nSpeed.Dev.#2.....:      314 H/s (49.20ms)\nHashtype: sha256crypt, SHA256(Unix)\nSpeed.Dev.#2.....:     4629 H/s (50.59ms)\nHashtype: sha512crypt, SHA512(Unix)\nSpeed.Dev.#2.....:     1751 H/s (70.20ms)\nHashtype: OSX v10.4, v10.5, v10.6\nSpeed.Dev.#2.....: 72243.4 kH/s (71.20ms)\nHashtype: OSX v10.7\nSpeed.Dev.#2.....: 10024.2 kH/s (64.98ms)\nHashtype: OSX v10.8+\nSpeed.Dev.#2.....:      124 H/s (61.78ms)\nHashtype: AIX {smd5}\nSpeed.Dev.#2.....:   119.9 kH/s (81.63ms)\nHashtype: AIX {ssha1}\nSpeed.Dev.#2.....:   521.7 kH/s (74.40ms)\nHashtype: AIX {ssha256}\nSpeed.Dev.#2.....:   209.9 kH/s (77.59ms)\nHashtype: AIX {ssha512}\nSpeed.Dev.#2.....:    74265 H/s (59.87ms)\nHashtype: Cisco-PIX MD5\nSpeed.Dev.#2.....:   178.2 MH/s (58.37ms)\nHashtype: Cisco-ASA MD5\nSpeed.Dev.#2.....:   177.6 MH/s (58.52ms)\nHashtype: Cisco-IOS SHA256\nSpeed.Dev.#2.....: 36115.5 kH/s (72.14ms)\nHashtype: Cisco $8$\nSpeed.Dev.#2.....:      687 H/s (88.06ms)\nHashtype: Cisco $9$\nSpeed.Dev.#2.....:      511 H/s (18446743149559.57ms)\nHashtype: Juniper Netscreen/SSG (ScreenOS)\nSpeed.Dev.#2.....:   157.5 MH/s (66.09ms)\nHashtype: Juniper IVE\nSpeed.Dev.#2.....:   119.9 kH/s (81.63ms)\nHashtype: Android PIN\nSpeed.Dev.#2.....:    60292 H/s (82.18ms)\nHashtype: Citrix NetScaler\nSpeed.Dev.#2.....: 75719.9 kH/s (67.94ms)\nHashtype: RACF\nSpeed.Dev.#2.....:  6794.6 kH/s (95.90ms)\nHashtype: GRUB 2\nSpeed.Dev.#2.....:      464 H/s (61.76ms)\nHashtype: Radmin2\nSpeed.Dev.#2.....: 86833.5 kH/s (59.32ms)\nHashtype: SAP CODVN B (BCODE)\nSpeed.Dev.#2.....: 39078.1 kH/s (66.57ms)\nHashtype: SAP CODVN F/G (PASSCODE)\nSpeed.Dev.#2.....: 17468.5 kH/s (70.42ms)\nHashtype: SAP CODVN H (PWDSALTEDHASH) iSSHA-1\nSpeed.Dev.#2.....:    63560 H/s (77.91ms)\nHashtype: Lotus Notes/Domino 5\nSpeed.Dev.#2.....:  5354.9 kH/s (56.92ms)\nHashtype: Lotus Notes/Domino 6\nSpeed.Dev.#2.....:  1723.6 kH/s (1438.38ms)\nHashtype: Lotus Notes/Domino 8\nSpeed.Dev.#2.....:     6805 H/s (74.40ms)\nHashtype: PeopleSoft\nSpeed.Dev.#2.....: 86941.3 kH/s (58.91ms)\nHashtype: PeopleSoft PS_TOKEN\nSpeed.Dev.#2.....: 33778.8 kH/s (76.96ms)\nHashtype: 7-Zip\nSpeed.Dev.#2.....:      124 H/s (75.81ms)\nHashtype: WinZip\nSpeed.Dev.#2.....:    11481 H/s (49.08ms)\nHashtype: RAR3-hp\nSpeed.Dev.#2.....:      717 H/s (889.67ms)\nHashtype: RAR5\nSpeed.Dev.#2.....:      406 H/s (88.05ms)\nHashtype: AxCrypt\nSpeed.Dev.#2.....:     2909 H/s (176.78ms)\nHashtype: AxCrypt in memory SHA1\nSpeed.Dev.#2.....: 82613.6 kH/s (62.22ms)\nHashtype: TrueCrypt PBKDF2-HMAC-RipeMD160 + XTS 512 bit\nSpeed.Dev.#2.....:     3084 H/s (48.70ms)\nHashtype: TrueCrypt PBKDF2-HMAC-SHA512 + XTS 512 bit\nSpeed.Dev.#2.....:     4837 H/s (62.48ms)\nHashtype: TrueCrypt PBKDF2-HMAC-Whirlpool + XTS 512 bit\nSpeed.Dev.#2.....:      209 H/s (3054.25ms)\nHashtype: TrueCrypt PBKDF2-HMAC-RipeMD160 + XTS 512 bit + boot-mode\nSpeed.Dev.#2.....:     6200 H/s (48.70ms)\nHashtype: VeraCrypt PBKDF2-HMAC-RipeMD160 + XTS 512 bit\nSpeed.Dev.#2.....:        0 H/s (48.70ms)\nHashtype: VeraCrypt PBKDF2-HMAC-SHA512 + XTS 512 bit\nSpeed.Dev.#2.....:        0 H/s (62.50ms)\nHashtype: VeraCrypt PBKDF2-HMAC-Whirlpool + XTS 512 bit\nSpeed.Dev.#2.....:        0 H/s (3099.91ms)\nHashtype: VeraCrypt PBKDF2-HMAC-RipeMD160 + XTS 512 bit + boot-mode\nSpeed.Dev.#2.....:        0 H/s (48.70ms)\nHashtype: VeraCrypt PBKDF2-HMAC-SHA256 + XTS 512 bit\nSpeed.Dev.#2.....:        0 H/s (95.59ms)\nHashtype: VeraCrypt PBKDF2-HMAC-SHA256 + XTS 512 bit + boot-mode\nSpeed.Dev.#2.....:       31 H/s (95.62ms)\nHashtype: Android FDE <= 4.3\nSpeed.Dev.#2.....:     8664 H/s (70.48ms)\nHashtype: Android FDE (Samsung DEK)\nSpeed.Dev.#2.....:     3371 H/s (88.05ms)\nHashtype: eCryptfs\nSpeed.Dev.#2.....:      123 H/s (65.03ms)\nHashtype: MS Office <= 2003 MD5 + RC4, oldoffice$0, oldoffice$1\nSpeed.Dev.#2.....:  2960.9 kH/s (54.78ms)\nHashtype: MS Office <= 2003 MD5 + RC4, collision-mode #1\nSpeed.Dev.#2.....:  4345.6 kH/s (70.80ms)\nHashtype: MS Office <= 2003 SHA1 + RC4, oldoffice$3, oldoffice$4\nSpeed.Dev.#2.....:  3663.2 kH/s (84.05ms)\nHashtype: MS Office <= 2003 SHA1 + RC4, collision-mode #1\nSpeed.Dev.#2.....:  4238.2 kH/s (72.49ms)\nHashtype: Office 2007\nSpeed.Dev.#2.....:     1385 H/s (73.51ms)\nHashtype: Office 2010\nSpeed.Dev.#2.....:      677 H/s (73.51ms)\nHashtype: Office 2013\nSpeed.Dev.#2.....:       93 H/s (65.62ms)\nHashtype: PDF 1.1 - 1.3 (Acrobat 2 - 4)\nSpeed.Dev.#2.....:  4301.6 kH/s (71.51ms)\nHashtype: PDF 1.1 - 1.3 (Acrobat 2 - 4) + collider-mode #1\nSpeed.Dev.#2.....:  5249.6 kH/s (58.42ms)\nHashtype: PDF 1.4 - 1.6 (Acrobat 5 - 8)\nSpeed.Dev.#2.....:   226.8 kH/s (267.51ms)\nHashtype: PDF 1.7 Level 3 (Acrobat 9)\nSpeed.Dev.#2.....: 36090.1 kH/s (72.14ms)\nHashtype: PDF 1.7 Level 8 (Acrobat 10 - 11)\nSpeed.Dev.#2.....:     1288 H/s (495.20ms)\nHashtype: Password Safe v2\nSpeed.Dev.#2.....:     6198 H/s (142.95ms)\nHashtype: Password Safe v3\nSpeed.Dev.#2.....:    13677 H/s (92.71ms)\nHashtype: Lastpass\nSpeed.Dev.#2.....:    27309 H/s (88.61ms)\nHashtype: 1Password, agilekeychain\nSpeed.Dev.#2.....:    34725 H/s (69.75ms)\nHashtype: 1Password, cloudkeychain\nSpeed.Dev.#2.....:       93 H/s (62.34ms)\nHashtype: Bitcoin/Litecoin wallet.dat\nSpeed.Dev.#2.....:       31 H/s (65.64ms)\nHashtype: Blockchain, My Wallet\nSpeed.Dev.#2.....:  1094.0 kH/s (94.61ms)\nHashtype: Keepass 1 (AES/Twofish) and Keepass 2 (AES)\nSpeed.Dev.#2.....:     1905 H/s (106.98ms)\nHashtype: ArubaOS\nSpeed.Dev.#2.....: 72274.6 kH/s (71.23ms)\n```. This fixes #412, yay!. @matrix I can't :/ It still crashes when benchmarking Whirlpool: https://github.com/hashcat/hashcat/issues/412#issuecomment-264703313. ",
    "schluk": "Hi , \non my macbook pro : \nschluk$ ./hashcat -m 7100 -b\nhashcat (v3.20-71-gfd2ea07) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-2635QM CPU @ 2.00GHz, skipped\nDevice #2: ATI Radeon HD 6490M, 128/256 MB allocatable, 2MCU\n\nHashtype: OSX v10.8+\nAbort trap: 6\nAlso : \nhow long should take example0 on such hardware ? \nThanks, . ",
    "jjarava": "Hi!\nI'm having the exact same issue of the OP.\nJust downloaded and compiled hashcat as per the BUILD.md file.\n```bash\njjarava@Mac:hashcat on master $ ./hashcat -b -D1,2\nhashcat (v3.40-93-g6c98fac) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-3520M CPU @ 2.90GHz, 4096/16384 MB allocatable, 4MCU\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\n\nHashtype: MD4\nSpeed.Dev.#1.....:   190.1 MH/s (21.88ms)\nSpeed.Dev.#2.....:   321.5 MH/s (51.79ms)\nSpeed.Dev.#*.....:   511.6 MH/s\n<...> \nHashtype: SHA-512\nSpeed.Dev.#1.....:  5840.5 kH/s (89.68ms)\nSpeed.Dev.#2.....:  7569.9 kH/s (63.25ms)\nSpeed.Dev.#*.....: 13410.4 kH/s\nHashtype: SHA-3 (Keccak)\nAbort trap: 6\n```\nIf I run hashcat -b -D1 I do get the benchmark to run past SHA-3, but the performance is lower...\n. ",
    "danpalmer": "I just experienced this on macOS Sierra, MacBook Pro i7, Hashcat 3.10.. ",
    "DustyPaw": "Same here, eg:\n```\n... Hashmode: 3200 - bcrypt $2*$, Blowfish (Unix) (Iterations: 32)\n\nDevice #1: Skipping unstable hash-mode 3200 for this device.\n             You can use --force to override, but do not report related errors.\n\nHashmode: 1800 - sha512crypt $6$, SHA512 (Unix) (Iterations: 5000)\nSpeed.Dev.#1.....:      624 H/s (79.90ms) @ Accel:512 Loops:128 Thr:1 Vec:2\nHashmode: 7500 - Kerberos 5 AS-REQ Pre-Auth etype 23\nclEnqueueNDRangeKernel(): CL_INVALID_WORK_GROUP_SIZE ...\n```\nor ...\n```\n$ ./hashcat -m 2500 -D1,2 -b\nhashcat (v4.1.0-7-gf6cfcbb) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-2640M CPU @ 2.80GHz, 4096/16384 MB allocatable, 4MCU\n\nBenchmark relevant options:\n\n--opencl-device-types=1,2\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#1.....:     2806 H/s (90.93ms) @ Accel:1024 Loops:256 Thr:1 Vec:4\nStarted: Fri Apr 13 20:24:51 2018\nStopped: Fri Apr 13 20:24:57 2018\n```. Ah OK, OpenCL isn't supported on Macs with Intel HD Graphics 3000.. ",
    "ZbigniewB": "\nBut I think the standard should be respected - and DOS/Windows standard is \"ending the line with CR-LF\". So you say: especially \"to save 500 bytes\" in output text file I should install text editor, which will occupy several megabytes of my disk space? Just to skip some CRs?\nNot sure which version he used - but many people still use Windows XP, and they don't care what Microsoft thinks about this. Considering that: \"32-bit binary\" should be \"Windows XP ready\", I think.\n\nAnyway: I reported obvious bugs - the rest isn't up to me.\n. One more thing: just compiled hashcat. When trying to use it, it istantly spits an error instead of doing its job:\n\"hashcat (v3.00-30-g450b779) starting...\nATTENTION! Can't find OpenCL ICD loader library\nYou're probably missing the \"ocl-icd-libopencl1\" package (Debian/Ubuntu)\n  sudo apt-get install ocl-icd-libopencl1\"\nOf course I'm missing, since I've got no idea, what \"OpenCL ICD loader library\" actually is, neither why do I want it (I didn't need it before). Not a single word about this in BUILD.md, of course - it is assumed, that since I'm Linux user, therefore I'm familiar with every single one out of thousands various libraries available for Linux.\n. - numactl dependency not mentioned at all\n- it could be worthy to explain, how to install \"OpenCL ICD loader library\" by hand, the most \"generic\" way, which will work everywhere (I use Slackware, not Debian/Ubuntu)\nWith a little help of \"strace\" finally I managed to make it work - it could be done much faster with proper, tidy docs.\n. ",
    "mshindal": "That worked, thanks!\n. ",
    "lifanov": "No problem! It works, according to me.\n. FreeBSD port for new hashcat landed. I renamed the previous port to hashcat-legacy as per upstream, so both are available.\n. Yes, it works. It has been working since release. I'm just trying to de-uglify the port.. Hmm, let me re-test. Yep, it works:\n$ file hashcat\nhashcat: ELF 64-bit LSB executable, x86-64, version 1 (FreeBSD), dynamically linked, interpreter /libexec/ld-elf.so.1, for FreeBSD 12.0 (1200019), FreeBSD-style, stripped\n$ ldd hashcat\nhashcat:\n    libhashcat.so => ./libhashcat.so (0x800827000)\n    libthr.so.3 => /lib/libthr.so.3 (0x800b07000)\n    libc.so.7 => /lib/libc.so.7 (0x800d2e000). Runtime works too. This is all that's needed for hashcat port to be patch-free in the next release:\nhttps://github.com/freebsd/freebsd-ports/commit/19bf8a22ad805fbf22ce7b5dabe4bd6a693a4e48. ",
    "negrusti": "Thanks for replying, I can send you the complete hash via email, can you send me yours to negrusti@gmail.com?\n. ",
    "vom513": "hashcat-potfile-example.txt\n. Yes, seems to (really) work as expected now - tested with v3.00-47-gbaea682.  I put my original oclHashcat.pot in place (~ 200k lines, multiple algos/hashes) and it did fine parsing that as well.\nThanks so much for looking at this so quickly.\n. Same hccap.  Essentially the crack can run up to two times for the same \"hash\".  The ordering of the AP and client MACs seem to make it think they are unique hashes, hence the second run.\n. I see the changelog entry for 3.00.  It could be that I still have some entries in my potfile(s) that have the 'old' ordering, therefore it's not matched on the new (stable) logic in 3.00.\nI've just manually edited my potfile to remove all the entries for my test network and recracked it.  After this I've ran hashcat many times against it and it seems to reliably match from the potfile and not recrack.  Looks like the fix was in 3.00 and my potfiles just have 'old' entries.  Sorry for the noise.\n. ",
    "AresS31": "Thanks for this reply @philsmd! \nCould I know why this choice of mask? It would be I think more logical to use ?a for the default mask to simulate a \"pure\" bruteforce attack using the default hashcat behavior.\nTherefore, as a code request for what I judge to be an improvement. I would suggest to change the mask to ?a for the default behavior.\nBest,\nAlexandre\n. I am happy with this explanation. Thanks for your time!\n. Exactly!\n. I personally think that it might be a \"good\" extra information to print out. It is up to you at the end. :)\n. Thanks :)\n. Understood! :)\nAn other question in the same line. Why not having only one hybrid attack mode instead of two (-a 6 and -a 7). The relative position of the mask to the wordlist should be easy to parse, isn't? \nFor example using\nhashcat -a hybrid_attack_id hashes.txt wordlist maskwould result in wordlist+mask\nand\nhashcat -a hybrid_attack_id hashes.txt mask wordlistwould result in mask+wordlist\n. > it's possible to specify a directory instead of several files (also for -a 6 and -a 7).\n@philsmd I have tried to give a directory instead of wordlists files and it did not work. \n. Same issue for me with a RS256 JWT token, I keep getting the \"Token length exception\".. Well, I don't really know the underlying code for this feature but that would basically be taking what is coming from STDIN as the wordlist rather than a text file. I think this could be a very useful feature and simplify quick cracking attempts.. ",
    "migroves": "Installing Nvidia's alternative drivers of OS X fixed it for an iMac with a geforce 750M (- Device #2: GeForce GT 750M, 256/1024 MB allocatable, 2MCU)\nThe current version for El Capitan (10.11.6) can be found here:\nhttp://www.nvidia.com/download/driverResults.aspx/105646/en-us\n. ",
    "komer83": "ERROR: clEnqueueNDRangeKernel(): CL_INVALID_WORK_GROUP_SIZE\nhashcat -D 1,2 -m xx -a 0 /Users/xxx/hashes.txt /xxx/rockyou.txt -outfile=unhashed.txt\n. ",
    "Ins1ghtLabs": "+1. +1. \nI got an algorithm that is sha1(unicode($pass.$salt)) and the salt is a fixed 40 char sha1 hash.\n. Seems I need to somehow add additional parser in mpsp.c and change status_ctx->words_off and \nstatus_ctx->words_base when the job is starting.\n. Pull request:\nhttps://github.com/hashcat/hashcat/pull/574\n. @magnumripper because it's easier to use '|' than ',' , so I won't have to write code to figure out whether that part is a custom charset or mask or skip/limit number, or touch the mask parsing logic.\n. \"For example, this would not work to set -s and -l for a folder full of wordlists, which hashcat supports and which is also an iterated attack.\"\nWhich attack mode is this? can you elaborate?\n. Well, the delimiter '|' can't be escaped, therefore it can't be used in any inline charsets or masks. Although '|' is very rarely used anywhere, which is the reason why use it as the delimiter.\n. Without this feature, hashcat can only distribute the workload one mask at a time, if the hash file is large, it takes a long time to restart because it has to reload the hash file into memory and map them  again.  By pre-calculating keyspaces and ECDs of all masks in a mask file before hand, we can divide heavier masks into smaller workloads and generate mask files with equal workload mask files  then assign these files to the worker nodes. We can also tailor workloads to different sizes to suit worker nodes that have different performance.\n. ",
    "DidierStevens": "Tested with new .cl files. It works now, thanks.\n. ",
    "mame82": "Using hascat64.bin Version 3.10 in attack mode 3 with --increment option enabled empty hashes don't geht recognized for LM (hashmode 3000).\nThis has to be solved manually by switching to straight attack and hitting enter to produce an empty hash, as --weak-hash-threshold doesn't work in attack mode 3 and an empty mask couldn't be used.\n. I fully understand, but empty hash checking should be done at least for second half of the LM hash in attack mode 3. Otherwise, if password have less than 8 chars they'll never get cracked. According to this issue this has been done in mode 3 on version 3.0.\nI've opened a new issue for this, feel free to close it but there should be an advise that straight attack has to be used upfront\n. `INFO: approaching final keyspace, workload adjusted\naad3b435b51404ee:X\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (?1) [1]\nHash.Target....: aad3b435b51404ee\nHash.Type......: LM`\nAccording to this output snippet from the post above, recognizing aad3b435b51404ee for\nempty hashes was possible, the only problem was that a wrong plain character gets delivered.\nCould you please clarify, if the only option to get a (single concatenated) LM hash with\nsecond half-hash empty, is to run straight attack mode upfront?\nThx in advance\n. I used the binary from https://hashcat.net/hashcat/ (2016.08.19).\nI'm trying to reproduce and report back.\n. $ hashcat64 -v\nv3.10\nTestcase test.txt (first hash is empty,second with length 4 \"hack\")\n$ cat test.txt \nempty:aad3b435b51404eeaad3b435b51404ee\nhack:9d82cdff56b35758aad3b435b51404ee\nInvoking hashcat  - hashcat64 is a symlink to hashcat64.bin, hashcat.pot was deleted before start.\nI was forced to remove libxnvctrl-dev, thus there's a warning (shouldn't matter here).\n```\n$ hashcat64 -m 3000 -a 3 --username --increment -1 ?u?d?s test.txt ?1?1?1?1\nhashcat (v3.10) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz, skipped\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #2: GeForce GTX 980M, 2028/8112 MB allocatable, 12MCU\nDevice #2: WARNING! Kernel exec timeout is not disabled, it might cause you errors of code 702\n             See the wiki on how to disable it: https://hashcat.net/wiki/doku.php?id=timeout_patch\n\nWARN: nvmlDeviceGetFanSpeed() 3 Not Supported\nWARNING: Failed loading the XNVCTRL library: libXNVCtrl.so: cannot open shared object file: No such file or directory\n         Please install libxnvctrl-dev package.\nHashes: 4 hashes; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Final-Permutation\n Not-Iterated\n Single-Salt\n* Brute-Force\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger set to 75c\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1) [1]\nCustom.Chars...: -1 ?u?d?s, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: aad3b435b51404ee, 9d82cdff56b35758\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#2...:        0 H/s (0.06ms)\nRecovered......: 0/2 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 69/69 (100.00%)\nRejected.......: 0/69 (0.00%)\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?1) [2]\nCustom.Chars...: -1 ?u?d?s, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: aad3b435b51404ee, 9d82cdff56b35758\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#2...:    22215 H/s (0.05ms)\nRecovered......: 0/2 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 4761/4761 (100.00%)\nRejected.......: 0/4761 (0.00%)\nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?1?1) [3]\nCustom.Chars...: -1 ?u?d?s, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: aad3b435b51404ee, 9d82cdff56b35758\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#2...:  1512.1 kH/s (0.87ms)\nRecovered......: 0/2 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 328509/328509 (100.00%)\nRejected.......: 0/328509 (0.00%)\n9d82cdff56b35758:HACK                                   \nINFO: approaching final keyspace, workload adjusted       \nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?1?1?1) [4]\nCustom.Chars...: -1 ?u?d?s, -2 Undefined, -3 Undefined, -4 Undefined\nHash.Target....: aad3b435b51404ee, 9d82cdff56b35758\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#2...: 81599.4 kH/s (11.87ms)\nRecovered......: 1/2 (50.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 22667121/22667121 (100.00%)\nRejected.......: 0/22667121 (0.00%)\nStarted: Fri Sep  2 12:05:44 2016\nStopped: Fri Sep  2 12:05:46 2016 \n```\nSo the mask mode starts with length 1 not 0.\nThe recognized hash is the one with 4 chars (hack), but the second half stay unrecognized.\n```\n$ hashcat64 -m 3000 -a 3 --username --show test.txt\nhashcat (v3.10) starting...\nhack:9d82cdff56b35758aad3b435b51404ee:HACK[notfound]\n```\nAs you can see, second half of \"hack\" is still declared [notfound] and the empty password for user\nempty isn't showing up.\nYour log shows the same, as the mask mode should have tested for a password \"X\" and the result for\ntarget aad3b435b51404ee are 0/1 recovered hashes - so you have already reproduced the issue.\n```\nHash.Target....: aad3b435b51404ee\nHash.Type......: LM\nTime.Started...: 0 secs\nSpeed.Dev.#1...:        0 H/s (0.05ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\n```\n. ",
    "ghroll": "wine hashcat32.exe -b -m 0 \nhashcat (v3.00-61-g2b7e36b) starting in benchmark-mode...\nOpenCL Platform #1: Mesa, skipped! No OpenCL compatible devices found\nERROR: No devices found/left\n. Here is intel\nI do not use gpu\nIt only works with gpu this new version of hashcat?\nIf so I'm lost ....\nI dont use video card :(\n. I saw it really is one terrible installation ...\nI'm going back to an earlier version of hashcat.\nI received a new update on linux kali and I am with this problem.\nI will try to find an easier way to solve it :/\nThank you for answering!\n. @neheb \nI have installed this shit\nHow can I solve this problem ?\nThe hashcat developer did not leave another alternative for users ... at least an earlier version.\nHe only knows close the issues .\nThank you for answering ;)\n. ",
    "dmknght": "Hi everyone! I am using core i3 3110M, parrot os 4.9. My hashcat is having clGetDeviceIDs(): CL_DEVICE_NOT_FOUND error. But i made it work by adding --force option.\nI used hashcat -m 0 hash temp/rockyou.txt --force, hash is the file stored my testing md5 hash.. ",
    "gripedthumbtacks": "If you run nvidia driver:\n$ sudo apt remove mesa-opencl-icd\n$ sudo apt install nvidia-opencl-icd. ",
    "kenji21": "see https://hashcat.net/forum/thread-6299.html : ~/.hashcat/hashcat.potfile\n. ",
    "ChristopherAnders": "good call.. It cracked. However, I tried with appleappleapple as a test to ramp things up and still no response. \ncomputer:~ Chris$ echo -n appleappleapple |md5\n43d96258357f08869100a1e650ff3442\ncomputer:~ Chris$ cat > test.txt\n43d96258357f08869100a1e650ff3442^D\ncomputer:~ Chris$ cat test.txt\n43d96258357f08869100a1e650ff3442\n```\ncomputer:~ Chris$ hashcat -m 0 -a 3 /Users/chris/test.txt\nhashcat (v3.00-63-gc837df0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\n* Raw-Hash\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1) [1]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...:        0 H/s (0.06ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 62/62 (100.00%)\nRejected.......: 0/62 (0.00%)\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?2) [2]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...:     3365 H/s (0.09ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 2232/2232 (100.00%)\nRejected.......: 0/2232 (0.00%)\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?2?2) [3]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...:    97716 H/s (0.14ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 80352/80352 (100.00%)\nRejected.......: 0/80352 (0.00%)\nATTENTION!\n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?2?2?2) [4]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...:  3440.5 kH/s (2.02ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 2892672/2892672 (100.00%)\nRejected.......: 0/2892672 (0.00%)\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?2?2?2?2) [5]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nSpeed.Dev.#2...: 94020.0 kH/s (8.85ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 104136192/104136192 (100.00%)\nRejected.......: 0/104136192 (0.00%)\nINFO: approaching final keyspace, workload adjusted\nSession.Name...: hashcat\nStatus.........: Exhausted\nInput.Mode.....: Mask (?1?2?2?2?2?2) [6]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: Fri Jul 22 23:03:12 2016 (8 secs)\nSpeed.Dev.#2...:   416.0 MH/s (7.61ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 3748902912/3748902912 (100.00%)\nRejected.......: 0/3748902912 (0.00%)\nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: Mask (?1?2?2?2?2?2?2) [7]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: 0 secs\nTime.Estimated.: Fri Jul 22 23:13:11 2016 (9 mins, 43 secs)\nSpeed.Dev.#2...:   230.9 MH/s (11.30ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 357826560/134960504832 (0.27%)\nRejected.......: 0/357826560 (0.00%)\nRestore.Point..: 0/1679616 (0.00%)\n```\n. I suppose my question isn't understood.. The info you have all provided has helped me understand hatchet a little more but why is my CPU not being ramped up via activity monitor like it used to with hashcat? Dave, JTR, aircrack etc all work just fine but for some reason hashcat won't show usage of hardware. \nHere is my output below based on a md5 hash appleappleapple and the mask to match it with all lower case. \nmy questions: \n- why is my CPU not being used fully\n- why are one of my devices being \"skipped\"\n```\ncomputer:~ Chris$ hashcat -m 0 -a 3 /Users/chris/test.txt ?l?l?l?l?l?l?l?l?l?l?l?l?l?l?l\nhashcat (v3.00-63-gc837df0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable Optimizers:\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Hash\n Single-Salt\n Brute-Force\n* Raw-Hash\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: Mask (?l?l?l?l?l?l?l?l?l?l?l?l?l?l?l) [15]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: Sat Jul 23 10:00:04 2016 (6 secs)\nTime.Estimated.: > 10 Years\nSpeed.Dev.#2...:   441.3 MH/s (11.69ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 2696970240/17052375651866279936 (0.00%)\nRejected.......: 0/2696970240 (0.00%)\nRestore.Point..: 0/970207991116652 (0.00%)\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: Mask (?l?l?l?l?l?l?l?l?l?l?l?l?l?l?l) [15]\nHash.Target....: 43d96258357f08869100a1e650ff3442\nHash.Type......: MD5\nTime.Started...: Sat Jul 23 10:00:04 2016 (17 secs)\nTime.Estimated.: > 10 Years\nSpeed.Dev.#2...:   420.5 MH/s (11.73ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 7847751680/17052375651866279936 (0.00%)\nRejected.......: 0/7847751680 (0.00%)\nRestore.Point..: 317440/970207991116652 (0.00%)\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\n```\n. ",
    "idontlie": "Ok, thanks. But since this seems to be a common issue, it would be nice if  someone made a wiki article tutorial thing about it. \n. ",
    "hack4sec": "Sorry for less information. Win7, ATI, HC2 and HC3. \"75D60B9507A4BCB20DDD0F3ADCAA47E7\" - target hash, \"374996a5e8a5e57fd97d893f7df79824\" - hash of alg 21 from wiki. \nHC2\n\nC:\\hc2>oclHashcat64.exe -m21 -a0 75D60B9507A4BCB20DDD0F3ADCAA47E7 tmp.txt\noclHashcat v2.01 starting...\nWARNING: Hash '75D60B9507A4BCB20DDD0F3ADCAA47E7': Line-length exception\nERROR: No hashes loaded\nC:\\hc\\hc>oclHashcat64.exe -m21 -a0 374996a5e8a5e57fd97d893f7df79824 tmp.txt\noclHashcat v2.01 starting...\nWARNING: Hash '374996a5e8a5e57fd97d893f7df79824': Line-length exception\nERROR: No hashes loaded\n\nHC3:\n\nC:\\hc3>hashcat64.exe -m21 -a0 75D60B9507A4BCB20DDD0F3ADCAA47E7 tmp.txt\nhashcat (v3.00-1-g67a8d97) starting...\nWARNING: Hash '75D60B9507A4BCB20DDD0F3ADCAA47E7': Line-length exception\nERROR: No hashes loaded\nC:\\hc3>hashcat64.exe -m21 -a0 374996a5e8a5e57fd97d893f7df79824 tmp.txt\nhashcat (v3.00-1-g67a8d97) starting...\nWARNING: Hash '374996a5e8a5e57fd97d893f7df79824': Line-length exception\nERROR: No hashes loaded\n. Oh, sorry, i thinked 36 it`s a password. Closing ticket.\n. \n",
    "vdun": "Thanks, this is what I meant.\nSometimes one does not know in details the implementation of the hash algorithm (e.g. closed source program). So would it be possible to add a new feature by making it more generic by letting hashcat call a target program (with the clear text) and comparing the output if it is correct or not ?\n. This could be done by making a new mode/API for target programs.\nExample:\n- input for target is: buf as byte, len as INT (length of buf)\n- If the target program returns 1=Good, -1=Bad, ...\n  And it is up to the reverser to make a wrapper around to make it comply with the API.\n. Thanks\n. ",
    "bledari": "I'm dealing with a MD5 + DES encryption, seems this issue would be the solution. Any suggestions on how I can use hashcat on my scenario?.  Why is this closed, @jsteube you should reopen it. ",
    "fransla": "./hashcat -m 1510 -b -D 1,2 -w 4\nhashcat (v3.00-70-gdbe33d8) starting in benchmark-mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i5-4690 CPU @ 3.50GHz, 2048/8192 MB allocatable, 4MCU\nDevice #2: AMD Radeon R9 M290X Compute Engine, 512/2048 MB allocatable, 20MCU\n\nHashtype: DES\nSpeed.Dev.#1.: 33435.1 kH/s (125.36ms)\nSpeed.Dev.#2.:   743.5 MH/s (477.53ms)\nSpeed.Dev.#*.:   777.0 MH/s\nStarted: Tue Aug  2 16:48:51 2016\nStopped: Tue Aug  2 16:48:57 2016 \n. Hi Jens,\nSorry for the slow response, I am a bit busy at work but will make most of the changes. The bitslicing will probably not be done yet though\nFrans\n\nOn 24 Aug 2016, at 11:14, Jens Steube notifications@github.com wrote:\n@fransla please respond\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. You should put the CipherText first, then the known PlainText, so try 1B5B3EDF6511A554:DA93B01EF7F98852\n. jsteube changed the order around when merging back into hashcat; the pull request had PT:CT, but this code now requires CT:PT. The bitslicing for -a 3 for DES might affect your results, so try using your example as a single key 3DES, which is equivalent, so this works for me:\nhashcat -m 14100 1b5b3edf6511a554:da93b01ef7f98852 -a 3 -1 ./charsets/DES_full.charset --hex-charset 01010101010126?101010101010126?1010101010101?1?1\nI am not quite sure why it seems to give trouble in -m 14000 -a 3\n. I can confirm that -m 14000 did not work for me\n. \n",
    "jark22": "Can anyone show an example that works with DES-ECB?  I was using the following command using that custom character set but I could be doing it wrong.\nhashcat -m 14000 --custom-charset1=charsets/DES_full.charset -a 3 0123456789abcdef:8a5ae1f81ab8f2dd     ?1?1?1?1?1?1?1?1  \nwhere the key was all 1's.  It takes a couple of minutes to run but obviously does not run through the whole keyspace and fails to find a solution\n. ",
    "Forts117": "Hi guys... great work you are doing here with this!  I'm hoping someone can point me in the right direction though.  I've run multiple sample numbers and I never seem to find the key.  For example jark22s post above, I don't find the key.  I've also used DA93B01EF7F98852:1B5B3EDF6511A554 which should be key: 0101010101012626 with no success (these numbers were confirmed as good with this tool - http://des.online-domain-tools.com/).  \nHere is the command line I'm using: \nhashcat64.exe -m 14000 hashes.txt -o cracked.txt -a 3 -1 charsets/DES_full.charset --hex-charset ?1?1?1?1?1?1?1?1 -w 3\nDoes anyone have any suggestions as to what I might be doing wrong?  Or have a known working set of numbers I can try?\nMany many thanks!\n. That's where it gets confusing, the very first message in this thread says PT:CT, yet I've seen other comments like yours suggesting CT:PT.  Regardless, I've tried both ways... No joy. Does it work for you? (If you happen to have a minute to give those numbers a try that is....)\nThanks!!\n. As I mentioned above, a few datasets were tested in the other page I linked to.  A few other users (jark22, fransla and bigfella237) were unable to get known keys from CT:PT pairs.  Fransla noted that -14100 works but he was unable to have success with -14000.  Here are 4 datasets, none of which seem to work for me:\n47DC9810ADE39295:A04AB36B33E34FF2  (key: 0101010101010101)\n1B5B3EDF6511A554:DA93B01EF7F98852  (key: 0101010101012626)\n1DBD2AB7D1CB9E7E:B36DE1B9DAC7DC0D  (key: 01020407080B0D0E)\n1BB15088EFD7E0FA:9510DC4C681ED5AD  (key: ABBACDDCEFFE1023)\nCan someone else please try one of these sets using -14000 and see if it works for them?\nAlso I don't understand the example you posted above... where is the recovered key shown? I'm quite new to this whole process so please excuse my ignorance if I'm doing something in the process incorrectly....\n. Oh!  Ok, maybe we've found the problem then.  You mentioned \"amd-gpu-pro is known to be broken\" and I am indeed using an AMD GPU (RX-480).  Could this be the root of all my issues then perhaps??\nUpdate: I just tried my sample numbers again using your command line of:\nhashcat64 -m 14000 47DC9810ADE39295:A04AB36B33E34FF2 -a 3 --quiet --hex-charset --outfile-format 5 --potfile-disable ?1?101010101?1?1 -1 charsets/DES_full.charset\nand it's working! Not sure what I was doing didderently but this is very encouraging.  Thank you very much for your help with this @jsteube it's greatly appreciated!\n. ",
    "redongh": "re-tested all supported truecrypt modes with a little script i just created against hashcat v2.01 and v3.00-1-g67a8d97 and all example .tc files provided in the hashcat wiki.\nfrom the scripts output (see attached files) you can see that this bug seems to only affect sha512 based cascaded ciphers in 1536 bit mode (-m6223) as all others seem to work like expected and done back in v2.01.\nresult_hc201.txt\nresult_hc300.txt\nresults.diff.txt\n. @jsteube Confirming that your workaround jsteube@d7f078cb45e5d0b3029c14e4d9cbf8e49c158ce2 is resolving #456 as my test-script now yields the same results as v2.01 did while maintaining the performance-level of v3.00 on my nvidia gtx 9X0 based machines.\nnice work, thanks for the superfast reaction! :+1:\n. @mubix while your particular usecase might make it appear more useful to have only the passphrase written to the .pot-file others (such as myself) may prefer different settings for their particular usecases. thats where configurable defaults or user-scripts that contain your favorite parameters come in handy.\nchanging such default behaviors involves the risk of breaking established workflows and tools reflecting such so I'd be rather hesitant on such change request, especially since as @usernamestaken just suggested the desired behavior is already implemented, working and accessible through --outfile and --outfile-format 2 parameters .\nmaybe configurable defaults might be a good idea, say by specifying something like a hashcat.defaults file that hashcat reads if present in its working-dir where certain parameters can be pre-set in a custom manner like suggested in #469. what do you think about such feature?\n. ",
    "mubix": "The point would be to make sure any \"known\" plaintext would not have to be cracked, even if it's from a different hash type\n. @usernamestaken aye, knew about those, just was looking for something that was always on and always appending. Updated the title to reflect (wrote this last night from my phone, sorry for not being more succinct :(\n. Closing, I'll hit up the forums instead. Looks like thats were stuff like this is supposed to go\n. For any who find this, it was actually mesa-opencl-icd that worked out\n. ",
    "KOLANICH": "\nSync your branch with hashcat master, I got tons with conflicts. We're are hashcat v3.10 already, while you're at v3.00\n\nYou can see I have already done that, the version was rebased upon master and conflicts are solved semi-manually. As you see, the version number now is parsed from the nearest tag from git and the version number v3.00 in CMakeLists.txt is just a fallback.\nMerge conflicts are not solved automatically (in theory they could be solved completely automatically, but it would require some advanced tools merging ASTs and keeping history of coder's actions in IDE) because a lot of code is changed and put into another files. To merge you need to solve conflict by simply picking my versions.\n\nIs it possible to make this without using cmake?\n\nBoth yes and no. Yes because you can pregenerate files with cmake. No because cmake gens system-specific files without flexibility in them. But don't worry, cmake is already de-facto standard way to build cross-platform software, lots of well-known projects use it: opencv, libnfc, websocketpp for example.\nOf course you can use another build system, but I don't think the users will be happy to download install python or cygwin just to build hashcat. Cmake is both lighthweight and powerful solution for this.\n\nWhat is a windows shim?\n\nit is *nix shim for windows. It is some headers missing in MSVC I found over internet and put together into a git repo for convenience.\n\nHow can I cross-compile the windows binaries from Linux. Users expect that from us\n\ncmake allows you to provide the toolchain you want to use, including cross-compilers.\n\nWhat advantage is it to have those enum types over macro definitions?\n\nMacros is a very dirty way to do things, they transform the source code in unobivious way, which can cause very hard-to-find errors. You see the code, but in fact it is another code. Please, don't use them except the case of extreme need. I have replaced macros with enums and inlines to be sure that the compilation errors I was getting were not caused by them.\n\nWhy did you add type naming after: typedef struct XXXX_t_ { ... } XXXX_t; ? Anonymous structs are fine aren't them?\n\nThey are fine, but Visual Studio writes the struct type in tooltips, not the typedef one, which looks not fine if the structs are anonymous.\n\nThe filenames have no real convention, for example: ext_OpenCL.h <- original, filenames_generators <- new type 1, hc_concurrency.h <- new type 2. So the question is, why having hc_* in front for some and for others not?\n\nBecause some symbols in them have hc_ prefix :)  In fact developing naming convention is not my target for now, the primary target is to make it be built without errors with msvc, gcc, g++ and clang.\n. > The idea seems nice, however there also some problem with it. If there's any code included automatically from a different repository, than this repository could be used to inject code without any changes to hashcat\nYes, it can be used, if one manages to find a collision for sha1 ;).\n. 1 I used the tool in VS to reindent the code. Reindentation was needed to be able to reorder commits. It crashed the handmade alignment and reindented using own standards. I (or you) can filter the branch with AStyle, which can solve some issues, will it be enough?\n2\n\nIt's not like that would create any better view on the folder, because in the main src folder is 10 files anyway\n\nThe count is increased in later commits.\n3\n\nIt's not like this creates alot of confusion. OTOH, it creates lots of problems with the Makefile. We'd need to rewrite it in a way so that it is able to handle the new folder structure. \n\nThe makefile is to be replaced with cmake script, which uses globbing to get list of all c and h files in the project.\n. > What is BASETSD_H ?\n\nIs BASETSD_H a pre-existing macro from vc or set from Makefile?\n\nA macro defined in a header supplied with compiler where the types you define are defined. Don't know if it exists in gcc and clang, but in VS it is.\n. > we can no longer inline it.\nThat's sad. There are dedicated instructions for this in cpus, so those header is just compiler abstraction layer, they are really meant to be inlined. In later commit I've implemented them as compiler intrinsics (which means their calls would be converted into a single instruction, and they really are, as disasm says).\n. > The use of them is not time intensive, so it's fine\nIt's true, but it is ugly. We still need headers, so I see no reason to move the implementations to a separate binary library. BTW, why do we keep cpu implementations of algorithms at all? GPUs perform much better for computations and there are opencl runtimes for cpus for the cases we need to do the operation on a cpu (and we don't need to optimize those kernels for cpus because as you mentioned performance is not critical in that case)?\n. OK\n. How is the progress?\n. OK.\n. The advantages:\n- capabitity design patterns, for example it can be possible to encapsulate cryptoalgorithms into classes and deal with them in a more uniform way (you can also do it in C putting the base object as the first field and casting the pointer)\n- c++ idioms like raii\n- c++ cross-platform standard library for dealing with threads, time and randomness\n- more strict type checking, elimination of macroses in favour of templates\n- computing tables of coefficients in compile time without storing them as they are in the source code.\nThe disadvantages:\n- imcompatibility with C\n- no standardized ABI for object oriented code which means  one doesn't simply link OO code from the libraries built with another compiler. Not a very big issue.\n- the standard library tools lack some features used like setting affinity\nSince C++ includes frequently used subset of C, I see no reason not to make some minor changes and start to use C++ right now.\n. > C is simpler and easier to read.\n... when used for simple hello-world-level programs.\n\n\"Entities must not be multiplied beyond necessity\"\n\n\n\n-Don't multiply entities, b1tch! Don't multiply!\n-OK, Occam, just move the razor away!\n\nIn this case it seems to be necessary because hc is much more complex than helloworld.\n. hashcat is not linux kernel and Linuse's statement was about c++03.\n. > it can be possible to encapsulate cryptoalgorithms into classes and deal with them in a more uniform way\n. Rust can be good, but it is a bit too complicated and hard-to-use. C++ is compatible with c which makes transition easy. So I think it'd be better migrate it to C++ first, reengineer, and then rewrite into rust if it worth it.\n. I still find no good reason to stay on an old language without built-in virtual functions, inheritance and backward compatible with the old one in some large subset.. No problem specific to hc. All the apps in C I saw have the same problems: the code is bloated with pointers (solved by the convention that this is the default pointer and inheritance, allowing to call access the inherited objects without this), macros (often can be solved by templates usage), resources allocation/freeing (raii) and copypasting the code (solved by inheritance and virtual functions). C++ is mainly just a syntax sugar for the things which can be (and often are) done manually in C , a bit more strict type checking and the c++ standard library.\nD can be even better, but it it doesn't have enough good tools and features. Python also can be used (and is used in pyrit) since the main work is done in opencl code, but there is a drawback that you need a python interpreter/jit-compiler. It is nearly always present on linux desktop systems, but nearly never in windows ones.. OK. > Some of those \"if/else\" ladders which you have rewritten to use switch(). I like the way it is and sometimes using switch() makes it harder to read.\n\nI prefer it the original way, it's much easier to read\nI don't think so, but you to decide. One of main purposes purpose of these to make it be build with VS. In fact we don't even need the ladders/switches because the better approach is to populate container with objects/function pointers and select the function by offset.\nMoving code into subfolders make the Makefile unneccary complicated\n\nNot moving makes directory content hard-to navigate. And I don't see much complication in it. Anyway, my cmake script did the globbing.\n\nNot sure why we should move this into a separate file.\n\nWhy not? Large files slow down IDEs.\n\n7fb6fce\n6deede5\n2f4dfdc\n\nand\n\n12e9365\nNot merged.\nDon't see a reason to do that.\nMakes it harder to read. Are there any technical advantages?\n\nType safety and \"source-code safety\" (I mean that if you see the code you can expect that it is actual code, and if you see it valid, it's valid, and if you encounter a compilation error you can investigate the cause without dumping preprocessed output, and if you debug, you see the code corresponding to binary not tampered with macros) are always an advantage. Macros must be eliminated everywhere it is possible because they make the project unmanageable.\n\nIs it because it's better not to use & inside a function macro?\n\nSince C has no references we have to use pointers to replace macros with inlines. The addresses of operands are not params for macros - they are params for inline functions (in the hope the compiler would optimize them out (VS does this and in release we have a long sequence of instructions without calls)). After migration to C++ it would be possible to replace pointers with refs (which are just syntax sugar for pointers) and remove ampersand operators.\nAnother problem is that I see that some defines in your code I've turned into consts/enums/inlines.\n\n239dd7e\n4db2492\n4b4f7ac\nNot merged.\nI don't see any disadvantages.\n\ntheoretically using include guards instead of pragmas slowes the compilation: the preprocessor have to load a file and process it instead of checking its internal associative container to determine if the file was already used. We have to solve problem with pragmas on Mac. If you possess one you can try adding pragmas one by one to determine the troubleful header.\n\nThis section has been taken of from original ADL headers from AMD. I don't think we should change anything to them directly. Can we do this indirectly?\nThis section has been taken of from original NVML headers from Nvidia. I don't think we should change anything to them directly.\n\nWe should decide how do we use the headers: as black boxes or as white ones. If we use them as black boxes we don't touch them at all and even don't have them in repo by itself, using submodules and make system (first check predefined paths, if not present - using submodules). If we use them as white boxes we are free to modify them.\nAnother issue is manual libraries loading. We should consider not to load libraries manually but to rely on compiler/linker delay load feature. GCC and VS have it.\n\n31f45ac\nebea5c5\n796bb05\n693649f\nb6d20be\n210ddd0\nNot merged (yet).\nWill do this (typing) when refactoring is completely finished\n\nOK. Some commits' messages contain regexes or scripts used to do them.\n\n2b7d6c5\n4c3e704\nNot merged.\nHWMON handling changed and moved to user_options.c\nNot very nice.\n6c8e702\nNot merged\nShould be fine as it is.\n\nDo you really consider buffer overflow possibility fine? \n\n80d9545\nNot merged\nI don't understand this one, please explain.\n\nMinor issue: \\n in the first line of file. Because of mess with formatting some unrelevant lines appeared in the diff.\n\n72b91dc\nNot merged\nWays too large, I think because of spaces/tabs. Not sure what changed\n\nReally?\n\nThis was just making C++ compiler happy about types.\n\ndd09ba6\nc6a3e57\nNot merged\n\nWhy? Are you going to merge this later?\n\n916c377\nNot merged\nSection no longer exist\nReally? thread.[hc] have this function declaration/definition unfixed\n6622cb1\nit's some hwmon-related stuff\n\nAnd you'v missed 3a816a3, 80cfc89, 91767b8, 0531df7, 11f58ee\n3a816a3, 80cfc89, 91767b8 should be ok\n0531df7 is not merged\n11f58ee is fixed to enum, but not moved to the dedicated file\nWhy do we split large files at all? It's hard to navigate and more importantly large files cause problems to some compilers and IDEs (I mean Visual Studio) because the standard doesn't require it. For example in interface.c we hit the limitation of nestedness (see C1061 for example).\n. > However, if you send a PR with only very basic cmake that works without any changes to the current structure and if I get a good understanding about how it works I may change to cmake.\nUsing cmake requires at least config file. It doesn't strictly requires it, you can add the preprocessor into command line, but this will be shit.\nIn fact you can use the cmake script I have already provided because there is no hardcoded paths to files except templates and results. It's very basic, it doesn't even include packaging. But it is not enough to make hashcat to be built with VS : some code changes you made are imcompatible. Another concern is compiler flags, I haven't succeeded in setting them. In any case the provided cmake script should be enough to generate makefiles for officially supported toolchaihs. .travis file is broken, there are some errors in them. In any case I'm not going to fix anything untill someone solved the problems with the files violating c++ standard which make succesful build using VS impossible.\n. The problem is in interface.c where there are lot of else if ladders causing great nesting.\nC++ standard, Annex B says\n\n\u2014 Nesting levels of compound statements, iteration control structures, and selection control structures [256]\n\nBut in VS they use 128 as limit.\nAnd I'm sorry, I was wrong claiming that some files violated the standard because\n\nthese quantities are only guidelines and do not determine compliance.\n\n, so (according to the standard) it's OK to have deep nesting and small nesting limits.\nThe fact that the code complying with the standard cannot be compiled by any compiler complying with the standard means we don't have the standard at all. :(\n. Feel free to close this issue, the most commits are already merged or wontfixed. I'll start a new issue if we have missed something. \n. 1 It is not crossplatform. I mean if you need make you will have to install a gnu toolchain either mingw or cygwin. Because make is not feature-rich, makefiles are often augmented with bash, which means most likely you will have to install cygwin and gnu utils. Cygwin is large and its installation is pain because it installs packages one by one.\ncmake is only ~40 Mib (unpacked) and doesn't need cli gnu tools to build the project if used in a right way. The right way is not to rely on bash or python (if python is strict requirement of your app, you can use scons) :)\n2 it is not good if you support many toolchains with different command lines. I mean that you'll have to write code creating buildng and linking command line by hand for every compiler and platform supported. cmake does this automatically (in fact not cmake itself, but the code in cmake language shipped with cmake, uts stdlib): you just declare the project files paths and cmake generates the files you need to build the project with the selected toolchain. Unfortunatily you will have to set some parameters like /nxcompat by hand because cmake dev's haven't developed this functionality yet.\n. 1 gnu toolchain and other gnu tools are missing. there are exist some native windows tools not requiring cygwin, but they are really ancient. To have bash you need cygwin and it is glitchy if you have non-ascii characters in path.\n. 2 cmake is shipped with scripts creating projects files for different ides and toolchains.. >I was under the impression cmake is required to build hashcat from VS, but it seems that's not the case.\nIt was not required, in fact, it was just an easiest way to make it build crossplatform crosstoolchain without messing with cygwin and bash. Since I don't use VS anymore (I have migrated to linux, but haven't managed to make VS to work on it (yet) ) VS support is not critical for me for now. cmake support is still will be helpful, because it is the project format used by qtcreator.\n. > Please explain, what is that BEX error and which effects does it have?\n\nBEX refers to Buffer Overflow Exception.\nhttps://support.solarwinds.com/Success_Center/Log_Event_Manager_(LEM)/Buffer_overflow_exception_(BEX)error_from_Reports_Console_due_to_Data_Execution_Prevention(DEP)\n\nIt is often triggered by an attempt to execute the code on a page marked as NoneXecutable. In any case when I've built hc with VS (after my modifications) the problem either disappeared or hid.\nI've checked your binary with PE format inspector (PeStudio) and found that it is imcompatible with dep and aslr (I have them forced enabled for all the processes). You may need try to mess with compiler and linker flags.\n. > Sounds like some mingw issue and not sure which compiler and linker\n\nflags you mean. Also, how did you notice this? hashcat runs normally on\nmy Windows 7.\n\nAgain, I have DEP force-enabled  for all the processes, even for those not explicitly marked as dep-enabled. It doesn't cause issues in most cases. In the case of hc from the website it did. You can try to solve it by adding -Wl --nxcompat --dynamicbase into the command line (I don't know which command line exactly).\n. Sorry, it is not clear how I can download it. On the website I see only August version and the listing of binaries directory (https://hashcat.net/files/) is disabled.\n. Sorry, I was without inet for some time. It doesn't. PEStudio showed the flags (dep and aslr) had appeared, but it still crashes, though with another error (exception code 80000003). \n. I use Windows 8.1. Is it forced? Do you have EMET?. I don't know. I don't have Windows on my PC anymore.. Thank you anyway.. 7 \u043e\u043a\u0442\u044f\u0431\u0440\u044f 2016 \u0433. 15:20:06 GMT+03:00, Jens Steube notifications@github.com \u043f\u0438\u0448\u0435\u0442:\n\nThere was a problem for large dictionaries related to u32 as word\ncounter. I've changed this to u64. I think this was the real problem.\n\nThank you. Then feel free to close this issue, when I am able to check I will comment this.\n. ",
    "MichalStaruch": "Test was performed on i3-4150 platform, using built-in HD Graphics 4400 GPU. CPU was skipped.\nDriver version displayed in Device Manager is 20.19.15.444, dated 2016-04-22.\nWhen I've manually forced CPU by adding --opencl-device-type 1 parameter it worked fine.\nI've done one more test, just replacing \"admin1\" with \"abc123\" (also included in 10k_most_common.txt), and it worked fine using both attack modes.\nContent of test2.hashes (made using \"abc123\" password):\n$keepass$*2*6000*222*7501bd1b923c97da9ab30b1f0ef384103635f7185ff9d13ab2867681eb92b2ac*fdc43070eb472cbb176633fa0859cb58da9006b6e5f15134d8c4c138eafefc65*fc51008560d5d422e4b84305ba24e1b2*7dd6b8b6320ca34ee462840dcda81ac59240b046a9eaf7e488102e3b095e9fa5*8a622ef5ab03d2ff235ba314fc3080012d7ba6bc1047be5618aba21b9d55873c\nSo it seems problem can be observed only for some passwords, and only when using GPU (default device type picked by hashcat).\n. On i5-6600K (driver 20.19.15.4463, dated 2016-05-25) with GTX 960 (driver 21.21.13.7254, dated 2016-08-11) and enforced NVIDIA platform (--opencl-platforms 1) both test.hashes and test2.hashes work fine in brute-force mode and fail in dictionary mode. I've got exactly the same results with enforced Intel platform and CPU mode (--opencl-platforms 2 --opencl-device-type 1).\nTrying to use Intel platform and GPU mode results in crash when building kernel:\n```\n./hashcat64 --potfile-disable -m 13400 -a 0 test.hashes 10k_most_common.txt --opencl-platforms 2 --opencl-device-type 2\nhashcat (v3.10) starting...\nOpenCL Platform #1: NVIDIA Corporation, skipped\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #1: Intel(R) HD Graphics 530, 1624/6496 MB allocatable, 24MCU\nDevice #2: Intel(R) Core(TM) i5-6600K CPU @ 3.50GHz, skipped\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\n\nDevice #1: Kernel m13400.e0cdb833.kernel not found in cache! Building may take a while...\n0x00007FFACE1F76E8 (0x0000000000000001 0x000000002A2C2DE0 0x0000000000000000 0x0000000000000001), freeBlock() + 0xCE178 bytes(s)\n0x00007FFACE1F9173 (0x0000000000883C20 0x0000000000884060 0x000000002D362CC8 0x0000000000884060), freeBlock() + 0xCFC03 bytes(s)\n0x00007FFACE1B748B (0x0000000000883C20 0x000000002D362CC8 0x000000002D362CC8 0x0000000000883C98), freeBlock() + 0x8DF1B bytes(s)\n0x00007FFACE1B99FF (0x00007FFACE1C4D40 0x00007FFACE5D1388 0x0000000000883C20 0x000000002D362CC8), freeBlock() + 0x9048F bytes(s)\n0x00007FFACE1BA208 (0x000000002D362CC8 0x000000002A4DB7C0 0x0000000028A28880 0x00000000311C0B01), freeBlock() + 0x90C98 bytes(s)\n0x00007FFACE16946F (0x000000002903E440 0x000000002D362CC8 0x000000002903E440 0x0000000000884060), freeBlock() + 0x3FEFF bytes(s)\n0x00007FFACE12C65B (0x00000000282C2330 0x00007FFACE4E5AE4 0x000000002903DA90 0x0000003100000030), freeBlock() + 0x30EB bytes(s)\n0x00007FFACE0CF390 (0x000000002903DA80 0x000000002903DA90 0x0000000028670EC0 0x000000002903DA80), ?IsVectorInst@DX9@@YA_NW4_D3DSHADER_INSTRUCTION_OPCODE_TYPE@@@Z() + 0xE8250 bytes(s)\n0x00007FFACE07873B (0x0000000027B3B601 0x0000000028670EC0 0x0000000029A58200 0x0000000000000124), ?IsVectorInst@DX9@@YA_NW4_D3DSHADER_INSTRUCTION_OPCODE_TYPE@@@Z() + 0x915FB bytes(s)\n0x00007FFACE4594F6 (0x0000000028670EC0 0x0000000027B3B600 0x0000000028815501 0x0000000028815500), OpenCompiler12() + 0x237916 bytes(s)\n0x00007FFACE45964F (0x0000000000000000 0x00000000284FEA01 0x0000000000000000 0x0000000028815500), OpenCompiler12() + 0x237A6F bytes(s)\n0x00007FFACE4598BA (0x0000000000000005 0x0000000027B3B640 0x0000000000884BA0 0x00000000008844C0), OpenCompiler12() + 0x237CDA bytes(s)\n0x00007FFACE458FD1 (0x0000000028A228E0 0x00000000008845A9 0x0000000000884568 0x0000000000884568), OpenCompiler12() + 0x2373F1 bytes(s)\n0x00007FFACDFEE0EC (0x0000000027DEBA90 0x0000000029A58210 0x00000000266AAB10 0x0000000026688EE0), ?IsVectorInst@DX9@@YA_NW4_D3DSHADER_INSTRUCTION_OPCODE_TYPE@@@Z() + 0x6FAC bytes(s)\n0x00007FFACDFF8014 (0x0000000027B2FEB8 0x00007FFACE5A194C 0x0000000000000004 0x0000000000884BA0), ?IsVectorInst@DX9@@YA_NW4_D3DSHADER_INSTRUCTION_OPCODE_TYPE@@@Z() + 0x10ED4 bytes(s)\n0x00007FFACDF0BF84 (0x0000000000000001 0x0000000027617970 0x0000000027B0A520 0x0000000027B0A520)\n0x00007FFACDF0AC2E (0x0000000000B034F0 0x00007FFA00080004 0x00000000264D6BC0 0x00007FFACF3921B1)\n0x00007FFACF39EE17 (0x00000000264D6BC0 0x00000000008856C9 0x0000000000B1ED70 0x0000000000000000), clGetCLObjectInfoINTEL() + 0x27D77 bytes(s)\n0x00007FFACF393541 (0x000000002342D950 0x00000000FFFFFFF5 0x0000000000000001 0x00000000264D6BC0), clGetCLObjectInfoINTEL() + 0x1C4A1 bytes(s)\n0x00007FFACF3927FB (0x0000000000080001 0x0000000000B1C660 0x0000000000080000 0x00007FFACF337E00), clGetCLObjectInfoINTEL() + 0x1B75B bytes(s)\n0x00007FFACF382C8A (0x0000000000B2AF40 0x0000000000885878 0x00000000FFFFFFD4 0x00000000264D66C0), clGetCLObjectInfoINTEL() + 0xBBEA bytes(s)\n0x00007FFACF3286BC (0x0000000000B2AB00 0x000000002633C810 0x0000000000000000 0x00007FFA00000000)\n0x00007FFACF370A78 (0x000000000C000000 0x0000000023BD1040 0x000000000048F540 0x0000000000003458), clBuildProgram() + 0xC8 bytes(s)\n0x0000000000462C6A (0x000000000000000A 0x0000000000961400 0x0000000000690D18 0x0000000000000000)\n0x00000000004013ED (0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000)\n0x000000000040152B (0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000)\n0x00007FFAFA268364 (0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000), BaseThreadInitThunk() + 0x14 bytes(s)\n0x00007FFAFBCC5E91 (0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000), RtlUserThreadStart() + 0x21 bytes(s)\n```\n\nIt doesn't look like something specific to particular OpenCL driver.\n. @jsteube: please read carefully. I've said those 2 test cases don't work in dictionary mode when using both NVIDIA GTX 960 GPU and Intel i5-6600K CPU.\n. @jsteube I just re-check everything on i5-6600K and NVIDIA. Exactly as you've said, I've made a mistake when performing dictionary test on another PC, wrong file. It fully works using i5-6600K CPU and GTX 960 GPU.\n. I will verify i3-4150 with latest Intel driver tomorrow. Original tests were performed using proper dictionary.\n. Problem is still there: using Intel i3-4150 with latest stable driver (20.19.15.4463, dated 2016-05-25) dictionary mode using GPU launched against \"admin1\" hash fails.\nSummary of tests in table below:\n| Mode | \"admin1\" hash | \"abc123\" hash |\n| --- | --- | --- |\n| brute-force on CPU | OK | OK |\n| brute-force on GPU | OK | OK |\n| dictionary on CPU | OK | OK |\n| dictionary on GPU | fail | OK |\nFull logs from test:\nhashcat #479, i3-4150 driver 20.19.15.4463, brute-force mode.txt\nhashcat #479, i3-4150 driver 20.19.15.4463, dictionary mode.txt\n. @jsteube If you're 100% sure it's a runtime problem, then I guess it's in Intel hands, now. Could you please share a link to error report describing this particular problem on Intel side? Hashcat users affected by this issue could vote on it to help things moving.\n. ",
    "peterjanos2": "new algorithm: bcrypt_pbdkf: http://www.openbsd.org/faq/current.html#r20160919\n. ",
    "Gnoxter": "To extract the key material from any  LUKS header these four hash primitives are needed: SHA1, SHA256, SHA512 and RIPEMD160\nI'm not particularly familiar with the hashcat code, but it is my understanding that hashcat does not offer these as simple to use primitives on the host. This would be a prerequisite. \nFor the cracking and comparison it needs PBKDF2 with the primitives above and custom iteration count, the symmetric encryption cipher + mode that is used for the FDE. Additionally it needs the hash primitive used for key extraction again, which is always identical with the one used for the PBKDF2. By default this is  aes-xts-plain64 with SHA256 as far as I know. \nFrom my brief code reading I learned that all the hash primitives and the specified ciphers (aes256, serpent, twofish) are available as OpenCl kernel even as xts modes. But only as -plain not as -plain64 if I understand correctly.\nw.r.t hashkill I looked at the luks-plugin and its incomplete/nonfunctional and since its GPL code reuse would not be possible due to License incompatibility.\nFor reference, the current LUKS specification can be found here: https://gitlab.com/cryptsetup/cryptsetup/wikis/LUKS-standard/on-disk-format.pdf . @matrix That is great news, because something just disappeared from my to-do list. Looking forward to it!  Hit me up if you need someone to test things.. ",
    "toine52000": "I tried to crack symphony hash so I make a little script in php that can reproduce Symfony hash.\nSymfony can use different hash algorithms (SHA512, MD5, SHA256...) and do an iteration of it.\nThe default values are: Algorithm: SHA512, Iteration: 5000, Base640fTheResult: Yes.\nI give you the php script, but I haven't the time to do it in C, if someone can work on it!\nLink to the script: https://gist.github.com/toine52000/e09d36ff2a15a0dab9a4e027455433ff\n. ",
    "blandyuk": "Example hash:salt:pass for testing:\n33d00ac42f7f141469ed7d2147d5574a:02f76533cfc1fdcdf20:sommer123\n. Originally seen on HashKiller forum here:\nhttps://forum.hashkiller.co.uk/topic-view.aspx?t=13829\nNot sure on any software name but the salt seems to be always 19 hex chars as I have a private list of 600k+ which always has a 19 char salt. I can beta test if you can compile to .exe thanks.\n. If that's the best option for you then yes, shortcuts would be OK :) It's a shame about the maskprocessor format as it is very easy and compact. Cheers atom.. Why can't you read the command-line parameter for -i and check if there is a value present? If not, default to what hashcat does anyway but, if say -i 4:8 was present, then apply the increment min/max values. I sure I could do this with my apps I have but not sure how hashcat is setup so it may not be possible :( if not, I'll just close this issue.. ",
    "TreyJenkins": "I would also appreciate this algorithm. ",
    "jeffmcjunkin": "Fixed in #496 \n. +1, this is a useful feature.. ",
    "clfdhq": "close it topic, it working, thanks\n. i dont know, i try more time, it run, but it cant decryption\n. ",
    "hartattack0": "clfdhq how did you fix this issue?\n. My nvidia driver was already on the latest version (372.70).\nWhat is \"clinfo\"? Is that the beginning part of hashcat's output that shows the OpenCL devices? \nBenchmarks using Stable v3.10\n```\nD:\\Profile\\Desktop\\hashcat-3.10>hashcat64 -b -m 0\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\nDevice #2: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\n\nHashtype: MD5\nSpeed.Dev.#1.:  1766.4 MH/s (95.89ms)\nSpeed.Dev.#2.:  1763.9 MH/s (95.92ms)\nSpeed.Dev.#*.:  3530.3 MH/s\nStarted: Fri Sep 16 16:50:11 2016\nStopped: Fri Sep 16 16:50:17 2016\nD:\\Profile\\Desktop\\hashcat-3.10>\n```\n```\nD:\\Profile\\Desktop\\hashcat-3.10>hashcat64 -b -m 500\n                                                                  hashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\nDevice #2: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\n\nHashtype: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nSpeed.Dev.#1.:   299.5 kH/s (84.14ms)\nSpeed.Dev.#2.:   305.8 kH/s (84.14ms)\nSpeed.Dev.#*.:   605.4 kH/s\nStarted: Fri Sep 16 16:51:02 2016\nStopped: Fri Sep 16 16:51:13 2016\nD:\\Profile\\Desktop\\hashcat-3.10>\n```\n```\nD:\\Profile\\Desktop\\hashcat-3.10>hashcat64 -b -m 1000\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\nDevice #2: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\n\nHashtype: NTLM\nSpeed.Dev.#1.:  3097.3 MH/s (96.00ms)\nSpeed.Dev.#2.:  3097.6 MH/s (96.01ms)\nSpeed.Dev.#*.:  6194.9 MH/s\nStarted: Fri Sep 16 16:51:56 2016\nStopped: Fri Sep 16 16:52:02 2016\nD:\\Profile\\Desktop\\hashcat-3.10>\n```\nThis one never made it passed Hashtype: phpass, MD5(Wordpress), MD5(phpBB3), MD5(Joomla), it seemed to have hanged.\n```\nD:\\Profile\\Desktop\\hashcat-3.10>hashcat64 -b\nhashcat (v3.10) starting in benchmark-mode...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\nDevice #2: GeForce GTX 590, 384/1536 MB allocatable, 16MCU\n\nHashtype: MD4\nSpeed.Dev.#1.:  3087.9 MH/s (94.96ms)\nSpeed.Dev.#2.:  3090.2 MH/s (94.87ms)\nSpeed.Dev.#*.:  6178.1 MH/s\nHashtype: MD5\nSpeed.Dev.#1.:  1765.6 MH/s (95.93ms)\nSpeed.Dev.#2.:  1766.6 MH/s (95.90ms)\nSpeed.Dev.#*.:  3532.2 MH/s\nHashtype: Half MD5\nSpeed.Dev.#1.:  1164.6 MH/s (95.55ms)\nSpeed.Dev.#2.:  1164.4 MH/s (95.31ms)\nSpeed.Dev.#*.:  2329.0 MH/s\nHashtype: SHA1\nSpeed.Dev.#1.:   568.0 MH/s (95.88ms)\nSpeed.Dev.#2.:   567.5 MH/s (94.07ms)\nSpeed.Dev.#*.:  1135.5 MH/s\nHashtype: SHA256\nSpeed.Dev.#1.:   248.7 MH/s (94.88ms)\nSpeed.Dev.#2.:   248.9 MH/s (94.85ms)\nSpeed.Dev.#*.:   497.6 MH/s\nHashtype: SHA384\nSpeed.Dev.#1.: 73705.8 kH/s (93.22ms)\nSpeed.Dev.#2.: 73844.6 kH/s (93.04ms)\nSpeed.Dev.#*.:   147.6 MH/s\nHashtype: SHA512\nSpeed.Dev.#1.: 75187.4 kH/s (93.94ms)\nSpeed.Dev.#2.: 75162.9 kH/s (93.92ms)\nSpeed.Dev.#*.:   150.4 MH/s\nHashtype: SHA-3(Keccak)\nSpeed.Dev.#1.: 68547.0 kH/s (94.95ms)\nSpeed.Dev.#2.: 68551.0 kH/s (94.93ms)\nSpeed.Dev.#*.:   137.1 MH/s\nHashtype: SipHash\nSpeed.Dev.#1.:  2650.5 MH/s (96.03ms)\nSpeed.Dev.#2.:  2660.3 MH/s (96.04ms)\nSpeed.Dev.#*.:  5310.8 MH/s\nHashtype: RipeMD160\nSpeed.Dev.#1.:   399.3 MH/s (94.80ms)\nSpeed.Dev.#2.:   399.3 MH/s (94.83ms)\nSpeed.Dev.#*.:   798.6 MH/s\nHashtype: Whirlpool\nSpeed.Dev.#1.: 61879.4 kH/s (131.74ms)\nSpeed.Dev.#2.: 62047.9 kH/s (131.71ms)\nSpeed.Dev.#*.:   123.9 MH/s\nHashtype: GOST R 34.11-94\nSpeed.Dev.#1.: 51458.2 kH/s (129.35ms)\nSpeed.Dev.#2.: 25594.1 kH/s (129.29ms)\nSpeed.Dev.#*.: 77052.3 kH/s\nHashtype: GOST R 34.11-2012 (Streebog) 256-bit\nSpeed.Dev.#1.: 11142.1 kH/s (188.36ms)\nSpeed.Dev.#2.: 11149.4 kH/s (188.32ms)\nSpeed.Dev.#*.: 22291.5 kH/s\nHashtype: GOST R 34.11-2012 (Streebog) 512-bit\nSpeed.Dev.#1.: 11139.1 kH/s (188.37ms)\nSpeed.Dev.#2.: 11143.0 kH/s (188.34ms)\nSpeed.Dev.#*.: 22282.1 kH/s\nHashtype: phpass, MD5(Wordpress), MD5(phpBB3), MD5(Joomla)\nSpeed.Dev.#1.:   223.9 kH/s (87.85ms)\nSpeed.Dev.#2.:   185.4 kH/s (87.85ms)\nSpeed.Dev.#.:   409.3 kH/s\n```\n. It seems to hang on -m 500 as well now.\nBenchmarks work fine, but -a 0 and -a 3 seem to hang.\nIn addition, the example.cmd files also seem to hang.\n. I think I solved it, I had Multi-GPU on,  decided to disabled it and its working now.\n. ",
    "mosreq": "C is simpler and easier to read.\n\"Entities must not be multiplied beyond necessity\"\n. > ... when used for simple hello-world-level programs.\nyeah? tell that to windows and linux kernel developers\n. ",
    "polarathene": "If you're open to refactoring to another language, Rust might be another good alternative over C++. Full disclaimer, I know very little C/C++/Rust and likely a perfect example of RIIR...\nBenefits in comparison to C/C++ from this answer:\n- a type system feature that helps eliminate memory leaks,\n- proper interfaces, called 'traits',\n- better type inference,\n- better support for concurrency,\n- (almost) first-class functions that can be passed as arguments.\nA devs experience with C++ and Rust\nAnother dev writes about pros/cons of Rust over C++\nRust FAQ\n\nJust saw the issue while checking for another and felt like mentioning the alternative, I just use hashcat so whatever you like to write it in is great :)\n. > Why not? Large files slow down IDEs.\nI rarely come across files like this with my editor of choice(Atom) but when I was navigating interface.c it definitely started to have a noticeable impact and I had to switch to a different text editor to avoid that.\n\nIf you're IDE can't handle large files it's not a problem of the project, it's a problem of the IDE. I don't use any IDE btw.\n\nWhile I'd agree, it does discourage contributions somewhat by affected users. I think I've opened other files in the project that were also large enough to cause the problems, from what I read here the refactor has addressed it.\n. I've ported it to Rust as a learning exercise, you can see a working version in browser here.\nIn doing so, I've found the algorithm produces the first hash value in examples I gave, so endianess had to be swapped, I also discovered the community version in C# modified it a bit by adding a loop to the remaining 23 bytes. I've implemented that to get the same results but it'd be non-standard for the algorithm I'm asking for inclusion.\nI'd still like to use hashcat with the modified algorithm so if there is any information on how I can add it to have my GPU utilize it that would be super helpful.\n. I'm attempting to get this working in Hashcat referencing the RAR5 commit and comparing against other algorithm files/settings. I'm figuring out what a bit of it means but struggling to figure out various other properties that are either Hashcat/Cracking/OpenCL specific(rather new to it all). \nI've got the algorithm ported over to OpenCL I think, but not sure how to go about testing it, it isn't clear how much additional code like in the RAR5 commit I need to add to do so as the flow is not clear to a new comer.\n. I'm able to hardcode the comparison value in my .cl file to that of the hash input stored in digest in the parse_hash method. I split a 64bit hex string to 2 u32 values(digest size 4_2?) with hex_string_to_u32(). I tried a digest size of 8_8(smallest u64/64-bit size?) but working with a u64 value instead of two u32 seems to require more work(COMPARE_M/S for example).\nDebugging the file with an nvidia card doesn't seem like I have much options? I can't use printf(), I thought maybe I could treat the comparison as a success and return/store some value in C file or terminal, no luck. I'm not sure how to work with my dict/key values, are the strings being converted into byte arrays? I see pws[gid].pw_len; and pws[gid].i[0]; used in other files assuming that's it?\nOnce I can match the input string to the hash I think I can make more progress, I've got everything working besides the .cl file now.\n. Created a thread on the forum.\nNo further progress so far with the trial and error of the .cl file. If anyone has the spare time to put together a basic example of the .cl file(I've got the rest covered I think, MSQL323 seems a better reference?) for a simple hash like FNV-1a 32-bit, that'd be super helpful.\nIt should look something like this I think, I'm just not familiar with the rest of the OpenCL that all the hash mode files use to integrate it:\n```\nu32 fnv1a32(char data) {\n    u32 hash = 2166136261;\n    for byte in data {\n        hash ^= byte;\n        hash *= 16777619;\n    }\nreturn hash;\n\n}\n```\nThe string \"hello\" should output a hash of \"4f9f2cab\".\n. @jsteube Yes, wikipedia, generator.\nIt's not the algorithm I'm trying to implement, which is larger. I chose this one as it's very simple and would make understanding the process of implement an algorithm showing the basics. \nThe developer could then expand from the base example with their more complicated logic, optimizations and additions like working with salts for their own algorithms.\n. Figured out why I was getting Exhausted for the status but 100% recovery and no key paired to the hash. My hardcoded test was of course providing a perfect match as soon as it was hit, I thought this would be the first word but I'm guessing it was run before the first word in my dictionary was used?\nAfter sussing that out, I was able to get cracked status with the intended hash:key match by filtering the hard coded compare to only happen when the first 4 bytes(\"hell\") was available. I had originally assumed I was getting each string character separately not 4 at a time, after Atom cleared that up it made it much easier :)\nImplemented the FNV1a32 algorithm above, initially with a hard coded byte array then modified it to work with how Hashcat was providing the string data, implemented bitshifts and when thinking about how to handle the <4 end of the string I noticed my approach was quite similar to the MySQL323 algorithm I was referencing, all of the sudden what was going on clicked and I could make sense of all that was going on in that function :P A good amount of it was to handle 3/2/1 bytes in the u32 value and the rest optimizations like avoiding lookups by copying the data into new variables.\nSome variable names I still don't get or understand why bother with larger array sizes than needed with unused indices being set to 0. Does it help performance in some way?\nOnce I've got my intended algorithm working I'll look at contributing some documention for new users wanting to implement new algorithms using the FNV1a32 as a basic example. It should clear up alot of the confusions I came across so someone else doesn't spend several days trying to figure it out :P\n. Tried to do a mask attack(new to this) with ?l?l?l?l?lbut instead of a range of aaaaa -> zzzzz I got sange -> uqoql.. Can my .cl file affect that?\nCommand:\nhashcat -a 3 -m 99000 -o cracked.txt '4f9f2cab00000000' ?l?l?l?l?l --potfile-disable\nOutput:\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (?l?l?l?l?l) [5]\nHash.Target....: 4f9f2cab00000000\nHash.Type......: PD2 - Payday 2\nTime.Started...: 0 secs\nCandidates.#1..: sange -> uqoql\nSpeed.Dev.#1...: 23480.9 MH/s (0.43ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 11881376/11881376 (100.00%)\nRejected.......: 0/11881376 (0.00%)\nHWMon.Dev.#1...: Temp: 53c Fan:  0% Util:  0% Core:1594Mhz Mem:3802Mhz Lanes:16\nMySQL323 / 200 didn't seem to have a problem cracking it's hash/key with the same mask, listed the same Candidates. My one requires  the first letter to be specified. Here's another for the key payday:\nhashcat -a 3 -m 99000 -o cracked.txt '7ce5206100000000' p?l?l?l?l?l --potfile-disable\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: Mask (p?l?l?l?l?l) [6]\nHash.Target....: 7ce5206100000000\nHash.Type......: PD2 - Payday 2\nTime.Started...: 0 secs\nCandidates.#1..: panger -> pqqoql\nSpeed.Dev.#1...: 18002.0 MH/s (0.44ms)\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 11881376/11881376 (100.00%)\nRejected.......: 0/11881376 (0.00%)\nI tried -1 p for payday example, it works like providing the letter directly. -1 ap or -1 pahowever fail. Tried another with key apple, ?l at the start still doesn't work but -1 with any mixture of letters as long as there was an a worked, checked with payday again with -1 xp, and now that cracks, so it's taking the first only after sorting I guess.\n. @magnumripper Is there anyway to output the keys mask attack tries? \nI've reduced my testing down to a single digit, like above I get Cracked if I provide the specific digit instead of a digit mask ?d. So the algorithm is fine, I've swapped my .cl(kernel?) for that of m00200_a3.cl(with 00200 replaced with my hash mode value)  and tested the key/hash and any mask works fine.... so surely I'm doing something wrong with my a3 kernel?\nOnly seems to trip up with the first mask value for some reason, it's a stripped down m00200_a3.cl.\n. Solved it after piecing all the defined code at the top into the one method, the value I initiate my hash with was before the main for loop, turns out it needs to be inside it.\nPRE to POST\n```\n  for (u32 il_pos = 0; il_pos < il_cnt; il_pos += VECT_SIZE)\n  {\n    const u32x w0r = words_buf_r[il_pos / VECT_SIZE];\nconst u32x w0 = w0l | w0r;\n\n// Only need these two lines to handle FNV1a32 on a single digit\nu32x hash = 2166136261;\nhash ^= w0 & 0xff; hash *= 16777619;\n\nu32x z = 0;\nCOMPARE_S_SIMD (hash, z, z, z);\n\n}\n```\nNot quite sure how that loop works if it's dependant on the first character of the key to be specified but allows masks for the rest. Initiating the hash inside the loop is the solution though.\n- What is il? \n- Is cnt count? \n- Does the r/l in w0r/w0l mean right/left?\n- What is the difference between u32x to u32?\nI don't need to know them since I can get the code working, but if there is any value in terms or knowing what the variables are it'd be good to note down :)\n. @jsteube thanks for all that :) I've got my hash algorithm working great at 19 GH/s for a 5 char string, it gets progressively slower the longer the string(15 chars 500MH/s). With the longer strings a good portion is an already known prefix before any mask is used.\nDoes hashcat provide some method to cache calculations based on string of chars? password?d?d for example, it would be a waste to do all the processing on the prefix of the key every time when it could just be done once then using a datastructure like a trie iterate through the string until it doesn't reached a cached result. p -> a -> s -> s -> w -> o -> r -> d -> ? would return the cached value up til d(or a digit if it's already processed that as well), when the prefix password changes to say secret the first character s has no cache hit so it'll start processing from there, 2nd time around it'll have the previous processed word in the cache.\nI'm unfamiliar with openCL, how portable is a C implementation of trie data structure?\n. I don't need to brute force an entire length of 30, I've done this with 9 mask characters and the rest static(56 in length), took a few minutes. I'd like to generate the prefix rather than manually input it. The prefix could be built from a preprocessor extracting out the known directory paths into a wordlist, or a rule attack(?) using some words to form common string patterns(eg ene_[enemy unit name]_?d or `level_[really long level name]stage?d[something else]).\nWith one of the examples I provided in the 1st post units/payday2/characters/ene_bulldozer_1/ene_bulldozer_1 plenty of that only needs to be calculated once. The algorithm iterates through the string(with hashcat, I've changed it to work on up to 4 characters at a time) to form the hash, so it's calculation time grows as the length of the string does, otherwise it's pretty fast. I don't think I can precompute the end of the password without having processed what came before it, but storing what I process in memory as a cache sounds feasible?\n\nThe best way to deal with it would be to generate the innerloop part for the end of the password, not the beginning. In such a scenario you could simply precompute the prefix before entering the inner loop and get full speed, regardless of the length.\n\nI might have misunderstood what you were saying here. I thought I don't have access to the key/password string until the inner loop(and for some reason have to start with w0 as w[0] doesn't appear to be what I expect, then start from w[1] and up). I'm only working on m99000s for a3 right now, would the outer loop still be in this method or is that the s04/s08/s16 methods that call it? I know s is for single hash comparison where I supply the hash in terminal, and m is for multiple from a dictionary, but besides the different allocations to w[] the numbered variants still aren't clear to me what use they are so I haven't touched them.\nDone a little optimization, was able to remove a while-loop/switch/conditional(tried a few variants) as well as just referencing w[i] instead of storing it in another var seemed to help boost performance for 5 chars to 33 GH/s. 15 chars is 560 MH/s now.\n. Sure, I've not written extensive notes, but I can provide the basic example and comment on what's going on along with a markdown file to describe the process/flow. I found out FNV1a32 tends to get hash collisions a bit where it'd crack the hash with a key that wasn't the expected one. I will also push a branch on my fork with the algorithm I'm working on at the moment.\n. I've got a rough version of my .cl file here(note to self hastebin is not reliable for this sort of thing), it's only the inner loop linked atm, can supply the full file text if it's helpful. Whereabouts is the outerloop, is it in m99000s before CODE_PRE's inner loop? or is it the s04/s08/s16 methods? You can see that it's an algorithm that iterates through the given input and could be paused/resumed by storing/retrieving the a/b/c values which I'd like to cache or precompute prefixes from wordlists before the mask/rule generation.\nlookup8.c example on repl.it, good news is I was wrong about my first impression of this being a variant/modifed version, it was just due to language differences or the C# author I guess and I assumed the output was different. They produce the same result so it might be a worthwhile contribution to hashcat community after all :)\n. @jsteube Well I feel stupid now ha, I assumed the performance degradation was my logic and spent all this time to optimize it and it turns out if I make the whole m99000s method empty I still get the performance drop. 15 char length is getting 647 MH/s with no logic for the method.\nIs it a performance problem with Hashcat somewhere generating the strings or is the string too large for the GPU and it's being handled differently?\nCommand that I was using:\nhashcat -a 3 -m 99000 'a0850878201803bd' ene_?l?l?l?l?l?l?l?lr_1 --potfile-disable\n. I think I understand it now, the parallelization branches off from the first 4 characters in some way? Where as I thought Hashcat generated enough strings from the first ?l and sent all those off to be processed by the GPU as if there was no difference from where the key branched off at.\nSo to clarify, from what I can tell on my GPU(GTX 1070) it seems with minimal logic I can get around 600MH/s  per....thread/core? And that by parallelizing from the initial 4 chars it seems I can achieve 64x that rate(I'm not sure why it's 64, is that a Hashcat thing or specific to my GPU specs?), that seems to be a bottleneck max rate as I can achieve it without the first 4 chars all being masked values. Does digest size have any impact on this?\n@jsteube If I understood the parallelization correctly, your work around with salt makes sense. Is it possible to have a precompute stage of 8k prefixes(copy/pasted) where I store the values in an array and my m99000s method could loop through each preprocessed prefix in the array for each generated string that the masks provides?( eg `?l?l?l?l?l?l?l - length 8 paired with each prefix in the inner loop?). According to a similar keyspace at 33 GH/s, looks like it'd take about 20 hours or less (against a single hash, not sure how much of an impact comparing against 4k hashes has).\n. Here is some output with my logic being running through instead of an empty function. It proves that the static chars are affecting performance when combined with masks:\nhashcat -a 3 -m 99000 'a0850878201803bd' ppp?a?a?a?a?a?d?d --potfile-disable\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (ppp?a?a?a?a?a?d?d) [10]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 20:57:45 2016 (47 secs)\nCandidates.#1..: pppeex6{73 -> ppp::~}z57\nSpeed.Dev.#1...: 16348.4 MH/s (8.01ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 773780937500/773780937500 (100.00%)\nRejected.......: 0/773780937500 (0.00%)\nHWMon.Dev.#1...: Temp: 72c Fan: 27% Util: 96% Core:1873Mhz Mem:3802Mhz Lanes:16\nhashcat -a 3 -m 99000 'a0850878201803bd' ?l?l?l?a?a?a?ap00 --potfile-disable\nLittle bit longer at 130% speed roughly, covered twice the keyspace almost:  773780937500 vs 1431576185000.\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (?l?l?l?a?a?a?ap00) [10]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 20:59:24 2016 (1 min, 6 secs)\nCandidates.#1..: xlqJPj}p00 -> uqo:~\\~p00\nSpeed.Dev.#1...: 21524.4 MH/s (5.26ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 1431576185000/1431576185000 (100.00%)\nRejected.......: 0/1431576185000 (0.00%)\nHWMon.Dev.#1...: Temp: 73c Fan: 29% Util: 94% Core:1847Mhz Mem:3802Mhz Lanes:16\nhashcat -a 3 -m 99000 'a0850878201803bd' pp?l?a?a?a?a?a?d0 --potfile-disable\nOver twice the keyspace almost 3x 773780937500 vs 2011830437500?\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (pp?l?a?a?a?a?a?d0) [10]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 21:10:54 2016 (1 min, 34 secs)\nCandidates.#1..: ppn\\Fn\"~60 -> ppz::~}z50\nSpeed.Dev.#1...: 21102.6 MH/s (5.07ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 2011830437500/2011830437500 (100.00%)\nRejected.......: 0/2011830437500 (0.00%)\nHWMon.Dev.#1...: Temp: 73c Fan: 31% Util: 93% Core:1860Mhz Mem:3802Mhz Lanes:16\nhashcat -a 3 -m 99000 'a0850878201803bd' pass?l?l?l?l?l?l?l --potfile-disable\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (pass?l?l?l?l?l?l?l) [11]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 21:51:09 2016 (16 secs)\nCandidates.#1..: passxcxkwvq -> passqlqlqvq\nSpeed.Dev.#1...:   482.5 MH/s (2.27ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 8031810176/8031810176 (100.00%)\nRejected.......: 0/8031810176 (0.00%)\nHWMon.Dev.#1...: Temp: 59c Fan:  0% Util: 96% Core:1923Mhz Mem:3802Mhz Lanes:16\n26x the keyspace of previous 8031810176 vs 208827064576, yet a vert similar time.\nhashcat -a 3 -m 99000 'a0850878201803bd' pas?l?l?l?l?l?l?l?l --potfile-disable\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (pas?l?l?l?l?l?l?l?l) [11]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 21:52:25 2016 (21 secs)\nCandidates.#1..: pastxcxkwvq -> pasxqlqlqvq\nSpeed.Dev.#1...:  9566.2 MH/s (4.70ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 208827064576/208827064576 (100.00%)\nRejected.......: 0/208827064576 (0.00%)\nHWMon.Dev.#1...: Temp: 68c Fan: 15% Util: 98% Core:1898Mhz Mem:3802Mhz Lanes:16\nhashcat -a 3 -m 99000 'a0850878201803bd' pa?l?l?l?l?l?l?l?l?l --potfile-disable\n26x the keyspace again, but done at twice the rate as the previous.\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (pa?l?l?l?l?l?l?l?l?l) [11]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: Mon Oct 10 21:54:59 2016 (4 mins, 21 secs)\nCandidates.#1..: panuhkceqvq -> paqoqlqlqvq\nSpeed.Dev.#1...: 20504.5 MH/s (7.19ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 5429503678976/5429503678976 (100.00%)\nRejected.......: 0/5429503678976 (0.00%)\nHWMon.Dev.#1...: Temp: 73c Fan: 33% Util: 95% Core:1835Mhz Mem:3802Mhz Lanes:16\nNo speedup with replacing a with ?l this time.\nhashcat -a 3 -m 99000 'a0850878201803bd' z?a?a?a?a --potfile-disable\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (z?a?a?a?a) [5]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: 0 secs\nCandidates.#1..: z4\"j\" -> z:~|~\nSpeed.Dev.#1...:   454.8 MH/s (2.27ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 81450625/81450625 (100.00%)\nRejected.......: 0/81450625 (0.00%)\nHWMon.Dev.#1...: Temp: 57c Fan:  2% Util: 51% Core:1759Mhz Mem:3802Mhz Lanes:16\nhashcat -a 3 -m 99000 'a0850878201803bd' ?a?a?a?a?a --potfile-disable\nSession.Name...: hashcat                                  \nStatus.........: Exhausted\nInput.Mode.....: Mask (?a?a?a?a?a) [5]\nHash.Target....: a0850878201803bd\nHash.Type......: PD2 - Payday 2\nTime.Started...: 0 secs\nCandidates.#1..: 1$OR} -> ::~|~\nSpeed.Dev.#1...: 16108.2 MH/s (8.12ms)\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 7737809375/7737809375 (100.00%)\nRejected.......: 0/7737809375 (0.00%)\nHWMon.Dev.#1...: Temp: 63c Fan:  2% Util: 97% Core:1860Mhz Mem:3802Mhz Lanes:16\n. Thanks for the explanation, I'm still having trouble understanding what you're saying though. Why does the same length have such a big difference if using a pure mask vs mask with some static string data?\n\nWithout a fixed w[0] the innerloop has nothing to iterate through\n\nThis is the first 4 chars right? When you say fixed what do you mean? Isn't the example with pass as the prefix static/fixed? Yet it seems considerably slower than replacing the letters with ?l. ?l?l?l?l?l?l?lpassfinishes straight away at 32 GH/s but pass?l?l?l?l?l?l?l which you'd think would have much less to compute takes 13 secs at <600 MH/s.. Am I better in some cases to always start my mask attack with first 4 chars as mask values? \nI'm not quite sure how parralelization is occuring, from the sounds of it, it seems starting the key with L the GPU can only operate on a single sequence at a time vs ?l where it can do parraelize 26? and presumably each of those 26 again if the next char is mask ?l?\n\nThere's no discussion needed about this behavior. It's a well known limitation and there's also a standard workaround\n\nWhere is this documented? There was no mention of this problem or work around on the Mask Attack wiki page from memory.\n\nThe best workaround is to have a prefix added to the hash as a salt.\n\nI don't know if this will be too viable, I have about 4k+ hashes and 8k+ file paths, that'd mean appending the salt 8k times per hash right? Are the other attacks where I can preprend the file path vulnerable to this performance problem too? \nI'm thinking my best option right now is to preprocess the paths and copy/paste their data into a prefix array before the inner loop and then loop through that array for each key generated by the mask.\n. Probably not an option, but is JIT compiling kernels perhaps with a template language if you want to have a variable salt that becomes static during compilation at runtime an option? ArrayFire does JIT compiling for it's kernels from memory.\n. ",
    "roobre": "Hi,\nYou are correct, my VRAM is clearly not enough to hold the whole list of hashes. I was thinking about some kind of internal splitting. Load the whole list on RAM, and move chunks to the vram maybe? It would be slow, yes, but is still better than launching several hashcats in succession.\nSorry if it's a dumb suggestion, I don't actually know how the hashcat internals work :(\n. Cool, I'll go on with the script approach then :smile: \nJust another related question: How can I determine how many hashes will fit in memory? Is it as simple as vram / size_of_hash, or is some other metadata stored with them?\n. ",
    "jamesthecat7": "Thank's jsteube. I'm now trying a 64 bit block but now get the error 'invalid mask' when trying 3DES.\nhashcat64 -m 14100 cd674507b21e5ebe:1435662222276461 -a 3 --potfile-disable. Sorry, new to hashcat, i wasn't sure if the mask would be set for me like with the 14000. I'll read up the documentation creating an efficient mask for my task, although i'd imagine a 3DES key will take a millennia to break anyway if they've used the full 192 bits. . ",
    "Thedemon007": "Now only old versions support cpu, without OpenCL runtime? \n. ",
    "mabrowning": "Honestly, cmake is best for when you need to make build-time decisions. hashcat has minimal dependencies. I was skeptical for 10 seconds at first too, but haven't had any problems just makeing.\nThe one A++ feature of cmake is trivial/necessary out-of-tree builds. I haven't attempted that with hashcat, but it is slightly annoying to me that the build artifacts are polluting my source control'd directory.. ",
    "n0x00": "already looked on the forum, hence me coming here.\nFWIW i also have the same issue on another system recently with a new installing Kali, so I'll take it over to those guys and see if they can help me get hashcat working - doesn't work out of the box nor beta nor fresh git. \n. ",
    "dibiloid": "I am willing to pay! You can add it?\n. please show how it can be done ). ",
    "filo-man": "Hi,\nAny idea when this will be integrated back?. ",
    "SquirrelAssassin": "fix for the current version is to use double quotes around your restore name --session=\"1\"\n. ",
    "botkosgap": "need for hashcat:D can?) \ni can give $\n. ",
    "x-falcon": "@jsteube download from first pages ,the version is 3.10 ,may not beta version \nfor detail,  one hash has been cracked and store in hashcat.pot,\nwhen crack the same hash again, the -o will not output  any file.\nIt's a small problem\n. @jsteube It work now. Thank you\n. ",
    "Chick3nman": "Fixed in Beta hashcat-3.10+515. Thank you!\n. I have 3 FE 1080's and I can cause the same hang ups by switching SLI on and fix them by switching SLI off. This is on win7 + 372.70. I believe the issue is simply SLI being enabled.\n. Fixed in rc6. Fixed in latest, thanks.. Working as expected, thanks.. This would be pretty easy cut/paste addition using hash mode -m 2811 md5(md5($salt).md5(pass)), would it not? Just some swapping around and then adding it to the mode selection.. Fixed, Thanks!. To add some more details and confirm this issue, using --keyspace with a custom character set, such as in the command shown above, will cause hashcat to not recognize that a mask has been set for some reason, whereas using a mask that doesn't include a custom character set works just fine. Custom character sets work in attacks, it's only when trying to use --keyspace that they fail, giving the error shown on the second line above. The same command as above does work in 3.30, so i believe the intended behavior is for it to work in 3.40 as well.. These questions seem better suited for the hashcat forums( https://hashcat.net/forum/index.php ) than for the issue tracker. You will likely have better luck asking there.. I like that idea better @roycewilliams  \ud83d\udc4d . I dont think it should be a configurable option, thats a bit too much. Simply compressing near the middle of the hash using an ellipsis to keep it within 1 terminal line would be fine in my opinion.. Looks good, thanks!. I personally feel that the status should be on stderr so that pipes can be used to handle cracked hashes and other output on stdout. This would remove the need to add a new flag just for /dev/null and would open things up a bit more for people to pipe cracks into other applications to handle them before going to a file.. Sorry, I had noticed CT and Mac were swapped in your script and forgot to update the examples. They we're generated with my original script, which is no longer the correct format.. @ethtester from what I can find regarding MIST wallets, the keystore seemingly shares the same format as Geth wallets and therefore both this algorithm as well as my extract script should work on MIST wallets as well. If you have a MIST wallet on hand that I could look at that would be helpful as I do not have one and can't seem to confirm 100% what the format of the JSON is and if it's compatible with ether2hashcat.. @kholia I was simply following the format of other extracted hashes however I do agree with the change. I will edit my extract script and both issues to reflect the corrected format.\n@ethtester those wallets look directly compatible as they follow the same format.. @kholia awesome, would you like me to push yours as the main extract script instead of https://github.com/Chick3nman/ether2hashcat.py/blob/master/ether2hashcat.py ? Mine is a lot less clean than yours, plus no error handling.. Perfect, I'll edit both issues to refer to your script and will use it as the extract script from now on. @ethtester Correct, hashcat will need to have the modes written and added to use them, this is simply a request to have them added.. @ethtester the developers are quite busy right now dealing with other, more important things. If no one from the community steps in to add this, it could be a few weeks before anyone can get to them. For now, @kholia's addition to JTR has been merged here: https://github.com/magnumripper/JohnTheRipper/pull/2525. @solardiz It's possible @atom was talking about JTR's implementation of the Ethereum Scrypt mode and not the Scrypt portion alone. That's how I interpreted it at least.. I now follow @kholia's extraction script as the master, hence the message that ether2hashcat was deprecated and replaced, so hashcat should follow his formats for scrypt/pbkdf2/presale. I had noticed the difference in our scripts and i believe there was a forum post that pointed it out as well, however I was not aware that hashcat parsed it under my old format. The OP on this thread was changed to follow @kholia's format directly after his script superseded mine. . I'm guessing your wallet uses the incredibly high 262144 settings? That scrypt setting is beyond the capability of most GPUs currently(by design), and if your CPU is running out of resources, its due to a lack of enough system RAM.. Interesting, that does seem like an issue with the shell and not hashcat. I'll play with surrounding things in quotes and escaping things to see if i can come up with something that works.. Huh, that's weird. I guess it's just something we'll need to work around during usage. I'll go ahead and close this as it's not a hashcat issue however I do think it could use some visibility so that others arent confused when they run across it. It caught me completely by surprise when testing a list earlier.. Can you give me a quick summary of the issue? I'm trying to read through that thread but it's quite long. It sounds like return characters were incorrectly considered during the KDF portion instead of being stripped, which caused wallets that implement the KDF correctly to fail to decrypt due to the lack of the return characters? If so, it should be trivial to apply those characters using a rule or a hex wordlist with those characters applied to the ends of the plaintexts.. --gpu-temp-disable        |      | Disable temperature and fanspeed reads and triggers  |\n     --gpu-temp-abort          | Num  | Abort if GPU temperature reaches X degrees Celsius   | --gpu-temp-abort=100\n     --gpu-temp-retain         | Num  | Try to retain GPU temperature at X degrees Celsius   | --gpu-temp-retain=95. You can't add flags to a restored session without modifying the restore file. Modifying the restore file is risky as well but there are some tutorials online how to do it if you look around. If you ask on the forums, there are more people that can help with the issue.. You can simply restart the attack to change the settings, taking note of where you left off and using --skip and --limit to start roughly where you left off and not go over the same work twice.. I was under the same assumption @jsteube , i thought hashcat was failing to crack the proper format, which is $ethereum$s*n*r*p*salt*ciphertext*mac. It seems both hashcat and JTR are aligned and following the correct format. The old format, $ethereum$s*n*r*p*salt*mac*ciphertext, was deprecated when @kholia built his script for john, and should NOT be used. Hashcat failing to crack the deprecated format is proper behaviour, there is no issue here.. The more VRAM you have, the more hashes you can fit into one run without having any issues. Myspace(~360m) fits into the VRAM on a Titan-X but not into the VRAM on a 1080. If artificially capped in a non-dynamic way, then anyone with Titan's would be limited for no reason.. It's possible all the target hashes fit but no recovered hash:plain pairs have room? I dont understand it at a low enough level to really tell.. So...chained SHA256 to try and derive the \"Hash of the day\" likely from a gambling site? Probably shouldn't be doing that.. Please take this question and others like it to the forums. The candidates displayed are the selection of current work, from point A - point Z. If the GPU can do 1 candidate at a time, it will load up a chunk of work, such as A,B,C,D,E,F,G,H,I and display A-I while it process through them 1 at a time. It will not update the chunk of work until it finishes. If it loads a chunk such as A-I and has only made it to candidate G when the status is printed, it will still display A-I.. You can already reference a wordlist on a different/networked drive. As long as hashcat has a clear path to the wordlist, it will work. Protocols like HTTP are likely not going to be supported and the speed of read/access would be terrible anyways.. You are receiving these errors because you are trying to run hashcat on a laptop where nvmlDeviceGetPowerManagementLimit() and nvmlDeviceGetFanSpeed() are not supported. Solution is basically don't run hashcat on a laptop.. This is not a hashcat problem, your hardware is simply not adequate for cracking Scrypt with such high settings. Please take this discussion to the forums instead of github. Thanks :). Lets take a look at this thread for a bit and maybe it will clear a few things up.\nhttps://hashcat.net/forum/thread-7170.html\nTL;DR It does not seem like the SSG is usable in that way according to its documentation.\n  . They don't understand how the SSG works then. The NVME drive(s) on the GPU are connected via the new HBCC(High Bandwidth Cache Controller) and act as a local file store for caching files that would normally be read from the host system storage, NOT as addressable mapped memory space. \nhttps://muropaketti.com/wp-content/uploads/2016/07/amd-capsaicin-radeon-pro-ssg-diagram-20160726.jpg\nAs you can see, the GPU Memory(VRAM) is separate from the NVME storage/cache.\nAnd from the thread I linked above:\nhttp://www.tomshardware.co.uk/amd-radeon-pro-ssg,news-53609.html\n\"AMD indicated that it is not using the NAND pool as a memory-mapped space currently...\"\n\"The current implementation merely uses the SSD as a storage volume for frequently-accessed data...\". From the article you linked:\n\"SSG would not replace graphics RAM itself, such as GDDR5+ or HBM or HBM2, as it would be too slow.\"\n\"When the GPU wants more work, it has to signal the CPU, which then fetches data from the larger pool of local system RAM or primary storage.\"\nIt's acting as a next step down from the VRAM, not as part of the local VRAM. Just like how Intel Optane is not RAM, it's simply a high speed cache that sits above the disks but below the system RAM. This is for when the GPU is done crunching its current work chunk and is going to get the next chunk of work from the disk. This does NOT allow you to increase the size of each work chunk beyond the size of the local HBM2 VRAM, it just lets you switch to the next chunk faster, increasing overall throughput. There seems to be some serious confusion here around the word \"Memory\". For the use case of acting as a Frame Buffer, the SSG will do very very well because it can load to/from the onboard SSD RAID very very quickly. But for our use case, we arent offloading a ton of file read/writes to a local cache. We are initializing a huge lookup table of random bit strings.\n\"The large memory requirements of scrypt come from a large vector of pseudorandom bit strings that are generated as part of the algorithm. Once the vector is generated, the elements of it are accessed in a pseudo-random order and combined to produce the derived key. A straightforward implementation would need to keep the entire vector in RAM so that it can be accessed as needed.\"\nhttps://en.wikipedia.org/wiki/Scrypt\nIf we could split this RAM usage up magically into several pieces, some of which would go into the VRAM and the rest into system RAM/Disk efficiently, then the SSG would make sense. But we aren't doing that because doing so is NOT efficient.\nAgain, even if we wanted to get fancy with this and try to do that, the current SSG implementation does NOT allow you to do what you think it does, so we couldn't do it regardless.\n\"http://pro.radeon.com/_downloads/SSG_API_User_Manual%20v1.01.pdf\nPretty clear from the API documentation that the OpenCL extensions added are solely for file operations. And even if the API did have functions to use the onboard storage as VRAM (which, again, it does not), those functions would have to actually be implemented within Hashcat to make use of them, which would be a significant undertaking for a device that surely no one would use for password cracking. It wouldn't just magically work, and we would not be willing to invest the level of effort required to make it work. But again, it does not exist, so this is a non-issue. \"\nFrom the thread on the Hashcat forums that I linked earlier.\n. It is currently not possible due to how the scrypt lookup table is being stored. If we found a way to write it into chunks and started storing internal states to the disk/sysRAM/etc. to get around the maximum VRAM limitation, it would very likely slow the whole process down even further. It would not make it more efficient. Scrypt is a Memory-Hardened algorithm and is very GPU resistant. It is designed specifically to make sure you can't do that efficiently. The ENTIRE lookup table needs to be accessible during computation since you need to look through following a pseudo-random order. Doing it in pieces would likely take more time loading/unloading than simply doing less of it concurrently but keeping the entire concurrent tables in the VRAM.. GPUs can do it now, just not well due to the limitations of their VRAM. Which is EXACTLY what SCrypt was designed to accomplish. It's high memory usage makes GPUs and other accelerated parallel processors require huge amounts of memory so that they arent faster/more efficient at cracking it. That was the goal of setting the SCrypt parameters that way when creating the wallet. To stop people from being able to crack it.. You would need to likely design an ASIC or use an FPGA with an absolutely ridiculous local memory size. It's simply not been done to my knowledge. You are far better off using many CPUs across many systems than designing your own processor. That will save you several million dollars.. I do not believe you understand what an ASIC is or how they work. If you would like, I can explain it, but it might be better to do so on the forums. I will try to make this as simple as possible to avoid having to explain all of that.\nSimple answer: No. There is nothing you can do except cluster a bunch of CPU machines together and hope for the best or deal with the speeds offered by your GPUs, if it runs on them at all. If you want, you can drop a couple million bucks and have a custom ASIC with a massive amount of memory designed to do your math, but most people don't have that kind of capital laying around to blow on something like this. There is no other magical way to make this work or suddenly make it faster. If there was, we wouldnt be using SCrypt for key derivation. Obviously.. What driver version is currently installed? Nvidia drivers are usually the culprit for specific modes not working.. I'm actually not sure when it happened @magnumripper, I need to dig through the versions and find out. It doesnt seem bad at all, considering all it does is add another rule for 'x' (Extract range) and move the original function (delete range) to 'O'.. Remove the *. That is NOT a part of the hash. What you are trying to load is a MySQL5 hashes, which is just a double round of SHA1 raw if i remember correctly. Strip the * and load as -m 300 and it will work just fine.. Cracking of the second layer passwords is supported by https://github.com/gurnec/btcrecover \nIt may be possible to implement for hashcat, though I haven't looked into how that specific algorithm works.. It's likely that one of the hashes you are targeting has different KDF settings, which can result in slower/faster generation times. KDF settings in applications are usually tuned towards slower generation speeds as time goes on to resist attacks from newer, more advanced hardware. It's possible that your unknown hash was generated using weaker settings and is thus easier/faster to generate candidates for.. \"hashcat --force\"\nWell that should tell you everything you need to know right there.. After some review, I have revised my proposed fix to include a warning message in place of the potfile count, skipping the potfile remove step entirely. I've issued a pull request that implements my changes. . ",
    "mrtifa12": "ok so now i found that i was using it wrong\nthe new command is \nhashcat64 -a 3 -m 0 test.txt ?l?u?d?s?a\nthe error is\nGenerating bitmap tables with 16 bits.... ERROR: clGetPlatformIDs(): CL_UNKNOWN_ERROR\n. ",
    "incognitus": "I've seen quite a bit of these, especially with different rounds up to 100, generally mostly are 10. support\n. ",
    "kvkenyon": "seen this in rail apps, would love to see this added.\n. ",
    "killswitch-GUI": "@jsteube Is this a issue with -m 7100 OSX v10.8+ as well? Interesting enough I'm experiencing issues where dict will work but brute force will not.\nreference:\n- salt 70 chars\noutput:\nalexanders-MBP:loader alexanderrymdeko-harvey$ hashcat -a 3 -m 0 test.txt ?a?a?a?a?a?a\nhashcat (v3.10) starting...\nWARNING: Hashfile 'test.txt' on line 1 ($ml$41076$935aae561d7f865eb5e6f8fc4392c154630XXXXXXXd7bb24ef9a7a166d8bc4c10$c8ae662a491d2055ef304da8eed716dXXXXXXXXXXXXXd330f28cb72d93171d63ff613c0b5142c7bced73d5575388ec3843e71611bde2d32022dbb49cc09a8e1bf961a6c367d5b6d6fae0fa3e7f93ff4bf73c5245df97217b4962b399c1d92f7b60e81bf642f694ccdbede495ef49587005e7d332d7e5a3c): Line-length exception\nParsed Hashes: 2/2 (100.00%)\nWith dict: \n```\nhashcat -a 0 -m 7100 test.txt dict.txt \nhashcat (v3.10) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashes: 1 hashes; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\n* Uses-64-Bit\nGenerated dictionary stats for dict.txt: 15 bytes, 1 words, 1 keyspace           \nATTENTION!                                              \n  The wordlist or mask you are using is too small.\n  Therefore, hashcat is unable to utilize the full parallelization power of your device(s).\n  The cracking speed will drop.\n  Workaround: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#how_to_create_more_work_for_full_speed\nINFO: approaching final keyspace, workload adjusted       \n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => s\nSession.Name...: hashcat\nStatus.........: Running\nInput.Mode.....: File (dict.txt)\nHash.Target....: $ml$48076$935aae5fc4392c15...\nHash.Type......: OSX v10.8+\nTime.Started...: Thu Jan 12 11:42:14 2017 (8 secs)\nSpeed.Dev.#2...:        0 H/s (0.00ms)\nSpeed.Dev.#3...:        0 H/s (2.70ms)\nSpeed.Dev.#*...:        0 H/s\nRecovered......: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.......: 0/1 (0.00%)\nRejected.......: 0/0 (0.00%)\nRestore.Point..: 0/1 (0.00%)\n$ml$42076$935aae561d7f865eb5e6f8fc4392cXXXXXX012df6ed7bb24ef9a7a166d8bc4c10$c8ae662a491d2055ef304da8eed7XXXXXXX85d28d8e234f6440721b7b33bfd330f28cb72d93171d63ff613c0b5142c7bced73d5575388ec3843e71XXXXde2d32:PASSWORD_AA\nSession.Name...: hashcat\nStatus.........: Cracked\nInput.Mode.....: File (dict.txt)\nHash.Target....: $ml$48076$935aae5e6f8fc4392c15...\nHash.Type......: OSX v10.8+\nTime.Started...: Thu Jan 12 11:42:14 2017 (14 secs)\nSpeed.Dev.#2...:        0 H/s (0.00ms)\nSpeed.Dev.#3...:        0 H/s (2.69ms)\nSpeed.Dev.#*...:        0 H/s\nRecovered......: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.......: 1/1 (100.00%)\nRejected.......: 0/1 (0.00%)\nStarted: Thu Jan 12 11:42:14 2017\nStopped: Thu Jan 12 11:42:38 2017 \n```\n. ",
    "chadgrant": "I have a hash dump with 64 chars of salt ... bummer hashcat can't do variable salt lengths since there are no restrictions on developers using very long salts. ",
    "gohashcat": "Hi! Its look nice to have speed loss, but can hashing more salt length.\nI need to hash sha256(salt.pass) with pass+salt length more than 55 characters (its up to 80-90 characters long) But I can't crack it :( Or help, how can I crack it? \nDo you can to create algoritm sha256(salt.pass) or just sha256 (to use mask instead salt) version with longer salt+pass length (but slower hashing)?\nThanks! (sorry my English ;) ). ",
    "Hydraze": "Seems good to me. Thank you atom!\n. It works, thanks.. I can't reproduce on macOS Sierra or El Capitan.\nBy the way, why are you running hashcat as root?. I can also run hashcat as root on my mac so I think there is an issue with your installation rather than with hashcat itself. ",
    "pascalqq": "I hava found this prob since hashcat 2.x.\nThe display of the AP and client MAC not always in one order.\n. Tks for the fix. It works fine now.\nBut still a question, why cracked with the statuts exhausted? Like this:\n$7z$0$19$0$$8$......:123456\nSession..........: all\nStatus...........: Exhausted\nHash.Type........: 7-Zip\nHash.Target......: $7z$0$19$0$$8$33265f3da.......\n........\n. All right, TKS.. Frist, use this http://www.intel.com/content/www/us/en/support/detect.html to update or reinstall your intel gpu driver.\nSecond, add --force to your para.\nThen, this should not be posted in issue, your should post your question here: https://hashcat.net/forum/forum-45.html. ",
    "johnnyxmas": "I do not experience the problem in 3.20 rc2. It appears to be cracking as expected. Thanks! \n. ",
    "diegodieguex": "no, sorry maybe It's a typing error. The truth is that the opencl-vector does not work\n. hashcat -a3 -m2500 -b\nSpeed.Dev.# 2.....:   111.6 kH/s (75.64ms)\nhashcat -a 3 -m 2500 --opencl-vector=2 -b\nSpeed.Dev.# 2.....:   111.0 kH/s (91.26ms)\nhashcat -a 3 -m 2500 --opencl-vector=4 -b\nSpeed.Dev.# 2.....:    55900 H/s (61.75ms)\nhashcat -a 3 -m 2500 --opencl-vector=8 -b\nSpeed.Dev.# 2.....:    55610 H/s (72.89ms)\nhashcat -a 3 -m 2500 --opencl-vector=16 -b\nSpeed.Dev.# 2.....:    27886 H/s (54.39ms)\n. using opencl-vector has decrease the performance. no looks good for me\n. ok thanks\nhashcat -a 3 -m 2500 --opencl-vector=4 example.hccap 014?d?d?d?d?d?d?d?d\nStatus...........: Cracked\nSpeed.Dev.# 2.....:    72466 H/s (11.81ms)\nslow... what is the improvement of opencl-vector?\nAt this point, I think than is better not use it\n. AMD Radeon R9 M395 Compute Engine\nMemory : 512/2048 MB allocatable\nhashcat -a3 -m2500 -b\nSpeed.Dev.# 2.....: 111.6 kH/s (75.64ms)\ndo you think than is a good speed? or what should I do?\n. but I have an iMac (Retina 5K, 27-inch, Late 2015)\n. I need to switch to PC? \nno many thanks ;-)\n. nope. Im sorry\nhttp://i.imgur.com/HlUpyJe.jpg. ok but no success\nhttp://textuploader.com/d6ma3. hashcat (v3.6.0-454-g12295dcd) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:    29942 H/s (117.17ms)\nStarted: Tue Aug 29 15:44:37 2017\nStopped: Tue Aug 29 15:44:51 2017. the same problem with MacOS High Sierra 10.13 GM\n(from source) no problem. v3.30 and v3.6.0 working\nhttps://i.imgur.com/ijKWa4p.jpg\nbut fail with all repos\nhttps://i.imgur.com/0dw8qm9.jpg. sorry again but I don't think so. maybe is a branch problem. all sources working OK and realy slow all repos \nhttps://i.imgur.com/Sx2L93S.jpg\nhttps://i.imgur.com/lslMUst.jpg. same problem nothing changed. thanks\nhttps://i.imgur.com/wBs6Yxg.jpg. hashcat (4.0.0-rc6) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Apple\n  Name    : Apple\n  Version : OpenCL 1.2 (Aug 23 2017 16:35:41)\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 4\n    Vendor         : Intel\n    Name           : Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz\n    Version        : OpenCL 1.2 \n    Processor(s)   : 8\n    Clock          : 4000\n    Memory         : 2048/8192 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.1\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : AMD\n    Name           : AMD Radeon R9 M395 Compute Engine\n    Version        : OpenCL 1.2 \n    Processor(s)   : 28\n    Clock          : 834\n    Memory         : 512/2048 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2 (Aug 24 2017 22:09:54)\n. hashcat (4.0.0-rc6) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, 2048/8192 MB allocatable, 8MCU\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nBenchmark relevant options:\n\n--opencl-device-types=1,2\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2\nSpeed.Dev.#1.....:     7583 H/s (67.70ms)\nSpeed.Dev.#2.....:    30054 H/s (117.51ms)\nSpeed.Dev.#*.....:    37637 H/s\nStarted: Fri Oct 20 10:11:32 2017\nStopped: Fri Oct 20 10:11:48 2017\n. hashcat (v3.6.0-48-g52c1e15f) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:    94570 H/s (75.32ms)\nStarted: Sat Oct 21 10:39:21 2017\nStopped: Sat Oct 21 10:39:33 2017\n\nhashcat (v3.6.0-51-g56dc8ae3) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:    30461 H/s (115.25ms)\nStarted: Sat Oct 21 10:40:58 2017\nStopped: Sat Oct 21 10:41:12 2017\n\nhashcat (4.0.0-rc6) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2\nSpeed.Dev.#2.....:    30101 H/s (117.51ms)\nStarted: Sat Oct 21 13:53:15 2017\nStopped: Sat Oct 21 13:53:35 2017. ok I think is somethig wrong\nI have this second image as a reference\nhttps://i.imgur.com/rAkfH3l.png\n40 times faster than GeForce GTX 1060 6GB it seems too much!\nhave installed hcxtools and hcxkeys but I dont know how make it work\nhttps://i.imgur.com/cjKeZ6J.jpg\nhttps://i.imgur.com/0ZS5SFb.jpg\nI share my .cap file and the pass\ncan you explain the method in detail to work it?\nhttp://www29.zippyshare.com/v/XelhBxYU/file.html\nthank you. well I think than -m 2501 displayed a huge speed while -m 2500 is getting slower\nhashcat -m 2500 -b\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nDevice #2: AMD Radeon R9 M395 Compute Engine, 512/2048 MB allocatable, 28MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#2.....:    29942 H/s (117.53ms) @ Accel:128 Loops:64 Thr:64 Vec:1\n. I hope to make captures with hcxtools and generate the possibles PMK. you think it's feasible compiling it in Apple systems ?. ",
    "recon-ng": "I was using the pre-compiled version 3.10 available through the hashcat website (binaries) with the following arguments: \"-m 99999 -a 3 path_to_file ?a?a?a?a?a?a?a?a\". I suppose the issue will go away once I pull the latest and build from source. I'll let you know how that goes when I succeed.. Yay! Works! Thnx!. Interesting. Thanks for the reply.. I see! Thnx. Closing this.. Thanks. I'll just assume the collisions aren't opening the file because it's corrupted... although a bruteforce did yield a password that successfully unlocked it.. ",
    "cristiaan3003": "I don't see the solution. Could you post solution here, please?. ",
    "hgbstu": "Tried starting two HC instances writing to same pot file, strace shows the same out as @jsteube mentioned in his post. So the second instance locks.. ",
    "pomwtin": "You are correct, it is windows OS (win7, 64bit)\nOutput of hashcat -I\n```\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Advanced Micro Devices, Inc.\n  Name    : AMD Accelerated Parallel Processing\n  Version : OpenCL 2.0 AMD-APP (1800.8)\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : Cypress\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 20\n    Clock          : 735\n    Memory         : 512/1024 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 1800.8 (VM)\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : Cypress\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 20\n    Clock          : 735\n    Memory         : 512/1024 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 1800.8 (VM)\nDevice ID #3\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : Cypress\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 20\n    Clock          : 735\n    Memory         : 512/1024 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 1800.8 (VM)\nDevice ID #4\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : Cypress\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 20\n    Clock          : 735\n    Memory         : 512/1024 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 1800.8 (VM)\nDevice ID #5\n    Type           : CPU\n    Vendor ID      : 1\n    Vendor         : AuthenticAMD\n    Name           : AMD FX(tm)-8320 Eight-Core Processor\n    Version        : OpenCL 1.2 AMD-APP (1800.8)\n    Processor(s)   : 8\n    Clock          : 3500\n    Memory         : 2047/4095 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 1800.8 (sse2,avx,fma4)\nPlatform ID #2\n  Vendor  : NVIDIA Corporation\n  Name    : NVIDIA CUDA\n  Version : OpenCL 1.2 CUDA 8.0.0\nDevice ID #6\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : GeForce GTX 980 Ti\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 22\n    Clock          : 1190\n    Memory         : 1536/6144 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 376.09\nDevice ID #7\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : GeForce GTX 980\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 16\n    Clock          : 1215\n    Memory         : 1024/4096 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 376.09\n```\noutput of clinfo\n```\nNumber of platforms:                             2\n  Platform Profile:                              FULL_PROFILE\n  Platform Version:                              OpenCL 2.0 AMD-APP (1800.8)\n  Platform Name:                                 AMD Accelerated Parallel Processing\n  Platform Vendor:                               Advanced Micro Devices, Inc.\n  Platform Extensions:                           cl_khr_icd cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_am\nd_event_callback cl_amd_offline_devices\n  Platform Profile:                              FULL_PROFILE\n  Platform Version:                              OpenCL 1.2 CUDA 8.0.0\n  Platform Name:                                 NVIDIA CUDA\n  Platform Vendor:                               NVIDIA Corporation\n  Platform Extensions:                           cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_\nint32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_\ncompiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_d3d9_sharing cl_nv_d3d10_sharing cl_khr_d3d10_sharing cl_nv_\nd3d11_sharing cl_nv_copy_opts\nPlatform Name:                                 AMD Accelerated Parallel Processing\nNumber of devices:                               5\n  Device Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     1002h\n  Board name:                                    AMD Radeon HD 5900 Series\n  Device Topology:                               PCI[ B#6, D#0, F#0 ]\n  Max compute units:                             20\n  Max work items dimensions:                     3\n    Max work items[0]:                           256\n    Max work items[1]:                           256\n    Max work items[2]:                           256\n  Max work group size:                           256\n  Preferred vector width char:                   16\n  Preferred vector width short:                  8\n  Preferred vector width int:                    4\n  Preferred vector width long:                   2\n  Preferred vector width float:                  4\n  Preferred vector width double:                 2\n  Native vector width char:                      16\n  Native vector width short:                     8\n  Native vector width int:                       4\n  Native vector width long:                      2\n  Native vector width float:                     4\n  Native vector width double:                    2\n  Max clock frequency:                           735Mhz\n  Address bits:                                  32\n  Max memory allocation:                         536870912\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          8\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   1024\n  Alignment (bits) of base address:              2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     No\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    None\n  Cache line size:                               0\n  Cache size:                                    0\n  Global memory size:                            1073741824\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Scratchpad\n  Local memory size:                             32768\n  Max pipe arguments:                            0\n  Max pipe active reservations:                  0\n  Max pipe packet size:                          0\n  Max global variable size:                      0\n  Max global variable preferred total size:      0\n  Max read/write image args:                     0\n  Max on device events:                          0\n  Queue on device max size:                      0\n  Max on device queues:                          0\n  Queue on device preferred size:                0\n  SVM capabilities:\n    Coarse grain buffer:                         No\n    Fine grain buffer:                           No\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                No\n    Profiling :                                  Yes\n  Queue on Device properties:\n    Out-of-Order:                                No\n    Profiling :                                  No\n  Platform ID:                                   000007FEDBF9F180\n  Name:                                          Cypress\n  Vendor:                                        Advanced Micro Devices, Inc.\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                1800.8 (VM)\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 AMD-APP (1800.8)\n  Extensions:                                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extend\ned_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store\ncl_khr_gl_sharing cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_op\ns2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_amd_image2d_from_buffer_read_only cl_khr_spir\n cl_khr_gl_event\nDevice Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     1002h\n  Board name:                                    AMD Radeon HD 5900 Series\n  Device Topology:                               PCI[ B#15, D#0, F#0 ]\n  Max compute units:                             20\n  Max work items dimensions:                     3\n    Max work items[0]:                           256\n    Max work items[1]:                           256\n    Max work items[2]:                           256\n  Max work group size:                           256\n  Preferred vector width char:                   16\n  Preferred vector width short:                  8\n  Preferred vector width int:                    4\n  Preferred vector width long:                   2\n  Preferred vector width float:                  4\n  Preferred vector width double:                 2\n  Native vector width char:                      16\n  Native vector width short:                     8\n  Native vector width int:                       4\n  Native vector width long:                      2\n  Native vector width float:                     4\n  Native vector width double:                    2\n  Max clock frequency:                           735Mhz\n  Address bits:                                  32\n  Max memory allocation:                         536870912\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          8\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   1024\n  Alignment (bits) of base address:              2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     No\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    None\n  Cache line size:                               0\n  Cache size:                                    0\n  Global memory size:                            1073741824\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Scratchpad\n  Local memory size:                             32768\n  Max pipe arguments:                            0\n  Max pipe active reservations:                  0\n  Max pipe packet size:                          0\n  Max global variable size:                      0\n  Max global variable preferred total size:      0\n  Max read/write image args:                     0\n  Max on device events:                          0\n  Queue on device max size:                      0\n  Max on device queues:                          0\n  Queue on device preferred size:                0\n  SVM capabilities:\n    Coarse grain buffer:                         No\n    Fine grain buffer:                           No\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                No\n    Profiling :                                  Yes\n  Queue on Device properties:\n    Out-of-Order:                                No\n    Profiling :                                  No\n  Platform ID:                                   000007FEDBF9F180\n  Name:                                          Cypress\n  Vendor:                                        Advanced Micro Devices, Inc.\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                1800.8 (VM)\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 AMD-APP (1800.8)\n  Extensions:                                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extend\ned_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store\ncl_khr_gl_sharing cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_op\ns2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_amd_image2d_from_buffer_read_only cl_khr_spir\n cl_khr_gl_event\nDevice Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     1002h\n  Board name:                                    AMD Radeon HD 5900 Series\n  Device Topology:                               PCI[ B#16, D#0, F#0 ]\n  Max compute units:                             20\n  Max work items dimensions:                     3\n    Max work items[0]:                           256\n    Max work items[1]:                           256\n    Max work items[2]:                           256\n  Max work group size:                           256\n  Preferred vector width char:                   16\n  Preferred vector width short:                  8\n  Preferred vector width int:                    4\n  Preferred vector width long:                   2\n  Preferred vector width float:                  4\n  Preferred vector width double:                 2\n  Native vector width char:                      16\n  Native vector width short:                     8\n  Native vector width int:                       4\n  Native vector width long:                      2\n  Native vector width float:                     4\n  Native vector width double:                    2\n  Max clock frequency:                           735Mhz\n  Address bits:                                  32\n  Max memory allocation:                         536870912\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          8\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   1024\n  Alignment (bits) of base address:              2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     No\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    None\n  Cache line size:                               0\n  Cache size:                                    0\n  Global memory size:                            1073741824\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Scratchpad\n  Local memory size:                             32768\n  Max pipe arguments:                            0\n  Max pipe active reservations:                  0\n  Max pipe packet size:                          0\n  Max global variable size:                      0\n  Max global variable preferred total size:      0\n  Max read/write image args:                     0\n  Max on device events:                          0\n  Queue on device max size:                      0\n  Max on device queues:                          0\n  Queue on device preferred size:                0\n  SVM capabilities:\n    Coarse grain buffer:                         No\n    Fine grain buffer:                           No\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                No\n    Profiling :                                  Yes\n  Queue on Device properties:\n    Out-of-Order:                                No\n    Profiling :                                  No\n  Platform ID:                                   000007FEDBF9F180\n  Name:                                          Cypress\n  Vendor:                                        Advanced Micro Devices, Inc.\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                1800.8 (VM)\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 AMD-APP (1800.8)\n  Extensions:                                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extend\ned_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store\ncl_khr_gl_sharing cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_op\ns2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_amd_image2d_from_buffer_read_only cl_khr_spir\n cl_khr_gl_event\nDevice Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     1002h\n  Board name:                                    AMD Radeon HD 5900 Series\n  Device Topology:                               PCI[ B#7, D#0, F#0 ]\n  Max compute units:                             20\n  Max work items dimensions:                     3\n    Max work items[0]:                           256\n    Max work items[1]:                           256\n    Max work items[2]:                           256\n  Max work group size:                           256\n  Preferred vector width char:                   16\n  Preferred vector width short:                  8\n  Preferred vector width int:                    4\n  Preferred vector width long:                   2\n  Preferred vector width float:                  4\n  Preferred vector width double:                 2\n  Native vector width char:                      16\n  Native vector width short:                     8\n  Native vector width int:                       4\n  Native vector width long:                      2\n  Native vector width float:                     4\n  Native vector width double:                    2\n  Max clock frequency:                           735Mhz\n  Address bits:                                  32\n  Max memory allocation:                         536870912\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          8\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   1024\n  Alignment (bits) of base address:              2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     No\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    None\n  Cache line size:                               0\n  Cache size:                                    0\n  Global memory size:                            1073741824\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Scratchpad\n  Local memory size:                             32768\n  Max pipe arguments:                            0\n  Max pipe active reservations:                  0\n  Max pipe packet size:                          0\n  Max global variable size:                      0\n  Max global variable preferred total size:      0\n  Max read/write image args:                     0\n  Max on device events:                          0\n  Queue on device max size:                      0\n  Max on device queues:                          0\n  Queue on device preferred size:                0\n  SVM capabilities:\n    Coarse grain buffer:                         No\n    Fine grain buffer:                           No\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\n  Kernel Preferred work group size multiple:     64\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                No\n    Profiling :                                  Yes\n  Queue on Device properties:\n    Out-of-Order:                                No\n    Profiling :                                  No\n  Platform ID:                                   000007FEDBF9F180\n  Name:                                          Cypress\n  Vendor:                                        Advanced Micro Devices, Inc.\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                1800.8 (VM)\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 AMD-APP (1800.8)\n  Extensions:                                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extend\ned_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store\ncl_khr_gl_sharing cl_ext_atomic_counters_32 cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_op\ns2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_amd_image2d_from_buffer_read_only cl_khr_spir\n cl_khr_gl_event\nDevice Type:                                   CL_DEVICE_TYPE_CPU\n  Vendor ID:                                     1002h\n  Board name:\n  Max compute units:                             8\n  Max work items dimensions:                     3\n    Max work items[0]:                           1024\n    Max work items[1]:                           1024\n    Max work items[2]:                           1024\n  Max work group size:                           1024\n  Preferred vector width char:                   16\n  Preferred vector width short:                  8\n  Preferred vector width int:                    4\n  Preferred vector width long:                   2\n  Preferred vector width float:                  8\n  Preferred vector width double:                 4\n  Native vector width char:                      16\n  Native vector width short:                     8\n  Native vector width int:                       4\n  Native vector width long:                      2\n  Native vector width float:                     8\n  Native vector width double:                    4\n  Max clock frequency:                           3500Mhz\n  Address bits:                                  64\n  Max memory allocation:                         2147483648\n  Image support:                                 Yes\n  Max number of images read arguments:           128\n  Max number of images write arguments:          64\n  Max image 2D width:                            8192\n  Max image 2D height:                           8192\n  Max image 3D width:                            2048\n  Max image 3D height:                           2048\n  Max image 3D depth:                            2048\n  Max samplers within kernel:                    16\n  Max size of kernel argument:                   4096\n  Alignment (bits) of base address:              1024\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     Yes\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    Read/Write\n  Cache line size:                               64\n  Cache size:                                    16384\n  Global memory size:                            4294107136\n  Constant buffer size:                          65536\n  Max number of constant args:                   8\n  Local memory type:                             Global\n  Local memory size:                             32768\n  Max pipe arguments:                            16\n  Max pipe active reservations:                  16\n  Max pipe packet size:                          2147483648\n  Max global variable size:                      1879048192\n  Max global variable preferred total size:      1879048192\n  Max read/write image args:                     64\n  Max on device events:                          0\n  Queue on device max size:                      0\n  Max on device queues:                          0\n  Queue on device preferred size:                0\n  SVM capabilities:\n    Coarse grain buffer:                         No\n    Fine grain buffer:                           No\n    Fine grain system:                           No\n    Atomics:                                     No\n  Preferred platform atomic alignment:           0\n  Preferred global atomic alignment:             0\n  Preferred local atomic alignment:              0\n  Kernel Preferred work group size multiple:     1\n  Error correction support:                      0\n  Unified memory for Host and Device:            1\n  Profiling timer resolution:                    292\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     Yes\n  Queue on Host properties:\n    Out-of-Order:                                No\n    Profiling :                                  Yes\n  Queue on Device properties:\n    Out-of-Order:                                No\n    Profiling :                                  No\n  Platform ID:                                   000007FEDBF9F180\n  Name:                                          AMD FX(tm)-8320 Eight-Core Processor\n  Vendor:                                        AuthenticAMD\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                1800.8 (sse2,avx,fma4)\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 AMD-APP (1800.8)\n  Extensions:                                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extend\ned_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomi\ncs cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_ext_device_fission cl_amd_device_attribute_query cl_amd\n_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_spir cl_khr_gl_event\nPlatform Name:                                 NVIDIA CUDA\nNumber of devices:                               2\n  Device Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     10deh\n  Max compute units:                             22\n  Max work items dimensions:                     3\n    Max work items[0]:                           1024\n    Max work items[1]:                           1024\n    Max work items[2]:                           64\n  Max work group size:                           1024\n  Preferred vector width char:                   1\n  Preferred vector width short:                  1\n  Preferred vector width int:                    1\n  Preferred vector width long:                   1\n  Preferred vector width float:                  1\n  Preferred vector width double:                 1\n  Native vector width char:                      1\n  Native vector width short:                     1\n  Native vector width int:                       1\n  Native vector width long:                      1\n  Native vector width float:                     1\n  Native vector width double:                    1\n  Max clock frequency:                           1190Mhz\n  Address bits:                                  64\n  Max memory allocation:                         1610612736\n  Image support:                                 Yes\n  Max number of images read arguments:           256\n  Max number of images write arguments:          16\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            4096\n  Max image 3D height:                           4096\n  Max image 3D depth:                            4096\n  Max samplers within kernel:                    32\n  Max size of kernel argument:                   4352\n  Alignment (bits) of base address:              4096\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     Yes\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    Read/Write\n  Cache line size:                               128\n  Cache size:                                    360448\n  Global memory size:                            6442450944\n  Constant buffer size:                          65536\n  Max number of constant args:                   9\n  Local memory type:                             Scratchpad\n  Local memory size:                             49152\n  Kernel Preferred work group size multiple:     32\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1000\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                Yes\n    Profiling :                                  Yes\n  Platform ID:                                   000000000259A1B0\n  Name:                                          GeForce GTX 980 Ti\n  Vendor:                                        NVIDIA Corporation\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                376.09\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 CUDA\n  Extensions:                                    cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_\nint32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_\ncompiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_d3d9_sharing cl_nv_d3d10_sharing cl_khr_d3d10_sharing cl_nv_\nd3d11_sharing cl_nv_copy_opts\nDevice Type:                                   CL_DEVICE_TYPE_GPU\n  Vendor ID:                                     10deh\n  Max compute units:                             16\n  Max work items dimensions:                     3\n    Max work items[0]:                           1024\n    Max work items[1]:                           1024\n    Max work items[2]:                           64\n  Max work group size:                           1024\n  Preferred vector width char:                   1\n  Preferred vector width short:                  1\n  Preferred vector width int:                    1\n  Preferred vector width long:                   1\n  Preferred vector width float:                  1\n  Preferred vector width double:                 1\n  Native vector width char:                      1\n  Native vector width short:                     1\n  Native vector width int:                       1\n  Native vector width long:                      1\n  Native vector width float:                     1\n  Native vector width double:                    1\n  Max clock frequency:                           1215Mhz\n  Address bits:                                  64\n  Max memory allocation:                         1073741824\n  Image support:                                 Yes\n  Max number of images read arguments:           256\n  Max number of images write arguments:          16\n  Max image 2D width:                            16384\n  Max image 2D height:                           16384\n  Max image 3D width:                            4096\n  Max image 3D height:                           4096\n  Max image 3D depth:                            4096\n  Max samplers within kernel:                    32\n  Max size of kernel argument:                   4352\n  Alignment (bits) of base address:              4096\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                                     Yes\n    Quiet NaNs:                                  Yes\n    Round to nearest even:                       Yes\n    Round to zero:                               Yes\n    Round to +ve and infinity:                   Yes\n    IEEE754-2008 fused multiply-add:             Yes\n  Cache type:                                    Read/Write\n  Cache line size:                               128\n  Cache size:                                    262144\n  Global memory size:                            4294967296\n  Constant buffer size:                          65536\n  Max number of constant args:                   9\n  Local memory type:                             Scratchpad\n  Local memory size:                             49152\n  Kernel Preferred work group size multiple:     32\n  Error correction support:                      0\n  Unified memory for Host and Device:            0\n  Profiling timer resolution:                    1000\n  Device endianess:                              Little\n  Available:                                     Yes\n  Compiler available:                            Yes\n  Execution capabilities:\n    Execute OpenCL kernels:                      Yes\n    Execute native function:                     No\n  Queue on Host properties:\n    Out-of-Order:                                Yes\n    Profiling :                                  Yes\n  Platform ID:                                   000000000259A1B0\n  Name:                                          GeForce GTX 980\n  Vendor:                                        NVIDIA Corporation\n  Device OpenCL C version:                       OpenCL C 1.2\n  Driver version:                                376.09\n  Profile:                                       FULL_PROFILE\n  Version:                                       OpenCL 1.2 CUDA\n  Extensions:                                    cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_\nint32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_\ncompiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_d3d9_sharing cl_nv_d3d10_sharing cl_khr_d3d10_sharing cl_nv_\nd3d11_sharing cl_nv_copy_opts\n```. Thank you for taking your time to work on this!\nI'll be able to test this on thursday, will post a result then.\nRegards\nMartin. Sorry for delay. Issue is fixed.\nThanks and a happy 2017. ",
    "M1chael": "Confirm this issue:\n```\n./hashcat64.bin -a0 -m 2500 wifi.hccap wordlist -r rules/leetspeak.rule\nhashcat (v3.20) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1:         Intel(R) Core(TM) i5-2500 CPU @ 3.30GHz, 959/3839 MB allocatable, 4MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 17\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\nWatchdog: Hardware Monitoring Interface not found on your system\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\nChecking for weak hashes...clEnqueueNDRangeKernel(): CL_UNKNOWN_ERROR\n```\nUPD: The same issue with\n* Device #1:        Intel(R) Core(TM) i5-2467M CPU @ 1.60GHz, 1969/7877 MB allocatable, 4MCU\nUPD2: The same issue with another hccap. @magnumripper, thanks for the idea. I tried dictionary with one word of 10 symbols without rules and got the same error.. ",
    "decker78": "Same problem here. ",
    "ixig": "The problem went away when I compiled v3.10 (was there with v3.20): \nAlso, -D 2 always works, so only -D 1 or -D 1,2 is when problem occurs.\n```\nPlatform #0\n  Name:                                  Apple\n  Version:                               OpenCL 1.2 (Jun 30 2016 20:18:53)\nDevice #0\n    Name:                                Intel(R) Core(TM) i7-4770HQ CPU @ 2.20GHz\n    Type:                                CPU\n    Version:                             OpenCL 1.2\n    Global memory size:                  16 GB\n    Local memory size:                   32 kB\n    Max work group size:                 1024\n    Max work item sizes:                 (1024, 1, 1)\nDevice #1\n    Name:                                Iris Pro\n    Type:                                GPU\n    Version:                             OpenCL 1.2\n    Global memory size:                  1 GB 512 MB\n    Local memory size:                   64 kB\n    Max work group size:                 512\n    Max work item sizes:                 (512, 512, 512)\n```. ",
    "bluehallu": "As of current commit a192cda224a1592679d86f7a74bb4ac463476fdd, bug still happening when trying to use CPU on OSX\n```\n../hashcat/hashcat -m 7100 hash ../dictionary.txt -D 1\nhashcat (ormat:%D) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4578U CPU @ 3.00GHz, 2047/16384 MB allocatable, 4MCU\nDevice #2: Iris, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD\n* Uses-64-Bit\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\nChecking for weak hashes...clEnqueueNDRangeKernel(): CL_UNKNOWN_ERROR\nStarted: Thu Dec 29 11:10:06 2016\nStopped: Thu Dec 29 11:10:06 2016\n```. ",
    "jezeniel": "Sorry for the necro, but I am experiencing the same, but when I rollback to v3.0 it works.. ",
    "erm3nda": "I have the same error. I used to increase the key lengh and it did start (showing the same error) and without being able to interact with the CLI menu (s for update status and watch \"activity\") and no way.\nI used this same computer and same version with Hashcat time ago. Seems that the OpenCL version is the one complaining here :-/. I have see right now, that my problem about the output was related to log file with no perms to write.\nAlso, i have used a 8char mask with no more problems. I just did sudo chown me /opt/* -R and started to work.\nHope it helps.. ",
    "coolbry95": "It has GH/s but you need to be at GH/s to have it displayed. It will not display 0.124 GH/s but instead display 124753.3 MH/s.. ",
    "RealEnder": "This happens because of\nhttps://github.com/hashcat/hashcat/blob/2039e2c06eb7459f89b7de25bc127362c538e8c8/src/status.c#L115\nI believe it's by design.. Please consider \"negative\" logic for bits 5&6.\nEg, if they are 0, we didn't detect BE/LE, if 6 is up, we should not check for BE, same for 5-LE. This way it looks to me more backward compatible.. The flags from last comment implemented in JtR's tool hccapx2john.py: https://github.com/magnumripper/JohnTheRipper/commit/f8a1e676e29b9f7721baec20fafda705f95c060d. For sure Time estimated have to be kept for current user's HW IMO. Maybe another line with that, but you may see coming the next request about quantums (with OpenCL support) ;). Can you provide samples (if they come from test network) and output log?. wpa_supplicant writes there PMK, -m 2501. The value is derived with PBKDF2-SHA1 from PSK (ie. the cleartext password) over ESSID.. Please post an issue on this here: https://github.com/ZerBea/hcxdumptool/issues. Also we should not forget LE/BE/ap-less info in control field. How do you extract MIC and keyver from EAPOL, eg. gor example EAPOL value here: https://hashcat.net/wiki/doku.php?id=hccapx?. ",
    "dtest505": "My bad.  Math-fu was off.  Thought 1000 M = 1 G.\n(Isn't 1000MB 1GB?  Thought that would carry over). Ah!  That makes sense.\nThanks guys.  Sorry to cutter things here.\n. ",
    "s3inlc": "Thanks a lot for implementing.\nIt seems to work, but I'm not sure if the result makes sense in this case:\n```\n$ hashcat/hashcat --machine-readable --opencl-devices=3 --hash-type=2711 hashlists/hl24 -a 0 files/wordlist.txt --progress-only\nhashcat (v3.20-29-gf424650+) starting in progress-only mode...\n3:131072:9.86\nStarted: Sat Dec 10 11:10:19 2016\nStopped: Sat Dec 10 11:10:34 2016\n\n* Device #3: GeForce GT 650M, 256/1024 MB allocatable, 2MCU\n```\nI'm wondering a bit about the small time of 9.86 ms. If I use your calculation there, it would give me a huge length number which is much bigger than the whole keyspace. The length on this task should be something around 250000 to take ~10 mins on this computer.\n. It seems to be related with the salts in some way. When I just use one of the hashes, the result will be the same. \nWith non-salted algorithms the numbers are correct.. I tried now with the same salted hashlist again, it works as it should now.\n```\n$ hashcat/hashcat --machine-readable --opencl-devices=3 --hash-type=2711 hashlists/hl24 -a 0 files/wordlist.txt --progress-only\nhashcat (v3.20-30-g367024d+) starting in progress-only mode...\n3:262144:534965.57\nStarted: Sat Dec 10 16:23:32 2016\nStopped: Sat Dec 10 16:32:45 2016\n```\nAs you see the benchmarking took quite some time, nearly as much as a chunk normally would be approximately. Is there a way that the number of keyspace progresses (like 262144 here) could be smaller?. Thanks a lot for explaining and implementing this. \nThe changes provide what I need now.. Thanks a lot for the quick fix. The output is correctly now.. Sorry for not stating my command clearly. I checked again, it only happens when --quiet is not set.. Yes, because your STATUS grep statement seems to be wrong:\n$ ./hashcat example0.hash -a 3 ?a --mac  | grep ^STATUS\ngives no output. \n$ ./hashcat example0.hash -a 3 ?a --mac  | grep STATUS | grep \" \" | wc -l\n       1\n$. Ok, that's really a strange behaviour. So this carriage return was causing the first part of the STATUS line to be with spaces instead of tabs in the terminal?\nBasically there is no problem with adding --quiet (I think it's cleaner anyway), just need to check that this is done everywhere on the clients. So I guess we will go with this solution.. Ok, thanks a lot.. But when the default is to never timeout, then the idea of alerting user forgetting the attack mode or a dictionary would not work anymore.. Ah sorry, my fault, I misunderstood this part.. Are you sure that this should be switched? Because there might be some confusion between some implementations (e.g. https://github.com/adegtyarev/streebog) which for some reason mirrored the example hashes compared to the original RFC (https://tools.ietf.org/html/rfc6986#section-10.1.2). And as far as I see, the current way hashcat is doing is the way how it's given by the examples in the RFC.. Yes, I can confirm that the client is working.\nThough, in case of an error on the client side, the log output is quite scrambled because it's in between the other status output etc.. @apatedolos Are you using the brain with a fast hash algorithm? Keep in mind that according to the release notes, it's only worth to use the brain for very slow algorithms otherwise the brain is a bottleneck.. Thanks, the server now starts successfully and works on Windows.\nBut now the brain client on Windows seem to be broken because of the change:\n```\nhashcat64.exe --brain-client --brain-host localhost --brain-password xxxxxx -m 0 -a 0 example0.hash example.dict\nhashcat (v5.0.0-9-g61ded2bd) starting...\nlocalhost: Either the application has not called WSAStartup, or WSAStartup failed.\nStarted: Wed Oct 31 10:59:42 2018\nStopped: Wed Oct 31 10:59:42 2018\n```. With the newest beta both client and server are working now on Windows, so the issue is resolved.\nThanks again.. The brain is not useful for all algorithms. It depends on the speed in total you have on it (including if you distribute it) otherwise it would introduce a large bottleneck for faster algorithms.. Like the name is indicating, electrum2john.py is part of John the Ripper, you can find it in its repository: https://github.com/magnumripper/JohnTheRipper/blob/bleeding-jumbo/run/electrum2john.py. The entry in the readme should be done with the second commit. And the tab_completion is contained in the first commit. Did I miss something there?\nI can give the optimized ones a try maybe at a later point.. Oh, I was not referring to improving the way how this message is displayed. My point mostly was to improve the (in most cases) wrong statement about 32 being the limit of optimized kernels.\nBut your idea is quite nice as well, reducing the number of lines printed, makes a better overview.. I can build as well without any problems on Mojave/10.14.2. Basically, the only steps I do, is to clone and then run make.\ngit clone https://github.com/hashcat/hashcat && cd hashcat\nmake\nBut as @magnumripper already asked, do you have xcode and the command line tools installed?. What kind of vanity hashes are you trying to generate?\nI have some modifications which allow finding special sha1 hashes: https://github.com/s3inlc/hashcat/tree/full-minmax\nMaybe this can help to see what you need to change to generate what you need.. Take a look at the changes which were required on the m00100_a3-optimized kernel, basically you can do nearly the same for the keccak kernel, just adjusted for the kind of vanity hashes you want.. Sorry for the delay, I updated the kernels based on your comments.. Requested changes are applied.. uhh, indeed a very stupid mistake \ud83d\ude48 \nBut I'm surprised that the tests didn't fail when I ran it.. ",
    "dellastreet": "For cracking a password with zero padding :). It seemed to me that adding a hash mode for this purpose was more complicated then adding a rule. So the main reasons are prob. Lack of knowledge if the code + lazyness.. I guess i also thought it would be more flexible. For bruteforce modes it would be possible to add the zeros to the search pattern.. So its mostly relevant for dictionary attacks anyway on which i want to do rule expansion anyway.. Ok, will look into that method. Probably won't look into before mid january.. ",
    "d3d3-g": "mode 6400  doesn't work ?. yes,hash-mode 14000/14100/14400/1300 not yet updated to wiki:\nhttps://hashcat.net/wiki/doku.php?id=example_hashes\n. @jsteube \nVersion 3.30 , Hashcat Added hash-mode 1300 = SHA-224\nsee here: https://hashcat.net/forum/thread-6187.html. ",
    "Bobbingbob": "I too would love to see PDF owner password handling implemented.. ",
    "maxdestructo": "Just signed up to give a thumbs up. Please add pdf owner passwords to hashcat!. ",
    "ZilentJack": "I just double tried to check on latest version (3.20) and it doesn't seem like Hash-Mode 7000 is included anymore, not sure why?\n-m 7000 should be \"Fortigate (FortiOS)\" (https://hashcat.net/wiki/doku.php?id=example_hashes), but I'm getting \"Unknown hash-type '7000' selected\".\n. ",
    "llamasoft": "Looks like that beta build fixes it!  Thanks for the quick response.. ",
    "peterpt": "Installed hashcat-legacy instead , working perfectly .\nhttps://s24.postimg.org/3w6fnjwt1/hashcat_legacy.png\nI fixed the script deps.sh in hashcat-legacy where was getting a 404 for libssl package .\nI compiled hashcat-legacy with the new changed script and it is working perfectly as you may see in the image before .\ncheck the pull requests .. After upgrading my graphic card to nvidia , all compilation issues disappeared , it was a straight forward compilation without any errors .\nhttps://s30.postimg.org/gmkgafext/hashcatnvidia.png\nThe first post could be related to an old ati card i had here installed that ati did not denveloped new drivers to it for the new kernels after 3.4 .. ",
    "usualwyy": "This is Hashcat dude,not JohnTheRipper.\nHashcat wont give a fuk on salt like 64 bytes length.. @jsteube Yes,we got solutions on cracking the long length salt,like EGB,JTR bla bla bla.They can do the job,I knew that.\nBut none of them as good as hashcat,that's why Im here asking for a new algorithm.. ",
    "mseguin": "Here we go : \n./hashcat64.bin ../Hash/all.txt ../Dic/CT_Crackedv2.txt -D 1,2 -w 3 --force -r rules/combinator.rule\nAlso the show command doesn't show it : \n./hashcat64.bin --show ../Hash/all.txt\nAnd I grep the hashcat.potfile to find the result of the screenshot:\ncat hashcat.potfile |grep \"\\.::\"\nIs it possible that the issue is related to the 4 colons like the issue 889 ? \n. Oops my bad, I did a bad copy paste, it's \n\n.::Killthezoo::. \n\nHere's the hashlist : \n\n30020acffe70e97f5672dbd144b74446\n782d37d42ca81398be30be0540648b25\n63ee9967dc9b571e746ecb52c9518455\nc3ee19ff73bcb2ebdf72188fd991aebe\n\nHere's the Dict : \n\n.::H|CBO::.\n.::Killthezoo::.\nmerhoussame:::::\n:d:d:d:d:d1\n\nI added the two following hash that cause the same error : \n\n30020acffe70e97f5672dbd144b74446:merhoussame:::::\n782d37d42ca81398be30be0540648b25::d:d:d:d:d1\n\nHere's the output off the -V and -I\n\n./hashcat64.bin -V\nv3.20\n./hashcat64.bin -I\nhashcat (v3.20) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) OpenCL\n  Version : OpenCL 1.2 LINUX\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           :        Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz\n    Version        : OpenCL 1.2 (Build 25)\n    Processor(s)   : 8\n    Clock          : 3400\n    Memory         : 2047/16015 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2.0.25\nPlatform ID #2\n  Vendor  : Advanced Micro Devices, Inc.\n  Name    : AMD Accelerated Parallel Processing\n  Version : OpenCL 2.0 AMD-APP (1800.11)\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : Advanced Micro Devices, Inc.\n    Name           : Cayman\n    Version        : OpenCL 1.2 AMD-APP (1800.11)\n    Processor(s)   : 24\n    Clock          : 880\n    Memory         : 512/1761 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1800.11 (VM)\nDevice ID #3\n    Type           : CPU\n    Vendor ID      : 128\n    Vendor         : GenuineIntel\n    Name           : Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz\n    Version        : OpenCL 1.2 AMD-APP (1800.11)\n    Processor(s)   : 8\n    Clock          : 3056\n    Memory         : 2047/16015 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1800.11 (sse2,avx)\n\n. Finally, I removed the old potfile and it was the problem. It working under the 3.20 build 88.. ",
    "Wolfmandeny": "Is this wanted even when the user explicitly spesifies the devices to use ?\nI can understand it's done when defaults are used, but don't think hashcat should overriding the users choices.. I assume in that case it would have to be -D 1,2, since otherwise it would be CPU only ?\nSo in this case -D 1,2 -d 1,2,3\n?\n. What I wanted was just to select individual devices regardless of the platform.\nI found it illogical that I had to specify the platforms as well.\nIt's the same thing with the platform (--opencl-platforms=) option. If I select the Intel platform the CPU will be skipped here as well, and only the GPU will be used.\nThis all seems just to force the user to use one more parameter then needed. Unless there is something I can't see here?\nIn my view the default restriction set on CPU should not be set when users start to configure the devices manually.\n. ",
    "Brendanbc1": "Isn't the bug fixed now? I haven't noticed any CPU load with nvidia GPUs, and when I manually enable both CPU+GPU it improves my total hash rate (at least for SHA1). ",
    "bolduz": "Ahah, thank you for your fast response instead.\nBelow is the output of hashcat64.exe -m 500 sample500.hashes example.dict -n 1 -u 1 --force.\nI pressed s a couple of times, out of curiosity.\nAt least it starts! (But it doesn't finish?)\nA couple of things to note:\n clEnqueueReadBuffer(): CL_OUT_OF_RESOURCES (first time I see this)\n Progress stuck at 96.6%\n```\nhashcat (v3.20) starting...\nnvmlDeviceGetFanSpeed(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 850M, 512/2048 MB allocatable, 5MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 4600, 480/1921 MB allocatable, 20MCU\nDevice #3: Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nCache-hit dictionary stats example.dict: 1080240 bytes, 129988 words, 129988 keyspace\nCracking performance lower than expected? Append -w 3 to the commandline!\nINFO: approaching final keyspace, workload adjusted\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nHash.Target......: \nTime.Started.....: Tue Jan 03 21:31:56 2017 (10 secs)\nTime.Estimated...: Tue Jan 03 21:32:06 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    17315 H/s (0.01ms)\nSpeed.Dev.#2.....:        0 H/s (0.06ms)\nSpeed.Dev.#.....:    17315 H/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 124868/129988 (96.06%)\nRejected.........: 0/124868 (0.00%)\nRestore.Point....: 0/129988 (0.00%)\nCandidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....:  ->\nHWMon.Dev.#1.....: Temp: 43c Util:  0% Core: 901Mhz Mem: 900Mhz Lanes:8 Throttled*\nHWMon.Dev.#2.....: N/A\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nHash.Target......: \nTime.Started.....: Tue Jan 03 21:31:56 2017 (1 min, 11 secs)\nTime.Estimated...: Tue Jan 03 21:33:07 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    17315 H/s (0.01ms)\nSpeed.Dev.#2.....:        0 H/s (0.06ms)\nSpeed.Dev.#.....:    17315 H/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 124868/129988 (96.06%)\nRejected.........: 0/124868 (0.00%)\nRestore.Point....: 0/129988 (0.00%)\nCandidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....:  ->\nHWMon.Dev.#1.....: Temp: 39c Util:  0% Core: 901Mhz Mem: 900Mhz Lanes:8 Throttled*\nHWMon.Dev.#2.....: N/A\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nclEnqueueReadBuffer(): CL_OUT_OF_RESOURCES\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nHash.Target......: \nTime.Started.....: Tue Jan 03 21:31:56 2017 (3 mins, 2 secs)\nTime.Estimated...: Tue Jan 03 21:34:58 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    17315 H/s (0.01ms)\nSpeed.Dev.#2.....:        0 H/s (0.06ms)\nSpeed.Dev.#.....:    17315 H/s\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 124868/129988 (96.06%)\nRejected.........: 0/124868 (0.00%)\nRestore.Point....: 0/129988 (0.00%)\nCandidates.#1....: ziggy1996 -> zzzzzzzzzzz\nCandidates.#2....:  ->\nHWMon.Dev.#1.....: Temp: 38c Util:  0% Core: 901Mhz Mem: 900Mhz Lanes:8 Throttled*\nHWMon.Dev.#2.....: N/A\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\n^C\n```. Well, that was simpler than I thought. It seems to work fine, thanks.\nRunning hashcat64.exe -m 500 sample500.hashes example.dict -d 1 goes until completion without errors (except nvmlDeviceGetFanSpeed(): Not Supported, but I don't think that's related).\nI also tried to run a benchmark and it seems to be working with hashcat64.exe -b -d 1.\nBelow is the output of the first command, and the second one is the benchmark.\nLet me know if you need some more testing / command runs ;)\n```\nhashcat (v3.20) starting...\nnvmlDeviceGetFanSpeed(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 850M, 512/2048 MB allocatable, 5MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 4600, skipped\nDevice #3: Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz, skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Temperature abort trigger set to 90c\nWatchdog: Temperature retain trigger disabled\nCache-hit dictionary stats example.dict: 1080240 bytes, 129988 words, 129988 keyspace\nINFO: approaching final keyspace, workload adjusted\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: md5crypt, MD5(Unix), FreeBSD MD5, Cisco-IOS MD5\nHash.Target......: \nTime.Started.....: Tue Jan 03 21:44:59 2017 (0 secs)\nTime.Estimated...: Tue Jan 03 21:44:59 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   699.1 kH/s (5.26ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 129988/129988 (100.00%)\nRejected.........: 0/129988 (0.00%)\nRestore.Point....: 129988/129988 (100.00%)\nCandidates.#1....: simmy -> zzzzzzzzzzz\nHWMon.Dev.#1.....: Temp: 40c Util: 68% Core:1084Mhz Mem: 900Mhz Lanes:8 Throttled\nStarted: Tue Jan 03 21:44:55 2017\nStopped: Tue Jan 03 21:45:01 2017\n```\n```\nhashcat (v3.20) starting in benchmark mode...\nnvmlDeviceGetFanSpeed(): Not Supported\nnvmlDeviceGetPowerManagementLimit(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 850M, 512/2048 MB allocatable, 5MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 4600, skipped\nDevice #3: Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz, skipped\n\nHashtype: MD4\nSpeed.Dev.#1.....:  6403.2 MH/s (52.28ms)\nHashtype: MD5\nSpeed.Dev.#1.....:  3463.2 MH/s (48.30ms)\nHashtype: Half MD5\nSpeed.Dev.#1.....:  2153.2 MH/s (77.73ms)\nHashtype: SHA1\nSpeed.Dev.#1.....:  1181.6 MH/s (70.88ms)\nHashtype: SHA256\nSpeed.Dev.#1.....:   419.2 MH/s (49.89ms)\nHashtype: SHA384\nSpeed.Dev.#1.....:   133.9 MH/s (78.09ms)\nHashtype: SHA512\nSpeed.Dev.#1.....:   137.4 MH/s (76.09ms)\nHashtype: SHA-3(Keccak)\n^C\n```. I'll see if the beta fixes that issue; in the meanwhile thanks for your help, I am closing the issue since the original problem has been resolved.. Sure! Device skipped and benchmark running fine as follows:\n```\nC:\\Users\\User\\Downloads\\hashcat-3.30_beta_rc4>hashcat64.exe -b\nhashcat (v3.20-96-gaa89b8b) starting in benchmark mode...\n\nDevice #2: Intel's OpenCL runtime (GPU only) is currently broken\n             We need to wait for an update of their OpenCL drivers\n             You can use --force to override this but do not post error reports if you do so\nnvmlDeviceGetFanSpeed(): Not Supported\n\nnvmlDeviceGetPowerManagementLimit(): Not Supported\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 850M, 512/2048 MB allocatable, 5MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 4600, skipped\nDevice #3: Intel(R) Core(TM) i7-4710HQ CPU @ 2.50GHz, skipped\n\nHashtype: MD4\nSpeed.Dev.#1.....:  6419.2 MH/s (52.11ms)\nHashtype: MD5\nSpeed.Dev.#1.....:  3486.0 MH/s (47.97ms)\nHashtype: Half MD5\nSpeed.Dev.#1.....:  2144.8 MH/s (78.04ms)\nHashtype: SHA1\nSpeed.Dev.#1.....:  1185.8 MH/s (70.64ms)\nHashtype: SHA256\nSpeed.Dev.#1.....:   423.2 MH/s (49.42ms)\nHashtype: SHA384\nSpeed.Dev.#1.....:   135.3 MH/s (77.24ms)\nHashtype: SHA512\n^C\n```. ",
    "chuckfw": "Those return values look fine to me. Thank you.. Yes, I think that the --progress-only feature will fit my needs. Thank you much.. ",
    "Francisko82": "Hops, that's absolutely true and thanks for your awesome reply! I have searched a lot before posting but didn't find this info... even atom has told me to request a new mode here.\nI still cannot use my Iris GPU in OSX on this hash, but that's another story...\nBtw if anyone could provide me with the correct line to edit the hashcat.hctune file to work with Iris GPU on OSX with this hash mode, I'd be very grateful!. ",
    "elitest": "Anyone looking to work on this, I would recommend taking a look at the MS-KILE documentation, which even has some key generation examples as well as a ton of other info regarding MS' implementation of Kerberos.. ",
    "brandoncasaba": "$100 Bounty added.\nhttps://www.bountysource.com/issues/40782580-support-for-kerberos-pre-auth-etype-17-18-sha-1. To be clear, the PIN 1234 is the same as the password 1234 in the implementation. The password is simply treated as a string. . Awesome, thank you, go collect your bounty from #959! . ",
    "Pridwen": "$20 Bounty Added. ",
    "Ysagi": "Sweet no it is working with the new hashcat.hctune file.\nThanks.\n. ",
    "amlweems": "I'm having the same issue using the hashcat.hctune file from the latest commit (89f8739dde). I have a slightly different machine type than Ysagi, however. @matrix I've tried tuning it myself, but I'm not quite sure what I'm doing. Any ideas?\n```\n$ hashcat -m 3200 hashes.txt ~/wordlists/words.txt -o cracked.txt\nhashcat (v3.30-397-g89f8739ddecc) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4870HQ CPU @ 2.50GHz, skipped\nDevice #2: Iris Pro, 384/1536 MB allocatable, 40MCU\nDevice #3: GeForce GT 750M, 512/2048 MB allocatable, 2MCU\n\nHashes: 140 digests; 140 unique digests, 140 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n* Zero-Byte\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\nCache-hit dictionary stats /Users/amlweems/wordlists/words.txt: 139921525 bytes, 14343299 words, 14343299 keyspace\nAbort trap: 6\n```. ",
    "kaluche": "I can confirm, same problem here, with latest 3.30.. ",
    "iceman1001": "You guys are so hardcore gurus, I don't deserve to be here :)\nMaybe you can optimize the iclass hash1, hash2, solution in the pm3 too.... Well,  http://www.legic.com/en/1093628/atc256-atc1024.html    further down this page, you see where it is used.. ",
    "0xpr03": "@jsteube I've retried it. This time with only one entry: Hashcat can crack it.\nBut if I try it with a pw-file of 300 entries (including the right one) I'm getting the following error:\n```\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit => clEnqueueReadBuffer(): CL_INVALID_VALUE\nclEnqueueReadBuffer(): CL_DEVICE_NOT_FOUND\nSession..........: hashcat\nStatus...........: Exhausted\n```\nwith\nhashcat64.exe -a 0 -w 3 -m 13723 \"X:\\XXX\" \"X:\\pws.TXT\"\nAnd so hashcat isn't able to crack it anymore. (regardless of using -w 3 or not.)\nSystem: Win7, 64bit\nGTX 970, latest drivers from NVIDIA\n```\nOpenCL Platform #1: NVIDIA Corporation\n======================================\n* Device #1: GeForce GTX 970, 1024/4096 MB allocatable, 13MCU\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #2: AMD FX-8370 Eight-Core Processor               , skipped\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\n```\nAs I've said, trying it with one PW-Entry works, but the moment I'm trying it again with some bulk entries, hashcat spits out this error.. Update:\nI've set the size of my file down to ~200 entries and now hascat doesn't emit any errors anymore. As if my file was too huge with 300 entries.. ",
    "nijikon": "@jsteube I've added it now, but it didn't help. Here is a build log https://gist.github.com/3f2211200a574873e1b4ea3ab8d4668e. ",
    "marukka": "Unfortunately this request isnt exactly practicable. If you dont intend on supporting virtualized environments then just close this out. Although I think especially in the future you'll see more and more people run this in those environments.. The CPUs and chipset set is a pair of Xeon E5-2660 v2 and a Intel C602 (on a SuperMicro X9DAE). Both are rather common pieces of hardware, which are widely used with environments with PCIe pass through.\nPCIe passthrough is not \"very experimental\". I'm not sure where you're getting this from. VT-d has been around for since the late 2000s, this isnt some bleeding edge feature.\nNo the VM isnt out of resources. It has 4 cores and 16GB RAM allocated to it with 100% resource reservations and all it is doing is running hashcat. The cards are identical, and this will happen even if I try it with a file with only a single SHA1 hash.\nAnd there is not \"too many variables\" for you to attempt to determine the root cause. FFS if you even google the error message, you'll see plenty of posts from other developers talking about how it is just a generic error message Nvidia will return for OpenCL apps when any number of problems go wrong such as kernel launch time exceeding a timeout, and you're just taking it literally without consulting Nvidia's documentation.\nI've been looking in to this some more and I do think I've found the root cause, which of course is a bug in hashcat. The kernel launch time is exceeding the timeout value on Windows (default of 2 seconds) and Windows is killing the driver because it thinks it crashed. The reason it works with one specific GPU is that GPU doesn't have a display attached to it, so the TDR functionality is disabled for it. Playing around with the TDRDelay registry value seems promising so far, I'll continue to test it more tomorrow and report back with more details.\nSee:\nhttps://devtalk.nvidia.com/default/topic/461532/cuda-programming-and-performance/cl_out_of_resources/post/3278455/#3278455\nhttp://mcx.sourceforge.net/cgi-bin/index.cgi?Doc/FAQ#Does_MCX_support_multiple_GPUs_in_a_single_computer\nhttps://msdn.microsoft.com/en-us/library/windows/hardware/ff570087(v=vs.85).aspx\nhttps://msdn.microsoft.com/en-us/library/windows/hardware/ff569918(v=vs.85).aspx. I still need to continue testing, or as you recommended disable TDR all together. But to reply to your comments on your experiences with passing through video cards, I've only noticed two issues with other applications. When playing games at 4k resolution with SLI enabled, in full screen mode the screen with have a strong purple tint and strobe effect. This can be worked around by running games in borderless windowed full screen mode or disabling SLI. The second being a compatibility issue between Nvidia's driver and the VMware SVGA driver, which causes the Nvidia driver to constantly crash. Disabling the VMware driver resolves the issue, and the only loss of functionality i've seen is that the remote console doesnt support things like automatically changing the resolution when you make it full screen. Otherwise everything works perfectly.\nI'm not saying this should be a standard test environment of yours, but if you ever decide to give it another try (and assuming you'd use ESXi and a GeForce card) there are a couple things you need to. Since Nvidia didnt want to cannibalize their \"professional\" product line,  they added a basic virtualization check to their driver to prevent it from running in virtualized environments with GeForce series cards. If you add hypervisor.cpuid.v0 = false to the VMX file of the VM, you can work around this restriction. And although this shouldnt be relevant from my reading of your documentation regarding SLI, if you need to enable SLI you can patch the drivers with DifferentSLI Auto 1.5 to remove the license check. VMware doesn't present a SLI license in the VM's BIOS if one is present on the motherboard (which it is in the case of my X9DAE). Personally I think it should, see how they support Apple's OS X license checks on Apple hardware, but I digress.. So i've been playing around with the TDR timeout values some more. Setting it to 300 (5 minutes) allowed hashcat to run for 9 or 10 minutes before it terminated. Setting it to 600 (10 minutes) has allowed it to run for well over half an hour now. But I have noticed some unexpected behavior, and I can only assume the root cause of it (whatever it may be) is what is causing this problem. For some reason the load on the 2nd GPU is fluctuating significantly. It will be at ~100% for a while and then drop down to 0% for a while as you can see in this screenshot. It will continue to oscillate back and forth between ~100% and 0% every few minutes. Do you guys have any idea why this might happen?\n\nAlso when this happens, even though hashcat reports the load as 0% (and the card temperature seems to confirm this) it will erroneously report a large processing rate under Speed.Dev.#2. After a few minutes the Speed.Dev.#2 value begins to drop.. So basically what you're saying is that your code is infailable, and that everyone else must be at fault. And that your programming skills make you a god among men. We just confirmed that your code is timing out and triggering the TDR in Windows, yet you're blamining everyone else. Whats next, when hashcat segfaults you're going to blame everyone else too for your code accessing an illegal address because the kernel should simply let you access any memory address you desire? Wow you've been blown the fuck out.. And to comment on your claim that there is no money in GPU computing for Nvidia, please explain their Tesla line of cards.. I apologize as I may have been a bit rash. But my point I think still stands. Take for instance the FDIV bug in old Intel Pentiums. When it was discovered the entire x86 computing industry didnt throw its hands up in the air and say, oh well too bad, it isnt our problem its Intels. Instead they worked around it, companies like MathWorks implemented software floating point routines for their products, and companies like Microsoft added switches like /QIfdiv to their compilers to use software floating point routines when it detected it was running on an effected chip.\nAnd although reporting a bug doesnt guarantee it will get fixed, a perfect example being my bug report right here, if you never report it upstream then that is a guarantee that it will never be fixed.\nNow i'll play devils advocate for a moment and assume this is a problem with a 3rd party you have no control over. You still can fix this bug. As we've discovered here, changing the TDR timeout works around the problem. All you have to do is have hashcat set a registry key and restart the driver or reboot the computer to make it take effect. As @epixoip said, hashcat used to at least display a warning in prior versions but this functionality was removed. Well as my case demonstrates, and as you say this is something \"we've experienced in the past\", there clearly seems to be a demand for this feature. Now of course this isnt the best fix as the GPU doesn't remain loaded constantly but some additional computing power is better than none.. Also it would be nice if you could address hashcat incorrectly reporting device performance. Specifically it saying Speed.Dev.#2 has a non-zero value when the load is 0% in my previous screenshot.. The FDIV bug wasnt worked around at the OS level afaik. It was worked around either in programs specifically such as MathWorks, or at the compiler level as with MS's VisualStudio compiler.\nIf you are concerned about user confusion regarding UAC prompts you can present a prompt beforehand. And if people are that worried about security then they'll be either running it in a VM like myself or on dedicated hardware which will be reimaged after use, which they wont care about a registry change on anyways.\nRegarding other applications being broken by a driver restart, when this bug occurs it will break them anyways when the driver is restarted by TDR. And again if you are concerned about this, a prompt can be displayed before making this change.\nIf you dont like my ideas then fine, its your product, not mine. But at least consider re implementing the message @epixoip said was in version 3.2. It at least will help some other people.\nAlthough this would be a much more time consuming (and thus a more unreasonable request), if you guys dont like OpenCL as much you can always try adding support for CUDA which gives the impression has better support from Nvidia.. It certainly is possible, not only in the ways I mentioned previously, but in the case of this error, resubmitting the workload, or detecting which GPU timed out and disabling its use. If you would rather  fix the root cause of the problem rather than work around it, then please, go open a support case with Nvidia. But as you've said repeatedly in this thread, you're not interested in doing that, or seemingly anything else about it other than say it exists, and has existed for a long time. You're in a far better position than myself to open a support case with Nvidia as you're actually familiar with the code base.\nAnd regarding false negatives, that is a ridiculous example. The overwhelming majority of systems running hashcat wont have ECC GPU or CPU memory. In the product pics of @epixoip 's Sagitta Brutalis with its base price of $18k, it shows it uses Radeons, not Quadros or Fire Pros which have ECC memory. If anyone was worried about false negatives, it would be his customers, and he would be advertising this system with Fire Pros/Quadros/Teslas if this was a concern of his customers.. ",
    "IncognitoEntity": "As per forum thread mentioned in the comment above I would love GPU implementation for manifest.plist IOS backup cracking.  Other current methods are very slow and not brilliant.  I feel GPU utilisation in hashcat would be the best solution to this.  I know personally that big police forces within the UK have wanted this implementation.  I'm surprised this hasn't been requested more given its prevolence.  I must get through at least around 25 - 30 of these per month.  Thank you hashcat for taking this onboard.  I look too look forward to any GPU implementation.. Just writing to add support a bitlocker feature within hashcat.  I believe it uses AES-XTS.  Will it be alike truecrypt striping out the first 512 bytes?. I've just looked at a bitlocker encrypted drive that i'm working on, and using a command prompt from a Windows 10 live cd within a VM of the bitlocker encrypted machine, the manage-bde -status command shows Encryption Method: AES-XTS 128.  I'm not sure though if bitlocker lets you set up different options like Truecrypt etc.  Something I can test if need be.. ",
    "dertuxel": "Hello, I am just back from the holidays and will test the same time.\nThank you for your work\nUwe\n\nVon: philsmd notifications@github.com\nGesendet: Donnerstag, 26. Januar 2017 20:20\nAn: hashcat/hashcat\nCc: dertuxel; Author\nBetreff: Re: [hashcat/hashcat] ITunes Backup Password via GPUs in Hashcat (#977)\nUpdate: we now also implemented -m 14800 = iTunes Backup >= 10 , see 07c8983https://github.com/hashcat/hashcat/commit/07c89833c922bd4980f9bee489fc0d73725380de\n-\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/hashcat/hashcat/issues/977#issuecomment-275501964, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AYE28Gj50pwngri5s0wQ-mDOJ2LO96Gbks5rWQAJgaJpZM4LpNX6.\n. ",
    "riverwu0709boss": "$itunes_backup$90259e63540c10104264a7e8e7a676fd4ed9f9895d5b0b294fdbae9c95e497c4235b846671f87f48d10000e9051012d7621b23a8c5ebe4b2837016f96ee7b2**\nplease help me how to solution this question , i forget password . ",
    "ArchWolfdale": "Yeah, it's just like you said, I was using the --restore-file-path option in the wrong way. Now it's working beautifully!\nThank you for the tip about the cwd, can you tell me how to specify the path in the profile directory? . ",
    "milzo247": "It can't be that difficult to remember all of 5 numbers and what they define.\nGood luck getting that implemented.. ",
    "lukasz1991a": "It is a lot of interference in the system kernel to increase the salt to 500 characters?. I do not know the language in which it is written. I tried on intuition and I had a memory error. I could ask you how to do it for this one mode?. at which point I declare SALT statically. What file.. pleas help me. tell me where to look.. It's very important to me. But still I'm doing something wrong. I have a memory error. kernel switched off checking the length, the variable tmp designated with salt to stiff - changing its type in the file m01760 I had bad salt. What would you like for your help?. ",
    "DoZ10": "Below is a quick hack showing what mostly needs to be done for a simple substr() operation on sha1. This kind of change may not be trivial for all algorithms and will require a lot of work for compatibility reasons... \nImplementing a more stable, but invasive code would be a lot more work. I am honestly not that much interested in investing the required time into this. Perhaps someone else is looking for a good challenge ? \ngit clone -b substr https://github.com/DoZ10/hashcat/ \n. Yes. My bad I only tested multi-mode with provided examples. \nJust pushed the modification. This is a nice example of all the little details that needs to be addressed only for changing R0 .. R3 values. to fit with substring(... , 0, 32).. I fixed the output.\nI'll leave it as is for now. You probably want to fork it in case I delete it some day.\nFor the substring() feature itself, still not sure how and why it should be merged to master unless there are some indications of frameworks/applications that are using this.\nCheers,. I'd like to get my hands dirty with Blake2 (hashing function used by Argon2).\nAny resources / quick guidance for new kernel implementations ?   Or we just do it hard with messy PRs ?. @roycewilliams Yeah sure will do. So I guess still no docs for key structs ^^ . Update of what is done so far;\n\n[x] Chacha20\n[x] Blake2b \n[ ] Argon2d\n[ ] Keepass format\n\nRegarding Argon2d, I am trying a full GPU implementation for low costs (bad parameters) and a hybrid CPU/GPU one for high memory costs. I'll probably need @jsteube advice for the hybrid one later on.\n . I could look into this, but I mean... why on earth would you want to crack hashes on Android ? Not sure it worths the time investment...\n. According to @Banaanhangwagen Doc link, this looks like AES-XTS 128 bits.\nI believe there is another Issue opened for this mode (Bitlocker for Windows 10).\nKDF is PBKDFv2 with salted SHA-256 (which is already implemented).\nThis might be simple to implement once AES-XTS is done. \nEDIT: Truecrypt and Veracrypt seem to implement XTS... perhaps this could be feasible.. Ok might have found a way to tshoot this. All GPU debuggers failed on my Ubuntu system, but I could probably return values in buffers of mark() call. Will look at this tomorrow.\nWhat you guys use for debugging ?. Just peed on myself. Never been so happy to have printf() working.\nThx rly much... will fix my crap.. Alright, debugged the kernel code for single hash function s04.\nCan you please confirm coding style is okay, before I move on to other functions and kernel files ?\nAlso, I am using the right params for the right kernel purpose or did I hack something in a useless way ? (I am not talking about optimizing my own code, but rather if I am using the right kernel parameters/macros/structs/functions.).\nFinally, a quick description of m04, m08 and m16 funcs ? Do they relate to different input dimensions or kernel threads dimensions ? \nThanks for helping me out !\n. Understood. \nYes there is a built-in salt in Blake2b and also a variable size output, but I was planning to add it at the very end to avoid too much confusion since this is my first kernel implementation... you know what they say... Romantic Dinner before backseat P0rn. But, I'll comply with JtR format and apply the changes during the weekend.\nThanks.. Alright.. so looking at JtR \nhttps://github.com/magnumripper/JohnTheRipper/blob/8bcaddef35f703c47367fad612e473061459b156/src/rawBLAKE2_512_fmt_plug.c \nit looks like optional salt is not implemented for this RAW 512 bit implementation also with fixed size output. I guess this would make more sense in the Argon2 implementation.\nIt should not be a hurdle to implement this (variable hash length + salt), but is it preferable to do it with another -m number such as 610 ?\nFor now, all 3 kernels are working and were tested. Hash format works against JtR. Please let me know the final steps, if any, to get this work merged.\nThanks,\n. Okay there is a problem with test.pl... will have to fix this first.\nIf anything else to look at comes to mind, please let me know.. I can see what is wrong, but I don't know the best approach to the problem. I am now testing only with Attack Mode 0. VECT_SIZE will define some kind of array to every u??x types, so I need to process this in \"parallel\" in the algorithm.\nAny thoughts on the best way to achieve this, I still feel there is one piece missing when I look at other implementations.... Thanks for the great feedback !\nI pretty much understand all your points, I'll push all fixes soon. \nI'll include support for blake2b options in kernels.  The big question here is since we need to test them, do we include directly these tests in a 610 mode in the current PR or not ?. Okay, spent some hours looking at this and I think I am doing it wrong by initializing the state and parameters in the kernel. Parameter block (p_) is used only once for state initialization and state (s_) is used and updated for each hash update/final.\nPerhaps, it would be better to handle those initialization variables in CPU and then just relay the state to the GPU kernels. That way, I would not be stuck with all conditional statements/execution branches and would improve speed.\nI saw that there were special cases such as SCRYPT that relays data from CPU directly to kernel function arguments. That would be convenient for this purpose, but I feel this is may become a major change in the current project. In the end, it would really simplify kernel code especially for KEYED mode where pre-hashing is required.\nWhat do you think ?\nPS: Btw only attack mode 0 received some love this weekend, As per dicussion above, next commits will be applied to all other modes.. Gave it a shot !\nParams and State are initiated in interface.c and relayed through \"esalt\" buffer down to GPU kernel. This should be suitable for transforms and KEYED-mode pre-computing.\nNow everything looks fine for attack modes 0, 1 & 3. VECT_SIZE > 1 also fixed for vector-types.\nI guess we can call this a day !\nCheers,. Okay. For the fixes I should be able to commit something tonight. For the questions:\n2) Vector cracking was working yesterday for VECT_SIZE 2 for attack mode 0, 1 & 3 using tools/test.sh. Will take a look to see if any bug was induced, but it should work now. Initial problem was a wrong usage of vector-types uXXx.\n3) Not yet but will do. I needed to have a fully working kernel before doing benchmark tests.\n5) Intent was for KEYED mode in Blake2b performs a first hash with the KEY. This could become handy to pre-hash this in CPU and relay the output through esalt buffer for computation without too much overhead on kernel code. Unless you believe there is a neat performance gain of putting all this in kernel, I could do so. For now, cpu_blake2.h only holds types used in interface.c.\n6) According to the official reference on github, the output is simply truncated. (see. blake2b_final(...) in blake2b-ref.c). So should be a piece of pie to implement in interface.c\n9) I'll comply with JtR convention.\nThanks. Alright. Pushed all the fixes.\nGreat perf gain for the blake2b_sigma integration. Over 100% in gain.\nNot so much for the esalt_bufs out of the loop tho.\n. Blake2 comes in four flavors. The \"b\" one is the most used right now so that is why it is probably referred to only \"Blake2\" in JtR. But the true name is \"Blake2b\" and I don't think this will confuse users since perl and python libraries refer to \"Blake2b\".\nThanks for your help and guidance on this one. Was fun to do, more to come ;). Okay I found what is the problematic code, but I'm not sure if this is some \"desired\" behavior.\nThe pw_max is overriden to 31 in straight.c at function straight_ctx_init see below:\n```\n[...]\nconst bool has_noop = kernel_rules_has_noop (straight_ctx->kernel_rules_buf, straight_ctx->kernel_rules_cnt);\nif (has_noop == false)\n  {\n    switch (user_options_extra->attack_kern)\n    {\n      case ATTACK_KERN_STRAIGHT:  if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                  break;\n      case ATTACK_KERN_COMBI:     if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                  break;\n    }\n  }\n  else\n  {\n    if (hashconfig->attack_exec == ATTACK_EXEC_INSIDE_KERNEL)\n    {\n      switch (user_options_extra->attack_kern)\n      {\n        case ATTACK_KERN_STRAIGHT:  if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                    break;\n        case ATTACK_KERN_COMBI:     if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                    break;\n      }\n    }\n    else\n    {\n      // in this case we can process > 32\n    }\n  }\n```\n ATTACK_EXEC_INSIDE_KERNEL is set for my hash mode 670 and has_noop is true.\nWhat was the original intent from this code ? Since it now seem to conflict with modes that permits pw > 31, I am not sure if we should use a workaround by selecting different configuration options or figure out a patch.  . 1) Sure.\n2) Early implementation leftover.. Thanks for catching it I'll remove it. This is a stream cipher and originally I wanted to allow variable length, but revised such design since it is totally useless for cracking purposes.\n3) I'll implement the is_valid_hex_string() since the hash format is fixed size. Thanks for pointing this out.\n4) Wasn't aware of this. Will fix.\n5) Sure.\n  . One cool thing to add would be position + offset values to be more flexible for the cipher position in use.\nI could commit something to reflect that change, but it requires a new format parameter.\nSuch as $SIGNATURE$*POSITION*OFFSET*IV*PLAINTEXT*CIPHERTEXT. Alright..\nCombining position and offset parameters, you can now reach any consecutive 8 bytes in any keystream. This new addition also enables to reach an 8 byte cipher across two keystream blocks !\nIt makes more sense to allow users to reach any part of the keystream.\nWill wait for your comments !. Hi,\nare you sure this isn't shell specific ? By that, I mean that '?' is interpreted by the command line as a wildcard. Try escape the question mark with a \"\\\".. Just reproduced your problem on Ubuntu with a file called \"dl\". Look at the output of strace utility:\nUBUNTU:~/dev/hashcat$ strace ./hashcat -a 3 -m 0 example0.hash -1 ?l ?1?1?1?1?1\nexecve(\"./hashcat\", [\"./hashcat\", \"-a\", \"3\", \"-m\", \"0\", \"example0.hash\", \"-1\", \"dl\", \"?1?1?1?1?1\"], [/* 65 vars */]) = 0\nbrk(NULL)                               = 0x250b000\nOne of the arguments is \"dl\" and not \"?l\" so it was interpreted by bash and not hashcat.\nSorry, there is no fix for this^^. I noticed a similar problem for some algorithms in GPU mode with input legnth 32 bytes. Problem was mentionned in my current PR, but not addressed yet... it might be related... here's a copy.\n```\nOkay I found what is the problematic code, but I'm not sure if this is some \"desired\" behavior.\nThe pw_max is overriden to 31 in straight.c at function straight_ctx_init see below:\n[...]\nconst bool has_noop = kernel_rules_has_noop (straight_ctx->kernel_rules_buf, straight_ctx->kernel_rules_cnt);\nif (has_noop == false)\n  {\n    switch (user_options_extra->attack_kern)\n    {\n      case ATTACK_KERN_STRAIGHT:  if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                  break;\n      case ATTACK_KERN_COMBI:     if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                  break;\n    }\n  }\n  else\n  {\n    if (hashconfig->attack_exec == ATTACK_EXEC_INSIDE_KERNEL)\n    {\n      switch (user_options_extra->attack_kern)\n      {\n        case ATTACK_KERN_STRAIGHT:  if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                    break;\n        case ATTACK_KERN_COMBI:     if (pw_max > PW_DICTMAX) pw_max = PW_DICTMAX;\n                                    break;\n      }\n    }\n    else\n    {\n      // in this case we can process > 32\n    }\n  }\nATTACK_EXEC_INSIDE_KERNEL is set for my hash mode 670 and has_noop is true.\nWhat was the original intent from this code ? Since it now seem to conflict with modes that permits pw > 31, I am not sure if we should use a workaround by selecting different configuration options or figure out a patch.\n```. So the question to @jsteube is if there is some design requirements for inputs over 31 bytes to be ignored in GPU ?. I believe this is actually a really bad design.\n1) Using two independant parts combined with XOR enables collisions. \n2) This algorithm is not secure. It is vulnerable to a clever attack by pre-computing the right side which may be empty (or padded) for passwords below 9 chars. \nWhich system uses this ?. Do you have a hint on the password's length you are looking for ? Or is it really fixed to 16 bytes ?\nAlso, can you provide a test samples ?. To be honest, I don't believe that implementing that algorithm will solve your problem.\nIf the password is known to be 16 bytes and is not using common dictionary terms, you stil have to search in the whole key space which is about 26**16 for only lowercase characters... which is kinda huge.\nThe way I see the problem, is that you could abuse from the collision problem of the XORing operation instead. You'll get a lot more probabilities of getting a successful result. The rationale behind this is the following:\nWe are looking for challenge C for a password in two parts P1 & P2. The result is thus C = f(P1) XOR g(P2) where f & g are hmacs functions. If we use small numbers to represent this, we know that 7 = 5 XOR 2 = 2 XOR 5. So there exists such collision if we inverse the results. But also, 7 = 3 XOR 4 = 4 XOR 3 and so on... It is a better bet to find a collision instead of a unique pair.\nThe attack could be simple: Pre-compute one side with 8 bytes password and XOR the result with the hash you are looking for. Store all resulting hashes with the password part used. Then compute the other side with new guesses and match the output against the hash stored at previous step. When you get a hit, you get a collision (or the ral password if really really lucky).\nOf course finding a collision will be useless if the password is reused along with another algorithm for further processing.... But if used only for authentication, than this could be a great solution. . I agree.\nIf the password was less than 16 chars this could've been a trivial attack just like fo LM hashes. But for 16 byte passwords it gets more tricky.\nNow understand that the attack I presented IS ambitious but has better potential than a pure key space search.\nIn the end, the question is \"shall we implement such kernel ?\". I don't belive so. But I am ready to help if other (and better) options are available. \nPerhaps core hashcat members can reject comments here.\n  . Looking at the Python code....\n```\ndef getHmac(secret, data, hash):\n    return hmac.new(secret, data, hash).digest()\ndef Khmac(secret, seed, bytes, hash):\n    nu_seed = seed\n    output = ''\n    while len(output) < bytes:\n        nu_seed = getHmac(secret, nu_seed, hash)\n        output += getHmac(secret, nu_seed + seed, hash)\n    return output[:bytes]\n```\nI've never implemented HMACs myself, but it looks odd to perform the computation twice. Seems like your problem may come from there @jsteube . @jamorham Yes if you are looking for a collision., because pre-computing the whole keyspace for just 8 bytes (one half) still requires a huge amount of space. So finding the exact pair will still remain a problem.. If you guys really want this password.. I believe what @jsteub is proposing will be your best bet.. Sure !\nI'll check this out.. Some heads up on this.\nI did not forget, will do this work in upcoming week. \nCheers.. ",
    "FireFart": "@jsteube I don't think it's all JtR does, but it is a good start to also check variants of the username if supplied. Other checks could be added in the future if someone analyzes JtR's source code.. awesome guys thanks for the details. So anyone of the core members think this is possible to implement with the current code structure?. ",
    "olsh": "@philsmd \nThanks for the reply.\nCould you please provide a valid pattern? \nhttps://hashcat.net/wiki/doku.php?id=example_hashes\nIt seems to me that pattern described here has different parameters.\n$sip$*192.168.100.100*192.168.100.121*username*asterisk*REGISTER*sip*192.168.100.121**2b01df0b****MD5*ad0520061ca07c120d7e8ce696a6df2d. Sorry, I meant they are different from what I see in digest parameters and in the john documentation. I was confused by $sip$, URI_SUFFIX, URI_PREFIX etc.\nThis method works, thank you. \ud83d\udc4d . ",
    "stephengroat": "@neheb is there any test case I can use to test the functionality of the glob?. i was still modifying my appveyor script, i can start a new pull request and allow both maintainers and anyone interested to edit\nthe only problem that i currently see if that msys 64bit builds currently fail because they find the i686 CRT_glob.o.\nI think adding this to main removes the need to find the .o:\n````c\nif defined(MINGW64) || defined(MINGW32)\nint _dowildcard = -1; \nendif\n````\nQuick question: how do you run tests? it's not just running tools/test.sh, right?. if i make a new pr with an appveyor branch and give anyone who's interested push access, could that be communally worked on? we could just leave it for awhile before merging. @philsmd the MSYSTEM environment variable controls 32 or 64 bit compilation environments. the base machine is still a 64 bit, so that's why it's always run out of the msys64. #1032 . the dupe command is necessary to upgrade the MSYS base files and then all the packages. and 2 separate lines are needed because a new shell is necessary for each step\ni'll check on the other issue tonight when i can rdp into the system\nupdate:\n@philsmd the specific error that I'm getting from hashcat -m 0 --show *ple0.hash is \n\nI think that's an issue with that dll not being in the system path, right?. @yhfudev you could also update the .travis.yml and .appveyor.yml files\nfor .travis.yml:\nscript:\n  - ./autogen.sh && ./configure && make\nfor .appveyor.yml:\nbuild_script:\n  - if defined BASH (%BASH% -lc \"cd $(cygpath ${APPVEYOR_BUILD_FOLDER}) && git submodule update --init && ./autogen.sh && ./configure && make install\")\nalso, should you remove the existing Makefiles?. @yhfudev looks nice!\nsince you're overriding CPPFLAGS=-I$(pwd)/deps/OpenCL-Headers/ for every build, do you just want to add it to the Makefile.am to make it the default?. @magnumripper you could add the https://github.com/github/gitignore/blob/master/Autotools.gitignore. on purpose, attempts to follow the existing alignment. probably need to merge and rebase against #1550. ",
    "hcbob": "I'd like to add my support for this - I also come across a lot of FV2 encrypted Macs and having support for it in Hashcat would be great. I could also provide some volume headers and EncryptedRoot.plist.wipekey combos for research if needed.\nMany thanks!. ",
    "Banaanhangwagen": "I am also interest in this new algorithm.\nWith libfvde/fdvetools it is possible to extract the hash-value. \nExtra info can be found in this documentation\nApparently, jtr  supports it also. \nThanks!. A little bump.\nSome documentation: http://www.cl.cam.ac.uk/%7Eosc22/docs/slides_fv2_ifip_2013.pdf. It is not an error. Keyspace is simply too large. Try a more clever attack (wordlist maybe); read some manuals/forums.\nGood luck!. The salt is 16 bytes long. The key is 4 bytes. So in total it makes 16+4+16 bytes.\nTesthash: a577888ff9a47b788e7f8f843d3a3e627b06684ffc89dddc2d7647e3dcf43703\nTestsalt (base64 encoded): /gGQ5AXwllHCGxpp1aB1aA==\nPasscode: 3033\n. Exactly, it is always 4 digits.\nI understand your argument.\nMy script does the job in a couple of seconds. Because the Apple restrictions password is supported (plist2hashcat), i thought it would be cool to implement this one also...\n. I do not understand your question. Can you please reformulate?\nI think you mean this:\nThe hash and salt are found in the userconfing.xml (typo intended); \npasscodeHashis found in hex uppercase\npasscodeSaltis found in base64\nSee real life examples in my first reply.. I tested https://github.com/kholia/apfs2john on my APFS image.\nThe script gave me this output (redacted):\n$fvde$1$16$0ec787cfa0bfff2c9a8ebd11d0d0XXXX$XXXXX$XXXX983140abdc4909e1ae1c2276bc672a0868bc424ab44a00000000000000000000000000000000\nAs we can see, the output was padded with zeroes. I simply cut them off and Hashcat succesfully cracked APFS encryption with -m16700.\nMaybe someone else can reproduce this?\n. Thanks! Much appreciated!\nWill test this in a couple of days on different images.. This is not a development issue.\nPlease look here https://hashcat.net/forum/thread-7792.html . ",
    "mneitsabes": "I am also very interested in FileVault support. I can also provide examples if needed or perform tests.. ",
    "boursie": "I tried with 3.30 and git master. My fault, I was working on 3.30 source and not master ^^\nIt no longer segfault with master repo but I have the same problem, --show doesn't merge LM hash:\n\n./hashcat -m 3000 --show  --potfile-path result hashs\n44efce164ab921ca:123456\n36077a718ccdf409:8\naad3b435b51404ee:\n0182bd0bd4444bf8:1234567\n67cd839bf040d93b:89\n./hashcat -m 3000 --show  --potfile-path result hashs --outfile-format 2 --username\ntest3:123456\ntest2:8\ntest1:\ntest3:\ntest1:1234567\ntest2:1234567\ntest4:1234567\ntest4:89. Ok thank you. \n",
    "julioauto": "For what is worth, I just updated my original post with some (motivating?) background.. You're right, @solardiz. That does seem to do the trick.\nI think all of the commands you mentioned are implemented in hashcat, in john-compatible syntax, except for the 'p' position. I haven't tried it, but src/rp_cpu.c:12 tells me it expects a digit for position (conv_ctoi()).. The latest version (from Git) does not contain this bug, therefore I'm closing the issue.\nThe latest release version (zip from June) still has it, so I recommend releasing a new one ASAP.\nI'm curious: Any idea of what might have solved the issue?. ",
    "solardiz": "I think we already have this functionality in JtR, here's an example of it in use:\nhttp://www.openwall.com/lists/john-users/2010/07/31/1\nThe position code \"p\" is documented as \"position of the character last found with the \"/\" or \"%\" commands\" in doc/RULES.\n. > @jsteube p rule is already taken in hashcat as: pN -> Append duplicated word N times. \nJtR's p discussed here is not a rule command, it is a character position code, so hashcat should have no problem introducing that position code as well.\nhashcat's different meaning of the p rule command is unfortunate (in JtR the p command means \"pluralize\", and we inherited it from Crack, so it's 20+ years old), but is irrelevant here.\n. On Sun, May 14, 2017 at 04:48:48AM -0700, Jens Steube wrote:\n\nIs there any rule in Crack that does what hashcat is doing with \"p\" rule function?\n\nNo, Crack only has \"d\" (duplicate), which allows for 2x, 4x, etc., but not 3x.  In JtR, we have the powerful \"X\" command, which can be used e.g. in \"d X0zz\" (triplicate the word - one of the examples given in doc/RULES) assuming that we're at the start of a rule or after an \"M\".\nOther examples with the \"X\" command (under same assumption) include \"X011\" (duplicate the first character) and \"Xm1z\" (duplicate the last character), which IIRC hashcat has dedicated commands for.\n. On Wed, May 17, 2017 at 08:08:36AM -0700, Royce Williams wrote:\n\nExamples are now documented here: https://hashcat.net/wiki/doku.php?id=rule_based_attack#using_p_nth_instance_of_a_character_with_positional_rules\n\nRoyce, you're wrongly calling \"p\" a \"rule\".  It is not.  It is a character position code.  This distinction is important.\n. I'm sorry for commenting out of context, but this issue was referenced on a JtR issue, and this caught my attention:\n\napprox. 12-13 H/s on my 4770k. That is ~20% faster than JtRs native SCRYPT CPU code.\n\nWhat scrypt settings are these?  JtR on i7-4770K (stock clocks) gives me 17 c/s with:\nLoaded 1 password hash (scrypt [Salsa20/8 128/128 AVX])\nCost 1 (N) is 262144 for all loaded hashes\nCost 2 (r) is 8 for all loaded hashes\nCost 3 (p) is 1 for all loaded hashes\nWill run 8 OpenMP threads\nIs it the same here?  Or are we talking 256 MiB with some other combination of N and r?\nThat's without use of huge pages.  We got to update JtR's code to newer yescrypt tree, which will use huge pages for scrypt too (after some threshold, which I had previously tuned at 12 MiB, so it surely would be reached here).  This should provide some speedup (above 17 c/s), provided that huge pages are allocated (with sysctl).. > This should provide some speedup (above 17 c/s), provided that huge pages are allocated (with sysctl).\nTested it - no, turns out 17 c/s was already with huge pages despite of the old code not requesting that yet. It's CentOS 7, and per /proc/meminfo I saw AnonHugePages growing to 2+ GiB (this matches expectations: 256 MiB times 8 hardware threads), so perhaps the kernel was using huge pages anyway. I wonder if this possibly wasn't happening on atom's machine.. ",
    "gum0x": "Hi, \nSorry for the delay on my answer. I have been disconnected these days. The fact is as I saw a special condition for Darwin OSes, I supposed all versions except MacOS Sierra used gsed instead of sed. I did not tested in previous versions of OSX. \nThanks for the fix and the corrections on the identation. Let me know if you need something from my side. \nRegards, \nJosep. . ",
    "julesduvivier": "Hey thanks for the quick answer.\nclinfo was SIGSEGV as well, i reinstall the drivers and it now works perfectly.\nSorry !. ",
    "llazzaro": "I have updated my issue.\n1. Updated. the error was copied from some log files\n2. Forget about the No hashes loaded, the issue is about fan speed...the error was copied in the issue by mistake\n. For now I will ignore the warning. I will try to check the code to see if I can do something to add support for this card.. ",
    "ratzrattillo": "i updated the issue with additional information ;). I tried cracking a JWT using JTR-Jumbo and it worked quite well.\nThe procedure looked like this:\n1. Download John the Ripper Jumboversion (http://www.openwall.com/john/)\n\nDownload conversion script (https://github.com/Sjord/jwtcrack/blob/master/jwt2john.py)\npip install PyJWT\n\npython jwt2john.py ORIGINAL_JSON_WEB_TOKEN_HERE (Example.:\nOriginal Token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9.b0KvNRPdABlRuFsw584inZijEdAY4IJclzwGdZfmlhg\nConverted Token:\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWV9#6f42af3513dd001951b85b30e7ce229d98a311d018e0825c973c067597e69618)\n\n\njohn.exe --show --format=HMAC-SHA256 converted-jwt.txt\n\n\nResult:\n1 password hash cracked, 0 left\nPassword:sec\nEven if this works, i would be interested in seeing this feature in Hashcat, as JWTs are getting more important as an Autorization mechanism in the web day by day ;)\nKeep up the good work! :). @roycewilliams \nI am not using JWTs at all, but a lot of people do :)\nFrom a security perspective the following article shows a lot of things that can go wrong when using JWTs: https://www.sjoerdlangkemper.nl/2016/09/28/attacking-jwt-authentication/\n. Hello @jsteube ,\ni got that one directly from https://jwt.io/ which states the reference for JWTs :)\nIf you stick to that page, you should not encounter any non standard behaviour.\nBest regards!. ",
    "ryman1": "Would be great to see support for JWT. ",
    "cardassian-tailor": "Hello jsteube. Thank you for your reply, I appreciate it. Any idea where I can look in the opencl documentation to find details on achieving that? . ",
    "ThomasCr": "For Intel exists something like CL_DEVICE_MAX_COMPUTE_UNITS\nBut is it really a variable to set or to get?\nI have also found while I was searching - that you be able to set max theads in the code... but don't know how mush this matches to hashcat.\nI also would like to see a possible way to limit the CPU usage, so that I can let this run on other systems too without slow them to mush down. Only setting the nice level is not enough. \n. ",
    "Faiz009": "The same issue here... ",
    "micceee": "exipoip, thanks! The patch worked! Completed the process without error. I'll monitor if I get that error message again on the other modes. \njsteube, you're right, for some reason it felt like a few minutes... . Thanks Atom. I will try that.. ",
    "Dmo68": "I need to put this timeout patch on my windows 10 machine as well because I am also getting the CL_OUT_OF_RESOURCES error. I have read the instructions on https://hashcat.net/wiki/doku.php?id=timeout_patch but I am a noob when it comes to editing the registry. I have looked everywhere for a more detailed instruction on how to install this patch. Would someone be so kind as to give me a step by step guide on how to add this file to the registry to fix this issue?. ",
    "Manouchehri": "There's also dislocker to use as a reference. \nhttps://github.com/Aorimn/dislocker. You can override the default (AES-XTS 128) via group policy. I don't think\nit's common though.\n. ",
    "e-ago": "Yes, I will release the final version of the code no later than 1 or 2 days. ",
    "QuelonaSec": "#2516 states: \"New hash format supported\". Since it seems to be implemented in JTR Jumbo, does this mean something for hashcat?\nIs there any progress? Is there something to help for someone with limited coding skills?\n. ",
    "LocutusOfBorg": "fixing shortly!. ",
    "blafois": "Hi Jens !\nHere is the header:\nheader.luks.zip\nSame result with --opencl-vector-width:\n./hashcat -a 0 -m 14600 --opencl-vector-width 1 ~/header.luks example.dict\nhashcat (v3.30-329-g14883bcd) starting...\n\nDevice #1: WARNING! Kernel exec timeout is not disabled, it might cause you errors of code CL_OUT_OF_RESOURCES\n             See the wiki on how to disable it: https://hashcat.net/wiki/doku.php?id=timeout_patch\nOpenCL Platform #1: NVIDIA Corporation\n======================================\nDevice #1: Quadro M2000M, 1009/4038 MB allocatable, 5MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable Optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nWatchdog: Hardware Monitoring Interface not found on your system\nWatchdog: Temperature abort trigger disabled\nWatchdog: Temperature retain trigger disabled\nCache-hit dictionary stats example.dict: 1080240 bytes, 129988 words, 129988 keyspace\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: LUKS\nHash.Target......: /root/header.luks\nTime.Started.....: Wed Feb 22 17:41:00 2017 (5 mins, 52 secs)\nTime.Estimated...: Wed Feb 22 17:46:52 2017 (0 secs)\nInput.Base.......: File (example.dict)\nInput.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:      369 H/s (5.27ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 129988/129988 (100.00%)\nRejected.........: 0/129988 (0.00%)\nRestore.Point....: 129988/129988 (100.00%)\nCandidates.#1....: ykqkd -> zzzzzzzzzzz\nHWMon.Dev.#1.....: N/A\nStarted: Wed Feb 22 17:40:42 2017\nStopped: Wed Feb 22 17:46:53 2017\n. Thank you Jens ! It works !. ",
    "Qwertylex": "ah! When I installed amdgpu-pro-installer on arch, I failed to install: amdgpu-pro-libdrm, amdgpu-pro-libgl \nwhich means nvidia's libgl and mesa were installed instead and some other libdrm.\nEverything in 3.30 works fine now that I have properly installed amdgpu-pro!\n(however latest git [ffc6788] says I have old or broken amd drivers)\nThanks for your time anyway :+1: . ",
    "Hans-Maulwurf": "Sorry, of course I mean SHA512. It's not really a password, it's a \"server seed\" and it's 64 characters long. But this seems to be longer than the supported length?. no, it would be 64 unknown characters (letters and numbers only). ",
    "wuppp": "@magnumripper I known the ciphertext and length of key.. ",
    "X-HAT": "Thanks jsteube, and i'm sorry it's the first time that i post something.. ",
    "alaneuler": "@magnumripper You mean with hashes whose length is less than 32 characters, I insert 0 into all possible positions to produce the 32 characters long hashes and then using hashcat to crack them?. I don't have much of them, it's a one-off, and I think your solution is enough for me. I think I can code myself :). Thank you very much! . ",
    "dzmodest": "looks im going to use the beta version for the first time... (could not wait for the new release)\nhttps://hashc.co.uk all depends on it\nfor now i would kindly ask you to check this issue: #1155 . that what i was searching for ^^\nthank you\na wiki page would be much easier to access. Looks the speed is being doubled per how many uniq hashes ..\n1 uniq hashes:\n Speed.Dev.#1.....: 370.7 kH/s (92.33ms)\n2 uniq hashes:\n Speed.Dev.#1.....: 741.2 kH/s (92.33ms)\n3 uniq hashes:\n Speed.Dev.#1.....: 1114.4 kH/s (92.33ms)\n4 uniq hashes:\n Speed.Dev.#1.....: 1480.9 kH/s (92.33ms). @philsmd no one forced you to do anything.\ni have a reason, to identify each wpa handshake as an uniq hash, since mac_ap:mac_sta:essid can be the same for two different handshake, while the hash not\nexample:\n 16450dbe240e410657e933042e78cf3f:b4eeb4fe338b:48e9f19d7397:HOTFiber-1255\n eb78f2dde751d67f6c00b9923e387e56:b4eeb4fe338b:48e9f19d7397:HOTFiber-1255. looking at the code,,\nwhat are: salt->salt_buf & wpa->pke\nnot found on hccapx detailed structure\nhttps://hashcat.net/wiki/hccapx. ",
    "ss23": "I got the error slightly wrong, I have included some more output that might help debug it. Unfortunately the only hashes I have are from a client job, so I can't provide a real world example. Perhaps if anyone out there has a FortiOS device they can pull a hash from, that could be used.\n```\nroot@zx-keyscore:/opt/crack# /opt/hashcat-legacy/hashcat-cli64.bin --hash-type 7000 ss23-fortinet-hashes.txt -a 0 /opt/wordlists/\nInitializing hashcat v2.00 with 4 threads and 32mb segment-size...\nAdded hashes from file ss23-fortinet-hashes.txt: 1 (1 salts)\nActivating quick-digest mode for single-hash with salt\n[s]tatus [p]ause [r]esume [b]ypass [q]uit =>\nvs\nroot@zx-keyscore:/opt/crack# /root/hashcat/hashcat --hash-type 7000 ss23-fortinet-hashes.txt -a 0 /opt/wordlists/ --force\nhashcat (v3.30-396-gd57b493) starting...\nADL_Overdrive6_TargetTemperatureData_Get(): -8\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Tonga, 3813/4005 MB allocatable, 32MCU\nDevice #2: Tonga, 3818/4045 MB allocatable, 32MCU\nDevice #3: Intel(R) Core(TM) i5-6600K CPU @ 3.50GHz, skipped\n\nHashfile 'ss23-fortinet-hashes.txt' on line 1 (AK1jmUeq[...]o2DiOM=): Hash-length exception\nParsing Hashes: 0/1 (0.00%)...No hashes loaded\n```\nAs you can see, this is using the exact same hash between both versions of hashcat, but the new implementation gives an error.\nI can confirm the hash length in both cases is 47 characters.. Works for me! Happy to have this closed once merged \ud83d\udc4d . ",
    "Explorer1092": "I am also concerned about this issue, legic card use is very extensive.\nThe realization of this algorithm, the rfid aspects of security have a great help. ",
    "phillycheeze": "I have a -r with a rule based list. The problem is with a dictionary and ruleset, I want hashcat to skip passwords less than 8 characters. This is because some combos of the rules with the plaintext passwords generate passwords less than 8 characters.\nSince I know the hash is at least 8 characters, there is no point in testing it. Maybe there is a way to run the rules against a dictionary and output every possible plaintext password?. Okay thanks for the feedback and help. My problem is actually the opposite. I want to not hash anything under 8 characters. . If i do that, it says it is an invalid rule. I tried >8 and '>8' on hashcat v3.4.\nWhen i use it with -j -k, it doesn't have any effect on the program. Maybe the documentation is out of date?. Is it always the case they are too slow? Currently I am running against bcrypt hashes with a cost factor of 10. That is why this rejection rule can really speed up my hashing time :). ",
    "mistermisschief": "but with the rule in place it creates a word that is 8 length in total as it adds 88 to the end of the word i.e momman88. so this means hashcat will only use 8 plus passwords to add rules too and not a smaller word that when ran with the rules is 8 or over in length?. ",
    "alphastar868": "@d2-d2 - many thanks for responding - was wondering if it was syntax related.\nDiscovered a few additional things:\n\nThis error occurs with every version after Hashcat 3.10 (i.e. 3.20 and up to the current Beta).\nHashcat doesn't yet work on $RAR3$*1* hashes, so I get the Line Length exception described here\n\nNeither of these explain the Permission denied error message under my specific circumstances.\nFWIW, my command was:\n.hashcat64.exe -a 6 -m 12500 --session=all -p * -o \"Output.txt\" --outfile-format=3 -w 2 --gpu-temp-abort=80 -1 ?h \"RARfile.hash\" \"dict1.dic\" ?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1?1. I should have clarified that point regarding FAT32.\nI actually started off with everything in a folder on the Desktop, i.e. hashcat\\hashcat-3.40 and hashcat\\HashcatGUI_050b1 - both on NTFS.\nWhen I saw the permissions issues, I tried to remedy by moving to a filesystem without additional filesystem security, then by changing the permissions on the folder(s).\nAs for re-testing, I used 7-Zip to extract all the files to C;\\Users\\\\<username>\\Downloads\\hashcat-test\\ (same folder structure as above) and then attempted the command above.  The output from the first run:\nhashcat (v3.40-38-gf651f44) starting...\n```\nhashcat (v3.40-38-gf651f44) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2048/8192 MB allocatable, 20MCU\n\ndocs: Permission denied\nStarted: Tue Mar 14 19:48:50 2017\nStopped: Tue Mar 14 19:49:02 2017\n```\nEven running from Downloads, the extracted folders all show as RO, although the individual files are not.  Any attempt to change them (and Apply to all folders, subfolders and files) results in the folders showing as RO the very next time (Right-click, Properties).\nAll subsequent runs give the following error:\n```\nhashcat (v3.40-38-gf651f44) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080, 2048/8192 MB allocatable, 20MCU\n\ncharsets: Permission denied\nStarted: Tue Mar 14 19:57:17 2017\nStopped: Tue Mar 14 19:57:17 2017\n```\n(It's always charset, for subsequent runs).. ",
    "Alexelroki": "Okay @roycewilliams, thanks for your quickly answer, I will post on that page.. ",
    "syntaxmonkey": "@philsmd - changes made as suggested.\nThe changes.txt appears to be committed changes based on version.  I'm not entirely clear how this change should be added.. ",
    "tankbusta": "The issue is that I may not know the contents of the potfile and/or the contents of a file that contains a list of 10 MD5's to crack. Some of them might exist in the potfile, all of them might, or none of them do. \nAs it works now I may have to run hashcat several times just to get my results. \nExample: hashcat_session_init, hashcat_session_execute, see that some hashes exist in potfile when my event callback gets EVENT_POTFILE_ALL_CRACKED, hashcat_session_destroy, hashcat_session_init, hashcat_session_execute (with show), .... You would still only be cracking the hashes that are not yet cracked and you would still be showing the hashes that were cracked whenever --show was used. The only change is that if show is specified AND there is still work to be done, that it continues with the cracking instead of just exiting.\nI guess I fail to see why --show has to be run independently. It seems a bit silly to have to start it twice. . I guess let me ask this then, is there a way I can pull the hash(s) out of hashcat/potfile if I get EVENT_POTFILE_ALL_CRACKED? (Maybe ctx->hashes?) . Nevermind, I figured out a way to do it by looking at potfile_handle_show. . I'll have a PR today that should remove this leak. I'm just waiting on some more test runs to complete. Awesome thanks! Just committed the changes you requested. . I'm not a fan of this name but willing to change it on suggestion. ",
    "sgerraty": "\nWhile sha1crypt may not currently be common, I anticipate that its use will in\ncrease. Since the only other options on JunOS appear to be descrypt and md5cry\npt, it is currently the strongest option on that platform.\n\nFWIW recent Junos supports more options including those found in recent\nFreeBSD.\n. On Thu, 23 Mar 2017 07:34:19 -0700, Royce Williams writes:\n\nMinor edit: I added a few more 'hashcat' NetBSD examples, to demonstrate the s\npread of the iteration counts.\n\nYes, the number of iterations was semi-randomized to make dictionary\nattacks more expensive, goal was approximate 1s runtime.\n. ",
    "cipri-tom": "just to mention, for me this issue is gone if I run as root: sudo hashcat ... \nfrom here. ",
    "anandumdas": "I didn't have graphics card and had to use OpenCL for CPU alone. I solved the error as shown here https://youtu.be/AieYqNQ6ADM. ",
    "polonskiy": "\nDownload OpenCL\u2122 Runtime 16.1.2 for Intel\u00ae Core\u2122 and Intel\u00ae Xeon\u00ae Processors for Red Hat* and Ubuntu* Linux* (64-bit) from https://software.intel.com/en-us/articles/opencl-drivers#latest_CPU_runtime\nExtract\nsudo ./install.sh\nNext, ignore missing dependencies, finish. \n",
    "Puvipavan": "@polonskiy  Yup, It's working. . ",
    "jsonbruce": "@polonskiy Thanks.\nAnd the same time I installed the below packages to avoid Cannot find an OpenCL ICD loader library.:\nsudo apt install ocl-icd-libopencl1 ocl-icd-dev ocl-icd-opencl-dev. ",
    "nmxhc": "Thanks for your confimation. This is, what I already expected. \n\nUsing charsets/standard/German/ANYTHING didn't work.\n\nHowever, how can I work with something like\n./hashcat64.bin --potfile-disable -a 3 -m 0 -1 charsets/standard/German/de_ISO-8859-1.hcchr (HASH OF GERMAN \u00e4) ?1\nNone of the German charset-files with either ?1 or ?1?1 has cracked my string. . So how do I attack such a hash? Try to find out the encoding and then work with this encoding? Is there any way in hashcat to use UTF8 inbuilt / self-built charsets (files) as encoding, as that is probably what I'm looking for.. ",
    "tautology0": "Good idea; except that the only mention of a library is in the release notes for 3.20 and there's no documentation (that I can find from searching the wiki, the forum and github).\nSo should I raise a new issue asking for documentation of libhashcat?. Thanks; I've been working my way through pyhashcat this morning.. ",
    "mrpeppels": "Apologies, I wasnt too thorough:). ",
    "redbluebg": "I'm sorry\nThe actual command that I execute is that:\nhashcat64 -D 2 -a 6 -m 11300 wallet.hash.dos dictionary.dict.txt ?a?a?a\n\n. ",
    "XxoraxX": "If im using wordlist + rule attack on wpa2  i need to make the wordlist contain password with 8 length \nif the password is less then 8 will not be used in cracking hashcat will search in wordlist for password min-len 8 and use it to crack the handshake \nif i have password like (google) hachcat will not use it for cracking but i know that wpa/wpa2 use 8 length password so i want to use the rule to add for me the renaming length (exp : google?d?d?d?d google2017)\nbut its not working because when hashcat detect that the password less then 8 will ignore the pass and use password with 8 length .\n I tried to search for option in hashcat and online but i did not find .. ",
    "stealthsploit": "I saw the ether2hashcat note said it was considered deprecated and replaced by ethereum2john.\nThe ether2hashcat format shown above was $ethereum$s*n*r*p*salt*mac*ciphertext , however ethereum2john converts it to $ethereum$s*n*r*p*salt*ciphertext*mac.\nHashcat only cracks $ethereum$s*n*r*p*salt*ciphertext*mac for me and fails to crack $ethereum$s*n*r*p*salt*mac*ciphertext   (?)\nE.g. (password of P@ssw0rd1!)\n{\u201cciphertext\u201d:\u201d7f5c865554d67604394ae54d7a4f9735bdb85c90e606a672d18add1d167d793b\u201c,\n\u201ccipherparams\u201d:{\u201civ\u201d:\u201dae4e8c9c2ac201d6c2baa58ff670fd39\u2033},\n\u201ccipher\u201d:\u201daes-128-ctr\u201d,\n\u201ckdf\u201d:\u201dscrypt\u201d,\n\u201ckdfparams\u201d:{\u201cdklen\u201d:32,\u201dsalt\u201d:\u201d437964c9bd1b5f63bde56560808c894792f8f670694590b776e22381e32dd\n33b\u201c,\u201dn\u201d:1024,\u201dr\u201d:8,\u201dp\u201d:1},\n\u201cmac\u201d:\u201d96f2a849321cc04cb6c0fcee1bd4b195ca681ca28064dc45000f02e47230c5b6\u201c}}\nthrough ethereum2john gives (and successfully cracks):\n$ethereum$s*1024*8*1*437964c9bd1b5f63bde56560808c894792f8f670694590b776e22381e32dd33b*7f5c865554d67604394ae54d7a4f9735bdb85c90e606a672d18add1d167d793b*96f2a849321cc04cb6c0fcee1bd4b195ca681ca28064dc45000f02e47230c5b6\nIs there an ethereum2john post i've missed somewhere?\n. Hey jsetube,\nWith regards to the below,\nGPU's will not be able to crack this because of the memory requirement. Math behind: Mem per candidate: size_scrypt = (128 * scrypt_r) * scrypt_N = 256MB. But to make use of the GPU power, we need to spawn at least 1280 parallel computations, so we end up with a memory requirement of 320GB ram per GPU. It would require a minimum of a 256 divisions TMTO to get it working on a GTX1080, which drops the performance < 1 H/s.\nI've tried digging to find further math, but can't find any additional reading on why we have to spawn (at least) 1280 parallel computations for the total GPU memory requirement?\nThanks.. Thanks for the clarification :). ",
    "ZVitaliy": "Hello everyone!\nI'm trying to crack my wallet but hashcat saying me no hash in this text. \n$ethereum$s*1024*8*1*437964c9bd1b5f63bde56560808c894792f8f670694590b776e22381e32dd33b*7f5c865554d67604394ae54d7a4f9735bdb85c90e606a672d18add1d167d793b*96f2a849321cc04cb6c0fcee1bd4b195ca681ca28064dc45000f02e47230c5b6\nI trying both hashes for ethereum 15600 an 15700, using mask of my password but nothing. Maybe it's because my wallet file newest version not a json?\n. @jsteube is there a difference in the commands for Linux and Windows? I'm using Win10. And how to make hashcat using more than one video cards?. Thanks @philsmd it works. . ",
    "anormore": "Hi all, I'm a bit confused by this... \nI've got a presale wallet, which I have generated just fine. I'm running hashcat on my GTX 1080.\nHowever I'm trying a newer wallet (Mist 0.9.3) and it simply doesn't run on the GPU. If I switch to CPU I get the CL_OUT_OF_RESOURCES error. Would applying that regedit patch fix this and start cracking? \nI'm trying to solve the problem of the \"Special Characters Bug\" which I believe I just proved over at: https://github.com/ethereum/mist/issues/3513. Still waiting... @philsmd Is there some sort of easy to understand guide I can follow? Trying to get this running... Noobish level cracker here... . Perfect, thanks for the guide. I have it running now (no luck yet initially). You've provided a great resource for lost souls like myself.\nHOWEVER! I'd like to know if the PreSale wallet website screwed up the input. Let's say I entered Password123!\nA) My wallet is wrong because the Ethereum bug has incorrectly applied the input, making the entire .json wallet screwed anyway. The scenario being the input password script from their website was bugged entirely.\nB) The wallet data is fine, it's just the Mist / Geth client that is bugged and not importing. This would mean that other tools (Kraken import tool,etc) work just fine. It would mean that Hashcat will find the password. The fact Hashcat hasn't found my password means I really screwed it up.\nSo I can accept B as fate -- but without knowing the CAUSE of this Ethereum bug, we can't rule out option A, which means 'corrupt' wallet.json\nThoughts?. Howdy yall, I have un-covered the bug with Ethereum wallets and return characters here: https://github.com/ethereum/mist/issues/3513\n@Chick3nman Hey buddy, can you have a look at this? It seems absurd but it's repeatable 100%. Come on over and join the conversation if interested... ",
    "iczman": "Confirmed fixed. Thanks for the quick turnaround!. ",
    "zza123": "Why does the situatiom appear?Can you solve it? Please help me. How to use windows APIs?I am greenhand.... ",
    "liyuefeng": "com here everyone. ",
    "satmonkey": "No problem, see attached.\ntest_log.zip\ntest.zip\nThis is the dirty fix, which works for me:\n hashcat.c   2017-05-13 09:23:17.311735018 +0200\n--- hashcat.c.bak   2017-05-13 09:20:56.119833768 +0200\n**\n 357,363 ***\nif (straight_ctx->dicts_cnt)\n{\n\n!     for (u32 dicts_pos = straight_ctx->dicts_pos = 0; dicts_pos < straight_ctx->dicts_cnt; dicts_pos++)\n      {\n        straight_ctx->dicts_pos = dicts_pos;\n--- 357,363 ----\nif (straight_ctx->dicts_cnt)\n{\n\n!     for (u32 dicts_pos = straight_ctx->dicts_pos; dicts_pos < straight_ctx->dicts_cnt; dicts_pos++)\n      {\n        straight_ctx->dicts_pos = dicts_pos;\n. The particular command for the test you asked for:\n./hashcat64.bin.ori -m 400 wp_400_002.hash -a6 ../wordlist/test masks/monkey-16.hcmask\nI expect all wordlists in the folder (../wordlists/test) will be combined with all masks in the file monkey-16.hcmask. In other words, the hcmask file will be applied to every file in that folder.\nAnd the actual behaviour I described initially. In addition, see the log what is happening.. ",
    "smarek": "Thank you, well according to this Debian bug-report https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=819990\nThe solution would be to fallback dlopen libnvidia-ml.so.1, see for reference BOINC project https://github.com/BOINC/boinc/pull/1522/files\nBut that still feels a bit like a workaround for existing problem, you decide please @jsteube . This would also match the naming of library here: /usr/lib/x86_64-linux-gnu/libnvidia-ml.so.1, which path should be the in LD_LIBRARY_PATH\nSo maybe we should, after all, try to load the .so.1 variant first or as a fallback?. ",
    "deepubhullar": "where i can download compiled long password branch for windows operating\nsystem?\nOn Sun, May 21, 2017 at 4:38 PM, Jens Steube notifications@github.com\nwrote:\n\nSorry, I don't want to merge this experimental code with master yet\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-302929925, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AaO6ech_-3o5U11ToyMBmTzXgpFeygE6ks5r8BshgaJpZM4NhhQ6\n.\n. please compile long password branch for windows for me.\nThank You.\n\nOn Sat, May 27, 2017 at 1:25 PM, Jens Steube notifications@github.com\nwrote:\n\nThere's\u200b no such Thing\nAm 27.05.2017 06:21 schrieb \"deepubhullar\" notifications@github.com:\n\nwhere i can download compiled long password branch for windows operating\nsystem?\nOn Sun, May 21, 2017 at 4:38 PM, Jens Steube notifications@github.com\nwrote:\n\nSorry, I don't want to merge this experimental code with master yet\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-302929925,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AaO6ech_-\n3o5U11ToyMBmTzXgpFeygE6ks5r8BshgaJpZM4NhhQ6\n.\n\n\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-304426409,\nor mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AJ83OV6ZRacCLrpDj_\ndiqye3xoieq8Qzks5r96S8gaJpZM4NhhQ6\n.\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/pull/1259#issuecomment-304436126, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AaO6edxHsD1Ppn7LlMAH765tdQkqxqHQks5r99bigaJpZM4NhhQ6\n.\n. i know you created file inc_hash_sha512.cl for long password please provide me that for long passwords.\nthank you.. \n",
    "ouguanxiaosilang": "Anyway thanks. I have solved this problem by installing the win-iconv and  patching the Makefile. @jsteube . ",
    "FalseProfit": "I understand what you're saying, but just because the dictionary word is less than 8 characters does not mean the final product after applying the rule is.\nAfter talking with some coworkers, it looks like the issue may actually be with the way aircrack creates its hccap file. I'll have to find some free time to continue debugging this but will update when I get a moment.\nThis is the forum post in particular that a coworker directed my attention to: https://hashcat.net/forum/thread-6273.html \nThanks.. ",
    "deadash": "but the 1 is the file of password. I've tested the software on 2 different computers, it worked on one PC but failed on the other (which is amd). I'll perform the drive test later.Perhaps the self-test should be added, in this situation, it will present run-time failures likejohn the ripper other than exhausted. I've also ran the other ones like office2007, office2010,etc. they all worked normally. . I noticed there is a self-test functionality in the newest version, which is really exciting. I'm gonna do more tests on my computer to find where the problem is.. ",
    "maykelbembibre": "I confirm that the same hash of office 2013 gets cracked on my machine with Nvidia graphics card but finishes as exhausted in my other machine with AMD graphics card. It's not a drivers issue in the second machine because on it I have tested a lot of other algorithms and all of them have cracked successfully. So, in a nutshell:\n- In Nvidia all algorithms I've tested do crack the hash.\n- In AMD all algorithms I've tested do crack the hash except for office 2013.\nIt seems like there is a sort of problem when we combine specifically the algorithm for office 2013 and AMD hardware environments.. ",
    "shaunwarman": "Looks good, sorry about that. ",
    "Giampetterson": "I'm really interested in this !! Hashcat works perfectly with wallet but for pre-sale wallet at the time there's no distributable solution across GPU, so if you have 24/25 char password using CPU can be tricky :-). ",
    "ChristianPapathanasiou": "This is sorely required.... Still waiting as well.... I\u2019m sure folks can even fund development of this based on cracked wallets ... \nSent from my iPhone\n\nOn 13 Dec 2017, at 10:09, Nicola Greco notifications@github.com wrote:\nplease@!\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Awesome does this mean that it will be included shortly in the main branch as part of the binary?\n\nSent from my iPhone\n\nOn 14 Dec 2017, at 17:54, philsmd notifications@github.com wrote:\nI must admit that I was quite unmotivated when I saw this issue for the first time because I saw that the algorithm description by the OP uses genwallet (), privtopub () and therefore I thought about Elliptic-curves cryptography and whatnot.\nNow I just gave it another glance and it seems that all of this is not needed at all. The algorithm is very easy.\nsha3 (aes_256_cbc_decrypt (pbkdf2 ($pass, $pass, 2000), $iv, $encseed))\nSo basically we just extract the first 16 bytes (0-15) from the \"encseed\" field which we use as the initialization vector for iv, the remaining bytes (starting from byte 16) we use as the encrypted seed.\nThe key for the AES-256-CBC decrytion is generated by using the user password as salt AND pass and use 2000 iterations of pbkdf2-hmac-sha256.\nThe final hash is just a sha3/keccak hash of the seed (the decrypted encseed from the AES decrytion mentioned above).\nTherefore the code is basically just this:\n!/usr/bin/env perl\nAuthor: philsmd (for hashcat)\nDate: dec 2017\nLicense: CC0 (public domain)\nuse strict;\nuse warnings;\nuse Crypt::PBKDF2;\nuse Crypt::CBC;\nuse Digest::Keccak qw (keccak_256);\n\nAlgorithm can be found in: https://github.com/tagawa/website/blob/f784ca60be00ddd6fab9418307cb74289822f1eb/pyethtool/pyethtool.py#L53 (attention: the pbkdf2 settings are different, also the salt for pbkdf is different)\n\nAn example can be found here: https://github.com/hashcat/hashcat/issues/1279\n\nExample 1: (password is \"password\", without quotes):\n$ethereum$w0b2fa2c63a8b5603e1104fbada15a609aa9736ed41db1678d91a9b1a1f7c1628e711dbc250c4c289b06b0faa56cd499dc4af9daf878202db22cc61df1a91c918314c77ce92e5c8b1265580edd79a852acf40fe2138653ac16524c08247381d9802cf5ef3f8c4baf69fb869f2b7fb796bae853cfbdc3c5b788a14e75f39e0cf7df2e90779181a5dd45cce8e8df938af3c6b6c8a92ce123338e6ed87eb16ff11a02cd4a2a07aff8a3a57097fcf137501e07a941a7ce9bc19498252d98769125fbd2c9a14f1c56212a6bf2a7e374474c60e7a3a1cf443ce8194c4c960474472d6ca761ada075169fa8c7017bf1274b99df898deb65f51ed8eb29fbc0997d69c9800ad9b8351155bec5d8e7f73e7e2882a6e1b62883d0158c44fed8e4412fb18e75757e1355aaadd8a2dab50ae40c800d032dc77d3e84904085d628b5a13b60317d6f12ede26b7b38e7c6805bea1d2e11e3a7d7153b76ebfd99ae2536dfdd071ff8111a86fbd63e7b17155162263ef45471ac5b4c517520572cd19410cc4cbde77914fad12326fe5a4cbd5fc4a297740d6b5e64001196b0531e2464b7e4cee77136a38844b94dc59a9a72eec3ff49bca3d5bf0c29652ee6ff028e22f8936aac58fa3cf05ce4c8de8883204e43b57e4ebed922ad7b3a8953042033d34d7e94bc8ff393d1df4c8b062f5228b4f9dbc5d157af96772af1ef2c84f6562049b1c44f0359c07f193623a8b0f1b7e34b31481ddf54a24128e5a21b929f57fd07f8911ad8eb8d8bfe928ae9dfa2d35663764161094552a43b43a0a43dca687d4d04b79c8dbb2d4f87b7d8e0805a77adddfd5149741faa594009639fb730dccfbee1f99286aaf94052c06a1c68efc29dcd57a8b1a421ef9438b7121a15fd127ec0d8a72ee2b3e8da04a5a*74fdb879ece341dd590a769f2cd39d67\n\nmy $iv_and_encseed = pack (\"H*\", \"0b2fa2c63a8b5603e1104fbada15a609aa9736ed41db1678d91a9b1a1f7c1628e711dbc250c4c289b06b0faa56cd499dc4af9daf878202db22cc61df1a91c918314c77ce92e5c8b1265580edd79a852acf40fe2138653ac16524c08247381d9802cf5ef3f8c4baf69fb869f2b7fb796bae853cfbdc3c5b788a14e75f39e0cf7df2e90779181a5dd45cce8e8df938af3c6b6c8a92ce123338e6ed87eb16ff11a02cd4a2a07aff8a3a57097fcf137501e07a941a7ce9bc19498252d98769125fbd2c9a14f1c56212a6bf2a7e374474c60e7a3a1cf443ce8194c4c960474472d6ca761ada075169fa8c7017bf1274b99df898deb65f51ed8eb29fbc0997d69c9800ad9b8351155bec5d8e7f73e7e2882a6e1b62883d0158c44fed8e4412fb18e75757e1355aaadd8a2dab50ae40c800d032dc77d3e84904085d628b5a13b60317d6f12ede26b7b38e7c6805bea1d2e11e3a7d7153b76ebfd99ae2536dfdd071ff8111a86fbd63e7b17155162263ef45471ac5b4c517520572cd19410cc4cbde77914fad12326fe5a4cbd5fc4a297740d6b5e64001196b0531e2464b7e4cee77136a38844b94dc59a9a72eec3ff49bca3d5bf0c29652ee6ff028e22f8936aac58fa3cf05ce4c8de8883204e43b57e4ebed922ad7b3a8953042033d34d7e94bc8ff393d1df4c8b062f5228b4f9dbc5d157af96772af1ef2c84f6562049b1c44f0359c07f193623a8b0f1b7e34b31481ddf54a24128e5a21b929f57fd07f8911ad8eb8d8bfe928ae9dfa2d35663764161094552a43b43a0a43dca687d4d04b79c8dbb2d4f87b7d8e0805a77adddfd5149741faa594009639fb730dccfbee1f99286aaf94052c06a1c68efc29dcd57a8b1a421e\");\nmy $bkp = pack (\"H*\", \"74fdb879ece341dd590a769f2cd39d67\");\n\nStart:\n\nget the initialization vector for AES-256-CBC from the \"encseed\" field:\nmy $iv = substr ($iv_and_encseed, 0, 16);\nget the raw encrypted seed (encseed):\nmy $encseed = substr ($iv_and_encseed, 16);\nsetup pbkdf2 params:\nmy $pbkdf2 = Crypt::PBKDF2->new\n(\n  hasher     => Crypt::PBKDF2->hasher_from_algorithm ('HMACSHA2', 256),\n  iterations => 2000,\n  output_len => 16\n);\nmain loop:\nwhile (my $pass = <>)\n{\n  chomp ($pass);\nmy $key = $pbkdf2->PBKDF2 ($pass, $pass);\nmy $aes_cbc = Crypt::CBC->new ({\n    key         => $key,\n    cipher      => \"Crypt::Rijndael\",\n    iv          => $iv,\n    literal_key => 1,\n    header      => \"none\",\n    keysize     => 16\n  });\nmy $seed = $aes_cbc->decrypt ($encseed);\nmy $hash = keccak_256 ($seed. \"\\x02\");\nif (substr ($hash, 0, 16) eq $bkp)\n  {\n    print \"Password found: '$pass'\\n\";\nexit (0);\n\n}\n}\nexit (1);\nAs you can see the algorithm is basically the same as -m 15600 = Ethereum Wallet, PBKDF2-HMAC-SHA256 (I say the same as -m 15600 because also 15600 uses a large number of iteration of pbkdf2 and a final keccak hashing step)... except that at the init phase (the init kernel function) we need to decrypt the encseed field (with AES-256-CBC) to get the raw seed.\nI was suprised that this algorithm is actually so easy, because from the description above it seemed to me that much more was involved here... but as said it is basically just the same as -m 15600 (with an additional AES decrypt step and slightly different settings for pbkdf2).\nI think that this is really easy to add, not sure why nobody added it yet (maybe others were also confused about all this genwallet and pubtopriv stuff which is not used at all ... or it is just not that common to have these presale hashes anymore because they were just used for a very short time)\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "nicola": "please@!. ",
    "branmcf": "@philsmd First of all, thank you for the PR! I've seen this question asked numerous times on multiple sites with very few answers, so hopefully this helps out. I know for a fact that Ethereum wallet backup json files with the format below exist, but I cannot speak as to whether this format is standardized.\n{\n    \"bkp\": 64 chars,\n    \"btcaddr\": 34 chars, \n    \"email\": example@github.com, \n    \"encseed\": 1248 chars, \n    \"ethaddr\": 40 chars\n}. @anormore I'm in a similar boat and I definitely feel your pain. I have a document that's verifiably unchanged since the year of my ETH presale purchase (I, too, used the website) but Kraken nor MIst/geth has been able to decrypt my backup file and I haven't had any luck recovering the password with pyethrecover or hashcat.\nI've seen rumblings about special characters (e.g. !) causing issues but I've also seen updates to posts, months later, where people who were certain of their password actually had it wrong so it's still unclear to me whether or not this is user or programmer error. \nAnyways, I'm working on getting hashcat installed on an EC2 instance that could be used to scale my password cracking efforts, feel free to reach out if you want to use it!\n  . ",
    "lavanoid": "Do those arguments work even when resuming a .restore file?. --gpu-temp-disable doesn't work. I originally specified it when I ran hashcat and it never saved the argument in my .restore file. When specifying --gpu-temp-disable after --restore, hashcat still persists on controlling fan speed and it still seems to have temperature limits.. Considering that I originally specified --gpu-temp-disable and it wasn't put in the .restore, I think hashcat needs to be updated so that it does add the argument to the .restore. Perhaps also add an implementation where specifying arguments after --restore will become valid/recognized (to an extent).\nIf a user wants to change a setting, then it's tedious to have to edit the restore file, with the risk of it breaking.. ",
    "SandraK82": "It is used in a closed medical appliance, an insulin delivery pump. The pump uses different hard coded passwords to authenticate different application layers to access the pump functions. \nWe need to get one of the passwords as we want to be able to use the pump in a so called closed loop system. \nOne layer we can access as the configuration software uses this (known) password to program different settings on the pump.. the password is 16 bytes, 8 bytes per side, the resulting hash is 16 bytes, the salt is 28 bytes\n```\nsalt = \"service pwd\" + \"56D59E656ABDC651294AB2AFBBF21E0E\".decode('hex')\nchallenge_response = \"07932f496a777a880b927b85b5b267a9\".decode('hex')\n(r1, r2) = evenHalveString(\"u+5Fhz6Gw4j1Kkas\")\nm1 = md5Khmac(r1, salt, 16)\ns1 = sha1Khmac(r2, salt, 16)\norig_result=stringXOR(m1, s1)\nassert(orig_result == challenge_response)\n```\nfor the functions please look at: https://github.com/jamorham/SightProxy/blob/master/lib/cryptograph.py#L75L79. It seems to be always 16bytes\nVon meinem iPhone gesendet\n\nAm 24.06.2017 um 10:52 schrieb Jens Steube notifications@github.com:\nIs the password always of length 16? I mean exactly 16? What if it password is length 15, does it need to be padded and if yes, which byte is used for padding?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "savek-cc": "Looking at the known pw, it seems to be 16 chars from [a-z][A-Z][0-9] and probably a couple of [,.-+?/()%&...] - so we have 26+26+10+10= 72 possibilities per char.\nWith 8 chars, this leaves us with 72^8 or ~2^50 16 byte storage space for the pre-computed side (slightly >5 PiB).. Using a-z, A-Z, 0-9, as well as the following symbols: !\"$%&/()=<>+#',;.:-_\nWe would have 83 possibilities per char --> 16 EiB. While this is a whole lot more doable than a brute-force of a 16 char pw, it's still ambitious.. As described in https://github.com/hashcat/hashcat/issues/1283#issuecomment-310754000 ?. Well - yes - basically that is just an ordering of the \"passwords\" to take a fixed value for the upper 8 bytes and then iterate through the full lower 8 bytes. It's the same as proposed by @jsteube though - only that he would test against 10-50 mil \"upper bytes\" with one loop through all lower halfes.. ",
    "TebbeUbben": "Yes, a collision would be a enough. It's just used to generate a password hash based on a given salt.. You should take a look at this: https://github.com/jamorham/SightProxy/blob/master/lib/cryptograph.py\nThis would be the method call for a service password we already know: multiHashXOR(\"u+5Fhz6Gw4j1Kkas\", \"service pwd\" + \"56D59E656ABDC651294AB2AFBBF21E0E\".decode('hex'), 16). Why does this not match?. Maybe we all can take different sets? (I have a GTX 1060, so I must take a smaller set, if this is possible.). I get this error when I try to run the patch:\n```\nInitialized device kernels and memory...* Device #1: ATTENTION! OpenCL kernel self-test failed.\nYour device driver installation is probably broken.\n```\nI already followed this guide: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions#i_may_have_the_wrong_driver_installed_what_should_i_do\n. But how can I run the patch without pressing R all the time?. My CPU RAM is completely full and the only message Hashcat displays is \"Sorting hashes...\"\nIs that normal? (I'm using about 13 Millionen hashes). ",
    "jamorham": "As the key gets split in half and then the resulting hashes are xor'd.. is it possible to treat one side of the password as a block of work and then iterate the other half of the password and compare with the xor of the challenge and the hash result from the \"block\" so that only, for example, the md5 component needs to be calculated rapidly while the sha1 component is only calculated once per \"block\" ?. @savek-cc @DoZ10 I don't think what I'm describing is a collision, I thought it was just a re-arrangement of the components. I'm not suggesting any pre-computation except that for each \"block\" of the iterations for half the key the other half of the key would be calculated. So that you only have to calculate one of the hmacs in a loop.. @jsteube A collision would be just fine if it can produce the challenge response for any challenge using this algorithm. If it passes that test that is all the \"key\" is needed for. But the second part of the challenge/salt will be different each time. I don't understand enough of what is discussed above to understand the distinction or how much the key-space gets reduced by looking for collisions. . @savek-cc that sounds about 10-50 million times faster than what I was suggesting.. @jsteube this is really great, thank you. ",
    "soxrok2212": "Speed on my R9 370X has also been halved, so @diegodieguex is not the only one. It's not my main rig so I don't really care for it but it would be nice to find a solution. IIRC, it was fine with hashcat 3.5.0.. Part of the problems seems to have come from Apple's drivers. On Sierra, I had ~33kH/s on Hashcat 3.40. Now on high sierra, I also tested on Hashcat 3.40 and maxed at ~13kH/s. 3.40 was unfortunately the newest release that I had saved a whole benchmark for. \nI wouldn't say it's completely a Hashcat issue just yet. \nThis was on the 2015 Retina model with an R9 M370X. . Some decent improvements on 10.13.3. AMD R9 M370X which was previously between 6 and 13KH/s IIRC.\nPlain benchmarks:\n```\n$ hashcat -m 2500 -b -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    18322 H/s (68.22ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nStarted: Sun Feb  4 12:57:31 2018\nStopped: Sun Feb  4 12:57:42 2018\n```\nWith -w 4:\n```\n$ hashcat -m 2500 -b -d 3 -w 4\nhashcat (v4.1.0) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--workload-profile=4\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    19438 H/s (259.88ms) @ Accel:128 Loops:64 Thr:256 Vec:1\nStarted: Sun Feb  4 12:57:55 2018\nStopped: Sun Feb  4 12:58:11 2018\n```\nAnything else you need, just ask. Also, plugging in the charger does nothing to improve performance, so they don't seem to be throttling on battery power.. @philsmd I was under the impression that @jsteube wanted us to test the new version...\n\nI've add some more code to change certain parameters, another shot in the dark, since I do not have access to that system and can not reproduce locally. Can you please pull master, recompile and retry again?. At commit https://github.com/hashcat/hashcat/commit/729c5f09bcd00c3a6e51387d152346c609525e9d:\n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v3.6.0-131-g729c5f09) starting in benchmark mode...\n\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#3.....:    18438 H/s (67.41ms)\nStarted: Mon Feb  5 09:21:19 2018\nStopped: Mon Feb  5 09:21:31 2018\n```\nI hopped, skipped, and jumped around in commits around that. The speed returns to normal in commits before https://github.com/hashcat/hashcat/commit/165380c454c80b3bcd428ba619a45893223585d0\nHere is a benchmark at this commit:\n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v3.6.0-49-g165380c4) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#3.....:    18451 H/s (67.41ms)\nStarted: Mon Feb  5 09:24:41 2018\nStopped: Mon Feb  5 09:24:53 2018\n```\nHere is a benchmark from https://github.com/hashcat/hashcat/commit/52c1e15f3f5b0f50c8ccce3b8b9c604941fe8a57 \n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v3.6.0-48-g52c1e15f) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#3.....:    34629 H/s (73.12ms)\nStarted: Mon Feb  5 09:23:10 2018\nStopped: Mon Feb  5 09:23:23 2018\n```\nIf you need -m 12000 benchmarks too or anything else, let me know.. Latest commits fixed the issues here and is actually a little faster than my v3.40 benchmark!\n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    34452 H/s (73.02ms) @ Accel:128 Loops:32 Thr:256 Vec:1\nStarted: Tue Feb 13 11:54:01 2018\nStopped: Tue Feb 13 11:54:25 2018\n. Speeds dropped back to what they were before.\n$ ./hashcat -b -m 2500 -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    17759 H/s (68.76ms) @ Accel:64 Loops:32 Thr:256 Vec:1\nStarted: Wed Feb 14 10:35:38 2018\nStopped: Wed Feb 14 10:35:50 2018\n. Same result:\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    17773 H/s (68.76ms) @ Accel:64 Loops:32 Thr:256 Vec:1\nStarted: Wed Feb 14 15:27:05 2018\nStopped: Wed Feb 14 15:27:17 2018\n. Got one new compiler warning in the self test:\nsrc/selftest.c:60:20: warning: passing 'char ' to parameter of type 'u8 ' (aka 'unsigned char ')\n      converts between pointers to integer types with different sign [-Wpointer-sign]\n        uppercase (pw_ptr, pw.pw_len);\n                   ^~~~~~\ninclude/convert.h:51:21: note: passing argument to parameter 'buf' here\nvoid uppercase (u8 buf, const size_t len);\n                    ^\n1 warning generated.\n```\nSpeed is back to normal:\n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    34508 H/s (73.02ms) @ Accel:128 Loops:32 Thr:256 Vec:1\nStarted: Wed Feb 21 10:11:13 2018\nStopped: Wed Feb 21 10:11:29 2018\n```\nCracking works:\n```\n$ ./hashcat -m 2500 -d 3 -a 3 hashcat.hccapx hashcat?s\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\nDevice #2: Iris Pro, skipped.\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Brute-Force\n* Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Temperature abort trigger disabled.\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \na895f7d62ccc3e892fa9e9f9146232c1:aef50f22801c:987bdcf9f950:8381533406003807685881523:hashcat!\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: WPA/WPA2\nHash.Target......: 8381533406003807685881523 (AP:ae:f5:0f:22:80:1c STA:98:7b:dc:f9:f9:50)\nTime.Started.....: Wed Feb 21 10:13:36 2018 (0 secs)\nTime.Estimated...: Wed Feb 21 10:13:36 2018 (0 secs)\nGuess.Mask.......: hashcat?s [8]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#3.....:      162 H/s (0.46ms) @ Accel:32 Loops:16 Thr:256 Vec:1\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 33/33 (100.00%)\nRejected.........: 0/33 (0.00%)\nRestore.Point....: 0/33 (0.00%)\nCandidates.#3....: hashcat! -> hashcat \nStarted: Wed Feb 21 10:13:33 2018\nStopped: Wed Feb 21 10:13:37 2018\n```. Same issue. \n```\n$ ./hashcat -m 2500 -b -d 3\nhashcat (v5.1.0-750-gba56f41d) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n/Users/macbook/hashcat/OpenCL/m02500-optimized.cl: Optimized OpenCL kernel requested but not needed - falling back to pure OpenCL kernel\nOpenCL Platform #1: Apple\n=========================\n Device #1: Intel(R) Core(TM) i7-4980HQ CPU @ 2.80GHz, skipped.\n Device #2: Iris Pro, skipped.\n* Device #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA-EAPOL-PBKDF2 (Iterations: 4095)\nSpeed.#3.........:    18588 H/s (67.91ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nStarted: Sun Mar 17 11:18:26 2019\nStopped: Sun Mar 17 11:19:21 2019\n```. Sorry to bring this back up, but it looks like SHA-384 is going to be used in WPA3. Mathy Vanhoef (discoverer of KRACK attacks) published this:\n\n\nIncreased Session Key Sizes\nFinally, the fourth improvement that WPA3 offers is increased key sizes. More specifically, they refer to the Commercial National Security Algorithms (CNSA) suite. This means WPA3 will support AES-GCM with 256-bit keys for encryption, and elliptic curve cryptography based 384-bit curves. Additionally, SHA384 of the SHA2 family will be used, and any employed RSA keys must be at least 3072 bits in size. All combined, this results in 192-bit security, because that's roughly the effective strength of 384-bit elliptic curves and SHA384.\n\n\nhttp://www.mathyvanhoef.com. ",
    "emwinkler": "Speed1:\n./hashcat -m 2500 -b\nhashcat (v3.6.0-48-g52c1e15f) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     5934 H/s (50.05ms)\nSpeed.Dev.#3.....:   213.9 kH/s (83.32ms)\nSpeed.Dev.#*.....:   219.9 kH/s\nStarted: Sat Feb  3 14:01:23 2018\nStopped: Sat Feb  3 14:01:51 2018\nSpeed2:\n./hashcat -m 2500 -b\nhashcat (v3.6.0-51-g56dc8ae3) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     5927 H/s (50.05ms)\nSpeed.Dev.#3.....:    62928 H/s (71.27ms)\nSpeed.Dev.#*.....:    68855 H/s\nStarted: Sat Feb  3 14:03:46 2018\nStopped: Sat Feb  3 14:04:32 2018\nMaster:\n./hashcat -m 2500 -b\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#2.....:     5924 H/s (53.25ms) @ Accel:128 Loops:32 Thr:8 Vec:1\nSpeed.Dev.#3.....:    59442 H/s (73.20ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nSpeed.Dev.#*.....:    65366 H/s\nStarted: Sat Feb  3 14:07:09 2018\nStopped: Sat Feb  3 14:08:08 2018\n. I would be glad to assist with issue.  I agree it looks like the same issue as #1497 as I was able to duplicate the benchmark speed drop discussed above.  Let me know how you want to proceed.. Test completed, but same poor benchmark as shown below.\nLast login: Sun Feb  4 13:53:15 2018 from ./hashcat -b -m 2500 -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    59540 H/s (72.54ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nStarted: Sun Feb  4 13:54:03 2018\nStopped: Sun Feb  4 13:54:19 2018\nCCUS-ADM-EWINKLER:hashcat ewinkler$ \n. Have you tried version 3.5.0?  I too am running MacOS High Sierra 10.13.3, but with an AMD RX 580 in eGPU on a Macbook Air.  I see terrible benchmarks with v4.0.1 as seen below.\nhashcat-3.5.0 results:\n./hashcat -m 2500 -w 3 -b -d 3\nhashcat () starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#3.....:   214.1 kH/s (83.32ms)\nhashcat-4.0.1 results:\n./hashcat -m 2500 -w 3 -b -d 3\nhashcat (v4.0.1) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--workload-profile=3\n\nHashmode: 2500 - WPA/WPA2\nSpeed.Dev.#3.....:    59432 H/s (72.00ms)\n. I will test later and let you know.  I do know that it only occurs with hashmode 2500.  All others benchmark equally or better with 4.0.1.. Same result with latest version 4.1.0.  I :\n./hashcat -b -m 2500 -d 3\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    58793 H/s (72.83ms)\nStarted: Fri Feb  2 14:52:50 2018\nStopped: Fri Feb  2 14:53:07 2018\nI went back and tested old versions of hashcat I had and the issue starts in all 4.0 versions I have.  3.6 versions have no issue as shown below:\n./hashcat -b -m 2500 -d 3\nhashcat (v3.6.0-3-ge87fb31d) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#3.....:   201.4 kH/s (83.16ms)\nStarted: Fri Feb  2 15:05:56 2018\nStopped: Fri Feb  2 15:06:03 2018\n. Same result.\n./hashcat -b -m 2500 -d 3   \nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, skipped.\nDevice #3: AMD Radeon RX 580 Compute Engine, 2048/8192 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    76867 H/s (54.31ms) @ Accel:1024 Loops:8 Thr:64 Vec:1\nStarted: Sat Feb  3 11:05:38 2018\nStopped: Sat Feb  3 11:06:03 2018 \n. Whatever you changed fixed the benchmark speed for my AMD Radeon RX 580:\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:   213.6 kH/s (85.01ms) @ Accel:128 Loops:64 Thr:256 Vec:1\n. The change you made breaks the benchmark speed for my AMD Radeon RX 580.  It is slow again:\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    62451 H/s (72.57ms) @ Accel:64 Loops:32 Thr:256 Vec:1. No change.  Still the slow benchmark.\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#3.....:    62638 H/s (72.42ms) @ Accel:64 Loops:32 Thr:256 Vec:1\n. Running on the same hardware after booting into Ubuntu 16.04, I get normal benchmarks with the RX 580.  Looks to be a macOS driver issue as you suggest.\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\n\nOpenCL Platform #2: Advanced Micro Devices, Inc.\n\nDevice #2: Ellesmere, 4048/6472 MB allocatable, 36MCU\n\nBenchmark relevant options:\n\n--opencl-devices=2\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nSpeed.Dev.#2.....:   212.3 kH/s (85.51ms) @ Accel:128 Loops:64 Thr:256 Vec:1. Using -O solved the problem.. Please provide details on MacOS version and hardware you are using.  Both the 4.10 master and latest github pull work just fine with your test for me on 2013 Macbook Air, MacOS 10.13.4, RX 580.. -D 1 does not work.  -D 2 works with no driver warning.\n-D 1 Output:\n./hashcat -b -m 2501 -d 1\nhashcat (v5.1.0-42-g471a8ccc) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nNo devices found/left.\nStarted: Mon Jan  7 10:16:12 2019\nStopped: Mon Jan  7 10:16:12 2019\n-D2 Output:\n/hashcat -b -m 2501 -d 2\nhashcat (v5.1.0-42-g471a8ccc) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\nDevice #2: HD Graphics 5000, 384/1536 MB allocatable, 40MCU\nDevice #3: AMD Radeon RX Vega 64 Compute Engine, skipped.\n\nBenchmark relevant options:\n\n--opencl-devices=2\n--optimized-kernel-enable\n\nHashmode: 2501 - WPA-EAPOL-PMK (Iterations: 1)\nSpeed.#2.........:  5293.0 kH/s (0.22ms) @ Accel:32 Loops:1 Thr:512 Vec:1\nStarted: Mon Jan  7 10:17:21 2019\nStopped: Mon Jan  7 10:17:24 2019\n. Sorry for the confusion.  The -D 1 option does work fine, so it is a driver issue.  As Apple is no longer supporting OpenCL with their move to Metal, I don't suspect to get the driver bug fixed.  I can run hashcat on Ubuntu linux for now.  Thanks for your help.. yes, this issue can be closed.  I confirm it is a driver bug.. I did a clean \"git clone\" of the latest source.  Still getting the error with the RX Vega64, but faster benchmark.\n./hashcat -b -m 2501 -d 3\nhashcat (v5.1.0-656-g8d6a69b2) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n/Users/emwinkler/Desktop/hashcat/OpenCL/m02501-optimized.cl: Optimized OpenCL kernel requested but not needed - falling back to pure OpenCL kernel\nOpenCL Platform #1: Apple\n=========================\n Device #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\n Device #2: HD Graphics 5000, skipped.\n* Device #3: AMD Radeon RX Vega 64 Compute Engine, 2044/8176 MB allocatable, 64MCU\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2501 - WPA-EAPOL-PMK (Iterations: 0)\n\nDevice #3: ATTENTION! OpenCL kernel self-test failed.\n\nYour device driver installation is probably broken.\nSee also: https://hashcat.net/faq/wrongdriver\nSpeed.#3.........:   174.3 MH/s (0.00ms) @ Accel:512 Loops:1024 Thr:64 Vec:1\nStarted: Mon Mar  4 08:28:47 2019\nStopped: Mon Mar  4 08:28:59 2019\n. Still the same issue.\n./hashcat -b -m 2501 -d 3\nhashcat (v5.1.0-718-g6e0ef698) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n/Users/emwinkler/Desktop/hashcat/OpenCL/m02501-optimized.cl: Optimized OpenCL kernel requested but not needed - falling back to pure OpenCL kernel\nOpenCL Platform #1: Apple\n=========================\n Device #1: Intel(R) Core(TM) i7-4650U CPU @ 1.70GHz, skipped.\n Device #2: HD Graphics 5000, skipped.\n* Device #3: AMD Radeon RX Vega 64 Compute Engine, 2044/8176 MB allocatable, 64MCU\nBenchmark relevant options:\n\n--opencl-devices=3\n--optimized-kernel-enable\n\nHashmode: 2501 - WPA-EAPOL-PMK (Iterations: 0)\n\nDevice #3: ATTENTION! OpenCL kernel self-test failed.\n\nYour device driver installation is probably broken.\nSee also: https://hashcat.net/faq/wrongdriver\nSpeed.#3.........:  9334.9 kH/s (0.00ms) @ Accel:512 Loops:1024 Thr:64 Vec:1\nStarted: Mon Mar 11 09:51:40 2019\nStopped: Mon Mar 11 09:51:43 2019\n. I just tested the latest compiled version on a very similar core i9 based MacBookPro (It has Radeon 555X instead of the Vega 20) and it worked just fine with the 555X, Intel UHD and a Vega64 eGPU.  Please share the output of ./hashcat -I.. ",
    "extended11": "Hi @philsmd ,\nI just tried to again with beta 3.6.0+305, and the issue seems to be gone. Thanks! . A note on the validity of '$' in the salt. While the crypt(3) man page states: \"salt is a two-character string chosen from the set [a-zA-Z0-9./].\", apparently some real-world systems do seem to use the '$' character in the salt. I just confirmed that hashcat is able to crack hashes with a '1$' salt.\nSo I guess allowing '$' in the salt is debatable. But regardless, the corruption should not happen. . @roycewilliams Good question, I actually don't know. I concluded that from the fact that in thedescrypt hash collection I'm working on there's a couple of hashes starting with '1$' and they can be cracked with -m 1500. So that means, some software has generated them at some point in the past. However this hash collection is over 20 years old (obviously, as I hope no one uses descrypt any more) and it does not contain any contextual information about the origin of the hashes or the software that was used to generate them.. This can explain the '$' in the salts:\nhttp://www.openwall.com/lists/oss-security/2011/11/15/5\nSeems like multiple BSD (Free, Open, DragonFly, Net) variants used to have crypt.c implementations that (silently) converted invalid chars in the salt to a '.' char when crypt()ing.\nAlso, here is an online implementation (in js, based on crypt.c from OpenBSD from 2003) that will accept invalid chars: https://unix4lyfe.org/crypt/. ",
    "ccakgunduz": "I didn't run root specifically for the hashcat. In parallel I needed to be root some other stuff and I just basically  didn't use the sudo for every command. Just run with root.. Interesting. I've just tried to run it with unprivileged mode and it works. @Hydraze thank you for your btw question, lol.. By the way I've check one of my friend who has upper version of MacBook Pro. So all device type in his MacBook is one level up than mine. He can successfully run hashcat as a root. So as I said, interesting.. I use the github version of hashcat.  I just followed the instructions on Build.md neither more nor less. So I'm not sure that it is my problem or something else.. There is another funny thing. Yesterday I almost tried 10 times for running ./hashcat --benchmark as a root and every time it gave inc_vendor.cl file not found error. After you said  \n\nwhy are you using hashcat as root?\n\n, I ran hashcat as root first and got the same error. Then I ran it as a normal user and it worked perfectly. \nThe funny stuff is I've just run the hashcat as root and there is no problem right now. It works with root user too.. ",
    "enilfodne": "Off-topic, but I'm wondering why is Ryzen detected as Intel Platform in your logs?\nOpenCL Platform #1: Intel(R) Corporation\n========================================\n* Device #1: AMD Ryzen 7 1700 Eight-Core Processor, 4014/16057 MB allocatable, 16MCU\n. ",
    "ckuethe": "Thanks for the useful feedback - that's exactly what I was looking for.. I haven't had much time to work on the opencl bits this week. Other stuff at work... \n. ACK. I still haven't got the OCL working, but I haven't forgotten.. ACK. ACK. ",
    "rockygsm": "Hello\nalgo is private i can share via email to you. if u can send me your email ? \nits 8 digit number sha256 its update with uniq id of 0xc byte and loop update for min 1048 also it have custom sha2update which use if data is not 0x20 then its xor with F0 first byte.\ni have try to add u on google hangout if possible we can talk private ?\n. its ok thanks for look.. as from all search and reading i found valid method and way to use hash for my task.\nhashcat64 -m 10900 -a 3 -w 3 --hex-salt sha256:5000:DBE4ECEF10CED715D83F4F8BE938BE3DFEAB1DB7CB57DD16514E5623BBFB2F0B:239AC14998913570FC0F2E25001CB6F5 ?d?d?d?d?d?d?d?d\ni get error\n`Parameter hex-salt not valid for hash-type 10900\nUnknown hash-type '10900' selected.`\nif i remove --hex-salt it work but never find correct hash.. answer of this hash is 00000000 for testing.\nafter 40 sec or more i recieve such error \nDriver temperature threshold met on GPU #1. Expect reduced performance.\nDriver temperature threshold met on GPU #1. Expect reduced performance.\nDriver temperature threshold met on GPU #1. Expect reduced performance.\nDriver temperature threshold met on GPU #1. Expect reduced performance.\nDriver temperature threshold met on GPU #1. Expect reduced performance.\nDriver temperature threshold met on GPU #1. Expect reduced performance.\nmy device details \n`OpenCL Platform #1: NVIDIA Corporation\n======================================\n* Device #1: GeForce GTX 1080 Ti, 2816/11264 MB allocatable, 28MCU\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz, skipped.\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates`\nnote i am using hashcat (v4.1.0) . ",
    "cobbr": "@jsteube Apologize for missing your followup question. I found a file named \"CPUU.ini\" in a fileshare, appears to be related to Dell's Client Profile Updating Utility: http://support-public.cfm.software.dell.com/12314_clientprofileupdatingutility_5.5_administratorguide.pdf\nIn my experience, it was a high value domain account hash stored in this file. Unfortunately don't have much more info than that.. ",
    "dandv": "Thanks! The rest is just typos:\n\nThat is useful if you want to do Hybrid attack in hashcat. All you need it to add the \u201c-r bf.rule\u201d.\n\n->\n\nThe generated rule file can be used to perform Hybrid attacks with hashcat. All you need is to pass the rule file to hashcat via -r bf.rule.. @philsmd Fair enough, but I think that breaks the usage pattern listed by --help.\n\nAnyway, running ./hc -a 0 -m 6211 -r bug.rule words.dic --stdout produces simplePass, which doesn't crack the archive.. @jsteube: No dice, I'm afraid:\n```text\n$ hashcat-3.6.0/hc -a 0 -m 6211 -r bug.rule sample.tc words.dic\nhashcat (v3.6.0-351-gec874c1) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i5-5200U CPU @ 2.20GHz, 3988/15954 MB allocatable, 4MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nWatchdog: Temperature retain trigger disabled.\nDictionary cache built:\n Filename..: words.dic\n Passwords.: 1\n Bytes.....: 10\n Keyspace..: 1\n* Runtime...: 0 secs\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \nSession..........: hashcat                              \nStatus...........: Exhausted\nHash.Type........: TrueCrypt PBKDF2-HMAC-RIPEMD160 + XTS 512 bit\nHash.Target......: sample.tc\nTime.Started.....: Wed Aug 16 02:41:24 2017 (0 secs)\nTime.Estimated...: Wed Aug 16 02:41:24 2017 (0 secs)\nGuess.Base.......: File (words.dic)\nGuess.Mod........: Rules (bug.rule)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (0.16ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 1/1 (100.00%)\nRejected.........: 0/1 (0.00%)\nRestore.Point....: 1/1 (100.00%)\nCandidates.#1....: \ufeffsimplePass -> \ufeffsimplePass\nHWMon.Dev.#1.....: N/A\nStarted: Wed Aug 16 02:41:17 2017\nStopped: Wed Aug 16 02:41:25 2017\n```\nHere's the TrueCrypt file sample.tc.. Gah. Turns out words.dic started with an invisible BOM (thanks for posting the md5sums).\n\nI don't presume hashcat is supposed to handle BOMs. My apologies for the false alarm.\n. ",
    "m33x": "Maybe some cool ASCII art can help fix the problem?\nBTW: +1. ",
    "joeyhub": "It's the latest from the website (3.6.0). Using putty to connect to Ubuntu 16 (latest LTS). The good news is that it's running and you can work around with --status to at least get some output about how long it will take, progress, etc.\nI don't see hashcat using any special library for input, it's just stdin and standard fd handling procedures. However the code does look quite complex as input processing goes.\nI would guess that something is either screwing with stdin or denying the mutex to the terminal thread.\nI have AMD and Intel both using the latest opencl drivers. In theory none of those should be touching stdin and are most likely touching the mutex. On the other hand you should be able to wget the AMD drivers without having to set a referrer and Intel should provide deb packages for their drivers but don't, both should be providing a repo and AMD should be providing support for ubuntu 17. Essentially all bets are off when it comes to expecting that those drivers might not do things like touch stdin.. ./hashcat64.bin -m14600 -a3 /dev/luksdev ?d?d?d?d?d?d?d\nI can't give you the file but you can easily dd zero to something like a 100MB file, cryptsetup luksFormat on it. You don't need to mount it and mkfs as normal since it's not testing cracking, the problem should present as it is exhausting..      ii  intel-opencl                                  0r5.0-63504                                  amd64\n     ii  libopencl1-amdgpu-pro:amd64                   17.30-465504\nIt very well could be that, which would mean most likely the driver is doing something around the context or stdin. I'll see if I can reproduce it after my current test has run.\nIt happens without putty as well.. It's definitely the intel drivers doing it.. ",
    "kureeoffsec": "Hashcat Version: v3.6.0-456-g6d112aeb\nBuilt following instructions for OSX on https://github.com/hashcat/hashcat/blob/master/BUILD.md\nDevice #3: AMD Radeon R9 M370X Compute Engine, 512/2048 MB allocatable, 10MCU\nhashcat/hashcat -a 0 -m 1000 -r hashcat/rules/best64.rule testNtlmHash.txt hashcatTestPass.txt --potfile-path testNtlmHash.pot -d 3\nI know that I can crack the password with JohnTheRipper, and that in order to properly compile JTR on OSX, I need to point to homebrew's version of openssl as you can see in the bottom of the info section. \n$brew info openssl\nopenssl: stable 1.0.2l (bottled) [keg-only]\nSSL/TLS cryptography library\nhttps://openssl.org/\n/usr/local/Cellar/openssl/1.0.2l (1,709 files, 12.2MB)\n  Poured from bottle on 2017-08-29 at 19:10:34\nFrom: https://github.com/Homebrew/homebrew-core/blob/master/Formula/openssl.rb\n==> Dependencies\nBuild: makedepend \u2718\n==> Options\n--without-test\n    Skip build-time tests (not recommended)\n==> Caveats\nA CA file has been bootstrapped using certificates from the SystemRoots\nkeychain. To add additional certificates (e.g. the certificates added in\nthe System keychain), place .pem files in\n  /usr/local/etc/openssl/certs\nand run\n  /usr/local/opt/openssl/bin/c_rehash\nThis formula is keg-only, which means it was not symlinked into /usr/local,\nbecause Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries.\nIf you need to have this software first in your PATH run:\n  echo 'export PATH=\"/usr/local/opt/openssl/bin:$PATH\"' >> ~/.bash_profile\nFor compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/openssl/lib\n    CPPFLAGS: -I/usr/local/opt/openssl/include\nCould it be an issue with OSX's native installed libraries, and if so, how could I point the hashcat compiler at the homebrew installed libraries?. Code recompiled on 10.13.3 with the same hardware and up to date homebrew. Hashcat version is 4.1.0. Issue seems to be resolved. \nI am unsure which configurations changed, but the update to the new version of OSX seems to have resolved the issue. \nAwesome update in that version by the way!. ",
    "dylib": "@hubert3, @jsteube: I've tested hashcat 4.0 (built from source) on macOS 10.13 using the described method in issue #1350 and did not appear to encounter any problems:\n```\n$ hashcat -m 5600 example.hash example.wordlist -O                      \nhashcat (v4.0.0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Xeon(R) CPU E5-1650 v2 @ 3.50GHz, skipped.\nDevice #2: AMD Radeon HD - FirePro D700 Compute Engine, 1536/6144 MB allocatable, 32MCU\nDevice #3: AMD Radeon HD - FirePro D700 Compute Engine, 1536/6144 MB allocatable, 32MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Optimized-Kernel\n Zero-Byte\n Not-Iterated\n Single-Hash\n* Single-Salt\nPassword length minimum: 0\nPassword length maximum: 27\nWatchdog: Temperature abort trigger disabled.\nWatchdog: Temperature retain trigger disabled.\nDictionary cache built:\n Filename..: example.wordlist\n Passwords.: 4\n Bytes.....: 40\n Keyspace..: 4\n* Runtime...: 0 secs\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.           \nADMIN::N46iSNekpT:08ca45b7d7ea58ee:88dcbe4446168966a153a0064958dac6:5c7830315c7830310000000000000b45c67103d07d7b95acd12ffa11230e0000000052920b85f78d013c31cdb3b92f5d765c783030:hashcat\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: NetNTLMv2\nHash.Target......: ADMIN::N46iSNekpT:08ca45b7d7ea58ee:88dcbe4446168966...783030\nTime.Started.....: Wed Nov 22 11:43:41 2017 (0 secs)\nTime.Estimated...: Wed Nov 22 11:43:41 2017 (0 secs)\nGuess.Base.......: File (example.wordlist)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:        0 H/s (0.17ms)\nSpeed.Dev.#3.....:        0 H/s (0.00ms)\nSpeed.Dev.#*.....:        0 H/s\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 4/4 (100.00%)\nRejected.........: 0/4 (0.00%)\nRestore.Point....: 0/4 (0.00%)\nCandidates.#2....: hashcat -> hellopass\nCandidates.#3....: [Copying]\nStarted: Wed Nov 22 11:43:34 2017\nStopped: Wed Nov 22 11:43:43 2017\nSecond pass...\n$ hashcat -m 5600 example.hash example.wordlist -O\nhashcat (v4.0.0) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Xeon(R) CPU E5-1650 v2 @ 3.50GHz, skipped.\nDevice #2: AMD Radeon HD - FirePro D700 Compute Engine, 1536/6144 MB allocatable, 32MCU\nDevice #3: AMD Radeon HD - FirePro D700 Compute Engine, 1536/6144 MB allocatable, 32MCU\n\nINFO: All hashes found in potfile! Use --show to display them.\nStarted: Wed Nov 22 11:43:45 2017\nStopped: Wed Nov 22 11:43:46 2017\n``\nThe configuration is entirelyAMD`, however, seemingly no issues here.. ",
    "tampe125": "So it was a clear case of RTFM :)\nThanks for taking your time to explain it to me.. ",
    "jjruiz": "Nobody? It had implemented in hashcat-legacy (hash mode 3500): https://hashcat.net/wiki/doku.php?id=example_hashes#legacy_hash_types and then it was removed (I don't know the reasons).\nIs it possible to reuse that code? Although it works only with CPU, it's better that than none.... ",
    "Elycin": "Suggestion if I may, to make this a little more dynamic.\nHow about an iteration-loop flag? a flag that specifies how many times to hash the previous calculation?\neg: 5\nmd5(md5(md5(md5(md5($text))))). ",
    "Bobbymac99": "I have the same issue under Ubuntu.  I will try and gather basic info too.. Mine happened using a wordlist using Ubuntu 16.04.  Hashcat V3.6.0-462-g151dbc5, hash Truecrypt 6213, or one in that range.  It is actually on a large script so I would need to reassemble both the original script, and the multiple word lists I had concatenated together.  This was installed on one SSD drive, alone with the wordlist in the same directory, as I recall I had something like 26 million rejects when I looked at the status on it before terminating the script - since I was running it overnight\nIf you wish me to actually reproduce this - I can I think, but it will take a bit of work to do. Looking at the code I was wondering what that actual conditional statement says:  What are pws_cnt and kernel_power as related to each other?\nWORDLIST.C\n  if (device_param->pws_cnt < device_param->kernel_power)\n.....\n  else\n  {\n    fprintf (stderr, \"BUG pw_add()!!\\n\");\n    return;. ",
    "kootik": "\n16 \u0441\u0435\u043d\u0442. 2017 \u0433., \u0432 13:55, Jens Steube notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nI've pushed 34c5eac https://github.com/hashcat/hashcat/commit/34c5eac5500dc921e50c7e6b3efcd7055b38726f in order to fix this. Can you please retry with latest version and close the issue if fixed? I can't test myself as you did not append an example header to reproduce.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/1357#issuecomment-329961406, or mute the thread https://github.com/notifications/unsubscribe-auth/AGMqUKSqwxcJmqXDBFhmuP_GjAM7WqKEks5si6kZgaJpZM4PY1wK.\n\n\non Monday going to check  this issue and as i see you fix veracrypt_ keyfile does not use  i will all check also and report to on 18/09/2017. and i forgot to tell you i don\u2019t have machine for compile new version\ncan you send me fresh hashcat binaries for win64\n\n16 \u0441\u0435\u043d\u0442. 2017 \u0433., \u0432 13:55, Jens Steube notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nI've pushed 34c5eac https://github.com/hashcat/hashcat/commit/34c5eac5500dc921e50c7e6b3efcd7055b38726f in order to fix this. Can you please retry with latest version and close the issue if fixed? I can't test myself as you did not append an example header to reproduce.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/1357#issuecomment-329961406, or mute the thread https://github.com/notifications/unsubscribe-auth/AGMqUKSqwxcJmqXDBFhmuP_GjAM7WqKEks5si6kZgaJpZM4PY1wK.\n\n\n. Hi I checked and it seems broken. I send you files you can check pass is hashcat. Also I made file with key file and pin with keyfile\nSend to another email\nhashcat32 -a 3 -w 3 -m 13731 hashcat_whirlpool_aes_13731-485-pim.vc hashcat\nhashcat_whirlpool_aes_13731-485-pim.vc:hashcat\nSession..........: hashcat\nStatus...........: Cracked\nHash.Type........: VeraCrypt PBKDF2-HMAC-Whirlpool + XTS 512 bit\nHash.Target......: hashcat_whirlpool_aes_13731-485-pim.vc\nTime.Started.....: Mon Sep 18 20:05:33 2017 (41 secs)\nTime.Estimated...: Mon Sep 18 20:06:14 2017 (0 secs)\nGuess.Mask.......: hashcat [7]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (2.44ms)\nRecovered........: 1/1 (100.00%) Digests, 1/1 (100.00%) Salts\nProgress.........: 1/1 (100.00%)\nRejected.........: 0/1 (0.00%)\nRestore.Point....: 0/1 (0.00%)\nCandidates.#1....: hashcat -> hashcat\nHWMon.Dev.#1.....: N/A\nStarted: Mon Sep 18 20:02:56 2017\nAnd  \nhashcat32 -a 3 -w 3 --veracrypt-pim=485 -m 13731 hashcat_whirlpool_aes_13731-485-pim.vc hashcat\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: VeraCrypt PBKDF2-HMAC-Whirlpool + XTS 512 bit\nHash.Target......: hashcat_whirlpool_aes_13731-485-pim.vc\nTime.Started.....: Mon Sep 18 20:15:25 2017 (41 secs)\nTime.Estimated...: Mon Sep 18 20:16:06 2017 (0 secs)\nGuess.Mask.......: hashcat [7]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:        0 H/s (2.44ms)\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 1/1 (100.00%)\nRejected.........: 0/1 (0.00%)\nRestore.Point....: 1/1 (100.00%)\nCandidates.#1....: hashcat -> hashcat\nHWMon.Dev.#1.....: N/A\n\n17 \u0441\u0435\u043d\u0442. 2017 \u0433., \u0432 13:17, Jens Steube notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nIt's on https://hashcat.net/beta/ https://hashcat.net/beta/\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/1357#issuecomment-330034064, or mute the thread https://github.com/notifications/unsubscribe-auth/AGMqUDIRqHx9myUXoTT78PJpC4XLiQA5ks5sjPG1gaJpZM4PY1wK.\n\n\n. All worked test with any pim,  key-file and pim vs keyfile(s)\n\n19 \u0441\u0435\u043d\u0442. 2017 \u0433., \u0432 17:45, Jens Steube notifications@github.com \u043d\u0430\u043f\u0438\u0441\u0430\u043b(\u0430):\nThanks for the files. I did a change to the veracrypt-pim handling. I hope it's fixed now. Please retry and close the issue if fixed.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub https://github.com/hashcat/hashcat/issues/1357#issuecomment-330562572, or mute the thread https://github.com/notifications/unsubscribe-auth/AGMqUKr0pyGZW0SvVtkbfO-JqvssSZnLks5sj9MsgaJpZM4PY1wK.\n\n\n. ",
    "dizcza": "I don't want to disable GPU temperature and fans triggers neither to burn down my card. So how can I fix this instead of hiding the warnings?. The host machine outputs the same warnings. I tried on different machines, including AWS instances. Also, I couldn't find a tutorial how to setup OpenCL + Nvidia for hashcat. The basic google steps give what I've already shown.. Yes, 2nd option works, thank you.\nI also found already discussed topic at https://github.com/hashcat/hashcat/issues/1262. I'm closing this a duplicate.. Although I use my phone as @jsteube mentioned - capture handshake and send to a cracking server, - sometimes such a pipeline is not convenient and I'd like to check really small password candidates beforehand. Once I missed for hashcat in android when I was sort of underground or in other countries where for some reason you can't use 3G (for example, it's not cheap for your network provider). Doing WPA/WPA2 handshake password guessing, aircrack-ng is an alternative. But in this case, you'd have to support both versions - hashcat and aircrack-ng - which is not what you want simply because hashcat is a more advanced engine.\nAnother alternative is to run hashcat in a docker container in Android. Has anyone tried this?. > Every CPU should be fine by using Intel OpenCL runtime (even for non-Intel CPU).\nTo use Intel OpenCL runtime one has to install it first which adds ~130 Mb on top of docker image.\nBut you made it clear. OK. ",
    "9128213": "@philsmd\nThanks for your response, and yes i ask in a lot off forums reddit too and maybe im asking a lot. I just see 2 problems.\n1- In the second command for username output\n./hashcat64.bin -m 2611 --show --outfile-format 2 --username hash.txt\nWhere is wordlist.txt ?\nor it is like these\n./hashcat64.bin -m 2611 --show --outfile-format 2 --username hash.txt wordlist.txt\n\n\nI think you are in the good direction cause inside my hash.txt there are 2 different VBulletin hashes, ill have to manually remove them or there is any good tool for remove specific hash type(ill search now)\n\n\nI dont have hashcat installed i just download binaries or whatever and go to the folder i have hashcat-3.6.0 inside there is hashcat64.bin and from here i just do\n./hashcat64.bin -m 2611  --username  /dir/dir/dir/hash.txt /dir/dir/dir/dir/wordlist.txt\n\n\nthese command is just and example maybe is something bad inside just for you check thath i dont have installed.\n\nRefering to 3. Should be better if i install it?.\n\nPretty new to linux/hashcat linux, i use windows hashcat time before and everything was quite more easy, but also more slow i think in these server i can have some good p/s.\nAlso thanks for getting free time for answer me :( sorry for being a d*ck sometimes i am. . ",
    "manjunath7472": "ok thanks! Let me give it a try.\nI have gone thru the default hashes in OpenCL folder.\nSo, What you mean is to learn openCL and edit that openCL file in notepad and rewrite custom hash function? . ",
    "mehrad100": "and i fotgot to say when i dont use -D it is show\nc:\\hashcat>hashcat64.exe -b\nhashcat (v3.6.0) starting in benchmark mode...\n\nDevice #1: WARNING! Kernel exec timeout is not disabled.\n             This may cause \"CL_OUT_OF_RESOURCES\" or related errors.\n             To disable the timeout, see: https://hashcat.net/q/timeoutpatch\nDevice #2: Intel's OpenCL runtime (GPU only) is currently broken.\n             We are waiting for updated OpenCL drivers from Intel.\n             You can use --force to override, but do not report related errors.\nOpenCL Platform #1: NVIDIA Corporation\n======================================\nDevice #1: GeForce 940MX, 512/2048 MB allocatable, 3MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 620, skipped.\nDevice #3: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz, skipped.\n\nHashtype: MD4\nSpeed.Dev.#1.....:  2781.2 MH/s (72.24ms)\nHashtype: MD5\nit is just skipped!!!. i'm really sorry for so much comment but i forgot this\nc:\\hashcat>hashcat64.exe -a3 -m 2500 gh.hccapx ?d?d?d?d?d?d?d?d\nhashcat (v3.6.0) starting...\n\nDevice #1: WARNING! Kernel exec timeout is not disabled.\n             This may cause \"CL_OUT_OF_RESOURCES\" or related errors.\n             To disable the timeout, see: https://hashcat.net/q/timeoutpatch\nDevice #2: Intel's OpenCL runtime (GPU only) is currently broken.\n             We are waiting for updated OpenCL drivers from Intel.\n             You can use --force to override, but do not report related errors.\nOpenCL Platform #1: NVIDIA Corporation\n======================================\nDevice #1: GeForce 940MX, 512/2048 MB allocatable, 3MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) HD Graphics 620, skipped.\nDevice #3: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz, skipped.\n\nHashes: 3 digests; 3 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Single-Salt\n Brute-Force\n Slow-Hash-SIMD\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nWatchdog: Temperature retain trigger disabled.\n[s]tatus [p]ause [r]esume [b]ypass [c]heckpoint [q]uit =>\nSession..........: hashcat\nStatus...........: Running\nHash.Type........: WPA/WPA2\nHash.Target......: gh.hccapx\nTime.Started.....: Sat Sep 23 10:46:22 2017 (5 secs)\nTime.Estimated...: Sat Sep 23 11:34:59 2017 (48 mins, 32 secs)\nGuess.Mask.......: ?d?d?d?d?d?d?d?d [8]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:    34276 H/s (10.00ms)\nRecovered........: 0/3 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 168960/100000000 (0.17%)\nRejected.........: 0/168960 (0.00%)\nRestore.Point....: 0/10000000 (0.00%)\nCandidates.#1....: 72345678 -> 71899001\nHWMon.Dev.#1.....: N/A. ",
    "wdworks": "Well, you probably right. Like i sad i'm trying to integrate the algo i'm researching into the hashcat to use all the great attack modes already implemented. So i need longer non standard kdf to use it than as a key etc. And because it is stated as \"Generic KDF\" i thought that it is appropriate starting point for my modification. I'm going to close the issue.. ",
    "globbergouhl": "I don't know what that means.  What NVIDIA drivers and what \"cards\" are you referring to? I am using an EC2 instance with no GPU. Also, how could OpenGL possibly be broken if I got it via \nsudo apt-get install olc-icd-libopencl1. Sorry for the back and forth, but you are assuming I know more than I do. Would hashcat work at all on a machine that does not even have a GPU?. Why not good idea?. for me works! speed is almost perfectly additive. Btw, I am on Amazon g2.2xlarge instance with 8CPU and 1 GPU.. what about second question? is \"speed\" number cleaned of rejected? if not, this would be a bug.\nAlso, running command as you suggested gives other bug: I run \nhashcat wordlist.txt -r rule.txst --stdout | hashcat -m 2500 your.hccapx -w 4 -D 1,2\nnow give output every 10 seconds or so and no more time till competion which makes sense. But Candidates.#1 (GPU) line in output only changes every 10 updates or so (sigh), while Candidates.#2 (CPU) changes every update, meaning GPU try same password many times?\nBtw, exist no documentation about what is correct interpretation of this line anyway: \nCandidates.#1 Lamabrta -> ehaillaster. answer makes no sense, it's GPU which does not update. please do not close issue before resolved. If does more than 1 hash/10 seconds, should always show different candidate already. Mine does 100kH/s and shows same after 10 seconds.. ",
    "krytarowski": "stat64 breaks NetBSD. ",
    "Szeak": "Ok, yes i want luckily to crack server seed on a site where can win free bitcoins. By posted forum thread, i can generate random passwords now. thank you.\nI thinking of generating speed. It looks like a bit slow for GPU cracking, wich can calculate extremly more hashes per second than passwords CPU can generates/s. ??? any idea?. ",
    "Meatballs1": "If etypes 1,2 or 3 have been enabled (DES) in a modern domain for backwards compatibility it would be handy to be able to run a raw DES brute force against these too. :) \nRequest TGT with etype 3. Crack ticket to get DES encryption key for krbtgt. Not sure if this is doable with mode 14000 or is that only EBC and not CBC? \nEdit: Will try https://github.com/h1kari/des_kpt#kerberos steps to try and wrangle it into a 14000 format. v4.0.0. Yes that looks like the problem. make install needs to clear out the /usr/local/share/hashcat/OpenCL directory? . ",
    "amitaymolko": "ok thanks. ",
    "juanitotc": "v3.6.0 Jun 9, 2017 is \"ultra outdated\"?. I am the package maintainer and it has not been installed incorrectly - the contents of the package can be seen here:\nhttp://tinycorelinux.net/8.x/x86_64/tcz/hashcat.tcz.list\n. ..but literally hundreds of apps packaged exactly like this work without problems.\nIn the few cases where apps packaged like this have not worked (eg the folks contacts app), the maintainers have kindly agreed to modify the code so that it follows symlinks as would be expected.\nIt would seem logical that the symlinked hashcat looks for data in /usr/local/share/hashcat/OpenCL or /tmp/tcloop/hashcat/usr/local/share/hashcat/OpenCL, either of which would work, but it doesn't.. ",
    "AlexandreFournier": "One can do if he has a good idea of the mask.. ",
    "mostafa88": "@philsmd : \nYou are right, hashcat 3.6.0 need this driver\nIntel CPUs require \"OpenCL Runtime for Intel Core and Intel Xeon Processors\" (16.1.1 or later) that need support SSE 4.2 where Inter Core 2 Due supoort  SSE 4.1. So I cannot run hashcat 3.6.0 on and proper opencl driver on my laptop.\n. ",
    "ilovezfs": "Also part of the workaround, it seems these need to be manually set\nSED=gsed SED_IN_PLACE=-i. I'd suggest reverting https://github.com/hashcat/hashcat/commit/c6d7fc845dfcde15af332b40ac19def13a9334b8.. yes\n```\ndiff --git a/src/Makefile b/src/Makefile\nindex 2173355..a3c9b2b 100644\n--- a/src/Makefile\n+++ b/src/Makefile\n@@ -127,7 +127,7 @@ COMPTIME                := $(shell date +%s)\n # the value will be something like this: \"tag: vX.Y.Z, refs/pull/Y/head\"\nVERSION_EXPORT          := HEAD -> master, tag: v4.0.0\n-VERSION_TAG             := $(shell test -d .git && git describe --tags --dirty=+ || echo \"$(VERSION_EXPORT)\" | $(SED) 's/.: v([.0-9]),./v\\1/')\n+VERSION_TAG             := $(shell test -d .git && git describe --tags --dirty=+ || echo \"$(VERSION_EXPORT)\" | $(SED) 's/.: v([.0-9])./v\\1/')\n##\n ## General compiler and linker options\n```\nseems to work. @jsteube shall I backport the fix or do you want to cut a new release?. @jsteube no worries. 4.0.0 shipped in Homebrew! Thanks again @philsmd and @jsteube!. Thanks :). looks good to me!. ",
    "rjzak": "For whatever it's worth, I'm trying to install hashcat 4.0.0 from the tarball on the website, and I had to manually change the VERSION_TAG line in the Makefile to get it to compile on Ubuntu 16.04. So it seems the fix didn't make it to the website.\nVERSION_TAG            := $(shell test -d .git && git describe --tags --dirty=+ || echo \"$(VERSION_EXPORT)\" | $(SED) 's/.*: v\\([\\.0-9]*\\).*/v\\1/'). Yup.. I missed the latest download link on the website. Sorry.. ",
    "googlesecurityteam": "My apologies, I was still on 3.10. 4.0.0 works great! Closing the issue. ",
    "Duncaen": "I fixed it by using the fallback sort_r_simple function.\nhttps://github.com/voidlinux/void-packages/blob/a481cae1c61f2122919c372b8b7c92d8f80c58be/srcpkgs/hashcat/patches/musl.patch. ",
    "bigbang66": "the END header of RAR volume whith headers encrypted is 32 bytes, not 16 bytes. After decrypted, it is 0x14 bytes.  length of padding bytes is 12 bytes, if they are 00 after decrypted, indicates that get right password.. @jsteube \nthanks for your reply\nthis is part of \"interface.c\":\n`  // there's no hash for rar3. the data which is in crypted_pos is some encrypted data and\n  // if it matches the value \\xc4\\x3d\\x7b\\x00\\x40\\x07\\x00 after decrypt we know that we successfully cracked it.\ndigest[0] = 0xc43d7b00;\n  digest[1] = 0x40070000;\n  digest[2] = 0;\n  digest[3] = 0;\nreturn (PARSER_OK);\n}`\nwhen a file is compressed to muti-volumes, if you still matche the value \\xc4\\x3d\\x7b\\x00\\x40\\x07\\x00, you will never get the right password.\n\n. ",
    "bpourriahi": "After reading the introductory post of the LUKS feature into hashcat https://hashcat.net/forum/thread-6225.html I see it avoids the second PBKDF2 by checking for a known file system. I didn't create a filesystem so that would explain it. Once I did that it worked.. ",
    "wdormann": "```\nNumber of platforms:                 1\n  Platform Profile:              FULL_PROFILE\n  Platform Version:              OpenCL 2.0 AMD-APP (2482.4)\n  Platform Name:                 AMD Accelerated Parallel Processing\n  Platform Vendor:               Advanced Micro Devices, Inc.\n  Platform Extensions:               cl_khr_icd cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_amd_event_callback cl_amd_offline_devices\nPlatform Name:                 AMD Accelerated Parallel Processing\nNumber of devices:               2\n  Device Type:                   CL_DEVICE_TYPE_GPU\n  Device ID:                     4098\n  Max compute units:                 64\n  Max work items dimensions:             3\n    Max work items[0]:               256\n    Max work items[1]:               256\n    Max work items[2]:               256\n  Max work group size:               256\n  Preferred vector width char:           4\n  Preferred vector width short:          2\n  Preferred vector width int:            1\n  Preferred vector width long:           1\n  Preferred vector width float:          1\n  Preferred vector width double:         1\n  Max clock frequency:               1630Mhz\n  Address bits:                  32\n  Max memory allocation:             3221225472\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      8\n  Max image 2D width:                16384\n  Max image 2D height:               16384\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           1024\n  Alignment (bits) of base address:      2048\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     No\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    16384\n  Global memory size:                3221225472\n  Constant buffer size:              3221225472\n  Max number of constant args:           8\n  Local memory type:                 Scratchpad\n  Local memory size:                 32768\n  Error correction support:          0\n  Profiling timer resolution:            1\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             No\n  Queue properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Platform ID:                   69CDA784\n  Name:                      gfx900\n  Vendor:                    Advanced Micro Devices, Inc.\n  Driver version:                2482.4 (PAL,HSAIL)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 1.2 AMD-APP (2482.4)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_fp16 cl_khr_gl_sharing cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_d3d11_sharing cl_khr_dx9_media_sharing cl_khr_image2d_from_buffer cl_khr_spir cl_khr_gl_event cl_amd_liquid_flash\nDevice Type:                   CL_DEVICE_TYPE_CPU\n  Device ID:                     4098\n  Max compute units:                 8\n  Max work items dimensions:             3\n    Max work items[0]:               1024\n    Max work items[1]:               1024\n    Max work items[2]:               1024\n  Max work group size:               1024\n  Preferred vector width char:           16\n  Preferred vector width short:          8\n  Preferred vector width int:            4\n  Preferred vector width long:           2\n  Preferred vector width float:          4\n  Preferred vector width double:         2\n  Max clock frequency:               3192Mhz\n  Address bits:                  32\n  Max memory allocation:             1073741824\n  Image support:                 Yes\n  Max number of images read arguments:       128\n  Max number of images write arguments:      64\n  Max image 2D width:                8192\n  Max image 2D height:               8192\n  Max image 3D width:                2048\n  Max image 3D height:               2048\n  Max image 3D depth:                2048\n  Max samplers within kernel:            16\n  Max size of kernel argument:           4096\n  Alignment (bits) of base address:      1024\n  Minimum alignment (bytes) for any datatype:    128\n  Single precision floating point capability\n    Denorms:                     Yes\n    Quiet NaNs:                  Yes\n    Round to nearest even:           Yes\n    Round to zero:               Yes\n    Round to +ve and infinity:           Yes\n    IEEE754-2008 fused multiply-add:         Yes\n  Cache type:                    Read/Write\n  Cache line size:               64\n  Cache size:                    32768\n  Global memory size:                2147483648\n  Constant buffer size:              65536\n  Max number of constant args:           8\n  Local memory type:                 Global\n  Local memory size:                 32768\n  Error correction support:          0\n  Profiling timer resolution:            320\n  Device endianess:              Little\n  Available:                     Yes\n  Compiler available:                Yes\n  Execution capabilities:\n    Execute OpenCL kernels:          Yes\n    Execute native function:             Yes\n  Queue properties:\n    Out-of-Order:                No\n    Profiling :                  Yes\n  Platform ID:                   69CDA784\n  Name:                      Intel(R) Xeon(R) CPU           X5482  @ 3.20GHz\n  Vendor:                    GenuineIntel\n  Driver version:                2482.4 (sse2)\n  Profile:                   FULL_PROFILE\n  Version:                   OpenCL 1.2 AMD-APP (2482.4)\n  Extensions:                    cl_khr_fp64 cl_amd_fp64 cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_gl_sharing cl_ext_device_fission cl_amd_device_attribute_query cl_amd_vec3 cl_amd_printf cl_amd_media_ops cl_amd_media_ops2 cl_amd_popcnt cl_khr_d3d10_sharing cl_khr_spir cl_khr_gl_event\n```. The current hardware that the GPU lives in only has PCI Express 2.0 slots, so using ROCm is out of the question.  So perhaps staying on 3.6.0 is the only workaround for now?\nAre there references to what sort of performance gains can be attained by switching to ROCm from the standard AMD drivers?. The beta worked fine on my Windows rig, thanks!   And in fact, most of the benchmark numbers are a touch faster than what's in the spreadsheet above.  So if there is any penalty for not using ROCm / PCI Express 3.0, I don't seem to be seeing it.   Windows + PCI Express 2.0 seems quite fine.. ",
    "harwoodr": "Alright, I guess I'll hack at the code and see what I can do. My opencl experience is limited, but perhaps this will be a good excuse to sharpen said skills.\nThanks.. Just to see if I'm on the right track, I'm working on just understanding how hashcat does the pbkdf2-hmac-sha256 component.\nI've created the following hash:\nsha256:4096:kh3A5g==:H9GA2pYsBCJ2p0o7r54T6/7BURU5F4QVrG0WpsVu0i//0FE2eVz4D8f0YGtkexArX6RBGaKpV4ujgGyiJXH41w==\n...which uses the password \"password1\".\nAll well and good.  Now, I need to figure out the next step - an AES-256-CBC decrypt.  From what I can tell, there is no existing mode that uses both - except maybe LUKS... but I'm still wrapping my brain around that.. ",
    "http403": "Since the hard disk of my machine is damaged and all data lost(including all backups), I will close this issue for now.. ",
    "DieKart": "@philsmd solution worked! Great job.\nI tested with a couple test databases all crack without issue.. ",
    "hycday": "hi,\nawesome topic!\nconsidering:\n- I fall under the \"pass+wua\" category\n- I know my password\n- I know my Windows User Account login+password\n- I reinstalled my Windows on same computer and used the same user account\ncan i manage to reopen my database following any abovementioned method ?\nor is any of the prerequesites to still be under the initial Windows installation where the database was created ?\n. @Fist0urs thanks for your answer ! \nI managed to find an old backup, and find the folder SID with the \"Preferred\" file and 12 WUA Master Key files.\nHowever, I couldnt retrieve the ProtectedUserKey.bin file (DPAPI blob) located in the C:\\Users\\\\AppData\\Roaming\\KeePass\\ directory of the old WUA.\nIs that mandatory ?\n. ",
    "KKGBiz": "Thank you all.\nHow to restore this pipe session? . ",
    "freeroute": "Did you tried this?\nSolution 1:\n1) echo [[[[[ > pre.rule\n2) hashcat  -j ^X^X^X^X^X -r pre.rule -r yournormalrule.rule  \nSolution 2:\n$ ./hashcat wordlist.txt -r rule.txt --stdout| ./hashcat -m 2500 mywpa.hccap -w 3. I have a same problem with hashcat v.4.x.x. I tried on 2 difference old laptop, the result: hashcat found passwords, but it is not the correct password.\nI didn't report it, because I use OS Kali and amd-opencl-icd driver as workaround (2 different, 8 years old laptop with NVidia GeForce 8400M GS graphic card). With hashcat v.3.6.0 has no such problem, it works well.\nWith my new \"upto-date\" PC there is no problem with hashcat v.4.x.x.. ",
    "einaros": "\n\nMax length of $pass.$hash is >32, <64.\n\n\nI did try writing a new sha1_update_ function, which takes both the global pass and salt, but the perf dropped just as much as with two calls.\n\n\nThat was pseudocode of sorts. Both pass and salt are u32[64].\n\n\nEdit: Guessing the difference comes from there being two calls to update from within sha1_update_global_swap_blah mentioned in (2), as the dictionary approach will cause all data to be within a single u32[64].. ",
    "lcsondes": "Using CPU causes * Device #1: ATTENTION! OpenCL kernel self-test failed. even though I'm on 16.1.1.. ",
    "xflyboy": "You are correct. My bad i forgot to mention that i tried to install OpenCL drivers on my old Intel Xenon x5xxx processor without success. Since it was long time ago i completely forgot about it. Apologize.\nClose the issue as N/A.\nI'll see how to solve the issue. Thx for quick reply.. ",
    "carlos204": "what is the problem???. how can i do to put only numbers and letters??. ",
    "satcom886": "I actually think, that would be a pretty good idea...If you have a big number of phones lying around doing nothing...\nFor cluster computing there are things like hashtopussy.. ",
    "oldmate89": "Hi Philsmd\nThank you for your efforts and helping all with the presale wallet. I will be trying this shortly. I saw on another thread you were seeking feedback. Have you got any comments back on this release? . ",
    "maiiz": "@jsteube what's the time for hashcat support that.. ",
    "SilRo991": "Hi,\nsorry but where did you get this information that it does not support password longer 12?\nFrom the help of an ASA Device I have this Information: Enter a password between 3 and 127 characters.\nYou can also find this online:\nSets the password as a string from 3 to 32 characters in length (9.5 and earlier) or 127 characters (9.6 and later), which can be any combination of ASCII printable characters (character codes 32-126), with the exception of spaces and the question mark.\nhttps://www.cisco.com/c/en/us/td/docs/security/asa/asa-command-reference/T-Z/cmdref4/u.html\n. Yes. It use the first 4 char from the username.. I can paste some examples too:\nCisco Adaptive Security Appliance Software Version 9.1(7)16\nPlain passwords:\nusername admin1 password 12345678901234\nusername admin2 password 12345678\nusername admin3 password 1234567890123456\nusername admin4 password 123456789012345678\nusername admin5 password 12345678\nusername admin6 password 123456789012\nusername a password 12345678\nMinimum allowed username length is 3\nERROR: Username addition failed.\nusername adm password 12345678\nusername admi password 12345678\nusername admin password 12345678\nHashed:\nusername admin1 password jPvB8dZSJc584qfl encrypted\nusername admin2 password YE2FV.4x2hjEDjup encrypted\nusername admin3 password Yx2nrL7o8myDPoI5 encrypted\nusername admin4 password Sep8sPNoTRHoSn7w encrypted\nusername admin5 password YE2FV.4x2hjEDjup encrypted\nusername admin6 password FAjQWHbLfs8.R717 encrypted\nusername adm password yBEOBp9AO4K.3mYs encrypted\nusername admi password YE2FV.4x2hjEDjup encrypted\nusername admin password YE2FV.4x2hjEDjup encrypted\n. ",
    "zot24": "jtlyk I have experiencing the same error on OS X El Capitan 10.11.6. ",
    "Sankulaatchuth": "bro do u made anything to make it work ......i am  stuck here now this is my same isssue i'm trying to run hashcat on my hp omen laptop but cant go further its gtx1060 6gb . ",
    "ryanwoods1706": "Also a side note, I'm cracking an ETH wallet for a friend that has about 22k worth of Ethereum in it, so if someone can help me resolve this, once I'm in I'm willing to pay :). @jsteube Sorry for the tag, but I'd appreciate some help :). @philsmd So its impossible to crack it with a GPU? How much VRam is needed? What if i purchase 256GB of system memory will that work at all or not?. @philsmd So really GPU cracking the wallet is out of the question?. When you tested with -m 15700 on the 1080ti, how much ram did the 1080TI have ? Also mind sending me the KDFParams of the wallet you tested on to see if its the same (forgot which of the paramaters changes how much RAM is needed) But I know that if one of the parameters of the KDFParams is \"262144\" as shown in the screenshot, then the RAM usage for the GPU goes through the roof. Hardware isn't an issue, I'm willing to go out and spend $1k/month renting a GPU server to try and crack this. However https://stealthsploit.com/2017/06/12/ethereum-wallet-cracking/ this tutorial on cracking ETH wallets, in the comments theres loads of people who have the same issue I'm having above and was told that the algorithm will NOT crack on a GPU if certain parameters are too high, hence im trying to get some help here before i go spend a grand. Because when cracking an Ethereum wallet, depending on the wallets parameters you\u2019re unable to crack it with a GPU, since it has huge memory requirements. . Spoken to about 10/15 various hardware experts, and most have said it\u2019ll work without any need of any implementation on the programs end, however some said that the program might need to use the API to intergrate with it. All have said it\u2019s possible, it\u2019s just whether it\u2019ll work without the API implementation or not . I'm waiting to hear back from AMD about this, contacted them directly a few days ago so waiting for a reply. But why wouldn't it be possible to use the SSG as memory in a way meaning that it'll save stuff to files for when it needs it? Might be a bit of work but logically it seems possible. https://www.pcworld.com/article/3099964/hardware/amds-new-ssg-technology-adds-an-ssd-to-its-gpu.html \"The SSG memory would be treated as part of a huge pool of RAM. If the GPU can\u2019t find its data in the local GDDR5+ or HBM RAM, it would then search the SSG. Only after that would it have to ask the CPU for what it wants.\" @Chick3nman \n. Okay fair enough, but from what you\u2019ve said that does that mean that if the GPU needs more memory it\u2019ll go to the System and ask for some? (But it\u2019ll be fucking slow) . If we could split this RAM usage up magically into several pieces, some of which would go into the VRAM and the rest into system RAM/Disk efficiently, then the SSG would make sense. But we aren't doing that because doing so is NOT efficient.\nFrom what you said there, would it be possible to do that with a normal GPU then? Like a 1080ti or something. Of course it wouldn\u2019t be efficient, but it would surely increase hashrates (if possible) to maybe like anywhere from a couple hundred to 10,000? (Just a guess), but it just won\u2019t be efficient \n. So its literally impossible to do this on a GPU at all?. Are there any parallel processors out there (that are good) cost isn\u2019t an issue. FPGA? Are there not ASIC scrypt machines out there? I\u2019d jut need to load an OS on them and run it, and of course as a ton of RAM. I've got a conference call with developers at AMD soon, but from the looks of our conversation so far it looks plausible:\n\u201cThe SSG API is intended to allow you to use the 2TB of SSD storage as a cache layer for the GPU, so it should appear effectively as GPU memory. At this point we\u2019re reaching the limits of what I can explain, and I would recommend getting a quick conference call scheduled between one of our developers and the customer \u2013 is that something you can arrange?\u201d\nOnce I've had the call with AMD and we've reached a conclusion, if it is possible to use the 2TB of SSG in that way, would you (hashcat developers) be able to implement that into your software? . @Chick3nman @jsteube .  Nope, I ended up just spinning up a couple google cloud servers and cracking it that way. :P . ",
    "spideyroc1": "Will this be added?. ",
    "lev4ukpavel2": "Please guys, we need it. I hope you can do it.. ",
    "killtacknine": "Looks like its 387.26\nuser@nvidia-p100-test:~$ nvidia-smi\nFri Jan 12 19:53:33 2018      \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 387.26                 Driver Version: 387.26                    |\n|-------------------------------+----------------------+----------------------+\n.... ",
    "jlmalone": "Thanks @neheb . I am on a Hackintosh that my friend built so I don't feel comfortable upgrading it.. Thank you for fixing this! It is working now on El Capitain 10.11.6 (15G1421). ",
    "mohemiv": "Thanks @philsmd,\nThe first one is really my misunderstanding. The 31-character password confused me, and I thought it was wrong too.. Done. Could you provide us a sample hash in the format that you are using?. ",
    "emcee59": "I would love to see 250 MH/s on a 1080! Do you have any idea why I only get half that? If you can help me optimise my standalone program (it's in the linked forums thread), I would be more than happy to spend whatever time is needed to use it as a basis for a hashcat merge.\n\nWhile looking at the JtR Code, I found that one example hash:\n\nI believe so, 99%. Electrum 1.x wallets should be checked by decrypting with sha256(sha256(pass)) and making sure the whole half seed is base16, I believe something very similar applies to versions between 2 and 2.8 (salt type 2, where they have the \"starts with xprv check\"), while they are using full wallet encryption for 2.8+.\nThe various extract scripts you see around are just taking the iv + first 16 bytes of the encrypted seed, leaving the remaining 32 bytes \"private\".\nI can open another issue for the addition request if you want to, of course. But since that I'm working on this almost fulltime maybe helping me optimise my terrible opencl code has the most return on time invested? ;)\nThank you!. ",
    "yarda": "We would like to package it to Fedora and according to the Fedora packaging guidelines every public library needs to be versioned. For me the library seems like public API/interface so it should probably have SONAME. We can provide patches. What's your opinion?. The patch is more like hack, but seems to work for us. Feel free to improve it or comment. We are ready to update it according to comments.. AppVeyor build failures seems unrelated to the patch for me.. Just proposal, we need API version. Usually in new projects we start from 0.0 (major/minor), but there can be any sane API numbering.. @TomasKorbar please update the PR to address the bug, i.e. edit it to have (you can do git push -f to force push it):\n-$(RM) -f obj/*.o obj/lzma_sdk/*.o *.bin *.exe *.so *.dll *.pid hashcat core\n+$(RM) -f obj/*.o obj/lzma_sdk/*.o *.bin *.exe *.so *.so.* *.dll *.pid hashcat core. No problem, if the e.g. 4.0.1 API is not compatible with the 4.0.0. E.g. all consumers of the API needs to be recompiled upon bump to 4.0.1, 4.0.2, etc. Most projects bump the stable API version after while only when doing API changes.. @jsteube  my previous comment is wrong, yours proposal is better.. Usually auto tools do all the magic :) I will re-think it and provide updated PR soon.. I think libhashcat.so.4.0.1 is OK for the filename of the library, but on Linux we should probably set SONAME to libhashcat.so.4, i.e. use only the MAJOR number for it when linking, ie.: call ld with '-Wl,-soname,libhashcat.so.4', this way the consumers of the API will have to be recompiled only if the MAJOR version of the API will be bumped taking into account the hashcat version means MAJOR.MINOR.PATCH. Well, it's probably non-portable (it seems e.g. FreeBSD use different approach than Linux). It's usually better to keep the magic on the libtool / auto-tools than doing it the hard way :)\nI will update the patch.. Also the SONAME_VERSION will have to be set by some bootstrap script before making the upstream release, because git history is not available in the tarball. Or maybe we could parse it from the VERSION_EXPORT variable.. it seems VERSION_TAG already does it.. Tomas will update the PR later today - I am supervising/sponsoring him in Fedora.. @TomasKorbar this is wrong patch.. @jsteube sorry for delay, please wait for next PR.. FYI for Tomas this is the first contribution to real upstream/github project.. @TomasKorbar mostly. Why is there hunk on lines 342 - 354? Also you shouldn't change the whitespaces .e.g lines 347/365 and many others. Please provide updated PR.. @TomasKorbar you probably didn't update your repo and rebased the commit by:\ngit pull\ngit rebase\n. @jsteube the basic idea should be clear even from this PR. We do not call now ldconfig in the install, because I think it should be handled by admin, i.e.:\n```\nmake install\nldconfig\n```\ne.g. with RPM packages the ldconfig is called in the RPM %postinst phase to make all the symlinks for new libraries. But we can add it to the install, if you think it's good to have.. @TomasKorbar great, well done, it looks much better now.. @jsteube it's ready for review :). OK, great, thanks.. I also added LZMA_SDK_INCLUDE variable which can specify full path to the SDK. Maybe we could use just one variable for it. Unfortunately the LZMA-SDK is not yet standardized across distros and the upstream LZMA-SDK release has still room for improvement.. Maybe you could consolidate the bundled lzma-sdk and more simplify the proposed patch (e.g. the ifdef could be removed).. Also we are trying to rebase the lzma-sdk to the latest 18.01 version in Fedora (https://bugzilla.redhat.com/show_bug.cgi?id=1546091). Hashcat needs small patch to compile with the lzma-sdk 18.01 (https://bugzilla.redhat.com/attachment.cgi?id=1398951&action=diff), maybe you could refresh the bundled lzma-sdk and apply the patch.. ",
    "guru431": "To use Windows is the only way out?\nI basically have to work in macOS. Can there is still some way to raise the speed? Is there something similar to the -w 3 key or can there be unofficial patched drivers for Vega?. ",
    "HaxorGaruda": "Thanks .. all Fix, before i use cuda 8.0 and after upgrade to cuda 9.0 not work, just remove all, and Re clone git repo.. All done.. . ",
    "Skwerl23": "To better give examples. S will take something like P@$$w0rd and make it p244W)RD\nAnd the the second rule I wrote it would turn\nP@$$w0rd int P@$$w0rdp244W)RD. I take it back. M rule does what I want. I need to practice it. So with S rule we could do\nSMI4 should make P@$$w0rd P@$$w0rdp244W)RD\nIf I understand M rule correctly. I'm speechless at the lack of care. I understand the different keyboards. An Sg rule could exist for German. This would find ten fold the passwords as it's a common tactic to double while holding shift. Thanks for looking at it. :/. I understand it's area specific. Why not a language input to hashcat like --language=German and then T could apply the correct shift case to that. This tactic is common on more complicated passwords. When a website says \"must have 2 upper 2 lower 2 numbers and 2 symbols\" people just use 8 digit passwords and hold shift and retype em. . The problem with the s1! Type rule is that it is a cross the board. And not on part of the password. My ultimate goal is to brute Force passwords where the first half is unshifted and the second half is shifted. I could do something like \n?1?1?1?1?1?1?1?1?2?2?2?2?2?2?2?2 and then have 1 = ?l?d and 2 = ?u?s but this does so many more characters. I'm trying to brute Force simplistic doubled and shifted passwords like \nhashcat7HASHCAT& \nThis is a common tactic employed by my co-workers and I need to squash it by finding the weak passwords this way. I've done a few tricks by using paste and an instance of hashcat combinating with a 2nd instance of hashcat combinating with the reverse characters. Or tr command. But this requires three instances of hashcat and is super slow. About 1/10th the speed. If I'm lucky. And hashcat fails to load 3 instances a lot and I get it cracking 8 character passwords half the time I run it. . ",
    "diveyez": "I got the same issues with ubuntu. Kali also has bad packages going out with their current release. You may want to stack trace this ;). ",
    "Victini517": "thanks. ",
    "trollmad3": "@Chick3nman That is apart of the hash. This also happens for MD5 without * . ",
    "evilmog": "Modified as requested. moving to 4.2. ",
    "Virgula0": "\nThis could be a duplicate of #1290 and #1497 . For both issues the current impression is that the driver is just very bad on macos, not supporting byte_align () and furthermore doing weird optimizations that lead to bad speed while the non-macos drivers (windows/linux) have no propblem with the identical kernel code.\n\nbut before with previous versions problem didn't exist... only with latest updates of hashcat and of osx . > I do not have the same hardware but it should be easy to test if the same problems occur with these tests:\n1290 (comment)\n1290 (comment)\nI have some problems to check with some commands...\nmake clean \nmake: *** No rule to make target clean'.  Stop.\nand\ngit checkout 52c1e15f3f5b0f50c8ccce3b8b9c604941fe8a57\nfatal: reference is not a tree: 52c1e15f3f5b0f50c8ccce3b8b9c604941fe8a57\nand \nmake\nmake: *** No targets specified and no makefile found.  Stop.\n. Test 1\n```\nhashcat (v3.6.0-48-g52c1e15f) starting in benchmark mode...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-3635QM CPU @ 2.40GHz, skipped.\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\nDevice #3: GeForce GT 650M, 256/1024 MB allocatable, 2MCU\n\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     3098 H/s (81.68ms)\nSpeed.Dev.#3.....:     6228 H/s (80.26ms)\nSpeed.Dev.#*.....:     9326 H/s\nStarted: Tue Feb 27 11:11:52 2018\nStopped: Tue Feb 27 11:12:11 2018\n```\nTest 2\n```\nOpenCL Platform #1: Apple\n=========================\n Device #1: Intel(R) Core(TM) i7-3635QM CPU @ 2.40GHz, skipped.\n Device #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\n* Device #3: GeForce GT 650M, 256/1024 MB allocatable, 2MCU\nHashtype: WPA/WPA2\nSpeed.Dev.#2.....:     3097 H/s (81.68ms)\nSpeed.Dev.#3.....:     6236 H/s (80.05ms)\nSpeed.Dev.#*.....:     9333 H/s\nStarted: Tue Feb 27 11:13:26 2018\nStopped: Tue Feb 27 11:14:02 2018\n```\nIf I try to do benchmark test with hashcat installed via homebrew it shows me errors of devices\n```\nhashcat (v4.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i7-3635QM CPU @ 2.40GHz, skipped.\nDevice #2: HD Graphics 4000, 384/1536 MB allocatable, 16MCU\nDevice #3: GeForce GT 650M, 256/1024 MB allocatable, 2MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 2500 - WPA/WPA2 (Iterations: 4096)\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n:12:1: error: unknown type name 'DECLSPEC'\nDECLSPEC void generate_pw (u32 pw_buf[64], __global const cs_t root_css_buf, __global const cs_t markov_css_buf, const u32 pw_l_len, const u32 pw_r_len, const u32 mask80, const u32 bits14, const u32 bits15, u64 val)\n^\n:12:10: error: expected identifier or '('\nDECLSPEC void generate_pw (u32 pw_buf[64], __global const cs_t root_css_buf, __global const cs_t markov_css_buf, const u32 pw_l_len, const u32 pw_r_len, const u32 mask80, const u32 bits14, const u32 bits15, u64 val)\n         ^\n\nDevice #2: Kernel /usr/local/Cellar/hashcat/4.1.0/share/hashcat/OpenCL/markov_le.cl build failed - proceeding without this device.\n\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n:12:1: error: unknown type name 'DECLSPEC'\nDECLSPEC void generate_pw (u32 pw_buf[64], __global const cs_t root_css_buf, __global const cs_t markov_css_buf, const u32 pw_l_len, const u32 pw_r_len, const u32 mask80, const u32 bits14, const u32 bits15, u64 val)\n^\n:12:10: error: expected identifier or '('\nDECLSPEC void generate_pw (u32 pw_buf[64], __global const cs_t root_css_buf, __global const cs_t markov_css_buf, const u32 pw_l_len, const u32 pw_r_len, const u32 mask80, const u32 bits14, const u32 bits15, u64 val)\n         ^\n:55:3: warning: implicit declaration of function 'generate_pw' is invalid in C99\n  generate_pw (pw_buf, root_css_buf, markov_css_buf, pw_l_len, pw_r_len, mask80, bits14, bits15, off + gid);\n  ^\n\nDevice #3: Kernel /usr/local/Cellar/hashcat/4.1.0/share/hashcat/OpenCL/markov_le.cl build failed - proceeding without this device.\n\nStarted: Tue Feb 27 11:15:00 2018\nStopped: Tue Feb 27 11:15:01 2018\n```\n. So i will wait for next patches and updates from Homebrew to resolve, or download and execute hashcat with the latest patch manually . ",
    "MESWEB": "Yes I know that but only this version support SL3. I was found my old phone and I want use it again for security reason and that's why I want deal with SL3.. @Xanadrel - Thank You. Strong words. I'd like to go down to your level but I don't know how far away is the idiot.\n@roycewilliams - Time control is not a problem for me. As You can see I was start this script. Thank You for links but I was see this before I post here. I don't understand why all dev is angry for somebody who is looking for help. If You wish - You can help me with this problem or copy post from @Xanadrel.\nThank You for all. @neheb :1st_place_medal: \n\n. I found file but another one is missing.\n./kernels/4318/css_be.sm_35.64.cubin: No such file or directory. ",
    "SpenGietz": "I'd like this too!. ",
    "easyname889": "Just found this below, does this mean that it's possible to run a multibit classic hash with the correct defined variables?\nThen how is it done?\nhttps://github.com/hashcat/hashcat/issues/393\nThanks. ",
    "Nik-Lz": "I have the exact same error. Did you figure it out?. I'm not sure what went wrong. I simply executed the command from hashcat root directory instead and it worked. I was executing from an arbitrary location preciously and simply pointing to hashcat64.exe binary. I am on Windows 8.1.. ",
    "zvodd": "@jsteube what is that issue number? Is there a plan to fix this?. ",
    "NilsOlze": "Agreeing with @bledari, it should be open as known issue / discussion, since it is still present and searching only display open issues by default. \nJust dropping a link to the other issue would be enough information @jsteube .. ",
    "OscarAkaElvis": "I did a workaround for this. Maybe could be useful to somebody. I'll explain it.\n\n\nFirst I added haschat dir to the PATH environment (remember to close cmd prompt and reopen it after modifying PATH env var to get new changes working). After doing this, I can run hashcat64.exe -V from anywhere but If I launch hashcat -b -m 0 -D 1 --force to test it is still failing saying ./hashcat.hctune: No such file or directory.\n\n\nThen I created on my hashcat directory (in my case is C:\\Program Files\\hashcat-5.1.0) a file called hashcat.bat . The content of the file is this:\n\n\n@echo off\nset original_dir=\"%CD%\"\ncd \"C:\\Program Files\\hashcat-5.1.0\"\nhashcat64.exe %*\ncd \"%original_dir%\" \nThe orgininal_dir var is set in order to return to the same directory where you are once launched. Otherwise it will change always our cmd prompt to hashcat directory. Remember that on the third line of the bat, the path that must be appear is where you have your hashcat (the same dir you added to the PATH env var, in my case is C:\\Program Files\\hashcat-5.1.0).\n\nLast step, just test it! Execute from anywhere hashcat -b -m 0 -D 1 --force <- this command execute the minimal benchmark test using CPU.\n\nThis worked for me on hashcat 5.1.0 for Windows (W10).. ",
    "devwhatsapp": "That works. :)\nNeed to change 10400 to 10500\nhashcat -m 10500 -a 3 -w 3 '$pdf$4*4*128*-3904*1*16*8aaf9105962aaa4182602a81b9485e69*32*615bb2bf8976796e272a3ca130b417d76a6d4429f3a6c5f3ab574bf17a02ff7d*32*3add260c37d64307876f6f0168414109638d74600eeccb925d4d472ee462e4f0' ?b?b?b?b\n`Session..........: hashcat\nStatus...........: Running\nHash.Type........: PDF 1.4 - 1.6 (Acrobat 5 - 8)\nHash.Target......: $pdf$44128-39041168aaf9105962aaa4182602a81b94...62e4f0\nTime.Started.....: Sat Mar 24 01:25:01 2018 (24 secs)\nTime.Estimated...: Sat Mar 24 03:38:21 2018 (2 hours, 12 mins)\nGuess.Mask.......: ?b?b?b?b [4]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   536.9 kH/s (119.49ms) @ Accel:256 Loops:35 Thr:64 Vec:8\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 12582912/4294967296 (0.29%)\nRejected.........: 0/12582912 (0.00%)\nRestore.Point....: 0/16777216 (0.00%)\nCandidates.#1....: $HEX[7c617269] -> $HEX[7cffff01]\nHWMon.Dev.#1.....: N/A\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit =>`\nAnything more than 4 of \"Guess.Mask.......: ?b?b?b?b\" - goes to 23 days and above on my system. guess this hash cant be cracked.\nDid I miss reading about the single quote somewhere ?\nOne thing I do not understand , the hash was obtained from 1.7 version 128 bit key , but we have to use -m 10500 which is for the lower version.\nThank you so much. ",
    "sundhaug92": "How'd one predict performance-improvements over such a long stretch? Moore's law seems to already be slowing down but we don't have that many years to extrapolate a model from.. @RealEnder Fair point but I'm not sure QC would substantially benefit hashing-algorithms, which is usually what hashcat deals with. ",
    "matlink": "Moore's law has an end. Transistors size is limited by electrons size. You could however imagine a similar law according to parallel computing grow. . ",
    "bove87150": "done :) . ",
    "tosiara": "Yeah, amd drivers look broken...\n```\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n================================================\n* Device #1: AMD Athlon(tm) II X2 255 Processor, 737/737 MB allocatable, 2MCU\nBenchmark relevant options:\n\n--force\n--opencl-device-types=1\n--optimized-kernel-enable\n\nHashmode: 0 - MD5\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n\"/home/motion/hashcat-4.1.0/OpenCL/inc_vendor.cl\", line 102: error: can't\n          enable all OpenCL extensions or unrecognized OpenCL extension\n  #pragma OPENCL EXTENSION cl_amd_media_ops2 : enable\n                                               ^\n\"/home/motion/hashcat-4.1.0/OpenCL/inc_types.cl\", line 356: error: function\n          \"amd_bfe\" declared implicitly\n    return amd_bfe (a, b, c);\n           ^\n\"/home/motion/hashcat-4.1.0/OpenCL/inc_types.cl\", line 361: error: function\n          \"amd_bfe\" declared implicitly\n    return amd_bfe (a, b, c);\n           ^\n3 errors detected in the compilation of \"/home/motion/hashcat-4.1.0/OpenCL/OCLV6JCjE.cl\".\nInternal error: clc compiler invocation failed.\n\nDevice #1: Kernel /home/motion/hashcat-4.1.0/OpenCL/m00000_a3-optimized.cl build failed - proceeding without this device.\n\nStarted: Tue May  8 17:03:45 2018\nStopped: Tue May  8 17:03:47 2018\n```. ",
    "Skybound1": "HI @matrix, the commands above are the commands I can use to reproduce, the missing command would be hashcat -m 1000 hash -a 3 mask when running without the optimised kernel however that just shows it works without the optimised kernel instead of showing the issue itself. Interesting you haven't been able to reproduce. \nI have been able to reproduce the issue on three different machines. hashcat -I for each can be seen below.\nMachine one (Arch Linux):\n```\nhashcat (v4.1.0) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) OpenCL\n  Version : OpenCL 1.2 LINUX\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-4600U CPU @ 2.10GHz\n    Version        : OpenCL 1.2 (Build 37)\n    Processor(s)   : 4\n    Clock          : 2100\n    Memory         : 3985/15940 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2.0.37\n```\nMachine two (Ubuntu):\n```\nhashcat (v4.1.0) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : NVIDIA Corporation\n  Name    : NVIDIA CUDA\n  Version : OpenCL 1.2 CUDA 9.0.282\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : GeForce GTX 1080 Ti\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 28\n    Clock          : 1582\n    Memory         : 2793/11172 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 384.111\n[..snip..]\nPlatform ID #2\n  Vendor  : Intel(R) Corporation\n  Name    : Intel(R) OpenCL\n  Version : OpenCL 1.2 LINUX\nDevice ID #7\n    Type           : CPU\n    Vendor ID      : 8\n    Vendor         : Intel(R) Corporation\n    Name           : Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\n    Version        : OpenCL 1.2 (Build 25)\n    Processor(s)   : 8\n    Clock          : 3600\n    Memory         : 8028/32112 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2.0.25\n```\nMachine three (Windows 10):\n```\nOpenCL Info:\nPlatform ID #1\n  Vendor  : NVIDIA Corporation\n  Name    : NVIDIA CUDA\n  Version : OpenCL 1.2 CUDA 9.1.75\nDevice ID #1\n    Type           : GPU\n    Vendor ID      : 32\n    Vendor         : NVIDIA Corporation\n    Name           : GeForce GTX 760\n    Version        : OpenCL 1.2 CUDA\n    Processor(s)   : 6\n    Clock          : 1084\n    Memory         : 512/2048 MB allocatable\n    OpenCL Version : OpenCL C 1.2\n    Driver Version : 388.13\n```\n. If it helps, see below a copy / paste of my terminal after reproducing the issue.\n```\n\u256d\u2500user@arch /tmp/test \n\u2570\u2500$ cat hash\n6E8EF5E8AFFDAC4F560D8F9A62215B5F\n78D50C731A4703CF1B9BEBA02370E85E\n\u256d\u2500user@arch /tmp/test \n\u2570\u2500$ cat mask\n?u?l?d,?1?1?1?1?1?1?1?1?1\n\u256d\u2500user@arch /tmp/test \n\u2570\u2500$ hashcat --keyspace -a 3 mask\n56800235584\n\u256d\u2500user@arch /tmp/test \n\u2570\u2500$ hashcat -O -m 1000 hash -a 3 mask \nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHz, 3985/15940 MB allocatable, 4MCU\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Optimized-Kernel\n Zero-Byte\n Precompute-Init\n Precompute-Merkle-Demgard\n Meet-In-The-Middle\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n Brute-Force\n* Raw-Hash\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 27\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => q\nSession..........: hashcat                     \nStatus...........: Quit\nHash.Type........: NTLM\nHash.Target......: hash\nTime.Started.....: Tue Apr 24 13:45:35 2018 (1 sec)\nTime.Estimated...: Tue May 26 20:25:12 2020 (2 years, 33 days)\nGuess.Mask.......: ?1?1?1?1?1?1?1?1?1 [9]\nGuess.Charset....: -1 ?u?l?d, -2 Undefined, -3 Undefined, -4 Undefined \nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....:   205.3 MH/s (9.41ms) @ Accel:1024 Loops:512 Thr:1 Vec:8\nRecovered........: 0/2 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 152190976/13537086546263552 (0.00%)\nRejected.........: 0/152190976 (0.00%)\nRestore.Point....: 36864/3521614606208 (0.00%)\nCandidates.#1....: nfIa90000 -> znxeA0000\nHWMon.Dev.#1.....: N/A\nStarted: Tue Apr 24 13:45:32 2018\nStopped: Tue Apr 24 13:45:37 2018\n\u256d\u2500user@arch /tmp/test \n\u2570\u2500$ hashcat -m 1000 hash -a 3 mask                                                                                 2 \u21b5\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-4600U CPU @ 2.10GHz, 3985/15940 MB allocatable, 4MCU\n\nHashes: 2 digests; 2 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Early-Skip\n Not-Salted\n Not-Iterated\n Single-Salt\n Brute-Force\n* Raw-Hash\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nATTENTION! Pure (unoptimized) OpenCL kernels selected.\nThis enables cracking passwords and salts > length 32 but for the price of drastically reduced performance.\nIf you want to switch to optimized OpenCL kernels, append -O to your commandline.\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => q\nSession..........: hashcat                     \nStatus...........: Quit\nHash.Type........: NTLM\nHash.Target......: hash\nTime.Started.....: Tue Apr 24 13:45:52 2018 (0 secs)\nTime.Estimated...: Wed Jan 14 13:44:42 2026 (7 years, 265 days)\nGuess.Mask.......: ?1?1?1?1?1?1?1?1?1 [9]\nGuess.Charset....: -1 ?u?l?d, -2 Undefined, -3 Undefined, -4 Undefined \nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#1.....: 55519.8 kH/s (4.65ms) @ Accel:1024 Loops:64 Thr:1 Vec:8\nRecovered........: 0/2 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 28835840/13537086546263552 (0.00%)\nRejected.........: 0/28835840 (0.00%)\nRestore.Point....: 0/56800235584 (0.00%)\nCandidates.#1....: S71eraner -> BXXndoner\nHWMon.Dev.#1.....: N/A\nStarted: Tue Apr 24 13:45:48 2018\nStopped: Tue Apr 24 13:45:53 2018\n```\n. ",
    "meme-lord": "You can install it with your package manager, one of these should work:\napt-get install hashcat\npacman -S hashcat\nyum install hashcat\nIf those don't work you can download the binaries/source from here: https://hashcat.net/hashcat/\nand compile it yourself.\nThis question is more suited to the hashcat forums as it isn't an issue with the codebase (error, problem or feature).\nYou can also read the FAQ here: https://hashcat.net/wiki/doku.php?id=frequently_asked_questions. ",
    "guange2015": "osx version 10.13.4 \nIntel Iris Graphics 6100 1536 MB\nMacBook Pro (Retina, 13-inch, Early 2015). .......cry\ntoday i re try, can cracked.. ",
    "joernheissler": "Thanks a lot!. ",
    "raikikon": "there should be an option while cracking the target hash, such that the newly generated hash while bruteforce colud be compared as equal greater or lesser than the target hash.\nfor(string value = aaaaa to zzzzz)\n{ if  (hashof(value) == target hash)\nbreak;\n// but there should be option\nif(hashof(value) < or > target hash)\nbreak;\n// want the option of < > or == so can implement block-chain with it\n}. i want that for the blockchain implementation. ",
    "yamahoto": "Sorry for delay in answer, havent looked at that project before now. I just retried and effectively, problem still same with hashcat 4.2.1 64 bits windows.\nNon-optimised Worked and Optimised didn't.\nTry your: ./hashcat -m 3710 --quiet hash word --potfile-disable -O\nWITH:\n42a5fb96fa75bb55c519678441306c88:98c00872f8e1c1e61fe9b956f55c944e  ( Sakamoto )\n194816eedfcd66859e3f1e057dd01d17:0a93f38bed8e3d7265954e965393ee22 ( BERKELEY )\n584820a9c6c809d49760856d39e52b6c:64288bcdb9cc8efecf048471ecab2e4a ( dookie69 )\n. Noted, thanks\n. ",
    "Cortexelus": "Yes this is for the older version. \nWe saw a surge of users who bought BitShares early in 2014-2015, used this older wallet client, ignored it for a few years until receiving the news their price soared, then came to forums asking for help recovering their wallets. They have wallet JSONs.. ",
    "dd404x": "@roycewilliams \n\nNo,thanks.\n. \n. @roycewilliams \n\nBecause there is no graphics on this computer\n. \nWho can help me\uff1f. ",
    "blark": "Thanks for the help! \nI did try that actually, I tried to specify it on the command line and then I manually changed it in src/Makefile and I get no error output. Maybe there is no output? Not sure what's going on. . ",
    "rikatz": "Same problem here.\nRunning hashcat 4.2.1 in a ppc64 machine with 4 Tesla P100, and get the clBuildProgram(): CL_BUILD_PROGRAM_FAILURE\nDid a make clean, and a make DEBUG=1 but nothing happens, only the error, no debug messages.\nAny advice? \nThanks!\nEDIT: Got some messages here:\n* Device #4: build_opts '-cl-std=CL1.2 -I OpenCL -I /home/katz/hashcat-4.2.1/OpenCL -D VENDOR_ID=32 -D CUDA_ARCH=600 -D AMD_ROCM=0 -D VECT_SIZE=1 -D DEVICE_TYPE=4 -D DGST_R0=0 -D DGST_R1=3 -D DGST_R2=2 -D DGST_R3=1 -D DGST_ELEM=4 -D KERN_TYPE=0 -D _unroll'\n* Device #4: Kernel m00000_a1-pure.0e14c4fb.kernel not found in cache! Building may take a while...\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE. ",
    "omula": "Unfortunately, there's no opencl support for target GPUs on power architectures.\nhttps://devtalk.nvidia.com/default/topic/1025683/opencl-on-power8/. @jsteube it now gives the following message:\n```\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\n\nDevice #4: Kernel /path/to/hashcat/OpenCL/m16800-pure.cl build failed - proceeding without this device.\n```\n\nIs this the expected output?\n. ",
    "huitc": "like this : 3b437c4e55d4a759117a83ba08912099. @roycewilliams but I don't know salt...\nif I knew it, how I can crack it? -m 2611?\nbut....... 6bits salt... no 3bits or 30bits..\n\u5f9e\u6211\u7684 MI6\uff0c\u4f7f\u7528 FastHub \u767c\u9001\u3002. ",
    "MehmetAliCan10": "and which is fast for hashcat generator wordlist windows or linux?. ok\n. I can not thread or post... I get not email resend activation :/. You do not have permission to access this page. This could be because of one of the following reasons:\nYour account has either been suspended or you have been banned from accessing this resource.\nYou do not have permission to access this page. Are you trying to access administrative pages or a resource that you shouldn't be? Check in the forum rules that you are allowed to perform this action.\nYour account may still be awaiting activation or moderation. (Resend Activation Code)\nYou have accessed this page directly rather than using appropriate forms or link.\nYou are currently logged in with the username: 'mehmet-ali_can'. ",
    "Lexus89": "I seem to have the same problem using v4.0.0, can someone else verify this as well? Would have cracked so many more passwords if this is indeed a bug.. ",
    "antnks": "@jsteube thanks for the workaround. Just to confirm, does stdin mode allow to estimate time, resume session after quit as well as pause at runtime?. ",
    "wifislax-ng": "Opss , i open another commit with same issues, but hash WPA/WPA2.. OK . i found where is the problem.\nhashcat-4.1.0 + beignet-1.3.1\nWhen process start i see a warning mesaage\nOPENCL kernel-self-test failed !!!!\nBut hashcat continue ..ignoring this ...\nOther plattform with hashcat-4.1.0  + Nvidia opencl device\nmessage not appears ..all is ok , and cracked works.\nI think , when kernel-self-test fails ... then no need continue with process.. We have  --> --self-test-disable\nI think , when test fails , --force never overwrite that , only the user, using the especific argument to ingoring this.\n--force sometimes are needing , cause some driver mismatch , but working, but if self test say no , please , stop with message , and point to use the specific argument.\nonly --self-test-disable , can ignore te opencl test failing , at least the user know the driver is failing without time lost passing dictionary for nothing.\n. Thanks !!!\nNow is perfect.. ",
    "testersz": "Admin:f5e6da01af01000097a42cf27356aef866ef545ac4b9a762aaef010ca29c37ae40f69ebb3a74ecdf00000000000000000000000000000000140541646d696e:aa42b3a4cccc9ed949c94794dd0cc046e10128ce\npassword: pentest\nadmin:c5a53db2d854061a5ae8c28acc2a077b85859ede6ea952be1d2a00005a0b0000a74800008247000035383339313447423830333334354a44140561646d696e:d82a44aa893b842ca9659f6877f3c5c46374d607\npassword: 12345678\nExplanation:\n1) create small dictionarry\n123\n1234\ntest\npentest\n12345678\n123456\nqwerty\n2)executing hashcat\nhashcat -m 7300 -o crack.txt --username hashes/IPMI.list lists/passwords.list\n3) using this dictionary, result cracked, and shows \"123\" is suitable for the hashes\n4) if we change \"pentest\" to \"pentest1\" in dictionary, and set --potfiles-disable\nanswer cracked only for one hash, and also \"123\"\n5) if we change \"12345678\" to \"112345678\"\nresult is Exhausted Recovered (0/2). From technical perspective - which Kali components may impact the process of cracking? \nDid you tried to reproduce it using Kali Linux? . I wrote about this:\nhttps://github.com/hashcat/hashcat/issues/1582\nhttps://github.com/hashcat/hashcat/issues/1695\n. Also tested on: \nLinux kali 4.17.0-kali1-686-pae #1 SMP Debian 4.17.8-1kali1 (2018-07-24) i686 GNU/Linux. ",
    "janisrubenis": "\nMy hashcat version is different from version mentioned above \nhashcat (v4.1.0-22-g469fece1+) starting...<\nMy hashcat (v4.1.0) starting...\n\n\n\nadditionally I tested on \u044586 system.\n2) before test  I deleted hashcat (apt remove) and installed it again.\nError is still the same.\nShould I focus on another components of the system, drivers for videocard or any libraries? \nFull scneario is here\nhashcat_bug_2 (1).txt\nhashcat_bug.txt\n. ",
    "cubagithub": "Is there any benefit to target multiple handshakes? I will research how to select one handshake - thanks for the feedback.. ",
    "Spear0070": "Hey jsteube, I tried deleting the pid to see if it works and it worked. Thanks for replying anyways. I'll close the issue now. . ",
    "DerBunteBall": "With the reply from @jsteube I could solve my problem within 1 minute. Eventually I simply don't read enough documentation but the error message really is missleading. Eventually something like \"Wrong maskfile syntax\" could be a better error message and would help more.\nBest Regards. First of all: If you don't know something of the structure of the pass I would say that you will not be able to recover it.\nMy benchmark shows 21h/s for a ATI GPU.... that's really. slow. The mode must be more or less complex.\nSteps to try:\n\nExtract the Hash of the iTunes Backup with something like itunes_backup2john.pl from the JohnTheRipper Package (http://www.openwall.com/john/). The exporters are helpful but Hashcat is the magic maker.\nYou will need to generate custom masks. You can gen a dictionary with the PACK Package (https://github.com/iphelix/pack). IMPORTANT: I think this won't work well. You try to solve the unsolveable problem.\nYour command looks like this: hashcat -a 3 -m 14800 -o cracked.txt --outfile-format=15 yourhash dict|mask|wordlist\n\nFor example a silly brute force for an 8 char pass about which you know nothing would look so:\nhashcat -a 3 -m 14800 -o cracked.txt --outfile-format=15 yourhash ?a?a?a?a?a?a?a?a\nThis would start but run until the universe explodes/implodes/or what ever it thinks it shoudl do when it ends. Think 9 char with ?a would cause an integer overflow. This could only be \"solved\" by generating intelligent masks. But also the masks generated by PACK could explode the integer I think.\nTo understand Mask Attacks read this: https://hashcat.net/wiki/doku.php?id=mask_attack\nHoep this helps a bit. But I think you pass and data are gone.\nBest Regards. ",
    "davidrozen76": "Obviously this is not the case, I'm talking about cracking the 32 chars encrypted PSK part in wpa_supplicant.conf. Yes, -m 12000 is the correct method.. ",
    "hashuser1": "Can I reopen this ticket?. Yes and no. I have new information but they released a new version of rocm\nyesterday. I have some tickets open with AMD and they noticed the self test\nerrors go away if you compile hashcat v4.2 from source. I confirmed this\nbut in my testing only short hashes can be found intermittently, longer\nones (more than 32 characters still fail). That being said the testing was\ndone with Rocm 1.8.3. And they released 1.9 yesterday and now I have to\ntest that.\nOn Fri, Sep 14, 2018, 23:45 Jens Steube notifications@github.com wrote:\n\nWhy, do you have new informations?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1596#issuecomment-421535988,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AmebeTDVB3TnKRSna1W7VEA_EfdhrVv1ks5ubKIbgaJpZM4UrAP-\n.\n. \n",
    "Enverex": "I'm in the same boat (\"clBuildProgram(): CL_BUILD_PROGRAM_FAILURE\" with Mesa OpenCL driver for the RX580).  Trying ROCM results in a segfault instead (in libamdocl-orca64.so).\nSo both fail in their own way.. This is an Intel Z370 chipset motherboard and should most definitely be PCIe-3.0.. ",
    "alexeypetrenko": "Do you have an instruction anywhere on how to gather debug info for you?\n--opencl-vector-width 1 didn't help.\nAlso, I'm sorry that I haven't tested it on different installation.  I think that you could simply close this issue if it's not reproducible. I'm currently running on a CentOS release, which is not exactly supported by AMD. So, there could be some problems with my configuration.. ",
    "metulski2013": "well, i think i read it in a document from passware. here https://sourceforge.net/p/veracrypt/discussion/search/?q=PIM are some more details. but in my mind, you can only decrypt, when you have the pass and the pim. if the field is empty, different pim's are used (depends on the password length and type of target). if i have the right pass, but the false pim, hashcat fails.. maybe build-in a loop?. > In theory yes, but that doesn't make much sense if you don't know the password. It could make sense if you know the password. However, in such a case a different tool would be more appropriate.\n\nHowever where did read about the maximum of 9999 for PIM?\n\nwell i think it makes sence because in an actual case we have some some possible candidates of passwords but no information about a used pim. yes, it is possible do build a loop but the gpu starts e new process and it costs a lot of time. maybe you can build in a loop like \"--pim 0-1000\". . ",
    "DroidKali": "The clinfo retuned is \"Number of platforms                               0\". What is the problem?. ",
    "alexhaiduk": "\nexample asterisk:\n\n```\nInternet Protocol Version 4, Src: 192.168.0.100, Dst: 192.168.0.11\nUser Datagram Protocol, Src Port: 53479, Dst Port: 5060\nSession Initiation Protocol (REGISTER)\n    Request-Line: REGISTER sip:192.168.0.11 SIP/2.0\n    Message Header\n        Via: SIP/2.0/UDP 192.168.0.100:53479;rport;branch=z9hG4bKPj43f7a3f82bdc44b981f4a050589b3ecc\n        Route: \n        Max-Forwards: 70\n        From: \"712\" sip:712@192.168.0.11;tag=0d0c3c675e89402d94e7c5abdd760532\n        To: \"712\" sip:712@192.168.0.11\n        Call-ID: f5da0f0edba447e2804cf3370ec8ce07\n        CSeq: 34467 REGISTER\n        User-Agent: MicroSIP/3.15.10\n        Contact: \"712\" sip:712@192.168.0.100:53479;ob\n        Expires: 300\n        Allow: PRACK, INVITE, ACK, BYE, CANCEL, UPDATE, INFO, SUBSCRIBE, NOTIFY, REFER, MESSAGE, OPTIONS\n        Authorization: Digest username=\"712\", realm=\"asterisk\", nonce=\"198bb98f\", uri=\"sip:192.168.0.11\", response=\"05b1108c62d01f3eace4dc5f1958c413\", algorithm=MD5\n        Content-Length:  0\n``\nin this example username = \"712\", realm = \"asterisk\", nonce = \"198bb98f\", uri = \"sip:192.168.0.11\", response = \"05b1108c62d01f3eace4dc5f1958c413\", algorithm = MD5\npassword = \"ab1234\" (!)\nwe get a hash filename \"712.hash\" with:$sip$sip:192.168.0.11712asteriskREGISTERsipsip:192.168.0.11198bb98f**MD505b1108c62d01f3eace4dc5f1958c413`\nstarting hashcat with params:\nhashcat64.exe -a 3 -m 11400 712.hash ?l?l?d?d?d?d --force\nthe password was found after the tenth attempt and create file \"hashcat.potfile\" with:\n$sip$*192.168.0.11**712*asterisk*REGISTER*sip*192.168.0.11**198bb98f****MD5*05b1108c62d01f3eace4dc5f1958c413:ab1234\nfor some reason the following attempts to find a password have not yielded results:\n```\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>hashcat64.exe -a 3 -m 11400 712.hash ?l?l?d?d?d?d --force\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz, skipped.\nDevice #2: Intel(R) HD Graphics 4000, 311/1246 MB allocatable, 16MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Not-Iterated\n Single-Hash\n Single-Salt\n* Brute-Force\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: SIP digest authentication (MD5)\nHash.Target......: $sip$sip:192.168.0.11712asteriskREGISTERsip*s...58c413\nTime.Started.....: Wed Jun 27 16:23:09 2018 (1 sec)\nTime.Estimated...: Wed Jun 27 16:23:10 2018 (0 secs)\nGuess.Mask.......: ?l?l?d?d?d?d [6]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:  6767.9 kH/s (2.39ms) @ Accel:4 Loops:2 Thr:512 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 6760000/6760000 (100.00%)\nRejected.........: 0/6760000 (0.00%)\nRestore.Point....: 10000/10000 (100.00%)\nCandidates.#2....: uq0123 -> xq8373\nHWMon.Dev.#2.....: N/A\nStarted: Wed Jun 27 16:23:08 2018\nStopped: Wed Jun 27 16:23:11 2018\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>\n```\n\nAnother example concerning the field of nonce\n\n```\nFrame 1: 580 bytes on wire (4640 bits), 580 bytes captured (4640 bits) on interface 0\nEthernet II, Src: AsrockIn_1e:c8:13 (bc:5f:f4:1e:c8:13), Dst: Microsof_00:28:01 (00:15:5d:00:28:01)\nInternet Protocol Version 4, Src: 192.168.0.100, Dst: 192.168.0.4\nUser Datagram Protocol, Src Port: 49315, Dst Port: 5066\nSession Initiation Protocol (REGISTER)\n    Request-Line: REGISTER sip:192.168.0.4:5066 SIP/2.0\n    Message Header\n        Via: SIP/2.0/UDP 192.168.0.100:49315;rport;branch=z9hG4bKPjc6c1a3ab035a4c9ea66611d91012077b\n        Max-Forwards: 70\n        From: \"4553\" sip:4553@192.168.0.4;tag=425f50003e7b45c2971ba1fab659d76b\n        To: \"4553\" sip:4553@192.168.0.4\n        Call-ID: 35c7a8f7060e4b48b329d4c6d2891853\n        CSeq: 9561 REGISTER\n        User-Agent: MicroSIP/3.15.10\n        Contact: \"4553\" sip:4553@192.168.0.100:49315;ob\n        Expires: 300\n        Allow: PRACK, INVITE, ACK, BYE, CANCEL, UPDATE, INFO, SUBSCRIBE, NOTIFY, REFER, MESSAGE, OPTIONS\n        Content-Length:  0\nFrame 2: 564 bytes on wire (4512 bits), 564 bytes captured (4512 bits) on interface 0\nEthernet II, Src: Microsof_00:28:01 (00:15:5d:00:28:01), Dst: AsrockIn_1e:c8:13 (bc:5f:f4:1e:c8:13)\nInternet Protocol Version 4, Src: 192.168.0.4, Dst: 192.168.0.100\nUser Datagram Protocol, Src Port: 5066, Dst Port: 49315\nSession Initiation Protocol (407)\n    Status-Line: SIP/2.0 407 Proxy Authentication Required\n    Message Header\n        Via: SIP/2.0/UDP 192.168.0.100:49315;rport=49315;branch=z9hG4bKPjc6c1a3ab035a4c9ea66611d91012077b\n        Proxy-Authenticate: Digest nonce=\"414d535c1144225218:ef255fff6bbafa40147fbd960f128803\",algorithm=MD5,realm=\"3CXPhoneSystem\"\n        To: \"4553\"sip:4553@192.168.0.4;tag=72139422\n        From: \"4553\" sip:4553@192.168.0.4;tag=425f50003e7b45c2971ba1fab659d76b\n        Call-ID: 35c7a8f7060e4b48b329d4c6d2891853\n        CSeq: 9561 REGISTER\n        User-Agent: 3CXPhoneSystem 15.5.13103.5 (11793)\n        Content-Length: 0\nFrame 3: 798 bytes on wire (6384 bits), 798 bytes captured (6384 bits) on interface 0\nEthernet II, Src: AsrockIn_1e:c8:13 (bc:5f:f4:1e:c8:13), Dst: Microsof_00:28:01 (00:15:5d:00:28:01)\nInternet Protocol Version 4, Src: 192.168.0.100, Dst: 192.168.0.4\nUser Datagram Protocol, Src Port: 49315, Dst Port: 5066\nSession Initiation Protocol (REGISTER)\n    Request-Line: REGISTER sip:192.168.0.4:5066 SIP/2.0\n    Message Header\n        Via: SIP/2.0/UDP 192.168.0.100:49315;rport;branch=z9hG4bKPja7425cc621bc463ea8576c5c0abe1d74\n        Max-Forwards: 70\n        From: \"4553\" sip:4553@192.168.0.4;tag=425f50003e7b45c2971ba1fab659d76b\n        To: \"4553\" sip:4553@192.168.0.4\n        Call-ID: 35c7a8f7060e4b48b329d4c6d2891853\n        CSeq: 9562 REGISTER\n        User-Agent: MicroSIP/3.15.10\n        Contact: \"4553\" sip:4553@192.168.0.100:49315;ob\n        Expires: 300\n        Allow: PRACK, INVITE, ACK, BYE, CANCEL, UPDATE, INFO, SUBSCRIBE, NOTIFY, REFER, MESSAGE, OPTIONS\n        Proxy-Authorization: Digest username=\"4553\", realm=\"3CXPhoneSystem\", nonce=\"414d535c1144225218:ef255fff6bbafa40147fbd960f128803\", uri=\"sip:192.168.0.4:5066\", response=\"b3cd2617f79b96adad84706754ae91e6\", algorithm=MD5\n        Content-Length:  0\nFrame 4: 473 bytes on wire (3784 bits), 473 bytes captured (3784 bits) on interface 0\nEthernet II, Src: Microsof_00:28:01 (00:15:5d:00:28:01), Dst: AsrockIn_1e:c8:13 (bc:5f:f4:1e:c8:13)\nInternet Protocol Version 4, Src: 192.168.0.4, Dst: 192.168.0.100\nUser Datagram Protocol, Src Port: 5066, Dst Port: 49315\nSession Initiation Protocol (200)\n    Status-Line: SIP/2.0 200 OK\n    Message Header\n        Via: SIP/2.0/UDP 192.168.0.100:49315;rport=49315;branch=z9hG4bKPja7425cc621bc463ea8576c5c0abe1d74\n        Contact: \"4553\"sip:4553@192.168.0.100:49315;ob;expires=300\n        To: \"4553\"sip:4553@192.168.0.4;tag=9035d65f\n        From: \"4553\"sip:4553@192.168.0.4;tag=425f50003e7b45c2971ba1fab659d76b\n        Call-ID: 35c7a8f7060e4b48b329d4c6d2891853\n        CSeq: 9562 REGISTER\n        User-Agent: 3CXPhoneSystem 15.5.13103.5 (11793)\n        Content-Length: 0\nin this example username = \"4553\", realm = \"3CXPhoneSystem\", nonce = \"414d535c1144225218:ef255fff6bbafa40147fbd960f128803\", uri = \"sip:192.168.0.4:5066\", response = \"b3cd2617f79b96adad84706754ae91e6\", algorithm = MD5\npassword = \"ab1234\" (!)\nwe get a hash filename \"4553.hash\" with:\n`$sip$*sip:192.168.0.4:5066**4553*3CXPhoneSystem*REGISTER*sip*sip:192.168.0.4:5066*5066*414d535c1144225218:ef255fff6bbafa40147fbd960f128803****MD5*b3cd2617f79b96adad84706754ae91e6`\nstarting hashcat with params:\n`hashcat64.exe -a 3 -m 11400 4553.hash ?l?l?d?d?d?d --force`\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>hashcat64 -a 3 -m 11400 4553.hash ?l?l?d?d?d?d --force\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz, skipped.\nDevice #2: Intel(R) HD Graphics 4000, 311/1246 MB allocatable, 16MCU\n\nHashfile '4553.hash' on line 1 ($sip$*sip:192.168.0.4:5066): Salt-length exception\nNo hashes loaded.\nStarted: Wed Jun 27 16:41:52 2018\nStopped: Wed Jun 27 16:41:52 2018\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>\nBut if we remove the \":\" in the field of nonce, then we will have nonce = \"414d535c1144225218ef255fff6bbafa40147fbd960f128803\" and we will never find a password.\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>hashcat64 -a 3 -m 11400 4553.hash ?l?l?d?d?d?d --force\nhashcat (v4.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Core(TM) i7-3770K CPU @ 3.50GHz, skipped.\nDevice #2: Intel(R) HD Graphics 4000, 311/1246 MB allocatable, 16MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nApplicable optimizers:\n Zero-Byte\n Not-Iterated\n Single-Hash\n Single-Salt\n* Brute-Force\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.\nSession..........: hashcat\nStatus...........: Exhausted\nHash.Type........: SIP digest authentication (MD5)\nHash.Target......: $sip$sip:192.168.0.4:506645533CXPhoneSystem*REG...ae91e6\nTime.Started.....: Wed Jun 27 17:06:21 2018 (2 secs)\nTime.Estimated...: Wed Jun 27 17:06:23 2018 (0 secs)\nGuess.Mask.......: ?l?l?d?d?d?d [6]\nGuess.Queue......: 1/1 (100.00%)\nSpeed.Dev.#2.....:  5233.7 kH/s (3.09ms) @ Accel:4 Loops:2 Thr:512 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 6760000/6760000 (100.00%)\nRejected.........: 0/6760000 (0.00%)\nRestore.Point....: 10000/10000 (100.00%)\nCandidates.#2....: uq0123 -> xq8373\nHWMon.Dev.#2.....: N/A\nStarted: Wed Jun 27 17:06:20 2018\nStopped: Wed Jun 27 17:06:23 2018\nc:\\Users\\sasha\\Downloads\\hashcat-4.1.0>\nthat would be convinced I recounted manually:\nha2 = md5.new(\"REGISTER:sip:192.168.0.4:5066\").hexdigest();\nha1 = md5.new(\"4553:3CXPhoneSystem:ab1234).hexdigest();\nresponse = md5.new(ha1+\":414d535c1144225218:ef255fff6bbafa40147fbd960f128803:\"+ha2).hexdigest();\nresponse = \"b3cd2617f79b96adad84706754ae91e6\" # the password correct\nelse if nonce = \"414d535c1144225218ef255fff6bbafa40147fbd960f128803\"\nresponse = md5.new(ha1+\":414d535c1144225218ef255fff6bbafa40147fbd960f128803:\"+ha2).hexdigest();\nresponse = \"e3f31b963dc6cfce8b56e58f75be39d1\" #and it will be incorrect\n```\nor am I wrong? \n\nWindows 10 x64bit. do not change/fix, thanks for the help, I will compile for myself separately. \n",
    "evrial": "Same issue, everything latest. win10, nvidia driver, hashcat64. \nexample0.cmd and benchmark doesn't run either. Older hashcat all the same.. 398.36 from 26/06/2018. 1060 here, reinstalled nvidia driver, nothing changed.. \nhashcat-crash.zip\nCrash dump attached. I deleted the file \nC:\\WINDOWS\\System32\\DriverStore\\FileRepository\\igdlh64.inf_amd64_250db833a1cd577e\\igdrclneo64.dll\nAnd hashcat works fine. Clearly should be fixed in hashcat.\n. Probably the thing is IGC disabled when no displays connected to it.. These tools work only with text files, but I wish to run naive (combinator/mask/hybrid) cracking with excluded dict file.. Yea I'm perfectly aware of everything you said, but using file is the same as dict attack and use unnecessary large disk space. Do you think it would make sense for WPA?. \ud83e\udd14Good point, but I don't want to waste my space anyways. \ud83d\ude1e . Thanks but -S doesn't work \n\nInvalid attack mode (-a) value specified in slow-candidates mode.. Much better now but still limited \ud83d\ude3a \nGuess.Base.......: Pipe\nSpeed.#1.........:   236.1 kH/s (6.54ms) @ Accel:128 Loops:64 Thr:64 Vec:1. Reworked file into mask:\nGuess.Mask.......: 050?d?d?d?d?d?d?d [10]\nGuess.Queue......: 1/35 (2.86%)\nSpeed.#1.........:   357.7 kH/s (12.99ms) @ Accel:64 Loops:16 Thr:1024 Vec:1. \n",
    "cyptus": "same here, also on win10 with nvidia driver and hashcat64. i am also running an gtx 1060 (6 GB) and reinstalled the nvidia drivers - still no output. same happens on hashcat64.exe -I command (i am using hashcat v3.6.0). this also worked for me! where did you find this and the crash dump?\n. ",
    "Gray-0men": "Also, side note, for some reason hashcat is not seeing my GPU but can find my CPU just fine.\nAMD FX(tm)-8350 Eight-Core Processor\nAdvanced Micro Devices, Inc. [AMD/ATI] Ellesmere [Radeon RX 470/480] <--- it's the 480\nidk if those two symptoms correlate but just thought I should mention that as well. Also I just found out if I rename the folder to 6.0.0 then so far hashcat seem to run fine without issues other than my GPU being missing for some reason.\n\nroot@TheOmen:~# hashcat -I\nhashcat (v4.1.0) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : The pocl project\n  Name    : Portable Computing Language\n  Version : OpenCL 1.2 pocl 1.1 None+Asserts, LLVM 6.0.0, SPIR, SLEEF, DISTRO, POCL_DEBUG\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 1\n    Vendor         : AuthenticAMD\n    Name           : pthread-AMD FX(tm)-8350 Eight-Core Processor\n    Version        : OpenCL 1.2 pocl HSTR: pthread-x86_64-pc-linux-gnu-bdver1\n    Processor(s)   : 8\n    Clock          : 4054\n    Memory         : 4096/13893 MB allocatable\n    OpenCL Version : OpenCL C 1.2 pocl\n    Driver Version : 1.1. well I just checked LVMM's main site and as of 2 days ago that updated from 6.0.0 to 6.0.1 so that would explain the sudden change . ",
    "komawoyo": "Hello, what did you do different from me? \n\n. Thank you for the suggestion, single GPU does not work also. fyi, these are all Vega 56\n\n. I'm able to use -a 6 to crack the password so the masking seems to work at least for that option \n\n. I ran the examples within the folders and they worked fine. the moment I changed to -a 3 mode, it does not work. I do not think -m 2500 is the problem because its able to crack it just fine with -a 6 mode. I have tried other drivers. I have not tried on linux. Everything works on my Intel GPU.  not sure whats the issue with AMD and -a 3 mode when other attacks works perfectly fine - anyways,  I'll close this issue soon - it looks like no one has the same problem as me using AMD \n. I would like to mention that using the maskprocessor and piping it works compared to the -a 3 mode\n. ",
    "thinksilicon": "Thanks, here's the dump:\n```\nHashmode: 0 - MD5\nProgram received signal SIGSEGV, Segmentation fault.\n0x0000000000000000 in ?? ()\n(gdb) bt\n0  0x0000000000000000 in ?? ()\n1  0x00007fffed10deb7 in ?? () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libcpu_device.so\n2  0x00007fffed10264b in ?? () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libcpu_device.so\n3  0x00007fffed103b16 in clDevCreateDeviceInstance () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libcpu_device.so\n4  0x00007fffee1af0c5 in ?? () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libintelocl.so\n5  0x00007fffee16c549 in ?? () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libintelocl.so\n6  0x00007fffee14d722 in ?? () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libintelocl.so\n7  0x00007fffee129a41 in clCreateContext () from /opt/intel/opencl-1.2-6.4.0.25/lib64/libintelocl.so\n8  0x0000000000456116 in ?? ()\n9  0x000000000045ba09 in ?? ()\n10 0x0000000000417639 in ?? ()\n11 0x0000000000417c2c in ?? ()\n12 0x0000000000402d31 in ?? ()\n13 0x00007ffff7413f4a in __libc_start_main () from /lib64/libc.so.6\n14 0x0000000000402d6a in ?? ()\n(gdb) \n```\ndoes that help in any way?. Yeah, looks to be intel's fault. I'll try with Ubuntu, and maybe also try to reach out to Intel (don't think I'll get any response though).\nHashcat is working nicely with Intel's drivers on my i5-7200U (and openSUSE with linux 4.17.2). It's only a laptop though, so I'm afraid it'll burn after a while.... Alright, I could verify that it's a problem with the distribution-kernel of openSUSE Leap. It's running fine with debian 9 (4.9.88).\nThanks for your help!. ",
    "skelsec": "You may merge this into mine :) issue here\n@mubix The issue has a solution as well but currently overwrites the -m13100 flag. Bit of a manual work but it's tested.. ",
    "DasExperimentator": "Thanks! \nI also searched for a maximum nonce length, but I didn't find an exact answer. Moreover, from my experience, nonce is not always a number. For example, nonces from Asterisk PJSIP contain forward slashes (though, the length was still less than 50 characters in that case).. I am testing the fix suggested in #1603 . It seem to work fine, but there's an issue if I try to restore the session afterwards. Whenever hashcat is started with the --restore option, I get an error:\nHash '$sip$*': Line-length exception\n. I just recompiled the hashcat from master. The --restore problem is still there, although now the error is different:\nHash '$sip$*': Separator unmatched\nNo hashes loaded.\nMy command to start the hashcat is:\nhashcat --session 111 -O -w 3 -a 3 -m 11400 '$sip$***1234567890*098765431*REGISTER*sip*10.10.10.10**5df64cc15b4b2c611XFc619ca4ebc1f5c02ca2bc1db314e52423a6*a39111119411168a*00000001*auth*MD5*14bfffbfe3eeeea1e2b3aaa4f16784ad'  --increment --increment-min 4   ?a?a?a?a?a?a?a?a?a?a?a?a?a\n(hashes and other data are replaced with dummy values, on purpose)\nThis starts the hashing normally (even with the dummy values). Then I stop it with 'c', wait until hashcat finishes, and then try to restore the session with:\nhashcat --session 111 --restore\nThat's when hashcat gives me the 'Separator unmatched' error.\nAm I doing something wrong?. @philsmd , wow! That was fast!\nI just tested the latest master on a freshly installed Ubuntu 18.04 LTS. :)\nEverything works perfectly fine. '--restore' worked flawlessly for the hash in a file and for the hash in a command line. I can confirm the issue is resolved.\nThanks a lot for all the help and support!!!. ",
    "madtomic": "Please add this new algorithm.\nThis might be handy.\nhttps://github.com/kholia/JohnTheRipper/commit/a24a26f8cf055311b3676b95204c52d6eded42e4. ",
    "bojanv55": "Removed Intel Graphic Card drivers, installed OpenCL Runtime. Works now ok.... Crazy. I just removed from system Intel Graphic drivers, and that SDK for OpenCL (since it was written on website to be downloaded and used), and after restart it works!. Seems working somewhat with new beta.\n```\nInitializing device kernels and memory...21 warnings and 1608 errors generated.\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\nCompilation started\nIn file included from 1:11:\nOpenCL\\inc_types.cl:6:9: error: unknown type name 'uchar'; did you mean 'char'?\nOpenCL\\inc_types.cl:7:9: error: unknown type name 'ushort'; did you mean 'short'?\nOpenCL\\inc_types.cl:8:9: error: unknown type name 'uint'; did you mean 'int'?\nOpenCL\\inc_types.cl:9:9: error: unknown type name 'ulong'; did you mean 'long'?\nOpenCL\\inc_types.cl:30:9: error: unknown type name 'uchar8'; did you mean 'char'?\nOpenCL\\inc_types.cl:22:28: note: expanded from macro 'VTYPE'\nOpenCL\\inc_types.cl:21:28: note: expanded from macro 'CONCAT'\n:2:1: note: expanded from here\nIn file included from 1:11:\nOpenCL\\inc_types.cl:31:9: error: unknown type name 'ushort8'; did you mean 'short'?\nOpenCL\\inc_types.cl:22:28: note: expanded from macro 'VTYPE'\nOpenCL\\inc_types.cl:21:28: note: expanded from macro 'CONCAT'\n:2:1: note: expanded from here\nIn file included from 1:11:\nOpenCL\\inc_types.cl:32:9: error: unknown type name 'uint8'\nOpenCL\\inc_types.cl:22:28: note: expanded from macro 'VTYPE'\nOpenCL\\inc_types.cl:21:28: note: expanded from macro 'CONCAT'\n:2:1: note: expanded from here\nIn file included from 1:11:\nOpenCL\\inc_types.cl:33:9: error: unknown type name 'ulong8'; did you mean 'long'?\nOpenCL\\inc_types.cl:22:28: note: expanded from macro 'VTYPE'\nOpenCL\\inc_types.cl:21:28: note: expanded from macro 'CONCAT'\n:2:1: note: expanded from here\nIn file included from 1:11:\nOpenCL\\inc_types.cl:54:10: error: implicit declaration of function 'as_ulong' is invalid in OpenCL\nOpenCL\\inc_types.cl:54:28: error: called object type '' is not a function or function pointer\nOpenCL\\inc_types.cl:66:4: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_types.cl:66:17: error: member reference base type 'u64x' (aka 'long') is not a structure or union\nOpenCL\\inc_types.cl:67:4: error: member reference base type 'u32x' (aka 'int') is not a structure or union\n...\nOpenCL\\inc_types.cl:924:33: error: member reference base type 'int' is not a structure or union\nOpenCL\\inc_types.cl:929:21: error: implicit declaration of function 'as_uchar8' is invalid in OpenCL\nOpenCL\\inc_types.cl:929:21: note: did you mean 'as_uchar4'?\nOpenCL\\inc_types.cl:924:20: note: 'as_uchar4' declared here\nOpenCL\\inc_types.cl:929:34: error: member reference base type 'int' is not a structure or union\nOpenCL\\inc_types.cl:934:10: error: implicit declaration of function 'rotate' is invalid in OpenCL\nOpenCL\\inc_types.cl:1039:32: error: member reference base type 'const u32x' (aka 'const int') is not a structure or union\nOpenCL\\inc_types.cl:1039:99: error: member reference base type 'const u32x' (aka 'const int') is not a structure or union\nOpenCL\\inc_types.cl:1041:21: error: member reference base type 'const u64x' (aka 'const long') is not a structure or union\nOpenCL\\inc_types.cl:2011:3: error: unknown type name 'uint4'\nIn file included from 1:12:\nOpenCL\\inc_common.cl:104:19: error: implicit declaration of function 'atomic_inc' is invalid in OpenCL\nOpenCL\\inc_common.cl:111:5: error: implicit declaration of function 'atomic_dec' is invalid in OpenCL\nOpenCL\\inc_common.cl:111:5: note: did you mean 'atomic_inc'?\nOpenCL\\inc_common.cl:104:19: note: 'atomic_inc' declared here\nOpenCL\\inc_common.cl:157:21: error: implicit declaration of function 'log2' is invalid in OpenCL\nOpenCL\\inc_common.cl:59902:3: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59842:3: note: expanded from macro 'PACKVS44'\nOpenCL\\inc_common.cl:59830:16: note: expanded from macro 'PACKVS4'\nOpenCL\\inc_common.cl:59902:3: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59842:3: note: expanded from macro 'PACKVS44'\n...\nOpenCL\\inc_common.cl:59848:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59839:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59849:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59836:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59849:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59837:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59849:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59838:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59849:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59839:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59850:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59836:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59850:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59837:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59850:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59838:8: note: expanded from macro 'PACKSV4'\nOpenCL\\inc_common.cl:59902:107: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_common.cl:59850:3: note: expanded from macro 'PACKSV44'\nOpenCL\\inc_common.cl:59839:8: note: expanded from macro 'PACKSV4'\n...\nOpenCL\\inc_simd.cl:1159:258: note: expanded from macro 'unpackv'\n1:241:5: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_simd.cl:1159:303: note: expanded from macro 'unpackv'\n1:241:5: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_simd.cl:1159:348: note: expanded from macro 'unpackv'\n1:241:5: error: member reference base type 'u32x' (aka 'int') is not a structure or union\nOpenCL\\inc_simd.cl:1159:393: note: expanded from macro 'unpackv'\n1:253:19: error: implicit declaration of function 'get_local_id' is invalid in OpenCL\n1:1020:19: error: implicit declaration of function 'get_local_size' is invalid in OpenCL\nCompilation failed\n\nDevice #2: Kernel ./OpenCL/m02500-pure.cl build failed - proceeding without this device.\n\nDictionary cache hit:\n Filename..: HashesOrg\n Passwords.: 446426189\n Bytes.....: 4456967734\n Keyspace..: 446426189\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit =>\n```. ",
    "RAN1": "Currently the first library pathname checked is the executing shell's $PWD/libhashcat. Because that pathname is copied from the library to executables, this is true of all executables linked, whether the library's in hashcat/ or the library directory. If there isn't a libhashcat in $PWD, then the default library paths are checked. This can cause misbehavior, so the PR changes it to the executable path for the initial build (in case the library is used in place) and again after install to the library directory.. > This sounds really strange to me. In Linux, there's no library search path for \".\" because of the security implication this creates. Here's an older issue that dealt with the same problem: #956 \nAs far as I can tell this is default behavior with macOS libraries if at build time the output isn't to an absolute path and the install path isn't specified.\n\nWait here, what kind of misbehavior are you talking about?\n\nI meant it is misbehavior for more or less clear reasons.\n\nOK, but wouldn't this create a relative path which is what we need to avoid (see the issue linked above)?\n\nIt's effectively the same as using $ORIGIN. The alternative is to just pass the library install path to -install_name and remove the changes to install_library and install_hashcat.. On macOS, library pathnames are hardcoded in the executable's load commands and they are checked first at runtime. If the path is \"relative/libfoo\" then it will look in \"./relative/libfoo\" first. This will cause problems similar to the ones RPATH causes.\nYes, there is the equivalent DYLD_LIBRARY_PATH on macOS, but it has lower precedence than the hardcoded paths.\nEDIT: I tested this badly, DYLD_LIBRARY_PATH is checked before everything else, the hardcoded paths only have precedence over the regular library search paths.. I amended my PR to use only the library install path.. My benchmarks also showed no performance change. Compiling both versions with clang produces practically identical LLVM IR, so the final pass is probably just optimized out.\nI haven't been able to get your code to pass the selftest, I also tried it with:\nfor (pos1 = 64, pos4 = 16; pos1 < len - 64; pos1 += 64, pos4 += 16)\nI think it has something to do with this:\nfor (MAYBE_VOLATILE u32 i = lid; i < 64; i += lsz)\n{\n    w[i] = pws[gid].i[i]; // i == lid\n}\n\nThis seems like it copies from 64 different passwords from global into 1 password in local.. I still can't get it to work on my GPUs but my CPU failed (at first, works now) because w is declared u32 * in:\nDECLSPEC void md4_update_vector_local (md4_ctx_vector_t *ctx, __local u32 *w, const int len, const u32x w0r)\n\nIt should be u32x *. The above was due to a typo, I didn't know how to apply a patch. I still can't get it to run on anything other than CPUs.. Hi all, sorry about the late reply.\nThe main reason for the PR was just that the behavior didn't match the flag name. I forgot about the help description, and I didn't notice that the throttle warnings would be set off when temperature abort isn't set.\nThe only other reason was a cosmetic issue with hwmon-less systems, where the hwmon and temp abort flags would prevent the hwmon-not-detected message from displaying. However it's no longer a problem so it doesn't have any significance here.\nThe most recent commit is probably the best way to handle it anyways, again sorry for not seeing this earlier.. ",
    "w3soul": "Thanks jsteube,\nCan you think of any possible solutions ?\nI installed kali almost 20 times just to get hashcat to work, because every single time i tried tons of possible solutions and then ended up at broken OS.\nIf you want i can provide you ssh access for a deeper look (if you have some time please)?\nThanks, W.. Love it, But can we please debug at Kali 2018 because i am (and really wanted to use) Kali as my pentest OS. I have Ubuntu 18.04 in VM. So it will be much much appreciated if we can debug it in Kali please ?. No problem bro, But if i am understanding correctly you can help debug only if i can install Ubuntu 16.04 or 18.04? Correct ?. Will do man. Appreciate your help.\nThanks, W.. Hey man, thanks for the follow up.\nSo the update is - hashcat 4.1.0 (from github or hashcat website) i was receiving same error no matter what. I tried every possible solution available on the internet without success.\nbut i garbed the binaries of 4.0.1 (also tried 4.0.0 and 3.6) from https://hashcat.net/hashcat/ and they all worked right out of the box with no issues.\nSo:\nroot@kali: hashcat -b (OBJECT_ALLOCATION_FAILURE for wpa2,zip,office etc)\nroot@kali:~/Downloads/hashcat4.0.1# ./hashcat -b (Works well)\nSo something is definitely going in 4.1.0 and i think the problem is with m02500.cl or m13600.cl.\nAny ideas when the next/new version will be avilable in the kali repos ?\nI am so sorry man, but installing ubuntu as a standalone OS and configuring 300+ pentest tools is a next level of pain in the butt.\nThanks & Hope it helps. W.. Oh - By the way if you want i will be happy to provide you the ssh access to kali box if that help resolving the issue in future releases.\nThanks and appreciated. W.. Thanks man but Yes, Still same error for wpa.\nVersion check: (For verification)\nroot@kali:~/Downloads/hashcat-4.2.0# ./hashcat --version\nv4.2.0\nBenchmarking\nroot@kali:~/Downloads/hashcat-4.2.0# ./hashcat -b\nhashcat (v4.2.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n Device #2: Not a native Intel OpenCL runtime. Expect massive speed loss.\n             You can use --force to override, but do not report related errors.\nOpenCL Platform #1: NVIDIA Corporation\n======================================\n Device #1: GeForce GTX 960, 492/1968 MB allocatable, 8MCU\nOpenCL Platform #2: The pocl project\n\nDevice #2: pthread-Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\n\nOpenCL Platform #3: Intel(R) Corporation\n\nDevice #3: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\nHashmode: 0 - MD5\nSpeed.Dev.#1.....:  6633.1 MH/s (80.21ms) @ Accel:128 Loops:512 Thr:1024 Vec:4\nHashmode: 100 - SHA1\nSpeed.Dev.#1.....:  2301.2 MH/s (72.13ms) @ Accel:256 Loops:128 Thr:640 Vec:1\nHashmode: 1400 - SHA-256\nSpeed.Dev.#1.....:   819.3 MH/s (81.06ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nHashmode: 1700 - SHA-512\nSpeed.Dev.#1.....:   277.2 MH/s (75.15ms) @ Accel:128 Loops:32 Thr:640 Vec:1\nHashmode: 2500 - WPA-EAPOL-PBKDF2 (Iterations: 4096)\nclEnqueueNDRangeKernel(): CL_MEM_OBJECT_ALLOCATION_FAILURE\nStarted: Sun Aug  5 15:21:08 2018\nStopped: Sun Aug  5 15:21:37 2018\n\nnvidia-smi results:\nroot@kali:~/Downloads/hashcat-4.2.0# nvidia-smi \nSun Aug  5 15:23:33 2018     \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 390.77                 Driver Version: 390.77                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 960     Off  | 00000000:01:00.0  On |                  N/A |\n| 38%   50C    P0    28W / 120W |    640MiB /  1968MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID   Type   Process name                             Usage      |\n|=============================================================================|\n|    0       880      G   /usr/lib/xorg/Xorg                            55MiB |\n|    0      1155      G   /usr/bin/gnome-shell                          53MiB |\n|    0      1437      G   /usr/lib/xorg/Xorg                           333MiB |\n|    0      1525      G   /usr/bin/gnome-shell                         193MiB |\n+-----------------------------------------------------------------------------+\nThanks, . Thank you for all your help man. Yes, i noticed that 640mb usage as well.\nSo - I haven't tested shutting down the X11 solution but i have checked the beta version  and it worked right out of the box with no shutting down of anything. It gives me the 102.3 kH/s for wpa (this is the exact speed i was expecting with my GPU, speed with my i7 CPU is 14000H/s)\nI tried both wpa (2500) and zip (13600) and they both worked.\nBelow are benchmark results.\nroot@kali:~/Downloads/hashcat-4.2.0-beta# ./hashcat -b\nhashcat (v4.2.0-4-ge67195aa) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n\nDevice #2: Not a native Intel OpenCL runtime. Expect massive speed loss.\n             You can use --force to override, but do not report related errors.\nOpenCL Platform #1: NVIDIA Corporation\n======================================\nDevice #1: GeForce GTX 960, 492/1968 MB allocatable, 8MCU\nOpenCL Platform #2: The pocl project\n====================================\nDevice #2: pthread-Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\nOpenCL Platform #3: Intel(R) Corporation\n========================================\nDevice #3: Intel(R) Core(TM) i7-6700K CPU @ 4.00GHz, skipped.\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 0 - MD5\nSpeed.Dev.#1.....:  6717.2 MH/s (79.24ms) @ Accel:128 Loops:512 Thr:1024 Vec:4\nHashmode: 100 - SHA1\nSpeed.Dev.#1.....:  2220.7 MH/s (74.56ms) @ Accel:256 Loops:128 Thr:640 Vec:1\nHashmode: 1400 - SHA-256\nSpeed.Dev.#1.....:   830.9 MH/s (80.02ms) @ Accel:128 Loops:64 Thr:1024 Vec:1\nHashmode: 1700 - SHA-512\nSpeed.Dev.#1.....:   281.3 MH/s (74.10ms) @ Accel:128 Loops:32 Thr:640 Vec:1\nHashmode: 2500 - WPA-EAPOL-PBKDF2 (Iterations: 4096)\nSpeed.Dev.#1.....:   102.6 kH/s (78.64ms) @ Accel:128 Loops:32 Thr:1024 Vec:1\nHashmode: 1000 - NTLM\nSpeed.Dev.#1.....: 11248.3 MH/s (94.51ms) @ Accel:128 Loops:1024 Thr:1024 Vec:2\nHashmode: 3000 - LM\nSpeed.Dev.#1.....:  5632.2 MH/s (94.63ms) @ Accel:256 Loops:1024 Thr:256 Vec:1\nHashmode: 5500 - NetNTLMv1 / NetNTLMv1+ESS\nSpeed.Dev.#1.....:  5557.5 MH/s (47.76ms) @ Accel:128 Loops:256 Thr:1024 Vec:1\nHashmode: 5600 - NetNTLMv2\nSpeed.Dev.#1.....:   491.5 MH/s (67.63ms) @ Accel:128 Loops:32 Thr:1024 Vec:1\nHashmode: 1500 - descrypt, DES (Unix), Traditional DES\nSpeed.Dev.#1.....:   259.8 MH/s (64.42ms) @ Accel:8 Loops:1024 Thr:256 Vec:1\nHashmode: 500 - md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5) (Iterations: 1000)\nSpeed.Dev.#1.....:  2537.2 kH/s (92.32ms) @ Accel:1024 Loops:1000 Thr:32 Vec:1\nHashmode: 3200 - bcrypt $2*$, Blowfish (Unix) (Iterations: 32)\nSpeed.Dev.#1.....:     3971 H/s (31.50ms) @ Accel:16 Loops:4 Thr:8 Vec:1\nHashmode: 1800 - sha512crypt $6$, SHA512 (Unix) (Iterations: 5000)\nSpeed.Dev.#1.....:    42094 H/s (76.87ms) @ Accel:512 Loops:128 Thr:32 Vec:1\nHashmode: 7500 - Kerberos 5 AS-REQ Pre-Auth etype 23\nSpeed.Dev.#1.....: 70882.1 kH/s (58.96ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nHashmode: 13100 - Kerberos 5 TGS-REP etype 23\n^C\nWould you still like me to try shutting down x11and testing hashcat from console? if yes, then i will need some time because i have google how to do this :) \nThanks, W.. Awesome!!! Can't wait for this to be included in the original kali repository!!. Are you sure it's -m 1811 ?? I am not seeing 1811 hashmode, is it 1800 ?. ",
    "nyxgeek": "With John the Ripper you can use the 'external' filters to throw out candidate words that don't meet criteria before hashing takes place, but after the rules are applied. I'm hoping something similar can be implemented.. ",
    "kipilk0": "Yes, blockchain.info/blockchain.com\nI forgot my second password, for paymets. Amazing. ",
    "fakirpic": "just  saw it thanx. ",
    "0Nak": "This is because you have the old version of hashcat, try to install the newest. and it works?. Nice!! I have the same problem. ",
    "MaximAndreev1011": "Decided..... \n1. apt-get remove hashcat\n2. git clone https://github.com/hashcat/hashcat.git\n3. cd hashcat\n4. make\n5. make install (at this point, I made an error...include/ext_OpenCL.h:15:10: fatal error: CL/cl.h: No such file or directory #include ......but I decided .... apt-get install opencl-headers -> make install)\n. Yes !). ",
    "yinjiahjk": "thank you!. ",
    "imperia777": "Hello,\nI have mining rig with 4 devices and only 4gb ram.\nWith version 4.0.1 I can run bruteforce scan, but with version 4.1 onward I cannot. So memory usage went up since version 4.1?. ",
    "theherp": "Similar problem on $bitcoin$64$, which oddly enough does run on v3.6.0. ",
    "qiufengqq": "\nNot a hashcat error\n\nyes  It's because lack of code for a lib named libiconv, I download the code win-libiconv, and copy the code libiconv.c to hashcat dir, add it in Makefile, rebuild hashcat , it runs well now. thanks a lot.. the hashcat version is 4.1.x or later ,will find the error above,  version old than 4.0.x is run well.. ",
    "zzulb": "Hello, we have encountered the same problem. Can you send me the relevant files (Makefile, libiconv.c)? Thank you! @qiufengqq . ",
    "scaery": "...going back to hashcat version 4.0.1 on Kali 2018.2 i386 live iso and it works again. . On every other box it works as usal, the sources from github inlcuded. They (VM creators of Kali) must have some other issue at their latest release. Just stumbled up on this.... if you want to reproduce download Kali from Offensive Security or fill a bugreport.\nhttps://images.offensive-security.com/virtual-images/kali-linux-2018.3-vm-i386.7z\n84715b351460cadad7e5d87e4034bfc50a9befc3904205bc6ca0afc6def61066  kali-linux-2018.3-vm-i386.7z\nThe error truely is still in their 2018.3 i368 Release. I think it can be closed now, as it`s not anymore related to the topic in here. But be warned about it and choose a different VM wisely.\n. Reported to Kali bugtracker!\nhttps://bugs.kali.org/view.php?id=4962. Could this be somehow related to #1683 ???\nI got the same issue. Can you try Kali 2018.2 live iso (Kernel: Linux kali 4.15.0-kali2-686-pae) and confirm. Then we can address this issue back to the right direction. Also, try a x64 machine as well.. ",
    "deargle": "Probably related to #1709 and #1695 . I found this same problem yesterday, https://github.com/hashcat/hashcat/issues/1709 replicated on live iso (in virtualized environment).\nIn my case, it isnt the first word per se, but rather, the first word from the current block of candidates being tested.\nPS -- issue not present on x64. I'm a noob with manual driver install but I'll give it a shot. Following this: https://github.com/intel/compute-runtime/blob/master/documentation/BUILD_Ubuntu.md. ",
    "slashbnl": "ok, no problem in that case. just figured you need to have 2 ?h?h for 1 hex ascii. ",
    "iceypotato": "I looked at the article, but I don't know to convert it to 64 bytes. ",
    "mathitam": "worked after installing nvidia driver. thanks . ",
    "steamp0rt": "Hashcat 3.6.0 works with WPA2.. It says \"15.12 or later\"... and I have 18.9.3. Also, yes, the beta works for some reason.... ",
    "SnakePin": "Can confirm, same problem happens with RX580 8GB and 18.10.1. And beta only works when --self-test-disable is present.. And also it is not stuck on that text, program just quits after that text is displayed if you look closely to the console log.. Seems like problem is fixed but only works if --self-test-disable present.\n\n*Device #1: ATTENTION! OpenCL kernel self-test failed.\nYour device driver installation is probably broken.\nSee also: https://hashcat.net/faq/wrongdriver\nAborting session due to kernel self-test failure.\nYou can use --self-test-disable to override this, but do not report related errors.. \n",
    "gavriilos": "(Thanks pointing me here @magnumripper)\nI second @magnumripper and @roycewilliams opinion that this should have both an option to disable and an option to increase the timeout. As I described on #1744 I am faced with a real use case that was broken by this stdin timeout.\nd4123333c0a6f7836df8ce40b56b9dc308da2925 does not help on my use case because the candidate generator I am using takes a long time before outputting the first candidate.. ",
    "imPRAGMA": "Thanks @jsteube how will I know when this is in a official binary release?. ",
    "frederickMaster": "@jsteube The problem has been fixed . Thanks a lot.. ",
    "Naufragous": "Indeed, you are right.\nThere definitely is some confusion, given that Alexey Degtyarev is both the maintainer of that implementation and the co-author of the RFC. I found the rationale behind his approach in the commit message of adegtyarev/streebog@dd005b5cd681ea01665c73298ba908ddf8a62851:\n\n\nFeature: command line options \"-e\" introduced (switch endianness). The standard does not specifies explicitly how to output the resulting hash. This implementation outputs hash in hexadecimal format in order how bytes are represented in memory - least significant first. With this option set, program outputs digest in hexadecimal format in reversed order - most significant first.\n\n\nI wonder how accurate this statement is, given that all the example digests are presented in big-endian order. I guess we should stick with big-endian, since it is more intuitive from the user point of view.\nWhat needs to be fixed is the ascii_digest branch for mode 11800 (Streebog-512). Currently, if you crack the example hash you get the output\na4db5b5dee898f8c110e[...]:hashcat\ninstead of\n5d5bdba48c8f89ee6c0a[...]:hashcat\nI'll amend the commit so that we won't need to open another PR.. > I would expect even deprecated schemes to be potential cracking targets.\nThey still are, I just did not include a testing container since I figured that there won't be much development going on with the RIPEMD-160 kernels anymore.\n\nI have a set here that includes RIPEMD-160 - could they be used as a start?\n\nYes, they could and yes, I would have saved a bit of time if I came across your set earlier >_>\nI'll add RIPEMD-160 container headers to the test suite, thanks!. > replace the smart match operator with a normal function\nDone.\n\nIs the pygost working with pip3 as well?\n\nIt is, but since the python code is executed with python2 -c, pip2 should be used indeed. Done.\n\nOCD error\n\nDone :). >I assume you will push another some PR for the one kernel which is using the hooks.\nYes, 7zip and scrypt kernels are next on the TODO list.. Thank you for the comments, I really did forget about a few things.\n\nadd ODF to the human readable descriptions\nadd missing entry in docs/readme.txt\nadd missing entry in extra/tab_completion/hashcat.sh\nadd 18400 to SLOW_ALGOS\nmode 18400 should not be listed in COMMON_UNSALTED_MODES\ninterface.c: snprintf (&out_buf[...\nkernel: replace [16 * i + 0] with const i16\nkernel: group swaps together\n\nAll done.\n\nmissing hashconfig->hash_type\n\nDone, although not necessary for this hash mode.\n\nROUNDS_LIBREOFFICE should be ROUNDS_ODF12?\n\nProbably not... The ODF 1.2 standard does not require a specific iteration count beyond the 1,024 default. The parser expects anything between 1,000 and 999,999. The current LibreOffice version uses 100,000, that is why I choose it as the benchmark constant.\nUpdated the PR & rebased on current master (09ec2a9).. Update:\n- use perl modules instead of python code in the test suite\n- complete test suite with proper verify and passthrough branches\n- remove support for hash suffix generated by libreoffice2john.py\nRebased on current master (0db6913).. You are right, we don't need python code here. That's the just code I used while writing the kernel, and since I am not a perl monk I wrote it in python. But I have to rewrite this anyway, because right now there is no way to properly use the verify function.\nBtw the last time I commited python code to the test suite was because of Streebog hashing. Didn't find anything on CPAN for that either.. That's what I initially did. Afterwards I added the suffix buffer to ensure a better UX; you can take the output of libreoffice2john.py and throw it at hashcat without editing. But if this is not required, then I actually would be glad to get rid of the suffix! Simplifies the parsing.\n@jsteube, what will it be?. I'd be happy to use FIXED_LENGTH (like I did for the 2048 chars of ciphertext at the end), but the tokenizer will automatically omit the separating * only if I use VERIFY_LENGTH. Or I am missing something?. Done! :D. @s3inlc, ouch! :laughing:\nGH-1821. Well, the tests for 18500 run just fine. It was the 18400 case branch that took the hit :sweat_smile: . ",
    "freetom": "Sample generated from http://jwtbuilder.jamiekurtz.com/\nAlg: HS256\nKey: qwertyuiopasdfghjklzxcvbnm123456\neyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.{"iss":"Online JWT Builder","iat":1540992130,"exp":1572528130,"aud":"www.example.com","sub":"jrocket@example.com","GivenName":"JohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawdwadawdawdawdwaJohnnyawd","Surname":"Rock","Email":"jrocket@example.com","Role":["Manager","Project Administrator"]}.VkgW4Ljz1AydqUszqDk9xmO8VO7LnVMBaAXLjT0qbTU\n. I get the same output (using the JWT from my prev comment):\nhashcat-4.2.1> .\\hashcat32.exe -m 16500 xxxxx\\Desktop\\hash.txt -a 3 -D 1 --force\n[...]\nHashfile 'xxxx\\Desktop\\hash.txt' on line 1 (eyJ0eX...dqUszqDk9xmO8VO7LnVMBaAXLjT0qbTU): Token length exception\nNo hashes loaded.\nHashcat for Win64\nAmen. ",
    "mpgn": "Same with version 5 and the token used by @jsteube \n```\n\u22ca> ~/D/hashcat-5.1.0 ./hashcat64.bin -m 16500 jwt.txt    rockyou.txt  --force -O -r rules/best64.rule                                                                                     14:26:22\nhashcat (v5.1.0) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Gen9 HD Graphics NEO, 4095/12740 MB allocatable, 24MCU\n\nHashfile 'jwt.txt' on line 1 (eyJ0eX...dqUszqDk9xmO8VO7LnVMBaAXLjT0qbTU): Token length exception\nNo hashes loaded.\nStarted: Thu Jan 17 14:26:24 2019\nStopped: Thu Jan 17 14:26:24 2019\n```. ",
    "vincentcox": "Did anyone from this thread got a solution?. The 2 posts above my initial comment said otherwise. I also have the same issue, hence why I ask it.\n. For those having issues and need an alternative in the meantime: https://github.com/brendan-rius/c-jwt-cracker. ",
    "marku89": "Im not completely sure what is was , but could be non default filesystem. In this time i often used sparc filesystems and experiment a lot. It is a image of a 8MB PCMCIA slot card and dd the whole device. \nWith --keep-guessing its around 1 guess per second , but non of this keys are good. Is there a switch to use the old key check and not guess the filesystem on the device , i know this is very rare and 99% of the luks partitions are ext2-4 systems. \nI provide the luksheader for detailed troubleshooting.\nluksheader.zip\n. Thanks for your reply , now im sure there is no formation on it. I just read about this case , but nobody shown how i look like. \nSo i start testing this with many headers and cases, they never look like 0xffffffff. \n@magnumripper I also like your idea of warning, that your crypto block is suspicious. I mean this could happen if you had data corruption and blocks are not able to read , we all know old flash drives :)\n. ",
    "ricsirigu": "@jsteube yes, it's different. The encryption scheme used is the one before LUKS, using the cryptoapi of the 2.4 kernel.\nThe old disk can be mounted with the current kernel using the command \ncryptsetup create --cipher twofish-cbc-plain --key-size 256 --hash ripemd160 crypted disk.raw\nin our case we know that the encrypted data contains an ext3 file system and this information is useful to know if the tried password is a correct guess or not.\nDecrypting 16 bytes at offset 600h in a ext2/ext3 file system should produce 16 bytes of 00h.\nUnlike LUKS, that has an header with the information of the cipher used and the keys encrypted, in the 2.4 kernel there is no header but only raw data. \n. ",
    "soronrheeyi": "ok, cool where can I download (sorry I reported a bug) and what is the term command, because I'm pretty sure I updated everything. ",
    "mqus": "I've upgraded already but I'll try it (may take some time). ",
    "armin884": "-S is -S, --slow-candidates ? How does that work? I never used that before... Well my hash is HMAC-SHA1 (key = $salt) and the salt is given in hex.. ",
    "apatedolos": "I can confirm the same issue.. Clent works fine here also however the time to crack jumps quite significantly. \nOn a standalone machine with hash list using rockyou with rule it would only take 20 minutes to completely run.\nOnce connected to the brain server this jumped up to 147 days!. ok, noted. next time i'll rtfm.... that is some bottleneck.. ",
    "ZeroChaos-": "after poking around for a while, it seems that the problem is hashcat cannot use system xxhash.  every mainstream distro ships xxhash, can you please use the system version?. Forgive me, I don't know all the name/version mapping for ubuntu, but cosmic has xxhash\nhttps://packages.ubuntu.com/search?searchon=sourcenames&keywords=xxhash\nAlso, even if you aren't going to unbundle it, maybe you could allow to use the host version like for lzma?. this definitely works for me. thanks. the flag seems to expect -llzmasdk which I can't actually find in the 7-zip sdk.  Could maybe some documentation be added to explain the requirement and what is required to build this unbundled?. @anthraxx this sure doesn't work for me, I don't even see anything called lzmasdk inside the lzmasdk that would make -llzmasdk work, you have any insight here?. that's fair, but probably the request is still valid, just auto-enable the brain when it's a good idea.. ",
    "ExzoTikStyle": "\n\u042d\u0442\u043e \u0442\u043e, \u0447\u0442\u043e \u043c\u043e\u0436\u0435\u0442 \u043f\u0440\u043e\u0438\u0437\u043e\u0439\u0442\u0438 \u0434\u043e\u0432\u043e\u043b\u044c\u043d\u043e \u0431\u044b\u0441\u0442\u0440\u043e, \u043a\u043e\u0433\u0434\u0430 \u0434\u0435\u043b\u043e \u0434\u043e\u0445\u043e\u0434\u0438\u0442 \u0434\u043e scrypt. \u0412 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u044e\u0442\u0441\u044f \u0432\u0441\u0435 \u0440\u0435\u0441\u0443\u0440\u0441\u044b.\nHashcat \u0437\u0430\u043f\u0440\u0430\u0448\u0438\u0432\u0430\u0435\u0442 \u0431\u0435\u0441\u043f\u043b\u0430\u0442\u043d\u0443\u044e \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e\u0441\u0442\u044c \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432 \u043f\u0440\u0438 \u0437\u0430\u043f\u0443\u0441\u043a\u0435, \u0430 \u0432\u0440\u0435\u043c\u044f \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f OpenCL \u043e\u0442\u0432\u0435\u0447\u0430\u0435\u0442 \u0437\u0430 \u043e\u0442\u0432\u0435\u0442. \u0415\u0441\u043b\u0438 \u0441\u0440\u0435\u0434\u0430 OpenCL \u043e\u0434\u043e\u0431\u0440\u044f\u0435\u0442 \u0434\u043e\u0441\u0442\u0430\u0442\u043e\u0447\u043d\u043e\u0435 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0440\u0435\u0441\u0443\u0440\u0441\u043e\u0432 \u0434\u043b\u044f \u0434\u043e\u0441\u0442\u0443\u043f\u043d\u043e\u0441\u0442\u0438, \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 \u044d\u0442\u043e \u043d\u0435 \u0442\u0430\u043a, \u044d\u0442\u043e \u0431\u043e\u043b\u044c\u0448\u0435 \u043f\u043e\u0445\u043e\u0436\u0435 \u043d\u0430 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f OpenCL, \u0430 \u043d\u0435 \u043d\u0430 \u043f\u0440\u043e\u0431\u043b\u0435\u043c\u0443 hashcat.\n\u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043e\u0431\u0445\u043e\u0434\u043d\u043e\u0433\u043e \u043f\u0443\u0442\u0438 \u043f\u043e\u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c -D 1 (\u043f\u043e\u0441\u043b\u0435 \u0443\u0441\u0442\u0430\u043d\u043e\u0432\u043a\u0438 \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u0432\u044b\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f Microsoft opencl \u0434\u043b\u044f \u0432\u0430\u0448\u0435\u0433\u043e \u043f\u0440\u043e\u0446\u0435\u0441\u0441\u043e\u0440\u0430).\n\nI tried to display the image on the monitors via the integrated gpu, and the same thing. The computer stops responding to any action.. all the same. a dictionary cache is created, and freezes. The video card\ndoes not work, because temperatures do not rise, and the fans continue to\nnot work, because. no load\n\u0432\u0441, 4 \u043d\u043e\u044f\u0431. 2018 \u0433. \u0432 12:20, Jens Steube notifications@github.com:\n\nPlease retry with latest beta from https://hashcat.net/beta/\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1754#issuecomment-435654066,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Ajvz7ELCd7evwsO6eQvyTnpM3h0gIt88ks5urrFtgaJpZM4YJUdo\n.\n\n\n-- \n\u0421 \u0443\u0432\u0430\u0436\u0435\u043d\u0438\u0435\u043c,\u041a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u0438\u043d\n. Hashcat.log\nTOP.5bdebaeb.0007ad03   START\nTOP.5bdebaeb.0007ad03   user_options->separator :\nTOP.5bdebaeb.0007ad03   user_options->encoding_from utf-8\nTOP.5bdebaeb.0007ad03   user_options->encoding_to   utf-8\nTOP.5bdebaeb.0007ad03   user_options->rule_buf_l    :\nTOP.5bdebaeb.0007ad03   user_options->rule_buf_r    :\nTOP.5bdebaeb.0007ad03   user_options->session   hashcat\nTOP.5bdebaeb.0007ad03   user_options->limit 0\nTOP.5bdebaeb.0007ad03   user_options->skip  0\nTOP.5bdebaeb.0007ad03   user_options->attack_mode   0\nTOP.5bdebaeb.0007ad03   user_options->benchmark 0\nTOP.5bdebaeb.0007ad03   user_options->benchmark_all 0\nTOP.5bdebaeb.0007ad03   user_options->bitmap_max    18\nTOP.5bdebaeb.0007ad03   user_options->bitmap_min    16\nTOP.5bdebaeb.0007ad03   user_options->debug_mode    0\nTOP.5bdebaeb.0007ad03   user_options->example_hashes    0\nTOP.5bdebaeb.0007ad03   user_options->force 0\nTOP.5bdebaeb.0007ad03   user_options->gpu_temp_abort    0\nTOP.5bdebaeb.0007ad03   user_options->gpu_temp_disable  1\nTOP.5bdebaeb.0007ad03   user_options->hash_mode 15700\nTOP.5bdebaeb.0007ad03   user_options->hex_charset   0\nTOP.5bdebaeb.0007ad03   user_options->hex_salt  0\nTOP.5bdebaeb.0007ad03   user_options->hex_wordlist  0\nTOP.5bdebaeb.0007ad03   user_options->increment 0\nTOP.5bdebaeb.0007ad03   user_options->increment_max 256\nTOP.5bdebaeb.0007ad03   user_options->increment_min 1\nTOP.5bdebaeb.0007ad03   user_options->keep_guessing 0\nTOP.5bdebaeb.0007ad03   user_options->kernel_accel  0\nTOP.5bdebaeb.0007ad03   user_options->kernel_loops  0\nTOP.5bdebaeb.0007ad03   user_options->keyspace  0\nTOP.5bdebaeb.0007ad03   user_options->left  0\nTOP.5bdebaeb.0007ad03   user_options->logfile_disable   0\nTOP.5bdebaeb.0007ad03   user_options->loopback  0\nTOP.5bdebaeb.0007ad03   user_options->machine_readable  0\nTOP.5bdebaeb.0007ad03   user_options->markov_classic    0\nTOP.5bdebaeb.0007ad03   user_options->markov_disable    0\nTOP.5bdebaeb.0007ad03   user_options->markov_threshold  256\nTOP.5bdebaeb.0007ad03   user_options->nvidia_spin_damp  100\nTOP.5bdebaeb.0007ad03   user_options->opencl_info   0\nTOP.5bdebaeb.0007ad03   user_options->opencl_vector_width   0\nTOP.5bdebaeb.0007ad03   user_options->optimized_kernel_enable   0\nTOP.5bdebaeb.0007ad03   user_options->outfile_autohex   1\nTOP.5bdebaeb.0007ad03   user_options->outfile_check_timer   5\nTOP.5bdebaeb.0007ad03   user_options->outfile_format    3\nTOP.5bdebaeb.0007ad03   user_options->wordlist_autohex_disable  0\nTOP.5bdebaeb.0007ad03   user_options->potfile_disable   0\nTOP.5bdebaeb.0007ad03   user_options->progress_only 0\nTOP.5bdebaeb.0007ad03   user_options->quiet 0\nTOP.5bdebaeb.0007ad03   user_options->remove    0\nTOP.5bdebaeb.0007ad03   user_options->remove_timer  60\nTOP.5bdebaeb.0007ad03   user_options->restore   0\nTOP.5bdebaeb.0007ad03   user_options->restore_disable   0\nTOP.5bdebaeb.0007ad03   user_options->restore_timer 60\nTOP.5bdebaeb.0007ad03   user_options->rp_files_cnt  0\nTOP.5bdebaeb.0007ad03   user_options->rp_gen    0\nTOP.5bdebaeb.0007ad03   user_options->rp_gen_func_max   4\nTOP.5bdebaeb.0007ad03   user_options->rp_gen_func_min   1\nTOP.5bdebaeb.0007ad03   user_options->rp_gen_seed   0\nTOP.5bdebaeb.0007ad03   user_options->runtime   0\nTOP.5bdebaeb.0007ad03   user_options->scrypt_tmto   0\nTOP.5bdebaeb.0007ad03   user_options->segment_size  33554432\nTOP.5bdebaeb.0007ad03   user_options->self_test_disable 0\nTOP.5bdebaeb.0007ad03   user_options->slow_candidates   0\nTOP.5bdebaeb.0007ad03   user_options->show  0\nTOP.5bdebaeb.0007ad03   user_options->speed_only    0\nTOP.5bdebaeb.0007ad03   user_options->status    1\nTOP.5bdebaeb.0007ad03   user_options->status_timer  10\nTOP.5bdebaeb.0007ad03   user_options->stdout_flag   0\nTOP.5bdebaeb.0007ad03   user_options->usage 0\nTOP.5bdebaeb.0007ad03   user_options->username  0\nTOP.5bdebaeb.0007ad03   user_options->veracrypt_pim 0\nTOP.5bdebaeb.0007ad03   user_options->version   0\nTOP.5bdebaeb.0007ad03   user_options->workload_profile  1\nTOP.5bdebaeb.0007ad03   user_options->brain_client  0\nTOP.5bdebaeb.0007ad03   user_options->brain_client_features 3\nTOP.5bdebaeb.0007ad03   user_options->brain_server  0\nTOP.5bdebaeb.0007ad03   user_options->brain_port    6863\nTOP.5bdebaeb.0007ad03   user_options->brain_session 0\nTOP.5bdebaeb.0007ad03   hashes->hashlist_mode   5\nTOP.5bdebaeb.0007ad03   hashes->hashlist_format 0\nTOP.5bdebaeb.0007ad03   hashes->hashes_cnt  0\nTOP.5bdebaeb.0007ad03   hashes->digests_cnt 1\nTOP.5bdebaeb.0007ad03   hashes->digests_done    0\nTOP.5bdebaeb.0007ad03   hashes->salts_cnt   1\nTOP.5bdebaeb.0007ad03   hashes->salts_done  0\nTOP.5bdebaeb.0007ad03   SUB.5bdebaf1.000dfe1a   START\nTOP.5bdebaeb.0007ad03   SUB.5bdebaf1.000dfe1a   straight_ctx->dict  C:\\Users\\ExzoTikFruiT\\Desktop\\hashcat-5.0.0+33\\hashcat-5.0.0\\dict.txt\n. `C:\\Users\\ExzoTikFruiT\\Desktop\\hashcat-5.0.0>hashcat64.exe -m15700 -d 1 hash --status --force C:\\Users\\ExzoTikFruiT\\Desktop\\hashcat-5.0.0\\dict.txt\nhashcat (v5.0.0-34-g9baf728f) starting...\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) UHD Graphics 630, 4095/13050 MB allocatable, 24MCU\nDevice #2: Intel(R) Core(TM) i7-8700K CPU @ 3.70GHz, skipped.\n\nOpenCL Platform #2: NVIDIA Corporation\n\nDevice #3: GeForce GTX 1080 Ti, skipped.\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n* Single-Salt\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nWatchdog: Temperature abort trigger set to 90c\nIncreasing single-block device memory allocatable for --scrypt-tmto 1.\nIncreasing single-block device memory allocatable for --scrypt-tmto 2.\nDictionary cache built:\n Filename..: C:\\Users\\ExzoTikFruiT\\Desktop\\hashcat-5.0.0\\dict.txt\n Passwords.: 362880\n Bytes.....: 14152319\n Keyspace..: 362880\n* Runtime...: 0 secs`. > That's what I expected. Your are using the GPU, not the CPU. Please make sure to specify -D 1 (note the capital D, not d).\noh,thanks.I did not think that the register has such a value. Wait, is brute force scrypt inaccessible through the GPU? I have seen others do it.. ",
    "fakename12345cat": "I used the most recent hashcat - 11/29 and used -m 18200 and received an error - \"No hashes loaded\". I found out the problem. I needed to add 23$ to the end of the first word. For example the hash needs to be - $krb5asrep$23$ not $krb5asrep$.. works. Thanks!\n. ",
    "warriar": "i also get an error while make:\ninclude/brain.h:41:10: fatal error: 'xxhash.h' file not found. The key was reading the manual.... BUILD.md:\ngit submodule update --init\nI however previously also cloned https://github.com/Cyan4973/xxHash in the deps folder - duno if that is necessary.\nAfter doing the submodule update it works fine.. ",
    "Tommrodrigues": "I was having the same issue on macOS 10.14.1 but \ngit submodule update --init\nsolved it for me as @warriar suggested.. @PcBlackbelt Did you run the command inside the \"hashcat\" repository (I.e. cd ~/hashcat && git submodule update --init)? Also, which operating system are you on?. ",
    "PcBlackbelt": "git submodule update --init \ncomes back as : fatal: not a git repository (or any of the parent directories): .git\nplease help ive installed and reinstalled whole system like 6 times now learning the ins and outs. yes ive cd hashcat5.0.0 && git submodule update --init\nstill says fatal error\nim running kali what os do you recommend\nive been running apt-get update and apt-get upgrade... still nothing\n. Will do tommorrow when i can thank you. im at a complete loss its the right hash im sure and its the right password im sure\nhashtocrack69.txt\nfakewordlist.txt\n. im using \npmkid\nrun airodump-ng wlan1mon\nhighlight ssid copy\ncd hashcat\n echo \"sside\">filter.txt \n run hcxdumptool -o hash -i wlan1mon --filterlist=filter.txt --filtermode=2 --enable_status 1\nwait for pmkid\n ctrl-c\nrun hcxpcaptool -z hashtocrack hash\n cat hashtocrack2\nrun : hashcat -m 16800 -a 0 hashtocrack69.tx fakewordlist.txt. awesome thank you.. could it be my wireless card the awus036nha?. my bad sorry for the inconvience. ",
    "Jamyz": "Works fine !!. ",
    "alotdv": "alo@alo-pc1:~/hashcat/beta/hashcat-5.0.0beta22$ cat 41.txt\n9da045aef3d95d048cabdb6a90de03a03af6af88\n3932f244c4e9c56a797cab9ca2f055684a8bea1b\n96117f91418e2cd8a1e83d8540f6603a605874a9\n508a55bcc29bdf69636933d4f784e5624a3070aa\n5b5fc56971231a50497dc3225e92d327a16617b8\nf3d90492e821d0d339458fab6e7318734e52922c\n468ae6e184b150d6a4e0180a94ca093f55137e59\n806afa5aab051dbe6fdc8baa623f2f9680e38b2a\n63a4c3d4d78cde24a8b5cde31a5ebcacb8ddefe5\n4e379bffae4fee3279cf4b9174bc0c294ae33cf3\n-m 122\n`alo@alo-pc1:~/hashcat/beta/hashcat-5.0.0beta22$ ./hashcat64.bin 41.txt example.dict -m 122\nhashcat (v5.0.0-22-gd4dad3e1) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080 Ti, 2792/11170 MB allocatable, 28MCU\nDevice #2: GeForce GTX 1080, 2029/8119 MB allocatable, 20MCU\n\nHashes: 10 digests; 10 unique digests, 10 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Early-Skip\n Not-Iterated\n Raw-Hash\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 256\nMinimim salt length supported by kernel: 0\nMaximum salt length supported by kernel: 256\nATTENTION! Pure (unoptimized) OpenCL kernels selected.\nThis enables cracking passwords and salts > length 32 but for the price of drastically reduced performance.\nIf you want to switch to optimized OpenCL kernels, append -O to your commandline.\nWatchdog: Temperature abort trigger set to 90c\nDictionary cache hit:\n Filename..: example.dict\n Passwords.: 128416\n Bytes.....: 1069601\n Keyspace..: 128416\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \nSession..........: hashcat                     \nStatus...........: Exhausted\nHash.Type........: macOS v10.4, macOS v10.5, MacOS v10.6\nHash.Target......: 41.txt\nTime.Started.....: Sun Nov  4 09:56:31 2018 (1 sec)\nTime.Estimated...: Sun Nov  4 09:56:32 2018 (0 secs)\nGuess.Base.......: File (example.dict)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#1.........:   114.0 MH/s (0.34ms) @ Accel:128 Loops:1 Thr:384 Vec:1\nSpeed.#2.........: 85364.6 kH/s (0.34ms) @ Accel:128 Loops:1 Thr:384 Vec:1\nSpeed.#*.........:   199.4 MH/s\nRecovered........: 0/10 (0.00%) Digests, 0/10 (0.00%) Salts\nProgress.........: 1284160/1284160 (100.00%)\nRejected.........: 0/1284160 (0.00%)\nRestore.Point....: 53507/128416 (41.67%)\nRestore.Sub.#1...: Salt:9 Amplifier:0-1 Iteration:0-1\nRestore.Sub.#2...: Salt:9 Amplifier:0-1 Iteration:0-1\nCandidates.#1....: columba -> zzzzzzzzzzz\nCandidates.#2....: 0 -> colum143\nHardware.Mon.#1..: Temp: 30c Fan:100% Util:  5% Core:1733MHz Mem:5005MHz Bus:16\nHardware.Mon.#2..: Temp: 41c Fan:  0% Util:  3% Core:1987MHz Mem:4513MHz Bus:16\nStarted: Sun Nov  4 09:56:25 2018\nStopped: Sun Nov  4 09:56:33 2018\n`\nHash loaded: 10. -m 1500\n`./hashcat64.bin 41.txt example.dict -m 1500\nhashcat (v5.0.0-22-gd4dad3e1) starting...\nOpenCL Platform #1: NVIDIA Corporation\n\nDevice #1: GeForce GTX 1080 Ti, 2792/11170 MB allocatable, 28MCU\nDevice #2: GeForce GTX 1080, 2029/8119 MB allocatable, 20MCU\n\nHashfile '41.txt' on line 1 (9da045aef3d95d048cabdb6a90de03a03af6af88): Hash-value exception\nHashfile '41.txt' on line 4 (508a55bcc29bdf69636933d4f784e5624a3070aa): Hash-value exception\nHashfile '41.txt' on line 5 (5b5fc56971231a50497dc3225e92d327a16617b8): Hash-value exception\nHashfile '41.txt' on line 6 (f3d90492e821d0d339458fab6e7318734e52922c): Hash-value exception\nHashfile '41.txt' on line 7 (468ae6e184b150d6a4e0180a94ca093f55137e59): Hash-value exception\nHashfile '41.txt' on line 8 (806afa5aab051dbe6fdc8baa623f2f9680e38b2a): Hash-value exception\nHashfile '41.txt' on line 9 (63a4c3d4d78cde24a8b5cde31a5ebcacb8ddefe5): Hash-value exception\nHashfile '41.txt' on line 10 (4e379bffae4fee3279cf4b9174bc0c294ae33cf3): Hash-value exception\nHashes: 2 digests; 2 unique digests, 2 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Precompute-Final-Permutation\n* Not-Iterated\nMinimum password length supported by kernel: 0\nMaximum password length supported by kernel: 8\nWatchdog: Temperature abort trigger set to 90c\nDictionary cache hit:\n Filename..: example.dict\n Passwords.: 128416\n Bytes.....: 1069601\n Keyspace..: 128416\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \nSession..........: hashcat                     \nStatus...........: Exhausted\nHash.Type........: descrypt, DES (Unix), Traditional DES\nHash.Target......: 41.txt\nTime.Started.....: Sun Nov  4 09:59:53 2018 (1 sec)\nTime.Estimated...: Sun Nov  4 09:59:54 2018 (0 secs)\nGuess.Base.......: File (example.dict)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#1.........: 36996.2 kH/s (0.54ms) @ Accel:64 Loops:1 Thr:512 Vec:1\nSpeed.#2.........: 27738.0 kH/s (0.57ms) @ Accel:128 Loops:1 Thr:512 Vec:1\nSpeed.#*.........: 64734.2 kH/s\nRecovered........: 0/2 (0.00%) Digests, 0/2 (0.00%) Salts\nProgress.........: 256832/256832 (100.00%)\nRejected.........: 43954/256832 (17.11%)\nRestore.Point....: 74910/128416 (58.33%)\nRestore.Sub.#1...: Salt:1 Amplifier:0-1 Iteration:0-1\nRestore.Sub.#2...: Salt:1 Amplifier:0-1 Iteration:0-1\nCandidates.#1....: 0 -> isl32207\nCandidates.#2....: isla -> zzzzzz\nHardware.Mon.#1..: Temp: 31c Fan:100% Util:  2% Core:1999MHz Mem:5005MHz Bus:16\nHardware.Mon.#2..: Temp: 40c Fan:  0% Util:  2% Core:1987MHz Mem:4513MHz Bus:16\nStarted: Sun Nov  4 09:59:48 2018\nStopped: Sun Nov  4 09:59:55 2018\n`\nHash loaded: 2. And so on you can load them for the below modes:\n-m 3000\n-m 5700\n-m 9000\n-m 16000\n-m 1722. ",
    "mastercracker1": "Not in my case.  Version 4.2.1 does not display any information about the GPU temps when --gpu-temp-disable is activated:\n\nHere's what I get with 5.0.0:\n\nThe definition of --gpu-temp-disable in the help is \"Disable temperature and fanspeed reads and triggers\".\n . I did not include it but when the temperature of the GPU #3 goes above  80\u00b0C, it starts adding yellow lines with the Driver temperature threshold met... message (in v5.0.0 only).  The information from the status display quickly become out of sight and you see only lines of the warning message.  I have MSI afterburner running in the background that keeps charge in throttling the card when it goes above 80\u00b0C.  Without it, it would go way above 80\u00b0C.  That's constant for both hashcat version so it's not an effect of a higher utilization of the card.. I am definitely not against seeing the GPU temps all the time.  It's just the continuous stream of lines saying \"Driver temperature threshold met...\" that is annoying.  There I can think of 2 options but I don't know if they are implementable.  1) Instead of having the \"Driver temperature...\" message.  Change the color of the line showing the temperature (or the temperature value only) to a different color (yellow or red). 2) When the temperature is reached, push the whole status display and the warning line.   I think the first option would be the best or I am open to other suggestions.  Worst case scenario revert to old behavior.. Yes it's a fast algo but I am in the desired case you described with > 150k salts.  Maybe I don't understand some concept enough.  I don't see why if I have 4 days worth of cracking, it cannot dispatch to both GPUs only to the weaker one.   For the \"more documentation\" I meant about the brain output: \n1541395014.654000 | 107.92s |   0 | C |     0.04 ms | Attacks: 14\n1541395125.962000 | 111.31s |   1 | C |   112.98 ms | Attacks: 1\n1541395233.931000 | 107.97s |   0 | C | 219260.90 ms | Hashes: 980589\n1541395233.932000 |   0.00s |   0 | R |     0.64 ms | Offset: 468746240, Length: 983040, Overlap: 0\n1541395236.913000 |   2.98s |   1 | C | 104533.06 ms | Hashes: 424940\n1541395236.914000 |   0.00s |   1 | R |     0.36 ms | Offset: 469729280, Length: 425984, Overlap: 0\n1541395305.641000 |  68.73s |  -1 | Wrote 2346884408 bytes from session 0x77687e51 in 68689.24 ms\nWhat are the code 0, 1, -1.  What does C, R, L means?  What's the offset, the overlap?  The hashes number don't seem to correspond to the amount in the session.. ",
    "marcus-brutus": "Confirmed fixed in beta.  Thanks.. ",
    "gs135269": "Please help me to see if this output indicates a successful start of the hashcat brain server.\nC:\\hashcat-5.1.0>hashcat64.exe --brain-server\n1543818302.353285 |   0.01s |   0 | Generated authentication password: 5247d54808013065\n1543818302.452291 |   0.10s |   0 | Brain server started\n1543818433.460784 | 131.00s |   0 | Brain server stopping\n@marcus-brutus \n. ",
    "coelner": "The password should be U$er1, but I am not sure.There could be a problem with this software that leads to the password U in real life. That was the reason why I sniffed this at all.\nI can generate a new handshake if needed.\nMaybe we should specify that hashcat only support iSCSI from the LIO in the linux kernel. the tgt framework is then not supported. Otherwise this is a request for a new algorithm. I tried this hashcat -m 10 -a 0 -j '^\\x02' --hex-salt hash.txt dict.txt but so far it does not work. I'm not sure, but I tried the option --stdout -o file.hex in combination with -j '^\\x02' . This seems not be working at all. Even adding a simple char does not work. \nDid I miss something?. Sorry, I missed the ^ in the comment above. \nUnder windows you need this -j \"^\\x02\"or ^^^\\x02.. ",
    "Azaran": "I can confirm that -m 12 works on beta.. I've had also Hashcat 4.2.1 crashing on Windows when using extracted hash from a WinZip file via zip2john.sh. But I have tested it on the version 5.0.0 and on the beta version and it seems to work there too. \nThanks for that fix.. Good job with tracking it down. And thanks for the effort, I bet it wasn't an easy bug hunting.. Thanks, it works with the beta.. Alright reverting back to 18.9.3 fixed that. Sorry for wasting your time. The drivers seemed OK at first. . I suppose it is the same as https://github.com/hashcat/hashcat/issues/1789 therefore wrong driver and not a hashcat's bug. But lets see what devs say.. ",
    "CyberTheReape": "today I downloaded the hashcat program from github..\nI installed hashcat program with make install\nhashcat program is currently in my downloads folder\ni did use this command\n./hashcat -m 0 -a 3 -D 1 --session deneme1 /home/cyberthereaper/zzzzz/md5.txt /home/cyberthereaper/zzzzz/rockyou.txt --force   \n(brute force does not start if I do not write the --force command)\nbrute force process started and i stopped the program later\nwanted to continue again but again I got a similar error\n\nI looked into the hashcat folder, but hashcat was created a file called deneme1.log\nshould I press a special key when stopping the brute force attack? c or q  ? Maybe that's why the session command doesn't work..\n. thank you so much... it is worked now....but I'm shocked now ....only 5 seconds the attack is over.. this is ver nice...this is very good.. this is very beautiful :) \nrockyou.txt is have 14344385 pass... hashcat is king.... ",
    "corcuma": "Thank you for your fast response.\nI'm using the beta, and it really looks like that enabling feature mode 3 fixed the issue.\nThanks!. ",
    "danielsoltesz": "Thank you for your help, I will try the things you wrote above.\nOn Sun, Nov 18, 2018, 20:04 Jens Steube <notifications@github.com wrote:\n\nAlso uninstall MESA, looks like a MESA JiT compiler error. Not a hashcat\nerror.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1790#issuecomment-439716916,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ArClIuauIyIGXKMYoKpFPIHAxCE3BDOzks5uwa82gaJpZM4Ynozj\n.\n. \n",
    "wang614340595": "it might be useful to have a --no-keep-guessing to exit on the first hit.. ",
    "mcovalt": "\nDo I understand it correctly that only version 1 was actually working and with your PR version 2 will be supported as well?\n\nCorrect.. ",
    "Libre12": "where do i find electrum2john.py ?\nI have downloaded and compiled hashcat directly from github on my Ubuntu but I can't find this file.. > did you try running electrum2john.py ?\n\ndoes the output start with $electrum$2 or is it $electrum$3 ?\nHashcat supports salt type 1 and 2 currently, not sure if your type is not supported (3 ?)\n\n$electrum$5*\nHashcat supports this version?. ",
    "jarlethorsen": "\nDoes this mean it is neither \"cbc-plain64\" nor \"cbc-essiv\" ? This is the cryptsetup luksDump output, right?\n\nCorrect. This is the output of \"cryptsetup luksDump\". The first part of the header looks like this (notice the plain \"cbc\":\n00000000: 4c55 4b53 babe 0001 6165 7300 0000 0000  LUKS....aes.....\n00000010: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000020: 0000 0000 0000 0000 6362 6300 0000 0000  ........cbc.....\n00000030: 0000 0000 0000 0000 0000 0000 0000 0000  ................\n00000040: 0000 0000 0000 0000 7368 6132 3536 0000  ........sha256..\n\nAre you able to open this volume with the correct password?\n\nI did not create the volume. Password unknown.\n\nAre you able to create a similar (new) volume with cryptsetup? How do you create a volume with this cipher mode?\n\nI don't know. According to google there does not seem to be a \"cbc\" mode... Maybe this was made by an ancient version of cryptsetup and is in fact the same as cbc-plain?. ",
    "ptrac3": "@philsmd Thanks for your help. Unfortunately I have already tried the latest hashcat version and I am running the recommended Nvidia drivers so I will try to reinstall them.\n@jsteube I see the issue was closed. Did I miss anything from the official documentation or was it a known issue?\nThanks.. ",
    "JacobTDC": "@magnumripper what should clinfo return? I get:\nNumber of platforms                               0\nI'm new to all this hashcat stuff. I just thought I'd be fun to try.. K. sigh well, so much for that.... ",
    "alexeynikitin": "@jsteube \nHello again!\nI applied you SMI-commands and tested one more time. Under Windows it is stiil as I said! NVidia driver \n399.24 gives more than 600 KH/s (600-620) and i also tested the latest 417.71, still got 570 KH/s at max!\nHave you tested it under Windows? Please, can anyone run theese tests under Windows to confirm the issue?. ",
    "bol-van": "zcash and etherium miners work fine . 2500  WPA-EAPOL-PBKDF2. ",
    "zephyrprime": "This still happens with the 3/14/2019 driver and with the February driver before this.  It seems like every newer driver is failing?. ",
    "askelon": "Thanks very much!\nSince it is so kind I would like to ask you another question concerning the execution of the -m 400 instance (WP MD5). When I use the only_latin.Top dictionary hashcat returns a token length error for every line of the dictionary. This happens exclusively for the dictionary mentioned above, but even much \"heavy\" dictionaries are loaded correctly.\n../only_latin.Top 'on line 1 (123456): Token length exception][only_latin.Top' on line 2 (123456789): Token length exception][...] thus continuing for every line of the dictionary. Thanks for the support!. ",
    "Raks-coder": "Please look into this. cd hashcat/ && make\nclang -c -W -Wall -Wextra -O2 -pipe -std=gnu99 -Iinclude/ -IOpenCL/ -Ideps/LZMA-SDK/C -Ideps/OpenCL-Headers -DWITH_BRAIN -Ideps/xxHash src/affinity.c -o obj/affinity.NATIVE.STATIC.o\nIn file included from src/affinity.c:7:\ninclude/types.h:11:10: fatal error: 'stdio.h' file not found\ninclude \n     ^~~~~~~~~\n\n1 error generated.\nmake: *** [src/Makefile:494: obj/affinity.NATIVE.STATIC.o] Error 1\nThis is what i get. Please help me how can i resolve this issue. I have updated command line tools\n. > I can build as well without any problems on Mojave/10.14.2\nCould you please elaborate the steps, i am following the steps in this gist https://gist.github.com/chadmayfield/600b211e9c309859f2bfb5dddc5de09c. xcode-select --install\nxcode-select: error: command line tools are already installed, use \"Software Update\" to install updates\n~ $ xcode-select --version\nxcode-select version 2354.\nI have tools installed and they are updated too. don't know why this problem is coming.  This is what i get    ~$/Users/rakshitmalhotra/anaconda3/bin/clang .I get it it's not a hashcat issue now anyways could you suggest me how to correct it, i will close the issue asap then\n\nYou didn't answer my question though. Also, what's the output of which clang?\nAnyway this is not a hashcat issue at all.\n\n. so anyone able to figure out the issue?\n. > The issue is on your end. I suggest you change your path to ensure /usr/bin/clang is used and not that foreign one.\nThank you I will close the issue now. Thanks for the help once again\n. ",
    "GuthL": "Thanks a lot!\nI'm trying to get the most 0 in a Keccak256. It does not matter how they are positioned.\nHow can I play with your version?. ",
    "0age": "Hey, jumping in here - asked @GuthL to lend his expertise and he knew the right place to look for answers :)\nBasically, the challenge can be broken up into three steps that would all be executed in parallel:\n Construct a payload that is exactly 85 bytes long, with a 41-byte static \"header\", a 12-byte variable search-space \"body\", and a 32-byte static \"footer\", that will serve as the input to keccak256 (this seems to be supported out-of-the-box via an appropriate mask)\n Take a keccak256 hash of that payload (e.g. using hash mode 17800)\n Drop the first 12 bytes from the resultant hash to get the 20-byte address, then count the number of zero bytes in that address; if there are five or more, write the input to stdout or a file (this step is the generally problematic one)*\nLooking at the kernel you referenced (this is the one, correct?), are you referring to COMPARE_S_SIMD in m00100s? Where might I find more information about how to configure the pattern to match against?\nThank you for taking a look at this! . One more quick followup question: I can successfully run ./hashcat -m 11111 -b after building your forked branch, as well as very specific searches like ./hashcat -m 11111 -a 3 f000111122223333444455556666777788889999, but attempts to utilize a mask / filter command all seem to fail. What would a proper command actually look like? Thanks!. Correct me if I'm wrong here, but it seems as though the hash you use to match against is basically disregarded for this particular mode. I think I've figured out how to apply a mask, but have run into a more fundamental issue: There's no \"Pure OpenCL kernel\" available (and appears as though the same is true for 17800 / keccak256) and the optimized kernel has a maximum password length that is too short (55 < 85).\nHowever, it does look like the optimized 17800 kernel also makes a salt available, up to length 51, but 17800 doesn't seem to support salts - if the salt could be applied directly to the password in raw-hashing mode, that could be used as one work-around. Otherwise, how feasible would it be for me to try and extend the supported password length in the optimized kernel?\nHere's the command I'm running on your branch:\n./hashcat -a 3 -w 3 -m 11111 --outfile-format=4 -o out.txt --hex-charset \\\n  0000000011111111222222223333333344444444 \\\n  'ffaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaabbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbcccccccccccc?b?b?b?b?b?bdddd' # still needs 30 more bytes!\nThanks again and let me know if there's a more appropriate forum for this line of inquiry.. ",
    "caglarsayin": "We can confirm that it only happens on md5 and sha1 for example but not 1600 office excel[AES] 2013. Is there any way to solve this?. ",
    "rscullin": "MD5\n./hashcat64.bin --brain-password password --brain-client -m 0 repro_md5.txt -a 3 \"?l?l?l?l?l?l?l\"\n\u274c Results in the same crash/output.\nHowever, running\n./hashcat64.bin --brain-password password --brain-client -O -m 0 repro_md5.txt -a 3 \"?l?l?l?l?l?l?l\"\n\u2705works fine.\nSHA1\n./hashcat64.bin --brain-password password --brain-client -m 100 repro_sha1.txt -a 3 \"?l?l?l?l?l?l?l\" \n\u274c\n./hashcat64.bin --brain-password password --brain-client -O -m 100 repro_sha1.txt -a 3 \"?l?l?l?l?l?l?l\" \n\u2705works fine.\nDEScrypt\n./hashcat64.bin --brain-password password --brain-client -m 1500 repro_des.txt -a 0 dictionary.txt\n\u2705 works fine.\nHopefully this helps narrow down the issue. Thanks for taking a look!. All the previously failing commands worked fine when running with the latest master code (6286874b). Thanks!. ",
    "Tydus": "Hi Steube,\nThanks for the reply. However my problem is not the case above.\nI digged more deeply into the code and made some (very ugly) hacks (sry...) by hard-code a 2000x larger plain-text buffer. Now it works like charm :)\nI'm using a 5-digits (20 bits) SHA256-prefix, so the expectation of the collision rate will be 1 of 2^20.\nOn my K80: 13 * 256 * 512 * 128 / 2^20 = ~208 results per kernel invocation (consistent with experiments). Thus, I think 2000 should be more than enough.\ncommit. ",
    "adrastee": "Ok ! Thanks.\nFor the record, I'll use combinator attack instead of rule.. ",
    "JKyang09": "The problem is solved, thanks a lot!. ",
    "olealgoritme": "pebkac? close issue? =) . ",
    "minanagehsalalma": "why the  \"bugs that are triggered only by some hashcat versions\"\nand\nAMD GPUs on Windows require \"AMD Radeon Software Crimson Edition\" (15.12 or later) this an outdated version of AMD Radeon Software..... Crimson Edition have a lot of errors and unoptimized performance ..... so i use Adrenalin Edition\n.... will the Radeon\u2122 Software Crimson ReLive Edition 17.11.4 work ?. ",
    "gitxmax": "Thanks.\nThis is not a VM machine.\nCan only run with the --force, otherwise, I get:\n`hashcat -b --opencl-device-types 1,2\nhashcat (v5.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\n\nDevice #1: Intel's OpenCL runtime (GPU only) is currently broken.\n             We are waiting for updated OpenCL drivers from Intel.\n             You can use --force to override, but do not report related errors.\nNo devices found/left.\n`\n\nWith --force, the output is \ud83d\udc4d \n`hashcat -b --opencl-device-types 1,2 --force\nhashcat (v5.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Gen9 HD Graphics NEO, 3129/6258 MB allocatable, 23MCU\n\nBenchmark relevant options:\n\n--force\n--opencl-device-types=1,2\n--optimized-kernel-enable\n\nHashmode: 0 - MD5\nSpeed.#1.........:   492.7 MH/s (95.95ms) @ Accel:128 Loops:64 Thr:256 Vec:4\nHashmode: 100 - SHA1\nSpeed.#1.........:   132.6 MH/s (89.38ms) @ Accel:64 Loops:32 Thr:256 Vec:4\nHashmode: 1400 - SHA2-256\n. Well, I'm not fully convinced, it's not a hashcat bug..\nBeen playing with it for a while and finally, managed to get both cpu and HD 630 gpu running.\nThe only way it works is running:hashcat -b --opencl-device-types 1,2 --force\nTotal wpa cracking speed is over 25000 keys per second, which seems very good, for having no dedicated gpu...\n`\nhashcat (v5.1.0) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Intel(R) Corporation\n\nDevice #1: Intel(R) Gen9 HD Graphics NEO, 3129/6258 MB allocatable, 23MCU\n\nOpenCL Platform #2: Intel(R) Corporation\n\nDevice #2: Intel(R) Core(TM) i5-8400 CPU @ 2.80GHz, 1955/7822 MB allocatable, 6MCU\n\nBenchmark relevant options:\n\n--force\n--opencl-device-types=1,2\n--optimized-kernel-enable\n\nHashmode: 0 - MD5\nSpeed.#1.........:   499.8 MH/s (95.42ms) @ Accel:128 Loops:64 Thr:256 Vec:4\nSpeed.#2.........:   559.9 MH/s (10.84ms) @ Accel:1024 Loops:1024 Thr:1 Vec:8\nSpeed.#*.........:  1059.7 MH/s\nHashmode: 100 - SHA1\nSpeed.#1.........:   134.8 MH/s (88.72ms) @ Accel:64 Loops:32 Thr:256 Vec:4\nSpeed.#2.........:   402.6 MH/s (3.80ms) @ Accel:1024 Loops:256 Thr:1 Vec:8\nSpeed.#*.........:   537.5 MH/s\nHashmode: 1400 - SHA2-256\nSpeed.#1.........: 63598.7 kH/s (94.11ms) @ Accel:64 Loops:16 Thr:256 Vec:4\nSpeed.#2.........:   178.6 MH/s (34.86ms) @ Accel:1024 Loops:1024 Thr:1 Vec:8\nSpeed.#*.........:   242.2 MH/s\nHashmode: 1700 - SHA2-512\nSpeed.#1.........: 12402.7 kH/s (60.45ms) @ Accel:16 Loops:8 Thr:256 Vec:1\nSpeed.#2.........: 51414.2 kH/s (60.60ms) @ Accel:1024 Loops:512 Thr:1 Vec:4\nSpeed.#*.........: 63816.9 kH/s\nHashmode: 2500 - WPA-EAPOL-PBKDF2 (Iterations: 4096)\nSpeed.#1.........:     7313 H/s (96.76ms) @ Accel:64 Loops:8 Thr:256 Vec:1\nSpeed.#2.........:    18175 H/s (81.91ms) @ Accel:1024 Loops:1024 Thr:1 Vec:8\nSpeed.#*.........:    25488 H/s\nHashmode: 1000 - NTLM\nSpeed.#1.........:   820.4 MH/s (57.58ms) @ Accel:128 Loops:64 Thr:256 Vec:4\nSpeed.#2.........:   971.5 MH/s (6.19ms) @ Accel:1024 Loops:1024 Thr:1 Vec:8\nSpeed.#*.........:  1791.9 MH/s\n. My point is, to get the set up working, the way it is now, I had to use the extra options \"--opencl-device-types 1,2 --force\", which are hardly documented anywhere. Before I found those, I spent a lot of time thinking it was the drivers problem.\nFeel free to close the issue now, as  I'm happy with the end result now.. ",
    "filippharg": "Thanks for answer, but I'm still unable to find right settings.\nI create this setup with latest inno setup utility\nhttps://ufile.io/ykgww\n with password aaa\nInnoextractor says:\n; PasswordHash=842d0bef6dbb0f060b337c6a9c7d6482a24978c0\n; PasswordSalt=ec2a71fc6498810b\nBut with hashcat command I'm unable to find aaa password.\nDo you know what right options with hashcat command I have to use or how to set hashcatGUI?\nMany thanks\n. Many thanks, friend. Now all is ok.\nIl mer 13 feb 2019, 16:45 Jens Steube notifications@github.com ha scritto:\n\nSee:\nroot@ht:~/hashcat# perl -e 'print \"PasswordCheckHash\" . pack (\"H*\", \"ec2a71fc6498810b\") . \"a\\0a\\0a\\0\"' | sha1sum\n842d0bef6dbb0f060b337c6a9c7d6482a24978c0  -\nThis mean you need to do something like this:\n./hashcat -m 140 842d0bef6dbb0f060b337c6a9c7d6482a24978c0:50617373776f7264436865636b48617368ec2a71fc6498810b --hex-salt -a 3 aaa\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1904#issuecomment-463249226,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AtYvIAhCdowBLYh2O_66SupAYMHtAco4ks5vNDMsgaJpZM4a42Kf\n.\n. \n",
    "suhel1986": "Hi, Thanks for the Reply, \nCan you please post the forum link. Sorry I don\u2019t know which one is it \n\nOn 14 Feb 2019, at 12:59 am, Jens Steube notifications@github.com wrote:\nLooks like the wrong mask, but a wrong mask is a user problem. Please ask on forum.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "taliseen": "Also doesnt work in 5.0.1 with hwmon disabled:\n\n. ",
    "TheYkk": "i use windows platform (win 10) , and install msys for make command. i install cygwin and same problem. i cant build \n\n\ni have cygwin and msys2. ",
    "Mister-X-": "Most likely. I just wanted to give an accurate report how I can reproduce the bug. The benchmark was the easiest way and doesn't require to provide a hash.\nThe machine was a brand new install. There was nothing but the base OS on it. Then I installed the Intel driver, then I downloaded hashcat and ran it and the issue happened. As you can see with the version number, it fits the requirement mentioned on hashcat.net (I verified this before reporting).\nI've done such install multiple times in the past without any issues on various machines, so I know this is the right driver and this is the first time it happened.\nI forgot to mention the kernel version: 4.18.0-10-generic. I ran hashcat in a VM on a 6700HQ just fine, on a few systems on AWS just fine and I thought running on this high-end Xeon would work.\nBeing a recent CPU according to ARK and my previous experience with hashcat on Intel CPU, I would assume hashcat would have given me a different output screen than the one I got when running hashcat -I as shown above if it wasn't supported.. This server/instance is headless. What other OpenCL application should I run? Hashcat is the only one I can think of.\nAnything else I should run on this? What I mean is that this is a VPS and I got to start an instance every time I need to test something.. Yes but done on a cheaper system with just 2 cores\n```\nPlatform: Intel(R) CPU Runtime for OpenCL(TM) Applications\n  Device: Intel(R) Xeon(R) Platinum 8168 CPU @ 2.70GHz\n    Driver version  : 18.1.0.0920 (Linux x64)\n    Compute units   : 2\n    Clock frequency : 2700 MHz\nGlobal memory bandwidth (GBPS)\n  float   : 24.16\n  float2  : 17.13\n  float4  : 23.68\n  float8  : 26.02\n  float16 : 24.42\n\nSingle-precision compute (GFLOPS)\n  float   : 52.47\n  float2  : 93.59\n  float4  : 182.69\n  float8  : 347.23\n  float16 : 88.69\n\nNo half precision support! Skipped\n\nDouble-precision compute (GFLOPS)\n  double   : 46.42\n  double2  : 90.91\n  double4  : 179.79\n  double8  : 32.03\n  double16 : 44.42\n\nInteger compute (GIOPS)\n  int   : 16.50\n  int2  : 32.75\n  int4  : 57.19\n  int8  : 21.32\n  int16 : 22.75\n\nTransfer bandwidth (GBPS)\n  enqueueWriteBuffer         : 7.12\n  enqueueReadBuffer          : 4.80\n  enqueueMapBuffer(for read) : 16679.57\n    memcpy from mapped ptr   : 4.80\n  enqueueUnmap(after write)  : 51194.72\n    memcpy to mapped ptr     : 5.04\n\nKernel launch latency : 2.50 us\n\n```\nlscpu:\nArchitecture:        x86_64\nCPU op-mode(s):      32-bit, 64-bit\nByte Order:          Little Endian\nCPU(s):              2\nOn-line CPU(s) list: 0,1\nThread(s) per core:  1\nCore(s) per socket:  1\nSocket(s):           2\nNUMA node(s):        1\nVendor ID:           GenuineIntel\nCPU family:          6\nModel:               85\nModel name:          Intel(R) Xeon(R) Platinum 8168 CPU @ 2.70GHz\nStepping:            4\nCPU MHz:             2693.674\nBogoMIPS:            5387.34\nVirtualization:      VT-x\nHypervisor vendor:   KVM\nVirtualization type: full\nL1d cache:           32K\nL1i cache:           32K\nL2 cache:            1024K\nL3 cache:            33792K\nNUMA node0 CPU(s):   0,1\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single pti tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves pku ospke\nIn case anybody needs to compile it:\napt install opencl-c-headers opencl-clhpp-headers cmake build-essential\nmkdir build\ncd build\ncmake ... Current master and stable now work fine (and tested again on the 32 CPU beast to confirm). The system is a VPS, and they were created when needed.\nNo idea what the difference is (apart from some package updates).. Actually, the issue may be linked with the kernel version. I noticed I was running 18.10 when reporting the bug and just tested with 18.04. So, something to do with OpenCL and that kernel version.\nclpeak reports the following and hangs until Ctrl-C with Ubuntu 18.10:\nPlatform: Intel(R) CPU Runtime for OpenCL(TM) Applications\nclCreateContextFromType (-2). Ubuntu 18.04 with 4.18.0-15-generic (HWE) also works fine where Ubuntu 18.10 with 4.18.0-10-generic or 4.18.0-15-generic fails (where the latter works fine on 16.04).. ",
    "johnjohnsp1": "this is the output from hash cat -I \ud83d\udc4d \nhashcat (v5.1.0-622-ge1fe3e75) starting...\nOpenCL Info:\nPlatform ID #1\n  Vendor  : Apple\n  Name    : Apple\n  Version : OpenCL 1.2 (Oct 31 2018 21:59:22)\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 4\n    Vendor         : Intel\n    Name           : Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz\n    Version        : OpenCL 1.2 \n    Processor(s)   : 12\n    Clock          : 2900\n    Memory         : 8192/32768 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.1\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 2147483648\n    Vendor         : Intel Inc.\n    Name           : Intel(R) UHD Graphics 630\n    Version        : OpenCL 1.2 \n    Processor(s)   : 24\n    Clock          : 1200\n    Memory         : 384/1536 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2(Dec 20 2018 21:30:35)\nDevice ID #3\n    Type           : GPU\n    Vendor ID      : 1\n    Vendor         : AMD\n    Name           : AMD Radeon Pro Vega 20 Compute Engine\n    Version        : OpenCL 1.2 \n    Processor(s)   : 20\n    Clock          : 740\n    Memory         : 1020/4080 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2 (Dec 20 2018 21:22:59)\ndid a new clone of the repository and before compile again i did make clean\ncommand issue:\ngit clone --recursive https://github.com/hashcat/hashcat\nmake clean\nmake\n. sorry thought i pasted the entire console, yes seems it works on bench mode:\nhashcat (v5.1.0-622-ge1fe3e75) starting in benchmark mode...\nBenchmarking uses hand-optimized kernel code by default.\nYou can use it in your cracking session by setting the -O option.\nNote: Using optimized kernel code limits the maximum supported password length.\nTo disable the optimized kernel code in benchmark mode, use the -w option.\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz, skipped.\nDevice #2: Intel(R) UHD Graphics 630, 384/1536 MB allocatable, 24MCU\nDevice #3: AMD Radeon Pro Vega 20 Compute Engine, 1020/4080 MB allocatable, 20MCU\n\nBenchmark relevant options:\n\n--optimized-kernel-enable\n\nHashmode: 0 - MD5\nSpeed.#2.........:   548.2 MH/s (44.47ms) @ Accel:512 Loops:128 Thr:16 Vec:1\nSpeed.#3.........:  5022.9 MH/s (62.63ms) @ Accel:1024 Loops:256 Thr:64 Vec:1\nSpeed.#*.........:  5571.1 MH/s\nHashmode: 100 - SHA1\nSpeed.#2.........:   192.2 MH/s (31.43ms) @ Accel:256 Loops:128 Thr:8 Vec:1\nSpeed.#3.........:  2451.7 MH/s (67.35ms) @ Accel:512 Loops:256 Thr:64 Vec:1\nSpeed.#*.........:  2643.8 MH/s\nHashmode: 1400 - SHA2-256\nSpeed.#2.........: 78825.8 kH/s (38.55ms) @ Accel:128 Loops:64 Thr:16 Vec:1\nSpeed.#3.........:   682.2 MH/s (121.57ms) @ Accel:512 Loops:128 Thr:64 Vec:1\nSpeed.#*.........:   761.0 MH/s\nHashmode: 1700 - SHA2-512\nSpeed.#2.........: 12218.5 kH/s (62.92ms) @ Accel:128 Loops:32 Thr:8 Vec:1\nSpeed.#3.........:   145.3 MH/s (71.11ms) @ Accel:128 Loops:64 Thr:64 Vec:1\nSpeed.#*.........:   157.5 MH/s\nHashmode: 2500 - WPA-EAPOL-PBKDF2 (Iterations: 4095)\nSpeed.#2.........:     7684 H/s (49.06ms) @ Accel:128 Loops:64 Thr:8 Vec:1\nSpeed.#3.........:    86691 H/s (117.05ms) @ Accel:256 Loops:128 Thr:64 Vec:1\nSpeed.#*.........:    94376 H/s\nHashmode: 1000 - NTLM\nSpeed.#2.........:   902.1 MH/s (54.25ms) @ Accel:1024 Loops:128 Thr:16 Vec:1\nSpeed.#3.........:  8870.8 MH/s (74.49ms) @ Accel:1024 Loops:512 Thr:64 Vec:1\nSpeed.#*.........:  9772.9 MH/s\nHashmode: 3000 - LM\n\nDevice #2: Skipping unstable hash-mode 3000 for this device.\n             You can use --force to override, but do not report related errors.\nDevice #3: Skipping unstable hash-mode 3000 for this device.\n             You can use --force to override, but do not report related errors.\nSpeed.#*.........:        0 H/s\n\nHashmode: 5500 - NetNTLMv1 / NetNTLMv1+ESS\nSpeed.#2.........:   145.5 MH/s (41.95ms) @ Accel:256 Loops:128 Thr:8 Vec:1\nSpeed.#3.........:  5963.8 MH/s (55.23ms) @ Accel:1024 Loops:256 Thr:64 Vec:1\nSpeed.#*.........:  6109.3 MH/s\nHashmode: 5600 - NetNTLMv2\nSpeed.#2.........: 38349.4 kH/s (39.77ms) @ Accel:64 Loops:32 Thr:32 Vec:1\nSpeed.#3.........:   350.4 MH/s (118.37ms) @ Accel:256 Loops:128 Thr:64 Vec:1\nSpeed.#*.........:   388.7 MH/s\nHashmode: 1500 - descrypt, DES (Unix), Traditional DES\n\nDevice #2: Skipping unstable hash-mode 1500 for this device.\n             You can use --force to override, but do not report related errors.\nDevice #3: Skipping unstable hash-mode 1500 for this device.\n             You can use --force to override, but do not report related errors.\nSpeed.#*.........:        0 H/s\n\nHashmode: 500 - md5crypt, MD5 (Unix), Cisco-IOS $1$ (MD5) (Iterations: 1000)\nSpeed.#2.........:   229.5 kH/s (51.81ms) @ Accel:256 Loops:250 Thr:8 Vec:1\nSpeed.#3.........:  2873.1 kH/s (55.19ms) @ Accel:512 Loops:250 Thr:64 Vec:1\nSpeed.#*.........:  3102.6 kH/s\nHashmode: 3200 - bcrypt $2*$, Blowfish (Unix) (Iterations: 32)\n\nDevice #2: Skipping unstable hash-mode 3200 for this device.\n             You can use --force to override, but do not report related errors.\nDevice #3: Skipping unstable hash-mode 3200 for this device.\n             You can use --force to override, but do not report related errors.\nSpeed.#*.........:        0 H/s\n\nHashmode: 1800 - sha512crypt $6$, SHA512 (Unix) (Iterations: 5000)\nclBuildProgram(): CL_BUILD_PROGRAM_FAILURE\nError returned by cvms_element_build_from_source\n* Device #3: Kernel /Users/luca/Downloads/hashcat/OpenCL/m01800-optimized.cl build failed - proceeding without this device.\nSpeed.#2.........:     2334 H/s (65.73ms) @ Accel:128 Loops:32 Thr:8 Vec:1\nSpeed.#*.........:     2334 H/s\nHashmode: 7500 - Kerberos 5 AS-REQ Pre-Auth etype 23\nSpeed.#2.........:  4154.8 kH/s (45.96ms) @ Accel:16 Loops:8 Thr:64 Vec:1\nSpeed.#*.........:  4154.8 kH/s\nHashmode: 13100 - Kerberos 5 TGS-REP etype 23\nSpeed.#2.........:  3677.2 kH/s (52.06ms) @ Accel:32 Loops:4 Thr:64 Vec:1\nSpeed.#*.........:  3677.2 kH/s\nHashmode: 15300 - DPAPI masterkey file v1 (Iterations: 23999)\nSpeed.#2.........:     1295 H/s (49.72ms) @ Accel:128 Loops:64 Thr:8 Vec:1\nSpeed.#*.........:     1295 H/s\nHashmode: 15900 - DPAPI masterkey file v2 (Iterations: 12899)\nSpeed.#2.........:      472 H/s (63.39ms) @ Accel:64 Loops:32 Thr:8 Vec:1\nSpeed.#*.........:      472 H/s\nHashmode: 7100 - macOS v10.8+ (PBKDF2-SHA512) (Iterations: 1023)\nSpeed.#2.........:     5929 H/s (61.50ms) @ Accel:64 Loops:31 Thr:8 Vec:1\nSpeed.#*.........:     5929 H/s\nHashmode: 11600 - 7-Zip (Iterations: 16384)\nSpeed.#2.........:     3260 H/s (56.79ms) @ Accel:256 Loops:64 Thr:8 Vec:1\nSpeed.#*.........:     3260 H/s\nHashmode: 12500 - RAR3-hp (Iterations: 262144)\n\nDevice #2: Skipping unstable hash-mode 12500 for this device.\n             You can use --force to override, but do not report related errors.\nSpeed.#*.........:        0 H/s\n\nHashmode: 13000 - RAR5 (Iterations: 32799)\nSpeed.#2.........:      832 H/s (56.73ms) @ Accel:128 Loops:64 Thr:8 Vec:1\nSpeed.#*.........:      832 H/s\nHashmode: 6211 - TrueCrypt RIPEMD160 + XTS 512 bit (Iterations: 1999)\nSpeed.#2.........:     5898 H/s (65.54ms) @ Accel:128 Loops:32 Thr:8 Vec:1\nSpeed.#*.........:     5898 H/s\nHashmode: 13400 - KeePass 1 (AES/Twofish) and KeePass 2 (AES) (Iterations: 24569)\nSpeed.#2.........:      487 H/s (64.78ms) @ Accel:64 Loops:32 Thr:16 Vec:1\nSpeed.#*.........:      487 H/s\nHashmode: 6800 - LastPass + LastPass sniffed (Iterations: 499)\nSpeed.#2.........:    47647 H/s (49.17ms) @ Accel:128 Loops:62 Thr:8 Vec:1\nSpeed.#*.........:    47647 H/s\nHashmode: 11300 - Bitcoin/Litecoin wallet.dat (Iterations: 200459)\nSpeed.#2.........:       63 H/s (61.20ms) @ Accel:128 Loops:32 Thr:8 Vec:1\nSpeed.#*.........:       63 H/s\nthanks for the help. unfortunately if i try with a specify test more detailed i get this:\n./hashcat -a0 -m 2500 kama.hccapx /Volumes/DATA/WORDLIST/keywalk.txt -r rules/best64.rule \nhashcat (v5.1.0-622-ge1fe3e75) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz, skipped.\nDevice #2: Intel(R) UHD Graphics 630, 384/1536 MB allocatable, 24MCU\nDevice #3: AMD Radeon Pro Vega 20 Compute Engine, 1020/4080 MB allocatable, 20MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 77\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nDictionary cache built:\n Filename..: /Volumes/DATA/WORDLIST/keywalk.txt\n Passwords.: 6222\n Bytes.....: 50490\n Keyspace..: 479094\n* Runtime...: 0 secs\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => Abort trap: 6\nand the system seems hang for a minute or so\n. both try with -w 1 and -d 3 seems to work fine:\n./hashcat -a0 -m 2500 kama.hccapx /Volumes/DATA/WORDLIST/keywalk.txt -r rules/best64.rule -d 3\nhashcat (v5.1.0-622-ge1fe3e75) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz, skipped.\nDevice #2: Intel(R) UHD Graphics 630, skipped.\nDevice #3: AMD Radeon Pro Vega 20 Compute Engine, 1020/4080 MB allocatable, 20MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 77\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nDictionary cache hit:\n Filename..: /Volumes/DATA/WORDLIST/keywalk.txt\n Passwords.: 6222\n Bytes.....: 50490\n Keyspace..: 479094\nThe wordlist or mask that you are using is too small.\nThis means that hashcat cannot use the full parallel power of your device(s).\nUnless you supply more work, your cracking speed will drop.\nFor tips on supplying more work, see: https://hashcat.net/faq/morework\nApproaching final keyspace - workload adjusted.  \n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => s\nSession..........: hashcat\nStatus...........: Running\nHash.Name........: WPA-EAPOL-PBKDF2\nHash.Target......: Kamarat (AP:e0:b9:e5:dc:4d:39 STA:4c:74:bf:e6:57:9a)\nTime.Started.....: Sat Mar  2 11:29:36 2019 (2 secs)\nTime.Estimated...: Sat Mar  2 11:29:44 2019 (6 secs)\nGuess.Base.......: File (/Volumes/DATA/WORDLIST/keywalk.txt)\nGuess.Mod........: Rules (rules/best64.rule)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#3.........:    23025 H/s (0.66ms) @ Accel:64 Loops:32 Thr:64 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 324966/479094 (67.83%)\nRejected.........: 270886/324966 (83.36%)\nRestore.Point....: 0/6222 (0.00%)\nRestore.Sub.#3...: Salt:0 Amplifier:20-21 Iteration:3648-3680\nCandidates.#3....: \u00f9\u00e0\u00f2lk21 -> zxcvbnm,.-\u00e021\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => s\nSession..........: hashcat\nStatus...........: Running\nHash.Name........: WPA-EAPOL-PBKDF2\nHash.Target......: Kamarat (AP:e0:b9:e5:dc:4d:39 STA:4c:74:bf:e6:57:9a)\nTime.Started.....: Sat Mar  2 11:29:36 2019 (6 secs)\nTime.Estimated...: Sat Mar  2 11:29:43 2019 (1 sec)\nGuess.Base.......: File (/Volumes/DATA/WORDLIST/keywalk.txt)\nGuess.Mod........: Rules (rules/best64.rule)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#3.........:    24469 H/s (0.65ms) @ Accel:64 Loops:32 Thr:64 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 433126/479094 (90.41%)\nRejected.........: 270886/433126 (62.54%)\nRestore.Point....: 0/6222 (0.00%)\nRestore.Sub.#3...: Salt:0 Amplifier:60-61 Iteration:2176-2208\nCandidates.#3....: $HEX[c3b9c3a0c36b] -> $HEX[7a786376626e6d2c2ea0]\nSession..........: hashcat                     \nStatus...........: Exhausted\nHash.Name........: WPA-EAPOL-PBKDF2\nHash.Target......: Kamarat (AP:e0:b9:e5:dc:4d:39 STA:4c:74:bf:e6:57:9a)\nTime.Started.....: Sat Mar  2 11:29:36 2019 (9 secs)\nTime.Estimated...: Sat Mar  2 11:29:45 2019 (0 secs)\nGuess.Base.......: File (/Volumes/DATA/WORDLIST/keywalk.txt)\nGuess.Mod........: Rules (rules/best64.rule)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#3.........:    23582 H/s (0.77ms) @ Accel:64 Loops:32 Thr:64 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 479094/479094 (100.00%)\nRejected.........: 270886/479094 (56.54%)\nRestore.Point....: 6222/6222 (100.00%)\nRestore.Sub.#3...: Salt:0 Amplifier:76-77 Iteration:0-1\nCandidates.#3....: \u00f2lk\u00f2 -> znm,.-\nStarted: Sat Mar  2 11:29:35 2019\nStopped: Sat Mar  2 11:29:47 2019\nthanks. unfortunaly i did another try but give it a longer session the mac will hang on and had to shut it down with the button.\nproblem is no log has been generated\nwell thanks for the help but i think the problem is the mac with this setup that won't work\nthanks once more for  all the help . well seems the crash log has been generated:\nProcess:               hashcat [905]\nPath:                  /Users/USER/Downloads/*/hashcat\nIdentifier:            hashcat\nVersion:               0\nCode Type:             X86-64 (Native)\nParent Process:        bash [473]\nResponsible:           hashcat [905]\nUser ID:               501\nDate/Time:             2019-03-02 14:23:13.382 +0100\nOS Version:            Mac OS X 10.14.3 (18D109)\nReport Version:        12\nBridge OS Version:     3.3 (16P3133)\nAnonymous UUID:        44F81955-E055-BE89-D949-42AEC10C77EE\nTime Awake Since Boot: 900 seconds\nSystem Integrity Protection: enabled\nCrashed Thread:        6  Dispatch queue: opencl_runtime\nException Type:        EXC_CRASH (SIGABRT)\nException Codes:       0x0000000000000000, 0x0000000000000000\nException Note:        EXC_CORPSE_NOTIFY\nApplication Specific Information:\nabort() called\nApplication Specific Signatures:\nGraphics hardware encountered an error and was reset: 0x00000813\nThread 0:: Dispatch queue: com.apple.main-thread\n0   libsystem_kernel.dylib          0x00007fff5983494e __ulock_wait + 10\n1   libsystem_pthread.dylib         0x00007fff598f070a _pthread_join + 356\n2   hashcat                         0x000000010396472b inner2_loop + 1307\n3   hashcat                         0x00000001039641c4 inner1_loop + 180\n4   hashcat                         0x0000000103963988 outer_loop + 1640\n5   hashcat                         0x00000001039631c0 hashcat_session_execute + 208\n6   hashcat                         0x000000010394d209 main + 361\n7   libdyld.dylib                   0x00007fff596f8ed9 start + 1\nThread 1:\n0   libsystem_pthread.dylib         0x00007fff598eb3f8 start_wqthread + 0\n1   ???                             0x0000000054485244 0 + 1414025796\nThread 2:\n0   libsystem_kernel.dylib          0x00007fff598395aa __select + 10\n1   hashcat                         0x000000010399b67a thread_keypress + 426\n2   libsystem_pthread.dylib         0x00007fff598ec305 _pthread_body + 126\n3   libsystem_pthread.dylib         0x00007fff598ef26f _pthread_start + 70\n4   libsystem_pthread.dylib         0x00007fff598eb415 thread_start + 13\nThread 3:\n0   libsystem_pthread.dylib         0x00007fff598eb3f8 start_wqthread + 0\n1   ???                             0x0000000054485244 0 + 1414025796\nThread 4:\n0   libsystem_kernel.dylib          0x00007fff59835eae __semwait_signal + 10\n1   libsystem_c.dylib               0x00007fff597c0830 nanosleep + 199\n2   libsystem_c.dylib               0x00007fff597c0692 sleep + 41\n3   hashcat                         0x000000010396c04a thread_monitor + 250\n4   libsystem_pthread.dylib         0x00007fff598ec305 _pthread_body + 126\n5   libsystem_pthread.dylib         0x00007fff598ef26f _pthread_start + 70\n6   libsystem_pthread.dylib         0x00007fff598eb415 thread_start + 13\nThread 5:\n0   libsystem_kernel.dylib          0x00007fff59835eae __semwait_signal + 10\n1   libsystem_c.dylib               0x00007fff597c0830 nanosleep + 199\n2   libsystem_c.dylib               0x00007fff597c0692 sleep + 41\n3   hashcat                         0x000000010398265a thread_outfile_remove + 362\n4   libsystem_pthread.dylib         0x00007fff598ec305 _pthread_body + 126\n5   libsystem_pthread.dylib         0x00007fff598ef26f _pthread_start + 70\n6   libsystem_pthread.dylib         0x00007fff598eb415 thread_start + 13\nThread 6 Crashed:: Dispatch queue: opencl_runtime\n0   libsystem_kernel.dylib          0x00007fff5983823e __pthread_kill + 10\n1   libsystem_pthread.dylib         0x00007fff598eec1c pthread_kill + 285\n2   libsystem_c.dylib               0x00007fff597a11c9 abort + 127\n3   libGPUSupportMercury.dylib      0x00007fff47fc91c5 gpusGenerateCrashLog + 168\n4   com.apple.driver.AppleIntelKBLGraphicsGLDriver  0x00007fff25813802 gpusKillClientExt + 9\n5   libGPUSupportMercury.dylib      0x00007fff47fc9b51 gpusQueueSubmitDataBuffers + 162\n6   com.apple.driver.AppleIntelKBLGraphicsGLDriver  0x00007fff24e84bf3 IntelCLCommandBuffer::getNew(GLDQueueRec) + 31\n7   com.apple.driver.AppleIntelKBLGraphicsGLDriver  0x00007fff24e84ae3 intelSubmitCLCommands(GLDQueueRec, unsigned int) + 69\n8   com.apple.driver.AppleIntelKBLGraphicsGLDriver  0x00007fff24e84a30 CHAL_INTEL::ChalContext::ChalFlush() + 82\n9   com.apple.driver.AppleIntelKBLGraphicsGLDriver  0x00007fff24e849a1 gldFinishQueue + 43\n10  com.apple.opencl                0x00007fff3506258f 0x7fff35051000 + 71055\n11  com.apple.opencl                0x00007fff350629d9 0x7fff35051000 + 72153\n12  com.apple.opencl                0x00007fff3507c0ac 0x7fff35051000 + 176300\n13  com.apple.opencl                0x00007fff3507dd9e 0x7fff35051000 + 183710\n14  libdispatch.dylib               0x00007fff596aadcf _dispatch_client_callout + 8\n15  libdispatch.dylib               0x00007fff596b6a2c _dispatch_lane_barrier_sync_invoke_and_complete + 60\n16  com.apple.opencl                0x00007fff3507dc22 0x7fff35051000 + 183330\n17  com.apple.opencl                0x00007fff3507b1e6 0x7fff35051000 + 172518\n18  com.apple.opencl                0x00007fff3507256f clEnqueueReadBuffer + 820\n19  hashcat                         0x0000000103971b2c hc_clEnqueueReadBuffer + 60\n20  hashcat                         0x000000010396542e check_cracked + 126\n21  hashcat                         0x000000010397531c run_cracker + 1612\n22  hashcat                         0x000000010395f2ab thread_calc + 3035\n23  libsystem_pthread.dylib         0x00007fff598ec305 _pthread_body + 126\n24  libsystem_pthread.dylib         0x00007fff598ef26f _pthread_start + 70\n25  libsystem_pthread.dylib         0x00007fff598eb415 thread_start + 13\nThread 7:\n0   libsystem_kernel.dylib          0x00007fff5983217a mach_msg_trap + 10\n1   libsystem_kernel.dylib          0x00007fff598326d0 mach_msg + 60\n2   com.apple.framework.IOKit       0x00007fff2eef2613 io_connect_method + 374\n3   com.apple.framework.IOKit       0x00007fff2eef2fb2 IOConnectCallScalarMethod + 76\n4   com.apple.IOAccelerator         0x00007fff4a40b23f IOAccelContextFinishFenceEvent + 41\n5   libGPUSupportMercury.dylib      0x00007fff47fcb07a gldFinishFenceOnQueue + 127\n6   com.apple.opencl                0x00007fff35063f10 0x7fff35051000 + 77584\n7   com.apple.opencl                0x00007fff3507a290 0x7fff35051000 + 168592\n8   com.apple.opencl                0x00007fff3507a134 clWaitForEvents + 185\n9   hashcat                         0x000000010397386b run_kernel + 2331\n10  hashcat                         0x0000000103972a0d choose_kernel + 1069\n11  hashcat                         0x000000010397508e run_cracker + 958\n12  hashcat                         0x000000010395f2ab thread_calc + 3035\n13  libsystem_pthread.dylib         0x00007fff598ec305 _pthread_body + 126\n14  libsystem_pthread.dylib         0x00007fff598ef26f _pthread_start + 70\n15  libsystem_pthread.dylib         0x00007fff598eb415 thread_start + 13\nThread 6 crashed with X86 Thread State (64-bit):\n  rax: 0x0000000000000000  rbx: 0x00007000063db000  rcx: 0x00007000063da2a8  rdx: 0x0000000000000000\n  rdi: 0x0000000000004107  rsi: 0x0000000000000006  rbp: 0x00007000063da2e0  rsp: 0x00007000063da2a8\n   r8: 0x00007000063da0b0   r9: 0x0000000000000010  r10: 0x0000000000000000  r11: 0x0000000000000206\n  r12: 0x0000000000004107  r13: 0x00007fec08909400  r14: 0x0000000000000006  r15: 0x000000000000002d\n  rip: 0x00007fff5983823e  rfl: 0x0000000000000206  cr2: 0x00007fff8c4d2188\nLogical CPU:     0\nError Code:      0x02000148\nTrap Number:     133\nBinary Images:\n       0x10394c000 -        0x1039beffb +hashcat (0) <7C1D0E07-1BD0-30B7-B4E1-6994DE347D68> /Users/USER/Downloads//hashcat\n       0x104236000 -        0x104369fff  com.apple.AMDRadeonX5000GLDriver (2.4.10 - 2.0.4) <7A491375-456D-31BE-BBB2-6378CC1F1879> /System/Library/Extensions/AMDRadeonX5000GLDriver.bundle/Contents/MacOS/AMDRadeonX5000GLDriver\n       0x1043df000 -        0x1043faff3 +module_02500.so (0)  /Users/USER/Downloads//module_02500.so\n       0x104fae000 -        0x10502ca87  dyld (655.1) <3EBA447F-A546-366B-B302-8DC3B21A3E30> /usr/lib/dyld\n    0x7fff22f47000 -     0x7fff236c0ff3  ATIRadeonX5000SCLib.dylib (2.4.10) <5DD9CA94-44E4-310E-B61A-5B24F9D59E2F> /System/Library/Extensions/AMDRadeonX5000GLDriver.bundle/Contents/MacOS/ATIRadeonX5000SCLib.dylib\n    0x7fff24c6b000 -     0x7fff25a4bfff  com.apple.driver.AppleIntelKBLGraphicsGLDriver (12.4.7.2 - 12.0.4) <3F6416CB-D223-30F3-9B46-5BD1AAB39D52> /System/Library/Extensions/AppleIntelKBLGraphicsGLDriver.bundle/Contents/MacOS/AppleIntelKBLGraphicsGLDriver\n    0x7fff2879c000 -     0x7fff2879cfff  com.apple.Accelerate (1.11 - Accelerate 1.11)  /System/Library/Frameworks/Accelerate.framework/Versions/A/Accelerate\n    0x7fff287b4000 -     0x7fff28e54fe3  com.apple.vImage (8.1 - ???)  /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vImage.framework/Versions/A/vImage\n    0x7fff28e55000 -     0x7fff290ccfd7  libBLAS.dylib (1243.200.4) <0ADBEAE3-6636-33E5-AC9F-11C2249E19D3> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib\n    0x7fff290cd000 -     0x7fff2913ffe7  libBNNS.dylib (38.200.5)  /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBNNS.dylib\n    0x7fff29140000 -     0x7fff294e6fff  libLAPACK.dylib (1243.200.4) <45722A8A-5788-3C4C-ADD9-1812763FA635> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib\n    0x7fff294e7000 -     0x7fff294fcffb  libLinearAlgebra.dylib (1243.200.4) <3923AB79-213E-32FD-AC87-8B1A1A832336> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLinearAlgebra.dylib\n    0x7fff294fd000 -     0x7fff29502ff3  libQuadrature.dylib (3.200.2) <4FBCAC0A-81A4-3C53-8458-27F3569C809D> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libQuadrature.dylib\n    0x7fff29503000 -     0x7fff29580ffb  libSparse.dylib (79.200.5) <2D650C50-E87E-3F24-9BFA-C8EB6DE1A6E9> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparse.dylib\n    0x7fff29581000 -     0x7fff29594ffb  libSparseBLAS.dylib (1243.200.4) <6F8C78BE-A0FD-3507-8A95-541AFC57F1EE> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libSparseBLAS.dylib\n    0x7fff29595000 -     0x7fff29779ff3  libvDSP.dylib (671.220.1) <2F576522-08B1-3C65-8F00-3427E938ADDA> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvDSP.dylib\n    0x7fff2977a000 -     0x7fff2982fff3  libvMisc.dylib (671.220.1)  /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libvMisc.dylib\n    0x7fff29830000 -     0x7fff29830fff  com.apple.Accelerate.vecLib (3.11 - vecLib 3.11) <221E4FEF-0431-3316-8281-22B6F8315A09> /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/vecLib\n    0x7fff2a854000 -     0x7fff2a854fff  com.apple.ApplicationServices (50.1 - 50.1) <86D6F10E-21F8-3CDC-9838-EB07A1C54BA9> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/ApplicationServices\n    0x7fff2a855000 -     0x7fff2a8c0ff7  com.apple.ApplicationServices.ATS (377 - 453.11) <4080F8BE-F2A2-3707-8754-436FBDB1DAF1> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/ATS\n    0x7fff2a959000 -     0x7fff2aa78fff  libFontParser.dylib (228.6)  /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontParser.dylib\n    0x7fff2aa79000 -     0x7fff2aac4ff7  libFontRegistry.dylib (228.12.1.1)  /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/Versions/A/Resources/libFontRegistry.dylib\n    0x7fff2abc0000 -     0x7fff2abc4ff3  com.apple.ColorSyncLegacy (4.13.0 - 1) <4B1238CC-9B77-3AA5-8329-EE3C736F07EA> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ColorSyncLegacy.framework/Versions/A/ColorSyncLegacy\n    0x7fff2ac61000 -     0x7fff2acb3ff3  com.apple.HIServices (1.22 - 627.14.2) <1F851BF9-AD29-3558-9EA5-AAD9BAAAC823> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/HIServices.framework/Versions/A/HIServices\n    0x7fff2acb4000 -     0x7fff2acc2ff3  com.apple.LangAnalysis (1.7.0 - 1.7.0) <5654723A-7B3B-391F-B9F7-0DE4D5940185> /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/LangAnalysis.framework/Versions/A/LangAnalysis\n    0x7fff2acc3000 -     0x7fff2ad0ffff  com.apple.print.framework.PrintCore (14.2 - 503.8)  /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore\n    0x7fff2ad10000 -     0x7fff2ad4bff7  com.apple.QD (3.12 - 407.2)  /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/QD.framework/Versions/A/QD\n    0x7fff2ad4c000 -     0x7fff2ad58ff7  com.apple.speech.synthesis.framework (8.1.0 - 8.1.0)  /System/Library/Frameworks/ApplicationServices.framework/Versions/A/Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis\n    0x7fff2ad59000 -     0x7fff2aff6fff  com.apple.audio.toolbox.AudioToolbox (1.14 - 1.14) <5D484151-F269-3D98-B507-0544A6B950AC> /System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox\n    0x7fff2b35c000 -     0x7fff2b71dfff  com.apple.CFNetwork (976 - 976)  /System/Library/Frameworks/CFNetwork.framework/Versions/A/CFNetwork\n    0x7fff2bc5b000 -     0x7fff2bd27fff  com.apple.ColorSync (4.13.0 - 3340) <2F45EB01-0C51-3D25-9836-18F99222E1C7> /System/Library/Frameworks/ColorSync.framework/Versions/A/ColorSync\n    0x7fff2bec2000 -     0x7fff2bf52fff  com.apple.audio.CoreAudio (4.3.0 - 4.3.0) <1E7EF105-B843-370D-884E-0A43E1A5800B> /System/Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio\n    0x7fff2bfe4000 -     0x7fff2c385fef  com.apple.CoreData (120 - 866.1) <18CD58FD-513E-385B-B43C-08EEB909709C> /System/Library/Frameworks/CoreData.framework/Versions/A/CoreData\n    0x7fff2c386000 -     0x7fff2c46fff7  com.apple.CoreDisplay (101.3 - 106.2)  /System/Library/Frameworks/CoreDisplay.framework/Versions/A/CoreDisplay\n    0x7fff2c470000 -     0x7fff2c8bdfef  com.apple.CoreFoundation (6.9 - 1562) <02A2C178-9FF6-385C-A9C5-7F4FC9D66311> /System/Library/Frameworks/CoreFoundation.framework/Versions/A/CoreFoundation\n    0x7fff2c8bf000 -     0x7fff2cf4cff7  com.apple.CoreGraphics (2.0 - 1249.2) <78B75F62-4B60-3FF4-9259-8981E755F6CD> /System/Library/Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics\n    0x7fff2cf4e000 -     0x7fff2d277fff  com.apple.CoreImage (14.2.0 - 720.0.130)  /System/Library/Frameworks/CoreImage.framework/Versions/A/CoreImage\n    0x7fff2d72d000 -     0x7fff2d72dfff  com.apple.CoreServices (941 - 941) <6DBA4791-26DB-39FB-A6A3-5910A0F2EDD2> /System/Library/Frameworks/CoreServices.framework/Versions/A/CoreServices\n    0x7fff2d72e000 -     0x7fff2d7acffb  com.apple.AE (771 - 771) <4B009524-699E-3891-98DD-E3B6BB433C8F> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/AE.framework/Versions/A/AE\n    0x7fff2d7ad000 -     0x7fff2da85ff7  com.apple.CoreServices.CarbonCore (1178.16 - 1178.16) <17FC2B9E-EB6C-3768-A2D0-6E086F2563D9> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/CarbonCore.framework/Versions/A/CarbonCore\n    0x7fff2da86000 -     0x7fff2dad0ff7  com.apple.DictionaryServices (1.2 - 284.16.3) <1DAC9153-FB5A-3798-8797-CBFEFF227F71> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/DictionaryServices.framework/Versions/A/DictionaryServices\n    0x7fff2dad1000 -     0x7fff2dad9ffb  com.apple.CoreServices.FSEvents (1239.200.12 - 1239.200.12) <8E1507EA-F0A8-3845-B32D-4FBC1381E89C> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/FSEvents.framework/Versions/A/FSEvents\n    0x7fff2dada000 -     0x7fff2dca5fff  com.apple.LaunchServices (941 - 941)  /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/LaunchServices.framework/Versions/A/LaunchServices\n    0x7fff2dca6000 -     0x7fff2dd48fff  com.apple.Metadata (10.7.0 - 1191.53) <48609998-8A34-3CAF-8A42-52C180809656> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/Metadata.framework/Versions/A/Metadata\n    0x7fff2dd49000 -     0x7fff2dd94ff7  com.apple.CoreServices.OSServices (941 - 941) <1B9EA259-09DF-332B-807A-BD50F3184CAC> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/OSServices.framework/Versions/A/OSServices\n    0x7fff2dd95000 -     0x7fff2de03ff7  com.apple.SearchKit (1.4.0 - 1.4.0)  /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SearchKit.framework/Versions/A/SearchKit\n    0x7fff2de04000 -     0x7fff2de28ffb  com.apple.coreservices.SharedFileList (71.27 - 71.27) <6389B59D-DDAC-3C97-A982-137B9B1FB734> /System/Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/SharedFileList.framework/Versions/A/SharedFileList\n    0x7fff2e170000 -     0x7fff2e2d5ffb  com.apple.CoreText (352.0 - 584.26) <5F61037C-825D-37A4-9091-0047413CC213> /System/Library/Frameworks/CoreText.framework/Versions/A/CoreText\n    0x7fff2e2d6000 -     0x7fff2e313fff  com.apple.CoreVideo (1.8 - 0.0) <34EC73F1-F0ED-32F5-B96E-7683B1F9A7A2> /System/Library/Frameworks/CoreVideo.framework/Versions/A/CoreVideo\n    0x7fff2e627000 -     0x7fff2e62cfff  com.apple.DiskArbitration (2.7 - 2.7) <97707A79-30E7-3D99-AA20-B992B0900BC4> /System/Library/Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration\n    0x7fff2e7f5000 -     0x7fff2ebc3fff  com.apple.Foundation (6.9 - 1562) <83D4A12B-EA5A-3C62-8D93-95E64F0A256B> /System/Library/Frameworks/Foundation.framework/Versions/C/Foundation\n    0x7fff2ec34000 -     0x7fff2ec64ff3  com.apple.GSS (4.0 - 2.0) <86D07291-5DFC-30C2-9A18-5FCEDB0BE621> /System/Library/Frameworks/GSS.framework/Versions/A/GSS\n    0x7fff2eeea000 -     0x7fff2ef7dfff  com.apple.framework.IOKit (2.0.2 - 1483.240.1) <241690BB-8AFA-3B6A-A210-67874197CB59> /System/Library/Frameworks/IOKit.framework/Versions/A/IOKit\n    0x7fff2ef7f000 -     0x7fff2ef89ff7  com.apple.IOSurface (255.1 - 255.1) <58826B1A-38E8-3C76-8FFC-76C9282DA893> /System/Library/Frameworks/IOSurface.framework/Versions/A/IOSurface\n    0x7fff2efe0000 -     0x7fff2f17efff  com.apple.ImageIO.framework (3.3.0 - 1822.1) <908907D5-5C29-32F7-ACD9-C6A6D51C4D15> /System/Library/Frameworks/ImageIO.framework/Versions/A/ImageIO\n    0x7fff2f17f000 -     0x7fff2f183ffb  libGIF.dylib (1822.1) <35E37B95-1962-3A25-9C9E-CADD161152B3> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libGIF.dylib\n    0x7fff2f184000 -     0x7fff2f269fe7  libJP2.dylib (1822.1)  /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJP2.dylib\n    0x7fff2f26a000 -     0x7fff2f28fff7  libJPEG.dylib (1822.1)  /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libJPEG.dylib\n    0x7fff2f562000 -     0x7fff2f588fe7  libPng.dylib (1822.1) <28FE6E2C-1A17-3A84-AAF3-76014DEADDD4> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libPng.dylib\n    0x7fff2f589000 -     0x7fff2f58bff7  libRadiance.dylib (1822.1) <687906E3-4EC2-3CE9-B7EA-34418239EE1B> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libRadiance.dylib\n    0x7fff2f58c000 -     0x7fff2f5daffb  libTIFF.dylib (1822.1) <0A1C083B-CE2F-3A00-8E45-EB58DCA2FF34> /System/Library/Frameworks/ImageIO.framework/Versions/A/Resources/libTIFF.dylib\n    0x7fff30684000 -     0x7fff3069dfff  com.apple.Kerberos (3.0 - 1) <5D1B0593-3C0E-32D5-AAE5-ABC22A98B639> /System/Library/Frameworks/Kerberos.framework/Versions/A/Kerberos\n    0x7fff310bf000 -     0x7fff31152fff  com.apple.Metal (158.5 - 158.5) <72BF7187-81FE-389B-882F-7B2587FEB455> /System/Library/Frameworks/Metal.framework/Versions/A/Metal\n    0x7fff3116f000 -     0x7fff3118fff7  com.apple.MetalPerformanceShaders.MPSCore (1.0 - 1) <18281B14-0C6A-38F8-AB80-2D4BB0743C88> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSCore.framework/Versions/A/MPSCore\n    0x7fff31190000 -     0x7fff3120eff7  com.apple.MetalPerformanceShaders.MPSImage (1.0 - 1)  /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSImage.framework/Versions/A/MPSImage\n    0x7fff3120f000 -     0x7fff31237fff  com.apple.MetalPerformanceShaders.MPSMatrix (1.0 - 1) <116D6C1A-2FD7-3743-95A0-CDDA3D459529> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSMatrix.framework/Versions/A/MPSMatrix\n    0x7fff31238000 -     0x7fff3136aff7  com.apple.MetalPerformanceShaders.MPSNeuralNetwork (1.0 - 1) <88E80BEE-3D2B-328B-80D4-F4717BDB2E9F> /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSNeuralNetwork.framework/Versions/A/MPSNeuralNetwork\n    0x7fff3136b000 -     0x7fff31386ff7  com.apple.MetalPerformanceShaders.MPSRayIntersector (1.0 - 1)  /System/Library/Frameworks/MetalPerformanceShaders.framework/Frameworks/MPSRayIntersector.framework/Versions/A/MPSRayIntersector\n    0x7fff31387000 -     0x7fff31387ff7  com.apple.MetalPerformanceShaders.MetalPerformanceShaders (1.0 - 1) <1BBA8BC8-49C6-3C9B-B985-7CE4373E3553> /System/Library/Frameworks/MetalPerformanceShaders.framework/Versions/A/MetalPerformanceShaders\n    0x7fff32585000 -     0x7fff32591ffb  com.apple.NetFS (6.0 - 4.0) <918DF6CD-2DB0-36A8-B869-5EF637A06C0D> /System/Library/Frameworks/NetFS.framework/Versions/A/NetFS\n    0x7fff35048000 -     0x7fff35050fe7  libcldcpuengine.dylib (2.10.3)  /System/Library/Frameworks/OpenCL.framework/Versions/A/Libraries/libcldcpuengine.dylib\n    0x7fff35051000 -     0x7fff350a9fff  com.apple.opencl (2.15.1 - 2.15.1)  /System/Library/Frameworks/OpenCL.framework/Versions/A/OpenCL\n    0x7fff350aa000 -     0x7fff350c6ff7  com.apple.CFOpenDirectory (10.14 - 207.200.4) <2CB1F122-2FA0-347C-8454-9CE0FA150832> /System/Library/Frameworks/OpenDirectory.framework/Versions/A/Frameworks/CFOpenDirectory.framework/Versions/A/CFOpenDirectory\n    0x7fff350c7000 -     0x7fff350d3ffb  com.apple.OpenDirectory (10.14 - 207.200.4)  /System/Library/Frameworks/OpenDirectory.framework/Versions/A/OpenDirectory\n    0x7fff35a36000 -     0x7fff35a38fff  libCVMSPluginSupport.dylib (17.3.1)  /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCVMSPluginSupport.dylib\n    0x7fff35a39000 -     0x7fff35a3eff3  libCoreFSCache.dylib (163.20) <566DB80E-F1D6-3AEC-AF06-08955507AFEE> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreFSCache.dylib\n    0x7fff35a3f000 -     0x7fff35a43fff  libCoreVMClient.dylib (163.20)  /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libCoreVMClient.dylib\n    0x7fff35a44000 -     0x7fff35a4cffb  libGFXShared.dylib (17.3.1) <9FFA679A-8CC9-3932-8A41-AA80C386AD3A> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGFXShared.dylib\n    0x7fff35a4d000 -     0x7fff35a58fff  libGL.dylib (17.3.1)  /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGL.dylib\n    0x7fff35a59000 -     0x7fff35a93fef  libGLImage.dylib (17.3.1) <1AEC8E56-D851-3516-96FE-2829883A8302> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLImage.dylib\n    0x7fff35a94000 -     0x7fff35c06ff3  libGLProgrammability.dylib (17.3.1) <3B701B8D-FF2C-383E-8F94-77B052ECC075> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLProgrammability.dylib\n    0x7fff35c07000 -     0x7fff35c44fff  libGLU.dylib (17.3.1) <90279918-D4B2-31E0-9709-8E06628D9486> /System/Library/Frameworks/OpenGL.framework/Versions/A/Libraries/libGLU.dylib\n    0x7fff365f4000 -     0x7fff36603ff3  com.apple.opengl (17.3.1 - 17.3.1) <2F59064F-D6EF-35CD-9747-20A91DB3D5DF> /System/Library/Frameworks/OpenGL.framework/Versions/A/OpenGL\n    0x7fff3679b000 -     0x7fff367c3ff7  GLRendererFloat (17.3.1) <444BAB14-2648-3CD9-863F-695EA9206059> /System/Library/Frameworks/OpenGL.framework/Versions/A/Resources/GLRendererFloat.bundle/GLRendererFloat\n    0x7fff3745f000 -     0x7fff376b8fff  com.apple.QuartzCore (1.11 - 696.3) <01A2F065-8759-311D-AC2E-FD49F52A87FA> /System/Library/Frameworks/QuartzCore.framework/Versions/A/QuartzCore\n    0x7fff37f0c000 -     0x7fff38234ff7  com.apple.security (7.0 - 58286.240.4) <91A03FF2-2EE9-36A7-AC4F-169E11FE7846> /System/Library/Frameworks/Security.framework/Versions/A/Security\n    0x7fff38235000 -     0x7fff382c4fff  com.apple.securityfoundation (6.0 - 55185.200.14)  /System/Library/Frameworks/SecurityFoundation.framework/Versions/A/SecurityFoundation\n    0x7fff382f6000 -     0x7fff382faff3  com.apple.xpc.ServiceManagement (1.0 - 1) <26BA237C-DBA0-3322-B9BF-8B8E739E3A20> /System/Library/Frameworks/ServiceManagement.framework/Versions/A/ServiceManagement\n    0x7fff386b7000 -     0x7fff38727ff3  com.apple.SystemConfiguration (1.17 - 1.17)  /System/Library/Frameworks/SystemConfiguration.framework/Versions/A/SystemConfiguration\n    0x7fff3b995000 -     0x7fff3ba3afe7  com.apple.APFS (1.0 - 1)  /System/Library/PrivateFrameworks/APFS.framework/Versions/A/APFS\n    0x7fff3c486000 -     0x7fff3c487ff3  com.apple.AggregateDictionary (1.0 - 1)  /System/Library/PrivateFrameworks/AggregateDictionary.framework/Versions/A/AggregateDictionary\n    0x7fff3cd8c000 -     0x7fff3cd9bfcf  com.apple.AppleFSCompression (96.200.3 - 1.0) <78D538DD-1D24-34FC-AFB3-10411494870D> /System/Library/PrivateFrameworks/AppleFSCompression.framework/Versions/A/AppleFSCompression\n    0x7fff3cee5000 -     0x7fff3cf2eff3  com.apple.AppleJPEG (1.0 - 1)  /System/Library/PrivateFrameworks/AppleJPEG.framework/Versions/A/AppleJPEG\n    0x7fff3d181000 -     0x7fff3d1a9ff7  com.apple.applesauce (1.0 - ???) <58654BC0-9243-39D1-BC43-B7F2E37A3A44> /System/Library/PrivateFrameworks/AppleSauce.framework/Versions/A/AppleSauce\n    0x7fff3d30f000 -     0x7fff3d325ffb  com.apple.AssertionServices (1.0 - 1) <3F767D20-FE14-35CF-A089-E0445375ECFB> /System/Library/PrivateFrameworks/AssertionServices.framework/Versions/A/AssertionServices\n    0x7fff3dad5000 -     0x7fff3dadeff3  com.apple.coreservices.BackgroundTaskManagement (1.0 - 57.1) <05CF66F0-9650-3F75-9857-F8D186043866> /System/Library/PrivateFrameworks/BackgroundTaskManagement.framework/Versions/A/BackgroundTaskManagement\n    0x7fff3db82000 -     0x7fff3dbf3ffb  com.apple.BaseBoard (360.24 - 360.24) <04AF4372-C5D3-3F0A-A688-68D888D6D138> /System/Library/PrivateFrameworks/BaseBoard.framework/Versions/A/BaseBoard\n    0x7fff3f7a8000 -     0x7fff3f7b1fff  com.apple.CommonAuth (4.0 - 2.0) <090893E5-BB65-39DA-A174-EAB2C7191EFE> /System/Library/PrivateFrameworks/CommonAuth.framework/Versions/A/CommonAuth\n    0x7fff404c2000 -     0x7fff404d6fff  com.apple.CoreEmoji (1.0 - 69.19.8) <26BC0F82-08C1-3EBD-9299-D3CC5091C467> /System/Library/PrivateFrameworks/CoreEmoji.framework/Versions/A/CoreEmoji\n    0x7fff40aac000 -     0x7fff40b1eff7  com.apple.CoreNLP (1.0 - 130.15.22)  /System/Library/PrivateFrameworks/CoreNLP.framework/Versions/A/CoreNLP\n    0x7fff40f80000 -     0x7fff40fb1fff  com.apple.CoreServicesInternal (357 - 357) <789E57F4-5A14-3220-93DF-1D4FEE315431> /System/Library/PrivateFrameworks/CoreServicesInternal.framework/Versions/A/CoreServicesInternal\n    0x7fff418b5000 -     0x7fff418b9ff7  com.apple.DSExternalDisplay (3.1 - 380) <76449D22-BA27-3FB1-AD25-A290936E6DEA> /System/Library/PrivateFrameworks/DSExternalDisplay.framework/Versions/A/DSExternalDisplay\n    0x7fff42bde000 -     0x7fff43006fff  com.apple.vision.FaceCore (3.3.4 - 3.3.4) <41218EB7-19C9-3813-A793-B0623387CADF> /System/Library/PrivateFrameworks/FaceCore.framework/Versions/A/FaceCore\n    0x7fff47fc7000 -     0x7fff47fd2ff7  libGPUSupportMercury.dylib (17.3.1)  /System/Library/PrivateFrameworks/GPUSupport.framework/Versions/A/Libraries/libGPUSupportMercury.dylib\n    0x7fff47fd3000 -     0x7fff47fd8ff7  com.apple.GPUWrangler (3.28.4 - 3.28.4) <7E06C75D-5502-3F1D-987C-4F103917CD85> /System/Library/PrivateFrameworks/GPUWrangler.framework/Versions/A/GPUWrangler\n    0x7fff48e43000 -     0x7fff48e52fff  com.apple.GraphVisualizer (1.0 - 5)  /System/Library/PrivateFrameworks/GraphVisualizer.framework/Versions/A/GraphVisualizer\n    0x7fff48fa3000 -     0x7fff49018fff  com.apple.Heimdal (4.0 - 2.0)  /System/Library/PrivateFrameworks/Heimdal.framework/Versions/A/Heimdal\n    0x7fff4a408000 -     0x7fff4a40fffb  com.apple.IOAccelerator (404.2.2 - 404.2.2) <2F099589-DBE9-3442-AC93-F4AB363482A0> /System/Library/PrivateFrameworks/IOAccelerator.framework/Versions/A/IOAccelerator\n    0x7fff4a413000 -     0x7fff4a42cfff  com.apple.IOPresentment (1.0 - 42.6)  /System/Library/PrivateFrameworks/IOPresentment.framework/Versions/A/IOPresentment\n    0x7fff4ab3f000 -     0x7fff4ac36fff  com.apple.LanguageModeling (1.0 - 159.15.15) <34609F31-4DA1-3881-8947-85BEA7AFC938> /System/Library/PrivateFrameworks/LanguageModeling.framework/Versions/A/LanguageModeling\n    0x7fff4ac37000 -     0x7fff4ac78ff7  com.apple.Lexicon-framework (1.0 - 33.15.10) <07E008F3-E823-333B-8B41-A46024AB0561> /System/Library/PrivateFrameworks/Lexicon.framework/Versions/A/Lexicon\n    0x7fff4ac7f000 -     0x7fff4ac85ff7  com.apple.LinguisticData (1.0 - 238.23.4)  /System/Library/PrivateFrameworks/LinguisticData.framework/Versions/A/LinguisticData\n    0x7fff4b9e2000 -     0x7fff4ba0affb  com.apple.spotlight.metadata.utilities (1.0 - 1191.53) <2CFFD786-87A5-3629-B5E1-8E4DEF51ADA8> /System/Library/PrivateFrameworks/MetadataUtilities.framework/Versions/A/MetadataUtilities\n    0x7fff4ba0b000 -     0x7fff4ba9dfff  com.apple.gpusw.MetalTools (1.0 - 1)  /System/Library/PrivateFrameworks/MetalTools.framework/Versions/A/MetalTools\n    0x7fff4bcf1000 -     0x7fff4bd1bff7  com.apple.MultitouchSupport.framework (2410.5 - 2410.5) <3A712911-F672-3BB3-B62B-A2A7BADF3578> /System/Library/PrivateFrameworks/MultitouchSupport.framework/Versions/A/MultitouchSupport\n    0x7fff4bf8e000 -     0x7fff4bf99fff  com.apple.NetAuth (6.2 - 6.2)  /System/Library/PrivateFrameworks/NetAuth.framework/Versions/A/NetAuth\n    0x7fff4c866000 -     0x7fff4c8bcfff  com.apple.OTSVG (1.0 - ???)  /System/Library/PrivateFrameworks/OTSVG.framework/Versions/A/OTSVG\n    0x7fff525ab000 -     0x7fff5285dff3  com.apple.SkyLight (1.600.0 - 337.5)  /System/Library/PrivateFrameworks/SkyLight.framework/Versions/A/SkyLight\n    0x7fff54432000 -     0x7fff5443fffb  com.apple.TCC (1.0 - 1) <81F88B91-49C1-36E7-8A39-C4BD654EE942> /System/Library/PrivateFrameworks/TCC.framework/Versions/A/TCC\n    0x7fff54833000 -     0x7fff54834fff  com.apple.TrustEvaluationAgent (2.0 - 31.200.1) <5C3E1B2D-40A8-3237-A8D9-4E7B15EEA678> /System/Library/PrivateFrameworks/TrustEvaluationAgent.framework/Versions/A/TrustEvaluationAgent\n    0x7fff56426000 -     0x7fff56428ff3  com.apple.loginsupport (1.0 - 1) <67BC49D6-320F-33ED-912E-16E5A342F385> /System/Library/PrivateFrameworks/login.framework/Versions/A/Frameworks/loginsupport.framework/Versions/A/loginsupport\n    0x7fff566e3000 -     0x7fff5671bfff  libCRFSuite.dylib (41.15.4) <92752A96-D1CF-3CA1-837A-1E075AE4C642> /usr/lib/libCRFSuite.dylib\n    0x7fff5671e000 -     0x7fff56729ff7  libChineseTokenizer.dylib (28.15.3) <55572692-4918-3C54-AD35-726E03EC47D5> /usr/lib/libChineseTokenizer.dylib\n    0x7fff567ba000 -     0x7fff567bbff7  libDiagnosticMessagesClient.dylib (107) <15210AC0-61F9-3F9D-A159-A009F62EB537> /usr/lib/libDiagnosticMessagesClient.dylib\n    0x7fff567f2000 -     0x7fff569b5ff7  libFosl_dynamic.dylib (18.3.2)  /usr/lib/libFosl_dynamic.dylib\n    0x7fff56a0b000 -     0x7fff56a2aff7  libMobileGestalt.dylib (645.220.9)  /usr/lib/libMobileGestalt.dylib\n    0x7fff56a2b000 -     0x7fff56a2bfff  libOpenScriptingUtil.dylib (179) <441A2E60-5D5C-3567-9B00-AA22E6EE5358> /usr/lib/libOpenScriptingUtil.dylib\n    0x7fff56b6c000 -     0x7fff56b6dffb  libSystem.B.dylib (1252.200.5)  /usr/lib/libSystem.B.dylib\n    0x7fff56bf7000 -     0x7fff56bf8fff  libThaiTokenizer.dylib (2.15.1)  /usr/lib/libThaiTokenizer.dylib\n    0x7fff56c0b000 -     0x7fff56c21ffb  libapple_nghttp2.dylib (1.24.1) <71C126C5-D869-3E67-9778-058FA7F3CA74> /usr/lib/libapple_nghttp2.dylib\n    0x7fff56c22000 -     0x7fff56c4bffb  libarchive.2.dylib (54.200.3) <32B8634D-E465-3F6D-B254-A20D44504508> /usr/lib/libarchive.2.dylib\n    0x7fff56ccf000 -     0x7fff56ccfff3  libauto.dylib (187) <003DEF68-0C59-3AFB-A7B7-A1B5ED301AF2> /usr/lib/libauto.dylib\n    0x7fff56da6000 -     0x7fff56db6ff3  libbsm.0.dylib (39.200.18) <58A9ACEC-BF46-3A4E-86F5-3DD9AD7095B4> /usr/lib/libbsm.0.dylib\n    0x7fff56db7000 -     0x7fff56dc5fff  libbz2.1.0.dylib (38.200.3) <4DEC3797-087F-3C8D-815B-48E895813251> /usr/lib/libbz2.1.0.dylib\n    0x7fff56dc6000 -     0x7fff56e1dff7  libc++.1.dylib (400.9.4)  /usr/lib/libc++.1.dylib\n    0x7fff56e1e000 -     0x7fff56e33fff  libc++abi.dylib (400.17) <446F4748-8A89-3D2E-AE1C-27EEBE93A8AB> /usr/lib/libc++abi.dylib\n    0x7fff56e34000 -     0x7fff56e34ff3  libcharset.1.dylib (51.200.6) <43F7E100-F5D1-36AB-A26E-CF94196A19C0> /usr/lib/libcharset.1.dylib\n    0x7fff56e35000 -     0x7fff56e45ffb  libcmph.dylib (6.15.1)  /usr/lib/libcmph.dylib\n    0x7fff56e46000 -     0x7fff56e5effb  libcompression.dylib (52.200.13) <05A2A91B-D24D-39E8-A071-261CBC5BB158> /usr/lib/libcompression.dylib\n    0x7fff57109000 -     0x7fff5711ffff  libcoretls.dylib (155.220.1) <1229F9EA-C070-3D03-9DC6-F548C59F9FD5> /usr/lib/libcoretls.dylib\n    0x7fff57120000 -     0x7fff57121ff3  libcoretls_cfhelpers.dylib (155.220.1) <33661841-3C3B-3608-86AC-C88D1CD6FE98> /usr/lib/libcoretls_cfhelpers.dylib\n    0x7fff572c0000 -     0x7fff57450ffb  libcrypto.35.dylib (22.240.1) <603427B4-6A5E-367B-B164-744606A2AA27> /usr/lib/libcrypto.35.dylib\n    0x7fff57798000 -     0x7fff577efffb  libcups.2.dylib (462.10) <29B6D106-A5F2-321D-8916-90F595545D88> /usr/lib/libcups.2.dylib\n    0x7fff57927000 -     0x7fff57927fff  libenergytrace.dylib (17.200.1)  /usr/lib/libenergytrace.dylib\n    0x7fff57959000 -     0x7fff5795eff7  libgermantok.dylib (17.15.2) <9381B152-5CFD-3D23-A5A7-4D64EE55B85E> /usr/lib/libgermantok.dylib\n    0x7fff5795f000 -     0x7fff57964ff7  libheimdal-asn1.dylib (520.220.2)  /usr/lib/libheimdal-asn1.dylib\n    0x7fff57990000 -     0x7fff57a81ff7  libiconv.2.dylib (51.200.6) <9FB95807-7C62-32B7-A19F-946D7FB7CCA6> /usr/lib/libiconv.2.dylib\n    0x7fff57a82000 -     0x7fff57ce5ffb  libicucore.A.dylib (62109.0.1)  /usr/lib/libicucore.A.dylib\n    0x7fff57d32000 -     0x7fff57d33fff  liblangid.dylib (128.15.1) <663D0A24-7260-31D1-9BFE-74D67B6F72F6> /usr/lib/liblangid.dylib\n    0x7fff57d34000 -     0x7fff57d4cfff  liblzma.5.dylib (10.200.3) <9A52A949-0CB1-39B6-9244-D079FB609559> /usr/lib/liblzma.5.dylib\n    0x7fff57d64000 -     0x7fff57e14fff  libmecab.1.0.0.dylib (779.24.1) <590BC39C-2A3E-368B-9499-C808B84C4955> /usr/lib/libmecab.1.0.0.dylib\n    0x7fff57e15000 -     0x7fff58052ff7  libmecabra.dylib (779.24.1) <22BFD5A8-EA42-3DC3-8910-F27DCFB1B631> /usr/lib/libmecabra.dylib\n    0x7fff5822a000 -     0x7fff58582ffb  libnetwork.dylib (1229.240.1)  /usr/lib/libnetwork.dylib\n    0x7fff58614000 -     0x7fff58d9afe7  libobjc.A.dylib (750.1) <804715F4-F52D-34D0-8FEC-A25DC08513C3> /usr/lib/libobjc.A.dylib\n    0x7fff58dad000 -     0x7fff58db1ffb  libpam.2.dylib (22.200.1) <85253002-89F2-3872-9C8A-1801303A2EBB> /usr/lib/libpam.2.dylib\n    0x7fff58db4000 -     0x7fff58deaff7  libpcap.A.dylib (79.200.4) <6D25197A-2F7C-3147-A45A-F6F13E55909F> /usr/lib/libpcap.A.dylib\n    0x7fff58f04000 -     0x7fff58f1cffb  libresolv.9.dylib (65.200.2)  /usr/lib/libresolv.9.dylib\n    0x7fff58f70000 -     0x7fff59147fe7  libsqlite3.dylib (274.22)  /usr/lib/libsqlite3.dylib\n    0x7fff593d4000 -     0x7fff593d7ffb  libutil.dylib (51.200.4) <10C5E165-0939-363A-9D13-7076F3B513EC> /usr/lib/libutil.dylib\n    0x7fff593d8000 -     0x7fff593e5fff  libxar.1.dylib (404) <16E875B3-CF89-3059-87BB-36D301B32E7B> /usr/lib/libxar.1.dylib\n    0x7fff593ea000 -     0x7fff594cdfff  libxml2.2.dylib (32.8) <3E7875AC-3195-3800-AC48-8AA3B7BE51E4> /usr/lib/libxml2.2.dylib\n    0x7fff594ce000 -     0x7fff594f6ff3  libxslt.1.dylib (16.1)  /usr/lib/libxslt.1.dylib\n    0x7fff594f7000 -     0x7fff59509ffb  libz.1.dylib (70.200.4) <15F7B40A-424C-33BB-BF2C-7E8195128B78> /usr/lib/libz.1.dylib\n    0x7fff5957a000 -     0x7fff5957eff3  libcache.dylib (81) <704331AC-E43D-343A-8C24-39201142AF27> /usr/lib/system/libcache.dylib\n    0x7fff5957f000 -     0x7fff59589ff3  libcommonCrypto.dylib (60118.220.1) <9C865644-EE9A-3662-AB77-7C8A5E561784> /usr/lib/system/libcommonCrypto.dylib\n    0x7fff5958a000 -     0x7fff59591fff  libcompiler_rt.dylib (63.4) <817772E3-E836-3FFD-A39B-BDCD1C357221> /usr/lib/system/libcompiler_rt.dylib\n    0x7fff59592000 -     0x7fff5959bff3  libcopyfile.dylib (146.200.3) <5C5C4F35-DAB7-3CF1-940F-F47192AB8289> /usr/lib/system/libcopyfile.dylib\n    0x7fff5959c000 -     0x7fff59620fdf  libcorecrypto.dylib (602.230.1)  /usr/lib/system/libcorecrypto.dylib\n    0x7fff596a7000 -     0x7fff596e1ff7  libdispatch.dylib (1008.220.2) <2FDB1401-5119-3DF0-91F5-F4E105F00CD7> /usr/lib/system/libdispatch.dylib\n    0x7fff596e2000 -     0x7fff59711ff3  libdyld.dylib (655.1) <90C801E7-5D05-37A8-810C-B58E8C53953A> /usr/lib/system/libdyld.dylib\n    0x7fff59712000 -     0x7fff59712ffb  libkeymgr.dylib (30)  /usr/lib/system/libkeymgr.dylib\n    0x7fff59713000 -     0x7fff5971fff7  libkxld.dylib (4903.241.1)  /usr/lib/system/libkxld.dylib\n    0x7fff59720000 -     0x7fff59720ff7  liblaunch.dylib (1336.240.2)  /usr/lib/system/liblaunch.dylib\n    0x7fff59721000 -     0x7fff59726fff  libmacho.dylib (921) <6ADB99F3-D142-3A0A-B3CE-031354766ACC> /usr/lib/system/libmacho.dylib\n    0x7fff59727000 -     0x7fff59729ffb  libquarantine.dylib (86.220.1) <58524FD7-63C5-38E0-9D90-845A79551C14> /usr/lib/system/libquarantine.dylib\n    0x7fff5972a000 -     0x7fff5972bff3  libremovefile.dylib (45.200.2)  /usr/lib/system/libremovefile.dylib\n    0x7fff5972c000 -     0x7fff59743ff3  libsystem_asl.dylib (356.200.4) <33C62769-1242-3BC1-9459-13CBCDECC7FE> /usr/lib/system/libsystem_asl.dylib\n    0x7fff59744000 -     0x7fff59744fff  libsystem_blocks.dylib (73) <152EDADF-7D94-35F2-89B7-E66DCD945BBA> /usr/lib/system/libsystem_blocks.dylib\n    0x7fff59745000 -     0x7fff597cdfff  libsystem_c.dylib (1272.200.26)  /usr/lib/system/libsystem_c.dylib\n    0x7fff597ce000 -     0x7fff597d1ff7  libsystem_configuration.dylib (963.200.27) <94898525-ECC8-3CC9-B312-CBEAAC305E32> /usr/lib/system/libsystem_configuration.dylib\n    0x7fff597d2000 -     0x7fff597d5ff7  libsystem_coreservices.dylib (66) <10818C17-70E1-328E-A3E3-C3EB81AEC590> /usr/lib/system/libsystem_coreservices.dylib\n    0x7fff597d6000 -     0x7fff597dcffb  libsystem_darwin.dylib (1272.200.26) <07468CF7-982F-37C4-83D0-D5E602A683AA> /usr/lib/system/libsystem_darwin.dylib\n    0x7fff597dd000 -     0x7fff597e3ff7  libsystem_dnssd.dylib (878.240.1) <5FEA5E1E-E80F-3616-AD33-8E936D61F31A> /usr/lib/system/libsystem_dnssd.dylib\n    0x7fff597e4000 -     0x7fff59830ff3  libsystem_info.dylib (517.200.9) <54B65F21-2E93-3579-9B72-6637A03245D9> /usr/lib/system/libsystem_info.dylib\n    0x7fff59831000 -     0x7fff59859ff7  libsystem_kernel.dylib (4903.241.1)  /usr/lib/system/libsystem_kernel.dylib\n    0x7fff5985a000 -     0x7fff598a5ff7  libsystem_m.dylib (3158.200.7)  /usr/lib/system/libsystem_m.dylib\n    0x7fff598a6000 -     0x7fff598caff7  libsystem_malloc.dylib (166.220.1) <4777DC06-F9C6-356E-82AB-86A1C6D62F3A> /usr/lib/system/libsystem_malloc.dylib\n    0x7fff598cb000 -     0x7fff598d6ff3  libsystem_networkextension.dylib (767.240.1) <4DB0D4A2-83E7-3638-AAA0-39CECD5C25F8> /usr/lib/system/libsystem_networkextension.dylib\n    0x7fff598d7000 -     0x7fff598defff  libsystem_notify.dylib (172.200.21) <65B3061D-41D7-3485-B217-A861E05AD50B> /usr/lib/system/libsystem_notify.dylib\n    0x7fff598df000 -     0x7fff598e8fef  libsystem_platform.dylib (177.200.16) <83DED753-51EC-3B8C-A98D-883A5184086B> /usr/lib/system/libsystem_platform.dylib\n    0x7fff598e9000 -     0x7fff598f3fff  libsystem_pthread.dylib (330.230.1) <80CC5992-823E-327E-BB6E-9D4568B84161> /usr/lib/system/libsystem_pthread.dylib\n    0x7fff598f4000 -     0x7fff598f7ff7  libsystem_sandbox.dylib (851.230.3)  /usr/lib/system/libsystem_sandbox.dylib\n    0x7fff598f8000 -     0x7fff598faff3  libsystem_secinit.dylib (30.220.1) <5964B6D2-19D4-3CF9-BDBC-4EB1D42348F1> /usr/lib/system/libsystem_secinit.dylib\n    0x7fff598fb000 -     0x7fff59902ff7  libsystem_symptoms.dylib (820.237.2) <487E1794-4C6E-3B1B-9C55-95B1A5FF9B90> /usr/lib/system/libsystem_symptoms.dylib\n    0x7fff59903000 -     0x7fff59918ff7  libsystem_trace.dylib (906.220.1) <4D4BA88A-FA32-379D-8860-33838723B35F> /usr/lib/system/libsystem_trace.dylib\n    0x7fff5991a000 -     0x7fff5991fffb  libunwind.dylib (35.4)  /usr/lib/system/libunwind.dylib\n    0x7fff59920000 -     0x7fff59950fff  libxpc.dylib (1336.240.2)  /usr/lib/system/libxpc.dylib\nExternal Modification Summary:\n  Calls made by other processes targeting this process:\n    task_for_pid: 4\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by this process:\n    task_for_pid: 0\n    thread_create: 0\n    thread_set_state: 0\n  Calls made by all processes on this machine:\n    task_for_pid: 67071\n    thread_create: 0\n    thread_set_state: 0\nVM Region Summary:\nReadOnly portion of Libraries: Total=356.3M resident=0K(0%) swapped_out_or_unallocated=356.3M(100%)\nWritable regions: Total=2.5G written=0K(0%) resident=0K(0%) swapped_out=0K(0%) unallocated=2.5G(100%)\n                            VIRTUAL   REGION\n\nREGION TYPE                        SIZE    COUNT (non-coalesced) \n===========                     =======  ======= \nActivity Tracing                   256K        2 \nDispatch continuations            24.0M        2 \nKernel Alloc Once                    8K        2 \nMALLOC                           910.0M       24 \nMALLOC guard page                   16K        5 \nMALLOC_LARGE (reserved)           52.8M        6         reserved VM address space (unallocated)\nOpenCL                             1.4G        8 \nSTACK GUARD                       56.0M        9 \nStack                             11.6M        9 \nVM_ALLOCATE                      129.2M        7 \n__DATA                            25.9M      202 \n__FONT_DATA                          4K        2 \n__GLSLBUILTINS                    5176K        2 \n__LINKEDIT                       216.5M        6 \n__TEXT                           139.8M      198 \n__UNICODE                          564K        2 \nmapped file                       6428K        4 \nshared memory                      628K        9 \n===========                     =======  ======= \nTOTAL                              3.0G      481 \nTOTAL, minus reserved VM space     2.9G      481 \n. thanks for the reply, i did another try one with no -d option and keep hang out with trap 6\nMBPRO:hashcat luca$ ./hashcat -a0 -m2500 ../kama.hccapx /Volumes/DATA/WORDLIST/rockyou.txt -r rules/best64.rule \nhashcat (v5.1.0-718-g6e0ef698) starting...\nOpenCL Platform #1: Apple\n\nDevice #1: Intel(R) Core(TM) i9-8950HK CPU @ 2.90GHz, skipped.\nDevice #2: Intel(R) UHD Graphics 630, 384/1536 MB allocatable, 24MCU\nDevice #3: AMD Radeon Pro Vega 20 Compute Engine, 1020/4080 MB allocatable, 20MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 77\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nDictionary cache built:\n Filename..: /Volumes/DATA/WORDLIST/rockyou.txt\n Passwords.: 14344392\n Bytes.....: 139921507\n Keyspace..: 1104517645\n* Runtime...: 2 secs\n[s]tatus [p]ause [b]ypass [c]heckpoint [q]uit => s\nAbort trap: 6\nthe other try with -d3 (only use vega) seems working:\nSession..........: hashcat\nStatus...........: Running\nHash.Name........: WPA-EAPOL-PBKDF2\nHash.Target......: Kamarat (AP:e0:b9:e5:dc:4d:39 STA:4c:74:bf:e6:57:9a)\nTime.Started.....: Mon Mar 11 20:39:43 2019 (4 mins, 42 secs)\nTime.Estimated...: Tue Mar 12 00:16:34 2019 (3 hours, 32 mins)\nGuess.Base.......: File (/Volumes/DATA/WORDLIST/rockyou.txt)\nGuess.Mod........: Rules (rules/best64.rule)\nGuess.Queue......: 1/1 (100.00%)\nSpeed.#3.........:    82524 H/s (6.52ms) @ Accel:64 Loops:32 Thr:64 Vec:1\nRecovered........: 0/1 (0.00%) Digests, 0/1 (0.00%) Salts\nProgress.........: 54023939/1104517645 (4.89%)\nRejected.........: 30840579/54023939 (57.09%)\nRestore.Point....: 561737/14344385 (3.92%)\nRestore.Sub.#3...: Salt:0 Amplifier:52-53 Iteration:1184-1216\nCandidates.#3....: 025791 -> 22lov1\nanything else i should test ?\n. ",
    "c0d3z3r0": "@philsmd I always use hashcat with --outfile-autohex-disable.\n\nI think it's more correct to use the last occurrence, because some hash types have \":\" within the hash line because of the salt etc\n\nDamn. You are right, I just tested this with salted SHA1 (120)...\nI will try to find another solution... one idea would be using something like ::: or ;;; or :*: as separator but this would maybe impact performance for big pot files. Another solution could be reverting $HEX for --show. I think the latter one is the correct way. What do you think?. > my response to this is that we shouldn't mix up outfiles with potfiles and that potfiles should (and do!) always use the $HEX[] notation, as it is also needed!\nACK. Didn't realized that before...\n\nI don't think changing the separator etc is a good idea.\n\nACK\n\nI think it's only a problem on your site because you are using outfiles as potfiles, aren't you ?\n\nNo, I don't. Example: I throw LM hashes on hashcat (using --potfile-path test.pot). Those hashes are splitted into two parts and cracked seperately. Then I use hashcat ... --show. The outfile/output then contains passwords with $HEX[...].\nWhat I'd like to have is an option to get those $HEX stuff decoded in the outfile/output.\nFor e.g. NTLM hashes I dont' use --show, since the full passwords go to the outfile. Here I use --outfile-autohex-disable.\nUnfortunately --outfile-autohex-disable does not work with --show.. ",
    "waliedyassen": "I apologize, I've updated the C implementation to match the one in the Java function, they both output identical results now.. This algorithm is widely used to hide the string content in a obfuscated code, and when reverse engineering, it could take huge amount of time to reverse a single string on the CPU, and by implementing it in hashcat, it makes the process go quite faster to retrieve the string content in that code.\nThe obfuscated code usually comes with many strings (could be in thousands), so using the CPU to crack all of those is really painful and time consuming.. That's correct, you could collide them pretty easily, but it's unlikely when dealing with file names or other names, which they use to hide in the most of the cases.\nHowever, you could tell which one is the correct/wanted one by telling which one makes more sense, let's say debug.txt and OwinxTU collide for the sake of giving an example, it would be obviously for the person who's trying to crack it that the first result is the one we are looking for.. The collision can be minimised to very little or none by using a related words list for a dictionary or a hybird attack/cracking.\nRegarding the examples, there is plenty of Java applications that do this to hide their file names, such as the RuneScape file storage system, you can click here to see an example of reversing some of these names.. As for the 64-bit version of this algorithm, I would say it is really unnecessary to implement as it is very uncommon to come across, don't see a need for it as of now.\nHowever, as for the optimisations, I am quite unaware on how to handle that properly.. ",
    "nori19870522": "Add information.\nI want to revive the second password of blockchain.com.. Current situation,\n\u00b7 It gets garbled when decoding with base64.\n\u00b7 Since I am concerned about + and / contained in the string, I changed the shape.\n\u2192 %2B , / \u2192%2F , = \u2192 %3. ",
    "crwingfield": "OpenCL Info:\nPlatform ID #1\n  Vendor  : Apple\n  Name    : Apple\n  Version : OpenCL 1.2 (Oct 29 2018 21:43:16)\nDevice ID #1\n    Type           : CPU\n    Vendor ID      : 4\n    Vendor         : Intel\n    Name           : Intel(R) Core(TM) i5-4308U CPU @ 2.80GHz\n    Version        : OpenCL 1.2 \n    Processor(s)   : 4\n    Clock          : 2800\n    Memory         : 2048/8192 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.1\nDevice ID #2\n    Type           : GPU\n    Vendor ID      : 4\n    Vendor         : Intel\n    Name           : Iris\n    Version        : OpenCL 1.2 \n    Processor(s)   : 40\n    Clock          : 1200\n    Memory         : 384/1536 MB allocatable\n    OpenCL Version : OpenCL C 1.2 \n    Driver Version : 1.2(Nov 26 2018 20:27:28)\n. ",
    "joshtriplett": "Awesome, thank you! I managed to figure out the issue and figure out the passphrase another way (https://issuetracker.google.com/issues/125696135), but I'm glad that this support exists now.\nAs far as I can tell, it looks like this requires manually extracting some data from the Android backup file and feeding it in as a specially formatted hash? Is there some documentation of the hashcat expected input format?. Thanks!. ",
    "SecT0uch": "Indeed, fixed with the AUR package intel-opencl-runtime.\nThanks. ",
    "komyaka": "privatekey -> publicekey -> secret. ",
    "elplum": "\nFixed with commit 0b1169e\n\nNow : $blockchain$v2$5000$32$3ab2a1c0966199c3f829134449e59a8da52e1a59c5eb375193c4dc2d4f80e80c:malutin1983malutin1983 in potfile (but password not correct). > Fixed with commit f92ebc6\nIm analyze my database (18k+), result... very big surprise!\nFirst 16 byte of decrypted data must be start of:\n```\n{ \"guid\": \"\nhex : 7B0A20202267756964223A2022*** (7B0A2020 before \"guid\")\n{ \"guid\" : \"\nhex : 7B0A09226775696422203A2022** (7B0A09 before \"guid\")\n{\"guid\":\"*\nhex : 7B2267756964223A22** (7B before \"guid\")\n{\"sharedKey\":\"\nhex : 7B227368617265644B6579223A22**\n{\"double_encrypt\nhex : 7B22646F75626C655F656E6372797074\n{\"address_book\":\nhex : 7B22616464726573735F626F6F6B223A\n{\"tx_notes\":{},\"\nhex : 7B2274785F6E6F746573223A7B7D2C22\n{\"tx_notes\":{\"\nhex : 7B2274785F6E6F746573223A7B22**\nvery-very-very little (1 of 18k+):\n{\"keys\":[{\"creat\nhex : 7B226B657973223A5B7B226372656174\n```\nSorry, i didn't run the test yesterday, before create this post :(\nIn my delphi program, i use this code now:\n// dblk = ansistring, decrypted first 16 byte\n    if\n      (pos ('\"guid', dblk) <> 0)\n    or\n      (pos ('\"tx_n', dblk) <> 0)\n    or\n      (pos ('\"shar', dblk) <> 0)\n    or\n      (pos ('\"addr', dblk) <> 0)\n    or\n      (pos ('\"doub', dblk) <> 0)\n    or\n      (pos ('\"keys', dblk) <> 0)\n    then ... (decrypt_all). ",
    "danielsokolowski": "Hi jsteube,\nThank you for responding. \n```\n\nuname --all\nLinux tardis 4.9.0-7-amd64 #1 SMP Debian 4.9.110-3+deb9u2 (2018-08-13) x86_64 GNU/Linux\n```\n\nYes I am running AMD OpenCL because Intel CPU does not target the 'Pentium(R) Dual-Core  CPU', so when I install the Intel OpenCL does not detect any devices\n. After doing hard git reset --hard, cleaning untracked files git clean -qfdx  (i.e. untracked files in OpenCL/OCL* were removed), then git pull, then make error still persists:\n```\nroot@tardis:/usr/local/wpa-sec.stanev.org-help_crack.py# /usr/local/src/github-hashcat-hashcat/hashcat --force -m16800 --logfile-disable --potfile-disable  -ohelp_crack.key help_crack.pmkid\nhashcat (v5.1.0-735-g14f66bb3) starting...\nOpenCL Platform #1: Advanced Micro Devices, Inc.\n\nDevice #1: Pentium(R) Dual-Core  CPU      E5400  @ 2.70GHz, 2048/3419 MB allocatable, 2MCU\n\nHashes: 1 digests; 1 unique digests, 1 unique salts\nBitmaps: 16 bits, 65536 entries, 0x0000ffff mask, 262144 bytes, 5/13 rotates\nRules: 1\nApplicable optimizers:\n Zero-Byte\n Single-Hash\n Single-Salt\n Slow-Hash-SIMD-LOOP\nMinimum password length supported by kernel: 8\nMaximum password length supported by kernel: 63\nWatchdog: Hardware monitoring interface not found on your system.\nWatchdog: Temperature abort trigger disabled.\nInitializing OpenCL runtime for device #1...Segmentation fault\n```. ",
    "andydis": "Hi Jen's\nThe intended use is as follows :-\nWe run batch files for our hashcat attacks,\nEach line has a hashcat command\nWe want to be able to show how long each command would possibly run for so\nwe can sort them fastest to longest .\nCurrently we run every command manually and wait for the ETA to show and\nthen cancel it , make a note of the time and move onto the next command\nIf we could pipe out the ETA and auto quit ,  it would free us up alot of\ntime\nOn Sat, Mar 16, 2019, 10:07 AM Jens Steube <notifications@github.com wrote:\n\nI'm not sure if this is of any practical use. For example, if you have a\nhash list of two (or more) -salted- hashes. During the attack, one of them\ngets cracked. This means the estimated runtime will reduce by 50%.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1953#issuecomment-473517451,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AXLeFl_KsEAMFpNn1ZoNIy5ochXPxjvRks5vXMJOgaJpZM4btSAP\n.\n. In the scernario where the hash would not be cracked , we can tell how long\nthe job will run for\nSo it can then go onto the next job\nSo we can sort jobs by time length\n\nOn Sat, Mar 16, 2019, 10:23 AM Jens Steube <notifications@github.com wrote:\n\nOK, I understood that already. But the ETA would be wrong in the scenario\nI've described. How does it help?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/hashcat/hashcat/issues/1953#issuecomment-473518435,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AXLeFnTsivk4nNljIfeJIwUJcXdU84FNks5vXMY6gaJpZM4btSAP\n.\n. \n",
    "wrzomar": "It means that hashcat is using all availaible memory and then some more... and more. To reproduce it on my system I just need to run example0.sh script, if I'd just nvidia device. . I've just checked v5.1.0 release and it is OK, so the commit I'm looking for is somewhere after v5.1.0.. It was commit bfdeb6e 'Move test_instruction() to opencl_ctx_devices_init()' from Mar 2, 2019.. That's because the problem was Intel, not nVidia. I've changed line 3974 in src/opencl.c in master branch from\nif (device_param->device_type & CL_DEVICE_TYPE_GPU)\nto\nif ((device_param->device_type & CL_DEVICE_TYPE_GPU) && ((device_param->platform_vendor_id == VENDOR_ID_NV) || (device_param->platform_vendor_id == VENDOR_ID_AMD)))\nas it was before and it's fixed.. ",
    "purnapattela": "Nice . Nice job\n. ",
    "Empact": "This may as well be break, for symmetry.. "
}