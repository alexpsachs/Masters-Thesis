{
    "1st1": "Yes, once I'm done with adding/testing the basic APIs, we'll experiment with files ;)\n. It uses threads on all platforms -- that's the only reliable way.\n. I've no idea. I think it will be a bit faster, since IO threadpool in libuv is implemented in C (compared to pure Python executors in asyncio).\n. @saghul Is that usually enough (I assume getaddrinfo uses the same threadpool)? Would be great to have an API call to change the size, instead of the UV_THREADPOOL_SIZE env var...\n. @GMLudo That's not a problem atm, since uvloop doesn't have any methods to work with files.\n. I'll just close this.  First async file IO must be implemented in asyncio directly.. The project isn't even in its \"alpha\" state right now ;)\nTo build you need cython, and to clone the repo with '--recursive'.  Then simply run \"make\"\n. I'm working on the project right now.  Have a bunch of changes to push.  I think we'll have an alpha pretty soon.\n. I'm a bit distracted by a few other projects, but I'm going to find some time to push uvloop to alpha soon. I need it for our core product in my firm, so be sure -- the project isn't dead ;)\n. Closing this one.\n. Added basic loop.create_unix_server in b1c130b80a986ffaa9ea49bce5c42d474b36753b\n. Added tests for loop.create_unix_server in c93da26c35607518f286dbdf9023034288074fab\n. Added support for sock parameter to loop.create_unix_server in 55228cb6adcf051d01f64d966b31dcbf61479397\n. Added basic implementation of loop.create_connection in e6f1d45135b7dab0510410dd89761cbe8eecca46 and a6266752babe6b826fa4a5e368d50de0dd6063f9.\nTODO: Add tests.\n. Added basic implementation of subprocess* functions in 800cde0d9a062a7e1af3bcb6bb90b6f7f8f44432\n. Implemented loop.connect_read_pipe and loop.connect_write_pipe in e293b283f8db181d9c9be580806b6560043a4067\n. loop.subprocess_shell and loop.subprocess_exec are almost done (see 1f4e720c229ed5eaa13f2aade5c7a401ea7ab7ed, 704eb6fa08d63cd55fcf6fc3e028d361e0f028e4, 5bcb103a9adc9200b597f2c847fe850db5185990, and 28d166e19342ab151280fa7d73c7101f0ef28cd7)\n. loop.subprocess_shell and loop.subprocess_exec are done now (see 91d17cdb394ee17ba1fcff8dba9cd3dee9171d98 and b8c410a646e5d9d0be8ac5be51d8b131c4f0ef6b)\n. Solved bunch of small issues and implemented create_unix_connection in 203a181bcab56e211de27d724d2cfe4ac56331e1\n. loop.getnameinfo has landed in 4b9471279321133e648abfb5bf40521fe22da687\n. 5457d1eda3af9831882a9d14663ab15e5ee76e35 implements loop.add_signal_handler and loop.remove_signal_handler\n. SSL landed in 2ed225eff9fd7e41bc34c6fe1a99a8b48cb3ce44 and 494894701e9b3d140a875d46325bb680f07b8ad5\n. UDP landed in deff28dc5ea1b9fe63809b9f65183b588c812696\n. Almost there. Will release an alpha version officially in a day or two. /cc @sametmax @asvetlov \n. Done! http://magic.io/blog/uvloop-make-python-networking-great-again/\n. @sametmax I guess I can make _exception_handler available as a read-only property. Would that work for you?\n. > But maybe that's the wrong road. Maybe I should open a ticket to get get_exeption_handler added to the API, the you go add this official API as well instead of copying something that is meant to be internal.\nThis is a very good idea. I suggest you to go ahead and open an issue on http://github.com/python/asyncio. Most of the \"set_*\" APIs have a corresponding \"get_\" method, so I see no problem in adding one more, provided that you have a use case.  You'll see it in Python 3.5.2.\n. I decided to implement SSL and UDP in alpha. Closing this one. See issue #3 for updates.\n. Already fixed in v0.4.10!\n. The PR is merged, closing this one. Thanks a lot for the contribution!\n. LGTM. Will merge later today.\n. Merged by hand. I've also published uvloop v0.4.11 with your fix in. Thanks a lot!\n. uvloop implements an asyncio-compliant event loop. It will have to be heavily reengineered to support both asyncio and Tornado (basically we'll have to re-implement a lot of Tornado in uvloop), and unfortunately, I don't have resources to do that.\n. > Tornado has a asyncio bridge though.\nDidn't know about that. I think that bridge is only operational under Python 3, though, since asyncio requires at least 3.3.  Am I right?\n. Thanks for reporting this. I'm working on a fix.\n. Should be fixed in 448eea338ae4b07dbf0afc5dd00593164531e482, will soon release a new version.\n. Please try uvloop 0.4.12.\n. Closing this issue. Please update it if the issue still isn't fixed in 0.4.13.\n. You're trying to build uvloop manually, right?\n. @digitaldavenyc Are you trying to build uvloop manually, or it's a fail of pip install?\nI think I can repackage the sdist to include a generated Makefile.\n. I think I'll simply run autotools on my machine before sdisting.\n. @digitaldavenyc Please try uvloop 0.4.12\n. @digitaldavenyc The updated uvloop doesn't need autotools at all, if you're installing it with pip. Closing the issue.\n. Please re-open the issue if it fails.\n. Thanks for reporting this, this should be easily fixable.\nBTW, I don't think you need this line:\npython\nasyncio.DefaultEventLoopPolicy = uvloop.EventLoopPolicy\n. Fixed in d350f916fbf828bad39a58b25c5bea5384fc96e2!\n. > I use it to ensure that the correct policy (the one I set in the framework imports) is invoked without needing to explicitly call set_event_loop_policy.\nGot it! :)\n. Is your framework open source, btw?\n. Yes, just put these lines\npython\nimport asyncio\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nin the very beginning of your program and it will run on uvloop. aiohttp will run too.\n. When we find a volunteer to implement it ;)\n. @brickgao As far as I know no one is.\n. I don't think Windows supports signals, so you should probably add checks like if not __WINDOWS__ around code that touches loop.py_signals and loop.uv_signals.\n. @brickgao Do you think we should find more people to look into this problem?\n. @schlamar You should have looked at uvloop source code first, before assuming that we don't know some basic libuv APIs.\n@brickgao Sorry for the delayed reply. For signals specifically I use sigaction to make sure that: \n1. uvloop restores CPython's signal handlers\n2. Ctrl+C is handled correctly, i.e. PyErr_SetInterrupt is called when uvloop runs Python callbacks.\nFor the Windows port we don't need (1). We might need to play with Windows APIs to workaround (2), I suggest you to look at how CPython handles Ctrl+C on Windows.\nAs for socketpair\u2013the whole subprocess handling code is complicated. I had to copy the logic from subprocess.py (and its C-level helper) to make uvloop's subprocess behave exactly like CPython's. Good news is that we can learn how subprocess.py uses Windows APIs, and copy that approach to uvloop.\n. Your PR looks very good, thanks a lot for working on this. I believe we don't need to do anything special for signals or forks. As for dup, I'll fix a bug in asyncio and change how uvloop implements get_extra_info in a couple of weeks.\n. > What do you plan for dup?\nJust to remove it completely. Right now it's there to save uvloop from segfaulting when someone uses sockets from transports with add_writer API.\n. > @1st1 I've fixed sendfile support on aiohttp master.\nSuper cool! Thanks!\n\nFunny fact: on travis dupped socket was in blocking mode.\n\nWow. Maybe this is something worth investigating? Is it something that asyncio causes?\n. @iceb0y In the latest version of uvloop I've redesigned how signals are implemented. No more libuv or system API calls, I now only use Python's signal module. This should help with the Windows port.\n. FWIW I'm working on to add Windows support in https://github.com/MagicStack/uvloop/tree/win. Any help is welcome.. Here's the PR https://github.com/MagicStack/uvloop/pull/62. > For those on windows 10, I believe you can use bash on ubuntu and install uvloop on there for now, or at least that seems to have worked for me.\nGreat! FWIW I don't have time to focus on the IOCP win port right now, but I can definitely help with reviews/suggestions if someone is interested in it.. @bfbd888 I think it should work, but I haven't tried it myself.. @matpow2 libuv has some design inconsistencies between Posix/Win versions. For nodejs they don't matter, but for uvloop they need to be fixed first. Unfortunately, that's a considerable chunk of work, and I don't need uvloop to be compatible with Windows for my own use. Therefore, the work on the port is stalled.\nIf someone wants to champion the PR, I'll certainly help them (both with changes to uvloop and to libuv).. > Would be great to see frameworks like Sanic working on Windows :)\nNothing prevents sanic from working on Windows.  uvloop should be an optional dependency.. uvloop should be an optional dependency.  It doesn't provide any extra APIs on top of vanilla asyncio, it's an accelerator.  It happens that uvloop only works on posix right now and it's OK.\nPlease file a bug report to uvicorn to make uvloop dep optional.. I almost got it working, except cases where the API accepts an existing socket to work with.  I.e. create_server(sock=sock), not create_server(addr).  The best approach would be to build uvloop on Windows with the patch (https://github.com/MagicStack/uvloop/pull/62) applied and work from that point.. I'll take a look on Monday. Are you using the win branch?. I've rebased it.  Have no idea if it still compiles on Windows, but it does compile OK on *nix after the rebase.. > What would be the best practice approach to doing this? Combine with tornado or any other async libary?\nuvloop only works with asyncio. It cannot work with Tornado, gevent, curio, or any other async Python library other than asyncio.\n\nLeverage other smaller libraries to handle things like user authentication and http parsing. Or does uvloop just need these features introduced directly into it to maintain the performance it currently has?\n\nasyncio is an async library that implements many low-level and high-level abstractions. It has Protocols and Transports, helpers to create network servers and clients, etc. I highly recommend you to glance over the documentation.\nasyncio is built around the event loop. That's the thing that runs asyncio. uvloop is an implementation of a fast event loop for asyncio.\nNow, asyncio, by itself, doesn't provide any high-level tools for you to write applications. For instance, it lacks an HTTP protocol implementation, etc.  You need other libraries built for asyncio to do that for you.  For HTTP, right now, there is aiohttp.  There are many other libraries for working with databases, using AMQP brokers, etc.\n\nThe performance on it is very impressive, however, it's so low level, taking this into a production application would be quite a challenge.\n\nOnce you have an asyncio application, speeding it up with uvloop is very easy -- just install the uvloop policy (see the README file).\n. > Do you mean I should review uvloop's documention or asyncio's?\nasyncio documentation to get a better idea of what it's capable of.\n\nIn your blog post you mentioned that the performance in aiohttp was pretty bad with uvloop due to aiohttp's HTTP parser. Wouldn't httptools be the prefered library for handing HTTP requests?\n\nRight. The httptools package at this moment doesn't provide an implementation of HTTP, it only has a high-performance parser.  So right now, aiohttp is the only option, but I hope its newly discovered performance issues will be fixed soon (by incorporating httptools or somehow else).\n. Thanks!\nClosing this issue.\n. Thanks a lot!\n. @claws This is one impressive PR. Thank you very much for working on this. I've left a few review comments and recommendations.\nOne more thing: I don't think that uvloop needs a logo/favicon.  Text is fine and less distracting.  If it's absolutely required by Sphinx or RTD, I can make a nice text-only logo.\n. I've just discovered the pip -e thing. Essentially, in your uvloop development venv, you do the following:\nshell\n$ cd uvloop\n$ pip -e .\nAfter that you can run python -m unittest from the uvloop/tests directory. py.test can be used without a $ PYTHONPATH=. py.test hack, and can also be used from any dir.\nI think we just need to document the pip -e as a recommendation for uvloop venv setup.\n. > It seems a little uncommon (admittedly there is variability between projects) to have pure test utils in the main package. My thought space on this topic is reducing the barrier to entry for any potential future contributors. What was the reason for putting some test utilities in the main uvloop package?\nTBH I didn't put a lot of thought into that.  Having some test harness in a module inside the main package is something we did in asyncio, see asyncio/test_utils.py for instance.\nIn this particular PR, I don't like the import _testbase line.  I know why it works, but still it looks confusing to me.\n. Another thought. I'd like this to be split in two PRs: one that adds docstrings to the Loop methods; and one that sets up docs/sphinx/etc.\n. Alright, I've left some feedback. Generally looks good, aside from a few nits. Let's break this PR into two though.\n. Looks good! Will merge it today.\n. Committed in 8511fec1f9a610b0b26547a1620ce034ad9d9947. Thanks a lot!\n. Looks like libuv has failed to build. Was there any other output on the screen?\n. Also, please try pip install -vvv uvloop\n. Strange. What's the version of pip?\n. @f0t0n Yeah, I'll comment out the new_MethodHandle2 func in the next release. In the meanwhile we're trying to figure out the build problems here, stay tuned.\n. @ChillarAnand @justinfay @f0t0n @jettify Please try v0.4.21. I think @elprans and I have figured this out.\n. Committed in 72487f63aec50a8cf68326d689407df7dcf41959. Thanks!\n. Thanks for the PR! BTW, uvloop requires libuv @v1.9.0.  It won't compile with an earlier version.  Is there any way to check the version of libuv in setup.py, or we should just let the compiler to fail?\n. Alright, merged in d65265689baf9b7a51952e980ec870df4a3a660b. Thanks a lot!\n. FYI v0.4.16 has this PR in.\n. Let me take a look. What should I do to reproduce this on my machine?\n. Right, that's what I'm doing... Can you send me the exact website on which everything stops working at some point? So far I've tried refreshing arstechnica & theverge (which have a ton of images/resources) for a while, everything works...\n. I'm using Firefox for the test.\n. Hm, can't reproduce this. How many times do you refresh the frontpage of http://www.obec.go.th before it stops working?  Also, what version of uvloop are you using?\n. When this happens, can you close the browser, wait a few minutes, and then open it again? Sometimes TCP connections are closing very slowly, and in this case, system may run out of available sockets.\n. Alright, I think I've reproduced the problem, however, I can see it for asyncio without uvloop too.\nWhat's the output of ulimit -n on your machine?\nCould you please do the following:\n1. type $ ulimit -n 128\n2. type $ ulimit -n -- should output 128\n3. then launch the wormhole\n4. open three tabs in Firefox (I did arstechnica.com, news.ycombinator.com, theverge.com), load the pages and then start refreshing each tab one by one without waiting till they load.\nWith the above steps I can get both asyncio and asyncio+uvloop to reject browser connections.\n. @cwt Sure, please reopen the issue if you find that uvloop behaves differently from asyncio.\nBTW, have you seen any speed improvements with uvloop?\n. Great to hear that!\n. Good idea!\n. I've updated my release script to upload wheel for Mac OS X. There are no wheel packages for Linux, unfortunately, and Windows isn't yet supported.\n. > There are wheels for Linux. :)\nWow, I couldn't google that, thanks!\n@saghul Do you think it's a good idea to provide Linux wheels compiled on CentOS 5? That's a pretty old Linux kernel, won't libuv be slower or less stable?\n. So now we have manylinux & macOS wheels. Closing the issue.\n. I don't think that anything is wrong here, it seems that you have something listening on port 50000. \nI've tried running this program and it started just fine. I also cloned aiofiles and modified aiofiles/__init__.py to install uvloop policy, all tests run fine (except test_sendfile_file which fails in the same way for asyncio and uvloop loops).\n. Can you try different port, say 60000?\n. Interesting. And it doesn't fail if you comment out the uvloop-policy line?\nWhat's your OS, Python version?\n. Alright, I've reproduced this on my Linux box.\n. Should be fixed in uvloop v0.4.24 (see 76bb934d802f33aced864514c7ff9904df3d4d20 for details)!\n. Maybe it's a bug in uvloop -- looks like Gunicorn is forking a running event loop, and then closing it (which is a very bad way of doing that). I'll take a look.\n. So I copied-pasted your example app code in a test.py file. I then tried the following command:\ngunicorn test:app --worker-class aiohttp.worker.GunicornWebWorker --bind localhost:8080\nand it worked (on Mac OS & Linux).\nThen I tried to launch it with a few workers:\ngunicorn test:app --worker-class aiohttp.worker.GunicornWebWorker --workers 5 --bind localhost:8080\nThis time, it failed with \"address already in use\". I then tried to run it with asyncio event loop, and it also errored out, albeit in a different way.\nAnyways, how exactly are you running your program, what exactly does it print to stderr/stdout, what's your OS, Python, uvloop/gunicorn/aiohttp versions?\n. Alright, I got it now -- will debug.\n. @f0t0n I think I've figured it out. It seems that it's too late to set up a uvloop policy in your app -- you have to do that at the gunicorn worker level. I've created a PR for the aiohttp project.\n. @asvetlov Andrew, when will you make a new aiohttp release?\n. aiohttp 0.22 was released a few days ago. Closing this one now, thanks everybody!\n. @machbio Please see http://aiohttp.readthedocs.io/en/stable/gunicorn.html#start-gunicorn, specifically the note about uvloop.\n. > @1st1 what do you mean by \n\n\"too late to set up a uvloop policy in your app -- you have to do that at the gunicorn worker level\"\n\nIt literally means that in order to use uvloop with aiohttp+gunicorn you have to use a special gunicorn  worker class that aiohttp now bundles:\nbash\n$ gunicorn ... --worker-class aiohttp.worker.GunicornUVLoopWebWorker\nAnd you shouldn't really do anything else in your app.\n. It doesn't upload the wheels to PyPI, right?\n. @elprans added the infrastructure for this (I think in a bit different way than this PR). Thanks a lot for giving it a shot!\n. Hm, libuv unlinks the path unconditionally, I can't do anything about it.\n@saghul, sorry for bothering you, do you think it's possible to add a flag in libuv to tell it not to unlink the path in uv__pipe_close?\n. Alternatively we can re-create the path once the unix socket is closed, but it feels too hacky to me.\n. @saghul Good idea, I followed your advice :)\n@AndreLouisCaron Thanks for reporting this! Should be fixed in the master branch; I'll also issue a new uvloop release shortly.\n. I've just released uvloop v0.4.26. Please check it out.\n. Thanks! Closing the issue.\n. This happens because libuv caches the \"now\" time and only makes one syscall per loop iteration to refresh it.  There is a special function to invalidate the cache -- uv_update_time -- which I think I'll use in loop.time now, to be compliant with asyncio.\n. Should be fixed in the master branch. I'll issue a new release shortly.\n. I've just released uvloop v0.4.26. Please check it out.\n. Please try v0.4.27.  I think I've finally fixed this.\n. Thanks!  Could you please write a unittest for this?\n. Should be fixed in https://github.com/MagicStack/uvloop/commit/37a0b15d42495392eedd5b40e033aedf18d0a789.  It would be great if you can create a regression test for this.\n. @saghul this is the last thing in uvloop that isn't currently supported, and the only thing that has to be implemented in libuv. And this is something that people actually use, for instance Facebook guys use it to call prctl(PR_SET_PDEATHSIG, SIGKILL) in the child processes.\nEssentially, I'm thinking if it's possible to add another field to uv_process_options_t: a pointer to a (void)after_fork() function.  Would that be possible?  I think I can make a PR.\n. After giving it more thought, I think I can use pthread_atfork... Should be easier than pushing new stuff to libuv.\n. Implemented in b5b3b12dbba915f635b583c8b51c1f41ed219d9c\n. Once PyPy implements Python 3.5 and is stable, we'll look into this.  Theoretically, it's not that difficult to rewrite uvloop with pure Python + CFFI.\n. NP. Let's keep this issue open, as this question periodically comes up.\n. I'll take a look soon :). Referencing another discussion: https://github.com/MagicStack/uvloop/issues/82. Should be fixed in v0.4.32. Please check.\n. Closing this one.\n. Thanks a lot for reporting this. I'll take a look on Monday.\n. Should be fixed in v0.4.32. Please check.\n. From the looks of it, all you need to do is to set up uvloop asyncio policy before installing AsyncIOMainLoop:\n``` python\nfrom tornado.platform.asyncio import AsyncIOMainLoop\nimport asyncio\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nAsyncIOMainLoop().install()\nasyncio.get_event_loop().run_forever()\n```\nPlease check if that works.\n. Thank you Ben for checking that. Closing this issue now.\n. Should be fixed in v0.4.32. Please check.\n. Thanks!\n. Would it be possible for you to share the program code, or to reduce it to a smaller size that can be shared?\nI'd suggest to build a debug version of uvloop with make debug.  You then can use an undocumented function loop.print_debug_info() to print a bunch of information about the loop and the running process.  For instance, you can use the following code:\npython\nasync def print_debug(loop):\n    while True:\n        print(chr(27) + \"[2J\")  # clear screen\n        loop.print_debug_info()\n        await asyncio.sleep(0.5, loop=loop)\nto create an asyncio task -- loop.create_task(print_debug(loop)) -- and have a live info screen.\n. Also, how exactly do you use Gunicorn with uvloop? Do you use aiohttp? Do you use the worker from https://github.com/KeepSafe/aiohttp/pull/878?\n. loop.print_debug_info() just prints to stdout, so you can use contextlib.redirect_stdout to redirect it to a file or, prehaps, a StringIO object.\n\nUnfortunately I can't share the program code in this instance as it contains trade secrets.\n\nNP.  Can you tell me more about the app though?  What modules does it use; for instance, do you use some async driver for memcache/redis/database/etc? Also, can you try to create a simple version of your app that still has the leak?  It might help us to understand what's going on here.\n. And, just to confirm, you can see the leak only when you're running the app behind Gunicorn?\n. > So we have added uvloop debugging to the scoreboard module, and I wonder if there is an issue with the way callback handles are being cleaned up, because the \"total callback handles\" number is going up at a rate that is proportional to the memory increase.\nBut the \"current\" number of callbacks is still low (not steadily increasing?)\nPlease try to remove @cython.freelist(DEFAULT_FREELIST_SIZE) decorator from Handle and TimerHandle classes in cbhandles.pyx.  And then try to remove the @cython.no_gc_clear decorators (although this might cause a segfault theoretically).\n\nAn interesting note is that the Read callbacks number is much smaller than the total callback handles number.\n\nIt's a different kind of callbacks -- \"read callbacks\" is the number of times libuv reads something from the socket and sends it back to uvloop.\n. How many UVTimer objects do you have?\n. I think it's UVTimer.\n. It's definitely UVTimer.  I wrote a small program that creates thousands of them, and it's leaking super fast.  I don't think it's related to freelists...\n. No, it's a uvloop bug. Somehow UVTimers do not free memory of their uv_timer_t handles. Looking into that now.\nI also have a refactoring branch where I remove most of PyMem_Malloc calls from uvloop, and it doesn't leak in that branch.\n. Pushed to the master branch. Please test.\n. Thanks a lot for discovering this and for your help with debug. I'll release a new version of uvloop shortly, as the bug is pretty severe; perhaps it affected other handles, such as Poll or TCP.\n. Awesome! Thanks!\n. BTW, did you guys do any benchmarking of your app?  How much faster is it when it's run on uvloop?\n. @kaniini I had to revert the original fix for this issue (see issue https://github.com/MagicStack/uvloop/issues/41) and it's now fixed in a different way.  Will issue a new release soon.\n. Please try uvloop v0.4.34. I've made several changes to make sure we won't introduce similar memory leaks in the future:\n- Loop has two new counters in debug build: _debug_uv_handles_total and _debug_uv_handles_freed which count number of PyMem_Malloc and PyMem_Free calls for uv_handle_t structs.\n- unittests, when run on debug build, test that those counters are equal at the end of each unittest.\n- Travis now tests both production and debug builds of uvloop.\n. Awesome, thanks!\n. Merged by hand. Thanks a lot!\n. The general advice is to create a minimal testcase and then debug the code with gdb (or lldb) and print statements ;)\nIn this particular case, could you please tell me the values of addr and ssl?  Does the loop have any other scheduled tasks?  Does it run in the main thread?\n. I'd also suggest to add prints before each await in Loop.create_server.  That should give us better understanding where exactly the loop hangs.\n. Hm, actually, there is only one await in Loop.create_server, and it waits on getaddrinfo. So it might be a bug in the DNS resolver. What's the value of addr?\n. And there's also an option to make a debug build with make debug. When built in debug mode, loop has a print_debug_info() method which outputs a bunch of useful debug info.\n. > OK, I'll try that.  Would you suggest print_debug_info() here:\nThe idea is to create a debug task that will periodically print debug info on the screen. This is how I use it in uvloop benchmarks:\nhttps://github.com/MagicStack/uvloop/blob/master/examples/bench/echoserver.py#L78\nI'm thinking about adding a manhole or something, that would let you attach to a running event loop from the outside.\n. Thanks a lot for confirming this!\n. Interesting. Thanks a lot for the script -- will investigate tomorrow.\n. Looks like this bug is in libuv.  A call to uv_getaddrinfo never calls back the passed callback function.  I suspect that there is a lock or something that breaks on fork() + starting a new event loop in the forked process.\nOptions:\n1. Start using Python's getaddrinfo in a Python threadpool. \n2. Fix the bug in libuv.\n3. Switch to c-ares or getdns (I wanted to do this sometime anyways).\nNot sure how to even estimate which option is more preferable here.\ncc @saghul\n. > > I suspect that there is a lock or something that breaks on fork() + starting a new event loop in the forked process.\n\nThis is the case, yes. The threadpool has some global state which needs to be adjusted in the child. Since uv_getaddrinfo runs on the threadpool it will fail. Basically using any loop before fork() and trying to use them (or a new one) is not currently supported.\nThere is, however, a pull request which addresses this: libuv/libuv#846 more eyes are always welcome!\n\nI've seen that PR, it looks good to me (I spent quite a bit of time looking and playing with libuv internals).  But I'm not a core libuv committer to say the LGTM :)\n\n\nStart using Python's getaddrinfo in a Python threadpool.\n\nYou might want to do this for another reason though: Python's getaddrinfo is not quite like getaddrinfo(3), it makes some normalizations and other stuff I no longer remember but it might be a good idea to use it, for consistency.\n\nYes, but I already have all the code to normalize libuv results into what Python code is expecting to see.  All that code would be useful for c-ares or getdns though.\n@jimfulton How serious is this bug?  Does it preclude you from using ZODB with uvloop?\n. I'll try to add connect_accepted_socket to uvloop today :)\n. @saghul I've left a comment for https://github.com/libuv/libuv/pull/846 -- it solves this particular bug and other bugs we have with os.fork calls. When do you think it can be merged?  (I really, really don't want to use patched libuv).\n. @jimfulton FWIW uvloop v0.5.1 has loop.connect_accepted_socket()!\n. Finally some good news ;)\n. Fixed in master. Will be in the next uvloop release (0.9.0) soon.. Please try uvloop v0.9.0.. I think it should be fixed now.\n. The fix is in v0.4.34 release.\n. Closing this one. Thanks a lot for reporting this, Ben.\n. Could you please tell how to run your proxy without docker? I.e. should I just clone the repo and run some script? How to enable uvloop in it?\n. I've just committed a small change - 2b060e170fc45ec0965bab926513725f9714c73b - please check if it fixes the problem.\n. > to run it without docker:\nThanks! And what should I do to crash it?\n. OK, I got it. Once I set up Firefox to use it, it crashed almost instantly.\n. Should be fixed by 7b0b195d100ccd63d6b5cd56e36b099ad6ace8b4. Will issue a new release soon.\n. Please try uvloop v0.4.34.\n. Thanks! See also https://github.com/MagicStack/uvloop/issues/37#issuecomment-232165394.\n. > I think this issue should be go asyncio ML, \"What is the standard way to switch protocol of transport?\"\nRight. Exposing the property would be an easy thing to do in uvloop, but we should (or shouldn't?) have an API for switching protocols.\n. set_protocol and get_protocol were added couple of releases ago. Closing this issue now.. Yes, libuv uses a thread pool to do getaddrinfo and getnameinfo, and so does uvloop. AFAIK nodejs doesn't use c-ares anymore.\nI'm still deciding how to approach this problem -- should we use c-ares? or getdns? Or keep things as is, since DNS in a thread pool is fine for most use cases?\n. @benjamingr Benjamin, thanks for chiming in! My current understanding is that for asyncio we'll have to approach this problem similarly to Node: add a completely new set of DNS APIs that doesn't use getaddrinfo and uses c-ares or getdns instead. Maybe we want to make it possible to plug custom DNS resolvers so that create_connection can use them.\n. Will be fixed in the next release (soon). BTW, are you using UDP with uvloop by any chance?\n. That's quite interesting, I'd love to check it out. Would be cool if it's open source.\n. Hi! Thank you for this PR! Would you be able to write a regression test?\n. @vodik With this PR test_create_datagram_endpoint_addrs fails on MacOS X:\n```\nERROR: test_create_datagram_endpoint_addrs (test_udp.Test_UV_UDP) (local_addr=('127.0.0.1', 0))\nTraceback (most recent call last):\n  File \"uvloop/loop.pyx\", line 2304, in uvloop.loop.Loop.create_datagram_endpoint (uvloop/loop.c:36698)\n    udp._bind(lai.ai_addr, reuse_address)\n  File \"uvloop/handles/udp.pyx\", line 117, in uvloop.loop.UDPTransport._bind (uvloop/loop.c:88034)\n    raise exc\nOSError: [Errno 49] Can't assign requested address\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\n  File \"/Users/yury/dev/magic/uvloop/tests/test_udp.py\", line 77, in test_create_datagram_endpoint_addrs\n    transport, client = self.loop.run_until_complete(coro)\n  File \"uvloop/loop.pyx\", line 1133, in uvloop.loop.Loop.run_until_complete (uvloop/loop.c:19943)\n    return future.result()\n  File \"uvloop/future.pyx\", line 123, in uvloop.loop.BaseFuture.result (uvloop/loop.c:94147)\n    return self._result_impl()\n  File \"uvloop/future.pyx\", line 78, in uvloop.loop.BaseFuture._result_impl (uvloop/loop.c:93686)\n    raise self._exception\n  File \"uvloop/task.pyx\", line 126, in uvloop.loop.BaseTask._fast_step (uvloop/loop.c:99430)\n    result = meth(None)\n  File \"uvloop/loop.pyx\", line 2315, in create_datagram_endpoint (uvloop/loop.c:36980)\n    raise OSError('could not bind to local_addr {}'.format(\nOSError: could not bind to local_addr ('127.0.0.2', 0)\n```\nWould it work if we bind local_addr to 127.0.0.1 and some unused port?\n. test_create_datagram_endpoint_addrs still fails for me on MacOS, now with a TimeoutError.\nAlright, could you please remove the unittest part from your PR and I'll merge it then. I'll try to figure out a way to test this properly later.\n. Merged, thanks a lot!\n. Releasing 0.5.3 right now.\n. I can only say that some top companies and startups are now using it in production. \nMy advice would be to test uvloop, see if your services are stable on it, and then gradually replace asyncio event loop with it.\n. Care to make a PR? Or I can commit this myself referencing your name.\n. Closing the issue, the PR has been merged. Thank you!\n. Merged manually in 7d5c37832f1c14360fef3fcaace3230d04d40fdd. Thanks a lot!\n. Releasing 0.5.3 right now.\n. What version of aiohttp are you using?  AFAIK there was an issue with how aiohttp implemented sendfile, which was fixed not long ago.\ncc @asvetlov \n. @asvetlov When will you release aiohttp with this thing fixed?\n. Closing the issue since it has been resolved in aiohttp.\n. > But uvloop returns another socket.\nYes. This will be fixed once we fix asyncio to error when transport's socket is used with loop.add_writer\n\nAFAIK socket flags are not shared between dups.\n\nTCP_NODELAY is shared (at least I observed that on Linux).  Could you please confirm that TCP_CORK isn't?\n\nThe problem is not such bad because libuv switches on nodelay by default IIRC but enabling/disabling CORK still makes sense.\n\nNo, libuv doesn't set NODELAY by default (and uvloop does not either)...\n. What's the use case?\n. Interesting. Well, in theory we could provide some API for that, but somebody will have to pioneer and submit a PR with an example use case code.\n. @iceb0y Are you still working on this?  I could probably expose a semi-public ctypes Ptr to the libuv event loop.\n. Thanks! Will merge in a couple of days.\n. Thank you, this PR is merged now! I'll release a new version soon.\n. No, uvloop should behave exactly as vanilla asyncio. Would it be possible for you to make a failing unittest similar to other subprocess tests in 'uvloop/tests/'?\n. Alright, I'll take a look in a few days!\n. I'm trying to figure out what's going on here and have some questions about how Pulsar works.  Could you please point out to the place where you fork/create subprocesses for actors?\n. I see, it looks like you just instantiate multiprocessing.Process class.  In asyncio, it's more reliable to use loop.subprocess_exec for that (at least that's what uvloop is tuned for).\n. Great! I ended up rewriting how signals handling is implemented in uvloop from scratch. Maybe multiprocessing will work just fine when I'm done.\n. @lsbardel Please try uvloop 0.5.4. Ctrl-C is now being handled exactly as in asyncio.\n. @lsbardel Thanks for confirming that everything works now!  Closing this issue.\n. What do you use to STARTTLS?  Can you provide a script and steps to reproduce the problem?\n. Also, can you reproduce this in vanilla asyncio?  The problem is that there's no \"SSL socket\" in 3.5, we use SSL memory BIO, which means that the socket object stays the same.\n. > According to the docs, socket should always map to a socket.socket, and ssl_object should map to an SSLObject or an SSLSocket, so I'm inclined to beleive that uvloop is in the right.\nRight.  One problem: I don't understand how can you have SSLSocket on 3.5.2 in asyncio at all.\n. > I don't know much about it, but it appears to be some hackery slixmpp is doing to use the old SSL, no idea why.\nGot it.  That explains why I couldn't see how this could happen in asyncio ;)  Would you be able to ask them why are they doing this?  Perhaps there is a bug that should be fixed ASAP, before Python 3.6 is out.\n. Cool! Thank a lot for investigating this.\n. I can't reproduce this. It's really weird that _GatheringFuture doesn't have the _blocking attribute.\n. @smortus Are you sure you used python 3.5 and not 3.6?\n@mstyvane I'm looking into this...\n. The reason I can't reproduce this is because this has been fixed in 0.5.4. Please try it out.\n. Alright, closing the issue then!\n. @methane It's OK, that was expected. We can workaround the inheritance.  I already have a patch, but it segfaults python (I might have discovered a bug in Cython/Python 3.6, will need to check).\n. uvloop 0.6.0 now runs on Python 3.6b3.\n. Yes, that would fix the image to be displayed, however, PyPI doesn't try to resize the image to fit to the screen. Since that PNG file is hi-res, it breaks the PyPI page. I've played with various ReST parameters to adjust how .. image:: is rendered, nothing really helps.\n. I'll need some details on this:\n- What kind of socket connection is the transport working with?  I.e. this exception can only be triggered if the socket is not AF_INET or AF_INET6.\n- Can you provide the source code that exhibits the problem?\n- Were you able to reproduce this on other OSes?\n. Seems that somehow gunicorn or aiohttp bind UNIX address using a TCP server (loop.create_server, instead of loop.create_unix_server).\n@asvetlov Do you have any idea what's going on?\n. Ah, I got it: https://github.com/python/asyncio/pull/453\n. This should be fixed in aiohttp 1.1.2 and uvloop 0.6.1. Feel free to reopen if anything.\n. Yeah, that's planned. Why do you need that, btw?\n. I'm not sure I understand why this 100% CPU loop happens. From the libuv docs:\n\nThe user should not close a file descriptor while it is being polled by an active poll handle. This can cause the handle to report an error, but it might also start polling another socket. However the fd can be safely closed immediately after a call to uv_poll_stop() or uv_close().\n\nIt seems that if you call remove_reader and remove_writer before closing the FD epoll errors that your strace dump shows should not happen...\n\nI could go into more detail about this but it's rather complex and I believe there are a number of issues you could tie back to the fact that remove_* isn't syncronous as it is with the stdlib implementation of EventLoop.\n\nI'd really appreciate if you could share your view on this.\n. Also, we can probably use uv_backend_fd() to do some manual operations with epoll/kqueue.\n. Seems that we can manually call epoll_ctl in remove_reader/remove_writer after the libuv poll handler is closed. Looks like it should be safe.\n@saghul Is this something we should fix in libuv somehow?. @mayfield Justin, https://github.com/MagicStack/uvloop/commit/641c26c441afb3393c7bf3acbb105be5f283b706 should fix the issue. Could you please review that commit and test if it actually fixes the issue (it does look like it fixes it).  I can make a new release tomorrow.. BTW, do you have any idea how to write a unittest for this in uvloop?. > I wouldn't be comfortable putting that into a unittest but here it is for reference..\nYeah, process_time isn't going to be reliable.  I've added a direct regression test of epoll/fd.  Will make a release shortly.. Closing this one, should be fixed in v0.6.7.. Rebased agains the current master branch.. This is strange, I don't see how this can happen. Could you please share the code so that I can debug this?. Should this issue be closed now?. OK, closing this.. You shouldn't use asyncio.get_child_watcher().attach_loop(loop) with uvloop -- uvloop doesn't have child watchers.\nAre you saying that running shell commands with uvloop creates zombies? Can you share your code?. What kind of commands are you trying to execute? Short/long living?\nCan you move transport.close() into a finally block so that it's guaranteed to be called?. Yeah, so far I can't reproduce this :(  It would be extremely helpful if you could provide a complete minimal program that reproduces the issue.. > Yeah, just tried this and it never ends: https://gist.github.com/NotSoSuper/df228346bc9645d105216d9f8c2fe38b\nExits normally (well, with exceptions on set_result(True) being called more than once) for me on Mac OS and Gentoo. Strange.\n\nEdit: Ending the python repl session returned 'done'\n\nWhat do you mean by that?. Have you been able to fix this/find the problem?. Ok, closing this one as I'm still unable to reproduce on both Linux and OS X. Feel free to reopen.. I'll take a look in a few days.. I see a different traceback now:\n12:22:52 [p=17947, t=140736377529280, ERROR, asyncio] Task exception was never retrieved\nfuture: <Task finished coro=<ActorSubProcess._start() done, defined at /Users/yury/dev/venvs/asyncio/lib/python3.5/site-packages/pulsar/async/concurrency.py:770> exception=OSError(9, 'Bad file descriptor')>\nTraceback (most recent call last):\n  File \"uvloop/future.pyx\", line 372, in uvloop.loop.BaseTask._fast_step (uvloop/loop.c:105907)\n    result = meth(None)\n  File \"/Users/yury/dev/venvs/asyncio/lib/python3.5/site-packages/pulsar/async/concurrency.py\", line 775, in _start\n    'impl': bytes(ForkingPickler.dumps(self)),\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/reduction.py\", line 50, in dumps\n    cls(buf, protocol).dump(obj)\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/reduction.py\", line 235, in _reduce_socket\n    df = DupFd(s.fileno())\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/reduction.py\", line 190, in DupFd\n    return resource_sharer.DupFd(fd)\n  File \"/opt/local/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/resource_sharer.py\", line 48, in __init__\n    new_fd = os.dup(fd)\nOSError: [Errno 9] Bad file descriptor\nI'm not sure I understand what's going on here. What socket are you working with?. > I get the sockets (usually two, ipv4 & v6) and remove their readers from the event loop\nOh, you shouldn't do that :( You are not supposed to use low-level remove_reader API on underlying sockets of any transports or servers. This already triggers an error (for most cases) in asyncio and uvloop. I'll fix asyncio & uvloop to raise an error if you use them for server sockets too.\nThe idea is that when you use create_server or create_connection, the loop has some state in addition to underlying sockets. Part of that state, is the assumption that the sockets state is fully controlled by the loop. If you try to interfere with low-level API, you can get the loop into an undefined state.\nIn uvloop when you do such things you can easily get a segfault in libuv, because it assumes that you'd never use different APIs on the same socket.\nI suggest you to re-implement create_server in your framework (it's a relatively simple method). Then you can pass accepted sockets to other processes, and use connect_accepted_socket API to wrap them in transports.. Thanks for reporting this. We'll fix this in the next release (soon). Fixed in 0.7.1. Thanks for reporting this!. Yes, CancelledError is a normal thing to occur. Most likely this has to be properly handled in Sanic.  Please report this issue on their tracker, and please reopen if this turns out to be a uvloop bug.. Uvloop uses asyncio implementation of ssl, so it's very likely an asyncio bug. Can you reproduce this without uvloop?. Does this mean that there's a bug in CPython ssl or asyncio/sslproto?. OK, I now remember that it's a known issue. We'll fix this in 3.7 or even next 3.6 bugfix release.. @elprans Do you think we can enable wheels for 3.6? Looks like manylinux supports it now: https://github.com/pypa/manylinux/pull/89. Right, we don't \"install\" them, but they are part of the distribution so that setuptools/package managers can run them before the actual installation. _testbase.py file is harmless, I don't think we need any extra effort to remove it.. Interesting. Did you compile uvloop from source? What version of cython do you have? What's the output of make?. Also, are you sure you have CPython 3.6.0 final, and not some beta version?. Is this still a problem we need to look into? I don't see anyone else posting here. Maybe it was just a glitch in that particular Fedora version/build.... Alright, closing this one.. Yeah, I don't think that the loop is a best place for a global context data. But I'm not sure what to advice to use instead, since there is no decent local-coroutine-storage sort of library or solution at the moment. Maybe in 3.7 we'll have a solution for this in asyncio core.. > What I'm unsure of is whether this is an implementation issue (given the performance of asyncpg), or if there are known issues with outbound TCP connections compared to inbound ones?\nIt is an issue of the implementation. Couple of things I found:\n\n\naredis uses streams, a high-level IO abstraction. You can get much more performance using the low-level asyncio.Protocol, like asyncpg does.\n\n\nIt seems that aredis uses text protocol, not binary.\n\n\nNo Cython optimizations.\n\n\n\nIf MagicStack could produce a performant version of a Redis client, that would be a huge boon.\n\nWe don't need a fast Redis client for ourselves at the moment, hence no plans to develop it. Although, this can be changed if someone wishes to sponsor the development.. You should, uvloop has a faster event loop/IO selector implementations.. Can you provide a snippet to reproduce this?\nOverall I think it's normal. asyncio.TimeHandle is an implementation detail of asyncio. In general, you shouldn't expect some private asyncio classes to be supported in uvloop and vice versa.. Right. I think I can easily add support for them, but since this is the first time I see this bug, I'd wait until more people complain. Thanks!. > Any idea what's happening here? I'm not 100% sure that uvloop is to blame, but it seems to be. \nYeah, most likely it's a uvloop bug. How can I reproduce this?. I see couple of CPython threads in the crash logs. Do you use call_later() only from one thread or from multiple?. I've created this simple script: https://gist.github.com/1st1/41e9ba2bb563a64da6dbb9a33e2ee42b which calls call_later thousands times a second, but I still fail to reproduce the issue.\n\nIs there anything I could do that would make debugging the issue easier for you?\n\nIt would be really helpful if we can write a smaller script which reproduces the crash... See my above question about the threads. Also, do you keep references to Handles? Do you cancel them?. Huge thanks, I was able to see the bug on my machine.\nSo yeah, the cause of the segfault is calling call_later from another thread. FWIW, if you run you script with PYTHONASYNCIODEBUG=1 or loop.set_debug(True) you'll see a RuntimeError telling you that call_later is not thread-safe (change 5620 to 10 to see it).  Also, in debug more, even vanilla asyncio gives you that RuntimeError.\n\nIs there a simple way to schedule delayed calls that is thread-safe?\n\nWe don't have a helper method for this, but you can use the following trick:\npython\ndef call_later_threadsafe(loop, delay, cb, *args):\n    loop.call_soon_threadsafe(loop.call_later, delay, cb, *args)\nI think it might be a good idea to add loop.call_later_threadsafe to asyncio. Feel free to open an issue on asyncio issue tracker.\nClosing this issue. Thanks!. Thanks!. (sorry, missed \"for\" from the commit message, my bad). Thanks!. Sorry I didn't look into this promptly. Were you able to resolve the issue?. Great! Thanks!. What if you explicitly close the transport?\npython\ntrans, photo =  await loop.connect_read_pipe(lambda: protocol, os.fdopen(fd))\nos.close(os.open('/tmp/fifo', os.O_WRONLY))\nawait asyncio.sleep(.1)\ntrans.close(). What OS are you testing this on?  For me, on macOS, the behaviour with uvloop is the same as without it.... I see that transports aren't GCed. I'm not sure how I feel about this bug: on one hand you have to close transports explicitly. On the other, we want uvloop to behave exactly as asyncio.\nAnyways, I'll try to get to the bottom of this.. I found the problem that causes this. The core problem is that the Transport is kept alive while its underlying FD is not closed, which shouldn't be an issue for web servers etc. In any case, I have a fix in mind, will try to implement it soon.. > The core problem is that the Transport is kept alive while its underlying FD is not closed\nActually, asyncio behaves in exactly the same way -- the Transport is kept alive by the _read_ready bound method as long as selector is monitoring its socket.\nWith 3.6.3 I don't see any difference between uvloop and vanilla asyncio.  On Linux, FDs get reused at some point of time when a GC happens (probably because _read_ready callback is triggered because the other end of the pipe is closed).  On MacOS, _read_ready doesn't receive any indication that the other end of the pipe is closed, so both uvloop and vanilla asyncio leak transports/FDs.\nThe advice is still the same: always close your transports.\nI'm going to close this as \"not a bug\".  Please feel free to reopen if you find another example where transports are closed/kept alive differently from asyncio.. This happens because you don't save a reference to the server object that app.create_server returns. If you replace asyncio.ensure_future(server, loop=loop) with srv = loop.run_until_complete(server), everything should work as expected.\nAnyways, this is something where asyncio and uvloop behave a bit differently. I'll fix this in the next release.. Fixed in master, will be in the next release (soon). Please try uvloop v0.9.0.. PyPy isn't yet supported, sorry.. We'll likely have to rewrite most of the code to use cffi (not cython), so it's not a quick fix. You should be able to use vanilla asyncio on PyPy, which should be quite a bit faster than vanilla asyncio on CPython.. First, I would want to write some benchmarks to see if uvloop even needs to be ported to PyPy. Maybe vanilla asyncio is fast enough on it. That means that I'll need a basic trimmed down version of CFFI-ed uvloop enough to run an echo server benchmark.\nSecond, if it does make sense to port uvloop to PyPy, then most likely we can convert 60-90% of the code to use CFFI for both CPython and PyPy (without performance degradation for the former). Remaining performance critical parts can be written in both CFFI & Cython. I definitely don't want to fork uvloop or copy/paste huge chunks of code.. Can you reproduce this with PYTHONASYNCIODEBUG=1 in env?. I'll take a look into this. For now you should be able to use this workaround:\npython\nsock = transport.get_extra_info('socket')\nlocal_ip = sock.getsockname(). Fixed in master. Will be in the next release (soon). Please try uvloop v0.9.0, where this bug should be fixed.. I'll close this PR.  Will re-open and merge if/when we have the actual Windows support committed.. Do we need to do this for all platforms or for Linux+arm only?. Merged as is. Thanks!. This means that something really unexpected is happening in the libuv layer. How did you trigger this?. Closing this one. Please reopen if you find a way to reproduce this.. > Does uvloop here on the blog mean uvloop protocol or what?\nYes.. Fixed in master. Will be in the next uvloop release (0.9.0) soon.. Please try uvloop v0.9.0.. Good catch.  I've fixed uvloop to raise an error when a DNS lookup is needed in .sendto(). I will fix asyncio in a similar fashion.  The fix will be in the next uvloop release in a couple of days.. Please try uvloop v0.9.0.. Nice! Stay tuned for more improvements in uvloop & asyncio => better performance :). Interesting. Thanks for providing a code to reproduce this, I'll take a look.. Fixed in master.  A simple race between transports and high-level asyncio streams.  A new uvloop version with a fix will be released soon.. What do I need to do to replicate this?. I'll try to find some time to look at all open uvloop issues sometime this week.. Why do you use signal.signal instead of loop.add_signal_handler?. Where do you handle HandledExit? There's clearly some difference in how uvloop and vanilla asyncio dispatch the signal.  Using add_signal_handler API should workaround your issue, but I'd like to understand what's going on here anyways... Right, that's what I thought. I'll try to figure out what's really going on here.. I think I figured this out.  You install a signal handler using signal.signal() API, which means that the event loop has no control over when and how the signal will be processed.\nWith asyncio:\nIt so happens that the signal arrives when we select on sockets [1].  Because that code isn't guarded with try..except, any exception there will stop the loop. That's why when your SIGINT handler raises a HandledExit error, the loop stops and the error propagates through the worker.run_until_complete(log_redis_version=True) line.\nNow, it's not guaranteed that the signal arrives at that particular code location.  It might, for example, arrive at some other place where there's a try..except block.  In which case anything can happen, depending on how that block is written.\nWith uvloop:\nuvloop intercepts and handles all signals asynchronously.  There's no signal handler registered with the loop.add_signal_handler() API, therefore, the exception is raised right in the uvloop internals.  But uvloop is a bit more resilient to errors than vanilla asyncio, so it simply logs that an unhandled error has happened.\nWhile uvloop behaves differently from asyncio in this very case, it's only a matter of time until we guard selector.select() in asyncio with a try..except block and arq stops working with vanilla asyncio.\nOptions for fixing this:\n\n\nHandledExit should subclass BaseException.  Both uvloop and asyncio will not try to suppress it, so your program will work reliably.  This is a preferred option for SIGINT specifically, because you want it to break Python tight loops if they ever occur in your code.\n\n\nUse loop.add_signal_handler() API and handle your signals in a graceful fashion, i.e. call loop.stop() etc.\n\n\nI'm closing this issue as \"not a bug\".\n[1] https://github.com/python/cpython/blob/v3.6.3/Lib/asyncio/base_events.py#L1390. To be more specific: you should probably keep using signal.signal() for SIGINT, and loop.add_signal_handler() for other signals.  But in any case please take my advice with a grain of salt, I suggest you to experiment and see what works best. Correctly handling signals is super hard and there's no generic advice that works in all cases.. > EDIT: I don't know if there is a fast test to tell if the host is an IP address or not.\nYes, there's a fast test. I'll look into this.. Fixed in master. Will be in 0.9.0 release (soon). Please try uvloop v0.9.0.. Thanks!. Interesting. I think some code in asyncio needs to be fixed too :). Specifically, asyncio code expects that fd is an int, not a file-like object. Everything works by accident because selector module supports both.. Let me experiment with this a bit more to confirm that we need to fix anything in asyncio. I just did a cursory look.. Fixed in master.  Will be in the next release 0.9.0 soon. 0.9.0 is available now!. Sorry, no update as of yet. I'm a bit behind on releasing a new uvloop version with fixes to all open issues. Will try to dedicate a few days closer to the end of the week. If you are willing to make a PR fixing this go ahead!. I'll fix this on Monday.. Just pushed a commit to master that should fix this.  Could someone please try it out?. I'll wait till tomorrow if someone tries the master branch out and confirms that the problem is fixed.  If not, I'll issue a minor uvloop release tomorrow morning.. I've just released 0.8.1 which should fix the issue. Please test.  Sorry it took so long, I was completely blocked with working on PEP 550.. Closing this now.. It works in asyncio by pure accident: https://github.com/python/cpython/blob/master/Lib/asyncio/base_events.py#L163\nPlease fix your program, as asyncio will raise the same error in Python 3.7.. My mistake.  After some testing with IPv6 connections I confirm this is a bug in uvloop.. Fixed. Will be shipped in uvloop 0.9.0 soon.. Please try uvloop v0.9.0.. There's not much we can do here.  uvloop can't detect/intercept socket.close(), and libuv/epoll have no mechanisms to behave correctly when such an unexpected thing happens.\nI filed an issue to add new API to CPython https://bugs.python.org/issue32038 to intercept socket.close() calls.. @saghul Do you think it's possible to fix epoll code in libuv like this?\ndiff\ndiff --git a/src/unix/linux-core.c b/src/unix/linux-core.c\nindex 4d480ce1..29ca3fe2 100644\n--- a/src/unix/linux-core.c\n+++ b/src/unix/linux-core.c\n@@ -241,6 +241,10 @@ void uv__io_poll(uv_loop_t* loop, int timeout) {\n      * events, skip the syscall and squelch the events after epoll_wait().\n      */\n     if (uv__epoll_ctl(loop->backend_fd, op, w->fd, &e)) {\n+      if (errno == EBADF) {\n+        uv__io_stop(loop, w, POLLIN | POLLOUT | UV__POLLRDHUP | UV__POLLPRI);\n+        continue;\n+      }\n       if (errno != EEXIST)\n         abort();. Good news!  It appears there's undocumented API for preventing socket objects from closing.  uvloop will no longer crash.  The fix will be in the next release (soon).. Please try uvloop v0.9.0.. Thank you, LGTM. Will merge it soon.. The actual fix turned out to be a bit more elaborate.  Closing this one in favour of https://github.com/MagicStack/uvloop/commit/8f2b6c66d47a7798b0ca0639ee9eb4bf4a842c38.  Thanks a lot!. libuv won't work with inf.  I guess a reasonable option would be to convert inf timeouts to 100 years from now.. Fixed in master. Will be in the next uvloop release (0.9.0) soon.. Please try uvloop v0.9.0.. Fixed in master.  Will be in the next release (soon). Please try uvloop v0.9.0.. https://github.com/MagicStack/uvloop/commit/357cb60a1ac5afa391697debedc841ee5db56ea2 should fix the \"unresolved symbol pthread_atfork\" problem.. Please submit a PR to add HOST_SYS env option. Although I'd rename it to LIBUV_CONFIGURE_HOST.. Will be in the next uvloop release (0.9.0) soon.. Please try uvloop v0.9.0.. Thanks!. Thanks @jimmylai . Look like this isn't a uvloop issue, but rather that it's related to Arch packaging. Closing this, feel free to reopen.. > asyncio claims that it decides based on host's value which family it chooses\nAlright, I'll take a look how Python/asyncio implements that.. BTW, feel free to submit a PR if you have a good idea how to fix this before I find time.. Fixed in master.  Will be in the next uvloop release next week.. Please try uvloop v0.9.0!. Should be fixed in master.  Can you test if UDP works for you guys now?. Please try uvloop v0.9.0, where this bug should be fixed.. Fixed in master. Will be in the next uvloop release (0.9.0) soon. Keep in mind that Cython isn't compatible with 3.7.0a2 yet, so we'll only have 3.7.0a1 compatibility.. v0.9.0 should be compatible with 3.7.0a1. I think I'll keep set_child_watcher non implemented. Asyncio's Windows policy doesn't implement it, which suggests us that it's OK for a working policy to not support this API.  So my advice is to simply handle NotImplementedError.. Thanks!. Thanks!. I plan to make a few changes to internals that can potentially require a few rounds of bugfix releases.  Let's release 0.9.x, give it a month and release 1.0 after that.. Thanks, Andrew. > @1st1, have you planned to fix this?\nYes.  Will take a look in a week or two.  If you have time to make a PR I'll review it.. Actually, uvloop can block only if you supply a preexec_fn argument to loop.subprocess_shell() or loop.subprocess_exec().  Could you please share your test?. No need to debug or profile. Just read the release notes: in 0.9.x UDP has a different implementation, because libuv doesn't provide enough APIs for uvloop to maintain full compatibility with asyncio. I'll be making a PR to libuv to add new APIs so that we can have the old high-performance UDP implementation back.\n10x slower is surprising though, I didn't expect this to happen.. If anyone want to help me with this: we need to add uv_udp_connect() function to libuv (similar to uv_tcp_connect()). As soon as we have it there, we'll have a fast UDP in uvloop.  I myself am super busy with other stuff, and don't have any ETA on when I can make that libuv PR (it could be this weekend or 3 months later).. This will potentially unblock us: https://github.com/libuv/leps/pull/10  As a last resort we can consider shipping patched libuv.. There's a debate about adding uv_udp_connect() in libuv 1.x here: https://github.com/libuv/libuv/pull/1872#issuecomment-464080195\n/ Fingers crossed. /. I think it would be easier to wait until they release it. \nThat said we can start working on this ;) A good place to start would be to find the old UDP implementation in the history and try to resurrect it.. That was quick ;)  I'm reading this on my phone so i missed the fact they released it already.\nWe can release uvloop 0.13 as soon as we update our UDP layer.. I'm actually working on it, and we have a new problem: libuv's uv_udp_t doesn't seem to support AF_UNIX sockets which we now support... We might need to open a PR @ libuv.  But so far I don't see the end of the rabbit hole.  I'll push my branch soon so that you can also play with it.. The https://github.com/MagicStack/uvloop/pull/238 PR is updating uvloop to start using uv_udp_t handles again. Anyone interested in seeing improved UDP performance please try to test/benchmark that PR.. Doesn't look like a uvloop issue. I'd suggest to file this issue to the websockets project.. Well, to me the backtrace looks like something is working just by accident in asyncio and breaks in uvloop, because it schedules things slightly differently. I can't check it right now myself, will take a look later.. Closing this one. Feel free to follow up if you think it's a uvloop issue.. Did you install uvloop via pip? Do you use any other packages that are compiled with Cython?. I suspect that the bug is in Cython.  Waiting for its next release to fix things.. Again, it looks like this is a regression in Cython.  Try installing earlier uvloop versions, we'll fix it with the next Cython release.. A new @cython.iterable_coroutine decorator has been added to Cython, which should resolve this issue. Now waiting for the next release to happen.. Fixed in master. Please test :). Please add some 'awaits' in your code where you call time.sleep. Otherwise the scheduler will simply call all blocking callbacks in a row and what you see is entirely reasonable.  I'll say more: there are no guarantees that vanilla asyncio will keep it's current behaviour w.r.t. how blocking code is exactly being executed.. I'm going to close this as \"not a bug\". There are no guarantees on how exactly callbacks are scheduled by event loops and I don't see any serious discrepancy with uvloop here. Feel free to reopen if you can find more examples.. An obvious fix is to manually call transport.close() instead of relying on GC. But uvloop shouldn't crash regardless. Looking into this.. Looks like the new UDP implementation is a bit racy w.r.t. GC. Ideally we should just revert to use uv_udp_t implementation, but that's blocked on https://github.com/MagicStack/uvloop/issues/120 and https://github.com/libuv/leps/pull/10.. I'll work on this next week. Expect to see an update soon.. Fixed in #149.  You can now build uvloop from source and test under Python 3.7.. Closing this in favor of https://github.com/MagicStack/uvloop/pull/138. Thanks so much for contributing this though! It's just the other PR is more developed and covers more cases.. Yeah, there's definitely a bug here. I don't have time to look at this right now \ud83d\ude1e, but feel free to submit a PR. . Well, one obvious solution is to simply remove self._close() line. The handler will be properly closed in its __dealloc__.  I'm going to try this.. I didn't make any changes to uvloop to support PyPy, so I guess it's just cpyext / cython getting fixed. Would appreciate you sharing your experience with running uvloop on PyPy.. What is \"deterministic scheduling\"? There are absolutely no guarantees that _thread_id will be exposed in future asyncio releases, it's a protected non-documented property. I usually don't want to make uvloop compatible on that level.. Well, generally you should just use loop.call_soon_threadsafe and asyncio.run_coroutine_threadsafe. Without you providing more details I cannot help you any further.. Unfortunately this isn't something that we can do in Cython (at least the support is very limited in 0.28.2). Many of uvloop objects are defined as extension types which cannot be derived from Python classes. A better option is to simply use duck typing.. Then isinstance checks will be slow. TBH there's little use case to actually use isinstance(s, AbstractServer) or isinstance(s, Transport). Do you know a good real-world use case?. Maybe. Feel free to open an asyncio feature request for 3.8. We'll need to check if we actually call isinstance in asyncio so that we don't harm performance.. Does it work with CPython?\nPyPy isn't officially supported by uvloop, so some things can be broken.  I'd appreciate you investigating this and making a PR if it's a bug.. I'm going to close this as PyPy compatibility isn't something I'm concerned with. The performance of vanilla asyncio under PyPy should be acceptable, so missing proper uvloop support for PyPy shouldn't be a deal breaker.. Please try the latest master branch.. This one seems to be very outdated now, closing it. Thanks for submitting a bug report anyways!. This seems to be a bug in your code that accidentally works under vanilla asyncio. Hard to say more without seeing a code snippet that reproduces this.. Yeah, you're right, that's what it seems to be. You can use asyncio.Task.all_tasks() API to get a number of all asyncio tasks for a particular event loop.\nYou can also build a debug build of uvloop that exposes a Loop.print_debug_info() method.\nI'm also looking into adding deeper introspection/tracing APIs to the next uvloop release. cc/ @pfreixes. This issue is superseded with this https://github.com/MagicStack/uvloop/issues/163, feel free to join the discussion!. Fixed in master. Please test!. What's the actual intent behind checking __version__? Ideally you should never depend on it in your source code.. Yep, I saw this PR yesterday. Will take a look tomorrow. Thanks!. > if you are in a rush with other stuff, I can make it.\nI think I'll work on it myself. My idea is to copy _asynciomodule.c to uvloop. Since it's my code I think it shouldn't take me too long to figure out how to do that correctly.. This PR needs to land before I start working on contextvars though.. > Travis CI uses an older 3.7-dev image, exactly 3.7.0a4+. And the 3.7 is no longer available. Since this breaking change [1] I would say that Python 3.7 is kinda broken for Travis. I hope that the Docker solution will be a temporary one, but right now is the only way to get a functional environment running an interpreter with a version beyond the alpha 4.\nCan you try installing python 3.7 using pyenv? It worked fine for me when we tried it for https://github.com/azure/azure-functions-python-worker/. I see the pain of fixing the CI to work with 3.7 ;(\nWhat are your thoughts about pyenv?  We also use it for macos here:\nhttps://github.com/MagicStack/uvloop/blob/28d35d9b7ff7108cd6195d51373f8058b5c57598/.ci/travis-install.sh#L5-L15. > PD2: Out of topic, I have a pending conversation with you regarding the tracing. I would like to give you another point of view. But I will work on it this weekend.\nNP, I plan to spend at least a week working on uvloop after mid-May. Will have time to discuss tracing and to prepare next uvloop release.. Closing this one in favour of #149. The new PR is a version of this one with removed CI tweaks.. Can you attach the full script to reproduce, along with versions of dependencies that you used?. Thanks, @squeaky-pl.. FWIW fixing it might never come on anyone's end, unless you try to fix it yourself :-). Definitely not a feature, but I'm not sure it's a bug of uvloop and not of sc2682cornell version of wrk. Would appreciate you investigating this further.. Do you think you can create a failing unit test?. Also, can you reproduce this with vanilla asyncio?. Maybe this is an httptools bug then.. httptools doesn't support pipelining. uvloop and asyncio have nothing to do with http.. > So a data object in data_received function consisting of multiple requests is an expected behavior if the client is using HTTP pipelining?\nProbably. I never implemented support for HTTP pipelining but I imagine it works in this way: concatenate a bunch of HTTP requests and let the client parse them. Since HTTP pipelining isn't used widely, I guess it's a non-issue for sanic.\nI'm going to close this issue since this isn't a uvloop (or even asyncio) bug.. Yes, it should be possible: https://github.com/MagicStack/uvloop/wiki. This seems to be a bug, I'll take a look. Thanks for reporting it!. This is actually a CPython bug :) Thanks for reporting. Closing this in favour of https://github.com/python/cpython/pull/7080.. If you look carefully at the asyncio code, you'll see that run_in_executor calls its _check_callback() method in debug mode:\nhttps://github.com/python/cpython/blob/b7555babe95ee0db2f1224ec53cfe68a005448a1/Lib/asyncio/base_events.py#L726-L727\nand _check_callback(), in turn, \nhttps://github.com/python/cpython/blob/b7555babe95ee0db2f1224ec53cfe68a005448a1/Lib/asyncio/base_events.py#L679-L683\nchecks that the passed function is not a coroutine or a coroutine function. Performance is the only reason why run_in_executor does not always check that.\nrun_in_executor was never ever supposed to run coroutines and making it doing so isn't a good idea.\nClosing this issue as \"not a bug\".. Well, asyncio certainly has its fair share of warts, many of which are addressed in Python 3.7 and will be further cleaned up in Python 3.8.  Calling it \"stupidly opinionated\" is a little short-sighted, and I do not appreciate that here.. > You're free to be irked over my use of the word \"stupid\" but I stand by it being opinionated given that it's usually within the purview of an executor instance to reject unusable tasks (submit or an internal method).\nasyncio has existed for many years now, and you're the first one who tries to use run_in_executor this way (and people request new asyncio features all the time). It suggests that what you're asking is either a very niche feature or a misuse of the API. It's your job to convince people otherwise :)\nBeing opinionated is fine, trying to abuse some API and complain that it didn't work in an offensive way is not. It makes your position weaker and prompts other people to simply stop the conversation. \nAs for your use case: what stops you from designing your own API/micro-framework/library/helper that does what you want?  Why do you want to use run_in_executor() for that?  Adding a simple wrapper like this is trivial:\npython\nasync def my_run_in_executor(func):\n    if inspect.iscoroutine(func):\n        return await my_special_executor.run(func)\n    loop = asyncio.get_event_loop()\n    return await loop.run_in_executor(func)\nYour code will become more readable; another developer will be able to follow what's going on and how it works.\nNow it's very unlikely that we will ever change run_in_executor() to accept coroutines. Not because of \"stasis\" but because we want to design an entirely new API (more high-level and robust) to interact with executors.. Fixed in #149.  You can now build uvloop from source and test under Python 3.7.. Thanks for the PR! I'll close it in favour of #138 which is a bit more generic.. Merged by hand in ce2bd4fbf749cbe2ffbf7da8bed09959ca5c5742. > _ssl module is taking quite some time, 90% of which is on read() and write() of _ssl.SSLSocket, and 9% on _ssl.MemoryBIO.\nOh, that's unfortunate. I looked at _SSLObject.read and write implementations in Modules/_ssl.c and it looks like they are just tiny wrappers of OpenSSL functions.  We can probably save some overhead by supplying our own buffer to read, but I wouldn't expect it to give us any significant improvements.. Maybe asyncio's read buffer is too small and we have too much overhead with WANT_READ.. Or you can try uvloop which has 256kb (or something like that) buffer size by default.. > asyncio has similar read buffer size as uvloop, 256KB vs 250KB. Tried both 2560KB with asyncio, and master uvloop.\nThat's true only for 3.7, but I get your point.\n\n\nPort the PoC to uvloop/sslproto.pyx to see how it works.\nProfile and improve cpython/Modules/_ssl.c (tried ltrace a bit, result is not yet convincing).\nRewrite asyncio/sslproto.py with new _ssl.c perhaps.\n\n\nLet's re-sync after (1).\n(2) and (3) will require us waiting until 3.8, considering your improvements to the ssl module are accepted.\n. > Meanwhile there's also a possibility to make uvloop use pyOpenSSL, libuv-tls or similar libs directly (as a last way).\nYes, I was thinking about that too until I looked at _ssl.c and saw a very thin wrapper around OpenSSL. I really don't think we can make it any faster. But this is just my first impression; maybe there are some faster OpenSSL APIs that we can use or something. After we have a better SSLProtocol implementation I'm totally open to profile Python's ssl module to see if it can be improved.. Christian Heims also suggests trying to enable http://manpages.org/SSL_CTX_set_read_ahead/3. We'll also need to think about offloading SSL encryption to a thread, in case it consumes significant CPU.. Also need to investigate SSL_MODE_ENABLE_PARTIAL_WRITE; a comment from _ssl.c:\nXXX should partial writes be enabled, SSL_MODE_ENABLE_PARTIAL_WRITE?\nI've seen some comments in forums suggesting enabling it for non-blocking IO.. > Previous commit embeds the loop in _ssl.c, and improved the overall performance by approximately 30%~40%.\nNice.. Great. You can also try to use BufferedProtocol, but really up to you in what order want to approach this.. > I'm trying to separate the flow control (FC), and extract a more clearer state transition model tomorrow, in order to survive e.g. renegotiation.\nTake your time.  And... nice diagram! We'll probably want to have a digital version of it to put somewhere in the docs ;). Great progress! (GH doesn't send notifications on edit, so this is the first time I see the updates)\n\n\nPython didn't expose it, OpenSSL didn't do it fully right, HTTP/2 forbid it, and TLS1.3 replaced it with something else. I'll try to get it working and tested with minimal effort - perhaps copying some tests from Trio as Nathaniel seemed already walked through this.\n\nIs it so broken that it's impractical to support it? I mean it's a very niche requirement, so if its support comes at the expense of code clarity/maintainability I'd say let's not do it at all. Your call though.\n\nTLS1.3 replaced it with something else\n\nCan you share some details on that?  Is that new TLS 1.3 renegotiation protocol easier to implement?  Maybe we can get away with supporting just that TLS 1.3 thing?. > I just realized that I\u2019ve been comparing encryption time with loopback network time, which is probably not a practical anchor point.\n\nMaking the time consumed in the _ssl module as the anchor point (unit of one), the first PoC sslproto.py was 34% faster (1.29 -> 0.85), and the decrypted data aggregation fix was 70% faster (0.52 -> 0.15) on 100KB echo server. In this special combo case, sslproto.py is improved to only take about 10% of the time spent in _ssl module, that is 6.5% extra overhead overall comparing to previous 15% ~ 30%, which is good enough I think.\n\nRight. This is great. Perhaps we'll be able to squeeze a few more %% when we cythonize the sslproto.py, but seems that the performance isn't that bad after all.\n. What's the latest news here?. This one can probably be closed now, right?. In 0.10.0 there's a 10 seconds timeout for the handshake operation. Is your endpoint slower than that?\nIt's also a default timeout for handshake in asyncio 3.7, although it's configurable via the ssl_handshake_timeout parameter to create_connection and create_server (the parameter isn't yet backported to uvloop).  Do you feel that 10 seconds is not enough?\n\nP.S. Bonus bug I cannot handily reproduce: sometimes I saw an AttributeError about errno not being on CertificateError or something like that.\n\nThat means asyncio 3.7 has this bug too. Will take a look.. What default timeout would you suggest?\n\nIt would also be great if we could do something about the output btw.\n\nYou mean the errno/CertificateError error? Or the \"... stalled during handshake\" error message?. (a PR to CPython to fix this: https://github.com/python/cpython/pull/7321). Fixed in v0.10.1. Please try it ;). https://github.com/MagicStack/uvloop/pull/160 is the first attempt at implementing the new API.  \nThe main thing I don't like about it is that it's designed around having various _begin and _end callbacks in so called Collector objects.  There are a few problems with this approach:\n\n\nThis isn't flexible: you'll need to update your collector with new _begin and _end methods whenever a new version of uvloop with new tracing bits comes out.\n\n\nIt's too generic. I don't like that users will be able to run arbitrary code at arbitrary places. Writing a proper and low-overhead collector will be a non-trivial task. Speaking from my experience, we will end up in a situation where people do all kinds of crazy stuff in those callbacks, including scheduling more callbacks and doing disk IO.\n\n\nIn my opinion it would be better to create a Span dataclass that has the following attributes:\n\nname: str -- name of the trace, like \"task.created\", or \"network.data_received\".\nid: uint64 -- unique span ID\nparent_id: uint64 -- ID of the parent span\ntype: uint8:  (or this can be just type of the class)\n0: duration\n1: counter\n\nFor \"duration\" spans:\n created_at: uint64 -- local monotonic time (in nanoseconds?) when the span was created\n duration: uint64 -- how long the span was active\nFor \"counter\" spans:\n* count: uint64 -- how many times a certain thing happened, or how many bytes were transferred\nThis is just an idea we should play with. The design is inspired by statsd and zipkin.. > So summary, providing uvloop its own system to create and handle spans might create some resistence to be adopted by some tracers.\nI agree, that will be a problem.  The idea here is that we need a mechanism to setup a custom Span constructor per trace.\nHere's my current idea of the API. It's quite close to Jaeger and few other tracing libraries. \n```python\n\nClasses that a tracing library would need to provide to\nsupport uvloop:\n\nclass Span(abc.ABC):\n@abc.abstract_method\ndef get_parent_span(self) -> Span:\n    \"\"\"Return the parent span.\"\"\"\n\nclass TimerSpan(Span):\n    pass\nclass CounterSpan(Span):\n    pass\nclass Tracer(abc.ABC):\n@abc.abstract_method\ndef start_timer_span(self, name: str) -> TimerSpan:\n    pass\n\n@abc.abstract_method\ndef end_timer_span(self, span: TimerSpan):\n    pass\n\n@abc.abstract_method\ndef start_counter_span(self, name: str) -> CounterSpan:\n    pass\n\n@abc.abstract_method\ndef end_counter_span(self, span: CounterSpan):\n    pass\n\n@abc.abstract_method\ndef increment_counter_span(self, span: CounterSpan, inc: int):\n    pass\n\n\nAPIs that uvloop will provide:\n\nclass TracedContext(abc.ABC):\n    \"\"\"An opaque object that encapsulates information about tracing.\"\"\"\ndef _get_tracer(self) -> Tracer:\n    \"\"\"Return the Tracer that was used to start the context.\"\"\"\n    # Private uvloop API\n\ndef _get_current_span(loop) -> Optional[Span]:\n    \"\"\"Return the current span.\"\"\"\n    # Private uvloop API\n\ndef _is_tracing(loop) -> bool:\n    \"\"\"Return True if tracing is enabled in the current context.\"\"\"\n    # Private uvloop API\n\ndef uvloop.start_tracing(loop, tracer: Tracer) -> TracedContext:\n    \"\"\"Start a new TracedContext and set it as current.\"\"\"\ndef uvloop.end_tracing(loop, trace_ctx: TracedContext):\n    \"\"\"Stop tracing for the passed TracedContext.\"\"\"\n```\nThe actual tracing implementation is deliberately hidden from uvloop users, allowing us to use contextvars or any other mechanism we want.\nOpen questions:\n\n\nShould TracedContext support nesting?  Maybe TracedContext can be a Span? In principle I'd be OK with uvloop.start_tracing() creating a top-level TimingSpan instance, but I'd like tracing boundaries to be a bit more visible than that.\n\n\nIdeally we should somehow indicate new Tasks -- so maybe we need a TaskSpan span too.\n\n\nHow can we shield some tasks from tracing? That's needed to spawn new tasks that are not traced (even if the Task that spawns them is traced).. > I like zipkin approach to spans since API is minimalistic and very powerful, here I created tracer for asyncio with aiohttp instrumentation (https://github.com/aio-libs/aiozipkin). I have implementation of spans/tracers/context etc.\n\n\nNice. What do you think about the approach I outlined in https://github.com/MagicStack/uvloop/issues/163#issuecomment-394416117? Would it work for aiozipkin? If no, then how would you change it?\n\nQuick question, zipkin/opentracing and co are all about distributed tracing (as described in dapper paper), it helps to find all tasks spawned by particular request on several distributed machines. Given that what purpose of uvloop/asyncio tracing subsystem? Is this only for debugging only local process or distributed also?\n\nI'd aim for both.\n\nDistributed case has some implication, trace or not to trace often decided on separate server per request, if we infer from incoming request that it sampled, subsystem should trace all child tasks and attach it to current span.\n\nWe'll be using contextvars to store the tracing context, so enabling tracing just for one web request should be naturally supported.. This is how asyncio works for regular transports and how it will work for SSL transports in 3.7. Note how most errors are logged in selector_events.py even though they are propagated to a protocol:\nhttps://github.com/python/cpython/blob/9602643120a509858d0bee4215d7f150e6125468/Lib/asyncio/selector_events.py#L669-L681. Looks like you're cancelling the test() task with loop.call_soon(cb) and the cancellation happens before await getting_foo and Foo.run() \"connect\" with each other.  If you change loop.call_soon(cb) to loop.call_later(0.1, cb) the script works as expected.\nThis might be a bug with asyncio.Task, but your code snippet is a bit hard to parse and understand.  I suggest you to spend some time and simplify your code so that it's more obvious what's going on here.  Then I suggest you to submit a bug to bugs.python.org!. Your english is totally fine :) Please do submit a bug,  your test script, and the proposed solution. I don't have time to look into this right now, but I'll try to find time before 3.7.1 is released.. Yeah, I don't think anything can be done here except increasing the amount of memory for your VM. I'd suggest using wheels to avoid the compilation step (simple pip install uvloop should just install a pre-compiled wheel package for you).. > Probably Cython needs to be installed before installing uvloop.\nNo. Cython is only used during the sdist/bdist phases. It's not a runtime dependancy.\nClosing this issue.. Would you mind making a PR fixing this?. Regarding #170: I don't think that copying the approach of asyncio/base_events.py is the right strategy here. IIRC I decided to go with a different implementation of loop.sock_* methods because asyncio has many other problems with cancellation.  In uvloop, cancellation happens in _new_reader_future and _new_writer_future methods, maybe they should be adjusted to handle your case?\nBTW, I don't see a unittest to reproduce the bug you're trying to fix.  It's absolutely crucial to have a unittest, can you please try to come up with one?. I made a new PR that is essentially a refactoring of your fix and another unittest: https://github.com/MagicStack/uvloop/pull/173. Closing in favour of #173. Looks good in general. I'll try to find time to get back to the discussion we have in the issue to see if we're missing anything.. > What is missing/What is pending to discuss:\nThis is a great summary, please update the issue with it.. This is weird.  The weakref module is referenced from uvloop/includes/__init__.py, and the includes module is then imported from uvloop/__init__.py to specifically guard against this scenario.\nSeems like a bug in Python 3.7 to be honest.. Should be fixed in master, please test. Thanks!. I don't like the idea of supporting private asyncio APIs and implementation details in uvloop. _run_once() is one of such methods that we might get rid of in asyncio in Python 3.8 too. Therefore my inclination right now is to close this as \"won't fix\".\nA simple workaround that uses only public APIs is to call loop.run_until_complete(asyncio.sleep(0)). Would that work for you?. > loop.run_until_complete doesn't work if the loop is already running.\nIf the loop is already running you can use loop.call_soon(call_me_after_one_loop_iteration) or await sleep(0).\n\nPerhaps just changing _on_idle to a cpdef would be acceptable?\n\nNo, not really, as people will start depending on it and that would make it harder to refactor uvloop in the long term.. uvloop's SSL implementation is now the same as in Python 3.7, so both vanilla asyncio and uvloop should have the same logging behavior. If you think that logging is redundant in this case, please open an issue on bugs.python.org so that we fix it in both places.\nThanks!. > According to libuv docs, the following read_cb might be called with nread=UV_EOF with no buffer allocated.\nAh, that makes sense. Thanks for fixing that; can you make a fix in a separate PR?\nWhat's the projected timeline for this PR? I assume you are planning to add more SSL tests, right? Or is it ready for a review now?. Anytime this week works.. In short: I like the new code, it's easy to follow. Great job! Don't have any major comments. The state transitions seem fine, the overall logic is OK too.\nI'd continue iterating on the codebase and adding tests (your current ToDo is great too!)\nAt some point when we think it's ready we'll commit the Python implementation (to have it in the repo) and start to Cythonize it to make it slightly faster. The pure-Python implementation will go straight to asyncio 3.8.. I'm testing this in debug mode just to make sure we haven't made some silly mistakes. I see that the process memory grows aggressively to some point and then flats out; this might be Python's famous memory fragmentation issue. But just in case, I'd like you to see if you can reproduce this locally.\nInstructions:\n\nbuild uvloop with make debug;\nrun python examples/bench/echoserver.py --proto --uvloop --ssl; you should see some debug info printed on the screen and dynamically updated;\nrun python examples/bench/echoclient.py --workers 6 --msize 10241 --num 10000 --ssl and watch how the Process memory metric increases.\nrepeat the last step a few times; then increase the payload size; repeat again.\n\nSo the process' memory usage grows with time. I'm 99% sure that this is just memory fragmentation. But maybe we also need to ensure that it's contained; for instance, it might be a good idea to cap max buffer size when we realloc.  In general, I'd appreciate if you take another quick glance over sslproto.pyx to make sure we're not leaking memory.\nOther than that, the PR is ready :). > Check sendfile support\nWe don't support the new sendfile in uvloop yet.. > And here's the SSL benchmark running modified vmbench on a 4-core 2.5GHz cloud server, all benchmarked servers are running in python:3.7 (Debian 9) docker containers (full benchmark data here):\nBTW, we should merge your additions back to the vmbench project.. > If okay, I'll rebase again and squash all commits.\ngo for it!. @elprans can you take a quick look at this before I merge?. @fantix hey, could you please take a look at the failed CI?. @asvetlov could you also take a look?  This is something that we'll use pretty much as is in asyncio in 3.8.. Thank you so much, @fantix! \ud83d\udcaf\ud83c\udf89\ud83d\ude80. Awesome, thanks!. uvloop fully supports 3.7, it's just we don't have wheels for it yet. The traceback you see is libuv failing to build in your environment.. v0.11.0 is now released with Python 3.7 wheels. Please test! :). While you're here, please update RELEASE_PYTHON_VERSIONS=\"3.5 3.6\" to RELEASE_PYTHON_VERSIONS=\"3.5 3.6 3.7\" in .travis.yml.. @elprans please take a look.. I pushed a CI change in a separate commit: https://github.com/MagicStack/uvloop/commit/37f964b757e48ae89ba7471df40345dc0d0fb233\nThank you for working on this, I credited you for the change!. AppVeyor was testing linux+python 3.7 (uvloop doesn't support Windows yet), which is now unnecessary.. Can you submit a PR to revert that commit and maybe write a unittest?. Thanks!. Fixed in uvloop 0.11.1. Thanks for working on this!. Could you please add a comment to uvloop/server.pyx explaining the code?  (I don't want to reintroduce this regression in a slightly different way that the test wouldn't be able to catch)\nThe PR looks fine otherwise and as soon as I merge it I'll issue a bugfix release.. Thank you!. Closing this one. I also think that README and the linked blog post address this question just fine.. All asyncio improvements benefit uvloop directly, so the performance gap should be the same.. Anybody wants to submit a PR? :). I just checked: while pause_reading() method does exist on DatagramTransport in asyncio, it raises a NotImplementedError. So strictly speaking there's no difference between asyncio and uvloop here.  Please open a bug on bugs.python.org if you think that pause_reading() and resume_reading() are needed for UDP.. Fixed in uvloop 0.11.1. Thanks for submitting this bug!. Wow! Thank you so much for tracking this down!\nI have a different idea how to fix this though. Instead of fixing refcount in __dealloc__ we should do that the moment we copy the context. Otherwise we can get another kind of leak if there's a cycle between the context and the task/callback handle. Hence https://github.com/MagicStack/uvloop/pull/192.  I'll close this one.\nI will issue a bugfix release for 0.11.x and 0.10.x today.. v0.11.2 has just been released with a fix for this. Thanks again!. Did you try running \"git submodule init; git submodule update\"?. > no i a manually adding libuv files in vendor folder in repository before installing.\nWell, you're on your own then, I can't help you here :(. It should, but i haven't ever tested that myself.. Closing this one, please feel free to reopen!. Are you trying to install it on Android? If so it's not officially supported and I have no way to test what's going on. And I can't reproduce this error on my machine. Most likely you don't really need uvloop on android anyways, vanilla asyncio should work just fine.. I'm going to close this as I don't see anything actionable for myself here. But please submit a PR if you know how to improve setup.py.. @fantix please take a look if you have time.. Crashes 100% consistently for me (I use pytest to run tests). I su\nJust tried this:\n```\n$ git status\nOn branch master\nYour branch is up to date with 'origin/master'.\nnothing to commit, working tree clean\n$ python --version\nPython 3.6.6\n$ pip freeze\naiohttp==3.2.1\nalabaster==0.7.10\nasn1crypto==0.24.0\nasync-timeout==3.0.0\nattrs==18.1.0\nBabel==2.5.3\ncertifi==2018.4.16\ncffi==1.11.5\nchardet==3.0.4\ncryptography==2.3\nCython==0.28.5\ndocutils==0.14\nidna==2.6\nidna-ssl==1.0.1\nimagesize==1.0.0\nJinja2==2.10\nMarkupSafe==1.0\nmore-itertools==4.1.0\nmultidict==4.3.1\nmypy-extensions==0.3.0\npackaging==17.1\npluggy==0.6.0\npsutil==5.4.6\npy==1.5.3\npycparser==2.18\nPygments==2.2.0\npyOpenSSL==18.0.0\npyparsing==2.2.0\npytest==3.5.1\npytz==2018.4\nrequests==2.18.4\nsix==1.11.0\nsnowballstemmer==1.2.1\nSphinx==1.7.5\nsphinxcontrib-websupport==1.0.1\ntyping-inspect==0.3.1\nurllib3==1.22\nyarl==1.2.4\n$ make distclean\n...\n$ make\n...\n$ pytest\n========================================== test session starts ==========================================\nplatform darwin -- Python 3.6.6, pytest-3.5.1, py-1.5.3, pluggy-0.6.0\nrootdir: /Users/yury/dev/magic/uvloop, inifile: pytest.ini\ncollected 456 items\ntests/test_aiohttp.py ....\ntests/test_base.py ..................................................................\ntests/test_context.py .ssssssssss\ntests/test_cython.py .\ntests/test_dealloc.py .\ntests/test_dns.py ...................................................\ntests/test_executors.py ....\ntests/test_pipes.py ..........\ntests/test_process.py ..............................................................\ntests/test_regr1.py .\ntests/test_signals.py ................\ntests/test_sockets.py .......................s...........\ntests/test_tasks.py ............................................................\ntests/test_tcp.py ..................F..s............s.........s..............fish: \u201cpytest\u201d terminated by signal SIGSEGV (Address boundary error)\n```\nI suspect that the problem is related to how BufferedProtocol support is implemented.  The \"test_create_server_buffered_1\" test fails and then we have a segfault:\n```\npytest -v tests/test_tcp.py\n========================================== test session starts ==========================================\nplatform darwin -- Python 3.6.6, pytest-3.5.1, py-1.5.3, pluggy-0.6.0 -- /Users/yury/dev/venvs/uvloop/bin/python3.6\ncachedir: .pytest_cache\nrootdir: /Users/yury/dev/magic/uvloop, inifile: pytest.ini\ncollected 85 items\ntests/test_tcp.py::Test_UV_TCP::test_connect_accepted_socket PASSED\ntests/test_tcp.py::Test_UV_TCP::test_connect_accepted_socket_ssl_args PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_2 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_3 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_4 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_5 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_6 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_open_con_addr PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_open_con_sock PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_connection_wrong_sock PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_1 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_2 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_3 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_4 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_5 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_6 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_7 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_8 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_buffered_1 FAILED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_buffered_2 PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_float_backlog PASSED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_stream_bittype SKIPPED\ntests/test_tcp.py::Test_UV_TCP::test_create_server_wrong_sock PASSED\ntests/test_tcp.py::Test_UV_TCP::test_flowcontrol_mixin_set_write_limits PASSED\ntests/test_tcp.py::Test_UV_TCP::test_many_small_writes PASSED\ntests/test_tcp.py::Test_UV_TCP::test_tcp_handle_abort_in_connection_made PASSED\ntests/test_tcp.py::Test_UV_TCP::test_tcp_handle_exception_in_connection_made PASSED\ntests/test_tcp.py::Test_UV_TCP::test_tcp_handle_unclosed_gc PASSED\ntests/test_tcp.py::Test_UV_TCP::test_transport_get_extra_info PASSED\ntests/test_tcp.py::Test_UV_TCP::test_transport_shutdown PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_2 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_3 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_4 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_5 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_6 SKIPPED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_open_con_addr PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_connection_open_con_sock PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_1 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_2 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_3 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_4 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_5 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_6 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_7 PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_create_server_8 SKIPPED\ntests/test_tcp.py::Test_AIO_TCP::test_tcp_handle_exception_in_connection_made PASSED\ntests/test_tcp.py::Test_AIO_TCP::test_transport_shutdown PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_create_connection_ssl_1 PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_create_connection_ssl_failed_certificate PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_create_connection_ssl_slow_handshake PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_create_server_ssl_1 PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_create_server_ssl_over_ssl PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_flush_before_shutdown PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_remote_shutdown_receives_trailing_data PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_renegotiation PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_shutdown_cleanly PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_shutdown_timeout PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_ssl_connect_accepted_socket PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_ssl_handshake_timeout PASSED\ntests/test_tcp.py::Test_UV_TCPSSL::test_start_tls_client_buf_proto_1 fish: \u201cpytest -v tests/test_tcp.py\u201d terminated by signal SIGSEGV (Address boundary error)\n```. Seems that #198 fixed it for me.  @elprans can you re-run tests on your machine?\n@fantix should this be closed now, or there's still something to be fixed?. What's the status on this? Ideally we want to make a release next week.. Thanks for working on this!. What's the status on this?. See the release notes for 0.11.2: https://github.com/MagicStack/uvloop/releases/tag/v0.11.2 :). Thank you!. Released in uvloop v0.11.3.. Thank you!. Released in uvloop v0.11.3.. Thanks for submitting this. Care to make a PR?. Hm, could you please try uvloop 0.12.0rc1?. I'm gonna close this one, as the SSL implementation has been rewritten from scratch in 0.12. Please feel free to re-open this issue if the problem appears in 0.12.. Thanks!. There's no \"Cython side\"; Cython compiles itself to C that calls into CPython C API. uvloop is all in Cython, so its own code isn't being interpreted.  But whenever a callback written in pure Python is scheduled it's executed with CPython ceval loop (the interpreter).. Feel free to ask more questions!. Cython-generated code always involves CPython code.  Roughly speaking, for a program compiled with Cython, roughly all of CPython core code is executed. It's just that instead of CPython opcode evaluator calling C API, the generated C code calls it.  When you compile a pure Python code snippet like\npython\nprint('a')\ninstead of evaluating CALL_FUNCTION opcode that calls Python's print() implementation, Cython will compile C code that calls Python's print() implementation.  The goal here is to make sure that all performance-critical parts are compiled with Cython and avoid the slow path of CPython's opcode interpreter.  In other words, it's not possible to not involve CPython interpreter completely, and it shouldn't even be a goal.. Yeah, uvloop is still a bit behind 3.7.. It's literally in the first Readme line.. Your code is invalid: in the first line,asyncio.ensure_future creates an implicit event loop, and later you create an instance of uvloop. One way to fix this:\n```python\nmain_asyncio_loop = uvloop.new_event_loop()\nasyncio.set_event_loop(main_asyncio_loop)\n[asyncio.ensure_future(md_ws_connect(pair)) for pair in options]\npending = asyncio.Task.all_tasks(loop= main_asyncio_loop)\nmain_asyncio_loop.run_until_complete(asyncio.gather(*pending))\nmain_asyncio_loop.close()\n```. > On my laptop the results of sending out a million packets:\n\n\nwithout the patch: 7.8s\nwith the patch: 3.0s\n\n\nGreat improvement!\n\nQuestions:\n\ndo we need the validation code at all?\n\n\nIdeally yes.  DNS lookup would be blocking and that would be quite hard to debug.\n\nif we do, would you consider a patch which caches the last successfully validated address and skips the validation if sendto is called again with the same address?\n\nYes, please submit a PR.  You can probably add a function with an @lru_cache decorator to keep track of last N checked addresses.. > I also tried something else: simply storing the socket's family, proto and type as int members of UDPTransport. This doesn't skip the call to getaddrinfo but gives a significant performance gain which holds no matter whether it's an address we have already seen or not. The same test runs in 4.3s with this patch.\nCaching family/proto/type is OK too.\n\nRegarding lru_cache wouldn't that mean dropping out of C and back into Python?\n\nlru_cache is implemented in C since 3.6 (IIRC), but yeah, it involves quite a few CPython C API calls.  You'd probably want to profile it to check if it's fast enough.. > Using uvloop provides some performance improvement, but not as much as I had hoped.\nSpeaking of which -- when libuv 2.0 is released we'll likely be able to switch to native UDP libuv implementation which should be significantly (up to 10x) faster than what we have now.. > I'm very eager to see this in action, and would be happy to help if I can!\nFor the UDP part specifically we're blocked until libuv 2.0 lands.  Meanwhile feel free to help with other parts of the project!  For instance, I still can't find time to implement loop.sendfile() and start_serving\u2014new asyncio 3.7 features.. Thank you!. :). (This PR is related to https://github.com/MagicStack/uvloop/issues/207)\nYeah, I think this _address check is a remnant of the old UDP implementation and the PR is correct to just drop the check.. Thank you, Jeremy!. No, 0.12.0 will be the absolutely the same as 0.12.0rc1, I just need to make a release (probably today or tomorrow).\nThe UDP _address fix can probably go into 0.12.0 as it's a minor change and a clear bug fix.  As for the perf optimization, I think it should go into 0.13.0, for which I also planned to add sendfile support.. > Ouch, I was hoping the performance optimization would go in as well since currently uvloop's UDP send performance is worse than vanilla asyncio\nThis makes it a pretty strong case to include the change in 0.12 :). Thank you, Jeremy!. > Does it mean we include libuv binaries or we rely on libuv to be found on the system?\nAll wheels include a libuv binary.  libuv is a hard requirement for uvloop, it cannot run without it.  It's possible to also manually build uvloop with the system libuv.\n\nwas increased by two-fold after running apt-get install libuv1 on Ubuntu 18.04\n\nWhat benchmarks did you use?  Can you share the results?  Also, could you please provide more details about your setup:\n\nHardware\nuvloop version\nDid you run benchmarks in a container / in a VM / metal?. Wow, this is unfortunate.\n\nDoes your application use SSL connections?. UDP?  0.12.0 has a couple of UDP-related changes.  If you use UDP please try to run 0.12.0rc1 too.\nThe 0.12 release has a brand new SSL implementation, so the leak might be related to that.  Ideally we need a script to reproduce it though.. @amir20 Thank you so much.\n@fantix please take a look.. @fantix were you able to figure it out?. Great, thank you! I'll try to find some time to help in the next couple of days.. asap; I'm working on another fix right now.. Please try the new uvloop 0.12.1; hopefully it fixes your case.. > I think it works. After 30 minutes, its still at 135MB which is a good sign. Great job @1st1 :)\nGreat news!  The fix is to @fantix's credit though :). Thank you for reporting.  This is basically a duplicate of https://github.com/MagicStack/uvloop/issues/211.. > OK if tests pass I think this PR is good enough now, please kindly review.\nLooks like it's red :(\n. Yeah, that's blocked by https://github.com/libuv/libuv/issues/2058. We might need to fork libuv at this point (which will make it impossible to use the system libuv).  libuv maintainers aren't very responsive :( . Alright, it appears that we can now migrate to new libuv: https://github.com/MagicStack/uvloop/pull/226. > This is still work in progress, but I wanted to have some code up so we can start discussing it.\nThank you!  Sorry for the late review, I was OOO for about 10 days.  I'll try to address all your questions below:\n\n\nI have moved backlog to a member, so that listen (internal API for start_serving) can be called without arguments.\n\n\nOK.\n\n\nI noticed some argument validation (e.g.: backlog, ssl, ssl_backlog, timeouts) is performed quite deep inside the code, inside UVStreamServer. Shouldn't this be done closer to the API surface?\n\n\nSure.  If necessary we can always add an assertion at a lower level for clarity.\n\n\nCurrently one test fails because the previous code caught an OSError and re-raised it with a different message. Is this a behaviour we want to preserve?\n\n\nUsually we try to match (exactly) OSErrors that Python asyncio is raising, down to the message of the exception.  Is that the case in the previous code?\n\n\nI'm having trouble understanding the Server class, which seem to serve as the user-facing API as opposed to the internal UVStreamServer subclasses.\n\n\nIt is a user-facing API: the object is returned from the create_server() coroutine.\nThings that have the UV prefix in the handles directory are Python high-level wrappers around low-level libuv concepts.\n\nThe bit that bothers we: why does Server have a list of servers, can there really be anything other than 0 or 1?\n\nYes, there can be many.  If you create a server on localhost it can create more than one server; in the most simple case, you'll have one for IPv4 and one for IPv6.\nIn asyncio implementation (see CPython/Lib/asyncio/base_events.py for the reference) the Server object has a list of Python sockets that the server listens on.  In uvloop, we have a list of libuv's uv_tcp_t handles wrapped in UVStreamServer objects.  We later call uv_listen on them to start accepting connections.\n\n\nWho should carry the internal is_serving state, the Server or the UVStreamServer?\n\n\nThe Server objects, as it is a user-facing API that controls a bunch of low-level libuv handles.\n\n\nHow should we implement the future returned by serve_forever?\n\n\nI think we should be able to copy/paste asyncio implementation from base_events.py.. Oh well... I guess the only sure option we have is to rewrite this part:\nhttps://github.com/MagicStack/uvloop/blob/d8fe153e5b67de1124b828f9c9b3c5397ac68d5d/uvloop/loop.pyx#L1658-L1696\nto create Python sockets and bind them in the same way asyncio does that here:\nhttps://github.com/python/cpython/blob/8a1657b93469580ef345c7c91738587f3d76e87d/Lib/asyncio/base_events.py#L1338-L1393\nAfter we have Python sockets bound, we can wrap them in TCPServer objects the same way we do it here:\nhttps://github.com/MagicStack/uvloop/blob/d8fe153e5b67de1124b828f9c9b3c5397ac68d5d/uvloop/loop.pyx#L1708-L1713\nThat's the only way I can think of that will preserve full compatibility with asyncio.  Performance-wise this shouldn't have any impact.. You can merge it yourself. Please rebase it on top of recent master before merging though (has now flake8 integration). Need to implement sendfile support first.. Unfortunately I don't have time to tackle that myself in the next couple of weeks. Hopefully we'll get it in March.. Thanks so much, @jlaine!. @fantix please take a look. Care to make a PR to add it to our CI targets? :). Yeah, it seems that PyPI isn't the right place for hosting wheels for Pi/other ARM archs.  This comment by Nathaniel is the key:\n\nUnless someone wants to do lots of abi compatibility testing across different arm distributions, I think the most viable way forward here would be to push forward with the idea of distro-specific wheel tags, so that people could upload e.g \"raspbian wheels\"?\n\nPlease ping piwheels.org. Unfortunately I'm out of capacity to handle that.. Unfortunately, the libuv's sendfile implementation is just a thin wrapper over the \"sendfile\" system call. I.e. uv_fs_sendfile() is not integrated with uv_tcp_t handles, so it's very similar to Python's os.sendfile().  This means that yes, what we'll need to do is similar to vanilla asyncio, and I think that using os.sendfile() should be easier for us (will ensure same error types/messages as in asyncio).\nIn terms of the actual implementation: first we'll need a loop.sock_sendfile() method, which should be relatively simple to implement.  This should probably be the first PR.\nThe second PR should add loop.sendfile(). This one is more tricky; we'll need to: \n\n\nuse uv_poll_t handles to temporary monitor read activity for uv_tcp_t and uv_pipe_t handles;\n\n\nreplicate asyncio's logic with pausing and resuming reading as well as exhausting write buffer before doing sendfile;\n\n\nreplicate sendfile fallback implementation to support it for SSL transports.\n\n\nGood news is that a lot of the above is already figured out in asyncio, so we just need to apply that knowledge to the slightly different IO implementation in uvloop.. Actually we do run flake8 in our other projects as part of CI, I just didn't know we can use flake8 on Cython files.  A nice TIL ;). Thanks for nudging me to the right direction though :). Should this one be closed? Or there's something else we can try?. Looks like CI isn't any faster with this PR, right?. I think it's a rather minor inconsistency that shouldn't cause trouble, isn't it?  How did you discover this?. Great, thank you!. Yeah, go for it!. > when called with loop.call_later(0.0004, ...), it may still get called too early.\nAnd that's probably fine, because the interval is less than the timer resolution.  I think using round() instead of the implicit floor/cast should be a good enough solution.. Thanks!. Thank you!. (merged by hand). So is the new test stable?. Alright, merged. Thank you! :). This is great, thank you!  BTW, do you want to start porting this implementation to CPython?  We almost have no time left until the feature freeze.. @jlaine Jeremy, could you please try this PR?  Is it any faster than what we have now?. > the sockets aren't \"connected\" as remote candidates can come in at any time.\nMaybe the usual benchmark would be enough? I don't think we need to benchmark \"connected\" UDP sockets specifically, we're just interested to see if UDP with this PR is generally faster than in uvloop 0.12.. > Is this buffers being flushed?\nMaybe... Can you add transport.abort() (closes the transport instantly) or transport.close() (allows the buffers to flush) and see what happens?. >> Is this buffers being flushed?\n\nMaybe... Can you add transport.abort() (closes the transport instantly) or transport.close() (allows the buffers to flush) and see what happens?\n\nAlright, I think I've figured it out.\n\n\nasyncio tries to do sock.send() if the send buffer is empty. It's an optimization that we have for our TCP layer, but not for the UDP.\n\n\nOnce I started to call uv_udp_try_send() the weird behaviour you spotted disappeared, and uvloop started to behave just like vanilla asyncio.\n\n\nAfter some debugging and profiling I think that the delay is caused by the system call itself.  In other words, 1000000 system calls can be quite expensive.  We'll need a more elaborate benchmark that actually sends and reads data.\nI also optimized how Python socket addresses are converted to low-level sockaddr* structs.  Now we have an LRU cache for that, which seems to add a noticeable speed boost.. > I still don't quite understand how the cost system calls shows up at the end of the run loop?\nBecause the previous version of this PR and the current master branch only queue system calls in udp.sendto().  The latest iteration of this PR and asyncio actually try to perform system calls right in udp.sendto() if there're no pending buffers to send.. >Vanilla asyncio: 120Mbps\nuvloop 0.12.1: 140Mbps\nuvloop (this PR): 185Mbps\n\nI'd say that's a pretty neat performance boost!\n\nGreat news! :)  A microbenchmark would probably show even greater performance improvement.. > A microbenchmark would probably show even greater performance improvement.\nI mean a microbenchmark that actually does receive and send data, similar to TCP echo server bench in examples/bench/echoserver.py.  The benchmark must engage the rest of uvloop/asyncio transport/protocol code.  Benchmarking how efficiently they do system calls doesn't tell us much.. Thank you for a thorough bug report.  I'll try to find time to investigate this soon.. Thanks to your excellent analysis it was fairly trivial to find the actual bug.  I've created a PR with a fix.  Once it's green I'll work on releasing 0.12.2 asap.  Thank you.. I'm not sure it's OK to have a line break in .PHONY. Just add a second section like this:\n.PHONY: compile clean all distclean test debug sdist clean-libuv\n.PHONY: sdist-upload sdist-libuv docs\n. I don't like when READMEs have a lot of shields -- it's hard to see the really important ones.  Let's keep the current shields (2) as is, and provide a link to the docs site.\n. Does embedsignaturework for you? I couldn't make inspect.signature produce anything meaningful for Loop methods :(\n. uvloop only needs Cython for manual builds. If you install it from PyPI -- only Python 3.5 is needed.\n. Again, this is only relevant for dev builds. And I think I'll add a requirements.txt file, and maybe add a make target to setup the dev venv.\n. Ah, I see you've added the requirements.txt file. I think we only need requirements.dev.txt. Please use pip freeze to list concrete deps versions.\n. Would be nice to have a link to the blog post here.\n. I'd recommend to use py.test for individual tests -- that's what I'm myself using.  For example:\n$ PYTHONPATH=. py.test -k test_signals_sigint_uvcode\n. I'd also add that we consider any deviation from asyncio behaviour as a bug.\n. We don't need this file\n. Let's just copy the shields code from README.rst. No need to center them.\n. I'd rephrase to:\nThis section of the documentation provides information about \nhow to use uvloop.\n. Can we remove all the commented code etc?\n. Let's add a note about pip -e .\n. Again, pip -e solves the PYTHONPATH problem.\n. I don't think we need to go into too much detail here... Let's keep the docs as concise as possible ;)\n. Let's specify the min required versions of Cython and sphinx here.\n. Maybe we don't need this Makefile?  Would it be possible to just call sphinx directly (using python -m sphinx) from the uvloop/Makefile?\n. This line is too long.\n. Can you also add this snippet of code here, to support Mac OS X + macports:\npython\n            if sys.platform == 'darwin' and \\\n                    os.path.exists('/opt/local/include'):\n                # Support macports on Mac OS X.\n                self.compiler.add_include_dir('/opt/local/include')\n. I've tested it ;)\n. Actually, the else is important here.\n. This is weird. Which version of pip did it upgrade to?. They seem to have \"3.7-dev\". Wouldn't that be enough?. Ideally I'd like to avoid using docker for running our tests, it would slow the CI down way too much.. I don't like this \"tests\" import. Just move/copy the necessary functions to uvloop._testbase.. We need to keep del asyncio. Otherwise uvloop would hold refs to Tasks longer than necessary (that's Cython's fault and these dels are a workaround).\nYou can use getattr:\ncython\ncdef aio_debug_wrapper = getattr(asyncio.coroutines, 'debug_wrapper', None)\nAnd just check if it's not None before you call it.. They should always be available, just raise NotImplementedError in 3.6/3.5.. Please use explicit is None checks.. This line seems out of place.. Seems that Cirrus CI is just a couple of days old. We'll wait until it's mature before spending any time trying to integrate it.. Drop \"wheels,release\" from BUILD.. Drop branches. Drop services. It's the same for other versions. There's only one target with BUILD=tests,wheels,release (3.5) which builds the wheels and releases them.  All other targets (except macos) only run tests.  So 3.7 linux target should also just run tests.. Eh, we needed to keep env: BUILD=tests. Never mind, I'll make a PR myself.. Maybe from OpenSSL import SSL as open_ssl? :)  To make it obvious where OpenSSL is really used.. Wow, you're brave! :). I'd call it SSLProtocolState. And maybe we don't need the leading _?. Can you put this function elsewhere and call it from UVBaseTransport._set_write_buffer_limits()?. Would it be a good idea to make this a cdef class? We don't need too many methods from asyncio.Transport (and working isinstance(ssl_proto_transport, asyncio.Transport) is not a requirement.\nIf we make this an extension class you won't need <SSLProtocol> casts.. Can we prefix it with _test_?. I think I reimplemented most of FlowControlMixin in UVBaseTransport. We might be able to reuse it somehow (but if it's not obvious let's not do that and keep things as is).. Maybe we should explore this in a separate PR after this one lands.. python\nself._buffer = bytearray(256 * 1024)\nself.buffer = memoryview(self._buffer). Ah, right :)\nWe'll need to add a new API to asyncio 3.8 to tell us when a write() has completed so that we can re-use the buffer.. Wow, we need to backport this fix to CPython. Care to submit a PR?. ditto. Can we rename this to FATAL_SSL_ERROR_IGNORE. We set self._app_transport = None in connection_lost.  I'm a bit worried that we might end up in a situation (accidentally or while debugging/refactoring) where we create _SSLProtocolTransport more than once for one protocol.  Thoughts?. Yeah, feel free to add one.. Better to simply skip this test under 3.5.. Can you try to make it a standalone function (not a method)?  That way the cache will be shared across different transports.. Hmm, can you explain why in the commit message?. I'm OK to wait for the amended commit a bit.  We can release 0.12.1 tomorrow then, if the memory leak issue is fixed!. I think we can try calling sock.detach() and skipping this line.  There's no point in keeping the reference to the original socket here.  Hopefully that will fix the warning you saw.. It's not about the platform having SO_REUSEADDR or not, its about it behaving quite differently on Windows.  Coincidentally there's a relevant discussion about this option here: https://github.com/python/cpython/pull/11784#discussion_r254843057 if you are interested in what's going on.\nRegarding has_SO_REUSEADDR -- I'd just inline this check to create_server().. It is, but IPV6_V6ONLY might be missing on some platforms.  So you probably want to add two constants: has_IPV6_ONLY = hasattr(socket, 'IPV6_V6ONLY') and IPV6_V6ONLY = getattr(socket, 'IPV6_V6ONLY', -1). Context: this whole ugly file is the result of Cython not cleaning up its PyModules properly.  That lead to circular references that prevented uvloop ResourceWarnings from showing (say about an event loop that the user forgot to properly close).  So this file is a workaround for that bug -- it references stuff from the stdlib without keeping references to Python modules.\nNow this Cython shortcoming has been fixed in some recent Cython release, so we probably can start importing things properly. It's something for us to check later.. (warning: the linked discussion is a bit... \"inflammatory\" \ud83e\udd28). just add os_name = os.name and sys_platform = sys.platform to uvloop/includes/stdlib.pxi.  We'll later than be able to use search/replace to remove that file.. No, it's the same. It's just an inconsistency that we'll want to fix at some point.  Initially my idea was to use Python constants for Python objects/APIs and uv.* constants for libuv, but I guess it's actually more confusing this way.. Everything looks great. One last nit: please make sure all lines are shorter than 80 chars.. Sure: https://github.com/MagicStack/uvloop/pull/229 :). Speaking of which, let's land https://github.com/MagicStack/uvloop/pull/229 first and then rebase this one.. Yeah, good catch! I've pushed a commit with a fix.. ",
    "pohmelie": "Great!\n. @1st1 hm, if so, is there any profit of use libuv for file io?\n. @1st1 sounds right. And I answer my question: this will be the only solution (with nice syntax of course), since AFAIK there is no async filesystem library in python except aiofiles (but this have no path operations).\nThanks for great project! :+1: \n. ",
    "GMLudo": "For my information, behind the scenes, it uses what on Linux? Threads?\n. @saghul: a filesystem stored on a slow SAN because it's overloaded, could also be considered as a long running blocking operation like serial, or not?\n. +10\nI'll test that as soon as possible.\nPing @methane ;-)\n. to my knowledge, trollius is deprecated.\nI don't know your codebase, however, it should less \"dangerous\" / more stable way to migrate first your source code to python 3 with tornado.\n. ",
    "saghul": "FWIW, the current builtin threadpool just has 4 threads.\n. So far it has been... unless you use it for long running blocking operations like talking to serial devices. We have plans to improve it, but no real ETA.\n. Yep.\n. On linux we do most of the syscalls manually, so as long as you have a recent kernel we'll use the new stuff.\n. No worries Yuri. I don't think we'd do that. See the comment before the unlink, it prevents a race.\nAlternatively, you can create a UNIX socket with the Python socket module and use uv_pipe_open, that way the path won't be unlinked because libuv doesn't store it.\n. @1st1 that would break the ABI so it would have to wait for v2 if it gets accepted. Feel free to open an issue to kickstart the discussion!\n. > I suspect that there is a lock or something that breaks on fork() + starting a new event loop in the forked process.\nThis is the case, yes. The threadpool has some global state which needs to be adjusted in the child. Since uv_getaddrinfo runs on the threadpool it will fail. Basically using any loop before fork() and trying to use them (or a new one) is not currently supported.\nThere is, however, a pull request which addresses this: https://github.com/libuv/libuv/pull/846 more eyes are always welcome!\n\nStart using Python's getaddrinfo in a Python threadpool.\n\nYou might want to do this for another reason though: Python's getaddrinfo is not quite like getaddrinfo(3), it makes some normalizations and other stuff I no longer remember but it might be a good idea to use it, for consistency.\n. > I've seen that PR, it looks good to me (I spent quite a bit of time looking and playing with libuv internals). But I'm not a core libuv committer to say the LGTM :)\nIf you don't mind, please leave a comment, it helps.\n\nAll that code would be useful for c-ares or getdns though.\n\nI'm not sure about that. c-ares does not implement getaddrinfo, and I don't know about getdns. You can make shim using A and AAAA queries, but mimicking the system getaddrinfo will be tricky.\n. @1st1 thanks! I can't really give an estimate, it's a (relatively) big change, so we are cautious.\n. @jlaine I think https://github.com/libuv/libuv/pull/1872#issuecomment-464080195 is indeed it. . ",
    "sametmax": "I just wanted to test it here to report failing test, hoping it would help you since I like the project. If you think it's too early for that, I can do that when the project is more mature. I don't want to add noise.\nAfter installing cython, I could run the test and good news:\n```\n$ make test\nPYTHONASYNCIODEBUG=1 python3 -m unittest discover -s tests\n.................................................\n\nRan 49 tests in 13.877s\nOK\npython3 -m unittest discover -s tests\n.................................................\n\nRan 49 tests in 1.992s\nOK\n```\nLet me know if you need me test more stuff :)\n. Just pinging to get some news on the project. Again, if you need me to run tests on some machines, let me know.\n. All tests pass on my machine (Ubuntu 14.04, Python 3.5 64b):\n```\n$ make test\nPYTHONASYNCIODEBUG=1 python -m unittest discover -s tests\n............................................................................................................................................................................\n\nRan 172 tests in 34.116s\nOK\npython -m unittest discover -s tests\n............................................................................................................................................................................\n\nRan 172 tests in 24.181s\nOK\n```\nIt's really, really sweet. \nI have a project using asyncio, and most unit tests are passing with uvloop too, so I'm thinking adding it as an optional dependency.\nCurrently the tests not passing are linked to the way we customize error handling. Errors like \"AttributeError: '_Loop' object has no attribute '_exception_handler'\". \nOn one hand, we kinda deserve it, since we are clearly access a private attribute. On the other hand, the way asyncio handles errors really need some customization to be usable, so we wrap it into a coherent API, and it breaks with uvloop. I'm wondering if we should detect uvloop running, and handle errors differently with it. But that would need create a whole separate code for handling sigterm, a fail fast debug mode, etc.\nAnyway, thanks a lot for this work, the async story on Python is starting to look very good.\n. It would help us with this issue, since to set the exception handler we use the public set_exception_handler(), but there is not such thing as get_exception_handler in asyncio's API.\nBut maybe that's the wrong road. Maybe I should open a ticket to get get_exeption_handler added to the API, the you go add this official API as well instead of copying something that is meant to be internal.\nAll in all, our project is not a big deal to anybody yet, so I don't want to make you feel like you need to spend time on this unless some other projects have a similar issue. I'm just raising it so that you can increment the counter in your head of people reporting the problem :)\n. ",
    "zet4": "What's stopping you from porting your apps to 3.5+ instead?\n. ",
    "breerly": "Tornado has a asyncio bridge though.\nhttp://www.tornadoweb.org/en/stable/asyncio.html\n\nOn May 4, 2016, at 12:37 PM, Aleksandr Tihomirov notifications@github.com wrote:\nWhat's stopping you from porting your apps to 3.5+ instead?\n\u2015\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\n. > asyncio requires at least 3.3\n\nThat's right. I'm going to play with uvloop, tornado, & trollius (asyncio to 2.7 port).\nWill followup.\n. Fair point, thanks\n. ",
    "schlamar": "@breerly Have you seen https://github.com/saghul/tornaduv\n. Libuv already provides a platform agnostic interface to signals and sockets (e.g. http://docs.libuv.org/en/v1.x/signal.html). You shouldn't have to deal with the Windows API at all. \n. ",
    "digitaldavenyc": "Also having an issue install on OSX\nWhen running $ make I receive this error.\nsubprocess.CalledProcessError: Command '['/bin/sh', 'autogen.sh']' returned non-zero exit status 127\nmake: *** [compile] Error 1\nI tried installing libtool as well but the error still persists. If there are libraries required for OSX install, I think a README update would be helpful.\n. @dabeaz glibtoolize already exists, probably from installing libtool\n. Perhaps I already had it install from another application. Doesn't fix the issue for me either way...\n. @1st1 I've tried both pip and manually and they both return the same error above\n. (env)LOSX-339619-DM-N:uvloop digitaldave$ make\nrm -fr dist/\nrm -fr uvloop/*.c uvloop/*.html uvloop/*.so build *.egg-info\nrm -fr uvloop/handles/*.html uvloop/includes/*.html\nfind . -name '__pycache__' | xargs rm -rf\necho \"DEF DEBUG = 0\" > uvloop/__debug.pxi\ncython -3 uvloop/loop.pyx; rm uvloop/__debug.*\n/bin/sh: cython: command not found\npython setup.py build_ext --inplace\nrunning build_ext\nautogen.sh: line 28: automake: command not found\nautogen.sh: line 33: test: : integer expression expected\nautogen.sh: line 34: test: : integer expression expected\n+ glibtoolize --copy\n+ aclocal -I m4\nautogen.sh: line 44: aclocal: command not found\nTraceback (most recent call last):\n  File \"setup.py\", line 74, in <module>\n    include_package_data=True\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 955, in run_commands\n    self.run_command(cmd)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/lib/python3.5/site-packages/setuptools/command/build_ext.py\", line 49, in run\n    _build_ext.run(self)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py\", line 338, in run\n    self.build_extensions()\n  File \"setup.py\", line 38, in build_extensions\n    self.build_libuv()\n  File \"setup.py\", line 31, in build_libuv\n    check=True)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 711, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['/bin/sh', 'autogen.sh']' returned non-zero exit status 127\nmake: *** [compile] Error 1\n. ```\n(env)LOSX-339619-DM-N:uvloop digitaldave$ pip install uvloop\nCollecting uvloop\n  Using cached uvloop-0.4.11.tar.gz\nBuilding wheels for collected packages: uvloop\n  Running setup.py bdist_wheel for uvloop ... error\n  Complete output from command /Volumes/Data/Users/dpadovano/.virtualenvs/tran/bin/python3.5 -u -c \"import setuptools, tokenize;file='/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" bdist_wheel -d /var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/tmpuuvyv4topip-wheel- --python-tag cp35:\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build/lib.macosx-10.10-x86_64-3.5\n  creating build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/init.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/_testbase.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  running egg_info\n  writing dependency_links to uvloop.egg-info/dependency_links.txt\n  writing top-level names to uvloop.egg-info/top_level.txt\n  writing uvloop.egg-info/PKG-INFO\n  warning: manifest_maker: standard file '-c' not found\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\n  reading manifest template 'MANIFEST.in'\n  writing manifest file 'uvloop.egg-info/SOURCES.txt'\n  copying uvloop/cbhandles.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/cbhandles.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/dns.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/errors.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/loop.c -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/loop.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/loop.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/os_signal.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/os_signal.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/request.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/request.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/server.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  copying uvloop/server.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n  creating build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/async_.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/async_.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/basetransport.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/basetransport.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/handle.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/handle.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/idle.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/idle.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/pipe.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/pipe.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/poll.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/poll.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/process.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/process.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/signal.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/signal.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/stream.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/stream.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/streamserver.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/streamserver.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/tcp.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/tcp.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/timer.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/timer.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/udp.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/udp.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\n  creating build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/init.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/consts.pxi -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/python.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/stdlib.pxi -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/system.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/uv.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\n  running build_ext\n  autogen.sh: line 28: automake: command not found\n  autogen.sh: line 33: test: : integer expression expected\n  autogen.sh: line 34: test: : integer expression expected\n  + glibtoolize --copy\n  glibtoolize: putting auxiliary files in '.'.\n  glibtoolize: copying file './ltmain.sh'\n  glibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\n  glibtoolize: copying file 'm4/libtool.m4'\n  glibtoolize: copying file 'm4/ltoptions.m4'\n  glibtoolize: copying file 'm4/ltsugar.m4'\n  glibtoolize: copying file 'm4/ltversion.m4'\n  glibtoolize: copying file 'm4/lt~obsolete.m4'\n  + aclocal -I m4\n  autogen.sh: line 44: aclocal: command not found\n  Traceback (most recent call last):\n    File \"\", line 1, in \n    File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 74, in \n      include_package_data=True\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/core.py\", line 148, in setup\n      dist.run_commands()\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 955, in run_commands\n      self.run_command(cmd)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/lib/python3.5/site-packages/wheel/bdist_wheel.py\", line 175, in run\n      self.run_command('build')\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n      self.distribution.run_command(command)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build.py\", line 135, in run\n      self.run_command(cmd_name)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n      self.distribution.run_command(command)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/lib/python3.5/site-packages/setuptools/command/build_ext.py\", line 49, in run\n      _build_ext.run(self)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py\", line 338, in run\n      self.build_extensions()\n    File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 38, in build_extensions\n      self.build_libuv()\n    File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 31, in build_libuv\n      check=True)\n    File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 711, in run\n      output=stdout, stderr=stderr)\n  subprocess.CalledProcessError: Command '['/bin/sh', 'autogen.sh']' returned non-zero exit status 127\n\nFailed building wheel for uvloop\n  Running setup.py clean for uvloop\nFailed to build uvloop\nInstalling collected packages: uvloop\n  Running setup.py install for uvloop ... error\n    Complete output from command /Volumes/Data/Users/dpadovano/.virtualenvs/tran/bin/python3.5 -u -c \"import setuptools, tokenize;file='/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" install --record /var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-76evy8ep-record/install-record.txt --single-version-externally-managed --compile --install-headers /Volumes/Data/Users/dpadovano/.virtualenvs/tran/bin/../include/site/python3.5/uvloop:\n    running install\n    running build\n    running build_py\n    creating build\n    creating build/lib.macosx-10.10-x86_64-3.5\n    creating build/lib.macosx-10.10-x86_64-3.5/uvloop\n    copying uvloop/init.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n    copying uvloop/_testbase.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop\n    running egg_info\n    writing dependency_links to uvloop.egg-info/dependency_links.txt\n    writing uvloop.egg-info/PKG-INFO\n    writing top-level names to uvloop.egg-info/top_level.txt\n    warning: manifest_maker: standard file '-c' not found\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwriting manifest file 'uvloop.egg-info/SOURCES.txt'\ncopying uvloop/cbhandles.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/cbhandles.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/dns.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/errors.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/loop.c -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/loop.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/loop.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/os_signal.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/os_signal.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/request.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/request.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/server.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncopying uvloop/server.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop\ncreating build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/async_.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/async_.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/basetransport.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/basetransport.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/handle.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/handle.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/idle.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/idle.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/pipe.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/pipe.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/poll.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/poll.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/process.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/process.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/signal.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/signal.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/stream.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/stream.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/streamserver.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/streamserver.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/tcp.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/tcp.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/timer.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/timer.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/udp.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncopying uvloop/handles/udp.pyx -> build/lib.macosx-10.10-x86_64-3.5/uvloop/handles\ncreating build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/__init__.py -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/consts.pxi -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/python.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/stdlib.pxi -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/system.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\ncopying uvloop/includes/uv.pxd -> build/lib.macosx-10.10-x86_64-3.5/uvloop/includes\nrunning build_ext\nautogen.sh: line 28: automake: command not found\nautogen.sh: line 33: test: : integer expression expected\nautogen.sh: line 34: test: : integer expression expected\n+ glibtoolize --copy\n+ aclocal -I m4\nautogen.sh: line 44: aclocal: command not found\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 74, in <module>\n    include_package_data=True\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 955, in run_commands\n    self.run_command(cmd)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/lib/python3.5/site-packages/setuptools/command/install.py\", line 61, in run\n    return orig.install.run(self)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/install.py\", line 539, in run\n    self.run_command('build')\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build.py\", line 135, in run\n    self.run_command(cmd_name)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/lib/python3.5/site-packages/setuptools/command/build_ext.py\", line 49, in run\n    _build_ext.run(self)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/distutils/command/build_ext.py\", line 338, in run\n    self.build_extensions()\n  File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 38, in build_extensions\n    self.build_libuv()\n  File \"/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py\", line 31, in build_libuv\n    check=True)\n  File \"/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/subprocess.py\", line 711, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['/bin/sh', 'autogen.sh']' returned non-zero exit status 127\n\n----------------------------------------\n\nCommand \"/Volumes/Data/Users/dpadovano/.virtualenvs/tran/bin/python3.5 -u -c \"import setuptools, tokenize;file='/private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" install --record /var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-76evy8ep-record/install-record.txt --single-version-externally-managed --compile --install-headers /Volumes/Data/Users/dpadovano/.virtualenvs/tran/bin/../include/site/python3.5/uvloop\" failed with error code 1 in /private/var/folders/lm/p6m9r8350k9c5my6ggm13dvcfkrtj7/T/pip-build-8vb__f85/uvloop/\n```\n. @1st1 Full output of both methods included if this helps at all\n. @dabeaz That did it!\n. @1st1 Should the updated uvloop 0.4.12 include the packages?\n. Ok thanks. I'm going to try this on a different OSX machine tonight to confirm. \n. I think you'll have to ... the public is not able to reopen issues on this repo. But I'll certainly throw a message out if there is an issue.\n. > I highly recommend you to glance over the documentation.\nDo you mean I should review uvloop's documention or asyncio's?\n\nYou need other libraries built for asyncio to do that for you. For HTTP, right now, there is aiohttp.\n\nIn your blog post you mentioned that the performance in aiohttp was pretty bad with uvloop due to aiohttp's HTTP parser. Wouldn't httptools be the prefered library for handing HTTP requests in order to maintain the performance measured in the benchmarks?\n. There was already an issue open over at aiohttp for swapping out the http parser for httptools. If the performance issues could be solved in the near future both libraries could be thrown into the spotlight. Being able to stay on the same performance level with Go is huge. Thank you so much for contributing this library to the community!\n. ",
    "dabeaz": "sudo ln -s /usr/local/bin/libtoolize /usr/local/bin/glibtoolize\n. That, I don't know.  I didn't get glibtoolize from installing libtool.  Adding the symlink fixed it.  uvloop seems to work on OSX. \n. It's complaining about automake not being installed.   I had to install recent versions of autoconf, automake, and libtool to get uvloop to build. After that, 'pip' installing it worked. \n. ",
    "claws": "Thanks.\nYeah, that line comes from my framework code. I forgot to take it out of the short example. I use it to ensure that the correct policy (the one I set in the framework imports) is invoked without needing to explicitly call set_event_loop_policy. Its purely a convenience action that reduces some boilerplate code in our environment. Many of our unit tests begin with a asyncio.set_event_loop_policy(None) to ensure a clean starting point.\n. Unfortunately not. It is developed for a client. Perhaps one day.\n. Hmmm, I got into a bit of a state with the branch trying to rebase recent updates. I'm not exactly sure what happened but it just looks a mess now. I think I might create a new branch, copy in the appropriate changes and re-submit the pull request under a different PR.\n. Your suggestion certainly looks like it would help in the use case that caused me to raise this PR. A minor clarification; I found that I had to use pip install -e ..\nIt seems a little uncommon (admittedly there is variability between projects) to have pure test utils in the main package. My thought space on this topic is reducing the barrier to entry for any potential future contributors. What was the reason for putting some test utilities in the main uvloop package? \nIt might be worth putting a note somewhere (perhaps in _testbase.py) about your design decision regarding this aspect. I can foresee future contributors wondering why test utils are in the main package and making the same suggestion I have.\n. Yeah I was thinking of asyncio when I mentioned test utils variability.\nOK, I'll close this out then.\n. I think that this addresses all the review comments.\n- removed the loop.pyx comments update to a separate PR.\n- loop.pyx now contains just the Sphinx related change supporting docs.\n- same shields as README\n- updated user doc with suggested re-write.\n- trimmed Sphinx conf.py to minimal content (removed commented out stuff)\n- added reference to using pip install -e . instead of using PYTHONPATH.\n- trimmed testing section\n- trimmed the docs section as suggested.\n- updated requirements.txt with package versions\n- Removed Sphinx Makefile with a call in from the main Makefile directly to\n  the sphinx-build call.\n. Added it down in the tests section.\n. Done\n. Back to two shields.\n. ",
    "brickgao": "@1st1 Hi, I'm interested in implementing this proposal, is anyone already working on it ;)?\n. @1st1 I have a little trouble porting posix.signal to Windows in https://github.com/MagicStack/uvloop/blob/master/uvloop/os_signal.pyx#L1 . I could not find a good way to implement it because of the difference in signal between Windows and nix. Could you please give me some advice?\n. @1st1 Sure, I find that there isn't a quick way to port uvloop with the native Windows API. I would try to port uvloop with Cygwin these days first, cuz I find Cygwin provide most of the NIX API on Windows.\n. @1st1 I find that Cygwin haven't provided Python3.5 officially :(, so we should work on it with the native Windows API again. Maybe we should find more people to look into this problem.\nThere are two major parts we need to port, socket and signal.\nFor socket, most of socket functions could be easy to ported by changing the header file, but Windows don't provide socketpair. Referring to https://github.com/ncm/selectable-socketpair and https://github.com/python/cpython/blob/c6ae2fcc724cbebb14e7c434b89eabdd64802cb3/Lib/asyncio/windows_utils.py#L37, it's possible to implement a socketpair that support AF_INET and AF_INET6, but it doesn't support AF_UNIX.\nFor signal, Windows provides a function signal(https://msdn.microsoft.com/en-us/library/xdkz3x12.aspx) to change the handlers of specific signal, but it doesn't provide the function to get the current handler of specific signal and it also doesn't provide sigfillset.\n. Some workarounds to the signal based on @iceb0y 's commits: https://github.com/brickgao/uvloop/commit/eb9b9b7881fb1950e61033c3ba3934daf0a0c7e0\n. ",
    "iceb0y": "Had a quick hack to make it buildable in windows (win7, python 3.5.2 x64): https://github.com/iceb0y/uvloop/commit/fa2b7db1d7940149bb8d16e856e7d1a642f3e6b8\nbuild snippet:\nin /vendor/libuv, use python2\nvcbuild.bat x64 release\nin /, use python3, do the same as makefile\ncython -3 -a -p uvloop/loop.pyx\npython setup.py build_ext --inplace\nHad a test with aiohttp server - the current stucking problem is that uvloop uses os_dup in multiple places to duplicate UVSocketHandle._fileno, where os_dup = os.dup and it duplicates posix file handles. In windows, posix file handle is implemented as an additional layer on NT handles where the handle numbers are not equal. I workaround this problem and aiohttp server works.\nNotice that os_dup is also used to duplicate posix handle in uvloop/loop.pyx and uvloop/handles/process.pyx. So we need to differentiate between this two kinds of dups. Also note that duplicating socket handles in windows is fragile (see http://bugs.python.org/issue14522). If we can share socket by sharing handle objects instead of duplicating OS handles, we can resolve this problem and avoid the dup system call.\n. dup is introduced in 6e9c43bdecfad711c38c423fbada8fd8b86ddf7f\nmaybe we need to find another way to solve the problem described by the commit?\n. Sharing handle objects seems not working. uv still complains Assertion failed: (loop->watchers[w->fd] == w), function uv__io_stop, file src/unix/core.c, line 888.\nChanging socket.socket to socket.fromfd, which uses _socket.dup which has special implementation for windows, without dup just works (tested in osx and windows). But I still feel a little strange to duplicate a socket handle.\nWhat do you plan for dup?\n. > Some workarounds to the signal based on @iceb0y 's commits: brickgao@eb9b9b7\n@1st1 I think the windows signal code is actually platform-independent\n1. Is it correct?\n2. Should we just use it for all platforms for simplification?\n. tested on windows - the signal handling code doesn't work on windows, probably due to usage of socketpair.\nLoop._setup_signals -> Loop._add_reader -> UVPoll.new -> UVPoll._init -> uv.uv_poll_init -> OSError: [Errno 4050] Unknown error.\nWhy does signal handling use a socketpair which seems to post notification to the loop?\n. I'm playing with a HTTP server called h2o which supports to be used as a library and I'm trying to make a python binding for it (just for fun now - if it could be done, we can get a super high performance HTTP server). The server supports its own event loop and also uv loop. It'll be nice if we could make python bindings of these kind of libraries which share a single event loop.\n. > What if you explicitly close the transport?\nThen it doesn't leak. However the default loop doesn't leak even if the transport not explicitly closed.. Linux Mint 18.1 Serena\nLinux 4.4.0-53-generic 64bit\nPython 3.5.2 64bit\nuvloop 0.8.0. Tested on Linux 3.13 and 4.8, and Python 3.6 - they all leak.. ",
    "asvetlov": "@1st1 I've fixed sendfile support on aiohttp master.\nFunny fact: on travis dupped socket was in blocking mode.\nHonestly I've not dug into but had added just socket.setblocking(False) call.\n. > > Funny fact: on travis dupped socket was in blocking mode.\n\nWow. Maybe this is something worth investigating? Is it something that asyncio causes?\n\n@1st1 I cannot reproduce the problem locally. The only error what I have is travis report: https://travis-ci.org/KeepSafe/aiohttp/builds/157838616\nSomething like this:\nresp = yield from sender().send(request, filepath)\n  File \"/opt/python/3.5.0/lib/python3.5/asyncio/coroutines.py\", line 105, in __next__\n    return self.gen.send(None)\n  File \"/home/travis/build/KeepSafe/aiohttp/aiohttp/file_sender.py\", line 148, in send\n    yield from self._sendfile(request, resp, f, file_size)\n  File \"/opt/python/3.5.0/lib/python3.5/asyncio/coroutines.py\", line 105, in __next__\n    return self.gen.send(None)\n  File \"/home/travis/build/KeepSafe/aiohttp/aiohttp/file_sender.py\", line 86, in _sendfile_system\n    ''.join(headers).encode('utf-8'))\n  File \"uvloop/loop.pyx\", line 1831, in sock_sendall (uvloop/loop.c:29654)\nValueError: the socket must be non-blocking\nsock.setblocking(False) has solved the problem.\nI have no Idea why it works with some configurations but fails with others.\n. Please no.\nKeep private API really private.\n. aiohttp 1.0 uses c-ares by default if aiodns is installed.\n. @WGH- \nHonestly I don't know how these tools are widespread.\nLet's look on users feedback.\n. There is KeepSafe/aiohttp#1093 issue.\nIt's still not fixed but very reproducible.\nI think aiohttp sends headers into transport's buffer but sendfile sends a content directly through the wire, that's why headers are sent too late.\n. @1st1 please close the issue as  KeepSafe/aiohttp#1093 is resolved.\n. @1st1 just after fixing bugs with cookiejar.\nIn a few days I hope.\n. Sorry, CORK is shared.\n. To achieve it uvloop should only expose uv_loop_t instance, isn't it?\n. At least it doesn't brings any harm.\n@1st1 I think you may just merge it.\n. Hrrr.\nYou are creating a global var here (class variable actually).\nIt is anti-pattern with very bad smell.. I believe the issue is not related to uvloop. \nRaise the question on sanic's bugtracker.. You could skip encoding by sending host parameter as bytes, isn't it?. Works for me.\nFeel free to close the issue.. Have observed the same problem in our production code.\nSurprisingly plain aiohttp example (without our straightforward but complex tooling built on top of aiohttp session) worked fine.\nI was unable to pin down the minimal reproducible test case unfortunately.. Theoretically, we can modify asyncio abstract classes to be real ABCs like collection.abc.\n@1st1 do you think it makes sense?. No, I'm thinking mainly about introspection. \nAbstract base classes from collections are also slow, but I found them very useful.\nAt least I always derive from proper ABC when developing a new data structure class.\nPerhaps correct class hierarchy is something that would be nice to have.. I bet @alpha-86 creates asyncio.Event() in module global scope before installing uvloop.. IMHO Python never states it.\nBut very many distros (not all) have __version__ attribute in top level package.. IPv6 address?. @benjolitz your \"custom executor\" doesn't follow executor's contract.\nThe executor should accept a function (any callable with __call__ method technically) and args and call it in a separate thread/process.\nCalling a coroutine in an executor doesn't make sense.\nasyncio was not designed in this way from the very beginning (but had no sanity check for the case).\nEventually, we've added the check (as well as many other sanity checks in asyncio API) to help users avoid silly errors.\nIn asyncio itself checks are not for free, that's why they are applied in debug mode only very often.\nYou've tried to break the contract and shoot your leg, that's sad.. Please build python from github master.\nDocker image is:\n1. Obsolete a little\n2. Has stripped test package.. Huge improvement! Thanks!. ",
    "martmists": "For those on windows 10, I believe you can use bash on ubuntu and install uvloop on there for now, or at least that seems to have worked for me.. ",
    "aiportal": "Is it support \"Bash on Ubuntu on Windows\"?\nIt's running on Windows Subsystem for Linux\uff08WSL\uff09\u3002. ",
    "fyears": "A side note on 2017/02/16 for those who are interested later.\nI come across these issues today (actually I want to install sanic), and try the latest windows branch commit https://github.com/MagicStack/uvloop/commit/3c741b4c27fec94569ff8c65222e4f314cf44079.\nI git clone the repo and try to python setup.py install. I meet an error complaining python 2.7 not found because of https://github.com/MagicStack/uvloop/blob/win/setup.py#L227. (It's ironical because uvloop is designed for Python 3.5 +.) Python 2.7 is required for gyp, so I installed Python 2.7 and manually change that line to hard code my Python 2.7 path.\nAfter that, I could successfully build and import uvloop! And the hello world of sanic works, too.\nI also run the tests/. These tests failed:\ntext\ntest_dns.py\ntest_sockets.py\ntest_tcp.py\ntest_udp.py\n. ",
    "tritium21": "Bash on Windows is Windows Subsystem for Linux.  You are not running a windows executable, you are quite literally running (at the time of your post) Ubuntu 14.04 x86-64.  WSL is not a production tool, it exists to let windows based developers write binaries that will be deployed on real ubuntu 14.04 (and now 16.04) machines.\nWSL runs real linux binaries on the windows kernel ... unreliably.  It's not a real solution to running on windows.. ",
    "matpow2": "What is the status on this?. ",
    "luckcolors": "@1st1 Hey, i've noticed that in the PR you refer to an uvloop PR wich has been merged. (well you actually refer to one that then refers to the one i've linked) https://github.com/libuv/libuv/pull/1447\nCould you check if working on this issue can proceed? :). ",
    "floqqi": "@1st1 @luckcolors would be interesting for me, too! Any chance? Would be great to see frameworks like Sanic working on Windows :). ",
    "aknaebel": "Some project like uvicorn (https://github.com/encode/uvicorn) use uvloop and cannot be used on windows which is very restrictive. ",
    "dakyri": "Yuri, what's the state of play with getting the windows port  working? I might be interested getting this done (I have a use case for it) ... at least as one contributor. I've worked with libuv in c/c++, so I know my way around that. Any idea how much work would be invoved time wise to get something functional?. Cool! That sounds like it's viable or close enough for me as it stands already, but I'll be happy to pick up the ball and contribute moving forwards.. ",
    "matemax": "@1st1 ,can you merge master into win branch?. No, but our project is using uvloop and python 3.6. I am going to make it cross-platform.\u00a0. I tried to instal branch 'win' and got folowing errors. \n\nFailed build\n warning: uvloop\\handles/stream.pyx:318:8: Unreachable code\n    warning: uvloop\\loop.pyx:2750:4: Unreachable code\nError compiling Cython file:\n------------------------------------------------------------\n...\n            self._fatal_error(exc, True)\n            return\n\n        cdef:\n            int backend_id\n            system.epoll_event dummy_event\n           ^\n------------------------------------------------------------\n\nuvloop\\handles/poll.pyx:67:12: 'epoll_event' is not a type identifier\n\nError compiling Cython file:\n------------------------------------------------------------\n...\n\n        cdef:\n            int backend_id\n            system.epoll_event dummy_event\n\n        if system.PLATFORM_IS_LINUX:\n                ^\n------------------------------------------------------------\n\nuvloop\\handles/poll.pyx:69:17: cimported module has no attribute 'PLATFORM_IS_LINUX'\n\nError compiling Cython file:\n------------------------------------------------------------\n...\n            # after calling uv_poll_stop.\n\n            backend_id = uv.uv_backend_fd(self._loop.uvloop)\n            if backend_id != -1:\n                memset(&dummy_event, 0, sizeof(dummy_event))\n                system.epoll_ctl(\n                     ^\n------------------------------------------------------------\n\nuvloop\\handles/poll.pyx:82:22: cimported module has no attribute 'epoll_ctl'\n\nError compiling Cython file:\n------------------------------------------------------------\n...\n            backend_id = uv.uv_backend_fd(self._loop.uvloop)\n            if backend_id != -1:\n                memset(&dummy_event, 0, sizeof(dummy_event))\n                system.epoll_ctl(\n                    backend_id,\n                    system.EPOLL_CTL_DEL,\n                         ^\n------------------------------------------------------------\n\nuvloop\\handles/poll.pyx:84:26: cimported module has no attribute 'EPOLL_CTL_DEL'\n\nError compiling Cython file:\n------------------------------------------------------------\n...\n                    with open(self._errpipe_write, 'wb') as f:\n                        f.write(str(ex.__class__.__name__).encode())\n                        f.write(b':')\n                        f.write(str(ex.args[0]).encode())\n                finally:\n                    system._exit(255)\n                         ^\n------------------------------------------------------------\n\nuvloop\\handles/process.pyx:173:26: cimported module has no attribute '_exit'\n\nError compiling Cython file:\n------------------------------------------------------------\n...\n                    with open(self._errpipe_write, 'wb') as f:\n                        f.write(str(ex.__class__.__name__).encode())\n                        f.write(b':')\n                        f.write(str(ex.args[0]).encode())\n                finally:\n                    system._exit(255)\n                         ^\n------------------------------------------------------------\n\nuvloop\\handles/process.pyx:173:26: cimported module has no attribute '_exit'\n\nError compiling Cython file:\n------------------------------------------------------------\n...\ncdef __socketpair():\n    cdef:\n        int fds[2]\n        int err\n\n    err = system.socketpair(uv.AF_UNIX, uv.SOCK_STREAM, 0, fds)\n               ^\n------------------------------------------------------------\n\nuvloop\\handles/process.pyx:719:16: cimported module has no attribute 'socketpair'\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"C:\\Users\\Maxim\\AppData\\Local\\Temp\\pip-joj6i769-build\\setup.py\", line 370, in <module>\n    test_suite='tests.suite'\n  File \"c:\\python36\\lib\\distutils\\core.py\", line 148, in setup\n    dist.run_commands()\n  File \"c:\\python36\\lib\\distutils\\dist.py\", line 955, in run_commands\n    self.run_command(cmd)\n  File \"c:\\python36\\lib\\distutils\\dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\egg_info.py\", line 279, in run\n    self.find_sources()\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\egg_info.py\", line 306, in find_sources\n    mm.run()\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\egg_info.py\", line 533, in run\n    self.add_defaults()\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\egg_info.py\", line 562, in add_defaults\n    sdist.add_defaults(self)\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\py36compat.py\", line 36, in add_defaults\n    self._add_defaults_ext()\n  File \"c:\\python36\\lib\\site-packages\\setuptools\\command\\py36compat.py\", line 119, in _add_defaults_ext\n    build_ext = self.get_finalized_command('build_ext')\n  File \"c:\\python36\\lib\\distutils\\cmd.py\", line 299, in get_finalized_command\n    cmd_obj.ensure_finalized()\n  File \"c:\\python36\\lib\\distutils\\cmd.py\", line 107, in ensure_finalized\n    self.finalize_options()\n  File \"C:\\Users\\Maxim\\AppData\\Local\\Temp\\pip-joj6i769-build\\setup.py\", line 138, in finalize_options\n    annotate=self.cython_annotate)\n  File \"c:\\python36\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1039, in cythonize\n    cythonize_one(*args)\n  File \"c:\\python36\\lib\\site-packages\\Cython\\Build\\Dependencies.py\", line 1161, in cythonize_one\n    raise CompileError(None, pyx_file)\nCython.Compiler.Errors.CompileError: uvloop/loop.pyx\nuvloop/loop.pyx: cannot find cimported module '.includes'\nuvloop/loop.pxd: cannot find cimported module '.includes'\nCompiling uvloop/loop.pyx because it changed.\n[1/1] Cythonizing uvloop/loop.pyx\n\n----------------------------------------\n\nCommand \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\Maxim\\AppData\\Local\\Temp\\pip-joj6i769-build\\\n. ",
    "nsavelyeva": "Hi All,\nI'm looking forward to this feature, too. Respect and many thanks to all devs involved.\nI tried today 'pip install uvloop' on Windows 10 and it failed with RuntimeError: uvloop does not support Windows at the moment.\n. ",
    "AymanEG": "Hello from 2018 , good luck guys completing it :). ",
    "griimnak": "Good luck, windows support would still be appreciated . ",
    "ofek": "Any progress?. ",
    "tweakimp": "It would be helpful if it at least said in the readme that it currently has no Windows support.. ",
    "justinfay": "I have also experienced this error when trying to install from pypi with pip. I think this message may be pertinent to the install failure:\n```\nCDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/bash /home/justin/github/mver/env/build/uvloop/vendor/libuv/missing aclocal-1.15 -I m4\n/home/justin/github/mver/env/build/uvloop/vendor/libuv/missing: line 81: aclocal-1.15: command not found\nWARNING: 'aclocal-1.15' is missing on your system.\n     You should only need it if you modified 'acinclude.m4' or\n\n     'configure.ac' or m4 files included by 'configure.ac'.\n\n     The 'aclocal' program is part of the GNU Automake package:\n\n     <http://www.gnu.org/software/automake>\n\n     It also requires GNU Autoconf, GNU m4 and Perl in order to run:\n\n     <http://www.gnu.org/software/autoconf>\n\n     <http://www.gnu.org/software/m4/>\n\n     <http://www.perl.org/>\n\nmake: *** [aclocal.m4] Error 127\n```\nAs a workaround I cloned the repo from github, install cython and followed the instructions in the README and uvloop successfully installed.\n. @1st1 I can confirm that I successfully installed 0.4.21 using pip, below is some info from my system:\n\n(env)\u279c  uvl  cat /etc/lsb-release \nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=14.04\nDISTRIB_CODENAME=trusty\nDISTRIB_DESCRIPTION=\"Ubuntu 14.04.4 LTS\"\n(env)\u279c  uvl  pip --version\npip 1.5.4 from /home/justin/github/uvl/env/lib/python3.5/site-packages (python 3.5)\n(env)\u279c  uvl  pip freeze\nuvloop==0.4.21\n. \n",
    "ChillarAnand": "@1st1  Full log\n``` python\nCollecting uvloop\n  Using cached uvloop-0.4.16.tar.gz\nBuilding wheels for collected packages: uvloop\n  Running setup.py bdist_wheel for uvloop\n  Complete output from command /home/anand/.virtualenvs/35/bin/python3.5 -c \"import setuptools;file='/tmp/pip-build-tmzeiyue/uvloop/setup.py';exec(compile(open(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" bdist_wheel -d /tmp/tmpkclkg6qypip-wheel-:\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build/lib.linux-x86_64-3.5\n  creating build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/init.py -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/_testbase.py -> build/lib.linux-x86_64-3.5/uvloop\n  running egg_info\n  writing top-level names to uvloop.egg-info/top_level.txt\n  writing dependency_links to uvloop.egg-info/dependency_links.txt\n  writing uvloop.egg-info/PKG-INFO\n  warning: manifest_maker: standard file '-c' not found\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\n  reading manifest template 'MANIFEST.in'\n  warning: no previously-included files matching '' found under directory 'vendor/libuv/.git'\n  warning: no previously-included files matching '' found under directory 'vendor/libuv/docs'\n  warning: no previously-included files matching '*' found under directory 'vendor/libuv/img'\n  writing manifest file 'uvloop.egg-info/SOURCES.txt'\n  copying uvloop/cbhandles.pxd -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/cbhandles.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/dns.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/errors.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/loop.c -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/loop.pxd -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/loop.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/os_signal.pxd -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/os_signal.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/request.pxd -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/request.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/server.pxd -> build/lib.linux-x86_64-3.5/uvloop\n  copying uvloop/server.pyx -> build/lib.linux-x86_64-3.5/uvloop\n  creating build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/async_.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/async_.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/basetransport.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/basetransport.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/handle.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/handle.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/idle.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/idle.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/pipe.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/pipe.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/poll.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/poll.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/process.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/process.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/signal.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/signal.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/stream.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/stream.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/streamserver.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/streamserver.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/tcp.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/tcp.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/timer.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/timer.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/udp.pxd -> build/lib.linux-x86_64-3.5/uvloop/handles\n  copying uvloop/handles/udp.pyx -> build/lib.linux-x86_64-3.5/uvloop/handles\n  creating build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/init.py -> build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/consts.pxi -> build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/python.pxd -> build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/stdlib.pxi -> build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/system.pxd -> build/lib.linux-x86_64-3.5/uvloop/includes\n  copying uvloop/includes/uv.pxd -> build/lib.linux-x86_64-3.5/uvloop/includes\n  warning: build_py: byte-compiling is disabled, skipping.\nrunning build_ext\n  checking for a BSD-compatible install... /usr/bin/install -c\n  checking whether build environment is sane... yes\n  checking for a thread-safe mkdir -p... /bin/mkdir -p\n  checking for gawk... gawk\n  checking whether make sets $(MAKE)... yes\n  checking whether make supports nested variables... yes\n  checking build system type... x86_64-unknown-linux-gnu\n  checking host system type... x86_64-unknown-linux-gnu\n  checking for gcc... gcc\n  checking whether the C compiler works... yes\n  checking for C compiler default output file name... a.out\n  checking for suffix of executables...\n  checking whether we are cross compiling... no\n  checking for suffix of object files... o\n  checking whether we are using the GNU C compiler... yes\n  checking whether gcc accepts -g... yes\n  checking for gcc option to accept ISO C89... none needed\n  checking whether gcc understands -c and -o together... yes\n  checking for style of include used by make... GNU\n  checking dependency style of gcc... gcc3\n  checking if gcc supports -fvisibility=hidden flag... yes\n  checking if gcc supports -g flag... yes\n  checking if gcc supports -std=gnu89 flag... yes\n  checking if gcc supports -pedantic flag... yes\n  checking if gcc supports -Wall flag... yes\n  checking if gcc supports -Wextra flag... yes\n  checking if gcc supports -Wno-unused-parameter flag... yes\n  checking for ar... ar\n  checking the archiver (ar) interface... ar\n  checking how to print strings... printf\n  checking for a sed that does not truncate output... /bin/sed\n  checking for grep that handles long lines and -e... /bin/grep\n  checking for egrep... /bin/grep -E\n  checking for fgrep... /bin/grep -F\n  checking for ld used by gcc... /usr/bin/ld\n  checking if the linker (/usr/bin/ld) is GNU ld... yes\n  checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n  checking the name lister (/usr/bin/nm -B) interface... BSD nm\n  checking whether ln -s works... yes\n  checking the maximum length of command line arguments... 1572864\n  checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n  checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n  checking for /usr/bin/ld option to reload object files... -r\n  checking for objdump... objdump\n  checking how to recognize dependent libraries... pass_all\n  checking for dlltool... no\n  checking how to associate runtime and link libraries... printf %s\\n\n  checking for archiver @FILE support... @\n  checking for strip... strip\n  checking for ranlib... ranlib\n  checking command to parse /usr/bin/nm -B output from gcc object... ok\n  checking for sysroot... no\n  checking for a working dd... /bin/dd\n  checking how to truncate binary pipes... /bin/dd bs=4096 count=1\n  checking for mt... mt\n  checking if mt is a manifest tool... no\n  checking how to run the C preprocessor... gcc -E\n  checking for ANSI C header files... yes\n  checking for sys/types.h... yes\n  checking for sys/stat.h... yes\n  checking for stdlib.h... yes\n  checking for string.h... yes\n  checking for memory.h... yes\n  checking for strings.h... yes\n  checking for inttypes.h... yes\n  checking for stdint.h... yes\n  checking for unistd.h... yes\n  checking for dlfcn.h... yes\n  checking for objdir... .libs\n  checking if gcc supports -fno-rtti -fno-exceptions... no\n  checking for gcc option to produce PIC... -fPIC -DPIC\n  checking if gcc PIC flag -fPIC -DPIC works... yes\n  checking if gcc static flag -static works... yes\n  checking if gcc supports -c -o file.o... yes\n  checking if gcc supports -c -o file.o... (cached) yes\n  checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n  checking whether -lc should be explicitly linked in... no\n  checking dynamic linker characteristics... GNU/Linux ld.so\n  checking how to hardcode library paths into programs... immediate\n  checking whether stripping libraries is possible... yes\n  checking if libtool supports shared libraries... yes\n  checking whether to build shared libraries... yes\n  checking whether to build static libraries... yes\n  checking whether make supports nested variables... (cached) yes\n  checking for dlopen in -ldl... yes\n  checking for kstat_lookup in -lkstat... no\n  checking for kvm_open in -lkvm... no\n  checking for gethostbyname in -lnsl... yes\n  checking for perfstat_cpu in -lperfstat... no\n  checking for pthread_mutex_init in -lpthread... yes\n  checking for clock_gettime in -lrt... yes\n  checking for sendfile in -lsendfile... no\n  checking for socket in -lsocket... no\n  checking for special C compiler options needed for large files... no\n  checking for _FILE_OFFSET_BITS value needed for large files... no\n  checking sys/ahafs_evProds.h usability... no\n  checking sys/ahafs_evProds.h presence... no\n  checking for sys/ahafs_evProds.h... no\n  checking for pkg-config... yes\n  checking that generated files are newer than configure... done\n  configure: creating ./config.status\n  config.status: creating libuv.pc\n  config.status: creating Makefile\n  config.status: executing depfiles commands\n  config.status: executing libtool commands\n  CDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/bash /tmp/pip-build-tmzeiyue/uvloop/vendor/libuv/missing aclocal-1.15 -I m4\n  /tmp/pip-build-tmzeiyue/uvloop/vendor/libuv/missing: line 81: aclocal-1.15: command not found\n  WARNING: 'aclocal-1.15' is missing on your system.\n           You should only need it if you modified 'acinclude.m4' or\n           'configure.ac' or m4 files included by 'configure.ac'.\n           The 'aclocal' program is part of the GNU Automake package:\n           http://www.gnu.org/software/automake\n           It also requires GNU Autoconf, GNU m4 and Perl in order to run:\n           http://www.gnu.org/software/autoconf\nhttp://www.gnu.org/software/m4/\nhttp://www.perl.org/\n  make: *** [aclocal.m4] Error 127\n  Traceback (most recent call last):\n    File \"\", line 1, in \n    File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 100, in \n      include_package_data=True\n    File \"/usr/lib/python3.5/distutils/core.py\", line 148, in setup\n      dist.run_commands()\n    File \"/usr/lib/python3.5/distutils/dist.py\", line 955, in run_commands\n      self.run_command(cmd)\n    File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/wheel/bdist_wheel.py\", line 175, in run\n      self.run_command('build')\n    File \"/usr/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n      self.distribution.run_command(command)\n    File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/usr/lib/python3.5/distutils/command/build.py\", line 135, in run\n      self.run_command(cmd_name)\n    File \"/usr/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n      self.distribution.run_command(command)\n    File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n      cmd_obj.run()\n    File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/setuptools/command/build_ext.py\", line 49, in run\n      _build_ext.run(self)\n    File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/Cython/Distutils/build_ext.py\", line 164, in run\n      _build_ext.build_ext.run(self)\n    File \"/usr/lib/python3.5/distutils/command/build_ext.py\", line 338, in run\n      self.build_extensions()\n    File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 59, in build_extensions\n      self.build_libuv()\n    File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 46, in build_libuv\n      subprocess.run(['make', j_flag], cwd=LIBUV_DIR, env=env, check=True)\n    File \"/usr/lib/python3.5/subprocess.py\", line 711, in run\n      output=stdout, stderr=stderr)\n  subprocess.CalledProcessError: Command '['make', '-j4']' returned non-zero exit status 2\n\nFailed to build uvloop\nInstalling collected packages: uvloop\n  Running setup.py install for uvloop\n    Complete output from command /home/anand/.virtualenvs/35/bin/python3.5 -c \"import setuptools, tokenize;file='/tmp/pip-build-tmzeiyue/uvloop/setup.py';exec(compile(getattr(tokenize, 'open', open)(file).read().replace('\\r\\n', '\\n'), file, 'exec'))\" install --record /tmp/pip-8kkvvvo8-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/anand/.virtualenvs/35/include/site/python3.5/uvloop:\n    running install\n    running build\n    running build_py\n    running egg_info\n    writing top-level names to uvloop.egg-info/top_level.txt\n    writing dependency_links to uvloop.egg-info/dependency_links.txt\n    writing uvloop.egg-info/PKG-INFO\n    warning: manifest_maker: standard file '-c' not found\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/.git'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/docs'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/img'\nwriting manifest file 'uvloop.egg-info/SOURCES.txt'\nwarning: build_py: byte-compiling is disabled, skipping.\n\nrunning build_ext\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... gawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking build system type... x86_64-unknown-linux-gnu\nchecking host system type... x86_64-unknown-linux-gnu\nchecking for gcc... gcc\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables...\nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to accept ISO C89... none needed\nchecking whether gcc understands -c and -o together... yes\nchecking for style of include used by make... GNU\nchecking dependency style of gcc... gcc3\nchecking if gcc supports -fvisibility=hidden flag... yes\nchecking if gcc supports -g flag... yes\nchecking if gcc supports -std=gnu89 flag... yes\nchecking if gcc supports -pedantic flag... yes\nchecking if gcc supports -Wall flag... yes\nchecking if gcc supports -Wextra flag... yes\nchecking if gcc supports -Wno-unused-parameter flag... yes\nchecking for ar... ar\nchecking the archiver (ar) interface... ar\nchecking how to print strings... printf\nchecking for a sed that does not truncate output... /bin/sed\nchecking for grep that handles long lines and -e... /bin/grep\nchecking for egrep... /bin/grep -E\nchecking for fgrep... /bin/grep -F\nchecking for ld used by gcc... /usr/bin/ld\nchecking if the linker (/usr/bin/ld) is GNU ld... yes\nchecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\nchecking the name lister (/usr/bin/nm -B) interface... BSD nm\nchecking whether ln -s works... yes\nchecking the maximum length of command line arguments... 1572864\nchecking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\nchecking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\nchecking for /usr/bin/ld option to reload object files... -r\nchecking for objdump... objdump\nchecking how to recognize dependent libraries... pass_all\nchecking for dlltool... no\nchecking how to associate runtime and link libraries... printf %s\\n\nchecking for archiver @FILE support... @\nchecking for strip... strip\nchecking for ranlib... ranlib\nchecking command to parse /usr/bin/nm -B output from gcc object... ok\nchecking for sysroot... no\nchecking for a working dd... /bin/dd\nchecking how to truncate binary pipes... /bin/dd bs=4096 count=1\nchecking for mt... mt\nchecking if mt is a manifest tool... no\nchecking how to run the C preprocessor... gcc -E\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking for dlfcn.h... yes\nchecking for objdir... .libs\nchecking if gcc supports -fno-rtti -fno-exceptions... no\nchecking for gcc option to produce PIC... -fPIC -DPIC\nchecking if gcc PIC flag -fPIC -DPIC works... yes\nchecking if gcc static flag -static works... yes\nchecking if gcc supports -c -o file.o... yes\nchecking if gcc supports -c -o file.o... (cached) yes\nchecking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\nchecking whether -lc should be explicitly linked in... no\nchecking dynamic linker characteristics... GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking whether stripping libraries is possible... yes\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... yes\nchecking whether make supports nested variables... (cached) yes\nchecking for dlopen in -ldl... yes\nchecking for kstat_lookup in -lkstat... no\nchecking for kvm_open in -lkvm... no\nchecking for gethostbyname in -lnsl... yes\nchecking for perfstat_cpu in -lperfstat... no\nchecking for pthread_mutex_init in -lpthread... yes\nchecking for clock_gettime in -lrt... yes\nchecking for sendfile in -lsendfile... no\nchecking for socket in -lsocket... no\nchecking for special C compiler options needed for large files... no\nchecking for _FILE_OFFSET_BITS value needed for large files... no\nchecking sys/ahafs_evProds.h usability... no\nchecking sys/ahafs_evProds.h presence... no\nchecking for sys/ahafs_evProds.h... no\nchecking for pkg-config... yes\nchecking that generated files are newer than configure... done\nconfigure: creating ./config.status\nconfig.status: creating libuv.pc\nconfig.status: creating Makefile\nconfig.status: executing depfiles commands\nconfig.status: executing libtool commands\nCDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/bash /tmp/pip-build-tmzeiyue/uvloop/vendor/libuv/missing aclocal-1.15 -I m4\n/tmp/pip-build-tmzeiyue/uvloop/vendor/libuv/missing: line 81: aclocal-1.15: command not found\nWARNING: 'aclocal-1.15' is missing on your system.\n         You should only need it if you modified 'acinclude.m4' or\n         'configure.ac' or m4 files included by 'configure.ac'.\n         The 'aclocal' program is part of the GNU Automake package:\n         <http://www.gnu.org/software/automake>\n         It also requires GNU Autoconf, GNU m4 and Perl in order to run:\n         <http://www.gnu.org/software/autoconf>\n         <http://www.gnu.org/software/m4/>\n         <http://www.perl.org/>\nmake: *** [aclocal.m4] Error 127\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 100, in <module>\n    include_package_data=True\n  File \"/usr/lib/python3.5/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/lib/python3.5/distutils/dist.py\", line 955, in run_commands\n    self.run_command(cmd)\n  File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/setuptools/command/install.py\", line 61, in run\n    return orig.install.run(self)\n  File \"/usr/lib/python3.5/distutils/command/install.py\", line 583, in run\n    self.run_command('build')\n  File \"/usr/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/usr/lib/python3.5/distutils/command/build.py\", line 135, in run\n    self.run_command(cmd_name)\n  File \"/usr/lib/python3.5/distutils/cmd.py\", line 313, in run_command\n    self.distribution.run_command(command)\n  File \"/usr/lib/python3.5/distutils/dist.py\", line 974, in run_command\n    cmd_obj.run()\n  File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/setuptools/command/build_ext.py\", line 49, in run\n    _build_ext.run(self)\n  File \"/home/anand/.virtualenvs/35/lib/python3.5/site-packages/Cython/Distutils/build_ext.py\", line 164, in run\n    _build_ext.build_ext.run(self)\n  File \"/usr/lib/python3.5/distutils/command/build_ext.py\", line 338, in run\n    self.build_extensions()\n  File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 59, in build_extensions\n    self.build_libuv()\n  File \"/tmp/pip-build-tmzeiyue/uvloop/setup.py\", line 46, in build_libuv\n    subprocess.run(['make', j_flag], cwd=LIBUV_DIR, env=env, check=True)\n  File \"/usr/lib/python3.5/subprocess.py\", line 711, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['make', '-j4']' returned non-zero exit status 2\n\n----------------------------------------\n\n```\n@justinfay I tried as you mentioned, it is still throwing this error\n```\nrunning install\nrunning bdist_egg\nrunning egg_info\nwriting uvloop.egg-info/PKG-INFO\nwriting top-level names to uvloop.egg-info/top_level.txt\nwriting dependency_links to uvloop.egg-info/dependency_links.txt\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/.git'\nwriting manifest file 'uvloop.egg-info/SOURCES.txt'\ninstalling library code to build/bdist.linux-x86_64/egg\nrunning install_lib\nrunning build_py\nwarning: build_py: byte-compiling is disabled, skipping.\nrunning build_ext\nbuilding 'uvloop.loop' extension\nx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.5m -I/home/anand/.virtualenvs/35/include/python3.5m -Ivendor/libuv/include -c uvloop/loop.c -o build/temp.linux-x86_64-3.5/uvloop/loop.o\nx86_64-linux-gnu-gcc: error: uvloop/loop.c: No such file or directory\nx86_64-linux-gnu-gcc: fatal error: no input files\ncompilation terminated.\nerror: command 'x86_64-linux-gnu-gcc' failed with exit status 4\n```\n. @elprans  Above command ran successfully.\nWhen i ran python setup.py install, it throwed this error\n``` py\nrunning install\nrunning bdist_egg\nrunning egg_info\nwriting top-level names to uvloop.egg-info/top_level.txt\nwriting uvloop.egg-info/PKG-INFO\nwriting dependency_links to uvloop.egg-info/dependency_links.txt\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no previously-included files matching '' found under directory 'vendor/libuv/.git'\nwarning: no previously-included files matching '' found under directory 'vendor/libuv/docs'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/img'\nwriting manifest file 'uvloop.egg-info/SOURCES.txt'\ninstalling library code to build/bdist.linux-x86_64/egg\nrunning install_lib\nrunning build_py\nwarning: build_py: byte-compiling is disabled, skipping.\nrunning build_ext\nbuilding 'uvloop.loop' extension\nx86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -Wstrict-prototypes -g -fstack-protector --param=ssp-buffer-size=4 -Wformat \n-Werror=format-security -D_FORTIFY_SOURCE=2 -fPIC -I/usr/include/python3.5m -I/home/anand/.virtualenvs/35/include/python3.5m -Ivendor/li\nbuv/include -c uvloop/loop.c -o build/temp.linux-x86_64-3.5/uvloop/loop.o\nuvloop/loop.c: In function \u2018__pyx_f_6uvloop_4loopuvudp_on_receive\u2019:\nuvloop/loop.c:78543:9: warning: passing argument 1 of \u2018pyx_f_6uvloop_4loopconvertsockaddr_to_pyaddr\u2019 discards \u2018const\u2019 qualifier fr\nom pointer target type [enabled by default]\n    pyx_t_2 = __pyx_f_6uvloop_4loopconvertsockaddr_to_pyaddr(pyx_v_addr); if (unlikely(!__pyx_t_2)) __PYX_ERR(7, 314, __pyx_L9_error)\n         ^\nuvloop/loop.c:72213:18: note: expected \u2018struct sockaddr \u2019 but argument is of type \u2018const struct sockaddr \u2019\n static PyObject __pyx_f_6uvloop_4loopconvertsockaddr_to_pyaddr(struct sockaddr *pyx_v_addr) {\n                  ^\nuvloop/loop.c: At top level:\nuvloop/loop.c:36870:18: warning: \u2018__pyx_f_6uvloop_4loop_new_MethodHandle2\u2019 defined but not used [-Wunused-function]\n static PyObject __pyx_f_6uvloop_4loop_new_MethodHandle2(struct __pyx_obj_6uvloop_4loop_Loop __pyx_v_loop, PyObject __pyx_v_name, __pyx_t_6uvloop_4loop_method2_t __pyx_v_callback, PyObject __pyx_v_ctx, PyObject __pyx_v_arg1, PyObject __pyx_v_arg2) {\n                  ^\nx86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.5/uvloop/loop.o vendor/libuv/.libs/libuv.a -lrt -o build/lib.linux-x86_64-3.5/uvloop/loop.cpython-35m-x86_64-linux-gnu.so\n/usr/bin/ld: vendor/libuv/.libs/libuv.a(libuv_la-threadpool.o): relocation R_X86_64_32 against `.bss' can not be used when making a shared object; recompile with -fPIC\nvendor/libuv/.libs/libuv.a: error adding symbols: Bad value\ncollect2: error: ld returned 1 exit status\nerror: command 'x86_64-linux-gnu-gcc' failed with exit status 1\n```\n. @elprans \nOS details\n``` sh\nanand at anand in ~/sandbox/tmp/uvloop-0.4.16/vendor/libuv [9:47:17]\n$ lsb_release -a\nNo LSB modules are available.\nDistributor ID: Ubuntu\nDescription:    Ubuntu 14.04.3 LTS\nRelease:        14.04\nCodename:       trusty\n(3)\nanand at anand in ~/sandbox/tmp/uvloop-0.4.16/vendor/libuv [9:47:31]\n$ uname -a\nLinux anand 3.16.0-51-generic #69~14.04.1-Ubuntu SMP Wed Oct 7 15:32:41 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\nAttached make.log here.\n. sh\n$ pip -V\npip 8.1.2 from /home/anand/.virtualenvs/35/lib/python3.5/site-packages (python 3.5)\n. Able to install correctly. Thanks @1st1 @elprans\n. ",
    "elprans": "@ChillarAnand: These build failures are likely because the timestamps on aclocal.m4 and configure get messed up somehow during unpacking.  To test this, can you please download the tarball from PyPI: https://pypi.python.org/pypi/uvloop/, unpack it, run the following:\nbash\n$ cd uvloop-0.4.16/vendor/libuv && ./configure && make -d\nAnd then attach the output. Thanks.\n. @ChillarAnand Which platform are you running this on?  \nAlso, please do attach the output of the \"make -d\" command, even though it succeeds. Please remove the uvloop dir, unpack again and re-run the command. \nbash\n$ rm -rf uvloop-0.4.16\n$ tar xzf uvloop-0.4.16.tar.gz\n$ cd uvloop-0.4.16/vendor/libuv && ./configure && make -d 2>&1 >make.log\nPlease attach \"make.log\" here.  \nThanks.\n. So we were able to track down the aclocal issue. On Ubuntu 14.04 and Pip 7.1, the timestamps on extracted files are not preserved properly, which triggers a rebuild.\n. Done.. @ignatenkobrain What would be the best way to reproduce this?. Throughput depends a lot on the chosen cipher.  See e.g. https://jbp.io/2018/01/07/rustls-vs-openssl-performance-1.html, the difference can be quite large.. Try pip install -U setuptools pip before.. The original issue is a setuptools bug. Do a pip install -U setuptools before installing uvloop.. Installing uvloop from a source distribution requires building the bundled libuv, which requires a working /bin/sh, GNU make, and a C compiler none of which are guaranteed to be present on Android.. For reference, here's how it crashes on my machine:\n```\ntests/test_tcp.py::Test_UV_TCPSSL::test_start_tls_client_buf_proto_1 \nFatal Python error: GC object already tracked\nThread 0x00007f65c27fc700 (most recent call first):\n  File \"/usr/lib64/python3.6/ssl.py\", line 633 in read\n  File \"/usr/lib64/python3.6/ssl.py\", line 871 in read\n  File \"/usr/lib64/python3.6/ssl.py\", line 994 in recv\n  File \"/home/elvis/dev/magic/uvloop/uvloop/_testbase.py\", line 348 in recv_all\n  File \"/home/elvis/dev/magic/uvloop/tests/test_tcp.py\", line 1679 in serve\n  File \"/home/elvis/dev/magic/uvloop/uvloop/_testbase.py\", line 486 in _handle_client\n  File \"/home/elvis/dev/magic/uvloop/uvloop/_testbase.py\", line 477 in _run\n  File \"/home/elvis/dev/magic/uvloop/uvloop/_testbase.py\", line 446 in run\n  File \"/usr/lib64/python3.6/threading.py\", line 916 in _bootstrap_inner\n  File \"/usr/lib64/python3.6/threading.py\", line 884 in _bootstrap\nCurrent thread 0x00007f65d94da540 (most recent call first):\n  File \"/usr/lib64/python3.6/ssl.py\", line 631 in read\n  File \"/home/elvis/dev/magic/uvloop/tests/test_tcp.py\", line 1755 in test_start_tls_client_buf_proto_1\n  File \"/usr/lib64/python3.6/unittest/case.py\", line 605 in run\n  File \"/usr/lib64/python3.6/unittest/case.py\", line 653 in call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/unittest.py\", line 176 in runtest\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 112 in pytest_runtest_call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 614 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 265 in init\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 248 in _wrapped_call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 613 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 334 in \n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 339 in _hookexec\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 745 in call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 182 in \n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 196 in init\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 182 in call_runtest_hook\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 162 in call_and_report\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 82 in runtestprotocol\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/runner.py\", line 68 in pytest_runtest_protocol\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 614 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 265 in init\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 248 in _wrapped_call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 613 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 265 in init\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 248 in _wrapped_call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 613 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 334 in \n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 339 in _hookexec\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 745 in call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/main.py\", line 169 in pytest_runtestloop\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 614 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 334 in \n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 339 in _hookexec\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 745 in call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/main.py\", line 146 in _main\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/main.py\", line 110 in wrap_session\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/main.py\", line 139 in pytest_cmdline_main\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 614 in execute\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 334 in \n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 339 in _hookexec\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/vendored_packages/pluggy.py\", line 745 in call\n  File \"/home/elvis/dev/venvs/uvloop/lib/python3.6/site-packages/_pytest/config.py\", line 58 in main\n  File \"/home/elvis/dev/venvs/uvloop/bin/pytest\", line 11 in \nfish: \u201cpytest --verbose\u201d terminated by signal SIGABRT (Abort)\n``. Try addingupdate: trueto thehomebrewhash. We are deliberately choosing an older version to ensure compatibility with a couple of prior macOS releases.  If there's a good way of achieving that on newer releases, I'm all for that.. Yes, we only need one \"release\" job for Linux.  The actual wheel build is done inside manylinux docker images which are selected with theRELEASE_PYTHON_VERSIONSenvironment variable.. I'd call thisadd_flowcontrol_defaults().. We usually spell thisargs,*kwargs`, even if unused.. ",
    "f0t0n": "https://github.com/MagicStack/uvloop/issues/20#issuecomment-218211914\nGot the same exit code and traceback while installing in container with pip.\nOS: Alpine Linux Edge, pip version:  8.0.3.\nThe warning about the unused function is enabled with gcc's flag -Wall which enables all warnings or with -Wunused-function. So that it requires to change these flags or to remove the unused function.\n. So basically new_MethodHandle2() is never used in the source code and this is why gcc fails to compile with default flag -Wall.\nCython guys talked about CYTHON_UNUSED macro which should suppress the warning, but I don't get how to use it in Cython source code. Maybe you guys know.\n. @1st1 There's gcc flag -Wno-unused-function that will suppress this as well. Though I'm not sure if it's available in all versions of gcc.\n. Just installed 0.4.24 successfully. Thanks guys!\n. So the example basic app could look like:\n```\nimport asyncio\nimport uvloop\nfrom aiohttp import web\ndef index(request):\n    return web.Response(text='Welcome home!')\ndef get_loop():\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    return asyncio.get_event_loop()\napp = web.Application(loop=get_loop())\napp.router.add_route('GET', '/', index)\nweb.run_app(app, port=8888)\n```\nIt works only without GunicornWebWorker.\n. @1st1 did you run my example with gunicorn with commenting/removing \nthe last line web.run_app(app, port=8888)?\nThis example is to run without Gunicorn, and it works well:\n``` py\nimport asyncio\nimport uvloop\nfrom aiohttp import web\ndef index(request):\n    return web.Response(text='Welcome home!')\ndef get_loop():\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    return asyncio.get_event_loop()\napp = web.Application(loop=get_loop())\napp.router.add_route('GET', '/', index)\nweb.run_app(app, port=8888)\n```\nAnother one (without the last line) to run by Gunicorn is not working:\n``` py\nimport asyncio\nimport uvloop\nfrom aiohttp import web\ndef index(request):\n    return web.Response(text='Welcome home!')\ndef get_loop():\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    return asyncio.get_event_loop()\napp = web.Application(loop=get_loop())\napp.router.add_route('GET', '/', index)\nweb.run_app(app, port=8888)\n```\nWhen I start with gunicorn it just hangs like listed below, and doesn't serve requests.\nsh\n$ gunicorn test:app --worker-class aiohttp.worker.GunicornWebWorker --bind localhost:8888\n[2016-05-17 00:46:17 +0000] [84] [INFO] Starting gunicorn 19.4.5\n[2016-05-17 00:46:17 +0000] [84] [INFO] Listening at: http://127.0.0.1:8888 (84)\n[2016-05-17 00:46:17 +0000] [84] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n[2016-05-17 00:46:17 +0000] [99] [INFO] Booting worker with pid: 99\nOS:\nsh\n~ $ cat /etc/*-release\n3.3.0\nNAME=\"Alpine Linux\"\nID=alpine\nVERSION_ID=3.3.0\nPRETTY_NAME=\"Alpine Linux v3.3\"\nHOME_URL=\"http://alpinelinux.org\"\nBUG_REPORT_URL=\"http://bugs.alpinelinux.org\"\nPython:\nsh\n~ $ python --version\nPython 3.5.1\nGunicorn:\nsh\n~ $ gunicorn --version\ngunicorn (version 19.4.5)\nuvloop:\nsh\n~ $ pip freeze | grep uvloop\nuvloop==0.4.24\naiohttp:\nsh\n~ $ pip freeze | grep aiohttp\naiohttp==0.21.5\n. ",
    "jettify": "@f0t0n I had succes with python:3.5.1-slim docker image. You can take a look here: https://github.com/aio-libs/aioodbc/blob/master/ci%2FDockerfile\nBut on travis ci can not build uvloop:\nhttps://travis-ci.org/aio-libs/aioodbc/jobs/128160252\n. Sync database clients usually faster on localhost (if implemented properly), since there is no coroutine/event loop overhead, but when we have network with concurrent clients, this is where async stuff begin to shine. . I like zipkin approach to spans since API is minimalistic and very powerful, here I created tracer for asyncio with aiohttp instrumentation (https://github.com/aio-libs/aiozipkin). I have implementation of spans/tracers/context etc. \nQuick question, zipkin/opentracing and co are all about distributed tracing (as described in dapper paper), it helps to find all tasks spawned by particular request on several distributed machines.  Given that what purpose of uvloop/asyncio tracing subsystem? Is this only for debugging only local process or distributed also? \nDistributed case has some implication, trace or not to trace often decided on separate server per request, if we infer from incoming request that it sampled, subsystem should trace all child tasks and attach it to current span.\n. As as far as aiozipkin concerts, I need only callbacks and way to pass context between them. zipkin spans already has capabilities to: annotate timeline, add metadata and tags, create child span. And developer usually decided how much to trace and what callbacks to instrument. \nAs for  https://github.com/MagicStack/uvloop/issues/163#issuecomment-394416117 not sure what the purpose of TimerSpan vs CounterSpan vs TaskSpan. Say I want to trace subtask tree creation, make zipkin span per task with appropriated child parent relation (this way we can see sequential vs parallel task execution as result find places where we can increase parallelism). How mentioned API fits for this?  . ",
    "darshan-jain-29": "try pip install -vvv uvloop\nThis worked for me\n. ",
    "mtorromeo": "I'm not sure how feasible it would be to test libuv version but I'd rather keep things simple.\nThe shared object version would be a way to check for ABI compatibility but version 1.8.0 installed libuv.so.1.0.0 just as 1.9.0 does.\nHaving the compiler just fail doesn't seem too bad to me as long as it is documented somewhere since --use-system-libuv is explicit and you should know what you are doing. Distribution packagers know how to check these things.\n. Fixed\n. Snippet added but I cannot test it since I don't use Mac OS X.\n. ",
    "cwt": "you can install it using this command:\npip install https://bitbucket.org/bashell-com/wormhole/get/uvloop.tar.gz\nand then just run wormhole, it will open port 8800, then set your browser/system http_proxy to 127.0.0.1:8800 and try to load http (not https) site with a lot of pictures for a while (control-R or command-R works too).\n. me too, I test on this site http://www.obec.go.th but the site is located in Thailand, may slow on your side.\n. I use the latest one. just install it 1 hour ago.\nI can't remember how many times I refresh the page. will try again, but now I already got this while the proxy is still running.\nscreen shot\n. Yes, I think that's the problem. My ulimit -n said 256, but the MAX_TASKS on my server.py is set to 1000. That should overload the system.\nI think the problem is on my side now. Thank you for your help. I will close the issue.\n. speed is really amazing! that also accelerate my problem on resource usage to happened faster than asyncio. with uvloop, hundreds of concurrent connections were created fast until number of sockets exceed the limit. now I already fix it by set semaphore limit to the 90% of max open files.\n. to run it without docker:\n$ pyvenv-3.5 wormhole\n$ source wormhole/bin/activate\n(wormhole) $ pip install Cython\n(wormhole) $ pip install uvloop\n(wormhole) $ pip install wormhole-proxy\n(wormhole) $ wormhole\nI'm cloning and building uvloop from git now. Will post the results again after finish.\n. unfortunately, it still crashed with the same error messages.\n. Yeah! my proxy work pretty well with v0.4.34. Thank you.\n. ",
    "Tinche": "There are wheels for Linux. :)\nhttps://github.com/pypa/manylinux\n. Sweet, great job!\n. Hm, weird. I definitely do not have anything running on 50000, and I tried other ports. 100% reproducible. Uvloop 0.4.23.\n. ```\n\npython t.py\nTraceback (most recent call last):\n  File \"uvloop/loop.pyx\", line 1168, in uvloop.loop.Loop.create_server (uvloop/loop.c:19802)\n  File \"uvloop/handles/streamserver.pyx\", line 38, in uvloop.loop.UVStreamServer.listen (uvloop/loop.c:56668)\n  File \"uvloop/handles/streamserver.pyx\", line 75, in uvloop.loop.UVStreamServer._fatal_error (uvloop/loop.c:57149)\nOSError: [Errno 98] Address already in use\n\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"t.py\", line 25, in \n    loop.run_until_complete(test_sendfile_socket())\n  File \"uvloop/loop.pyx\", line 1015, in uvloop.loop.Loop.run_until_complete (uvloop/loop.c:18124)\n  File \"/usr/lib/python3.5/asyncio/futures.py\", line 274, in result\n    raise self._exception\n  File \"/usr/lib/python3.5/asyncio/tasks.py\", line 240, in _step\n    result = coro.send(None)\n  File \"t.py\", line 18, in test_sendfile_socket\n    server = await asyncio.start_server(serve_file, port=port)\n  File \"/usr/lib/python3.5/asyncio/streams.py\", line 116, in start_server\n    return (yield from loop.create_server(factory, host, port, **kwds))\n  File \"uvloop/loop.pyx\", line 1172, in create_server (uvloop/loop.c:19927)\nOSError: [Errno 98] error while attempting to bind on address ('::', 60000, 0, 0): address already in use\n```\n. Correct, it works if I comment out the policy switch.\nUbuntu 16.04, kernel 4.4.0-22-generic, Python 3.5.1+ virtualenv. pip list:\npip (8.1.1)\npkg-resources (0.0.0)\nsetuptools (20.7.0)\nuvloop (0.4.23)\nWhile virtualenv is active, just python t.py.\n. Confirm, my test suite passes now :)\n. ",
    "methane": "I'm trying.  But travis's Linux machine (not container based) doesn't start for a long time...\nhttps://travis-ci.org/methane/uvloop/builds/130526994\nhttps://github.com/methane/uvloop/commit/1dac4c7e051b99f39fe0dfc02cacf8c159e84dbc\n. Same to uvloop-release.tar.gz.  It uploads to github release when tagged in master branch.\n. I can't find aiopyramid websocket example.\nThe exception happened here?\nhttps://github.com/housleyjk/aiopyramid/blob/8aef5f4f8c823d138f36b68df2ad40a8b5adb6a3/aiopyramid/websocket/config/gunicorn.py#L118-L128\nI think this issue should be go asyncio ML,  \"What is the standard way to switch protocol of transport?\"\n. I'm sorry about incompatibilities at Python 3.6.\nBut inhertance from asyncio.future.Future is still required?\n. ",
    "ssbb": "Both PR are merged and looks like issue is fixed. But only worker class should be specified w/o installing event loop policy manually.\n. ",
    "machbio": "What version will this fix be available ?\n. Upgraded but still not working -  requests are still blocked and hangs -  \nuvloop==0.5.0\naiohttp==0.22.3\n@1st1  what do you mean by \n\"too late to set up a uvloop policy in your app -- you have to do that at the gunicorn worker level\"\n. Thank you @1st1 - the above solution works\n. ",
    "AndreLouisCaron": "Thanks!\n. Just tried 0.4.26 and it now works as expected!  Thanks!\n. ",
    "ze-phyr-us": "@1st1 Thanks for the quick response. loop.time seems to be working correctly now, but my first test program is still behaving the same. call_later fires the callback immediately. Steps to reproduce:\n```\n$ virtualenv -p $(which python3) env && . env/bin/activate\nRunning virtualenv with interpreter /usr/local/bin/python3\nUsing base prefix '/usr/local/Cellar/python3/3.5.1/Frameworks/Python.framework/Versions/3.5'\nNew python executable in env/bin/python3.5\nAlso creating executable in env/bin/python\nInstalling setuptools, pip...done.\n(env)$ pip install uvloop==0.4.26\nDownloading/unpacking uvloop==0.4.26\n  Downloading uvloop-0.4.26.tar.gz (1.9MB): 1.9MB downloaded\n  Running setup.py (path:/private/tmp/env/build/uvloop/setup.py) egg_info for package uvloop\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/.git'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/docs'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/img'\n\nInstalling collected packages: uvloop\n  Running setup.py install for uvloop\n[SNIP]\n(env)$ pip freeze\nuvloop==0.4.26\n(env)$ cat > test.py\nimport asyncio\nimport time\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\ndef f():\n    print('f   ', time.time())\nasync def main(loop):\n    await asyncio.sleep(0.001)\n    time.sleep(1)\n    print('main', time.time())\n    loop.call_later(1, f)\n    await asyncio.sleep(1)\nloop = asyncio.get_event_loop()\nloop.run_until_complete(main(loop))\n^D\n(env)$ python test.py\nmain 1463967084.144865\nf    1463967084.145064\n```\n. It works! Thank you very much.\n. ",
    "rahulverma": "Thanks! I wish I had the time to do the tests. :+1: \n. ",
    "OOPMan": "That's good to know. Thanks for answering my question!\n. ",
    "Yardanico": "@1st1 by the way, you can already play around PyPy3.5, there's nightly builds:\nhttp://buildbot.pypy.org/nightly/py3.5/\nIt's not stable thought\n. @1st1 the time has come!\nFirst public release of PyPy3.5. @thedrow \nWhere is CFFI in pyuv?\nI see no CFFI here, only usual Python C extension.\nIf uvloop would use pyuv, PyPy3.5 would be slower, because Python C Extensions are slower than CFFI extensions (in PyPy).\n Uvloop wants to be fast, so if it wants to be fast on PyPy it should use CFFI. @thedrow , @1st1, I found this uvloop CFFI extension - https://github.com/koehlma/uv/. @1st1 see this - https://github.com/koehlma/uv. ",
    "thedrow": "https://github.com/saghul/pyuv already implements a CFFI extension that works on PyPy3 beta.\nIt's just a matter of providing the necessary Python API that wraps it.. Seems like the CFFI extension is no longer maintained :(. ",
    "nibrag": "It works, thanks.\n. ",
    "bdarnell": "Yes, it looks like that just works. \n. ",
    "cigor": "yes. 0.4.32 removed this error message.\n0.4.32 also removed a memory leak that i had been observing in my application. \nGood work :)\n. ",
    "kaniini": "Hello,\nUnfortunately I can't share the program code in this instance as it contains trade secrets.  We have a \"scoreboard\" facility (like Apache) -- would it be possible to get the text from loop.print_debug_info() into that using a StringIO object?\nWe used the aiohttp.worker.GunicornUVLoopWebWorker from aiohttp git, so that is probably the same from KeepSafe/aiohttp#878.  As such, I don't think the example task will work, but our scoreboard facility should be helpful.\nUVLoop provides a significant CPU usage reduction over the default loop, so we are very eager to help in whatever way we can.  Of note is that we haven't ported the application to Python 3.5 async/await statements from the old yield from syntax.\n. Based on what I see here: https://github.com/MagicStack/uvloop/blob/master/uvloop/loop.pyx#L832-L918 it will need to be modified, but no worries, we can do that modification and send it as a pull request.\n. We use a custom asyncio driver for Aerospike, code available at http://github.com/kaniini/aerospike-py as well as aioredis.  We also use an async client to talk to the BIRD BGP routing daemon (but this is being replaced for various reasons, and has been determined not responsible for the leak).  Other than that, it is a pretty simple aiohttp.web application.\n. We haven't really bothered to test outside of Gunicorn as we use Gunicorn to manage our workers -- retooling to use aiohttp directly (even though the aiohttp worker basically replaces the entirety of Gunicorn's actual web serving infrastructure) is not something we're eager to do right now.  I will add the loop debug info to the scoreboard tomorrow and post some stats.\n. Hello,\nSo we have added uvloop debugging to the scoreboard module, and I wonder if there is an issue with the way callback handles are being cleaned up, because the \"total callback handles\" number is going up at a rate that is proportional to the memory increase.\nTCPTransport and UVTimer objects are the most heavily used, which is unsurprising.\nAn interesting note is that the Read callbacks number is much smaller than the total callback handles number.\n. Hello,\nYes, the current number of callbacks is low.\nHere is one of the UVHandles dumps from a worker, which should answer the other questions:\nalive  | closed  |\nUVHandles               python | libuv   | total\n                        objs   | handles |\n-------------------------------+---------+---------\n    TCPServer                1 |       0 |       1\n    TCPTransport            57 |  414552 |  414609\n    UVAsync                  1 |       0 |       1\n    UVCheck                  1 |       0 |       1\n    UVIdle                   1 |       0 |       1\n    UVPoll                   0 |      10 |      10\n    UVSignal                 8 |       0 |       8\n    UVTimer                  2 |  558155 |  558157\n    UnixTransport            1 |  139022 |  139023\nI will make the requested modifications shortly, and report back.\n. Hello,\nI applied the modifications and now it is leaking heavily.  Roughly 1MB per second per worker.\n. Seems the leak rate is now slowing down on the modified server, so I will monitor for a bit more and give an update.\n. Right now what I am seeing is heavy CPU use (probably due to GC pressure), and a much slower leak rate, but it is still leaking a little: an asyncio default event loop worker started at the same time with the same load is using about 210mb RSS, while the uvloop is using about 250mb.\nI agree that it may be UVTimer, do you want me to put the freelists back for the non-timer case?\n. Awesome!  Is there anything I can do on my end to help with getting a fix going?  I'm unfortunately not very familiar with libuv internals, but if it is a bug on their side I may be able to help fix it.\n. If you can make that branch public, I'm more than happy to deploy it and give it a go.\n. Looks good so far, will run it for 24 hours and see where it's at.  Thanks!\n. 3 hours later and no leak, I think we can call this one done.  Will deploy uvloop 0.4.33 to all workers, thanks so much!\n. The main advantage for the app (a real-time ad server DSP/SSP engine) in question is that UVLoop provides more stable latencies (due to more performant socket I/O and polling provided by libuv).  CPU is cut by about 30% over baseline, so it is a nice performance improvement there.  The key thing though is that latencies are more stable.  We have been testing with libuv for about a month now and finally had diagnosed uvloop as the only remaining culprit, hince the report :)\nEach server has 8 workers and processes approximately 6000-12000 requests per second.\n. we will deploy it on one of our nodes and verify there are no regressions, thanks!\n. We've deployed uvloop 0.4.34 and see no regressions in terms of memory leaks.\n. :+1: patch works for me on a Solaris 11 box\n. ",
    "jimfulton": "On Thu, Jul 7, 2016 at 5:39 PM, Yury Selivanov notifications@github.com\nwrote:\n\nThe general advice is to create a minimal testcase and then debug the code\nwith gdb (or lldb) and print statements ;)\nYeah. I took an initial stab at that, but it was too minimal.  I'll take\nanother stab.\nIn this particular case, could you please tell me the values of addr and\nssl?\nssl is usually, but not always None.  I just hacked out SSL-related tests\nand ssl support, and still hanging.  So for the sake of this discussion,\nSSL is always None.\n\nThe address is almost always ('127.0.0.1', 0). I just did some test\ncleanup to make this so. :) Previously, it often had a host of\n'localhost' or '' and a randomly selected port. There may also be a\ntest or 2 that uses unix-domain sockets. (If not, I should add one. :) ).\nDoes the loop have any other scheduled tasks?\nNo.\n\nDoes it run in the main thread?\nNo. (I don't currently call set_event_loop, because I pass the loop around\nand nothing was relying on the default event loop.  Previously, I was\ncalling set_event_loop, and the server was hanging then as well.\n\nI'm 70% sure this is a resource exhaustion problem of some sort.\nAlso worth noting:\n- I tried just using uvloop for clients and still got a test failure, one\n  of which had to do with running the client within a multiprocessing Process.\n- The test servers almost always are run in a multi-Processing process.\nJim\n\nJim Fulton\nhttp://jimfulton.info\n. On Thu, Jul 7, 2016 at 6:05 PM, Yury Selivanov notifications@github.com\nwrote:\n\nHm, actually, there is only one await in Loop.create_server, and it waits\non getaddrinfo. So it might be a bug in the DNS resolver. What's the\nvalue of addr?\nAlmost always ('127.0.0.1', 0)\n. On Thu, Jul 7, 2016 at 6:45 PM, Yury Selivanov notifications@github.com\nwrote:\nAnd there's also an option to make a debug build with make debug. When\nbuilt in debug mode, loop has a print_debug_info() method which outputs a\nbunch of useful debug info.\nOK, I'll try that.  Would you suggest print_debug_info() here:\n\nhttps://github.com/zopefoundation/ZEO/blob/debug-uvloop/src/ZEO/asyncio/server.py#L226\n. The program was running out of file descriptors.  Not an issue with uvloop at all. Sorry for the noise.\n. I was wrong. It has nothing to do with running out of file descriptors. (I was able to make uvloop fail when having too many open files, but that's not what made the tests fail.)\nMany of the ZEO tests are integration tests. Typically, these tests run a server in a subprocess using multiprocessing.  A few tests run the server in a thread, which makes it possible to introspect server state. Mixing thread-based and multiprocessing-based tests leads to hanging in the test runner when using uvloop.\nHere's a minimal script that demonstrates the problem:\nhttps://gist.github.com/jimfulton/59c02a96ebe4720d512b2b0ee426c7ed\nI'm not sure if this issue is specific to multiprocessing (I suspect so because magic :) ) or would also be an issue with other ways of running a server in a subprocess.\n. The bug is mainly an inconvenience at this point.  \nInformal performance measurements indicate that most of the win is on the client, so for the moment, I'm not using uvloop on the server. I could use it on the server if I rearrange some tests, which I think I'll probably do. (If it was easy for you to fix, I'd have waited, but I'll go ahead and work around it.)\n(Lack of connect_accepted_socket is also preventing using on the server for the main project I'm working on. :) )\n. Great! I'll try it today.\nBTW, I've updated the ZEO tests so they pass with uvloop (when run a certain way that runs groups of tests in separate processes).\n. connect_accepted_socket works great. :) ZEO is now using it in it's multi-threaded-server configuration. Thanks.\n. ",
    "urbaniak": "The exception happens exactly here https://github.com/housleyjk/aiopyramid/blob/8aef5f4f8c823d138f36b68df2ad40a8b5adb6a3/aiopyramid/websocket/config/gunicorn.py#L126.\nThe aio websocket example can be created like that:\npip install aiopyramid gunicorn\npcreate -s aio_websocket <project>\ncd <project>\npython setup.py develop\npserve development.ini # or gunicorn --paste development.ini\nI agree that there should be a better way in asyncio transport to switch protocol other than accessing private variable, but for now we don't have it. I've proposed it on python/asyncio issue tracker (https://github.com/python/asyncio/issues/388)\nHaving a private property similar as asyncio standard loop is a good thing, just to make uvloop a drop-in replacement for asyncio standard loop even in edge cases like aiopyramid's one.\n. ",
    "deltaindiatango": "somewhat relevant to the conversation: https://gist.github.com/deltaindiatango/7bf157202c17681d62667a006eb15abd\nfound some existing pure-Python resolver, did basic work to make async.\nIt's not noticably slower than getaddrinfo/getnameinfo.\n. @1st1 Yes I am, I have a pretty minimal DNS resolver I'm running in uvloop.\n. @1st1 https://gist.github.com/deltaindiatango/7bf157202c17681d62667a006eb15abd\nWIP but functional.\n. ",
    "benjamingr": "Hi, Node guy here - NodeJS does use c-ares. Here's discussion about replacing it https://github.com/nodejs/node/issues/1013 \nDNS thread pool is a compromise. Node documents .lookup:\n\nThough the call to dns.lookup() will be asynchronous from JavaScript's perspective, it is implemented as a synchronous call to getaddrinfo(3) that runs on libuv's threadpool. Because libuv's threadpool has a fixed size, it means that if for whatever reason the call to getaddrinfo(3) takes a long time, other operations that could run on libuv's threadpool (such as filesystem operations) will experience degraded performance. In order to mitigate this issue, one potential solution is to increase the size of libuv's threadpool by setting the 'UV_THREADPOOL_SIZE' environment variable to a value greater than 4 (its current default value). For more information on libuv's threadpool, see the official libuv documentation.\n\nAnd .resolve:\n\nThese functions are implemented quite differently than dns.lookup(). They do not use getaddrinfo(3) and they always perform a DNS query on the network. This network communication is always done asynchronously, and does not use libuv's threadpool.\n. @1st1 I'm in the opinion you're doing an excellent job using libuv and that you shouldn't worry about this until it becomes a real problem. \n\nI'd argue that the vast majority of programs don't perform a huge amount of uncacheable DNS queries and that it's an edge case. I'd invest more in getting more library adoption and feedback. \nIn practice the wrapper will behave like users expect for the vast majority of users. I don't see how you'd solve this without using something other than libuv either. \n. ",
    "WGH-": "But won't c-ares break expectations in case /etc/nsswitch.conf has somethings more complex than hosts: files dns, like mdns or resolved (systemd-resolved-based plugin, which supports LLMNR, per-interface domain names, etc.)?\n. ",
    "DeoLeung": "we encountered a dns problem using uvloop with tornado\nbash\nsocket.gaierror: [Errno -3] Temporary failure in name resolution\nthis hangs our program\nmaybe there's a way to set a timeout on the lookup or may uvloop dns lookup async?\n\nI found UV_THREADPOOL_SIZE may help, so I'm increasing it to maximum 128, still I think getting a way to timeout dns lookup or throw error will help the program, seems hanging is really bad.... ",
    "vodik": "No, I had the server misconfigured. My bad. No bug.\n. No, false alarm again. I forgot to configure the client correct. One change must be made from the example. The client needs to set both a custom local_addr and remote_addr. Once you add it in, it routes traffic to the local_addr instead of the remote_addr.\n. Here's what I see in strace:\nWith local_addr set to 10.200.0.6:8000, the packet is sent from the local_addr and then recieve back again.\nstrace\nsendmsg(9, {msg_name={sa_family=AF_INET, sin_port=htons(8000), sin_addr=inet_addr(\"10.200.0.6\")}, msg_namelen=16, msg_iov=[{iov_base=\"This is the message. It will be \"..., iov_len=39}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 39\nrecvmsg(9, {msg_name={sa_family=AF_INET, sin_port=htons(8000), sin_addr=inet_addr(\"10.200.0.6\")}, msg_namelen=128->16, msg_iov=[{iov_base=\"This is the message. It will be \"..., iov_len=256000}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 39\nWithout the local_addr, for contrast, it sends and receives a packet from the remote_addr.\nstrace\nsendmsg(9, {msg_name={sa_family=AF_INET, sin_port=htons(9999), sin_addr=inet_addr(\"10.10.8.30\")}, msg_namelen=16, msg_iov=[{iov_base=\"This is the message. It will be \"..., iov_len=39}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 39\nrecvmsg(9, {msg_name={sa_family=AF_INET, sin_port=htons(9999), sin_addr=inet_addr(\"10.10.8.30\")}, msg_namelen=128->16, msg_iov=[{iov_base=\"This is the message. It will be \"..., iov_len=256000}], msg_iovlen=1, msg_controllen=0, msg_flags=0}, 0) = 39\nWhich explains why aiosip doesn't work. Both addresses are specified.\n. Think I found the bug. PR hopefully coming shortly.\n. I'll see what I can do with different loopback address.\n. Okay, I've modified the UDP test case to set a fixed local_addr of 127.0.0.2. This causes the UDP tests to fail on master, but work with this patch.\nIf you rather a separate test case, I can do that too, but mind giving me some pointers how I should organise things?\n. Yeah, that works. Actually, there's no reason to use a second address so long as we bind to port 0.\nStill fails on master/passed with fix.\n. No problem. I don't have a mac so I can't lend a hand. Figuring out something more proper might benefit the TCP tests too.\nMaybe its as simple as putting them as a different test and documenting that 127.0.0.2 needs to be added to loopback. My understanding, after googling around, is that it works on mac. Just the networking stack defaults to 127.0.0.1/32 instead of 127.0.0.1/8.\n. ",
    "mackeyja92": "Currently our stack is python 2 on twisted so we are moving some of our services out to py3 and asyncio.  But that is good enough for me! Thanks\n. ",
    "petriborg": "Sure, created pull request #49.\n. ",
    "diogobaeder": "Hi @1st1 ,\nUnfortunately I'm already using the latest version, which is 0.22.5. Mind trying it as well, and see if it works fine for you?\nThanks for the quick reply :-)\n. Hmmm... makes sense...\nShould we close this issue as a duplicate? Want me to refer it in the other one?\n[EDIT] Already done, sorry. You can close this one if you want.\n. ",
    "ganwell": "Well, I'll need that too, I am writing a portable messaging library chirp connecting the major platforms (python, node, ruby... etc and C of course). The most efficient way to write bindings is uvloop and chirp sharing uv_loop_t. It shouldn't be too difficult to grab the pointer somewhere. It will take some time till I am writing the bindings... if there is no API for this till then, I'l do the PR.. ",
    "MarkReedZ": "I have a server that sets up uvloop in python then runs in C.  To access the loop I call out to python.  It would be nice to have access to the uv_loop_t to attach say this redis C client to the loop using the following code.\nhttps://github.com/redis/hiredis/blob/master/adapters/libuv.h\n. Exposing the loop may not be a good idea as I believe I see uvloop and other libraries using the loop's data field.  It would at least need a note.  Locally I've exposed the loop by adding a function that returns it as a PyLong and am using it. . I may have worded that wrong, but python states you should make the version number available in version which I don't think is set by uvloop. . ",
    "zchee": "Just in case, I know now setup.py can build with ARCHFLAGS=' -arch x86_64'(add space to before -arch), but I think this fix maybe more user-friendly.\n. ",
    "lsbardel": "I'm not sure how to do that! :disappointed:\nThe issue occurs only when I press Ctril-C on the shell.\nIf I send SIGINT/SIGTERM to the main process not using Ctrl-C, everything works as expected.\nYou can see it yourself by running this script:\npip install git+http://github.com/quantmind/pulsar.git@coroactor#egg=pulsar uvloop\npy scripy.py --io uv\nwhere script.py is\n``` python\nfrom pulsar import MethodNotAllowed\nfrom pulsar.apps import wsgi\ndef hello(environ, start_response):\n    '''The WSGI_ application handler which returns an iterable\n    over the \"Hello World!\" message.'''\n    if environ['REQUEST_METHOD'] == 'GET':\n        data = b'Hello World!\\n'\n        status = '200 OK'\n        response_headers = [\n            ('Content-type', 'text/plain'),\n            ('Content-Length', str(len(data)))\n        ]\n        start_response(status, response_headers)\n        return iter([data])\n    else:\n        raise MethodNotAllowed\ndef server(description=None, kwargs):\n    '''Create the :class:.WSGIServer running :func:hello.'''\n    description = description or 'Pulsar Hello World Application'\n    return wsgi.WSGIServer(hello, description=description, kwargs)\nif name == 'main':  # pragma nocover\n    server().start()\n```\nTry to Ctrl-C and wait for about 5 seconds.\nThan test with the vanilla asyncio loops\npy script.py\nor\npy script.py --io select\n. Right, that is what I suspected.\nPulsar was born before asyncio, that is why multiprocessing module is used for process-based actors.\nI will have to look into the subprocess_exec method and see what exactly does and compare with multiprocessing.\n. OK, using asyncio subprocess_exec fixes the issue.\nLooks like the multiprocessing won't be used directly by pulsar anymore (I still need it for sharing server sockets between processes)\n. Yes it works! Nice one.\nPulsar 1.5 will have two ways of doing multiprocessing, via asyncio subprocess or multiprocessing module. The asyncio way is better because it does not block during forking.\nIn any case thanks for feedback and fixes.\n. In the Master Process\nI create a stream socket\npython\nserver = await loop.create_server(protocol, *address)\nI get the sockets (usually two, ipv4 & v6) and remove their readers from the event loop\npython\nsockets = server.sockets\nfor sock in sockets:\n    loop.remove_reader(sock.fileno())\nAt this point I have the server sockets ready but not registered with the event loop.\nAt this point these sockets are passed to child processes using the multiprocessing socket serialization mechanism.\nIn the Child Process\nThe sockets are registered with the child process event loop\nRemoving versus not removing\nUsing this method I have several child processes serving the socket application but the master process is not serving.\nThis works with vanilla asyncio, but with uvloop, the serialisation fails with the error you see above (your error is a different version of the one I reported but they are caused by the same issue).\nIt looks like uvloop closes the sockets at some point after the remove_reader function call.\nIf I dont' remove the reader in the master process, everything works as expected. Which means the main process will serve the application as well as the workers.\n. As I mentioned above, if I don't remove the reader, multiprocessing socket servers work in pulsar.\nThat is what I'm doing now, therefore this ticket is not as important as I thought it was.\nHowever, it would still be interesting to know why uvloop does not like my original implementation.. > I suggest you to re-implement create_server in your framework (it's a relatively simple method)\nI was trying to avoid doing that :wink:\nAnyway, as I said above, this is no longer an issue for me. Thanks for looking into it.. ",
    "SamWhited": "I was thinking that I couldn't provide a script without requiring that you get an account somewhere, but it doesn't really matter if auth fails; presumably (hopefully) STARTTLS happens before auth. One moment, I'll try to provide a minimal script.\n. > Also, can you reproduce this in vanilla asyncio? The problem is that there's no \"SSL socket\" in 3.5, we use SSL memory BIO, which means that the socket object stays the same.\nI can't; running with normal asyncio I get an ssl.SSLSocket object returned, but if I run with uvloop I always get a socket.socket (which doesn't have a getpeercert() method, so slixmpp panics).\nRequires\nslixmpp==1.2.1\nuvloop==0.5.4\nMWE\n(note that this appears to be flakey; you may have to run it once or twice to see the issue)\n``` python\n!/usr/bin/env python3\nimport asyncio\nimport uvloop\nfrom slixmpp import ClientXMPP\nif name == \"main\":\n    asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\n    loop = asyncio.get_event_loop()\nclient = ClientXMPP(\"fakeaccount@samwhited.com\", \"fakepassword\")\nclient.loop = loop\nclient.connect()\n\nloop.run_forever()\n\n```\n. For context, the starttls connection is being created in Slix with:\npython\nssl_connect_routine = self.loop.create_connection(lambda: self, ssl=self.ssl_context,                            \n                                                  sock=self.socket,                                              \n                                                  server_hostname=self.default_domain)\nSee: https://github.com/poezio/slixmpp/blob/master/slixmpp/xmlstream/xmlstream.py#L472\n. Another related difference, it appears that the ssl_object extra info also contains the ssl.SSLSocket in asyncio's default event loop, but contains ssl.SSLObject in uvloop (which makes more sense, given the name). I'm not entirely sure these even count as a stable API that should be the same though (I didn't see them documented anywhere), but I don't know how else we'd get a reference to the socket or SSL socket, so I assume at least socket should have the same value in different implementations.\n. Sorry for all the spam, one more thing: This does appear to be a documented API (https://docs.python.org/3/library/asyncio-protocol.html), and it appears that uvloop is doing things right and asyncio's built in event loop (and slix) is doing it wrong. According to the docs, socket should always map to a socket.socket, and ssl_object should map to an SSLObject or an SSLSocket, so I'm inclined to beleive that uvloop is in the right. Closing this issue.\n. > I don't understand how can you have SSLSocket on 3.5.2 in asyncio at all.\nI don't know much about it, but it appears to be some hackery slixmpp is doing to use the old SSL, no idea why. From their chat room:\n10-06 12:44 <== <mathieui> but we use the old-style SSL implementation in asyncio\n10-06 12:44 <== <mathieui> because I had issues with the new one\nRelated issues that I failed to find before:\n- https://bugs.python.org/issue22768\n- https://bugs.python.org/issue25114\n. >  Perhaps there is a bug that should be fixed ASAP, before Python 3.6 is out.\nI think it was just that the ssl_object wasn't being set on 3.4 (see the issues I posted, that regression has already been fixed). I'll try to get more info out of them though, and submit a patch if anything is required on the asyncio side.\nEDIT: Update for issue historians: jank workaround for the 3.4 regression submitted: https://github.com/poezio/slixmpp/pull/5/files\n. ",
    "styvane": "Hi @1st1, I was about to file the same bug. Just ran into this. Also this doesn't release the interpreter, I have to use kill -9 \n- Python 3.6.0b1\n- asyncpg==0.5.4\n- uvloop==0.5.3\nCode:\n```\nimport asyncio\nimport uvloop\nimport asyncpg\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nloop = asyncio.get_event_loop()\nstatement = 'select id from dict.operators where country_id = ANY($1::varchar[])'\ndns = 'postgres://postgres:password@127.0.0.1:5432/test'\nasync def get_id(pool, statement, countries):\n    async with pool.acquire() as con:\n        stmt = await con.prepare(statement)\n        return await stmt.fetch(countries) \nasync def run(dns, countries):\n    async with asyncpg.create_pool(dns) as pool:\n        print(await get_id(pool, countries))\nloop.run_until_complete(run(dns, ['AF', 'CI', 'SD', 'SS']))\n```\nWhich returns the result with a traceback:\n```\n[, , , , , , , , , , , , , , , ]\nException in callback \nhandle: \nTraceback (most recent call last):\nFile \"uvloop/cbhandles.pyx\", line 57, in uvloop.loop.Handle._run (uvloop/loop.c:38264)\nFile \"uvloop/task.pyx\", line 202, in uvloop.loop.BaseTask._wakeup (uvloop/loop.c:101008)\nFile \"uvloop/task.pyx\", line 195, in uvloop.loop.BaseTask._fast_wakeup (uvloop/loop.c:100711)\nFile \"uvloop/task.pyx\", line 159, in uvloop.loop.BaseTask._fast_step (uvloop/loop.c:99772)\nAttributeError: '_GatheringFuture' object has no attribute '_blocking'\n```\n. ",
    "smortus": "Confirm. With uvloop 0.5.4 app running normal. Thank you.\n. ",
    "mikeputnam": "Hmm... I see.  Closing!\n. ",
    "Dexus77": "\nYes, the problem is when connect via unix socket.\nTest add. Main config Nginx - default.\nSorry, no other OS.\n\ntestapp.zip\n. ",
    "p1otr": "I plan to package it for Debian and even though it's only one additional line in my Makefile (debian/rules) - I'm lazy and I don't like hacks (anymore :)\nThe more people use it (and more will regenerate .c file if it's in setup.py) - the less work for me later... and you want more people to regenerate it, run tests, etc. f.e. to detect bugs like https://bugs.python.org/issue28634 early - thanks for the fix, BTW!\n. ",
    "mayfield": "Hi Yury,\nI believe the CPU is being burned in the libuv poll here, \nhttps://github.com/libuv/libuv/blob/v1.x/src/unix/linux-core.c#L327-L348\nThat in itself may be a libuv bug but I have less experience with their community to say for certain.\nFrom what I've gathered epoll is susceptible to confusion when you feed it a dup() FD, then close the dup() based FD but leave the original file description open.  As far as epoll is concerned the file description (not descriptor) pointed to by the dup() based FD is still open, so it may trigger events for an FD that is no longer valid;  Attempts to use EPOLL_CTL_DEL on that FD will fail as you can see in the strace output.\nSome context from epoll(7)..\n\nQ6  Will closing a file descriptor cause it to be removed from all epoll sets automatically?\nA6  Yes,  but  be aware of the following point.  A file descriptor is a reference to an open file description (see open(2)).  Whenever a file descriptor is duplicated via dup(2),\n           dup2(2), fcntl(2) F_DUPFD, or fork(2), a new file descriptor referring to the same open file description is created.  An open file description continues to  exist  until  all\n           file  descriptors  referring to it have been closed.  A file descriptor is removed from an epoll set only after all the file descriptors referring to the underlying open file\n           description have been closed (or before if the file descriptor is explicitly removed using epoll_ctl(2) EPOLL_CTL_DEL).  This means that even after a file descriptor that  is\n           part of an epoll set has been closed, events may be reported for that file descriptor if other file descriptors referring to the same underlying file description remain open.\n\nRegarding calling remove_* first:  In this case it is being called first, but the underlying epoll_ctl(EPOLL_CTL_DEL) runs later due to the mechanics of libuv.  I think it's flagged for removal and handled later in another context but I didn't deep dive into that to be honest.\nThe python code that produced this result is from aiohttp and the only setup required was to serve a single, but large, file over a link that will cause os.sendfile to raise BlockingIOError.\nhttps://github.com/KeepSafe/aiohttp/blob/master/aiohttp/file_sender.py#L103-L110\nAs you can see, that code will always call remove_writer before calling socket.close but if you look closely at the strace output you will see that close() runs first.\n. Here is a simplified test that will reproduce the issue.\n``` python\nimport os\nimport uvloop\nloop = uvloop.EventLoopPolicy().get_event_loop()\nrfd, wfd = os.pipe()\nwfd2 = os.dup(wfd)\ndef on_write_event():\n    loop.remove_writer(wfd2)\n    os.close(wfd2)\nloop.add_writer(wfd2, on_write_event)\nloop.run_forever()\n```\n. My test cases are passing now.  Thank you very much @1st1!. I've been just using time.process_time() to check CPU usage after letting the loop run for a second.  I wouldn't be comfortable putting that into a unittest but here it is for reference..\n```python\nimport asyncio\nimport os\nimport time\nimport uvloop\nloop = uvloop.EventLoopPolicy().get_event_loop()\nrfd, wfd = os.pipe()\nwfd2 = os.dup(wfd)\ndef on_write_event():\n    print(\"   START REMOVE\")\n    loop.remove_writer(wfd2)\n    print(\"   DONE REMOVE - START CLOSE\")\n    os.close(wfd2)\n    print(\"   DONE CLOSE\")\nloop.add_writer(wfd2, on_write_event)\nct = time.process_time()\nloop.run_until_complete(asyncio.sleep(0.100, loop=loop))\nloop_cputime = time.process_time() - ct\nassert loop_cputime < 0.050, 'libuv is running hot!'\n```. ",
    "srikawnth": "Is this fix added in C library of libuv as well?. ",
    "ahartikainen": "Hi, what is the current situation with Windows support?\nIs the problem with msvc and if so, could mingw64-w64 used to circumvent those problems?\nI'am happy to help, but not sure where to start.\nps We are using this package with https://github.com/stan-dev/httpstan. ",
    "superstarrr": "Finally I figure it out, it is caused by the incorrect position of installing code.\nThe installing code is put under one imported module which creates an instance of aiohttp.ClientSession(), for example,\n```python\nmain.py\nimport asyncio\nfrom foo import Foo\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nasync def fetch(url):\n    foo = Foo()\n    async with foo.session.get(url) as resp:\n        # RuntimeError will be raised here\n        pass\nloop = asyncio.get_event_loop()\nloop.run_until_complete(fetch('http://example.com'))\nfoo.py\nimport aiohttp\nclass Foo():\n    session = aiohttp.ClientSession()    # to share session between instances of Foo\n```\n. I have to admit that it is a bad idea. And will remove these lazy code. Thanks!. ",
    "NotSoSuper": "Yeah, here: https://gist.github.com/NotSoSuper/8eb4305309a85c6dbc4dfa9a8157a876\nThe issue which I got the get_child_watcher code was from https://github.com/python/asyncio/issues/281\nI woke up this morning with 1k+ zombie processes, the only explanation I could find was the subprocess functions I was using.. Most of the commands are usually ffmpeg which takes only a few seconds, others are stuff like cowsay, so nothing that takes too long. I'll try that, thanks.. Yeah, just tried this and it never ends: https://gist.github.com/NotSoSuper/df228346bc9645d105216d9f8c2fe38b\nThing I can't explain here is that in my main projects code the function returns the result from cowsay or etc but this script won't return anything, not sure..\nEdit: Ending the python repl session returned 'done'. Yeah, putting it into a python script file and running it returned the same but I'm getting zombie processes from somewhere when this is run.. ",
    "atbentley": "Thanks for the quick fix, Yury!. ",
    "livercat": "Should I try to reproduce the issue without uvloop, or does the commit above resolve it in any case?\nThank you.. I was able to reproduce the RuntimeError in asyncio without uvloop. Closing this issue.\nThank you.. Update: this issue manifested when aiohttp tried to cleanup closed SSL transports. This was default behavior until aiohttp 2.0.5, and doesn't reproduce after. To avoid this issue with earlier versions of aiohttp, set disable_cleanup_closed=True when creating the TCPConnector.. > Does this mean that there's a bug in CPython ssl or asyncio/sslproto?\nJudging by the comment in the aiohttp cleanup routine, it might be a bug in asyncio:\n:param tuple enable_cleanup_closed: Some ssl servers do not properly complete ssl shutdown process, in that case asyncio leaks ssl connections. If this parameter is set to True, aiohttp additionally aborts underlining transport after 2 seconds. It is off by default.. Awesome, thank you!\nEdit: found the relevant PR: https://github.com/python/cpython/pull/409. ",
    "ignatenkobrain": "$ python3 --version\nPython 3.6.0\n$ cython3 --version\nCython version 0.25.2\nHere is full build log: https://ignatenkobrain.fedorapeople.org/uvloop.log. @elprans hmm. you can run docker container with fedora:rawhide image, update it, install dnf-plugins-core package and:\n$ curl -O https://ignatenkobrain.fedorapeople.org/for-review/python-uvloop-0.7.0-1.fc26.src.rpm\n$ sudo dnf -y builddep ./python-uvloop-0.7.0-1.fc26.src.rpm\n$ rpmbuild --rebuild ./python-uvloop-0.7.0-1.fc26.src.rpm. ",
    "jasonab": "Appreciate the feedback, I'll look into making those suggestions to aredis.. ",
    "stuaxo": "Awesome, cheers - I'll give it a go :). ",
    "fafhrd91": "i am fine with that. one problem is public name asyncio.TimeHandle. ",
    "Noctem": "@1st1 I'm not completely sure, other than that the problem started occurring in this commit of my project: Noctem/Monocle@d51220a\nI assume it's related to the new call_laters here and here. So it's executing thousands of call_laters an hour with delay times of up to one hour. I've only tested it on macOS so far. Is there anything I could do that would make debugging the issue easier for you?\nBy the way, my instance with the Python event loop has now been running for 10 hours without issue.. Here's a new and somewhat different looking crash report:\nPython_2017-02-04-190530_Noctem-Desktop.crash\nIt ran 24 minutes before segfaulting this time.. Okay, this seems to reliably reproduce it on my system:\n```python\n!/usr/bin/env python3\nfrom threading import Thread\nfrom random import random\nfrom uvloop import EventLoopPolicy\nimport time\nimport asyncio\nasyncio.set_event_loop_policy(EventLoopPolicy())\nloop = asyncio.get_event_loop()\nsync_count = 0\nasync_count = 0\ndef sync_print():\n    global sync_count\n    sync_count += 1\n    print('sync', sync_count)\ndef sync_launcher():\n    for _ in range(5000):\n        time.sleep(0.001)\n        loop.call_later(random(), sync_print)\nasync def async_print():\n    global async_count\n    async_count += 1\n    print('async', async_count)\ndef async_launcher():\n    for _ in range(5620):\n        time.sleep(.001)\n        asyncio.run_coroutine_threadsafe(async_print(), loop)\nasync_thread = Thread(target=sync_launcher)\nasync_thread.start()\nsync_thread = Thread(target=async_launcher)\nsync_thread.start()\ntry:\n    loop.run_forever()\nexcept KeyboardInterrupt:\n    loop.stop()\n    loop.close()\n``\nThe test script operates similarly (at a basic level) to my project. There's one thread that's launching coroutines withrun_coroutine_threadsafe()and there's another thread that I recently started usingcall_laterin. I guess sincecall_later` isn't thread-safe this is dangerous, and yet CPython's event loop runs this intentionally deadly script without issue.\nIs there a simple way to schedule delayed calls that is thread-safe? I want to reduce the threading in my application, but for now my DB operations are synchronous and it's the DB thread that is adding to and scheduling removals from a cache.. Thanks for that snippet. Noctem/monocle@69896c458796f86589808b45336610b79fb8974a seems to have fixed it.\nI should have realized sooner that threading was the issue.. ",
    "Sniedes722": "The loop compiles fine when I install sanic using package installer. however, trying to independently build the loop through pip does not. . @1st1 yup builds fine for 3.5.2 & 3.6.0. Thanks. . ",
    "bright-pan": "hi, \ni test it but i can`t reproduct it.\n```\nconnecting to mongodb!\n/Users/jason/.pyenv/versions/pulsar-env/lib/python3.6/site-packages/sanic/sanic.py:454: DeprecationWarning: Passing a loop will be deprecated in version 0.4.0 https://github.com/channelcat/sanic/pull/335 has more information.\n  DeprecationWarning)\n2017-03-18 09:50:53,717: DEBUG: \n                 \u2584\u2584\u2584\u2584\u2584\n        \u2580\u2580\u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2584\u2584\u2584       ___\n      \u2584\u2584\u2584\u2584\u2584  \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2584  /                 \\\n     \u2580\u2580\u2580\u2580\u2588\u2588\u2588\u2588\u2588\u258c \u2580\u2590\u2584 \u2580\u2590\u2588 |   Gotta go fast!  |\n   \u2580\u2580\u2588\u2588\u2588\u2588\u2588\u2584\u2584 \u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2584\u2588\u2588 | _____/\n   \u2580\u2584\u2584\u2584\u2584\u2584  \u2580\u2580\u2588\u2584\u2580\u2588\u2550\u2550\u2550\u2550\u2588\u2580 |/\n        \u2580\u2580\u2580\u2584  \u2580\u2580\u2588\u2588\u2588 \u2580       \u2584\u2584\n     \u2584\u2588\u2588\u2588\u2580\u2580\u2588\u2588\u2584\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2584 \u2584\u2580\u2580\u2580\u2580\u2580\u2580\u2588\u258c\n   \u2588\u2588\u2580\u2584\u2584\u2584\u2588\u2588\u2580\u2584\u2588\u2588\u2588\u2580 \u2580\u2580\u2588\u2588\u2588\u2588      \u2584\u2588\u2588\n\u2584\u2580\u2580\u2580\u2584\u2588\u2588\u2584\u2580\u2580\u258c\u2588\u2588\u2588\u2588\u2592\u2592\u2592\u2592\u2592\u2592\u2588\u2588\u2588     \u258c\u2584\u2584\u2580\n\u258c    \u2590\u2580\u2588\u2588\u2588\u2588\u2590\u2588\u2588\u2588\u2592\u2592\u2592\u2592\u2592\u2590\u2588\u2588\u258c\n\u2580\u2584\u2584\u2584\u2584\u2580   \u2580\u2580\u2588\u2588\u2588\u2588\u2592\u2592\u2592\u2592\u2584\u2588\u2588\u2580\n          \u2580\u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2580\n        \u2584\u2584\u2588\u2588\u2580\u2588\u2588\u2588\u2588\u2588\u2588\u2580\u2588\n      \u2584\u2588\u2588\u2580     \u2580\u2580\u2580  \u2588\n     \u2584\u2588             \u2590\u258c\n \u2584\u2584\u2584\u2584\u2588\u258c              \u2580\u2588\u2584\u2584\u2584\u2584\u2580\u2580\u2584\n\u258c     \u2590                \u2580\u2580\u2584\u2584\u2584\u2580\n \u2580\u2580\u2584\u2584\u2580\n2017-03-18 09:50:53,717: INFO: Goin' Fast @ http://127.0.0.1:5000\n2017-03-18 09:50:53,717: INFO: Goin' Fast @ http://127.0.0.1:5000\nconnected to mongodb!\n```. ",
    "rudineirk": "You have to start the application without mongodb running (or with an invalid host), the problem happens after the first connection retry (about 5 seconds after the process started). ",
    "btegs": "Is this something PyPy needs to work out or is this an issue the uvloop team will investigate?. So what would the solution be down the road? Converting uvloop away from Cython to cffi or to have a fork of uvloop that is cffi that can be run by PyPy3?. I'll give it a go again when I get home, but I did revert to uvloop 0.8.1 and it ran without a hitch.. This isn't my project, so the fixing will have to come on yours or japronto's end.. True, but when the maintainer of this project, @squeaky-pl is saying \"I hinted the issue author what he needs to do to fix it\" it shows that he doesn't care about this project and it should be moved to inactive status. It works with uvloop 0.8.1 but you don't want to force people to downgrade their packages. . ",
    "delfick": "This problem only seems to happen in prod, where we have enough load, so we turned it on for half an hour in prod.\nDuring that time nothing crashed and we can't seem to find any log messages that would indicate something worth looking at (only things like \"Executing  took 0.386 seconds\").\nIt also seemed to slow down things enough that we were forced to turn it off.. The good news is we turned off uvloop and it was still segfaulting, so the core dump above is most like a red herring..... ",
    "frederikaalund": "For the record, the workaround does not work. local_ip contains ('0.0.0.0', 34252).. Thank you very much. I'll try the master branch on Monday.. Works here, thanks!. > Do we need to do this for all platforms or for Linux+arm only?\nGood point. Theoretically, it's needed for all operating systems that use POSIX threads, which is most Unix-like operating systems (Linux, MacOS, etc.). Practically speaking, that is every platform except Windows.\nI'm surprised that I'm the first person to get the undefined symbol error. Apparently, this error only triggers in the Linux + ARM combination? Anyhow, linking explicitly against pthread is the way to go.\nAlso, consider using -pthread instead of -lpthread. I know that I use -lpthread in my patch; I learnt about the difference after making the pull request.. ",
    "JelleZijlstra": "Thanks!. ",
    "tonal": "Can you test for Pothon 3.6.x?. ",
    "alex-eri": "best was sanic workers. what is \"sanic workers\"?. ",
    "kura": "Might be worth doing a couple of things;\n\nCheck what your max processes and max open file descriptors are set to. You can do this with ulimit -a.\n    I'd say while it's unlikely you'll be hitting max processes. if you're running this quite frequently during testing you may easily hit the open files limit, especially if it's causing unclean process shutdown.\nCheck how much entropy you have in urandom. That may be doing things that cause bad behaviour or hanging for a process. I've seen weird cases where distros mess with urandom that are really not nice.\n\nFYI, I tested this code on a high spec test rig, found it failed fairly frequently when set to length of 1000000, so I tested it hundreds more times with a random delay between test periods with different length values. All of my tests had zero errors up to and including a length of 100000, I tried 250000, 500000, and 750000, all three of these lengths resulting errors with the default range(50) provided in your example.\n\nlength 10000 fails 0\nlength 50000 fails 0\nlength 100000 fails 0\nlength 250000 fails 91/100\nlength 500000 fails 89/100\nlength 1000000 fails 92/100. Cool! Well, that would totally explain it. You OK to copy this issue to CPython issues?. Rgr that.. \n",
    "ghost": "@kura Well using /dev/urandom was just a cheap way to open file descriptors and generate data, the same problems appear on my computer with the command \"yes | head -c %s\" and a length of 10,000,000, even after removing the limits on the number of open file descriptors.. Can confirm this also.\nIf it is any use, this is the traceback I get for this.\npython\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ashley/code/n3/n3/__main__.py\", line 57, in <module>\n    main()\n  File \"/home/ashley/code/n3/n3/__main__.py\", line 47, in main\n    import uvloop\n  File \"/home/ashley/code/n3/venv/lib/python3.7/site-packages/uvloop/__init__.py\", line 7, in <module>\n    from .loop import Loop as __BaseLoop  # NOQA\n  File \"uvloop/includes/stdlib.pxi\", line 41, in init uvloop.loop\nAttributeError: module 'asyncio.coroutines' has no attribute 'debug_wrapper'\nPlatform: Python3.7b4, Ubuntu 16.04.3 LTS x64\n. ",
    "samuelcolvin": "code demo.py:\n```python\nimport asyncio\nfrom arq import Actor, BaseWorker, concurrent\nimport uvloop\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nclass DemoActor(Actor):\n    @concurrent\n    async def foobar(self, a):\n        print(a)\nclass Worker(BaseWorker):\n    shadows = [DemoActor]\nasync def enqueue_jobs():\n    d = DemoActor()\n    await d.foobar('hello')\n    await d.foobar('world')\n    await d.close()\nif name == 'main':\n    loop = asyncio.get_event_loop()\n    loop.run_until_complete(enqueue_jobs())\n```\nrun:\npip install arq uvloop\npython demo.py  # enqueues some jobs, not necessary to cause the error but helps explain whats going on\narq demo.py # you should see the jobs execute\nctrl + c  # you should see the error\nIf you comment out the two uvloop lines it should work fine.. (oh, and you need redis installed). @1st1 did you have a chance to look at this? Is there anything else I can do to help?. I guess my mistake, I'll try add_signal_handler and let you know whether that fixes it.. https://github.com/samuelcolvin/arq/blob/master/arq/worker.py#L435. Thanks so much for the explanation.\nI've started a PR https://github.com/samuelcolvin/arq/pull/73 to implement both your suggestions.. I know signals are tricky. I built arq partly because libraries like rq handle signals in strange ways. :-)\nThey're made more difficult because it's virtually impossible to write proper tests for all cases.\nI'll definitely test a lot manually before I release and updated with this change.. I can confirm this fixes shutdown behaviour with python 3.6.5 and aiohttp 3.3.2.\nWould be great to get this merged and released.. ",
    "Glandos": "Yes, but the host parameter is the one received from datagram_received, so it theoretically could be a FQDN.\nEDIT: I don't know if there is a fast test to tell if the host is an IP address or not.. ",
    "myusuf3": "any updates on this? blocking progress up stream willing to work to get it fixed. . @1st1 can you tell where the issue is? how you would go about fixing it, I can dive in. Thanks for responding so quick. . @1st1 huzzah!!. ",
    "tomitm": "I believe I know what the issue is, but not familiar enough to setup and test this - feel free to give this a try @myusuf3.\nLooking at the trace, the issue is here while aiocoap called with family=socket.AF_INET6.\nhttps://github.com/MagicStack/uvloop/blob/490c41032172b1a7d365ea83642aff7696ef9fc1/uvloop/loop.pyx#L2421-L2436\nIt's an IPv6 socket binding to an IPv4 address. 0.0.0.0 is not a valid IPv6 address, hence the Address family for hostname not supported error.\nShould check if family is AF_INET6 and bind to :: or ::/0 instead, which is the IPv6 equivalent of 0.0.0.0.. ",
    "lwis": "@myusuf3 is this something you could take a look at? If not I can probably set some time aside in a 3-4 days.. @1st1 you da man, let us know if you need us to test bud :+1: . For those interested, I just tested a quick fix for this;\nhttps://github.com/chrysn/aiocoap/blob/a2c2abe28107af0d492fac715f915dd3307d4a31/aiocoap/transports/udp6.py#L142 fails with;\ntraceback\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/site-packages/homeassistant/setup.py\", line 191, in _async_setup_component\n    result = yield from component.async_setup(hass, processed_config)\n  File \"/usr/lib/python3.6/site-packages/homeassistant/components/tradfri.py\", line 107, in async_setup\n    allow_tradfri_groups))\n  File \"/usr/lib/python3.6/site-packages/homeassistant/components/tradfri.py\", line 121, in _setup_gateway\n    api = yield from api_factory(host, key, loop=hass.loop)\n  File \"/config/deps/lib/python3.6/site-packages/pytradfri/api/aiocoap_api.py\", line 46, in api_factory\n    _protocol = yield from Context.create_client_context(loop=loop)\n  File \"/usr/lib/python3.6/site-packages/aiocoap/protocol.py\", line 524, in create_client_context\n    self.transport_endpoints.append((yield from TransportEndpointUDP6.create_client_transport_endpoint(new_message_callback=self._dispatch_message, new_error_callback=s$\nlf._dispatch_error, log=self.log, loop=loop, dump_to=dump_to)))\n  File \"/usr/lib/python3.6/site-packages/aiocoap/transports/udp6.py\", line 179, in create_client_transport_endpoint\n    return (yield from cls._create_transport_endpoint(new_message_callback, new_error_callback, log, loop, dump_to, None, multicast=False))\n  File \"/usr/lib/python3.6/site-packages/aiocoap/transports/udp6.py\", line 142, in _create_transport_endpoint\n    sock = transport._sock\nAttributeError: 'uvloop.loop.UDPTransport' object has no attribute '_sock'. @1st1 feel free to release, I believe the issue is resolved from your end and the incompatibility now resides downstream in aiocoap. Thanks!. ",
    "terrisgit": "I am also hitting this problem. Thank you for this package!. I'd be happy to try this but I don't think I have the time or skill to build it.. ",
    "Terris-Dianomic": "See also https://github.com/chrysn/aiocoap/issues/84. ",
    "chenfengyuan": "Maybe we could use a socket wrapper that makes close and other methods async, to avoid this problem entirely.I suppose asyncio without uvloop also need an async version of close( in this gist asyncio will wait forever on sock_recv). Or can we use a modified version of libuv?  There is already a libuv compatible hack. @1st1 I filed an issue months ago (https://bugs.python.org/issue30996).\nI suppose callback or loop.sock_close can solve the problem to some degree. Either way is better than do nothing.. ",
    "ly0": "it's very helpful to me!. ",
    "cmcqueen": "My Yocto bitbake recipe python3-uvloop_0.8.0.bb is as follows:\nDESCRIPTION = \"Fast implementation of asyncio event loop on top of libuv\"\nHOMEPAGE = \"https://pypi.python.org/pypi/uvloop\"\nSECTION = \"devel/python\"\nLICENSE = \"MIT & Apache-2.0\"\nLIC_FILES_CHKSUM = \"file://LICENSE-MIT;md5=3bd0b2e751776b370b2151ac508af939 \\\n                    file://LICENSE-APACHE;md5=dc498442db12459256eff4dcbc80c32f\"\n\nFILESEXTRAPATHS_prepend := \"${THISDIR}/${PN}:\"\n\nSRCNAME = \"uvloop\"\n\nSRC_URI = \"https://files.pythonhosted.org/packages/source/u/${SRCNAME}/${SRCNAME}-${PV}.tar.gz\"\n\nSRC_URI[md5sum] = \"279163a7b8f39dc15007cf76e3a92c02\"\nSRC_URI[sha256sum] = \"2c22f1f0b6e00e99f5ee635993e5f26418e740bd26f1214cf78c70f237eec06b\"\n\nSRC_URI += \"file://0001-Allow-for-cross-compile-of-libuv.patch\"\nSRC_URI += \"file://0001-Specify-pthread-library-dependency-for-uvloop.loop-e.patch\"\n\nS = \"${WORKDIR}/${SRCNAME}-${PV}\"\n\nDEPENDS = \"${PYTHON_PN}-cython-native\"\n\nBBCLASSEXTEND = \"native\"\n\ninherit setuptools3\n\ndo_compile_prepend() {\n    export HOST_SYS=${HOST_SYS}\n}\n\ndo_install_prepend() {\n    export HOST_SYS=${HOST_SYS}\n}\n\nI'm currently using Yocto morty branch.. I'm not sure if those patches are suitable for incorporating into the mainline code. If you think they are, I could submit a pull request.. I've tried uvloop v0.9.0, and it fixes the two issues nicely. Thanks very much!. This is for issue #104.. ",
    "Sherlock-Holo": "I install it by AUR python-uvloop. I used Arch official repo libuv and then build_ext --use-system-libuv\nbuild_py, now I can installed it on my Arch. I written a comment about it\non aur python-uvloop waiting for maintainer reply me.\nAlireza Mosajjal notifications@github.com\u4e8e2017\u5e749\u670811\u65e5\u5468\u4e00 \u4e0b\u53488:27\u5199\u9053\uff1a\n\nI recommend using a virtualenv and installing it with pip. Works\nperfectly for me.\n$ python3 -m venv uvloop-venv\n$ cd uvloop-venv\n$ source bin/activate\n$ pip install uvloop\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/MagicStack/uvloop/issues/107#issuecomment-328513517,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJoPKWiGwHgn_dnrySi_dgfZKpZGjL8Yks5shSc9gaJpZM4PMVQ0\n.\n. I forgot if I met this problem, but I guess the build script about uvloop\nhas some problems because I rewrite the Arch pkgbuild about uvloop and\nfixed some problems like yours\n\nAlex Kuzmenko notifications@github.com \u4e8e 2017\u5e7412\u67086\u65e5\u5468\u4e09 17:01\u5199\u9053\uff1a\n\n\nuvloop version: 0.9.1\nPython version: 3.6\nPlatform: Ubuntu Xenial\n\nVersion 0.9.1:\nI got an error\nFile \"/app/app/<>/utils.py\", line 35, in <>\n    async with app['client_session'].get(url) as response:\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/client.py\", line 690, in aenter\n    self.resp = yield from self._coro\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/client.py\", line 267, in _request\n    conn = yield from self._connector.connect(req)\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\", line 402, in connect\n    proto = yield from self._create_connection(req)\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\", line 748, in _create_connection\n    , proto = yield from self._create_direct_connection(req)\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\", line 831, in _create_direct_connection\n    req=req, client_error=client_error)\n  File \"/usr/local/lib/python3.6/dist-packages/aiohttp/connector.py\", line 796, in _wrap_create_connection\n    return (yield from self._loop.create_connection(args, *kwargs))\nTypeError: 'coroutine' object is not iterable\nVersion 0.8.1:\nNot reproduced\nThe error does not depend on other libraries.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/MagicStack/uvloop/issues/122, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AJoPKUG3ZBQ4l1ck6TYOBd86OcJwziOsks5s9lfigaJpZM4Q3kuJ\n.\n. oh, it compiles failed again, \ud83d\ude02 I have to compile on my PC, and succeed.\nso sad for my small memory VPS\ud83d\ude02\n\nYury Selivanov notifications@github.com \u4e8e 2018\u5e746\u67086\u65e5\u5468\u4e09 05:14\u5199\u9053\uff1a\n\nClosed #167 https://github.com/MagicStack/uvloop/issues/167.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/MagicStack/uvloop/issues/167#event-1664746347, or mute\nthe thread\nhttps://github.com/notifications/unsubscribe-auth/AJoPKVDim1iARrHJSHXN37KjKor622exks5t5vSlgaJpZM4UatL9\n.\n. \n",
    "mosajjal": "I recommend using a virtualenv and installing it with pip. Works perfectly for me.\n$ python3 -m venv uvloop-venv\n$ cd uvloop-venv\n$ source bin/activate\n$ pip install uvloop. ",
    "chrysn": "More precisely, it does not work without further options with IPv6; setting family=AF_INET6 does make a ::1 connection work, but then again doesn't allow v4 addresses to be used without prior inspection of the address for which family to set. Passing flags=socket.AI_V4MAPPED in addition to family creates a default behavior that seems to be equivalent to asyncio's. (asyncio claims that it decides based on host's value which family it chooses; I did not verify that, and only looked at the simple test's behavior).. ",
    "industrialsynthfreak": "I can confirm. No difference on Sierra for both 0.7.x and 0.8.x.. ",
    "cjrh": "Verified, works against Python nightly in one of my projects :100: . ",
    "oneek": "As you can see, Python.h header file is not available in your system.\nHow to fix this you can see in this SO answer: https://stackoverflow.com/a/21530768. ",
    "mkn2016": "OMG...it was right in-front of me all i had to do was look. Fixed it. Can't thank you in enough!. ",
    "jlaine": "@soonum could you please share your test as requested by @1st1 ?. Let's hope so! I had a quick chat with @saghul at FOSDEM mentioning UDP performance improvements in uvloop were currently tied to uv 2.x plans... Yay, this PR landed:\nhttps://github.com/libuv/libuv/pull/2217\n.. and is released in libuv 1.27\n@1st1 could we have an update of the bundled libuv so we can try and make use of this feature?. The release has actually been tagged :). Thanks for bumping the libuv version, I'll do a bit of archeology to see what the old implementation looked like.\nCan we retain the caching logic I added for address validation though? In the case of an unconnected socket it's still nice not to hit the slow validation code.. This looks like a real bug, still present in the current code:\nhttps://github.com/MagicStack/uvloop/blob/d5ad2b86fff1bf08a391aa344561e69c98be3b66/uvloop/handles/udp.pyx#L168\nI don't understand why we need to check self.address at all to be honest. As far as I can tell, the only way for _conn_lost to be set for UDPTransport is if close() or _force_close() was called. This is not dependent on whether a remote address was provided when creating the endpoint.. @Forevka69 did 0.12.0rc1 solve your issue?. There is a work in progress PR at #224 . PR #224 has landed, fixing this issue. The trivial patch I used:\n```patch\ndiff --git a/uvloop/handles/udp.pxd b/uvloop/handles/udp.pxd\nindex 4f03650..25a7e61 100644\n--- a/uvloop/handles/udp.pxd\n+++ b/uvloop/handles/udp.pxd\n@@ -3,6 +3,7 @@ cdef class UDPTransport(UVBaseTransport):\n         object sock\n         UVPoll poll\n         object address\n+        object last_address\n         object buffer\n cdef _init(self, Loop loop, object sock, object r_addr)\n\ndiff --git a/uvloop/handles/udp.pyx b/uvloop/handles/udp.pyx\nindex 81ad198..6ecc489 100644\n--- a/uvloop/handles/udp.pyx\n+++ b/uvloop/handles/udp.pyx\n@@ -6,6 +6,7 @@ cdef class UDPTransport(UVBaseTransport):\n         self.sock = None\n         self.poll = None\n         self.buffer = col_deque()\n+        self.last_address = None\n         self._has_handle = 0\n cdef _init(self, Loop loop, object sock, object r_addr):\n\n@@ -143,7 +144,7 @@ cdef class UDPTransport(UVBaseTransport):\n             raise ValueError(\n                 'Invalid address: must be None or {}'.format(self.address))\n\nif addr is not None and self.sock.family != socket.AF_UNIX:\nif addr not in (None, self.last_address) and self.sock.family != socket.AF_UNIX:\n             addrinfo = __static_getaddrinfo_pyaddr(\n                 addr[0], addr[1],\n                 uv.AF_UNSPEC, self.sock.type, self.sock.proto, 0)\n@@ -155,6 +156,7 @@ cdef class UDPTransport(UVBaseTransport):\n                 raise ValueError(\n                     'UDP.sendto(): {!r} socket family mismatch'.format(\n                         addr))\nself.last_address = addr if self._conn_lost and self._address:\n     if self._conn_lost >= LOG_THRESHOLD_FOR_CONNLOST_WRITES:\n\n``. I also tried something else: simply storing the socket'sfamily,protoandtypeasintmembers ofUDPTransport. This doesn't skip the call togetaddrinfo` but gives a significant performance gain which holds no matter whether it's an address we have already seen or not. The same test runs in 4.3s with this patch.\n\n\nRegarding lru_cache wouldn't that mean dropping out of C and back into Python?\n. It looks like lru_cache performance is really not an issue. With the patch I submitted in #215 my test now runs in 3.1s, so almost identical to the \"single address cache\" version!. > Speaking of which -- when libuv 2.0 is released we'll likely be able to switch to native UDP libuv implementation which should be significantly (up to 10x) faster than what we have now.\nI'm very eager to see this in action, and would be happy to help if I can! It doesn't look as though UDP is getting as much love in the asyncio world as TCP is, but that might change with the likes of HTTP/3.. Thanks for the amazingly fast turnaround!. You are most welcome! Are there any blockers which need to be addressed for the 0.12.0 release which I could help with?. Ouch, I was hoping the performance optimization would go in as well since currently uvloop's UDP send performance is worse than vanilla asyncio, meaning you have to choose between a fast event loop and fast UDP transmission... Since we seem to use the Python test suite's certificates we can make use of:\nhttps://github.com/python/cpython/commit/e6dac0077996b1e1f886f036d6f2606237fa4c85. I have submitted PR #218 to update the test certificate / key. This was fixed by PR #224 . I'm guessing this issue should be closed since d8fe153e5b67de1124b828f9c9b3c5397ac68d5d has landed?. > > * Currently one test fails because the previous code caught an OSError and re-raised it with a different message. Is this a behaviour we want to preserve?\n\nUsually we try to match (exactly) OSErrors that Python asyncio is raising, down to the message of the exception. Is that the case in the previous code?\n\nAFAICT, cpython only wraps OSError when calling sock.bind():\nhttps://github.com/python/cpython/blob/bb3c05d7efca8d23bf39bc2640297ba2598899f3/Lib/asyncio/base_events.py#L940\n.. but not when calling sock.listen():\nhttps://github.com/python/cpython/blob/bb3c05d7efca8d23bf39bc2640297ba2598899f3/Lib/asyncio/base_events.py#L290\n\n\nThe bit that bothers we: why does Server have a list of servers, can there really be anything other than 0 or 1?\n\nYes, there can be many. If you create a server on localhost it can create more than one server; in the most simple case, you'll have one for IPv4 and one for IPv6.\n\nOK sorry for the noise, I missed the for loop.\n\n\n\nHow should we implement the future returned by serve_forever?\n\n\nI think we should be able to copy/paste asyncio implementation from base_events.py.\n\nIndeed, I did just that.. I had another look at \"why are the OSError messages different\", and it looks like the reason is:\n\n\nThe call to uv_tcp_bind succeeds even if there is already a socket bound to the same address / port.\n\n\nThe call to uv_listen however fails if there is already a socket bound to the same address / port.\n\n\nThe libuv docs for uv_tcp_bind mention this explicitly:\n\nWhen the port is already taken, you can expect to see an UV_EADDRINUSE error from either uv_tcp_bind(), uv_listen() or uv_tcp_connect(). That is, a successful call to this function does not guarantee that the call to uv_listen() or uv_tcp_connect() will succeed as well.\n\nThis is very different from plain asyncio, which bombs as soon as it attempts socket.bind(). This API difference used not to be visible to users, as the bind / listen steps were run in immediate succession, but with the introduction of start_serving it becomes important. How do you suggest we proceed?. OK sounds like a plan!. @1st1 I have implemented what you suggested, but I'm now getting a warning about an unclosed resource:\nuvloop/tests/test_tcp.py:967: ResourceWarning: unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('0.0.0.0', 43443)>\n  None, 0, backlog=bl)\nWhat do we need to do with the Python socket object once we have wrapped it in a TCPServer?\nEdit: the problem was in fact due to TCPServer.new raising an exception (in this case validating the backlog argument) which left the socket unclosed.. Hi Yury, what's the commit policy for uvloop, specifically who is expected to actually do the merge to master? The reviewer, author, .. ?. OK I've rebased on top of master and fixed 2 flake8 errors. If CI completes successfully I'll merge it.. A much better option is to coordinate with https://github.com/bennuttall/piwheels\nThe piwheels project is awesome, it automatically builds wheels for all packages on pypi, and makes them directly installable in the default raspbian distro.\nuvloop up to and including 0.12.0 are available, not sure what's up with 0.12.1:\nhttps://www.piwheels.org/simple/uvloop/. Still my point remains that putting the effort on the piwheels side seems more relevant. Even if uvloop's CI produced wheels for Raspberry Pi, there would be no \"right\" place to upload them. PyPI would almost certainly not be the right place, see:\nhttps://github.com/pypa/manylinux/issues/84. To clarify the requirement here: is the plan to leverage some support from libuv or is this a matter of replicating the code from vanilla asyncio?\nThe only reference to sendfile I seem to find in libuv is:\nhttp://docs.libuv.org/en/v1.x/fs.html#c.uv_fs_sendfile. I wonder where this is coming from :). Well that failed miserably... Adding \"update: true\" kind of defeats the point of what I'm trying to do here, which is to cut out the lengthy update process! I'm still going to give it a shot, but I'm not hopeful.\nBy the way, what's the reason for explicitly choosing an antique xcode / osx version?. Nope, because we are again updating homebrew.. If we want this to be \"no earlier than\" shouldn't this be a ceil() ?. Okidoki, I'll butt out ;). If we want to respect the guarantee that the CB is called \"no earlier than X\", isn't ceil() more appropriate than round()?. Ok sorry for the duplicate message. I was able to build your branch but I need some time to come up with a proper benchmark. My usual benchmark (DataChannel / SCTP / DTLS / ICE) won't cut it: the sockets aren't \"connected\" as remote candidates can come in at any time.. I'm not sure what has changed since last time I ran my tests, but I'm seing a behaviour I had not previously identified (both with 0.12 and with this PR):\n```python\nimport asyncio\nimport socket\nimport time\nimport uvloop\nclass DummyProtocol(asyncio.DatagramProtocol):\n    pass\nasync def run(loop):\n    addr = ('127.0.0.1', 1234)\n    data = b'M' * 1500\n    transport, protocol = await loop.create_datagram_endpoint(\n        lambda: DummyProtocol(),\n        family=socket.AF_INET)\nfor i in range(1000000):\n    transport.sendto(data, addr)\nprint('after sendto', time.process_time() - start)\n\nstart = time.process_time()\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nloop = asyncio.get_event_loop()\nloop.run_until_complete(run(loop))\nprint('after run', time.process_time() - start)\n```\nBoth 0.12 and this PR give me almost identical results which look like:\nafter sendto 1.394025113\nafter run 4.101789539\nVanilla asyncio looks like:\nafter sendto 3.545451784\nafter run 3.54558408\nThe behaviour I hadn't spotted: more time seems to be spent exiting the run() method than actually executing it. Is this buffers being flushed?. __convert_pyaddr_to_sockaddr : very nice, now all such calls benefit from the caching logic, and I see we gained a cythonized LRU cache in the process. I'm wondering if cpython's getsockaddrarg would also benefit from similar logic?\nI still don't quite understand how the cost system calls shows up at the end of the run loop?\nUsing the \"dumb\" benchmark uvloop is now consistently ~ 20% faster than vanilla asyncio so we're definitely making progress. I'll now run some tests closer to real-world usage using:\nhttps://github.com/aiortc/aiortc/tree/master/examples/datachannel-filexfer\n(NOTE: it benchmarks much more than just raw UDP throughput as there is also DTLS + a pure-python SCTP stack involved). As promised here are some results using aiortc to send a file over datachannels / SCTP / DTLS / UDP. All tests were performed with Python 3.7 on my laptop : quad core Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz.\naiortc's data channels code is single threaded so you end up maxing out one core for the sender and one for the receiver. All the SCTP stack including packet parsing is pure Python, so there is considerable overhead. You also pay for DTLS encryption / decryption (using PyOpenSSL) and checksuming (using crc32c). Still, it's as close as I have to a real-world example.\nPreliminary setup\nClone aiortc:\ngit clone https://github.com/aiortc/aiortc\ncd aiortc\npip install -e .\nSwitch CPU scaling governor to performance for more stable results:\necho performance > /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\necho performance > /sys/devices/system/cpu/cpu1/cpufreq/scaling_governor\necho performance > /sys/devices/system/cpu/cpu2/cpufreq/scaling_governor\necho performance > /sys/devices/system/cpu/cpu3/cpufreq/scaling_governor\nRunning the tests\nCreate 256MB of random data:\ndd if=/dev/urandom of=/tmp/test.bin bs=1M count=256\nLaunch the sender, using a UNIX socket for signaling:\npython examples/datachannel-filexfer/filexfer.py -s unix-socket send /tmp/test.bin\nLaunch the receiver:\npython examples/datachannel-filexfer/filexfer.py -s unix-socket receive /dev/null\nResults\nVanilla asyncio: 120Mbps\nuvloop 0.12.1: 140Mbps\nuvloop (this PR): 185Mbps\nI'd say that's a pretty neat performance boost!. Absolutely, done.. This is directly lifted from: https://github.com/python/cpython/blob/3e028b2d40370dc986b6f3146a7ae927bc119f97/Lib/asyncio/base_events.py#L1220. Is this the right place / way to do it?. OK I'll do a sock.detach() followed by sock = None.\nRegarding the warning I saw, it was something else: if any calls raise an exception we need to ensure the socket gets closed. That is why I keep track of sock and close it in the finally, otherwise we need try/catch every function call and do sock.close() at every possible failure.. I'm not sure how to inline the check, I had done so initially but the code bombed, even if I import os and import sys I don't seem to be able to use os.name or sys.platform.. some Cython pecularity I don't know?. OK. One thing I could not understand: why do we define SO_REUSEPORT, can its value ever be different from uv.SO_REUSEPORT?. Sure thing. I wasn't too sure as the limit doesn't seem to be 100% enforced. Maybe we should get CI to enforce this ?. It looks like err should be assigned?. ",
    "soonum": "Sorry I wasn't following up this old issue.\nIn fact my use case is that one, I provide a preexec_fn argument to these methods and as a result, the loop is blocking.. ",
    "python-programmer": "python\n1. import asyncio\n2. import uvloop\n3. asyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\nDoes order matter?\nbelow code works:\n```python\n!/usr/bin/env python\nimport datetime\nimport random\nimport asyncio # --------------------> this\nimport uvloop # --------------------> this\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy()) # --------------------> this\nimport websockets\nasync def time(websocket, path):\n    while True:\n        now = datetime.datetime.utcnow().isoformat() + 'Z'\n        await websocket.send(now)\n        await asyncio.sleep(random.random() * 3)\nstart_server = websockets.serve(time, '127.0.0.1', 5678)\nasyncio.get_event_loop().run_until_complete(start_server)\nasyncio.get_event_loop().run_forever()\n```\nwhy?. Thank you for your prompt reply.. ",
    "alxpy": "yes, we use pip. and we have other packages (compiled with Cython) (for example: aiohttp, cChardet) . ",
    "oliwarner": "I get the same with Python 3.6 (stock cpython, Ubuntu 17.10) with a pip-installed uvloop. ",
    "achimnol": "Another bump here with Python 3.6 on Ubuntu as well.. Cython 0.28 and 0.28.1 which includes the required patch is released now. :tada:\nRef: The Cython 0.28.1 changelog\n@1st1 I think it is the time to update uvloop! :wink:. I'm facing the same/similar error in my Travis CI environment.\nMy uvloop version is 0.8.1 and pytest version is 3.5.0, and I'm passing stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL.\n```\n        proc = await asyncio.create_subprocess_exec(*[\n            'python', '-m', 'ai.backend.agent.stats',\n            f'tcp://127.0.0.1:{stats_port}',\n            cid,\n            '--type', collection_type,\n\n  ], **output_opts)\n\ntests/test_stats.py:53: \n\n\n/usr/local/lib/python3.6/asyncio/subprocess.py:225: in create_subprocess_exec\n    stderr=stderr, **kwds)\nuvloop/loop.pyx:2164: in __subprocess_run (uvloop/loop.c:39419)\n    ???\nuvloop/handles/process.pyx:549: in uvloop.loop.UVProcessTransport.new (uvloop/loop.c:93810)\n    ???\nuvloop/handles/process.pyx:49: in uvloop.loop.UVProcess._init (uvloop/loop.c:84790)\n    ???\nuvloop/handles/process.pyx:38: in uvloop.loop.UVProcess._init (uvloop/loop.c:84510)\n    ???\nuvloop/handles/process.pyx:239: in uvloop.loop.UVProcess._init_options (uvloop/loop.c:88007)\n    ???\nuvloop/handles/process.pyx:415: in uvloop.loop.UVProcessTransport._init_files (uvloop/loop.c:91046)\n    ???\n\nself = <_pytest.capture.DontReadFromInput object at 0x7f4717c82860>\n    def fileno(self):\n\n  raise UnsupportedOperation(\"redirected stdin is pseudofile, \"\n                               \"has no fileno()\")\n\nE       io.UnsupportedOperation: redirected stdin is pseudofile, has no fileno()\n../../../virtualenv/agent/lib/python3.6/site-packages/_pytest/capture.py:583: UnsupportedOperation\n```. \n",
    "frnkvieira": "Same here. (Python 3.6.4, Ubuntu 17.10). Fair enough, thanks!. ",
    "Urahara": "I facing this problem too, using aiohttp, any workaround? Snippet of my code:\ntry:\n                async with async_timeout.timeout(15):\n                    async with self.session.get('http://example.com') as resp:\n                        response = resp\n                        break\n            except Exception as e:. ",
    "dyeray": "I'm having the exact same issue on my project, in this case when creating an asyncio_redis connection. It only happens if I import BeautifulSoup at the module level (so it was already imported before calling loop.create_connection()). I'm importing it at the function level as a workaround.. ",
    "codeadict": "I have this issue too with aiohttp. ",
    "em1208": "I have the same issue using uvloop 0.9.1 in python 3.5.2 with asyncio create_subprocess_exec. I hope this will be fixed soon! . ",
    "woyodb": "uvloop version: 0.9.1\nPython version: 3.6.4\nPlatform: Mac OS\nI got the same issue, hope this to be fixed soon.. ",
    "alexeykhit": "I add custom awaits in my code. Vanilla asyncio has same problems only when I use await after time.sleep.\nasync def get_sync(request):\n    if 'before' in request.query:\n        await asyncio.sleep(float(request.query.get('before')))\n    time.sleep(float(request.query.get('sleep', 5)))\n    if 'after' in request.query:\n        await asyncio.sleep(float(request.query.get('after')))\n    return web.Response(text='OK')\nMaybe problem with AbstractEventLoop.create_server logic? Maybe uvloop has some await (code switch) before return result and vanilla asyncio don't?. @1st1 I was right about problem in AbstractEventLoop.create_server.\nI write simple TCP Server:\nhttps://github.com/alexeykhit/pyasyncweb-tests/blob/master/main_builtin.py\nhttps://github.com/alexeykhit/pyasyncweb-tests/blob/master/main_builtin_uvloop.py\nAnd make new tests:\nhttps://github.com/alexeykhit/pyasyncweb-tests#test2\nDefault loop return result right after each self.transport.write/self.transport.close.\nBut uvloop return result after last self.transport.write/self.transport.close.. ",
    "drpoggi": "Looks like this is being covered in #138 . ",
    "aptonline": "Any chance the above reference  (#20829) can be investigated? After removing uvloop 0.12.0 from Home Assistant my docker container has not crashed once.. ",
    "wumpus": "I am seeing this on python 3.7.0b4 with uvloop 0.9.1\nI installed from git -- it says it is uvloop-0.9.2.dev0 -- and I see the same error.\n3.7 is getting close to release! People cannot easily test if fundamental libs like uvloop and pyyaml are not updated.\nLooks like PR https://github.com/MagicStack/uvloop/pull/138 is intended to fix this bug -- I installed the branch from the PR and this test passes for me.. I am using pyenv, python 3.7.0b4 on CentOS 7, and installed this branch -- success!\nIt would be nice for this to get released so more people could test 3.7-dev. I personally also use Travis/Xenial for CI so the remaining bug affects me, but .... I think we are agreeing that uvloop should not wait for TravisCI.. ",
    "byllyfish": "If I replace the line transport.close() with any of the following, the code runs fine under uvloop:\n\ntransport.kill()\ntransport.terminate()\ntransport.get_pipe_transport(0).close()\n\nLooking at the code for UVProcessTransport.close (uvloop/handles/process.pyx), does self._close() close the libuv internal handle before it has had a chance to reap the child process?\n```python\n    def close(self):\n        if self._returncode is None:\n            self._kill(uv.SIGKILL)\n    if self._stdin is not None:\n        self._stdin.close()\n    if self._stdout is not None:\n        self._stdout.close()\n    if self._stderr is not None:\n        self._stderr.close()\n\n    self._close()\n\n```\nuvloop Issue #64 (\"asyncio.get_child_watcher Not Working\" ) is similar to this one. I think there's a race condition in the sample code provided, which is why it may not have been reproducible.\n. ",
    "blakev": "Events are scheduled differently if we're on the MainThread. I'm not sure how to check which thread the loop is running on without accessing that attribute.. ",
    "janhn": "@1st1 Yes, it works with CPython.\nI can try, but I'm not familiar with Cython. This is what I'm getting after some digging:\nUnhandled exception in event loop\nTraceback (most recent call last):\n  File \"uvloop/handles/timer.pyx\", line 80, in uvloop.loop.__uvtimer_callback\nKeyError: <TimerHandle _set_result_unless_cancelled created at /opt/pypy3/lib-python/3/asyncio/tasks.py:522>. ",
    "extraymond": "+1 for the problem.\nI think the problem might be pypy not supporting async generator syntax since it's still based on 3.5.. ",
    "alpha-86": "thanks\uff0cI found asyncio.Event() was creates in global scope.\nI have fix this problem. ",
    "kxepal": "Not really. pkg_resources gets all the information from package metadata directories (.egg-info or .dist-info). If you install uvloop correctly (via pip), then it will works as expected.\n```\n$ pip install uvloop\nCollecting uvloop\n  Downloading uvloop-0.9.1-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.2MB 451kB/s \nInstalling collected packages: uvloop\nSuccessfully installed uvloop-0.9.1\n$ python\nPython 3.6.5 (default, Apr  8 2018, 11:23:52) \n[GCC 7.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n\n\nimport pkg_resources\npkg_resources.require(\"uvloop\")[0].version\n'0.9.1'\ntype(pkg_resources.require(\"uvloop\")[0])\n\n``.versionthing is just an agreement the same asauthor,revision` and the rest of those. These has no effect nor special meaning. However, version in package metadata matters since all the managers (pip, setuptools, pipenv) will use it for their work. Which makes it's more reliable source of truth than some custom module attribute.\n\n\n\nThe main problem with __version__ attribute is a chicken and egg one. You need package version to install the package, but you can't get package version without install it. So you have to found yourself to do import hacks (install-without-install) or doing regexp parsing. Not quite cool nor reliable ways to go just to achieve...what?. ",
    "sakurai-youhei": "FYI: Mine is reliable & straightfoward version check by python -c 'import uvloop; print(uvloop.__version__)' rather than querying pip.. Duplicate with https://github.com/MagicStack/uvloop/issues/126. My apologies for spamming.. @asvetlov Thanks, good to know the recent state of Docker image. Here are outputs from python github master (3.8) and 3.7 branch. The same results are brought; Looks like there are more problems other than https://github.com/MagicStack/uvloop/issues/146 when running uvloop with 3.7+.\n\n3.8 (excerpt)\nroot@5015e9fd7c5e:/usr/src/uvloop# python3.8 -VV\nPython 3.8.0a0 (heads/master:55bfe69, May 22 2018, 11:11:58)\n[GCC 7.3.0]\nroot@5015e9fd7c5e:/usr/src/uvloop# PYTHON=python3.8 make test\nPYTHONASYNCIODEBUG=1 python3.8 setup.py test\nrunning test\n...\ncreating build/temp.linux-x86_64-3.8\ncreating build/temp.linux-x86_64-3.8/uvloop\n...\ntest_check_thread (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:247: DeprecationWarning: get_coroutine_wrapper is deprecated\n  loop.run_until_complete(fut)\n/usr/src/uvloop/tests/test_base.py:247: DeprecationWarning: set_coroutine_wrapper is deprecated\n  loop.run_until_complete(fut)\nException in callback <built-in method set_result of _asyncio.Future object at 0x7f08b7ee8dc8>\nhandle: <Handle Future.set_result created at /usr/src/uvloop/tests/test_base.py:238>\nsource_traceback: Object created at (most recent call last):\n  File \"/usr/local/lib/python3.8/threading.py\", line 885, in _bootstrap\n    self._bootstrap_inner()\n  File \"/usr/local/lib/python3.8/threading.py\", line 917, in _bootstrap_inner\n    self.run()\n  File \"/usr/local/lib/python3.8/threading.py\", line 865, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/usr/src/uvloop/tests/test_base.py\", line 238, in check_in_thread\n    loop.call_soon_threadsafe(fut.set_result, None)\nTraceback (most recent call last):\n  File \"uvloop/cbhandles.pyx\", line 49, in uvloop.loop.Handle._run\n    callback(*args)\n  File \"uvloop/loop.pyx\", line 1154, in uvloop.loop.Loop.call_soon\n    def call_soon(self, callback, *args):\nTypeError: call_soon() got an unexpected keyword argument 'context'\n3.7 (full)\n```\nroot@01d0f68f75fe:/usr/src/uvloop# python3.7 -VV\nPython 3.7.0b4+ (heads/3.7:3718f92, May 22 2018, 11:12:01)\n[GCC 7.3.0]\nroot@01d0f68f75fe:/usr/src/uvloop# PYTHON=python3.7 make test\nPYTHONASYNCIODEBUG=1 python3.7 setup.py test\nrunning test\nrunning egg_info\nwriting uvloop.egg-info/PKG-INFO\nwriting dependency_links to uvloop.egg-info/dependency_links.txt\nwriting top-level names to uvloop.egg-info/top_level.txt\nreading manifest file 'uvloop.egg-info/SOURCES.txt'\nreading manifest template 'MANIFEST.in'\nwarning: no previously-included files matching '*' found under directory 'vendor/libuv/.git'\nwriting manifest file 'uvloop.egg-info/SOURCES.txt'\nrunning build_ext\nlibtoolize --copy\nlibtoolize: putting auxiliary files in '.'.\nlibtoolize: copying file './ltmain.sh'\nlibtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\nlibtoolize: copying file 'm4/libtool.m4'\nlibtoolize: copying file 'm4/ltoptions.m4'\nlibtoolize: copying file 'm4/ltsugar.m4'\nlibtoolize: copying file 'm4/ltversion.m4'\nlibtoolize: copying file 'm4/lt~obsolete.m4'\naclocal -I m4\nautoconf\n\nautomake --add-missing --copy\nconfigure.ac:38: installing './ar-lib'\nconfigure.ac:25: installing './compile'\nconfigure.ac:22: installing './config.guess'\nconfigure.ac:22: installing './config.sub'\nconfigure.ac:21: installing './install-sh'\nconfigure.ac:21: installing './missing'\nMakefile.am: installing './depcomp'\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking build system type... x86_64-pc-linux-gnu\nchecking host system type... x86_64-pc-linux-gnu\nchecking for gcc... gcc\nchecking whether the C compiler works... yes\nchecking for C compiler default output file name... a.out\nchecking for suffix of executables...\nchecking whether we are cross compiling... no\nchecking for suffix of object files... o\nchecking whether we are using the GNU C compiler... yes\nchecking whether gcc accepts -g... yes\nchecking for gcc option to accept ISO C89... none needed\nchecking whether gcc understands -c and -o together... yes\nchecking for style of include used by make... GNU\nchecking dependency style of gcc... gcc3\nchecking if gcc supports -pedantic flag... yes\nchecking for gcc way to treat warnings as errors... -Werror\nchecking if gcc supports -fvisibility=hidden... yes\nchecking if gcc supports -g flag... yes\nchecking if gcc supports -std=gnu89 flag... yes\nchecking if gcc supports -Wall flag... yes\nchecking if gcc supports -Wextra flag... yes\nchecking if gcc supports -Wno-unused-parameter flag... yes\nchecking if gcc supports -Wstrict-prototypes flag... yes\nchecking for ar... ar\nchecking the archiver (ar) interface... ar\nchecking how to print strings... printf\nchecking for a sed that does not truncate output... /bin/sed\nchecking for grep that handles long lines and -e... /bin/grep\nchecking for egrep... /bin/grep -E\nchecking for fgrep... /bin/grep -F\nchecking for ld used by gcc... /usr/bin/x86_64-linux-gnu-ld\nchecking if the linker (/usr/bin/x86_64-linux-gnu-ld) is GNU ld... yes\nchecking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\nchecking the name lister (/usr/bin/nm -B) interface... BSD nm\nchecking whether ln -s works... yes\nchecking the maximum length of command line arguments... 1572864\nchecking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\nchecking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\nchecking for /usr/bin/x86_64-linux-gnu-ld option to reload object files... -r\nchecking for objdump... objdump\nchecking how to recognize dependent libraries... pass_all\nchecking for dlltool... no\nchecking how to associate runtime and link libraries... printf %s\\n\nchecking for archiver @FILE support... @\nchecking for strip... strip\nchecking for ranlib... ranlib\nchecking command to parse /usr/bin/nm -B output from gcc object... ok\nchecking for sysroot... no\nchecking for a working dd... /bin/dd\nchecking how to truncate binary pipes... /bin/dd bs=4096 count=1\nchecking for mt... no\nchecking if : is a manifest tool... no\nchecking how to run the C preprocessor... gcc -E\nchecking for ANSI C header files... yes\nchecking for sys/types.h... yes\nchecking for sys/stat.h... yes\nchecking for stdlib.h... yes\nchecking for string.h... yes\nchecking for memory.h... yes\nchecking for strings.h... yes\nchecking for inttypes.h... yes\nchecking for stdint.h... yes\nchecking for unistd.h... yes\nchecking for dlfcn.h... yes\nchecking for objdir... .libs\nchecking if gcc supports -fno-rtti -fno-exceptions... no\nchecking for gcc option to produce PIC... -fPIC -DPIC\nchecking if gcc PIC flag -fPIC -DPIC works... yes\nchecking if gcc static flag -static works... yes\nchecking if gcc supports -c -o file.o... yes\nchecking if gcc supports -c -o file.o... (cached) yes\nchecking whether the gcc linker (/usr/bin/x86_64-linux-gnu-ld -m elf_x86_64) supports shared libraries... yes\nchecking whether -lc should be explicitly linked in... no\nchecking dynamic linker characteristics... GNU/Linux ld.so\nchecking how to hardcode library paths into programs... immediate\nchecking whether stripping libraries is possible... yes\nchecking if libtool supports shared libraries... yes\nchecking whether to build shared libraries... yes\nchecking whether to build static libraries... yes\nchecking whether make supports nested variables... (cached) yes\nchecking for dlopen in -ldl... yes\nchecking for kstat_lookup in -lkstat... no\nchecking for gethostbyname in -lnsl... yes\nchecking for perfstat_cpu in -lperfstat... no\nchecking for pthread_mutex_init in -lpthread... yes\nchecking for clock_gettime in -lrt... yes\nchecking for sendfile in -lsendfile... no\nchecking for socket in -lsocket... no\nchecking for special C compiler options needed for large files... no\nchecking for _FILE_OFFSET_BITS value needed for large files... no\nchecking sys/ahafs_evProds.h usability... no\nchecking sys/ahafs_evProds.h presence... no\nchecking for sys/ahafs_evProds.h... no\nchecking for pkg-config... no\nchecking that generated files are newer than configure... done\nconfigure: creating ./config.status\nconfig.status: creating Makefile\nconfig.status: executing depfiles commands\nconfig.status: executing libtool commands\nmake[1]: Entering directory '/usr/src/uvloop/build/libuv'\n  CC       src/libuv_la-fs-poll.lo\n  CC       src/libuv_la-inet.lo\n  CC       src/libuv_la-threadpool.lo\n  CC       src/libuv_la-uv-common.lo\n  CC       src/libuv_la-version.lo\n  CC       src/unix/libuv_la-async.lo\n  CC       src/unix/libuv_la-core.lo\n  CC       src/unix/libuv_la-dl.lo\n  CC       src/unix/libuv_la-fs.lo\n  CC       src/unix/libuv_la-getaddrinfo.lo\n  CC       src/unix/libuv_la-getnameinfo.lo\n  CC       src/unix/libuv_la-loop-watcher.lo\n  CC       src/unix/libuv_la-loop.lo\n  CC       src/unix/libuv_la-pipe.lo\n  CC       src/unix/libuv_la-poll.lo\n  CC       src/unix/libuv_la-process.lo\n  CC       src/unix/libuv_la-signal.lo\n  CC       src/unix/libuv_la-stream.lo\n  CC       src/unix/libuv_la-tcp.lo\n  CC       src/unix/libuv_la-thread.lo\n  CC       src/unix/libuv_la-timer.lo\n  CC       src/unix/libuv_la-tty.lo\n  CC       src/unix/libuv_la-udp.lo\n  CC       src/unix/libuv_la-linux-core.lo\n  CC       src/unix/libuv_la-linux-inotify.lo\n  CC       src/unix/libuv_la-linux-syscalls.lo\n  CC       src/unix/libuv_la-procfs-exepath.lo\n  CC       src/unix/libuv_la-proctitle.lo\n  CC       src/unix/libuv_la-sysinfo-loadavg.lo\n  CC       src/unix/libuv_la-sysinfo-memory.lo\n  CCLD     libuv.la\nar: u' modifier ignored sinceD' is the default (see `U')\nmake[1]: Leaving directory '/usr/src/uvloop/build/libuv'\nbuilding 'uvloop.loop' extension\ncreating build/temp.linux-x86_64-3.7\ncreating build/temp.linux-x86_64-3.7/uvloop\ngcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/usr/local/include/python3.7m -Ivendor/libuv/include -c uvloop/loop.c -o build/temp.linux-x86_64-3.7/uvloop/loop.o -O2\nuvloop/loop.c: In function \u2018pyx_f_6uvloop_4loop_9UVProcess__after_fork\u2019:\nuvloop/loop.c:99422:3: warning: \u2018PyOS_AfterFork\u2019 is deprecated [-Wdeprecated-declarations]\n   PyOS_AfterFork();\n   ^~~~~~~~~~~~~~\nIn file included from /usr/local/include/python3.7m/Python.h:125:0,\n                 from uvloop/loop.c:20:\n/usr/local/include/python3.7m/intrcheck.h:16:18: note: declared here\n PyAPI_FUNC(void) PyOS_AfterFork(void) Py_DEPRECATED(3.7);\n                  ^~~~~~~~~~~~~~\ncreating build/lib.linux-x86_64-3.7\ncreating build/lib.linux-x86_64-3.7/uvloop\ngcc -pthread -shared build/temp.linux-x86_64-3.7/uvloop/loop.o build/libuv/.libs/libuv.a -lrt -lpthread -o build/lib.linux-x86_64-3.7/uvloop/loop.cpython-37m-x86_64-linux-gnu.so\ncopying build/lib.linux-x86_64-3.7/uvloop/loop.cpython-37m-x86_64-linux-gnu.so -> uvloop\ntest_aiohttp_basic_1 (test_aiohttp.Test_AIO_AioHTTP) ... skipped 'no aiohttp module'\ntest_aiohttp_basic_1 (test_aiohttp.Test_UV_AioHTTP) ... skipped 'no aiohttp module'\ntest_call_at (test_base.TestBaseAIO) ... ok\ntest_call_later_1 (test_base.TestBaseAIO) ... ok\ntest_call_later_2 (test_base.TestBaseAIO) ... ok\ntest_call_later_negative (test_base.TestBaseAIO) ... ok\ntest_call_soon (test_base.TestBaseAIO) ... ok\ntest_call_soon_base_exc (test_base.TestBaseAIO) ... ok\ntest_calls_debug_reporting (test_base.TestBaseAIO) ... ok\ntest_check_thread (test_base.TestBaseAIO) ... ok\ntest_close (test_base.TestBaseAIO) ... ok\ntest_debug_slow_callbacks (test_base.TestBaseAIO) ... ok\ntest_debug_slow_task_callbacks (test_base.TestBaseAIO) ... ok\ntest_debug_slow_timer_callbacks (test_base.TestBaseAIO) ... ok\ntest_default_exc_handler_broken (test_base.TestBaseAIO) ... /usr/src/uvloop/tests/test_base.py:488: DeprecationWarning: get_coroutine_wrapper is deprecated\n  loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:488: DeprecationWarning: set_coroutine_wrapper is deprecated\n  loop.run_forever()\nok\ntest_default_exc_handler_callback (test_base.TestBaseAIO) ... ok\ntest_handle_weakref (test_base.TestBaseAIO) ... ok\ntest_inf_wait_for (test_base.TestBaseAIO) ... ok\ntest_now_update (test_base.TestBaseAIO) ... ok\ntest_run_once_in_executor_plain (test_base.TestBaseAIO) ... ok\ntest_run_until_complete_error (test_base.TestBaseAIO) ... ok\ntest_run_until_complete_loop (test_base.TestBaseAIO) ... ok\ntest_run_until_complete_loop_orphan_future_close_loop (test_base.TestBaseAIO) ... ok\ntest_run_until_complete_type_error (test_base.TestBaseAIO) ... ok\ntest_set_debug (test_base.TestBaseAIO) ... ok\ntest_set_exc_handler_broken (test_base.TestBaseAIO) ... ok\ntest_set_exc_handler_custom (test_base.TestBaseAIO) ... ok\ntest_set_task_factory (test_base.TestBaseAIO) ... ok\ntest_set_task_factory_invalid (test_base.TestBaseAIO) ... ok\ntest_shutdown_asyncgens_01 (test_base.TestBaseAIO) ... ok\ntest_shutdown_asyncgens_02 (test_base.TestBaseAIO) ... ok\ntest_shutdown_asyncgens_03 (test_base.TestBaseAIO) ... ok\ntest_call_at (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:192: DeprecationWarning: get_coroutine_wrapper is deprecated\n  self.loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:192: DeprecationWarning: set_coroutine_wrapper is deprecated\n  self.loop.run_forever()\nok\ntest_call_later_1 (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:140: DeprecationWarning: get_coroutine_wrapper is deprecated\n  self.loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:140: DeprecationWarning: set_coroutine_wrapper is deprecated\n  self.loop.run_forever()\nok\ntest_call_later_2 (test_base.TestBaseUV) ... Task was destroyed but it is pending!\nsource_traceback: Object created at (most recent call last):\n  File \"setup.py\", line 320, in \n    test_suite='tests.suite'\n  File \"/usr/local/lib/python3.7/site-packages/setuptools/__init.py\", line 129, in setup\n    return distutils.core.setup(attrs)\n  File \"/usr/local/lib/python3.7/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/usr/local/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n    self.run_command(cmd)\n  File \"/usr/local/lib/python3.7/distutils/dist.py\", line 985, in run_command\n    cmd_obj.run()\n  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/test.py\", line 226, in run\n    self.run_tests()\n  File \"/usr/local/lib/python3.7/site-packages/setuptools/command/test.py\", line 248, in run_tests\n    exit=False,\n  File \"/usr/local/lib/python3.7/unittest/main.py\", line 101, in init\n    self.runTests()\n  File \"/usr/local/lib/python3.7/unittest/main.py\", line 271, in runTests\n    self.result = testRunner.run(self.test)\n  File \"/usr/local/lib/python3.7/unittest/runner.py\", line 176, in run\n    test(result)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 84, in call\n    return self.run(*args, kwds)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 122, in run\n    test(result)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 84, in call\n    return self.run(args, kwds)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 122, in run\n    test(result)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 84, in call\n    return self.run(*args, kwds)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 122, in run\n    test(result)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 84, in call\n    return self.run(args, kwds)\n  File \"/usr/local/lib/python3.7/unittest/suite.py\", line 122, in run\n    test(result)\n  File \"/usr/local/lib/python3.7/unittest/case.py\", line 663, in call\n    return self.run(*args, kwds)\n  File \"/usr/local/lib/python3.7/unittest/case.py\", line 615, in run\n    testMethod()\n  File \"/usr/src/uvloop/tests/test_base.py\", line 159, in test_call_later_2\n    self.loop.run_until_complete(main())\n  File \"/usr/local/lib/python3.7/asyncio/tasks.py\", line 552, in ensure_future\n    task = loop.create_task(coro_or_future)\ntask: .main() running at /usr/src/uvloop/tests/test_base.py:153> created at /usr/local/lib/python3.7/asyncio/tasks.py:552>\nUnexpected calls to loop.call_exception_handler():\n[{'message': 'Task was destroyed but it is pending!',\n  'source_traceback': [>,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ,\n                       ],\n  'task': .main() running at /usr/src/uvloop/tests/test_base.py:153> created at /usr/local/lib/python3.7/asyncio/tasks.py:552>}]\nERROR\nFAIL\ntest_call_later_negative (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:171: DeprecationWarning: get_coroutine_wrapper is deprecated\n  self.loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:171: DeprecationWarning: set_coroutine_wrapper is deprecated\n  self.loop.run_forever()\nok\ntest_call_soon (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:55: DeprecationWarning: get_coroutine_wrapper is deprecated\n  self.loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:55: DeprecationWarning: set_coroutine_wrapper is deprecated\n  self.loop.run_forever()\nok\ntest_call_soon_base_exc (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:66: DeprecationWarning: get_coroutine_wrapper is deprecated\n  self.loop.run_forever()\n/usr/src/uvloop/tests/test_base.py:66: DeprecationWarning: set_coroutine_wrapper is deprecated\n  self.loop.run_forever()\nok\ntest_calls_debug_reporting (test_base.TestBaseUV) ... /usr/local/lib/python3.7/unittest/case.py:643: RuntimeWarning: coroutine 'sleep' was never awaited\n  outcome.errors.clear()\ntest_check_thread (test_base.TestBaseUV) ... /usr/src/uvloop/tests/test_base.py:247: DeprecationWarning: get_coroutine_wrapper is deprecated\n  loop.run_until_complete(fut)\n/usr/src/uvloop/tests/test_base.py:247: DeprecationWarning: set_coroutine_wrapper is deprecated\n  loop.run_until_complete(fut)\nException in callback \nhandle: \nsource_traceback: Object created at (most recent call last):\n  File \"/usr/local/lib/python3.7/threading.py\", line 885, in _bootstrap\n    self._bootstrap_inner()\n  File \"/usr/local/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n    self.run()\n  File \"/usr/local/lib/python3.7/threading.py\", line 865, in run\n    self._target(self._args, self._kwargs)\n  File \"/usr/src/uvloop/tests/test_base.py\", line 238, in check_in_thread\n    loop.call_soon_threadsafe(fut.set_result, None)\nTraceback (most recent call last):\n  File \"uvloop/cbhandles.pyx\", line 49, in uvloop.loop.Handle._run\n    callback(args)\n  File \"uvloop/loop.pyx\", line 1154, in uvloop.loop.Loop.call_soon\n    def call_soon(self, callback, *args):\nTypeError: call_soon() got an unexpected keyword argument 'context'\n```. Oops, this PR seems to be duplicate work with https://github.com/MagicStack/uvloop/pull/138.... FYI.\n\n\n3.6 (excerpt)\n```\nroot@7e3bc77a12b7:/usr/src/uvloop# python3.6 -VV\nPython 3.6.5+ (heads/3.6:ab90ea2, May 22 2018, 11:54:42)\n[GCC 7.3.0]\nroot@7e3bc77a12b7:/usr/src/uvloop# python3.6 -m pip freeze\nattrs==18.1.0\nCython==0.27.3\nmore-itertools==4.1.0\npluggy==0.6.0\npy==1.5.3\npytest==3.5.1\nsix==1.11.0\nuvloop==0.9.2.dev0\nroot@7e3bc77a12b7:/usr/src/uvloop# PYTHON=python3.6 make test\n...\n\nRan 383 tests in 59.630s\n\n\nOK (skipped=6)\n* **3.5 (excerpt)**\nroot@cf5d78a0204d:/usr/src/uvloop# python3.5 -VV\nPython 3.5.5+\nroot@cf5d78a0204d:/usr/src/uvloop# python3.5 -m pip freeze\nattrs==18.1.0\nCython==0.27.3\nmore-itertools==4.1.0\npluggy==0.6.0\npy==1.5.3\npytest==3.5.1\nsix==1.11.0\nuvloop==0.9.2.dev0\nroot@cf5d78a0204d:/usr/src/uvloop# PYTHON=python3.5 make test\n...\n----------------------------------------------------------------------\nRan 383 tests in 61.499s\nOK (skipped=17)\n```. Probably Cython needs to be installed before installing uvloop.. Here is one sentence taken from README, which explains the reason well for me.\n\nuvloop is implemented in Cython and uses libuv under the hood.. \n",
    "pfreixes": "No way, Travis still failing one test gets frozen forever. \nMy gut feeling says that is because the older 3.7-dev CPython version pointing still to 3.7.0a4+. Tried to run the Travis step using Ubuntu 16.04 that must come with 3.7.0b1 [1] but looks like Travis does not have official and production-ready support for Xenial - WAT! - and keeps installing the Trusty version. \nAny ideas?\n[1] https://s3.amazonaws.com/travis-python-archives/binaries/ubuntu/16.04/x86_64/python-3.7-dev.tar.bz2\n. @1st1 ^^. Finally got a green CI, not really happy with some of the patches. in any case, its something that can be used to start and obviously to get improve it. Feedback welcomed @1st1.\nI know that you had some plans to give support for contextvars - the natural continuation after this PR. if you are in a rush with other stuff, I can make it.. @1st1 Changes applied, about the issues with Pip and Python 3.7:\nTravis CI uses an older 3.7-dev image, exactly 3.7.0a4+. And the 3.7 is no longer available. Since this breaking change [1] I would say that Python 3.7 is kinda broken for Travis. I hope that the Docker solution will be a temporary one, but right now is the only way to get a functional environment running an interpreter with a version beyond the alpha 4.\nThe Pip issue started with the recent 10.0.0 release and the Pyenv environments [2] [3]. Take a look to the last commit, just pins the PIP version for the Mac osx environment. I hope so again that this will be just a temporary solution.\n[1] https://github.com/travis-ci/travis-ci/issues/9069\n[2] https://github.com/pypa/pip/issues/5240\n[3] https://github.com/pyenv/pyenv/issues/1141. I didn't manage to make it run, but I'm still on it.\nBrief summary. Initially I was trying to pull through pipenv the 3.7-dev Python version, but most of the times Travis failed with a timeout because of the downloading process from Git plus the compilation process. So, later Ive tried pinning to the 3.7.0 beta 3 that is the last available by downloading it through FTP, and more important in my machines passes all of the tests with that version. Surprisingly, pinning to that version the timeouts during the install process in CI vanished.\nUnfortunately, it turns out that the tests get frozen, exactly in the test_create_connection_3 [1]. This is something that I've already experienced with alpha versions of the 3.7 - also in my local machine - but never with the beta ones. Indeed, as I said in my local machine all the tests work like a charm using the 3.7.0 beta 3 and the same using Docker.\nSo what is happening? No  idea. I've checked that the python version used to run the test is the right one installed by pipenv [2], and it seems to be right. \nI will try to work more on this,  first I need to reproduce the issue In my local machine otherwise it is gonna be really painful :)\nAny suggestions will be wellcomed.\nPD: The time needed to pass the Travis step using Docker for the Python 3.7 is more or less the same that is needed for the none dockerized steps. So, if you consider that this technical debt can be removed at some point - perhaps having the proper resolution by the Travis guys, we could think moe ahead with the Docker solution thinking on it as a temporary one. Agree, that if this is a testing issue has to be solved but my gut feeling says that this is not test issue, you can pull the branch and test it against your local Python 3.7 installation\nPD2: Out of topic, I have a pending conversation with you regarding the tracing. I would like to give you another point of view. But I will work on it this weekend.\n[1] https://github.com/MagicStack/uvloop/blob/master/tests/test_tcp.py#L424 \n[2] https://github.com/MagicStack/uvloop/pull/138/files#diff-bd3c3a6aaea54a8f42fa6e7850a7a252R17\n. @1st1 I didn't manage to reproduce the same issue in local. These have been the environments that ran the tests successfully in local:\n\nDocker image with Ubuntu 14.04 (trusty) with a OpenSSL 1.1 and Python 3.7 b03 from Pyenv,\nDocker image with Ubuntu 16.04 (xenial), with Python 3.7 b03 from Pyenv.\nDocker image with Ubuntu 16.04 (xenial), with Python 3.7 b04 (used the same one that is used by Travis)\n\nI've tried to reproduce the local environment following this guide but looks like that the Xenial is still experimental and there is no way to download the image used by Travis, or at least I wasn't able to find it. In any case, I've opened an issue to gather some feedback from Travis\nAlso, I've tried to get some information running the Travis CI, no luck and also the same issue: stuck in the same test test_create_connection_3 (test_tcp.Test_AIO_TCP). Worth mentioning that the xenial environment is quite slower than the trusty one, usually takes 10 minutes more to start! and even sometimes the job finishes while the worker is still compiling the package (timeout?).\nSo, let's wait for some feedback from the Travis team. But I wouldn't put so many hopes on it, taking into account that for them the Xenial is still experimental and not officially supported by Travis.. Definitely, something is wrong with Xenial and Travis . My proposal here is going for the Docker option that was proven as successful and TBH didn't add so much overhead in terms of time needed to run the tests.\nLater if the xenial distro is officially supported by Travis and the tests can be run natively without using Docker its a matter of changing the configuration.. Thanks!. Closing this PR, I'm more interested in open one the MR once #138 gets merged, so not having this full of useless commits. Also, I would prefer to make it in a specific branch for tracing.. Hi @sakurai-youhei  I would say that #138 solves all of the problems and passes all the tests with py37,  but waitting the blessing about how to keep moing on from @1st1.\n. @1st1 comments are welcomed.\nIf at some point we believe that we can move on with this feature - that most likely will be composed of many small MR - I would create a feature branch to don't block master. . Yeps, closing right now. Thanks for your feedback @1st1 \nRegarding your concerns about the implementation proposed by #160 I partially agree on both of them but I have my reasons starting with such proposal.\nThis first approximation had as a goal implement a generic system that would allow the user to implement on top of it its own logic or implementation, so it would allow the implementation of interfaces that would provide the glue for ZipKin, OpenTracing, AWS Xray, Statsd, and other tools either for tracing or for monitoring. So basically the interface presented wanted to solve both cases: tracing plus monitoring.\nIt's true that having such open interface it might end up allowing the users using bad practices, and yes that the creation of a new duration span with the pair _begin and _end functions would mean that most of the interfaces should update their implementations.\nYour proposal, that goes more aligned with the initial conversations, narrows and makes explicit the implementation, so losing freedom but at the same point having the following advantages:\n\nAvoid implicitly the use of bad practices, by design.\nPuts a clear boundary between the application code and the uvloop code, without having cross communication as we had with the callbacks that must help to keep the footprint of the tracing within the cython figures.\nCould allow flexibility in terms of maintencance for future wrappers.\n\nI agree with the concept of Span in terms of an operation that takes some time - as it is already described in the tracing world. But I disagree with the other cases that are not timed operations, such as the counters which IMO they are more related to monitoring.  \nLets take as an example the following snippet:\npython\nasync def coro(loop):\n    with uvloop.tracing(\"coro_span\") as span:\n        connection = await redis.connect(\"loclahost\")\n        value = await connection.get(\"foo\")\n        span.finish()\n        print(span)\nThe uvloop.tracing will create span such as:\nSpan(\n  name='coro_span',\n  created_at=t0,\n  duration=x,\n  children=[\n    Span(\n      name='uvloop.getaddrinfo',\n      created_at=t1,\n      duration=y,\n      host='localhost'\n      port=6677\n      addr='127.0.0.1'\n    ),\n    Span(\n      name='uvloop.connect',\n      created_at=t2,\n      duration=y,\n      addr='127.0.0.1:6667', \n    ),\n  ]\n)\nSo basically the Spans are a hierarchy of the duration events with their metadata.\nHaving something like this, the goal of tracing gets narrowed and it should mean that future wrappers - such us OpenTracing - must be able to implement something enough generic to allow changes on the metadata related to each Span, allowing them to make a pure translation to their span idiom.\nEven I guess we might add as metadata some metrics that can be gathered within an ongoing span, such as the counters that we were speaking, for example, the next snippet shows what could implement the callback that is in charge of feed some data from the network\npython\ndef feed(self, data):\n    if span:\n        span.rx += len(data)\nSo later the span will incorporate this data automatically.\nBut I'm still thinking that we would need a way to provide pure monitoring KPIs with an interface that is not coupled to the tracing interface, allowing the owners of the services that run applications on top of uvloop to gather the operational metrics such as RX, TX, callbacks, tasks, polling time and so on, that is part of the monitoring field rather than tracing. \nRegarding the id of the Span, I'm not really sure if we need it, and I'm inclined to think that this is more something that depends on the tracer implementation - the wrapper - that identifies univocally the spans with its system. So, the question will be if the raw implementation really needs it and if an implicit serialization as the one that was presented would be enough.\nI finally the implementation of the tracing moves into that direction, meaning that uvloop is gonna provide its own span implementation. As soon as there is a POC of this implementation I would try to make some tests and check how much friction imposes its wrapping for systems such as Zipkin, OpenTracing, AWS Xray and so on.\n. I've been digging a bit about how easily will be serializing the uvloop spans that later would be converted to the tracer format that is the one being used by an application such as Jaeger, DDog, AWS Xray and so on.\nTake as an example the following code that tries to emulate this serialization for the Jaeger library [1]\n```Python\nfrom jaeger import tracer\n@contextmanager\ndef jaeger_trace(loop):\n    uvloop_span = loop.trace():\n    yield\n    uvloop_span.finish()\nroot = tracer.start_span(\n    uvloop_span.name,\n    tags=uvloop_span.tags\n    start_time=uvloop_span.start_time\n)\n\nfor uvloop_child in uvloop_span.children:\n    child = tracer.start_span(\n        uvloop_child.name,\n        child_of=root,\n        tags=uvloop_child.tags,\n        start_time=uvloop_child.start_time\n    )\n    child.finish(finish_time=uvloop_child.stop_time)\n\nroot.finish(finish_time=uvloop_span.stop_time)\n\n```\nBasically it leaves to uvloop to make all of the work and once it is done the wrapper builds programatically the Jaeger spans using as a source the uvloop spans. \nIn an ideal world all of the libraries that iplement the OpenTracing standard [2] must be able to serialize traces using a piece of code quite similar with the above one. But some libraries that claim to be OpenTracing compatibles do not have an exact implementation, perhaps Data Dog has a Span object that supports the finish time as a parameter of its constructor while the start_span function - the one used to start a new span - does not support it [4]. Others like AWS Xray [5] would need a change in their API to allow serialize tracers programatically that come from a uvloop.\nSo summary, providing uvloop its own system to create and handle spans might create some resistence to be adopted by some tracers. On the other hand, having a more generic implemenentation as the callback one provided by #160, libraries should have enough freedom to implement their own span system.\nWorth mentioning that tracers system place none core fields - id, duration, - under a generic field called tag,meta or other. So if finally uvloop implements its own span system, I would keep the core fields as minimum is possible copying the ones implemented by OpenTracing and putting all of the extra under a namespace such as tags, meta u other.  \n[1] https://github.com/jaegertracing/jaeger-client-python\n[2] https://github.com/opentracing/opentracing-python/blob/master/opentracing/tracer.py#L37\n[3] https://github.com/DataDog/dd-trace-py/blob/master/ddtrace/span.py#L51\n[4] https://github.com/DataDog/dd-trace-py/blob/master/ddtrace/tracer.py#L137\n[5] https://github.com/aws/aws-xray-sdk-python/blob/master/aws_xray_sdk/core/recorder.py#L163. Regarding your proposal @1st1, TL;DR Ok!.\nThe proposal circumvents the issue of the friction to allow the wrappers being integrated with not so much pain, indeed this proposal goes more into the direction of the callbacks but narrowing the use case making the API super opinionated.\nOn the other hand, having this proposal you know that who will dictate the performance degradation will be the tracer, so the crosstalk between Cython code and  Python code will be there by design. None sampled spans end up as real Python objects [1]\nAbout the three different spans Timer, Counter and Increment IMO as I said it does not make sense, a Span is an object that represents an execution during a time that is the perfect match for the Timer span, while Counter and Increment are just metrics that have another nature. Take as an example the Jaeger implementation, they do not have any other concept for Span aside of the Timer one, indeed they have a metrics subsystem [2] that allow them to send some related metrics such as counters and increments.\nIMO the metrics/stats must be provided by uvloop in another interface perhaps:\npython\nascnc def coro():\n    with uvloop.stats() as stats:\n        with uvloop.start_tracing(tracer) as span:\n            span.set_tag(\"rx\", stats.rx)\nRegarding your quesitons:\n\nShould TracedContext support nesting? Maybe TracedContext can be a Span? In principle I'd be OK with uvloop.start_tracing() creating a top-level TimingSpan instance, but I'd like tracing boundaries to be a bit more visible than that.\n\nI dont get this question.\nIn any case seeing how other traces implement its counterpart start_tracing, this  should create the root span.\n\nIdeally we should somehow indicate new Tasks -- so maybe we need a TaskSpan span too.\n\nIMO whatever part of the underlying code that is executed by uvloop that can be isolated and it is interpretable as a span should implement what is needed to be traced, creating the spans as a children of the root span.\nSo the easy example is the DNS resolution, so having\npython\nascnc def coro():\n    with uvloop.start_tracing(tracer) as span:\n        hosts = await loop.getaddrinfo(..)\nThe span object must have a children span that identifies clearly the DNS resolution. Im inclined to think that we have to use the same Span object for all of the spans that uvloop can create, or at maximum just an ephemeral child class that dictates some attributes such as the name.\nThen the no easy part, the Task one. If we have a code such as:\npython\nasync def coro():\n    with uvloop.start_tracing(tracer) as span:\n        task = loop.create_task(bar())\n        await task\nIm inclined to think that the await task must be considered as a children span. The same for any of the other primitives that allow you wait for a task.  Hence, facing to all of the impediments that we will have without having Asyncio implementing tracing natively.\nI would say that this one of the critical parts that would need some answers as soon as possible, having also the option of just leave aside this problematic without implementing them as children spans, so the user losing some granualirity in the trace.\n\nHow can we shield some tasks from tracing? That's needed to spawn new tasks that are not traced (even if the Task that spawns them is traced).\n\nIm wondering why someone that is interested on instrumentalize a piece of code gathering the trace and its spans would be interested on discard some specific tasks. I have the feeling that there is no an easy way to make this and the implementation and inteface can end up much more complicated for just do something that might be used by nobody.\nAnd last but not least, did you considere to put the start_tracing as a method of the loop? This defenitly will help in the future to make the convergency with asyncio, or  is it too much adventurous?\n[1] https://github.com/aio-libs/aiozipkin/blob/master/aiozipkin/span.py#L81\n[2] https://github.com/jaegertracing/jaeger-client-python/blob/master/jaeger_client/metrics/metrics.py. Hi @jettify gad to see you here\n\nGiven that what purpose of uvloop/asyncio tracing subsystem?\n\nThe goal is give more granularity to the user when the user traces an application that runs on top of Asyncio, IMO the annalogy is other frameworks that they already implement tracing system [1].\nHaving Asyncio implementing tracing under the hood we must be able to enrich current solutions, such as the Aiohttp middleware for AWS Xray [2] giving to the user a more fine granularity for free. \nThe question is why not in Asyncio ?\n[1] https://github.com/opentracing-contrib\n[2] https://github.com/aws/aws-xray-sdk-python/blob/master/aws_xray_sdk/ext/aiohttp/middleware.py#L15. Could we start implementing something like:\npython\n    with tracer.start_span('TestSpan') as span:\n        tracer_ctx = uvloop.stat_tracing(tracer.uvloop)\n        .....\n        uvloop.stop_stracing(tracer_ctx)\nThe tracer.start_span its just the Jaeger implementation - could be others such as aiozipkin, etc - and it's irrelevant, the importance here is: \n1) uvloop.stat_tracing flags uvloop to start making the spans at each instrumentalized piece of code\n2) uvloop.stat_tracing receives the interface that allows uvloop to handle spans internally using the external implementation provided by the tracer implementation.\n3) In this POC all spans created by uvloop are just child spans of the parent span create before by the tracer.\n@1st1 @jettify thoughts ?. Regarding #171, the pending discussions that it raises are:\n\n\nMetricsSpan, CounterSpan and TimingSpan controversial, this PR only implements a generic Span that is a timing one.\n\n\nuvloop.tracing.Tracer.current_span needs to be adapted to avoid race conditions, when a span is created the \"global\" attribute is overwritten. Most likely current_span will end up as another context variable.\n\n\nAgreement of an almost final draft of the start_tracing entry point, right now the implementation hides the TracedContext, so making it usable only internally by uvloop. I'm wondering if we must make it public providing to the user a way of creating spans in his code, so becoming the way of trace asyncio uvloop code.\n\n\nCurrent implementation implicitly wires the Tracer context using the parent span, so for example when internally a new span is created using the TracedContext.start_span under the hood the parent span is passed to the Tracer.create_span, so allowing to the tracer to fetch some context information from this, also allowing make the new span child of the parent one. Should we reconsider this with a more explicit interface?\n\n\nSupport for other spans within uvloop. But before doing this, we would need a kind of agreement of behind what circumstances the spans are created. A good example is the create_connection loop function, would feel comfortable with something like this:\npyhton\nasync def create_connection(...)\n    with __traced_context() as span:\n        .....\nThat it would mean that when there is no tracing enabled it will create a noop span, the benefits of this global wrapping make the code cleaner and easier to maintain but the drawbacks are quite clear.\nAlso worth mentioning that going to a pattern that uses a global context would mean that we will be creating a span when indeed in some failure scenarios we connected to nothing and without yielding the loop.. any feedback on this @1st1?\nI've been a bit out lately and I don't think that I will have time till the second week of August. But any discussion that helps us to reach some conclusions will be worth it.\nRegarding the last summary that I've written down related with the #171 PR I left two open questions which I have some thoughts.\n\nAgreement of an almost final draft of the start_tracing entry point, right now the implementation hides the TracedContext, so making it usable only internally by uvloop. I'm wondering if we must make it public providing to the user a way of creating spans in his code, so becoming the way of trace asyncio uvloop code.\n\nThe tracer provider already provides a known API and the user is used to use it, so IMO we must allow the user to keep using the tracer interface that is used to use it and not forcing it to use a new interface. Therefore, the TracedContext and other stuff implemented by uvloop would remain hidden.\n\nwe would need a kind of agreement of behind what circumstances the spans are created. A good example is the create_connection loop function, would feel comfortable with something like this:\n\nI'm inclined to think that the span has to be created only when the loop is yielded. For example, for the create_connection loop function if it never reaches the step that yields the loop the span shouldn't be created. So, the __traced_context context wouldn't make sense.\n. If you have some light about why this testing is failing with 3.7 please tell me.. Just removed the asyncio to avoid losing the ability to call later the asyncio.coroutines.debug_wrapper when uvloop run on an interpreter different than 3.7. \nIf you believe that this is a red flag, let's find another way to make the _set_coroutine_debug ready to be executed by different Python versions.. Getting this error with the Mac environment\nbash\nYou should consider upgrading via the 'pip install --upgrade pip' command.\n+pip install --upgrade setuptools\nTraceback (most recent call last):\n  File \"/Users/travis/.pyenv/versions/3.6.3/bin/pip\", line 7, in <module>\n    from pip import main\nImportError: cannot import name 'main'. Some questions regarding this\n\ndo we have to use the same trace for the happy path and for the none happy path?\ndo we have to pass as a parm the exception?\n\nI'm more inclined to think that decoupling both signals to two different things will help us to make the interface cleaner, perhaps having __send_trace(TRACE_DNS_REQUEST_END_EX, ex).. unfortunately, the _getaddrinfo can be called with the unpack enabled or disabled. with the current PR, the user won't be able to know explicitly wich format meets the argument.\nI more inclined to think that we must give always the unpack version of the result that is the format returned by the public method getaddrinfo. . should we force an immutable version for all of the params?. ",
    "kyuupichan": "Well the asyncio error has an IPv4 one.  I'm not sure what else you're asking.. ",
    "squeaky-pl": "This doesn't belong here. The problem probably lies in Japronto: The original issue is here https://github.com/squeaky-pl/japronto/issues/99\nDidn't have time/resources to look into it.. I hinted the issue author what he needs to do to fix it in https://github.com/squeaky-pl/japronto/issues/122, feel free to close.. \"He doesn't care\" is a very broad statement. I certainly do care, if I would not care I would not bother to respond to you, or certainly not provide any further information. It's true that the project development is stale or inactive but I am not going to pull it down just because of that. I am also in touch with a couple of companies that actively keep using it (it's paid consulting, not open source). They didn't have a problem with uvloop version so far.\nAnyway now with the steps hopefully somebody with spare open-source time can provide a fix before I get into it.\nPlease don't continue this discussion here, but in japronto repo instead.. ",
    "0x161e-swei": "I was able to reproduce this with server provided in vmbench with the same load generator.\nThis server was configured to use uvloop and httptools.\nSimply printing from data_received function gives me this:\nb'GET /256 HTTP/1.1\\r\\nHost: 10.157.90.165:25000\\r\\n\\r\\nGET /256 HTTP/1.1\\r\\nHost: 10.157.90.165:25000\\r\\n\\r\\nGET /256 HTTP/1.1\\r\\nHost: 10.157.90.165:25000\\r\\n\\r\\n'\nIt is unlikely that this is a bug of sc2682cornell since the same load generator works perfectly with a Flask server.. Also profiled using wireshark, all the HTTP packets, sent from the client side, captured have a single request.. Interestingly I can indeed reproduce this with asyncio with httptools using the same server code at vmbench\nAs of unit test. I am afraid I cannot.. If I understand this correctly, the data_received function is called before the httpparser from httptools is even involved, right?. I was able to reproduce all these bugs with original wrk with HTTP pipeline script.\nIt seems that uvloop and asyncio do not have support for HTTP pipelining?. ok. now it makes sense to me.\nSo a data object in data_received function consisting of multiple requests is an expected behavior if the client is using HTTP pipelining?. ",
    "benjolitz": "Thank you 1st1. You\u2019re correct.\nI had not noticed that asyncio is stupidly opinionated in the interface for sharding out tasks to another worker.. That's not short sighted - given the relative stasis that stdlib packages exist in, time-wise, it is quite reasonable to expect that interface restriction (no coroutines) will not change. You're free to be irked over my use of the word \"stupid\" but I stand by it being opinionated given that it's usually within the purview of an executor instance to reject unusable tasks (submit or an internal method).\nEither way, that's a part of the ecosystem that's probably not going to change.. ",
    "fantix": "@1st1 Thanks! I'm trying to quickly profile asyncio/sslproto.py, shall follow up with results here.. Vanilla asyncio echo server on Python 3.7b3 without SSL:\n\nWith SSL:\n\nI've repainted this in red (sslproto.py) and green(_ssl module):\n\nThis gives a rough idea about the time portfolio:\n\nIt's true that there is no single bottleneck in sslproto.py.\n_ssl module is taking quite some time, 90% of which is on read() and write() of _ssl.SSLSocket, and 9% on _ssl.MemoryBIO.\n\nTop tottime detail data:\nncalls | tottime | percall | cumtime | percall | filename:lineno(function)\n-- | -- | -- | -- | -- | --\n1200003 | 10.24 | 8.537e-06 | 10.24 | 8.537e-06 | ~:0()\n600006 | 6.573 | 1.095e-05 | 6.573 | 1.095e-05 | ~:0()\n600009 | 4.789 | 7.982e-06 | 17.19 | 2.865e-05 | sslproto.py:157(feed_ssldata)\n600009 | 4.74 | 7.9e-06 | 4.74 | 7.9e-06 | ~:0()\n313269 | 3.829 | 1.222e-05 | 63.06 | 0.0002013 | base_events.py:1642(_run_once)\n600009 | 3.821 | 6.369e-06 | 18.51 | 3.085e-05 | sslproto.py:641(_process_write_backlog)\n313278 | 3.2 | 1.021e-05 | 3.2 | 1.021e-05 | ~:0()\n600000 | 2.86 | 4.767e-06 | 6.207 | 1.034e-05 | sslproto.py:231(feed_appdata)\n600009 | 2.432 | 4.054e-06 | 48.54 | 8.089e-05 | selector_events.py:790(_read_ready__data_received)\n600006 | 2.215 | 3.691e-06 | 41.36 | 6.894e-05 | sslproto.py:502(data_received)\n600000 | 2.115 | 3.525e-06 | 2.115 | 3.525e-06 | ~:0()\n313269 | 1.956 | 6.245e-06 | 5.571 | 1.778e-05 | selectors.py:553(select)\n600003 | 1.437 | 2.396e-06 | 20.16 | 3.361e-05 | sslproto.py:569(_write_appdata)\n600006 | 1.42 | 2.367e-06 | 8.121 | 1.353e-05 | selector_events.py:830(write)\n313268 | 1.112 | 3.55e-06 | 2.488 | 7.941e-06 | selector_events.py:558(_process_events)\n1200003 | 1.081 | 9.008e-07 | 11.33 | 9.438e-06 | ssl.py:698(read)\n5140518/5140477 | 0.9978 | 1.941e-07 | 0.9978 | 1.941e-07 | ~:0()\n600040 | 0.9382 | 1.564e-06 | 50.39 | 8.398e-05 | events.py:86(_run)\n600040 | 0.9134 | 1.522e-06 | 49.45 | 8.241e-05 | ~:0()\n600011 | 0.9081 | 1.514e-06 | 1.376 | 2.293e-06 | base_events.py:1624(_add_callback)\n600000 | 0.8536 | 1.423e-06 | 21.17 | 3.528e-05 | sslproto.py:375(write)\n600000 | 0.7963 | 1.327e-06 | 21.96 | 3.66e-05 | echoserver.py:73(data_received)\n600006 | 0.6575 | 1.096e-06 | 0.6575 | 1.096e-06 | ~:0()\n2401300 | 0.637 | 2.653e-07 | 0.637 | 2.653e-07 | ~:0()\n600006 | 0.537 | 8.95e-07 | 0.537 | 8.95e-07 | ~:0()\n2 | 0.4861 | 0.243 | 63.55 | 31.77 | base_events.py:504(run_forever)\n1801088 | 0.3929 | 2.181e-07 | 0.3929 | 2.181e-07 | ~:0()\n600000 | 0.3147 | 5.245e-07 | 2.43 | 4.049e-06 | ssl.py:710(write). Just made a very simple PoC, the improvement is not significant. I'll keep trying on something else tomorrow, just posting the results here for now.\n\n\nncalls | tottime | percall | cumtime | percall | filename:lineno(function)\n-- | -- | -- | -- | -- | --\n1200000 | 10.04 | 8.365e-06 | 10.04 | 8.365e-06 | ~:0()\n600006 | 6.57 | 1.095e-05 | 6.57 | 1.095e-05 | ~:0()\n600009 | 3.858 | 6.43e-06 | 3.858 | 6.43e-06 | ~:0()\n600000 | 3.519 | 5.865e-06 | 29.98 | 4.997e-05 | sslproto.py:888(_do_read)\n305014 | 3.079 | 1.009e-05 | 3.079 | 1.009e-05 | ~:0()\n305005 | 2.853 | 9.353e-06 | 53.28 | 0.0001747 | base_events.py:1642(_run_once)\n600000 | 2.651 | 4.419e-06 | 13.75 | 2.292e-05 | sslproto.py:868(_do_write)\n600006 | 2.325 | 3.874e-06 | 32.99 | 5.498e-05 | sslproto.py:794(buffer_updated)\n305005 | 2.124 | 6.964e-06 | 5.646 | 1.851e-05 | selectors.py:553(select)\n600009 | 1.954 | 3.256e-06 | 38.95 | 6.491e-05 | selector_events.py:761(_read_ready__get_buffer)\n305004 | 1.941 | 6.362e-06 | 3.643 | 1.195e-05 | selector_events.py:558(_process_events)\n600000 | 1.694 | 2.824e-06 | 1.694 | 2.824e-06 | ~:0()\n600006 | 1.618 | 2.696e-06 | 8.361 | 1.394e-05 | selector_events.py:830(write)\n600011 | 1.19 | 1.983e-06 | 1.703 | 2.838e-06 | base_events.py:1624(_add_callback)\n1200000 | 1.137 | 9.474e-07 | 11.17 | 9.312e-06 | ssl.py:698(read)\n600000 | 0.9503 | 1.584e-06 | 14.7 | 2.45e-05 | sslproto.py:725(write)\nJust curious about Trio, which is using the same stdlib _ssl module (MemoryBIO, read() and write()): \nWith SSL:\n\nWithout SSL:\n\n. All above tests are using cipher ECDHE-RSA-AES256-GCM-SHA384, I'll quickly try ECDHE-RSA-AES128-GCM-SHA256.\n\nUsing ECDHE-RSA-AES128-GCM-SHA256 didn't produce much difference, 8.53 vs 8.47. Let me try to tweak the buffer size.. Sorry for the delay! Tweaking buffer size had no luck. Actually:\n\nasyncio has similar read buffer size as uvloop, 256KB vs 250KB. Tried both 2560KB with asyncio, and master uvloop.\nThe test data is small enough to fit in the read buffer for each request - there are 0.6mil socket.send() calls, and 1.2mil _SSLSocket.read() calls. From sslproto.py this looks like half of the _SSLSocket.read() calls provided all decrypted data in one go, the other half simply raised WANT_READ to break the loop in feed_ssldata().\n\nI'm thinking of these TODOs next, please kindly advice:\n\nPort the PoC to uvloop/sslproto.pyx to see how it works.\nProfile and improve cpython/Modules/_ssl.c (tried ltrace a bit, result is not yet convincing).\nRewrite asyncio/sslproto.py with new _ssl.c perhaps.\n\n(Similarly, quick-and-dirty PoCs first.). Got it, thanks! Meanwhile there's also a possibility to make uvloop use pyOpenSSL, libuv-tls or similar libs directly (as a last way).. Fixed two buffer size issue in the PoC, and tested again with:\n\nPython 3.7.0b5\nOpenSSL 1.1.0h\nECDHE-RSA-AES256-GCM-SHA384\nTested with both 1KB requests and 100KB requests\n5 tests for each combination\n\nResults:\n\n\nThe SD is kind of large, probably because of a bad testing environment.\nStill the PoC new sslproto.py is approximately 10% ~ 20% faster, however I doubt it could still keep the advantange if it is completed with all the error checks, shutdown, etc.\nThe effect applying \"read ahead\" and \"partial write\" flags is not significant, \"partial write\" may be helpful, but I haven't check or fix any side effects the flags may bring.\n\n~I'm trying this in uvloop, as well as call SSL-related methods in threads, will update soon.~ Results of uvloop comparing to the same non-uvloop:\n\n. In the process testing with 100kB requests, I found that SSL_read() is returning maximum 16kB data (the record size for SSLv3/TLSv1 according to the manual), which caused roughly 8x~16x more function calls to _ssl.SSLSocket.read() than the number of calls to sslproto.data_received(). \nPrevious commit embeds the loop in _ssl.c, and improved the overall performance by approximately 30%~40%. Because the test subject is an echo server, making _ssl.SSLSocket.read() return more leads to much less calls to echoserver.data_received(), therefore less calls to transport.write().\n\nWe could actually do the same in sslproto.py to combine decrypted data into a bigger buffer, then call client data_received(). UPDATE: tested and verified the conclusion, both C-level fix and Python-level fix have the same improvement.\nThis has no effect if the payload is small (like 1kB).. \ud83d\ude03  currently working on a relatively more complete sslproto.py on latest cpython master, should be ready to show by tomorrow.. Fully buffered - also supporting client BufferedProtocol. \ud83d\ude04. It's taking longer than expected, previous commit shows the rough idea - \nI'm trying to separate the flow control (FC), and extract a more clearer state transition model tomorrow, in order to survive e.g. renegotiation.. Sure thing!\nLooks like renegotiation is a bit awful - Python didn't expose it, OpenSSL didn't do it fully right, HTTP/2 forbid it, and TLS1.3 replaced it with something else. I'll try to get it working and tested with minimal effort - perhaps copying some tests from Trio as Nathaniel seemed already walked through this.\n\n\nEventually figured out how renegotiation works in Python, there are quite some implications:\n\nIf the other peer initiates a renegotiation by sending a Hello message (probably together with other regular data messages), SSLObject.read() is required to consume the Hello message.\nThis call to SSLObject.read() will write a handshake message into the outgoing buffer.\nSSLObject.write() won't do - it doesn't touch the incoming buffer at all. Therefore, calling SSLObject.write() before SSLObject.read() would only send app data as usual, with the Hello message staying in the incoming buffer.\nHowever, it raises an ssl.SSLSyscallError to call SSLObject.write() after SSLObject.read() consumed the Hello message, until the renegotiation is done.\n\nTherefore, I came up with this process diagram:\n\n\nWhenever data arrives, always call SSLObject.read().\nBecause we cannot send anything during a renegotiation, downstream writes need to be buffered (in the write_backlog buffer).\nAny SSLObject.read() may write data into the outgoing buffer or complete a renegotiation, therefore we should always try (the blue arrow) to write data from write_backlog into the SSLObject without waiting for the next downstream write (missing from current cpython), and flush the outgoing buffer if any (present in current cpython).\nThe flow control is done differently. Current cpython simply forward events between upstream and downstream. I'd like to keep each SSLprotocol independent, water marks (high/low for incoming, and high/low for outgoing + backlog) can be separately tweaked in scenarios like SSL over SSL over SSL.\nExplicit handshake and shutdown is not yet considered.\n\nMeanwhile, I'm still trying to fit this into a state transitioning diagram - states probably make more sense with explicit handshake and shutdown included.\n\n\n\nWritten data from APP is buffered during DO_HANDSHAKE and SHUTDOWN, then processed afterwards accordingly.\n\nOther than the 4 original states, I added 3:\n\nThe two PASSTHRU are used between get_buffer() and buffer_updated() in UNWRAPPED  mode to ignore any environment changes (very unlikely), when app reading is not paused and we could just pass it through without buffering locally.\nThe NO_CONNECTION is used so that we don't have to judge if self._transport is None.. Thanks! No worries, I didn't want to make too frequent noises, just about to ask for your review and next steps.\n\nThe renegotiation support is actually done in previous commit. It turns out that as far as we follow the process diagram to call OpenSSL functions with those implications considered, current TLS<=1.2 renegotiation shall just work. It's manually tested, a unit test would require pyOpenSSL installed, though I'm not sure if that is practical in cpython source code.\nFor the two renegotiation issues, 1) duplex traffic during renegotiation: it seems that OpenSSL had already fixed the issue, by preventing sending app data once it had sent the renegotiation Hello. I didn't find the actual fix, but verified the behavior (test code is a bit ugly), so it should just work fine now. 2) TLS 1.3 rekeying is still in OpenSSL 1.1.1 beta, so it is a future thing I think.\n\nAnother finding during fixing cpython tests is about canceling handshake. SSL/TLS has this user_canceled alert to manually cancel an ongoing handshake. OpenSSL has this type too, but exposed no API (should use ssl3_send_alert() to send a user_canceled). Therefore, we shall simply close the underlying connection in this case. (The state diagram above is updated with a few transitions to NO_CONNECTION on errors)\n\nA side topic - we may be able to support user-random SSL wrap/unwrap in the same TCP connection without reconnecting (transitioning between UNWRAPPED and WRAPPED multiple times). Original sslproto.py won't stay in UNWRAPPED state for too much time, but still allowed unencrypted data passing through for an extremely short while after a successful shutdown before connection lost. (Also, current asyncio supported one-time upgrading by inserting an SSLProtocol before user protocol by loop.start_tls())\nThe worry is about being unwrapped by the peer - application protocol needs to be aware or even in charge of the SSL downgrading, or sensitive data may be sent in plaintext by mistake. For now, an SSL close_notify alert coming from the peer is received as an empty read (sslobj.read() returns b''). We may use similar pattern to notify the app protocol that this connection is being unwrapped - if data_received(b'') happens, then all data will be in plaintext afterwards. We could also allow user to configure the behavior of response to close_notify alerts, either close the connection directly, or downgrade immediately, or even let the user to choose when to respond to the close_notify alert with calling unwrap().\nI think this is getting too far, sorry for the long story! It might be better to just stay with closing the connection immediately as the first part of RFC 5246 7.2.1 stated, and leave the random wrap/unwrap to a new feature. If so, I'll simply clean up the pass through logic (also the one from original sslproto.py), and make sure all traffic is always encrypted.. About the performance thing, I just realized that I\u2019ve been comparing encryption time with loopback network time, which is probably not a practical anchor point. So I\u2019ve compared the absolute throughput of OpenSSL(with this benchmark tool found in Elvis's reference) and cpython/_ssl.c(with asyncio echo server and cProfile), the result is: 2059 MB/s vs 1390 MB/s (68%). I think this is a reasonable result, considering async overhead, BIO memory copy overhead and Pythonize overhead.\nThis probably means that our initial problem was incomplete - SSL connections are 3-4x slower than regular connections when the network time is about the same as encryption/decryption time. If the encryption/decryption time was 10% of the network time, then current SSL implementation is supposed to be adding another 15% ~ 30% overhead.\nMaking the time consumed in the _ssl module as the anchor point (unit of one), the first PoC sslproto.py was 34% faster (1.29 -> 0.85), and the decrypted data aggregation fix was 70% faster (0.52 -> 0.15) on 100KB echo server. In this special combo case, sslproto.py is improved to only take about 10% of the time spent in _ssl module, that is 6.5% extra overhead overall comparing to previous 15% ~ 30%, which is good enough I think.. Got a few local commits, will update tomorrow.  :)\n. The failing test is unstable, ~checking now~.\n```\nUnexpected calls to loop.call_exception_handler():\n...\n {'exception': RuntimeError('no python buffer is allocated in on_read; nread=-4095',),\n  'message': 'Fatal error on transport UnixTransport',\n  'protocol': ,\n  'transport': }]\nFAIL\n======================================================================\nFAIL: test_create_unix_connection_ssl_1 (tests.test_unix.Test_UV_UnixSSL)\n\nTraceback (most recent call last):\n  File \"/home/decentfox/uvloop/uvloop/_testbase.py\", line 102, in tearDown\n    self.fail('unexpected calls to loop.call_exception_handler()')\nAssertionError: unexpected calls to loop.call_exception_handler()\n```\nAccording to libuv docs, the following read_cb might be called with nread=UV_EOF with no buffer allocated.\nhttps://github.com/MagicStack/uvloop/blob/b996e0f7ddc622afbbd06d1640f7804f0a97745c/uvloop/handles/stream.pyx#L935-L980\nHowever, this code didn't handle UV_EOF before above error got raised.. > Ah, that makes sense. Thanks for fixing that; can you make a fix in a separate PR?\nOh sure thing, will do.\n\nWhat's the projected timeline for this PR? I assume you are planning to add more SSL tests, right? Or is it ready for a review now?\n\nYes, I was planning to add more tests (renegotiation for example), and fix some obvious issues and make improvements during the testing. Let's do the review tomorrow anyway, shall we? \ud83d\ude03 . I'm adding a new state FLUSHING before SHUTDOWN (please see updated diagram at top), for cases that:\n\ntransport.close() is called, but there is still data in _write_backlog\nclose_notify is received, but there is still data in _write_backlog\n\nUsually APP data will transiently stay in _write_backlog and immediately be encrypted into SSL data in outgoing buffer. But when the other peer starts an renegotiation, SSLObject will stop the encryption work and wait for renegotiation to finish. So both cases do exist.\nWhile in FLUSHING state:\n\nNo further data will be fed to APP protocol - it'll be simply discarded\nWriting to the transport has no effect - data is discarded and warning will be raised after a few attempts, similar to the behavior of TCPTransport\nThe SSLProtocol keeps trying to flush the data in _write_backlog, and moves to SHUTDOWN state once done\nThe newly-added ssl_shutdown_timeout also covers this state - that means the countdown starts when it enters FLUSHING state. (Took 1.5 hours to correctly write a FLUSHING test first, but only half an hour to actually implement the FLUSHING state \ud83d\ude03). Working on eof_received() case when peer closes the writing channel only, we still flush all pending data if any if possible, send close_notify without waiting for peer's close_notify and close the transport.\n\nA question here - do we want to treat peer's close_notify as a half-close, calling APP's eof_received()? Theoretically it is still possible to send data as far as we don't send close_notify. (Reading this paper, it seems important to let APP protocol know that whether close_notify is received or not. So I think no matter half-close should be supported or not, eof_received() should get called first. Please see new diagram above.)\n\nUpdate: it is now implemented as follows: treating TLS as transport details, close_notify is always considered as EOF for upper APP protocols, while EOF from lower transport level (TCP for example) is considered as a brutal disconnection, thus not causing APP-level EOF.. Spent some time to make it run faster in uvloop - about 20% ~ 40% faster than original uvloop in 1~100 KiB echo benchmark. Here're the cProfiled diagrams for time spent on each module:\n\nAnd here's the SSL benchmark running modified vmbench on a 4-core 2.5GHz cloud server, all benchmarked servers are running in python:3.7 (Debian 9) docker containers (full benchmark data here):\n\nWhere:\n\nssl raw is pure OpenSSL 1.1.0f echo encryption and decryption without network I/O written in C++ based on openssl-bench initially referenced by Elvis, it is the theoretical computing limit.\ngolang (1.7.4) implemented its own TLS transport, well optimized it is assumed, thus it is considered as the computing limit + network I/O.\nssl uvloop protocol is using the new sslproto.pyx with regular EchoProtocol inherited from asyncio.Protocol.\nssl uvloop buffered is similar, but uses EchoBufferedProtocol which has less memory copies, but additional calls added more overhead.\nssl orig uvloop is original uvloop with asyncio.Protocol.\nnodejs is on version 4.8.2.\nssl asyncio protocol is vanilla asyncio with asyncio.Protocol.\ngevent is on version 1.3.5 (with greenlet 0.4.13).\nssl threaded is copied from Curio.\ntwisted is on version 18.7.0.\n\nThe new sslproto.pyx is performing slightly better than Golang at 100KiB, but MemoryBIO added much memory copy overhead which is significant for smaller payloads, still it is 10% ~ 20% faster than original uvloop on throughtput, and 60%~80% faster than cpython.. Thanks a lot for reviewing in late night! \u2764\ufe0f. Totally reasonable. Will do, and I'll see if I can find some more tools or ways to check possible memory issues.. I could reproduce the memory pattern. The memory increase seems to be more relevant to new SSL connection, rather than repeated echo send and recv. So I tested with python examples/bench/echoclient.py --workers 6 --msize 10241 --num 10 --ssl --times 10000, and memory usage of the server stabilized at around 30MB. Increasing the number of concurrent workers to 12, the server memory usage ended up at around 40MB.\nI've also reviewed the code, and made a few small changes. (I'll create a separate PR for the vmbench changes)\nIf okay, I'll rebase again and squash all commits.. Sure thing! Sorry been out of office, will check today.. Seems to be an unstable test, a retest passed. Tried but didn't reproduce locally, I'll try to find clues in the failing log.. Thanks a lot @1st1  \ud83d\ude03\ud83c\udf7b. Added test - took some time to figure out how to reproduce the \"EPOLLHUP with data\" scenario. Now the test is stably failing without the fix.. sure thing!. Thanks for the finding and sorry for the trouble! I'm working on it now.. Tried several combinations (macOS 10.13 Python 3.5, 3.6, 3.7, official pkg and HomeBrew, case-sensitive file system or not, Ubuntu 14.04, 16.04, Python 3.5.2, 3.6, uvloop make with or without debug, pytest or unittest) but didn\u2019t reproduce. Also reviewed code with clues from the traceback. I must have missed something, I\u2019ll try to cover a bit more areas, please kindly suggest:\n\nDoes it crash randomly, or consistently?\nWhat OpenSSL version?\nAny special environment variable?\n\nThanks!. Reproduced the crash with OpenSSL 1.1.1. It's also leading to more issues e.g. hanging test_write_to_closed_transport, failing test_remote_shutdown_receives_trailing_data and also the crash on test_start_tls_client_buf_proto_1. I'll fix them asap.\n\nFor me the case is: test_remote_shutdown_receives_trailing_data is unstable, when it fails, run test_ssl_handshake_timeout, then test_start_tls_client_buf_proto_1 will crash with random error.\n\nFixed unstable test_remote_shutdown_receives_trailing_data, but test_start_tls_client_buf_proto_1 still crashes with full test_tcp run. Interestingly it won't crash if uvloop was built with make debug.\n\nNoticed an issue that _SSLProtocolTransport.__dealloc__ was called twice on the same instance in test_ssl_handshake_timeout. Only pytest has this issue even running this single test only. Two calling stacks:\nFile \"/Volumes/Home/fantix/.pyenv/versions/3.6.6/lib/python3.6/unittest/case.py\", line 608, in run\n    self.tearDown()\n  File \"/Volumes/Home/fantix/PycharmProjects/uvloop/uvloop/_testbase.py\", line 112, in tearDown\n    gc.collect()\nFile \"/Volumes/Home/fantix/.pyenv/versions/3.6.6/envs/uvloop36/lib/python3.6/site-packages/_pytest/warnings.py\", line 96, in pytest_runtest_protocol\n    yield\n  File \"/Volumes/Home/fantix/.pyenv/versions/3.6.6/lib/python3.6/contextlib.py\", line 88, in __exit__\n    next(self.gen)\n\nIt seems that if SSL handshake is aborted externally (by timeout for example), loop.pyx will only close the TCP transport, leaving the SSL transport to GC, but somehow pytest captured the reference after GC and tried to dealloc the same instance again. After fixing loop.pyx to close SSL transport instead, the crash is gone. I'll then fix the hanging test and create a PR.. Thanks for the merge! Please leave this issue open until I figure out how the crash happened so that it won't affect others.. I guess the context manager used in pytest may have triggered some Cython memory bug, but I need some time to confirm that, I'll try to make it early next week.\n\nReproduced the crash: https://gist.github.com/fantix/a1d8b850f0623a39f635ca380bc76948, and it's still crashing on latest master. However, it crashes with pytest only - crash happened during pytest cleanup. It doesn't crash without the explicit gc.collect(). Working on a fix now.. Sure thing. Figured out the cause - resource warning is raised in __dealloc__ of _SSLProtocolTransport, where the transport instance was used as warning source. Then pytest deferred all warning calls to cleanup stage, when the transport instances are already recycled, and caused segmentation fault. I'll fix this asap.. There it is! \ud83d\ude03. Thanks for the reproducing! I'm checking into this.. @1st1 I'm still trying to find a clue, but I can reproduce the issue.. Thanks for the merge!\n@amir20 please feel free to let me know if it has further issues. Thanks!. OK if tests pass I think this PR is good enough now, please kindly review.. Oh I'm stupid, has been investigating why Test_UV_TCPSSL.test_handshake_timeout_handler_leak passes locally while Travis is red ... it is actually failing for Test_AIO_TCPSSL!! Let me see\n\nOkay found the same (part of) bug in asyncio, skipping the test for now, I'll create another PR to fix in asyncio.\n(So the bug is, the handshake timeout handle is never cancelled if the handshake was terminated early - an additional timeout for example. In this case, all objects in the reference chain including SSLProtocol, transport, SSLContext will remain in memory until the handle actually times out, thus it is some kind of a memory leak.). Yay! Green now. Also added a second test.\nUsing Amir's script, it's like this before this fix:\n\nAnd now after this fix:\n\n. I can reproduce this, even after fixing a floating-point precision issue in your demo script:\ndiff\n-        if ti > ti0:\n+        if ti - ti0 > 0.0000001:\nAlso when failing, it is always called 1ms earlier than expected in my ~20 tries. I think the reason is:\n\nlibuv only provides integers in millisecond with uv_now() which is used by uvloop.\nuvloop turns this millisecond to seconds in float.\nAfter tweaking (+ 0.1), the float second is again changed back to integer millisecond truncating all decimals e.g. 0.09899999998742715 * 1000 -> 98, hence losing the 1ms.\n\nI think the fix would be as easy as using round instead of the implicit floor:\ndiff\n-        when = <uint64_t>(delay * 1000)\n+        when = <uint64_t>round(delay * 1000)\nAt least it didn't report an error in 10+ minutes in my local testing.. > Is this the only place that time is converted from float to milliseconds integer?\nYes, this is the only place.\n\nFor now, as a workaround in my code, I simply add 1ms to each timestamp given to call_at().\n\nRight, that should work for now. I'll create a PR to add the round if no objections.. Using ceil() has a side-effect:\npython\nround((123123.1 + 0.1) * 1000)      # 123123200\nmath.ceil((123123.1 + 0.1) * 1000)  # 123123201\nBut yeah, I got your point that when called with loop.call_later(0.0004, ...), it may still get called too early. One possible solution could be to still use round(), but adding a time check before calling, and delay one more millisecond if the check fails. (This would also help with the failing unit test in this PR when PYTHONASYNCIODEBUG=1) However this would add a bit more complexity to the implementation, I'm not sure if it is worth it. Any thoughts, please?. @jlaine replied in https://github.com/MagicStack/uvloop/issues/233#issuecomment-473678282. Yeah I think so. @1st1 thanks for the merge! I'll port this fix to CPython today, and yes I've been working on the port of this SSL implementation to CPython, the process is kind of slow due to my limited time, I'm not 100% sure that it could catch up with the 4/28 or 5/26 deadline, but I'll try!. The same fix comitted at python/cpython#12386. Sure. LOL was rushing to avoid manual protocol code - perhaps it's better be replaced by protocol so that the test can be robust enough even if asyncio changes its implementation in the future.. _do_read() should be removed in _SHUTDOWN, because a peer should start to discard incoming app data once it sends the close_notify alert.. Sure thing!. Right, they were globals and I forgot to rename them.. Sure \ud83d\ude03 . Yeah I was thinking about that too, but didn't go that way because I found no cdef methods in transport, and it was checked somewhere that FlowControlMixin must be a parent class. Let me check and get back to you. If possible, I prefer cdef class too with less dict lookups. \ud83d\ude08. Got it, I'll take a quick look and include it if it's simple. Ha! Been there, should have commented - to make sure the echo is true, the buffer needs to be copied, so that next read doesn\u2019t change previous outgoing data which is still pending. With memoryview and bytes again, the benchmark gets slightly slower, therefore it ended up like this now. Thanks anyway! I\u2019ll add comment.. That\u2019s interesting!. Makes sense, thanks!. Both fixed, thanks for the reviewing!. Makes sense! Will do, thx.. No problem, will do!. Yeah I had the same concern. How about adding an additional flag to make sure it's created only once? https://gist.github.com/fantix/d3135195bc3a51d11e53225a78f3ff85. Oh sure, about to amend that commit with tests and possible further fixes too. Do you think we should merge this initial fix first as a hotfix?. I see, let me try to split the work with more details, and let you know when the first one is ready for review and merge.. ",
    "hynek": "\nDo you feel that 10 seconds is not enough?\n\nHow do you think I found out? ;) 10s is wayyy to short once you have to communicate from/to Africa or Asia. I spent a month in Cape Town and learned this the hard way.\nIn this case I couldn\u2019t communicate with a server in India. If this goes into 3.7 there\u2019s gonna be a lot of...reports. :D. It would also be great if we could do something about the output btw.. > What default timeout would you suggest\nNo clue! Check what browsers or Java or Go do maybe?\n\nYou mean the errno/CertificateError error? Or the \"... stalled during handshake\" error message?\n\nBoth \u2728 \nAlthough the errno thing is a lot more severe.. (I can live with it staying at 10s btw as long as you give me a knob to turn. :)). Happy to report I can connect to India again. :). ",
    "roy2220": "@1st1 Thanks for you time and advice! That is a subtle situation, I spended a whole day to figure out the behavior of Task.cancel, finally I made a patch to Task.cancel for more rational behavior. Here is the commit (Actually I patched the _asyncio C module, but here is python for readability).\nIn conclusion, I regard it as a bad design of Task.cancel behavior. I want to submit a bug to bugs.python.org, but this issue is subtle and I'm not good at English, it's somewhat difficult (for me) to describe the situation.. ",
    "japrogramer": "Im having this issue the image is and as you can see im updating setuptools and pip before trying to install from requirements.\n```\nFROM python:3.7.0-alpine3.8\nRUN apk update \\\n    && apk add python3 postgresql-libs \\\n    && apk add --update --no-cache --virtual .build-deps alpine-sdk python3-dev musl-dev postgresql-dev libffi-dev \\\n    && pip install -U setuptools pip \\\n    && pip install --no-cache-dir -r /requirements/local.txt \\\n    && rm -rf /requirements \\\n    && apk --purge del .build-deps\n. This is where it freezes\n  Downloading https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz (1.9MB)\n  Downloading from URL https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz#sha256=a97bd62ebbdf7e6e84bf44afe439d9b24ce4d8661a29a639626a8c03748f6f98 (from https://pypi.org/simple/uvloop/)\n  Ignoring unknown cache-control directive: immutable\n  Updating cache with response from \"https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz\"\n  Caching due to etag\n  Added uvloop from https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz#sha256=a97bd62ebbdf7e6e84bf44afe439d9b24ce4d8661a29a639626a8c03748f6f98 to build tracker '/tmp/pip-req-tracker-ake3ksvf'\n  Running setup.py (path:/tmp/pip-install-iqezhk3g/uvloop/setup.py) egg_info for package uvloop\n    Running command python setup.py egg_info\n    running egg_info\n    creating pip-egg-info/uvloop.egg-info\n    writing pip-egg-info/uvloop.egg-info/PKG-INFO\n    writing dependency_links to pip-egg-info/uvloop.egg-info/dependency_links.txt\n    writing top-level names to pip-egg-info/uvloop.egg-info/top_level.txt\n    writing manifest file 'pip-egg-info/uvloop.egg-info/SOURCES.txt'\n    reading manifest file 'pip-egg-info/uvloop.egg-info/SOURCES.txt'\n    reading manifest template 'MANIFEST.in'\n    warning: no previously-included files matching '' found under directory 'vendor/libuv/.git'\n    warning: no previously-included files matching '' found under directory 'vendor/libuv/docs'\n    warning: no previously-included files matching '' found under directory 'vendor/libuv/img'\n    writing manifest file 'pip-egg-info/uvloop.egg-info/SOURCES.txt'\n  Source in /tmp/pip-install-iqezhk3g/uvloop has version 0.11.2, which satisfies requirement uvloop from https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz#sha256=a97bd62ebbdf7e6e84bf44afe439d9b24ce4d8661a29a639626a8c03748f6f98\n  Removed uvloop from https://files.pythonhosted.org/packages/5c/37/6daa39aac42b2deda6ee77f408bec0419b600e27b89b374b0d440af32b10/uvloop-0.11.2.tar.gz#sha256=a97bd62ebbdf7e6e84bf44afe439d9b24ce4d8661a29a639626a8c03748f6f98 from build tracker '/tmp/pip-req-tracker-ake3ksvf'\nBuilding wheels for collected packages: uvloop\n  Created temporary directory: /tmp/pip-wheel-dl4xx4sw\n  Running setup.py bdist_wheel for uvloop: started\n  Destination directory: /tmp/pip-wheel-dl4xx4sw\n  Running command /usr/local/bin/python -u -c \"import setuptools, tokenize;file='/tmp/pip-install-iqezhk3g/uvloop/setup.py';f=getattr(tokenize, 'open', open)(file);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, file, 'exec'))\" bdist_wheel -d /tmp/pip-wheel-dl4xx4sw --python-tag cp37\n  running bdist_wheel\n  running build\n  running build_py\n  creating build\n  creating build/lib.linux-x86_64-3.7\n  creating build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/init.py -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/_patch.py -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/_testbase.py -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/_noop.py -> build/lib.linux-x86_64-3.7/uvloop\n  running egg_info\n  writing uvloop.egg-info/PKG-INFO\n  writing dependency_links to uvloop.egg-info/dependency_links.txt\n  writing top-level names to uvloop.egg-info/top_level.txt\n  reading manifest file 'uvloop.egg-info/SOURCES.txt'\n  reading manifest template 'MANIFEST.in'\n  warning: no previously-included files matching '' found under directory 'vendor/libuv/.git'\n  warning: no previously-included files matching '' found under directory 'vendor/libuv/docs'\n  warning: no previously-included files matching '' found under directory 'vendor/libuv/img'\n  writing manifest file 'uvloop.egg-info/SOURCES.txt'\n  copying uvloop/cbhandles.pxd -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/cbhandles.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/dns.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/errors.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/loop.c -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/loop.pxd -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/loop.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/pseudosock.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/request.pxd -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/request.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/server.pxd -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/server.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  copying uvloop/sslproto.pyx -> build/lib.linux-x86_64-3.7/uvloop\n  creating build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/async_.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/async_.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/basetransport.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/basetransport.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/check.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/check.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/handle.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/handle.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/idle.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/idle.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/pipe.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/pipe.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/poll.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/poll.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/process.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/process.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/stream.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/stream.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/streamserver.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/streamserver.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/tcp.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/tcp.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/timer.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/timer.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/udp.pxd -> build/lib.linux-x86_64-3.7/uvloop/handles\n  copying uvloop/handles/udp.pyx -> build/lib.linux-x86_64-3.7/uvloop/handles\n  creating build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/init.py -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/compat.h -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/consts.pxi -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/debug.h -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/debug.pxd -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/python.pxd -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/stdlib.pxi -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/system.pxd -> build/lib.linux-x86_64-3.7/uvloop/includes\n  copying uvloop/includes/uv.pxd -> build/lib.linux-x86_64-3.7/uvloop/includes\n  running build_ext\n  checking for a BSD-compatible install... /usr/bin/install -c\n  checking whether build environment is sane... yes\n  checking for a thread-safe mkdir -p... ./install-sh -c -d\n  checking for gawk... no\n  checking for mawk... no\n  checking for nawk... no\n  checking for awk... awk\n  checking whether make sets $(MAKE)... yes\n  checking whether make supports nested variables... yes\n  checking build system type... x86_64-unknown-linux-gnu\n  checking host system type... x86_64-unknown-linux-gnu\n  checking for gcc... gcc\n  checking whether the C compiler works... yes\n  checking for C compiler default output file name... a.out\n  checking for suffix of executables...\n  checking whether we are cross compiling... no\n  checking for suffix of object files... o\n  checking whether we are using the GNU C compiler... yes\n  checking whether gcc accepts -g... yes\n  checking for gcc option to accept ISO C89... none needed\n  checking whether gcc understands -c and -o together... yes\n  checking for style of include used by make... GNU\n  checking dependency style of gcc... gcc3\n  checking if gcc supports -pedantic flag... yes\n  checking for gcc way to treat warnings as errors... -Werror\n  checking if gcc supports -fvisibility=hidden... yes\n  checking if gcc supports -g flag... yes\n  checking if gcc supports -std=gnu89 flag... yes\n  checking if gcc supports -Wall flag... yes\n  checking if gcc supports -Wextra flag... yes\n  checking if gcc supports -Wno-unused-parameter flag... yes\n  checking if gcc supports -Wstrict-prototypes flag... yes\n  checking for ar... ar\n  checking the archiver (ar) interface... ar\n  checking how to print strings... printf\n  checking for a sed that does not truncate output... /bin/sed\n  checking for grep that handles long lines and -e... /bin/grep\n  checking for egrep... /bin/grep -E\n  checking for fgrep... /bin/grep -F\n  checking for ld used by gcc... /usr/x86_64-alpine-linux-musl/bin/ld\n  checking if the linker (/usr/x86_64-alpine-linux-musl/bin/ld) is GNU ld... yes\n  checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n  checking the name lister (/usr/bin/nm -B) interface... BSD nm\n  checking whether ln -s works... yes\n  checking the maximum length of command line arguments... 98304\n  checking whether the shell understands some XSI constructs... yes\n  checking whether the shell understands \"+=\"... no\n  checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n  checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n  checking for /usr/x86_64-alpine-linux-musl/bin/ld option to reload object files... -r\n  checking for objdump... objdump\n  checking how to recognize dependent libraries... pass_all\n  checking for dlltool... no\n  checking how to associate runtime and link libraries... printf %s\\n\n  checking for archiver @FILE support... @\n  checking for strip... strip\n  checking for ranlib... ranlib\n  checking command to parse /usr/bin/nm -B output from gcc object... ok\n  checking for sysroot... no\n  checking for mt... no\n  checking if : is a manifest tool... no\n  checking how to run the C preprocessor... gcc -E\n  checking for ANSI C header files... yes\n  checking for sys/types.h... yes\n  checking for sys/stat.h... yes\n  checking for stdlib.h... yes\n  checking for string.h... yes\n  checking for memory.h... yes\n  checking for strings.h... yes\n  checking for inttypes.h... yes\n  checking for stdint.h... yes\n  checking for unistd.h... yes\n  checking for dlfcn.h... yes\n  checking for objdir... .libs\n  checking if gcc supports -fno-rtti -fno-exceptions... no\n  checking for gcc option to produce PIC... -fPIC -DPIC\n  checking if gcc PIC flag -fPIC -DPIC works... yes\n  checking if gcc static flag -static works... yes\n  checking if gcc supports -c -o file.o... yes\n  checking if gcc supports -c -o file.o... (cached) yes\n  checking whether the gcc linker (/usr/x86_64-alpine-linux-musl/bin/ld -m elf_x86_64) supports shared libraries... yes\n  checking whether -lc should be explicitly linked in... no\n  checking dynamic linker characteristics... GNU/Linux ld.so\n  checking how to hardcode library paths into programs... immediate\n  checking whether stripping libraries is possible... yes\n  checking if libtool supports shared libraries... yes\n  checking whether to build shared libraries... yes\n  checking whether to build static libraries... yes\n  checking whether make supports nested variables... (cached) yes\n  checking for dlopen in -ldl... yes\n  checking for kstat_lookup in -lkstat... no\n  checking for gethostbyname in -lnsl... no\n  checking for perfstat_cpu in -lperfstat... no\n  checking for pthread_mutex_init in -lpthread... yes\n  checking for clock_gettime in -lrt... yes\n  checking for sendfile in -lsendfile... no\n  checking for socket in -lsocket... no\n  checking for special C compiler options needed for large files... no\n  checking for _FILE_OFFSET_BITS value needed for large files... no\n  checking sys/ahafs_evProds.h usability... no\n  checking sys/ahafs_evProds.h presence... no\n  checking for sys/ahafs_evProds.h... no\n  checking that generated files are newer than configure... done\n  configure: creating ./config.status\n  config.status: creating Makefile\n  config.status: creating libuv.pc\n  config.status: executing depfiles commands\n  config.status: executing libtool commands\n    CC       src/unix/libuv_la-async.lo\n    CC       src/unix/libuv_la-core.lo\n    CC       src/unix/libuv_la-dl.lo\n    CC       src/unix/libuv_la-fs.lo\n    CC       src/unix/libuv_la-getaddrinfo.lo\n    CC       src/unix/libuv_la-loop-watcher.lo\n    CC       src/unix/libuv_la-getnameinfo.lo\n    CC       src/unix/libuv_la-loop.lo\n    CC       src/unix/libuv_la-pipe.lo\n    CC       src/unix/libuv_la-poll.lo\n    CC       src/unix/libuv_la-process.lo\n    CC       src/unix/libuv_la-signal.lo\n    CC       src/unix/libuv_la-stream.lo\n    CC       src/unix/libuv_la-tcp.lo\n    CC       src/unix/libuv_la-thread.lo\n    CC       src/unix/libuv_la-timer.lo\n    CC       src/unix/libuv_la-tty.lo\n    CC       src/unix/libuv_la-udp.lo\n    CC       src/unix/libuv_la-linux-core.lo\n    CC       src/unix/libuv_la-linux-inotify.lo\n    CC       src/unix/libuv_la-linux-syscalls.lo\n    CC       src/unix/libuv_la-procfs-exepath.lo\n    CC       src/unix/libuv_la-proctitle.lo\n    CC       src/unix/libuv_la-sysinfo-loadavg.lo\n    CC       src/unix/libuv_la-sysinfo-memory.lo\n    CC       src/libuv_la-fs-poll.lo\n    CC       src/libuv_la-inet.lo\n    CC       src/libuv_la-threadpool.lo\n    CC       src/libuv_la-uv-data-getter-setters.lo\n    CC       src/libuv_la-uv-common.lo\n    CC       src/libuv_la-version.lo\n    CCLD     libuv.la\n  ar: u' modifier ignored sinceD' is the default (see `U')\n  building 'uvloop.loop' extension\n  creating build/temp.linux-x86_64-3.7\n  creating build/temp.linux-x86_64-3.7/uvloop\n  gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -DTHREAD_STACK_SIZE=0x100000 -fPIC -I/usr/local/include/python3.7m -I/tmp/pip-install-iqezhk3g/uvloop/vendor/libuv/include -c uvloop/loop.c -o build/temp.linux-x86_64-3.7/uvloop/loop.o -O2\n  uvloop/loop.c: In function '__pyx_f_6uvloop_4loop_9UVProcess__after_fork':\n  uvloop/loop.c:107423:3: warning: 'PyOS_AfterFork' is deprecated [-Wdeprecated-declarations]\n     PyOS_AfterFork();\n     ^~~~~~~~~~~~~~\n  In file included from /usr/local/include/python3.7m/Python.h:125:0,\n                   from uvloop/loop.c:20:\n  /usr/local/include/python3.7m/intrcheck.h:18:18: note: declared here\n   PyAPI_FUNC(void) PyOS_AfterFork(void) Py_DEPRECATED(3.7);\n                    ^~~~~~~~~~~~~~\n```. ",
    "vproman": "Run this command to recreate issue:\ndocker run python:3.7 pip install uvloop==0.8\nAs a workaround, you can either use python 3.6 instead:\ndocker run python:3.6 pip install uvloop==0.8\nOr you can update uvloop to at least v0.9:\ndocker run python:3.7 pip install uvloop==0.9\n. ",
    "Recro-Barry": "@1st1 is there another issue that addresses this topic? The issue got closed without addressing the main problem at all.. ",
    "saitaro": "\nThe original issue is a setuptools bug. Do a pip install -U setuptools before installing uvloop.\n\nIt doesn't solve the problem for me :/. ",
    "andr-04": "Ok, I compare the implementation with base loop one and see you don't check does the future is cancelled or not yet. It's bad because it's a real usecase to wrap sock_recv by asyncio.wait with a timeout.. Well, I've understood the behaviour and Lock is not a problem there at all; the problem is shifting in the source data structure: before exception we read the data which already is related with other caller.\nI didn't use Cython in real life yet and I'm aware it will take a lot of time to make a fix, check it and write unit tests for it. Especially I've not done it there.\nBut I can to try later.. Well, it more difficult to reproduce than I thought before. I've investigated the problem by write the sequence of operations to the log.\nThe normal pipeline with timeouts is:\n1. await sock_recv;\n2. _on_cancel callback from previously timeout sock_recv;\n3. _remove_reader called by _on_cancle callback;\n4. _add_reader called by the last await sock_recv;\n5. interrupting await sock_recv by timeout with calling fut.cancel().\nIn the InvalidStateError the sequence a little bit differ: before _on_cancel we get _sock_recv. Well, it's really not guaranteed the data must not be received at this time. So, due to the previous future from await sock_recv is cancelled, but the data from socket has read, so it is completely lost.\nAnother issue which I have caught -- even if I add a check the result future must not be cancelled (i.e. if it cancelled just return from _sock_recv without reading), the new _add_reader does not raise _sock_recv for old data which was given, but not read yet. I suppose It is also because of _on_cancel callback is async and can happens after _add_reader: it removes the last reader which is actual. It's more seldom behavior, I've no fair experiment for it.\nAs a solution I suggest to make a subclass from the base Event and redefine cancel method of it to make this part of code be synced. What the name you would like I give for it and what are your views for this solution at all?\nYes, I've reproduced main situation and can add a unit test for it. The second case is related, but more difficult to be clearly reproduced and can be eliminated by suggested solution as well.. Actually, this is not correct behavior yet, I'm testing the additional patch now. Stay tuned please.. ee13f17bd90ffa9c8946ff3d736f6cbbc8772cd5 not helped yet. @1st1, if you have an idea why -- let me know.\nThe difference between base loop and uvloop implementation is base tried to call internal _sock_recv without a reader first. In uvloop it's Cython method, so an initial reading is absent and goes through reader. It looks a collision between removing and adding reader occurs.\nHow can we do this?. ",
    "jamesjer": "Actually, the first error I see in the logs is this one:\n```\nERROR: test_aiohttp (unittest.loader._FailedTest)\n\nImportError: Failed to import test module: test_aiohttp\nTraceback (most recent call last):\n  File \"/usr/lib/python3.7/unittest/loader.py\", line 434, in _find_test_path\n    module = self._get_module_from_name(name)\n  File \"/usr/lib/python3.7/unittest/loader.py\", line 375, in _get_module_from_name\n    import(name)\n  File \"/builddir/build/BUILD/uvloop-0.10.1/tests/test_aiohttp.py\", line 12, in \n    from uvloop import _testbase as tb\n  File \"/builddir/build/BUILD/uvloop-0.10.1/uvloop/init.py\", line 7, in \n    from .loop import Loop as __BaseLoop  # NOQA\n  File \"uvloop/includes/stdlib.pxi\", line 128, in init uvloop.loop\n    cdef long MAIN_THREAD_ID = threading.main_thread().ident\nOverflowError: Python int too large to convert to C long\n```\nChanging the type from long to long long fixes that, and then the other errors all disappear.. ",
    "hroncok": "Oh. I should have posted full log in the first place. Nice catch! . ",
    "vstinner": "It seems like the bug has been fixed by the commit a68f3c9a30a888d0bd28d608f6113f749e9c9cc9.\nMost uvloop tests pass on my 32-bit Ubuntu and Python master (future 3.8). I have a few failures coming from the fact that I didn't install Python, but ran it from the directory where I compiled it from source.. ",
    "frmdstryr": "loop.run_until_complete doesn't work if the loop is already running.\nPerhaps just changing _on_idle to a cpdef would be acceptable?. Ahh, ok.  Thanks for the prompt replies.. ",
    "waghanza": "@chenleo https://www.python.org/downloads/release/python-370/ is too probably young to support\n@1st1 python 3.7 introduce some backwards incompatibilities https://docs.python.org/3.7/whatsnew/3.7.html, does it affect uvloop ?. @1st1 awesome :tada: but why removing appveyor ?. :tada: . waiting https://travis-ci.org/MagicStack/uvloop/builds/400060588 to finish\nmay I suggest using 1 CI that support OSX / Linux / Windows (instead of 2)\nI've found https://cirrus-ci.org/. Could also be the same for other python versions, no ?. :+1: reverting my change, it will be better to refactor test after this. ",
    "chenleo": "0.11 works now! thank you for the fast work!. ",
    "ciscorn": "I wrote a test and then reverted the 124e981bc90fbe2814dd1efd051e5b5a394cf1df, but the test still fails with uvloop.\nI'll investigate further and write a PR.. Sorry, I didn\u2019t remove the generated .c file to rebuild the binary.\nAfter running python3 setup.py bulid_ext --cython-always, the reverted revision passed the test.. @1st1 I added a comment.. ",
    "pvizeli": "Can we have a bugfix release?. ",
    "andrejsh": "Yea, absolutely agree.... ",
    "pitachx": "very annoying bug. ",
    "svjukov": "Same issue, unfortunately . . ",
    "ttill": "Thank you!. ",
    "hellysmile": "travis build for https://github.com/MagicStack/uvloop/pull/191/commits/042d360324c482b07788c3be0c3aced1764f61f4 failed seems due slow travis mac ssl connection and seems not related to this PR, cuz previous commit is green\nCan someone restart these builds?. ",
    "jeffiy": "no i a manually adding libuv files in vendor folder in repository before installing.. Actually i am having proxy issues therefore it command didn't work for me.\n. Sorry for bearing me just one question will UVloop work on arm processor.. @1st1  now i am installing it via pip and getting this error\nmake: Warning: File 'm4/libtool.m4' has modification time 1106448 s in the f                                                                             uture\nCDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/bash /tmp/pip-install-q2hsbafe/uv                                                                             loop/build/libuv/missing aclocal-1.14 -I m4\n/tmp/pip-install-q2hsbafe/uvloop/build/libuv/missing: line 81: aclocal-1.14:                                                                              command not found\nWARNING: 'aclocal-1.14' is missing on your system.\n         You should only need it if you modified 'acinclude.m4' or\n         'configure.ac' or m4 files included by 'configure.ac'.\n         The 'aclocal' program is part of the GNU Automake package:\n         <http://www.gnu.org/software/automake>\n         It also requires GNU Autoconf, GNU m4 and Perl in order to run:\n         <http://www.gnu.org/software/autoconf>\n         <http://www.gnu.org/software/m4/>\n         <http://www.perl.org/>\nMakefile:1116: recipe for target 'aclocal.m4' failed\nmake: *** [aclocal.m4] Error 127\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/tmp/pip-install-q2hsbafe/uvloop/setup.py\", line 270, in <module>\n    test_suite='tests.suite'\n  File \"/opt/python3.6/lib/python3.6/distutils/core.py\", line 148, in setup\n    dist.run_commands()\n  File \"/opt/python3.6/lib/python3.6/distutils/dist.py\", line 955, in run_co                                                                             mmands\n    self.run_command(cmd)\n  File \"/opt/python3.6/lib/python3.6/distutils/dist.py\", line 974, in run_co                                                                             mmand\n    cmd_obj.run()\n  File \"/opt/python3.6/lib/python3.6/site-packages/setuptools/command/instal                                                                             l.py\", line 61, in run\n    return orig.install.run(self)\n  File \"/opt/python3.6/lib/python3.6/distutils/command/install.py\", line 545                                                                             , in run\n    self.run_command('build')\n  File \"/opt/python3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_com                                                                             mand\n    self.distribution.run_command(command)\n  File \"/opt/python3.6/lib/python3.6/distutils/dist.py\", line 974, in run_co                                                                             mmand\n    cmd_obj.run()\n  File \"/opt/python3.6/lib/python3.6/distutils/command/build.py\", line 135,                                                                              in run\n    self.run_command(cmd_name)\n  File \"/opt/python3.6/lib/python3.6/distutils/cmd.py\", line 313, in run_com                                                                             mand\n    self.distribution.run_command(command)\n  File \"/opt/python3.6/lib/python3.6/distutils/dist.py\", line 974, in run_co                                                                             mmand\n    cmd_obj.run()\n  File \"/opt/python3.6/lib/python3.6/site-packages/setuptools/command/build_                                                                             ext.py\", line 75, in run\n    _build_ext.run(self)\n  File \"/opt/python3.6/lib/python3.6/site-packages/Cython-0.28.5-py3.6-linux                                                                             -armv7l.egg/Cython/Distutils/old_build_ext.py\", line 186, in run\n    _build_ext.build_ext.run(self)\n  File \"/opt/python3.6/lib/python3.6/distutils/command/build_ext.py\", line 3                                                                             39, in run\n    self.build_extensions()\n  File \"/tmp/pip-install-q2hsbafe/uvloop/setup.py\", line 198, in build_exten                                                                             sions\n    self.build_libuv()\n  File \"/tmp/pip-install-q2hsbafe/uvloop/setup.py\", line 185, in build_libuv\n    cwd=LIBUV_BUILD_DIR, env=env, check=True)\n  File \"/opt/python3.6/lib/python3.6/subprocess.py\", line 418, in run\n    output=stdout, stderr=stderr)\nsubprocess.CalledProcessError: Command '['make', '-j2', 'CFLAGS= -O2 -fPIC '                                                                             ]' returned non-zero exit status 2.\n\n----------------------------------------\n\nRolling back uninstall of uvloop\nCommand \"/opt/python3.6/bin/python3.6 -u -c \"import setuptools, tokenize;file_                                                                             _='/tmp/pip-install-q2hsbafe/uvloop/setup.py';f=getattr(tokenize, 'open', open)(                                                                             __file);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, fil                                                                             e, 'exec'))\" install --record /tmp/pip-record-6wxxdncc/install-record.txt --si                                                                             ngle-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-                                                                             install-q2hsbafe/uvloop/\n. ",
    "Dj-jom2x": "hmm good morning sir :) I believe termux can do that. I already compiled ffmpeg, lavalink, libopus, quickbms, cython\ni believe the configure is missing while copying..\nso....\nI build uvloop straight from your repo guys\nclone repo\npkg install clang\npkg install automake\npkg install cython\npkg install libtools or libtool i forgot.\ngit submodule update --init --recursive\nthen replace all bin/sh/ into sh only\nbecause on termux bin/sh is invalid..\nalso this configure.ac that generates configure..  i don't know how to edit that ac\n+ autoconf\n    + automake --add-missing --copy\n    configure.ac:38: installing './ar-lib'\n    configure.ac:25: installing './compile'\n    configure.ac:22: installing './config.guess'\n    configure.ac:22: installing './config.sub'\n    configure.ac:21: installing './install-sh'\n    configure.ac:21: installing './missing\nI don't know I just feel that one is responsible of making configure file. it uses /bin/sh .. sorry for my noobness\nso I have to edit it after that..\ni did this clever thing\nbelow touch commands\nwith open( f\"{LIBUV_BUILD_DIR}/configure\", 'r') as f:\n            fdata = f.read()\n        fdata = fdata.replace(\"/bin/sh\",\"sh\")\n        with open( f\"{LIBUV_BUILD_DIR}/configure\", 'w') as t:\n            t.write(fdata)\nthen install it ... pip install .\n$ pip install .\nProcessing /data/data/com.termux/files/home/uvloop\nInstalling collected packages: uvloop\n  Running setup.py install for uvloop ... done\nSuccessfully installed uvloop-0.12.0.dev0\n$\nbtw my solution above is not the answer of the question I make :)\ni use the pip install uvloop then it will return\n ./configure is no such directory\nbut on the fresh from the hub i only need to edit /bin/sh to sh only, else i got this\n./configure: 1: eval: /bin/sh: not found\n    configure: WARNING: 'missing' script is too old or missing..\nwhich is not an issue i guess its pretty normal consider it termux uses command sh directly and not /bin/sh on setup.py\nnow I can install sanic.\nhttps://github.com/channelcat/sanic\nto see whats new \ud83d\ude02.\nhehe. I feel sanic is incomplete without uvloop. I just want to play with it. on my phone :) im currently playing on discordpy flask & redis\n. ",
    "gjcarneiro": "Ah, lovely!  Indeed it's fixed in v0.11.2!  Sorry.\nSorry, I  was convinced I was on the latest uvloop release, but clearly was confused.  Too many microservices.... ",
    "amelchio": "Not really. I am not set up for uvloop development and I don't even know how to reproduce the problem.. ",
    "Forevka69": "\nHm, could you please try uvloop 0.12.0rc1?\n\nOk, i will. ",
    "davidbrochart": "Thanks @1st1. To be more precise, I want to write some Cython code that will use asyncio. If I replace asyncio with uvloop, is it going to involve the CPython interpreter at all (and will that be a big penalty), or is it going to be Cython calling Cython?. ",
    "amir20": "Yes it does. . I am not using UDP. It is only HTTPS and called about 51 requests per second. I'll see what I can do to reproduce it. I have an API, mongo storage and a bunch of other things that need to be stripped. \nI might just create a tight loop with the two versions and record the memory. \n. Alright. I was able to reproduce this pretty easily. \nHere is my script.\n```py\nimport asyncio\nimport os\nimport aiohttp\nimport uvloop\nfrom async_timeout import timeout\nasyncio.set_event_loop_policy(uvloop.EventLoopPolicy())\ndef headers():\n    return dict(authorization=f\"Bearer {os.getenv('API_TOKEN')}\")\nasync def fetch(url):\n    async with aiohttp.ClientSession(headers=headers()) as session:\n        async with timeout(8):\n            async with session.get(url) as response:\n                data = await response.json()\n                return response.status, data\nfor i in range(1000):\n    future = fetch(\"https://api.clashofclans.com/v1/clans/%23UGJPVJR\")\n    code, response = asyncio.get_event_loop().run_until_complete(future)\n    print(i, code)\n```\nI ran this with 0.11.x and after 200 iterations my memory was around 25MB. I used Docker so here is a screenshot. \n\nI did pip install -U uvloop and docker-compose build with the latest uvloop and after 200 iterations the memory is around 64MB. \nScreenshot attached. \n\nI have not investigated any further as to what could be causing this. \n. Nice. Would you be able to get a patch released? . I am testing right now. Will let it run for an hour and post an update. . I think it works. After 30 minutes, its still at 135MB which is a good sign. Great job @1st1 :) . ",
    "ahesford": "I don't believe PR #224 fixes this issue. This issue is caused because the stock asyncio.base_events.Server in Python 3.7 was made into an asynchronous context manager. The entry method is simple:\nasync def __aenter__(self):\n    return self\n\nwhile the exit method closes the server:\nasync def __aexit__(self, *exc):\n    self.close()\n    await self.wait_closed()\n\nThe TCP echo server uses this manager in an async with server clause to ensure the server closes.\nThe uvloop replacement, uvloop.loop.Server, does not implement the methods for an asynchronous context manager in the master branch or in commit #8fac545a9351935eefc0c8d281bebd0dd2917d66 to address PR #224.. ",
    "wrobell": "Nice, thanks.. According to https://www.piwheels.org, no Python 2.7, 3.6 and 3.7 at the moment (personally, I am using 3.7).. Fair enough. Just would like to point out that for Raspberry Pi, you would need to build for armv6 only (see the pypa/manylinux#84 itself). RPi is probably the most popular ARM platform running Python, so IMHO it is worth considering.. ",
    "denismakogon": "When a new release with these changes will be published?. Any estimates for that?. ",
    "mhchia": "Thank you for your reply!\n\nI think it's a rather minor inconsistency that shouldn't cause trouble, isn't it?\n\nAgree. I made an issue in CPython for the document of 3.7+, about the fact that they mentioned \"List of socket.socket objects the server is listening on, or None if the server is closed.\", which is not consistent with the implementation. The issue was fixed, and the behavior of uvloop.server.Server.sockets is aligned with the document of python 3.7+. So there is no issue now:)\n\nHow did you discover this?\n\nI checked asyncio.Server.sockets is None to ensure the server is closed, in Python 3.6. It works, but fails right after I changed to use uvloop.\n. Closed due to no issue now. Thanks! \ud83d\ude04 . ",
    "yope": "@fantix Yes, I think you are right. It definitely is a rounding issue. Is this the only place that time is converted from float to milliseconds integer? I guess all such places would have to be changed...\nFor now, as a workaround in my code, I simply add 1ms to each timestamp given to call_at(). This seems to work well enough for me while waiting for the correct fix.. UVloop has a timer resolution of 1ms, so if call_at of higher than that resolution is made, uvloop may round up or down to whole milliseconds. How it does that is not so important.\nWhat is important, is that whenever I want to call_at() a time that is an integer number of milliseconds, it does not get called at an earlier integer number of milliseconds.\nIn other words, if I run call_at(12.34, func) it does not get called at 12.399. In this case, round() should suffice.\nOTOH, if I call_at(12.3456, func) and func gets called at either 12.345 or 12.236, that is not an issue because this is due to the resolution of uvloop. If you need more resolution than that, don't use uvloop.\n. ",
    "gukoff": "This looks strange. Why not if sys_version_info < (3, 7, 0)?. "
}