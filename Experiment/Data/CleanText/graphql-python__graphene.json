{
    "syrusakbary": "@ashinohara I've fixed the introspection method in the schema.\nJust update your graphene package to 0.1.3 version and run schema.introspect() in your graphene.Schema:\n``` python\nimport json\nschema = graphene.Schema(....)\nintrospection_dict = schema.introspect()\nPrint the schema in the console\nprint json.dump(introspection_dict)\nOr save the schema into some file\nopen('schema.json', \u2018w\u2019) as fp:\n    json.dump(introspection_dict, fp)\n```\n. Thanks @jhgg for showing me the way :wink: \n. Duplicated and better explained in #7.\nClosing this one\n. I want to have automatic field ordering in graphene enabled as default, which is in contradiction with what graphql-core thinks it should be.\nHowever you should be still able to change it whenever you want. Going to merge the code soon.\nLet me know your thoughts on that @jhgg\n. hahaha... almost same commits!\n. Done! :wink: \n. Sure!\n. :+1: \n. Thanks!\n. The easiest solution is add a viewer field to your query.\nThis is how SWAPI Graphene is dealing with it:\nhttps://github.com/graphql-python/swapi-graphene/blob/master/starwars/schema.py#L143\nhttps://github.com/graphql-python/swapi-graphene/blob/master/starwars/schema.py#L169-L170\nClosing this issue, please reopen it if you think have something to do with this implementation.\n. Somehow the schema is not able to reach the node you mentioned.\nA easy hack is doing:\n``` python\n@schema.register\nclass MyNode(relay.Node):\n    name = graphene.StringField()\n@classmethod\ndef get_node(cls, id):\n    return MyNode(MyType())\n\n```\nHowever if you can create a Gist would be great, I would like to know why the schema is not reaching your node.\n. @Globegitter is this problem solved? Let me know for closing the issue.\n. @Globegitter ok! Let me know!! I would love to fix any problem as soon as possible!\n. The reason for the error is the id is not a correct base64 id (for knowing the id for certain node instance, just call your_node_instance.to_global_id() where your_node_instance is a instance of a class that inherits from graphene.Node and have a defined id.\nSo this should work:\npython\nt = Tester(id=\"mo\")\nthe_id = t.to_global_id()\nprint the_id\nAnd then use the_id in the query (id:\"$the_id_value\").\nHowever Graphene should return a None value instead of throwing a error. So will keep this issue open until is solved.\n. @Globegitter This will be fixed (returning None for non-valid ids) in graphene 0.4.0\n. @jhgg Check the reasons for graphene for not going through a TypeRegister.\n. And post any advantages that I might be missing! I would love to discuss that! :)\n. Feel free to reopen the task for discussing that! :)\n. Thanks @adamcharnock, will let you know once the docs are ready!\n. @adamcharnock Some of this new documentation is now living in the docs branch (until is finished and merged into master), take a look and let me know your thoughts! https://github.com/graphql-python/graphene/tree/docs/docs/pages\nFeel free to open any Pull request into docs branch with all the changes/improvements you think could be useful!!\n- [x] docs / Quick start\n- [x] docs / Django Quick start\n- [x] guide / ObjectType\n- [x] guide / Interface\n- [x] guide / Mutation\n- [ ] guide / Fields\n- [x] guide / Relay\n. Great! A new simpler syntax will come with version 0.4.0 that simplifies how arguments and fields are handled\n. Hi @jhgg, I've seen that... I would had love to do it by myself but you been so fast.\nPlease add me to the pypi package as maintainer so I could update it.\nHowever I think the best thing is mixing the django-graphql and the other view from graphene. And provide only one package. Probably the naming could be improved.\nI would love to discuss when a new repo comes out without actually throwing the code into the community, if that makes sense :)\n. Maybe is easier if you start here https://github.com/graphql-python/graphene/blob/master/tests/contrib_django/test_views.py :wink: (vars are not supported in graphene view implementation yet, so are not tested as well)\n. Looks great! @montemishkin \n. @jhgg If you can change the branch to merge into to 0.4.0 instead of master would be great!\n. And... deleting repeated tests maybe?\n. Thank you Jake!\n. @rapilabs the importing issue will be fixed in the upcoming version 0.4.0 ;)\nhttps://github.com/graphql-python/graphene/blob/0.4.0/graphene/init.py#L13\n. Related issue needed to resolve before this task: #57\n. Yup, we can close the issue here and reopen in graphene-django if necessary. This is changed in upcoming version 0.4.0 to <Mutation>Input -> https://github.com/graphql-python/graphene/blob/0.4.0/graphene/relay/types.py#L117\nLet me know if you have more suggestions!\n. Version 0.4.0 is now on master. Closing issue.\n. Thats a good advice! However a quickstart should have everything needed for \"warming up\" and \"working\" doing copy&paste.\nIf you could make the example work with just one file (not importing somewhere) and working I will love to merge it.\nPS: Maybe doing a very simple dict memory storage solution will work :wink: \n. I have to see if everything works, and if is the case I will approve soon! @Globegitter \n. Closing this issue as the Quickstart guide docs are now more detailed now.\nPlease reopen if you feel that something have to be changed.\n. I think having a __str__ method will be useful.\n. Good catch!\n. @Globegitter Will take a look on your example shortly!\n. In your example, you don't really need to create AddressType, just only with relay.ConnectionField(Address, edge_type=AddressTypeEdge) will work.\nYour example is failing because you are using LazyField in a resolved component (LazyField only wants either a string or a function for resolve once the schema is known).\nSo you can solve it doing:\npython\n    edges = graphene.List(AddressTypeEdge)\nOr\npython\n    edges = AddressTypeEdge.List\n. I will keep this issue until LazyType notifies if a wrong input is received (not str or function)\n. Hi @Globegitter!\nThanks to this commit you can return a Connection instance in the ConnectionField resolver.\nhttps://github.com/graphql-python/graphene/commit/fe860774e8525cb50095f857c6013cffbc41f117\nReopen this issue if you find any errors.\n. @Globegitter could you post your schema definition? I could either see if is a problem in graphene or guide you for fixing it :)\n. (the code is the same you posted before?)\n. @inklesspen Yep, is a breaking change but will be accepted.\nHowever a node could only be retrieved by the id arg (there are no other args in the base javascript implementation/ relay specification)\nSo, the syntax could be something like this:\npython\n    @classmethod\n    def get_node(cls, id, info):\n        pass\n. Merged!\n. Great! Merging.... will add a function inspector on top for assure compatibility (checking if the function has one or two args, and decorating with a warning for the old-style get_node.\n. Hi @kiennt,\nYep, adding support for automatic Google App Engine NDB mapping to graphene would be great.\nYou can get inspired how graphene is doing with Django models mapping.\nEverything should be similar except of the converter (which have to be adapted for converting the fields from NDB), and types.py which also have to be adapted for getting the fields from the NDB model.\n. Closing this issue, as @ekampf did a terrific job with graphene-gae, which is now part of the GraphQL-Python community.\n[Would be great to have a PR into this repo adding the docs]\n. I like the example @amitsaha, thanks for contributing!\nThe graphene project runs flake8 syntax checker, and there are some syntax improvements that needed to be made in order to pass flake8 (and pass the tests).\nhttps://travis-ci.org/graphql-python/graphene/jobs/92172692#L337\n. @amitsaha nope, you can directly subclass from graphene.ObjectType ;)\n. Good work!\n. Hi @adamcharnock , just uploaded to PyPI the latest code under version 0.4.1.\nThe models are already wrapped in Django mapping, so you could do:\n``` python\n    @resolve_only_args\n    def resolve_all_accounts(self, **kwargs):\n        return models.Account.objects.all()\n@resolve_only_args\ndef resolve_all_transactions(self, **kwargs):\n    return models.Transaction.objects.all()\n\n```\nA full working example is swapi-graphene. Check the schema which is where everything happens.\nPing me if any question!\n. I removed temporary the version 0.4.1 from PyPI until I add the support for previous get_node syntax. (Will be done in few mins)\n. Reuploaded again, everything should work fine :)\n. Yep, installing latest version of graphql-core (0.4.9 - specified setup.py in graphene) should solve this.\nPlease reopen this issue if not.\n. Oh! That's a bug! Thanks for such a detailed log!\nAs you pointed, if everything works using resolve_transactionsOut it seems that the problem is the field name is not converting well to snake_case.\nSo I will probably start looking there.\nEDIT: ~~Seems to be the the graphene.contrib.django.fields.ConnectionOrListField~~\n. @adamcharnock Could you copy here the output of this execution?\npython\nfield = Account._meta.fields_map['transactions_out']\nprint (field, field.attname, field.name, field.object_type, field.type)\nThanks!\nEDITED: Corrected from fields to fields_map\n. @adamcharnock  I've recreated your issue and the last commit fixes it :)\n. Hi @millerjs!\nI've just added an example of how to use InputObjectType.\nIt's in examples/complex_example.py.\nHope it helps! :)\n. @millerjs open an issue with a example that replicates the error (query and maybe the some similar ObjectTypes used in the query) so I can take a look into it! (the more info I have the better for fixing it!)\n. You have a detailed log where this error was triggering? (file, line)\nCould be very useful for adding more feedback to the developer in future cases by raising a custom detailed exception :)\n. Hi @millerjs, thanks for asking!\nI think path to go will be having snake_cased fields converted to camelCase by default, but adding the possibility for changing this via some global variable or graphene settings.\nWill keep this issue open until graphene adds the ability of not camelCase if defined in settings.\n. @millerjs this is now fixed.\nThanks to a new plugin structure you can even create some plugin for transform the name the way you want.\nThe current usage for disable the auto camelCase is:\npython\nschema = graphene.Schema(query=..., auto_camelcase=False)\nHope it helps! ;)\n. Right now graphene is already transversing Django relations (only if the target model is in some ObjectType in the schema), and resolving to ConnectionFields whenever the target model is defined in some DjangoNode in the schema, without the need for a resolve_FIELD() method.\nI was thinking about adding support to django-filter for filtering the querysets (so you can define which attributes you can filter on).\nI agree that could be very useful having the possibility to autodiscover the schema by searching into the django INSTALLED_APPS (something similar to django.admin is doing).\nAbout optimizing the hits to the dbs only fetching the data needed... I'm working on that! :)\nThe mutations will probably require a little bit more of work!\n. Probably adding custom permissions for querying/updating using django-guardian is also a good enhancement (and could be required when using automutation models?). Thoughts about that?\n. Great work @adamcharnock!\nAbout creating a BaseQuery class for DjangoNodes I think is something very opinionated for the framework. Why? I think imposing the ConnectionField fields names as all_X should be done explicitly by the developer.\nOnce the django-filter integration is done, probably will be not strictly required to create resolve_FIELDNAME methods, as will be resolved by default with the DjangoFilter resolver.\nThoughts?\n. I think creating directly this fields by the developer will be better and less opinionated for the framework. (Maybe having this as some external package?)\nI imagine doing something like this:\npython\nclass Query(graphene.ObjectType):\n    all_droids = DjangoFilterConnectionField(Droid)\n(Note that might not be necessary to create the resolve_all_droids method)\n. @adamcharnock, after taking a deeper look at the gist here are some thoughts:\n- Why convert_form_field_to_djangomodel returns an ID? (If I'm querying for a model inside a model, aka user.group.name, I want to get the whole instance for the group, not just the id)\n- What you think about having SimpleQuerySetConnectionResolver,FilterConnectionResolver as function decorators? So you can also do:\npython\nclass Query(ObjectType):\n    # ...\n    @filter_connection\n    def resolve_all_accounts(self, args, info):\n        return Account.objects.filter(user=info.context.request_context.user) # Only for my user\n- We could also create a Filter class dynamically (aka django_filters.FilterSet) when using DjangoFilterConnectionField, similar as Django Rest Framework is doing, something like:\npython\nclass Query(ObjectType):\n    account = relay.NodeField(accounts_nodes.Account)\n    all_accounts = DjangoFilterConnectionField(accounts_nodes.Account, fields=['name', 'slug', 'created'])\nOverall I really like your solution!\n. Closing this issue as the main PR #60 is merged into master.\n. Hi @amitsaha!\nCan you post this in StackOverflow so will be easier for other people for searching if they have the same problem?\nI would be more than happy for answering! :)\nIf you could post here the stackoverflow post url after would be great\n. @amitsaha You can use #graphql #graphene #python :)\n. Thanks for such a detailed example @inklesspen.\nWill fix this in the next commit.\n. As of the time of writing, there are two Graphene-MongoEngine integrations:\nhttps://github.com/tomasgarzon/graphene-mongoengine by @tomasgarzon\nhttps://github.com/ozanturksever/graphene-mongoengine by @ozanturksever\nWould love to integrate one or another into the graphql-python community.\nClosing the issue, but please comment if you would like to be the official maintainer for graphene-mongoengine in the graphql-python community.. Based on @abawchen initiative, we started the official repo Graphene-mongo that @abawchen will be leading.\nhttps://github.com/graphql-python/graphene-mongo\nAny more contributors will be welcome, so please write here if anyone is interested.. Hi @amitsaha, I'm willing to create a package for integrating graphql in flask easily (with GraphQL and GraphiQL views). Once is done, yeah... any example will be more than welcome!\nMeanwhile I've linked your package in the documentation package (the new version of the website will be released tomorrow):\nhttps://github.com/graphql-python/graphene/blob/docs/docs/pages/community.md\n. I've created the GraphQL-Flask package for using GraphQL in Flask easily.\nAlso, you can check the Flask SQLAlchemy in the sqlalchemy branch:\nhttps://github.com/graphql-python/graphene/tree/sqlalchemy/examples/flask_sqlalchemy\nThis example, with the SQLAlchemy support will be merged soon: #87 \n. Great work! Merging!\n. The main reason is:\n- In the first example, the Query object, as inherits more than one ObjectType is automatically mapped to a Union type. Some how graphql doesn't allow union types for the root query object.\n- In the second example, the objects are not inheriting for ObjectType, so when Query inherit those objects is not copying their fields.\nHowever I certainly believe we should be able to do this in a good way.\nI'm thinking about create the concept of abstract ObjectTypes so you can extend from them without converting in a UnionType.\nSomething like:\n``` python\nclass Query1(ObjectType):\n    class Meta:\n        abstract = True\n    all_accounts = relay.ConnectionField(accounts_nodes.Account)\n    account = relay.NodeField(accounts_nodes.Account)\nclass Query2(ObjectType):\n    class Meta:\n        abstract = True\n    all_transactions = relay.ConnectionField(accounts_nodes.Transaction)\n    transaction = relay.NodeField(accounts_nodes.Transaction)\nclass Query3(ObjectType):\n    class Meta:\n        abstract = True\n    all_users = relay.ConnectionField(accounts_nodes.User)\n    resolve_all_users = ConnectionResolver(accounts_nodes.User)\nclass Query(Query1, Query2, Query3):\n    pass\n```\nThoughts?\n. @jhgg for seeing the print output just open the browser console.\n@Globegitter I'm happy to see you started using the playground, let me know if any suggestions there!\n. I think this thing will be improved in the next version of Relay, so the might send the flattened query\nhttps://github.com/facebook/relay/commit/ca0afe134d29fc8c2dc046be5f91253aebdf8565\nHowever, no idea why graphql-core (and probably graphql-js) doesn't get the fields from fragments... any suggestion @jhgg?\n. Thanks Kyle!\n. @thebritican I'm still thinking a good way for handling the case you commented.\n. @thebritican meanwhile you can use raw graphql-core objects as fields.\nSo this would work:\npython\nclass AddTodo(relay.Mutation):\n    class Input:\n        text = graphene.String(required=True)\n    todoEdge = graphene.Field(theGraphQLCoreType)\nI will try to have this working with graphene around this week.\nPS: Graphene is using graphql-relay library under the hoods, but the function cursor_for_object_in_connection is not yet implemented there, so probably I will implement this in graphql-relay before anything else.\n. @adamcharnock I will work on this ASAP (is superbowl here so probably in the weekend will be difficult).\nNo need for bounties :wink: \n. @adamcharnock I'm revising this now.\nAre you using graphene.Mutation but it seems you should be using relay.ClientIDMutation and mutate_and_get_payload function, as Edges are only relevant to Nodes.\nLet me know if that's the problem.\n. Let me know! I would like to find a good solution for this!! :)\n. @varunarora @defrex @thebritican in the version 1.0 of Graphene Relay edges and connections are created in a easier, cleaner and more understandable way.\nPlease take a look!\nhttps://github.com/graphql-python/graphene/blob/master/graphene/relay/tests/test_connection.py\n. @reinierpd Edge is a very custom ObjectType that depends on the node of the connection, therefore will be a new Edge type per Connection node.\nOnce you have a specific Connection type (MyCustomConnection), you can easily retrieve it's edge with MyCustomConnection.Edge.\nClosing the issue as I think Connections are better defined in later versions of Graphene.\nPlease comment or reopen if you feel there is still not enough info into how to us Connections/Edges now.. I've updated graphene with a big refactor using ClassTypes (shouldn't suppose a problem for fixing the merge issues, but ping me if any question!)\nApart from that I think django-filter should not be a required package by default, instead I think we should only allow the usage of the filter fields if django-filter is present (throwing an error otherwise).\nOther than this and your checklist items everything looks good!\n(I will have to spend more time seeing the tests and the usage for having more insights!)\n. I was thinking something similar to the code you wrote, however I just realized the Field should know which arguments it's going to receive (you cannot send random arguments, as have to be created explicitly), so the arguments have to be typed in the Field definition. Adding then @filter_connection decorator only adds redundancy.\nSo, let's keep it lean and simple, and go with your current implementation without method decorators :)\n. I've been thinking more, and maybe the filter args could be inside a InputObjectType, so instead of requesting:\ngraphql\n{\n   posts(first:2, headline__icontains: \"peter\") {\n      title\n   }\n}\nWe can do \ngraphql\n{\n   posts(first:2, filter: {headline__icontains: \"peter\"}) {\n      title\n   }\n}\nThis way, we can implement exclude very easily too, and if we have more args it wont collide with the filter fields. But I'm not pretty convinced yet.\nThoughs?\n. I think having a order_by arg is fine! :+1: \n. How mount works:\nAll the fields when contributed to a class (meaning, when placed as attrs inside a class), hold a relation to the class where is contributed.\nLike:\npython\nclass MyObjectType(ObjectType):\n    name = Field(String())\nSo the Field(String()) is now referencing it's parent MyObjectType (because it was contributed to it).\nHowever, the inner types (in our case String()) have to hold a reference to MyObjectType, so in this case (for inner types), we use .mount().\nBut, Why referencing or mounting the inner types?\nIt's important to hold this reference somewhere, because in some cases we need to access it, like:\npython\nclass Human(ObjectType):\n    friends = Field(List('self'))\nHope this clarifies a little bit how mounting works! @adamcharnock \n. @adamcharnock for testing with Django db initialized (and setup'ed) you can write this mark from pytest-django, in the tests:\n``` python\nimport pytest\npytestmark = pytest.mark.django_db\n```\nThis is how starwars_django is dealing with it. Let me know if that works ;)\n. I know some graphene developers that are using Django 1.6, so I would like to still support them.\nI can work with you in fixing those tests (even if we add some boilerplate code) ;)\nYou know why the tests seem to fail? Which build? Maybe not testing in Python 3.3+Django 1.9 fixes the tests?\n. I really like your suggestions.\nHowever I think we should remain as lean as possible, that means if we can include the filter_fields attr in the Meta in classes graphene.contrib.django.types.ObjectType and graphene.contrib.django.types.Node would be better (and simpler) than create more Filter... classes.\nSo instead of using DjangoFilterNode, use DjangoNode.\nBut only permit to set the filter_fields attr if is supported by the environment (meaning the django-filter package is installed).\nImplementing this logic in the django ObjectTypeMeta will work better, as DjangoNodeMeta inherits from it, and also the fitler_fields attrs could be also set in django ObjectType.\nApart from that, I think we should create also a DjangoFilterField class, that acts as a Field with a List, but with the filter args (as DjangoFilterConnectionField).\nThoughts @adamcharnock ? :)\n. Maybe, for keeping the logic separated, you can create a separate meta class and let django ObjectTypeMeta extend it (only extend it if the django-fitler is found?).\n. I will take a look tomorrow on the broken tests.\n. Nope, I can improve things also after merge @adamcharnock. However documentation could be really useful\n. I will try to fix the issue with the relations, the test you added really helps! ;)\nIf you can focus on the documentation would be great! :)\n. I have to re-read everything and add some test cases. But this could be merged very soon @adamcharnock :)\n. I've tested this among with the changes in #79 and this is now good to go.\n@adamcharnock @michaelkuty \n. Hi @bigblind,\nconnection_from_list expect an iterable (this iterable had to implement len and a item getter like iterable[20:30] though). Could be a list, could be a lazy list, or anything that you could iter through.\nHowever, we don't iter through the iterable until the end (when we show the results).\nIn the example of Starwars relay the resolve_ships return a complete list. But the swapi example the method returns an iterable.\nSo, for example, when you are using django querysets, the list is only \"resolved\" (aka queried in the DB) when we iter though it (when we return the resolved result), and after the list is sliced.\nSo it will already do in the most optimal way :)\n. Good catch. I will rethink better how we can handle this.\nProbably moving some code from the graphql_relay Python library to graphene and wrapping in some class where people could manage it easily is the path to go!\nWill keep this issue open until we have a good way for handling this case.\n. Not relevant right now. It could be useful create a custom package graphene-geojson.\n. Thanks for such a detailed response!\nMy thoughts... I always think as signals as something potentially async. I feel little bit weird doing a trigger of a signal for retrieving their response in a synchronous way. But the concept of how it should be done is good.\nYou are right about all the points you mentioned. A plugin should be easy to debug, and mutating the object_type in real time it's probably not the best thing to do.\nI will improve the code soon based on your suggestions!\nOfftopic: Explanations on internal code\nGraphene internals have to be improved. Adding internal __docs__, and probably some refactor in the code for making it easier to understand probably are musts in the future.\nRight now I'm more focused in how I want to use graphene.\nEven after 3 major refactors on the internals, the syntax have remained the same (which is great!)\n\nYou can improve the internals whenever you want if the public facing API is well tested, but the syntax is what will make the usage for working on that easier.\n\nA very interesting related video conference: simplicity is complicated.\nHowever, the more simplicity we can achieve also in the code, the better. And any suggestions for improving there will be always welcome :)\n. @adamcharnock the related PR to camelCase plugin: https://github.com/graphql-python/graphene/pull/65\n. @adamcharnock I've improved everything based on your considerations :)\n. @Globegitter The url is not working well (some error in the Graphene IDE?).\nMeanwhile can you copy & paste here the code so I can see what's happening?\n. Will work on that soon! :)\n. This is now fixed in the master branch (1.0.dev version in PyPI), as you can make reusable AbstractType for sharing fields.\nClosing the issue! :)\n. Hi @ustun,\nI've fixed the name argument in Fields with this commit: https://github.com/graphql-python/graphene/commit/2eea03cb62f9c254792f066ca8b697060b2407ed\nSo the first code you wrote would work perfectly.\nAbout the last code you wrote:\n``` python\nimport graphene\nclass Query(graphene.ObjectType):\n    hello = graphene.String(first_name=graphene.String())\ndef resolve_hello(self, args, info):\n    return 'Hello ' + args.get('first_name')\n\nschema = graphene.Schema(query=Query)\nresult = schema.execute(\"\"\"\nquery foo($first_name:String)\n{\n        hello(first_name:$first_name)\n}\n\"\"\", args={\"first_name\": \"Serkan\"})\nprint result.data\n```\nGraphene, converts (by default, could be disabled) not only the field names in ObjectTypes/Interfaces, but also the argument names to be camelCase when you query it.\nSo if you use an argument for having a first_name name, you should query in the GraphQL query using: firstName.\nLike:\npython\nresult = schema.execute(\"\"\"\nquery foo($firstName:String)\n{\n        hello(firstName:$firstName)\n}\n\"\"\", args={\"firstName\": \"Serkan\"})\nAbout the from error, it's a Python syntax error, so Graphene will not show any errors for that, as it will not be executed.\nHope it helps!\n. Thanks for the PR @ustun, I think it would help a lot to people who's starting with Graphene!\nI will think more about having InputObjectTypes as Arguments when used in Fields without specifically writing it!\n. Yeah, any pull request will be more than welcome.\nWe only support Django 1.6+,  so only adding models.GenericIPAddressField into convert_field_to_string should work ;)\n. @adamcharnock is working in #60, which apart of the main propose (filtering in django connections) provides a way for mapping also forms into Graphene types.\n. Right now the code merged by #60 into master allows to convert any kind of form with its fields to a Graphene Type.\nClosing this issue, please reopen if any questions or suggestions ;)\n. Great work! :+1: \n. I'm working in fixing the compatibility in older versions of Django. And adding some basic testing for the command.\nIf you could add some documentation would be great! @lightning18 (just create a dedicated .md file in this folder and I will take care of the rest)\n. @jfeinstein10 already did an amazing work trying to integrate sqlalchemy into graphene.\nI'm going to fork its sqlalchemy graphene branch and preserve his work updated with the recent changes of graphene.\n. Work in progress pull request: #87 \n. @gwind some code ported by @jfeinstein10 was not updated to reflect the SQLAlchemy nature, as you exposed.\nHowever is actually fixed by some commits I did recently: https://github.com/graphql-python/graphene/blob/sqlalchemy/graphene/contrib/sqlalchemy/types.py#L122\n1. The Relay ID field have to be a String, by spec. The field id in the SQLAlchemy model is mapped to an integer, but this query .filter(id='1') works also well in this cases.\nFeel free to fork this work and do any improvements!\n. Graphene is using from_global_id from graphql_relay right now.\nHowever you can customize the id_fetcher function in NodeField (https://github.com/graphql-python/graphene/blob/master/graphene/relay/fields.py#L68)\n. SQLAlchemy support is now merged into master, closing the issue \ud83d\ude0e\n. This is solved by #77.\n. Hi @BillyBarbaro, the problem is in the function arguments, not in the function name (mutate_and_get_payload is only for the Relay mutations).\nInstead of def mutate(cls, args, info): should be def mutate(cls, instance, args, info):\n. :+1: \n. Hi @amitsaha, the \"issue\" is caused because graphene automatically maps snake_case field names and args to camelCase (as camelCase is the preferred way in js clients). So the good query will be\npython\nschema.execute('{ helloId }`)\nYou can disable this auto camelCase behavior doing:\npython\nschema = graphene.Schema(query=Query, auto_camelcase=False)\nRelated issue: #46 \nHope it helps.\n. @amitsaha the errors field in the response is implemented following the GraphQL spec:\nhttps://facebook.github.io/graphql/#sec-Errors\nThis field (errors) will be added if any exception occurs while processing the query (validation or field retrieving).\nThe errors will be written in the response as a field in the json, however you can always wrap the response checking if any errors and changing the HTTP status code accordingly.\n. Great work! Thanks for the patch ;)\n. @dwiel if you wrap your fields with common attributes to a ObjectType, as @Globegitter suggested, the resolver for this ObjectType will be only called once.\nSo yes, resolving field would be called 3 times.\n1. The helloPing field in the Query.\n2. The hello field in HelloPing\n3. The ping field in HelloPing\nHowever, as GraphQL (and graphene as well) is prepared to run the resolving fields functions asynchronously, this is how the nature of resolving queries should look like (as defined by the Spec, when querying we cannot assure that the fields would be resolved in order, hence we cannot depend on other fields resolve value in the same type level).\n. No problem! Closing the issue\n. Never thought about that but makes sense :+1: \n. Reopening the issue as it might be useful to have. Are the inherited classes (trainings.schema.Query and brainstormers.schema.Query) abstract?\nBy abstract I meant this:\n``` python\nIn trainings/schema.py\nclass Query(graphene.ObjectType):\n    class Meta:\n        abstract = True\n```\nCheck this comment in a related issue: https://github.com/graphql-python/graphene/issues/55#issuecomment-160536000\n;)\nGoing to close this issue, but feel free to reopen if is not working for you!\n. @Grmiade Can you copy the output of the error here?\n. Reopening the issue as the previous fix #55 was invalidated by a major refactor.\nThis issue will be fixed very soon (few minutes).\n. @Grmiade A new version of graphene is uploaded to PyPI 0.6.1... use it and everything should be fine! ;)\nhttps://pypi.python.org/pypi/graphene/0.6.1\n. @greenteamer could you detail a little bit more?\nA stacktrace of the Exception or the output of the /graphql endpoint when querying would be useful :)\n. @greenteamer The final query type used in the schema should not be abstract.\nTry with:\npython\nclass Query(ObjectType):\n    note = relay.NodeField(NotesNode)\n    all_notes = DjangoFilterConnectionField(NotesNode)\n(without the Meta)\n. The abstract queries bases should only be used when we inherit the final Query type from them.\nExample:\n``` python\nclass QueryNotes(ObjectType):\n    note = relay.NodeField(NotesNode)\n    all_notes = DjangoFilterConnectionField(NotesNode)\n    class Meta:\n         abstract = True\nclass QueryUsers(ObjectType):\n    user = relay.NodeField(UserNote)\n    all_users = DjangoFilterConnectionField(UserNote)\n    class Meta:\n         abstract = True\nclass Query(QueryNotes, QueryUsers):\n    pass\nschema = graphene.Schema(name='My Schema')\nschema.query = Query\n``\n. Hi @gwind, in the mutation in relay (in the client) you have to specify the output you want when you do thesignin` mutation (example)\nThe clientMutationId output field is automatically added by relay, however you must add the data you want to get to.\nRight now it seems you are doing something like this in the client\ngraphql\nmutation Signin {\n    signin(input:$input_0)\n}\nBut instead you should do:\ngraphql\nmutation Signin {\n    signin(input:$input_0) {\n        session {\n             id\n        }\n    }\n}\nDoes that makes sense?\n. @gwind as far as I know there are some companies playing with graphene for usage in production. And I have few projects too ;)\nThe main question should be directed to Relay, I guess... as the problems that could emerge by graphene are also in the principal graphql-js implementation.\n. Closing this issue, please reopen if the same question arises.\n. Makes sense! Will review this better later.\n. Don't worry! Your work helped a lot! :wink: \nLet me know if you have any suggestions before I merge into master.\nFlask+SQLAlchemy example usage\n. Thanks for asking about that.\nA GraphQL Python client is planned in the roadmap, however we're waiting until Facebook isolates the Relay-core from Relay React so porting Relay-core client to Python will be quite easy.\n. Going to close it until Facebook releases relay-core :)\n. @gwind Quick note, we released the gql package that intends to be a Python client for GraphQL servers. Now is super basic, but it's worth to take a look!\nhttps://github.com/graphql-python/gql\n. Looks great! Thanks for the fix ;)\n. You are completely right.\nHowever the problem is caused by graphql-core library.\nRelated issue: https://github.com/graphql-python/graphql-core/issues/41\nI'm going to work to fix ASAP in graphql-core so will not happen anymore on graphene.\n. Hi @rafales, thanks for asking this!\ngraphene principal focus at the beginning was the syntax and the way you use it.\nHowever, as you mentioned, there are things that could be simplified. And there are others that it's not as easy to simplify when you have support for multiple schemas.\nAs the code-coverage and testing is quite good, it's easy to do internal refactors (it's been three massive internal refactors since we launched in October)\nI would work on this in the long-term run, but any suggestion on what you think could be simplified or pull request for simplifying graphene will be always welcome :wink: \n. ## Initial version: Django approach\nWhen we launched, the way we approached was very similar to Django:\npython\nclass User(graphene.ObjectType):\n    name = graphene.StringField()\nSwitching to SQLAlchemy approach\nBut the main usage problem arises when you want to use a String as a Argument too (not only as a Field). So naming StringField for and Argument was not very intuitive.\nSo then, we switched to something closer to the SQLAlchemy approach:\npython\nclass User(graphene.ObjectType):\n    name = graphene.Field(graphene.String(), my_arg=graphene.Argument(graphene.String()))\nHowever we were not as confortable as we should, as is much more verbose.\nApart from that, this approach was working for SQLAlchemy as mostly the only time you use a type is in a Column function, however in GraphQL a field is another kind of type.\nCurrent approach\nSo we decided to simplify to this:\npython\nclass User(graphene.ObjectType):\n    name = graphene.String(my_arg=graphene.String())\nWhich is much more easier to read and develop.\nConlusion\nIf you have any idea that could make it better (either syntax/framework usage or internal code) I'm quite open for discussing and improving graphene for the benefit of all :)\n. I'm going to close this issue, please reopen it if you have any idea for simplifying the internal code or want to discuss it further! :)\n. @Globegitter You can now use graphene.String(..., deprecation_reason='Deprecated since 1.0') :wink: \n. For limiting field access you can use @gwind suggestion.\nAbout filtering depending on the context, is quite easy:\n``` python\nclass PostNode(DjangoNode):\n    class Meta:\n        model = Post\n        only_fields = ('title', 'description', 'created')\nclass Query(graphene.ObjectType):\n    posts = PostNode.List() # You can also use DjangoConnectionField(PostNode)\n    def resolve_posts(self, args, info):\n        # If you are using graphql-django-view, the request_context is the Django request\n        request = info.request_context\n        return Post.objects.filter(owner=request.user)\n```\nHope it helps!\n. Feel free to reopen if any question! ;)\n. @bradreardon the example @jameswyse pointed should solve the problem.\nWhen with_context was released in graphene v.0.9.0 it was not documented at all, so was easy to run into this problem.\nWe solved this with better documentation. But let me know if you run into more issues.\n. @dgoldstein0 This is now fixed as all the plugins are removed from the codebase, giving place to Middlewares which using Promises seemed to make a much better job.\n. Thanks for pointing this out!\nProbably this could be fixed by using a newer version of react-burger-menu.\n. @Globegitter You can use the way you mentioned, or using inheritance:\n``` python\n    class Human(ObjectType):\n        name = String()\nclass Pet(ObjectType):\n    name = String()\n\nclass Thing(Human, Pet):\n    '''Thing union description'''\n    my_attr = True\n\n```\nExample taken from the objecttype tests\nHowever I feel this current approach (the one I wrote) is not the best one so I was thinking about deprecating it and allow the following:\npython\nclass Thing(Union(Human, Pet)):\n    '''Thing union description'''\nPS: the one you mentioned would be still valid.\nThoughts?\n. @imranolas Sure! A new version will be pushed to PyPI soon! :)\n. Just published a new version to PyPI with this fix and other features \npip install graphene==0.7.1\nRelease notes: https://github.com/graphql-python/graphene/releases/tag/v0.7.1\n. Good catch!\n. Great! However I'm going to add the source option to fields! It makes it much more pleasant to develop!\nSo you can do something like\n``` python\nclass ArtworkNode(DjangoNode):\n    url = graphene.String(source='get_absolute_url')\nclass Meta:\n    model = Artwork\n    filter_fields = ['id', 'title']\n\n```\n. @sgtsquiggs You can retrieve an Artwork Node doing:\n{\n  node(id:\"SOME_STRING\") {\n    id\n  }\n}\nIn this case SOME_STRING will be the value of ArtworkNode.global_id(1).\n. Sure. You can do it using arguments.\n``` python\nclass Query(graphene.ObjectType):\n    artwork = graphene.Field(ArtworkNode, slug=graphene.String())\ndef resolve_artwork(self, args, info):\n    return Artwork.get_by_slug(args.get('slug', None))\n\n```\nThen you can query it with the following query:\n{\n  artwork(slug:\"my_slug\") {\n    id\n    title\n  }\n}\nHope it helps!\n. Hi @Globegitter, I'm investigating it right now.\nEverything should work fine. Are you using graphene.Enum explicitly somewhere? What is the Python version?\n. In the case you where using graphene.Enum previously, can you paste here the code for seeing how are you using it?\n. That's a great contribution!! Merging :+1: \n. Hi @defrex, thanks for the PR!\nI'm actually thinking of allowing DateTime() types inside Fields.\nI will either merge your PR or merge something that allows doing what you described in #105 \n. Great. I just improved graphene according to your proposal, so now you can also do instances of Scalars as Fields or Arguments, like this:\npython\nclass Post(graphene.ObjectType):\n    created = DateTime()\n. Great!\nI will merge once the tests are complete.\n. @sgtsquiggs for doing the pagination it have to know how many elements it have.\nSo its doing a count on the query SELECT count(id)  from artworks where ....\nCan you install the Django debug plugin and see whats the response for that?\nHow to install Django Debug Plugin?\n``` python\nfrom graphene.contrib.django.debug import DjangoDebugPlugin\n...\nschema = graphene.Schema(query=Query, plugins=[DjangoDebugPlugin()])\n```\nAnd then query it like:\n{\n  YOUR_QUERY_FIELDS,\n  __debug {\n    sql {\n      rawSql\n    }\n  }\n}\nPlease post here what queries are happening so I can fix it better :)\n. Which Graphene and Django version are you using?\nAre you hitting the database in the resolve_article function?\n. I think models.Artwork.get_by_pk_or_slug(pk_or_slug) is somehow not hitting the DB.\nCan you try return models.Artwork.first()?\n. Weird, is tested here, for Django versions 1.6, 1.7, 1.8 and 1.9 and the tests are passing.\nAre you already using django-debug-toolbar in your Django project?\n. Ok, I will fix that now, so you will be able to use django-debug-toolbar and DjangoDebugPlugin at the same time.\n. Ummmm... not limit is applied.\nCan you try with DjangoConnectionField and output what happens?\npython\nclass Query(ObjectType):\n    all_artworks = DjangoConnectionField(Artwork)\n. Great! I think I know where is the issue.\nWill push a solution around today.\n. Hi @sgtsquiggs, this is now fixed and tested.\nInstall the latest graphene version pip install graphene==0.7.2. Everything should be running as expected.\nPlease reopen this issue if not.\n. That's right! Merging!\n. Hi @imranolas,\nYou can achieve this by using String references (ala Django):\n``` python\ncategory_type.py\n@schema.register\nclass Category(graphene.ObjectType):\n    Post = graphene.List('Post')\npost_type.py\n@schema.register\nclass Post(graphene.ObjectType):\n    category = graphene.Field('Category')\n```\n. As posted in the pull request #111, there is already another \"undocumented\" way for doing solving this if you don't want to use string references.\n``` python\nclass Category(graphene.ObjectType):\n    Post = graphene.LazyType(lambda _: Post)\nfrom .post_type import Post\npost_type.py\nclass Post(graphene.ObjectType):\n    category = graphene.LazyType(lambda _: Category)\n```\n. Please feel free to reopen if you have any other suggestion of how to achieve it! :)\n. Hi @imranolas,\nYou can actually do this if you don't want to use string references.\n``` python\nclass Category(graphene.ObjectType):\n    Post = graphene.List(graphene.LazyType(lambda _: Post))\nfrom .post_type import Post\npost_type.py\nclass Post(graphene.ObjectType):\n    category = graphene.LazyType(lambda _: Category)\n```\nSorry it's not documented anywhere (Docs will be improved soon too!)\n. Thanks for pointing this!\nThe problem resides in graphql-core, which powers the internals of graphene.\nhttps://github.com/graphql-python/graphql-core/issues/41\nI'm working in resolving this issue there (in graphql-core)... will close the issue here!\n. Thanks! ;)\n. Which graphene version are you using?\n. Thanks! \nThis commit fixed the issue: https://github.com/graphql-python/graphene/commit/314703d7b5380c80fe2ee1e2ad4a3eb3d9ed7fc4#diff-233528cf66f4e9df736a367fe12b2ec1R30\n. Hi @defrex, you have to transform the graphene types into the graphql-core internal types.\nFor that, just do:\n``` python\nclass MyType(graphene.ObjectType):\n   ...\ngraphql_internal_type = schema.T(MyType)\n``\n. @defrex the schema is yourgraphene.Schema` instance.\nLike in here: https://github.com/graphql-python/graphene/blob/master/examples/starwars/schema.py#L56\n. For avoiding that, you can define the schema before any other type.\nhttps://github.com/graphql-python/swapi-graphene/blob/master/starwars/schema.py#L12\nAnd then set the root Query, Mutation and/or Subscription.\nhttps://github.com/graphql-python/swapi-graphene/blob/master/starwars/schema.py#L173\n. Quite useful! Merging :+1: \n. Hi @bigblind! Sorry for taking long time for fixing this.\nNow the home page have no animation on it, so it should be faster and easier to browse!\n. Not anymore! :)\n. I believe this is not longer an issue, as the executors are now standarized using Promises.\nPlease reopen if you see any issue with the latest version.\n. Hi @gwind,\nSorry for taking too much time on this.\nI didn't accepted the pull request because I thought the camelCase should be imposed everywhere or nowhere (having mixed cases in the same schema looks very weird).\nAs I'm not very convinced of what is the best path to choose I will accept the pull request. However this might change in the future.\n. @mamaar I'm currently implementing that.\nI'm thinking about to return the rangeField in the query as a List rather than an ObjectType.\nThe reason for that is the data is mapped as a list in Python.\nSo you could query like:\n{\n    event {\n        ages\n    }\n}\nreturning\njson\n{\n    \"event\": {\n        \"ages\": [0, 10]\n    }\n}\nThoughts?\n. Hi @mamaar,\nI finally added support for postgres RangeFields (and ArrayField, JSONField and HStoreField).\nIt will output the field data as a js list with two elements [lower, upper].\nYou can try it in the last version of graphene==0.8.0 :wink: \n. As @mjtamlyn commented, this will be probably not implemented in graphene.relay as is not in the relay spec.\nClosing this issue.\n. Good catch!\nThis was fixed in Django with the commit https://github.com/graphql-python/graphene/commit/314703d7b5380c80fe2ee1e2ad4a3eb3d9ed7fc4#diff-233528cf66f4e9df736a367fe12b2ec1R30 but forgot to replicate in SQLAlchemy.\n. I will probably improve it later using the default method, as keep things simpler!\n. Looks good! Thanks for the improvements!\n. By definition, only GraphQL ObjectTypes can inherit from an Interface, so is not possible.\nBut I think it could be reasonable to add other abstraction so they can both (InputObjectType and ObjectType) inherit from it.\n. In 1.0 I added the AbstractType type that could be inherited from InputObjectType, Interface, ObjectType and Mutation (Mutation.Input too). This way we can reuse and share fields more easily.\nHere's the documentation for it!\nhttp://docs.graphene-python.org/en/latest/types/abstracttypes/\nClosing the issue.\n. InputObjectType and ObjectType are two completely different types in GraphQL, and can't be shared there. Therefore, a type for each needs to be created in order to use it as input, or output type.. Sorry for taking some time in taking a look. I've been in vacations... but I'm back!\nrelay.Connection as you mentioned should call super. Fixing this now.\n. Hi @varunarora, at first sorry for taking so long in replying... I was in vacations until yesterday.\nThe error is caused by django_filter, not graphene[django]. You can try uninstalling it, as is incompatible with Django 1.6, with:\nshell\npip uninstall django-filter\nThen, importing graphene should work fine :)\nPlease reopen this issue if not, or if you have any other question.\n. That's a bug... Fixing!\n. Thanks for such a detailed issue @kaglowka.\nTaking a look right now.\n. This is now fixed in master.\nYou can use now in Input doing:\npython\nclass OneFieldMutation(ClientIDMutation):\n    class Input:\n        one = MyEnum(description='This is a MyEnum field')\n. v0.7.3 is now as Graphene release in Github \ud83d\ude03\nhttps://github.com/graphql-python/graphene/releases/tag/v0.7.3\n. Hi @sdcooke,\ngraphql explicitly doesn't set any DateType and graphene chose this path too.\nHowever I can see the usefulness in this.\nCheck the custom scalars section in graphene documentation.\nI'm thinking about an option for adding this to graphene in a configurable way.\n. I finally added complete support for conversion from DateField to a DateTime scalar in graphene that will output the python date in a ISO-8601 format (Javascript Date format).\nYou can update graphene to the last version 0.8.0 and it will be working as expected.\n. Should be covered. I will push a fix soon :wink: \n. The GraphQL spec currently don't define any way for extending the Error entries (for handling validation on fields, for example) https://facebook.github.io/graphql/#sec-Errors\nSo graphene will wait until the spec is better defined in this sense (we could implement something but could be confusing for the users as didn't reflect what is happening in other implementations that follow the spec).\nHowever, I would like to give you a solution for form validation:\nAdd a validation_errors field in the mutation, and use it.\n``` python\nclass Mutation(graphene.Mutation):\n    introduce_ship = graphene.Field(IntroduceShip)\n    validation_errors = graphene.List(graphene.String())\n@classmethod\ndef mutate(cls, instance, args, info):\n    try:\n        # whatever you want to do\n    except Exception, e:\n        return Mutation(validation_errors=[str(e)])\n\n```\n. I just seen this article, you might find it useful!\nhttps://medium.com/@tarkus/validation-and-user-errors-in-graphql-mutations-39ca79cd00bf#.btrdt641t\nI will try to talk with the GraphQL-js main developers (fb) and see how we can improve the spec regarding more personalized errors.\n. An update here:\nI'm working in using Promises for the graphql-core package and upgrading for being compatible with the last graphql spec 0.5.0. As soon this PR (https://github.com/graphql-python/graphql-core/pull/54) is merged would be very easy to add custom errors in graphene.\n. Hi @DasIch,\nI think it's a great proposal!\nShould be good to start a discussion about how we want to use it!\nI was thinking of something like:\npython\nclass ArticleInput(DjangoInputObjectType):\n    class Meta:\n        form = ArticleForm\nI like mapping form.errors to the context. I think would be good if is done explicitly.\nThoughts?\n. If you remove the resolve_id method in the GQUser class it will automatically took it.\nHowever if you still want to get it you can do return self.id\n. Currently we use the id, but I'm open for define a more flexible way for approaching this!\n. Looks great! \ud83d\udc4d \nMerging (in few hours a new graphene version will be in pypi)\n. Good catch! This will be solved soon!\n. Good idea! Right now it could be achieved easily by looking at the releases:\nhttps://github.com/graphql-python/graphene/releases\n. Hi @mbrochh the reason this error is happening is because a mismatch between graphql versions in client side and server side.\nGraphene is compatible with graphql 0.4.18, but it seems you are using graphql 0.5.0 in your client side. I'm working for being compatible with the last version of the spec.\nGraphQL April 2016 version generalizes the support of locations in directives, and this change is not yet reflected in the grapqhl powering graphene, so the introspection query is a little bit different.\nWhat you can do for fix this issue?\n- Downgrade your local graphql-js version to 0.4.18.\n- Update your js introspectionQuery to use the same one required in graphene:\njs\nvar introspectionQuery = `query IntrospectionQuery {\n    __schema {\n        queryType { name }\n        mutationType { name }\n        subscriptionType { name }\n        types {\n            ...FullType\n        }\n        directives {\n            name\n            description\n            args {\n                ...InputValue\n            }\n            onOperation\n            onFragment\n            onField\n        }\n    }\n}\nfragment FullType on __Type {\n    kind\n    name\n    description\n    fields(includeDeprecated: true) {\n        name\n        description\n        args {\n            ...InputValue\n        }\n        type {\n            ...TypeRef\n        }\n        isDeprecated\n        deprecationReason\n    }\n    inputFields {\n        ...InputValue\n    }\n    interfaces {\n        ...TypeRef\n    }\n    enumValues(includeDeprecated: true) {\n        name\n        description\n        isDeprecated\n        deprecationReason\n    }\n    possibleTypes {\n        ...TypeRef\n    }\n}\nfragment InputValue on __InputValue {\n    name\n    description\n    type { ...TypeRef }\n    defaultValue\n}\nfragment TypeRef on __Type {\n    kind\n    name\n    ofType {\n        kind\n        name\n        ofType {\n            kind\n            name\n            ofType {\n                kind\n                name\n            }\n        }\n    }\n}\n`;\nHope this helps!\nPlease comment or reopen this issue is you have more issues!\n. Hi @sehmaschine, this is how I approached the same issue in swapi-graphene.\nExample swapi-graphene totalCount query.\ngraphql\n{\n  myFavoriteFilm: film(id:\"RmlsbToz\") {\n    id\n    title\n    episodeId\n    characters(first:5) {\n      totalCount\n      edges {\n        node {\n          name\n        }\n      }\n    }\n  }\n}\nImplementation: https://github.com/graphql-python/swapi-graphene/blob/master/starwars/schema.py#L18-L22\nAnd then use connection_type in your EntryNode:\n``` python\nclass EntryNode(DjangoNode):\n    class Meta:\n        model = Entry\nconnection_type = Connection\n\n```\nHope it helps!\n[Reopen this issue if you run into some errors or have more questions in the process].\n. Good catch. I think is something that is not very easy to solve as it depends on other fields to resolve before the debug, but could be possible to achieve.\nWill do some research on that.\n. Closing issue, as this is now documented.\n. (will reopen once I start working in the next stable version, as I will refactor the plugin system).\n. I've created the core-update branch in graphene based on your work with fix in tests and other enhacements.\nClosing this PR, and opening from the core-update branch :)\n. Thank you for referencing it! I will put a link in the graphene community page.\n. I just fixed this in the latest commit.\n. I believe this is fixed in graphene 1.0.dev (master branch).\nPlease reopen the issue if not! :)\n. Hi @HelloYie, you cannot \"quit\" the GraphQL context inside a GraphQL query.\nIn fact, there is a good reason for that:\nIf you quit the GraphQL context, GraphQL could not assure that all the mutations that the client sent are executed.\n. Good catch. Thanks! :)\n. Hi @Globegitter, for simplifying the executors in graphql-core we got rid of the middleware, so there is no longer any way for having multiple \"middlewares\" at the same time.\nWhat could be the use case for having middleware?\n. I think is reasonable adding middleware.\nI'm checking various implementations like:\n- express (node.js)\n- Koa (node.js)\n- Django Middleware\n- aiohttp\n- GraphQL-Ruby (Ruby)\n- sangria\nActually I'm thinking to use something similar to aiohttp, but using promises.\n. I added support for middlewares, now you should be able to add tracking :)\n. Check instructions here: http://graphene-python.org/docs/middleware/\n. @Globegitter any feedback on the middleware? :)\n. @mjtamlyn @danielfarrell thanks for opening the issue and the PR.\nFor achieve more simplicity, context and info args will be not mandatory in the resolver in the next stable version of graphene (see Roadmap).\nSo resolvers could access the context and info only if they requested explicitly by using the with_context and with_info decorators.\nThe current implementation only uses with_context, as step in the middle before the next stable release.\nPS: In JS this is a little bit easier as you could call a function with less arguments than required without triggering an error as it will complete the argument values with undefined, so they didn't have this problem\nMakes sense?\n. I would like to discuss about that.\nSomehow I like having the args exposed directly as keyword arguments in the resolver.\nLike:\n``` python\nclass Query(graphene.ObjectType):\n    say = graphene.String(what=graphene.String())\ndef resolve_say(self, what):\n    return \"Hey {}\".format(say)\n\n```\nI think it's too verbose having info and context as required arguments... as are not going to be used always. Since we moved the context outside info, do we really use/need info in the general case? And therefore... it should be a required arg/kwarg?\nMaybe using decorators (like with_context, with_info) could have some side effects, so I don't mind to revisit.\nI would like to get into a solution that could solve both points of view, or at least get closer.\nMerging args and context, info in one dict is another possible solution (like: dict(args, context=context, info=info)). \nBut then, we could have collision between argument names and context/info.\nMore proposals? Thoughts?\n. Hi @mjtamlyn, @Globegitter.\nI've been researching and Jinja use the decorators for passing some extra args to the function.\nhttp://jinja.pocoo.org/docs/dev/api/#jinja2.contextfunction\nImplementation: https://github.com/pallets/jinja/blob/75685ec5e5079bcdbd443696c3d79d0cb86f7cf8/jinja2/utils.py#L41\nAlso, if this is the chosen path for graphene and context/info in functions could be completely possible to skip this behavior. (as it will be done via middleware).\nI'm not very sure yet about what's the good choice here though.\nAnother option, is grouping context and info in other instance and pass something like:\npython\ndef resolve_blablabla(self, context_with_info, **args):\n    pass\n. @ekampf @mjtamlyn @Globegitter I've been thinking in a good way to solve this for a long time.\nIf we use a magical approach using inspect, we could make the api's more obscure and handling things like middleware could become a problem (as the middleware functions have to be aware of the resolver context based on the inspection of the original function).\nAlso, the resolver in graphene should have exactly the same structure as is in graphql-core.\nI'm thinking of merging back context into info, so you can have functions like:\npython\ndef resolve_blablabla(self, args, info):\n    context = info.context\n    # ...\nThoughts?\n. I think I found a way to make the resolvers much more fun to write using type annotations in Python 3.\nWould love to get some feedback! @Globegitter @mjtamlyn @ekampf\nCode and examples of usage in the PR: #500. Good catch. Will fix this soon\n. Plugins are now deprecated. If you were using DjangoDebugPlugin please see the latest docs for integrate DjangoDebugMiddleware.\nhttp://graphene-python.org/docs/django/debug/\n. (using the middleware should solve the problem)\n. Thanks for the catch! \ud83d\udc4d \n. It means that the AnonymousUserType is not registered in the schema, as there is no direct pointer from a field to it, and therefore the only available ObjectType for Customer is UserType.\nYou can solve by decorating the class, like:\npython\n@schema.register\nclass AnonymousUserType(Customer):\n    pass\nHope it helps!\nPlease reopen the issue if not.\n. Could you do print(str(schema)) and output here the results?\n. Ok, I think I found the issue.\nThe Customer interface as is written there, is not a real GraphQL interface, but an abstract one (because of the abstract=True in the Meta).\nThe real interface is six.with_metaclass(DjangoObjectInterfaceMeta, Customer), which is the one the UserType inherits.\nTry extending the same interface class from AnonymousUserType.\nSomething like:\n``` python\nCustomerInterface = six.with_metaclass(DjangoObjectInterfaceMeta, Customer)\n@schema.register\nclass AnonymousUserType(CustomerInterface):\n    pass\nclass UserType(CustomerInterface):\n    # ...\n```\n. You are right.\nHave you tried this?\n``` python\nclass Customer(graphene.Interface):\n    id = graphene.Int()\n    email = graphene.String()\n    name = graphene.String()\n    first_name = graphene.String()\n    last_name = graphene.String()\n    phone = graphene.String()\n    receive_notifications = graphene.Boolean()\n    receive_update_emails = graphene.Boolean()\n    shipping_destinations = graphene.List(ShippingDestinationType)\n    payment_methods = graphene.List(PaymentMethodType)\n@classmethod\ndef _resolve_type(cls, schema, instance, *args):\n    if instance.is_anonymous():\n        return AnonymousUserType.internal_type(schema)\n    return UserType.internal_type(schema)\n\nclass AnonymousUserType(Customer):\n    pass\nclass UserType(DjangoObjectType):\n    class Meta:\n        interfaces = [Customer]\n    # ...\n```\n. Oh! It should, I will work on a fix :)\n. @iawia002 @HelloYie version of Django and graphene?\n. Thanks!\n. That could be a good idea.\nIt this field type inside sqlalchemy, or in a third party library?\n. Postgresql SQLAlchemy field conversion is now available in 1.0.dev (master branch).\nClosing the issue!\n. #177 should fix this issue.\n. Good work on the PR. Will merge once the tests are passing :)\n. It seems the only error right now will be solved by changing allMyNodes to contextNodes in the expected dict and some minor python flake8 things ;)\n. Looks good for me, please fix the tests so I can merge:\nhttps://travis-ci.org/graphql-python/graphene/jobs/131773091#L448\n. @AdrielVelazquez \nAnother thing, for assuring that everything work... could you add this test too?\n(all numbers starting in a string should be skipped).\npython\ndef test_to_const_skip_first_char_if_number():\n    assert to_const('13 snakes $1. on a \"#plane') == 'SNAKES_1_ON_A_PLANE'\n. I was worried about Enum names, not values... but that should work.\nMerging!\n. Thanks for the fix!\n. I think is worth to take a closer look into this approach.\nAlso, having an order that strictly determine all the items in the queryset is somewhat essential for pagination.\nMy ideas here are:\n- Use CursorPaginatedConnection when possible (if a query order its defined).\n- Use the current behavior otherwise.\nLet's play with it in a branch that could let us see the edge cases\n. I think is possible to fix schema.register adding the type also in the types argument in GraphQLSchema (GraphQL v0.5.0)\nIf you please can post (here or creating a test scenario in a branch) the code for showcasing this bug would be great. So I can be make sure that the fix is working :)\n. Just pushed a fix into master. Please reopen if you find more problems with it.\n. The Django integration now lives on its own package, and this issue is now fixed in graphene-django on master. :)\n. Hi @iawia002, the latest version of flask-graphql have the graphiql endpoint in the/graphql` url.\nYou have to enable it having the option graphiql=True:\npython\napp.add_url_rule('/graphql', view_func=GraphQLView.as_view('graphql', schema=schema, graphiql=True))\n. I think this is reasonable :)\n. Thanks for the ping. This is now fixed :)\n. @emekanw it takes some time to load.\nIf is still not loading would be very helpful know your browser and version. :)\n. Thanks for posting, will take a look soon! :). Makes sense! Sorry for reviewing so late, I've been spending a lot of time in the next version of graphene lately!\nPlease take a look and let me know your thoughts!\nhttps://github.com/graphql-python/graphene/tree/1.0\n. Closing PR, seems to be directed to graphene 0.10.X and it's a behavior that should be fixed in 1.X.\n(Feel free to reopen another PR if this is not fixed in master). There is no much progress in the planning phase related to the GraphQL execution.\nOther than that, now is possible to use DataLoaders with Graphene, solving the N+1 loading problem.\nhttp://docs.graphene-python.org/en/latest/execution/dataloader/\nClosing the issue, please feel free to open a new issue (or comment here) if there is something left to be better defined.. That should be fixed in master! Closing the issue.\n. Closing the issue as there is no short-term plans to adopt graphql-cats.\n(Will reopen once comes back into the plans!). Hi @MrSurly, I think the issue is in typing Null instead of null in the input.\nHopefully this will solve the issue, please reopen if not.\nPS: Your understanding in the nullables is perfect :)\n. Thanks for submitting the issue!\nI've updated the docs reflecting the latest version usage of Flask-GraphQL.\nhttps://github.com/graphql-python/graphene-python.org/commit/60ba59b2bcc9c3e2f5c9fa4ffa167a660f0490b8\n. Makes sense! Thanks for the fix :)\n. This should be fixed in graphene-django:master. Closing here :)\n. Hi @stefanfoulis, the docs were wrong... the actual attribute is filter_order_by. Fixing it now.\n. Thanks for the catch!\n. Thanks for the PR! Merging :)\n. Thanks! Merging\n. Yeah, you're right!\n. Hi @mattbillenstein, you can get the exceptions with result.errors.\nBut I agree with you that the exceptions handling in GraphQL/Graphene should be better when playing with it. I'm researching in few different ways to improve it, any help will be always welcome too.\n. Exception handling has been improved significantly in Graphene 2.0, we can close the issue but @mattbillenstein feel free to reopen if you think is still an issue.. There is a bug in the pytest coverage package in Python 3.5... that's why tests failed, your changes are perfectly valid.\nMerging!\n. I think this is solved in the latest version of Graphene, GraphQL core and Promise.\nPlease reopen the issue if not!. @tom-zeit the first parameter of the Field is the GraphQL type, and is named as type keyword argument.\nYou can bypass this this by doing:\npython\nbla = graphene.Field(DocumentNode, _type=graphene.String(name='type'))\nPlease reopen the ticket if this doesn't work or you run in more issues.\n. This is now fixed in graphene-django in master. Closing :). Graphene doesn't support that yet, it might be a good case to add!\n. @ekampf This issue is hard to fix with the current architecture implementation. However I'm assuring that in 1.0 version no problems like that will happen.\nA testcase that replicates the issue could be very helpful too :)\n. This parallel execution issue should no longer exist with the current reimplementation (master branch, 1.0.dev version in PyPI).\nPlease reopen the issue if the problem is not mitigated when using the dev version.\n. Sorry for taking time for merging this. The PR looks good \ud83d\udc4d \n. Oh! Good catch! This is a unintended behaviour\n. This is fixed in master. Closing the issue!\n. Hi @impguard thanks for submitting the issue.\nIn the next version of graphene, the session will be tied to the context, and would be very easy to change the context session depending on the route :)\n. Closing the issue.\nYou can now use a custom session tied to the GraphQL context_value :).\nThe SQLAlchemy integration is now living here: https://github.com/graphql-python/graphene-sqlalchemy\n. Not yet, is completely possible to support it though!\nI would be super happy to merge a integration for that, if you are interested in creating a PR! :)\n. The graphene-django repo is now separated in its own repo.\nhttps://github.com/graphql-python/graphene-django/\nFeel free to open a PR with a integration for django-mptt!\n. Hi @nickhudkins!\nFirst of all, thanks for raising your concerns.\nI'm now involved in the next version of Graphene (1.0) that will improve a lot the code in the core.\nWith this version, both Django and SQLAlchemy integrations will be separated in other repos, so the collaborations will be easier to do and maintain.\nAny PR to the main codebase will be always welcome.\nI will add happily as collaborator/maintainer to anyone that contributes periodically into the framework.\n. The first stage of the Plan for maintenance is more clear now, so here's a heads up!\nDifferent repos\nAll the Graphene integrations are now separated into different repos. The docs are also in each repo, so maintaining and updating them is much easier now! :)\nTransparency and Core Contributors\nAs the integrations are now separated from the core, is easier to achieve better project permissions.\nThis integrations will have more transparency and core maintainers apart of myself. I have few people in mind for each of the integrations (excluding the ones that are already maintained and created by other people, like graphene-gae and graphene-peewee).\nProject priorities\nAlso, for the main repository, graphene we will take advantage of the new feature of Github -Projects- and use it as board of the priorities for the project. Any idea will be discussed and we will decide as community what are the features we want graphene to have, while preserving compatibility and assuring a good path for the future!\nPS: Graphene 1.0 will be released quite soon!\nPlease let me know if you have any other suggestion! :)\n. This should be fixed now!\nPlease let me know if the issue persist!\n. This behavior is defined by django-filters, so it's seems is required.\nAs Graphene-Django doesn't enforce this behavior closing the issue seems the path to go.\nFeel free to open a PR in the graphene-django repo if something could be more clear transmitted in the docs!\n. This should be fixed in 1.0.dev (master). Closing the issue.\n. This is fixed in 1.0. Closing the issue :)\n. I'm working on fixing this and isolating the docs in a new repo. In few hours will be solved.\nThanks all for the support!\n. This is now fixed.\nThe docs are now living in https://github.com/graphql-python/graphene-python.org\n. Good catch! I would like to merge.\nI'm refactoring the base code of graphene, so would be great if we have tests covering the use case so we assure support for this in the future (the tests will remain very similar even in the refactor).\n. Thanks!!\n. Thanks for the suggestion, It might be possible that we merge the docs back.\nThe main reason for keep them separate was isolating the docs/website building away from the travis testing, but there might be a intermediate formula to make all people happy! :)\n. Hi @nirshubz, it's possible to use the UUIDs as long as you can map from a UUID to a type/model.\nSo, given a UUID get the corresponding model.\nWith the current implementation this is not as easy to achieve but with the upcoming version 1.0 it will be trivial:\nhttps://github.com/graphql-python/graphene/blob/1.0/graphene/relay/tests/test_node_custom.py\n. A quick update on this issue!\nThe 1.0.dev version is live on PyPI, I recommend you to give it a try having a similar approach to this: https://github.com/graphql-python/graphene/blob/master/graphene/relay/tests/test_node_custom.py\nUsually for mapping this random id's to type+id is useful to have a \"utility table\" that stores what is the table/type corresponding to each \"UUID\".\nHope that helps!\n. This will be fixed in 1.0.dev once we support disabling auto_snakecase (soon).\n. This is now fixed in master with the commit: https://github.com/graphql-python/graphene/commit/9f30aa2d45761aa29b03585adde8ff556f3a3ba3\n(You can update graphene with pip install graphene>=1.0.dev).\n. Yeah, that's a bug! Thanks for all the detailed information, I will take a look!\n. This should be fixed in the master branch in graphene-django! :)\n(feel free to open the issue there if this problem still occur).\n. It seems to be a bug. Thanks for reporting :)\n. 1.0 was the first approach of remaking the core of graphene. After doing all the implementation I realized I made some assumptions that were making the code less understandable and more coupled.\nBecause of that I created another branch: next with a cleaner and more maintainable implementation.\nWhat are the main differences between 1.0 and next?\n\n1.0 was coupling the GraphQL definition to the graphene type definition\nnext separated this graphene to GraphQL conversion in a TypeMap definition.\nnext is separating the Interfaces from ObjectTypes\nnext have AbstractTypes that could be inherited from any Interface, ObjectType or InputObjectType.\n\nBecause of this reasons the next branch will be the one that graphene adopts for its next version: 1.0 (and the 1.0 current branch will replaced will next)\n. 1.0.dev is now in master.\nAlso is uploaded to PyPI (you can install it with graphene-sqlalchemy>=1.0.dev).\n. Let me reopen this PR, I think makes sense to have AbstractTypes inheritance in Mutation Inputs.\n. Hi @Globegitter, thanks for the contribution!\nAbstractTypes are meant to be generic and and allow inheritance to ObjectTypes, Interfaces and InputObjectTypes.\nHowever the specific config should live in the corresponding type. AbstractType it's only meant to be used for fields (which is common among all the types that I described before), but other things like interfaces are too specific for living in a \"global\" type.\n. Hi Markus,\nI closed the PR by mistake, I think we should still try to find a way for make it work.\nIf you wanna reopen the PR and discuss further I'm happy with that! :)\n. Thanks for sharing here!\nClosing the issue as people would be able to get into here when searching in google \"graphene token django rest framework\" :)\n. @slorg1 this should be fixed in 1.0.dev, you can install the latest Django version using pip install graphene-django>=1.0.dev.\nPlease reopen this issue if you run into the same error :)\n. That makes sense! I will work on it :)\n. This is now fixed in the master branch in graphene-django.\n. Closed as #264 is merged into next branch.\n. Closed as #265 is merged into next branch.\n. Fixed in 1.0.dev :)\n. Hi @kfuchs, @AT-SyT I've created a gist with an example of how to do it in the newest version of graphene-sqlalchemy (1.0.dev):\nhttps://gist.github.com/syrusakbary/6cdb2597daee9922f330a05a7a08413c\nHope this helps!\n. Hey @samvit, using a List for listing items in a collection is also supported.\nHowever if you plan to use pagination in this collection, using a relay ConnectionField should be the path to go, as it provides builtin structures for handling pagination (pageInfo, cursors, ...), cursor based pagination, and so on.\nYou can still use a List with pagination if you need to, but you would need to implement the pagination for it.\nYou can achieve it with something similar to this:\n``` python\nclass Query(graphene.ObjectType):\n    all_users = List(User, page=graphene.Int())\ndef resolve_all_users(self, args, context, info):\n    page_size = 10\n    offset = args.get('page', 0) * page_size\n\n    # The following will only be available in types inheriting from SQLAlchemyObjectType\n    user_query = User.get_query(context)\n\n    return user_query.offset(offset).limit(page_size)\n\n```\nHope this helps!\n. ## If you mean the React-Relay dependency\nThe Relay dependency in the client it's not necessary even if you're using the Relay spec in your backend.\nSo you can use redux (apollo-client) in your client application with Graphene (and graphene relay).\nWhy is that? Relay is actually two things:\n- A GraphQL server specification\n- A GraphQL client for react\nIn this sense, Graphene only implements the server specification, so you can use the client you want in the frontend (Relay, apollo-client, ...) without imposing any specific client.\nIf you mean using a List instead of Relay Connections in the model relations\nYes, there is a way for skipping the Relay Connections conversion!\nThe SQLAlchemy to graphene types converter checks if the SQLAlchemyObjectType implements the relay.Node type, and in this case it uses a connection whenever a relation to the model defined there is found.\nSo for skipping this automatic Relay Connection creation, just don't implement the relay.Node in the SQLAlchemyObjectType :).\n. @gsvitak Your last example should work replacing the (Folder with FolderModel in the SQLAlchemy query).\n``` python\nclass Folder(SQLAlchemyObjectType):\n    class Meta:\n        model = FolderModel\nclass Query(graphene.ObjectType):\n    folder = graphene.Field(Folder)\n    folders = graphene.List(Folder)\ndef resolve_folder(self, *args, **kwargs):\n    return db.session.query(FolderModel).first()\n\ndef resolve_folders(self, *args, **kwargs):\n    return db.session.query(FolderModel).all()\n\n``\n. I recommend you usinggraphiql` and trying to do there the test queries.\nThere is also some documentation about querying relay connections and nodes that might be useful.\nhttp://graphene-python.org/docs/relay/\nIf you post here the errors you are seeing while doing the frontend I might be able to help! :)\n. Closing the issue as more input is needed but there is no response.\nFeel free to comment and I will happily re-open if there is more data to dig in.\n. The errors are not related to this PR. Everything looks good here \ud83d\udc4d \n. As in the other PR ( #264 ) the errors are not related to this changes.\nThe PR looks good \ud83d\udc4d \n. I closed this PR by mistake. Merging your changes! :)\n. Merged with https://github.com/graphql-python/graphene/commit/061c33f8d611f6a3bd0d69cebbf220f7cda4955f\n. @mwilliamson-healx as Eran pointed, the next version its been rewritten with a special focus on performance.\nWe also added a benchmark for a similar case you are exposing (retrieving about 100k elements instead of 10k).\nhttps://github.com/graphql-python/graphene/blob/next/graphene/types/tests/test_query.py#L129\nThe time spent for retrieving 10k elements should be about 10-20 times faster in the next branch (50-100ms?).\nhttps://travis-ci.org/graphql-python/graphene/jobs/156652274#L373\nWould be great if you could test this case in the next branch and expose if you run into any non-performant case, I will happily work on that :).\n. @mwilliamson-healx some of the performance bottleneck was also in the OrderedDict generation.\nFor that graphql-core uses cyordereddict when available (a implementation of OrderedDict in Cython that runs about 2-6x faster).\nCould you try installing cyordereddict with pip install cyordereddict and running again the tests? (no need to modify anything in the code).\nThanks!\n. PS: There are plans to port some code to Cython (while still preserving the Python implementation) to make graphene/graphql-core  even more performant, however any other suggestion would be always welcome! :)\n. Hi @mwilliamson-healx,\nAt first congrats for your great proof of concept!\nI've been thinking for a while how we can improve performance in GraphQL. This repository -graphene- uses graphql-core under the hood which is a very similar port of the GraphQL-js reference implementation.\nThe problem we are seeing is that either in graphql-core and graphql-js that each type/value is checked in runtime (what I mean is that the resolution+serialization function is \"discovered\" in runtime each time a value is completed). In js the performance difference is not as big as it usually have a great JIT that optimizes each of the type/value completion calls. However as Python doesn't have any JIT by default, this result in a quite expensive operation.\nIn the current graphql-js and graphql-core implementations if you want to execute a GraphQL query this is how the process will look like:\nParse AST from string (==> validate the AST in the given schema) ==> Execute a AST given a Root type.\nHowever we can create a \"Query Builder\" as intermediate step before executing that will know exactly what are the fields we are requesting and therefore it's associated types and resolvers, so we don't need to \"search\" for them each time we are completing the value.\nThis way, the process will be something like:\nParse AST from string (==> validate the AST in the given schema) ==> Build the Query resolver based in the AST ==> Execute the Query resolver builder given a Root type.\nYour proof of concept is doing the latter so the performance difference is considerable comparing with the current graphql-core implementation.\nI think it's completely reasonable to introduce this extra Query resolver build step before executing for avoid the performance bottleneck of doing it in runtime. In fact, I would love to have it in graphql-core.\nAnd I also think this would be super valuable to have it too in the graphql-js implementation as it will improve performance and push forward other language implementations ( @leebyron ).\n. I'm working in the query builder concept. As of right now the benchmarks shows about 4x improvement when returning large datasets.\nRelated PR in graphql-core: https://github.com/graphql-python/graphql-core/pull/74\n. Some updates!\nI've been working non-stop on keep improving the performance with the Query Builder.\nBenchmarks\nRetrieving 10k ObjectTypes\nDoing something similar to the following query where allContainers type is a [ObjectType] and x is a Integer:\ngraphql\n{\n  allContainers {\n    x\n  }\n}\n- With Query Builder: https://travis-ci.org/graphql-python/graphql-core/jobs/158369656#L488\n\n30ms\n- Without Query Builder: https://travis-ci.org/graphql-python/graphql-core/jobs/158369656#L484\n350ms\n\nRetrieving a List with 10k Ints\nDoing something similar to the following query where allInts type is a [Integer]\ngraphql\n{\n  allInts\n}\n- With Query Builder: https://travis-ci.org/graphql-python/graphql-core/jobs/158369656#L483\n\n12ms\n- Without Query Builder: https://travis-ci.org/graphql-python/graphql-core/jobs/158369656#L486\n30ms\n\nNOTE: Just serializing a plain list using GraphQLInt.serialize takes about 8ms, so the gains are better compared substracting this amount from the totals: 4ms vs 22ms\nConclusion\nThe work I'm doing so far is being a demonstration the code performance still have margins to improve while preserving fully compatibility with GraphQL syntax.\nThe proof of concept speedup goes between 5x and 15x while maintaining the syntax and features GraphQL have. Still a lot of work to do there, but it's a first approach that will let us discover new paths for speed improvement.\nExtra\nI think by using Cython for some critical instructions we can gain about another 10-20x in speed.\nTransport\nApart of using Cython I'm thinking how we can plug multiple kind of transports into GraphQL.\nSo instead of creating Python Objects each time we are accessing a field, and then transforming the result to JSON, another approach could be transform the values directly into JSON or whatever transport we are using.\nThis way the result could be created directly in the output format. This way we can plug other transports like binary (CapN Proto/FlatBuffers/Thrift/others), msgpack or any other thing we could think of.\n. Hi @qubitron,\nIf you use the experimental branch features/next-query-builder in graphql-core, you will be able to use a new execution system that improves significantly the speed: https://github.com/graphql-python/graphql-core/pull/74/.\nIt should give you a ~3-5x speed improvement for both big and small datasets.\nHow to use it\n\n\nInstall it with pip install https://github.com/graphql-python/graphql-core/archive/features/next-query-builder.zip\n\n\nEnable the new executor (execute this code before any query)\n```python\nfrom graphql.execution import executor\n\n\nexecutor.use_experimental_executor = True\n```\n\nExecute the query\n\nIf you can try it and output here your results would be great!\nExtra questions\nTo help us optimize for your use case:\n Are you in a CPython environment? (non pypy or google app engine) (to see if we can optimize easily with Cython)\n How many fields are resolved? (what is the \"size\" of the GraphQL output)\n* Did you use any GraphQL middleware?\n. Hi @qubitron, thanks for the info and the profiling data!\nI've fixed few issues in the experimental executor and now is as stable as the master branch.\nFor extra verification, I've executed all the master tests using the experimental executor and all are passing \u263a\ufe0f\nSo yes, as stable as master! :). I'm still working on improving Performance.\nFirst step is quite close to be ready, is a new (and ultra-performant) promise implementation.\nI'm going to drop here some numbers, so is easier to see the advantages by using just the faster implementation of promise:\nNon-optimized GraphQL resolution\nOld promise\n------------------------------------------------------------------------------------------ benchmark: 5 tests -----------------------------------------------------------------------------------------\nName (time in ms)                                      Min                 Max                Mean             StdDev              Median                IQR            Outliers(*)  Rounds  Iterations\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_big_list_of_ints_serialize                     2.4519 (1.0)        4.8950 (1.0)        2.8593 (1.0)       0.4961 (1.0)        2.6586 (1.0)       0.4846 (1.0)            48;21     380           1\ntest_big_list_of_ints                              61.0509 (24.90)     73.8399 (15.08)     66.3891 (23.22)     3.7764 (7.61)      66.2786 (24.93)     6.3930 (13.19)            6;0      16           1\ntest_big_list_objecttypes_with_one_int_field      231.4451 (94.39)    274.0550 (55.99)    253.6332 (88.70)    17.2165 (34.70)    257.7021 (96.93)    27.6580 (57.08)            2;0       5           1\ntest_big_list_objecttypes_with_two_int_fields     373.6482 (152.39)   407.3970 (83.23)    391.4426 (136.90)   14.5990 (29.43)    391.9201 (147.42)   26.1913 (54.05)            2;0       5           1\ntest_fragment_resolver_abstract                   233.4590 (95.22)    283.4949 (57.92)    259.2367 (90.66)    21.3765 (43.09)    263.5479 (99.13)    37.4374 (77.26)            2;0       5           1\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nNew promise implementation https://github.com/syrusakbary/promise/pull/23\n------------------------------------------------------------------------------------------ benchmark: 5 tests -----------------------------------------------------------------------------------------\nName (time in ms)                                      Min                 Max                Mean             StdDev              Median                IQR            Outliers(*)  Rounds  Iterations\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_big_list_of_ints_serialize                     2.4672 (1.0)        7.0231 (1.0)        2.9814 (1.0)       0.5989 (1.0)        2.7701 (1.0)       0.4563 (1.0)            40;31     378           1\ntest_big_list_of_ints                              23.3240 (9.45)      31.2262 (4.45)      26.8308 (9.00)      1.9695 (3.29)      26.7700 (9.66)      3.2494 (7.12)            14;0      36           1\ntest_big_list_objecttypes_with_one_int_field      165.3101 (67.00)    201.4430 (28.68)    181.6540 (60.93)    15.7699 (26.33)    181.4460 (65.50)    29.1352 (63.85)            3;0       6           1\ntest_big_list_objecttypes_with_two_int_fields     248.4190 (100.69)   291.1139 (41.45)    267.6542 (89.77)    17.9228 (29.93)    259.4721 (93.67)    28.7293 (62.96)            2;0       5           1\ntest_fragment_resolver_abstract                   112.4361 (45.57)    160.6219 (22.87)    139.5578 (46.81)    20.4794 (34.19)    149.4532 (53.95)    35.4158 (77.61)            2;0       7           1\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nOptimized GraphQL resolution https://github.com/graphql-python/graphql-core/pull/74\nOld Promise\n------------------------------------------------------------------------------------------ benchmark: 5 tests -----------------------------------------------------------------------------------------\nName (time in ms)                                      Min                 Max                Mean             StdDev              Median                IQR            Outliers(*)  Rounds  Iterations\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_big_list_of_ints_serialize                     2.4519 (1.0)        5.0600 (1.0)        2.8100 (1.0)       0.4778 (1.0)        2.6290 (1.0)       0.3346 (1.0)            40;35     361           1\ntest_big_list_of_ints                              48.6422 (19.84)     61.3708 (12.13)     55.8666 (19.88)     2.9545 (6.18)      55.4373 (21.09)     2.9249 (8.74)             6;1      20           1\ntest_big_list_objecttypes_with_one_int_field      148.5479 (60.58)    192.1201 (37.97)    164.5386 (58.55)    18.2469 (38.19)    153.1000 (58.23)    30.8557 (92.23)            2;0       7           1\ntest_big_list_objecttypes_with_two_int_fields     214.3099 (87.41)    252.1060 (49.82)    237.2049 (84.41)    16.0745 (33.64)    241.0800 (91.70)    26.6772 (79.74)            1;0       5           1\ntest_fragment_resolver_abstract                   263.5369 (107.48)   294.0340 (58.11)    275.1848 (97.93)    13.9760 (29.25)    268.7261 (102.21)   24.3396 (72.75)            1;0       5           1\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nNew Promise implementation\n------------------------------------------------------------------------------------------ benchmark: 5 tests -----------------------------------------------------------------------------------------\nName (time in ms)                                      Min                 Max                Mean             StdDev              Median                IQR            Outliers(*)  Rounds  Iterations\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_big_list_of_ints_serialize                     2.4509 (1.0)        4.5359 (1.0)        2.9296 (1.0)       0.4356 (1.0)        2.7819 (1.0)       0.4752 (1.0)            54;25     351           1\ntest_big_list_of_ints                              14.3750 (5.87)      20.3481 (4.49)      16.1198 (5.50)      1.0453 (2.40)      15.9812 (5.74)      0.8274 (1.74)            15;6      65           1\ntest_big_list_objecttypes_with_one_int_field       73.8251 (30.12)    115.9289 (25.56)     92.0637 (31.43)    15.2907 (35.10)     82.6714 (29.72)    27.2505 (57.35)            4;0      12           1\ntest_big_list_objecttypes_with_two_int_fields      98.5930 (40.23)    149.9560 (33.06)    123.6130 (42.19)    19.3822 (44.50)    128.8331 (46.31)    35.7828 (75.31)            4;0       9           1\ntest_fragment_resolver_abstract                   115.6740 (47.20)    156.7039 (34.55)    138.5075 (47.28)    16.4670 (37.80)    146.8499 (52.79)    28.6682 (60.33)            3;0       7           1\n-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n. When used with PyPy the difference is even bigger, and this is just the beginning.\nAlso, when having multiple fields in a same ObjectType, the improvement is also quite significant.\nAfter finishing this promise implementation, I will work on separate the serializer that I assume will give another ~2x gains if using a simple dict instead of OrderedDict for serialization, and maybe even higher if serialized directly to JSON. This will also open the possibility of using other serializers like msgpack :)\nAnd after that, optimizations with Cython will help to crush all benchmarks! \ud83d\ude0a\nAnd all this, while preserving 100% compatibility with the GraphQL spec and the current GraphQL Graphene implementation, with no changes required for the developer, other than updating the package once the new version is published.. PS: Meanwhile I'm also working on a dataloader implementation for Python that will solve the N+1 problem in GraphQL. I've been able to improve a little bit more the type resolution, giving an extra ~35% in speed gains: https://github.com/graphql-python/graphql-core/pull/74/commits/81bcf8c639e2a09c01f34e724bdc3903412e1a64.\nNew benchmarks (new promise and better type resolution with experimental executor)\n--------------------------------------------------------------------------------------- benchmark: 5 tests ---------------------------------------------------------------------------------------\nName (time in ms)                                     Min                 Max               Mean            StdDev             Median               IQR            Outliers(*)  Rounds  Iterations\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\ntest_big_list_of_ints_serialize                    2.6469 (1.0)        5.0581 (1.0)       2.9428 (1.0)      0.4469 (1.0)       2.7812 (1.0)      0.2511 (1.0)            47;53     401           1\ntest_big_list_of_ints                             13.6490 (5.16)      21.1191 (4.18)     15.1494 (5.15)     1.7030 (3.81)     14.3925 (5.18)     1.9491 (7.76)            12;2      62           1\ntest_big_list_objecttypes_with_one_int_field      60.2801 (22.77)     90.2431 (17.84)    67.1742 (22.83)    9.6505 (21.60)    63.0350 (22.67)    5.5089 (21.94)            2;2      15           1\ntest_big_list_objecttypes_with_two_int_fields     82.4349 (31.14)    110.2500 (21.80)    90.0414 (30.60)    7.7319 (17.30)    88.1380 (31.69)    9.3712 (37.32)            1;1      12           1\ntest_fragment_resolver_abstract                   92.1650 (34.82)    107.6009 (21.27)    98.8749 (33.60)    4.5259 (10.13)    97.8079 (35.17)    4.3540 (17.34)            2;0       8           1\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------. (all this benchmarks are without PyPy, just plain Python with the common CPython executor). The latest next-query-builder branch now includes the ultra-performant version of promise.\nJust by running pip install pip install https://github.com/graphql-python/graphql-core/archive/features/next-query-builder.zip it should upgrade promise to  promise>=2.0.dev.\n(you will also need to do: executor.use_experimental_executor = True)\n@qubitron Willing to know the extra performance improvements!. No idea why there is not a performance improvement for your case.\nIt might be possible that the last version packages are not installed properly?\nHere are the new promise 2.0+query-builder requirements:\n```bash\nInstalling Next query builder\npip install https://github.com/graphql-python/graphql-core/archive/features/next-query-builder.zip\nInstalling promise 2.0\npip install \"promise>=2.0.dev\"\n```\nHere are the previous requirements:\n```bash\nInstalling Next query builder (working with old promise)\npip install https://github.com/graphql-python/graphql-core/archive/features/next-query-builder-prev.zip\nInstalling promise 1.x\npip install \"promise==1.0.1\"\n```\nFor verifying that the versions installed corresponds with the ones listed, you can do:\nbash\npip freeze | grep \"graphql\"\npip freeze | grep \"promise\". Hi @jameswyse,\nThe experimental executor is specially suited when returning big lists of scalars or ObjectTypes with few fields. However, it should beat the normal executor in almost all benchmarks.\nCould be possible to have a repo that let me reproduce it so I can analyze better? :). Hi all!\nI'm working in Quiver, the next generation GraphQL engine.\nThis engine works in a similar way as a high-performance template engine.\nThe queries will be compiled directly to python functions, so this way remove the overhead of the GraphQL framework, and the queries will be as performant as calling all the resolution functions by hand. With it we can se a 5-10x improvement over the default GraphQL engine.\nRight now is closed-source and specifically directed to medium-large size companies.\nSo if please, you have any needs to speed up GraphQL an order of magnitude contact me.\nhttp://graphql-quiver.com. Hi everyone,\nQuiver is now ready to being used by the public!\nI released a new article analyzing how it works:\nhttps://medium.com/@syrusakbary/quiver-graphql-on-steroids-13612ea1ea77\nYou can register here:\nhttps://graphql-quiver.com/signup/\nPlease let me know if you would like to start using it or have any question :). With the current execution model is almost impossible to achieve more speedup.\nPS: I just tested your code using Quiver, and the performance Gains are considerable (10x)\nWithout Quiver\n```\n============== Profiler start ==============\n Fetch using ObjectType ...\nExecution time 3.200170 seconds\n\n============== Profiler start ==============\n Fetch using Scalar ...\nExecution time 0.540605 seconds\n\n```\nWith Quiver\nAbout 10x speedup.\n```\n============== Profiler start ==============\n Fetch using ObjectType ...\nExecution time 0.333384 seconds\n\n============== Profiler start ==============\n Fetch using Scalar ...\nExecution time 0.048430 seconds\n\n```\nHere is the code I used for testing:\n```python\nimport graphene\nimport cProfile\nfrom io import StringIO\nimport pstats\nfrom contextlib import contextmanager\nfrom graphql import GraphQLDeciderBackend, GraphQLCachedBackend, GraphQLCoreBackend\nfrom graphql.backend.quiver_cloud import GraphQLQuiverCloudBackend\n@contextmanager\ndef profile(show_calls=None, message=None):\n    print(\"\\n============== Profiler start ==============\")\n    if message:\n        print(\" \" + message + \" ... \")\npr = cProfile.Profile()\npr.enable()\nyield\npr.disable()\ns = StringIO()\nsortby = \"cumulative\"\nps = pstats.Stats(pr, stream=s).sort_stats(sortby)\nif show_calls:\n    ps.print_stats()\n    print(s.getvalue())\nelse:\n    print(\"Execution time %f seconds\" % ps.total_tt)\nprint(\"--------------------------------------------\")\n\nclass UserQuery(graphene.ObjectType):\n    id = graphene.Int()\nclass UserAbstract(graphene.Scalar):\n    @staticmethod\n    def serialize(dt):\n        return dt\nclass Query(graphene.ObjectType):\n    users = graphene.Field(graphene.List(UserQuery))\n    users_abstract = graphene.Field(graphene.List(UserAbstract))\ndef resolve_users(self, context):\n    return users\n\ndef resolve_users_abstract(self, context):\n    return resolved_users\n\nclass User(object):\n    def init(self, id):\n        self.id = id\nFor using Quiver\nQUIVER_DSN = \"https://YOUR_DSN@api.graphql-quiver.com/\"  # You get this DSN when registering in GraphQL-quiver.com website and creating a Project, no cost for trying it\nbackend = GraphQLQuiverCloudBackend(QUIVER_DSN, {\"asyncFramework\": None})\nFor use the normal backend\nbackend = GraphQLCoreBackend()\nnof_users = 100000\nusers = [User(index) for index in range(nof_users)]\nresolved_users = [user.dict for user in users]\nschema = graphene.Schema(query=Query)\ndocument1 = backend.document_from_string(schema, \"{users{id}}\")\ndocument2 = backend.document_from_string(schema, \"{usersAbstract}\")\nwith profile(message=\"Fetch using ObjectType\", show_calls=False):\n    response = document1.execute()\n    assert len(response.data[\"users\"]) == nof_users\nwith profile(message=\"Fetch using Scalar\", show_calls=False):\n    response = document2.execute()\n    assert len(response.data[\"usersAbstract\"]) == nof_users\n```. Hi @wxkin,\nI'm sorry to hear that. Graphene is just a helper on top of graphql-core, which improves significantly readability and ease of use of GraphQL within Python.\nI've spent a lot of time on the overhead side and I can assure (regarding performance), that Graphene and GraphQL-core are equally performant (and will always be), since after Schema creation Graphene doesn't interact with the mix (ergo, no overhead on the execution side).\nNote: In the first versions of Graphene (0.x), Graphene was wrapping the root values with Graphene instances, and that affected performance in a significant way. But we worked to solve it and managed to remove any all the overhead introduced by Graphene at execution time.. @dan98765 I think all this ideas are great. Will reply inline:\nSome optimisation ideas off the top of my head:\n\nGraphene, Graphene-Django, GraphQL-Core, Promises, etc, all make very heavy use of functions and lambdas - these aren't particularly fast in Python when you get into the realm of detailed performance optimisation, I wonder if there's some parts that could be refactored to remove some of the function calls.\n\nPerhaps some cases can be improved. Not sure how % we can save from it (maybe ~2-5% max?)\n\nThese libraries also make heavy use of isinstance, callable, issubclass, etc, to support a range of input types at various points. While this results in a nice API, and these functions aren't slow, the number of times they are being called is very significant (these 3 functions are called roughly 4.4 million times in our query above, taking ~1.3 seconds).\n\nI would very happy if we can lower the times this functions are called :)\n\nIs there a possibility for users of these libraries to return the JSON result for portions of the return data, if they are able to generate this easily? This would allow users to drop down to lower level code and manually construct responses in order to optimise if necessary.\n\nYou mean returning JSON without going through the GraphQL engine?\n\nCould these libraries optimise the code path for when Promises aren't being used? Anecdotally, we use Promises in ~1-2% of resolvers, and while they are really useful in these cases, it's a large penalty on other code paths - in this case roughly a 30% speed reduction.\nThat's true. Promises (or async code in general) introduce a significant overhead.\n\nEven if only one field in a subtree (for example the distance field in: getUser->photos->location->distance) is a Promise, all parent \"roots\" will be wrapped in a promise for it's resolution.\nThat means that:\n distance is a promise (as is the result of executing the resolver)\n location will be a promise (since depends on the distance promise field)\n photos will be a promise (returning an array, since one or more of it's photos is a promise)\n getUser will be a promise\nThis is something that can't be changed in the current GraphQL model, given the spec.\nQuiver tries to stop the Promise chain, by only using it when strictly necessary, but there are few very specific scenarios where the behavior for NonNull exceptions changes slightly from the spec.\nIn the case of using just asyncio (without promises, with graphql-core-next), the same thing happens. So it's not really a matter of the library, but how the GraphQL executor is implemented.. Hey @felipellrocha, this is fixed in the newest version of graphene: 1.0.dev.\nI added a test case so we can make sure that this will work also in future releases: https://github.com/graphql-python/graphene/blob/master/graphene-sqlalchemy/graphene_sqlalchemy/tests/test_query.py#L244-L330\nYou can try the latest dev version with pip install graphene_sqlalchemy>=1.0.dev.\nHope this helps!\n. @mickeyinfoshan it seems you have the latest version of graphql-core (which removed get_fields in favor of fields) and using a graphene version lower than 1.0.dev.\n. What you commented might be the cause.\nIn the 1.0.dev version this is not longer an issue as the Django integration is moved into a external package graphene-django.\nYou can install it by doing pip install graphene-django>=1.0.dev.\nIf you do, would be helpful to read the Upgrade Guide.\nPlease reopen this issue if the problem persists.\n. Now you should be able to install it using pip install graphene-django==1.0.dev.\n. Hi @markflorisson, could be possible to have a working example of the issue?\n. Oh ok, thanks for the example.\nWhat is failing is Input requires a InputField instead of a Field.\nYou can also do this:\n``` python\nclass DoSomething(graphene.Mutation):\n    class Input:\n        myEnum = MyEnum() # This will act as InputField automatically\nmessage = graphene.String()\n\n@classmethod\ndef mutate(cls, instance, args, info):\n    return DoSomething(message=\"Success!\")\n\n```\nHope this helps! Closing the issue, but feel free to comment and I will follow :)\n. Fixed! :)\n. Updated the PyPI package. Should be good to go now :)\n. Thanks for the detailed examples, I think that's a bug in the filter argument conversion. I will take a look! :)\n. Thanks for your example, it helped a lot for making the fix faster! :)\nJust uploaded a new version of graphene_django to PyPI with the fix\n. This is fixed in graphene-django :)\nClosing issue!\n. Hey @benjaminjkraft,\nEven if a resolver is defined as a classmethod, it needs to receive a root (parent) element.\nSo the classmethod resolvers would look something like:\npython\nclass MyObjectType(graphene.ObjectType):\n    name = graphene.String()\n    @classname\n    def resolve_name(cls, root, args, context, info):\n        return 'My Name'\nI know it sounds a little bit counter intuitive but all resolvers needs to receive the parent element they are working with.\nHope this helps!\n. I improved the documentation regarding resolvers, so it's easier to know what's going on.\nhttp://docs.graphene-python.org/en/latest/types/objecttypes/#resolvers\nClosing issue!\n. I think that's a great idea!\n. Hi @prokofiev!\nYou can actually use the default_value in the Argument and set another default than None.\nSo currently you can do:\n``` python\nclass Undefined(object): pass\nclass Query(graphene.ObjectType):\n    field = graphene.String(\n        input=graphene.String(default_value=Undefined)\n    )\n```\nIt might be interesting to set Undefined as default_value in a GraphQLArgument in graphql-core instead of None, but probably this is something that we should investigate a little bit further :)\n. Hey @prokofiev, after thinking about this I realized this could be approached in a easier way. As input is a dict, you could check if  not_null in exists in input.\nSomething like\npython\n@classmethod\ndef mutate_and_get_payload(cls, input, context, info):\n    not_null = 'UNDEFINED'\n    if 'not_null' in input:\n        # ....\n        not_null = input['not_null']\n   # ....\nDoes that make sense?\n. After checking, I realized that this query:\ngraphql\nmutation UpdateFoo{\n    saveFoo (input:{\n        clientMutationId:\"1\"\n        id:\"id\"\n        nullable: null\n    }) {\n      ...\n    }\n}\nIs actually not valid as null is not a valid value in GraphQL.\nhttps://github.com/graphql-python/graphql-core/blob/master/graphql/language/tests/test_parser.py#L80-L84\nFor this reason I guess that some client's check when the value is null and then skip it (Relay?).\nAs an extra exercise, I checked that arguments and input fields that are not provided don't fill the dictionary with None values:\n``` python\ndef test_does_not_include_arguments_that_were_not_set():\n    InputObject = GraphQLInputObjectType(\n        name='InputObject',\n        fields={\n            'value': GraphQLInputObjectField(GraphQLString, default_value=None),\n            'other': GraphQLInputObjectField(GraphQLString, default_value=None)\n        }\n    )\n    def resolver(data, args, *_):\n        print args\n        return 'other' in args['c']\nschema = GraphQLSchema(GraphQLObjectType(\n    'Type',\n    {\n        'field': GraphQLField(\n            GraphQLInt,\n            resolver=resolver,\n            args={\n                'a': GraphQLArgument(GraphQLBoolean),\n                'b': GraphQLArgument(GraphQLBoolean),\n                'c': GraphQLArgument(InputObject),\n                'd': GraphQLArgument(GraphQLInt),\n                'e': GraphQLArgument(GraphQLInt),\n            }\n        )\n    }\n))\n\nast = parse('{ field(c: {value: \"3\"}) }')\nresult = execute(schema, ast)\nassert result.data == {\n    'field': False\n}\n\n```\nIf you can provide more insights that I might be missing please let me know.\n. I think the clientMutationId fix is good to go!\nHowever I'm not sure if I see the use case of decorating the GlobalID. Instead of returning node_id maybe is better to return node (a field referencing the Node interface) and get node { id }. Thoughts?\n. I think it could be useful to add default_value back into Field, however I think it only should be applied when using the default resolver, as if not it could have side-effects if the custom resolver function returns None.\nFor that, we can do two things:\n- Add defaut_value into Field, and modifying the Typemap default resolver to use the default value if the attr is not found in root. Similar to getattr(root, attname, default_value)\n- Create a resolver decorator that mimics the logic that you did.\nIf the latter is the best approach to make, maybe keeping the decorator in your app scope is a good case until more people have the same issue.\nLet me know your thoughts!\n. Thanks for the work on this PRs, Markus!\n. Hey @BossGrand,\nThanks for pointing this. As of right now ObjectTypes don't work when are inherited.\nIf you want to extend a Type, you should be able to use AbstractTypes for it.\nLike:\n``` python\nclass MasterDatabaseQuery(graphene.AbstractType):\n    my_query_field_1 = graphene.String()\nclass Query(MasterDatabaseQuery, graphene.ObjectType):\n    pass\n```\nHope this helps!\nClosing the issue, but feel free to open a PR in the Upgrading guide with a extra comment for this case! (I will try to fix it anyway, but any help is always welcome!).\n. Hi Charles,\nI'm absolutely open for having an integration between Peewee and Graphene, I think it will be super valuable for the developers!\nStarting with the next version 1.0, Graphene integrations will be separated from the main codebase into external repos within the graphql-python community. (This is already happening for the Graphene Google App Engine integration)\nEach of the repos will be maintained by different people that are specialized in the framework that are integrating with (I can't think of someone better than you for the graphene-peewee integration! \ud83d\ude09 )\nWe can follow the same process we did for graphene-gae: You can start a graphene-peewee repo in your profile and once is mature (tested and with a working example) we can move it into the graphql-python community :)\nOr we can start directly creating a graphene-peewee repo in the graphql-python community and you will be the admin of this repo.\nJust let me know what you prefer! :)\n. Great! :)\nPS: I just added you the perms for maintain the graphene-peewee package in PyPI (if you want to use it!)\n. Hi @glusa8, I believe this is fixed in the development version.\nCould you try using the latest version? (pip install \"graphene-django>=1.0.dev\")\nHere is the upgrade guide\n. (please reopen the issue if the CharField with choices keeps happening in the latest version!)\n. removed my comment as I pointed in the bad direction and could mislead other people having this problem.\nClosing the issue :)\n. Hi @benblippar, you should use graphene.List(graphene.Int) instead of graphene.List(graphene.Int()).\ngraphene.Int() is a shortcut for graphene.Field(graphene.Int).\nClosing the issue, but feel free to do any comment!\n. Looking at it now! :)\n. Just merged the code propose change in: https://github.com/graphql-python/graphene/pull/266\nThis should solve the issue! (I tried the graphene-tutorial and the fragment error is no longer happening :) )\nPushing the graphene dev version to PyPI\n. Looks good! \ud83d\udc4d\n. Good catch! \ud83d\udc4d \n. Hey Markus,\nI amended the merge commit changing from gql_type to type.\nThe reason for that is trying to preserve compatibility as I'm aware of some cases where developers where using Field(type=XXX, ...).\nNow should be fixed on master. Thanks for the PR though!\n. Thanks for the report, I just fixed it on master :)\n. Hi @adamhadani, the newest version of graphene (1.0.dev, that is on master) take now always the context argument.\nProbably you are using graphene 0.x, (you can check the README in the 0.x branch, it should be similar to the one you pointed)\n. Yeah! This is actually fixed in the latest development version of graphene-django \ud83d\ude09 \n. Hey Markus,\nThanks for opening the PR and this issue and sorry for replying so late.\nI agree that the Connections implementation have a lot of things to improve, and actually I like most of the ideas that you have in the PR.\nHowever before moving forward with it I think is worth to analyze how connections should work, trying to solve questions like:\n- Where the connection resolution should live? Should we start transferring some resolver logic to the Connection type?\n- How we should handle the \"automatic\" connection types creation? We should handle it at all? (as is right now)\n- How we can handle different connections for same types? And then, how we handle name clashing?\nSome of this questions are easy to solve if we are more explicit (as your PR points), but before choosing a definitive approach would be good to explore if there is any way that we could achieve simplicity and extensibility at the same time (as we did for Nodes).\nIn general I think is worth to spend some time analyzing, discussing and getting a stable API for connections than releasing something that we might have to change after.\nPlease raise any ideas you have! (and thanks for your great work too!)\nPS: Meanwhile I'm going to add support to the test you pointed to unblock your transition to 1.0 :)\n. I just added support to return a Connection instance in the connection resolver.\nhttps://github.com/graphql-python/graphene/commit/c7929234294a181993158b4439c24006e9ed1ebd\n. No worries!\n. Eran example should now work.\nI added also a testcase to ensure resolvers can return connection instances: c7929234294a181993158b4439c24006e9ed1ebd\n. Hi @Momotv45, I guess you forked graphene some time ago as now the core has been rebuilt and the Django integration is living in its own repo: https://github.com/graphql-python/graphene-django/\nI'm closing here the PR but feel free to open it in graphene-django.\nThanks anyway for your work!\n. Hi @jnak @morgante,\nGraphene is completely ready to handle concurrency/parallelization. Under the hood is using graphql-core which few months ago was improved to be capable to use Promise abstraction in Python.\nHere's the related PR: https://github.com/graphql-python/graphql-core/pull/59\nThanks to using Promises we would be able to abstract the way functions are executed and finished independently of the execution engine/event loop.\nThe most important thing is the application logic and Graphene types and resolvers should remain the same independently of the executor used.\nAvailable executors\nBy default, graphql will use a SyncExecutor. However, there are more executors available:\n- graphql.execution.executors.asyncio.AsyncioExecutor: This executor executes the resolvers in the Python asyncio event loop.\n- graphql.execution.executors.gevent.GeventExecutor: This executor executes the resolvers in the Gevent event loop.\n- graphql.execution.executors.process.ProcessExecutor: This executor executes each resolver as a process.\n- graphql.execution.executors.thread.ThreadExecutor: This executor executes each resolver in a Thread.\n- graphql.execution.executors.sync.SyncExecutor: This executor executes each resolver synchronusly (default).\nHow you can use it with Graphene?\n``` python\nfrom graphql.execution.executors.thread import ThreadExecutor\nschema = graphene.Schema(query=...)\nschema.execute(query, executor=ThreadExecutor())\n```\nPython 3.5\nIf you are using Python 3.5 Graphene should be able to resolve your async/await functions in the asyncio event loop too with no logic changes in your app ;)\nHere are some tests demonstrating this in graphql-core.\nPS: Sorry this is not documented yet in the website.\n. Hi @JimVanEeden @jameswyse, in v1.0 you can use lambdas in a Field.\nA simple example:\npython\nclass Viewer(graphene.ObjectType):\n    viewer = graphene.Field(lambda: Viewer)\n. @jameswyse graphene is not using callable there because self._type could be a class reference. (in this case, callable will be True and field.type would return a type instance instead of the class type).\n. Thanks for contributing and sorry about taking so long for merging!. This issue is now fixed. Closing :)\n. Great work there! I will take a closer look the next days and try to give you some feedback! :)\n. Hi Marcus,\nI think this PR is very tied to the application logic instead of the framework... I'm not sure how this could be useful to other developers.\nMaybe the best solution could be subclassing Field and use your custom classes with the extra attrs you need.\n. @yfilali comment should address the issue.\nI will close it, but feel free to re-open it if you still have problems with it :)\n. I think this was because foo is an instance of SimpleLazyObject and not a model.\nThis issue was reported in https://github.com/graphql-python/graphene-django/issues/22 and is now fixed!\nPS: Graphene-django issues are better reported in https://github.com/graphql-python/graphene-django/ :)\n. Hi @richburdon!\nThe argument that you should use is variable_values.\nSomething like the following should work:\npython\nschema.execute(query, variable_values={\"userId_0\": \"123\"})\nPS: The name is variable_values instead of variables for being more similar to the GraphQL JS API.\n. Hi Marcus,\nIs there any reason on why subclassing Scalar and replacing there the get_type function as bounded method is not a good solution?\n``` python\nclass MyCustomString(Scalar):\n    def init(self, *args, kwargs):\n        super(MyCustomString, self).init(*args, kwargs)\n        self._meta = {'my_meta': True}\ndef get_type(self):\n    return graphene.String\n\n```\n. After reviewing, I'm not super sure that adding scalar instances to the typemap conversion is a good idea.\nIf we do it, things like the following could be possible:\npython\nclass MyObjectType(graphene.ObjectType):\n    my_string = graphene.Field(graphene.String())\n    mg_string = graphene.Field(graphene.String) # This is the only way that works now\n(Note that the PR will introduce two ways for doing the same thing).\nI'm favorable of changing the Scalar implementation to something like the following, though:\n``` python\nclass Scalar(six.with_metaclass(ScalarTypeMeta, UnmountedType)):\n    '''\n    Scalar Type Definition\nThe leaf values of any request and input values to arguments are\nScalars (or Enums) and are defined with a name and a series of functions\nused to parse input from ast or variables and to ensure validity.\n'''\n\nserialize = None\nparse_value = None\nparse_literal = None\n\ndef get_type(self):\n    '''\n    This function is called when the unmounted type (Scalar instance)\n    is mounted (as a Field, InputField or Argument)\n    '''\n    return type(self)\n\n```\nWould that work?\n. Closing this PR in favor of #392 :). As Eran pointed, all mutations are enforced to be top level.\nRelated spec improvement in the GraphQL spec: https://github.com/facebook/graphql/issues/252. Just fixed this by adding a redirection meta in the old doc pages.\nHere is the commit: https://github.com/graphql-python/graphene-python.org/commit/df0c0e572996768aefae612dfb7deccbb9d0748d\n(Google should also update this page urls soon in their engine once they crawl the new contents)\nNow when someone access: http://graphene-python.org/docs/relay/ it will be redirected to: http://docs.graphene-python.org/en/latest/relay/\n@ecamaj Just checked that middleware is not ported to the new docs, I will work on it! :)\n. This should be fixed in master with #342 (thanks to @ekampf work).\n. Thanks Eran!\n. This is fixed in graphene-django with this commit: https://github.com/graphql-python/graphene-django/commit/d1f28633744d61aa955dc862c5cd2c29d678695c\nThe docs had an issue while doing the build so they haven't been automatically updated with each git commit, but I'm working on fixing that there.\nRefer to the graphene-python.org issue if you want to keep track of this.\nClosing issue :)\n. Thanks for keeping track of the issue @yfilali.\nClosing the issue as it seems resolved.\n. In Relay Mutations the input fields you have in the NewCatalogItem.Input are inside the input argument in the mutation.\nIt seems the issue is in the way the mutation is executed in the client side.\nSo, for your example to work, you would need to execute the following mutation:\ngraphql\nmutation Catalog {\n  newCatalogItem(input: {id: \"\", store: \"\"}, clientMutationId:\"123\") { # and all the other fields\n    catalogItem {\n      id\n    }\n  }\n}\nYou can find a more detailed example here: https://facebook.github.io/relay/docs/graphql-mutations.html\nThe tests for graphene Relay mutations might help too: https://github.com/graphql-python/graphene/blob/master/graphene/relay/tests/test_mutation.py#L130\nLet me know if that helps! :)\n. Great! Seems you were able to solve the issue.\nClosing this then, but feel free to reopen if you have any other question!. Closing in favor of #500 . @ekampf you can do something like the following (extracted from a PR that optimizes queries in graphene-django).\n``` python\ndef get_type(_type):\n    if isinstance(_type, (GraphQLList, GraphQLNonNull)):\n        return get_type(_type.of_type)\n    return _type\ndef get_fields(info):\n    field_asts = info.field_asts[0].selection_set.selections\n    _type = get_type(info.return_type)\nfor field_ast in field_asts:\n    field_name = field_ast.name.value\n    yield field_name\n    # You can also do:\n    # field_def = get_field_def(info.schema, _type, field_ast)\n    # yield field_def.resolver # This will get the field resolver\n\n```\n. @ekampf the solution provided by @yfilali or myself should work for knowing the requested fields.\nFeel free to reopen the issue if not! :)\n. For sure!!\nThe Django integration already have batching support on master thanks to this PR: https://github.com/graphql-python/graphene-django/pull/38\n(a new version will be uploaded to PyPI soon)\n. Makes sense!\nMerging :)\n. The solution provided by @ekampf should work. Closing issue. This should be fixed in master (as the PR is merged). Closing :)\n. Tests covering what this PR improves would be great, so this things are not missed in future refactors! :)\n. Hi @jamesboehmer,\nI think things like a OmniScalar could be useful for other developers, but I think is better if is as an independent package as solves a very specific use case and could mislead the developers on which one they should use -String or OmniScalar- as both would work for \"String\" fields.\n. @ekampf example should work, I also improved the messaging in graphene so it's easier to fix from a developer view.\n. Closing this PR in favor of #392 :). Hi @tangerilli,\nThe way Connections work will be changed by #347 (removing the need of an ObjectType for have a Connection on it).\nYou can still make Connection work with Union, doing something like:\n``` python\nclass MyUnion(Union):\n    class Meta:\n        types = (MyObjectType1, MyObjectType2)\nclass MyUnionConnection(Connection):\n    class Meta:\n        node = MyUnion\nclass Query(ObjectType):\n    objects = ConnectionField(MyUnionConnection)\ndef resolve_objects(self, args, context, info):\n    return [MyObjectType1(), MyObjectType2()]\n\n``\n. This issue is fixed with the latest version ofgraphene-django:1.2.0`.\nhttps://github.com/graphql-python/graphene-django/releases/tag/v1.2.0\nClosing issue.. The PR looks good!\nAdding tests for ensuring that everything works as expected is a good idea before merging :). Great!. Hey @jwfehr,\nThere was an issue in graphql-core that was causing a lot of unwanted prints: https://github.com/graphql-python/graphql-core/issues/94 .\nI believe this is fixed with the latest version of graphene and graphql-core\nshell\npip install graphene>=1.1.2\npip install graphql-core>=1.0.1\nLet me know if that works for you!. Could be possible to have a working example describing this issue?. @fbyossi using graphene.Dynamic is a valid solution however I recommend using this simpler version.\npython\nfriends = graphene.List(lambda: UserType)\nPS: Dynamic is the recommended approach when the field is resolved \"lazily\" depending on the schema. For example, having or not certain field in a ObjectType (rather than deciding the type lazily).. For using unions as connections, you need to create a ConnectionType for the union.\nThe following should work:\n```python\nclass Cat(graphene.ObjectType):\n    class Meta:\n        interfaces = (relay.Node,)\n    name = graphene.String()\nclass Dog(graphene.ObjectType):\n    class Meta:\n        interfaces = (relay.Node,)\n    name = graphene.String()\nclass Animal(Union):\n    class Meta:\n        types = (Cat, Dog)\nclass AnimalConnection(graphene.Connection):\n    class Meta:\n        node = Animal\nclass Query(graphene.ObjectType):\n    animals = graphene.ConnectionField(AnimalConnection)\n```\n(related issue #356). Hi @tsunammis,\nAt first thank you for contributing!\nAs you commented this were the issues:\n is_thenable returned False for coroutines, even if the promisify method was able to handle it correctly.\n Relay Connections were not accepting Promise-like objects / coroutines.\nI fixed each separately in their corresponding packages:\n Fixed is_thenable for accepting coroutines (inside the promise package): https://github.com/syrusakbary/promise/commit/8b0d5da3dca2d99671b820478ef74353ac24c97b\n Relay connections now promisify if the object is thenable https://github.com/graphql-python/graphene/commit/3df62d26a7962f1273df972da21b25ac75bc9cf3\nI've released a new version of promise: 1.0.1 and graphene: 1.1.3 that have this changes.\nPlease let me know if everything works as expected with the new versions! :). Great! Closing the PR :). Hey @janhancic,\nYour code should work with the latest version of Graphene (it seems you're using 0.10.X).\nPlease reopen the issue if not :). Tests reflecting this improvement would help to not repeat the issue in the future! :). As the implementation is completely abstract from the json serialization/unserialization I renamed the JSON type to GenericScalar.\nYou can use it by:\n```python\nfrom random import random\nimport graphene\nfrom graphene.types.generic import GenericScalar\nclass Query(graphene.ObjectType):\n    generic = GenericScalar()\ndef resolve_generic(self, args, context, info):\n    if random() > 0.5:\n        return 5.0 # We return a float\n    return False # We return a boolean\n\n```\nHope this helps!. I'm going to merge it, but renaming from JSON to Generic as it's definition is abstract of json (json is just the most common \"serializer\"/\"unserializer\" for GraphQL now, but maybe there will be more in the future! \ud83d\ude09 ). It seems you have multiple node.__name__ + 'Connection' types in your schema. (same name, different type).. I'm closing the issue here, as is more related on the spec than this implementation.\nFeel free to open an issue in the GraphQL relay spec: https://github.com/facebook/relay. The locations field was implemented in graphql-core in this commit: https://github.com/graphql-python/graphql-core/commit/f62eddc4d05ee4fcf9bd258b6e6b142dc8fdfe2b (which graphene was using since 0.10 if I recall correctly.\nAn update to graphene >= 1.0 should fix the issue.\nSee SWAPI GraphQL introspection query\nPlease reopen or re-comment if not.\nThanks!. Hi @kirberich, this behavior is intentional and caused by how the Python imports work.\nThe datetime module is not imported in types/__init__.py (intentionally, as it requires iso8601 package), therefore you can't import it from there.\nHowever, when you do from graphene.types import datetime you are importing directly the module.\nAnd then, the module is exposed in graphene.types.. Thanks for the fix!. Makes sense! Thanks for the PR :). Looks great! Thanks for contributing :). Hey Jonas, I improved a little bit the PR, placing the Apollo mention in the integrations part!. The example that @BossGrand provided should solve the issue.\nAlso, I improved the mutation docs so I will close this issue.\nFeel free to reopen if something is not clear!. Love the work here! \u2764\ufe0f\nMerging . Resolvers not always returns promises.\nBecause of that, the way of writing Middleware should be uniform despite the resolver output, that's why wrapping in promises is useful.\nBased on this, and other factors, I'm working in a much faster promise implementation (about 5 times faster).\nHowever, even in this case I can see the cases where the cost of wrapping into Promises is still high, if you want to work in a PR in graphql-core to make optional wrapping the middleware into promises or not I will happily consider it :). Great work @grazor!\nI've created a repo in the organization: sanic-graphql, you should have received an email from Github to join the organization and also have write perms on the repo.\n:). Done! Also, if you can add perms to the PyPI package (https://pypi.python.org/pypi/Sanic-GraphQL) would be great, so I can automate the package submission to PyPI once a new tag is pushed to the git repo :)\nMy PyPI username: syrusakbary. Closing issue as we already added the repo for GraphQL in Sanic in the org! :). Great catch! Will push a fix soon :). Thanks for the contribution!. Thanks for the fixes!!. This is awesome!\nI will take a closer look next week and provide some feedback then :). I took a look in the implementation and besides some small nits (like Apollo* naming) it looked good!\nI'm waiting to few things:\n Having a subscriptions integration with Django so we assure that the subscriptions structure is abstracted in a scalable way.\n The formal subscription RFC in the GraphQL spec to be merged https://github.com/facebook/graphql/pull/305\n. @Eraldo @hballard Yes, I think I should post an update here as I'm working full on subscriptions now.\nSome thoughts about my journey: the way Apollo-Subscriptions use to manage subscriptions was not very friendly for the developer, needing to hack around the resolution and a specific PubSub implementation that was \"bypassing\" the GraphQL engine for adapting it into subscriptions.\nThe reason for that is the GraphQL-js engine was not ready for subscriptions (meaning that was only able to return either a promise or a static value, but not a async iterator).\nHowever GraphQL-js recently added a way to subscribing to a GraphQL query (that return an async iterator a.k.a. Observable) that pushed towards simpler and cleaner implementations of subscriptions that decouple the subscription resolution from the \"listener\" on the subscription.\nThat led to better implementations of the transport mechanisms in GraphQL subscriptions like subscriptions-transport-ws.\nSo, in summary, subscriptions is something that should be bundled fully into the GraphQL engine, in a way that is easy to plug any mechanisms, such as:\n websockets with asyncio\n websockets with gevent\n* websockets with django-daphne\nThat don't require any specific pub/sub implementation and, eventually, let this decision to the developer (in case it want to use it).\nFor the next version of Graphene, 2.0 I plan to have subscriptions bundled into the Engine :)\nThere is already a branch in graphql-core where I'm doing the research process.\nI will keep updating this thread with more information as I keep working on it.. Hi @nsh87,\nAs a recommendation, Is better to be explicit on the query, and adding arguments to a field when their attributes could change the resolution of that field.\nIn this case, would be better (and more scalable) to add a username argument to the posts field,\nNote that Input and Output data have different types by design (as reflected in the GraphQL spec), so you can't use a ObjectType as input.\nExample\nSo you can query like:\ngraphql\nquery {\n    posts (tag: \"science\", user: {username: \"john_doe\"}) {\n        id,\n        title,\n        user {\n            # Note that I moved the username filter the posts field, as affects its resolution\n            username,\n            first_name\n        }\n    }\n}\nAnd the implementation:\n```python\nfrom graphene import InputObjectType, ObjectType, String, ID, Field, List\nclass UserSchema(ObjectType):\n    username = String()\n    first_name = String()\ndef resolve_username(self, args, context, info):\n    return self.get('username')\n\ndef resolve_first_name(self, args, context, info):\n    return self.get('first_name')\n\nclass PostSchema(ObjectType):\n    id = ID()\n    title = String()\n    user = Field(UserSchema)\ndef resolve_id(self, args, context, info):\n    return self.get('id')\n\ndef resolve_title(self, args, context, info):\n    return self.get('title')\n\ndef resolve_user(self, args, context, info):\n    return self.get('user')\n\nclass UserInputSchema(InputObjectType):\n    username = String()\n    first_name = String()\nclass QueryType(ObjectType):\n    posts = List(\n        PostSchema,\n        id=ID(),\n        title=String(),\n        user=UserInputSchema()\n    )\ndef resolve_posts(self, args, context, info):\n    return mongo.db.posts.find(args)\n\n```\n(check also a similar example working in the playground)\nHope this helps!. Hi @janhancic,\nIt might be a good idea to create a  converter from the ProtobufEnum to the graphene Enum.\nSomething like this will probably work:\n```python\ndef pb2enum_to_graphene_enum(pb2_enum):\n    desc = pb2_enum.DESCRIPTOR\n    return graphene.Enum(desc.name, desc.values_by_name)\nMyEnum = convert_pb2enum_to_graphene_enum(my_pb2.MyEnum)\n```\nAnd then use it like:\npython\nclass Bob(graphene.ObjectType):\n    my_field = MyEnum()\nHope this helps!. The way I would recommend is actually creating a GraphQL enum type, as is more powerful, semantic and takes the advantage of GraphQL enums that clients might find useful.\nHowever, re-reading the issue, it seems is not actually the desired behavior.\nYou can achieve something similar by creating a new field type, and mapping from the protobuf to a Int.\n```python\nfrom functools import partial\nclass ProtoEnum(graphene.Field):\n    def init(self, protobuf_enum, *args, kwargs):\n        self.protobuf_enum = protobuf_enum\n        super(ProtoEnum, self).init(graphene.Int, *args, kwargs)\ndef resolver(self, parent_resolver, root, args, context, info):\n    resolved_value = parent_resolver(root, args, context, info)\n    # We check is a valid value in the protobuf enum\n    # This might be not actually the way to check, but serves the concept!\n    assert resolved_value in self.protobuf_enum\n    return resolved_value\n\ndef get_resolver(self, parent_resolver):\n    return partial(self.resolver, parent_resolver)\n\n```\nAgain, I think the cleaner and best way to achieve this would be using a graphene.Enum (as it maps to a GraphQL enum), and could be used not only in output fields, but also in input arguments.. Thanks for including a working example!\nClosing the issue :). String references are no longer available.\nYou can achieve the same result with:\n```python\nclass A(graphene.ObjectType):\n     name = graphene.String()\n     to_b = graphene.Field(lambda: B)\nclass B(graphene.ObjectType):\n     name = graphene.String()\n     to_b = graphene.Field(lambda: B)\nclass Query(graphene.ObjectType):\n     get_a = graphene.Field(A)\n     get_b = graphene.Field(B)\nschema = graphene.Schema(query=Query)\n``. There is also thelazy_import` utility function that makes this task easier:\n```python\nmymodule/a.py\nclass A(graphene.ObjectType):\n     name = graphene.String()\n     to_b = graphene.Field(graphene.lazy_import('mymodule.b.B'))\n```\n```python\nmymodule/b.py\nclass B(graphene.ObjectType):\n     name = graphene.String()\n     to_a = graphene.Field(graphene.lazy_import('mymodule.a.A'))\n     to_b = graphene.Field(lambda: B)\n```\nThe main reason string references were dropped was because it was non-deterministic.\nTalking of a type A (referenced only by the name) only makes sense when including their schema context, however the definitions are outside the schema (for reusability).\nHope this makes sense!. Hi @blakegong,\nIt seems this is a bug. Could you create a PR with a test case that helps to reproduce it, so I might be able to fix it quicker?. Ok!. Will take a look soon! Thanks for reporting the issue and creating the repo :). Hey @blakegong,\nI think improving lazy_import to accept a extra argument as inner attr might be a more robust solution.\nSomething like:\npython\nlazy_import('some_package.schema.nodes.Event', 'Connection.Edge')\nThoughts?. Great! If you wanna create a PR I will happily review it and merge \ud83d\udd25 . Revising this now. Thanks for the report :). This is now fixed in master :).\nI improved the TypeMap converter rather than modifying the __eq__ in the GrapheneGraphQLType as it's more robust and fixes the issue directly rather than silence it.  . Hi @davidyapdy,\nI'm sorry that you find the docs unpleasant/terrible, definitely they need some more love and dedication.\nFortunately, this is an open source project and I'm quite open to contributions in this sense.\nAny help to improve the docs will be more than welcome!!\nThere are some good docs about GraphQL that could help to define/improve the docs:\n http://graphql.org/learn/\n https://learngraphql.com/basics/introduction\n* https://rmosolgo.github.io/graphql-ruby/\nPlease let me know if you would like some guidance in how to contribute into the docs! :). Sure! You can email me to: me@syrusakbary.com or you can post it here... whatever you prefer! :). The coverage drop is minimal, everything is looking good!\nMerging \ud83d\udc4d . I've created a PR for improving the ability of comparing graphene.Enum with their values, and added extra sugar to imitate the normal native behavior for member getters.\nPlease take a look on the PR and let me know your thoughts!\nhttps://github.com/graphql-python/graphene/pull/446. @dewiniaid feel free to review this PR and let me know if you have any suggestion!. @khankuan I think would be a great addition into the docs, if you want to open a PR with a new section documenting the input args I will happily merge it! :). Hi @fangaofeng,\nThe code seems right, what is the query you are making?. If the code is executed properly, I'm not sure why you can't set a break point.\nTwo things that might help to debug:\n Are you using a custom GraphQL executor?\n What debugging tool are you using?\n. Great addition!. As @jkimbo commented, the logic is better when coupled with your API server.\nI started the project graphql-env to provide an abstraction similar to the pseudocode commented.\nhttps://github.com/graphql-python/graphql-env\n. Not at the moment, as in the GraphQL spec Strings have no length limitations.\nHave you thought about creating a new String-length-limited scalar?\n```python\nimport six\nfrom graphql.language.ast import StringValue\ndef assert_short_string(str_value):\n    if len(str_value) > 255:\n        raise Exception(\"ShortString can only receive strings with less than 255 chars!\")\nclass ShortString(Scalar):\n    '''\n    The ShortString scalar type represents textual data, represented as UTF-8\n    character sequences, with a max length of 255.\n    '''\n@staticmethod\ndef coerce_string(value):\n    if isinstance(value, bool):\n        return u'true' if value else u'false'\n\n    str_value = six.text_type(value)\n    assert_short_string(str_value)\n    return str_value\n\nserialize = coerce_string\nparse_value = coerce_string\n\n@staticmethod\ndef parse_literal(ast):\n    if isinstance(ast, StringValue):\n        assert_short_string(ast.value)\n        return ast.value\n\n```. Hi,\nI recommend you using the SQLAlchemy automap feature.\nAnd then transform the table model to Graphene automatically with Graphene-SQLAlchemy.\nThis way you will not need it to do it by hand :). Usually lambdas are used when there is a dependency that only can be resolved lazily.\n(for example, a self-reference to the field parent type).\nOtherwise, using the non-lambda form is the recommended approach :). A similar solution to what @bochuxt pointed would be:\n```python\nclass Coworker(SQLAlchemyObjectType):\n    class Meta:\n        model = CoworkerModel\n        interfaces = (relay.Node,)\nrowid=graphene.Int()\n\n@resolve_only_args\ndef resolve_rowid(self):\n    return self.id\n\n```. @sineo could be possible to have some code that reproduces this issue?\n(either a repo or a code snippet would work)\nWith that I might be able to assist on a quick fix easily.. Thanks for the PR!. Hi @chaffeqa!\nI think creating an Optics client for Graphene would be a great move for @apollographql as few more people already asked for that.\nThe easiest way would be doing the integration using a custom middleware for it.\nCurious to know if this in your plans? @helfer @stubailo. Given the recent interest (here and offline), I'm thinking to create an open-source GraphQL logging tool with an easy integration with Graphene or any other GraphQL framework.\n(similar business model as Sentry).\nWill some of you be open to pay half of the price as apollo optics while having a similar interface?. I'm happy that you found a way to solve the issue.\nClosing here, but feel free to reopen if you think something is still not clear :). I just tried and the page is working fine. Perhaps might be your internet connection or caused by a Github page external issue?. Hi Phil!\nThe reason this is happening is because the DataLoader runs on top of the promise loop engine instead of one based in gevent event loop.\nSo, the fields are resolved asynchronously, but the dataloader relies on the \"next tick\" of the event loop, which in this case is not Gevent's and therefore the ticks are triggered even before the Gevent next loop tick.\nWhy creating an event loop?\nIn older versions of Python (2.7, 3.3) there was no event loop provided by default (asyncio was added in Python 3.4), and the easier way to have Promises working in a universal way was to mimic the effects of an event loop.\nHow to solve it\nThis could be fixed by making dataloader to push the job for batching to the Gevent loop instead of the custom one (async_instance).\nhttps://github.com/syrusakbary/promise/blob/master/promise/dataloader.py#L199\nI can assist you on that, if you need so!. Hey @nikvdp I think documenting this scenario is a great idea.\nThe interfaces docs is probably the best place to do it!. Taking a look now, thanks for such a great report!. I decided to fix the argument output name to be _from instead of from, as it simplifies and makes more clear how to retrieve the arguments from the python resolver.\nThis way, the previous function you expected to work, should work:\npython\n    def resolve_some_query(_, args, context, infos):\n        args[\"from_\"]  # Not longer KeyError :). @whalesalad the example you posted for inline fragments is only applicable to Interfaces.\nIn the case of Unions, there is no \"common\" fields between types (at least none that the GraphQL engine is aware of, without making some assumptions that might not be correct).\nOn the other hand, with an Interface, you assure that all it's implementations at least have the interface fields in common.\nQuoted from the official GraphQL spec:\n\nWith interfaces and objects, only those fields defined on the type can be queried directly; to query other fields on an interface, typed fragments must be used. This is the same as for unions, but unions do not define any fields, so no fields may be queried on this type without the use of typed fragments.\n\nClosing the issue. Thanks for the fix! Merging. Hi @keattang,\nYou can do in (graphene 2.0):\npython\n    def resolve_thing(self, info, args):\n        thing_schema = info.return_type.graphene_type. @matclayton I think persisted queries is indeed quite a useful feature (and I think is a better strategy for saving time compared to bypass the validation step).\nAt the moment I'm more inclined to have an example of persited queries backed into one of the integrations, such as graphene-django as there is already a default way provided to persist the data using Django Models.\nAfter that might be useful to put some of the common abstractions back into graphene so people can create it's own \"persisted queries\" implementations easily.\nThoughts?. This will be solved in 2.0 as you will be able to use normal inheritance without using AbstractType :). Happy you found the bug :)\nClosing the issue. Closing this PR as totalCount is not part of the relay spec as mentioned by @ekampf.. Hi @scotmatson, first thanks for contributing!\nThe code was intended the way it was written (no indentation), however I think it was not a good example.\nI've improved it with this commit: https://github.com/graphql-python/graphene/commit/f3bdd7de6901521bec7bd22e32743bf3c87fdb91\nPlease let me know if is still not clear!\nClosing the PR. Hi @AshwinRamesh, I'm open to create a 1.4.2 release with the changes, however I'm not sure which bug fixes you refer to as there are not a lot of bugfixes in master since the last release 1.4.1 (only relevant change in code is https://github.com/graphql-python/graphene/commit/f22504c2fc931007111264f4067e11662dd4ed13 )\nhttps://github.com/graphql-python/graphene/commits/master\nYou were referring to this change or maybe other bugfixes of 2.0?. Thanks for contributing!. This PR should be no longer necessary in Graphene 2.0.\nNow you can do:\n```python\nclass SuperInterfaceOptions(InterfaceOptions):\n    extra_option = None\nclass SuperInterface(Interface):\n    class Meta:\n        abstract = True\n@classmethod\ndef __init_subclass_with_meta__(cls, extra_option=None, **options):\n    meta = SuperInterfaceOptions(cls)\n    meta.extra_option = extra_option\n    return Interface.__init_subclass_with_meta__(cls, _meta=meta, **options)\n\n``. Thanks for the catch! Fixing it now :). Hi @japrogramer, You will need to use the latest version ofgraphene-django`.\nbash\npip install \"graphene-django>=2.0.dev\"\nLet me know if this works!. Hi @mojochao,\nSorry, there was a typo on the 2.0 docs that I just fixed with the commit: https://github.com/graphql-python/graphene/commit/74550637280b65179cb897c8386799a9a6776f42.\nEverything should run if you add the info argument after root (and before company_data).\nLike:\npython\n    @staticmethod\n    def mutate(root, info, company_data=None):\nLet me know if this works!. Hi @nakeeon,\nThanks for reporting the issue! Could be possible to have a full test case that reproduces your issue or a repo that I can clone?. I was waiting for Subscriptions to release the next stable version of Graphene 2.0.\nToday, I released Graphene 2.0 (with support to subscriptions) in the GraphQL Summit.\nClosing this issue now :). Hi @achimnol, you will need to initialize the Enum (or wrap on a Field) when using it:\n```python\nclass KernelStatus(enum.Enum):\n    PREPARING = 10\n    RUNNING = 30\n    ...\nKernelStatusEnum = graphene.Enum.from_enum(KernelStatus)\nclass ComputeSession(graphene.ObjectType):\n    status = KernelStatusEnum()\n    ...\nclass Query(graphene.ObjectType):\n    compute_sessions = graphene.List(ComputeSession,\n        access_key=graphene.String(required=True),\n        status=KernelStatusEnum())\n``. Hi, \nIt seems you are using Graphene 2.0.dev, so you will need the latest package of graphql-core that haveResolveInfo`.\nYou can solve the issue by doing pip install \"graphql-core>=2.0.dev\". Closing as now the website have no playground (once it have it again, will be with the new syntax :) ). Just a note, for having this working you just need to use asyncio executor:\nresult = asyncio.wait_for(schema.execute(query, variable_values=foovar, executor=AsyncioExecutor(), **kwargs), 1.0). As per my comment on #555:\nIf you want to make the fields private, you just need to not instantiate with Field (or String...).\nLike:\npython\nclass Query(ObjectType):\n    hello = Field(String)\n    _private = None. Hi @mrstork.\nIf you want to make the fields private, you just need to not instantiate with Field (or String...).\nLike:\npython\nclass Query(ObjectType):\n    hello = Field(String)\n    _private = None. The following is now possible:\npython\nclass Mutation(graphene.ObjectType):\n    add_product = AddProduct.Field(description=\"Test\")\nEnabled by this commit: https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95\nClosing PR. I think that's a great idea @patrick91!. @patrick91 any progress on the tutorial?. Sorry for not announcing the plan for it before.\nI released the stable version of Graphene 2.0 today 24 Oct at GraphQL Summit.\nClosing the issue :). Yup, let me do a quick release of 1.4.2 so we fix this :)\nVersions will be pinned on future releases of Graphene thanks to #581, so this way we assure this issue is not longer repeated.\nThanks all for raising the issue.. Just published a new version of Graphene 1.4.2 with the pinned requirements.\nhttps://pypi.python.org/pypi/graphene/1.4.2\nClosing the PR :). Just published a new version of Graphene 1.4.2 with the pinned requirements.\nhttps://pypi.python.org/pypi/graphene/1.4.2\nClosing the PR :). Just fixed this in master. The issue was happening on both ObjectTypes and Mutations (when used as containers)\nI also added tests so this issue is not repeated in the future :). A connection is an enhanced structure for items that can be paginated, enabling the following capabilities for the client:\n The ability to paginate through the list.\n The ability to ask for information about the connection itself, like totalCount or pageInfo.\n The ability to ask for information about the edge itself, like cursor or friendshipTime.\n The ability to change how our backend does pagination since the user just uses opaque cursors.\nI'm not sure if this statement makes more clear what connections are for, but I would love to improve the docs with something that can be properly understood for both newbies and experienced GraphQL devs.\nThoughts? How do you think we can make connections clear for everyone?. The following is now possible:\npython\nclass Mutation(graphene.ObjectType):\n    add_product = AddProduct.Field(description=\"Test\")\nEnabled by this commit: https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95\nClosing PR. Yes, we created a new version graphene 1.4.2 that fixes this issue.. @nparrish it looks great!\nBefore merging it would be needed to have some tests that test against the issue that this PR resolves, so we make sure this issue is no repeated in the future :). Reopened. Closing this issue :). Hi @mandx,\nFor using Graphene with asyncio you need to add AsyncioExecutor as the executor, like:\n```python\nfrom graphql.execution.executors.asyncio import AsyncioExecutor\nfrom graphql import graphql\nmy_result = graphql(schema, '{ the query }', executor=AsyncioExecutor())\n```\nIf you want the result to be awaitable you can also do:\npython\nasync def execute_query():\n    my_result = await graphql(schema, '{ the query }', executor=AsyncioExecutor(), return_promise=True)\nLet me know if this solves your issue :). Might be caused by some of the middleware.\nCould be possible to have this in a repo I can clone, so can help you fix the issue? (or fix it in graphene or graphql-core, if that's the case). Thanks for the report. This is now fixed on master.. Hi @danpalmer,\nI think your concerns regarding the \"pythonic\" way of doing things are not just valid, but very reasoned and thoughtful.\nBefore adding into the docs, I would love to describe here the \"whys\" on each of the points you made, so we can go back and forth with the explanations until they are clear. And from there we can write them into the docs.\nPromises\n\nWhat is a promise? Promises aren't a concept in Python, and it might be assumed that async/await could be used instead. Providing a brief reason for why promises are used in Graphene and links to further documentation would be great.\n\nYou are completely right, with async/await syntax the promise abstraction is no longer needed (I even tweeted about it few months ago \ud83d\ude1c).\nThe main reason Graphene/GraphQL-core was using Promises in the first place is for the need of a abstraction \"future\" to be managed in Python versions where the async/await syntax was not available (Python 2.7+, Python ~< 3.4).\nIt's also true that in Python and some of its libs the concept of Deferred and Future was also available, but there were some reasons for using a Promise abstraction instead:\n1) It provides a \"universal\" way of working with futures/deferrals independently of the framework (gevent, tornado, threading, ...., as each of this implementation have a different implementation of a Future).\n2) It provides a very easy API to chain this \"future\" values.\n3) It incredibly simplified the GraphQL core codebase, making it easy for contributors to step on to the code: https://github.com/graphql-python/graphql-core/pull/59\nBut the truth is, once Python 3 is used by most of the Graphene users, the promise abstraction can be safely removed :)\nself in resolvers\n\nself not being a class instance in resolver 'methods'. I don't understand the architectural reasons why this can't be the case, but in Python an instance method (like the resolver methods) is expected to take a self first argument. The documentation says that this isn't the case with Graphene (which is unexpected), but it still calls the argument self in some cases which further confuses the issue. It is mentioned that these methods act like static methods, however it's unexpected that they aren't decorated with the @staticmethod decorator.\n\nAt the beginning (in Graphene), all resolvers were receiving the args self, args, info, where self was actually an instance of the ObjectType itself.\nSo, for accessing the root value, the developer need to type: self.root. Also, for ease of development, a __getattr__ was created in the ObjectType so each time you do self.abc it was calling getattr(self.root, 'abc').\nThis resulted in very bad performance in the earlier versions of Graphene (previous to 1.0), as for each ObjectType resolution, the result needed to be wrapped in a new instance of the ObjectType.\nSo then, we have to solve other question also... why all resolvers are static without the need of them being decorated with @staticmethod?\nThe main reason for that is:\n1) To simplify the code necessary to be written by the developer\n2) If the developer forgets to wrap it with @staticmethod, there will be no real self (as we don't want to wrap the result because of performance as exposed before).\nA very similar decision was made by the Python committee when the new __init_subclass__ method was introduced in PEP-487 choosing not to require a @classmehtod on the method, mainly because of minifying developer issues.\nEventually, both the Graphene types and the real datatypes will be merged into the same object (for static typing reasons, plus readability, I can explain this in another comment if necessary), so this hopefully will no longer be an issue.\nInterfaces not inherited\n\nInterfaces are listed in a Meta class attribute. In normal Python I would expect these to be in the inheritance tree, perhaps as an abstract base class using abc. Again I'm sure there are great reasons why this is not the case, but giving some motivation for this in the documentation would go a long way to making Graphene easier to understand.\n\nIn the first versions of Graphene (pre 1.0), the only way to inherit a specific Interface in a ObjectType was through Python object inheritance (rather than meta like right now, see the Graphene 1.0 upgrade guide)\nHowever, the nature of ObjectTypes and Interfaces are mainly different (both hold fields, but one can be instantiated while the other don't...), mixing both classes to be inherited at the same time can result challenging:\n1) When a class inherits an Interface, how can we check that is an ObjectType versus an abstract Interface? (like the Node interface).\n2) How we can make both metaclasses not to collide (ObjectType metaclass and Interface metaclass).\nRight now I believe this might be easier resolved thanks to the __init_subclass__ approach, but will wait until a valid (and easy to understand) proof of concept is made.\nMiddleware as a class rather than a function\n\nMiddleware is implemented object instances with a resolve method. Again I'm sure there are reasons for this, but I wonder if the class is needed, could middleware just be a function (I think this would be more Pythonic). Alternatively, middleware could be specified to Graphene as classes, not instances, and Graphene could instantiate on each request-response cycle so that the instance is able to hold data in the request lifecycle. This is how Django does it, and it can be useful with more complex middleware. Right now that is not well supported.\n\nThe reason Middleware was created as a class was because of it was created with the aim, of not only act in the resolution of a field, but also intercepting the beginning/end of a GraphQL query.\nBut the truth, is this was planned, but never added afterwards.\nAbout middleware as just a function, it's also supported by Graphene, but sadly not documented.\n\nWould love to hear your thoughts on this! :). This is now fixed by #701 .. Thanks a lot for this token of appreciation, it really helps me to continue pushing forward.\nI'm super happy that you find Graphene useful in your day to day... and I will make sure this remains true for the next years to come (lots of exciting stuff to come in next releases!).\nBest,\nSyrus Akbary. The following is now possible:\npython\nclass Mutation(graphene.ObjectType):\n    add_product = AddProduct.Field(description=\"Test\") # \u2190 this is ignored\nEnabled by this commit: https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95\nClosing PR. Thanks @jkimbo . This is now fixed in master (and graphene 2.1.0).\nPlease reopen the issue if is not working as expected.. Closing this PR in favor of #701, now merged into master\nThanks anyway for the effort @frsv . The link should direct to https://facebook.github.io/relay/docs/en/graphql-server-specification.html rather than graphql-in-relay.html (as the latter is for the React-Relay integration).\nI will do it in a direct commit.\nThanks for pointing the issue :). Yup, sorry for being silent about this.\nThe main reason this is not merged is because the provided solutions tried to get the description from the mutation output ObjectType, when actually the description is for the Field.\nThe best solution would be to allow description to be set directly in the Field function:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/mutation.py#L79\n. Just fixed this issue with commit: https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95. Thanks for contributing! :). Good catch! Will fix soon. This is now fixed in master :). Closing issue in favor of #476.. I just fixed this with https://github.com/graphql-python/graphene-django/commit/9cdd95c11436566d48b9b3e19aed9e648fcb3d76. Closing issue. I just fixed the broken __str__ implementation for abstract types with:\nhttps://github.com/graphql-python/graphene/commit/562cafc14f66bbad7f76e7600fa0acd71d00194e\nThanks for the snippet! (I think might be worth to add somewhere in the docs). I believe .iterable is used by graphene-sqlalchemy. Thanks for the input.\nI just checked and default_value was actually dismissed for fields. I've added a test case based on your example to avoid this repeating again in the future.\nThanks.. Hi @ewhauser, I would love to have the project under graphql-python, while conserving you as main contributors/maintainers to the repo.\nIf you like the idea let me know and I will setup things so we are able to move it over :). Sorry for missing it. I just added you perms (@ewhauser) to be part of the org.\nYou should be able to transfer the repo over to graphql-python now :)\n(let me know if you can't). @ewhauser I\u2019ve just added you admin rights on the repo.. I intentionally kept GenericScalar away from the default exported items.\nThe main reason for this is because I think it introduces a bad practice when creating and using GraphQL schemas (that might bite the developer later), and it should be only useful in a handful of situations (so no need to be a default exported item).\nThoughts?. It goods look to merge for me @jkimbo, feel free to merge once you review it :). @ocavue thanks for opening the discussion.\nThe new resolution syntax on Graphene 2 root, info, **options was took specially with typing in mind, so it could be very easy to annotate the resolver arguments in the future.\nPersonally, I do really like the way NamedTuple works in the typing package for defining the attributes for the named tuple: https://docs.python.org/3/library/typing.html#typing.NamedTuple\nIn Python 3.7 onwards, the @dataclass attribute will let the user create a data class very easily: https://www.python.org/dev/peps/pep-0557/\nInspired in all this I think the next version of Graphene (Graphene 3.0) could also allow developers to type their schemas like the following:\n(while maintaining 100% compatibility with the previous syntax)\n```python\n@ObjectType\nclass Person:\n    id: str\n    name: str\n    last_name: str\n    def full_name(self, info) -> str:\n        return f'{self.name} {self.last_name}'\npersons_by_id = {\n  '1': Person(id='1', name='Alice'),\n  '2': Person(id='2', name='Bob')\n}\n@ObjectType\nclass Query:\n   def get_person(self, info, id: str) -> Person:\n       '''Get a person by their id'''\n       return persons_by_id.get(id)\n```\nThere are some reasons on why I think this is a very powerful syntax:\n The decorator syntax permits to extend the normal data types, and will make easier to reason about self in resolvers (currently, on Graphene 2, self is referring to the root object, automatically marking the resolver as a @staticmethod... and sometimes this might be confusing)\n It permits a fully typed and testable schema, end to end\n* The layering needed between native Python types and GraphQL types will be minimal\nHowever, there are some cons of this approach:\n field types will be required by default. As an optional type is always a super set of the normal type Optional[T] = Union[T, None] *, Optional types will need to be explicitly defined and being required will be the default.\n If the ObjectType have other attributes annotated (that we don't want to expose to GraphQL) they will be exposed automatically. We can solve this in various ways:\n  -  do not include attributes starting _ (private) to GraphQL\n  - Add a explicit way of skipping attributes, such as:\npython\n@ObjectType(skip: ['password'])\nclass Person:\n   # ...\n   password: str\n* We will need to rethink about connections and how are resolved, so we can do things like:\n```python\n@Connection(node=People)\nclass ConnectionPeople:\n    pass\n@ObjectType\nclass Query:\n    def all_people(self, info, first: int = 10) -> ConnectionPeople:\n        return ConnectionPeople.get_from_iterable(...)\n```\n* Will be challenging to keep the previous syntax 100% compatible (but still possible, it will be just a bit harder and might complicate the logic for a bit).\nWhat are your thoughts?. Thanks for the PR @dan98765!\nMerging :). I agree with @jkimbo. Replacing reorder_python_imports with isort (https://github.com/pre-commit/mirrors-isort ) should solve it . Looks good, if you can replace the lowercase graphene into Graphene will be great \ud83d\udc4d . Makes sense, thanks for the PR :). Thanks for the implementation and tests, the PR looks great \ud83d\udc4d . Thanks for the upgrade guide improvement! Merging. default_value have to be MyGrapheneEnumType.MEMBER.value.\nLet me know if this fixes your issue:\npython\nMyGrapheneEnumType = graphene.Enum.from_enum(\n    MyEnumType\n)\nclass MyInput(graphene.InputObjectType):\n    my_enum_field = graphene.Field(MyGrapheneEnumType, default_value=MyGrapheneEnumType.MEMBER.value). @dan98765 having test in extra_requirements was intentional.\nSome companies like to run graphene tests after install to test that graphene is working properly in their environment. Because of that, they require to be able to install requirements with pip install graphene[test]. Looks great!. Merging then :). Great improvements! Merging. I like this, however, let's make sure we write this down as a breaking change on the release, so people are aware the name has to be changed from resolve_type to _resolve_type.\n(It will also require a minor version bump 2.2.0). @japrogramer was this caused by Graphene?. As per the GraphQL spec, an argument can't be deprecated at the moment.\nClosing this issue.. This is a great suggestion. I would love to merge any PRs fixing this.\nYou can find in the repo https://github.com/graphql-python/graphene-python.org the necessary instructions to set the docs layout locally, and submit a PR once the fix is done :). First, thanks a lot for your work @Kacppian.\nAfter reviewing this PR, I sincerely don't prefer this new syntax, since with the assert the code was much more legible/readable.\nThis was my fault since I embraced the change proposed by @danpalmer without questioning if the readability was going to be better or not (#784), maybe this PR is approached differently to what Dan suggested:\n\nInstead of:\n\npython\nassert something is not None, \"Something was unexpectedly None\"\n\nWe should do this:\n\npython\nif something is not None:\n    raise AssertionError(\"Something was unexpectedly None\")\nWhat we have in the PR:\npython\nraise_assertion_if_not(\n   something is not None,\n   \"Something was unexpectedly None\"\n)\nI would love to get more input into this, so comments are more than welcome!. Hi @leebenson , @patrick91.\nThanks a lot for chiming in for Commercial support, this is something I've been thinking for a while.\nIt might permit me to open-source (with license) Quiver, so more companies can have access to it.\nAs a way of organizing the different tiers for contributing into the project, I was thinking on doing similarly to Vue.js in patreon and Django Rest Framework\n Backer\n  $10 or more per month\n  Support ongoing development\n  Your name will be put in backers.md in the Graphene repository.\n Generous Backer\n  $50 or more per month\n  Support ongoing development\n  Your name will be put at the top of backers.md in the Graphene repository.\n Bronze Sponsor\n  $100 or more per month\n  Support ongoing development\n  Your name or company logo (small) will be put in backers.md in the Graphene repository.\n Silver Sponsor\n  $250 or more per month\n  Support ongoing development\n  Priority support for your engineers\n  Your name or company logo (medium) will be put at\n  - the top of backers.md in the Graphene repository;\n  - on a dedicated sponsors page on graphene-python.org.\n Gold Sponsor\n  $500 or more per month\n  Support ongoing development\n  Priority support for your engineers\n  A job post on every documentation page\n  Your name or company logo (big) will be put at\n  - The homepage of graphene-python.org; (50k+ impressions per month)\n  - The top of the project repo's README. (~6k+ unique visitors per month)\n Platinum Sponsor\n  $2,000 or more per month\n  Support ongoing development\n  Priority support for your engineers\n  A job post on every documentation page\n  Your name or company logo will be put on:\n  - The top left of every documentation page on graphene-python.org\n  - The homepage of graphene-python.org (at the top of the sponsors section)\n  - The top of the project repo's README.\nThoughts?. I'm working towards what we talked here \ud83d\ude0a\nThese are the most recent changes:\n Added ROADMAP file in the project repo (and link it from the README)\n  https://github.com/graphql-python/graphene/blob/master/ROADMAP.md\n Added TEAM page in Graphene website (so it's easier to see main contributors of the community)\n  https://graphene-python.org/team/\n Added a support page in Graphene (is hidden right now, will be enabled once we are all happy with the current commercial support layout)\n  https://graphene-python.org/support-graphene/\n Created Patreon page \n  https://www.patreon.com/syrusakbary\nWould be awesome if you could visit the Patreon page, the Graphene support page and write here your feedback ...it would be highly appreciated!\nOnce we are all happy with the model, I will start featuring it in Twitter and other media :)\n@codeocelot @leebenson @patrick91 \nPS: I will update the ROADMAP with your suggestions towards specific issues / features you would like to see in the GraphQL Python community moving forward, so we make sure the funding will enable those. I'm working on this right now. Waiting for Algolia to approve the application for the docsearch:\nhttps://community.algolia.com/docsearch/. Algolia just approved the application and docsearch is now live in all Graphene pages :)\n\n. Thanks for the changes! Looks great \ud83d\udc4d . Hi @dani0805, this PR belongs to the Graphene-Django docs, not to the base Graphene Docs.\nPlease reopen there the PR for re-review :). @danpalmer looks good. For tests to pass you will need to change also the following assertion:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/relay/tests/test_connection.py#L141\nI will merge after! :). \ud83d\udc4d Merging. Cool, I will close the issue as seems unrelated to Graphene or Graphene-Django integration.. Hi @danpalmer,\nHave you tried the following?\npython\nclass SomeMutation(relay.ClientIDMutation):\n    class Input:\n        class Meta:\n            description = \"Some documentation for this input type.\"\nI'm concerned for injecting the base class at the beginning of the inheritance tree as it might overwrite already defined methods in other classes (such as __init__ or so).. Super useful PR towards improving documentation!\nThanks for the work @danpalmer, merging. Hi @larsblumberg,\nThe plan (in the long term) is use graphql-core-next only. However there will be a period (probably long) while both libraries can be used indistinctly.\nSpecific roadmap\nRight now the APIs for graphql-core and graphql-core-next are very similar, but not compatible at all.\nWe need both to be almost 100% compatible, so Graphene can start using them indistinctly.\nFor this to work, we would need to:\n1. Port some functions, such as graphql_sync, from graphql-core-next to graphql-core\n2. Adapt graphql-core-next to be able to use some features that are currently only on graphql-core: middleware, custom Typemap creation (on the works)\nBenefits of using graphql-core-next\nPython 2 is coming to an end. There are a lot of features of Python 3 that we can't use direclty, such as:\n Type annotations (static typing with mypy)\n async/await syntax\n* async iterators (ideal for subscriptions)\nBy using graphql-core-next we will deprecate the usage of custom executors and promises, and take advantage of the Python 3 new features. While removing a lot of boilerplate code that was needed for Python 2/ 3 compatibility.\nHope this clarifies your questions!. I've been working with @Cito laying out a plan for a transition.\nHere is what we decided:\n Consistency across projects is a must, therefore we are going to port graphql-core-next to graphql-core so they have exactly the same API (with some minor tweaks). This also will bring the latest features of the GraphQL spec to Python 2. I'm already working on this and will have a prototype ready in a few days.\n All packages (when used in Python 3) should be 100% compatible with one or the other library (thanks to the fact that promises are awaitable and observables can be iterated as async iterators)\n Graphene should be compatible out of the box with graphql-core and graphql-core-next (ergo, we can make a conditional dependency on using graphql-core or graphql-core-next just depending on the Python version)\n We stop fragmentation at the core. Here is an update on graphql-core, on the modernized version based on graphql-core-next:\nAbout 1476 of 1596 tests are now passing. \nI will create a branch in graphql-core named modern with all the changes once all tests are passing.\nOnce that's achieved, I will work on the next version of Graphene (v3) that will support it, along with new awesome features.. Here it is: https://github.com/graphql-python/graphene/blob/master/ROADMAP.md#graphene-3\n(It should be getting more detailed as time passes). GraphQL-core (modern) is now passing all tests for both Python 2.7 and Python 3.4+ \ud83c\udf89\nThat means that all the new features of the latest GraphQL spec (June 2018) and draft (Oct 2) will be available once a new release is scheduled.\nhttps://github.com/graphql-python/graphql-core/tree/modern\nThere are few things left to do in order to be able to use it with Graphene:\n\n[ ] Add support for executors (probably refactor the way they are architected... as just a gather option is required)\n[ ] Add support for snake_case fields represented externally with GraphQL with camelCase naming\n[ ] Update all dependencies (http-framework integration, websockets integration) to use a new package graphql-backend for query execution (that abstracts the API of https://github.com/graphql-python/graphql-core/tree/master/graphql/backend in a new package)\n[ ] Add execute, execute_sync and subscribe methods to the GraphQLDocument\n. Hi @devArtoria, based on the current GraphQL spec, Union Types need to reference directly to NamedTypes or other Union Types:\nhttp://facebook.github.io/graphql/draft/#sec-Unions\n\nIn your case, I recommend to create a HumanResults type that returns the list of humans that you want to retrieve. Such as:\n```graphql\ntype HumanResults {\n  results: [Human]\n}\nunion SearchResult = HumanResults | Message\n```. Looks good to me. Feel free to merge once you re-review it @jkimbo @patrick91 . @jkimbo @patrick91 @danpalmer @ekampf @BossGrand @phil303. For those that are not in the Slack channel:\nWe are meeting in Yelp offices on March 6th at 11am PST.\nWe will do a Hangouts for those who can't attend in person:\nhttps://meet.google.com/zog-nfoj-rxx\nNote: we will probably start the meeting in Hangouts around 11:15am PST\nPlease let me know privately (me@syrusakbary.com) if you would like to attend to the meeting in person.. Yesterday we had the meeting.\nThe details are in the doc that @brianmcfeeley posted.\nhttps://docs.google.com/document/d/12-olPz5FHGx3w8kCkNX3FNhhx38abVR1VK-U2ehxHok\nAs a summary, here are the things that we talked:\n Companies & developers interested on moving Graphene / GraphQL Python ecosystem forward\n How to move Graphene forward (by using graphql-core-modern and/or graphql-core-next)\n Different repos in the ecosystem and people that would like to start governing / maintaining them\n How to handle communication between collaborators / maintainers (we will have all the communication in the Slack channel)\nIn general, we are going to add more maintainers into the repo so we can start reviewing and merging PRs without my explicit approval.\nIn general, if you contributed to the repos of @graphql-python and you would like to be added as maintainer to a specific repo please let us know and someone will add you.\nAlso, if you would like to start collaborating or knowing where Graphene is going next please join our Slack channel.\nPRs should be merged when a certain number of approvals is reached: 4 for Graphene, 3 for GraphQL-core, 5 or 4 for Graphene-Django, 2 for Graphene-SQLAlchemy...\nAlso, I'm going to be present and helping the transition. But the goals of where Graphene should go in next releases will start coming from the community, collaborators and governors of the ecosystem.. I just created a team of \"Governors\" for the Graphene / GraphQL-Python ecosystem.\nThey will be:\n @Cito \n @jkimbo \n @ProjectCheshire\n @BossGrand \n* @syrusakbary (myself)\nThey will have the rights for:\n Adding more maintainers into the repos\n Specify the amount of approvals needed for merging PRs in certain repos\n* Other rights to be able to administrate the repos\n. This syntax is not python valid :( (have to be key: value). Also, could be done using the container instead of a dict (User(user_id='1', ...)) and with the key as the user_id.\nSomething like:\npython\nUSER_DATA = {'1':User(user_id='1', ...), '2': ...}\n. convert_form_field_to_list perhaps?\n. convert_form_field_to_id\n. I'm more inclined to use order_by as I automatically think of it as a String (field to order), as opposed as using order that I think more as a Boolean (if we want to order the results: True or False).\n. @adamcharnock Why we have to convert the django field?\n. Here is where the Plugin inits\n. ^ Here is how to do the GraphQL query for see all the sql queries executed\n. For being in constance with the implementation of Interface, maybe the following will be better.\npython\nfrom functools import partial\n...\n            resolve_type=partial(cls._resolve_type, schema),\n. I will either have the iso8601 to be in graphql/core/pyutils/iso8601.py and import from there, or to require a generic version of iso8601 in setup.py (generic version == no version specified).\nThe reason for that is any other package could be already using an older or newer version of iso8601 and when installing graphene package it will trigger a incompatibility error as requires a specific version of it. (That's the reason Django includes a lot of third-party libraries in their own codebase).\n. We were using self._executor because the default used in graphql-core in versions previous to 0.5.0 was not using a OrderedDict by default.\nHowever this is no longer necessary, as now we can use the default chosen by graphql-core.\nJust doing return self._executor should work fine :)\n. @ekampf in Python 3 dict.values() returns an iterable that raises an error if the dict is changed in runtime. Casting to a list fix this problem.\nSee the related failed tests: https://travis-ci.org/graphql-python/graphene/builds/133549359\n. Agreed.\n. For consistency we should also check if map[type._meta.name].graphene_type == type :)\n. This will check the connection_type each time the field is resolved, however we can move this logic to connection_resolver so is just executed once :). We should keep this value. Is used to automatically upload the package to PyPI. ",
    "jhgg": "No problem! \n. Yes, that is the intended behavior. If you want the snake_cased name (which I don't recommend you do -- keep with convention and use camelCasing) you can simply pass name='work_order' to the Field constructor. \n``` python\n class Query(ObjectType):\n    work_order = Field(WorkOrder, id=graphene.Argument(graphene.String), name='work_order')\n@resolve_only_args\ndef resolve_work_order(self, id):\n    return WorkOrder(id='1', state='test')\n\n``\n. The schema is generally going to be consumed by a JavaScript application. Casing there is camel. Graphene will keep things in Python snake cased, but outwards facing graphQl schema will be camel cased which is generally the convention for JavaScript and grqphQL. \n.graphql-corealso supports py3.5 asyncio, graphene's resolve functions should also supportasync/await` in py35. \n``` python\nclass Human(Character):\n    pet = Field(Pet)\nasync def resolve_pet(self, *args):\n    pet = await queryPetFromSomewhereWithOwner(self.instance.id)\n    return Pet(pet)\n\n``\n. I have more testing to do with 40b88bc. I'll have an answer for you tomorrow. Was just super busy today.\n. I've added the get/set default executors ingraphql-core`. https://github.com/graphql-python/graphql-core/commit/ad228f0087968d6e5706f4f90cd3a40e9c7de736\n. Oop. It looks like you did this too!\n. Yup. That works. Thanks!\n. Mmmmmmmm. Good ideas. \n. I've created a repo here:\nhttps://github.com/graphql-python/graphql-django-view\nI'm going to start porting over the view code, fixing it up, writing tests, etc.... \n. Right. The code was just there to get things setup. I'm probably going to end up re-writing it tomorrow. It doesn't seem to work right with graphiql/relay, and isn't properly handling errors (i.e. syntax errors). \nBut I just wanted to have something there for now. \n. I've rewritten the GraphQLView in https://github.com/graphql-python/graphql-django-view/blob/master/graphql_django_view/init.py\nNeed to finish writing tests. \n. v1.0.0 has been released w/ stable API & 100% test coverage:\nhttps://pypi.python.org/pypi/graphql-django-view/\nhttps://github.com/graphql-python/graphql-django-view/releases/tag/v1.0.0\n. Also @syrusakbary I've added you as contributor & maintainer of pypi package.\n. PR #25 is open to replace the implementation of GraphQLView with graphql-django-view in an API backwards compatible way. ^^\n. Closed PR #25 in favor of #26 which will merge into 0.4.0 branch.\n. Fixed in 0.4.0\n. I think this change is superceded by #23 eventually @syrusakbary \n. Yeah. I will clean out tests. Just wanted to leave them there for now to prove that it would be a plug-in replacement.\n. I'll have to open a new PR to change branch to merge. \n. Hi @rapilabs,\nIssue here is that you are trying to use an ObjectType as an InputType. They are not compatible. This is a limitation with graphql in general, and not an issue with graphene. \nWhat you would have to do is define a Cell that is an InputObjectType.\nPerhaps:\npython\nclass CellInput(graphene.InputObjectType):\n    title = graphene.StringField()\n    item = graphene.StringField()\nYou can then use it:\n``` python\nclass NewCell(relay.ClientIDMutation):\n    class Input:\n        parent = graphene.IDField(required=True)\n        newCells = graphene.ListField(CellInput)\nparent = graphene.Field(Tree)\n\n``\n. This exists in [graphql-core](https://github.com/graphql-python/graphql-core) (which is the underlying graphql implementation thatgraphene` uses).\n``` python\nfrom graphql.core.utils.schema_printer import print_schema\nschema = YourGrapheneSchema()\nprint(print_schema(schema.schema))\n```\nPerhaps maybe a __str__ method could be added to graphene.core.Schema that would \"stringify\" the schema by calling print_schema? \n. Regarding graphene, I think that the execution context should be added to get_node. As a good practice, the execution context should be available in all resolvers for this very reason.\nRegarding graphql-core, in addition to root_value, I provide a request_context inside of ExecutionContext which can be set to any value you want to use. In graphql-django-view, I use it to store the current request object from Django. But given your use-case, perhaps it would make more sense to pass it a dict containing your session and auth objects.\nYou should be able to do this using graphene.core.Schema.execute() by passing request_context as a kwarg to that function.\nI.e. somewhere:\npython\nschema.execute(query, request_context={\n   'session': Session(),\n   'auth': get_auth()\n})\nIn a standard resolver, you would then access session by doing info.request_context['session']\npython\ndef resolve_ship(self, args, info):\n    session = info.request_context['session']\n    ship_id = args.get('id')\n    ship = session.query(Ship).filter_by(id=ship_id).one()\n    return Ship(ship)\n. This is going to be a breaking change... but I think should be made. 0.5.0 here we come lol.\n. :+1:\n. Hi @kiennt - As it turns out, graphene, graphql-core and graphql-epoxy in general doesn't have a preference for what kind of database backend you use. Although graphene does come with built in support for the introspection of Django models to generate a Schema, you could easily just manually define your Schema & Types to fit your NDB entity schema, and resolvers to query your database accordingly. \n. Make sure that you have the latest graphql-core installed. Subscriptions were introduced to graphql-core in v0.4.9\n. It's convention. Generally you would want to use camel case in javascript world. But graphene keeps things snake cased in Python. If you want to use snake cased fields though you can explicitly specify a name. \nSent from my iPhone\n\nOn Nov 22, 2015, at 9:00 PM, Josh Miller notifications@github.com wrote:\nI didn't find a forced conversion to camelCase in the spec. Did I miss it? Or is graphene just opinionated on style standards. Will there be any way to opt out of this in the future?\n\u2014\nReply to this email directly or view it on GitHub.\n. One cool thing would be to inspect field asts and generate the correct prefetch_related, select_related and only calls onto the queryset. I think syrus is working on something like this. \n\nSent from my iPhone\n\nOn Nov 23, 2015, at 11:12 AM, Adam Charnock notifications@github.com wrote:\nI've been thinking a bit about Django integration for Graphene. This is in part because I think it could be really useful, and in part because this is something I'd be interested in contributing a pull request for. However, development seems to be moving quickly so I thought it best to discuss these ideas first in case there are already plans.\nThe main motivation here is reducing boilerplate code. My intention would be to make all automatic functionality overridable & customisable.\nNodes:\nAutomatically traverse Django relations. A resolve_FIELD() may be specified to customise this traversal, but if not then traversal will be done using the relation's manager's all() method.\n Automatically support query args for all/specified model fields (reduces resolve_FIELD() boilerplate code).\nQuery:\nAutomatically resolve ConnectionFields which connect to DjangoNodes without the need for a resolve_FIELD() method.\n Support for pulling in schema definitions from individual Django apps, rather than being defined centrally. (I currently do this by using a top-level Query class which inherits from multiple app-specific Query classes)\nMutations:\nProvide a DjangoMutation which provides standard functionality though which to update Django models.\n Consider a class-based views approach, with CreateMutation, UpdateMutation, and DeleteMutation base classes.\nAll/any thoughts very welcome indeed!\n\u2014\nReply to this email directly or view it on GitHub.\n. Hi @amitsaha  - you are running into the no scalar leafs validation error.\n\nThis means your query is wrong.\n. Chances are you are calling:\nmutation { \n    updatePerson(id: 5, name: \"Hello\") {\n        person\n    }\n}\nYou should be calling:\nmutation { \n    updatePerson(id: 5, name: \"Hello\") {\n        person {\n            id\n            name\n        }\n    }\n}\n. ``` python\nfrom graphql.core.execution.base import collect_fields\nfields = collect_fields(info.context, info.parent_type, info.field_asts[0], {}, set())\n```\n. Weird. Can you post you code somewhere. I'll mess with it when I've got some time! \nSent from my iPhone\n\nOn Nov 30, 2015, at 9:50 AM, Markus Padourek notifications@github.com wrote:\n@jhgg if I change your code example to:\nfields = collections.defaultdict(list) #can not just be dict because of 'id' from relay\nfields = collect_fields(info.context, info.parent_type, info.field_asts[0].selection_set, fields, set())\nI am getting to print all the field names in the 'collect_fields' function, but it just returns before it has traversed the whole ast. So the actual retyurn of fields is just defaultdict(, {u'id': [Field(alias=None, name=Name(value=u'id'), arguments=[], directives=[], selection_set=None)]})\n\u2014\nReply to this email directly or view it on GitHub.\n. Open a PR and I'll review it today! \n. This is already supported in core. Just pass a deprecation_reason to the underlying GraphQLField. \nThere is no is_deprecated as a non-null value for deprecation_reason implies is_deprecated for the purpose of schema introspection.\n. Typo. Should be User I think.\n. \n",
    "llevar": "This should be automatically exposed by Graphene as a query that returns the file.. I have Graphene + SQLAlchemy + Postgres + Flask on server and React + Relay on front end. There's a well defined business layer on the server and my ideal scenario would be to add some decorators to generate a GraphQL endpoint that can handle CRUD operations on those objects, delegating to SQLAlchemy for ORM. Now I had to define all of these classes by hand, even though they are completely vanilla - \"fetch object by id\", \"fetch all objects\", \"create new object\", \"update object by id\".. \n@ekampf Why do you think this needs to be tied to sqlalchemy? If I have a set of Python objects that have a basic CRUD lifecycle I would want to be able to serve them up via GraphQL by writing minimal additional code, whatever they are backed up (if anything). I don't think a dependency on SQL Alchemy is necessary at that point since the interaction between Graphene and these objects should be via their lifecycle (create_blah(), update_blah(), etc.) methods.. That's kind of my point, presuming you have a business layer that defines lifecycle methods for your objects you ought to be able to annotate these and have graphene auto-generate an endpoint that serves these up without peering into the data access layer.. ",
    "ashinohara": "Great, thanks.  I am more concerned with the fields when defining the schema actually, where name seems to work as well:\nclass WorkOrder(Node):\n    id = IDField()\n    state = StringField()\n    nodes = ListField(WorkOrderNode)\n    req_uid = StringField(name='req_uid')\nSince we are defining the schema in python it is nice to make it more pythonic.  Why don't you recommend using snake case?\n. Thanks for the clarification!\n. ",
    "mbetz08": "Thanks @syrusakbary!  :raised_hands:\n. ",
    "Globegitter": "Sorry to keep on piling here, but seems I am running into this issue: https://github.com/facebook/relay/issues/112\n. @syrusakbary the example is great thanks, but how can I query the viewer now? I can't find any tests or examples about it.\nE.g.\nquery{viewer{...__RelayQueryFragment0u3d70s}}fragment __RelayQueryFragment0u3d70s on allFilms{...}\njust thorws me an error [GraphQLError('Unknown type \"allFilms\".',)]\nI tried a few other queries as well but all not working so far. Will carry on playing around with it but an example would be much appreciated. Thanks!\nEdit: Think I might have gotten it to work :)\n. Sorry, after a quick sprint yesterday I had to put our relay advancements on hold for the time. For now I am just using a connectionfield as a workaround. Will put up an example as soon as I get time the next few days. \n. Just looking into this again now (and carrying on implementing relay/graphql into our codebase) @syrusakbary so should have an update soon.\n. Just tried more, and so far I am not getting around the error [GraphQLError('Incorrect padding',)]\nExample:\n``` py\nschema = graphene.Schema()\nclass Tester(relay.Node):\n    name = graphene.StringField()\n@classmethod\ndef get_node(cls, id):\n    print('stuff')\n    return Tester(name='mo')\n\nclass Query(graphene.ObjectType):\n    tester = relay.NodeField(Tester)\nschema.query = Query\nquery = '''\n  query RebelsShipsQuery {\n    tester(id:\"mo\") {\n      name\n    }\n  }\n'''\nresults = schema.execute(query)\nprint(results.errors)\nprint(results.data)\n```\nI am on python 2.7 btw\n. Looking forward to seeing this land :)\n. Ahh, managed to get it to work using e.g. full_name = graphene.StringField(args={'to': graphene.Argument(graphene.String)})\n. user_id is a field in the User Object. The reason we use separate id and ..._id in our apps is so we can display our actual IDs. But happy to completely remove it and write as you suggested.\nOtherwise addressed your comments :)\n. Sorry about that - my head was clearly on kwargs.\n. @ptz0n Yeah was working for me, but rather than copy&pasting the fixes I just typed them. And well seemed to have been a bit blind. Anyway should be good now.\n. Did just that @ptz0n :)\n. Thank you for that @syrusakbary!\n. A more complete example btw (just picked out the relevant pieces):\n``` py\nclass Address(relay.Node):\n    address_id = graphene.ID()\n    postal_line = graphene.String()\n@classmethod\ndef get_node(cls, address_id):\n    return Address(address_id=address_id, postal_line='3 March Avenue')\n\nclass AddressTypeEdge(relay.Edge):\n        address_type = graphene.String()\nclass AddressType(relay.Connection):\n    edges = graphene.List(graphene.LazyType(AddressTypeEdge))\nclass User(relay.Node):\n    user_id = graphene.ID()\n    addresses = relay.ConnectionField(Address, connection_type=AddressType,\n    edge_type=AddressTypeEdge)\n@classmethod\ndef get_node(cls, user_id):\n    user = {'user_id': '1'}\n    return User(**user)\n\ndef resolve_addresses(self, args, info):\n        # Edit 23/11/2015\n        # return AddressType(edges=[AddressTypeEdge(address_type='1', node=Address(postal_line='blaa'))])\n        return [AddressTypeEdge(address_type='1', node=Address(address_id='1', postal_line='UK'))]\n\nnode_type = 'User'\nuser_id = '1'\nrelay_global_id = base64(':'.join([node_type, str(user_id)]))\nquery = '''\n            query testQuery {\n                user(id: \"%s\") {\n                    userId,\n                    addresses {\n                        edges {\n                            addressType\n                            node {\n                                postalLine\n                            }\n                        }\n                    }\n                }\n            }\n        ''' % relay_global_id\nresult = schema.execute(query)\n```\nOn 0.4.0.1 that results into [GraphQLError(\"'node' is an invalid keyword argument for this function\",)]\n. Also when I have \nclass AddressType(relay.Connection):\n    edges = graphene.List(AddressTypeEdge)\nI seem to be getting the same error/behaviour. The thing that I specifically want is to have extra fields on the AddressTypeEdge (and from what I can tell from the relay specs that should be supported). It might be address_type but could be a bunch of others as well.\nSo the expected output that I would like to get is something like that (converted to json):\n{\"customer\": {\"customerId\": \"1\", \"fullName\": \"Paul Kalk\", \"addresses\": {\"edges\": [{\"addressType\": 'has some value', \"node\": {\"street\": \"UK\"}}]}}}\nWhere-as right now I only manage to get:\n{\"customer\": {\"customerId\": \"1\", \"fullName\": \"Paul Kalk\", \"addresses\": {\"edges\": [{\"addressType\": null, \"node\": {\"street\": \"UK\"}}]}}} , or some error as mentioned above.\n. Will give it a try, thank you!\n. @syrusakbary Just tested it and now getting [GraphQLError(\"'node' is an invalid keyword argument for this function\",)] (having the same code as above). Could this be related to the change a few days ago: https://github.com/graphql-python/graphene/commit/266dd5efe089e92d235802166471b1fbbf7f58d6#diff-5483f154953c0d23d7680373eec49d90L30\n. Also from what I can tell you would have to manually implement pageInfo and cursor the current way, right?\nBeen playing around with the source code for a bit and still not been able to fully get it to work.\n. Yes, the code is pretty much the same as above (only modified the resolve_addresses function and now actually added a Query class):\n``` py\nclass Address(relay.Node):\n    address_id = graphene.ID()\n    postal_line = graphene.String()\n@classmethod\ndef get_node(cls, address_id):\n    return Address(address_id=address_id, postal_line='3 March Avenue')\n\nclass AddressTypeEdge(relay.Edge):\n        address_type = graphene.String()\nclass AddressType(relay.Connection):\n    edges = graphene.List(graphene.LazyType(AddressTypeEdge))\nclass User(relay.Node):\n    user_id = graphene.ID()\n    addresses = relay.ConnectionField(Address, connection_type=AddressType,\n    edge_type=AddressTypeEdge)\n@classmethod\ndef get_node(cls, user_id):\n    user = {'user_id': '1'}\n    return User(**user)\n\ndef resolve_addresses(self, args, info):\n        return AddressType(edges=[AddressTypeEdge(address_type='some text', node=Address(postal_line='blaa'))])\n\nclass Query(graphene.ObjectType):\n    user = relay.NodeField(User)\nnode_type = 'User'\nuser_id = '1'\nrelay_global_id = base64(':'.join([node_type, str(user_id)]))\nquery = '''\n            query testQuery {\n                user(id: \"%s\") {\n                    userId,\n                    addresses {\n                        edges {\n                            addressType\n                            node {\n                                postalLine\n                            }\n                        }\n                    }\n                }\n            }\n        ''' % relay_global_id\nresult = schema.execute(query)\nprint(result.errors)\nprint(result.data)\n``\n. @syrusakbary Have you had the chance to look into this some more again?\n. @syrusakbary here is the example on the new playground: http://graphene-python.org/playground/?schema=import%2520collections%250A%250Aimport%2520graphene%250Afrom%2520graphene%2520import%2520relay%250A%250Aclass%2520Address(relay.Node)%253A%250A%2520%2520%2520%2520address_id%2520%253D%2520graphene.ID()%250A%2520%2520%2520%2520postal_line%2520%253D%2520graphene.String()%250A%250A%2520%2520%2520%2520%2540classmethod%250A%2520%2520%2520%2520def%2520get_node(cls%252C%2520address_id)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520Address(address_id%253Daddress_id%252C%2520postal_line%253D%273%2520March%2520Avenue%27)%250A%250Aclass%2520AddressTypeEdge(relay.Edge)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520address_type%2520%253D%2520graphene.String()%250A%250Aclass%2520AddressType(relay.Connection)%253A%250A%2520%2520%2520%2520edges%2520%253D%2520graphene.List(graphene.LazyType(AddressTypeEdge))%250A%250Aclass%2520User(relay.Node)%253A%250A%2520%2520%2520%2520user_id%2520%253D%2520graphene.ID()%250A%2520%2520%2520%2520addresses%2520%253D%2520relay.ConnectionField(Address%252C%2520connection_type%253DAddressType%252C%250A%2520%2520%2520%2520edge_type%253DAddressTypeEdge)%250A%250A%2520%2520%2520%2520%2540classmethod%250A%2520%2520%2520%2520def%2520get_node(cls%252C%2520user_id)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520user%2520%253D%2520%257B%27user_id%27%253A%2520%271%27%257D%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520User(**user)%250A%250A%2520%2520%2520%2520def%2520resolve_addresses(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520return%2520AddressType(edges%253D%255BAddressTypeEdge(address_type%253D%27some%2520text%27%252C%2520node%253DAddress(postal_line%253D%27blaa%27))%255D)%250A%250Aclass%2520Query(graphene.ObjectType)%253A%250A%2520%2520%2520%2520user%2520%253D%2520graphene.Field(User)%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520def%2520resolve_user(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520user%2520%253D%2520%257B%27user_id%27%253A%2520%271%27%257D%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520User(**user)%250A%250Aschema%2520%253D%2520graphene.Schema(query%253DQuery)%250A&query=query%2520testQuery%2520%257B%250A%2520%2520user%2520%257B%250A%2520%2520%2520%2520userId%252C%250A%2520%2520%2520%2520addresses%2520%257B%250A%2520%2520%2520%2520%2520%2520edges%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520addressType%250A%2520%2520%2520%2520%2520%2520%2520%2520node%2520%257B%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520postalLine%250A%2520%2520%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%2520%2520%257D%250A%2520%2520%2520%2520%257D%250A%2520%2520%257D%250A%257D\n. Ah sorry, I only updatedgrapheneand forgot to updategraphql-core`.\n. ahhh great, thanks @jhgg, will give that a try!\n. @jhgg if I change your code example to:\nfields = collections.defaultdict(list) #can not just be dict because of 'id' from relay\nfields = collect_fields(info.context, info.parent_type, info.field_asts[0].selection_set, fields, set())\nI am getting to print all the field names in the 'collect_fields' function, but it just returns before it has traversed the whole ast. So the actual retyurn of fields is just defaultdict(<type 'list'>, {u'id': [Field(alias=None, name=Name(value=u'id'), arguments=[], directives=[], selection_set=None)]})\n. Yep will do as soon as possible.\n. Here we go @jhgg http://graphene-python.org/playground/?schema=import%2520collections%250A%250Aimport%2520graphene%250Afrom%2520graphene%2520import%2520relay%250Afrom%2520graphql.core.execution.base%2520import%2520collect_fields%250A%250Aclass%2520Customer(relay.Node)%253A%250A%2520%2520%2520%2520first_name%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520middle_name%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520last_name%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520expensive_field%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520%2540classmethod%250A%2520%2520%2520%2520def%2520get_node(cls%252C%2520customer_id%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520Customer()%250A%2520%2520%2520%2520%2520%2520%2520%2520%250Aclass%2520Query(graphene.ObjectType)%253A%250A%2520%2520%2520%2520hello%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520ping%2520%253D%2520graphene.String(to%253Dgraphene.String())%250A%2520%2520%2520%2520customer%2520%253D%2520graphene.Field(Customer)%250A%250A%2520%2520%2520%2520def%2520resolve_hello(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27World%27%250A%250A%2520%2520%2520%2520def%2520resolve_ping(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27Pinging%2520%257B%257D%27.format(args.get(%27to%27))%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520def%2520resolve_customer(self%252C%2520_%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520fields%2520%253D%2520collections.defaultdict(list)%250A%2520%2520%2520%2520%2520%2520%2520%2520fields%2520%253D%2520collect_fields(info.context%252C%2520info.parent_type%252C%2520info.field_asts%255B0%255D.selection_set%252C%2520fields%252C%2520set())%250A%2520%2520%2520%2520%2520%2520%2520%2520print(fields)%250A%2520%2520%2520%2520%2520%2520%2520%2520%2523%2520only%2520calculate%2520expensive_field%2520here%2520if%2520it%2520is%2520in%2520fields%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520Customer(id%253D%271%27%252C%2520first_name%253D%27Test%27%252C%2520last_name%253D%27customer%27)%250A%250Aschema%2520%253D%2520graphene.Schema(query%253DQuery)%250A&query=query%2520GetCustomer%257B%250A%2520%2520customer%257B%250A%2520%2520%2520%2520id%252C...__RelayQueryFragment0wau8gf%250A%2520%2520%257D%250A%257D%2520%250Afragment%2520__RelayQueryFragment0wau8gf%2520on%2520Customer%257B%250A%2520%2520firstName%250A%2520%2520lastName%250A%257D\nThat should be pretty similar to what I am currently working with\n. @syrusakbary yeah thanks for the docs, they are great! And the playground also works well, especially knowing the prints are showing in the console.\n. Thanks for that work @mixxorz Also it seems that graphql itself might get that feature anyway. See: https://github.com/graphql/graphql-js/pull/304\nLooks pretty great :)\n. I have also tried\npy\nclass Input(object):\n            __metaclass__ = TestCustomer\n...\nbased on the example linked above, but then getting:\nFile \"third_party/python/graphene/core/classtypes/objecttype.py\", line 60, in __init__\n    raise IndexError(\"Number of args exceeds number of fields\")\nIndexError: Number of args exceeds number of fields\nIf I remove the check if args_len > len(fields): in the objecttype.py the code at least compiles. Still have to test what happens then, will try tomorrow.\n. Outside of work already unfortunately. Will post tomorrow. \n. @syrusakbary here is the example:\n``` py\nimport graphene\nfrom graphene import relay\nclass SharedUserFields(graphene.ObjectType):\n    first_name = graphene.String()\n    last_name = graphene.String()\nclass User(relay.Node):\n    user_id = graphene.ID()\n@classmethod\ndef get_node(cls, user_id):\n    user = {'user_id': '1'}\n    return User(**user)\n\nUser.extend_fields([SharedUserFields])\nclass UpdateCustomer(relay.ClientIDMutation):\n    class Input(SharedUserFields):\n        pass\nuser = graphene.Field(User)\n\ndef mutate_and_get_payload(cls, mutation_input, info):\n    # update stuff here\n    return(User(first_name='Mutated first_name'))\n\nclass Query(graphene.ObjectType):\n    user = graphene.Field(User)\ndef resolve_user(self, args, info):\n    user = {'user_id': '1'}\n    return User(**user)\n\nschema = graphene.Schema(query=Query)\n```\nThanks for looking into this so quickly.\nEdit: If I add it as a metaclass to the Input class as in the example above and I comment out the if check I am getting the following error on a mutation: GraphQLError: Variable \"$input_0\" expected value of type \"UpdateCustomerInput!\" but got: {\"firstName\": \"Pete\"}.\n. @syrusakbary any update on this?\nI am just running into this again. Refactoring our queries and mutations and again have to copy and paste the shared fields between the two. \nI also tried to use graphene.Interface but also does not seem to work.\n. @syrusakbary I would also be happy to look into this myself. Do you have any starting pointers? Would love to give something back to this library, this issue just seems to be quite deeply rooted :)\n. @dwiel \nThat does of course depend on the actual use-case, but one way is to just group them together into an ObjectType and then you can have something as follows:\nhttp://graphene-python.org/playground/?schema=import%2520graphene%250A%250Aclass%2520HelloPing(graphene.ObjectType)%253A%250A%2520%2520%2520%2520hello%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520ping%2520%253D%2520graphene.String()%250A%250Aclass%2520Query(graphene.ObjectType)%253A%250A%2520%2520%2520%2520hello%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520ping%2520%253D%2520graphene.String(to%253Dgraphene.String())%250A%2520%2520%2520%2520hello_ping%2520%253D%2520graphene.Field(HelloPing%252C%2520to%253Dgraphene.String())%250A%250A%2520%2520%2520%2520def%2520resolve_hello(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27World%2520%257B%257D%27.format(id(self))%250A%250A%2520%2520%2520%2520def%2520resolve_ping(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520h%2520%253D%2520self.resolve_hello(args%252C%2520info)%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27Pinging%2520%257B%257D%2520%253A%2520%257B%257D%27.format(args.get(%27to%27)%252C%2520h)%250A%2520%2520%2520%2520%250A%2520%2520%2520%2520def%2520resolve_hello_ping(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520h%2520%253D%2520%27World%2520%257B%257D%27.format(id(self))%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520HelloPing(ping%253D%27Pinging%2520%257B%257D%2520%253A%2520%257B%257D%27.format(args.get(%27to%27)%252C%2520h)%252C%250A%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520%2520hello%253Dh)%250A%250Aschema%2520%253D%2520graphene.Schema(query%253DQuery)%250A&query=query%2520%257B%250A%2520%2520hello%250A%2520%2520ping(to%253A%2522Peter%2522)%250A%2520%2520helloPing(to%253A%2522Peter%2522)%2520%257B%250A%2520%2520%2520%2520hello%250A%2520%2520%2520%2520ping%250A%2520%2520%257D%250A%257D%250A\n. @gwind We are using graphene + relay in our app that we'll release in closed beta by beginning of march.\n. Ok will have a look - thanks for the quick response :)\n. @syrusakbary Thank you for the quick turnaround :)\n. Should be update now :)\n. @syrusakbary After talking to one of my colleauges, we are apparently doing something ourselves to ensure we have enums available (also using the package enum34), so my guess it is related to that and some issue with the way we are using that and the way graphene is ensuring that enums exist.\nTrying to us it as follows now:\n``` py\nclass Episode(graphene.Enum):\n    NEWHOPE = 4\n    EMPIRE = 5\n    JEDI = 6\nclass Some(graphene.ObjectType):\n    episode = graphene.Field(Episode)\n...\n```\nI will look into it again tomorrow to identify if there is something that we can do, to resolve that issue or if it would require more.\n. Ok it was an error purely on our side - sorry for unnecessarily opening this issue.\n. @defrex \nI think if you try:\npy\nclass Summary(graphene.ObjectType):\n    income = graphene.Field(Money)\n    allocated = graphene.Field(Money)\n    spent = graphene.Field(Money)\n    net = graphene.Field(Money)\nit should work.\n. @sgtsquiggs That is the difference between a graphene.List and a graphene.ConnectionField. A ConnectionField is basically a list on steroids with information about pagination. See here for some more info on it: https://facebook.github.io/relay/docs/graphql-connections.html#content\n. Or looking at Graphql-core another syntax option could be\npy\nclass Post(graphene.ObjectType):\n    fields = lambda: dict(\n        category = graphene.Field(Category)\n    )\nBut of course that would mean that graphene would either have to break backwards-compatibility to a quite substantial degree, or support two different syntaxes.\n. Yeah also on the relay repo they seem to suggest to customize the error response: https://github.com/facebook/relay/issues/777#issuecomment-184321489\nOnce we can add custom errors it would also be important to be able to add multiple custom error for one mutation. So if you have form input validation that you can return all field errors at once. With the current method raise Exception('field a is invalid') you can not really have more than one error per mutation.\n. @defrex now with graphene 0.10 you have access to the original_error so you can already customize the error response any way you want.\nwe have something like:\npy\nresult = schema.execute(query)\nif result.errors:\n  # check for result.errors[...].original_error and build your own json\n  # send custom json response (that still follows the graphql format) to the frontend.\n. @syrusakbary We used it for zipkin tracing, i.e. to get an accurate time profile of each resolve function. This has been quite useful to track down performance bottlenecks.\n. @syrusakbary man that was fast! Thanks :D\n. @syrusakbary Haven't gotten around to it just yet. Been working on improving error-handling and Promise support first :) It is on my list for this week though, so will let you know once I got to it.\n. @syrusakbary is it possible to maybe have this as an option? We use the context all over the place and it would be quite a pain to have to add the with_context decorator to 90% of our resolve function. Also why then not just write resolve_bla(self, _, __) if you don't need the arguments. Or resolve_bla(self, *_) or resolve_bla(self, **_) depending on if they are being passed in as positional or keyword args. \nEspecially the * versions seems to me simpler than having to remember and import different decorators depending on what you need. I hope that decision is not fully set in stone yet.\n. @syrusakbary yeah that is a quite difficult one. I mean the only other solution I could think of then is dict(args=args, context=context, info=info) to not have potential name conflict. I personally would prefer that all to the decorator.\n. @syrusakbary Having thought about it a bit more I am leaning mostly towards the inspect.getargspec(resolver_func).args approach suggested by @ekampf. That would make it really straightforward and simple to use.\nAlso if the arguments passed in would ever change again it that approach would imo make it a bit simpler.\nThat all said though, I do think your suggested approach also works.\n. @syrusakbary just fallen into this while upgrading. Any chance to bump the version number?\n. Thanks for fixing up the last issues. Was going to do it today but you beat me to it :) \n. Also happy to add tests if that is something you feel makes sense to merge in :)\n. Ok, abandoning that for now after disscussion at: https://github.com/facebook/relay/issues/1201\nMight pick up this PR again at a later point if it turns out to be useful for us or anyone else.\n. Yeah, I suppose the metaclass could have an additional field connection_type_name or something.\n. @mjtamlyn what then if the core ObjectType is being used in different ConnectionFields? Maybe it should be an option on the ConnectionField itself?\n. @mjtamlyn yeah I like the idea, though I do think it should be optional as pretty much anywhere in graphene the class-name is coupled to the typename per default.\n. Not sure why the test is failing. Will investigate tomorrow.\n. Actually on top of that it would also be nice to be able to not pass in the count, but instead hasNextPage or hasPreviousPage. Just starting to write our pagination and some of our service will return these values directly. Just a note for myself. \n. Also this is a good article on pagination with relay: https://m.alphasights.com/how-to-do-effortless-pagination-with-relay-connections-and-graphql-ruby-a534ffaf5cbf#.qm18yr7gm\n. We have now actually resorted to create the connection and edges ourselves like so:\n```\ndef _create_statement_edge(statement):\n    edge_type = relay.Edge.for_node(StatementEntry)\n    return edge_type(node=statement, cursor=base64.b64encode(str(statement.id)))\n...\ndef resolve_bla(...):\n    pagination_param = base64.b64decode(args['after']) if args.get('after') else None\nstatements, has_next_page  = call_to_database_service(pagination_param)\n\nedges = [_create_statement_edge(statement) for statement in statements]\nconnection_type = relay.Connection.for_node(StatementEntry)\n\nreturn connection_type(edges=edges, page_info=relay.PageInfo(has_next_page=has_next_page))\n\n```\nThere is a bug though with returning connection_type in this way, which I fixed here: https://github.com/graphql-python/graphene/pull/237\n. @yfilali That has changed with the 1.0 release and thanks for the answer, will give that a try once we managed to upgrade.\n. This is probably the same as https://github.com/graphql-python/graphene/issues/198\n. I think you have to instantiate it as graphene.Field(Inner()). And your types are also registered in the schema?\n. Yep @nickhudkins, @syrusakbary has been pretty good so far with merging PRs and responding to issues as we have come across a few bugs while using graphene. So I think contributing to this repository rather than keeping a fork would be better for the community :)\nAnd love the plan of putting Django and SQLAlchemy into a separate repository. Will make contributing certainly simpler.\nIs there still much missing for 1.0 @syrusakbary? Happy to give it a spin in our app, or making PRs towards that if so. Happy to try and help to get it out of the door a bit earlier :)\n. @erydo https://github.com/graphql-python/graphene/pull/237 should fix this :)\n. Not sure why the build fails on py 3.5 but it seems unrelated to my changes.\n. @syrusakbary Any word on this PR? Is that something you could see getting merged in? Would allow to clean up our source code a bit.\n. Also as a note, we are using this patch already locally in our graphene. So really hope this functionality makes it in. Even if it is in a different way with 1.0.\nI am also happy btw to make these last PRs agains the 1.0 branch if you want @syrusakbary \n. I know my last commit is not directly related but since I am already touching the code I thought I'd fix that here as well. This is something we notice when trying to return a Connection directly instead of a list, that it actually does not work with the given isinstance check.\n. @syrusakbary Added tests for both fixes in here :)\n. I only added the tests to relay right now as this is what we are using, but happy to add them to standard graphql as well if accepted.\n. Ahh, I have just found the AbstractType. Great addition! the only thing I am noticing is that the subclass does not inherit the interface that the abstract type implements. Would be nice to get that feature as well.\n. @syrusakbary we have a use case though where AbstractType is perfect but we also need to be able to guarantee that the separate ObectTypes inheriting from this AbstractType implement the same Interface. This PR enables this use-case. I can see though why you might not want that. Would there be a possibility to add a more specific AbstractObjectType to allow for our specific use case? Or otherwise the AbstractType could only pass on the Interface specification to ObjectTypes but nothing else. Or any other ideaa to allow for this?\n. @syrusakbary Is there any support for this in 1.0, or what was the conclusion you came to? This is still something quite important to us.\n. @syrusakbary Thanks, will add a new PR soon :)\n. Not sure why the tests are failing. Are working locally for me.\n. This is being fixed in https://github.com/graphql-python/graphene/pull/288.\n. @benjaminjkraft why not just define them as free form function and use them like name = graphene.String(resolver=resolve_name)\n. Also added GlobalID to be exported.\n. Sorry btw, for this overlap in functionality change in this PR. But it is still a small diff so should hopefully be fine. But let me know if you want me to split this out in 2 PRs.\n. In some cases, e.g. a RANGE_DELETE or NODE_DELETE relay expects the global id of a thing to be sent back directly (as a string or a list of strings) rather than nested (see https://facebook.github.io/relay/docs/guides-mutations.html#range-delete). And I have always found it would be nice if we could specify that in the schema rather than how we do it currently: specifying graphene.ID() and then using to_global_id(NodeType._meta.typename, 'local_id').\n. @syrusakbary what do you think of this given that relay sometimes expects a global id/global ids to be returned directly?\n. @syrusakbary just started upgrading our codebase to 1.0 again and the fact that relay.GlobalID() needs a node parameter is starting to clutter up our codebase. What is blocking this PR from getting merged in?\n. Just stumbling over more things again. To describe our use-case further, whenever we have an objecttype that implements relay.Node we re-define relay.GlobalID() directly on that type because we need to add some metadata specific to our system (the annotation function mentioned above).\nSo whenver we have an objectType we would have:\n```\nclass SomeClass(graphene.ObjectType):\nclass Meta:\n    interfaces = (relay.Node, )\n\nid = annotation_function(relay.GlobalID(relay.Node, required=True), 'some_metadata')\n\n```\nBut the syntax around GlobalID in 0.x seemed much cleaner to me and it would just be:\n```\nclass SomeClass(graphene.ObjectType):\nclass Meta:\n    interfaces = (relay.Node, )\n\nid = annotation_function(relay.GlobalID(), 'some_metadata')\n\n```\nThe above syntax would still be valid, just that it now has imo more sensible defaults.\n. I'll have a bit of a think about it but I like the sound of the first solution :)\n. New PR: https://github.com/graphql-python/graphene/pull/298\n. Ok, I am also seeing that fastcache has some issues running on pypy. I could investigate that or switching to a thread-safe memoize, but I am leaning more and more towards ConnectionField only taking a Connection and putting the responsibility to the user rather than the framework trying to be a bit too clever.\n. I now implemented what I proposed - removing the 'magic' auto generation of Connections in favour of declarative genaration of Connections, which should remove any issues of caching as well as tying any Connections to a Node but also allowing ObjectTypes to be used for Connections as specified in the Relay spec.\n. Can be closed in favour of #347\n. Not sure why pypy is failing with:\nImportError while importing test module '/home/travis/build/graphql-python/graphene/graphene/types/tests/test_objecttype.py'.\nOriginal error message:\n'No module named mock'\nMake sure your test modules/packages have valid Python names.\nAny ideas?\n. Oh yes, good point did completely not think about this.\n. Hey Syrus,\nThank you for getting back with such a detailed answer. Yes, my PR is certainly not perfect, it was partially also me just getting to know that area of the code and if I would make another PR I would probably do it differently. \nAnd yes, I think it is very good that you are asking these questions and before anything is rewritten we should answer them.\n- Having some connection resolution on the type could make sense. Was there anything you had in mind already?\n- There more I think about it, the more I am against the 'automatic' connection type creation. It is really cool to start off with, but for a slightly bigger sized team, where you might have other people come on/off it has been less maintainable in my experience. You have to explain people that this does not return the type itself, but something wrapped around it etc. And imo while it does make code writing easier it makes its maintenance more difficult (because of the magic one has to be aware of). I think just making it easy to create and return connection types would be the best of both worlds: You have to write a bit more but there is no magic going on and one can understand everything just from reading the app code.\n- If we don't have the 'automatic' creation anymore it should be easier to have different connections for the same type: The user is always explicitly creating a connection so if subclassing from Connection then creating giving it whatever name they want. If we would have something like DefaultConnection.for_type(Type) then you could only create that once per schema.\nLet me know what you think. I would be happy btw to create a fresh PR based on the ideas we come up with here.\n. @morgante While I agree this should work, one thing you could do in the meantime is using the AbstractType as shown here: https://github.com/graphql-python/graphene/blob/master/graphene/relay/tests/test_mutation.py#L36\n. Well, I guess my rationale behind this is: We are doing a magic conversion of an unmounted type to a field. So we might as well magically copy all attributes from the unmounted type. But maybe there is a better/easier way of doing this.\nBut I can also understand that decision and I am sure for this we can find a solution on application level.\n. Replaced with #332 \n. Ok, it was not quite as simple as I initially thought but was not that much more effort. I did it now in the slightly more backwards-compatible way. Let me know what you think about this approach @syrusakbary \n. Also just starting to test this patch out in our app and it does resolve our issue, while being imo far less intrusive to graphene itself.\n. Yes we could do something like you proposed (though I am not sure if this exact snippet would work) but I am quite reluctant to that as the change between 0.x and 1.0 was an undocumented quite significant behavioural change and more importantly it would mean all of our apps would have to use our own scalars rather than the default ones. Even though most of it could be done automatically that would require a huge code change (the number of scalar fields we have probably ranges in the 1000s for our codebase) and further it would require us to ensure that this custom code still works in the future, etc.\nWhat is the issue with having get_type as an instance method on Scalar?  It is in an instance method on unmountedtype so even seems to me more consistent for all subclasses to be an instance method as well.\n. @syrusakbary That doesn't work unfortunately either. I have thought about that a bit more and would you be open to introducing some kind of metadata concept that we can store on the field definition? It would not be to difficult to implement and you would simply have a set_metadata method that would set a _metadata attribute and then we can just make sure to carry around this _metadata attribute. This would then actually make it a feature other people could use as well.\nTo give an example I could have:\n``` py\ndef set_metadata(gql_type, value):\n    gql_type.set_metadata(value)\n    return gql_type\nclass MyObjectType(graphene.ObjectType):\n    my_string = set_metadata(graphene.String(), 'some_value')\n    mg_string = set_metadata(graphene.Field(MyScalar), 'some_other_value')\n```\nand internally we would have:\n``` py\nclass UnmountedType(OrderedType):\n    '''\n    This class acts a proxy for a Graphene Type, so it can be mounted\n    dynamically as Field, InputField or Argument.\nInstead of writing\n>>> class MyObjectType(ObjectType):\n>>>     my_field = Field(String(), description='Description here')\n\nIt let you write\n>>> class MyObjectType(ObjectType):\n>>>     my_field = String(description='Description here')\n'''\n\ndef __init__(self, *args, **kwargs):\n    super(UnmountedType, self).__init__()\n    self.args = args\n    self.kwargs = kwargs\n    self._metadata = None\n\ndef get_type(self):\n    raise NotImplementedError(\"get_type not implemented in {}\".format(self))\n\ndef set_metadata(value)\n    self._metadata = value\n\ndef Field(self):  # noqa: N802\n    '''\n    Mount the UnmountedType as Field\n    '''\n    from .field import Field\n    f = Field(\n        self.get_type(),\n        *self.args,\n        _creation_counter=self.creation_counter,\n        **self.kwargs\n    )\n    f.set_metadata(self._metadata)\n    return f\n\ndef InputField(self):  # noqa: N802\n    '''\n    Mount the UnmountedType as InputField\n    '''\n    from .inputfield import InputField\n    f = InputField(\n        self.get_type(),\n        *self.args,\n        _creation_counter=self.creation_counter,\n        **self.kwargs\n    )\n    f.set_metadata(self._metadata)\n    return f\n\ndef Argument(self):  # noqa: N802\n    '''\n    Mount the UnmountedType as Argument\n    '''\n    from .argument import Argument\n    a = Argument(\n        self.get_type(),\n        *self.args,\n        _creation_counter=self.creation_counter,\n        **self.kwargs\n    )\n    a.set_metadata(self_metadata)\n    return a\n\n```\nAnd Argument, Field and InputField would of course implement these methods accordingly. We could even allow it being set at instantiation to keep it a one-liner. What do you think? Imo a worthy feature to add and will keep everything else exactly as it currently is.\n. Or after having thought about it longer, we could even make it 'less intrusive' and not have this set_metadata interface and just allow for  _metadata to be passed in at instantiation (similar to _creation_counter) or otherwise we could set it directly gql_type._metadata = 'dfs' and that just gets on passed through e.g.\ndef Field(self):  # noqa: N802\n        '''\n        Mount the UnmountedType as Field\n        '''\n        from .field import Field\n        return Field(\n            self.get_type(),\n            *self.args,\n            _creation_counter=self.creation_counter,\n            _metadata=self._metadata,\n            **self.kwargs\n        )\nThis is imo less pythonic but as I said would make it less intrusive.\n. Liking the direction this is heading so far :)\n. @syrusakbary ha - you where a tiny step ahead of me. Just pushed the tests :)\n. Good catch @bigblind - that would be great to have in graphene core/ResolveInfo\n. This is the only line of this PR that I am not sure about. Since get_type() now returns self, this equality check ends up being infinitely recursive. But as far as I can tell all we want to compare is their graphql type information so that should be self.get_type()._meta == other.get_type()._meta.\n. I wasn't a 100% sure though if equality on the meta class like that just works of if we would need to compare the props directly on the meta class.\n. The only minor problem I have with this is that the instance check does not allow for duck-typing, which goes in line with https://github.com/graphql-python/graphql-core/pull/91 and is a quite common principle in python.\n. Support for duck-typing would be nice here as well but I think it would probably be far less used and more a nit-pick from my side.\n. ",
    "ratson": "I am wondering how it could be integrated with django.contrib.auth, an example / tutorial will help a lot.\n. ",
    "adamcharnock": "I'm just getting started and this looks really promising, but some docs would really help out. I'd be happy to lend a hand in anyway I can (e.g. proofing, newbie's perspective)\n. Fantastic! I've just submitted #54 which expands the django quickstart a little\n. Just thought I'd drop a note here to say that I plan to do a lot of work on the Django quickstart guide as part of PR #60.\n. I just updated from 0.4.0 to 4a591354f1d809e0c5d34ba425bcd4a0960fe2ee and this seems to be fixed now.\nI'd be very grateful if someone could give me a nod wrt the query I'm doing though. Does that look sane?\n. @syrusakbary Ah yes, thank you very much. The SW example has been very handy actually. I think #40 was throwing me a bit, but now that is sorted that should make life easier.\n. Ah, I could swear I was using the latest version of both, but I've checked again this morning and it seems to be working fine. That's what I get for reporting issues at 2am I guess! :-)\n. BTW: I've had a good look around the code to figure this out. I'd ideally write a pull request for this, but I'm not confident enough with the codebase to really know where to start. My guess would be to somehow handle this in graphene.contrib.django.fields.ConnectionOrListField.\n. Fantastic, just tried it and it works great :-)\nI'm about to create another issue to start a discussion around point 2 in the above description.\n. I agree @jhgg, I think that is #28.\nAs far as my ability to contribute is concerned, I would probably look to implement the basic ideas/functionality which could then be optimised.\n. @syrusakbary I'll checkout the existing Django traversing, I think I mustn't have realised that.\nSupporting third party packages such as django-filter and django-guardian sounds like a good idea, and I think you're right that some permission checking would be needed for most projects. I suggest we avoid requiring their use though, as people may already have other systems in place (especially for permissions). Which makes me wonder if a pluggable system of some form could make sense.\nI haven't looked into how I'd actually implement the mutations, but I'd be open to suggestions.\n. I've just knocked out a proof of concept for a DjangoQuery class. I just took my existing Query class and wrote a metaclass to autogenerate the necessary attributes. I'd be willing to accept that this is somewhat crude, but I felt it was worth a shot. It also has the advantage of allowing one to extend/override the attributes/methods in the child class.\nhttps://gist.github.com/adamcharnock/78dbc5d8e448b4e5b1d9\n. Thanks @syrusakbary, and I totally agree. That was something I meant to comment but clearly forgot. I couldn't see an obvious way of allowing the developer control of those names, so I just hard coded it for the sake of a simple proof-of-concept.\nGood point on the resolve_FIELDNAME methods. I'll take a look at creating a resolver based on django-filter.\nGiven these comments, are you happy with the general direction of the above gist? If so I'll continue to develop it. If not, I'll hold off until we figure out a better idea.\nEDIT: Added comments to gist\n. Just checking in to say I haven't forgotten about this. My initial attempt \u2013 while a learning experience for me \u2013 is clearly not the way to go. I've spent some time getting on with my own project and in doing so I have definitely come around to the method you suggest above.\nI'll knock up another gist in a bit.\nEDIT: @syrusakbary Thank you very much for the suggestions and taking the time\n. Ok, here is attempt number two:\nhttps://gist.github.com/adamcharnock/ad051b419d4c613d40fe\nI have it loosely working at the moment, but no doubt they'll be issues. The main points are:\n- The addition of a DjangoFilterConnectionField field\n- ...which uses a FilterConnectionResolver to resolve the field to a queryset as provided by django-filter\n- The contents of FilterConnectionResolver were largely taken from the django-filter FilterView class\nPoints of concern:\n1. The dubious conversion of django-filter filters to Graphene types in DjangoFilterConnectionField.get_filtering_args()\n2. The use of the on parameter to specify the model field upon which the filtering should be performed. Just a general feeling that this could be done better.\n. Ok, I've just rewritten the conversion to Graphene types and updated the gist. The conversion is now down based upon the the form fields graphene uses to parse & validate the incoming values. See converter.py in the gist. Maybe there is a smarter way of doing this, but doing lookups seems to be the way both graphene and django-filter already do this so I did the same.\nIssues to be addressed (suggestions welcome):\n- The ordering of fields in the root Query is important. If a filter can filter upon a relation, then Graphene must already be aware of that model's existence, and that model's entry in the root Query must therefore come first.\n- I think I need to implement an extra filter (GlobalIDFilter?) in order to filter against global IDs. This would need to reference a GlobalIDField form field, which'll also need implementing.\n. @syrusakbary Great, those sounds like some very good points. It's 3:30am here so I should really get some sleep, but I'll probably take a look tomorrow.\n. I've created PR #60 as this seems like a sensible time to stop working with gists.\n@syrusakbary My reasoning for convert_form_field_to_djangomodel() returning an ID type is that, if one is filtering for a model, one would do so by the model's ID. However, this decision was not arrived at after an abundance of reflection. Do you have thoughts on this?\nYour other two points sound like good suggestions. I'll investigate them further when get back to coding.\n. Great, thanks :-) I'm thinking I'll have a quiet weekend, but I may do more next week.\n. I think that looks like a good solution. It like that it has some parity with Django's models. Ideally we wouldn't have to specify that a Query is abstract and things would just work, but given that this is not possible I think this is a good solution. :+1: \n. @syrusakbary I'm currently struggling with this too. I have something like this:\n``` python\nclass CreateEvent(graphene.Mutation):\n  class Input:\n    description = graphene.String()\n    start_date = graphene.String()\n    end_date = graphene.String()\n    # ...\n    all_day = graphene.Boolean()\nevent_edge = graphene.Field('EventNodeEdge')\n  event = graphene.Field(EventNode)\n@classmethod\n  def mutate(cls, instance, args, info):\n    event = Event.objects.create(**args)\n    cursor = cursor_for_object_in_connection([e.id for e in Event.objects.all()], event.id)\nassert cursor\nreturn cls(\n  event=event,\n  # Side question: Which Edge class should this be? I see two:\n  #     graphql_relay.connection.connectiontypes.Edge\n  #     graphene.relay.Edge\n  event_edge=Edge(\n    node=event,\n    cursor=cursor,\n  )\n)\n\n```\nCurrently I'm receiving \"Cannot return null for non-nullable field EventNodeEdge.cursor.\". However, cursor_for_object_in_connection() is returning a string value.\nAny help here would be very welcome indeed!\n. This is driving me up the wall. Still receiving Cannot return null for non-nullable field EventNodeEdge.cursor errors. I'd be willing to offer a bounty for some clear documentation if it can be done ASAP.\n. Thank you very much @syrusakbary, that'll be really useful :-)\nFor now I've managed a temporary workaround by just doing this.props.relay.forceFetch() after the mutation has been executed, thereby reloading all currently rendered data from the server.\n. @syrusakbary I could swear I replied to this! Sorry for the delay. I had actually using both relay.ClientIDMutation and 'mutate_and_get_payload ' with no luck. I may be working on this again soon so it would be great if I could figure this stuff out :-)\n. @syrusakbary Will do.\nTo clarify, what I mean is I think that a working example in the docs would really help a lot. I felt I had run out of avenues to explore when I last looked at this.\n. Great, I've just rebased the branch. There was only a minor conflict in graphene/contrib/django/__init__.py.\nI was wondering the same thing about django-filter, I've added it to the list.\nI've got some client work coming up next week, so my hope is to have this mostly done in the next few days.\n. @syrusakbary I'm thinking about your idea of method decorators. I'm imaging something like this:\n``` python\nclass Query(ObjectType):\n    all_accounts = DjangoFilterConnectionField(AccountNode)\n@filter_connection(fields=['id', 'name', 'slug'], order_by=['name', 'slug'])\ndef resolve_all_accounts(self, args, info):\n    return Account.objects.filter(user=info.context.request_context.user)\n\n```\nIs that roughly what you had in mind?\nIs there any benefit of doing that over doing this (which is now implemented):\n``` python\nclass Query(ObjectType):\n    all_accounts = DjangoFilterConnectionField(AccountNode, \n                                               fields=['id', 'name', 'slug'], \n                                               order_by=['name', 'slug'])\ndef resolve_all_accounts(self, args, info):\n    return Account.objects.filter(user=info.context.request_context.user)\n\n``\n. Any views on the ordering field being calledorderororder_by? It is the former for now. I felt django-filter's default ofo` was too terse for the otherwise more descriptive language used in GraphQL.\n. Thanks for that @syrusakbary, that helps a lot!\nI think your idea of putting the filter args inside a InputObjectType makes technical sense. However, I really like how cleanly the GraphQL reads in the current system. I haven't actually made much use of this filtering in my Relay app yet, so I'm not sure what the impact will be from a front-end code point of view. I'm tempted to 'wait and see' on this one. What do you think?\n. I'm also having a lot of trouble trying to test some new code (see in coverage.io). It seems that Django hasn't loaded the relations for the models and therefore I cannot navigate reverse relations in the tests. This probably isn't surprising given we are testing outside of Django's testing framework, but it is causing me a problem.\nDo you have any suggestions for a way around this?\n. I've updated the Django version requirement to >=1.8. It seems that the tests on master don't pass for 1.7 or 1.6, and fixing the issues proved difficult. I've also updated the travis config to build both 1.8 and 1.9. How do people feel about this?\n. @syrusakbary Also, thank you for the tip on the test! That helped a lot :-)\n. It seems that there are differences in the Django ORM API in different versions, certainly involving relations. My head is a bit fuzzy at this point though. Definitely up for graphene working in order django versions.\n. I've also just added this in 3a23c1f940fbd30293b5722c872daa9a86c4c924:\n``` python\nschema = graphene.Schema(name='Cookbook Schema')\nclass CategoryNode(DjangoNode):\n    class Meta:\n        model = Category\n        filter_fields = ['name', 'ingredients'] # Can now specify filtering on the destination node\nclass IngredientNode(DjangoNode):\n    class Meta:\n        model = Ingredient\n        filter_fields = ['name', 'notes', 'category']\nclass Query(ObjectType):\n    category = relay.NodeField(CategoryNode)\n    all_categories = DjangoFilterConnectionField(CategoryNode)\ningredient = relay.NodeField(IngredientNode)\nall_ingredients = DjangoFilterConnectionField(IngredientNode)\n\nschema.query = Query\n```\nHaving this option available makes sense to me as the attributes a node can be filtered on are primarily related to the node, not the connection. They can still be specified/overridden at the connection level though.\n. I'm thinking that creating a DjangoFilterNode class could make the most sense. This way I can customise how the fields get generated* and also create a separate DjangoFilterOptions class to handle the additional Meta options that will be needed.\nVery much open to thoughts on any of this though.\n- as per the PR's todo item: 'Filtering should be available on nodes without having to explicitly define the fields'\n. @syrusakbary Done, with caveats:\n1. I implemented your last point regarding DjangoObjectTypeMeta. However, I actually created a DjangoFilterObjectTypeMeta class which is an optional base of DjangoNodeMeta. I needed this in order to adjust the default django field conversion. I'm not sure this is a good idea, partly because it looks weird, and party because...\n2. ... two tests are breaking and I'm not sure why. If DjangoNodeMeta does not inherit from DjangoFilterObjectTypeMeta then they pass.\nThoughts very welcome!\n. Ok, I'll take a look.\nAny thoughts on those broken tests?\n. @syrusakbary Ok, I've reverted the commit. I think my concern was more to do with behaviour during imports. But I think you are right.\n. Thank you :+1: I may be less around this week depending on how busy I am with work.\n. So by now it is probably clear that I haven't had time to revisit this yet! It sounds like I'll be working full-time in January too.\nHowever, I'd really like to get this merged in so it can start being useful. Aside from documentation, is there anything that needs to be done before it can be merged? ( @syrusakbary )\n. @syrusakbary Great. I've done a little more work on the docs but then got sidetracked by a bug I discovered. It seems that the results are not correctly returned when relationships are traversed (for filtered models only). All results are returned rather than just the results for that relationship.\nI've spent a couple of hours trying to figure this out, but I've clearly forgotten how a lot of this hangs together since I last came to it. Would you be able to shed any light on this?\nI'll do some more work on the docs.\n. @syrusakbary Great, thank you!\nI've just expanded on the django quckstart and added a separate section on filtering. Let me know if you think I've missed anything (or it needs any amends), but other than that I think I'm happy to consider it done.\n. I've also added an example django app named cookbook. I left the starwars app intact for a couple of reasons:\n1. I felt it could still have value in its current form\n2. On a philosophical note: I know SW is the canonical GraphQL example, but I feel that understanding it requires some specific pop culture knowledge. Also SW fans are predominantly white males. Therefore, in the interest of diversity and common knowledge I went with food instead :-)\n. Brilliant! Thanks so much for taking a look over it.\n. Fantastic! :dancer: \n. Hey @syrusakbary, thanks for pinging me. I think allowing modification of internal functionality is a great idea.\nThe way I've seen this done in the past is:\n1. Configuring which classes/modules should be used to provide functionality (such as Django's DEFAULT_FILE_STORAGE, TEMPLATE_LOADERS etc). I think this can break down into:\n   - Specifying a single class/module/etc which should be used (DEFAULT_FILE_STORAGE)\n   - Specifying multiple classes/modules in more of a 'behaviour pattern' style (TEMPLATE_LOADERS, INSTALLED_APPS)\n2. Providing hooks into internal code. I've normally seen this done explicitly in the code which is to be modified. (Django has signals, wordpress has apply_filters and do_action, used like this)\n3. Monkey-patching (which I'd say is best avoided)\nAfter a little reading, I think the characteristics of a good plugin system are:\n1. Easy to understand and use (i.e. both in code, and in documentation)\n2. Loosely coupled. There is some central plugin manager with code code on one side, and plugin code on the other. Each side does not know or care about the other\n3. Easy to debug\n4. Have a mechanism for registering plugins (and potentially inspecting those plugins installed)\nEasy to understand\nI've been hacking around with Graphene for about a week now and I'm still pretty unsure of how the schema & type system work. I don't think this is the fault of Graphene, but rather this is just a project that is both inherently complex and lacking in documentation of that complexity (for now).\nIf the plugin system needs to be easier to understand than the graphene internals, then perhaps the plugin API should be more verbose. For example, providing multiple clearly named hooks.\nI feel the code in the CamelCase plugin requires I knowledge of Graphene's internals. One must know that is it GroupNamedType.get_named_type() that one needs to override, which I don't think would be easy to discover. Neither GroupNamedType or get_named_type shout out to me as obvious places for this to be.\nSeparately: The CamelCase plugin also needs to check the type of _type for each call. I feel this is something Django's signals have a solution to. (I'm not saying we should use Django's signals, rather that this is an idea to consider)\nLoosely coupled\nI say this based on a blog post from 2008, but I don't this has changed much.\nThe current plugin seems to not obey this principle as plugins require knowledge of Graphene internals.\nEasy to debug\nPlugins start to change code behaviour in unexpected ways. Even if how the behaviour will change cannot be made clear, I think the fact that behaviour can change should be. In the current plugin system it seems that we monkey patch a method to customise the functionality. I think this is a problem because:\n1. The original code will never be called and it would not be obvious why to a developer doing debugging\n2. There are no hints in the core code that it's behaviour may be changed\nI'd suggest something like:\npython\nclass GroupNamedType(BaseType):\n    ...\n    def get_named_type(self, schema, type):\n        name = type.name or type.attname\n        # Either:\n        name = signals.type_name.trigger(name, sender=GroupNamedType)\n        # Or:\n        name = PluginManager.trigger(\"get_type_name\", name)\n        return name, schema.T(type)\n... or something along those lines.\nNode that Django's signals will return a list of values, one for each handler, so this would need to change in our implementation.\nMechanism for registering plugins:\nThis is currently done by passing Schema(plugins=[...]), which seems like a reasonable solution to me.\nI'm think I'm out of thoughts for now :-) Thoughts?\n. [Initial conversation, #64]\nNo problem, it's nice to look into a new problem. I've added a couple of comments into the commits, but overall I think this is great. I think figuring out where the hooks should be could be a larger job.\nI don't think I considered signals to be async, but I presume that is just because were coming from different backgrounds. I think your view is valid.\nI'm also slightly aware that I don't seem to have seen this kid of hook system used in many other python projects. I'm wondering if this is just my experience or if there is some larger reason. I'd be interested to get other opinions on this.\nRe 'Explanations on internal code': Sounds perfectly reasonable.\n. @lightning18 This is great, thank you :-)\nJust a minor hiccup: It seems that the SUCCESS style was only added in Django 1.9. I don't really see a sensible alternative style though :s\n. I recall @syrusakbary stating a preference to support Django 1.6 as quite a few of the graphql-core folks are using it. IMHO I don't think it is a critical problem in this case, but it is a very useful command so it would be great to sort it somehow.\nPersonally, I'd be tempted to just remove the styling.\nSide note \u2013 I didn't know that Django offered this styling - I'm sure I'll be making use of it soon :-)\nEdit: Added link\n. @matclayton FWIW I'm currently treating the through table as simply another node. It makes the GraphQL somewhat nested, but it works for now.\n. Good point, done\n. Good point, done\n. Done, bbbf6884492360e6ae1b57263d02f067b18c7d7c\n. Thoughts on this new connection_field_class and its use?\n. ",
    "montemishkin": "Whoops, I forgot to check your contributing guidelines.  I'm adding tests now.\n. ",
    "rapilabs": "@jhgg, mate, props for the instant response on a weekend!\nOk yes I see now, it's working thanks!\nNote I had to actually manually import InputObjectType from graphene.core.types as it's not part of the graphene namespace: https://github.com/graphql-python/graphene/blob/master/graphene/init.py#L15\n. Awesome, I should check these new branches before I suggest something ;)\n. ",
    "bigblind": "I think you can get this info from the query AST, but there should be a more convenient way to get this.\n. Can I just create my own field with a type of Connection? The database I'm using, rethinkdb, allows me to do much more optimized queries with cursors than with indices based on len. Basically, with the approach that you use, I need to know the index of every item in the database. With cursors, a rethinkdb query would look like this:\n`r.db(\"my_db\").table(\"users\").between(cursor, r.maxval).limit(first+1).run(connection)``\nIf you're not interested in rethinkdb, I don't expect you to look up how this code works, but I wanted to give a use case for actually doing this.\nThe reason I'm fetching first+1 items, is so that I know there's a next page of results. if the query returns first items or fewer, I know there are no more items.\n. graphql-core already has implementations for executing fetches in parallel for things like gevent and asyncio. Many of these systems use an event loop. Maybe we could add batching support to these.\n. This function seems useful outside Django, to get the fields from an info object. Is there any way this could be refactored into  graphene core? I'm willing to do the work, but I'm not familiar enough with the codebase to know where this should fit.\nUpdate: I'm looking into whether this can be directly added to the ResolveInfo class in graphql-core. It seems the most logical place for this to go.\n. ",
    "mjtamlyn": "I've written something along these lines for my own project. It just works on a connection at the moment. It uses the info to work out which fields (if any) are being requested on the underlying node, and then checks the corresponding node type for a optimize_foo classmethod. If that exists, it passes the queryset through that method, before passing the queryset to the connection_from_foo function. They have a similar signature to a resolver. You have to be careful in resolver methods that both optimized and non-optimized cases are covered in some cases.\n``` python\nclass PostNode(DjangoNode):\n    [...]\n@classmethod\ndef optimize_owner(cls, queryset):\n    return queryset.select_related('owner')\n\n@classmethod\n@with_context\ndef optimize_loved(cls, queryset, context):\n    # Sets user_loves attribute on post\n    return queryset.prefetch_user_loves(context.user)\n\n@with_context\ndef resolve_loved(self, args, context, info):\n    try:\n        return self.user_loves\n    except AttributeError:\n        return self.love_set.filter(user=context.user).exists()\n\n@classmethod\ndef optimize_field_with_arguments(cls, queryset, args):\n    return queryset.process_args(args)\n\n``\n. My understanding is that.only()` is in fact a performance hit in many cases. This may seem counter intuitive, but it comes down the the fact that the returned model object from an only query is much more complex than a raw one, and this extra time is a bigger hit that the extra work your database does.\nSee the documentation for only and defer, the note pretty much says \"don't do this unless you absolutely have to\".\n. The relay spec explicitly states that a root node field must accept only a single argument of id.\nYou can have other root fields which load data differently, but they have to fit with certain rules.\nOf course if you are not building a GraphQL API for Relay, or your node is not at the root, then you can in theory do as you please.\n. Could both the InputObjectType and the ObjectType inherit from the same Interface?\n. As far as I can tell from the GraphQL spec there is no discussion of http response codes at all. The status codes of HTTP are strongly tied to rest principles. It's not clear to me whether GraphQL APIs should distinguish between 2XX and 4XX status codes.\nMost notably, you can batch multiple mutations into the same request to the server. If one successfully creates a resource (201), one mutates a resource (200), one fails validation (400) and another the target object does not exists (404), what should the return value from the API be?\nAt the moment, GraphQL APIs seem to err on the side of 200 unless the server blows up, in which case 500.\n. Right, I think that makes sense. Python actually wanting a proper set of arguments to a function does complicate the issue slightly.\nBy the way, there's no tagged release or changelog I can find for 0.9 which did make this slightly more complicated to work out! I'll give it a go using with_context.\n. Ok, I've got it working fine apart from relay mutations which need a bit of extra work I've done in the PR. It would also be very helpful to add some docs about with_context and how to use it.\n. I would agree that resolve_blah(self, args, **options) where options is now info=, context= but can be extended later would be more pythonic.\n. Ok, so this is a tricky design decision in some ways because we want to mimic the \"argument magic\" that javascript can manage in python. We've also got a possible name clash issue.\nHere are a few possible approaches:\n- Use decorators to explicitly mark which resolvers need which arguments. This is the current proposal. It doesn't feel very pythonic. We could have a convention that context and info could be passed as _context and _info if there's a name clash, or always.\n- Use the inspect module to find the signature. inspect.getargspec(resolver_func).args will return a list of names of arguments. If that includes context or info then we pass them. This is \"fully\" magical, but I don't find it any more distasteful than the _root/getattr pattern we have at the moment. I'm not sure if we can get access to which arguments might be relevant to deal with name clashes, but it would be easy to see if a user is expecting context AND _context and pass the arg as the former and the context as the latter.\n- Define a more pythonic standard API for a resolver. Something like def resolve_foo(self, arg1, arg2, **options). Again we can deal with name clashes with _context if necessary, or just have a convention that you don't do that. I feel this is the route we would be taking if there wasn't the JS reference implementation.\n. I think args, info is the simplest option, I don't think we need extra arguments.\n. This could be fixed in the same way as mutate_and_get_payload was fixed - https://github.com/graphql-python/graphene/commit/61e7beee7b9c83c55b7b47c3814f120e421400b6. The discussion is quite related to what we decide to do in the long term with resolver functions though - See #164 \n. Thanks, that's really useful!\nI think it makes sense for get_queryset to have a consistent API between DjangoNode, and possibly also DjangoConnection rather than DjangoConnectionField. I was bouncing some ideas around in https://github.com/graphql-python/graphene/issues/180#issuecomment-221283513 which might remove the need for a separate connection field anyway.\nThe Roadmap plans to move graphene.contrib.django out into its own package (graphene-django) for 1.0. I think in that package we need to try and provide approaches which feel more \"Django\" than \"graphql-js\", having this get_queryset method definitely does that.\n. Looking at this a bit more in the context of #62 I wonder whether we can reduce the plumbing duplication needed for various different data backends. The core logical structure is the same for my Django implementation, for the GAE one, and for the rethinkdb cursor mentioned in #62.\nIdeally what we want is an easy way to add a Cursor subclass or similar which has some defined API, possibly similar to what I defined in django-cursor-pagination. It needs to be able to:\n- Be initialised with some data set\n- Have some method like page(first, last, after, before), which returns an object with resultant set of items, and the data needed for PageInfo.\n- Have a means of getting the cursor for each item\nIdeally you could then specify the cursor as a kwarg and/or attribute of graphene.relay.ConnectionField and everything else would follow. A built in DjangoCursor could swap between using CursorPaginator or the current count/slice approach as needed.\n. The example at the top worked on Graphene 0.X, you're right it doesn't work with 1.X.\nI redefined Connection more completely on graphene 1.X to make it work:\nclass CursorPaginatedConnection(six.with_metaclass(graphene.relay.connection.ConnectionMeta, graphene.ObjectType)):\n    ...\nI also had to add a different default resolver to the field.. I think that's a minimal test case.\n. I feel that the restrictions on a GraphQL enum type don't fit well with choices in all cases. In particular Django choices intends that the \"internal\" (first) representation is used to submit data, and the \"external\" (second) representation is used to render output data. Enum types use the \"name\" of the value for both cases, which may not be unique.\n. A failing test for a similar case was proposed in #184 - would this fix that test as well?\n. Thanks @jkimbo \n. Should there also be a way to explicitly name any given type? This could be useful for refactoring/changing the backend\n. I was actually wondering if this should be \"deeper\" than the connection and there should be an option on the core ObjectType\n. Sorry, by core ObjectType I meant the actual ObjectType class, rather than the target of the connection. Connection is a subclass of ObjectType, and you can specify the connection_type when creating ConnectionField, so that would let you name it explicitly in the case, but also explicitly name any other type in your system.\nBasically we're disconnecting the python name of the class and the schema name of the type.\n. Of course, it's a good convention to have the names matching but I'm sure there are times when it would be inconvenient.\n. This appears to be an open problem at the moment. There's some discussion in #57, #28 and in the JS graphQL implementation in https://github.com/graphql/graphql-js/pull/304.\n. I feel that will be dependent on the backend you are using - the way this would work would be rather different for Django than for SQLAlchemy than for GAE. Django certainly provides alternative ways to optimise queries for relational databases.\n. This looks like a good way to allow simple optimisations.\n. That is following the Relay spec for connections. In principle you can write a Graph query which is not relay compatible, but you'd need to invent some other way to handle pagination.\n. Amazing thanks! That'll make my workshop tomorrow go rather better ;)\n. You can pass context to schema.execute as context_value=<obj>. Info describes the structure of the query from this point downwards, you can inspect it but you can't control it.\n(ref: https://github.com/graphql-python/graphql-core/blob/49fa28f2a75a8bca6a90ad7852772a58ae8599fc/graphql/graphql.py#L30-L32)\n. At the moment, connections are implemented according to the Relay cursor spec - which doesn't mention totalCount. You can create your own connection class (and field) if you want to add it\n. As far as I'm aware, not really. The advantage of the latter is that it can be used when X has not yet been defined, allowing circular references. For example:\n```py\nclass A(ObjectType):\n    children = graphene.List(lambda: B)\nclass B(ObjectType):\n    parent = graphene.Field(A)\n``. Ah ha! Thanks @charettes. I hadn't heard ofsys.excepthookso didn't know where to look. Should be fixed in the next release ofgraphql-core.. In Django, we would use [force_text`](https://docs.djangoproject.com/en/1.9/ref/utils/#django.utils.encoding.force_text) to do something like this. I guess that's probably not an option for graphene itself, although it could be in the Django field transfer step. this might be a better fix.\n. ",
    "jkimbo": "@syrusakbary I think this issue can be closed? If it's still an issue then it should be raised on the graphene-django repo. Ha, that is a good point @svilendobrev !\n@syrusakbary should probably rename the function to _resolve_type and do it soon since it's now documented. I guess it's technically a breaking change but I don't think it's extensively used so we can probably get away with releasing it in 2.2 version. Hi @bigblind . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @adamcharnock . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @Speedy1991 source is specific to the graphene-django integration.\nFor plain graphene you can use the resolver kwarg to specify a custom resolver: http://docs.graphene-python.org/en/latest/types/objecttypes/#resolvers-outside-the-class. @mathieusteele @helpse the issue is that Django does not convert the field that has just been set into a datetime object until you re-instantiate the model.\nYou can see this happening in the shell:\npython\nreunion.fecha = '2018-04-04T20:10:00+00:00'\nreunion.save()\nprint(reunion.fecha)  # '2018-04-04T20:10:00+00:00'\nreunion.refresh_from_db()\nprint(reunion.fecha)  # datetime.datetime(2018, 4, 4, 20, 10, tzinfo=<UTC>)\nSince Graphene doesn't know anything about Django, it just takes whatever object it is given and reads the fields off it.. Hi @defrex . It looks like this issue might have been solved. In an effort to try and clean up the issue tracker I'm going to close this.. Hi @DasIch . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @lig could you open an issue on graphene-django then since that is where we track any issues with the Django integration. Hi @rapilabs . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @Globegitter . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @mjtamlyn . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. PR: https://github.com/graphql-python/graphene/pull/241\n. An implementation of Dataloader is available to use inside Graphene: http://docs.graphene-python.org/en/latest/execution/dataloader/. @syrusakbary is this still an issue since 2.0? I have not had any issues with error handling in 2.0. Hi @tom-zeit The Django integration with Django is now in a separate repository (https://github.com/graphql-python/graphene-django). If this issue is still a problem for you could you create an issue on that repository so that it can be addressed?. Looks like some workable solutions have been suggested for this issue. Closing. Hi @Globegitter. We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. So I've had a quick look into trying to fix this but I'm not sure how to do it. The line that causes the issue and the subsequent lines are used to actually construct the kwargs for the underlying connection type and as far as I can see, need to be defined at instantiation. However LazyType needs to have the context of the schema to resolve Type into the actual definition and this is not available in the __init__ method of DjangoFilterConnectionField and I can't see an easy way of deferring all the instantiation to resolve time.\n@syrusakbary any ideas?\n. It looks like this issue might have been fixed in https://github.com/graphql-python/graphene-django/pull/58\nIn an effort to clean up the issue tracker I'm going to close this issue. If it is still important @nickhudkins  please comment and I'll reopen this.\nThanks!. Closing this issue since the Django and SQLAlchemy integrations have been moved into separate repos now.. PR for potential fix: https://github.com/graphql-python/graphene/pull/240\n. Thanks!\n. My personal preference is keeping docs with the code since it means that there is less chance of them getting out of sync (maintaining docs is hard enough already!).\nAnyway regardless I didn't mean to come across as ungrateful or anything! It's a fantastic project and I'm enjoying using it. Got some time on my hands at the moment as well so I'll try and pick off some of the low hanging issues if thats ok?\n. @slorg1 I submitted a pull request for this (https://github.com/graphql-python/graphene/pull/238) and it was merged a couple of weeks ago. It's possible it just hasn't been published yet?\n. @slorg1 I don't know much about your second issue I'm afraid but if you could create a failing test case for it that would help immensely\n. @giorgi94 if you are having an issue with graphene-django can you please open an issue on that repo. Hi @hyusetiawan \nRegarding the error in the docs, the example should return Post.objects.none() since you're right the resolver does expect a queryset to be returned. I've raised a PR for the docs here: https://github.com/graphql-python/graphene-python.org/pull/4\nAs for your other question on how to exclude fields, you can use the exclude_fields meta attribute. e.g.\nclass UserNode(DjangoNode):\n    class Meta:\n        model = User\n        exclude_fields = ('password',)\nHope that helps!\n. @mickeyinfoshan running pip install -e .[django] should install all the dependencies required for the tests\n. graphql-core is responsible for the query parsing so that is where adding null to the language will need to be added. Looks like there is already a pull request open to implement it: https://github.com/graphql-python/graphql-core/pull/119\n@rdemetrescu I can't reproduce your issue. If you are still having problems can you open a new issue with everything needed to reproduce it?\nClosing this for now. Hi @Globegitter . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @morgante . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @jnak . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @zbyte64 . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @mzohaibqc . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @gijs . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @nlhkh . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nIn regards to this particular issue you might want to look at dataloader as a solution.\nThanks!\n. This was fixed by https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95. Hi @jwfehr . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @jwfehr . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @kevinbarabash . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @daironmichel . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @pedrorjbr. We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @pedrorjbr . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @mleonard87 . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. @nderkach nice! I'll try and get it included in the documentation somewhere.. Hi @raun. We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. It looks like this issue has been solved. Closing the issue.. Hi @Exertive . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @pedroabi . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. Implementing a custom PageInfo object is possible using something like the code in https://github.com/graphql-python/graphene/issues/307#issuecomment-250881176. Hi @davidyapdy . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @CreatCodeBuild I completely agree! Would you like to contribute some documentation to the project? As someone new to the project I'm sure you would have some interesting insight into places where the documentation is lacking.. There is not much we can do about this since this is how python's module resolution works. Graphene is based off graphql-core which is a port of the reference graphql server implementation graphql-js. graphql-core installs itself as graphql so if you name a file graphql.py in your project python will pick that up first and any further imports to graphql will reference your local file and not the library graphql-core.\nTo avoid this issue I can only suggest that you name your graphql implementation as something other than the literal name \"graphql\" (or \"graphene\" for that matter).. Hi @jwfehr . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. I don't think implementing static (aka persisted) queries is within the scope of the Graphene project since it is tightly coupled to the rest of your application. You would need to define where the persisted queries are stored, how the front end part of your app adds new queries, how your server interprets static queries etc.\nHere is a quick pseudo code example of how I imagine it could be setup inside an application:\n```python\nGraphql endpoint view\nimport graphene\nfrom my_graphql_server import schema # your apps schema\ndef graphql_endpoint(request):\n    query_identifier, variables = parse_body(request)\ntry:\n    # Retrieve a grapqhl.language.ast.Document instance from an identifier\n    # so that query doesn't need to be parsed again\n    document = get_document_from_identifier(query_identifier)\n    return schema.execute(document, variable_values=variables)\nexcept QueryNotFound:\n    return HttpResponse(status=404)\n\n`` . @michaelkuty @tivaliy you could probably use [eq](https://docs.python.org/3/reference/datamodel.html#object.__eq__) to make the all theShortString` classes equal to each other?. Hi @gamesbrainiac . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. @danpalmer sure I can reopen this issue but I think it would make more sense for this issue to be opened on the graphene-django repo since that is where any improvements would happen. . Hi @frbsfri . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @syrusakbary it does look like this is still broken. Any chance of fixing it or should the demo just be retired?. Hi @sineo . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. This issue looks like it should be raised on graphene-sqlalchemy. Hi @bochuxt . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @stan-sack I don't think this is an issue with Graphene since it is backend agnostic and doesn't do anything special to support SQLAlchemy. If you have a reproducible example I could take a look at it?. Hi @kaspermarstal . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @macolsson . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this. It's possible this issue is fixed in graphene 2.0 anyway.\nThanks!. Hi @keattang . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Looks like this issue has been solved. Closing.. It looks like this issue was fixed in graphql-core. Closing. @BossGrand is right, this belongs in the graphene-django repo. If the issue is still important then please open a new issue there.. Hi @femesq . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. I'm going to close this issue since it's stale. However just to add: I've found that modeling expected errors as part of your mutation response is essential. Your client needs to know what to do if your mutation fails. To do that I've found that modeling your response types as unions works really well since it allows you explicitly model the errors you're expecting. So in a createUser mutation similar to yours @jonatasbaldin you can do this:\n```python\nclass CreateUserFailUsernameExists(graphene.ObjectType):\n    suggested_alternatives = graphene.List(graphene.String)\n    error_message = graphene.String(required=True)\nclass CreateUserFailOther(graphene.ObjectType):\n    error_message = graphene.String(required=True)\nclass CreateUserSuccess(graphene.ObjectType):\n    user = graphene.Field(User, required=True)\nclass CreateUserPayload(graphene.Union):\n    class Meta:\n        types = (CreateUserFailUsernameExists, CreateUserFailOther, CreateUserSuccess)\nclass CreateUser(graphene.Mutation):\n    class Arguments:\n        username = graphene.String(required=True)\n        password = graphene.String(required=True)\nOutput = CreateUserPayload\n\ndef mutate(root, info, username, password):\n    if User.objects.filter(username=username).exists():\n        return CreateUserFailUsernameExists(\n            error_message=\"Username already exists\",\n            suggested_alternatives=get_alternatives(username)\n        )\n    try:\n        user = create_user(username, password)\n        return CreateUserSuccess(user=user)\n    except:\n        return CreateUserFailOther(error_message=\"Something went wrong\")\n\n```\nThen in your client your mutation query becomes:\njs\nmutation createUser($username, String!, $password: String!) {\n    createUser(username: $username, password: $password) {\n        __typename\n        ... on CreateUserFailUsernameExists {\n            suggestedAlternatives\n        }\n        ... on CreateUserFailOther {\n            errorMessage\n        }\n        ... on CreateUserSuccess {\n            user {\n                id\n            }\n        }\n    }\n}\nThen you just need to check the __typename value to figure out if there was an error (and what kind) or if the mutation succeed.. Hi @alehl . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. 2.0 is out so I'm going to close this issue. If there are any specific bugs please open new issues for them.. Hi @janhancic . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. Hi @minrock . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @jimshepherd . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @btorellALTA . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @richmondwang . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. @piercefreeman @joetempleman looks like you can achieve what you want using the Output option:\n```python\nclass AddChannelMutation(graphene.Mutation):\n    class Input:\n        name = graphene.String(required=True)\nOutput = Channel\n\ndef mutate(self, info, name):\n    # create new channel\n    return Channel(...)\n\n```\nCode is here: https://github.com/graphql-python/graphene/blob/be1f7d72a46f29eb491d3a6110fd955d0b72dea4/graphene/types/mutation.py#L34-L43. Hi @achimnol . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @leebenson it's a result of how Python find modules: https://docs.python.org/3/tutorial/modules.html#the-module-search-path. @dpnova is this still an issue for you? It seems that the issue in your example is that you need to return myenum.value from your resolve_foo function.. Closing this since I haven't heard anything back from you @dpnova . Please comment with more information if you are still having an issue.. Hi @mplis . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Looks like @jasonphillips has implemented something similar to this in https://github.com/graphql-python/graphene/issues/448 \nClosing this issue in favour of that one. Hi @japrogramer . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @mbrochh . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @achimnol . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Hi @Fercho191 . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!\n. @dfee is this issue still important?. Hi @LittleWolfWerewolf . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 6 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. Closing this issue as part of a clean up effort. @taut-and-yare if you are still having issues then please comment and I'll reopen.. @lincolnq all fields take a resolver parameter so your example can become (without the need for decorators):\n```python\ngraphene_models.py\nfrom graphene_impl import resolve_user_name, mutate_signup\nclass User(ObjectType):\n    name = String(resolver=resolve_user_name)\nclass Signup(Mutation):\n    class Arguments:\n        name = String()\n    id = ID()\nclass Mutations(ObjectType):\n    signup = Signup.Field(resolver=mutate_signup)\n```\nOtherwise @HeyHugo 's suggestion would work. Also https://github.com/graphql-python/graphene/issues/448#issuecomment-356777997 has some code that would allow you define your server using the GraphQL Schema Definition Language like graphql-tools.\nIf any of these solutions don't work for you do say and I'll open this issue again.. Hi @Dandi91 . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. I don't think graphene should be responsible for defining the default timezone for a datetime since it could misrepresent the actual timezone for the underlying value. If the datetime value is timezone aware then it will be represented in the response accurately. If the datetime value is not timezone aware then we can't assume it is in UTC.\nIt is the responsibility of the developer to ensure that timezone aware datetimes are resolved for any DateTime types and not the framework.. @tricoder42 I'm not sure that context should be defined by default since context_value does not have to be defined. Also it's not clear what it should be mocked to by default. In tests it should be up to the developer to pass context_value when creating the test client (e.g. client = Client(schema, context_value=request). Closing this issue as clean up but happy to have a discussion about it if anyone feels strongly.. This was fixed by https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95 and will be released soon.. Looks like this has been resolved now. Closing.. Hi @victorandree . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @Cito this has been added to the docs now: http://docs.graphene-python.org/en/latest/types/scalars/. @tomanizer to use the datetime types you can import them like this:\nfrom graphene.types.datetime import DateTime, Date, Time. Ok that is fair enough. Looks like https://github.com/graphql-python/graphene/pull/645 solves that so lets follow up there. Hi @ramarivera . We're currently going through old issues that appear to have gone stale (ie. not updated in about the last 3 months) to try and clean up the issue tracker. If this is still important to you please comment and we'll re-open this.\nThanks!. @mjtamlyn is right, it's to allow circular references when defining your schema.. @nykolaslima did @frsv 's solution fix things for you?. Closing until more information is provided . This was fixed by https://github.com/graphql-python/graphene/commit/a7a4ba62af4cb8b00ffa6a9f8cf79bd87dfb5e95 and will be released soon.. Closing this since it looks like your question has been answered.. @chanind Unions can only be used with ObjectTypes: http://facebook.github.io/graphql/October2016/#sec-Unions\nSo in your example the best thing to do would be to add a new input to the mutation and deprecate the old status input argument.. @weiztech you should be able to just pass any arguments you want as kwargs. E.g.:\n```python\nclass Query(graphene.ObjectType):\n    my_field = graphene.String(min_length=xx, some_arg=graphene.String(), another_arg=graphene.Int())\ndef resolve_my_field(root, info, some_arg, another_arg):\n    pass\n\n```. @weiztech can you give a me a bit more context on the code that you're having trouble with? Also make sure you're on the latest version of graphene. The following definitely works:\n```python\nclass Query(graphene.ObjectType):\n    my_field = graphene.String(min_length=graphene.Int())\ndef resolve_my_field(root, info, min_length):\n    pass\n\n```\nIf you would like to make a custom scalar you can follow the example of the Date scalar: https://github.com/graphql-python/graphene/blob/5df134e096f4ac839331d9aa6bfcc2bd50affa95/graphene/types/datetime.py#L18-L41. I'm still not sure I'm understanding your issue properly. From the code you've included I assume you want to apply some kind of validation to the input argument str in your mutation? If that is the case you can do that in the mutate method of the Mutation. That will allow you to return an accurate error message to the user.\nE.g.:\n```python\nclass TestMutate(graphene.Mutation):\n    class Arguments:\n        str = graphene.String(required=True)\nerror_message = graphene.String()\nok = graphene.Boolean(required=True)\n\ndef mutate(root, info, str):\n    # validate str\n    try:\n        validate_str(str)\n        return TestMutate(ok=True)\n    except StrTooLong:\n        return TestMutate(error_message=\"Input string is too long\", ok=False)\n    except StrTooShort:\n        return TestMutate(error_message=\"Input string is too short\", ok=False)\n\n```. @weiztech I don't think it's possible since the argument types use classmethods to parse and serialise values so they don't contain any actual state (which you would need to have to validate values)\nI would suggest creating some helper functions/classes to validate inputs that can then be called in the mutate function. I actually think that is a better solution anyway since it allows you to return accurate error messages to the client.. @dbrrt is this still an issue for you?. That's a shame. Can you give any more details so I could reproduce the error? . @dbrrt I found the issue and fixed it in https://github.com/dbrrt/apollo-aiohttp-graphene/pull/1\nBasically the schema execute function needed the variable values that were being sent by Apollo.. BTW you can see how graphene-django executes the query here: https://github.com/graphql-python/graphene-django/blob/a480a39713d3392dc3a7cee9565989a713d05856/graphene_django/views.py#L263-L271. Just found https://github.com/graphql-python/graphql-core/pull/103 which looks related. Not sure where the best place to solve this is? @syrusakbary @jhgg . @syrusakbary I'd appreciate a decision on this PR. If you don't don't want it as part of graphene then I'll close it. . Ping @syrusakbary \nAny feedback would be welcome. @akshaybabloo graphene is a server side implementation of graphql, not a client. You probably should post this under https://github.com/graphql-python/gql\nAlso, the example there should be more than enough to get you there anyway:\nhttps://github.com/graphql-python/gql/blob/3653bb5260b60a6c72d0bb0137874fb40969a826/tests/test_transport.pyr. @miracle2k it looks like the issue is that you have two types which are both called Node in the schema. This can happen if you are using relay.Node as an interface anywhere as well as your custom Node implementation.. Closing this since I haven't heard anything back from you @miracle2k . Please comment with more information if you are still having an issue.. @syrusakbary this looks ready to merge. @Speedy1991 you can just add the includeDepreacted flag to your query and it should work. The reason it's showing up in graphiql is because the introspection query it uses has it included: https://github.com/graphql-python/graphql-core/blob/v2.0.0/graphql/utils/introspection_query.py#L24. Sorry no one got back to you @valentinradu . As you guessed though, currently Graphene doesn't support remote schemas or stitching.. Nice catch!. @altaurog yep I've come across this issue before with the Node type. The way we worked around it was to create our own custom Relay.Node type and use that everywhere instead. That then gives you the opportunity to define a resolve_type method on the Node interface that can translate your underlying data structure into a Graphene type. E.g:\n```python\nclass RelayNode(relay.Node):\n    class Meta:\n        name = 'Node'\n        description = 'An object with an ID'\n@classmethod\ndef resolve_type(cls, instance, info):\n    if isinstance(instance, TestInstance):\n        return Test\n\n    return cls.resolve_type(instance, info)\n\n```. @altaurog I'm not sure what you are referring to when you say \n\nhelps break the dependency between the schema types and the resolvers and thereby allows more flexibility in the organization of the code\n\nCould you expand?\nAlso I dont think assuming the name of the data source instance will be the same as the graphene type is a good idea. Your schema will likely (and should) diverge from your underlying data structure so it's unlikely that assumption will hold for very long.. ObjectType documentation has been updated to be much more detailed in how to use resolvers. . @jloveric looks like your question has been answered so I'm going to close this issue. Thanks for the help everyone!. @luvwinnie do you have any more information on this issue so that we can try and help?. Closing until more information provided. The code for the JSONField type is pretty simple: https://github.com/graphql-python/graphene/blob/2594cdb61409f8ecedf0958ee959f8f8ded3efbc/graphene/types/json.py All it does to output the json string is call json.dumps(dt). \nI would recommend you make a custom scalar type based on the JSONField to try and see if changing the serialize function solves your issue. If you do please comment on this issue with your solution.. @alexisrolland for scalars you can add the description kwarg to specify a description and for ObjectType you can add a description field to the Meta class.\n```python\nclass MyType(graphene.ObjectType):\n    class Meta:\n        description = \"Some description for MyType\"\nmy_field = graphene.String(description=\"Some description for myField\")\n\n```. Yep there seems to be several open issues/pull requests about not being able to define a description for a mutation (e.g. PRs: https://github.com/graphql-python/graphene/pull/618, https://github.com/graphql-python/graphene/pull/565 or https://github.com/graphql-python/graphene/pull/594 and issues: https://github.com/graphql-python/graphene/issues/634, https://github.com/graphql-python/graphene/issues/626 and https://github.com/graphql-python/graphene/issues/593 )\n@syrusakbary any reason why one of the above PRs hasn't been merged yet?. @alexpantyukhin the @skip and @include directives are already available (they are implemented in the graphql-core library which graphene uses). Tests to show it working are here: https://github.com/graphql-python/graphql-core/blob/master/graphql/execution/tests/test_directives.py\nSome documentation to show they exist would be helpful I admit!. @dani0805 can you include the relevant parts of the code so that I can try and reproduce?. Closing this issue. I can reopen it again if more information is provided.. Ok I'm not sure I can help without a way of reproducing the error. Can you create a test case where it happens?. @aniagarwal97 also make sure that you haven't got any folders or files named as graphql or graphene since that will override the grapqhl and graphene modules.. Closing this issue. I can reopen it again if more information is provided. . @anisjonischkeit I think this is issue is happening because there is a semantic difference in the GraphQL specification between an argument that is null vs one that is not defined: http://facebook.github.io/graphql/October2016/#sec-Null-Value That is why when name is not defined, in your example, it is not passed to the mutate method at all.\nThe way to work around that is to use kwargs:\n```python\nclass DoMutation(graphene.Mutation):\n    class Arguments:\n        name = graphene.String()\nok = graphene.Boolean()\n\ndef mutate(self, info, **args):\n    name = args.get('name', None)\n    # mutate\n    return DoMutation(ok=True)\n\n```\nI don't think changing the default value of the required attribute is a good idea since it will be diverging from the GraphQL specification.. @gmetzker this the way that graphene-django handles it: https://github.com/graphql-python/graphene-django/blob/dbd3957a9f622573b2b106546f3accc48f5d5b41/graphene_django/views.py#L161-L163\nBasically it calls format_error from graphql.error on each GraphQLError . @gmetzker does my comment answer your question?. Closing issue until there is more information. @morenoh149 correct it does. The whole Relay integration part of graphene needs a lot of attention from both a code standpoint and a documentation one. The Relay classic integration probably also needs to be dropped since it\u2019s no longer supported by the Relay team. . @montemishkin for reference here is some example code on how you can customise Connections: https://github.com/graphql-python/graphene/issues/875#issuecomment-450738767. @anuragensemble what version of graphene are you using?. Your Metadata definition fields need to be instantiated:\npython\nclass Metadata(graphene.ObjectType):\n    address = graphene.String()\n    birthday = graphene.String() \nThat should fix the assertion error you're seeing. Your __init__ definition on User doesn't look right either. You probably don't want to do it that way.. @anisjonischkeit this looks good. Could you please add some tests first?. @syrusakbary this looks ready to merge. @bwanglzu as far as I'm aware there is no such ability in the graphql spec: http://facebook.github.io/graphql/October2016/ Graphene is just a framework to implement a graphql server and so it must conform to the specification.\nIf you want to allow your client to arbitrarily pass filters to your underlying data fetching method you could model it as a list argument as you suggested:\npython\nclass Query(graphene.ObjectType):\n    things = relay.ConnectionField(ThingConnection, or_filters=graphene.List(graphene.String)\n. Great, glad I could help. Generally with graphql there is not a big overhead in having multiple ways to query the data since it's up the client to decide how to query. And it's usually better to be explicit with naming so what you've come up with looks great. . @yywing just because you're storing the data in that nested json object does not mean you need to represent it in your api like that. When building a GraphQL api you need to think about how to model the data like your client thinks about it and then translate that internally to how your data is actually stored.\nNow I have no idea what you're actually trying to model so this will probably be the wrong way of doing it but it looks like the main objects you care about are a Crawler and a Task. So from that schema could look like this:\n```python\nclass CrawlerType(graphene.ObjectType):\n    auth_username = graphene.String()\ndef resolve_auth_username(crawler, info):\n    request_restriction = crawler.get('request_restriction', None)\n    if not request_restriction:\n        return None\n    auth = request_restriction.get('auth', None)\n    if not auth:\n        return None\n    return auth.get('username', None)\n\nclass TaskType(graphene.ObjectType):\n    crawlers = graphene.List(graphene.NonNull(CrawlerType))\ndef resolve_crawlers(data: Plan, info):\n    task = data.task_advance\n    return task.get('crawlers', [])\n\n```\nThen your mutation becomes:\n```python\nclass CrawlerInputType(graphene.InputObjectType):\n    auth_username = graphene.String()\nclass CreateCrawler(graphene.Mutation):\n    class Arguments:\n        task_id = graphene.ID(required=True)\n        crawler = CrawlerInputType()\ntask = graphene.Field(TaskType)\nnew_crawler = graphene.Field(CrawlerType)\n\n``. @yywing any update with this?. Please remember that this library (and most open source libraries) are maintained by people in their free time. If you would like to help us with that then that would be great but there is no need to be rude about it. . @vaskinyy yep I think you're right,iterableis not used on the connection object anymore. I've implemented a customConnectionFieldfor django pagination at work and omitted theiterable` argument and it worked fine. @syrusakbary correct me if I'm wrong.. Also @vaskinyy a PR to remove it would be welcome. @hornedbull there isn't any documentation currently on how to host graphiql in your app though you can follow how graphene-django does it here: https://github.com/graphql-python/graphene-django/blob/fdb7d5a253619df3478832032bf7b340cb6dc97b/graphene_django/views.py#L118-L128\nYou can also use a one of the many standalone graphiql apps: \nhttps://github.com/skevy/graphiql-app\nhttps://github.com/andev-software/graphql-ide\nhttps://github.com/graphcool/graphql-playground. @hornedbull did you manage to get this working?. @ahujamoh I'm sure they would appreciate a PR to update their documentation. @saturdayplace the graphene-django repo is here: https://github.com/graphql-python/graphene-django\nI'm sure a PR to update the documentation would be appreciated.. @nikordaris in your first example it should be default_value=MyEnum.FOO.value. Looks like you're right, there is an issue with representing the a default value of an Enum in graphiql. The issue is probably in https://github.com/graphql-python/graphql-core which is pretty much a direct port of graphql-js. Thanks @nikolas , I'm going to close this issue in favour of the one in the graphql-core repo.. @kavink GraphQL doesn't specify any particular ways of grouping mutations or subscriptions. There is an interesting discussion on it here: https://github.com/facebook/graphql/issues/376\nGenerally it's not useful to try and map traditional CRUD api endpoints to a GraphQL api. Mutations end up being very specific to a particular use case and so are difficult to group anyway.. @jchang10 another approach to resolving interface types is to define a (undocumented) classmethod resolve_type(cls, instance, info) method on the interface. This allows you to resolve the concrete type given some data. So in your example:\npython\nclass UserInterface(graphene.Interface):\n    @classmethod\n    def resolve_type(cls, data, info):\n        if data['type'] == 'human':\n            return Human\n        return Droid\nThen your NotesType would just return the some_init_dictionary in the resolver and (given it has a type attribute`) it would resolve to the correct concrete type. e.g.:\n```python\nclass NotesType(ObjectType):\n    user = graphene.Field(UserInterface)\ndef resolve_user(self, args, context, info):\n    return some_init_dictionary\n\n```\nI've found this very useful when implementing interfaces.. This is a fair point and we should probably change it. @jjmurre do you have time to do a PR for this?. Great idea! Would love to see a PR with this and some tests.\nAlso parse_value should probably return None if it's not a valid Decimal (like how it's done in the datetime types: https://github.com/graphql-python/graphene/blob/05d7e61b844b574f59d68ead86ed40431843d51d/graphene/types/datetime.py#L60-L64). Decimal support has now been merged into master. Thanks @picturedots !. Hi @mingzhou ,\nThere is already an open issue about this https://github.com/graphql-python/graphene/issues/448 where @jasonphillips has example of how it can work https://github.com/graphql-python/graphene/issues/448#issuecomment-356777997\nHowever I don't think that allowing you to build a schema using the DSL is in the scope of this project. Graphene is an opinionated framework on how to build a GraphQL server in Python and so a solution that uses the GraphQL SDL language probably lives outside this project. I would be really interested in seeing a solution to that though.. You can either pass a lambda to graphene.Field or a string import. e.g.:\npython\nclass Query(graphene.ObjectType):\n    current_user = graphene.Field(lambda: User)\n    favorite_pet = graphene.Field('mobileapi.definitions.pets.Pet'). @Allan-Nava did you get this working?. Closing issue until there is more information. @yamila-moreno the reason it's now erroring is that date parsing changed to use the aniso8601 library which is stricter about parsing dates. The example input you've given is a datetime rather than a date which is why it's failing. You can see this in the shell:\n```python\n\n\n\nfrom aniso8601 import parse_date\nparse_date('1991-01-01T00:00:00.000Z')\naniso8601.exceptions.ISOFormatError: \"1991-01-01T00:00:00.000Z\" is not an ISO 8601 date, perhaps it represents a time or datetime.\n```. @Benjaminryejones it looks like it's the node ID's that are duplicated not the cursor values. How are you generating the list of objects for the connection? And how are you generating their ID's?. @globophobe can you raise this issue in the https://github.com/graphql-python/graphene-django repo? . @hornedbull do you have an example of the issue? I can't seem to reproduce it in the following example:\n\n\n\n```python\nimport graphene\nclass TestQuery(graphene.ObjectType):\n    stringify = graphene.String(input=graphene.DateTime(required=True))\ndef resolve_stringify(_, info, input):\n    return input.isoformat()\n\nschema = graphene.Schema(query=TestQuery)\ndef test_issue():\n    query_string = '''\n    query testQuery($input: DateTime!) {\n        stringify(input: $input)\n    }\n    '''\nresult = schema.execute(query_string, variable_values={\n    'input': '2018-04-14T17:03:20+00:00',\n})\n\nassert not result.errors\nassert result.data['stringify'] == '2018-04-14T17:03:20+00:00'\n\n```. @hornedbull any updates?. Closing issue until there is more information. @droudrou looks like there are a couple of issues with your code:\nFirst your TrialResults input type defines lol to be a required input. However the input to your first mutation doesn't have a lol field so it will fail.\nSecond, your object type definition for TrialTypeDefinition should define the lol attribute like this: lol = graphene.Field(TrialArgsOutPut).\nLastly your second mutation needs to have a sub selection when querying the lol field on the TrialTypeDefinition since it is an object type. e.g.:\nmutation toto($param: TrialResults!){\n      createTrialMutation(trialResults: $param) {\n        task\n        kwargs\n        id_\n        lol {\n            data\n        }\n      }\n}\nHope that helps!. I'm not sure I understand what you are trying to do. You want to validate a request from a user? Why can't you just let Graphene do it since it won't accept an invalid request?. Closing issue until there is more information. So I've been thinking about this a lot and I think that being able to define a class to resolve an ObjectType would be quite useful. I've got some working code based on the Mutation class @un33k if you want to include it in your application and see if it works:\n```python\nfrom collections import OrderedDict\nfrom graphene.utils.get_unbound_function import get_unbound_function\nfrom graphene.utils.props import props\nfrom graphene.types.field import Field\nfrom graphene.types.objecttype import ObjectType, ObjectTypeOptions\nfrom graphene.types.utils import yank_fields_from_attrs\nfrom graphene.utils.deprecated import warn_deprecation\nclass FieldResolverOptions(ObjectTypeOptions):\n    arguments = None  # type: Dict[str, Argument]\n    output = None  # type: Type[ObjectType]\n    resolver = None  # type: Callable\nclass FieldResolver(ObjectType):\n    @classmethod\n    def init_subclass_with_meta(cls, resolver=None, output=None, arguments=None,\n                                    _meta=None, **options):\n        if not _meta:\n            _meta = FieldResolverOptions(cls)\n    output = output or getattr(cls, 'Output', None)\n    fields = {}\n    if not output:\n        # If output is defined, we don't need to get the fields\n        fields = OrderedDict()\n        for base in reversed(cls.__mro__):\n            fields.update(\n                yank_fields_from_attrs(base.__dict__, _as=Field)\n            )\n        output = cls\n\n    if not arguments:\n        input_class = getattr(cls, 'Arguments', None)\n        if input_class:\n            arguments = props(input_class)\n        else:\n            arguments = {}\n\n    if not resolver:\n        _resolver = getattr(cls, 'resolve', None)\n        assert _resolver, 'All field resolvers must define a resolve method'\n        resolver = get_unbound_function(_resolver)\n\n    if _meta.fields:\n        _meta.fields.update(fields)\n    else:\n        _meta.fields = fields\n\n    _meta.output = output\n    _meta.resolver = resolver\n    _meta.arguments = arguments\n\n    super(FieldResolver, cls).__init_subclass_with_meta__(\n        _meta=_meta, **options)\n\n@classmethod\ndef Field(cls, name=None, description=None, deprecation_reason=None, required=False):\n    return Field(\n        cls._meta.output,\n        args=cls._meta.arguments,\n        resolver=cls._meta.resolver,\n        name=name,\n        description=description,\n        deprecation_reason=deprecation_reason,\n        required=required,\n    )\n\n```\nYou use it in pretty much the way you want to in your example:\n```python\nclass JwtRefreshQuery(FieldResolver):\n    class Arguments:\n        token = graphene.String(required=True)\ntoken = graphene.String()\n\ndef resolve(self, info, **args):\n    token = refresh_token(args['token'])\n    return JwtRefreshQuery(token=token)\n\nclass Query(graphene.ObjectType):\n    jwt_refresh = JwtRefreshQuery.Field()\n```\nI'm not sure what to call it at the moment or where it might fit in in the project. It might even be that the ObjectType class should be extended to allow this kind of use. Any thoughts @syrusakbary ?. The result object you get back from execute has an errors attribute that contains an array of errors that happened during the execute phase. You can use that to report errors to sentry. E.g.:\npython\nfor error in result.errors:\n    # error is an instance of `GraphQLLocatedError` where the original error\n    # is on the `original_error` attribute\n    try:\n        raise error.original_error\n    except Exception:\n        sentry_client.captureException()\nOr you can configure your logging setup to propagate errors from graphql.execution.executor to sentry. They are logged out here: https://github.com/graphql-python/graphql-core/blob/b3a6bd0f89651af10a937e5270e46c696672a2e5/graphql/execution/executor.py#L314. @BrianChapman I'm not sure I fully understand the question but it's up to you to define whatever fields you might on a type even if the underlying data is a composite one. For example you might define your composite type like this:\n```python\nclass CompositeType(graphene.ObjectType):\n    id = graphene.ID(required=True)\ndef resolve_id(root, info):\n    return '{}:{}'.format(root['id_a'], root['id_b'])\n\n```\nIf you want a globally unique ID (for example for using with Relay) you can use the graphene.relay.Node interface which will give you one.\nHope that helps!. Yep it's totally up you! There is a convention around IDs with Relay since they have to be globally unique. So to ensure that you just base64 encode {Typename}:{ID} and use that as the ID. It's quite a good pattern to follow generally since it indicates to the client that they should try and generate the ID field. . @BrianGenisio did I manage to answer your question? Can this issue be closed if I did?. @j-robin-hunter have you tried moving the data fetching to the level above the Heating type so that you can do it at the same time? For example:\n```python\nclass Query(graphene.ObjectType):\n    heating = graphene.Field(Heating)\ndef resolve_heating(_, info):\n    water_heater = get_water_heater_load()\n    space_heater = get_space_heater_load()\n    total = water_heater + space_heater\n    return {\n        'water_heater': water_heater,\n        'space_heater': space_heater,\n        'total_load': total,\n    }\n\n```. @j-robin-hunter how did it go?. Closing issue because I think it's solved. Will reopen if it's still a problem. . @Fohlen it looks like your mutation is query is wrong. It should be:\nmutation ($email: String!) {\n   creatInvitation(email: $email) {\n       invitation {\n           creationDate\n      }\n   }\n}\nNotice that the argument to the mutation comes first and then the variable you are passing to the mutation: createInvitation(email: $email)\nDid you construct the mutation in the GraphiQL browser or just by hand?. Also the error is not very helpful and should be better. Any help with that would be really appreciated!. @Fohlen I can't reproduce your error. I've tried here: https://github.com/graphql-python/graphene/compare/issue-719\nCan you make a failing test case?. Do you have the rest of the code? Might be related to graphene Django . So the issue comes from this:\npython\ninvite = Invitation.objects.create(\n    creator=info.context.user,\n    email=email\n)\nThe Invitation model has no field email so it's throwing an error. \nI'm not sure why you can't see it in your traceback but in mine I can see:\nFile \"/Users/jk/code/virtualenvs/failing-graphene-build/lib/python3.6/site-packages/django/db/models/query.py\", line 415, in create\n    obj = self.model(**kwargs)\n  File \"/Users/jk/code/virtualenvs/failing-graphene-build/lib/python3.6/site-packages/django/db/models/base.py\", line 495, in __init__\n    raise TypeError(\"'%s' is an invalid keyword argument for this function\" % kwarg)\nTypeError: 'email' is an invalid keyword argument for this function. Seems like an oversight. Could you create a PR with some tests @mcakes ?. It's currently not possible but there is an ongoing debate in the graphql-js repo about it: https://github.com/graphql/graphql-js/issues/207\nI think it's probably more complexity than it's worth and I agree with Lee here: https://github.com/graphql/graphql-js/issues/207#issuecomment-243639236 . @ProstoMaxim you can validate the input inside the mutate method of the mutation. This gives you the opportunity to resolve a mutation with different error types depending on what can be expected to go wrong. For example:\n```python\nclass CreateNumberTooLargeError(graphene.ObjectType):\n    message = graphene.String(required=True)\nclass CreateNumberTooSmallError(graphene.ObjectType):\n    message = graphene.String(required=True)\nclass CreateNumberSuccess(graphene.ObjectType):\n    number = graphene.Int(required=True)\nclass CreateNumberPayload(graphene.Union):\n    class Meta:\n        types = (\n            CreateNumberSuccess,\n            CreateNumberTooSmallError,\n            CreateNumberTooLargeError,\n        )\nclass CreateNumberMutation(graphene.Mutation):\n    class Arguments:\n        number = graphene.Int(required=True)\nOutput = CreateNumberPayload\n\ndef mutate(self, info, number):\n    if number > 10:\n        return CreateNumberTooLargeError(message=\"Number is too large\")\n    if number < 5:\n        return CreateNumberTooSmallError(message=\"Number is too small\")\n    return CreateNumberSuccess(number=number)\n\n```\nThis way the client knows exactly what went wrong by just looking at the response type.. I'm not very familiar with relay.ClientIDMutation. Why are you using it?. @samuelvillegas did you mean to open this issue in the graphene-django repo?. Closing issue until there is more information. @syrusakbary I can't merge, I need write access to do that.. This has been released in v2.1.1. @picturedots you'll need to setup a virtualenv with python 2.7 Then run the commands in the contributing section in the readme: https://github.com/graphql-python/graphene#contributing\nLooks like the flake8 (for linting) is not included in the requirements so you'll need to install it first before running it.. Also thanks for the PR! It's looking great. @syrusakbary merge whenever you're happy. @Arlus graphene doesn't know anything about sessions. It doesn't even need to be run in an HTTP context. How are you integrating graphene into your web application?. Closing issue until there is more information . Hi @bellomusodiq , you can find instructions on how to set up subscriptions in the graphql-ws repo. You can try it out in the GraphiQL browser or use a compatible client library like Relay or Apollo. There is an example of how to setup subscriptions in Django with Django Channels: https://github.com/graphql-python/graphql-ws#django-channels. I really like this @ocavue ! I had no idea you could do this python annotations. I don't know much about annotations actually but I have a couple of questions:\n\nHow would ObjectTypes work?\nCould you use both ObjectTypes and AnnotatedObjectType's in the same schema?\nIs there anything that can be expressed in the python type system that can't be expressed in GraphQL (or vice versa)?\n\nI think keeping the ObjectType and AnnotatedObjectType separate is essential, not just for keeping python 2.7 compatibility, but also supporting both ways of writing ObjectTypes.. Thanks for the answers.\n\nHow would ObjectTypes work?\n\nI meant could you do something like this:\n```python\nclass Heroine(AnnotationObjectType):\ndef best_friend(root, info) -> Person:\n    if only_first_name:\n        return [self._first_name]\n    return [self._first_name, self._last_name]\n\n```\nwhere Person is a normal ObjectType or an Interface\n\nAlso I thought of another question: How would you define fields that don't need a resolver?\nCurrently if you have:\nclass User(ObjectType):\n    name = graphene.String(required=True)\nand it gets passed an object with an attribute name it will just use grab that data and use it without the need for a resolver. How would you do that with AnnotatedObjectType?. @nerdyator I'm not sure I understand what the issue is exactly. What are you trying to achieve?\nIf you want to setup a Relay connection (in the format of how relay expects them: https://facebook.github.io/relay/graphql/connections.htm) then you can use the graphene.relay.Connection class: http://docs.graphene-python.org/en/latest/relay/connection/. @nerdyator I'm going to close this issue for now. If you can provide more info on the problem you are having then I'll happily reopen it.. This behaviour is correct according to the GraphQL docs: http://graphql.org/learn/schema/#lists-and-non-null\nAn empty list is a non-null value so it should be accepted by the schema definition you have.. I don't think this is really necessary since (as you can see from the diff) the only place that is using requirements.txt is the docs and it's barely using it. I don't think it's worth introducing another pre-commit config for this.. Any reason why you prefer having the test requirements in a requirements-dev.txt file and not in the setup.py as they currently are?. Thanks!. Since it\u2019s a breaking change it should probably be part of a 3.0 release (instead of 2.2 as I suggested earlier). Do you agree @graphql-python/governors ?. @marcelombc just to clarify you want to avoid having to do:\npython\n_, _id = relay.Node.from_global_id(id)\n_, _property_id = relay.Node.from_global_id(property_id)\ninside your resolvers. Is that right?\nAt the moment there isn't a way in Graphene of defining an argument as specifically a Relay ID and getting it to decode the ID automatically. I don't really have to time now to figure out how to do it but if you would like to contribute one that would be great!\nAt my work we have found a work around using a decorator that cleans up our code a bit:\n```python\ndef unmask(config):\n    def unmask_decorator(func):\n        def unmask_wrapper(obj, info, kwargs):\n            for arg_name, kls in config.items():\n                if kwargs[arg_name]:\n                    schema_type, unmasked_id = relay.Node.from_global_id(kwargs[arg_name])\n                if schema_type != kls._meta.name:\n                    kwargs[arg_name] = None\n\n                kwargs[arg_name] = unmasked_id\n        return func(obj, info, **kwargs)\n    return unmask_wrapper\nreturn unmask_decorator\n\n```\nYou can then use it like this:\npython\n@unmask(id=Room, property_id=Property)\ndef resolve_room(root, info, id, property_id, **kwargs):\n    return rooms_loader.load(\n        {'context': info.context, 'id': int(property_id)}\n    ).then(lambda rooms: [\n        item for item in rooms if item.id == int(id)\n    ][0]). Btw you don't need to decorate your resolvers with @staticmethod either. Ah ok sorry, I think I see where the misunderstanding comes from now.\nRelay is only one option with working with GraphQL on the client (others include Apollo as you mentioned and even slimmer clients like urql). Graphene supports all of these options out of the box and it also provides several helper classes to support Relay specifically (everything in the graphene.relay namespace).\nThe bit thats probably confusing you is that in the old version of Relay (relay-classic) it assumed that your GraphQL schema was setup in a particular way. For example it assumed you had a node field in the root query that allowed relay-classic to refetch a particular node whenever it needed to. This is what relay.Node.Field is for (more information can be found on the relay docs). With the new version of Relay (relay-modern) most of this is optional so you don't have to implement any of it in your schema.\nHaving said that you might still want to implement some of the relay schema patterns such as the node field and the connections specification because they turn out to be very useful even if you are not using relay. If that is the case then you can use the graphene.relay part of the graphene library but it is not required to start using GraphQL on your client.\nI hope that clears some things up \ud83d\ude42 . I don't think you should try and overload the graphene.relay.Node.Field class to try and accept arbitrary arguments since the class is there for a specific purpose which is to implement the root node field.\nIf your data model is such that there is no way to get a room without going through a property then I would create a room_by_id field on the Property type and have a top level property_by_id field that fetches the room. The schema would look like this:\n```graphql\ntype Query {\n    propertyById(id: ID!): Property!\n}\ntype Property {\n    roomById(id: ID!): Room!\n}\n```. Sure it's totally up to you. What I would say is that the best way to architect your schema is to think about what makes the most sense for how the front end client wants to use the data. You can always improve efficiency in the backend but if your client has to work around types or fields that don't make sense to how the data is actually being used then you might as well be using a traditional REST api.\nAnyway I'm going to close this issue as it doesn't seem like there is anything that needs to change in Graphene.. @dan98765 do the contributing docs need to be updated now to recommend using tox? Also would be good to align the pytest command in the tox.ini with the one in the .travis.yml: py.test --cov=graphene graphene examples. Yep totally agree. Just waiting for @syrusakbary to approve and then this PR can be merged.. @dan98765 you didn't answer my question as to why this structure is better than the current one? I'm not convinced this is clearer for new starters.\nI'm fine with removing the test command in setup.py since I expect most people are familiar with just running pytest directly. I like the Makefile for helper steps but I don't think it should be creating a virtualenv for you. Outlining that you should probably be creating a virtualenv when developing should be part of the README.\nGenerally people should be able to get started in a couple of simple steps but I think that is already the case. So I'm happy to accept some small changes to the setup.py (like dropping the test option) and the introduction of the Makefile to help with some commands like installing pre-commit hooks, but I'm not going to approve a large change like this since I don't think it provides much benefit.. Thanks @dan98765 !. @impowski the relay.Node.Field is meant to implement a field that you fetch by using the relay id. If you would like to be able to find a user using other criteria you will have to implement your own field resolver. For example:\n```python\nclass Query(graphene.ObjectType):\n    user = graphene.Field(UserType, username=graphene.String(required=True))\n    all_users = DjangoFilterConnectionField(UserType)\ndef resolve_user(root, info, username):\n    return UserModel.objects.get(username=username)\n\n```. @impowski what version of graphene are you using? The new api for resolvers is:\npython\ndef resolve_user(self, info, **args):\n    username = args.get('username')\nYou can find more information here: https://github.com/graphql-python/graphene/blob/master/UPGRADE-v2.0.md. @impowski I'm going to close this issue now. Please do post any updates you have here for posterity.. @altaurog graphene is powered by graphql-core which is an almost direct port of the graphql-js library for node. graphql-core doesn't support null yet but there is an open issue (https://github.com/graphql-python/graphql-core/issues/118) and a potential pull request open (https://github.com/graphql-python/graphql-core/pull/172) for it.\nI'm going to close this issue in favour of tracking progress in the graphql-core repo.. @paunovic you can do the authentication at the mutation level. In the def mutate function you can inspect the request context and determine if the user is allowed to perform that mutation. You would also define what error gets returned if the user is not allowed to perform the mutation.\nAt work use the following decorator to remove some of the boilerplate code from the mutate function:\npython\ndef anonymous_return(value):\n    def anonymous_return_decorator(func):\n        def anonymous_return_wrapper(obj, info, **kwargs):\n            if not info.context.user.is_authenticated():\n                if callable(value):\n                    return value()\n                return value\n            return func(obj, info, **kwargs)\n        return anonymous_return_wrapper\n    return anonymous_return_decorator\nAnd we have a common AuthenticationError type which looks like this:\n```python\nclass AuthenticationRequired(graphene.ObjectType):\n    message = graphene.String(\n        required=True,\n    )\n@staticmethod\ndef default_message():\n    return AuthenticationRequired(\n        message=\"You must be logged in to perform this action\"\n    )\n\n```\nThen our mutations look like this:\n```python\nclass AddCredit(graphene.Mutation):\n    class Arguments:\n        amount = graphene.Int(required=True)\nOutput = AddCreditPayload\n\n@anonymous_return(AuthenticationRequired.default_message)\ndef mutate(self, info, amount):\n    # User is authenticated now\n\n```\nYou can of course expand on this to build in any kind of arbitrary permission logic but this is a basic example. . @ZZHHAANNGG this looks like http://localhost:8000/graphql is returning html and not JSON which is what the apollo-codegen tool is expecting.\nWhat happens if you run the following in a terminal?\ncurl --request POST http://localhost:8000/graphql/. Ok thats your issue then. You need to mark your /graphql endpoint as exempt from CSRF protection. You can do this by wrapping the view in the csrf_exempt decorator like this:\n```python\nurls.py\nfrom django.views.decorators.csrf import csrf_exempt\nurlpatterns = [\n    url(r'^graphql$', csrf_exempt(GraphQLView.as_view(schema=schema))),\n]\n```\nThere is more information in the Django documentation: https://docs.djangoproject.com/en/2.0/ref/csrf/#module-django.views.decorators.csrf. @CreatCodeBuild yep this is on purpose - by default Graphene will auto convert to camelCase since that is the convention in JS/mobile clients which are likely to consume the api. You can turn this off at a schema level by passing auto_camelcase=False to the Schema constructor. Or you can override the name at a field level by passing name='appears_in' to the graphene.List constructor. You can find out more here: http://docs.graphene-python.org/en/latest/types/schema/#auto-camelcase-field-names. @keyeMyria I'm cleaning up old issues that haven't had any activity for a while. If this is still an issue the issue can be reopened.. @benwis when using the test client you can pass context_value to the execute call: http://docs.graphene-python.org/en/latest/testing/#execute-parameters\nThat allows you to pass authorization headers to the query execution.. @kawasakikou I'm not sure that what that error is. Can you provide a reproducible example?. @syrusakbary you're going to have to merge since at least 2 reviews are required and I can't review it myself.\n\n. @lee-flickswitch can you show me your def mutate(...) function? Because I can't reproduce your issue? Also what graphene version are you using?. Yep so because airtime_amount is an optional field, when it is not provided in your mutation it won't be passed to your mutate function and that is causing the error. Replace your mutate function def with:\npython\ndef mutate(root, info, msisdn, network_id, **kwargs):\n    product_id = kwargs.get('product_id', None)\n    airtime_amount = kwargs.get('airtime_amount', None)\nThe reason why it's not passed to your mutate function if it's not defined is so that you can differentiate between it being 'undefined' and it being null.. @patrys I think you can achieve this using middleware. I'd imagine you set up some counter in the execution context and then increment it in the middleware. I've not actually tried this though but if you're willing to try it out do let us know how it goes.. @dan98765 I found this comment that implies that you already have something working? Could you share how you do it?. Ah sorry I missed that part. As far as I know there isn't an \"official\" way of doing this but I've been playing around with then new backends feature that @syrusakbary introduced in graphql-core (https://github.com/graphql-python/graphql-core/pull/185) and I think this would be a great use case for it.\nYou should be able to do something like this with graphql-core 2.1rc:\n```python\nfrom graphql.backend.core import GraphQLCoreBackend\ndef measure_depth(selection_set, level=1):\n    max_depth = level\n    for field in selection_set.selections:\n        if field.selection_set:\n            new_depth = measure_depth(field.selection_set, level=level + 1)\n            if new_depth > max_depth:\n                max_depth = new_depth\n    return max_depth\nclass DepthAnalysisBackend(GraphQLCoreBackend):\n    def document_from_string(self, schema, document_string):\n        document = super().document_from_string(schema, document_string)\n        ast = document.document_ast\n        for definition in ast.definitions:\n            # We are only interested in queries\n            if definition.operation != 'query':\n                continue\n        depth = measure_depth(definition.selection_set)\n        if depth > 3: # set your depth max here\n            raise Exception('Query is too complex')\n\n    return document\n\n```\nThen when you're executing the following query it will bail out before trying to execute the query:\n```python\nquery_string = '''\n    query {\n        myFavouriteBook {\n            author {\n                bestBook {\n                    author {\n                        name\n                    }\n                }\n            }\n        }\n    }\n'''\nbackend = DepthAnalysisBackend()\nschema = graphene.Schema(query=Query)\nresult = schema.execute(query_string, backend=backend)\nassert result.errors\n```\nI think there is a lot more that could be done here (like being able to assign complexity values to each field) but hopefully this helps you for now.. Closing this issue in favour of tracking multiple approaches to protecting against malicious queries in #907 . @ocavue what version of graphene are you using? Because you should already be able to do this.\nThe following sets the description on the id argument fine for me:\n```python\nclass Query(graphene.ObjectType):\n    user = graphene.Field(\n        User,\n        required=True,\n        id=graphene.Int(required=True, description=\"user's id with hex formatting\")\n    )\ndef resolve_user(self, info, id):\n    return loaders.get_user_by_id_loader.load(id)\n\n``. @ccsv can you raise this issue on https://github.com/graphql-python/graphene-django ? I'm sure a PR fixing the documentation error would be appreciated as well.. @xiaohanghangList` types can only represent lists and can't have any other attributes so what you're trying to do in the example is not possible.\nYou could model it by using an ObjectType to store totalCount like this:\n```\ntype Query {\n    allUsers: AllUsersConnection\n}\ntype AllUsersConnection {\n    totalCount: Int!\n    edges: [User]\n}\ntype User {\n    id: ID!\n    name: String!\n}\n```\nand so your query would look like this:\nquery {\n    allUsers: {\n        totalCount\n        edges: {\n            id\n            name\n        }\n    }\n}\nThe Graphene code to model the above would look like this:\n```python\nclass User(graphene.ObjectType):\n    id = graphene.ID(required=True)\n    name = graphene.String(required=True)\nclass AllUsersConnection(graphene.ObjectType):\n    total_count = graphene.Int(required=True)\n    edges = graphene.List(User)\nclass Query(graphene.ObjectType):\n    all_users = graphene.Field(AllUsersConnection)\n```\nI'll leave the implementation of the resolvers up to you.\nHope that helps! You might also want to look at the Relay Connections Spec which codifies a way of defining connections and is a good pattern to follow even if you don't use relay.. Glad I could help!. @keyeMyria no plans that I'm aware of. What do you think the validation could look like?. I'm not familiar with WTForm so you're going to have to help me out with what you're looking for. Do you have an example api that you think would work? . That would be a great addition to the docs! https://github.com/graphql-python/graphene#documentation has some instructions on how to update the docs locally. Could you add something?. @keeth as far as I know there isn't a solution for response deduplication in the graphene ecosystem. I would love for someone to build one though!\nIt looks like you should be able to build something standalone that just takes the response from execute. \nE.g.:\npython\nresult = schema.execute('...')\ndeduped_data = deflate(result.data)\n. @keeth I've implemented both graphql-crunch (https://github.com/graphql-python/graphene/pull/787) and graphql-deduplicator (https://github.com/graphql-python/graphene/pull/786) in python. I didn't see any benefit on the queries we use at work but try them out and let me know if you see any benefits.. @femesq you and @keeth made me curious about how you could add deduplication to graphene so I reimplemented graphql-deduplicator in python: https://github.com/graphql-python/graphene/pull/786\nIt's a pretty simple algorithm and it should work with the corresponding JS inflate method. It also doesn't need a middleware - it can all be applied after the execution phase. Unfortunately it doesn't seem to help much with any of our queries at work but hopefully it's useful for someone.. Closing this since the deduplicator functionality is now available in 2.1.3. @danpalmer totally agree would this and would love to see a PR which takes us in this direction . That would be great @Kacppian !. @wilk your query should look like this:\ngql\n{\n      allServices {\n        id\n      }\n}\nNotice the lack of (). @keyeMyria please don't open multiple issues on the same topic. Let's keep the discussion in #777 . What does the photos field that you get back from db.users.find_one(dict(_id=_id)) look like? By default Graphene uses getattr to pick off fields from a data object.. You could change the default resolver on the Photo Object type like this:\n```python\nfrom graphene.types.resolver import dict_resolver\nclass Photo(graphene.ObjectType):\n    class Meta:\n        default_resolver = dict_resolver\nid = graphene.ID()\nurl = graphene.String()\nfileName = graphene.String()\nextension = graphene.String(). Yep I agree. A PR would be welcome if you have the time . Also I have a PR #638 which should mean by default graphene would handle dicts and objects transparently . @xiaohanghang did you resolve your issue?. @lgants sorry for not getting back to you sooner on this. Can you include the python code for your `addPost` mutation? It looks like the output of that mutation is not a `Post` type which is why your fragment is failing.. @lgants I'm going to close this issue since you haven't responded to it so I'm going to assume it's been resolved. If it is still an issue then please reply with more information and I'll reopen this.. It looks like this is issue has been resolved now.. In JavaScript the `invariant` function is quite commonly used (https://github.com/zertosh/invariant) and I've found that I makes my code more readable. Would changing the method name to be more concise help? . I agree that the unwrapped form is the one to go for because it's unambiguous and requires no extra\n\ndomain knowledge. However I do think it hurts readability because it draws attention to what are just sanity checks. IMO the best form is the assert one, it's just a shame that python doesn't respect it in production environments!. @charlesverdad I think you're right but I don't have time to verify it right now. The place to fix it would be here: https://github.com/graphql-python/graphene/blob/c40ce98bb8a82a73d673e5d14bb5ccd2ccdfb1a6/graphene/types/mutation.py#L88\nThat line probably needs to become:\npython\ndescription=description or cls.__doc__\nCould you create a PR with the change and some tests to go along with it? There is also a trim_docstring utility function that you might find useful: https://github.com/graphql-python/graphene/blob/master/graphene/utils/trim_docstring.py. Closing since this is resolved now (thanks @cherls !). @Fity you need to do:\npython\nassert MyEnum.TypeA.value == big_value\nassert MyEnum.TypeB.value == big_string. @Fity I think the graphene Enum follows the same behaviour as the Python Enum class (https://docs.python.org/3/library/enum.html#comparisons)\n```python\nfrom enum import Enum as PyEnum\nbig_value = 99999999999999\nbig_string = 'hello' * 100\nclass MyEnum(PyEnum):\n    TypeA = 99999999999999\n    TypeB = \"hello\" * 100\nassert MyEnum.TypeA == big_value\nassert MyEnum.TypeB == big_string\n```\nThe assertions in the above code will also fail. I think it would be more confusing if the Graphene Enum didn't behave in a similar way to the Python Enum don't you agree?\nAlso I'm not sure what you mean when you say MyEnum.TypeA == small_value works? What is small_value?. Ah I didn't know about that. Thanks!. @leebenson good spot! Could you submit a PR that fixes it? You can find instructions on how to build the docs in the README: https://github.com/graphql-python/graphene#documentation. It doesn't look like this is supported in the spec: https://github.com/facebook/graphql/issues/197\nI'll close this issue for now but we can revisit it once the spec is updated.. Hi @elmehalawi , it looks like your issue is with the Django integration with graphene so you are better off posting your issue on that repo: https://github.com/graphql-python/graphene-django. @ProjectCheshire great comment and I would be very interested to see what you think an outline for the docs would look like.\nJust so you're aware though there is currently quite a bit of uncertainty with the maintenance of this project (see https://github.com/graphql-python/graphene/issues/884#issuecomment-456995174) and the community is waiting on @syrusakbary to provide a clear plan going forward. Until then it's unclear how anything (like the website) gets updated so any contributions might take a while to be accepted.. Looks like @robhobbes answered your question @StevenXue (thanks @robhobbes !) Closing this issue.. @romaia you can lazily reference other types by using a lambda function like this:\n```python\nclass Sale(ObjectType):\n    items = List(lambda: SaleItem)\nclass SaleItem(ObjectType):\n    sale = Field(Sale)\n```\nYou can also specify a full import path as a string (like Django):\n```python\nThis file is api/definitions/sale.py\nclass Sale(ObjectType):\n    items = List('api.definitions.sale.SaleItem')\nclass SaleItem(ObjectType):\n    sale = Field(Sale)\n``. You're welcome @mikebobadilla . Glad I could help!. @robhobbes @johnnymetz : @ekampf is correct.contextis the way to inject data that each resolver can access.. @zhammer does that not work? I would expect it to work.. @japrogramer theinfoarg is part of the execution context and is created when the schema is executed. The object is defined here in graphql-core: https://github.com/graphql-python/graphql-core/blob/master/graphql/execution/base.py#L66. @F-Chaudhry this looks like an issue with datetimes and not a Graphene issue. I would recommend asking this question on StackOverflow.. @getglad I think the issue is that you're assuming that you only need to define one resolver for how to getAccountregardless of where it is needed in the schema. That won't work because although the resolver will always return the same type (Account`) it won't always get the instance of that type in the same way.\nFor example if you want to be able to access an Account type by it's name at the top level of your query then you set up the resolver that you have:\n```python\nclass Query(graphene.ObjectType):\n    account = graphene.Field(\n        Account,\n        account_name=graphene.String(default_value=None),\n        account_id=graphene.String(default_value=None)\n    )\ndef resolve_account(root, info, account_name=None, account_id=None):\n    # get Account by account name or account id\n    inventory = get_inventory()\n\n    result = [i for i in inventory if (\n        (i.account_id == account_id) or \n        (i.account_name == account_name)\n    )]\n    return result[0] if len(result) else Account()\n\n```\nThen you can query it like this:\njs\n{\n  account(accountName:\"foo\") {\n    accountName\n    accountId\n  }\n}\nHowever if you are getting an account that is associated with another type (like with Item) then the resolver needs to be different because the way that it finds the right account is fundamentally different.\nFor example:\n```python\nclass Item(graphene.ObjectType):\n    item_name = graphene.String()\n    account = graphene.Field(Account)  # <= Note I am not setting up any extra arguments here\ndef resolve_account(\n    item,  # <= the first argument is object that is returned from the parent resolver\n    info,\n    item_name=None\n):\n    account_id = item.account_id\n    inventory = get_inventory()\n\n    result = [i for i in inventory if (\n        (i.account_id == account_id)\n    )]\n    return result[0] if len(result) else Account()\n\nclass Query(graphene.ObjectType):\n    item = graphene.Field(\n        Item,\n        item_name=graphene.String(default_value=None)\n    )\ndef resolve_item(root, info, item_name=None):\n    inventory = get_inventory()\n\n    result = [i for i in inventory if (\n        (i.item_name == item_name)\n    )]\n    return result[0] if len(result) else Item()\n\n```\nThen you can query it like this:\njs\n{\n  item(itemName: \"bar\") {\n    itemName\n    account {\n      accountId\n      accountName\n    }\n  }\n}\nI hope that makes sense!. @getglad did my comment solve your issue? . @ahokinson you can pick apart and customise exactly how to get the page info by returning an instance of the relay.Connection type in the connection resolver. A relay.Connection is just an extended ObjectType. So for example (carrying on with @dvndrsn 's example):\n```python\nimport graphene\nfrom graphene import relay\nclass Post(graphene.ObjectType):\n    id = graphene.ID()\n    title = graphene.String()\nclass PostConnection(relay.Connection):\n    class Meta:\n        node = Post\nclass Query(graphene.ObjectType):\n    posts = relay.Connection(PostConnection)\ndef resolve_posts(_, info, **args):\n    first = args.get('first')\n    last = args.get('last')\n    after = args.get('after')\n    before = args.get('before')\n\n    # Get relevant posts using the pagination info above\n    posts = get_posts(first, last, after, before)\n\n    edges = [\n        PostConnection.Edge(\n            node=node,\n            cursor=cursor_string_from_node(node)\n        )\n        for node in edges\n    ]\n\n    total_length = get_posts_count()  # Here you can optimise how you get the count\n\n    page_info = relay.PageInfo(\n        has_next_page=(total_length > first),\n        has_previous_page=False,  # This can be quite hard to determine so you can just ignore it\n        start_cursor=edges[0].cursor,\n        end_cursor=edges[-1].cursor,\n    )\n\n    return PostConnection(\n        edges=edges,\n        page_info=page_info,\n    )\n\n```\nYou'll have to build your own functions for get_posts, get_posts_count and cursor_string_from_node but that should mean that you can start optimising exactly how the connection gets the page info.. @ahokinson did my answer resolve your question? . @ahokinson I'm going to close this issue since there hasn't been any activity on it for a couple of months. Feel free to comment if this is still a problem and I'll reopen it.. @antoine-gallix you might want to submit this issue to the graphene-sqlalchemy repo. Otherwise if it's not specific to that library can you please include a way to reproduce the issue?. There is a link to the sqlalchemy project in the README: https://github.com/graphql-python/graphene#integrations\nI'm not sure it can be much more prominent than that \ud83d\ude42 Anyway I'm glad you solved your issue.. @antoine-gallix the recommended pattern with handling authorization in GraphQL servers (not just Graphene) is to delegate it to the business logic layer. See: https://graphql.org/learn/authorization/\nI'm not sure trying to handle authorization in the middleware layer is going to work very well unfortunately.. @ckristhoff it looks like you're grabbing FILES from the context object so it's probably a request object. You'll need to replicate that in your test case as well (or at least create a mock object with a FILES property). @ckristhoff in your example code you're passing the context in the test as a dictionary:\npython\ncontext = {\n    \"img1.jpg\": tempfile.NamedTemporaryFile(suffix=\".jpg\"),\n    \"img2.jpg\": tempfile.NamedTemporaryFile(suffix=\".jpg\")\n}\nThat context needs to be the same as a Django request object (I'm assuming you're using Django) for it to work. You can use the RequestFactory to get an object that will match what you need.\nIf that still doesn't work then if you could create a simple reproduction of the issue that would help a lot.. @ckristhoff I created a fix here: https://github.com/ckristhoff/graphene-test-uploads/pull/1\nI\u2019m going to close this issue now. If you are still having problems add a comment and I can reopen it. . @DrPyser there aren't any plans at the moment as far as I'm aware. I would be interested to see any solution that you come up with though! . Great news! I'd be happy to help out. Email: hello@jkimbo.com. For people not in the Slack group: @syrusakbary is organising a meeting on March 6th to discuss possible governance models and next steps. Doesn't look like anything will change until then.. @chirag-shah1 yes definitely! Graphene (and a core part of and GraphQL server) is that it is agnostic to where the data underlying each field lives and how it is fetched. So for example say we have the following schema:\n```\ntype Post {\n    title: String!\n    content: String!\n    relatedPosts: [Post]\n}\ntype Query {\n    searchPosts(searchTerm: String!): [Post]\n}\n```\nand say that to search for posts you are using Elasticsearch but the actual posts are stored in Mysql with Django. You could build your server like this:\n```python\nimport graphene\nfrom blog.models import Post as DjangoPost  # your Django model\nclass Post(graphene.ObjectType):\n    title = graphene.String(required=True)\n    content = graphene.String(required=True)\n    date_published = graphene.DateTime(required=True)\n    related_posts = graphene.List(Posts)\ndef resolve_related_posts(post, info):\n    related_posts = get_related_posts(post.id)  # Query Elasticsearch for related posts\n    return related_posts\n\nclass Query(graphene.ObjectType):\n    search_posts = graphene.List(Post, search_term=graphene.String(required=True))\ndef resolve_search_posts(_, info, search_term):\n    relevant_posts = find_posts(search_term)  # Get all the relevant posts from Elasticsearch\n    post_ids = [post['id'] for post in relevant_posts]\n    posts = DjangoPost.objects.filter(id__in=post_ids)\n    return posts\n\n```\nAs you can see the graphql server is querying multiple data sources and even combining multiple data sources into one to satisfy a client query.\nHope that helps!. FYI there was some interesting discussion on using type annotations to actually define the schema in a this issue: https://github.com/graphql-python/graphene/issues/729. Yes you're right. The code should be:\n```python\nclass Query(graphene.ObjectType):\n    user = graphene.Field(User, id=graphene.ID(required=True))\ndef resolve_user(_, info, id):\n    return get_user_by_id(id)\n\nschema = graphene.Schema(Query)\nresult = schema.execute(\n    '''query getUser($id: ID) {\n        user(id: $id) {\n            id\n            firstName\n            lastName\n        }\n    }''',\n    variables={'id': 12},\n). @prasanthvajja this looks like a https://github.com/graphql-python/graphene-django issue. If this is still a problem you'll need to create an issue in that repo.. @nkjmr you can use the name attribute to override the name of the field. So:\npython\nclass Edge(graphene.ObjectType):\n    _from = graphene.Int(name='from')\n    to = graphene.Int(). @lucascharlesz there isn't any magic in Graphene that would interfere with the mocking of Foo so I would guess that your patch is not working. When patching objects in python you need to make sure you patch the callsite and not the definition site. E.g. @patch('schema.Foo') not @patch('mymodels.Foo)`. No worries, we all make mistakes! Glad I could help. . @pawarchinmay27 can you provide a more complete example of what you are trying to do?. So the output of the resolve method is passed to the next level down in the tree and it can be of any shape as long as the next level understands it. So in your case you can do:\n```python\nclass Instance(graphene.ObjectType):\n    products = graphene.List(Product)\ndef resolve_products(instance, info):\n    # instance looks like:\n    # {\n    #   'products': ['abc', 'def'],\n    #   'name': 'Instance name',\n    # }\n    return [\n        {\n            'productName': product,\n            'instanceName': instance['name'],\n        } for product in instance['products']\n    ]\n\nclass Product(graphene.ObjectType):\n    productName=graphene.String()\n    productDependecies=graphene.List(ProductDependency)\ndef resolve_productDependencies(product, info):\n    instance_name = product['instanceName']\n\n``. @pawarchinmay27 it would help if you could give me a way to reproduce your error. Also did you try and use the code that I suggested? Did it not work?. @pawarchinmay27 you're returning aProductobject at the end of yourresolve_productsfunction. That object is then being passed as theselfparameter to theresolve_productDeproductDependenciesfunction and so when you try and printself['instanceName']it's not working becauseself` is an object and not a dict. You can change the code to:\npython\n    def resolve_productDeproductDependencies(self,info):\n        print(self.instanceName)\nTo debug issues like this I would recommend using something like pdbpp to debug what values you are getting in the resolver function.\nAlso in future it would help if you could provide a full working example of your issue (maybe in the form of a github repo) or just try the solution that I provided to you first.. There is an open PR that fixes this: https://github.com/graphql-python/graphene/pull/775\nHowever because it's a breaking change it will have to be part of a v3 release.. @episodeyang could you not use the String type of this? And then do the deserialization in the client?. @Arfey this is an area where there aren't any official answers in Graphene at the moment but I'll give you my opinion on the approaches that you've listed:\n1 and 2: query cost or resource limitations + limiting query depth\nIn another issue I've written up some sample code (not thoroughly tested) that will implement a basic max query depth check: https://github.com/graphql-python/graphene/issues/772#issuecomment-400094405 Something similar could be used for query cost calculations but it's unclear to mean how you would determine the cost of particular fields.\nI think there is opportunity for experimentation in user space for this.\n3. query whitelisting\nThe backend functionality is also the place to implement any kind of persisted/query whitelisting. I actually don't think this feature is within the scope of the Graphene project though because it's going to be tightly coupled to the rest of your application. You would need to define where the persisted queries are stored, how the front end part of your app adds new queries, how your server interprets static queries etc. Again this is a place where experimentation can happen in userland and Graphene already exposes the right hooks through backends to implement it.\n4. hide introspection for production mode\nThis sounds like a reasonable suggestion and I think it could be implemented. Any thoughts @graphql-python/core @graphql-python/governors ?. @claradaia unfortunately it doesn't look like this is possible. Graphene delegates the actual validation part to the graphql-core and I'm not sure exactly where the validation happens. I'll do some more digging but I'm pretty sure at the moment what you're asking for is not possible.\nOne workaround would be to test the schema with your input type to check if it works. For example:\n```python\nfrom mytypes import MyInputType  # <- this is the input type you want to test\nclass TestMutation(graphene.Mutation):\n    class Arguments:\n        input = MyInputType()\nok = graphene.Boolean()\n\ndef mutate(root, info, **args):\n    return TestMutation(ok=True)\n\nclass TestQuery(graphene.ObjectType):\n    name = graphene.String(default_value=\"Dave\")\nclass MyMutations(graphene.ObjectType):\n    input_type_test = TestMutation.Field()\nschema = graphene.Schema(query=TestQuery, mutation=MyMutations)\ndef test_input_type():\n    query_string = \"\"\"\n    mutation testMutate($input: MyInputType!) {\n        inputTypeTest(input: $input) {\n            ok\n        }\n    }\n    \"\"\"\nresult = schema.execute(query_string, variables={\n    'input': {\n        'some': 'data',\n        'more': 'data',\n    }\n})\n\nassert not result.errors\n\n```\nYou can probably abstract most of that code into a test helper.. @michelecocuccio this issue doesn't seem related to graphene. Are you sure that adding the path for graphql/ is the reason your static assets are missing the /media/ path?. @slorg1 you're probably right about moving the snake case translation into get_order as that is probably cleaner. I also don't think graphene currently supports ordering by multiple fields. Possibly raise that as a separate issue/PR with a failing test case?\n. This line is over the 120 character limit. Could you split it up?. Done!. I think a better check would be to use callable then it would catch both cases.. Ah yeah you're right. What you've done then looks good. Just needs some tests.. Why do you have to define the dependencies here when they are already defined in the setup.py?. But why doesn't the tox file just have the pip install -e \".[test]\" command that is outlined in the README? Then the whole [testenv] section just becomes:\n[testenv]\ncommands = \n    pip install -e \".[test]\"\n    py.test --cov=graphene graphene examples\nand there is no need to define requirements in multiple places.\n. Top level imports should be above relative imports. I'm really not a fan of the imports being split up like this. How the imports were arranged is much clearer and easier to read.. According to the github v1.2.0 is the latest version. Any reason you're not using that?. Doesn't look mypy is actually run anywhere? Can you add it as a step in the matrix. What was this for and is it ok to remove?. This won't work if you request a key that doesn't exist. The pattern we've been following is something like this:\npython\nusers = {user.id: user for user in User.objects.filter(id__in=keys)}\nreturn Promise.resolve([users.get(id, None) for id in keys])\n. @dan98765 so the reason I don't use self when defining resolvers is because self means a specific thing in python (the instance of the current class) but in Graphene the first argument to the resolver is not an instance of the current class. Actually resolvers work like static functions and the first param is whatever the parent resolver returned.\nUsing self in the past has led to people being confused about what the value actually is and assuming it's the current instance (which is not unreasonable) so I've taken to naming the value as _ when it's at the top of the tree (because if there is no root value then it's always None) or calling it a name that refers to what I'm expecting to receive. For example:\n```python\nclass User(graphene.ObjectType):\n    name = graphene.String()\ndef resolve_name(user, info):  # <-- the first argument will be a Django model instance\n    return user.name\n\nclass Query(graphene.ObjectType):\n    user_by_id = graphene.Field(User, id=graphene.Int())\ndef resolve_user_by_id(_, info, id):  # <-- no root value so the first argument is always None\n    return DjangoUser.objects.get(id=id)\n\n```\nI agree that we should standardise on something and actually thinking about it it makes sense to standardise on root for the top level Query resolvers (rather than _) so I'm happy to change the documentation to reflect that. I would also strongly recommend not using self for any resolver documentation because I think it ends up being confusing. Does that make sense @dan98765 @ProjectCheshire ?. I'm unsure if you can add @staticmethod to resolvers actually but I don't see why it wouldn't work. It would get quite tedious to have to do it everywhere though.. As per other discussions it looks like we're going to standardise on root for top level resolvers so I'll change this.. ",
    "ptz0n": "Please have a look in Python 2.7 as well. I see alot of syntax errors in the code right now.\n. @Globegitter is this really working for you? Output from test.py is None.\nWorks if you change sort_directon to sort_direction. :+1: \n. Would be nice to check the new example code with flake8.\n. I cannot find where you have defined the Users class.\n. This one, should be sort_direction.\n. ",
    "ekampf": "+1 here.\nTrying to define a list on an edge type: slices = graphene.List(ESSearchResultEdge) and getting a GraphQLError('Cannot query field \"node\" on type \"ESSearchResultEdge\".',).\n```\nclass ESSearchResultEdge(relay.Edge):\n    search_result_info = graphene.Field(SearchResultInfoType, required=True)\n...\nslices = graphene.List(ESSearchResultEdge)\n```\nThe schema generated:\n```\ntype ESSearchResultEdge {\n  cursor: String!\n  searchResultInfo: SearchResultInfoType!\n}\n```\n. :+1: \n. Hey @kiennt, @cyrfer  would love your feedback on https://github.com/ekampf/graphene-gae\n. docs PR in the works...\n. Similar case here working with AppEngine's NDB (would be the same for HBase or most other nosqls I guess).\nI have a huge table. You can iterate it using a starting cursor value (you get the cursor value from the DB) and count of entries you want to fetch. There's an iterator that can do this in batches...  but there's no len() operation...\nExample fetching a page:\ngreets, next_curs, more = Greeting.query().fetch_page(10, start_cursor=None)\nmore will be True\\False on wether there's a next page and next_curs is the start_cursor for the next query.\nIs there a way to implement this logic of iterating a big list with no len() ?\n. Maybe its coming from the Ruby world... but I kinda like the \"magical\" approach of automatically injecting values by argument name using inspect.getargspec(resolver_func).args (and inspect.signature() in 3.6+).\nThis way you can automatically not just context and info but args like in @syrusakbary's example too.\nThis automatic objection could be implemented as a decorator too... (which can help resolving possible name by providing some sort of mapping between default name and var name...)\n. \ud83d\udc4d (happens on my end on GAE too)\n. @syrusakbary any idea regarding this issue? happens to us a lot on Google AppEngine...\n. Ill try to report with a test\n. allUsers is a Connection type so you have to query it via edges and nodes because thats how a Connection is defines.\nConnection is GraphQL spec for defining a paginated list - it provides the pageInfo information that lets you paginate a large dataset regardless of wether you're using Relay or not\n{ allUsers { id firstName } } is a query you'd do on a List type.\nSince allUsers is probably a big table of data that requires pagination its defined as a Connection and not a List\n. @mwilliamson-healx Ive had the same problem.\nFortunately the next version of Graphene fixes the issue (and also adds performance tests to make sure it doesnt regress).\nThough its a risk using the library's bleeding edge, Ive been running the next version (pip install graphene>=1.0.dev) for a couple of weeks now in production without problems.\nSo you should give it a try and see if it solves your problem (and if not, maybe there's some new performance test cases to add to Graphene's performance tests)\n. Need to debug to make sure it works but should be something like\n```\nclass MyConnection(Connection):\n    class Meta:\n        node = UserType\ntotal_count = Int()\n\nsome_query = ConnectionField(MyConnection)\ndef resolve_some_query(self, *_):\n  edges = .. create edges from query ...\n  total_count = .. calculate total ...\n  return MyConnection\n      total_count=total_count,\n      edges=edges,\n      page_info=PageInfo(\n            start_cursor=start_cursor.urlsafe() if start_cursor else '',\n            end_cursor=end_cursor,\n            has_previous_page=has_previous_page,\n            has_next_page=ndb_iter.has_next()\n        )\n  )\n``\n.Field()` expects a type not an instance...\nChange code to:\nargumented_string = graphene.Field(graphene.String, arg=graphene.Int())\n. Hey @mzohaibqc \nJust note that while using hierarchies in mutations is valid under the GraphQL spec, it will not work if you use Relay on your client to call it.\nRelay enforces all mutations to be top-level: https://github.com/facebook/relay/issues/551\nIts very annoying, but thats the way it is :(\nAnyway, if you still want to do it all you need to do is define a root:\n```\nclass MutationRoot(graphene.ObjectType):\n   sn_mutations = graphene.Field(SnMutations)\ndef resolve_sn_mutations(self, *_):\n       return SnMutations()\n```\n. Hey @yfilali,\nSay my query is:\n{\n   viewer {\n      friends {\n          firstName\n          lastName\n      }\n   }\n}\nIf I use an object proxy then, given a user, if you query for friends then resolve_friends will only query for the user friendsIDs and return a list of proxy objects.\nEach proxy object will fetch itself to resolvefirstNameandlastName.\nThis will result into N database calls.\nI would want to make a one call to fetch all friends...\n. once per type...  iffriends` is an array of 10 proxies....\n. Maybe this describes the problem better:\nhttp://guides.rubyonrails.org/active_record_querying.html#eager-loading-associations\n. I don't think I follow this solution ...\nWhat if your query is:\n{\n  viewer { \n    firsName\n    lastName\n    friends { firstName, lastName } \n  } \n}\nThe __getattr__ method will be called for firstName - how do I know there I need to fetch the user from DB + its friends ?\n. Ended up with the following introspection code (based on the code above, but allows looking several levels deep into the query):\n```\ndef get_field_names(info):\n    \"\"\"\n    Parses a query info into a list of composite field names.\n    For example the following query:\n        {\n          carts {\n            edges {\n              node {\n                id\n                name\n                ...cartInfo\n              }\n            }\n          }\n        }\n        fragment cartInfo on CartType { whatever }\nWill result in an array:\n    [\n        'carts',\n        'carts.edges',\n        'carts.edges.node',\n        'carts.edges.node.id',\n        'carts.edges.node.name',\n        'carts.edges.node.whatever'\n    ]\n\"\"\"\nfrom graphql.language.ast import FragmentSpread\nfragments = info.fragments\n\ndef iterate_field_names(prefix, field):\n    name = field.name.value\n\n    if isinstance(field, FragmentSpread):\n        results = []\n        new_prefix = prefix\n        sub_selection = fragments[field.name.value].selection_set.selections\n    else:\n        results = [prefix + name]\n        new_prefix = prefix + name + \".\"\n        sub_selection = field.selection_set.selections if field.selection_set else []\n\n    for sub_field in sub_selection:\n        results += iterate_field_names(new_prefix, sub_field)\n\n    return results\n\nresults = iterate_field_names('', info.field_asts[0])\nreturn results\n\n``. yes you can.\nTo use an abstract type you derive from it:class SpecificQuery(ObjectType, CountryQuery):So any method defined onCountryQuerywill also be available onSpecificQuery`\n. This should work:\nclass SetAddress(graphene.Mutation):\n    class Input:\n        geo = GeoInput()\n. Though using the context solution usually work it has some edge cases when runnning resolvers in parallel.\nFor example:\n{\n   product1: product(id: \"1\") { id, name, ...}\n   product2: product(id: \"2\") { id, name, ...}\n}\nif resolve_product sets something in context, say context['current_product'] = self then it might be a problem.... I think adding a permission array of strings to the model's Meta is a good idea.\nWe can then write a middleware that verifies current user (from context) against the current model's permissions.... Might be too high-level though...\nFor example, it will allow you to seperate Admin models\\fields from user models\\fields but wont allow you differentiate between users (say there's a user resource but a user can only access his own resources)\nMaybe its best to add a class method to the model:\n```\nclass Person(graphene.ObjectType)\n    ...\n@classmethod\ndef is_authorized(cls, user):\n     return True\n\n```\nand then call that from a middleware...\n. yes. Out graphql handler does the authentication and sets context['current_user'] before passing the query to the GraphQL execution.\nSo the current user is accessible via context.\nWe can do very specific authorization code inside the resolvers themselves but a nicer way would be to generalize it via a middleware.. @nickhudkins I think this is very implementation specific, what would you want such a PR to contain?. maybe we can make the middleware generic.... 1. The middleware cant put the user in context, it supposed to get it as input. There are 2 ways to do it:\n1.1. Set it in the handler before executing the query\n1.2. Instead of using the context set it in the middleware's constructor when you execute the query:\n```\nclass AuthorizationMiddleware(object):\n  def init(self, user):\n    self.user = user\ndef resolve(self, next_step, root, args, context, info):\n    ... do authorization logic ...\n...\n    result = schema.execute(query,\n                            operation_name=operation_name,\n                            variable_values=variables,\n                            context_value=dict(),\n                            middleware=[AuthorizationMiddleware(current_user)])\n\n```. as for the actual logic for the middleware I think there are 2 levels of authorization.\nFirst level is permission token based - can the current user even access this model\\field?\nFor this its worth looking at what Reindex and Scaphold doing:\nhttps://www.reindex.io/docs/security/authorization/\nhttps://scaphold.io/docs/?__hstc=85828166.8dd772556de03c0650938130c7a38a29.1484336017404.1484336017404.1484336017404.1&__hssc=85828166.1.1484336017405&__hsfp=1917043275#permissions-authorization\nSecond level of authorization is - given a resolved value, check if user is allowed to get it.\nSomething like:\n```\ndef resolve(self, next_step, root, args, context, info):\n    ... do authorization logic ...\n            result = next_step(root, args, context, info)\n        return result.then(\n            lambda resolved: self.__check_authorization(resolved, root, args, context, info),\n            lambda error: self.__handle_error(metrics, error)\n        )\ndef __check_authorization(resolved, root, args, context, info):\n   resolved_type = type\n   if hasattr(resolved_type, \"check_authorization\") and callable(resolve_type.check_authorization):\n      resolve_type.check_authorization(self.user, resolved)\n```\n. @mleonard87 graphene generate the response json not Flask.  It collect said errors as part of its execution...  should probably improve it and add trace etc. Its not really clear what you want graphene to do here.\nRelay Modern still makes regular GraphQL calls to the server...   the only thing you can do is know in advance what kind of queries to expect and optimize your resolves accordingly...\n. Maybe I'm missing something but it doesn't seem like whats in https://github.com/apollographql/optics-agent should make sense outside the Apollo team...\nIt would be great if there was a rough \"Quickstart\" on the guidelines for a new agent.... @syrusakbary I'd be happy to help build it.. So I'm 99% done integrating Apollo Tracing into Graphene.\nThe code is actually in graphql-core (See https://github.com/graphql-python/graphql-core/pull/148) and graphql-server-core where the code middleware doing the tracing and adding the data is (PR as soon as the relevant graphql-core changes get merged). @dvndrsn I kinda stopped working on it waiting for that PR to merge. \nWill try and find time to complete this feature ASAP.... Sorry I didnt have the time to work on it latelly...  I will try to finish everything and push some code this weekend. \nWill need help testing it :)\nI will update here ASAP. Ok so I haven't had time to complete it in the past few days but I'm sharing the work that has already been done.  I hope I'll be able to get to it this week but anyone who wants to help is welcome :)\ngraphql-server-core\nhttps://github.com/ekampf/graphql-server-core/tree/feature/tracing\nTracingMiddleware is where we implement the collection of the tracing data that we later need to expose somewhere in the run_http_query flow.... So this has been a long awaited update...\nI have updated https://github.com/ekampf/graphql-server-core/tree/feature/tracing to match the spec (use nanoseconds) and support Python 3.7.\nI'm going to do some testing with Apollo to make sure this works this weeks.\nHowever, I think the right place for the TracingMiddleware would be graphql-core - this way we could also instrument the parsing & validation phases.\nSo I will do some more testing and then move the code there.\n@syrusakbary any thoughts?\n. Here is the initial code in graphql-core - https://github.com/ekampf/graphql-core/tree/feature/tracing\nIf anyone subscribed here can help test this against Apollo Engine and provide feedback that would be much appreciated\n. @Prince-Leto you dont use it directly but rather call set_default_backend(GraphQLCoreBackend(tracing=True)) before initializing GraphQLView. The reason is its not a pure middleware - it has a middleware part to trace all the resolvers, but it also has part that has to ruin in backend itself to measure parsing and validating the query (before resolvers start to run). @helpse you can find me at the #graphene channel at the GraphQL slack. Hey @mbrochh,\nMy solution to that problem was to define a simple mock Schema for my test and make a real query.\nFor example:\n```\ndef test_resolve_image1_thumbnail(self):\n  p = mixer.blend('marketplace.Product')\nclass Query(ObjectType):\n    product = Field(ProductType)\n    def resolve_product(self, *_):\n       return p\nresult = Schema(query=Query).execute('''\n  {\n    product {\n      image1Thumbnail \n    }\n  }\n  ''')\n  self.assertIsNone(result.errors)\nresult_thumbnail = result.data[\"product\"][\"image1Thumbnail\"]\n  self.assertEqual(...)\n. But if you really insist on testing the resolver method directly you can just test it as a method.\nInstance method are simply functions who's first param is self so you can do something like:\nproduct = mixer.blend('marketplace.Product')\nresolver_fn = ProductType.resolve_image1_thumbnail\nresult = resolver_fn(product, None, None, None)\n``\nAnd now when you're inresolve_image1_thumbnailthe value ofselfwill bemixer.blend('marketplace.Product')`\n(btw, this is exactly what the Graphene executor does)\nSee sample run:\n```\nIn [1]: class Product(object):\n   ...:     def sayHello(self):\n   ...:         print(\"Hello \" + self.name)\nIn [2]: fn = Product.sayHello\nIn [3]: class Foo(object):\n   ...:     def init(self):\n   ...:         self.name = \"Eran\"\nIn [4]: fn(Foo())\nHello Eran\n``. Why isReadImagea mutation and not a query?  \nFrom the looks of it, it only reads data and doesn't mutate anything.... That said, GraphQL arguments cannot be queries...\nWhat I'd do is allow theWriteMutationget an optionalpathas input (and makeimageoptional too) and ifpathis given run the logic that lots it from file in theWriteMutationresolver. I don't think you can do that with GraphQL .... @nxexox where do you see this in the Relay spec?  it only defines two fields as required -pageInfoandedges` - https://facebook.github.io/relay/graphql/connections.htm#sec-Connection-Types.Fields\nAlso when you think about it, it doesnt make sense to have totalCount as part of the Connection spec because what do you do when you paginate a long nosql table?\nSay the FB newsfeed for example... the totalCount is meaningless.\n. I'm not aware of the graphene.List(lambda: Dictionary) syntax.\nBut why not use the Dynamic type?\nSomething like:\n```python\nclass Language(graphene.ObjectType):\n    id = graphene.Int()\n    dictionaries = graphene.List(Dynamic(Language .get_dictionary_type))\n@staticmethod\ndef get_dictionary_type():\n    from .dictionary import Dictionary\n    return Dictionary\n\ndef resolve_dictionaries(self, args, context, info):\n    result = list()\n    for dictionary in db_list:\n        result.append(Dictionary(id=dictionary.id))\n    return result\n\n. Sure you can implement it yourself. All you need is a Result object that returns both result and a set of items:\nclass CommentsPage(graphene.ObjectType):\n  cursor = graphene.String()\n  comments = graphene.List(Comment)\ncomments = graphene.Field(CommentsPage, cursor=graphene.Argument(String))\n@graphene.resolve_only_args\ndef resolve_comments(self, cursor=None):\n   comments, new_cursor = ... fetch from DB according to cursor value ...\n   return CommentsPage(\n      cursor=new_cursor,\n      comments=comments\n   )\n. @rjdp the tradeoff is that this schema is simpler and easier to use (and implement).\nBut, you can't use it with Relay. If you're not using Relay this could do just fine for you.... @rjdp I guess you can close the issue?. You cant duplicate this exact schema but if you want to return an object from the mutation what you do is this:\nclass AddChannelMutation(graphene.Mutation):\n    class Input:\n        name = graphene.String(required=True)\nchannel = graphene.Field(Channel)\n\n@graphene.resolve_only_args\ndef mutate(self, name):\n    new_channel = ...\n    return AddChannelMutation(channel=new_channel)\n\n```\nSo in your schema, the mutation type would look like:\n```\ntype AddChannelMutation implements Messageable {\n  channel: Channel\n}\ntype Mutation {\n  addChannel(name: String!): AddChannelMutation\n}\n```\nWhich offers the same functionality as what you're looking for only that channel is returned via the AddChannelMutation type and not directly.\n. @piercefreeman I havent tried it but looking at the code I think you can just implement your mutation as a field instead of deriving from Mutation\nSomething like this:\n```\nclass Query(graphene.ObjectType):\n   ...\nclass Mutations(graphene.ObjectType):\n  add_channel = graphene.Field(Channel)\ndef resolve_add_channel(self, args, context, info):\n     channel = ... do stuff ...\n     return channel\nschema = graphene.Schema(query=Query, mutation=Mutations)\n```\n. Should work as it's basically what the graphene.Mutation class does behind the scenes. \nLet me know if it solves your Apollo problem :). 2.0 is out. Can close this.... Sounds like a task for graphene-sqlalchemy to provide default resolvers.... @llevar implementing CRUD implies writing entities to some store.\nYou could write a class that implements given an object implements basic create\\update\\delete mutations but what will those mutations it implements for you do? they have to be tied to some DB right?\nSomething like:\n```\nPersonMutations = SQLAlchemyCRUDMutations(Person)\nclass MutationsRoot(ObjectType, PersonMutations):\n   ...\n```\nWill implement basic createPerson, updatePerson, deletePerson mutations that update the DB with a person entity (You know all the fields from the meta of the Person ObjectType so you can create all the types required for said mutations)\n. > presuming you have a business layer that defines lifecycle methods your objects you ought to be able to annotate these ...\nSimilar to what I described above you can probably write a code that takes a function as input (which would be one of your business layer's functions) and infer a Mutation schema from it using Python inspect capabilities.\nHowever, how would you infer types?\nSay you have a function: def updatePerson(person_id, name, age) how would you infer a Mutation schema who's input is name that's a String and age that is an Int ?\nIf your business layer exposes this information in some way you can write a utility method that automatically converts your business layer functions to mutations...\n. Adding graphql-core ~= 1.1 to requirements.txt solves the problem but I do think there should be a new graphene 1.x release that fixed its graphql-core requirements...\n@syrusakbary  ?. This looks fine to me. \nI want to fix the build in the master branch before starting to approve and merge PRs.\nI'll try to get master ready to accept new PRs ASAP. See issue #476\n. Very interesting!\n. Use the context - https://docs.graphene-python.org/en/latest/execution/execute/. This is a breaking change.\nSo I guess this would require a version major\\minor change...\n@syrusakbary whats your policy on such changes?\n. @avivey let's discuss how we can make this backward-compatible.\nIt should work the old way by default until we make the cut to Python3.... Closing in favor of #913 . @jkimbo @ProjectCheshire @dan98765 congrats!  our first PR as the new graphene group :). Why do you need to cast self._types_names.values() to a list? dict.values() is already a list ...\n. Your mutation doesnt have an ok field\n. Didn't think of that... checking. @dan98765 ok closing this PR in favor of yours. ",
    "inklesspen": "I can prepare a PR to make get_node work like other resolver functions (with the possibility of decorating it with resolve_only_args for the previous style of behavior).\nThat is: \npython\nclass Foo(Node):\n    @classmethod\n    def get_node(cls, args, info):\n        # do the right thing\n        pass\nor\npython\nclass Foo(Node):\n    @classmethod\n    @resolve_only_args\n    def get_node(cls, id):\n        # do the right thing\n        pass\nWould such a PR be accepted?\n. ok, so it wouldn't support resolve_only_args then.\nI will try to prepare a PR in the next day or so.\n. Just a reminder the PR is ready.\n. Using type as a variable in Python code and using type as a field in a schema to send data between several systems, many of which may not be written in Python, are two different scenarios.. ",
    "lightning18": "How does this work? How do you trigger a push from the server? The way I understand the commit is that this is just the subscription part and I have to manually implement a pub-sub, am I right?\n. No need for checks then. Submitted #71, added a test in it too.\n. That is unfortunate, is it a deal breaker? Should I use an if statement to support 1.8 too?\n. Yes, sure, I don't mind it being removed, it's just a visual after all. I can submit a PR for that. I'd also like to include some documentation. Should I just add it on the Django quickstart?\n. If you want to try, you can start here: https://github.com/graphql-python/graphene/blob/master/graphene/contrib/django/converter.py\n. ",
    "Vir-Cotto": "@lightning18 The standard doesn't explicitly say when a trigger happens, only that the client may request a subscription. I would guess that then 'when' question would be something that would be something related to a signal on a given object in a post-save.\nI'd guess that the right way to handle this is to require the use of django-channels (https://github.com/django/channels/) and then place a request to update the clients on the appropriate channel bus.\nI'm less sure how to do this in an agnostic way- maybe the right thing to do isn't to explicitly say that graphene-django must support this, but instead to provide a documentation example of how to implement it, both for the general case of a simple notification, but also to show how (as per the GraphQL spec) there needs to be authentication support- ie a user should only get notified of a subscription to which they have proper permissions.\n. @femesq Sure, that makes sense. Anything that would add/modify/delete data is grounds for a triggered event, but there's a key distinction to be made here, which is that if you place the trigger event on a mutation, then if I understand you, that means that only mutations that happen through GraphQL will trigger that event. That means things like the django admin, or command line scripts that may run (scheduled cron jobs or other events), unless those are all modified to use graphql, will not cause the event to happen.\nIf, on the other hand, the event happens post-save on the model, then as long as the django ORM was involved, it will trigger.\nre: permissions, I wasn't actually suggesting this was a problem, but it's a situation where an example would be useful. The important thing here is to not tie permissions too closely to the framework. It should be up to developer how they want to check for permissions, but we want an example that's beyond \"broadcast to everyone\".\n. ",
    "femesq": "I'm joining the conversation 'cause I'm interested in this topic.\n@KinkyVirCotto:\nMost of the talks I saw, make use of examples that fires subscription when a mutation happens... But yes: that could happen on DB's post-save if data-mutation can happen other places too..\nAbout the permission, that could be solved my checking the permission on subscription request. In case the user don't have access to receive such updates, the query could return an 'false' flag on a \"success\" field, or return null on fields values.. . Probably because graphql-core's version. Try going to 1.0.dev for this package too.\nIf you need middleware, wait for this [https://github.com/graphql-python/graphql-django-view/issues/14] to get solved.\nGood luck,\n. When defining your Schema, use the types option:\nschema = graphene.Schema(query=Query, types=[Option, CategoryOption])\nseens it happens when no other field points do that specific type...\nHope it helps.... ",
    "cyrfer": "+1\n. ",
    "amitsaha": "Thanks for taking a look @syrusakbary , fixed the issues now.\n. @syrusakbary related question, is this the simplest way to do this? Do I have always have to define an interface and then subclass it ? Can't I use any class instead as a field?\n. OK, that's great. I have changed the example now. Please take a look thanks.\n. Thanks @jhgg - that was it, thank you.\n@syrusakbary Do you still want me to post it? For the future, what tags should I be using?\n. I am working on something: https://github.com/amitsaha/flask-graphql-demo it's really basic but shows off querying, updating existing data and uploading files. I am hoping to keep working on it, feel free to suggest changes/improvements/enhancements.\n. @syrusakbary is this something you would want to integrate into the source tree as an example? If yes, what would you like to see in it?\n. Thanks @syrusakbary - that would be awesome. Do you already have some work done that I can look at? \n. @syrusakbary just wondering if you have any code that you can share? I would like to integrate graphiql into my project. If you don;'t have any, I will try to set it up somehow .. :)\n. Thanks @syrusakbary - will check them out. \n. @syrusakbary it works great. @msoedov Will do, does it support file uploads? My approach is very basic here: https://github.com/amitsaha/flask-graphql-demo/blob/master/schema.py \nWould be curious to know if you have a better idea?\n. Thank you @syrusakbary \n. +1 @dgoldstein0 I think there could be a FAQ as a wiki page @syrusakbary ?\n. @syrusakbary Thanks for your clarification. I am pondering how to best return the error messages in a single HTTP response, in case there is more than one. \n. ",
    "millerjs": "Thanks! Your example is as expected, however when I plug it in to a more complex schema, I get a TypeError: Cannot read property 'types' of undefined from graphiql.  The example is helpful though, thanks!\n. Will do, I figure it's just a misuse on my part.  If it turns out not to be, I'll open that issue.\n. The reason it did not work for me is because the InputObject class was defined in a function local scope (I'm generating ObjectTypes classes at runtime).\n. :+1: This would be a great feature despite it's unconventionality.\n. Fantastic! thanks @syrusakbary \n. ",
    "sulabhjain": "\n@millerjs this is now fixed.\nThanks to a new plugin structure you can even create some plugin for transform the name the way you want.\nThe current usage for disable the auto camelCase is:\npython\nschema = graphene.Schema(query=..., auto_camelcase=False)\nHope it helps! ;)\n\nHi @syrusakbary, I am using this thread for a question related to auto_camelcase, let me know if there is more appropriate forum to addresses this issue.\nWe are running into a requirement where not all clients of graphql api wants to use camelCase for interacting with the api (eg. non-javascript based internal services). So the question here is, if there is a way to dynamically pass a parameter to graphql api which determines if camelCase to snake_case conversion should happen or not on the server side. If not, is this a requirement on the future roadmap ? Appreciate your help.\n. ",
    "svilendobrev": "this is still a problem on graphene.Interface - resolve_type is a classmethod there... ",
    "cherls": "Using type as a variable is an anti-pattern in Python as it overwrites a built-in function, not to mention the use of type in GraphQL Schemas. The better alternative, in my opinion, would be to rename the field as location_type or type_.. class Query(graphene.ObjectType):\n    search = graphene.Field(\n        SearchResult,\n        query=graphene.String(required=True),\n        filters=graphene.Argument(Filters, default_value={})\n    )\nSeems to work and produces\ntype Query {\n  search(query: String!, filters: Filters = {}): SearchResult\n}\nI also tried it with your DefaultFilters but I couldn't output the schema for some reason.. @tlinhart \nExecution works fine for me with the following code. Note that the filters argument is missing on the search field.  I think the error is something else in your code.\n```\nimport json\nimport graphene\nclass SearchResult(graphene.ObjectType):\n    result = graphene.String()\nclass Filters(graphene.InputObjectType):\n    name = graphene.String()\n    type = graphene.List(graphene.String)\nclass Query(graphene.ObjectType):\n    search = graphene.Field(\n        SearchResult,\n        query=graphene.String(required=True),\n        filters=graphene.Argument(Filters, default_value={})\n    )\ndef resolve_search(self, info, query, filters):\n    return SearchResult(result=\"result for \" + query)\n\nschema = graphene.Schema(query=Query)\nresult = schema.execute(\n    '''\n    query {\n        search (query: \"test query\") {\n            result\n        }\n    }\n    '''\n)\nprint(json.dumps(result.data))\nwith open('schema.graphql', 'w') as fp:\n    fp.write(str(schema))\n```. ",
    "msoedov": "As temporary workaround I used https://github.com/msoedov/flask-graphql-example/blob/master/ql.py#L13-L20\npython\n    def resolve_user(self, args, info):\n        u = User.objects.get(email=args.get('email'))\n        return construct(UserField, u)\n. @amitsaha I have really simple flask app example https://github.com/msoedov/flask-graphql-example, you can build it from docker-compose and check that out \n. ",
    "dmzkrsk": "Hello, I started a project for MongoEngine integration\nhttps://github.com/dmzkrsk/graphene-mongoengine\nI copied code from contrib.django and contrib.sqlalchemy and replaced classes with mongoengine ones.\nIt's in pretty early stage, I have no docs, tests, but it has working fields, relations, relay. Mutations not tested yet.\nPlease join, test on your projects, add tests, etc\n. ",
    "sibelius": "@dmzkrsk that's great to know\ntake a look at https://github.com/RisingStack/graffiti-mongoose, it's have the same ideia but for JS\n. @syrusakbary you should consider using the graffiti approach\nTo enable adapters for databases.\nFor now, you already have two of them in contribute django and sqlalchemy, I think the next one could be mongoengine\nThanks for this repository\n. ",
    "subodhpareek18": "Hi is there any movement on this issue to the best of your knowledge @syrusakbary @dmzkrsk?\nThis seems to be almost an year old request.\n. ",
    "ozanturksever": "i did a impl here https://github.com/ozanturksever/graphene-mongoengine \nit is mostly code modifed from graphine-django\n. ",
    "gordol": "wheee, nobody did tests in their implementations.. hmm, seems to me that neither of those implementations are complete... not all object types are supported, for example, and relations are also not supported by either implementation.. ",
    "yfilali": "FYI: https://github.com/yfilali/graphql-pynamodb is a recent implementation for dynamodb, Amazon's NoSQL database. I am not too familiar with mongodb, but the basic structure should be very similar to @ozanturksever  implementation. I also had the need to implement relationship attributes. So maybe that could be of use to the mongo port. The MongoDB documentation on \"Model One-to-Many Relationships with Document References\" seems pretty close to the pattern I ended up implementing: https://docs.mongodb.com/v3.0/tutorial/model-referenced-one-to-many-relationships-between-documents/\n. Btw, this doesn't work on the sqlalchemy side. I have a PR in there to fix it and make the total_count and iterable available like it is on the django side:\nhttps://github.com/graphql-python/graphene-sqlalchemy/pull/36\n. I think what you're looking is on Argument (not list like you show above) and is called default_value, not default:\n```\nfield = graphene.Field(SomeField, order_by=graphene.Argument(graphene.List(OrderingParameter), default_value=[\n            OrderingParameter(key=OrderingKeys.CREATION_TS, direction=OrderingDirection.DESC)])\n```\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/argument.py#L11\nP.S.: Jul 5th unanswered issue! I hope this is still relevant to you...\n. Just a shot in the dark, but you may need to add your own resolve_type method to  CreatePostResult:\ndef resolve_type(self, _type):\n    return type(_type)\n. I have spent the last couple of days implementing the PynamoDB integration. What I ended up doing is grabbing the SQLAlchemy repo and creation the PynamoObjectType, PynamoConnectionField, and PynamoObjectTypeMeta.\nGetting the tests and examples to run with PynamoDB was a good way of getting the basic support up and running. \n. This is now pretty stable, I've been using it for a little while and I am pretty content with it's current status. Let me know if you see anything amiss or what you'd like to do with it next.\n. The short answer is, what you're doing is fine, you don't need to mess with Argument.\nThe long answer is what you put in the Input class will get converted by the Mutation's meta class:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/mutation.py\nFrom there, the attributes defined on Input are passed to Field as args=:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/field.py\nField init then calls to_argument(args), which runs them through a few conditions of interest to you:\n```\n    if isinstance(arg, Dynamic):\n        arg = arg.get_type()\n        if arg is None:\n            # If the Dynamic type returned None\n            # then we skip the Argument\n            continue\n\n    if isinstance(arg, UnmountedType):\n        arg = arg.Argument()\n\n    if not isinstance(arg, Argument):\n        raise ValueError('Unknown argument \"{}\".'.format(default_name))\n\n```\nSo as you can see, it handles Dynamic types, UnmountedType (this is what you're using), and Argument types.\nBtw, if you mean to use this for Relay, then you can use the ClientIDMutation parent:\n```\nclass AMutation(graphene.relay.ClientIDMutation):\n    class Input:\n        foo = graphene.String()\n        bar = graphene.String()\nok = graphene.Boolean()\n\n@classmethod\ndef mutate_and_get_payload(cls, input, context, info):\n    ok = True\n    return AMutation(ok=ok)\n\n```\n. Do you mean you need to create the DatasourceType attributes from the result of another method call? If so then this should do the job:\n```\ndef call_that_returns_fields_dict():\n    result = {}\n    for name, field in dynamicfields.items():\n        result[name] = graphene.String()\nreturn result\n\nDatasourceType = type('DatasourceType', (graphene.ObjectType,), call_that_returns_fields_dict())\n```\nIf you mean to say you need to get the column names from your query as fields, then that means you will need to make the function above query the DB to find out the table's column names.\nBtw, you should note that once you've created the schema, the fields will not and should not change. This is because the party querying your GraphQL API should not have the fields change on them at random per the spec. GraphQL only works when both the client and server agree on the schema.\n. I agree that this could probably use a little clarification in the docs, but if you look at it as pure Python:\n1- graphene.String is a class, you use the class when you want to say I want a List of Strings. List(String) means you want a list of object of type String. The argument to List(Structure).init is actually called 'of_type': https://github.com/graphql-python/graphene/blob/master/graphene/types/structures.py#L10\n```\nclass Structure(UnmountedType):\n    '''\n    A structure is a GraphQL type instance that\n    wraps a main type with certain structure.\n    '''\ndef __init__(self, of_type, *args, **kwargs):\n    super(Structure, self).__init__(*args, **kwargs)\n    self.of_type = of_type\n\n```\n2- graphene.String() is an instance of the UnmountedType String just like List() is an instance of the type List.\nIt wouldn't make sense to say you want a list of a particular instance of the String class. Inversely, when you're using String to create a Field, you do want an instance in that case. I don't want a field to equal the String class, I want an instance of the type, an actual String instance.\nI hope this clarifies it a bit.\n. @WGierke graphene is a server side implementation of graphql, not a client. You probably should post this under https://github.com/graphql-python/gql\nAlso, the example there should be more than enough to get you there anyway:\nhttps://github.com/graphql-python/gql/blob/master/tests/test_transport.py\nMove this issue there if you can't get it working.\n. @rattrayalex you should probably move this issue to https://github.com/graphql-python/graphene-django/issues as it is a django integration issue and not a core graphene issue.\nAlso, this seems a duplicate of https://github.com/graphql-python/graphene-django/issues/8\n. Hi @jwfehr, could you please post a full code sample? Also, what version of graphene are you using?\nDoing the following works fine with v1.0.2\n```\nfrom graphene.types.json import JSONString\nclass Foo(ObjectType):\n    json = JSONString()\n```\n. expanding on what @syrusakbary said, if you are using es6 and relay:\n```\nexport default class NewCatalogItem extends Relay.Mutation {\n  static fragments = {\n    store: () => Relay.QLfragment on Store { id }\n  };\ngetMutation() {\n    return Relay.QLmutation {\n      newCatalogItem(input:$input)\n    };\n  }\ngetFatQuery() {\n    return Relay.QLfragment on NewCatalogItemPayload @relay(pattern:true) {\n        catalogItem\n        store {\n          items\n        }\n      };\n  }\ngetVariables() {\n    return {\n        id: this.props.id,\n        store: this.props.store.id,\n        desc: this.props.desc,\n        thumb: this.props.thumb,\n        price: this.props.price,\n        created: this.props.created\n        start: this.props.start,\n        end: this.props.end\n    };\n  }\ngetConfigs() {\n    return [{\n      type: 'RANGE_ADD',\n      parentName: 'store',\n      parentID: this.props.store.id,\n      connectionName: 'items',\n      edgeName: 'items',\n      rangeBehaviors: ({orderBy}) => {\n        return 'append';\n      }\n    }];\n  }\n}\n```\nNote that you are missing a few output fields on the server side code that would let you do the RANGE_ADD on the client side. You would need to add a connection field called items and return an array containing your catalog item. \n. Yes, it's coming from getVariables. Anything you return there gets crammed into a single input object per the relay spec. The relay client side code handles the clientMutationId for you automatically. The query coming out of the client side will look like @syrusakbary's example.\nThis is where the relay conventions are documented: https://facebook.github.io/relay/docs/graphql-mutations.html\n. Since you want a relay mutation, try inheriting relay.ClientIDMutation instead of graphene.Mutation. change your mutate function to a mutate_and_get_payload function and you should be good to go:\nhttp://docs.graphene-python.org/en/latest/relay/mutations/\nThis should help you with the update: https://github.com/graphql-python/graphene/blob/master/UPGRADE-v1.0.md\n. I am doing something similar in a related project. I think it's something that's probably better handled outside the resolve function. You do get the info argument passed to resolve_viewer, but to my knowledge, it's not easy to parse and would be way too fragile as it may change depending on the query.\nA better approach could be to return a lazy loading object that resolves the viewer from DB when a non-id field is accessed. You would return ViewerProxy(user_id, UserClass) instead of the real User. When the underlying graphene code tries to get friends from your user object, the \"prefetch\" would trigger.\n```\nfrom wrapt import ObjectProxy\nclass ViewerProxy(ObjectProxy):\n    def init(self, id, obj):\n        super(ViewerProxy, self).init(obj)\n        self._id = id\n        self._self_model = obj\ndef __getattr__(self, name):\n    if name == \"id\":\n        return self._id\n    if not name.startswith('_') and isinstance(self.__wrapped__, type):\n        self.__wrapped__ = [THIS IS WHERE YOU QUERY THE REAL THING]\n    return super(ViewerProxy, self).__getattr__(name)\n\n```\nAnother thing that comes to mind: I don't know what you're setup is for authentication, but most likely, the viewer has already been queried as part of your authentication/session logic, so you probably already made a query to the db by the time you hit the resolve_viewer in which case, you'd be returning g.user (for flask) or request.user for django, so I don't know if you'd be gaining anything from this approach.\n. Not so! Notice that I have a test for that \"and isinstance(self.wrapped, type):\"\nIf the wrapped object is a type, we query and convert it to an instance. This makes sure we only query once.\nEdit: sorry, I think I misunderstood at first. See how I do it here: RelationshipResultList\nhttps://github.com/yfilali/graphql-pynamodb/blob/master/graphene_pynamodb/relationships.py\n. Yes, in your case, the sequence would go something like this:\n1) resolve_viewer => return a viewer proxy object\n2) resolve_friends is called and passed the previously resolved viewer proxy object as the root (or self) first argument. At this point, no query was made yet. Now you know that friends is accessed and do the optimal query for viewer + friends.\n. Here is the same thing in code. Does something like this work for you?\n```\n    class User(object):\n        pass\nclass Friend(graphene.ObjectType):\n    class Meta:\n        interfaces = (graphene.relay.Node,)\n\n    firstName = graphene.String()\n    lastName = graphene.String()\n\nclass User(graphene.ObjectType):\n    class Meta:\n        interfaces = (graphene.relay.Node,)\n\n    firstName = graphene.String()\n    lastName = graphene.String()\n    friends = graphene.List(Friend)\n\n    def resolve_friends(root, args, context, info):\n        print root.id  # == 1\n\nclass Query(graphene.ObjectType):\n    viewer = graphene.Field(User, )\n\n    def resolve_viewer(self, args, context, info):\n        return ViewerProxy(1, User)\n\nschema = graphene.Schema(query=Query)\n\nresult = schema.execute('{viewer { friends { firstName, lastName } } }')\n\n```\n. Wow, that's a much less flawed approach than mine!\n@syrusakbary What about spreading fragments like per @ekampf's initial question? something like this?\n``` python\n    def get_type(_type):\n        if isinstance(_type, (GraphQLList, GraphQLNonNull)):\n            return get_type(_type.of_type)\n        return _type\ndef get_fields(info):\n    fragments = info.fragments\n    field_asts = info.field_asts[0].selection_set.selections\n    _type = get_type(info.return_type)\n\n    for field_ast in field_asts:\n        field_name = field_ast.name.value\n        if isinstance(field_ast, FragmentSpread):\n            for field in fragments[field_name].selection_set.selections:\n                yield field.name.value\n            continue\n\n        yield field_name\n\n```\n. Short answer is yes. I suggested a way to deal with it here by delaying the query as much as possible in other to be able to ask the ORM to select_related:\nhttps://github.com/graphql-python/graphene/issues/348#issuecomment-259253099\n. Also, cache all the things, in memory preferably, per request at the very least.\n. The proxy object is just there to lazy load the parent object. The problem is that you need to know what related entities to prefetch with the parent object so instead of resolving it, you return a proxy that resolves itself only when the attributes are accessed. It allows you to delay the actual DB query until you've hit the resolvers for the related objects.\nEach ORM integration with graphene deals with this differently. I wrote the integration with PynamoDB, and there, I resolve all relationships into proxy objects which only query the db when the non-id attributes are accessed.\n. This is what I ended up implementing for SQLAlchemy:\nGraphQL, Graphene, SqlAlchemy and the N+1 problem\nThe problem with lazy promises is that the query is executed when it is trimmed, as it is treated as a list, so it needs to know in the initial resolver what it needs to include.\nhttps://github.com/graphql-python/graphql-relay-py/blob/c4c65337df2e169ae5c178dc79d25e8e234debd5/graphql_relay/connection/arrayconnection.py#L81. If you're using Flask: https://github.com/yfilali/graphql-pynamodb/tree/master/examples/flask_auth_pynamodb\nSpecifically schema.py:\n```\ndef graphql_token_view():\n    view = GraphQLView.as_view('graphql', schema=schema, graphiql=bool(app.config.get(\"DEBUG\", False)))\n    view = jwt_required()(view)\n    return view\napp.add_url_rule('/graphql', view_func=graphql_token_view())\n```. @syrusakbary showed an example of that here: https://github.com/graphql-python/graphene/issues/348#issuecomment-259591901\n```\ndef get_type(_type):\n    if isinstance(_type, (GraphQLList, GraphQLNonNull)):\n        return get_type(_type.of_type)\n    return _type\n\ndef get_fields(info):\n    fragments = info.fragments\n    field_asts = info.field_asts[0].selection_set.selections\n    _type = get_type(info.return_type)\n\n    for field_ast in field_asts:\n        field_name = field_ast.name.value\n        if isinstance(field_ast, FragmentSpread):\n            for field in fragments[field_name].selection_set.selections:\n                yield field.name.value\n            continue\n\n        yield field_name\n\n```\nAlso, for the original question, by the time you get to resolve_userIsTeamLeader, I am assuming you have already a resolved user in which case the resolve_userIsTeamLeader has access to the parent user object. Maybe try something like this?\ndef resolve_userIsTeamLeader(self, args, context, info):\n        print(self.id). In the docs, CreatePerson is a Mutation, not an ObjectType. ObjectType has no Field() method. You can create a field from an ObjectType with graphene.Field(...), but I don't think that's what you meant to do.\n```\nclass CreatePerson(graphene.Mutation):\n    class Input:\n        name = graphene.String()\nok = graphene.Boolean()\nperson = graphene.Field(lambda: Person)\n\ndef mutate(self, args, context, info):\n    person = Person(name=args.get('name'))\n    ok = True\n    return CreatePerson(person=person, ok=ok)\n\n```. You can create parent query classes that inherit from all the query classes, and likewise for mutations then add the parent query/mutation classes to a schema:\nhttps://github.com/graphql-python/graphene-django/blob/master/examples/cookbook/cookbook/schema.py\nclass SuperQuery(App1Query, App2Query, graphene.ObjectType):\n    pass\nschema = graphene.Schema(query=SuperQuery). I've used Zappa pretty successfully with flask + graphene + lambda. Zappa sets out api gateway routes for you and is a snap to get up and running from a flask application: https://github.com/Miserlou/Zappa\nShameless plug: there is also a pynamodb implementation for graphene in case you need to use dynamodb.\n. @uprego: packaging your application to run on AWS Lambdas has nothing to do with graphene. Graphene provides the graphql part of your backend, not the web application which would be provided by Flask/Django, etc.\nZappa is just one utility that helps you package your whole backend application for AWS API Gateway/Lambda, nothing prevents you from doing the same manually, but that is not graphene related. Using zappa for your project will take you about 5 minutes and 2-3 commands on the command line, so I highly recommend reading the getting started there: https://github.com/Miserlou/Zappa#basic-usage. My personal 2cts: graphene is pythonic, keeps your schema in sync with models, provides resolvers and filtering out of the box. graphql-core does none of that.\nAs you probably already know, graphene is a framework to make building graphql-core schemas easier. You can of course build your own schema by hand instead of using graphene-django. This means a lot more work depending on how many models you have. And when those models change, you'll need to make sure to also change the graphql schema, and the resolvers, etc.\nWith graphene, and in your case, graphene-django. Your graphql schema is generated for you from your django models. \nFrom the graphene-django docs, here is a simple Django model:\n```\nfrom django.db import models\nclass UserModel(models.Model):\n    name = models.CharField(max_length=100)\n    last_name = models.CharField(max_length=100)\n```\nTo create a GraphQL schema for it you simply have to write the following easy to read Python class:\n```\nfrom graphene_django import DjangoObjectType\nimport graphene\nclass User(DjangoObjectType):\n    class Meta:\n        model = UserModel\n```\nNow you already have quite a lot, you have the documented model in graphiql, you get a default resolver, you can add filters quite easily, etc.\nNow you could instead do this directly with graphql-core:\nuserType = GraphQLObjectType(\n    'User',\n    description='A User',\n    fields=lambda: {\n        'id': GraphQLField(\n            GraphQLNonNull(GraphQLString),\n            description='The id of the user.',\n        ),\n        'name': GraphQLField(\n            GraphQLString,\n            description='The name of the user.',\n        ),\n        'last_name': GraphQLField(\n            GraphQLList(characterInterface),\n            description='The last name of the user.',\n            resolver=lambda user, info, **args: getUser(user),\n        )\n    }\n)\nIt's a matter of opinion, but to my Python eyes, that is quite an eyesore, and will be hard to keep in sync with the model classes as your project grows.\nAnd as you said, you'll then need to implement resolvers, and filtering, etc. All code you get for free with graphene-django. ",
    "abawchen": "Hello,\nAfter checking, these 2 repos\nhttps://github.com/tomasgarzon/graphene-mongoengine\nhttps://github.com/ozanturksever/graphene-mongoengine\ndoes not support graphene 2.0 and neither relationship.\nSo I start https://github.com/abawchen/graphene-mongo, which supports one-to-one with ReferenceField and one-to-many with List(ReferenceField), and I have some basic test cases as well.\nHope it helps.\nThanks @tomasgarzon & @ozanturksever, got a lot from your implementation! :beers:. @akshaybabloo : Do these 2 help?\nhttps://github.com/graphql-python/graphene/issues/399\nhttps://codeburst.io/how-to-build-a-graphql-wrapper-for-a-restful-api-in-python-b49767676630. @luvwinnie : Could you provide you input, currently output and expected output? It will help a lot to understand you question (at least for me :p).. @jkimbo : I take this easy one in #692. ",
    "commandtab": "Thanks for your repo, @amitsaha! It cleared up a number of things for me as I'm getting going with graphene :)\n. Thanks for fixing! I really appreciate it.\n. ",
    "savovs": "I'm working on an updated flask example, would like to include file uploads but I'm getting this error:\nUploadFile fields must be a mapping (dict / OrderedDict) with field names as keys or a function which returns such a mapping.\nUsing this simple schema:\n```python\nfrom graphene import Schema, Argument, String, Int, ObjectType, Mutation\nclass Query(ObjectType):\n    hello = String()\ndef resolve_hello(self, info):\n    return 'Hello there.'\n\nclass UploadFile(Mutation):\n    class Arguments:\n        pass\ndef mutate(self, info):\n    return 'test'\n\nclass Mutations(ObjectType):\n    uploadFile = UploadFile.Field()\nschema = Schema(query = Query, mutation = Mutations)\n```. ",
    "ustun": "This is an interesting topic. Should each django app have its own schema? Then, how do we prevent name collisions? Should we be prefixing the resources then or should each app be serving its own graphql schema at a different URL?\nSome of these are subjective, but it would be better if we could give some recommended best practices to the community there.\n. Also, possibly related, underscores in field names do not work:\n```\nimport graphene\nclass Query(graphene.ObjectType):\n    hello = graphene.String(first_name=graphene.String())\ndef resolve_hello(self, args, info):\n    return 'Hello ' + args.get('first_name')\n\nschema = graphene.Schema(query=Query)\nresult = schema.execute(\"\"\"\nquery foo($first_name:String)\n{\n        hello(first_name:$first_name)\n}\n\"\"\", args={\"first_name\": \"Serkan\"})\nprint result.data\n``\n. Incidentally,fromargument name was the first thing I tried on the playground since it accepts an argument namedtoand it took me some time to remember thatfrom` is a keyword. Maybe the error message could be made better there too.\nhttp://graphene-python.org/playground/?schema=import%2520graphene%250A%250Aclass%2520Query(graphene.ObjectType)%253A%250A%2520%2520%2520%2520hello%2520%253D%2520graphene.String()%250A%2520%2520%2520%2520ping%2520%253D%2520graphene.String(to%253Dgraphene.String()%252C%2520from%253Dgraphene.String())%250A%250A%2520%2520%2520%2520def%2520resolve_hello(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27World%27%250A%250A%2520%2520%2520%2520def%2520resolve_ping(self%252C%2520args%252C%2520info)%253A%250A%2520%2520%2520%2520%2520%2520%2520%2520return%2520%27Pinging%2520%257B%257D%2520%257B%257D%27.format(args.get(%27to%27)%252C%2520args.get(%27from%27))%250A%250Aschema%2520%253D%2520graphene.Schema(query%253DQuery)%250A&query=query%2520%257B%250A%2520%2520hello%250A%2520%2520ping(to%253A%2522Peter%2522%252C%2520FROM%253A%2520%2522Ustun%2522)%250A%257D%250A\n. ",
    "jcouser": "Hi,\nI'm attempting to create this level of abstraction as well.  I'm using graphql-sqlalchemy and when I do something like:\nclass UserGroupMember(SQLAlchemyObjectType):\n    class Meta:\n        abstract = True\n        model = UserGroupMemberModel\n        interfaces = (CustomNode, )\nI'm getting the following error:\nTypeError: Invalid attributes: abstract. Hi,\nI wasn't sure where this comment was best placed.  Which is also in:\nhttps://github.com/graphql-python/graphene/issues/55\nI'm attempting to create this level of abstraction as well. I'm using graphql-sqlalchemy and when I do something like:\nclass UserGroupMember(SQLAlchemyObjectType):\n    class Meta:\n        abstract = True\n        model = UserGroupMemberModel\n        interfaces = (CustomNode, )\nI'm getting the following error:\nTypeError: Invalid attributes: abstract. ",
    "mixxorz": "This code snippet successfully extracts all fields from info:\n``` python\ndef get_fields(info):\n    prev_fragment_names = set()\n    params = collections.defaultdict(list)\n    params = collect_fields(info.context,\n                            info.parent_type,\n                            info.field_asts[0].selection_set,\n                            params,\n                            prev_fragment_names)\nfor fragment_name in prev_fragment_names:\n    params = collect_fields(info.context,\n                            info.parent_type,\n                            info.fragments[fragment_name].selection_set,\n                            params,\n                            prev_fragment_names)\n\nreturn set(params.keys())\n\n```\nThis hasn't been tested for all edge cases though.\n. After much work, here's a much nicer code snippet to get requested fields:\nhttps://gist.github.com/mixxorz/dc36e180d1888629cf33\n. Did you find a workaround for this?\n. I've worked around the issue by using a regular graphene.Field(), and doing some trickery in the resolve method.\n``` python\nclass GraphQuery(graphene.ObjectType):\n    topic = graphene.Field(Topic, id=graphene.String(), slug=graphene.String())\ndef resolve_topic(self, args, info):\n    field = relay.NodeField(Topic)\n    if args.get('id'):\n        return field.id_fetcher(args.['id'], info)\n    return get_topic(info, **args)\n\n```\n. ",
    "ProjectCheshire": "This appears resolved, per gist above / also from 2016 :p . I was working on something similar, and thought someone could refine/make use of, My use case is that I don't even the queries/mutations to appear, (I'm using directives for field level)\n```\nBaseQuery(graphene.ObjectType):\n    pass\nQuery_001(BaseQuery):\nscopes = ['admin']\nqueryThing = List(SomeType, thing=SomeTypesInput(), resolver=thisthingsresolver)\nQuery_002(BaseQuery):\nscopes = ['user']\nqueryanother = (same routine as above, as standard)\nUSER_SCOPE = 'user' (Get this from the logged in user, which means generating the schema post authentication)\nall_queries = [Query_001, Query_002]\nfilered_queries = [i for i in all_queries if USER_SCOPE in i.scopes]\nROOT_QUERIES = type('Query', tuple(filtered_queries), {})\n```\nThen\nMYSCHEMA = graphene.Schema(query=ROOT_QUERIES)\nI haven't extensively tested it, however, or tested performance. I have no idea if this is remotely legit, but it looks like schema level decorators to filter out mutations/queries like we can do with fields with directives is nowhere to be found (yet - though some people have been making proposals for it)\n. @dfee For permissions on models, that is great :) I hadn't seen that before. \nWhat I was referring to was a dynamic generation of the schema to filter the queries / mutations / etc. \nWould it work the same way? \nMore complex oyvey. Actually, I'm trying to get away from the super complex, which I was gravitating to via neomodel and doing scopes on structuredrels and the like and defining roles as nodes(in the neo4j sense) unto themselves and checking for the rel vs the string. . @dfee bollocks. I have dynamic schema generation working (I want to run some tests on performance) using the method I outlined. I have a base mutation/query/subscription class I inherit the rest from, so I can actually access them all through Base.subclasses()\nGiven that list, I then filter them (using the primitive scopes method I described with strings, heh - each base has default scopes) and then the filtered list becomes what the schema is built from using type()\nCurrently I have it under the RootValue(GraphqlView) class so when I resolve the get root value, I can generate the schema. I ensure that I have a user since I'm using flask_classful decorators and login_required. At load time, I use a default schema with dummy operations (eg returning a random cat from https://placekitten.com/)\nWhat Id love to see is schema level decorators as mentioned in https://github.com/apollographql/graphql-decorators and some other places. \nThere is a long (but really interesting) discussion of filters on introspection / schema at https://github.com/graphql/graphql-js/issues/113 which I think? resolved to facebook sorts saying 'don't do it' \nHm, I wonder if caching the schema in the session or flask.g would work (Note: I'm not advanced with web whatnot so pardon my naivete. I mostly work on embedded and found graphql to be pretty amazing for some of the edge/cloud/fog work I'm doing. I'm working on a proto port of using graphql as the api layer inside EdgeXFoundry)\n. So.. I think I'm going back to my original what-feels-heavy implementation, but using some concepts from your implementation above with Permits / resources (at least for the models portion. I'm still waffling on schema filtering)\nMy stack is Neo4j -> neomodel -> graphene, so I'm going to set up my roles as nodes so i can use the neomodel relationship search capability by associating users to them, and set up permits on the role nodes, either the class or a specific instance. Similarly with the user, so the get_permits for a given user will be the combination of the permits on their roles and their own permits. \nStill sketching it out, and I need to verify how neomodel/neo4j will store it. The permit may become simply a structuredrel between a user node and specific instance nodes that are outside their role set of permits (eg, exceptions, or a user cannot edit all nodes of type x but can edit this specific node of type x\nSo far, graphql plays really nicely with neomodel, so I'm pretty confident I can stuff this then into the AuthorizationMiddleware as suggested above. \nThanks for the commentary and pointers!. @dfee @japrogramer wanted to share, since I finally have something that seems to be consistently working going. \n(and yes, I am excited in what feels like fighting this forever)\n- AioHttp based, 95% of my traffic goes over websockets\n- using asyncio/await, and no observables\n- for routing and message permissions/channels equivalent, Im using rabbitmq (base container from dockerhub)\nI have a simple pub mixin i include on any class that I am going to have publish. (This could probably be cleaned up)\n\nI set it up to have a standard channel name so that I can dynamically grab/generate/route to the correct queues. eg. I want to be able from the team node (neo4j) get to the project node,and when there, use the project.channel_name:{mutation_name} as a way to route who needs to get what updates.\nso i have \nproject:id:teamUpdated\nproject:id:teamRemoved\net al.\nReality being is that I wont need as many subscriptions as Queries/mutations (I think...)\n\n```python\nclass PublisherMixin(object):\n    @property\n    def channel_name(self):\n        return self.cls_name + ':' + str(self.id) if hasattr(self, 'cls_name') else str(self.id)\nasync def pub(self, payload, routing_key=None):\n    logger.debug('pub triggered')\n    loop = asyncio.get_event_loop()\n    if routing_key is None:\n        routing_key = self.channel_name\n    connection = await aio_pika.connect_robust('amqp://guest:guest@localhost/', loop=loop)\n    channel = await asyncio.ensure_future(connection.channel())\n    maybe = aio_pika.Message(body=pickle.dumps(payload))\n    logger.debug(routing_key)\n\n    await channel.default_exchange.publish(maybe, routing_key=routing_key)\n\n```\nwhich means during my mutations i can just call something like 'routing = [ go find the right routing path key] + 'mutationName'\nasyncio.ensure_future(this_mutated_object_doohickey.pub(payload=this_mutated_object_doohickey, routing_key=routing)\nAgain, probably more elegant ways to solve, but it's working and for now that feels fan-damn-tastic.\nmy subscription is just \npython\nclass TeamSubscription(BaseSubscription):\n    on_team_updated = Field(TeamType, input=UUID(), resolver=resolve.team_updated_subscription)\neasy peasy standard args/query format.\nresolver\npython\nasync def team_updated_subscription(root, info, **args):\n    loop = asyncio.get_event_loop()\n    connection = await aio_pika.connect_robust('amqp://guest:guest@localhost/', loop=loop)\n    channel = await asyncio.ensure_future(connection.channel())\n    x = args['input']\n    lazy = LazySwitcher()\n    p = lazy.project.get(root=root, eid=x, info=info)\n    q_name = p.channel_name + ':onTeamUpdated'\n    keh = await channel.declare_queue(q_name, auto_delete=True)\n    while True:\n        async for message in keh:\n            m = pickle.loads(message.body)\n            with message.process():\n                yield m\nlazy is just a mapping into lazy_callables to get around some circular dependency issues. I have an object that maintains it's own internal mapping so I can avoid circular import hell. Nothing special there. \nusing the base rabbit-alpine docker\n```yaml\nversion: '3.3'\nservices:\n  roger:\n    image: rabbitmq:3.7.6-alpine\n    network_mode: host\n    container_name: roger\n```\nhttps://github.com/heyrict/cindy-realtime was probably the most useful repository ever for referencing things\n(aside, to get the AioHttp subscription server working with middleware and authentication I had to subclass and override quite a bit. However, now that I did it, I'm loving having most of my traffic over websockets *for a hilarious read on subscriptions / etc read about 5 minutes into here ) . @syrusakbary what ended being the recommended approach on this? I'm using graphql python and loving it, and I'm working on an iot device project where they use mqtt for data observations.  Curious if there is a recommended approach or if it is 'do what thou wilt' for subscriptions in graphql python. \nThanks! . Cleaning up the backlog - thanks for your post / sources!. @ahopkins you rock my socks. my folder structure is almost the exact same as yours and I'm totally going to steal your code. Err, 'make use of open source ecosystem' \n\n- input\n- type\n- model // this is my OGM layer since I'm working with neo4j\n- mutations\n- queries\n- resolvers // I've been doing from . import resolvers as resolve so I can do resolver=resolve.create_ or resolve.users and keep the functional bits all together and the other files crisp.\nFWIW, I've been loving using neomodel with graphene if anyone else goes down the neo4j-python-graphql rabbit hole :) \n. Resolving per above and lack of further activity.. It appears this is resolved. Please let me know if otherwise.. I've set up mixins for sets of fields that I use with my mutation /subscription argument classes, and even the object type. Then I include those with the class, and any additional fields required. It works well for the object type for resolvers that 'just work' without additional defs, eg 1:1 mapping of the field name from the root/model. If I need to define a custom resolver, then I set that field explicitly. . @altaurog actually graphene has a thing called lazy_import you can import.\nScroll down on https://github.com/graphql-python/graphene/issues/714\nCircular refs dodged! \n. Fixed by #891 . @heyhugo I have a fractal style schema where one module per entity and a mutation / type / model / query / subscription files within that.\nI also have my resolvers separated out between query/mute and field resolvers just to keep the logic semi organized and then all my fields have resolver= in the types.\nWhat is magic is that I auto generate my schema by some old fashioned python and inheriting from common classes by root type. I forget from whom I sourced this from, but it's worked really well for me for the past year ish.\nIt's a workaround, and I'd love to see the query / mutation homogenity too :) \nhttps://gist.github.com/ProjectCheshire/277c5ff1468460a05c2a44556e270eff\n. @cmmartti similar to how graphene does with lazy import. https://pypi.org/project/lazy-import/\nThere's probably a github issue around here that mentions it specifically :) \nFor functions I often use lazy callable if there is some shared logic I need*. (such as inflating models via neomodel) Since I'm using a graph database, I get a lot of circular models.\n*I'm not a guru, so if you delve deep and find the way to pass the type hints (eg your typical ide sugars) along when calling a lazy callable, I'm all ears.\n(geography is just my mixin for wkt and geojson fields and some common funcs I use when using the spatial plugins on neo4j) \n```python\nfrom graphene import String, Int, ObjectType, Float, Field, lazy_import\nfrom api.models.global_resolvers import country_\nfrom ..fields import GeographyFields\nclass CityType(ObjectType, GeographyFields):\n    \"\"\"A City represents authoritative data on a location as defined in Geonames.org\"\"\"\n    name = String()\n    country = Field(lazy_import('api.models.country.type.CountryType'), resolver=country_)\n    timezone = String()\n    latitude = Float()\n    longitude = Float()\n    population = Int()\n    featureCode = String()\n    featureClass = String()\n    geonameid = Int()\n```. @prokher Tidying up the backlog - I don't think this requires any more info and is not a bug/other request. Please let me know if otherwise.. Documentation is similar to a schema with models/types/mutations/queries scoped by 'entity'. \nThere are clear 'sections' within graphql-python which each need elements like\n\n[ ] Explanation / Summary - What is this / why is it useful / where is it used\n[ ] Link to relevant place(s) in the libraries\n[ ] Code examples (maybe even a repl / datacamp embedded type runnable?)\n[ ] Simple case, it runs, but not much else\n[ ] Non trivial case\n[ ] Integrations++  Not specifically Django/aiohttp/nameaframework, but more like auth/sessions/jwt or even libraries to be easy to use/work well with (eg neomodel has made using neo4j + graphql-python near trivial, though the async python Neo4J support is lagging)\n\nIn general, I find lists help people focus and see the progress of a thing. It is easier to say \"I will do a pull request to add a non-trivial example to the middleware section\" vs 'Yay! I'd love to to help!\" and be confronted with the vast blank paper (editor) problem of where to start, and also know what is already being worked on. E.g. I think the subscriptions/websocket area needs a hefty amount of docs given the issues I see come through here and elsewhere - I use RabbitMQ for my pubsub support (since I'm already using it for RPC support), it's worked great, but I have no idea of better practices or what others are doing. \nMy wishlist:\n Custom directives (is this even possible?)\n Subscriptions in more detail\n* Tracing / Extensions (I went through a hack job of getting tracing/extensions to work with graphql-python and having more analytics / performance measures is a great way to advocate the library for production)\nSimilar to the integrations, I'd love to see an Appendix where the community can submit supplementary libraries that integrate with graphql-python.\nNot being an armchair pontificator witout action, I can take a first stab at an outline if the general breakdown of what is wanted for each section seems accurate / other additions. @syrusakbary thoughts?. @jkimbo yikes. Thanks for the headsup. \nI think it's a feedback loop - the better the docs, the easier it is to grow a community which in turn begets better docs/contributions and better utilization in production environments (which gets better press and thus more community so on so forth).\n( Related to the above, I think it'd be grand to have 'starter kits' where someone could clone a repo and get at least a semi-functional app they can poke with basic things like auth, subscriptions, etc. so they can build on that vs everything from scratch - good for growth and new blood - there may very well be some, just not well advertised). I'm game, mostly from the documentation/information dissemination side. jessamyn.hodge@gmail.com. @ktosiek only things under the graphql-python namespace are considered. Syrus has a lot of projects :) . @dfee there you are! If you can pass me your preferred email, I can add you to the slack if you aren't already. . @hannes-petri-maxiv-lu-se You can find the ResolveInfo object at https://github.com/graphql-python/graphql-core/blob/master/graphql/execution/base.py . I use functools lru cache https://docs.python.org/3/library/functools.html. And elsewhere it is root, info, **args\nConsistent would be fantastic . ",
    "thebritican": "While we investigate a solution to this, is there a way to incorporate an Edge as the payload and then write schema with vanilla python-graphql objects? Basically, can I write this in Python and reference it as an output field?\nIf not, my next intermediate solution was to produce the schema with Graphene and then introspect the produced schema, modifying the payload.\nAs for how Graphene could implement this: we only need a cursor_id field to be returned as well as node. I'm not sure how cursor_id is computed, but if we compute that string via the Edge constructor and pass it the relevant node, would that suffice? I was trying to use cursorForObjectInConnection to no avail.\n. I see the cursor_for_object_in_connection and it appears functionally equivalent to the JS repo (and passes on the corresponding tests). Until it is working(?), however, using a graphQLCoreType is tough since the aforementioned method is used to generate the opaque cursor string. I'm assuming I can just generate a naive cursor in the meantime, but querying with before and after would likely be broken when relay tries to reconcile the edge with an existing connection list.\nI'll take a look at this next week if it's still open and try a PR. Thanks for the great work so far!\n. ",
    "mikberg": "@thebritican Did you find a work-around for this? I'm creating a cursor via offset_to_cursor and trying to return it as an edge, but can't get it to work.\n@syrusakbary What would the \"theGraphQLCoreType\" be? My connection is to objects of type Comment, so I've been trying to use CommentEdge. It produces the correct schema, the execution errors with Cannot return null for non-nullable field CommentEdge.cursor, which I've tried to set in mutate_and_get_payload in a couple of different ways ...\n. ",
    "rafales": "Current implementation of cursor_for_object_in_connection relies heavily on the fact that data is provided as a list. What about Django ORM/SQLAlchemy where there may be thousands of records? This would cause to fetch them all. It doesn't seem like a good idea.\n. This bit me too.\n. Depends on the requirements.\nFor example syntax where we can define scalar fields without the need to use Field instance looks a bit nicer but is one of the causes of additional complexity and is misleading, especially at the beginning. Are you open to changing that to more sqlalchemy-like style? Or is this the syntax we want and all we can do is change the internals?\n. ",
    "defrex": "BTW, a couple tips for anyone else looking at this. You can grab a reference to a Relay edge like so.\n``` python\nfrom graphene.relay.types import Edge\nMyEdge = Edge.for_node(MyNode)\n```\nAlso, if you're using array cursors for now, this is probably the most performant option.\n``` python\nfrom graphql_relay.connection.arrayconnection import cursor_for_object_in_connection\ncursor_for_object_in_connection(list(MyModel.object.values_list('id', flat=True)), my_model.id)\n```\n. @mickeyinfoshan that assumes your edge is at the end of the list. If it's somewhere in the list, but you don't know the offset, this won't work.\n. Fundamentally, index-based cursors are never going to work, because you need the full context of the list to know what the index will be. In a relay context, that means a different cursor for every sort/filter combo that might be addressing the edge. The data required for that is out of control, IMO.\nStepping back, the only requirement for a cursor is that you can select before and after it. Thus, the simplest type of non-index cursor is the sort value for the list. For example, say you have a list of objects with created_date fields, ordered by created_date. In that case, your cursor could literally be the created_date value for the object, since you can always .filter(created_date__gt=cursor) to slice the results.\nOptionally, if you want the sort field to be dynamic, you can use an object's unique id. In that case you would need to query the sort value matching that id and perform a similar query.\nAs far as I can tell, once of these two options is required to solve this issue.\n. Thanks for the help!\n. That did the job, thanks!\n. Consistency with the other basic types seems like a good idea, though if graphene.Field is still necessary that should probably be noted in the docs.\nIf you let me know where you net out I can adjust the PR accordingly.\n. Awesome. In that case, maybe it's not necessary to show off the custom field being used. It's still a good idea to add the import though.\n. Looks like this is solved as of 0.7.2. I upgraded yesterday afternoon, and I can no longer reproduce.\nKeep up the great work!\n. @syrusakbary Thanks for the quick response! \nWhere is that schema object coming from?\n. Ah, I see. I can't reference that from this point in the code without a circular import, since I'm still defining the schema. That's a good lead on how to solve it though. I'll dig into the source there and see if I can work around the issue.\n. That'll do. Thanks for the help once again.\n. Unfortunately, because I'm using Relay, the data returned from successful mutations is mostly out of my control.\nThe spec does seem to allow for extending the error objects.\n\nGraphQL servers may provide additional entries to error as they choose to produce more helpful or machine\u2010readable errors, however future versions of the spec may describe additional entries to errors.\n\nSomething as simple as an addition property I can add to an exception object that can be copied transparently into the error would be immediately useful.\nAt the moment I've resorted to json-encoding some extra data into the message line of an exception, which makes me feel like I need a shower, haha.\n. This approach would be great, but doesn't work well with react-relay.\nIn relay, you can't directly control the mutation queries. You tell relay which types of data may be changed after the mutation, and it generates a query that fetches just enough data to replace anything it has cached. You can't manually add fields to the mutation response.\nI suppose you could work around this by having a top-level \"errors\" type in the schema and get relay to invalidate it's cached state when you run a mutation. It's a hack for sure, and you couldn't have errors from multiple mutations in memory at once this way, but it might work.\n. I haven't take the time to power through the with_context breaking change yet, since it destroys my codebase utterly. I'll make the time to get up to date soon though, and let you know how this solution works for me.\n. I figured it out. It's the args keyword argument to schema.execute. It should be a dict (or other map type) and the keys should be camelCase. For example:\nPython\nschema.execute(\n    '''\n    mutation UpdateItem($input_key: UpdateItemMutationInput!) {\n        updateItem(input: $input_key)\n    }\n    ''',\n    args={\n        'input_key': {\n            'clientMutationId': 'whatever',\n            'someOtherInputValue': 42,\n        }\n    },\n)\n. I would love this. \nI'll underscore one point. Right now you can't lookup a node's cursor without the full context of the connection. This means returning an edge from a mutation requires a ton of overhead and possibly knowledge you don't have. For that reason the ability to look up a cursor for a given node without any additional information should be a goal. This issue has been discussed a lot in #59.\nAlso, to solve the issue of a missing order value, you could order by primary key by default.\n. ",
    "mickeyinfoshan": "Any new progress about this issue? \n. I've found a tricky way to get the new edge, which may help.\nuse offset_to_cursor  in graphql_relay.connection.arrayconnection.\nHere's an example:\n``` python\nclass AddTodo(relay.ClientIDMutation):\nclass Input:\n    text = String(required=True)\n\nviewer = Field(User)\ntodoEdge = Field(relay.types.Edge.for_node(Todo))\n\n@classmethod\ndef mutate_and_get_payload(cls, input, info):\n    viewer = get_viewer(info.request_context)\n    todo = viewer.todos.create(text=input.get(\"text\"))\n\n   # get cursor here!\n    cursor = offset_to_cursor(viewer.todos.count() - 1)\n\n    edge = relay.types.Edge.for_node(Todo)(node=todo, cursor=cursor)\n    return AddTodo(viewer=viewer, todoEdge=edge)\n\n```\n. @defrex It is just a tricky way to get the new cursor while performing a RANGE_ADD request, where the new edge should be the last one. It's not a clean one but a fast one for the reason that you don't need to iterate the list at all. In addition, RANGE_ADD is the only situation that a cursor is required on the server-side explicitly, as far as I'm concerned. \n. Thank you! \n. I have not modified any code yet but 10 tests failed. What's wrong?\n``` sh\n====================================================================================== FAILURES ======================================================================================____________ test_object_type ______________\ndef test_object_type():\n    object_type = schema.T(Human)\n    Human._meta.fields_map\n    assert Human._meta.interface is False\n    assert isinstance(object_type, GraphQLObjectType)\n    assert_equal_lists(\n\n\n      object_type.get_fields().keys(),\n        ['headline', 'id', 'reporter', 'pubDate']\n    )\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/contrib/django/tests/test_types.py:77: AttributeError\n__________ testdjango_objecttype_could_extend_interface ____________\ndef test_django_objecttype_could_extend_interface():\n    schema = Schema()\n\n    @schema.register\n    class Customer(Interface):\n        id = Int()\n\n    @schema.register\n    class UserType(DjangoObjectType):\n        class Meta:\n            model = Reporter\n            interfaces = [Customer]\n\n    object_type = schema.T(UserType)\n\n\n  assert schema.T(Customer) in object_type.get_interfaces()\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_interfaces'\n\ngraphene/contrib/django/tests/test_types.py:102: AttributeError\n___________ test_objecttype_registered ___________\ndef test_objecttype_registered():\n    object_type = schema.T(Character)\n    assert isinstance(object_type, GraphQLObjectType)\n    assert Character._meta.model == Reporter\n    assert_equal_lists(\n\n\n      object_type.get_fields().keys(),\n        ['articles', 'firstName', 'lastName', 'email', 'id']\n    )\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/contrib/sqlalchemy/tests/test_types.py:50: AttributeError\n____________ test_object_type ______________\ndef test_object_type():\n    object_type = schema.T(Human)\n    Human._meta.fields_map\n    assert Human._meta.interface is False\n    assert isinstance(object_type, GraphQLObjectType)\n    assert_equal_lists(\n\n\n      object_type.get_fields().keys(),\n        ['headline', 'id', 'reporter', 'reporterId', 'pubDate']\n    )\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/contrib/sqlalchemy/tests/test_types.py:94: AttributeError\n___________ testinputobjecttype ____________\ndef test_inputobjecttype():\n    class InputCharacter(InputObjectType):\n        '''InputCharacter description'''\n        name = String()\n\n    schema = Schema()\n\n    object_type = schema.T(InputCharacter)\n    assert isinstance(object_type, GraphQLInputObjectType)\n    assert InputCharacter._meta.type_name == 'InputCharacter'\n    assert object_type.description == 'InputCharacter description'\n\n\n  assert list(object_type.get_fields().keys()) == ['name']\n\nE       AttributeError: 'GraphQLInputObjectType' object has no attribute 'get_fields'\n\ngraphene/core/classtypes/tests/test_inputobjecttype.py:21: AttributeError\n_____________ test_interface _______________\ndef test_interface():\n    class Character(Interface):\n        '''Character description'''\n        name = String()\n\n    schema = Schema()\n\n    object_type = schema.T(Character)\n    assert issubclass(Character, Interface)\n    assert isinstance(object_type, GraphQLInterfaceType)\n    assert Character._meta.interface\n    assert Character._meta.type_name == 'Character'\n    assert object_type.description == 'Character description'\n\n\n  assert list(object_type.get_fields().keys()) == ['name']\n\nE       AttributeError: 'GraphQLInterfaceType' object has no attribute 'get_fields'\n\ngraphene/core/classtypes/tests/test_interface.py:24: AttributeError\n_____________ test_mutation ________________\ndef test_mutation():\n    class MyMutation(Mutation):\n        '''MyMutation description'''\n        class Input:\n            arg_name = String()\n        name = String()\n\n    schema = Schema()\n\n    object_type = schema.T(MyMutation)\n    assert MyMutation._meta.type_name == 'MyMutation'\n    assert isinstance(object_type, GraphQLObjectType)\n    assert object_type.description == 'MyMutation description'\n\n\n  assert list(object_type.get_fields().keys()) == ['name']\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/core/classtypes/tests/test_mutation.py:24: AttributeError\n____________ test_object_type ______________\ndef test_object_type():\n    class Human(ObjectType):\n        '''Human description'''\n        name = String()\n        friends = String()\n\n    schema = Schema()\n\n    object_type = schema.T(Human)\n    assert Human._meta.type_name == 'Human'\n    assert isinstance(object_type, GraphQLObjectType)\n    assert object_type.description == 'Human description'\n\n\n  assert list(object_type.get_fields().keys()) == ['name', 'friends']\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/core/classtypes/tests/test_objecttype.py:23: AttributeError\n_____________ test_uniontype _______________\ndef test_uniontype():\n    class Human(ObjectType):\n        name = String()\n\n    class Pet(ObjectType):\n        name = String()\n\n    class Thing(UnionType):\n        '''Thing union description'''\n        class Meta:\n            types = [Human, Pet]\n\n    schema = Schema()\n\n    object_type = schema.T(Thing)\n    assert isinstance(object_type, GraphQLUnionType)\n    assert Thing._meta.type_name == 'Thing'\n    assert object_type.description == 'Thing union description'\n\n\n  assert object_type.get_types() == [schema.T(Human), schema.T(Pet)]\n\nE       AttributeError: 'GraphQLUnionType' object has no attribute 'get_types'\n\ngraphene/core/classtypes/tests/test_uniontype.py:28: AttributeError\n___________ test_node_connection_should_have_edge ____________\ndef test_node_connection_should_have_edge():\n    connection = relay.Connection.for_node(OtherNode)\n    edge = relay.Edge.for_node(OtherNode)\n    connection_type = schema.T(connection)\n\n\n  connection_fields = connection_type.get_fields()\n\nE       AttributeError: 'GraphQLObjectType' object has no attribute 'get_fields'\n\ngraphene/relay/tests/test_types.py:63: AttributeError\n======================================================================= 10 failed, 308 passed in 4.69 seconds ========================================================================\n```\n. ",
    "varunarora": "Is there any temporary version of documentation on this? Perhaps in another branch?\n. So turns out switching back to an old Django version wasn't that hard. And this might be an issue with how pip works. Irrespective, it makes for a very bad user experience.\nThere is another issue with the choice of Django version. It seems like the app actually requires a minimum of Django 1.8. I got this error AFTER upgrading to 1.6.11:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py\", line 99, in get_response\n    resolver_match = resolver.resolve(request.path_info)\n  File \"/usr/local/lib/python2.7/dist-packages/django/core/urlresolvers.py\", line 337, in resolve\n    for pattern in self.url_patterns:\n  File \"/usr/local/lib/python2.7/dist-packages/django/core/urlresolvers.py\", line 365, in url_patterns\n    patterns = getattr(self.urlconf_module, \"urlpatterns\", self.urlconf_module)\n  File \"/usr/local/lib/python2.7/dist-packages/django/core/urlresolvers.py\", line 360, in urlconf_module\n    self._urlconf_module = import_module(self.urlconf_name)\n  File \"/usr/local/lib/python2.7/dist-packages/django/utils/importlib.py\", line 40, in import_module\n    __import__(name)\n  File \"/home/varun/Code/opencurriculum/oc_platform/oc_platform/urls.py\", line 6, in <module>\n    from oc_platform.schema import schema\n  File \"/home/varun/Code/opencurriculum/oc_platform/oc_platform/schema.py\", line 2, in <module>\n    import curriculum.schema\n  File \"/home/varun/Code/opencurriculum/oc_platform/curriculum/schema.py\", line 2, in <module>\n    from graphene.contrib.django.filter.fields import DjangoFilterConnectionField\n  File \"/usr/local/lib/python2.7/dist-packages/graphene/contrib/django/filter/fields.py\", line 2, in <module>\n    from .utils import get_filtering_args_from_filterset, get_filterset_class\n  File \"/usr/local/lib/python2.7/dist-packages/graphene/contrib/django/filter/utils.py\", line 4, in <module>\n    from .filterset import custom_filterset_factory, setup_filterset\n  File \"/usr/local/lib/python2.7/dist-packages/graphene/contrib/django/filter/filterset.py\", line 7, in <module>\n    from django_filters import Filter, MultipleChoiceFilter\n  File \"/usr/local/lib/python2.7/dist-packages/django_filters/__init__.py\", line 3, in <module>\n    from .filterset import FilterSet\n  File \"/usr/local/lib/python2.7/dist-packages/django_filters/filterset.py\", line 19, in <module>\n    from .filters import (Filter, CharFilter, BooleanFilter, BaseInFilter, BaseRangeFilter,\n  File \"/usr/local/lib/python2.7/dist-packages/django_filters/filters.py\", line 16, in <module>\n    from .fields import (\n  File \"/usr/local/lib/python2.7/dist-packages/django_filters/fields.py\", line 13, in <module>\n    from .utils import handle_timezone\n  File \"/usr/local/lib/python2.7/dist-packages/django_filters/utils.py\", line 4, in <module>\n    from django.db.models.expressions import Expression\nImportError: cannot import name Expression\n. ",
    "richburdon": "Broken link (https://github.com/graphql-python/graphene/blob/1.0/graphene/relay/tests/test_connection.py)\nAlso, the official example doesn't seem to implement creating edges in the mutation.\nhttps://github.com/graphql-python/graphene/blob/master/examples/starwars_relay/schema.py\nSo I'm still getting:\nError: Cannot query field \"createItemEdge\" on type \"CreateItemMutationPayload\".\nBecause My parent class defines:\nitems = relay.ConnectionField(Item)\n. Thanks @varuna82 really helpful.\n. ",
    "varuna82": "Here's how I create an edge. There might be a better solutions, but hope this will help for now.\nfrom graphql_relay.connection.arrayconnection import offset_to_cursor\ncursor = offset_to_cursor(0)\nedge_type = TestNode.Connection.Edge or Edge\nedge = edge_type(cursor=cursor, node=new_event)\nFollowing link explains how to create custom connection.\nhttp://docs.graphene-python.org/en/latest/relay/connection/\n. ",
    "reinierpd": "I'm using graphene-django 1.3 and  neither relay.types.Edge  or relay.Edge exist. Any idea from where  can  i import Edge ?? @mickeyinfoshan. ",
    "rangermeier": "Since I struggled a lot to expose a newly created item as edge, here is a complete example using Graphene 2.0, building on the suggestions from  @mickeyinfoshan and @varuna82. Hope this is of some help:\n```Python\nimport graphene\nfrom graphene import relay\nfrom graphene_django import DjangoObjectType\nfrom graphql_relay.connection.arrayconnection import offset_to_cursor\nfrom myapp import models\nclass Topic(DjangoObjectType):\n    class Meta:\n        model = models.Topic\n        interfaces = (relay.Node, )\nTopicEdge = Topic._meta.connection.Edge\nclass CreateTopic(relay.ClientIDMutation):\n    class Input:\n        title = graphene.String(required=True)\ntopic = graphene.Field(Topic)\ntopic_edge = graphene.Field(TopicEdge)\n\n@classmethod\ndef mutate_and_get_payload(cls, root, info, **input):\n    topic = models.Topic.objects.create(title=input['title'], created_by=user)\n    edge = TopicEdge(cursor=offset_to_cursor(0), node=topic)\n    return CreateTopic(topic=topic, topic_edge=edge)\n\n```. ",
    "michaelkuty": ":+1: \n. Big thanks, maybe notice somewhere will be good for others. Is there possibility to declare max_length as parameter for String constructor ? like String(max_length=20) ?\nmaybe factory.. ?. I write simple wrapper around your example\n```\ndef String(length=None, args, *kwargs):\ndef assert_short_string(str_value):\n    if length and len(str_value) > length:\n        raise Exception(\"Some parameter has more \"\n                        \"than allowed number of characters (%s) \" % length)\n\nclass ShortString(Scalar):\n    '''\n    The `ShortString` scalar type represents textual data, represented as UTF-8\n    character sequences, with a max length of 255.\n    '''\n\n    @staticmethod\n    def coerce_string(value):\n        if isinstance(value, bool):\n            return u'true' if value else u'false'\n\n        str_value = six.text_type(value)\n        assert_short_string(str_value)\n        return str_value\n\n    serialize = coerce_string\n    parse_value = coerce_string\n\n    @staticmethod\n    def parse_literal(ast):\n        if isinstance(ast, StringValue):\n            assert_short_string(ast.value)\n            return ast.value\n\nreturn ShortString(*args, **kwargs)\n\n```\nThanks again for your time !. Yes, this is still little bit tricky, but we have own registry where we suppress this error.. \ud83e\udd14 . ",
    "Virako": "Hello @syrusakbary, if I want to use graphql with the geodjango, is possible? I'm newby with graphql, but when i want to try add models.PointField to graphql, I obtain Exception: Don't know how to convert the Django field player.Player.pos (). Do you know how to resolve this problem? Is easy or i should create a graphene-geojson package first? Thanks you very much. ",
    "Mhs-220": "same problem here,\nhow can i solve it?. @farnoodma Hey there!\nI had same problem but finally i fix it!\nHere is my code\nclass OrderedDjangoFilterConnectionField(DjangoFilterConnectionField):\n    @classmethod\n    def connection_resolver(cls, resolver, connection, default_manager, max_limit,\n                            enforce_first_or_last, filterset_class, filtering_args,\n                            root, info, **args):\n        filter_kwargs = {k: v for k, v in args.items() if k in filtering_args}\n        qs = filterset_class(\n            data=filter_kwargs,\n            queryset=default_manager.get_queryset(),\n            request=info.context\n        ).qs\n        order = args.get('orderBy', None)\n        if order:\n            qs = qs.order_by(*order)\n        return super(DjangoFilterConnectionField, cls).connection_resolver(\n            resolver,\n            connection,\n            qs,\n            max_limit,\n            enforce_first_or_last,\n            root,\n            info,\n            **args\n    )\nand then, just use it instead of DjangoFilterConnectionField, like this:\nperson = OrderedDjangoFilterConnectionField( PersonNode, orderBy=graphene.List(of_type=graphene.String) )\nand then, the query is something like this:\nquery {\n    person (orderBy: [\"field1\",\"-field2\"...]){\n        edges{\n            node{\n                name\n            }\n        }\n    }\n}\nP.S: fix pagination bug. @giorgi94 hey again, no there is no pagination bug for me( i use default graphene pagination ). @androane I copy this method from here and just added three line to it and it's working for me properly. ",
    "farnoodma": "+1. Ok whats going on here? There is no orderBy (or order_by) documentation and also there is no order_by function or variable in DjangoFilterConnectionField! Latest version will throw this error:\nUnknown argument \\\"orderBy\\\" on field ...\nor if you use order_by:\nUnknown argument \\\"order_by\\\" on field ...\nThere is unused order_by in DjangoFilterConnectionField:\ndef __init__(self, type, fields=None, order_by=None,\n                 extra_filter_meta=None, filterset_class=None,\n                 *args, **kwargs):\n        self._fields = fields\n        self._provided_filterset_class = filterset_class\n        self._filterset_class = None\n        self._extra_filter_meta = extra_filter_meta\n        self._base_args = None\n        super(DjangoFilterConnectionField, self).__init__(type, *args, **kwargs)\nAnd also there is no filter_order_by in DjangoObjectType Meta fields. (which mentioned in other issue)\nPlease let me know how should I order my objects in latest version?. ",
    "zbyte64": "This guy is working on one: https://github.com/flavors/django-graphql-geojson/. Found the unit tests from graphql-core to be very enlightening: https://github.com/graphql-python/graphql-core/blob/master/tests/starwars/starwars_schema.py\n. I think graphql has an emphasis on fields that DRF does not in that they are also connections. Relying on different serializers/ObjectType's might result in recreating large trees of serialization. Thinking of an example; moderating blog comments we might see::\n```\nclass Portal(ObjectType):\n    blog = Field(Blog)\nclass Blog(ObjectType):\n    comments = List(Comment)\nclass Comment(ObjectType):\n     user = Field(User)\n     flags = List(ModeratorFlags)\n```\nBut for a standard user we would need to reimplement the entirety with a different User reference as not to include sensitive information. . I volunteer as tribute: zbyte64@gmail.com. ",
    "mekarpeles": "I'm working on something with no security implications (all data is public), so s a make-shift solution (don't use in production), I'm registering (pseudo code) all models using the following approach crufty:\nimport Base # = some declarative_base(cls=mixin), see [1]\nimport graphene\nclass Query(graphene.ObjectType): pass\nfor k, v in Base._decl_class_registry.items():\n    setattr(Query, k.lower(), v)\n    setattr(Query, 'resolve_%s' % k, lambda self, args, info: v.get(args.get('id')).dict()) #dict() coming from [1]\n[1] see https://github.com/thegroovebox/api.groovebox.org/blob/master/groovebox/api/core.py#L33\nNote: _decl_class_registry has some non-models registered with it (e.g. _sa_module_registry), so additional error handling / logic is required. \n. ",
    "gwind": "@jfeinstein10  I saw this code  : \n``` python\nclass SQLAlchemyNode(BaseNode, SQLAlchemyInterface):\n    id = GlobalIDField()\n@classmethod\ndef get_node(cls, id, info=None):\n    try:\n        instance = cls._meta.model.filter(id=id).one()\n        return cls(instance)\n    except cls._meta.model.DoesNotExist:\n        return None\n\n```\nIn the cls._meta.model.filter(id=id).one() , I'm concern:\n1. use a django like model query , not original sqlalchemy orm usage.\n2. use id as id. Relay ID is a string, model id maybe integer always.\n@syrusakbary I'm working on sqlalchemy backend, any progress would be interested.\n. @syrusakbary  may be a raise NotImplementedError() would be a good choice.\nI have a local sqlachemy binding, but it is very basic, and i am not familiar with graphql - relay.\nThanks,\n. @syrusakbary I've saw that graphene.relay.NodeField in root query would convert original id (int or string) to a uniq ID ( type + id => base64) .\nSo my concern about instance = cls._meta.model.filter(id=id).one() was wrong: id is the object id in table exactly now.\nI've another question: the graphene convert all id to type + id => base64 string, but how to get object by id nicely?\nexample:\n``` python\nclass RootQuery(graphene.ObjectType):\n    group = graphene.Field(Group, id=graphene.String().NonNull)\ndef resolve_group(self, args, info):\n    print(\"args.get('id') = \", args.get('id'))\n\n```\nthis query is ok:\nquery MyQuery {\n  node (id: \"R3JvdXA6NA==\") {\n    id\n    ... on Group {\n      name\n      description\n    }\n  }\n}\nbut query one object is failed:\nquery MyQuery {\n    group(id:\"R3JvdXA6NA==\") {\n      id\n      name\n    }\n}\nIn graphene/relay/types , there is a to_global_id() , but no a reverse method such like from_global_id() : \n``` python\nclass Node(six.with_metaclass(NodeMeta, Interface)):\n    '''An object with an ID'''\n    id = GlobalIDField()\nclass Meta:\n    abstract = True\n\ndef to_global_id(self):\n    type_name = self._meta.type_name\n    return to_global_id(type_name, self.id)\n\nconnection_type = Connection\nedge_type = Edge\n\n@classmethod\ndef get_connection_type(cls):\n    return cls.connection_type\n\n@classmethod\ndef get_edge_type(cls):\n    return cls.edge_type\n\n```\ngraphql_relay/node/node.py have a from_global_id() indeed\npython\ndef from_global_id(global_id):\n    '''\n    Takes the \"global ID\" created by toGlobalID, and retuns the type name and ID\n    used to create it.\n    '''\n    unbased_global_id = unbase64(global_id)\n    _type, _id = unbased_global_id.split(':', 1)\n    return ResolvedGlobalId(_type, _id)\nIs there a nice method to handle this ?\n. I see, thanks :smile: \n. There is need a attention in schema = graphene.Schema(query=Query, auto_camelcase=False) , auto_camelcase would meet some issues in client-side which use React/Relay.\ne.g\n- clientMutationId\n- pageInfo\n. @syrusakbary , thanks for you fast reply!\nIn fact, I've submit a communication at github.com/facebook/relay - How to get full mutation response?\nbecause relay has restriction itself, the default behavior can not execute a mutation like:\nmutation Signin {\n    signin(input:$input_0) {\n        session {\n             id\n        }\n    }\n}\nSo, I've interest about is there anyone use graphene and react-realy build a real app?\nThanks again.\n. @syrusakbary yes, Relay is base on GraphQL, but have restrictions extremely. May be it is in progress more than a product solution.\nBut I'm very like the GraphQL, Relay, React, it is a very important thing after REST. :smile: \n. @Globegitter :+1: \nI'm working on it. Although many issues with relay in practice, I'm love it so much!\n. :+1: \n. me too.\nBTW, some related suggest:\n1. Intergrade with form validate, such as WTForm\n2. field with validate\n. Use only_fields   -  code\npython\nclass PostNode(DjangoNode):\n    class Meta:\n        model = Post\n        only_fields = ('title', 'description', 'created')\n. Hi @syrusakbary \nThank you for getting back to me.\nI agree, my pull request is not a good idea. But realy.QL have a confusion about pageInfo and it is unstable dev now. Relay like camelCase usualy, but python like snake_case except Class Name.\nThanks again.\n. This is required by GraphQL spec.\nIn the graphql_relay package, there is a /usr/local/lib/python3.4/dist-packages/graphql_relay/node/node.py\nhow to do:\npython\nfrom graphql_relay.node.node import from_global_id\nrid = from_global_id(YOUR_GLOBAL_ID)\nprint(rid.id)\n. I think so.\nMy object is defined with SQLAlchemy model:\n``` python\nclass BlogArticle(BlogNode):\nclass Meta:\n    model = models.BlogArticle\n    only_fields = ('uid', 'title', 'abstract', 'body', 'body_markup',\n                   'status', 'vote_up', 'vote_down', 'view_count', 'comment_count',\n                   'is_public', 'created', 'updated')\n\n```\nMy mutation defined:\n``` python\nclass BlogArticleNew(relay.ClientIDMutation):\nclass Input:\n    category_uid = graphene.String(description=_(\"Category UID\"))\n    catalog_uid = graphene.String(description=_(\"Catalog UID\"))\n    title = graphene.String(description=_(\"Title\"), required=True)\n    abstract = graphene.String(description=_(\"Abstract\"))\n    body = graphene.String(description=_(\"Body\"))\n    body_markup = graphene.Int(description=_(\"Body Markup\"))\n    is_public = graphene.Boolean(description=_(\"Is Public\"))\n    tags = graphene.List(graphene.String())\n\n```\nI thought that:\n1. Every field in class Input would be needed with custom description/doc. Such as title - The title about article. Needed!\n2. class Input could have a custom validation.\n3. Usually, query object is defined with ORM(Django Model / SQLAlchemy)\n. ",
    "BillyBarbaro": "@syrusakbary Thanks for the correction there.  I've only ever used graphene alongside Relay, but that all makes sense now.  Made the correction.  Let me know if you think there's anything else that needs to be done.\n. ",
    "dgoldstein0": "I think I just wasted an hour or two (maybe more) because this behavior is not demonstrated in the examples - or if it is, it's extremely nonobvious.  This should really be better documented.\n. ",
    "dwiel": "The problem is that even with this solution, resolve_hello will be run 3 separate times.  This can be a problem if that function is slow or depended on by multiple other fields in the query.\n. I see that makes sense.  Thanks for the detailed answer\nOn Thu, Feb 4, 2016 at 12:33 PM, Syrus Akbary notifications@github.com\nwrote:\n\n@dwiel https://github.com/dwiel if you wrap your fields with common\nattributes to a ObjectType, as @Globegitter\nhttps://github.com/Globegitter suggested, the resolver for this\nObjectType will be only called once.\nSo yes, resolving field would be called 3 times.\n1. The parent resolver (helloPing)\n2. The hello field in HelloPing\n3. The ping field in HelloPing\nHowever, as GraphQL (and graphene as well) is prepared to run the\nresolving fields asynchronously, this is how the nature of resolving\nqueries should look like (as defined by the Spec, when querying we cannot\nassure that the fields would resolved in order, hence we cannot depend on\nother fields resolve value in the same type level).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/graphql-python/graphene/issues/82#issuecomment-179958910\n.\n. \n",
    "matclayton": "We'd also love to see this, an example of using m2m relationships would also be fantastic.\n. This looks fantastic, we're currently running Graphene with a reasonable amount of traffic (100's queries per sec) site, and have noticed a significant amount (~50%) of CPU time / latency is spent doing query validation. When investigating fixes for this, persisted queries looks like the ideal scenario.\nAre there any plans to add persisted queries to 2.0? or alternatively provide a hook to bypass validation/parsing if we know the query comes from a trusted source.. @syrusakbary That makes perfect sense and was sort of what I was expecting, I'd just forgotten the django specific code had been pulled out into a separate package.\n. ",
    "tom-zeit": "We would also like to see this feature :)\n. I have the same issue here\n. Currently I implemented this in the following way:\n```\nclass TransactionFilter(FilterSet):\n    class Meta:\n        model = models.Transaction\nclass TransactionNode(DjangoNode):\nclass Meta:\n    model = models.Transaction\n\nclass Query(graphene.ObjectType):\n    transactions = TransactionNode.List(**get_filtering_args_from_filterset(TransactionFilter, \"a\"))\ndef resolve_transactionTest(self, args, info):\n    # If you are using graphql-django-view, the request_context is the Django request\n    return models.BusinessTransaction.objects.filter(**args)\n\n```\nIt works, but it's much more cumbersome than using DjangoFilterConnectionField. Is there an easier way to implement this?\n. ",
    "Grmiade": "Yes my classes are abstracts like this.\n```\nclass BrainstormerNode(DjangoNode):\nclass Meta:\n    model = Brainstormer\n    filter_order_by = ['name']\n\nclass BrainstormerPropositionGroupNode(DjangoNode):\nclass Meta:\n    model = BrainstormerPropositionGroup\n    filter_order_by = ['name']\n\nclass Query(ObjectType):\nclass Meta:\n    abstract = True\n\nbrainstormer = relay.NodeField(BrainstormerNode)\nall_brainstormer = DjangoFilterConnectionField(BrainstormerNode)\n\nbrainstormer_proposition_group = relay.NodeField(BrainstormerPropositionGroupNode)\nall_brainstormer_proposition_group = DjangoFilterConnectionField(BrainstormerPropositionGroupNode)\n\n```\nand\n```\nclass TrainingSessionNode(DjangoNode):\nclass Meta:\n    model = TrainingSession\n\nclass Query(ObjectType):\nclass Meta:\n    abstract = True\n\nsessions = relay.NodeField(TrainingSessionNode)\nall_sessions = DjangoFilterConnectionField(TrainingSessionNode)\n\n```\nAn idea ?\n. Sure.\nERROR Internal Server Error: /graphql\nTraceback (most recent call last):\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/django/core/handlers/base.py\", line 132, in get_response\n    response = wrapped_callback(request, *callback_args, **callback_kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/contextlib.py\", line 30, in inner\n    return func(*args, **kwds)\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/django/views/decorators/csrf.py\", line 58, in wrapped_view\n    return view_func(*args, **kwargs)\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/django/views/generic/base.py\", line 65, in view\n    self = cls(**initkwargs)\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/contrib/django/views.py\", line 10, in __init__\n    schema=schema.schema,\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/core/schema.py\", line 83, in schema\n    query=self.T(self.query),\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/core/schema.py\", line 58, in T\n    internal_type = _type.internal_type(self)\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/core/classtypes/uniontype.py\", line 37, in internal_type\n    types=list(map(schema.T, cls._meta.types)),\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/core/schema.py\", line 58, in T\n    internal_type = _type.internal_type(self)\n  File \"/Users/jeremyfauvel/.virtualenvs/mtp/lib/python3.4/site-packages/graphene/core/classtypes/objecttype.py\", line 91, in internal_type\n    raise Exception(\"Abstract ObjectTypes don't have a specific type.\")\nException: Abstract ObjectTypes don't have a specific type.\n. Thanks.\n. It's work !\nSo fast ! Thank you so much ;)\n. ",
    "greenteamer": "Hello, i have the same 500 error in 0.7.3 version when trying \nquery {\n  allNotes {\n    edges {\n      node {\n        id,\n        title\n      }\n    }\n  }\n}\nthis is my schema \npython\nclass NotesNode(DjangoNode):\n    class Meta:\n        model = Notes\n        filter_fields = ['title',]\n        filter_order_by = ['title']\n``` python\nclass Query(ObjectType):\n    note = relay.NodeField(NotesNode)\n    all_notes = DjangoFilterConnectionField(NotesNode)\nclass Meta:\n    abstract = True\n\n```\npython\nschema = graphene.Schema(name='Notes Schema')\nschema.query = Query\nand this is my model \n``` python\nclass Notes(models.Model):\n    title   = models.CharField(max_length=100)\n    text    = models.TextField()\ndef __str__(self):\n    return self.title\n\n.\nTraceback (most recent call last):\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/django/core/handlers/base.py\", line 149, in get_response\n    response = self.process_exception_by_middleware(e, request)\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/django/core/handlers/base.py\", line 147, in get_response\n    response = wrapped_callback(request, callback_args, callback_kwargs)\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/django/views/decorators/csrf.py\", line 58, in wrapped_view\n    return view_func(*args, kwargs)\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/django/views/generic/base.py\", line 62, in view\n    self = cls(*initkwargs)\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/graphene/contrib/django/views.py\", line 10, in init\n    schema=schema.schema,\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/graphene/core/schema.py\", line 86, in schema\n    query=self.T(self.query),\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/graphene/core/schema.py\", line 61, in T\n    internal_type = _type.internal_type(self)\n  File \"/Users/greenteamer/Desktop/Django/env/monolit/lib/python2.7/site-packages/graphene/core/classtypes/objecttype.py\", line 96, in internal_type\n    raise Exception(\"Abstract ObjectTypes don't have a specific type.\")\nException: Abstract ObjectTypes don't have a specific type.\n```\n. wow ... this is amasing!!! thank you !!! you did a great job\n. ",
    "jfeinstein10": "Thanks for pushing this past the finish line and my apologies for not having enough time to do it myself!\n. ",
    "bradreardon": "Hi @syrusakbary, I'm either mistaken or the docs on this are out of date. It appears that even when using graphql-django-view, request_context is not an attribute passed on the info parameter of resolve functions.\nAm I doing something wrong? Perhaps you could help me out here. It seems the documentation on this is pretty vague. Thanks!\n. ",
    "jameswyse": "@bradreardon I had the same issue, it seems to be a recent change. Try using the with_context decorator:\n``` python\nfrom graphene.utils import with_context\n@with_context\ndef resolve_current_user(self, args, context, info):\n    if context.user.is_authenticated:\n        return context.user\n``\n. @creimers Shouldn't it bequery DingDong($fromDate: DateTime!) { ... }? the!at the end of the type is because ofrequired=True` . \ud83d\udc4d  I was also having difficulty understanding/implementing this.\n. I've been trying out the experimental executor (with all libs on latest stable versions) but it seems to be slower with it enabled.\nI did some basic comparison benchmarks by recording the total request time of my two largest / most complex queries with it enabled and disabled and the average results were:\n\nQuery 1 went from 1738ms to 2142ms (404ms slower)\nQuery 2 went from 1453ms -> 1749ms (296ms slower). @syrusakbary that makes sense. Most of our slower queries are lists of ObjectTypes from Django models with lots of relations / deep nesting and most of the request time seems to be spent in python instantiating and resolving all these types.\n\nIt's kinda tricky to extract but I'll try to put a repo together soon \ud83d\udc4d . I've ran into a similar problem, I need to include the parent when using RANGE_ADD mutations but graphene.Field('Viewer') no longer works\n. Same problem here. I'm gonna try using __import__ or importlib.import_module inside the lambda. Not ideal either but it should do the trick.\n. @JimVanEeden It works :)\nHere's some example code:\n``` python\nimport graphene\nfrom importlib import import_module\nfrom graphql_relay.connection.arrayconnection import offset_to_cursor\nfrom something_app.models import Something\nfrom something_app.schema import SomethingNode\nclass CreateSomething(graphene.relay.ClientIDMutation):\n    class Input:\n        name = graphene.String()\nviewer = graphene.Field(lambda: import_module('your_app.schema').Viewer)\nsomething_edge = graphene.Field(SomethingNode.Connection.Edge)\nsuccess = graphene.Boolean()\n\n@classmethod\ndef mutate_and_get_payload(cls, input, context, info):\n    name = input.get('name')\n\n    something = Something(name=name)\n    something.save()\n\n    # hacky but works for now\n    cursor = offset_to_cursor(Something.objects.count() - 1)\n    edge = SomethingNode.Connection.Edge(node=something, cursor=cursor)\n\n    # passing viewer here may not be necessary - everything seemed to work just fine without it but YMMV\n    return cls(viewer=import_module('your_app.schema').Viewer, edge=edge, success=bool(something.id))\n\n```\nand the client-side mutation config:\n``` javascript\nimport Relay from 'react-relay';\nexport default class CreateSomethingMutation extends Relay.Mutation {\ngetMutation () {\n    return Relay.QLmutation { createSomething };\n  }\ngetVariables () {\n    return { name: this.props.name };\n  }\ngetFatQuery () {\n    return Relay.QLfragment on CreateSomethingPayload @relay(pattern: true) {\n        clientMutationId\n        success\n        edge {\n          node {\n            id\n          }\n        }\n        viewer {\n          id\n          allSomethings\n        }\n      }\n  }\ngetConfigs () {\n    return [{\n      type: 'RANGE_ADD',\n      parentName: 'viewer',\n      parentID: this.props.viewer.id,\n      connectionName: 'allSomethings',\n      edgeName: 'edge',\n      rangeBehaviors: {\n        '': 'append'\n      }\n    }];\n  }\n}\n``\n. @JimVanEedencallable(self._type)might be a good alternative toinspect.isfunction` :)\n. ah good point.\n. The new databinding features in django-channels look ideal for graphql subscriptions: https://channels.readthedocs.io/en/stable/binding.html \nI'd love to see an example of subscriptions in graphene using channels (or any other method) :). Static Queries is also something the Apollo team are working on (see https://github.com/apollographql/persistgraphql) - it'd be great if we could find a common solution!. That's exactly what I do to build select_related and prefetch_related in my top level resolvers. I'm out at the moment but will share some code when I get home \ud83d\ude42. I've extracted some code and simplified it a bit (our implementation is a bit more complex) but hopefully you find it useful. One day I'll find the time to release this as a reusable package (or perhaps directly in to graphene-django)\nhelpers.py\n```python\nfrom graphql.utils.ast_to_dict import ast_to_dict\nfrom django.utils.six import iteritems\ndef collect_fields(node, fragments, variables):\n    field = {}\n    selection_set = node.get('selection_set') if node else None\n    selections = selection_set.get('selections', None) if selection_set else None\nif selections is not None:\n    for leaf in selections:\n        leaf_kind = leaf.get('kind')\n        leaf_name = leaf.get('name', {}).get('value')\n        leaf_directives = leaf.get('directives')\n\n        # Check if leaf should be skipped\n        # - If name is '__typename'\n        # - if @skip directive is used and evaluates to True\n        # - if @include directive is used and evaluates to False (not yet implemented!)\n        should_skip = False\n        for directive in leaf_directives:\n            if directive.get('name', {}).get('value') == 'skip':\n                for arg in directive.get('arguments', []):\n                    arg_value = arg.get('value', {})\n                    if arg.get('name', {}).get('value') == 'if':\n                        if arg_value.get('kind') == 'Variable':\n                            var_name = arg_value.get('name', {}).get('value')\n                            should_skip = variables.get(var_name, should_skip)\n                        elif arg_value.get('kind') == 'BooleanValue':\n                            should_skip = arg_value.get('value')\n\n        if leaf_name != '__typename' and not should_skip:\n            if leaf_kind == 'Field':\n                field.update({leaf_name: collect_fields(leaf, fragments, variables)})\n            elif leaf_kind == 'FragmentSpread':\n                field.update(collect_fields(fragments[leaf_name], fragments, variables))\nreturn field\n\ndef get_fields(info):\n    \"\"\"Return a nested dict of the fields requested by a graphene resolver\"\"\"\n    fragments = {}\n    node = ast_to_dict(info.field_asts[0])\nfor name, value in iteritems(info.fragments):\n    fragments[name] = ast_to_dict(value)\n\nfields = collect_fields(node, fragments, info.variable_values)\n\nreturn fields\n\n```\nExample usage\n```python\nfrom django.db.models import Prefetch\ndef resolve_posts(self, args, context, info):\n    qs = Post.objects.all()\n    fields = get_fields(info)\n# posts { author }\nif fields.get('author', {}):\n    qs = qs.select_related('author')\n\n# posts { comments }    \nif fields.get('comments', {}):\n    all_comments = Comment.objects.all()\n\n    # posts { comments { author } }\n    if fields.get('comments', {}).get('author', {}):\n        all_comments = all_comments.select_related('author')\n\n    qs = qs.prefetch_related(Prefetch('comments', queryset=all_comments))\n\nreturn qs\n\n```. ",
    "imranolas": "@syrusakbary: Any chance you could release these changes?\n. @syrusakbary: This is exactly what I was looking for. Thanks\n. ",
    "alex-wilmer": "Hi, I wasn't able to figure this out from the docs... does it even currently address union types? Do I need to include from graphene.core.classtypes.uniontype import UnionType?\n. ",
    "sgtsquiggs": "Figured it out.\n``` python\nclass ArtworkNode(DjangoNode):\n    url = graphene.String()\nclass Meta:\n    model = Artwork\n    filter_fields = ['id', 'title']\n\ndef resolve_url(self, args, info):\n    return self.instance.url\n\n```\nIs it possible to retrieve via pk?\n. Is it possible to get a single item via a field other than id? for instance I have a slug field on Artwork and in my django endpoint I use Artwork.get_by_slug(slug).\nsource= would be perfect, I use it extensively in my serializers\n. I see! I'll have to read up on Relay.\n. Doesn't seem to be working. Tried it on a simpler query:\n{\n  artwork(slug:\"97397-bird-prince\") { pk title }\n  __debug {\n    sql {\n      rawSql\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"artwork\": {\n      \"pk\": 97397,\n      \"title\": \"Bird Prince\"\n    },\n    \"__debug\": {\n      \"sql\": []\n    }\n  }\n}\n. Django 1.6.11\npython\ndef resolve_artwork(self, args, info):\n        pk_or_slug = first_not_none(args.get('slug', None), args.get('pk', None))\n        return models.Artwork.get_by_pk_or_slug(pk_or_slug)\nand finally\npython\n    @classmethod\n    def get_by_pk_or_slug(cls, value):\n        try:\n            return cls.objects.get(Q(status='public'), Q(slug=value) | Q(pk__iexact=value))\n        except cls.DoesNotExist:\n            return None\n. {\n    allArtworks(first: 5) {\n        edges {\n            cursor,\n            node { pk title }\n        }\n    }\n__debug {\n    sql {\n      rawSql\n    }\n  }\n}\njson\n{\n  \"data\": {\n    \"allArtworks\": {\n      \"edges\": [\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjA=\",\n          \"node\": {\n            \"pk\": 7,\n            \"title\": \"TEST ARTWORK A\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjE=\",\n          \"node\": {\n            \"pk\": 9,\n            \"title\": \"yet another artwork\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjI=\",\n          \"node\": {\n            \"pk\": 39,\n            \"title\": \"Moonwalk\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjM=\",\n          \"node\": {\n            \"pk\": 40,\n            \"title\": \"Sky High (Things are Getting Better)\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjQ=\",\n          \"node\": {\n            \"pk\": 41,\n            \"title\": \"Missed Mark\"\n          }\n        }\n      ]\n    },\n    \"__debug\": {\n      \"sql\": []\n    }\n  }\n}\n. return models.Artwork.objects.first() also returned \"sql\": []\n. Ok, if I disable django-debug-toolbar, DjangoDebugPlugin works:\njson\n{\n  \"data\": {\n    \"allArtworks\": {\n      \"edges\": [\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjA=\",\n          \"node\": {\n            \"pk\": 7,\n            \"title\": \"TEST ARTWORK A\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjE=\",\n          \"node\": {\n            \"pk\": 9,\n            \"title\": \"yet another artwork\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjI=\",\n          \"node\": {\n            \"pk\": 39,\n            \"title\": \"Moonwalk\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjM=\",\n          \"node\": {\n            \"pk\": 40,\n            \"title\": \"Sky High (Things are Getting Better)\"\n          }\n        },\n        {\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjQ=\",\n          \"node\": {\n            \"pk\": 41,\n            \"title\": \"Missed Mark\"\n          }\n        }\n      ]\n    },\n    \"__debug\": {\n      \"sql\": [\n        {\n          \"rawSql\": \"SELECT `artwork`.`slug`, `artwork`.`id`, `artwork`.`title`, `artwork`.`description`, `artwork`.`literature`, `artwork`.`special_terms`, <<SNIP 40 MORE FIELDS>> `artwork`.`end_date`, `artwork`.`suppress_display`, `artwork`.`shipping_category_id` FROM `artwork`\"\n        }\n      ]\n    }\n  }\n}\nThis took 36.15 seconds\n. That seems to be it.\n... FROMartworkLIMIT 5 OFFSET 92034\" when using DjangoConnectionField\n. ",
    "paymog": "How do I resolve a django object along with an extra, calculated field like below during a query?\n```python\nclass ProjectType(DjangoObjectType):\n    class Meta:\n        model = Project\nextra_field = graphene.String()\n\nclass Query(ObjectType):\n    project = graphene.Field(ProjectType,\n                             name=graphene.String())\ndef resolve_project(self, info, name):\n\n    if id is not None:\n        return Project.objects.get(pk=id) # how do I populate `extra_field` here?\n\n\n    return None\n\n```. ",
    "Speedy1991": "Can you give an example how this works please?\ne.g.: This does not work:\nclass Query(graphene.ObjectType):\n    ls = graphene.String(source='_ls', path=graphene.String())\n\n    @staticmethod\n    def _ls(path=None):\n        cmd = \"ls -la \"\n        return subprocess.check_output((cmd + path) if path else cmd, shell=True).decode(\"utf-8\")\n\nRunning {ls} leads to:\n{\n  \"data\": {\n    \"ls\": null\n  }\n}\nWith a default resolver it just runs fine. Is there an easy way to add the includeDeprecated flag to graphene?. ",
    "ubill": "DjangoFilterConnectionField doesn't seem to be respecting the max_limit and pulling all (6000+) rows from my table.\nHere's how I defined it in my code:\ndevices = DjangoFilterConnectionField(DeviceNode)\nI saw that there is a constant in graphene_django/settings.py\n```\nCopied shamelessly from Django REST Framework\nDEFAULTS = {\n'RELAY_CONNECTION_MAX_LIMIT': 100,\n```\nbut it 100 doesn't seem to be used.\nAny ideas? @syrusakbary @sgtsquiggs Thanks. :)\n. ",
    "Lucretiel": "Hey guys\u2013 I've seen a lot of similar issues and pull requests, all of which are closed as being fixed; is any of this documented anywhere? I can't find any reference to it in the main page documentation.. I think, based on reading through the source code, that graphene.Dynamic is intended to be the solution. It looks like this:\ngraph.List(graph.Dynamic(lambda: CircularType))\n\nBut there's sadly no documentation for this class at all. For instance, would this be more appropriate?\ngraph.Dynamic(lambda: graph.List(CircularType)). Confirmed that the lambda thing works pretty much everywhere. Seems like that's the thing to do. Should definitely be documented explicitly somewhere.. >> one of the most critically useful features of Graphene\n\n\nIn any event, I am curious what you are doing that makes this so useful.\n\nThe answer here is twofold: one for my particular use case, and one for why in general it's useful. The reason I think it's useful in general is that it means that you can continue to reuse whatever your data model type is, instead of having to reassign useful data to your graphene ObjectType instances.\nIn my case, it means that I can just pass around Django Model instances, rather than having to populate my ObjectType. This is especially important because Django does semi-lazy lookups and queries based on attribute access, so it's incredibly useful to have graphene look up only the desired attributes. My code is here: https://github.com/Lucretiel/SkillServe/blob/v2018/skillboards/graphql/query.py?ts=4\nNotice, for example, in this snippet. I resolve_games returns a Django QuerySet, which is unresolved until graphql actually iterates over it to get the individual database rows. The objects of the QuerySet are, themselves, not graphql objects, but Model instances. GraphQL knows from the schema that Player.games is a list of schema.Game, and automatically applies that schema to the models.Game instance.\nIt sounds complicated but it really makes sense once you're used to it.\nIn my original bug posting, I mentioned that the documents hint at this functionality. That hinting happens here:\n\nNOTE: The resolvers on a ObjectType are always treated as staticmethods, so the first argument to the resolver method self (or root) need not be an actual instance of the ObjectType.. It's worth noting, too, that you don't even need lazy_import in most cases. It's not well documented, but you can just use field = lambda: Type instead of field = Type in most cases.. \n",
    "joetempleman": "I agree, what's the way to do this in graphene 2.0? Neither the string or the LazyType seem to work for me.... Did this solve the above problem? It seems like a hacky way of writing such a basic schema. I would imagine most Create mutations would want to return the object which was created, is there a reason that's not supported in Graphene?. Circling back to answer my own question, it is an intentional limitation of the graphQL spec that means Input and Output types are different. Quoting the spec: \n\nFields can define arguments that the client passes up with the query, to configure their behavior. These inputs can be Strings or Enums, but they sometimes need to be more complex than this.\nThe Object type defined above is inappropriate for re\u2010use here, because Objects can contain fields that express circular references or references to interfaces and unions, neither of which is appropriate for use as an input argument. For this reason, input objects have a separate type in the system.\nAn Input Object defines a set of input fields; the input fields are either scalars, enums, or other input objects. This allows arguments to accept arbitrarily complex structs.\n\n\nhttp://facebook.github.io/graphql/October2016/#sec-Input-Objects\nI'm going to structure our classes to have separate input/output classes but have them with a common superclass which will contain the common fields to avoid the drifting apart.\n. ",
    "sanfilippopablo": "Looking at some unrelated docs here it seems like you can do this:\npy\ngraphene.List(lambda: MyCircularType)\ngraphene.Field(lambda: MyCircularType)\nI just tested it and it works.. ",
    "janbaykara": "This whole project is woefully under-documented. But great finds!. ",
    "lisongx": "@syrusakbary \nanyway to do this just using graphql-core? thanks. Any one can help? cc @syrusakbary . @syrusakbary \nHi Syrus, actaully I opened this issue because of this is any docs about using Union on our http://graphene-python.org/ website, maybe we could still let this open?. oh I found the problem.\nI have two graphql endpoint , one is came from the graphiql and one is that I hand written the flask view. And I forget to put context_value to the graphiql.. @syrusakbary \nThanks\nBTW:\nJust wonder why the flask-graphiql have the default context set to flask request?. thanks!. ",
    "matt-dalton": "@sanfilippopablo How did you actually import the types? I'm still struggling to get this working without an error. ",
    "mekhami": "the lambda option doesn't solve the problem of circular imports, just circular dependencies. Is there a supported solution for the problem of circular imports? specifying it as a dotted package string 'mymodule.gqlobjects.Foobar' seems to work, I think.. This conversation shouldn't be closed. @syrusakbary the graphene documentation says that:\n\nEach attribute of the AbstractType represents a field (a graphene.Field or graphene.InputField depending on where it is mounted)\n\nThis is the opposite of the behavior defined. You should be able to make an AbstractType whose fields are either Field or InputField depending on the mount point?. ",
    "xikxp1": "What is the status of it now? I don't see LazyType wrapper in graphene implementation now. Should I use lazy_import?. Was able to find the solution for my problem in related graphql-django project: https://github.com/graphql-python/graphene-django/issues/205.\nIt turned out that executor had to be class instance rather than class itself. ",
    "jdugan1024": "Thanks @syrusakbary \n. @syrusakbary OK.  I'm fine removing the version limitation there -- it's just habit for me to put it in there. I can see how in this case where you have a library used by lots of different projects that you don't want to lock down the version number.  I'll update the setup.py file.\n. ",
    "SmileyChris": "Iiiiiiiiiiiiiiiiiiiii. Iiiiiii. ",
    "Jpadilla1": "@gwind Thank you!\n. ",
    "alecklandgraf": "[python 2.7.x] The graphql-relay==0.4.4 package doesn't return a named tuple or class with an id attribute for from_global_id so I did the following to mimic your rid.id usage which is more semantic than from_global_id(YOUR_GLOBAL_ID)[1].\n``` py\nfrom collections import namedtuple\nRid = namedtuple('Rid', 'name id')\n...\nrid = Rid(*from_global_id(YOUR_GLOBAL_ID))\nprint(rid.id)\n``\n. Closing this as it was an errant.pycleft around after I moved theschemafile and didn't update my urls to reference the new location, which found thepyc` file locally.\nSorry,\nAleck\n. ",
    "mamaar": "That's great, @syrusakbary !\nGraphene is definitely a fantastic library.\n. ",
    "rsalmei": "Hello @syrusakbary, this really works for single level fields.\nPlease, how do I nest one inside another?\nLet's say I have:\n```\nclass PersonFields(graphene.AbstractType):\n    name = graphene.String()\n    age = graphene.Int()\nclass PersonContactFields(graphene.AbstractType):\n    phone = graphene.Int()\n```\nHow do I fit they together?\nclass PersonFields(graphene.AbstractType):\n    name = graphene.String()\n    age = graphene.Int()\n    contact = graphene.??????(PersonContactFields)\n. Thanks @valdergallo, but that way you loose the ability to share types, which is the intent of this thread.\nIt would be needed to maintain it as an AbstractType, to be able to inherit it both from InputType and ObjectType.\nUnfortunately I think this is not yet possible.\n@syrusakbary Can you confirm please? . Yes, I know that and agree, but that's why you did create AbstractType, isn't it? \nThe only problem now is that one can't inherit from it without materializing it... That way we could embed types and still share them.. ",
    "valdergallo": "Did you checked the document ? \n(http://docs.graphene-python.org/en/latest/types/mutations/) \n```\nimport graphene\nclass LatLngInput(graphene.InputObjectType):\n    lat = graphene.Float()\n    lng = graphene.Float()\nA location has a latlng associated to it\nclass LocationInput(graphene.InputObjectType):\n    name = graphene.String()\n    latlng = graphene.InputField(LatLngInput)\n```. ",
    "j-robin-hunter": "Can you re-open this!! I agree that an AbstractType or similar needs to be able to be used to define both an Object and an InputObject. Noting that the AbstractType is now deprectaed at the least this should be possible from an Interface. This is a good idea and not one I had thought of. I'm sure this will do what I'm after. Many thanks. ",
    "Ian-Foote": "There are unfortunately still problems with mapping Django choices to Enum: #184, #185, #186.\nItem 1 in the list above seems like the most crucial one to fix. #139 did not address this as far as I can see - the display value is still being used inappropriately.\nItem 3 is closely related to item 1 and also does not appear to have been addressed.\nCan this issue be re-opened? I think we need to decide how Django choices should be handled and then work out how to migrate to that. It seems to me that Enum is definitely not the correct concept to be using here.\n. @syrusakbary have you seen this?\n. ",
    "creimers": "I'm having difficulties to use DateTime with the graphiql query variables.\nThis is the error I'm getting:\n\nAnd this is how I declare the variable:\n\nCan you think of a reason why this doesn't work? There's nothing wrong with the datetime string as far as I can see, as it works perfectly fine when I use it in the query instead of the variable.\nFor the sake of completeness, this is how I declare the field:\n\n. @jameswyse That's it. Thanks for spotting it.. ",
    "rdhara": "I don't see the graphene.types.datetime.DateTime class; I am running graphene==2.0.1. Has this feature been removed?\n. ",
    "Audace": "I also have run into an issue on a model with a DateTimeField. During testing, graphene seems to be unable to serialize the value. \nStacktrace:\nTraceback (most recent call last):\n  File \"/Users/williamfry/Development/SolutionLoft/code-clippy-portal/venv/lib/python3.6/site-packages/promise/promise.py\", line 65, in try_catch\n    return (handler(*args, **kwargs), None)\n  File \"/Users/williamfry/Development/SolutionLoft/code-clippy-portal/venv/lib/python3.6/site-packages/graphql/execution/executor.py\", line 375, in <lambda>\n    resolved\n  File \"/Users/williamfry/Development/SolutionLoft/code-clippy-portal/venv/lib/python3.6/site-packages/graphql/execution/executor.py\", line 399, in complete_value\n    return complete_leaf_value(return_type, result)\n  File \"/Users/williamfry/Development/SolutionLoft/code-clippy-portal/venv/lib/python3.6/site-packages/graphql/execution/executor.py\", line 440, in complete_leaf_value\n    return return_type.serialize(result)\n  File \"/Users/williamfry/Development/SolutionLoft/code-clippy-portal/venv/lib/python3.6/site-packages/graphene/types/datetime.py\", line 54, in serialize\n    'Received not compatible datetime \"{}\"'.format(repr(dt))\nAssertionError: Received not compatible datetime \"'2018-01-20 09:35:53+00:00'\". ",
    "helpse": "In my case. problem happenned in this situation:\nreunion.fecha = fecha\nreunion.hora = hora\nreunion.save()\nreturn UpdateReunionMutation(reunion=reunion)\nHere, fecha is a string. It will save the model, but graphene will trigger the error.\nChanging last line to:\nreturn UpdateReunionMutation(reunion=Reunion.objects.get(pk=reunion.pk))\nFixed the problem.\nIt reloads the model, and reunion.fecha becomes a Date field.. @mjtamlyn I agree with you.\nHowever, sometimes you want to send a 401 Unauthorized or a 403 Forbidden. Under these circumstances, graphene should send a 401/403 HTTP status.. > Given the recent interest (here and offline), I'm thinking to create an open-source GraphQL logging tool with an easy integration with Graphene or any other GraphQL framework.\n\n(similar business model as Sentry).\nWill some of you be open to pay half of the price as apollo optics while having a similar interface?\n\nI'd be happy to contribute! Is there a Slack channel that I could join?. ",
    "mathieusteele": "I found this issue and followed the advice of helpse and fetched the saved object before returning it at the end of the mutation function. This fixed the issue I was having when sending date data (\"2018-03-30\") in a mutation but I'm not really sure why.. ",
    "rok-povsic": "I've solved the AssertionError: Received not compatible datetime \"'2018-01-20 09:35:53+00:00'\" issue by creating and using a custom type that overrides serialize and parses the string datetime:\npython\nfrom dateutil.parser import parse\nclass CustomGrapheneDateTime(graphene.DateTime):\n    @staticmethod\n    def serialize(date):\n        if isinstance(date, str):\n            date = parse(date)\n        return graphene.DateTime.serialize(date). ",
    "coveralls": "\nChanges Unknown when pulling e1a693e57c86e73ff42611c87d66cffca103dfa9 on features/enum-improvements into * on master*.\n. \nCoverage decreased (-0.2%) to 96.256% when pulling 91cc0ced86aa2dbf080f405523405920aff9a77d on features/django-fields into ae23a1154c07b6034157e5866f9da256ca4f9a57 on master.\n. \nCoverage increased (+0.06%) to 96.317% when pulling 492ffdace4eacc408a9edba87cc54f3352ab43b6 on karec:master into 8497e0c4e039ca1aed1881685f67e586d0a6bc4c on graphql-python:master.\n. \nCoverage increased (+0.05%) to 96.37% when pulling 8e3b9b430e4d07d166217ce7e6d87d63a5d19b55 on jdugan1024:improve-iso8601-handling into d48d24176f0c189b493504861640fa2810e194ba on graphql-python:master.\n. \nCoverage increased (+0.05%) to 96.368% when pulling a158f4e00261003c556da6729c2536d21407014b on jdugan1024:improve-iso8601-handling into d48d24176f0c189b493504861640fa2810e194ba on graphql-python:master.\n. \nCoverage increased (+0.05%) to 96.368% when pulling f325964a9e35284b2046ff6b92a6bc994b2c4f4a on jdugan1024:improve-iso8601-handling into d48d24176f0c189b493504861640fa2810e194ba on graphql-python:master.\n. \nCoverage increased (+0.2%) to 96.471% when pulling 9c2d571aae0e14cd5d89ae48659dbbc415a02fe8 on jdugan1024:improve-iso8601-handling into d48d24176f0c189b493504861640fa2810e194ba on graphql-python:master.\n. \nCoverage increased (+0.2%) to 96.471% when pulling aea560e3635fb5a92f1aa3bde59353f6a5e94e1d on jdugan1024:improve-iso8601-handling into d48d24176f0c189b493504861640fa2810e194ba on graphql-python:master.\n. \nChanges Unknown when pulling 7be5b83fdfdbb06060ea66ed4253437d26469ea9 on core-update into * on master*.\n. \nCoverage remained the same at 96.447% when pulling 71153061568dddd166276cff9390f237fc3d7525 on stefanfoulis:patch-1 into 5b6308480283a26786a30ec92c4ee931d1a40f52 on graphql-python:master.\n. \nCoverage remained the same at 96.447% when pulling d3a573cc8a38e786ecf516ef4b8510d5a58378c7 on danielfarrell:restore-context into 398088a0c496937f0f3fe3d8dc04c8d163767723 on graphql-python:master.\n. \nCoverage increased (+0.005%) to 96.452% when pulling 61e7beee7b9c83c55b7b47c3814f120e421400b6 on mjtamlyn:relay-mutation-with-context into 398088a0c496937f0f3fe3d8dc04c8d163767723 on graphql-python:master.\n. \nCoverage remained the same at 96.466% when pulling 4d15bc4f796db403e1ed4877665b80422b516eca on AdrielVelazquez:master into b431bfe477282a261a57277adedcc10c3abd4bdc on graphql-python:master.\n. \nCoverage decreased (-0.3%) to 96.179% when pulling 10e5424e313d3486fcbc5bf4a090ee3aceea5a0d on features/middlewares into b431bfe477282a261a57277adedcc10c3abd4bdc on master.\n. \nCoverage increased (+0.006%) to 96.185% when pulling 11a5ee189ef6f99ff361755dedad6b567f426f35 on bugfixes/context-in-connectionfield into 3093d2b300ff047750b011e3384ec34f46a2e422 on master.\n. \nCoverage decreased (-0.05%) to 96.138% when pulling feb0825a639876ed02ea0914d4ce1163d1fd20ca on AlecAivazis:master into 91a2423e5e0bec40c13117402b80cb1aa96e232c on graphql-python:master.\n. \nCoverage increased (+0.004%) to 96.189% when pulling 161f19845163ca0323483d7045e26bf52df1c6c9 on AlecAivazis:master into 91a2423e5e0bec40c13117402b80cb1aa96e232c on graphql-python:master.\n. \nCoverage increased (+0.004%) to 96.189% when pulling 427a08106b8c27457a383557aba707a3abe0a46f on AlecAivazis:master into 91a2423e5e0bec40c13117402b80cb1aa96e232c on graphql-python:master.\n. \nCoverage decreased (-0.05%) to 96.078% when pulling bd7b3362792e80f2d9a4cb0fdf2fc4acb95c937a on register-interface-failure-fix into 8bc14953d7f7a8df27dfdc98c054f095dc67e336 on master.\n. \nCoverage remained the same at 96.13% when pulling da09bc321001213f5dc7e199e63378283f8ba501 on register-interface-failure-fix into 8bc14953d7f7a8df27dfdc98c054f095dc67e336 on master.\n. \nChanges Unknown when pulling c43d3cc5122408a1b661a33be0fe7cb75cec9ef0 on JCB-K:fix_lazy_translated_choice into * on graphql-python:master*.\n. \nChanges Unknown when pulling be449ab1c02f9d7256941b40c6733a344a742ada on JCB-K:fix_lazy_translated_choice into * on graphql-python:master*.\n. \nChanges Unknown when pulling 6e00afa98acc128d7f01950acc8589cacc0c865e on fix_lazy_translated_choice into * on master*.\n. \nChanges Unknown when pulling 4936e40258a6494cde6044bb01c49cac26675eea on fix_lazy_translated_choice into * on master*.\n. \nChanges Unknown when pulling edfbbf52ef5745c409def954af6b520ac6a73506 on fix_lazy_translated_choice into * on master*.\n. \nCoverage increased (+0.006%) to 96.14% when pulling 9e715cd902be6c5bc8fd88d9783dfb92ad80e0f5 on django-choices-grouping into 6eb00083d9a7f169806e1a83c1b1e066e99f2714 on master.\n. \nCoverage decreased (-0.4%) to 95.716% when pulling 90c88abb5d8f99f43efb245e56fda7ad15040405 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.716% when pulling 16ae9de16bd0bdf8f11c50d783d6fd9a39d81c33 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.765% when pulling 6553d4554b7574424e383305cf2f8ae5f1364f52 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling 631fa23249e4244b885b303c225c8cfcf509a1f8 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling cfb0b2257b74d2a5919100a84f0c28ae529dadb7 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling cfb0b2257b74d2a5919100a84f0c28ae529dadb7 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling bc4896af91bc048899a8c1fc9b6011591cf84bad on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling bc4896af91bc048899a8c1fc9b6011591cf84bad on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling 87b48efbe1a3233078e84634ccfeef8e6144449f on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling 8749047565425ef1b3b743c3168d57ef3579b144 on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.721% when pulling 576c3b1092921ad07bc5c9bfeb1c82e05366fc8b on Globegitter:patch-4 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage increased (+0.002%) to 96.146% when pulling 9ff444aa1e539d3b4af81c799017e10f33e33962 on Globegitter:patch-5 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage increased (+0.006%) to 96.15% when pulling 40705d3924e11d7778d269736a786f2782703306 on Globegitter:patch-6 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.1%) to 96.047% when pulling 6f8b03d2d8c64dea184a80adcfb15f2c10243302 on Globegitter:patch-6 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage decreased (-0.1%) to 96.047% when pulling a821f19fcc6ac4a833cb932be0eea7a33e65f158 on Globegitter:patch-6 into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage remained the same at 96.144% when pulling 67fe978f2da2a00ffe1dea1be539bb44c0ade7c4 on pyoner:master into 1711e6a52907b3061f1faeca8ac629c985e28acf on graphql-python:master.\n. \nCoverage increased (+0.02%) to 96.168% when pulling 52a2107211ff091c238aa4dda35f8b281a059b2a on karec:master into 531083702ee20a716ed7e305cb574406dabdeb95 on graphql-python:master.\n. \nCoverage increased (+0.02%) to 96.168% when pulling 49d482b36fd8e6e5a1be08dd799ba31cfd0e2cf7 on karec:master into 531083702ee20a716ed7e305cb574406dabdeb95 on graphql-python:master.\n. \nCoverage remained the same at 96.168% when pulling 693f84ba388867bc42712e9811394959c76813ca on AlecAivazis:master into b5b66326a788cefa5915f79d5c920dad7aa61734 on graphql-python:master.\n. \nCoverage remained the same at 96.168% when pulling 7200ec6dfa208e39b511b73153313a891792cdec on AlecAivazis:master into b5b66326a788cefa5915f79d5c920dad7aa61734 on graphql-python:master.\n. \nCoverage decreased (-0.9%) to 95.286% when pulling 4c168203eb1118b6dc062b16559f0dd5a4c95476 on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nCoverage decreased (-0.9%) to 95.289% when pulling 1aa9bf70f5e10bdcbb7412f34e239df636f1a052 on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nCoverage decreased (-0.9%) to 95.294% when pulling 191267e0eddad4f0f1d68d426d4b0ec904a8d099 on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 96.203% when pulling 47a85bd08d1d45e3bac40d5d6cb389a07c02ddb6 on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 96.203% when pulling 4e05d1cac1a12b7cf3bae863b7d0e7dcd1944f7f on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 96.203% when pulling 0c63b0c5e2c78a17a850292c600cbad4d0653ef5 on conradev:django-nonnull into 8711dd20b60c0c0226a111c7c25a2cebd8de5c51 on graphql-python:master.\n. \nChanges Unknown when pulling 311e4793f9a30d0ca1c1b69b71d15f7f32ec3153 on Globegitter:patch-7 into * on graphql-python:master*.\n. \nChanges Unknown when pulling 651200262310ac983ca0951e1dc41bdabf15dc37 on Globegitter:patch-7 into * on graphql-python:master*.\n. \nChanges Unknown when pulling 651200262310ac983ca0951e1dc41bdabf15dc37 on Globegitter:patch-7 into * on graphql-python:master*.\n. \nChanges Unknown when pulling 7f85f65ba793d8c53dd0f6d37f679303f266014a on Globegitter:patch-7 into * on graphql-python:master*.\n. \nChanges Unknown when pulling a7d7f95b86f004f6d12b38f58e91b8885538ebb4 on Globegitter:patch-7 into * on graphql-python:master*.\n. \nCoverage remained the same at 96.398% when pulling 886ceb77b22e85d55a577645143aa5d1af573056 on Globegitter:patch-7 into 17ba01570a1d975612ed091c5d47f5ccd28eca83 on graphql-python:master.\n. \nChanges Unknown when pulling 603d4770eb3f1233748588525c56cc2d0a53a337 on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 603d4770eb3f1233748588525c56cc2d0a53a337 on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 2a288eab9d98b90120b1cb446623611b13a943bc on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 0d9e645beac81dc111e5d0ba25e643586b3af66a on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 0d9e645beac81dc111e5d0ba25e643586b3af66a on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 0d9e645beac81dc111e5d0ba25e643586b3af66a on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nChanges Unknown when pulling 878391be4e5175be69d42f332fcb30264dbd996d on Globegitter:connection-fields-object-types into * on graphql-python:master*.\n. \nCoverage increased (+0.06%) to 96.207% when pulling 05a9078629dddd6fbcdcecd28896014dc9aedc03 on jkimbo:order_by_camelcase into bd1fbb6a339c58b462e613df0ec40d993e6cdf14 on graphql-python:master.\n. \nCoverage remained the same at 96.185% when pulling 9baaa05f6928c1b7a4c5a2ab5e678e3062d44bc9 on jkimbo:fix-tests into 4ccddf4b7b93e7f79fc04e4ca67f53178159bb02 on graphql-python:master.\n. \nCoverage remained the same at 96.185% when pulling 4d387cc1aa81d4f7550c3d32783df05ed7f254cc on jkimbo:optional-client-mutation-id into 4ccddf4b7b93e7f79fc04e4ca67f53178159bb02 on graphql-python:master.\n. \nCoverage increased (+0.004%) to 96.189% when pulling e486a7afdbe5a75ba2ecd2125b2be941eb36af3f on jkimbo:indent-option-schema into 2d8f8794454339d6fd0c2fec797e5350c169b2db on graphql-python:master.\n. \nCoverage increased (+0.2%) to 96.398% when pulling 1d86d18cbfa1b17d4be5beb17c8faa06410a2c43 on jkimbo:json-custom-scalar-fix into b8a9e454fa72220716ed3b2a2b6e1272aa3b540b on graphql-python:master.\n. \nCoverage increased (+0.2%) to 96.398% when pulling 5845aaf723647bd0ddfcd058929b42b61c335a89 on jkimbo:json-custom-scalar-fix into b8a9e454fa72220716ed3b2a2b6e1272aa3b540b on graphql-python:master.\n. \nCoverage decreased (-0.04%) to 96.362% when pulling b9f08606a04a205fa872a20c2682fc610332409d on Globegitter:patch-8 into 17ba01570a1d975612ed091c5d47f5ccd28eca83 on graphql-python:master.\n. \nCoverage decreased (-1.2%) to 95.149% when pulling 1e1dc4c83a1b457974962f3298a8f89c510a7f31 on Globegitter:patch-8 into 17ba01570a1d975612ed091c5d47f5ccd28eca83 on graphql-python:master.\n. \nCoverage decreased (-0.09%) to 96.306% when pulling bdf57391f790929dc53cfa9c5d7b9d806f046f41 on sjhewitt:sqla-scalar-list-type into 17ba01570a1d975612ed091c5d47f5ccd28eca83 on graphql-python:master.\n. \nCoverage decreased (-0.06%) to 96.334% when pulling 9e185b01c284dcd10d583658a4c966a85e45ff4c on sjhewitt:sqla-composite-columns into 17ba01570a1d975612ed091c5d47f5ccd28eca83 on graphql-python:master.\n. \nCoverage remained the same at 83.357% when pulling 95e36222ce5b577a31813f3ea9a12838b87dfd42 on ekampf:patch-1 into dac4f2dc19a01d3b756acb90a2192dd6b90fe887 on graphql-python:next.\n. \nCoverage remained the same at 83.357% when pulling 95e36222ce5b577a31813f3ea9a12838b87dfd42 on ekampf:patch-1 into dac4f2dc19a01d3b756acb90a2192dd6b90fe887 on graphql-python:next.\n. \nCoverage remained the same at 83.357% when pulling 2635a0c70df4ed87b2cf671472ddcefd1e35313a on sjhewitt:next-sqla-pageinfo into dac4f2dc19a01d3b756acb90a2192dd6b90fe887 on graphql-python:next.\n. \nCoverage remained the same at 83.227% when pulling 9c15092e61ce1fcb761e931bee176d2479d25566 on ekampf:patch-2 into 9109b9de90a5d011aacf138c60569e1fe31ce05d on graphql-python:next.\n. \nCoverage remained the same at 83.239% when pulling 77d68689ba1bd6d1bdb6793cb5695e09a6852eaf on sjhewitt:next-sqla-scalar-list into ceffc4de691509968f200065642731fcc4acd217 on graphql-python:next.\n. \nCoverage remained the same at 83.239% when pulling b9c4e62e975f3dd199f573f600b83b2835e02f71 on sjhewitt:next-sql-composite into ceffc4de691509968f200065642731fcc4acd217 on graphql-python:next.\n. \nCoverage decreased (-0.05%) to 83.191% when pulling 7952f94f530fa7820c12e79c9d48e3a142106f9c on sjhewitt:next-typemap-duplicate into ceffc4de691509968f200065642731fcc4acd217 on graphql-python:next.\n. \nCoverage increased (+0.009%) to 91.886% when pulling c15ce935427099d59de4a773805e3cbda42e2dea on Globegitter:union-type-export into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage increased (+0.009%) to 91.886% when pulling 3888307f89ec9e3bcb576fd528a6f828e0bd762a on Globegitter:union-type-export into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage remained the same at 91.878% when pulling 513b3e46c392cad15700072098802ccd57adaf3d on Globegitter:global-id-node-optional into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage increased (+0.04%) to 91.92% when pulling 47c1f3e6559f403d6c8bbf9a6331bcf5819ef025 on Globegitter:global-id-node-optional into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage increased (+0.05%) to 91.929% when pulling 7f4541524a241b389914f7b14bf968ddcc37a6d2 on Globegitter:global-id-node-optional into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage increased (+0.04%) to 92.034% when pulling 6f9d8b4df831b0a639e326b26dc1e9b5d588529a on Globegitter:global-id-node-optional into 8e320da051fa07d16bdf54991e83691249357186 on graphql-python:master.\n. \nCoverage increased (+0.05%) to 91.164% when pulling aa6aeabc33c31a847c134f8e05475e85b73eefcb on Globegitter:global-id-node-optional into d8eeb65b5c8a1bb3765d0a1c734c28b889fa4a12 on graphql-python:master.\n. \nCoverage increased (+0.02%) to 94.726% when pulling 3d6486a899ec849a1d5cb857ecb97521862c9c9d on Globegitter:global-id-node-optional into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage increased (+0.06%) to 91.937% when pulling fce0b85b8a57a58afa059eff516f49794187474f on Globegitter:re-add-default-value into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage decreased (-0.1%) to 91.736% when pulling dd727593967735278652b108bf2e31b7a4c2ea9b on Globegitter:re-add-default-value into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage increased (+0.07%) to 91.946% when pulling e362471b3912df5a5c88a3d0f89e86723fc98183 on Globegitter:re-add-default-value into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage remained the same at 91.878% when pulling f232e433e6d4ad4f7c54a6d119c27a04743acee8 on dialoguemd:fix-assert-message into 94d46f7960c2a1943d1f9e1a4bc089c15a32c4af on graphql-python:master.\n. \nCoverage remained the same at 91.886% when pulling 73945fb569af8e0859567c248ccc3fa203e86986 on Globegitter:edge-for-type into e504c7227e0a71af0496dbfb6de5b6074254f423 on graphql-python:master.\n. \nCoverage remained the same at 91.886% when pulling aa94fe157eaeb05ccde9cce1eec61ce8860d119a on Globegitter:edge-for-type into e504c7227e0a71af0496dbfb6de5b6074254f423 on graphql-python:master.\n. \nCoverage increased (+0.1%) to 91.992% when pulling 2975e1fc42709cfd8c2331a57dd91091f6ad2ef4 on Globegitter:easier-private-state into bb636b81c229cfcc05e510fb4d550c377246adfb on graphql-python:master.\n. \nCoverage decreased (-0.3%) to 91.649% when pulling 7137a5974922d619127b201fff805154d724b0c2 on Globegitter:edge-for-type-2 into 84c8711f7901d4994a574b6078ed14f8322d49f2 on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 91.57% when pulling ebcc1f046d526e0e1dbd10bc53a2c5861cb929a3 on Globegitter:edge-for-type-2 into 84c8711f7901d4994a574b6078ed14f8322d49f2 on graphql-python:master.\n. \nCoverage remained the same at 91.509% when pulling c9777fd16e06ec4899e0cfb92bee85c1b3101bfc on mwilliamson:patch-1 into 4610f85af81afe3c13b21af696f5f31449f8a267 on graphql-python:master.\n. \nCoverage increased (+0.05%) to 91.201% when pulling a7e90a37b3036582f2f73336be35727ec74a49af on Globegitter:object-type-string-method into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage increased (+0.05%) to 91.201% when pulling a7e90a37b3036582f2f73336be35727ec74a49af on Globegitter:object-type-string-method into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage increased (+0.05%) to 91.201% when pulling a7e90a37b3036582f2f73336be35727ec74a49af on Globegitter:object-type-string-method into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage decreased (-0.009%) to 91.146% when pulling 87634240c9da458c2eaa438289939017bbd64924 on sjhewitt:connection-node into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage remained the same at 91.155% when pulling a77b27987e97504ff9c74ade696b36c174e4c612 on sjhewitt:connection-node into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage remained the same at 91.155% when pulling a77b27987e97504ff9c74ade696b36c174e4c612 on sjhewitt:connection-node into f955280d1acd8504c0e2263056c0f69611fc2321 on graphql-python:master.\n. \nCoverage increased (+0.02%) to 91.137% when pulling d9b8f5941d3d54b580acf0cdb8ad4bb31d175d75 on Globegitter:default-resolver-default-value into 316569b01903746f85276ce05d386ff2a12ff55f on graphql-python:master.\n. \nChanges Unknown when pulling 45cfd8eaa029cfc086c3925e938281849d987697 on Globegitter:fix-default-resolver into * on graphql-python:master*.\n. \nCoverage remained the same at 91.146% when pulling c400e1fff725dc0383398ac2a4a1faa3cd0fa52b on adamhadani:feature/ah-fix-readme-example into 8128292b028fe1254f0f13c9ba99e675da687348 on graphql-python:master.\n. \nCoverage remained the same at 91.82% when pulling 9231e0d28dafcfa699dcebf052a5512af56364c5 on mikhuang:patch-1 into c961f0b3c60c3a7a6223d5218c912d69585aef5c on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling 71b4de936997714bca3c79937cf867af78ae7af3 on ksonj:master into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling 71b4de936997714bca3c79937cf867af78ae7af3 on ksonj:master into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling 71b4de936997714bca3c79937cf867af78ae7af3 on ksonj:master into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling 71b4de936997714bca3c79937cf867af78ae7af3 on ksonj:master into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \n\nCoverage remained the same at 96.589% when pulling dda294d911cdc2216231303e6838ff7006d6dd1a on ksonj:master into edd090efdefef0f17b3caba9dc43edbdea4da5c9 on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling ef18eb5ce3ed8c65a1cf57c139cd5380f76ef707 on Globegitter:patch-9 into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage increased (+0.01%) to 94.721% when pulling 822b030938533d4b2b182bd6bf64172f8816c0f4 on Globegitter:add-dynamic-tests into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 94.737% when pulling 04085911410f247a918b017d2d4d62910f4dbe0e on Globegitter:add-dynamic-tests into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 94.737% when pulling 04085911410f247a918b017d2d4d62910f4dbe0e on Globegitter:add-dynamic-tests into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage increased (+0.03%) to 94.737% when pulling 04085911410f247a918b017d2d4d62910f4dbe0e on Globegitter:add-dynamic-tests into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage decreased (-0.03%) to 94.679% when pulling 8fa8fba718477f7b88743f74059540c8188dfcd3 on Globegitter:allow-attribute-setting-on-unmounted-type into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage remained the same at 94.71% when pulling 77e4ead0d76de2e7d0e99b4553140ad02b21b9b8 on wenley:wenley/nit-fix-documentation into 88ccaec8fac06adb42963c506a27fd0b5b1d2dd7 on graphql-python:master.\n. \nCoverage decreased (-0.06%) to 94.689% when pulling e11d595f5111e5763df225f3b3934a6e9b063b74 on Globegitter:patch-10 into 0a80119f5eabbee2e34d0aa755afb9847ae2cf2c on graphql-python:master.\n. \nCoverage increased (+0.02%) to 94.763% when pulling 16e9f221b52510bd1ac54ff5691e4f2a506dda4b on Globegitter:patch-11 into 0a80119f5eabbee2e34d0aa755afb9847ae2cf2c on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 344d85c19e3be0dc09de228a25eaa34b666346f5 on ekampf:feature/connection_edges_should_be_nonnull into c7a48c3c2c09bfe2cf434998a55d5051d8a001bf on graphql-python:master.\n. \nCoverage decreased (-0.4%) to 95.487% when pulling 42b93b5546858ecd74c7cac5ebb09add368eac48 on features/connection into adfbffb267b8e4c7bf6067c743a22a1e3c990d90 on master.\n. \nCoverage decreased (-0.4%) to 95.496% when pulling 3fa65aa343ce535f0736eb6c7332f13620ba071b on features/connection into adfbffb267b8e4c7bf6067c743a22a1e3c990d90 on master.\n. \nCoverage decreased (-0.4%) to 95.496% when pulling e6733d56b20bc6c8a5c065b1bcc03b6cd2a1feb2 on features/connection into adfbffb267b8e4c7bf6067c743a22a1e3c990d90 on master.\n. \nCoverage remained the same at 95.884% when pulling f5c5d33639b6b9f089aa527de65b46a28d8adba0 on nvie:patch-1 into adfbffb267b8e4c7bf6067c743a22a1e3c990d90 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling b2d7dfe5461913f94b5859f071d5b998a5b22afc on nvie:doc-fixes into adfbffb267b8e4c7bf6067c743a22a1e3c990d90 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling c1f567c4e4ba86cf4525dd2acbf1518cacb0d616 on ttz21:docs_update into 3f0c01ed3c4775019c81b686c77734ff54a29900 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling d1a9bdb5c3d4c0bd04e165aff506d458b4ac93fe on bcb:master into 5bb028e3d73a3f30a0b473d3641c2819f29fc527 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 937e257d609c51ad81675168a38792b6083d0e2f on ekampf:patch-3 into 4a4123e660b914e9ff0ec39ea5234c6e39697701 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 937e257d609c51ad81675168a38792b6083d0e2f on ekampf:patch-3 into 4a4123e660b914e9ff0ec39ea5234c6e39697701 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling a427a0fb18b6d2c59893d7c9014b5d67c6866efd on timothyjlaurent:#359-fix-index-error-on-enum-functions into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 5f7af3e43f91e8c4da82bce8ef880871463b53cd on Globegitter:node-simplifications into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 5f7af3e43f91e8c4da82bce8ef880871463b53cd on Globegitter:node-simplifications into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 0a79df3d13a6aebf7f12b55a185b4aa7a2267430 on Globegitter:node-simplifications into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 0a79df3d13a6aebf7f12b55a185b4aa7a2267430 on Globegitter:node-simplifications into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 0a79df3d13a6aebf7f12b55a185b4aa7a2267430 on Globegitter:node-simplifications into 50eadde8b23f43c62b51aafd12f32d0b7a24b1a1 on graphql-python:master.\n. \nCoverage increased (+0.01%) to 95.896% when pulling 09969355fa6341d1f6d5b1dc4ac2bfca6a6087d9 on Globegitter:node-parent-type into 6c7cd4e4fa6e29f55ebf02f173281d46d9f8fc1c on graphql-python:master.\n. \nCoverage decreased (-0.8%) to 95.064% when pulling d639cdb7625daa78fee9e11f08d0c0665495e34d on jamesboehmer:master into b1bffc4f8da66a143e43aeb7893293a2911526d3 on graphql-python:master.\n. \nCoverage decreased (-0.7%) to 95.172% when pulling cae40be4533d3ce47c36190912ec5169ce91523f on jamesboehmer:master into b1bffc4f8da66a143e43aeb7893293a2911526d3 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling b179d012d768aea67ec66a9e3a0b8a89ace490ca on BossGrand:master into b1bffc4f8da66a143e43aeb7893293a2911526d3 on graphql-python:master.\n. \nCoverage remained the same at 95.884% when pulling 85cad0efc38997f1a0ea8a20063ad62e2cf4185d on BossGrand:master into b1bffc4f8da66a143e43aeb7893293a2911526d3 on graphql-python:master.\n. \nCoverage increased (+0.008%) to 96.158% when pulling f728de311ecdff9a8a01ee044d4d14b7b4c54518 on Globegitter:field-metadata into 3c99302ed6edc0140e98d21838c161d6055d11cf on graphql-python:master.\n. \nCoverage decreased (-0.2%) to 96.0% when pulling c4442b69b4c6fbb67ef8c686626203074b46acca on tangerilli:union_connections into 3c99302ed6edc0140e98d21838c161d6055d11cf on graphql-python:master.\n. \n\nCoverage remained the same at 96.252% when pulling 11996e9121dc897ff67b0d4127d824136f06973b on sangheestyle:patch-1 into 67c0872c9fceed737b2300d118e6950ee20e97fe on graphql-python:master.\n. \n\nCoverage decreased (-0.5%) to 95.707% when pulling f089c78b997e2a588775360af2e12944b573cdd8 on pizzapanther:master into 5cfa895881fbe9a1dc6fa8b3ad1fd202f4d57cb4 on graphql-python:master.\n. \n\nCoverage decreased (-0.5%) to 95.707% when pulling f089c78b997e2a588775360af2e12944b573cdd8 on pizzapanther:master into 5cfa895881fbe9a1dc6fa8b3ad1fd202f4d57cb4 on graphql-python:master.\n. \n\nCoverage increased (+0.2%) to 96.491% when pulling ad83a7e07694a48bb5ee8cbfe2b953150620fa31 on pizzapanther:master into 5cfa895881fbe9a1dc6fa8b3ad1fd202f4d57cb4 on graphql-python:master.\n. \n\nCoverage remained the same at 96.491% when pulling 20ca84966e8a0e67ba0c731b60182d192c407a10 on pizzapanther:master into 692d7e76ad06b0b0eb777c14197d041913519868 on graphql-python:master.\n. \n\nCoverage decreased (-0.06%) to 96.429% when pulling f64934f85da6d198602be0dc281c68e3ea345827 on tsunammis:master into 51c37fef98dc0fd99e517ab2cd612acf4e818af0 on graphql-python:master.\n. \n\nCoverage decreased (-0.06%) to 96.429% when pulling f64934f85da6d198602be0dc281c68e3ea345827 on tsunammis:master into 51c37fef98dc0fd99e517ab2cd612acf4e818af0 on graphql-python:master.\n. \n\nCoverage decreased (-0.06%) to 96.429% when pulling f64934f85da6d198602be0dc281c68e3ea345827 on tsunammis:master into 51c37fef98dc0fd99e517ab2cd612acf4e818af0 on graphql-python:master.\n. \n\nCoverage remained the same at 96.491% when pulling 774e9bf4639ca459d0a12a10e090d9ab671b6459 on riddlesio:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.4%) to 95.062% when pulling 714f4884c0326ff637e8bbcfc35fbec7383a085f on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.3%) to 95.161% when pulling ce2bc5d161bce3db4156f143f16dcdff687d20b5 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.2%) to 95.256% when pulling 3c72f3a67531772a832771bc499e9d618bc06688 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.2%) to 95.256% when pulling 3c72f3a67531772a832771bc499e9d618bc06688 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.2%) to 95.256% when pulling 3c72f3a67531772a832771bc499e9d618bc06688 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.2%) to 95.329% when pulling 7011f0d66215cab148c30d3742b05bc9e70b73e5 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-1.2%) to 95.329% when pulling 7011f0d66215cab148c30d3742b05bc9e70b73e5 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-0.02%) to 96.473% when pulling 4dc7a93a61e2a7f0d619f4c480469e1c2aefd929 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage decreased (-0.02%) to 96.473% when pulling a74c402f1344709364e489798277ff2d8dbe4982 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage increased (+0.08%) to 96.568% when pulling 17ea139ce4e33b739e0151779723c453e6345313 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage increased (+0.08%) to 96.568% when pulling 17ea139ce4e33b739e0151779723c453e6345313 on hung-phan:master into da3683028e3049bf7b9e0d8327d11e45261a8e52 on graphql-python:master.\n. \n\nCoverage increased (+0.1%) to 96.589% when pulling 93dacda923069f6c944da93830fbf94b5ff33728 on features/mounted-refactor into 7e5285d8594d814a16047c0ea2f30eb2f5db29b6 on master.\n. \n\nCoverage increased (+0.007%) to 96.595% when pulling f3865300ffdd018ee57c7616d3e0ba1785548316 on features/allow-custom-mounted-classes into edd090efdefef0f17b3caba9dc43edbdea4da5c9 on master.\n. \n\nCoverage remained the same at 96.689% when pulling 888348bd94243f5b0d5272ce840541c9b6af772e on kelvintaywl:fix-small-readme-typo into 2ef0e23dcf036aa41e7ee96dd2468c7177021829 on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling f728542ce7d431359ed32f3522bea12d629eb329 on docmatrix:feature/source-method into 02eb6856ed72841f87bd532e91fe1dc123c0c9d2 on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling 1232ff3ee1e4006a262be5e50664f44c6e635200 on BossGrand:master into a3c3be26f4ea29aa099ad51183b267299fb6064a on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling b9d3abee3166b71a6a56302e1c0cac554230b8ea on BossGrand:master into a3c3be26f4ea29aa099ad51183b267299fb6064a on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling b9d3abee3166b71a6a56302e1c0cac554230b8ea on BossGrand:master into a3c3be26f4ea29aa099ad51183b267299fb6064a on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling b9d3abee3166b71a6a56302e1c0cac554230b8ea on BossGrand:master into a3c3be26f4ea29aa099ad51183b267299fb6064a on graphql-python:master.\n. \n\nCoverage remained the same at 96.689% when pulling 0ed4050bb63e1a338e88e9176f197bebe327769e on BossGrand:master into a3c3be26f4ea29aa099ad51183b267299fb6064a on graphql-python:master.\n. \n\nCoverage remained the same at 96.612% when pulling 81c1cf3d61e47527ff49a15e97cfdbabe88a8755 on helfer:patch-1 into 8dff91d4c689ea6a92c13a5a5520c1ce9c360e04 on graphql-python:master.\n. \n\nCoverage increased (+0.03%) to 96.685% when pulling da08a82597bd928b4a91f81c2dc21c33057fe2f5 on yen223:fix-docstring-whitespace into e2cdd80a5cc5524af0a45273fd257c08b0ff8bc2 on graphql-python:master.\n. \n\nCoverage increased (+0.03%) to 96.685% when pulling c592e94f73923ee2d2fbac26311e5976fcddee87 on yen223:fix-docstring-whitespace into e2cdd80a5cc5524af0a45273fd257c08b0ff8bc2 on graphql-python:master.\n. \n\nCoverage remained the same at 96.657% when pulling 47bb5292fa97a6307cbef3385a837a579502e72b on helfer:patch-2 into e2cdd80a5cc5524af0a45273fd257c08b0ff8bc2 on graphql-python:master.\n. \n\nCoverage remained the same at 96.657% when pulling 47bb5292fa97a6307cbef3385a837a579502e72b on helfer:patch-2 into e2cdd80a5cc5524af0a45273fd257c08b0ff8bc2 on graphql-python:master.\n. \n\nCoverage remained the same at 96.657% when pulling 47bb5292fa97a6307cbef3385a837a579502e72b on helfer:patch-2 into e2cdd80a5cc5524af0a45273fd257c08b0ff8bc2 on graphql-python:master.\n. \n\nCoverage remained the same at 96.736% when pulling 3a198d052acc01a8469dc03d0c0d798612830be2 on chappers:master into ad251e9a8dd46d212e39da67945df4fc3e02b361 on graphql-python:master.\n. \n\nCoverage remained the same at 96.739% when pulling d86bbd8a8647bbcf9d668968977cc35c64f67f12 on gbezyuk:patch-1 into 360d5cfac5f8ae1f6c2da2b145a247a7c6d92058 on graphql-python:master.\n. \n\nCoverage remained the same at 96.739% when pulling b52ecb408c5b8b0b27cc92045faa12bed3cd4787 on helfer:apollo-docs into a837fb6836db14272f13a559b15f76e59fbc8df8 on graphql-python:master.\n. \n\nCoverage decreased (-0.4%) to 96.346% when pulling f9c99fe629808ad471bb3a721f862082e2387ea6 on helfer:apollo-docs into a837fb6836db14272f13a559b15f76e59fbc8df8 on graphql-python:master.\n. \n\nCoverage remained the same at 96.102% when pulling 86f5cbc08ee053baa4a94e74282ff51fc59fbbf2 on helfer:apollo-docs into fccc22b6512b87212c2b02582cc3381ec52c8d59 on graphql-python:master.\n. \n\nCoverage decreased (-0.05%) to 96.257% when pulling 087f1c55cd99d591ac99595beed9ac8c2e8f3fe5 on blakegong:features/add-dotted-arguments-for-lazy-import into d4d8a76a0936b8b8b90e6b316003c31c21e30500 on graphql-python:master.\n. \n\nCoverage decreased (-0.05%) to 96.257% when pulling 3822d6568e7617700dc056c018541a24be2bd1e5 on blakegong:features/add-dotted-arguments-for-lazy-import into d4d8a76a0936b8b8b90e6b316003c31c21e30500 on graphql-python:master.\n. \n\nCoverage increased (+0.03%) to 96.329% when pulling afed25a18015643749439288a9536235232dd493 on features/improved-enums into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.03%) to 96.267% when pulling dfcd7f256340301d7551e2af383e4e84454db097 on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.03%) to 96.267% when pulling 60e29028a8c7e025d5bbfe1d9f730c937829c98c on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.03%) to 96.267% when pulling 60e29028a8c7e025d5bbfe1d9f730c937829c98c on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.03%) to 96.267% when pulling b369ccfa0828817f41b647938d926f5c2a4cb192 on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.3%) to 96.028% when pulling 917dc16ea64b3d896e81f5648dea0aebb78b468e on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage decreased (-0.3%) to 96.031% when pulling 6c040e68a2474ec17f1d2ccd5a4b295ffab63dbd on features/test-client-and-snapshot-testing into aaf9e92d24485ef0ffdd5cb7e87091783f3026a9 on master.\n. \n\nCoverage remained the same at 96.072% when pulling 06757f10c6cbfb3885531b02a2c93e94491380a5 on khankuan:patch-1 into b8323ed8e760fdcbd0d01cdf636508c1ad76104b on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling 631905f315265b2f1131ec698eecc07b6357c832 on MikeTYChen:update-relay-doc-link into 8cae7bd16f6d3bba7e933950e3128ca8e6b61f66 on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling 5052536787503290fee145ada575ec8810fdf308 on MikeTYChen:update-relay-doc-link into 8cae7bd16f6d3bba7e933950e3128ca8e6b61f66 on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling bad6f5a18873c5ef6488910b8f58728b8ff1ac1e on yixizhang:typo into 8cae7bd16f6d3bba7e933950e3128ca8e6b61f66 on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling b5d15b635eabcf6004e222e77c6eb9ad0963cb32 on ryanwilsonperkin:patch-1 into 23e028fe72ee46500f20b37c678b239eda7576b0 on graphql-python:master.\n. \n\nCoverage increased (+0.01%) to 96.102% when pulling 388253ede47c2b998c0fb20030f86d908fb383ce on affablebloke:master into 606575a2b04fd488cb319ae2f3aeb38102f1dd34 on graphql-python:master.\n. \n\nCoverage increased (+0.01%) to 96.102% when pulling 83857bfcfe02c9eb7d9baee367d54c0e2d887e9d on affablebloke:master into 606575a2b04fd488cb319ae2f3aeb38102f1dd34 on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling 0a9dbb608a0ee71dd556c0bd206a0b39bd5a337d on ryanashcraft:patch-1 into 606575a2b04fd488cb319ae2f3aeb38102f1dd34 on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling 9d30136095551108fad5ee63b3f479b31c818bd6 on vincentfretin:patch-1 into cb0adcb0fec1436ce8f0adbc41d2a96c956dd3ee on graphql-python:master.\n. \n\nCoverage remained the same at 96.092% when pulling d7dff53f46967601a9b289a075a8bf7190431282 on pmlandwehr:patch-1 into cb0adcb0fec1436ce8f0adbc41d2a96c956dd3ee on graphql-python:master.\n. \n\nCoverage increased (+0.02%) to 96.057% when pulling ce8a93c405c55dcdb18531369ad610f5e7ef0b3f on loanstreet-usa:master into 985252920ce2e2701388e2e20f3cc74419ff3b85 on graphql-python:master.\n. \n\nCoverage increased (+0.02%) to 96.057% when pulling 9e408b385aaf28c0c7f03a1066108be56f3bbab7 on loanstreet-usa:master into 985252920ce2e2701388e2e20f3cc74419ff3b85 on graphql-python:master.\n. \n\nCoverage increased (+0.02%) to 96.057% when pulling c012c48866b307345935401b02e0b6de542d5d83 on loanstreet-usa:master into 985252920ce2e2701388e2e20f3cc74419ff3b85 on graphql-python:master.\n. \n\nCoverage increased (+0.02%) to 96.057% when pulling faf8a41118555c715c3a56b8371ab33b654fe9ab on loanstreet-usa:master into 985252920ce2e2701388e2e20f3cc74419ff3b85 on graphql-python:master.\n. \n\nCoverage remained the same at 96.047% when pulling 93fc03d9e0e1fc0840f7d1b975216f3b174e9126 on XatMassacrE:master into f22504c2fc931007111264f4067e11662dd4ed13 on graphql-python:master.\n. \n\nCoverage remained the same at 96.047% when pulling dc5de1f5036258725e4d56c86e3f57c4828c63f3 on XatMassacrE:master into f22504c2fc931007111264f4067e11662dd4ed13 on graphql-python:master.\n. \n\nCoverage remained the same at 96.047% when pulling c155b7a56e5963d9fafac98184603eef636c2ad0 on Thibaut-Fatus:patch-1 into 3e62fcf0cc1b1b21598777d7a2429bfbc9e6c07e on graphql-python:master.\n. ",
    "prokofiev": "@defrex may be something like this:\npython\nclass MyGraphQLView(GraphQLView):\n    @staticmethod\n    def format_error(error):\n        if isinstance(error, GraphQLError):\n            formatted_error = {\n                'message': error.message,\n            }\n            if hasattr(error, 'original_error') and isinstance(error.original_error, exceptions.GraphQL\u0415TypedError):\n                formatted_error['type'] = error.original_error.error_type\n            elif error.locations is not None:\n                formatted_error['locations'] = [{'line': loc.line, 'column': loc.column} for loc in error.locations]\n            return formatted_error\n        return {'message': six.text_type(error)}\n. Hi @syrusakbary !\nThanks for answer, but default_value  will not be able to solve my problem.\nI try to describe the problem in more detail:\npython\nclass Foo(models.Model):\n    ''' Example model with nullable field '''\n    not_null = models.CharField(max_length=10)\n    nullable = models.CharField(max_length=10, null=True)\nNext my use cases:\n1) Insert with default null value\nmutation InsertFoo{\n    saveFoo (input:{\n        clientMutationId:\"1\"\n        notNull:\"value\"\n    }) {\n      ...\n    }\n}\n2) Update nullable field (set \"value\"), not_null ignored\nmutation UpdateFoo{\n    saveFoo (input:{\n        clientMutationId:\"1\"\n        id:\"id\"\n        nullable: \"value\"\n    }) {\n      ...\n    }\n}\n3) Update nullable field (set null), not_null ignored\nmutation UpdateFoo{\n    saveFoo (input:{\n        clientMutationId:\"1\"\n        id:\"id\"\n        nullable: null\n    }) {\n      ...\n    }\n}\nHow can I use \"default_value\" to set the nullable field to null (case 3)?\n. Hi @syrusakbary !\nIt does not make sense because the fields with null values are removed from the argument list and not in the input dict. \nProblem in graphql-core in this and this functions.\nFunction value_from_ast return None, and then function get_argument_values check if value is not None.\n. null value may be passed like this:\nmutation UpdateFoo($var1:String!){\n    saveFoo (input:{\n        clientMutationId:\"1\"\n        id:\"id\"\n        nullable: $var1\n    }) {\n      ...\n    }\n}\nvariables:\n{\"var1\": null}\n. Hi @nuschk.\nI found solution for my case. It's monkey patch but it works...\nYou can see my patch here\nCall apply from any place when initialize your app.. If somebody knows how to fix it more correctly, please let me know.. ",
    "smmoosavi": "I extend GraphQLView in order to custom error handling.\ncode and example\nyou just need raise special error:\npy\nraise ResponseError(\"Invalid Password\", code='invalid_old_password')\nand get error response:\njson\n{\n  \"errors\": [\n    {\n      \"message\": \"Invalid Password\",\n      \"code\": \"invalid-old-password\",\n      \"params\": null\n    }\n  ],\n  \"data\": {\n    \"changePassword\": null\n  }\n}\nthe only problem is logging ResponseError.. ",
    "nlyn": "According to GraphQL specs custom info like this should be added to the extensions key. It looks like this isn't yet supported in Graphene.\nhttps://facebook.github.io/graphql/June2018/#example-fce18. ",
    "vam": "Thank you for your answer. I'm convinced.\n. ",
    "lsdsjy": "@helpse I think HTTP status code represents the status of the HTTP response itself, but not something related to the GraphQL query in the payload of the HTTP request. The request is handled perfectly by the server, that's what 200 means. And the errors in the queries? It's GraphQL's business to point them out in the response content, but not somewhere else which should be controlled by the Web Server itself. After all, the GraphQL query is only handled by only an endpoint of the server. And I think it's one of the disadvantages of GraphQL against RESTful.. ",
    "gcheshkov": "Hi! Here is my proof of concept code to map DRF serializers to mutations: https://gist.github.com/gcheshkov/555b3e300b45f451b5b0fe79c73531ae\n. @stefanfoulis ErrorType  is simple graphene object type for representing errors: \nclass ErrorType(graphene.ObjectType):\n    field = graphene.String()\n    message = graphene.String()\nHowever now I took different approach to error handling. Just raising ValidationError in mutation handler and adding error messages to errors object in overridden GraphQLView.format_error  method:\n```\ndef format_error(error):\n    data = {\n        'message': str(error),\n    }\nif isinstance(error, GraphQLLocatedError):\n    data.update(format_graphql_error(error))\n    if isinstance(error.original_error, Exception):\n        error = error.original_error\n    else:\n        return data\n\nif isinstance(error, APIException):\n    if isinstance(error, ValidationError):\n        data.update({\n            'message': _('Validation error'),\n            'code': 'validation_error',\n            'fields': error.detail\n        })\n    else:\n        if getattr(error, 'error_code', None):\n            data['code'] = error.error_code\n\n        if getattr(error, 'extra', None):\n            data.update(error.extra)\n\nelif isinstance(error, DjangoPermissionDenied):\n    data.update({\n        'message': _('Permission denied'),\n        'code': 'permission_denied'\n    })\n\nelif isinstance(error, GraphQLError):\n    pass\n\nelif isinstance(error, HttpError):\n    pass\n\nelse:\n    data['code'] = 'unhandled_exception'\n    if not settings.DEBUG:\n        data['message'] = _('Server error')\n    else:\n        data['message'] = '{}: {}'.format(error.__class__.__name__, error)\n        data['traceback'] = itertools.chain(\n            *[[l for l in ll.split('\\n') if l.strip() != '']\n              for ll in traceback.format_exception(\n                    error.__class__, error, error.__traceback__)])\n\nreturn data\n\n```\n. ",
    "stefanfoulis": "@gcheshkov thanks for the gist. I noticed you're importing from .types import ErrorType. Could you post the code to that too?\n. @gcheshkov thanks. that helped me a lot :-)\n. Thanks for the pointers you grave me on slack @mjtamlyn .\nThis is my DjangoNode subclass that allows filtering the queryset by overriding get_queryset():\n``` python\nclass QuerysetDjangoNode(graphene.contrib.django.types.DjangoNode):\n    class Meta:\n        abstract = True\n@classmethod\ndef get_queryset(cls, id, context, info=None):\n    \"\"\"\n    Added get_queryset to allow overriding the queryset in subclasses.\n    \"\"\"\n    model = cls._meta.model\n    return model.objects\n\n@classmethod\n@graphene.with_context\ndef get_node(cls, id, context, info=None):\n    \"\"\"\n    Same as super(), but gets the queryset from get_queryset()\n    \"\"\"\n    qs = cls.get_queryset(id, context, info=info)\n    try:\n        instance = qs.get(id=id)\n        return cls(instance)\n    except cls._meta.model.DoesNotExist:\n        return None\n\n```\nand this is an application specific subclass that always adds .for_user(user) to the queryset (we have that method as a chainable queryset on all Model managers:\n``` python\nclass PermissionAwareDjangoNode(QuerysetDjangoNode):\n    class Meta:\n        abstract = True\n@classmethod\n@graphene.with_context\ndef get_queryset(cls, id, context, info=None):\n    qs = (\n        super(PermissionAwareDjangoNode, cls)\n        .get_queryset(id, context=context, info=info)\n    )\n    user = context.user\n    return qs.for_user(user)\n\n```\nand similarly a permission aware DjangoFilterConnectionField:\n``` python\nclass PermissionAwareDjangoFilterConnectionField(\n    graphene.contrib.django.filter.DjangoFilterConnectionField):\ndef get_queryset(self, qs, args, context, info):\n    # permission check:\n    qs = qs.for_user(context.user)\n    return (\n        super(PermissionAwareDjangoFilterConnectionField, self)\n        .get_queryset(qs, args, info)\n    )\n\ndef from_list(self, connection_type, resolved, args, context, info):\n    resolved_qs = maybe_queryset(resolved)\n    qs = self.get_queryset(resolved_qs, args, context, info)\n    return (\n        # we are calling super of DjangoConnectionField on purpose, because\n        # we've re-implemented from_list here and don't want to run it\n        # again.\n        super(graphene.contrib.django.fields.DjangoConnectionField, self)\n        .from_list(connection_type, qs, args, context, info)\n    )\n\n``\n. I'm closing this issue for now. If there is interest in havingget_queryset()onDjangoNode` in core, I can make a pull request.\n. ",
    "johandc": "Hi what is the status on this?\nI need something like a UserInputType for a IntroduceUser mutation and i don't want to manually map all the fields of the Django User model.\nI would like if there would be a DjangoInputObjectType that could be created similar to the DjangoObjectType. Passing it through Django Forms is a brilliant solution to handling field validation, but being able to bypass validation would be appreciated for bulk data imports from a trusted system.. ",
    "fangaofeng": "i can see form.py and form_convert.py in graphene-django , but never found any how to use. \nDjango: Map Form to Mutation how to use\uff1f. @syrusakbary i query express all filed. It can work and query result is right, except nod debug.\nother code:\n```python\nclass ExpressCompanyModel(db.Model):\n    tablename = \"express_company\"\n    id = db.Column(\n        db.Integer, primary_key=True, nullable=False, autoincrement=True)\n    name = db.Column(db.String(20), nullable=False)\n    num_courier = db.Column(db.Integer, default=0, nullable=False)\ndef __init__(self, name):\n    self.name = name\n\nclass ExpressCompanyType(SQLAlchemyObjectType):\n    class Meta:\n        model = ExpressCompanyModel\nschema = graphene.Schema(query=Query)\n. I use flask_GraphQL .\napp.add_url_rule(\n    '/graphql',\n    view_func=GraphQLView.as_view('graphql', schema=schema.schema, graphiql=True))\n```\ndebugging tool is vscode  1.9 and python plugin. \nI try eclipse pydev,thank you replay.. i test by eclipse pydev ,it can debug. \nthank you very much.. ",
    "patrick91": "@fangaofeng this is not implemented yet. I'm working on something similar for django rest framework's serialisers in https://github.com/graphql-python/graphene-django/pull/186\nI'm happy to do the same for the Forms, but right now I don't have much time, and I'd like to finish the other PR first :). Authentication in graphql is a bit different that usual APIs, you might want to do one of the followings:\n\nProtect the whole API\nProtect some queries/mutations\nProtect some fields\n\nFor all of them you might use any authentication system, I've done it with JWT and also via sessions based authentication (both with django, but doesn't really matter).\nThe first one is pretty easy since you can just protect the GraphQL view.\nThe way I've approached the second was to check for the user in the resolve_* methods and return empty elements when the user is not logged. This can be fine for you use case, but it will leak the types in the documentation (which might not be a bad thing, but, again, depends on the use case[1]).\nI'm mostly interested in trying to tackle the third way, specifying some condition on some of the fields. So for example I can hide field_x for a particular kind of user. I haven't needed this feature so far, so I have no idea how to implement it.\nSo, hopefully that was a bit useful, so, going back to your issue, with flask, you might be able to use a login_required decorator, like here: http://flask.pocoo.org/docs/0.12/patterns/viewdecorators/\nThat will protect the whole API, but you will still need to authenticate the user, I don't use flask that much (I'm working on a side project right now that needs auth and graphql, so I might have some updates soon) but I believe you can use this package: https://flask-login.readthedocs.io/en/latest/#custom-login-using-request-loader \nLet me know how that goes!\n[1] As far as I know github hides some fields/types that are not public, so you can't use them and you can't see them in the docs.. @rotten please have a look at this: https://medium.com/the-graphqlhub/graphql-and-authentication-b73aed34bbeb\nIf I find some time I'll create a demo with authentication and Flask if that could be helpful :). @Musbell I didn't have the time yet, but I found this post that can be helpful :) http://danielwelch.github.io/django-graphql-token-auth.html\n. @hballard will you be at EuroPython? maybe we can find someone to help during the sprints! :). @rdemetrescu I never used Relay! I use Apollo, but I might try it :)\nAre you using Relay Modern?. Oh I see what you mean! You can definitively use \"relay\" with Apollo. For some reason I thought of the Relay client, not the specification :)\nSee here: https://facebook.github.io/relay/docs/graphql-relay-specification.html\nIt is \"just\" a standardised way to add pagination to a graphql field, I'll try to add that in the tutorial as well :). @hbutau I don't use ember, sorry!\n@syrusakbary no :( it's on my task list for sunday tho :). @all sorry, I've been busy on so many things during the last few months, I'll try to get back to this soon :). Thanks @fishy do you have any example for this? Maybe it could be nice to write some docs/tips for it.. can you post the result of pip freeze?. The guide on graphql.org is outdated :)\nSee http://docs.graphene-python.org/en/latest/quickstart/#creating-a-basic-schema. I'd love to support Graphene too, both with money and with my personal time, I'm not working much on Python right now, but I'm sure I will in future.\n@syrusakbary what do you think of a Kickstarter campaign or, maybe, a patreon?. @syrusakbary is there a public roadmap for the new features?. That\u2019s interesting, I\u2019ll think about it, if you have an example on how this would look in graphene post it :)\nChanging the field won\u2019t work much in graphene or graphql since the schema should not change at runtime, at least not based on the user, what do you think?. I see, I think GitHub has the concept of public and private fields, private fields are only used in the private api. Which I think it is quite nice, but I still think it is separate from permissions. Imagine if we are building an admin app where there are different permissions level, I\u2019d still want to see the whole schema while working on it, if I change the schema based on the user that would complicate things a bit. \nI\u2019m just brainstorming right now, I might be wrong :) I\u2019ll keep thinking on it! I\u2019m really looking forward to see what we come up with:). @zbyte64 I usually have two types, PrivateUser and PublicUser to solve that issue, but with field permissions we might not need that anymore :). I've stopped working on Graphene until we have a clear maintenance proposal, see #884 :). @firasalkafri no :(. I usually do it in the resolver:\n```python\nclass MyQuery(...):\n    ...\ndef resolver(root, info, filters=ABC):\n    pass\n\n```\ndoes this help? :). Yeah using Filters() should work, so I guess there's a bug somewhere :)\nI'll see if I can have a look at it soon. @asodeur yes we use pytest :)\nNot sure about the location, I'd put them here: https://github.com/graphql-python/graphene/blob/master/graphene/types/tests/test_datetime.py . patrick.arminio@gmail.com. Invited all :). I think anyone can invite people, as long as we have their email :) @adilnaimi ping me yours and I'll send the invite :). Yup, I think we should pass all the arguments to the permission class, I was a bit lazy with the comment \ud83d\ude05\n. suggestion\n which resolves to a list of ``values``.. ",
    "lig": "@jkimbo this feature request is still valid if it is not implemented yet. Such a future would be very helpful for projects migrating from an existing Django infrastructure.. ",
    "tadeo": "Just as a reference for who will implement this feature in the future, I found something that seems could help in another OS project: https://github.com/mirumee/saleor/blob/99d45583985eb64e62966b3411bee54ba5052b1a/saleor/dashboard/graphql/core/mutations.py\nI'm too new to graphQL and I don't have the skills to take this task but I hope this serves as an inspiration to someone.\n@jkimbo sorry about commenting here, I didn't find this topic in graphene-django issues.. ",
    "karec": "Working on it right now ;)\nPull request #146 \n. I close it since the PR has been merged :) \n. Reference to issue #145 \n. :+1: \nSome fields could be really simple to implement within the existing code, I will try to work on it this week if I have some times.\nIt could be nice to define a list for all fields that we need to add\n. @dgouldin I've added all this fields to sqlalchemy converters, I still need to make some tests before pull request but my fork is up to date if you need to test it\n. ",
    "jimmay5469": "FYI - It appears as though args has been renamed variable_values.. ",
    "mbrochh": "This was extremely helpful! Thank you so much!\n. Any insights on this? Should I re-post this issue on the graphene-django repo?. @ekampf I ended up making a real query as well, but wow... I like that other approach a lot more. 8 years of Python an I never knew that you can pass in self like that.. @ekampf hmmm... I tried it just now like this:\ndef test_resolve_detail_url(self):\n        product = mixer.blend('marketplace.Product', published=True)\n        func = schema.ProductType.resolve_detail_url\n        res = func(product, None, None, None)\n        self.assertEqual(res, product.get_detail_url())\nAnd I'm getting this:\nTypeError: unbound method resolve_detail_url() must be called with ProductType instance as first argument (got Product instance instead)\nAre you sure that this method works?. @ekampf AHA! some google-fu taught me, that there is something called im_func in Python (which I was never aware of), so this seems to work:\ndef test_resolve_detail_url(self):\n        product = mixer.blend('marketplace.Product', published=True)\n        res = schema.ProductType.resolve_detail_url.im_func(product, None, None, None)\n        self.assertEqual(res, product.get_detail_url()). ",
    "sehmaschine": "Please Note: I'm not even sure this is related to graphene ... any hints are highly appreciated.\n. @syrusakbary thanks a lot \u2013 it works now. but I do have another minor issue: when I'm filtering the query (e.g. with something like name_Icontains) the counter returns the number of filtered items. do you have an idea how I'm able to get all items (independent of any filters applied)?\n. ",
    "BossGrand": "I would override total count on your connection to return Model.objects.count(). I'm using a custom uuid primary key for my models, any chance that would be the cause?\n. Ok so I found what was causing this to happen,\nI had to add related_name='buildings' to my address foreign key field on Building model.\nIs this a bug? It wasn't clear in the docs that this was required\n. @syrusakbary have you seen this pull request?\nhttps://github.com/facebook/graphql/pull/83\ngraphql now supports nullable types. Can we get some support for this in graphene?. This issue is solved in graphene 2.0 and should be closed. So it looks like the issue is how I was pulling this query into my main query\nwhen I changed \n```\nclass Query(md_schemas.MasterDatabaseQuery):\n    # This class will inherit from multiple Queries\n    # as we begin to add more apps to our project\n    pass\nschema = graphene.Schema(query=Query)\n```\nto\nschema = graphene.Schema(query=md_schemas.MasterDatabaseQuery)\nit worked as expected. This change wasn't documented in the upgrade guide. What is the proper way to compose queries from multiple apps together now?\n. Sweet thanks for the help, I'll add a pr request over the weekend with an updated readme!\n. @vwrobel You can use a django method filter \nI would just pass in a dict that has a value and exclude \n```\nclass ExampleFilter(django_filters.FilterSet):\n    search_with_exclude = django_filters.MethodFilter()\n def filter_search_with_exclude (self, queryset, value):\n     filter_value = value['filter_value']\n     exclude_value = value['exclude_value']\n\n     queryset = queryset.filter(ownerName=filter_value)\n     queryset = queryset.exclude(ownerName=exclude_value)\n\n     return queryset\n\n```\nthen you can just pass an object into your graphql query kinda like you would a mutation! :D\n. Can you put your code from the class thats causing the issue. @dmitry-saritasa all inputs to a mutation have to be wrapped in a input object\nthis \ncreateHero(name:\"Test\", planet:\"Test\"){\nshould be \ncreateHero(input:{ name:\"Test\", planet:\"Test\" }){. @dmitry-saritasa  I see another error\nclass Mutation(graphene.ObjectType):\n    create_hero = graphene.Field(CreateHero)\n\nshould be \nclass Mutation(graphene.ObjectType):\n    create_hero = CreateHero.Field()\n\nhttp://docs.graphene-python.org/en/latest/types/mutations/\nLet me know if that works! \n. Awesome pr!\nI suggest adding some docs on passing context into the execute method. This Issue belongs in https://github.com/graphql-python/graphene-django. This kind of depends on what you're trying to achieve. Are you trying to send back a message to the front end user? Or are you trying to send a error message to a fellow developer?\nBased on the context of your question I would guess you are trying to send a message to the front end user. If that is the case then you need to catch the exception, or capture the error message and return it as part of the payload of your mutation. \nNow this gets tedious if you want to achieve this for all your mutations. What I've done is written my own Mutation Class that extends ClientIDMutation\nI'll provide the solution I came up with. I only needed simple single string error messages. If you need to return more complex error details then this will need to be expanded.\n```python\nclass CustomClientIDMutationMeta(ClientIDMutationMeta):\n    ''' We have to subclass the metaclass of ClientIDMutatio and inject the errors field.\n        we do this because ClientIDMutation subclasses do not inherit the fields on it.\n    '''\n    def new(mcs, name, bases, attrs):\n        attrs['errors'] = String()\n        return super().new(mcs, name, bases, attrs)\nclass CustomClientIDMutation(ClientIDMutation, metaclass=CustomClientIDMutationMeta):\n    ''' Custom ClientIDMutation that has a errors  @fields.'''\n    @classmethod\n    def mutate(cls, root, args, context, info):\n        try:\n            return super().mutate(root, args, context, info)\n    except MutationException as e:\n        return cls(errors=str(e))\n\n```\nAlso note that I've created a custom Exception Object called MutationException\npython\nclass MutationException(Exception):\n    '''A Mutation Exception is an exception that is raised\n       when an error message needs to be passed back to the frontend client\n       our mutation base class will catch it and return it appropriately\n    '''\n    pass\nThis solution has worked really nicely for my needs because anytime I need to send a validation message I just have to raise a MutationException and it will propagate back to the frontend user nicely. This Issue might belong in https://github.com/graphql-python/graphene-django. You don't need to make graphene to take more then one input to accomplish this.\ni.e\njavascript\neditFoo(id: 5, fooString: \"test\", showOutput: true){\n   isSuccessful\n}\nShould  be \njavascript\neditFoo(input: {id: 5, fooString: \"test\", showOutput: true}){\n   isSuccessful\n}\neven though I'm using \"one\" variable I can have any number of arguments\n. nah you don't, from a javascript perspective input is an object and you can put anything you like in your objects :)\nMake sure to close this issue if you've gotten it to work for yourself. Yea thats what I ended up doing to. I have a subclass of mutation that I use on all my mutations so it was relatively painless. \nI think that long term this needs to be fixed in the code base. A node is a type. If you want to use relay's connection specification for pagination then your Object Type will need to implement the node interface.\nBasically a Connection is a way to paginate a list of data. Each connection is a list of edges that have a cursor and a node. The node is your actual data object.\nlets take the example provided\n```python\nclass Ship(graphene.ObjectType):\n    ship_type = String()\n    def resolve_ship_type(instance, info):\n         return instance.ship_type\nclass Meta:\n      interfaces = (Node,)\n\nclass ShipConnection(Connection):\n    total_count = Int() # i've found count on connections very useful! \ndef resolve_total_count(instance, info):\n     return get_count_of_all_ships()\n\nclass Meta:\n    node = Ship\n\nclass Edge:\n    other = String()\n     def resolve_other(instance, info):\n            return \"This is other: \" + instance.node.other\n\n```\nI've included a ShipNode implementation and some resolvers to make the example of how this all works together \nso this gives us the ability to create query for lists of ships.\nlets say we have a root level query\n```python\nclass Query(graphene.ObjectType):\n     ships = relay.ConnectionField(ShipConnection)\ndef resolve_ships(self, info):\n     return get_ships_from_database_or_something_idk_its_your_implmentation()\n\nschema = graphene.Schema(query=Query)\n```\nnow in graphiql we can query for ships, \nthe following query will give us the first 10 ships\n```\nquery{\n     ships(first: 10){\n          totalCount,\n          edges{\n                cursor,\n                node{\n                   id,\n                   shipType\n                }\n          }\n     } \n}\n```\nyou can also do last\nquery{\n     ships(last: 10){\nor you can take one of your cursors and do the first 10 after that\nquery{\n     ships(first: 10, after: $someCursor){\nthis is really useful because now you have pagination for basically free, especially if you're using something like graphene-django. Its amazing\nYou can either add to your first count to get the infinite scrolling lists like on fb page, or you can paginate by pages using cursors.\nthere is also a pageInfo object on  connections that give you info that is helpful for paginating.\nquery {\n    ships(first: 10){\n         pageInfo {\n             startCursor\n             endCursor\n             hasNextPage\n             hasPreviousPage\n          }\n         edges{  ... ect\n         }\n    }\n}\nI hope this helps!  \nAlso something to note. Relay has their own special id system. Each id needs to be unique for every node in your whole application. In graphene-django they combine id with node type to achieve this.\nThere are two helper functions to help with this id'ing\npython\nfrom graphql_relay import from_global_id, to_global_id\nif you want more information here are the relay docs for the connection specification\nhttps://facebook.github.io/relay/docs/graphql-connections.html\nthe graphene docs should probably link to them so that people can get a more indepth understanding of this specification\nAlso one last note. You do not have to use relay to use connections. It is only a specification. I use Apollo as my frontend client and find connections very handy! \n@danpalmer\n. @hheimbuerger the cursor is not a database cursor. Its kind of similar but its relays own thing. Its just a way to keep track of where you are in pagination\n@keyeMyria i can't tell you how to calculate pageinfo. I think the graphene.Connection handles that. But not sure. @fanadol you can specify your own Connection\nFor example is this is the one my company uses\n```\nclass HelloOfficeConnection(graphene.Connection):\n    count = graphene.Int()\ndef resolve_count(self, info):\n    return self.length\n\nclass Meta:\n    abstract = True\n\n```\nand then on the query you can do this\nquery {\n    ships(first: 10){\n         count\n    } \n}\nand count will the be the total of get_all_ships . @syrusakbary I'm interested in helping out whatever I can do.  me@charlesharo.com\n. This is possible! You need to wrap the resolver like such\n```python\ndef wrap_resolver(cls, resolver):\ndef wrapped_resolver(root, info, **args):\n    try:\n        with transaction.atomic():\n            return resolver(root, info, **args)\n\n    except Exception as e:\n        return cls(errors=str(e))\n\nreturn wrapped_resolver\n\nclass CustomMutation(Mutation):\nclass Meta:\n    abstract = True\n\n\n@classmethod\ndef __init_subclass_with_meta__(cls, resolver=None, **options):\n\n    if not resolver:\n        mutate = getattr(cls, 'mutate', None)\n        assert mutate, 'All mutations must define a mutate method in it'\n        resolver = get_unbound_function(mutate)\n        resolver = wrap_resolver(cls, resolver)\n\n    super(CustomMutation, cls).__init_subclass_with_meta__(resolver, **options)\n\n    cls._meta.fields['errors'] = (Field(String, name='errors'))\n\n```\nThen you use CustomMutation as class that all your Mutations will subclass. This wraps the resolver and catches any exceptions. In my own implementation I have a custom Exception class that i'm looking for. But thats up for you to decide. what type of errors do you expect to get via queries?. You can also upload to something like aws's s3 and send the url back . When I want to cache I usually do it from the resolver level\n```python\nfrom django.core.cache import cache\nclass MyType(ObjectType):\n    display_label = String()\ndef resolve_display_label(self, info, **args):\n    cache_key = \"some_unique_key_based_on_object\"\n    display_label = cache.get(cache_key)\n\n    if display_label is not None:\n        return display_label\n\n    display_label  = _do_logic_to_get_display_label_\n\n    cache.set(cache_key, display_label  , 30)  # 30 second timeout\n\n    return display_label\n\n```\nI know you didn't ask about django in particular but I'm sure there's alternatives that do the same thing.\nThis is one option I'm sure other people might have other ways of doing this. As for 1. you can create your own resolve_xxx method that would override the resolver generated by graphene_django. You might lose the free filters provided byDjangoFilterConnectionField, not 100% about this you'll have to check yourself\nfor 2 you could generate the json and upload it from the resolver, but then if you want to avoid any trafic hitting the server you'll have to do the logic to grab it from your frontend client. . Thanks I just changed this!\n. ",
    "Vitiell0": "I arrived here by Google first but ultimately found the total_count implementation at this thread easier to follow and use: https://github.com/graphql-python/graphene-django/issues/162\n```\nfrom graphene import Int\nclass ProductNode(DjangoObjectType):\n    class Meta:\n        model = Product\n        filter_fields = {\n            'name': ['exact', 'icontains', 'istartswith'],\n        }\n        interfaces = (relay.Node, )\n@classmethod\ndef get_connection(cls):\n    class CountableConnection(relay.Connection):\n        total_count = Int()\n\n        class Meta:\n            name = '{}Connection'.format(cls._meta.name)\n            node = cls\n\n        @staticmethod  # Redundant since Graphene kinda does this automatically for all resolve_ methods.\n        def resolve_total_count(root, args, context, info):\n            return root.length\n\n    return CountableConnection\n\n```. ",
    "scotmatson": "@Vitiell0 This worked well for me. However I had to modify how the resolver was working since it was crashing my test server on cases >100K records while attempting to count the edges.\nI ended up just using a SQLA statement filtered with the current_user and returned with .count().. ",
    "rattrayalex": "Just documenting it is probably fine :-) \nI'll submit a PR if I can...\n. I also hit this\n. When I tried changing AbstractType to ObjectType and open /graphql, I get this error message: \n{\n  \"errors\": [\n    {\n      \"message\": \"Query fields must be a mapping (dict / OrderedDict) with field names as keys or a function which returns such a mapping.\"\n    }\n  ]\n}\n. I resolved by changing class Query(cookbook.ingredients.Query): to class Query(cookbook.ingredients.Query, graphene.ObjectType): in the top-level schema. \nThat is, I had my top-level Query object inherit from graphene.ObjectType in addition to the app-specific schema Query objects\n. Ah, yes it is a dup. Apologies. \n. ",
    "dfee": "I believe this should be re-opened. It does not work in v1.2.\nAs a workaround, I'm currently using:\nclass ActionVarietyEnum(Enum):\n    join = 'join'\nand ...\nvariety = Column(\n        # Because graphql barfs on an actual enum value in the SQLA model.\n        ChoiceType([(v.name, v.value) for v in ActionVarietyEnum]),\n        nullable=False,\n    ). Perhaps this should be re-opened in graphene-sqlalchemy though. What do you think @syrusakbary . @philiptzou ping.. @philiptzou I think I might've run into this same issue, and was wondering if you were still attempting to merge this code.. (I shared an implementation on https://github.com/graphql-python/graphene-django/issues/79#issuecomment-306583068, but it might make more sense here\u2026)\nAttached is a version of ACLMiddleware I'm experimenting with.\nNote that my implementation has:\n get_principals returns principals (i.e. ['group:Admin', 'user:1234'])\n permits is a function that returns True or False with arguments (resource typically an instance of the model, principals as above, permission such as 'edit').\nThose implementation details aren't Django specific, but I think this problem is more general than the Django, and this is where the conversation is happening.\nAs for constraints from previous comments:\n1) this doesn't support permissions per field (though Meta could pretty easily be extended to support that),\n2) when querying node, we don't (can't?) get access to the ObjectType so we have to re-implement the get_node method on ObjectType classes.\n```python\nclass ACLMiddleware:\n    def resolve(self, next, root, args, context, info):\n        result = next(root, args, context, info)\n        graphene_type = getattr(info.return_type, 'graphene_type', None)\n        if not isinstance(graphene_type, SQLAlchemyObjectTypeMeta):\n            return result\n    permission = getattr(graphene_type._meta, 'permission', None)\n    if not permission:\n        return result\n\n    authenticated_user = context.get('authenticated_user', None)\n    principals = _User.get_principals(\n        context['session'],\n        authenticated_user,\n    )\n    return result if permits(result.value, principals, permission) else None\n\n``. One consequence of the approach I took above is that edge nodes that a user doesn't have access to will be returned asNone`.\nI.e.\njson\n{\n  \"data\": {\n    \"node\": {\n      \"id\": \"VXNlcjp5QnJWTXd6bVV0SFRVM245MmRuN3M1\",\n      \"memberships\": {\n        \"totalCount\": 2,\n        \"edges\": [\n          {\n            \"node\": null\n          },\n          {\n            \"node\": null\n          }\n        ]\n      }\n    }\n  }\n}. There is continued activity here, but after working heavily with graphene over the last few months, it seems like the right way to do this is to use middleware.\nIf you want permissions on your models (ObjectTypes) then why not just subclass ObjectTypeOptions and ObjectType (specifically __init_subclass_with_meta__) and add that as an attribute? Then you'll just have to watch for those objects to come by in middleware (usually watching on info.return_type.graphene_type.\nOr for a more complex authorization architecture, don't define permissions as strings, but add a callable (class, function, or instance \u2013 that defines __call__) that receives root and info (which contains your context) and make determinations there.\nFor an example, see this: https://github.com/graphql-python/graphene/blob/master/graphene/tests/issues/test_425.py. @ProjectCheshire I was actually responding to the top and hadn't read all the way down. Anyways, yeah, you could definitely generate a dynamic schema per user. That's a creative idea.\nBut no, that'd be entirely different. You're going to have a bit more code overhead on your part, but it's definitely doable. You'd likely want to cache the Query, Mutation, Subscription (root types) per user (perhaps using pickle), as it'd become pretty expensive to re-generate it on each request.\nFunny enough, the codebase I've been writing tests on to release actually does something very similar to generating dynamic schemas. Take a look at the abstract-factory pattern for software engineering. You'll ultimately create Factory classes that generate the graphene.ObjectTypes / InputObjectTypes that you'll need and supply those to a schema on demand.\nedit: just checked, and indeed schemas are not pickleable. It errors out because the actual __Schema uses lambdas which are not pickleable.. @hballard checking it out. But wow, this was one of the major things holding me back.. I'm about to start digging into subscription support probably tomorrow, but I'm looking at the code here (graphql-python test code). Here's a very simple gist of how to use subscriptions with graphene.\nIn a nutshell, it's probably easiest to return an rx.Observable using the pattern in the implementation above, though returning an AsyncIterator is also allowed. rx is a dependency of graphene anyway, meaning that it's not additional requirement you'll need to install, and it works on py2 and py3.\nAs you're probably using this for a web view, you'll actually want to save that subscriber and store it in a dict so a user can unsubscribe from it in the future. And, you'll probably also want to use websockets, or socket.io, etc. so you can actually push the subscription data out instead of appending it to a list as I've done on that same line.. @japrogramer I honestly haven't used Django since 1.4 (about 6 years ago), so I don't have too much to offer about specifics.\nHowever, my hunch is that Django's signals concept and the rx concept are pretty similar in theory, but quite different in implementation. You'll probably need some glue to connect the rx.Observable object and the Django signal.\nI did notice in your code that you're defining class MyObserver. If I'm imagining  correctly, that you lifted that from the tests here I'd point out two things:\n1) you probably don't need to define a class **\n2) the test code isn't even using that class. It should be dropped from the file.\n** see this note from the rxpy docs:\n\nMost of the time you will not want to go through the verbosity of implementing your own Observer. You can instead pass 1 to 3 lambda arguments to subscribe() specifying the on_next, on_complete, and on_error actions.\n\n```python\nfrom rx import Observable\nsource = Observable.from_([\"Alpha\", \"Beta\", \"Gamma\", \"Delta\", \"Epsilon\"])\nsource.subscribe(on_next=lambda value: print(\"Received {0}\".format(value)),\n                 on_completed=lambda: print(\"Done!\"),\n                 on_error=lambda error: print(\"Error Occurred: {0}\".format(error))\n                 )\n```. For what it's worth, when i've run into this problem it had nothing to do with multiple schemas with the same name. Rather, I was bungling a model name and a schema name. I'm using SQLAlchemy, but this might provide some insight (notice how I'm importing the model with an underscore):\n```\nexample.py\nfrom .models import Message as _Message\nfrom .graphql import Message\n```. So to confirm, the recommend approach to circular references is to import the referenced (or, related) ObjectType after its needed:\n```\na.py\nclass A(graphene.ObjectType):\n     name = graphene.String()\n     to_b = graphene.Field(lambda: B)\nfrom .b import B\n```\n```\nb.py\nfrom .post_type import Post\nclass B(graphene.ObjectType):\n     name = graphene.String()\n     to_b = graphene.Field(lambda: A)\nfrom .a import A\n```\n```\nschema.py\nfrom .a import A\nfrom .b import B\nclass Query(graphene.ObjectType):\n     get_a = graphene.Field(A)\n     get_b = graphene.Field(B)\nschema = graphene.Schema(query=Query)\n```\nThe other alternative I'm aware of is the method you mentioned here using graphene.LazyType.\nI can't seem to find it, but why was support for string references dropped?\nThanks for your help.. Fortunately I came across this. Pinning to master works.. I'm a little bit closer. Getting the InputObjectType from the schema, and using create_container gives something a bit more useful (a fully structured InputObjectType):\nMyIOT = schema.get_type('MyIOT')\nMyIOT.create_container({'my_field': 'asdf'})\nHowever, with a more complex example:\n```\nclass ChildIOT(graphene.InputObjectType):\n    nested_field = graphene.String()\n@property\ndef invert_nested(self):\n    return self.nested_field[::-1]\n\nclass ParentIOT(graphene.InputObjectType):\n    root_field = graphene.String()\n    child_field = graphene.Field(ChildIOT)\n... create schema, etc.\nFullParentIOT = schema.get_type('ParentIOT')  # is this actually called \"mounted\"?\nfp_iot = FullParentIOT.create_container({\n    'root_field': 'i am root',\n    'child_field': {'nested_field': 'i am nested'},\n})\nassert type(fp_iot.child_field) == dict  # unfortunately, this is not a hydrated / full ChildIOT instance!\nfp_iot.child_field.invert_nested  # of course, we can't access ChildIOT methods on a dict instance.\n```\nSo, how do I build a complex InputObjectType? Do I need to manually build the subcomponents and then inject them?. Here's the answer (look at synthesize_input_container):\n```python\nimport graphene\ndef resolve_type_heirarchy(obj):\n    if isinstance(obj, graphene.Field):\n        nested_type = obj.type\n        type_ = graphene.Field\n    elif isinstance(obj, graphene.InputField):\n        nested_type = obj.type\n        type_ = graphene.InputField\n    elif isinstance(obj, graphene.List):\n        nested_type = obj.of_type\n        type_ = graphene.List\n    elif isinstance(obj, graphene.NonNull):\n        nested_type = obj.of_type\n        type_ = graphene.NonNull\n    else:\n        return (obj,)\nreturn (type_, *resolve_type_heirarchy(nested_type))\n\ndef resolve_leaf_type(obj):\n    return resolve_type_heirarchy(obj)[-1]\ndef is_collection(obj):\n    return graphene.List in resolve_type_heirarchy(obj)\ndef synthesize_input_container(input_object_type_cls, data):\n    # pylint: disable=protected-access\n    for field_name, value in data.items():\n        field = input_object_type_cls._meta.fields[field_name]\n        if is_collection(field):\n            items = []\n            for item in value:\n                leaf_type = resolve_leaf_type(field)\n                if issubclass(leaf_type, graphene.InputObjectType):\n                    item = synthesize_input_container(leaf_type, item)\n                items.append(item)\n            data[field_name] = items\n        else:\n            if issubclass(field.type, graphene.InputObjectType):\n                data[field_name] = synthesize_input_container(field.type, value)\nreturn input_object_type_cls._meta.container(data)\n\n```\nfor use like:\n```python\ndef test_synthesize_input_container():\n    class RelatedInput(graphene.InputObjectType):\n        id = graphene.ID()\nclass Input(graphene.InputObjectType):\n    id = graphene.ID()\n    ids = graphene.List(graphene.NonNull(graphene.ID))\n    related = RelatedInput()\n    relateds = graphene.List(graphene.NonNull(RelatedInput))\n\ninput_raw = {\n    'id': 'input_id_1',\n    'ids': ['input_id_2',],\n    'related': {'id': 'related_input_id_1'},\n    'relateds': [{'id': 'related_input_id_2'}],\n}\n\ninput_container = synthesize_input_container(Input, input_raw)\n\nassert isinstance(input_container, Input)\nassert input_container.id == input_raw['id']\n\nassert isinstance(input_container.ids, list)\nassert len(input_container.ids) == 1\nassert input_container.ids[0] == input_raw['ids'][0]\n\nassert isinstance(input_container.related, RelatedInput)\nassert input_container.related.id == input_raw['related']['id']\n\nassert isinstance(input_container.relateds, list)\nassert len(input_container.relateds) == 1\nassert isinstance(input_container.relateds[0], RelatedInput)\nassert input_container.relateds[0].id == input_raw['relateds'][0]['id']\n\n``. You can access all known types viaschema.get_type`. For instance:\npython\nSignupMutation = schema.get_type('SingupMutation')\nprint('{}.{}'.format(SignupMutation.__module__, SignupMutation.__qualname__). Just wanted to leave a note for the future, this is the case for graphene.Enum as well.. For what it's worth, I'm in the process of building a package (with the intent of open sourcing) that takes care of a bunch of the boilerplate. There are a handful of constraints in it, inherent due to the structure of graphene. Search for issues related to my name, and you'll get a clue as to what those constraints are.\nI've put a couple weeks into it, but the goal is to get it out in the next few days. Outwardly, it closely resembles the API of graph.cool.. @SpaceK33z I'm actually still working on it. It's pretty much an identical clone of graph.cool's api.\nIt has query / mutation / subscription support, but is currently hung up on a couple issues I'm sorting through \u2013 largely speaking, that's graphene (python) / graphql naming.\n(p.s. it's currently sitting at something like 7500 lines of code with about 750 tests).. You're not missing anything. As you can see here it's just syntactic sugar for doing what you've done above.. @wesdyoung alternatively, you can just construct the ObjectType as any other object type and add it to your mutation using graphene.Field(). the Mutation wrapper simply creates an InputObjectType from the args and does just that.. It might not be the right forum to ask this, but as I'm a member, and already a contributor of aiohttp-graphql, should I move https://github.com/dfee/graphql-ws-next into this organization too? @Cito @syrusakbary ?. @ProjectCheshire :) devin@devinfee.com. ",
    "danielfarrell": "That PR seems to address this issue for me, and I've got it working locally.  If there should be anything else on there, let me know.\n. Dangit, how was I all over the codebase yesterday and didn't see with_context.  Ha, I'll close the PR.\n. Should be handled using the with_context decorator.\n. And I did just confirm that if I make a new Field on query that returns AnonymousUserType that it then works on the interface.\n. I do register it with the schema, so that isn't the issue.\n. Sure, it's definitely not there, even with a register:\n```\nschema {\n  query: Query\n  mutation: Mutation\n}\ntype CartItemType {\n  id: ID\n  user: UserType\n  sessionKey: String\n  promotionCode: PromotionCodeType\n  ordered: Boolean!\n  createdDate: DateTime\n  updatedDate: DateTime\n  order: [OrderType]\n}\ntype CategoryFeatureOptionType {\n  id: ID\n  productCategoryFeature: CategoryFeatureType\n  name: String\n  image: String\n  icon: String\n  lastUpdate: DateTime\n  created: DateTime\n}\ntype CategoryFeatureType {\n  options: [CategoryFeatureOptionType]\n  id: ID\n  productCategory: CategoryType\n  name: String\n  lastUpdate: DateTime\n  created: DateTime\n}\ntype CategoryType {\n  features: [CategoryFeatureType]\n  id: ID\n  name: String\n  slug: String\n  lastUpdate: DateTime\n  created: DateTime\n  product: [ProductType]\n}\ninterface Customer {\n  id: Int\n  email: String\n  name: String\n  firstName: String\n  lastName: String\n  phone: String\n  receiveNotifications: Boolean\n  receiveUpdateEmails: Boolean\n  shippingDestinations: [ShippingDestinationType]\n  paymentMethods: [PaymentMethodType]\n}\nscalar DateTime\ntype FeatureType {\n  id: ID\n  name: String\n  image: String\n  primaryPreviewImage: String\n  secondaryPreviewImage: String\n  baseMarkup: Float\n  weight: Float\n  burnColor: String\n  burnedColor: String\n  orderitem: [OrderItemType]\n}\ntype GuestRegisterType {\n  ok: Boolean\n}\ntype ItemStatusType {\n  id: ID\n  name: String\n}\nscalar JSONString\ntype LoginType {\n  ok: Boolean\n  token: String\n  user: UserType\n}\ntype Mutation {\n  login(email: String!, password: String!): LoginType\n  userCreate(password1: String!, password2: String!, email: String!, firstName: String!, lastName: String!, phone: String!, authenticate: Boolean): UserCreateType\n  userUpdate(email: String!, firstName: String!, lastName: String!, phone: String!, receiveUpdateEmails: Boolean): UserUpdateType\n  passwordChange(oldPassword: String!, password1: String!, password2: String!): PasswordChangeType\n  userNotificiations(receiveNotifications: Boolean, receiveUpdateEmails: Boolean): UserNotificationsType\n  guestRegister(email: String!, password1: String!, password2: String!): GuestRegisterType\n  productCustomizeInvite(id: ID!, email: String!): ProductCustomizeInviteType\n  productCustomizedUpdate(id: ID!, customizedProduct: JSONString): ProductCustomizedUpdateType\n}\ntype OrderItemType {\n  id: ID\n  order: OrderType\n  product: ProductCustomizedType\n  featureOptions: [FeatureType]\n  engraveFront: String\n  engraveBack: String\n  quantity: Int\n  price: Float\n  lastUpdate: DateTime\n  created: DateTime\n  orderitem: [OrderItemType]\n}\ntype OrderStatusHistoryType {\n  id: ID\n  order: OrderType\n  user: UserType\n  created: DateTime\n}\ntype OrderStatusType {\n  id: ID\n  name: String\n}\ntype OrderType {\n  orderNo: String\n  status: String\n  dateCreated: DateTime\n  dateShipped: DateTime\n  dateDelivered: DateTime\n  id: ID\n  customer: UserType\n  cart: CartItemType\n  shippingDestination: ShippingDestinationType\n  paymentMethod: PaymentMethodType\n  promotionCode: PromotionCodeType\n  totalProduct: Float\n  totalShipping: Float\n  totalTax: Float\n  totalDiscount: Float\n  total: Float\n  charge: PaymentChargeType\n  chargeDate: DateTime\n  totalCharged: Float\n  totalRefunded: Float\n  pdfFile: String\n  statusHistories: [OrderStatusHistoryType]\n  items: [OrderItemType]\n}\ntype PageType {\n  templates: [TemplateType]\n  id: ID\n  type: String\n  title: String\n  summary: String\n  product: [ProductType]\n}\ntype PasswordChangeType {\n  ok: Boolean\n}\ntype PaymentChargeType {\n  id: ID\n  user: UserType\n  sessionKey: String\n  card: PaymentMethodType\n  stripeTokenId: String\n  stripeChargeId: String\n  amount: Float\n  amountRefunded: Float\n  description: String\n  status: String\n  captured: Boolean!\n  paid: Boolean!\n  disputed: Boolean!\n  refunded: Boolean!\n  failureCode: String\n  failureMessage: String\n  createdBy: UserType\n  lastUpdate: DateTime\n  created: DateTime\n  order: [OrderType]\n}\ntype PaymentMethodType {\n  default: Boolean\n  id: ID\n  user: UserType\n  stripeCardId: String\n  cardType: String\n  nameOnCard: String\n  expMonth: String\n  expYear: String\n  billingZip: String\n  last4: String\n  order: [OrderType]\n  userDefaults: [UserType]\n  paymentcharge: [PaymentChargeType]\n}\ntype PinType {\n  id: ID\n  name: String\n  icon: String\n  iconClass: String\n  image: String\n}\ntype ProductCustomizeInviteType {\n  ok: Boolean\n}\ntype ProductCustomizedType {\n  id: ID\n  product: ProductType\n  user: UserType\n  sessionKey: String\n  customizedProduct: JSONString\n  cartDisplay: JSONString\n  markup: Float\n  addedWeight: Float\n  renderedFront: String\n  renderedBack: String\n  orderitem: [OrderItemType]\n}\ntype ProductCustomizedUpdateType {\n  ok: Boolean\n  productCustomized: ProductCustomizedType\n}\ntype ProductOverlayShapeType {\n  id: ID\n  shape: String\n  svg: String\n  coordinateX: Int\n  coordinateY: Int\n  dimensionsX: Float\n  dimensionsY: Float\n  pixelWidth: Int\n  pixelHeight: Int\n  zIndex: Int\n  lastUpdate: DateTime\n  created: DateTime\n  product: [ProductType]\n}\ntype ProductType {\n  pages: [PageType]\n  overlay: ProductOverlayShapeType\n  id: ID\n  category: CategoryType\n  sku: String\n  name: String\n  description: String\n  thumbnailImage: String\n  maxLines: Int\n  textStartHeight: Float\n  marginTop: Int\n  marginRight: Int\n  marginBottom: Int\n  marginLeft: Int\n  yOffset: Int\n  dimensionsX: Int\n  dimensionsY: Int\n  previewDimensionsX: Int\n  previewDimensionsY: Int\n  maxContentWidth: Int\n  basePrice: Float\n  baseWeight: Float\n  lastUpdate: DateTime\n  created: DateTime\n  productcustomized: [ProductCustomizedType]\n  product: [ProductType]\n}\ntype PromotionCodeType {\n  id: ID\n  title: String\n  description: String\n  code: String\n  start: DateTime\n  end: DateTime\n  active: Boolean!\n  discountPercent: Float\n  discountAmount: Float\n  freeShipping: Boolean!\n  numberOfUses: Int\n  numberOfUsesRemaining: Int\n  cart: [CartItemType]\n  order: [OrderType]\n}\ntype Query {\n  me: Customer\n  orders(lastUpdateDate: DateTime, status: String, created: String): [OrderType]\n  product(id: ID!): ProductType\n  productCustomized(id: ID!): ProductCustomizedType\n  products: [ProductType]\n  categories: [CategoryType]\n  features: [FeatureType]\n  orderStatuses: [OrderStatusType]\n  itemStatuses: [ItemStatusType]\n  symbols: [SymbolType]\n  separators: [SeparatorType]\n  styles: [StyleType]\n  pins: [PinType]\n}\ntype SeparatorType {\n  id: ID\n  name: String\n  character: String\n  image: String\n}\ntype ShippingDestinationType {\n  id: ID\n  user: UserType\n  recipient: String\n  company: String\n  address1: String\n  address2: String\n  postalCode: String\n  city: String\n  state: String\n  country: String\n  order: [OrderType]\n  userDefaults: [UserType]\n}\ntype StyleType {\n  id: ID\n  name: String\n  marginTop: Int\n  marginRight: Int\n  marginBottom: Int\n  marginLeft: Int\n  styleClass: String\n  iconClass: String\n  symbolImage: String\n  editable: Boolean!\n  symbol: [SymbolType]\n}\ntype SymbolType {\n  id: ID\n  style: StyleType\n  name: String\n  iconClass: String\n  image: String\n}\ntype TemplateType {\n  id: ID\n  page: PageType\n  name: String\n  description: String\n  details: JSONString\n}\ntype UserCreateType {\n  ok: Boolean\n  user: UserType\n}\ntype UserNotificationsType {\n  ok: Boolean\n}\ntype UserType implements Customer {\n  id: Int\n  email: String\n  name: String\n  firstName: String\n  lastName: String\n  phone: String\n  receiveNotifications: Boolean\n  receiveUpdateEmails: Boolean\n  shippingDestinations: [ShippingDestinationType]\n  paymentMethods: [PaymentMethodType]\n}\ntype UserUpdateType {\n  ok: Boolean\n  user: UserType\n}\n``\n. When I throw aanonymous = Field(AnonymousUserType)in the Query then it shows up.\n. Unfortunately AnonymousUser isn't a real django model and then gives me aProvided model in  is not a Django model` error if it inherits from that.  It works fine with the workaround of it being in another field, which is strange.\n. Doesn't look like DjangoObjectType's meta class supports that:\nTypeError: 'class Meta' got invalid attribute(s): interfaces\n. Hey @alexche8, here is a gist of the code I used to make it work: https://gist.github.com/danielfarrell/87561b8930d917f339aaff0ea8245231. ",
    "FrankSalad": "According to the docs: http://docs.graphene-python.org/en/latest/types/objecttypes/\nBy default resolvers take the arguments args, context and info.\nFollowed by\ndef resolve_reverse(self, info, word):\n        return word[::-1]\nAs you can see, the example resolver method only has the self, info and word params. There was no usage of args or context at all, and no mention of what I should actually find passed in info. I'm still digging around to try to understand what I should expect in these params. This is confusing and unpythonic. The expectation around function params is that if they're positional, their actual names don't matter.  I had to find this issue to understand what you guys were even trying to do here.  If your intent was to create a function that ignores some of its arguments, adding **kwargs to the end to do so explicitly is the right way. . ",
    "vinigfer": "In case anyone is also having troubles on how to access the context, after an endless effort/search I found on this link:\nhttp://docs.graphene-python.org/projects/django/en/latest/authorization/\nthat I can access context like this:\nif not info.context.user.is_authenticated():\nHope this helps anyone. ",
    "alexche8": "Hello @danielfarrell ! Can you please provide your full working example for now? I still didn't get how to implement interfaces with django graphene. @danielfarrell , Thank you very much for this!. Got it, thanks.. ",
    "iawia002": "if i change OneToOneField to ForeignKey, it works fine\n. Django version 1.9.2, graphene (0.7.3)\n. thanks\n. ",
    "HelloYie": "+1\n. - graphene==0.9.1\n- Django==1.9.6\nMy profile model:\n```\nfrom django.db import models\nfrom django.contrib.auth.models import User\nclass Profile(models.Model):\nuser = models.OneToOneField(\n    User,\n    verbose_name=u\"user\",\n    related_name=\"profile\",\n    null=False,\n    blank=False,\n)\nnickname = models.CharField(\n    max_length=20,\n    verbose_name=u'nickname',\n    null=True,\n    blank=True,\n)\n\nclass Meta:\n    verbose_name = u'personal info'\n    verbose_name_plural = u'personal info'\n\n```\nMy schema:\n```\nimport graphene\nfrom graphene import relay\nfrom graphene.contrib.django import DjangoNode\nfrom django.contrib.auth.models import User as UserModel\nfrom graphene.contrib.django.filter import DjangoFilterConnectionField\nfrom graphene.contrib.django.debug import DjangoDebugPlugin\nfrom apps.profile.models import Profile as ProfileModel\nclass User(DjangoNode):\n    class Meta:\n        model = UserModel\nclass Profile(DjangoNode):\n    class Meta:\n        model = ProfileModel\nschema = graphene.Schema(name='schema', plugins=[DjangoDebugPlugin()])\nclass Query(graphene.ObjectType):\n    all_users = DjangoFilterConnectionField(User)\n    all_profile = DjangoFilterConnectionField(Profile)\n    user = relay.NodeField(User)\n    profile = relay.NodeField(Profile)\n    node = relay.NodeField()\n    viewer = graphene.Field('self')\ndef resolve_viewer(self, *args, **kwargs):\n    return self\n\nschema.query = Query\n```\nMy query:\n{\n  user(id:\"VXNlcjox\") {\n    id\n    profile {\n      edges {\n        node {\n          id\n        }\n      }\n    }\n  }\n}\nError log:\n{\n  \"errors\": [\n    {\n      \"message\": \"Resolved value from the connection field have to be iterable\",\n      \"locations\": [\n        {\n          \"column\": 5,\n          \"line\": 4\n        }\n      ]\n    }\n  ],\n  \"data\": {\n    \"user\": {\n      \"id\": \"VXNlcjox\",\n      \"profile\": null\n    }\n  }\n}\n. ",
    "dgouldin": "Inside sqlalchemy. It's an entire module of fields. Types listed in the docs starting here:\nhttp://docs.sqlalchemy.org/en/latest/dialects/postgresql.html#array-types\n. ARRAY, JSON, JSONB, HSTORE, ENUM, and UUID are IMO the most common postgres-specific types.\n. ",
    "tgdn": "TSVECTOR is probably important to mention here if full text search is needed. Not sure if an implementation is required but at least exclude the field by default as it would probably only used in the resolve method to search.\n. Not using graphene anymore, I figured that using NodeJS would be the best solution.\nFeel free to close this issue if @makmanalp 's answer is satisfactory.. ",
    "patvdleer": "Due a wrapper (for JSONB on Sqlite) I wrote (and stole/copied) I ran into the same error. Maybe this will help others.\n```python\nimport json\nfrom graphene import JSONString\nfrom graphene_sqlalchemy.converter import convert_sqlalchemy_type, get_column_doc, is_column_nullable\nfrom sqlalchemy import types, TypeDecorator\nfrom sqlalchemy.dialects.postgresql import JSONB\nfrom sqlalchemy.ext.compiler import compiles\nfrom sqlalchemy.sql import sqltypes\nfrom sqlalchemy.sql.functions import FunctionElement\nclass SqliteJsonElement(FunctionElement):\n    type = types.Text()\n    name = \"JsonElement\"\n@property\ndef astext(self):\n    return self\n\n@compiles(SqliteJsonElement)\ndef compileSqliteJsonElement(element, compiler, **kw):\n    return \"jsonExtract(%s)\" % compiler.process(element.clauses)\nclass SqliteJson(TypeDecorator):\n    impl = types.Text\ndef process_bind_param(self, value, dialect):\n    if isinstance(value, tuple) and len(value) == 1:\n        value = value[0]\n    return json.dumps(value or {})\n\ndef process_result_value(self, value, dialect):\n    if value is None:\n        return {}\n    return json.loads(value)\n\nclass comparator_factory(sqltypes.Concatenable.Comparator):\n    def __getitem__(self, other):\n        \"\"\"Get the value at a given key.\"\"\"\n        return SqliteJsonElement(self.expr, other)\n\nclass SqliteCompatiblePostgresOptimizedJson(TypeDecorator):\n    # See: http://docs.sqlalchemy.org/en/latest/core/custom_types.html\n    # impl = None\n    impl = types.JSON\ndef load_dialect_impl(self, dialect):\n    dialectTypeMap = {\n        'sqlite': SqliteJson,\n        'postgresql': JSONB\n    }\n\n    self.impl = dialect.type_descriptor(dialectTypeMap[dialect.name])\n    return self.impl\n\ndef process_bind_param(self, value, dialect):\n    return value\n\ndef process_result_value(self, value, dialect):\n    # Todo: refactor\n    if isinstance(value, (tuple, list)) and len(value) == 1:\n        value = value[0]\n    if isinstance(value, dict) and len(value.keys()) == 1 and \"meta\" in value.keys():\n        value = value[\"meta\"]\n    return value\n\n@property\ndef comparator_factory(self):\n    \"\"\"express comparison behavior in terms of the base type\"\"\"\n    return self.impl.comparator_factory\n\n@convert_sqlalchemy_type.register(SqliteCompatiblePostgresOptimizedJson)\ndef convert_json_to_string(type, column, registry=None):\n    return JSONString(description=get_column_doc(column), required=not(is_column_nullable(column)))\n```. ",
    "jkosir": "Wow, thanks for the quick fix! :+1: \n. ",
    "AdrielVelazquez": "@syrusakbary  All set!\n. @syrusakbary to_const is being used to convert Django choices to constant values. Django currently accepts any value for these Enums even if starting with integers. This also is the case with MySQL and Postgres. A starting integer wouldn't effect the current functionality of the dictionary being created (or rather the list created to guarantee unique type)\nI can add additional tests of Django models with choices getting translated correctly and choices unaffected?\n. ",
    "crucialfelix": "The example at the top doesn't work now because you cannot make an abstract subclass of graphene.relay.Connection. \nJust by importing this (not using it, just defining the class):\nclass CursorPaginatedConnection(graphene.relay.Connection):\n    @classmethod\n    def from_list(cls, queryset, args, context, info):\n        connection = connection_from_cursor_paginated(queryset, args, connection_type=cls, edge_type=cls.edge_type, pageinfo_type=graphene.relay.PageInfo)\n        connection.set_connection_data(queryset)\n        return connection\nraises:\nAssertionError: You have to provide a node in ConnectionMeta.Meta\nConnectionMeta does some error checking to ensure that it's subclasses are usable:\nhttps://github.com/graphql-python/graphene/blob/v1.2.0/graphene/relay/connection.py#L61\nI've been running into issues with these meta classes quite a bit when working with graphene. You cannot write an abstract subclass of DjangoObjectType for the same reason \u2014 the error checking scolds you. \nI guess these reusable things should be written as plain classes and then apply them as mixins. But then to actually use them we need to write factory methods to assemble a one off class and use it immediately.\n```\ncannot do this\nclients = connection.CursorPaginatedConnectionField(ClientNode)\nI will have to write a factory\nclients = make_paginated_connection(ClientNode)\n```. Similar approach but not as fully featured:\n```python\ndef field_selects_path(field, path):\n    if len(path) == 0:\n        return False\n    for subfield in field.selection_set.selections:\n        if subfield.name.value == path[0]:\n            if len(path) == 1:\n                return True\n            return field_selects_path(subfield, path[1:])\n    return False\ndef path_is_selected(info, path):\n    for field in info.field_asts:\n        if field.name.value == path[0]:\n            return field_selects_path(field, path[1:])\n    return False\ndef select_related(info, qs, path, select):\n    \"\"\"\n    @param info  {graphene.Info} ie the info at the end of: def resolve_thumb(agent, args, context, info):\n    @param qs {QuerySet}\n    @param path {str} - eg deals.edges.node.client\n    @param select {str} - The table to select eg 'client' or 'client__showingrequest'\n    \"\"\"\n    if path_is_selected(info, path.split('.')):\n        return qs.select_related(select)\n    return qs\n```\nUsage:\npython\nqs = select_related(info, qs, 'deals.edges.node.client', 'client'). This also broken in pre-2.0 releases. If you pip install:\ngraphene==1.4.1\ngraphene-django==1.3\n\nYou get:\ngraphene (1.4.1)\ngraphene-django (1.3)\ngraphql-core (2.0)\n\nAnd we get the mysterious deep error TypeError: resolve() takes exactly 6 arguments (4 given) because graphql-core 2 is not compatible with graphene\nThe solution is to explicitly add this to requirements:\ngraphql-core==1.1.0\n\n. ",
    "necnec": "@mjtamlyn you said you also added a resolver? \nCould you provide any working example with your custom paginator?. ",
    "ramusus": "@mjtamlyn could you please update your approach for latest\ngraphene==2.0.1\ngraphene-django==2.0.0\nthere is no such class as graphene.relay.connection.ConnectionMeta. ",
    "perrierism": "Ah. Note that if django-filter isn't installed graphene won't provide access to DjangoFilterConnectionField. check graphene.contrib.django.fields.DJANGO_FILTER_INSTALLED. (Closing)\n. ",
    "emekanw": "This issue is not fixed.\n\n. ",
    "ewdicus": "@syrusakbary The playground was working great a few days ago, but It's currently stuck loading. (I've left it open for several minutes with no change.) The output in the console is:\n\nI'm on Chrome 58.0.3029.81 (64-bit). ",
    "Kagandi": "I am having the same error and it happens inconsistently, sometimes I can run the same queries several times and everything is working and after some point it starts crashing.\nI noticed that it is only happening when I am sending multiply asynchronous fetch requests in the same time. \n. ",
    "nickhudkins": "This would be huge. Node makes it trivial thanks to the event loop and therefore process.nextTick() enabling this to have been built. Coming from writing Node graphql backends, I am terrified about performance because of the lack of DataLoader, but hoping things like select_related in django etc will help minimize this.\n. Has there been work done to resolve this? If not, I'd love to dive in and see if we can figure this out.. Have a look here: https://github.com/graphql-python/graphene-django/pull/58 This may be of use to you. @geohuz, if you are looking to protect the entire endpoint, you can just use standard request middleware to handle this, otherwise, have a look at the middleware arg that can be passed to GraphQLView.as_view\nand you can then write your own AuthorizationMiddleware like so:\nclass AuthorizationMiddleware():\n    def resolve(self, next, root, args, context, info):\n       # do whatever you need to to to context, or root or however you would like to handle auth\n        return next(root, args, context, info)\nSince this is not a graphene specific issue, I would encourage you to ask over on StackOverflow as well and close out this issue so the maintainers can tackle bugs / improvements.. Hey @barakcoh I was concerned about this as well. Personally, I am not sure that it actually impacts me as I protect data at the resolver level, since if I have defined it as a relayNode, I have explicitly asked to be able to resolve it through the node resolver. \nCan you elaborate, or provide an example of when you would want a node resolver to be protected, and not sub fields of said node? Is this mainly a concern of leaking data by being able to guess types / ids and construct node queries to find data?. @ekampf That sounds fantastic, This seems django specific to me, so I think we can probably close this and track in https://github.com/graphql-python/graphene-django/issues/79. This would certainly keep it from getting overly specific. Are you picturing user getting passed to is_authorized from context?. This sounds terrific then. Do you want to start on this, or I can and submit a PR? Either is fine with me \ud83d\udc4d . I am thinking that there would be two pieces: 1.) Provide a \"UserMiddleware\" that provides a hook to simply do whatever you need to get a user. The middleware would place that user on context, and the rest would be ensuring that object resolvers (if is_authorized is defined) and get_node would be respected, and otherwise return None.. hey @mleonard87 the reason this is happening is that ObjectTypes resolve object attributes, and what you have here is a dict with keys that are strings. \nIf from the request you can build a python object, you'll be in good shape.\nHave a look here: http://stackoverflow.com/a/15882054 as to one method of doing so.. ",
    "makmanalp": "I've been looking into this too and wondering, but it also does seem super backend specific to me. SQLAlchemy handles stuff like this with eager loading strategies to batch everything into a single query using joined loads and similar:\nhttp://docs.sqlalchemy.org/en/latest/orm/loading_relationships.html#using-loader-strategies-lazy-loading-eager-loading\n@nickhudkins / @bigblind How would the event loop help here? You could do it in parallel, but you're still spending the handshake / connection management / data serialization overhead of talking to the database server n times, which in all likelihood would be causing most of the slowness, not to mention spamming your db server with connections, which it may have a cap on. That would in effect mean that even though the client is doing the queries in parallel, since the db server only handles so many at a time, it degrades into being serial-ish.\n. ",
    "zry656565": "Is this issue solved now?. ",
    "ap1459777123": "Hi!\nAfter tracing some code in flask-graphql and refering to https://pypi.python.org/pypi/Flask-GraphQL, I found that GraphQL should take argument graphiql=True.\nSo app.py:30\nGraphQL(app, schema=schema, default_query=default_query)\nshould be\nGraphQL(app, schema=schema, default_query=default_query, graphiql=True)\nAnd the gui could be found at /graphql.\nAlso tested POST method /graphql with payload {\"query\":\"query{allEmployees{edges{node{id}}}}\"},\n was able to get the content set in database.py\nI would leave to dev team to close this issue in case I've done something wrong.\nLots of thanks for this project!\n. ",
    "PeteAndersen": "Does it work if you define everything as plain strings instead of using _('xxxxx')?\n. ",
    "olref": "No, I have the same issue\n. ",
    "glusa8": "Is this issue related to https://github.com/graphql-python/graphene/issues/290?\n. This was due to browser sync\n. ",
    "akira-dev": "It is not a graphene issue but a graphql-core issue.\nPull request link: https://github.com/graphql-python/graphql-core/pull/68\n. ",
    "insolite": "Looks like resolver should not be a coroutine. However it can return asyncio.Future which will be executed asynchronously. And of course Schema.execute should be called with return_promise=True to get promise and execute it in your asyncio event loop. I've modified your code a bit so now it returns OrderedDict([('recipes', [OrderedDict([('name', 'hello')])])]) as expected.\n``` python\nimport asyncio\nfrom graphql.execution.executors.asyncio import AsyncioExecutor\nimport graphene\nclass Recipe(graphene.ObjectType):\n    name = graphene.String()\nclass Query(graphene.ObjectType):\nrecipes = graphene.List(Recipe)\n\n@asyncio.coroutine\ndef async_resolve_recipes(self):\n    return [\n        Recipe(name='hello')\n    ]\n\n@graphene.resolve_only_args\ndef resolve_recipes(self):\n    return asyncio.async(self.async_resolve_recipes())\n\nschema = graphene.Schema(\n    query=Query,\n    executor=AsyncioExecutor()\n)\nexecuted_promise = schema.execute(\"\"\"\n    query {\n        recipes {\n            name\n        }\n    }\n\"\"\", return_promise=True)\nexecuted = asyncio.get_event_loop().run_until_complete(executed_promise)\nprint(executed.data)\n```\n. If someone is interested I've done some implementation for peewee-async package here. It should not be much different from graphene-django integration which I mostly relied on at the design stage. Initially I was doing that for my own needs, but now I am trying to provide generic maintaining. So if someone will make use of it or want to contribute, I would be glad to help.. ",
    "ivlevdenis": "https://gist.github.com/ivlevdenis/3fb0ede89650889cc9f62a77770e7156. Use cursor, and standard query args (first, after, and etc.). @un33k ok. Simple query.\n{\n  offers(first: 2) {\n    edges {\n      node {\n        id\n      }\n      cursor\n    }\n    pageInfo {\n      hasNextPage\n      hasPreviousPage\n      startCursor\n      endCursor\n    }\n  }\n}\nThis response with meta about cursor state:\n{\n  \"data\": {\n    \"offers\": {\n      \"edges\": [\n        {\n          \"node\": {\n            \"id\": \"T2ZmZXJPYmplY3Q6MjI0\"\n          },\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjA=\"\n        },\n        {\n          \"node\": {\n            \"id\": \"T2ZmZXJPYmplY3Q6OTc3\"\n          },\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjE=\"\n        }\n      ],\n      \"pageInfo\": {\n        \"hasNextPage\": true,\n        \"hasPreviousPage\": false,\n        \"startCursor\": \"YXJyYXljb25uZWN0aW9uOjA=\",\n        \"endCursor\": \"YXJyYXljb25uZWN0aW9uOjE=\"\n      }\n    }\n  }\n}\nFor next portion of offers need call this query:\n{\n  offers(first: 2, after: \"YXJyYXljb25uZWN0aW9uOjE=\") {\n    edges {\n      node {\n        id\n      }\n      cursor\n    }\n    pageInfo {\n      hasNextPage\n      hasPreviousPage\n      startCursor\n      endCursor\n    }\n  }\n}\nThis return\n{\n  \"data\": {\n    \"offers\": {\n      \"edges\": [\n        {\n          \"node\": {\n            \"id\": \"T2ZmZXJPYmplY3Q6MjA2Ng==\"\n          },\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjI=\"\n        },\n        {\n          \"node\": {\n            \"id\": \"T2ZmZXJPYmplY3Q6MjE4MQ==\"\n          },\n          \"cursor\": \"YXJyYXljb25uZWN0aW9uOjM=\"\n        }\n      ],\n      \"pageInfo\": {\n        \"hasNextPage\": true,\n        \"hasPreviousPage\": false,\n        \"startCursor\": \"YXJyYXljb25uZWN0aW9uOjI=\",\n        \"endCursor\": \"YXJyYXljb25uZWN0aW9uOjM=\"\n      }\n    }\n  }\n}\nhttp://graphql.org/learn/pagination/. @un33k for graphene+django this work \"from box\". It's tested and worked query's from real app.. ",
    "callsamleung": "@ivlevdenis helpful. \"inherit\" is very \"beautiful\" solutions, thank you so much.. ",
    "heyrict": "I'm using this resolve function to handle a list of orderBy.\n```python\n    def resolve_all_users(self, info, **kwargs):\n        orderBy = kwargs.get(\"orderBy\", None)\n    if orderBy:\n        return User.objects.order_by(*orderBy)\n    else:\n        return User.objects.all()\n\n```. @tricoder42 Thank you for your promising code!\nIs it possible to use Group instead of GraphQLSubscriptionStore to store queries (as sending to multiple channels in a group is optimized)?\nFor example:\n```python\nsubscribed_groups = {'User': set(), ...}\nsubscription_string = transform('subscription mysub on UserNode { ... }');\ndef on_message(message):\n    global subscribed_groups;\n    ...\n    subscription_string = 'sub-%s' % hash(message.content['payload'])\n    Group(subscription_string).add(reply_channel);\n    model_name = message.content['model']\n    subscribed_groups[model_name].add(subscription_string);\n    ...\n@receiver(post_save, sender=model)\ndef send_model_update(...):\n    global subscribed_groups;\n    for group_name in subscribed_groups[model.name]:\n        Group(group_name).send(...)\n```. @prokher actually I'm using @tricoder42 's implementation for graphql subscription in production (with minor modifications as I'm using python3.5 and redis backend) , and it turns out working perfectly (and much cleaner than graphene-django-subscriptions).\nMaking bridges between two packages may be time consuming, but if you want to use subscription right now, I recommend you to simply migrate the code to your project, as it won't be much work.. What do you think about not sending useless data back to the client?\nActually, I am having lots of subscription objects with {'subscriptionName': None}.\n```python\n    def _send_result(self, id, result):\n        # Don't send results if no useful data is generated\n        errors = result.errors\n        if not errors:\n            if not isinstance(result.data, dict):\n                return\n            if sum(map(lambda x: x != None, result.data.values())) == 0:\n                return\n    self.send({\n        'type':\n        'websocket.send',\n        'text':\n        json.dumps({\n            'id': id,\n            'type': 'data',\n            'payload': {\n                'data': result.data,\n                'errors': list(map(str, errors)) if errors else None,\n            }\n        })\n    })\n\n```. ",
    "nikolaik": "We are seeing the Schema must contain unique named types but contains multiple types named {} in type_map_reducer a lot running with the Django dev server. Testing with python manage.py runserver --nothreading now.\n. ",
    "czchen": "@Globegitter Thanks for the hint.\n. ",
    "alehl": "@czchen something like this? \n```\n      class Inner(CmsObjectType):\n         image_asset = GrapheneHelper.string_field('image_asset')\n  class Outer(CmsObjectType):\n    height = GrapheneHelper.int_field(Inner('height'))\n    width = GrapheneHelper.int_field(Inner('width')).\n",
    "conradev": "Sorry for all of the noise, I had to make this PR compatible with all of the supported versions of Django \u2013 tests should now all pass!\n. @syrusakbary, @AlecAivazis, thoughts?\n. Awesome, let me know what I need to do to get this merged!\n. ",
    "AlecAivazis": "This seems reasonable to me as it nicely \"patches\" the singledispatch handler that is used to convert fields. Also the build for python3.5 has a bug in it so I'm pretty sure we can ignore the failing build on travis.\n. Unforunately, i'm unable to merge PRs so we'll have to wait for @syrusakbary. Also, I know he's working on a rather large refactor of the internals so it would be best for him to verify that this will still be applicable in 1.0 before we consider it \"done\". \n. This is the only part that seems to have drastically changed - I did some investigating and it looks like the Executor uses an OrderedDict by default now so I don't think I needed to specify it explicitly.\n. Ah, got it. I removed that logic - still having trouble with the tests, though. I'll give it another shot later today\n. ",
    "saharhashai": "Happens here as well.\n. ",
    "joshourisman": "It appears that this fix may have caused a new bug with Relay mutations. Specifically, when I just updated my graphene install to 1.x (1.1.3, specifically), a mutation that had previously been working with a JSONString() in the input started failing. I was eventually able to determine that ClientIDMutation.mutate_and_get_payload() expects the input value to be a string, not an object.\nI was able to resolve the issue and get my mutation working again by simply changing the JSONString.parse_value() method back to it's original form:\nclass JSONString(graphene.types.json.JSONString):\n    @staticmethod\n    def parse_value(value):\n        return json.dumps(value). ",
    "pcraciunoiu": "Currently, there is no way for aDjangoObjectType to have a DjangoFilterConnectionField that references itself unless this issue is fixed.\nOr is there another way and I am missing it?\nE.g. This does not work: \nclass User(DjangoObjectType):\n    followers = DjangoFilterConnectionField(lambda: User)\nCould not import 'example.schema.schema' for Graphene setting 'SCHEMA'. AttributeError: 'function' object has no attribute '_meta'.. ",
    "impguard": "Fantastic! And I see lots of changes have been made since I first played around here. I'll take a look at all the cool work you've done! Thanks!\n. ",
    "agilgur5": "It doesn't seem like there's a milestone or otherwise list of issues + features set for 1.0 (aside from the respective branch). I think that would be really good to have to promote + make contributions simpler, as well as to give a roadmap of things to expect for potential users.\nPlanning on integrating GraphQL with our Django app and I've been watching Graphene's progress for a while now as it makes that daunting task seem simpler and simpler with each release (props on the great work so far!). Some of the biggest concerns I see with this project are the lack of transparency and number of core contributors/maintainers -- having a more defined upgrading process may help alleviate both. Hoping to have a great experience with this library soon :)\n. ",
    "erydo": "Additionally, the Relay Connection specification supports that this should be allowed:\n\nAn \u201cEdge Type\u201d must contain a field called node. This field must return either a Scalar, Enum, Object, Interface, Union, or a Non\u2010Null wrapper around one of those types. Notably, this field cannot return a list.\n(\u2026) Relay can perform certain optimizations if this field returns an object that implements Node, however, this is not a strict requirement for use of Relay.\n\nA quick look at the source (https://github.com/graphql-python/graphene/blob/master/graphene/relay/types.py#L80) makes me believe that those assert is_node(node) statements should just be removed entirely\u2026at a first glance nothing appears to actually depend on those types implementing Node and so that check is erroneously restrictive.\n. ",
    "jnak": "I would happily to send you a pull request with it fixed but it seems to be handled by travis, I don't have access to the logs to see what's going on\n. Wow! That's much more that I expected!\nThat's really awesome. Thanks for implementing this and sharing it here. I'm going to be toying with the Gevent executer next week and we'll report back. If everything works fine, I'll definitely try to send a PR to put this in the doc. Hopefully, in the meantime, people interested in this topic will find this answer.\nOn a related note,  since Gevent uses an event loop, it is probably feasible to implement something similar to Dataloader in the JS world. This is especially useful for the 1+N^2 fan out problem. Have you heard of anyone interested in doing this as well?\n. ",
    "nirshubz": "Got you. Thanks for the answer @syrusakbary \nOur UUID is generated by an external system, and is completely random, so it would be kind of hard to follow that logic.\nDo you think it would be possible to somehow figure out the mapping from the query when using Django? Any other suggestions?   \nThanks :)\n. ",
    "nlhkh": "I think I still see this problem with the latest version. I have to explicitly specify the related_name.\n. Do you have an example? From the doc of graphene-django, there is nowhere that we have to construct the query manually.\nOn Nov 10, 2016, 12:38 AM +0200, Yacine Filali notifications@github.com, wrote:\n\nAlso, cache all the things, in memory preferably, per request at the very least.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub (https://github.com/graphql-python/graphene/issues/358#issuecomment-259547357), or mute the thread (https://github.com/notifications/unsubscribe-auth/ADTJWKlZ6Xfi2UXZGPuRGJy8qKmnncsDks5q8kuBgaJpZM4KuD8A).\n. Or sorry, I missed your included link.\n\nOn Nov 10, 2016, 12:38 AM +0200, Yacine Filali notifications@github.com, wrote:\n\nAlso, cache all the things, in memory preferably, per request at the very least.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub (https://github.com/graphql-python/graphene/issues/358#issuecomment-259547357), or mute the thread (https://github.com/notifications/unsubscribe-auth/ADTJWKlZ6Xfi2UXZGPuRGJy8qKmnncsDks5q8kuBgaJpZM4KuD8A).\n. I don't quite get the proxy object. Is it something from Graphene?\n\nAnyway, I think what I can do is when resolving a parent object, I should also prefetch related entities. This is fine for now, but I wonder if graphene is flexible enough to only get related entities when required; sometimes users just want, for e.g., a list of articles without included comments\n. ",
    "hugoduncan": "Thanks for the rapid fix!   What's the difference between next (the branch to which this was committed) and 1.0?\n. ",
    "travisbloom": "Adding some additional steps that I had to take when following this integration:\n```python\nclass RTGraphQLView(GraphQLView):\ndef parse_body(self, request):\n    if type(request) is rest_framework.request.Request:\n        return request.data\n    return super().parse_body(request)\n\n```\nGraphene was expecting the .body attr but DRF reads it and attaches it to .data before being passed to GraphQLView.. ",
    "jacobh": "For my use I rolled the two above examples up into a single view class:\n```python\nfrom graphene_django.views import GraphQLView\nimport rest_framework\nfrom rest_framework.permissions import IsAuthenticated\nfrom rest_framework.decorators import authentication_classes, permission_classes, api_view\nfrom rest_framework.settings import api_settings\nclass DRFAuthenticatedGraphQLView(GraphQLView):\n    def parse_body(self, request):\n        if isinstance(request, rest_framework.request.Request):\n            return request.data\n        return super(APGraphQLView, self).parse_body(request)\n@classmethod\ndef as_view(cls, *args, **kwargs):\n    view = super(APGraphQLView, cls).as_view(*args, **kwargs)\n    view = permission_classes((IsAuthenticated,))(view)\n    view = authentication_classes(api_settings.DEFAULT_AUTHENTICATION_CLASSES)(view)\n    view = api_view(['GET', 'POST'])(view)\n    return view\n\n```. ",
    "eamigo86": "Hi @jacobh  I try to use your code but do not make anything, I can make requests without any authentication header.. Hi @jacobh. I already worked your code, the truth has saved me an important time. I did not work before because I had the private route after the public route, so I only had to define my private route before the public route and it worked perfectly. Hi @AgentChris, take a look at this module, maybe you might be interested:\ngraphene-django-subscriptions. ",
    "dperetti": "@travisbloom It works but it's really a hack.\ngraphene.django.view.parse_body() is totally skipped, which should be fine in most situations, but it could also probably yield headaches in some edge cases.. At least some warning on the website about this would prevent every newcomer from wasting a couple hours of his lifetime.... ",
    "alshafai": "\nFor my use I rolled the two above examples up into a single view class:\n```python\nfrom graphene_django.views import GraphQLView\nimport rest_framework\nfrom rest_framework.permissions import IsAuthenticated\nfrom rest_framework.decorators import authentication_classes, permission_classes, api_view\nfrom rest_framework.settings import api_settings\nclass DRFAuthenticatedGraphQLView(GraphQLView):\n    def parse_body(self, request):\n        if isinstance(request, rest_framework.request.Request):\n            return request.data\n        return super(APGraphQLView, self).parse_body(request)\n@classmethod\ndef as_view(cls, *args, **kwargs):\n    view = super(APGraphQLView, cls).as_view(*args, **kwargs)\n    view = permission_classes((IsAuthenticated,))(view)\n    view = authentication_classes(api_settings.DEFAULT_AUTHENTICATION_CLASSES)(view)\n    view = api_view(['GET', 'POST'])(view)\n    return view\n\n```\n\nThis implementation worked perfectly for me on my local development server. For some odd reason when I deploy it on AWS it gives me the following error : \n\nYou cannot access body after reading from request's data stream. \n",
    "jstacoder": "@alshafai that is because you are calling super(APGraphQLView, self) when you should be calling super(DRFAuthenticatedGraphQLView, self). ",
    "HideoKuze": "This was really great thank you. I want to include an additional line I added for people using GraphQL/Graphene with the Django OAuth Toolkit:\n from oauth2_provider.contrib.rest_framework import TokenHasReadWriteScope, TokenHasScope, \n OAuth2Authentication\n\n class DOTAuthenticatedGraphQLView(GraphQLView):\n     def parse_body(self, request):\n         if isinstance(request, rest_framework.request.Request):\n             return request.data\n         return super(DOTAuthenticatedGraphQLView, self).parse_body(request)\n\n     @classmethod\n     def as_view(cls, *args, **kwargs):\n         view = super(DOTAuthenticatedGraphQLView, cls).as_view(*args, **kwargs)\n         view = permission_classes((IsAuthenticated, TokenHasReadWriteScope, ))(view)  # add \n permissions to the view\n         view = authentication_classes((OAuth2Authentication,))(view)\n         view = api_view(['POST'])(view)\n         return view\n\nNotice the view = authentication_classes((OAuth2Authentication,))(view) line, it's necessary for it to work. The previous line for the permission_classes isn't actually necessary it seems. But I kept it for whatever reason. \nThanks again, this has shown me I need to read deeper into what's going on with the views. Does anyone know any good articles that go into depth? I want to really learn more about these class methods so I can figure something like this out on my own in the future. > Adding some additional steps that I had to take when following this integration:\n\n```python\nclass RTGraphQLView(GraphQLView):\ndef parse_body(self, request):\n    if type(request) is rest_framework.request.Request:\n        return request.data\n    return super().parse_body(request)\n\n```\nGraphene was expecting the .body attr but DRF reads it and attaches it to .data before being passed to GraphQLView.\n\nCan you explain to me exactly what happening here and why I need to do it? It works for me but I'm not certain as to why. Originally I was also getting the You cannot access body after reading from request's data stream error, but your code fixed it. ",
    "willianantunes": "Hi guys! I wrote a playground project with all you posted here.\nThe customized view:\nhttps://github.com/willianantunes/django-graphql-playground/blob/151b59c29c648ce053937ea70ad07af0d7db74d9/api/graphql/views.py#L10\nIts setup:\nhttps://github.com/willianantunes/django-graphql-playground/blob/151b59c29c648ce053937ea70ad07af0d7db74d9/django_graphql_playground/urls.py#L29\nAnd some integration tests with GraphQL clients:\n\nWith prisma/python-graphql-client: https://github.com/willianantunes/django-graphql-playground/blob/151b59c29c648ce053937ea70ad07af0d7db74d9/api/tests/integration/test_urls.py#L87\nWith graphql-python/gql: https://github.com/willianantunes/django-graphql-playground/blob/151b59c29c648ce053937ea70ad07af0d7db74d9/api/tests/integration/test_urls.py#L121\n\nThank you!. ",
    "fortheworld2017": "Hi\nI got this error in serverless code\nTypeError: Error when calling the metaclass bases\n    init_subclass_with_meta() got an unexpected keyword argument 'model'\nimport graphene\nfrom models.people import People\nfrom graphene import relay\nclass Character(graphene.Interface):\n    name = graphene.String()\nclass PeopleNode(graphene.ObjectType):\n      class Meta:        \n          interfaces = (Character,)\n          model = People\nclass Query(graphene.ObjectType):\n    peoples = graphene.List(PeopleNode)\ndef resolve_users(self, args, context, info):\n    return People.scan()\n\nschema = graphene.Schema(query=Query)\nPlease help me. ",
    "slorg1": "@jkimbo it does not seem to be in the newest version (0.10.2) that I got from pip.\nAlso, thank you for your fix. I see you saw the same issue I did. In your changes I see the change to the DjangoFilterConnectionField\nIt does not address the secondary issue issue I had. Maybe I should open 2 git issues. Suggestions?\n. @jkimbo I added a couple questions to your PR. Thank you.\n. thx!\n. should get_order which is the function designed to handle the API level (args) to the to_snake_case so it would \"own\" the API layer and let get_queryset deal with qs level things? (separation of concerns / layering).\n. Other question: what if order is a list? https://docs.djangoproject.com/en/1.10/ref/models/querysets/#django.db.models.query.QuerySet.order_by\nTo do multi field ordering (in your test order_by('first_name', 'articles'))\ndjango_filters.filterset.BaseFilterSet\nqs = qs.order_by(*self.get_order_by(ordered_value))\nwould handle it, though (since I do not need a nice patch from you for this one) it would not handle the nice to_snake_case you added.\n. ",
    "giorgi94": "@Mhs-220 Thanks for OrderedDjangoFilterConnectionField. I spent couple of weeks with this problem. But is there any problem with pagination? It uses Base64 encoding, and to simplify working with it, I wrote this functions\n```python\nimport base64\ndef encode(e):\n    # BlogNode:2 -> QmxvZ05vZGU6Mg==\n    try:\n        return base64.urlsafe_b64encode(e.encode()).decode()\n    except:\n        return None\ndef decode(e):\n    # QmxvZ05vZGU6Mg== -> BlogNode:2\n    try:\n        return base64.urlsafe_b64decode(e).decode()\n    except:\n        return None\ndef cursor_page(page, per_page):\n    first = per_page\n    endCursor = encode('arrayconnection:' + str(page * first - 1))\n    return (first, endCursor)\n```. ",
    "androane": "@Mhs-220 Your solution shouldn't work and indeed is not working. When you compute qs you pass it to the super method as the default_manager. The order is not preserved. Sorry, was a mistake from my side. Digging into the code I saw that default_manager can be a queryset as well. And it wasn't actually working for me because I was trying with a String isntead a list of Strings. ",
    "fsck-mount": "any docs regarding this ?. ",
    "felix-zg": "Thanks!\n. ",
    "AT-SyT": "I also tried to enable custom filters/mutations with existing SQLAlchemy Schemas but I haven't found a way to do so. \nAre these features not implemented in graphene or am I missing something? \n. Thank you for providing this example. \nExactly what I was looking for. \n. ",
    "gsvitak": "Thanks for the great work!!\nWe use Redux instead of Relay in our app. Is there a way to use Graphene with SQLAlchemy without the Relay dependency?\n. Thanks for the suggestion. Can you please provide a quick sample? \nDo I need to add my own reducers methods.. like the following?\nhttps://github.com/graphql-python/graphene/blob/master/graphene-sqlalchemy/graphene_sqlalchemy/tests/test_query.py\nHere is what I am attempting.\nschema.py\n```\nclass Folder(SQLAlchemyObjectType):\n    class Meta:\n        model = FolderModel\nclass Query(graphene.ObjectType):\n    all_folders = SQLAlchemyConnectionField(Folder)\nSchema = graphene.Schema(query=Query, types=[Folder])\n```\nalso tried\n```\nclass Folder(SQLAlchemyObjectType):\n    class Meta:\n        model = FolderModel\nclass Query(graphene.ObjectType):\n    folder = graphene.Field(Folder)\n    folders = graphene.List(Folder)\ndef resolve_folder(self, *args, **kwargs):\n    return db.session.query(Folder).first()\n\ndef resolve_folders(self, *args, **kwargs):\n    return db.session.query(Folder)\n\n```\n. thank you!!\n. ",
    "pedrorjbr": "Hello,\n```\nclass Query(graphene.ObjectType):\n    product = graphene.Field(Product, id=graphene.ID())\n    all_products = relay.ConnectionField(ProductConnection)\n    products = graphene.List(Product)\n    node = relay.Node.Field()\ndef resolve_product(self, args, context, info):\n    session =  context['session']\n    id_ = from_global_id(args['id'])[1]\n    p = session.query(ProductModel).filter(ProductModel.id == id_).first()\n    return p\n\ndef resolve_products(self, args, context, info):\n    session =  context['session']\n    return [x for x in session.query(ProductModel).all()]\n\ndef resolve_all_products(self, args, context, info):\n    return []\n\n```\nIs the code above is a good practice? \nI have allProducts as a ConnectionField to fullfil Realy requirements and products like a simple list to GraphQL.\nOr is it better just to choose one of the implementations?\n. Hey. Why do you need flask to run it on Aws Lambda + API gateway?\nI thought you just need to use graphene + API gateway + Aws lambda. ",
    "hyusetiawan": "i just figured out that i need to expose the foreign key related class in the Query before I can traverse from ParentClass --foreignkey--> ChildClass.\nIs there a way to traverse the foreign key relationship without exposing it through Query? \nAlso, how can I hide certain properties? such as user { password, } right now I do resolve_password and return None but that means property name \"password\" is still exposed though the value is None\nPS: I am sorry for hijacking the error reporting with questions ><\n. thanks, that answers it! \n. ",
    "mwilliamson-healx": "Thanks for the suggestion! I gave Graphene 1.0.dev0 a go, and while it's certainly faster, it still takes around a second to run the example above. Admittedly, I didn't try it out on the speediest of machines, but suggests that it would still be the dominant factor in response time for our real data.\n. Thanks again for the suggestion! Using cyordereddict shaves about 200ms off the time (from 1s to 0.8s), so an improvement, but still not ideal. I had a look around the code, but nothing stuck out to me as an easy way of improving performance. The problem (from my extremely quick and poorly informed glance!) is that you end up resolving every single value, which includes going through any middleware and having to coordinate promises. Keeping that functionality while being competitive with just spitting out dicts directly seems rather tricky.\nThe proof of concept I've got sidesteps the issue somewhat by parsing the GraphQL query, and then relying on the object types being able to generate the requested data directly, without having to further resolve values. It's very much a proof of concept (so doesn't support fragments, and isn't really GraphQL compliant yet), but feel free to have a look. Assuming the approach is sane, then it's hard to see how to reconcile that approach with the normal GraphQL resolve approach.\n. In case it's useful, I've been using the project I mentioned above in production, and performance has been good enough. In particular, it avoids having to run a (potentially asynchronous) resolver for every field. I'm still tweaking the API, but it should be reasonably stable (and better documented!) soon.\nhttps://github.com/healx/python-graphjoiner. Unfortunately, this is still probably too slow for my use-case -- GraphJoiner is around four times faster. When profiling, it seems like most of the time is spent in (potentially asynchronous) field resolution.\nHaving said that, I'm not sure that the approach I'm using is really compatible with the way Graphene works. I suspect my comments aren't particularly helpful, so I'll be quiet!. ",
    "mwilliamson": "Thanks for the kind words. One question I had was how much you'd imagine trusting the query builder? For my implementation, I was planning on putting the responsibility of correctness onto the queries (rather than having the GraphQL implementation check). The result is that, unlike the normal implementations of GraphQL, it's possible to implement something that doesn't conform to the GraphQL spec.\n. Thanks for working on this. I've taken a look at the proof of concept you wrote, but it's not clear to me exactly how it behaves, and how it's saving time versus the existing implementation. It seems like it's still resolving all fields of objects in the response, but I could easily have misread.\nI adjusted my proof of concept to (optionally) integrate with GraphQL properly. This means that you can do things like generating the schema, introspect, and the all other stuff that GraphQL does, but it means you hit the performance penalty again. It seems to me that the easiest way of fixing this for my use case would be a way to prevent resolution from descending into the object that my proof of concept produces -- a way of returning a value from resolve functions that doesn't trigger resolution on any fields (since they're already resolved).\nPerhaps something like:\npython\ndef resolve_users(...):\n    ...\n    return FullyResolvedValue(users)\nwhere users is already fully resolved by inspecting the AST or whatever. Alternatively, a decorator on the function itself might be clearer.\nThis shifts more responsibility onto the calling code to make sure that the returned value is of the correct shape in order to ensure it's still a valid GraphQL implementation, but that's definitely a good trade-off for me.\n. ",
    "qubitron": "@syrusakbary any update on this thread? I am using graphene in production and unfortunately it simply doesn't scale for even the moderate data sets being returned by my API. I'm slowly rewriting my API calls as normal HTTP calls and seeing 10x RPS increases (and therefore 10x reduction in server costs), but it means I'm losing the flexibility of the graphQL approach. Seems like the solution discussed in this thread would save me from this headache!. @syrusakbary it took me a bit of time to get to a place where I had a good test for this. The package you provided seems to make a big improvement! Cutting total execution time for my request roughly in half, with the graphene portion reduced by a factor of 3x. \nInitially it wasn't working because I already had graphql-core installed, doing \"pip uninstall graphql-core\" before running your command above finally yielded the performance improvements.\nMore about my workload... I'm using a flask web server with graphene_sqlalchemy and returning objects that inherit from SQLAlchemyObjectType (not sure if that counts as middleware but I get similar results when I return plain graphene.ObjectType). \nFor this particular example, I have ~300 items being returned, and resolving 5 fields (on each. The SQL Query takes about 18ms to return results, and the full HTTP response takes 78ms.\nAfter installing your package the request takes about 18ms and full HTTP response takes 37ms. This is much more reasonable, but there still might be some opportunities for improvements. \nI ran the CPython profiler for the duration of the request, here is the breakdown of time spent in the graphql libraries with the experimental executor:\n```\n   ncalls  cumtime    filename:lineno(function)\n        1    0.165    flask/app.py:1605(dispatch_request)\n        1    0.165    flask/views.py:82(view)\n        1    0.165    flask_graphql/graphqlview.py:58(dispatch_request)\n        1    0.162    flask_graphql/graphqlview.py:149(execute_graphql_request)\n        1    0.159    flask_graphql/graphqlview.py:146(execute)\n        1    0.159    graphql/execution/executor.py:32(execute)\n        1    0.159    graphql/execution/experimental/executor.py:14(execute)\n        3    0.159    promise/promise.py:42(init)\n        1    0.159    promise/promise.py:73(do_resolve)\n        1    0.159    graphql/execution/experimental/executor.py:42(executor)\n        1    0.159    graphql/execution/experimental/executor.py:59(execute_operation)\n    323/1    0.159    graphql/execution/experimental/fragment.py:98(resolve)\n   2255/1    0.155    graphql/execution/experimental/resolver.py:25(on_complete_resolver)\n```\nI'm using a CPython runtime in AWS, do you think your experimental executor is complete/stable enough for me to use it in production (obviously I will test it)?. @mwilliamson-healx I agree it would be nice if this could be faster, for me these changes make it usable but further performance improvements would be nice. I took a cursory look at the GraphJoiner, I haven't had time to full internalize how it works and although it seems like a promising alternative, I'd prefer if the graphene approach could be made faster or if some sort of hybrid approach could be used.\nOne thing that would be interesting for me is if somehow we could select only the columns from SQL that were requested by the user's query, to further improve database performance.. Amazing work, @syrusakbary! Looking forward to the improvements, let me know if I can help test any changes.. @syrusakbary I am a bit hesitant to use PyPy, I ran into some bugs/compatibility issues with Cython libraries (unrelated to graphene) and was getting mixed performance results using sqlalchemy. That being said, if the wins are there then it's always good to have that option.. @syrusakbary I gave this a test and I'm seeing similar performance numbers as the previous version, wish I had a different answer! Still seems to be spending about ~20ms of time in resolving in the graphql layer. \nDo you still have the previous archive available? My code has changed somewhat and will be easier for me to compare results if I can change back and forth.. @ekampf @syrusakbary \nI have updated the sample to use:\n```\nclass SetAddress(graphene.Mutation):\n    class Input:\n        geo = GeoInput()\naddress = graphene.Field(lambda: Address) \ndef mutate(self, args, context, info):\n    geo = args.get('geo')\n    address = Address(latlng=\"({},{})\".format(geo.get('lat'), geo.get('lng')))\n    return SetAddress(address=address)\n\n```\nThe mutate( ) method never gets called and the code returns an error:\n$ python complex_example.py\n(32.2,12.0)\nTraceback (most recent call last):\n  File \"complex_example.py\", line 73, in <module>\n    print(result.data['address']['latlng'])\nTypeError: 'NoneType' object is not subscriptable\nI noticed that the mutation docs look like they were recently updated and advise using graphene.InputField( ... ), and\nif I switch it back to graphene.InputField(GeoInput), now I get a different error:\n$ python complex_example.py\nTraceback (most recent call last):\n  File \"complex_example.py\", line 31, in <module>\n    class Mutation(graphene.ObjectType):\n  File \"complex_example.py\", line 32, in Mutation\n    setAddress = SetAddress.Field()\n  File \"/usr/local/lib/python3.5/site-packages/graphene/types/field.py\", line 53, in __init__\n    self.args = to_arguments(args or OrderedDict(), extra_args)\n  File \"/usr/local/lib/python3.5/site-packages/graphene/types/argument.py\", line 56, in to_arguments\n    arg.type\nValueError: Expected geo to be Argument, but received InputField. Try using Argument(GeoInput).\nWhen trying to use graphene.Argument(GeoInput), the mutate method never gets called and I get the same runtime error as above. I've updated my fork here with the example code:\nhttps://github.com/qubitron/graphene/blob/patch-1/examples/complex_example.py\n. ",
    "sirmarlo": "Has anyone gotten any improvement with this challenge (i.e. slow response times due to field resolution)? We are addressing this issue as well with even smaller data sets (returning 50-100 items). Our main issue is our data types are large and a bit nested so there are multiple fields that need to get resolved whenever a client has a complex query.\nWe've tried adding some layer of caching in the field resolution but are unable to get something feasible even if we cache the resolve functions and/or the execute call within a custom executor (that we inherit from SyncExecutor).. ",
    "wxkin": "is there any update on this? Consider the following example, inspired by @mwilliamson-healx, where 100K Users need to be returned. Using graphene.Scalar the response is x8 faster.\n\nIs there any way to drop the type checking/casting? Or anyway to speed up the resolves? \nIt is not really a use case to return such number of objects however it is a use case to return a few thousand nested objects.\n\n```python\nimport graphene\nimport cProfile\nimport StringIO\nimport pstats\nfrom contextlib import contextmanager\nfrom graphene.test import Client\n@contextmanager\ndef profile(show_calls=None, message=None):\n  print(\"\\n============== Profiler start ==============\" )\n  if message:\n    print(\" \" + message + \" ... \")\npr = cProfile.Profile()\n  pr.enable()\n  yield\n  pr.disable()\n  s = StringIO.StringIO()\n  sortby = 'cumulative'\n  ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n  if show_calls:\n    ps.print_stats()\n    print s.getvalue()\n  else:\n    print ('Execution time %f seconds' % ps.total_tt)\n  print(\"--------------------------------------------\")\nclass UserQuery(graphene.ObjectType):\n    id = graphene.Int()\nclass UserAbstract(graphene.Scalar):\n@staticmethod\n  def serialize(dt):\n    return dt\nclass Query(graphene.ObjectType):\n    users = graphene.Field(graphene.List(UserQuery))\n    users_abstract = graphene.Field(graphene.List(UserAbstract))\ndef resolve_users(self, context):\n  return users\n\ndef resolve_users_abstract(self, context):\n  return resolved_users\n\nclass User(object):\n    def init(self, id):\n        self.id = id\nnof_users = 100000\nusers = [User(index) for index in range(nof_users)]\nresolved_users = [user.dict for user in users]\nschema = graphene.Schema(query=Query)\nwith profile(message=\"Fetch using ObjectType\", show_calls=False):\n  response = Client(schema).execute('{users{id}}')\n  assert (len(response['data']['users']) == nof_users)\nwith profile(message=\"Fetch using Scalar\", show_calls=False):\n  response = Client(schema).execute('{usersAbstract}')\n  assert (len(response['data']['usersAbstract']) == nof_users)\n```\n```\n============== Profiler start ==============\n Fetch using ObjectType ... \nExecution time 8.595509 seconds\n\n============== Profiler start ==============\n Fetch using Scalar ... \nExecution time 1.008313 seconds\n\n```. We have decided to drop Graphene and use just the GraphQL-Core. At this moment we have the feeling that Graphene does not add match (we don't use all the features) but instead introduces overhead. We really don't need type checking on that level as  we can guarantee the types/attributes.. ",
    "samlll42-github": "We are also having a lot of performance problem with large set (few hundreds, or few thousands) being excruciatingly slow to resolve.\nBesides non-opensource options (.ie Quiver), will graphene/graphql-core ever have decent performance on large sets? Is anybody working on that or have ideas on how we could optimize? We are happy to help if there is any such initiative in progress.\n. ",
    "chriggi": "Same here, I wish I knew this before I implemented graphene!. ",
    "danpalmer": "We're doing something similar to this. It's a little less trivial, but not far off.\nWith 35k products, the following query takes around 14 seconds after we've managed to get the IDs. We're getting the IDs as just a list of integers from a cache, and then bypassing the database query that would typically generate the list if the client only requests the IDs. (The use-case here is for clients to pre-populate a full ID result set).\ngraphql\nquery Products {\n    products {\n        edges {\n            cursor\n            node {\n                id\n            }\n        }\n    }\n}\nI realise that this is not the most optimal structure in which to return the data, but this is the format that makes most sense for the client to our API, and we'd also rather not change the architecture of parts like this for speed reasons if we can avoid it (we're obviously cool with optimising the code behind this as much as we can).\nA quick test shows that the following demo code takes ~0.24s on the same machine. This is obviously missing the overheads from Django, GraphQL parsing, etc, but I think it's a reasonable lower bound.\n```python\nimport base64\nimport json\nimport time\ndef item(x):\n    return {\n        'cursor': base64.b64encode('arrayconnection:{}'.format(x).encode('ascii')).decode('ascii'),\n        'node': {\n            'id': base64.b64encode('ProductType:{}'.format(x).encode('ascii')).decode('ascii'),\n        }\n    }\nt1 = time.time()\njson.dumps([item(x) for x in range(35_000)])\nprint(time.time() - t1)\n```\n~I've tried this query with Quiver Cloud and I don't see any difference in the response time. I might have it set up incorrectly, but it looks ok - it's making queries to the service and receiving valid responses.~ Edit: we were using the caching query backend, so never hitting the Quiver optimisations - these reduce the runtime to ~3-4 seconds.\nFrom some basic profiling, it seems that Promises are causing quite a large overhead. Of the top 10 slowest functions, totalling 4.4 seconds of run time. It also looks like there are possible optimisations in Graphene - 0.5 seconds are spent in isinstance, which is called 2.3 million times.\nSome more advice here would be great.\nSome optimisation ideas off the top of my head:\n\nGraphene, Graphene-Django, GraphQL-Core, Promises, etc, all make very heavy use of functions and lambdas - these aren't particularly fast in Python when you get into the realm of detailed performance optimisation, I wonder if there's some parts that could be refactored to remove some of the function calls.\nThese libraries also make heavy use of isinstance, callable, issubclass, etc, to support a range of input types at various points. While this results in a nice API, and these functions aren't slow, the number of times they are being called is very significant (these 3 functions are called roughly 4.4 million times in our query above, taking ~1.3 seconds).\nIs there a possibility for users of these libraries to return the JSON result for portions of the return data, if they are able to generate this easily? This would allow users to drop down to lower level code and manually construct responses in order to optimise if necessary.\nCould these libraries optimise the code path for when Promises aren't being used? Anecdotally, we use Promises in ~1-2% of resolvers, and while they are really useful in these cases, it's a large penalty on other code paths - in this case roughly a 30% speed reduction.\n\nThoughts appreciated!. @syrusakbary Cool, it sounds like there are fewer performance optimisations than I thought there might be.\n\nYou mean returning JSON without going through the GraphQL engine?\n\nYes. In this particular instance we happen to trivially know what the JSON result would be, so a potential optimisation would be to allow the resolver to return the actual JSON that will be returned in the response. I realise this is quite a layering violation, and I don't like the idea, but it could potentially cut ~97% of the runtime of this particular query.\n\nEven if only one field in a subtree (for example the distance field in: getUser->photos->location->distance) is a Promise, all parent \"roots\" will be wrapped in a promise for it's resolution.\n\nThis makes sense, I understand that it has to go up the tree. In our case we're not returning a promise from anything in this query, so it doesn't feel worth it to wrap every resolver in a Promise layer. In this case, there are 35k nodes, each with a cursor and an ID, so I believe that would be around 105k resolutions to be made. That could be quite an overhead vs just returning the data directly.\n\nIn the case of using just asyncio (without promises, with graphql-core-next), the same thing happens. So it's not really a matter of the library, but how the GraphQL executor is implemented.\n\nWe don't use asyncio, we're just doing synchronous execution.\nI've tried the suggestion you gave me in our email:\npython\nfrom promise import async_instance\nasync_instance.disable_trampoline()\nThis reduces the runtime by around half. Now 6-7 seconds to get the 35k list items, but at the cost of not being able to use promises in the few places we do make use of them.\n. @jkimbo hey, I'm still interested in this, would be great if it could be re-opened.\nI wonder if something like this might be a nice approach:\n```python\nclass ItemType(DjangoObjectType):\n    class Meta(object):\n        model = Item\n        only_fields = (\n            'id',\n            'stock',\n            'price_gbp',\n            'price_previous_gbp',\n            'images',\n            'sizes',\n        )\n        interfaces = (relay.Node,)\n    def qs(self, fields):\n        selects = {\n            'brand_name': ['item_base__brand'],\n            'name': ['item_base'],\n        }\n        prefetches = {\n            'sizes': ['sizes'],\n        }\n        return self.model.objects.select_related(\n            *[x for y in fields for x in selects.get(y, [])],\n        ).prefetch_related(\n            *[x for y in fields for x in prefetches.get(y, [])],\n        )\n\n```\nIn this example, fields is a list of the field names requested on this type, for which the resolvers will be called.\nselects and prefetches could possibly be defined on the Meta class instead, but it would be good to have a hook to do this entirely manually anyway.. Hi, I just started working on GraphQL stuff again, was reading through docs, and realised I still don't know what \"vitaminized\" means, could someone explain this and/or update the docs?. Following up on this, I still don't know what \"vitaminized\" means.\n. This description sounds great! Much better than \u201cvitaminized\u201d, which I\u2019m not sure is even a word. \n\nOn 31 Aug 2018, at 11:07, Syrus Akbary notifications@github.com wrote:\nA connection is an enhanced structure for items that can be paginated, enabling the following capabilities for the client:\nThe ability to paginate through the list.\nThe ability to ask for information about the connection itself, like totalCount or pageInfo.\nThe ability to ask for information about the edge itself, like cursor or friendshipTime.\nThe ability to change how our backend does pagination since the user just uses opaque cursors.\nI'm not sure if this statement makes more clear what connections are for, but I would love to improve the docs with something that can be properly understood for both newbies and experienced GraphQL devs.\nThoughts? How do you think we can make connections clear for everyone?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Go for it. I\u2019m happy to review the PRs if you do.\nOn 4 Jul 2018, at 05:02, Kaushik Asp notifications@github.com wrote:\nCan I take this up?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Hey sorry for not looking at this sooner. I agree with Syrus, the helper feels unnecessary. It basically just abstracts out an if statement, which I think makes the code less readable. . @Kacppian in my opinion, we should use the form:\n\npython\nif condition:\n    raise AssertionError(message)\nAnd I think we should do this at the call sites, not in a function.\n@jkimbo I think that makes more sense in the JS ecosystem where everything is libraries and functions all the way down, but in Python it's much expected that you do the obvious thing rather than wrapping up potentially unexpected effects.\nIn this case I don't think there's any benefit introduced by wrapping up AssertionErrors - it really does just feel like turning an if statement into a function - that requires an extra import, possibly a test, documentation, knowledge transfer, and understanding by new developers. An if/raise is just standard usage of two core parts of the language.. @Kacppian apologies for the back and forth. I disagree with @dan98765's suggestion on that PR, and it appears that @syrusakbary does too. I'm afraid we're not a cohesive team, just people who happen to have an interest in this library!. No problem! I didn\u2019t read it as rude, and it is a valid criticism. \n\nOn 29 Aug 2018, at 18:39, Kaushik Asp notifications@github.com wrote:\nI'm extremely sorry. I didn't mean it to come out like that. Just mentioning the reason I've done it this way.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @syrusakbary thoughts on this? I've applied this patch in our codebase, and it allows this to work:\n\npython\nclass SomeMutation(relay.ClientIDMutation):\n    class Input:\n        # This class is mixed in to the Input type constructed by Graphene.\n        def __init_subclass__(cls, **meta_options):\n            super().__init_subclass__(\n                description=\"Some documentation for this input type.\"\n                **meta_options\n            )\n. @syrusakbary Unfortunately this doesn't work.\n<trimmed>\n  File \"/Users/dan/Code/styleme/styleme/graphql/urls.py\", line 6, in <module>\n    from .schema import schema\n  File \"/Users/dan/Code/styleme/styleme/graphql/schema.py\", line 14, in <module>\n    import styleme.account.schema # noqa: I001\n  File \"/Users/dan/Code/styleme/styleme/account/schema.py\", line 6, in <module>\n    from styleme.cart.schema import CartMixin\n  File \"/Users/dan/Code/styleme/styleme/cart/schema.py\", line 3, in <module>\n    from .mutations import SetQuantity, SetProductSize\n  File \"/Users/dan/Code/styleme/styleme/cart/mutations.py\", line 46, in <module>\n    class SetQuantity(CartEditFormMixin, FormMutation):\n  File \"/Users/dan/.virtualenvs/styleme/lib/python3.6/site-packages/graphene/utils/subclass_with_meta.py\", line 48, in __init_subclass__\n    super_class.__init_subclass_with_meta__(**options)\n  File \"/Users/dan/Code/styleme/styleme/graphql/graphene_replacements.py\", line 294, in __init_subclass_with_meta__\n    **options,\n  File \"/Users/dan/Code/styleme/styleme/graphql/graphene_patches.py\", line 125, in ClientIDMutation__init_subclass_with_meta__\n    client_mutation_id=String(name='clientMutationId'),\n  File \"/Users/dan/.virtualenvs/styleme/lib/python3.6/site-packages/graphene/utils/subclass_with_meta.py\", line 36, in __init_subclass__\n    delattr(cls, \"Meta\")\nAttributeError: Meta. Any thoughts on this?. @syrusakbary ping on this. We'd like to be able to document our edges, but can't currently do this.. @syrusakbary I'm open to improving the documentation here, but I think this is a reasonable start.\nWe're trying to fully document our API, hence the PRs relating to enabling documentation for APIs built with Graphene.. Also interested. dan@danpalmer.me\n\nOn 3 Jan 2019, at 11:00, Piero Palevsky notifications@github.com wrote:\nI'd be interested. I have spent the last year plus working with Graphene in production and would love to contribute back to the project.\nEmail: ppalevsky@gmail.com\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. Thanks for the update Syrus!\n\nI\u2019d love to become a maintainer or Graphene/Graphene Django if possible. I believe I\u2019ve contributed to both in the past, and would be keen to keep doing so. \n\nOn 7 Mar 2019, at 20:10, Syrus Akbary notifications@github.com wrote:\nYesterday we had the meeting.\nThe details are in the doc that @brianmcfeeley posted.\nhttps://docs.google.com/document/d/12-olPz5FHGx3w8kCkNX3FNhhx38abVR1VK-U2ehxHok\nAs a summary, here are the things that we talked:\nCompanies & developers interested on moving Graphene / GraphQL Python ecosystem forward\nHow to move Graphene forward (by using graphql-core-modern and/or graphql-core-next)\nDifferent repos in the ecosystem and people that would like to start governing / maintaining them\nHow to handle communication between collaborators / maintainers (we will have all the communication in the Slack channel)\nIn general, we are going to add more maintainers into the repo so we can start reviewing and merging PRs without my explicit approval.\nIn general, if you contributed to the repos of @graphql-python and you would like to be added as maintainer to a specific repo please let us know and someone will add you.\nAlso, if you would like to start collaborating or knowing where Graphene is going next please join our Slack channel.\nPRs should be merged when a certain number of approvals is reached: 4 for Graphene, 3 for GraphQL-core, 5 or 4 for Graphene-Django, 2 for Graphene-SQLAlchemy...\nAlso, I'm going to be present and helping the transition. But the goals of where Graphene should go in next releases will start coming from the community, collaborators and governors of the ecosystem.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "mjmonroe": "We use MongoDB as our database, which outputs BSON, easily converted into JSON. One MongoDB document is used to create a nested set of Graphene objects. Every Graphene object is then type checked by the GraphQl library. The type checking is a significant bottleneck. Being able to turn it off, or otherwise bypass the type checking would make our application much faster.\nAll the data in MongoDB is already type checked before being saved to the database via MongoEngine. In our application, type checking a second time is not necessary and just adds overhead.\n. @ktosiek that sounds perfect. I would definitely use it in my graphene services since I already have a layer that validates the types, there is no need for me to have Graphene do that as well. That's a very nice speedup!. We have the same use case. GraphQl is not a query language and does not natively support nested queries. The graphene.InputObjectType can be used to create your own JSON format that supports nested queries. The code then reads the JSON and translates it into django Q objects. We are using MongoEngine's  Q objects, which are based on django's.\nIn our case we have a filter input which is a self referencing graphene.InputObjectType. Self referencing because you can nest the query as deep as you want. Each filter level represents a single nesting level. The linkage between a resolver and a query is broken because a single InputObjectType can be used to query any field in the database. By breaking the linkage, we allow for abritary 'AND'/'OR' combinations of any depth with any field in the database. For instance, a field can be queried on, but never returned by GraphQl. The search model is completely decoupled from the GraphQl domain model. Now that they are separate, they can evolve separately. Different views of the data can be generated and returned by GraphQl, all based on the same query.\nExample Filter InputObjectType\n| Input | Description |\n| ------ | -------------|\n| op | Enum: Operator to apply at current level |\n| content | [Filter]: List of filters to apply underneath current level. Only valid for logic operators 'AND', 'OR', 'MATCH'. This is self referencing, filters contain lists of more filters.  |\n| field | String: Field to apply operator on. Not valid for 'AND' and 'OR' operators. |\n| value | [String]: Value is what a field is compared to, << field >><< op >><< value >>. Not valid for logic operators. |\n| negate_op | Boolean: Negate the operator by adding a programatic 'not' |\n```graphql\nquery ExampleFourNesting {\n    result(filter: {\n        op: OR,\n        content: [{\n                op: AND,\n                content: [{\n                        op: eq,\n                        value: [\"4\"],\n                        field: \"some_field\"\n                    }, {\n                        op: gt,\n                        value: 16,\n                        field: \"another_field\"\n                    }\n            ]\n        }, {\n            op: exact,\n            value: \"some_value\",\n            field: \"another_field\"\n        }\n    ]\n}) {\n    hits {\n       stuff\n    }\n    pagination {\n        count\n        pages\n        page\n        size\n    }\n}\n\n}\n```. ",
    "ktosiek": "Would it make sense to add a special RawGraphQLResult type for skipping complete_*_value?\nThis way users could use the current APIs for specifying types, while having a way to implement a custom resolver that skips the type checking.\nI have a prototype that went from 0.8s to 0.3s by moving from graphene ObjectType to a dict and a simple fields filtering/renaming function.. Simplified version of the monkey patch I'm using: https://gist.github.com/ktosiek/a309f772399482a47cf2c4ed219ff1af\nYou still have to look at info to know which fields should be returned, but this will skip a lot of computations.. Is snapshottest considered to be a part of the GraphQL-Python ecosystem? I see there are some doubts about its future too, for example https://github.com/syrusakbary/snapshottest/issues/64 and https://github.com/syrusakbary/snapshottest/issues/37. I haven't seen any documentation on that, but it's an instance of ResolveInfo: https://github.com/graphql-python/graphql-core/blob/v2.1.0/graphql/execution/base.py#L66. I'd love to see an example too!\nJust an idea: you could put the Dataloaders on info.context (which is actually the current request).. ",
    "daironmichel": "Thanks! @syrusakbary \n. Thanks! @syrusakbary \n. Hi again,\nWell I don't know if this is a good fix but it worked for me. All my tests pass and my system is working properly.\nHere's what I did. I just added to methods to DjangoFilterConnectionField\n``` python\ngraphene_django/filter/fields.py\n...\nclass DjangoFilterConnectionField(DjangoConnectionField):\n...\n@staticmethod\ndef connection_resolver(resolver, connection, default_manager, filterset_class, filtering_args,\n                        root, args, context, info):\n    filter_kwargs = {k: v for k, v in args.items() if k in filtering_args}\n    order = args.get('order_by', None)\n    qs = default_manager.get_queryset()\n    if order:\n        qs = qs.order_by(order)\n    qs = filterset_class(data=filter_kwargs, queryset=qs)\n\n    return DjangoConnectionField.connection_resolver(resolver, connection, qs, root, args, context, info)\n\ndef get_resolver(self, parent_resolver):\n    return partial(self.connection_resolver, parent_resolver, self.type, self.get_manager(),\n                   self.filterset_class, self.filtering_args)\n\n```\nHope it helps.\n. Thanks for the fast response. Glad I could help! :)\n. BTW, good job with the docs and version 1.0\n. thanks for your response @mjtamlyn,\ncan you please give me an example on how will I get the framework to use my own connection class?\n. Thanks man. Nice work!\nOn Oct 1, 2016 1:54 PM, \"Syrus Akbary\" notifications@github.com wrote:\n\nEran example should now work.\nI added also a testcase to ensure that resolvers can return connection\ninstances: c792923\nhttps://github.com/graphql-python/graphene/commit/c7929234294a181993158b4439c24006e9ed1ebd\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/issues/307#issuecomment-250926732,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AGqlaQN74U8TZLWPriIDS78jYeNB5yJaks5qvp5ogaJpZM4KLJJV\n.\n. \n",
    "markflorisson": "Here is a small example:\n``` python\nimport graphene\nclass MyEnum(graphene.Enum):\n    Foo = 0\n    Bar = 1\nclass DoSomething(graphene.Mutation):\n    class Input:\n        myEnum = graphene.Field(MyEnum)\nmessage = graphene.String()\n\n@classmethod\ndef mutate(cls, instance, args, info):\n    return DoSomething(message=\"Success!\")\n\nclass MyMutations(graphene.ObjectType):\n    doSomething = graphene.Field(DoSomething)\nschema = graphene.Schema(mutation=MyMutations)\nprint(schema.execute(\n    \"\"\"\n    mutation {\n        doSomething(myEnum:\"Foo\") {\n            message\n        }\n    }\n    \"\"\").errors)\n```\nWhich gives: GraphQLError('Unknown argument \"myEnum\" on field \"doSomething\" of type \"MyMutations\".',).\nIt used to give something else, but I upgraded graphene to 1.0.dev, where even the basic mutation example from the website doesn't seem to work (http://graphene-python.org/docs/mutations/).\n. ",
    "wodCZ": "Just in case someone else comes to this issue and has an existing enum.Enum, here is sample code to use it in mutation without need to redefine it as graphene.Enum:\n```\nfrom enum import Enum\nimport graphene\nclass ShareTypes(Enum):\n    public = 'PUBLIC'\n    authority = 'AUTHORITY'\n    users = 'USERS'\nclass DoSomething(graphene.Mutation):\n    class Input:\n        myEnum = graphene.Enum.from_enum(ShareTypes)(required=True)\nmessage = graphene.String()\n\n@classmethod\ndef mutate(cls, instance, args, info):\n    return DoSomething(message=\"Success!\")\n\n```. Similar here, except that your workaround doesn't work for me.\nclass InteractWithAnnouncement(graphene.ClientIDMutation):\n    class Input:\n        interaction_id = graphene.Field(graphene.String, deprecation_reason='Deprecated')\nbehaves exactly same as \nclass InteractWithAnnouncement(graphene.ClientIDMutation):\n    class Input:\n        interaction_id = graphene.String(deprecation_reason='Deprecated')\nwhich behaves exactly same as \nclass InteractWithAnnouncement(graphene.ClientIDMutation):\n    class Input:\n        interaction_id = graphene.String()\nI don't get deprecation notice in graphiql nor in console.\n. ",
    "Eraldo": "This does not work if I use that enum in one of my model's fields. :|\nError: AssertionError: Found different types with the same name in the schema: MyEnum, MyEnum.\nI guess the reason is that it is already in the registry.\n. @NiekHoekstra Does a PR exist yet for this? If not are you willing to take the patch and turn it into a PR? :). How about getting someone from the django core team to assist?\nI think reactive programming is something that would bring new people to django which would benefit in the long run. It was the reason for me to look into other solutions.\nWhat do you think?. Thank you for the update @hballard that sounds really awesome. :D. I am using django in some projects and would love to replace drf (django-rest-framework) with what you are building. I really prefer reactive programming and I think a graphQL api with subscriptions would totally add a lot of value on top of the django project.\nI am not a core django person nor do I have experience with django-channels.. I do however have practical experience with django. Feel free to reach out me if it helps. ;). Did you get to give it a try yet? :). ",
    "yen223": "This also fails for choices with non-ASCII characters, e.g. django-countries's CountryField will fail on \u00c5LAND_ISLANDS. \n. > Perhaps the best option is to just allow the user a way to easily override the enum data?\nTotally agreed. Also, we should take this discussion over to https://github.com/graphql-python/graphene-django\n. One potential win from separating the two is being able to define types with the GraphQL Schema Definition Language for easier interop with clientside code, while defining resolvers in Python-land.. ",
    "benjaminjkraft": "I'm not sure what the best thing to do here is.  One option is to prefix with an underscore, but that has other meanings.  Another option is to truncate the initial prefix until finding something valid, but that might cause dupes, or result in a similar underscore-prefix.  Perhaps the best option is to just allow the user a way to easily override the enum data?  Not sure if that's already possible.\n. Ok.  It seems like in that case, the correct non-classmethod definition would be\ndef resolve_name(self, root, args, context, info):\n    ...\nsince it seems like the root isn't really properly a self argument at all -- so maybe the docs should be updated to do that (or the classmethod)?\nThis is a pretty minor thing, in any case, just something that confused me for a few minutes.\n. Yeah, that would work too; it's certainly easy enough to work around this in several ways.  That is, this isn't broken per se, it's just a somewhat confusing API in  my opinion.\n. ",
    "pity7736": "I have the same problem. I'm using graphene-django 1.1.3.. ",
    "nuschk": "Hey @prokofiev , did you find a workaround for this?\nI'm struggling with exactly the same problem and am very interested in your approach. The least hack I could come up with, is to always require all arguments and then use 'input.get('myVar', None)' to retrieve them in 'mutate_and_get_payload()'. \nEven setting the field to be required and having a default value will not make it appear in the input dict.... @prokofiev Hehe, thanks for the snippet. Will look into it. . ",
    "NiekHoekstra": "Any progress on this?. ",
    "patrickkempff": "We are having the same problem!. ",
    "arif-hanif": "Does someone have an example for 2.0?. @rdemetrescu i get the same thing... so not sure if this is really fixed.. ",
    "rdemetrescu": "@BossGrand  I am still having this problem with null values.\nIf my javascript client sends a mutation with those variables:\n{\"id\": 4, \"titulo\": \"TITULO\", \"resenha\": \"RESENHA\", \"autorId\": 1}\nmy server receives this as **args (at mutate function):\n{'autor_id': 1, 'id': 4, 'resenha': 'RESENHA', 'titulo': 'TITULO'}\nHowever, if the client sends this:\n{\"id\": 4, \"titulo\": \"TITULO\", \"resenha\": null, \"autorId\": null}\nMy python **args param receives only 2 keys/values:\n{'id': 4, 'titulo': 'TITULO'}\n(where I would expect receiving {'id': 4, 'titulo': 'TITULO', 'resenha': None, 'autorId': None})\nMy packages versions:\n\u279c pip freeze | grep -i graph\nFlask-GraphQL==1.4.1\ngraphene==2.0\ngraphene-sqlalchemy==2.0.0\ngraphql-core==2.0\ngraphql-relay==0.4.5\nShould this issue be reopened ?\nThanks in advance. @arif-hanif, just noticed that mutations using relay work perfectly.. Amazing @patrick91 .\nIf possible, could you include info on how to work with Relay and how to address situation where you already have \"id\" as a column name of your tables/models and using SQLAlchemy ?\n(I am thinking about problem described here:  https://github.com/facebook/relay/issues/1061)\nThanks in advance!. @patrick91 , no, I'm doing my first project with Aurelia + Apollo at client side and Graphene + Flask + SQLAlchemy at server side.\nTrying to figure out best practices to implement pagination, authentication, authorization at both sides.  :)\nI mentioned Relay because, I liked the pagination support it gives. But i guess we can't use Relay + Apollo together, right? \n. ",
    "jinty": "I have seen this query:\nmutation myMutation {\n                       editIt(Input: {id: \"AFJS\", title: null}) {\n                           It {id}\n                       }\n                  }\nfail with:\n 'Syntax Error GraphQL request (3:112) Unexpected Name \"null\"\n\nHowever when I pass title as a \"variable\" it does work.. ",
    "coleifer": "I'll take it on as a personal repo, and we can take it from there. Thanks for your encouragement and your interest!\n. Hey @danigosa -- between work and moving our house I don't believe I'll be able to work on this for at least a couple weeks. I hope you understand.. ",
    "ParthGandhi": "@coleifer Awesome, look forward to it. I'd love to help if you need any.\n. ",
    "joshdavey": "Hey guys, thanks so much for these two amazing libraries. Can't wait for them to work together officially. Is there anywhere I can follow the progress of graphene-peewee?\nThanks\n. ",
    "danigosa": "@coleifer we need to decide in our organization if we go for SQLAlchemy or Peewee (coming from Django ORM in older projects), could you open the work in progress so we can check how is it doing and possibly contribute to make it possible? Most devs in my team we prefer Peewee (congrats and thanx!) but GraphQL is one elevated requirement for the stack we are building.  . Don't even worry, we are facing other architecture layers? Anyway we are using peewee-async finally so no matter what in the times to come if you start this we'll contribute, for now we are not going to far in the frontend side to use graphql at its best so... Good luck with the move :) . ",
    "axsauze": "Thank you very much for this contribution @coleifer! @Danigosa I would definitely recommend Peewee, especially if you come from the Django ORM world. ",
    "jontonsoup": "Is there a place where I can follow this? @coleifer . ",
    "Hendler": "Excited! Can we help out? Is there a place we can follow @coleifer ? . ",
    "codejamninja": "What's the status of this? Are there any existing ways to use peewee with graphql? . ",
    "alexpantyukhin": "It's interesting for me @coleifer @syrusakbary  @danigosa . I can try to implement if it's not done yet and nobody already works with it.. . @jkimbo thank you very much!. @japrogramer Could you please clarify what is the @client directive? Couldn't find it.. ",
    "danfairs": "Updating the version fixed it for me - thanks! I'll leave this issue open if you're using it to track docs changes.\n. ",
    "benblippar": "worked it out just before you comment... thanks!\n. Ah this was caused by objects that can't be pickled ... hmm\n. ",
    "warunaeniplex": "what is this >>> assert _type.graphene_type == type\n                         AssertionError. ",
    "adamhadani": "got it @syrusakbary - thanks for clarifying! makes sense\n. ",
    "Luftzig": "This issue belongs in graphene-django\n. ",
    "vwrobel": "My problem might rather concern django-filters yet I would appreciate any input regarding how to query with exclusion through Graphene. \n. I should have posted in graphene-django. Sorry.\n. Thanks a lot @BossGrand!\nUpdating to graphene-django 1.0, I have been able to do what I wanted with the following query definition:\n```\nclass Query(AbstractType):\nselected_scenes = DjangoFilterConnectionField(SceneNode, exclude=Boolean())\n\ndef resolve_selected_scenes(self, args, context, info):\n    owner__name = args.get('owner__name')\n    exclude = args.get('exclude')\n    if exclude:\n        selected_scenes = Scene.objects.exclude(owner__name=owner__name)\n    else:\n        selected_scenes = Scene.objects.filter(owner__name=owner__name)\n    return selected_scenes\n\n```\nI will try the solution you propose!\n. ",
    "ariannedee": "Is there a way to resolve total_count within the MyConnection class?\n. I usually return a GraphQLError.\nfrom graphql import GraphQLError\n...\nraise GraphQLError('That email already exists')\nIt takes a few more arguments: nodes, stack, source, and positions, but I have never used these.. ",
    "morgante": "@Globegitter I actually did try to use the AbstractType and it still didn't work. Like so:\n``` python\nclass SimpleCreationMutation(AbstractType):\n    class Input:\n        name = graphene.String(required=True)\nok = graphene.Boolean()\n\n@classmethod\ndef mutate_and_get_payload(cls, input, context, info):\n    model = cls.Config.model\n\n    name = input.get('name')\n\n    instance = model(name=name)\n    instance.save()\n\n    return cls(result=instance, ok=bool(instance.id))\n\nclass CreateTag(SimpleCreationMutation, relay.ClientIDMutation):\n    class Config:\n        model = Tag\nresult = graphene.Field(TagNode)\n\n```\n. I'd love to know more about this story as well. We're working on moving some large projects to Graphene, but need to have good answers before doing so.\n. ",
    "picturedots": "@morgante  Did you ever find a way to make the class Input inheritable?  I have a similar problem where I have a large number of CRUD mutations and I'd like to make the input shared between set and create mutations.  I am successful at least sharing fields by inheriting from AbstractType just like the line ok = graphene.Boolean() in your example.  . You can do something like Person(**args) . Thanks -- I guess the documentation as it stands is correct then, but it's misleading for Django users, because there isn't any Django-specific testing docs.. @jkimbo That's correct -- the point though is that DateTime etc. aren't consistent with other types now.  For example, here's how you important both Int and Date:\nfrom graphene.types.datetime import Date\nfrom graphene.types import Int. Ok, I will take a crack at it when I have a chance.  I'll have a look at the existing tests for other types for some examples.. If someone can explain why the python 2.7 tests are failing, and how to run  the travis builds locally I can fix the travis errors.. I got stalled on the tests and forgot to come back to this -- when is the next release?. I appreciate the updates to the \"Contributing\" section in README.MD -- I will see if I can finally get this finished this week.. @jplock It looks like #794 is going to provide a helper method once its accepted, so maybe it's best to wait.  I did, however fix some linting errors  that complained about `assert x == None` and converted to `assert is None`.. It looks like there are black formatting errors in `test_mutation.py` from the master branch that is breaking tox for me.  @sebdiem  do you know anything about this?  If somebody can fix it on master then I can merge in that change to clear the Travis errors.. This should be all good to go now, @jplock  -- unfortunately it looks like I missed the latest release..\n",
    "huckebein79": "You should add resolve_type(...) to CreatePostResult\npython\n@staticmethod\ndef resolve_type(obj, context, info):\n    if isinstance(obj, Success):\n        return Success\n    return Fail\nI think we need document for Union anyway. \n. ",
    "DeoLeung": "Hi,\nI'm trying to get into the GraphQL world.\nI want to use Graphene as a standalone server, do I still need to scale up like normal REST backend by deploying multiple instances?\nI'm using tornado at the moment, it looks like if I use the AsyncioExecutor, it'll run on only one eventloop, so I still need multiple tornado instances?. ",
    "JimVanEeden": "Yes I got that from the documentation, the problem is that I can't import the classes. The only solution is to put all the models and the construction class in one file, which is highly undesirable.\n. I solved it only partially. Below is the solution I could come up with. My case differs from the above in that the model class name is a variable, where in the above example it's a constant (Viewer).\n``` python\nfrom importlib import import_module\nfrom functools import partial\ndef convert_relationships(db_model_class):\n    converted_relationships = {}\nfor prop_name, relationship in iteritems(db_model_class.__dict__):\n    if not isinstance(relationship, Relationship):\n        continue\n\n    direction = relationship.direction\n    model_name = relationship.target\n\n    if direction == Direction.MANYTOONE or direction == Direction.ONETOONE:\n        converted_relationships[prop_name] = Field(\n            partial(get_graphql_model_class, model_name=model_name))\n    elif direction == Direction.ONETOMANY or direction == Direction.MANYTOMANY:\n        converted_relationships[prop_name] = relay.ConnectionField(\n            partial(get_graphql_model_class, model_name=model_name))\n\nreturn converted_relationships\n\ndef get_graphql_model_class(model_name):\n    module = import_module('examplemodule.models.' + model_name)\n    return getattr(module, model_name, None)\n```\nnote: My database model classes have custom Relationship properties that are used to create the field properties, but the code should be understandable without knowing the Relationship class\nHowever\nfunctools.partial is used to pass model_name to the function so the function knows which model to return (I don't know of any other way to do this). But, this doesn't work out of the box with the Field class from graphene:\npython\n@property\ndef type(self):\n    if inspect.isfunction(self._type):\n        return self._type()\n    return self._type\ninspect.isfunction does not recognize a partial function as a function, so I had to adapt that code a bit to have it recognize a partial as well. \nNow it works perfectly fine, but my request is to preferable change the functionality from 0.x back where you can just pass the name string, and otherwise have it recognize functools.partial. But the latter still feels a bit hacky to me.\n. As a quick fix i changed it to inspect.isfunction(self._type) or type(self._type) is partial, but this is not ideal.\n. ",
    "philiptzou": "This pull-request is dependent on https://github.com/graphql-python/graphql-core/pull/88. Once the graphql-core pull-request get accepted the Travis tests should be passed.\n. @dfee pong.\nOn Sun, Apr 2, 2017 at 12:19 AM Devin Fee notifications@github.com wrote:\n\n@philiptzou https://github.com/philiptzou ping.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/pull/319#issuecomment-290969549,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAxbiTYUDbgX190ouX3Qmn_diPwuaUQbks5rr0v2gaJpZM4KS3pX\n.\n. @dfee I turned to install from my forked repositories now. But yes I'm\nstill attempting to merge the code.\nOn Sun, Apr 2, 2017 at 9:02 PM Devin Fee notifications@github.com wrote:\n@philiptzou https://github.com/philiptzou I think I might've run into\nthis same issue, and was wondering if you were still attempting to merge\nthis code.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/pull/319#issuecomment-291044168,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAxbiRgGodrDM7mys7s7g3QFDTlf-Nuwks5rsG83gaJpZM4KS3pX\n.\n. \n",
    "reverie": "I ran into a similar problem. There are lots of pages like this index by Google. Not sure where these URLs came from, but you have to click Documentation at the top and navigate to the one you want.\n. Lots of pages like this are indexed by Google. I think they are deprecated/old URLs somehow. You have to click Documentation at the top and then navigate to the one you want.\n. @jkimbo Doesn't this contradict the documentation at https://github.com/graphql-python/graphene/blob/master/UPGRADE-v2.0.md ? See \"Simpler resolvers\" before/after.. Any explanation here? This is bizarre.. ",
    "bcb": "This was fixed in #334 \n. Any chance of redirecting the old URLs?\n. That worked for most docs @syrusakbary ~~although I noticed the django tutorial (http://graphene-python.org/docs/django/tutorial/) now leads to 404.~~ Working now.\n. ",
    "wenley": "Augh, thanks! \n. ",
    "thisiswei": "@syrusakbary \nhow can I pass parameters like following: \njs\n{\n emailAddresses(id: 10) {\n   id\n }\n}\n```python\nclass EmailAddress(SQLAlchemyObjectType):\n    class Meta:\n        model = EmailAddressModel\nclass Query(graphene.ObjectType):\n    email_addresses = graphene.List(EmailAddress)\ndef resolve_email_addresses(self, args, context, info):\n    query = EmailAddress.get_query(context)\n    return query.all()\n\nschema = graphene.Schema(query=Query)\n```\nhow do I pass id=10 to EmailAddress and only fetch EmailAddress with id 10?\n. ",
    "thomasloh": "@thisiswei check args, args['id'] == 10. ",
    "ecamaj": "Same for me, but not for all pages. I found this link in some other issue - http://graphene-python.org/docs/middleware, and nothing is shown when I click on it. \nTried in Chrome and Safari.\nAlso, where are middleware pages in docs? There is no mention of Middlewares in http://docs.graphene-python.org/en/latest/.\nAm I missing something here?\n. Sure. That would make sense if you can show me link to middleware explanation. \n. OK, found it here: https://github.com/graphql-python/graphene/blob/0148401c0694893ef57d6b52a40adae272e6ebd5/UPGRADE-v1.0.md#schema\nIt is not in Schema anymore but in \"schema.execute\" and it is not \"middlewares\" it is \"middleware\" argument.\n. ",
    "chaffeqa": "I ran into this gotcha too... really confusing error message as well :/\n. none here :( sorry been deep in integrating apollo w next.js \ud83c\udf89 . regardless of what my company says, we will gladly pay for that!\nI've honestly been looking for ways to contribute to both graphene and apollo personally, its making huge wins for our company and my personal sanity \ud83d\ude09 . Great idea!  Count me in.  You can reach me or hangout me at chaffeqa@gmail.com\n(east coast... cuz timezones /shrug). ",
    "jwfehr": "interests = graphene.types.json.JSONString()\nis an example of the lines throwing errors. I did however try the import like you have above and it worked for me.\n. That did the trick! Thanks @syrusakbary. Is there any documentation for the info object and how to parse through it? or can someone point me to the code where it is formed?. Apologies for the delay, I am continuing to work this problem and am having issues. When I look at the field_asts for the info object in my user class I can see my teamID argument as part of the selection set which includes userIsTeamLeader, however when I look at the field_asts for the info object in my resolve_userIsTeamLeader function the only field that is present is the userIsTeamLeader with its argument, is there any way to access the user field_asts from within my resolve_userIsTeamLeader function?. @angieellis Thanks very much for the help, I will take a look at that.. ",
    "othane": "@yfilali yes I have the array of items in the server code which I left out for brevity ... What I don't get in your example is the $input variable in getMutation, where does that come from, ie how does it know what the mutation inputs are ? Or is it comming from getVariables ?\n. Awsome that must be my missunderstanding ... I'll give it a go ... Cheers @yfilali\n. @yfilali I just tried it, but relay gave\nError: Unknown argument \"input\" on field \"newCatalogItem\" of type \"Mutation\".\nwhen compiling the schema ... and if I try it in graphiql it also does not recognise the input option, ie this works.\nmutation {\n  newCatalogItem (id: \"Q2F0YWxvZ05vZGU6MQ==\", price: 3.11) {\n    catalogItem {\n      id\n      desc\n      price\n    }\n  }\n}\nIt turns out my Graphene libs are probably quite old, could this be it?\n$ cat requirements.txt \nbackports.shutil-get-terminal-size==1.0.0\ndecorator==4.0.10\nDjango==1.9.7\ndjango-filter==0.13.0\ndjango-graphiql==0.4.4\ndjangorestframework==3.4.0\ngraphene==0.10.2\ngraphql-core==0.5.3\ngraphql-django-view==1.3\ngraphql-relay==0.4.4\nipdb==0.10.1\nipython==5.0.0\nipython-genutils==0.1.0\niso8601==0.1.11\npathlib2==2.1.0\npexpect==4.2.0\npickleshare==0.7.3\nPillow==3.3.0\npkg-resources==0.0.0\npromise==0.4.2\nprompt-toolkit==1.0.3\nptyprocess==0.5.1\nPygments==2.1.3\nsimplegeneric==0.8.1\nsingledispatch==3.4.0.3\nsix==1.10.0\ntraitlets==4.2.2\nwcwidth==0.1.7\nBTW I just tried updating, but got a bunch of other problems ill have to work through first.\nCheers for the help\n. Awsome !! ... haha I just realised my mistake with relay.ClientIDMutation just as I saw this comment ... sorry that should have been obvious :)\nStill not quite right though do I still add the mutation like this\n```\nclass Mutation(graphene.ObjectType):\n    new_catalog_item = graphene.Field(NewCatalogItem)\nclass Meta:\n    abstract = True\n\n```\nEDIT: when I run it this way I get back \"message\": \"mutate_and_get_payload() takes exactly 4 arguments (3 given)\",\nthat is with a mutation like this \nmutation {\n  newCatalogItem (input: {clientMutationId: \"a\", id: \"Q2F0YWxvZ05vZGU6MQ==\", price: 12}) {\n    clientMutationId\n    catalogItem {\n      id\n    }\n  }\n}\n. ",
    "tsunammis": "Hello @syrusakbary \nSince your commit -> 760ccc8, Is it not possible to use async resolver method for a relay.ConnectionField, isn't it ?\nI get this error ->  AssertionError: Resolved value from the connection field have to be iterable or instance of SectionConnection. Received \"<coroutine object get_sections at 0x7f0de4b14518>\". cc @syrusakbary . I have hesitated to cherry-pick your commit e6733d5, but your method is_thenable doesn't handle an object type which is equals to coroutine.\nSo, I think that you should add asyncio.iscoroutine(resolved) in is_thenable as you handle this type in the promisify method.\n@syrusakbary What do you think ?\nI did another workaround on a fork for my company -> https://github.com/dailymotion/graphene/commit/c60fe1dac36cfe3e5429d923881286662a3acb3b. Hello @syrusakbary \nThanks for your time. It works fine now.\nNext time, I will take some time to create PR on each projects ;-)\nHave a nice day.. ",
    "ajhyndman": "Hey guys.  I'm wondering what the status is on this PR.  It seems like some of the documented Connection APIs might be out of date?\nI'm getting errors that look like this when I try to declare a property with type ConnectionField(MyNode):\n16, in is_node\n    if not issubclass(objecttype, ObjectType):\nTypeError: issubclass() arg 1 must be a class. I'm interested in helping make a graphene-optics-agent client a reality!\nI'll try joining the Apollo slack team to make myself a little more reachable.. ",
    "tangerilli": "@syrusakbary the commit above changes the error, but doesn't allow unions to be used in a connection. I submitted #367 which does allow unions to be used in a connection.  But if there's a better way to do it, I'm happy to hear it \ud83d\ude04 \n. @syrusakbary thanks, that worked!\n. ",
    "bforchhammer": "I've stumbled onto this problem a couple of days ago as well. My issue is that I have to request data from another service for one of the nodes in my GraphQL structure, and ideally I would like to execute only one bulk request for all required objects instead of 10 separate requests. Unfortunately the Proxy-Object method did not quite work for me, because the node can appear in different parts of the requested graph and I did not have one ConnectionField being initiated with the list of IDs as seems to be done with the PynamoDB solution...\nHere's what I ended up with instead: \n I created a class for lazy promises, which are not evaluated until resolution is explicitly triggered\n I trigger the resolution in a custom GraphQL executor by overriding Executor.wait_until_finished (i.e. pretty much at the end of the request cycle)\n* When instantiating the lazy promise, I also register all values which I need to retrieve data for, so I can do one bulk request in the end.\nYou can find all the code with an example in this gist, feel free to use/copy/adapt it for anything if you find it useful :smiley: \n. I had a similar problem (see https://github.com/graphql-python/graphene/issues/358#issuecomment-269220991), maybe that also works for you... . ",
    "richmondwang": "@yfilali thanks for the post you created! It worked for me like a charm.\nAlso, I somehow \"forked\" it and updated it to select only the requested fields/columns from the info. Here is my gist (https://gist.github.com/richmondwang/cc9ba2db32e44795359417dd08326c31).\nIt worked, though I haven't created test script for it yet.. There are breaking changes in graphql-core==2.0.dev\nSee UPGRADE-v2.0.md to have help on upgrading to 2.0.\nThe gist:\nYour resolve_user should have this signature def resolve_user(self, info, **args) ( or def resolve_user(self, info, id, username) ) for the rest of the resolve code to work.. ",
    "chanind": "Another option is to use an intelligent lazy loader. I'm not sure about Django, but we use the following lazy loader for SqlAlchemy which should solve the n+1 query problem without needing any custom code. We open-sourced the lazy loader here in case it's helpful for anyone else: https://github.com/operator/sqlalchemy_bulk_lazy_loader. I figured it out. It turns out I needed to register the instances of the interface with the schema explicitly and then this works. A more meaningful error message could help in case other people get confused as well.. ",
    "ksonj": "I also can confirm that this is not working and I am using ClientIDMutation as well. Neither Field(..., deprecation_reason=\"..\") nor String(deprecation_reason=\"...\") has any effect.\n  . Should be fixed in graphql-core with https://github.com/graphql-python/graphql-core/pull/140. ",
    "mzins": "I am wanting to deprecate input parameters for a backend query rather than a mutation. Example \n```\nclass NameArgs(InputObjectType):\n    firstname = List(String, description=\"query by a list of first names\")\n    lastname = List( String, description=\"query by a list of last names\" )\nclass PersonQuery(ObjectType):\n    person = List(PersonType, input_args=NameArgs())\ndef resolve_person( self, info, input_args ):\n    return back_end_query(**input_args)\n\n```\nsay I wanted to deprecate first name and only allow users to query by last name, the following edit does not actually depreciate the last name argument \n```\nclass NameArgs(InputObjectType):\n    firstname = List(String, description=\"query by a list of first names\")\n    lastname = List( String, description=\"query by a list of last names\",\n                     deprecation_reason=\"last name is no longer supported by database\")\n```. ",
    "amelius15": "https://pypi.python.org/pypi/django-auth-anywhere/0.0.2\nMight not be exactly what you want, but it'd do the trick to help with auth, you could just use DRF auth with graphene.. I've accomplished a similar functionality by adding a \"search\" method filter and using django-watson to actually perform the search. Something like this\n`\nclass ObjectFilter(django_filters.FilterSet):\nsearch = django_filters.MethodFilter(action='filter_search')\n\nclass Meta:\n\n    model = Object\n\ndef filter_search(self, queryset, value):\n\n    return watson.filter(queryset, value)\n\n`\nI don't know if this is considered the best way, but it certainly works.. ",
    "rotten": "I'm confused.  https://pypi.python.org/pypi/Flask-GraphQL  doesn't list any \"middleware\" option to as_view().   I've been playing with graphql in flask for a few days now, and it still isn't obvious how to secure the endpoint, even with a simple api key, other than implementing something entirely in front of it in a proxy layer.  This middleware approach sounds like it would work well, except the option doesn't appear to be documented anywhere.. Ok, I see it in the source.  https://github.com/graphql-python/flask-graphql/blob/973d10f1823cd690a63995707ce669d5793e79e0/flask_graphql/graphqlview.py#L22   Thanks for the hint, and sorry to complain.  I'll see if I can blog about it after I get it working.. The fundamental lack of accessible integrated authentication and authorization mechanisms is a serious flaw.  I've spent 3 days trying to get something to work, I can't deploy anything without this basic feature set working.  Tomorrow I'll go back to writing REST endpoints.  I'll check in with GraphQL again in another year or two.  I predict that without easy security integration, GraphQL will flame out and disappear.  It is a show stopper for us at least.. ",
    "Musbell": "@patrick91 it will be helpful if u could come up with the demo. if u wouldn't mind probably Django as well. :). ok @patrick91 \n. Ahhh! i have been waiting for this. @prokher i will definitely check it out. . @prokher thanks for the notice. :+1: . For update, using graphene.Argument() instead of graphene.Field() worked for me \n```\nclass SomeError(graphene.ObjectType):\n    code = graphene.Argument(\n        type=graphene.Enum.from_enum(ErrorCodes),\n        required=True\n    )\n    message = graphene.String(required=True)\n...\nreturn SomeMutation(someErrors=[SomeError(code=e.code.value, message=e.message)])\n```. it is my  internet connection. Thanks a lot.. ",
    "mongkok": "A package and examples for Django framework.\nhttps://github.com/flavors/graphql-jwt. ",
    "pizzapanther": "Need a test?. Looks good but I would probably move the permissions off the field. I think its more concise for the user to generate the fields dynamically and then a user can switch fields based on the permission. See the DRF example which is similar: https://www.django-rest-framework.org/api-guide/serializers/#dynamically-modifying-fields\nNote DRF really doesn't do this exactly and Django Forms don't do this either because you have to base fields on the request. But it is a constant hack I always use.  So if graphene could support, that would be incredible.\nMore info for reference: https://stackoverflow.com/questions/19128793/per-field-permission-in-django-rest-framework\nNote often times with DRF you just have 2 different serializers based on the user.. one example that i've seen on other GraphQL implementations is that you have access to different data based on whether you are logged in or not. So I could see that going down to the field level. And ideally you want to not show fields you don't have access too.\nAgain not really a feature I've seen in other Python frameworks so you find ways around it to produce the same result. So I think it makes sense to bake it in.\n. \n. i mention dynamic fields because I'm thinking it might be easier to implement, but that's just my best guess.. maybe not it the same place but yes. You often times need the context (request) and all the inputs to validate. When you have inputs that depend on each other you need that. Although you shouldn't need inputs to determine field access, just to validate.. ",
    "fbyossi": "Alright, I got it working with \npython\nfriends = graphene.Dynamic(lambda: graphene.List(UserType))\nIs this the correct solution?\n. ",
    "sofiama": "it should be animals = relay.ConnectionField(Animal). ",
    "wkiser": "@syrusakbary , worked for me. Thanks!. ",
    "angieellis": "I've been trying to find a solution to this myself. The only way I've found is through the info parameter in the resolve method. That holds all the arguments, models, and requested fields in the query. However, its a bit messy to go that route because you have to parse through it. Would be great to have a cleaner/easier way to do this. . I'm sorry. That only works the other way around, when you are trying to access child arguments from the parent. In that case, you should go with what @yfilali demonstrated with self. You should have the first part of the argument resolved in self with the User object. So you should be able to access the id field from there.. @jwfehr I looked at this again today. You can access the parent arguments in the info object, but not in the field_asts attribute. Try the operation attribute (info.operation). That seems to have all arguments in both contexts.. You can utilize the dynamic field type by using lambda: \nfamous_song = graphene.Field(lambda: Song)\n. @kevinbarabash This seems to be a prevalent concern in the GraphQL community right now. Many GraphQL libraries don't support batch querying or merging queries. There is a library in Javascript that provides this functionality (https://github.com/stems/join-monster), but none that I know of in Python. This is definitely something I would like to see as well.. Can you please paste your code for this?. ",
    "nylocx": "Hi, I have the same problem and I can't get the self solution to work.\nI tried to add a minimal example to the playground at:\nhttps://goo.gl/gd1CgM\nDo I really have to parse the whole info object just to get to the filter value?\nI found a workaround https://goo.gl/BqMtjV\nBut I don't really like it.. ",
    "Zevgon": "For anyone else who thinks that the above solutions are too hard, my workaround was to add the arguments to info.context in the higher level resolve method. Not pretty, but very easy.. @pcattori Yes, your first example is exactly what I mean. About your second example, I think that's possible if you access arg directly from self? Pretty sure this works:\n```python\ndef resolve_parent(self, info, arg):\n        return ChildType(arg=arg)\n...\nclass Child(graphene.ObjectType):\n    def resolve_some_field(self, info):\n        return self.arg\n```\nAlthough I still prefer not doing that type of thing in cases where the child inherits from DjangoObjectType because of the possibility of arg clashing with one of the model's property names.. ",
    "pcattori": "@Zevgon not sure exactly how to \"add arugments to info.context\". could you provide an example?. maybe like this?\n```python\ndef resolve_parent(self, info, arg):\n        info.context.args = dict(arg=arg)\n        return ChildType()\n...\nclass Child(graphene.ObjectType):\n    some_field = ...\n    def resolve_some_field(self, info):\n        return info.context.args.get('arg')\n```\nthough I wish something like this would be possible, to make namespacing easier:\n```python\ndef resolve_parent(self, info, arg):\n        return ChildType(arg=arg)\n...\nclass Child(graphene.ObjectType):\n    def resolve_some_field(self, info):\n        return self.args.get('arg')\n```. ",
    "janhancic": "Yes that was it. Finished the upgrade now and can use the required now. Thanks!. Hi @syrusakbary thanks, but this is exactly what I wanted to avoid.\nI'm using protos on the FE too, so want to keep the link as direct as possible. This also seems like code duplication basically.\nIs there any reason we couldn't have the serialize&co functions be instance functions? That would allow me to do what I want, and as far as I can see everything else would continue to function just fine?. Hey @syrusakbary sorry to bother but have toy got any new info on this?. Sweet, I haven't thought about using a Field to do this. Thanks, I'll give it a spin after the holidays. Cheers!. Finally got some time to try this out. I had to modify your code a bit (resolver method was being overridden by Field in it's init, and you can't use partial on class methods), but in general it works exactly as I wanted.\nFor anyone reading this in the future, this is what I ended up doing:\n```python\nfrom functools import partial\nimport third_party.python3.graphene as graphene\nclass ProtoEnum(graphene.Field):\n    \"\"\"Provides a link between protobuf enums and GraphQL fields\"\"\"\ndef __init__(self, protobuf_enum, *args, **kwargs):\n    super(ProtoEnum, self).__init__(graphene.Int, *args, **kwargs)\n    self.protobuf_enum = protobuf_enum\n\ndef get_resolver(self, parent_resolver):\n    return partial(_enum_resolver, self.protobuf_enum, parent_resolver)\n\ndef _enum_resolver(protobuf_enum, parent_resolver, root, args, context, info):\n    resolved_value = parent_resolver(root, args, context, info)\nif resolved_value not in protobuf_enum.values():\n    raise ValueError('Enum value \"%s\" is invalid' % resolved_value)\n\nreturn resolved_value\n\n```\nSo thank you very much for the help!. Can you post the various exceptions you get, maybe that would help @syrusakbary figure out what's going on.. Right, so the above are really unrelated to my original comment .... Yes, this is still an issue, and I'm waiting for some help from you guys :) (most of the latest comments are not related to my original issue). ",
    "odero": "This actually solved it thank you. Hadn't used django-watson before.. ",
    "hung-phan": "Sth like this for example:\n```\nimport graphene\nfrom graphene.types.scalars import MIN_INT, MAX_INT\nfrom graphql.language.ast import BooleanValue, StringValue, IntValue, ListValue, ObjectValue, FloatValue\nclass JSON(graphene.Scalar):\n    \"\"\"\n    The JSON scalar type represents JSON values as specified by\n    ECMA-404.\n    \"\"\"\n@staticmethod\ndef identity(value):\n    if isinstance(value, (unicode, str, bool, int, float)):\n        return value.__class__(value)\n    elif isinstance(value, (list, dict)):\n        return value\n    else:\n        return None\n\nserialize = identity\nparse_value = identity\n\n@staticmethod\ndef parse_literal(ast):\n    if isinstance(ast, (StringValue, BooleanValue)):\n        return ast.value\n    elif isinstance(ast, IntValue):\n        num = int(ast.value)\n        if MIN_INT <= num <= MAX_INT:\n            return num\n    elif isinstance(ast, FloatValue):\n        return float(ast.value)\n    elif isinstance(ast, ListValue):\n        return [JSON.parse_literal(value) for value in ast.values]\n    elif isinstance(ast, ObjectValue):\n        return {field.name.value: JSON.parse_literal(field.value) for field in ast.fields}\n    else:\n        return None\n\n```. ",
    "cristianfraser": "Hey @syrusakbary, not meaning to post in this old thread... but should GenericScalar still work? Was it replaced?\nIn the changelog I can only see when it was added, but nothing else. And when importing with from graphene.types.generic import GenericScalar I get that it doesn't exist.\nEDIT: nvm, im dumb\nI was using name = graphene.GenericScalar() instead of name = GenericScalar(). ",
    "japrogramer": "is GenericScalar stilll around .. I need to return a json object .. and i can't find it.\n@syrusakbary \nnvm: found it,  for some reason i cant do graphene.GenericScalar\nbut i found it under types.generic. from graphene.types import generic\n...\n    errors = generic.GenericScalar()\n. @globophobe django channels cannot do broadcasting with ws\nhttps://channels.readthedocs.io/en/stable/concepts.html#groups. For anyone interested this is how i implemented subscriptions with channels.\nhttps://github.com/graphql-python/graphene/pull/500#issuecomment-325560994. @miketout awesome, lots of interesting techniques and code there, will definitely be taking a look.. @dfee any ideas on how to use django signals with observables ..?\nI was thinking of doing the same thing you are doing. take a look here \n```\nsubject = rx.subjects.Subject()\nand in the signal consumer have\n@receiver(post_save, sender=Model)\ndef send_update_product(sender, instance, created, args, *kwargs):\n    # I think I might be misunderstanding where I should put this line\n    subject.on_next((instance.pk, created))\n```\n19 def send(result, message):\n 18     data = result.data\n 17     message.reply_channel.send(\n 16         {\n 15             'text': str({'data': json.loads(json.dumps(data))})\n 14         })\n 13\n 12\n 11 @channel_session\n 10 def ws_GQLData(message):\n  9     clean = json.loads(message.content['text'])\n  8     query = clean.get('query')\n  7     foovar = clean.get('variables')\n  6     message.dataloaders = DataLoaders(get_language())\n  5     kwargs = {'context_value': message}\n  4     #  TODO: Implement weight, can this query run for this user or is it too expensive <10-11-17> #\n  3     #  TODO: Implement timeout mechanism <10-11-17> #\n  2     result = schema.execute(query, variable_values=foovar, allow_subscriptions=True, **kwargs)\n  1     if isinstance(result, rx.Observable):\n37          class MyObserver(rx.Observer):\n  1\n  2             def on_next(self, x):\n  3                 send(x, message)\n  4\n  5             def on_error(self, e):\n  6                 ...\n  7\n  8             def on_completed(self):\n  9                 ...\n 10\n 11         result.subscribe(MyObserver())\n 12     else:\n 13         send(result, message)\nProblem I see here . is if the signal is fired from a django instance that the user didn't subscribe to the user wont see the message. \nat the moment im sending the message in the signal with channel groups, but that doesn't take advantage of observables and the user has to re-run the query to get the info they wanted. @ProjectCheshire your solution looks a lot more elegant than what i ended up implementing\n@dfee  I got the observables part down\nhttps://github.com/graphql-python/graphene/issues/430#issuecomment-396015394\nmy solution is so convoluted and the graphql-core package doesn't like that i have loop already running https://github.com/graphql-python/graphene-django/issues/452  it raises an error but doesn't stop thee execution of the subscription.\nThat leads to some issues that I have found a work around, unfortunately that leaves me with some undesired behavior\n that lead me to not  actually using the subscription directly instead I use it to trigger a refetch on the actual query im inteerested in \n``\n   this.subscription = this.props.data.subscribeToMore({\n      document: gql\n        subscription ChangeInProduct($id: ID!) {\n          subProduct(product: $id) {\n            title\n          }\n        }\n      `,\n      variables: { id: this.props.match.params ? this.props.match.params.id : null },\n      updateQuery: (prev, { subscriptionData }) => {\n        if (!subscriptionData.data) {\n          return prev;\n        }\n        console.log('interesting', prev, subscriptionData);\n        this.props.data.refetch()\n        return prev;\n      },\n    });\n```\n. @AgentChris \nHere is how i managed it https://github.com/graphql-python/graphene/pull/500#issuecomment-325560994\nalso look at https://github.com/graphql-python/graphql-core/issues/149. @Oxyrus it seems that the mechanism has been decided to be rx observables but the method for delivery to the client is still up to you.. @tricoder42 interesting code layout, I was using observables to emit subscriptions but I was having problems making django pretend to be async .. Your aproach seems cleaner.\nTo avoid repeating queries you could use promises and dataloaders to group as much repetitive work to just one computation.. @tricoder42 how does django-channels 2.0 make the implementation cleaner?. @tricoder42 I just did some experimenting with Channels 2.0 this is what I have ..\nIm still digging into the Docs. I also don't have much time this days but Ill update once I get something more substantial going.\nNote: line 62, probably needs to be made sync since I don't think on_next can be async\n1   from django.utils.translation import get_language                                                                                                                                                                                                                                                                                                                                                                                     \n  1 import json                                                                                                                                                                                                                                                                                                                                                                                                                           \n  2 # import functools                                                                                                                                                                                                                                                                                                                                                                                                                    \n  3 import asyncio                                                                                                                                                                                                                                                                                                                                                                                                                        \n  4 import rx                                                                                                                                                                                                                                                                                                                                                                                                                             \n  5                                                                                                                                                                                                                                                                                                                                                                                                                                       \n  6 from channels.consumer import AsyncConsumer                                                                                                                                                                                                                                                                                                                                                                                           \n  7                                                                                                                                                                                                                                                                                                                                                                                                                                       \n  8 from graphene_django.settings import graphene_settings as gqsettings                                                                                                                                                                                                                                                                                                                                                                  \n  9 from .views import DataLoaders                                                                                                                                                                                                                                                                                                                                                                                                        \n 10                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 11                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 12 schema = gqsettings.SCHEMA                                                                                                                                                                                                                                                                                                                                                                                                            \n 13                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 14                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 15 class GQLConsumer(AsyncConsumer):                                                                                                                                                                                                                                                                                                                                                                                                     \n 16     # NOTE: asgiref.SyncToAsync for django ORM                                                                                                                                                                                                                                                                                                                                                                                        \n 17                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 18     async def graphsend(self, opID, result, message):                                                                                                                                                                                                                                                                                                                                                                                 \n 19         data = result.data                                                                                                                                                                                                                                                                                                                                                                                                            \n 20         await self.send(                                                                                                                                                                                                                                                                                                                                                                                                              \n 21             {                                                                                                                                                                                                                                                                                                                                                                                                                         \n 22                 'type': 'websocket.send',                                                                                                                                                                                                                                                                                                                                                                                             \n 23                 'text': str(json.dumps({'data': data, 'type': 'data', 'id': opID}))                                                                                                                                                                                                                                                                                                                                                   \n 24             })                                                                                                                                                                                                                                                                                                                                                                                                                        \n 25                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 26     # @allowed_hosts_only                                                                                                                                                                                                                                                                                                                                                                                                             \n 27     async def websocket_connect(self, event):                                                                                                                                                                                                                                                                                                                                                                                         \n 28         # message.reply_channel.send({'accept': True, 'text': json.dumps({'type': 'connection_ack'})})                                                                                                                                                                                                                                                                                                                                \n 29         #  TODO: This might need some security, auth users or apps only <10-11-17> #                                                                                                                                                                                                                                                                                                                                                  \n 30         await self.send({                                                                                                                                                                                                                                                                                                                                                                                                             \n 31             \"type\": \"websocket.accept\",                                                                                                                                                                                                                                                                                                                                                                                               \n 32         })                                                                                                                                                                                                                                                                                                                                                                                                                            \n 33                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 34     async def websocket_receive(self, message):                                                                                                                                                                                                                                                                                                                                                                                       \n 35         # message is gone from the call signature, need to inspect the content of text_data and bytes_data                                                                                                                                                                                                                                                                                                                            \n 36         clean = json.loads(message['text'])                                                                                                                                                                                                                                                                                                                                                                                           \n 37         gqtype = clean.get('type')                                                                                                                                                                                                                                                                                                                                                                                                    \n 38         clean = clean.get('payload')                                                                                                                                                                                                                                                                                                                                                                                                  \n 39                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 40         if gqtype == 'connection_init':                                                                                                                                                                                                                                                                                                                                                                                               \n 41             await self.send({'type': 'websocket.send', 'text': json.dumps({'type': 'connection_ack'})})                                                                                                                                                                                                                                                                                                                               \n 42         elif gqtype == 'start':                                                                                                                                                                                                                                                                                                                                                                                                       \n 43             __import__('pdb').set_trace()                                                                                                                                                                                                                                                                                                                                                                                             \n 44             self.operationName = clean.get('operationName')                                                                                                                                                                                                                                                                                                                                                                           \n 45             self.query = clean.get('query')                                                                                                                                                                                                                                                                                                                                                                                           \n 46             self.foovar = clean.get('variables')                                                                                                                                                                                                                                                                                                                                                                                      \n 47                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 48             # This part acts like a request                                                                                                                                                                                                                                                                                                                                                                                           \n 49             message = dict()                                                                                                                                                                                                                                                                                                                                                                                                          \n 50             message['reply_channel'] = self.channel_name                                                                                                                                                                                                                                                                                                                                                                              \n 51             message['scope'] = self.scope                                                                                                                                                                                                                                                                                                                                                                                             \n 52             message['dataloaders'] = DataLoaders(get_language())                                                                                                                                                                                                                                                                                                                                                                      \n 53             self.kwargs = {'context_value': message}                                                                                                                                                                                                                                                                                                                                                                                  \n 54                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 55             #  TODO: Implement weight, can this query run for this user or is it too expensive <10-11-17> #                                                                                                                                                                                                                                                                                                                           \n 56             #  TODO: Implement timeout mechanism <10-11-17> #                                                                                                                                                                                                                                                                                                                                                                         \n 57             result = schema.execute(self.query, variable_values=self.foovar, allow_subscriptions=True, **self.kwargs)                                                                                                                                                                                                                                                                                                                 \n 58             if isinstance(result, rx.Observable):                                                                                                                                                                                                                                                                                                                                                                                     \n 59                 class MyObserver(rx.Observer):                                                                                                                                                                                                                                                                                                                                                                                        \n 60                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 61                     def on_next(self, x):                                                                                                                                                                                                                                                                                                                                                                                             \n 62                         self.graphsend(self.operationName, x, message)                                                                                                                                                                                                                                                                                                                                                                \n 63                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 64                     def on_error(self, e):                                                                                                                                                                                                                                                                                                                                                                                            \n 65                         ...                                                                                                                                                                                                                                                                                                                                                                                                           \n 66                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 67                     def on_completed(self):                                                                                                                                                                                                                                                                                                                                                                                           \n 68                         ...                                                                                                                                                                                                                                                                                                                                                                                                           \n 69                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 70                 result = result.publish().auto_connect()                                                                                                                                                                                                                                                                                                                                                                              \n 71                 result.subscribe(MyObserver())                                                                                                                                                                                                                                                                                                                                                                                        \n 72         elif gqtype == 'stop':                                                                                                                                                                                                                                                                                                                                                                                                        \n 73             operationName = clean.get('operationName')                                                                                                                                                                                                                                                                                                                                                                                \n 74             await self.channel_layer.group_discard(operationName, self.channel_name)                                                                                                                                                                                                                                                                                                                                                  \n 75         else:                                                                                                                                                                                                                                                                                                                                                                                                                         \n 76             await self.send({'type': 'websocket.send', 'text': json.dumps({'data': 'connection_ack'})})                                                                                                                                                                                                                                                                                                                               \n 77                                                                                                                                                                                                                                                                                                                                                                                                                                       \n 78     async def websocket_disconnect(self):                                                                                                                                                                                                                                                                                                                                                                                             \n 79         if 'Groups' in self.scope['session']:                                                                                                                                                                                                                                                                                                                                                                                         \n 80             for x in self.scope['session']['Groups'].split(','):                                                                                                                                                                                                                                                                                                                                                                      \n 81                 ...                                                                                                                                                                                                                                                                                                                                                                                                                   \n 82                 # for every Group in the session, unsubscribe current connection                                                                                                                                                                                                                                                                                                                                                      \n 83                 await self.channel_layer.group_discard(x, self.channel_name)                                                                                                                                                                                                                                                                                                                                                          \n 84             # finally del the Groups from the session                                                                                                                                                                                                                                                                                                                                                                                 \n 85             del self.scope['session']['Groups']                                                                                                                                                                                                                                                                                                                                                                                       \n~. @kavink graphene is intended to use RXPY for that part, I'm currently trying to work out how to use that with channels so i don't know that much about it but hopefully it leads you down the right road.. @tricoder42 you could try using rx.Observable.from_iterable also take a look at this page for examples, here is a direct link to a relevant example: https://github.com/thomasnield/oreilly_reactive_python_for_data/blob/master/class_notes/class_notes.md#44---an-observable-emitting-tweets\nIm still trying to wrap my head around observables. I like how if the resolve method for the subscription receives an object instance it publishes a new result.. @tricoder42 what query are you using with your code? doesn't the model get read from the database for each subscriber?\nDid you mean to pass an observer to your stream initiation here L71 ?. @tricoder42 how about using dataloaders from promises to fetch the instance so that the db is only hit once per process?. hey quick follow up, has anyone managed to make an asyncronous consumer for subscriptions ?\ncurrently im using concurrent threads as the executor but im switch over to \nfrom graphql.execution.executors.asyncio import AsyncioExecutor\nIm mocking out some code .. here is what i have so far \n```\nfrom django.utils.translation import get_language\nfrom asgiref.sync import SyncToAsync\nimport json\nimport functools\nimport asyncio\nimport concurrent.futures\nimport rx\nfrom rx.subjects import Subject\nfrom rx.concurrency import AsyncIOScheduler\nfrom channels.consumer import AsyncConsumer\nfrom channels.exceptions import StopConsumer\nfrom graphene_django.settings import graphene_settings as gqsettings\nfrom .views import DataLoaders\nschema = gqsettings.SCHEMA\nclass GQLConsumer(AsyncConsumer):\n    # NOTE: asgiref.SyncToAsync for django ORM\ndef __init__(self, scope):\n    super().__init__(scope)\n    # keeps a record of streams\n    self.subscriptions = {}\n    # keeps a record of groups the connection belongs to\n    self.groups = {}\n    # scheduler\n    # self.scheduler = AsyncIOScheduler()\n\n# @allowed_hosts_only\nasync def websocket_connect(self, event):\n    # message.reply_channel.send({'accept': True, 'text': json.dumps({'type': 'connection_ack'})})\n    #  TODO: This might need some security, auth users or apps only <10-11-17> #\n    await self.send({\n        \"type\": \"websocket.accept\",\n        \"subprotocol\": \"graphql-ws\",\n    })\n\nasync def websocket_receive(self, message):\n    # message is gone from the call signature, need to inspect the content of text_data and bytes_data\n    request = json.loads(message['text'])\n\n    if request['type'] == 'connection_init':\n        await self.send(\n            {\n                'type': 'websocket.send',\n                'text': json.dumps({'type': 'connection_ack'})\n            })\n    elif request['type'] == 'start':\n        payload = request.get('payload')\n        id = request.get('id')\n\n        # This part acts like a request, QUESTION: should this be a dict like object that set/get from the self.scope?\n        message = dict()\n        message['id'] = id\n        message['reply_channel'] = self.channel_name\n        message['scope'] = self.scope\n        message['groups'] = self.groups\n        message['dataloaders'] = DataLoaders(get_language())\n\n        stream = Subject()\n        #  TODO: Implement weight, can this query run for this user or is it too expensive <10-11-17> #\n        #  TODO: Implement timeout mechanism <10-11-17> #\n        # result = await SyncToAsync(schema.execute)(self.query, variable_values=self.foovar, allow_subscriptions=True, **self.kwargs)\n        result = asyncio.wait_for(\n                                  schema.execute(\n                                      payload['query'],\n                                      operation_name=request['operationName'],\n                                      variable_values=payload['variables'],\n                                      executor=concurrent.futures.ThreadPoolExecutor(),\n                                      root_value=Observable.create(stream).share(),\n                                      allow_subscriptions=True,\n                                      **{'context_value': message})\n                                  )\n\n        if isinstance(result, rx.Observable):\n            result = result.publish().auto_connect()\n            result.subscribe(functools.partial(self._send_result, id))\n            self.subscriptions[id] = stream\n        else:\n            self._send_result(id, result)\n    elif request['type'] == 'stop':\n        operationName = request.get('operationName')\n        await self.channel_layer.group_discard(operationName, self.channel_name)\n\nasync def websocket_disconnect(self):\n    for group in self.groups.keys():\n        await self.channel_layer.group_discard(group, self.channel_name)\n\n    await self.send({\n        \"type\": \"websocket.close\", \"code\": 1000\n    })\n    raise StopConsumer()\n\nasync def _send_result(self, id, result):\n    errors = result.errors\n\n    await self.send({\n        'type': 'websocket.send',\n        'text': json.dumps({\n            'id': id,\n            'type': 'data',\n            'payload': {\n                'data': result.data,\n                'errors': list(map(str, errors)) if errors else None,\n            }\n        })\n    })\n\ndef model_changed(self, message):\n    forwhat = message['models']\n    ...\n\n```. ok Im a bit closer to having an async consumer.. however there is one small issue.\nLet me go into detail before you get to the code. currently I am attempting to use an async executor to run the schema .. that however causes the result not to return an observable but a\n \nthe errors property returns this \n[RuntimeError('This event loop is already running',)]\nso I would expect that the schema not to execute since these error should mark the end of the execution and nothing should be resolve .. however some strange behaviour occours ..\nI set a brake point inside of the resolve method for the subscription and after the schema executes and is returned that brake point is hit\n```\n\n/app/apple/graphquery/consumers.py(74)websocket_receive()\n-> result = schema.execute(\n(Pdb) c\n/app/apple/graphquery/consumers.py(84)websocket_receive()\n-> if isinstance(result, rx.Observable):\n(Pdb) result\n\n(Pdb) result.errors\n[RuntimeError('This event loop is already running',)]\n(Pdb) c\n/app/apple/product/schema.py(179)resolve_sub_product()\n-> await make_sub(info, input.get('product'))\n(Pdb) ll\n177         async def resolve_sub_product(self, info, input):\n178             import('pdb').set_trace()\n179  ->         await make_sub(info, input.get('product'))\n180             name = ProductType._meta.model.class.name\n181\n182             stream = info.root_value\n183             return stream.map(lambda message: self.next(message, info, input))\n(Pdb)\n```\n\nhere is what the updated consumer looks like \n```\nfrom django.utils.translation import get_language\nfrom asgiref.sync import SyncToAsync\nfrom rx.subjects import Subject\nfrom rx.concurrency import AsyncIOScheduler\nfrom channels.consumer import AsyncConsumer\nfrom channels.exceptions import StopConsumer\nfrom graphql.execution.executors.asyncio import AsyncioExecutor\nfrom graphql import graphql\nfrom graphene_django.settings import graphene_settings as gqsettings\nfrom .views import DataLoaders\nimport rx\nimport json\nimport json\nimport functools\nimport asyncio\nimport functools\nimport asyncio\nschema = gqsettings.SCHEMA\nclass GQLConsumer(AsyncConsumer):\n    # NOTE: asgiref.SyncToAsync for django ORM\ndef __init__(self, scope):\n    super().__init__(scope)\n    # keeps a record of streams\n    self.subscriptions = {}\n    # keeps a record of groups the connection belongs to\n    self.groups = {}\n    # self.executor = AsyncioExecutor(loop=asyncio.get_event_loop())\n\n# @allowed_hosts_only\nasync def websocket_connect(self, event):\n    # message.reply_channel.send({'accept': True, 'text': json.dumps({'type': 'connection_ack'})})\n    #  TODO: This might need some security, auth users or apps only <10-11-17> #\n    await self.send({\n        \"type\": \"websocket.accept\",\n        \"subprotocol\": \"graphql-ws\",\n    })\n\nasync def websocket_receive(self, message):\n    # message is gone from the call signature, need to inspect the content of text_data and bytes_data\n    request = json.loads(message['text'])\n\n    if request['type'] == 'connection_init':\n        await self.send(\n            {\n                'type': 'websocket.send',\n                'text': json.dumps({'type': 'connection_ack'})\n            })\n    elif request['type'] == 'start':\n        payload = request.get('payload')\n        id = request.get('id')\n\n        # This part acts like a request, QUESTION: should this be a dict like object that set/get from the self.scope?\n        message = dict()\n        message['id'] = id\n        message['reply_channel'] = self.channel_name\n        message['scope'] = self.scope\n        message['subscribe'] = functools.partial(self._subscribe, id)\n        message['dataloaders'] = DataLoaders(get_language())\n\n        stream = Subject()\n        #  TODO: Implement weight, can this query run for this user or is it too expensive <10-11-17> #\n        #  TODO: Implement timeout mechanism <10-11-17> #\n        # result = await SyncToAsync(schema.execute)(self.query, variable_values=self.foovar, allow_subscriptions=True, **self.kwargs)\n        __import__('pdb').set_trace()\n        result = schema.execute(\n                      payload['query'],\n                      variable_values=payload['variables'],\n                      root_value=rx.Observable.create(stream).share(),\n                      allow_subscriptions=True,\n                      executor=AsyncioExecutor(loop=asyncio.get_event_loop()),\n                      **{'context_value': message})\n        isinstance(result, rx.Observable)\n        __import__('pdb').set_trace()\n\n        if isinstance(result, rx.Observable):\n            result = result.publish().auto_connect()\n            result.subscribe(functools.partial(self._send_result, id))\n            self.subscriptions[id] = stream\n        else:\n            self._send_result(id, result)\n    elif request['type'] == 'stop':\n        await _unsubscribe(request)\n\nasync def websocket_disconnect(self, *args, **kwargs):\n    for group in self.groups.keys():\n        await self.channel_layer.group_discard(group, self.channel_name)\n\n    await self.send({\n        \"type\": \"websocket.close\", \"code\": 1000\n    })\n    raise StopConsumer()\n\ndef _subscribe(self, id, gp_name):\n    group = self.groups.setdefault(gp_name, set())\n    self.groups[gp_name].add(id)\n\nasync def _unsubscribe(self, request):\n        operationName = request.get('operationName')\n        await self.channel_layer.group_discard(operationName, self.channel_name)\n        id = request.get('id')\n        del self.subscriptions[id]\n\nasync def _send_result(self, id, result):\n    errors = result.errors\n    await self.send({\n        'type': 'websocket.send',\n        'text': json.dumps({\n            'id': id,\n            'type': 'data',\n            'payload': {\n                'data': result.data,\n                'errors': list(map(str, errors)) if errors else None,\n            }\n        })\n    })\n\nasync def model_changed(self, message):\n    __import__('pdb').set_trace()\n    gp_name = message['gp_name']\n    pk = message['pk']\n\n    for id in self.groups.get(gp_name, []):\n        stream = self.subscriptions.get(id)\n        if not stream:\n            continue\n        stream.on_next((pk, model))\n\n```\nThe misterous async subscription that executes after it fails to execute ...\n```\nclass ProductSubscritption(object):\n\"\"\"test\"\"\"\nsub_product = graphene.Field(\n    ProductType,\n    description='subscribe to updated product',\n    product=graphene.ID())\n\nasync def resolve_sub_product(self, info, **input):\n    __import__('pdb').set_trace()\n    await make_sub(info, input.get('product'))\n    name = ProductType._meta.model.__class__.__name__\n\n    stream = info.root_value\n    return stream.map(lambda message: self.next(message, info, **input))\n\n@classmethod\ndef next(cls, message, info, **input):\n    # here the message comes from the stream but the info and **input come frome\n    # subscribing to the next method to the stream\n    inst = relay.Node.get_node_from_global_id(info, input.get('product'))\n    return inst\n\nand the signal register, this doesn't seem to be related to the issue im having but just in case you would like to look at it\nfrom asgiref.sync import AsyncToSync\nfrom channels.layers import get_channel_layer\nfrom graphene import relay\nfrom graphql_relay import from_global_id as fgi  # , to_global_id\nfrom promise.dataloader import DataLoader\nfrom promise import Promise\nimport json\nchannel_layer = get_channel_layer()\ngroup_send = AsyncToSync(channel_layer.group_send)\ndef send_update(sender, instance, created, attr='pk', args, *kwargs):\n    value = str(getattr(instance, attr))\n    payload = {\n        'type': 'model.changed',\n        'pk': instance.pk,\n        'attr': value,\n        'created': created,\n    }\n    # if the instance was created, send to channels listening for created\n    if created:\n        group_send(\n                'gqp.{0}-add'.format(str.lower(instance.class.name)),\n                payload\n            )\n        return\n    # pk is prefered if available over the provided attr\n    if hasattr(instance, 'pk'):\n        name = getattr(instance, 'pk')\n    else:\n        name = value\n    gp_name = 'gqp.{0}-updated.{1}'.format(str.lower(instance.class.name), name)\n    payload['gp_name'] = gp_name\n# If the item was updated, send signal to channels listening for updates\ngroup_send(\n        gp_name,\n        payload\n    )\n\nasync def make_sub(info, gid):\n    inst = relay.Node.get_node_from_global_id(info, gid)\n    try:\n        gp_name = 'gqp.{0}-updated.{1}'.format(str.lower(inst.class.name), inst.pk)\n        # Group(gp_name).add(info.context.reply_channel)\n        # info.context.channel_session['Groups'] = ','.join( (gp_name, info.context.channel_session['Groups']))\n        await channel_layer.group_add(\n                gp_name,\n                info.context['reply_channel']\n            )\n        subscribe = info.context['subscribe']\n        if subscribe:\n            subscribe(gp_name)\n    except:\n        pass\n```\nhere im going to tag some people, \n@tricoder42 @prokher @hballard @syrusakbary \ngetting closer : https://github.com/graphql-python/graphql-core/issues/63#issuecomment-396017113. I figured it out, \njust needed this line to get async observable working\nresult.subscribe(lambda t: loop.create_task(self._send_result( id, t)))\ncurrently using a work around for this issue https://github.com/graphql-python/graphene-django/issues/452\nThis is the work around, instead of using subscriptions directly .. I use them to trigger regular queries\n``\n  subscribeToNewMessages() {\n    this.subscription = this.props.data.subscribeToMore({\n      document: gql\n        subscription ChangeInProduct($id: ID!) {\n          subProduct(product: $id) {\n            title\n          }\n        }\n      `,\n      variables: { id: this.props.match.params ? this.props.match.params.id : null },\n      updateQuery: (prev, { subscriptionData }) => {\n        if (!subscriptionData.data) {\n          return prev;\n        }\n        console.log('interesting', prev, subscriptionData);\n        this.props.data.refetch()\n        return prev;\n      },\n    });\n  }\n```\n. @syrusakbary Hello, I know that subscriptions are going to be implemented in graphene soon but i just want to share how I managed to get them working with channels.\n\n\nfirst I made a route for both http and ws \n1                                                                                                                                                                                                                                                                                                                                                         \n4   channel_routing = [                                                                                                                                                                                                                                                                                                                                     \n  1             route('http.request', ws_GQLData, path=r\"^/gql\"),                                                                                                                                                                                                                                                                                           \n  2             route('websocket.connect', ws_GQL_connect, path=r\"^/gql\"),                                                                                                                                                                                                                                                                                  \n  3             route('websocket.receive', ws_GQLData, path=r\"^/gql\"),                                                                                                                                                                                                                                                                                      \n      ...                                                                                                                                                                                                                                                                                \n  6         ]\n\n\nthan i accepted the connection\n```\n@allowed_hosts_only\ndef ws_GQL_connect(message):\n    message.reply_channel.send({\"accept\": True})\n\n\n- parsed the request and executed the query\n@channel_session                                                                                                                                                                                                                                                                                                                                          \ndef ws_GQLData(message):                                                                                                                                                                                                                                                                                                                                  \n    clean = json.loads(message.content['text'])                                                                                                                                                                                                                                                                                                           \n    try:                                                                                                                                                                                                                                                                                                                                                  \n        query = clean['query']                                                                                                                                                                                                                                                                                                                            \n    except:                                                                                                                                                                                                                                                                                                                                               \n        query = None                                                                                                                                                                                                                                                                                                                                      \n    try:                                                                                                                                                                                                                                                                                                                                                  \n        foovar = clean['variables']                                                                                                                                                                                                                                                                                                                       \n    except:                                                                                                                                                                                                                                                                                                                                               \n        foovar = None                                                                                                                                                                                                                                                                                                                                     \n    kwargs = {'context_value': message}                                                                                                                                                                                                                                                                                                                   \n    result = schema.execute(query, variable_values=foovar,  **kwargs)                                                                                                                                                                                                                                                                                     \n    message.reply_channel.send(                                                                                                                                                                                                                                                                                                                           \n        {                                                                                                                                                                                                                                                                                                                                                 \n            'text': str({'data': json.loads(json.dumps(result.data))})                                                                                                                                                                                                                                                                                    \n        })        \n- Subscription class that adds user to Group\nclass ProductSubscritption(object):\n\"\"\"test\"\"\"\nsub_product = graphene.Field(ProductType, description='subscribe to updated product', uuid=graphene.String())\n\ndef resolve_sub_product(self, info, **args):\n    uuid = args.get('uuid')\n    qs = ProductType.get_queryset()\n    try:\n        Group('gqp.product-updated.{0}'.format(uuid)).add(info.context.reply_channel)\n    except:\n        pass\n    return qs.get(uuid=uuid)\n\n```\n\npost_save receiver that sends messages, Note: here the client only receives the uuid that was updated,\n    than it is up to the client to do another query to get the specific fields they want from that object if any\n```\n\n@receiver(post_save, sender=Product)\ndef send_update(sender, instance, created, args, *kwargs):\n    uuid = str(instance.uuid)\n    if created:\n        Group(\"gqp.product-add\").send({'added': True})\n        return\n    Group('gqp.product-updated.{0}'.format(uuid))\\\n        .send({'text': uuid})\n```\n\nthan finally the js\n\nsocket = new WebSocket(\"ws://\" + window.location.host + \"/gql\");\nsocket.onmessage = function(e) {\n    alert(e.data);\n}\nsocket.send(JSON.stringify({query: 'subscription {\\\n  subProduct (uuid: \"714a3f4f-4a21-4ff9-b058-f12ad6389f72\"){\\\n    id,\\\n    disabled,\\\n    title,\\\n  }\\\n}'})). @AgentChris ProductType is the DjangoObjectType\nmine looks like this, / dont worry about TypeMixin or the resolver /\n25 class ProductType(TypeMixin, DjangoObjectType):\n 26     attr = 'uuid'\n 27\n 28     \"\"\"Query API def for Product\"\"\"\n 29\n 30     class Meta:\n 31         model = Product\n 32         only_fields = ('uuid', 'owner', 'title', 'active', 'disabled', 'description')\n 33\n 34         interfaces = (relay.Node, )\n 35\n 36     def resolve_id(self, info, **args):\n 37 \n           return str(self.uuid)\n. @AgentChris are you spliting the link so that subscriptions get routed to ws?\nAnd what are the errors you are getting ?\nThe way I am planning on using the subscription is every time I get an update on that channel I invalidate and schedule a different query, thus causing the data to be re-fetch and my component to update.. @AgentChris Oh, also you might want to look at the actual post data send by apollo,\nIm sure that the lines like query = clean['query'] might not be working because of that .. im in the process of implementing subscriptions with apollo .. will have answer in a while. @AgentChris Im currently trying to get apollo to connect to my django implementation of subscriptions if you want to track my progress, I ran into an issue here\nhttps://github.com/apollographql/subscriptions-transport-ws/issues/319. @BossGrand wouldn't the user need to query for errors on the mutation?\nIf the user does a mutation without requesting the errors field, they won't see anything.. I see, so I don't have to do anything special in the input class?\nthanks will try.. I was still using context instead of info.context now it works \ud83d\udc4d . wonder if there is any relation to #538 . @syrusakbary thanks \ud83d\udc4d . Hi im having issues now, that I have revisited this issue, \nPlease look at thiss\nhttps://github.com/graphql-python/graphene/issues/430#issuecomment-396015394\nI have tried also the snipet @syrusakbary suggested above like this \n```\n            import('pdb').set_trace()\n            result = asyncio.wait_for(schema.execute(\n                          payload['query'],\n                          variable_values=payload['variables'],\n                          root_value=rx.Observable.create(stream).share(),\n                          allow_subscriptions=True,\n                          executor=AsyncioExecutor(loop=asyncio.get_event_loop()),\n                          **{'context_value': message}), 1)\n            result = next(result)\n            import('pdb').set_trace()\n```\nand received this \n```\n\n/app/apple/graphquery/consumers.py(75)websocket_receive()\n-> result = asyncio.wait_for(schema.execute(\n(Pdb) c\n/app/apple/product/schema.py(179)resolve_sub_product()\n-> await make_sub(info, input.get('product'))\n(Pdb) result\n NameError: name 'result' is not defined\n(Pdb) ll\n177         async def resolve_sub_product(self, info, *input):\n178             import('pdb').set_trace()\n179  ->         await make_sub(info, input.get('product'))\n180             name = ProductType._meta.model.class.name\n181\n182             stream = info.root_value\n183             return stream.map(lambda message: self.next(message, info, input))\n(Pdb) n\n2018-06-10 03:33:01,667 - ERROR - server - Exception inside application: An asyncio.Future, a coroutine or an awaitable is required\n  File \"/usr/local/lib/python3.6/site-packages/channels/sessions.py\", line 175, in call\n    return await self.inner(receive, self.send)\n  File \"/usr/local/lib/python3.6/site-packages/channels/consumer.py\", line 54, in call\n    await await_many_dispatch([receive, self.channel_receive], self.dispatch)\n  File \"/usr/local/lib/python3.6/site-packages/channels/utils.py\", line 50, in await_many_dispatch\n    await dispatch(result)\n  File \"/usr/local/lib/python3.6/site-packages/channels/consumer.py\", line 67, in dispatch\n    await handler(message)\n  File \"/app/apple/graphquery/consumers.py\", line 75, in websocket_receive\n    result = asyncio.wait_for(schema.execute(\n  File \"/usr/local/lib/python3.6/asyncio/tasks.py\", line 345, in wait_for\n    fut = ensure_future(fut, loop=loop)\n  File \"/usr/local/lib/python3.6/asyncio/tasks.py\", line 526, in ensure_future\n    raise TypeError('An asyncio.Future, a coroutine or an awaitable is '\n  An asyncio.Future, a coroutine or an awaitable is required\n[2018/06/10 03:33:01] WebSocket DISCONNECT /gql [10.255.0.2:53120]\n/app/apple/product/schema.py(180)resolve_sub_product()\n-> name = ProductType._meta.model.class.name\n(Pdb)\n\n```. also this \n```\nFile \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n2018-06-10 03:38:54,786 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n[2018/06/10 03:38:54] WebSocket HANDSHAKING /gql [10.255.0.2:53170]\n[2018/06/10 03:38:54] WebSocket CONNECT /gql [10.255.0.2:53170]\nDJANGO DEBUG TOOLBAR  OK\n[2018/06/10 03:38:55] HTTP GET /service-worker.js 200 [0.10, 10.255.0.2:53174]\n[2018/06/10 03:38:58] WebSocket DISCONNECT /gql [10.255.0.2:53170]\nDJANGO DEBUG TOOLBAR  OK\n[2018/06/10 03:38:59] HTTP GET /admin/ 200 [0.36, 10.255.0.2:53178]\n2018-06-10 03:38:59,280 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\nDJANGO DEBUG TOOLBAR ___ OK\n[2018/06/10 03:39:03] HTTP GET /admin/product/product/ 200 [0.27, 10.255.0.2:53184]\n2018-06-10 03:39:04,070 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\nDJANGO DEBUG TOOLBAR ___ OK\n2018-06-10 03:39:04,084 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n[2018/06/10 03:39:04] HTTP GET /admin/jsi18n/ 200 [0.05, 10.255.0.2:53188]\n2018-06-10 03:39:04,178 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\nDJANGO DEBUG TOOLBAR  OK\n[2018/06/10 03:39:06] HTTP GET /admin/product/product/1/change/ 200 [0.30, 10.255.0.2:53194]\nDJANGO DEBUG TOOLBAR  OK\n2018-06-10 03:39:06,579 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n2018-06-10 03:39:06,583 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n2018-06-10 03:39:06,585 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n[2018/06/10 03:39:06] HTTP GET /admin/jsi18n/ 200 [0.11, 10.255.0.2:53194]\n2018-06-10 03:39:06,662 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\nDJANGO DEBUG TOOLBAR  OK\n[2018/06/10 03:39:11] HTTP POST /admin/product/product/1/change/ 302 [0.20, 10.255.0.2:53206]\nDJANGO DEBUG TOOLBAR  OK\n[2018/06/10 03:39:12] HTTP GET /admin/product/product/ 200 [0.27, 10.255.0.2:53206]\nDJANGO DEBUG TOOLBAR ___ OK\n[2018/06/10 03:39:12] HTTP GET /admin/jsi18n/ 200 [0.05, 10.255.0.2:53206]\n2018-06-10 03:39:12,235 - ERROR - http_protocol - Traceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/twisted/internet/defer.py\", line 1386, in _inlineCallbacks\n    result = g.send(result)\nStopIteration: \nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/daphne/http_protocol.py\", line 166, in process\n    \"body\": self.content.read(),\nValueError: I/O operation on closed file.\n``. @syrusakbary even tho my resolve returns an observable and is an async function whenever i pass   return_promise=True, to execute i get this error[GraphQLError('Subscription must return Async Iterable or Observable. Received: ',)]`\n. Like a custom Scalar ?. could you change the resolve method to be, \ndef resolve_value(self, info, **args):\n     if hasattr(self, 'value'):\n         if self.value:\n              return self.value\n      return 12345. I found a work around, To create my own input with custom meta and stuff\nmine is to have this\n```\nclass SomeInput:\n    class Meta:\n             stuff\n    def new(cls):\n        # do stuff with meta class\n        return type('test', (InputObjectType),  ... )\nSomeInput = SomeInput()\n```. Is there a method where the node that connects to an edge is passed into where I can then use to to set the appropriate value for the field on the edge\nsomething maybe like this:\n```\nclass User(graphene.ObjectType):\n    '''A ship in the Star Wars saga'''\n    class Meta:\n        interfaces = (relay.Node, )\n    name = graphene.String(description='The name of the User.')\nclass ShipConnection(Connection):\n    extra = String()\nclass Meta:\n    # Ship is a Typeobject\n    node = Ship\n\nclass Edge:\n    other = String()\n\n    def resolve_other(self, info, **args):\n          '''\n          here I imagine self being the node value for this edge\n          '''\n          return self.value\n\n```\nIn the documentation I see no refrence on how to resolve for fields on edges!. well, It looks like the above code works but I would like to have access to the User from which all edges originate ... from within each edge.\ncurrently I have access to the Node Ship In Edge but not the User that connects them .. well, I found a way to work around the problem I was having. so I guess Ill be closing this.. How are you doing CRUD?\ndo you mean the type and Input declaration? are you using graphene with django?. you could try making a class, that takes that boiler plate away.\nRight know im using graphene-django's construct_fields method in a class generator, it generates the input class for the mutations,that take some of the boiler plate away. \nIm also working on making generic CRUD classes to take away most of the boiler plate. \nBut for know I wrote a long snippet that at least makes writting them a little faster.. Probably because graphene is design to be agnostic on how the data is retrieved.. ... altho I can think of one instance where graphene and more specifically relay could be more agnostic and make less assumptions about how data is retrieved. And that is in relay.Connection.\nhmm, I should open an issue about this.. Could create a class that generates a class with the correct mutations. The class could have a Meta class that has a Interface as an attribute. It could than infer that it has standard method names for CRUD.\nIt could than create an ObjectType with the correct mutation interface. you could use\ninspect.getargspec(foo)\nto inspect the call signature of function foo combined with pythons new type system it would be trivial to get the appropriate field type from the call signature. \nThan simply add appropriate attributes to the generated class.. This doesn't seem to be a graphene problem as detailed here \nhttp://django-parler.readthedocs.io/en/latest/advanced/mptt.html#combining-managers. The reason I need to use the django Paginator with the connection is because if i slice the queryset in the resolver for that ConnectionField than the connection field will not know that it has already been sliced, the list, and it will try to slice the list again in the slice method, and the pageinfo in the connection will be wrong. Also PageInfo isn't really a page info more like a slice info.\nhttps://github.com/graphql-python/graphql-relay-py/blob/17ce2efa3c396df42791ae00667120b5fae64610/graphql_relay/connection/arrayconnection.py#L32. Well I did it \ud83d\ude04 \nThis is how my queries look now \n```\n{\n  wish(pk: \"2\") {\n    title\n    products (page: 1) {\n      pageInfo {\n        Count\n        NumPages\n        hasNext\n        hasPrevious\n        hasOtherPages\n        nextPageNumber\n        previousPageNumber\n        startIndex\n        endIndex\n      }\n      edges {\n        through{\n          reason\n          qty\n        }\n        node {\n          active\n          title\n        }\n      }\n    }\n  }\n}\nand this is what I get back\n{\n  \"data\": {\n    \"wish\": {\n      \"title\": \"testme\",\n      \"products\": {\n        \"pageInfo\": {\n          \"Count\": 2,\n          \"NumPages\": 1,\n          \"hasNext\": false,\n          \"hasPrevious\": false,\n          \"hasOtherPages\": false,\n          \"nextPageNumber\": null,\n          \"previousPageNumber\": null,\n          \"startIndex\": 1,\n          \"endIndex\": 2\n        },\n        \"edges\": [\n          {\n            \"through\": {\n              \"reason\": \"Added this Car to test\",\n              \"qty\": 1\n            },\n            \"node\": {\n              \"active\": false,\n              \"title\": \"This is Item is a Car\"\n            }\n          },\n          {\n            \"through\": {\n              \"reason\": \"Needs more cowbell\",\n              \"qty\": 7\n            },\n            \"node\": {\n              \"active\": true,\n              \"title\": \"CowBell\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n```\n. shure, I have a few extra stuff related to my implementation, here is the meat and potatoes of it tho simplified to work with your example here is a quick example.\nNot aware of a simpler way, maybe to just use a resolver for page info, you could maybe pass the info you need into the resolver some other way.\n``` \n 33 class MyConnectionField(relay.ConnectionField):                                                                                                                                                                                                                                                                                                                                                 | |\n 32                                                                                                                                                                                                                                                                                                                                                                                        | |\n 31     \"\"\"PQCField Is a custom ConnectionField that works with a django Paginator \"\"\"                                                                                                                                                                                                                                                                                                     | |\n 30     def init(self, *args, kwargs):                                                                                                                                                                                                                                                                                                                                               | |\n 29         kwargs.setdefault('page', Int(description='Page to retrieve'))                                                                                                                                                                                                                                                                                                                 | |\n 28         kwargs.setdefault('perpage', Int(description='Items per page'))                                                                                                                                                                                                                                                                                                                | |\n 27         super().init(*args, kwargs)                                                                                                                                                                                                                                                                                                                                              | |\n 26         remove = ['before', 'after', 'first', 'last']                                                                                                                                                                                                                                                                                                                                  | |\n 25         for x in remove:                                                                                                                                                                                                                                                                                                                                                               | |\n 24             self.args.pop(x, None)                                                                                                                                                                                                                                                                                                                                                     | |\n 23                                                                                                                                                                                                                                                                                                                                                                                        | |\n 22     @classmethod                                                                                                                                                                                                                                                                                                                                                                       | |\n 21     def resolve_connection(cls, connection_type, args, resolved):                                                                                                                                                                                                                                                                                                                      | |\n 20         if isinstance(resolved, connection_type):                                                                                                                                                                                                                                                                                                                                      |4|\n 19             return resolved                                                                                                                                                                                                                                                                                                                                                            | |\n 18                                                                                                                                                                                                                                                                                                                                                                                        | |\n 17         assert isinstance(resolved, Iterable) or isinstance(resolved, Paginator), (                                                                                                                                                                                                                                                                                                    | |\n 16             'Resolved value from the connection field have to be iterable or instance of {}. '                                                                                                                                                                                                                                                                                         | |\n 15             'or an instance of Paginator'                                                                                                                                                                                                                                                                                                                                              | |\n 14             'Received \"{}\"'                                                                                                                                                                                                                                                                                                                                                            | |\n 13         ).format(connection_type, resolved)                                                                                                                                                                                                                                                                                                                                            | |\n 12                                                                                                                                                                                                                                                                                                                                                                                        | |\n 11         if isinstance(resolved, Iterable):                                                                                                                                                                                                                                                                                                                                             | |\n 10             resolved = Paginator(resolved, 20)                                                                                                                                                                                                                                                                                                                                         | |\n  9                                                                                                                                                                                                                                                                                                                                                                                        | |\n  8         connection = connection_from_paginator(                                                                                                                                                                                                                                                                                                                                        | |\n  7             resolved,                                                                                                                                                                                                                                                                                                                                                                  | |\n  6             args,                                                                                                                                                                                                                                                                                                                                                                      | |\n  5             connection_type=connection_type,                                                                                                                                                                                                                                                                                                                                           | |\n  4             edge_type=connection_type.Edge,                                                                                                                                                                                                                                                                                                                                            | |\n  3             pageinfo_type=PaginatorInfo                                                                                                                                                                                                                                                                                                                                                | |\n  2         )                                                                                                                                                                                                                                                                                                                                                                              | |\n  1         connection.iterable = resolved                                                                                                                                                                                                                                                                                                                                                 | |\n128         return connection\n| 36 def connection_from_paginator(list_slice, args=None, connection_type=None,                                                                                                                                                                                                                                                                                                             |\n | 35                               edge_type=None, pageinfo_type=None, **kwargs):                                                                                                                                                                                                                                                                                                           |\n | 34     '''                                                                                                                                                                                                                                                                                                                                                                                |\n | 33     Given a slice (subset)from a Paginator, returns a connection object for use in                                                                                                                                                                                                                                                                                                     |\n | 32     GraphQL.                                                                                                                                                                                                                                                                                                                                                                           |\n | 31     This function is similar to connectionFromArray, but is intended for use                                                                                                                                                                                                                                                                                                         |\n | 30     cases where you know the cardinality of the connection, consider it too large                                                                                                                                                                                                                                                                                                      |\n | 29     to materialize the entire array, and instead wish pass in a slice of the                                                                                                                                                                                                                                                                                                           |\n | 28     total result large enough to cover the range specified in args.                                                                                                                                                                                                                                                                                                                  |\n | 27     '''                                                                                                                                                                                                                                                                                                                                                                                |\n | 26     connection_type = connection_type                                                                                                                                                                                                                                                                                                                                                  |\n | 25     edge_type = edge_type or Edge                                                                                                                                                                                                                                                                                                                                                      |\n | 24     pageinfo_type = pageinfo_type                                                                                                                                                                                                                                                                                                                                                      |\n | 23                                                                                                                                                                                                                                                                                                                                                                                        |\n | 22     args = args or {}                                                                                                                                                                                                                                                                                                                                                                  |\n | 21     page = args.get('page', 1)                                                                                                                                                                                                                                                                                                                                                         |\n | 20                                                                                                                                                                                                                                                                                                                                                                                        |\n | 19     try:                                                                                                                                                                                                                                                                                                                                                                               |\n | 18         _slice = list_slice.page(page)                                                                                                                                                                                                                                                                                                                                                 |\n | 17     except PageNotAnInteger:                                                                                                                                                                                                                                                                                                                                                           |\n | 16         # If page is not an integer, deliver first page.                                                                                                                                                                                                                                                                                                                               |\n | 15         page = 1                                                                                                                                                                                                                                                                                                                                                                       |\n | 14         _slice = list_slice.page(page)                                                                                                                                                                                                                                                                                                                                                 |\n | 13     except InvalidPage:                                                                                                                                                                                                                                                                                                                                                                |\n | 12         # If page is out of range (e.g. 9999), deliver last page of results.                                                                                                                                                                                                                                                                                                           |\n | 11         page = list_slice.num_pages                                                                                                                                                                                                                                                                                                                                                    |\n | 10         _slice = list_slice.page(page)                                                                                                                                                                                                                                                                                                                                                 |\n |  9                                                                                                                                                                                                                                                                                                                                                                                        |\n |  8     edges = [                                                                                                                                                                                                                                                                                                                                                                          |\n |  7         edge_type(                                                                                                                                                                                                                                                                                                                                                                     |\n |  6             node=node,                                                                                                                                                                                                                                                                                                                                                                 |\n |  5             cursor=offset_to_cursor(page, page + i)                                                                                                                                                                                                                                                                                                                                    |\n |  4         )                                                                                                                                                                                                                                                                                                                                                                              |\n |  3         for i, node in enumerate(_slice)                                                                                                                                                                                                                                                                                                                                               |\n |  2     ]                                                                                                                                                                                                                                                                                                                                                                                  |\n |  1     page = pageinfo_type()                                                                                                                                                                                                                                                                                                                                                             |\n |44      setattr(page, 'pcursor', list_slice)                                                                                                                                                                                                                                                                                                                                               |\n |  1     setattr(page, 'cpage', _slice)                                                                                                                                                                                                                                                                                                                                                     |\n |  2     return connection_type(                                                                                                                                                                                                                                                                                                                                                            |\n |  3             edges=edges,                                                                                                                                                                                                                                                                                                                                                               |\n |  4             page_info=page                                                                                                                                                                                                                                                                                                                                                             |\n |  5         )\nclass PaginatorInfo(graphene.ObjectType):\n      pcursor = None\n      cpage = None\n      count = graphene.Int(name='Count', description='Total count')\n      def resolve_count(self, info, **args):\n          return self.pcursor.count\nclass MyConnection(relay.Connection):\n     page_info = graphene.Field(PaginatorInfo, required=True)\n     class Meta:\n          node = SomeType\nclass MyType(DjangoObjectType):\n       somemodel = MyConnectionField(MyConnection)\n       def resolve_somemodel(self, info, **args):\n            return Paginator(somemodel.objects.all(), 30)\n```\n. hello, the  ` @client` directive has become very popular\n\nis there a way to have a list of directives that graphene should just ignore, since they are used client side.?. @alexpantyukhin it is a directive used with the apollo client to reference its local cache. . @syrusakbary my error, \ndid this \ngraphene.string() \ninstead of \ngraphene.String(). forgot to close this, the decorator class that the snippet above belonged to didn't explicitly inherit from object and apparently that needs to be a thing in python 2.7 for me to be able to call the call method of a class.. Looks good to me, doesn't really make sense to return the field unless it is later used to validate data generated or retrieve from somewhere else other than user input.. ",
    "fmartins": "@barakcoh @nickhudkins \nHi, I am interested in this topic. Anyone of you already did some draft about this?\nIn first hand, I had the impression that a model structured based in @annotations is great. What do you think about this?\nPlease, check this another issue about this some area of knowledge - https://github.com/graphql-python/graphene-django/issues/79\nThank you!\n. ",
    "austinnichols101": "Are there any limitations with this implementation?  I've been waiting for the merge, but not sure why it's delayed.. ",
    "eclipselu": "@angieellis Great! Thank you very much! This works.  :hooray:\nDidn't look closely to the source code, there's actually example in the tests:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/tests/test_field.py#L60. ",
    "zeroSteiner": "You're right, that appears to be the issue. Thanks for pointing that out.. ",
    "globophobe": "That would depend on what kind of subscription, for example long-polling or WebSocket. It also depend on your backend, for example Django, with django channels, could handle subscriptions by broadcasting to connected sockets from a post_save signal.. @japrogramer You're right. There's an extra step. The client would need to be added to a group. I don't have time (nor ever will) to explore this. Personally waiting for, https://github.com/encode/uvicorn and https://github.com/encode/apistar to bring good things to Django, or obviate my need for it.. Of course, my apologizes.. ",
    "Jufik": "I'd guess it's pretty straight forward to code a model related subscription.\nI'm working with Django, and plan to use Django Channel: my suggestions and answers are opinionated that way.\nGetting inspired by  mutation from sources, one could push down the data to customer quite easily.\nIn case of Mutation, mutate is called is the resolver. I guess a general subscribe  function could be written to \"hookup\" the customer channel on an \"subscription specific channel\", it self hooked up on the \"model channel\". \nUsing a post_save, writting down a custom save method or binding could do the Job to propagate the data down to clients.\nI don't know how to solve two stuff though:\n- how to get the information of which channel is expecting which \"query\" (eg which fields should be sent to which client).\n- parameters handling. Like how to handle a subscription to a model, based on a category filter.\nFor the first point, I guess I could use  caching engine and a 3 layer structure to  push data to my channel. Like: Customer Channel hooked up to a Query Channel, that his hooked up to the model channel. The query used  in the Query Channel being store in cache. It seems non trivial bu feasible.\nFor the second point, only a cache based solution seems viable, storing filters in a dict, stored in cache. But that's lot of work. \nAny suggestion on those two questions is welcome!\nI'll give a basic architecture a try, and create share repo' to give some feedback. . ",
    "jeffreybrowning": "@Jufik Any updates?. @syrusakbary Thoughts? . ",
    "hballard": "I implemented a port of the apollo graphql subscriptions modules (graphql-subscriptions and subscriptions-transport-ws) for graphene / python.  They work w/ apollo-client.  \nIt is here.\nSame basic api.  It is still very rough...but works so far, based on my limited testing.  Uses redis-py, gevent-websockets, and syrusakbary/promises.  It is still missing a few of the server options and keep-alive messages, but those are pretty easy to implement and I'll do that in the next few days.  I was going to add a simple example app too.  Some of it is below.  Only works on python2 for now and it needs tests, setup.py, etc.  I figured I'd go ahead and share in case anybody is interested...\nSimple example:\nServer (using Flask and Flask-Sockets):\n```\nfrom flask import Flask\nfrom flask_sqlalchemy import SQLAlchemy\nfrom flask_sockets import Sockets\nfrom .subscription_manager import SubscriptionManager, RedisPubsub\nfrom .subscription_transport_ws import ApolloSubscriptionServer\napp = Flask(name)\nsockets = Sockets(app)\npubsub = RedisPubsub()\nschema = graphene.Schema(\n    query=Query,\n    mutation=Mutation,\n    subscription=Subscription\n)\nsubscription_mgr = SubscriptionManager(schema, pubsub)\n@sockets.route('/socket')\ndef socket_channel(websocket):\n    subscription_server = ApolloSubscriptionServer(subscription_mgr, websocket)\n    subscription_server.handle()\n    return []\nif name == \"main\":\n    from geventwebsocket import WebSocketServer\nserver = WebSocketServer(('', 5000), app)\nprint '  Serving at host 0.0.0.0:5000...\\n'\nserver.serve_forever()\n\n```\nOf course on the server you have to \"publish\" each time you have a mutation (in this case to a redis channel).  That could look something like this (using graphene / sql-alchemy):\n```\nclass Subscription(graphene.ObjectType):\n    users = graphene_sqlalchemy.SQLAlchemyConnectionField(\n        User,\n        active=graphene.Boolean()\n    )\ndef resolve_users(self, args, context, info):\n    query = User.get_query(context)\n    return query.filter_by(id=info.root_value.get('id'))\n\nclass AddUser(graphene.ClientIDMutation):\nclass Input:\n    username = graphene.String(required=True)\n    email = graphene.String()\n\nok = graphene.Boolean()\nuser = graphene.Field(lambda: User)\n\n@classmethod\ndef mutate_and_get_payload(cls, args, context, info):\n    _input = args.copy()\n    del _input['clientMutationId']\n    new_user = UserModel(**_input)\n    db.session.add(new_user)\n    db.session.commit()\n    ok = True\n    if pubsub.subscriptions:\n        pubsub.publish('users', new_user.as_dict())\n    return AddUser(ok=ok, user=new_user)\n\n```\nClient (using react-apollo client):\n```\nimport React from 'react'\nimport ReactDOM from 'react-dom'\nimport { graphql, ApolloProvider } from 'react-apollo'\nimport gql from 'graphql-tag'\nimport ApolloClient, { createNetworkInterface } from 'apollo-client'\nimport { SubscriptionClient, addGraphQLSubscriptions } from 'subscriptions-transport-ws'\nimport ChatApp from './screens/ChatApp'\nimport ListBox from '../components/ListBox'\nconst SUBSCRIPTION_QUERY = gqlsubscription newUsers {\n    users(active: true) {\n      edges {\n        node {\n          id\n          username\n        }\n      }\n    }\n  }\nconst LIST_BOX_QUERY = gqlquery AllUsers {\n    users(active: true) {\n      edges {\n        node {\n          id\n          username\n        }\n      }\n    }\n  }\nclass ChatListBox extends React.Component {\ncomponentWillReceiveProps(newProps) {\n    if (!newProps.data.loading) {\n      if (this.subscription) {\n        return\n      }\n      this.subscription = newProps.data.subscribeToMore({\n        document: SUBSCRIPTION_QUERY,\n        updateQuery: (previousResult, {subscriptionData}) => {\n          const newUser = subscriptionData.data.users.edges\n          const newResult = {\n            users: {\n              edges: [\n                ...previousResult.users.edges,\n                ...newUser\n              ]\n            }\n          }\n          return newResult\n        },\n        onError: (err) => console.error(err)\n      })\n    }\n  }\nrender() {\n    return \n  }\n}\nconst ChatListBoxWithData = graphql(LIST_BOX_QUERY)(ChatListBox)\nexport default ChatListBoxWithData\nconst networkInterface = createNetworkInterface({\n  uri: 'http://localhost:5000/graphql'\n})\nconst wsClient = new SubscriptionClient(ws://localhost:5000/socket, {\n  reconnect: true\n})\nconst networkInterfaceWithSubscriptions = addGraphQLSubscriptions(\n  networkInterface,\n  wsClient,\n)\nconst client = new ApolloClient({\n  dataIdFromObject: o => o.id,\n  networkInterface: networkInterfaceWithSubscriptions\n})\nReactDOM.render(\n  \n\n,\n  document.getElementById('root')\n)\n```\nI'm very new to open source, so any critiques or pull requests are welcome.  . Cool.  Let me know your thoughts.  I just pushed an update that added the keep_alive messages and the on_connect, on_disconnect, on_subscribe, and on_unsubscribe optional server setup functions.  This should make it mostly the same as the Apollo subscriptions API at this point.. Thanks for the comments @syrusakbary .  I think your grapqhl / graphene / promises libraries are amazing...any constructive criticism you have I'm happy to hear.  I only used the \"Apollo..\" naming convention because my implementation was initially based on their (Apollo's) graphql subscription transport protocol.  But, as the final spec should be merged soon, I'm happy to drop that convention, since it only affects the main subscription transport class.  I've been tied up the last couple months, since I published this, so I haven't been able to devote much time to improving it.  Some priorities in the near term for me:\n\nFinish up tests. I'm about done w/ the last bit (focused on the transport module) and should be publishing them in the next few days.\nAdd Python 3 support\nAdd Django support\nFinish simple example chat app\nAbstract the concurrency executor (uses Gevent now...but obviously with python >3.5 would like to have asyncio as an option and also be able to use regular threads (for simple dev / testing); I was thinking something like what you did in graphene / graphql-core\nAdd a simple pubsub class for testing / development; so the RedisPubsub doesn't have to be used\nLot's of other things could be done obviously...my time being the limiting factor there.  Once I finish the tests...obviously easier for folks to contribute.\n\nThanks!. @Helw150 - I can't speak for @syrusakbary, but I know I'd welcome any contributions on my repo.  Also, not sure if @syrusakbary is interested in integrating it into graphene eventually, just prefers to fork it, or go his own way.  I started this mainly as a hobby project, when I was playing w/ Apollo subscriptions and noticed their wasn't an implementation for graphene (python being my preferred server language).  I just pushed a commit to the \"tests\" branch with about half the subscriptions-transport tests and all the subscriptions-manager tests were added a few weeks ago.  The rest of the transport tests should be easier to finish up now, the initial test setup for those slowed me down a bit--some of it was new for me.  I haven't had a ton of time to devote to this and I don't really use django...so not sure when I would get to that.  My next focus would be Python 3 compatibility...which might not be that difficult.  Of course now that the initial commits for graphql subscriptions have been added to the spec, probably lot's more need to be done outside of these focues.  You can read my summary of the my transport tests commit on the issue I created for them here. Update: Initial tests have been added as of last weekend (see commit here and I merged a commit last week that added Python 3 compatibility (2.7, 3.4, 3.5, & 3.6).   My next two priorities are adding additional executors (threads, asyncio, etc.) and some type of Django compatibility.  I don't really use Django...for those that do...is channels the preferred method for adding real-time services to Django now or something like django-websocket-redis or django-socketio?  I've been doing a little reading on Django and channels.... @leebenson  - Very cool. Any feedback you can provide is appreciated.  Let me know if I can be of assistance.\nPer @syrusakbary previous comment above, \"Having a subscriptions integration with Django so we assure that the subscriptions structure is abstracted in a scalable way...\"; I've been thinking about the best way to do that.  \nMy thought is that it should be fairly straightforward to generalize the concurrency executor methods like @syrusakbary did in graphql-core and have separate executor classes for each concurrency library (probably will even borrow some of the logic in graphql-core for each one).  Then the RedisPubsub and SubscriptionTransport classes would utilize the corresponding executor passed in by the user when they instantiate each class.  I'd welcome any feedback anyone has (@syrusakbary or others) on this structure.  \nI spent a couple hours reading through the Django channels library this weekend and it would seem it could be treated as just another executor class under this model.  Also, anyone familiar w/ Django...seems like I would utilize a \"class-based consumer\" (inherit from WebsocketConsumer) for the SubscriptionServer.  The redis pubsub \"wait_and_get_message\" method in the RedisPubsub class could be implemented as another consumer.  Thoughts on this (from anyone more familiar w/ Django channels)?. I'm happy to have any assistance from another contributor--particularly a django core.  I haven't reached out to them since I don't utilize django and I needed to abstract the concurrency executor from the base subscriptions manager and websocket server logic, in order to use other concurrency frameworks (like django channels). It would be fairly straightforward to integrate the current gevent version with django-socketio or create a simple package similar to flask-sockets to integrate geventwebsocket into django directly. I found a small library on bitbucket that seems to do just that -- django-gevent-websocket (here). \nI'm currently working on abstracting the currency executor to be able to use asyncio for concurrency as well (vs the current gevent).  I should merge a version of that with master in the next week or so (which will allow use w/ Sanic web framework using uvloop / asyncio)...and then I was going to turn my attention to django integration, using the same abstraction base.  But my plan was to focus more on django-channels...since that seems to be the way forward for django concurrency.. Afraid not...I live in Texas (US)...and that would be a bit of hike!  . I just submitted a pull request to graphql-ws that gives an example of a publish - subscription implementation, to make it easier to use subscriptions with graphql-ws.   I modified the README and examples to show how it might work.  Not sure if @syrusakbary would want this as a part of the graphql-ws library or in a separate one. Here is my fork in case you want to try it out.  . See my most recent comment on #430 for a link to a Flask example.. ",
    "miketout": "I just collaborated with @IlyaRadinsky on a graphene/Tornado/subscriptions integration with websockets that requires one line of code to get your graphene schema + subscriptions up and available as an API. Here's a link to his original repo, which has incorporated my changes as well:\nhttps://github.com/IlyaRadinsky/tornadoql. ",
    "prokher": "JFYI: We have eventually published our domestic subscriptions implementation DjangoChannelsGraphqlWs. Actually we implemented a simple WebSocket-based GraphQL server implemented on Django Channels. Subscriptions are implemented in the Graphene-like style. The work is still in progress, but probably someone will find it useful.. Dear @syrusakbary on July 30 you made a great comment about the place subscriptions implementation must be, you also told that you start the research in the branch. I just wanted to ask for an update. Did you succeed in your research? Shall we expect subscriptions to be the part of Graphene library eventually? I see there are couple implementations available (e.g. GraphQL Subscription with django-channels, graphene-django-subscriptions), but none of them can be used in production out of the box (by different reasons).. @heyrict Thank you very much, we came to the same conclusion. The code in the gist indeed very simple and clean. That is definitely way to go. Manu thanks to @tricoder42.. BTW, just for information: the protocol used by the subscriptions-transport-ws (WebSocket-based transport used by Apollo subscriptions) is described here.. JFYI: We have eventually published our domestic subscriptions implementation DjangoChannelsGraphqlWs. Actually we implemented a simple WebSocket-based GraphQL server implemented on Django Channels. Subscriptions are implemented in the Graphene-like style. The work is still in progress, but probably someone will find it useful.. @Musbell be careful, it is not ready for production yet, currently we are working hard to improve (add asynchronous message handling, ordering/serialization, examples, etc), and we are happy to receive any feedback you have.. Dear @yfilali , thank you for your thoughtful response.\nIndeed, using graphene-django it is really easy to expose a Django model to the GraphQL API and keep them in sync.\nThe reason I asked the question is because we have already implemented quite a big GraphQL schema on Graphene and only a small part of GraphQL types we have are created with graphene-django. It does work quite well, but it is hard to capture the schema reading these dozens of Python classes. That lead me to the thought that it would be nice to split the GraphQL schema declaration from the resolvers implementation. I am still not sure, but I see having schema statically declared in the language-agnostic manner is quite an interesting option.\nIn other words, I am still not sure that combining schema definition and schema implementation (implementation of the resolvers hierarchy) is a good approach for writing GraphQL API.\nI would love to hear other opinions.. ",
    "LexFrench": "I'm seeing the same issue as well even when not using the graphene-django plugin.. ",
    "chrisbrantley": "I have this problem as well. According to the spec it seems like this is expected behavior but for the life of me I can't understand why.. ",
    "janosroden": "Hi @syrusakbary, coud you please reopen this issue because the spec changed on 12 Sep 2017?\nCurrent spec. Hi, I'd like to keep this issue open if you don't mind.\nThanks!. ",
    "cliedeman": "Hello\nHave you looked at the sqlalchemy integration project?\nPagination is already implemented there for relay.\nCiaran. ",
    "marcovc": "Hi, \nThe code is the one from the documentation linked above. \nThanks\nMarco. ",
    "m-charlton": "The following code, from the given link, works fine (on my setup at least):\n```python\nimport graphene\nclass PersonInput(graphene.InputObjectType):\n    name = graphene.String()\n    age = graphene.Int()\nclass CreatePerson(graphene.Mutation):\n    class Input:\n        person_data = graphene.InputField(PersonInput)\nperson = graphene.Field(lambda: Person)\n\ndef mutate(self, args, context, info):\n    p_data = args.get('person_data')\n\n    name = p_data.get('name')\n    age = p_data.get('age')\n\n    person = Person(name=name, age=age)\n    return CreatePerson(person=person)\n\n```\nHowever the next example, on the same page, fails:\npython\n1    import graphene\n2\n3    class LatLngInput(graphene.InputObjectType):\n4        lat = graphene.Float()\n5        lng = graphene.Float()\n6\n7    #A location has a latlng associated to it\n8    class LocationInput(graphene.InputObjectType):\n9        name = graphene.String()\n10       latlng = graphene.InputField(LatLngInputType)\nwith this traceback:\npython\nTraceback (most recent call last):\n  File \"ex1.py\", line 8, in <module>\n    class LocationInput(graphene.InputObjectType):\n  File \"ex1.py\", line 10, in LocationInput\n    latlng = graphene.InputField(LatLngInputType)\nNameError: name 'LatLngInputType' is not defined\nIt looks as if there is a typo on line 10: LatLngInputType should be LatLngInput,\nor the class LatLngInputshould be LatLngInputType.\nThe error is in docs/types/mutations.rst.\nI'm willing to make and test the change.\nPython 2.7 environment as follows:\ngraphene==1.1.3\ngraphql-core==1.0.1\ngraphql-relay==0.4.5\npromise==1.0.1\nsix==1.10.0\ntyping==3.5.3.0. ",
    "lucasrcosta": "I can confirm the error reported by @marcovc using 1.1.3. There's even specific code for raising it in the to_arguments function on types.argument::52:\npython\n        if isinstance(arg, (InputField, Field)):\n            raise ValueError('Expected {} to be Argument, but received {}. Try using Argument({}).'.format(\n                default_name,\n                type(arg).__name__,\n                arg.type\n            )). ",
    "yeyuguo": "I have this problem at the moment\uff0cDo you have a good solution?. ",
    "nderkach": "```python\ndef _json_object_hook(d): return namedtuple('X', d.keys())(*d.values())\ndef json2obj(data): return json.loads(data, object_hook=_json_object_hook)\nclass Listing(ObjectType):\n    id = ID()\n    name = String()\nclass Review(ObjectType):\n    language = String()\n    listing = Field(Listing)\n    listing_id = ID()\nclass Query(ObjectType):\n    reviews = List(Review, id=Int(required=True))\ndef resolve_reviews(self, args, context, info):\n    api = get_reviews() # returns a Python dictionary\n    return json2obj(json.dumps(api.get_reviews(args.get(\"id\"))[\"reviews\"]))\n\n```\nUsing the helper function from SO, we convert our dictionary to a json string and then to an object to that we can call methods on it. In this example, we also have some nested objects in the schema, and inner fields can be queried as well.. @m7albasha by analogy, you'd have a class like this:\npython\nclass Result(ObjectType):\n  collectionId = ID()\nthen in your query something like this:\n```python\nclass Query(ObjectType):\n    results = List(Result)\ndef resolve_results(self, args, context, info):\n    responce = get_results() # get your json from the API here\n    return json2obj(json.dumps(responce)[\"result\"])) # map to list of results\n\n``. I've recently written an [article](https://codeburst.io/how-to-build-a-graphql-wrapper-for-a-restful-api-in-python-b49767676630) on this topic, hope this helps.. Simply changing the data type inPersontoInt()` should work. Btw, in your example, the resolver is never called.. ",
    "m7albasha": "@nderkach, I have the below Rest response,  How can I query for collectionId? Thank you in advance.\n{\n    \"count\": \"287\",\n    \"result\": [\n        {\n            \"case\": {\n                \"id\": \"167779\"\n            },\n            \"collectionAgentVersion\": \"\",\n            \"collectionDate\": \"2017-08-02 15:11:28.000\",\n            \"collectionFileType\": \"TSR\",\n            \"collectionId\": \"55CBD446E6F01ABFE05346CAA00A9B2E\",\n            \"customer\": {\n                \"companyName\": \"\"\n            },\n            \"device\": {\n                \"assetSerialNumber\": \"\",\n                \"clientId\": \"\",\n                \"deviceType\": \"\",\n                \"modelNumber\": \"\",\n                \"operatingSystem\": \"\",\n                \"serviceTag\": \"H6WC62S\"\n            },\n            \"importDate\": \"2017-08-02 20:11:28.0\",\n            \"projectId\": \"\",\n            \"totalCollections\": \"\"\n        },\n        {\n            \"case\": {\n                \"id\": \"\"\n            },\n            \"collectionAgentVersion\": \"\",\n            \"collectionDate\": \"2017-08-02 15:05:29.000\",\n            \"collectionFileType\": \"TSR\",\n            \"collectionId\": \"55CBC779F890B8ABE0534ACAA00AFF44\",\n            \"customer\": {\n                \"companyName\": \"\"\n            },\n            \"device\": {\n                \"assetSerialNumber\": \"\",\n                \"clientId\": \"\",\n                \"deviceType\": \"\",\n                \"modelNumber\": \"\",\n                \"operatingSystem\": \"\",\n                \"serviceTag\": \"1GR634J\"\n            },\n            \"importDate\": \"2017-08-02 20:05:29.0\",\n            \"projectId\": \"\",\n            \"totalCollections\": \"\"\n        }\n    ]\n}\n. ",
    "ItsmeKernel": "@ghoshabhi, I had similar issues while trying to run the example from the doc. Finally, this is what worked for me:\n```\nschema.py (courses app)\nclass CreateTeacher(graphene.Mutation):\n    class Input:\n        name = graphene.String()\n        email = graphene.String()\nteacher = graphene.Field(TeacherNode)\n\n@classmethod\ndef mutate(self, cls, input, context, info):\n    name = input.get('name')\n    email = input.get('email')\n\n    teacher = Teacher(name=name, email=email)\n    teacher.save()\n    return CreateTeacher(teacher=teacher)\n\nclass CourseMutations(AbstractType):\n    create_teacher = CreateTeacher.Field()\nAnd then:\nschema.py (project level)\nclass AllMutations(courses.schema.CourseMutations, graphene.ObjectType):\n    pass\nschema = graphene.Schema(query=Query, mutation=AllMutations)\n```\nSo I can execute:\nmutation{\n  createTeacher(name: \"Mace Windu\", email:\"mwindu@jedi.org\"){\n    teacher{\n      id\n      name\n      email\n    }\n  }\n}\nThough this code works, I don't know if it's 100% correct, I'm also new to Graphene.. @ghoshabhi, I put together a second example, this time using ClientIDMutation:\n```\nclass CreateCourse(graphene.ClientIDMutation):\n    class Input:\n        name = graphene.String()\n        summary = graphene.String()\n        teacher_id = graphene.String(required=True)\ncourse = graphene.Field(CourseNode)\n\n@classmethod\ndef mutate_and_get_payload(cls, input, context, info):\n    name = input.get('name')\n    summary = input.get('summary')\n    teacher_id = input.get(\"teacher_id\")\n    try:\n        teacher_id = int(teacher_id)\n    except ValueError:\n        try:\n            _type, teacher_id = Node.from_global_id(input.get(\"teacher_id\"))\n            assert _type == 'TeacherNode', 'Found {} instead of teacher'.format(_type)\n            teacher_id = int(teacher_id)\n        except:\n            raise Exception(\"Received Invalid Teacher id: {}\".format(teacher_id))\n\n    teacher = Teacher._meta.model.objects.get(id=teacher_id)\n    course = Course(name=name, summary=summary, teacher=teacher)\n    course.save()\n    return CreateCourse(course=course)\n\nclass CourseMutations(AbstractType):\n   # ...\n    create_course = CreateCourse.Field()\n```\nTo execute this kind of mutations you need to pass an input argument\nmutation {\n  createCourse(input: {name: \"Testing Course\", summary: \"the summary\", teacherId: \"VGVhY2hlck5vZGU6MQ==\"}) {\n    course {\n      name\n      teacher {\n        name\n      }\n    }\n  }\n}\nI hope this helps.. ",
    "raix": "opened new https://github.com/graphql-python/graphql-core/issues/101 - fixing in graphql-core. ",
    "pedroabi": "```\n        mutation = '''\n        mutation productCreator ($input: CreateProductInput!){\n          createProduct (input: $input){\n            product {\n              id\n              title\n            }\n          }\n        }\n    '''\n    variables = {\"input\": {\"title\": \"My First product\", \"clientMutationId\": \"abc\"}}\n    r = self.graphql.execute(mutation, variables)\n    id_ = r.data['createProduct']['product']['id']\n\n```. ",
    "blorenz": "Unfortunately this isn't appearing to work.  I am only yielding __debug in my queries though I get only my Challenge schema as expected if set SCHEMA to challenge.schema.game.schema.\n```\nclass Query(challenge.schema.game.GameQuery, graphene.ObjectType):\n    debug = graphene.Field(DjangoDebug, name='__debug')\nschema = graphene.Schema(query=Query)\n```\nGameQuery is a graphene.ObjectType. I am not using Relay in my architecture so I have it configured as in the basic tutorials.\n\nSOLVED:  Queries must be named the class of Query.  Trying to name it GameQuery was incorrect.\n```\nclass Query(challenge.schema.game.Query, graphene.ObjectType):\n    debug = graphene.Field(DjangoDebug, name='__debug')\nschema = graphene.Schema(query=Query)\n```\n. ",
    "Yeboster": "Hello, Is still possible to do a superquery ?\nI'm using the structure of the code like on the example but it gives me this error:\nAssertionError: Type <function SuperQuery at 0x7f4a3707ec80> is not a valid ObjectType.\nThe codes example are here:\n```\nclass Query(AbstractType):\n    # find data of a sensor; of a day; of both\n    search_data = List(Data, input=i_data())\n    # find a sensor with id\n    search_sensors = List(Sensors, input=i_sensor())\nall_data = List(Data, input = i_User_Token())\nall_sensors = List(Sensors, input = i_User_Token())\n[ omitted resolvers ]\n\ndef SuperQuery(Query, ObjectType):\n    pass\n```\nI know that AbstractType is deprecated since 2.0 so I've tried to use the 'object' type but got the same error.\nIs there a possibility to combine multiples Query objects from different locations?\nI'm using last graphene\n---SOLVED\n I wrote bad my code. \nclass SuperQuery(Query, ObjectType):\n    pass\nThis is working just fine. ",
    "gbezyuk": "@Exertive any progress on this one? Which name do you think does the system lack?. ",
    "shaleh": "To build on @dfee 's excellent observation, I hit this error a few minutes ago and went looking.\nMy issue?\nclass Query(object):\n    all_users = graphene.List(User)\nDid you spot it? Yep, User is Django's contrib.auth.models.User. I should have used the UserType I just defined a few lines earlier.. ",
    "abettke": "Not sure if this is the official solution but found fix for this by replacing the following.\nOld Code:\ncampaign = graphene.InputField(CampaignInput)\nNew Code:\ncampaign = CampaignInput(). ",
    "Waitak": "I think that I've solved it. The parent class of MyMutations needs to be AbstractType and not ObjectType.. ",
    "un33k": "@ivlevdenis any code snippet or link to example code would be nice.. @ivlevdenis Looking for a working graphene pagination example. No problem with the concept or the frontend. Thx. ",
    "Fohlen": "It doesn't for me... You're right, I didn't type the mutation correctly. This here is how it looks correctly in GraphiQL\n\nThe corresponding Mutation class is\n```\nclass Mutation(graphene.ObjectType):\n    create_invitation = CreateInvitation.Field()\nschema = graphene.Schema(query=Query, mutation=Mutation)\n````\nAnd I'm still getting the same error\nweb_1     | Traceback (most recent call last):\nweb_1     |   File \"/usr/local/lib/python3.6/site-packages/graphql/execution/executor.py\", line 330, in complete_value_catching_error\nweb_1     |     exe_context, return_type, field_asts, info, result)\nweb_1     |   File \"/usr/local/lib/python3.6/site-packages/graphql/execution/executor.py\", line 383, in complete_value\nweb_1     |     raise GraphQLLocatedError(field_asts, original_error=result)\nweb_1     | graphql.error.located_error.GraphQLLocatedError: 'email' is an invalid keyword argument for this function. Yup, I can:\n```\nfrom django.test import TestCase\nimport graphene\nfrom .schema import Mutation, Query\nclass SchemaTestCase(TestCase):\n    def test_create_invitation(self):\n        query_string = '''\n            mutation ($email: String!) {\n               createInvitation(email: $email) {\n                   invitation {\n                       creationDate\n                  }\n               }\n            }\n        '''\n    schema = graphene.Schema(query=Query, mutation=Mutation)\n    result = schema.execute(query_string, variable_values={\n        'email': 'foo@bar.com',\n    })\n\n    assert not result.errors\n\n```\nYields in \n```\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/site-packages/graphql/execution/executor.py\", line 330, in complete_value_catching_error\n    exe_context, return_type, field_asts, info, result)\n  File \"/usr/local/lib/python3.6/site-packages/graphql/execution/executor.py\", line 383, in complete_value\n    raise GraphQLLocatedError(field_asts, original_error=result)\ngraphql.error.located_error.GraphQLLocatedError: 'email' is an invalid keyword argument for this function\nF\n======================================================================\nFAIL: test_create_invitation (eventzimmer.tests.SchemaTestCase)\n\nTraceback (most recent call last):\n  File \"/code/eventzimmer/tests.py\", line 23, in test_create_invitation\n    assert not result.errors\nAssertionError\n\nRan 1 test in 0.023s\nFAILED (failures=1)\n```\nNote: I commented the creator part for testing, so it wouldn't complain about the context being inaccesible.\nFurther investigation shows:\npip freeze\ngraphene==2.1\ngraphene-django==2.0.0\ngraphql-core==2.0\ngraphql-relay==0.4.5\npython3.6.5 is the only available interpreter (this is inside a docker container).\n. @jkimbo thanks for sticking so much with me and this issue. \ud83e\udd42 \nI hope this gist can bring some insight.. Lovingly, that worked out for me. Don't know why the error logging is so spartan\u00e4ious. . ",
    "frankh": "Doesn't work for me either.. ",
    "sebastiandev": "Is not working for me either and i think the calculations for those fields in graphql-relay are not right or documentation is not clear.\nThe solution is actually here but hasn't been merged yet\n. Found the issue in the grpahql-relay repo. Closing this. Yeah I already did that, but if the users make more than one query for example, quota would be present on both query results. I was thinking about something that is at a higher level, like the errors and data fields from the response payload.. @BossGrand yes, for mutations it works, and I solved it in the same way, but for queries doesn't work. That's the main problem, having to check errors differently for mutations and queries is not a good user experience.  \nSo to keep them consistent we need to have a errors field for queries as well, if the root response cannot be extended, then subclassing ObjectType and adding an errors field, and use the custom ObjectType as the base type for every query result.\nQueries may fail, but also, the resolvers of each field from the query response may fail, so you need a way of catching any of those errors, and some how populate the error field with them. Problem is you don't control when fields are resolved, thus cannot force the error field to be resolved at the very end to make sure all the other resolvers were executed and catched (if they errored).\nIts a bit confusing, but hopefully you got the idea.\n. Well queries are resolved in many different ways, from different microservices, so errors can happen. \nLike unauthorized access to a resource, bad search input (which is not strictly typed), and some complex queries that might return domain errors. I just don't think having to check in 2 places for errors is convenient for the user. So you use the errors payload or have a errors field on each query/mutation, but not both.. ",
    "abdulhaq-e": "The playground doesn't seem to be relevant to the code in scheme.py which you linked.. The value it takes depends on the user. It is a Request object if you are using graphene-django. This repository is for graphene, a general framework for using GraphQL in Python, the GraphQL website has the following regarding context:\n\ncontext A value which is provided to every resolver and holds important contextual information like the currently logged in user, or access to a database.\nhttp://graphql.org/learn/execution/. You can give the front-end developer a link to the graphiql client from which he/she can see everything.. \n",
    "dmitry-saritasa": "@BossGrand I tried with 'input' and it didn't work either\nmutation {\n  createHero(input:{name:\"Test\", planet:\"Test\" }){\n    hero {\n      id,\n      name,\n      homeworld {\n        id\n      }\n    }\n  }\n}\nand this is the error\n{\n  \"errors\": [\n    {\n      \"message\": \"Unknown argument \\\"input\\\" on field \\\"createHero\\\" of type \\\"Mutation\\\".\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 14\n        }\n      ]\n    }\n  ]\n}. Another thing is query through connection\n```\n{\n  allFilms {\n    edges {\n      node {\n        id\n        title\n        characters {\n          edges {\n            node {\n              id\n            }\n          }\n        }   \n  }\n}\n\n}\n  __debug {\n    sql {\n      vendor\n      alias\n      sql\n      duration\n      rawSql\n      params\n      startTime\n      stopTime\n      isSlow\n      isSelect\n      transId\n      transStatus\n      isoLevel\n      encoding\n    }\n  }\n}\n```\nwill give the answer:\n{\n  \"errors\": [\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    },\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    },\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    },\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    },\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    },\n    {\n      \"message\": \"Cannot combine queries on two different base models.\",\n      \"locations\": [\n        {\n          \"column\": 9,\n          \"line\": 7\n        }\n      ]\n    }\n  ],\n  \"data\": {\n    \"allFilms\": {\n      \"edges\": [\n        {\n          \"node\": {\n            \"id\": \"RmlsbTox\",\n            \"title\": \"A New Hope\",\n            \"characters\": null\n          }\n        },\n        {\n          \"node\": {\n            \"id\": \"RmlsbToy\",\n            \"title\": \"The Empire Strikes Back\",\n            \"characters\": null\n          }\n        },\n        {\n          \"node\": {\n            \"id\": \"RmlsbToz\",\n            \"title\": \"Return of the Jedi\",\n            \"characters\": null\n          }\n        },\n        {\n          \"node\": {\n            \"id\": \"RmlsbTo0\",\n            \"title\": \"The Phantom Menace\",\n            \"characters\": null\n          }\n        },\n        {\n          \"node\": {\n            \"id\": \"RmlsbTo1\",\n            \"title\": \"Attack of the Clones\",\n            \"characters\": null\n          }\n        },\n        {\n          \"node\": {\n            \"id\": \"RmlsbTo2\",\n            \"title\": \"Revenge of the Sith\",\n            \"characters\": null\n          }\n        }\n      ]\n    },\n    \"__debug\": {\n      \"sql\": [\n        {\n          \"vendor\": \"unknown\",\n          \"alias\": \"default\",\n          \"sql\": \"SELECT COUNT(*) AS \\\"__count\\\" FROM \\\"starwars_film\\\"\",\n          \"duration\": 0.0011839866638183594,\n          \"rawSql\": \"SELECT COUNT(*) AS \\\"__count\\\" FROM \\\"starwars_film\\\"\",\n          \"params\": \"[]\",\n          \"startTime\": 1493950734.813272,\n          \"stopTime\": 1493950734.814456,\n          \"isSlow\": false,\n          \"isSelect\": true,\n          \"transId\": null,\n          \"transStatus\": null,\n          \"isoLevel\": null,\n          \"encoding\": null\n        },\n        {\n          \"vendor\": \"unknown\",\n          \"alias\": \"default\",\n          \"sql\": \"SELECT \\\"starwars_film\\\".\\\"id\\\", \\\"starwars_film\\\".\\\"created\\\", \\\"starwars_film\\\".\\\"edited\\\", \\\"starwars_film\\\".\\\"title\\\", \\\"starwars_film\\\".\\\"episode_id\\\", \\\"starwars_film\\\".\\\"opening_crawl\\\", \\\"starwars_film\\\".\\\"director\\\", \\\"starwars_film\\\".\\\"producer\\\", \\\"starwars_film\\\".\\\"release_date\\\" FROM \\\"starwars_film\\\" LIMIT 6\",\n          \"duration\": 0.0003190040588378906,\n          \"rawSql\": \"SELECT \\\"starwars_film\\\".\\\"id\\\", \\\"starwars_film\\\".\\\"created\\\", \\\"starwars_film\\\".\\\"edited\\\", \\\"starwars_film\\\".\\\"title\\\", \\\"starwars_film\\\".\\\"episode_id\\\", \\\"starwars_film\\\".\\\"opening_crawl\\\", \\\"starwars_film\\\".\\\"director\\\", \\\"starwars_film\\\".\\\"producer\\\", \\\"starwars_film\\\".\\\"release_date\\\" FROM \\\"starwars_film\\\" LIMIT 6\",\n          \"params\": \"[]\",\n          \"startTime\": 1493950734.815223,\n          \"stopTime\": 1493950734.815542,\n          \"isSlow\": false,\n          \"isSelect\": true,\n          \"transId\": null,\n          \"transStatus\": null,\n          \"isoLevel\": null,\n          \"encoding\": null\n        }\n      ]\n    }\n  }\n}. ",
    "keepexploring": "Hi, I'm struggling to be able to get the mutations working. I set up the project and the query's work fine, but when I post in GraphiQl:\nmutation {\n  createHero(input:{name:\"Test\", planet:\"Test\" }){\n    hero {\n      id,\n      name,\n      homeworld {\n        id\n      }\n    }\n  }\n}\nI get the following response:\n{\n  \"errors\": [\n    {\n      \"message\": \"Unknown argument \\\"input\\\" on field \\\"createHero\\\" of type \\\"Mutation\\\".\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 14\n        }\n      ]\n    },\n    {\n      \"message\": \"Field \\\"createHero\\\" argument \\\"name\\\" of type \\\"String!\\\" is required but not provided.\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 3\n        }\n      ]\n    },\n    {\n      \"message\": \"Field \\\"createHero\\\" argument \\\"homeworldId\\\" of type \\\"String!\\\" is required but not provided.\",\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 3\n        }\n      ]\n    }\n  ]\n}\nI modified the mutation code as suggested above.\neven if I use the online demo, it does not seem to work:\nhttp://swapi.graphene-python.org/graphql?query=mutation%20%7B%0A%20%20createHero(input%3A%7Bname%3A%22Test%22%2C%20planet%3A%22Test%22%20%7D)%7B%0A%20%20%20%20hero%20%7B%0A%20%20%20%20%20%20id%2C%0A%20%20%20%20%20%20name%2C%0A%20%20%20%20%20%20homeworld%20%7B%0A%20%20%20%20%20%20%20%20id%0A%20%20%20%20%20%20%7D%0A%20%20%20%20%7D%0A%20%20%7D%0A%7D&operationName=undefined\nWhat am I doing wrong? I'm sure there must be a simple solution to this!\nIs anyone able to provide an example of a mutation that works in http://swapi.graphene-python.org/graphql ?\nThanks so much!. ",
    "uprego": "I got here looking for a simplest tutorial on deploying Graphene for Python to AWS Lambda to be used via AWS API Gateway without (if possible) adding Zappa.\nThe product is relatively small and the use case is kind of niche and (probably) unable to grow too large, so if there is no boilerplate or convenient demo, I'm going to be tempted into not using Graphene... and I don't like that.\n. Things have pivoted aggressively so I'm not trying it before several months from now, but I am now more confident the basic example is probably going to be enough for me.\n\nZappa is just one utility that helps you package your whole backend application for AWS API Gateway/Lambda, nothing prevents you from doing the same manually, but that is not graphene related. Using zappa for your project will take you about 5 minutes and 2-3 commands on the command line, so I highly recommend reading the getting started there: https://github.com/Miserlou/Zappa#basic-usage\n\nI appreciate your zeal, but I really think Zappa is sadly still very young for me to be considered as a good generic pipeline for AWS Lambda deployment (sources this, this, this and this, among others relating to proprietary software), by the way without needing Zappa I can already upload new code to AWS Lambda in one step, whenever no new dependency is required (sadly I've had to become knowledgeable in the arts of generating dependencies ready for the AWS Lambda runtimes Python 2 and 3).\nSorry for the noise and keep up the good stuff.\n. ",
    "switchtrue": "I believe I've raised this in the wrong place it should be in Flask-graphql. Apollogies.. ",
    "TimOrme": "@mleonard87  Did you ever find a way to do this in flask-graphql? Having the same issue. ",
    "grazor": "Thanks, @syrusakbary!\nI've finished transfering sanic-graphql to the organization. Could you please enable Travis Ci and Coveralls for this repo?. @syrusakbary, done as well!. ",
    "rhoog": "I would like this functionality as well. I need a more traditional pagination approach using pages instead of cursors (which is not difficult to implement) and I also want to store the current pagenumber in pageInfo (which I have not managed). ",
    "vivekdurai": "See @ekampf code in #307 . ",
    "dudanogueira": "Nice!!!. Indeed. This would make Django a great fit for angular2 real time apps. ",
    "NSLS": "@syrusakbary Any update on this?. ",
    "Helw150": "@hballard @syrusakbary With the official spec now merged, is there room for contributions on getting subscriptions implemented? I'm interested in using graphene with a new django project, and this would be huge.. ",
    "leebenson": "Great work @hballard. I'd like to use this as inspiration for an example in my ReactQL starter kit to show how subscriptions can be served from a non-Node.js server.. Out of interest, is this generally a problem with any Python lib, or just some particular way Graphene is importing the graphql lib?. I think that's a great idea.\nFor me personally, it's not so much about the reward scheme/publicity link-back, as it is the time investment in features (although I'm sure other/bigger companies would be interested.)\nIf I knew that, say, 50 people paying $50/mo would yield 20 hours of dedicated focus each month and increased traction against bug reports/feature requests, I'd be very happy to contribute. It's specifically about the code, for me. I'd like to know the back-bone of my API server is being supported by someone with a commercial incentive to keep it going.. Thanks @syrusakbary. I've kick-started your Patreon with $50/mo. Once I get my current project off the ground and funding is a little less tight, I'll be happy to bump this up to a higher tier.\nHope you reach your goals!. Can we help @syrusakbary drum up a bit more support?\nThis thread has a bunch of upvotes, but no additional contributions so far. Would be awesome if we could collectively buy a realistic chunk of time to devote to smashing through Syrus's to-do list.. It's disappointing to see that the campaign hasn't moved in nearly 3 months. Still no further activity on Patreon. This is an incredible library with a ton of promise, but without any commercial backing, I'm not sure how much we can expect to move the needle forward on issues/feature requests.. ",
    "AgentChris": "can we have an example of how subscriptions works with Graphene in Django?. thanks a los, i was trying to find an example for the last 2 days. what does ProductType represents?, or can you send my a link with the file, to see it better. this works, but when i use react-apollo, it doesn't seems to work. ",
    "Oxyrus": "I would like to know what is the progress in the implementation of subscriptions into the core of Graphene, could someone clarify please?. ",
    "tricoder42": "Here's a gist with my solution using django-channels. It's a working proof of concept. Next task is optimize it for production environment. Feedback welcome!. @japrogramer What do you mean by dataloaders to group?\nThe main problem is that workers run in different processes, so I need to run query at least once per process. Second problem is that workers are intended to be short-lived, so I can't take it granted that parsed query is available. Worker can be restarted anytime.. The only part which would fit into graphene is Subscription class. Everything else depends on backend (django-channels or redis), so it might be better to either keep it in separate package or locally in project. Anyway, django-channels 2.0 are on the way which makes imlementation a bit cleaner.\n\n\n\n2018 v 1:13, Chad Dombrova notifications@github.com:\n\n\n\n\n@tricoder42 So Is there hope of getting this into graphene or not? Should it be spun off into its own library?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @japrogramer I havent' tried it yet, but it should be possible to register custom callbacks to a Group. \n\nRight now it's only possible to add another Channel to a Group and when message is sent, it's automatically broadcasted to all channels in Group. This is enough if you know the shape of data before sending a message. E.g if you have a Serializer (like in REST API), you can listen post_save signal, serialize new instance and broadcast it to the Group.\nIn GraphQL, however, we don't know what shape of data user requested, so we need to serialize instance for each Channel (subscriber) in a group separately. That's why I'm having two layers of notifications - one for model changes and second for graphql subscriptions. In channels 2.0 it should be possible to register a callback which feeds data to Observable and returns serialized data.. After first real-world implementation and testing I updated the gist with recent code changes:\n- added session handling\n- fixed GraphQLSubscriptionStore - subscription_id isn't unique across clients\n- added cleanup on ws.disconnect\nStill using django-channels 1.x.. @heyrict Unfortunately you can't in general case, because each client might be subscribed for different data. In other words: two clients might use the same subscription, but still fetch different data. I'm using custom redis store, because I need to keep graphql query around. In django-channels 1x, workers and interface are different processes so I can't data using globals either.\nHowever, in django-channels 2.x this is solved differently, I'm gonna try it soon.. @japrogramer How do you broadcast changes in DB? Do you use django signals?\nI've updated my project to django-channels 2.x and also the gist.\nTL;DR:\n- post_save listener sends messages to django.{app_label}.{model} group.\n- when new subscription is created, consumer's channel is added to django.{app_label}.{model} (this defaults to subscription's output_type, but might be overridden in Subscription.subscribe method)\n- when message from post_save signal is received, the query is executed again, but this time with (pk, model_label) tuple as a root_value. Subscription.next receives this tuple as first parameter and return None or corresponding object from db.\nI wish I could parse query just a once and pass a coroutine to Observable. At initialization, the coroutine would subscribe to django.{app_label}.{model}, and then I would simply call coroutine.send((pk, model)) and Observer would send serialized data to client. However it seems that whenever I pass iterable to observable, it always tries to consume it whole, even when it should wait for new data. I'm kinda lost here, but it's just an optimization. The implementation works as it is, now I'm just struggling with unit tests.\nAny feedback welcome,\ncheers!. @japrogramer Thank you for the link! I finally got it, see updated gist.\nKey points:\n- StreamObservable - simple observable which you can send data into.\n- Subscription.resolve - subscribes to model_changes and map data from observable to Subscription.next, which returns instance to be sent as a new result\nThe pipeline is following:\n1. channel model_changed - notification is received on model_changed channel\n2. StreamObservable.send - calling stream.send pushes new data down the stream\n3. Subscription.next - (pk, model) tuple is resolved in model instance\n4. GraphQL Executor - all results from observable are serialized using GraphQL executor\n5. GraphqlSubcriptionConsumer._send_result - finally, new data are sent to client\n. @japrogramer Yeah, each subscribers needs to load the instance from DB. It may be optimised for single worker, but once you start scaling up, each subscriber might be handled by different process and you can only pass serializable objects through channels.\nStreamObservable could be actually replaced with rx.Subject which does the same.\nExample query is:\ngraphql\nsubscription AlertsSubscription {\n  alerts {\n      id,\n      code,\n      date,\n      read\n  }\n}. @emilyzzz I solved it by passing context_value to client.execute explicitly.\nFirst I create fixtures for requests. It's necessary to run them through all required middlewares:\n```python\nrf fixture is from django-pytest and make_user is own user model factory\n@pytest.fixture\ndef rq_authenticated(rf, make_user):\n    user = make_user(email='test@example.lan', password='test')\nrequest = rf.post('/')\nSessionMiddleware().process_request(request)\nrequest.session.save()\nrequest.user = user\n\nreturn request\n\n@pytest.fixture\ndef rq_anonymous(rf):\n    request = rf.post('/')\n    SessionMiddleware().process_request(request)\n    request.session.save()\n    request.user = AnonymousUser()\nreturn request\n\n```\nTest is something like:\npython\ndef test_query(client, rq_authenticated):\n    executed = client.execute(query, context_value=rq_authenticated)\nI use rq_authenticated and rq_anonymous explicitly everywhere I check authentication (which is almost everywhere). ",
    "chadrik": "@tricoder42 So Is there hope of getting this into graphene or not?  Should it be spun off into its own library?\n. ",
    "kavink": "Any examples of Graphql/Graphene using subscriptions in a Flask App? Hopefully something comparable with Apollo suite ? . @ahopkins Please can you post the example someplace. Would love to look at it and maybe port it to flask.. @ahopkins Thanks ! How does one publish to feed and subscribe from server side ? i.e. how can I modify for functions to either send data into feed to client or listen to client from feed.. @japrogramer @ahopkins Thanks for gist and the pointer to RXPY, I will certainly look at it. But what im trying to understand how would it all work , Graphene/RXPY and the gist(Graphql subscriptions), basically trying to wrap my head around on it. i.e. should I use RXPY to publish and read from feed ? But I dont see a way to create channels in RXPY, like architecture wise what all components tie together. I can then try to reverse and implement something working .. ",
    "ahopkins": "@kavnik\nNot with flask, but I did build something with Sanic which is flask like if you are interested I can send it to you.\nSee here: https://github.com/graphql-python/graphene/issues/545\nAdam Hopkins\nOn Feb 7, 2018, 4:13 AM +0200, kavink notifications@github.com, wrote:\n\nAny examples of Graphql/Graphene using subscriptions in a Flask App? Hopefully something comparable with Apollo suite ?\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub, or mute the thread.\n. @kavink Here is a gist: https://gist.github.com/ahopkins/52bcd7d15de1e0356ee22f82b6cbf9c8. I have mine broken out into sub \"apps\", and then I have a utility to \"auto load\" my queries and migrations.\n\nSo, it looks like this:\ndata\n    player\n        mutations.py\n        queries.py\n        types.py\n    team\n        mutations.py\n        queries.py\n        types.py\n    user\n        mutations.py\n        queries.py\n        types.py\n    mutation.py\n    query.py\nThe contents of data/query.py is something like this:\n```python\nclass QueriesAbstract(graphene.ObjectType):\n    pass\nqueries_base_classes = [QueriesAbstract]\ncurrent_directory = os.path.dirname(os.path.abspath(file))\ncurrent_module = current_directory.split('/')[-1]\nsubdirectories = [\n    x\n    for x in os.listdir(current_directory)\n    if os.path.isdir(os.path.join(current_directory, x)) and\n    x != 'pycache'\n]\nfor directory in subdirectories:\n    try:\n        module = importlib.import_module(f'{current_module}.{directory}.queries')\n        if module:\n            classes = [x for x in getmembers(module, isclass)]\n            queries = [x[1] for x in classes if 'Query' in x[0]]\n            queries_base_classes += queries\n    except ModuleNotFoundError:\n        pass\nqueries_base_classes = queries_base_classes[::-1]\nproperties = {}\nfor base_class in queries_base_classes:\n    properties.update(base_class.dict['_meta'].fields)\nQueries = type(\n    'Queries',\n    tuple(queries_base_classes),\n    properties\n)\n```\nAnd, a similar file for mutation.py\nProbably could be improved some. But, what this allows.. me to do:\npython\nschema = Schema(query=query.Queries, mutation=mutation.Mutations)\nAnd, all I need to do is create a file in the right directory and everything gets loaded automatically.. @nishant-jain-94 \nIt is hooked up to a DB. In this case, it is using Neo4j. So, inside data/player/types.py is the following:\n```python\nimport graphene\nfrom data.base_abstracts import BaseAbstract\nfrom lib.utils import import_module\nfrom lib.db import fields\nfrom lib.db.resolvers import RelatedNodeResolver\nclass SchoolAbstract(BaseAbstract):  # BaseAbstract just defines some fields that should be on ALL types\n    name = graphene.String()\n    slug = graphene.String()\n    abbreviation = graphene.String()\n    ...\nclass School(SchoolAbstract, graphene.ObjectType):\n    players = fields.NodeList('data.player.types.Player')\n    ...\n###########################\n#        RESOLVERS        #\n###########################\ndef resolve_players(self, args, context, info):\n    Player = import_module('data.player.types.Player')\n    return RelatedNodeResolver(self, 'Player', args, context, info).execute(Player)\n\n```\nBasically, my types.py file has two things (perhaps I could break them out into separate files, I have not found the need yet).\n\nAbstract classes\nObject classes\n\nThe Abstract classes define the fields. The Object classes define the resolvers, and inherit from the Abstract. This separation makes it so that everything is easy (for me) to find.\nAs for RelatedNodeResolver, I have a set of custom resolvers that I have abstracted away so that each of my resolvers inside the types.py files are very short. They put together my cypher queries for Neo4j and execute to return the results. If you are also using Neo4j and curious what that looks like, let me know.. @ProjectCheshire Glad to hear you are using it. Or something like it. I agree that there is room for improvement, and I may borrow some of your adjustments too!\nAs for neomodel, I thought about using it but ended up writing some custom resolvers that build the queries and execute them, mostly because I was interested to play around with cypher directly.. ",
    "mgasner": "also super interested in anything with flask or flask-like. ",
    "blackflame007": "Subscriptions should be in Graphene2.0+ @syrusakbary mentioned it in this tweet https://twitter.com/syrusakbary/status/923325568157859840?lang=en\nI can't find the function in the repo or any documentation, let's hope we get an update soon. ",
    "nsh87": "\nNote that Input and Output data have different types by design (as reflected in the GraphQL spec), so you can't use a ObjectType as input.\n\nThat is especially explanatory as to why my proposed method wouldn't work.\nI suspected this was possible in some way. This does solve the nested queries quite well. I've looked through several Issues regarding nesting/subquerying; some playground examples in the docs (for this and other common scenarios) would be valuable, in my humble opinion. I saw the InputObjectType in the AbstractType docs page, but for me that more demonstrated type inheritance (which is, in fact, quite convenient in that example) than how to take additional input. It becomes more clear with more knowledge of GraphQL's specs and what that class aims to do. Awesome work, by the way, @syrusakbary. Thanks for the quick response and the library.\n. ",
    "ghost": "This method no longer seems to work on Graphene 2.0. What would be a good way to accomplish filtering under this new upgrade?\nSpecifically, 'args' is now deprecated, and when I tried passing in, say, 'title' in the resolve_ function, it's complaining\nresolve_<field>() missing 1 required positional argument: 'title'. ",
    "Tchol": "You can fix this one in many ways.\nI think the simplest fix would be to add the following :\npython\ncls = ObjectTypeMeta.__new__(cls, name, bases, dict(attrs, _meta=options))\noptions = cls.options # <- this\nin graphene-django.types l#86\nor by calling extend_with_meta on either _meta from graphene.objecttypes or options from graphene-django.types like so : \nin graphene-django.types\npython\ncls = ObjectTypeMeta.__new__(cls, name, bases, dict(attrs, _meta=options))\noptions.extend_with_meta(cls.options)\nHaven't tried it yet though.\nI am not really sure what was intended with this implementation in the first place but it feels that both fixes are somewhat wacky patterns.. ",
    "helfer": "@syrusakbary Ping. It would be great if this could be merged before we release Apollo 1.0!. Thanks @vincentfretin, I just fixed it!. @syrusakbary bump. ",
    "vincentfretin": "@helfer I don't use Django but I looked at the code in graphene_django/views.py\nThere is this line in the __init__:\nassert not all((graphiql, batch)), 'Use either graphiql or batch processing'\nIt seems that you can't enable graphiql with batch enabled, right? So it seems your example is wrong.\nIf this is Django specific, it may be a better idea to include this doc in https://github.com/graphql-python/graphene-django. Hi @return007, maybe I'm off topic, but it may interest you. For a webob implementation (for pyramid framework for example) I use https://github.com/ecreall/graphql-wsgi/ on both Python 2.7 and Python 3 projects. I updated it recently to work with latest graphene version. I plan to implement batching queries soon.. The issue is only on Python 3, this is because in graphene/types/enum.py\nthere is this:\ntry:                                                                            \n    from enum import Enum as PyEnum                                             \nexcept ImportError:                                                             \n    from ..pyutils.enum import Enum as PyEnum\nThere seems to actually import again graphene/types/enum.py module, not the enum package from standard lib, as I found out last time I tried to debug the \"AttributeError: 'ProtoEnum' object has no attribute '_meta'\" error.\nTry to rename graphene/types/enum.py to something else to see if this resolve the issue.\nFor a workaround, to not use the wrong imported enum, you can create your enum this way:\nfrom graphene.pyutils.enum import Enum as PyEnum\nsentiments_enum = PyEnum('SentimentTypes', (                                    \n    ('LIKE', 'LIKE'),                                                           \n    ('DISAGREE', 'DISAGREE'),                                                   \n    ('DONT_UNDERSTAND', 'DONT_UNDERSTAND'),                                     \n    ('MORE_INFO', 'MORE_INFO')))                                                \nSentimentTypes = graphene.Enum.from_enum(sentiments_enum). My comment https://github.com/graphql-python/graphene/issues/520#issuecomment-324839001 may help you.. ",
    "blakegong": "For now I have modified customRelayField = relay.Node.Field(CustomRelayNode) to:\n```python\ncustom_relay_field = graphene.Field(CustomRelayNode, id=graphene.NonNull(graphene.ID))\ndef resolve_custom_relay_field(self, args, context, info):\n    return relay.Node.get_node_from_global_id(args.get('id'), context, info)\n```\nThis is for now the workaround I am using, and is working fine. But the problem remains.. Hi @syrusakbary ,\nSure. Will prepare one and let you know again :). This issue happened on my company repo. Was not able to connect during weekends.\nWill try to extract a minimal reproduction code and come back here in a day or two ;). Well... I tried all the ways I could think of to reproduce this issue by using only package graphene itself, but could not get the same error output. Then I tried to reproduce this issue in the big company repo (I was questioning myself whether this is a real issue after failing so many times to reproduce it), and indeed it was there.\nI guess I will set up a minimal Django project to demo it (the same as the company repo), hopefully you could kindly help to debug on that! Thanks!. Hi @syrusakbary,\nPlease take a look at this repo if possible. The actual code written by myself in this project is less than 100 lines, just to get everything set up and going. \nI have written a brief README over there and should help to get the project up and running. Please let me know if anything else is needed.\nApologies for the long delay and this unusual way to report the bug... Hope you would understand :)\nThanks!. Thank you @syrusakbary! \ud83d\udc4d . The suggestion I could give is... when doing module_path, class_name = dotted_path.rsplit('.', 1), if class_name == Edge or class_name == Connection, recursively going deeper into the upper path to resolve the class.\nOr maybe just always try all the combination of module_path and class_name, if certain layer can be imported correctly, just return. e.g.:\n```python\nfunction call:\nlazy_import('some_package.schema.nodes.Event.Connection.Edge')\nimports to be tried (module_path, class_name_with_attributes):\nsome_package.schema.nodes.Event.Connection        Edge\nsome_package.schema.nodes.Event        Connection.Edge\nsome_package.schema.nodes        Event.Connection.Edge\nsome_package.schema        nodes.Event.Connection.Edge\nsome_package        schema.nodes.Event.Connection.Edge\n```\nIf you think this is good, I can write a PR for this.. Hi @syrusakbary ,\nLooks good! Yours is more definitive and can be easily implemented. Should lead to less bugs in production compared to the API I was proposing.. Umm, forgot to update documents of import_string... Please do not merge yet. Document of import_string is also updated. But I could not find a concise and clear way to explain what import_string does, felt it was a bit poorly written. Please feel free to update/rewrite the document.\nBTW, I am not sure about the reason for the drop in coverage, I am sure the coverage for graphene/utils/module_loading.py is still 100%.. Well that is a bit wrong indeed...\nTake your Job resolver for example, Job.objects.filter(**args) approximately equates to Job.objects.all().filter(**args). And that is why you are not getting only children Jobs.\nInstead you should be putting each children resolver inside its parent node, and doing something like:\n```python\nclass PushNode(DjangoObjectType):\n    class Meta:\n        model = Push\n        filter_fields = ('revision', )\n        interfaces = (relay.Node, )\njobs = DjangoFilterConnectionField(JobNode)\n\ndef resolve_jobs(self, args, context, info):\n    Job.objects.filter(push=self).filter(**args)\n\n```\nAnd of course, remove all the unnecessary all_* queries from your root Query class.\nThe above code might not work, but should be enough for demonstration purposes ;). ",
    "hueypeard": "Hi, I had the issue and I was able to fix it with this commit.\nIt seems that the following lines in graphql-core don't correctly compare GrapheneGraphQLType types, due to no fault of graphql-core itself. To fix this and any other issues with GrapheneGraphQLTypes being equivalent, I simply added an __eq__ comparison method to GrapheneGraphQLType to only compare the internal graphene_type and not the instances themselves.\n```\nif type.name in map:\n  assert map[type.name] == type, (\n    'Schema must contain unique named types but contains multiple types named \"{}\".'\n  ).format(type.name)\n````\nI'd be happy to submit a pull request if this is, in fact, the correct way to go about solving this issue, but I can't say for sure due to my lack of experience with this library, so if any experienced graphene users can weigh in here please let me know.. ",
    "ncrmro": "@hueypeard thanks for the input, I'm not particularly versed on the internals myself (should probably do that anyway). I await the graphene teams input as well.. @hueypeard I can confirm copying the bit from your your posted solution does allow me to dump the schema. . So graphene-django requires 'graphene>=1.1.3' for one atm. When implementing the __eq__ method querying graphql returns \n{\n  \"errors\": [\n    {\n      \"message\": \"unhashable type: 'GrapheneObjectType'\"\n    }\n  ],\n  \"data\": {\n    \"parts\": null\n  }\n}\nAlso the main motivation for upgrading is I need the lazy import feature. @syrusakbary you're amazing, thank you so much! My unit tests are now passing!. ",
    "davidyapdy": "I'm would love to contribute. I'm also starting to use Graphql for a machine learning app I'm building and would love to share what I understand. Do I email the text doc to you?. ",
    "CreatCodeBuild": "From a glance, this project is well written (though I consider some API designs hard to use). The best part so far is that it's super easy to test.\nBut, the documentation is not comprehensive. I consider myself an experienced Python developer and I am fairly familiar with GraphQL. The lib is still hard to get started because it provides many conventions and utilizes some fancy Python programming (magic).\nI am sure that this lib is very hard to use for people without GraphQL experiences. More documentation is necessary!. I am playing around with the lib. Glad to contribute some example code. The good thing is the source code is quite readable.. ",
    "thelenilson": "I have the same problem! I don't want to add the _ql suffix on all my files. This is terrible!. ",
    "alexisrolland": "Same problem here. Has anyone find a better solution to this?. I solved my issue, it seems the problem was because of missing backref parameters in  the SQLAlchemy relationships I created for these two entities. Defining the SQLAlchemy classes as below solved my issue.\n```python\nfrom .base import Base, Dictionary\nfrom .status import Status\nfrom sqlalchemy import Column, DateTime, ForeignKey, Integer, String\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\nclass BatchOwner(Base, Dictionary):\n    \"\"\"Batch owners.\"\"\"\n__tablename__ = 'batch_owner'\n\nid = Column('batch_owner_id', Integer, primary_key=True)\nname = Column('batch_owner', String, nullable=False, unique=True)\ncreatedDate = Column('created_date', DateTime, server_default=func.now())\nupdatedDate = Column('updated_date', DateTime, server_default=func.now(), onupdate=func.now())\n\nbatches = relationship('Batch', backref='batchOwner', passive_deletes=True, lazy='subquery')\nindicators = relationship('Indicator', backref='batchOwner')\n\nclass Batch(Base, Dictionary):\n    \"\"\"Batches.\"\"\"\n__tablename__ = 'batch'\n\nid = Column('batch_id', Integer, primary_key=True)\nbatchOwnerId = Column('batch_owner_id', Integer, ForeignKey('batch_owner.batch_owner_id', ondelete='CASCADE'), nullable=False)\nstatusId = Column('status_id', Integer, ForeignKey('status.status_id'), nullable=False)\ncreatedDate = Column('created_date', DateTime, server_default=func.now())\nupdatedDate = Column('updated_date', DateTime, server_default=func.now(), onupdate=func.now())\n\nsessions = relationship('Session', backref='batch', passive_deletes=True)\n\n```. I did not even know there was such a method so I agree with you that documentation about mutations is lacking overall.\nFor this reason I have documented the way I do it here on this link: https://github.com/alexisrolland/flask-graphene-sqlalchemy/wiki/Flask-Graphene-SQLAlchemy-Tutorial#add-graphql-mutations\nI\u2019m not sure if that\u2019s a good way to do mutations but it works for me.. Thank you @jkimbo \nI'm actually using Graphene-SQLAlchemy so I realize I might have not posted the question on the right repository. My ObjectType is actually defined like this:\n```python\nfrom graphene_sqlalchemy import SQLAlchemyObjectType\nfrom database.model_people import ModelPeople\nimport graphene\nclass People(SQLAlchemyObjectType):\n    \"\"\"People node.\"\"\"\nclass Meta:\n    model = ModelPeople\n    interfaces = (graphene.relay.Node,)\n\n```\nMy \"People node.\" docstring get displayed properly in GraphiQL but I'm not able to get a description for the attributes of my node since they come from the ModelPeople class defined by SQLAlchemy.\n\nI will check on the Graphene-SQLAlchemy side how this is managed.\nThanks\n. @jkimbo one more question though. Do you know how to provide a description for the fields created for my Mutation class below?\npython\nclass Mutation(graphene.ObjectType):\n    \"\"\"Mutations which can be performed by this API.\"\"\"\n    createPerson = schema_people.CreatePerson.Field()\n    updatePerson = schema_people.UpdatePerson.Field()\n    createPlanet = schema_planet.CreatePlanet.Field()\n    updatePlanet = schema_planet.UpdatePlanet.Field()\nI've tried adding the description kwarg to the Field() method but it did not really work.\n\nThanks in advance.. Thanks for the answer.\nBut this is not supported at the moment (sorry I don't understand the code snippet you linked).\nIs it?. @syrusakbary Thanks for committing this change. I have one more question. I'm installing graphene with pip. I have upgraded my graphene package to its last version:\npip install graphene --upgrade\nBut I don't think it already includes your last changes / commits to the master branch. I'm curious, what does it take to have your new version pushed to PyPi?\nThank you\nAlexis. Wrongly opened this issue in graphen repository.\nI'm closing it here and reopened it in graphene-sqlalchemy repository:\nGenerate Input Arguments from SQLAlchemy Class? #112. @ahujamoh, on a slightly different note but in case this would be of interest for you, I have put together a tutorial to use Graphene with SQLAlchemy and Flask. Feel free to check it out here: https://github.com/alexisrolland/flask-graphene-sqlalchemy/wiki. ",
    "SamCB": "Think I figured out what I was doing wrong, still a bit puzzled as to how this is what needs to be done, could probably be improved in the enum documentation?\n```python\nclass SomeError(graphene.ObjectType):\n    code = graphene.Field(\n        type=graphene.Enum.from_enum(ErrorCodes),\n        required=True\n    )\n    message = graphene.String(required=True)\n...\nreturn SomeMutation(someErrors=[SomeError(code=e.code.value, message=e.message)])\n```. ",
    "wilhelmklopp": "Thanks! This helped me resolve my problem as well. Didn't realize I had to use graphene.Field :). ",
    "camd": "Thank you!!  This got me going here.  I hadn't realized I should add resolvers into the Nodes.  I somehow missed that, but makes perfect sense now that I think about it.\nYour code was near perfect, but just needed a return in the resolver:\ndef resolve_jobs(self, args, context, info):\n    return Job.objects.filter(push=self, **args)\n\n. Here's another approach on solving this: https://gist.github.com/camd/cae123923ba8ce2442ebd6e1be34377e\nIt's a bit verbose because I included my supporting graphs for usage and context.  Most of it is in the helper.py\nI definitely borrowed heavily from several different sources (including those in this thread.)  :). I have sort-of a solution to this:\nclass TextLogErrorGraph(DjangoObjectType):\n    class Meta:\n        model = TextLogError\n\n    bug_suggestions = graphene.types.json.JSONString()\n\n    def resolve_bug_suggestions(self, args, context, info):\n        return error_summary.bug_suggestions_line(self)\n\nIn this case, it will return a JSON string for the bug_suggestions value.  I can, then, load that back into an object in the client.  This isn't optimal, but perhaps that's the only way I can return an Object for this field.  I'm not yet able to find a type that would just be an Object.. This worked to get me a normal object returned, rather than a JSON blob.  I created my own field type as such:\nfrom graphene.types.scalars import Scalar\n\nclass ObjectField(Scalar):\n\n    @staticmethod\n    def serialize(dt):\n        return dt\n\n    @staticmethod\n    def parse_literal(node):\n        return node.value\n\n    @staticmethod\n    def parse_value(value):\n        return value\n\nThen I just use this as my type for the bug_suggestions field like so:\nbug_suggestions = ObjectField()\n\nI understand why this may be considered by some to be \"against GraphQL\" because you can't specifically specify which parts of bug_suggestions get returned.  In my case, I don't care.  I want to return the whole thing and not have to specify it in my query.  Perhaps this will help someone sometime.  :). ",
    "TomRaz": "+1. ",
    "samirbr": "There is a way, but not in Graphene.\n```\nimport graphql\nsource = open('/path/to/graphql/schema/file')\nast = graphql.parse(source.read())\nsource.close()\nschema = graphql.build_ast_schema(ast)\ndef resolve_users(args, context, info):\n      // do something\nresolvers = {\n      'users': resolve_users\n}\n``\nThen, in theory you can usegraphql(schema, root_value=resolvers)` to execute. \nI tested parse the schema file to graphql schema, but not execute with my own resolvers yet.\n. I manage to make it work:\n```\ndef snake_case(w):\n    return re.sub(r'([A-Z])', r'_\\1', w).lower()\ndef keys_for(info):\n    fields = []\nfor field_ast in info.field_asts:\n    for selection in field_ast.selection_set.selections:\n        arguments = {}\n        for argument in selection.arguments:\n            arg = argument.name.value\n            value = info.variable_values.get(arg, None)\n\n            try:\n                value = argument.value.value\n            except AttributeError:\n                pass\n\n            arguments[snake_case(arg)] = value\n\n        fields.append((selection.name.value, arguments))\n\nreturn fields\n\ndef resolve_paginated(root, args, context, info):\n        limit = args.pop('limit', None)\n        offset = args.pop('offset', 0)\n        keys = keys_for(info)\n    d = {\n        key: getattr(resolvers, 'resolve_%s' % key)(\n            root,\n            dict(args.items() + arguments.items()),\n            context,\n            info,\n        ).limit(limit).offset(offset) for (key, arguments) in keys\n    }\n\n    return PaginatedType(**d)\n\n```. ",
    "jasonphillips": "I made a minimal example here:\nhttps://gist.github.com/jasonphillips/d80642fc33d98cb34bad131adfcf6ed8\nwhich could be further expanded, but covers the basics (simple resolvers).. ",
    "mplis": "@jasonphillips that is awesome! I would love for something like this to be included in graphene or installable from another package.. > Btw, in your example, the resolver is never called.\nI think that's my problem. I want the resolver to be called when using an ObjectType as a data container. I thought it might be called on __init__ but I don't think that's happening, since in my example, peter.height is a string not an integer. Is the only solution to call the resolver manually?. ",
    "tarekrached": "Would this approach also enable the output of the graphql schema language definition from an instance of graphene.Schema, or should I open a new issue to discuss that?. nm, can do this already with\npython\nfrom graphql.utils import schema_printer\nschema_printer.print_schema(schema). ...and even that's unnecessary, as the __str__ method of graphene.Schema already does this.. ",
    "dutradda": "There's a issue about that on https://github.com/graphql-python/graphql-core?\nBecause I want to implement a PR on graphql-core based on the @jasonphillips code. ",
    "x0y-gt": "I think that using this new library solves the problem: \nhttps://graphql-core-next.readthedocs.io/en/latest/usage/sdl.html. I think that using this new library solves the problem: \nhttps://graphql-core-next.readthedocs.io/en/latest/usage/sdl.html. ",
    "JohnEmhoff": "I just ran into this myself. After some source-diving and doc perusing I've more or less discovered how it works: the query must be in \"long form\" where it starts with query followed by an operation name and typed argument list. As far as I can tell this operation name is completely arbitrary (someone please correct me if I'm wrong).\nquery someMadeUpString(thingId: String!) \n{ \n  getById(id: $thingId) { someField someOtherField }\n}\nYou can then provide a binding to thingId by passing it in under variable_values to .execute:\nschema.execute(query_string, variable_values=dict(thingId=\"123\")). ",
    "khankuan": "@JohnEmhoff finally found what i was looking for. It is:\nclass Query(ObjectType):\n    thing_by_id = graphene.Field(ThingType, id=graphene.String())\n    def resolve_thing_by_id(self, args, context, info):\n        print(args['id'])\nquery {\n  thing_by_id (id: \"1\") {\n  }\n}\n. ",
    "adamdonahue": "Just found out that a lambda works.  Closing.. Is anyone going to bother looking at this, or should I just close it?. Actually, I'll just close.   Feel free to reopen if outside contributions ever become of interest, though.. ",
    "Tritlo": "What's the status of these in Graphene? . ",
    "stegben": "Require updating snapshot. create another branch . ",
    "tivaliy": "@syrusakbary @michaelkuty Can you give me an idea (with function as a factory)... It works, but if I try to call it several times (declare different arguments) I get an error:\nAssertionError: Found different types with the same name in the schema: ShortString, ShortString.. @michaelkuty so, as far as I understand there are no quick workaround on this issue?. @jkimbo, without success.... ",
    "bochuxt": "class Coworker(SQLAlchemyObjectType):\nclass Meta:\n    model = CoworkerModel\n    interfaces = (relay.Node,)\nrowid=graphene.Int()\n@resolve_only_args\ndef resolve_rowid(self, **args):\n    # print(self.__dict__)\n    id = self.__dict__['id']\n    return id.\n",
    "eldos-dl": "Isn't there any simpler way to delegate resolving to children?. This is my current hotfix. Is there a better way to do this?\n```\nimport graphene\nimport inspect\nclass ListType(graphene.List):\n    def init(self, *args, kwargs):\n        try:\n            of_type = [item for item in inspect.getmembers(self.class)\n                       if item[0] == 'child'][0][1]\n        except IndexError:\n            raise AttributeError('Class must have an attribute with name child')\n        super(ListType, self).init(of_type=of_type, *args, kwargs)\nclass AList(graphene.ListType):\n    child = A\nclass B(graphene.ObjectType):\n    a_list = graphene.Field(AList())\n```. ",
    "phil303": "I've figured out the issue here. It was a problem with the particular six version, 1.6.1 and it's implementation of with_metaclass. Upgrading up to 1.10.0 fixes this.. Sure, reopening per @sineo request.. Thanks Syrus\nWhat you're saying makes total sense. Converting the line you mentioned to the following worked:\npython\ndef enqueue_post_promise_job(fn):\n    global resolved_promise\n    if not resolved_promise:\n        resolved_promise = Promise.resolve(None)\n    gevent.spawn(fn)\nWhich is awesome and what I expected looking at the code again with your reply in mind. But this is obviously not a very generic solution. What are your thoughts on how to do that? Naively, it seems like it'd be an overhaul for the Promise codebase.. Closing as this is fixed with the Schedulers refactor.. Closing! Based on the tests, I understand how this is supposed to be used. . ",
    "sineo": "I'm currently experiencing the same issue with Graphene and Six. I'm on OSX Yosemite and using Graphene 1.1, Six 1.10.0 with Python 2.7.\nHere's the traceback:\n/Library/Python/2.7/site-packages/flask/exthook.py:71: ExtDeprecationWarning: Importing flask.ext.login is deprecated, use flask_login instead.\n.format(x=modname), ExtDeprecationWarning\nTraceback (most recent call last):\nFile \u201crun.py\u201d, line 1, in \nfrom application import application\nFile \u201c/Users/mmcartor/Sites/shiphero-api-v1/application.py\u201d, line 29, in \nimport shiphero_app.core.database\nFile \u201c/Users/mmcartor/Sites/shiphero-api-v1/shiphero_app/core/database/init.py\u201d, line 529, in \nimport graphene\nFile \u201c/Library/Python/2.7/site-packages/graphene/init.py\u201d, line 19, in \nfrom .types import (\nFile \u201c/Library/Python/2.7/site-packages/graphene/types/init.py\u201d, line 3, in \nfrom .objecttype import ObjectType\nFile \u201c/Library/Python/2.7/site-packages/graphene/types/objecttype.py\u201d, line 6, in \nfrom .abstracttype import AbstractTypeMeta\nFile \u201c/Library/Python/2.7/site-packages/graphene/types/abstracttype.py\u201d, line 40, in \nclass AbstractType(six.with_metaclass(AbstractTypeMeta)):\nFile \u201c/Library/Python/2.7/site-packages/graphene/types/abstracttype.py\u201d, line 24, in new\nif not issubclass(base, AbstractType) and issubclass(type(base), AbstractTypeMeta):\nNameError: global name \u2018AbstractType\u2019 is not defined\nAny help would be greatly appreciated.. @phil303 Do you mind re-opening this issue please, as your solution did not work for me.. ",
    "quytang": "I've just got it done.\nThanks. Yikes, I know it recently! Thanks!. ",
    "nimish-gupta": "@ArfatSalman Same here, i want to restrict the fields in the nested query. But how to do? Any Sol?. ",
    "taybin": "I worked around this by setting up my own resolvers for those fields that used DataLoader to batch the queries together.  Then nested, redundant fields would use the same data, avoiding the N+1 issue.. ",
    "stubailo": "Right now we aren't actively working on Graphene integration but we provide advice and support for people working on new agents, for example there is one currently being worked on for Sangria. Looks like you're ahead of the game @chaffeqa, since you've found the correct repository. I'll ping people on Slack to get in touch and pass along any more resources we have!. I'd suggest joining the Apollo slack and messaging me there, we have a channel to help people build agents.. @chaffeqa, I think @martijnwalraven is the person to talk to to help build out an Optics integration! We're dedicated to making sure the pricing works for people at all scales. The new free tier is just the first step, we want to make sure everyone who wants to get insight into their GraphQL API can do that.\nWe have some ideas also about how we can work towards a more standard way for GraphQL servers to report performance data so you can send data to optics or any other service in an easy way that all servers can support. So if anyone is interested in that let's set up a hangout sometime soon?. ",
    "pobed2": "Hey guys,\nAny progress on this? Is there anything I can do to help?\n. This is also something that we'd like to see implemented. We've been using Graphene in production internally for a couple months now and the experience has been great so far. However, to allow us to open our API to 3rd parties, we need to be able to limit the introspection queries based on the context at execution time. \n@syrusakbary, would you be able to provide some suggestions on how this could be implemented? I'd love to help build this feature, but I'm not sure where to start.. ",
    "martijnwalraven": "@chaffeqa: Great! I'll ping a few more people and we can try to set up a meeting for next week.. @syrusakbary @chaffeqa @ajhyndman: I'm sorry I'm only getting back to you now, but I just published a description of Apollo Tracing, a proposed tracing format for GraphQL that will allow all GraphQL servers to report data to Optics. Would be great to get your feedback and see how we can add support for this to Graphene!. ",
    "dvndrsn": "@ekampf It looks like graphql-python/graphql-core#148 was merged ~15 days ago. Any update on the remaining changes for graphql-server-core and graphene?. Thanks sir! We're pretty excited for this feature, please let us know if there's anything we can do to help!. I'd also be interested in contributing to documentation. I've been using Graphene for over a year now and we've done our share of digging through the code to reverse engineer solutions and discover best practices for ourselves.\nJust wondering what the best place to start is though!. @ahokinson - could you provide some code for your schema or a more specific example of what you're trying to do?\nGraphene provides ConnectionField to implement pagination using the relay compliant connection API.\nThere's a code sample here (tho its bare bones and might need a little elaboration):\nhttps://docs.graphene-python.org/en/latest/relay/connection/\nTo page forward, we use cursor value from pageInfo or edge as after argument to the connection field and first as the pagesize in our query.\nHere's an example query:\nquery connectionStuff($cursor: String, $pageSize: int) {\n  posts(first: $pageSize, after: $cursor) {\n    pageInfo { pageEnd hasNextPage }\n    edges {\n       cursor\n       node {\n         id\n         title\n       }\n    }\n}. I'd be interested! Email: dave@dvndrsn.com\nSome folks from Joor may be interested in joining this discussion too: @pieropalevsky @nbbdog11 please cascade to interested people.. ",
    "akaone": "Any news on this ?. ",
    "lmatheus": "@chaffeqa @ekampf This seems like a great feature to have. Hope we can have it soon! . ",
    "vanpelt": "@ekampf I'm eager to hook up Optics.  What can I do to help push this over the finish line?  My company would gladly make a monetary contribution and I can contribute some code if you point me in the right direction.. ",
    "Prince-Leto": "Thank you @ekampf for your work! Can you explain how to use TracingMiddleware please?\nI tried to use it with graphene-django, but I am not able to make it work. It may not be compatible yet?\nI tried this in settings.py:\npython3\nGRAPHENE = {\n    'SCHEMA': 'path.to.schema',\n    'MIDDLEWARE': [\n        'graphql.execution.tracing.TracingMiddleware',\n    ]\n}\n[...]\n  File \"/usr/local/lib/python3.6/site-packages/graphene_django/views.py\", line 48, in instantiate_middleware\n    yield middleware()\nTypeError: __init__() missing 1 required positional argument: 'enabled'\nThen, I tried in urls.py\n```python3\nfrom graphene_django.views import GraphQLView\nfrom graphql.execution.tracing import TracingMiddleware\nurls = [\n    path('graphql/', GraphQLView.as_view(graphiql=True, middleware=[TracingMiddleware(True)])\n]\n\n[...]\n  File \"/usr/local/lib/python3.6/site-packages/graphql/execution/tracing.py\", line 96, in resolve\n    \"startOffset\": self.now() - self.start_time,\nTypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n```. ",
    "flaker": "maybe the extra types are considered superfluous somehow?  . Seems like a known behavior. Thanks!. ",
    "stan-sack": "@bochuxt did you ever deal with this? @jkimbo This is definitely still an issue. @jkimbo thanks but you're right it was a different issue. For anyone reading this in the future my problem was that I never set the teardown condition:\n@app.teardown_appcontext\ndef shutdown_session(exception=None):\n    db_session.remove(). ",
    "simpletrontdip": "I added mapping for django.contrib.auth.models.User and it worked.\n. ",
    "kaspermarstal": "You are right that this would solve the problem stated above. However WriteImage should eventually be able to accept an Image from many different kinds of mutations, e.g. a smoothing filter or a rescaling operation etc, which themselves should be able accept an image as an input argument. The idea is to script the image processing pipeline in GraphQL. I omitted that from the question to keep it simple but should have included in hindsight. Any input on this particular use case?. ",
    "frensjan": "This is an issue with or without custom meta classes:\n```python\nclass PublicQueries(ObjectType):\n    version = String()\ndef resolve_version(self, args, context, info):\n    ...\n\nclass MeQueries(PublicQueries):\n    pass\nalso causes:\nAssertionError: MeQueries fields must be a mapping (dict / OrderedDict) with field names as keys or a function which returns such a mapping.\n```. ",
    "return007": "I close it because I solved it now. For others who might face the same issue, this is what I can conclude. \nThe metaclass is where the whole problem lies. While I was doing setattr(cls, 'quantity', graphene.String()) I wrongly presumed that cls would be my Attack class. The correct way to do this is:\n```\nimport graphene\nfrom graphene.types.objecttype import ObjectType, ObjectTypeMeta\nclass mytype(ObjectTypeMeta):\n    def new(cls, clsname, base, clsdict):\n        print \"Hello\"\n        clsdict['quantity'] = graphene.String()\n        return ObjectTypeMeta.new(cls, clsname, base, clsdict)\nclass combined_meta(mytype, ObjectTypeMeta):\n    pass\nclass Attack(graphene.ObjectType):\n    metaclass = combined_meta\n    def init(self, dic):\n        self.quantity = \"123\"\n        print \"Hello world\"\n        print dic\nclass Query(graphene.ObjectType):\n    attack = graphene.Field(Attack)\n    def resolve_attack(self, args, context, info):\n        return Attack(dict())\nschema = graphene.Schema(query = Query)\nquery = '''\n{\n    attack\n}\n'''\nresult = schema.execute(query)\nprint result['data']\n```\n. @frensjan Yeah the issue is related to fact that the fields must be in form of dictionary.. ",
    "nikvdp": "After digging through some related issues, discovered @femesq's comment on  https://github.com/graphql-python/graphene/issues/478#issuecomment-305947413.\nAdding types=[Human, Dog] to the graphene.Schema(query=Query) call also fixes the issue for me.  \n@syrusakbary I'd like to update the documentation to describe this behavior, would the interfaces doc be the best place to do that?. ",
    "waxisien": "Hi,\nyou can implement it that way (simplified) : \n```\nclass Anything(graphene.types.union.Union):\n    class Meta:\n        types = (Human, Droid, Starship)\nclass Query(graphene.ObjectType):\n    search = graphene.List(Anything)\n```\nThen write a resolver for the search that will concatenate results for each type : \ndef resolve_search(self, args, context, info):\n    humans = droids = starships = []\n    # search for each type\n    return humans + droids + starships. @whalesalad Does your query contain an inline Fragment http://graphql.org/learn/queries/#inline-fragments ?\nSince the union returns different types you need a query like this : \n{\n  search {\n    __typename\n    ... on CashContract{\n      id\n      contract_status\n    }\n    ... on FuturesContract{\n      expiration_date\n    }\n  }\n}. Hi, something like this : \n```\nclass ForgottenPassword(graphene.Mutation):\n    class Input:\n        email = graphene.String(required=True)\nok = graphene.Boolean()\n\n@staticmethod\ndef mutate(root, args, context, info):\n    print 'Send email to ', args['email']\n    return ForgottenPassword(ok=True)\n\nclass MyMutations(graphene.ObjectType):\n    forgotten_password = ForgottenPassword.Field()\n```\nLook at http://docs.graphene-python.org/en/latest/types/mutations/. ",
    "whalesalad": "I am also having difficulty here.\n```python\nimport graphene\nfrom graphene.types.union import Union\nclass Contract(graphene.Interface):\n    id = graphene.Int(required=True)\n    basis = graphene.Field(DollarAmount)\n    contract_date = graphene.Field(Date)\n    contract_price = graphene.Field(DollarAmount)\n    notes = graphene.String()\n    quantity = graphene.Int()\n    underlying = graphene.Field(Underlying)\nclass CashContract(graphene.ObjectType):\n    contract_status = graphene.Field(ContractStatus)\n    contract_type = graphene.Field(CashContractType)\n    delivery_date = graphene.Field(Date)\nclass Meta:\n    interfaces = (Contract, )\n\nclass FuturesContract(graphene.ObjectType):\n    expiration_date = graphene.Field(Date)\nclass Meta:\n    interfaces = (Contract, )\n\nclass ContractUnion(Union):\n    class Meta:\n        types = (CashContract, FuturesContract)\n```\nI get the following error when I try and request a common attribute, id, in my query:\n\"message\": \"Cannot query field \\\"id\\\" on type \\\"ContractUnion\\\". Did you mean to use an inline fragment on \\\"Contract\\\", \\\"CashContract\\\" or \\\"FuturesContract\\\"?\"\n=(. @waxisien that makes sense, but I also see that in the official guide you can ask for shared attributes between the two different fragments: http://graphql.org/learn/queries/#inline-fragments\nquery HeroForEpisode($ep: Episode!) {\n  hero(episode: $ep) {\n    name\n    ... on Droid {\n      primaryFunction\n    }\n    ... on Human {\n      height\n    }\n  }\n}\nIn this case name is on both, so you can ask for it without using a fragment. . @syrusakbary thanks for the response. I actually don't even want to use a union type... I want to just pass the interface class into the List for my but that does not work. But I was finding that graphene wasn't happy about putting an interface somewhere where an ObjectType was expected? Is this intentional?. Thanks for doing that.\nIn the future I would suggest usin == instead of greater than and less than. While the chances are less likely due to the trajectory of those other projects, there is still room for this mistake to happen again. \nWhen the phrase \u201cpinning a version\u201d is used, it\u2019s implied that the versions will be exact and not a range. . ",
    "sdcooke": "I've managed to narrow this down (in our test suite, at least) to the assert in the NonNull class because it checks self.of_type in __init__. I'm not sure what the best way would be to fix this, but since it's an assert it's obviously not necessary for the code to run.. ",
    "demux": "My bad, apparently this is covered in the documentation. ",
    "keattang": "Hi @jkimbo, yes I'm still very interested in having this question answered. \nCheers!. ",
    "robinelvin": "Solved.\nOk, it was my mistake. I hadn't made the Mutations derive from graphene.AbstractType however, the error message that came back is very misleading.. ",
    "achimnol": "That annoys me as well.\nThis issue could be delegated to https://github.com/graphql-python/graphql-core/issues/112.. Tried converting my enum to graphene.pyutils.enum.Enum but the same error persists... \ud83d\ude1e . It seems that the pure graphene.Enum also does not work with the same error.. I could workaround this by modifying the resolve_value() method:\npython\n    def resolve_value(self, info):\n        if self.status == 'LIVE':\n            return 12345  # fetch some value from a remote resource\n        else:\n            return self.value\nBut this seems to be unnecessary if graphene/graphql supports conditional use of resolvers.. I began to suspect the root cause of this design \"hole\" is because there is no discretion between \"undefined\" and \"null\" values in Python like Javascript. Maybe we could use a sentinel object (kinda global constant) to represent undefined values throughout the graphene API.. ",
    "morenoh149": "@iAmMrinal0 where do you propose the link go exactly? the GitHub repo points to the project page which has docs in the navbar. The readme prominently links to the project page already. I'd vote to close this issue.. I thought so as well, but realized that that is the Contributing > documentation section. Meaning it describes how to build the docs while contributing. In my opinion a link there to the docs is not correct.. @janhancic could you share a minimal graphene api that reproduces the issue? As a GitHub repo ideally so folks can clone and run. I actually cannot follow your snippets. Granted I'm new to GraphQL and graphene.. @anudeepsamaiya I'd imagine you're free to pick this up. It's been a few months.. I take it this does not mean the js lib relay, but a graphene concept of relay?. @dan98765 needs rebase. needs rebase. needs love ;). ",
    "iAmMrinal0": "@morenoh149 I was wondering if it could be added in the Documentation section. It's a click less when someone is already reading the Readme. The impression one gets when they read the Readme is that they'd need to use Sphinx which is not the case unless one wanted to make changes to the documentation. So I thought it would be a good idea to include the link directly, similar to how other projects like Flask, Requests, Pipenv, Tornado do.\nReference\n1. Flask\n2. Requests\n3. Pipenv\n4. Tornado. ",
    "edmorley": "Looking good on the latest 2.x dev release:\nhttps://pypi.python.org/pypi/graphene/2.0.dev20170802065539\nMany thanks!. Ah this is the wrong repo - the GitHub logo on that page linked to this one instead (for which I've filed graphql-python/graphene-django#357) - I'll refile this over there (edit: filed as graphql-python/graphene-django#358).. ",
    "JoeNyland": "For anyone facing a similar issue, I worked out how to do this. self.id holds the ID of the FormType object.\nFor example, the following would be a replacement for the resolve_visits method above:\ndef resolve_visits(self, args, context, info):\n        return DBI.get_form_sessions(form_id=self.id, start_ts=args.get('start'), end_ts=args.get('end')). ",
    "pawarchinmay27": "`class Product(graphene.ObjectType):\n    productName=graphene.String()\n    productDependecies=graphene.List(ProductDependency)\n       '''\n                Here I Want access the instanceIP How Can I do that\n       '''\nclass Instance(graphene.ObjectType):\n    instanceIP=graphene.String()\n    products=graphene.List(Product)\n    ebsvolumes=graphene.List(EBSVolume)`\n       def resolve_products(self,info):\n               #some code that follows. @jkimbo I have a use case where instance will have a list of products \n I want to access the instanceName property of the class Instance in the product class.\nThe Instance class has the resolve method for products \nthe structure is more like this\ninstance123:{\n     products:['abc','def']\n}\n. @jkimbo \n```\nclass Instance(graphene.ObjectType):\n    products = graphene.List(Product)\n    instanceName=graphene.String()\n    def resolve_products(instance, info):\n          return [Product(productName,[ProductDependency()])]\nclass Product(graphene.ObjectType):\n    productName=graphene.String()\n    productDependecies=graphene.List(ProductDependency)\ndef resolve_productDependencies(product, info):\n    instance_name = product['instanceName']\n            print(instance_name)\n\n```\nI tried with this approach and got an error message 'Product' object is not subscriptable\n. @jkimbo  were you able to find a solution to this?. ```\nclass Product(graphene.ObjectType):\n    productName=graphene.String()\n    productDependencies=graphene.List(ProductDependency)\n    def resolve_productDeproductDependencies(self,info):\n        print(self['instanceName'])\nclass Instance(graphene.ObjectType):\n    instanceName=graphene.String()\n    products=graphene.List(Product)\n    def resolve_products():\n        return [Product(\"xyz\")]\n```\n@jkimbo  this is the code I tried and ended up getting that 'Product' object is not subscriptable on this line print(self['instanceName']). @jkimbo  could you help with this. ",
    "jonatasbaldin": "Thanks! Really awesome usage! I think we should include the GraphQLError on the Graphene docs.. ",
    "reverland": "just raise GraphQL may not a good idea? for I find the error directly raised in mutation wont be even catched? so tests with assertRaises will never work.\n```\nIn [9]: try:\n   ...:     client.execute(query_string)\n   ...: except:\n   ...:     pass\n   ...:\n\nGraphQLLocatedError                       Traceback (most recent call last)\n~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/graphql/execution/executor.py in complete_value_catching_error(exe_context, return_type, field_asts, info, result)\n    328     try:\n    329         completed = complete_value(\n--> 330             exe_context, return_type, field_asts, info, result)\n    331         if is_thenable(completed):\n    332             def handle_error(error):\n~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/graphql/execution/executor.py in complete_value(exe_context, return_type, field_asts, info, result)\n    381     # print return_type, type(result)\n    382     if isinstance(result, Exception):\n--> 383         raise GraphQLLocatedError(field_asts, original_error=result)\n    384\n    385     if isinstance(return_type, GraphQLNonNull):\nGraphQLLocatedError: custom_error\n```. ",
    "AshwinRamesh": "@syrusakbary Sorry for the confusion. I meant to post this on the graphene-django issues. The many-to-many bug (https://github.com/graphql-python/graphene-django/pull/181) etc. are items we are looking forward to in an official release. Also looking forward to 2.0 in all packages. Thanks!!. ",
    "joealcorn": "I'm getting similar errors using a subclass of the built in Enum type, seems like using it in inputs is not supported to me. I found this comment from over a year ago but it no longer seems to work.\nI've tried all of the following (and wrapped with Argument too) and received an error every time\npython\nclass Input:\n    type = ProjectTypeEnum(required=False)\npython\nclass Input:\n    type = ProjectTypeEnum(required=False).InputField()\npython\nclass Input:\n    type = ProjectTypeEnum(required=False).Field()\n. Wrapping in Argument doesn't work either - when trying with\npython\nclass Input:\n    type = graphene.Argument(ProjectTypeEnum(required=False))\nI get AttributeError: 'ProjectTypeEnum' object has no attribute 'name'.\nI'm on graphene==1.4.1\nI can give it a name attr and it'll get further, but it still does not work and that is not documented, so I'm feeling like that's the wrong thread to follow.\nERROR      2017-08-24 12:12:18,038 [a7a9a0db-2532-4eac-9fbf-3911927bffc0] executor:203 resolve_or_error An error occurred while resolving field __Type.kind\nTraceback (most recent call last):\n  File \"/Users/joe/.venvs/marvel/lib/python2.7/site-packages/graphql/execution/executor.py\", line 200, in resolve_or_error\n    return executor.execute(resolve_fn, source, args, context, info)\n  File \"/Users/joe/.venvs/marvel/lib/python2.7/site-packages/graphql/execution/executors/sync.py\", line 7, in execute\n    return fn(*args, **kwargs)\n  File \"/Users/joe/.venvs/marvel/lib/python2.7/site-packages/graphene_django/debug/middleware.py\", line 55, in resolve\n    promise = next(root, args, context, info)\n  File \"/Users/joe/.venvs/marvel/lib/python2.7/site-packages/graphql/execution/middleware.py\", line 57, in make_it_promise\n    return Promise.resolve(next(*a, **b))\n  File \"/Users/joe/.venvs/marvel/lib/python2.7/site-packages/graphql/type/introspection.py\", line 213, in kind\n    raise Exception('Unknown kind of type: {}'.format(type))\nException: Unknown kind of type: <marvelapp.graphql.schema.ProjectTypeEnum object at 0x10a8b0390>\n. I'm defining an Enum like the documentation says\nhttp://docs.graphene-python.org/en/latest/types/enums/#definition\n(sorry, slightly different to the original issue, but with similar errors)\n. That's not my code :)\nMine looks like this\npython\nclass ProjectTypeEnum(graphene.Enum):\n    PROTOTYPE = 1\n    DESIGN = 2\nI've been able to get the enum reflected in the schema but I can't manage to actually pass it values using graphql which is why I've been trying to find other ways.\n```python\nclass CreateProjectInput(graphene.InputObjectType):\n    type = ProjectTypeEnum(required=False)\nclass CreateProjectMutation(graphene.Mutation):\n    class Input:\n        data = graphene.Argument(CreateProjectInput)\n```\n\nRequest\ngraphql\nmutation mutName {\n  createProject(data: {name: \"Test\", type: \"PROTOTYPE\"}) {\n    ok\n  }\n}\nResponse\njson\n{\n  \"errors\": [\n    {\n      \"message\": \"Argument \\\"data\\\" has invalid value {name: \\\"Test\\\", type: \\\"PROTOTYPE\\\"}.\\nIn field \\\"type\\\": Expected type \\\"ProjectTypeEnum\\\", found \\\"PROTOTYPE\\\".\",\n      \"locations\": [\n        {\n          \"column\": 23,\n          \"line\": 2\n        }\n      ]\n    }\n  ]\n}. I took it out to keep the example short, it's there in reality.\nThe error message is specifically saying the value for the type field is wrong\nArgument \"data\" has invalid value {name: \"Test\", type: \"PROTOTYPE\"}.\nIn field \"type\": Expected type \"ProjectTypeEnum\", found \"PROTOTYPE\".. No luck there, but I have found a fix for the issue.\nI've been passing the enum value incorrectly.\nhttp://graphql.org/learn/schema/#enumeration-types\nNotice that enums aren't defined as strings in the schema, but I've been passing a string in my mutation.\nHere's a correct mutation:\ngraphql\ncreateProject(data: {type: PROTOTYPE}) {\n    ok\n}\nSorry for hijacking this issue, and thanks for the help! :). ",
    "totaki": "In input fields you need use graphene.Argument instead Field. Example: https://github.com/totaki/graphql-learn/blob/develop/articles/ru/episode-2/move_task/README.md\n. I think you doing some thing wrong, if you want use some custom field you need Scalar http://docs.graphene-python.org/en/latest/types/scalars/. class ProtoEnum(graphene.Field):\nit`s not same in documetation\nhttp://docs.graphene-python.org/en/latest/types/enums/#definition. python\nclass CreateProjectInput(graphene.InputObjectType):\n    type = ProjectTypeEnum(required=False)\nWhere name field?. Change field name :). Please use python for highlight, and split files and examples. My solve problem, something like this\n**iteration.py**python\nclass IterationObject(graphene.ObjectType):\n    id = graphene.Int()\n    tasks = graphene.List(TaskObject)\n```\ntasks.py\n```python\nclass TaskObject(graphene.ObjectType):\n    id = graphene.Int()\n    iteration = graphene.Field('iteration.IterationObject')\n@property\ndef iteration_class(self):\n    return self._meta.fields['iteration'].type\n\n.python\n    class Input:\n        text = graphene.String(description='Text', required=True)\n        id = graphene.Int(description='Todo Id', required=True)\nThis schema say you can use only:graphql\n  mutation RenameTodoMutation($textValue: String!, $idValue: Int!) {\n    renameTodo(text: $textValue, id: $idValue) {\n      todo {\n        id\n        text\n      }\n    }\n  }\n```\nFor custom types you need use http://docs.graphene-python.org/en/latest/types/scalars/. ",
    "btubbs": "I've found that this works if I use double backslashes to escape the quotes in the mutation argument.  Working example:\n```\nimport graphene\nfrom pprint import pprint\nclass CreatePerson(graphene.Mutation):\n    class Arguments:\n        name = graphene.String()\n        meta = graphene.JSONString()\nok = graphene.Boolean()\nperson = graphene.Field(lambda: Person)\n\ndef mutate(self, info, name, meta):\n    pprint(meta)\n    person = Person(name=name, meta=meta)\n    ok = True\n\n    return CreatePerson(person=person, ok=ok)\n\nclass Person(graphene.ObjectType):\n    name = graphene.String()\n    meta = graphene.JSONString()\nclass MyMutations(graphene.ObjectType):\n    create_person = CreatePerson.Field()\nWe must define a query for our schema\nclass Query(graphene.ObjectType):\n    person = graphene.Field(Person)\nschema = graphene.Schema(query=Query, mutation=MyMutations)\nq = \"\"\"\nmutation myFirstMutation {\ncreatePerson(name:\"Peter\", meta:\"{\\\"foo\\\":\\\"bar\\\"}\") {\n        person {\n            name,\n            meta\n        }\n        ok\n    }\n}\n\"\"\"\nresult = schema.execute(q)\nprint(result)\nprint(result.errors)\nimport json\nprint(json.dumps(result.data, indent=2))\n```. ",
    "IgorBMSTU": "How can we solve this problem without violating pep8? \nThere is import inside function. Thank you! This is exactly what we need. ",
    "tony": "@ekampf I wonder if this example would still work now?\nFor me this gives AttributeError: 'Dynamic' object has no attribute 'name' (2.1.3). @jkimbo Has this changed since this issue has been posted? (I'm playing with this example code right now and it's not working. It seems the resolve_type on the interface is never executed. I will try to come up with a minimal example)\n(Edit) Potentially related: https://github.com/graphql-python/graphene/pull/775. This issue was due to me using a field named type. I'm abandoning this PR since my case is probably solved by #775. What I want to do: I want to see if I can compute the concrete type of a field early, but need more information:\nI'd like to have access to other object information for the parent type, and possibly the schema implementing it (lambda isn't enough in this case).. ",
    "jychen7": "It is kind of useful because in our case, we need user_id to resolve user\nit would be better if frontend team only see user in introspection. ",
    "Fity": "Same issue with @pobed2 \nDon't know how to solve it yet.. @jkimbo  why not update Enum.__eq__ function to use == for non-enum object values?\nIt is weird that MyEnum.TypeA == small_value works and MyEnum.TypeB == big_value not.\nIMO, graphene should support these two cases or, just remove this feature and users should only use MyEnum.TypeA.value.\nrelated code in graphene: https://github.com/graphql-python/graphene/blob/master/graphene/types/enum.py#L15\nupdates\nfind out that using is supports EnumA.Field != EnumB.Field. Not sure what is the best way to compare the values.. @jkimbo Yes, you are right. Will close this issue.\nAbout small_value, due to Python's small objects pool, if we have a Enum like this:\nPython\nclass MyEnum(graphene.Enum):\n    SmallValue = 123\nMyEnum.SmallValue == 123 would work fine.. ",
    "harryjubb": "Gentle bump for this? With Graphene-Django I've made middleware to change access rights depending on whether the user is authenticated (see graphql-python/graphene-django#345), but the whole schema can still be introspected which is not ideal.. ",
    "rjdp": "@ekampf Is there any tradeoff with this approach as compared to relay style cursor pagination ? I am trying to understand the same, your insight will be greatly helpful.. @syrusakbary I have usecase , any insight is very helpful , consider  an api that returns paginated response which are flat(unlike relay style nodes/edges) , performance is my top priority still I would want to have flat response, is it possible to somehow efficiently parse relay style response to flat style.     even if you can point me to some resource that will me make this decision, it will be very helpful .. what would you do for this use case ? . Thanks for the help \ud83d\udc4d . ",
    "earlgreyz": "I don't know how about Django, but you might do it manually\n```python\nclass Query(graphene.ObjectType):\n    cities = graphene.List(City, kind__in=graphene.List(graphene.String)\ndef resolve_cities(self, args, context, info):\n    query = # Get django query\n    kind__in =  args.get('kind__in', None)\n    if kind__in:\n       # Apply django in filters\n    return query\n\n```. GraphQL allows you to traverse graph and there is no way to filter on child node properties. In many cases you create backrefs and traverse graph starting in child nodes and then going back to parent, but as you need to filter on both parent and child this won't help you. It feels wrong because GraphQL was not meant for this kind of queries, however your solution is correct for this particular problem.. You need a schema to query. GraphQL is strongly-typed and you also need resolvers to tell graphene how to get the data from the dict. To make this example work you'll need something like:\n```python\nfrom functools import partial\nimport graphene\nSOME_DATA = {\n    \"too\": 42,\n    \"much\": [1, 2],\n    \"data\": \"hello world\"\n}\ndef resolver(param, self, args, context, info):\n    return self[param]\nclass MyData(graphene.ObjectType):\n    too = graphene.Int()\n    much = graphene.Field(graphene.Int, index=graphene.Int())\n    data = graphene.String()\nresolve_too = partial('too', resolver)\nresolve_data = partial('data', resolver)\n\ndef resolve_much(self, args, context, info):\n    index = args.get(index)\n    return data['much'][index]\n\nclass Query(graphene.ObjectType):\n    data = graphene.Field(MyData)\n    def resolve_data(self, args, context, info):\n        return SOME_DATA\nschema = graphene.Schema(query=Query)\nresult = schema.execute('''\n{\n    data {\n        much(1)\n        data\n    }\n}\n''')\nprint(result.data)\n```\nThe result would be\njson\n{\n    \"data\": {\n        \"much\": 2,\n        \"data\": \"hello world\"\n    }\n}\nYou might write something more generic to map your dict to graphene type (check out graphene-sqlalchemy library source code or graphene-django). Let's say you created graphene-dict library based on the graphene-sqlalchemy/graphene-django - then mapping/resolving is generated automatically and you might do:\n```python\nimport graphene\nfrom graphenedict import DictObjectType\nclass MyData(DictObjectType):\n    class Meta:\n        model = SOME_DATA\nclass Query(graphene.ObjectType):\n    data = graphene.Field(MyData)\n    def resolve_data(self, args, context, info):\n        return SOME_DATA\nschema = graphene.Schema(query=Query)\n```\nDon't worry it's actually easier than it sounds ;D.\n. ",
    "jkuszczynski": "Now I see this issue belongs more to graphene-django.\nAnyhow I applied workaround by custom filter with new field ingredient_name which has custom method. \nStill it would be best to provide option to filter by objects. Which  then are properly translated to foreign_key query.. ",
    "mvdwaeter": "I think it relates to: https://github.com/graphql/graphql-js/issues/433\nAnd based on that ticket I managed to fix it, by adding a parse_value to NodeID:\n```\nclass NodeID(ID):\n    @staticmethod\n    def parse_literal(node):\n        \"\"\"\n        :return: Object or None\n        \"\"\"\n        if isinstance(node, StringValue):\n            return get_from_global_id(node.value)\n@staticmethod\ndef parse_value(s):\n    \"\"\"\n    :return: Object or None\n    \"\"\"\n    if isinstance(s, string_types):\n        return get_from_global_id(s)\n\n```\nThe mutation query without query parameters is using NodeID.parse_literal\nAnd the second mutation query, with query parameters is using NodeID.parse_value\n. ",
    "mojochao": "Thanks @syrusakbary.  Unfortunately, I'm still seeing the same error.. I found that I had to update graphql-core, graphene, and graphene-sqlalchemy to the 2.0.dev versions.  After that, the suggestion made by @syrusakbary worked for me. . ",
    "absolutelyNoWarranty": "@syrusakbary don't know if this is the same as @mojochao's issue but the mutation example in the docs doesn't seem to work. I copied and pasted the example from the documentation on mutations into the playground\nand the result is Unknown argument \\\"name\\\" on field \\\"createPerson\\\" of type \\\"MyMutations\\\".). ",
    "nakeeon": "Hi @syrusakbary,\nI solved the issue. Graphene is fine. The problem was in the Apollo client, because  Apollo cannot determine the IDs to use for object. There is a dataIdFromObject function for that purpose. I took this peace of code from the Apollo tutorial:\nconst client = new ApolloClient({\n  dataIdFromObject: o => o.id\n});\nBut I have several instances of a Django models with the same ids, so it caused the problem with typename of objects.\nChanging the code to this is solved the problem:\nconst client = new ApolloClient({\n  dataIdFromObject: o => `${o.__typename}-${o.id},`\n});\nSorry for disturbing.. ",
    "rafaponieman": "I haven't seen a reference to this on the documentation, but thankfully I found this issue as I was seeing data randomly replaced... Maybe this could be documented? Thank you. ",
    "oharlem": "@btorellALTA \nI'm in the same situation and just had to implement a list of custom arguments specifically for that, ex. content_slug that goes into a related Content type to filter by slug.\nHowever, that said, I initially started with this: https://github.com/graphql-python/graphene-django/blob/master/docs/filtering.rst\nAnd looks like it should work with django-filters  / DjangoFilterConnectionField, allowing you to use arguments like content__slug <- check the double underscore in it. Had to stop as getting mixed set of different issues.\n. @gijswobben \nWorking in Django, for example, through some trial and error I found it useful to split as simple as:\nsh\nfoo_graphql/\n  errors.py\n  middlewares.py\n  dataloaders.py\n  schema.py\n  types.py\n  util.py\n  ...etc\nThe largest file is obviously types.py. \nWith a number of types growing, will just move into its own dir with types as separate files.. @japrogramer \nMind sharing how you added custom fields to pageInfo please?\nI reached a point where I use a custom connection (class MyConnection(relay.Connection):)  and my version of PageInfo, however I believe the questions is - how to pass data from a resolver to PageInfo? i.e. total counts, etc.\nThank you!\n. ",
    "anisjonischkeit": "Is graphene 2.0 stable enough for us to start testing with? Is syntax stable?. If you want to use these, you can already, just import like this\nfrom graphene.types.datetime import DateTime, Date, Time. added tests. ",
    "zahlio": "We would also like to hear about the state of 2.0. Docs tell you to use 2.0 (although its a dev release), should we use 2.0 or stay on 1.X for now?\nWhat is the timeline of 2.0?. ",
    "caffodian": "I also have similar questions - it would be nice if there was a PR or issue organizing what is left before a 2.0 release (we could even help out, too, if we knew what was needed) . ",
    "mraak": "It's still not tagged so I guess it's not stable enough.. I figured out. It's returning null because id of the model has to be GraphQL idnot the Django id. . ",
    "pwuertz": "Thank you @earlgreyz for this in-depth explanation! Basically my understanding of graphene's principles was very limited. When I saw its query/response syntax for the first time I was intrigued by the idea of using this protocol in my application as a type of generic object debug/inspection tool (so no statically defined type hierarchy).\nWith graphene relying on static, strongly typed interfaces this doesn't seem to be the right tool for this specific use case. But if things get more settled here I'd love to take a shot at DictObjectType and post my results.\nThanks again!. ",
    "yarian": "Experiencing same issue. This broke production for us. got an unexpected keyword argument. I tried adding the following to my requirements.txt and it seems to have accomplished the same outcome:\ngraphql-core ~= 1.1\ngraphql-relay~=0.4.5\ngraphene ~= 1.0\ngraphene_sqlalchemy ~= 1.0\nDefinitely annoying that this just broke with no warning. :. ",
    "0xCMP": "For anyone experiencing this issue please be sure to update your version of pip first. I had 1.5.4 installed and it wouldn't respect the ,<2 restraint.. To help those googling: \"Object is not a Promise like object\"\nI only found this issue via my co-worker.. ",
    "jeremytiki": "Excellent! That was exactly what the problem was! Thank you for your help @richmondwang . ",
    "piercefreeman": "Hi @ekampf - Got it.  The reason the above schema would be useful is because Apollo (http://dev.apollodata.com) uses client-side hashing based on entity types that are returned by mutations.  So if a Channel is returned by a mutation, its internal buffers will be updated to reflect the added/modified Channel object.  If \"AddChannelMutation\" comes back it doesn't offer the same level of built-in caching since the return type is different.\nAre there any workarounds to support this or would I have to migrate to another framework?. ",
    "nishant-jain-94": "@ahopkins I like your folder structure. But I have something which is bothering me. How do you manage field resolvers, for instance your team may have a list of players, where do you exactly resolve that? In the data/team/queries.py? or probably somewhere else? . ",
    "cmmartti": "The examples on this page were a little confusing, so once I figured it out, I thought I'd put together a small working example of the fractal-style schema approach, which you can find  at https://github.com/cmmartti/fractal-style-schema.. @Lucretiel That works if all your types are in one file, but as soon as you have types that reference one another (for example, Student has a Teacher, and Teacher teaches Students), which is extremely common, you'll run into circular import errors.. @ProjectCheshire How do you handle circular imports? I can use lambdas if I put everything in one file, but I'd like to use yours and ahopkins' approach, which otherwise works great.. @ProjectCheshire Oh wow, yet another thing that should be in the docs but isn't. That solves my problem perfectly :)\nFound an issue that mentions it. Thought I'd been thorough with my searches, but apparently not.\nI put together a small working example of this \"fractal-style schema\" approach here.. ",
    "dongyuzheng": "EDIT: I had a folder called graphql in my path. Changing its name fixed this.\nI have the same issue:\n```powershell\n(venv) PS D:\\backend\\backend> python .\\manage.py runserver\n...\nFile \"D:\\backend\\venv\\lib\\site-packages\\graphene\\types__init__.py\", line 2, in \n    from graphql import ResolveInfo\nImportError: cannot import name 'ResolveInfo'\n(venv) PS D:\\backend\\backend> pip freeze\ncolorama==0.3.9\ndecorator==4.1.2\nDjango==1.11.5\ngraphene==2.0.dev20170802065539\ngraphene-django==2.0.dev2017083101\ngraphql-core==2.0.dev20170801051721\ngraphql-relay==0.4.5\nipdb==0.10.3\nipython==6.2.0\nipython-genutils==0.2.0\niso8601==0.1.12\njedi==0.10.2\npickleshare==0.7.4\npromise==2.1.dev0\nprompt-toolkit==1.0.15\nPygments==2.2.0\npytz==2017.2\nsimplegeneric==0.8.1\nsingledispatch==3.4.0.3\nsix==1.11.0\ntraitlets==4.3.2\ntyping==3.6.2\nwcwidth==0.1.7\n(venv) PS D:\\backend\\backend> python --version\nPython 3.6.2\n(venv) PS D:\\backend\\backend>\n```. ",
    "dpnova": "Digging into this:\n```\n\n/home/dpn/.virtualenvs/nibble/lib/python3.5/site-packages/graphql/type/definition.py(409)serialize()\n-> def serialize(self, value):\n(Pdb) s\n/home/dpn/.virtualenvs/nibble/lib/python3.5/site-packages/graphql/type/definition.py(410)serialize()\n-> if isinstance(value, collections.Hashable):\n(Pdb) pp isinstance(value, collections.Hashable)\nFalse\n(Pdb) pp self._value_lookup.get(value)\n*** TypeError: unhashable type: 'EnumMeta'\n(Pdb) \n\n```\nIt seems Enum isn't hashable.. Sorry I haven't been working on the codebase - but you solution seemed to be right based on what my own patches had added to the lib, I suspect it's more a documentation thing now.\nThanks!. ",
    "metrafull2": "use def resolve_hello(self, info, **kwargs): instead, is a problem in this patch, I don't know why. ",
    "badrobit": "I would also really like to be able to ingest a schema using the type language, maybe to simplify things just the datatypes instead of the methods but some form of pulling this in would be amazing!. ",
    "rmoorman": "@mraak thank you so much for this issue, mentioning that the id used for a relay.Node.Field() has to be a GraphQL id (base64 encoded MyType:idofthetype) and that you created a project readme with useful information. I was trying to get the relay.Node.Field working on an object type to lookup a related object based on some parent information and you made me realise that instead of using:\ncourse(id: \"c1cd7622-9a69-4aa7-b0e1-e69f8a150a10\") {\n  name\n}}\nI would have to use\nnode(id:\"Q291cnNlVHlwZTpjMWNkNzYyMi05YTY5LTRhYTctYjBlMS1lNjlmOGExNTBhMTA=\") {\n  ... on CourseType{\n    name\n  }\n}\nfor this kind of field \ud83d\udc4d \n. ",
    "aj07mm": "\nhttps://github.com/graphql-python/graphene/issues/552#issuecomment-333738311\n\nwhere I can find the graphql id?. ",
    "ravangen": "Seems to relate to https://github.com/graphql-python/graphene/issues/538. ",
    "g--": "Yup! Duplicate . ",
    "mrstork": "Error from the travis logs: The program 'py.test' is currently not installed. To run 'py.test' please ask your administrator to install the package 'python-pytest'. ",
    "nykolaslima": "Great implementation, thank you it really helped me!. ",
    "flpStrri": "@dfee, you managed to make this work when using a graphene DateTime scalar? I could not make it with your solution.. ",
    "jakesyl": "This looks resolved.. ",
    "lincolnq": "I also have this problem, and it's a big blocker for me. However, I don't like the suggested PR. I think it would be better to fix it at the GraphQLEnumType level (because this is really not an issue with the resolver -- it's an issue with the enum type itself not recognizing instances of enum as valid values), but I'm not sure how exactly is the best way to do it.\nExample that clarifies that it's not a resolver issue:\n```py\nimport graphene as gql\nclass Currency(gql.Enum):\n    USD = 10\n    GBP = 20\nclass Query(gql.ObjectType):\n    currency1 = Currency()\n    currency2 = Currency()\n    def resolve_currency1(self, info):\n        \"\"\"Return a Currency value.\"\"\"\n        return 10\n    def resolve_currency2(self, info):\n        \"\"\"Return a Currency instance.\"\"\"\n        return Currency.USD\nschema = gql.Schema(query=Query)\nassert schema.execute('{currency1}').data['currency1'] == 'USD' # works\nassert schema.execute('{currency2}').data['currency2'] == 'USD' # fails, it's None\n```. @alexisrolland Your question is off-topic for this issue, but the list should be part of your schema. Depending on the client library you are using, you may already have a matching type definition already auto-generated for you. If you don't, then you could make a server request to the introspection schema in order to get the type definition.. ",
    "kenashcraft": "@lincolnq The workaround should be straightforward:\n```\nclass Query(gql.ObjectType):\n    currency2 = graphene.Field(Currency)  // NOTE: Previous code was just 'Currency()'\ndef resolve_currency2(self, info):\n    return Currency.USD.value // NOTE: Previous code was just 'Currency.USD'\n\n```. ",
    "ChristopherZhong": "I too have a similar problem. I posted a question to StackOverflow about this issue; here is a link to the question.\nSimilarly, I have a trivial example to highlight the issue here.. ",
    "ArnaudPel": "@lincolnq this issue is referenced in #139, which has been superseded by #140, which has eventually been merged. Can we transitively assume that this issue resolved then ? Thx. ",
    "Fercho191": "i solved this issue making a BaseParentNode (AbstractType) with childs common fields and create 'relay Nodes' inheriting from BaseParentNode\n. I just did something very similar, but with a list of global IDs\nIf you need make a filter with multiples choices, you can use GlobalIDMultipleChoiceFilter class..\nThis filter receive a list of GlobalIds\n. ",
    "SpaceK33z": "@dfee I was wondering if you ever got around to publishing your package?. ",
    "dani0805": "I am trying to find a workable solution to this and I am wandering off in this particular direction, basically trying to scan the model and autogenerate the schema on the fly:\n```\nregistry = {}\ndef register(target_class):\n    registry[target_class.name] = target_class\ndef c2u(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\nclass AutoSchemaMeta(type):\ndef __new__(meta, clsname, superclasses, attributedict):\n    new_class = type(clsname, superclasses, attributedict)\n    for app_name in new_class.app_models.split(\",\"):\n        app_models = apps.get_app_config(app_name.strip()).get_models()\n        for model in app_models:\n            model_name = model.__class__.__name__\n            _node_class = type(\"{}Node\".format(model_name),\n                (DjangoObjectType,),\n                {\"Meta\":{\"model\": model, \"interfaces\": (Node,), \"filter_fields\": []}})\n            register(_node_class)\n            setattr(new_class, \"all_{}s\".format(c2u(model_name)), DjangoFilterConnectionField(_node_class))\n            setattr(new_class, \"{}\".format(c2u(model_name)), Node.Field(_node_class))\n    return new_class\n\nclass Query(metaclass=AutoSchemaMeta):\napp_models = \"app1,app2\"\n\n```\nbut I am running in some kind of recursion... AssertionError: Found different types with the same name in the schema: ModelBaseNode, ModelBaseNode. Anyone cares to chip in?. I corrected my code and now I can automagically generate the schema from the model with 2 lines of configuration, namely which apps I want and which models I want.\n```\nregistry = {}\ndef register(target_class):\n    registry[target_class.name] = target_class\ndef c2u(name):\n    s1 = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s1).lower()\ndef s2p(name):\n    s1 = re.sub(\"y$\", \"ie\", name)\n    return \"{}s\".format(s1)\nclass AutoSchemaMeta(type):\ndef __new__(meta, clsname, superclasses, attributedict):\n    new_class = type(clsname, superclasses, attributedict)\n    include = new_class.include_models.split(\",\")\n    for app_name in new_class.app_models.split(\",\"):\n        app_models = apps.get_app_config(app_name.strip()).get_models()\n        for model in app_models:\n            model_name = model._meta.model_name\n            _model_name = c2u(model_name)\n            if hasattr(new_class,_model_name) or not model_name in include:\n                continue\n            class_name = \"{}Node\".format(model_name.title())\n            _node_class = type(class_name,\n                (DjangoObjectType,),\n                {\"Meta\":{\"model\": model, \"interfaces\": (Node,), \"filter_fields\": []}})\n            register(_node_class)\n            setattr(new_class, \"all_{}\".format(s2p(_model_name)), DjangoFilterConnectionField(_node_class))\n            setattr(new_class, _model_name, Node.Field(_node_class))\n    print(new_class.__dict__)\n    return new_class\n\nclass Query(metaclass=AutoSchemaMeta):\napp_models = \"app1,app2\"\ninclude_models =\"country,address,phone\"\n\n```\nIs this something that we could build upon to provide a default schema? I welcome any suggestion to improve on this.. Sorry I missed your message, its not a specific part of the code, at some point whenever I added a Node, any Node I got this error. Only way to remove it was to remove some Node, or increase the recursion limit. just made a PR for the middleware documentation covering its configuration in settings.py https://github.com/graphql-python/graphene/pull/820\nPlacing it here for lack of better ideas. In graphene-django this part of the documentation is completely missing. Someone could extrapolate by looking how the debug middleware is deployed and then see the base documentation for general guide about how to develop a new middleware. \nBut if you are not the one that installed graphene-django and you never saw it in settings, you might be trying to use the direct call example that is in the base documentation.\nWould it make sense to:\n\nrepeat the explanation in graphene-django including deployment or,\nreference the debug middleware django (and possibly flask if it even makes sense ) in the base documentation so that people using Django can find it easily\n\nLet me know what you think and I can adapt it.. best practices to avoid performance bottlenecks and n+1 problems . ",
    "techdragon": "@jkimbo I'm currently having this exact issue. The graphene/graphene-django documentation is not yet complete enough for me to see a way to solve this similar to the linked to method of combining managers by inheritance. \nDjango-CMS makes heavy use of django-parler so not having a simple solution/documentation to do this will prevent anyone who can't figure out how to extend graphene/graphene-django enough to support this sort of translated model inheritance, from being able to use it with Django-CMS based sites.. ",
    "hbutau": "@patrick91  the idea of a Django Polls Tutorial like tutorial is great. Just wanted to ask if you will be doing a django-graphql-apollo-ember one also?. ",
    "SAThomsen": "It would be awesome with proper coverage of mutations as well the current django-tutorial does not describe that :) \nhttp://docs.graphene-python.org/projects/django/en/latest/tutorial-plain/. ",
    "anudeepsamaiya": "@ALL can I pick this and continue from the point where @patrick91 left? I would appreciate any kind of inputs on how to structure the future content.. ",
    "pbaranay": "@stasm This is also being discussed in #538...looks like others have the same question!. ",
    "stasm": "No worries and congrats on the release! :). ",
    "dmr": "Congratulations on the new release!\nI have one question: Is there an documentation on the new subscriptions features?\nI did not find any in the documentation.\n. ",
    "warabak": "Should graphene release a 1.4.2 version with a gated version of graphql-core : \ngraphql-core>=1.1,<2.0 ?\nThis would allow a single version bump from 1.4.x instead of manually including graphene's transitive dependencies.. ",
    "ryanwilsonperkin": "Here's an example of an error:\npython\nGraphQLLocatedError: resolve() got an unexpected keyword argument 'id'\n  File \"graphql/execution/executors/utils.py\", line 6, in process\n    val = f(*args, **kwargs). Thanks Syrus, you're the best. Congrats on 2.0!\nOn Sat, Oct 28, 2017, 2:26 PM Syrus Akbary notifications@github.com wrote:\n\nClosed #580 https://github.com/graphql-python/graphene/issues/580.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/issues/580#event-1315266851,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AC3Wz5YvhXpJHUjCVJsTQDJ3YNVBFs89ks5sw3HggaJpZM4QH5m5\n.\n. \n",
    "HeyHugo": "Hi,\npersonally I don't see the big win in separating these things, when it comes to readability I'd almost argue the opposite is true. But anyway if you want to separate type declarations from resolve logic I guess you could do like this:\n```python\nclass UserResolver(object):\n    def resolve_full_name(self, info):\n        return 'John Doe'\nclass UserObject(UserResolver, ObjectType):\n    name = graphene.String()\n```\n(or the other way around: UserResolver is ObjectType and inherits from UserObject)\nA better way to decouple your data fetching logic I think would be to make separate functions that you use inside the resolvers. (See starwars example https://github.com/graphql-python/graphene/tree/master/examples/starwars). Ah, got this working now. I think it might have been something with the info argument (timestamp or similar?). I solved it by calling another function with only the graphql variable arguments from the resolve. . Hi,\nyou can do like this:\n```python\nclass JwtRefreshQuery(object):\n    token = graphene.String(graphene.String, token=graphene.String(required=True))\ndef resolve_token(self, info, token):\n    return refresh_token(token)\n\nclass Query(JwtRefreshQuery, SomeOtherQuery, graphene.ObjectType):\n    pass\n```\nI agree intuitively I think it would make more sense if the API for mutations and queries were more similar. In any case yes the docs/examles are a bit lacking in showing how you can do \"merge multiple query classes\" . nice @jkimbo I like it!. ",
    "jlward": "I found this as well. \nI was able to \"fix\" it by making my mutation explicitly set None for each field not being assigned. This fixed a possibly related bug where I was getting errors in the response for custom types and other scalars.\n```python\nimport graphene\nclass TestMutation(grapheneMutation):\n    test = graphene.Int()\n@classmethod\ndef mutate(cls, root, info, **kwargs):\n    return TestMutation()\n\n```\ngraphql\nmutation{\n    testMutation{\n         test\n    }\n}\n'errors': [{'message': \"int() argument must be a string or a number, not 'Int'\"}]\nFunny thing is the rest of the response had the correct data (in my case). I think graphene.String accidentally doesn't produce an error because you can call str() on almost anything without it causing an exception. \nHope this helps, and if you would rather I make an independent issue I'd be happy to. \nTLDR: Default values are no longer None. So explicitly pass along None for old behavior.. ```python\ndef test():\n    class CreateBlank(Mutation):\n    class Arguments:\n        name = String()\n\n    string = String()\n    integer = Int()\n\n    def mutate(self, info, **args):\n        return CreateBlank()\n\nclass Query(ObjectType):\n    a = String()\n\nclass MyMutation(ObjectType):\n    create_blank = CreateBlank.Field()\n\nschema = Schema(query=Query, mutation=MyMutation)\nresult = schema.execute(''' mutation mymutation {\n    createBlank(name:\"Peter\") {\n        string\n        integer\n    }\n}\n''')\nassert not result.errors\nassert result.data == {\n    'createUser': {\n        'string': None,\n        'integer': None,\n    }\n}\n\n```\nI had some trouble figuring out where the problem is happening at. But I was able to create a test that illustrates the issue here. It's not a PR, but since I haven't found where to actually fix it, I'd rather get the test out there. Hopefully it can help someone who actually knows what they are doing fix the problem.. ",
    "emilyzzz": "Ran into similar issue. Upgraded to 2.0 recently, using graphene with Django.\nMy mutate is defined as:\nclass Login(graphene.Mutation):\n    .....\n    def mutate(root, info, **args):\n        user = authenticate(\n            username=args.get('username'),\n            password=args.get('password'),\n        )\n        info.context.session['token'] = user.token    # 'info.context' is None only when running tests.\nTest is py.test style, looks like this:\nfrom graphene.test import Client\nclient = Client(schema)\nresult = client.execute(query)       # this will cause error, due to info.context is None.\n. ",
    "hheimbuerger": "@BossGrand That's a great explanation, thanks! I agree with @danpalmer that the Graphene documentation is missing all of this detail.\nThat said, could you comment some more on what the cursors actually are when working with Graphene? How are you handling them? Are they actually database cursors? If so, where do you store them and when do you release them?. ",
    "keyeMyria": "@BossGrand How to calculate pageInfo in resolver method as you mentioned above, such is:\n```\nclass Query(graphene.ObjectType):\n     ships = relay.ConnectionField(ShipConnection)\ndef resolve_ships(self, info):\n     return get_ships_from_database_or_something_idk_its_your_implmentation()\n\nschema = graphene.Schema(query=Query)\n```\nIs there any method for calculate pageInfo in  \"graphene.Connection\" ? I'm using \ngraphene-sqlalchemy.\n@syrusakbary @adamcharnock \n. Just like WTForm's validation.. I figure out the problem. \n```\nPageArguments = dict({ \"first\": graphene.Int(), \"last\": graphene.Int(), \"before\": graphene.UUID(), \"after\": graphene.UUID() })\ndef search_organizations(cls, info, **kwargs):\nfirst = kwargs.get('first')\nlast = kwargs.get('last')\n\nafter = kwargs.get('after')\nbefore = kwargs.get('before')\n\n #do something search\n\norga_query = Organization.get_query(info)\n\nreturn orga_query.all()\n\nclass OrganizationFullConnection(graphene.Connection):\nclass Meta:\n    node = OrganizationQLSchema\n\nclass RootQuery(graphene.ObjectType):\n    find_organization  = graphene.relay.ConnectionField(OrganizationFullConnection, target=graphene.String(), resolver=search_organizations)\n```\nWhile, another question raised.  Each network request find_organization lead to twice query database .\n. ",
    "fanadol": "Hi @BossGrand awesome example there. But i want to ask something, lets say i have this field in Query schema\nship = ConnectionField(ShipConnection)\nso i need to resolve this by using resolve_ship(self, info): return get_all_ships()\nBut in the query schema i only want to query count. By doing this approach isn't that we waste the get_all_ships function? Can you give me better approach to this problem, to only get specific count without querying all the ships?\nThank you. Thank you for your answer @BossGrand , but i still cannot figure out what is self.length here. How do i get the list of get_all_ships inside connection class ? iam using native graphene for this. nvm, i got it by doing len(self.edges) in resolve_count.\nThank you very much for the help!. ",
    "sboisson": "Quick fix in #594 . ",
    "MrEbbinghaus": "Appeared in https://github.com/graphql-python/graphene-django/issues/282#issuecomment-340839101. @syrusakbary Is it solved?. ",
    "nparrish": "@syrusakbary: any objections to this?. @syrusakbary This became a little more complicated than I initially thought.  Handling complex inputs (like lists of non-null objects, for example) required a bit more work.  I think I'm now handling all the possible cases, but it's possible I missed something.. Wouldn't it make more sense to invoke the base class constructor before performing any derived-class initialization?. Right...and returning a combination of fields and values is a bit confusing.. ",
    "gonardfreeman": "Guys, I'm almost solve it myself, so I'm think I show you results in few hours! It'll be more like django-filter, but not so \"pretty\"!). So here it is!\npython\n    @classmethod\n    def get_query(cls, model, info, **args):\n        query = super(CustomConnectionField, cls).get_query(model, info, **args)\n        for field, value in args.items():\n            if field not in cls.RELAY_ARGS:\n                for arg in cls.CUSTOM_ARGS:\n                    if arg in field:\n                        query = query.filter(\n                            getattr(model, field.replace('_' + arg, '')).like('%{}%'.format(value))\n                        )\n                        return query\n                    if isinstance(value, InputObjectType):\n                        values = list(value.values())\n                        keys = list(value.keys())\n                        rel = inspect(model).relationships[field]\n                        if len(values) > 1 or len(keys) > 1:\n                            for key, val in value.items():\n                                query = query.join(rel.mapper.class_).filter(\n                                    getattr(rel.mapper.class_, key) == val\n                                )\n                        else:\n                            query = query.join(rel.mapper.class_).filter(\n                                getattr(rel.mapper.class_, keys[0]) == values[0]\n                            )\n                        # return query\n                    else:\n                        query = query.filter(\n                            getattr(model, field) == value\n                        )\n        return query\nI'm want to test it with many input fields, but it seems to be legit;). Okey, its alive! There is only thing it still cant do, to make more complex joins, like this Table1->Table2->Table3. But joins like Table1->Table2 its easy and in any count! \nSQL\nJOIN TABLE2\n  ON TABLE2.ID = TABLE1.field\nJOIN TABLE3\n  ON TABLE3.ID = TABLE1.field\nAnd the most beautiful part of it, it only depends on your model and schema, you only \"hardcode\" names of fields.\nExample how it works\n```python\nclass EmployesModel(Base):\n  ID = Column(Integer, primary_key=True)\n  name = Column(String)\nclass MyModel(Base):\n  ID = Column(Integer, primary_key=True)\n  test = Column(String)\n  employee_id = Column(Integer, ForeignKey('EmployesModel.ID')\n  employee_id_connection = relationship(EmployesModel)\nclass MyModel(SQLAlchemyObjectType):\n    class Meta:\n        model = MyModel\n        interfaces = (relay.Node,)\nclass MyModelInputSchema(InputObjectType):\n    name = String()\nclass MyModelQuery(ObjectType):\n    test = relay.Node.Field(MyModel)\n    all_tests = CustomConnectionField(MyModel, employee_id_connection=MyModelInputSchema())\nand query:graphql\nquery {\n  allTests(employeeIdConnection:{name:\"test\"}){\n     test\n     employeeIdConnection{\n        name\n     }\n  }\n}\nhere code of CustomConnectionpython\n@classmethod\n    def get_query(cls, model, info, args):\n        query = super(CustomConnectionField, cls).get_query(model, info, args)\n        for field, value in args.items():\n            if field not in cls.RELAY_ARGS:\n                for arg in cls.CUSTOM_ARGS:\n                    if arg in field:\n                        query = query.filter(\n                            getattr(model, field.replace('' + arg, '')).like('%{}%'.format(value))\n                        )\n                        return query\n                    if isinstance(value, InputObjectType):\n                        values = list(value.values())\n                        keys = list(value.keys())\n                        rel = inspect(model).relationships[field]\n                        if len(values) > 1 or len(keys) > 1:\n                            for key, val in value.items():\n                                query = query.join(\n                                    rel.mapper.class,\n                                    getattr(model, field.replace('' + arg, ''))\n                                ).filter(\n                                    getattr(rel.mapper.class, key) == val\n                                )\n                        else:\n                            query = query.join(\n                                rel.mapper.class_,\n                                getattr(model, field.replace('' + arg, ''))\n                            ).filter(\n                                getattr(rel.mapper.class, keys[0]) == values[0]\n                            )\n                    else:\n                        query = query.filter(\n                            getattr(model, field) == value\n                        )\n        return query\n```. ",
    "sf-sagarj": "yes it is possible. You will need to force the graphql-core version as well. We use following:\ngraphene == 1.4\ngraphql-core == 1.1. You should  use json.dumps() on result.data instead of result object. \nYou can check for result.errors before json.dumps() on result.data . ",
    "Morreski": "I enforced the graphql-core version as you proposed and it works like a charm.\nThanks !. ",
    "Cito": "Thank you @jkimbo.. @jkimbo I'm also using type_ instead of type in graphql-core-next, so this would be consistent.. I guess the README.rst was for PyPI and the README.md for GitHub.\nAs far as I know GitHub now understands README.rst as well, and on the other hand PyPI now also understands README.md when you set long_description_content_type=\"text/markdown\" in setup.py. So in fact one of them should be removed, but make sure everything still looks nice in both GitHub and PyPI.. ",
    "mandx": "\nis it expected in this code not to receive the error list?\n\nThe query is not asking for the errors, so I guess that's why they are not in the response...\npython\n    result = client.execute('''\n        mutation CreatePerson($input: CreatePersonInput!) {\n            createPerson(input: $input) {\n                ok\n                errors  # Ask for the errors too\n            }\n        }\n    ''', variable_values=variables)\nCan you try adding errors to the query and see if they appear in result?. This is more or less the web server setup code I'm using:\n```python\nfrom aiohttp import web\nfrom aiohttp_graphql import GraphQLView\nfrom graphql.execution.executors.asyncio import AsyncioExecutor\n...\napp = web.Application(loop=loop)\n...\ngraphql_view = GraphQLView(\n    schema=Schema,\n    graphiql=True,\n    middleware=(\n        # ...\n    ),\n    context={\n        # ...\n    },\n    enable_async=True,\n    executor=AsyncioExecutor(),\n)\n...\napp.router.add_get('/graphql', graphql_view)\nPackage versions:\naiohttp==2.3.3\naiohttp-graphql==1.0.0\ngraphene==2.0.1\ngraphql-core==2.0\ngraphql-relay==0.4.5\ngraphql-server-core==1.0.dev20170322001\nfuture==0.16.0\npromise==2.1\n```\nBTW, I'm using some custom middleware classes, and none of them uses coroutines or promises.. I'm closing this because I haven't been able to reproduce this with a test repo. I might need to investigate further in my code, which incidentally has a lot of (asynchronous) moving parts. I might reopen it if I found a real bug/problem to report.\nThanks!. Are you able to debug any Python code at all? If instead of breakpoints, you add print() statements do they show up in your terminal?\nPersonally, I don't use my editor to debug any Python code, what I do is install IPython and PuDB (inside the virtualenv, if any) and simply add this line import pudb; pudb.set_trace() to make PuDB pop up at that line.\nAt the very least, print() statements should appear in your terminal. If they do, then the problem might be your VSCode setup. First try debug with VSCode a simple hello world Python program, then try with your Flask/Graphene app.. Try this then: Add print statements inside code blocks that you know it is executed. If those print statements show up, then place breakpoints at those print statements, then try again.. This is real-world example of how to use lists/arrays as input values: Basically the same behavior of the node field, but get a list of Relay nodes for a list of Relay IDs:\n```python\nimport graphene\nfrom graphene import relay\nclass Query(graphene.ObjectType):\n    node = relay.Node.Field(required=True)\n    nodes = graphene.List(relay.Node, required=True, ids=graphene.List(graphene.ID))\ndef resolve_nodes(self, info, ids=None):\n    if ids:\n        return [\n            relay.Node.get_node_from_global_id(info, node_id)\n            for node_id in ids\n        ]\n    return []\n\n```. ",
    "yamila-moreno": "Holy cow! That was the problem!! I was just not seeing this.\nThank you for your help!!!. @jkimbo Thank you, that makes totally sense!!! We'll update our code to send a Date instead of a DateTime.. ",
    "KaySackey": "I'd say this was extremely helpful, and ought to be placed in an FAQ somewhere.. One suggestion I'd make is... at least in development mode for graphene-django, when there's an exception, rather than catching it within the promise executer, and handling it... instead simply throw an exception. \nAs it is right now, I have to manually set a debugger point within Graphene to catch exceptions before they're handled by the framework. . i'd be interested in joining kay@9cloud.us. ",
    "nealmcb": "Thank you both!\nAny updates on these issues a year later? Has this been incorporated into FAQs or documentation? Have the answers changed at all?. ",
    "tomanizer": "I think that's right.\nGraphene 2.01 currently errors with\nAttributeError: module 'graphene.types' has no attribute 'datetime'\nwhen declaring a class with:\nclass Observation(graphene.ObjectType):\n    id = graphene.ID()\n    date = graphene.types.datetime.Date(). ",
    "ramarivera": "No, print statements do not show.\nYes, I can and have debugged other Python code using vscode.\nThanks. Hello @jkimbo . No problem, Unfortunately i haven't worked with graphene for a long time due tu school and work stuff, so I cant remember if i ever solved it. Close away, . ",
    "uhho": "Related to: https://github.com/graphql-python/graphene/pull/594. ",
    "tomas-sk": "Prior to version v2.0.1, it was possible to set attributes before invoking the base class init. So it is sort of a \"breaking change\" for people who assumed it is a \"feature\" and used it in existing code bases. It luckily was discovered as a failing test.\nI think it would be better to keep previous behavior or produce some warning on misuse or at least put it in upgrade notices/docs.\nThe cause is the added default argument to pop call in objecttype.py:84. As it is now, the surrounding try block looks unnecessary to me. That makes me think this code will benefit from another review.. ",
    "sheldonrong": "Just being drunk, figured out myself. Just return instance of the class\ndef resolve_car(self, info, **kwargs):\n          return CarData(). ",
    "heynemann": "Any news on this? I'm having the same issue.. ",
    "Fedalto": "I think this is the logging you're after:\nhttps://github.com/graphql-python/graphql-core/blob/6df8a6312b579a6a1454bcf29a566ce5d0fa9849/graphql/execution/executor.py#L313-L315\nThis is the only logging in this module, so you can disabled it.. ",
    "charettes": "See https://github.com/graphql-python/graphql-core/issues/142 and https://github.com/graphql-python/graphql-core/pull/154.. ",
    "frsv": "You have to register a success callback for your promise which will return a data. So your return should be like\nreturn context['data_loaders'].point_of_consuming_product_loader.load(self.id).then(lambda response: response). ",
    "weiztech": "@jkimbo , got error\nTypeError: __init__() got an unexpected keyword argument 'min_length'\nso i actually want to make a custom scalar that can add min_length as the arguments. but get error like above.  is there any way to do something that ?\n. @jkimbo , im using graphene2.0 \nis it possible to add extra arguments on the custom scalar \nclass CustomString(Scalar):\n\n   def __init__(self, *args, **kwargs):\n    super(CustomString, self).__init__(*args, **kwargs)\n\n  @staticmethod\n  def serialize(dt):\n      return dt\n\n  @classmethod\n  def parse_literal(self, node):\n      if isinstance(node, ast.StringValue):\n          return node.value\n\n  @classmethod\n  def parse_value(self, value):\n      return value\n\n\nclass testMutate(graphene.Mutation):\n    class Arguments:\n        str = CustomString(max_length=10, min_length=5)\n\n    string = graphene.String()\n\ncould you let me know how to access attr max_length and min_length inside the CustomString class. ?\ncurrently its show error TypeError: __init__() got an unexpected keyword argument 'max_length'. @jkimbo , i actually dont want validate inside the mutation class  because i'm afraid  need to repeat the validation code for other mutation class.\ni think its better if i can catch/validate it inside the CustomString/CustomScalar class if this case is possible.. Thanks @jkimbo , yes i agree\ni also found some good example at issue 456. ",
    "samkit-jain": "Opening the issue where it belongs in graphene-django https://github.com/graphql-python/graphene-django/issues/349. ",
    "wesdyoung": "graphene.types.mutations.Mutation.Field doesn't pass on it's *args or **kwargs to the  graphene.types.fields.Field constructor.  Is this by design or a bug?  If by design I feel this should be changed to at least allow the description argument to be passed to the graphene.types.fields.Field constructor.\nMy current work around is to set the description attribute on the mutation field after an instance has been created.. ",
    "dbrrt": "@jkimbo Yes, I temporarily switched to a nodejs back-end. https://github.com/dbrrt/apollo-aiohttp-graphene\nYou can start client using yarn and yarn start\nand server with make\nI'm calling mutation with Apollo in : https://github.com/dbrrt/apollo-aiohttp-graphene/blob/master/client/components/views/Home/mut.js\nIt works using GraphiQL, so the problem might be related to Apollo client directly.. ",
    "styk-tv": "@jkimbo @abawchen @akshaybabloo : fair, but in case of server that HAS to implement its own method/query level authentication (or populate query variables based on token details) AND let's say neo4j/graphql endpoint all and ready what will most likely have to happen is that new auth api will have both server (relay-compliant) as well as direct client access to already implemented graphql. yes? would you then recommend using graphene or move directly into something like graphql-relay-py+gql? OR would you recommend completely by-pass of graphql plugin for neo4j in that case (loosing idl endpoint for example) and start implementing relay server from zero?. ",
    "fishy": "Actually never mind. We figured out a way to go Route 1 without modifying graphene code (and Route 2 will change a lot of APIs, which will be very risky).\nThe basic idea is, you can use a private field in the type (we use _complexity), something like:\n```python\nclass MyType(graphene.ObjectType):\n    field1 = ...\n    field2 = ...\n    ...\n_complexity = {\n    'field1': 2,\n}\n\n```\nThen, in the complexity analysis code, you can get that map back from the schema by something like schema.get_query_type().fields['fieldName'].graphene_type._complexity.. ",
    "zanchi": "I came across the same thing, it looks like deprecated fields are not included by default but can be included with an includeDeprecated arg\ngraphql\n{\n  __type(name: \"YourType\") {\n    fields(includeDeprecated: true) {\n      isDeprecated\n      name\n    }\n  }\n}. I have no idea, I don't actually use graphene, I just found this when I was having the same issue and thought that might be useful!. ",
    "lucas-bremond": "Did you find an answer to that question?. That's what I guessed... Thanks for your answer!. ",
    "valentinradu": "Nobody answered for a long time so I assumed: no. End up using an Apollo JS gateway able to stitch multiple Graphene powered microservices.. ",
    "kigen": "@valentinradu  Were you able to get Apollo JS gateway to load your graphene-based schema implementations?  . ",
    "jkida": "Still very new to graphql/graphene but i found this works.\n```\nuser_input = {\n    'name': graphene.String(required=True, description=\"Full Name\"),\n    'email': graphene.String(description=\"Email\"),\n    'username': graphene.String(required=True, description=\"Username\")\n}\nclass AddUser(graphene.Mutation):\n    class Meta:\n        arguments = user_input\nuser = graphene.Field(User)\n\ndef mutate(self, info, **user):\n    user = UserModel(**user)\n    session.add(user)\n\n    return AddUser(user=user)\n\n```. ",
    "dkleissa": "I determined the issued was with a development middleware we implemented that used some code based off of the functional middleware example in the docs. Schema object does not have the _meta attribute, so you cannot get the parent name. Will PR a docs tweak so others avoid this in the future.. ",
    "altaurog": "This doesn\u2019t seem to be supported with use of schema interfaces.  There may be a way to do it, but a direct adaptation of the above doesn\u2019t work (note that test = Test() is incorrect).\nTake the following schema:\n```python\nimport graphene\ndef resolve_test(*_):\n    return TestInstance()\nclass TestInstance:\n    id = 1\n    x = 1\n    y = 2\nclass Test(graphene.ObjectType):\n    x = graphene.Int()\n    y = graphene.Int()\nclass Meta:\n    interfaces = (graphene.relay.Node,)\n\n@classmethod\ndef get_node(*_, **__):\n    return resolve_test()\n\nclass Query(graphene.ObjectType):\n    node = graphene.relay.Node.Field()\n    test = graphene.Field(Test, resolver=resolve_test)\nschema = graphene.Schema(query=Query)\n```\nNow we can execute the following query:\ngraphql\n{ test { id x y } }\nAnd get this result:\njson\n{\n   \"data\": {\n      \"test\": {\n         \"id\": \"VGVzdDox\",\n         \"x\": 1,\n         \"y\": 2\n      }\n   }\n}\nBut if you try:\ngraphql\n{ node(id: \"VGVzdDox\") { ... on Test { id x y } } }\nYou will get the following error:\ngraphql.error.base.GraphQLError: Abstract type Node must resolve to an Object type at runtime for field Query.node with value \"<test.graphql.testschema.TestInstance object at 0x7fa84c5b05c0>\", received \"None\".\nPresumably the limitations placed on the resolved object are to ensure that the executor can determine its type, since it does not know the type a priori in this case.. > one of the most critically useful features of Graphene\nIn any event, I am curious what you are doing that makes this so useful.. @jkimbo thanks.  The value I see in this is it helps break the dependency between the schema types and the resolvers and thereby allows more flexibility in the organization of the code.  It also allows me to cache additional data on the objects without having to play tricks to allow that.  I am adapting your code as below.  Also I figured out how to make a ConnectionField such that the resolver does not need the connection type:\n```python\nfrom graphene import relay\nclass Node(relay.Node):\n    \"\"\"\n    Custom Node interface type\n    The purpose of this type is to allow resolvers to return objects\n    which are not instances of graphene.ObjectType, but which has the\n    same name as a graphene type in the schema.  The graphene type will\n    be inferred from the class name.\n    \"\"\"\n    class Meta:\n        \"\"\"meta class\"\"\"\n        name = 'Node'\n        description = 'An object with an ID'\n@classmethod\ndef resolve_type(cls, instance, info):\n    \"\"\"Assume the class name is the same\"\"\"\n    return type(instance).__name__\n\nclass ConnectionField(relay.ConnectionField):\n    \"\"\"\n    Custom connection field interface type\n    The purpose of this type is to allow relay connection resolvers to return a dict\n    which can be used to instantiate the connection object.\n    \"\"\"\n    @classmethod\n    def resolve_connection(cls, connection_type, args, resolved):\n        if isinstance(resolved, dict):\n            return connection_type(**resolved)\n        return super().resolve_connection(connection_type, args, resolved)\n. Let\u2019s say I have the following in my schema:python\nclass BlogEntry(graphene.ObjectType):\n    datePublished = graphene.String()\n    title = graphene.String()\n    author = graphene.Field(lambda: Author, resolver=resolve_blog_author)\n    content = graphene.String()\nclass Meta:\n    interfaces = (relay.Node,)\n\nclass BlogEntryConnection(graphene.Connection):\n    class Meta:\n        node = BlogEntry\nclass Author(graphene.ObjectType):\n    name = graphene.String()\n    blogEntries = relay.ConnectionField(\n        BlogEntryConnection,\n        resolver=resolve_author_blog_entries\n    )\n``\nUnfortunately, there\u2019s a bit of a circular reference betweenBlogEntryandAuthor`, which we were able to set up using a lambda in the former.  IMO it would be much nicer to specify just class name and resolve the type lazily, but that does not seem to be supported directly.  So although I might ideally want to split my schema types up and define them in several different modules, I think it would be a bit awkward to do that.  Is there a way?\nBut this conversation is about resolvers.  Now if the resolvers had to return the actual schema types, we\u2019d have more interdependencies.  The schema classes depend on the resolvers and the resolvers depend on other classes in the schema.  Which again, it seems to me, makes it difficult to organize my resolvers in their own modules.  So everything goes in one big module with all these circular references.\nBut since the resolver can return any kind of object, it does not have to depend on the schema and I can move it elsewhere.\nRegarding your second point, that the schema is likely to diverge from the underlying data structure, I agree with you 100%, which is why I would never return an ORM object or queryset from a reducer.  I created a separate set of intermediate plain-old-data classes which I instantiate in my resolver with the data it loads.  Those classes serve no purpose other than to hold the data and specify the type, or in other words to look like the schema types without actually being the schema types, so there is no risk in relying on the name.\n(It seems to me that there are plenty of devs who are willing to couple their schema quite tightly to the underlying data structure, though.  Isn\u2019t that what graphene-django does?). Ah, never mind.  I just realized I could return the graphene type without referencing it directly using info.return_type.graphene_type. . Another thing I want to do with the return type is cache additional information on it.  For example, with the query:\n{ blogEntries(first: 2) { edges { node { title author { name } } } } }\nIf the underlying data source were an RDBMS I would probably do a join like this:\nSELECT blog_entry.blog_entry_id, blog_entry.title, author.author_id, author.name\nFROM blog_entry JOIN author USING (author_id)\nORDER BY blog_entry.blog_entry_id\nLIMIT 2\nThen I could instantiate an Author object and attach it to each BlogEntry object in resolve_blog_entries.  Then I can check info.root in resolve_blog_author to see if it already has the Author instance available and if so, return it.  Now there\u2019s no reason why I couldn\u2019t do this with the graphene type, so:\nauthor = Author(**author_data)\nblog_entry = BlogEntry(**blog_entry_data)\nblog_entry.author = author\nBut it would be a tad nicer IMO to be able to do the following, which isn\u2019t allowed with the graphene types:\nauthor = Author(**author_data)\nblog_entry = BlogEntry(author=author, **blog_entry_data). @ProjectCheshire thanks, that is useful.  I wrote the following wrapper to allow relative imports when called as lazy_import('.site.Site', __name__):\npython\ndef lazy_import(path, relative_to_path=''):\n  if path.startswith('.'):\n    return graphene.lazy_import(relative_to_path.rsplit('.', 1)[0] + path)\n  return graphene.lazy_import(path). In this case I could just use a string with comma-separated values:\nrange | query\n----- | -----\namps < 3 | components (amps: \",3\")\n1 < amps < 3 | components (amps: \"1,3\")\n1 < amps | components (amps: \"1,\")\nBut I would lose some type safety that way.  It seems to me that null would be useful as a legal value in any case.. @jkimbo thanks!  I\u2019ll have a look there.. ",
    "DrPyser": "That's weird behavior. Generator shouldn't be assumed to be coroutines. From what I understand, generator-based coroutines should be explicitly annotated with @asyncio.coroutine, and can then be unambiguously distinguished from normal generator functions using asyncio.iscoroutinefunction.. @avivey Yeah, those are also my concerns. Using python annotations to define the schema is cute, but will conflict with the intended usage for static type checking. Using typing types to define graphql fields means usurping that API for something it's not intended for. That API might evolve in a direction that is not compatible with GraphQL usage. \nThat being said, I think a middle ground would be to require explicit flagging of resolvers, and still rely on annotations as much as they remain valid type hints:\n@ObjectType\nclass Collection:\n    @Field.from_resolver\n    def items(self, min: int = 0, max: int = 10) -> List[Item]:\n        \"\"\"\"Some description\"\"\"\n        return get_items(....)\nWe still need to have a separate way to define any extra information for arguments, fields, types, etc.\n\nThe Field.from_resolver decorator could extract a description from the resolver docstring. We could expect the docstring to include argument descriptions using a well-defined format.\nAdditional field metadata, like deprecated, could either be specified through decorator arguments(e.g. @Field.from_resolver(deprecated=True)), or through separate decorators, i.e. \n@Field.deprecate\n    @Field.from_resolver\n    def items(self, min: int = 0, max: int = 10) -> List[Item]: ... \n  Same for arguments, e.g. @Field.deprecate_args(\"name\").\n  This might become verbose though if many options are specified that way.. I think I now understand that fragments are defined client-side. Closing.. Yup, it does. Is it possible to explain why? I feel the default value should be of the same type as the field.. Also, I feel this should raise a more user friendly exception, like a type error.. I think this is an issue with all libraries using the same to define \"schema\"-like entities, e.g.\nsqlalchemy\nmarshmallow\ndjango (orm)\n\nSince this pattern(of using class-level attributes for one purpose, and instance attributes of the same name for another) is used so often, I think there should actually be support for it in type checkers(and the typing module). Some thing like that:\n```\nfrom typing import Hybrid\nclass Example:\n  a: Hybrid[String, str] = String()\n  b: Hybrid[Integer, int] = Integer()\nx: Example = ... \nprint(x.a.encode(\"utf-8\")) # typechecks\nprint(x.b + 2) # typechecks\nprint(Example.a.required) # typechecks, assuming String objects have 'required' attribute\nprint(Example.b.required) # typechecks, assuming Integer objects have 'required' attribute\n```\n@avivey Until that happens, I guess your first suggestion is the way to go. \nI also prefer having a separate namespace in the class for field definitions, just like there's a separate Meta namespace for other configuration options. This leaves the rest of the class namespace as free real estate for custom class attributes and methods.\nAnd actually, I just thought of a good way to define resolvers in any namespace without relying on the method name:\n```\nclass MySecondAttempt(ObjectType):\n    class __SCHEMA:\n        name = String()\n        age = Int(required=True)\n    @name.resolver\n    def resolve_name(self, ...): ...\n\n    @age.resolver\n    def resolve_age(self, ...): ...\n\nage: int\n\n```\nThe resolvers could have any arbitrary name, and could also be defined before or after the class definition. Explicit is better than implicit. Resolvers could still be search from method names by default if the explicit decorator isn't used. Guess I could create a separate issue for that.. ",
    "eclar": "Isn't it similar to the connection in graphene relay ? http://docs.graphene-python.org/en/latest/relay/. ",
    "art1415926535": "Hi, @jloveric. I do it this way:\npython\nclass Query(ObjectType):\n    some_func = Field(SomeObjectType, args={'value': graphene.List(graphene.String)}). ",
    "luvwinnie": "sorry for late reply, my input is a speech recognition result of Japanese like below.\n{\n    \"recognition_result\": {\n      \"tri4\": [\n        {\n          \"utterance_id\": \"new_processing_0000158_0000381\",\n          \"result\": \"\u6b4c\u8a5e+\u540d\u8a5e \u524d\u9762+\u540d\u8a5e \u306b+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u3044+\u611f\u52d5\u8a5e \u7a81\u3063\u5f35\u308a+\u52d5\u8a5e/\u30e9\u884c\u4e94\u6bb5/\u9023\u7528\u5f62 \u611f+\u540d\u8a5e \u304c+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u3042\u308b+\u52d5\u8a5e/\u30e9\u884c\u4e94\u6bb5/\u9023\u4f53\u5f62 \u305d\u3046+\u540d\u8a5e \u3067\u3059+\u52a9\u52d5\u8a5e/\u7d42\u6b62\u5f62\",\n          \"start_time\": 1.58,\n          \"end_time\": 3.81\n        },\n        {\n          \"utterance_id\": \"new_processing_0000426_0000688\",\n          \"result\": \"<sp> \u4eca\u56de+\u540d\u8a5e \u6b69\u884c+\u540d\u8a5e \u8a13\u7df4+\u540d\u8a5e \u3092+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u5b9f\u65bd+\u540d\u8a5e \u3057+\u52d5\u8a5e/\u30b5\u884c\u5909\u683c/\u9023\u7528\u5f62 \u307e\u3057+\u52a9\u52d5\u8a5e/\u9023\u7528\u5f62 \u305f+\u52a9\u52d5\u8a5e/\u7d42\u6b62\u5f62\",\n          \"start_time\": 4.26,\n          \"end_time\": 6.88\n        }\n      ],\n      \"dnn\": [\n        {\n          \"utterance_id\": \"new_processing_0000158_0000381\",\n          \"result\": \"\u304b+\u52a9\u8a5e/\u7d42\u52a9\u8a5e \u81ea\u7136+\u5f62\u72b6\u8a5e \u9762+\u540d\u8a5e \u306b+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u7a81\u3063\u5f35\u308a+\u52d5\u8a5e/\u30e9\u884c\u4e94\u6bb5/\u9023\u7528\u5f62 \u611f+\u540d\u8a5e \u304c+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u3042\u308b+\u52d5\u8a5e/\u30e9\u884c\u4e94\u6bb5/\u9023\u4f53\u5f62 \u305d\u3046+\u540d\u8a5e \u3067\u3059+\u52a9\u52d5\u8a5e/\u7d42\u6b62\u5f62\",\n          \"start_time\": 1.58,\n          \"end_time\": 3.81\n        },\n        {\n          \"utterance_id\": \"new_processing_0000426_0000688\",\n          \"result\": \"\u56de+\u540d\u8a5e \u6b69\u884c+\u540d\u8a5e \u8a13\u7df4+\u540d\u8a5e \u3092+\u52a9\u8a5e/\u683c\u52a9\u8a5e \u5b9f\u65bd+\u540d\u8a5e \u3057+\u52d5\u8a5e/\u30b5\u884c\u5909\u683c/\u9023\u7528\u5f62 \u307e\u3057+\u52a9\u52d5\u8a5e/\u9023\u7528\u5f62 \u305f+\u52a9\u52d5\u8a5e/\u7d42\u6b62\u5f62\",\n          \"start_time\": 4.26,\n          \"end_time\": 6.88\n        }\n      ]\n    }\n  }\nand this data is use to save to my database. And I Wish to get the result like below query.\nquery{\n          data{\n                   recognition_result\n           }\n}\nHowever when I can get the output result. My Japanese character are all encoded in Unicode.\nwhen I use the normal String data type it will decode the Japanese Character but the JSONField not.\nFor my solution now, I have to escape all the Japanese character in my client side. Is there anyway to solve this problem?\nI'm not in the control of my server, I would send my query result later on.\nBut the result is just simple Unicoded Japanese character.Example like \n\\u56DE+\\u540D\\u8A5E \\u6B69\\u884C+\\u540D\\u8A5E \\\nThx!. ",
    "djm": "Agreed, this should have proper documentation. I just spent a small amount of time working this out so I'll leave this here for anyone landing here from Google! \ud83d\ude03 \nmutate_and_get_payload is only available to override if you are subclassing relay.ClientIDMutation and you should only be doing this if you're working with Relay on the frontend.\nRelay requires a specific payload syntax for queries and mutations and thus subclassing relay.ClientIDMutation rather than the standard graphene.Mutation allows graphene to abstract away a lot of the extra work otherwise required.\nThe method has a different name seemingly due to graphene design decisions, if you take a look at the code you can see that the normal mutate has a bunch of wrapping logic and calls mutate_and_get_payload within that flow. If you overrode mutate here, you would lose all that wrapping logic without special care and attention.\n. ",
    "maarcingebala": "What are the plans for releasing a new version? I'd love to have this feature.. I'd be happy to share my thoughts and experiences after using graphene/graphene-django in Saleor. Email: maarcin.gebala@gmail.com.. Shouldn't it check for decimal.DecimalException here, as for example Django does? I've copied your changes to my repo (as it hasn't been released yet) and I'm trying to use it in my mutations, but when providing invalid values like an empty string I'm getting:\n{\n  \"errors\": [\n    {\n      \"message\": \"[<class 'decimal.ConversionSyntax'>]\"\n    }\n  ]\n} . ",
    "genomics-geek": "I see this behavior as well - but I think it has to do with changing the schema while the django server (manage.py runserver) is running.  When it occurs, I just kill the django server and refresh the page and it works just fine.  \nI only see this during development and not in our production environments - so I am assuming it has to do with the updates while running the django server - but not 100% sure - I could not trace it down.  Seems to happen randomly as well.. ",
    "morinx": "We ran into this issue as well as our schema got bigger. For now the only solution for us is to change recursion limit. \nThis issue is difficult to reproduce consistently in a basic graphene setup. But one way of reproducing it is to lower the recursion limit to something around 300 or 500 for one of your fairly large schemas:\npy\n   sys.setrecursionlimit(300)\n. ",
    "nyejon": "Opened issue in the graphen-django repo: https://github.com/graphql-python/graphene-django/issues/402. ",
    "gmetzker": "@sf-sagarj My result.data serializes fine.  But I was asking, more specifically, about how to do the serialization when I do have results.errors present and I want to communicate those in the GraphQL response.  GraphQLLocatedError doesn't seem to serialize, and I can't find any documentation on what the format for .errors should be.. ",
    "anuragensemble": "2.0\nroot@event-stream-ui:/home/ubuntu/graphene_graphql_server# pip freeze\nDjango==1.11.10\ngraphene==2.0\ngraphql-core==2.0\ngraphql-relay==0.4.5\niso8601==0.1.12\npromise==2.1\npsycopg2==2.7.3.2\npymongo==3.6.0\npytz==2018.3\nRx==1.6.0\nsingledispatch==3.4.0.3\nsix==1.11.0\ntyping==3.6.4\nvirtualenv==15.1.0. Oops, Thanks !. ",
    "bwanglzu": "Thanks! @jkimbo , it works for me now!\nThe way I do it is to use two queries, not very elegant, but still works...\n```graphql\nbackend\nthings = ConnectionField(ThingConnection, type=graphene.String())\nGraphiql front-end\nquery{\n  things(type: \"a\"){\n    edges{\n      node{\n        field_a\n        field_b\n      }\n    }\n  }\n}\n```\nAnd to query (filter) with a list of types:\n```graphql\ngraphene backend\nthings_by_type = ConnectionField(ThingConnection, type=graphene.List(graphene.String))\nGraphiql Front-end\nquery{\n  thingsByType(type: [\"type_a\", \"type_b\"]){\n    edges{\n      node{\n        field_a\n        field_b\n      }\n    }\n  }\n}\n```\nAnd also, it also supports for arguments:\ngraphql\nquery($type:[String]){\n  thingsByType(type:$type){\n    edges{\n      node{\n        field_a\n        field_b\n      }\n    }\n  }\n}\nneed a parameter in Query Variables field:\ngraphql\n{\n  \"type\": [\"type_a\", \"type_b\"]\n}\n. In case you're usingSQLAlchemy, please take a look at the latest comment here. My fault.. . ",
    "Wesitos": "You can only reference Scalars, InputObjectTypes and Lists of InputObjectTypes inside an InputObjectType\n```python\nclass TestSub():\n    test = graphene.String()\nInputs\nclass TestSubInput(TestSub, graphene.InputObjectType):\n    pass\nclass TestInput(graphene.InputObjectType):\n    test_list = graphene.List(TestSubInput)\nObjects\nclass TestSubType(TestSub, graphene.ObjectType):\n    pass\nclass TestType(graphene.ObjectType):\n    test_list = graphene.List(TestSubType)\n```. ",
    "yywing": "If i have a dict\n{\n  \"first\":{\n    \"second\":{\n      \"third\": \"maybe more\"\n    }\n  }\n}\nso I have to do like this\n```\nclass Third():\n    third = String()\nclass ThirdInput(Third, InputObjectType):\n    pass\nclass SecondInput(InputObjectType):\n    second = NoNull(ThiedInput)\nclass FirstInput(InputObjectType):\n    first = NoNull(SecondInput)\nand do the same to Objects\n...\n```\nis not it?. So is there a simple way to achieve it?\n I think we need an object that can resolve the nest problem.. I did not understand why there are two type(InputObjectType and ObjectType) before. But now, I understand it with writing more graphql. And I think it is necessary.\nPS: I think two more thing is useful:\n+ InputUnion\nI write another issue and also read the answer, but I still think it is necessary.\n+ Enum for one certain value\nlike this:\n```\nclass TypeEnum(graphene.Enum):\n    A = 'a'\n    B = 'b'\nclass AType(graphene.ObjectType):\n    type = TypeEnum()  #  Actually, it is A\n```\nThanks for your reply.\n. By the way, the document is useless. \n   = _ =. And I think it is a very normal usage.Is there any way to solve it?. I understand what you said.\n\u2018\u2019\u2018Arguments can be either required or optional. When an argument is optional, we can define a default value - if the unit argument is not passed, it will be set to METER by default.\u2019\u2018\u2019\nAnd I found this in graphql Document.\nBut, I think if timeout is not nullable & has default_value defined, it should get default_value when timeout=None.\nOr, default_value is useless, it is only used when nullable and not passed value.. @dan98765  Thanks\uff01. ",
    "vaskinyy": "@jkimbo thanks for confirming! The PR is in place. \nWe also tried to remove the field in our custom implementation and nothing happened.. It seems that graphene-sqlalchemy has a variable called iterable, but it doesn't use this field https://github.com/graphql-python/graphene-sqlalchemy/search?utf8=%E2%9C%93&q=iterable&type=. ",
    "schrockn": "Thanks so much for all the hard work on this project! If this is a new/unknown issue I could put together a PR. But before I did all that wanted to see if it was on someone's radar. Thanks!. Awesome! Thanks for the super fast fix.\nOn Wed, Mar 14, 2018 at 10:17 PM Syrus Akbary notifications@github.com\nwrote:\n\nThis is now fixed in master :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/issues/685#issuecomment-373263529,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AbaFeapZhIptQdo0pS4hS7YZdPh95bR9ks5tefligaJpZM4SrQ_X\n.\n. \n",
    "tlinhart": "GraphiQL is a standalone application, it doesn't require any integration. I have an API built on top of Flask and using GraphiQL in the same application for exploration the API. Basically all I had to do was to adapt the official example - change the URL for fetch in graphQLFetcher function. If GraphiQL is to run on the same domain, it's probably all you have to do. If it runs on different domain, you'll have to enable CORS and that's it.. Not really, for two reasons. When I define default value in the resolver, it's not advertised in a schema, for example in GraphiQL I don't see the default value for filters argument. That's why I specify the default value in field definition. The second reason is that I specifically don't know how to define an empty value of the Filters type. If I try to use filters=Filters() I get this error:\n{\n  \"errors\": [\n    {\n      \"message\": \"argument of type 'List' is not iterable\",\n      \"locations\": [\n        {\n          \"line\": 15,\n          \"column\": 3\n        }\n      ],\n      \"path\": [\n        \"search\"\n      ]\n    }\n  ],\n  \"data\": {\n    \"search\": null\n  }\n}\nWhen I try to use empty dict as the default value, I get this error:\n{\n  \"errors\": [\n    {\n      \"message\": \"'dict' object has no attribute 'project'\",\n      \"locations\": [\n        {\n          \"line\": 15,\n          \"column\": 3\n        }\n      ],\n      \"path\": [\n        \"search\"\n      ]\n    }\n  ],\n  \"data\": {\n    \"search\": null\n  }\n}\nHowever, when I query the schema like this\nquery Search {\n  search(query: \"some text\", filters: {}) {\n    count\n  }\n}\nI get the data without error.. After a lot of experimenting, I've found a workaround. If I define class\nclass DefaultFilters(object):\n    name = None\n    type = None\nI can then use its instance as a default value in field definition:\nclass Query(graphene.ObjectType):                                               \n    search = graphene.Field(\n        SearchResult, query=graphene.String(required=True),\n        filters=Filters(default_value=DefaultFilters)\n    )\nAlthough this works, I don't believe this is the correct way to achive the goal.. @cherls Yeah, it produces the correct schema (or at least the schema I except and I'm happy with), but the problem is with execution. When I execute the query and don't provide filters argument to search field, I get this error:\n{\n  \"errors\": [\n    {\n      \"message\": \"'dict' object has no attribute 'project'\",\n      \"path\": [\n        \"search\"\n      ],\n      \"locations\": [\n        {\n          \"line\": 2,\n          \"column\": 3\n        }\n      ]\n    }\n  ],\n  \"data\": {\n    \"search\": null\n  }\n}\nThinking about it, I guess Graphene is just about schema creation and not concerned with execution, right?. I don't execute the query directly, I use run_http_query and encode_execution_results functions from graphql-server-core package. But I'm pretty sure that's not the issue.\nAfter some debugging, I think I found the source of the problem. Inside the resolver, I work with filters argument as of type Filters i.e. I use dotted notation to access the attributes (e.g. filters.type). But when I define the default value as {} and don't supply the value in a query, inside the resolver filters is of type dict and thus I receive the 'dict' object has no attribute 'type' error message during execution. When I provide a value in the query (e.g. search(query: \"some query\", filters: {type: TYPE1}) { result } where TYPE1 is an enum value), inside the resolver filters is of type Filters and dotted notation works. Also the schema can be dumped using fp.write(str(schema)).\nIf I define the default value as Filters() (i.e. empty instance), inside the resolver filters is correctly of type Filters. However, if I don't supply a value in a query and try to print the value in the resolver, I get <schema.Filters object at 0x7f6892f544e0> (serialization doesn't work). If I provide a value in the query (e.g. search(query: \"some query\", filters: {type: TYPE1}) { result }), filters is of type Filters inside the resolver and printing the value correctly outputs {'type': ['type1']}.\nAnother problem is that with Filters() as a default value, schema cannot be dumped. If I try fp.write(str(schema)), it produces this error:\nTraceback (most recent call last):\n  File \"/home/tmp/test.py\", line 59, in <module>\n    fp.write(str(schema))\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphene/types/schema.py\", line 111, in __str__\n    return print_schema(self)\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 31, in print_schema\n    schema, lambda n: not (is_spec_directive(n)), _is_defined_type\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 75, in _print_filtered_schema\n    for typename, type in sorted(schema.get_type_map().items())\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 76, in <listcomp>\n    if type_filter(typename)\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 108, in _print_type\n    return _print_object(type)\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 138, in _print_object\n    type.name, implemented_interfaces, _print_fields(type)\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 174, in _print_fields\n    for f_name, f in type.fields.items()\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 174, in <genexpr>\n    for f_name, f in type.fields.items()\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 198, in _print_args\n    for arg_name, arg in field_or_directives.args.items()\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 198, in <genexpr>\n    for arg_name, arg in field_or_directives.args.items()\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/schema_printer.py\", line 206, in _print_input_value\n    default_value = \" = \" + print_ast(ast_from_value(arg.default_value, arg.type))\n  File \"/home/tmp/venv/lib/python3.4/site-packages/graphql/utils/ast_from_value.py\", line 55, in ast_from_value\n    assert isinstance(value, dict)\nAssertionError\nI naively assumed that this kind of things is handled automatically by Graphene. Is there something that I'm missing?. ",
    "vatsalshah1990": "Yup. Thanks a bunch. We can close this.\nSent from my iPhone\n\nOn 15-May-2018, at 11:14 PM, Jonathan Kim notifications@github.com wrote:\n@hornedbull did you manage to get this working?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub, or mute the thread.\n. \n",
    "ahujamoh": "The new example works, thanks. Hence, I am closing this issue.. @jkimbo thanks for the idea, raised the PR \ud83d\udc4d . ",
    "nikordaris": "@jkimbo using the value breaks the graphql enum spec. Introspection doesn't provide the value of an enum, only the name. This means that the value is never used once it gets to the client side. By setting the default_value to the enum value, the default_value becomes invalid as input for the enum on the client. This is an oversight of the spec in my opinion but graphql-js implements enum such that serializing the enum grabs the name instead of the value. graphene is not consistent with graphql-js which is considered the standard implementation.\nBut that is why i tried setting the value to a string that is the same as the name but the parser for default_value for enum's doesn't parse string values correctly for enum. it includes escaped quotes in the value.. Ok, i'll create an issue in graphql-core as well to see what they think about it. https://github.com/graphql-python/graphql-core/issues/166. ok @jkimbo I've added a test for partial. let me know if there is anything else i should change. This is a critical part of my company as well. Please include me as well. nikordaris@gmail.com. You can't use callable because class types are callable. . I could do not inspect.isclass(type) and callable(type). Really though I was basing it off of https://github.com/graphql-python/graphene/blob/12d4dab7742c9408777380c390152d7cef0f838d/graphene/types/utils.py#L44\nI wasn't sure if there were callable types we didn't want to support. ",
    "leethree": "related to #634 . . ",
    "jchang10": "To answer my own question, I had to make sure to define a classmethod on UserObjectType named is_type_of(cls, value,context,info) to return a bool value on whether to accept the \"returned data type\" that your custom code returns from the resolver for your ObjectType.\nSee https://github.com/graphql-python/graphene/blob/d46d8e8c33b1432ed664d94f432f357c44f3447e/graphene/types/objecttype.py#L61-L65\nIt's too bad there isn't better documentation. We have to rely on the code. However, the code isnt even really commented much, like the line above.\n. Cool. Just saw this. Thanks for the update!. ",
    "mingzhou": "Hi @jkimbo \nI'm quite confused that why there are two types of definition. Graphene schema definition graphene.types.schema.Schema and graphql-core schema definition graphql.type.schema.GraphQLSchema. \nSince graphene.types.schema.Schema is extended from graphql.type.schema.GraphQLSchema, how could I get   graphene.types.schema.Schema from graphq.parse(DSL file)?\n. ",
    "kusumkumari": "For graphene  using DateTime datatype.  follow three steps mention below -\n1. pip install dateutils\n2. In top  import this line  \"from dateutil.parser import parse\"  graphql file or graphene schema file\n3. graphene.DateTime()\nIts working for me. ",
    "Benjaminryejones": "Thanks for the response, @jkimbo.\nThe objects are generated by the Django ORM and I'm using a sorted version of the Graphene DjangoFilterConnectionField:\nGQL Card type:\nclass CardType(DjangoObjectType):\n    class Meta:\n        model = Card\n        interfaces = (relay.Node, )\n        filter_fields = {\n            'id': ['exact'],\n            'card_type': ['exact', 'icontains'],\n            'feeds': ['exact']\n        }\nGQL Card query:\nclass CardQuery(graphene.ObjectType):\n    card = relay.Node.Field(CardType)\n    cards = OrderedDjangoFilterConnectionField(CardType, orderBy=List(String))\nOrderedDjangoFilterConnectionField:\n```\nfrom graphene import relay, String, List, ObjectType\nfrom graphene_django.filter import DjangoFilterConnectionField\nfrom graphene_django.fields import DjangoConnectionField      \nclass OrderedDjangoFilterConnectionField(DjangoFilterConnectionField):\n    @classmethod\n    def connection_resolver(cls, resolver, connection, default_manager, max_limit,\n                            enforce_first_or_last, filterset_class, filtering_args,\n                            root, info, args):\n        filter_kwargs = {k: v for k, v in args.items() if k in filtering_args}\n        qs = filterset_class(\n            data=filter_kwargs,\n            queryset=default_manager.get_queryset(),\n            request=info.context\n        ).qs\n        order = args.get('orderBy', None)\n        if order:\n            qs = qs.order_by(*order)\n        return super(DjangoFilterConnectionField, cls).connection_resolver(\n            resolver,\n            connection,\n            qs,\n            max_limit,\n            enforce_first_or_last,\n            root,\n            info,\n            args\n        )\n```\n(For reference, I also get dupes when I use DjangoFilterConnectionField).\nI did a quick sanity check and I do not see any duplicate ids for the relevant table in postgres:\n\nAs I understand the node ids are generated from a hash of __typename + id, so I don't believe there should be any duplicate node ids.\nLet me know if you have any other questions or if I can provide more context!\n. Quick update:\nAfter some testing yesterday, it looks like the data argument passed into connection_from_list in graphql-relay/connection/arrayconnection.py (link) changes depending on the first and after arguments passed in in the GraphQL query.\nAs the function notes, it only works if the same array is static:\ndef connection_from_list(data, args=None, **kwargs):\n    '''\n    A simple function that accepts an array and connection arguments, and returns\n    a connection object for use in GraphQL. It uses array offsets as pagination,\n    so pagination will only work if the array is static.\n    '''\nNot sure where/how this is happening (must be in the DjangoFilterConnectionField resolver or something), I'll take a look later today.. I was able to troubleshoot by installing the Graphene Django debug middleware\nLooks like the inconsistent returns is a result of how Postgres handles LIMITs and OFFSETs: https://www.postgresql.org/docs/9.3/static/queries-limit.html\nWhile I was able to find a workaround in simple queries by results using a modified version of the DjangoFilterFieldConnection that allows one to order the results, I am unable to pass an orderBy argument to more complicated queries involving joins.\nExample with nested/joined query (can't pass orderBy into two):\nquery example {\n     one(after: \"xyz\", first: 5, orderBy: \"id\") {\n        stuff\n        two(after: \"abc\", first: 5, orderBy: \"id\") {\n        ...\n    }\n}\nReopening to request postgres cursor pagination support. ",
    "droudrou": "@jkimbo Thanks a lot for your help !\nIn fact, your answer perfectly fixed my problem :+1: \nNote that my first mutation was intentionally wrong because I wanted to get an error from it, \nin order to catch it and process it later.\nThe idea of the script is to catch bad requests from the user.\n@jkimbo Do you think there is a more appropriate approach to complete this goal ?\n:cactus: :blue_heart: :whale2: \n. ",
    "BrianGenisio": "@jkimbo Yes, this helps, and it seems you understand the questions fine.  I was just trying to understand if there were any conventions built in to the serialization of ID types that we should be adhering to, and it seems the answer is \"no\" which is a fine answer :)\nThanks!. Yes, thanks!. ",
    "ewhauser": "Happy to go that direction. Just let me know what we need to do.. * There was a PR that was merged earlier this year that makes it compatible with Python 3 although that is not currently reflected in the README file. As far as I know there are no blockers using this with Python 3 as-is although I have not tested it myself\n We should probably have the tests running via tox for both Python 2 and 3\n DroneDeploy continues to need Python 2 support for the near future (and it is fairly trivial to support both versions) so I don't see a need to go Python 3 only\n No blockers in upgrading to Tornado 5\n Happy to merge PRs for all of these things\n@syrusakbary - Still waiting on you for moving this repo over to graphql-python.. Repo moved - all set. I'll close this issue and we get started over there.\nThanks!. @syrusakbary - One more thing. Can you give me the ability to manage that project? Need to be able to merge PRs.. Any of the examples for Graphene should apply to graphene-tornado. The only difference is that your resolvers need to be async. See the README at https://github.com/graphql-python/graphene-tornado.. ",
    "kinow": "For a project, I would like to compare flask+graphql, and tornado+graphql. Happy to dedicate some hours coding/testing/or helping with documentation if necessary. Will probably go through the existing code, and try using the latest version of libraries, plus some sample code, to see if everything works fine.. ",
    "codeocelot": "Thank you very much DroneDeploy for sharing your work!  I've been playing with this code for a bit of time now, and I think it's a great addition to the python-graphql ecosystem.  It would be great to find a home for this project because I've got a handful of minor contributions, including adding support for python3.7.\n@syrusakbary can you set things up to move this project over so we can start contributing?  . Having just solved this last night, I appreciate the pain point.  I'm happy to write it up if @adamdavis40208 is busy. . I love these ideas. A few more things that could be accomplished with sponsorship that could increase visibility and promote graphql in python: \n\nGraphene's documentation can be fleshed out to make it more attractive to less-ambitious developers.  There's a fair bit of digging needed to get up and running with the current documentation.\nIncreased support for authentication, security and establishment of reasonable best-practices to remove doubt and instill the confidence to drive adoption through to production.\nSupport for community led initiatives, like developing ports for different python frameworks/servers (like my beloved tornado!)\nEstablish best practices in testing.  I think Python has all the tools to do this, we just need to document the best practices so testing becomes intuitive to newly onboarded developers.\n\nI'm ready and able to pitch in and make contributions to make this a reality, because I really think GraphQL in python has a ton of potential for a thriving ecosystem.. ",
    "mjpuser": "First glance, that repo is on python 2.7 using tornado 4.  I would recommend at minimum updating both of those.  \n@ewhauser I'd be interested in plotting out a roadmap and contributing.. ",
    "felipefaraco": "Do you guys have an example based on graphene-tornado to share ? I'm new to graphql/graphene and struggling a bit to understand this library.. ",
    "ProstoMaxim": "Thank you. Could you give an example of returning error via relay.ClientIDMutation, inside mutate_and_get_payload method. Your example gives no message\n{\n    \"data\": {\n        \"createNumber\": {\n            \"number\": null\n        }\n    }\n}. ",
    "jplock": "Anyway we can get this into the next release?. I don't think there's any set schedule, I've just been noticing some release-related activity on the various graphql-python projects and thought a new graphene release was imminent.. @picturedots maybe try adding 'Decimal' into __all__ in graphene\\__init__.py to fix the linting issue. To be ahead of https://github.com/graphql-python/graphene/pull/794, we could raise assertion errors. . Thanks for all the efforts @picturedots!  @jkimbo @syrusakbary think this could make the next release?. @maarcingebala can you submit a pull request with this change so it can be reviewed?. ",
    "sebdiem": "@picturedots done: https://github.com/graphql-python/graphene/pull/802. ",
    "bellomusodiq": "@jkimbo I have been trying but still not getting it. How do I check if it is working. I use Django by the way. Thank you. I'll try it. ",
    "ocavue": "@ekampf @jkimbo Thanks for your like!\n\n@jkimbo Here are my answers for your questions. I'm not very familiar with Graphene nor Annotation. So any corrections are welcome.\n\nHow would ObjectTypes work?\n\nWhen Hero inherit ObjectType,   ObjectType and it's base classes' __init_subclass_with_meta__ methods will be called. The main purpose of those __init_subclass_with_meta__ methods is create Hero._meta, who stores almost all information about Hero, like this one:\nIn [5]: Hero._meta.fields\nOut[5]: OrderedDict([\n            ('name', <graphene.types.field.Field at 0x10e6e11d0>),\n            ('age', <graphene.types.field.Field at 0x10e6e1278>)\n        ])\n\nCould you use both ObjectTypes and AnnotatedObjectType's in the same schema?\n\nif AnnotatedObjectType is a subclass of ObjectType, it should be easy to let them in the same schema.\n\nIs there anything that can be expressed in the python type system that can't be expressed in GraphQL (or vice versa)?\n\nThe only thing that I can find is that python type can do static check by tools like mypy or pyre. For example:\nShell\n\u279c  cat -n test_type.py\n     1  from typing import List\n     2\n     3\n     4  def process_user(user_ids: List[int]):\n     5      pass\n     6\n     7\n     8  process_user([1, 2, 3])\n     9  process_user([4, 5, \"NOT_INT\"])\n\u279c  mypy .\ntest_type.py:9: error: List item 2 has incompatible type \"str\"; expected \"int\"\nBut I don't think it's a big deal because of two reasons:\n\ntyping only support python 3.5+\nGraphene's type checker is made for request and response. There are not very \"static\".\n\n\nI think keeping the ObjectType and AnnotatedObjectType separate is essential, not just for keeping python 2.7 compatibility, but also supporting both ways of writing ObjectTypes.\n\nAgree! A downward compatibility API is very important. We all know the story about python 2.7 \ud83d\ude02.. @jkimbo \nI do write a simple AnnotationObjectType implementing:\n```python\nclass AnnotationObjectType(ObjectType):\ndef __init_subclass__(cls, *args, **kwargs):\n    fields = []\n    for name, func in cls.__dict__.items():\n        if name != \"Meta\" and not name.startswith(\"__\"):  # __init__ etc ...\n            fields.append((name, func))\n    for name, func in fields:\n        setattr(cls, \"resolve_{}\".format(name), func)\n        setattr(\n            cls,\n            name,\n            Field(func.__annotations__.pop(\"return\"), **func.__annotations__),\n        )\n    super().__init_subclass__(*args, **kwargs)\n\n```\nAnd it works fine for \"mix\" of AnnotationObjectType, ObjectType and Interface:\ngraphql\nquery {\n    hero {\n        name\n        wife {  # AnnotationObjectType\n            name ( only_first_name: true )\n        }\n        best_friend {  # Interface\n            name ( only_first_name: true )\n        }\n    }\n    heroine {\n        name\n        husband {  # normal ObjectType\n            name ( only_first_name: true )\n        }\n        best_friend {  # Interface\n            name ( only_first_name: true )\n        }\n    }\n}\njson\n{\"hero\": {\"best_friend\": {\"name\": [\"Hope\"]},\n          \"name\": [\"Scott\", \"Lang\"],\n          \"wife\": {\"name\": [\"Hope\"]}},\n \"heroine\": {\"best_friend\": {\"name\": [\"Scott\"]},\n             \"husband\": {\"name\": [\"Scott\"]},\n             \"name\": [\"Hope\", \"Van\", \"Dyne\"]}}\nYou can find the entire example in here.\n\n\nHow would you define fields that don't need a resolver?\n\npython\nclass User(AnnotationObjectType):\n    def name(self, info) -> graphene.String(required=True):\n        pass\n```python\nclass User(ObjectType):\n    name = graphene.String(required=True)\ndef resolve_name(self, info):\n    pass\n\n```\nFor my implementing of AnnotationObjectType, these two definitions are equivalent. In other words, we can define this kind of fields with an \"empty\" function. Not beautiful but it works. \nUpdate: A easier way for writting is as below:\nclass AnnotationObjectType(ObjectType):\n    def __init_subclass__(cls, *args, **kwargs):\n        ...\n        for name, func_or_field in fields:\n            if is_field(func_or_field):\n                pass\n            else:\n                setattr(cls, \"resolve_{}\" ...\n                setattr(cls, name, ...\npython\nclass User(AnnotationObjectType):\n    name = graphene.String(required=True). @syrusakbary Thank's for your comment. It's a beautify syntax. I really like it.\n\n\n\ndo not include attributes starting _ (private) to GraphQL\nAdd a explicit way of skipping attributes, such as:\n\n\nI'm ok with those two rules since graphene_sqlalchemy has aleady something similar:\n```python\nclass User(Base):\n    id = Column(Integer, primary_key=True)\n    username = Column(String(30), nullable=False, unique=True)\n    password = Column(String(128), nullable=False)\nclass User(SQLAlchemyObjectType):\n    class Meta:\n        model = User\n        only_fields = (\"id\", \"username\")\n```\nWe should also consider that someone may do want to add attributes starting _ into GraphQL.\n\n\nThe layering needed between native Python types and GraphQL types will be minimal\n\nif we use native python types, mypy may raise an error when using DataLoader because what DataLoader.load return is a Promise object. How to solve this?\npython\ndef get_student_names(self, info) -> typing.List(str):\n    return student_names_dataloader.load(self.__class_id)\n\npython<=3.5 don't support variable annotation syntax. So maybe we can support both syntaxes below:\n```python\n@ObjectType\nclass Person:\n    id: str\n@ObjectType\nclass Person:\n    id = graphene.String()  # current syntax\n```. Yes, that works for me. Forgot to check the document. My bad.  Thanks a lot.. ",
    "jlowin": "This is great! I'd love to see first-class support for annotation-based schemas.\nOne thought: AnnotationObjectType should only take fields that (1) are functions and (2) have return annotations corresponding to Graphene classes. Otherwise, people will be unable to add helper objects/classes to their ObjectTypes. Perhaps functions starting with '_' would be ignored.. ",
    "avivey": "(Coming from #886)\nI like the idea in general, but I have a problem in trying to glue together the type systems of GraphQL and Python - or rather, with writing a single statement to describe both at the same time:\npy3\n@ObjectType\nclass Collection:\n    def items(self, min: int = 0, max: int = 10) -> List[Item]:\n        return get_items(....)\nPython type system doesn't let me describe some important aspects of GraphQL type system:\n- Description (For fields, arguments, and ObjectTypes)\n- Directives (@deprecated, etc)\nMore importantly, there's a certain level of hackyness here: it requires that Python and GQL type systems play very nice together. They probably mostly do, but type systems are always more complicated than they appear, and any little incompatibility will break the abstraction. \n. oh, it's from an external lib. never mind.. update: never mind, I got the existing syntax to work. I still think the code is overly-complicated and this syntax isn't that useful, but it works.\n\nThe more I look at the code trying to resolve it, the more it looks like I'll want to completely break the existing syntax and replace it with something like this:\n```python3\nfrom enum import Enum\nimport graphene \n@graphene.enum\nclass Episode(Enum):\n    NEWHOPE = 4\n    EMPIRE = 5\n    JEDI = 6\nLengthUnit = graphene.enum(ExistingPythonEnum)\n```\nWhich, while obviously much less cool than the existing syntax, it's not much less readable and makes the Graphene source much more readable.\nThoughts?. > @avivey what was your solution for fixing introspection with default values?\nI didn't have one. \nConsidering the code complexity, my other issues with the project, and my personal hunch that \"when an argument is an Enum, the default value should be implicitly obvious\", I didn't spend any time on this.\nInstead, I don't define a default value and specify it in the resolver directly.. @ekampf . (I think #879 also makes this stuff work). Couple of suggestions on syntax to resolve this issue:\n```python3\nclass MyFirstAttempt(ObjectType):\n    __SCHEMA = dict(\n        name=String(description='Name of person'),\n        age=Int(required=True),\n    )\n    name: str\n    age: int\nclass MySecondAttempt(ObjectType):\n    class __SCHEMA:\n        name = String()\n        age = Int(required=True)\nage: int\n\n``\n(Actual type-hints onnameandageinstance field is completely optional in these options;__SCHEMA` just moves the gql fields into a single class member, so it doesn't interfere with the instance field types.\nAnother option, which I don't really like, looks like this:\npy3\nclass MyLeastFavoriteOption(ObjectType):\n    name = MagicTypingHelper[str](String(description='foo'))\n    age = MagicTypingHelper[int](Int)\nWhere MagicTypingHelper[A](B) is something that statically resolves to have type A, but dynamically resolves to have value B (which is of a completely different type).\nI don't like this one because of all the magic, and because we're working against the type checker (eg, MyLeastFavoriteOption.name here have value String() of type String, but the checker thinks it's type is str).. ",
    "dan98765": "Thanks @syrusakbary! \nhttps://github.com/graphql-python/graphql-core/pull/178 is the exact same change but for graphql-core. . @jkimbo @syrusakbary thanks for the responses; I truly don't care which import sorter is used I just really like having one. :) \nI created https://github.com/graphql-python/graphene/pull/743 to do the same thing as this PR, but with  isort. I'll close this PR out. . @jkimbo you're right this isn't very useful yet. I'd like to try tossing the test reqs into a requirements-dev.txt file and doing some other changes to try and make it easier for first time contributors to get started; could we leave this open a bit until you've had a chance to consider those changes and then decide?\nedit those changes are over at https://github.com/graphql-python/graphene/pull/745. @jkimbo I bumped the version up using pre-commit autoupdate. Does it look OK to merge?. Travis build passed at last; score!. @syrusakbary FYI this is the graphene repo's version of https://github.com/graphql-python/graphql-core/pull/188. @syrusakbary could you please give this a review? . @jkimbo how do you feel about this branch?. @jkimbo I think it would be good to update the contributing docs re: using tox. I don't think that should be a blocker on merging in this branch; I'll put out a separate PR to update the contributing docs. \nedit https://github.com/graphql-python/graphene/pull/744 to do this. . \ud83c\udf7b\ud83d\udc4d. @jkimbo sounds good; how about I'll break this up into smaller pieces and you can pick+choose which, if any, you think would be an improvement. \npy36 classifier : https://github.com/graphql-python/graphene/pull/763\nrequirements-dev.txt & remove test command in setup.py: https://github.com/graphql-python/graphene/pull/764. https://github.com/graphql-python/graphene/pull/765 to update README to encourage use of virtualenv. My expectations for this situation (and how I think it currently works) : \nIf your field timeout on InputObjectType is nullable & has a default_value defined. If timeout=None is passed by the user then I think the user's explicit passing of None should be respected and the default_value not take effect. The value is None. However, if the user omits passing the argument timeout completely then I think the default_value should take effect. \nIf timeout is not nullable & has default_value defined, then as a user I prefer that if I were to explicitly do timeout=None it would error because it probably means there's a bug in my code that resulted in None getting passed instead of an integer.. @yywing I'm not part of the graphql-python team so I can't speak for them and their design decisions. However, I would say that the current behavior around default & required values seems to follow the same pattern as swagger/openapi, which is quite large & respected.\nSpecifically, check out https://swagger.io/docs/specification/describing-parameters the section on \"Required and Optional Parameters\". In the \"Common Mistakes\" section:\n\nThere are two common mistakes when using the default keyword:\nUsing default with required parameters or properties, for example, with path parameters. This does not make sense \u2013 if a value is required, the client must always send it, and the default value is never used.\n. @keyeMyria what kind of fix are you hoping for? Are you asking for way to allow integers to take values below -2147483648 and above 2147483647? Or are you asking about something else?. @syrusakbary ah thanks for the context behind why test is there. \nAre you up for having test stay in extra_requirements and then have a requirements-dev.txt file in addition? Or would you prefer to drop this altogether?. I've seen use of lru_cache, or use anything from https://cachetools.readthedocs.io/en/stable/ both of which are caching per request-handling-worker you are running. \n\nIf you're working in a larger company/have more resources... To share the cache across multiple separate processors/machines in a data center we've used memcache. At this point you're getting into general large scale cache system design though that's not really graphene (or even graphql) specific... . This was the existing pattern in this repo; tox is pulling deps only from that list for running tests and not reading the list of test reqs from setup.py. \nI suggest accepting this PR so tox stops failing for now. Then I'd be happy to put out a followup PR to create a requirements-dev.txt file which can be the single source of truth for test requirements. . Sounds good; updated!. Nope; I'll go ahead and pre-commit autoupdate to bump to latest. . Unfortunately I'm not sure what it was for, and I don't currently have a good theory. cc  @syrusakbary do you recall what this was for?. Good catch, thanks. Added!. I suggest only using is for comparing versus None, or identity comparisons. == is for comparing logical equivalence, which is going to be pretty much all numeric comparisons.\nSome of the answers on https://stackoverflow.com/questions/2239737/is-it-better-to-use-is-or-for-number-comparison-in-python discuss it a bit more (1st SO page I googled). . Rather than repeating the construction:\nif BOOLEAN_EXPRESSION:\n    raise AssertionError(\"...\")\nCould you DRY things up by writing a helper function that does this and use it across the code as a straight replacement for the assert statements?. since the typing in this file is just type hints, which are just comments to the python interpreter, do you even need this for py27? What happens if you just remove the else completely and so only have Type defined for py3?. I gave it a shot in https://github.com/graphql-python/graphene/pull/913, seems like omitting the else statement tests still pass.. suggest keeping self here. It's python convention. Plus we have it in the example above this for resolve_name. . ahh I just opened an issue on your other PR about putting self into each method as per python convention, and also its used in other examples in the docs. But now here I see this place in the docs it is also set to be _ previously. Having it both ways in the docs feels not-consistent.\nIn the case of this particular PR your addition here matches the convention in this file of not having self so I'm fine with just merging this in and maybe we can figure out the whole self-vs-underscore thing across the docs separately... . Thanks for the explanation, @jkimbo! I agree that we should not use self unless the it actually does represent the instance of the current class in the standard python way.\n\nActually resolvers work like static functions and the first param is whatever the parent resolver returned.\n\nCould resolvers be decorated with @staticmethod to make this more explicit? Or does that break something?\n. ",
    "marcelombc": "Hi @jkimbo, the idea is to get rid of the resolve_room resolver and add the get_node method in the Room node. The idea is to pass an extra argument in the relay node field like this:\n```python\nclass Room(graphene.ObjectType):\n    class Meta:\n        interfaces = (relay.Node, )\nname = graphene.String(description='The room name')\n\n@classmethod\ndef get_node(cls, info, id, property_id):\n    return rooms_loader.load(\n        {'context': info.context, 'property_id': int(property_id)}\n    ).then(lambda rooms: [\n        item for item in rooms if item.id == int(id)\n    ][0])\n\nclass RelayQuery(graphene.ObjectType):\n    ...\n    room = relay.Node.Field(Room, property_id=graphene.ID(required=True))\n    ...\n```\nI know that this is not possible, that's why I created a graphene field for the room and get the id from global id.\nSince I'm new with GraphQL and graphene I just want to understand if what I did is a good practice or not. Another question is why we should use relay in the server side? Shouldn't we use relay as client side? And should I use graphene relay to build my API if I'm not using React in the client side? I'm really confusing with this part since relay is a JavaScript framework for building data-driven React applications. What if I choose to use Apollo for the client side? Should I implement relay in the server side? It would be great to get a more complete documentation about graphene relay.. Thanks for the explanation @jkimbo it was very clear. Like you said, the relay-classic assumes that you have a node in the root query. I've tried to create a general node to refetch both Property and Room like the following:\npython\nclass RelayQuery(graphene.ObjectType):\n    node = relay.Node.Field()\nThis way I could do the following queries to get a specific Property and Room:\ngraphql\nquery {\n  node(id: \"UHJvcGVydHk6Mjg5Mg==\") {\n    id\n    ... on Property {\n      id, name,\n      rooms {\n        edges {\n          node {\n            id, name\n          }\n        }\n      }\n    }\n}\ngraphql\nquery {\n  node(id: \"Um9vbTo2\") {\n    id\n    ... on Room {\n      id, name\n    }\n  }\n}\nBut since my get_rooms method depends on the property id I can't do this, that's why I created a root node field for the Property only (property = relay.Node.Field(Property)) and a root graphene field (has two required graphene.ID() arguments, one for the room id and another for the property id) for the Room (room = graphene.Field(Room, id=graphene.ID(required=True), property_id=graphene.ID(required=True))). \nDo you think it's possible to create a workaround to set a generic root node field to refetch both Property and Room like the previous example? What is your opinion about this and if you need to implement something like this, how do you approach it? Sorry for all the questions, but I just want to understand the best way to work with graphene and graphene relay and follow good practices from the beginning.. Thanks for the idea @jkimbo but I see a problem with your approach. Since my method get_room accepts the room id and the property id, there is no need to fetch the property. All I need is to pass the property id and room id to my service to get the room details. Going through the property is an unnecessary job because it will pass in the get_node method from the Property node. Since I'm using DataLoader the data is in cache but even then I don't want my code to go through unnecessary methods to fetch the data.\nI would prefer to use a room graphene field at root and translate the global id to proper id using the from_global_id method. ",
    "zflamig": "We are doing what you describe, our code might be a little bit hard to follow but you can start from https://github.com/uc-cdis/peregrine/blob/master/peregrine/resources/submission/graphql/node.py#L705 hopefully it makes sense.... ",
    "impowski": "@jkimbo Ok I see, I did something like that:\ndef resolve_user(self, args, ctx, info):\n        username = args.get('username')\nAnd it didn't work. @jkimbo we use the latest version, but shouldn't it work just like that with DjangoFilterConnectionField? Or it will only work on all_users? I don't understand the point of it if I need to write my own resolvers or it should work like that?. Ok, I guess I figured it finally, will post my update shortly.. ",
    "zhammer": "ugh i'm super sorry for this ^. just realized this is happening while going through my issues. i put an internal note in a commit on a development branch and have done a bunch of rebases. i'll remove the comment on my next rebase.. Didn't work for me.. Seems like this is where the name is set: '_meta': <ObjectTypeOptions name='GraphQlSong'>,. thanks @helloqiu. i'm going to try this out tomorrow when i have some time.\nalso thanks for linking this to #823. graphene is cool but is in dire need of improved documentation.. ",
    "paunovic": "Magical. Thank you.. ",
    "ZZHHAANNGG": "It complains about CSRF.\n```\n<!DOCTYPE html>\n\n\n\n\n403 Forbidden\n\n    html * { padding:0; margin:0; }\n    body * { padding:10px 20px; }\n    body * * { padding:0; }\n    body { font:small sans-serif; background:#eee; color:#000; }\n    body&gt;div { border-bottom:1px solid #ddd; }\n    h1 { font-weight:normal; margin-bottom:.4em; }\n    h1 span { font-size:60%; color:#666; font-weight:normal; }\n    #info { background:#f6f6f6; }\n    #info ul { margin: 0.5em 4em; }\n    #info p, #summary p { padding-top:10px; }\n    #summary { background: #ffc; }\n    #explanation { background:#eee; border-bottom: 0px none; }\n  \n\n\n\nForbidden (403)\nCSRF verification failed. Request aborted.\nYou are seeing this message because this site requires a CSRF cookie when submitting forms. This cookie is required for security reasons, to ensure that your browser is not being hijacked by third parties.\nIf you have configured your browser to disable cookies, please re-enable them, at least for this site, or for 'same-origin' requests.\n\n\nHelp\nReason given for failure:\n\n    CSRF cookie not set.\n    \nIn general, this can occur when there is a genuine Cross Site Request Forgery, or when\n  Django's\n  CSRF mechanism has not been used correctly.  For POST forms, you need to\n  ensure:\n\nYour browser is accepting cookies.\nThe view function passes a request to the template's render\n    method.\nIn the template, there is a {% csrf_token\n    %} template tag inside each POST form that\n    targets an internal URL.\nIf you are not using CsrfViewMiddleware, then you must use\n    csrf_protect on any views that use the csrf_token\n    template tag, as well as those that accept the POST data.\nThe form has a valid CSRF token. After logging in in another browser\n    tab or hitting the back button after a login, you may need to reload the\n    page with the form, because the token is rotated after a login.\n\nYou're seeing the help section of this page because you have DEBUG =\n  True in your Django settings file. Change that to False,\n  and only the initial error message will be displayed.  \nYou can customize this page using the CSRF_FAILURE_VIEW setting.\n\n\n\n```. It works now. Django issue -_-. Have been struggling for days. Thank you.. ",
    "messa": "I've just noticed this issue in notifications, I will try to answer the question anyway :)\nI think it's clearly explained in the comment:\n```\nAs per the GraphQL Spec, Integers are only treated as valid when a valid\n32-bit signed integer, providing the broadest support across platforms.\n\nn.b. JavaScript's integers are safe between -(2^53 - 1) and 2^53 - 1 because\nthey are internally represented as IEEE 754 doubles.\nMAX_INT = 2147483647\nMIN_INT = -2147483648\n```\nIf you need to transfer integers outside this limit - or if you need to work with numbers with decimal or arbitrary precision - just put the number inside a string.. I'm interested too, thank you! petr.messner@gmail.com. If you really need to return binary data then simplest solution would be (I think) to encode them using base64 to a String value. GraphQL usually returns data as JSON and JSON itself does not support binary data.\nBut maybe it would be better to return just URL of the image in the query response :). ",
    "lee-flickswitch": "```python\nclass RechargeSim(graphene.Mutation):\n    class Arguments:\n        msisdn = graphene.String(required=True)\n        network_id = graphene.ID(required=True)\n        product_id = graphene.ID(default_value='')\n        airtime_amount = graphene.Float(default_value=0)\nrecharge_id = graphene.Int()\nmessage = graphene.String()\n\n@staticmethod\n@graphql_secure\ndef mutate(root, info, msisdn, network_id, product_id, airtime_amount):\n    organisation = info.context.organisation\n\n    if not organisation.allow_recharges_via_api:\n        error = (\n            'You do not have permission to perform recharges via the API,'\n            ' please contact support to request access.'\n        )\n        raise Exception(error)\n\n    if not organisation.recharge_callback_url:\n        raise Exception('Please configure your Recharge Callback URL under Settings')\n\n    # HACK: Optional fields do not seem to be working,\n    # so we default to 0 in the field definition and then reset it here\n    # Defaulting to None falls over.\n    if airtime_amount == 0:\n        airtime_amount = None\n\n    _, network_id = from_global_id(network_id)\n    if product_id:\n        _, product_id = from_global_id(product_id)\n\n    data = {\n        'msisdn': msisdn,\n        'network': network_id,\n        'product': product_id,\n        'airtime_amount': airtime_amount\n    }\n\n    form = AdhocRechargeForm(organisation, data)\n\n    if not form.is_valid():\n        raise Exception(form.errors.as_data())\n\n    adhoc_recharge_id = form.recharge()\n\n    notification = 'Request Queued. Status will be POSTed to your callback URL when ready'\n    return RechargeSim(recharge_id=adhoc_recharge_id, message=notification)\n\n```\nhere are all the versions of the related libs:\ngraphene                                    2.1         \ngraphene-django                           2.0.0       \ngraphql-core                              2.0         \ngraphql-relay                             0.4.5. ",
    "patrys": "@jkimbo I want to calculate this and reject a query before it starts to be evaluated.. ",
    "Falieson": "Here's some more about the topic from the JS world:\nhttps://blog.apollographql.com/securing-your-graphql-api-from-malicious-queries-16130a324a6b\nhttps://github.com/pa-bru/graphql-cost-analysis\n. ",
    "honi": "Any update on this?. ",
    "xiaohanghang": "Hi\uff0cjkimbo   \uff0cThanks\uff01\uff01\uff01. can you give a example\uff1fit will helpful. yes. thanks\u53d1\u81ea\u6211\u7684\u534e\u4e3a\u624b\u673a-------- \u539f\u59cb\u90ae\u4ef6 --------\u4e3b\u9898\uff1aRe: [graphql-python/graphene] Is there anyway to do subquery? (#801)\u53d1\u4ef6\u4eba\uff1aJonathan Kim \u6536\u4ef6\u4eba\uff1agraphql-python/graphene \u6284\u9001\uff1ahangzaizai 479135798@qq.com,Mention @xiaohanghang did you resolve your issue?\n\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/graphql-python/graphene\",\"title\":\"graphql-python/graphene\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://github.githubassets.com/images/email/message_cards/header.png\",\"avatar_image_url\":\"https://github.githubassets.com/images/email/message_cards/avatar.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/graphql-python/graphene\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@jkimbo in #801: @xiaohanghang did you resolve your issue?\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.com/graphql-python/graphene/issues/801#issuecomment-473532352\"}}}\n[\n{\n\"@context\": \"http://schema.org\",\n\"@type\": \"EmailMessage\",\n\"potentialAction\": {\n\"@type\": \"ViewAction\",\n\"target\": \"https://github.com/graphql-python/graphene/issues/801#issuecomment-473532352\",\n\"url\": \"https://github.com/graphql-python/graphene/issues/801#issuecomment-473532352\",\n\"name\": \"View Issue\"\n},\n\"description\": \"View this Issue on GitHub\",\n\"publisher\": {\n\"@type\": \"Organization\",\n\"name\": \"GitHub\",\n\"url\": \"https://github.com\"\n}\n}\n]. ",
    "JulianSchneider": "I would think that would look like the from validators in django. You would specify a validator for the input and its checked once the endpoint is called.. ",
    "nwaxiomatic": "Here is an example of what validation could look like if modelled after REST Serializers (why do i need to inlclude serializers to get validation currently?)\nvalidation logic for rest here:\nhttps://github.com/encode/django-rest-framework/blob/master/rest_framework/serializers.py\n```\nclass ValidationMutation(graphene.Mutation):\n    class Arguments:\n        field1 = graphene.String()\n        field2 = graphene.String()\ndef validate_field1(self, value):\n    if value != 'BAD':\n        return value\n    raise graphene.FieldError('field1 is BAD')\n\ndef validate_field2(self, value):\n    if value != 'OOPS':\n        return value\n    raise graphene.FieldError('field1 is OOPS')\n\ndef validate(self, fields):\n    field1 = fields.get('field1', None)\n    field2 = fields.get('field2', None)\n    if field1 == field2:\n        raise graphene.FieldError('fields are the same value')\n    return fields\n\ndef mutate(self, field1, field2):\n    # This should be done with a loop through arguments\n    self.validate_field1(field1)\n    self.validate_field2(field2)\n    self.validate({\n        'field1':field1, \n        'field2':field2\n    })\n    return ValidationMutation()\n\n```. ",
    "adamdavis40208": "Sure thing, I'm no technical writer but I can take a swing at it.. @codeocelot Absolutely! I totally lost track of this. . ",
    "Sach97": "Any updates on this ? Thank's for the great work with graphene !. ",
    "fmoga": "Bump \u261d\ufe0f . ",
    "keeth": "Thanks! I'll close this issue for now.. ",
    "Kacppian": "Can I take this up? . On it. Sorry for the delay, was caught up. Here's a PR I raised, scraped the previous one - #808 . Still awaiting for reviews on #808 . Closed. This was resolved in #808 . Thank you for the comments. Should I fall back to not having the helper method? . I used the suggested construction in #794 and closed it later because you'd suggested I use a helper method. Never mind, I'll revert back to it. . I'm extremely sorry. I didn't mean it to come out like that. Just mentioning the reason I've done it this way.   . Cool then, I'll remove the helper method and make the necessary changes. . I am trying to do something like this - \n```\ndef raise_assertion_if(condition=None, message=None):\n    if condition:\n        raise AssertionError(message)\nraise_assertion_if(\n    condition=version[3] not in (\"alpha\", \"beta\", \"rc\", \"final\"),\n    message=\"Release version is unkown\"\n)\n```\nBut, Black (linter) keeps failing. Any clue as to why? . ",
    "wilk": "Yep, it was a GQL issue, my bad, sorry.\nThanks \ud83d\udcaa \nI'm closing this issue.. ",
    "ilyakitaev": "@jkimbo as I say it's a list of dicts. I can convert it to list of Photos() manually, but the question is there any already implemented way to fill ObjectType with nested fields from dictionary or I have to implement it by myself.. Thanks, @jkimbo. That's what I was looking for. I think that it would be in docs.. ",
    "saffrydaffry": "I'm surprised this wasn't in the docs, i'd spent so much unnecessary effort explicitly resolving dicts... please update the docs, this is an expected behavior of graphql.  thanks. ",
    "tomateos": "Yes, just add it as an argument to the resolver. Just define a new variable in your resolver and pass it in as a variable value when executing the query. This is a trivial example from the docs, but it should give you a good idea of how to create your resolver:\nhttps://github.com/graphql-python/graphene/blob/master/docs/quickstart.rst#creating-a-basic-schema. ",
    "NovemberOscar": "I think this is Flask-GraphQL's . Thanks! . ",
    "hqman": "use decorator\n@Promise.safe\n```python\nfrom promise import Promise\nfrom promise.dataloader import DataLoader\ndef get_user(id):\n    print(\"getting.......\")\n    return f\"User<{id}>\"\nclass UserLoader(DataLoader):\n    def batch_load_fn(self, keys):\n        print(f\"keys: {keys}\")\n        return Promise.resolve([get_user(id=key) for key in keys])\n@Promise.safe\ndef do():\n    user_loader = UserLoader()\n    p1=user_loader.load(1) \n    p2=user_loader.load(2) \n    p = Promise.all([p1, p2])\n    value1, value2 = p.get()\n    print(value1, value2)\ndo().get()\n```. ",
    "bitsapien": "You will have to pass the Mutation class to graphene.Schema for it to work like this, along with your Query class as shown below\npython\ngraphene.Schema(query=Query, mutation=Mutation)\n. ",
    "whirish": "Yes, that was done. See my above code.. It does, no I did not end up solving this problem. I ended up switching to DRF, though I may consider adopting graphene in the future if the code stabilizes. . ",
    "jakubczaplicki": "@whirish : did you managed to solved this problem ?\nMake sure the code uses the variable schema in view_func = GraphQLView.as_view('graphql', schema=schema) and is not overwriting the schema argument with something else.. I'll reply myself:\n\nPython server code:\n\n```\nclass UploadImage(graphene.Mutation):\n    class Arguments(object):\n        file = graphene.String(required=True)\nstatus = graphene.Boolean()\n\ndef mutate(self, info, file):\n    img = info.context.files[file].read()\n    # more stuff\n    return UploadImage(status=True)\n\n```\n\nCurl request:\n\ncurl -X POST http://localhost:5001/graphql \\\n             -H 'content-type: multipart/form-data; boundary=----GraphQlFileUpload' \\\n             -F 'query=mutation {uploadImage(file: \"photo\") {status}}' \\\n             -F 'photo=@selfie.jpg'. ",
    "MidTin": "It seems the reason is the class Mutation  inherited from graphene.AbstractType. ",
    "DianaD96": "I was having the same issue until I realized django's settings schema was pointing to a wrong one which was empty. Changed it to the correct one and it worked.\npython\nGRAPHENE = {\n    'SCHEMA': 'schemas.schema.schema'\n}\nSame for the urls:\npython\nurl(r'^graphql-dev', csrf_exempt(GraphQLView.as_view(graphiql=True, schema=schema)))\nThe rest of my mutation code looks like this (which seems to be working fine)\n``` python\nclass PropertyInput(graphene.InputObjectType):\n    id = graphene.Int(required=False)\n    name = graphene.String()\n    category = graphene.String(required=False)\n    status = graphene.String(required=False)\n    address = graphene.String(required=False)\n    city = graphene.String(required=False)\n    country = graphene.String(required=False)\n    photo = graphene.String(required=False)\n    area_land = graphene.String(required=False)\nclass CreateProperty(graphene.Mutation):\n    property = graphene.Field(PropertyType)\nclass Arguments:\n    input = PropertyInput(required=True)\n    owner = graphene.Int()\n\n@staticmethod\ndef mutate(root, info, input, owner):\n    owner_obj = Contact.objects.filter(id=owner)[0]\n\n    property = Property.objects.create(owner=owner_obj, **input)\n    property.save()\n    return CreateProperty(property=property)\n\nclass Mutation(graphene.ObjectType):\n    create_property = CreateProperty.Field()\nschema = graphene.Schema(query=Query, mutation=Mutation)\n```\nHope this helps.. ",
    "shifqu": "I had the problem about the docs not being updated as well. Current workaround is to have the local graphiql bookmarked without any arguments. \nI think that when you run a query, the docs get cached, so by removing the ?query= part of the url, you force graphiql to refetch the doc-strings.. I bet we are doing something wrong here, @symstu .\nBut I have the same issue. I try to call a method I defined in my Mutation object, it's called validate.\nWhen I try to call this method from my mutate method, the self param is empty. I think the usage will have changed when they removed the @classmethod. First off, I am using graphene-django, so this might be totally unrelated.\nAs a current work around I keep mutate as a @classmethod.\nI also changed the signature from self, info, **kwargs to cls, root, info, **kwargs. ",
    "a-musing-moose": "This also seems to apply to resolve_* methods too. . ",
    "vladcalin": "I also experience some frustrations with this and I think this is intended. I remember I saw a discussion in another issue related on this and the conclusion was that this design was deliberately implemented like this but I don't remember the justification and I can't seem to find the issue right now. \nI think this is a very poor design choice as it doesn't allow any OOP principle to be applied for mutations and queries as I can't access any method or member. What's the point of using classes if you can't use OOP principles anyway?\n. ",
    "woodpav": "What is the rationale for unbinding mutate @syrusakbary ?\nhttps://github.com/graphql-python/graphene/blob/08c86f3def71b1cb8aebc13026dae11982fc1ef7/graphene/types/mutation.py#L66\nEdit: the commit that unbounded mutate: https://github.com/graphql-python/graphene/commit/999bca84c98d452634dd530e374ea6b649167c64. I think the rationale is that the Mutation class is not a traditional class. Instead serves only as a description of a mutation. I also think the unbounded mutate was to fix a bug. \ud83e\udd37\ud83c\udffb\u200d\u2642\ufe0f. ",
    "gotexis": "Hmmmmm..... @BossGrand Hey thanks for the answer.\nActually, I was using Django, so your code is super useful and I wanted to take a similar approach.\nFollowing this, I have some more questions and thoughts, would be open to any suggestions:\n\n\nI am using DjangoFilterConnectionField to resolve queries, as for single items, I use Node.Field(Model)... which does not (as per the document) require a \"resolve_xxx\" method. Because there is no method, I wonder how to put caching logic here.\n\n\nBecause in my case, the API calls is gonna be quite heavy, I hoped to achieve a kind of greedy type of cache, which does not require traffic to the backend at all. Here are the steps required:\n\n\nquery once, and serialize the output into JSON file (may even be done periodically through Celery)\n\nsave the JSON into S3 storage, automatically uploaded to CDN\nfrontend (Vue) fetch that JSON before attempting to query the server. If the cache is too old or not present, can query the server.\n\nWith this way, I guess the most optimistic result will be zero calls to the server and all calls to CDN... Another benefit is that it will help clients worldwide since it is easy to have mirror CDNs than having a multi-zone DB instance / API.\nI guess we need to hook on to the query serializer process of Graphene, though I am unfamiliar with the project.\nAnyway, (2) is just a future projection, but I would be glad if anyone can just help me with (1) for the moment  \ud83d\udcaf Haha\n. @BossGrand Thanks and will post back here when I figure this out. The first step would be to find out how stock resolver is generated. ",
    "alxpy": "thx!. ",
    "elmehalawi": "Thanks @jkimbo, will do.. ",
    "helloqiu": "It would be great if some documents about how to change a schema name (#839) can be added.. According to the source:\nhttps://github.com/graphql-python/graphene/blob/master/graphene/types/base.py#L6\nYou can customize the type name like this:\npython\nclass MyGraphQlSong(graphene.ObjectType):\n  class Meta:\n    name = 'Song'\n@zhammer . ",
    "genericmoniker": "Why is the \"Mutations\" section under \"Types Reference\"? It seems like it would fit better in an operation type section, so that queries and mutations are together.\nAdd more GraphQL examples showing how a particular Python construct is used.\nAdd explanations of why something would be useful. \"You can pass context to a query via context.\" OK...\nSome sections are a bit awkward, and could use general editing:\n\nThe Relay section under Accepting Files: \"Mutations can also accept files, that\u2019s how it will work with different integrations:\".\nA heading called \"Dataloader\" when it should probably be \"DataLoader\". \netc.\n. \n",
    "lggwettmann": "Same with the graphene-django documentation. I have quite some problems making it to work and the documentation is seriously lacking lots of deeper info.. ",
    "antoine-gallix": "I'm starting to use graphene at our company to replace our REST API. I feel slowed down by the fact that the documentation is only composed of a tutorial. In my opinion, a good documentation is composed of a verbose tutorial to get people started on the basic concept, and a more terse but complete API reference where users can lookup details, signatures, parameters definitions and expected behaviors. Also in the case of a framework, explain the workflow that the framework is following. Which user function is called in which order for example. The most common approach in big python packages seems to be that the API reference, that is closer to the code, is self generated from the docstrings in the code itself. I had to often dive into the package source code to find answers to my questions and I felt a bit lost with the lack of docstrings and comments in the code as well. And just as a note, I would be willing to contribute a bit to the documentation.. Thanks @jkimbo , that was it. I finally found the answer to my question in an example of the readme file of the graphene-sqlalchemy project. There is a system of include/exclude fields from the conversion from SQLAlchemy model to Graphene ObjectType. In this example section it's written that one can do the following:\npython\nclass User(SQLAlchemyObjectType):\n    class Meta:\n        model = UserModel\n        # only return specified fields\n        only_fields = (\"name\",)\n        # exclude specified fields\n        exclude_fields = (\"last_name\",)\nSo I used those options to override the definition and resolver for that email field.\nI think the main thing that blocked me from finding this was that it was not clear to me that the sqlalchemy integration was developed in another project and that there were some additional documentation to be found in the readme of the project, not in a static documentation page.\nTo avoid such issues in the future, my suggestion would be to link to this page from the python-graphene documentation to make that information more discoverable.. Ok thank you for the advice!. @syrusakbary Now that more than a month have passed and many people have expressed their will to contribute to and maintain the project, what are the next steps? It seems to me that issues and pr are piling up, and the energy to contribute might dissipate if the evolution of this package is blocked by a contribution wall.. @patrick91 I'm also interested to see what's going to happen. We are using graphene in production and need to assess the future of the package and weather to put some efforts into it. antoine.gallix@gmail.com. What I found out:\nThe following worked to define a List field\n```python\nclass Thing(SQLAlchemyObjectType):\n    class Meta:\n        model = models.Thing # sqlalchemy model\nthings = graphene.List(ThingGraphQLType)\n@staticmethod\ndef resolve_things(args, info):\n    # returning a query seems to be ok\n    return Thing.get_query(info=info)\n```\nHowever the following does not:\n```python\nclass ThingConnection(relay.Connection):\n    class Meta:\n        node = Thing\nthings = relay.ConnectionField(ThingConnection)\n@staticmethod\ndef resolve_things(args, info):\n    return Thing.get_query(info=info)\n```\ngraphql.error.located_error.GraphQLLocatedError: object of type 'BaseQuery' has no len()\nBut this works:\npython\n@staticmethod\ndef resolve_things(args, info):\n    return Thing.get_query(info=info).all()\nThis is all based on try and error. That could be nice to explain that upfront in the doc.\n. After the previous declaration, I see on my schema that ThingConnection exposes first,last,before and after. This makes me think that pagination is implemented. \nHowever if I try to use the first argument in my query, like things(first:1) {edges{node{name}}}, I get back an error like graphql.error.located_error.GraphQLLocatedError: resolve_farm_connection() got an unexpected keyword argument 'first'\nLooks like it's not implemented. So I add the first argument to my resolver signature, without actually implementing the pagination:\npython\n@staticmethod\nresolve_things(args,info,first=None):\n    # 'first' argument is not used anywhere, only added to the signature\n    return models.Things.query().all()\nThere is three Things in my db. If I query things {edges{node{name}}}, I get 3 edges. Then if things(first:1) {edges{node{name}}}, I get only one. So after all even if I don't implement it myself, something in the Connection class will do it. But I still need to allow first in the resolver signature.\nI keep exploring this package but it's a slow process of try and error to discover features, find out what is possible and how to do it. The documentation is really lacking in this area.\n. Ok I'll start completing the doc as I discover about the package: https://github.com/graphql-python/graphene/pull/892. ",
    "timsavage": "Documentation of generating errors in mutations would be nice. Searching in the documentation for GraphQLError returns no results.. ",
    "jkhaui": "Any updates on whether Graphene has plans for schema stitching?. ",
    "robhobbes": "@StevenXue, there's a project called graphql-flask that works great: https://github.com/graphql-python/flask-graphql. ",
    "mikebobadilla": "@jkimbo Thanks so much. I came from JavaScript and completely forgot that arrow functions are just lambda functions \ud83d\ude1b . ",
    "collinc777": "So after diving into it further. I think this is happening because our replica database doesn't have the data. I'm trying to return the response with Cart.objects.using(\"default\").get(id=id) but I'm getting a Cannot assign \"\": the current database router prevents this relation.. ",
    "greenled": "@larsblumberg i just found GraphQL-core-next too. You should check the roadmap.. ",
    "eMerzh": "@syrusakbary Thanks for your work and the update \ud83d\udc4d \nSmall question, we were planing to move from -core to -core-next because we use asyncio and wanted to use updated graphql feature. But reading this it seems that you plan to incorporate the next into the modern branch then make it the \"only\" maintained repo.\nSo, should we wait until modern is ready, should we use -next, or 42?\n. ",
    "johnnymetz": "I have the same question.. ",
    "NateScarlet": "Wrong repo i will post this in graphene-django. ",
    "taoufik07": "Hey, Since we're talking here about permissions, I want  to get your feedback about this new package https://github.com/taoufik07/django-graphene-permissions\n. ",
    "firaskafri": "Any updates on this?. @patrick91 any timeline has been shared with you? there are great pull requests stuck in the pipline and the community is losing interest.. I'm interested\nfiras.alkafri@gmail.com. Could you please share the timeline for this with us please?. @syrusakbary We would like to have an update on this. This is an open source community project and there are some great pull requests stuck in the pipeline across grahpene's repositories. What is the proposed timeline and action plan for this?. ",
    "etandel": "Thanks for the feedback @patrick91 @jkimbo!\nI just implemented your suggestions, and rebased the branch.. ",
    "abdelhalimresu": "@jakubczaplicki  I think the request should respect the Multipart Request Spec, because many client libraries use it for files upload.. ",
    "artemnesterenko": "@cherls Using default_value={} I get the correct schema definition but the value passed eventually to my resolver is the empty dictionary but not my custom input type with default values I was expecting. Am I missing something or is that the intended behavior?. For now, I've ended up with the following solution:\n```python\nimport graphene\nclass InputObjectType(graphene.InputObjectType):\n@classmethod\ndef default(cls):\n    meta = cls._meta\n    fields = meta.fields\n    default_fields = {name: field.default_value for name, field in fields.items()}\n    container = meta.container\n    return container(**default_fields)\n\nclass SizeInput(InputObjectType):\n    width = graphene.Int(default_value=100)\n    height = graphene.Int(default_value=100)\ndef square(self):\n    return self.width * self.height\n\nSince now, it's possible to do:python\nclass Query(graphene.ObjectType):\n    square = graphene.Field(\n        graphene.NonNull(graphene.Int),\n        size=graphene.Argument(SizeInput, default_value=SizeInput.default())\n    )\n@staticmethod\ndef resolve_square(root, info, size, **kwargs):\n    return size.square()\n\n```\nIt produces the correct schema and passes the default value I was expecting instead of the empty dict.. ",
    "asodeur": "I'll write some tests Monday. I'd assume they should go under graphene/tests/issues/test_863.py and test framework is pytest, correct? . Added tests and improved response to bad variables a bit. However, I noticed  there currently is no way to get sane error messages when an input for a variable is not JSON serializable (the culprit being graphql.utils.is_valid_value.is_valid_value line 79). Marked these tests as xfail for now.. Turns out this is at the same time better and worse than I originally thought. Better because it depends on the Windows locale hence might not bite all Windows users (locale.getdefaultlocale() == ('de_DE', 'cp1252') does not work). Worse because even after the fix above other tools (like poetry) choke on the resulting PKG-INFO. Seems best to avoid anything non ASCII in the README.rst altogether.. ",
    "getglad": "From what I am seeing, it looks like rather than being passed in as an argument, account_id is being stored already as part of account in the ObjectType.\nSo if I add the below, I can get to the result that I want.\naccount_id = account_id if getattr(self, \"account\", None) is None else self.account.account_id\nIs this probably the best approach?\nIf so, I would be happy to try to add this into the docs for others.. @jkimbo - sorry for the radio silence. Have been working on this off and on.\nI'm tracking w/ your explanation, and I maybe didn't do a good job of explaining my solution, but I think we arrived at a similar solution, only I was reusing the same resolver w/ some added fault tolerance.\n```\ndef resolve_account(\n        self, # <= the resolved parent type\n        info,\n        account_id=None,\n        account_name=None\n    ):\n    inventory = get_inventory()\n\n    #change implemented here\n    account_id = account_id if getattr(self, \"account\", None) is None else self.account.account_id\n\n    result = [Account(\n        account_id=i.account_id,\n        account_name=i.account_name\n    ) for i in inventory if (\n        (i.account_id == account_id) or \n        (i.account_name == account_name)\n    )]\n    ...\n\n```\nYou comment re: \"the way that it finds the right account is fundamentally different\" did get me thinking. My solution works because my resolvers are actually extremely similar (they just access their inputs differently), but I could see a situation where a dissimilar enough logic exists that an unique resolver attached to the parent would be justified.\nI get a little itchy at the idea of resolver propagation, especially when the underlying data sources remain the same. \nA place where this strategy falls down, however, is when you want something from a parent's parent. I suppose this could be solved by adding parameters to your resolver method that you don't expose as an argument in the Field.\ndef resolve_account(\n        self, # <= the resolved parent type\n        info,\n        account_id=None,\n        account_name=None,\n        parents_parent=None\n    ):\n        ...\nBut I could see that getting messy/noisy fast, so maybe not a great idea.\nThoughts?. ",
    "kiendang": "force-pushed to rerun travis build. ",
    "ahokinson": "When using a connection field, you do a count(*) on a subselection which includes every column in the table. That seems unnecessary. \nIt's a particular issue for me because I am dealing with massive amounts of data using https://www.snowflake.com/. The metadata query for pagination details is actually super expensive in this situation because it has to move all the data just to get a row count. \nWould it not suffice to only use the node selections in the count?. ",
    "MichaelAquilina": "@avivey what was your solution for fixing introspection with default values?\nBoth default_value=MyEnum.Foo.value and default_value=MyEnum.Foo.name dont seem to work correctly for me . That's basically the approach I've gone for too - it's just not ideal for clarity in some situations :/ . ",
    "ckristhoff": "Thank you @jkimbo for you answer\nI'm grabbing the files from FILES in context just like you said. It's the way recommended by graphene at https://docs.graphene-python.org/en/latest/relay/mutations/#accepting-files.\nIn my test case I'm using the Client class recommended by Graphene doc at https://docs.graphene-python.org/en/latest/testing/#testing-in-graphene. But I'm does not achieve add files to the client graphene GraphQL mutation request. Graphene's documentation does not mention it \ud83e\udd14. Here a test repo.\nhttps://github.com/ckristhoff/graphene-test-uploads\n. ",
    "pieropalevsky": "I'd be interested. I have spent the last year plus working with Graphene in production and would love to contribute back to the project.\nEmail: ppalevsky@gmail.com. Can I get a slack invite? ppalevsky@gmail.com. In addition is there any way we can make this discussion public instead of slack., that way we can attract the most contributors as possible.. ",
    "Nabellaleen": "I'm also interested :) florian.briand@digital-engine.info. ",
    "adamchainz": "Me too, me@adamj.eu\nOn Thu, 3 Jan 2019 at 22:23, Florian Briand notifications@github.com\nwrote:\n\nI'm also interested :) florian.briand@digital-engine.info\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/graphql-python/graphene/issues/884#issuecomment-451296641,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AA0WCYE1Q7x-gIJBgEUGCgzSzp0pCSo3ks5u_oLlgaJpZM4ZiyOV\n.\n-- \nAdam\n. https://graphenetools.slack.com but you need an invite from @syrusakbary . \n",
    "leotsem": "I'm also interested. I've worked with Graphene in a couple of projects and I'm happy to share my thoughts and contribute back. leotsem@gmail.com. ",
    "dcrobinett": "I'm interested.  This is a central component for our companies intranet projects.  I wouldn't mind donating some time.  dennisr@sailrite.com. ",
    "forforeach": "I'd like to join forforeach@gmail.com. ",
    "dopeboy": "I'm interested! In the bay area too.\narithmetic@gmail.com. ",
    "phalt": "@syrusakbary @patrick91 this project is a major dependency for my team, so I'd be happy to join the discussion and contribute. paulandrewhallett@gmail.com. ",
    "cobalamin": "I'm in if you'll let me :)\nsimon@serioese.gmbh. ",
    "bk-equityzen": "We use it at EquityZen and are interested in joining the conversation and contributing. bryant.khau@equityzen.com. ",
    "bastiW": "Yeah, please please give us an update\n. @episodeyang \nGood idea!\n@all\nHere is the link for upvoting:\nhttps://news.ycombinator.com/item?id=19195824. ",
    "adilnaimi": "@jkimbo thank you for . the update, what's the slack workspace name?. @patrick91 my email is adilnaimi@gmail.com. Thank you . ",
    "p02diada": "I am interested in the discussion. My email is p02diada@gmail.com, could someone invite me to the slack channel? Maybe @patrick91 . thank you very much. ",
    "episodeyang": "I posted this on Hacker News to get some attention from people. Thanks for what you have done! My email is yangge1987@gmail.com\n. Can someone add me to the slack? yangge1987@gmail.com. There are quite a number of out-standing issues and we really need to setup a few key people to maintain this library soon @patrick91 . Hey @jkimbo! Thanks for your reply! \nI consider this to be a problem on the serving-side, as an implementation detail behind the graphQL schema. \nSuppose I have a large JSON string (5MB) that is read from postgreSQL. Deserializing it into python object, then serialize back is unnecessary. Would be nice if we could __insertUnsafeJson__ into the final graphQL response.. @patrick91 @dan98765 Can someone comment on this issue? We can create a PR if this indeed is considered something that we want.. yeah that's right! Was just about to post too. Thanks Ariel! @arielnmz \nSpec file see: https://facebook.github.io/relay/graphql/mutations.htm. ",
    "alexandremjacques": "Count me in! alexandremjacques@gmail.com. ",
    "wolowczyk": "Totally agree! pawelwolowczyk@gmail.com. ",
    "benldietchef": "Please add me. dream.without.sleeping@gmail.com. ",
    "artofhuman": "Hi. I'm interested, mail@semyonpupkov.com. ",
    "ceelian": "Hi, I'm interested as well: christian.haintz@cnc.io. ",
    "daveoconnor": "Could this be in a publicly accessible location instead?. @pieropalevsky take a look at the comment @syrusakbary just posted for details on the publicly accessible forum.. ",
    "ryou90": "What are the results of the meeting? Any news on this?. ",
    "brianmcfeeley": "I'm also looking for an update on the minutes of the meeting, or a summary, please.\nEDIT: From the #graphene channel in the GraphQL slack, I was forwarded the following meeting notes: https://docs.google.com/document/d/12-olPz5FHGx3w8kCkNX3FNhhx38abVR1VK-U2ehxHok. @syrusakbary is the slack still invite only? May I get an invitation please, if so, to brian@trialspark.com. ",
    "akinadebowale": "Hello, invitation to Slack channel please: akin@akinadebowale.com. . ",
    "louisdvs": "Agree that it's a huge trial and error effort to understand this lib. My understanding is that pagination is implemented on the edges, you appear to be trying to implement it on the root node. ie I think:\nthings(first:1) {edges{node{name}}}\nshould be:\nthings{edges(first:1){node{name}}}\nThis keeps it clean when you want to filter things, then paginate the results ie:\nthings(name:$name,type:$type)\n      { edges(first:$limit) {\n         node{\n           name\n         }\n       }\n    }\nThat is the benefit that you get from having the tedious amount of boilerplate in your queries.. ",
    "PsidomPC": "@jkimbo How can I use a customized class as args in graphene.Field?\nclass AdGroupConfigChangesArguments(graphene.InputObjectType):\n    platform = graphene.String()\n    platform_id = graphene.String()\n    bid_strategy = graphene.String()\nI tried with:\ngraphene.Field(\n    graphene.List(AdGroupConfigChanges), \n    args=AdGroupConfigChangesArguments, \n    resolver=adgroup_config_changes_resolver)\nBut it gives an error:\n\nAssertionError: Arguments in a field have to be a mapping. \n",
    "Hyakuningiri": "try to put like this;\ncategory:[{id: \"3\"}]. ",
    "nkg168": "@jkimbo that works as expected. Thanks a lot.. ",
    "averypmc": "Not sure what framework you're using, but with Flask I think the approach that we're going to take is to instantiate and attach our dataloaders to the g object on before_request and then delete it on teardown_request. Basically combining some notes from the DataLoader docs here https://github.com/syrusakbary/aiodataloader#creating-a-new-dataloader-per-request and the Flask docs here http://flask.pocoo.org/docs/1.0/patterns/deferredcallbacks/#deferred-request-callbacks.. ",
    "lucascharlesz": "Man, I must be the most dumb python dev ever.\nAfter two days hitting my head against a wall, you saved my week.\nThanks @jkimbo, it worked.. ",
    "norman-thomas": "You can avoid such naming conflicts by using the name parameter. You just name the field differently, but pass name='type' in your field definition. So in your case:\n```python\nclass Item(Interface):\n    id = Int()\n    type_ = Field(Color, name='type')  # notice the underscore in type_\n@classmethod\ndef resolve_type_(cls, instance, info):\n    if instance.type == Color.red.value:\n        return RedItem\n    elif instance.type == Color.green.value:\n        return GreenItem\n    elif instance.type == Color.blue.value:\n        return BlueItem\n\n```\nTypically, you can do the same for other names like id where pylint usually complains about using a reserved keyword as variable name.. Would inheriting from graphene.ObjectType and using the inherited class as parent for all others not solve the issue?\ni.e.\n```python\nclass ObjectWithQuota(graphene.ObjectType):\n    quota = graphene.Int()\ndef resolve_quota(self, info):\n    remaining_quota = determine_quota(...)\n    return remaining_quota\n\nclass Message(ObjectWithQuota):\n    pass  # TODO fields and resolvers\n```\nAll Message objects would then have the quota field with a default implementation of how to calculate it.. ",
    "lexdene": "@norman-thomas \nThe resolve_type of ObjectType has been rename to _resolve_type in https://github.com/graphql-python/graphene/commit/7340d80fa64d4aa815300322de5a9c5b25c394c3 \u3002\nI suggest that Interface.resolve_type can do the same thing to avoid such naming conflicts.. ",
    "crazyscientist": "With the most simple model manager that is defined exactly like the original django.db.models.manager.Manager the problem still persists:\n```\nclass NewManager(BaseManager.from_queryset(QuerySet)):\n    pass\nclass Reference(models.Model):\n    ...\n    objects = NewManager()\n``. I found the cause of the problem: ingraphehe_django/utils.pyin the functionmaybe_queryset. It is assumed that custom model manager are derived fromfrom django.db.models.manager.Manager`.\nSorry for bothering you, I will report this to the graphene-django project.. ",
    "jmichalicek": "I have recently been looking into exactly these same things. It would be great to have something built in available, and if not, at least some examples of how someone might best implement these with graphene.. ",
    "mvanlonden": "@jkimbo @Arfey Solution 4 sounds good. Easy to implement and will address this vulnerability in a timely manner. I don't see a reason why we would need introspection in production. @Arfey mind submitting a PR with this approach?. ",
    "Arfey": "yes, i will make pull request some time later. ",
    "arielnmz": "After doing some research I learned that that field's actual purpose is so the client can keep track of the mutations it sends to the backend (i.e. for Apollo or similar), that's why it's a String and not an ID or GlobalID, so perhaps it is indeed desired behaviour. Anyway, you still have to manually  add an ID field to the input (and resolve it afterwards) if your goal is to mutate an object referenced by a GlobalID, maybe the problem is that I expected a bit more from ClientIDMutations, so I came up with a crude solution in the form of Mixins and some helper functons to make them a bit more useful. Maybe I can create a PR when I'm done with this sprint, or at least link to a gist.... ",
    "PiDelport": "Sure thing!. ",
    "erback": "Shouldn't kwargs  be passed as well?, I have cases where i need to check permissions based on input params. agreed!. ",
    "keitheis": "Maybe\npython\n    def __init_subclass_with_meta__(cls, node=None, name=None, connection_options=None, **options):\n        _meta = connection_options or ConnectionOptions(cls)\nand have a test for this.. I just looked at this function and made the common comment. It should be fine if this repo went with the convention.. ",
    "wakemaster39": "I updated to add a unit test. I went with the _meta kwarg over connection_options because then it is the same name flowing through the entire process chain. \nIf you think it makes more sense to change it to connection_options I will do that, I just think it feels weird to change the naming convention.. "
}