{
    "scotthernandez": "manually merged\n. This should include the db, if it exists.\n. Yep, we should fix that for both :)\n. We are thinking of abstracting all the server selection behind an interface with a default implementation which can be overridden, like in the MongoOptions.\n. I see, it should be easy to expose the list of Nodes/ServerAddresses (probably the latter) from the ReplicaSetStatus instance for the replica set connection.\n. It is probably good to only add $and if there are children with the same name, otherwise $and is not needed, will bloat the query, and it may cause performance issues.\n. That is true, it is up to programmer to use the method but I'd be afraid they will use it logically without thinking about the ramifications of using lots of \"and\"s together. Perhaps this is best dealt with in (java)docs and we can just wait to see if the problems arise.\n. I'm not so wild about this interface or the way this is done. It would probably be better to provide a set of helper classes related to sharding operations which do not clutter the DB/Collection interfaces.\n. Cool, the changes look good generally. I've added a jira issue to track this: https://jira.mongodb.org/browse/JAVA-541\n. Looks good -- any chance of a test case for this?\n. We do record each address (pool) including the hashcode to uniquely identify it. See:\nprivate ObjectName createObjectName( ServerAddress addr ) throws MalformedObjectNameException {\n            String name =  \"com.mongodb:type=ConnectionPool,host=\" + addr.toString().replace( \":\" , \",port=\" ) + \",instance=\" + hashCode();\n            if ( _options.description != null )\n                name += \",description=\" + _options.description;\n            return new ObjectName( name );\n        }\nA failing unit test would be good so we can figure out that issue which causes the problem, before we fix it. There should really be no chance of collision with this naming scheme, in the same JVM.\n. ",
    "trishagee": "Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Closing old pull requests.  If the requirement is still valid, please feel free to submit a new pull request against the current driver code.\n. Hi Bryan, sorry for the very late response.  We're not going to merge this as it's a very old pull request and no-one's screaming for it.  Going forward, the driver will use gradle instead of maven.\n. Hi, I'm afraid we're going to close this pull request as it's very old.\n. The pull request did not work with the current code base, sadly we'd left it too long and the code had moved on.  If someone wanted to submit an updated one, we'd look again at merging it.\nHowever, please be aware that the whole driver is undergoing a large change as we implement the 3.0 driver, and we may find a better way to do this later.\n. BSON.java does use CopyOnWriteArrayList now\n. We won't be adding these sorts of helper methods to the existing driver, since we haven't seen a lot of demand for this functionality.  If this sort of thing is a requirement for a developer's application, we would suggest they write their own helper classes, the driver's API is quite crowded with methods at the moment as it is.\n. Hi,\nWe're currently working on a new driver, on the 3.0 branch.  We won't be making major changes to the 2.x driver, especially simply for performance, but we do hope the 3.0 driver will (eventually) be more performant.  We certainly hope that people will be able to tweak and tune it better.\nWhen that's released, please feel free to profile that version and send us feedback.\nTrisha\n. Apologies for the delay in response.  I agree that your code would definitely work, but the race condition you talk about is not actually a problem - the existing second check inside the synchonized block will stop the second thread from creating a new pool.  That first check is an optimisation to allow a fast, non-synchronized access to the collection to return quickly in the case that a pool currently exists.  \nI agree that this code is not very readable and can certainly be simplified, and my colleagues and I are in the process of doing just that - the 3.0 branch has a much cleaner architecture for managing connections, and simpler code too. Feel free to take a look.\n. Hi, sorry for the extreme delay in responding to this issue.  I agree that Exception messages in the Java driver are less than optimal, however for the 3.x driver we're changing all the exceptions across the board, hopefully with more useful information.  We'd rather not change Exceptions individually in the existing driver (like this pull request) but implement an overall strategy that should address all exceptions.\n. I agree, however we anticipate that the next release of the current driver will only contain defect fixes.  Although this pull request is a small change, because of the existing limitations with exceptions it's likely that users are actually parsing Exception message Strings to figure out what's going on, so any change to exception messages might actually break people's code.  Technically the change doesn't break backwards compatibility, but it could have an impact, and it's not a chance we want to take with the existing driver right now.\nIf we do make an update to the driver that's not just defects, then we'll consider adding this pull request. \n. Hi, thanks for the pull request.  Unfortunately, supporting Java enums is not as straightforward as it might at first seem, see https://jira.mongodb.org/browse/JAVA-268 for more details.  We're going to look into implementing it after the 3.0 release - feel free to check out the 3.0 branch to see how you might implement it there.\nTrisha\n. I'd like to apologise for the radio silence on this issue.  We have not been good at staying on top of pull requests or clearing the existing backlog, a situation we are actively working to remedy.\nWe won't merge this particular pull request, because of some of the issues raised by @dgottlieb.  I also agree with the comments that BSONObject could implement Map, but we'd need to work out the implications on the current API, and now seems to be a good time to evaluate this since we are working on a new version of the Java driver and the associated BSON library.\n. I think this is a good idea, however it's now difficult to merge this change and we're doing all new functionality on the 3.x driver not the existing 2.x driver.  The new driver outputs the server details when a network exception is thrown.\n. Going to close this as it's backwards-breaking\n. Hi Alex,\nJust a couple of pedantic issues, otherwise it looks good:\n1) Why use a LinkedList instead of a Stack?  It's being used as a Stack so it feels like that would be the most logical data structure\n2) Small naming improvements: I'd prefer \"name\" (line 70 on DefaultDBCallback) to be lastName, which would be consistent with the old functionality; and the DBCollection variables in DBRefTest should have more descriptive variable names than \"a\", even if it's just \"collection\".  I also don't like \"fake\" as a field name, this too should be something more descriptive.\nI appreciate the second point might come across as overly fussy, but we're working hard to improve the quality of the overall code base in terms of naming and conventions.\nTrisha\n. Closing as the Jira ticket is also closed.\n. Small pedantic comment - MongoOptions line 33 doesn't have a deprecated javadoc comment\n. I appreciate that this code is probably auto-generated, but could you add all the appropriate curly braces for the \"if\"s please?  We're trying to move towards a standard code style in the driver.\n. I see your point of view, and I too am not a fan of having unnecessary things in the codebase (I'm also not a fan of things like the inconsistency you've discovered).  However, at this time I don't think removing the synchronized key word is the best solution to this problem.  The fact that it's synchronized at all points to some design decisions that need to be re-considered.  \nThanks to your pull request, we have recognised the need have design discussions in this area and come up with a more logical API (preferably without synchronized scattered throughout the code), and have added this to the board of things to do for the new driver, which is currently under development.\nI am going to close this pull request because, as it stands right now, having the keyword on that method documents to the caller that this method has a cost.  However, you have highlighted an important point and we will address it in the new driver.\n. We're not going to add this for the 2.x driver, but we do know that there is a need for more logging/monitoring in the driver.  This is something that should be addressed in the 3.x driver.\n. Thanks Juan.\nIs there any way to test this functionality? Preferably in an automated way, but I appreciate this might not be possible.\n. Also, could you put the changes to gitignore into a separate pull request please?\n. Hi,\nI've made some comments on JAVA-640 outlining my preferred approach, but I suggest we implement this on the 3.0 branch - we don't intend to make any API changes on the current driver, it makes sense to have them all on the new version.  Feel free to submit a pull request based on that code.\nTrisha\n. We haven't had requests from our users to add this functionality.  Can you outline the use-cases / requirements for adding JNDI support?  I appreciate that it's a fairly simple change, but every additional line of code in the driver is something that needs to be supported, so we need to fully understand the requirements for it.\n. I take your points, but for now I'm going to park it - not least because we're working on the 3.0 driver, and we'd like to only make critical changes to the old code base.\nThank you for your detailed response, it was very useful.\n. We're not going to add this for the 2.0 driver, but we will consider adding it for 3.0.\n. Hi Caleb, sorry for the delay in responding.  In fact, it's so delayed that I can't automatically merge your pull request.  Is there any way you can update it to work on the current code?\n. Thank you\n. As discussed on JAVA-831, this is not really the required behaviour.  In fact, the travis build for this pull request has failed because this method should not be closing any connections.  Thank you for raising the issue of unclear documentation around using this functionality, we will address that.\n. Closing - merge conflicts.\n. Merge problem\n. Unfortunately this does not compile - we're using TestNG not JUnit, this is not the way to ignore tests.  Instead, it should have \"enabled=false\" in the Test annotation.  Also, if we were to ignore this test, we should make a note of why - in this case I'd want some comment in the test annotation about \"needs to be run with slaves\" or similar.\n. Hi,\nWhile I totally see the need for this feature, we're designing a way to do this in the new 3.0 driver which will be more configurable and extensible.\nAlso, this pull request doesn't compile because it only works on Java 7 and above, and the current version of the Java driver needs to work with Java 5 and above.\nThanks for submitting this, but I'm afraid I can't accept it at this stage.\nTrisha\n. Not yet!  We're actually working on the design this week as it happens.  As soon as we have something we'll make it public.\n. Needs to be on the 3.0 branch\n. Is there a Jira ticket to implement this?\n. Thanks for the pull request.  A couple of things:\n1) Is there a Jira ticket for this?\n2) This code doesn't actually compile\n3) We'd like to see tests around functionality that's been implemented.\n. Hi, thanks for the pull request.  A couple of comments:\n1) I'd really like a test to go with this - feel free to add it to DBTest.\n2) I prefer to wrap validation code in a Validator class, or failing that at least a method that explains what the validation is trying to achieve.\nTrisha\n. I also don't like checking the Exception message specifically - I see why you want to do it, but a) it's very brittle and b) if we ever internationalise error messages all of this will break.  Normally I'd prefer to throw a specific exception type and check that, but that's not the pattern we follow in the driver, so for now simply checking the Exception is thrown is OK.\nAlso, I prefer tests to test a single thing - I know the existing tests aren't great at this, but we should try to move towards it.  Therefore I'd like to see whenDBNameIsInInvalidFormatThenThrowException split into two tests, where the test name is more specific (e.g. whenDBNameIsEmptyFormatThenThrowException)\n. I see that you've tried to reuse the mongo instance in whenRequestStartCallsAreNestedThenTheConnectionShouldBeReleaseOnLastCallToRequestEnd, but you don't need to do this.  The settings used in that test are not those needed by your tests.  Instead, you can use cleanupMongo like the setup does, and you won't need to add all that init and cleanup code.\nIn addition, you've actually changed the test whenRequestStartCallsAreNestedThenTheConnectionShouldBeReleaseOnLastCallToRequestEnd so it no longer does what it's supposed to - it's meant to have nested calls to requestStart and you've removed the second level of requestStart, but that's what the test is testing.\n. Oh, I see what's changed.  But the request start is now now in the try block, so the finally with the request end is not in the right place.  Can you reset that test back to the way it was please?\n. Supported versions for 2.x are 1.5+\n. Thanks for finding this and submitting a pull request.  However, a couple of things: firstly, ordinarily we like a test to show what the original problem was, as well as the the change. Secondly (and you weren't to know this) the area of codecs is still very much under development, and almost definitely won't look anything like this, therefore we're not accepting pull requests in this area at the moment.  Sorry about that.\n. Thanks for the pull request, and very sorry it's taken so long to respond.\nCan you add some tests to prove the need for this feature? Pull requests with adequate tests are more likely to be merged.\n. I'm not keen on the name CodecSource, can we use something like CodecProvider instead?\n. - Not keen on the existing BSON values being inconsistently named with the new ones - i.e. Binary should be BsonBinary.  We need to keep the old type as well, I don't mind another layer of indirection to provide consistency\n- In DBCollection.update(), there's an \"if\" with nasty dots all over the place - can we pull that into a method that describes what that check is?\n. Small niggle - I can't see it in the list of changed files here, but I'm assuming this happened somewhere in this pull request: When you changed GetIndexesOperation to take a generic Param, you needed to update the Javadoc for the class to explain what that param is\n. So far, I've gone through the changes in the BSON module, and I've come up with a few things. These are all mostly small things that IntelliJ analysis pointed out to me, I can't see anything that's a showstopper so far.  I'm pretty happy with the fact the classes seem fairly simple and do one thing, and happy with the fact there are tests :)\nHere goes:\nBSONWriterSpecification needs spock, and it\u2019s not on the dependencies for the BSON module\nDidn\u2019t we decide to call CodecSource CodecProvider? \nDidn\u2019t we agree to have a BsonBinary as well as a Binary type to provide consistency?  Similarly, it\u2019s confusing that some of the codecs start with Bson and others do not\nBsonValue: isDateTime(), isJavaScript() and isJavaScriptWithScope() are not used.  Does this mean there\u2019s missing functionality, missing tests, or they\u2019re not really needed?\nBsonDocument:\n- javadoc is not complete for the constructor, doesn\u2019t document the params\n- also has unused methods, suggesting missing tests\n- getDocument(),getArray(),getInt32(),getInt64(),getDouble(),getBoolean(),getString() all missing javadoc for params\nBsonDocumentWrapper: missing javadoc for getWrappedDocument(),getEncoder(),isUnwrapped()\nCode & CodeWithScope: missing javadoc for constructor and getCode()\nDBPointer: missing javadoc for constructor, getNamespace() and getId()\nObjectId: missing javadoc, but probably was that way when you started working on it\nTimestamp should be BsonTimestamp since it was only introduced in 3.0 anyway (and getInc() missing javadoc)\nUndefined should be BsonUndefined?\nAbstractBsonReader.isClosed() needs javadoc\nAbstractBsonWriter looks simpler than it was - yay!\nBsonBinaryWriter.Context - does this have to be a public class, or can it be default/package?  I appreciate this was already in this state, so, not exactly a showstopper for this PR\nBsonDocumentReader/BsonDocumentWriter: constructor missing javadoc\nBsonReader/BsonWriter: there are unused methods, and I\u2019m not sure if that means they\u2019re not needed, not used, or not tested.\n. Something else I noticed on the BSON module:\nBsonDocument isString documentation is a little misleading - I assume it will also return false if the key is present but not a string.  Which actually makes this method a bit weird, it\u2019s sort of \u201chasThisKeyAndIsStringValue\u201d, but that\u2019s a lot less catchy\n. OK, I made it through all the changes in the driver module, although because it's a big pull request it's not totally clear if all the classes that look like they were affected were actually in this PR.   But all the same, I have quite a few observations.  Most of them are small tweaks and changes, although there are a couple of questions in the mix about design/architecture.  So here are my thoughts, in a random order (the order of the class differences as presented by IntelliJ):\nI\u2019m not 100% certain if BsonTypeClassMap belongs in driver or bson, although I think there are arguments for both\nThere are two CodeWithScopeCodec classes?  One in driver and one in bson?\nI\u2019m still not sure about the name \u201cCollectibleCodec\u201d, particularly as there\u2019s no such thing as a Collectible.  And if there were a Collectible, I think that would be the thing that\u2019s responsible for creating the ID, not the codec - currently a CollectibleCodec violates the Single Responsibility Principle, as it\u2019s responsible for generating the ID and serialising the document.\nDocumentCodec: there\u2019s missing Javadoc for the IdGenerator param in the constructor;\nDocumentCodec - now I remember why the ID stuff is on the codec, because of what you need to do to get non-BsonValue IDs out.  Still feels like a smell, but I can\u2019t think of something better to suggest without introducing the concept of two types of documents, a collectable one and one without an ID\nDocumentCodecSource: I assume we only support lists and not arrays or other Iterables? And what about Maps?\nEncodingException doesn\u2019t seem to be used\nIn some of the codecs, you have:\nregistry.get(bsonTypeClassMap.get(reader.getCurrentBsonType()))\nI think I can see why the class map is separate to the registry, but it feels like a bit of a smell to have three \u201cget\u201d methods there, it suggests we\u2019re not doing \u201ctell don\u2019t ask\u201d since we\u2019re asking for three things.  The registry doesn\u2019t have to have a BsonTypeClassMap (I can see why it wouldn\u2019t), but maybe you could have a method on it: get(BsonType, BsonTypeClassMap) which encapsulates this functionality, since I assume it\u2019s going to be reproduced in most of the codecs.\nPatternCodec is missing Javadoc\nServerStateNotifier: getString() and listToSet() look like utility methods that belong somewhere else - maybe a helper class, or maybe on BsonDocument itself.\nAggregateHelper.asBsonArray also looks like a util method that belongs somewhere else\nAggregateOperation constructor missing javadoc\nOperationHelper.getBsonDocumentCodec() - not entirely sure this is necessary, since it just news up a new Codec.  However, if it is necessary so it\u2019s just one central place for creating new codecs, it should probably be in a factory not some random util class.  In fact, I\u2019m not really keen on CommandOperationHelper at all, it seems like a bit of a dumping ground for stuff which suggests some missing concept somewhere, but it\u2019s not a problem for this pull request.\nBaseUpdateRequest: doesn\u2019t need the checkstyle suppression any more\nFindAndModify: doesn\u2019t need the checkstyle suppression any more\nGroupOperation: param T javadoc missing\nMixedBulkWriteOperation: javadoc missing for constructor params\nRemoveRequest: doesn\u2019t need checkstyle suppression\nUserExistsOperation: line 93 can be simplified\nGetCollectionNamesOperation: line 62 can be simplified\nUserOperationHelper: I preferred chaining \u201cappend\u201d methods rather than multiple \u201cput\u201d calls, but that\u2019s just a style thing\nRequestMessage: why does this have a static BsonDocumentCodec when in other places (like the OperationHelper) create new codecs on demand?\nStorageDocumentFieldNameValidator: why do we talk about a Storage Document here, and yet have a CollectibleCodec? we need to standardise on names\nProtocolHelper lines 58, 133, 140 can be simplified\nWriteCommandResultHelper has a lot of \u201cget\u201d calls that can be simplified to remove casting\nWriteResultCallback: checkstyle suppression not needed; ordered field can be final\nCodeWithScope: there\u2019s a a bson one and a mongodb one, is this necessary?\nAllPrimitiveTypes is no longer used\nDocumentCodecSpecification: I uncommented the DbPointer stuff and the tests still worked, so I assume we can add that back in again?\nStorageDocumentFieldNameValidatorTest: could be a Spock test.  Just sayin\u2019\n. Oh, and findbugs-exclude.xml contains a reference to JSONWriterSettings, which presumably is now redundant\n. Given the rather massive amount of (mostly tiny) changes I've suggested, I also want to point out the positives, especially from the point of view of the driver module:\n- It's good that messages are responsible for knowing how to validate field names\n- I like the reduction in document codecs being passed around\n- The reduction in casting makes the code a lot easier to read\n. Feedback for changes to driver-compat module:\nQuestions/suggestions:\n- There\u2019s a BSONTimestamp and BSONTimestampCodec in driver-compat? Are these needed?  If so, they also need the new capitalisation applied\n- BulkWriteOperation does ID generation?  I thought CollectibleCodec did that?  And DBObjectCodec does have an ID generator\n- DBObjects: now this is a useful codec util, maybe it belongs somewhere codec-shaped (and could be renamed to something more useful?)\n- What\u2019s DBObjectFactory?  Does the functionality that\u2019s still in DBObjects belong somewhere in an implementation of this?\n- DBCursor min() and max() are missing javadoc for params\nThings I like:\n- This makes the conversion between DBObject and BsonObject much better than the DBObject -> Document conversions we were doing before\n- DBCollection seems simpler\n- WriteRequest subclasses are simpler\n. I've been through the updated files and they all look good to me.  The points that I'm not sure about are not going to impact any of the public-facing API, so I'm happy with this pull request.  I started looking at the BsonValue rename as well, but I agree we should keep that separate,\n. I like any commit that removes more lines than it adds (if all the tests still pass!).  Looks simpler.\n. Hi, thanks for the pull request.  I'm interested in why you deleted the test testParseWithPortWhenNonEquivalentPortIsAlsoSpecified?  It seems to me that both the test you added and the previous test can co-exist happily, not sure why the old test is no longer valid?\n. Thank you for fixing this misleading documentation, and apologies for the delay in replying.  To make it even clearer, it would be great if you could add the following to the end of the Javadoc:\n* @mongodb.driver.manual reference/command/createUser createUser\nFor an example, see line 291 in that class (DB.java). This tells our custom tag to insert a link to the appropriate place in the MongoDB documentation.  By adding this we can improve the documentation even further.\n. Made suggested changes, although I re-wrote some of the history (specifically around the \"final\" changes which I didn't want to put into the code and then take out again) which I think has lead to some of the inline comments becoming disassociated with the current files.  Changes made:\n- Removed final from Exception catches and for loops\n- Made wording changes\nI think the branch had moved on since the pull request was submitted, so I think the following files weren't in the original pull request:\n- ConnectionPoolSettings\n- ServerDescription\n- SSLSettings\n- MapReduceOutputOperations\nThis time I will not make changes to the branch until the pull request is merged.\n. We can get checkstyle to check that parameters are final for methods, but we can't get it to check that final is NOT put on variables or throws methods.\n. You can change parameter names without affecting binary compatibility:\n\nChanging the name of a formal parameter of a method or constructor does not impact pre-existing binaries.\n\nFrom Oracle's binary compatibility documentation\n. As usual, I have comments on the testing of the implementation, but other than that looks good to me.\n. Already done.\n. Done\n. Comments addressed - changes made.\n. Some comments but overall LGTM\n. Some comments inline, but otherwise this change looks like a good move.\n. Have addressed the specific points, and also I went back over all the changes to make sure I didn't change the visibility of any other classes. Discovered some other minor nits while I was on it so I've address all those. This should be a slightly neater set of changes as I've rolled back some changes that were just noise.\n. If there aren't any further comments on this, I'll merge it\n. Merged.\n. Have rolled back the changes to BsonTimestamp since they don't add anything to the user's understanding. I believe I have addressed all the comments now.\n. All comments/questions addressed.\n. Squashed and merged.\n. I've fixed the problem with the uberjars - for some reason, only the \"provided\" dependency from the top level project was being excluded. I've explicitly excluded both provided dependencies as it's the clearest way to document what's going on.\n. OK so... here's what we've got now:\n- Addressed specific points raised in the pull request conversation\n- Removed netty from uber jar, not sure how that snuck back in\n- Publishes individual module jars to Sonatype Nexus with the correct artifact name (this was broken before), and publish an '-all' jar that's the uber jar\n- Attaches the uber jar for the driver project to the release notes\nThis process is still very brittle, and I'm considering only automating the \"publish\" bit and removing the \"prepareRelease\", \"draftReleaseNotes\" and \"updateToNextVersion\" steps.\n. Latest commit - now there's not a big web of dependencies, all tasks can be run independently if wanted/needed.  There's still a \"release\" task which runs everything, theoretically in order (by using \"mustRunAfter\" on each of the tasks). \n. Is there a test for this?\n. This can be simplified to \nnonceResponse.getResponse().getString(\"nonce\u201d)\n. Can be simplified to \nBsonInt32 conversationId = res.getResponse().getInt32(\"conversationId\");\n. Can be simplified to \nwhile (!res.getResponse().getBoolean(\"done\").getValue()) {\n. There's no getBinary()?\n. Can be simplified to:\nreturn commandResult.getResponse().getInt32(\"setVersion\").getValue();\n. Can be simplified to:\ncursorId = cursor.getInt64(\"id\").getValue();\n. This is invalid HTML under Java 8 Javadoc\n. Added package-info for packages that were touched.\n. Following the standards agreed a while back, parameters should be final and variables don't have to be.\n. We agreed we don't need/shouldn't have final on variables.\n. Final is not required on interfaces.\n. I'm going to do that on the second pass.  This pass is about making sure there is documentation for all public methods and classes.\n. Applied change.\n. Applied change.\n. Done.\n. Done.\n. Have reworded.\n. Done.\n. Done.\n. Done.\n. Changed IDE configuration and reverted final changes to for loops and exceptions.\n. Done.\n. Done.\n. Done.\n. Done.\n. A list was much tidier than a table.\n. This was undocumented, and turns out it's never really thrown anyway.\n. Ah, this was a mistake.  I've removed it.\n. Arg, my spell check got turned off.  Fixed.\n. The code implies it gets all of them.  @jyemin?\n. According to my IntelliJ inspections, @code is the preferred method.  Although if you use pre you don't actually need @code, I found out yesterday.\n. Have updated the docs, and added a test to show that a CommandFailureException is thrown if the collection already exists, regardless of the options.\n. Have updated the docs, and added a test to show that a CommandFailureException is thrown if the collection already exists, regardless of the options.\n. This was already tested in DBTest\n. Sure, but since we don't have tutorials at the moment, I suggest we keep the samples we've got at the moment and replace them with links to tutorials when we have them.\n. It's no big deal to reproduce this everywhere - I'm thinking about users who look at just the method javadoc (something I do myself a lot).\n. Sure.  But I can't think of any other way to phrase it: DBCursor contains a much more detailed explanation of how that works.\n. These comments haven't been changed, I just updated the parameter name. I'm going to go over existing comments in a later pass.  Including americaniZing the spelling.\n. Which one? \"The batch size can be changed even after a cursor is iterated...\"?\n. I'd be tempted to split this into two tests: \"shouldSupportTryNextOnTailableCursors\" and \"shouldThrowExceptionOnTryNextForNonTailableCursors\" or something like that.\n. Needed to prevent errors when checking javadoc from checkstyle.\n. Ignore Javadoc checks for client package\n. Ignore javadoc checks for Lazy* files which will be address in a different Jira\n. Made this private as it didn't seem to be something to expose (and document) to users.\n. As per Mongo/MongoClient, have removed all detailed usage from here to encourage people to use MongoCLientURI\n. Deprecation details are on the superclass\n. I dunno, I was surprised it was checked in, but since I changed it, it seemed only right to commit the changes.\n. Done.\n. Two reasons - 1) I stole this from the javadoc earlier in the file and 2) the standards suggest there's no need to use code on \"true/false\".  But since my inclination was to add @code, I have made this change.\n. Done.\n. Mmm, good point.  There is one, but it's not public.  I'll remove that line from the docs.\n. Should this be 'the response from the server' like it is in MongoException?\n. Is this the ID that the server identifies the cursor by?\n. This is not good practice, and might not work under java 8. Best to put the <p> tags around each paragraph.\n. Shouldn't this be 'if value is null'?\n. This is something that I could not find good documentation on. What exactly IS the scope?\n. 'as a primitive int'? Otherwise the two methods don't look different from the docs\n. 'as a Double\"\n. 'as an Integer'\n. 'as a Boolean'\n. 'as a primitive boolean'?\n. This is copied from 3.0.  This is not currently used in the build, but was used in development for tracking down missing documentation, and can potentially be enabled at a later date.\n. We had a checkstyle file, but checkstyle was never enabled in the build.  I disabled all the checks that were failing (most of them) and added the Javadoc checks,  This is still not enabled in the build (there's no way to turn off the check for deprecated methods and classes) but it gives us checkstyle settings which are close to being enabled should we want to.\n. I didn't do this comment as part of the last lot of documentation, it was already there from when Bulk was first implemented. But I can make the change in both places if you like.\n. It uses System.out and it's an undocumented public method. It's the same on 3.0 too, so I copied it over before I decided that turning on checkstyle was just not feasible.\n. According to IntelliJ, this method is not used.\n. According to IntelliJ, this method is not used.\n. Why do we still have some types in org.mongodb?\n. I'm not sure, but this is the documentation as it stands in the 2.x driver, I thought it was more detailed than the version in 3.x so I moved it over. I think it comes from the server documentation.\n. Done\n. It looks like it should, but getLogger is an abstract method, so this abstract class can effectively ask for the logger for any child classes. This is the only way to really do this.\n. Local is needed for the build to work correctly offline.  As I found out on the plane on Friday.\n. This gives us the \"provided\" scope without the complexity\n. Not needed if we have the groovy plugin\n. We can use this to fix our intelliiJ \"provided\" scope woes\n. Good catch.  Should be in all subprojects.\n. Hmm, I had thought that I tried that and it didn't work.  But that must have been a different problem as it works fine now.\n. The netflix \"provided\" plugin.  MavenCentral has an older version, 1.12.2, which doesn't work with gradle 2.0 which we are using.\n. The release version is in the build file.  However, it gets changed as part of the release process, the -SNAPHOT is removed from the version number.  This really interferes with Gradle, as it's already loaded the version number into the config and it's extremely hard to change this (I struggled with the same problem in Morphia, and did a massive hack to get it to work). The alternative is to do the release in several separate steps, instead of a single gradle task\n. In theory, you should be able to simply use git without the credentials if you've already set up your environment. Although I can [follow these steps] and successfully ssh to git, I cannot then successfully run a script which uses these credentials. I spent about 3 days trying to figure this out, before simply going with the credentials file as specified by the plugin.\n. A magic incantation, built in to gradle, which somehow means the default artifacts are published instead of the shadow ones. I have NO idea why this is different to artifact [something]\n. ",
    "agirbal": "this was merged into master, thx Guy\n. couldnt use patch as-is since the class was modified recently.\nfix is same as patch, but default value for keepalive is false. \n. thanks for finding this bug.\nI had to tweak a little so I did my own commit.\n. thanks the feature was ported to trunk\n. ",
    "daspilker": "has been merged\n. ",
    "erh": "Merged the comments.\n. merged\n. merged\n. Merged.\nNot the comparison was handled correctly so not a bug, but cleaner this way.\n. merger\n. Why do you think that?\nIt's not part of the key.\n. Looks good - merged.\n. We might want to do this later, but this is not something we want to do right now.\n. Well that means that everyone can agree on what a clean build is :)\nFor non-maven people, the current setup is closer to what they would consider clean.\n. Making bson.jar without mongo.jar should be done.  It does seem there is an issue there that we should fix.\nWe can even make testing for mongo imports part of the ant task to guarntee no deps slip in.\nAdded a case here: http://jira.mongodb.org/browse/JAVA-239\n. There are a number of major uses of the java driver who have voiced vigorous opposition to maven - which I fully appreciate.\nI think a driver should use the lightest weight tool possible.\n. Its on various mailing list, probably not jira.\nMostly that maven is very heavy handed, and for people who don't use it, its not a friendly interface.\nBy lightweight I meant easy for someone to checkout, build, etc...  no dependencies,\n. merged, thanks!\n. It looks like you are using different formatting ruies.\nCan you check that you're following the standard.\n. ",
    "mebigfatguy": "Ah I see. ServerAddress.equals handles InetSocketAddress.... Altho this is really a bad thing to do, as it breaks a primary rule of equality, namely symmetry..... InetSocketAddress.equals(ServerAddress) will always fail, but ServerAddress.equals(InetAddress) may succeed. I'd recommend removing that from ServerAddress.equals.\n. +1 for ant. I don't want that much black magic in my build tools.\n. Sorry, but i pull alot of open source projects. alot. Projects built with maven don't build around 80% or the time. Those that use ant don't build around 20% of the time. (OK these are unscientific numbers, but it is my personal impression). One would assume projects that chose maven do so because they like maven. Those that chose ant do so because they like ant. Therefore they are vested in having their projects and build tools work right. The fact that maven projects are so flaky (at least at start of project adoption) is not a good thing for new developer uptake. As for convention, sure as long as you stay on the straight and narrow, it will probably work. But when the project calls for any variance of any kind  you'll want to stab maven in the epiglottis (and your own). As a project grows, the chance of this grows as well. You always know with ant, you can easily make whatever you want to work, work.\n. The java compiler will replace += with StringBuilder, but kevin is right. His code only generates one new StringBuilder(), many append calls, and one toString call. Whereas, the a += ... generates 'n' new StringBuilder() calls, the same number of appends, and 'n' toString calls.\nCreates alot of garbage\nbtw kevin, the toString() call on the Integer is superfluous when calling append.\n. ",
    "trevorbernard": "Issue fixed with this commit: 916afd83f477a27769b2783702cf3f8fc27809b2\n. ",
    "nemtsov": "+1 Please merge these changes. It's really not possible to use the driver in an OSGi environment without hand-editing the manifest in the jar (adding the versions to the exported packages). I'm testing with Virgo, and can provide a simple client to test this if needed. \n. I just merged Neil's af38e1c1 to a branch made from the stable r2.6.3, and the driver works well in Virgo 2.1.1.\nThe only hassle is to manually update the version in mongo.bnd; but that's much easier than maintaining the manifest by hand.\n. +1 For either Bundlor or Bnd (pull 19; which will have to be included as well).\n. ",
    "koen-serry": "One thing I forgot, the code as is doesn't compile because of the reasons given above (Only if you combine both trees), \n. Euh, why do we want to do a clean build 'later'? If the driver of mongodb has some problems, why wouldn't we want to fix this right now (I'm even willing to fix it myself, provided that a decision can be taken) \n. I could care less if it's done in maven or ant, but it seems dangerous to me if we're building 2 'modules', but they can't actually be used separately. What's the point then of separating... \nA reason you might consider using maven, is that you create transparancy in the project (ant scripts can do anything, but no idea where they might be done) and therefor lowering the bar for new committers.\n. Why do you prefer to create/maintain something yourself that already exists (and is used by numerous other projects). I'm going to use this driver in production and I'd really like to contribute other things except for the build (like DBApiLayer that has a variable called 'D', com.mongodb.util.TestCase which seems to be a wannabe fork of junit,...). Maybe we should post these questions on the mailing list to ask the cummunity what they think.\n. I agree the java driver should be very light (and it is), but the build isn't related to the artifact it's producing. Can I ask what their motivation was against maven (is there an ticket of the sort)?\n. Seems to be a lot of FUD to me, found some references (http://jira.mongodb.org/browse/BUILDBOT-3) that seem to agree with me.\nAlso :\ngit clone ...\nmvn install\ndoesn't seem to heavy to me\n. That's exactly the reason to use maven. Ant lets you do whatever you want (screw up your dependencies, build all of them together, split them, whatever..) With maven you can't do that (well actually you can, but it's a lot harder) and this gives it exactly the transparency it needs. I suggest you take a closer look at maven before saying that it's black magic. It is a build tool 'by convention', not by depending who wrote it.\n. Ok, not starting any religious wars over here, if it's only a build system you need/want I just hope the code doesn't suffer from it (as well as the project I'm working on)\n. ",
    "bwmcadams": "In regards to the argument for ant vs. maven---most Unix-like systems install ant by default now, and typically not Maven.  \nFor this same reason we stuck with ant on the mongo-hadoop integration and only went as far as to add ivy to ensure dependency resolution.  Overall the size and complexity of a maven project file is vast compared to ant.\n. As for the ApiToolsTaglet, it is used to generate links to the official mongodb documentation through an @dochub Javadoc annotation.\n. Java's compiler automatically does this optimization for you since either 5 or 6, so not necessary.\n. I stand corrected. Ill reopen this shortly. Thanks for the clarifications as\nwell.\nOn Jul 29, 2011 8:33 PM, \"mebigfatguy\" \nreply@reply.github.com\nwrote:\n\nThe java compiler will replace += with StringBuilder, but kevin is right.\nHis code only generates one new StringBuilder(), many append calls, and one\ntoString call. Whereas, the a += ... generates 'n' new StringBuilder()\ncalls, the same number of toStrings, and 'n' toString calls.\nCreates alot of garbage\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mongodb/mongo-java-driver/pull/39#issuecomment-1686466\n. Can you please sync with master and send a single squashed commit? This patch, as sent, isn't cleanly mergable. \n. Unfortunately, any work we do on Domain Sockets will need to be standalone with no dependencies required for users not interested in the Unix Socket support.\n. \n",
    "bwaldvogel": "Eliot opened a ticket: http://jira.mongodb.org/browse/JAVA-287\n. ",
    "cmaitchison": "Lol, some backslash escaping affected my previous comment, making the two expressions in my comment seem identical when the second actually has double backslashes. The issue is that single backslashes in a regex are being serialized as double backslashes, and deserialized as double backslashes.\n. ",
    "nzrgit": "Merged into master.\n. Thanks for the work! \nWe would rather not include the Bundlor lib in the project. \nIs it possible to do this using the Ant Manifest task?\n. paoloditommaso - Just to clarify the changes Antoine made:\nhttps://github.com/mongodb/mongo-java-driver/commit/aa146fb7e69a7d0293fa35c4c7ca4f7ee005877f\n. Thanks Kevin for the cleanup!\n. Thanks for fixing this!\n. We are trying to get 2.7.0 out on Monday... but it may be delayed a little bit. Very soon :-)\n. Thanks for the patch. We will review this soon.\n. Ok... I reviewed the commit. \nThere is an issue where it only calls close inside of a conditional. \nAdditionally, since you can construct a GridFSInputFile with an InputStream, it is really the callers responsibility to close the intput stream object. It would be presumptuous for us to close it.\nThe problem is when the driver constructs the InputStream object, it is definitely not being closed.\nWe are going to investigate further, but thank you for calling this to our attention!\n. FYI - I have created the following bugs:\nhttps://jira.mongodb.org/browse/JAVA-463\nhttps://jira.mongodb.org/browse/JAVA-462\nIf you would like to follow the status, you can click \"Watch\"\nThanks again for your help!\n. I agree... but if someone passes in an inputstream, they theoretically do something else with it (you can rewind an inputstream depending on what it is backed by - e.g., FileInputStream). As odd as that seems... it is something to consider.\nTypically, if you don't open it, you shouldn't close it (at least from a driver perspective).\nI could be mistaken, but I thought the close was inside the block:  if (!_savedChunks) {\nThe save won't fail... it is just messy.\nMore than likely, the solution we will take is if we opened the input stream in the driver, we will close. If it is passed by the user, it is their responsibility to close. The javadocs for the class definitely need to be updated to reflect this.\nIf you want to try piecing this together, we welcome the help!\n. Moving discussion to: https://jira.mongodb.org/browse/JAVA-462\n. My mistake... the api is still ok.\n. Hi Jon,\nThese are not interfaces we want to expose and will likely change in the near future.\nCan you please get in touch with scott @ 10gen (email address) to discuss what you would like to do (to make sure we cover your needs in the 3.0 driver).\nThanks,\n-Ryan\n. Hey... thanks for the patch.\nDo you think we should also change the setChunkSize method so that it throws and exception if the following is true?\nif (_outputStream != null || _savedChunks)\n        return;\n. Thanks :-)\n. This cursor should be in a try/finally block with an explicit close. If you are able to successfully iterate through all of the documents in the cursor, it is automatically closed. However, if there is an exception while iterating, you will leak a cursor.\n. Ha... thanks so much! I have not been following this section of the code so I was not aware of what changes have been made recently.\n. ",
    "ractive": "Am 14.06.2011 20:05, schrieb rgnitz:\n\nThanks for the work!\nWe would rather not include the Bundlor lib in the project.\nIs it possible to do this using the Ant Manifest task?\nJust using the manifest task is not sufficient, no. Bundlor creates the \nmanifest on the fly by analyzing the code and the config files.\nThe bundlor libs must not be included in the project, but people \nbuilding the driver must install them in their $ANT_HOME/lib folder. \nAdding some libraries in ant's lib folder would also be required when \nusing bnd or other OSGi manifest generation tools.\n. \n",
    "philwills": "The reason I avoided that was because the current implementation of equals doesn't use the db and my main aim was to make the two consistent. I can see arguments either way for doing it in both or neither, but I definitely think it should be consistent between the two and this was the minimal change for that.\n. Just as a note, I finally got a chance to have another look at this and Scott's suggestion of making the DB part of the equality hash-code contract.  Unfortunately DB currently uses the default object identity for equality and I don't think that would make a whole lot of sense to integrate into the DBRef equality, but I'm also not convinced there's a better choice of how equality should be defined for DB, so I'm leaving it alone for now.\n. ",
    "jyemin": "Look like this was addressed in https://jira.mongodb.org/browse/JAVA-612.\n. http://jira.mongodb.org/browse/JAVA-475 was closed in 2.8.0, and it looks like these changes were incorporated into the release (see the commit log on the issue).  I'm not sure why this pull request was not simply merged, but instead re-applied by hand.\n. I consider logger name changes to be backwards breaking, so tabling this until 3.0 release.\n. While I appreciate the brevity, it would be too confusing (and harder to maintain) to have two classes with the same semantics.  \nPlease feel free to submit pull requests with enhancements of the existing QueryBuilder class.\n. There's a problem with this.  ClassMapTest fails here:\nhttps://github.com/mongodb/mongo-java-driver/blob/encoding-concurrency/src/test/org/bson/util/ClassMapTest.java#L41\nThe problem is that any cached ancestry mappings have to be reset whenever a new mapping is added to the map.  Otherwise, you can get incorrect results, as the test illustrates.\n. Not sure.  It fails for me:\nnew-host-3:mongo-java-driver jeff$ ant test\nBuildfile: /Users/jeff/fresh/mongo-java-driver/build.xml\n...\n[testng] [TestResult: test STATUS:2 METHOD:org.bson.util.ClassMapTest.test()]\n   [testng] Exception : \n   [testng] -[Object] != [Serializable] -\n   [testng]   com.mongodb.util.MyAsserts._assertEquals(MyAsserts.java:99)\n   [testng]   com.mongodb.util.MyAsserts.assertEquals(MyAsserts.java:82)\n   [testng]   org.bson.util.ClassMapTest.test(ClassMapTest.java:41)\n   [testng]   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) (with others of java.lang.reflect.* or sun.reflect.* omitted)\n   [testng]   org.testng.internal.MethodHelper.invokeMethod(MethodHelper.java:580) (with others of org.testng.* omitted)\n...\nBUILD FAILED\n/Users/jeff/fresh/mongo-java-driver/build.xml:244: The tests failed.\n. Love the graphic.\nOn Fri, Feb 3, 2012 at 11:22 AM, Richard Wallace <\nreply@reply.github.com\n\nwrote:\nGood news, everyone!  This solves our contention issues in ClassMap, but\nnow we have contention elsewhere\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mongodb/mongo-java-driver/pull/58#issuecomment-3799382\n. Hi.  Can you provide your benchmark in a comment or gist?\n. The benchmark code.  I understand you can't provide your application's source code, but can you create a small benchmark program that demonstrates the effectiveness of this change?\n. Registration of both beans would be better, perhaps by including the Mongo instances identity hash code, or something else unique, as part of the bean name. Since the bean is a management interface for the connection pool owned by a Mongo instance, it doesn't make sense to include one instance over another.  The problem with this is that it makes the bean name unpredictable and so more difficult to automate monitoring of.  But I still think it would be better than the current behavior.\n. By the way, what's your use case for having multiple Mongo instances referring to the same mongo server?\n. This kind of makes sense, but it does surprise me.\n\nBy the way, the driver already provides a simple map of MongoURI to Mongo in the com.mongodb.Mongo.Holder class.\n. Found further evidence: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6321873\n. Can you redo the pull request without ManyMongoTest?  I don't think it's necessary to have it.\n. Thanks for the fix.\n. Looks like this has been addressed in https://jira.mongodb.org/browse/JAVA-488.  Sorry for the late response.\n. My apologies, but the code has changed too much since this pull request for it to be merged.  Specifically, all the MongoURI functionality is all moved to MongoClientURI.  \nAlso, note that it's not ever a good idea to only mention one member of the replica set in the URI, which is why I don't consider this change to be all that crucial.  Still, I would like to see it implemented at some point.\n. Thanks for the pull request.  Would you mind putting your test code to com.mongodb.gridfs.GridFSTest#testInputStreamSkipping and adding it to the pull request?  Thanks.\n. While I like this change, NetworkInterface.getHardwareAddress() was added in Java 6, and the 2.x Java driver needs to work on Java 5.\nThere is an issue for this in Jira: https://jira.mongodb.org/browse/JAVA-586.  I set the fix version to 3.0.0.  When we have a branch for 3.0.0 in git, perhaps you could re-open this pull request against it. \n. I think the expectation should be that the DB is authenticated without using the MongoURI.connectDB method.  Rather, Mongo(MongoURI) constructor should take care of it.  I'm going to give that a try on top of the changes I recently made for JAVA-682\n. Can you add some tests to GridFSTest?  Thanks.\n. It looks good, I just need a bit of time to review it thoroughly.  Thanks!\n. Thanks!\n. Requested a small change to a conditional.  Let's see if the Travis build succeeds after the change.\n. Code looks good, but please re-open with the three commits squashed and the Jira issue as the prefix of the commit comment.\n. Hi Louisa,\nI'm going to close this without merging. Please submit a new pull request with all these commits squashed into a single commit, and please reference the jira issue number in the commit message, e.g.  \"JAVA-746: Added support for comments in JSON parsing...\"\n. Sorry to be a bother about this, but can you open a new pull request without the merge commits.  Those will happen automatically anyway when I merge.\n. Thanks for submitting this.  I merged this onto a local branch and will push it to master manually.\nRegards,\nJeff\n. Thanks for finding this problem.  I'd definitely like to address it, but the fix you propose looks to bury the problem by returning false rather that returning the correct result.  If you can determine the root cause of the connector being null, we can work together to fix that.\n. I suspect this will just be the tip of the iceberg, and really the problem is that Mongo, DB, and DBCollection are all inter-dependent through package-protected methods and even fields, so anything we do will be quite brittle.\n. The problem with going in this direction is that isMongosConnection is a method we'd like to remove in the long term, not make more visible.  Have you had success mocking DBCollection itself?  This is what people typically want to mock, as it is the class with the CRUD operations\n. Thanks.  I'm going to close this then, but please keep in touch if you encounter issues that you can't resolve.\n. The problem with this approach is that it every operation now has a second network hop.  It's way too expensive to have as a default.  A better way would be with a background thread and a configurable timer to indicate how often to check each socket.\n. Although Travis CI build did pass, I'm going to close this one without merging. :)\n. This looks good, but I prefer the solution proposed by agrinevsky, and opened https://jira.mongodb.org/browse/JAVA-836 to track it.  Feel free to open a new pull request for that.\n. Merged locally and pushed to 3.0.x\n. It's not clear to me why you would use MongoClientOptions at all if you are creating your own Cluster.  The intent is for it to be used along with MongoClient.\n. That's a good idea.\n. I suspect there is a more elegant way of accomplishing this.  What are you overriding in your GridFS subclass?\n. This pull request is not done correctly.   If you'd like, you can just attach a patch file to the Jira issue instead.\n. See https://jira.mongodb.org/browse/JAVA-1081.   Based on pymongo, I would prefer to use a different algorithm: find the first document in the errObjects array that has an err field equal to the top level one, and grab the code from there.\nWould you like to take a stab at fixing it that way, or shall I close?\n. The underlying issue was fixed in scope of https://jira.mongodb.org/browse/JAVA-1081, so I'm going to close this.\n. Merged\n. Merged\n. Hi Arthur.  We're in a code freeze now until 2.12.0 ships and after that we won't be making any Javadoc changes until the next release (3.0).  Please consider applying this change to the 3.0.x branch instead.\nThanks,\nJeff\n. Hi Arthur,\nI'd like to consider this change in the 3.0.x branch, as we are currently in a code freeze for 2.12.0.  Please consider opening a pull request on the new branch.\nThanks,\nJeff\n. Normally that's what we do, but for the last six months or so we've really had two versions in active development: 2.12 and 3.0: the former is on master and the latter is on the 3.0.x branch (which really should have been named 3.x).  Once 2.12 is stable its development will move to a 2.12.x branch and 3.0.x will be merged into master.  Does that make sense?\n. This has been merged but since I rebased it's not showing up that way.\n. This has been merged but since I did some rebasing it's not showing that way.\n. A few more inline comments.\nI pushed some other changes to my fork as well: https://github.com/jyemin/mongo-java-driver/commit/45b8238c1ae4beeb4a9d98829324004b3fab515a\nAlso, I still don't think we have the same formatting.  With what I have, everything lines up under the paren, e.g.\n    int x = foo.bar(1, 2, 3,\n                            4, 5, 6);\nNot sure why you're not picking that up.\n. Merged after rebasing.\n. I don't think an automated test for this can be written with the way the code is organized.\n. I merged this into the 2.12.x branch, not master, so it didn't automatically close.  Thanks for finding this.\n. Just a few small things to address, then it can be merged.\n. Rebased and merged.\n. Rebasing and merging\n. The new binding is ok for testing, but will need some work for production to make it truly async. As it is now, the calls to getServer and getConnection are blocking. However, that's true for AsyncClusterBinding too currently, so let's leave it like this and fix them both together.\n. My sincere apologies.  We recently merged the 3.0.x into master, and on deletion of the 3.0.x branch all the pull requests were summarily closed.\n. Does https://github.com/mongodb/mongo-java-driver/pull/199 supersede this?\n. Closing.\n. Added https://jira.mongodb.org/browse/JAVA-1476 to track this.\n. Have you looked at the Travis failure?\n. For why not to use Cloneable, see http://www.artima.com/intv/bloch13.html.   Copy constructors are a better alternative.\n. Unless there is a compelling reason, a copy constructor is more common:\npublic Document(Document from) {...}\n. Feel free to merge this in to 2.12.x branch.\n. Hi Tugdual,\nSorry!  This was a mistake.  When we merged 3.0.x into master and deleted the 3.0.x branch, all the PRs on 3.0.x were closed automatically and I didn't notice this one.\nSo, can you re-open on master please?  Also, there is a new Filters class that replaces QueryBuilder in the new CRUD API, and it doesn't have Geo support yet either.  I'd like to get Geo support in there as well.\nRegards,\nJeff\n. @rozza next change is to change all existing BSON/JSON-prefixed classes to Bson/Json\n. Capitalization of files is messed up.  Closing and opening a new one\n. Looks like Travis failed.  Haven't looked for the cause of it.\n. For AsynchronousSocketChannelStream I'm not sure either.  Report a JIRA on it for now so we don't lose track of it.\n. lgtm except for the one comment.\n. Looks like FindBugs found a problem.\n. lgtm\n. Handled everything except \n1. Unused methods in BsonReader/BsonWriter (this is not a new situation, so to be fixed later)\n2. Bson prefix on ObjectId, Timestamp, Undefined, etc.  I'm not yet convinced about this, so putting it off for a bit.\n. I\u2019m not 100% certain if BsonTypeClassMap belongs in driver or bson, although I think there are arguments for both\nIf we end up moving Document into bson, then this will move to.\nThere are two CodeWithScopeCodec classes?  One in driver and one in bson? \nCodeWithScope is annoying because you need one for each type of document to use for the scope.\nI\u2019m still not sure about the name \u201cCollectibleCodec\u201d, particularly as there\u2019s no such thing as a Collectible.  And if there were a Collectible, I think that would be the thing that\u2019s responsible for creating the ID, not the codec - currently a CollectibleCodec violates the Single Responsibility Principle, as it\u2019s responsible for generating the ID and serialising the document.  \nThis was the result of long design discussions with the .NET team.  We started with the .NET driver design and simplified it.  The alternative would be to have a second registry of IdGenerator<T>, which seems worse.\nDocumentCodec: there\u2019s missing Javadoc for the IdGenerator param in the constructor;\nfixed\nDocumentCodec - now I remember why the ID stuff is on the codec, because of what you need to do to get non-BsonValue IDs out.  Still feels like a smell, but I can\u2019t think of something better to suggest without introducing the concept of two types of documents, a collectable one and one without an ID\nI'll consider this closed.\nDocumentCodecSource: I assume we only support lists and not arrays or other Iterables? And what about Maps?\nCorrect.  It only supports List and Document.  I don't see why we should do more unless asked and given a really good reason.\nEncodingException doesn\u2019t seem to be used\nDeleted\nIn some of the codecs, you have:\nregistry.get(bsonTypeClassMap.get(reader.getCurrentBsonType()))\nI think I can see why the class map is separate to the registry, but it feels like a bit of a smell to have three \u201cget\u201d methods there, it suggests we\u2019re not doing \u201ctell don\u2019t ask\u201d since we\u2019re asking for three things.  The registry doesn\u2019t have to have a BsonTypeClassMap (I can see why it wouldn\u2019t), but maybe you could have a method on it: get(BsonType, BsonTypeClassMap) which encapsulates this functionality, since I assume it\u2019s going to be reproduced in most of the codecs.\nI don't agree that the CodecRegistry should know about the class map at all.  The only codecs that need a class map are the ones with open type systems: DBObject and new Document.  It should not be needed by a ClassModelCodec.  It's not needed by BsonDocumentCodec.\nPatternCodec is missing Javadoc\nadded\nServerStateNotifier: getString() and listToSet() look like utility methods that belong somewhere else - maybe a helper class, or maybe on BsonDocument itself.\nIf they go somewhere else, they have to be public, and I don't want to make them public.  And I don't want to create methods on BsonValue or BsonDocument that return any types that are a BsonValue, as that will result in an explosion of methods and method names.  In this case we would need BsonDocument.getBsonString(key) and BsonDocument.getString(key), and so on.  In practice I don't expect normal Java programmers to be using BsonDocument directly.  They will either use Document or a POJO.  So I didn't worry too much about making BsonDocument/BsonValue particularly friendly for Java programmers.  It's possible that we can define Scala or Groovy extensions that make these class easier to use (as in .NET).\nAggregateHelper.asBsonArray also looks like a util method that belongs somewhere else\nsame as above\nAggregateOperation constructor missing javadoc\nadded\nOperationHelper.getBsonDocumentCodec() - not entirely sure this is necessary, since it just news up a new Codec.  However, if it is necessary so it\u2019s just one central place for creating new codecs, it should probably be in a factory not some random util class.  \nremoved\nIn fact, I\u2019m not really keen on CommandOperationHelper at all, it seems like a bit of a dumping ground for stuff which suggests some missing concept somewhere, but it\u2019s not a problem for this pull request.\nThe other option I can think of is to introduce AbstractCommandOperation as a base class to all command-based operations.  I think you would like that even less.  I think of these like extension methods in languages, like .NET, that support such a concept, and the static imports make it appear like that.\nBaseUpdateRequest: doesn\u2019t need the checkstyle suppression any more\nFindAndModify: doesn\u2019t need the checkstyle suppression any more\ndone\nGroupOperation: param T javadoc missing\ndone\nMixedBulkWriteOperation: javadoc missing for constructor params\n   done\nRemoveRequest: doesn\u2019t need checkstyle suppression\n    done\nUserExistsOperation: line 93 can be simplified\n   simplified\nGetCollectionNamesOperation: line 62 can be simplified\n    simplified\nUserOperationHelper: I preferred chaining \u201cappend\u201d methods rather than multiple \u201cput\u201d calls, but that\u2019s just a style thing\nRequestMessage: why does this have a static BsonDocumentCodec when in other places (like the OperationHelper) create new codecs on demand?\n   inlined\nStorageDocumentFieldNameValidator: why do we talk about a Storage \nDocument here, and yet have a CollectibleCodec? we need to standardise on names\n  Renamed to CollectibleDocumentFieldNameValidator\nProtocolHelper lines 58, 133, 140 can be simplified\n   done\nWriteCommandResultHelper has a lot of \u201cget\u201d calls that can be simplified to remove casting\n  done\nWriteResultCallback: checkstyle suppression not needed; ordered field can be final\nCodeWithScope: there\u2019s a a bson one and a mongodb one, is this necessary?\n   Unfortunately yet.\nAllPrimitiveTypes is no longer used\n   deleted, along with all other classes in that package\nDocumentCodecSpecification: I uncommented the DbPointer stuff and the tests still worked, so I assume we can add that back in again?\n   it's back\nStorageDocumentFieldNameValidatorTest: could be a Spock test.  Just sayin\u2019\n   that's a different PR\n. Feedback for changes to driver-compat module:\nQuestions/suggestions:\n- There\u2019s a BSONTimestamp and BSONTimestampCodec in driver-compat? Are these needed?  If so, they also need the new capitalisation applied\n  Would be nice, but can't change it without breaking binary compatibility with 2.x\n- BulkWriteOperation does ID generation?  I thought CollectibleCodec did that?  And DBObjectCodec does have an ID generator\n  This is sad, but necessary.   2.x treats a DBObject with {_id : null} as a document without an _id, though according to spec BSON Null is a valid value for an _id (though there can only be one per collection...).  I would like to change that, but it will break many apps and frameworks (like Morphia), which set _id to null and rely on the driver to generate an _id.  So the compromise I made was to have DBCollection still handle _id generation in the way it always has, but have DBObjectCodec do it the right way.  That way, if someone creates a MongoCollection, _id generation will work exactly as it does with MongoCollection: an id will only be generated if the _id key is entirely absent.\n- DBObjects: now this is a useful codec util, maybe it belongs somewhere codec-shaped (and could be renamed to something more useful?)\n  I'm open to suggestions.  I couldn't think of anything, and didn't worry about it too much because it's not public.\n- What\u2019s DBObjectFactory?  Does the functionality that\u2019s still in DBObjects belong somewhere in an implementation of this?\n  DBObjectFactory is something that's relevant only in the context of decoding DBObject in a DBCollection (It encapsulate the objectClass in DBCollection.setObjectClass()).  It should not be needed in DBObjects.\n- DBCursor min() and max() are missing javadoc for params\n  Not relevant to this code review.  I'll put in on the list.\n. Ready for final review. \nAn update on adding Bson prefix to all BsonValue subclasses: I have that done in a separate branch, but let's review it separately as it's quite a lot of changes.\n. Merged manually after rebasing\n. If they stop mid iteration, the driver discards the remaining responses on the wire via the GetMoreDiscardProtocol\n. Yes\n. Yes\n. Before I go further with the review, let's resolve the design issue that is of concern to me.\n. Rebased and merged.\n. I see why it didn't error, but it's still incorrect, as by calling writeResult.isUpdateOfExisting it's forcing a getlasterror to be sent to the server, which is not what we want to happen.\n. lgtm\n. 1. No conclusion for 3.0.x but we're leaning towards a BsonWriterSettings.preserveNumericTypes with a default value of true.  Also leaning towards having only two output modes: JSON and SHELL, but we can leave that for another PR.\n2. Tests in the 3.0.x branch?  2.12.x can't get any new APIs but we can add methods in driver-compat for 3.0 if necessary.\n. I'd actually like to push the changes involving removal of TEN_GEN and JAVASCRIPT.  That's still valuable, even if we wait a bit for $numberLong\n. @rozza do you want to close this?\n. lgtm\n. @craiggwilson check out JAVA-1252 commit, as it has some design changes that .NET driver may need as well.\n. Merged into 3.0.x\n. The ObjectId class has changed substantially in master since this was submitted.  Any interest in trying to re-apply your changes to the latest on master?\n. $query should not be supported.  lgtm\n. Hi there,\nDo you already have a use case for this?  One issue that I see is that these contexts are in most cases created way down inside the bowels of the driver, so it's not clear how a third party could ever add additional information to the contexts.  There would have to be a setting of some sort exposed higher up the stack.\nThanks,\nJeff\n. I'd still like to see a more realistic use case for this before we pull the trigger on it.  We've thought about how to build a POJO Codec and didn't see a need to extend the capabilities of the encoder or decoder contexts to do it.\n. Glad to hear that you figured a way to do this in your Codec implementation.  It's what we've found as well and  I hope that will be the case for others.\nI'm going to leave this open for now in case we decide to do something in the future, but not merge it at this point\n. It's historical.  Even before this commit,  the driver's packages have always been prefixed with com.mongodb but the Maven groupId has always been org.mongodb.. I see why this would be useful, but not in isolation like this.  Rather, I'd prefer it be done in the context of https://jira.mongodb.org/browse/JAVA-805.  In addition to the observer pattern described in that ticket, I can envision a method on MongoClient like:\nClusterType getClusterType();\nor even\nClusterDescription getClusterDescription();\nI'd prefer that to forcing users to call the ismaster command themselves.\nRegards,\nJeff\n. Understood.  I still maintain that it will be better long term for MongoClient to depend on ServerType/ClusterType rather than introduce a dependency in the other direction.\n. It's worth it, yes, to write a unit test.  I see what you mean about an integration test though.  There are no side effects, so the only test you could write would be to m/r over a huge collection with jsmode true and assert that it blows up.\n. This pull request doesn't compile, and when I fix the compilation errors many of the tests fail.  Is there perhaps a better-working version?\n. Looks good.  Only thing I noticed is that MongoCredential is missing @since tags.  I added them to master and 3.0.x just now, so please rebase and add @since 2.13 for the Scram-related public API methods and fields\n. lgtm\n. Response to general comments:\n- Those classes will be replaced,\n- The spec was very cleverly written to allow a variety of styles including options classes like this.  After trying both styles, I felt that the user experience was better with options classes, as it allows use of collection methods that don't require any optional parameters to avoid having to use models.\n- What do you mean by \"in use\"?  In the tests?  In practice I expect people to use anything from BsonDocument (for type safety lovers) to Document to DBObject, to custom classes like Criteria or Sort or Projection which provide domain specific APIs for those use cases.\n- Again, the spec does allow this.  An empty find() is fine because it allows specification of all required model properties, which in this case is none.  The spec does not allow overloads based on different combinations of optional properties, but this is ok.\n- I don't actually think Operation is all that inconsistent with the models.  Like the models, required parameters are included in the operation constructor, and then optional parameters can be set in a fluent style.  The only difference is that it's combined into a single class instead of split as in the model classes.  In any case, actually users will be using one or the other so won't really notice the inconsistency. \n. The text needs to be update per my line note.\n. That commit only addresses one occurrence, but it applies to everywhere that it says that, e.g. DBDecoder, DBDecoderFactory, etc.\n. A few nits\n. lgtm\n. Please squash the second commit.\n. Please reference JAVA-1406 in the commit comment\n. lgtm\n. A few comments, but otherwise LGTM\n. I'd like you to review all the links to make sure that they are to MongoDB server documentation if at all possible, rather that shell-specific API docs.  I cited a few examples, but I'm sure there are more.\n. The links look good with the exception of the bulk write ones.  I made some suggestions for non-shell docs to link to.\n. A few nits, but otherwise LGTM\n. Pushed fixes for everything and closing\n. Merged on the command line.  Thank you Robert!\n. lgtm\n. Merging on command line\n. lgtm\n. @craiggwilson I moved Document to org.bson.types to sit alongside Objectid, Binary, etc.  But it could go in org.bson instead alongside BsonDocument and the old BSONObject interface, which Document is intended to replace.  Would that be preferable to everyone?  It's starting to make more sense to me as i think about it.\n. Moved Document to org.bson\n. Merging on the command line\n. I didn't go over it with a fine toothcomb as I assumed it was mostly a straight copy of what's already been reviewed.  I notice a few things that should be addressed, but overall looks great and will be very helpful to our users and support staff.\n. lgtm\n. A few requests, otherwise LGTM\n. lgtm\n. Rebased and merged\n. The problem with this fix is that at any time the cursor id in the QueryResultIterator can become 0 without the cursor being closed, in which case the finalizer should not add the cursor to the dead cursor list. This happens naturally when the cursor is exhausted (the last batch will return a cursor id of 0).\nI put up a PR for an improved fix in the 3.0.x branch at mongodb#272. The same technique can probably be applied here.\n. I'd consider it for 2.13.0.  Do you want to try to patch this PR, or leave it to me to deal with?\n. it would be on master\n. I think the intent would be clearer if this was coded more in the style of https://github.com/mongodb/mongo-java-driver/pull/272. \n. I don't think so, since the OptionalFinalizer can be mutable.  I gave it a go here: https://github.com/jyemin/mongo-java-driver/commit/74ba7bfd9e39b73b1ab1e7b14cee553487e21fe5\n. OK, I'm going to close this and open a PR with my commit.  Thank you for bringing this to our attention.\nJeff\n. Rebasing and merging on the command line\n. LGTM, but please try to avoid mixing extensive formatting changes with behavioral changes.  It makes it hard to find the latter when there is so much more of the former.  At the least, the formatting changes  should be separated into different commits.\n. Thanks Nick.\n. Overall looks good.  Just had a few questions and comments.\n. One problem I see with the uber jars: it's pulling in the netty class files too.\n. Do you see a way that we can publish more than one artifact per project, one shadowed and one not?\nI think that the default jars that we upload should not embed the contents of their dependent jars, and for those that we decide to embed, we should have that be a separate Maven artifact, e.g. mongo-java-driver-ALL.\n. Can you characterize the brittleness more precisely?  What sort of problems have you run into?\n. Things I saw pushing a snapshot:\n1. The artifactId of core changed from driver-core to mongo-java-driver-core.  What was the reason for that?\n2. -all jars are for every project (even bson), and don't produce pom, javadoc, or sources, making them not very useful.  We should disable until we get it right.\n3. The dependencies in the published pom, say from core to bson, are runtime rather than compile.  I'm not sure if this matters though, but please find out\n4. The dependencies on netty and slf4j should be optional:true rather than scope:provided, according to http://maven.apache.org/guides/introduction/introduction-to-optional-and-excludes-dependencies.html and http://maven.apache.org/guides/introduction/introduction-to-dependency-mechanism.html#Dependency_Scope.\n5. The OSGI manifest entries are not correct.  No exported packages, unnecessary imported packages.  Can we use the osgi plugin?\nBy the way, I found it useful to replace\nurl 'https://oss.sonatype.org/content/repositories/snapshots'\nwith \nurl 'file:///tmp/snapshots'\nfor local testing.  Otherwise we risk pushing bad snapshots to Sonatype.\n. There were a few things that didn't work properly in this pull request.  In particular, it didn't properly sign all the artifacts and Sonatype rejected the upload as a result.  I was unable to get signing to work properly with a multi-project Gradle build using the new Gradle publish plugin.  The only way I got it to work was using the old nexus plugin.\n. Steve, \nThis will definitely be useful to us, but will have to leave it on the back burner for a bit, as we are working on a new cross-driver GridFS spec, and I don't want to add any new GridFS APIs before that spec is finalized.\nAlso, definitely need some tests ;)\nJeff\n. Apologies for closing this PR on you summarily.  I didn't predict the ramifications of deleting the 3.0.x branch after merging it into master, which is that all the PRs on 3.0.x are automatically closed.  \nCan you please re-submit against master?\n. Initial review complete.\n. lgtm\n. As this issue is now fixed in master, which will be released as 3.0.0 soon, I'd like to forego this pull request.\n. Can you add a test to show what you're trying to achieve here and prove that this is a correct solution? \n. Thanks for providing the extensive context.  Can you open an issue in Jira that we can link this to as well as add a test case?\n. I think you're on to something.  \nI added Update last night, and since it required the same render method as Filter, I created a Renderable interface with that single method, which both Filter and Update implement.\nSo what if we just make all the types Renderable instead of Filter, Update, etc, and then make Document, BasicDBObject, BsonDocument implement that type, and have all the builder methods return that type?  That way we don't need any wrapping for the types we support, and third party libraries that want to produce Renderables can either implement the interface directly or provide a wrapper, as is done in the Filter class here.\nAs is usually the case, the biggest problem is naming.  I was ok with a render method since no one really sees it, but Renderable is just an awful name to sprinkle everywhere.  In an earlier iteration of MongoCollection, we had a ConvertibleToDocument marker interface, which is more descriptive, but ConvertibleToBsonDocument is surely a mouthful. \n. rebased and merged\n. Rebased and merged, minus the Filters class, which I'll commit separately after it's completed\n. rebased and merged\n. @craiggwilson can you review too\n. @craiggwilson fyi\n. Re-opening on a different branch\n. Added a few new sections for Codec, BsonReader/Writer, and CRUD.  I haven't added all the apiref links yet.  I'll do that after getting approval on the content.\nAlso read through all the pages once more in order and fixed problems that I found along the way.\n. Rebased, merged, pushed\n. OK, closing this out then.  Thanks.\n. cc @craiggwilson @rstam \n. - I find the CRS parts confusing - why only 3 named systems?  Do we support different CRS systems, Does it impact storage internally and can you use multiple systems and query them?  Very confusing.\n  - Those are the three named systems that I found supported by the server.  The CRS names are stored by the server, but the only one that has any different effect from the default is STRICT_WINDING, and that one is only allowed on a query filter, not for stored documents.  And it does change the semantics of the query, according to the documentation.\n- I found some error message to hard to decipher so suggested alternatives.\n  - Will take a look\n- Groovy files seem to be missing newlines - you might want to tweak intellij to auto add on save.\n  - Found the setting and changed it.  Will fix.\n- Also, its much easier to use multiline strings rather than concatenate them in the tests ;)\n  - I did it this way because those strings were copied from our documentation, and IntelliJ added the newlines automatically\n- Missing documentation!\n  - Aware :)\n. Addressed all comments except for reference documentation.\n. Added reference documentation of the Filters builder methods, include geospatial methods.\n. Do you mean that you can do:\nand(new Document(\"field\", new Document(\"$crazyOperator\", 1)...)\nand it will just send it to the server as is?  This will only happen if you leave the Filters world, and I don't show any examples of that yet.\n. In that case why not leave it as is?  Either way, the user will get an error reported, just by the server instead of the driver. \n. Rebased and merged.\n. Florian,\nI posted a comment on the ticket about JsonWriter, as well as $numberLong.  Feel free to tackle those as well.  Generally, JsonReader and JsonWriter should comply with the documentation here; http://docs.mongodb.org/manual/reference/mongodb-extended-json/\nThanks for the report and the pull request.\n. I found a few more things when I brought it into my editor:\n- If you run ./gradlew check, you'll see that Checkstyle fails due to the * imports, which we disallow.\n- Please change the exception message for the fist JsonParseException to say something like: \"JSON reader expected an ISO-8601 date string but found '%s'.\"\n- Please add a test for the exceptional condition where the date is in an invalid format\n- Please change the exception message for the second JsonParseException to say something like: \"JSON reader expected an integer or string but found '%s'.\".  Extra credit if you add a test for that branch too, which I noticed we missed.\nPlease also squash the commits at the end, as that's our practice.\nThanks,\nJeff\n. It looks great.  Merged to 3.0.x and master.\nThanks!\n. Hi Steven,\norg.bson.types.ObjectIdTest#testHexStringConstructor is failing with this patch\n. Hi Steve,\nApologies for not asking for this sooner, but would you mind submitting a Jira issue for this and referencing the issue number in the commit message? \n. Reported this as a bug at https://jira.mongodb.org/browse/JAVA-1792 and merged on the command line after amending the commit to change the name of the test and add the Jira issue number to the commit log.\nThanks so much for finding this.\n. LGTM after the obvious squashing is done.\n. Have you looked to see why Travis is failing?\nOverall, I like the direction but before we go off to the next chunk of work there needs better test coverage of what's in this one.\n. Yes, unrelated.\nOn Fri, Jun 26, 2015 at 4:04 AM, fzhinkin notifications@github.com wrote:\n\nHi Jeff,\nseems like OOME that caused org.bson.GenericBsonTest::shouldPassAllOutcome\nfailure does not relate to my change, is it?\nThanks,\nFilipp.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/320#issuecomment-115567694\n.\n. Initial review complete.  I'll merge as soon as the comments are addressed.\n\nThanks,\nJeff\n. Since I haven't heard back from you in a while, I went ahead and made the changes that I suggested, and pushed to master.\nThanks!\n. Closing this, as we're not ready to pull the trigger on this work.\n. Thanks Matthew!\n. Much obliged.  Thanks!\n. I tried this out on the test site, and I'm seeing some strange behavior relative to http://mongodb.github.io/mongo-java-driver/3.0/.  On the latter, if I reduce the width of the window and then increase it again, the left nav disappears and then returns.  On your branch it mostly disappears (except for a sliver) but then never returns.\n. What behavioral difference should I see now?\n. lgtm\n. One thing missing: writeConcern should be supported in DBCollection as well for all the findAndModify helpers.\n. Initial review complete.\n. lgtm\n. Thanks for the sharp eyes.  Keep 'em coming if you spot more.\n. Using apiref, but the internal links like WriteConcern#ACKNOWLEDGED don't work.  I can't remember why...\n. I'm not going to mess with 2.x javadoc generation now, so I think it's best to revert the change to use apiref.\n. Please also refer to the related Jira for a Jackson-based Codec: https://jira.mongodb.org/browse/JAVA-1314\n. Looks like this PR was opened in error.\n. Thanks for the close read and the pull request.  Keep 'em coming as you see them.\n. Your branch is 3519 commits behind master.  If you'd like to submit a pull request, please do so from the tip of master, and please first report a bug in our Jira project at https://jira.mongodb.org/browse/JAVA describing the issue you're trying to solve.\n. The failures are due to Checkstyle issues in ConcurrentPoolTest:\n[ant:checkstyle] /home/travis/build/mongodb/mongo-java-driver/driver-core/src/test/unit/com/mongodb/internal/connection/ConcurrentPoolTest.java:26: Using the '.' form of import should be avoided - org.junit.Assert..\n[ant:checkstyle] /home/travis/build/mongodb/mongo-java-driver/driver-core/src/test/unit/com/mongodb/internal/connection/ConcurrentPoolTest.java:70:31: ',' is not followed by whitespace.\n. One issue with the change is that it doesn't interact well with the maxConnectionIdleTime setting, which is sometimes used to handle short-term connection spikes.  It lets the connection pool temporarily expand to its maximum allowed size during a spike, and then shrink back down to its minimum allowed size as load decreases and connections are idle. But this relies on the connection pool being treated as as LIFO queue rather than a FIFO queue.  Otherwise, all the connections are cycled through and none are ever idle for long, unless usages effectively drops to zero.\nWhile it would be possible to detect this and switch to FIFO if maxConnectionIdleTime is set, that seems to violate the element of least surprise for users.\n. Perhaps the answer lies not in tweaking the connection pool implementation but rather in exposing a new API.  The MongoDB driver for golang has a Session-based API that allows the user finer-grained control over what socket the application is using.   An approach like that might be applicable for this use case, as then the application itself could reserve as many sockets as it needed for unacknowledged writes, and use a different set for other operations.\n. I'm not sure why you're asking a question in a pull request, so I'm going to close this.  Please post any questions you have about the Java driver to https://groups.google.com/forum/#!forum/mongodb-user.\nThanks,\nJeff \n. Please see my latest comment on https://jira.mongodb.org/browse/JAVA-2224.\n. I'd like to do a bit more work than this (like synchronizing start and close methods), so I'm going to close this.  I very much appreciate the diagnosis, though.\nThanks,\nJeff\n. lgtm\n. Thanks for submitting this pull request.\nPlease run ./gradlew check on your branch, as it appears from Travis that the patch is violating our Groovy test coding standards.\nAlso, as per our contributing guidelines, please also open an issue in our JIRA project so that we have an issue to link this pull request to.\nAlso, please note in our documentation that autoIndexId has been deprecated in the MongoDB server as of the 3.2 release and is scheduled for removal in 3.4.  \nThanks,\nJeff\n. I suggest that you ask your archiving question in the mongodb-users Google group, as this isn't the right forum for that sort of discussion.\nI have a few suggestions about the tests.  After handling those, please\nsquash the commits and prefix the single commit message with \"JAVA-2257: \", and we'll get this merged.\nThanks,\nJeff \n. Merged via command line.  Thanks again!\n. Thanks for noticing that!\n. Looks great.  I'm just going to make a few additions to conform to our coding standards (@since javadoc annotations, etc.) and will merge prior to the 3.4.0 release candidate.\nThanks!\n. Merged after amending the commit to add the Jira issue to the commit message.\n. Thanks Kay.  It's looking great.\n. Two remaining issues:\n1.  I recommend removing the openUploadStream/openDownloadStream examples for the initial version.  The code is going to get rather complicated if we want to do it right.  We can just mention the existence of the methods and say that they are there if you require fine-grained control of the upload/download process.\n2. Please run 'gradle -x test check' and fix the checkstyle issues in the new Java examples  (that's why the Travis build is failing)\n. Hi Tug,\nThank you for the pull request.  I commented on https://jira.mongodb.org/browse/JAVA-2301 to explain why it works the way it does.  Let's continue the discussion there.\n. Merged.  Thanks Kay.\n. Vladimir,\nPlease squash your commits and then I'll merge.\nThanks,\nJeff\n. Hi Chris,\nI do not want to make this change until we have agreement from all supported drivers on how to handle this situation.  This would likely come on the heels of an amendment to the BSON specification that describes the recommended behavior for BSON decoders that encounter duplicate fields.  \nNote that a third possibility, which is implemented in the .NET driver, is to treat duplicate fields as an error and throw an exception.\nAfter all, it's just as likely that the \"correct\" value for the duplicate field is the last occurrence rather than the first.  Or there could be more than two occurrences and the \"correct\" value is neither the first not the last.  It just so happens that the particular manifestation of a duplicate field in SERVER-27271 places the correct value in the first occurrence of the roles field.\nPlease also note that a new server ticket has been added to address the general problem on the server side: SERVER-19091. LGTM. Please squash the commits and then I'll merge it.. Merged. Already merged.. As of MongoDB 3.0 mongoexport outputs dates in Zulu time:\n ~$ /mongodb/mongodb-3.0.default/bin/mongoexport -d test -c d\n{\"_id\":{\"$oid\":\"58c1e8ef28489b68ac9feeb8\"},\"d\":{\"$date\":\"2017-03-09T23:44:47.898Z\"}}\n\nSince MongoDB 2.6 (the release prior to 3.0) will be EOLed this fall, I'm not convinced that this issue should be addressed at all.\nI'm going to close this PR, but please let us know if you have a use case that really requires this, and we can reconsider.\n. LGTM. This isn't a clean merge.  You should be making the change on a branch off of master and requesting a merge on to master.  The 3.4.x branch should not be involved.. lgtm. I changed the commit message to add the issue number, rebased, and pushed.\nhttps://github.com/mongodb/mongo-java-driver/commit/e53fb26fb9733c12f9e0844c2fcf2d0c28185873. Thanks, you're right.  As I was reviewing I noticed that there's a typo in the same sentence: 'equalss'.  You want to fix that too and then we'll merge?. We're going to have to devote more time to this.  Issues that we need to address before moving forward include:\nReview the events to make sure they are what we want.  For example, the message-related events in ConnectionListener should probably go because they duplicate what's available in the CommandListener interface.\n Coordinate with other drivers to make sure we agree on the event types\n* Remove the @Beta flag on the interfaces\n. Thanks for pushing this along.  We're going to work on this in scope of JAVA-805, making some of the changes that I mentioned above.  Please look for progress on that ticket, which is currently in internal code review.. For reference, the associated Jira issue: https://jira.mongodb.org/browse/JAVA-163. Hi @joankaradimov thanks for updating this PR.  Our focus right now is on driver support for MongoDB 3.6, but this is definitely on our radar to review as soon as our time frees up a bit.. Thanks for catching that.  Say no to typos!. Make sure you fix the checkstyle errors before pushing.. I'd prefer not to use system properties to control the behavior of the driver.  Most of the ones the driver used to rely on have ended up replaced with an options that's controllable via a public API.\nWhat do you think though about the approach in https://jira.mongodb.org/browse/JAVA-2203 as an alternative? That would make it unnecessary to make this change.. Squashed, rebased, and merged to master.  Thanks very much @kashike !. This change will make the test fail for people in a locale that uses \".\" as the decimal separator rather than \",\", so it's not making things better for everyone.  Can you see about making a fix that works for all locales?  \nI'm surprised this is a problem, as I was under the impression that the DecimalFormat that the driver is using to format that number is locale-agnostic.. The driver lower-cases hostnames because names in DNS are case-insensitive.  See https://tools.ietf.org/html/rfc4343.  \nAre you having a specific problem on Docker or another container service that this change alleviates?  If so, please provide details as we'd certainly like to be aware of the situation so that it can be addressed across all MongoDB drivers.. Thanks for noticing, and also fixing!. Note that the docs publishing process is currently manual, so the change won't show up immediately.. As @rozza indicated on JAVA-2631, the AsynchronousSocketChannelStream#openAsync method is responsible for catching the IOException and wrapping it in a MongoSocketOpenException.\nFurthermore, the InternalStreamConnection#open method is responsible for closing the stream on any exception.  \nGiven this, I'm closing this PR as I don't see that it will resolve the issue raised in JAVA-2631.\n. I checked out this branch and ran\n./gradlew driver-core:codenarcTest\nand I see the failures.  It's trailing whitespace on 7 lines of AggregatesFunctionalSpecification.groovy.  The line numbers are 392, 416, 420, 443, 466, 467, 470\n. I want to get this into 3.6 so can you revert the last commit?  \nThanks!. Thank you for the contribution. \nRegards,\nJeff. I'm not concerned about the test failure with regard to this change, as there's no way they can be related.. I agree with @fhassak, so I'm going to close this one.\nThanks though for the contribution and feel free to fix any other docs issues that you come across.. Thanks for the work on this @fhassak!  It's now merged to master.. Hi Ricardo, as I mentioned on JAVA-2718 this change would break binary compatibility.. Closing this, as the change would break binary compatibility.  We can consider for the next major release (4.0).. Good catch, @fhassak.  We generally use our own CI server and not Travis, but good to have this updated so that pull requests use the latest MongoDB server on Travis.. I'm not clear what your intention is here.  The RFC that you reference is for the GSSAPI SASL mechanism, but the class you modified is for SCRAM-SHA-1 SASL mechanism.\nAlso, the part of the GSSAPI RFC you quoted seems to apply to servers, while the driver is used on clients.. Please open a ticket at https://jira.mongodb.org/projects/JAVA so we can gather more details before considering a pull request.  I'd like to see some sample code and the full stack trace.\nThanks,\nJeff. OK, I see.  From what I now understand, https://tools.ietf.org/html/rfc5802 is the relevant spec, which says:\n\nThe characters ',' or '=' in usernames are sent as '=2C' and '=3D' respectively.  If the server receives a username that contains '=' not followed by either '2C' or '3D', then the server MUST fail the authentication.\n\nSame idea, though.  I've opened https://jira.mongodb.org/browse/JAVA-2763 to track this bug.\nThis PR will ultimately need some unit tests to verify it.  Did you want to take that on as well or leave it to the maintainers?\nRegards,\nJeff\n. I've dealt with the unit test, so don't worry about it.  I'll push it along with the commit in this PR.\nThanks again,\nJeff. Pushed to master and 3.6.x branch.  See https://jira.mongodb.org/browse/JAVA-2763 for links to the commits.\nThanks Brendan!. Squashed, rebased, and merged to master via command line: https://github.com/mongodb/mongo-java-driver/commit/c14e41abccf2f9f69fa37d7fe835f68eb63f93d7.\nThanks for the contribution!. Rebasing and merging.  Thanks for the contribution!. Great find.  Thank you!. Thanks for the contribution @fhassak.  \nHave you had any luck getting IntelliJ to compile this?  When I Rebuild Project I get:\nInformation:java: Errors occurred while compiling module 'util_main'\nInformation:javac 9 was used to compile java sources\nInformation:4/30/18, 12:16 PM - Compilation completed with 21 errors and 3 warnings in 3s 514ms\nWarning:java: source value 1.6 is obsolete and will be removed in a future release\nWarning:java: target value 1.6 is obsolete and will be removed in a future release\nWarning:java: To suppress warnings about obsolete options, use -Xlint:-options.\n    /Users/jeff/mongo-java-driver/util/src/main/DocTaglet.java\n        Error:(17, 30) java: package com.sun.source.doctree does not exist\n        Error:(19, 26) java: package jdk.javadoc.doclet does not exist\n\neven though they clearly do exist.. I figured out the IntelliJ issue.  You have to uncheck the \"Use '--release' option for cross-compilation (Java 9 and later)\" on the \"Build, Execution, Deployment > Compiler > Java Compiler\" preference page.  Otherwise when it builds it sets the \"--release\" command line argument for javac to \"--release 6\" based on the \"targetCompatibility = JavaVersion.VERSION_1_6\" in build.gradle.\n. Squashed, rebased, and merged to master at https://github.com/mongodb/mongo-java-driver/commit/74b9ff6e474abbf12240274ec39dd9d2a92f6b7b.\nThanks so much for this contribution.  The javadoc looks so much better now.. Thanks for doing the investigation and the work.  Tracking with https://jira.mongodb.org/browse/JAVA-2844.. Squashed, rebased, and merged: https://github.com/mongodb/mongo-java-driver/commit/a0175e5316b2a4e83fb3c678a002e6328228dce5\nThanks again!. We're currently not able to build the driver with Java 11 due to Gradle incompatibilities.  See https://jira.mongodb.org/browse/JAVA-2991. Thanks for catching this!\nRegards,\nJeff. @umang-jalan Our apologies for losing track of this PR and doing our own implementation of this issue.  See https://github.com/mongodb/mongo-java-driver/commit/468bcb95a3d1904c2033a52453476b56b94d9bff for what got committed to the repository.. You can already do something similar with the existing API:\n    MongoClientSettings settings = MongoClientSettings.builder()\n            .credential(MongoCredential.createCredential(userName, password))\n            .applyConnectionString(new ConnectionString(\"mongodb://localhost,localhost:27018\"))\n            .build();\n    MongoClient client = MongoClients.create(settings);\n\nIs that sufficient for your use case?. Good idea.  Added https://jira.mongodb.org/browse/JAVA-2975 to track the request.  Feel free to open a pull request to address it, as our documentation is stored in the repository.. How about\nThis package contains the synchronous CRUD API.. Hi @fhassak\n\nI changed the commit message slightly and committed this via the command line.\nThanks again for spotting and fixing this.  You have sharp eyes!\n. Trying to standardize on future.\n. I don't understand this comment.  Can you elaborate?\n. I tried to make it less smelly, but failed.  It's more difficult to generalize this one because it's turning an exception into a normal completion.\n. I think it looks worse than it is because there are so many overloads, to make the operations dead simple.  If you have a suggestion to make it simpler, let me know.\n. Perhaps.  I try to put the data first, then the connection-related parameters next, and return-based parameter last.\n. The other protocol executeAsync methods are logging as \"Asynchronously ...\"  Can you change these to do the same?\n. good catch\n. We've been statically importing AsyncCallableWithConnection in other operations\n. nit: too many spaces before \"for\"\n. Can just be: \n} else if (result.isAcknowledged()) {\n   bulkWriteBatchCombiner.addResult(result, run.indexMap);\n}\n. Why convert the Iterator back to a List?  You can just pass the Iterator itself into executeRunsAsync and stop when hasNext() == false.   If you assert in the constructor that there is at least one WriteRequest in the list, then you are guaranteed that the first call to next() will return a Run. \n. I thought we were in the first test.  It gives full coverage of the save() method.  Are we missing functionality in the method itself?\n. So it can.  Good tip.  I was looking for something like this, but thought it would be something that returned a Future, so didn't find it.\n. Instead of Future.syncUninterruptibly, can we instead call Future#addListener?\n. I don't think you need to ensureOpen on a read, since according to MongoDB protocol, a read is never the first operation on a socket.  A write is always first.\n. Is this the only exception we have to wrap?\n. I don't think we should throw a Netty-specific exception.  It will create un-portable code for people that switch between async implementations.\n. Asserting that it throws UnsupportedOperationException?  No.\n. The new BsonBinary class.  Note that it does not wrap Binary, as I didn't see any advantage to doing so.\n. DBPointer to BsonDbPointer\n. This was formerly just the the Code class, which had been retrofitted to extend BsonValue.  It no longer does, and there is this new class.\n. Name change of CodeWithScope to BsonJavaScriptWithScope (to match .NET and the BSON spec)\n. New class, since MaxKey is pre-existing.\n. New class, since MinKey is pre-existing\n. New class.  This one holds an ObjectId.\n. Name change\n. Name change\n. Needs Javadoc\n. This is a mistake.  The Symbol class is pre-existing so have to leave it.  Will fix.\n. Name change\n. Name change\n. This can be reverted.  Will fix\n. The move from ObjectId to BsonObjectId exposed a bug.  We have to convert the upsertedId, which is a BsonValue, to whatever our DBObject decoder says it should be.\n. Have to convert BsonValue to the correct type according to the DBObject decoder.\n. The only issue I see here is that the BsonDocumentWrapper will decode the entire replacement document just to get the id.  But as this is already going to be woefully slow (bulk api against 2.4) I think it's ok to leave it as is.\n. For consistency, this should also take a Boolean\n. Perhaps:\n\"A write concern that blocks acknowledgement of a write operation until a majority of replica set members have applied it.\"\n. There are not parameters though.  I really do not want to go through and make these all final, since we have not configured checkstyle to do that.  I also don't see a big benefit, as I don't think I've ever accidentally modified an exception reference in a catch clause.\n. Actually, it throws if SSL IS enabled.. Which should probably happen in the constructor instead.\n. @since 3.0 (it wasn't public in 2.x).  Please check the rest for the same mistake.\n. 3.0\n. There is no public close method for Server, so this comment should be re-worded a bit.  The main point is that it releases all resources and can no longer be used.\n. \"to a single server\"\n. \"to a MongoDB server\"\n. For async, this may not be threads waiting.  Can we just say \"the maximum number of waiters\"?\n. Local variable: no final needed.  Is your IDE configured differently that checkstyle?\n. this is the maximum size of a wire protocol message.\n. Many of these deserve an @mongodb.driver.manual javadoc annotation\n. \"instances of {@code SocketStream}\"?\n. \"that match the criteria of the implementing ServerSelector\" is an awkward phrasing.  It's enough to say:\n\"Select a list of server descriptions from the given cluster description according to some criterial.\n. \"a non-null, possibly empty list of ServerDescription\"?\n. This is a bit better, but what does this mean?  How is it reflected?\n. I'd rather keep the code samples for tutorials and leave the Javadoc as specifications.\n. Everywhere else I've just been writing:\n@return this\nCan you document the chaining once in the class javadoc?\n. How about:\nThrows a {@code CommandFailureException} if the command failed.  Otherwise, returns normally.\n@see ok()\n. Server Address lowercase unless you are referring to the class in which case use {@code ServerAddress}\n. This is self-referential.  You're basically defining what an interface is used for.\n. This is not true.  It doesn't create a collection on the server.  It just creates a client representation of the collection that can be used to interact with the server.\nAlso, not sure what that comment about being NOT part of the public API means?  DBCollection is part of the public API.  Does it mean that this method is not?  I think it should just be removed, since we're not deprecating it in 2.x.\n. Looking at master, it looks like this method was not properly ported to 3.0.  See https://github.com/mongodb/mongo-java-driver/blob/master/src/test/com/mongodb/JavaClientTest.java#L1077-1077\n. CommandFailureException\n. American spelling please :)\n. \"The encoder with which to encode the command document\" ?\n. Missing period before \"Accepts\"\n. Can we just call the parameter \"limit\" as well?  I don't want to introduce the term \"element\", and I think it's fine for a fluent API for the parameter name to simply match the method name.\n. Take this paragraph out.  It's not true anymore.\n. or implicitly with try-with-resources\n. Since all the constructors for this class are deprecated, what do you think about removing all this tutorial-style documentation entirely, and push users towards MongoClient instead?\n. So glad to see this exception go!\n. Since this is the doc for 3.0, I'd simplify this to:\nChanges to {@code MongoOptions} that are made after connection...\n. lowercase\n. Surround this with {@code }?\n. How about something like:\nAn iterator of documents that is possibly backed by a server-side cursor, which can be forcibly closed via the {@code close()} method.  Under normal circumstances, the cursor will be closed automatically when all the documents have been iterated, but care should be taken to manually close it in the face of early termination of the iterator.\n. Yes, that one.\n. Good catch.\n. Change to WriteConcern.ACKNOWLEDGED\n. Why  and not @code?\n. It's already deprecated, so say instead it may be removed in a future release\n. Should this file even be checked in?\n. I don't see a public method that lets you get each chunk as a byte array.\n. Missing period before \"Operations\".  Missing newline after \"include:\"\n. Remove @author tags.  We don't do that anymore.\n. This class will not stay.\n. same\n. Done\n. Clarified.  Done.\n. Done\n. Yes.  Done.\n. Found it on bsonspec.org and copied the definition from there.\nDone\n. Done\n. Done\n. Done\n. Done\n. Done\n. According to http://docs.mongodb.org/manual/reference/mongodb-extended-json, $maxKey and $minKey is correct.  So I think it's JsonReader that needs to change, not JsonWriter.\n. No final for local variables\n. There should be a number of failure conditions here:\n- no comma at all\n- no colon in each property\n. I think this actually will not work to always use string for the mechanism value, since authenticators are expecting typed values (like a boolean)\n. Currently the authenticators don't.  So we need to fix this either here or there.\n. While unlikely to affect anyone, this is a binary compatibility break, so I think we are stuck with the API that we have.\n. Link to reference/command/update/ instead of the shell documentation\n. Link to \nreference/command/delete/\nreference/command/update/\nreference/command/insert/\ninstead of the shell example\n. Link to\nreference/command/delete/\nreference/command/update/\nreference/command/insert/\ninstead of the shell example\n. Link to\nreference/command/delete/#output\nreference/command/update/#output\nreference/command/insert/#output\ninstead of shell example\n. Link to \nreference/command/update/#update.upserted\ninstead of shell example\n. This comment doesn't make a lot of sense to me.  What is an internal increment value?  What does epoch inc is an ordinal mean?\n. I'd prefer tutorial/modify-documents/#upsert-option, as this is shell documentation you're linking to here.\n. Looks like you missed my last set of comments on https://github.com/mongodb/mongo-java-driver/pull/256 where I requested a change of these bulk write links from shell documentation to the command documentation reference.\n. Whoa whoa whoa!  Looks like you made a few types public that used to be non public.\n. Here too.\n. typo: \"since 3.0\" should be removed\n. What style is being violated here?\n. Here's the server docs: http://docs.mongodb.org/manual/reference/bson-types/#timestamps.  It does not not use either of those phrases.\n. They are next to go.\n. This class is a copy of the one from driver-core so I'm leaving it in for future use in the bson module even though it's currently unused.  I didn't want driver-core reaching into bson for its Assertions, which is why I copied it.\n. This was discussed at length in the .NET implementation.  The reason for equals to not include serverValue is so that users can correlate the ConnectionId before it has a server value with one after it discovers its value.  In practice, the driver won't ever create a ConnectionId with the same localValue but different server value as another ConnectionId.\n. I changed my mind about events providing structural equality/hashCode methods.  I don't see it providing any value to users and I had only added them so that we can write tests that easily compared events. \n. Yes, you're right.  Something to investigate.\n. I assume you mean ClusterId\n. This is the only negative consequence of removing equals from the events.  Is there another way to do this that doesn't rely on an equals method for each event?\n. Done\n. Done\n. Done\n. For another day... Done\n. Missing newline\n. What are we picking up from jcenter?\n. Why no osgi plugin here?\n. Not clear to me why this is needed here but not in the other build files\n. Done\n. Can you clarify this for me please?\n. Done\n. Is this just a sanity check?  In maven release process, IIRC, if your pom contained a version like 3.0.0-SNAPSHOT, it would assume the release version is 3.0.0.\n. The credentials have to be stored in a file?  Is there any other way?\n. Missing newline at end of file\n. Oh, here's that global variable.\n. I don't understand this comment.  What's components.java?\n. Let's follow the convention of MongoDatabase/Collection and make this an interface.\n. While it would be nice to be able to use the Objects class, we have decided not to rely on any Java 7 APIs except AsynchronousSocketChannel (which can be replaced by Netty).\n. We have a logger class available: com.mongodb.diagnostics.logging.Loggers\n. Better to figure out a way to add this provider to the registry in the MongoDatabase used by the GridFS instance.\n. Rename to getDatabase\n. Probably can use org.bson.codecs.configuration.RootCodecRegistry#withCodec instead of needing this class at all.\n. Unused field\n. How about returning a MongoIterable instead, since the list could be rather large in some use cases?\n. Since we know we're deleting a single file, DeleteResult is not useful.  Better to return Void\n. Did you consider a ListCollectionsOptions class in case more options are added in the future (like a projection)?\n. Need tests for the other listCollection* methods\n. Can we test that batchSize is actually being applied?\n. Can we test that batch size is actually being applied?\n. Perhaps abstract this line into a static method in CursorHelper?\n. Can you explain what we're trying to accomplish here?  Does the query filter work differently for the command and the legacy query?\n. This may be a problem.  The reason for including it is to allow implementors to re-write filters, projections, sorts, and updates based on knowledge of the class of the document that is in effect for the collection.\nConsider a Person class, a MongoCollection, and a Codec that transforms the \"name\" member of Person to an \"n\" field in the BSON representation.  Then consider a query like this:\ncoll.find(eq(\"name\", \"Ross\"))\nwhen the filter is rendered to a BsonDocument, we'd like to be able to transform the filter to \n{n : \"Ross\"}\nand in order to do that we need to know about the Person class, so we can look up its Codec in the registry and pull out this information (assuming we have a sub-interface of Codec which provides this information).\nThe problem is that with a single Renderable interface, we don't know whether we're rendering a filter, a projection, a sort, or an update.\n. Done\n. We don't need a semaphore here.  It's just a lock. And I had to make it re-entrant because otherwise the tests with mock streams will deadlock.  I'll point out where the deadlock would be below.\n. The async reader is now using readerLock in a different way than the sync reader, so they won't work together properly.  \nIf we end up using this design, I'm not sure yet how to make it work with concurrent sync and async readers.\nBut we don't have any tests of concurrent async and sync readers. \n. No need to hold the lock just to call the callback\n. There are two possibilities:\n- my response has already been read: if so, no need to add myself to the read queue.  Just grab the callback and execute it (after I give up the lock)\n- my response has not yet been read: I need to put myself on the read queue.\n. This conditional is the one I'm least sure about.  The second condition, I believe, is necessary to prevent simultaneous readers.    And without the first condition the \"InternalStreamConnectionSpecification#should handle out of order messages on the stream asynchronously\" test fails on the second async read. \n. I don't need to hold this lock, now that I've updated all my internal state\n. processPendingResults is not necessary because at most one result ever becomes available at a time.\n. It's possible that the recipient of this message has not put itself on the read queue yet, so we have to store the message for them.\n. If there are more messages to read, read one of them\n. Again, no need to hold the lock while executing the callback\n. The problem with this wording is that, if the condition is false, the IllegalArgumentException's message will be: \"state should be: geometrys cannot contain null values\".  The way it is now, it will be: \"state should be: geometrys contain only non-null elements\"\n. 1. I considered it, but decided against it, as there are no other classes named Point, Position, etc that are likely to be used in a server application.\n2. Just because it can be added if and when we add features support, without breaking binary compatibility.\n. That's what import is for, to disambiguate.  I just don't see people using a different Point or Position class in the same .java file\n. Yes, exactly.\n. No, this one if for the legacy $polygon: http://docs.mongodb.org/manual/reference/operator/query/polygon/#op._S_polygon.\nIt's the same in .NET's FilterDefinition, I believe.\n. No, I'm relying on the server to throw in this case.  I'll look into adding run time checks.\n. This is the only one, I believe.  And it's just because polygon coordinates have two parts: exterior and holes.  So this was the only way to pass a list of them.  Note that the Polygon class has a constructor that takes one of these, and another one that takes the two pieces separately.\n. There are two Point classes in the JDK: java.awt.Point and javafx.scene.effect.Point.  Neither are likely to be used in the same Java file along with the Java driver.\n. It's worth something.  Should be fixed. ;)\n. Please revert this change.  We've been using IntelliJ's default toString generator and this will introduce an inconsistency with all the other generated methods.\n. What's the reason for implementing decode/encode on ClassModel?\n. This shouldn't be done automatically.  It should be triggered by users of the class (such as a convention).\n. The 'value' parameter should be of type T.  Have you run with compiler warnings enabled?\n. This class seems unnecessary at present.\n. The Set should be copied so that instances are immutable.\n. Add Immutable annotation\n. Add Immutable annotation.\n. Let's use or create a better exception than this.\n. As above\n. Should this be abstract?\n. I don't want this pushed with a dependency on fasterxml, so please create a Jira about getting rid of it or shading it.\n. I particularly don't like that fasterxml is part of the public API, even in this small way of a constructor parameter\n. ProviderBuilder\n. So it is...\n. We have to consider how this will be used in the context of the Java driver.  Currently, you have to be explicit about the collection name:\ndatabase.getCollection(\"people\", Person.class);\nI suppose the collectionName could be ignored when used this way, and could be taken into account with an alternate API like:\ndatabase.getCollection(Person.class)\nFor this usage, the Codec interface would have to be optionally extendable to provide the collection name.\n. I think this is incorrect.  The thread can't enter the wait queue if the wait queue is full, so the event should not be generated.\nHow about instead we pull the throw of the wait queue full exception up out of the try block? That way the finally block will not be executed when the exception is thrown.\n. Make param final (to check for style errors, run \"gradlew check\")\n. As above.\n. I'd like these classes to be more consistent with BaseWriteOperation. To do so would require the following changes:\n- Add a new constructor that takes a non-null WriteConcern parameter\n- Deprecate the existing constructor  (so as not to break binary compatibility for any users of core)\n- Remove the new writeConcern setter method\n- For backwards compatibility, default the writeConcern field to ACKNOWLEDGED in the deprecated constructor\n. This should be:\nserverIsAtLeastVersionThreeDotTwo(description) && !writeConcern.isServerDefault() && writeConcern.isAcknowledged()\nas I don't think the driver should be sending \nwriteConcern : { w : 0}\nor \nwriteConcern : {}\nto the server.\n. Given above comment, should test with three different write concerns:\n- ACKNOWLEDGED\n- UNACKNOWLEDGED\n- W1\n. Done\n. Done\n. Done\n. Done\n. Done.  The link is a bit funny (http://api.mongodb.org/java/3.2/?), but it works.\n. I had added a version for it above.  Now it's in this versions list as well.\n. Couple of suggestions for the tests:\n1. Combine the two tests into one using Spock's where syntax: e.g.\nwhere:\n   autoIndex  | expectedNumberOfIndexes\n   true            | 1\n   false           | 0\n2. Combine the two \"then\" clauses.  The \"when\" clause is for the code that is under test, so the second one is a mis-use of it, and can be folded into the \"then\" clause\n. Closer... Generally there is no need for to follow \"then:\" with \"expect:\".  Just get rid of the \"expect:\" and even the stats local variable.\n. It's a stretch to use this language about the FindIterable being empty, as there is no empty() method on FindIterable.  Since this is about returning the first document in the collection (with no filter), better just to say: If the collection is empty, the operation returns null. \n(change in both sync and async)\n. Change databaseName to name \n. CC @rozza \nThis is not guaranteed to work as the write method won't necessarily write all the bytes remaining in data.  In other words: 0 <= result <= data.remaining(), so for this method of writing the user may have to repeatedly call write until data.remaining == 0.\n. CC @rozza \nSame problem here I believe: read may invoke the callback while there is still room is dstByteBuffer, so may have to call read repeatedly to fill it.\n. \"and the collStats command\"\n. \"and the collStats command\"\n. DRY this up by implementing toByteArray in terms of it\n. DRY this up by implementing ObjectId(final byte[] bytes) in terms of this\n. I think it would be clearer if, instead of adding a new test, you just add another assertion to testToByteArray and to testFromByteArray (perhaps renaming to testToBytes and testFromBytes)\n. Yes, it's ok. \n. This will cause a nasty leak as is.  Change to:\n    EventLoopGroup eventLoopGroup = new NioEventLoopGroup();  // make sure application shuts this down\n\nand then\n    NettyStreamFactoryFactory.builder().eventLoopGroup(eventLoopGroup).build();\n\n. Unindent. These were left out intentionally, as since Java 7 the type can be inferred by the compiler.  . Change to:\n// handle exception. Change to\n\n// handle exception. As above. Executable is a confusing suffix for this class.  Perhaps CreatorExecutor?. Should read \"Unable to set...\". I'm not sure what the intention is here and below.  The way the message reads it seems like the intent is that the second string is the name of the enclosing class, but it's actually the property type.  So we'll end up with something like:\n\n \"Unable to get value for property 'someInt' in java.lang.Integer\". Getter methods also can't have arguments, so should check for that too.. Setter methods have a single argument, so should check for that too.. I missed this the first time around: These should all throw a driver-defined exception, as this is an abuse of IllegalStateException.  The error messages should also identify the declaring class of the property so that it's easy for users to find the source of the problem.. When we talked about this did we reject the idea of prefixing the annotation names with \"Bson\", e.g. BsonProperty?  I can't remember anymore.  It does look like Jackson uses a \"Json\" prefix, e.g. JsonProperty. To support transient properties where the field name doesn't match the property name, I think we'll need the equivalent of JsonbTransient though I prefer Jackson's choice of JsonIgnore.. A property should be added to the class model for deserializable properties, even if they're not serializable.. This leaves it up to chance which annotation is applied if there are duplicates, e.g.\n\n@Property(\"foo\") int getBaz();\n@Property(\"bar\") void setBaz(int baz);\n\nJsonB actually allows this, and applied them both, one for serialization and the other for deserialization. We should either do that, or at least report an error if there's a conflict.. A method starting with \"set\" that has more than one parameter does not define a property, so should just be ignored rather than thrown an exception.. typeData is ignored for all but the first of getter/setter/field to be found.  Instead, I think there should should be some check to ensure the type data is the same for all the elements of a property.. Instead of ignoring the case where multiple constructors/static factory methods have the Creator annotation, should throw an exception to inform the application of the error (as in Json-B 4.5). It should also be required to return an instance of the declaring class, as per 4.5, paragraph 3.. In Yasson this isn't actually an error.  See org.eclipse.yasson.customization.JsonbCreatorTest#testCreatorWithoutJavabeanProperty\nIn other words it's perfectly ok to use a creator with a property defined by one of its arguments that doesn't match up with any property defined in the model.. Acknowledged.  I was reading it as an executable like mongod.exe.. Ack. Ack. I'm not quite seeing that use case.  If the public API is all ObjectId there's no point in storing as a private String field.  I could see this:\nprivate String id; \npublic String getId() {\n    return id;\n}\n\npublic void setId(final String id) {\n    this.id = id;\n}\n\nand wanting to serialize id as an ObjectId.  But that's a different case.  Let's discuss.. I know I mentioned this class to you, but on further reflection (no pun intended) let's avoid this dependency on java.beans.Introspector.  In Java 9 this will force applications to pull in the jdk.desktop module, which is going to limit our deployment opportunities.  \nhttp://download.java.net/java/jdk9/docs/api/java/beans/Introspector.html#decapitalize-java.lang.String-. Similarly, these should not be considered get/set methods\n int getfoo();  \n void setfoo(int foo);\n int get();\n void set(int foo);\n\nIn other words there has to be at least one character after get/set prefix and it has to be a capital letter (using Character.isUpper(char c)).\n. Acknowleded. Acknowledged. Add \n@since 3.6. Add\n\n@since 3.6. Remove extra space before field name.. This test seems redundant.  Is this testing anything that's not already being tested above? . I'd remove the second one with all options. Needed so that InternalStreamConnection can just call it without having to know what subclass of BsonDocument it has.. And might as well optimize it here rather than force creation of a keySet.. This change is necessary because otherwise calling createOne on a document within an OP_MSG that is followed by a payload will fail, as the create method thinks it's just a bunch of contiguous documents and doesn't know anything about the payload structure.  So this is just a copy of createOne but without the loop.\n\nI didn't see a straightforward way to refactor for code re-use, but I'll take another look.... Used by CommandMessage to find the start of the payload. Not the prettiest but it gets the job done.. createMany or createList?. Unfortunate introduction of a new public method in a patch release.  I don't see a way around it.  Unlike the original commit I didn't introduce this pipe method into the BsonWriter interface.  That would be a bridge too far.... And here's the root cause of the bad test: this method returns a singleton BsonDocument, which the test then goes ahead and mutates.  It wasn't caught because it happened to be the last test that used this method.  \nChanged to return a new BsonDocument on every call.. There was actually a bug in the original version, which compared the current level to 0 instead of -1.  It wasn't caught then either because of the test bug.. To avoid introducing the overloaded pipe method to the BsonWriter interface, changed this to depend on BsonBinaryWriter.. And here's where the test was mutating what used to be a shared global singleton. . I'd like to see a unit and functional test for this overload.  Currently it's untested, but I want to make sure we catch any issues when let is null.. Let's fix this comment now, as there is no filter, but rather a pipeline.  Perhaps:\nCreates a $lookup pipeline stage, joining the current collection with the one specified in from using the given pipeline.\n. Replace \"specifies\" with \"the\".  . (I realize the comment in the existing lookup method is misleading as well.  Feel free to fix that one too if you're so inclined.). The build failure is due to trailing whitespace on this line.  If you run  `./gradlew driver-core:check' it should fail for you too.. No need for javadoc of a private method. Remove public modifier and Javadoc (we generally don't Javadoc non-public methods unless it really is needed for clarity).. Change to\ngetElapsedTimeFormattedInMilliseconds. SpotBugs founds this based on the annotations. SpotBugs found this one too.. A test like this in JsonReaderTest would be more to the point:\n@Test\npublic void testTimestampWithUnquotedKeys() {\n    String json = \"{$timestamp : { t : 1234, i : 1 } }\";\n    bsonReader = new JsonReader(json);\n    assertEquals(BsonType.TIMESTAMP, bsonReader.readBsonType());\n    assertEquals(new BsonTimestamp(1234, 1), bsonReader.readTimestamp());\n    assertEquals(AbstractBsonReader.State.DONE, bsonReader.getState());\n}\n\n. This change casts too wide a net, as this method is called from both methods implementing \"Extended JSON\" and for methods implementing \"Shell\" mode, e.g. JsonReader#visitObjectIdConstructor, and it's not correct in the shell to do something like:\n{ _id : ObjectId(5aaff8caa33024673db4cddf) }\n\nIt's also called to read values in some places, not just keys.\nTo address this, I think you will need to leave the current method alone and add a new method that is used only to read extended JSON keys, e.g. in JsonReader#visitTimestampExtendedJson. It's fine to fail fast here.. Is this what's creating the extra white below the MongoDB Documentation and Since Server Release paragraphs,  as seen in the first screen shot?  And #468 will fix it?. Understood.  \nIntelliJ does however suggest this small change:\n    return new HashSet<Location>(\n            asList(Location.CONSTRUCTOR, Location.METHOD, Location.FIELD, Location.OVERVIEW, Location.PACKAGE, Location.TYPE));\n\n. Merged!. Please also change \"will use used\" to just \"will use\".  As is it's not grammatically correct.. Please append a newline.. ",
    "kevinsawicki": "Then why do so many other places in the mongo-java-driver use StringBuilder.append instead of += on String objects?  These were the only 3 classes that use +=.\n. Try running both of these and see if you get the same amount of time to complete:\n``` java\npublic static void main( String[] args ) {\n    long start = System.currentTimeMillis();\n    String a = \"test\";\n    for ( int i = 0; i < 10000; i++ ) {\n        a += Integer.valueOf( i ).toString();\n    }\n    System.out.println( System.currentTimeMillis() - start );\n}\npublic static void main( String[] args ) {\n    long start = System.currentTimeMillis();\n    StringBuilder a = new StringBuilder( \"test\" );\n    for ( int i = 0; i < 10000; i++ ) {\n        a.append( Integer.valueOf( i ).toString() );\n    }\n    System.out.println( System.currentTimeMillis() - start );\n}\n```\n. > btw kevin, the toString() call on the Integer is superfluous when calling append.\nYes, I am aware of that, I was just trying to create a simple but explicit example of appending a String to a String.\nIs this pull request going to be reopened?\n. ",
    "BryanHunt": "Sorry, I'll try again.\n. ",
    "ylussaud": "At runtime the dependency is only needed if the user use an URI triggering UDS. At this point the unix socket library will ask for native libraries. If the user don't use URI triggering UDS it should not need more dependencies at runtime.\n. ",
    "richardwilly98": "I need to go through the entire gridfs collection. I am currently using getFileList() but facing the issue above.\nI need to call an additional findOne to get it working.\nMy current working code is:\njava\n            GridFS grid = new GridFS(mongo.getDB(definition.getMongoDb()),\n                    definition.getMongoCollection());\n            cursor = grid.getFileList();\n            while (cursor.hasNext()) {\n                DBObject object = cursor.next();\n                if (object instanceof GridFSDBFile) {\n                    GridFSDBFile file = grid.findOne(new ObjectId(object.get(MONGODB_ID_FIELD).toString()));\n                    addToStream(OPLOG_INSERT_OPERATION, null, file);\n                }\n            }\nWhat would be the prefered way to walk through the entire gridfs collection?\nAny reason this PR has not been merged?\n. ",
    "efroese": "More exclamation points! \nDo you have an eta on the next version you'll publish?\n. ",
    "greenlaw110": "Hi,\nLogically the inputstream should be closed when it's no longer needed. In\nour case the inputstream will no longer be used once the data  is saved,\ni.e. saveChunks(chunkSize) is called. Let me answer you concerns below:\n1. \"There is an issue where it only calls close inside of a conditional.\"\n- Do you mean \"if (null != _in)\" condition? I suppose that's absolutely a\n  safeguard to make sure you don't call method on an null object.\n1. \"Additionally, since you can construct a GridFSInputFile with an\n   InputStream, it is really the callers responsibility to close the intput\n   stream object. It would be presumptuous for us to close it.\"\n- It's hard to say inputstream should always be closed by caller. It depends\n  on how you define the contract of the API. In the case of GridFSInputFile,\n  it's very clear to define the contract that the GridFSInputFile will close\n  the stream once the data is saved. I don't think it's very user friendly\n  that we force app developer to close the inputstream passed in after he call\n  the gridfsInputFile.save().\n1. \"The problem is when the driver constructs the InputStream object, it is\n   definitely not being closed.\"\n- That's for sure, otherwise saving the data chunk will fail. That's also\n  why I said the inputstream should be closed immediately when you saved the\n  data.\nOn Sat, Oct 29, 2011 at 2:21 AM, Ryan \nreply@reply.github.comwrote:\n\nOk... I reviewed the commit.\n\nThere is an issue where it only calls close inside of a conditional.\n\nAdditionally, since you can construct a GridFSInputFile with an\nInputStream, it is really the callers responsibility to close the intput\nstream object. It would be presumptuous for us to close it.\nThe problem is when the driver constructs the InputStream object, it is\ndefinitely not being closed.\nWe are going to investigate further, but thank you for calling this to our\nattention!\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/mongodb/mongo-java-driver/pull/50#issuecomment-2557299\n. Hi,\n\nLogically the inputstream should be closed when it's no longer needed. In our case the inputstream will no longer be used once the data  is saved, i.e. saveChunks(chunkSize) is called. Let me answer you concerns below:\n1. \"There is an issue where it only calls close inside of a conditional.\"\n   Do you mean \"if (null != _in)\" condition? I suppose that's absolutely a safeguard to make sure you don't call method on an null object.\n2. \"Additionally, since you can construct a GridFSInputFile with an InputStream, it is really the callers responsibility to close the intput stream object. It would be presumptuous for us to close it.\"\n   It's hard to say inputstream should always be closed by caller. It depends on how you define the contract of the API. In the case of GridFSInputFile, it's very clear to define the contract that the GridFSInputFile will close the stream once the data is saved. I don't think it's very user friendly that we force app developer to close the inputstream passed in after he call the gridfsInputFile.save().\n3. \"The problem is when the driver constructs the InputStream object, it is definitely not being closed.\"\n   That's for sure, otherwise saving the data chunk will fail. That's also why I said the inputstream should be closed immediately when you saved the data.\n. I see this is purely a design decision of API. the STL container by default will NOT clean up the data it points to when it is destroyed, while boost ptr_container does. It's all depend on how you communicate the contract of the API to application developers.\nAs an application developer I 100 percent vote for GridFSInputFile to close the stream when my data is saved. As it's purely the purpose of the input stream object been created. If someone reuse the input stream object he is not doing a clean design. What if somebody close or rewind that input stream object when _readStream2Buffer method is reading data from it? You can't really prevent people from doing bad things. So stick to the design which do favor to good application developers is the correct decision to me. \n. ",
    "hoffrocket": "I want to build something like mongostat, but in java.  That means being able to talk to the individual servers in a replica set and maintaining a list of active secondaries.\nSince the driver already maintains the active pool of secondaries, I'd like to reuse that functionality.\n. @jyemin fongo does some crazy mocking of the Mongo instance itself to satisfy the interdependencies between that and DB, DBCollection, etc.  I think @aakhmerov encountered a bug in fongo and I'll work with him to correct. \n. ",
    "saynomoo": "Hi breinero, \nThe whole pull request https://github.com/mongodb/mongo-java-driver/pull/53 should be applied to be useful. At least in my use case.\n. ",
    "reynders": "Any progress here? Without this feature it is impossible to do tag aware sharding on chunks collection (which is the most likely target for sharding if you ask from me): http://www.mongodb.org/display/DOCS/Tag+Aware+Sharding\n. ",
    "Shekharv": "Done.\n. so, what's next?\n. any comments?\n. ",
    "alaz": "I had initially implemented something alike in Subset, but have finally decided to leave the explicit logic (e.g. it's the developer who decides) because this \"automated behavior\" should be ideally more complex: e.g. if any of the arguments already contains $and it should be unfold and the new $and constructed with all the arrays merged.\n. ",
    "freeeve": "There's no reason it can't check for other $and operators in the query, and then check for keys with the same name, if that's better behavior. I didn't realize it would perform worse so I just did the naive/safe way. I agree with Scott that it would be misleading--a lot of people use query builders exclusively and it should work in the best way possible. I'll submit another patch when I can get to it.\n. Alright. It's too bad that the syntax between the C# and Java query builders is so different, when they could be consistent.\n. Ha, thanks. Maybe I should have left it open a little longer to see if more enthusiasm rolls in. I for one found the Java QueryBuilder a pain to use after being exposed to the C# one. :)\n. ",
    "JakeWharton": "Great work! It's a shame terseness and the fluent pattern aren't more embraced by this library.\n. ",
    "jedws": "OOI, why does \"ant test\" not report this (at least, it doesn't for me). I reproduce the failure only by running the test's main.\n. https://github.com/mongodb/mongo-java-driver/pull/58\n^^^ definitely passes the tests now.\n. removed ^^^\n. Yeah, I saw Vector in BSON, easily fixed by replacing the use of Vector with CopyOnWriteList \u2026 I'll submit something.\n. ",
    "purefn": "This fixes the issue I was seeing with the serialization exception for ::.  Going to do some perf testing soon.\n. Good news, everyone!  This solves our contention issues in ClassMap, but now we have contention elsewhere (albeit, not nearly as much).\n. Heh already done dude. \n. ",
    "rocketraman": "This is obsolete, as per https://jira.mongodb.org/browse/JAVA-249.\n. ",
    "thkala": "Are you asking about the benchmark results, or the benchmark code itself? The first I could type into a comment, but the second refers to significant parts of my codebase that I would not be able to release at this time - at least not without a lot of work.\n. I cobbled up this little benchmark - just point it to a DB and collection with lots of C-strings, although some of the improvements should be visible everywhere:\n```\ntry {\n    long time = System.nanoTime();\nMongo mongo = new Mongo(\"127.0.0.1\", 27017);\n\nDBCursor cur = mongo.getDB(\"db\").getCollection(\"collection\").find();\n\nlong count = 0;\n\nwhile(cur.hasNext()) {\n    cur.next();\n\n    ++count;\n\n    if ((count % 100000) == 0) {\n        System.out.print('.');\n    }\n}\n\ntime = System.nanoTime() - time;\n\nSystem.out.println(\"\\n\" + count + \" documents in \" + (time/1000000000D) + \" seconds\");\n\n} catch (UnknownHostException e) {\n    e.printStackTrace();\n} catch (MongoException e) {\n    e.printStackTrace();\n}\n```\nIn my own code I was using a custom callback that did some pre-processing on the received documents. This one is as simple as it gets and it seems to highlight the performance improvements even more. I see a 25% improvement over the 2.7.3 stable release - I'll see about comparing with git master shortly...\n. ",
    "gerner": "Any plans to incorporate any of these changes (in particular the buffer size) I'm working with large result sets and I suspect a larger network buffer size would help things for me.\n. ",
    "havocp": "The only changed effect is to log info rather than warning; are there any existing tests with some setup for examining what gets logged? Or does that need inventing?\nI was thinking, while this patch is slightly better and probably can't hurt, a \"real fix\" might at least make it deterministic whether the old vs. new mbean is used (maybe by removing isRegistered and just always handling InstanceAlreadyExistsException by replacing the mbean, though there's another race there still between unregister/re-register). An even better fix might be to somehow either make one mbean represent all connections, or register a separate mbean for each connection. I don't know enough about jmx usage to say what could make sense.\nI guess a third alternative - maybe simplest of all - is to synchronize registration on some kind of global lock.\nNot sure it matters that much, since it only happens if you rapidly start two connections at once, which probably isn't done on purpose most of the time.\n. Right, I'm not quite sure why the instance= in the name doesn't help. The log message I got was like:\nMar 18, 2012 9:36:35 AM com.mongodb.DBPortPool$Holder get\nWARNING: jmx registration error: javax.management.InstanceAlreadyExistsException: com.mongodb:type=ConnectionPool,host=localhost,port=27017,instance=28344541 continuing...\nI suppose it could be a hash collision though that seems somewhat far-fetched. Needs more debugging, I can try to figure it out.\nI don't have a use case for multiple instances, it's more like I didn't write the extra code at first to detect duplicates and re-use the Mongo. So then I had each unit test creating its own Mongo, which generates the warning.\nI did fix my code now to keep a map from addresses to Mongo and share Mongo instances.\n. OK, a simple test reproduces it for me. Using that test (which I'll push), if I instrument DBPortPool.Holder to have a count like this:\nstatic AtomicInteger count = new AtomicInteger(0);\n    final int ourCount = count.incrementAndGet();\nThen create tons of Mongo and add some print statements, I get this:\n...\n[testng] Holder hashCode=8204368 id=8204368 ourCount=830\n[testng] Holder hashCode=8204368 id=8204368 ourCount=829\n[testng] Mar 18, 2012 8:42:01 PM com.mongodb.DBPortPool$Holder get\n[testng] WARNING: jmx registration error: javax.management.InstanceAlreadyExistsException: com.mongodb:type=ConnectionPool,host=localhost,port=27017,instance=8204368 continuing...\nSo it looks like it is a hash collision. I googled around and someone claims that Object.hashCode may be based on the object's location when you first call hashCode on the object, and the GC may move the object around. So that could explain it, both objects are in the same place when hashCode is first called, but they aren't in the same place at the same time - one of them was moved. Or something. (If either had been finalized that would be the simple explanation, but they haven't been as best I can tell.)\nIf I change to use the \"ourCount\" instead of hashCode in the mbean name, the problem is fixed.\n. Unfortunately the unit test sort of sucks since \"pass\" is to not log a warning and \"fail\" is to log a warning, and the test never actually fails.\n. Done\n. ",
    "holyjak": "It would be perhaps even better to include some tips how to fix the problem? F.ex. if the problem is that the driver is talking to a slave and hasn't been allowed to do so then the exception should tip the user about it:\n\"Connected to a slave Mongo instance but (reading from|writting to) a slave isn't allowed (set slaveOK if you want to allow it.) \" + \n. ",
    "killme2008": "@jakubholynet \nMuch better if you can give some tips about the problem.But i don't know if there are other situations exists that make this exception happen except set slaveOK to be true.\n. If we have some tips is better,but i think the driver at here should not eat the error message from the server.\n. ",
    "benmccann": "@trishagee going over all the exceptions is a great strategy! however, in the meantime, this causes a lot of pain and the pull request would be a nice stop gap. this doesn't change the exception type, but only adds useful missing information to the exception message, so i don't see the downside\n. It was massively confusing to me whether DB was deprecated or just Mongo.getDB. I think this makes it clearer to users what the intended path forward is.\n. Adding the note to DBCollection and DBCursor wouldn't be a bad idea. Do you mind if we go that way instead? The thing that really threw me was that there's nothing on these classes at all to indicate that they're deprecated.\n. ",
    "dgottlieb": "I like the idea that Enum support is only exposed via the ReflectionDBObject. This patch looks good to me, though I wish the OnlineTest didn't stop short on actually testing the values that were read back out from the DB.\n. Thanks for the bug catch. I'm sorry for any inconvenience it caused. This is definitely a cleaner function; once again taught me to not be cute with recursion. I did have to touch the new skip method to null out _data when skipping past the end of the GridFS File such that subsequent reads would return -1. I also took the liberty of modifying the existing test to skip the first byte (when _currentIdx = -1) instead of reading it. The tests look good now.\n. ",
    "ymind": "I'm so sorry! This is my mistake, I had fixed these problems, please check it.\nI'm a newbie for java, thanks for your guidance!\n. ",
    "skripalschikov": "ping\n. ",
    "daizw": "Great! Now everything looks perfect, ;-)\n. ",
    "trnl": "I've cleaned build.xml file.\nIntroduced set of properties instead of hardcoded dirs:\n<property name=\"build.dir\" location=\"${basedir}/build\"/>\n<property name=\"build.main.dir\" location=\"${build.dir}/main\"/>\n<property name=\"build.test.dir\" location=\"${build.dir}/test\"/>\n<property name=\"build.util.dir\" location=\"${build.dir}/util\"/>\n<property name=\"build.instrumented.dir\" location=\"${build.dir}/instrumented\"/>\n<property name=\"build.logs.dir\" location=\"${basedir}/logs\"/>\n<property name=\"build.docs.dir\" location=\"${basedir}/docs\"/>\n\nRemoved test-single. Now if you need only one test - just pass the -Dtest.classes=BSONTest\nant test -Dtest.classes=BSONTest\n\nRemoved testng.xml and test-single.xml. Using classfileset to specify tests\n<classfileset  dir=\"${build.test.dir}\" includes=\"**/${test.classes}.class\" />\n\nChanged test-jenkins-coverage to coverage-instrument and coverage-report.\nIf you need html report - just pass the -Dcobertura.format=html\n. What can be added:\nRight now all jars are being put to ${basedir}. I suggest to put them into ${build.dir}/dist. As I can see in maven/build.xml this is being done by default.\n<copy tofile=\"build/dist/mongo-java-driver-sources-${build.conf.lib.version}.jar\" file=\"mongo-sources.jar\" overwrite=\"true\" filtering=\"false\"/>\n<copy tofile=\"build/dist/mongo-java-driver-javadoc-${build.conf.lib.version}.jar\" file=\"mongo-javadoc.jar\" overwrite=\"true\" filtering=\"false\"/>\n<copy tofile=\"build/dist/mongo-java-driver-${build.conf.lib.version}.jar\" file=\"mongo.jar\" overwrite=\"true\" filtering=\"false\"/>\n<copy tofile=\"build/dist/bson-sources-${build.conf.lib.version}.jar\" file=\"bson-sources.jar\" overwrite=\"true\" filtering=\"false\"/>\n<copy tofile=\"build/dist/bson-javadoc-${build.conf.lib.version}.jar\" file=\"bson-javadoc.jar\" overwrite=\"true\" filtering=\"false\"/>\n<copy tofile=\"build/dist/bson-${build.conf.lib.version}.jar\" file=\"bson.jar\" overwrite=\"true\" filtering=\"false\"/>\n. @jyemin  please take a look\n. Created a single commit and pushed to master: a454aafa82de91c651215936cdfdac95311cb519. \nThank you @prakapenka for you help!\n. @calebjones I've added your tests to 3.x branch. They are working there.\nLet's fix it here too.\n. @calebjones any chance to look at it?\n-vova\n. @calebjones,\nI just found that JAVA-794 marked as duplicate of JAVA-820 and both of them marked as fixed. Also I can see that testDotKeysListFail from you pull request is passing for current HEAD. \nSo because of this pull request can't be actually a solution for JAVA-794, can you please create a new ticket in Jira for a bug shown in testDotKeysArrayFail?\n. Created JAVA-873.\n. Will be fixed in 3.x\n. Hmm, looks like we can close it.\n. Thank you for noticing this!\n-vova\n. Hello @jvmisc22 ,\nThank you for your pull request!\nSadly, I can't merge it for now - we are working on the 3.0 driver, and we don't want to add additional functionality to the old codebase.\nAlso there is a related ticket: JAVA-806. Can you please vote for it in JIRA and we will consider adding it for 3.0.\n-vova\n. Thank you for pull request, @nlloyd!\nSorry, but I can't merge it for now - we are working on the 3.0 driver and I don't want to introduce possible backward compatibility breaking changes in 2.x.\nAlso I've found that your test is not entirely correct. If you check badrefs.count() after calling evals - you'll find 0.\n-vova\n. ",
    "tedyoung": "Any reason this pull hasn't been merged? Some of the javadoc here would've helped me when getting started.\n. ",
    "phil-schneider": "Thank you Francesa, I sent you an email (different address, but same domain). Please make sure the pullrequest gets into the actual code in one of the next releases, because this is a missing feature of the driver and the spring-data-mongo project needs this to fix an request on their side. Thanks\n. Yes I will, but it will take a while. I will do this over the holidays\n. @jyemin I added two test for it.\nIs it ok like this? Do you want more?\nIs it enough to accept the pull request and include this in the mongoDB source code?\n. Thats actually true. I was just focused on improving the sort sort function.\nI will fix it\n. Please see new version here:\nhttps://github.com/phil-schneider/mongo-java-driver/commit/b9fd84288cbe17238423a3a95dfe065a4e6a7fed\n. ",
    "seanjreilly": "No problem. The reason I bunched the two commits into a single pull request is because github seems to only allow one pull request per fork/branch combination to be active at a time. The second commit didn't seem big enough to warrant its own branch on my repo. But if that's how you'd prefer to receive them, I'm happy to submit each commit as a separate pull request.\n. ",
    "mutyonok": "Hi Jeff,\nPlease see the changes, hope now it's good to merge.\nWhen do you think you will able to release them?\nAnd thanks for super fast response!\n. will try to commit changed code today or tomorrow\n. Hi Trisha,\n1) First of all I Stack is built on top of Vector and is synchronized and obsolete, I used LinkedList because it implements Deque interface in Java 6 (easy to port on java upgrade) and the main thing is that in org.bson.BasicBSONCallback nameStack is also LinkedList, so I decided to be consistent with the parent class.\n2) I'll change the names of variables today.\nHope you will find my objections to the first question to be reasonable.\nHope to hear from you soon!\nAlex\n. ",
    "sjoerdmulder": "Yes, it is / was auto generated... Actually had an issue with map.containsKey() logic that was boiling down to this issue.\n. ",
    "juanlmelo": "Ok, I will add a unit test\n. ---\nT E S T S\nRunning TestSuite\nConfiguring TestNG with: TestNGMapConfigurator\nTests run: 372, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 106.922 sec\nResults :\nTests run: 372, Failures: 0, Errors: 0, Skipped: 0\n[INFO] ------------------------------------------------------------------------\n[INFO] BUILD SUCCESS\n[INFO] ------------------------------------------------------------------------\n[INFO] Total time: 1:55.348s\n[INFO] Finished at: Sat Apr 27 11:45:08 MST 2013\n[INFO] Final Memory: 14M/330M\n[INFO] ------------------------------------------------------------------------\n. I suppose you haven't had requests to natively implement JNDI because most of the programmers tend to think that JNDI is useful in the following cases:\n1) Relational dabatase connections (JDBC)\n2) Custom application settings (configuration POJO's)\nAnd probably never thought to integrate a nosql database with JNDI which is highly understimated, remember that recommended usage of com.mongodb.MongoClient is as a singleton which is the default JNDI instantiation type of most containers like tomcat.\nI consider this change could be useful in the following cases:\n```\n1) For users creating webapps who want to leave mongo configs outside of their WAR file. This will allow them to promote the same WAR file thru all the different deployment stages like dev/Qa/Prod since context.xml can live outside of the application package.\n2) For users who want to ensure a single MongoClient instance will be used through one or many applications, since it can be configured as a GlobalResource for more info see http://tomcat.apache.org/tomcat-7.0-doc/config/globalresources.html\n3) For enterprises which are looking for a clean way to configure mongodb and support sharded layouts(It's based in MongoClientURI). a use case: Preventing developers from accessing production URIs.\n```\nLast year, I successfully implemented a very similar solution for my previous employer and has been running in production without any problems since then. My guess is that you won't get much bug support requests since users are responsible for doing the lookup and resource configuration, this change is only for the instantiation part.\nBelow is a servlet example and configuration I just tested:\n```\npublic class MyServlet extends HttpServlet {\nMongoClient _mongoClient;\n\n@Override\npublic void init() throws ServletException {\n    super.init();\n    try {\n        _mongoClient = (MongoClient) new InitialContext().lookup(\"java:comp/env/mongodb/MongoClientJndi\");\n    } catch (NamingException e) {\n        e.printStackTrace();\n        throw new ServletException(e.getMessage());\n    }\n}\n\npublic void doGet(HttpServletRequest request, HttpServletResponse response) {\n    PrintWriter out = null;\n    try {\n        out = response.getWriter();\n    } catch (IOException e) {\n        e.printStackTrace();  \n    }\n\n    out.println(_mongoClient.getDatabaseNames());\n}\n\n}\n```\ncontext.xml\n```\n<?xml version='1.0' encoding='utf-8'?>\n\n\n\n```\nResult in http://localhost:8080/MongoSample/myservlet\n[admin, DBPortTest1, DBPortTest2, local, queryBuilderTest, results, DBPortTest3]\nI think that as users get more familiar with mongo java driver they'll sooner or later start asking for JNDI support.\n. ",
    "green-coder": "Note: As someone pointed on JIRA, \"The signature change would not be binary compatible\".\nMaybe the old signature could be kept.\n. ",
    "aakhmerov": "The rot cause is that Mongo instantiated as Mockito mock object. Mockito is using http://objenesis.googlecode.com/svn/docs/index.html project to bypass constructors defined in the class and create plain instance of the object without invocation of any constructors code. \nIn my opinion, it would be an overkill to try to handle such use cases, however desire to mock Mongo object itself is totally legitimate. I would go for changing methods signature to protected, not package private and  appropriate null pointer handling in default implementation. \nLet me know if you want me to go deeper in objenesis library and see if there is a way to force defined constructors execution. \n. We can at least start working on it. I can try to refactor methods and fields to protected values and prepare several unit tests to illustrate resulting mocking process. Or follow your directions.\n. ",
    "calebjones": "I didn't see any published requirements for modifications to the README.md contributors list, so I took the liberty and added myself to that list as part of this pull request. If there's some extra set of criteria for doing so, just ignore that modification.\n. I'll take a look tonight.\nOn Jul 2, 2013 8:10 AM, \"Trisha Gee\" notifications@github.com wrote:\n\nHi Caleb, sorry for the delay in responding. In fact, it's so delayed that\nI can't automatically merge your pull request. Is there any way you can\nupdate it to work on the current code?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo-java-driver/pull/115#issuecomment-20351765\n.\n. American holiday festivities took over earlier this week. Does earlier this\nweekend or early next week work?\nOn Jul 5, 2013 1:18 AM, \"Uladzimir Mihura\" notifications@github.com wrote:\n@calebjones https://github.com/calebjones any chance to look at it?\n-vova\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo-java-driver/pull/115#issuecomment-20506175\n.\n. \n",
    "grossws": "Is this dropped later by accident in current MongoClientURI or collection will be dropped eventually from it?\n. ",
    "subnetmarco": "I currently have this problem and a fix would be highly appreciated. Here's my stack trace:\ncom.mongodb.MongoException$Network: IOException authenticating the connection \n        at com.mongodb.DBPort$NativeAuthenticator.authenticate(DBPort.java:552) \n        at com.mongodb.DBPort.authenticate(DBPort.java:322) \n        at com.mongodb.DBPort.checkAuth(DBPort.java:333) \n        at com.mongodb.DBTCPConnector.innerCall(DBTCPConnector.java:243) \n        at com.mongodb.DBTCPConnector.call(DBTCPConnector.java:216) \n        at com.mongodb.DBApiLayer$MyCollection.__find(DBApiLayer.java:288) \n        at com.mongodb.DBApiLayer$MyCollection.__find(DBApiLayer.java:273) \n        at com.mongodb.DBCursor._check(DBCursor.java:368) \n        at com.mongodb.DBCursor._hasNext(DBCursor.java:459) \n        at com.mongodb.DBCursor.hasNext(DBCursor.java:484) \n        at org.mongodb.morphia.query.MorphiaIterator.hasNext(MorphiaIterator.java:43) \n        at org.mongodb.morphia.query.QueryImpl.get(QueryImpl.java:408) \n        at org.mongodb.morphia.dao.BasicDAO.findOne(BasicDAO.java:235)\n. ",
    "nathanvda": "Wow! Travis is awesome :)\n. No problem :) I was trying to understand the code,  and just suggested an improvement while maintaining the same functionality. \n. ",
    "fernandezpablo85": "\u00af(\u30c4)/\u00af\n. Also, annotated tests will run no matter what, don't need to prefix them with \"test\"\n. ",
    "lawrencediao7": "anytime!\n. ",
    "davydotcom": "rechecked this, actually looks ok. Either way shouldnt be filling the pool with new connections on a gotError so this still resolves that.\n. Adjusted PR Description critical bug found with a semaphore leak.\n. saw contribution notes, gonna close this until tests are in place.\n. ",
    "leifwalsh": "forgot pull requests go to the original repo :(\n. ",
    "drmirror": "Did some more work on that javadoc. Closing this push and opening a separate one.\n. ",
    "rozza": "Should have been in driver not driver-compat\n. I see what you mean, I was trying to reuse the DefaultClusterableServerFactory and as MongoClientOptions is a companion for creating a cluster I thought it made sense to reuse that class as well rather than replicate it.  You used to be able to do that but recent refactorings have stopped that being the case.\nI'm happy to implement my own version, especially if it wasn't the intent to make MongoClientOptions usable for 3rd party libs.  Perhaps we should update driver-compat so it doesn't use it either (currently it proxies it) then it can be a reference implementation of building your own driver implementation on top of the core driver.\n. Refs: JAVA-902\n. Casbah has two wrappers for GridFS - the main just adds on custom handlers to accept scala streams etc.\nThe other handles GridFS for use with JodaDateTime / JodaDateTime.  \nNormally the transformers would handle this transparently, but with GridFS this is not the case and we have to override the put method to convert and JodaDate's into native Java Dates so not to fall foul of type checks on certain fields.  That covers 90% of the requirements but leaves an edge case. \nThe edge case found in SCALA-113 was that GridFS requires uploadDate to explicitly be a Date and the check for this occurs after any registered transformers.  Which in that case converts Date objects to JodaDate and then causes GridFSFile to fail.  Allowing the user to setGridFS means that when iterating a GridFSDBFile I can set the correct underlying implementation of GridFS file and not fail the type checks for uploadDate.\n. Closing - in casbah we still can override setGridFS and use the super to set the db.\n. The new GridFS implementation allows for arbitrary metadata via a {{Document}} which has this functionality.\nThe legacy implementation is effectively deprecated as such I'm closing this ticket.\n. Apologies - for the lack of recent feedback.  The new GridFS implementation allows for arbitrary metadata via a {{Document}} which is an implementation of a Map and should meet your requirements.\nThe legacy implementation is effectively deprecated as such I'm closing this ticket.\n. Hi, apologies for not coming back to this ticket sooner.  As you can see there has been masses of work and improvements to the driver and this code no longer can be merged.\nThe new 3.x series allows for custom Document types so its possible to add your own implementations.  The DB/DBCollection code path and DBObjects have been deprecated in favour of MongoDatabase/MongoCollection and Documents.  The new Document class is an implementation of Map<String, Object> and there are currently no plans to extend it.  However, it is possible to add your own types and codecs should this feature be needed.  See the bson documentation for more information.\n. @jyemin I've merged in your changes and responded to the inline comments.\nMy formatting rules should be the same - as I had the defaults and then replaced all of them with the ones given.  Although I have noticed it can be quirky at times and I shied away from doing full file reformat codes for fear of adding noise.\n. Looks good - couple of questions / comments.\n. :+1: :shipit:  :)\n. Closing - already merged\n. Thanks @dwursteisen for the PR\n. I've also updated the gradle build file to explicitly set charset and docencoding to UTF-8\n. Fixed the issues rebased and merged.\n. Looks good :)\n. Merged\n. lgtm\n. Updated as per comments and merged.  Added JAVA-1200 in regards to the blocking.\n. Moved and merged :)\n. Apologies for not coming back to this ticket sooner, I'm pleased to say this functionality was added in the 3.x series of the driver and your contribution help make it so!  Many thanks.\n. Updated to copy()\n. Parking for now.\n. Merged into 2.12.x\n. Thanks @tgrall when the Querybuilder comes into sprint we review fully.\n. Removed isCapped and getStatistics from the api\n. Rebased and merged\n. I'm looking forward to the walkthrough to get a full understanding as this is quite epic.\nI agree with @trishagee regarding BSON values naming - I'd also like to see it consistent going forward :) I'm confused by the naming conventions - when is it right to use BSON over Bson? It caused my ocd to :scream:  but I'm guessing theres a reason :)\n. NettyStream now follows the the AsynchronousSocketChannelStream and blocks on first\nwrite or read.  NettyStream does follow connectTimeoutMS unlike AsynchronousSocketChannelStream\nas this blocks for an undefined amount of time:\nchannel.connect(serverAddress.getSocketAddress(), null, new CompletionHandler<Void, Object>() { .. }\nThis could be mimicked with:\nFuture<Void> futureConnection = channel.connect(serverAddress.getSocketAddress());\nfutureConnection.get(settings.getConnectTimeout(MILLISECONDS), MILLISECONDS);\n. Anything more to do with Netty?\nAs for AsynchronousSocketChannelStream I can't think of a simple way make channel.connect non-blocking and have a fixed timeout - any ideas?\n. ## Updates:\n- Simplified ensureOpen\n- Added JAVA-1265\n- Applied settings to AsynchronousSocketChannelStream as well\n- Made Travis happy.\nHow I tested:\n\nServerAddress with an unresolvable end point eg (192.255.255.1) - ensured all stream types threw: MongoSocketOpenException\nSet ServerAddress to a mongodb and set ipfw to add a delay \n   2.1 Set connection timeout to be 1ms and check got a MongoSocketOpenException\n   2.2 Set read timeout to be 1ms and ensured I got a MongoSocketReadTimeoutException\n\nTodo\nWrite timeouts: Default sockets just have a single timeout (the read timeout) but Async can differentiate between read and write timeouts - should we add a writeTimeoutMS setting?\n. Added check to operationComplete.\nAdded JAVA-1269 for write timeouts - I was incorrect and normal sockets don't support them, so no need to add handlers to the async versions.\n. Updated and fixed the findbugs issue - travis is backed up but should come back green :)\n. Rebased and merged\n. Couple of nits I noticed today: \n- BSONWriter / BSONReader code comments need updating to the new format, the spec test should be renamed as well.\n- BSONType  method names need updating eg: readBSONType()\n- PrimitiveCodecs mentioned in the comments of BSONDocumentBufferCodec\n. @dbuschman7 many thanks for the pull request your contribution is appreciated. GridFS is on the backlog for 3.0.x and when it comes into sprint we will review your code.\n. One question outstanding.  Should we call kill cursor on an exhaust cursor? What happens if a user stops the block mid iteration?\n. So in #208 we need to make sure thats still true? \n. That makes it much cleaner and simpler \n. This good to merge?\n. Closing in favour of #208 \n. Updated as per review but parking as need to be able to work with JAVA-1268 \n. LGTM\n. Updated - read support only\n. Merging read support in 2.12.x\n. Reworked so WriteResult doesn't need changing.\n. Done\n. Done\n. Rebasing and merging.\n. 1. Added perserveNumericTypes.\n   I added static helpers to the settings as the indented helper took a boolean and then ignored it and now we have two settings that take a boolean.\n2. Parsing is in driver-compat. Not sure how best to configure / support settings for serialisation.\n. Updated - ready for review.\n1. added JsonMongoDBVersion and a builder for JsonWriterSettings \n2. added $numberLong support for com.mongodb.util\n3. remove JAVASCRIPT and TEN_GEN modes.\n. Parking whilst waiting for a decision on SERVER-6812\n. Cherry picked the removal of TEN_GEN and JAVASCRIPT modes 5142e18de1552d0238b6042fba1e7ec7b5431c4f\n. ok cool\n. Will add com.mongodb.util.JSON support in another PR\n. Merged\n. Merged\n. I added a little more info in Jira - but the cause and subsequent fix are based on observation.  I don't know the reason why creating the CompletionHandler inside the AsyncCompletionHandler triggers the IllegalAccessError on the vert.x reload but it does.  Setting it outside as a final var stops the issue.\n. I've tried to recreate (https://gist.github.com/rozza/df88df8beef83aaed06d) but no joy dynamically recompiling and reloading a class doesn't trigger it - so it seems to be an issue with Vert.x reloading mechanism.\n. Out of date\n. Merged\n. Merged\n. lgtm\n. Done merged into 2.12.x \n. Excellent - closing then\n. Closing - added docs and rebased.\n. Closing, much has changed since this initial patch with the new 3.x series of the driver.  As such this no longer can be applied cleanly.\n. Hi @hoffrocket apologies for taking so long to review and action this pull request.  We are looking to fix in 2.13 but I have a question - have you seen E11001 (update) errors take this form? I cant replicate an update on shard that would trigger it.\n. Thanks @hoffrocket we used this pull request as the basis for a fix in master and on the 3.0.x branch\n. Closing as lots has changed since writing this\n. Hi @philnate thanks for the pull request.  Looks interesting - I'd really like to see an example use case - a test example would be best as it helps ensure we have adequate code coverage.\nAlso, I noticed travis picked up a checkstyle nit, you can run the tests locally like so: \n./gradlew clean check or a specific project (bson) like so ./gradlew clean :bson:check\n. Added a Jira ticket JAVA-1357 to ensure its ported into 3.0.x as well.\n. Thanks @neerajbhatt this has now been squashed, merged and ported!\nMerged into master: https://github.com/mongodb/mongo-java-driver/commit/a965d3900d3730c84bdb23b138439af6ab4215e9\nPorted to 3.0.x : https://github.com/mongodb/mongo-java-driver/commit/0b2734a76536ecfdcbbba2b3a35496410ae87566\n. Had a look through your branch and the commits - looks good.  Theres too much noise to accurately review but we can iron any resulting issues out once this and the subsequent migration commits are merged\n. Thanks again @stevebriskin I also added the reference links as @trishagee suggested.\n. Thanks @guoyr - squashed and merged in 992fa34b87328fea2a489a112804ecff6b42bc58\n. Apologies for not coming back to this ticket sooner.  JAVA-805 is still open and followups should be continued there.\n. @jyemin ready for review\n. Updated - I suppose if the server changes default we can deal with then!\nThe only test case I could think of would be testing the command document created for the options given - is that worth it\n. @jyemin this ok to merge?\n. Updated\n. Squashed and merged\n. Squashed and merged\n. Some small nits - looks good.\nFor final on variables / interfaces can we checkstyle that?\n. LGTM \nI have one newbie question does changing the method variable names impact binary compatibility?\n. @jyemin & @trishagee  ready for review\n. good call - fixed, rebased and merged\n. lgtm!\n. Note: In ee73e78d748c0873816fd240ad8d92e0e2d4b816 and aa91d7baed39602f43d318b9d2f0d63453bc4dbc I mistakenly flagged the JIRA tickets as JAVA-1255 not JAVA-1215\n. Code review comments:\n- Inconsistent use the asbson helper in the collections\n- Models aren't to spec as we have extra options classes which in the spec are on the Model classes themselves.\n- Model options which take Object but in use are only ever typed to BsonDocument - seems wrong.\n- The NewMongoCollection interface isn't to spec eg: find - can be empty, a clazz or findOptions but the spec says it should take FindModel.\nObservations:\nFor Models we have option classes that have mutable builder style helpers.\nFor operations we have both option classes but they have have builders and immutable data structures (eg Index and ParallelScanOptions).  And we have moved away from option classes in operations and now store the data in the operation class and have added mutable builder style helpers.\nI'm not sure I like the inconsistency\n. FYI I've rebased fixed the commit messages and put all commits ontop of current 3.0.x in: https://github.com/rozza/mongo-java-driver/tree/crud-ontop\n. This has been added to, replayed on top of 3.0.x and merged.\n. Thanks @smola for the pull request - will add to the backlog and review in due course.\n. Many thanks @smola - I used your pull request and commit 2b3e75433aaa26e24f95fc4a740442581cc09214 as the basis for an equals and hashcode implementation.\n.  Hi, apologies for not coming back to this ticket sooner.  As you may be aware much has changed in the codebase with the new and improved 3.x series.\nThe DB/DBCollection code path has been deprecated in favour of the new MongoDatabase/MongoCollection path.  Bulk operations now follow the CRUD spec.  And for those reasons I'm closing this ticket.\n. Have updated.\nNow mechanismProperties is a Map and the GSSAPI authenticator parses the string for canonical host names.  An alternative might be to make ConnectionString aware of mechanism property types - but that seemed the wrong place to store that information.\n. Reverted changes to MongoCredential and now ConnectionString handles the conversion of CANONICALIZE_HOST_NAME to boolean.  \nInvalid pairs in authenticationMechanismProperties now follow tagSets and throw IllegalArgumentException.\n. Rebased and merged\n. LGTM\n. lgtm\n. Hi, apologies for not coming back to this ticket sooner.  As you may be aware much has changed in the codebase with the new and improved 3.x series.  This ticket can no longer be merged, so its being closed.\nCurrently the standardized way of dealing with multiple hosts in a string is to use a connection string.  Adding an alternative way is not currently planned, as it simple enough to do with a quick loop.\n. @nscavell thanks for the ticket and pull request - will review shortly.\n. Many thanks @nscavell I rebased and applied to RX as well.  FYI I'll be working on normalising the api's for the async versions this week.\n. Looks much better - a couple of comments:\n-  the tests seem to have been knocked by the accidental deletion in InternalStreamConnectionSpecification.\n- Why delete / not update the equals methods\n- Regression test for valid ObjectName names\n. LGTM!\n. Thanks @fmela I've merged to master\n. Minor convention nit - but LGTM\n. Thanks for the pull request, could you please also provide a test case for the new code?\n. Hi, apologies for not coming back to this ticket sooner.  As you may be aware much has changed in the codebase with the new and improved 3.x series.  This ticket can no longer be merged, so its being closed.\nI'm pleased to let you know 3.x now supports timezones in json strings!\n. Hi, apologies for not coming back to this ticket sooner. As you may be aware much has changed in the codebase with the new and improved 3.x series. This ticket can no longer be merged, so its being closed.\nIn 3.x JSON.parse is effectively deprecated and Document.parse or BasicDBObject.parse is preferred.  These new methods will throw an exception with the invalid json.\n. I'm not sure I would have removed junit in the same step, seems a lot of work on the tests - which are only tangentially related to the build / release process but thanks for doing it.\nI think Travis failed on a couple of tests and I saw a newline nit on bson/build.gradle - but other than that LGTM\n. ## Todos\n- [x] Make listCollections & listIndexes fluid - so can set the batchSize from the client api and to help be future compatible.\n- [x] Support MaxTimeMS\n- [x] Test batchSize in listCollections & listIndexes - can we do an initial batchSize (0) and then change it?\n- [x] Add Tests for listCollections* - to ensure its covered in async\n. Have pushed an update - was more in depth than I initially thought but we now support batchSize and maxTimeMS.\nWe currently force the listCollection & listIndex methods to read from primary but the spec says:\n\nDrivers MUST run listCollections on the primary node in \"replicaset\" mode, unless directly connected to a secondary node in \"standalone\" mode.\n\nI'm not sure how best to achieve that, the operation however just uses the passed in readPreference - so I'm hoping thats acceptable.\n. I did a some what painful rebase onto 3.0.x and actioned all points in aea41f4 \nI updated FindFluentSpecification as thats where I based the fluent specs from and also added unit tests to check results for the various interfaces to ensure they handle the canned data as expected.  The Operation Specs themselves will handle any logic in execute based on server version and the acceptance tests / smoketest also test that functionality.\n. Ready for review again @jyemin :)\n. Rebased and merged\n. Hi, apologies for not coming back to this ticket sooner. As you may be aware much has changed in the codebase with the new and improved 3.x series. This ticket can no longer be merged, so its being closed.\nThe DB class was deprecated in 3.x and the MongoDatabase interface is now the preferred way to interact with the database.  However, the implementations of MongoDatabase are purposely private.\n. Hi, apologies for not coming back to this ticket sooner. As you may be aware much has changed in the codebase with the new and improved 3.x series. \n@st-h I think your PR is great and would like to thank you for your contribution and the time you spent publishing it.  As a a drivers team we are continually trying to ensure we improve and standardize across all the drivers.  The outcome of which has been a new GridFS specification which introduces a new API. The sync driver already has an implementation of this new spec and I'm currently working on the async version (JAVA-1282).  For that reason I'm having to close this ticket.\n. @st-h its still in progress at the moment but unfortunately its not going to make the 3.2.0 release.  So will be in the following 3.3.0 release.  \nI'll update this ticket once its available in a 3.3.0-SNAPSHOT.\n. Hi @tkgreg the test case should be submitted as part of the pull request - this way we can see intent, keep the test coverage up and ensure there is a regression test as part of the codebase.\n. I'm closing this pull request, as the related jira ticket has been closed as \"fixed\" - thanks to the changes in  the 3.0. series.\n. Thanks @ankon !\n. I really like the builders!\nWithout implicits this seems verbose but its way better than raw objects!  I think we could improve upon it.  Are we expecting the user to supply a different type to Sort or Projection than they supply to asFilter(T document)?  \nI'm not sure we do in the tests, we currently let the user do that, but should we support it? Or do we think it's better to force the user to wrap all their types in asFilter() asSort(), asProjection() because it provides ultimate flexibility, at some cost usability?  In essence asFilter() is just a helper just to convert type T => BsonDocument.\nWhat if we added a constraint and stopped supporting a mixture of types for all cases? We could simplify all of this by making MongoCollection take two types:  MongoCollection<TCollection, TDocument>\n-  TCollection could be the thing the collection stores People, Workers, Documents etc\n- TDocument would be the document like type we use for defining filters, sorts, projections\nThat way users wouldn't have to wrap everything in asFilter(), asSort(), asProjection() just to create the BsonDocumentWrappers we could do it for them.  If they wanted to mix types they could still do this but they would either have to wrap themselves or we we could make some special TDocument  type that mirrors what asFilter() does has a generic name and can be used everywhere where we use object now - basically making creating a BsonDocumentWrapper a doddle.\nI think we should look to help the common case the most and I think making the user declare a type could be the simplest approach.  Although I'm sure I've missed something..\n. Couple of questions inline - but overall it looks good.\n. Also I saw on #294 your comment about the name - my vote is for: ConvertibleToDocument Document to me is strong enough concept that we could just document the interface that we mean BsonDocument  either way naming things is hard!\n. LGTM\n. This the one in codereview?  I reviewed there but also fixed it up in https://github.com/rozza/mongo-java-driver/tree/j1569-2\n. This work has been refactored, rebased and merged into master.\n. Hi, apologies for not coming back to this ticket sooner.  This is similar #282 but because 3.x JSON.parse is effectively deprecated, I'm closing this ticket.  Some users may be relying on this behaviour.\nThe good news is BasicDBObject.parse, Document.parse and BsonDocument.parse will throw an exception with the invalid Json - so those methods should be preferred.\n. Thanks @kay-kim \n. Hi, apologies for not coming back to this ticket sooner. As you may be aware much has changed in the codebase with the new and improved 3.x series.\nAs this ticket interacts with the legacy and effectively deprecated GridFS implementation I'm closing it.  There is a new GridFS spec which doesn't have a remove(query) method, due to complexities that can happen if there were to be an error when deleting the data.  \nIf you feel this is a mistake and it should be included for all drivers - then please can I ask you to open a Drivers ticket?\n. LGTM\n. Thanks @xcoulon \n. Looking good.  Comments are:\n- I find the CRS parts confusing - why only 3 named systems?  Do we support different CRS systems, Does it impact storage internally and can you use multiple systems and query them?  Very confusing.\n- I found some error message to hard to decipher so suggested alternatives.\n- Groovy files seem to be missing newlines - you might want to tweak intellij to auto add on save.\n- Also, its much easier to use multiline strings rather than concatenate them in the tests ;)\n- Missing documentation!\n. :+1: \n. Currently failing checkstyle.\n. Looks great, I like the documentation.  Is it worth mentioning that the helpers don't validate the document that is built but rather build document as requested.\n. Yes or an unsupported $not query etc..\n. Thats fine, but a note in the documentation as well wouldn't hurt either.\n. Hi @stevenbenjamin looks like its still failing on travis - this time it looks like its the check style rules.\nAre you ok to fix? It'll probably be worth squashing and rebasing into a single commit.\nThanks Ross.\n. Many thanks Steve. I cherry-picked and merged 024e94a222301295f69fc1f2d4a9f7211c019edd.\n. Updated to fix findbugsTest issues\n. Done\n. More updates @jyemin @evanchooly \n. Squashed, rebased and merged\n. Thanks for the PR @MorrisLaw - the _varName is an existing convention for private variables in some of the legacy parts of the codebase and as its used elsewhere.\nAlthough we may no longer follow this convention in the new parts of the codebase, for legacy parts we are happy to maintain the existing convention.\n. Thanks @MorrisLaw  - I updated the exception based on your PR, but left the toString() method as is.\n. Thanks @OzMolaim!\n. @kgignatyev the class has effectively deprecated, in 3.0 Mongo.getDB was annotated as @Deprecated so all code under is effectively deprecated.  Theres no need to annotate every class as that would be painful for legacy users of the API.\nThinking about it I would prefer the Mongo.getDB documentation be clarified rather than DB as that seems to have been the source of the confusion.  Anyone using getDB will have a deprecation warning and that tells users to use getDatabase.  I'm not sure we need the note in the DB class because if we need it there then shouldn't we have it also on DBCollection and DBCursor?   \n@benmccann what do you think?\n. Having discussed this further with the team, we don't have current plans to mark DB, DBCollection, DBCursor and others under that code path as deprecated.  We will continue to fully support those classes during the 3.x series of the driver.  Once a final timeline has decided for 4.0 we will then look to annotating and deprecating classes under DB.   \nAt this present time, we will continue to advise users and 3rd party libraries to continue adopting the new API.  I've reopened JAVA-1858 to help improve both the documentation and API docs for the forthcoming 3.1 release.\nMany thanks @benmccann for being patient and persevering with this.\n. Thanks @grossws\n. Thanks @grossws \n. Closing as per @evanchooly 's explanation.  \nThe artifacts are also published on Maven Central making this not required for non -SNAPSHOT releases. The docs do include information for how to setup for snapshots in the same style as you've included.\nSometimes it can take a few minutes for sonatype to sync to maven central which may have been the reason you needed to manually add sonatype coordinates. \n. The downside to this is it floats the nav items which then wrap on a smaller screen (when in fact we probably should just hide them).\n. Merged in: 39c8691e6250a107551465c943b8f91c0d7ec136\nAdded hidden-xs to topRight.html in 0cc1f7018d16621fe13c56fddcab64128282ffe0\n. Thanks @m-vojvodic !\n. I'll add some window resize logic - its not going to be indicative of a mobile experience as they wont be able to resize past the set minimum.\n. Should be better now - will need to hard refresh to get the latest script.\n. The difference should be that the menu toggle works on small screens.\n. Rebased and merged\n. Updated\n. Rebased and merged\n. Thanks @ralscha this has been merged!\n. Thanks @ralscha this has been merged!\n. Once you are happy that its also listing 2.14.0 on the landing page its a LGTM.\n. We should be able to use the apiref helper - so we dont have to change urls for the apidocs.\n. We had to add extra options for the java doc including tracking - that should solve it:\nSee: https://github.com/mongodb/mongo-java-driver/blob/master/build.gradle#L89-L110\n. No problems - LGTM\n. I understand you are frustrated @steowens and are venting that frustration, but this really isn't the best way to achieve anything positive.  \nHave you tried emailing the mongodb-user group asking for help on this issue?  We do actively monitor the user group and help users.\nCan I ask you to open a Jira ticket with more specifics about what the API isn't achieving for you?  This way we can work on it to help you and other new users to the API.\nAll the best,\nRoss\n. I'm going to close this PR as well and refer you to my response in #337 \n. Thanks @jamel we used this PR as the basis for the improvement \ud83d\udc4d \n. Hi @mutaherul,\nFirstly, apologies for the lack of response on this pull request. Thanks for sharing your code and creating the pull request. I can see the utility of your builder and hopefully it will be of interest to other users.  However, as its working with the old BsonObject API we have no plans to incorporate into the  driver.  The 3.x version of the driver introduced the new Document and BsonDocument classes as the new preferred way of creating Bson Documents.\nAll the best,\nRoss. @mutaherul I don't believe it can - the hadoop connector still works with the older style BSONObject and BSONEncoders / Decoders.. Hi @vedala,\nFirstly, apologies for the lack of response on this pull request. We've been working hard on the new 3.4 release of the driver.  Please could you resync this to master and I'll look to merge?\nAll the best,\nRoss. Hi @vedala, thats correct as there currently is a conflict in the file preventing the merge.. Many thanks @vedala . Hi @Dufgui,\nFirstly, apologies for the lack of response on this pull request. I like the idea behind your code however, as a drivers team we need to ensure that we are able to interoperate with the different drivers and server tools (such as MongoImport). Because of this I can't consider merging your code into the Java driver. \nHowever, if you feel strongly that the MongoDB Drivers really should support this feature, then I urge you to file a ticket to the DRIVERS project.  If you explain the rational for new feature and the conversions to and from Bson types, then as a drivers team we can best look at the feature.\nAll the best,\nRoss. Hi @Gauravshah,\nI'm going to close this pull request for the reasons discussed above. Feel free to add a ticket to the JAVA project with the suggested improvement.\nAll the best,\nRoss. Hi @andresoviedo,\nFirstly, apologies for the lack of response on this pull request. We've been busy working on the new 3.4 version of the driver.\nIf we implement this ticket we'll have to do it across the various bson document codecs (DBObject, Document and BsonDocument). Because of that I'm going to close this pull request and any follow up will be done in the scope of JAVA-2180.\nAll the best,\nRoss. Hi @gsmet,\nFirstly, apologies for the lack of response on this pull request. Thanks for sharing your code and creating the pull request.  I can see the utility of your code and hopefully it will be of interest to other users. However, as its working with the old DBObject API we have no plans to incorporate into the driver. The 3.x version of the driver introduced the new Document and BsonDocument classes as the new preferred way of creating Bson Documents.  \nHowever, as your code includes the codec (BasicDBListCodec) you can still use that to handle the conversion of Json to and from BasicDBLists without the need for an explicit helper method.\nAll the best,\nRoss. Hi @gsmet,\nFirstly, apologies for the lack of response on this pull request. Thanks for sharing your code and creating the pull request. As you've mentioned there are some tickets open regarding this issue and as a drivers team we need to ensure that we are able to interoperate with the different drivers and server tools (such as MongoImport). Because of this internally we are currently looking at formalising the extended Json specification.  Once this has been completed we'll look to unify in our approach to dealing with Json. \nI'll update JAVA-2185 with progress  in the future.\nAll the best,\nRoss\n. Thanks @vagran this looks good and is something that was previously undecided upon. Your PR has helped us come to a decision that it would be a useful feature!\nI've reopened JAVA-1720 to track this PR and will potentially extend it to cover getArray and BsonDocument as well. I've marked this a 3.3 desired and aim for it to be apart of the forthcoming 3.3 release.\n. I'm closing this PR and the follow up will take place on the JAVA-1720  ticket.. Thanks @xardazz for the PR - I'll make sure we review in time for the 3.3 release.\nWill need to test / support Document and BsonDocument as well.\n. Hi @xardazz,\nFirstly, apologies for the lack of response on this pull request. As a drivers team we need to ensure that we are able to interoperate with the different drivers and server tools (such as MongoImport). Because of this internally we are currently looking at formalising the extended Json specification.  Once this has been completed we'll look to unify our approach to dealing with Json.\nAll the best,\nRoss . Thanks @ekandlen for the ticket and the patch\n. Hi @gsmet,\nAs mentioned in #350 we are currently looking at formalising the extended Json specification. Once this has been completed we'll look to unify in our approach to dealing with Json. I'll update JAVA-2224 with progress in the future.\nI should have thanked you in the previous PR's for your work, they have helped ensure we look at how we deal with JSON across the drivers / server tools.\nAll the best,\nRoss. Thanks @Powerrr!. Conversation ongoing in: JAVA-2230\n. Closing as per JAVA-2230.. Many thanks @squarejaw I have merged into master.\n. Other than the join method - LGTM\n. Many thanks @sunjaec for reporting this.  \nWe've added JAVA-2270 to track the progress. We'll take your patch and add some regression test cases as well.\nRoss \n.  JAVA-2270 has now been fixed and is awaiting release.\n. Please post questions to the mongodb usergroup or stackoverflow and we or the wider community will follow up there.\n. @vedala thanks for the ticket and your work.  We've realised the brittleness in the WorkerCodec implementation around the field order, so we decided not to include it in the documentation. As it could lead others to write brittle codecs.\nHowever, we are working on JAVA-1812 and hope to have a better solution in the future.\nAll the best,\nRoss. Thanks for the PR @tdyas!\n. Closing as per: JAVA-2301. Hi @kazuki-ma,\nThanks for the PR - we may look to upgrade gradle in the future, if the current version doesn't meet our need. We just want to minimise any potential risk by upgrading in isolation to other build changes.\nAll the best,\nRoss. Hi @kazuki-ma just to let you know - we have updated gradle to 2.14.1 in aa82a6de6c34124e0645505b812467d7904a39bb\n. Thanks @grossws for the javadoc update!. thanks @SanderGielisse for the PR!\n. Thanks @Daniel-Dos your PR helped promote this issue for 3.5.0 and hashcode and equals are now in master.. Hi @tomdcsmith,\nCould you add a regression test to JSONCallbackTest and we'll look to squash and merge?\nRoss. Many thanks @tomdcsmith this has been squashed and merged into master!. Thanks @mrbeskin . Hi @chusse3t,\nI can the server ticket for this SERVER-27271 is scheduled for a 3.4.1 release.  \nIn the meantime I can suggest creating a custom BsonDocumentCodec that handles duplicate keys and then use that codec when running your CommandReadOperation.\nRoss. Anything here left to merge?. Thanks @nurkiewicz for the PR. Will review and get back to you.. @jyemin can you also review this PR?. Many thanks @nurkiewicz !. Looking at this PR it was created in error as its a merge of 3.4.x to master and doesn't deal with the issue (JAVA-2437) closing.. thanks @jsonking \ud83d\udc4d . @slothspot - this looks good. Will review and look to merge next week.. Hi @slothspot thanks again for this PR. \nDuring the code review phase, the JVM team thought it would be even cleaner to just add:\nDocument.get('key', defaultValue)\n\nIts analogous to the Map.getOrDefault that was added in Java 8, works for all possible types, keeps the API simple and works well in Java 6 & 7.\nThis improvement will be released in 3.5!. Thanks @almostimplemented !. Thanks @m-vojvodic !. Thanks @Mebur!. Hi @jsonking thanks for the PR.  \nI don't think we should blanket advise to set ulimits to 1024, however, I like the idea of pointing out that they may cause the test suite to fail.  \nSo instead could you update to add a paragraph describing the error and how to fix? It would be good if it linked to the manual: https://docs.mongodb.com/manual/reference/ulimit/ \nThanks again,\nRoss. All good - thanks @jsonking \ud83d\udc4d . Thanks @csarrazi . Fixed the build upstream and now the tests here pass as expected.. Thanks @andyphillips404 for the PR. This will be released as part of 3.5.. Fixed the build upstream and now the tests here pass as expected.. Hi @joankaradimov  thanks for your PR, just to let you know your work formed the base for Unix Domain Socket support. \nI rebased your commits into master d2ff8e12a3352d76a297178f75177d7093295ebe and added MongoConnectionString support in e1680a252ae5122ac77f942eed4625d589d4ec72\nMany thanks for contribution.\nRoss. Thanks @nathanosoares for the docs fix.. Done, docs updated, rebased and merged  \ud83c\udf89 . Thanks @volyx - merged.  The documentation process isn't automatic so the online documentation will be updated in due course.. Fixed in #420 . @ChappIO I'm going to close this ticket, the reasoning for lowercasing has been discussed.\nIf there are specific interop issues with Docker or other container services we are interested to know more. Please follow up either by a post to mongodb-user mailinglist or via a Java jira ticket.\nRoss. Hi @visualage,\nThanks for the ticket. I've added JAVA-2599 to track this issue.\nA property has 3 names:\n\nThe original name of the property \n    (either the field name or the method name (minus any bean conventions get/set).\nThe write name\nThe read name\n\nThis allows for a high level of flexibility over how data is controlled.  Currently, in the context of @bsonCreator the @bsonproperty value relates to the actual property name and not the write name.\nOn reflection using the write name would have been a better choice and I like your backwards compatible approach, so thanks again for the patch. We'll look to incorporate into the next release.\nIn the meantime, you can provide your own Conventions to the PojoCodecProvider to configure these annotations.\nRoss. Thanks @visualage after rebasing and some minor changes - your PR was commited to master: b376aa4648c0fa82842713eba56dfa3ab7623e5d\nThank you for the excellent PR and your work on improving the PojoCodec.. Thanks @visualage for the PR, it looks good.  \nI've added JAVA-2608 to track this.\nRoss. Thanks @visualage after rebasing and some minor changes - your PR was commited to master: 41f8cf0b333d7882a96a8bfb4b10f6dcace45606\nThank you for the excellent PR and your work on improving the PojoCodec.. Thanks @jflorencio,\nThis looks great, I've added JAVA-2612 to track this.\nRoss. Thanks @jflorencio after rebasing and some minor changes - your PR was commited to master: 275513a0ae355039aad81664c23d0c1d5ceb7aa5\nThank you for the excellent PR and your work on improving the PojoCodec.. Hi @jflorencio,\nMany thanks for your PR's for the POJOCodec. Just to give a quick update our focus right now is on driver support for MongoDB 3.6, but this is definitely on our radar to review as soon as our time frees up a bit.\nAll the best,\nRoss. Thanks @jflorencio after rebasing and some minor changes - your PR was commited to master: f525edfb09141b460b68ff7b974ae9099e0fa7fe\nThank you for the excellent PR and your work on improving the PojoCodec.. Hi @bcluap,\nFirstly, thanks for the PR, apologies for the lack of response. We are currently focusing on MongoDB 3.6 features for the upcoming release of the Java driver.  I have some PojoCodec tickets to review in due course and I will review this PR as part of that work.\nRoss. Closing as support for setting collections / maps via getters has been added via a convention.. Thanks for the PR @visualage - this will be release in the forthcoming 3.6.0 release.. Hi @visualage,\nThanks for the ticket. I've added JAVA-2661 to track this.\nRoss. @visualage it would be good to understand more about the error and if it is only triggered when calling tryAcquire(0, TimeUnit) .  Could you provide some more information about triggering this error?. Double checking the RxJava2 thread, it looks like ReactiveX/RxJava#5715 fixes ReactiveX/RxJava#5711- can you confirm @visualage ?. @72MiguelGomes the issue with this fix is tryAcquire() does not respect other waiters on the permit - its greedy. Whereas tryAcquire(0, TimeUnit) does respect other waiters.\nHaving not heard back from @visualage and the belief that there is a fix in RxJava, I think this can be closed. However, please follow up if that is not the case.. @vinssor this doesn't appear to have any commits by you in.  Looks like a PR wanting to merge the 3.6.x branch into master?\nPlease check and resubmit.. Hi @denis-zhdanov,\nMany thanks for your POC. Personally, I like the idea of automating such checks but as we are currently performing minor and patch releases, the risk of adoption is considered too high at this time. \nPerhaps, in the future for a major release, such a strategy may be considered. In the meantime we wish you all the best with your library!\nRoss\n. Hi @thiaguten,\nThanks for the ticket, I agree that error is a better logging level for exceptions caused by callbacks. \nI've rebased and linked the commit to the ticket JAVA-2728.  f4f4977 is now in master and will be released as part of the 3.7.0 release.\nThanks again,\nRoss. Thanks @fhassak . Hi @fhassak,\nThanks for the pull request, can you add your motivation for the change to the description?  What benefit do you see to adding to the API?\nRoss. Ok thanks @fhassak . Thanks @robrua,\nI reworded your commit (bb07462) to link to the jira issue: JAVA-2756.  When adding a test case I realised we had to handle decoding and I noticed Map values had the same issue (e38c3f7). \nThanks again,\nRoss. Thanks @fhassak . Thanks @fhassak - we have wrapper task in build.gradle that will also update.. Thanks @fhassak  - as DBCursor is already part of a deprecated API we will review in the future.. Hi @ashu01 \nThank you for the PR - currently equals methods are automatically generated in a readable manner.\nAlthough, there is a simplification in terms of the lines of code, merging all the steps into a single line does increase the code complexity and make the code less readable. This is especially important when users wish to debug / add breakpoints to code.\nIn this case readability trumps lines of code and for that reason I'm inclined to close this PR. If you disagree with the above, then by all means feel free to explain your motivations for the PR in a comment.\nRoss. Thanks @niccottrell . Thanks @edaniels merged into master. 8+ might cover it.. Hi all,\nI'm going to close this as the java version graph was a cause of confusion and removed in the latest release (61282f4). See: http://mongodb.github.io/mongo-java-driver/3.9/upgrading/\nRoss. Thank you @kikniknik . Hi @ToniA,\nThanks for the ticket, there are no planned releases for the 2.14 version of the driver, the last release was over two years ago. Please look to migrating over to the 3.x series of the MongoDB Java driver. As this not only contains bugfixes but also contains many improvements to the API as well as access to many of MongoDB's new features.\nBecause there are no planned 2.14.x releases and as this is an issue outside MongoDB, I'm closing this ticket as won't fix.\nAll the best,\nRoss. Thanks for the PR @arunkjn . Thanks @cycchow for the PR. Tracking in: https://jira.mongodb.org/browse/JAVA-3148 . Hi @cycchow,\nDo you have an example or test case that uses a default method?\nRoss. Thanks @fhassak I'm currently working on a refactor for the build and will look to merge in after.. @ZeroErrors many thanks for the pull request and corresponding Jira ticket. \nJust to let you know we've currently scheduled this feature for the next release (3.10) and will review in due course.. Hi @AarjavP, thanks for the PR. I think that there are some implications for the existing code here.\nThe simplest fix would be to add a EnumCodec to the codec registry that you want to use. The best fix would be to use the Codec that is specifically assigned to: myPojo.mySpecialEnumProperty. It maybe if users want to specialize then they will have to have their own enum codec higher up than the codec registry and we fall through to the base EnumCodec, considerations also have to be made to ensure any changes don't break existing users.. nit\n. Empty Doc string\n. Empty docstring\n. :+1: \n. nit\n. Replace with the serverIsAtLeastVersionTwoDotSix helper\n. Can we standardise on retVal or future? for return futures we seem to use either.\n. Is there an args ordering preference I don't know about?\n. Seems wrong that theres no getCollectionBasedProtocol().execute(connection) dual for async, so we miss out on the logging that InsertProtcol.execute provides.\n. I'm glad this has been split out as OperationHelper is much more readable.  Still seems quite epic though.\n. minor nit - AsyncReadOperation<Long>, ReadOperation<Long> we've standardised on async first elsewhere.\n. nit - AsyncWriteOperation<WriteResult>, WriteOperation<WriteResult> we've standardised on async first elsewhere.\n. :+1: \n. Use VoidTransformer rather than returning null?\n. The two comments in this also apply to: DropUserOperation, UpdateUserOperation and UserExistsOperation\n. This wrapping seems smelly compared to the nicer Function transformers we use for non error results, but then probably because its a double nesting.\n. Is it worth promoting this transformer to OperationHelper?  Its the same in the FindAndDoSomethingOperations\n. (dual as in - a notion of paired concepts that mirror one another.)\ngetCollectionBasedProtocol() returns an InsertProtocol which has a an execute method but not a executeAsync() making it look lopsided:\ngetCollectionBasedProtocol().executeAsync(connection, transformer());\nSeems nicer to me and mirrors the sync version. Also the executeProtocolAsync(... path misses out on the logging that happens in the sync version (but that may be a ticket for another day).\n. We should also test upserts in save\n. Can be simplified to return observable.timeout(1, SECONDS).toBlockingObservable().last();\n. Can be simplified to: return observable.timeout(1, SECONDS).toList().toBlockingObservable().first();\n. should this Impl class be public?\n. I think so we already catch IOExceptions on AsynchronousSocketChannel.open();\n. Removed\n. Now properly async.\n. Removed - we now use MongoSocketReadTimeoutException which has been generalised \n. This was no longer used anywhere ...\n. We have to explicitly cast to Integer / String to help the compiler\n. Done\n. Nested <p> tags are also invalid - we should really use a <div> to wrap the <p>'s if Javadoc doesnt automatically do that.\n. acknowkledge typo\n. Weird name - does it get any or all or some?\n. Same as above - confusing method naming\n. Can we clarify what the maintenance jobs actually do?\n. I prefer the format for the  ServerDescription.getShortDescription():\n\nReturns a short, pretty description for this ServerDescription.\n. I prefer the format for the  ServerDescription.getShortDescription():\nReturns a short, pretty description for this ServerDescription.\n. Do we need the:\nIf the collection does not exist, a new collection is created.\n\nIts confusing as to why you would use this if the collection does exist and doesn't answer what happens if you have different options (eg capped)\n. Lines indented differently.  For multi line code examples would <code> be better?\n. done!\n. In createQueryOperation we use the asBson helper - so if this class were to stay I'd vote for consistency.\n. Prefer asBson\n. Doc nit - seems we have a convention to have return after the params and before the mongodb tags.\n. Nice generics!\n. Auto find and replace nit.\n. Auto find and replace nit.\n. Auto find and replace nit.\n. No newline nit\n. Newline nit\n. Done\n. Done\n. Done\n. Done\n. Done\n. Done\n. The logic is the same as parseOptions - I'll remove the final keyword there also.\nNo comma at all is handled as it will just have a single part.\nNo colon in each property is also handled as they are ignored in the same way as options are.\nI did have add a test for invalid separator and I've moved it out into its own block.\n. This is inline with the spec - the are parsed as strings in the spec test case.  So the authenticators should handle strings and convert / ignore.\n. Good catch - that settles that then!\n. I think this was deleted in error - its causing the tests to fail.\n. Does it matter we aren't comparing serverValue?  Could the values ever be different ints?\n. Why are we removing this rather than updating?\n. I cant figure out with statements and spock - this with statement does check the assertions.\n. I think its worth still checking this case incase of future regression - probably have to Stub CursorId to do it.\n. cool - though as a much\n. I'm fine with that - just wanted to double check\n. Might be able to provide a closure to test against (http://spock-framework.readthedocs.org/en/latest/interaction_based_testing.html#argument-constraints) eg:\n1 * listener.connectionPoolOpened({ it.getServerId() == SERVER_ID && it.getSettings() == settings })\n. yes :)\n. Should getLogger() calls be replaced with a static LOGGER var?\n. As previous\n. Can remove netty from async  - just needed in core.\n. In casbah we have the release version in the build file - keeps it simple ;)\n. Its best to have them in a file, the alternative would be to type them in but that would be bad and error prone.\n. Yes but at the moment we only have batchSize as an extra option and it is only applied in 2.8.  I thought this was more akin to the fluentFind which we I could implement for listCollections and listIndexes and then we can expand in the future.\n. Will add a new test for 2.8 and above to test the batches.\n. As previous\n. Will do although they are implicitly tested here.\n. Yes, for pre 2.8 we have to ensure that the filter is a string and append the dbname to the string.  This is so we comply with the spec.\n. :+1: \n. Formatting rules have changed again :(\n. Is documentClass needed? I can't see where its actually used by a Renderable.\n. I'm not sure how collectionClass is used which lead me to double check the Renderable use of it - is it needed?\n. Minor nit - but the html is closed out of order?\n. Suggestion: \"geometrys cannot contain null values\"\n. Suggestion: \"coordinates cannot contain null values\"\n. Suggestion \"line cannot contain null values\"\n. Suggestion: \"coordinates cannot contain null values\"\n. Suggestion: \"coordinates cannot contain null values\"\n. Suggestion: \"ring cannot contain null values\"\n. Suggestion: \"ring cannot contain null values\"\n. Suggestion: \"values cannot contain null values\"\n. nit: no new line\n. nit: no new line\n. Groovy supports multiline strings which might have been easier to use eg:\nparse('''{loc : {\n     $near: {\n        $geometry: {\n           type : \"Point\",\n           coordinates : [ -73.9667, 40.78 ]\n        },\n        $maxDistance: 5000.0,\n        $minDistance: 1000.0,\n     }\n  }\n}''')\n. nit\n. nit\n. nit\n. Could this have supposed to have been:\nbinaryType == BsonBinarySubType.BINARY.getValue()\n-                    || binaryType == BsonBinarySubType.OLD_BINARY.getValue()\n. I'm not sure how well this will play in Scala as unapply is special cased at least in objects and maybe its only a convention - see: http://docs.scala-lang.org/tutorials/tour/extractor-objects.html\n. apply is fine as it can return type T, its more the unapply convention of returning Option[F] rather than a flat F.\nI'm not sure it has any real implications, other than perhaps surprising to some Scala users.  It could mean you have to use a class rather than an object when creating custom Converters.\n. It could help, to() and from() could work as its all ready in the documentation, or expanded out to convertFrom etc...  Naming things is hard!  ;)\n. Done\n. Done\n. Done\n. Update to use apiref - so we dont have to tweak the version each time. eg: \n[`runCommand()`]({{< apiref com/mongodb/async/client/MongoDatabase.html#runCommand-org.bson.conversions.Bson-com.mongodb.ReadPreference-com.mongodb.async.SingleResultCallback-\" >}})\n. Prefer apiref helper\n. apiref helper might even work here! - not sure though.\n. We'll need 2.14 as well.\n. We'll need 2.14 as well here.\n. I'm not sure this has been pushed yet.\n. Don't think this method is needed.\n. What does the default of 0 mean?\nChange to: <p>Default is 0, indicating no limit to the idle time.</p>. Change to: <p>Default is 0, indicating no limit to the life time.</p>. It would be best to keep the timeunits for all the timeouts, so the user doesn't have to look it up. eg:\n<p>Default is 10,000.</p>. Lets add a default for getDbDecoderFactory as well.. You can simplify the test cases by extending the existing binaryParsing test and add a test case similar to the existing one with a hex string eg:\nBinary parsedBinaryWithHexType = (Binary) JSON.parse((\"{ \\\"$binary\\\" : \\\"YWJjZA==\\\", \\\"$type\\\" : \\\"80\\\" }\"));\nassertEquals(128, parsedBinaryWithHexType.getType());. This is incorrect because when $type is a String it represents a hex string and not an int string.\nIt needs to be updated to: Integer.valueOf((String) b.get(\"$type\"), 16). Updated to the latest Hugo version 0.21. Hugo 0.18 broke directory/index.md. So turning off section and taxonomy type pages fixed the issue. I also disabled the 404 page as it isn't used. Only the top level 404 page is used and there isnt a mongodb/mongodb repo with gh-pages so there isnt a custom 404 page.. The other braking changes was Url => URL. Go added whitespace trimming into its template language and now the reference index page size has been reduced from over 3000 lines to 350.. It mirrors the intent that becomes available in the JDK 1.8 Executable abstract class and abstracts getting an instance from either executable - a constructor or a method.. Good catch - Done.. Done.. Interesting, theres a difference in how annotations are only handled. We only handle them by conventions,  so we should leave it up to the convention to sort and ensure they are unique or how they impact the model.\nIf we take this:\n```\n@Property(\"boo\")  // Serialize to \"boo\"\npublic int baz;\n@Property(\"foo\") int getBaz(); // Serialize to \"foo\"\n@Property(\"bar\") void setBaz(int baz); // Deserialize from \"bar\"\n```\nAs it stands we would create a PropertyModel for baz and that is the same as yasson. In yasson the field property is ignored - as there is already one for the getter and setter. So I think we should follow that convention but possibly add a debug level warning.  \nIt does require separating out the property name and the read and write names in the PropertyModel but thats also easily do-able.. Will update.. I will add, its slightly complicated by the fact that we need to keep field data for checking validity of the model data later.  And as Field types can legitimately differ:\n```\nprivate String id;\npublic ObjectId getId() {\n    return new ObjectId(id);\n}\npublic void setId(final ObjectId id) {\n    this.id = id.toHexString();\n}\n```\nI've added a checkType boolean.. It throws in yasson - but I'm happy to ignore.. Done.. Done.. Well the idea was to just have it stored internally as a different type to what is supported by MongoDB. But given we now have ignorable properties - I don't think its a big issue.  \nNow all property types must align.. Done.. Done.. Done.. Done. Removed. Done. Done.. Added asymmetrical tests for alternative read and write property names.\nField annotations are applied as both read and write annotations. Any duplicate annotations for either read or write annotations will throw an exception. So the original case still stands, the above example will error.. Agreed - added BsonIgnore.. No, it was still open / tbc. I like the Bson prefix - so have updated and think it looks reasonable.. Ack. Ack. Seems simple enough.. As ByteBufBsonDocument.create and ByteBufBsonDocument.createOne are poorly named as create actually creates a list. This made me double take at whats added to the BsonArray. \nCan we take this opportunity to rename?. createList seems most inkeeping with existing API names. This file is no longer in the source. The copyright for these files was still intact.. ",
    "augustbering": "Ah, alright, too bad (or very good depending on when the 3.0 release is \nscheduled). Is there any documentation on how the new feature is \nimplemented?\nOn den 19 september 2013 17:21:06, Trisha Gee wrote:\n\nHi,\nWhile I totally see the need for this feature, we're designing a way\nto do this in the new 3.0 driver which will be more configurable and\nextensible.\nAlso, this pull request doesn't compile because it only works on Java\n7 and above, and the current version of the Java driver needs to work\nwith Java 5 and above.\nThanks for submitting this, but I'm afraid I can't accept it at this\nstage.\nTrisha\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/142#issuecomment-24747331.\n. \n",
    "ramazanpolat": "There is no Jira ticket for this update.\nThe code doesn't compile because java.util.Map object is not imported.\nI am very sorry. This is my first open source contribution.\nCan you please help me about that.\nIs there any jira ticket needed?\n2013/10/21 Trisha Gee notifications@github.com\n\nThanks for the pull request. A couple of things:\n1) Is there a Jira ticket for this?\n2) This code doesn't actually compile\n3) We'd like to see tests around functionality that's been implemented.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/mongodb/mongo-java-driver/pull/151#issuecomment-26731882\n.\n. \n",
    "mohansingh0141": "Updated code as per comments.\n. Moved Code to DB Class. Removed Null Check for DB name as Mongo class anyway throws NullPointerException if name is null ( throws NPE while accessing ConcurrentHashMap with Null Key)\n. Updated Test Cases\n. Please check \nhttps://github.com/mohansingh0141/mongo-java-driver/blob/0c769ab94f0d8b406e9397544e95212cf0be44ba/src/test/com/mongodb/DBTest.java#L155 , we still check for nested  \"requestStart\" .\nJust removed the outer try block (the one that takes care of closing the connection) but in the diff it looks the other way , so just checkout the raw version of file.\nI've updated the other tests.\n. The updated test was doing the same thing and the 'requestDone' part was exactly where it was supposed to be according to the previous version of test. \nAnyway , I've reverted it back to the original.\n. ",
    "craiggwilson": "Have you experienced this issue?  More than one document coming back from the find one?\nYou'll notice the previous parameter is a -1.  This parameter relates to the batch size.  When a negative batch size is sent to the server, the server will automatically close the cursor and only return that many documents.  \nThis is definitely a little odd, but it stems from the fact that the OP_QUERY wire protocol message doesn't include a way to specify both a batch size and a limit, only a numberToReturn.  You can see how this gets translated to the wire protocol here.\nHowever, it might make more sense to go ahead and use a 1 here to be very clear about what is going on.  What do you think?\n. forced pushed fixes up and reverted the SaslAuthenticator to the same state as master.\n. lgtm.\n. lgtm.\n. Yeah... We have the same problem.  In Core, I have just used Map, but in legacy API, because it is Map, I had to make someone aware about CANONICALIZE_HOST_NAME and convert it to a boolean.  Otherwise, lgtm.\n. Other than the org.bson.types, lgtm.\nCan it not just be org.bson?\n. I'm of two minds about having this in here. Strictly speaking, this is just codec and should know anything about a collection. For instance, what if this class is intended for use in more than one collection?\n. I think adding all the fields and methods is an elegant way to handle the added/removed problem. +1.\n. Isn't, by definition, the fact that the class was registered with the codec provider enough to justify that it should be mapped?\n. This doesn't seem complete... I assumed it would inherit from MappedType just like FieldModel.\n. Probably should change these to annotation.\n. I hadn't thought of having this out there. Is there any reason for this other than debugging purposes?\n. Might as well use your provided constants, Weights.BUILT_IN_CONVENTION.\n. Does your upper casing here suffer from any cultural problems?\n. If this is the default, I wouldn't have a convention for it and simply set the default when you construct the ClassModel.\n. So, perhaps the solution here isn't to add something explicit into the code, but rather to add a way for ODMs to annotate things at runtime with desirable information. For instance, have a Map or something.\n. It just seems completely redundant to me. Even in the MorphiaCodecProvider, presumably it wouldn't recognize things that morphia couldn't map at the codec provider level... hence, the isMappable check is still unnecessary.\n. Do you call them attributes in Java? Don't you call them annotations?\n. Why is getWeight() on the interface? It doesn't seem like any consumers would ever use this. ConventionPack, for instance, doesn't use it. And, in practice, it is quite restrictive as to what weights could be applied inside a convention. For instance, a hypothetical CompositeConvention that has a couple of conventions inside it with different weights, which one gets returned out of this method...  So, I think that getWeight() shouldn't be on the interface.\n. I liked value. entity implies something in DDD, and an entity is not a value type. \"value\" seems sufficiently generic.\n. I'm still questioning the isMappable requirement here... For now, I think it is probably fine, but in the long this will turn into something else. For instance, when the user doesn't use conventions to map a class, but rather uses explicit code to handle it manually. \n. I thought you got rid of converters...\n. Since this is the default convention for mapping, this should probably be DEFAULT.\n. Do you want all lower case, or just camelCase?\n. kk. In this case, we don't store collection names with our codecs, so you can do what you want.\n. ",
    "k2hyun": "You're all right. The limit size 1 cannot improve the performance. I didn't see the chooseBatchSize and how it works.\n. ",
    "ajaygeorge": "@trishagee does the commit look good? . If you have any review comments please let me know.\n. ",
    "ekuzmichev": "Hi! What is the status of resolving the issue?\n. ",
    "arthurnn": "Pretty minor doc change,\nalso ping @rozza and @jyemin for review\n. pretty small change.\nping @rozza and @jyemin for review\n. Sounds good.. I will reopen this one against 3.0.x branch.\nMaybe on the java driver we should follow the same pattern as the ruby driver where the development version is always master, and the current version 2.x is a branch. So contributors can freely open PRs against master.\nThoughts? \n. :+1: make 100% sense. thanks for the explanation. \n. Comment https://github.com/arthurnn/mongo-java-driver/commit/9579b5af12b3b2015a086dd4d5ee6c2b222858c4#commitcomment-5588424 make sense... I removed that commit from the PR, as we cannot remove append because of the returning type.\n. ",
    "finalspy": "Updated/improved by https://github.com/mongodb/mongo-java-driver/pull/192\n. ",
    "john-morales": "Whoops - closing and reopening targeted at branch 2.12.x.\n. ",
    "tgrall": "Yes it does. but the 199 has only been tested on 3.0.x branch\n. Need to test again and Java 6 and keep the same build \n. Any comment on the reason why you have close this PR without any comment?\n- not happy/interested by my contribution? \n  Anything I should do to get a review, and may be get this integrated to the product?\n. ",
    "minisu": "\nMy changes are just in the type signature, which cannot affect run time, thus not needing additional tests (adding tests would be completely pointless in this case).\nLike I wrote, the reason why this is needed is to be able to insert a List<BasicDBObject>, as opposed to just List<DBObject>.\n. \n",
    "philnate": "Hi,\nIf you provide a Codec which is used to decode Documents you're on top and can provide useful information like the class of embedded documents. I admit this is probably nothing you'll need if you stick more or less to the actual driver, but if you want to build some custom framework around it (for automatical de/encoding of java instances you might need it). I'm yet not 100% done with it, maybe I can avoid the usage. But I'm not sure if it would harm to have it available non the less.\n@rozza will keep this in mind for the next commit, thank you!\n. @rozza @jyemin I wrote some small tests for the context classes and provided some non complete example of how a custom EncoderContext could be used. The build is actually failing, but this is coming from gridfs.java.\nI believe Encoder.encodeWithChildContext should as well keep those custom set properties instead of handing over a vanilla EncoderContext.\nWhat do you think?\n. I got around using the Context by keeping the array handling stuff in my codec, rather than using the default list codec. So indeed I don't need the context for carrying. Still I think it wouldn't hurt to have this available.\n. ",
    "neerajbhatt": "Hi Trisha\nThanks for pointing out,  the test is still needed. It is back in ServerAddressTest.java, please merge the changes in main repository\n. ",
    "nbkhope": "Could someone clarify why we declare a dependency like compile 'org.mongodb:mongodb-driver:3.6.0' in gradle using org.mongodb, but import the packages uses com.mongodb...?\nWhat's the difference between org.mongodb and com.mongodb and why did you change it?. ",
    "luketn": "Fair enough, thanks for checking out the idea.\nIt'd be great if the MongoClient had a simple method like that. The ClusterType being available on the MongoClient class would meet the requirement I have right now to figure out if the connection is to a Sharded cluster or another type.\nI'd only comment that it's probably more important to be able to determine ClusterType than to have an observable interface you can use to monitor state changes. Also it'd be a lot easier to create a method on MongoClient that returned the ClusterType than creating the observable interface, which I guess would be a much more complex feature.... Maybe the two could be separate features? If you'd agree to that I'd be happy to implement just that method:\nClusterType getClusterType();\non the MongoClient, and submit it as another pull request. Let me know.\n. Re your comment: \"I'd prefer that to forcing users to call the ismaster command themselves.\"\nI just wanted to point out that in the ServerType enum code proposed in the pull request there's no public overload of getServerType() that requires clients to call ismaster themselves. The only public overloads take a DB and a MongoClient.\nThe overload of getServerType() that took the result of ismaster was a package local method, which is just the exact method that was in the ServerMonitor class moved there.\n. ",
    "smola": "Great @rozza, thank you!\n. ",
    "guoyr": "squashed the commits\n. fixed\n. ",
    "rkapsi": "Good catch. Do you have any plans adding a fix to 2.x?\n. I'm happy to open a PR if you tell me which branch.\n. Done.\nhttps://github.com/mongodb/mongo-java-driver/pull/273\n. That would require a new class that holds the closed state and the cursorId.\n. That should work.\n. ",
    "evanchooly": "lgtm\n. I meant you'll need to do it in both places since we define that header twice.\n. :+1: \n. @jyemin @rozza @craiggwilson @rstam\npushed updates to address the conversation in our code review\n. bump\n. For the released artifacts, the standard maven repository is used and doesn't need configuration.  This repository is used when you want -SNAPSHOT artifacts.\n. probably also needs to be done in reference/ \n. I guess findbugs doesn't have an xsd to validate against?\n. indentation is off now, fwiw.\n. delegating down to where the mapping information is.  I'm not entirely convinced the two classes shouldn't be merged.  ClassModelCodec feels like a thin, nigh-useless veneer on ClassModel.\n. oh, good call.  i'll remove this.\n. absolutely!  :D\n. It will be once the Conventions are in\n. Which class?\n. Immutable is in driver-core...\n. https://jira.mongodb.org/browse/JAVA-1853\n. A good point.  I'll see what I can do to hide that...\n. I see your point but this isn't not that different than putting a field name on the FieldModel:  it's just telling the codec how/where to map this to.\nAs for multiple destinations, morphia, for example, allows only a single collection mapping but you can override it when calling the Datastore methods by passing the name of the collection to use.\n. I realized that by doing this, i can effectively hide all the reflection/introspection away.\n. Not necessarily.  Morphia's implementation will allow for mapping whole packages as well.  Probably the driver version will allow that as well.  Can't see why it wouldn't.\n. It's a bit of a smell that i haven't quite mitigated.  It initially did but MappedType has a getType() and the closest a method has to a type is its return type.  I think I changed it when I hit an NPE trying to extract the class of the return type on a void method.  I can probably fix it but I just haven't come back around to this one yet.  Ideally, yes, it'd be MappedType as well.\n. come again?\n. Hadn't thought about what now?\n. facepalm  yeah...\n. Potentially some i18n issues here but since this is all coming from source, we're basically guaranteed English names.  The Beans Spec all but requires it really with its use of \"get\" and \"set\" prefixes.  I don't know that there's much wiggle room in this case.\n. That could be said about almost everything that ends up in the DefaultConventionPack, though...  Morphia defaults to just the classname, though.  Before enshrining too many defaults hard coded in to the model classes, I'd want to have some conversations about those default behaviors should be.\n. That's a great point actually.  With the driver, we'd have an explicit MongoCollection in hand.  This name is really for ODMs (read:  Morphia) to know how to get the appropriate MongoCollection to use.  hrm...\n. getWeight() is used internally when setting values.  It could probably be removed but I do like that it forces convention writers to explicitly deal with that concept.  I do see your point, though...  I'm on the fence.\n. Could be debated.  This is mostly here for POC more than any recommendation.  The final set of default conventions has yet to be decided but will probably mirror the c# driver's where it can.\n. apply() is as well but I don't think it'll be a problem since it's not on\na case class.  @rozza?\n--------------------------------\n{ name     : \"Justin Lee\", \n  title    : \"_Software Engineer\",\n  twitter  : \"@evanchooly http://twitter.com/evanchooly\",\n  web      : [ \"10gen.com\", \"antwerkz.com\" ],\n  location : \"New York, NY\" }_\nOn Tue, Jul 14, 2015 at 9:01 AM, Ross Lawley notifications@github.com\nwrote:\n\nIn\nbson/src/main/org/bson/codecs/configuration/mapper/conventions/Converter.java\nhttps://github.com/mongodb/mongo-java-driver/pull/323#discussion_r34564855\n:\n\n\n* @return the new T value\n*/\nT apply(F value);\n  +\n/**\n* @return The Class representing the type T\n*/\nClass getType();\n  +\n/**\n* Converts a value of type T back to one of type F\n*\n* @param value the value to convert\n* @return the new F value\n*/\nF unapply(T value);\n\n\nI'm not sure how well this will play in Scala as unapply is special cased\nat least in objects and maybe its only a convention - see:\nhttp://docs.scala-lang.org/tutorials/tour/extractor-objects.html\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/323/files#r34564855.\n. I'm open to changing the names if it'd help.  apply() felt the natural\nchoice which led to unapply() which, i'll admit, was a nod to Scala.  We\ncould change to convert()/unconvert()  or deconvert().  I'm just not\nsure what a decent name would be.\n\n--------------------------------\n{ name     : \"Justin Lee\", \n  title    : \"_Software Engineer\",\n  twitter  : \"@evanchooly http://twitter.com/evanchooly\",\n  web      : [ \"10gen.com\", \"antwerkz.com\" ],\n  location : \"New York, NY\" }_\nOn Tue, Jul 14, 2015 at 9:12 AM, Ross Lawley notifications@github.com\nwrote:\n\nIn\nbson/src/main/org/bson/codecs/configuration/mapper/conventions/Converter.java\nhttps://github.com/mongodb/mongo-java-driver/pull/323#discussion_r34565723\n:\n\n\n* @return the new T value\n*/\nT apply(F value);\n  +\n/**\n* @return The Class representing the type T\n*/\nClass getType();\n  +\n/**\n* Converts a value of type T back to one of type F\n*\n* @param value the value to convert\n* @return the new F value\n*/\nF unapply(T value);\n\n\napply is fine as it can return type T, its more the unapply convention of\nreturning Option[F] rather than a flat F.\nI'm not sure it has any real implications, other than perhaps surprising\nto some Scala users. It could mean you have to use a class rather than an\nobject when creating custom Converters.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/323/files#r34565723.\n. You're right.  Was using that for a failed approach and missed it in the clean up.\n. \n",
    "nscavell": "Awesome. Looking forward to the async 'sync' up :)\n. ",
    "fmela": "\ud83d\udc4d\n. ",
    "gigaclood": "Json parser to manage timezone offset:(for example)\n- \"\\\"fdata\\\" : {$date: \\\"2011-11-21T14:30:00.123-0400\\\"},\"\n- \"\\\"fdat2\\\" : {$date: \\\"2011-11-21T14:30:00.123Z\\\"},\"\n- \"\\\"fdat3\\\" : {$date: \\\"2011-11-21T14:30:00-0400\\\"},\"\n- \"\\\"fdat4\\\" : {$date: \\\"2011-11-21T14:30:00Z\\\"}\"\n. Hi, I have added test case as requested. \n. ",
    "st-h": "Test are added and I have made most of the requested changes. Waiting for feedback on the remaining things. Let me know what you think.\n. Jeff, could you please provide some details about what is going to happen to GridFS support for the async driver? \n. Sure. No problem.\nGreat that 3.0.x made it into master :)\n. @rozza thanks for comming back in this. Is there currently any information about the ETA?\n. Is this what you have in mind?\njava\n    public MongoIterable<GridFSFile> find(final Object query) {\n        return fileCollection.find(query).sort(new Document(\"filename\", 1));\n    }\nThis brings up one of the things I wanted to discuss:\nThe GridFSFile class needs a reference to the MongoCollections it uses. I am currently using a similar workaround as the sync driver ( by calling the injectContext() method after the GridFSFile has been retrieved, which sets the required references).\nI think it would be a lot nicer, if we could access the MongoCollection (and MongoDatabase) a Document has been retrieved from through the DecoderContext in the Codec. That way these fields could be initialized when the Object is created in the Codec. However, I am currently not sure if this is something the DecoderContext is meant for or if this has any other impact. \n. Hm, that currently appears to be consistent with the MongoCollection interface:\njava\nvoid deleteOne(Object filter, SingleResultCallback<DeleteResult> callback);\nProviding the DeleteResult allows to answer the question \"Did I actually delete a file?\", which might be useful in some cases. Returning Void could mean two things: \n- one file has been deleted\n- no file has been deleted\nI favour keeping the DeleteResult in this case.\nFor acknowledged writes we could check if the correct number of chunks has been deleted as well and return an error if not? However if such a operation fails, this usually leaves the database in an inconsistent state. I was wondering if we should provide an option to mark the files document as being deleted before issuing any actual delete operation, delete the chunks first and then finally delete the files document. That at least would make it easy to find any GridFS files where anything went wrong.\n. As of JAVA-1596: Now adding the codec to the files collection/database which is used by the gridfs instance. Reverted any changes to the CodecRegistry\n. ",
    "romario13": "The reason for this is to use the encoder to update operation.  At the insert operation driver accept custom encoder. DBObject query may contain custom DBObject on the tree and I prefer to control their BSON serialization stream to achieve the best performance.\nFor example. I can put custom object into update operation:\njava\n        DBObjectCheat documentKey = new DBObjectCheat(key);\n        DBObjectCheat document = new DBObjectCheat(value);\n        dbCollection.update(documentKey, document, true, false);\nThen i can catch documentKey object at custom encoder\n``` java\n        if (!(o instanceof DBObjectCheat)) {\n            return false;\n        }\n    Object obj = ((DBObjectCheat) o).getObject();\n    if (obj == null) {\n        throw new IllegalArgumentException(\"DBObjectCheat has no (null) object to encode\");\n    }\n\n    StreamBSerializer streamBSerializer = bSerializationService.getSerializer(obj.getClass());\n\n    final int sizePos = _buf.getPosition();\n    _buf.writeInt(0); // leaving space for this.  set it at the end\n\n    streamBSerializer.write(this, obj);\n\n    _buf.write(EOO);\n    _buf.writeInt(sizePos, _buf.getPosition() - sizePos);\n\n    return true;\n\n```\nAnd then use fastest serializer for particular object\n``` java\npublic class RootPojoStreamBSerializer implements StreamBSerializer {\npublic static final CString STR = new CString(\"str\");\npublic static final CString DATE = new CString(\"date\");\npublic static final CString UUID = new CString(\"uuid\");\npublic static final CString HOUSE = new CString(\"house\");\npublic static final CString LONG_ARRAY = new CString(\"longArray\");\n\nInnerPojoStreamBSerializer innerSerializer = new InnerPojoStreamBSerializer();\n\n@Override\npublic Class<RootPojo> getObjectClass() {\n    return RootPojo.class;\n}\n\n@Override\npublic void write(BDataOutput out, RootPojo rootObj) {\n\n    out.writeInt(_ID, rootObj.getI());\n    out.writeString(STR, rootObj.getStr());\n    out.writeDate(DATE, rootObj.getDate());\n    out.writeUUID(UUID, rootObj.getUuid());\n\n    InnerPojo house = rootObj.getHouse();\n\n    if (house != null) {\n        final int label = out.writeObject(HOUSE);\n        innerSerializer.write(out, rootObj.getHouse());\n        out.writeObjectStop(label);\n    }\n\n    long[] longs = rootObj.getLongArray();\n\n    if (longs != null) {\n        final int label = out.writeArray(LONG_ARRAY);\n        for (int i = 0; i < longs.length; i++) {\n            out.writeLong(i, longs[i]);\n        }\n        out.writeArrayStop(label);\n    }\n\n}\n\n@Override\npublic RootPojo read(BDataInput in) {\n\n    RootPojo obj = new RootPojo();\n    obj.setI(in.readInt(_ID));\n\n    obj.setDate(in.readDate(DATE));\n\n    int label = in.readObject(HOUSE);\n    if (label != -1) {\n        obj.setHouse(innerSerializer.read(in));\n        in.readObjectStop(label);\n    }\n\n    obj.setUuid(in.readUUID(UUID));\n\n    label = in.readArray(LONG_ARRAY);\n    if (label != -1) {\n        int arraySize = in.readArraySize();\n        long[] longs = new long[arraySize];\n\n        for (int i = 0; i < arraySize; i++) {\n            longs[i] = in.readLong(i);\n        }\n\n        obj.setLongArray(longs);\n\n        in.readArrayStop(label);\n    }\n\n    obj.setStr(in.readString(STR));\n\n    return obj;\n}\n\n}\n```\nThe mine goal is to give the opportunity to avoid costly conversion POJO objects to DBObject map structure and vice versa. I can do this on simple queries, but can not when try to request an update of a particular object.\n. This is an example of plugin to mongo driver\nhttps://github.com/taskurotta/taskurotta/tree/develop/mongodb/src/main/java/ru/taskurotta/mongodb/driver\nThis is a perfomence test:\nhttps://github.com/taskurotta/taskurotta/blob/develop/hazelcast/src/test/java/ru/taskurotta/mongodb/driver/MongoSerializationTest.java\nCustom encoder wins 7 seconds (30%) on insertion of 100000 simple POJO structures.\nSometimes plugin forced to use deprecated driver API.Please do not pay attention to it We are waiting the third version of driver to avoid this.\n. ",
    "tkgreg": "Also you could check our compare test with custom serialization to BSON https://github.com/taskurotta/taskurotta/blob/develop/services-hz/src/test/java/ru/taskurotta/hz/test/SerializationCompareTest.java\nFYI: Test measures only stage of serialization without real write-read operation to mongo\nTest Results for serialization of 100,000 POJO\nOur custom serialization for MongoDB driver\nBSON: Serialization took 680 ms, object size 1354 bytes\nBSON: Deserialization took 1580 ms object size 1350 bytes\nDefault serialization by MongoDB driver\nDBObject: Serialization took 8158 ms, object size 1678 bytes\nDBObject: Deserialization took 16969 ms, object size 1678 bytes\nCustom serialization to Hazelcast\nHZ: Serialization took 459 ms, object size 792 bytes\nHZ: Deserialization took 672 ms object size 792 bytes\n. I have created this one https://jira.mongodb.org/browse/JAVA-1647\nWhat kind of test case do you want to see? As you see above we have already provided our test. \n. ",
    "xcoulon": "@rozza my pleasure! congratulations for the work you did on the driver and the website !\n. ",
    "oallouch": "Actually, I messed up a bit.\nI left some old slf4j in my lib dir, but now I use a new log4j (with the updated packages name).\nSo the old slf4j is looking for an old log4j, hence the exception.\nWhen I remove the faulty jars, everything works like a charm.\nThe only thing you could do is add a general catch stating that there is a badly configured slf4j.\nSorry again.\n. ",
    "fbuecklers": "Hopes that it looks good for you now ;-)\n. ",
    "stevenbenjamin": "Sorry about that - This updated version is 4x faster than the previous and passes that test.\n. ",
    "brendon-": "i don't think the CI build failure was related to my code changes.\n. ",
    "gianpaj": "thanks. my bad\n. Oh sorry (again). didn't know there were two places. I've made a second commit on #312 - hope that's ok. happy to do one commit instead\n. ",
    "MorrisLaw": "\"is\" not \"this\" was the grammatical error I found in the exception error under getModifiedCount.\n. ",
    "fzhinkin": "Hi Jeff,\nseems like OOME that caused org.bson.GenericBsonTest::shouldPassAllOutcome failure does not relate to my change, is it?\nThanks,\nFilipp.\n. ",
    "saarp": "Thanks for the update. For some reason my local config was not fetching the artifact from Maven Central, possibly due to an incorrectly configured local proxy.\n. ",
    "jamel": "Cool! Thanks a lot!\n. ",
    "mutaherul": "Thank you for your response. I used this at the project where I have to deal with  com.mongodb.hadoop.io.BSONWritable  ( BSONWritable(BSONObject doc)  ) . Can the new Document   be possible to pass at BSONWritable ?  I am using mongo-hadoop-core  (V 2.0.1) in my project .. ",
    "vedala": "Hi @rozza,\nNo problem about the delay. Glad you are considering merging this pull request. I have sync the master. But do I have to sync the feature branch to master too?\nThanks.. Hi @rozza, I have synced the feature branch to master. As you mentioned, there was a merge conflict which I resolved.. Hi @rozza, I have made the changes you suggested. I added back the timeunit for locations that I removed it from. I also added timeunit for few additional functions.. There was a line too long checkStyle error on one line. I fixed it and pushed the changes.. Thanks, Ross. I look forward to the solution to be provided by JAVA-1812.. ",
    "Dufgui": "See https://jira.mongodb.org/browse/DRIVERS-342\n. ",
    "Gauravshah": "same tests are failing on master since commit d12a26efad19f876e53829c8a8444d5e5340c765\n. thanks @jyemin fixed it.\n. I understand the concern there. Is there a better way to solve this ? I am\nnot able to think of a clean solution.\nOn Friday 15 April 2016, Jeff Yemin notifications@github.com wrote:\n\nOne issue with the change is that it doesn't interact well with the\nmaxConnectionIdleTime setting, which is sometimes used to handle short-term\nconnection spikes. It lets the connection pool temporarily expand to its\nmaximum allowed size during a spike, and then shrink back down to its\nminimum allowed size as load decreases and connections are idle. But this\nrelies on the connection pool being treated as as LIFO queue rather than a\nFIFO queue. Otherwise, all the connections are cycled through and none are\never idle for long, unless usages effectively drops to zero.\nWhile it would be possible to detect this and switch to FIFO if\nmaxConnectionIdleTime is set, that seems to violate the element of least\nsurprise for users.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/347#issuecomment-210472736\n. Probably that sounds better.\n\nI don't think I know java that well to implement new API.\nOn Mon, Apr 18, 2016 at 12:51 PM, Jeff Yemin notifications@github.com\nwrote:\n\nPerhaps the answer lies not in tweaking the connection pool implementation\nbut rather in exposing a new API. The MongoDB driver for golang\nhttps://godoc.org/labix.org/v2/mgo has a Session-based API that allows\nthe user finer-grained control over what socket the application is using.\nAn approach like that might be applicable for this use case, as then the\napplication itself could reserve as many sockets as it needed for\nunacknowledged writes, and use a different set for other operations.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/mongodb/mongo-java-driver/pull/347#issuecomment-211549011\n. created issue in https://jira.mongodb.org/browse/JAVA-2169. \n",
    "xardazz": "@rozza Can you please review?\n. ",
    "Powerrr": "Already done in 0fa058cdd1530bc4bc078305e8955b7a90d54598.\n. ",
    "ia3andy": "The issue has been created (even if it will be deprecated, it's still a bug).\nTalking about my use case, I'm looking for a way to \"archive/restore\" a read-only big data collection on the fly when it hasn't been used for a while (because of indexes size). I was thinking about just removing indexes, but since autoIndex=false will be deprecated (I can't get rid of _id index size), do you suggest using mongo dump/restore instead? Do you have some plan on doing such a feature (archive)?\nThanks,\nAndy.\n. Sorry, I'm not familiar with Spock, it's seems to me that all the test file should be rewritten from what you said because it's using the pattern I've been copying from. This change should be in another pull request since it's not part of the bug fixing.\nThanks,\n. ",
    "sunjaec": "Thanks for the quick response. Looking forward to having the fix generally available. \n. ",
    "upa8": "You are most welcome . \nFound similar change in all the scala drivers document as well . \nPlease have a look . \n. ",
    "tdyas": "Any response to this feature?\n. Will do\n. Will do\n. Writing toByteArray in terms of putToByteBuffer will incur an allocation of a ByteBuffer that will just be thrown away (and same for the ByteBuffer.wrap in the constructor). Is that okay?\n. Done.\n. Done.\n. Done.\n. ",
    "kay-kim": "Updated the gridfs blurbs : )\nAlso, ran gradle and found that I had accidentally committed the little java class I was using to test things as I was writing.  So removed that little sucker.\n. Updated w feedback.. squashed :). ",
    "vladimirdolzhenko": "Hi Jeff,\nRebased and squashed. Please proceed. \n. ",
    "Daniel-Dos": "You're welcome. Thanks for helping out a bit.\nThank you.. ",
    "tomdcsmith": "I've added two tests to JSONCallbackTest, one to test the parsing of binary data with the $type value as an integer, and one with the $type value as a hexadecimal string.. I've extended this method now, but the 128 int needed to be cast to a byte:\nassertEquals((byte) 128, parsedBinaryWithHexType.getType());. I've updated this now.. ",
    "chusse3t": "Hi Ross,\nthanks for the quick response. I just want to underline that we would really appreciate this change being made to the official java driver too, since even though the server is going to be fixed, the broken servers are still out there :). And if it's officially fixed we have one fewer patch to make to the java driver.\nCheers\nChris. ",
    "epkugelmass": "This is great. Was looking at a stack trace today and was scratching my head. Pool-2-Thread-1.... ",
    "slothspot": "Hi @rozza , added tests for added methods.. @rozza Any update on this one?. ",
    "dkublik": "Issue\nCurrently org.bson.json.JsonReader in unable to read all base64 characters when creating BinData\nTroublesome characters: '+', '/', '='\nThis makes for example org.bson.Document.parse(final String json) fail when reading documents with binary uuids.\nto reproduce:\nin org.bson.json.JsonReaderTest.testBinDataWithNew() \nreplace\nString json = \"{ \\\"a\\\" : new BinData(3, AQID) }\";\nwith\nString json = \"{ \\\"a\\\" : new BinData(3, AQIDBA==) }\";\nto get new byte[]{1, 2, 3, 4}\nit will fail as BinDataConstructor expects only unquotted string as byte value and\norg.bson.json.JsonScanner.scanUnquotedString()\nreads only '$', '_', letters and digits. ",
    "aantono": "Any update on the status of this PR to be merged?. ",
    "jsonking": "The travis CI build seems to be stuck 'in progress', so I tried closing and re-opening the pull request to re-trigger it. It doesn't seem to have helped :confused:. Hi @rozza I have pushed a fresh commit with the change suggested.\nThe reason I thought it would be ok to set the ulimit explicitly is that when running the test suite it needs it to be above the default of 256 (on macOS) and when logging in via the shell I get the following: \"WARNING: soft rlimits too low. Number of files is 256, should be at least 1000\". Agree the single command is cleaner and should work for most people.\nThanks\nJason\n. Hello,\nIs this pull request ok to be merged or would you like further changes?\nThanks\nJason. ",
    "andyphillips404": "I am not sure why the test failed, the added tests and changes to the FloatCodec have passed though:\n[Test org.bson.codecs.FloatCodecTest > shouldRoundTripFloatValues]\n[Test org.bson.codecs.FloatCodecTest > shouldRoundTripFloatValues] SUCCESS (0 ms) \n[Test org.bson.codecs.FloatCodecTest > shouldRoundTripNegativeFloatValues]\n[Test org.bson.codecs.FloatCodecTest > shouldRoundTripNegativeFloatValues] SUCCESS (0 ms) \n[Test org.bson.codecs.FloatCodecTest > shouldErrorDecodingOutsideMinRange]\n[Test org.bson.codecs.FloatCodecTest > shouldErrorDecodingOutsideMinRange] SUCCESS (1 ms) \n[Test org.bson.codecs.FloatCodecTest > shouldErrorDecodingOutsideMaxRange]\n[Test org.bson.codecs.FloatCodecTest > shouldErrorDecodingOutsideMaxRange] SUCCESS (1 ms) \n. ",
    "joankaradimov": "The build failure happens during the execution of gradle :mongo-java-driver:javadoc\nThe error itself is:\njavadoc: error - invalid flag: -->\nIt does not look related to my changes. It also appears this pull request - https://github.com/mongodb/mongo-java-driver/pull/400 - has the same issue. I am assuming that there is something wrong with the build in master.. I've rebased on the latest master.\nI've also added a commit that should allow usage with Socket/SocketAddress implementations other than InetSocket/InetSocketAddress. So in theory with some SocketFactory magic in the MongoClientOptions you should be able to use something like jnr-unixsocket.. I rebased and added a new commit. The new commit implements Unix sockets inside the main codebase (as opposed to the possibility of a user-defined SocketFactory). The change is less than 30 lines. There's only one change in the public API - the addition of a new constructor to ServerAddress.\nThe previous commits are related to the latest change, but they also make sense on their own (as I've already mentioned).\nThe implementation uses jnr-unixsocket which in turn uses jnr-ffi. The latter is interesting because it is the basis of JEP 191 which is soon to be release in Java 9. However, existing jnr-ffi versions run perfectly fine on old JVMs. Java Native Runtime libraries are cool, because there is no need to manually install native components or to change the environment (which is a drawback of junixsocket).\nHere are some notes:\n- I've not tested it with clusters. I doubt it's a use case.\n- The jnr-unixsocket dependency is optional. In case the JAR is missing the connection will ultimately fail with:\n    Caused by: java.lang.ClassNotFoundException: jnr.unixsocket.UnixSocketAddress\n- If it is run on Windows (with jnr-unixsocket present in the classpath) it will fail with something like:\n    Timed out after 30000 ms while waiting to connect. Client view of cluster state is {type=UNKNOWN, servers=[{address=\\tmp\\mongodb-27017.sock:0, type=UNKNOWN, state=CONNECTING, exception={com.mongodb.MongoException: java.lang.UnsatisfiedLinkError: The operation completed successfully.}, caused by {java.lang.UnsatisfiedLinkError: The operation completed successfully.}}]\n- I have some examples I played with, but I wouldn't call them tests. If there is interest I can put together some real tests based on them.. There were some conflicts with latest master. I've rebased and force pushed the branch.. ",
    "jpstotz": "I checked the propose change of  https://jira.mongodb.org/browse/JAVA-2203 and it indeed solves my problems with the detection of slf4j. I changed my push request accordingly.. @jyemin As long as I did not miss anything all of your requested changes are now included in this pull request.. ",
    "ChappIO": "I found an explicit test that checks if the hostname is lowercased. What is the reason for this? Why should the hostname be lowercased?\n. ",
    "jflorencio": "Hey @rozza, I just pushed an extra fix to this branch. My apologizes for not making a new PR, but it touches a lot of the same stuff in this PR so I didn't want to make merging overly complicated.\nNew fix is: Don't throw if field type != property type\nIf a property was discovered through reflection, we shouldn't be heavily introspecting the underlying field and enforcing that the type matches. How the object stores the field internally should be treated as an implementation detail if proper getters/setters/constructors are provided.\nThis change is made so it remains backwards compatible, in that things that successfully serialized using a combination of properties and direct field access will still serialize/deserialize.. ",
    "fhassak": "alternative solution : https://github.com/mongodb/mongo-java-driver/pull/420. Can you help me to see what went wrong:\nExecution failed for task ':driver-core:codenarcTest'.\n\nCodeNarc rule violations were found. See the report at: file:///home/travis/build/mongodb/mongo-java-driver/driver-core/build/reports/codenarc/test.html\n\nI don't know how to access this file.\nBecause, it work on my machine. Done !. will do a PR with 1 commit. Can you please give me more details about failed test \ncom.mongodb.client.CommandMonitoringTest\n\u2717 [TEST FAILURE] shouldPassAllOutcomes[A successful delete many] (81 ms)\nBecause it's work on my machine and previous PR #426 was success with same changes.\nMaybe try to restart build, or should i close this PR and create new ?\n. Hello,\nThis is not necessary because the method eq of the Filters class is imported statically by the following import statement as specified in Prerequisites paragraph:\nimport static com.mongodb.client.model.Filters.*;\n. It's hard for me to know what's wrong because it works on my pc :\n\n. All tests passed successfully with this PR on my pc !\n\n. please wait before merge, i will propose an alternative solution. To avoid errors, avoid looking for the default host, for simplicity, to avoid redundancy...\nlike here https://github.com/apache/camel/commit/c2d613564b673cdeaee7853d25488171d9a22b03\nI think it's good to have the possibility to write \nreturn new MongoClient(PORT);. Finally after careful reflection, this constructor does not make sense. \nIt is better to use the constructor with explicit values \u200b\u200bfor the host and port. \nIt does not make sense to only have the port.\nI suggest closing this PR.. And java 11 ? . i think, the driver can run on java 6 to java 11.\nIt need only to be build with java 9.. Only java 9 is required. Source cannot be compiled with java 10 or java 11. See https://jira.mongodb.org/plugins/servlet/mobile#issue/JAVA-2844. Fixed by https://github.com/mongodb/mongo-java-driver/commit/d076619cc09a078b01a2d2abf756ac52e82d9e4f. Yes, it's redundant. I have added 2 tests : \n\n\nwith only  restricSearchWithMatch  option : \nnew GraphLookupOptions().restrictSearchWithMatch(eq('hobbies', 'golf')))\n\n\nwith all options ;\nnew GraphLookupOptions().depthField('depth').maxDepth(0).restrictSearchWithMatch(eq('hobbies', 'golf')))\n\n\nI can remove one test. Which ?. done ! . Text (url path) is mandatory when generating javadoc. see DocTaglet.java. We can't use Java 9 style : \nreturn Set.of(Location.CONSTRUCTOR, Location.METHOD, Location.FIELD, Location.OVERVIEW, Location.PACKAGE, Location.TYPE);\n   because of source compatibility to java 6.\n/mongo-java-driver/util/src/main/DocTaglet.java:30: error: static interface method invocations are not supported in -source 1.6               \n  (use -source 8 or higher to enable static interface method invocations)\nAt compile time : \nwarning: [options] source value 1.6 is obsolete and will be removed in a future release\nwarning: [options] target value 1.6 is obsolete and will be removed in a future release\nwarning: [options] To suppress warnings about obsolete options, use -Xlint:-options.\n. if there is an empty tag @mongodb.driver.manual without text (like in Projections.fields), getContent().get(0) throw an exception.\nI think text is mandatory in tag. So it's good to failed and not necessarry to add control ? \nif (getContent().size() > 0 ) {\ntext = getContent().get(0).toString();\n}\nOr, we can add default value (default path + default display (see genLink method) ? \njavadoc: error - An internal exception has occurred.\n        (java.lang.IndexOutOfBoundsException: Index: 0, Size: 0)\nPlease file a bug against the javadoc tool via the Java bug reporting page\n(http://bugreport.java.com) after checking the Bug Database (http://bugs.java.com)\nfor duplicates. Include error messages and the following diagnostic in your report. Thank you.\njava.lang.IndexOutOfBoundsException: Index: 0, Size: 0\n        at jdk.compiler/com.sun.tools.javac.util.List.get(List.java:490)\n        at DocTaglet.toString(DocTaglet.java:48)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.taglets.UserTaglet.getTagletOutput(UserTaglet.java:147)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.taglets.TagletWriter.genTagOutput(TagletWriter.java:238)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.formats.html.HtmlDocletWriter.addTagsInfo(HtmlDocletWriter.java:333)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.formats.html.MethodWriterImpl.addTags(MethodWriterImpl.java:207)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.MethodBuilder.buildTagInfo(MethodBuilder.java:206)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.MethodBuilder.buildMethodDoc(MethodBuilder.java:153)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.MethodBuilder.build(MethodBuilder.java:128)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.ClassBuilder.buildMethodDetails(ClassBuilder.java:393)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.ClassBuilder.buildMemberDetails(ClassBuilder.java:341)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.ClassBuilder.buildClassDoc(ClassBuilder.java:145)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.builders.ClassBuilder.build(ClassBuilder.java:120)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.formats.html.HtmlDoclet.generateClassFiles(HtmlDoclet.java:267)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.AbstractDoclet.generateClassFiles(AbstractDoclet.java:290)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.AbstractDoclet.generateClassFiles(AbstractDoclet.java:272)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.AbstractDoclet.startGeneration(AbstractDoclet.java:211)\n        at jdk.javadoc/jdk.javadoc.internal.doclets.toolkit.AbstractDoclet.run(AbstractDoclet.java:117)\n        at jdk.javadoc/jdk.javadoc.doclet.StandardDoclet.run(StandardDoclet.java:72)\n        at jdk.javadoc/jdk.javadoc.internal.tool.Start.parseAndExecute(Start.java:581)\n        at jdk.javadoc/jdk.javadoc.internal.tool.Start.begin(Start.java:430)\n        at jdk.javadoc/jdk.javadoc.internal.tool.Start.begin(Start.java:343)\n        at jdk.javadoc/jdk.javadoc.internal.tool.Main.execute(Main.java:63)\n        at jdk.javadoc/jdk.javadoc.internal.tool.Main.main(Main.java:52). <br/> must be removed by #468 . Now, we need JDK 9 to build project. If you merge on master, all next commits must be compiled with jdk 9.. Building with JDK 10, show me this warning : \njavadoc: warning - You have not specified the version of HTML to use.\nThe default is currently HTML 4.01, but this will change to HTML5\nin a future release. To suppress this warning, please specify the\nversion of HTML used in your documentation comments and to be\ngenerated by this doclet, using the -html4 or -html5 options.\nHTML 5 is not working...\n. Now, we have link to java package : \n\nNot working without https : \n\n. Yes ! I suggest to merge #468 on master. I will rebase and fix conflict on this line. Yes, i made this change but not yet committed. We can also import statically Location.* :\nreturn new HashSet<Location>(asList(CONSTRUCTOR, METHOD, FIELD, OVERVIEW, PACKAGE, TYPE));\n\n. Or maybe: \nreturn new HashSet(asList(Location.values()));. done. . ",
    "bcluap": "Any chance of this being pulled? Tx. Something like this?:\njava\n} else if (propertyMetadata.isSerializable() && value instanceof Collection) {\n                // PCB : https://jira.mongodb.org/browse/JAVA-2648\n                // If a type is a collection and there is no setter then use the getter and addAll to it from the value\n                // Also check that the collection is currently empty. Without this check some test cases fail.\n                T collection;\n                if (propertyMetadata.getGetter() != null) {\n                    collection = (T) propertyMetadata.getGetter().invoke(instance);\n                } else {\n                    collection = (T) propertyMetadata.getField().get(instance);\n                }\n                Collection<?> col = ((Collection<?>) collection);\n                if (col != null && col.isEmpty()) {\n                    col.addAll((Collection) value);\n                }\n            }\n. ",
    "visualage": "The following is an exception triggered by this bug.\nException in thread \"RxComputationThreadPool-2\" java.lang.IllegalStateException: Attempted to decrement the reference count below 0\n    at com.mongodb.binding.AbstractReferenceCounted.release(AbstractReferenceCounted.java:39)\n    at com.mongodb.binding.AsyncClusterBinding$AsyncClusterBindingConnectionSource.release(AsyncClusterBinding.java:113)\n    at com.mongodb.operation.AsyncQueryBatchCursor.killCursorOnClose(AsyncQueryBatchCursor.java:187)\n    at com.mongodb.operation.AsyncQueryBatchCursor.close(AsyncQueryBatchCursor.java:89)\n    at com.mongodb.async.client.MongoIterableSubscription.postTerminate(MongoIterableSubscription.java:71)\n    at com.mongodb.async.client.AbstractSubscription.unsubscribe(AbstractSubscription.java:53)\n    at com.mongodb.reactivestreams.client.internal.ObservableToPublisher$1$1.cancel(ObservableToPublisher.java:60)\n    at io.reactivex.internal.operators.observable.ObservableFromPublisher$PublisherSubscriber.dispose(ObservableFromPublisher.java:70)\n    at io.reactivex.internal.disposables.DisposableHelper.dispose(DisposableHelper.java:125)\n    at io.reactivex.internal.disposables.SequentialDisposable.dispose(SequentialDisposable.java:73)\n    at io.reactivex.internal.operators.observable.ObservableObserveOn$ObserveOnObserver.dispose(ObservableObserveOn.java:146)\n    at io.reactivex.internal.operators.observable.ObservableElementAtMaybe$ElementAtObserver.onNext(ObservableElementAtMaybe.java:82)\n    at io.reactivex.internal.operators.observable.ObservableObserveOn$ObserveOnObserver.drainNormal(ObservableObserveOn.java:200)\n    at io.reactivex.internal.operators.observable.ObservableObserveOn$ObserveOnObserver.run(ObservableObserveOn.java:252)\n    at io.reactivex.internal.schedulers.ScheduledRunnable.run(ScheduledRunnable.java:67)\n    at io.reactivex.internal.schedulers.ScheduledRunnable.call(ScheduledRunnable.java:52)\n    at java.util.concurrent.FutureTask.run(FutureTask.java:266)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)\n    at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:748). Sorry for the late reply. The rxjava fix would solve my problem, so this is not needed.. ",
    "72MiguelGomes": "@rozza Not sure what error @visualage is trying to solve but it seems total sense if the timeout is 0 try to lock or return immediately. And it is also part of a function documentation:\n\ntimeout  negative - forever 0        - return immediately no matter what positive ms to wait\n\nIn this case I would say that you should add this fix. Why not directly call isSerializable(), this way you also have the logic around transient fields.... This should be the default parameter exception. ",
    "csarrazi": "You\u2019re welcome! \ud83d\ude09. All tests are green now on High Sierra!\n  . Actually, I guess we should also mention compatibility with Java 10, as more and more people will be using it.. missing final. ",
    "denis-zhdanov": "Hi @72MiguelGomes,  \nThanks for the feedback!  \nYeah, the project is rather young, that's why I'm proactively looking for good host projects :) Please note a couple of moments regarding that:\n there is an extensive test-suite which covers a lot of use-cases\n the feature set is relatively small\n* the project is built by a professional with more than ten years experience in the industry (myself :P )  \nRegarding the default exception - I see that the most of existing approaches use java.util.Objects.requireNonNull() or com.google.common.base.Preconditions.checkNotNull() which both throw NullPointerException. So, I just ease the transition here.. ",
    "brendanJsonar": "when sending to servers with =2D, servers don't recognize it as a comma so servers use =2D instead of comma to do authentication, and clients get MongoSecurityException.. As referring to the mongo implementation, it uses =2C instead of =2D to encode/decode comma.\nmongo/src/mongo/db/auth/sasl_scram_server_conversation.cpp\nmongo/src/mongo/client/sasl_scram_client_conversation.cpp. Thanks a lot for such a quick response.. ",
    "salsama59": "Ok, looks like my pull request fail to pass the checkstyletest.\nI will fix this and send another pull request..  Hello @jyemin, sorry for my late reply and thank you for your previous advices, I think now that I have a better understanding of the Json reader. Can you please review my new commit? I've updated the Pull Request based on what you told me in your code review.\nThank you, have a nice day.. Thank you for the tips, however I wonder what is the best way to identify methods implementing \"Shell\" mode? Is it by looking for methods name built like this : visitXxxxConstructor? e.g \"JsonReader#visitTimestampConstructor\". ",
    "wrey75": "This is perfect. You should add this example in the API documentation or in the documentation. It is not very clear that applying the connection string without credentials keeps the previous ones. . ",
    "IanWhalen": "Fixed in d076619cc09a078b01a2d2abf756ac52e82d9e4f. Tracking in https://jira.mongodb.org/browse/JAVA-3132. Additional changes made - note that this has now caught the 'edit this page' links as well as a variety of links to QuickTour*.java files.  I've tried a sampling of both kinds of links from pre and post 3.7.x and both seem to work.\nI also just tried grepping the entire tree for /master/ and the only remaining links referencing that branch look to be referencing others repos.. ",
    "ZeroErrors": "This has been resolved by replacing the current output instead of adding more settings.\nSee JAVA-3085 for more info.. ",
    "jstewart-mongo": "(issued PR by accident). ",
    "rstam": "Look at that banana! :)\n. This withConnection, CallableWithConnectionAndSource with its call method trick is a rather roundabout way of getting this done...\n. Two comments:\n1. Do you not want to prefix your GeoJson classes with GeoJson to avoid ambiguity or name collissions?\n2. Why does this not have GeoJsonObject as a base class? I realize that since you chose not to implement GeoJsonFeature (yet) that GeoJsonGeometry would be the only GeoJsonObject subclass so far, but it seems like the right thing to do is to have a GeoJsonObject class.\n. Where's the bounding box?\nWhat about extra members?\n. Why do some coordinates get special classes (e.g. PolygonCoordinates) and others are just something like List>?\n. Seems like Point is a class name destined for lots of name collisions...\n. Another class name that seems like it's destined for name collisions...\n. I understand the simplification you are making here... but this means that every position could have a different number of dimensions, which would be invalid.\nAre there any run-time checks to make sure the dimensionality of all the coordinates are in agreement?\n. Is Runnable because you don't have lambdas in older versions of Java?\n. Shouldn't the parameter be of type GeoJson Polygon?\n. ",
    "kashike": "Missing newline at end of file.. "
}