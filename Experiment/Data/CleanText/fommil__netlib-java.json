{
    "fommil": "From Sam.Hall...@gmail.com on March 11, 2009 22:13:44\na good point, well put... fixed in trunk\n. From Sam.Hall...@gmail.com on May 14, 2009 20:13:27\nI'm quite busy at the moment so don't hold your breath for a fix... but I'd gladly accept one! :-D\nIf I understand the problem correctly, are you saying there is a type mismatch between \"jint\" and \"integer\"? That's \ntroublesome! Will certainly result in less optimal 64 bit code.\nI encountered something similar with the jboolean type. I think you're on the right track... a function is needed to \nconvert jint into integer, and back again. It should be in a preprocessor statement only if there is a type mismatch.\nAs a first step (and you're on the case), try writing the function and get it to work. You can place it in f2j_jni.{c,h}. \nDon't forget the inverse function.\nAfter that, have a look in src/org/netlib/generate/JNIGenerator.java and insert some generator code to reproduce this. \n(Sorry, it's not the cleanest code in the world).\nAs an aside, I'm not entirely sure if CLAPACK-3.0 is supported... please let me know if all the functions are there! A \nfew functions are disabled on purpose because they are not supported by all platforms.\nAdditionally, let me know if you think arpack.h needs an update. It uses primitive types in its header file.\n. From goo...@oliford.co.uk on May 14, 2009 21:29:15\nMost of the problem is currently just the single integers like n, m, k etc which \nshouldn't require much overhead. They just need a local 64-bit int copy to be \ncreated rather than a whole conversion function. \nHowever, I hadn't thought about integer arrays, which might be less trivial.\nI've had a look through JNIGenerator.java and it makes sense to me. It's obviously \nbeen written in a rush but it's not as bad as you make out, it's fairly well \ncommented and clear enough to read. I'll add the conversion and but probably not \nuntil some point in the next few weeks as I'm also a bit short on time.\nI am going to try recompiling CLAPACK with 32-bit ints first, it looks to me like it \nshould be. Do you happen to know if under FORTRAN compiled on 64-bit, an 'integer' \nwould use 32-bit ints or 64?\nIf CLAPACK-3.0 isn't supported should I be using something else? All we want is to \nbe able to run fast multiply, inversions and eigenvector and lu decompositions on \nlarge matricies (n>1000) etc from java. netlib-java with CLAPACK and ATLAS seemed to \nbe the most sensible way of doing it I could find. Have I missed something?\nThanks for the help and the quick reply,\nOliver\n. From Sam.Hall...@gmail.com on May 14, 2009 21:34:13\nI strongly suspect that CLAPACK-3.0 shouldn't give a problem. If there are missing functions, you now know \nhow to comment them out in the generator ;-)\nI have no idea how compiling 32 bit versions will pan out... you'll probably need to hack the f2j.h file to make \nsure everything is of the right type.\nIt's times like these I'm soooo glad that I spend most of my time in Java land and not C! :-D\n. From goo...@oliford.co.uk on May 15, 2009 10:09:00\nYes, I know what you mean. My supervisor works on windows, I work on linux and \nanother guy has just joined the project who uses a Mac. Java normally makes like a \nlot easier but I suspect getting Atlas, Blas and Lapack onto both of those will be a \npain.\nI've got everything working here now. The (rather quick and dirty) patches are here:\nhttp://www.oliford.co.uk/files/netlib-java-patches/\nnetlib-java-64bitInts.patch is the 64bit ints stuff. If enabled, it applies to \nLAPACK, ARPACK but not BLAS. BLAS passes takes ints by value and has no int arrays \nso isn't a problem. All three now compile without warnings and I've tested BLAS and \nLAPACK. I don't use ARPACK so haven't tested it but the fact that it compiles \nwithout the incompatible types warnings is a good sign.\nnetlib-java-invertTest.patch is a rather crude LU decomp' / inversion test because \nthe pivots array is an int array so tests the integer passing both in and out.\nnetlib-java-fixNullFilesArray.patch is an unrelated patch to catch a null File[] \narray which kept throwing exceptions here.\nHope that helps,\nOliver\n. From Sam.Hall...@gmail.com on May 15, 2009 10:30:16\nThanks a bunch!\nCould you please upload the patches to this issue. I'd do it myself, but for source-of-origin reasons it would be \ngood if you posted them. When I get a moment, I'll polish and integrate these.\n. From goo...@oliford.co.uk on May 15, 2009 17:58:31\nNo problem, patches attached.\nI have however just discovered that when run more than a few times, the JLAPACK \nimplementation is just as fast as the full ATLAS optimised native code, even for e.g \n500x500 matricies, so most of my work on this was pointless for myself. I hope it \nhelps someone else.\nOliver\n. From Sam.Hall...@gmail.com on May 15, 2009 18:48:20\nIt's definitely worthwhile doing the profiling as native libs bring pain. I find the matrices have to be 1000 x 1000 \n(or the architecture specifically designed for linear algebra) before the native libs start to really pay off. But when \nthey do... you really notice!\n. From martyv...@gmail.com on February 22, 2012 21:45:36\nWorking with netlib-java svn trunk, even in 32 bit Ubuntu 11.10, when running make in the jni dir I get a lot of warnings like this:\norg_netlib_arpack_NativeARPACK.c:445:2: warning: passing argument 22 of \u2018sseupd_\u2019 from incompatible pointer type [enabled by default]\narpack.h:74:8: note: expected \u2018integer \u2019 but argument is of type \u2018jint \u2019\n. Related to #15\n. From Sam.Hall...@gmail.com on August 01, 2010 20:11:05\nThanks for the report. In the latest svn version, this does not happen - the variable correctly points to\nJLAPACK_JNI_CP=../netlib-java-0.9.1.jar:../lib/f2j/arpack-combined.jar\nPerhaps I should make a 0.9.2 release with this fix included.\n. From Sam.Hall...@gmail.com on December 07, 2010 12:01:05\nCould you please attach the discussion reference?\n. From jzaugg on December 07, 2010 12:37:02\nOops, here it is.\n[1] http://icl.cs.utk.edu/lapack-forum/archives/lapack/msg00500.html\n. From Sam.Hall...@gmail.com on December 07, 2010 20:14:40\nThanks - this should be a simple fix. In the meantime, you should be able to create your own workaround by having a static piece of code in an entrance class run the offending methods, just like the fortran init code you found.\n. From Sam.Hall...@gmail.com on April 22, 2011 22:09:55\nI'm about to release 0.9.3 which implements the init code you referenced. Please let me know if it has not fixed this issue - I'm assuming calling \"slamch\" and \"dlamch\" fix this.\n. Reopening to remind me to implement this again in the new generator.\n. turns out I had already remembered!\n. From Sam.Hall...@gmail.com on April 22, 2011 22:05:57\nWow, this would be a massive change - but I completely understand why you'd want it. One of my few gripes about java is the lack of support for subarrays, which would make this a non-issue.\nUnfortunately, the change request is far too much of an ask for the Native implementation. However, as a workaround, and if you're happy using just pure-java, then I suggest you revert to using the F2J Java implementations of BLAS and LAPACK directly. For example, call\norg.netlib.BLAS.Dscal.dscal(int n, double da, double[] dx, int _dx_offset, int incx)\nHope that helps you out!\n. From kevin.wa...@gmail.com on June 06, 2011 19:44:04\nHere's a patch that adds new methods with array offsets.  Works with F2J and native implementations.  Did not rigorously test it.\n. From Sam.Hall...@gmail.com on June 12, 2011 16:03:57\nThanks for this!! It'll be a while before I get round to another release - it's mostly maintenance now - but having the patch here allows anyone to use it if they find it useful.\nIf anyone else uses this patch and thinks it should be included in future releases, please let us know here.\n. Patch referred to above is at http://code.google.com/p/netlib-java/issues/attachmentText?id=7&aid=70002000&name=offsets.patch&token=9833_ACLfFU14_iKffWjP6KaeI%3A1371935558900\n. @dramage you originally reported this in 2011... just getting round to it now :-)\n. @kdub0 you submitted a patch to implement this in the old netlib-java code. I'm working on it now but the code has been completely rewritten. I'd appreciate it if you had a look to see if what I'm doing is efficient (and correct!)\n. @dlwh natives with offsets available in maven for OS X and Linux 64 bit. Enjoy :-) windows tonight/tomorrow\n. _From millst...@gmail.com on May 20, 2011 18:32:54\nOk, more info.  I checked out the version of netlib over svn and things seem to work.  IT is only when downloading the zip file that I got into issues.\n. From alex@bedatadriven.com on September 26, 2011 19:23:25\nHere is the corrected jniWrapperLoader()\nprivate String jniWrapperLoader(String wrapperName) {\n    StringBuilder b = new StringBuilder();\n    b.append(\"\\t// singleton\\n\");\n    b.append(\"\\tprotected static final Native\" + wrapperName\n            + \" INSTANCE = new Native\" + wrapperName + \"();\\n\\n\");\n    b.append(\"\\t// indicates if the JNI loaded OK. If this is false, calls to the native\\n\");\n    b.append(\"\\t// methods will fail with UnsatisfiedLinkError\\n\");\n    b.append(\"\\tprotected final boolean isLoaded;\\n\\n\");\n    b.append(\"\\tprivate Native\" + wrapperName + \"() {\\n\");\n    b.append(\"\\t\\tString libname = JNIMethods.getPortableLibraryName(\\\"jni\"\n            + wrapperName.toLowerCase() + \"\\\");\\n\");\n    b.append(\"\\t\\tboolean succeeded=false;\\n\");     \n    b.append(\"\\t\\ttry {\\n\");\n    b.append(\"\\t\\t\\tSystem.loadLibrary(libname);\\n\");\n    b.append(\"\\t\\t\\tsucceeded=true;\\n\");        \n    b.append(\"\\t\\t} catch (UnsatisfiedLinkError e) {\\n\");\n    b.append(\"\\t\\t} catch (SecurityException e) {\\n\");\n    b.append(\"\\t\\t}\\n\");\n    b.append(\"\\t\\tisLoaded = succeeded;\\n\");\n    b.append(\"\\t}\\n\\n\");\n    return b.toString();\n}\n. From Sam.Hall...@gmail.com on October 08, 2011 10:57:53\nThanks! I've committed this fix. I don't believe this is severe enough to warrant a full release but it will be included in the next one for sure. Let me know if you (or anyone else) really needs a release with this fix at this time.\n. From alex@bedatadriven.com on October 08, 2011 13:26:05\nGreat! No that's fine for now, I've set up renjin (R for the JVM) to use a patched version for the time being. I'll come back to hassle you when approach a full release ourselves!\n. From alex@bedatadriven.com on February 18, 2012 20:33:51\nHere is the fix.\n. From Sam.Hall...@gmail.com on February 19, 2012 11:13:31\nThanks Alex, this bug is a bit of a \"doh!\" moment. And very hard to test case for.\n. From alex@bedatadriven.com on February 21, 2012 09:17:14\nDefinitely! It's actually more an AppEngine problem, but probably quicker to fix in netlib-java. Thanks!\n. From martyv...@gmail.com on February 22, 2012 21:54:42\nsorry meant to do\nldd libjnilapack-linux-x86.so (the good one)\n    linux-gate.so.1 =>  (0xb7729000)\n    libblas.so.3gf => /usr/lib/libblas.so.3gf (0xb739c000)\n    liblapack.so.3gf => /usr/lib/liblapack.so.3gf (0xb6ac4000)\n    libc.so.6 => /lib/i386-linux-gnu/libc.so.6 (0xb6947000)\n    libgfortran.so.3 => /usr/lib/i386-linux-gnu/libgfortran.so.3 (0xb6845000)\n    libgcc_s.so.1 => /lib/i386-linux-gnu/libgcc_s.so.1 (0xb6827000)\n    libpthread.so.0 => /lib/i386-linux-gnu/libpthread.so.0 (0xb680c000)\n    libm.so.6 => /lib/i386-linux-gnu/libm.so.6 (0xb67e2000)\n    /lib/ld-linux.so.2 (0xb772a000)\n    libquadmath.so.0 => /usr/lib/i386-linux-gnu/libquadmath.so.0 (0xb676d000)\n. From martyv...@gmail.com on February 27, 2012 16:19:22\nupdate: I added -z defs to LDFLAGS in jni/configure, which showed lots of undefined symbols.  That led me to fix Makefile like this:\n$(LIBPREPEND)jnilapack$(LIBAPPEND): org_netlib_lapack_NativeLAPACK.h org_netlib_lapack_NativeLAPACK.o f2j_jni.o\n\u200b $(LD) $(LDFLAGS) $(BLAS_LIBS) $(LAPACK_LIBS) org_netlib_lapack_NativeLAPACK.o f2j_jni.o -o $@\n$(LD) $(LDFLAGS) org_netlib_lapack_NativeLAPACK.o f2j_jni.o $(BLAS_LIBS) $(LAPACK_LIBS) -o $@\nand then I get only a few undefineds\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_dlamc1':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x80195): undefined reference todlamc1_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_dlamc2':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x80611): undefined reference todlamc2_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_dlamc4':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x80803): undefined reference todlamc4_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_dlamc5':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x8095c): undefined reference todlamc5_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_slamc1':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x80bae): undefined reference toslamc1_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_slamc2':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x8102a): undefined reference toslamc2_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_slamc4':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x81210): undefined reference toslamc4_'\norg_netlib_lapack_NativeLAPACK.o: In function Java_org_netlib_lapack_NativeLAPACK_slamc5':\norg_netlib_lapack_NativeLAPACK.c:(.text+0x81369): undefined reference toslamc5_'\n. From Sam.Hall...@gmail.com on February 27, 2012 16:29:36\nCan you check and see if functions of those vague names exist in the lapack.h file - often the OS headers don't actually define all the functions correctly.\nThanks for the feedback on the Makefile, I'll have to check that it works on other OSes. Bizarre that the ordering of the flags makes such a difference!\n. From martyv...@gmail.com on February 27, 2012 16:35:31\nand I fixed those undefineds by adding\n\"slamc1\", \"slamc2\", \"slamc4\", \"slamc5\",\n\"dlamc1\", \"dlamc2\", \"dlamc4\", \"dlamc5\",\nto notSupportedByJNI after line 579 in JavaGenerator.java\nI also updated the other makefile targets to fix more undefineds like this:\n$(LIBPREPEND)jniblas$(LIBAPPEND): org_netlib_blas_NativeBLAS.h org_netlib_blas_NativeBLAS.o f2j_jni.o\n\u200b $(LD) $(LDFLAGS) $(BLAS_LIBS) org_netlib_blas_NativeBLAS.o f2j_jni.o -o $@\n$(LD) $(LDFLAGS) org_netlib_blas_NativeBLAS.o f2j_jni.o $(BLAS_LIBS) -o $@\n$(LIBPREPEND)jnilapack$(LIBAPPEND): org_netlib_lapack_NativeLAPACK.h org_netlib_lapack_NativeLAPACK.o f2j_jni.o\n\u200b $(LD) $(LDFLAGS) $(BLAS_LIBS) $(LAPACK_LIBS) org_netlib_lapack_NativeLAPACK.o f2j_jni.o -o $@\n$(LD) $(LDFLAGS) org_netlib_lapack_NativeLAPACK.o f2j_jni.o $(BLAS_LIBS) $(LAPACK_LIBS) -o $@\n$(LIBPREPEND)jniarpack$(LIBAPPEND): org_netlib_arpack_NativeARPACK.h org_netlib_arpack_NativeARPACK.o f2j_jni.o arpack.a\n\u200b $(LD) $(LDFLAGS) $(BLAS_LIBS) $(LAPACK_LIBS) $(FORTRAN_LIBS) org_netlib_arpack_NativeARPACK.o f2j_jni.o arpack.a -o $@\n$(LD) $(LDFLAGS) org_netlib_arpack_NativeARPACK.o f2j_jni.o arpack.a $(BLAS_LIBS) $(LAPACK_LIBS) $(FORTRAN_LIBS) -lm -o $@\nThat left me with one undefined, \"etime\", which I fixed by commenting the line\nEXTERNAL           ETIME\nin jni/ARPACK/UTIL/second.f\nhttp://ubuntuforums.org/showthread.php?t=1714367\n. From martyv...@gmail.com on February 27, 2012 16:44:08\nI am pretty sure there is no \"lapack.h\" on my system, only\n/usr/include/atlas/clapack.h\nand there is not much in there, e.g.\ngrep dgesdd /usr/include/atlas/*\ncomes up empty (huh?).  I think the build in your jni dir is succeeding because it is picking up the clapack.h that you supplied, which does define the offending slamc? and dlamc?\n. From Sam.Hall...@gmail.com on February 27, 2012 17:33:36\nYou're spot on. ATLAS doesn't define a full LAPACK implementation in the header file, sigh. However, that doesn't mean the functions don't exist. If the linker is linking them, then there is a good chance they are there but not in the header. (I gave up reporting this to ubuntu and occasionally I see some activity on the old bug report).\nYou can check the netlib distro here http://www.netlib.org/clapack/clapack.h and let me know what you find :-)\n(The generator could be updated to automatically determine the functions to call natively for a given system, but that could lead to all kinds of madness as then the classes themselves are system dependent (not just the JNI routines). That would imply that multiple classes must be made, perhaps following an OS/version/arch naming convention.)\n. From Sam.Hall...@gmail.com on October 16, 2012 19:55:14\nThis might be non-trivial and could involve having to write a maven plugin to generate code, instead of the current two-pass build system.\n. thanks to http://jira.codehaus.org/browse/MNG-1911 this will have two be implemented as two maven projects, not two modules. sigh\n. Modules for the legacy com.googlecode.netlib-java organisation:\n- source-generator\n- netlib-java (containing the Java impl)\n- native-common\n- native-osx\n- native-linux-atlas\nThis should enable future implementations to be created easily and loaded in a more sensible way.\n. Actually, we should break this down into blas, lapack and arpack, with the legacy organisation and netlib-java simply pulling in those projects.\nWe can have an umbrella project that pulls in everything for people as well.\n. https://docs.sonatype.org/display/Repository/Sonatype+OSS+Maven+Repository+Usage+Guide#SonatypeOSSMavenRepositoryUsageGuide-7b.StageExistingArtifacts\n. Quick update for people: the new generator code is almost finished. All the Java generation seems to be in place and I just have to rewrite the old JNI C code in antlr scripts. Easy loading of native libraries should be a big win for all users. The only thing that is likely to slow me down is getting the natives compiling on all the target platforms...\n. @dlwh what is your primary dev environment? I'd like you to try out my SNAPSHOT release when I have it building for your platform if that's ok (I have reference native BLAS/LAPACK working on OS X so far).\nAfter that I'll finalise the builds of the reference natives for all major platforms and start work on some \"optimised\" native backends (e.g. ATLAS or Intel builds... which will require some help from you).\nOnce that's done, I'll probably push a major release and then work on the offsets as a minor update.\n(we've actually been chatting on the thread for the offset RFE, I'm moving this here just to separate the issues).\n. @dlwh this is a bit of a hack at the moment, but it does seem to work for me in MTJ\n<dependency>\n        <groupId>com.googlecode.netlib-java</groupId>\n        <artifactId>netlib-java</artifactId>\n        <version>1.0-SNAPSHOT</version>\n    </dependency>\n    <dependency>\n        <groupId>com.github.fommil.netlib</groupId>\n        <artifactId>netlib-native_ref-osx_64</artifactId>\n        <version>1.0-SNAPSHOT</version>\n        <classifier>natives</classifier>\n    </dependency>\nYou'll need to have the sonatype snapshots enabled. This should work from SBT as well.\n(I intend to change the pom setup to be a one-import shot for all platforms... it's a bit tricky so hang in there!)\nand then when you run your application, set the following properties:\n-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS\n-Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.NativeRefLAPACK\nand enable ALL debugging in the com.github.fommil.netlib.level realm.\nThis is just the reference implementation of BLAS/LAPACK built with dragonegg. I intend to use the OS X optimised libraries once all the major OS are buiding under reference... although I might still have to compile the LAPACKE wrapper over the fortran libs (I think they use the horrible CLAPACK interface).\nPerformance wise, I'm seeing ddot take 30% of the time the Java impl takes on arrays of about 1 million entries about 80% on 10 million.\n. you can also specify -Dcom.github.fommil.jni.dir=... if you don't want to use a temporary directory, or extract the jnilib manually and point the javalibs dir at it (the usual JNI approach).\nJNILIB extraction is remarkably fast. I'm adding some profiling code to it now to test.\n. 93 milliseconds to extract the JNI file on my machine. That's once per JVM, so not bad :-)\n. btw, you can build the binaries yourself if you want to play around with compiler versions and optimisation flags. I found dragonegg was faster than gcc, and I didn't see any improvement with the i7-avx target specified... but I was only looking at ddot.\nOS X binaries are built by the native_ref/osx_64/pom.xml file and you'll need to clear out the target/objs if you want to change the flags. Compile takes 3-4 minutes on my machine. Instructions in the file. I'll create a module like this that is designed for end-users to use to compile their own versions.\nmvn -pl generator compile\nmvn compile\nmvn install\n. help needed: http://stackoverflow.com/questions/17912077\nNOTE TO SELF: don't forget to change the dependency tree so that the generator is not a dependency of downstream (and also try to work out why it's not being deployed to sonatype)\n. @dlwh Linux 64 bit build now available in sonatype. I think you might need to do a local \"mvn install\" of the generator jar to get this to work. Maven is being a bitch.\n. @dlwh I just made this a bit easier: The following is what you'll need (it'll grab the natives I have currently build for OS X and Linux, and soon Windows)\n<dependency>\n        <groupId>com.googlecode.netlib-java</groupId>\n        <artifactId>netlib-java</artifactId>\n        <version>1.0-SNAPSHOT</version>\n    </dependency>\n    <dependency>\n        <groupId>com.github.fommil.netlib</groupId>\n        <artifactId>all</artifactId>\n        <version>1.0-SNAPSHOT</version>\n        <type>pom</type>\n    </dependency>\nthen, as noted above, pass the following parameters to enable the reference implementation native binaries\n-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS\n-Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.NativeRefLAPACK\nThe reference implementation should be available on all major platforms.\nOther backends might only be available for some platforms, so selecting the right properties to use for a given target is being shunted to whoever packages the application.\n. (btw, once you change to use the com.github.fommil.netlib package instead of org.netlib, feel free to drop the legacy com.googlecode.netlib-java dependency. The API has remained the same... just a change in package name.)\n. Windows 64 bit support looks like it might be a PITA. The Fortran code looks like it's using 16bit INTEGERs and the C is using 32bit #typedef long int. It might even extend to float/double. If there is an inconsistency in float/double sizes, the JNI is never going to be efficient because we'd have to recreate all arrays explicitly for every call. The overhead for recreating jint* might be negligible compared to the savings... we already have to do this for Booleans because the fortran/java representation of a Boolean is different.\nI'm tracking Windows stuff in issue #23 \n. this actually stinks of #2 ... everybody seems to be using their own typedefs for ints and int arrays.\n. @dlwh Linux natives will always need to have the libgfortran3 library installed by the user. Unfortunately i've been unable to build partially static libraries as the fortran static lib (at least gcc4.7/ubuntu) is not compiled with the necessary -fPIC flags :-(\n. @kkofler glad that worked for you. This next release is primarily targeting 32 bit. I can't guarantee that the 32 bit types are all in agreement.\n. @kkofler I have decided not to support 32 bit architectures as they are too fiddly for me to build. However, I'd be happy to bundle the pom.xml to allow people to create the builds.\nYou're currently using the reference implementation. If you wait a few weeks, I'll have builds in place that use ATLAS.\nSee #24 #25 and #26 for the 32 bit tickets I've closed.\nIf you can teach me how to cross-compile an x86_32 binary on a 64 bit Linux, I'll consider re-opening #24. Same goes for #26 (I'd quite like to have Raspberry Pi support to be honest).\n. @kkofler  #25 might actually be doable... MinGW bundle a 32 bit compiler. Hmm. I'll see! If you can help with the Linux 32bit/ARM that would really help me out.\n. cross compiling would be awesome, as then I could build all targets from my OS X machine. I'll have to look into it.\n. @kkofler cross-compiling is slightly trickier than this... it is important that the correct Java header files and libraries are linked. For example, the native size of jint (which backs Java int values) is 32 bit on Windows (32/64 bit) but 64 bits on UNIX 64 bit.\n. Actually the code I wrote is GPL, but the generated code (which is the code in the jar file) is a translation of the original netlib code and therefore subject to its original license. I refactored much of this and contributed it to paranamer several years ago... but I never updated netlib-java to depend on it.\nI''ll get round to updating this at some point, thanks for pointing it out.\n. dupe of #12 \n. I'm in the middle of rewriting all of this.\n. @kkofler which OS are you on? I have a SNAPSHOT for OS X working and Linux/Win should be coming very soon.\n. @kkofler follow the other thread on this, it has instructions for Linux for the snapshot release\n. it would be great if we included some of the test routines like random matrix generation.\n. oh joy...\ntypedef long jint;\ntypedef __int64 jlong;\ntypedef signed char jbyte;\n64 bit Windows support might be a PITA, and might even require explicit construction of long* arrays from casts of the individual int* parts...\n. I forget myself: http://en.wikipedia.org/wiki/C_data_types\nlong is indeed an int (in classic C speak).\nSo perhaps this just needs some flags to change the type def in the BLAS...\n. This may be a moot point: int and long are actually the same size (32bit) on windows 64bit: http://en.wikipedia.org/wiki/64-bit_computing#64-bit_data_models\n. I've asked on SO about this http://stackoverflow.com/questions/18300653/ignore-type-warnings-on-windows\n. The latest problem to scupper this build: argument list to the linker is too long!!!\n. yuck http://cygwin.com/ml/cygwin/2006-12/msg00132.html\nPossible workarounds include:\n- getting a cross-compiler setup\n- building in C:\\netlib to reduce command line length\n. https://jira.codehaus.org/browse/MOJO-1963\n. cross compiled binaries should not be disted in snapshots. I'll need to wait for the weekend to test them... I'm not sure they've been linked correctly.\n. @kkofler I'm going to try and support linux 32 bit in the next release, however I'm seeing this error during linking\n/usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-linux-gnu/4.7/libgfortran.so when searching for -lgfortran\n/usr/bin/ld: skipping incompatible /usr/lib/gcc/x86_64-linux-gnu/4.7/libgfortran.a when searching for -lgfortran\n/usr/bin/ld: cannot find -lgfortran\ncollect2: error: ld returned 1 exit status\nwhich is weird, because I installed the 32 bit lib in /usr/lib32/libgfortran.so.3 and I'm passing -m32 -L/usr/lib32 to the linker.\n. turns out explicitly passing /usr/lib32/libgfortran.so.3 works\n. can you convert your last two posts into a PR?\n. @kkofler A Pull Request, not a new issue :-P\nI just wanted a one-line summary of what it is that you think will fix the problem... I am aware of why it is undesirable.\n. I think all of this can be summarised as: please run\nsudo apt-get install  lib32gfortran-4.8-dev\nright?\n. @kkofler I've uploaded 32 bit Linux binaries to snapshot them but I don't have access to 32 bit JVM on Linux. Can you please check these natives? I'll hold the release until you can confirm they work. A sensible test is to grab the trunk and run (in the perf directory)\nmvn test -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS -Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.NativeRefLAPACK\nand check the \"successfully loaded\" log output for linux-i686\n. @kkofler I don't need you to test your own build, I wanted you to test my binaries before release. I wiped the sonatype repo and will upload new ones in a few hours. If you could test those that would be good, but I now have an Ubuntu 32 bit machine that I can test with.\nBTW, the /opt/linux-i686/jdk7/include are essential when cross-compiling as I must use the correct cross-compiler and  target JVM to ensure compilation success. If you want to create your own binary builds, I'd recommending taking those poms as a starting point but building entirely new artefacts.\n. SUCCESS!!! Debian x86_64 successfully cross-compiles for 32bit and I tested it in Ubuntu 32 bit server (just to show some level of cross-distro support)\n. @kkofler you should be able to run the perf tests now without the need to compile anything locally (except the tests, of course). don't forget to install libgfortran3\n. FAILED testing :-(\nIt loaded ok but gave an unsatisfied link error when attempting to load ddot\n. asked on the mingw mailing list:\nhttp://sourceforge.net/mailarchive/forum.php?thread_name=046F4A0F-6C94-42AA-B9E1-7034DF4586D6%40gmail.com&forum_name=mingw-users\n. Mustn't forget this obscure linker flag! (who woulda thunk...)\n-Wl,--kill-at\n. I have this building for HF but not able to test just yet\n. http://www.raspbian.org/RaspbianInstaller\n. fail :-(\n```\nINFO: extracting jar:file:/home/pi/.m2/repository/com/github/fommil/netlib/netlib-native_ref-gnueabihf-arm/1.0-SNAPSHOT/netlib-native_ref-gnueabihf-arm-1.0-SNAPSHOT-natives.jar!/netlib-native_ref-gnueabihf-arm.so to /tmp/netlib3765034287720588808netlib-native_ref-gnueabihf-arm.so\n\nA fatal error has been detected by the Java Runtime Environment:\n\nInternal Error (os_linux_zero.cpp:285), pid=11949, tid=3062035568\nfatal error: caught unhandled signal 4\n```\nDoing a native compile now to see if this is even possible.\n. It works if I build from the RPi. I'm upgrading Ubuntu to see if gcc48 fixes things.\n. Ubuntu's cross-compiler doesn't work for the RPi... http://t.co/cEp0hACg6l what a mess.\n. Success! I'm going to create the R graph :-D\n. rather disappointing results...\n\n. maven native plugin seems to ignore the excludes tag. sigh\n. http://jira.codehaus.org/browse/MOJO-1967\n. I worked around it AND got performance charts for OS X veclib as the backend :-D DGEMM results are impressive but DGETRI is a bit disappointing compared to the pure C version.\n. yay! it was just a regression in the test parameters\n. @dlwh snapshots are now available with veclib support in OS X (Linux to come soon, I'm not sure about Windows... will have to investigate further) as discussed in https://github.com/scalanlp/breeze/issues/85\n. @dlwh this is insane, I'm seeing x10 performance for larger DBGEMM and DGETRI etc vs even the native ref\n. now windows builds available... but due to limitations in the availability of system BLAS/LAPACK, I had to link against libopenblas.\n. snapshots available on sonatype\n. reopening to get proper windows linking against a libblas3.dll and liblapack3.dll and cuBLAS support documented for OS X.\n. I have simple instructions now to build our own CBLAS/LAPACK to link against.\n. getting the following working are part of this ticket:\nhttps://developer.nvidia.com/cublas\nhttps://github.com/clMathLibraries/clBLAS\n. tested builds on osx, linux 32/64, win 32/64 and Raspberry Pi :-D\nUnfortunately, the OpenCL BLAS implementations are not quite there yet... but in theory end users can set it up long after we release (all they need to do is to implement CBLAS).\n. where all major OS in this case is Windows/Linux 64 bit (and maybe OS X 64 bit)\n. https://sourceforge.net/p/math-atlas/discussion/75123/thread/3d908506/\n. #27 let the user choose ATLAS at runtime...\n. docs should include performance results for various platforms.\n. rpi doesn't like the bigger matrix tests. we'll have to add an option for the max value to be used.\nWhile at it, the parameterized tests should return the true parameter they used.\n. refactor as a standalone main/jar (not test) that writes to CSV files\n. #23 #24 #25 #26 \n. also asked on SO http://stackoverflow.com/questions/18300820\n. edit\n/opt/local/var/macports//sources/rsync.macports.org/release/tarballs/ports/_resources/port1.0/group/crossgcc-1.0.tcl\nand add fortran as a language.\nthen\nsudo port -ns install i386-elf-gcc x86_64-elf-gcc build.jobs=1\nor\nsudo port -ns upgrade --force i386-elf-gcc x86_64-elf-gcc build.jobs=1\n(this currently fails to compile)\n(not sure about ARM / Windows yet)\n. I appear to be blocked by https://trac.macports.org/ticket/40177\n. maybe a better option: http://crosstool-ng.org\n. ./configure --prefix=/opt/crosstool --with-objcopy=gobjcopy --with-objdump=gobjdump --with-readelf=greadelf --with-libtool=glibtool --with-libtoolize=glibtoolize\nmake\n-->\nGEN    'config/configure.in'\n  GEN    'paths.mk'\n  GEN    'paths.sh'\n  CC     'zconf.tab.o'\nIn file included from zconf.tab.c:223:\nzconf.hash.c: In function \u2018kconf_id_lookup\u2019:\nzconf.hash.c:183: error: expected expression before \u2018struct\u2019\nzconf.hash.c:183: error: initializer element is not constant\n. Hmm, this might be bigger than just the offsets. Maybe the ordering for all the native code is wrong...\nBLASTest.offsets:58 [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0]: arrays first differed at element [2]; expected:<2.0> but was:<1.0>\n. @kdub0 any ideas why this might be failing?\nnative code for this function is\nJNIEXPORT void JNICALL Java_com_github_fommil_netlib_NativeRefBLAS_dscal_1offsets (JNIEnv * env, jobject calling_obj, jint n, jdouble da, jdoubleArray dx, jint _dx_offset, jint incx) {\n  jdouble * jni_dx = (*env)->GetPrimitiveArrayCritical(env, dx, JNI_FALSE);\n  check_memory(env, jni_dx);\ncblas_dscal(n, da, jni_dx + _dx_offset*sizeof(jdouble), incx);\n  (*env)->ReleasePrimitiveArrayCritical(env, dx, jni_dx, 0);\n}\nthe test is\n@Test\n  public void offsets() {\n    double[] matrix = new double[]{\n        1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1\n    };\n    blas.dscal(5, 2.0, matrix, 2, 5);\n    double[] expected = new double[]{\n        1, 1, 2, 1, 1,\n        1, 1, 2, 1, 1,\n        1, 1, 2, 1, 1,\n        1, 1, 2, 1, 1,\n        1, 1, 2, 1, 1\n    };\n    Assert.assertArrayEquals(Arrays.toString(matrix), expected, matrix, 0.0);\n  }\n. OK... think I've worked it out. The sizeof is redundant and it's making our pointers jump too far to the right.\n. http://www.netlib.org/benchmark/linpackjava/\n->\nhttp://www.netlib.org/benchmark/\n. http://code.google.com/p/java-matrix-benchmark\n. http://blog.mikiobraun.de/2009/04/some-benchmark-numbers-for-jblas.html\n. http://www.netlib.org/benchmark/linpackjava/LinpackJava.zip\n. turns out that LINPACK is pretty trivial to implement, so it should be part of #30 \n. this is looking impossible without physical access to older mac boxes. There are no cross compilers available to do this.\n. 32 bit builds should be possible: I have access to a machine\n. http://stackoverflow.com/questions/5333490\n. I am only going to support 32/64 bit. uploading them now... but will test 32bit tomorrow.\n. 32 bit failed to work on an older macbook. I'm abandoning support for OS X other than 64 bit Intel.\n. argh, the API has f2j object in it so we can't remove compile time deps\n. I learnt all about GLIBC versions and readelf -a... compiling on Debian (which has more modest glibc version restrictions) gives a wider range of portability across distributions.\n. we were case sensitive for char params, no big deal\n. last ticket before the release... very exciting!\n. while working on this, I think a bug in the native ARPACK was uncovered\njava(857,0x101ed2000) malloc: *** error for object 0x7f9f69c17138: incorrect checksum for freed object - object was probably modified after being freed.\n*** set a breakpoint in malloc_error_break to debug\n. no bug in ARPACK native, I was just calling it wrong\n. uuuh, this is on the wrong project\n. dlopen/dlsym and LoadLibrary/GetProcAddress are my friend\n. This deserves its own project: https://github.com/fommil/multiblas\n. @kkofler cool! do you have a reference for MUMPS?\nTAUCS is in C, not Fortran, so auto-generating Java code that fits into the same ecosystem as the existing BLAS/LAPACK/ARPACK APIs will be non-trivial.\n. I have no plans to work on this. The only sparse solver I know of in Java is ARPACK in MTJ. It would be good if you created a project on github with a port of TAUCS etc.\n. @dlwh On my machine (OS X) I'm getting a crash with this test, (same QR code):\nsbt \"test-only breeze.linalg.LinearAlgebraTest\"\nI'm also getting a failure for DenseMatrixTest, but that looks like a machine precision problem:\n[info] - Solve *** FAILED ***\n[info]   DenseVector(0.18131868131868126, -0.313186813186813, 0.4395604395604394) did not equal DenseVector(0.1813186813186811, -0.3131868131868131, 0.43956043956043944) (DenseMatrixTest.scala:375)\n. btw, I can confirm that there is no such crash or test failure with F2J backend\nSBT_OPTS=\"-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS -Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.F2jLAPACK -Dcom.github.fommil.netlib.ARPACK=com.github.fommil.netlib.F2jARPACK\" sbt \"test-only breeze.linalg.LinearAlgebraTest\"\n(you might need to edit your SBT launcher script to get this to work)\nand it also appears with the NativeRef builds\nSBT_OPTS=\"-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS -Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.NativeRefLAPACK -Dcom.github.fommil.netlib.ARPACK=com.github.fommil.netlib.NativeRefARPACK\" sbt \"test-only breeze.linalg.LinearAlgebraTest\"\nHowever, the problem also arises when I go back to 1.0, so this is not a regression. Oops! Is this a new test?\n. @dlwh I found it. Technically speaking it's a bug in your code :-P but I think I should support the corner case so I'll fix it on my end.\nYou're passing null arrays and that means when I try to get a reference to the array in the native code it fails.\n. @dlwh I've disted new SNAPSHOTs, but I think you need to check your test logic :-P\n```\nINFO: successfully loaded /var/folders/lr/331rxc_d187d9pmrwjj99nvr0000gn/T/jniloader2052816085861155377netlib-native_system-osx-x86_64.jnilib\n[info] LinearAlgebraTest:\n[info] - qr  FAILED \n[info]   0.06052275326688006 was not -0.06052275326 plus or minus 1.0E-8 (LinearAlgebraTest.scala:145)\n``\n. @kkofler sorry, but I'm not going to fix this:\n1. it would complicate (the already very complicated) build/release process on my side\n2. it would mean that there are **three** copies of each native file in central maven... I'm embarrassed enough that there are two.\n3. if people choose to step outside the maven / ivy world then they bring this onto themselves.\n4. bundling \"system optimized\" natives is against the whole point of that backend. It is the responsibility of the end user  / provisioning to ensure that they are available at runtime. I'm not going to be distributing one vendor's generic implementation: that's what the native ref is for.\n. @kkofler as a workaround, you can build your own single jar distro. just look in theperf` module for how to do that.\nSpecifically\ncd perf\nmvn compile assembly:single\nhttps://github.com/fommil/netlib-java/blob/master/perf/pom.xml#L9\nalthough you might want to copy the pom.xml to your own filesystem, delete the src and remove the dependencies that are only for the performance tests (e.g. Guava, OpenCSV).\n. @kkofler another workaround is to build a single MTJ and netlib-java jar, the same assembly command will work with the trunk https://github.com/fommil/matrix-toolkits-java/\n. @kkofler remove the <type>pom</type> from the legacy API. This will be removed in the next release, so I suggest you migrate now. Yes, I noted that you should remove the performance test dependencies.\nYes, the binaries are rather large, hence my reluctance to distribute an additional file that doubles the storage and bandwidth requirements. I also have absolutely no intention of encouraging self management of jars. The correct solution is for you to use a dependency manager: use Ivy if you're stuck with ant (the legacy build system of Netbeans).\nThe OpenBLAS builds are generic as they don't include a lot of the compiler optimisation flags that one would expect of a system optimised binary. They are also generically tuned instead of machine empirically tuned. The instructions for enabling OpenBLAS on a Windows machine are in the README and please encourage OpenBLAS to build statically against the gcc / gfortran libs to make the installation even easier for end users and system admins: https://github.com/xianyi/OpenBLAS/issues/296 Installation amounts to dropping a file into a library, it doesn't get much simpler than that.\nI have no intentions of distributing vendor specific implementations. They either implement BLAS/LAPACK or they don't. If they do, NativeSystem is how to use it.\n. @kkofler thanks! I'll make sure this makes the 1.1 release. If you could send pull requests, instead of patches, in the future that would really help clean up my workflow. Github is great!\n. @kkofler I can restrict the symbols on Linux and OS X, but if you ever want this for Windows too then you're going to have to create a .def file containing an explicit list of all the Java_ symbols.\nI've uploaded the corrected binaries for all systems. Please try them and let me know if they work for you. I'm planning on making the 1.1 release this weekend.\n. @kkofler if I do -s when stripping, then nm -a claims there are no symbols at all, so I do not wish to strip everything, I only want to strip non-global -x and debugging -S. However, ld seems to ignore this and I have no way in this workflow to run strip afterwards: http://stackoverflow.com/questions/19289901\nI'm running another compile with flags to remove unused code. I'll upload tonight.\nRe: Windows, see here http://sourceforge.net/p/mingw/bugs/1134/ specifically\n--version-script=version-scriptfile\n           Specify the name of a version script to the linker.  This is typically used when creating shared libraries to specify additional information about the version\n           hierarchy for the library being created.  This option is only fully supported on ELF platforms which support shared libraries\nso a .DEF file is required. I have no plans to build or ship such files.\n. I'm getting some assertion errors during the Raspberry Pi compile. I need to check that all the tests pass at the weekend before feeling comfortable enough to release this.\n. well, I'm doing the symbol table lookup on windows just to be on the safe side.\nThe native system libs you tried today weren't actually the new ones.\nI need to check the ARM bins before I can release: the dead code removal was causing assertion errors and I want to make sure the assertion errors were just overzealous warnings and not that my binaries are borked.\n. we already have zero copy between Java and native code through the critical array primitive sections, so I don't see what advantage this could bring.\nIn addition, if you have huge files on disc, it is highly likely that they will be sparse (and hence not appropriate for blas routines anyway) and the memory pipelining of such a setup would offset any potential benefits from native implementations.\nI'm closing this ticket because I don't intend to work on this: it would result in a dramatic change to the API (effectively making the entire current API legacy). I really don't believe this is simple.\nHowever, I'd love to see a feasibility that shows that NIO buffers are faster than arrays with critical sections. Would you be prepared to do this? I would honestly be shocked if you could show this, as all major OSes already have zero copy. It sounds like jcuda and jcublas should be exposing an array based API.\nBTW, you can potentially swap the netlib implementation to use CUBLAS as the backend if you like, see MultiBLAS, no need to use \"jcublas\" directly (which, incidentally, I've never heard of).\nMy performance tests (see the Performance section of the README) showed that GPU BLAS backends are not quite there yet as drop-in replacements, as the memory transfer costs outweigh the benefits of the faster computation, so it is necessary to rewrite programs to make use of the GPU memory addressing system. Perhaps this is what jcublas does: a wrapper over the C API.\nBTW, BLAS/LAPACK are Fortran APIs, not C ;-) The C API (which simply delegates to the BLAS routines) are called CBLAS and LAPACKE, respectively.\n. hmm, that's all pretty old thinking for the critical regions. I've never seen any problems - does one use of a critical region in one piece of JNI code really stop GC for everything? For all implementations of the GC? And for all memory regions? If that is true, it's a pretty epic performance bottleneck in the JVM.\nIn any case, netlib-java is best used in a manner such that the native code is only being called by one (or a very small number of) Java threads at a time. The reason for this is because native implementations will tend to use all your CPU cores anyway, so trying to do any multi-threading organisation on top is just going to burden the OS's context switcher. I created MultiBLAS to see if multiple processor architectures could be used to get additional throughput (e.g. if the CPU is busy, use the GPU, even though it's not really much faster) but I've been distracted by other projects.\nI'd be happy to advise on a pull request with a ByteBuffer alternative API. NIO is something I considered at the outset (many years ago) but I concluded that the user base for such an API would be too small to warrant any work on it, the additional cost to PermGen would be high, and it would only be beneficial to users of the native backends (it would necessarily slow down the fallback F2J implementation).\nI can certainly see the benefit of using ByteBuffers if CUDA is maintaining its own special memory regions. That's something we can't map as a critical region, since it is created in the native code. I wasn't aware that CUDA created any special memory zones in the CPU memory space... I thought it was all GPU stuff which one can't access via NIO.\nThe reality is that \"CUBLAS\" is not actually BLAS. It's a BLAS-like thing, which requires special memory management. I'm going to keep an eye on this whole space over the next few years and my hope is that the memory transfer costs reduce to the point where special memory regions are no longer needed.\nBTW, If you start work on a Pull Request, you'll see that it is definitely not a simple addition ;-) You'll need to appreciate the amount of code that is auto generated, and the process required to push native binaries, to fully appreciate the magnitude of what you're asking.\n. have you got a definitive reference on critical sections blocking different types of GC? I'd really like to know the fuller story as I've heard several . (It suppose it wouldn't be too hard to write a small JNI that simply blocks for 5 minutes, and then do some work and observe the whole thing in VisualVM, but I'd like to hear the official story.)\nI have certainly used GPUs, that's what my other project is for, but I didn't realise that CUDA had a special type of memory mapping between CPU and GPU memory spaces. What is the native function call that you're making to create the memory region?\n. I'm reopening this just because it is still of interest, but I don't have any time for plans to work on this personally so Pull Requests (or funding!) is realistically the only way its going to happen :-(\n. If you know anyone willing to fund this for a few months, please let me know.\n. BTW most people who think they need nio buffers don't really understand what netlib-java is doing and don't actually need it. But I can see it would be an improvement and there are rare cases that would benefit.\n. @bkgood hi, thanks for looking at this! From skimming your branch, it does look a bit hacky for me to be able to merge into the main code branch: this would effectively create two extra API variants for everything that we currently have? (correct me if I'm wrong)\nIf this work is going to be done, I'd like it to be done from the ground up and for F2J to support the same API. That approach would involve going the #76 direction. Realistically, I'd be looking for funding for a 6 month period to do this.\n. I suppose I could be convinced by something that supports F2J in a second API. But actually cutting a belli is extremely complex. Perhaps it's easier now that docker exists, but OS X was always the problem.\n. /belli/release/ (to idea what autocorrect was doing there)\n. I think a second API would be best otherwise we'll be hitting classfile limits on the existing interfaces/classes.\n. Well, there is that limit, but I'm also thinking about the burden on anyone who uses this library.\n. 1. does this crash your application?\n2. are you using the latest release 1.1.2 of netlib-java?\n. the external .so needs to be a JNI that points to the BLAS/LAPACK. You shouldn't need to create your own, just place your custom BLAS/LAPACK on the dynamic link path as per the instructions in the README.\n. yeah, probably binary incompatibilities sorry. You're probably best asking on Linux forums for your distro as these things can be fiddly. I compiled the JNI code on a pretty old debian to try and make it as compatible with as many systems as possible.\nWorst case scenario, you build your own JNI binaries.\n. or, just live with the fortran reference implementation or the Java code on this system. It might work fine on your target systems. \n. it's probably incompatible gfortran libs\n. make sure you have netlib-java 1.1.2\n. @jmelot did you follow all the advice here? https://github.com/fommil/netlib-java#linux\nI'm very surprised about these reports of Ubuntu precise not working, it was one of my test platforms.\n. if NativeRefBLAS fails to load, it means you don't have the correct version of libfortran installed.\n. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis.\n. please read the README for setup on different Linux distributions, and also, the MTJ README that shows how to work around this particular issue.\n. @dlampart did this solve your issue? I've been meaning to release an update of MTJ that pulls in the correct version for a while now.\n. Try bumping the org.netlib logging towards FINEST. \nAlso what is your LD_LIBRARY_PATH? \n. And what version of gfortran is installed? \n. Ugh, bloody archlinux. Create your own maven save artifact. The poms are reasonably well documented, for my own sake. \n. Hi, these are standard Java questions, not specific to netlib-java. I recommend reading the Javadocs for your logging framework.\n. https://github.com/fommil/netlib-java#machine-optimised-system-libraries\n- Linux (i686, x86_64, Raspberry Pi armhf) (must have libgfortran3 installed)\n...\nTo enable machine optimised natives in netlib-java, end-users make their machine-optimised libblas3 (CBLAS) and liblapack3 (Fortran) available as shared libraries at runtime.\n. On mobile device sorry for terse response. Reread the README, you're linking to wrong lib.\n. you can't do it at the moment. I did speed tests using C code and concluded that there was no point because memory overhead costs to/from the GPU negate all the benefits.\nThe reason you can't use it directly is because CudaBLAS is not BLAS. It's BLAS-like.\n. Cool! Thanks for pointing it out. I actually have a GPU project in the pipeline too, but probably best to discuss it privately for now as it may be something I'm doing commercially if there is a market for it. \n. Sweet! I've never heard of that setup before. If you're getting below \"The Zone\"  then you're definitely sharing memory between CPU and  GPU.  I'd planned to do something in this space but couldn't commercially justify it. I'm glad it has moved on. I'll have to read up on this library that you reference. If they are smart, they'll implement libblas.so. If they can't, they are cheating in the way described in my README \n. Watch my talk :smile:\nIf they can't implement libblas.so then they have some custom memory management that will only work for a small set of examples and will never be appropriate for arbitrary linear algebra. I hope they are using APU shared memory because that is the future. \n. it is impossible to get faster than MKL using the traditional CPU memory region. If they are using the GPU then they are using the GPU memory region: which means they can't implement libblas.so because libblas.so takes pointers to the CPU memory region. They could, however, be getting a performance benefit by \"cheating\" and only using GPU memory, they won't be including copying memory to/from the GPU region, which is absolutely necessary to get any results out of the computations.\n. if you can write your entire algorithm to run in the GPU so that you only copy in the setup and copy back the result, that's probably going to give you the best performance. That means not using BLAS/LAPACK (for the reasons discussed above) so it is certainly less portable.\nI really hope that APUs fix this and in which case you'll find that netlib-java with MultiBLAS (using dual MKL/GPU backends) will win every race :wink: That won't even require you to update your netlib-java installation.\n. @avulanov btw, locally compiling OpenBLAS won't give you a performance speedup. It is assembly code so doesn't tune itself. You're thinking of ATLAS (I admit, my own README doesn't help clear this up... I should rewrite it). Ditto, MKL (which is proprietary anyway).\n. @avulanov btw, how did you do netlib-cublas ?? I'm not aware of a libblas.so.3 that is provided by cuBLAS. It would be very interesting if there is one!\n. oh, it might be a version thing. Was the pre-installed version of OpenBLAS version perhaps lacking your CPU instructions?\nRe: cublas I don't see how that would work. libcublas is not BLAS... it is BLAS-like. Unless they recently released a real BLAS implementation. Check that JNILoader didn't just bail.\nBTW, I don't know why you're building netlib-java for this. You just need to change the library at runtime... have a read of the README again because you're doing far too much work.\n. @EmergentOrder I don't need to use anything specific in netlib-java, you can swap libblas implementations at runtime.\n. do an ldd on the .so files, you'll see missing links.\n(my money is on missing or incompatible libgfortran3)\n. is this on the machine that works? you need it on the failing machine\n. btw, you can certainly lower the debugging levels to ALL or something like that for com.github.fommil. it's just using the JUL (and I presume you're routing that through SLF4J/logback or something similar).\n. oh, might be classpath/classloader weirdness. looks like your binaries are good for that machine, which is good news. or maybe spark doesn't pass on the properties you are setting.\n. That mailing list is confused. Breeze doesn't use jblas anymore. \nClosing because this is a native problem. \n. @yangliuyu be careful with licenses when distributing such \"assembled\" jars as not all packages allow it.\n. hmm, looks like you're missing the cblas layer on top of BLAS (which is a fortran API). most distros compile the C API into the blas library.\nCheck if you have a libcblas you can install (e.g. ATLAS' version)\nOr compile your own CBLAS against your fortran BLAS. Sources included in this project.\nCan you do an ldd against the system-linux lib?\nDoes the reference lib work ok?\n. yeah, unfortunately the only thing I can recommend is to tell Fedora to learn how to package these projects correctly.\nYou could try installing the debian/ubuntu equivalents.\nYou don't need to recompile netlib-java. You just need to link it to a library at runtime that implements libblas.so.3 and liblapack.so.3 through symlinks.\nTry OpenBLAS or Intel's Math Kernel Library. They are faster anyway.\n. GSL is GPL. Make sure that your application is correctly licensed GPL if distributing them linked to GSL.. Or use docker / virtual machine orchestration. A lot than changed in the last few years.\n. would everybody stop downloading the bloody zip file! Don't you people know how to use maven ffs?\n. I'm updating the README to explicitly say not to download the zip file because I'm getting an email like this every day now.\n. https://github.com/fommil/netlib-java/blob/master/README.md#installation\n. sorry, to accept this patch would be to rewrite history, but I can help explain the situation.\nBasically there is no 1.1.2 release for many of the modules because it was a bugfix release for the core but natives remained unchanged. I released a 1.1.2 parent simply for convenience of end users.\nWhat you really want to do is to go back to the 1.1.0 tag\nhttps://github.com/fommil/netlib-java/tree/1.1.0\nand rebuild just the native modules that you want.\nI made everything separate modules for the reason that they could each have separate versioned releases without incurring rebuilds for all the other platforms. Doing a full build would probably take me a full day now because it requires setting up so many environments.\nI was able to get Linux to cross-build to all platforms except OSX. If somebody could help me out with building for OSX from Linux, I could move this to a single build and even pump out snapshots from travis/cloudbees in a CI.\nHow old is your cluster? I actually went really far back for my linux builds and used debian wheezy. I even tested it on really old RHEL.\n. we're using the built-in Java (JUL) logger: see an article here http://www.vogella.com/tutorials/Logging/article.html\nIf you are using a wrapper around JUL, such as SLF4J, then it will have its own way of doing it.\n. that article is actually really terrible, this is better http://tutorials.jenkov.com/java-logging/configuration.html\n. @naiveCoder you need to spend more time reading the documentation of JUL, it is clear from what you have posted that you haven't quite figured it out yet.\nFrom your questions, I'm getting the impression that you are a new Java developer. You should be aware that netlib-java is a very advanced piece of kit, and the native bindings are well beyond what most seasoned Java developers are used to dealing with. If system natives are not working for you after following the instructions, then I seriously doubt that you'll be able to debug this. I recommend just using the default implementation and only investing in natives if you have strong evidence that this is a bottleneck for your application.\n. you might find that http://stackoverflow.com/ is a better forum for these kinds of questions: I am happy to help with any problems specifically related to netlib-java but this is basic java stuff.\n. that sounds like a problem with your native libraries, not in netlib-java.\nI recommend using a BLAS supplied by your chip manufacturer, and if you're really keen try to isolate the problem in OpenBLAS and submit a bug report to them.\n. This is an extremely non-trivial project to build. Just use the published jars unless you are aiming to contribute. \n. This is through the standard logging framework. Learn how to do this via the Java Util Logging API (or use the JUL backend to SLF4J).\nUnfortunately it is not possible to get any more fine grained detail than \"it failed to load\" because it's all happening in the native layer. You could try extracting the relevant netlib-java .so and doing an ldd on it to see which libs it is linking to.\n. Read the README again. \n. That's because there is no snapshot version. Use stable. Why would you even want to do that? \n. this is wrong on so many levels. If you insist on actually building your own cut of netlib-java, you should at least be using the commit tagged as the release. Why you're rolling your own build, I have no idea, everything is published on maven central.\n. @DreamFlasher why are you unable to use official builds from maven central? Which is working for 100,000+ downloads per month.\n1.1.2 was a critical bugfix release for only one submodule, hence not all poms were updated: https://github.com/fommil/netlib-java/commit/8bafea3d6478dedd0c0f9d1bcda47d8958c822cc\n. @avulanov yes, only custom installs on unsupported hardware. I would never recommend this approach as the way to \"install netlib-java\" as it is near-on impossible to get right.\n. I'm only supporting netlib-java on a commercial basis.\n. Apache don't let us use LGPL, so I've had to make the native parts optional. \nSorry, this would upset Apache too much (who are doing this for political reasons... LGPL is far superior to Apache License) \nCan you please add a link to the libraries you're talking about? I'm not sure it would make sense to pull in other Java libraries because applications can just pull them in if they need them  anyway. \n. Btw MTJ in LGPL so if you have a faster alternative for some solver, you could put it there! \n. The build pipeline for netlib-java is incredibly complex, due to the lack of cross-compilers to OS X (particularly the fortran and libvec linking).\nEven for other native libraries, I'm going to create separate projects. The goal of netlib-java is really just the netlib.org libraries onto the JVM.\nre: \"compiling with native netlib flag\", what do you mean? Please watch my talk, linked from the main page, for more details on why \"system optimised\" is far superior to the \"native\" libs. Also, I trust that you're not actually recompiling netlib-java.\n. @debasish83 also reread the spark docs on this area. I updated them very recently. The spark guys were a bit confused with the details :-)\n. @debasish83  https://github.com/apache/spark/blob/0cba802adf15f5ab8da24dd1e8a5e7214cc4e148/docs/mllib-guide.md#dependencies\n. watch my talk\n. just using the fortran compiled blas/lapack is still going to be crap, you need to set up MKL or OpenBLAS to get real performance.\n. the javadocs are needed to build netlib-java with provided scope. Sounds like a bug in sbt/ivy if you're pulling it in.\n. heh, maybe it's a maven bug.\n. I'll reopen, but mark blocked (upstream).\n. thinking about this again, it's definitely an upstream bug.\n. This sounds like a spark environmental problem. You'd be best asking on the spark user's list as all I can do is point you at the netlib-java README which tells you everything that needs to be available, sorry.\n. awesome, thanks! I'm sure many people will be thankful of this.\nI think it's a bit long and detailed for the README --- it's actually longer the entire current section on system optimised natives. I'd be happy to take this as a full Wiki page. Do you have edit rights to create a new page?\nThen we'll create a link to the wiki page. Hopefully, being a wiki, others will feel compelled to expand on it and we're more likely to have up-to-date instructions. :smile:\n. save it, for sure! The Wiki is a great place for documenting exotic natives. Probably best that you call it NVBLAS rather than something generic like GPU.\n. @avulanov \nYou also need a library that has CBLAS interface and calls Fortran BLAS. In Debian/Ubuntu it is libblas.so.3:\nIn Debian/Ubuntu the libblas.so.3 is the Fortran and C API together. Are you sure that this technique works?\nGiven that we have to compile CBLAS anyway, it feels like a simpler approach might be to compile the netlib CBLAS API with linking flags to nvblas.so. Then there should be no need to LD_PRELOAD anything and users on Debian-based systems can simply use the alternatives system.\nIndeed, since the compilation of the CBLAS API, linked to NVBLAS, is MIT licensed, you/we could even offer a .tar.gz download to go into /opt/nvblas.\n. ok, I didn't realise that it was possible to have multiple definitions of the same symbols in C. How come this doesn't work for ATLAS?\nI'll add the link tonight, ping me if I forget.\n. I'm pretty sure ATLAS and OpenBLAS implement both the fortran and C APIs. You can check by inspecting the binaries, the fortran API just gets an underscore before its name in C land.\n. linked :smile: thanks again! And don't forget to post the link to the spark mailing list\n. got you now\n. Try just the BLAS, I'm not sure which API they implement. Maybe ask on one of their forums to find out which library you need to link to, and confirm that they have CBLAS. If not, you might need to do something similar to nvidia (NVBLAS). \n. interesting, we had a similar report at https://github.com/fommil/matrix-toolkits-java/issues/64 which is ultimately using the same core libs.\nFundamentally, the results are always going to be prone to error (see my scalax talk's section about errors) and quality can vary wildly between implementations.\n~~However, the more concerning thing from my perspective is if there is a multi-threaded aspect to these reports. The jury is still out, but it looks like some threads see the arrays in a different state. Try wrapping your tests in synchronized blocks to force a memory resync (equivalent to putting volatile on everything).~~ ok you only have one thread, so that's irrelevant.\n. http://fommil.github.io/scalax14/#/ => go to video bit\nin particular skip through to http://fommil.github.io/scalax14/#/6 (key down in the web slides)\n. the implementations most certainly will parallelise under the hood. If you are able to do some error tracking using the BLAS/LAPACK error tracing functions then it would be incredibly useful to confirm that the results are coming back within the tolerances claimed by the implementation.\nHonestly, it is not surprising that you're seeing variation and I recommend using Intel MKL over ATLAS / OpenBLAS. If accuracy is more important to you than speed, then you might even want to look at using a specialist high precision implementation (e.g. the xxdg... libs) directly.\n. Ok, if you need determinism then you can't use any parallelism. Go with F2J.\nRounding errors alone are prone to ordering. \nClosing, but I'd still love to hear the results of your analysis here when you do it. \n. Android isn't real java so I honestly don't know. You might be best doing some performance tests first of DGEMM in Java and then from a C app just to get an idea of the potential benefits to see if it is worthwhile. RPi was worth it because java was really slow at the time but Google might have invested a lot in making their virtual machine really good. \n. It's documented in the pom files. Sorry, it's quite a painful process and honestly I'm only going to dive into it on a commercial basis because it's not something that I need.\n. I am completely unable to convince java to actually show me the segfault so I have no idea which function is exhibiting the problem. But what I do know is that it works on Debian Wheezy (in a docker container) and the \"native ref\" implementation is ok... so that would point at a problem with the external implementation (e.g. openblas or MKL).\n. ATLAS actually works as a backend. So OpenBLAS appears to be broken and I have no idea what is wrong with MKL.\n. I'm upgrading MKL to see if that fixes it.\n. Right, I think I got to the bottom of this. It looks like it's an issue with ATLAS installing a libcblas.so in /usr/lib/libcblas.so.\nBasically, my MKL and OpenBLAS aren't working using gcc and all fresh sources... so my system is clearly borked. Closing as it isn't relevant to the larger community.\n. doh! I forgot to follow my own bloody instructions and add the MKL libs to the ld.conf files.\n. downstream (not upstream) bug\n. Unfortunately making a release is exceptionally difficult due to the cross build nature. I don't think I'll be doing a release just for this, although if you were to send in a PR it word be part of the next release.\n. How does OSGi even handle natives?\n. @briantopping I think you'd have to dive into the details of how a multi-platform cross compile of fortran libraries and JNI actually works before we could say anything about packaging. I could add all the natives to one jar already with an extra step, but that doesn't help deployment because we're using JNILoader to simplify the cross platform deploy --- indeed many people would complain that they were being forced to install natives for platforms that they don't care about. Good luck, this is one of the most necessarily complex builds you'll find :smile: Perhaps if it could be refactored into a build that can be build from a docker image, it would simplify things a lot but I can't cross compile Fortran libs for OSX.\n. #68 may need to be a dependency to anything to be honest.\n. As RHEL 7 is a paywalled (and increasingly proprietary) platform, it is extremely unlikely that I will be able to do anything for you without a commercial engagement.\nYou can try to debug this yourself by extracting the binary that is attempting to link to your system implementation and run ldd on it. If that looks ok, then look inside your libblas.so.3, liblapack.so.3 and libgfortran3.so and see if they are missing any symbols that are referred to.\nOne guess I have is that perhaps RHEL have gone and packaged CBLAS into the BLAS.\n. What about the reference native implementation? If that works, at least the fortran libs are linking OK. Also, read the README again closely to make sure you've followed all the steps.\n. Yeah, looks like you need to start inspecting symbols. Sounds like RHEL cocked up and broke backwards compact on these libraries.\n. It sounds like there in a confusion here about what is going wrong. Your ldd shows that there is no linker problem (assuming you run Java apps in the same environment as your shell). The problem must therefore be an expectation problem: some symbols must be missing from RHEL's system libraries. To find them, you'll need to inspect the symbol lists against a working system or try to compile against the netlib natives with a test C app. You're going to have the get your hands dirty.\nSpecifying the natives in the properties as you have suggested makes no sense. The natives need to implement the netlib-java API, not BLAS/LAPACK..\nOne question you should really ask yourself is: do you really need the performance from system natives? And if you have an empirical answer to that question, you probably wouldn't be using ATLAS to be perfectly honest ;-) (I strongly recommend that you watch the talk I gave at Scala exchange last year, linked from the readme)\n. native_ref is the reference implementation in Fortran. I recommend doing some performance testing as it is rarely of benefit.\nYou need native_system if you want to be using your OpenBLAS. Is that what you see after updating the symlinks?\n. yeah, as I suspected it sounds like RHEL have screwed up the packaging of the libraries. At least they haven't broken binary compatibility, which is good news. OpenBLAS is much better than ATLAS anyway, outshined only by MKL.\nThanks for feeding back your conclusions.\n. this is all documented in https://github.com/fommil/netlib-java#machine-optimised-system-libraries\nIf you are passing your libopenblas.so as a parameter to com.github.fommil.netlib.NativeSystemBLAS.natives you have not fully grokked the documentation, as that will not work.\n. ask your GNU/Linux distribution or sysadmin to provide you with the ability to create these links\n. probably creating a link from liblapack.so.3 to libopenblas.so will work, but you don't pass these to the JVM like you're doing: that's the jni library that goes there.\n. happy hacking\n. You must be terminating the JVM forcefully or have a buggy runtime because it's flagged as delete on exit. You can manage the native lib location manually, read the docs for JNILoader.\n. Or don't use natives. Most people don't actually need natives.\n. thats all normal, see my comments above.\n. sorry, I've actually never set this up on Windows MKL... when I had access to a windows box I just made sure it worked with the reference, ATLAS and openblas implementations.\nnote https://github.com/fommil/netlib-java#customisation specifically the bit in bold text, where I think you have gone wrong.\n. FWIW I think it should \"just work\" if you copy the MKL libs to files with these names (they make the same mistake as openblas), again note the docs:\n\nThe native_system builds expect to find libblas3.dll and liblapack3.dll on the %PATH%\n. if its anything like the Linux version, it is not enough to have that one file on your libpath, you'll also need to ensure that the OS knows about the entire MKL directory (plus the renaming is very important).\n. Probably the MKL forums are the must place to discuss. Please link us up the the discussions.\n. Must => best\n. If you're not using the jars that I publish, you're on your own. In fact, I have absolutely no idea why you would ever try to compile netlib-java. https://github.com/fommil/netlib-java#installation\n. There is an entire section it the README specifically for this.\n. Your maven config is definitely wrong, probably you disabled transitive deps.\n. It does. Sounds like you have a bad system config. You need a reproducible falling test case (use docker) to convince me otherwise.\n. It is hardly ominous. Apache Spark can't distribute LGPL (e.g. jni-loader) or proprietary binaries (e.g. Intel MKL).\n. I've tried contacting people, but not got any response. If you have any contacts in that area, I'd be happy to talk to them, but I'm not sure what value would be added by having this support in the JDK... the real power comes from the backend implementation anyway and provisioning your JDK to have the correct load path is probably a lot harder than configuring a dynamic library.\n. @almson watch my talk and see why you won't get a benefit unless you have machine optimised binaries. It's not enough to link to any old \"native BLAS\", Java is faster than you think.\n. The talk linked on the main page. I'd be amazed if you don't learn something from it. I learnt a lot writing it. Unless Oracle plan on shipping MKL, I really can't see an embedded BLAS actually improving anything.\n. You should ask on spark mailing lists. I don't have time to answer devops questions unless it's under a commercial arrangement.\n. yes, it's all standard JUL logging. I don't know how you've set any of this up so I can't comment on how to change it. No doubt Spark does some magic with log messages.\n. android is not supported, see the README.\n. (you should just be using the F2J implementation, I don't know why you're trying to load natives that are not there)\n. Caused by: java.lang.ClassNotFoundException: Didn't find class \"com.github.fommil.netlib.BLAS\"\n\nthis means you have not got the required jars on your classpath. It's not a bug in netlib-java.\nDepending on all is wasteful on Android, you only need core.\n. hmm, I wonder if gradle is unable to correctly handle pom only projects.\n. Interesting, when was the routine added to LAPACK?\n. OK, well that might be after the f2j jar was built, which defines our set.\nI'm afraid it would be a large undertaking, with a large component devops, to rebuild everything off the latest LAPACK, so I could only look into this on a commercial basis. Perhaps a full week's work (the biggest difficulty is prepping cross platform build machines) going via #20 assuming f2j handles the updates to LAPACK, which it might not if they upgraded their Fortran version or changed their coding style.\nRather than solve it directly like this, which is not scalable, I'd be far more interested in tackling it via #76 which would bring many additional benefits with it. That is more like 1 - 3 months.\n. OK, will close as a dupe then.\n. I only do custom builds on a commercial basis - it is not trivial and requires access to the target hardware. You need to read and understand the pom.xml files to be able to do this yourself.\n. Because a) it is a support request that I've answered and b) I'm not interested in fixing this without financial remuneration.\n. @edelsohn if you want this implemented, please feel free to contact me directly, but I will warn you that the kinds of money your bounty programme is proposing is not really something that grabs my attention. Feel free to create and publish your own artefacts using the code generator here, it is designed to be used as such. I consider ppc64 to be too niche.\n. depends on #76 and possibly significant extra work if the APU uses callbacks.\n. if by \"near empty\" you mean \"completely empty\". We need to compile the fortran code for the JVM before we can even think about adding it to netlib-java.\n. Hi, sorry I only answer support questions about netlib-java under a commercial contract. This is not a bug.\n. you could try increasing the logging levels, that's about all I can help you with. This is clearly a devops issue.\n. This is a concern of your system implementation.\n. Hi, sorry I only answer support questions about netlib-java under a commercial contract. This is not a bug.\n. not without significant funding. This would require #76 and ideally #58\n. Hi, sorry I only answer support questions about netlib-java under a commercial contract. This is not a bug\n. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis. Please no time wasters: I'm not prepared to do any work on student rates, I am a professional developer and my day rate is in line with the London Scala contracting market in investment banking.\n. Cool thanks. I don't have the hardware to do anything with this but maybe it'll be useful for somebody.\n. ok, I'll merge, but as noted in https://github.com/fommil/netlib-java/wiki/CallForFunding it is far too much effort for me to cut a release so we'll leave this as \"do it yourself and publish on your artifactory if you need it\".\nThanks!\n. btw, I'd probably remove the native_ref builds if I was cutting another release. They are an interesting curiosity, but offer no performance gain. MKL and OpenBLAS are really needed.\n. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis.\n. @osallou that's an automated response. But to answer your question, no there is no changelog and I have no plans to provide one: the commit history is the changelog. I generally don't advise using OS bundled versions of .jar files, the preference is by far to use maven central (unless somebody comes along to recreate a locally built, from-source, maven central). If you're building just the native backends, then it is definitely not compatible.\n. do we support this in jniloader?\n. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis.\n. https://github.com/fommil/netlib-java/pull/113 added support been I'm not planning on releasing binaries.\n. no\n. This is literally documented in the README.\n. this is in bold text on the README.\n. Nope.\n. Why? And does it allow primitive critical array access?\nYou should know that I only work on this project under a commercial contract.. There would be absolutely no performance advantage without critical array pass through. Use the java impl if you have trouble, and if you need help beyond that I can only help with a contract in place.. sorry, I'm not interested in accepting this PR. I am not making any more releases for netlib-java unless a paying customer wants it, and these changes affect the build system in a way that I no longer know what to do. I'll leave the PR open incase it helps somebody.. No idea what you mean. Fortran has no concept of what you're talking about.. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis.. Thanks @tutnixzursache, I appreciate the offer. I've expected this for a long time and I have tried to warn the community.\nThe JVM implementation will always work, so nothing will break overnight for anybody. Commercial users of this library need to start supporting it properly. Perhaps this is the break that they need, I've been warning them for years.. Please read the Installation part of the documentation and copy/paste it if necessary.\nI bet you're missing <type>pom</type>.. This doesn't look like a bug in netlib-java, it looks more like a support request for your machine.\nUnfortunately I simply don't have the time to help out with these sorts of requests without a commercial contract in place. Most of the information that you need to solve this problem is available in the README and a seasoned GNU/Linux admin would be able to solve it for you. I'm not interested in making any more binary builds available for custom distributions.\nIf you'd be interested in getting your organisation to sponsor me to work on the netlib-java roadmap, to add support for additional native libraries or hardware (e.g. graphics cards and FPGAs) that is something I'd be interested in on a commercial basis.. it is the truth. 1.1.1 was a bad (binary dep) release. I really don't agree that you should be distributing these jars this way, it runs contrary to the way the entire JVM ecosystem works. If you have customers paying you for this service, I would appreciate some of the profits.. I understand you, and I'm telling you that the tags are correct: the jars were both created from the same commit but with different build environments. Fork this repo and use whatever tags you want, wherever you want them. I'm not interested in rewriting history to pander to an arbitrary build tool.. nope. This is a terrible idea. You can't just do printing stacktraces on people. The current code uses the logging system so that users can choose to ignore it... you're intentionally filling their stderr with noise and most people don't care.. I don't understand the point of these <relativePath> entries. I didn't need it when I built it... are you sure you read the documentation in the parent pom.xml?. this is not how the release workflow works. It needs to be performed over multiple OS, which is why making a release is so time consuming.. (it's also documented in great detail in the root pom.xml). everything else is ok, but not this.. oh, I see... yes your version is better. Thanks!. ",
    "kdub0": "As far as I can tell, the f2j implementation look fine.  You are missing the JNI portion still.\n. ",
    "dlwh": "I have easy access to Ubuntu x64 and OS X 10.8. I have an out of date Win7\nx64 install as well.\nThanks!\n-- David\nOn Mon, Aug 5, 2013 at 1:41 AM, Sam Halliday notifications@github.comwrote:\n\n@dlwh https://github.com/dlwh what is your primary dev environment? I'd\nlike you to try out my SNAPSHOT release when I have it building for your\nplatform if that's ok (I have reference native BLAS/LAPACK working on OS X\nso far).\nAfter that I'll finalise the builds of the reference natives for all major\nplatforms and start work on some \"optimised\" native backends (e.g. ATLAS or\nIntel builds... which will require some help from you).\nOnce that's done, I'll probably push a major release and then work on the\noffsets as a minor update.\n(we've actually been chatting on the thread for the offset RFE, I'm moving\nthis here just to separate the issues).\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/fommil/netlib-java/issues/15#issuecomment-22093386\n.\n. great thanks!\n\nOn Wed, Sep 4, 2013 at 2:10 PM, Sam Halliday notifications@github.comwrote:\n\n@dlwh https://github.com/dlwh snapshots are now available with veclib\nsupport in OS X (Linux to come soon, I'm not sure about Windows... will\nhave to investigate further) as discussed in scalanlp/breeze#85https://github.com/scalanlp/breeze/issues/85\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/fommil/netlib-java/issues/27#issuecomment-23824263\n.\n. (Bug not present in 1.0)\n. Hrm, does QR have a nonidentifiability in sign?\n\nThanks!\n. (obviously this is low priority and you have probably less bandwidth than I do, but I am somewhat interested in support for NIO Buffers. It's come up a few times in issues and questions for Breeze.)\n. hey, this is still super early, but you might be interested in Gust:\ngithub.com/dlwh/gust\nIt's still very immature, but I think it's a reasonably nice API, if I may\nsay so myself. It's modeled on Breeze (github.com/scalanlp/breeze)\n-- David\nOn Wed, Jun 11, 2014 at 7:05 PM, sproblvem notifications@github.com wrote:\n\nThank you, I will find other way to leverage CudaBLAS in Scala.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/fommil/netlib-java/issues/64#issuecomment-45822512.\n. \n",
    "kkofler": "FYI, I was able to build linux_32 by just copying the native_ref/linux_64 directory to native_ref/linux_32, changing the artifactId in native_ref/linux_32/pom.xml to netlib-native_ref-linux_32 and building the whole thing on my 32-bit machine. (I also removed the 3 pom.xml lines which enable the dragonegg plugin, it built fine with plain GCC.) I haven't tried actually using this yet though.\n. Building 32-bit on 64-bit (for the same architecture, e.g. i386 on x86_64) can be as simple as adding -m32 to the compiler and linker flags (which will have no effect when used on a 32-bit machine, so you can add it unconditionally to the 32-bit pom.xml).\nIn some cases, more elaborate tricks are needed to trick build systems into finding the correct version of the libraries, such as using setarch or building in a 32-bit chroot. Or of course a cross-compiler such as the cross-MinGW ones can be used. But -m32 should already be sufficient for you.\nARM is a different story, you need to use an actual cross-compiler there.\n. I'm on GNU/Linux, Fedora to be precise. But the next task once I have this working is to get it running on my colleague's Window$ machine, so official support for that (which hadn't been there previously) would be very appreciated, too.\n. Passing the full path is a poor workaround. (One of the reasons it sucks is that it hardcodes the soversion 3.) You're missing the unversioned libgfortran.so symlink. On Ubuntu, you need to install the lib32gfortran-4.7-dev package, which installs a /usr/lib/gcc/x86_64-linux-gnu/4.7/32/libgfortran.so \u2192 /usr/lib32/libgfortran.so.3 symlink. (That package also depends on lib32gfortran3, so you need to list only lib32gfortran-4.7-dev in your instructions.) Then -m32 -lgfortran should just work. (-L/usr/lib32 should not be needed.)\n(Note: The package name lib32gfortran-4.7-dev is for Ubuntu 13.04 (Raring Ringtail) and newer. In Ubuntu 12.10 (Quantal Quetzal), the package is named gfortran-4.7-multilib instead. But otherwise, the instructions are the same.)\nMore detailed explanation: lib32gfortran3 is only the runtime package. On GNU/Linux, there are 2 packages for a library: a runtime package, which contains only the versioned library, and a development package, which contains the unversioned symlink. To run something compiled against the library, only the runtime package is needed, but to compile something against the library, you need the development package (and also the runtime package, but normally, the development package depends on the runtime package).\n. And another reason why hardcoding /usr/lib32/libgfortran.so.3 is a very bad idea is that it is distro-specific and even host-platform-specific: It works on your 64-bit Ubuntu, but it will not work on:\n- 32-bit Ubuntu, which installs the library to: /usr/lib/libgfortran.so.3\n- Fedora, which also installs the 32-bit library to: /usr/lib/libgfortran.so.3 (The 64-bit version on 64-bit Fedora goes to /usr/lib64/libgfortran.so.3; this setup called \"multilib\" allows using 32-bit RPMs unmodified on 64-bit Fedora.)\n- future versions of Ubuntu, which will install the 32-bit library to: /usr/lib/i386-linux-gnu/libgfortran.so.3. (The 64-bit version will go to: /usr/lib/x86_64-linux-gnu/libgfortran.so.3. This setup is called \"multiarch\", and similarly to Fedora's \"multilib\", allows using 32-bit debs unmodified on 64-bit Debian/Ubuntu. Many packages in Ubuntu have already been converted.)\n- and of course, any setups with admin- or user-installed libgfortran outside of /usr.\nSo it is very unwise to hardcode absolute paths for libraries on GNU/Linux.\n. OK, filed issue #39.\n. Oops, sorry for the misunderstanding, I'm really not used to the GitHub world, \"PR\" has always meant \"problem report\", i.e. \"bug report\", to me.\nWhat you have now looks right to me, I'm running the build and test now.\n. Oops, the XML tags got butchered here. So I was saying:\nWell, the hardcoded;\n<jdkIncludePath>/opt/linux-i686/jdk7/include</jdkIncludePath>\nis also unhelpful, I commented that out. (I'm building on a 32-bit machine, so the default path just works. And I use the Fedora-packaged OpenJDK, so it's not in /opt.) I also commented out all the other platforms in native_ref/pom.xml and native_ref/xbuilds/pom.xml and added\n<module>xbuilds</module>\nto native_ref/pom.xml. I see why you set up things the way you did (it is what you use for your builds), but I think there really needs to be a better solution so that building the native native ;-) on users' computers just works. (Also note that building linux-x86_64 on linux-x86_64 is technically not a cross-build.)\nIt builds fine now, but I cannot run the test you asked me to run:\n[ERROR] Failed to execute goal on project perf: Could not resolve dependencies for project com.github.fommil.netlib:perf:jar:1.0-SNAPSHOT: Failure to find com.github.fommil.netlib:all:pom:1.0-20130826.181411-12 in https://oss.sonatype.org/content/repositories/snapshots/ was cached in the local repository, resolution will not be reattempted until the update interval of sonatype-snapshots has elapsed or updates are forced -> [Help 1]\nSomehow this wants to test (nonexistent) stuff from your repository rather than the stuff I just built.\n. FYI, as far as I can tell, at least MUMPS and TAUCS are already Open Source.\n. http://graal.ens-lyon.fr/MUMPS/\nThe download page states that it is in the public domain.\n. Is there any update on this stuff (interfacing e.g. MUMPS)? We could really use a Java interface for a sparse linear solver here at the University of Vienna now.\n. Uhm, mvn compile assembly:single in perf drags in a lot of unwanted dependencies (which are used in the benchmarking process). I created this netlib-java/pom.xml:\n``` xml\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n\n4.0.0\n<!-- mvn compile assembly:single -->\n\n<parent>\n    <groupId>com.github.fommil.netlib</groupId>\n    <artifactId>parent</artifactId>\n    <version>1.1-SNAPSHOT</version>\n</parent>\n\n<artifactId>netlib-java</artifactId>\n<packaging>jar</packaging>\n\n<dependencies>\n    <dependency>\n        <groupId>${project.parent.groupId}</groupId>\n        <version>${project.parent.version}</version>\n        <artifactId>all</artifactId>\n        <type>pom</type>\n    </dependency>\n</dependencies>\n\n<build>\n    <plugins>\n        <plugin>\n            <artifactId>maven-assembly-plugin</artifactId>\n            <configuration>\n                <archive>\n                    <manifest>\n                        <mainClass>${exec.mainClass}</mainClass>\n                    </manifest>\n                </archive>\n                <descriptorRefs>\n                    <descriptorRef>jar-with-dependencies</descriptorRef>\n                </descriptorRefs>\n            </configuration>\n        </plugin>\n    </plugins>\n</build>\n\n\n```\nwhich seems to do more or less what I want (but yikes, those natives are huge! :-( ). Wouldn't that be easily scripted into your build process? Or are you doing everything by hand?\nBut a remaining issue is that I'd really like to also get it to include the legacy directory, and somehow I can't get that to work. Adding the dependency:\nxml\n        <dependency>  <!-- legacy API backwards compatibility-->\n            <groupId>com.googlecode.netlib-java</groupId>\n            <version>${project.parent.version}</version>\n            <artifactId>netlib-java</artifactId>\n            <type>pom</type>\n        </dependency>\nthe obvious way does nothing (and I tried changing my artifactId to something different from \"netlib-java\", that didn't help either).\nAs for:\n\nbundling \"system optimized\" natives is against the whole point of that backend. It is the responsibility of the\nend user / provisioning to ensure that they are available at runtime. I'm not going to be distributing one\nvendor's generic implementation: that's what the native ref is for.\n\nFYI, OpenBLAS's \"generic\" builds are not unoptimized builds like the reference ones, they do runtime CPU detection and automatically select the optimized assembly kernels for the CPU detected at runtime. There are also no licensing issues with distributing them. (It's BSD-licensed.) That said, I now agree that -system is not the right backend for that. What would you think of a native-openblas backend (which would also look for the libopenblas they ship rather than for libblas and liblapack, or maybe link it statically like native-ref does)? I think many developers would be happy with shipping that (and only that, omitting native-ref which would be slower and native-system which is too complicated to set up for most end users), if it were available.\n. > but if you ever want this for Windows too then you're going to have to create a .def file containing an explicit\n\nlist of all the Java_ symbols.\n\nThe symbols are already restricted there. (Just check your DLLs in any export viewer. Do not trust mingw32-nm: That one shows debugging symbols, not exported symbols!) The DLL system defaults to exporting only the symbols explicitly marked dllexport in the code, which is exactly what you want here.\nI also do not understand the changes you made to stripping. They may make sense on OS X (not sure), but on GNU/Linux, stripping is entirely unrelated to symbol exporting, it does not touch the dynamic symbol table (the table of exported symbols).You should just use -s on GNU/Linux. GNU ld will not strip the dynamic symbol table with -s. Your -Wl,-xS produces a larger shared object, because it keeps a second copy of the exported symbols in the debugging symbol table. That makes no sense, because GDB can process the dynamic symbol table just fine. Use nm -D to view the dynamic symbol table, the one that matters for symbol exports. As I said in the previous paragraph, Windows/MinGW also has 2 symbol tables, and there too, you should use -s when linking to strip the debugging symbols. However, unfortunately, the MinGW nm does not support -D. (It does not show anything, but the DLL is actually exporting symbols.) So you cannot trust the MinGW nm for that either.\n. PS: MinGW does provide a working tool to view the export table of a DLL (the equivalent of the dynamic symbol table of the GNU/Linux ELF format), it's called pexports:\nhttp://www.mirrorservice.org/sites/downloads.sourceforge.net/m/mi/mingw/MinGW/Extension/pexports/\nUnfortunately, that tool is not part of the standard MinGW or cross-MinGW distributions.\n. > I've uploaded the corrected binaries for all systems. Please try them and let me know if they work for you.\nWe tried them at the university today (the snapshot that was current when you posted that comment), and we can confirm that they work fine. In particular, the native_ref .so no longer crashes MATLAB.\n(For what it's worth, the native_system library still triggers the same fatal symbol conflict, but we cannot fix that case in the same way, because the system BLAS/LAPACK libraries obviously have to export the symbols or they wouldn't work at all. It is really MATLAB's fault, I cannot think of any sane way to work around that right now. But at least native_ref works now.)\n\nif I do -s when stripping, then nm -a claims there are no symbols at all\n\nnm -a does not show the dynamic symbol table / export table, you really have to use nm -D for GNU/Linux or pexports for MinGW. OS X is actually the odd one out in this context, because (as I understand it) it uses only one symbol table where the other operating systems use 2 separate ones.\n. > Re: Windows, see here http://sourceforge.net/p/mingw/bugs/1134/ specifically\n\n[snip]\nso a .DEF file is required. I have no plans to build or ship such files.\n\nA .DEF file is required if you want anything other than the default behavior. But on Windows, exporting only the Java_* functions is already the default behavior, so you don't actually have to do anything. (Try running pexports or something equivalent on the DLL if you don't believe me. I checked the export table in a hex viewer.)\nMore precisely, MinGW (like Visual C++, whose behavior it emulates in this context) only exports functions marked as __declspec(dllexport) (or the GCC syntax __attribute__((dllexport))). This is exactly what the JNIEXPORT macro in include/win32/jni_md.h expands to. Any function not marked dllexport is not exported from the DLL. This is unlike the behavior on other platforms, where symbols are exported by default.\nSee:\n- http://msdn.microsoft.com/en-us/library/vstudio/3y1sfaz2.aspx\n- http://gcc.gnu.org/onlinedocs/gcc-4.8.1/gcc/Function-Attributes.html#index-g_t_0040code_007b_005f_005fdeclspec_0028dllexport_0029_007d-2597\nSo you can safely remove that TODO comment. Your code is already doing the right thing on Windows.\n. ",
    "almson": "Using GetPrimitiveArrayCritical can cause showdowns and stalls in multi-threaded code: mail.openjdk.java.net/pipermail/hotspot-runtime-dev/2007-December/000074.html\nI suppose it isn't a big deal, but ByteBuffers are often preferred when working with native code.\nJCublas is a wrapper of the C api. I manage memory myself. ByteBuffers are used to expose native memory regions,  including those that have special properties to the CUDA runtime (such as those that are pinned in physical memory and are much faster to copy to/from the GPU). JCublas also can take plain arrays (this is all managed through the neat Pointer class that the C functions take).\nI think overloads that take FloatBuffer would be a simple addition.\n. You're probably right that the demand for this isn't big enough to bother. I've put in copies, and they're not a problem.\nNVIDIA (ie CUDA) probably will never overcome the PCIe bandwidth bottleneck. But AMD and Intel might. Their integrated GPUs, though not the famed teraflop beasts, connect to system memory and should work better for this kind of \"drop-in\" GPGPU. (Hence AMD referring to their chips as \"APUs\") \nTo make PCIe transfer faster, CUDA optionally uses pinned and/or write-combined memory. These let the DMA engines do their work without worrying about virtual memory and cpu caches,  respectively. I don't believe it helps much for small transfers, though.\nI'm surprised you haven't had much exposure to GPUs. If one wants to do fast linear algebra, a GPU is the only way to go. Using them from Java is also very pleasant.\n. Any compacting GC (CMS isn't compacting, which is why i use G1), can't run while JNI code has entered a critical section in order to access JVM memory. That's why the function has \"critical\" in its name and why it is advised to be used only for short operations. But I agree that when BLAS is keeping all CPUs busy, this doesn't usually matter (although if I/O code stops, it might). \n. The CUDA function is simply cudaHostAlloc. See:\nhttp://developer.download.nvidia.com/compute/cuda/4_1/rel/toolkit/docs/online/group__CUDART__MEMORY_g15a3871f15f8c38f5b7190946845758c.html\nGetPrimitiveArrayCritical seems to cause hangs when using G1 GC and Java 8.\nIn JCuda it is a complete deadlock, while with Netlib it's a temporary one\nwhere all threads but one stop working. Concurrent Mark Sweep GC doesn't\nhave this problem on Java 8. I'll open up an issue as soon as I figure out\nhow to use Visual Studio to get the stack trace in the JDK.\nOn Tue, Jan 14, 2014 at 11:45 AM, Sam Halliday notifications@github.comwrote:\n\nReopened #58 https://github.com/fommil/netlib-java/issues/58.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/fommil/netlib-java/issues/58\n.\n. @bkgood It's exciting to hear that you were about to get the JVM to vectorize your methods. I've been following the autovectorization developments, but in my experience only loops that index the array starting from 0 get vectorized. Were you able to get it working with non-0 offsets? Or is your dgemv limited in that sense?\n. That's too bad. Relying on a native library is fine, but it would be very nice if a pure-Java implementation could get even 75% of native performance. Java in general is sorely in need of vectorization. It's a bit of a mystery to me why they are moving so slowly towards it and saying so little. I'll let you know if I get a hold of anyone who might be worthwhile.\n. Which talk? I'm not sure what you are trying to say. I understand what's involved in writing an optimized matrix multiplication.\n. \n",
    "bkgood": "I've got a fork over at https://github.com/bkgood/netlib-java that dirtily adds NIO buffer support. Would you be interested in merging it in if I polished it up?\nIt's got some extraneous stuff I want to remove, the F2J implementation fails on direct buffers and the JNI implementations fail on array-backed buffers. It currently fulfills my needs (multithreading done in the BLAS implementation wasn't cutting it so I'm doing in myself in-JVM; long story) but I'd love to get a cleaned up version in in a proper release if you'd be interested in such a version.\nOn fixing the latter two issues I brought up- I agree that letting the F2J implementation handle non-array-backed buffers will slow it down considerably, but given the incredibly poor performance this implementation currently exhibits, I'm not sure I see the extra copying work leading to much of a regression. If performance is a goal of the Java implementation, F2J seems to really miss the mark - I, at one point, reimplemented dgemv in Java in such a way that I had it running in the same order of magnitude as the OpenBLAS implementation because I was able to write Java in such a way that Hotspot was able to vectorize it. F2J's bytecode doesn't seem to be written (well, generated) in such a way. I am concerned about the necessary allocations, though. Any ideas here? Like I mentioned earlier, I currently just throw an exception which might be better than implicitly allocating a potentially huge array.\nTo fix the final issue (JNI implementation fails on array-backed buffers), it seems to make sense to just get the backing array from the buffer and call GetPrimitiveArrayCritical on it. To my knowledge there isn't a sort of nio buffer that has neither a 'peer' nor a backing array but this can also be guarded against. \nFWIW there are a couple of nice uses I see for supporting NIO buffers here but I've been unable to see gains in TTSP (time to safepoint, which ideally avoiding the pinning of GetPrimitiveArrayCritical would reduce, but I've yet to see evidence of any gains). The biggest gain has been in memory locality as all the hardware backing my current project is commodity multi-socked x64 boxes under NUMA constraints, achieved with the help of some topology-aware allocation routines.\n. > From skimming your branch, it does look a bit hacky for me to be able to merge into the main code branch\nAgreed, that's why I wanted to ask for your thoughts before doing a big code drop-style pull request ;)\n\nthis would effectively create two extra API variants for everything that we currently have?\n\nI was planning to delete the POINTER_AS_LONG variant as part of my cleanup (performance improvement over NIO_BUFFER was appreciable but not what I'd consider significant), so it would only be the  NIO_BUFFER variant plus the original array-based one.\n\nIf this work is going to be done, I'd like it to be done from the ground up and for F2J to support the same API. That approach would involve going the #76 direction. Realistically, I'd be looking for funding for a 6 month period to do this.\n\nUnfortunately my patches came from an immediate need and since they fulfill my needs (the F2J implementation is very much useless in my project, although I see its utility elsewhere) I can't really sell 6 months' funding and time.\nOne could presumably modify the F2J class files such that we duplicate all the methods (and associated bytecode), splice out the relevant Xaload instructions and splice in calls to XBuffer.get and replace the relevant bits of the method signatures. I'm less than excited about such a proposition for perhaps obvious reasons :) but I agree that fully supporting F2J is necessary for the goals of netlib-java. This would entail significantly less work IMO than a new Fortran-to-Java transpiler (and I would be willing to give it a go), although has a hacky nature of its own.\nIf you're interested in a patch that solves the issue in a way similar to what I've got now, I'd very much like to work to get something mergeable :) I'm more than willing to do the work to get it there.\nedit: blah, POINTER_TO_LONG should have been POINTER_AS_LONG\n. A second API as in a second interface and set of implementations? Or additional methods to the existing class, along with support for copying in from DirectBuffers? (IOW an extension of what I'm doing now) My memory is a bit fuzzy but I imagine I could get this to generate a separate set of classes.\nFWIW I've been developing on OSX and have my SNAPSHOT releases building there so I could lend a hand as needed. I imagine you'd want to do the building since you're signing but I can at least share my experiences (homebrew in particular made it fairly easy to get the fortran compiler I needed, and then it was just a matter of fixing a few paths and commenting out the non-osx stuff from the various pom.xmls).\n. Sorry, your reply got buried in a gmail thread somehow :/\nLooking at the classes generated by my fork, it seems we're quite far away from classfile limits on methods/class (https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-4.html#jvms-4.11 says ~65k)\n17:25 $ grep 'public native' native_system/java/target/netlib-native/com/github/fommil/netlib/NativeSystemARPACK.java |wc -l\n      48\n17:28 $ grep 'public native' native_system/java/target/netlib-native/com/github/fommil/netlib/NativeSystemLAPACK.java |wc -l\n    2352\n17:29 $ grep 'public native' native_system/java/target/netlib-native/com/github/fommil/netlib/NativeSystemBLAS.java |wc -l\n     404\nIt seems ok from a classfile perspective (and these numbers actually include the methods taking a pointer in a long which I don't want to merge, so they're actually higher than they ought to be).\n. ",
    "eiennohito": "JNI stubs can be similar to what lz4-java does for array/BB support (https://github.com/jpountz/lz4-java/blob/master/src/jni/net_jpountz_lz4_LZ4JNI.c#L94)\n. ",
    "MartinSenne": "Hi Sam,\nI was using 1.1.1 netlib-java ....... and yes, it was \"crashing\" the app.\nAs the problem does not occur with 1.1.2 anymore (thx!) I'll close this issue.\nThx and cheers,\nMartin\n. ",
    "jmelot": "Thanks for your response, but I am still having issues.\nI have set my $LD_LIBRARY_PATH to point to a directory that contains liblapack.so.3 and libblas.so.3 (I am on a shared machine, so I can't edit /etc/ld.so.conf). When I print java.library.path, I can see that the directory containing those \".so\"s is being read. But I get these warnings:\nJan 31, 2014 1:42:12 PM com.github.fommil.netlib.BLAS \nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\nJan 31, 2014 1:42:12 PM com.github.fommil.jni.JniLoader liberalLoad\nINFO: successfully loaded /tmp/jniloader6100528718704752377netlib-native_ref-linux-x86_64.so\n. ",
    "swadey": "I had the same issue and following @fommil's advice, it did require recompile of the JNI bindings to work. \n@fommil your default 1.1 jars with netlib-native_ref-linux-x86_64.so and netlib-native_system-linux-x86_64.so don't work on Ubuntu 12.04.4 LTS.  Here are the kernel details:\nLinux nike1 3.8.0-35-generic #50~precise1-Ubuntu SMP Wed Dec 4 17:25:51 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux\nI've had similar binary compatibility issues in the past and the only distro I have found that allows successful cross-platform binary action on x6_64 is Centos 5 (I compiled a working version with 5.8).\n. Could very well be. If you'd like the compiled .so. Let me know.  I can put it somewhere. \nJust as another note the reference fortran version also didn't work which supports your gfortran libs hypothesis.\n. ",
    "muuki88": "I have a similar issue on Ubuntu 14.04\npr 20, 2014 2:21:53 PM com.github.fommil.netlib.BLAS <clinit>\nWARNUNG: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\nApr 20, 2014 2:21:53 PM com.github.fommil.netlib.BLAS <clinit>\nWARNUNG: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\nOutput of sudo ldconfig -p | grep blas\nbash\n    libopenblas.so.0 (libc6,x86-64) => /usr/lib/libopenblas.so.0\n    libf77blas.so.3 (libc6,x86-64) => /usr/lib/libf77blas.so.3\n    libcblas.so.3 (libc6,x86-64) => /usr/lib/libcblas.so.3\n    libblas.so.3 (libc6,x86-64) => /usr/lib/libblas.so.3\n    libblas.so (libc6,x86-64) => /usr/lib/libblas.so\nOutput of sudo ldconfig -p | grep atlas\nbash\n    liblapack_atlas.so.3 (libc6,x86-64) => /usr/lib/liblapack_atlas.so.3\n    libatlas.so.3 (libc6,x86-64) => /usr/lib/libatlas.so.3\nI didn't try to compile everything myself as I thought the packages in the repo are good enough :/\nOutput of sudo update-alternatives --config libblas.so.3\n``` bash\n  Selection      Path                                    Priority State\n\n\n0            /usr/lib/openblas-base/libblas.so.3      40        Auto-Mode\n  1            /usr/lib/atlas-base/atlas/libblas.so.3   35        manuel mode\n  2            /usr/lib/libblas/libblas.so.3            10        manuel mode\n  3            /usr/lib/openblas-base/libblas.so.3      40        manuel mode\n```\n. \n",
    "nrigheriu": "I get this and other similar errors in Intellij when trying to run weka.classifiers.functions.LinearRegression. I'm running Ubuntu 16.04 and have libfortran3 installed (5.4.0-6ubuntu1~16.04.4). What could be causing this problem?\n\ncom.github.fommil.netlib.BLAS \nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS \ncom.github.fommil.netlib.LAPACK \nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n. \n",
    "dlampart": "What resolved the issue in the end was to do a fresh installation of gcc and pull in the libgfortran.so.3 from there. I don't  know exactly why the old libgfortran.so.3 didn't work though.\nThanks for all the good work.\nDavid\n. ",
    "yangliuyu": "either upgrade your libgfortran with gcc above 4.6 or build your own netlib-native_system-xxx.so with the existing libgfortran.so.3\nhttp://stackoverflow.com/questions/23041840/scilinux-libgfortran-so-3-version-gfortran-1-4-not-found\n. add /opt/intel/mkl/lib/intel64 in your /etc/ld.so.conf then sudo ldconfig and try again\n. @hmolina hope this will help http://apache-spark-user-list.1001560.n3.nabble.com/Native-library-can-not-be-loaded-when-using-Mllib-PCA-tp7042p10566.html\n. just FYI, package all netlib-java jars and so files(package as jar) into spark-assembly is a workaround\n. Thanks @fommil , \nldd /tmp/jniloader9104995036364593011netlib-native_system-linux-x86_64.so\nldd: warning: you do not have execution permission for `/tmp/jniloader9104995036364593011netlib-native_system-linux-x86_64.so'\n    linux-vdso.so.1 =>  (0x00007fffaf9fe000)\n    libgfortran.so.3 => /lib64/libgfortran.so.3 (0x00007fc871320000)\n    libblas.so.3 => /lib64/libblas.so.3 (0x00007fc8710c7000)\n    liblapack.so.3 => /lib64/liblapack.so.3 (0x00007fc87085c000)\n    libc.so.6 => /lib64/libc.so.6 (0x00007fc87049b000)\n    libquadmath.so.0 => /lib64/libquadmath.so.0 (0x00007fc87025f000)\n    libm.so.6 => /lib64/libm.so.6 (0x00007fc86ff5c000)\n    libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007fc86fd46000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fc8719d3000)\nNo missing so files hint here...\nThe atlas-3.10.1-7.el7.x86_64 (CentOS 7) do not contain libcblas.so.3 which atlas-3.8.4-2.el6.x86_64 (CentOS 6.5) does. After install old version of atlas and arpack, the problem fixed.\nAnd now ldd result is:\nldd /tmp/jniloader9104995036364593011netlib-native_system-linux-x86_64.so\nldd: warning: you do not have execution permission for `/tmp/jniloader9104995036364593011netlib-native_system-linux-x86_64.so'\n    linux-vdso.so.1 =>  (0x00007fffef36d000)\n    libgfortran.so.3 => /lib64/libgfortran.so.3 (0x00007fa068595000)\n    libblas.so.3 => /lib64/libblas.so.3 (0x00007fa06833c000)\n    liblapack.so.3 => /usr/lib64/atlas/liblapack.so.3 (0x00007fa067b1a000)\n    libc.so.6 => /lib64/libc.so.6 (0x00007fa067759000)\n    libquadmath.so.0 => /lib64/libquadmath.so.0 (0x00007fa06751d000)\n    libm.so.6 => /lib64/libm.so.6 (0x00007fa06721a000)\n    libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007fa067004000)\n    libf77blas.so.3 => /usr/lib64/atlas/libf77blas.so.3 (0x00007fa066de5000)\n    libcblas.so.3 => /usr/lib64/atlas/libcblas.so.3 (0x00007fa066bc4000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fa068c48000)\n    libatlas.so.3 => /usr/lib64/atlas/libatlas.so.3 (0x00007fa066568000)\n    libpthread.so.0 => /lib64/libpthread.so.0 (0x00007fa06634c000)\n. ",
    "sproblvem": "Thank you for your quickly reply!\nAfter redefine the log level, I got this\nFINE: skipping load of /tmp/jniloader6369873912425631753netlib-native_system-linux-x86_64.so [com.github.fommil.jni.JniLoader] /tmp/jniloader6369873912425631753netlib-native_system-linux-x86_64.so: /usr/lib64/libgfortran.so.3: version `GFORTRAN_1.4' not found (required by /tmp/jniloader6369873912425631753netlib-native_system-linux-x86_64.so) java.lang.UnsatisfiedLinkError\n...\nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK [com.github.fommil.netlib.LAPACK]\nIt seems that the problem is my gfortran. And my gfortran version is \n```\n$ gfortran --version\nGNU Fortran (GCC) 4.4.7 20120313 (Red Hat 4.4.7-4)\nCopyright (C) 2010 Free Software Foundation, Inc.\nGNU Fortran comes with NO WARRANTY, to the extent permitted by law.\nYou may redistribute copies of GNU Fortran\nunder the terms of the GNU General Public License.\nFor more information about these matters, see the file named COPYING\n```\nI try to downgrade gfortran on my CentOS 6.4, but failed. I didn't find yum repo which contain libgfortran3. And I think reinstall GCC from source code is really aweful.\nSo, what's your suggestion? Maybe reinstall my computer with Ubuntu 14.4?\n. Thank you, I will find other way to leverage CudaBLAS in Scala.\n. @dlwh thank you for your tips, I will have a try!\n. ",
    "ravi9": "Hi,\nI have the same issue when trying to use Spark with MKL. \nHow can I change org.netlib logging towards FINEST ?\nThank you.\n. Thank you fommil.\n@cre8ivejp Try the following:\nIn this example, I build the jar \"spark-testexample.jar\" with maven dependency\n<dependency>\n    <groupId>com.github.fommil.netlib</groupId>\n    <artifactId>all</artifactId>\n    <version>1.1.2</version>\n    <type>pom</type>\n</dependency>\n1. try specifying --driver-class-path /path/to/ur/jar in your spark-submit argument.\n   Example: spark-submit --class test.Example --master local[*] --driver-class-path /target/spark-testexample.jar --driver-memory 10g --executor-memory 10g /target/spark-testexample.jar\n2. If that doest work, try the following:\n   In \"spark-testexample.jar\", you must have several .so files. If your system is linux, then extract \"netlib-native_system-linux-x86_64.so\" as follows:\n$sudo jar xf spark-testexample.jar netlib-native_system-linux-x86_64.so\nOnce you have extracted the netlib-native_system-linux-x86_64.so from the jar, do the following:\n$ ldd netlib-native_system-linux-x86_64.so\nThis should print something similar to the following:\n$ ldd netlib-native_system-linux-x86_64.so\nldd: warning: you do not have execution permission for `./netlib-native_system-linux-x86_64.so'\n        linux-vdso.so.1 =>  (0x00007fff243b6000)\n        libgfortran.so.3 => /usr/lib64/libgfortran.so.3 (0x00007f8b88615000)\n        libblas.so.3 => /usr/lib64/atlas/libblas.so.3 (0x00007f8b880a5000)\n        liblapack.so.3 => /usr/lib64/atlas/liblapack.so.3 (0x00007f8b87883000)\n        libc.so.6 => /lib64/libc.so.6 (0x00007f8b874ef000)\n        libquadmath.so.0 => /usr/local/lib/../lib64/libquadmath.so.0 (0x00007f8b872b4000)\n        libm.so.6 => /lib64/libm.so.6 (0x00007f8b8702f000)\n        libgcc_s.so.1 => /usr/local/lib/../lib64/libgcc_s.so.1 (0x00007f8b86e19000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x00007f8b86c15000)\n        libf77blas.so.3 => /usr/lib64/atlas/libf77blas.so.3 (0x00007f8b869f5000)\n        libcblas.so.3 => /usr/lib64/atlas/libcblas.so.3 (0x00007f8b867d5000)\n        /lib64/ld-linux-x86-64.so.2 (0x00000034b6400000)\n        libatlas.so.3 => /usr/lib64/atlas/libatlas.so.3 (0x00007f8b86179000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f8b85f5b000)\nIf this is a problem with GFORTRAN, it will print a warning message like the following--  version `GFORTRAN_1.4' not found:\n$ ldd netlib-native_system-linux-x86_64.so\nldd: warning: you do not have execution permission for `./netlib-native_system-linux-x86_64.so'\n./netlib-native_system-linux-x86_64.so: /usr/lib64/libgfortran.so.3: version `GFORTRAN_1.4' not found (required by ./netlib-native_system-linux-x86_64.so)\n        linux-vdso.so.1 =>  (0x00007fff1a9ff000)\n        libgfortran.so.3 => /usr/lib64/libgfortran.so.3 (0x00007f119ed5a000)\n        libblas.so.3 => /usr/lib64/atlas/libblas.so.3 (0x00007f119e7ea000)\n        liblapack.so.3 => /usr/lib64/atlas/liblapack.so.3 (0x00007f119dfc8000)\n        libc.so.6 => /lib64/libc.so.6 (0x00007f119dc34000)\n        libm.so.6 => /lib64/libm.so.6 (0x00007f119d9b0000)\n        libdl.so.2 => /lib64/libdl.so.2 (0x00007f119d7ab000)\n        libf77blas.so.3 => /usr/lib64/atlas/libf77blas.so.3 (0x00007f119d58c000)\n        libcblas.so.3 => /usr/lib64/atlas/libcblas.so.3 (0x00007f119d36c000)\n        /lib64/ld-linux-x86-64.so.2 (0x00000034b6400000)\n        libatlas.so.3 => /usr/lib64/atlas/libatlas.so.3 (0x00007f119cd0f000)\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f119caf2000)\nIf GFORTRAN is the issue, then update gcc to atleast 4.8, which includes gfortran v4.8\nIf you already have gfortran >4.8, then point  libgfortran.so.3  to the correct .so\n1.  (@fommil correct me if I'm wrong in the following testing style.)\n   To test what has been loaded, in your program do the following:\nimport com.github.fommil.netlib.BLAS;\nSystem.out.println(BLAS.getInstance().getClass().getName());\nIf it is correctly loaded, then it should print:\ncom.github.fommil.netlib.NativeSystemBLAS\nif it does not load, then it will print:\n15/07/09 09:56:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n15/07/09 09:56:04 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\ncom.github.fommil.netlib.F2jBLAS\n. ",
    "cre8ivejp": "Same issue here\n15/07/10 04:09:53 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n15/07/10 04:09:53 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n. ",
    "debasish83": "I am also having the same issue on CentOS 6.5 GCC 4.4.7\nldd: warning: you do not have execution permission for ./netlib-native_system-linux-x86_64.so'\n./netlib-native_system-linux-x86_64.so: /usr/lib64/libgfortran.so.3: versionGFORTRAN_1.4' not found (required by ./netlib-native_system-linux-x86_64.so)\nI installed GCC 4.8.2 through devtools and linked the libgfortran.so.3 to libgfortran.so and then I am getting the following errors:\n./netlib-native_system-linux-x86_64.so: error while loading shared libraries: /usr/lib64/libgfortran.so.3: invalid ELF header\nShould I install GCC 4.8 directly from the source and not use the devtools ?\n. This issue is resolved...I have regenerated netlib-java for CentOS 6.5 with gcc 4.4.7...\n. This is the library: http://faculty.cse.tamu.edu/davis/suitesparse.html We used it in ECOS...\nIt is not possible to add this in native part of netlib-java ? Since you already have a JNI flow, I would like to reuse it rather than adding another JNI flow\n. Also personally I am anyway compiling with native netlib flag for dgemm and blocked matrix operations :-)...\n. Not recompiling but compiling Spark with -Pnetlib-lgpl...Let me look into the talk...I am not using any native libs if I compile spark with -Pnetlib-lgpl and use dgemm from BLAS ? It will fall back to my system's BLAS ? \n. I got it...netlib-java is for netlib library...Could you point me to the code where you make sure within JVM and Native no array copies are done ? I think I did not optimize on that aspect and my JNI implementation was slower...But it was not bad\n. watching it :-)\n. Thanks I got what I was looking for http://fommil.github.io/scalax14/#/9/6 :-) My JNI implementation was crap and doing all sort of copies I think...no wonder it was slow !\nhttps://github.com/debasish83/ecos/blob/master/src/main/native/NativeECOS.c \n. Got it...Let me set it up for OpenBLAS...\n. I could recompile it for CentOS 6.5 with gcc 4.4. We are migrating to CentOS 7.2 but for now we will publish netlib-java internally for CentOS 6.5 and MacOSX. We will load 1.2-SNAPSHOT on Breeze and Spark. I will report on the runtime numbers. Cholesky was horrible on f2J (around 12 second on 4096 rank compare to 0.5 second on Mac). I am hoping OpenBLAS native cholesky will be at part with Mac's veclib. Thanks for the well structured repository. Native on Java/Scala is always tricky. We are using netlib-java heavily for Spark neural net but did you know if there were any benchmarks with nd4j with netlib-java ?\n. ",
    "rongqi79": "I am having a problem here:  Failed to load NativeSystemBLAS on worker node, but succeeded on master node.\nI am using Mllib on a cluster (spark standalone). I followed the instructions here to use MKL within netlib-java. What might be the reason? The symbolic links in working nodes are right.\n. ",
    "avulanov": "Hi @fommil ! I was able to link cublas 6.0 to netlib-java linux native system wrapper. The performance of matrix multiplication was similar to openBlas for arrays up to 10K elements. For bigger arrays it was worse, probably due to the issues that you refer to in previous posts. Then I was told about BIDMat. It has Intel MKL blas and cublas via jcuda, as far as I understand. According to my tests, BIDMat's matrices multiplication is ~10x faster with cublas than with mkl blas. I also linked netlib-java with mkl blas and it was few times faster than openblas. To summarize the kind of matrices multiplication performance what I got: BIDMat jcuda >> BIDMat mkl ~= netlib-java-mkl>>netlib-java openblas>netlib-java cublas>f2jblas. Just in case, my tests are not statistically sound since they were done in few runs on one particular xeon machine (2.4) with particular geforce graphic card (gtx titan). So I would like to hear you opinion. Could you be so kind to comment what should be faster, jcuda with cublas or netlib-java with openblas (or mkl blas)? \n. Could you elaborate what do you mean by implementing libblas.so and cheating? \n. I've watched your talk the day before yesterday :smile: so I was able to understand \"The Zone\" term\nHowever, I'm still confused by \"implement libblas.so\" and \"custom memory management\". Could you please explain it in more details? Which particular APU do you refer to?\n. Thanks for explanation! Indeed, it would be interesting to know if they copy the result or not. If not, I think it is still OK because they can run the whole algorithm on GPU given that it computes much faster than CPU. \nIn the meantime, I was finally able to make additional performance comparisons. It turns out that: \nBIDMat-cublas>>BIDMat MKL==netlib-mkl==netlib-openblas-compiled>netlib-openblas-yum-repo>netlib-cublas=netlib-blas>f2jblas\nJust in case, below is the link to the spreadsheet with full results. \nhttps://docs.google.com/spreadsheets/d/1lWdVSuSragOobb0A_oeouQgHUMx378T9J5r7kwKSPkY/edit?usp=sharing\n. I observed almost 5x speedup for locally compiled OpenBlas versus OpenBlas installed from Fedora repo. It performed almost as MLK. One of the reasons might be that it has optimizations for different CPU families, see https://github.com/xianyi/OpenBLAS/blob/develop/TargetList.txt. Probably during the compilation it assembled for my CPU specifically versus the generic assembly from repo. Does it makes sense to you?\nRegarding netlib-cublas, I changed the linker option in native_system/xbuilds/linux-x64_86/pom.xml from -lblas to -lcublas and added the linker path option -L/usr/local/cuda/lib64 so it was able to find the library. The same way mkl and openblas linking was done.\n. nvblas functions should replace current blas functions calls after executing LD_PRELOAD as suggested in http://docs.nvidia.com/cuda/nvblas/#Usage without any changes to netlib-java. \n. Apparently, Sonatype's Snapshot Repository does not contain netlib jars. You need to change the version of generator in pom.xml from ${project.version} to one of the versions that can be found in Maven central, e.g. 1.1.2.\nSam, this information is missing in README, and can be found only in the main pom.xml as a comment.\n. @DreamFlasher You are welcome. I can find only few reasons to build Netlib-java from scratch. One of them would be to make it compatible with the older GCC if you have e.g. RedHat 6.3. Netlib-java binaries require libgfortran.so.3 from GCC 4.8+. Though in this case I compile the new GCC instead. @fommil Correct me please, if I'm missing something\n. You are welcome! \nI was able to create a wiki page (actually the first one in the project(?)), but didn't try to save it. Should we leave the main bullets in the readme and put the rest to the wiki? The other option would be to reduce the amount of text and don't bother creating wiki.\n. Yes, it does. It works because CBLAS functions call BLAS Fortran functions. The latter are replaced with preloaded symbols in runtime. CBLAS shared library that I compiled for Fedora also contains Fortran BLAS.\nI am not sure how linking with nvblas.so will work because it has only a number of Fortran BLAS level 3 symbols, not all of the BLAS.\nbtw could you add the link from readme to nvblas wiki?\n. As far as I understood, It does not work for ATLAS (or OpenBLAS) because its C functions do not call Fortran BLAS, they call their own routines instead.\n. You are correct, ATLAS and OpenBLAS do implement Fortran and C APIs and they do have those symbols, otherwise they could not tell that they are BLAS :) However, that does not mean that their C API calls their Fortran API, what is needed for plugging nvblas.\n. ",
    "EmergentOrder": "@fommil I think you've already been introduced recently based on the spark-dev mailing lists, but you should definitely consider using NVBLAS here. It is a full, drop-in BLAS replacement, available since CUDA 6.0. See my never-merged [due to project stagnation] PR here: https://github.com/mikiobraun/jblas/pull/47 . Not entirely sure, but I think the default is it forwards only BLAS level 3, size 10,000 or higher to cuBLAS. Doc here: http://on-demand.gputechconf.com/supercomputing/2013/presentation/SC3108-New-Features-CUDA%206%20-GPU-Acceleration.pdf \nclaims : \"Optionally configure which routines and matrix sizes are accelerated\" \nalthough I don't see the size setting in the official doc here: http://docs.nvidia.com/cuda/nvblas/index.html#NVBLAS_CONFIG_FILE\n. In the context of this project it seems like the most appropriate place might be the README. \nSide note: I'm planning on checking out your talk.\n. Thanks guys. I did realize this, I just meant it might be nice to mention that this is possible in the README.\n. ",
    "hmolina": "Thanks for your fast reply. The ldd looks Ok:\nldd /usr/local/lib64/netlib-native_system-linux-x86_64.so \n    linux-vdso.so.1 (0x00007fff44bff000)\n    libgfortran.so.3 => /usr/lib/gcc/x86_64-pc-linux-gnu/4.7.3/libgfortran.so.3 (0x00007f69a94ff000)\n    libblas.so.3 => /usr/lib64/libblas.so.3 (0x00007f69a8fbb000)\n    libc.so.6 => /lib64/libc.so.6 (0x00007f69a8c0b000)\n    libquadmath.so.0 => /usr/lib/gcc/x86_64-pc-linux-gnu/4.7.3/libquadmath.so.0 (0x00007f69a89d5000)\n    libm.so.6 => /lib64/libm.so.6 (0x00007f69a86d8000)\n    libgcc_s.so.1 => /usr/lib/gcc/x86_64-pc-linux-gnu/4.7.3/libgcc_s.so.1 (0x00007f69a84c1000)\n    libdl.so.2 => /lib64/libdl.so.2 (0x00007f69a82bd000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007f69a9bcf000)\nldd /usr/lib64/libblas.so.3\n    linux-vdso.so.1 (0x00007fff37108000)\n    libdl.so.2 => /lib64/libdl.so.2 (0x00007fc5c9533000)\n    libc.so.6 => /lib64/libc.so.6 (0x00007fc5c9183000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fc5c9ca3000)\n. It is the same machine:\nthe only difference is : fails if I run using Spark to launch a distributed process and works if I launch directly using the command line.\nI will try to modify JUL level to check to see which library is broken.\nThx.\n. ",
    "gabeos": "I ran into this same issue -- in Fedora 21 atlas is packaged only with libsatlas.so (serial) and libtatlas.so (threaded)\nErrant bug report describing change\nThere's an apparently ongoing discussion of how to handle this here\nAnyway, now with fedora 21, you can't downgrade to atlas 3.8, so there's no easy way to get things working. I force installed an old rpm of 3.8 with 'rpm' rather than yum/dnf, but it's super hacky and might very well break things..\nanyway, I'm just wondering if you have any other suggestions, is there a way to build netlib-java or otherwise directly specify with libraries to use? I tried making symlinks to the libsatlas.so library in the /lib64/atlas directory (same error).\n. ",
    "kgrech": "Same issue for openSuse 13.2. Solved by removing repository version of atlas and installing the following rpm:\nhttp://rpm.pbone.net/index.php3/stat/4/idpl/23733523/dir/opensuse/com/atlas-3.8.3-5.1.x86_64.rpm.html\n. ",
    "danielkza": "Sorry for reviving this old issue, but it seems as of today Fedora still does not ship CBLAS with ATLAS or OpenBLAS. There seems to be an implementation available from GSL in libgslcblas.so.0. My first try was to simply symlink it to libcblas.so.3, but it was not sufficient, as it seems the netlib JNI objects are not compiled with -lcblas.\nThe only solution that seemed to work was to run Java with LD_PRELOAD=libgslcblas.so.0 in it's environment, so that the CBLAS symbols are already loaded in the JVM when netlib-native is loaded. Unfortunately I don't see an easy way to construct a library that would work in both situations, as explicitly linking to CBLAS would break Debian-based distributions, which do not have it.. I'm not distributing any binaries with the LD_PRELOAD workaround applied, I only used it privately. I thought it might be useful to anyone ending up in this thread from Google.\nedit: contrary to my previous statement, preloading libopenblas.so.0 actually seems to work, and does not bring up any licensing concerns.. ",
    "naiveCoder": "Hi,\nI even tried to clone the project using git and then build the jar using maven. But getting the same error.\n. Hi Fommil,\nThanks for your help, I tried this in my main class:\nLogManager.getLogManager().getLogger(Logger.GLOBAL_LOGGER_NAME).setLevel(Level.FINEST);\nBut it didn't help\n. Thanks but i could figure out and this did the trick :\nI put this in a config file and passed the file name as -Djava.util.logging.config.file=/home/mylogging.properties\nWhere contents of mylogging.properties are : \nhandlers = java.util.logging.ConsoleHandler, java.util.logging.FileHandler\n.level = FINEST\njava.util.logging.ConsoleHandler.level = FINEST\njava.util.logging.FileHandler.level = FINEST\njava.util.logging.ConsoleHandler.formatter = java.util.logging.SimpleFormatter\norg.netlib.level = FINEST\norg.netlib.handler=java.util.logging.ConsoleHandler\n. ",
    "Myasuka": "Thank you for your reply, our cluster set up in the begin of 2011. At that time, the version of gcc included in the OS is 4.4.\n. ",
    "xhudik": "thanks fommil for the fast answer!\nI do have an additional question:\ndoes netlib-java have any verbosity/logging switch?\nBasically, my problem is that I always get error message:\nBLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\nEven i have successfully installed openBlas and make ln -s  /usr/local/lib/libopenblas.so libblas.so.3. Therefore some more logs would be welcome...\nthanks, Tomas\n. ",
    "DreamFlasher": "Thank you  @avulanov - your comment was extremely helpful!\nIn order to do that I executed find . -type f -name \"pom.xml\" -exec sed -i 's/1.2-SNAPSHOT/1.1.2/g' {} + in root. \n. It might be wrong, but it works, which is the great advantage in contrast to your solution. The tag https://github.com/fommil/netlib-java/tree/1.1.2 also has the 1.2-SNAPSHOT version in it.\n. ",
    "ldmtwo": "@fommil On RedHat, CentOS, etc, we are having huge issues getting this working. There are too many dependencies to satisfy and this is the only one we are not making progress with. As people said above, it is difficult to get our custom library to load when F2jBLAS keeps getting loaded. Libgfortran 1.4 and other magic is needed. I can't even force it to load my desired library with any of these below or combinations. I also find myself building this from scratch. Branch 1.1 ... I mean 1.2-snapshot. The comments in the pom might be helpful. I'll know in a few hours. I hope you will listen to the issues people are having soon. ....Nope. Has anyone been able to build this from scratch? I'm using GCC 5.3 (built from source, which has at least gfort 1.4). Previously, we were using GCC 4.8. The dependencies were fixed and thoroughly tested to be working, but netlib is still loading the wrong .so files. I need to show Spark and Spark-perf using non-standard BLAS libs.   \n-Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS \n-Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.NativeRefLAPACK \n-Dcom.github.fommil.netlib.ARPACK=com.github.fommil.netlib.NativeRefARPACK \n-Dcom.github.fommil.netlib.NativeSystemBLAS.natives=/opt/intel/mkl/lib/intel64/libmkl_rt.so\n-Dcom.github.fommil.netlib.NativeSystemBLAS.natives=/root/spark-perf/mllib-tests/target/netlib-native_system-linux-x86_64.so\n. ",
    "gtopper": "Thanks for the quick answer. Looking at the POM file, I see\nxml\n<dependencies>\n        ...\n        <dependency>\n            <groupId>net.sourceforge.f2j</groupId>\n            <artifactId>arpack_combined_all</artifactId>\n            <classifier>javadoc</classifier>\n        </dependency>\n</dependencies>\nSo I wonder why would SBT not pull it in?\n. It looks like the dependency is \"provided\" in the source pom, but not so in the artifact pom.\n. If so, it seems to still exist in the latest Maven (3.3.1). Please consider reopening this issue. I guess I'll have to work around it in my project for now, since my knowledge of Maven is limited.\n. ",
    "marcelluethi": "@fommil As you say, the problem can be reproduced from a single thread. But it seems to be more prominent if we run things in parallel. In one case (a large example that is too big to reproduce here), it gave horrible results when we run things in parallel and worked without problems when we run it single threaded. Does atlas also parallelize  internally? Using libatlas3gf-base (on Ubuntu 14.04) also seems to be causing the problem.\n. Unfortunately, I will personally not find time to dig deep into the problem within the next weeks, but can follow it up a bit later if needed (from early June things should look better, time-wise). \nNeither accuracy nor speed is a big issue for us at the moment, but the behaviour should be deterministic. The code is part of an evaluation metric that assesses the quality of a statistical model, and we realized that different runs for the same model resulted in very different metric values. \nFor the moment we will therefore use F2jblas to guarantee that we get consistent results. \nBTW, thanks a lot for providing these libraries. So far they worked very well for us. \n. ",
    "ibrahima": "Well, I don't know how \"real\" Android's Java is but it does support JNI. I did manage to get openblas built for Android so I'll try and see how DGEMM performance looks for F2J vs the native implementation. My initial test of some random matrix code was like 1000x slower on Android vs PC so I figured there must be some performance to be gained by using a native implementation but I guess comparing Broadwell vs Snapdragon is never going to be a close comparison. I tried sticking openblas in the library directory symlinked to libblas.so.3 but it doesn't seem to load correctly without really telling me why (it loads fine when I force it to load via System.loadLibrary()). I might want to rebuild the JNI library but I get errors like the following when attempting to use maven to compile:\n[ERROR] Plugin com.github.fommil.netlib:generator:1.2-SNAPSHOT or one of its dependencies could not be resolved: Failed to read artifact descriptor for com.github.fommil.netlib:generator:jar:1.2-SNAPSHOT: Failure to find com.github.fommil.netlib:generator:pom:1.2-SNAPSHOT in https://oss.sonatype.org/content/repositories/snapshots/ was cached in the local repository, resolution will not be reattempted until the update interval of sonatype-plugins-snapshots has elapsed or updates are forced -> [Help 1]\nHow should I go about building netlib-java?\n. ",
    "briantopping": "Hi Sam, thanks for the consideration. Timeframes wouldn't be a problem. I'm not sure about schedules on my end either.\nI haven't build native libraries for OSGi before, but it seems to simplify deployment a lot. It appears that one jar can hold all the different platforms and build metadata helps sort it out on deployment. So maybe an n+1 native library for OSGi that has everything is an option. I'd play with it and we could try some different configurations on to see what feels best.\n. Yes, it's certainly formidable! I will have to plow through your custom plugin to get a better idea, but you did a really nice job with it all, kudos. Docker does sound interesting, but OS X support is weak.\n. ",
    "hntd187": "Well here is what I get from the extracted jar \nldd netlib-native_system-linux-x86_64.so\n    linux-vdso.so.1 =>  (0x00007ffff19ba000)\n    libgfortran.so.3 => /usr/lib64/libgfortran.so.3 (0x00007f199fcaa000)\n    libblas.so.3 => /usr/lib64/libblas.so.3 (0x00007f199fa51000)\n    liblapack.so.3 => /usr/lib64/liblapack.so.3 (0x00007f199f1e6000)\n    libc.so.6 => /usr/lib64/libc.so.6 (0x00007f199ee25000)\n    libquadmath.so.0 => /usr/lib64/libquadmath.so.0 (0x00007f199ebe9000)\n    libm.so.6 => /usr/lib64/libm.so.6 (0x00007f199e8e6000)\n    libgcc_s.so.1 => /usr/lib64/libgcc_s.so.1 (0x00007f199e6d0000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007f19a0366000)\n. and the reference implementation\nldd netlib-native_ref-linux-x86_64.so\n    linux-vdso.so.1 =>  (0x00007fffb7926000)\n    libgfortran.so.3 => /usr/lib64/libgfortran.so.3 (0x00007fe8246f9000)\n    libc.so.6 => /usr/lib64/libc.so.6 (0x00007fe824338000)\n    libquadmath.so.0 => /usr/lib64/libquadmath.so.0 (0x00007fe8240fb000)\n    libm.so.6 => /usr/lib64/libm.so.6 (0x00007fe823df9000)\n    libgcc_s.so.1 => /usr/lib64/libgcc_s.so.1 (0x00007fe823be3000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fe82507d000)\n. Okay, is it possible to just specify my own native libraries manually like this?\n-Dcom.github.fommil.netlib.NativeSystemBLAS.natives=/lib64/libblas.so\n-Dcom.github.fommil.netlib.NativeRefBlas.natives=/lib64/libblas.so\nOr if that isn't correct, is it fine to just extract the shared objects from the jar and link to that via this method?\n. I have what seems to be working now, but I'm unsure if my library is being loaded. I compiled OpenBLAS on the system and updated the alternatives for libblas and liblapack and I get this in my log \n14 Aug 2015 11:24:04,436 WARN Executor task launch worker-0 com.github.fommil.netlib.BLAS - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n14 Aug 2015 11:24:04,470 INFO Executor task launch worker-0 com.github.fommil.jni.JniLoader - successfully loaded /tmp/jniloader3044167538019362070netlib-native_ref-linux-x86_64.so\nI'm not sure if this is saying the loading of the library failed or the loaded was successful, could you shed some light on this?\n. actually I added symlinks from lib64 to the openblas libraries and the warning disappeared, sounds like it's working, also the info about loading successfully still comes up.\n. Yup, you're right it's loading the system now.\nFor reference the atlas blas and lapack libraries don't work out of the box it seems, but compiling with open blas seems to work.\n14 Aug 2015 11:47:52,396 INFO main-EventThread com.github.fommil.jni.JniLoader - successfully loaded /tmp/jniloader2356580035481457001netlib-native_system-linux-x86_64.so\n. ",
    "RoiViber": "Hi.\nI read this one, and have actually managed to make this work also by linking (using alternatives) and using the JNI loader. My problem still remains. \nI know that i should link  to  \nbut what about  ?\nthe OpenBLAS build doesn't provide me with anything that have \"lapack\" in its name. The only files I get from MAKE-INSTALLing the OpenBLAS are:\nlibopenblas.so\nlibopenblas.a\nlibopenblas_sandybridge_.so\nlibopenblas_sandybridge_.a\n. OK. I understand that the \"jni\" library does the linking through a temporary .so file it creates for the Spark run (in /tmp). I also got it linking right - the < temp netlib's .so file> contains the same links as the < libopenblas.so > file (i ldd both of them), except that i got the following error when trying matrix multiplication in spark-shell:\n/usr/java/latest/bin/java: symbol lookup error: /tmp/jniloader6728254881598867695netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm\nAnd now I really believe I did everything written in the manual.\nI finally got it solved by adding:\nexport LD_PRELOAD=< libopenblas.so >\nThanks for everything, especially the quick reply. I really appreciate that!\n. Fair enough. Thanks for the fast reply. \nDoes Netlib log some message that can be informative regarding whether is it used or not?\n. ",
    "danielkorzekwa": "this is what I'm getting on runtime:\nSep 01, 2015 11:47:13 AM com.github.fommil.netlib.LAPACK \nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\nSep 01, 2015 11:47:14 AM com.github.fommil.jni.JniLoader liberalLoad\nINFO: successfully loaded C:\\Users\\KORZEK~1\\AppData\\Local\\Temp\\jniloader437420495990851267netlib-native_ref-win-x86_64.dll\nSep 01, 2015 11:47:14 AM com.github.fommil.netlib.BLAS \nWARNING: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\nSep 01, 2015 11:47:14 AM com.github.fommil.jni.JniLoader load\nINFO: already loaded netlib-native_ref-win-x86_64.dll\n. ",
    "tgsoverly": "Yea, I have tried both of those things as well.  I put it on the PATH and directly in System32, with the names above and not renaming.\n. ",
    "hmf": "For anyone encountering this problem with ivy/sbt: you need to add f2j explicitly.\nlibraryDependencies += \"net.sourceforge.f2j\" % \"arpack_combined_all\" % \"0.1\"\nlibraryDependencies += \"com.github.fommil.netlib\" % \"all\" % \"1.1.2\" pomOnly()\nlibraryDependencies += \"com.googlecode.matrix-toolkits-java\" % \"mtj\" % \"1.0.4\"\n\nHTHs. ",
    "bashimao": "Is there a way to get the path of the loaded native library in code? I know there is a debug output, but I want to see if all my cluster nodes load my preferred native implementation.\n. ",
    "radiodee1": "the F2j implementation crashes. That's the problem. Is this \nsetProperty() line written wrong? I'm not loading anything. Should it be \n\"F2JBLAS\" to work?\nOn 02/05/2016 05:09 PM, Sam Halliday wrote:\n\n(you should just be using the F2J implementation, I don't know why \nyou're trying to load natives that are not there)\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/fommil/netlib-java/issues/99#issuecomment-180590950.\n. thank you. replacing 'all' with 'core' stops that particular error. \nThanks again.\n\nOn 02/05/2016 05:50 PM, Sam Halliday wrote:\n\n|Caused by: java.lang.ClassNotFoundException: Didn't find class \n\"com.github.fommil.netlib.BLAS\" |\nthis means you have not got the required jars on your classpath. It's \nnot a bug in |netlib-java|.\nDepending on |all| is wasteful on Android, you only need |core|.\n\u2014\nReply to this email directly or view it on GitHub \nhttps://github.com/fommil/netlib-java/issues/99#issuecomment-180608699.\n. \n",
    "evolutics": "From the release notes, I think that dpstrf first came with LAPACK 3.2 in 2008.\n. Thanks a lot for clarifying! I was not aware of all this complexity. And I thought that I may have just looked for dpstrf in the wrong place.\nBut not a problem \u2013 for now, I\u2019ll probably just fall back on a general matrix decomposition like the LU decomposition.\n. ",
    "edelsohn": "VMs on POWER8 systems running PPC64 Linux are available to Open Source developers. Why was the issue closed?\n. If you weren't so quick to close this, you might have learned that IBM is offering bounties to fix issues, which is why @aszalucha opened the issue and recommended a bounty.\n. ",
    "randallwhitman": "Is the dependency on #76 the reason I get near-empty F2jFITPACK.{java,class} when I made a brief attempt at it - as opposed to missing something other than core/pom.xml that would need to be changed?\n$ ls netlib/FITPACK/\nbispeu.f  curfit.f  fpbacp.f   fpcoco.f  fpdeno.f  fpinst.f  fpperi.f  fprppo.f  fptrnp.f  percur.f  sphere.f\nbispev.f  dblint.f  fpbfout.f  fpcons.f  fpdisc.f  fpintb.f  fppocu.f  fprpsp.f  fptrpe.f  pogrid.f  splder.f\nclocur.f  evapol.f  fpbisp.f   fpcosp.f  fpfrno.f  fpknot.f  fppogr.f  fpseno.f  insert.f  polar.f   splev.f\ncocosp.f  fourco.f  fpbspl.f   fpcsin.f  fpgivs.f  fpopdi.f  fppola.f  fpspgr.f  Makefile  profil.f  splint.f\nconcon.f  fpader.f  fpchec.f   fpcurf.f  fpgrdi.f  fpopsp.f  fprank.f  fpsphe.f  parcur.f  README    sproot.f\nconcur.f  fpadno.f  fpched.f   fpcuro.f  fpgrpa.f  fporde.f  fprati.f  fpsuev.f  parder.f  regrid.f  surev.f\ncualde.f  fpadpo.f  fpchep.f   fpcyt1.f  fpgrre.f  fppara.f  fpregr.f  fpsurf.f  pardeu.f  spalde.f  surfit.f\ncurev.f   fpback.f  fpclos.f   fpcyt2.f  fpgrsp.f  fppasu.f  fprota.f  fpsysy.f  parsur.f  spgrid.f\nxml\n       <execution>\n           <id>fitpack-interface</id>\n           <goals>\n               <goal>interface</goal>\n           </goals>\n           <configuration>\n               <outputName>com/github/fommil/netlib/FITPACK.java</outputName>\n               <scan>org.netlib.fitpack</scan>\n               <fallback>com.github.fommil.netlib.F2jFITPACK</fallback>\n               <impls>com.github.fommil.netlib.NativeSystemFITPACK,com.github.fommil.netlib.NativeRefFITPACK,com.github.fommil.netlib.F2jFITPACK</impls>\n           </configuration>\n       </execution>\n       <execution>\n           <id>fitpack-f2j-implementation</id>\n           <goals>\n               <goal>f2j</goal>\n           </goals>\n           <configuration>\n               <outputName>com/github/fommil/netlib/F2jFITPACK.java</outputName>\n               <scan>org.netlib.fitpack</scan>\n               <implementing>com.github.fommil.netlib.FITPACK</implementing>\n           </configuration>\n       </execution>\nmvn package\n```\n$ ls -sh ./core/target/classes/com/github/fommil/netlib/\n 12K ARPACK.class   36K F2jARPACK.class  4.0K F2jFITPACK.class  4.0K FITPACK.class\n 12K BLAS.class     32K F2jBLAS.class    444K F2jLAPACK.class   112K LAPACK.class\n$ wc -l core/target/generated-sources/netlib-java/com/github/fommil/netlib/*a \n  13534 core/target/generated-sources/netlib-java/com/github/fommil/netlib/ARPACK.java\n  12606 core/target/generated-sources/netlib-java/com/github/fommil/netlib/BLAS.java\n    592 core/target/generated-sources/netlib-java/com/github/fommil/netlib/F2jARPACK.java\n    722 core/target/generated-sources/netlib-java/com/github/fommil/netlib/F2jBLAS.java\n     38 core/target/generated-sources/netlib-java/com/github/fommil/netlib/F2jFITPACK.java\n   7037 core/target/generated-sources/netlib-java/com/github/fommil/netlib/F2jLAPACK.java\n     86 core/target/generated-sources/netlib-java/com/github/fommil/netlib/FITPACK.java\n 158016 core/target/generated-sources/netlib-java/com/github/fommil/netlib/LAPACK.java\n```\n. For my purposes I got interpolation matching SciPy output, by adapting FITPACK code translated by f2j.\nhttps://github.com/randallwhitman/netlib-java/tree/fitpack-interpolation-f2j\nUp to you whether to keep this issue open for more general interest in FITPACK.\n. ",
    "mtbrandy": "Hardware is available at no-charge via the Power Development Cloud for exactly this situation.  It would be great if this could be added to the build.\n. ",
    "yuqilinaro": "I launched a pull request for jniloader for supporting AArch64: \nhttps://github.com/fommil/jniloader/pull/6\n. ",
    "heroxbd": "Sorry I read the REAMDE, it already have\nxml\n    <repositories>\n        <repository>\n            <id>sonatype-snapshots</id>\n            <url>https://oss.sonatype.org/content/repositories/snapshots/</url>\n            <releases>\n                <enabled>false</enabled>\n            </releases>\n            <snapshots>\n                <enabled>true</enabled>\n            </snapshots>\n        </repository>\n    </repositories>\nIn the pom.xml.   But it does not work.  Which part of the README are you referring to?\n. ",
    "DemiMarie": "@fommil no.  I guess my real issue is that there is no good way to debug failure to load native system libraries (I couldn't figure out how to do so).. @fommil The purpose isn't to create a release.  It's for users who build from source.. ",
    "zarzen": "Now, the jar is not available anymore? \nI want to install Spark Velox, which depends on this library. It always failure in building, due to Could not resolve dependencies for project edu.berkeley.veloxms:veloxms-core:jar:0.0.1-SNAPSHOT: Failure to find com.github.fommil.netlib:all:jar:1.1.2. I have tried several way to find all.jar, haven't succeeded. \n. Hi I did confirm that it has the <type>pom</type> tag in pom.xml. I am building Spark Velox(https://github.com/amplab/velox-modelserver), which depends on keystoneml_2.10. The Velox itself doesn't contain dependency \n<dependency>\n            <groupId>com.github.fommil.netlib</groupId>\n            <artifactId>all</artifactId>\n            <version>1.1.2</version>\n            <type>pom</type>\n        </dependency>\nBut keystoneml has one.. ",
    "tutnixzursache": "Well, I would consider it is less a bug or feature request than a heads-up and I understand that for most people this is a non-issue right now. \nFor myself, I've mitigated the problem using the above described solution (for Arch Linux). But, I assume more users will run into the same issue in the coming months:\nAs far as I've grasped the issue, the native components of netlib-java are compiled against the dynamic linked runtime libraries of gcc version 6.  However, I assume that  in the near future  more Linux distributions will drop support for GCC version 6 and its runtime libraries (i.e. among others libgfortran.so.3) and adopt GCC version 7 (stable since May 2017; shipping only libgfortran.so.4).\nThis means, that for those distributions---out of the box---only the fallback Java implementation would work, but not the native_ref/native_system versions (regardless of the underlying hardware architecture).\nP.s. \nRegarding commercial sponsoring: Sorry, I'm just a student working with Scala Breeze on small university projects/homework. But I gladly buy you a cup of coffee or a bottle of beer in case we meet some day :-)\n. ",
    "ghisvail": "\n1.1.1 was a bad (binary dep) release\n\nDid you read what I wrote? I am talking about the tags, not the binary releases. Both tags 1.1.1 and 1.1.2 point at the very same commit, so one of them is most likely wrong.\n\nI really don't agree that you should be distributing these jars this way, it runs contrary to the way the entire JVM ecosystem works.\n\nI am talking about the source code here, not the jars.\n\nIf you have customers paying you for this service, I would appreciate some of the profits.\n\nThis is completely off-topic to this issue, please read my opening statement again.. ",
    "grimreaper": "Right now this line is under the conditional but is at the same indentation. as the if statement and the \"callback\" below. Is that intended?. "
}