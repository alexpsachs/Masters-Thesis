{
    "siddontang": "I want to use pure go leveldb library level-go, but I hear nobody  uses it in production environment, so now I use cgo + leveldb. \nIf you have better choice, please tell me. Replace cgo + leveldb is easy.\n. I have wrote a pure go version here https://github.com/siddontang/ledisdb/tree/pure-go, based on https://github.com/syndtr/goleveldb, but I don't guarantee that it can be used in production.\n. Yes, now we use ledisdb in our production,  and we have been maintaining it as strong as possible to let people use safely. \nYou can try it yourself and then decide whether to use or not. \nI hope you can enjoy it.\n. you can use \nsource dev.sh\n./ledis-server config.json\ndev.sh will add leveldb and snappy lib path to LD_LIBRARY_PATH\n. only some server info support, keyspace statistics is not easy, not support\n. slaveof host port binlog_index binlog_pos\nbinlog log command\n. Well, supporting transaction perfectly is not easy, I may try to support it later, but only multi + exec + discard, watch and unwatch are not considered right now.\nThank you!\n. At first, LedisDB refers to the SSDB and cares little about transaction.  It only guarantees the atomicity of every command. \nAnd to improve multi write performance, It uses multi locks for different data structure, which makes more hard to support transaction. \nSo I have not think a good solution for supporting transaction right now.\nBolt may help me, it an awesome db, I will try to read the source and see how it supports transaction.\nThank you very much! \n. Today I saw bolt and kv in detail, and found that they all use a global lock to support transaction. Maybe it's the simplest way.\nI may use the same way, each DB (LedisDB has 16 independent DB) use a lock to  prevent multi write but support transaction, which like MySQL serializable isolation level. \n. Well, now I only care about LevelDB, but later, I will consider an unique store interface to wrap some other db, Eg, RocksDB, goleveldb, or even KV, BoltDB, LMDB.\nI browse LMDB source and find that it also use a lock to support transaction, maybe I can abstract same interface for all.\n. Well, c calls lua is very simple but I don't think go is easy too. I have no experience about the interaction of go and lua, maybe using swig or other? I don't known.\nIf you have any suggestion, please tell me, then I will consider supporting lua scripting.\nThank you!\n. Bolt is an awesome db,  I will  learn from it and try to support transaction in LedisDB. \nAfter that, for lua scripting consistency, maybe,  I think it only needs to start a transaction, exec some commands, then commit transaction. \nGo wrappers for the Lua is a new one for me, I will take a look at it.\nThank you very much!\n. now support in branch, later merge to develop\nonly boltdb, lmdb can support transaction\n. We add begin, commit, rollback command like MySQL transaction.\nLMDB and BoltDB are both serialized write, so begin will block all other write operations. You may not use the long-time transactions.\n. Of course, using transaction will block whole database because both LMDB and BotlDB use only one lock for write transaction.\nI will add the transaction caveat in readme and begin command in wiki.\n. we try to support transaction, using begin, commit and rollback, so I think lua is not requisite.\n. In fact, I love lua very much, I spent many time to develop a wrapper between c++ and lua for a network game before.\nUnlike Redis,I want to guarantee the ACID in the lua script, so I must support transaction first.\nSupporting lua depends on some workload, I have to consider LedisDB cluster and develop a MySQL Proxy https://github.com/siddontang/mixer at same time, and  I have not enough time now. Maybe I will try to ask someone for help:)\nBtw: if you have some interests in mixer, please give me advice too.\nThank you. \n. Hi @robert-zaremba \nLedisDB now supports lua scripting using https://github.com/aarzilli/golua in develop branch, like Redis http://redis.io/commands/eval.\nI will merge to master later. \n. SADD\nSCARD\nSDIFF\nSDIFFSTORE\nSINTER\nSINTERSTORE\nSISMEMBER\nSMEMBERS\nSREM\nSUNION\nSUNIONSTORE\nSClear\nSMClear\nSExpire\nSExpireAt\nSTTL\nSPERSIST\n. not necessary\n. not support, complicated \n. LedisDB's protocol is the same as Redis, so any Redis client in Node.js may be used directly for LedisDB, but not 100% compatibility because of some commands implementation. \nI will try to add Node.js later as quickly as possible. Thank you!\n. Hi @caio-ribeiro-pereira, thanks @wenyekui,  LedisDB now supports Node.js, you can try it. \nFeedback is very welcome. Thank you!\n. only support boltdb\ngive up kv\n. well, we will bench it too, using ledis-benchmark.\nredis-benchmark can not bench z* commands.\n. Well now the benchmark only refers to redis-benchmark,  it is simple. \nLater I will  benchmark writing a huge number of data exceeding RAM and  reading.\nI will also write a wiki about why LedisDB supports these databases and how to choose the proper one in your production, it is not a easy work and needs us to learn something deeply, but it is worth doing.\n. :+1: \nMaybe RocksDB is the best choice for LedisDB later.\nI have also do a benchmark with RocksDB and LevelDB, https://github.com/siddontang/ledisdb/wiki/Performance-Benchmark, but it is not completed.\nThank you very much!\n. prefer to use proxy to support multi ledis-server instance \n. Well, we are doing it now, here, but have not committed yet. Maybe next week!\nThank you very much!\n. Hi @railsmechanic, LedisDB now supports boltdb, you can try it.\nFeedback is very welcome.\n. LMDB write is very awesome, I will ask the author of the BoltDB for more help to improve it.\nThank you very much.\n. Thanks your feedback. It's my cursoriness. \nI don't known why you build snappy failed, maybe more information or use google? \nBut you can still use ledisdb +  leveldb without snappy. \n. only support nosync config\n. Manage go dependencies is not easy, I find many way to do it, like you list above or gopkg.in, or cloning to a vendor folder, or even forking to my own project. \nNow I fork most of the dependencies, and others work well now, \nLater, I prefer gopkg.in + fork, maybe consider Godeps.\nThank you very much. \n. Well, using json as the configuration is not friendly, only because my company uses it.\nI have been considering using yaml or even plain kv config instead. \nI have not used toml before, I will see it, then decide whether to use or not.\nThank you very much!\n. Well, I use goleveldb as the default storage now. LMDB's benchmark is very awesome because I use some dangerous configuration but BoltDB not uses, you can see more here.\nLater I will add some configurations to control how to sync in LMDB. Because LedisDB supports replication, it can take some risk for better performance.\nCGO maybe a bottleneck, but it's not too bad, our company uses LevelDB in production now, it works well too.\nThank you!\n. I will see TOML as far as I can. Using json seems unwise now.\n. @pkieltyka , Now I have refactored the configuration, you can see it in the develop branch.\nSome changes:\n- Use toml as the preferred config format, but because other projects in my company depend on json heavily, I have to support it too. \n- All modules, ledis, server, store and other use the same config struct.\n- Support default config if you not set.\nThank you.\n. Done!!! \n. @hit9  Done it. You can see it in develop branch.\n. no problem. you can see my go-websocket, or gorilla, but only RFC6455.\nThank you!\n.  I think you put forward a good HA solution for distributed LedisDB which I have not considered it. \nNow, for the replication, I only want to support a simple Master/Slave mode, like Redis or MySQL, slave only syncs with master using binlog and does nothing else, although you can read data from slave, you must take the risk not reading the new data. If the master down, you must choose whether to upgrade slave to master or wait master alive again.\nAs you see, it is very simple but not powerful, but it's the first step. I must promise LedisDB is stable as a single service.\nLater, I will try to support distribute, I will consider your suggestion, groupcache, couchbase, redis cluster or event a proxy, as you see, many things I need to know, not easy.\nBtw, now I have been developing a MySQL Proxy https://github.com/siddontang/mixer, so later maybe I will prefer proxy first, aha.\nThank you!\n. well, I use vitess parser now, maybe more like query cache later. vitess is a huge project for me,  I try to build a simple one just for my interest.\nThank you.\n. maybe we have same low taste, reinventing the wheel is not good most of time :)\n. may be you will encounter some tokuft building errors, using google or asking me.\n. please update, lmdb now is disable in windows \n. Individual package is only the db package, I need a space to register them uniformly. \nThe register function is in store package, if I  register db in its own package, import will be cycle.\nNow I only support lmdb, boltdb and goleveldb default, if you want to add other db, you must assign building tags.\nThe code in store is not good, I may refactor it later.\nBtw, are you build lmdb OK in windows?\n. Thank you, i will try refactor it later. \nSorry that I have no windows platform, I can not help you to solve this compile error, you can remove related lmdb files directly if possible, then have a try.\nThank you very much!\n. Thanks for using LedisDB.   \nAny suggestion is very welcome. \n. Hi @balzaczyy , Now I have refactored store, reduced some code, put register function in individual db.\nIt's in develop branch, you can try it.\n. I think we could learn something from couchbase. http://www.couchbase.com/\n. well, support cluster is not easy, or redis 3.0 would be released early. \nAny suggestion is welcome.\n. I will try to use RAFT to support distributed proxy. \n. Well, many go projects use the above way, like Vitess. In Ledisdb, it will also include self package, e.g: ledis will import store package, so you must guarantee ledisdb in the corrent go path. \n. Btw, can you tell me how to use ./configure? I want to add it for better building.\n. As you see, sometimes maintaining go package and go path is very painful. I heard that go1.5 may  solve it, hope so:)\n. https://github.com/siddontang/ledisdb/pull/53 has too.\n. Please send pull request to my develop branch, not master. \nWe only allow to merge develop to master.\nI will add your change manually, but not file permission, I prefer sh code.sh or python code.py explicitly, and we must use source dev.sh to export environment variables. \nFor sudo, I will not consider adding it, because someone may install leveldb without root permission.\nThank you very much!\n. Well, here is the mysql building guild http://dev.mysql.com/doc/refman/5.6/en/installing-source-distribution.html, if you follow it, you still can not install mysql because of root permission for /usr/local/mysql\nBut in RocksDB install guild https://github.com/facebook/rocksdb/blob/master/INSTALL.md, it uses sudo.\nNow I add sduo, later I will try to refactor the building, even remove leveldb support because I prefer pure go.\nThank you.\n. well, LedisDB supports scan hscan in ledis package not in server now, we will consider adding it later.\nLedisDB's scan operator is not the same as Redis, maybe we will use another name for no confusion.\nThank you.\n. Well, you mention above that you want to use scan to support some history operator? Maybe use zset better?\n. I got it. Thank you.\n. I will use row-format, not statement for simple.\nLater, in cluster I will use multi-write to different nodes, so binlog is not necessary.\n. I will remove the cpu info because some fields in Go is not cross platform and we may use other powerful tool to see it.\nThank you very much.\n. Bad luck, RocksDB changed some option APIs from v3.5, I have to update LedisDB with it.\nI hope RocksDB may not change API anymore, or at least retain old API and add new.\nThank you very much!\n. Well, Ledisdb has some API different from Redis, eg, del only deletes KV data, hclear deletes Hash data, etc, but in Redis, del can delete all type data, the same for persist and ttl.\nAlthough they have differences, you can write your own LedisDB client based on Redis client easily. \nI don't know Haskell at all, but I think it's easy to write a client based on https://github.com/informatikr/hedis.\nYou can see the commands.json and commands.doc in LedisDB doc, or wiki https://github.com/siddontang/ledisdb/wiki/Commands.\nBtw: :+1:  I have not heard any guy or company uses Haskell at all in China.\nThank you very much.\n. Why does LedisDB not use del to delete all type data?\n- At first, LedisDB refers to SSDB which uses del to deletes only KV data.\n- Performance,  If LedisDB can use del to delete all type data, it must save the relation ship with the key and the type in store, and get the type with key may have little performance cost. \n. :+1: , it's a good idea, I will add it as soon as possible. \nI have move this issue to #66.\nThank you very much!\n. :+1: \nI have not known this before.  In my scenario, I will use some keeper services. The keepers use raft or ZooKeeper to select the leader keeper and then manage the ledisdb servers, including select the master, etc...\nIt's very simple and someone tells me that they use the above way to manage mysql replication in production. \nWhy I want to try raft  is that  java is too heavy, but I will also consider it later because ZooKeeper may be more stable. \nThank you very much!\n. move #90, building a sentinel first using raft.\nLedisDB supports eventual consistency, maybe I will try to support strong consistency later. \n. @robert-zaremba \nI have wrote a simple wiki for the differences from Redis, maybe it can help you to use LedisDB in Haskell.\nhttps://github.com/siddontang/ledisdb/wiki/Differences-from-Redis\n. scan, hscan, etc, are different from Redis, You may pay attention to it. ::)\n. :+1:  using scan, etc, is very confused for me, but I have not found the proper one to name them.\nI will change them later. \nThank you very much!\n. I move it to #68 \n. @pkieltyka\nI have added xscan, hxscan, etc.\n. :+1:  I will update with it.\n. I have merged the update and find that goleveldb has a very big performance improvement, you can go get -u github.com/siddontang/goleveldb/leveldb to use.\nBtw, I think I will use godep or other tool to manage dependencies later.\n. Now LedisDB supports godep. You can use it with make directly if installed.\n. :+1:  Awesome! \nI will add it in wiki.\nI have not used docker before, I will try it later.\nThank you very much!\n. see #72  for more.\nI will do it later. Thank you. \n. Adding  zlexcount, zrangebylex, zremrangebylex\n. Well, I have not found a proper and fast way to support DBSIZE now, but I will try to do it later. \nSorry that the most thing for me is to support strong consensus replication using raft or paxos for LedisDB (our company needs it very much) now. After do that, I will try to add these APIs.\nThank you very much.\n. @wenerme \nwe use xcodis(a modified codis version) to support cluster, so we will not consider replication using raft or paxos any longer.\nLedisdb support a sync replication (master <-> slave) in configuration. but it will degrade to asynchronous replication sometimes, so not always consensus.\n. Thank you, I will fix it later.\n. Please update code and test it too.\n. Adding a command to ledisdb will change many codes, not only above yours. I will consider to add it later.\nBtw, your time implementation is not the same as redis, we need compatibility.\nThank you very much.\n. @dancebear \nLedisDB now supports time command in develop branch. Later I will merge it to master.\n. Well, I suggest using LevelDB(RocksDB, GoLevelDB) for huge data (1 billion+) stored in LedisDB (not BoltDB and LMDB) because they have more high performance. But they don't support transaction at all, so supporting this feature may be not necessary?\nTo support a simple transaction, later I will try to add multi, discard, exec like Redis or you can use Lua in LedisDB.\nBtw, later, I will try to add cluster support for LedisDB, at that time, transaction can not be used at all. \nThank you very much!\n. I will retain it. :-)\n. Well, maybe the simplest way is to git pull the latest code, then . ./dev.sh and make clean, make.\nI will try to keep the API compatibility, but I have not release a stable 1.x version for LedisDB until now, so sometimes it may not be backend compatibility when you update.\nThank you very much.\n. No, if you not use server, no connection needs to be opened.\nThank you very much!\n. It's very dangerous to change storage API, so I will not change it except that we encounter some very serious bugs, but not for LedisDB API, eg, I may remove begin, commit, rollback because of the db limitation. \nBtw, I will change replication mechanism later, so the previous binlog may be unusable.\n. It's very strange for me too. Maybe below:\n- You start another LedisDB using the same path and not close. You can see https://github.com/syndtr/goleveldb/issues/23\n- You have no permission to write this directory? \nMaybe you can try these below:\n- Set data_dir to another directory like /tmp/ledisdb_server to see whether it can start or not.\n- killall ledis-server, remove old data_dir path then start again?\n- Use boltdb instead of goleveldb\nThank you very much.\n. :+1: \nYou run two application with the same path for goleveldb, and goleveldb will crash for it. I think I will try to check this by myself, not goleveldb.\nThank you very much!\n. Adding a command for LedisDB will add many code not only above one but for doc, wiki, client(lua, python, nodejs), ledis-cli.\nI will add append in todo plan.\nThank you very much.\n. Not support now.\n. Support in rpl-feature branch now, later merge to develop branch.\n. Sorry that I can not understand your scenario completely.\nLike Redis, LedisDB only uses integer for db and has select command to choose it. You will maintain the relationship between the name and the number index for a db in your own application.\nI see above code may be written by python, for redis-py(the python redis client), it also does not support select because of the connection pool, which makes you have to create multiple db instances. \nI guess you may need below feature?\nl  = redis.Ledis(**redis.Config)\ndb_title = l.Select(0)\ndb = l.Select(1)\nThank you very much!\n. Maybe another choice is to using a single DB and specified prefix key for different objects like below?\n```\ndb := ledis.Ledis(db = 0, **config)\ndb.Set(\"title:xxx\", value)\ndb.Set(\"cat:tree:xxx\", value)\n```\n. Well, for LedisB, it only uses a single database like LevelDB, all Dbs[0-15] are stored together and distinguished by the first byte of the key in LevelDB.\nEg, if you set key abc with value 123 in db 0, the real key stored in LevelDB likes this: 01abc, 0 is the db index 0, 1 is the data type for KV, and abc is the key you input.\nSo using multiple DBs will works well and have no performance bottleneck. \nThank you very much!\n. LedisDB supports ledis-load and ledis-dump tools in cmd directory. \nThank you very much!\n. For next ledisdb release, the ledis-load will discard all old data before loading the backup. :-)\n. Thank you, if you find any typo error, please tell me.\nI am not good at english, so your help is very important for LedisDB.\n. Well, ledis-cli uses redis linenoise which dose not support windows at all. (the same for redis). \nI think it does not matter. \nThank you,\n. Supporting daemon for go application is not easy. You may use some external tool like supervisor or daemonize to support it.\nFor the second, can you give me some examples about your scenario? \nYou must know that for LevelDB(RcoksDB, GoLevelDB), reverse iteration is very slow, so maybe you can adjust the storage mode for your data and use scan?\nThank you very much!\n. :+1: \n. Redis has daemonize config, so it can support it directly......\n. You can also try to remove your building pkg first. :-)\n. It does not matter for your use. \nMaybe you can send this issue to the author of the gomdb.\n. Thank you! I have fixed it.\n. :+1: \n. - install godep and run bootstrap.sh again or\n- go get github.com/siddontang/go/filelock and try make\n. I guess you need xrevscan like zrevrangbyscore not desc?\nI think desc are for sorting which you can do it in your own app but not for descending iteration.\n. @robert-zaremba , if I think above right, I will add xrevscan in todo?\nBtw, you must realize that reverse iteration is very slow in LevelDB.\n. For LevelDB, RocksDB, GoLevelDB,  reverse iteration is all slow. You can see the benchmark about zrangebyscore and zrevrangebyscore, so use forward iteration!\nReverse iteration is fast in LMDB and BoltDB, but I don't suggest using them, BoltDB is very slow for write, and LMDB is not suitable for very large data.\nBtw, this article may help you too http://influxdb.com/blog/2014/06/20/leveldb_vs_rocksdb_vs_hyperleveldb_vs_lmdb_performance.html\n. LedisDB now supports xrevscan, hxrevscan, etc..., you can use them like xscan but with reverse order. \n. well,  the reason I wanted to use raft before is that I thought raft is easy to learn, but I don't implement it.\nNow I use a codis derivative named xcodis to support cluster, which uses zookeeper, although it does not support failover automatically, I think it is still ok.\nBtw, if codis supports sentinel later, I will add it to xcodis too. \n. support in http://github.com/siddontang/redis-failover\n. Is it necessary? Most of time, eventual consistency is ok, strong consistency is very hard to implement and has very bad performance.\n. not support now!!!\n. I have no 32 linux environment, please run go test in filelock, if no error happens, maybe your change is ok, otherwise, I may ignore file locking in linux 32.\nThanks. \n. @Leither \nPlease run go get -u github.com/siddontang/go/filelock and then run make.\nIf you have installed godep, run make directly.\nThanks\n. Hi @xlab, are you sure to save so big data in ledis? I tested writing big data (4kb, 10kb) into rocksdb, leveldb, goleveldb directlly and found that performance was very bad. I worry that ledis will not work well for this, especially using replication at same time.\n. Hi @xlab, I don't think RocksDB is good for saving big data. Eg, if you write 12mb to rocksdb, first it will write it in log, then commit it to mem table, and flush to sst in the end. \nIf you open replication, it will write this data to replication log, too bad!!! \nI have written ledis-storebench, you can use it to test rocksdb with big data. You can use the tool db_bench in rocksdb source too.  You also can use ledis-benchmark to test ledisdb at same time. \nBut as you say, it is a good way to share files if you don't care too much about performance :-) \nHope more bench result. \n. :+1:  Thanks for you detailed report, @xlab, and sorry that this limitation causes your inconvenient use.\n Maybe later I will support changing it in config file. \nBtw, use at your own risk for the big file, aha!!!\n. I found a bug in ledisdb-benchmark, randomizing the big buffer every time, which is very slow. So the performance is not good.\n. bugfix the ttl key format in db., must run ledis-upgrade-ttl to upgrade db manually.\n. Sorry, bitmap is a data structure, not picture. \nRedis uses bit for its name, and we use bitmap which confuses you.\n. support in develop branch now\n. support now, use GetSlice\n. Thank you, I will try to learn and use travis too.\n. Thanks @Leither \nBatch is not transaction, it only means writing multi k-v atomically. Transaction means ACID support, you can rollback your change which batch can not do this.\nI will optimize LoadDump later, using batch.\n. add todo: optimize LoadDump using batch\n. Not the same. For a transaction, let's consider below condition:\n```\nt := begin()\nt.Set(a, 1)\nb = t.Get(a)\n//b must 1\n```\nWhatever you write in the pre batch, you will read the new data, this is not easy to support for leveldb, especially for iterator. \nIn my opinion, transaction must support ACID, but leveldb can not support it, you can using google for more information.  like http://stackoverflow.com/questions/9022691/what-constitutes-a-transaction-layer-when-talking-about-database-systems or https://groups.google.com/forum/#!topic/leveldb/O_iNRkAoObg/discussion\nThank you.\nBtw, I will discard transaction later, it causes hard code and I don't want to maintain it anymore :-)\n. batch load dump is supported in rep-feature now, later merge to develop then, master.\n. as you see, only one key transaction, but not for many keys using iterator, it is not easy to support. \n. LedisDB does not support filter or customized replication, and I have no idea about this now. Maybe later. \nBut you must know that if this feature supported, you can not promote a slave to master arbitrarily.\n. :+1: \nThis formatEventKey in event.go may help you writing your own key parser, and you can use BatchData to parse the replication log.\nGreat, but use your own risk, the slave can not be promoted as master. \nBtw, please use develop branch, not master branch. \n. support https://github.com/siddontang/xcodis here\n. Hi @ShawnMilo , I will merge your contribution today. \nAs you see, my Chinese english is very bad, :smile: so I need more help like yours to improve the syntax, fix the typo. \nThank you!\n. :smile: \n. Thanks @Leither \n1, LedisDB uses hsize key to support scan and I don't want to support keys, you can see the scan function for more.\n2, Why seperator? LedisDB will use this to support hgetall, hkeys and hvalues, I need a fast way to iterate all fields, not keys. \n3, If I put the type in the key end, how could I fetch the specified type data easily with iteration? you must know that leveldb seek is prefix match first.\n. Hi @Leither , you focusing on key gathered, I focus on type gathered which may hit performance,  but I don't think it is unacceptable. \n1, how to select a proper separator? people can use any arbitrary character. \n2, many people use SSD, so the disk problem gets less seriously.\n3, cache, we can use it for specified meta type like hsize to avoid random read. \nIn my production environment, we don't meet any leveldb performance issues so far, and you must know that if the key format changed, how to let all users update easily? \nI will not change the key format unless I see that it hits performance very much and can not be used in production. \nThank you. \n. Thanks @Leither, as you see, the key is limited in application, but can you limit all users to not use a specified separator? redis has no this limitation, ledisdb will not. \nI think performance is very important, but sometimes we may sacrifice it a little. :smile: e,g, if I put the type in the key end, for the TTL, how to find the next expiring key quickly? \nBtw, your advice is very useful, I want more foreign friends can see and discuss this, may you use english later? \n. :+1:  but please don't change this issue anymore, which wastes your time.\nUse english at next issue, :smile:\n. No, you can use the official snappy, I just fork it. \nThank you. \n. maybe you don't install lmdb, do you use windows? if yes, comment this:\nfunc TestTx(t *testing.T) {\n//  testTx(t, \"lmdb\")\n    testTx(t, \"boltdb\")\n}\nbtw, I have no windows, so supporting it has low priority. \n. I don't support lmdb in windows.\nfix it in develop branch. \n. retain bitmap for some time, but will not improve it any more. \nLater add bit operations for kv type. \n. Sorry, can you give me more explanation? I could not find why it has problem.\n. :+1:  , thank you very much. \n. @wenyekui \n. ledisdb is not redis, only using its protocol, so you can not think they are compatible. \nSee https://github.com/siddontang/ledisdb/wiki/Differences-from-Redis \n. :+1: \n. First of all, we use leveldb, goleveldb in some products, but now, we prefer using rocksdb. \nSome people told me they use rocksdb in product environment too. \n. Do you use the newest LedisDB? I have not used my forked goleveldb. Maybe you can update the source and use ./bootstrap.sh to get the dependences again. \n. If you meet again, I think we will send this issue to goleveldb author. :smile: \n. Em, maybe I will create another project to do this?\n. Now Ledisdb support same key name for different type, I hope anyone has not not used this feature, :-),  otherwise it is very difficult to upgrade the db.\n. @spitfire2  you can try qdb, this is a redis compatibility implementation. \n. Hi @GlenDC \nLedisDB is not compatible with Redis, but if we need commands, we can think a way to add them one by one. . :+1:  The goleveldb updates too frequently and seems not supporting compatibility.\nI will try to upgrade ledisdb later. \nBtw, Ledisdb supports godep, maybe you can use it to build? \nThank you. \n. fix in develop branch.\n. :+1:  I will try it later. :smile: \n. Use xscan \"\" first, * is the key, maybe not existed in your db. if you want to use some regexp, use like XSCAN  key MATCH abc* COUNT 10. \nThe return for xscan is a array which the first one is the key for next xscan. \nMaybe the document for ledisdb is not easy to understand. :worried: \n. Sorry @pkieltyka, \"X\" makes you surprised, I will change it later. \nBtw, do you think it is necessary to do #117 or #120 ? \nI just notice that https://github.com/github/hub use \"godep -r\" feature, which makes the package management easy, but the import path looks very long and ugly :-)\n. Thanks @pkieltyka \nI will use godep -r later, although the import path looks ugly :smile: \nFor redis comparability, I mean maybe del can delete not KV data, but also Hash, List, etc... like in Redis, but it may cause some performance degradation and data upgrade. \nBtw, the XSCAN can be used correctly in your project?\n. Thanks @Alienero , I have merged it into develop branch bb01d4c246db3281af3b02a337059e34fb4f7069\n. Hi @naterockhold , ledisdb supports xscan, xlscan, etc, which can do the same things and may be better and more efficient. \nFor Redis, I think it is not wise to use keys for large dataset too. So I would not support it. \nThank you. \n. fix, thank you\n. thanks, fix in develop branch now. \n. Yes, WaitReplication will return immediately, it does not block if no event handled.\n. Maybe I can add a timeout argument, if no event, wait timeout before return. \n. Hi @iwanbk , LedisDB uses RocksDB WriteBatch, which will guarantee atomic writing for multi values, so I think all elements will be pushed ok, except RocksDB has some  bugs in WriteBatch :smile:\n. Thanks @coleifer, sort looks complex, I will dive into it and evaluate the difficulty. But this function is so powerful that I also want to support it :smile: \nLedisDB can not check the type with a raw key, so maybe I will use xhsort for hash, xlsort for list, etc...\n. hi @coleifer ,  I have supported sort command in develop branch, unlike redis, I use xlsort for list type, xssort for set type and xzsort for zset type\ne.g.\nledis>mset w_1 1 w_2 2 w_3 3\nOK\nledis>mset o_1 1 o_2 2 o_3 3\nOK\nledis>lpush a 1 2 3\n(integer) 3\nledis>xlsort a\n1)  \"1\"\n2)  \"2\"\n3)  \"3\"\nledis>xlsort a desc\n1)  \"3\"\n2)  \"2\"\n3)  \"1\"\nledis>xlsort a by w_*\n1)  \"1\"\n2)  \"2\"\n3)  \"3\"\nledis>xlsort a by w_* get o_* get #\n1)  \"1\"\n2)  \"1\"\n3)  \"2\"\n4)  \"2\"\n5)  \"3\"\n6)  \"3\"\nRedis's sort has some optimization for zset type,  but I don't have done it now, it is not a serious problem. \nI will add some docs and merge this into master branch later if possible. :-)\n. Please supplement doc too :smile: \n. keep all commands in commands.md, then write some script to generate others. \n. support in develop branch now\n. Hi @arneto \nThe default read connection buffer is 10k in the config, here \nconn_read_buffer_size = 10240\nconn_write_buffer_size = 10240\nmaybe this causes your problem, but I am confused too. \nI write a benchmark tool using go, you can use it to compare your c tool, like this:\nledis-benchmark -t=set -vsize=10194 -n=1 -r=10 -c=1\nledis-benchmark -t=set -vsize=10195 -n=1 -r=10 -c=1\nthe value size is10194 or 10195 ,round is 10, and request number is 1 in every round, one client.\nor like this:\nledis-benchmark -t=set -vsize=10194 -n=1000 -c=1\nledis-benchmark -t=set -vsize=10195 -n=1000 -c=1\nIn my computer, the different value size does not affect the result too much, so I wait yours. \nThank you. \n. Hi @arneto \nDo you fix your problem now? \nHow about the comparison between your c tool and ledis-benchmark?\nIncreasing the conn buffer is still slow?\nThank you! :smile: \n. Hi @kouhate ,  role is my fault, I fix it in develop branch. \nThis seems an interesting error for replication, can you redo like below, only using flag and default flag:\n```\n// master\nledis-server -rpl -addr=localhost:6380 -data_dir=./var\n//slave\nledis-server -rpl -addr=localhost:6381 -data_dir=./var1 -slaveof=localhost:6380\n```\nIn my test, role for master and replication all are ok. \n. Hi @kouhate , make sure you use the latest develop branch code and rebuild ledis-server. (you can make clean first then make again)\nIn my computer, redis-failover can handle it. \n. I find a bug for the use_replication config, and will fix it later. \nThank you. \n. Hi @kouhate \nIn the message here\n[2015/02/14 16:58:24] app.go:333 [Error] do after failover handler for localhost:6380 -> 127.0.0.1:6381 err: no such addr 127.0.0.1:6381 not found\nI suggest you should use 127.0.0.1 for all instead of localhost. \nredis-failover uses role command to get the slave information, although you set localhost:6381 as slave in codis, the role command will return 127.0.0.1 as the slave host, so redis-failover can not find the slave server using 127.0.0.1.\n. Hi @kouhate , I am also surprised at the salve type. you can see cmd/ha/failover.go and cmd/ccconfig/server_group.go, I use the same function Promote to handle this changing.\nCan you show me the output for redis-failover? \n. Maybe we will do more test later, I am confused too. :-)\n. Hi @kouhate , sorry for the later response. I have a long vacation for Chinese Spring Festive and will go to work next week. \nSupporting HSCAN may be easy, but like XSCAN compared to SCAN, the function may be different from HSCAN in Redis. So giving another name with X prefix may be a good choice, maybe you can help me name it :smile: \n. Thanks @kouhate, using HXSCAN or other before is my fault, I may remove them later or reuse as your recommendation. :-)\nI can not change XSCAN because of the compatibility.\n. Sure. I think we could use another new name, not \"scan\", maybe \"travel\"?\n. Hi @kouhate,  move to #138. \n. Aha, @kouhate suggests me to prefix data type for commands like Redis. I think using X prefix may be good to distinguish Redis commands. \nMaybe we can think another name, like HSEEK?\n. Hi @kouhate,  Support in develop branch now. Commands:\nXSCAN type cursor [MATCH match] [COUNT count]\nXHSCAN key cursor [MATCH match] [COUNT count]\nXSSCAN key cursor [MATCH match] [COUNT count]\nXZSCAN key cursor [MATCH match] [COUNT count]\n. Hi @kouhate , redis does not support reverse scan, and I don't find a useful use case too.\nBtw, supporting reverse scan is easy, is it necessary to support reverse scan for hash, set and zset?\n. @kouhate , I will add reverse scan later, but you must know below:\n- reverse scan is slower than forward, unless leveldb or rocksdb improves it.\n- migrating a huge hash data (with many fields and values) is very terrible in xcodis when resharding. We must dump this huge data first, then transfer into another server and load it, it may take huge memory, cost many time and block other write operations for a long time. \nBtw, I think ZREVRANGE* may be more convenient than XZSCAN DESC.\n. Now, yes, because I must guarantee the atomic migration. When I migrate the key, other write operation may update the key at same time, it may cause data inconsistency. \nBut this can be improved later, only using a lock for the key and not for the whole. \n@kouhate, we can move to #141 for this discussion. \n. @kouhate, for redis, ZSCAN first scans elements with small score, then uses lexicographical ordering for same score, but for ledisdb, it only use lexicographical ordering, is this a problem for you? \n. Hi @kouhate, I have been trying to use ledisdb + xcodis + redis-failover to build a high availability distributed key-value store service in my company.  I guess you may do the similar thing. \nCould you tell me your email? Maybe we can have a in-depth discussion or even work together to build a NoSQL product.\n. Hi @jgoodall, using transaction with boltdb or lmdb is easy likes MySQL transaction using, below:\nledis> begin\nledis> set a 1\nledis> set b 2\nledis> commit\nBut is it necessary to support transaction in LedisDB? I've always wondered. \n- Transaction is not universal, leveldb, rocksdb can not support it, and most of the ledisdb users use rocksdb as the backend. \n- Transaction will block any other write operations, this may degrade performance. \n- Above all, transaction leads to complexity. \nBtw, why should you use this feature? \n. Hi @jgoodall , in your scenario, ZIncrBy would increment the set and return the new score atomically, so you don't need a transaction, below may be ok:\ndb.ZIncrBy(...)\ndb.ZRangeByScore(...)\nThe boltdb API has a Begin method to start a transaction, but it is underlying, so I don't suggest to use it directly. \n. I have Removed them. \n. #138 @kouhate said blocking write operation would be a fatal problem.\nBut\n1. migration is not often, or even would not be occurred if we pre plan enough nodes.\n2. we can do resharding at some time, like middle night,  this would affect the whole system little. \nBtw, for codis, it would also block any write operation when migration. \n. @kouhate, maybe you are right.\nThis will be the optimization later, locking the key is not easy because I must check it in every write operations, this may be a huge work and cost time. \nI think another important thing for us is to verify the system (ledisdb + xcodis + redis-failover) can work well in production, and we can optimize the migration at the same time. \nI think porting people original redis data into this system is important too, I don't like codis's redis-port, so I decide to write a common one, redis-canal.\nBtw, I think codis/xcodis is not easy to use, would you give some advices on improvement? \n. Hi @kouhate , I just optimize migration, now it will not block other write problems, but only can be used safely with xcodis. I think it does not matter. \n. Hi @kouhate, for xcodis, if a slot n is in migration, e.g, from group1 -> group2, xcodis will handle every key in n, first migrate the key to group2, then do the write operation in group2, whether the key is in group1 or already in group2. \nSo I said the migration is only safe with xcodis now, because xcodis will guarantee the migration in group1, and write operation in group2. \n. redis-port is powerful but a little complex, and can not support ledisdb well, so I decide to develop redis-canal, syncing redis data into redis/ledisdb.\nI want redis-canal be a universal service, not only for xcodis. e.g, you can define your key routing rule and let redis-canal sync origin redis data into different places.\nBut I have not began to develop it, maybe this month. :-)\n. use xexists instead please. \n. Hi @jgoodall , it seems that go1.4 doesn't use cgo as default, you can see the news here https://golang.org/doc/go1.4, \"Unless cgo is being used to build the package, the go command now refuses to compile C source files\"\nThis may be a big problem for me, I use some c files too. I will see it tomorrow and think how to resolve it. \nThank you. \n. Hi @jgoodall, I think this is not the problem for ledisdb only, but also for any other projects using cgo too, for cross compile.\nI try to rebuild a linux go version using sudo CGO_ENABLED=1 GOOS=linux GOARCH=amd64 ./make.bash --no-clean and then compile ledisdb, but it still fails with below error:\n```\nruntime/cgo\nld: unknown option: --build-id=none\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n```\nI have no idea about how to fix it. LedisDB uses cgo in many places, not only in mdb. It may be a hard work to let it support cross compile. \nI think the only way now is to compile it in actual linux environment, not cross compile. :-)\nThank you. \n. go 1.3 seems not work too for cross compile.\nI think a better way is to adding a build flag for ledisdb to disable cgo for cross compile, if you don't want to use cgo, you can not use leveldb, rocksdb and lmdb as the backend storage, can not use lua, and can not use ledis-cli. \nBut I guess you may embed ledis into your own project as a package, so disabling above feature does not matter. \n. Adding a tag may be not hard, only need work. But you may know that LedisDB will use cgo as default, so if you want to use it, you may pass a tag in your own build, like go build -tags 'nocgo'. \nI will try later and check whether it can be ok for cross compile. \n. Hi @jgoodall, maybe you can use the latest master branch directly if you don't pass leveldb, rocksdb, lmdb, lua and linenoise into your build tags.\n. Hi @jgoodall , golang docker image is linux based, so you can use it for your linux compile. I think this may be a better way for cross compile, e.g. if you want to build a windows version, you can use a windows docker too. \nBtw, do you build successfully using cross compile with latest ledisdb code? \n. :smile: \n. Hi @zhibinr,  I have already merged your pr into develop branch. \nThank you. \n. use varint can support 2 ** 64 index, but it's too large, may be [0, 10240] or less\n. @kouhate, 1024 or 2048 may be enough, and I think zookeeper can save these with an acceptable performance. \nI hope I can support large index next week, then use it in xcodis. Next week another colleague will help me. So if you have any advice, please tell me.I hope we can improve the whole thing together. \n. Hi @kouhate, I have supported large db index in develop, and later I will support in xcodis. \nMaybe you can help me test it. Thank you.\n. Thanks @kouhate \nI know the connection pool problem and will fix it later, may be tomorrow. \n\nDo you intend to increase the number to 1024 or more? This implementation may have some inefficiency for a large number of dbs.\n\nAbove means the problem for zookeeper saving 1024 slots? \n. :smile: \nI think we can close this issue and move on.\n. Unlike redis lua, ledisdb's will not guarantee atomic script because other goroutine can do writing too. \n. Hi @adulau, now the ledisdb maximum set memeber size is 1024, you can not insert larger one.\nI know redis supports 512mb,  but I don't want to support so large member for performance.\nWe may change maximum set member below. \n//max set member size\nMaxSetMemberSize int = 1024\nBecause I use 2 byte to store member size in backend storage, so the maximum size is 65535.\nI would change  MaxSetMemberSize to a larger one, which is enough for many projects, maybe 10240?\n. Sorry that I forgot to enlarge this value for current release version. I will change this to a large value(maybe 1GB, like KV type) later. \nFor redis, the maximum value size is 512MB, and I think it's ok for most of us.Supporting too large value is not necessary. \n. \u8fd9\u4e2a\u53ea\u80fd\u53d6\u51b3\u4e8e\u4f60\u81ea\u5df1\u7684\u5224\u65ad\u3002\u6211\u4eec\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5b58\u50a8\u63a8\u9001\u6570\u636e\uff0csession\u7b49\uff0c\u800c\u4e14\u4e5f\u6709\u4e00\u4e9b\u670b\u53cb\u544a\u8bc9\u6211\u4ed6\u4eec\u4e5f\u7528\u4e8e\u4e86\u751f\u4ea7\u73af\u5883\uff0c\u4f46\u8fd9\u4e9b\u53ef\u80fd\u5bf9\u4f60\u6765\u8bf4\u6ca1\u6709\u4efb\u4f55\u5e2e\u52a9\u3002\nLedisDB\u73b0\u5728\u4ecd\u65e7\u662falpha\u7248\u672c(0.4 version release)\uff0c\u800c\u4e14\u6211\u73b0\u5728\u51e0\u4e4e\u6bcf\u5929\u90fd\u5728\u6539\u8fdb\uff0c\u5982\u679c\u4f60\u5bf9\u8fd9\u4e2a\u5f88\u5728\u610f\uff0c\u5efa\u8bae\u4f60\u4f7f\u7528couchbase\uff0credis\u6216\u5176\u5b83NoSQL\u3002\n\u8c22\u8c22\u3002\n. No, we have. \n. Hi @pyros2097 , cockroachdb is a distributed kv store, and I think it's too huge as a backend storage. \n. This seems a good idea for ledisdb, but I have no time to see cockroachdb code.\nBtw, we have used xcodis for cluster, redis-failover for tolerance. \nBut later, I want to build a cluster similar like elasticsearch or redis cluster architecture, maybe at that time, we can refer cockroachdb. \n. @ericnp, Any contribution is very welcome. :smile: \nI will support SHUTDOWN later. \n. Hi @ericnp , SHUTDOWN is supported now.\nI guess you want to change data_dir in runtime, this may be dangerous for ledis, because we need to handle lots of thing, like close storage or replication first, etc..... So config set is not proper for this.\n. Thanks @ericnp \nYou can contact me directly later, or in the github issue too. \n- Gmail: siddontang@gmail.com\n- Skype: live:siddontang_1\n. LedisDB supports listening unix socket, where other place?\n. @Leither ledis will use goleveldb and boltdb for default, and use go build tags for other storages, if you don't build with passing rocksdb, leveldb or lmdb tags, ledis will not build them. \nLater I will check whether build with not passing these flags will reduce the application size. \n. @Leither , in my mac osx, I do like yours above, but the application size reduces little. \n. Thanks @akhenakh , how about your data size in a size? only one?\nCould you show me your benchmark test case?\nzset uses an iterator which seeks to the first score 0 first, then one by one to the laster 99999999, if your size is big, this may be slow, especially for reverse range. \n. Thanks @akhenakh , I find the problem, here is the code for zrange:\n```\nnv := 64\nif count > 0 {\n    nv = count\n}\nv := make([]ScorePair, 0, nv)\n```\nhere count is 99999999, so make costs a very long time. Later I will use a default maximum count if possible.\n. I have fixed it, you can update the code and try again. :-\uff09\n. Hi @uchti \nCould you tell me why do you want to use sophia? Do LevelDB, RocksDB, LMDB or others not fit your need?\nI don't use sophia before, is its performance better than others? Has it some killer features? \n. Sorry that golua only supports lua 5.1 and I may deprecate lua feature later because it has many limitations.\n. You can only EVAL commands, the same as Redis EVAL, http://redis.io/commands/eval\nI don't find any good libs integrating lua in go, so this feature is just a try, I don't recommend you using it. \nThank you. \n. Btw, the developer for LedisDB is only me, so I don't have enough time to perfect documents. :-) \n. Thanks @felixbuenemann \nMaybe we can use building tag to distinguish 5.1, 5.2. \n. I think we should use two folder with different building tags and let outer determine which version to use. \nGodep doesn't handle package with building tags directly.\n. Thanks @felixbuenemann \n. Yes, this may be a danger, but I have not found a better way to solve it. Maybe later we can use a int64 for the list head and tail sequence, so it is nearly impossible that the list will exceed. \nBut this will let old user upgrade saved data. \n. In the backend storage, we will use a list meta size key, so LLEN is O(1) in LedisDB if the key in rocksdb cache, and O(lgN) if the key not in cache.\n. sorry, we use a meta key for list length and some other informations now. \nThe cache in RocksDB is LRU, so if you use this list frequently (Every write operations for list will change meta key), the meta key may be in cache all the time.\n. Sorry, I cannot give you the answer because I don't benchmark this scenario. \nThe best case for using LedisDB is that you have lots of data exceeding memory but only a few is be used at some time. \nIn my old product, a push server, I use list to store about 10,000,000 user messages (every user has maximum 20 messages), push messages to about 200,000 users at same time, it works well but I still think it has no reference. \n. Yes, saving all data in redis costs much $$, this is not cost-effective. In my opinion, we can use cluster solution if one machine can not hold the data size and request rate.\nBtw, I have been developing a distributed KV in our startup team, here https://github.com/reborndb, maybe you have some interests too.\n. This is my work, so I must build this :-) \nDon't care too much about the benchmark too, it has not be updated for a very long time. \n. CockroachDB is only KV, but does not support other redis data structure and commands. \nBtw, our team has also been building a distributed SQL based on coackroachdb too. :-)\n. I developed LedisDB in my spare time before I join my current team. And now I nearly has no time to improve it, badly!!!\n. RebornDB is redis compatibility, but LedisDB is not. So LedisDB may be faster than RebornDB. \nLedisDB is my personal product, but RebornDB is a company product, I think it may be more robust. (Btw, I am still confident that LedisDB can be used in production too!!!)\nLater, we will develop a really distributed system like Elasticsearch architecture which can re-shard data automatically and protect your data safely. \nIn the end of this month, we will release a beta version which will be used in some company (our customer :-) ), then we will release a stable version in August or September. \nOf course, the distributed version may not be ready at that time. So you may still care the whole cluster and do something like re-sharding with command tool manually. \n. Now we are developing code and don't know when to complete document, but I have add an issue here https://github.com/reborndb/qdb/issues/41, maybe next week.\nYes, RebornDB uses rocksdb, leveldb, goleveldb as the backend storage, but we will support more later. \n. I think you can create an issue in qdb, not here. \n. Now it is MIT, but I am not sure whether it will be changed later (I am not the co-founder:-) ).\nBut it will be open source forever.\n. Got it. :-)\n. LedisDB is written with go, and you can use a pure go backend storage like boltdb or goleveldb, so I think you can use it in windows. Btw, I have no windows environment so I can not tell you whether it is or not. \nLedisDB is not redis, with some differences, you must know that too. \n. Not fully compatible with Redis.\nThe build sciripts is only for linux and macosx, you can use go install ./... directly for pure go version.  :-)\n. You may use godep go install ./...\n. The godep will be installed in $GOPATH/bin, you must set this in your system $PATH or call godep with absolute command path like $GOPATH/bin/godep\n. Bad  news, windows has no this function. \nYou can first comment this line which has no affect. :-)\n. You can not build ledis-cli in windows, the same for redis-cli too, because they both use a linenoise lib which only be supported in linux and macosx. \n. Pardon? I don't know what you mean?\nI know that MS builds a portable redis version in windows, maybe including a redis-cli?\n.  maybe:\n- https://github.com/MSOpenTech/redis, build it and use redis-cli.exe for test\n- https://github.com/ServiceStack/redis-windows/tree/master/src/msopentech/redis-64.2.8.17, it has a redis-cli.exe, but I don't know whether it is ok or not in your system\n- write your own test with official redis library, like python, go, but it costs time. \n. Hi @spx, I just want to let ledisdb keep simple and don't rely on outer service like MySQL. \nIf MySQL is down, all services will not work too and I don't think using MySQL is faster than other local backend storage like RocksDB, but we need a benchmark for it. :-)\nBtw, supporting MySQL may be easy (I prefer plain sql and don't trust handlersocket) but I have no time now, sorry. \n. \u4f60\u76f4\u63a5\u53ef\u4ee5\u5b89\u88c5\u7eafgo\u7248\u672c\u7684ledisdb\uff0c\u4f7f\u7528 go install ./...\u5c31\u53ef\u4ee5\u4e86\uff0c\u9ed8\u8ba4\u4f7f\u7528\u7684goleveldb\u5f15\u64ce\n. \u4f60\u76f4\u63a5 go get github.com/siddontang/ledisdb\uff0c\u5e94\u8be5\u4f1a\u5728\u4f60\u7684$GOPATH/bin\u4e0b\u9762\u751f\u6210\u4e00\u4e2aledis-server\n. go install ./... \n. \u5982\u679c\u4f60\u6709godep\uff0c\u90a3\u5c31godep go install ./...\n. ledis-cli\u662f\u4e0d\u652f\u6301\u7684\uff0c\u56e0\u4e3a\u7528\u7684\u8ddfredis\u4e00\u6837\u7684cli\uff0c\u4e0d\u652f\u6301windows\uff0c\u4f60\u53ef\u4ee5\u8003\u8651\u7528\u4e00\u4e2awindows\u7f16\u8bd1\u597d\u7684redis cli\u6765\u6d4b\u8bd5\n\u53ef\u4ee5\u53c2\u8003\nhttps://github.com/MSOpenTech/redis\nhttps://github.com/ServiceStack/redis-windows/tree/master/src/msopentech/redis-64.2.8.17\n. :-)\n. ```\nimport \"github.com/siddontang/ledisdb/ledis\"\n l, _ := ledis.Open(cfg)\ndb, _ := l.Select(0)\ndb.Set(key, value)\ndb.Get(key)\n```\na simple example. :-)\n. I have already supported it. maybe another API?\n. @mmindenhall \nCould you send me a PR to support it?\n. Hi @clangley, I know some people and company have already used it in production, but I am still not sure whether it can be production ready or not.\nBut you can have a try, your feedback is very welcome for its improvement. Thank you :-)\n. :-) \nI am very surprised that I have been developing it for more than a year !!!\n. :-)\nThanks @linked , your feedback is the most motivation for me to improve it. \n. Hi @darshan-ghumare \nWhat's your GOPATH, GOROOT and  Go version?\n. Hi @darshan-ghumare , if you don't set GOROOT to your go installed path, you can not use the standard   package like encoding. \nledisdb is not in the correct path, e,g, the source must be in ${GOPATH}/src/github.com/siddontang/ledisdb, you can see the readme for more build and install information. \nThank you. \n. Hi @darshan-ghumare , if you install your go like /usr/local/go, do you do export GOROOT=/usr/local/go?\n. Hi @darshan-ghumare , /usr/lib/x86_64-linux-gnu/go/4.9/ doesn't seem a valid go root path, how do you install go? if you enter this path, what's the output for ls? do you see any \"src\", \"bin\" or \"pkg\" directory in it?\nyou can see more here https://golang.org/doc/install \nbtw, can you run any other go program?\n. Hi @darshan-ghumare \nledis-server is installed in your GOPATH/bin directory, look it here.\nlater I will change it to install in local bin directory. \n. :-) \n. We cannot support whole lua features like redis, btw, using lua in go has some limitations and we have to distinguish 5.1, 5.2 or even 5.3 later. \n. well, @pkieltyka , the newest boltdb may cause a deadlock, which it doesn't allow run both read and write transaction in a goroutine at same time, but in LedisDb, we have many places to do these things:\n```\nit := db.NewIterator()\ndefer it.Close()\n//iteration and use db.Delete to do something. \n```\nThis is ok with goleveldb/rocksdb/leveldb, and even lmdb, but not boltdb now. \nI have no time to fix this for boltdb now and I don't think its performance can beat rocksdb, maybe the best choice is to remove it.\nIf someone tells me they will use it in production, I may consider fixing it. \nBtw, I find a way to let rocksdb support transaction too, so later I can support begin, commit, rollback feature with rocksdb/leveldb/goleveldb. :-)\n. yes, the newest boltdb version will cause deadlock and I have no way to fix it now. \n. @mmindenhall \nIf boltdb starts a read only transaction, it will block any other write operations, and even more, if we do some write operations in read transaction, a deadlock occurs.\nNow the iterator implementation based on boltdb uses its read only transaction, and we do some write operations in some iterations, like\n```\nit := SeekFirst()\ndefer it.Close()\nfor it.Next() {\n    key := it.Key()\n    deleteKey(key)\n}\n```\nwe will meet deadlock using boltdb. We can solve this problem with refactoring all these codes, but I have no time to do it, sorry. \n. Hi @linked \nYou can not copy and sync this folder directly.\nLedis supplies ledis-dump and ledis-load command.\nYou can use ledis-dump to dump the snapshot into a file, sync to other place and use ledis-load to restore. \n. The mechanism depends on leveldb/rocksdb snapshot, so it doesn't block your service. \n. ok, I will fix it. \n. @pkieltyka \nthe first one is to control leveldb/rocksdb  synchronous writes, leveldb/rocksdb uses asynchronous writes default, we can use this config to let it how to do a synchronous write.\nthe second one is to control replication log how to be flushed to disk. \nI will add some docs later.\n. Seem a little slow, how about use smaller size like 1k or with rocksdb/leveldb?\n. 128k seems too large. 4k seems having an acceptable performance. \nI don't know why goleveldb has the terrible performance, I will check it again and contact the author. \nWhat's your scenario for data saving, if you have lots of data with big size (64k or 128k), I don't think ledisdb can fit your need. \nThank you. \n. Sorry that I don't know how to tune the IO.\nI see that you use hiredis APIs, do you use multi connections concurrently at same time, if you just only use one client, the performance is not good. \n. leveldb/rocksdb\u8fd9\u79cd\u7684\u4f1a\u6709\u9600\u503c\uff0c\u5f53\u8d85\u8fc7\u4e4b\u540e\u624d\u4f1a\u8fdb\u884ccompact\u5904\u7406\u3002\n. \u4e0d\u4f1a\uff0cLSM\u6a21\u578b\u662f\u4f7f\u7528\u7684\u6587\u4ef6\u8ffd\u52a0\u65b9\u5f0f\uff0c\u4f60\u7684\u4efb\u4f55delete\u64cd\u4f5c\u662fappend\u5230\u6587\u4ef6\u672b\u5c3e\u7684\uff0c\u800c\u4e0d\u662f\u76f4\u63a5\u53bb\u5bf9\u5e94\u7684\u4f4d\u7f6e\u5220\u9664\u3002\n\u53ea\u6709\u8fc7\u4e86\u76f8\u5e94\u7684\u9600\u503c\uff0c\u624d\u4f1a\u89e6\u53d1compact\u3002\n. \u8fd9\u4e2a\u4f60\u5177\u4f53\u770b\u4e0bleveldb\u6216\u8005rocksdb\u7684\u6587\u6863\u5427\uff0c\u5982\u679c\u7528\u7684default\u7684goleveldb\uff0c\u4e5f\u53ef\u4ee5\u770b\u4e0b\uff0c\u4e0d\u8fc7leveldb\u8c8c\u4f3c\u662f\u6539\u4e0d\u4e86\u7684\uff0crocksdb\u6216\u8005goleveldb\u80fd\u6539\uff0c\u90a3\u914d\u7f6e\u4e5f\u8db3\u591f\u4f1a\u8ba9\u4eba\u90c1\u95f7\u6b7b\uff0c\u592a\u591a\u4e86\u3002\n\u53e6\u5916\uff0c\u4e2a\u4eba\u611f\u89c9\u8fd9\u4e48\u70b9\u786c\u76d8\u635f\u8017\u5176\u5b9e\u4e0d\u5fc5\u592acare\u3002\n. Supporting it may be easy, but I have no time to develop it, sorry.\nSo it is very appreciated that you can send me a PR. :-) \n. Great :-) \n. Thanks @ukd1 \nNot supporting HTTP is ok. \n. Cool, Thank you very much! @ukd1 \n. :-) \n. @chenbaihu \nSorry, what's this?\n. What's your go version? or do you set your GOROOT, GOPATH correctly? \n. LedisDB is Go and SSDB is C++, I think this may be the biggest difference. :-)\nMost of these projects (not only LedisDB, SSDB, but also RebornDB, etc...) all use a fast key/value store like LevelDB or RocksDB as the backend storage, and use the similar way to emulate Redis's APIs. \n. There is no big different in inner implementation to support Redis APIs for LedisDB and SSDB. \nWhy I want to develop LedisDB but not use SSDB is that SSDB is not supported cluster, and SSDB is written by C++, which is hard to modify, at the same time, SSDB saves operation log in LevelDB for replication which I don't think it is efficient. \nLedisDB is written by Go, so you can learn it, modify it easily, some people who don't know Go can even send me a PR to improve it.\nUsing xcodis(a modified codis verion), LedisDB can support cluster.\nAnd I refer MySQL binlog to support LedisDB's replication. \nI think above is the biggest different. \nBtw, Go is not slower than C++, if you care much about performance, use SSDB. :-) \n. no, ledisdb is not redis, but you can try qdb\n. Thanks @felixbuenemann \nI knew that homebrew installs rocksdb/leveldb in /usr/local directly, why using /user/local/opt here? \n. Got it, but this is just for mac, not for other platform, should we check os in bash?\n. wrLock is for API and commitLock is for replication. \n. Thanks @FlamingTree \n. No, we don't support pipeline. \n. As you see above, you need buffer multi commands which is done by client, not server. \n. yes. server doesn't care how client sends commands, and handle them one by one. \n. hi @FlamingTree , as I knew, if the sync failed, slave will try another full sync later, if not, this may be a problem. \nof you can send slaveof instead to fix it?\n. \u53ef\u4ee5\uff0c\u76f4\u63a5\u5728config\u91cc\u9762\u914d\u7f6e\u3002\n. \u9700\u8981\uff0cmake\u7684\u65f6\u5019\u4f1a\u5e26\u4e0arocksdb\u8fd9\u4e2abuild tag\uff0c\u4e0d\u7136\u4e0d\u4f1a\u7f16\u8bd1rocksdb\u8fd9\u4e2apackage\n\u6216\u8005\u4f60\u624b\u52a8go build -tags \"rocksdb\"\uff0c\u524d\u63d0\u662frocksdb\u7684\u5b89\u88c5\u8def\u5f84\u8981\u5728linux\u6807\u51c6\u8def\u5f84\u91cc\u9762\uff0c/usr/local/include\u4ee5\u53ca/usr/local/lib\uff0c\u5982\u679c\u5982\u679c\u4f60\u662f\u7528homebrew\u8fd9\u4e9b\u5b89\u88c5\u7684\u5e94\u8be5\u80fd\u76f4\u63a5\u627e\u5230\n. \u5f97\u88c5rocksdb\uff0c\u56e0\u4e3a\u662f\u52a8\u6001\u5e93\n. \u8fd9\u660e\u663e\u662f\u7cfb\u7edf\u6ca1\u627e\u5230\u4f60\u8fd9\u4e2a\u52a8\u6001\u5e93\uff0c\u65b0\u5f00\u4e00\u4e2a\u4f1a\u8bdd\u518d\u8bd5\u8bd5\uff0c\u6216\u8005\u5f3a\u5236\u8bbe\u7f6e\u4e00\u4e0bLD_LIBRARY_PATH\uff0c\u53e6\u5916\uff0c\u4f60\u786e\u5b9alibrocksdb.so.4.2\u8fd9\u4e2a\u5728/usr/local/lib\u4e0b\u9762\uff1f\n. \u52a8\u6001\u5e93\u5bf9\u4e8e\u4efb\u4f55\u7a0b\u5e8f\u90fd\u4e0d\u65b9\u4fbf\u3002\n\u5728linux\u4e0b\u9762\u4f60\u4e5f\u53ef\u4ee5\u5c1d\u8bd5\u9759\u6001\u7f16\u8bd1rocksdb\uff0c\u8fd9\u6837\u5c31\u6ca1\u6709\u52a8\u6001\u5e93\u8def\u5f84\u7684\u95ee\u9898\uff0c\u4f46\u6211\u6ca1\u8bd5\u8fc7\uff0c\u4e0d\u4fdd\u8bc1\u80fd\u6210\u529f\u3002\n. Thanks @nathandao \n. Ledis\u4e5f\u4e0d\u662fredis\u5b8c\u5168\u517c\u5bb9\u7684\uff0cqdb\u662fredis\u517c\u5bb9\u7684\u3002\nLedis\u6bd4ssdb\u6162\uff0c\u4e3b\u8981\u539f\u56e0\u5728\u4e8ego\u6bd4c++\u8981\u6162\uff0c\u53e6\u5916\uff0c\u53ea\u8981\u4e0d\u662f\u6307\u6570\u500d\u6570\u7684\u5dee\u8ddd\u6211\u89c9\u5f97\u90fd\u53ef\u4ee5\u63a5\u53d7\u3002\n. \u4e3a\u4ec0\u4e48\u8fd9\u4e48\u6162\u5982\u679c\u4f60\u6709\u5174\u8da3\uff0c\u6b22\u8fce\u63d0PR fix\uff0c\u6211\u73b0\u5728\u6ca1\u6709\u65f6\u95f4\u53bb\u5f04\u8fd9\u4e2a :-) \n\u5bf9\u4e8eledis\u6216\u8005qdb\uff0c\u6211\u4eec\u73b0\u5728\u6ca1\u6709\u4efb\u4f55\u8ba1\u5212\uff0c\u592a\u5fd9\u4e86\uff0csorry\u3002\n. @mmindenhall \nI don't use etcd before, so I can't tell you whether feasible or not, but I don't think we will have a good performance even it can be. :-) \n. lmdb\u6ca1\u6709\u5220\u9664\uff0c\u53ea\u5220\u9664\u4e86boltdb\u3002\u4e0d\u8fc7lmdb\u73b0\u5728\u9700\u8981\u4f20\u5165lmdb\u8fd9\u4e2abuilding tag\u8fdb\u884c\u7f16\u8bd1\uff0c\u4f7f\u7528 make build_lmdb\u5373\u53ef\u3002\n. \u4e0d\u597d\u610f\u601d\uff0c\u6ca1\u660e\u767d\uff1f\nsnapshot\u53ea\u662f\u5e95\u5c42kv\u7684\u673a\u5236\uff0c\u5916\u9762\u9664\u4e86sync\u7684\u65f6\u5019\u4f1a\u7528\uff0c\u5176\u4ed6\u5730\u65b9\u4e0d\u4f1a\u7528\u7684\u3002\n. \u8fd9\u4e2a\u5916\u9762\u4e0d\u4f1a\u7528\u7684\uff0c\u53ea\u4f1a\u5728sync\u7684\u65f6\u5019\u7528\u5230\u3002sync\u4f1a\u5c06\u5f53\u524d\u7684snapshot\u5b58\u653e\u5230\u4e00\u4e2a\u6587\u4ef6\uff0c\u7136\u540e\u5728\u540c\u6b65\u3002\n. rosksdb\u662f\u53ef\u4ee5\u7684\uff0c\u56e0\u4e3a\u662f\u5b8c\u5168\u7684mvcc\u7684\uff0clmdb\u8c8c\u4f3c\u53ef\u4ee5\uff0c\u4e0d\u8fc7\u6ca1\u5b9e\u9645\u6d4b\u8bd5\u8fc7\u3002\n. LGTM\n. \u73b0\u5728\u6ca1\u65f6\u95f4\u5f04\u8fd9\u5757\uff0c\u6b22\u8fce\u63d0PR\u3002:-)\n. thanks @jan4984  I will check it later.\n. Hi @dg3feiko \nThanks for you attention, but now I have not time to do this (have to do lots of works for my job :cry: ), sorry. \nI will add it TODO. \n. @Leither Could you send me a PR directly. \nSorry for replying late. :-) \n. LGTM\n. score\u8fd9\u4e2a\u662f\u5386\u53f2\u9057\u7559\u539f\u56e0\u4e86\uff0c\u5f53\u65f6\u6ca1\u60f3\u5230\u4ec0\u4e48\u5f88\u597d\u7684\u529e\u6cd5\u5bf9float\u8fdb\u884c\u6392\u5e8f\u3002\n\u4e0d\u8fc7\u867d\u7136\u73b0\u5728\u6709\u529e\u6cd5\u4e86\uff0c\u4f46\u662f\u5982\u4f55\u5904\u7406\u9057\u7559\u6570\u636e\u53c8\u662f\u4e00\u4e2a\u95ee\u9898\uff0c\u800c\u4e14\u6ca1\u65f6\u95f4\u5f04\uff0c\u5c31\u4e00\u76f4\u653e\u7740\u4e86\u3002\nfloat\u6392\u5e8f\u7f16\u7801\u53ef\u4ee5\u53c2\u8003 https://github.com/reborndb/qdb/blob/master/pkg/store/util.go\n. \u73b0\u5728\u7684\u6539\u52a8\u53ef\u80fd\u4f1a\u6bd4\u8f83\u5927\uff0c\u63a5\u53e3\u8fd9\u4e9b\u7684\u5168\u662fint\u7684\u3002\n. \u6069\uff0c\u7b49\u6211\u5fd9\u5b8c\u4e86\u8fd9\u4e00\u6bb5\u65f6\u95f4\uff0c\u770b\u6709\u6ca1\u6709\u65f6\u95f4\u5b8c\u5168\u91cd\u6784\u5427\u3002\n. \u4f60\u7528\u7684\u5185\u5b58\u6570\u636e\u5e93\uff0c\u6570\u636e\u5168\u653e\u5185\u5b58\u7684\uff0c\u5185\u5b58\u4e0d\u4f1a\u964d\u7684\u3002\n. \u8fd9\u4e2a\u5c31\u8981\u770bgoleveldb\u5185\u90e8\u5177\u4f53\u600e\u4e48\u5b9e\u73b0\u7684\u4e86\uff0c\u53e6\u5916\uff0c\u4f60\u8fd9\u4e2a\u6570\u636e\u8fd8\u4e0d\u52301mb\uff0c\u6709\u70b9\u5c0f\uff0c\u4e0d\u8bb0\u5f97goleveldb\u7684cache\u662f4mb\u8fd8\u662f64mb\u4e86\u3002\n. lpush/rpush\u548clpop/rpop\u7528\u7684\u662f\u540c\u4e00\u5957\u4ee3\u7801\uff0c\u5185\u5b58\u6da8\u662f\u6da8\u4e86\u591a\u5c11\uff1f4mb\uff0c\u8fd8\u662f\u66f4\u591a\uff1f\n. \u5927\u6982\u77e5\u9053\u539f\u56e0\u4e86\uff0clpush/rpop\u7684\u903b\u8f91\u4f1a\u91cd\u7528index\u7684head/tail seq\uff0c\u6240\u4ee5\u6bcf\u6b21\u90fd\u662f\u5728\u5185\u90e8\u7528\u4e00\u4e2aseq\u4e0a\u9762\u64cd\u4f5c\u6570\u636e\uff0c\u4f46\u662frpush/lpop\u4f1a\u7528\u4e0d\u540c\u7684seq\uff0c\u4e5f\u5c31\u5bfc\u81f4\u4e86\u6bcf\u6b21\u90fd\u662f\u5220\u9664\u8001\u7684\u6570\u636e\uff0c\u7136\u540e\u63d2\u5165\u4e86\u65b0\u7684\u6570\u636e\uff0c\u5bfc\u81f4\u5e95\u5c42db\u4e00\u76f4\u5728compaction\uff0c\u7136\u540e\u4f60\u8fd9\u4e2a\u6d4b\u8bd5\u63d2\u5165\u592a\u5feb\u4e86\uff0c\u6839\u672c\u5904\u7406\u4e0d\u8fc7\u6765\u4e86\uff0c\u6240\u4ee5\u5185\u5b58\u66b4\u6da8\u3002\n\u8fd9\u4e2a\u4ee3\u7801\u903b\u8f91\u4e0a\u9762\u6ca1\u95ee\u9898\uff0c\u4f46\u662f\u9700\u8981\u4f18\u5316\uff0c\u4f46\u6211\u73b0\u5728\u6ca1\u65f6\u95f4\u5f04\u8fd9\u4e2a\uff0c\u53ea\u80fdtodo\uff0c\u8c22\u8c22\u3002\n. \u54e6\uff0c\u6240\u4ee5\u73b0\u5728\u6211\u4e5f\u4e0d\u786e\u5b9a\u4e3a\u5565\u4f1a\u5185\u5b58\u6da8\u4e86\uff0c\u4e3b\u8981\u662f\u73b0\u5728\u6ca1\u65f6\u95f4\u5f04\u8fd9\u4e2a\u3002\n@jan4984  \u4f60\u80fd\u4e0d\u80fd\u5e2e\u6211profile\u4e00\u4e0b\uff0c\u770b\u5185\u5b58\u5230\u5e95\u6d88\u8017\u5728\u4ec0\u4e48\u5730\u65b9\uff1fledisdb server\u53ef\u4ee5\u76f4\u63a5\u6253\u5f00pprof\uff0c\u4e0d\u8fc7\u5982\u679c\u4f60\u53ea\u662ftest\uff0c\u5c31\u9700\u8981\u624b\u52a8\u6ce8\u5165pprof\u7684\u4ee3\u7801\u4e86\u3002\n. LGTM\nThanks @felixbuenemann\nAfter @nikolay-turpitko test, I will merge this. \n. Hi @nikolay-turpitko , in my mac, running return will return \"return: can only return' from a function or sourced script\".  :-) \n. @nikolay-turpitko \nhow aboutfalse? can you help me test in linux?\n. @nikolay-turpitko \nwhat I mean is usingfalseinstead ofexit 1` like : \nif []; then\n   echo \n   false\nfi\nThis can work in my mac osx, how about in your linux system? \n. Hi @nikolay-turpitko \nCan you send me a PR for this? :-)\n. Hi @Aurlin \nHow do you install lua? does liblua.so not in the lua dir? \n. This is not a universal way for other users :-) \nMaybe this is a bug and we will try to fix it. \nHow do you install your lua? \n. Hi @nikolay-turpitko \nCan you send a PR to help me fix it? \n. \u6709\u4e2a\u7ebf\u7a0b\u904d\u5386\u5220\u9664\n. Cool @Aurlin \nI will check it later. \n. Hi @Aurlin \nI test in my mac and find it works. I will merge it. \nwe will re-discuss this if anyone meets compile error later :-)\nThank you. \n. LGTM\nThanks @nikolay-turpitko \n. Hi @nikolay-turpitko \nI think either bool or nil is ok, if redis returns bool, we can also return it too. :-) \nThank you.\n. Hi @nikolay-turpitko \nI see this PR supports bool, if yes, we can merge this. ok?\n. LGTM \nThank you @nikolay-turpitko \n. LGTM \nThank you @nikolay-turpitko \n. Thanks @nikolay-turpitko \nThis is just imported in #222, hi @Aurlin, can you help me test it again? \n. I knew that travis only had ubuntu, no other systems. \n. LGTM\n. ok\n. no plan. \n. \u4e3b\u8981\u662frocksdb\u81ea\u5df1\u6ca1\u6709\u673a\u5236\u80fd\u652f\u6301\u590d\u6742\u7684\u4e8b\u52a1\u3002\n\u8b6c\u5982\uff0c\u4f60\u5199\u4e86\u4e00\u4e2a\u6570\u636e\uff0c\u8fd8\u6ca1\u63d0\u4ea4\uff0c\u8fd9\u65f6\u5019\u53c8\u60f3\u7528iterator scan\u5230\u8fd9\u4e2a\u6570\u636e\uff0crocksdb\u4e0d\u652f\u6301\u8fd9\u79cd\u7684\u3002\n. \u4e0d\u652f\u6301\u8fd9\u4e2aapi\uff0c\u4f7f\u7528xscan\u6279\u91cf\u67e5\n. the config ExpiredLogDays is 0, not valid. maybe you can set 1 first. \n. \u8fd9\u79cd\u7684\u505a\u6cd5\u662fnew store\u7684\u65f6\u5019\u9700\u8981\u7edf\u4e00\u7684\u53c2\u6570\u63a5\u53e3\uff0c\u5c31\u8ddfgo sql\u4f7f\u7528\u7684dsn string\u4e00\u6837\uff0c\u4f46\u8fd9\u8fb9\u8c8c\u4f3c\u662f\u4e0d\u540c\u7684\u3002\n\u53e6\u5916\uff0c\u4e5f\u6ca1\u518d\u8003\u8651\u8fc7\u52a0\u65b0\u7684engine\u4e86\uff0c\u7ef4\u62a4\u6210\u672c\u592a\u5927\u3002\n\u5982\u679c\u4f60\u6709\u597d\u7684\u65b9\u6848\uff0c\u6b22\u8fcePR\u3002\n. LedisDB is in valid gopath? \nI don't use in go 1.6 now, why does godep not search godep path? \n. ok, ledisdb now doesn't support vendor, I will support it later then I can remove godeps.\n. Maybe we should fire an issue to go lmdb, or can you help me solve it? \nI have not enough time now. \n. Or you can skip LMDB now. \n. Ok, I will find a time to upgrade to go 1.6. \n. Thank you @nii236 \n. Now I have no time to do it, I will try to improve it later. \n. Hi @agnibha \nI don't test with pre-filled before. \nSorry that I don't understand your scenario exactly? if you want to use origin ledisdb's data in xcodis, I think not ok, maybe you should do a dump + load. \n. We can't use xcodis with origin ledisdb data directly, because xcodis will hash key to different db with index = hash(key) % 1024.\nSo maybe you save a data in db 0 in ledisdb, but it will be passed to db n in xcodis. \n. maybe yes, but this may only work if you have one ledisdb. \n. Sorry, none. \nCodis has a tool redis-port which can do this, but now ledisdb doesn't support redis replication.\n. LedisDB is not redis, only uses its protocol.\nIf you want to find a compatible one with redis, qdb(https://github.com/reborndb/qdb) may be ok. \n. Hi @tigranbs \nMaybe ledisdb uses a lower version lib which your gopath has too, which lib? \nI will update ledisdb with new vendor feature (go 1.5+) but have no time to do it now, sorry. \n. Go 1.6 can't compile LMDB package now,we should wait the package fixes it first or choose another proper one. \n. Cool, but I have no time to embed it now, very busy in this month. \ud83d\ude2d \n. ulimit -n and set a bigger one maybe. \n. LGTM\n. I think LREM is hard to support in ledisdb, as you see, we save list like key:1 -> a, key:2 -> b, key:3 -> c, if we delete b, we will update all following items' key, so origin key:3 -> c may key:2 -> c.\n. Seem no problem, but as you see, if the list is too huge, we may meet a very big performance problem. \n. Thanks, can you send me a PR?\n. hi @pkieltyka \nNow we use vendor in cmd folder like etcd does\n. Hi @pkieltyka \nThe vendor use is from etcd, see https://github.com/coreos/etcd/tree/master/cmd\nIf we put vendor in ./vendor, other use ledisdb as library will import this vendor too. \nI will fix the compile errors later. \n. Hi @pkieltyka \nWhat's the compile error? I use 4.11 but it's ok.\n. @pkieltyka \nDynamic linking is not convenient, maybe we can use https://github.com/cockroachdb/c-rocksdb instead. \n. @baotiao \u505a\u5e7f\u544a\u4e0d\u5e26\u8fd9\u6837\u7684\u3002\u3002\u3002\n. \u4efb\u4f55SST\u67b6\u6784\u7684\u90fd\u6709\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u76f8\u6bd4\u4e8eleveldb\uff0crocksdb\u6709\u4e00\u5806\u53c2\u6570\u53ef\u4ee5\u8c03\uff0c\u80fd\u7a0d\u5fae\u7f13\u548c\u4e00\u4e0b\n. Hi @let4be \nRedis is single-thread, so it can easily support atomic and execute batch commands in a single step. LedisDB is multi-thread, so it can't guarantee any atomic for batch executions. \n. you must build ledisdb with rocksdb tag, what does your make build output?\n. go build -tags \"rocksdb\" main.go\n. Here is the error for linux can't find the rocksdb, you can goole to solve it, not ledisdb problem. \nI suggest adding rocksdb to your LD_LIBARARY_PATH or installing rocksdb in common /user/local/lib so linux can find it directly.\n. don't use ssh clone, use https clone.\ngit clone https://github.com/siddontang/ledisdb.git\n. \u94c1\u5b9a\u4e0d\u652f\u6301 1PB\uff0c\u5355\u673a 1TB \u53ef\u80fd\u5c31\u662f\u6781\u9650\u4e86\u3002\n\u6709\u4eba\u8ddf\u6211\u8bf4\u5728\u751f\u4ea7\u73af\u5883\u7528\u8fc7\uff0c\u4f46\u6211\u6ca1\u7ec6\u95ee\u516c\u53f8\u3002\n. \u6ca1\u8bd5\u8fc7\u8fd9\u4e48\u5927\u96c6\u7fa4\u91cf\u7684\uff0c\u4e0d\u4fdd\u8bc1\u80fd\u6b63\u5e38\u5de5\u4f5c\u3002\nledisdb + xcodis \u624d\u662f\u96c6\u7fa4\uff0c\u4f46\u73b0\u5728\u6211\u4e5f\u6ca1\u7cbe\u529b\u53bb\u7ef4\u62a4 xcodis \u4e86\uff0c\u53e6\u5916\uff0cledisdb \u6709\u4eba\u7528\u5728\u751f\u4ea7\u73af\u5883\uff0c\u4f46\u6211\u4e0d\u6e05\u695a xcodis \u6709\u6ca1\u6709\u3002\n. xcodis \u6570\u636e\u5b58 zookeeper\uff0cxodis \u8fd9\u4e2a\u9879\u76ee\u5df2\u7ecf\u6ca1\u7cbe\u529b\u7ef4\u62a4\u4e86\uff0c\u98ce\u9669\u81ea\u63a7\n. \u8c8c\u4f3c\u6ca1\uff0c\u4e0d\u8fc7\u901a\u5e38\u522b\u592a\u5927\uff0c\u5e95\u5c42 rocksdb \u5bf9\u5927 value \u7684\u6027\u80fd\u5176\u5b9e\u4e0d\u597d. If we meet OOM, the data is still here because backend engine (rocksdb/goleveldb) can guarantee this. . There is no own library, you can use any current library. I think redigo is ok too :-) . Seem that you use two processes to handle the same directory? If yes, it is ok because goleveldb/rocksdb can only allow one process at one time.\nIf not, there is a bug. . @ascotan \nYou open two different ledis instances, and of course, this can not work. \nWhen you create the server, you can use server.App Ledis() function to get a ledis  instance. . @frankxieke \nI don't remember now, seem the lock is to guarantee the replication safety. . seem that I must upgrade go version and all dependences.\nI will do it later if I have time. . what does your ulimit -n output? . Does other ledis open the same folder? . what I mean is if your ledis-server is still running at same time, you can't use ledis-load for the same data path. . Because ledis-server has already locked the data path. . ledis-server will lock the path, the backend engine rocksdb does it automatically to avoid other process accessing the data. \nyes, you can dump with one engine and then load to another engine, but I don't test it fully. . @unoexperto \nBitmap is treated as KV, you can not scan it directly. \nFor scan KV, you can use XSCAN KV SCAN cursor [MATCH pattern] [COUNT count] . LedisDB is written by Go and pika is with C++.\nBtw, pika is written by my friend, so I list it in my project. . \u73b0\u5728\u6ca1\u652f\u6301\u8fd9\u4e48\u65b0\u7684 rocksdb\uff0c\u540e\u9762\u6709\u65f6\u95f4\u6211\u5347\u7ea7\u4e00\u4e0b. go build \u7684\u65f6\u5019\u5e26\u4e0a\u4e86 -tags rocksdb \u4e86\u5417\uff1f \u4f60 make \u7684\u65f6\u5019\u8f93\u51fa\u8f93\u51fa\u662f\u600e\u6837\u7684\uff1f. 4.13, 5.0+ \u7684\u4e00\u4e9b API \u6539\u4e86\uff0c\u6ca1\u6cd5\u517c\u5bb9\u3002\u8fd9\u4e2a\u6211\u540e\u9762\u8003\u8651\u7528 https://github.com/tecbot/gorocksdb \u7684\u9759\u6001\u7f16\u8bd1\u6765\u89e3\u51b3\u4e0b\u8fd9\u4e2a\u95ee\u9898. \u8fd9\u4e2a\u4e0d\u6e05\u695a\uff0c\u4f60\u53ef\u4ee5\u91cd\u65b0\u5728\u8bbe\u7f6e\u4e00\u4e0b  GOPATH \u5427. Hi @daddyz \nIt seems that goleveldb is stall, maybe you know that for the LSM DB (RocksDB, goleveldb), when the mem table is full, it will flush the mem table to level 0 SST files, but when the level 0 SST file number reaches a limit, it will slow or stop the write. I guess this is the problem here.\nWhat's your IO until when slow begins? could you see it with iostat ? \nFor TTL, because restore is to load raw Key-Value data into DB one by one, so it can be loaded later. \nBtw, I will try to upgrade all goleveldb, leveldb, rocksdb version, but have no time now, very sorry. . rocksdb \u6570\u636e\u76ee\u5f55\u91cc\u9762\u6709\u81ea\u5df1\u7684 LOG\uff0c\u53ef\u4ee5\u770b statistics\n\u73b0\u5728\u6ca1\u6709 qps \u7edf\u8ba1. \u56e0\u4e3a\u4f60\u53ef\u80fd\u4e4b\u524d\u52a0\u4e0a\u4e86 -tag=leveldb \u7f16\u8bd1\u8fc7. Hi @charl \nAny log in current new master and slave. Is master sending snapshot to the slave? . Sorry for the late response, @charl \nAny sync log message in the log file? Can you show me the log?\nHow about run fullsync in the slave, can it still work? \nSincerely, the replication code is very ugly and I have to consider to refactor it all.\n. oh, bad news. \nI will see it later. . Hi @charl \nI use the newest master but can't reproduce this error. Do you have any old replication data? . \u4f60\u662f\u4e0d\u662f\u624d\u5347\u7ea7\u8fc7\uff0c\u6211\u521a\u53d1\u73b0 repliaction \u7684\u6570\u636e\u65b0\u65e7\u7248\u672c\u4e0d\u517c\u5bb9\u4e86\u3002\u3002\u3002. nohup \u90a3\u4e2a\u95ee\u9898\uff0c\u4f60\u662f\u4e0d\u662f\u76f4\u63a5\u5728 console \u63a7\u5236\u53f0\u542f\u52a8\u7684\uff0c\u7136\u540e\u5173\u95ed\u4e86 session\uff1f\u5982\u679c\u662f\u8fd9\u6837\uff0c\u5f88\u6709\u53ef\u80fd\u4e5f\u4f1a\u5173\u6389 nohup \u542f\u52a8\u7684\u3002\u4f60\u53ef\u4ee5\u5c06 nohup \u547d\u4ee4\u653e\u5230\u4e00\u4e2a\u811a\u672c\u6587\u4ef6\u91cc\u9762\u6267\u884c\u3002. \u7b2c\u4e8c\u4e2a\u6211\u5e94\u8be5\u5df2\u7ecf fix \u4e86\uff0c\u4e0d\u8fc7\u4f60\u7684\u5907\u4efd\u6570\u636e\u53ef\u80fd\u5df2\u7ecf\u574f\u4e86\uff0c\u4fdd\u9669\u8d77\u89c1\uff0c\u53ef\u4ee5\u5c06\u6240\u6709 master \u548c slave \u7684 rpl \u76ee\u5f55\u4e1c\u897f\u5168\u90e8\u5220\u9664\uff0c\u7136\u540e\u5728\u91cd\u65b0\u542f\u52a8\u96c6\u7fa4\u4e86\u3002\u3002\u3002. del 1000 \u4e4b\u540e\u5728 get 1000 \u770b\u770b\u5462\uff1f\u4f1a\u4e0d\u4f1a\u662f\u4f60\u76f4\u63a5\u540c\u6b65\u6570\u636e\u7684\u65f6\u5019\u51fa\u4e86\u95ee\u9898\uff0c\u56e0\u4e3a\u4e4b\u524d\u6709 bug\u3002\u3002\u3002. \u4e4b\u524d\u9519\u8bef\u7684\u540c\u6b65\u5bfc\u81f4\u7684\u95ee\u9898. \u73b0\u5728\u53ea\u80fd\u6539\u6e90\u7801\u91cd\u65b0\u7f16\u8bd1\u3002\u3002\u3002\n\u4f60\u53ef\u4ee5\u6dfb\u52a0\u4e00\u4e2a config structure . rocksdb\uff0cleveldb \u5e95\u5c42\u8fd9\u79cd\u5bf9\u4e8e\u5927 value \u7684\u6027\u80fd\u582a\u5fe7\uff0c\u5c24\u5176\u662f\u6570\u636e\u91cf\u5927\u7684\u65f6\u5019\uff0c\u5199\u653e\u5927\u7279\u522b\u4e25\u91cd\uff0cIO \u9876\u4e0d\u4f4f\u7684\u3002. \u5982\u679c\u4f60\u7684\u9700\u6c42\u662f\u5927 value\uff0c\u8fd8\u4e0d\u5982\u7528 kv \u5b58 meta\uff0c\u4f60\u7684 value \u76f4\u63a5 append \u5230 file. Thanks @josephlewis42 \nCan you send me a PR?. Hi @GlenDC \nIt is great if we can use pure GO LUA implementation. But I have no time this week, will see it next weekend. \nYou can send me a PR too. Thanks. . Thanks @GlenDC . +1 @robvanmieghem :-)\nIt is appreciated that you can send the PR. . Cool @GlenDC \nDo you use make update_vendor to re-update the dependency? seem that some needless files are introduced in vendor.  . Thanks @GlenDC \nSeem that Go Lua is more easy to use. \nRest LGTM. Thanks @GlenDC\nI still want to use \"127.0.0.1:2380\" for the server by default, but now the default config address is empty, maybe we can set it explicitly after https://github.com/siddontang/ledisdb/blob/master/cmd/ledis-server/main.go#L42. \n. Hi @GlenDC\nLike redis using 2379 as the default port, I prefer using 2380 for ledisdb server. For a server, using a random port to start may be strange. :-). Aha @GlenDC \n2379 and 2380 are the default port for etcd, I am wrong. :-). Hi @GlenDC @robvanmieghem \nFor another config like \"UseFreeLocalAddress\", maybe we can use toml:\"-\" to ignore this field explicitly.\nI think this change is ok for me now, I will merge it. Thank you. \n. LGTM\nThis seems to a typo for me :-). . I will close it because badger won't support snapshot now. . Hi @palamccc \nHave the plan, but now short of time, maybe later to rewrite whole code. . No, ledisdb is not redis :-) . @islamTaha12 \nNo way now, RocksDB, LevelDB don't support this too.. Thanks @muhamadazmy \nUpgrading the toml library can solve the problem? If yes, I will upgrade it. . Thanks @muhamadazmy \nDoes the latest https://github.com/BurntSushi/toml fix this problem, if yes, we can upgrade it directly?. Hi @muhamadazmy \nNow we use glide to manage the vendor.\nYou can update this in the glide.yaml (removing origin TOML, add new one)  and run make update_vendor which will clean up the imported test file. . LGTM\nThanks @muhamadazmy . Do, but we can re-consider it with newest RocksDB later. . Yes, I have discarded it because the backend engine (leveldb, goleveldb) doesn't support the transaction.\nRocksDB now supports it, but I have no time to re-support this feature now. . @justinfx \nI've not known goleveldb now supporting the transaction, it is very cool, but I worry about the performance. Maybe RocksDB may still be the best choice. \nAnother choice is to introduce badger which supports transaction too. \n. @justinfx \nAs sad as I know, even we use memory mode for goleveldb(maybe latest version has fixed this, but I don't know), it still needs to operate files because of WAL. So now I have been searching a really pure memory implementation. :-). \u76f4\u63a5 import ledis \u5305\u5c31\u53ef\u4ee5. https://github.com/siddontang/ledisdb#package-example. Hi @digipigeon \nI suggest using go profile or perf to see which one costs the most CPU, or do you use top -H to see the CPU? I guess maybe RocksDB is compacting in the background after you insert too many items. . Hi @digipigeon \nSET and LPUSH are two different operations, and I think SET is much faster than LPUSH. I think the problem still exists for LPUSH, I will see it later.. Hi @FreedomMatrix2015 \nsee https://github.com/siddontang/ledisdb/issues/296\n. rocksdb \u6709\u4e00\u4e2a c-rocksdb\uff0c\u4f46\u6211\u8fd8\u6ca1\u6d4b\u8bd5\u8fc7\uff0c\u5982\u679c\u53ef\u4ee5\uff0c\u540e\u9762\u53ef\u4ee5\u76f4\u63a5\u7528\n\u4f46 leveldb \u6211\u6ca1\u627e\u5230\u8fc7. \u4e0d\u662f. Aha, I forgot to renew it. . Done. @CocaCola183 \nLedis don't load data to memory.\nDo you use RocksDB engine? Can you give me the LOG of RocksDB and ledis's log?. leveldb will have a LOG in the leveldb data path.. Not supported yet. Maybe it is easy, but I have no time to do it now, sorry.. Thanks @muhamadazmy \nI think I have found the concurrent problem. I will explain briefly.\nFor BRPop, the flow (we will use a for the flow here) is \n\nTry to pop the list, if pop one, return directly\nIf the list is empty, add a signal handler to the pop key.\nWait for the signal.\n\nFor LPush, the flow (b) is\n\nPush the list\nIf the key has an associated signal handler, signal it.\n\nSo the concurrent problem may happen at https://github.com/siddontang/ledisdb/blob/master/ledis/t_list.go#L791\nThe flow is a1 -> a2 -> b1 -> b2 -> a3 \nAs you can see, if we can't notify the chan, we will ignore it directly, this may cause b3 wait forever.\nMaybe the simplest way to fix is to change https://github.com/siddontang/ledisdb/blob/master/ledis/t_list.go#L695 with ch := make(chan []byte), len(keys)), can you help me to check whether it works or not? . Hi @GlenDC \nWe don't support exists for hash key, you should use hkeyexists instead. \nhttps://github.com/siddontang/ledisdb/wiki/Commands#hkeyexists-key. @GlenDC \nFor performance, if we must keep compatibility with redis to support these function, we must use another key to save the type of the data. E.g, if we want to support exists, so for a key foo, how do we know the real type? We must save a key foo -> string or foo -> hash in the backend engine. \nBut as you see, saving another key in the write command can cause performance reduction especially when you only do set key value. . But if you really want to keep compatibility, it is not hard to do. RebordDB and pika also do this, and we can support it too.. Thanks @muhamadazmy \nBut CI failed, I have to see why causes the failure. . @muhamadazmy \nThe failed CI may be caused by https://github.com/siddontang/ledisdb/blob/master/ledis/t_list_test.go#L218\nEven we sleep for 100ms, the goroutine may still be not started yet because travis CI is slow. Can you enlarge the sleep time, like 1 second, to see whether we can pass the CI or not.. Thanks @muhamadazmy \nI will see it.. ok @muhamadazmy \nI will try it later. :-). CI still failed :sob:. Hi @muhamadazmy \nI find the reason of the failed test, you can't call lock and unlock at the beginning of the function popOrWait, which may cause deadlock, a better way is:\n```\nfunc (l lBlockKeys) popOrWait(db DB, key []byte, whereSeq int32, fn context.CancelFunc) ([]interface{}, error) {\n    v, err := db.lpop(key, whereSeq)\n    if err != nil {\n        return nil, err\n    } else if v != nil {\n        return []interface{}{key, v}, nil\n    }\nl.Lock()\n\ns := hack.String(key)\nchs, ok := l.keys[s]\nif !ok {\n    chs = list.New()\n    l.keys[s] = chs\n}\n\nchs.PushBack(fn)\n    l.Unlock()\nreturn nil, nil\n\n}\n```. Thanks @muhamadazmy \nI think we can remove \"golang.org/x/net/context\" and use standard context library directly. \nAnd we should update the go version in travis CI, maybe  1.8 is fine. . Thanks @muhamadazmy \nNow the lua vendor also uses the context, we can still use it, no need to upgrade now.. rocksdb \u8fd9\u79cd\u7684\u5e76\u4e0d\u662f\u7acb\u523b\u5220\u9664\uff0c\u8981\u7b49\u5230 compaction \u7684\u65f6\u5019\u624d\u4f1a\u5220\u9664. I only support migrating from redis to ledisdb, so maybe you should write yourself. . \u6ca1\u660e\u767d\u4e0d\u518d\u589e\u957f\u7684\u610f\u601d\uff1f\u662f\u6570\u636e\u63d2\u5165\u4e0d\u8fdb\u53bb\uff1f. Thanks @GlenDC . \u4f60\u7684\u5185\u5b58\u7528\u91cf\u53d6\u51b3\u4e8e rocksdb cache \u914d\u7f6e\u7684\u5927\u5c0f\uff0c\u9700\u8981\u770b\u4e0b\u8d85\u8fc7\u4e86 rocksdb \u7684 cache \u4e4b\u540e\uff0c\u5185\u5b58\u8fd8\u4f1a\u4e0d\u4f1a\u4e00\u76f4\u4e0a\u6da8. \u65b9\u4fbf\u63d0\u4f9b\u4e0b\u4f60\u7684\u6d4b\u8bd5\u4ee3\u7801\u4e0d\uff1f\n\u4e5f\u63d0\u4f9b\u4e0b\u4f60\u7684\u914d\u7f6e\u6587\u4ef6. \u4f60\u7684 rocksdb \u914d\u7f6e\u5462\uff1f\u4e0a\u9762\u8d34\u7684\u662f leveldb \u7684\n\u5185\u5b58\u6da8\u5230\u591a\u5c11\uff1f. > \u538b\u6d4b\u7684\u7a0b\u5e8f\u662f\u662f\u7528golang \u7684redis\u9a71\u52a8\u5199\u7684\uff0c\u4e0d\u65b9\u4fbf\u63d0\u4f9b\uff0c\u6d89\u53ca\u4e86\uff0c\u5177\u4f53\u6570\u636e\u683c\u5f0f\uff0c\u57fa\u672c\u5c31\u662fhset \u548chdel \u6570\u636e\uff0c\u4f46\u662fkey\u4e2d\u7684filed\u6240\u5bf9\u5e94\u7684\u6570\u636e\u5927\u5c0f\u6bd4\u8f83\u5927\uff0c\u5927\u6982value\u7684\u5927\u5c0f\u662f78kb\u5b57\u7b26\u4e32\u3002\u5f00500goroutine\u8fdb\u884c\u538b\u6d4b\u3002\n\u4f60\u5982\u679c\u53d1\u73b0\u5185\u5b58\u4e00\u76f4\u4e0a\u6da8\uff0c\u7136\u540e\u505c\u6389\u6d4b\u8bd5\u4ee3\u7801\uff0c\u5185\u5b58\u4f1a\u4e0d\u4f1a\u964d\u4e0b\u6765\uff0c\u4f60\u8fd9\u4e2a\u6570\u636e\u91cf\u592a\u5927\uff0c\u5f88\u53ef\u80fd GC \u5fd9\u4e0d\u8fc7\u6765\n\u4f60\u53ef\u4ee5\u5728\u542f\u52a8 ledis server \u7684\u65f6\u5019\u4f20\u5165  --pprof=true\uff0c\u7136\u540e\u770b\u770b curl http://ip:6060/debug/pprof/heap \uff0c\u8fd9\u6837\u5c31\u80fd\u77e5\u9053\u5177\u4f53\u7684 heap \u60c5\u51b5. \u4f60 redis cli \u5982\u4f55\u83b7\u53d6\u6570\u636e\u7684\uff1f. \u5728 redis cli \u91cc\u9762\u5177\u4f53\u547d\u4ee4. get setkey \u5462\uff1f. \u5ba2\u6237\u7aef\u4ee3\u7801\uff1a\ncfg := lediscfg.NewConfigDefault()\ncfg.Addr = \"xxx.xxx.xxx.xxx:7380\"   //xxx.xxx.xxx.xxx \u5185\u7f51\u67d0\u53f0\u673a\u5668ip\u5730\u5740\nl, err := ledis.Open(cfg)\ndb, err1 := l.Select(0)\nfmt.Println(err1)\n\u4f60\u4e3a\u5565\u76f4\u63a5 ledis open \u800c\u4e0d\u662f\u7528\u7684\u4e00\u822c\u7684 redis client\uff1f ledis open \u4f1a\u6253\u5f00\u4e00\u4e2a\u672c\u5730\u7684 db\uff0c\u8ddf\u4f60\u7684\u8fdc\u7aef\u6ca1\u5565\u5173\u7cfb\u3002\n\u4f60\u76f4\u63a5 redis-cli \u8fde\u4e0a\u53bb\uff0cset \u4e00\u4e0b\uff0c\u770b\u80fd\u4e0d\u80fd get\n. @c2h5oh \nI think we can pin after #325 . LGTM. Thanks @c2h5oh . PTAL @c2h5oh. LGTM. Thanks @csjc008 \nPlease send me a PR to fix it.\n. Thanks @benjafire \nCan we send me a PR? . oh, do you use make test to build it?. Thanks @nim-nim \nI will re-test with 1.10 and fix the problem later, maybe this week.\nOr can you help me fix this?. Amazing, seem Go 1.10 breaks many packages.... LGTM @benjafire . hi @mstory21 \nCan you tell me where the bottleneck?\n\nScanning all data from the RocksDB snapshot and writing to a file\nSync to the slave\nApply the snapshot to the slave\n\nI guess step 3 may take a long time, is it?. so the bottleneck may be the compression? if yes, maybe we should use a config to control it.. LedisDB will use snappy in full dump.. Thanks, @mstory21 \nI must re-browse whole codes to figure it out, maybe I will refactor all soon. . Thanks @mstory21 \nSorry that I have no time to improve replication, I have to re-think and re-browse the whole codes to remember why I did this before. \nI will refactor the whole replication later, maybe break the compatibility. . can you send me a PR? @mstory21 . LGTM. oh, does the slave fall behind the master?  Every time you insert a member, the slave can't see it?. hi @mstory21 \nDo you mean that the data can be eventually consistent? If yes, seem this the problem of the speed of async replication, and it certainly exists. Maybe we should think how to speed up it.. Thanks @mstory21 \nBut it is better to send a PR to goredis, and then update the vendor here.. Hi @Xeoncross \nSorry for the late reply, I am very busy these days.\nYour case is very interesting, I have never thought about it. Using Sets is a way, or maybe we can use Lists, E.g.:\nlat:32 -> lng list\nlat:33 -> lng list\nYou can use 360 items or more in one list. Each item represents one longitude. E.g, the first item is lng:-180, ... lng:0, ... lng:180\nSo if you want to search an area, you can call Redis List LRANGE for each latitude, get all objects and union them all in your program.\nBut I can't say which way is better. :-). oh, forget to renew \ud83d\ude2d . hi @rfyiamcool \nnot atomic, unlike redis, ledisdb is multi-thread, and allows other goroutines still operates the data. . 1. can you provide the test code?  HMget is for hash, for for list. \n2. No plan now\n3. One is Go vs C++, the other may B+ Tree vs LSM. . @unisqu \nA simple change, which can pass compile and print the hash.\n```go\npackage main\nimport (\n    //      \"crypto/md5\"\n//      \"encoding/gob\"\n//      \"flag\"\n\n\"fmt\"\n\"net/http\"\n\"strconv\"\n\"time\"\n\nlediscfg \"github.com/siddontang/ledisdb/config\"\n\"github.com/siddontang/ledisdb/ledis\"\n\n)\nvar cfg = lediscfg.NewConfigDefault()\nvar fcachel, _ = ledis.Open(cfg)\nvar fcachedb, _ = fcachel.Select(0)\ntype FVPair struct {\n    Field []byte\n    Value []byte\n}\ntype FCacheItem struct {\n    s int\n    h []byte\n    c []byte\n    t int\n}\nfunc GetFCache(urlhost string, urlreq string) (int, http.Header, []byte, int) {\nhash, _ := fcachedb.HMget([]byte(urlhost), []byte(\"c\"+urlreq), []byte(\"h\"+urlreq), []byte(\"t\"+urlreq), []byte(\"s\"+urlreq))\n\nfor k, v := range hash {\n    fmt.Printf(\"Key : %q, Value : %q\\n\", k, v)\n}\n//as the above doesn't show anything, i don't know how to return anything\nreturn 0, nil, nil, 0\n\n}\nfunc SetFCache(urlhost string, urlreq string, statuscode int, qwcache []byte, htmlcode []byte) {\n/*\n   db, _ := l.Select(0)\n   key := []byte(\"test\")\n*/\n\n//I'm not sure if it's working or not for the set function. seems to work with default goleveldb storage but i would like it to be in RAM\ntimeNow := int(time.Now().UTC().Unix())\n\nc := ledis.FVPair{Field: []byte(\"c\" + urlreq), Value: []byte(htmlcode)}\nh := ledis.FVPair{Field: []byte(\"h\" + urlreq), Value: []byte(qwcache)}\nt := ledis.FVPair{Field: []byte(\"t\" + urlreq), Value: []byte(strconv.Itoa(timeNow))}\ns := ledis.FVPair{Field: []byte(\"s\" + urlreq), Value: []byte(strconv.Itoa(statuscode))}\n\nfcachedb.HMset([]byte(urlhost), c, h, t, s)\nexpirefc := 100\nfcachedb.HExpire([]byte(urlhost), int64(expirefc))\n\n}\nfunc main() {\n    cfg.DBName = \"RAM\"\n//Basically this is what I would like to achieve with RAM. only RAM and nothing else.\n//please inform how to set the cfg.DBName etc configuration initialization. Thanks!\n\nSetFCache(\"example.com\", \"/url\", 200, []byte(\"html header values\"), []byte(\"<html>html content</html>\"))\nstatuscode, headervalues, htmlcontent, timecached := GetFCache(\"example.com\", \"/url\")\nfmt.Printf(\"%d %v %q %d\", statuscode, headervalues, htmlcontent, timecached)\n\n}\n```. oh, I forget to renew for my domain.. IMO, I can't get your point about how to set \"RAM\", you can set it every where before you initialize ledisdb.\n\nI'm running HMset at 6s\n\nCan you give me your benchmark case? 6s is too slow. . @unisqu \nThe RAW mod you used is wrong, here is my change:\n```go\nvar cfg lediscfg.Config\nvar fcachel ledis.Ledis\nvar fcachedb *ledis.DB\nfunc main() {\n    cfg = lediscfg.NewConfigDefault()\n    cfg.DBName = \"memory\"\n    var err error\n    fcachel, _ = ledis.Open(cfg)\n    fcachedb, _ = fcachel.Select(0)\n```\nAbove can use the memory mode. But this is still slower than freecache, some reasons:\n\nYou set multi field-values, each pair is a new key-value written, so the number of total written keys is 4 times than freecache. \nHMset and HExpire also need to write meta data, another extra two Write operations.\nHMSet and HExpire also need to read the meta data of Hash, another extra two Read operation\nHMSet and HExpire will encode the key internally, this causes allocation and memmove. \ngoleveldb uses skiplist, which is not optimized\n\nAs you can see, many things need to be done in LedisDB, but I am still not satisfied with its performance, I have been planning to refactor this project, but have not enough time, sorry. . another thing is that even we use memory mode, goleveldb will still write data to WAL which will cause another I/O.... @unisqu \nThere is no way to disable WAL, you have to change the goleveldb code, but I don't know wether it is right or not. You can comment https://github.com/siddontang/ledisdb/blob/master/vendor/github.com/syndtr/goleveldb/leveldb/db_write.go#L244\nFor memory mode, all data will be saved in memory, no LRU, so you may meet OOM.\nyou can use \nparis := []ledis.FVPair{\n  {key, value},\n  {key, value},\n} \nto simplify your code. \n. IMO, if you care too much about performance and just want a cache now, my project is not a good choice for you, because I have no time to improve it. \n. > is there a quick fix to this? limiting ram usage and evicting based on LRU. do you mind pointing me to where i can fix this myself? i can buy you a few more coffee for this feature.\nmaybe we can try other memory engines instead. But you must realize that LedisDB is not designed for cache. So if you forget to expire the key, you will meet OOM. \nThis is not one day or one-weekend work, and another problem is that I have not enough time even at the weekends these days.  To my honest, I want many guys to use my project, but now I have to suggest not using this project because it can't fit your need and can't be improved quickly. . maybe https://github.com/golang/groupcache?. Thanks @HaraldNordgren . If you run make install, the library will be installed in the lib path. . Thanks @saromanov . Hi @justinfx \nNow memory mode uses goleveldb but it still creates WAL and some files. I will choose a pure memory implementation.. Thanks, @mullikine \n. Sorry @popadi \nNow we haven't supported this feature, and it is not in the plan because I am too busy. \ud83d\ude2d . Maybe we only need AuthPassword, if it is not empty, we will use password, otherwise, don't. :-)\n. The variable format is_authed is not suggested in Go. we could use isAuthed or other camel format instead. :-)\n. I know that log package doesn't have Infof function, am I wrong? \n. no need to check seq validation? e,g, seq is > tail or < head. \n. maybe need calling r.Body.Close(). \n. switch t := elem.(type)\ncase []byte:\n    lst[i] = convertBytesToString(t)\ncase [][][byte:\n   lst[i] = convertBytesSliceToString(t)\n. why not use nil here?\n. I think using err = fmt.Errorf(\"panic: %v\", r) is enough. . I prefer using go context directly.\nBtw, we can upgrade go verion in traivs CI too. . if we get the item or meet error, we should cancel the context when return to avoid the resource leak. . I am confused with this, why not using \n<-ctx.Done()\ncancel()\nerr = ctx.Err()\ndireclty? . here we must also call cancel to avoid the resource leak. . can we remove the empty line?. ditto. I guess we can remove 1.7 now.. does the new LevelDB have a function to set manifest file size like RocksDB does? . can we support this? Or SetMaxFileSize already does?. need alignment here. do we need this patch now? I think we can remove it if it can't improve too much performance.. Got it. \nI think we can still keep the patch :-). make alignment . make alignment. make alignment. make alignment. I prefer defining a Options contains addr, read/writeSize and connectTimeout, etc..., then add a function ConnectWithOptions. I think we can remove 1.8 and 1.9 now. . I prefer bit op NOT . ",
    "silentsai": "As you can see that REDIS is limit in the memory capacity in some environment , so I strongly recommend you to give it a try. \nBut there is an issue that we just implements some functionality of REDIS so far. So, once you wanna to put it in practice , may be you need to ensure that LEDIS is fully suitable to your project. ( for more, pls check apis in WIKI in detail. )\nHopefully LEDIS can do help to you : )\n. ",
    "Michael2008S": "\u8c8c\u4f3c\u8fd9\u6837\u505a\u89e3\u51b3\u4e86.\n\u5728/etc/ld.so.conf.d\u7684\u6587\u4ef6\u5939\u4e2d \u65b0\u5efa\u4e00\u4e2a\u6587\u4ef6 \u52a0\u5165/usr/local/lib\u8fd9\u4e00\u884c\uff0c\u4fdd\u5b58\u4e4b\u540e\uff0c\u518d\u8fd0\u884c\uff1a/sbin/ldconfig \u2013v\u66f4\u65b0\u4e00\u4e0b\u914d\u7f6e\u5373\u53ef\u3002\n. ",
    "robert-zaremba": "There are few backends which supports transactions. Eg, the pure go one:\n- https://github.com/boltdb/bolt\nThe issue is more about setting a model, in which a user can do some sort of transactions. In Redis user is sure that each query is performed atomically. Also if he wants to involve operations on multiple keys then he can:\n- multi + watch\n- Lua script\nI think it's quiet fair approach, and the soundness is related to the model how the operations are performed (eg: simple, yet powerful solution is that each write is done only in a single thread/worker).\n. This is a fair solution. Redis do similar (without lock, but it's implicated by it's single threaded process). Better to implement something now then struggle with a complicate & buggy solution for 6 months.\nHow it would work if you use (LMDB)[http://symas.com/mdb/] as a backend (it supports transactions)? Or even Boltdb?\n. Personally I would use some pipelining without interfacing lua and go. There are some nice project which were doing some lua - go job, but I don't know details. Maybe it will be good to contact @benbjohnson, he was playing with this and he is behind: https://github.com/boltdb/bolt . It's worth to check his presentation Writing a High Performance Database in Go\nWith the pipeline approach:\n1. you have a luajit worker which expect some function\n2. from go you send a request to luajit worker and wait for a result with some timeout.\n3. worker should be able to access database for a simple operations (get, set, hget...) - like we have in Redis).\nIt's important to consider a consistency model here and inform users about it. For example: Redis blocks it's request processing when executing a lua job. So we know that their effect is atomic and DB is consistent.\n. @benbjohnson - do you have any document which explains a consistency model of Skydb (eg: how lua script interfer DB execution)?\n. For reference: lua scripting integration is moved to https://github.com/siddontang/ledisdb/issues/19 task\n. How the transactions are supported? Is it done through MULTI, EXEC + WATCH? Can you share some internals of it (how transactions impact database worload)?\n. Hmm, do you know the block level? From my understanding it block whole database. Am I right? We should keep all this info in wiki for future reference.\n. Depends on a workload. In Redis Lua is a very important feature, because you don't need to open a transaction to make a composed atomic operation.\n. Interesting operations are z* ones (zadd, zrangebyscore, ...)\n. ledis is more and more awesome!\n. It's worth nothing that RocksDB excels when data can't fit in RAM (when it fits in RAM then its comparable to LevelDB). LevelDB shines as long as data fits in RAM. RocksDB main selling point is that is good when the size of data < size of RAM, and is still good when data is bigger then size of RAM.\nLevelDB performance degradates compared to RocksDB in that use case. Alos RocksDB has better performance for concurrent workload.\nI think this should be noted in benchmark notes that it doesn't present a good workload and in a production it probably behave totally different (LRANGE_600, MSET (10 keys) ... tests doesn't test performance when DB needs to use disk heavily).\n. Awesome!\n. I was testing ledis db with RocksDB and LMDB in my project (data analysis system) where I analyse 10GB of data. A main part of the system is an algorithm which builds a model. Workload is about 40% reads and 60% writes.\nUsing LMDB, the main algorithm run time was 1:23 h. With RocksDB only 0:32 h.\nAlso I found this interesting article: http://influxdb.com/blog/2014/06/20/leveldb_vs_rocksdb_vs_hyperleveldb_vs_lmdb_performance.html\n. yaml is more widely used than toml\n. Thank you for details! I know hedis. Now I'm using https://github.com/twittner/redis-io. \nSince there is a custom Python client, and README says that Ledis is compatible with custom redis clients, It would be good to update it and add a support sections in wiki/Commands about API changes from a custom redis client.\n. Thank you! ::)\n. > I will try to keep the API compatibility, but I have not release a stable 1.x version for LedisDB until now, so sometimes it may not be backend compatibility when you update.\nYou mean ledisdb package, not a storage?\n. Yes, I know that when a client is initialized you can't change a DB (select). \nMy question is if using multiple DB simultaneously  (throught multiple clients) is a good idea.\n. that was my alternative. But I don't know the system internals. So if Ledis works well with multiple DBs then I prefer the solution with multiple clients. I didn't test what's better. So here is this issue/question.\n. Thank you - this is what I was looking for.\n. Correct - It's better to leave this job to system tools (systemd, upstart, supervisor...). It's not worth to mess the code for daemonizing.\n. Tell me if I'm wrong, but redis also doesn't support running in the daemon mode directly.\n. It's normall. You need to rebuild you dependencies after update\ngo install all\n. Yes, I was thinking about reverse scan.\nThat will be really good! Thanks.\nDo you know about other storages? How it will perform? Anyway this will be easy to check after having this functionality.\n. This is a relly good idea. Having redis compatybile API will make it easier to expand ledisdb.\n. I'm using https://github.com/mattn/gom, it's very convinient. Especially gom  exec command - I can use it with all go tools.\n. ",
    "benbjohnson": "There are some Go wrappers for the Lua library (e.g. https://github.com/stevedonovan/luar). Interfacing using CGO isn't too bad either although you have to manage the stack when calling functions which takes some getting used to. LuaJIT is another option but Lua is probably a little easier to start with and you can always swap them out later.\nLet me know if you have any specific questions. I used LuaJIT before in a database (Sky) and it worked pretty well. I used it to transpile from a SQL-like language to LuaJIT which then compiled down to machine code. Here's the file that does most of the LuaJIT interaction. (Plain Lua integration is similar)\nhttps://github.com/skydb/sky/blob/unstable/query/execution_engine.go\n. @robert-zaremba I don't have a document about it. Sky basically opens a Bolt transaction and a C function made available to LuaJIT iterates a cursor over the connection. There's some complicated mapping between serialized Sky data and a dynamically generated C struct in Lua-land but that's for performance reasons. You don't need to get that complicated. It's strongly consistent and uses serializeable transactions (but that's because it's Bolt).\n. :+1: for TOML with a .conf extension. I always have to re-learn YAML whenever I need to use it. TOML seems more natural to use (even for people who don't know it's TOML).\n. ",
    "railsmechanic": "Many thanks for that update.\nI'll try to test it in depth (hopefully this week)\nThese are the benchmark results (MB Air 1,8GHz i5, 8GB, 128GB SSD):\nset: 2610.49 requests per second\nincr: 3519.43 requests per second\nget: 40233.09 requests per second\nrpush: 2881.19 requests per second\nlrange: 27197.44 requests per second\nlrange: 13257.01 requests per second\nlrange: 8250.14 requests per second\nlpop: 2609.26 requests per second\nhset: 3379.01 requests per second\nhget: 39368.55 requests per second\nhincrby: 3355.82 requests per second\nhdel: 3430.82 requests per second\nzadd: 3452.01 requests per second\nzincrby: 3471.48 requests per second\nzrange: 34549.02 requests per second\nzrangebyscore: 32332.58 requests per second\nzrevrange: 35630.11 requests per second\nzrevrangebyscore: 32292.83 requests per second\nzrem: 3513.46 requests per second\nAs BoltDB is a \"clone\" of LMDB, writes are slow but reads are really fast. So, perfect for read-only applications.\n. ",
    "ckrissun": "and I cannot build snappy library in my Linux system. Just download a snappy-1.1.2.tar.gz, \nthen omit the autoreconf line in build_leveldb.sh\n. ",
    "pkieltyka": "Keep up the great work! btw, have you thought about making \"goleveldb\" the default database since its pure Go and easy to package? hopefully it gets faster with time as well. The CGO performance hit is unfortunate. Also, I'm very surprised to see how poor boltdb does in this those benchmarks, considering how well lmdb performs and its based on it..\n. Ah cool. Thx for the link on that bolt issue, I'm interested too\n. Yea that's what I like about TOML.. Is it feels very natural, intuitive and clean\n\nOn Aug 5, 2014, at 12:26 PM, Ben Johnson notifications@github.com wrote:\nfor TOML with a .conf extension. I always have to re-learn YAML whenever I need to use it. TOML seems more natural to use (even for people who don't know it's TOML).\n\u2014\nReply to this email directly or view it on GitHub.\n. nice! this looks great. \n\nalso, what do you think about naming the config file ledis.conf instead of ledis.toml?  ...it's just more obvious what the file is for, and the format is pretty plain and feels like a conf file\n. nevermind, there is the SCAN command that works great.\n. maybe call it XSCAN, XHSCAN then if its different from the redis api..?  \nOn Monday, September 8, 2014 at 9:02 PM, siddontang wrote:\n\nscan, hscan, etc, are different from Redis, You may pay attention to it. ::)\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/siddontang/ledisdb/issues/67#issuecomment-54910178).\n. nice! and yes, I fully agree to use something like godep or goop\n. im using rocksdb btw for the data store\n. hey @siddontang .. I think you should write some basic docs, and note the XSCAN comamnds. I finally just noticed HXSCAN .. which I think should be XHSCAN .. the \"X\" prefix noting the extensions / added commands to the redis protocol\n. For 120, I agree using godep -r or this project: https://github.com/robfig/glock which is similar. I started using glock with my projects and really enjoy it.\n\nFor 117, I think redis api comparability is important.. But what do you mean specifically because I find ledis to already be very close to the same. I do think additional commands are fine and just prefix with an X.\n\nOn Jan 23, 2015, at 7:42 PM, siddontang notifications@github.com wrote:\nSorry @pkieltyka, \"X\" makes you surprised, I will change it later.\nBtw, do you think it is necessary to do #117 or #120 ? \nI just notice that https://github.com/github/hub use \"godep -r\" feature, which makes the package management easy, but the import path looks very long and ugly :-)\n\u2014\nReply to this email directly or view it on GitHub.\n. Good stuff! I don't think backwards compatibility for these kinds of commands matter. \n\nAlso, what do you think about the naming of XHSCAN instead of HXSCAN ? I like the idea of prefixing any \"extensions\" to redis commands with an X.. makes for more consistency.\n. its been solid for us for over a year of a 10GB data set (rocksdb), on a service doing 100 to 200 req/sec, of which every request would hit ledisdb and its been a rock.\n. long-term data persistence and a data set that can grow > 100GB\n. ledisdb isn't the default choice over redisdb, but if you have those two requirements above.. large data set, where keys are greater than memory, and you want the dataset to be stored in a proper on-disk storage engine, then ledisdb is a much better choice, with still great performance (but not as good as redis since thats all in-memory).\n. why remove boltdb..?\n. I'm trying to update the Docker image to the latest but running into issues with the dependency drift. Can you update to use golang/snappy which was previously google/go-snappy.\n. thank you :)\n. @siddontang ah, you've put the files in cmd/vendor and link it.. how come you do this though? why not just keep it in ./vendor?\nalso, what version of RocksDB is ledisdb compatible with? I tried v4.8 but had compile errors\n. @siddontang thanks for the reply, I tried v4.9+ and it works great.\nalso, perhaps update the Makefile for production builds to setup the link etc.. or add it to the notes. I'm going to update the Dockerfile/build now too\n. ",
    "hit9": "Good!\n. \u54c8\u54c8\uff0c\u95ee\u4e2a\u4e0d\u76f8\u5173\u7684\u95ee\u9898\uff0cgo\u8bed\u8a00\u505awebsocket\u5982\u4f55\uff1f\n. ",
    "blinkinglight": "for mysql proxy, check google vitess project. maybe find some ideas for query cache and so on.\n. yeah. i do the same. all projecs is \"too big\" for me :) \n. ",
    "holys": "Bad performance, abandoned. Any one interests can check out the code from https://github.com/holys-archive/ledisdb\n. @Leither  Have you installed the dependencies in https://github.com/siddontang/ledisdb/blob/master/Godeps/Godeps.json?\nIf not,  go get godep  from https://github.com/tools/godep, and then execute script file named bootstrap.sh. It'll install the dependencies automatically.\n. :+1: \n. ",
    "balzaczyy": "Since I embed ledisDB in my web app, the existing build script doesn't help much. I see that you put the driver register logic in store package, which would inevitably load all the drivers. Maybe it's a design decision, but can you move the register logic to individual driver package?\nFor example, move the init() function from store/mdb.go to store/mdb/mdb.go\n. I'm able to continue testing by bypassing the mdb init() manually, BTW.\n. Seems so... With mingw-w64 (4.9.1, x86_64, posix, seh) and git shell env, I can build lmdb but can not run it (or go test it), due to error \"undefined: strdup\". I didn't try other mingw-w64 options, though.\nBTW, moving init() to individual driver package won't cause dep cycle, since package store is only a registry, as I understand. I'm using this method to workaround the issue I encountered.\n. No problem. I have made it work now. Thanks for creating this good software.\n. ",
    "guileen": "It will be the most important reason why I use Ledis in production environment.\n. Is it a pattern of Go lang? Why not use a ./configure file\n. I got it.\n. About sudo, you are right, but I can't build successfully by follow README, because of /usr/local/* staff.\nonly two options:\n1. Modify README, add sudo\n2. Modify build_leveldb.sh, no more /usr/local/*\n. \u5bf9\u4e8eLedis\u5728ZRANGE\u8fd9\u4e2a\u64cd\u4f5c\u4e0a\u7684\u6162\uff0c\u5e94\u8be5\u4e0d\u53ef\u80fd\u662fgo\u6bd4c++\u6162\u5bfc\u81f4\u7684\u3002go\u6bd4c\uff0b\uff0b\u6162\u7684\u56e0\u7d20\u5728\u6240\u6709\u547d\u4ee4\u4e2d\u90fd\u662f\u76f8\u540c\u7684\uff0c\u5305\u62ec\uff0cSET\u3001GET\u8fd9\u4e9b\u57fa\u672c\u64cd\u4f5c\u4e5f\u5e94\u8be5\u80fd\u6210\u500d\u7684\u8868\u73b0\u51fa\u6765\u3002\u663e\u7136\uff0cSET\u3001GET\u547d\u4ee4\u5e76\u4e0d\u6bd4ssdb\u6162\u5f88\u591a\u3002\u4f46ZRANGE\u5219\u6bd4ssdb\u6162\u5f97\u592a\u591a\uff0c\u663e\u5f97\u4e0d\u592a\u5408\u7406\u3002\n\u975e\u5e38\u9ad8\u5174\u770b\u5230 qdb \u8fd9\u4e2a\u5b8c\u5168redis\u517c\u5bb9\u7684\u9879\u76ee\u51fa\u6765\u3002\u4e0d\u77e5\u9053\u672a\u6765 qdb \u4e0e ledis\u7684\u8ba1\u5212\u662f\u600e\u4e48\u6837\u7684\u5462\uff1f\u6b64\u5916\u53d1\u73b0 qdb \u5c5e\u4e8ereborndb\u8fd9\u4e2a\u7ec4\u7ec7\u7684\uff0c\u800c\u8fd9\u4e2a\u7ec4\u7ec7\u4e5f\u6709\u4e00\u4e2areborndb \u7b80\u4ecb\u662fredis\u517c\u5bb9\u7684\u3002\u60f3\u8981\u77e5\u9053\uff0c\u662f\u5426\u9002\u5408\u5728\u9879\u76ee\u4e2d\u4f7f\u7528qdb\u3002\n. \u975e\u5e38\u611f\u8c22\u3002qdb\u7684\u4ee3\u7801\u770b\u8d77\u6765\u5f88\u8d5e\u3002\n. ",
    "gl-works": "Cool! Thanks for this timely reply. We are plan to use something like this to support conversation histories. Scanning (within some specified key range) is a MUST in our design. Hope to see the scan soon.\n. zset won't fit our case. What we want to store are chat logs where each log is keyed by receiver, sender and sequence number, while value will be string-encoded object. On the read side, typical operations are logs scan for particular receiver.\n. ",
    "ernado": "Please make sure that it is highly tested. \nFor example, raft implementation in another golang project, weedfs, behaves strange in some cases.\nIt is very critical because fault handling heavily depends on it. \nThank you! \n. ",
    "wenerme": "How ledis strong consensus replication ?\n. ",
    "dancebear": "premiss is the database is empty\n. ",
    "glycerine": "Transactions are very important for many applications. Please retain them! :-)\n. Excellent.\n. Have you tried the instructions in the README.md?\nYou could also simply cross compile. Must be easier.\nhttp://dave.cheney.net/2013/07/09/an-introduction-to-cross-compilation-with-go-1-1\nOn Thu, Sep 25, 2014 at 9:00 PM, Doyle notifications@github.com wrote:\n\nHow to build on windows?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/siddontang/ledisdb/issues/83.\n. \n",
    "emilgpa": "Thanks!\nLast question:\nI use ledisdb with goleveldb, i use this by package (not server, for the moment), i should open and close a connection every time I do an operation?\n. Ops, It's more stranger, only works if I change data_dir to \"./var\" and not \"./db\"...\n. Ok. I found the problem. I was running ledis by server, and when I wanted to run ledis by package, it crash...\nNot is possible have ledis running by server and package, right?\nThanks!\n. ",
    "doylecnn": "ledisdb \u6211\u5728windows \u4e0a\u7f16\u8bd1\u4e86\uff0c\u76ee\u524d\u9664\u4e86 ledis-cli \u8fd9\u4e2a\u4e4b\u5916\uff0c\u5176\u5b83\u90fd\u7f16\u8bd1\u6210\u529f\u4e86\n\u76f4\u63a5 go install github.com/siddontang/ledisdb/cmd/ledis-server\n\u5176\u5b83\u7684\u7c7b\u4f3c\uff08go install github.com/siddontang/ledisdb/cmd/ledis-benchmark \u5c31\u5b89\u88c5\u4e86ledis-benchmark.exe\uff09\n\u76ee\u524d\u53ea\u6709 ledis-cli \u8fd9\u4e2a\u6ca1\u53d1\u8fc7\u2026\u2026\u5728windows \u4e0b\uff0c\u8bf4\u627e\u4e0d\u5230termios.h \u8fd9\u4e2a\u5934\u6587\u4ef6\ncygwin \u4e0b\u5219\u8bf4\u627e ld \u547d\u4ee4\u627e\u4e0d\u5230 mingwex \u548c  mingw32  \u8fd9\u4e24\u4e2a\u9759\u6001\u5e93\uff08\u5373\u4f7f\u5df2\u8bbe\u7f6eLD_LIBRARY_PATH \u548c LIBRARY_PATH\uff09\n. ok\u2026\u2026\n. ",
    "kouhate": "OK, I'll use superviror to daemonize it, but maybe general redis users do not expect it as natural thing.\nFor the second,  I wasn't take the performance issue into consideration.\nReverse iteration is not suitable for production environment...\nThanks.\n. Hi @siddontang ,\nReplication works well after using -rpl flag. Thanks.\nBut perhaps noobs expect use_replication=true is the only flag to enable it.\nBTW, I also try redis-failover.\n\n//master\nledis-server -rpl -addr=localhost:6380 -data_dir=./var\n//slave\nledis-server -rpl -addr=localhost:6381 -data_dir=./var1 -slaveof=localhost:6380\n//redis-failover\nredis-failover -addr=localhost:11000 -masters=localhost:6380\n[2015/02/14 14:25:10] group.go:195 [Info] slave 127.0.0.1:6381 added\n\nThen I killed master process localhost:6380.\n\n[2015/02/14 14:27:10] group.go:65 [Error] do ROLE command for localhost:6380 error: EOF, try again\n[2015/02/14 14:27:10] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:10] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:10] app.go:179 [Warn] check master localhost:6380 err Node is down, down time: 1.00s, retry check\n[2015/02/14 14:27:11] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:11] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:11] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:11] app.go:179 [Warn] check master localhost:6380 err Node is down, down time: 2.00s, retry check\n[2015/02/14 14:27:12] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:12] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:12] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 14:27:12] app.go:189 [Error] check master localhost:6380 err Node is down, do failover\n[2015/02/14 14:27:12] group.go:265 [Error] no proper candidate to be promoted\n\nrole of localhost:6381 is still slave.\n\n# redis-cli -p 6381\n127.0.0.1:6381> role\n1) \"slave\"\n2) \"localhost\"\n3) (integer) 6381\n4) \"connect\"\n5) (integer) 2\n\nThis works only for redis-server?\n. Hi @siddontang ,\nThose are fixed after I switched to origin/develop and pulled latest changes.\nThanks a lot.\nNow I'm trying codis-ha.\nSetup codis-config.\n\ncd xcodis/sample\n../bin/codis-config server add 1 localhost:6380 master\n../bin/codis-config server add 1 localhost:6381 slave\n../bin/codis-config server list\n[\n   {\n     \"id\": 1,\n     \"product_name\": \"test\",\n     \"servers\": [\n       {\n         \"type\": \"master\",\n         \"group_id\": 1,\n         \"addr\": \"localhost:6380\"\n       },\n       {\n         \"type\": \"slave\",\n         \"group_id\": 1,\n         \"addr\": \"localhost:6381\"\n       }\n     ]\n   }\n]\n\nReplication is already runnning like this.\n\n//master\n127.0.0.1:6380> role\n1) \"master\"\n2) (integer) 2\n3) 1) 1) \"127.0.0.1\"\n      2) \"6381\"\n      3) \"2\"\n//slave\n127.0.0.1:6381> role\n1) \"slave\"\n2) \"localhost\"\n3) (integer) 6380\n4) \"connected\"\n5) (integer) 2\n\nSetup codis-ha.\n\n../bin/codis-ha -addr=\"localhost:11000\" -masters=\"localhost:6380\"\nno config file, use default config[2015/02/14 16:57:09] app.go:72 [Info] unsupported broker , use no cluster\n[2015/02/14 16:57:10] group.go:195 [Info] slave 127.0.0.1:6381 added\n\nThen I stopped master node localhost:6380\n\n[2015/02/14 16:58:22] group.go:65 [Error] do ROLE command for localhost:6380 error: EOF, try again\n[2015/02/14 16:58:22] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:22] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:22] app.go:196 [Warn] check master localhost:6380 err Node is down, down time: 1.00s, retry check\n[2015/02/14 16:58:23] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:23] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:23] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:23] app.go:196 [Warn] check master localhost:6380 err Node is down, down time: 2.00s, retry check\n[2015/02/14 16:58:24] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:24] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:24] group.go:57 [Error] dial localhost:6380 error: dial tcp 127.0.0.1:6380: connection refused, try again\n[2015/02/14 16:58:24] app.go:206 [Error] check master localhost:6380 err Node is down, do failover\n[2015/02/14 16:58:24] group.go:269 [Info] select slave 127.0.0.1:6381 as new master, priority:100, repl_offset:2\n[2015/02/14 16:58:24] app.go:220 [Error] master is down, elect 127.0.0.1:6381 as new master, do failover\n[2015/02/14 16:58:24] app.go:333 [Error] do after failover handler for localhost:6380 -> 127.0.0.1:6381 err: no such addr 127.0.0.1:6381 not found\n\nFailover seems to be done correctly.\n\n127.0.0.1:6381> role\n1) \"master\"\n2) (integer) 2\n3) (empty list or set)\n\nBut codis-config didn't handle the change.\n\n../bin/codiconfig server list\n[\n   {\n     \"id\": 1,\n     \"product_name\": \"test\",\n     \"servers\": [\n       {\n         \"type\": \"master\",\n         \"group_id\": 1,\n         \"addr\": \"localhost:6380\"\n       },\n       {\n         \"type\": \"slave\",\n         \"group_id\": 1,\n         \"addr\": \"localhost:6381\"\n       }\n     ]\n   }\n ]\n\nIs it still developing?\n. Hi @siddontang ,\nFailover works well after I changed \"localhost\" to \"127.0.0.1\".\nThank you.\nNow, codis-config server list shows like this.\n\n[\n   {\n     \"id\": 1,\n     \"product_name\": \"test\",\n     \"servers\": [\n       {\n         \"type\": \"master\",\n         \"group_id\": 1,\n         \"addr\": \"127.0.0.1:6381\"\n       },\n       {\n         \"type\": \"slave\",\n         \"group_id\": 1,\n         \"addr\": \"127.0.0.1:6380\"\n       }\n     ]\n   }\n ]\n\nType is changed successfully, but the type of stopping master node is changed to slave.\nThis is not good if it is still unaccessible.\ncodis-config server promote \"group_id\" \"redis_addr\"\nchange the \"redis_addr\" to master, and demoted master is changed to offline\nI don't know enough about codis, but I expect offline type of node should not be accessed by codis-proxy.\nUnreliable node type would be \"offline\", and when it comes back online, changing the type to \"slave\" is good idea.\n. Hi @siddontang , I tried failover operation again, and this time slave type turned into \"offline\" correctly.\nI have no idea why it was caused.\nredis-failover show only successful messsages like this.\n\n...\n[2015/02/14 21:39:39] app.go:206 [Error] check master 127.0.0.1:6380 err Node is down, do failover\n[2015/02/14 21:39:39] group.go:269 [Info] select slave 127.0.0.1:6380 as new master, priority:100, repl_offset:2\n[2015/02/14 21:39:39] app.go:220 [Error] master is down, elect 127.0.0.1:6381 as new master, do failover\n\nAnyway, thanks a lot.\n. Hi, @osiloke \nIt's a good idea if you use ledisdb in a single node, but I'm planning to use xcodis.\nOnce you switch to cluster, all keys are distributed to multiple nodes.\nSo, this design will force us to query all nodes... (except for using hash tag {})\nHash type is grouped by key and sorted by field, and the data structure looks like column-oriented nosql.\nIf HSCAN is supported, we could use it like cassandra.\n. Hi @siddontang, I'm glad to hear from you.\nNow, ledis has a lot of redundant *SCAN commands such as HXSCAN, XHSCAN, HXREVSCAN, XHREVSCAN....\nI suppose these are rarely used in production, because in app we should use key-name like table-name of relational database.\nSo, those only help our maintenance operation, I think.\nIMHO, It is better to combine key iterable commands(HXSCAN, LXSCAN, ZXSCAN, SXSCAN...) to XSCAN, and provide options to select targeted data type. (simply changing the name HXSCAN to HKEYSCAN is not so bad)\nThen, HXSCAN or XHSCAN should overwritten to support value or field iteration.\nI recommend to use HXSCAN because most of all redis commands are prefixed by data type.\nThese may confuse ledis user, but will improve the compatibility with redis.\n. Thank you, @siddontang.\nBTW, would you also support SXSCAN and ZXSCAN?\nThese are useful too.\n. Hi @siddontang, maybe \"range\" or \"slice\" is more suitable.\n\"seek\" is also proposable and the shortest.\n. Hi there, OK. I agree to use X prefix.\nI think H S Z prefix makes the target data type more certain..., but this may disturb the consistency.\n. Thanks @siddontang, I'll test them later.\n. Hi @siddontang, would you also support reverse scan?\nAs I know reverse scan is more slower than forward one, but this may useful for some use case.\nMaybe XREV.. bring more redundancy like before, so if you could, supporting by option would be better.\nXSCAN type cursor [MATCH match] [COUNT count] [ASC | DESC]\n. @siddontang, especially for hash, reverse scan is necessary I think.\nIn my use case, Hash filed-name will TimeUUID and I want to retrieve recent data.\nFor time series data,  maybe reverse scan cannot be avoided, or app must plan the key name to be reversed.\nIn the case of Cassandra CQL3, they support WITH CLUSTERING ORDER BY (clumn-name [ASC | DESC]) option for setting default order.\nOnce the table are created with the option, saved data is always ordered by the specified order.\nSo, the performance of reverse heavy operation will be boosted after setting the DESC option.\nFurthermore, ZSET also have a similar problem.\nFor ranking or access counting, what we are interested in is usually the highest score data.\nSo, we easily use reverse scan such as ZREVRANGE or ZREVRANGEBYSCORE, but unfortunately, these commands are 10 times slower than forward scan, especially using leveldb or rocksdb as storage.\nThis is not happend when using Redis.\nIn my app, sometimes a score of ZSET is prefixed by \"-\" on purpose of reverse sorting, but this force me to decode and encode when inserting and retrieving.\nAnyway, reverse scan is necessary for my use case.\n. @siddontang, ok, I know the two cons, but does XMIGRATEDB keep blocking any write operation until  finished?\nIf so, it may be a fatal problem for me.\n. Hi @siddontang, those difference is not a problem.\nMy purpose of using *XSCAN is to scan by value, so this is rather welcomed.\n. Hi @siddontang, I've just updated my prof, pls check it.\n. @siddontang, \n1. It is difficult to estimate enough nodes for the future at the time of startup.\n   Migration is always harmful even if it is rare. That is especially why I want to execute it more safely.\n2. it's true, but this is not user friendly.\n   Furthermore, it would be true the larger the amount of keys grow, the longer blocking time take.\nAs you said before, setting a lock for the key that migration is in progress looks like the best way.\nI guess scaling out with ease is one of the advantage to use it in production.\n. Hi @siddontang, thank you for the improvement, and I want to make sure how it is non-blocking.\nWhen migrating group-1 to group-2, as you know this is the case of using xcodis, the followings are expected:\n1) Write-operation to the key which is not yet migrated is routed to group-1.\n2) Write-operation to the key which is already migrated is routed to group-2.\n3) Only the write-operation for the key migrating just now is blocked.\nAre these implemented certainly?\nAccording to my code reading, it seems the lock only prevent duplicated migration.\nIf those are not supported yet, even simple write-operation may easily bring inconsistency.\nI suppose this issue should be discussed together with busy key routing one.\n. @siddontang, aha, it all makes sense now. Thanks for the clarification.\nBtw, what will be the difference between redis-port and redis-canal?\n. That's nice.\nI suppose this would be also useful for another project when not only porting but rehashing.\n. @siddontang, now you have changed db index to 16 as before.\nThen, how many db index would you plan on supporting?\n. That's enough to scale out, and it may be good to start from 1024 while an alternative plan to solve the performance issue of keeping huge routing table is not found.\nThanks:-)\n. Hi @siddontang, make test_ledis passed, and 10240 db also works well under replication environment.\nBtw, xcodis seems to have a connection pool per db-index in order to reduce performance degradation, and its pooling capacity looks like 16.\nDo you intend to increase the number to 1024 or more? This implementation may have some inefficiency for a large number of dbs.\n. Oh, I meant this is only for the connection problem, not for zookeeper.\n. ",
    "genedna": "I remove everything and build from first. \n```\ngo get -u github.com/siddontang/ledisdb/ledis\ngithub.com/szferi/gomdb\n../../szferi/gomdb/mdb.c:5862:9: warning: variable 'rc' is used uninitialized whenever 'if' condition is false [-Wsometimes-uninitialized]\n../../szferi/gomdb/mdb.c:5888:9: note: uninitialized use occurs here\n../../szferi/gomdb/mdb.c:5862:5: note: remove the 'if' if its condition is always true\n../../szferi/gomdb/mdb.c:5721:10: note: initialize the variable 'rc' to silence this warning\n../../szferi/gomdb/mdb.c:9260:46: warning: data argument not used by format string [-Wformat-extra-args]\n/usr/include/secure/_stdio.h:47:56: note: expanded from macro 'sprintf'\n```\nThen I run go get -u again, it's OK.\n. Thanks, I report it at https://github.com/szferi/gomdb/issues/33 .\n. ",
    "eryx": "Confirm this problem has been resolved. great work!\n. ",
    "rbastic": "Why not consider utilizing pre-existing external consensus engines for this?\nZooKeeper, etc.\n. ",
    "1fei": "\u597d\u7684\uff0c\u6211\u8bd5\u4e00\u4e0b\n. \u6211\u539f\u6765\u7684\u4ee3\u7801\u901a\u4e0d\u8fc7\uff0c\u4f60\u7684\u4ee3\u7801\u901a\u8fc7\uff0c\u591a\u8c22\n. \u67e5\u4e86\u4e00\u4e0b\uff0c\u5f88\u4e0d\u9519\u7684\u5185\u5bb9\n. \u770b\u4e86\u4ee3\u7801\u662f\u6807\u51c6\u7684\u6b63\u5219\uff0c\u597d\uff0c\u6211\u67e5\u4e00\u4e0b\u76f8\u5173\u5199\u6cd5\n. ",
    "xlab": "On my macbook I have 15-50ms delay for writing a 12Mb file into LMDB/RocksDB.. For me this is pretty much OK since this is a good way to share some files across distributed system. I'll test this in the production config today.\n. \nThere's the bench results, the graph is based on ~3k results mined from the logs over a week. We're storing a single file about 13MB in size, the time is fine for us. This is the LMDB backend.\nI just don't see any point in limiting the size of value in the sources \u2014 this could be defined in client by a developer with an ease or a ledisdb config if this is really required. Such a hardcoded limit forces us to patch the source and have a private docker image :cry: \nP.S. We don't use the replication and we don't plan to use it anyway, so we really don't care about performance there. Totally don't care. This is a temporary workaround until we'll get rid of this bulk file and it works just fine though.\n. ",
    "Leither": "\u5982\u679c\u6211\u7684begin\u662f\u751f\u6210\u4e00\u4e2abatch,\u4e2d\u95f4\u7684\u64cd\u4f5c\u90fd\u5199\u5728batch\u4e2d\uff0ccommit\u662f\u4e00\u6b21\u6027\u5199\u8fd9\u4e2abatch,rollback\u662f\u64a4\u6d88\u8fd9\u4e2abatch\uff0c\u8fd9\u6837\u4e0d\u548c\u4e8b\u52a1\u4e00\u6837\u5417?\n. \u591a\u8c22\n. thanks\n. \u6211\u627e\u5230\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u4f60\u7684\u5907\u4efd\u4fe1\u606f\u90fd\u6253\u5728Log\u91cc\nledis\u521d\u59cb\u5316\u7684\u65f6\u5019\u901a\u8fc7AddNewLogEventHandler\u52a0\u4e00\u4e2a\u6211\u81ea\u5df1\u7684\u5904\u7406\u51fd\u6570\n\u56e0\u4e3alog\u91cc\u7684\u5185\u5bb9\u867d\u7136\u662f\u5b57\u8282\u6d41\uff0c\u4f46\u524d\u9762\u662f\u957f\u5ea6\uff0c\u548ckey\uff0c\u76f8\u5bf9\u5bb9\u6613\u505a\u5206\u53d1\u5904\u7406\u3002\n\u603b\u4f53\u4e0a\u53ef\u4ee5\u5728\u4e0d\u52a8\u4f60\u4ee3\u7801\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6839\u636ekey\u8fdb\u884c\u5206\u6d41\u5907\u4efd\u3002\n\u5982\u679c\u4e0d\u538b\u7f29\uff0c\u6216\u53ea\u5728\u5206\u6d41\u540e\u538b\u7f29\u57fa\u672c\u4e0a\u4e0d\u5f71\u54cd\u4ec0\u4e48\u6027\u80fd\u3002\n\u591a\u8c22\u3002\n. \u6211\u8fd9\u8fb9\u662f\u4f5c\u4e3a\u5305\u4f7f\u7528\uff0c\u53ea\u4f7f\u7528ledis\u5305\uff0c\u4e0d\u4f1a\u52a8ledis\u6216ledisdb\u8fd9\u8fb9\u7684\u76f8\u5173\u4ee3\u7801\u3002\n. 1\u3001\u662f\u4e0d\u662f\u8fd9\u4e2a\u610f\u601d\uff1a\u626b\u63cfhsize\u7c7b\u578b\u5c31\u53ef\u4ee5\u7a77\u4e3e\u51fa\u6240\u6709\u7684hash\u7c7b\u578b\u7684key\u3002\u662f\u4e2a\u4e0d\u9519\u7684\u529e\u6cd5\u3002\n2\u3001\u6027\u80fd\u6709\u5f71\u54cd\u5417?\u6ca1\u6709\u5427\uff01\u5206\u9694\u7b26\u548ckey\u7684\u957f\u5ea6\u662f\u76f8\u4e92\u5197\u4f59\u7684\u3002\u53bb\u6389\u4e00\u4e2a\u53cd\u800c\u66f4\u5feb\u3002\n3\u3001\u56e0\u4e3akey end\u662f\u53ef\u4ee5\u5feb\u901f\u5b9a\u4f4d\u8bfb\u53d6\u7684\u3002type\u7684\u503c\u672c\u8d28\u4e0a\u662f\u5c5e\u4e8evalue\u7684\uff0cseek\u8fc7\u7a0b\u4e2d\uff0ckey(\u5305\u62ecdbindex,field\u548cindex)\u7684\u91cd\u8981\u6027\u8fdc\u9ad8\u4e8etype.\u653e\u5728\u6700\u540e\u662f\u9002\u5408\u7684\u3002type\u653e\u5728\u524d\u9762\u6253\u4e71\u4e86key\u7684\u8bed\u4e49\u6240\u8868\u793a\u7684\u903b\u8f91\u987a\u5e8f\u3002\n\u9644\uff1ae\u6587\u5f88\u6e23\uff0c\u62b1\u6b49\u7528\u4e2d\u6587\u4e86\u3002\n. \u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff1a\nkey \u4e09\u73ed\u5f20\u4e09\u7684\u6210\u7ee9 \u7c7b\u578bhashmap\nkey \u4e09\u73ed\u5f20\u4e09\u7684\u5e74\u9f84 \u7c7b\u578bkv\nkey \u4e09\u73ed\u674e\u56db\u7684\u6210\u7ee9 \u7c7b\u578bhashmap\nkey \u4e09\u7ebf\u674e\u56db\u7684\u5e74\u9f84 \u7c7b\u578bkv\n\u5982\u679ctype\u5728\u540e\u9762\uff0c\u8fd9\u56db\u4e2a\u5185\u5bb9\u5b58\u5728\u78c1\u76d8\u76f8\u8fd1\u7684\u5730\u65b9\u3002\n\u5982\u679ctype\u5199\u5728\u524d\u9762\uff0c\u8fd9\u56db\u4e2a\u5185\u5bb9\u5b58\u5728\u5b8c\u5168\u8ddd\u79bb\u5f88\u8fdc\u7684\u5730\u65b9\u3002\n\u5728\u5b9e\u9645\u5de5\u4f5c\u4e2d\uff0c\u4e24\u8005\u5b58\u53d6\u6027\u80fd\u76f8\u5dee\u5f88\u5927\u3002\u5f53\u7136bench\u53ef\u80fd\u6d4b\u4e0d\u51fa\u6765\u8fd9\u79cd\u5dee\u522b\u3002\nkey\u4e2d\u5305\u542blen\u4fe1\u606f\uff0c\u4e5f\u4f1a\u53d1\u751f\u540c\u6837\u7684\u95ee\u9898\n. \u8fd9\u91cc\u9762\u7684\u6027\u80fd\u5305\u62ec\u4e24\u4e2a\u90e8\u5206\uff1a\n1\u3001\u7a7a\u95f4\uff1aleveldb\u5bf9\u4e34\u8fd1\u8bb0\u5f55\u4e2dkey\u76f8\u540c\u7684\u90e8\u5206\u662f\u7701\u7565\u5b58\u50a8\u7684\u3002\u6253\u65ad\u4e86\u5c31\u65e0\u6cd5\u4f18\u5316\u4e86\u3002\n2\u3001\u65f6\u95f4\uff1aleveldb\u4e4b\u6240\u4ee5\u5feb\uff0c\u6838\u5fc3\u7406\u5ff5\u5c31\u662f\u786c\u76d8\u8bfb\u5199\u7684\u5c31\u8fd1\u539f\u5219\uff0c\u5199\u7684\u65f6\u5019\u4e00\u6b21\u6027\u5199\u4e0b\uff0c\u7136\u540e\u540e\u53f0\u628a\u6570\u636e\u5f52\u6574\u4e3a\u6309key\u6392\u5e8f\u3002\n\u6253\u65ad\u4e86\u8fd9\u79cd\u8fde\u7eed\u6027\u610f\u5473\u7740\u8bfb\u53d6\u7684\u65f6\u5019\u78c1\u5934\u79fb\u52a8\u7684\u8303\u56f4\u8981\u5927\u7684\u591a\u3002\n. 1\u3001\u5206\u9694\u7b26\u53ef\u5b9a\u4e49\u7684\u8303\u56f4\u8fd8\u662f\u5f88\u5927\u7684\uff0c\u5728\u6a21\u5757\u5c42\u9762\uff0ckey\u4e0d\u53d7\u9650\u5236\uff0c\u5728\u5e94\u7528\u5c42\uff0ckey\u90fd\u662f\u53d7\u9650\u7684\u3002\n2\u3001\u770bleveldb\u4f5c\u8005\u7684\u76f8\u5173\u8bba\u6587\uff0c\u4e0d\u7ba1\u79d1\u6280\u53d1\u5c55\u5230\u4ec0\u4e48\u65f6\u5019\uff0c\u6027\u80fd\u548c\u7a7a\u95f4\u4e0d\u80fd\u4e24\u5168\uff0c\u5b58\u50a8\u4ecb\u8d28\u4e4b\u95f4\u6c38\u8fdc\u662f\u6709\u6570\u91cf\u7ea7\u7684\u5dee\u522b\uff0c\u73b0\u5728\u7684\u78c1\u76d8\u548c\u5f53\u521d\u7684\u78c1\u5e26\u5dee\u4e0d\u591a\u3002SSD\u662f\u4ecb\u4e8e\u4e24\u8005\u4e4b\u95f4\uff0ccache\u662f\u5feb\u7684\u5185\u5b58\u3002\n3\u3001\u770b\u4e86hsize\u76f8\u5173\u7684\u4ee3\u7801\uff0c\u7279\u522b\u662f\u51e0\u4e2ascan\u51fd\u6570\uff0c\u57fa\u672c\u4e0a\u89e3\u51b3\u4e86\u6211\u5f53\u524d\u7684\u95ee\u9898\u3002\n\u6570\u636e\u7ed3\u6784\u7684\u76f8\u5173\u53d8\u52a8\u4f1a\u9020\u6210\u5f88\u5927\u7684\u9ebb\u70e6\uff0c\u4e00\u822c\u662f\u524d\u671f\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u9884\u7559\u7248\u672c\u4fe1\u606f\uff0c\u540e\u671f\u5347\u7ea7\u65f6\uff0c\u65b0\u7248\u672c\u81ea\u52a8\u517c\u5bb9\u65e7\u7248\u672c\uff0c\u6216\u8005\u4f7f\u7528\u524d\u81ea\u52a8\u8f6c\u5316\u6570\u636e\u3002\u5f53\u7136\uff0c\u539f\u5219\u4e0a\u662f\u80fd\u4e0d\u52a8\u5c3d\u91cf\u4e0d\u52a8\u3002\n\u591a\u8c22\u60a8\u7684\u56de\u7b54\uff01\n. The\u00a0perfect key solution is : in front of a content-related, followed by construction-related (reverse read) so that you do not need a delimiter.\n\u6700\u5b8c\u7f8e\u7684\u952e\u65b9\u6848\u662f:\u524d\u9762\u662f\u5185\u5bb9\u76f8\u5173,\u540e\u9762\u662f\u7ed3\u6784\u76f8\u5173\uff08\u5012\u5e8f\u8bfb\u53d6\uff09.\u8fd9\u6837\u5c31\u4e0d\u9700\u8981\u5206\u9694\u7b26\u4e86\u3002\n\u6211\u82f1\u8bed\u5b9e\u5728\u6e23\uff0c\u6015\u4f60\u770b\u4e0d\u61c2\uff0c\u8bd5\u7740\u540c\u65f6\u653e\u4e2d\u82f1\u6587\u3002\n. Yes, I'm using windows.\nI have installed mdb,github.com/szferi/gomdb\n but do not know what did not work\n. Document Error:\nHash: hclear, mhclear =\u300bhmclear\nList: lclear, mlclear =>lmclear\nSet: sclear, msclear=>smclear\nZset: zclear, mzclear=>zmclear\nBitmap: bclear, mbclear=>bmclear\n. http://godoc.org/github.com/siddontang/ledisdb/ledis\nno hexists\nHKeyExists :key\nHEXISTS : key and field \n. ``` golang\nfunc (db *DB) LSet(key []byte, index int32, value []byte) error {\n    if err := checkKeySize(key); err != nil {\n        return err\n    }\nvar seq int32\nvar headSeq int32\nvar tailSeq int32\n//var size int32\nvar err error\nt := db.listBatch\nt.Lock()\ndefer t.Unlock()\nmetaKey := db.lEncodeMetaKey(key)\n\nheadSeq, tailSeq, _, err = db.lGetMeta(nil, metaKey)\nif err != nil {\n    return err\n}\n\nif index >= 0 {\n    seq = headSeq + index\n} else {\n    seq = tailSeq + index + 1\n}\n\nsk := db.lEncodeListKey(key, seq)\n//\u627e\u5230\u4e86\u5bf9\u5e94\u7684key sk\n//v := it.Find(sk)\n//fmt.Printf(\"LSet sk=%d\\r\\n\", sk)\nt.Put(sk, value)\nerr = t.Commit()\nreturn err\n\n}\n. check index\n.\n// leither.go\npackage ledis\nimport (\n    \"fmt\"\n\"github.com/gpmgo/gopm/log\"\n\"github.com/siddontang/go/snappy\"\n\"github.com/siddontang/ledisdb/rpl\"\n\"github.com/siddontang/ledisdb/store\"\n\n)\ntype kType int\ntype Replay struct {\n    r   rpl.Log\n    f   func(r rpl.Log, key []byte) uint\n    ret uint\n}\nfunc (replay *Replay) Put(key, value []byte) {\n    //fmt.Printf(\"put k=%s r=%v\\r\\n\", key, replay.r)\n    replay.ret = replay.f(replay.r, key)\n    replay.r = nil\n}\nfunc (replay *Replay) Delete(key []byte) {\n    //fmt.Printf(\"Delete k=%s r=%v\\r\\n\", key, replay.r)\n    replay.ret = replay.f(replay.r, key)\n    replay.r = nil\n}\nfunc (l Ledis) Logs2Db(logs []rpl.Log) (lastID uint64, err error) {\n    fmt.Printf(\"Logs2Db len=%d\\r\\n\", len(logs))\n    for _, r := range logs {\n        fmt.Printf(\"Logs2Db old id =%d\\r\\n\", r.ID)\n        if r.Compression == 1 {\n            //todo optimize\n            if r.Data, err = snappy.Decode(nil, r.Data); err != nil {\n                fmt.Printf(\"decode log error %s\", err.Error())\n                return\n            }\n        }\n        var rl rpl.Log\n        rl, err = l.r.Log(r.Data)\n        if err != nil {\n            fmt.Printf(\"l.r.Log error %s\", err.Error())\n            return\n        }\n        fmt.Printf(\"Logs2Db new id =%d\\r\\n\", rl.ID)\n        var bd store.BatchData\n        if bd, err = store.NewBatchData(rl.Data); err != nil {\n            fmt.Printf(\"decode batch log error %s\", err.Error())\n            return\n        } else if err = bd.Replay(l.rbatch); err != nil {\n            fmt.Printf(\"replay batch log error %s\", err.Error())\n        }\n        log.Log(\"Logs2Db replay ok\")\n        l.commitLock.Lock()\n        if err = l.rbatch.Commit(); err != nil {\n            fmt.Printf(\"commit log error %s\", err.Error())\n        } else if err = l.r.UpdateCommitID(rl.ID); err != nil {\n            log.Error(\"update commit id error %s\", err.Error())\n        }\n    l.commitLock.Unlock()\n    if err != nil {\n        return\n    }\n    lastID = rl.ID\n    fmt.Printf(\"Logs2Db commit ok\\r\\n\")\n}\nfmt.Printf(\"Logs2Db end\\r\\n\")\nreturn\n\n}\nfunc (l Ledis) ProcessLog(log rpl.Log, f func(r rpl.Log, key []byte) uint) (ret uint, err error) {\n    if log.Compression == 1 {\n        if log.Data, err = snappy.Decode(nil, log.Data); err != nil {\n            fmt.Printf(\"decode log error %s\\r\\n\", err.Error())\n            return\n        }\n    }\n    replay := &Replay{\n        r: log,\n        f: f,\n    }\n    //fmt.Printf(\"ProcessLog replay %v \\r\\n\", replay)\n    var bd store.BatchData\n    if bd, err = store.NewBatchData(log.Data); err != nil {\n        fmt.Printf(\"decode batch log error %s\", err.Error())\n        return\n    } else if err = bd.Replay(replay); err != nil {\n        fmt.Printf(\"replay batch log error %s\", err.Error())\n        return\n    } else if replay.ret != 0 {\n        ret = replay.ret\n        return\n    }\n    return\n}\n//start end-1 \u7b80\u5355\u5904\u7406\n//end lastid \u5b8c\u5168\u5904\u7406\nfunc (l Ledis) ProcessLogs(startLogID, endLogId uint64, f func(r rpl.Log, key []byte) uint) (lid uint64, err error) {\n    fmt.Printf(\"startLogID=%d endLogId=%d\\r\\n\", startLogID, endLogId)\n    if !l.ReplicationUsed() {\n        err = ErrRplNotSupport\n        return\n    }\n    var firtID uint64\n    if firtID, err = l.r.FirstLogID(); err != nil {\n        return\n    }\n    if startLogID < firtID {\n        fmt.Printf(\"startLogID=%d, firtID=%d\\r\\n\", startLogID, firtID)\n        err = ErrLogMissed\n        return\n    }\n    //var  lastID uint64\n    //lastID, err = l.r.LastLogID()\n    //if err != nil {\n    //  return\n    //}\n    //if endLogId < lastID { //\u4e0d\u80fd\u8bf4\u660e\u4ec0\u4e48\u95ee\u9898\uff0c\u633a\u6b63\u5e38\u7684\u60c5\u51b5\n    //  fmt.Printf(\"\u53ef\u80fd\u5f53\u524d\u65e5\u5fd7\u672a\u5165\u5e93\uff0c\u5e94\u8be5\u5c11\u53d6\u4e00\u4e2a tbd %d<%d\\r\\n\", endLogId, lastID))\n    //}\nfor i := startLogID; i <= endLogId; i++ {\n    fmt.Printf(\"getlog i=%d\\r\\n\", i)\n    rl := &rpl.Log{}\n    if err = l.r.GetLog(i, rl); err != nil {\n        return\n    }\n    //fmt.Printf(\"processlog rl=%v\\r\\n\", rl)\n    var ret uint\n    if ret, err = l.ProcessLog(rl, f); err != nil || ret != 0 {\n        return\n    }\n    lid = i\n}\nreturn\n\n}\nfunc (l Ledis) RevProcessLogs(startLogID uint64, f func(r rpl.Log, key []byte) uint) (lid uint64, err error) {\n    if !l.ReplicationUsed() {\n        err = ErrRplNotSupport\n        return\n    }\n    var firtID, lastID uint64\n    if lastID, err = l.r.LastLogID(); err != nil {\n        return\n    }\nif startLogID > lastID {\n    fmt.Println(\"startLogID=%d, lastID=%d\", startLogID, lastID)\n    err = ErrLogMissed\n    return\n}\n\nif firtID, err = l.r.FirstLogID(); err != nil {\n    return\n}\n\nfmt.Printf(\"lastID=%d startlogid=%d firstID=%d\\r\\n\", lastID, startLogID, firtID)\nfor i := startLogID; i >= firtID; i-- {\n    rl := &rpl.Log{}\n    if err = l.r.GetLog(i, rl); err != nil {\n        return\n    }\n    var ret uint\n    if ret, err = l.ProcessLog(rl, f); err != nil || ret != 0 {\n        return\n    }\n    lid = i\n}\nreturn\n\n}\n```\n. ",
    "baotiao": "You can add a version number before the value, then use the operator like cas(check and set) to implement one key transaction.\n. \u4f60\u53ef\u4ee5\u8bd5\u8bd5 Pika \u8fd9\u4e2a\u9879\u76ee, \u6211\u4eec\u5bf9\u5e95\u4e0brocksdb \u505a\u4e86\u633a\u591a\u7684\u8c03\u6574.  https://github.com/Qihoo360/pika\n. @wangxingge   \u54c8\u54c8.. \u4f60\u53ef\u4ee5\u6d4b\u8bd5\u5bf9\u6bd4\u4e00\u4e0b. \u76ee\u524d\u6211\u4eec\u7ebf\u4e0a\u6709\u51e0\u767e\u4e2a\u5b9e\u4f8b, \u800c\u4e14\u6839\u636e\u633a\u591a\u5185\u90e8, \u5916\u90e8\u7528\u6237\u7684\u6d4b\u8bd5\u6548\u679c, \u6027\u80fd\u597d\u5f88\u591a\u7684. \n. ",
    "ShawnMilo": "You're welcome. I was happy to help. And I don't know any other language, so be proud of your English!\n. ",
    "iwanbk": "Thanks\n. i found the problem.\nIt caused by change in github.com/syndtr/goleveldb\nwe need to use git rev  871eee0a7546bb7d1b2795142e29c4534abc49b3\n. thanks\n. ",
    "libingbuaa": "From line 139 - line 144, variable names points to the begining of s.names, and s.names would have the file [n:end] after copy. So os.Remove will delete the files [n:n+num], not files[0:num]\n. ",
    "datastream": "No, last night I build a new version LedisDB (at commit 5534390b6b20ece96a3802794cbcbec1c15ed8cc). I'm testing it now. Maybe it will take a long time to reproduce the bug.\n. ",
    "spitfire2": "any progress of this? Redis compatibility is very important for us.\n. looks like qdb have no update for months and contributors are working on Tidb now. \n. ",
    "GlenDC": "I'm not sure if it's related. But there are quite some commands supported by Redis that aren't supported by Ledis. Would it be in the scope of this project, to support a lot more of the available redis commands?\nI do think that Ledis covers the most important commands, and have not yet run into a problem where I was missing a command that I have in Redis but not in Ledis. But perhaps it could be interesting to list which commands are missing, and describe how do-able adding each command would be.\nWhat do you think @siddontang?. Hi @siddontang a PR is open for this :) The unit tests pass, and I've also tested it manually with some stuff, and it all seems to hold up fine. Up to you to be the final judge of course.. Wow, that was fast, thanks @siddontang. I'm working on integrating github.com/yuin/gopher-lua right now. So you should see a (new) PR for that within the next 24 hours. As you accepted this PR, I'll also make sure to support both ledis and redis in that PR as a global var. Thanks once again \ud83d\udc4d . @siddontang oh no sorry, totally missed that Make target. Was manually updating the dependencies using the glide tool, and than copying them over to the _vendor folder. Will force update the PR, with the first commit replaced by a new commit.. @siddontang you were totally right, and thanks for providing that make target, I wish I had seen that earlier, hehe. The dependency commit is now last (instead for first), and contains indeed quite some files less, than the original first commit. Good for pointing that out!. @siddontang I also added support for CJSON, as that was also supported previously before. I think this PR is good to go now. Let me know what you think.. Thank you to @siddontang, for the fast responses, I really appreciate that.\nI agree that using Gopher-Lua is quite easy, compared to the CGO lua.\nI added and rebased the change you requested \ud83d\udc4d . Is this PR fine @siddontang, or do you require changes?. Sure it's possible. In our case we're not using the server though, and creating the App directly. Your proposes request does seem reasonable. What is the reason, if I may ask, that you would prefer to keep the server default? As it seems like a pretty randomly chosen port value, anyhow.. @siddontang I guess you mean 6379 and 6380, instead of 2379 and 2380. That does sound reasonable. I changed the only commit of this PR to reflect your request.\n@robvanmieghem I think allowing to set the (*Config).Addr property to the empty string is a better solution, as it doesn't add yet another property. Adding an extra property that serves to override the given config is a bit confusing, and adds another layer of indirection with no good reason IMHO. I was also thinking to provide a new constructor, but that would again override the existing (*Config).Addr property, which I think can be very confusing.\nExplicitly passing/assigning empty strings is a common thing to do in the Go STD As well, so therefore I went with the suggested approach of @siddontang.\n. Sure, but why break compatibility with redis? Surely we could merge those 2 commands, no? I don't see why they would need to be separate.. @siddontang I addressed your remarks.. Let me know if something else has to be done @siddontang :). Sure thing, I think it was there in the original code, but I'll remove it either way.\nThank you for responding so fast, appreciated as always! \ud83d\udcaf . Sure thing, I think it was there in the original code, but I'll remove it either way.. ",
    "popadi": "Regarding Redis/Ledis compatibility: is there a way to get all the keys using a regex/pattern? In Redis, there is the KEYS function that does that and I am wondering if the same behavior can be obtained using LedisDB. Right now, using the redis client connected to a ledisdb instance gives an error:\nclient.keys(\"domain*\", function (err, res) {\n    console.log(err, res);\n});\n=>\n{ ReplyError: command not found\n    at parseError (/home/adrianpop/test/node_modules/redis-parser/lib/parser.js:193:12)\n    at parseType (/home/adrianpop/test/node_modules/redis-parser/lib/parser.js:303:14) command: 'KEYS', args: [ 'domains*' ] }\nThanks!. Okay, thanks for the answer!. ",
    "coleifer": "Awesome thanks for the really quick reply. I can't think of a more complex Redis command, so I imagine you've got your work cut out for you! I'll keep an eye on this issue, and am glad to hear you're interested in trying to add something similar to LedisDB.\n. :+1: :100: \n. ",
    "arneto": "Hi Siddontang,\nThis absolutely fixes my issue.\nYour help is greatly appreciated.\nThanks and best regards,\nArne\n. Hi Siddontang,\nI changed in config conn_read_buffer_size = 102400.\nThis is more than needed, however the number of connections is limited and under our control.\nTested on real world sizes, and responses come in really fast - also in the real application.\nI will tune config conn_read_buffer_size to what is needed later.\nI have not run the ledis-benchmark.\nThanks for the advice and best regards,\nArne\n. ",
    "osiloke": "+1\nI guess you could save the field value as a key and then do a scan. i.e prefix_somekey_fieldname_value\nA scan like \nXSCAN prefix_*_fieldname_value\n. ",
    "jgoodall": "I would actually like to use this (with boltdb), but I dont see any documentation as to how. Trying to use ledis sorted sets with boltdb backend (for transactions) - is that even possible?\n. Using ledis within a go application, want to use transactions with sorted sets, something like this (pseudo code):\ntx := db.Begin()\na := tx.ZIncrBy(...)\nb := tx.ZRangeByScore(...)\ntx.Commit()\nI need to increment a set and then get the scores, and am accessing the sorted sets from multiple goroutines\n1. I dont see a way to do that in the boltdb API (only see put, get, delete) - am I missing something obvious?\n2. Is there a way to accomplish the above without using Locks?\nThanks. Ledis is a really nice package!\n. Is using go 1.3 still working?\nOn Mar 10, 2015, at 10:06 PM, siddontang notifications@github.com<mailto:notifications@github.com> wrote:\nHi @jgoodallhttps://github.com/jgoodall, I think this is not the problem for ledisdb only, but also for any other projects using cgo too, for cross compile.\nI try to rebuild a linux go version using sudo CGO_ENABLED=1 GOOS=linux GOARCH=amd64 ./make.bash --no-clean and then compile ledisdb, but it still fails with below error:\nruntime/cgo\nld: unknown option: --build-id=none\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\nI have no idea about how to fix it. LedisDB uses cgo in many places, not only in mdb. It may be a hard work to let it support cross compile.\nI think the only way now is to compile it in actual linux environment, not cross compile. :-)\nThank you.\n\ufffd\nReply to this email directly or view it on GitHubhttps://github.com/siddontang/ledisdb/issues/143#issuecomment-78187249.\n\nJohn Goodall  |  jgoodall@ornl.govmailto:jgoodall@ornl.gov  |  (865) 446-0611\nTeam Lead, Situation Awareness and Visual Analytics team\nCyber & Information Security Research group\nOak Ridge National Laboratory\n. Yes, that is exactly what I want to do: embed ledis and use boltdb or in memory backends only. So is adding a build flag something you are going to move towards?\nOn Mar 11, 2015, at 8:57 AM, siddontang notifications@github.com<mailto:notifications@github.com> wrote:\ngo 1.3 seems not work too for cross compile.\nI think a better way is to adding a build flag for ledisdb to disable cgo for cross compile, if you don't want to use cgo, you can not use leveldb, rocksdb and lmdb as the backend storage, can not use lua, and can not use ledis-cli.\nBut I guess you may embed ledis into your own project as a package, so disabling above feature does not matter.\n\ufffd\nReply to this email directly or view it on GitHubhttps://github.com/siddontang/ledisdb/issues/143#issuecomment-78257707.\n\nJohn Goodall  |  jgoodall@ornl.govmailto:jgoodall@ornl.gov  |  (865) 446-0611\nTeam Lead, Situation Awareness and Visual Analytics team\nCyber & Information Security Research group\nOak Ridge National Laboratory\n. I found a way to build the linux binary on OS X using the golang docker image and boot2docker.  Install docker (the client) and boot2docker (the linux vm) using brew:  brew install docker boot2docker. Then spin up a VM and use the 1.3 or 1.4.2 image to build the project that uses Ledis.\nboot2docker init\nboot2docker start\n$(boot2docker shellinit)\ndocker run --rm -v `pwd`:/go/src/github.com/<username>/<project> -w /go/src/github.com/<username>/<project> golang:1.4.2 go build -o <binary>_linux_amd64\nThis will mount the current directory as a volume in the container into the proper gopath (/go), use the official golang image, and build a binary called <binary>_linux_amd64. Not ideal, but at least a workable solution.\nThis solves my issue, so not sure if you want to keep this open or not...\n. I did not attempt to cross compile - only needed to build a linux binary on a Mac, and using the docker golang image that works fine.\nOn Mar 12, 2015, at 11:11 AM, siddontang notifications@github.com<mailto:notifications@github.com> wrote:\nHi @jgoodallhttps://github.com/jgoodall , golang docker image is linux based, so you can use it for your linux compile. I think this may be a better way for cross compile, e.g. if you want to build a windows version, you can use a windows docker too.\nBtw, do you build successfully using cross compile with latest ledisdb code?\n. ",
    "xyproto": "Could the maximum set size be doubled when it runs out of space, until it reaches maximum size? This way, people using small sets will have good performance and people using larger sets will not get an error?\n. ",
    "aegsea": "\u597d\u7684\uff0c\u8c22\u8c22\u3002\u6211\u7c97\u7565\u770b\u4e86\u4e0b\u4ee3\u7801\uff0cledisdb\u76ee\u524d\u8fd8\u6ca1\u6709\u4e3b\u4ece\u540c\u6b65\u7684\u8bbe\u8ba1\u662f\u5427\uff1f\n. ",
    "pyros2097": "I was thinking if we use cockroachdb, as at its core uses rocksdb you can directly connect its low level db functions to ledisdb and Maybe get the clustering, fault tolerance for ledisdb automatically\n. ",
    "ericnp": "+1, this would be very useful to me. And/or RESP 'SHUTDOWN' command\nbefore i saw this i created duplicate here with explanation of my motivation: https://github.com/siddontang/ledisdb/issues/154\nI'd be happy to work on this at your specification/guidance if you'd like.\n. Oh, damn, I missed notifications that you responded! That's awesome, thanks so much.\n. I'd like to work on the project if you could use my help. Which of the Issues are high priority that I could work on? I have github notifications turned on now :)\n. Closed: duplicate \n. ",
    "xiaoao": "yeah, how to config it in ledis.conf or other place\n. ",
    "akhenakh": "Run this code on your computer, empty db ! :)\n. No need for a bench this one ZRange takes 25.97s on a core i5 \n. Thank you!\n. Awesome, thank you\n. ",
    "uchti": "Leveldb, RocksDB (LSM tree) have problems to get value on very large volumes of data when data stored on deeper level, sophia does not have such problems. \n. ",
    "lethegit": "Thank you very much @siddontang\nBut I have another question: how to call a LEDIS command in Lua script ?Is there a method like REDIS.CALL?Sorry to trouble you ,but I have to say the documents about LEDIS are too few.... \n. ",
    "felixbuenemann": "@siddontang I have got lua 5.2 support working in my fork (see changes). If you're interested in integrating it, I could do a PR. I did not bother to keep 5.1 backwards compatibility, so my fork is 5.2 only.\n. And then use two different directories, like vendor/lua51 and vendor/lua52?\nMaybe if the modified golua lib was in it's own package, godeps could pick up a different version, depending on which lua version is detected?\nI'm no go developer, so I'm not sure if that's possible.\n. OK, I'm off to bed right now, but I'll give it a try tomorrow.\n. @unoexperto Do you have a specific need for LUA 5.3? Otherwise you could just install lua 5.1 and compile against it, on mac this can be done using brew install lua51.\n@siddontang While it's possible to use build tags and modified copies of golua with build tags to enable building against lua 5.1/5.2./5.3 (eg. lua51.go, lua52.go) it would probably be easier to just vendor a copy of the lua library. That's what redis is doing to (see redis/deps/lua).. @unoexperto I've rebased my lua-5.2 branch on top of the current master. You could try compiling it against lua 5.2.x. Compiling against lua 5.3.x would likely need more changes. If you are using homebrew on a mac you should probably update the dev.sh script to point to /usr/local/opt/lua instead if /usr/local/opt/lua51.\nI can't really test if it still works fine on current master, because the build environment is not working properly for me and I'm missing lots of go packages.. Why do you want to remove it?\n. If you don't want to support multiple lua versions, you could just specify the supported version in the README or vendor the lua sources like redis which also uses lua 5.1.\nEven if not all features possible in redis work in ledis, I think it's still a useful feature to have.\n. The /usr/local/opt/package symlink point to the packages versions directory in the cellar, eg. /usr/local/opt/leveldb points to ../Cellar/leveldb/1.18.\nUsing the opt paths makes sure you don't get any conflicts with files from other packages.\n. We could check for brew --prefix and use it, that way it would work with homebrew on mac or linux no matter what installation directory is used (there is an unofficial version of homebrew for linux).\n. OK, I've pushed a new version that checks if brew is installed and doesn't hardcode the prefix.\n. ",
    "unoexperto": "@felixbuenemann Have you had a chance to finish it ? I just attempted to build version with LUA 5.3 and hit same problem as you did.. @felixbuenemann Yes, I wanted to have bitwise operations for better implementation of base64 encoding. It was added to LUA 5.2.. @siddontang 1024. Could you please clarify what you mean by that ? ledis-server works well. I was also able to create dump with ledis-dump.\nBut the answer is probably yes. Directory structure is this\n```\ntotal 12\n4 drwxrwxr-x 4 expert expert 4096 Dec 16 14:20 data\n8 -rw-rw-r-- 1 expert expert 4175 Dec 16 11:35 ledisdb.conf\n``. Oh, so unlikeledis-dump,ledis-load` only works when  server is off ? I didn't realize that.\nBy the way is it possible to make dump of DB with one engine/compression and  then load it to DB with different engine ?. Thanks!. ",
    "ghost": "OK, then how this caching will work ? I think, my approach is something useful, that lpush lpop commands trigger incr +x/-x actions on metadata. \nwe will use a list meta size key\n\"will use\"? so, it's fullscan now?\n. however, after I rethink about my approach, ltrim can be problematic :) may it is better with delete/flush - set``\n. LRU with millons? well, so how about if we have a few millions list? pinterest uses millions of list data types with Redis, but it's not cost efficient for medium size web-apps. So, what performance we can expect from LedisDB using lists ?\n. I think, LedisDB is the only Redis list alternative out there. SSDB performance with lists is bad.\nAnd lists are used often in webapps. So, maybe in the future, you can pay attention to this feature as LedisDB already has HA. Pinterest may also interest with this, http://blog.pivotal.io/pivotal/case-studies-2/using-redis-at-pinterest-for-billions-of-relationships to cut some $$. :)\n. I don;t know how it's different _internally_ but benchmark results are very different from LedisDB, some operations perform much faster, some other perform slower. LPUSH / LRANGE example. I have a question. Why did you build this ? The reason is **distribution** ?\n. this one reminds me cockroachdb which is another newsql/nosql.\n. How can you handle all this stuff ? Is it not your effort too much ? :) you're playing with too many technologies. \n. Respect ! :) It seems like, you and your team gonna be famous in near future :) Tell me more about RebornDB, :) why and when we/developers should use rebornDB over LedisDB\n.Don't care too much about the benchmark too, it has not be updated for a very long time.`\nwhen we can see an updated benchmark of RebornDB :)\n1. install gorocks.a & levigo.a to GOPATH``\nI think it's storage is powered by leveldb and rocksdb, right?\n. Perfect ! how about it's license ? open source or some limited open source :)\n.I think you can create an issue in qdb, not here.`\nactually, our conversation turns to QA :) that's why I've changed the title, to make seo friendly. I'm really looking to see it in production. many promises & challenges in it :)\n. ",
    "techtonik": "But LegisDB is API compatible with Redis, no?\nI tried to use LegisDB from repository, but build uses bash scripts. Is it possible to have a cross-platform build toolchain?\n. My goal is basically to get http://python-rq.org/ working on Windows. I don't know what protocol does it use to talk with Redis, but I hope it is not as hard as getting Redis there.\nTo build LedisDB I tried:\n```\n\nset GOPATH=C:\\ledis\ngo get github.com/tools/godep\ngo install ./...\ncmd\\ledis-benchmark\\main.go:13:2: cannot find package \"github.com/siddontang/goredis\" in any of:\n    C:\\Program Files\\Go\\src\\github.com\\siddontang\\goredis (from $GOROOT)\n...\n```\n\nAnd a lot of messages like this. What else is needed?\n. It appears that no, can't use it. =)\n```\n\ngodep go install ./...\n'godep' is not recognized as an internal or external command,\noperable program or batch file.\n```\n. Ok. For Windows it is:\n\n```\n\n%GOPATH%\\bin\\godep go install ./...\n\ngithub.com/siddontang/ledisdb/server\nserver\\client_resp.go:175: undefined: syscall.Kill\ngodep: go exit status 2\n```\nStill no luck.\n. ```\ngithub.com/siddontang/ledisdb/server\nserver\\client_resp.go:11: imported and not used: \"syscall\"\n```\nCommented import too. Now godep worked well. Is that all?\n. ```\n\n%GOPATH%\\bin\\ledis-cli.exe \nPlease use linenoise to build again, or use redis-cli instead\n```\n\nHmm...\n. =/\nHow to test that it works then?\n. I mean how can I test that ledisdb is compiled successfully and works as expected?\n. Strange that there is no Go client to test access to ledisdb from different machines. May be later.\n. ",
    "insionng": "\u4f60\u6240\u8bf4\u7eafGo\u7248\u672c\u662f\u6307\u8fd9\u4e2a\u5417? github.com/siddontang/ledisdb/ledis\n. \u8fd9\u662f\u4e0d\u53ef\u80fd\u7684 \u56e0\u4e3a\u4f60\u7684\u76ee\u5f55\u91cc\u6ca1\u6709main\u6587\u4ef6\u5165\u53e3\n. insion@SATELLITE /E/gopath/src/github.com/siddontang/ledisdb (master)\n$ go install\ncan't load package: package github.com/siddontang/ledisdb: no buildable Go sourc\ne files in E:\\gopath\\src\\github.com\\siddontang\\ledisdb\n. \u597d\u5427 \u539f\u6765\"go install ./...\"\u662f\u4e00\u53e5\u5b8c\u6574\u7684\u547d\u4ee4. \u7b2c\u4e00\u6b21\u77e5\u9053\u8fd8\u6709\u8fd9\u7528\u6cd5.\n. \u597d\u7684 \u5df2\u7ecf\u5728\u7528redis-cli\u4e86,\u51c6\u5907\u5728\u4e00\u4e2a\u975e\u5e38\u590d\u6742\u7684\u7cfb\u7edf\u91cc\u7528ledisdb,\u5e0c\u671b\u5e26\u7ed9\u6211\u597d\u8fd0~\n. \u6211\u770b\u5230snapshot\u76ee\u5f55\u4e00\u76f4\u597d\u50cf\u662f\u7a7a\u7684\uff0c\u6240\u4ee5\u95ee\u95ee\u600e\u4e48\u7528\u4e0a\uff1f\n. \u5927\u6982\u660e\u767d\u4e86 \u8c22\u8c22~\n. \u5982\u679c\u80fd\u4e0d\u8003\u8651\u9057\u7559\u6570\u636e\uff08\u6211\u6253\u7b97\u5bf9\u65e7\u7684\u6392\u5e8f\u6570\u636e\u91cd\u7f6e\uff09\uff0c\u90a3\u4e48\u5e94\u8be5\u9488\u5bf9ledisdb\u54ea\u91cc\u8fdb\u884c\u6539\u52a8\u624d\u80fd\u652f\u6301float64\uff1f\n\u6216\u8005\uff0c\u53ef\u4ee5\u5728\u542f\u52a8\u68c0\u67e5\u914d\u7f6e\u6587\u6863\u91cc\u52a0\u4e2a\u652f\u6301float64\u7684\u5f00\u5173\uff0c\u9700\u8981\u7684\u540c\u5b66\u53ea\u8981\u8bbe\u4e86\u5c31\u53ef\u4ee5\u7528float64\uff0c\u4f60\u89c9\u5f97\u8fd9\u6837\u5982\u4f55\uff1f\n. \u597d\u5427 \u8fd8\u771f\u662f\u4e2a\u86cb\u75bc\u7684\u9057\u7559\u95ee\u9898  \u73b0\u5728\u53ea\u80fd\u5c06\u5c31\u7684\u8f6c\u6362\u540e\u5b58\u50a8\u4e86\n. ",
    "txchen": "thanks, will have a try!\n. ",
    "mmindenhall": "@Leither is correct...there does not appear to be an implementation for HEXISTS, despite it being in the list of supported commands.  Currently, the only way to determine whether a field exists within a hash is to fetch it via HGET:\ngo\n    myObj, err := ledisdb.HGet(myKey, myField)\n    if err != nil {\n        // handle error\n    }\n    if myObj == nil {\n        // does not exist\n    } else {\n        // exists\n    }\nI'd much rather just do this:\ngo\n    if ledisdb.HExists(myKey, myField) {\n        // exists\n    } else {\n        // does not exist\n    }\n. Just saw this...I'm using boltdb in the application I'm currently building.  Planning to be in production with it in a few weeks.\nI guess I'm confused about why you need separate transactions?  The boltdb readme says \"Each transaction has a consistent view of the data as it existed when the transaction started.\".  So it would seem that if you created a single read-write transation, you could both iterate and delete (per the comment above from Aug 7).  I assume I'm missing something here, so please let me know what the fix would entail.\n. ",
    "sirvon": "If I can be a bit nosey can @clangley @pkieltyka tell me why you chose this db over redis?\nthanks!\n. ",
    "leewardbound": "+1\nI found Ledis about 4 days ago -- My redis was exceeding 16GB and crashing a $200 server. I downloaded it at 10am, played with it until 10pm (load testing it up to 50GB dataset four times, excellent response speeds for my sparse dataset, no changes to my redis code, 0 errors and only 500mb RAM in use), implemented in production by 4am, monitored health until 8am, and since then I have been sitting by the pool. I know it'll take me 2 months to grow to 50GB and I'm confident I don't have to worry until then.\nTLDR: I switched my production machines to Ledis in less than a day, saved $150/mo on hardware, and solved my \"redis is crashing all the time\" problem. I feel good about it; where can I send a donation?\n. I would very much like to donate, to provide even more motivation.\n. ",
    "nsuper": "@linked How do you backup and restore your ledisdb? Does #176 resolved?. WTH with ledis-dump v0.5 ??? \nVersion: 0.5\n\n\nI must delete ${datadir}/snapshot folder\n\n\nStop ledis-server, because open ledis_server/snapshot/dmp-2017-08-31T12:59:36.198949448: no such file or directory\n\n\nRun ledis-dump. OK.\n\n\nTest add new data: ledis-cli:6380>set abc 123\n\n\nRun ledis-dump again. Oh no, it only copy old snapshot file, not found abc key!!!\n\n\nRepeat to the first step!!! Must delete ${datadir}/snapshot folder again!!! \n. \n\n",
    "darshan-ghumare": "$ make\ngodep go install -tags 'linenoise leveldb' ./...\nGodeps/_workspace/src/github.com/BurntSushi/toml/encoding_types.go:10:2: cannot find package \"encoding\" in any of:\n        /usr/src/pkg/encoding (from $GOROOT)\n        /home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/encoding (from $GOPATH)\n        /home/cloud/gocode/src/encoding\n        /home/cloud/gocode/bin/src/encoding\n        /home/cloud/gocode/pkg/src/encoding\n        /home/cloud/gocode/src/src/encoding\n        /home/cloud/prototypes/ledisdb/src/encoding\ngodep: go exit status 1\nmake: *** [build] Error 1\n. Thanks /siddontang.\n$GOPATH\n/home/cloud/gocode/:/home/cloud/gocode/bin:/home/cloud/gocode/pkg:/home/cloud/gocode/src:/home/cloud/prototypes/ledisdb\nGOROOT not set\ngo version\ngo version xgcc (Ubuntu 4.9.1-0ubuntu1) 4.9.1 linux/amd64\n. cloud@ubdesk1404:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb$ $GOPATH\n-bash: /home/cloud/gocode/:/home/cloud/gocode/bin:/home/cloud/gocode/pkg:/home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb:/home/cloud/prototypes/ledisdb: No such file or directory\ncloud@ubdesk1404:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb$ make\ngodep go install -tags 'linenoise leveldb' ./...\nGodeps/_workspace/src/github.com/BurntSushi/toml/encoding_types.go:10:2: cannot find package \"encoding\" in any of:\n        /usr/lib/x86_64-linux-gnu/go/4.9/src/pkg/encoding (from $GOROOT)\n        /home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/encoding (from $GOPATH)\n        /home/cloud/gocode/src/encoding\n        /home/cloud/gocode/bin/src/encoding\n        /home/cloud/gocode/pkg/src/encoding\n        /home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb/src/encoding\n        /home/cloud/prototypes/ledisdb/src/encoding\ngodep: go exit status 1\nmake: *** [build] Error 1\n. Hi siddontang,\nThats what I did.\n$ $GOROOT\n/usr/lib/x86_64-linux-gnu/go/4.9/: Is a directory\ncloud@ubdesk1404:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb$ make\ngodep go install -tags 'linenoise leveldb' ./...\nGodeps/_workspace/src/github.com/BurntSushi/toml/encoding_types.go:10:2: cannot find package \"encoding\" in any of:\n        /usr/lib/x86_64-linux-gnu/go/4.9/src/pkg/encoding (from $GOROOT)\n        /home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/encoding (from $GOPATH)\n        /home/cloud/gocode/src/encoding\n        /home/cloud/gocode/bin/src/encoding\n        /home/cloud/gocode/pkg/src/encoding\n        /home/cloud/prototypes/ledisdb/src/github.com/siddontang/ledisdb/src/encoding\n        /home/cloud/prototypes/ledisdb/src/encoding\ngodep: go exit status 1\nmake: *** [build] Error 1\n. Thanks.\nNow, not able to find ledis-server\n$ ledis-server\nNo command 'ledis-server' found, did you mean:\n Command 'redis-server' from package 'redis-server' (universe)\nledis-server: command not found\n. Thank you so much siddontang.\n. With RocksDB\nroot@Machine3:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb# /root/prototypes/ledisdb/bin/ledis-benchmark -port=6380 -vsize=4096 -t=\"set\"\nset: 51.073598ms 51.073 micros/op, 19579.59op/s\nroot@Machine3:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb# root/prototypes/ledisdb/bin/ledis-benchmark -port=6380 -vsize=4096 -t=\"set\" -n=3000\n-bash: root/prototypes/ledisdb/bin/ledis-benchmark: No such file or directory\nroot@Machine3:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb# /root/prototypes/ledisdb/bin/ledis-benchmark -port=6380 -vsize=4096 -t=\"set\" -n=3000\nset: 118.286611ms 39.429 micros/op, 25362.13op/s\nroot@Machine3:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb# /root/prototypes/ledisdb/bin/ledis-benchmark -port=6380 -vsize=8192 -t=\"set\" -n=3000\nset: 139.347168ms 46.449 micros/op, 21528.96op/s\nroot@Machine3:~/prototypes/ledisdb/src/github.com/siddontang/ledisdb# /root/prototypes/ledisdb/bin/ledis-benchmark -port=6380 -vsize=65536 -t=\"set\" -n=3000\nset: 1m3.72185611s 21240.619 micros/op, 47.08op/s\nIs it possible to get 10K IOPS for value size from 4K to 128K?\n. Following is my setup,\n1. FIO with following parameters, ioengine=psync, iodepth=32, bs=4k,\n   number_ios=1000000, rw=randwrite, direct=1, fsync_on_close=1\n2. Runs FIO on Ubuntu 14.04 VM created on QEMU-KVM.\n3. I have written QEMU block driver which will trap FIO IOs on disk and\n   forward it to LedisDB using hiredis APIs.\nFollowing are my observations,\n1. With 4K block size I got 5.4K IOPS.\n2. With 8Kblock size I got 3K IOPS.\n3. IOPS this way drops down to 1-3 IOPS when I start increasing block\n   size eventually.\nPlease help.\nOn Mon, Aug 24, 2015 at 9:27 AM, siddontang notifications@github.com\nwrote:\n\n128k seems too large. 4k seems having an acceptable performance.\nI don't know why goleveldb has the terrible performance, I will check it\nagain and contact the author.\nWhat's your scenario for data saving, if you have lots of data with big\nsize (64k or 128k), I don't think ledisdb can fit your need.\nThank you.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/siddontang/ledisdb/issues/179#issuecomment-134015709.\n\n\nDarshan\u00ae\n. ",
    "chzyer": "I will recommend the library I'm working on: https://github.com/chzyer/readline ;)\nIt works well on darwin/linux/windows, and bring us the zsh-style-readline user experience.\n. ",
    "zaibon": "Is boltdb already removed from the supported backend ?\nledis-server -db_name boltdb    \nno config set, using default config\nstore boltdb is not registered\n. ",
    "bittoy": "\u7406\u8bba\u4e0a\u6211\u7684\u7406\u89e3\u662f\u8fd9\u6837\u7684\uff0c\u5f53\u6211\u7ed9key\u8bbe\u7f6e\u8fc7\u671f\u65f6\u95f4\u65f6\uff0c\u5f53\u8d85\u8fc7\u8fc7\u671f\u65f6\u95f4\u6b64key\u4f1a\u88ab\u5220\u9664\uff0c\u90a3\u4e48\u4fdd\u5b58\u5176\u4fe1\u606f\u7684ldb\u6587\u4ef6\u4e2d\u4e5f\u4f1a\u5220\u9664\u6b64\u6761\u6570\u636e\uff0c\u4e0d\u7136\u7684\u8bddldb\u6587\u4ef6\u4f1a\u4e00\u76f4\u589e\u957f\u4e0b\u53bb\n. \u597d\u7684\uff0c\u8bf7\u95ee\u9600\u503c\u662f\u5728\u4ec0\u4e48\u5730\u65b9\u53bb\u67e5\u770b\u4e0e\u8bbe\u7f6e\u7684\n. \u77e5\u9053\u4e86\uff0c\u975e\u5e38\u611f\u8c22\n. ",
    "defia": "i found that i made a mistake\n. ",
    "ukd1": "@siddontang I'm working on it now, I'll open a WIP PR - would love your comments on my implemenation\n. Yay! Thanks @siddontang \n. FYI, this does not support auth for HTTP, as I not need it personally. I can add if it's really required.\n. @siddontang that should be fixed; added some docs too :+1: \n. @siddontang ok, I've fixed the is_authed --> isAuthed :+1: \n. Sure, no problem.\n. Heheh ok - as mentioned, I'm a go newb. Fixing.\n. ",
    "luren5": "@siddontang \u6211\u4e5f\u9047\u5230\u4e86\u540c\u6837\u7684\u95ee\u9898. ",
    "ketor": "Thank you for reply.\nWhat I focus on is the Redis protocol compatibility between SSDB and ledisdb. Because many redis db instances will migrate to disk db like ledisdb or SSDB, and I am researching redis disk db choices.When I find ledisdb, I feel incredible. But it is hard to see if there is a clear evaluation criteria between SSDB and ledisdb.\nIf you could able to explain more about the Redis protocol  compatibility between SSDB?\n. ",
    "FlamingTree": "why? I just need buffer multi commands and send all buffer once, and recv response repeatly. is there problem?\n. I understand. redis's so-call pipelined seem to be client behaviour too, right?\n. thanks~\n. https://github.com/siddontang/ledisdb/blob/master/ledis/ledis.go#L174-L179  here is problem, flushall clear commit id and logid, but slave node doesn't clear. is it known problem?\n. I read flushall command implementation, found it does not log deletion write, nor send flushall command to slave, but it clean master's logid, cause master's logid less than slave's. maybe better solution is send flushall to slave, but i don't know how to~\n. https://github.com/FlamingTree/ledisdb/commit/f781c8e9d8fd088c2fc7d96ae39a7713130be86e  I try to fix it. I will send a PR if it's ok. but it's insignificant because rarely use.\n. https://github.com/siddontang/ledisdb/blob/master/Godeps/_workspace/src/github.com/siddontang/go/log/log.go#L268 I reconfirmed\n. ",
    "leedstyh": "\u6211\u662f\u76f4\u63a5\u628aconfig\u6587\u4ef6\u5939\u91cc\u90a3\u4e2a.toml\u6587\u4ef6cp\u8fc7\u6765\uff0c\u5c31\u6539\u4e86\u4e0b\u91cc\u9762\uff0c\u8bbe\u7f6e\u6210rocksdb\uff0c\u4f46\u662f\u8fd0\u884c\u8bf4rocksdb\u6ca1\u6709\u6ce8\u518c\u3002\n\u6211\u6ca1\u6709\u5728lediadb\u91cc\u6267\u884cmake\uff0c\u6211\u60f3\u5d4c\u5165\u5f0f\u7684\u4f7f\u7528\u4e0d\u9700\u8981\u8fd9\u6b65\u5427\n. \u54e6\u597d\u7684\u6211\u518d\u8bd5\u8bd5\uff0c\u8fd8\u6709\uff0c\u8fd9\u4e2a\u5d4c\u5165\u5f0f\u4f7f\u7528\uff0c\u662f\u4e0d\u662f\u6211\u7684\u7a0b\u5e8fgo build\u540e\u628a\u4e8c\u8fdb\u5236\u4ecd\u5230\u670d\u52a1\u5668\u5c31\u884c\uff0c\u670d\u52a1\u5668\u4e0d\u9700\u8981\u5b89\u88c5\u4efb\u4f55\u4e1c\u897f\u4e86\n. \u6211\u8bd5\u4e86\u4e0b\uff0c\u5b89\u88c5\u4e86rocksdb\uff08\u6309\u63d0\u4f9b\u7684\u90a3\u4e2a\u94fe\u63a5\uff0cmake shared_lib\uff09\n/usr/local/include\u548c/usr/local/lib\u90fd\u6709\n\u7136\u540e\u7528\u7684go build -tags \"rocksdb\" t.go\u7684\u65b9\u5f0fbuild\u4e86\uff0c\u4f46\u662f\u8fd0\u884c\u7684\u65f6\u5019\u51fa\u9519\uff0c\u4fe1\u606f\u5982\u4e0b\uff1a\nerror while loading shared libraries: librocksdb.so.4.2: cannot open shared object file: No such file or directory\n. \u662f\u7684\uff0c\u662f\u5728/usr/local/lib\nhttp://lizh.me/files/rocksdb.png\n. \u73b0\u5728\uff0c\u6211\u5728.profile\u91cc\u6dfb\u52a0\u4e86export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/lib\uff08\u662f\u8fd9\u6837\u6dfb\u52a0\u5427\uff0c\u73b0\u641c\u7d22\u7684\uff09\n\u6b63\u5e38\u8fd0\u884c\u4e86\u3002\n\u5b66\u5230\u4e86\u4e0d\u5c11\u65b0\u4e1c\u897f\uff0c\u4e0d\u8fc7\u611f\u89c9\u7528\u8d77\u6765\u4e0d\u592a\u65b9\u4fbf\u5462\n. ",
    "captncraig": "Nevermind. I was able to do what I need with LMCLEAR\n. ",
    "FanyuxiNIE": "I meet some problem like yours,do you mean how to slove?what is LMCLEAR?. \u80fd\u5426\u6253\u4e00\u4efd\u6b63\u786e\u7684build\u6587\u4ef6. ",
    "wangfx": "\u6211\u60f3\u57fa\u4e8eledisdb\u5f00\u53d1\u4e2a\u5206\u5e03\u5f0f\u6570\u636e\u5e93\uff0c\u662f\u8fd9\u4e48\u60f3\u7684\uff1a\n1\u3001\u4e3b\u8981\u4f7f\u7528rocksdb\u5b58\u50a8kv\n2\u3001\u4e3b\u8981\u4f7f\u7528lmdb\u5b58\u50a8zset\n\u6709\u89c4\u5f8b\u7684\u751f\u6210key\uff0c\u907f\u514drocksdb\u6df1\u5ea6\u6392\u5e8f\uff0ckey\u503c\u751f\u6210\u7684\u60f3\u6cd5\u5982\u4e0b\uff1a\nxxxx00111nxa1234567\nxxxx \u6bcf\u5341\u5929\u4e00\u4e2a\u8ba1\u6570\u7684\u65f6\u95f4\u503c\n00  \u96c6\u7fa4\u6807\u793a\uff0c\u6700\u59273844\n111 slot\u6570\u6700\u59271000\uff0c\u7528\u4e8e\u6570\u636e\u8fc1\u79fb\uff0c\u6bcf\u4e2a\u96c6\u7fa4\u4e3b\u673a\u6570,\u6700\u59271000\nn   \u4e00\u7ea7\u547d\u540d\u7a7a\u95f4\u5206\u7c7b \u6700\u592762\nx   \u4e8c\u7ea7\u547d\u540d\u7a7a\u95f4\u5206\u7c7b \u6700\u592762\na   \u6570\u636e\u7c7b\u578b\n1234567  \u57fa\u4e8exxxx00111n\u751f\u6210key\u5e8f\u5217\u53f7\n\u8fd9\u6837\u907f\u514drocksdb\u6df1\u5ea6\u6392\u5e8f\uff0c\u5229\u7528lmdb\u7684zset\u7684range*\u6027\u80fd\uff0clmdb\u76f8\u5f53\u4e8e\u4e00\u4e2arocksdb\u7684\u7d22\u5f15\u5e93\uff1b\n\u8bf7\u6307\u6559\uff01\uff01\uff01\n. ",
    "jan4984": "\u770b\u770b\u8fd9\u4e48\u6539\u6709\u6ca1\u6709\u95ee\u9898 https://github.com/siddontang/ledisdb/pull/206\n. \u4f46\u662f\u6709Pop\u6389\u554a\u3002\u6bd4\u5982MySQL\uff0c\u6709insert\u6709delete\uff0c\u5360\u7528\u7a7a\u95f4\u5728\u4e00\u5b9a\u9608\u503c\u662f\u4f1a\u56de\u6536\u7684\u624d\u5bf9\u3002\n. \u795e\u4e86\uff0cLPush RPop\u6ca1\u95ee\u9898\uff0cRPush LPop\u5185\u5b58\u8f70\u8f70\u8f70\u7684\u6da8\uff0c\u540c\u6837\u4ee3\u7801\u3002\n\u80af\u5b9a\u54ea\u513f\u6709bug\uff0c\u6211\u770b\u4e86\u534a\u5929\uff0c\u6539\u4e0d\u6765\uff0cDB\u592a\u590d\u6742\u4e86...\n. \u5f88\u5feb\u5c31\u80fd\u5230g\u7ea7\u522b\u2026\n. \u5982\u679c\u6211\u6ca1\u7406\u89e3\u9519\u7684\u8bdd\uff0c\u597d\u50cf\u4e0d\u5bf9\u3002\n\u6211\u52a0\u4e86\u6253\u5370\u6d88\u606f\uff0clpush/rpop\u548crpush/lpop\u90fd\u4f1a\u5bfc\u81f4seq\u4e0d\u505c\u5de6\u79fb\u6216\u53f3\u79fb\u3002\u540c\u65f6t.Delete(itemKey)\u4e5f\u662f\u8ddf\u7740\u4e00\u76f4\u79fb\u52a8\u3002\u4e5f\u5c31\u662f\u8bf4head/tail/meta\u8fd93\u4e2akey\u5728\u4e24\u79cd\u64cd\u4f5c\u4e0b\u90fd\u662f\u4e00\u76f4\u53d8\u5316\u7684\uff0c\u6240\u4ee5\u4e0d\u662f\u5f88\u786e\u5b9a\u4f60\u8bf4\u7684index\u8bd5\u4e0d\u662f\u6307\u4fdd\u5b58list\u7ed3\u6784\u7684\u8fd93\u4e2akey\u3002\n. \u8fd9\u4e24\u5929\u53c8\u8dd1\u4e86\u51e0\u6b21\uff0c\u8fd9\u4e2a\u95ee\u9898\u8fd8\u4e0d\u662f\u5f88\u786e\u5b9a\u3002\u53ef\u4ee5\u786e\u5b9a\u7684\u662fLpush/Rpop\u6bd4Rpush/LPop\u5360\u7528\u5185\u5b58\u4f1a\u4f4e\u5f88\u591a(\u50cf\u8fd9\u91cc\u8d34\u7684\u4ee3\u7801\u4f1a\u591a\u51e0\u767eMB-top\u547d\u4ee4\u770bRES)\u3002\u4e0d\u8fc7\uff0c\u6700\u7ec8\u5360\u7528\u90fd\u662f\u7a33\u5b9a\u7684\u3002\u6240\u4ee5\u4e0d\u7b97\u662f\u4ec0\u4e48\u592a\u5927\u7684\u95ee\u9898\u5427\u3002\n. ",
    "nikolay-turpitko": "Thx, guys, that one works!\nTested on Ubuntu 14.04.3 LTS, GNU bash, version 4.3.11(1)-release.\n. Well, don't know how to fix it then. May be just add something like read -n1 -rsp $'Press any key to exit...\\n' before exit to let user read the message before window disappears?\n. Well, I placed confirmation before exit like\n```\nLEDISTOP sanity check\nif [[ \"$LEDISTOP\" == \"${LEDISTOP/\\/src\\/github.com\\/siddontang\\/ledisdb/}\" ]]; then\n    echo \"WARNING: LEDISTOP($LEDISTOP) does not contain src/github.com/siddontang/ledisdb\"\n    read -n1 -rsp $'Press any key to exit...\\n'\n    exit 1\nfi\n```\nWhen project placed in the wrong dir it give me a chance to read message before exit and close terminal window. In the right place it works as usual. Sorry, if I misunderstand your question. \n. Yes, this works perfectly in Ubuntu!\n. It seems, that script eventually works:\nredis ledisdb.socket> EVAL \"ledis.call('set', 'answer', 42)\" 0\n(nil)\nredis ledisdb.socket> get answer\n\"42\"\nBut when I invoke script from app via redigo there is some issue. They have:\nhttps://github.com/garyburd/redigo/blob/master/redis/script.go#L62\nfunc (s *Script) Do(c Conn, keysAndArgs ...interface{}) (interface{}, error) {\n    v, err := c.Do(\"EVALSHA\", s.args(s.hash, keysAndArgs)...)\n    if e, ok := err.(Error); ok && strings.HasPrefix(string(e), \"NOSCRIPT \") {\n        v, err = c.Do(\"EVAL\", s.args(s.src, keysAndArgs)...)\n    }\n    return v, err\n}\nAnd you return: https://github.com/siddontang/ledisdb/blob/81381343f881670b41762e7eff0f4f4b7ac6eb9c/server/cmd_script.go#L80\nif evalSha1 {\n    return fmt.Errorf(\"missing %s script\", key)\n}\nThere is no \"NOSCRIPT \" in your error description, so their logic won't work. Not a big deal, I'll try to preload script, but if you wish, you may add this string to make it more convenient for redigo users.\n. And please add to doc that your global object is \"ledis\" not \"redis\" ;-)\n. I have to reopen this issue, cause I think I find what was wrong with the first example. This one works:\nredis ledisdb.socket> eval \"return ledis.call('echo', 'zzz')\" 0\n\"zzz\"\nBut this one - does not:\nredis ledisdb.socket> EVAL \"return ledis.call('ECHO', 'zzz')\" 0\n(error) command not found\nRedis works with both upper and lower case.\n. I think, these should be documented in the EVAL command description as a deviations from Redis (at least):\n- global object name: redis -> ledis\n- command names in the ledis.call() are case sensitive (lowercase accepted only)\n- ledis.call('hmget', ...) returns empty strings instead of boolean for absent keys (see #219)\n- EVALSHA command returns error message without \"NOSCRIPT \" prefix, so redigo users should preload script explicitly\n. Checked with redis-cli, command names are no longer case sensitive.\nComments added to Lua script-related commands. Fixed.\n. Checked version from master with redis-cli. Works as Redis.\n. I removed comments from the script.go and commented unit tests for resp writer. So, if you OK with both, please merge them from one PR, I'd rather not spend a time to split it. Thanks.\n. yep\n. ",
    "anolek": "Hi,\nYes, everythings works, but i have to edit the file ./vendor/lua/lua.go and change this line \n#cgo LDFLAGS: -llua\nto\n#cgo LDFLAGS: -llua5.1\n. I use apt-get like this apt-get install lua5.1 lua5.1-dev\n. It works on Ubuntu 14.04.3 and CoreOS :+1: \nMaybe we can run multiple build on multiple OS with Travis ? :-)\n. ",
    "q1101151": "\u95ee\u9898\u89e3\u51b3\u4e86\n. \u90a3\u5982\u679c\u6211\u60f3\u5199\u4e8b\u52a1  \u8fd8\u6709\u4ec0\u4e48\u529e\u6cd5\uff1f\n. ",
    "sotoup": "Thanks for your reply\nI found a solution\nexport GO15VENDOREXPERIMENT=0\nmake clean\nmake build_lmdb\n. Although compile passed, ledisdb with lmdb don't work. \nbecause gomdb don't work with go1.6\nerror below:\ncgo argument has Go pointer to Go pointer\n. I really wish to help you with it, but I'm sorry I'm not familiar with golang\nI had switch to go1.5\n. ",
    "agnibha": "We have a LedisDB which we fill using a RocksDB snapshot. When we do a ledis-load on a ledisDB instance, we can get the data using the CLI.\nWhen we use xcodis to be the proxy for this ledis instance, we can't fetch the keys using the proxy.\nIs there a way we can restore the snapshot with xcodis proxy in place?\n. Okay. I get it. I have a read-only use-case, which can expand to read-write later.\nSo, if we reverse-engineer our code to write the data to index = hash(key) % 1024, can we then use xcodis to fetch data for us?\n. Also, is there a way of using a snapshot to fill data into a cluster of ledisdb's?\n. Thanks @siddontang for all the help.\n. ",
    "kwojtaszek": "Isn't that proper library: https://github.com/bmatsuo/lmdb-go ? It looks like lmdb has better performance on Sorted Sets and Lists operations\n. ",
    "jieniu": "\u627e\u5230\u539f\u56e0\u4e86\u3002$GOROOT\u5bf9\u5e94\u4e0d\u4e0a\n. ",
    "jrudio": "So the issue is that it's hard to update all the keys after b?\nI attempted to do something like LREM, but could only remove 1 occurrence, anymore and my tests wouldn't pass. \nHere's my mockup LRemOnce and the tests for it\nDo you see any potential issues with LRemOnce?\n. Very true!\n. ",
    "wangxingge": "@baotiao \u6211\u53bb\u770b\u4e00\u4e0b\u3002\u3002\u3002\n. \u7528ledis\u8fd8\u6709\u4e00\u4e2a\u539f\u56e0\u662f\u7528go\u5199\u7684\u3002\u3002\u3002\u3002\u3002 \n@siddontang ledis \u6709\u6ca1\u6709\u6211\u8bf4\u7684\u90a3\u4e2a\u95ee\u9898\u554a\uff1f\n. \u8c22\u8c22\u554a\u3002\u6211\u5728\u60f3\u60f3\u3002\n@baotiao \u90a3Pika \u4e5f\u662f\u8fd9\u6837\u7684\u55bd\uff1f\n. ",
    "wxf4150": "```\npackage main\nimport (\n\"github.com/siddontang/ledisdb/store/driver\"\n \"github.com/siddontang/ledisdb/store/rocksdb\"\nlediscfg \"github.com/siddontang/ledisdb/config\"\n\"github.com/siddontang/ledisdb/ledis\"\n\"log\"\n\n)\nfunc main(){\n    println( driver.ListStores())\n    println( rocksdb.DBName)\n    //# Use Ledis's default config\n    cfg := lediscfg.NewConfigDefault()\n    cfg.DBName=\"rocksdb\"\n    //cfg.DBName=\"goleveldb\"\n    cfg.Databases=16\n    l, err := ledis.Open(cfg)\n    if err!=nil{\n        log.Println(err)\n        return\n    }\n    db, _ := l.Select(0)\nkey:=[]byte(\"test1\")\nvalue:=[]byte(\"test1 value\")\ndb.Set(key, value)\n\nvaluer,_:=db.Get(key)\nlog.Println(string(valuer))\n\n}\nfunc init() {\n    println(\" main init\",rocksdb.DBName)\n}\n```\ni use Package Example\nit build succese. \nwhen run will throw error  at     l, err := ledis.Open(cfg)\ni am not good at cgo.  i will  do more try and learn.\ni found files in package github.com/siddontang/ledisdb/store/rocksdb \nhave this  code  \"//+build rocksdb\" in the first line; the init() will not run.\n. thank you .\ngive some more help\n\"error while loading shared libraries: librocksdb.so.4.9\"\n```\nwxf@dell:~/go/src/rocks$ ls /usr/local/rocksdb/librocksdb.so*\n  /usr/local/rocksdb/librocksdb.so    /usr/local/rocksdb/librocksdb.so.4.9\n /usr/local/rocksdb/librocksdb.so.4  /usr/local/rocksdb/librocksdb.so.4.9.0\nwxf@dell:~/go/src/rocks$ ls /usr/local/rocksdb/include/\n  rocksdb\nCGO_CFLAGS=\"-I/usr/local/rocksdb/include\" CGO_CXXFLAGS=\"-I/usr/local/rocksdb/include\"  \\\nCGO_CXXFLAGS=\"-I/usr/local/rocksdb/include\" CGO_LDFLAGS=\"-L/usr/local/rocksdb -lrocksdb\" \\\n go build -tags \"rocksdb\"\u3000\nthe build succes\nwxf@dell:~/go/src/rocks$ ./rocks \n   ./rocks: error while loading shared libraries: librocksdb.so.4.9: cannot open shared object file: No such file or directory\n```\ni use use rocksdb4.9 .    compile with \"make shared_lib\"; when compile finish,   librocksdb.so.4.9 is under \"/usr/local/rocksdb\"  not under \"/usr/local/rocksdb/lib\".\n. ln -s  /usr/local/rocksdb/librocksdb.so.4.9.0 /usr/local/lib/librocksdb.so.4.9\necho $LD_LIBARARY_PATH \n\u3000/usr/local/lib:/usr/local/rocksdb\ni had set LD_LIBARARY_PATH . and the error still.\ni will try more.\n. LD_LIBARARY_PATH  should be LD_LIBRARY_PATH\nwxf@dell:~/go/src/rocks$ export LD_LIBRARY_PATH=/usr/local/lib:/usr/local/rocksdb\nwxf@dell:~/go/src/rocks$ echo $LD_LIBRARY_PATH \n/usr/local/lib:/usr/local/rocksdb\nthen the programe excute succes!\nthank you!\n. \u6211\u8be6\u7ec6\u6d4b\u8bd5\u4e86\u4e0b\uff0c\u5e94\u8bd5\u6b63\u5e38\u5199\u5165\uff0c\u662f\u6211\u641e\u9519\u4e86\u3002 \n\u6d4b\u8bd5\u4e2d\u53d1\u73b0\uff1a\n\u76f8\u6bd4\u4f7f\u7528Lib\u7684 \u65b9\u5f0f \uff0c \u7528ledis-server \u4f1a\u5360\u7528\u4e0d\u5c11\u5185\u5b58\uff082-3G\u5de6\u53f3\uff09\uff0c\u8fd9\u662f\u6b63\u5e38\u7684\u5417\uff1f\n\n\u5199\u4e8620GB \u6570\u636e\uff0c\u673a\u68b0\u786c\u76d8\u3002\n\u5199\u7684\u6587\u4ef6\u6bd4\u8f83\u5927\u3002\nledis_server buffer\u8981\u8bbe10M \uff1b\u8981\u4e0d\u7136\u4f1a\u51fa\u9519\u3002\n   conn_read_buffer_size = 10240000\n   conn_write_buffer_size = 10240000\n\u7528github.com/go-redis/redis \u8fde\u63a5\u6d4b\u8bd5\u7684\uff0c\u6d4b\u8bd5\u65f6\u589e\u52a0redisClient \u7684\u8d85\u65f6\u4e3a10\u79d2\u3002\n\u53ef\u80fd\u673a\u68b0\u786c\u76d8\u6162\u7684\u539f\u56e0\uff0c\u6d4b\u4e00\u6bb5\u65f6\u95f4\u8fd8\u662f\u4f1a\u51fa\u8fd9\u6837\u7684\u9519 (net.TCPAddr)(0xc4203b4600), Err:(net.timeoutError)(0xd35820)}\n\u6d4b\u8bd5\u4ee3\u7801\u5982\u4e0b\uff0c\uff1a\n`func Test_Ledis_Server(t *testing.T){\n    //bs,err:=ioutil.ReadFile(\"/home/wxf/\u4e0b\u8f7d/rocksdb-5.7.2.tar.gz\") //\u5927\u6587\u4ef63865045Byte(3.9M) \n    bs,err:=ioutil.ReadFile(\"/home/wxf/\u4e0b\u8f7d/a.jpg\") //\u5c0f\u6587\u4ef6234680 Byte(234K) \n    assert.Equal(t,nil,err,\"\u6587\u4ef6\u6ca1\u6709\u6b63\u5e38\u8bfb\u53d6\")\nallbs:=0\nfor i:=0;i<1024*15*1000;i++{\n    gbs:=allbs/1024/1024/1024\n    if gbs>22{ //\u6700\u591a\u8bd5\u523022G\n        t.Log(\"\u603b\u5171\",strconv.Itoa(gbs),\"GB count:\",i+1)\n        break;\n    }\n    err:= RClient.HSet(\"testfile3\",strconv.Itoa(i),bs).Err()\n    assert.Equal(t,nil,err,\"ledis_server insert\u9519\u8bef:\",\"writeSize:\",gbs,\" writeCount:\",i)\n    allbs+=234680\n\n}\nt.Log(\"insert finish\")\n\n}\n`. ",
    "a651694192": "\u6211\u660e\u767d\u554a\u3002 \u4e0d\u662f\u5355\u673a\u554a\u3002 ledisdb\u4e0d\u662f\u652f\u6301\u5206\u5e03\u5f0f\u96c6\u7fa4\u5417\uff1f \u90a31PB\u4e5f\u4e0d\u53ef\u80fd\u5417\uff1f\n. \u8fd8\u6709\u5f53ledisdb\u589e\u52a0\u8282\u70b9\u65f6\uff0c\u4f1a\u5bf9\u4e1a\u52a1\u6709\u5f71\u54cd\u5417\uff1f\n. ",
    "CocaCola183": "@perfgao \u4e0d\u77e5\u9053\u4f60\u8bf4\u7684\u9650\u5236\u662f\u4e0d\u662f\u4e0b\u9762\u8fd9\u4e9b\n```go\nconst (\n    MaxDatabases int = 10240\n//max key size\nMaxKeySize int = 1024\n\n//max hash field size\nMaxHashFieldSize int = 1024\n\n//max zset member size\nMaxZSetMemberSize int = 1024\n\n//max set member size\nMaxSetMemberSize int = 1024\n\n//max value size\nMaxValueSize int = 1024 * 1024 * 1024\n\n)\n```\n\u6e90\u7801\u4e2d\u6709. +1. @siddontang \u55ef\uff0c\u611f\u8c22\u62bd\u7a7a\u56de\u590d\ud83d\ude4f  \uff01 \u4fee\u6539\u6e90\u7801\u91cd\u65b0\u7f16\u8bd1\u5df2\u7ecf\u89e3\u51b3\u4e86\u62a5\u9519\u95ee\u9898\uff0c\u6709\u51e0\u4e2a\u95ee\u9898\u8fd8\u662f\u60f3\u8bf7\u6559\u4e0b\uff0c\n \u539f\u67651024\u7684\u503c\u662f\u57fa\u4e8e\u600e\u6837\u7684\u903b\u8f91\u8bbe\u5b9a\u7684\uff1f\u4fee\u6539\u4e4b\u540e(1024 * 1024 * 1024)\u662f\u5426\u6709\u53ef\u4ee5\u9884\u77e5\u7684\u95ee\u9898\n \u6211\u4eec\u7684\u573a\u666f\uff1a\n    * \u9ad8\u987a\u5e8f\u5199\u5165\u6027\u80fd\n    * \u4e0d\u53d7\u5185\u5b58\u9650\u5236\n    * \u5c3d\u53ef\u80fd\u7b80\u5355\u7684\u96c6\u7fa4\u642d\u5efa\u6b65\u9aa4\uff08\u53ef\u80fd\u7684\u8bdd\uff09\n\u57fa\u4e8e\u4e0a\u9762\u7684\u573a\u666f\u8c03\u7814\u4e86\u6bd4\u8f83\u591a\u7684key value\u6570\u636e\u5e93\uff0c\u6700\u7ec8\u5728\u7531leveldb\u9a71\u52a8\u7684\u4e00\u4e9b\u6570\u636e\u5e93\u4e2d\u9009\u62e9\u4e86leveldb\uff0c\u800c\u4e14\u5f88\u6709\u53ef\u80fd\u4f1a\u5c06\u8fd9\u4e2a\u6295\u5165\u5230\u751f\u4ea7\u73af\u5883\u4f7f\u7528\uff0c\u4f46\u662f\u56e2\u961fgo\u8bed\u8a00\u80fd\u529b\u5dee\uff0c\u4e0d\u77e5\u9053\u60a8\u5bf9\u6b64\u600e\u4e48\u770b\uff1f. @siddontang \u611f\u8c22\u56de\u590d\uff01\u4e0d\u77e5\u9053\u6709\u6ca1\u6709\u63a8\u8350\u7684\u5408\u9002\u7684kv\uff1f. @siddontang \u597d\u7684\uff0c\u518d\u6b21\u611f\u8c22\uff0c\u7a0d\u540e\u5982\u679c\u6709\u6709\u4ef7\u503c\u6027\u80fd\u4fe1\u606f\u4f1a\u5728\u8fd9\u91cc\u8d34\u51fa\u6765. @siddontang \nEngine is leveldb and there is no startup log. Do you need access log?. ",
    "perfgao": "@CocaCola183 \u5bf9\u7684\uff0c \u662f\u8fd9\u4e9b\uff0c\u8c22\u8c22\u4e86. ",
    "ascotan": "same process but i background the server.\n```\n  cfg := config.NewConfigDefault()\n  cfg.DataDir = \"data\"\n  app, _ := server.NewApp(cfg)\n  var wg sync.WaitGroup\n   wg.Add(1)\n   go func(app *server.App) {\n     app.Run()\n     wg.Done()\n   }(app)\nled, _ := ledis.Open(cfg)\n  db, _  := led.Select(0)\n  db.HSet([]byte(\"hash\"), []byte(\"hello\"), []byte(\"world\"))\nwg.Wait()\n```\nThis dies on the fact that ledis.Open is attempting to open a directory that is locked by server.NewApp.  \nAlso it appears that calling NewApp from the goroutine still has the same problem.. ",
    "frankxieke": "in rocksdb wiki:\n\nQ: Is basic operations Put(), Write(), Get() and NewIterator() thread safe?\nA: Yes.\n\nSo I think key-level lock can improve throughput greatly.. I also noticed qdb,  in qdb the lock become larger. Can you give me some hints why do you desgin like this.. export GODEBUG=cgocheck=0 @icexin . ",
    "wangcn": "\u76ee\u524d4.13\u53ef\u4ee5\u7528. @penuel-leo \u6211\u76ee\u524d\u75284.13\u7f16\u8bd1\u901a\u8fc7\u7684\u3002. ",
    "penuel-leo": "\u5185\u5b58\u6bd4\u786c\u76d8\u6602\u8d35\u592a\u591a. \u6211\u5c06ledisdb rm\u540e\uff0c\u91cd\u65b0\u5b89\u88c5\u5c31\u884c\u4e86\uff1b\n\u4f46\u662f\u62a5\u9519\u548cissue274\u4e00\u6837\uff0c\n\u8bf7\u95ee\u73b0\u5728rocksdb\u652f\u6301\u5230\u54ea\u4e2a\u7248\u672c. \u4f7f\u75284.13\u7f16\u8bd1\u8fc7\u4e86\uff0c\u4f46\u662f\u5728\u6267\u884cRocksDB support\u91cc\u9762\u7684\u6b65\u9aa4\nmake clean && make\u51fa\u73b0\u9519\u8bef\n\nGO15VENDOREXPERIMENT=\"1\" go build -o bin/ledis-server -tags 'rocksdb' cmd/ledis-server/\ncmd/ledis-server/main.go:15:2: cannot find package \"github.com/siddontang/ledisdb/config\" in any of:\n    /usr/local/go/src/github.com/siddontang/ledisdb/config (from $GOROOT)\n    /home/allen/go/src/github.com/siddontang/ledisdb/config (from $GOPATH)\ncmd/ledis-server/main.go:16:2: cannot find package \"github.com/siddontang/ledisdb/server\" in any of:\n    /usr/local/go/src/github.com/siddontang/ledisdb/server (from $GOROOT)\n    /home/allen/go/src/github.com/siddontang/ledisdb/server (from $GOPATH)\nmake: ** [build] Error 1\n\n\u53d1\u73b0GOPATH\u627e\u7684\u4f4d\u7f6e\u4e0d\u5bf9\uff0cecho $GOPATH\n\n/home/allen/.go\n\n\u81ea\u5df1\u770b\u4e86\u4e0bsource dev.sh\u91cc\u9762$GOPATH\u8fd8\u662f\u6b63\u786e\u7684\uff0c\u4e0d\u77e5\u9053\u5728\u54ea\u4e00\u6b65\u7ed9\u6362\u6389\u4e86?. \u627e\u5230\u95ee\u9898\u4e86\uff0c\u56e0\u4e3adev.sh\u91cc\u9762\u4f1a\u6839\u636eleveldb\u914d\u7f6e\u7684\u8def\u5f84\u627eleveldb\uff0c\u5982\u679c\u627e\u5230\u5219\u4f1a\u7ed9$GO_BUILD_TAGS\u589e\u52a0\u4e00\u4e2atag(leveldb)\uff0c\u6240\u4ee5\u6267\u884c\u7684\u65f6\u5019\u4f1a\u53d6\u8fd9\u4e2a$GO_BUILD_TAGS\u53d8\u91cf\uff1b\n\u6211\u672c\u5730\u521a\u597d\u6709leveldb\u5728\u914d\u7f6e\u7684\u8def\u5f84\u4e0b\u3002\u3002\u3002\n\u5c06dev.sh \u7684leveldb\u8def\u5f84\u4fee\u6539\u4e3a\u4e0d\u5b58\u5728\u7684\u8def\u5f84\u5373\u53ef\uff1b\n\u591a\u8c22\u63d0\u9192\u3002. \u5148\u8d5e\u4e0b. OK\uff0c\u5df2\u7ecf\u597d\u4e86\uff1b\n\u987a\u4fbf\u63d0\u4e00\u53e5\uff0cMakefile\u91cc\u9762\u5c11\u4e86ledis-server\u548cledis-cli\u547d\u4ee4\u7684\u7f16\u8bd1\u3002\nshell\ngo build -o bin/ledis-server -tags '$(GO_BUILD_TAGS)' cmd/ledis-server/*\ngo build -o bin/ledis-cli -tags '$(GO_BUILD_TAGS)' cmd/ledis-cli/*. @siddontang \n\u5f53\u6211\u76f4\u63a5get \u6570\u5b57\u7684\u65f6\u5019\uff0c\u4f1a\u8fd4\u56de\u7279\u6b8a\u7684\u503c:\n\n127.0.0.1:6380> get 1\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n127.0.0.1:6380> get b\n(nil)\n127.0.0.1:6380> get 2\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n127.0.0.1:6380> get 3\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n127.0.0.1:6380> get 1000\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n127.0.0.1:6380> set 1 2\nOK\n127.0.0.1:6380> get 1\n\"2\"\n\n2:xmigrate\u662f\u539f\u5b50\u7684\u5417\uff1f\u5982\u679c\u628adb0\u7684\u6570\u636emigrate\u5230db1\uff0c\u540e\u7eed\u5199\u7684\u6570\u636e\u662f\u4e0d\u662f\u8fd8\u5728db0\u4e0a\uff1f. del\u4e4b\u540e\uff0c\u518dget\u5c31\u5bf9\u4e86\uff0c\u53ef\u662f\u8001\u6570\u636e\u91cc\u9762\u6ca1\u6570\u5b57key\uff0c\u800c\u4e14\u6309\u7167\u4f60\u8bf4\u7684\uff0c\u6211\u628arpl\u4e0b\u9762\u7684\u90fd\u5220\u4e86\uff0c\u540c\u6b65\u8fc7\u7a0b\u4e5f\u6ca1\u62a5\u9519\uff0c\n\u8fd9\u4e9bkey\u4e0d\u77e5\u9053\u4ece\u54ea\u51fa\u6765\u7684\u3002. ",
    "daddyz": "and I noticed that replication restore doesn't restore ttl of keys, at least during restore process. ",
    "charl": "On the master:\n$ ls -la /mnt/volume-sfo2-06/var/lib/ledis/rpl/\ntotal 16\ndrwxr-xr-x 3 root root 4096 Feb 15 10:53 .\ndrwxr-xr-x 5 root root 4096 Mar  5 15:53 ..\n-rw-r--r-- 1 root root    8 Mar  9 09:29 commit.log\ndrwxr-xr-x 2 root root 4096 Mar  9 09:24 ldb\n$ ls -la /mnt/volume-sfo2-06/var/lib/ledis/rpl/ldb/\ntotal 13182800\ndrwxr-xr-x 2 root root      4096 Mar  9 09:24 .\ndrwxr-xr-x 3 root root      4096 Feb 15 10:53 ..\n-rw-r--r-- 1 root root 268435588 Mar  3 00:11 00003838.data\n-rw-r--r-- 1 root root   4232644 Mar  3 00:11 00003838.meta\n[...]\n-rw-r--r-- 1 root root 238678131 Mar  9 09:54 00003888.data\n-rw-r--r-- 1 root root   3739440 Mar  9 09:54 00003888.meta\nOn the slave:\n$ ls -la /mnt/volume-sfo2-02/var/lib/ledis/leveldb_data/\ntotal 24\ndrwxr-xr-x 2 root root 4096 Mar 11 05:48 .\ndrwxrwxr-x 5 root root 4096 Mar  9 09:29 ..\n-rw-r--r-- 1 root root    0 Mar 11 05:48 000013.log\n-rw-r--r-- 1 root root   16 Mar 11 05:48 CURRENT\n-rw-r--r-- 1 root root    0 Mar  9 08:30 LOCK\n-rw-r--r-- 1 root root  175 Mar 11 05:48 LOG\n-rw-r--r-- 1 root root  172 Mar  9 09:00 LOG.old\n-rw-r--r-- 1 root root   50 Mar 11 05:48 MANIFEST-000012\n$ ls -la /mnt/volume-sfo2-02/var/lib/ledis/rpl/\ntotal 16\ndrwxr-xr-x 3 root root 4096 Mar  9 08:38 .\ndrwxrwxr-x 5 root root 4096 Mar  9 09:29 ..\n-rw-r--r-- 1 root root    8 Mar 14 08:49 commit.log\ndrwxr-xr-x 2 root root 4096 Mar  9 08:38 ldb\n$ ls -la /mnt/volume-sfo2-02/var/lib/ledis/rpl/ldb/\ntotal 8\ndrwxr-xr-x 2 root root 4096 Mar  9 08:38 .\ndrwxr-xr-x 3 root root 4096 Mar  9 08:38 ..\nHere's the traffic I see on the master to the slave:\n```\n$ sudo tcpdump -i eth0 -X -s 2048 host 10.0.0.99 and dst port 6380\ntcpdump: verbose output suppressed, use -v or -vv for full protocol decode\nlistening on eth0, link-type EN10MB (Ethernet), capture size 2048 bytes\n08:55:31.085191 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [P.], seq 2270108330:2270108344, ack 1622922997, win 229, length 14\n  0x0000:  4500 0036 db76 4000 3f06 4f0e 8a44 3863  E..6.v@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1aaa 60bb d6f5  .........O.....\n  0x0020:  5018 00e5 de6a 0000 2a31 0d0a 2434 0d0a  P....j..*1..$4..\n  0x0030:  5049 4e47 0d0a                           PING..\n08:55:31.086324 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [.], ack 8, win 229, length 0\n  0x0000:  4500 0028 db77 4000 3f06 4f1b 8a44 3863  E..(.w@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1ab8 60bb d6fc  .........O.....\n  0x0020:  5010 00e5 f27f 0000 0000                 P.........\n08:55:31.086398 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [P.], seq 14:63, ack 8, win 229, length 49\n  0x0000:  4500 0059 db78 4000 3f06 4ee9 8a44 3863  E..Y.x@.?.N..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1ab8 60bb d6fc  .........O.....\n  0x0020:  5018 00e5 e424 0000 2a33 0d0a 2438 0d0a  P....$..*3..$8..\n  0x0030:  7265 706c 636f 6e66 0d0a 2431 340d 0a6c  replconf..$14..l\n  0x0040:  6973 7465 6e69 6e67 2d70 6f72 740d 0a24  istening-port..$\n  0x0050:  340d 0a36 3338 300d 0a                   4..6380..\n08:55:31.123268 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [.], ack 35, win 229, length 0\n  0x0000:  4500 0028 db79 4000 3f06 4f19 8a44 3863  E..(.y@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1ae9 60bb d717  .........O.....\n  0x0020:  5010 00e5 f233 0000 0000                 P....3....\n08:55:41.087286 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [P.], seq 63:77, ack 35, win 229, length 14\n  0x0000:  4500 0036 db7a 4000 3f06 4f0a 8a44 3863  E..6.z@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1ae9 60bb d717  .........O.....\n  0x0020:  5018 00e5 de09 0000 2a31 0d0a 2434 0d0a  P.......*1..$4..\n  0x0030:  5049 4e47 0d0a                           PING..\n08:55:41.087718 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [.], ack 42, win 229, length 0\n  0x0000:  4500 0028 db7b 4000 3f06 4f17 8a44 3863  E..(.{@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1af7 60bb d71e  .........O.....\n  0x0020:  5010 00e5 f21e 0000 0000                 P.........\n08:55:41.087746 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [P.], seq 77:126, ack 42, win 229, length 49\n  0x0000:  4500 0059 db7c 4000 3f06 4ee5 8a44 3863  E..Y.|@.?.N..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1af7 60bb d71e  .........O.....\n  0x0020:  5018 00e5 e3c3 0000 2a33 0d0a 2438 0d0a  P.......*3..$8..\n  0x0030:  7265 706c 636f 6e66 0d0a 2431 340d 0a6c  replconf..$14..l\n  0x0040:  6973 7465 6e69 6e67 2d70 6f72 740d 0a24  istening-port..$\n  0x0050:  340d 0a36 3338 300d 0a                   4..6380..\n08:55:41.127149 IP 10.0.0.99.47238 > 10.0.0.208.6380: Flags [.], ack 69, win 229, length 0\n  0x0000:  4500 0028 db7d 4000 3f06 4f15 8a44 3863  E..(.}@.?.O..D8c\n  0x0010:  8ac5 c3d0 b886 18ec 874f 1b28 60bb d739  .........O.(..9\n  0x0020:  5010 00e5 f1d2 0000 0000                 P.........\n[...]\n```. When I try to start the new master with -rpl it panics:\n```\n/usr/local/bin/ledis-server -rpl -config=/etc/ledis/ledis.conf\npanic: runtime error: index out of range\ngoroutine 27 [running]:\ngithub.com/siddontang/ledisdb/store/leveldb.(WriteBatch).Delete(0xc8201c79e0, 0xc82022e42e, 0x0, 0x106)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/leveldb/batch.go:58 +0x49\ngithub.com/siddontang/ledisdb/store.(WriteBatch).Delete(0xc8201f3d00, 0xc82022e42e, 0x0, 0x106)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:33 +0x5c\ngithub.com/syndtr/goleveldb/leveldb.(Batch).Replay.func1(0x1, 0x0, 0xc82022e42e, 0x0, 0x106, 0x0, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/github.com/syndtr/goleveldb/leveldb/batch.go:129 +0x5f\ngithub.com/syndtr/goleveldb/leveldb.(Batch).decodeRec(0xc82026a6c0, 0xc820034d58, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/github.com/syndtr/goleveldb/leveldb/batch.go:227 +0x33f\ngithub.com/syndtr/goleveldb/leveldb.(Batch).Replay(0xc82026a6c0, 0x7f73bc778738, 0xc8201f3d00, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/github.com/syndtr/goleveldb/leveldb/batch.go:131 +0x53\ngithub.com/siddontang/ledisdb/store.(BatchData).Replay(0xc82026a6c0, 0x7f73bc778708, 0xc8201f3d00, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:140 +0x74\ngithub.com/siddontang/ledisdb/ledis.(Ledis).handleReplication(0xc8201b0240, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/replication.go:58 +0x70c\ngithub.com/siddontang/ledisdb/ledis.(Ledis).onReplication(0xc8201b0240)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/replication.go:86 +0xf5\ncreated by github.com/siddontang/ledisdb/ledis.Open\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/ledis.go:83 +0x46f\ngoroutine 1 [runnable]:\ngithub.com/siddontang/ledisdb/ledis.(*Ledis).WaitReplication(0xc8201b0240, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/replication.go:102 +0x2b4\ngithub.com/siddontang/ledisdb/ledis.Open(0xc8200b2780, 0xc8201a56e0, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/ledis.go:87 +0x47d\ngithub.com/siddontang/ledisdb/server.NewApp(0xc8200b2780, 0x1d, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/app.go:120 +0x81a\nmain.main()\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/cmd/ledis-server/main.go:92 +0x4d4\ngoroutine 17 [syscall, locked to thread]:\nruntime.goexit()\n    /usr/local/go/src/runtime/asm_amd64.s:1696 +0x1\ngoroutine 21 [syscall]:\nos/signal.loop()\n    /usr/local/go/src/os/signal/signal_unix.go:22 +0x18\ncreated by os/signal.init.1\n    /usr/local/go/src/os/signal/signal_unix.go:28 +0x37\ngoroutine 22 [select]:\ngithub.com/siddontang/go/log.(*Logger).run(0xc82006a150)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/github.com/siddontang/go/log/log.go:100 +0x269\ncreated by github.com/siddontang/go/log.New\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/Godeps/_workspace/src/github.com/siddontang/go/log/log.go:80 +0x1cc\ngoroutine 24 [select]:\ngithub.com/siddontang/ledisdb/server.(*snapshotStore).run(0xc8201a56e0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/snapshot.go:115 +0x2c3\ncreated by github.com/siddontang/ledisdb/server.newSnapshotStore\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/snapshot.go:67 +0x2fb\ngoroutine 25 [select]:\ngithub.com/siddontang/ledisdb/rpl.(*FileStore).checkTableReaders(0xc82006a460)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/rpl/file_store.go:285 +0x338\ncreated by github.com/siddontang/ledisdb/rpl.NewFileStore\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/rpl/file_store.go:97 +0x298\ngoroutine 26 [select]:\ngithub.com/siddontang/ledisdb/rpl.(Replication).run(0xc82006e720)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/rpl/rpl.go:298 +0x796\ncreated by github.com/siddontang/ledisdb/rpl.NewReplication\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/rpl/rpl.go:78 +0x5da\n```. I built a new version of the server from the master branch and I get this on the replication master when starting it up with -rpl*:\n```\n/var/tmp/ledis-server -rpl -config=/etc/ledis/ledis.conf\npanic: runtime error: index out of range\ngoroutine 10 [running]:\ngithub.com/siddontang/ledisdb/store/leveldb.(WriteBatch).Delete(0xc420237ce0, 0xc42028042e, 0x0, 0x106)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/leveldb/batch.go:58 +0x57\ngithub.com/siddontang/ledisdb/store.(WriteBatch).Delete(0xc42024e100, 0xc42028042e, 0x0, 0x106)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:33 +0x5c\ngithub.com/syndtr/goleveldb/leveldb.(Batch).Replay.func1(0x1, 0x0, 0xc42028042e, 0x0, 0x106, 0x0, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/syndtr/goleveldb/leveldb/batch.go:129 +0xb6\ngithub.com/syndtr/goleveldb/leveldb.(Batch).decodeRec(0xc4202c0a40, 0xc420037d60, 0x410f58, 0xa2e300)\n    /home/charl/projects/go/src/github.com/syndtr/goleveldb/leveldb/batch.go:227 +0x17d\ngithub.com/syndtr/goleveldb/leveldb.(Batch).Replay(0xc4202c0a40, 0x7f78701da330, 0xc42024e100, 0x7f78701da330, 0xc42024e100)\n    /home/charl/projects/go/src/github.com/syndtr/goleveldb/leveldb/batch.go:131 +0x67\ngithub.com/siddontang/ledisdb/store.(BatchData).Replay(0xc4202c0a40, 0xfb68c0, 0xc42024e100, 0xc4202c0a40, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:140 +0x6a\ngithub.com/siddontang/ledisdb/ledis.(Ledis).handleReplication(0xc4201f6240, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/replication.go:58 +0x1b0\ngithub.com/siddontang/ledisdb/ledis.(Ledis).onReplication(0xc4201f6240)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/replication.go:86 +0x102\ncreated by github.com/siddontang/ledisdb/ledis.Open\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/ledis.go:83 +0x408\n```. If I stop the master, move the rpl dir to rpl.off and start the master back up with the -rpl switch I get:\n[2017/03/17 12:36:44] client_resp.go:101 [Fatal] client run panic goroutine 81 [running]:\ngithub.com/siddontang/ledisdb/server.(*respClient).run.func1(0xc420245020)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/client_resp.go:98 +0x139\npanic(0xa24860, 0xc420191490)\n    /usr/local/go/src/runtime/panic.go:489 +0x2cf\ngithub.com/siddontang/ledisdb/store/leveldb.(*WriteBatch).Data.func1(0x1f6bee0, 0xc420234140)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/leveldb/batch.go:100 +0x8b\ngithub.com/siddontang/ledisdb/store/leveldb.(*WriteBatch).Data(0xc4202380a0, 0x40523c, 0xfe2720, 0xc420039c68)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/leveldb/batch.go:102 +0x64\ngithub.com/siddontang/ledisdb/store.(*WriteBatch).BatchData(0xc420234100, 0x1f6bee0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:65 +0x37\ngithub.com/siddontang/ledisdb/store.(*WriteBatch).Data(0xc420234100, 0x7adf3c, 0x1f6bee0, 0xc420116690)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/store/writebatch.go:75 +0x2b\ngithub.com/siddontang/ledisdb/ledis.(*Ledis).handleCommit(0xc4201e0240, 0xfb33c0, 0xc420234100, 0xfb3400, 0xc420234100, 0x1, 0x8)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/batch.go:108 +0x7d\ngithub.com/siddontang/ledisdb/ledis.(*batch).Commit(0xc4202380c0, 0xc420116690, 0x69)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/batch.go:26 +0x97\ngithub.com/siddontang/ledisdb/ledis.(*DB).incr(0xc42024c000, 0xc420116620, 0x67, 0x67, 0x1, 0x0, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/t_kv.go:93 +0x2c9\ngithub.com/siddontang/ledisdb/ledis.(*DB).IncrBy(0xc42024c000, 0xc420116620, 0x67, 0x67, 0x1, 0x1, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/ledis/t_kv.go:220 +0x53\ngithub.com/siddontang/ledisdb/server.incrbyCommand(0xc42030a580, 0xc4201a24e0, 0xc420191458)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/cmd_kv.go:163 +0xbe\ngithub.com/siddontang/ledisdb/server.(*client).perform(0xc42030a580)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/client.go:134 +0x267\ngithub.com/siddontang/ledisdb/server.(*respClient).handleRequest(0xc420245020, 0xc420056dc0, 0x3, 0x3, 0x0, 0x0)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/client_resp.go:185 +0x102\ngithub.com/siddontang/ledisdb/server.(*respClient).run(0xc420245020)\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/client_resp.go:139 +0x217\ncreated by github.com/siddontang/ledisdb/server.newClientRESP\n    /home/charl/projects/go/src/github.com/siddontang/ledisdb/server/client_resp.go:91 +0x353\n:runtime error: cgo argument has Go pointer to Go pointer. Confirmed fixed.. Thanks for all your hard work @siddontang!. ",
    "justinfx": "Sorry to comment on an old thread, but I just came across this issue while searching if another problem I had was already posted....\nI have been porting an implementation using boltdb over to ledisdb and had selected a Zset as a way to support a queue of values that is ordered by an incrementing integer key. Then I just randomly saw that internally the ordered set is capped to 1024. Historically, I have seen my queue reach sizes of 8 million items, and after reading (the translation of) this ticket, it seems the Ledisdb implementation of ordered set is not suitable for this solution? Hopefully you can provide a little more insight so I can choose the right approach?\nOriginally I had started with the idea of:\n\nGetting the next numeric id with an INCR key\nIndexing items in a hash by id -> item\nManaging queue order in a list of ids (referring to hash id)\n\nAfter I started writing this approach, I realized that there doesn't seem to be an efficient way to remove queued items by the id without scanning the list. With boltdb, I relied upon the ability to Get(id) and also have the bucket cursor iterate the queue ordered by those ids.\nBecause of this, and what also seems to be the lack of transactions to support the management of those multiple data structures, I thought it would be smart to switch to Zset, using the numeric incrementing id as the score. This would give me ordered queue items that could also be addressed directly by id. But I see now that there is a member cap.\nWhat is the right way to use ledisdb for this kind of item queue? Do I just need to accept the lack of transactions when maintaining secondary indices, and also accept the potential hit if my Get(id) ends up scanning deep into a list that possibly has 8 million items? Zset seemed like the closest match to boltdb bucket. Unless a hash guarantees iteration is ordered by key?. Hi. I know this is an older thread but I didn't want to start a new one since there are already a few about transaction support.\nIt seems goleveldb supports transactions? \nhttps://godoc.org/github.com/syndtr/goleveldb/leveldb#Transaction\nSo if the 3 options left are leveldb, goleveldb, and rocksdb, is the leveldb option the only one holding back transaction support? If so, is there a real benefit to keeping leveldb if goleveldb performs just as well?\nIve just hit an issue for the second time because I forgot that the first time I tried Ledisdb I realised there were no transactions. Now I need them again :-/\nGreat project btw! . @siddontang\nI did have a project where I switched from Bolt to Badger and it was a decent performance boost. I feel like goleveldb is the \"easy\" option right now since it doesn't require any external building, and that someone choosing goleveldb would know about its strengths and weaknesses vs rocksdb. But Badger would be another easy embeddable option. However, in terms of Ram-only db, Badger doesn't have this option, and goleveldb could be adjusted to properly not require any filesystem access. \nTransaction support would be an awesome addition to this project. . Thanks for the clarification! If it doesn't need to create the files, that would be pretty cool to have a pure memory impl so I don't have to clean up temporary directories :-)\nAlso, thanks for this cool project. . ",
    "robvanmieghem": "I think having a property on the App struct like \"UseFreeLocalAddress\" would be fine. This way it is not done through the config but explicitly through the App object. One would probably never do this through a non-embedded App anyway since you can not know the port that way.. ",
    "palamccc": "Any plan to support Badger ? Badger claims to have snapshot support. https://github.com/dgraph-io/badger/issues/39. ",
    "0xIslamTaha": "@siddontang thanks for fast respond. I'm wondering if its secure to expose it the public world or not. ",
    "muhamadazmy": "The tests are falling due to a bad toml library.\nWhile the Config.AuthMethod is explicitly given the tag toml:\"-\" it still tries to reflect it's type which (of course) not supported by the toml library.\nI suggest u move to a better toml library, or suggest a better solution. I will try some other libraries and see which will work the best. Thanks a lot for your feedback :). @siddontang it passes now. I used https://github.com/pelletier/go-toml instead. I also updated the vendor directory.\nBy the way, how do you maintain your vendor directory? It's not compatible with godep and I had to do it manually.\nAbout your question regarding BurntSushi/toml, It was too late when i saw your comment i already did the migration to go-toml. Sorry.. Hi @siddontang \nFixed vendor as you said :)\n. Hello @siddontang \nThanks a lot for the fast response. I applied your change and it indeed fixed it. I tried to run my gist again once your fix was in place, it doesn't block forever anymore. \nCould you please commit this change to master ?\n```diff\ndiff --git a/ledis/t_list.go b/ledis/t_list.go\nindex 718ad8e..5002166 100644\n--- a/ledis/t_list.go\n+++ b/ledis/t_list.go\n@@ -692,7 +692,7 @@ func (db *DB) LKeyExists(key []byte) (int64, error) {\n }\nfunc (db *DB) lblockPop(keys [][]byte, whereSeq int32, timeout time.Duration) ([]interface{}, error) {\n-   ch := make(chan []byte)\n+   ch := make(chan []byte, len(keys))\nbkeys := [][]byte{}\nfor _, key := range keys {\n\n```\nOr merge my pull request\nThanks. @siddontang sorry for late response, i have must missed that you have commented back. \nI tried this out and rerun the test locally and it also did not work. I still got a test timeout.. @siddontang I did some refactoring on the logic to avoid the race condition by implementing an atomic \"popOrWait\" method. \nAlso I used context instead of channel since they are much easier to use for signalling jobs (u can see from amount of code removed) \n. Sorry, don't merge yet. it seems this reproduce the original bug. I get random indefinite blocking again.. Also if u run the gist that is attached to the issue u will see that it blocks again :( I don't know why, and it happens in the listBatch lock method for some reason. And i found that it even blocks the push.\nI couldn't figure out why, so if u may look at it if u like the refactoring i made.. Thanks @siddontang for merging this in. \nWe can definitely upgrade context to the standard lib one, except i didn't want to break compatibility with 1.6 version. Also i noticed context package is used in other parts of ledisd. Should we upgrade all or just this part ?. Good point :). done. ",
    "sloonz": "I see there was the beginning of an implementation of MULTI here : https://github.com/siddontang/ledisdb/commit/b2e86584701af21c23478a444ac7e32b6b908191\nWhy did you discarded it ?. ",
    "digipigeon": "If I change the SET to a LPUSH (still at 150 ops / second), this problem does not happen.. ",
    "zhenruyan": "goleveldb  \u5c31\u662f\u9759\u6001\u94fe\u63a5\u7684leveldb\u662f\u5427\uff1f   . ",
    "steedyu": "\u6211\u4f7f\u7528\u5982\u4e0b\u914d\u7f6e\u542f\u52a8ledisserver\uff0c\u7136\u540e\u7528golang\u5199\u4e86\u4e00\u4e2a\u538b\u6d4b\uff0c\u53d1\u73b0linux\u64cd\u4f5c\u7cfb\u7edfledisserver\u7684\u5185\u5b58\u4e0d\u65ad\u98d9\u5347\uff0c\u964d\u4e0d\u4e0b\u6765\uff0c\u540c\u65f6\u538b\u6d4b\u7a0b\u5e8f\u91cc\u6709\u4e00\u4e2adial\u68c0\u6d4b\uff0c\u4f1a\u663e\u793ai/o timeout,\u4ece\u6d4b\u8bd5\u7684\u6837\u5b50\u770b\uff0c\u6211\u8bbe\u7f6e\u7684\u8fd9\u4e2acache\u5927\u5c0f\uff0c\u5185\u5bb9\u4ecd\u7136\u8fd8\u4f1a\u7ee7\u7eed\u4e0a\u6da8\uff0c\u6da8\u5230\u4e00\u6bb5\u65f6\u95f4\u540e\uff0cledis-server\u5c31\u6302\u6389\u4e86\u3002 \u6211\u538b\u6d4b\u7684\u6570\u636e\u7ed3\u6784\u5c31\u662fhash\uff0c\u6bcf\u4e2ahash\u670910\u4e2afield\uff0c\u6bcf\u4e2afield\u5927\u5c0f87kb\u3002\u4ece\u8fd9\u91cc\u770b\uff0c\u611f\u89c9\u5e76\u4e0d\u50cfcache\u8bbe\u7f6e\u8fc7\u5927\uff08\u5c1d\u8bd5\u8fc7\u8bbe\u7f6e500mb\uff0c100mb\uff0c\u6700\u540e\u8bbe\u7f6e\u62101024\uff09\uff0c\u800c\u5185\u5b58\u4ecd\u7136\u4e0d\u65ad\u4e0a\u6da8\u3002\u8bf7\u95ee\uff0c\u8fd9\u4e2a\u6709\u4ec0\u4e48\u529e\u6cd5\u89e3\u51b3\uff1f\nLedisDB configuration\nServer listen address\naddr = \"0.0.0.0:6380\"\nServer http listen address, set empty to disable\nhttp_addr = \"127.0.0.1:11181\"\nData store path, all ledisdb's data will be saved here\ndata_dir = \"./var\"\nSet the number of databases. You can use select dbindex to choose a db.\ndbindex must be in [0, databases - 1].\nDefault databases is 16, maximum is 10240 now.\ndatabases = 16\nLog server command, set empty to disable\naccess_log = \"\"\nSet slaveof to enable replication from master, empty, no replication\nAny write operations except flushall and replication will be disabled in slave mode.\nslaveof = \"\"\nReadonly mode, slave server is always readonly even readonly = false\nfor readonly mode, only replication and flushall can write\nreadonly = false\nAuthentication (for non-http connections). Connect, then use the AUTH command to authenticate.\nauth_password = \"russellwashere\"\nChoose which backend storage to use, now support:\n\nleveldb\nrocksdb\ngoleveldb\nmemory\n\ndb_name = \"goleveldb\"\nIf not set, use data_dir/\"db_name\"_data\ndb_path = \"\"\nSync commit to disk if possible\n0: no sync\n1: sync every second\n2: sync every commit\ndb_sync_commit = 0\nenable replication or not\nuse_replication = false\nset connection buffer, you can increase them appropriately\nmore size, more memory used\nconn_read_buffer_size = 10240\nconn_write_buffer_size = 10240\nif connection receives no data after n seconds, it may be dead, close\n0 to disable and not check\nconn_keepalive_interval = 0\nchecking TTL (time to live) data every n seconds\nif you set big, the expired data may not be deleted immediately\nttl_check_interval = 1\n[leveldb]\nfor leveldb and goleveldb\ncompression = false\nblock_size = 32768\nwrite_buffer_size = 67108864\ncache_size = 1024\nmax_open_files = 1024. \u538b\u6d4b\u7684\u7a0b\u5e8f\u662f\u662f\u7528golang \u7684redis\u9a71\u52a8\u5199\u7684\uff0c\u4e0d\u65b9\u4fbf\u63d0\u4f9b\uff0c\u6d89\u53ca\u4e86\uff0c\u5177\u4f53\u6570\u636e\u683c\u5f0f\uff0c\u57fa\u672c\u5c31\u662fhset \u548chdel \u6570\u636e\uff0c\u4f46\u662fkey\u4e2d\u7684filed\u6240\u5bf9\u5e94\u7684\u6570\u636e\u5927\u5c0f\u6bd4\u8f83\u5927\uff0c\u5927\u6982value\u7684\u5927\u5c0f\u662f78kb\u5b57\u7b26\u4e32\u3002\u5f00500goroutine\u8fdb\u884c\u538b\u6d4b\u3002\n\u914d\u7f6e\u6587\u4ef6\u5185\u5bb9\u5982\u4e0b\uff1a\naddr = \"0.0.0.0:7380\"\nhttp_addr = \"127.0.0.1:11181\"\ndata_dir = \"./var\"\ndatabases = 16\naccess_log = \"\"\nslaveof = \"\"\nreadonly = false\ndb_name = \"goleveldb\"\ndb_path = \"\"\ndb_sync_commit = 0\nuse_replication = false\nconn_read_buffer_size = 10240\nconn_write_buffer_size = 10240\nconn_keepalive_interval = 0\nttl_check_interval = 1\n[leveldb]\ncompression = false\nblock_size = 32768\nwrite_buffer_size = 67108864\ncache_size = 52428800\nmax_open_files = 1024. leveldb\uff0c\u6211\u6700\u540e\u7528leveldb\u6d4b\u8bd5\u4e5f\u662f\u540c\u6837\u7684\u60c5\u51b5\uff0c\u8fd9\u91cc\u5c31\u7ed9\u51fa\u4e86leveldb\u7684\u914d\u7f6e\uff0c\u4e00\u6837\u7684\u60c5\u51b5\u3002. redis cli\u5c31\u662f\u76f4\u63a5 redis-cli -h xxxx.xxx.xx.xxx -p 7380. hgetall hashkey. get setkey\u4e5f\u662f\u83b7\u53d6\u4e0d\u5230. ",
    "c2h5oh": "I'll add a dockerfile tomorrow - let's include it too.. Preparatory work for Dockerfile is in this pull request https://github.com/siddontang/ledisdb/pull/326\nFinal pull request will follow in the next hour or so.. Final pull request - Dockefile to allow building new version - https://github.com/siddontang/ledisdb/pull/327. With all 3 merged let's tag it 0.6. Rebased & tests passing.. Indentation fixed.. The problem is definitely creating a db dump, which at least with RocksDB goes as follows:\n\nCreate a temporary rocksdb snapshot (dmp-<timestamp>.tmp)\nRead temporary rocksdb snapshot and write ledisdb dump\n\nFirst step is bottlenecked on read IO, specifically random read operations per second. In my case it maxes out IOPS, but read throughput remains low: 15-25% of disk sequential read speed.\na 100GB db snaphot takes about two hours to create on AWS EBS volume with 500 iops.\nSecond step has to read entire rocksdb snapshot and write it again in ledisdb format, which happens at disk sequential r/w speed.\nStep 1 could be sped up significantly if we could use checkpoints instead of snapshots (which should be possible, but I haven't had the time to test it) or use RocksDB backup API: \nhttps://github.com/siddontang/ledisdb/blob/master/store/rocksdb/db.go#L238\nhttps://github.com/facebook/rocksdb/wiki/Checkpoints\nhttps://github.com/facebook/rocksdb/wiki/How-to-backup-RocksDB%3F\nWith that step 1 would be limited to creating a bunch of hardlinks on most cases without having to copy entire db. Step 2 would read the checkpoint immediately creating a ledisdb dump file or streaming it to replica.. done. Yes it does - it's a recent addition.. In your fork you've made a total of 4 changes to LevelDB:\n1. you've increased the target (max) file size - which is now exposed as a setting and I've made it configurable in the other branch\n2. you've doubled the soft limit on 0-level files (8 -> 16)\n3. you've increased the hard cap on 0-level files from 12 to 64\n4. you've doubled the grandparent overlap (10 -> 20 times target file size)\nChange 1 is no longer required as that value is now exposed in LevelDB and I've made it configurable in Ledis. Changes 2-4 are made using the patch file.\nNote: I know next to nothing about LevelDB - all I did was replicating your changes in v0.5.. We already support it - it's MaxFileSize in LevelDBConfig - you can modify it by changing Ledis config file. The default is the exact same value you've set in your fork of LevelDB for Ledis 0.5. ",
    "kaixinbuyu": "list or filter queue/hash names. \u4ece\u5176\u4ed6\u5730\u65b9\u770b\u5230\uff0cXSCAN\uff0c\u4e0d\u77e5\u9053\u5343\u4e07key\u4e0bregex\u6027\u80fd\u5982\u4f55. ",
    "benjafire": "@siddontang , Sorry for replying so late. The PR has been created. https://github.com/siddontang/ledisdb/pull/336 . Hope this project gets better and better. :-) . ",
    "nim-nim": "Hi,  honestly I can not promise anything, this is part of a mass rebuild of more 700 Go packages with Go 1.10, I'll probably be stuck doing emergency updates and repairs on quite a lot of those before even looking at fixing go vet warnings is possible. Just making the effort to report problems as they're  identified is taking several day.. It\u2019s mostly just more strict because Google got fed up with small mistakes making complex Go apps fail, but there is a huge pile of small mistakes to fix in existing projects.. ",
    "mstory21": "The main problem is 1.  It took a long time to write the dmp file out to disk and put undue stress on the box that was currently handling traffic.  Number 3 was also an issue, but it is not as concerning as 1.. I'm currently not using compression. Currently using mmap, sync every second, store type of file.. The Dial just needs to be changed to a DialTimeout in github.com/siddontang/ledisdb/vendor/github.com/siddontang/goredis/conn.go.. Will send you a PR today.. I believe at some point the databases became inconsistent, perhaps on the key that counts how many members are in the set.  I was doing a lot of failover testing at the time.  So this could be related to replication.. OK, will issue a PR for goredis with Options.. ",
    "EdKung": "Same problem here. \nIn my case, services which manipulate dbs are stopped first for caution.\nHowever, db crashed after normally restart the ledis-server.\nAny recommendations to hard fix by truncating some logs or other possible ways? \nThanks.\n```\n[2018/05/23 02:17:07] file_table.go:65 [Error] check 38 error: invalid log table, first 16214177, last 2025978305930216789, and log num 7127, try to repair\npanic: runtime error: invalid memory address or nil pointer dereference\n[signal SIGSEGV: segmentation violation code=0x1 addr=0x28 pc=0x7ce4ed]\ngoroutine 1 [running]:\ngithub.com/siddontang/ledisdb/rpl.(tableReader).repair(0xc4202581c0, 0x21, 0xc4201199f0)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/rpl/file_table.go:241 +0x31d\ngithub.com/siddontang/ledisdb/rpl.newTableReader(0xc4201cab70, 0x22, 0x26, 0x1, 0xc420119af8, 0x1, 0x1)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/rpl/file_table.go:67 +0x204\ngithub.com/siddontang/ledisdb/rpl.(FileStore).load(0xc42023dab0, 0x22, 0xc4000001ed)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/rpl/file_store.go:340 +0x21c\ngithub.com/siddontang/ledisdb/rpl.NewFileStore(0xc4201cab70, 0x22, 0xc4201ec000, 0xc4201cab70, 0x22, 0x0)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/rpl/file_store.go:85 +0x129\ngithub.com/siddontang/ledisdb/rpl.NewReplication(0xc4201ec000, 0xc4201cc280, 0x0, 0x0)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/rpl/rpl.go:62 +0x1dc\ngithub.com/siddontang/ledisdb/ledis.Open(0xc4201ec000, 0xc4201c6ba0, 0x0, 0x0)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/ledis/ledis.go:76 +0x2e4\ngithub.com/siddontang/ledisdb/server.NewApp(0xc4201ec000, 0x16, 0x7ffe593c48ec, 0x16)\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/server/app.go:174 +0x3eb\nmain.main()\n    /home/edkung/ledisdb/src/github.com/siddontang/ledisdb/cmd/ledis-server/main.go:92 +0x5c1\n```. ",
    "2276282419": "\u6211\u4e5f\u662f\u60f3\u77e5\u9053\u8fd9\u4e2a\u95ee\u9898. ",
    "Xeoncross": "I found a complete example in the dump_test.go file.. Did you suggest lists because they take up less space or are faster for lookups?\nAre you saying each item in the list is a serialized/JSON array that contains all keys for the actual objects in that longitude? I don't understand how lists would work since lists are 0 indexed so the list would have to be \nlat:32 -> list [\n    0: [city:34, city:521, city:94, ...], \n    1: [...], \n    ..., \n    360: [...]\n]\n\n. @ivanjaros interesting, so after the X,Y coordinate is encoded as a geohash - how would you query the database to find neighbors or locations within a given bounding box?\n. ",
    "thumbsized": "usually, geolocation is stored in form of geohash in uint64 form, not in floats. See https://github.com/mmcloughlin/geohash#func--encodeintwithprecision. ",
    "prettyyjnic": "It seem's like that it\u2018s because of windows 10 Ubuntu sub operation.\nThe problem solve while i used VMware. ",
    "unisqu": "\n\nWhat I would like to achieve:\nhttps://pastebin.com/raw/DZheFgwX\n\n\nOK.\n\n\nAlright. Thanks. Appreciate this.\n\n\nOnce 1. is resolved, will buy a cup of coffee donation. Thanks! . Very good.. I'm using https://pastebin.com/raw/fntT7PKJ\nit's actually as a package. How do I do cfg.DBName = \"RAM\" from a package called \"myLedisDB\"?\nI dont know how to call it in func main() too... but I prefer it's set inside \"myLedisDB\" package. Can you provide some guidance? Thanks.\ni've tried\nlediscfg.NewConfigDefault().DBName = \"RAM\" (doesnt work obviously)\nI've tried also inside \"package myLedisDB\" (which seems to be working)\n         func init() {\n                    cfg.DBName = \"RAM\"\n         }\n\nhow can I tell if it's working as RAM package library? is there a way to check?\n. 6s for 100,000 HMset, around 16666.6667 HMset per second. I would like to speed this up because I'm getting freecache for 100,000 set at 60ms, around 1,666,666.67 req/s using freecache set.\npossible to improve this? 16k hmset request/s i think it can be much higher, it's 100x slower than freecache\n. try this : \nhttps://pastebin.com/raw/df4pMAsz\npls give suggestions on how to speed it up. it's really too slow. I think 20x slower is acceptable but not  >20x slower... actually i think <10x slower is considered good.\nactually both are in RAM so i dont really understand why HASH should be so much slower.. > @unisqu\n\nThe RAW mod you used is wrong, here is my change:\n```go\nvar cfg lediscfg.Config\nvar fcachel ledis.Ledis\nvar fcachedb *ledis.DB\nfunc main() {\n  cfg = lediscfg.NewConfigDefault()\n  cfg.DBName = \"memory\"\n  var err error\n  fcachel, _ = ledis.Open(cfg)\n  fcachedb, _ = fcachel.Select(0)\n```\n\n\n\n\nI see a significant improvement from 6.5s to 5.3s with the above change. Thx\n\n\nI see, how to disable the WAL? I need it in memory mode only.\n\n\nthere's advantage to using hash data type in cache on my application. if memory is exceeded, what will happen? the hash \"key\" is dropped based on LRU? (i would prefer this way)\n\n\ni can rewrite the code for the \"pure ram version\" if u can guide me on the section to do so.\notherwise i would prefer getting the application up and temporary disabling WAL with code modification. Please point me to the direction for disabling WAL too. Thx.. by the way, i'm quite surprised there's no easier way to rewrite this... seems very \"redundant/extra\"\n       c := ledis.FVPair{Field: []byte(\"c\" + urlreq), Value: []byte(htmlcode)}\n       h := ledis.FVPair{Field: []byte(\"h\" + urlreq), Value: []byte(qwcache)}\n       t := ledis.FVPair{Field: []byte(\"t\" + urlreq), Value: []byte(strconv.Itoa(timeNow))}\n       s := ledis.FVPair{Field: []byte(\"s\" + urlreq), Value: []byte(strconv.Itoa(statuscode))}\n\n. > OOM\n\n\nis there a quick fix to this? limiting ram usage and evicting based on LRU. do you mind pointing me to where i can fix this myself? i can buy you a few more coffee for this feature.\n\n\nok i've seen the code to goleveldb... i think i can comment enough things to skip those goleveldb sections. \n\n\ntruly, this package is more useful if purely MEMORY only. I really thought it was just memory only but i can't believe still needing to go through goleveldb.\nfrom my assessment of your code, should only take 1 day for you to write for pure memory only with LRU.\nI dont mind waiting a bit for this but when do you think you can do this? over the weekend? . do you have alternatives for the moment that uses hash like data structure for cache in golang? in-memory. it doesn't have hash key field value\nonly key value\ngroupcache doesnt have expire value. ",
    "silentsokolov": "ok, thx. ",
    "mullikine": "Hi @siddontang ,\nShane from CodeLingo here. We stuffed up, sorry.\nWe made an error when writing a Tenet that was used on your repository that resulted in incorrect changes to your code in some edge cases. We've fixed the bug and improved our internal process to prevent this happening again.\nWe're keen to learn how we can best help dev teams without getting in your way. Your feedback would really help us, my email's shane@codelingo.io.\nThanks,\nShane & the CodeLingo Team. ",
    "liukun": "OK, will change.\n. convertBytesToString will handle nil case.\n. Yes, thanks. Will update later.\n. ",
    "HaraldNordgren": "@siddontang Updated.. "
}