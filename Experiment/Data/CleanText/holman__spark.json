{
    "holman": "jeez, don't run it without any args then.\nActually I'm not sure; it's hanging on the read because it's expecting it to come in from a pipe if there aren't any args. I haven't really done many scripts that accept input from a pipe; anyone know the best way to handle this particular scenario?\n. Cool; got it. Thanks!\n. Fixed in d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks!\n. Decided to go with printf: d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks, all!\n. I added another one in 5ad423bfb27b48c2e7845b12e631bd1217dc0733. My OCD won't allow those two extra blocks that go below the y-axis, though! :)\n. This should be fixed now. Thanks, all!\n. Duh. Careless mistake. Thanks!\n. Based on #39, I'm going to tentatively close this for now. If someone wants to open another pull for what's remaining (things like --max and --min), by all means. :metal:\n. Thanks!\n. I've gone with printf in d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks!\n. d03bd2c4311fd80ace7831cb8fe4467edd7736f1 should do the trick. Thanks!\n. Closed with 4ecdbe29c3d0930d5b6bd661465a3e26360bdf8d.\n. This is rad. And though it's a bit neater and I'm sure much faster than my own spark, I think I want to keep it shell-only right now. I encourage you to split this off into its own project, though!\n. This should be fixed now, thanks!\n. Love @webandy, but I do not care about namespace conflicts in other languages one bit.\n. I'm going with d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks to both of you!\n. WAY TOO MUCH MERGEBUTTONING\n. The fix you wanted was actually f07309fefe4293fa342ce68032300b7bdc76c8ef.\n. Should be fixed with #31, I think.\n. Cool!\nRuby's for chumps, though.\n. That's awesome. You can add it to the wiki yourself, though:\nhttps://github.com/holman/spark/wiki/Wicked-Cool-Usage\n. I was thinking the same thing as I was writing those examples.\n. Kaboom, #27.\n. I'd dig having tabs and newlines too (newlines in particular).\n. Can you pull down the latest? We don't use bc anymore.\n. Awesome.\nints-only right now (it's a regression since bc handled floats for us), but the aim is to fix that asap.\n. I think I am in like with you, peff.\n. Should be fixed with #31.\n. Love it. Going to suggest spaces for most operations from this point forward, I think.\n. Love the tests though. :) Love all of this, actually, aside from the bc call.\n. I think I'm getting a little skeptical of this. Don't get me wrong, the code looks good enough, but I really want to get a lot simpler than I already have rather than get a lot more complicated. Shell is fuckin' insane enough as it is.\nI think the better option at this point is to rethink how we can rewrite the majority of the script- if we need the multi-loop approach, etc. I just want something a bit more readable (as readable as shell can be, of course!)\nThanks for the work on this, though- I don't want to criticize what you've done, just criticize why floats are so hard in this stuff, heh.\n. Thanks for this. I did remove the debugging stuff, though. Just don't want to include it in the actual script (things are getting large enough already!) But thanks so much for digging into this!\n. Looks sharp; I've seen a lot of Python and Ruby samples floating around too. Goes to show that a higher-level language can be much more terse. :)\n. I'm going to :-1: this. I might add something to the README that explains a bit more, but I kind of love writing READMEs and have a particular style I want to maintain with them.\n. I might. I just don't want the top of my README to read that way.\n. distro?\n. I've been using Menlo; looks sharp.\n. Up front where?\n. It is 7.\nI think I'm going to hold off on this, mostly because I don't really want it to be estimated in that way. I mean, the sparkline is oft-criticized for being a graph that has statistical problems with it; expecting someone to try to calculate relative sizes of bars sends the wrong message, I think. I'd rather make it about the trending line rather than any absolute numbers.\nThanks, by the way. Much appreciated. :)\n. This is great work. Merged it in. Thanks so much for digging way way into this for me. I noticed something had broken it earlier but was too busy to actually dive in and see what the problem was.\n:+1:\n. Cool.\n. This is so awesome.\nI threw together spark one afternoon and have been waiting to go back and do something similar to this; it certainly needed a rewrite rather than the bunch of small changes that were being made. I'm more than happy that someone went ahead and did that before I sat down and did that. :)\nI've merged this in, updated the tests for the smarter calculations, and shipped it.\nThe only small problem: running ./spark just hangs on user input. Do you know of a decent way to check for that (and then just show help() in this case)?\nThanks again for your help!\n. Love it.\n. Awesome. Thanks for your help.\n. That's cool, but I think I want to keep things simple for the main spark script. By all means, keep it in your own script, though. :)\n. Pretty rad. I was thinking I probably needed to head up in this direction anyway. I'm out of town right now, but I'll push up a version as soon as I can.\n. Your wish is my command. Sorry for the delay; submit away!\n. Given enough popularity of a project, everything eventually turns to dicks. A+ for effort, though!\nB==:fist:==D :sweat_drops:\n. Formula's in there, so I'm pretty sure you just need to brew update first.\n. Awesome!\n. Cool! Thanks.\n. Not a huge fan of using environment variables here (probably), but I think given how we call spark this is a pretty non-invasive way of doing things.\n. Ended up reverting this due to various array errors. If someone wants to tackle this again, fix the edge cases, and add tests I'd be happy to merge it.\n. Closing (see https://github.com/holman/spark/pull/71#issuecomment-42779557).\n. Thanks!\n. Think there's some issues with GitHub at the moment with zip building. Sorry about that!\n. Pretty cool usage of it. I haven't really mucked with something like this before, though, so I don't know what the problem might be.\n. It should be okay with floats after https://github.com/holman/spark/issues/28... maybe there are some edge cases, however.\n. It's a strange feature, to be sure, but I'm going to stick with it for now.\n. I'm not interested in porting it to Python, but thanks- looks cool!\n. Yeah; I'm not interested in adding more dependencies.\n. It's a bug that we should probably fix, sure. To be honest, though, if you're looking for a very accurate graphs you should probably be running far away from sparklines in the first place.\n. Pulls (in bash) requested. :)\n. Who knows; mostly it's more fun to write it in bash.\n. Nice!\nThanks for this. :heart:\n. I like the idea, but I'm not a huge fan of the implementation. The colors don't really have any meaning. If it were all shades from cool to warm, that might make sense (although we're limited by typical shell color palettes), but I don't think there's a lot of definition to be had here regardless. It's mostly just color for color's sake.\nGoing to close this for now, but we can always revisit it in the future!\n. best-spark-ever\n. :) I think if there's a conflict I'd go with spark-shell.\n. I think I'm cool with that. Or maybe spark.sh. I'm at dinner and I've had a lot of wine so I reserve judgement on this a bit.\n. :)\nGoing to close this out, since there's nothing to do on spark's end now.\n. $b is really non-descriptive. Can you change it to $spark?\n. Thanks!\n. Going to go with #54 instead here.\n. I'm mostly just not into the additional code that comes with it.\n. I think I'm good with spark being a single-line thing, but thanks for the pull! Cool idea.\n. :+1:\n. There's a bit more than detailed in the pull's description here; if you want to send separate pulls for the printf or the basename call (or pull out the min/max commit) I can merge it in.\n. I think this was a temporary issue; give it another show and it should work for ya.\n. Work's been done in this in #54 and #70; haven't really sat down and looked at what makes sense to pull in yet.\n. #54.\n. 22439644fb39de086482d71d36a9251966affc67\n. Hm. Interesting thought, and it appeals to my everything-in-their-place part of my brain.\nI'm kind of on the fence; part of what I like about spark is that it's pretty accessible, particularly for people who might be new to shell scripts (or even programming at all!). It's a little thing, but tucking it away in bin/ might make it a bit more opaque, or otherwise give the impression that what's going on in here is more complicated than it is.\nMight be overthinking it, though. Would be curious on what other people think make the most sense here. (And if we move to bin/, we'll also need to update the README link and then probably add a test/ for the test files, too.)\n. I think I'm going to :-1: this; I like the discoverability of it right in the directory. Thanks for the idea, though!\n. #54 should fix this one up.\n. I think this came up awhile back as an aside in another pull request. It's too bad there's formatting differences for this, because Kate's screenshot looks prettttttty. I agree that it's likely best to hold off on this so we can keep a bit of consistency across environments, though.\n. I think spark's pretty simple enough to just plug in additional characters in the local copy of it rather than supporting a flag in the repo; don't think it's necessary to add more options.\n. Thanks for creating and linking the issue, @rogeruiz! I'm going to tentatively close this issue out. I'm subscribed on that thread, and if it ends up being a problem with Spark itself we can reopen and make some fixes.\n. Dig it! Thanks!\n. What's the current look of it in tmux?\n. Do you mind dropping in a quick screenshot here?\nI'm a little concerned about bloating things a little bit much (I don't think we'd need multiple color schemes, for example... maybe just a -c option), but I'm not totally :-1: on this yet either. Would be interested to hear what others think on this.\n. Ha, good catch. :)\n. Nice approach to it \u2014 I dig it. Thanks! :+1:\n. Huh- maybe it was just a temporary thing? Looks like the code in the README is correct when I checked it just now.\n. Ah, good call! Serves me right for putting something in the page that might change from time to time. I've fixed it (for the time being, ha).\n. Makes sense. There's some conflicts in this pull, though; if you resolve 'em I'd be happy to merge this.. jeez, don't run it without any args then.\nActually I'm not sure; it's hanging on the read because it's expecting it to come in from a pipe if there aren't any args. I haven't really done many scripts that accept input from a pipe; anyone know the best way to handle this particular scenario?\n. Cool; got it. Thanks!\n. Fixed in d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks!\n. Decided to go with printf: d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks, all!\n. I added another one in 5ad423bfb27b48c2e7845b12e631bd1217dc0733. My OCD won't allow those two extra blocks that go below the y-axis, though! :)\n. This should be fixed now. Thanks, all!\n. Duh. Careless mistake. Thanks!\n. Based on #39, I'm going to tentatively close this for now. If someone wants to open another pull for what's remaining (things like --max and --min), by all means. :metal:\n. Thanks!\n. I've gone with printf in d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks!\n. d03bd2c4311fd80ace7831cb8fe4467edd7736f1 should do the trick. Thanks!\n. Closed with 4ecdbe29c3d0930d5b6bd661465a3e26360bdf8d.\n. This is rad. And though it's a bit neater and I'm sure much faster than my own spark, I think I want to keep it shell-only right now. I encourage you to split this off into its own project, though!\n. This should be fixed now, thanks!\n. Love @webandy, but I do not care about namespace conflicts in other languages one bit.\n. I'm going with d03bd2c4311fd80ace7831cb8fe4467edd7736f1. Thanks to both of you!\n. WAY TOO MUCH MERGEBUTTONING\n. The fix you wanted was actually f07309fefe4293fa342ce68032300b7bdc76c8ef.\n. Should be fixed with #31, I think.\n. Cool!\nRuby's for chumps, though.\n. That's awesome. You can add it to the wiki yourself, though:\nhttps://github.com/holman/spark/wiki/Wicked-Cool-Usage\n. I was thinking the same thing as I was writing those examples.\n. Kaboom, #27.\n. I'd dig having tabs and newlines too (newlines in particular).\n. Can you pull down the latest? We don't use bc anymore.\n. Awesome.\nints-only right now (it's a regression since bc handled floats for us), but the aim is to fix that asap.\n. I think I am in like with you, peff.\n. Should be fixed with #31.\n. Love it. Going to suggest spaces for most operations from this point forward, I think.\n. Love the tests though. :) Love all of this, actually, aside from the bc call.\n. I think I'm getting a little skeptical of this. Don't get me wrong, the code looks good enough, but I really want to get a lot simpler than I already have rather than get a lot more complicated. Shell is fuckin' insane enough as it is.\nI think the better option at this point is to rethink how we can rewrite the majority of the script- if we need the multi-loop approach, etc. I just want something a bit more readable (as readable as shell can be, of course!)\nThanks for the work on this, though- I don't want to criticize what you've done, just criticize why floats are so hard in this stuff, heh.\n. Thanks for this. I did remove the debugging stuff, though. Just don't want to include it in the actual script (things are getting large enough already!) But thanks so much for digging into this!\n. Looks sharp; I've seen a lot of Python and Ruby samples floating around too. Goes to show that a higher-level language can be much more terse. :)\n. I'm going to :-1: this. I might add something to the README that explains a bit more, but I kind of love writing READMEs and have a particular style I want to maintain with them.\n. I might. I just don't want the top of my README to read that way.\n. distro?\n. I've been using Menlo; looks sharp.\n. Up front where?\n. It is 7.\nI think I'm going to hold off on this, mostly because I don't really want it to be estimated in that way. I mean, the sparkline is oft-criticized for being a graph that has statistical problems with it; expecting someone to try to calculate relative sizes of bars sends the wrong message, I think. I'd rather make it about the trending line rather than any absolute numbers.\nThanks, by the way. Much appreciated. :)\n. This is great work. Merged it in. Thanks so much for digging way way into this for me. I noticed something had broken it earlier but was too busy to actually dive in and see what the problem was.\n:+1:\n. Cool.\n. This is so awesome.\nI threw together spark one afternoon and have been waiting to go back and do something similar to this; it certainly needed a rewrite rather than the bunch of small changes that were being made. I'm more than happy that someone went ahead and did that before I sat down and did that. :)\nI've merged this in, updated the tests for the smarter calculations, and shipped it.\nThe only small problem: running ./spark just hangs on user input. Do you know of a decent way to check for that (and then just show help() in this case)?\nThanks again for your help!\n. Love it.\n. Awesome. Thanks for your help.\n. That's cool, but I think I want to keep things simple for the main spark script. By all means, keep it in your own script, though. :)\n. Pretty rad. I was thinking I probably needed to head up in this direction anyway. I'm out of town right now, but I'll push up a version as soon as I can.\n. Your wish is my command. Sorry for the delay; submit away!\n. Given enough popularity of a project, everything eventually turns to dicks. A+ for effort, though!\nB==:fist:==D :sweat_drops:\n. Formula's in there, so I'm pretty sure you just need to brew update first.\n. Awesome!\n. Cool! Thanks.\n. Not a huge fan of using environment variables here (probably), but I think given how we call spark this is a pretty non-invasive way of doing things.\n. Ended up reverting this due to various array errors. If someone wants to tackle this again, fix the edge cases, and add tests I'd be happy to merge it.\n. Closing (see https://github.com/holman/spark/pull/71#issuecomment-42779557).\n. Thanks!\n. Think there's some issues with GitHub at the moment with zip building. Sorry about that!\n. Pretty cool usage of it. I haven't really mucked with something like this before, though, so I don't know what the problem might be.\n. It should be okay with floats after https://github.com/holman/spark/issues/28... maybe there are some edge cases, however.\n. It's a strange feature, to be sure, but I'm going to stick with it for now.\n. I'm not interested in porting it to Python, but thanks- looks cool!\n. Yeah; I'm not interested in adding more dependencies.\n. It's a bug that we should probably fix, sure. To be honest, though, if you're looking for a very accurate graphs you should probably be running far away from sparklines in the first place.\n. Pulls (in bash) requested. :)\n. Who knows; mostly it's more fun to write it in bash.\n. Nice!\nThanks for this. :heart:\n. I like the idea, but I'm not a huge fan of the implementation. The colors don't really have any meaning. If it were all shades from cool to warm, that might make sense (although we're limited by typical shell color palettes), but I don't think there's a lot of definition to be had here regardless. It's mostly just color for color's sake.\nGoing to close this for now, but we can always revisit it in the future!\n. best-spark-ever\n. :) I think if there's a conflict I'd go with spark-shell.\n. I think I'm cool with that. Or maybe spark.sh. I'm at dinner and I've had a lot of wine so I reserve judgement on this a bit.\n. :)\nGoing to close this out, since there's nothing to do on spark's end now.\n. $b is really non-descriptive. Can you change it to $spark?\n. Thanks!\n. Going to go with #54 instead here.\n. I'm mostly just not into the additional code that comes with it.\n. I think I'm good with spark being a single-line thing, but thanks for the pull! Cool idea.\n. :+1:\n. There's a bit more than detailed in the pull's description here; if you want to send separate pulls for the printf or the basename call (or pull out the min/max commit) I can merge it in.\n. I think this was a temporary issue; give it another show and it should work for ya.\n. Work's been done in this in #54 and #70; haven't really sat down and looked at what makes sense to pull in yet.\n. #54.\n. 22439644fb39de086482d71d36a9251966affc67\n. Hm. Interesting thought, and it appeals to my everything-in-their-place part of my brain.\nI'm kind of on the fence; part of what I like about spark is that it's pretty accessible, particularly for people who might be new to shell scripts (or even programming at all!). It's a little thing, but tucking it away in bin/ might make it a bit more opaque, or otherwise give the impression that what's going on in here is more complicated than it is.\nMight be overthinking it, though. Would be curious on what other people think make the most sense here. (And if we move to bin/, we'll also need to update the README link and then probably add a test/ for the test files, too.)\n. I think I'm going to :-1: this; I like the discoverability of it right in the directory. Thanks for the idea, though!\n. #54 should fix this one up.\n. I think this came up awhile back as an aside in another pull request. It's too bad there's formatting differences for this, because Kate's screenshot looks prettttttty. I agree that it's likely best to hold off on this so we can keep a bit of consistency across environments, though.\n. I think spark's pretty simple enough to just plug in additional characters in the local copy of it rather than supporting a flag in the repo; don't think it's necessary to add more options.\n. Thanks for creating and linking the issue, @rogeruiz! I'm going to tentatively close this issue out. I'm subscribed on that thread, and if it ends up being a problem with Spark itself we can reopen and make some fixes.\n. Dig it! Thanks!\n. What's the current look of it in tmux?\n. Do you mind dropping in a quick screenshot here?\nI'm a little concerned about bloating things a little bit much (I don't think we'd need multiple color schemes, for example... maybe just a -c option), but I'm not totally :-1: on this yet either. Would be interested to hear what others think on this.\n. Ha, good catch. :)\n. Nice approach to it \u2014 I dig it. Thanks! :+1:\n. Huh- maybe it was just a temporary thing? Looks like the code in the README is correct when I checked it just now.\n. Ah, good call! Serves me right for putting something in the page that might change from time to time. I've fixed it (for the time being, ha).\n. Makes sense. There's some conflicts in this pull, though; if you resolve 'em I'd be happy to merge this.. ",
    "eyko": "On my machine (Mac OSX), man echo says:\n```\n The following option is available:\n-n    Do not print the trailing newline character.  This may also be\n       achieved by appending \\c' to the end of the string, as is done by\n       iBCS2 compatible systems.  Note that this option as well as the\n       effect of\\c' are implementation-defined in IEEE Std 1003.1-2001\n       (``POSIX.1'') as amended by Cor. 1-2002.  Applications aiming for\n       maximum portability are strongly encouraged to use printf(1) to\n       suppress the newline character.\n```\nI wonder if it's better to use printf? Either way, I've modified mine to use -n, although -e also works for me, so nitrogeniogic's commit fixes the new line bug in my case too.\n. Hm, nice to know, thanks!\nedit: Oh, i guess help echo only works for bash, which makes sense (I'm using zsh).\n. On my machine (Mac OSX), man echo says:\n```\n The following option is available:\n-n    Do not print the trailing newline character.  This may also be\n       achieved by appending \\c' to the end of the string, as is done by\n       iBCS2 compatible systems.  Note that this option as well as the\n       effect of\\c' are implementation-defined in IEEE Std 1003.1-2001\n       (``POSIX.1'') as amended by Cor. 1-2002.  Applications aiming for\n       maximum portability are strongly encouraged to use printf(1) to\n       suppress the newline character.\n```\nI wonder if it's better to use printf? Either way, I've modified mine to use -n, although -e also works for me, so nitrogeniogic's commit fixes the new line bug in my case too.\n. Hm, nice to know, thanks!\nedit: Oh, i guess help echo only works for bash, which makes sense (I'm using zsh).\n. ",
    "nitrogenlogic": "Yeah, printf would be better, but I opted for the least invasive change possible.\nAlso note that man echo and help echo will refer to different things -- man provides documentation on /bin/echo, while help (if available) documents the shell's built-in version.\n. Yeah, printf would be better, but I opted for the least invasive change possible.\nAlso note that man echo and help echo will refer to different things -- man provides documentation on /bin/echo, while help (if available) documents the shell's built-in version.\n. ",
    "quag": "I was just wondering the same thing: only 6 of the 8 characters are used (http://www.fileformat.info/info/unicode/block/block_elements/utf8test.htm). My guess is that the font holman is using displays the missing two characters in an odd way.\n. I was just wondering the same thing: only 6 of the 8 characters are used (http://www.fileformat.info/info/unicode/block/block_elements/utf8test.htm). My guess is that the font holman is using displays the missing two characters in an odd way.\n. ",
    "canadaduane": "http://dl.dropbox.com/u/118766/misc/github-spark-why-not-all-eight.png\n. http://dl.dropbox.com/u/118766/misc/github-spark-why-not-all-eight.png\n. ",
    "DrewDouglass": "I'm relatively new to setting up shell scripts, but I'm also getting this type of output. OS X 10.7.2\nbash --version\nGNU bash, version 3.2.48(1)-release (x86_64-apple-darwin11)\nIf I need to include more information, I'd be happy to, please just let me know.\n. Thanks @cathoderay, that fixed it right up.\n. This should probably be merged with https://github.com/holman/spark/issues/7\n. I'm relatively new to setting up shell scripts, but I'm also getting this type of output. OS X 10.7.2\nbash --version\nGNU bash, version 3.2.48(1)-release (x86_64-apple-darwin11)\nIf I need to include more information, I'd be happy to, please just let me know.\n. Thanks @cathoderay, that fixed it right up.\n. This should probably be merged with https://github.com/holman/spark/issues/7\n. ",
    "artemiy-rodionov": "confirm  bug\n bash --version\nGNU bash, \u0432\u0435\u0440\u0441\u0438\u044f 4.2.10(1)-release (i686-pc-linux-gnu)\n. confirm  bug\n bash --version\nGNU bash, \u0432\u0435\u0440\u0441\u0438\u044f 4.2.10(1)-release (i686-pc-linux-gnu)\n. ",
    "cathoderay": "confirm bug 2\nbash --version\nGNU bash, version 4.2.10(1)-release (x86_64-pc-linux-gnu)\n. made a pull request to fix it\n. confirm bug 2\nbash --version\nGNU bash, version 4.2.10(1)-release (x86_64-pc-linux-gnu)\n. made a pull request to fix it\n. ",
    "etanol": "Much better indeed.  Just like with Python or Ruby interpreters.\n. Much better indeed.  Just like with Python or Ruby interpreters.\n. ",
    "yuchi": "replace the whole print_ticks function on line 117 with:\n``` bash\nIterate over all of our ticks and print them out.\n\nReturns nothing.\nprint_ticks()\n{\n  TEMP=\"\"\n  for number in ${numbers[@]}\n  do\n    TEMP+=$\"$(print_tick $number)\"\n  done\n  echo $TEMP\n  echo \"\"\n}\n```\nHad the same problem on Ubuntu, this solved it. Would you mind to check if it works on OSX too?\n. Update: Pull request #12 addresses the same issue, follow _that_ solution, not mine please :)\n. replace the whole print_ticks function on line 117 with:\n``` bash\nIterate over all of our ticks and print them out.\n\nReturns nothing.\nprint_ticks()\n{\n  TEMP=\"\"\n  for number in ${numbers[@]}\n  do\n    TEMP+=$\"$(print_tick $number)\"\n  done\n  echo $TEMP\n  echo \"\"\n}\n```\nHad the same problem on Ubuntu, this solved it. Would you mind to check if it works on OSX too?\n. Update: Pull request #12 addresses the same issue, follow _that_ solution, not mine please :)\n. ",
    "agborkowski": "both of solutions works better but sill its something wrong for me lok at 2 coulmns at start http://dl.dropbox.com/u/2925509/Screen%20Shot%202011-11-15%20at%202.38.40%20PM.png\n. both of solutions works better but sill its something wrong for me lok at 2 coulmns at start http://dl.dropbox.com/u/2925509/Screen%20Shot%202011-11-15%20at%202.38.40%20PM.png\n. ",
    "severin": "No problem, just wanted to let you know...\n. No problem, just wanted to let you know...\n. ",
    "webandy": "Haha, whoops. Thanks Zach.\n. Haha, whoops. Thanks Zach.\n. ",
    "rupa": "I'd prefer printf \"%s\" $\"$(print_tick $number)\", for portability.\n. I'd prefer printf \"%s\" $\"$(print_tick $number)\", for portability.\n. ",
    "tombell": "Yes that is the one!\n. Yes that is the one!\n. ",
    "gwern": "I think there's something wrong in the mapping algorithm. Look at this behavior with HEAD:\n[03:12 PM] 145Mb$ echo 1 2  | spark\n\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 | spark\n\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 | spark\n\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 | spark\n\u2587\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 | spark\n\u2587\u2587\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 7 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:13 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 9 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:13 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 9 10 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\nThat can't be right... For example, I'd expect '1 2' to map either onto \u2581\u2582 or \u2581\u2587, and likewise, '1 2 3' to map onto \u2581\u2582\u2583 or \u2581\u2584\u2587, '1 2 3 4' to be \u2581\u2582\u2583\u2584 or \u2581\u2583\u2585\u2587 etc.\n. Looks good:\n$ spark 1 2\n\u2581\u2582\n$ spark 1 2 3 \n\u2581\u2582\u2583\n$ spark 1 2 7\n\u2581\u2582\u2587\n$ spark 1 2 10\n\u2581\u2582\u2587\n$ spark 1 2 3 4\n\u2581\u2582\u2583\u2584\n. So that's just supporting spaces? What about tabs or newlines? Newlines would be helpful for #9, inasmuch as HEAD spark now only reads one line:\n[02:35 PM] 145Mb$ echo -e 1\\n5\\n6\\n10\\n15\\n10\\n11\\n4 | spark\n\u2587\nvs\n[02:34 PM] 145Mb$ spark 1 5 6 10 15 10 11 4\n\u2581\u2583\u2583\u2585\u2585\u2586\u2582\n. That shouldn't be too hard, especially since you're already using tr to handle one form of whitespace - just use one of the more general character classes tr defines.\n. This will hopefully address all the comments on Hacker News complaining 'I don't know what this is talking about'\n. I don't think 'style' is a very good reason to not inform readers; at least link to Wikipedia or something!\n. If you don't want to link to Wikipedia, you could just throw in a link to Tufte's big page on sparklines: http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&topic_id=1\n. FWIW, I agree with the alternate algorithm. The maximum input should be set the the 7th element and the minimum input should be set to the 0th element and everything graphed in between - we should be showing as much variation as exists, not whatever the current thing is. I wrote a Haskell script to preprocess the numbers down into a scaled 0-7, and the difference is dramatic:\n$ runhaskell scale.hs 50 50 50 51 52 | spark # input: 0.0 0.0 0.0 3.5 7.0\n\u2581\u2581\u2581\u2584\u2587\n$ spark 50 50 50 51 52\n\u2588\u2588\u2588\u2588\u2588\nThe latter is almost completely useless. There may be times when that behavior (over-emphasizing the absolute values) makes sense, but I think they are many fewer than when it doesn't make sense - which is most inputs using large numbers and many using small numbers.\nThe Haskell script:\n``` haskell\nimport System.Environment (getArgs)\nmain :: IO ()\nmain = do args <- getArgs\n          let n = map read args :: [Int]\n              mx = maximum n\n              mn = minimum n\n              scale x = fromIntegral (x - mn) * 7 / fromIntegral (mx - mn) :: Double\n              scaled = map scale n\n          putStrLn $ unwords $ map show scaled\n``\n. I dunno. Tough problem; when you callcat, it takes over control. And you can't simply check$#because then you break piping in, when there are no arguments. If we were usingread, there's a time-out option or length option we could use, but as pointed out before,readon its own is horrible and needs to be in a complicated loop according to the examples I saw. We _could_ do something hacky like(sleep 10s && help && exit)` but that doesn't work too well in practice.\nhttp://stackoverflow.com/questions/635361/ksh-how-to-probe-stdin is probably relevant.\n. I didn't know about that. I tried a little with the TTY stuff in that stack exchange link but didn't see what it was supposed to do.\n. I think there's something wrong in the mapping algorithm. Look at this behavior with HEAD:\n[03:12 PM] 145Mb$ echo 1 2  | spark\n\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 | spark\n\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 | spark\n\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 | spark\n\u2587\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 | spark\n\u2587\u2587\u2587\u2587\u2587\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 7 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:12 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:13 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 9 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\n[03:13 PM] 145Mb$ echo 1 2 3 4 5 6 7 8 9 10 | spark\n\u2581\u2582\u2583\u2584\u2585\u2586\u2587\nThat can't be right... For example, I'd expect '1 2' to map either onto \u2581\u2582 or \u2581\u2587, and likewise, '1 2 3' to map onto \u2581\u2582\u2583 or \u2581\u2584\u2587, '1 2 3 4' to be \u2581\u2582\u2583\u2584 or \u2581\u2583\u2585\u2587 etc.\n. Looks good:\n$ spark 1 2\n\u2581\u2582\n$ spark 1 2 3 \n\u2581\u2582\u2583\n$ spark 1 2 7\n\u2581\u2582\u2587\n$ spark 1 2 10\n\u2581\u2582\u2587\n$ spark 1 2 3 4\n\u2581\u2582\u2583\u2584\n. So that's just supporting spaces? What about tabs or newlines? Newlines would be helpful for #9, inasmuch as HEAD spark now only reads one line:\n[02:35 PM] 145Mb$ echo -e 1\\n5\\n6\\n10\\n15\\n10\\n11\\n4 | spark\n\u2587\nvs\n[02:34 PM] 145Mb$ spark 1 5 6 10 15 10 11 4\n\u2581\u2583\u2583\u2585\u2585\u2586\u2582\n. That shouldn't be too hard, especially since you're already using tr to handle one form of whitespace - just use one of the more general character classes tr defines.\n. This will hopefully address all the comments on Hacker News complaining 'I don't know what this is talking about'\n. I don't think 'style' is a very good reason to not inform readers; at least link to Wikipedia or something!\n. If you don't want to link to Wikipedia, you could just throw in a link to Tufte's big page on sparklines: http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&topic_id=1\n. FWIW, I agree with the alternate algorithm. The maximum input should be set the the 7th element and the minimum input should be set to the 0th element and everything graphed in between - we should be showing as much variation as exists, not whatever the current thing is. I wrote a Haskell script to preprocess the numbers down into a scaled 0-7, and the difference is dramatic:\n$ runhaskell scale.hs 50 50 50 51 52 | spark # input: 0.0 0.0 0.0 3.5 7.0\n\u2581\u2581\u2581\u2584\u2587\n$ spark 50 50 50 51 52\n\u2588\u2588\u2588\u2588\u2588\nThe latter is almost completely useless. There may be times when that behavior (over-emphasizing the absolute values) makes sense, but I think they are many fewer than when it doesn't make sense - which is most inputs using large numbers and many using small numbers.\nThe Haskell script:\n``` haskell\nimport System.Environment (getArgs)\nmain :: IO ()\nmain = do args <- getArgs\n          let n = map read args :: [Int]\n              mx = maximum n\n              mn = minimum n\n              scale x = fromIntegral (x - mn) * 7 / fromIntegral (mx - mn) :: Double\n              scaled = map scale n\n          putStrLn $ unwords $ map show scaled\n``\n. I dunno. Tough problem; when you callcat, it takes over control. And you can't simply check$#because then you break piping in, when there are no arguments. If we were usingread, there's a time-out option or length option we could use, but as pointed out before,readon its own is horrible and needs to be in a complicated loop according to the examples I saw. We _could_ do something hacky like(sleep 10s && help && exit)` but that doesn't work too well in practice.\nhttp://stackoverflow.com/questions/635361/ksh-how-to-probe-stdin is probably relevant.\n. I didn't know about that. I tried a little with the TTY stuff in that stack exchange link but didn't see what it was supposed to do.\n. ",
    "jcromartie": "Oh, and it works with space-separated lists and xargs without tr and sed.\n. Oh, and it works with space-separated lists and xargs without tr and sed.\n. ",
    "Naatan": "To me the charm of a script like this would be that I can easily run it on just about any linux environment, if it were based on Ruby that'd be a whole other story. I personally only have Ruby installed if the server in question is purposed for a Ruby app.\n. To me the charm of a script like this would be that I can easily run it on just about any linux environment, if it were based on Ruby that'd be a whole other story. I personally only have Ruby installed if the server in question is purposed for a Ruby app.\n. ",
    "timrandg": "The sparks print out best with a fixed width font like Menlo Regular, 17 font, slightly increased character spacing (~1.06) and line spacing (~1.13). Also, ruby version is sweet!\n. This is a great idea. On my mac (OS X 10.7.2). Terminal is printing out some ticks below the baseline. Spacing is also an issue with some ticks wider and some thinner. I tried changing font, linespacing etc. Nothing seems to cahnge it. See example below. I would imagine that your nice looking sparks require your terminal settings--perhaps you could kindly post them if it is in fact pertinent. Thanks for the cool script. \n./spark 0 30 55 80 33 150\n\u2581\u2582\u2584\u2585\u2582\u2588\n. The sparks print out best with a fixed width font like Menlo Regular, 17 font, slightly increased character spacing (~1.06) and line spacing (~1.13). Also, ruby version is sweet!\n. This is a great idea. On my mac (OS X 10.7.2). Terminal is printing out some ticks below the baseline. Spacing is also an issue with some ticks wider and some thinner. I tried changing font, linespacing etc. Nothing seems to cahnge it. See example below. I would imagine that your nice looking sparks require your terminal settings--perhaps you could kindly post them if it is in fact pertinent. Thanks for the cool script. \n./spark 0 30 55 80 33 150\n\u2581\u2582\u2584\u2585\u2582\u2588\n. ",
    "ghedamat": "woops :P sorry :) \n. yup, we corrected the same thing :-) tnx!\n. woops :P sorry :) \n. yup, we corrected the same thing :-) tnx!\n. ",
    "wenestvedt-zz": "Doing it now\u2026..\nHey, GREAT!  It is heaaaaled!\nThanks, this is lovely and I intend to use it to tun some boring text walls into eye candy mountain ranges. :7)\n- Will\n  P.S.  It only works on whole numbers, right?\n  On Nov 15, 2011, at 2:21 PM, Zach Holman wrote:\n\nCan you pull down the latest? We don't use bc anymore.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/issues/24#issuecomment-2749606\n\n\nWill Enestvedt\nwille@enestvedt.net\n\"There is always an easy solution to every human problem--neat, \nplausible, and wrong.\" -- H.L. Mencken\n. Doing it now\u2026..\nHey, GREAT!  It is heaaaaled!\nThanks, this is lovely and I intend to use it to tun some boring text walls into eye candy mountain ranges. :7)\n- Will\n  P.S.  It only works on whole numbers, right?\n  On Nov 15, 2011, at 2:21 PM, Zach Holman wrote:\n\nCan you pull down the latest? We don't use bc anymore.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/issues/24#issuecomment-2749606\n\n\nWill Enestvedt\nwille@enestvedt.net\n\"There is always an easy solution to every human problem--neat, \nplausible, and wrong.\" -- H.L. Mencken\n. ",
    "joshmoore": "bc or rewrite in Python? :)\n. Version in P(ython) in gh-41 for review.\n. This includes the fix from #19 (PR #26)\n. Streams in 7879797. ;) Thanks for the distraction!\n. bc or rewrite in Python? :)\n. Version in P(ython) in gh-41 for review.\n. This includes the fix from #19 (PR #26)\n. Streams in 7879797. ;) Thanks for the distraction!\n. ",
    "mjdominus": "I'm fixing it now. It's not even as complicated as I thought it might be.\n. Commit 0cde7d00 fixes this. The solution is somewhat ridiculous, but it works, the tests pass, and it is fast.\n. Commit 0cde7d0 removes the dependency on bc.  You're right, it is a lot faster without bc.\n. That's okay, I thought it was a fool's errand anyway.  Shell is clearly the wrong language for this project, since it would be rewritten in one of the P languages in about three lines.  I'll probably redo it in Perl for my own use.\nThanks for the idea though. I had fun screwing around with rational arithmetic in bash.\n. My commit ccd59de adds a -d flag to enable debugging mode; you may find this useful.\n. I'm fixing it now. It's not even as complicated as I thought it might be.\n. Commit 0cde7d00 fixes this. The solution is somewhat ridiculous, but it works, the tests pass, and it is fast.\n. Commit 0cde7d0 removes the dependency on bc.  You're right, it is a lot faster without bc.\n. That's okay, I thought it was a fool's errand anyway.  Shell is clearly the wrong language for this project, since it would be rewritten in one of the P languages in about three lines.  I'll probably redo it in Perl for my own use.\nThanks for the idea though. I had fun screwing around with rational arithmetic in bash.\n. My commit ccd59de adds a -d flag to enable debugging mode; you may find this useful.\n. ",
    "singpolyma": "bc is standard btw: http://pubs.opengroup.org/onlinepubs/009695399/utilities/bc.htmlw though the implementation you have may have extensions\nIt should be possible to remove the bash dependency also, I'll look into that.\n. bc is standard btw: http://pubs.opengroup.org/onlinepubs/009695399/utilities/bc.htmlw though the implementation you have may have extensions\nIt should be possible to remove the bash dependency also, I'll look into that.\n. ",
    "ecto": "Hahahahaha\n. Hahahahaha\n. ",
    "stwalkerster": "ubuntu oneiric :)\n. ubuntu oneiric :)\n. ",
    "l0b0": "@stwalkerster: What's the output of locale?\n. Closing because it's been fixed in parallel.. @stwalkerster: What's the output of locale?\n. Closing because it's been fixed in parallel.. ",
    "malvim": "I have the same issue, on RHEL. Here's the output of locale on my box:\nLANG=en_US.UTF-8\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\nLC_ALL=\n. Sorry, I should also tell that I'm logging into this box via ssh using PuTTY on Windows. :/\nSetting PuTTY to use UTF-8 gives better results, but still not the intended ones. When I run spark 2 4 1, I get the blank square for 2 and 1, and the correct character in the middle (for 4).\n. Alright, this was a font issue on Windows. Spark works out-of-the-box on my personal MacBook, but here at work, I had to:\n1) set PuTTY's \"Window/Translation\" setting to use UTF-8\n2) Change the font, since Courier New doesn't have the correct characters. I used DejaVu Sans Mono, which works. I'm sure there are others.\n. I have the same issue, on RHEL. Here's the output of locale on my box:\nLANG=en_US.UTF-8\nLC_CTYPE=\"en_US.UTF-8\"\nLC_NUMERIC=\"en_US.UTF-8\"\nLC_TIME=\"en_US.UTF-8\"\nLC_COLLATE=\"en_US.UTF-8\"\nLC_MONETARY=\"en_US.UTF-8\"\nLC_MESSAGES=\"en_US.UTF-8\"\nLC_PAPER=\"en_US.UTF-8\"\nLC_NAME=\"en_US.UTF-8\"\nLC_ADDRESS=\"en_US.UTF-8\"\nLC_TELEPHONE=\"en_US.UTF-8\"\nLC_MEASUREMENT=\"en_US.UTF-8\"\nLC_IDENTIFICATION=\"en_US.UTF-8\"\nLC_ALL=\n. Sorry, I should also tell that I'm logging into this box via ssh using PuTTY on Windows. :/\nSetting PuTTY to use UTF-8 gives better results, but still not the intended ones. When I run spark 2 4 1, I get the blank square for 2 and 1, and the correct character in the middle (for 4).\n. Alright, this was a font issue on Windows. Spark works out-of-the-box on my personal MacBook, but here at work, I had to:\n1) set PuTTY's \"Window/Translation\" setting to use UTF-8\n2) Change the font, since Courier New doesn't have the correct characters. I used DejaVu Sans Mono, which works. I'm sure there are others.\n. ",
    "deanius": "Probably both the README, and spark -h\nIs it 7 ?\nVery nice work, btw..\nOn Tue, Nov 15, 2011 at 6:33 PM, Zach Holman\nreply@reply.github.com\nwrote:\n\nUp front where?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/issues/36#issuecomment-2753866\n. Probably both the README, and spark -h\n\nIs it 7 ?\nVery nice work, btw..\nOn Tue, Nov 15, 2011 at 6:33 PM, Zach Holman\nreply@reply.github.com\nwrote:\n\nUp front where?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/issues/36#issuecomment-2753866\n. \n",
    "markusfisch": "You're welcome!\nI found spark so nice, I was kind of sucked into it and just couldn't stop\n:)\nAbout that terminal problem; originally I had taken that out because I\nthought it would be nice to be able to cut and paste some data into the\nterminal. And because most unix tools accept the terminal as stdin too.\nBut you have a point, so my solution for this would be:\nif ([ -z $1 ] && [ -t 0 ]) || [ \"$1\" == '-h' ]\nthen\n    help\n    exit\nfi\nI'll put this into another pull request.\nOn Thu, 17 Nov 2011 23:20:34 +0100, Zach Holman\nreply@reply.github.com\nwrote:\n\nThis is so awesome.\nI threw together spark one afternoon and have been waiting to go back\nand do something similar to this; it certainly needed a rewrite rather\nthan the bunch of small changes that were being made. I'm more than\nhappy that someone went ahead and did that before I sat down and did\nthat. :)\nI've merged this in, updated the tests for the smarter calculations, and\nshipped it.\nThe only small problem: running ./spark just hangs on user input. Do\nyou know of a decent way to check for that (and then just show help()\nin this case)?\nThanks again for your help!\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/pull/42#issuecomment-2782961\n\n\nO         ,-\n  \u00b0 o    . -\u00b4  '     ,-\n   \u00b0  .\u00b4        . \u00b4,\u00b4\n     ( \u00b0   ))     . (-;    . -\u00b4 ..\n          `.'       \u00b4\nMarkus Fisch\nhttp://markusfisch.de\n. Thanks for the tip, but the original test whether stdin is a terminal\n[ -t 0 ]\nis working fine for me, at least on Linux (with bash 4.1.9) and OS X (with\nbash 3.2.48).\nDoesn't that work in your environment?\nOn Fri, 18 Nov 2011 01:44:47 +0100, gwern\nreply@reply.github.com\nwrote:\n\nI dunno. Tough problem; when you call cat, it takes over control. And\nyou can't simply check $# because then you break piping in, when there\nare no arguments. If we were using read, there's a time-out option or\nlength option we could use, but as pointed out before, read on its own\nis horrible and needs to be in a complicated loop according to the\nexamples I saw. We could do something hacky like (sleep 10s && help  \n&& exit) but that doesn't work too well in practice.\nhttp://stackoverflow.com/questions/635361/ksh-how-to-probe-stdin is\nprobably relevant.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/pull/42#issuecomment-2784308\n\n\nO         ,-\n  \u00b0 o    . -\u00b4  '     ,-\n   \u00b0  .\u00b4        . \u00b4,\u00b4\n     ( \u00b0   ))     . (-;    . -\u00b4 ..\n          `.'       \u00b4\nMarkus Fisch\nhttp://markusfisch.de\n. Look at the comments I made in line 39. Floats get their fractional part cut off because there's no portable way of reading them and bash does only work with integers anyway.\nSo my advice would be to simply multiply the input values to become integers.\n. Actually that's a feature since 010 is interpreted as octal number because of the 0 prefix. See man bash for more info about that or just try:\necho $(( 010 ))\nWhich gives 8 decimal.\n. @rsvp \nYou may want to add this to your .bashrc or .bash_aliases or .profile:\nalias fspark=\"awk '{ for(i = 1; i <= NF; ++i) print \\$i*1000 }' | spark\"\nThen, magically, you can use floats with spark:\n$ echo .3 .51. .75 | fspark\nIt's just not that much of a problem.\n. @rsvp \nThere is no overflow problem.\nWhy? Because spark has a resolution of 8. That means, all numbers you fire through spark get scaled within 8.\nTherefore, to show anything of meaning, the input numbers must differ significantly when scaled within 8. You won't get any meaning of the fractional part in input like this: 1.2 90 499. The fractional part is just scaled away.\nSo using very big numbers together with very small numbers doesn't make sense.\nThe purpose of spark is to show relative differences on a scale of 8 and it does that well. There's no need to pull in python (or any other dependency) to do this. It can all be done with bash only and that's all it should need.\nIt's very easy to scale your input values (whatever they may be) to get into a meaningful range. That conversion should not be part of spark because converting data is another matter (and probably part of a specific domain).\nYou might have heard of the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. ...\nPlease respect that spark tries to follow that philosophy.\nOne last word about dependencies. Please, do always question them and don't just pull them in blindly. You suspect there's virtually no situation where there is bash but no python. From the top of my mind: A windows box with git bash. Android terminal emulators.\nIf you prefer python, that's okay. A fork is nice. But then you should consider using python only and no bash. For the very same reasons. A windows box may have python but no bash.\n. $ echo -0.20 0.08 0.20 -0.20 | fspark\nWorks well. qed.\n. You're welcome!\nI found spark so nice, I was kind of sucked into it and just couldn't stop\n:)\nAbout that terminal problem; originally I had taken that out because I\nthought it would be nice to be able to cut and paste some data into the\nterminal. And because most unix tools accept the terminal as stdin too.\nBut you have a point, so my solution for this would be:\nif ([ -z $1 ] && [ -t 0 ]) || [ \"$1\" == '-h' ]\nthen\n    help\n    exit\nfi\nI'll put this into another pull request.\nOn Thu, 17 Nov 2011 23:20:34 +0100, Zach Holman\nreply@reply.github.com\nwrote:\n\nThis is so awesome.\nI threw together spark one afternoon and have been waiting to go back\nand do something similar to this; it certainly needed a rewrite rather\nthan the bunch of small changes that were being made. I'm more than\nhappy that someone went ahead and did that before I sat down and did\nthat. :)\nI've merged this in, updated the tests for the smarter calculations, and\nshipped it.\nThe only small problem: running ./spark just hangs on user input. Do\nyou know of a decent way to check for that (and then just show help()\nin this case)?\nThanks again for your help!\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/pull/42#issuecomment-2782961\n\n\nO         ,-\n  \u00b0 o    . -\u00b4  '     ,-\n   \u00b0  .\u00b4        . \u00b4,\u00b4\n     ( \u00b0   ))     . (-;    . -\u00b4 ..\n          `.'       \u00b4\nMarkus Fisch\nhttp://markusfisch.de\n. Thanks for the tip, but the original test whether stdin is a terminal\n[ -t 0 ]\nis working fine for me, at least on Linux (with bash 4.1.9) and OS X (with\nbash 3.2.48).\nDoesn't that work in your environment?\nOn Fri, 18 Nov 2011 01:44:47 +0100, gwern\nreply@reply.github.com\nwrote:\n\nI dunno. Tough problem; when you call cat, it takes over control. And\nyou can't simply check $# because then you break piping in, when there\nare no arguments. If we were using read, there's a time-out option or\nlength option we could use, but as pointed out before, read on its own\nis horrible and needs to be in a complicated loop according to the\nexamples I saw. We could do something hacky like (sleep 10s && help  \n&& exit) but that doesn't work too well in practice.\nhttp://stackoverflow.com/questions/635361/ksh-how-to-probe-stdin is\nprobably relevant.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/holman/spark/pull/42#issuecomment-2784308\n\n\nO         ,-\n  \u00b0 o    . -\u00b4  '     ,-\n   \u00b0  .\u00b4        . \u00b4,\u00b4\n     ( \u00b0   ))     . (-;    . -\u00b4 ..\n          `.'       \u00b4\nMarkus Fisch\nhttp://markusfisch.de\n. Look at the comments I made in line 39. Floats get their fractional part cut off because there's no portable way of reading them and bash does only work with integers anyway.\nSo my advice would be to simply multiply the input values to become integers.\n. Actually that's a feature since 010 is interpreted as octal number because of the 0 prefix. See man bash for more info about that or just try:\necho $(( 010 ))\nWhich gives 8 decimal.\n. @rsvp \nYou may want to add this to your .bashrc or .bash_aliases or .profile:\nalias fspark=\"awk '{ for(i = 1; i <= NF; ++i) print \\$i*1000 }' | spark\"\nThen, magically, you can use floats with spark:\n$ echo .3 .51. .75 | fspark\nIt's just not that much of a problem.\n. @rsvp \nThere is no overflow problem.\nWhy? Because spark has a resolution of 8. That means, all numbers you fire through spark get scaled within 8.\nTherefore, to show anything of meaning, the input numbers must differ significantly when scaled within 8. You won't get any meaning of the fractional part in input like this: 1.2 90 499. The fractional part is just scaled away.\nSo using very big numbers together with very small numbers doesn't make sense.\nThe purpose of spark is to show relative differences on a scale of 8 and it does that well. There's no need to pull in python (or any other dependency) to do this. It can all be done with bash only and that's all it should need.\nIt's very easy to scale your input values (whatever they may be) to get into a meaningful range. That conversion should not be part of spark because converting data is another matter (and probably part of a specific domain).\nYou might have heard of the Unix philosophy: Write programs that do one thing and do it well. Write programs to work together. ...\nPlease respect that spark tries to follow that philosophy.\nOne last word about dependencies. Please, do always question them and don't just pull them in blindly. You suspect there's virtually no situation where there is bash but no python. From the top of my mind: A windows box with git bash. Android terminal emulators.\nIf you prefer python, that's okay. A fork is nice. But then you should consider using python only and no bash. For the very same reasons. A windows box may have python but no bash.\n. $ echo -0.20 0.08 0.20 -0.20 | fspark\nWorks well. qed.\n. ",
    "robcowie": "Done. Submitted. I'll let you know when it's accepted. Cheers.\n. Done. Submitted. I'll let you know when it's accepted. Cheers.\n. ",
    "kevinsawicki": "Shouldn't it end with at least one ~?\n. Shouldn't it end with at least one ~?\n. ",
    "clindsey": "Reason #6735 why female programmers aren't more common.\n. Reason #6735 why female programmers aren't more common.\n. ",
    "franciscolourenco": "it already does\n. it already does\n. ",
    "lalyos": "yo were right, although brew update failed with Error: Failure while executing: git checkout -q master, so i had to reinstall brew. but then spark got installed.\n. yo were right, although brew update failed with Error: Failure while executing: git checkout -q master, so i had to reinstall brew. but then spark got installed.\n. ",
    "aborrero": ":) thanks you for merging.\n. :) thanks you for merging.\n. ",
    "ncanceill": ":+1: \n. @afeld Not able to reproduce. You should debug your script.\nI was able to show output in watch with following dummy test.\nsh\n(for i in {1..20};do echo $i>>/tmp/ts;sleep 1;done)&watch \"cat /tmp/ts|./spark\"\nHowever, the characters \u2582 \u2587 etc are printed as ? because watch does not handle special characters, so I am afraid it will not be of any use to you anyway. (You can escape characters to be sure: watch \"cat /tmp/ts|./spark|cat -v\")\nprocps version 3.2.8\n. @ncolton You are not reading it correctly.\n@afeld Please close, or provide more info.\nHe says \"I'm running a large CSV export job\": he has a process in the background adding lines to file users.csv (NOT SHOWN HERE). Then he calls watch on the result of wc -l users.csv which counts the lines in the file. He continuously appends the result to another csv file, and uses spark on that one. So, yes, the left part (where he uses wc -l to count the lines of users.csv) needs to complete first, but that is the intended result.\nAnyway, his shell command is not the issue here. I already answered the problem: watch does not support special characters.\n. In this spirit of combining \"spark\" and \"shell\", I humbly suggest shpark.\n. No hard feeling, I was just submitting it because it was asked for in #55. Good job building this anyway!\n. I'm glad you like it. You can use it rightaway with:\nbash\ngit remote add ncanceill git@github.com:ncanceill/spark.git\ngit fetch ncanceill\ngit cherry-pick 2550076\n. #54 would be a solution for this \u2014 setting $SPARK_MIN to zero.\n. Well, duh! #54 has not been pulled yet. If you want it, you can\nbash\ncurl https://github.com/holman/spark/commit/663fb3b334b9da5629aa0c7b3fb5d4316443c1af.patch | git apply -\n(You will have to go the patch way since the PR branch was deleted.)\n. +1\n. Could be your font. Have you try changing it?\n. :+1: \n. @afeld Not able to reproduce. You should debug your script.\nI was able to show output in watch with following dummy test.\nsh\n(for i in {1..20};do echo $i>>/tmp/ts;sleep 1;done)&watch \"cat /tmp/ts|./spark\"\nHowever, the characters \u2582 \u2587 etc are printed as ? because watch does not handle special characters, so I am afraid it will not be of any use to you anyway. (You can escape characters to be sure: watch \"cat /tmp/ts|./spark|cat -v\")\nprocps version 3.2.8\n. @ncolton You are not reading it correctly.\n@afeld Please close, or provide more info.\nHe says \"I'm running a large CSV export job\": he has a process in the background adding lines to file users.csv (NOT SHOWN HERE). Then he calls watch on the result of wc -l users.csv which counts the lines in the file. He continuously appends the result to another csv file, and uses spark on that one. So, yes, the left part (where he uses wc -l to count the lines of users.csv) needs to complete first, but that is the intended result.\nAnyway, his shell command is not the issue here. I already answered the problem: watch does not support special characters.\n. In this spirit of combining \"spark\" and \"shell\", I humbly suggest shpark.\n. No hard feeling, I was just submitting it because it was asked for in #55. Good job building this anyway!\n. I'm glad you like it. You can use it rightaway with:\nbash\ngit remote add ncanceill git@github.com:ncanceill/spark.git\ngit fetch ncanceill\ngit cherry-pick 2550076\n. #54 would be a solution for this \u2014 setting $SPARK_MIN to zero.\n. Well, duh! #54 has not been pulled yet. If you want it, you can\nbash\ncurl https://github.com/holman/spark/commit/663fb3b334b9da5629aa0c7b3fb5d4316443c1af.patch | git apply -\n(You will have to go the patch way since the PR branch was deleted.)\n. +1\n. Could be your font. Have you try changing it?\n. ",
    "sindresorhus": "@holman ping\n. @holman to quote you in #54:\n\nNot a huge fan of using environment variables here\n\nCan you reconsider this instead? Using flags would be a more natural solution here.\nThough --min/--max instead of -m/-M would be better.\n. :+1: This would be very useful to achieve streaming sparkline output.\n. @holman Can you reopen this since #54 was reverted?\n. :+1: Added this to my JavaScript port.\n. @holman ping\n. @holman to quote you in #54:\n\nNot a huge fan of using environment variables here\n\nCan you reconsider this instead? Using flags would be a more natural solution here.\nThough --min/--max instead of -m/-M would be better.\n. :+1: This would be very useful to achieve streaming sparkline output.\n. @holman Can you reopen this since #54 was reverted?\n. :+1: Added this to my JavaScript port.\n. ",
    "jamesfzhang": "No problem, thanks Zach!\n. No problem, thanks Zach!\n. ",
    "ncolton": "If I am reading it correctly, on the left side of the && you are doing the processing and on the right side you are reading the processed output and feeding it to spark. As you are not backgrounding any of these tasks, the processing will need to complete first, then the return value of it can be evaluated, determining whether the logical and needs to evaluate the second argument.\nIf the processing completes and returns without error, only then will (cat sizes.csv | ./spark) be evaluated and run.\nWhat you probably want instead would be\n(wc -l users.csv | awk '{print \\$1}') >> sizes.csv & watch \"(cat sizes.csv | ./spark)\"\nwhich does the processing in the background, with watch \u2026 running in the foreground.\n. If I am reading it correctly, on the left side of the && you are doing the processing and on the right side you are reading the processed output and feeding it to spark. As you are not backgrounding any of these tasks, the processing will need to complete first, then the return value of it can be evaluated, determining whether the logical and needs to evaluate the second argument.\nIf the processing completes and returns without error, only then will (cat sizes.csv | ./spark) be evaluated and run.\nWhat you probably want instead would be\n(wc -l users.csv | awk '{print \\$1}') >> sizes.csv & watch \"(cat sizes.csv | ./spark)\"\nwhich does the processing in the background, with watch \u2026 running in the foreground.\n. ",
    "seekshreyas": "@holman @markusfisch : Thanx. Will do. \n. @holman @markusfisch : Thanx. Will do. \n. ",
    "krishnan-mani": "Please take a look at http://apple.stackexchange.com/questions/57172/homebrew-sha1-mismatch-even-after-update\nIt is possible that the file was not downloaded in full or corrupted when downloaded.\n. 'brew install spark' worked fine for me just today and /usr/local/Library/Formula/spark.rb lists the following:\nurl 'https://github.com/holman/spark/archive/v1.0.1.tar.gz'\n  sha1 '11c6a0c5e52720a1282c5da5019432c33dcf9403'\nuname -a:\nDarwin Krishnans-MacBook-Pro.local 12.4.0 Darwin Kernel Version 12.4.0: Wed May  1 17:57:12 PDT 2013; root:xnu-2050.24.15~1/RELEASE_X86_64 x86_64\nbrew -v:\nHomebrew 0.9.4\n. Please take a look at http://apple.stackexchange.com/questions/57172/homebrew-sha1-mismatch-even-after-update\nIt is possible that the file was not downloaded in full or corrupted when downloaded.\n. 'brew install spark' worked fine for me just today and /usr/local/Library/Formula/spark.rb lists the following:\nurl 'https://github.com/holman/spark/archive/v1.0.1.tar.gz'\n  sha1 '11c6a0c5e52720a1282c5da5019432c33dcf9403'\nuname -a:\nDarwin Krishnans-MacBook-Pro.local 12.4.0 Darwin Kernel Version 12.4.0: Wed May  1 17:57:12 PDT 2013; root:xnu-2050.24.15~1/RELEASE_X86_64 x86_64\nbrew -v:\nHomebrew 0.9.4\n. ",
    "AshyIsMe": "Cheers for looking into it, i ended up just grabbing the latest from github and copying the script to my /usr/local/bin\n. Cheers for looking into it, i ended up just grabbing the latest from github and copying the script to my /usr/local/bin\n. ",
    "rsvp": "Look closer... it's still a bash script. It just uses Python as one would say, awk.\n. Ok, I understand. Thanks for looking at the code. But just try my first example on the current version of spark, and you will see that scientists/engineers will not want integer truncation to wipe out resolution on their sparkline charts. \n. Every tool has its place. For polished charts, I like R -- but for getting a rough idea, sparklines are wonderful. For example, to quickly show the Treasury yield curve:  \u2581\u2584\u2587\u2588 \nThat uses the proposed rewritten version. With rates between 0 and 4, the current spark cannot fully resolve even the simplest of data which is used by banks and households. What's the point of debugging software if problems like that are swept under the rug? Most users might not notice, but they implicitly rely on the developers for accuracy. That's the code, my friends. Else, post the limitations in bold on your forehead :-)\n. @markusfisch sure, let's append that patch to the help() function so all users are reminded to execute fspark instead.  Or one could simply multiply each data point before truncation in the script itself. Then on the other hand, awk will have an overflow problem if the raw data contains large integers. That when I started to write the python portion of spark :-)\n. @holman et al. Re: dependencies, you got me wondering: what percentage of machines which have bash installed do not have Python installed? Most frequently it's a system include, and the user does not have to install Python himself. So what is the case against having a Python dependency (just to do some numerical work) within a bash script?\n. @markusfisch try this very trivial example that most users would expect to work correctly:\nspark -0.20 0.08 0.20 -0.20\nThe pure bash version currently FAILS the second portion of your cited \"Unix philosophy: Write programs that do one thing and do it well.\" It's funny that your kludge fix is so antithetical to that philosophy because it violates the first portion. \n. Look closer... it's still a bash script. It just uses Python as one would say, awk.\n. Ok, I understand. Thanks for looking at the code. But just try my first example on the current version of spark, and you will see that scientists/engineers will not want integer truncation to wipe out resolution on their sparkline charts. \n. Every tool has its place. For polished charts, I like R -- but for getting a rough idea, sparklines are wonderful. For example, to quickly show the Treasury yield curve:  \u2581\u2584\u2587\u2588 \nThat uses the proposed rewritten version. With rates between 0 and 4, the current spark cannot fully resolve even the simplest of data which is used by banks and households. What's the point of debugging software if problems like that are swept under the rug? Most users might not notice, but they implicitly rely on the developers for accuracy. That's the code, my friends. Else, post the limitations in bold on your forehead :-)\n. @markusfisch sure, let's append that patch to the help() function so all users are reminded to execute fspark instead.  Or one could simply multiply each data point before truncation in the script itself. Then on the other hand, awk will have an overflow problem if the raw data contains large integers. That when I started to write the python portion of spark :-)\n. @holman et al. Re: dependencies, you got me wondering: what percentage of machines which have bash installed do not have Python installed? Most frequently it's a system include, and the user does not have to install Python himself. So what is the case against having a Python dependency (just to do some numerical work) within a bash script?\n. @markusfisch try this very trivial example that most users would expect to work correctly:\nspark -0.20 0.08 0.20 -0.20\nThe pure bash version currently FAILS the second portion of your cited \"Unix philosophy: Write programs that do one thing and do it well.\" It's funny that your kludge fix is so antithetical to that philosophy because it violates the first portion. \n. ",
    "creaktive": "Scientists/engineers will use gnuplot ;)\n\n\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0441 \u043c\u043e\u0435\u0433\u043e iPhone\n. Scientists/engineers will use gnuplot ;)\n\n\u041e\u0442\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u043e \u0441 \u043c\u043e\u0435\u0433\u043e iPhone\n. ",
    "jleclanche": "Heh. :)\nI wanted to go with sparklines but get upstream blessing first. Input appreciated.\n. Ok. What about potential binary name conflict? should it also be /usr/bin/spark-shell?\n. Sorry, notification ended up in spam. Fixed.\n. Heh. :)\nI wanted to go with sparklines but get upstream blessing first. Input appreciated.\n. Ok. What about potential binary name conflict? should it also be /usr/bin/spark-shell?\n. Sorry, notification ended up in spam. Fixed.\n. ",
    "JeffAbrahamson": "sparkline or spark-line (singular or plural) seems more descriptive.\nIn case descriptive is among the criteria. ;-)\n. sparkline or spark-line (singular or plural) seems more descriptive.\nIn case descriptive is among the criteria. ;-)\n. ",
    "davidcelis": "I'd also ask for reconsideration here; If the environment variable solution had array issues, perhaps this could be revisited?\n. That's fair; thanks for the honesty. In the meantime, if anybody else needs this for some utility like I did, I brought in @talwrii's changes into my own fork and added a homebrew formula to install it. brew tap davidcelis/spark && brew install davidcelis/spark/spark\n. I'd also ask for reconsideration here; If the environment variable solution had array issues, perhaps this could be revisited?\n. That's fair; thanks for the honesty. In the meantime, if anybody else needs this for some utility like I did, I brought in @talwrii's changes into my own fork and added a homebrew formula to install it. brew tap davidcelis/spark && brew install davidcelis/spark/spark\n. ",
    "ghost": "Nice!\n. OK. Thanks~  :)\n2014-05-28 16:05 GMT+08:00 Nicolas Canceill notifications@github.com:\n\nI'm glad you like it. You can use it rightaway with:\ngit remote add ncanceill git@github.com:ncanceill/spark.git\ngit fetch ncanceill\ngit cherry-pick 2550076\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/holman/spark/pull/73#issuecomment-44376498\n.\n\n\n\u5085\u4f1f\n\u5317\u4eac\u90ae\u7535\u5927\u5b66\u79fb\u52a8\u751f\u6d3b\u4e0e\u65b0\u5a92\u4f53\u5b9e\u9a8c\u5ba4\n\u4e3b\u9875:http://fhfuwei.github.io/index.html\n. Nice!\n. OK. Thanks~  :)\n2014-05-28 16:05 GMT+08:00 Nicolas Canceill notifications@github.com:\n\nI'm glad you like it. You can use it rightaway with:\ngit remote add ncanceill git@github.com:ncanceill/spark.git\ngit fetch ncanceill\ngit cherry-pick 2550076\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/holman/spark/pull/73#issuecomment-44376498\n.\n\n\n\u5085\u4f1f\n\u5317\u4eac\u90ae\u7535\u5927\u5b66\u79fb\u52a8\u751f\u6d3b\u4e0e\u65b0\u5a92\u4f53\u5b9e\u9a8c\u5ba4\n\u4e3b\u9875:http://fhfuwei.github.io/index.html\n. ",
    "juanibiapina": "In the spirit of everything in its place, I don't like having the main\nexecutable and its tests in the same directory. Maybe separating the tests\nin a directory and leaving the spark executable where it is could help\nmake it more clear. That way the project root would not have anything test\nrelated.\nOn Nov 9, 2014 5:06 PM, \"Zach Holman\" notifications@github.com wrote:\n\nHm. Interesting thought, and it appeals to my everything-in-their-place\npart of my brain.\nI'm kind of on the fence; part of what I like about spark is that it's\npretty accessible, particularly for people who might be new to shell\nscripts (or even programming at all!). It's a little thing, but tucking it\naway in bin/ might make it a bit more opaque, or otherwise give the\nimpression that what's going on in here is more complicated than it is.\nMight be overthinking it, though. Would be curious on what other people\nthink make the most sense here. (And if we move to bin/, we'll also need\nto update the README link and then probably add a test/ for the test\nfiles, too.)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/holman/spark/pull/78#issuecomment-62314766.\n. In the spirit of everything in its place, I don't like having the main\nexecutable and its tests in the same directory. Maybe separating the tests\nin a directory and leaving the spark executable where it is could help\nmake it more clear. That way the project root would not have anything test\nrelated.\nOn Nov 9, 2014 5:06 PM, \"Zach Holman\" notifications@github.com wrote:\nHm. Interesting thought, and it appeals to my everything-in-their-place\npart of my brain.\nI'm kind of on the fence; part of what I like about spark is that it's\npretty accessible, particularly for people who might be new to shell\nscripts (or even programming at all!). It's a little thing, but tucking it\naway in bin/ might make it a bit more opaque, or otherwise give the\nimpression that what's going on in here is more complicated than it is.\nMight be overthinking it, though. Would be curious on what other people\nthink make the most sense here. (And if we move to bin/, we'll also need\nto update the README link and then probably add a test/ for the test\nfiles, too.)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/holman/spark/pull/78#issuecomment-62314766.\n. \n",
    "asahaf": "Setting $SPARK_MIN to zero doesn't solve the issue.\n$ ARRAY=(25 45)\n$ echo ${ARRAY[*]} | SPARK_MIN=0 spark \n\u2581\u2588\n. correct! this suggested solution also works \n$ ARRAY=(25 45)\n$ echo ${ARRAY[*]} | SPARK_MIN=0 ./spark\n\u2584\u2588\n. Setting $SPARK_MIN to zero doesn't solve the issue.\n$ ARRAY=(25 45)\n$ echo ${ARRAY[*]} | SPARK_MIN=0 spark \n\u2581\u2588\n. correct! this suggested solution also works \n$ ARRAY=(25 45)\n$ echo ${ARRAY[*]} | SPARK_MIN=0 ./spark\n\u2584\u2588\n. ",
    "dotwaffle": "With the exception of a watch loop, no... However for that particular\nexample you could use prettyping:\nhttps://bitbucket.org/denilsonsa/small_scripts/src/tip/prettyping.sh\n. With the exception of a watch loop, no... However for that particular\nexample you could use prettyping:\nhttps://bitbucket.org/denilsonsa/small_scripts/src/tip/prettyping.sh\n. ",
    "szepeviktor": "Oh! Thank you!\nI've found https://github.com/dkogan/feedgnuplot\n. I suggest you this kind of script header for bash/python and anything that handles hashmark:\n``` bash\n!/bin/bash\n\nRestart PHP-FPM and Apache dependently\n\nVERSION       :0.1\nDATE          :2014-12-12\nAUTHOR        :Viktor Sz\u00e9pe viktor@szepe.net\nLICENSE       :The MIT License (MIT)\nURL           :https://github.com/szepeviktor/debian-server-tools\nBASH-VERSION  :4.2+\nLOCATION      :/usr/local/sbin/webrestart.sh\nDEPENDS       :apt-get install php5-fpm apache2\n```\nIt can easly parsed:\nhttps://github.com/szepeviktor/debian-server-tools/blob/master/install.sh#L20-L37\n. Finally\nbash\nping -n google.com \\\n | sed -u -n 's|^.* bytes from .*: icmp_req=\\([0-9]\\+\\) .* time=\\([0-9.]\\+\\) .*$|\\1 \\2|gp' \\\n | feedgnuplot --terminal 'dumb 120,40' --stream --lines -xlen 30 --set \"xtics 10\" --domain\n. Oh! Thank you!\nI've found https://github.com/dkogan/feedgnuplot\n. I suggest you this kind of script header for bash/python and anything that handles hashmark:\n``` bash\n!/bin/bash\n\nRestart PHP-FPM and Apache dependently\n\nVERSION       :0.1\nDATE          :2014-12-12\nAUTHOR        :Viktor Sz\u00e9pe viktor@szepe.net\nLICENSE       :The MIT License (MIT)\nURL           :https://github.com/szepeviktor/debian-server-tools\nBASH-VERSION  :4.2+\nLOCATION      :/usr/local/sbin/webrestart.sh\nDEPENDS       :apt-get install php5-fpm apache2\n```\nIt can easly parsed:\nhttps://github.com/szepeviktor/debian-server-tools/blob/master/install.sh#L20-L37\n. Finally\nbash\nping -n google.com \\\n | sed -u -n 's|^.* bytes from .*: icmp_req=\\([0-9]\\+\\) .* time=\\([0-9.]\\+\\) .*$|\\1 \\2|gp' \\\n | feedgnuplot --terminal 'dumb 120,40' --stream --lines -xlen 30 --set \"xtics 10\" --domain\n. ",
    "jacobtomlinson": ":+1:\n. :+1:\n. ",
    "niedzielski": "The underscore does not seem to align well with the baseline of the block characters.\n. It looks perfect in your screenshot. It does not align well with Menlo Regular, Courier New, Monaco, Bitstream Vera Sans Mono, or Source Code Pro. It does look good in Source Sans Pro. Here's a screen shot of Menlo Regular:\n\n. Maybe a more consistent alternative would be to use a space character instead of an underscore?\n. Since there is opportunity for inconsistency, it'd be neat to have a command line flag to enable underscores and spaces, or even something more general, a flag to pass in all tick characters:\nspark -t' _\u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588'\n(With the default being today's ticks.) Users wanting the full experience can create an alias.\n. In case anyone would like to see what the changes might look like on top of @KateAdams' PR, I've made them here.\n. The underscore does not seem to align well with the baseline of the block characters.\n. It looks perfect in your screenshot. It does not align well with Menlo Regular, Courier New, Monaco, Bitstream Vera Sans Mono, or Source Code Pro. It does look good in Source Sans Pro. Here's a screen shot of Menlo Regular:\n\n. Maybe a more consistent alternative would be to use a space character instead of an underscore?\n. Since there is opportunity for inconsistency, it'd be neat to have a command line flag to enable underscores and spaces, or even something more general, a flag to pass in all tick characters:\nspark -t' _\u2581\u2582\u2583\u2584\u2585\u2586\u2587\u2588'\n(With the default being today's ticks.) Users wanting the full experience can create an alias.\n. In case anyone would like to see what the changes might look like on top of @KateAdams' PR, I've made them here.\n. ",
    "AshleighAdams": "Hmm, what font are you using?\nThis is how it looks to me (default Monospace in Debian on Gnome Terminal): \n\n. \nAbove is how that looks for me.  Maybe it's best to leave it as is (no underscore/space), as those block chars are p.much guaranteed to work on any fonts.\n. @niedzielski I would say an environment variable (SPARK_TICKS) would be more suitable if that were done.\n. @niedzielski Yeah, that is much better in my opinion.\n. Hmm, what font are you using?\nThis is how it looks to me (default Monospace in Debian on Gnome Terminal): \n\n. \nAbove is how that looks for me.  Maybe it's best to leave it as is (no underscore/space), as those block chars are p.much guaranteed to work on any fonts.\n. @niedzielski I would say an environment variable (SPARK_TICKS) would be more suitable if that were done.\n. @niedzielski Yeah, that is much better in my opinion.\n. ",
    "apretto": "I had the same problem on OS X Yosemite.\nThe terminal was using the Monaco font. Changing to use Menlo made fixed the issue of some of the bars not aligning.\n. \n. I'm fine with closing this PR and going with @abrist's implementation (#94).. I had the same problem on OS X Yosemite.\nThe terminal was using the Monaco font. Changing to use Menlo made fixed the issue of some of the bars not aligning.\n. \n. I'm fine with closing this PR and going with @abrist's implementation (#94).. ",
    "pboling": "I am seeing bars fall below the apparent bottom of the graph, as if somehow they have a negative origin.  I am on Yosemite, using iTerm 2, 12pt Monaco, and bash.  Going to try a new font.  Menlo did not help. :(\nThe following examples both exhibit the issue for me:\nspark 900 1400 1200 2500 12 1300 324 5466\ngit shortlog -s |     cut -f1 |     spark\n. I am seeing bars fall below the apparent bottom of the graph, as if somehow they have a negative origin.  I am on Yosemite, using iTerm 2, 12pt Monaco, and bash.  Going to try a new font.  Menlo did not help. :(\nThe following examples both exhibit the issue for me:\nspark 900 1400 1200 2500 12 1300 324 5466\ngit shortlog -s |     cut -f1 |     spark\n. ",
    "rogeruiz": "I'm seeing the same thing here. Here's an example of the output and a screenshot. \n\n\u276f\u276f\u276f\u276f\u276f\u276f\u276f clocker data | grep -oEi '\\d+\\.\\d+' | SPARK_MIN=0 spark\n\u2581\u2583\u2583\u2581\u2583\u2583\u2583\u2585\u2585\u2585\u2581\u2585\u2585\u2582\u2583\u2584\u2582\u2582\u2585\u2586\u2583\u2585\u2586\u2587\u2586\u2586\u2586\u2588\u2587\u2583\u2581\u2582\u2581\u2583\u2586\u2585\nChanging it to Menlo didn't do anything for me either. :sob: \n\n. Hmmm. It might be worth opening an issue in iTerm's repo on this and tie them together. Seems like it's not necessarily a bug in spark so much.\n. @casidiablo It's M+ 2m regular. It's open source and you can download it here.\n. iTerm uses Gitlab for their issues so I can't cross-post it using Github's fancy #XXX shortcuts. Here's a link to the issue on Gitlab. :+1: \n. I'm seeing the same thing here. Here's an example of the output and a screenshot. \n\n\u276f\u276f\u276f\u276f\u276f\u276f\u276f clocker data | grep -oEi '\\d+\\.\\d+' | SPARK_MIN=0 spark\n\u2581\u2583\u2583\u2581\u2583\u2583\u2583\u2585\u2585\u2585\u2581\u2585\u2585\u2582\u2583\u2584\u2582\u2582\u2585\u2586\u2583\u2585\u2586\u2587\u2586\u2586\u2586\u2588\u2587\u2583\u2581\u2582\u2581\u2583\u2586\u2585\nChanging it to Menlo didn't do anything for me either. :sob: \n\n. Hmmm. It might be worth opening an issue in iTerm's repo on this and tie them together. Seems like it's not necessarily a bug in spark so much.\n. @casidiablo It's M+ 2m regular. It's open source and you can download it here.\n. iTerm uses Gitlab for their issues so I can't cross-post it using Github's fancy #XXX shortcuts. Here's a link to the issue on Gitlab. :+1: \n. ",
    "cp": "I am seeing this too, in iTerm 2 both inside and out of Tmux. :cry: \n. I am seeing this too, in iTerm 2 both inside and out of Tmux. :cry: \n. ",
    "dasilvacontin": "Same here.\n. Same here.\n. ",
    "casidiablo": "Same here. Works fine on Terminal.\n.  @rogeruiz Yeah, makes sense. By the way, what's the name of the font you were using in your screenshot?\n. Same here. Works fine on Terminal.\n.  @rogeruiz Yeah, makes sense. By the way, what's the name of the font you were using in your screenshot?\n. ",
    "shivanju": "\nsorry if I am missing some configuration. I am new to linux.\n. \nsorry if I am missing some configuration. I am new to linux.\n. ",
    "CristianCantoro": "I can not reproduce this on my sistem with:\n- Ubuntu 16.04 LTS\n- spark v. 1.0.0\n- tmux v. 2.1\n. I can not reproduce this on my sistem with:\n- Ubuntu 16.04 LTS\n- spark v. 1.0.0\n- tmux v. 2.1\n. ",
    "MaxWorgan": ":+1: came here to see if anyone had added this\n. :+1: came here to see if anyone had added this\n. ",
    "abrist": "@apretto I was inspired by your commit and subsequently fattened up the color features in my PR:  https://github.com/holman/spark/pull/94\n. @neuhaus See my PR and branch for the requested feature:  https://github.com/holman/spark/pull/94\necho 1 2 3 4 5 6 7 8 7 6 5 4 3 2 1 | ./spark -p 52,88,160,166,172,178,148,82\n\n. @apretto Thank you so much for your time, work, and inspiration!. \n\n. Also, it looks like the travis tests are failing, but ./test works on my side:\n\n. @apretto I was inspired by your commit and subsequently fattened up the color features in my PR:  https://github.com/holman/spark/pull/94\n. @neuhaus See my PR and branch for the requested feature:  https://github.com/holman/spark/pull/94\necho 1 2 3 4 5 6 7 8 7 6 5 4 3 2 1 | ./spark -p 52,88,160,166,172,178,148,82\n\n. @apretto Thank you so much for your time, work, and inspiration!. \n\n. Also, it looks like the travis tests are failing, but ./test works on my side:\n\n. ",
    "neuhaus": "can we make the color range configurable (perhaps as start and end values in HSV)? I'd like it to go from green to red for example.. can we make the color range configurable (perhaps as start and end values in HSV)? I'd like it to go from green to red for example.. ",
    "fletch": "Aah my bad; I think we're looking at different things since I wasn't clear which sample I was talking about.\nThe sample incantation in the README fetching at 2.5_day.csv works (which I missed before, but just checked myself as well and it's working for me as well), it's the URL in the sample shown on the page http://zachholman.com/spark/ referencing an eqs1day-M1.txt which is what gives the HTML \"that's moved\" output.\n\nProbably you could just replace that example there with the working one from the README.\n. Aah my bad; I think we're looking at different things since I wasn't clear which sample I was talking about.\nThe sample incantation in the README fetching at 2.5_day.csv works (which I missed before, but just checked myself as well and it's working for me as well), it's the URL in the sample shown on the page http://zachholman.com/spark/ referencing an eqs1day-M1.txt which is what gives the HTML \"that's moved\" output.\n\nProbably you could just replace that example there with the working one from the README.\n. ",
    "Nebuchadrezzar": "This is a fantastic enhancement.  When its going to be accepted? . This is a fantastic enhancement.  When its going to be accepted? . "
}