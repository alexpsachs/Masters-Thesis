{
    "boucman": "did someone close your patches on trac ? \ndo you want me to do it ?\nif yes could you post me the trac number or URL ?\n. I'm simply trying to clean up our patches on redmine... so since we will follow through github I want to close your patches on redmine\nbut I didn't find them, do you remember how they were called ?\n. What exactly are those files ? in what way are they not normal README ?\n. thx, I had planned to go and check all the lingering branches at some point, but this will gain me quite some time\nI'll have a look at it tonight...\n. BTW, you are asking to merge into master... I guess you want us to merge into detachable instead... that would make more sense.\nUnless you believe that detachable is ready for merging into master but I don't think this is the case, is it ?\n. that's ok, i'll merge it to the detachable branch, and close this pull\nrequest...\nOn Mon, Jun 4, 2012 at 9:10 PM, Loic GUIBERT\nreply@reply.github.com\nwrote:\n\nSorry,\nI'm not very friendly with pull request.\nI just want you to merge my detachable branch on the official detachable branch.\nI've updated my branch merging the master into it to get it up-to-date.\nI don't think the branch is ready to merge into master. Still to do : restore panels position on dt start and check the code. I'm not a confirmed C developper.\nI've not seen where change the pull request.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/10#issuecomment-6107572\n. this looks good, i'll test it tonight... could you look if it's easy to add it to all source code ? (ours, not the things we pull like libraw etc...) \n\nI think there is a script somewhere in the tools directory to reindent/reformat the style, you might want to check what it does and if more can be put in the vim line. \nIf you had a script to add the vim+kate line everywhere that would be wonderfull\n. We really need to have IRC logs somewhere...\nOn Wed, Jun 6, 2012 at 9:55 AM, Jose Carlos Garcia Sogo\nreply@reply.github.com\nwrote:\n\nThe pull request has arrived. I know yesterday there were some\ndiscussion on it on the IRC channel, but I was not able to\nparticipate.\nOn Tue, Jun 5, 2012 at 8:01 AM, Richard Wonka\nreply@reply.github.com\nwrote:\n\nThis is my first pull request to see if I have understood how this is done.\nadded vim modeline to set some basic defaults for vim users\nYou can merge this Pull Request by running:\ngit pull https://github.com/richardwonka/darktable wonky\nOr you can view, comment on it, or merge it online at:\nhttps://github.com/darktable-org/darktable/pull/11\n-- Commit Summary --\n- * added vim: modeline to darktable.c\n- * changed vim modeline to be more explicit\n-- File Changes --\nM src/common/darktable.c (5)\n-- Patch Links --\nhttps://github.com/darktable-org/darktable/pull/11.patch\n\u00a0https://github.com/darktable-org/darktable/pull/11.diff\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/11\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n\u00a0 \u00a0jcsogo@gmail.com\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/11#issuecomment-6145007\n. Ok, the modelines themselves are OK, but the pull request as is has little purpose...\n\nI'll close it, feel free to rerequest a pull request when all files have the commit line...\nCheers\n. it's a bit early for a pull-request on that, you still have debug printf in your code and there are important TODO that needs to be filled\non another note, we have been discussing this issue on IRC a bit and we don't have a consensus on adding that checkbox...\nWe do agree on the problem of overwriting, but we are looking for a better UI solution than the checkbox. We will post on the ML thread once we are a bit more consistent on our opinion\nIn the mean time I will close this merge request, feel free to rerequest once it is more mature\n. > Sorry Boucman,\n\nI'm newbie on github and I didn't understand pull-request use; I didn't\nwant to use it as request to merge but only as commit notification to\nmain team. My mistake!\n\nno problem, we are all learning...\nwe can see what other people are doing on wesnoth using\nhttps://github.com/darktable-org/darktable/network\n\n\non another note, we have been discussing this issue on IRC a bit and we don't have a consensus on adding that checkbox...\n\nOk, no problem, but I had no feedback about this and I started to add it\nbecause in my workflow will be useful and because to learn something\nabout DT code and gtk :)\n\nyes, these are good reasons and we havn't been good at voicing our\nopinion on that particular debate...\n\n\nWe do agree on the problem of overwriting, but we are looking for a better UI solution than the checkbox. We will post on the ML thread once we are a bit more consistent on our opinion\n\nOk, no problem. I agree there could be a better solution.\n\nIn the mean time I will close this merge request, feel free to rerequest once it is more mature\n\nOf course!\nbut you think could have sense to complete my branch or is better stop\nworking waiting a better solution you ask above?\n\nthere are all sorts of small feature requests in redmine that could be\ngood learning tasks... marie-no\u00eblle's recent UI request comes to mind\nbut is certainly not the only one... feel free to work on any of\nthese, it might be more usefull than that particular feature.\n\nIf dev-team will never accept this patch because there is not consensus,\nmay be I will spend my time over other issue or features.\nThank you and sorry for entropy :)\n\nno prob, the only way to avoid entropy is to not do anything... which\nis worse...\n\nIvan\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/12#issuecomment-6147256\n. I like that, I guess it's ok with the general bauhaus philosophy... @hanatos is it ok with you ? if yes you can auto-merge, I have tested on my side...\n. oh, and the case independent commit has already been cherrypicked as df0550954d4d82852ed457f3496fe49e87932660 \n. ok, i'll close this pull requests, just reopen a new one once you do it through memcy...\n\nCheers\nBoucman\n. and done...\n. could you please update your branch by merging master ? thx\n. Ok, thx for pointing out the line.\nAfter discussing with other devs we decided that this was not worth an option. Thus the auto-expanding feature has been removed entirely. \nSince it was a one line fix, I did it directly and didn't pull from your branch, thx for looking for the faulty line...\n. hmm, there are things in there I don't want to merge directly (e7ca45a in particular) i'll have to look at the rest... i'll probably postpone this merge until we decide what to do with issue #8644\n. out of curiosity, what git commands did you do to remove the commit and regroup ? did you destroy your branch and recreate it ?\nI might need to do something similar in other cases...\n. related issue : http://www.darktable.org/redmine/issues/8786\n. Ok, I've readded the old keys for backward compatibility since upgrading existing values was a bit tricky\nnote that you had missed quite a few instances of the old names (see my followup commit before the merge) please be a bit more carefull, a simple grep would have easily found it\n. so far our discussions tend to go toward a policy of \"no rebase on a branch that has been published\" the problem is that it changes history, but once published you can't guarentee that it is not left in someone else's history (our \"latex\" has the problem, it was rebased but there is a github fork that still has it lying around...)\nso, no. avoid rebase on public branches\nyou might want to point to \nhttp://www.darktable.org/redmine/projects/darktable/wiki/Hacking_on_darktable\nrather than the page you pointed to...\neven better would be to merge these two pages into one as detailed as yours, but following the policies we described above...\ncould you do that ?\nthx \nBoucman\n. my bad, I meant make it point/merge with http://www.darktable.org/redmine/projects/darktable/wiki/Contributing_Code\n. and I don't think that \"credit\" for merge commit makes sense... if you want to do who did what you look at the author (not commiter) field of any given commit, you only look at merge commit when they introduce bugs...\n. Ok, I changed the contributing link to the page we want, everything else is unchanged, thx for that\n. Ok, i'll close this pull request for the moment, please make a new one when you consider this ready (if you decide not to change anything, just redo the same pull request, i'm closing it only for bookkeeping purpose...)\n. could you at least encapsulate the callse in a dt_devs_modulegroups_refresh() function ? i'm not sure if it's worth adding a proxy to modulegroup, but that would at least make the call sites more readable if we decide to go that way later...\n. the PR can't be automerged anymore, could you rebase or merge master please ?\n. from itarozzi's mail :\nI have a fix for #8937:\nhttp://www.darktable.org/redmine/issues/8937\nBut, as mentioned in redmine, before to pull request, I would know if\nrename functions names or string labels, according the Simon response to\nchange \"edit\" to \"rename\".\nIvan\n. has this been merged ? can I close the PR ?\n. well... that whole debian subdir is actually unused and unmaintained, so your patch reminded me that we needed to remove it.\nthx for reminding me though,...\n. thx, done\n. this PR is probably post 1.1 material anyway, so I don't think we will merge until the next stable is released...\nso don't worry if we don't merge right away...\n. woops, wrong button\n. since there are no response and we are not sure we want to merge, i'll close this PR\n. some UI comments \noverall this is a great feature, I really like it\n- right clicking while editing the keystone has weird effect, you probably want to disable this completely\n- reseting the plugin didn't reset the keystone menu (the effect seems to be reseted but not the menu itself)\n- it would be nice if the autocropping option could be enabled with keystoning, i'm not sure how possible that is\n- I don't like how the whole horizontal/vertical/full/correction-applied menu works... I am not sure how to make it cleaner\n- I don't like how you have to click OK to validate keystoning... it's conflicting with the way crop is automatically applied, again I don't have a simle suggestion\nbasically the C&R needs a redesign (the UI, not the feature set) I am not sure what to do there, maybe make it modal (crop mode, rotate mode, keystone mode) with a toolbar in the iop gui to select the current mode (which would also change what is displayed below : angle, crop params etc..\nbut that's a way bigger job than what your patch is doing, so if you could clean up what is easy in my suggestion that would already be nice...\n. well, you could separate keystoning into its own plugin at this oint... but that's a different FR altogether, so unles someone has a great idea let's drop it for the moment\nanother thing that might be nice to add : when setting keystone, you usually try to align the lines with features on the image... it would be cool if it was possible to drag the keystone lines without changing their angle... maybe by draging the \"lock\" icon ? not sure...\n. should this be cherrypicked to 1.1 or only for master ?\n. jcsogo: any reason you didn't merge that yourself ? (asking mainly so I know if I need someone to review this for you)\n. @McBofh could you test the latest version on macos and give us a go/nogo ?\nif this doesn't work how reliable is bash ? if everybody has bash, we'll move back to env=>bash\nlet's get this one going...\n. well... i'll merge and if there are any problem in any os we will revert. but i'd be suprised since the current way of doing is less portable\n. hmm, i'm not sure this is reliable... could you at least check that the camera is a NIKON (probably available in another exif field) and make the script fail if no ISO is found\nthis way if other camera makers set this field to empty we can diagnose it easily and improve the script....\n. looks good, i'll give it a try tonight on my D90 (just so we test with multiple cameras) then merge\n. ok, this works, merging..\n. first commit seems good, I would rename default_radius to last_radius, but that's a detail\nI'm not sure about the second one... why do we have a min radius in the first place ? my guess is that if the radius is too small it becomes impossible to handle properly in the UI\nif that's the case, lowering the radius would introduce a bug for lower res cameras.... the min radius probably needs to be calculated in pixel, but im' not sure how to do that...\n. so, are you working on this some more or should we review/merge ? I'm not very clear with your last comment\n. and done\n. oops, I just realized....\nyou are supposed to add an entry to data/darktableconfig.xml\ncould you add it in another PR please ?\n. hmm, no... the name field is the one you will find for the new option in your darktablerc, it's a pseudo path that uniquely identify your new option\nsorry I didn't write an explanation in time for you to check it\n. that would be me, sorry about that\ni'll be away for the next four day, so I won't be able to handle it....\nif someone can handle it that would be nice, if not i'll do that when I get back\n. this PR has been sort of forgotten... is it still needed ? if yes, could you please rebase your usermanual branch on master ?\nmoreover you have two commits that seems unrelated. This is probably an error, so you should probably separate that into two pull requests\nif it's not an error, how are these changes related ?\n. This is a generic comment, not related directly to your patch...\nI don't like how GUI stuff is mixed with non-gui stuff in the common/style.* files\n- it relies heavily on selection, which doesn't exist in non-gui mode\n- it calls control_log in case of error instead of returning it and letting the GUI layer display it\nin the case of your code, you also display a window directly from the style.c code...\ni'd like it if you moved the selection+gui look out of the style.c part... it's a small step in the right direction\n. Ideally i'd like common/styles.h to only be about manipulating the styles themselves, it should work without depending on the GUI, it shouldn't use control to display errors, it shouldn't call libs/styles in any way and it shouldn't have any selection dependant code...\nand it shouldn't find styles based on style name, that prevents safe renaming....\nhowever this is a long term goal and not the subject of this patch, so just discard my previous remark, this will be part of another cleanup....\n. fwi if you rebase then push a branch, the github PR system will handle it correctly so it's ok to do so...\n. hmm, I didn't react on the ML discussion but the \"common names\" for these type of action are\n- copy\n- paste\n- paste special (\"collage sp\u00e9cial\" in french\n  and we probably need to add copy special for the last one\nI think we should try to keep the usual names here...\n(i'm afk next week, so feel free to discuss/get it merged by other devs)\n. This pull request seems to pull with itself most of master, that's probably not what you wanted to do\nwhat you probably want to do is to create a translation branch on origin/1.1 branch, then cherry-pick the commits you are interested in from trunk, and then do a PR for that\n. ok, my bad.... my last expanation was totally of the mark\nwhat you did wrong is that you asked to pull into master instead of pulling int darktable-1.1.x\nyour branch was probably ok\nplease redo the PR asking to merge to darktable-1.1.x and in should be fine\n(and you could look up git-cherry-pick and git cherry these commands could be very usefull for maintaining translations if you don't know them)\n. sorry for the long answer...\nI don't really like the way you deal with missing sequence number... the best would be to simply refuse name without sequence number when setting the pattern name and only reset it if we find there is none when loading the module/cpature view wherever it makes sense\nthe idea of simply changing the filenamepattern without any error message of any form to the user and without stoping the user action seems very bad to me from a usability point of view\n. ok, repeating a couple of comments on the code from irc\noverall it works but there are a few things you could work on to make it even better\n- the void returning function we discussed on IRC\n- if you look at the export module in lighttable mode, it has a widget that uses the same $(XX) things that your new widget, but it has a nice tooltip and nice auto-completion, you could probably reuse/generalise that code in your widget\nwith those in, it should be ready to commit\n. I just noticed your latest commits, this looks good i'll look at that tonight\n. We had a look with the other main devs and we are not very found of supersized either...\nit's a bit of a shame because of the work you put in that one and your previous attempt.\nThere was a bit of discussion and the overall conclusion was that the DT web exporter should stay a minimal thing that is only here as a quick way of doing web galeries rather than a complete solution...\nhowever there are two things you can do to help with the web-gallery thing if it's important to you....\n- we are ready to include improvements to our current web gallery, in particular a patch to downscale images that are too large would be awesome\n- we are not completely closed to idea of replacing our current exporter with some external one, but you should probably do a mail to the mailing list with links to a technology you would like to implement, this way we can all discuss it together before you put too much time into it\nsorry for the time you spend doing this, there is work to do in that area so hopefully we can do something...\n. the problem is a quite common misunderstanding wrt pull- request\na pull request is on a branch, which means that if you move the branch, you move the pull request...\nhere cornergraf asked us to merge his pranch \"master\" but then he continued working on it and (apparently) rebased it, causing the large number of commits most of which are unrelated\nI am a bit confused about the current situation at this point, it might be a good idea to close this PR and open a new one on a dedicated branch if things are too confusing (not sure if that's the case)\n. the master branch has been fixed since... I still don't like merging a branch called master, but corner seems to know what he's doing, so let's continue the review process as usual\n. would it be possible to have that modeline on a single line ? \nwe don't really care about modeline readability here, and most editors check for modeline in the first N modeline where N is rather short... so we should try not to spread to much...\n. Pascal, I am assigning the PR to you since you worked in that area and said you would look at it with your changes...\nif you don't want to look into it, please deassign yourself and i'll deal with it\nthx\n. oh, I must have missed that...\n. still working on this ? should I wait for an update or is it good as is ?\n. ok, I wasn't able to test the code itself because the aspect in c&r seems to be very broken in multiple ways\n\"image\" ratio is not selected (3:2) on new images, though it seems tocome back randomly\nthe aspect ratio seems to be carried over from image to image when switching...\ni'm sorry for your PR but i'd rather merge it on a solid basis and this is currently not the case. don't worry we didn't forget you, though\n. Ok, the C&R module was really buggy, and @AlicVB reimplemented a big part of it in his branch. Fixing the bugs meant implementing what this patch was doing but in a different way. So your feature request was fulfilled, but not using your patch\nthx for the code anyway\n. Sorry for the long delay in answering, I have been slow on reviewing patches recently...\nAfter discussing this for a bit we don't really like the expanded view that much. our current histogram already allows to see the different channels and the gain of seeing them in three separate historgram isn't worth the added UI complexity. the idea was interesting, but that not the direction we want to go at this point\nthanks for the patch, though\n. hmm, the question is : \nis changing the display of colorlabels/rating a preference (i.e each user has his taste, but we don't expect to change this regularly) or an ui \"mode\" i.e you use both depending on your needs of that particular moment)\nI personally think it's a preference and should be moved to pref, but that matches my use-case\ncornergraf, pascal, do you really expect to switch that mode regularly, i.e during your actual work, or can this be moved to preference ?\n. how is this going ? is there still work on this ? is it ready to merge ?\n. ok, no problem, take your time\nI was more asking to make sure we don't have dead PR lying around... \n. side note : feature freeze do not apply this patch before next release\n. ok, 1.2 is officially released, you might want to rebase this PR on master. \nis there still work going on ?\n. ok, unfortunately cornergraf seems to be MIA, so i'll close this PR, feel free to reopen it if you want to work on this some more...\n. I am not sure I understand the point of these scripts, do they need to be run once ? why is there two scripts\nif it's run once, why do you save a new lr.db\ncan't the call to sqlite be put in one of the scripts\nappart from that (which is probably some background I am missing on how LR works) I don't have problems with the scripts themselves\n. ok, can we close this PR then ?\n. it would make sense if the image was removed from the filmroll when moved to the map...\nbut since the image is already in the fimroll, I think that either a dedicated target or no target at all is what makes most sense...\n. is this still a work in progress or should this be closed ? \nsince the undo feature is being worked on separately, maybe we could get this to work without any undo capability and get the undo in separately ?\n. @pmjdebruijn probably a candidate for backport...\n. side note : feature freeze do not apply this patch (this doesn't change its chances to be applied after next release)\n. technically if you copy an existing sentence you are not breaking the string freeze, but I think this is post 1.2 material anyway...\n. just for bookkeeping...\nthis is post 1.2 stuff, isn't it ?\n. assigned to alicVB since he is the most likely to handle it\n. assigning to @AlicVB since he is the most likely to see what's happening here\n. pushed a small update fixing a compilation error in an intermediate commit\n. there are multiple stuff i'm not happy with at this point closing the PR for the moment\n. how about keeping a separate branch for spelling and typo, and merge that branch just before string freeze ? \n. thx a lot, my bad for introducing this... \n. As a side note : your pull request only updated \"master\" I am not sure of the status of polish translation in 1.1.x and 1.2.x but if you want these updated too, you need to do separate pull requests\n. ok, good...\njust mentionning because some translations missed the stable release because they thought updating master was enough...\n. I'm a bit suprised that there isn't such a feature in glib, but if there isn't, the patch looks good...\n. that sounds like an improvement to me, but i'd wait for @hanatos  's opinion on that one...\n. note to self: (or any reviewer) this seems good to test and merge and has been agreed on principle in IRC\n. it doesn't seem to be rebased here, maybe you forgot to push... I'm soryy I forgot that push request, working on it now...\n. hmm, github seems not to see that I reabased and commited\nclosing manually, but this was applied as 118df94c6fe7e365cb1ee2c088b885a004207fef\n. both commits only affect one file... I'm not sure what you mean. Should I merge the PR or close it and let you open another one ?\n. pinging this pull request... @bencahill do you still intend to have a followup commit ?\n. @hanatos : we probably need your go/no-go on that one....\n. please do only one logical change per pull-request, anything else makes much more job for us\nmoreover, we are working on that import problem separately and I think that option had disapeared\n. ok, after discussing a little bit on IRC...\n- we tend to prefer en_GB but the standard for code in the open source community is en_US so we are OK to have an en_GB translation. However if our source code is a mixture of en_US and en_GB it would be nice to have that fixed. Please do two pull requests, one fixin the code to be proper en_US and one adding en_GB after that.\n- there are too many problems with that particular pull request (binary files added and removed, multiple issues in the same pull request etc...) so I am closing it. You are free to recreate it (see above)\n. @wgoetz : would it be possible for you to rebase your branch to untable a little bit the commits ? i'm a bit confused on what's happening on this pull request...\ni'm not really clear on what it does either, but i'll investigate that separately...\n(as a rule of thumb, it's more handy to rebase in your personal repo rather than mergin master, it makes things cleaner for us to merge...)\n. did you write about it/ask gtk people on IRC ? that might be a hole worth noting in their API (so they fix it in the next release)\n. @jcsogo you can create PR but you can't do the rebase yourself, can you ?\nanyway, thx to both of you for the cleanup...\n. Ok, 1.4 has been released and it's time to wake up this PR, the general agreement seems to be that we want to avoid triggers in general, but if they are simple and well contained (as is the case here) it might be ok.\n@TurboGit : can you rebase and merge ? \n. Tested here... this fixes the problem.\nI didn't proofread the code to check what it actually does... just tested\n. are you still working for this ? are you looking for feedback or getting it merged ?\n. Ok, i'll close the PR for the time being, feel free to reopen when you consider it usefull\n. so, any chance to resurect this PR ? @jakeprobst : still interested ?\n. well, the feature is interesting but it doesn't apply cleanly anymore and I had a couple of remarks in the code...\nif you update the pull request and reply/fix my comments, we could get this merged...\n. Thx for the cleanup, this makes the request much more readable... \nAnd thx for still being around after such a long time with no news from our side.\nI still have a few remarks about how things are done. I think you tried to work around the code structure instead of changing it where it's needed. \nIt's better to change the structure if possible, so here is my suggestion\ncurrently you the session time and set it to the exif date.. that sounds hackish. I think it would be better to change the  request_image_path mechanic to depend on the actual image instead of hacking around. It make sense that the image path depends on the image and it would avoid adding a callback with a complicated meaning.\nis that fine with you ?\n. my comment wasn't very clear...\nadd a folder and filename to _dispatch_request_image_path and further down the call chain, and use that info to generate the path (using a method similar to what you do in _get_exif_time_from_import)\nthat would be less intrusive and much more logical\n. that looks good.\nI don't have my camera around so this will be tricky for me to test. I'm trying to find someone to test the patch for me and hopefully get this merge.\nI'll keep you posted, sorry for the delay\n. @rwh86 : what was the default path you used ? I think the current system is designed to import to a single filmroll (i.e directory) and if you add a date in the path part, it might try to import to different directories. This is still a bug, but that would be a big clue\n. so, IIUC it works correctly for RAW but doesn't work for JPG... @jakeprobst can you check that and tell us if you find anything ?\nthx\n. @jakeprobst any news ?\n. ...but you're still around and interested, good, that's all I wanted to know :)\n. @rkahl any news ?\n. @rkahl for your information (since github is not very explicit on that) @houz has rebased and merged your PR, it's just not indicated as such by the github UI\n. I need to check the lua handling if there is a non-existant entry, but this might cause breakage of the lua API\nand since the manual is frozen I can't document the change anymore, so postpone to after 1.4 ?\n. @LebedevRI can you rebase and resubmit ? we should be able to merge this...\n. Accordint to @houz the way you use list_append is incorrect, please fix it while you're at it... \nthx\n. You did not update the build.sh script, please do...\nlooking a bit deeper into the patch, it doesn't do exactly what I think it did... so i'm not sure i'm completely happy with it\n- png and tiff used to be mandatory and are now optional. I'm not sure we want that. That was houz's original point and I misunderstood it (my apologies, I thought it only added the cli option to force disabling, not that it made optional a mandatory feature)\n- for openexr and webp, it is now mandatory unles forcibly disabled. i.e: DT will not build unless either webp is installe or cmake is invoked with USE_WEBP=0. there is no autodetection anymore. \nideally:\n- if USE_WEBP=1 die if webp is not available\n- if USE_WEBP=0 compile without webp\n- if it is not set, use autodetection\nThis sort of three way logic is already implemented for other options, so you can just copy how they do it.\n@pmjdebruijn @parafin i'd like your input about making tiff and png optional... It seems to me that it makes sense to keep these two mandatory, but i'm not a package maintainer. I understand the \"being able to do a lean and mean\" idea, and it certainly apply to complicated deps like maps, but png and till seems like core formats to me...\n. afaict the test for the PNG lib is only done if you don't manualy disable png... so if you force disable, it will not test and work (not tested, but taht's how I read it)\nif you don't disable then yes, it's mandatory\n. usefull parts of this PR have been manually picked, so i'm closing it now, thx.\n. Ok, this is postponed because of feature-freeze, that's for sure\nafter that, the idea is OK... (but see comment in code)\n. there is no lua support in here... I can either add it for you after merge or I can show you how to do it. What do you prefer ?\n. DE ? \nok, i'll review the PR itself then add the lua part\n. Don't you need to add a backward compatibility function to update param format ? i'm not sure how it works exactly, but i'm pretty sure you need it in some form..\n. to be a bit more precise, you need to implement the optional legacy_params function for your iop\n. after IRC discussion, there is no easy upgrade path for storage and formats @houz said he will look into it. \nso this PR is on hold for the moment\n. what does this PR needs ? discussion ? you might want to send a mail to the ML in that case... is it still up for merge ?\n. IIUC you copy the mask from an image to another image, this is not good because it dont' work if the image is removed.\nI am not sure if it's fine to save the mask in preset. I don't really see why not, but otoh I don't really see the point of saving masks and spots in the preset. timelapse and focus stacking ?\nI'll try to get people from IRC to comment here\n. @TurboGit that feature can definitely be usefull and it's time to resurect it... if you are still interested.\nhow possible would it be to have checkbox instead of a pulldown menu ? this way you could have three checkboxes \"ldr\" \"hdr\" \"raw\" and users could easily choose any combo....\n. Please also have a look at the special case of sRAW:\n(09:55:24) pmjdebruijn: https://github.com/darktable-org/darktable/blob/master/src/common/imageio_rawspeed.cc#L148\n(09:55:51) pmjdebruijn: https://github.com/darktable-org/darktable/blob/master/src/common/imageio_rawspeed.cc#L190\n(09:56:06) pmjdebruijn: particularly L190\n(09:56:23) pmjdebruijn: that would suggest sRAW aren't marked RAW currently\n(09:56:47) pmjdebruijn: which is sortof correct from a technical point\n(09:56:52) pmjdebruijn: but less from the user logic point\n. after discussion it seems that a line of checkboxes with simple statements (\"apply to RAW\" \"apply to HDR\" \"apply to normal images\") is the least worse of solutions, so if that's fine with you please do it that way. \n. does renaming a field in the DB present any compatibility risk ? I don't really know how these things work\n. ok, it would make sense to change that name, then... don't add this to this particular though (obviously :P )\n. I'll... need a little more context on this one... is this still usefull ? what does it do exactly ?\n. @TurboGit any news ?\n. @upegelow i'm still not very clear about this...\nis this for the master or usermanual branch ?\n. quick note (this was discussed on IRC)\nJPG become completely black when deflicker is enabled. This needs to be fixed before merge\n- either by finding out what's going on with jpg\n- or by disabling deflickr for jpg\ninvestigation is in progress\n. ok, we are getting there, there are still a couple of weird details I found out, though...\n- when selecting a jpg, the deflicker checkbox is not greyed out. It can't be selected but it's still there. This is slightly problematic because clicking on it will still disable autoexposure if it is selected\n- when selecting a RAW and having autoexposure selected you need to click twice on deflicker to activate it. the first click will disable autoexposure, the second one will activate deflicker\n. note that the \"auto\" button, which is supposed to work more or less the same way doesn't have the problem. maybe check in what way they differ ?\n. Ok, this is good to go. However this is not integrated with our normal gettext infrastructure, i'm not sure if/how to do that. @levitte if you know a little more about that, don't hesitate to do a followup PR\n. no, I will close this PR, please do a new one with just the lua part\nthx for your work\n. just stating the obvious but... \nThis is a huge feature with lots of implication, do not expect it to be merged right away. It has lots of implications for DT (including, but not limited to, having to host user generated stuff, which we never did so far) it needs quite a bit of discussion\n. ok, before any inclusion, there is some cleanup needed. You add stuff to the usermanual, you change stuff in the histogram, and there is a new keyword module which might be related to style upload, but should probably be a separate PR in the first place. \nplease try to cleanup this (probably as a new PR) and then i'll try to review\nin the mean time i'll discuss the feature idea itself with the other devs...\n. oh, that's a shame, the idea was a good one :( \nI'll close the PR for the moment since there is little sense to keep it open, but please pick it back up at  some point. We can help with the git part too\n. Ok. Since we don't know what we want to do, this is a simple code, and it is most likely to not be what we want in the long term, i'll close the PR\nfeel free to reopen one when we have figured out what we really want to do...\n. let's go for a new PR if it makes more sense... please reopen one with the verb vs noun context\n. what is the use-case ? what distro do you have problems with ?\n(note to self: tested, works correctly)\n. i'll do a quick review, but this is not my domain, i'll try to reping @hanatos\n. From a documentation point of view it might be worth adding a good, thick, README file in that directory for users to know how to use the tool\na README in the tool directory can be updated if we update the tools, which is a nice thing.\nwe will also need to update the blog post about basecurves to point at the README, but that's a small thing to remember to do once it's perged\n. @MRIG is your git clean ? could you double-check with git-status ?\n. yes, perfectly. (didn't test, that was just to test the building, no DT time right now)\n. what shell are you using ? please type \"which sh\" if you are not sure\n. my guess is that mycameracurves.sh contains some bashism...\nit's hard to say becauseI don't have the file around @edgomez  : did you look into it ?\n. @MRIG can you retest ? that would be awesome...\n. ok, no big deal, we will wait for you to get better \n. I copy/pasted manually because of merge conflict, but it's in\n. awesome, i'll look into this ASAP\n. this looses existing translations... is there a way to salvage that ? \n. ok, let's loose the translation, then... no big deal.\n. A quick look it seems fine. i'll ask around, but it should be good to merge\n. the commit about the memcpy is wrong according to @hanatos so you want to remove it before merge...\ndiscuss it on IRC if you are not convinced\n. (we usually do PR in english, but since this is about the french translation I guess it's fine)\nnon, il faut qu'un d\u00e9veloppeur DT les accepte. C'est g\u00e9n\u00e9ralement moi, mais la traduction fran\u00e7aise est g\u00e9n\u00e9ralement g\u00e9r\u00e9e par @TurboGit \nJe ne suis pas certain de ce que tu as chang\u00e9 donc je vais vous laisser discuter et merger\n@TurboGit : A priori je te laisse faire, si tu ne souhaite pas t'en occuper, laisse un commentaire et je reprendrais la main...\n. ok, dois-je fermer cette PR ? je crois que vous pouvez le faire vous-m\u00eame... sinon, dois-je la merger ?\n. @michleb for next time, please always use english for your commit messages\nthese end up in our git history and french speakers might not be the only ones needing them\n. I can't test this myself (no opencl enabled computer but this sounds like a great idea which will help bug reports, i'm all for it :)\n. I don't have the skill to juge or review this... @houz ? @hanatos ?\n. @LebedevRI will you update according to @houz 's comment on IRC or is this still good to go ?\n. Ok, separate to any discussion on actually merging the algo, this PR is very messy.\nyou add some project build files from your editor that shouldn't be there\nthere are a couple of .orig files that shouldn't be there\nyou add a huge build.log file that should not be there\nyou add some compiled binaries from the tools/subdir\nthat's not good. you need to rebase/cleanup/resubmit this PR.  please cleanup and resubmit.\n. that would be better. As you can see there is some defiance to the idea of including new algorithms if we can't prove they are usefull and don't have the manpower to maintain them.\ngetting a go/no-go on the ML first would avoid you too much useless work...\n. as I said, so far the devs in general arn't convinced your new algos are really providing a better solution for high noise iso, my guess is that you should build a sort -of online gallery to show your results... but again, try to post that on the ML rather than here, since this is not the right place for feature discussion\n. After discussion on IRC this is an interesting subject but is not good \"as is\" this needs (at least) to be configurable with sane defaults.\nFeel free to open another PR with this\n. could you give a bit more detailed description of what you are doing exactly ? it seems to me that all this is indeed doable via lua (in which case I will close the pull request) but i am not entirely sure...\nLua would probably make it useable only through shortcuts (no UI elements in lua at this stage) but @houz is right that this is too specific to be merged in mainline... so let's make sure lua provides all the tools you want and then close the PR\n. yes, so if I understand correctly, a pseudo code for you would be something like\n```\non_shortcut()\n   foreach(image)\n       if(is in a group) then check_leader(image)\n   end\nend\ncheck_image(image)\n  if(no image in group is modified) then\n     set the jpg as group leader\n  else\n    set a modified image as group leader\n```\nthis is very simplified but I think that's your use case. It can be entirely done in lua quite easily, so this PR can indeed be closed.\nThere isn't really a way to share lua scripts at this point, you should post it on the mailing list and add it to http://www.darktable.org/redmine/projects/darktable/wiki/LuaScripts\nbut we don't have a very good structure to collect scripts yet. \n. i'm not very good at cmake, in with what build system did you need this ?\n. I kinda felt asleep at the wheel here... is this still needed ? If yes i'll test and merge quickly...\n. -  removing version history is trivial. I can also add it as its own section at the end\n- I'm open to suggestions on how to make the attribute info more clear. I thought clickable links to a section explaining what it is was good...\n- which ones ? how can I do that ? automatically split them somewhere ? \nmost of these are function description, I could change \nf(a:ta,b:tb,c:tc) : ret \nto \nf(\n  a: ta\n  b: tb\n  c: tc\n ) :ret \nmaybe with clickable links... what do you think ?\n. my script\npackage.path = package.path..\";/home/rosen/perso/darktable/darktable/tools/lua_doc/?.lua\"\nusermanual = require \"usermanual\"\noutfile =io.open(\"/home/rosen/perso/darktable/darktable/doc/usermanual/lua/lua_api.xml\",\"w+\")\noutfile:write(usermanual.get_doc())\noutfile:close()\nos.exit()\nyou seem to be missing the first line... i'm not sure that's the problem, though... your error is weird...\n. sorry, I was away. I'll try to reproduce your problem here ASAP and keep you posted\nyou did not answer my comment about formating, though, which is something we can work on in parallel to your build problem...\n- I will remove all version history unless you want me to add it elsewhere/differently\n- any ideas for attributes ? again, this is now quite adaptable, but it needs to be in the documentation somewhere...\n- how can I improve the synopsis... I could remove the type info entirely for fuction, that could work too since the info is in the detailed parameter description...\nAs a more general thought, I am not sure if the lua api should be in the usermanual or in a separate document...\n- it's a lot of work to translate for little gain\n- it's really something you want to look at separately\nthoughts ?\n. removed history in the newest version...\nplease note the commented lines in the generator, it seems that the id= attribute in  is not processed correctly. that's a shame, I can't make term definitions tagets of clickable links...\n. The following works for me...\npackage.path = package.path..\";/home/rosen/perso/darktable/darktable/tools/lua_doc/?.lua\"\nusermanual = require \"usermanual\"\noutfile =io.open(\"/home/rosen/perso/darktable/darktable/doc/usermanual/lua/lua_api.xml\",\"w+\")\noutfile:write(usermanual.get_doc())\noutfile:close()\nos.exit()\ndoes it for you ? (with adapted path, obviously)\nif it doesn't it might have something to do with your library.db file... I'll try with an empty one and make sure everything works ok...\n. sorry for the long time to come back to you...\nyour version of DT seems not to have webp compiled in, which causes the documentation tools to crash when trying to document the webp module\nI can see two ways around this problem\n- make all options mandatory when compiling for documentation (which forces the documentation to be complete) and check properly to avoid the crash\n- make optional parts be optional for documentation generation, maybe with a warning message when generating documentation\nwhich way do you think we should go ?\n. hmm, looking at the line numbers you probably did not use the version from the lua_usermanual branch... \n(and you probably have no image in your database, but the lua_usermanual branch checks that for you)\nI appreciate that you test the generation code, it helps debugging it, but if you don't want to, that's fine too. Please comment on the lua_api.xml it's pretty easy for me to change/regenerate it so let's focus on that...\n. ok, let's just drop the lua generation\nplease generate the usermanual with the lua_usermanual branch and tell me what you think of the lua_api section (layout, organisation, XML tags used) I'll regenerate and update based on your comments\n. ok, so are we good at this point ? can I merge this ?\nI think we are good. I doesn't look perfect but it's mergeagble, and separating the lua API from the rest of the usermanual is a different task altogether....\n. ok, I'll look into that... i'm not sure what you mean with your second point, could you detail a bit more ?\n. ok, pushed a commit that fixes the xmllint aspect. waiting for you feedback for the rest\n. you mean that I use  instead of  .. \nyeah.. I have problem with numbered section. I can easily generate the section numbers, but they are limited in depth. The lua API is higly tree-like by nature and needs more depth than that. I am open to suggestions on how to solve this, but I don't really know...\n. not sure if this one is for @pmjdebruijn or @hanatos i'm assigning it to @pmjdebruijn for the time being, feel free to reassign \n. nice idea, our review bandwith is very limited, but we'll do our best to try to review it...\n. @fingerle since you know the area really well, it would be great if you could review and test #548 I will close this PR in the mean time... thx for the work, it's great to have people joining the fun...\n. I don't think this is the proper fix. If export_dispatched is mandatory then lua storages should provide it. The default call uses a _nop fucntion and we should either set it to that function or to a similar, empty one ( @houz : any comment on that ?) moreover there is a similar problem, IIRC, with formats that needs to be checked too.\nLast, it might be interesting to actually have a lua callback here. That would not be too hard to implement. Something to add to my todo list, I guess...\ncould you look into doing a cleaner fix ? the bug itself is a real one. You can do the callback part if you want to, but if you don't i'll do it at some point...\n. forget my comment about a similar problem with formats... lua can't add new formats, only new storages\n. Ok I have commited a fix for that bug, so no need for this one anymore. thx for reporting\n. @bieber ping ? is this ready to commit ?\n. @jcsogo  did you try with a newer version ? does it work ?\nmlq, I am not sure that libsecret/gnomekeyring/kwallet should be exclusive. A packager that compiles DT for a distribution probably wants his package to work on both backends with a single binary\nalternatively the packager could only enable libsecret at compile time and depend on that lib...\n@pmjdebruijn : opinions ? you know distro policies better than we do...\n. good to close ?\n. oooh... WB + masks = finally getting those dual-lighted images working :)\n. maybe we need a \"sticky z\" and fix this, rather than keeping it that way and making it a feature...\n. my idea\n1. preview shouldn't stick when leaving DT\n2. preview sholdn't stick when pressing z\n3. a new shortcut should be added for sticky-preview\nso IIUC you are offering to fix 1 and not touch to how sticky work for the other cases ? that sounds like a step in the right direction, but it would be nice to fixup 2 and 3 at the same time if possible...\n. ok, sounds good\n. This is safe for lua, so i'm ok to merge. Note my remark about using PATH_MAX rather than 4096\n. At this point it might be safer to not rely on PATH_MAX at all and replace it with DT_PATH_MAX or something...\n. could you add a proper #define then ? I don't like to have 4096 constants everywhere, especially in places where it's not obvious that the 4096 is a common pattern that can be relied on for path names\n. as a side note, it would have been better to name your PR something like \"french translation update\"\nIt makes managing things on our side simpler, thx...\n. we can't leave possibly hundreds of images dangling around on our user's FS, we need to deal with it.\nIf the images are copied locally we can expect to have a day's worth of images for a pro-photographer, which is usually a very high number of RAW files.\n. just add a tag to quickly to see it's not ready for merge yet...\n. thx\n. marking as bug to make sure this gets reviewed/merged before 1.6\n. @parafin if I understand your idea, you generalize the previous way of handling things (replace old parameters) by saying that all the instances of an IOP should be seen as one chunk, and you replace the whole chunk with the new chunks, including MI names, number of MI and of course MI parameters...\nI like that, it's pretty simple to explain and understand...\n. stating the obvious but... this will have to wait for after the 1.6 release...\nI'm a bit sorry, this FR has been going on for a very long time, but the timing is really bad. We will look into it once we are out of feature-freeze...\n. I would do a second PR, if possible.\n(on a side note, be carefull that a PR in github is linked to a branch, not a commit. so if you move the branch tip, you will move the PR. If you want to \"stack\" PR you need to create a second branch on top of the first one)\n. so, is it OK to close this PR and open one on your  new branch ?\n. I assume this is post 1.6 ?\n. This breaks string freeze :(\nshould it wait for 1.6.1 ?\n. isn't the text of the new option used as a tooltip and translated (I could be wrong, but i'm pretty sure it is)\n. oh, ok. I was pretty certain it was, in that case no problem with thtat\n. I'll just close it then... it shouldn't change anything for you and it simplifies bookkeeping on our side...\nfeel free to open a new one whenever you feel ready to have something you want merged\n. ok, @hanatos meant to merge master into print-module, not the other way round\nI have reverted the merge and rebased the print-module branch, hopefully I got it right.\nfeel free to reopen the PR and continue discussion there\n. mentionning @chubinou so he is aware of this...\n. can the PR be closed then ?\n. I personally think that A4 is better than A on its own. it's the most common paper size and will be  recognized by the people that are used to DIN standards. I never heard of our paper formats be called A or A family or anything like that, so A on its own won't be easily understood, whereas A4 will be recognized instantly.\nThe other formats (B and C) are much less used and the few people that would know about them would probably know enough about the DIN standard to recognize them as DIN and know that they have the same ratio than the A family.\nIn other word : people that know the DIN standard won't be helped by having A, B, C listed next to it, and people that don't wouldn't recognize A on its own as \"the common paper format ratio\"  so A4 sounds a good idea to me...\n. because of (2) I would argue that it should build in master but be disabled before release. \nuser can't be trusted to read the warnings on the box...\n. Thanks for taking care of lua\n. I usually use g_idle_add or similar when I need to do that for lua... I.e I pass a function to the mainloop to execute on my behalf\n. one small issue left, the tooltip should change with the the trash status, appart from that, all seems good\n. I think the high level answer is that an error should be displayed if we try to delete files and no file is deleted. I.E if some files are deleted, it's ok. I am not sure how this could happen with a bunch of file, but yeahj, avoiding flooding the user with messages would be better...\n. @LebedevRI I'll have to disagree on that one... 5.3 is not really a magical number, it's the first version that is not 5.2 \nWith lua we usually want an exact major version since compatibility breaks, and in the case of 5.2 we know for a fact that it does, since 5.3 is released. To me it makes little sense to specify it at the call level since it won't ever be any value except 5.3\nIt could be argued that we should be able to test either =5.2 or >=5.2, but this is a DT implementation of FindLua5.2 and in our case we want exactly 5.2 until we migrate and want exactly 5.3\nAnd thx for reviving this PR, I had forgotten about it :)\n. good point\n. Ok, except for crosslinks to the API everything should be ready(i'm not sure how to do that @upegelow if you have any idea, just tell me in a comment and I'll update everything. There seems to be only a couple of links in doc/usermanual/lua/lua.xml)\n. commited directly to trunk\n. I don't see any logging of which version of process is eventually used... you probably want to add that to default_process to help debugging...\nopencl/non-opencl already complicates bug reports a lot, so we definitely want a way for users to realiably tell us what they are using...\n. I wasn't thinking of letting them decide, more of an equivalent of \"-d opencl\" to know what implementation is used when debugging\n. is it normal that this PR is closed ? apparently it was closed and some commits added afterward....\n. hmm, would it be possible to add a \"self\" parameter to this ?\nI might want to add a way for lua to implement that function and lua code need to have access to the widget itself to know what it's working on...\n. adding a \"GtkWidget* self\" parameter to the callback pointing to the widget for whom we are calculating the value would be enough for my need...\n. yes, that's it, thx a lot\n. looks good to me, it supports all the cases I can think of, and seems consistant.\n. couple of remarks (I havn't read the whole thing yet)\n- you can download archives from github using curl, thus avoiding needing git. maybe see if git exists and if it doesn't, then download the archive (you can probably download any commit/branch)\n- we need a branch policy on the lua-scripts before we do that. In particular so that lua script branches follow DT branches. I tried to do that at some point, but I am not sure how \"clean\" we are wrt compatibility. \nSo, overall, i'm ok with the idea but I don't think lua-scripts is ready for that yet. of course @supertobi has the last word on that particular aspect.\n. I agree mostly with @supertobi, it's too early to integrate, the idea is good though.\nWe can think of a better UI, I can add widgets if needed, or look into making stuff more scriptable in preferences...\nbut anyway, the big question is settling the lua-scripts infrastructure. I think this PR should be closed and reopened once the other side is ready enough. \n. I would temporarly add it to lua-scripts, less chance o it being lost than on the ML, and we will just rmove it from there once it's ready for darktable proper\n. beter late than never, here is a small lua script that uses the \"dt.control.read\" function, which is the one calling the \"select\" call you didn't know how to port\nit's fairly representative of how I see it being used : to read on named pipes or char devices to do weird stuff in dt\n```lua\ndt=require \"darktable\"\n-- create a pipe in the current directory\nos.execute(\"mkfifo ./tmp-dt\")\ndt.control.dispatch(function()\n    print(\"thread1 start\")\n    while not dt.control.ending do\n        print(\"writing to pipe\")\n        -- we need to use dt.control.execute because writing to a pipe is blocking until the pipe is opened for reading\n        -- and that won't happen if the control is blocked. dt.control.execute does not block lua\n        dt.control.execute(\"echo 'test string' > ./tmp-dt\")\n        dt.control.sleep(1000)\n    end\n    end)\nprint(\"between threads\")\ndt.control.dispatch(function()\n    print(\"thread2 start\")\n    local fifo = io.open(\"./tmp-dt\",\"r\")\n    while not dt.control.ending do\n        -- dt.control.read is more like a \"select\" : it blocks this lua thread without blocking the actual execution but does not actually read data\n        dt.control.read(fifo)\n        print(fifo:read())\n        dt.control.sleep(1000)\n    end\n    end)\n. after discussing with @houz, dt.control.read makes little sense under windows since pipes and devices work differently, and any code using this API would be linux specific anyway.\nso I will disable it for windows build (via #defined(_WIN32) don't worry about it\nI'll push the change once master is not frozen anymore. This looks correct but I don't have time to completely check and we are deep in RC territory.\nthat would be worth adding, though. no API change, strictly a bugfix. ok, first stable update it is, then... that is not a release blocker. Thx for pointing that out, I have reviewed all pushnumber sites in the code and fixed quite a few in a separate commit. Ok, your example file has convinced me, except maybe the pairs example\nwidgets should be consistant and i'm not sure how other widgets react to pairs() do they return their attributes ?\nit would make sense that iterating on a widget would return all attributes (including childs) and ipairs would return child only... LGTM. Looks good to me. you sure about this ? I guess this should be generic to all views...\n. there is a dt_view_type_flags_t defined in src/views/view.h does your dt_undo_type_t duplicate it .? if yes, it might be better to reuse...\n. here using dt_undo_type_t instead of uint32_t would probably make it better for the reader to figure out what to use as parameters\n(same thing in clear_undo)\n. shouldn't the undo list be attached to a view instead of being a global variable ?\nyou might have a use case where having a global would make more sense, but in that case wouldn't it make more sense to have it in the darktable global variable that already stores all sort of global stuff...\n. arn't you calling dt_control_queue_redraw_center twice here ?\n. shouldn't there be a #else here ? an undefine LF_SEARCH_SORT_AND_UNIQUIFY will cause a compilation error\n. hmm, this seems a bit weird... the function will return the last need_exif value. shouldn't it somehow \"combine\" what the different cameras want ?\n. shouldn't there be a FOR_HDR somewhere in that line ?\n. you added a whitespace here\n. yes, that's what I meant. (and I was not the one finding that out, just the one pointing it, btw)\nnote that I didn't check the context, it was more a \"warning, this is not a nop\" kind of warning\n. you will need to provide descriptions before we merge...\n. good point. git blame will be enough to figure out what it is, I guess...\n. agreed, renaming to luaapi, \nhowever, only translated UM are added to the UM target and I did the same... I can change that, but i'd rather stay consistant with UM\n. not sure what you mean, changed from darktable-api to darktable-lua-api ?\n. no, but most people will build both the api and the UM, so no harm... and i might add images at some point, so I might as well have the infra in place\n. enable\n. how do you do that ?\n. if this is a generic problem, you might want to make a separate PR for those\n. what's the problem with this code, win miss fseek  ? is that something that is generic and is needed for other arch ?\n. This is the backend to our implementation of the blocking read in lua. that function is supposed to block on a file-descriptor and return when there is some data to read. (while releasing the lua lock)\nit can't be removed like that or it would be breaking all scripts using that functionality.\nI don't know how to do the equivalent of a \"select\" in windows. I'm not even sure if it makes sense for windows (the point is to read special files, like sockets, that windows usually doesn't have) \nreally not sure what to do here. \n. why this chunk of code ? what are you fixing ?\n. here, you are returning a nil instead of raising an error when accessing out-of-bound elements.\nI'm not sure it's a good idea. we have a length operator so people can check early and it's a change in API that I don't really see the advantage\nmoreover that change of behaviour isn't documented in your commit message. same remark. That last line has disapeared and that looks weird to me\nthe old code returned container->uservalue[searched_widget]  your new code returns searched_widget directely.\nCould you check what's going on here ? IIRC because of the way GTK and lua interact, you need to go throught that gymnastic or you risk returning the gtk-widget instead of the lua widget.... wait... I don't see how this is related to ipairs, \nyes you are supposed to be able to iterate with ipairs, do you know why it didn't work , did ipair try to access out of bound element ?\nmaybe it would be enough to return nil for key == length+1 and an error for other access... \nI don't want to allow access to negative index (not sure exactly how lua reacts to that) and i'm a bit worried about accessing random beyond-end indices. If you set a random non-existing index, we would need to \"fill up\" the widget with the missing elements ?. hmm, good point\n. why change this ? . same here. arn't these two pointers aliased via the type system , lua/widget.c line 102 aliases the gtk widget to the lua widget...\n. ",
    "jcsogo": "@boucman Actually trac is closed now. The bug has been moved to redmine. I am not sure how git and redmine integrates.\n. @boucman that file has some special github markup, so the links are treated as such, and some other things. I plan to do a plain text file of it and place it as a normal README.\n. @jesperpedersen I see you have opened a new pull request... is that an updated file? I think you can update a pull request when you update your patch... check the help here https://help.github.com/articles/using-pull-requests\nThanks\n. The pull request has arrived. I know yesterday there were some\ndiscussion on it on the IRC channel, but I was not able to\nparticipate.\nOn Tue, Jun 5, 2012 at 8:01 AM, Richard Wonka\nreply@reply.github.com\nwrote:\n\nThis is my first pull request to see if I have understood how this is done.\nadded vim modeline to set some basic defaults for vim users\nYou can merge this Pull Request by running:\ngit pull https://github.com/richardwonka/darktable wonky\nOr you can view, comment on it, or merge it online at:\nhttps://github.com/darktable-org/darktable/pull/11\n-- Commit Summary --\n- * added vim: modeline to darktable.c\n- * changed vim modeline to be more explicit\n-- File Changes --\nM src/common/darktable.c (5)\n-- Patch Links --\nhttps://github.com/darktable-org/darktable/pull/11.patch\n\u00a0https://github.com/darktable-org/darktable/pull/11.diff\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/11\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n\u00a0 \u00a0jcsogo@gmail.com\n. On Mon, Jun 11, 2012 at 10:46 AM, Richard Wonka\nreply@reply.github.com\nwrote:\n\nAll files have been set up and a quick hack is in tools/ that will update these modelines on demand.\n\nNice, then please reopen the pull request with the updated commits!\nThanks!\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n\u00a0 \u00a0jcsogo@gmail.com\n. Everything is ok, I just say it after replying you. Anyway, if you are using your own branch within your own fork (as I think you are), you can just update the pull request. https://help.github.com/articles/using-pull-requests\n. On Sun, Aug 12, 2012 at 8:52 AM, hanatos notifications@github.com wrote:\n\nworks as advertised for me. not sure about the copy feature, do we need\nit? i guess removing features will always be kind of simple though. i'd\nalso be interested in jose's opinion on this, he is working on a\nfolder-based collection thing that might touch similar code.\nI think it makes sense to have this feature. I will check the UI later, but\ndepending on how it is made, we can integrate it in my module, or make it\nsomething complementary.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. @jesperpedersen I may try to clear this out a bit, but I wouldn't like to leave this as one commit: it doesn't shows how many works I have put in there ;-)\n. On Saturday, September 8, 2012, hanatos wrote:\n\ni tried this again, and have some comments :)\n- i like the separation folders/film rolls\n- when i select folders for the first time, dt crashes (can't\n  reproduce though, doesn't do it the second time)\n May be related with the db not being updated or something related,\n\nI will look to it.\n- until the sync thing is implemented, the button should be removed\n  from the gui (as it causes an instant crash, too)\n I know, it is there only as a proof of concept,\n\n\n\nwhen i expand a couple of folders, the list grows indefinitely\n  (larger than screen)\nI need to put that box into a gtkscrolledwindow, but when I tried\n  before nothing was shown. I will check again..\n- double clicking a folder doesn't always seem to work. it shows a >0\n  count of pictures, but the collection remains empty (no other filters/stars\n  active)\nNever happened to me,\n- i still don't understand the `local hdd' label. seems to be\n  constant/without functionality? most of my pictures are on a removable\n  drive, that doesn't seem to matter?\nI am not rescanning your directories, so dt doesn't know where old\n  film rolls are placed. I will think about it, but probably a bg job should\n  do that the first time the path in which the film roll is placed.\n\n\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. Already merged\n. @jesperpedersen I will look at it later, in case it is not produced by the new way to define signals.thanks for testing!\n. @jesperpedersen it should be working now, but a minor bug I found that I was not able to fix yesterday night (was too late). I will fix it today.\n. @jesperpedersen sorry if I wasn't clear before. The \"minor\" bug is big in the sense of functionality (the path in the third column of the tree doesn't match what you see in the tree itself) but it is easy to fix. It is only a problem of writing one thing in the node and another in the path column\n. @jesperpedersen now everything should work, and the warning shouldn't be there any more\n. @jesperpedersen Thanks again for your tests\nIssues:\n- Your 3 issues are solved. Actually the second one is not a bug but a feature. Now, only if you type in the gtkentry the list is going to be filtered, but it is not while you use the mouse and click on a row to select it. That allows you to browse those and change from one to another without having to reset the rule.\nAbout your other stuff:\n- The sync action is (was) there. I have just disabled it as it is not complete and is for releasing. But the skeleton of the code is in the file.\n- I know the scrollbar is added, but I don't know other way to solve that if your tree is deep. If you have files/filmrolls in external drives it can be reduced if we use back what I have disabled in this branch. It was using a label to separate each drive and therefore to be able to reduce the tree depth to a minimun.\nThanks\n. @jesperpedersen thanks for your patience! :D\nWhere/when that assert appears? What were you using?\n. Recreating the tree is the easiest to do when the list is updated, but the side effect is what you see: the tree is collapsed. To avoid that, a lot more code has to be added to insert and remove nodes as they are added or disappear, so the tree is not regenerated.\n. I wanted people to be able to review and test, and also to wait for 1.1.1\nto be released.\nOn Sun, Dec 9, 2012 at 9:17 PM, Boucman notifications@github.com wrote:\n\njcsogo: any reason you didn't merge that yourself ? (asking mainly so I\nknow if I need someone to review this for you)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/90#issuecomment-11175323.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. Can't we consider sh as the minumun standad? I usually thought that all\nshells were compatible with sh, as it was defining the minimun set. If that\nis true, and if our scripts can work with it, it will be ok to assume that.\nOn Wed, Dec 12, 2012 at 10:10 AM, Jean-S\u00e9bastien P\u00e9dron \nnotifications@github.com wrote:\n\nI don't assume /bin/sh to be Bash: *BSD systems ships Bash as\n/usr/local/bin/bash. I assume /bin/sh to be Bourne shell compatible. For\ninstance:\n- Debian ships Dash as /bin/sh\n- Mac OS X (at least 10.5) ships Bash 3.2 as /bin/sh\nI don't know ksh, but the official site states that it's compatible with\nBourne shell. I tried tools/create_release.sh with ksh93 and it worked.\nI proposed what you suggest in a previous pull request: #88https://github.com/darktable-org/darktable/issues/88\n.\nMy only goal is to stop referring to Bash as /bin/bash, because it's not\nportable. boucman asked about /bin/sh and I thought it would be ok too,\nconsidering the current scripts. Thus, this new pull request. But I'm fine\nwith whatever pull request (or none) you choose :-)\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/94#issuecomment-11281587.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. Just curiosity, but is there a reason for the radius to be dependent on image size, and not screen size?\n. @TurboGit thanks for all your contributions! A couple of things about this feature: 1. wouldn't make sense to have all checked and let the user uncheck what he doesn't want? 2. would make sense to compress the history stack internally before showing it to the user, so only the module in the last state can be selected? Currently is a bit misleading if the same module is shown several times.\nThanks\n. Oh, and also select all (or select none if it is change) shouldn't be select all and accept, IMHO.\n. I have added the g_object_unref needed for those two GFiles generated inline.\n. I have not tried the code yet, but would it make sense to have to drop it in the filmroll to delete the GPS tagging? As in the analogy to drag from the filmroll to the map and from the map to the filmroll.\n. Also, what happens when you want to drag an image outside of the current\narea of the shown map? Do you have to grab it and place it in the border,\nso the map scrolls? If this is like I am commenting, it may be quite easy\nto drop it out of the image, and then lose the location without any other\nwarning\nOn Tue, Feb 5, 2013 at 2:10 PM, Henrik Andersson\nnotifications@github.comwrote:\n\nI disagree with you, trashbin should just be shown while dragging which\nwould make more sense\nthen a hidden feature by dropping outside the map.. Its not obvious and I\nwouldn't even \"try\" that\nto \"see\" if i could remove gps information that way..\n2013/2/5 Pascal Obry notifications@github.com\n\nI would avoid the trashbin as it will clutter the screen for not much.\nMoving outside the map seems a comprehensible gesture to say \"please\nremove\nthis image from the map\".\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/darktable-org/darktable/pull/175#issuecomment-13128056>.\n\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/175#issuecomment-13128396.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. I think that having a more advanced undo would be a great improvement.\nIn a first moment I thought that having the undo per view would the best,\nbut I have doubts when you can do lighttable operations in darkroom (stars,\ncolor labels,...)\n. Really, the fix doesn't need the messages. They only make clearer if the\nrating has been applied to 1 or several images, so it is more obvious to\nthe user to spot an error.\nOn Wed, Mar 13, 2013 at 9:24 AM, Boucman notifications@github.com wrote:\n\ntechnically if you copy an existing sentence you are not breaking the\nstring freeze, but I think this is post 1.2 material anyway...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/192#issuecomment-14829420\n.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. We have to be careful about changing things, even a little. In the not so\nlong term we need a framework to keep old images with old ions, and only\nupdate them on user request.\nEl mi\u00e9rcoles, 13 de marzo de 2013, Pascal Obry escribi\u00f3:\n\nIt won't affect history stack. It just change a little bit the border size\nfor portrait picture.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/194#issuecomment-14864364\n.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. Yes, this is what I was expecting. The are only a couple of minor issues: I would make the arrow more obvious, so it is not needed to zoom so much and I think you are drawing the arrow a bit behind the last pixel of the line and it makes a funny effect when you move the circle.\nAnyways, thanks\n. Yes, looks better. And as you say, just seeing which circle doesn't have the line in the middle of it is enough.\n. @houz I think that the places in which the function is being used makes sense, but I have to admit that for the last one reseting the filter to 0 stars can help the user to see faster if he has added the right filmroll.\n. This PR is becoming messy, but the patch is interesting :)\nPlease do the following in your branch:\ngit rebase upstream/master\nand push the result to github (you will need to git push -f to force it)\nAnd recreate the pull request. I think it is correct to apply for the current version, but I wanted to check what it did contained and it is becoming pretty hard. To avoid this in the future, always put your commits in a different branch than master and rebase it from time to time\n. No I can't, but he  already had done the rebase it seems as there were only\n5 commits of difference on top of snapfix branch. It was only that the old\nPR was messy in the github system.\nEl 24/08/2013 11:04, \"Boucman\" notifications@github.com escribi\u00f3:\n\n@jcsogo https://github.com/jcsogo you can create PR but you can't do\nthe rebase yourself, can you ?\nanyway, thx to both of you for the cleanup...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/290#issuecomment-23205574\n.\n. How is this supposed to work on terms of the UI? I haven't noticed this\nfunctionality, but I don't tag a lot either. The suggested cloud tag could\nbe the most used related to the ones already present in the image\nEl 03/09/2013 21:15, \"hanatos\" notifications@github.com escribi\u00f3:\nas the original author of the tagxtag table i want to raise the question\nif that stuff is still useful today? is anyone really using the tag\nproposals? i remember some confusion on the mailing list where people would\nactually expect a dump alphabetic/most used list more than a `related tags'\nlist. maybe we should just remove all of that code?\ni'm not tagging a lot, so i can't judge how useful these proposals are..\nwe haven't been using sql triggers anywhere else so far, so i would be\nafraid of debugging this in case anything goes wrong.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/298#issuecomment-23739130\n.\n. I think that probably this is useful as well, but it needs some enhancements in the UI, like a tag cloud that autoupgrades when a tag is written.\n. The changes seem ok to me, but I don't have right now access to my laptop and I can't merge this and test it before pushing. So if anyone can do it I would be glad - I don't want to use the Merge pull request button in github without testing.\n. Hi,\n\nWhy are you doing all these mini-PR? Even if you are a bit behind the project I think you don't need overview for all this. ;-)\n. It would be interesting to have the main points beyond of it being configurable that were discussed on IRC, in case Pedro wasn't there or anyone else would like to implement the missing bits.\n. You have really made the patch that houz and I were discussing last weekend! Thanks! I will test it and let you know if something need to be fixed.\n. Ok. It seems that you are missing the FindLibsecret.cmake file in your commits and I can't compile it.\n. No, as it requires upgrading to the latest libsecret I haven't had time\nyet. I will probably be able to do so this weekend.\n El 11/06/2014 08:16, \"Boucman\" notifications@github.com escribi\u00f3:\n\n@jcsogo https://github.com/jcsogo did you try with a newer version ?\ndoes it work ?\nmlq, I am not sure that libsecret/gnomekeyring/kwallet should be\nexclusive. A packager that compiles DT for a distribution probably wants\nhis package to work on both backends with a single binary\nalternatively the packager could only enable libsecret at compile time and\ndepend on that lib...\n@pmjdebruijn https://github.com/pmjdebruijn : opinions ? you know\ndistro policies better than we do...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/577#issuecomment-45739086\n.\n. I have updated to libsecret 0.18 and the PR compiles, and the passwords seems to be stored, but I can't see the bucket you're dropping them with seahorse... is that a seahorse problem? I don't like to have things around I can't see.\n. Will this make the changed history bit be always enabled?\n. But no one of these are used if you use jpg thumbnails, only for RAW\nthumbnails. Rotation will always be used\n. It seems to work. Merging.\n. Well,  you can always send an old fashioned patch diff file to the mailing\nlist. t\n. @parafin this is the only way to support facebook right now. This or we drop support for it. You can of course decide not linking it to webkit and you won't have it.\n\n@hanatos sorry about those files, I used an old copy of the repo and forgot about those when doing the initial commit. Already fixed in the code (rebased)\n. I am asking right now for the app to be transferred to us/darktable\nfacebook page. Let's see when this is done.\nOn Tue, Jan 27, 2015 at 11:41 AM, houz notifications@github.com wrote:\n\nI wouldn't know how to do that without a Facebook account and access to\nthe app settings.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/825#issuecomment-71624771\n.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\n   jcsogo@gmail.com\n. dt_ratings_apply_to_image() doesn't call dt_control_queue_redraw_center(), but my idea was to remove this call from dt_ratings_apply_to_selection() also and call it in the caller. It might be I only made that halfway (the wonders of doing things late in the night)\n. And yes, this line has to be deleted\n. ",
    "itarozzi": "I'm newbie on submitting patch, so may be I did not do all steps right.\nI submitted 2 patches here:\nhttp://sourceforge.net/apps/trac/darktable/ticket/438\nI thinked developers team have to examine and decide if reject or merge\n(apply) in master.\nAfter this we received mail from Petr Styblo in  dev mailing list,\nwith new patch (he did not see my patch on trac).\nExamining his patch I found some other fix to do, but meanwhile new\ngithub arrived :)\nSo I completed my fix and, instead to submit a new old-style patch, I\nforked github project and create this bugfix branch.\nBefore push I squeezed previous commit, so this makes old patch obsolete.\nNow I don't now what to do about old patch, but I think the bug can be\ntranslated to new redmine and there give some reference to github fork?\nIf I have to do something myself please write me :)\nIvan\n. As I wrote, I sent patch in trac only:\nhttp://sourceforge.net/apps/trac/darktable/ticket/438\nNow I activated my account in redmine too, but there I can't found my\nsubmitted bugs in trac (was #438 and #439).\nI wrote to Simon to notify this few minutes ago.\nSeems these bug and patch are not transfered from trac to redmine ?!?\nI asked Simon if I need to recreate bug on redmine or if better to wait\nuntil switch is complete. I'm waiting a response.\nIf I have to talk with you instead Simon, please tell me. I wrote Simon\nbecause he write to ML about switching account from trac to redmine ;)\nThanks!\n. Created new Bug #8722 in redmine. Thanks!\n. Il 06/06/2012 10:48, Boucman ha scritto:\n\nit's a bit early for a pull-request on that, you still have debug printf in your code and there are important TODO that needs to be filled\n\nSorry Boucman,\nI'm newbie on github and I didn't understand pull-request use; I didn't\nwant to use it as request to merge but only as commit notification to\nmain team. My mistake!\n\non another note, we have been discussing this issue on IRC a bit and we don't have a consensus on adding that checkbox...\n\nOk, no problem, but I had no feedback about this and I started to add it\nbecause in my workflow will be useful and because to learn something\nabout DT code and gtk :)\n\nWe do agree on the problem of overwriting, but we are looking for a better UI solution than the checkbox. We will post on the ML thread once we are a bit more consistent on our opinion\n\nOk, no problem. I agree there could be a better solution.\n\nIn the mean time I will close this merge request, feel free to rerequest once it is more mature\n\nOf course!\nbut you think could have sense to complete my branch or is better stop\nworking waiting a better solution you ask above?\nIf dev-team will never accept this patch because there is not consensus,\nmay be I will spend my time over other issue or features.\nThank you and sorry for entropy :)\nIvan\n. ",
    "simonspa": "Hi, I wrote you concerning the tickets. They got lost during transition and you might wanna re-create them in redmine. Thanks!\n. Hi Jesper,\nthanks for that.\nOne thing I noted when going through the wiki page quickly: the \"--rebase\" part. The problem with this is that it changes history. So if your branch is public (so pushed to your github repository) and people following this you will break their history.\nWe discussed this recently - but I don't know the final words on this. Maybe Jeremy can jump in?\n/Simon\n. huh? It didn't point there before? I didn't even look at the url since I saw Jepser's wiki page before the pull request...\nBeside the rebase thing I'd say: pulling.\n. Good catch!\nlooks fine, thanks!\n. Pulled and rephrased as suggested by McBofh:\n\"all except rejected\"\nThanks, minusdreidb!\n. I get\nIn file included from /usr/include/stdio.h:930:0,\n                 from /home/smn/own-dt/src/common/dtpthread.h:25,\n                 from /home/smn/own-dt/src/common/darktable.h:31,\n                 from /home/smn/own-dt/src/develop/develop.h:21,\n                 from /home/smn/own-dt/src/bauhaus/bauhaus.h:22,\n                 from /home/smn/own-dt/src/iop/watermark.c:25:\nIn function 'snprintf',\n    inlined from 'refresh_watermarks' at /home/smn/own-dt/src/iop/watermark.c:712:15:\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:65:3: error: call to __builtin___snprintf_chk will always overflow destination buffer [-Werror]\n. Hi Michal,\nfirst of all: thank you for contributing, even small patches improve dt and are very welcome.\nConcerning this pull request:\nYou unluckily missed the string freeze for our next release by some days. This means that no changes that affect strings should be applied to git master anymore since translators need some time to finish their work for the release.\nSo don't be disappointed if it takes some time from now until your patch reaches the main repo.\nBeside that maybe other devs want to comment anyway, I don't have time to test your patch right now.\n:)\nRegards,\nSimon\n. thank you! Maybe you can talk to Henrik/dinamic or Christian/christte on how to translate the missing bits...\n. thanks!\n. Hi Richard, \nthanks for your constant work. I suggest waiting with the merge of this particular PR since quite some people are not comfortable with the LR import being part of the darktable main application. So best thing is to wait until we sorted that out and then merge to where it belongs afterwards.\nOkay?\nThanks anyway,\nSimon\n. @levitte changed my mind: merged anyway - just the file will change...\n@TurboGit Maybe better somewhere else than here? IRC? Mailing list? I just talked to some. It's not the functionality in general, just the place.\n. Short question here:\nWhy do the rejected cross and the stars do have separate buttons? It's the same functionality (rejected = -1 star). Now showing the stars does not reveal rejected images since they could have no rating at all (0 stars)\nI'd go for one button (\"Show all ratings\") - and we already got rid of one UI element. :)\nBeside that: I like it.\nAnd I think it's more usable as toggle than as preference, too.\n. since we are in string freeze for 1.2.1 now you might just want to rebase to master for a merge.\n. I just ported your changes to master, thanks for the fixes.\n. Hi, could you please rebase this and merge it into darktable-1.2.x?\nThanks a lot!\n. thanks.\n. as far as I understand the case this is not correct. Changing the module drastically would then break the presets since they are bound to one specific version of the module. The translation to newer versions is then done via legacy parameters.\n. @rikles not sure about that, I guess it should work for both.\n@TurboGit the issue only occured because I wrongly bumped the preset versions to '3' while the module was still at '2'.\n. I tested this yesterday and it worked fine for me (running GTK+3 there). Not yet tested on GTK+2. Needs rebase.\n. probably @upegelow should have a look since the code is from him. But looks fine to me.\n. Sorry for the delay. Works fine for me, merged.\n. Hm, looks fine to me. Maybe HEAD changed and now it's corrected?\n@houz merge if you are okay with it, I don't see any problem with this PR.\n. I'm not entirely sure I would like to see that. Not applying c&r w/ double click usually means you haven't finished your cropping and the result is not the one you want to achieve. So I think the current behavior is more consistent here.\n. the crop& rotate module has always been one or darktable's Achilles tendons... :-)\n. Would it be possible for you to join is on IRC #darktable at tome point to discuss that a bit more in detail? I think in general solving this would be interesting but I would like to have that nailed down with some more opinions, both on the concept and the actual implementation. I haven't really looked at yours in detail but it only seems to take care of the mouse action, but what if we switch module by assigned key accelerator?\n. Nice feature, I marked it as Post-1.4 since we're in feature freeze.\n. i was also puzzled  when seeing the merge - it turned out he only merged a bug fix commit and somehow managed to close the pr.\nas far as it concerns me this is definitely post-1.4 stuff.\n. Hi Victor,\nthis PR doesn't apply cleanly to master anymore. Could you resolve the conflict so we can merge it?\nThanks!\n/Simon\n. Hi Victor,\nyou need to go into your repo and run\n$ git merge upstream master\n$ git push origin master\n(or whatever the names of your remotes are)\nin order to update your repository with the changes applied to our master. Something was in there making the merging non-fast-forward why you have to do it by hand.\nCheers,\nSimon\n. Hm, I actually have no idea what the problem was - doing it via command line there revealed no merge conflicts. I pushed your changes, thanks a lot! :)\nAnd your workflow is also the way to do it. The only thing you could improve is adding the main repository as another remote so you don't have to copy the url every time:\ngit remote add upstream git@github.com:darktable-org/darktable.git\ngit pull upstream master\n[...]\nCheers,\nSimon\n. what about the preceding _ for intltools?\nthe linked gnome page says:\nMaintainers/developers must set a preceding underscore in \"_Keywords\" to inform intltool that this field should be extracted, and its translations merged back into the .desktop.in file.\n. We were all still in Leipzig spending another day after LGM...\n:)\n. @fingerle I guess the easiest way would be to just produce one by checking out a git version featuring dt_iop_lensfun v2.\n. @pmjdebruijn is there anything special about this, since you are mentioned? Beside some indentation looks fine to me...\n@phedders could you do me a favor and just indent the lines as (almost) the rest of the file? Just a readability thing... Thanks!\n. Hi @cherrot \nI can't merge this PR since it doesn't apply cleanly. Could you rebase and update the PR? Thanks!\n/Simon\n. Just indent the brackets with the four multiplier to be in line with the rest of the file...\n. @milankni: can't merge, please rebase.\n. Thanks, @milankni !\n. Thanks!\n. Thanks!\n. Looks fine, thanks for the huge effort translating the manual!\n. @josepvm do you prefer to keep this PR around until you finished your translation work or is this commit already worth going into master on its own?\n. also .gitignore is changed, but I guess excluding Gimp files from the repo won't hurt anyone.\n. Thanks fro the translations, @upegelow: can the changes for the manual also just be merged or would you like to have them separately?\n. @houz: last time prokoudine said Russian would be \"good enough\" so i guess he wouldn't mind. Not sure about Ukrainian though.\n. Exactly, and he was arguing agains kicking it out, because most of the missing string would only be somewhere in tooltips and so on. That's what he meant with \"good enough\". So I vote for merging...\n. Suggestion for additional CONTRIBUTING.md content:\nGetting Started\n\nmake sure you have a user account on GitHub and are logged in\n'fork' the (main) project on GitHub using the button on the page of the main repo\n\nGeneral guidelines\n\nmake atomic commits (aka commit often)\nfor anything but trivial changes (e.g. affecting documentation only)\n  please do not work on the master branch, but create a feature\n  branch (see below for instructions) and commit only changes that\n  affect this particular feature\nuse descriptive commit messages -- for an example, see below\nfollow the style (indentation, naming schemes for variables, ...) of the existing code, where possible\n\nMaking Changes\nHave you fixed a bug already or would like to contribute your own\nprocessor into the main repository? Then please fork the project and\nissue a pull request using these instructions:\n- now add the newly forked repository as a git remote to your local darktable installation and rename the original repository to 'upstream':\ngit remote rename origin upstream\ngit remote add origin https://github.com/[YOUR GITHUB USER HERE]/darktable\ngit remote -v show\n- create and checkout a new branch for the feature you are developing based on the master branch:\ngit branch my_feature_branch master\ngit checkout my_feature_branch\n- now edit away on your local clone! But keep in sync with the development in the upstream repository by running\ngit pull upstream master\non a regular basis. Replace master by the appropriate branch if you work on a separate one within the main repository.\n- Commit often using a descriptive commit message in the form of\n```\nThis is a concrete and condensed headline for your commit\nAfter the headline followed by an empty line, add a more thorough\ndescription of what you have changed and why.  Refer to any issues on\nGitHub affected by the commit by writing something along the lines of\ne.g. 'this addresses issue darktable-org/darktable#1' to refer to the\nfirst issue in the main repository.\n```\n- push the edits to origin (your fork)\ngit push origin my_feature_branch\n- verify that your changes made it to your GitHub fork and then click there on the 'compare & pull request' button\n- summarize your changes and click on 'send'\n- now we will review your changes and comment on anything unclear; any\n  further commits you will make before the pull request is merged will\n  also end up in the same pull request, so you can easily add or\n  correct parts of your contribution while the review is ongoing.\n. @TurboGit why that? Looking at the description, I find:\n\nDefined as sharing your physical real-time location.\nFor example, this would include uploading the GPS co-ordinates of your current location. NOTE: This does not include heuristic based location services, e.g. GeoIP and others. \n\nEditing photos and uploading them does not reveal my current physical real-time location, but a location the picture has been taken at. Also, dt doesn't transmit this information automatically but the user needs to manually intervene and upload pictures to a service.. Without defining WGWG this is pretty useless, no?\n. Just to keep the code clean: could you remove those blank lines again?\n. This doesn't really belong here, right? Could you remove this from the PR?\n. Pull Request, sorry for the jargon...\n. ",
    "jesperpedersen": "@boucman as @jcsogo said, it is GitHub markup - see https://github.com/github/markup for details - you can see how it is rendered at https://github.com/jesperpedersen/darktable\n@jbsogo there are two; one for [master] and one for [darktable-1.0.x] since the build instructions are different\n. Closing\n. Hi Simon,\nYes, it keeps the history linear, since the merge commits are gone - take a look at master in gitk; it is quite complex. It also makes merging two commits for a backport easier. The merge commit gives credit to the committer where it should be the author that is in focus - see https://github.com/jbossas/jboss-as/ as an example.\nHowever, that is the way we do it at work; you guys decide for DT :)\nBest regards,\n Jesper\n. Squashing the commits into a single commit would make it easier to manage. I welcome this change :)\n. Had to apply:\n```\ndiff --git a/src/control/signal.c b/src/control/signal.c\nindex 7ce49f8..c433dd6 100644\n--- a/src/control/signal.c\n+++ b/src/control/signal.c\n@@ -56,7 +56,7 @@ static dt_signal_description _signal_description[DT_SIGNAL_COUNT] =\n{\"dt-collection-changed\",NULL,NULL,G_TYPE_NONE,g_cclosure_marshal_VOID__VOID,0,NULL},                   // DT_SIGNAL_COLLECTION_CHANGED\n\n\"dt-filmrolls-changed\",                         // DT_SIGNAL_FILMROLLS_CHANGED\n{\"dt-filmrolls-changed\"},                         // DT_SIGNAL_FILMROLLS_CHANGED\n\n/ Develop related signals /\n   {\"dt-develop-initialized\",NULL,NULL,G_TYPE_NONE,g_cclosure_marshal_VOID__VOID,0,NULL},                  // DT_SIGNAL_DEVELOP_INITIALIZED\n``\n. (process:7558): GLib-GObject-WARNING **: gsignal.c:1589: return value of type' for signal \"DarktableSignals::dt_filmrolls_changed\" is not a value type\n. Changed to \"folders\" during import:\n```\nthis is darktable 1.0+1761~g9dd899d reporting a segfault:\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n[New Thread 0x7fa38df3a700 (LWP 7621)]\n[New Thread 0x7fa38e73b700 (LWP 7620)]\n[New Thread 0x7fa38ef3c700 (LWP 7619)]\n[New Thread 0x7fa38d739700 (LWP 7618)]\n[New Thread 0x7fa38cf38700 (LWP 7617)]\n[New Thread 0x7fa38c737700 (LWP 7616)]\n[New Thread 0x7fa3819a7700 (LWP 7615)]\n[New Thread 0x7fa3821a8700 (LWP 7595)]\n[New Thread 0x7fa3829a9700 (LWP 7594)]\n[New Thread 0x7fa3831aa700 (LWP 7593)]\n[New Thread 0x7fa38b87e700 (LWP 7592)]\n[New Thread 0x7fa38b07d700 (LWP 7591)]\n[New Thread 0x7fa38a87c700 (LWP 7590)]\n[New Thread 0x7fa38a07b700 (LWP 7589)]\n[New Thread 0x7fa3839ab700 (LWP 7580)]\n[New Thread 0x7fa3841ac700 (LWP 7579)]\n[New Thread 0x7fa3849ad700 (LWP 7578)]\n[New Thread 0x7fa3851ae700 (LWP 7577)]\n[New Thread 0x7fa3859af700 (LWP 7576)]\n[New Thread 0x7fa3861b0700 (LWP 7575)]\n[New Thread 0x7fa3869b1700 (LWP 7574)]\n[New Thread 0x7fa4132a5700 (LWP 7569)]\n[New Thread 0x7fa413aa6700 (LWP 7568)]\n[New Thread 0x7fa3ebaa6700 (LWP 7567)]\n[New Thread 0x7fa4142a7700 (LWP 7566)]\n[New Thread 0x7fa414aa8700 (LWP 7565)]\n[New Thread 0x7fa4152a9700 (LWP 7564)]\n[New Thread 0x7fa415aaa700 (LWP 7563)]\n[New Thread 0x7fa4162ab700 (LWP 7562)]\n[New Thread 0x7fa416aac700 (LWP 7561)]\n[New Thread 0x7fa4172ad700 (LWP 7560)]\n[New Thread 0x7fa417aae700 (LWP 7559)]\n0x0000003b6dee8803 in poll () from /lib64/libc.so.6\n0  0x0000003b6dee8803 in poll () from /lib64/libc.so.6\n1  0x0000003b6fe45448 in ?? () from /lib64/libglib-2.0.so.0\n2  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n3  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n4  0x00007fa41a141361 in dt_gui_gtk_run (gui=0x12294d0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n5  0x0000000000400a66 in main (argc=1, argv=0x7fff55ad74a8) at /home/jp/DarkTable/darktable/src/main.c:25\nThread 33 (Thread 0x7fa417aae700 (LWP 7559)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e981f in dt_control_work (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1163\n    s = 0x1204250\n    __FUNCTION__ = \"dt_control_work\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 32 (Thread 0x7fa4172ad700 (LWP 7560)):\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\nNo symbol table info available.\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\nNo symbol table info available.\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\nNo symbol table info available.\n5  0x00007fa41a08f248 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n    read_something = 0\n    fd = 0x7fa404143f10\n    buf = \"\\001\\000\\000\\000\\000\\000\\000\\000\\030\\344\\023\\004\\244\\177\\000\\000\\330\\320\\032\\001\\000\\000\\000\\000\\350\\335\\033\\001\\000\\000\\000\\000\\330\\320\\032\\001\\000\\000\\000\\000\\350\\376\\033\\001\", '\\000' <repeats 20 times>\"\\330, \\320\\032\\001\\000\\000\\000\\000\\350\\304\\034\\001\\000\\000\\000\\000x\\253\\035\\004\\244\\177\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000`\\000\\000\\000\\000\\000\\000\\000\\230\\000\\000\\000\\000\\000\\000\\000\\330\\320\\032\\001\\000\\000\\000\\000+q\\203\\211;\\000\\000\\000\\350\\304\\034\\001\", '\\000' <repeats 20 times>, \"\\001\\000\\000\\000\\000\\000\\000\\000\\350\\300\\035\\004\\244\\177\\000\\000\\002\\000\\000\\000\\000\\000\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000\\265r\\203\\211;\\000\\000\\000\\330\\320\\032\\001\\000\\000\\000\\000\\350\\300\\035\\004\\244\\177\\000\\000\\b\\304\\033\\001\\000\\000\\000\\000x\\253\\035\\004\\244\\177\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000\\367y\\204\\211;\", '\\000' <repeats 19 times>, \"\\003\", '\\000' <repeats 16 times>, \"\\001\", '\\000' <repeats 22 times>...\n    name_used = 0x7fa40416c500 \"/tmp/darktable_bt_6KWFLW.txt\"\n    fout = 23\n    delete_file = 0\n    datadir = \"/usr/local/packages/darktable-1.1-20120929/share/darktable\\000\\000\\001\\000\\000\\000\\210\\324\\033\\001\\203\\000\\000\\000\\377\\377\\377\\377\\377\\377\\377d\\006\\000\\000\\000\\000\\000\\000\\000\u061e\\035\\004\\244\\177\\000\\000\\210\\260\\033\\001\\000\\000\\000\\000\\002\", '\\000' <repeats 12 times>\"\\210, \\223@\u061e\\035\\004\\244\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000y&\\204\\211;\\000\\000\\000X\\324\\032\\001\\000\\000\\000\\000\\320\\324\\032\\001\\000\\000\\000\\000\u061e\\035\\004\\244\\177\\000\\000\\210\\001\\035\\001\\000\\000\\000\\000@\\301\\035\\004\\244\\177\\000\\000\\271\\034\\203\\211;\\000\\000\\000\u061e\\035\\004\\244\\177\\000\\000H\\377\\033\\001\", '\\000' <repeats 12 times>, \"Sm\\201\\211;\\000\\000\\000\\330v\\033\\004\\244\\177\\000\\000h\\304\\033\\001\\000\\000\\000\\000PJ\\027\"...\n    command = 0x7fa4041dd0e0 \"gdb darktable 7558 -batch -x /usr/local/packages/darktable-1.1-20120929/share/darktable/gdb_commands\"\n\n6  \nNo symbol table info available.\n7  0x00007fa3925c2bbd in filmrolls_updated (instance=0x119da80, self=0x11ad078) at /home/jp/DarkTable/darktable/src/libs/collect.c:1545\n    dm = 0x11ad078\n    d = 0x1\n\n8  0x0000003b71a05d64 in ffi_call_unix64 () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n9  0x0000003b71a05785 in ffi_call () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n10 0x0000003b71e0ef6b in g_cclosure_marshal_generic () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n11 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n12 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n13 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n14 0x00007fa41a0f2b07 in dt_control_signal_raise (ctlsig=0x11a77c0, signal=DT_SIGNAL_FILMROLLS_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:113\n    extra_args = {{gp_offset = 24, fp_offset = 48, overflow_arg_area = 0x7fa4172ac810, reg_save_area = 0x7fa4172ac740}}\n    i_own_lock = 1\n\n15 0x00007fa41a0a83ae in dt_film_remove (id=10) at /home/jp/DarkTable/darktable/src/common/film.c:611\n    stmt = 0x7fa404190388\n    __FUNCTION__ = \"dt_film_remove\"\n    __PRETTY_FUNCTION__ = \"dt_film_remove\"\n\n16 0x00007fa41a0a4f01 in dt_film_cleanup (film=0x7fa404121830) at /home/jp/DarkTable/darktable/src/common/film.c:62\nNo locals.\n17 0x00007fa41a0a709a in dt_film_import1 (film=0x199a930) at /home/jp/DarkTable/darktable/src/common/film.c:471\n    dfn = 0x0\n    cdn = 0x7fa4041caf10 \"/home/jp/Pictures/Hawaii/20120825\"\n    recursive = 1\n    images = 0x143a000 = {0x7fa404001af0, 0x7fa40401e480, 0x7fa4040080c0, 0x7fa40401e980, 0x7fa404005ef0, 0x7fa404009a30, 0x7fa40401cd70, 0x7fa404002090, 0x7fa404003530, 0x7fa4040038f0, 0x7fa40401b010, 0x7fa404004ba0, 0x7fa404001a50, 0x7fa40401b430, 0x7fa4040054b0, 0x7fa4040034e0, 0x7fa404008610, 0x7fa40401e2f0, 0x7fa404005f90, 0x7fa4040047e0, 0x7fa40401e5c0, 0x7fa404001d70, 0x7fa40401b250, 0x7fa40401e160, 0x7fa40401dbc0, 0x7fa404001c80, 0x7fa404004830, 0x7fa4040086b0, 0x7fa404004bf0, 0x7fa4040050f0, 0x7fa4040060d0, 0x7fa4040025e0, 0x7fa4040051e0, 0x7fa404002130, 0x7fa404003710, 0x7fa40401e660, 0x7fa40401ca50, 0x7fa40401e020, 0x7fa40401ceb0, 0x7fa404007f80, 0x7fa40401a5b0, 0x7fa404008520, 0x7fa404006350, 0x7fa40401c280, 0x7fa40401ad50, 0x7fa4040084d0, 0x7fa404001b40, 0x7fa40401f190, 0x7fa4040052d0, 0x7fa404003e40, 0x7fa404006850, 0x7fa40401b570, 0x7fa40401ae20, 0x7fa40401af30, 0x7fa4040078a0, 0x7fa404005f40, 0x7fa40401b110, 0x7fa404002e00, 0x7fa40401b3e0, 0x7fa404005230, 0x7fa404004fb0, 0x7fa404009600, 0x7fa4040024a0, 0x7fa40401e840, 0x7fa404001f00, 0x7fa404002590, 0x7fa40401caa0, 0x7fa40401c910, 0x7fa4040065d0, 0x7fa4040046f0, 0x7fa404004e20, 0x7fa404006170, 0x7fa40401e070, 0x7fa40401b2a0, 0x7fa404006b20, 0x7fa40401b660, 0x7fa404001a00, 0x7fa40401e1b0, 0x7fa404009230, 0x7fa40401c000, 0x7fa40401c7d0, 0x7fa404001aa0, 0x7fa40401f000, 0x7fa40401c820, 0x7fa40401b750, 0x7fa404003030, 0x7fa404003da0, 0x7fa404005000, 0x7fa404005ea0, 0x7fa404005410, 0x7fa40401caf0, 0x7fa40401e250, 0x7fa40401ddf0, 0x7fa4040082a0, 0x7fa404006a30, 0x7fa404004ab0, 0x7fa404001e10, 0x7fa404003b20, 0x7fa404006580, 0x7fa404006e50, 0x7fa404002540, 0x7fa40401b200, 0x7fa40401c140, 0x7fa404007bc0, 0x7fa404009320, 0x7fa404007fd0, 0x7fa40401b520, 0x7fa40401b950, 0x7fa40401b7a0, 0x7fa404009370, 0x7fa404003ad0, 0x7fa4040099e0, 0x7fa40401e0c0, 0x7fa40401b480, 0x7fa404005320, 0x7fa404002400, 0x7fa40401cbe0, 0x7fa404006670, 0x7fa404002450, 0x7fa40401b1b0, 0x7fa40401d850, 0x7fa404006300, 0x7fa40401de90, 0x7fa404006620, 0x7fa40401e7a0, 0x7fa40401e4d0, 0x7fa404003850, 0x7fa40401e7f0, 0x7fa404006e00, 0x7fa40401add0, 0x7fa404004970, 0x7fa404008200, 0x7fa404005050, 0x7fa40401c780, 0x7fa4040083e0, 0x7fa404002270, 0x7fa4040030d0, 0x7fa4040088f0, 0x7fa404004d80, 0x7fa40401e750, 0x7fa40401c9b0, 0x7fa404008340, 0x7fa40401aee0, 0x7fa4040035d0, 0x7fa40401c4b0, 0x7fa40401e200, 0x7fa4040037b0, 0x7fa404004a10, 0x7fa404002ef0, 0x7fa404001f50, 0x7fa40401e930, 0x7fa40401c050, 0x7fa404002220, 0x7fa40401e110, 0x7fa40401f280, 0x7fa40401ac00, 0x7fa40401db20, 0x7fa4040082f0, 0x7fa40401c190, 0x7fa4040039e0, 0x7fa40401c320, 0x7fa40401ca00, 0x7fa4040031c0, 0x7fa4040068a0, 0x7fa40401b340, 0x7fa40401df80, 0x7fa40401dc10, 0x7fa404003800, 0x7fa40401e430, 0x7fa4040064e0, 0x7fa404003210, 0x7fa4040062b0, 0x7fa404005500, 0x7fa4040081b0, 0x7fa404003cb0, 0x7fa4040053c0, 0x7fa404003bc0, 0x7fa40401c3c0, 0x7fa404003df0, 0x7fa40401f140, 0x7fa404009280, 0x7fa4040024f0, 0x7fa40401dd50, 0x7fa40401c370, 0x7fa4040063a0, 0x7fa404006ad0, 0x7fa4040036c0, 0x7fa40401d9e0, 0x7fa40401e3e0, 0x7fa4040011a0, 0x7fa404004920, 0x7fa40401c500, 0x7fa404003490, 0x7fa404003fa0, 0x7fa40401ce60, 0x7fa40401b840, 0x7fa40401c550, 0x7fa404001be0, 0x7fa404004650, 0x7fa40401b5c0...}\n    message = \"importing 1690 images\", '\\000' <repeats 490 times>\n    fraction = 0.96863905325441602\n    total = 1690\n    jid = 0x7fa40411ad00\n    cfr = 0x7fa404121830\n    image = 0x7fa40402d0a0 = {0x7fa40402cb10, 0x7fa40402e300, 0x7fa40402dcc0, 0x7fa40402e0d0, 0x7fa40402e1c0, 0x7fa40402e170, 0x7fa40402da40, 0x7fa40402dfe0, 0x7fa40402e490, 0x7fa40402dae0, 0x7fa40402ec00, 0x7fa40402dea0, 0x7fa40402e080, 0x7fa40402e350, 0x7fa404025890, 0x7fa40402ed40, 0x7fa40402d840, 0x7fa40402dd60, 0x7fa40402de50, 0x7fa40402e540, 0x7fa404027460, 0x7fa40402ec50, 0x7fa40402de00, 0x7fa40402ecf0, 0x7fa40402ca50, 0x7fa40402e030, 0x7fa40402df90, 0x7fa40402d950, 0x7fa40402db80, 0x7fa40402e440, 0x7fa40402eca0, 0x7fa40402dc70, 0x7fa40402d9f0, 0x7fa40402d9a0, 0x7fa40402e120, 0x7fa40402ed90, 0x7fa40402cca0, 0x7fa40402def0, 0x7fa40402e2b0, 0x7fa40402ede0, 0x7fa4040269c0, 0x7fa40402df40, 0x7fa40402dbd0, 0x7fa40402dc20, 0x7fa40402e260, 0x7fa40402d900, 0x7fa40402e210, 0x7fa40402da90, 0x7fa40402e3a0, 0x7fa40402e3f0, 0x7fa40402db30, 0x7fa40402ddb0, 0x7fa40402dd10}\n    dfn = 0x3b6da14f05 \"I\\211\\303L\\213L$0L\\213D$(H\\213|$ H\\213t$\\030H\\213T$\\020H\\213L$\\bH\\213\\004$H\\203\\304HA\\377\\343ffffff.\\017\\037\\204\"\n\n18 0x00007fa41a0f26ba in dt_film_import1_run (job=0x19a3300) at /home/jp/DarkTable/darktable/src/control/jobs/film_jobs.c:37\n    t = 0x19a4218\n    __FUNCTION__ = \"dt_film_import1_run\"\n\n19 0x00007fa41a0e8db8 in dt_control_run_job (s=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:961\n    j = 0x19a3300\n    bj = 0x0\n    __FUNCTION__ = \"dt_control_run_job\"\n    ts_now = 1348920954\n    jobitem = 0x0\n\n20 0x00007fa41a0e97d6 in dt_control_work (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n    s = 0x1204250\n    __FUNCTION__ = \"dt_control_work\"\n\n21 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n22 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 31 (Thread 0x7fa416aac700 (LWP 7561)):\n0  0x0000003b6debd9fd in nanosleep () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6debd89c in sleep () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x00007fa41a0e9732 in _control_worker_kicker (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1141\n    s = 0x1204250\n    __FUNCTION__ = \"_control_worker_kicker\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 30 (Thread 0x7fa4162ab700 (LWP 7562)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 0\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 29 (Thread 0x7fa415aaa700 (LWP 7563)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 1\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 28 (Thread 0x7fa4152a9700 (LWP 7564)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 2\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 27 (Thread 0x7fa414aa8700 (LWP 7565)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 3\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 26 (Thread 0x7fa4142a7700 (LWP 7566)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 4\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 25 (Thread 0x7fa3ebaa6700 (LWP 7567)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 5\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 24 (Thread 0x7fa413aa6700 (LWP 7568)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\nNo symbol table info available.\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x00007fa41a0eb340 in dt_control_gdk_lock () at /home/jp/DarkTable/darktable/src/control/control.c:1511\nNo locals.\n4  0x00007fa41a0f2a9d in dt_control_signal_raise (ctlsig=0x11a77c0, signal=DT_SIGNAL_DEVELOP_MIPMAP_UPDATED) at /home/jp/DarkTable/darktable/src/control/signal.c:111\n    extra_args = {{gp_offset = 16, fp_offset = 48, overflow_arg_area = 0x7fa413aa43b0, reg_save_area = 0x7fa413aa42e0}}\n    i_own_lock = 0\n\n5  0x00007fa41a0cdaa6 in dt_mipmap_cache_read_get (cache=0x11d8b60, buf=0x7fa413aa5a90, imgid=1025, mip=DT_MIPMAP_2, flags=DT_MIPMAP_BLOCKING) at /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:937\n    dsc = 0x7fa3bfabfe50\n    key = 1073742848\n    __PRETTY_FUNCTION__ = \"dt_mipmap_cache_read_get\"\n\n6  0x00007fa41a0edc1f in dt_control_indexer_job_run (job=0x120e130) at /home/jp/DarkTable/darktable/src/control/jobs/control_jobs.c:212\n    buf = {size = DT_MIPMAP_NONE, imgid = 1024, width = 330, height = 495, buf = 0x0}\n    buf_decompressed = 0x7fa3c0e5df60 \" 9+\"\n    idximg = 0x7fa3d8003770\n    message = \"re-indexing 201 images\", '\\000' <repeats 489 times>\n    fraction = 0.27860696517412942\n    total = 201\n    jid = 0x7fa3d8005be0\n    scratchmem = 0x0\n    images = 0x7fa3d8002240 = {0x7fa3d8000fa0, 0x7fa3d8000fc0, 0x7fa3d8000fe0, 0x7fa3d8001000, 0x7fa3d8001020, 0x7fa3d8001040, 0x7fa3d8001060, 0x7fa3d8001080, 0x7fa3d80010a0, 0x7fa3d80010c0, 0x7fa3d80010e0, 0x7fa3d8001100, 0x7fa3d8001120, 0x7fa3d8001140, 0x7fa3d8001160, 0x7fa3d8001180, 0x7fa3d80011a0, 0x7fa3d80011c0, 0x7fa3d80011e0, 0x7fa3d8001200, 0x7fa3d8001220, 0x7fa3d8001240, 0x7fa3d8001260, 0x7fa3d8001280, 0x7fa3d80012a0, 0x7fa3d80012c0, 0x7fa3d80012e0, 0x7fa3d8001300, 0x7fa3d8001320, 0x7fa3d8001340, 0x7fa3d8001360, 0x7fa3d8001380, 0x7fa3d80013a0, 0x7fa3d80013c0, 0x7fa3d80013e0, 0x7fa3d8001400, 0x7fa3d8001420, 0x7fa3d8001440, 0x7fa3d8001460, 0x7fa3d8001480, 0x7fa3d80014a0, 0x7fa3d80014c0, 0x7fa3d80014e0, 0x7fa3d8001500, 0x7fa3d8001520, 0x7fa3d8001540, 0x7fa3d80021d0, 0x7fa3d8001560, 0x7fa3d8001580, 0x7fa3d80015a0, 0x7fa3d80015c0, 0x7fa3d80015e0, 0x7fa3d80036f0, 0x7fa3d8003710, 0x7fa3d8003730, 0x7fa3d8003750, 0x7fa3d8003770, 0x7fa3d8003790, 0x7fa3d80037b0, 0x7fa3d80037d0, 0x7fa3d8001800, 0x7fa3d8001820, 0x7fa3d8001840, 0x7fa3d8001860, 0x7fa3d8001880, 0x7fa3d80018a0, 0x7fa3d80018c0, 0x7fa3d80018e0, 0x7fa3d8001900, 0x7fa3d8001920, 0x7fa3d8001940, 0x7fa3d8001960, 0x7fa3d8001980, 0x7fa3d80019a0, 0x7fa3d8003e00, 0x7fa3d8003e20, 0x7fa3d8003e40, 0x7fa3d8003e60, 0x7fa3d8003e80, 0x7fa3d8003ea0, 0x7fa3d8003ec0, 0x7fa3d8003ee0, 0x7fa3d8003f00, 0x7fa3d8003f20, 0x7fa3d8003f40, 0x7fa3d8003f60, 0x7fa3d8003f80, 0x7fa3d8003fa0, 0x7fa3d8003fc0, 0x7fa3d8003fe0, 0x7fa3d8004000, 0x7fa3d8004020, 0x7fa3d8004040, 0x7fa3d8004060, 0x7fa3d8004080, 0x7fa3d80040a0, 0x7fa3d80040c0, 0x7fa3d80040e0, 0x7fa3d8004100, 0x7fa3d8004120, 0x7fa3d8004140, 0x7fa3d8004160, 0x7fa3d8004180, 0x7fa3d80041a0, 0x7fa3d80041c0, 0x7fa3d80041e0, 0x7fa3d8004a00, 0x7fa3d8004a20, 0x7fa3d8004a40, 0x7fa3d8004a60, 0x7fa3d8004a80, 0x7fa3d8004aa0, 0x7fa3d8004ac0, 0x7fa3d8004ae0, 0x7fa3d8004b00, 0x7fa3d8004b20, 0x7fa3d8004b40, 0x7fa3d8004b60, 0x7fa3d8004b80, 0x7fa3d8004ba0, 0x7fa3d8004bc0, 0x7fa3d8004be0, 0x7fa3d8004c00, 0x7fa3d8004c20, 0x7fa3d8004c40, 0x7fa3d8004c60, 0x7fa3d8004c80, 0x7fa3d8004ca0, 0x7fa3d8004cc0, 0x7fa3d8004ce0, 0x7fa3d8004d00, 0x7fa3d8004d20, 0x7fa3d8004d40, 0x7fa3d8004d60, 0x7fa3d8004d80, 0x7fa3d8004da0, 0x7fa3d8004dc0, 0x7fa3d8004de0, 0x7fa3d8004e00, 0x7fa3d8004e20, 0x7fa3d8004e40, 0x7fa3d8004e60, 0x7fa3d8004e80, 0x7fa3d8004ea0, 0x7fa3d8004ec0, 0x7fa3d8004ee0, 0x7fa3d8004f00, 0x7fa3d8004f20, 0x7fa3d8004f40, 0x7fa3d8004f60, 0x7fa3d8004f80, 0x7fa3d8004fa0, 0x7fa3d8004fc0, 0x7fa3d8004fe0, 0x7fa3d8005600, 0x7fa3d8005620, 0x7fa3d8005640, 0x7fa3d8005660, 0x7fa3d8005680, 0x7fa3d80056a0, 0x7fa3d80056c0, 0x7fa3d80056e0, 0x7fa3d8005700, 0x7fa3d8005720, 0x7fa3d8005740, 0x7fa3d8005760, 0x7fa3d8005780, 0x7fa3d80057a0, 0x7fa3d80057c0, 0x7fa3d80057e0, 0x7fa3d8005800, 0x7fa3d8005820, 0x7fa3d8005840, 0x7fa3d8005860, 0x7fa3d8005880, 0x7fa3d80058a0, 0x7fa3d80058c0, 0x7fa3d80058e0, 0x7fa3d8005900, 0x7fa3d8005920, 0x7fa3d8005940, 0x7fa3d8005960, 0x7fa3d8005980, 0x7fa3d80059a0, 0x7fa3d80059c0, 0x7fa3d80059e0, 0x7fa3d8005a00, 0x7fa3d8005a20, 0x7fa3d8005a40, 0x7fa3d8005a60, 0x7fa3d8005a80, 0x7fa3d8005aa0, 0x7fa3d8005ac0, 0x7fa3d8005ae0, 0x7fa3d8005b00, 0x7fa3d8005b20, 0x7fa3d8005b40, 0x7fa3d8005b60, 0x7fa3d8005b80, 0x7fa3d8005ba0...}\n    stmt = 0x7fa3d8002d68\n    __FUNCTION__ = \"dt_control_indexer_job_run\"\n    __PRETTY_FUNCTION__ = \"dt_control_indexer_job_run\"\n    imgitem = 0x7fa3d8001720 = {0x7fa3d8003770, 0x7fa3d8003790, 0x7fa3d80037b0, 0x7fa3d80037d0, 0x7fa3d8001800, 0x7fa3d8001820, 0x7fa3d8001840, 0x7fa3d8001860, 0x7fa3d8001880, 0x7fa3d80018a0, 0x7fa3d80018c0, 0x7fa3d80018e0, 0x7fa3d8001900, 0x7fa3d8001920, 0x7fa3d8001940, 0x7fa3d8001960, 0x7fa3d8001980, 0x7fa3d80019a0, 0x7fa3d8003e00, 0x7fa3d8003e20, 0x7fa3d8003e40, 0x7fa3d8003e60, 0x7fa3d8003e80, 0x7fa3d8003ea0, 0x7fa3d8003ec0, 0x7fa3d8003ee0, 0x7fa3d8003f00, 0x7fa3d8003f20, 0x7fa3d8003f40, 0x7fa3d8003f60, 0x7fa3d8003f80, 0x7fa3d8003fa0, 0x7fa3d8003fc0, 0x7fa3d8003fe0, 0x7fa3d8004000, 0x7fa3d8004020, 0x7fa3d8004040, 0x7fa3d8004060, 0x7fa3d8004080, 0x7fa3d80040a0, 0x7fa3d80040c0, 0x7fa3d80040e0, 0x7fa3d8004100, 0x7fa3d8004120, 0x7fa3d8004140, 0x7fa3d8004160, 0x7fa3d8004180, 0x7fa3d80041a0, 0x7fa3d80041c0, 0x7fa3d80041e0, 0x7fa3d8004a00, 0x7fa3d8004a20, 0x7fa3d8004a40, 0x7fa3d8004a60, 0x7fa3d8004a80, 0x7fa3d8004aa0, 0x7fa3d8004ac0, 0x7fa3d8004ae0, 0x7fa3d8004b00, 0x7fa3d8004b20, 0x7fa3d8004b40, 0x7fa3d8004b60, 0x7fa3d8004b80, 0x7fa3d8004ba0, 0x7fa3d8004bc0, 0x7fa3d8004be0, 0x7fa3d8004c00, 0x7fa3d8004c20, 0x7fa3d8004c40, 0x7fa3d8004c60, 0x7fa3d8004c80, 0x7fa3d8004ca0, 0x7fa3d8004cc0, 0x7fa3d8004ce0, 0x7fa3d8004d00, 0x7fa3d8004d20, 0x7fa3d8004d40, 0x7fa3d8004d60, 0x7fa3d8004d80, 0x7fa3d8004da0, 0x7fa3d8004dc0, 0x7fa3d8004de0, 0x7fa3d8004e00, 0x7fa3d8004e20, 0x7fa3d8004e40, 0x7fa3d8004e60, 0x7fa3d8004e80, 0x7fa3d8004ea0, 0x7fa3d8004ec0, 0x7fa3d8004ee0, 0x7fa3d8004f00, 0x7fa3d8004f20, 0x7fa3d8004f40, 0x7fa3d8004f60, 0x7fa3d8004f80, 0x7fa3d8004fa0, 0x7fa3d8004fc0, 0x7fa3d8004fe0, 0x7fa3d8005600, 0x7fa3d8005620, 0x7fa3d8005640, 0x7fa3d8005660, 0x7fa3d8005680, 0x7fa3d80056a0, 0x7fa3d80056c0, 0x7fa3d80056e0, 0x7fa3d8005700, 0x7fa3d8005720, 0x7fa3d8005740, 0x7fa3d8005760, 0x7fa3d8005780, 0x7fa3d80057a0, 0x7fa3d80057c0, 0x7fa3d80057e0, 0x7fa3d8005800, 0x7fa3d8005820, 0x7fa3d8005840, 0x7fa3d8005860, 0x7fa3d8005880, 0x7fa3d80058a0, 0x7fa3d80058c0, 0x7fa3d80058e0, 0x7fa3d8005900, 0x7fa3d8005920, 0x7fa3d8005940, 0x7fa3d8005960, 0x7fa3d8005980, 0x7fa3d80059a0, 0x7fa3d80059c0, 0x7fa3d80059e0, 0x7fa3d8005a00, 0x7fa3d8005a20, 0x7fa3d8005a40, 0x7fa3d8005a60, 0x7fa3d8005a80, 0x7fa3d8005aa0, 0x7fa3d8005ac0, 0x7fa3d8005ae0, 0x7fa3d8005b00, 0x7fa3d8005b20, 0x7fa3d8005b40, 0x7fa3d8005b60, 0x7fa3d8005b80, 0x7fa3d8005ba0, 0x7fa3d8005bc0}\n\n7  0x00007fa41a0e8a78 in dt_control_run_job_res (s=0x1204250, res=6) at /home/jp/DarkTable/darktable/src/control/control.c:883\n    __PRETTY_FUNCTION__ = \"dt_control_run_job_res\"\n    j = 0x120e130\n    __FUNCTION__ = \"dt_control_run_job_res\"\n\n8  0x00007fa41a0e9667 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1122\n    s = 0x1204250\n    threadid = 6\n    __FUNCTION__ = \"dt_control_work_res\"\n\n9  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n10 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 23 (Thread 0x7fa4132a5700 (LWP 7569)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007fa41a0e4631 in dt_pthread_cond_wait (cond=0x1207d50, mutex=0x1206e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007fa41a0e96c5 in dt_control_work_res (ptr=0x1204250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1204250\n    threadid = 7\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 22 (Thread 0x7fa3869b1700 (LWP 7574)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 21 (Thread 0x7fa3861b0700 (LWP 7575)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 20 (Thread 0x7fa3859af700 (LWP 7576)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 19 (Thread 0x7fa3851ae700 (LWP 7577)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 18 (Thread 0x7fa3849ad700 (LWP 7578)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 17 (Thread 0x7fa3841ac700 (LWP 7579)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 16 (Thread 0x7fa3839ab700 (LWP 7580)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 15 (Thread 0x7fa38a07b700 (LWP 7589)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 14 (Thread 0x7fa38a87c700 (LWP 7590)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 13 (Thread 0x7fa38b07d700 (LWP 7591)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 12 (Thread 0x7fa38b87e700 (LWP 7592)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 11 (Thread 0x7fa3831aa700 (LWP 7593)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 10 (Thread 0x7fa3829a9700 (LWP 7594)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 9 (Thread 0x7fa3821a8700 (LWP 7595)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 8 (Thread 0x7fa3819a7700 (LWP 7615)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 7 (Thread 0x7fa38c737700 (LWP 7616)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 6 (Thread 0x7fa38cf38700 (LWP 7617)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 5 (Thread 0x7fa38d739700 (LWP 7618)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 4 (Thread 0x7fa38ef3c700 (LWP 7619)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 3 (Thread 0x7fa38e73b700 (LWP 7620)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 2 (Thread 0x7fa38df3a700 (LWP 7621)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 1 (Thread 0x7fa41865ca00 (LWP 7558)):\n0  0x0000003b6dee8803 in poll () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6fe45448 in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n2  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n3  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n4  0x00007fa41a141361 in dt_gui_gtk_run (gui=0x12294d0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n    widget = 0x13704f0\n    tb = 8\n\n5  0x0000000000400a66 in main (argc=1, argv=0x7fff55ad74a8) at /home/jp/DarkTable/darktable/src/main.c:25\nNo locals.\n```\n. Switch to folders, then do import:\n```\nThread 53 (Thread 0x7fff77621700 (LWP 7873)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 52 (Thread 0x7fff78623700 (LWP 7872)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 51 (Thread 0x7fff78e24700 (LWP 7871)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 50 (Thread 0x7fff69e96700 (LWP 7870)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 49 (Thread 0x7fff60bc8700 (LWP 7869)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 48 (Thread 0x7fff603c7700 (LWP 7868)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 47 (Thread 0x7fff5fbc6700 (LWP 7867)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 37 (Thread 0x7fff77e22700 (LWP 7857)):\n0  0x0000003b6ea0be4f in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x0000003b71202445 in ?? () from /lib64/libgthread-2.0.so.0\n2  0x0000003b6fe196ff in ?? () from /lib64/libglib-2.0.so.0\n3  0x0000003b6fe19f51 in g_async_queue_timed_pop () from /lib64/libglib-2.0.so.0\n4  0x0000003b6fe6cb27 in ?? () from /lib64/libglib-2.0.so.0\n5  0x0000003b6fe6a6e6 in ?? () from /lib64/libglib-2.0.so.0\n6  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n7  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 34 (Thread 0x7fff79839700 (LWP 7854)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 33 (Thread 0x7fff7a03a700 (LWP 7853)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 32 (Thread 0x7fff7a83b700 (LWP 7852)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 31 (Thread 0x7fff68eb5700 (LWP 7851)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 30 (Thread 0x7fff686b4700 (LWP 7850)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 29 (Thread 0x7fff67eb3700 (LWP 7849)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 28 (Thread 0x7fff676b2700 (LWP 7848)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 19 (Thread 0x7fff613c9700 (LWP 7839)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 18 (Thread 0x7fff61bca700 (LWP 7838)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 17 (Thread 0x7fff623cb700 (LWP 7837)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 16 (Thread 0x7fff62bcc700 (LWP 7836)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 15 (Thread 0x7fff633cd700 (LWP 7835)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 14 (Thread 0x7fff63bce700 (LWP 7834)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 13 (Thread 0x7fff643cf700 (LWP 7833)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 12 (Thread 0x7fffe77fe700 (LWP 7829)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 11 (Thread 0x7fffecff9700 (LWP 7828)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\n3  0x00007ffff7c2b340 in dt_control_gdk_lock () at /home/jp/DarkTable/darktable/src/control/control.c:1511\n4  0x00007ffff7c32a9d in dt_control_signal_raise (ctlsig=0x6117c0, signal=DT_SIGNAL_DEVELOP_MIPMAP_UPDATED) at /home/jp/DarkTable/darktable/src/control/signal.c:111\n5  0x00007ffff7c0daa6 in dt_mipmap_cache_read_get (cache=0x642b60, buf=0x7fffecff8a90, imgid=1074, mip=DT_MIPMAP_2, flags=DT_MIPMAP_BLOCKING)\nat /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:937\n\n6  0x00007ffff7c2dc1f in dt_control_indexer_job_run (job=0x678130) at /home/jp/DarkTable/darktable/src/control/jobs/control_jobs.c:212\n7  0x00007ffff7c28a78 in dt_control_run_job_res (s=0x66e250, res=6) at /home/jp/DarkTable/darktable/src/control/control.c:883\n8  0x00007ffff7c29667 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1122\n9  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n10 0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 10 (Thread 0x7fffed7fa700 (LWP 7827)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 9 (Thread 0x7fffedffb700 (LWP 7826)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 8 (Thread 0x7fffee7fc700 (LWP 7825)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 7 (Thread 0x7fffeeffd700 (LWP 7824)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 6 (Thread 0x7fffef7fe700 (LWP 7823)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 5 (Thread 0x7fffeffff700 (LWP 7822)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\n1  0x00007ffff7c24631 in dt_pthread_cond_wait (cond=0x671d50, mutex=0x670e70) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\n2  0x00007ffff7c296c5 in dt_control_work_res (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 4 (Thread 0x7fffe7fff700 (LWP 7821)):\n0  0x0000003b6debd9fd in nanosleep () from /lib64/libc.so.6\n1  0x0000003b6debd89c in sleep () from /lib64/libc.so.6\n2  0x00007ffff7c29732 in _control_worker_kicker (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1141\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 3 (Thread 0x7ffff4ded700 (LWP 7820)):\n0  0x00007ffff7d2fffa in RawSpeed::LJpegDecompressor::HuffDecode (this=0x7ffff4dd45f0, htbl=0x7ffff4dd4fa0)\nat /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/LJpegDecompressor.cpp:618\n\n1  0x00007ffff7d32bbb in RawSpeed::LJpegPlain::decodeScanLeft2Comps (this=0x7ffff4dd45f0)\nat /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/LJpegPlain.cpp:572\n\n2  0x00007ffff7d30b5b in RawSpeed::LJpegPlain::decodeScan (this=0x7ffff4dd45f0) at /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/LJpegPlain.cpp:92\n3  0x00007ffff7d2f33b in RawSpeed::LJpegDecompressor::parseSOS (this=0x7ffff4dd45f0)\nat /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/LJpegDecompressor.cpp:281\n\n4  0x00007ffff7d2edbd in RawSpeed::LJpegDecompressor::startDecoder (this=0x7ffff4dd45f0, offset=4327744, size=22982450, offsetX=0, offsetY=0)\nat /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/LJpegDecompressor.cpp:166\n\n5  0x00007ffff7d20900 in RawSpeed::Cr2Decoder::decodeRawInternal (this=0x7fffe8004a20)\nat /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/Cr2Decoder.cpp:118\n\n6  0x00007ffff7d09faf in RawSpeed::RawDecoder::decodeRaw (this=0x7fffe8004a20) at /home/jp/DarkTable/darktable/src/external/rawspeed/RawSpeed/RawDecoder.cpp:301\n7  0x00007ffff7c02859 in dt_imageio_open_rawspeed (img=0x7ffff4dd8a70, filename=0x7ffff4dd79d0 \"/home/jp/Pictures/Hawaii/20120818/212C7220.CR2\", a=0x7ffff4dd8c58)\nat /home/jp/DarkTable/darktable/src/common/imageio_rawspeed.cc:121\n\n8  0x00007ffff7bfb334 in dt_imageio_open (img=0x7ffff4dd8a70, filename=0x7ffff4dd79d0 \"/home/jp/Pictures/Hawaii/20120818/212C7220.CR2\", a=0x7ffff4dd8c58)\nat /home/jp/DarkTable/darktable/src/common/imageio.c:705\n\n9  0x00007ffff7c0d7a6 in dt_mipmap_cache_read_get (cache=0x642b60, buf=0x7ffff4dea2d0, imgid=978, mip=DT_MIPMAP_FULL, flags=DT_MIPMAP_BLOCKING)\nat /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:874\n\n10 0x00007ffff7bfa5e6 in dt_imageio_export_with_flags (imgid=978, filename=0x7ffff7d53cb3 \"unused\", format=0x7ffff4deae90, format_params=0x7ffff4deb380, ignore_exif=\n1, display_byteorder=1, high_quality=0, thumbnail_export=1) at /home/jp/DarkTable/darktable/src/common/imageio.c:486\n\n11 0x00007ffff7c0e9f4 in _init_8 (buf=0x7fff9fc10730 \"\", width=0x7fff9fc10720, height=0x7fff9fc10724, imgid=978, size=DT_MIPMAP_0)\nat /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:1274\n\n12 0x00007ffff7c0da48 in dt_mipmap_cache_read_get (cache=0x642b60, buf=0x7ffff4decb30, imgid=978, mip=DT_MIPMAP_0, flags=DT_MIPMAP_BLOCKING)\nat /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:930\n\n13 0x00007ffff7c327ff in dt_image_load_job_run (job=0xe8f660) at /home/jp/DarkTable/darktable/src/control/jobs/image_jobs.c:38\n14 0x00007ffff7c28db8 in dt_control_run_job (s=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:961\n15 0x00007ffff7c297d6 in dt_control_work (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n16 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n17 0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 2 (Thread 0x7ffff55ee700 (LWP 7819)):\n0  0x00007fff6d51cb94 in filmrolls_updated (instance=0x607a80, self=0xf7ff9188) at /home/jp/DarkTable/darktable/src/libs/collect.c:1542\n1  0x0000003b71a05d64 in ffi_call_unix64 () from /usr/lib64/libffi.so.5\n2  0x0000003b71a05785 in ffi_call () from /usr/lib64/libffi.so.5\n3  0x0000003b71e0ef6b in g_cclosure_marshal_generic () from /lib64/libgobject-2.0.so.0\n4  0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n5  0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\n6  0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n7  0x00007ffff7c32b07 in dt_control_signal_raise (ctlsig=0x6117c0, signal=DT_SIGNAL_FILMROLLS_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:113\n8  0x00007ffff7be71c6 in dt_film_import1 (film=0xe82000) at /home/jp/DarkTable/darktable/src/common/film.c:493\n9  0x00007ffff7c326ba in dt_film_import1_run (job=0xe829a0) at /home/jp/DarkTable/darktable/src/control/jobs/film_jobs.c:37\n10 0x00007ffff7c28db8 in dt_control_run_job (s=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:961\n11 0x00007ffff7c297d6 in dt_control_work (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n12 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\n13 0x0000003b6def119d in clone () from /lib64/libc.so.6\nThread 1 (Thread 0x7ffff619ca00 (LWP 7816)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\n3  0x0000003723e5ee72 in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\n4  0x0000003b6fe44c14 in g_main_context_check () from /lib64/libglib-2.0.so.0\n5  0x0000003b6fe45462 in ?? () from /lib64/libglib-2.0.so.0\n6  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n7  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n8  0x00007ffff7c81361 in dt_gui_gtk_run (gui=0x6934d0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n9  0x0000000000400a66 in main (argc=1, argv=0x7fffffffdbd8) at /home/jp/DarkTable/darktable/src/main.c:25\n0  0x00007fff6d51cb94 in filmrolls_updated (instance=0x607a80, self=0xf7ff9188) at /home/jp/DarkTable/darktable/src/libs/collect.c:1542\n    dm = 0xf7ff9188\n    d = 0x3b7011f800\n\n1  0x0000003b71a05d64 in ffi_call_unix64 () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n2  0x0000003b71a05785 in ffi_call () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n3  0x0000003b71e0ef6b in g_cclosure_marshal_generic () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n4  0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n5  0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n6  0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n7  0x00007ffff7c32b07 in dt_control_signal_raise (ctlsig=0x6117c0, signal=DT_SIGNAL_FILMROLLS_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:113\n    extra_args = {{gp_offset = 24, fp_offset = 48, overflow_arg_area = 0x7ffff55ed8b0, reg_save_area = 0x7ffff55ed7e0}}\n    i_own_lock = 1\n\n8  0x00007ffff7be71c6 in dt_film_import1 (film=0xe82000) at /home/jp/DarkTable/darktable/src/common/film.c:493\n    recursive = 1\n    images = 0x985120 = {0x7ffff0003140, 0x7ffff0015e10, 0x7ffff0002a60, 0x7ffff0016360, 0x7ffff0007140, 0x7ffff00023d0, 0x7ffff00147f0, 0x7ffff00036e0, \n0x7ffff0003cd0, 0x7ffff0004fe0, 0x7ffff0008580, 0x7ffff0001130, 0x7ffff00030a0, 0x7ffff0012f90, 0x7ffff0006ec0, 0x7ffff00044f0, 0x7ffff0002fb0, 0x7ffff0015c80, \n0x7ffff0007230, 0x7ffff0005ad0, 0x7ffff0015f50, 0x7ffff00033c0, 0x7ffff00149d0, 0x7ffff0015af0, 0x7ffff0014d90, 0x7ffff00032d0, 0x7ffff0005b20, 0x7ffff00058f0, \n0x7ffff0001a60, 0x7ffff00056c0, 0x7ffff0007370, 0x7ffff0003c30, 0x7ffff0006a10, 0x7ffff0003780, 0x7ffff0004e00, 0x7ffff0015ff0, 0x7ffff0014520, 0x7ffff00151a0, \n0x7ffff0014930, 0x7ffff0003ed0, 0x7ffff00084e0, 0x7ffff0002ec0, 0x7ffff0005490, 0x7ffff0013760, 0x7ffff0014a70, 0x7ffff0002e70, 0x7ffff0003190, 0x7ffff0016540, \n0x7ffff0006b00, 0x7ffff0005620, 0x7ffff0008210, 0x7ffff0013080, 0x7ffff0016220, 0x7ffff0013490, 0x7ffff0006e70, 0x7ffff0007190, 0x7ffff0008620, 0x7ffff0003e10, \n0x7ffff0012f40, 0x7ffff0006a60, 0x7ffff00067e0, 0x7ffff00055d0, 0x7ffff0003af0, 0x7ffff0016180, 0x7ffff0003550, 0x7ffff0003be0, 0x7ffff0014570, 0x7ffff0014430, \n0x7ffff0007f90, 0x7ffff00059e0, 0x7ffff0006920, 0x7ffff0007410, 0x7ffff0015a00, 0x7ffff0012e50, 0x7ffff0006650, 0x7ffff0013170, 0x7ffff0003050, 0x7ffff0015b40, \n0x7ffff0005760, 0x7ffff00134e0, 0x7ffff00142f0, 0x7ffff00030f0, 0x7ffff00163b0, 0x7ffff0014340, 0x7ffff0013260, 0x7ffff0004040, 0x7ffff0001a00, 0x7ffff0006830, \n0x7ffff00070f0, 0x7ffff0006c40, 0x7ffff00145c0, 0x7ffff0015be0, 0x7ffff0014fc0, 0x7ffff0002c40, 0x7ffff00083f0, 0x7ffff0005da0, 0x7ffff0003460, 0x7ffff0006ce0, \n0x7ffff0007f40, 0x7ffff0005f80, 0x7ffff0003b90, 0x7ffff0012e00, 0x7ffff0013620, 0x7ffff0002560, 0x7ffff0005850, 0x7ffff0002970, 0x7ffff00133a0, 0x7ffff0014a20, \n0x7ffff00132b0, 0x7ffff00058a0, 0x7ffff00051c0, 0x7ffff0002380, 0x7ffff0015a50, 0x7ffff0012fe0, 0x7ffff0006b50, 0x7ffff0003a50, 0x7ffff00146b0, 0x7ffff0008030, \n0x7ffff0003aa0, 0x7ffff00086c0, 0x7ffff0014ac0, 0x7ffff0005440, 0x7ffff0015060, 0x7ffff0007fe0, 0x7ffff00160e0, 0x7ffff0015e60, 0x7ffff0004f40, 0x7ffff0016130, \n0x7ffff0005210, 0x7ffff00133f0, 0x7ffff0005c60, 0x7ffff0002ba0, 0x7ffff0006bf0, 0x7ffff00142a0, 0x7ffff0002d80, 0x7ffff00038c0, 0x7ffff00040e0, 0x7ffff0005990, \n0x7ffff0005f30, 0x7ffff0016090, 0x7ffff0014480, 0x7ffff0002ce0, 0x7ffff0013440, 0x7ffff0001c70, 0x7ffff0013990, 0x7ffff0015b90, 0x7ffff0004ea0, 0x7ffff0005d00, \n0x7ffff0004590, 0x7ffff00035a0, 0x7ffff0016310, 0x7ffff0013530, 0x7ffff0003870, 0x7ffff0015aa0, 0x7ffff0016630, 0x7ffff0012590, 0x7ffff0014d40, 0x7ffff0002c90, \n0x7ffff0013670, 0x7ffff00050d0, 0x7ffff0013800, 0x7ffff00144d0, 0x7ffff00041d0, 0x7ffff0008260, 0x7ffff0012ef0, 0x7ffff0015100, 0x7ffff0014de0, 0x7ffff0004ef0, \n0x7ffff0015dc0, 0x7ffff0007ea0, 0x7ffff0004220, 0x7ffff0001db0, 0x7ffff0006f10, 0x7ffff0002b50, 0x7ffff00053a0, 0x7ffff0007570, 0x7ffff00052b0, 0x7ffff00138a0, \n0x7ffff00054e0, 0x7ffff00164f0, 0x7ffff00057b0, 0x7ffff0003b40, 0x7ffff0014f20, 0x7ffff0013850, 0x7ffff0002200, 0x7ffff0008530, 0x7ffff0001d60, 0x7ffff0014c50, \n0x7ffff0015d70, 0x7ffff00088f0, 0x7ffff0005c10, 0x7ffff00139e0, 0x7ffff00044a0, 0x7ffff0006d30, 0x7ffff00148e0, 0x7ffff0013350, 0x7ffff0013a30, 0x7ffff0003230, \n0x7ffff0005940, 0x7ffff00130d0...}\n    message = \"importing 402 images\", '\\000' <repeats 491 times>\n\n---Type  to continue, or q  to quit---\n        fraction = 1.0000000000000071\n        total = 402\n        jid = 0x7ffff003cbc0\n        cfr = 0xe82000\n        image = 0x0\n        dfn = 0x3b6da14f05 \"I\\211\\303L\\213L$0L\\213D$(H\\213|$ H\\213t$\\030H\\213T$\\020H\\213L$\\bH\\213\\004$H\\203\\304HA\\377\\343ffffff.\\017\\037\\204\"\n9  0x00007ffff7c326ba in dt_film_import1_run (job=0xe829a0) at /home/jp/DarkTable/darktable/src/control/jobs/film_jobs.c:37\n    t = 0xe838b8\n    __FUNCTION__ = \"dt_film_import1_run\"\n\n10 0x00007ffff7c28db8 in dt_control_run_job (s=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:961\n    j = 0xe829a0\n    bj = 0x0\n    __FUNCTION__ = \"dt_control_run_job\"\n    ts_now = 1348921314\n    jobitem = 0x0\n\n11 0x00007ffff7c297d6 in dt_control_work (ptr=0x66e250) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n    s = 0x66e250\n    __FUNCTION__ = \"dt_control_work\"\n\n12 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n13 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\n```\n. Tried - same result:\n```\ndiff --git a/src/control/signal.c b/src/control/signal.c\nindex c433dd6..b8ceb58 100644\n--- a/src/control/signal.c\n+++ b/src/control/signal.c\n@@ -56,7 +56,7 @@ static dt_signal_description _signal_description[DT_SIGNAL_COUNT] =\n{\"dt-collection-changed\",NULL,NULL,G_TYPE_NONE,g_cclosure_marshal_VOID__VOID,0,NULL},                   // DT_SIGNAL_COLLECTION_CHANGED\n\n{\"dt-filmrolls-changed\"},                         // DT_SIGNAL_FILMROLLS_CHANGED\n{\"dt-filmrolls-changed\",NULL,NULL,G_TYPE_NONE,g_cclosure_marshal_VOID__VOID,0,NULL},                         // DT_SIGNAL_FILMROLLS_CHANGED\n\n/ Develop related signals /\n   {\"dt-develop-initialized\",NULL,NULL,G_TYPE_NONE,g_cclosure_marshal_VOID__VOID,0,NULL},                  // DT_SIGNAL_DEVELOP_INITIALIZED\n```\n. Inside folders - right-click - \"remove\":\nthis is darktable 1.0+1771~g36c3dd9 reporting a segfault:\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n[New Thread 0x7f0885d77700 (LWP 7360)]\n[New Thread 0x7f0886578700 (LWP 7359)]\n[New Thread 0x7f0886d79700 (LWP 7358)]\n[New Thread 0x7f087946f700 (LWP 7357)]\n[New Thread 0x7f0878c6e700 (LWP 7356)]\n[New Thread 0x7f087846d700 (LWP 7355)]\n[New Thread 0x7f0877c6c700 (LWP 7354)]\n[New Thread 0x7f0871175700 (LWP 7345)]\n[New Thread 0x7f0871976700 (LWP 7344)]\n[New Thread 0x7f0872177700 (LWP 7343)]\n[New Thread 0x7f0872978700 (LWP 7342)]\n[New Thread 0x7f0873179700 (LWP 7341)]\n[New Thread 0x7f087397a700 (LWP 7340)]\n[New Thread 0x7f087417b700 (LWP 7339)]\n[New Thread 0x7f08fbfff700 (LWP 7334)]\n[New Thread 0x7f0900b06700 (LWP 7333)]\n[New Thread 0x7f0901307700 (LWP 7332)]\n[New Thread 0x7f0901b08700 (LWP 7331)]\n[New Thread 0x7f08ebfff700 (LWP 7330)]\n[New Thread 0x7f0902309700 (LWP 7329)]\n[New Thread 0x7f0902b0a700 (LWP 7328)]\n[New Thread 0x7f090330b700 (LWP 7327)]\n[New Thread 0x7f0903b0c700 (LWP 7326)]\n[New Thread 0x7f090430d700 (LWP 7325)]\n[New Thread 0x7f0904b0e700 (LWP 7324)]\n0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\n3  0x0000003723e5ee72 in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\n4  0x0000003b6fe44c14 in g_main_context_check () from /lib64/libglib-2.0.so.0\n5  0x0000003b6fe45462 in ?? () from /lib64/libglib-2.0.so.0\n6  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n7  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n8  0x00007f09072013b1 in dt_gui_gtk_run (gui=0x214d490) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n9  0x0000000000400a66 in main (argc=1, argv=0x7fff7660f908) at /home/jp/DarkTable/darktable/src/main.c:25\nThread 26 (Thread 0x7f0904b0e700 (LWP 7324)):\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\nNo symbol table info available.\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\nNo symbol table info available.\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\nNo symbol table info available.\n5  0x00007f090714f298 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n    read_something = 0\n    fd = 0x7f08fc003ce0\n    buf = \"\\000\\314\\000\\374\\b\\177\\000\\000\\060\\272\\260\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\u0522\\004!7\\000\\000\\000p\\271\\260\\004\\t\\177\\000\\000w\\000\\000\\000|\", '\\000' <repeats 23 times>, \"\\001\\000\\000\\000\\061\", '\\000' <repeats 11 times>, \"\\r\\000\\000\\000\\001\\000\\000\\000\\020\\000\\000\\000x\\262\\260\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\001\", '\\000' <repeats 15 times>, \"\\001\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\377\\377\\377\\177\", '\\000' <repeats 122 times>\"\\360, ?p\\263\\260\\004\\t\\177\\000\\000\\200\\265\\260\\004\\t\\177\\000\\000\\200\\265\\260\\004\\t\\177\\000\\000\\000\\000\\000\\000\\t\\177\\000\\000\\360\\265\\260\\004\\t\\177\\000\\000\\001\\000\\000\\000\\r\\000\\000\\000\\000\\000\\000\\000\\020\\000\\000\\000h\\263\\260\\004\\t\\177\\000\\000\\344\\a\\347m;\\000\\000\\000\\001\\200\\255\\373\\000\\000\\360?\\200\\265\\260\\004\\t\\177\"...\n    name_used = 0x7f08fc010320 \"/tmp/darktable_bt_D9WBLW.txt\"\n    fout = 20\n    delete_file = 0\n    datadir = \"/usr/local/packages/darktable-1.1-20121001-jose/share/darktable\\000\\000\\270\\260\\004\\t\\177\\000\\000\\030{_!7\\000\\000\\000P\\272\\260\\004\\t\\177\\000\\000P\\003\\003!7\", '\\000' <repeats 19 times>\"\\336, \\005\\000\\000\\006\\000\\000\\000$\\016\\000\\000\\000\\000\\270B\\360\\233Nr;\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\\\362\\377\\377\\\\362\\377\\377\\244\\016\\000\\000\\244\\016\\000\\000\\300\\n\\037\\000\\306H,@\\257\\266\\001!7\\000\\000\\000\\360\\267\\260\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\310{_!7\\000\\000\\000\\060\\277\\001!7\", '\\000' <repeats 11 times>\"\\310, {_!7\\000\\000\\000\\360\\265\\260\\004\\t\\177\\000\\000\\030{_!7\\000\\000\\000\"...\n    command = 0x7f08fc003e20 \"gdb darktable 7323 -batch -x /usr/local/packages/darktable-1.1-20121001-jose/share/darktable/gdb_commands\"\n\n6  \nNo symbol table info available.\n7  0x00007f087fcd4b88 in get_collect (r=0x5ddb7e18) at /home/jp/DarkTable/darktable/src/libs/collect.c:935\n    d = 0x3b89855579\n\n8  0x00007f087fcd4bd7 in changed_callback (entry=0x0, dr=0x5ddb7e18) at /home/jp/DarkTable/darktable/src/libs/collect.c:943\n    d = 0x25b34e0\n    stmt = 0x7f0904b0d020\n    iter = {stamp = 4, user_data = 0x3000000000, user_data2 = 0x7f09ffffffff, user_data3 = 0x7f0904b0cd50}\n    tree = 0x7f08fc0102e0\n    view = 0x7f08fc010140\n    listmodel = 0x26e9540\n    treemodel = 0x0\n    query = \"\\257\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\001\\000\\000\\000\\004\", '\\000' <repeats 15 times>\"\\257, \\000\\000\\000\\000\\000\\000\\000i\\025\\341q;\\000\\000\\000\\260\\325h\\002\\000\\000\\000\\000\\322\\v\\346o;\", '\\000' <repeats 11 times>\"\\322, \\v\\346o;\", '\\000' <repeats 11 times>, \" \\000\\000\\000\\000\\000\\000\\000\\200\\240\\350\\001\\000\\000\\000\\000P\\000\\000\\000\\000\\000\\000\\000h\\307w\\002\\000\\000\\000\\000h\\307w\\002\\000\\000\\000\\000h\\307w\\002\\000\\000\\000\\000\\320LR\\002\\000\\000\\000\\000\\070\u02f0\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\262\\241\\342q;\\000\\000\\000\\360\\356\\343q;\\000\\000\\000P\\307w\\002\\000\\000\\000\\000\\002\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\070\\307w\\002\\000\\000\\000\\000 \\307w\\002\\000\\000\\000\\000H\\000\\000\\000\\000\\000\\000\\000\\004\"...\n    property = 6\n    text = 0x7f08fc0064e8 \"\\370\\020\\351\\001\"\n    escaped_text = 0x500000000 <Address 0x500000000 out of bounds>\n    confname = \"\\025\", '\\000' <repeats 23 times>\"\\235, \ue149;\\000\\000\\000\\000\\370\\021p;\\000\\000\\000\\001\", '\\000' <repeats 15 times>\"\\320, \\t\\342q;\\000\\000\\000p\\307w\\002\\000\\000\\000\\000p\u0270\\004\\t\\177\\000\\000 \u0270\\004\\t\\177\\000\\000\\300\u02b0\\004\\t\\177\\000\\000P\u0270\\004\\t\\177\\000\\000\\b\\214\\000\\374\\b\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\240:\\000\\374\\b\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000\\000\\000\\002\\000\\000@\\t\\177\\000\\001\\220\\n\\000\\000\\000\\000\\000\\000@LR\\002\\000\\000\\000\\000\\330\u02b0\\004\\t\\177\", '\\000' <repeats 18 times>\"\\200, \u0270\\004\\t\\177\\000\"\n    __FUNCTION__ = \"changed_callback\"\n    **PRETTY_FUNCTION** = \"changed_callback\"\n\n9  0x00007f087fcd6c2c in filmrolls_updated (instance=0x1e81a80, self=0x1e91098) at /home/jp/DarkTable/darktable/src/libs/collect.c:1550\n    d = 0x1e91098\n\n10 0x0000003b71a05d64 in ffi_call_unix64 () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n11 0x0000003b71a05785 in ffi_call () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n12 0x0000003b71e0ef6b in g_cclosure_marshal_generic () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n13 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n14 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n15 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n16 0x00007f09071b2b57 in dt_control_signal_raise (ctlsig=0x1e8b790, signal=DT_SIGNAL_FILMROLLS_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:114\n    extra_args = {{gp_offset = 24, fp_offset = 48, overflow_arg_area = 0x7f0904b0d4c0, reg_save_area = 0x7f0904b0d3f0}}\n    i_own_lock = 1\n\n17 0x00007f0907167483 in dt_film_remove_empty () at /home/jp/DarkTable/darktable/src/common/film.c:527\n    **FUNCTION** = \"dt_film_remove_empty\"\n    **PRETTY_FUNCTION** = \"dt_film_remove_empty\"\n\n18 0x00007f09071af455 in dt_control_remove_images_job_run (job=0x2756c30) at /home/jp/DarkTable/darktable/src/control/jobs/control_jobs.c:625\n    imgid = -1\n    t1 = 0x2757b48\n    t = 0x0\n    total = 0\n    message = \"removing 0 images\", '\\000' <repeats 494 times>\n    fraction = 0\n    jid = 0x7f08fc1beb80\n    query = \"update images set flags = (flags | 256) where id in (select imgid from selected_images)\", '\\000' <repeats 254 times>, \"832\", '\\000' <repeats 29 times>, \"840\\000\\000\\000\\000\\000\\000\\000\\000\\030\\000\\000\\000\\060\\070\\063\\062\\300\u0670\\004\\t\\177\\000\\000\\000\u0670\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\030\\000\\000\\000\\060\\000\\000\\000\\340\u0670\\004\\t\\177\\000\\000\\030\\000\\000\\000\\060\\000\\000\\000\\360\u0670\\004\\t\\177\\000\\000\\060\u0670\\004\\t\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\030\\000\\000\\000\\060\\000\\000\\000\"...\n    **FUNCTION** = \"dt_control_remove_images_job_run\"\n    **PRETTY_FUNCTION** = \"dt_control_remove_images_job_run\"\n    list = 0x0\n    stmt = 0x7f08fc008d28\n    imgname = 0xff0000ff0000 <Address 0xff0000ff0000 out of bounds>\n\n19 0x00007f09071a8e08 in dt_control_run_job (s=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:961\n    j = 0x2756c30\n    bj = 0x0\n    **FUNCTION** = \"dt_control_run_job\"\n    ts_now = 1349088023\n    jobitem = 0x0\n\n20 0x00007f09071a9826 in dt_control_work (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n    s = 0x1ee83a0\n    **FUNCTION** = \"dt_control_work\"\n\n21 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n22 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 25 (Thread 0x7f090430d700 (LWP 7325)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a986f in dt_control_work (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1163\n    s = 0x1ee83a0\n    **FUNCTION** = \"dt_control_work\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 24 (Thread 0x7f0903b0c700 (LWP 7326)):\n0  0x0000003b6debd9fd in nanosleep () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6debd89c in sleep () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x00007f09071a9782 in _control_worker_kicker (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1141\n    s = 0x1ee83a0\n    __FUNCTION__ = \"_control_worker_kicker\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 23 (Thread 0x7f090330b700 (LWP 7327)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 0\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 22 (Thread 0x7f0902b0a700 (LWP 7328)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 1\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 21 (Thread 0x7f0902309700 (LWP 7329)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 2\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 20 (Thread 0x7f08ebfff700 (LWP 7330)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 3\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 19 (Thread 0x7f0901b08700 (LWP 7331)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 4\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 18 (Thread 0x7f0901307700 (LWP 7332)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 5\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 17 (Thread 0x7f0900b06700 (LWP 7333)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 6\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 16 (Thread 0x7f08fbfff700 (LWP 7334)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f09071a4681 in dt_pthread_cond_wait (cond=0x1eebea0, mutex=0x1eeafc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f09071a9715 in dt_control_work_res (ptr=0x1ee83a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x1ee83a0\n    threadid = 7\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 15 (Thread 0x7f087417b700 (LWP 7339)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 14 (Thread 0x7f087397a700 (LWP 7340)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 13 (Thread 0x7f0873179700 (LWP 7341)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 12 (Thread 0x7f0872978700 (LWP 7342)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 11 (Thread 0x7f0872177700 (LWP 7343)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 10 (Thread 0x7f0871976700 (LWP 7344)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 9 (Thread 0x7f0871175700 (LWP 7345)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 8 (Thread 0x7f0877c6c700 (LWP 7354)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 7 (Thread 0x7f087846d700 (LWP 7355)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 6 (Thread 0x7f0878c6e700 (LWP 7356)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 5 (Thread 0x7f087946f700 (LWP 7357)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 4 (Thread 0x7f0886d79700 (LWP 7358)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 3 (Thread 0x7f0886578700 (LWP 7359)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 2 (Thread 0x7f0885d77700 (LWP 7360)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 1 (Thread 0x7f090571ca00 (LWP 7323)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\nNo symbol table info available.\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003723e5ee72 in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\nNo symbol table info available.\n4  0x0000003b6fe44c14 in g_main_context_check () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n5  0x0000003b6fe45462 in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n6  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n7  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n8  0x00007f09072013b1 in dt_gui_gtk_run (gui=0x214d490) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n    widget = 0x21a70f0\n    tb = 8\n\n9  0x0000000000400a66 in main (argc=1, argv=0x7fff7660f908) at /home/jp/DarkTable/darktable/src/main.c:25\nNo locals.\n. During import:\nthis is darktable 1.0+1771~g36c3dd9 reporting a segfault:\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n[New Thread 0x7f6ee7bdc700 (LWP 7458)]\n[New Thread 0x7f6ee918c700 (LWP 7457)]\n[New Thread 0x7f6ee998d700 (LWP 7456)]\n[New Thread 0x7f6eea18e700 (LWP 7455)]\n[New Thread 0x7f6ed8d18700 (LWP 7454)]\n[New Thread 0x7f6ed8517700 (LWP 7453)]\n[New Thread 0x7f6ed7d16700 (LWP 7452)]\n[New Thread 0x7f6ed7515700 (LWP 7451)]\n[New Thread 0x7f6ed10da700 (LWP 7442)]\n[New Thread 0x7f6ed18db700 (LWP 7441)]\n[New Thread 0x7f6ed20dc700 (LWP 7440)]\n[New Thread 0x7f6ed28dd700 (LWP 7439)]\n[New Thread 0x7f6ed30de700 (LWP 7438)]\n[New Thread 0x7f6ed38df700 (LWP 7437)]\n[New Thread 0x7f6ed40e0700 (LWP 7436)]\n[New Thread 0x7f6f5bfff700 (LWP 7433)]\n[New Thread 0x7f6f60a7a700 (LWP 7432)]\n[New Thread 0x7f6f6127b700 (LWP 7431)]\n[New Thread 0x7f6f61a7c700 (LWP 7430)]\n[New Thread 0x7f6f53fff700 (LWP 7429)]\n[New Thread 0x7f6f6227d700 (LWP 7428)]\n[New Thread 0x7f6f62a7e700 (LWP 7427)]\n[New Thread 0x7f6f6327f700 (LWP 7426)]\n[New Thread 0x7f6f63a80700 (LWP 7425)]\n[New Thread 0x7f6f64281700 (LWP 7424)]\n[New Thread 0x7f6f64a82700 (LWP 7423)]\n0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\n3  0x0000003723e5eeee in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\n4  0x0000003b6fe444d2 in g_main_context_prepare () from /lib64/libglib-2.0.so.0\n5  0x0000003b6fe452dd in ?? () from /lib64/libglib-2.0.so.0\n6  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n7  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n8  0x00007f6f671753b1 in dt_gui_gtk_run (gui=0x1c48490) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n9  0x0000000000400a66 in main (argc=1, argv=0x7fff63239618) at /home/jp/DarkTable/darktable/src/main.c:25\nThread 27 (Thread 0x7f6f64a82700 (LWP 7423)):\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\nNo symbol table info available.\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\nNo symbol table info available.\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\nNo symbol table info available.\n5  0x00007f6f670c3298 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n    read_something = 0\n    fd = 0x7f6f4c0afc20\n    buf = \"\\000\\000\\200\\377\\000\\000\\200\\377\\377\\377\\377\\000\\377\\377\\377\\000\\001\\000\\000\\000\\000\\000\\000\\000\\004\\000\\000\\000\\001\", '\\000' <repeats 27 times>, \"\\001\\000\\000\\000\\001\\000\\000\\000\\006\\000\\000\\000o\\177\", '\\000' <repeats 26 times>, \"o\\000\\000\\000\\000\\000\\000\\000\\b\\265\\232\\001\\000\\000\\000\\000\\030B\\vLo\\177\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000`\\000\\000\\000\\000\\000\\000\\000\\230\\000\\000\\000\\000\\000\\000\\000\\370\\300\\230\\001\\000\\000\\000\\000+q\\203\\211;\\000\\000\\000\\b\\265\\232\\001\", '\\000' <repeats 12 times>, \"p\\257\\240n;\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\030\\061\\vLo\\177\\000\\000\\002\\000\\000\\000\\000\\000\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000\\265r\\203\\211;\\000\\000\\000\\370\\300\\230\\001\\000\\000\\000\\000\\030\\061\\vLo\\177\\000\\000\\350\\344\\231\\001\\000\\000\\000\\000\\030B\\vLo\\177\\000\\000\\a\\000\\000\\000\\000\\000\\000\\000\\367y\\204\\211;\"...\n    name_used = 0x7f6f4c0b2ea0 \"/tmp/darktable_bt_QQJ9KW.txt\"\n    fout = 23\n    delete_file = 0\n    datadir = \"/usr/local/packages/darktable-1.1-20121001-jose/share/darktable\\000\\000\\000\\000\\000\\000\\000\\000\\000`\\372\\247do\\177\\000\\000\\001\\000\\000\\000\\001\\000\\000\\000@\\370\\247do\\177\\000\\000\\070\\000\\250do\\177\\000\\000\\000\\320$go\\177\\000\\000L\\000\\000\\000\\000\\000\\000\\000\\017{\\344m;\\000\\000\\000\\325\\377\\000\\000\\326\\377\\000\\000\\r\\005\\346o;\\000\\000\\000\\331\\377\\000\\000\\332\\377\\000\\000\\t\\320$go\\177\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\337\\377\\000\\000\\340\\377\\000\\000\\341\\377\\000\\000\\342\\377\\000\\000\\343\\377\\000\\000\\344\\377\\000\\000\\345\\377\\000\\000\\346\\377\\000\\000\\060V\\327\\001\", '\\000' <repeats 13 times>\"\\270, \\326\\001\", '\\000' <repeats 24 times>, \"\\001\\000\\000\\000a\\220.\\002\", '\\000' <repeats 12 times>...\n    command = 0x7f6f4c0a1950 \"gdb darktable 7422 -batch -x /usr/local/packages/darktable-1.1-20121001-jose/share/darktable/gdb_commands\"\n\n6  \nNo symbol table info available.\n7  0x00007f6edcfa1be9 in filmrolls_updated (instance=0x197ca80, self=0x674ed1c8) at /home/jp/DarkTable/darktable/src/libs/collect.c:1548\n    d = 0x674ed1c8\n\n8  0x0000003b71a05d64 in ffi_call_unix64 () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n9  0x0000003b71a05785 in ffi_call () from /usr/lib64/libffi.so.5\nNo symbol table info available.\n10 0x0000003b71e0ef6b in g_cclosure_marshal_generic () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n11 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n12 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n13 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n14 0x00007f6f67126b57 in dt_control_signal_raise (ctlsig=0x1986790, signal=DT_SIGNAL_FILMROLLS_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:114\n    extra_args = {{gp_offset = 24, fp_offset = 48, overflow_arg_area = 0x7f6f64a818b0, reg_save_area = 0x7f6f64a817e0}}\n    i_own_lock = 1\n\n15 0x00007f6f670db216 in dt_film_import1 (film=0x22eee70) at /home/jp/DarkTable/darktable/src/common/film.c:493\n    recursive = 1\n    images = 0x22c4b80 = {0x7f6f4c01fcc0, 0x7f6f4c01a4f0, 0x7f6f4c013850, 0x7f6f4c01aae0, 0x7f6f4c004530, 0x7f6f4c0138f0, 0x7f6f4c006c00, 0x7f6f4c01a540, 0x7f6f4c0021d0, 0x7f6f4c002d60, 0x7f6f4c005b90, 0x7f6f4c003300, 0x7f6f4c002fe0, 0x7f6f4c015be0, 0x7f6f4c001130, 0x7f6f4c023450, 0x7f6f4c019570, 0x7f6f4c01c440, 0x7f6f4c01f180, 0x7f6f4c007cb0, 0x7f6f4c005f50, 0x7f6f4c01ee60, 0x7f6f4c015780, 0x7f6f4c01a6d0, 0x7f6f4c01d600, 0x7f6f4c023590, 0x7f6f4c007e40, 0x7f6f4c01f860, 0x7f6f4c01e280, 0x7f6f4c002ea0, 0x7f6f4c004e90, 0x7f6f4c007ad0, 0x7f6f4c005b40, 0x7f6f4c009670, 0x7f6f4c0153c0, 0x7f6f4c002bd0, 0x7f6f4c002590, 0x7f6f4c01a860, 0x7f6f4c01b090, 0x7f6f4c01d6a0, 0x7f6f4c0175a0, 0x7f6f4c006de0, 0x7f6f4c01d6f0, 0x7f6f4c01eaa0, 0x7f6f4c014700, 0x7f6f4c021480, 0x7f6f4c004580, 0x7f6f4c01d470, 0x7f6f4c003260, 0x7f6f4c016c40, 0x7f6f4c018990, 0x7f6f4c0029f0, 0x7f6f4c020440, 0x7f6f4c01b590, 0x7f6f4c023040, 0x7f6f4c01bc70, 0x7f6f4c004d00, 0x7f6f4c01e500, 0x7f6f4c016790, 0x7f6f4c015fa0, 0x7f6f4c01dc40, 0x7f6f4c005070, 0x7f6f4c0168d0, 0x7f6f4c0169c0, 0x7f6f4c018d50, 0x7f6f4c01a590, 0x7f6f4c004800, 0x7f6f4c019250, 0x7f6f4c01e960, 0x7f6f4c003670, 0x7f6f4c003800, 0x7f6f4c01e4b0, 0x7f6f4c018df0, 0x7f6f4c0027c0, 0x7f6f4c01aa90, 0x7f6f4c01f3b0, 0x7f6f4c01d1a0, 0x7f6f4c01bd10, 0x7f6f4c018300, 0x7f6f4c007a80, 0x7f6f4c0142f0, 0x7f6f4c01bae0, 0x7f6f4c021b60, 0x7f6f4c0082a0, 0x7f6f4c01d510, 0x7f6f4c004f30, 0x7f6f4c006680, 0x7f6f4c01e190, 0x7f6f4c018080, 0x7f6f4c01e820, 0x7f6f4c0024a0, 0x7f6f4c0029a0, 0x7f6f4c017140, 0x7f6f4c01da10, 0x7f6f4c004990, 0x7f6f4c01db50, 0x7f6f4c023130, 0x7f6f4c017550, 0x7f6f4c01be00, 0x7f6f4c016ce0, 0x7f6f4c018210, 0x7f6f4c01e730, 0x7f6f4c01ddd0, 0x7f6f4c0043a0, 0x7f6f4c0037b0, 0x7f6f4c018030, 0x7f6f4c0197a0, 0x7f6f4c01f360, 0x7f6f4c0155a0, 0x7f6f4c005f00, 0x7f6f4c001ff0, 0x7f6f4c002860, 0x7f6f4c016ba0, 0x7f6f4c001c30, 0x7f6f4c013a80, 0x7f6f4c021f20, 0x7f6f4c008020, 0x7f6f4c004df0, 0x7f6f4c013bc0, 0x7f6f4c021fc0, 0x7f6f4c009820, 0x7f6f4c0193e0, 0x7f6f4c001f00, 0x7f6f4c012c30, 0x7f6f4c01ec30, 0x7f6f4c009a50, 0x7f6f4c0207b0, 0x7f6f4c01f9f0, 0x7f6f4c005c80, 0x7f6f4c013c60, 0x7f6f4c012b90, 0x7f6f4c019a20, 0x7f6f4c021020, 0x7f6f4c01c5d0, 0x7f6f4c017fe0, 0x7f6f4c021930, 0x7f6f4c006c50, 0x7f6f4c0166a0, 0x7f6f4c01eff0, 0x7f6f4c01e9b0, 0x7f6f4c004cb0, 0x7f6f4c0049e0, 0x7f6f4c020760, 0x7f6f4c01fc70, 0x7f6f4c0158c0, 0x7f6f4c01c490, 0x7f6f4c01f540, 0x7f6f4c0234a0, 0x7f6f4c016bf0, 0x7f6f4c01d4c0, 0x7f6f4c015d20, 0x7f6f4c015410, 0x7f6f4c017320, 0x7f6f4c020670, 0x7f6f4c012d20, 0x7f6f4c005fa0, 0x7f6f4c01f950, 0x7f6f4c021160, 0x7f6f4c01f2c0, 0x7f6f4c006900, 0x7f6f4c022100, 0x7f6f4c01fe50, 0x7f6f4c006540, 0x7f6f4c007da0, 0x7f6f4c002770, 0x7f6f4c015640, 0x7f6f4c002450, 0x7f6f4c0172d0, 0x7f6f4c0035d0, 0x7f6f4c01c4e0, 0x7f6f4c01c170, 0x7f6f4c0047b0, 0x7f6f4c006270, 0x7f6f4c020850, 0x7f6f4c018850, 0x7f6f4c01e870, 0x7f6f4c0173c0, 0x7f6f4c01fb80, 0x7f6f4c01b7c0, 0x7f6f4c006450, 0x7f6f4c0208a0, 0x7f6f4c01b630, 0x7f6f4c022d70, 0x7f6f4c001c80, 0x7f6f4c003170, 0x7f6f4c002e50, 0x7f6f4c01b0e0, 0x7f6f4c0152d0, 0x7f6f4c009910, 0x7f6f4c01e1e0, 0x7f6f4c01de70, 0x7f6f4c01b5e0, 0x7f6f4c008390, 0x7f6f4c014340, 0x7f6f4c006d40, 0x7f6f4c002e00, 0x7f6f4c006950, 0x7f6f4c0092a0, 0x7f6f4c01b2c0, 0x7f6f4c01c120...}\n    message = \"importing 960 images\", '\\000' <repeats 491 times>\n    fraction = 1.0000000000000233\n    total = 960\n    jid = 0x7f6f4c09cf60\n    cfr = 0x22eee70\n    image = 0x0\n    dfn = 0x3b6da14f05 \"I\\211\\303L\\213L$0L\\213D$(H\\213|$ H\\213t$\\030H\\213T$\\020H\\213L$\\bH\\213\\004$H\\203\\304HA\\377\\343ffffff.\\017\\037\\204\"\n\n16 0x00007f6f6712670a in dt_film_import1_run (job=0x22f7840) at /home/jp/DarkTable/darktable/src/control/jobs/film_jobs.c:37\n    t = 0x22f8758\n    __FUNCTION__ = \"dt_film_import1_run\"\n\n17 0x00007f6f6711ce08 in dt_control_run_job (s=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:961\n    j = 0x22f7840\n    bj = 0x0\n    **FUNCTION** = \"dt_control_run_job\"\n    ts_now = 1349088108\n    jobitem = 0x0\n\n18 0x00007f6f6711d826 in dt_control_work (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n    s = 0x19e33a0\n    **FUNCTION** = \"dt_control_work\"\n\n19 0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n20 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 26 (Thread 0x7f6f64281700 (LWP 7424)):\n0  0x0000003b6ea0e34d in **lll_lock_wait () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\nNo symbol table info available.\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x00007f6f6711f390 in dt_control_gdk_lock () at /home/jp/DarkTable/darktable/src/control/control.c:1511\nNo locals.\n4  0x00007f6f67126aed in dt_control_signal_raise (ctlsig=0x1986790, signal=DT_SIGNAL_DEVELOP_MIPMAP_UPDATED) at /home/jp/DarkTable/darktable/src/control/signal.c:112\n    extra_args = {{gp_offset = 16, fp_offset = 48, overflow_arg_area = 0x7f6f6427f810, reg_save_area = 0x7f6f6427f740}}\n    i_own_lock = 0\n\n5  0x00007f6f67101af6 in dt_mipmap_cache_read_get (cache=0x19e0a00, buf=0x7f6f64280b30, imgid=35, mip=DT_MIPMAP_0, flags=DT_MIPMAP_BLOCKING) at /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:937\n    dsc = 0x7f6eff3c9c10\n    key = 34\n    __PRETTY_FUNCTION** = \"dt_mipmap_cache_read_get\"\n\n6  0x00007f6f6712684f in dt_image_load_job_run (job=0x231d5a0) at /home/jp/DarkTable/darktable/src/control/jobs/image_jobs.c:38\n    t = 0x231e4b8\n    buf = {size = 1680345936, imgid = 32623, width = 1729218642, height = 32623, buf = 0x201060501 <Address 0x201060501 out of bounds>}\n\n7  0x00007f6f6711ce08 in dt_control_run_job (s=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:961\n    j = 0x231d5a0\n    bj = 0x0\n    **FUNCTION** = \"dt_control_run_job\"\n    ts_now = 1349088121\n    jobitem = 0x0\n\n8  0x00007f6f6711d826 in dt_control_work (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1159\n    s = 0x19e33a0\n    **FUNCTION** = \"dt_control_work\"\n\n9  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n10 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 25 (Thread 0x7f6f63a80700 (LWP 7425)):\n0  0x0000003b6debd9fd in nanosleep () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6debd89c in sleep () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x00007f6f6711d782 in _control_worker_kicker (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1141\n    s = 0x19e33a0\n    __FUNCTION__ = \"_control_worker_kicker\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 24 (Thread 0x7f6f6327f700 (LWP 7426)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 0\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 23 (Thread 0x7f6f62a7e700 (LWP 7427)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 1\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 22 (Thread 0x7f6f6227d700 (LWP 7428)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 2\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 21 (Thread 0x7f6f53fff700 (LWP 7429)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 3\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 20 (Thread 0x7f6f61a7c700 (LWP 7430)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 4\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 19 (Thread 0x7f6f6127b700 (LWP 7431)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 5\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 18 (Thread 0x7f6f60a7a700 (LWP 7432)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 6\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 17 (Thread 0x7f6f5bfff700 (LWP 7433)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f6f67118681 in dt_pthread_cond_wait (cond=0x19e6ea0, mutex=0x19e5fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f6f6711d715 in dt_control_work_res (ptr=0x19e33a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x19e33a0\n    threadid = 7\n    **FUNCTION** = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 16 (Thread 0x7f6ed40e0700 (LWP 7436)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 15 (Thread 0x7f6ed38df700 (LWP 7437)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 14 (Thread 0x7f6ed30de700 (LWP 7438)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 13 (Thread 0x7f6ed28dd700 (LWP 7439)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 12 (Thread 0x7f6ed20dc700 (LWP 7440)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 11 (Thread 0x7f6ed18db700 (LWP 7441)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 10 (Thread 0x7f6ed10da700 (LWP 7442)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 9 (Thread 0x7f6ed7515700 (LWP 7451)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 8 (Thread 0x7f6ed7d16700 (LWP 7452)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 7 (Thread 0x7f6ed8517700 (LWP 7453)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 6 (Thread 0x7f6ed8d18700 (LWP 7454)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 5 (Thread 0x7f6eea18e700 (LWP 7455)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 4 (Thread 0x7f6ee998d700 (LWP 7456)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 3 (Thread 0x7f6ee918c700 (LWP 7457)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 2 (Thread 0x7f6ee7bdc700 (LWP 7458)):\n0  0x0000003b6ea0be4f in pthread_cond_timedwait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b71202445 in ?? () from /lib64/libgthread-2.0.so.0\nNo symbol table info available.\n2  0x0000003b6fe196ff in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n3  0x0000003b6fe19f51 in g_async_queue_timed_pop () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n4  0x0000003b6fe6cb27 in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n5  0x0000003b6fe6a6e6 in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n6  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n7  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 1 (Thread 0x7f6f65690a00 (LWP 7422)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\nNo symbol table info available.\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003723e5eeee in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\nNo symbol table info available.\n4  0x0000003b6fe444d2 in g_main_context_prepare () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n5  0x0000003b6fe452dd in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n6  0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n7  0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n8  0x00007f6f671753b1 in dt_gui_gtk_run (gui=0x1c48490) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n    widget = 0x1ca1cf0\n    tb = 8\n\n9  0x0000000000400a66 in main (argc=1, argv=0x7fff63239618) at /home/jp/DarkTable/darktable/src/main.c:25\nNo locals.\n. I'm guessing that the number of pictures is still work in progress. But doesn't crash on startup anymore :)\n. During shutdown:\n``\n(darktable:7654): Gtk-CRITICAL **: IA__gtk_tree_model_iter_n_children: assertionGTK_IS_TREE_MODEL (tree_model)' failed\n(darktable:7654): Gtk-CRITICAL **: IA__gtk_tree_model_iter_n_children: assertion `GTK_IS_TREE_MODEL (tree_model)' failed                                                \n(darktable:7654): GLib-CRITICAL **: g_ptr_array_free: assertion `array' failed\n```\n. Perfect, I'll keep testing the pushes.\n. @jcsogo it doesn't crash now, thanks :)\nA couple of issues:\n- Folder view: Double click on a folder doesn't activate the roll\n- Filmroll view: You can select the activate roll by double clicking, but it isn't moved to the top of the list anymore\n- Switching from filmroll view to folder view seems to mix up images from different rolls. Double click will blank due to the above issue\nOther stuff:\n- Folder view: It would be nice to have a \"sync\" / \"update\" action on right-click to sync with the current directory content\n- Folder view: In many cases a horizontal scrollbar is added, since there isn't room for the image counters\nThanks again\n. @jcsogo There is of \"jumping\" around when importing - it seems that the new entry in the tree isn't created at once, and switched to\n. @jcsogo select an image, and switch to darkroom (using 'd'):\n```\nthis is darktable 1.0+1796~ge0317d6 reporting a segfault:\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib64/libthread_db.so.1\".\n[New Thread 0x7f0375ec1700 (LWP 6947)]\n[New Thread 0x7f03766c2700 (LWP 6946)]\n[New Thread 0x7f0376ec3700 (LWP 6945)]\n[New Thread 0x7f03776c4700 (LWP 6944)]\n[New Thread 0x7f0377ec5700 (LWP 6943)]\n[New Thread 0x7f03786c6700 (LWP 6942)]\n[New Thread 0x7f0378ec7700 (LWP 6941)]\n[New Thread 0x7f03bedfa700 (LWP 6939)]\n[New Thread 0x7f03bf5fb700 (LWP 6938)]\n[New Thread 0x7f03bfdfc700 (LWP 6937)]\n[New Thread 0x7f0375652700 (LWP 6936)]\n[New Thread 0x7f036d175700 (LWP 6935)]\n[New Thread 0x7f0353fff700 (LWP 6934)]\n[New Thread 0x7f03537fe700 (LWP 6933)]\n[New Thread 0x7f036d976700 (LWP 6918)]\n[New Thread 0x7f036e177700 (LWP 6917)]\n[New Thread 0x7f036e978700 (LWP 6916)]\n[New Thread 0x7f036f179700 (LWP 6915)]\n[New Thread 0x7f036f97a700 (LWP 6914)]\n[New Thread 0x7f037017b700 (LWP 6913)]\n[New Thread 0x7f037097c700 (LWP 6912)]\n[New Thread 0x7f03fcf70700 (LWP 6907)]\n[New Thread 0x7f03fd771700 (LWP 6906)]\n[New Thread 0x7f03effff700 (LWP 6905)]\n[New Thread 0x7f03fdf72700 (LWP 6904)]\n[New Thread 0x7f03fe773700 (LWP 6903)]\n[New Thread 0x7f03fef74700 (LWP 6902)]\n[New Thread 0x7f03ff775700 (LWP 6901)]\n[New Thread 0x7f03fff76700 (LWP 6900)]\n[New Thread 0x7f0400777700 (LWP 6899)]\n[New Thread 0x7f0400f78700 (LWP 6898)]\n[New Thread 0x7f0401779700 (LWP 6897)]\n0x0000003b6dee43fd in read () from /lib64/libc.so.6\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\n5  0x00007f04041fbd38 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n6  \n7  0x00007f037c54ab97 in changed_callback (entry=0x0, dr=0x2734500) at /home/jp/DarkTable/darktable/src/libs/collect.c:934\n8  0x00007f037c54cbd9 in collection_updated (instance=0x1fdaa80, self=0x2734500) at /home/jp/DarkTable/darktable/src/libs/collect.c:1516\n9  0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n10 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\n11 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n12 0x00007f040425f5fb in dt_control_signal_raise (ctlsig=0x1fe4790, signal=DT_SIGNAL_COLLECTION_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:114\n13 0x00007f04041f2e57 in dt_collection_update_query (collection=0x2011370) at /home/jp/DarkTable/darktable/src/common/collection.c:580\n14 0x00007f037d58ad85 in _lib_filter_update_query (self=0x26097c0) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:232\n15 0x00007f037d58aad2 in gui_init (self=0x26097c0) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:162\n16 0x00007f04042d11b3 in dt_view_manager_switch (vm=0x2450220, k=1) at /home/jp/DarkTable/darktable/src/views/view.c:279\n17 0x00007f040425740e in dt_ctl_switch_mode_to (mode=DT_DEVELOP) at /home/jp/DarkTable/darktable/src/control/control.c:1380\n18 0x00007f04042ad9fb in _gui_switch_view_key_accel_callback (accel_group=0x22bc400, acceleratable=0x22cb030, keyval=100, modifier=0, p=0x3) at /home/jp/DarkTable/darktable/src/gui/gtk.c:558\n19 0x000000372374f4e8 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n20 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n21 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\n22 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n23 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\n24 0x00000037236702d4 in gtk_accel_group_activate () from /usr/lib64/libgtk-x11-2.0.so.0\n25 0x00000037236716d9 in gtk_accel_groups_activate () from /usr/lib64/libgtk-x11-2.0.so.0\n26 0x000000372389db1e in gtk_window_activate_key () from /usr/lib64/libgtk-x11-2.0.so.0\n27 0x000000372389dba7 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n28 0x000000372374ed03 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n29 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n30 0x0000003b71e20b7c in ?? () from /lib64/libgobject-2.0.so.0\n31 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n32 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\n33 0x0000003723883f41 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n34 0x000000372374c8f7 in gtk_propagate_event () from /usr/lib64/libgtk-x11-2.0.so.0\n35 0x000000372374cb8b in gtk_main_do_event () from /usr/lib64/libgtk-x11-2.0.so.0\n36 0x0000003723e6207c in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\n37 0x0000003b6fe44f3d in g_main_context_dispatch () from /lib64/libglib-2.0.so.0\n38 0x0000003b6fe45738 in ?? () from /lib64/libglib-2.0.so.0\n39 0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n40 0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n41 0x00007f04042aed89 in dt_gui_gtk_run (gui=0x20665e0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n42 0x0000000000400a66 in main (argc=1, argv=0x7fff2eea2738) at /home/jp/DarkTable/darktable/src/main.c:25\nThread 33 (Thread 0x7f0401779700 (LWP 6897)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f0404256313 in dt_control_work (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1163\n    s = 0x20413a0\n    __FUNCTION__ = \"dt_control_work\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 32 (Thread 0x7f0400f78700 (LWP 6898)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f0404256313 in dt_control_work (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1163\n    s = 0x20413a0\n    __FUNCTION__ = \"dt_control_work\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 31 (Thread 0x7f0400777700 (LWP 6899)):\n0  0x0000003b6debd9fd in nanosleep () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6debd89c in sleep () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x00007f0404256226 in _control_worker_kicker (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1141\n    s = 0x20413a0\n    __FUNCTION__ = \"_control_worker_kicker\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 30 (Thread 0x7f03fff76700 (LWP 6900)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 0\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 29 (Thread 0x7f03ff775700 (LWP 6901)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 1\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 28 (Thread 0x7f03fef74700 (LWP 6902)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 2\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 27 (Thread 0x7f03fe773700 (LWP 6903)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 3\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 26 (Thread 0x7f03fdf72700 (LWP 6904)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 4\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 25 (Thread 0x7f03effff700 (LWP 6905)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 5\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 24 (Thread 0x7f03fd771700 (LWP 6906)):\n0  0x0000003b6ea0e34d in __lll_lock_wait () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x0000003b6ea09f97 in _L_lock_863 () from /lib64/libpthread.so.0\nNo symbol table info available.\n2  0x0000003b6ea09deb in pthread_mutex_lock () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x00007f0404257e34 in dt_control_gdk_lock () at /home/jp/DarkTable/darktable/src/control/control.c:1511\nNo locals.\n4  0x00007f040425f591 in dt_control_signal_raise (ctlsig=0x1fe4790, signal=DT_SIGNAL_DEVELOP_MIPMAP_UPDATED) at /home/jp/DarkTable/darktable/src/control/signal.c:112\n    extra_args = {{gp_offset = 16, fp_offset = 48, overflow_arg_area = 0x7f03fd76f3b0, reg_save_area = 0x7f03fd76f2e0}}\n    i_own_lock = 0\n\n5  0x00007f040423a59a in dt_mipmap_cache_read_get (cache=0x2016660, buf=0x7f03fd770a90, imgid=3816, mip=DT_MIPMAP_2, flags=DT_MIPMAP_BLOCKING) at /home/jp/DarkTable/darktable/src/common/mipmap_cache.c:937\n    dsc = 0x7f03aef78b00\n    key = 1073745639\n    __PRETTY_FUNCTION__ = \"dt_mipmap_cache_read_get\"\n\n6  0x00007f040425a713 in dt_control_indexer_job_run (job=0x204b280) at /home/jp/DarkTable/darktable/src/control/jobs/control_jobs.c:212\n    buf = {size = DT_MIPMAP_NONE, imgid = 3815, width = 647, height = 431, buf = 0x0}\n    buf_decompressed = 0x7f03aee3ed00 \"\\006\\020\\t\"\n    idximg = 0x7f03c4006500\n    message = \"re-indexing 372 images\", '\\000' <repeats 489 times>\n    fraction = 0.78225806451612845\n    total = 372\n    jid = 0x7f03c4000930\n    scratchmem = 0x0\n    images = 0x285a060 = {0x7f03c4000e90, 0x7f03c40016b0, 0x7f03c40016d0, 0x7f03c40016f0, 0x7f03c4001710, 0x7f03c4001730, 0x7f03c4001750, 0x7f03c4001770, 0x7f03c4001790, 0x7f03c40017b0, 0x7f03c40017d0, 0x7f03c40017f0, 0x7f03c4001810, 0x7f03c4001830, 0x7f03c4001850, 0x7f03c4002680, 0x7f03c40026a0, 0x7f03c40026c0, 0x7f03c40026e0, 0x7f03c4002700, 0x7f03c4002720, 0x7f03c4002740, 0x7f03c4002760, 0x7f03c4002780, 0x7f03c40027a0, 0x7f03c40027c0, 0x7f03c40027e0, 0x7f03c4002800, 0x7f03c4002820, 0x7f03c4002840, 0x7f03c4002860, 0x7f03c4002880, 0x7f03c40028a0, 0x7f03c40028c0, 0x7f03c40028e0, 0x7f03c4002900, 0x7f03c4002920, 0x7f03c4002940, 0x7f03c4002960, 0x7f03c4002980, 0x7f03c40029a0, 0x7f03c40029c0, 0x7f03c40029e0, 0x7f03c4002a00, 0x7f03c4002a20, 0x7f03c4002a40, 0x7f03c4002a60, 0x7f03c4002a80, 0x7f03c4002aa0, 0x7f03c4002ac0, 0x7f03c4002ae0, 0x7f03c4002b00, 0x7f03c4002b20, 0x7f03c4002b40, 0x7f03c4002b60, 0x7f03c4002b80, 0x7f03c4002ba0, 0x7f03c4002bc0, 0x7f03c4002be0, 0x7f03c4002c00, 0x7f03c4002c20, 0x7f03c4002c40, 0x7f03c4002c60, 0x7f03c4002c80, 0x7f03c4002ca0, 0x7f03c4002cc0, 0x7f03c4002ce0, 0x7f03c4002d00, 0x7f03c4002d20, 0x7f03c4002d40, 0x7f03c4002d60, 0x7f03c4002d80, 0x7f03c4002da0, 0x7f03c4002dc0, 0x7f03c4002de0, 0x7f03c4002e00, 0x7f03c4002e20, 0x7f03c4002e40, 0x7f03c4002e60, 0x7f03c4002e80, 0x7f03c4002ea0, 0x7f03c4002ec0, 0x7f03c4002ee0, 0x7f03c4002f00, 0x7f03c4002f20, 0x7f03c4002f40, 0x7f03c4002f60, 0x7f03c4002f80, 0x7f03c4002fa0, 0x7f03c4002fc0, 0x7f03c4002fe0, 0x7f03c4003000, 0x7f03c4003020, 0x7f03c4003040, 0x7f03c4003060, 0x7f03c4003080, 0x7f03c40030a0, 0x7f03c40030c0, 0x7f03c40030e0, 0x7f03c4003100, 0x7f03c4003120, 0x7f03c4003140, 0x7f03c4003160, 0x7f03c4003180, 0x7f03c40031a0, 0x7f03c40031c0, 0x7f03c40031e0, 0x7f03c4003800, 0x7f03c4003820, 0x7f03c4003840, 0x7f03c4003860, 0x7f03c4003880, 0x7f03c40038a0, 0x7f03c40038c0, 0x7f03c40038e0, 0x7f03c4003900, 0x7f03c4003920, 0x7f03c4003940, 0x7f03c4003960, 0x7f03c4003980, 0x7f03c40039a0, 0x7f03c40039c0, 0x7f03c40039e0, 0x7f03c4003a00, 0x7f03c4003a20, 0x7f03c4003a40, 0x7f03c4003a60, 0x7f03c4003a80, 0x7f03c4003aa0, 0x7f03c4003ac0, 0x7f03c4003ae0, 0x7f03c4003b00, 0x7f03c4003b20, 0x7f03c4003b40, 0x7f03c4003b60, 0x7f03c4003b80, 0x7f03c4003ba0, 0x7f03c4003bc0, 0x7f03c4003be0, 0x7f03c4003c00, 0x7f03c4003c20, 0x7f03c4003c40, 0x7f03c4003c60, 0x7f03c4003c80, 0x7f03c4003ca0, 0x7f03c4003cc0, 0x7f03c4003ce0, 0x7f03c4003d00, 0x7f03c4003d20, 0x7f03c4003d40, 0x7f03c4003d60, 0x7f03c4003d80, 0x7f03c4003da0, 0x7f03c4003dc0, 0x7f03c4003de0, 0x7f03c4004600, 0x7f03c4004620, 0x7f03c4004640, 0x7f03c4004660, 0x7f03c4004680, 0x7f03c40046a0, 0x7f03c40046c0, 0x7f03c40046e0, 0x7f03c4004700, 0x7f03c4004720, 0x7f03c4004740, 0x7f03c4004760, 0x7f03c4004780, 0x7f03c40047a0, 0x7f03c40047c0, 0x7f03c40047e0, 0x7f03c4004800, 0x7f03c4004820, 0x7f03c4004840, 0x7f03c4004860, 0x7f03c4004880, 0x7f03c40048a0, 0x7f03c40048c0, 0x7f03c40048e0, 0x7f03c4004900, 0x7f03c4004920, 0x7f03c4004940, 0x7f03c4004960, 0x7f03c4004980, 0x7f03c40049a0, 0x7f03c40049c0, 0x7f03c40049e0, 0x7f03c4004a00, 0x7f03c4004a20, 0x7f03c4004a40, 0x7f03c4004a60, 0x7f03c4004a80, 0x7f03c4004aa0, 0x7f03c4004ac0, 0x7f03c4004ae0, 0x7f03c4004b00, 0x7f03c4004b20, 0x7f03c4004b40, 0x7f03c4004b60, 0x7f03c4004b80...}\n    stmt = 0x7f03c4001cf8\n    __FUNCTION__ = \"dt_control_indexer_job_run\"\n    __PRETTY_FUNCTION__ = \"dt_control_indexer_job_run\"\n    imgitem = 0x7f03c4005f60 = {0x7f03c4006500, 0x7f03c4006520, 0x7f03c4006540, 0x7f03c4006560, 0x7f03c4006580, 0x7f03c40065a0, 0x7f03c40065c0, 0x7f03c40065e0, 0x7f03c4006600, 0x7f03c4006620, 0x7f03c4006640, 0x7f03c4006660, 0x7f03c4006680, 0x7f03c40066a0, 0x7f03c40066c0, 0x7f03c40066e0, 0x7f03c4006700, 0x7f03c4006720, 0x7f03c4006740, 0x7f03c4006760, 0x7f03c4006780, 0x7f03c40067a0, 0x7f03c40067c0, 0x7f03c40067e0, 0x7f03c4007000, 0x7f03c4007020, 0x7f03c4007040, 0x7f03c4007060, 0x7f03c4007080, 0x7f03c40070a0, 0x7f03c40070c0, 0x7f03c40070e0, 0x7f03c4007100, 0x7f03c4007120, 0x7f03c4007140, 0x7f03c4007160, 0x7f03c4007180, 0x7f03c40071a0, 0x7f03c40071c0, 0x7f03c40071e0, 0x7f03c4007200, 0x7f03c4007220, 0x7f03c4007240, 0x7f03c4007260, 0x7f03c4007280, 0x7f03c40072a0, 0x7f03c40072c0, 0x7f03c40072e0, 0x7f03c4007300, 0x7f03c4007320, 0x7f03c4007340, 0x7f03c4007360, 0x7f03c4007380, 0x7f03c40073a0, 0x7f03c40073c0, 0x7f03c40073e0, 0x7f03c4007400, 0x7f03c4007420, 0x7f03c4007440, 0x7f03c4007460, 0x7f03c4007480, 0x7f03c40074a0, 0x7f03c40074c0, 0x7f03c40074e0, 0x7f03c4007500, 0x7f03c4007520, 0x7f03c4007540, 0x7f03c4007560, 0x7f03c4007580, 0x7f03c40075a0, 0x7f03c40075c0, 0x7f03c40075e0, 0x7f03c4007e00, 0x7f03c4007e20, 0x7f03c4007e40, 0x7f03c4007e60, 0x7f03c4007e80, 0x7f03c4007ea0, 0x7f03c4007ec0, 0x7f03c4007ee0, 0x7f03c4007f00}\n\n7  0x00007f040425556c in dt_control_run_job_res (s=0x20413a0, res=6) at /home/jp/DarkTable/darktable/src/control/control.c:883\n    __PRETTY_FUNCTION__ = \"dt_control_run_job_res\"\n    j = 0x204b280\n    __FUNCTION__ = \"dt_control_run_job_res\"\n\n8  0x00007f040425615b in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1122\n    s = 0x20413a0\n    threadid = 6\n    __FUNCTION__ = \"dt_control_work_res\"\n\n9  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n10 0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 23 (Thread 0x7f03fcf70700 (LWP 6907)):\n0  0x0000003b6ea0bae5 in pthread_cond_wait@@GLIBC_2.3.2 () from /lib64/libpthread.so.0\nNo symbol table info available.\n1  0x00007f0404251125 in dt_pthread_cond_wait (cond=0x2044ea0, mutex=0x2043fc0) at /home/jp/DarkTable/darktable/src/common/dtpthread.h:170\nNo locals.\n2  0x00007f04042561b9 in dt_control_work_res (ptr=0x20413a0) at /home/jp/DarkTable/darktable/src/control/control.c:1128\n    old = 0\n    s = 0x20413a0\n    threadid = 7\n    __FUNCTION__ = \"dt_control_work_res\"\n\n3  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n4  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 22 (Thread 0x7f037097c700 (LWP 6912)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 21 (Thread 0x7f037017b700 (LWP 6913)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 20 (Thread 0x7f036f97a700 (LWP 6914)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 19 (Thread 0x7f036f179700 (LWP 6915)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 18 (Thread 0x7f036e978700 (LWP 6916)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 17 (Thread 0x7f036e177700 (LWP 6917)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 16 (Thread 0x7f036d976700 (LWP 6918)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 15 (Thread 0x7f03537fe700 (LWP 6933)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 14 (Thread 0x7f0353fff700 (LWP 6934)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 13 (Thread 0x7f036d175700 (LWP 6935)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 12 (Thread 0x7f0375652700 (LWP 6936)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 11 (Thread 0x7f03bfdfc700 (LWP 6937)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 10 (Thread 0x7f03bf5fb700 (LWP 6938)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 9 (Thread 0x7f03bedfa700 (LWP 6939)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 8 (Thread 0x7f0378ec7700 (LWP 6941)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 7 (Thread 0x7f03786c6700 (LWP 6942)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 6 (Thread 0x7f0377ec5700 (LWP 6943)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 5 (Thread 0x7f03776c4700 (LWP 6944)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 4 (Thread 0x7f0376ec3700 (LWP 6945)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 3 (Thread 0x7f03766c2700 (LWP 6946)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 2 (Thread 0x7f0375ec1700 (LWP 6947)):\n0  0x0000003b852099a6 in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n1  0x0000003b8520848e in ?? () from /usr/lib64/libgomp.so.1\nNo symbol table info available.\n2  0x0000003b6ea07d90 in start_thread () from /lib64/libpthread.so.0\nNo symbol table info available.\n3  0x0000003b6def119d in clone () from /lib64/libc.so.6\nNo symbol table info available.\nThread 1 (Thread 0x7f0402387a00 (LWP 6896)):\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\nNo symbol table info available.\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\nNo symbol table info available.\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\nNo symbol table info available.\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\nNo symbol table info available.\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\nNo symbol table info available.\n5  0x00007f04041fbd38 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n    read_something = 0\n    fd = 0x2863850\n    buf = \"\\000\\000\\000\\000\\000\\000\\000\\000#6\\343o;\\000\\000\\000\\340\\322\\340q;\\000\\000\\000\\367k\\341q;\\000\\000\\000\\002\", '\\000' <repeats 23 times>\"\\240, `\\177\\002\\000\\000\\000\\000\\220f\\177\\002\\000\\000\\000\\000\\355\\342\\340q;\\000\\000\\000\\002\\000\\000\\200\\000\\000\\000\\000\\016\\364\\341q;\", '\\000' <repeats 11 times>, \"#6\\343o;\\000\\000\\000\\002\\000\\000\\210\\000\\000\\000\\000#6\\343o;\\000\\000\\000\\300q\\177\\002\\000\\000\\000\\000p\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\200;\\000\\000\\000\\200\\064~\\002\", '\\000' <repeats 12 times>, \"P\\316+\\002\\000\\000\\000\\000\\240@{\\002\\000\\000\\000\\000\\240@{\\002\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\200\\211r\\002\\000\\000\\000\\000\\340\\322\\340q;\\000\\000\\000\\002\\243\\342q;\\000\\000\\000\\000\\000\\000\\200;\\000\\000\\000\\030\\000\\000\\000\\060\\000\\000\\000\\220\\356\\351.\\377\\177\\000\\000\\320\\355\\351.\\377\\177\\000\\000\"...\n    name_used = 0x2834890 \"/tmp/darktable_bt_DFOHLW.txt\"\n    fout = 22\n    delete_file = 0\n    datadir = \"/usr/local/packages/darktable-1.1-20121003-jose/share/darktable\\000\\000\\000\\000\\000\\000\\000\\000\\000\\322\\v\\346o;\", '\\000' <repeats 11 times>\"\\300, \\326}\\002\\000\\000\\000\\000\\200\\060\\376\\001\\000\\000\\000\\000 \\000\\000\\000\\000\\000\\000\\000\\260\\232}\\002\", '\\000' <repeats 12 times>, \"p\\257\\240n;\\000\\000\\000\\000\\332+\\002\\000\\000\\000\\000\\310\\352\\351.\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\262\\241\\342q;\\000\\000\\000\\350\\352\\351.\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\262\\241\\342q;\\000\\000\\000\\330\\326}\\002\\000\\000\\000\\000\\300\\326}\\002\\000\\000\\000\\000\\030\\000\\000\\000\\000\\000\\000\\000\"...\n    command = 0x28d9800 \"gdb darktable 6896 -batch -x /usr/local/packages/darktable-1.1-20121003-jose/share/darktable/gdb_commands\"\n\n6  \nNo symbol table info available.\n7  0x00007f037c54ab97 in changed_callback (entry=0x0, dr=0x2734500) at /home/jp/DarkTable/darktable/src/libs/collect.c:934\n    d = 0xffffffff8ccc0800\n    stmt = 0x3b8981cc6c\n    iter = {stamp = 0, user_data = 0x2411820, user_data2 = 0x3b71e0fe60, user_data3 = 0x1fea0f8}\n    tree = 0x7f04042582b2\n    view = 0x2411820\n    listmodel = 0x0\n    treemodel = 0x3b71202620\n    query = \"`\\376\\340q;\\000\\000\\000\\323\u0308#7\", '\\000' <repeats 11 times>\"\\352, \\002\\000\\000I\\002\\000\\000\\360k\\001\\002\\000\\000\\000\\000\\n\\v+\\004\\004\\177\\000\\000\\360\\370,\\002\\000\\000\\000\\000\\200\\252\\375\\001\\000\\000\\000\\000\\360k\\001\\002\", '\\000' <repeats 20 times>, \"D\\352\\340q;\\000\\000\\000P\\005\\352.\\377\\177\\000\\000\\bF\\217\\002\\000\\000\\000\\000\\002\\000\\000@\", '\\000' <repeats 16 times>, \"\\001\\000\\000\\000\\240\\004\\352.\\377\\177\\000\\000\\002\\000\\000\\000\\377\\177\\000\\000#6\\343o;\\000\\000\\000\\001\\000\\000\\000\\004\\177\\000\\000 \\004\\033n;\", '\\000' <repeats 11 times>, \" \\303\\066\\002\\000\\000\\000\\000\\300\\261\\000\\002\\000\\000\\000\\000 \\303\\066\\002\\000\\000\\000\\000\\000\\370\\021p;\", '\\000' <repeats 11 times>, \" \\303\\066\\002\\000\\000\\000\\000\\320\\t\\342q;\\000\\000\\000\\000\\a\\352.\\377\\177\\000\\000\\220\\005\\352.\\377\\177\"...\n    property = 2\n    text = 0x7fff2eea08e0 \"\"\n    escaped_text = 0x7f03fc1db3a7 \"\\353\\001\\220H\\203\\304\\070[]\\303UH\\211\\345SH\\203\\354(H\\211}\u063fh\"\n    confname = \"\\240\\326b\\002\\000\\000\\000\\000\\001\", '\\000' <repeats 16 times>\"\\313, *\\002\\000\\000\\000\\000\\352\\002\\000\\000\\000\\000\\000\\000\\177\\372\\343#7\", '\\000' <repeats 19 times>\"\\360, \\370,\\002\", '\\000' <repeats 20 times>\"\\352, \\002\\000\\000\\000\\000\\000\\000I\\002\\000\\000\\000\\000\\000\\000\\352J\\210#7\\000\\000\\000`j8\\004\\004\\177\\000\\000R\\000\\000\\000R\", '\\000' <repeats 11 times>\"\\352, \\002\\000\\000I\\002\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\066\\001\\000\\000R\\000\\000\\000\\340\\003\\352.\\377\\177\\000\\000\\360\\370,\\002\\000\\000\\000\\000 \\004\\352.\\377\\177\\000\\000\\001\", '\\000' <repeats 14 times>\n    __FUNCTION__ = \"changed_callback\"\n    __PRETTY_FUNCTION__ = \"changed_callback\"\n\n8  0x00007f037c54cbd9 in collection_updated (instance=0x1fdaa80, self=0x2734500) at /home/jp/DarkTable/darktable/src/libs/collect.c:1516\n    d = 0x2734500\n\n9  0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n10 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n11 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n12 0x00007f040425f5fb in dt_control_signal_raise (ctlsig=0x1fe4790, signal=DT_SIGNAL_COLLECTION_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:114\n    extra_args = {{gp_offset = 16, fp_offset = 48, overflow_arg_area = 0x7fff2eea0d10, reg_save_area = 0x7fff2eea0c40}}\n    i_own_lock = 0\n\n13 0x00007f04041f2e57 in dt_collection_update_query (collection=0x2011370) at /home/jp/DarkTable/darktable/src/common/collection.c:580\n    query = \"(film_id in (select id from film_rolls where folder like '/home/jp/Pictures/Firework%'))\\000#7\\000\\000\\000\\024\\000\\000\\000\\000\\000\\000\\000#6\\343o;\\000\\000\\000\\024\\000\\000\\000\\000\\000\\000\\000p*\\224\\002\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\360y}\\002\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\300\\256\\000\\002\\000\\000\\000\\000\\070\\020\\352.\\377\\177\\000\\000\\245\\000\\000\\000\\000\\000\\000\\000\\000\\370\\021p;\\000\\000\\000\\351\\233\\342q;\\000\\000\\000\\360\\363|\\002\\000\\000\\000\\000\\006\\000\\000\\000\\000\\000\\000\\000\\006\\000\\000\\000\\000\\000\\000\\000\\360\"...\n    confname = \"plugins/lighttable/collect/mode0\\000\\060\\000\\002\\000\\000\\000\\000#6\\343o;\\000\\000\\000\\360y}\\002\\000\\000\\000\\000\\070\\237|#7\\000\\000\\000\\360y}\\002\\000\\000\\000\\000\\360y}\\002\\000\\000\\000\\000\\001\\000\\000\\000\\000\\000\\000\\000\\300\\256\\000\\002\\000\\000\\000\\000(\\017\\352.\\377\\177\\000\\000\\275\\000\\000\\000\\000\\000\\000\\000\\000\\370\\021p;\\000\\000\\000\\351\\233\\342q;\\000\\000\\000\\350\\367\\021p;\\000\\000\\000\\245\\023\\341q;\\000\\000\\000\\000z}\\002\\000\\000\\000\\000\\360y}\\002\\000\\000\\000\\000p\\257\\240n;\\000\\000\\000\\000\\370\\021p;\\000\\000\\000\\350\\367\\021p;\\000\\000\\000\\021B\\343q;\\000\\000\\000p\\363c\\002\\000\\000\\000\"\n    complete_query = 0x2701800 \"\\360\\036\\201\\002\"\n    num_rules = 1\n    conj = {0x7f0404378ed8 \"and\", 0x7f040437968d \"or\", 0x7f0404379690 \"and not\"}\n    stmt = 0x27c2948\n    cquery = 0x28d98a0 \"select distinct id from images where   (flags & 256) != 256 and ((film_id in (select id from film_rolls where folder like '/home/jp/Pictures/Firework%'))) order by filename limit ?1, ?2\"\n    __FUNCTION__ = \"dt_collection_update_query\"\n    __PRETTY_FUNCTION__ = \"dt_collection_update_query\"\n\n14 0x00007f037d58ad85 in _lib_filter_update_query (self=0x26097c0) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:232\nNo locals.\n15 0x00007f037d58aad2 in gui_init (self=0x26097c0) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:162\n    d = 0x269e840\n    widget = 0x27d79f0\n\n16 0x00007f04042d11b3 in dt_view_manager_switch (vm=0x2450220, k=1) at /home/jp/DarkTable/darktable/src/views/view.c:279\n    w = 0x26ef9d0\n    plugin = 0x26097c0\n    plugins = 0x23c8560 = {0x26097c0, 0x2604de0, 0x25fdf50, 0x26296d0}\n    endmarker = 0x1fd99d0\n    error = 0\n    v = 0x2450220\n    newv = 1\n    nv = 0x2450340\n\n17 0x00007f040425740e in dt_ctl_switch_mode_to (mode=DT_DEVELOP) at /home/jp/DarkTable/darktable/src/control/control.c:1380\n    oldmode = DT_LIBRARY\n    widget = 0x22cf8f0\n    buf = \"switch to lighttable mode\\000\\003!7\\000\\000\\000\\030-DT\\373!\\371?\\240\\\"\\203\\002\\000\\000\\000\\000\\020\\030\\352.\\377\\177\\000\\000\\vz\\003!7\\000\\000\\000\\240\\\"\\203\\002\\000\\000\\000\\000\\240\\\"\\203\\002\\000\\000\\000\\000\\030\\350\\000\\304\\003\\177\\000\\000\\327|\\003!7\\000\\000\\000@\\276\\066\\002\", '\\000' <repeats 13 times>, \"\\020*\\002\\000\\000\\000\\000\\000\\020*\\002\\000\\000\\000\\000\\020a:\\002\\000\\000\\000\\000z\\025\\342p;\", '\\000' <repeats 19 times>\"\\240, \\\"\\203\\002\\000\\000\\000\\000mx\\003!7\\000\\000\\000\\240\\\"\\203\\002\\000\\000\\000\\000\\347\\202\\003!7\\000\\000\\000h\\200*!7\\000\\000\\000\\000\\020*\\002\\000\\000\\000\\000\\207\\231 \\006\\000\\000\\000\\000@*1\\002\\000\\000\\000\\000X\\226/\\002\\000\\000\\000\\000\\000\\020*\\002\\000\\000\\000\\000\\240\"...\n    i_own_lock = 0\n    error = 1847269120\n\n18 0x00007f04042ad9fb in _gui_switch_view_key_accel_callback (accel_group=0x22bc400, acceleratable=0x22cb030, keyval=100, modifier=0, p=0x3) at /home/jp/DarkTable/darktable/src/gui/gtk.c:558\n    view = 3\n    mode = DT_DEVELOP\n\n19 0x000000372374f4e8 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n20 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n21 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n22 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n23 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n24 0x00000037236702d4 in gtk_accel_group_activate () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n25 0x00000037236716d9 in gtk_accel_groups_activate () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n26 0x000000372389db1e in gtk_window_activate_key () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n27 0x000000372389dba7 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n28 0x000000372374ed03 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n29 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n30 0x0000003b71e20b7c in ?? () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n31 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n32 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\nNo symbol table info available.\n33 0x0000003723883f41 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n34 0x000000372374c8f7 in gtk_propagate_event () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n35 0x000000372374cb8b in gtk_main_do_event () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n36 0x0000003723e6207c in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\nNo symbol table info available.\n37 0x0000003b6fe44f3d in g_main_context_dispatch () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n38 0x0000003b6fe45738 in ?? () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n39 0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\nNo symbol table info available.\n40 0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\nNo symbol table info available.\n41 0x00007f04042aed89 in dt_gui_gtk_run (gui=0x20665e0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n    widget = 0x22cf8f0\n    tb = 8\n\n42 0x0000000000400a66 in main (argc=1, argv=0x7fff2eea2738) at /home/jp/DarkTable/darktable/src/main.c:25\nNo locals.\n```\n. @jcsogo similar - if not the same with \"map\" ('m'):\n```\n0x0000003b6dee43fd in read () from /lib64/libc.so.6\n0  0x0000003b6dee43fd in read () from /lib64/libc.so.6\n1  0x0000003b6de79ed8 in _IO_new_file_underflow () from /lib64/libc.so.6\n2  0x0000003b6de7af2e in _IO_default_uflow_internal () from /lib64/libc.so.6\n3  0x0000003b6de6f21a in _IO_getline_info_internal () from /lib64/libc.so.6\n4  0x0000003b6de6e06b in fgets () from /lib64/libc.so.6\n5  0x00007f6517b57d38 in _dt_sigsegv_handler (param=11) at /home/jp/DarkTable/darktable/src/common/darktable.c:132\n6  \n7  0x00007f6490305b97 in changed_callback (entry=0x0, dr=0x1180600) at /home/jp/DarkTable/darktable/src/libs/collect.c:934\n8  0x00007f6490307bd9 in collection_updated (instance=0x94ca80, self=0x1180600) at /home/jp/DarkTable/darktable/src/libs/collect.c:1516\n9  0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n10 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\n11 0x0000003b71e2a161 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n12 0x00007f6517bbb5fb in dt_control_signal_raise (ctlsig=0x956790, signal=DT_SIGNAL_COLLECTION_CHANGED) at /home/jp/DarkTable/darktable/src/control/signal.c:114\n13 0x00007f6517b4ee57 in dt_collection_update_query (collection=0x983370) at /home/jp/DarkTable/darktable/src/common/collection.c:580\n14 0x00007f6491345d85 in _lib_filter_update_query (self=0xfabf90) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:232\n15 0x00007f6491345ad2 in gui_init (self=0xfabf90) at /home/jp/DarkTable/darktable/src/libs/tools/filter.c:162\n16 0x00007f6517c2d1b3 in dt_view_manager_switch (vm=0xdf2bf0, k=0) at /home/jp/DarkTable/darktable/src/views/view.c:279\n17 0x00007f6517bb340e in dt_ctl_switch_mode_to (mode=DT_LIBRARY) at /home/jp/DarkTable/darktable/src/control/control.c:1380\n18 0x00007f6517c099fb in _gui_switch_view_key_accel_callback (accel_group=0xc5ec00, acceleratable=0xc6d030, keyval=108, modifier=0, p=0x2) at /home/jp/DarkTable/darktable/src/gui/gtk.c:558\n19 0x000000372374f4e8 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n20 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n21 0x0000003b71e20d37 in ?? () from /lib64/libgobject-2.0.so.0\n22 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n23 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\n24 0x00000037236702d4 in gtk_accel_group_activate () from /usr/lib64/libgtk-x11-2.0.so.0\n25 0x00000037236716d9 in gtk_accel_groups_activate () from /usr/lib64/libgtk-x11-2.0.so.0\n26 0x000000372389db1e in gtk_window_activate_key () from /usr/lib64/libgtk-x11-2.0.so.0\n27 0x000000372389dba7 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n28 0x000000372374ed03 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n29 0x0000003b71e0ea44 in g_closure_invoke () from /lib64/libgobject-2.0.so.0\n30 0x0000003b71e20b7c in ?? () from /lib64/libgobject-2.0.so.0\n31 0x0000003b71e29f33 in g_signal_emit_valist () from /lib64/libgobject-2.0.so.0\n32 0x0000003b71e2a302 in g_signal_emit () from /lib64/libgobject-2.0.so.0\n33 0x0000003723883f41 in ?? () from /usr/lib64/libgtk-x11-2.0.so.0\n34 0x000000372374c8f7 in gtk_propagate_event () from /usr/lib64/libgtk-x11-2.0.so.0\n35 0x000000372374cb8b in gtk_main_do_event () from /usr/lib64/libgtk-x11-2.0.so.0\n36 0x0000003723e6207c in ?? () from /usr/lib64/libgdk-x11-2.0.so.0\n37 0x0000003b6fe44f3d in g_main_context_dispatch () from /lib64/libglib-2.0.so.0\n38 0x0000003b6fe45738 in ?? () from /lib64/libglib-2.0.so.0\n39 0x0000003b6fe45c85 in g_main_loop_run () from /lib64/libglib-2.0.so.0\n40 0x000000372374bbb7 in gtk_main () from /usr/lib64/libgtk-x11-2.0.so.0\n41 0x00007f6517c0ad89 in dt_gui_gtk_run (gui=0xc16ee0) at /home/jp/DarkTable/darktable/src/gui/gtk.c:952\n42 0x0000000000400a66 in main (argc=1, argv=0x7ffff1837ad8) at /home/jp/DarkTable/darktable/src/main.c:25\n```\n. @jcsogo excellent, things seems to be working now :)\n@hanatos I think this is ready for you to look at\n. @jcsogo there was a \n(darktable:18229): GLib-CRITICAL **: g_dir_read_name: assertion `dir != NULL' failed\n(darktable:18229): GLib-CRITICAL **: g_dir_rewind: assertion `dir != NULL' failed\nthough\n. @jcsogo didn't see it before I did a quit -- did an import, moved around between different folders, went into darkroom / map mode, and back again\n. Yeah, I don't necessary like the buttons on all the time too - it should be on mouse-over. There is no option for that yet though. I will report upstream - there are other nice-to-have features too, like slideshow and filmstrip.\nThe banner will only be added if there is no title now.\nIdeally a more full featured library like galleria.io should be used, but that requires a lot more web-fu - maybe something for 1.2+.\n. Doing a galleria.io version instead\n. Closing this PR until all tethering changes are in place\n. Related is http://www.darktable.org/redmine/issues/9130\nI got a couple of updates on tethering in my 'tether' branch.\n. I have created http://www.darktable.org/redmine/issues/9200 for the slideshow functionality, and http://www.darktable.org/redmine/issues/9201 for the web gallery functionality. The two concerns are separate, but the Supersized framework provided a quick solution for both.\nLightbox 2 which being used currently doesn't have image rescale functionality, so it would be more work and I don't know anything about HTML/JavaScript/CSS other than the basic stuff.\n. I generally like this, including the higher contrast :)\nA couple of comments\n- The file type in the background should be removed - the information is available in \"Image information\"\n- The toggles should be moved to the \"Preferences\"\n- Using the entire background for the color labels is too much I think. Using a smaller portion would be better, as it doesn't removes focus as much from the image; like Photo Mechanic.\n- The modes should be exclusive to each other - e.g. no color label circles, if color label background is enabled\nNice job !\n. ",
    "rikles": "Sorry,\nI'm not very friendly with pull request.\nI just want you to merge my detachable branch on the official detachable branch.\nI've updated my branch merging the master into it to get it up-to-date.\nI don't think the branch is ready to merge into master. Still to do : restore panels position on dt start and check the code. I'm not a confirmed C developper.\nI've not seen where change the pull request.\n. Hi,\nI've finally resolve the orientation problem. Aspect ratios are now fixed : 3:2 -> landscape, 2:3 -> portrait.\nI've so add missing corresponding portrait/landscape ratios.\nDefault is now \"constant border\".\nAspect ratio \"image\" is now good working with cropped/rotated pictures.\nI've also test legacy_params. It seems to work fine.\nIf your tests are OK, I think this can be merge into master.\n. Hi,\nso, i've think about it again. In your solution, if i've well understand it, i'll remove from the list all portrait aspect ratios and play only with \"auto orientation\" checkbox. But in this case, how do you make a preset 2:3 (portrait oriented) that always apply 2:3 aspect no matter incoming orientation ? you enter a manual aspect with checkbox unchecked ?\nI would prefer, in this case, to keep only landscape aspects to reduce aspect combobox items list (like you suggest) and transform the auto-orientation checkbox in a \"3-states\" widget auto, landscape, portrait. I think it will be more user friendly. What do you think ?\nFor the litlle bug on 100% frame offset : it come from a round down on frame width/height calculation to be sure to never overflow the output buffer. But i didn't care very much because of this situation is not very common, if a user want make a frame line sticked to outside border (like a \"marie-louise\"), he'll probably do the right inverse : flip frame and border color and create a 0% offset frame line ;).... but.... ok, in this case, there is a little problem..., i should not fix the max frame size to 50%...O_o...\n. I've replace the \"auto-orientation\" checkbox with 3 toggle buttons \"auto, landscape, portrait\" and remove double aspect ratio like 3:2, 2:3.\nI've also fix a little bug on frame line positionning.\n. OK, cool.\nThank you helped me.\n\nLoic\n\nDe\u00a0: hanatos reply@reply.github.com\n\u00c0\u00a0: Loic GUIBERT lfdummy-github@yahoo.fr \nEnvoy\u00e9 le : Mardi 19 juin 2012 1h48\nObjet\u00a0: Re: [darktable] Borders (#17)\nthanks, this is now in git master.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/17#issuecomment-6410186\n. OK, I thought  the legacy_params function is for the \"user saved presets\" only and the developer who change the module version must change hard-coded presets by hand.\nSorry ;)\n. ",
    "richardwonka": "I have added those two lines in a separate file in my branch 'wonky' that will be useful to adapt and source for some automation.\n. All files have been set up and a quick hack is in tools/ that will update these modelines on demand.\n. I have issued a new pull request from my local master branch just before I wrote comment here. Hope that's okay.\n. Aaah, I was relying on legacy code without checking it. Have updated the line in beautify_style.sh, too. :-)\nThanks for the pointer to the help file. I hope I'll be getting things right soon.\n. One thing: The term \"border\" is much better than \"framing\" as in photography framing is also used in a composition context.\nCould you set the module's name to \"border\" or \"borders\" please?\n. I have applied some changes that have been suggested. Not sure if this is up to date now. - I guess it would have been more useful to create a topic branch for this...\n. I have updated my forked master branch from upstream and created a feature branch called editor_modelines.\nThank you for your patience.\n. i capitalised the first letter of a sentence, as is somewhat common. if no capitalisation is a project policy it strikes me as appealing for some uses (like modules, keywords, etc..), but as soon as we write full sentences it will just look like we are too lazy to type well and have a quick email-feel. e.g. this comment. qed. ;-)\n. As for colloquial language. To some extent I am a fan, but shortened forms like \"haven't\" or \"didn't\" do not belong in written production text. We might as well put txt-style there:\nY U no hv pix?\n:-P\n. Oh, and the ellipsis indicates a connection between the two disjunct lines allowing the reader to read and understand a full sentence even though it has been split in the middle.\n. still looks good, by the way. :-)\n. +1 for inclusion, please.\n. Oh, sorry, that doesn't belong there. Please ignore that. Gah, Apparently I still haven't figured out how to keep a branch clean.\nThis pull request has nothing to do with 8644. This Pull request was only meant to be about https://github.com/richardwonka/darktable/commit/1e8adc72620274d6b22a44e6dca7f21b2680d88a\n. Aaah, that's better.\n. it was - IIRC...---\ngit br wording.messy\ngit reset --hard upstream/master\ngit co wording.messy list of files I actually wanted in this branch\ngit diff upstream/master     # to check if the changes are what I want them to be\ngit commit -a\ngit br -D wording.messy\nI think.\nI also found that\ngit reset --hard ORIG_HEAD\nwoks wonders at times..\n. Oh, and I had to sneak a \ngit push origin :wording\nin between to get rid of the messy branch at github\nand then \ngit push origin wording\n. @hanatos I was considering going for DIR instead of FOLDER to shorten things further, but saw that everything is in full words. Anyway, if #8785 comes through, then this won't be an issue anyway.\n. Odd.. I did grep -i the src/ tree... Thanks for cleaning this up. \n. Sorry, I was not aware.\nWill stick to one change per request in the future.\nThanks for the heads up.\nRichard\n\nRichard Wonka\nrichard.wonka@gmail.com\n64/17 Ban Muntana, Land & House, Chalong, Rawai, Phuket, 83130, Thailand\n+66 83 185 7289\nOn Jul 28, 2013 2:31 PM, \"Boucman\" notifications@github.com wrote:\n\nplease do only one logical change per pull-request, anything else makes\nmuch more job for us\nmoreover, we are working on that import problem separately and I think\nthat option had disapeared\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/273#issuecomment-21678505\n.\n. On 29 July 2013 20:25, Boucman notifications@github.com wrote:\nwe tend to prefer en_GB but the standard for code in the open source\ncommunity is en_US so we are OK to have an en_GB translation. However if\nour source code is a mixture of en_US and en_GB it would be nice to have\nthat fixed. Please do two pull requests, one fixin the code to be proper\nen_US and one adding en_GB after that.\n\nI suggest creating two more translations: en and en_US -\nThis will facilitate future corrections, keeping all language related\nthings in one place and will keep me from editing code I don't understand.\n(Because I really don't)\nen can then be a link to (or copy of)  en_GB if you prefer.\n\nthere are too many problems with that particular pull request (binary\nfiles added and removed, multiple issues in the same pull request etc...)\nso I am closing it. You are free to recreate it (see above)\n\nMakes sense. I will have to find out how to avoid these things in the\nfuture. Will do my best.\nI will also create an issue regarding this to centralise communication on\nthe topic.\nAgain, sorry for the inconvenience, I am somewhat out of my depth in this\npractical stuff - have not been coding in years. My current related work in\nUI and functionality testing is more abstract; I rely on other people to\nimplement the changes I design. I know about structure, patterns,\nconsistency, user interfaces and language - but my hacking skills are rusty\nat best. :-p\nLet's see what I can do, then.\n. see http://www.darktable.org/redmine/issues/9541\n. ",
    "christte": "Err, closing this one, resubmitting with correct commit history. Sorry for the static.\n. Comments from jcsogo on IRC made me think my description was too abstract, so here's a demo: http://tinyurl.com/dtautocomp1 (ogv screencast)\nMy next idea when time allows is to add autocomplete support for file paths as well.\njcsogo also suggested to rewrite the function a bit so that $( is not needed to trigger the dropdown list. I'll have a look into that as well.\n. Your commit breaks the Linux build. The solution might be to add -lintl only when (CMAKE_SYSTEM_NAME MATCHES \"FreeBSD\").\n. Great! Merged!\n. I were able to log on and with some fiddling I got a list of albums. However, during export, I get the following crash:\n*** glibc detected *** /opt/darktable-fb/bin/darktable: double free or corruption (fasttop): 0x00007fffe0001610 ***\n======= Backtrace: =========\n/lib/x86_64-linux-gnu/libc.so.6(+0x7e626)[0x7ffff73bc626]\n/opt/darktable-fb/lib/darktable/plugins/imageio/storage/libfacebook.so(store+0x44b)[0x7fff68ae5ce1]\n/opt/darktable-fb/bin/../lib/darktable/libdarktable.so(+0xf65fe)[0x7ffff7a0e5fe]\n/opt/darktable-fb/bin/../lib/darktable/libdarktable.so(dt_control_export_job_run+0x476)[0x7ffff7a0e055]\n/opt/darktable-fb/bin/../lib/darktable/libdarktable.so(dt_control_run_job+0x2ba)[0x7ffff7a059c8]\n/opt/darktable-fb/bin/../lib/darktable/libdarktable.so(dt_control_work+0x33)[0x7ffff7a063e6]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x7e9a)[0x7ffff7702e9a]\n/lib/x86_64-linux-gnu/libc.so.6(clone+0x6d)[0x7ffff74304bd]\nFull backtrace from a crash:\nhttp://chr.tellefsen.net/fb-branch-crash.txt (However, the image actually gets uploaded! :-) )\njson library version: Ubuntu Precise: libjson-glib-1.0-0 (0.14.2-1)\nOther observations:\n- On my first logon (only first time after I had to authenticate) the albums dropdown was empty. I did not have any albums. I were not able to find a way to add a new album. After adding one album via Facebook and restarting darktable the dropdown was populated and I were able to add new albums.\n- I have to copy an url from my browser each time i log on.  I guess this is a tradeoff caused by a wish to avoid including a dependency to a http-library? Maybe a few details on tradeoffs and design would be nice to have at the top of facebook.c\n- Some junk printed to stdout during logon/export. (maybe Debug only?)\n- Creating new album on export works fine (but dt still crashes)\nI haven't had time to look too closely at the code yet.\n. Bullet 2: Correction: Credentials are stored correctly when compiling with --enable-gnome-keyring and having enabled gnome keyring in settings.\n. My first attempt at exporting gave the following error: (and the image is not exported)\n``\n(darktable:11048): GLib-WARNING **: GError set over the top of a previous GError or uninitialized memory.\nThis indicates a bug in someone's code. You must ensure an error is NULL before it's set.\nThe overwriting error message was: <none>:1: Parse error: unexpected character<', expected value\n (darktable:11048): CRITICAL : fb_parse_response: assertion `(ret)' failed\n```\nI have not been able to reproduce it (yet).\nAlso, the following metadata causes a crash: (replace (aaa) with an @). I believe it is the Description that causes the problem here.\nTitle: Around Nedalshytta\nDescription: Email: photos(aaa)tellefsen.net\nCreator: Christian Tellefsen\nPublisher: christian-foto(aaa)tellefsen.net\nRights: All rights reserved.\nAn issue which probably can be fixed later:\n- \"Failed to get parameters from storage module. Aborting export\" <--- When you click \"export\" but have forgotten to log on\n. Reproduced a crash when working with an empty database (try running dt with e.g. darktable --configdir /tmp --cachedir /tmp ). It may be the same error as the first one in my previous comment, but this time from within GDB..\n```\n\nGdk:ERROR:/build/buildd/gtk+2.0-2.24.10/gdk/gdkregion-generic.c:1114:miUnionNonO: assertion failed: (r->x1 < r->x2)\n\nGdk:ERROR:/build/buildd/gtk+2.0-2.24.10/gdk/gdkregion-generic.c:1110:miUnionNonO: assertion failed: (y1 < y2)\nProgram received signal SIGABRT, Aborted.\n[Switching to Thread 0x7fffeca3b700 (LWP 18895)]\n0x00007ffff736a445 in raise () from /lib/x86_64-linux-gnu/libc.so.6\n```\nAll metadata attributes for the image are empty.\nBacktrace:\n```\n0  0x00007ffff736a445 in raise () from /lib/x86_64-linux-gnu/libc.so.6\n1  0x00007ffff736dbab in abort () from /lib/x86_64-linux-gnu/libc.so.6\n2  0x00007ffff70a6f9d in g_assertion_message ()\nfrom /lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007ffff70a74c2 in g_assertion_message_expr ()\nfrom /lib/x86_64-linux-gnu/libglib-2.0.so.0\n4  0x00007ffff6b705d4 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n5  0x00007ffff6b7142f in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n6  0x00007ffff6b71c47 in gdk_region_union ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n7  0x00007ffff6b7b797 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n8  0x00007ffff6b7b943 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n9  0x00007ffff6755d2a in gtk_widget_queue_draw_area ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n10 0x00007ffff675ce53 in gtk_widget_queue_draw ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n11 0x00007ffff675cf88 in gtk_widget_set_sensitive ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n12 0x00007ffff65af2f3 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n13 0x00007ffff6dffca2 in g_closure_invoke ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n14 0x00007ffff6e10d71 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n15 0x00007ffff6e19099 in g_signal_emit_valist ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n16 0x00007ffff6e19242 in g_signal_emit ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n17 0x00007ffff6759340 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n18 0x00007ffff675cf28 in gtk_widget_set_sensitive ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n19 0x00007ffff65ae879 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n20 0x00007ffff65b5daf in gtk_combo_box_set_model ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n21 0x00007fff63c8487d in ui_reset_albums_creation (ui=0xb6f180)\nat /home/christian/prog/darktable-fb/src/imageio/storage/facebook.c:925\n\n22 0x00007fff63c85cb5 in finalize_store (self=0xb6eef0, data=0x7fffe0066d00)\nat /home/christian/prog/darktable-fb/src/imageio/storage/facebook.c:1195\n\n23 0x00007ffff7a0b6f1 in dt_control_export_job_run._omp_fn.0 ()\nat /home/christian/prog/darktable-fb/src/control/jobs/control_jobs.c:1297\n\n```\nWhen I restart darktable the export works perfectly.\n. Ok. Ref 2) I'll try to reproduce the crash here and do some digging.\nchubinou notifications@github.com wrote:\n\n1) parse response error: I didn't encounter this issue, it looks like a\nbad response from the server (or perhaps a network problem), I added\ntrace for curl with the macro FACEBOOK_EXTRA_VERBOSE, it might be\nuseful for getting more details if we encounter this problem again\n2) title/description export error : I don't think this is related to\nthe content of theses fields, I tried to upload some photos with fields\nlike &\u00e9#\"([\u00f6*\u00e2\u2122 without any issue\n3) \"Failed to get parameters from storage module. Aborting export\" :\nactually this behavior is consistent with other exporter. \n4) crash in ui_reset_albums_creation: I fixed some stuff in my\nmanagement of combox models, I think it should be better\nand, ... I think I've made too much tests with this web app (especially\nauthorizing/deauthorizing the application) and it seems that the\napplication is now being taged as phishing/spam, each time I log (no\nmatter what account) I have a beautiful  \"SECURITY WARNING: The above\nURL is NOT NOT VALID FOR A CASH CARD OR GIFT CARD. Giving away the URL\nmay result in your account being HIJACKED.\"   yay  \\o/\nI think I should recreate the app on facebook side to get one with a\nclean state, but I'll do it once it is stabilized enough\nI had some difficulty reproducing the bugs you found, so I hope theses\nchange will be enough. I didn't notice anything particular using a\nfresh configdir/cachedir.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/52#issuecomment-9054439\n\n\nSent from my Android phone with K-9 Mail. Please excuse my brevity.\n. I got this warning when exporting a 4320x2868 pixel image:\n\n    ** (darktable:1370): CRITICAL **: fb_query_post: assertion `(res == CURLE_OK)' failed\n\ngdb tells me res == 56, which means \"Failure receiving network data\" 1\nFrom facebook docs[2]:\n\"It is strongly recommended that you scale the image in your application before adding it to the request. The largest dimension should be at most 720 pixels (the largest display size Facebook supports).\"\nI propose to limit the maximum upload size to 720 pixels (or maybe larger, I've uploaded 1024x1024 without trouble).\n[1] http://curl.haxx.se/libcurl/c/libcurl-errors.html\n[2] https://developers.facebook.com/docs/reference/rest/photos.upload/\n. These issues remain, I think:\n- fix crash caused by clearing ui->model_album\n- fix max picture size?\n- \"fixme\" comment\n- Rebase to make it possible to merge your pull request\n. It seems we weren't able to nail the crash completely yet. :-/\n``` gdb\n glibc detected  /opt/darktable-fb/bin/darktable: double free or corruption (fasttop): 0x00007fffe0096230 *\n\nGdk:ERROR:/build/buildd/gtk+2.0-2.24.10/gdk/gdkregion-generic.c:1110:miUnionNonO: assertion failed: (y1 < y2)\nProgram received signal SIGABRT, Aborted.\n[Switching to Thread 0x7fffeca27700 (LWP 7607)]\n0x00007ffff7356445 in raise () from /lib/x86_64-linux-gnu/libc.so.6\n(gdb) where\n0  0x00007ffff7356445 in raise () from /lib/x86_64-linux-gnu/libc.so.6\n1  0x00007ffff7359bab in abort () from /lib/x86_64-linux-gnu/libc.so.6\n2  0x00007ffff7092f9d in g_assertion_message ()\nfrom /lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007ffff70934c2 in g_assertion_message_expr ()\nfrom /lib/x86_64-linux-gnu/libglib-2.0.so.0\n4  0x00007ffff6b5c500 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n5  0x00007ffff6b5d42f in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n6  0x00007ffff6b5dc47 in gdk_region_union ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n7  0x00007ffff6b67797 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n8  0x00007ffff6b67943 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgdk-x11-2.0.so.0\n9  0x00007ffff6741d2a in gtk_widget_queue_draw_area ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n10 0x00007ffff6748e53 in gtk_widget_queue_draw ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n11 0x00007ffff659d312 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n12 0x00007ffff6debca2 in g_closure_invoke ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n13 0x00007ffff6dfcd71 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n14 0x00007ffff6e05099 in g_signal_emit_valist ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n15 0x00007ffff6e05242 in g_signal_emit ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n16 0x00007ffff6621fdd in gtk_list_store_remove ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n17 0x00007ffff662276c in gtk_list_store_clear ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n18 0x00007fff62a78a86 in ui_reset_albums_creation (ui=0xb86b50)\nat /home/christian/prog/darktable-fb/src/imageio/storage/facebook.c:944\n\n19 0x00007fff62a7a0e9 in finalize_store (self=0xb85180, data=0x7fffe006d460)\nat /home/christian/prog/darktable-fb/src/imageio/storage/facebook.c:1232\n\n20 0x00007ffff7a057b0 in dt_control_export_job_run._omp_fn.0 ()\n```\nI'll try to do some digging when I have time.\n. I think I have found the problem.\nThe gtk_combo_box_set_active_iter() may have been a wild goose chase. The real problem is that finalize_store() is  calling gtk functions from outside the GUI thread.\nFix, following a nice hint from @houz:\nadd gdk_threads_enter() and gdk_threads_leave() at the top and bottom of the finalize_store() function.\nAs far as I can see this is the only place where facebook.c operates on widget information outside the GUI thread.\nI haven't tested it through, but I'll have a go tomorrow. If that fixes the problem I think it's time to merge :-)\n. On 07/10/12 18:03, chubinou wrote:\n\nOh, I compile darktable without the openmp support, because I have \nsome issues with it (the export crash in pixelpipe_hb.c, but it works \nfine with the ppa version) but it's not related to my exporter as it \ncrash as well with the other exporters. It might be the reason I \ndidn't see the problems you had\nI added the guards to the function but I can't test it.\n\nAh, that makes it even more likely we're on the right track now! :-)\nI'll do some testing when I can, tonight or tomorrow.\nChristian\n. Merged!\nI found a small bug though:\nhttp://www.darktable.org/redmine/issues/8982\n. On 08/10/12 20:49, chubinou wrote:\n\ngreat \\o/\nI'll look at this issue as soon as possible\nI remember having the same problem working on another module.\n\nI think what happens is that when you return to lightroom, darktable \nsends a signal to show all gtk widgets.\nI don't recall exactly how to fix it though.. You might need to hide the \nwidgets when gui_reset() is called.\n. I did a bit of testing and here's my first impressions.\nFirst: Nice feature!\nI like the patch but as Simon wrote a merge needs to wait until at least we create a post-1.1 branch.\nUntil then there's a couple of points which might be addressed:\nThe text colour is static and may blend with the background, which you mention yourself. Maybe give it a tooltip like box as background or an adaptive colour.\nThe crop info could be extended with a percentage and possibly the aspect ratio, unless it becomes visually intrusive.\nRotate: I might want the text to be positioned at the start of the  line rather than the end. This would prevent the text from moving all over the place. Maybe it is not a problem when the text is made more visible.\nThe max crop size does not match the image size. This may be less relevant though as the final image size is dependent on a few other modules, like framing.\nChristian\n. Hi Jiri! Thank you for the patch. It is much appreciated.\nI'm adding a couple of comments for the benefit of the other developers.\nThe interface were changed in libgphoto2 2.5.0, released 2012-07-10.\nRef\nhttp://sourceforge.net/p/gphoto/code/12735/\nand\nhttp://sourceforge.net/projects/gphoto/files/libgphoto/2.5.0/\nThis patch is appropriate for version 2.5.0. Unfortunately, many distributions are still on 2.4.x. We'll need to do different calls for libgphoto => 2.5.0 and < 2.5.0.\n. We need to handle both gphoto 2.4 and 2.5. I am closing this pull request but taking your input with me in a workaround.\nSee https://github.com/darktable-org/darktable/pull/203\n. Or use a cmake trick to limit the change to gcc >= 4.8\nhttp://stackoverflow.com/questions/4058565/check-gcc-minor-in-cmake\n. Ok. I'll merge this as a temp bugfix, and do a rewrite for pkg-config later.\n. Thanks :)\n. Thanks!\n. Thanks for the contribution!\n. Thank you!\n. Going to fix this up a bit + get in support for osx.. might\n. s/an/a/\n. s/an/a/\n. Fixme needs to be fixed?\n. After an amount of digging and some input from @dinamic, I discovered that crash 2) is caused by the gtkcombobox model being updated. \nThe following code is needed before nuking the model to avoid a crash:\n\ngtk_combo_box_set_active_iter(ui->comboBox_album, NULL);\n\nI propose to apply the following diff:\n\n--- a/src/imageio/storage/facebook.c\n+++ b/src/imageio/storage/facebook.c\n@@ -731,6 +731,9 @@ static void ui_refresh_users(dt_storage_facebook_gui_data_t \n   GSList *accountlist= load_account_info();\n   GtkListStore *list_store = ui->model_username;\n   GtkTreeIter iter;\n+\n+  // reset iter before clearing model to avoid a crash\n+  gtk_combo_box_set_active_iter(ui->comboBox_username, NULL);\n   gtk_list_store_clear(list_store);\n   gtk_list_store_append(list_store, &iter);\n\n@@ -779,6 +782,9 @@ static void ui_refresh_albums(dt_storage_facebook_gui_data_t\n     goto cleanup;\n   }\n\n+  // reset iter before clearing model to avoid a crash\n+  gtk_combo_box_set_active_iter(ui->comboBox_username, NULL);\n+\n   GtkTreeIter iter;\n   gtk_list_store_clear(ui->model_album);\n   gtk_list_store_append(ui->model_album, &iter);\n@@ -932,6 +938,8 @@ static void ui_login_clicked(GtkButton *button, gpointer dat\n\n static void ui_reset_albums_creation(struct dt_storage_facebook_gui_data_t *ui)\n {\n+  // iter must be reset before nuking the model if we want to avoid crashing.\n+  gtk_combo_box_set_active_iter(ui->comboBox_album, NULL);\n   gtk_list_store_clear(ui->model_album);\n   gtk_entry_set_text(ui->entry_album_summary, \"\");\n   gtk_entry_set_text(ui->entry_album_title, \"\");\n@@ -1099,6 +1107,7 @@ void gui_init(struct dt_imageio_module_storage_t *self)\n void gui_cleanup(struct dt_imageio_module_storage_t *self)\n {\n\n+  free(self->gui_data);\n }\n\n /* reset options to defaults */\n\n. Not a major issue, but g_return_val_if_fail() should be reserved as an alternative to assert().\nAccording to GTK docs the function should be used to test \"if (programming error detected) return\".\n. optionally\n. neat!\n. \"number of CPUs\" ?\n. Would this be more readable presented on two lines? Also, darktable is always written with lowecase D.\n\nThe darktable configuration is finished.\nTo build and install darktable you need to type:\n. Suggestion: Separate sentences, lowercase D.\n\ndarktable finished building. To actually install darktable you need to type:\n. This assignment overrides the value set by parse_args, causing -j to be ignored.\nSuggestion: Replace line 243 with:\nif [ $MAKE_TASKS -lt 1 ] ; then\n    MAKE_TASKS=$(num_cpu)\nfi\n. Not sure if I get what you mean in your last comment :-) I've fixed it in master the way I sughested above, but feel free to share additional fixes or suggestions.\n. pid_t is 32bit int.\n64 should be sufficient: strlen(\"/proc/[int64_max]/cmdline\") < 64.. This should always work as long as the name of the dt binary contains 'darktable'. This also works when dt is launched from a script.. ",
    "hanatos": "thanks, this is now in git master.\n. @richardwonka, i like the new wording. much shorter :)\n@boucman: `git rebase -i' is great. allows you to reorder/drop/sqash/alter commits. especially reordering is easy, you just reorder the lines in the oneline log that comes up in your editor when issuing this command.\n. i don't have a 7d, so change of behaviour doesn't worry me personally ;)\nthere's no way to find out if you didn't rate it yet? we could overwrite 0 with the usual import default in that case.\n. cool, thanks. merged to master.\n. works as advertised for me. not sure about the copy feature, do we need it? i guess removing features will always be kind of simple though. i'd also be interested in jose's opinion on this, he is working on a folder-based collection thing that might touch similar code.\ndiff seems clean and short, gui is kept very simple, so i think i can safely merge without loss of being future proof :)\nthanks for that, i merged to master.\n. re: broken colors. could that be the same cause as the font size before? that darktable.gtkrc is not found? can you copy it into your config directory? or give a (writable) config directory via --configdir directly on the commandline?\n. still works on linux, so i merged it :)\n. i tried this again, and have some comments :)\n- i like the separation folders/film rolls\n- when i select folders for the first time, dt crashes (can't reproduce though, doesn't do it the second time)\n- until the sync thing is implemented, the button should be removed from the gui (as it causes an instant crash, too)\n- when i expand a couple of folders, the list grows indefinitely (larger than screen)\n- double clicking a folder doesn't always seem to work. it shows a >0 count of pictures, but the collection remains empty (no other filters/stars active)\n- i still don't understand the local hdd' label. seems to be constant/without functionality? most of my pictures are on a removable drive, that doesn't seem to matter?\n. looks cool, i'm a bit worried we're duplicating driver functionality. i'll test it on my nvidia box to see how it interacts with the driver's cache.\n. thanks, pushed this to master. now it would be cool to have it for all the other export modules, too! :)\n. duplicate entries in selected_images? really? that sounds wrong. any idea where that might come from? how did you select your images? maybe we just need adistinct' in some query that writes into selected_images?\n. is libintl part of glibc on linux? i don't even have that library on my system (gcc 4.6.3).\n. great, thanks. seems to work and not crash on my system, pushed to master so it will receive more testing.\n. cool, that works! thx.\n. hey, i like the +=1 part, but the number drawing introduces a lot of graphical noise that i'm not sure is of any practical use for the image? also it leads to some drawing artifacts when moving the zones (numbers overlap input/output boxes and sometimes disappear in the grey of the output box..). so i cherry picked only 4508a51.\n. looks good to me. the macro sends the signal and locks a mutex (which is not necessary because you're all in the gui thread, but also doesn't hurt).\n. actually the only critique i have is i probably would have put it into the select_this_image(imgid) function. any reason why not to do that? it seems to be called a couple more times.\n. edit is correct because you can edit the auto apply options (iso ranges and such).\n. the two dot ellipsis is on purpose, a third would be wasteful.\nyou're showing crop size in what units? relative or pixels? will have to check it out :)\n. i made `degrees' a non-translatable special character and pushed. thanks for that :)\n. i found some time to test it, here's what i like:\n- download button :) people seem to be confused about how to get the image with the concise instructions at the bottom of the frontpage.\n- it only seems to be scaling the pictures down to fit the screen, not up to make them blurry. so if you keep your output resolution to like 1200x800 you'll get about the same result as with the old version\nand what i don't like:\n- buttons overlay the image all the time? i find that distracting. looks more like social media than serious photography.\n- fat darktable logo with distracting colors visible all the time :)\n. hey, sorry for the long delay. just tested this again and am not sure what to do about it. the only thing i really like better than the current web gallery exporter is the ability to scale images down (great for netbooks).\nthe upscaled images get really blurry/grainy and make it look more like a messy social media thing (where you're never sure what size of picture you're looking at) than photography. wasn't an earlier version avoiding the upscaling?\nalso the `film strip' in the bottom is a little bit too fancy for me, i find it distracting (same for the one in dt, but that's quick to hide if you don't need it).\ni also tend to like the current style sheet better, it's less contrasty. talking about styles, i really don't like to tie our users to a system that involves commercial themes (whereas it's easy to edit the simple css in the current one).\nother opinions on that?\n. i guess that must have been a copy paste thing. or an early change in api with the dtgtk sliders and just carried over with another copy paste :)\n0 digits precision on a 0--100% scale are fine anyways though.\n. yea, that's very idiotic. i remember i was wondering why the value changed so little (must have been drunk). thanks for spotting.\n. i've tested this some and quite like it :)\ni've put a couple of commits on top (branch `keystone'), you might especially want to look at 846dd29 which tries to re-enable right-click-drag-rotate after keystone adjustments, not sure i did it the right way.\ni also have one more question about your transform. looks very 2d, you sure it's what you want? i mean, there's no perspective 1/z correction term as you would have in a 3d transform:\nhttp://picpaste.com/2012-12-01-213506_1920x1080_scrot-acoMZPKW.png\nsee how lines are mapped to curves?\n. re: transformation. here's a 2d illustration of what i mean:\nhttp://freespace.virgin.net/hugo.elias/graphics/x_persp.htm\nthis one has a slide on `removing projective distortion' using 2d homogeneous coordinates (which is what you want):\nwww.cs.utexas.edu/~fussell/courses/cs395t/slides/L3(ProjGeom).pdf\n. cool, sounds like you're on fire lately :)\nwill check it out once i get home..\n. looks good to me now, thanks for all that. a few minor afterthoughts:\n- the gui will lead you to select edges directly, so skyscrapers will be perfectly straight (which looks odd, like they're falling down on you. slightly undercorrecting usually looks better)\n- the gui works fine, but has some peculiar inner workings (rotation off, then rotation back on after the keystone has been corrected). all that is nicely reflected in the gui with disabled widgets, so lets see how people like it.\ndefinitely a good step up from where it was though.\n. looks good, using signals and all. code looks clean, i'd like to test it before merging though, hope i'll find a minute for it soon :)\n. works as advertised. collapses the list every time on update though.\n. what's data/kernels/blendop_cl_unused ?\nother than that it looks good to me. really like your style of creating a pull request. well structured and easy to review.\n. cool, thanks :)\n. wooot :)\n. hey, i cherry picked the whitespace cleanup one. the bold fonts i don't like. maybe because i'm using a larger fontsize in my gtkrc i think it looks a little bit unbalanced/cluttered by introducing even more shapes into the already messy module header.\nso i'm closing this for now, if anyone feels strongly about it lets discuss again.\n. i'll take your word for the testing.. pushed, thx :)\n. yes, the preview pipeline should produce the same results, and it operates\non a downscaled version (so pixels don't mean anything consistent).\nOn Sat, Dec 22, 2012 at 1:42 AM, Jose Carlos Garcia Sogo \nnotifications@github.com wrote:\n\nJust curiosity, but is there a reason for the radius to be dependent on\nimage size, and not screen size?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/107#issuecomment-11611554.\n. nice, looks almost as i would have imagined it. i would probably have put the style* into the global export parameters:\n\ndt_imageio_module_data_t (src/common/imageio_module.h:41) and probably then as a `const char style[256]' or whatever fixed size so the derived parameter structs know where to append their data and to avoid possible memory leaks due to dynamic allocation.\nthat way you won't have to pass style* everywhere (but would need to adjust all the param structs in all format/ storage/ modules to match the same prefix as dt_imageio_module_data_t, not terribly great design, could have been a sub-struct).\none advantage of this approach is that it'll be stored in your presets.\noh, also the image viewer src/dtview/main.c doesn't compile anymore with the changes to dt_imageio_export() (needs one more NULL).\ngui wise: i would put the style after color profile/intent, and maybe it could need a more descriptive tooltip (reassuring the user that it'll not apply the style permanently but just for export).\n. re: compilation: you probably don't have libsdl, so the viewer isn't compiled at all for you. no big deal, was a 5-char patch :)\ni'll have a look at the rest later today i hope.. \n. nice, your new version doesn't pass style*, so the export() function has the same signature. no more additional patch needed. oh, you need libsdl-dev of course. can you `make darktable-viewer' and it does something?\none more thing:\n-  char *style = dt_conf_get_string(\"plugins/lighttable/export/style\");\n-  dt_control_export(max_width, max_height, format_index, storage_index, high_quality, style);\n(style will be the result of a g_strdup() here and would need a g_free()).\nand just storing a pointer to that string in the job system is a memory leak (as far as i can tell it's not cleaned up after the job finishes.. and even if it was, it would be messy because it's unclear how it was allocated. statically? on the stack? g_malloc?). again, i'd just store the same char[128] as you do on the params on the job as well. it's a multithreaded system with a job queue, the pointer might not even be valid any more by the time the job starts execution.\n. cool thanks, i think that works. i patched a few minor things to make presets work again (important bit, especially together with styles). was my fault in ugly old code i guess, so just fair that i fix it :)\n. lgtm :)\n. you're on fire man :) more discussion can follow when more people test it (on master). for example the ctrl-shift+c shortcut doesn't work for me? is that only for the filmstrip (then why is it not a regular user-bindable key accel, or is my compile broken)?\n. so this now has to loop over the whole table (my 10k image collection in case of a `film roll %' query)? i'd like to see some performance numbers for that.. darktable -d perf should still output some lighttable numbers i think?\n. can't see a performance regression. merged, thanks :)\n. cool, numbers look good to me (noise levels are the same as 5dm2, just with more isos enabled..?)\n. (not true, was looking at red, not green. it's slightly better, especially the poissonian part, maybe a better CFA)\n. cool! there's no way to cancel the extended paste dialog, is there? in case you close the dialog, it just pastes everything (same as if you don't check anything in the list and press paste).\n. works fine for me. i tend to have liked the version with fewer buttons even better, but fair enough.\n. omg, was that code really like that .. embarrassing, thanks for fixing..\n. cool, graphs look fine indeed. thanks!\n. lgtm :)\nprobably some of those could have been fixed by taking away the GTK_EXPAND flag from the table entry. but this way will even work without the table.\n. okay :)\ngreat that it prints the name of the to-be-updated preset in bold.. of course i overwrote one of my presets while trying it (because create new preset doesn't update that string). apart from that i like it :)\n. cool, that looks good :)\n. oops, thanks.\n. nice but now zoomable lighttable mode zooms somewhere random instead toward the mouse pointer..\n. what happened to this one? what's all the random garbage commits in there now?\nanyways, cherry-picked the juice of it and pushed to a branch `zoomfix' in the main repo.\na few comments:\n- sometimes now there is an offset in the top left corner when entering lighttable mode (starting darktable). looks like a waste of space or at least untidy. wasn't necessary until we zoomed, right?\n- keyboard shortcuts g and shift-g (go to begin/end) don't seem to work anymore?\n- lighttable performance feels a little more laggy (darktable -d perf -d lighttable goes from about 0.08s to 0.12s for me at 7 pictures/row). not sure these numbers are any significant though.\n. pushed, thanks.\n. so i gave it a quick spin, some more comments:\n- i don't like any of the color changes. most prominently the yellow stars, but also the increased contrast between file type in the bg and the darker image frame. makes it look distracting to a point where i'd rather not have that file type thing in the bg at all.\n- i don't like the new shape of the stars. looks like they've been inflated to make them look like the cartoon version of a star. reminds me of what kde looked like when windoos vista was hip.\n- while the position of the buttons might be convenient for someone who actually wants to use them, they shadow the more important `preferences' button (and that one has even become smaller). probably even the group button is not a terribly well placed thing there.\n- does anyone really like the background color label thing? i think it looks terrible, and the striped version isn't any quicker to discover than the little circles (at least those stay in their place and don't depend on other labels to be present).\n- the thing i agree to is to add the possibility to switch off the decorations as we already have them.\n. two generic comments:\n- to navigate the undo list, you will need undo and redo functions.\n- it needs to be thread safe (i.e. guarded by dt_pthread_mutex calls) because most batch operations are done in background threads to not freeze the gui.\n. the more i think about it, the more i think it should be its own struct darktable.undo and be created as all the others in darktable.c with some sort of dt_undo_init() and respective _cleanup() calls. these would then have their own dt_undo_t struct (as all the rest) so you could put all necessary data inside that (GList* and dt_pthread_mutex_t and what-have-you). maybe there are extensions in the future that we don't think about just yet, so we'll be prepared.\ni would say you want your own mutex. if for nothing else then for clean encapsulation (we could use the gdk lock, but given how that api still changes, i'd rather do our own).\nalso, if everything is in one dt_undo_t and functions accept that as argument, we could easily instantiate two of them (one for tethering and one for lighttable for example?). with a global static GList* that's not very easy.\n. just read some more code, you already have a struct dt_undo_t which describes just one item in the undo list. i didn't mean that one.\nas far as functions go, these should be named to avoid name clashes. so a dedicated undo module would probably come with a prefix like `dt_undo_*' \nthat stuff is kind of important, because if you link to an external library that comes up with the same name (do_undo) or just happen to use that symbol in one of the iop modules for example you'll have a great time debugging which one is actually called.. (we did not have that before, ever ;) )\n. (citing myself) \nalso, if everything is in one dt_undo_t and functions accept that as argument, we could easily instantiate two of them (one for tethering and one for lighttable for example?). with a global static GList* that's not very easy.\nin more detail, you could have darktable.undo.lighttable and darktable.undo.tethering or decide to put the undo struct into each view.. it's way more flexible (object oriented, if you want text book trash talk).\nalso this is the data access pattern used throughout darktable. you have exactly one global struct, `darktable' and if you really need to access stuff, you can. \nencapsulation in the mother struct means it's not polluting the namespace (just the one word is global).\nbut if you don't want to code these 10 lines of boilerplate code around it i can also do that once the rest works. you will need global initialization (init the mutex for example), so you need an entry point from darktable.c anyways, i don't see a point to start doing this in another way than we always did so far.\n. hey, just a quick heads-up, i really like this to be in 1.2 (and feature freeze for a release immediately after a merge). the only thing i could spot so far is your constructor _init() seems to take an argument, but the destructor _cleanup() doesn't? that way it can't be used to do multiple instances easily ;) but it's really minor. if i get a couple of minutes at some point i'll merge.\n. cool, graphs look good (apart from blue, which you noticed, too, apparently.. :)\n. forgot to say: thanks for profiling and posting the patch!\n. oh. in this case it's dumbbell's script which is clever enough to zero out channels where the fit was off. your blue was underexposed (check the graphs, red and green line up with the data, whereas the blue fit is decreasing, not increasing as the data is). currently that doesn't matter at all (we only use green and derive the rest), so you won't see any difference if you re-profile.\n. any reason why this is not a G_TYPE_INT then? i guess if we cast it to\na void* at some point we want it to be machine dependent to\ncorrespond to the address width.. not sure why we would though in this\ncontext.\nbut yeah, if the mess was there before your patches it's probably not\nin the scope of this pr to clean it up.\nOn Wed, Feb 20, 2013 at 10:21 PM, Pascal Obry notifications@github.com wrote:\n\nHum, no so easy, the long int comes from the list store:\nGtkListStore *liststore = gtk_list_store_new (DT_STYLE_ITEMS_NUM_COLS,\nG_TYPE_BOOLEAN, G_TYPE_BOOLEAN, G_TYPE_STRING, G_TYPE_LONG, G_TYPE_LONG);\nReading the documentation a G_TYPE_LONG corresponds to a glong which in\nturns corresponds to standard C long. I will use glong in the code.\n\u2014\nReply to this email directly or view it on GitHub.\n. didn't test yet, but did you play with the font size? i have a copy of\ndarktable.gtkrc (from /usr/share/darktable) in ~/.config/darktable\n(will be picked up automatically) and increased font size by setting\n\nfont_name = \"Sans 10\"\nsomewhere on the top. with the default 8 i have the same problems\nfinding stuff you describe. the above will also make the controls\nthemselves larger and thus easier to hit with the mouse.\nOn Mon, Mar 4, 2013 at 7:19 AM, Pascal Obry notifications@github.com wrote:\n\nThis strike-out a bit more and ends-up more readable given the number of\nmodule in darktable at this point.\nI had proposed a bold label and it was rejected. I'm using more and more\ndarktable and I really feel that I'm having hesitation/difficulties to see\nwhere are the modules. All the text being white the different modules does\nnot strike out enough and I loose time \"parsing\" the screen. At first I\nthought that with the habit it will be easier, but not much and after all\nthis time using darktable this is not satisfactory for me.\nSo, this simple patch adds a light blue color to the module labels. Looks\nbetter to me.\nPlease use it, look at this and tell me what you think.\n\nYou can merge this Pull Request by running\ngit pull https://github.com/darktable-org/darktable module-label-color\nOr view, comment on, or merge it at:\nhttps://github.com/darktable-org/darktable/pull/189\nCommit Summary\nUse a light blue for module labels.\nFile Changes\nM src/develop/imageop.c (2)\nM src/libs/lib.c (2)\nPatch Links:\nhttps://github.com/darktable-org/darktable/pull/189.patch\nhttps://github.com/darktable-org/darktable/pull/189.diff\n. how will that affect existing history stacks? \n. On Thu, Mar 14, 2013 at 8:58 AM, Jose Carlos Garcia Sogo \nnotifications@github.com wrote:\nWe have to be careful about changing things, even a little. In the not so\nlong term we need a framework to keep old images with old ions, and only\nupdate them on user request.\n\nhm? i have no idea what you mean, and this is certainly the wrong place to\ndiscuss it.. but i'm going to disagree strongly that we should replace the\nlegacy_params() system with something that involves user interaction or\nencourages to keep crappy legacy code around for longer.\n\nEl mi\u00e9rcoles, 13 de marzo de 2013, Pascal Obry escribi\u00f3:\n\nIt won't affect history stack. It just change a little bit the border\nsize\nfor portrait picture.\n\u2014\nReply to this email directly or view it on GitHub<\nhttps://github.com/darktable-org/darktable/pull/194#issuecomment-14864364>\n.\n\n\nJos\u00e9 Carlos Garc\u00eda Sogo\njcsogo@gmail.com\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/194#issuecomment-14864871\n.\n. that module should not ever be enabled for jpg images (makes no sense\non non-linear input). maybe a test for non-raw data would help here?\n\nOn Tue, Mar 19, 2013 at 2:43 AM, Pascal Obry notifications@github.com wrote:\n\nA possible fix for a crash I have observed in the denoise profile iop. Using\ngdb I have found that when a applying a style with a denoise profile to a\njpeg image without any exif (so not camera, lens or whatever information)\nthe g->profile_cnt was read uninitialized.\nEven if this is correct (which I'm not sure) there is still something wrong.\nTo reproduce:\n0 start dt\n1 ppen a jpeg file (not tested with RAW) without any modification:\n2. activate denoise profile (change whatever parameter)\n3. add new instance of denoise profile (change whaterver parameter)\n4. swicth to lighttable\nAt this point I have a crash:\nProgram received signal SIGSEGV, Segmentation fault.\n0x00007ffff6dbbad5 in ?? () from\n/usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n(gdb) bt\n0 0x00007ffff6dbbad5 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n1 0x00007ffff6dac09b in gtk_widget_unparent ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n2 0x00007ffff6bddb33 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n3 0x00007ffff74585f4 in g_cclosure_marshal_VOID__OBJECTv ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n4 0x00007ffff745506a in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n5 0x00007ffff746f317 in g_signal_emit_valist ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n6 0x00007ffff746fa72 in g_signal_emit ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n7 0x00007ffff6daeb45 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n8 0x00007ffff745b500 in g_object_run_dispose ()\nfrom /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n9 0x00007ffff6bdda6a in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n10 0x00007ffff7aafbbe in dt_view_manager_switch (vm=0x880fb0, k=k@entry=0)\nat /home/obry/dev/OpenSource/builds/darktable/src/src/views/view.c:267\n11 0x00007ffff7a4dde7 in dt_ctl_switch_mode_to (mode=mode@entry=DT_LIBRARY)\nat /home/obry/dev/OpenSource/builds/darktable/src/src/control/control.c:1444\n12 0x00007fffa6e48b6f in _lib_viewswitcher_button_press_callback (\nw=, ev=, user_data=)\nat\n/home/obry/dev/OpenSource/builds/darktable/src/src/libs/tools/viewswitcher.c:223\n13 0x00007ffff6c8f119 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libgtk-x11-2.0.so.0\n\nYou can merge this Pull Request by running\ngit pull https://github.com/darktable-org/darktable\nfix-crash-denoiseprofile\nOr view, comment on, or merge it at:\nhttps://github.com/darktable-org/darktable/pull/197\nCommit Summary\nMake sure profile_cnt is initialized.\nFile Changes\nM src/iop/denoiseprofile.c (2)\nPatch Links:\nhttps://github.com/darktable-org/darktable/pull/197.patch\nhttps://github.com/darktable-org/darktable/pull/197.diff\n. i don't think i can make it raw only without breaking string freeze or making it look stupid in case someone tries it on his jpgs. the way to do it would probably detect image_ldr() in commit_params() and disable the module there. and display a label `only works on raw images' as c/a correction does. i reproduced half of your patch (not the re-matching in gui_update() that should be redundant), let me know if there are persisting problems with it.\n. probably one day the keywords module will be part of the collect module and update itself more often, so the signal gets less important. until then i think this is a necessary commit..\n. cool, code looks all good to me (maybe someone else wants to comment, too?).\n\nthe bit cached-or-not will end up in the database, but not in the xmp (which is what we want). we can probably iterate on whether or not and how to indicate the cached status in the metadata panel or how to draw that white indicator on the thumbnail frame, but that's minor.\nthere's a slightly increased chance of data loss because now we unlink files (only the cached one, but still), and the cached edits will only be in sqlite and not in an additional xmp. but judging by the code i think as soon as you plug in your hdd once (even while still cached) it will use the original and also write the xmp again.\n. cool, thanks for those. wb_presets.c is straight from ufraw and importing new presets might turn out to be interesting if we diverge a lot. we can still revert that part of the patch if that turns out to be a problem.\n. awesome, thanks for that. pictures are identical and i get a nice 8x+ speedup here.\n. as the original author of the tagxtag table i want to raise the question if that stuff is still useful today? is anyone really using the tag proposals? i remember some confusion on the mailing list where people would actually expect a dump alphabetic/most used list more than a `related tags' list. maybe we should just remove all of that code?\ni'm not tagging a lot, so i can't judge how useful these proposals are..\nwe haven't been using sql triggers anywhere else so far, so i would be afraid of debugging this in case anything goes wrong.\n. i didn't even open the module in quite some time.. a year ago or so it worked like that:\nyou type a tag name, it'll refresh the list of all matching names, ordered by frequency in your tag database. it would use the conditional probability P(tag Y in list | given the tags X your image already has) based on a frequency table that tells you how many images that have tag X also have tag Y.\n. heya, thanks for the effort. however i don't think proper error handling and good engineering helps to make this tiny tool more readable. it only runs through once and the whole heap will be destroyed when it exits.\ni think if someone is interested in this code then it'll be for the technique, not for the error handling. i'd hate that person need to read through hundreds of lines of warn_unused_result handling.\n. looks like the camera does some processing on this for high iso? anyways, the graphs look fine (green part, colors not so much).\n. commit_params() is called every time the history stack is committed to the\nindividual pipelines. that happens shortly after you change something in\nthe module's gui or when you init the pipe for example. it's needed as a\nsync point between the pipes which are usually executed in bg threads and\nthe gui.\nyou're only committing now in case the lens is unique, right? i guess maybe\nthat makes sense.. didn't test the patch though.\nOn Mon, Jan 6, 2014 at 10:19 AM, Torsten Bronger\nnotifications@github.comwrote:\n\nI should add: You see an effect only with SVN lensfun.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/421#issuecomment-31615906\n.\n. i think this is now obsolete, this line:\n\nhttps://github.com/darktable-org/darktable/blob/master/src/views/view.c#L1419\nshould have the same effect, right?\n. i'd be interested to include this in the cache2 branch.\na few comments:\ni think this should go into mipmap_cache.c instead of cache.c, since it's really specific to thumbnails (i don't think we want to store dt_image_t on disk, which are also using this cache). also i would store the thumbs as jpg, for a couple of reasons:\n- well, size (i don't think the small thumbs should take long to compress/decompress, and the code is already in the serialization code in mipmap cache)\n- you don't want to store the rest of the struct with control information (buffer descriptor object)\nthe hooks for eviction/allocation are the allocate/deallocate callbacks that are already registered from mipmap_cache.c, so i think there'll be no need to change cache.c at all.\n. this is now implemented in the cache2 branch: 5ec0f27\n(but doesn't work with compression yet)\nyou need to enable it in your `core' preferences. let me know what you think.\ninterestingly it starts to write a lot of images immediately, even for a 1GB cache, all of them mip1 for me (so that might indicate some potential to optimize the in-memory cache).\n. closing this pull request now, i think the basic idea is implemented in the cache2 branch and working really well. it has rough edges, so i think it'll be better to concentrate efforts on cleaning those up.\n. overall the approach looks good, the patch modifies the right places. not sure whether a param update would have been needed for this, i would have tried to hide the bit in the other flags somewhere. i guess this way it's cleaner. the lens module is quite a complex beast, so this needs testing.\n. re: changed history bit: this very stupidly only depends on the implementation of dt_image_altered, which is easily adjusted (check whether bits are different to bits in exif/raw)\n. good stuff, i think this is good to merge, congrats and thanks for all the hard work!\ni'm sure more issues will pop up after a lot of users test it on their images :)\n. looks good to me.\n. flip_and_zoom_8 creates cache images from real images (jpg thumb or pipeline output). that includes flipping the order of rgb/bgr so we can later directly blit it to cairo without re-swizzling during the draw event. your input is already flipped, so this is the wrong function to call.\nthe cache has been rewritten from scratch lately, and sits in a branch (cache2). in case this idea still makes sense with the new caching backend, i'd suggest reworking it on top of that branch.\n. actually i don't think we have this variant of the function (without the\nflipping). the others are slightly different in their zooming behaviour. in\na similar use case (pre-generating all thumbnails offline,\nhttps://github.com/darktable-org/darktable/pull/803/files#diff-4314716e9360578ae5af4635142ba3adR98\n) i resorted to just un-flipping after calling the function, since this\nwasn't a very performance critical case.\nOn Wed, Dec 31, 2014 at 12:09 AM, mgehre notifications@github.com wrote:\n\nThanks for the hint! Which function would be the correct one to zoom the\ncache image?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/707#issuecomment-68348324\n.\n. was also playing around with the stupid reload_defaults order. some notes here:\nhttps://gist.github.com/hanatos/14a5d8acf0434ce2089f\n. looks very good.\n. i think there is already something quite similar to this in master, slightly uglier but with fewer lines of code. i don't think it's necessary any more, but if someone wants this, it definitely needs rebasing to master.\n. yes, i would say we merge this, unless someone finds out it doesn't work..\n\nOn Tue, Jan 6, 2015 at 10:51 PM, Pascal Obry notifications@github.com\nwrote:\n\nSo, hanatos if I read correctly your message it should be merged, right?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/790#issuecomment-68845887\n.\n. heya, as LebedevRI said, we don't push noise profiles without some quality assurance.\n\nas far as the average goes: it's unclear to me that averaging the fitting parameters makes any sense, if anything the input data needs to be merged before profiling. apart from that it seems risky to put that job into a shell script, from a maintenance point of view.\n. shouldn't gtk widgets be double-buffered already? i suspect that it might be enough to make the parent widgets transparent via css, to avoid the need for constant redrawing, but can't proof it at this time.. (that's one difference between gtk2 and gtk3, that all in-between widgets such as event boxes, hboxes, etc now are drawn solid)\n. all i tried in 3 minutes with css actually made it worse.. i would say if we can't quickly find the better gtk way let's just merge, this flicker is really annoying.\n. (i think something similar happens when leaving darkroom mode. instead of just leaving the old image there until light table exposes, the background first draws itself over everything in solid gray)\n. omg, i feel stupid now :)\n. \nthis is what it looks for me. i think it looks quite unacceptable with all the different bg colours.\nalso i really don't like how the buttons don't look flat.\n. background in prefs looks better, i still think the whole idea to leave\nanything to the system style is a bad idea. all colours look different and\ndifferent button styles look like it doesn't belong to the same application\nany more. the one thing it seems to fix is the padding of all gui elements\nin the gtkfilechooser. this could probably have been achieved in much less\nintrusive ways, without the side effect of breaking look and feel for\ngtkdialogs.\nOn Fri, Jan 9, 2015 at 6:28 AM, Pascal Obry notifications@github.com\nwrote:\n\nHow does it looks to you know?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/816#issuecomment-69215303\n.\n. \n\ni noticed some #preferences_notebook .button in the css.. are these intended to also affect the close button at the bottom? because it doesn't here..\n. looks great thanks. yeah, css should support regular expressions and\nnegation, not just this subset that it does.. :)\nOn Fri, Jan 9, 2015 at 11:01 PM, Pascal Obry notifications@github.com\nwrote:\n\nThe button should be flat now. I agree that it would have probably be\nbetter to not specialized the GtkDialog, I tried (hard) but felt to have\nsomething usable. I may try again at some point...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/816#issuecomment-69314768\n.\n. also another success story of a different system with different default css in the background. i very much doubt leaving anything to the default system is a good idea.\n\n\n. well i'm sure i won't link against it in my build :)\nwhat's with all the files with funny endings? (.c.old, .c.orig, .c.roi)\nOn Sun, Jan 18, 2015 at 8:49 AM, parafin notifications@github.com wrote:\n\nSeriously? DT will link against full-blown browser engine?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/825#issuecomment-70381502\n.\n. +1\n\nOn Mon, Jan 19, 2015 at 1:30 PM, Roman Lebedev notifications@github.com\nwrote:\n\nFor the record, i highly do not like this at all.\nI vote for just dropping fb export.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/825#issuecomment-70485820\n.\n. merged.\n. as discussed in irc. i think we procrastinated on this for long enough now. changing defaults seems dangerous, and the thing to do would be to store all/complete data in the history stack (at least the 3x3 coefficients). i'm not sure we still have a steady flow of enhanced matrices at all, so i'd just keep the old behaviour for the old cameras.. i agree with houz on this one. overlaid metadata can be hidden by using the mouse pointer now.. closing as discussed in irc. let's keep as is and for the future move more towards a curve that comes late in the pipe (as possible using a measured tone curve potentially in RGB today already). okay, since code comments in liquify.c don't seem to work, i'll try manually.\n\ni have a comment about the comment in the code :) :\nhttps://github.com/darktable-org/darktable/blob/liquify/src/iop/liquify.c#L407\nall of this blurb about coordinate systems seems to be utterly wrong and makes me doubt the iop works correctly. i also observed some weird things when trying to zoom in on an image with applied transformations. these seem to switch themselves off and then be placed in a wrong place after zooming out again..?\nfirst\n- RAW: These are sensor coordinates. They go from x=0, y=0 to x=, y=.\n    an iop has no idea about the raw dimensions, you'd have to pull it out from the mipmap cache. is that really what this thing tries to do? if so, it's broken. it should only care about the ROI and the corresponding full input buffer (buf_in). the raw has some black borders which are cropped away early in the pipe, for instance.\ni'm not sure the reasoning with the distortions is very convincing. does this really work exactly? i mean, does it also convert strengths, falloffs, directions etc correctly? somehow i can't imagine this would work in the general case. if it doesn't work precisely the user will have to be aware of pipe ordering anyways to get accurate results. so maybe just ignore this?\nhttps://github.com/darktable-org/darktable/blob/liquify/src/iop/liquify.c#L537\ndefine CAIRO_SCALE (1.0 / MAX (piece->pipe->backbuf_width, piece->pipe->backbuf_height))\nis this ^ a hardcoded zoom-to fit scale? is that the reason why it does interesting things when i zoom in? btw it stays broken when i zoom back out.\n. On Mon, Jan 18, 2016 at 2:31 AM, Roman Lebedev notifications@github.com\nwrote:\n\nDoes this module have any assumptions about it's working color space, does\nit need to work in camera rgb? lab?\nif anything, camera rgb (linear scene-referred light, we'll be taking\naverages for pixel filtering). not sure it matters much.\nAlso, is it safe to assume that lens correction will be applied in direct\ndirection (i.e. correct), not in reverse (i.e. distort)\nwhere is that assumption? it will evaluate the transforms of controls to\npixels via the respective distortion callbacks in lens.c, right? using\nwhatever parameters you set there?\nBased on answers to these questions i see 3 possible places for liquify\nplace in pipe:\n1. before spot removal, like now\n2. before lens correction\n3. after lens correction, before input color profile\ni think 3 is the latest it could go (before input colour profile, linear\nlight).\n\nand as disucssed in irc, i don't see a particular requirement. maybe if it\ncomes late in the workflow it should be later in the pipe (speed reasons),\nbut i can't judge liquify workflows.\n\n\nafter crop and rotate?\n\nPersonally, 3. seems like the best place to me.\nOr, at least comment in tools/iop_dependencies.py needs fixing :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1088#issuecomment-172325722\n.\n. hehe, re: rgb->LCh .. i think that name nowadays is just legacy. nothing to\ndo any more with real LCh or the code in ufraw where this came from, back\nthen.\n\nOn Wed, Apr 27, 2016 at 5:15 AM, Dan Torop notifications@github.com wrote:\n\nThank you for checking it over, and the greatly improved Lch algorithm! I\nhave to admit not totally understanding the math of the RGB->Lch conversion\n(it seems like a shorthand version of a full conversion?) but it is such a\nvast improvement. Glad to have it in the X-Trans code now.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1189#issuecomment-214815893\n. i should probably add some context:\n\nhttp://permalink.gmane.org/gmane.comp.graphics.darktable.devel/7472\ni know nothing about the different needs of the different decoders. maybe it would be a good idea to let the CameraSensorInfo struct fill whatever it has to the raw struct with a small member function? so we don't have to copy around the code to fill in the blacks in all the individual decoders.\n. hm. there seems to be indeed a tag with the black levels in the file:\nexiftool -n -D DSCF3831.RAF | grep Black\n61450 Black Level                     : 253 258 258 253\n. hm. i'm now reading the metadata from the raw file.\njust a note on this specific raw (x100): it's a bayer pattern (non-rotated,\nnon-xtrans, no-bs). i still don't know what you mean by the regular place\nwhere this should be done, i'm just grabbing the exif tag entry where the\nblack point is set (also gave it a probably nonsensical name in the list of\ntags).\ni was noting some issue with the blackpoint not being picked up in the\npreview pipeline though. so the navigation view still has the green cast :/\nOn Mon, May 16, 2016 at 9:10 PM, Pedro C\u00f4rte-Real notifications@github.com\nwrote:\n\nThis is probably not the correct fix. If these files really have different\nblack levels per channel those are probably encoded in the metadata itself\nand just need to be read. Specifying blackpoints in cameras.xml is only for\nformats that don't have it in metadata. We had a report in the past of a\nfile that needed blackpoint as 0 in a very high-iso and low light shot but\nnormal blackpoints for normal shots. That was in my backlog somewhere.\nIf there is a format that actually does this (having fixed blackpoints\nthat are different per channel) it can just be implemented the same place\nwhere the rest of is done to apply to all formats. The only reason RAF\nfiddles with these at all is that because of the rotation code it ended up\nnot using the normal code path and having to reimplement these bits.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1202#issuecomment-219381974\n. On Wed, May 18, 2016 at 8:22 PM, Roman Lebedev notifications@github.com\nwrote:\ni was noting some issue with the blackpoint not being picked up in the\npreview pipeline though. so the navigation view still has the green cast :/\nBecause preview pipeline is demosaiced,\nhttps://redmine.darktable.org/issues/10978, so that is totally expected.\nOne more pin into the coffin of pre-demosaicing, should be gone in my wip\nMIP_F rework branch.\n\nyeah, that's what i thought too. i did merge your branch and try with that,\nbut for whatever reason it still didn't work (may have been me doing it\nwrong though, i was in a rush..)\n. > The code looks fine to me, pretty much what I'd have written too.\ncool, thanks for checking. so we merge and let's take care of the mipf pipeline madness separately?\n. those regression tests are cool!\nand yes, there will be differences (at least to files that were imported before rawprepare even existed..), i don't see how we can do anything about it. unless we want to run rawspeed with a legacy-mode timestamp that dynamically checks out old code and recompiles it as needed :)\nso i'd say this is a bugfix and affected users will be surprised in a good way when looking at old shots.\n. hm. for whatever reason github cut off the last image, so here's a link\n. a bit more on the topic:\nhttps://jo.dreggn.org/blog-fusion/post.html\nit's not perfect wrt halos around small features with high contrast but i think it's a worthwhile tool in the box. i'd like to merge before 2.2.\n. to answer the questions:\n- the base curve affects this heavily, this is why it's inside this module.\n- it kindof works with a linear curve, but will give very different results (mostly unpleasant from what i've seen)\nthe way it works is it pushes the image by a couple stops, then applies the base curve, and finally merges the results. the way to think about it is really you develop the image three times, once for shadows, once for mid-tones, once for highlights, and take the best of the three.\ni don't think a linear base curve in the sense that you care about scene-referred linear colour makes any sense with this. if you submit to exposure fusion, your linear workflow is out the window. you just want to merge features of the image to look pleasant at this point.\n. this looks so cool. the last two images, what are we seeing there? is it just due to aliasing that this pattern emerges at a different scale? or is it zoomed in a lot?\n. tried locally and it works. i like the change, this is how we should do things. if i can understand why we have buffer descriptors on each piece and on the full pipeline i think we're good to go with this.\n. looks good to me. thanks for doing these!. yep, clearly improves the readability, thanks. maybe even all the individual pdf wouldn't be necessary to pack into the tarball any more if the combined is available.\n. indeed, thanks for preparing the pr!\n. excellent, thank you. thanks for profiling! these look good to me.. thanks @schenlap for verifying :). there is some potentially related code in a branch that i use to build laplacian pyramids (blur and then downsample):\nhttps://github.com/darktable-org/darktable/blob/monochrome/src/common/locallaplacian.c#L124\nand it also has the reverse case, upsample by interpolating missing pixels via blurring.\ndidn't look at the code yet.. but what exactly are you blurring? just CFA colours or some intermediate r-g and b-g colour planes? i think the latter should yield better results (but be a bit more complicated to reason about).. i think this looks very good! much better than current master. there are still some colour fringes, but much reduced as compared to what we have now.\nyou're blurring all three channels by the same amount? (didn't look at the code yet). re: blurring factor: i think it should be related to the spacing of the respective colour channel (i.e. we could potentially blur colours way more and green a bit less). it should be designed to band limit the signal before sub-sampling it to the lower res CFA pattern (following the nyquist limit). not sure whether we should use the conservative max distance in each direction or rather an average... rebased and pushed manually, to avoid merge conflicts with rawspeed submodule. thanks for this @dtorop!. hi,\nvery interesting work!\ni don't have my collection of fusion test images with me currently, so i can't comment on the workflow experience.\nin any case the opencl code path would need fixing before merging :)\nwhen first looking at this PR i thought it was about merging priorities, i.e. weight brightness levels differently when selecting the coefficients in the laplacian pyramid here:\nhttps://github.com/darktable-org/darktable/blob/master/src/iop/basecurve.c#L844\nwhich may be another interesting nob to play with (and one that cannot be emulated by using the exposure module). did you play around with that thing, too? are you sure you want exactly the exposure switch as you implemented it?\ni know that sometimes i feel like the highlights get blown out a bit too much with the current configuration, your slider may help alleviate this issue.. so i'm very interested in getting an improvement here :) just want to be sure we discuss all options (and would like to test on my images once i get home).. thanks for the detailed explanations and images! i merged this into master now.\nand thanks for providing the the pull request, it does simplify the workflow considerably.\nre: opencl: must have missed that you changed this function already.\ni guess next on my wishlist for this module is speed improvements for the cpu codepath.. :). hehe, indeed that sounds like a leftover. it was probably just above the\nline that switched off the opencl flag on the pipeline :)\nOn Sat, Feb 4, 2017 at 7:53 AM, Matthieu Moy notifications@github.com\nwrote:\n\nPerfect, thanks.\nBTW, talking about OpenCL, there's still a TODO in the code: // TODO:\nimplement opencl version:\nhttps://github.com/darktable-org/darktable/blob/0885e553d84380a4ca8d1dbee711ecb38838c816/src/iop/basecurve.c#L1159.\nIs it still relevant or shall we remove it?\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1429#issuecomment-277330274,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgFKWfBrsfPnoJgjF2IvsZq99i7kYIvks5rY3eSgaJpZM4LvBmB\n.\n. tested this and it works fine. i would classify the N<4 cases as bugfix (we're in feature freeze). i also like everything that avoids the svd code.. thanks for looking into this at this level of numerical detail!. hi, i just tried and merged this. it's... not sure it's a bugfix but whatever. i think the results really do look very good, and the patch is now not very intrusive at all any more. we can still improve speed in the future. fwiw, working with it in dr mode for a short while is noticeably slower than the default, but not absolutely unworkable, so i think people will find it very useful.\n\nthanks for contributing this!. On Thu, May 17, 2018 at 5:17 AM, edgardoh notifications@github.com wrote:\n\nIRC doesn't really work for me, I know is not the same but here or mail is\nbetter for me.\nBefore the merge there's still this that needs to be addressed:\nhttps://github.com/darktable-org/darktable/pull/1548/files#diff-\ne3fe6a161b31cae7e75c7f5a8cd99ec2L40\nNot sure if I mentioned, but the retouch and the spot removal are not 100%\ncompatible. The retouch work in-place, that is, all operations are done in\nthe input image. The spot removal use as source always the input image and\nas destination the output image for the clone.\n\n\ndo i understand right that you're saying you modify the input buffer in\nprocess() ? that will mess with the caching of the pixel pipeline, it keeps\na copy of the old input buffer to accelerate future pipeline evaluations.\n\nThis shouldn't be an issue, I don't see why a user will set the source of\na clone as the destination of a previous one, but in theory it can happen.\nAdding that it will probably be less confusing for the user I vote for\nthis to be a new iop, but of course not really my call.\nonce this has been decided I can do the DT_MASKS_UNMANAGED change.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-389731872,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgFKc6g-_XIcb8mU5jwVshu239iUmMoks5tzOvGgaJpZM4QKYV4\n.\n. i would be much in favour of draggable scrollbars on the outside. this way\nthey will be in the same place whether or not the panel is visible and\nthere wouldn't be an additional gui element, potentially popping up and\nmoving things by small amounts.\n\nOn Thu, Jan 4, 2018 at 2:54 AM, Pascal Obry notifications@github.com\nwrote:\n\nscreenshot for the lighttable. on the darkroom we have both vertical and\nhorizontal ones but I don't think we want scrollbars on darktable.\n[image: scrollbar]\nhttps://user-images.githubusercontent.com/467069/34523018-e7b5e9f4-f095-11e7-8439-4bcef9408ca3.jpg\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1607#issuecomment-355016866,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgFKX_nXEAecFYwaXCJ-yHIMNIhxY_lks5tG4aMgaJpZM4RRlik\n.\n. okay, i trust this should work (and didn't do anything stupid in a short test). thanks for looking into it and for the pull request!. this looks good to me, thanks for the pull request. unfortunately it now conflicts, i'll merge manually. it's really a minimally invasive fix so no problem with the feature freeze.. Hi yes that's my code though the syncing should be the same in a couple of\nplaces.. Maybe it's broken there too? I'll have a look as soon as I find\ntime ..\n\nOn Wed, 8 Aug 2018, 13:12 Matthieu Moy, notifications@github.com wrote:\n\nI don't fully understand the logic here (not familiar at all with this\npixelpipe syncing mechanism), so I'm far from confident in the fact that\nthis is the right fix. But it seems to make sense, and in practice it does\nfix the issue. A bit more details on the diagnosis is available on the\nredmine bug https://redmine.darktable.org/issues/11872. @hanatos\nhttps://github.com/hanatos, you're the author of the original code, can\nyou have a look?\nWhen changing image in darkroom, and when both the previous and the new\nimage have local laplacian activated, the optimization grabing data from\nthe preview pixelpipe introduced in 911133c\nhttps://github.com/darktable-org/darktable/commit/911133c87b45be22251cf7252ed729d1632a27b2\n(local laplacian: make roi\naware in darkroom mode, 2017-10-15) was actually grabing data from the\npreviously selected image.\nThe guilty line was:\nif(hash != 0 && !dt_dev_sync_...)\n\nin case hash == 0, the sync is not done, but the else branch still\ndoes the grabbing. Change this to exhibit 3 cases: 1) don't try to\nsync and grab, 2) sync failure, 3) sync success.\n\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/darktable-org/darktable/pull/1709\nCommit Summary\n\nbilat: don't grab data from preview pipe if hash==0, fixes #11872\n\nFile Changes\n\nM src/iop/bilat.c\n   https://github.com/darktable-org/darktable/pull/1709/files#diff-0\n   (6)\n\nPatch Links:\n\nhttps://github.com/darktable-org/darktable/pull/1709.patch\nhttps://github.com/darktable-org/darktable/pull/1709.diff\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1709, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgFKb5V3UBpdrJpkFYEXkZ8XU9gd_88ks5uOseegaJpZM4VzvDh\n.\n. hi, thanks for the pull request! do you have the pdf results from the profiling so we can judge the quality of the fit?. i'm sorry but these graphs look nothing like they should look like. the noise levels look much like taken from images that had a basecurve applied to them (random guess). if nothing went wrong during profile creation that would mean the camera is completely unsuitable for this noise model.. i was under the impression the problem was more in lines like this one:\n\nhttps://github.com/darktable-org/darktable/blob/4113ca907c602f773f8c424b86771c8a9bba7675/src/develop/masks/path.c#L430\n? where index computation goes into the [] brackets unshielded? at least that is where the sigsegv handler was called in the stack trace you posted in irc:\nhttps://xor.cryptomilk.org/darktable/darktable_bt_VU5KRZ.txt\nso i'm thinking more than adding a few bits to the int on most systems (size_t isn't really always the same thing across platforms) it may be good to add a few [CLAMP()] to array accesses here and there?. i'm also having issues with this. please revert!\nit breaks legacy history stacks and the results look like a lot of aliasing indeed. if you change the algorithm you need to provide a way to reproduce the old one, in general. if it's a mere bugfix that always makes pictures better there may be exceptions to this, but in this case i'm not happy with the output.. _mm_load_ps() is probably what you mean. but swizzling data from float to\nsse registers may well eat up any performance benefit you might get here.\ndid you feed this code in a minimal main.c or similar to clang and look at\nthe disassembly? sometimes it uses vector code already. in a float[3][3]\ncase it may be hard to cast it to a __m128[4] block automatically though.\nOn Tue, Jan 29, 2019 at 11:07 PM Pascal Obry notifications@github.com\nwrote:\n\nThe segfault is probably in the SSE2 code path because you cast the float\nto _m128 but those are probably not properly aligned. You need to use\n_mm_set1_ps() I think.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2035#issuecomment-458482052,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABgFKXiWnITKTKXDQQV61CJsKMhqmoDKks5vIB1ygaJpZM4aUB0y\n.\n. why not just use dt_get_wtime() (will be a double in seconds), that seems to be less code?\n. please don't store non-obvious data types in the parameter struct. these end up in the database, and being unsure about the size of stuff that is not a language feature but defined in random libraries will potentially cause trouble.\n\nso maybe store a flag/an int with bitmasks instead of gboolean.\n. why did you need to change this file at all? from what i gather you didn't add new features to the core, but made the keystone correction accessible from a different gui? \n. why did you remove these lines ^ ? anything to do with keystoning?\n. this change seems to affect non-keystone codepaths, too, and possibly result in an out of bounds memory access?\n. i see. makes perfect sense, thanks.\n. it could live on the view manager or in darktable.* if there will be enough stuff to justify a global undo struct. please don't declare global variables like that (ever, and if you do not with a generic name without a prefix like that, or at least make it static to limit the damage to that file). this way, ulist will be accessible from all other .c files in libdarktable.so.\n. i'm not comfortable with derived types from random libraries in our params struct. this will end up binary in the database and xmp files.. i would just go for an honest int :)\n. do those aggregate types work with houz' introspection?\n. why not just put it on the stack? i.e.\ndt_dev_histogram_params_t histogram_param;\n?\n. okay, this only reads the histogram, and lives in the pipeline thread. maybe document somewhere in the header where the module struct is defined that commit_params is thread safe wrt gui thread and pipes, and this one isn't?\n. no more initialization required? seems like piece->data will now be filled with garbage?\n. houz is right. i don't think you should release the read lock before you're done with img. that should probably move right before each return point of this function? or just grab whatever you need now and copy locally, then release the struct (i.e. copy width/height, filename to something on the stack)\n. most of this function will be gone after integration of https://github.com/darktable-org/darktable/pull/584 but the logic should only get simpler, so probably no big deal to merge either way\n. see above, the logic here will simplify if the only place we flip things is the orientation module.\n. modulo operations used to be dead slow. not sure it's still the case on newer processors. any evidence that this becomes a bottleneck? might be faster to just use a padded 8-wide array and do & instead of %?\n. nice :)\n. it seems i need to put these two back or else switching film strip between raw and jpg files will do random things to the gui (modules disappearing, more modules empty, module header still there but body isn't, sometimes whole right panel empty..).\nif i put them back and switch back and forth between raw and jpg for a few times, i'll get\n(darktable:9657): GLib-CRITICAL **: Source ID 2026 was not found when attempting to remove it\n(with random ID numbers) and dt will freeze.\n. of course i cannot reproduce in debugger.. :/\n. actually testing master again with the same raw/jpg filmstrip switching experiment it behaves very wonky, too. not sure this is a regression (but would be good to find the deadlock, freezing completely isn't nice..).\n. well, i don't care too much. i'm using it as an int in the for() loop, so i thought the code is easier to understand this way. \n. yes. so the code is correct, right? and if(mkd) is shorter than if(mkd == -1) .. also less error prone in case the api is extended by another error code.\n. what about the == 0 case? i thought sqlite indices were 1-based. anyways this is for the case where the cache doesn't return an image because it is full and all entries are locked/can't be evicted. i don't think this should happen any more (the new cache will temporarily go over memory budget to avoid this.. of course crashing if the caller requests an unbounded amount of data and never releases the locks).\n. not that it matters.. but this looks like a typo (french spelling?)\n. i think you can actually give the struct the same name and the same tag. why the leading underscore?\n. missing format character after % ?\n. isn't there a break; missing here?\n. does that break x-trans and esoteric sensors? or would these always use a single black level instead?\n. same question. hard wired to bayer pattern with 4 different colours?\n. wait, how does the pipeline work? you don't pass on the unchanged uint16_t value, but you rescale it to 0..1? is that required for something? i'd rather use the exact value and pass on a white point, too.\nnoise profiles will depend on the absolute scale, also filling in random bits to prevent banding will need to know about the unscaled input.\n. are most of these only cleanup/whitespace changes?\n. i think it's exactly what he means there, locking the history mutex.\nusually we make sure you don't have to do this because you operate either\nin gui thread on module-> or in process() thread on piece-> data. these\nfunctions can unfortunately be called from both gui and process threads, so\nyou need to take care the history doesn't change under your feet, i.e.\ncommit_params() isn't called while you evaluate.\nthe alternative is providing two such functions to be called from the two\ndifferent thread realms, and operating on different input data. as far as i\nunderstand though some of this input data is only generated in\ncommit_params or modify_roi_in/out? so a double implementation would get\nmessy and cause some duplicated code, potentially inside all distortion\nmodules.\nOn Tue, Jan 6, 2015 at 4:17 AM, Roman Lebedev notifications@github.com\nwrote:\n\nIn src/develop/develop.c\nhttps://github.com/darktable-org/darktable/pull/790#discussion-diff-22465606\n:\n\n@@ -1553,11 +1553,16 @@ int dt_dev_distort_backtransform(dt_develop_t dev, float points, size_t points\n int dt_dev_distort_transform_plus(dt_develop_t dev, dt_dev_pixelpipe_t pipe, int pmin, int pmax,\n                                   float *points, size_t points_count)\n {\n-  dt_pthread_mutex_lock(&dev->history_mutex);\n\nThis looks like a dirty hack to me, i'm afraid there are more issues\ncaused by same cause as this one.\nSo i'd sat, deeper investigation is required...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/790/files#r22465606.\n. intistics or intrinsics?\n. not sure i understand the logic. the above function is not simd at all, right? it's called plain and that's exactly what it does, no vectorisation at all? so why would i want that called if OPENMP_SIMD is set?\n. whatever. SSE has 16-byte. who knows whether the logic is really 4_sizeof(float). there are also 16_sizeof(uint8_t) operations, no?\n\nbut would any of this need to change for omp simd and avx?\n. hehe, i like it much better this way. unfortunately the code formatter will destroy it next time we run it..\n. so you did rename the innocent process() to process_plain() after all? why? to make sure it doesn't use SSE and force us to look over every single module?\n. Ope_n_MP\nokay, so the logic is there is a stray process() if you want to, and a more restricted process_plain() and a rogue process_sse() where you can use inline assembly. but why keep process() and process_plain() ? sounds like making things overly complicated and inviting people to write both at the same time?\n. a crazy lot of code. cool stuff, i'm sure it introduces subtle bugs :)\nso the modules you didn't touch yet don't do anything at all? if we were just treating process() as process_sse() because it potentially contains sse? then it would just fail for the case that the user explicitly requested omp simd/plain or has limited cpu capabilities? or how does that currently work with the three versions of process()?\n. oh, and about points.h. i vote for just replacing it by a 5-loc random number generator. it won't be pixel-identical, but random, too. my hope is that nobody was using random for pixel-precise artwork..\n. for the backbuf_width/height ones, preview_pipe->backbuf_mutex would be enough to lock (see pixelpipe_hb.c:2440)\n. that one is fine, i don't think anything other than this mutex will be locked when the input changes. unfortunately this mutex will also be locked for the whole process()ing of the preview pipe. did you notice any speed impact from this?\n. yeah all that input width access with a mutex seems like overkill to me. it's really just the size of the according  MIPF (see develop.c:222 dt_dev_pixelpipe_set_input) and only changes when changing images via exit/enter dr mode or spacebar/filmstrip.\nabout these widths/heights (backbuf same as input) i'm not all that concerned. worst thing to happen is that the gui jumps weirdly if it picks up a new backbuf width before the height is written and will be refreshed a millisecond after.\nbut the backbuf mutex can be locked in a reasonably fine-grained manner, so i think we should do it.\ninput only matters during image switching, and the preview_pipe_mutex is a pretty big thing, so not sure if worth it.\n. collapse(2) ? to give omp more freedom to schedule.\n. yeah i don't remember the details in demosaic.c. but i think it might be safer to walk over the output roi and just get whatever you need from the input for that (which may sometimes be rounded up to full bayer pattern sizes, i.e. larger than the output)\n. hard to tell from the crippled diff on github. but this is only disabling opencl for the monochrome case, right?\n. what's the reasoning of this somewhat inconsistent naming scheme with the leading underscore?\n. right, the above minus diff is probably formatted by the old code formatting tool (pre clang-format)\n. data->clip is a user parameter, processed_max is what rawspeed tells us. i\nguess you're right and we should respect whatever the user tells us, they\nprobably know better :)\nOn Wed, Mar 9, 2016 at 11:29 AM, Roman Lebedev notifications@github.com\nwrote:\n\nIn src/iop/highlights.c\nhttps://github.com/darktable-org/darktable/pull/1168#discussion_r55498875\n:\n\n}\n-  // update processed maximum\n-  const float m = fmaxf(fmaxf(\n\nLooks wrong. What about data->clip ?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1168/files#r55498875.\n. nono, after highlight reconstruction (LCh or color), the new maximum is\npotentially the /largest/ of the three channels (hence the max). only if\nyou really do conservative clipping it'll become the minimum. which will\nthrow away half of your red channel usually.\n\nOn Wed, Mar 9, 2016 at 3:10 PM, Roman Lebedev notifications@github.com\nwrote:\n\nIn src/iop/highlights.c\nhttps://github.com/darktable-org/darktable/pull/1168#discussion_r55522251\n:\n\n}\n-  // update processed maximum\n-  const float m = fmaxf(fmaxf(\n\nIn either case, data->clip * fminf() is the actual upper clipping\nthreshold.\nhttps://github.com/darktable-org/darktable/blob/90d0a0811ca00c98c587c24e350cfc4382b8f17c/src/iop/highlights.c#L549-L551\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1168/files#r55522251.\n. oops, sorry. that was on my list and i forgot about it. it should be\nstraight forward to do, if you have an hour or so please go ahead (i'm\ntravelling at this point and don't have an opencl-enabled laptop with me).\n\nOn Sun, Mar 13, 2016 at 11:59 PM, Ulrich Pegelow notifications@github.com\nwrote:\n\nIn src/iop/highlights.c\nhttps://github.com/darktable-org/darktable/pull/1168#discussion_r55935387\n:\n\n}\n-  // update processed maximum\n-  const float m = fmaxf(fmaxf(\n\nAnybody working to bring the demosaic changes to the OpenCL codepath? If\nnot, I could do it.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1168/files#r55935387.\n. k is already 64 bits, so 4*k should be, too, right?\n. sizeof(float) should be size_t, right?\n. why exactly do we need this here? sounds like asking for trouble having them on the per-iop pieces and on the full pipe, too? will this be overwritten as the pipe is processed? and then contain different data than the dsc_out on the piece? how does it work with tiling?\n. this is just a line wrapping change.. but it reminds me. is the filters variable on dsc now independent on roi->{x,y}? or do we still need to offset it according to the region of interest?\n. do i understand correctly that this leaves the exposure fusion offsets untouched, but adds an exposure bias, equivalent to applying the exposure module before this manually? the difference being that it's scaled by the exposure stops, so the interface is a bit more intuitive (and convenient, because it's right there in the same module)?. so you're not using any svd any more but always gaussian elimination? isn't that a lot slower? and what about numerical robustness?. any reason in particular why you changed the kernel function?. why remove the comment on the RBF and the reference to where the math comes from?. while this looks all very plausible to me, why do both the source and the target coordinate k and l get offset by the same value? because the buffer layouts are the same and source and target just give the region of interest to process?. are you sure this is safe? replacing -1 by 0? 0 sounds like a valid number, -1 not so much... \n",
    "edgomez": "On 11/06/2012 10:45, Richard Wonka wrote:\n\nM src/external/CL/cl.h (2)\nM src/external/CL/cl_d3d10.h (2)\nM src/external/CL/cl_ext.h (2)\nM src/external/CL/cl_gl.h (2)\nM src/external/CL/cl_gl_ext.h (2)\nM src/external/CL/cl_platform.h (2)\nM src/external/CL/opencl.h (2)\nM src/external/OpenCL/cl_platform.h (2)\nM src/external/adobe_coeff.c (2)\nM src/external/dcraw.c (2)\nM src/external/rawspeed/RawSpeed/ArwDecoder.h (2)\nM src/external/rawspeed/RawSpeed/BitPumpJPEG.h (2)\nM src/external/rawspeed/RawSpeed/BitPumpMSB.h (2)\nM src/external/rawspeed/RawSpeed/BitPumpMSB32.h (2)\nM src/external/rawspeed/RawSpeed/BitPumpPlain.h (2)\nM src/external/rawspeed/RawSpeed/BlackArea.h (2)\nM src/external/rawspeed/RawSpeed/ByteStream.h (2)\nM src/external/rawspeed/RawSpeed/ByteStreamSwap.h (2)\nM src/external/rawspeed/RawSpeed/Camera.h (2)\nM src/external/rawspeed/RawSpeed/CameraMetaData.h (2)\nM src/external/rawspeed/RawSpeed/CameraMetadataException.h (2)\nM src/external/rawspeed/RawSpeed/CameraSensorInfo.h (2)\nM src/external/rawspeed/RawSpeed/ColorFilterArray.h (2)\nM src/external/rawspeed/RawSpeed/Common.h (2)\nM src/external/rawspeed/RawSpeed/Cr2Decoder.h (2)\nM src/external/rawspeed/RawSpeed/DngDecoder.h (2)\nM src/external/rawspeed/RawSpeed/DngDecoderSlices.h (2)\nM src/external/rawspeed/RawSpeed/FileIOException.h (2)\nM src/external/rawspeed/RawSpeed/FileMap.h (2)\nM src/external/rawspeed/RawSpeed/FileReader.h (2)\nM src/external/rawspeed/RawSpeed/IOException.h (2)\nM src/external/rawspeed/RawSpeed/LJpegDecompressor.h (2)\nM src/external/rawspeed/RawSpeed/LJpegPlain.h (2)\nM src/external/rawspeed/RawSpeed/NefDecoder.h (2)\nM src/external/rawspeed/RawSpeed/NikonDecompressor.h (2)\nM src/external/rawspeed/RawSpeed/OrfDecoder.h (2)\nM src/external/rawspeed/RawSpeed/PefDecoder.h (2)\nM src/external/rawspeed/RawSpeed/PentaxDecompressor.h (2)\nM src/external/rawspeed/RawSpeed/Point.h (2)\nM src/external/rawspeed/RawSpeed/RawDecoder.h (2)\nM src/external/rawspeed/RawSpeed/RawDecoderException.h (2)\nM src/external/rawspeed/RawSpeed/RawImage.h (2)\nM src/external/rawspeed/RawSpeed/RawParser.h (2)\nM src/external/rawspeed/RawSpeed/Rw2Decoder.h (2)\nM src/external/rawspeed/RawSpeed/SrwDecoder.h (2)\nM src/external/rawspeed/RawSpeed/StdAfx.h (2)\nM src/external/rawspeed/RawSpeed/TiffEntry.h (2)\nM src/external/rawspeed/RawSpeed/TiffEntryBE.h (2)\nM src/external/rawspeed/RawSpeed/TiffIFD.h (2)\nM src/external/rawspeed/RawSpeed/TiffIFDBE.h (2)\nM src/external/rawspeed/RawSpeed/TiffParser.h (2)\nM src/external/rawspeed/RawSpeed/TiffParserException.h (2)\nM src/external/rawspeed/RawSpeed/TiffParserHeaderless.h (2)\nM src/external/rawspeed/RawSpeed/TiffParserOlympus.h (2)\nM src/external/rawspeed/RawSpeed/TiffTag.h (2)\nM src/external/squish/alpha.h (2)\nM src/external/squish/clusterfit.h (2)\nM src/external/squish/colourblock.h (2)\nM src/external/squish/colourfit.h (2)\nM src/external/squish/colourset.h (2)\nM src/external/squish/config.h (2)\nM src/external/squish/csquish.h (2)\nM src/external/squish/maths.h (2)\nM src/external/squish/rangefit.h (2)\nM src/external/squish/simd.h (2)\nM src/external/squish/simd_float.h (2)\nM src/external/squish/simd_sse.h (2)\nM src/external/squish/simd_ve.h (2)\nM src/external/squish/singlecolourfit.h (2)\nM src/external/squish/squish.h (2)\n\nEverything in ./src/external should be better left untouched as we\nbundle these sources into darktables' one for convenience. Keeping their\nsource as pristine as possible would help us future code drop ins.\ncould you please update your branch with src/external left untouched ?\nthx\n\nEdouard Gomez\n. On 01/11/2013 09:01 PM, Dennis Gnad wrote:\n\nOk, I can't merge, one of the main devs has to do this...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/147#issuecomment-12160946.\n\nMerged. thanks\n\nEdouard Gomez\n. On 02/27/2014 12:47 PM, Robert William Hutton wrote:\n\nSeems to work so far, though I had to revert 573ef41\nhttps://github.com/darktable-org/darktable/commit/573ef413 or I got\na build error on tiff.c. Will continue playing around when I have some\nmore time, hopefully this afternoon.\n\nHi,\nI'm the aauthor of that commit\nMake sure to get the next commit to that same file, I didn't realize the\ntmsize_t typedef was a libtiff4 defined typedef. In the next commit I\njust used regular size_t which seems to comply with the definition of\ntmsize_t.\nIt's in the repo for more than a few days already, so merging master in\nyour branch could help\nIn all cases, do not submit a revert of that commit please :-D\n\nEdouard Gomez\n. will do\n----- Mail original -----\n\nDe: \"houz\" notifications@github.com\n\u00c0: \"darktable-org/darktable\" darktable@noreply.github.com\nCc: \"Edouard Gomez\" ed.gomez@free.fr\nEnvoy\u00e9: Mardi 26 Novembre 2013 14:43:41\nObjet: Re: [darktable] One tonecurve inconsistency in the GUI + 32bit float TIFFs direct support  (#376)\nCould you please split this up into two PRs? It's not only that we\nare in string freeze, but more importantly we are also in feature\nfreeze. The tonecurve one I would like to merge though (and give you\nthe credit of fixing it).\n\u2014\nReply to this email directly or view it on GitHub .\n. created a separate PR for the bugfix. I left this one for later merge, when feature freeze is over.\n\nthx for the feedback guys. I knew i would have messed up the repo if i had pushed directly :-D\n. Would not it be better to just refer to float format in the export GUI just like we do for EXR and PFM formats ?\nIf you think it makes sense i'll prepare a PR for that.\n----- Mail original -----\n\nDe: \"Henrik Andersson\" notifications@github.com\n\u00c0: \"darktable-org/darktable\" darktable@noreply.github.com\nEnvoy\u00e9: Samedi 4 Janvier 2014 23:41:27\nObjet: Re: [darktable] Add support for 32bit float TIFF export. (#418)\nMerged #418 .\n\u2014\nReply to this email directly or view it on GitHub .\n. This patch series doesn't aim at promoting Tonecurve vs Basecurve. This has to be thought as a mere improvement for our users who could be interested in also being able to generate tonecurves.\n\nNow to tell the truth, for Nikon D7000, using the Nikon Alternate basecurve gives very saturated colors, using a computed basecurve with dt-curve-tool improves things a bit, but not enough for hard cases photos. Surprisingly, the tonecurve (fixed for 1,1 point) gives better images for these pics and on almost any other test image i threw at it.\nThis can be merged w/o much thought as this modifies a tool that is only available to users compiling from sources.\n. If i get no objections from the other devs in the next following days, i'll eventually merge this.\nFire up your critiques, feedback is welcome\n. On 02/26/2014 09:21 AM, Boucman wrote:\n\na README in the tool directory can be updated if we update the tools,\nwhich is a nice thing.\n\nDone.\nPlease review and give me your feedback.\n\nEdouard Gomez\n. On 03/01/2014 05:24 PM, Ger wrote:\n\nEdouard,\nMay I ask you. Do I have to checkout to a branch to test your script?\n$ git checkout ???\n\nI'm not a git expert when it comes to deal w/ multiple repositories, but\nsomething along the lines:\n$ git remote add edgomez https://github.com/edgomez/darktable.git\n$ git fetch edgomez\n$ git checkout -b tool_basecurve_improvements\nedgomez/tool_basecurve_improvements\nshould give you an opportunity to test my work.\n\nThe script, better, the output makes me curious.I would like to test it.\nJust a small note, I have read the README file on the web, JPG and RAW\nshould be of same size? This is not mentioned as far as I read.\n\nNot exactly the same size, but at least the same orientation. It takes\ncare of this, like it used to do, i get no credit here. Ah, don't forget\nabout the JPEG being sRGB.\nRegards\n\nEdouard Gomez\n. On 03/02/2014 03:54 PM, Ger wrote:\n\nEdouard,\nI tried but couldn't make the tool.\nAn error with the make file??? Any idea what's is wrong?\n$ ~/darktable/tools/basecurve# make BUILD_TYPE=Release\nMakefile:6: *** ontbrekend scheidingsteken. Gestopt.\nWhat make program are you using ?\n\n\nEdouard Gomez\n. It seems your make program behaves quite differently than mine, first it\ncomplains on line 6 which has neither leading spaces or tabs, and\nsecondly the Makefile works on my debian machine w/o any kind of\ntrickery :-D\nSo i'm trying to clear out what's different on yours.\nMine:\n$ make --version\nGNU Make 3.81\nCopyright (C) 2006  Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nThis program built for x86_64-pc-linux-gnu\nYours ?\n\nEdouard Gomez\n. @boucman does it compile for you ? because truth is @MRIG's error is weird\n. On 03/10/2014 01:56 PM, Boucman wrote:\n\nit's hard to say becauseI don't have the file around @edgomez\nhttps://github.com/edgomez : did you look into it ?\n\nThat script complies w/ POSIX shell. My /bin/sh points to dash which\ndoesn't support any bashism AFAIK. And I ran that scripts quite a few\ntimes during the development of the proposed changes.\n\nEdouard Gomez\n. On 03/10/2014 10:02 PM, Edouard Gomez wrote:\n\nOn 03/10/2014 01:56 PM, Boucman wrote:\n\nit's hard to say becauseI don't have the file around @edgomez\nhttps://github.com/edgomez : did you look into it ?\n\nThat script complies w/ POSIX shell. My /bin/sh points to dash which\ndoesn't support any bashism AFAIK. And I ran that scripts quite a few\ntimes during the development of the proposed changes.\n\nSpoken too soon. There was a debug leftover and a last minute\nbeautifiying change in strings W/ a missing leading #.\nCommitted  two additional fixes to my repo branch.\n\nEdouard Gomez\n. Last email i received from Ger had a nice tonecurve screenshot. So i think his first attempts were kludgy because he only used one shot, whereas later on, he sampled more images and obtained a correct tonecurve..\nI did some more testing on my side, and i really tend to believe Nikon makes are using a tonecurve and not a basecurve for their in camera JPEG engine. Now I added the overflow test inside the tool, i did not fear running it over a few hundreds of shots. With that save state, i computed curves that really get me colors very close to the camera JPEGs, and way more natural than the basecurve module.\nFor some testcharts and comparison shots available online this is very clear, basecurve pushes the oranges to the reds, and make them almost indistinguishable colors, whereas using a tonecurve looks much closer to \"reality\" of the comparison scene.\nhttp://www.imaging-resource.com/PRODS/D7000/D7000THMB.HTM\nI'd be glad to hear back from Canon users.\nAlso any improvement idea is welcome to increase usefulness of this tool:\n- add support for colorprofiles ? in theory having AdobeRGB JPEGs as input should help the tool calibrate the curves on a wider Gamut, very usefull for a* and b*\n- avoid the funky curves on a* and b_. As a_ and d* are very wide gamut, the useful part of the curve (ie: the central part) may not be approximated as accurately as desired because many control points are used for insignificant part of the gamut\n  ...\n. Attention here, I'm absolutely not pushing for basecurve replacement.\nThis is very sensitive change as it is used by default, all the time. Except \"power\" users that decided to start w/ an empty default style.\nI'm just trying to help in tooling and informing the project for a later decision by darkatble devs community.\n. @bronger \nwell the tonecurve/basecurve discussion is more about when to apply a curve that breaks linearity of input data, early in the pipe (basecurve) or late in the pipe (tonecurve). \nI've been informed that devs meeting at LGM will discuss these matters looking at accuracy of colors, accuracy of maths, possibility to approximate the in camera engine look etc...\nThis PR is totally disconnected from that discussion.\nThis PR is about improving an existing  tool that is currently shipped in the source package and that is way too limited to give good results even for basecurve.\nNow of course, I hope that the tool will be useful whatever decision and probably new IOP comes out of DT devs meeting. But I can't predict the future ;-D\nI also try to give some feedback about tonecurve being more accurate for the D7000. Plain fact, no hidden agenda beyond that.\n. On 04/05/2014 12:16 PM, Roman Lebedev wrote:\n\nYou have broken GCC-4.6 and clang build by merging this.\n\nNot intentionnaly.\nGCC 4.8 never reported this. Otherwise the -Werror would have catched it.\nInitial report is just about signed unsigned comparison, why did you\ndisable the loop instead of just turning the k value to unsigned int ?\nBtw, what is current policy concerning compiler support ? what version\nshould we test our changes with ?\n\nEdouard Gomez\n. AH forgot to mention, this is also material for branch 1.4\n. Pushed bad commits/I'll open a correct pull request once i fix my public email\n. On 07/22/2014 06:05 PM, Roman Lebedev wrote:\n\nIRC: | i see no problem with that one (624)|\nSo i will merge this in +48 hours if no one objects.\n\nI gave it a try, and it seems like an intrinsic header include is\nmissing for my Debian setup:\nIn file included from\n/home/ed/programming/workspace/darktable/build/src/iop/introspection_invert.c:15:0:\n/home/ed/programming/workspace/darktable/src/iop/invert.c: In function\n\u2018process\u2019:\n/home/ed/programming/workspace/darktable/src/iop/invert.c:242:11: error:\nunknown type name \u2018__m128\u2019\n     const __m128 val_min = _mm_setzero_ps();\n- a few more of these for other intrinsic types or functions.\nAdding a #include  in invert.c fixed the build\n\nEdouard Gomez\n. I need to check the D7000 curve again (i just noticed the 0 point not  being black), but the D750 is good to go.\nI'd like to start merging this after my D7000 review. Any objections ?\n. I reviewed the curves a bit more.\nBefore I put to sell my trusty D7000, I took time to compute again the curves for both the D750 and D7000. I got nice zero starting points, and limiting the number of nodes to 8 seems to limit bumpy curves.\nI also ironed out somehow the tonecurve preset setup, so that only the matching model curve shows up in the menu.\nGoing to merge in a bit as nobody objected\n. I see there is a D750 pull request already.\nFirst will sort if a D610 profile had been submitted too\n. I also understand that AlicVB is working on collect rework, so takes this PR as a reminder of a feature request from a g+ user.\nI would not be offended if it went to /dev/null if the feature is part of another better PR :-D\n. Well, the branch has been regularly master rebased, i just checked and the added filters do work.\nSo unless @AlicVB objects, this is good for merge from my POV. Then up to @AlicVB to maintain the feature in the new implementation. \n. I'll be rebasing these changes on the new branch\n. I included the requested additional changes myself. Tell me if you are satisfied\n. On 12/30/2014 09:35 AM, Matthieu Volat wrote:\n\nMaybe this is just overthinking, but maybe you'd want to include\nsomething like mazhe@795a346\nhttps://github.com/mazhe/darktable/commit/795a3461ba252e039c8dfad4855d9b80959dbe7b\nto be still able to run the script without installing?\n\nAgreed, doesn't hurt.\nThis commit and the following have been merged in master already.\nThanks\n\nEdouard Gomez\n. No objection ? I'll merge tomorrow\n. Does the rescaling happen with the color data still being linear in hq case ?\nBecause current scaling doesn't take care to linearize the data itself so it can't be done after any gamma is applied.\n. could be considered for stable as well. This fixes an annoying UI design and should have no compatibility impact\n. If no objection, will be merged tomorrow.\n. @houz fixed !\nthx. any other comment ?\n. The patch in itself ensures we only parse tk data. This is better than current approach, but in the end this PR just kills one warning visible to users looking at stderr. I propose this as PR because i'm not sure it's a valuable patch or not\n. Tested the GPX file from the bugreports and added a few printf to make sure that those valid elements are correctly skipped with this PR.\nYes, this PR also fixes #10682. Which sorts of qualifies this PR as bugfix. Great :-)\nWill you merge this and close the bug ? do we want this in 1.6.x as well ?\n. thanks @houz, if no 1.6.x release is planned then I'll just push the PR this evening on master.\n. > 1. parsing_tk should be called parsing_trk.\nDone\n\n\ndoesn't your code leak memory when there are trkpt outside of a trk?\n\n\nNot that i can think of as the new code doesn't try parse anything outside trk>, we don't even issue malloc for wptType data as was done in the old code.\nI checked importing a few GPX files and a ASAN build, no leaks reported on exit.\n\n\nformatting is off, please remove spaces between if and (.\n\n\nDone\n\n\nyou should also init parsing_trk to FALSE.\n\n\nIs already done, the gpx struct is allocated using g_malloc0 and hopefully FALSE == 0 in glib.\nAre we good for merge ?\n. > Please close that bug as fixed if this indeed fixed it.\nThanks for the commit log tip.\nI've marked the bug as Fixed in redmine.\n\nEdouard Gomez\n. > I'd say we have two options:\n\n* Accept curves as submitted by the users with minimal quality\nchecking (does it look right? does it have too many points?).\nSince we no longer autoapply per-camera base curves by default\nthis would just add new presets that users can just ignore if\nthey want. It would still result in a variable quality of base\ncurves shipped directly by us.\n* Just remove all the per-camera base curves. We don't have a way\nto validate the curves and have misgivings even about some\nalready merged. So let's at least be consistent and not have\ncurves for any camera.\n\nI'd like to share my opinion and past experience about the basecurve/tonecurve.\nIn my case, i tried to create the D7000 and the D750 basecurves/tonecurves because the ones that are shipped just don't work well: over saturation of the red/orange tones (bad for skin), kill detail in the shadows.\nBy chance the curve tool was already there, but had some limitations.\nI tried to overcome some of them, but I'm still not happy with the tool:\n- the averaging on multiple photos helps output consistent curves\n- the fact the tool has to go though multiple pictures has increased the difficulty for the user, the doc tries to workaround that but it's not enough\n- i failed at getting a_/b_ curves done right. They have some specificity that current code doesn't respect (0 is probably is point of symmetry)\nIMHO, we should spend more time on the curve tool:\n- make sure that the tool output meets some quality criteria (even the curves i did aren't good in the end, i see weird artifacts on higlight areas). We should probably check that the first derivative and second derivatives are smooth and bound to safe values.\n- improve the procedure so that we can help the user create good material to compute the curves, the denoise profile procedure is great in that regard.\n- maybe the accumulated data should be sent to the developers, the same way a tarball is created for denoise profiles ?\n- for the nikon case, why not use the curves embedded in the EXIF data ? what about the other brands ?\n- get the curves out of the code, adding curves should be easy, not a developer task, or a sqlite command. The denoise JSON approach is nice. The LUA repo approach is nice too.\nCurves are a critical part of a photography rendering. Getting rid of the current curves is nothing but hiding the fact we don't spend enough energy/time on providing good ones, or the means to create them.\nI can dedicate some time on this, but what i lacked a few months ago, was ideas and objectives.\n\nEdouard Gomez\n. I rebased on top of current master.\n. Sure I'm not in a hurry. I just happened to try an up to date version to see if one of my new lenses was supported. Then i just found out and fixed this small issue.\nAs you're preparing 2.6, i fully understand this can be put on hold. I'm ok. > Could this be because of the alpha encoding to \"exact\"? Is that even necessary for pictures?\nIt probably comes from the fact that the old code used YUV encoding and was going through the usual video encoding pipeline of VP8 codec w/ very low quantization parameter, or quantization disabled altogether.\nThe new code uses a newer encoding mode that got designed when WEBP team realized they were missing true RGB lossless encoder.\nAnd  I guess that lossless encoder didn't receive much optmization love as the video one.\nBut it's just a wild guess, I didn't follow WEBP/VP8 encoders' dev much.. On 03/05/2014 04:44 PM, houz wrote:\n\nThat sentence no verb.\n\nBest review ever.\nNo verb yet in my answer.\nTried to review and address most obvious english mistakes in 83a5ff1.\nThanks for the feedback.\n\nEdouard Gomez\n. Indeed thanks for catching this. I'll fix it this evening\n\u00c9douard Gomez\nOn 31 May 2015 16:04, houz notifications@github.com wrote:In src/iop/clipping.c:\n\n/* flip H/V, rotate an image, then clip the buffer. /\n typedef enum dt_iop_clipping_flags_t\n {\n-  FLAG_FLIP_HORIZONTAL = 1,\n-  FLAG_FLIP_VERTICAL = 2\n-  FLAG_FLIP_NONE = 0,\n-  FLAG_FLIP_HORIZONTAL = 1<<0,\n-  FLAG_FLIP_VERTICAL = 2<<1,\n\nDon't you mean 1<<1?\n\u2014Reply to this email directly or view it on GitHub.\n. addressed in 331aa0e\n. addressed in 331aa0e\n. addressed in 331aa0e\n. addressed in 331aa0e\n. Oops i didn't see that comment in my email.\nIt was easier to just move the MAKE_vars lines above features_set_to_autodetect call.\nToo bad you merged fast. I'll just modify directly the script as it's a very small change, it makes the code more straightforward\n. My take on this is that the L values are only going to match the reference values in very specific cases during the shot and there are probably more risks at trying to adjust L values differently depending on their chromaticity.\nFor example, if the target is not lit homogeneously (close speedlight w/ rapid falloff, or target hold w/ an angle to light source), matching L would mess up L values for the different patches depending on their physical position in the scene.\nHence my comment about letting users adjust L* globally on the image.\nBut I have no strong opinion on this. What's yours ?. ",
    "upegelow": "Hi Gabriel,\nthanks! Patch is merged into master.\n. Hi Franz,\nsorry for being so late in testing. Looks really good. I will commit to master. One small thing. There seems to be no clean-up of the cache. So the cache might fill up quickly with pre-compiled opencl binaries, especially for developers. Maybe you should at some time add a clean-up function.\nUlrich\n. Thank you, I just pulled your changes. You will notice that I made a few minor changes to your proposed OpenCL code. That's mainly to avoid branches in the double for-loop and gives a tad faster performance.\n. Fully true. That's a left-over from a debugging  phase. In the end the if-clause will only be FALSE if something is really wrong (button release event passed by unnoticed). In normal operation it should always be TRUE. Maybe I should convert it into an assert statement.\n. Hi,\nthanks for your proposal. The reason we are checking for the package is that FindXslt.cmake will look for saxon and saxon extensions in the first place. If found they take precedence. xsltproc is only used as a fall-back. It is not able to produce a nicely looking usermanual unfortunately.\nCould you please check if the following sequence would work on Debian unstable? It tries to combine the best of two worlds:\nfind_program(Fop_BIN fop)\nfind_program(Xml2po_BIN xml2po)\nfind_package(Xslt)\nfind_program(Xslt_BIN xsltproc)\nif(${Fop_BIN} STREQUAL \"Fop_BIN-NOTFOUND\")\n    message(\"Missing fop\")\n    set(can_build_usermanual OFF)\nendif()\nif((NOT Xslt_FOUND) AND (${Xslt_BIN} STREQUAL \"Xslt_BIN-NOTFOUND\"))\n    message(\"No Xslt processor found\")\n    set(can_build_usermanual OFF)\nendif()\nif(NOT Xslt_FOUND)\n        set(XSLT_XSLTPROC_EXECUTABLE \"${Xslt_BIN}\")\nendif()\n. There are in fact two elements in this PR. The first issue has been fixed in-between although in a slightly different manner.\nThe second topic is the idea to put some documentation into usermanual on how to back up library.db. This documentation will\nneed some further work and should then be put into a new pull request. This one will be closed.\n. Thanks for making this pull request. I like the final results and the ease of working with your colorpickers.\nI have some concerns with the internal way of working, though. You store color picker positions in module parameters - you probably\nwant to have them saved so you can at a later point in time come back to the old positions. However, I see this as problematic. We should\nalways consider module parameters as an entity that can easily be copy-pasted onto other images or put into a style. Colorpicker positions\non the other hand are specific to a certain image. The same positions are useless on other images.\nSo you should consider to separate module parameters and GUI related stuff - colorpickers belonging to the GUI.  Maybe have a look at module \"exposure\" where users can select a rectangular area in GUI that then helps to calculate fitting whitepoint and blackpoint values. \nIt's not easy to do so, I know, and might lead to deadlocks if not done correctly, but I think it must be done.\n. Hi Josef,\nI like the idea. Quite frequently I am in the situation to have no real idea on the zoom factor.\nA few thoughts:\n- I think the position left to the navigation window is not optimal as it adds to graphical clutter. I would prefer to have the percentage printed close to the navigation frame within the preview image. Ideally within the frame (upper left corner or so). If the frame is too small the text should move out of the frame but close to it - ideally still within the preview image.\n- Not sure if this is possible: the text might go away a few seconds after last change to zoom or to navigation frame. But that's not too important. \n. For the \"working ...\" approach you should consider that the time it is visible strongly depends on the complexity of your pixelpipe and the speed of your computer. Might go down to a few ten milliseconds where it's hardly readable.\n. @TurboGit: thanks for testing. In fact this patch is only a first step to get position updates right - my focus was to first get rid of the annoying jumps as they make for a rather unprofessional look. Mid term - after 1.4 - there is the need for a more general rework. Some issues to fix: currently the position of a collection is not restored reliably; the fact you described where the thumbs would only be displayed correctly after you mouse over the center image; ...\n. Seems to work and anyhow not a big deal with low risk to screw things.\n. We had it in the past and it caused a lot of problems by giving wrong results. Lens parameters have the property that you either get the single correct set or better nothing at all. There is no \"closeness\" of lenses with similar names when it comes to lens parameters.\nTo my understanding the issue to be solved is the following: exiv2 reports a different name than lensfun has assumed. A list of alias names would be the best solution IMHO. Especially taking into account that users may maximum have just a few lenses which don't fit: done once and then it's fixed forever (at least as long as exiv2 and lensfun's database don't change).\n. Translation work on the usermanual should be done in master. Branch usermanual contains some reformatting of the english version in order to make the code pass xmllint and to make it more nice looking in the editor. We should first get the translations done, then merge branch usermanual and make the (hopefully few) needed adjustments.\n. One small comment: you should consider to give the public functions (i.e. the non-static ones) of your histogram library a name that clearly makes them part of the darktable naming scheme. Most likely by just prepending \"dt_\" to them. Else we might run into problems as third party library which we link against might also decide to offer a histogram_worker() function and the like.\n. I continue to struggle with the bootstrap process. Here is my luarc:\nusermanual = require \"usermanual\"\noutfile =io.open(\"/home/pegelow/darktable/darktable/doc/usermanual/lua/lua_api.xml\",\"w+\")\noutfile:write(usermanual.get_doc())\noutfile:close()\nos.exit()\nAnd this is the output of '-d lua':\nLUA ERROR : should never happen\nstack traceback:\n        [C]: in ?\n        [C]: in ?\n        [C]: in function 'for iterator'\n        /home/pegelow/.config/darktable/lua/core.lua:138: in function 'document_type_from_obj'\n        /home/pegelow/.config/darktable/lua/core.lua:206: in function \n        (...tail calls...)\n        /home/pegelow/.config/darktable/lua/core.lua:144: in function 'document_type_from_obj'\n        /home/pegelow/.config/darktable/lua/core.lua:189: in function \n        (...tail calls...)\n        /home/pegelow/.config/darktable/lua/core.lua:607: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/.config/darktable/lua/content.lua:1: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/.config/darktable/lua/usermanual.lua:26: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/.config/darktable/luarc:1: in main chunk\nTo be honest I never successfully used Lua.\n. Spontaneous feedback concerning content. Main problem is overflow of information that forces us to streamline a bit.\nVersion history is of low relevance for the usermanual, we should skip that.\nThe attributes field is a mass of details that most people will not be able to decode. The previous version was quite concise, now its a bit bloated.\nSome synopsis lines are exceeding the right border. We had one or two of those in 1.4, which I fixed manually. Now there are many more and one should consider to do that automatically.\n. I had copied the .lua files into my ~/.config/darktable/lua folder. But even with adding the original lua_doc directory to the search path does not help. The error message remains the same.\nShall we continue to discuss it here or should I open a redmine ticket?\n. Sorry, does not work. Even with an empty library.db I get an error. A different one this time:\nLUA ERROR : /home/pegelow/darktable/tools/lua_doc/core.lua:471: attempt to index local 'node' (a nil value)\nstack traceback:\n        /home/pegelow/darktable/tools/lua_doc/core.lua:471: in function 'set_alias'\n        /home/pegelow/darktable/tools/lua_doc/content.lua:313: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/darktable/tools/lua_doc/usermanual.lua:26: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/.config/darktable/luarc:2: in main chunk\n. Well, I think it would be best that I step out of the lua_api.xml generation business and I would prefer that you take care. I installed webp and recompiled, then started with a complete virgin configdir and I still fail to run lua:\n[defaults] found a 64-bit system with 16444472 kb ram and 8 cores (0 atom based)\n[defaults] setting high quality defaults\n[mipmap_cache] cache is empty, file `/tmp/mipmaps-9d21b425574bb004e9bf37c1209e3854980bdba2' doesn't exist\nwarning, avoid problems with picasa/facebook\nLUA ERROR : /home/pegelow/darktable/tools/lua_doc/core.lua:536: not a function documentation : undocumented\nstack traceback:\n        [C]: in function 'error'\n        /home/pegelow/darktable/tools/lua_doc/core.lua:536: in function 'add_parameter'\n        /home/pegelow/darktable/tools/lua_doc/content.lua:477: in main chunk\n        [C]: in function 'require'\n        /home/pegelow/darktable/tools/lua_doc/usermanual.lua:26: in main chunk\n        [C]: in function 'require'\n        /tmp/luarc:2: in main chunk\n. Well, I am lost with that topic. I can do what I want, this lua code crashes for me. It's regardless of the the fact if I am working on my filled library or on an empty one. The error messages and stack trace are different but the end result is the same.\nConcerning the branch I am using. I am sure that is the lua_usermanual branch from this pull request. The last commit is 716c3529029589c1eb6ed8a14d0be46f8e012162.\nI am for from being able to debug that lua stuff myself. If you want me to be of any help you will need to give me clear advice what to test.\n. Yeah, let's merge it.\n. I just have checked our manual with xmllint. Unfortunately it does not pass the tests due to a few aspects in lua_api.xml. At first sight I identified two issues:\nFirst:\n```\nreturn\nvariable\nNothing for \"wait_ms\" and \"file_readable\"; the returned code of the command for \"run_command\".\n\n```\ndoes not conform as the word \"variable\" is not put into any container. We had it in the  container in the previous version which printed it in a courier font. We should put it into  now. This holds true for a lot equivalent items.\nSecond:\nCurrently every section is put into a  environment. That is not a valid environment for docbook. We need nested structures of , , ... . We had that structures in the 1.4..x version of lua_api.xml.\nThe reason I am insisting on that is the fact that checking the validity of the xml code via xmllint is the only way of detecting certain bugs. Currently this is not possible as the error messages caused by lua_api.xml will flood all other issues one might want to detect.\n. Cool, the first issue is fixed.\nThe second one remains. Let me try to explain. In lua_api.xml you are using nested  environments for structuring the content. However, docbook does not allow that -  is not a valid element in a docbook document. Instead you need to use  nested , over  etc. till  to describe the structure. This means you have to keep track of the nesting level of the content and use the right environment. BTW: we had this issue already some time ago; then you fixed it for the 1.4.x version of the manual.\n. This code on my system leads to darktable immediately crashing at startup:\n1  0x00007f348b5632fb in _dt_sigsegv_handler (param=11) at /home/pegelow/darktable/src/common/darktable.c:163\n    pid = <optimized out>\n    name_used = 0x278ce40 \"/tmp/darktable_bt_ON9FFX.txt\"\n    fout = <optimized out>\n    delete_file = 0\n    datadir = \"/usr/local/test/share/darktable\\000\\000\\000\\000\\000\\002\\000\\000\\000\\240uu,\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\240\\b\\000\\000\\000\\000\\000\\000\\000\\060wu,\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\240uu,\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000_s\\300\\204\\064\\177\\000\\000\\000\\000\\000\\000\\064\\177\\000\\000\\031\\000\\000\\000\\064\\177\\000\\000\\000\\000\\000\\000\\000\\000P\\303\", '\\000' <repeats 12 times>, \"\\005\\000\\000\\000C\\000\\000\\000\\000\\000\\000\\000\\374\\262C\\000\\000\\000\\000\\000B\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\000\\064\\177\\000\\000\\v\\000\\000\\000\\001\\000\\000\\000\\360\\002r\\002\", '\\000' <repeats 12 times>, \"Pw\\344\\210\\064\\177\\000\\000\\031\\000\\000\\000\\000\\000\\000\\000\"...\n    pid_arg = 0x27b2f10 \"11039\"\n    comm_arg = 0x2796a50 \"/usr/local/test/share/darktable/gdb_commands\"\n    log_arg = 0x27b1cd0 \"set logging on /tmp/darktable_bt_ON9FFX.txt\"\n\n2  \nNo symbol table info available.\n3  reload_defaults (module=0x27b72d0) at /home/pegelow/darktable/src/iop/lens.c:1040\n    gd = 0x0\n    dt_iop_lensfun_db = <optimized out>\n    img = <optimized out>\n    tmp = {modify_flags = -1124075202, inverse = 0, scale = -2.34800244e-34, crop = 4.56318832e-41, focal = 4.68773797e-38, aperture = 0, distance = -4.01773625e-32, target_geom = 32564, camera = \"\\377\\377\\377\\377\\000\\000\\000\\000\\061\\r\\234\\207\\064\\177\\000\\000\\350n\\264\\204\\064\\177\\000\\000\\310$\\267\\213\\064\\177\\000\\000\\230!z\\002\\000\\000\\000\\000\\004\\000\\000\\000\\000\\000\\000\\000Xh|\\001\\000\\000\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\b\\017\\177\\001\\000\\000\\000\\000('\\356\\204\\064\\177\\000\\000` `\\000\\000\\000\\000\\000,\\001\\000\\000\\000\\000\\000\\000\\340\\240u,\\377\\177\\000\\000\\227\\242\\270\\204\\064\\177\\000\\000\\200\\350R\\002\\000\\000\\000\\000\\060\\000\\000\\000\\060\\000\\000\", lens = \"\\340\\213u,\\377\\177\\000\\000 \\213u,\\377\\177\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000('\\356\\204\\064\\177\\000\\000`\\001\", '\\000' <repeats 38 times>, \"\\024\\000\\000\\000\\065\\000\\000\\000[\\000\\000\\000n\\000\\000\\000w\\000\\000\\000|\\000\\000\\000\\\\000\\000\\000n\\000\\000\\000@\\026\\356\\204\\064\\177\\000\\000\\060\\001\\000\\000\\000\\000\\000\\000\\b\\017\\177\\001\\000\\000\\000\", tca_override = -2064767192, tca_r = 4.56318832e-41, tca_b = 8.82782159e-39, modified = 0}\n    new_lens = 0x27b72d0 \"\\200\\267h\\002\"\n    model = \"\\000\\000\\000\\000\\000\\000\\000\\000\\330\\r\\266\\213\\064\\177\\000\\000\\005\", '\\000' <repeats 15 times>, \"\\001\\000\\000\\000\\000\\000\\000\\000(\\027\\275\\213\\064\\177\", '\\000' <repeats 18 times>, \"8\\342}\\001\\000\\000\\000\\000\\030\\024q\\002\", '\\000' <repeats 12 times>, \"8\\342}\\001\\000\\000\\000\\000\\000\\000\\000\"\n\n. @LebedevRI: I'd like to ask you to revert your commit. It's a serious bug as it leads to an immediate crash. This should be sorted first before finally committing.\n. Thanks. One remark: lua_api.xml can be left alone. It's auto-generated from the sources by a script.\n. I need to revert the merge as I learnt that the manual with your changes does not compile:\nparser error : Entity 'mdash' not defined\nPlease try to find a solution for the mdash topic or change back to '-'. It would be a pity to lose all the other valuable changes.\n. OK, I fixed it.\n. I think that pull requests are no longer the right tool for user manual changes as soon as they affect more than unifying typography. In the end your last batch of changes affects mostly stylistic elements. People tend to have different opinions on how to phrase something and a pull request translates to something like \"take it or leave it\". Well, in this case I'd leave it. As the maintainer of the manual I appreciate any comments and suggestions but finally I need to decide for the final text.\nMy preferred way of receiving stylistic suggestions is as annotations into a PDF (either with Acrobat or alternatively you can use xournal).\n. Yes, you need create the PDF. After you have compiled darktable do the following:\ncd ./build\nmake darktable-usermanual\nand find the PDF in ./build/doc/usermanual\n. As discussed we close this pull request and use PDF annotations for further style improvements.\n. After short discussion on IRC I had a look at the usermanual changes: all fine!!!\n. I did a few checks with older edits. So far all masks are converted correctly.\nSmall recommendation: you should move the masks version number as a makro definition into masks.h.\n. merged following discussion on IRC\n. I don't like it. Putting code parts into include files breaks automatic re-processing of pre-compiled kernels (never liked common.h and colorspaces.cl in the first place). So please leave it as it is.\n. Sorry, I made a mistake when commenting. So I reopen it and will give a detailed comment later.\n. OK, let's hope I don't screw it this time :)\nFirst of all I like your documentation already a lot! Only a few recos:\n1) I would suggest the following three index terms: \"module .. defringe\", \"defringe\", and \"purple fringing\"\n2) When you explain the sliders it would be great if you could shortly explain the consequences of setting higher or lower values.\n3) Maybe you could split some of the longer sentences to ease reading.\nDo you have a striking example with images before/after defringing?\n. OK, understood. Just give me a hint when you think this PR is ready to merge.\n. @LebedevRI: my PR is relative to master, it does not contain code of PR717. I also see the garbage on this specific image, but no longer if I merge PR717. Can you confirm?\n. OK, I also see the garbage now. Happens when you zoom into the image.\n. I close this pull request and will open a new one without commits from PR717.\n. Merged. I'll take care that we have one of the native speakers go through it for proofreading.\n. @LebedevRI: can you supply a test case please? I'd guess that blending in \"raw denoise\" is the most typical one, right?\n. There is certainly something fishy in the pre-demosaic blending, but I'm not sure if this PR goes into the right direction. First, so far I did not manage to cause a crash with current master - any hints? \nThen secondly I see the following problem: \nWhen you activate blend mode \"difference\" in raw denoise with an opacity of 100% you would expect to get a mostly black image with only the areas \"highlighted\" where raw denoise alters the image. This works as expected with current master. However, with this pull request you get something completely different.\nI would need to have some further look in the next days.\n. @LebedevRI: I'll have a closer look tomorrow. Besides the issue you mention there are two other problems:\n- drawn masks don't seem to have any effect :(\n- the \"display mask\" feature results in a strange looking output\n. Yeah. Probably we are not well advised to have an outer for-loop going in steps of 4 and then an inner switch statement that differs between color spaces. Better would b an outer switch statement and an inner for-loop.\n. I would not go to call it a new feature. It's a bug fix. However, as we are close to release 1.6 and because the underlying bug is a rather infrequent GUI-only problem, let's merge after 1.6.\n. No probs found in testing. Let's merge.\n. Fine if there is a better way.\n. I suggest we merge. We can always drop double buffering if we find a better fix later.\n. reserved1 and reserved2 have been in there from the beginning, never been exposed to the user and always initialized to 0.0f. So it should be safe :)\n. Looks good and it's more than reasonable to handle command line parameters in one single place.\n. Although the deltas are hardly noticeable in real life images even at 200% magnification, let's keep the algorithm in sync with dcraw and RawTherapee.\n. I had a look at the OpenCL code. It works, however, it's not set up in an optimal way. It's best to avoid branches in OpenCL if possible as they slow down processing. Here we could put together all checks of the individual coordinates ppi[0..5] and only have one branch. Something like the following would work:\nbool valid = true;\nfor(int i = 0; i < 6; i++) valid = valid && isfinite(ppi[i]);\nif(!valid)\n  {\n    pixel = (float4)0.0f;\n    write_imagef (out, (int2)(x, y), pixel);\n    return;\n  }\nThe same could of course be written without using a boolean variable by directly combining the isinite checks - gets a bit unhandy then but YMMV.\nUlrich\n. @AlicVB: thanks for reviewing. So let's merge.\n. I'm having issues to build with openSUSE 13.2. The version of cups is 1.5.4.\n/home/pegelow/darktable/src/common/cups_print.c: In function \u2018_detect_printers_callback\u2019:\n/home/pegelow/darktable/src/common/cups_print.c:133:3: error: implicit declaration of function \u2018cupsEnumDests\u2019 [-Werror=implicit-function-declaration]\n   const int res = cupsEnumDests(CUPS_MEDIA_FLAGS_DEFAULT, 30000, &_cancel, 0, 0, _dest_cb, pctl);\n   ^\n/home/pegelow/darktable/src/common/cups_print.c:133:33: error: \u2018CUPS_MEDIA_FLAGS_DEFAULT\u2019 undeclared (first use in this function)\n   const int res = cupsEnumDests(CUPS_MEDIA_FLAGS_DEFAULT, 30000, &_cancel, 0, 0, _dest_cb, pctl);\n                                 ^\n/home/pegelow/darktable/src/common/cups_print.c:133:33: note: each undeclared identifier is reported only once for each function it appears in\ncc1: all warnings being treated as errors\n. cups 1.5.4 is the most recent one offered in openSUSE 13.2 which in turn is the current version of that distro. No option to upgrade, so I would be out :(\n. Having a first look I discovered an issue with some dangling cross references in lua.xml. These cross references should be replaced by an  to the manual. We don't have the specific place yet, but it will certainly end up under http://www.darktable.org/resources/\n. @LebedevRI, @houz thanks for review. I'm gonna merge it.\n. Hi Michel,\nmaybe you can have a look at commit 80ac7f3c9d67113a85c515eb8584de8c5c13e780 and how it affects the french manual version. Let's hope we don't see too many changes before 2.0 :)\n. Late comment as I have been out a few days. Generally I like the images, although the image of the darkroom mode lacks a bit of \"reduction\" in my personal opinion :)\nWhat I don't like is the manual editing and overwriting of some elements in the image information panels. Probably you crossed out your name? So you should remove the manual editing or rename the corresponding elements (author field, film roll, whatever) of the image and repeat the screenshot.\n. Looks good to me and seems to fix the issue. I suggest to merge.\n. There are modules where benchmarking results would vary a lot depending on module parameters. demosaic is an example. For some demosaicing methods OpenCL typically performs ahead of the CPU, for others it might drop behind.\n. My tests on AMD and NVIDIA hardware reveals that the code is working as expected. In terms of performance evaluation I need some benchmarking data from more users.\n. > This block is bothering me:\n\nhttps://github.com/darktable-org/darktable/blob/385801d7e6643790f3fddf437856e8c759b41dd2/src/iop/demosaic.c#L3256-LL3263\nhttps://github.com/darktable-org/darktable/blob/385801d7e6643790f3fddf437856e8c759b41dd2/src/iop/demosaic.c#L3527-L3532\nShouldn't those 2 cases in|commit_params()| also check\n|darktable.opencl->enable_markesteijn|, and if it is |0|, do\n|piece->process_cl_ready = 0;| ?\nElse i think we are risking to see that |\"[opencl_demosaic] Markesteijn\ndemosaicing with OpenCL not enabled (see\n'opencl_enable_markesteijn')\\n\"| when user zooms-in close-enough, no?\n\nThat's in fact intended. Markesteijn is still slow, even on GPU. \nTherefore we use VNG (or even linear interpolation) if we are zoomed-out \nenough. The zoom status is not known in commit_params, so we can either \ngo or not go the OpenCL route. Not going the OpenCL route while we could \ntake advantage of the fast VNG interpolation would be a pitty.\nWorst thing that could happen: user has decided to de-activate the \nopencl_enable_markesteijn option (it's enabled by default). Then when \nzoomed in darktable falls transparently back to CPU code: besides of the \nspeed no user visible difference. Only if the user decides to run with \n-d opencl and then inspects the output he will be reminded that he \nswitched off the opencl_enable_markesteijn option. An informative \nmessage, so the user might reconsider his decision. Nothing to worry about.\nIMHO it should stay like this. Alternative: we completely skip the \nopencl_enable_markesteijn option. However, I am not yet 100% sure if \nthere might be users who will then suffer a lot from a processing speed \nthat is even slower than the CPU. For them it would be a good relief to \nhave this option other than completely switching off OpenCL.\nUlrich\n. Good initiative to rework c&r as it tends to be overloaded or virtually impossible to maintain (had my own experiences with that...)\nMain advantage of ashift over all manual perspective corrections would be ease of use in case of not-so-clear image features (either blurry and difficult to accurately spot or too many too small ones).\n. The module is mostly ready now. A few quirks are remaining but they shouldn't be show stoppers. Needs some testing by a broader audience so I suggest to merge soon.\n. Both are changed versus the original ones. The changes in LSD are minor, the ones in nmsimplex are quite significant. Changes vs. original are documented in the headers.\n. In this case overhead of going multi-threaded is probably slowing down things. In contrast to lens.c this module will only make an affine transformation of the image. So the rectangular image will transfer into a tetragon with straight lines between the corners. Therefore we only need to visit those four corners to get the roi's. The for loops are just a lazy form of expressing that :) I could as well have stated the four checks individually.\n. Thanks for reporting that. I am not very familiar with the grid packer which I needed to use it here for the first time in order to get a halfway structured layout. I decided to force all columns of the grid to the same size. Obviously the larger size of the text label now determines the total size and leads to the observed issue. Might get even worse for many translated strings. I have to see how to solve this differently. Ideally I would give the text label the space that it needs (plus some extra) and let the three other columns use all the remaining space in an equal distribution.\n. > About those 0.5 hard limits for shift - are they really hardcoded deep down in code, or can they be easily changed to something bigger? I would prefer for them to be bigger.\nI orignally had a value of 1.0 here but then I found that all cases where you still can extract a reasonably sized rectangular image have a  lower shift value. So let's see what users report.  We can at any time increase this value if needed.\nConcerning the rotation angle. I find the mathematically correct polarity a bit counter intuitive - moving the slider right turns the image \"left\". But I understand that we should have rotation sliders behave the same in darktable modules. So I will change that in ashift.\n. If there are no objections I'll merge soon.\n. > hmm, would it be possible to add a \"self\" parameter to this ?\nHow should this look like?\n. Please check if this is what you want. Callback needs to be defined now as\nfloat callback(GktWidget *self, float inval, dt_bauhaus_callback_t dir)\n. You're welcome :)\n. Yeah, I've seen that and it's the way our lens module reliably gets the camera crop factor in the end. Not sure if it's worth to use it in a broader way. Most critical point would be the fact that lensfun will not be available on all systems (even the lens module is only integrated if lensfun is found at compile time). In the end I'd prefer to have not too many cross-dependencies. It's nice if exif_crop is available, OTOH it's also not a too big issue if users need to set this manually.\n. > Not sure there is anything here to review, but just to be sure...\nLooks good.\n. I'd go for 600 and add a comment why we have that offset. This will make clear that there are no magics involved in case some other developer requires an adjustment at some later point in time.\n. I stumbled over a minor syntax issue in function hexmap(). At least for me gcc complaints about a type mismatch of the third argument. Defining the function as \nstatic inline const short *const hexmap(const int row, const int col,short (*const allhex)[3][8])\nfixes the problem.\n. Looks good now. I'll merge.\n. Changes should be complete now. Anybody interested is invited to review.\n. Looks like the original xtrans code never really worked. In that case \nit's a bugfix with no need to support legacy history stacks.\nUlrich\n. @LebedevRI: please tell me when I should take over with this PR.\n. @LebedevRI: thanks. I only made a few linguistical changes .\n. @LebedevRI: cool! All good.\n. In terms of content I'm fine as far as the manual is concerned.\n. Looks good. I think a tiling overlap of 4 could be a good default value.\n. Please do so.\n. I tested with OpenCL using an NVIDIA device and an AMD device, respectively. No problems with the color picker so far.\nThe \"manual\" mode in white balance still does not work with OpenCL.\n. > Not sure what that is about, but since you used word \"still\", i'm guessing it is not a regression, so i can skip it.\nIt's certainly a regression. Just checked and it works in the 2.0.x branch. Will need to bisect to find the point where it got lost.\n. It's \"spot\" mode in preset. Special case here is: I am running also the preview pipe on GPU (a different one than the full pipe). I will try to bisect tomorrow.\n. @LebedevRI \nOK, I see. Obviously the OpenCL code needs to be adapted according to the CPU code. I'll take care.\nBTW: a small naming issue: IMHO we should rename pixelpipe_picker_helper() as its name obfuscates its function. The \"helper\" suffix should better be reserved to the functions in color_picker.c\n. Testing the proposed code works here for both, AMD and NVIDIA devices.\nIMHO it's not fully clear from the opencl specs if params_value_size_ret in clGetDeviceInfo() gets filled in even if param_value and param_value_size are both NULL/0.\nThe relevant statements are: \"param_value_size_ret returns the actual size in bytes of data being queried by param_value.\" and \"If param_value is NULL, it is ignored.\"\nSo one could read it as: if param_value is NULL no data is queried (obviously) and due to that param_value_size_ret receives 0 as output, i.e. the actual number of bytes transferred.\nAs written before the most relevant implementations of OpenCL devices behave as you hoped but probably no guarantee.\n. OK, worst thing that could happen is that either params_value_size_ret receives 0 or does not receive a value at all. One could pre-initialize the variable with -1 (0xffffffff) and then check for *params_value_size_ret == 0 and == 0xffffffff. If this happens one could allocate a buffer reasonably big (2048?). \n. > I'm not too sure about guessing and allocating e.g. 4096 bytes if we did not error-out, but if you insist..\nProbably not needed. We should check each return value of dt_opencl_get_device_info() within opencl_init() and disable opencl in case of errors. \n. > hmm, so you propose:\nSomething like that. I'd probably emit the error message within dt_opencl_get_device_info() (\"[opencl_init] could not query device info\"). \nThen something like:\nif(err != CL_SUCCESS) goto finally;\n...\nSo we don't have too much verbosity in the code which in the end reduces readability.\n. Hmm. Doesn't seem to work. I get this:\nhttp://pastebin.com/H5wpEw6e\nWhile I would expect to get:\nhttp://pastebin.com/xYPzLPLf\n. Looks good here.\n. I don't see any issues.\n. Interestingly the opencl specs don't define explicitely what happens for \nclReleaseMemObject(NULL). So in any case we should catch that case in \ndt_opencl_release_mem_object(). I'll take care.\n. I think that's a typical way of handling docbook stylesheets (though I \ndidn't set this up myself).\nFrom the docbook stylesheet manual:\nYou do not actually have to download the stylesheet files to use them. \nMost XSL processors, if given a URL instead of a filename, will fetch \nthe stylesheet over the Internet. However, because the DocBook \nstylesheets are big and use many file modules, this process uses a lot \nof network bandwidth and greatly slows down the processing of your \ndocuments. But it can be used in a pinch when you are on a machine that \ndoes not have the stylesheets installed. For example:\nxsltproc  \\\n    http://docbook.sourceforge.net/release/xsl/current/html/docbook.xsl \\\n    myfile.xml\nAm 16.10.2016 um 11:42 schrieb Roman Lebedev:\n\n@upegelow https://github.com/upegelow\nam i missing some packages?\nwhy does it try to get xsl from the internet?\n. @LebedevRI\nUnfortunately no idea how to make xsltproc faster. As an alternative to \nactually building the manual we could test the sources for consistency \nwith xmllint:\n\nxmllint --xinclude --noout --postvalid darktable.xml\nThat's even more picky than xsltproc.\n. As discussed: in real life nothing.\n. As discussed: the specs don't explicitely tell what happens for NULL. \nBut all real life implementations seem to accept it.\nI will take care of that in due time.\n. I think we are not fully there. The function in question is modify_roi_in(). That function receives as parameter the coordinates of an output buffer (either the full one or a partial window). It now calculates what part of the input buffer would be needed to process the output buffer.\nPreviously all coordinates of the output buffer (full or window) were considered for this question. Now we only take the rectangular rim of the output buffer and see what input area is needed for them. Could a situation occur where pixels from the internal part of the output buffer (inside the rim) require processing input pixels beyond that area?\n. So, my interpretation is:\n- we need to make sure that darktable doesn't crash while trying to access coordinates that are outside of the input image. AFAIK that's already the case. The interpolation routines in the CPU path take according action, and the OpenCL sampler anyhow will guarantee that we always get some kind of a valid reading into the input buffer.\n- in some cases we might face issues where lensfun creates an output with invalid (black) pixels. However, these cases are due to broken lensfun profiles and are anyhow out of bounds for darktable.\nWhich means: we are safe to go with this PR (in darktable 2.3).\n. Has been discussed with AlicVB offline and we are good to go.\n. Good point. However, I think we are in string freeze for 2.2.0 so we can only merge after the release.\n. >  It seems that for the pencil the shift-scroll still change the size of the object and not the feather. Do you confirm that?\nThis is true. The brush shape works differently from the other ones. It is defined by size+hardness rather than size+feather. \n. > Last-minute new feature addition into masks(!) is the worst.\n\nJust saying.\n\nWell, and now?\n. Not being happy is not a call for action. So we either merge or not.\n. @TurboGit: knowing that French text tends to be longer than the English one, could you please have a look if we get into issues with the changed hinter messages? The one for the ellipse shape is probably the longest one. \n. To me the biggest problem of the clipping module is that it has evolved over several years without a consistent mathematical approach. So every element has been put on top of the other (clipping margin, rotation matrix, perspective shear) plus the strange way of generating the final correction data over several steps (commit_params, modify_roi_out, process).. Let's also first see if lensfun brings enough to the table. After all rotation and perspective correction are not directly lens bound and can be implemented in a straightforward way with homographic conversions (like in ashift). I am a bit concerned to rely on a fresh implementation in an external library as any incompatible changes in that library will put the burden on us to guarantee legacy behavior.. Travis reports errors on MacOS but I don't think they are related to this PR.\nIf no objections I'll merge tomorrow.. @dtorop: I have concerns with the downscaling early in the pixelpipe. You know that the preview is not only used for display purposes but some modules like perspecitve correction need to take its nput when they want to see the full image rather than the potentially zoomed-in center view. Currently the preview is typically like 1350 x 900. If we go down to 720 x 450 early in the pipe a lot of resolution is lost. For perspective correction this means that the accuracy of the automatic fit will drop clearly. . Looks good to me.. Detection of the situation is most likely module specific. Handling should be generic. Question is what to do? As said in the redmine ticket we could offer a shortkey to reprocess the center view (Ctrl-R?) and give a hint with dt_control_log() or have a more discreet way to flag this situation (like a symbol in the navigation view popping up...). So, that's how it could work.. To test one could add dt_iop_nap(500000); early into dt_dev_process_preview().. > Hopefully tomorrow.\nBump (friendly reminder).. @LebedevRI: nevertheless thanks for having a look. \nI guess I'll merge then soon and wait for user reaction. Normally it should be OK.. >  I get a short status popup \"inconsistent result\"\nThis means that the pipe synchronization has timed out. The full pixelpipe waits up to about 0.5s for the preview pixelpipe to catch up before timing out.\nWhat I wonder is why your history stack makes the preview pipe run so slowly on the CPU. . Please consider to use variable names width and height rather than N0 and N1. We use the former ones throughout the code in darktable.. I don't know for sure but judging from the many new_xyz_image() calls it seems that haze removal uses quite a lot of temporary memory space. In order to not exceed the amount of available memory we have the option to call process() in a tiling context. Now that most users have moved away from semi-deprecated 32-bit systems memory limitations are typically not a big issue any longer, at least for \"normal\" images - but you never know if users want to process a stitched huge panorama. To activate tiling you need to supply a tiling_callback() function and you need to enable the IOP_FLAGS_ALLOW_TILING flag.. >  I estimated the amount of temporary storage for a 30 mega pixel image to about 2GB. \nThat's massive! Probably the highest overhead of any of darktable's modules. If this module would not require tiling then we should get rid of tiling in the first place. Let's assume a user has a nice NY picture taken from the ESB stitched from 10 single images and totalling at 200 mega pixels. A nice image, if it were not for the haze. Throw it at the dehaze module in darktable ... here we go.\n\nWill the sizes of the input and output regions of interest that are processed in the process function differ by (twice of) this amount?\n\nNo, process() is called in the same way as it would be called by any region of interrest (roi) that you would get by zooming into the image. The tiling algorithm will make sure that only the \"good\" part of a tile gets transferred into the final image, i.e. the center part without the border area defined by the overlap parameter - of course with the exception of those parts that are anyhow borders to the original image.. > However, the tiling mechanism of darktable and the hazeremoval module do not play nicely together. \nOK, I see. In that case one could leave tiling disabled and try to reduce memory footprint in the module. As a minimum you should catch OOM situations in the module gracefully and emit some error message to the console. Additionally you might consider to make the module behave as a noop in the error case.\n\nAt the moment I think the only possible solution to reduce the memory footprint is to implement a tiling algorithm within the process function.\n\nYou may do so by defining your own process_tiling() within the module which would take precedence over the globally defined one.. > Some time ago i played with the idea of adding a sample() callback, which would be run before the process(), and with the full input buffer. As long as the sampling itself is not too memory-hungry, that would be the solution. I never finished that code though.\nAnother option could be an \"auxiliary\" pixelpipe that supports an export pixelpipe in a way as the preview does for the full one. That auxiliary pixelpipe would be called prior to the real export pixelpipe and could be initiated on request of a module that needs it.. > The sample() callback approach would not need any of that. \nThat would be the optimal solution. . I'll have a deeper look the next days. It already compiles for me nicely :). A bit of feedback after some tests on my system.\nGenerally the module works great in fixing hazy images. I'm not sure how specific the results are, e.g. compared to combination of tone curve and some black point correction. But overall it works nicely.\nWhat I do see is that the default settings are way too strong. Even with a reduced strength value of 0.45 (which I would take as the maximum tolerable) I am already getting some \"postcard style\" output. In darktable we generally prefer that the default settings of a module either lead to no effect or that the effect is reduced to some noticable but subtle change. We should leave extreme settings to the user.\nTo me the threshold value remains somewhat of a mystery. Not so much in its meaning but in its effect. I can change the value all the way from low to high with only marginal effects. Only if I go to the extreme right (above 0.8) it makes a noticeable difference. You should consider to change the scaling of that parameter so that the change of effects is a bit more evenly distributed over the data range.. Looks much more controlled now! On activation of the module one sees how it improves the image but the effects are tuned-down enough to stay serious.\nI have a few further considerations which I will describe in individual comments so it's easier to follow up.. I suggest to move the descriptive part of the module code higher up in hazeremoval.c. This mostly affects lines 700 to 745 which I would recommend to put directly after all #includes and #defines. Reason is that other developers might need to have a quick glance at the params/flags/group etc. without them wanting to scroll 700 lines down.. process_tiling(): not sure why this function is there in the first place. As far as I understand you anyhow apply a tiling mechanism in process() to reduce memory overhead. Therefore process_tiling() is not needed and should be removed.\nConcerning tiling_callback(): you set tiling->maxbuf = 2.f. That parameter describes the largest single buffer that the module needs to allocate (in units of the input/output base buffer). This is needed for OpenCL which has a device dependent upper size limit for allocations. For CPU processing like in hazeremoval the parameter is not utilized but should be set to 1.0f despite that fact.. About pixelpipe synchronization. We already talked about that. Meanwhile a working principle has been implemented and haze removal should apply the same mechanism. Take the code in global tonemap as a reference.. Great! I'll have a deeper look later this week.. I checked and have found no issues. Looks good to me. . From my side OK to merge. I only suggest that you once apply clang-format beforehand so that code is formatted according to darktable standards.. Great. Then I think we are ready to merge. If there are no objections I'll merge tomorrow.. > leave a comment summoning me once you are done making changes :)\nJust a few days to go :). > Can we avoid that and just trigger the display when keying shift or control?\nAny suggestion would be appreciated. I have not found a way to do so. AFAIK in gtk shift and control are only modifier keys. They don't trigger an event when pressed. So this only works in combination with some other event. I tried with motions-notify-event but that would effectively prevent the sliders to work in the first place.. @LebedevRI: looks like we need to leave the activation part as it is. Anyhow we can change the key codes at any time later. Would be great if you could have a look at the PR, especially the parts behind the curtain.. > I was thinking that we could just use some standard keys \nSure I got that point. My issue is not to imagine how it could look but the fact that I have not found a way to implement. A draft implementation would be highly appreciated.. A few things to add. I think there are two issues which prevent the functionality as suggested by @TurboGit: press a key to activate channel/maks display and release the key to return to normal.\nFirst, I think that in gradientslider.c the handling of key-press-event is not correct. AFAIK an event handler needs to return TRUE if it has handled the event and the event handling chain should stop here and it should return FALSE otherwise. Now in gradientslider the event handler just does the opposite. Therefore a new event handler will not see key press events other than the ones handled in _gradient_slider_key_press_event(). Maybe someone with more knowledge on gtk can verify.\nSecond, I think we do not get any key-release-events. In fact that event is only handled in one central location in gtk.c and none of our widgets makes use of it. Are key-release-events blocked somewhere in the chain?. Fair enough. Let's go ahead and check alternative gui options in parallel.\n@LebedevRI: could you please have a look and review? Unrelated to this maybe you could also have a look at the key-press-event handler in gradientslider.c (see my comment above).. So that's it right now.. > But the discoverability of that feature it even lower than usual for dt features :)\nCertainly deserves some mentioning in the manual :) Drop me a note when you are done with review and I'll merge in the next days.. > I am proposing that timeouts are plain wrong in the first place, we need to make sure to dispatch everything in the right order ..\nThat's not how it works. The full pipe and the preview file are not coupled and get triggered independently. Sometimes only the full pixelpipe needs to be reprocessed. Sometimes one of the pixelpipes is processing but gets interrupted because parameters have changed etc. Always forcing a reprocessing of both pixelpipes in order just for the few modules that might require synchronization would be wasteful.\nThe feature of this PR is meant for very fast GPUs (like NVIDIA 1060 or the like). Try setting pixelpipe synch to zero in this case which means: better quickly reprocess everything on the fast GPU rather than waiting for things to get in sync.\n. > Fonts are rendered slightly differently\nMost screenshots in the manual come from my system and I'm using font: DejaVu Sans Regular 8; in darktable.css. I can take care that the screenshot fits to the others after merging.\nA suggestion: although the module does a great job (I used it on several images recently with nice results) users should be warned that taking out all atmospheric perspective from an image might render their images flat.. Cool.\n\nOptimal values are typically slightly below unity \n\nSo my mileage varies here :) Don't know if this depends on the camera or my overall history stack but on my images (mostly Fuji, some Canon) I typically stay with strength values about 0.3 and distance about 0.04. In my eyes higher values lead to an unnatural look.. Checked with Bayer and X-Trans images and the fix clearly improves identity between cpu and OpenCL codepath. So I'll merge.. Thanks!. There seems to be an issue in overview.xml. There you wrote a structure like C<filename> which should probably read <quote>filename</quote>.. Wait, that's not a good idea. Blending requires the image buffer to carry an alpha channel. The hotpixels acts on raw images which are stored as float[1]. That's the reason why modules acting on raw data don't allow blending, else you would get a crash.. OK, I see. We can of course have uniform blending (as of the above commit) and drawn masks but without mask display. Good to go.. I'm seeing some quite heavy alias-like artifacts in structures with fine detail like foliage. See for example the leaves in this image: https://www.dropbox.com/s/as0iozppfjalb4e/IMG_2517.CR2?dl=0, especially if fully zoomed in.\nI see the artifacts with processing on CPU and GPU the like. In addition on the GPU I have intermittent \"gaps\" in the image when panning the view.. >  it seems more complicated than that. I have to understand fully the opencl code to try to find the issue.\nPlease read the publication that is quoted in the header of denoiseprofile.cl. The OpenCL algorithm collects data in a different way than the sliding window CPU algorithm. Accumulating rounding errors play a role here and I would not expect bitwise identical results. However, the border issue looks strange indeed.\nConcerning the loop: going from -K to 0 takes advantage of the symmetry and is key for GPU performance.. I like the options for mask refinement a lot. However, I am a bit afraid of the large number of controls that are visible all the time. Looks a bit like an airplane cockpit now. Wouldn't it be better to only activate all these controls on request? Maybe a combobox \"mask refinement\" with yes/no could help to improve clarity.. Another important remark: looks like the recent commits have broken legacy presets. I have my own defined presets with parametric masks defined in several modules. When I activate the preset now I only get the module with blending switched off :(. > @upegelow : I have fixed the blending legacy support, a cut&paste issue!\nHmm, not sure that this has worked out. I still cannot see the parametric masks. Legacy parametric masks seem to be gone also when importing legacy history stacks. I don't want to test it too much with my work as I fear to lose all edits.. Blending options for presets are stored in data.db. Looks like darktable automatically tries to update all of them to the latest version. If an error occurs here the blending part of a preset is lost. I have just restored my data.db from a recent backup, and now with current master presets are back to normal. Once again the blendop version of all presets gets automatically updates on first invocation of darktable - this time with correct results. Bad news for those who don't have a backup of data.db.. I assume that there is a problem with blendop version 8. Whatever happened: all settings which have been converted recently to this version are screwed. This seems to affect all entries in presets as version updates happens for all presets each time darktable is started. But this is also true for all image edits which have been touched recently. For touching it seems to be sufficient to open an image in darkroom or export an image. All blending is set to off in this case and the module takes effect on the full image. As I use a lot of parametric masks I have lost quite some edits. Not good.\nAll images that have not been touched and still contain blendop version 7 or earlier seem to be OK if opened with current master.. > That's sad, but always possible for us working on master :( As dev we really need to have a backup, you had one and I had one too.\nTrue, but I think we should take this as a reminder not to be too permissive when breaking legacy history stacks in central parts of the program. The parametric mask is a feature that is used very intensively by many users and developers. It would have been better in this case to not overwrite the blendop version 8 with a newer one but generate a new one. Even if the algorithm has changed and not all of the version 8 features can be fully converted it would have been the better choice.\nI am more relaxed when it comes to the development of a completely new iop, like retouch or filmic. If I use it I know that incompatible changes can happen.\nFor me it means that I have now a lot of edits where blendop parameters have been converted into the dead-end version 8. Any idea how I could restore them? Maybe a tool to convert back to version 7?\n. Presets are restored, but I have lost like 70 edits.. > @rabauke : the documentation has always been handled by @upegelow.\nIt would be great if someone else could take the lead on the manual this time. I am fully drowned in a new job.. > Nice going! Let's see if @upegelow can get back the 70 edits...\nI will give it a try tomorrow evening. Right now I have been able to find a backup of my XMPs originating from the day just before the problematic commit. From there I can reconstruct the changes I made in between.\n. I am clearly in favor of Pascal's suggestion. The section labels are already an improvement but I still see the risk of overwhelming novice users. While they will understand what \"blur\" means the complete set of options is so much that many will not even dare to test. The most clean place for the toggle is of course in the blendop parameters (migrating to version 9). Take one of the reserved fields to not let the params block grow bigger.. > It's the metaphor of the aircraft cockpit\u2026 Yes, you have a lot of knobs but they are immediately accessible. It took me less time to set up an autopilot in an A-340 than what it takes me to set up a consumer GPS.\n\nIt all ends up to the question if our target group resembles more a trained airplane pilot or the buyer of a piece of consumer electronics. There are probably good reasons for the way how cockpits are designed and how consumer GPS devices are designed.\nReminds me of a discussion we had several years ago: should we offer a general selection between an \"novice view\" and an \"expert view\"?. @rawfiner: thanks for spotting and fixing the bug.. Cool. Very well written!. Thanks for the explanations. Very much appreciated! See comments on some of the paragraphs.. Looks like I forgot to press \"submit\".. Perfect. Thanks!. I get a lot of compile errors. Any special curl version requirements?\n/home/pegelow/darktable/src/imageio/storage/piwigo.c: In Funktion \u00bb_piwigo_api_post_internal\u00ab:\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:272:3: Fehler: Unbekannter Typname \u00bbcurl_mime\u00ab; meinten Sie \u00bbcurliocmd\u00ab?\n   curl_mime form = NULL;\n   ^~~~~~~~~\n   curliocmd\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:309:5: Fehler: Unbekannter Typname \u00bbcurl_mimepart\u00ab; meinten Sie \u00bbcurl_TimeCond\u00ab?\n     curl_mimepart field = NULL;\n     ^~~~~~~~~~~~~\n     curl_TimeCond\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:311:12: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_init\u00ab; meinten Sie \u00bbcurl_multi_init\u00ab? [-Werror=implicit-function-declaration]\n     form = curl_mime_init(ctx->curl_ctx);\n            ^~~~~~~~~~~~~~\n            curl_multi_init\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:311:10: Fehler: Zuweisung an \u00bbint \u00ab von \u00bbint\u00ab wandelt eine Zahl in einen Zeiger um, ohne explizite Typkonvertierung [-Werror=int-conversion]\n     form = curl_mime_init(ctx->curl_ctx);\n          ^\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:318:15: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_addpart\u00ab; meinten Sie \u00bbcurl_write_data_cb\u00ab? [-Werror=implicit-function-declaration]\n       field = curl_mime_addpart(form);\n               ^~~~~~~~~~~~~~~~~\n               curl_write_data_cb\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:318:13: Fehler: Zuweisung an \u00bbint \u00ab von \u00bbint\u00ab wandelt eine Zahl in einen Zeiger um, ohne explizite Typkonvertierung [-Werror=int-conversion]\n       field = curl_mime_addpart(form);\n             ^\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:319:7: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_name\u00ab; meinten Sie \u00bbcurl_getdate\u00ab? [-Werror=implicit-function-declaration]\n       curl_mime_name(field, ca->name);\n       ^~~~~~~~~~~~~~\n       curl_getdate\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:320:7: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_data\u00ab; meinten Sie \u00bbcurl_getdate\u00ab? [-Werror=implicit-function-declaration]\n       curl_mime_data(field, ca->value, CURL_ZERO_TERMINATED);\n       ^~~~~~~~~~~~~~\n       curl_getdate\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:320:40: Fehler: \u00bbCURL_ZERO_TERMINATED\u00ab nicht deklariert (erstmalige Verwendung in dieser Funktion); meinten Sie \u00bbCURLINFO_PRIVATE\u00ab?\n       curl_mime_data(field, ca->value, CURL_ZERO_TERMINATED);\n                                        ^~~~~~~~~~~~~~~~~~~~\n                                        CURLINFO_PRIVATE\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:320:40: Anmerkung: jeder nicht deklarierte Bezeichner wird nur einmal f\u00fcr jede Funktion, in der er vorkommt, gemeldet\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:324:11: Fehler: Zuweisung an \u00bbint *\u00ab von \u00bbint\u00ab wandelt eine Zahl in einen Zeiger um, ohne explizite Typkonvertierung [-Werror=int-conversion]\n     field = curl_mime_addpart(form);\n           ^\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:326:5: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_filedata\u00ab; meinten Sie \u00bb_curl_is_cb_data\u00ab? [-Werror=implicit-function-declaration]\n     curl_mime_filedata(field, filename);\n     ^~~~~~~~~~~~~~~~~~\n     _curl_is_cb_data\nIn file included from /usr/include/curl/curl.h:2305,\n                 from /home/pegelow/darktable/src/imageio/storage/piwigo.c:33:\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:328:37: Fehler: \u00bbCURLOPT_MIMEPOST\u00ab nicht deklariert (erstmalige Verwendung in dieser Funktion); meinten Sie \u00bbCURLOPT_TIMEOUT\u00ab?\n     curl_easy_setopt(ctx->curl_ctx, CURLOPT_MIMEPOST, form);\n                                     ^~~~~~~~~~~~~~~~\n/home/pegelow/darktable/src/imageio/storage/piwigo.c:357:16: Fehler: Implizite Deklaration der Funktion \u00bbcurl_mime_free\u00ab; meinten Sie \u00bbcurl_free\u00ab? [-Werror=implicit-function-declaration]\n   if(filename) curl_mime_free(form);\n                ^~~~~~~~~~~~~~\n                curl_free\ncc1: Alle Warnungen werden als Fehler behandelt\nsrc/imageio/storage/CMakeFiles/piwigo.dir/build.make:62: recipe for target 'src/imageio/storage/CMakeFiles/piwigo.dir/piwigo.c.o' failed\n. Here on my system:\n\nrpm -q libcurl4\nlibcurl4-7.37.0-42.1.x86_64\nrpm -q libcurl-devel\nlibcurl-devel-7.37.0-42.1.x86_64\n\n. There doesn't seem to be any other version of libcurl around here. The problem seems to be linked to curl_mime related features. Could it be that this is an optional part of the curl library and some implementations leave it out?. > I have libcurl4 7.62 on my machine. So maybe a more recent version is needed.\nThat might be an issue on some systems, mine included. If there is no workaround for older versions of that library you may need to make piwigo support optional at compile time.. It does the job!. From a logical point of view: shouldn't the retouch tools come below the wavelet decompose? In the normal way of working you first consider how to separate an image and then you start to work with tools on specific scales. This also would bring the shape modifiers closer to the shape producers.. @edgardoh should give his POV on this.. To me adding nodes to the display goes into the wrong direction. This will increase mismatch between user expectation and function. To me the graph is a pure assist function to visualize the settings of the sliders in a supplementary way (you know my opinion). With nodes this generates even more of an expectation that the graph is meant for direct manipulation. Users will try, they will fail and they will get frustrated.. Thanks, I think it's well explained. Some proof reading to be done later.. > Also, @upegelow, what is the XML syntax for external links ?\nPlease use ulink like in <ulink url=\"http://www.inkscape.org\"><emphasis>Inkscape</emphasis></ulink>\n. Please drop me a note when you think the documentation is ready. You don't need to pay attention to typos and minor language issues, that's something I will fix when proofreading. Just make sure the content is well understandable.. Thanks for the work. I think it's ready to be merged. Please note that the English version of the manual still lacks documentation on filmic and on the recent changes of unbreak input profile. The 2.6 manual will be released after these pending parts have been added and the translators will need to follow accordingly.. Yepp, works well.. > A complete rewriting seems to me the most efficient way to kiss compatibility good-bye.\nThen better start with a new project.\nFrom time to time we see revolutionary ideas how things could have been done in a much better way. However, the darktable project is dead in the moment when we tell people that they can forget there legacy history stacks because we some great idea of the day that is now so  much better. \nI have always been strongly advocating for consistency and keeping all history stacks valid even from day one. If we give up that part I am out.. I understand the reason behind. However, shouldn't it be better controlled by a preset where it can be made dependent on camera model? That would better especially for users with different camera models.. I mean regardless of the question if the module is on or off by default users should be able to define presets that can activate the module dependent on camera model. Let's take my situation as an example. I shoot with Canon and Fuji. The my Canon the current sharpen default is normally a good starting point. For my Fuji with xtrans sensor that level of sharpening is way too much. However, I still want apply a low level of sharpen, so I defined a preset in the sharpen module which gets automatically applied for Fuji raws.. OK, understood. So in the end this PR offers just another way to switch off sharpen by default. Maybe that's a bit more easy for novice users than defining a suitable preset.. I am fine with warning the user in the tooltip to be cautious, but I am against the name change. \"Unclip negative values\" while maybe technically correct is obscure from a user perspective.. > Could \"black/noise level\" be an option ?\nI don't like this. It follows the same idea of obfuscating the parameter. Even worse, some users might think that this is a denoise feature. As said I am fine to change the tooltip.. Fine for me as well.. Looks like a tiling problem. Do you run with OpenCL? If yes, what \nhappens if you disable it?\nUlrich\nAm 07.01.19 um 19:15 schrieb pierre-guillot:\n\nHello guys.\nI updated darktable to 2.6 on my Archlinux (directly from official repo) \nand now I have a problem with the equalizer module.\nI usualy apply the style \"EQ+Denoise+HotP - Matt Eastwood\" (you can \nfound it on https://dtstyle.net/) on my high ISO picture to denoise it \nbut since the last version, some \"black square\" are presents on the \npicture when I use this style : \nhttps://framapic.org/7x6tOxMTPuEV/MhcL4XAH5zY1.png\nIf I export this picture, the problem is still present.\nUsed camera : DMC G7 and RAW file. Tested with a RAW downloaded here and \nsame result : http://www.mamiyaleaf.com/samples_credo_80.html\n. I would be interested to see the output when exporting with opencl \nenabled and with command line parameters '-d opencl'.\n. Please open a terminal session. Find out the full path of the darktable \nbinary (there are different ways; try e.g. 'which darktable' or 'locate \ndarktable').\n\nThen start darktable the following way:\n/FULLPATH/darktable -d opencl -d nan > /tmp/darktable.out\n(Where FULLPATH is the path of the darktable binary.) Within darktable \nyou now export an image which you know will produce black rectangles. \nThen you close darktable and you post the contents of /tmp/darktable.out \nhere.\nUlrich\nAm 18.01.19 um 08:32 schrieb pierre-guillot:\n\nsorry for the late response, Can you explain to me exactly what I need \nto do? Lunch darktable with command line with the \"-d opencl\" parameter \nand copy/past the output?\n. Looks good. I found only one minor typo.. > Shouldn't it be kept in LAB and just set LAB colorspace in colorin iop? Is conversion LAB->sRGB->LAB lossless?\n\nThere are a lot of modules before colorin that implicitely assume RGB input. One of it is retouch and the wish to use this module for certain scanner images has been the starting point for the PR.. > Sounds good! Do you think this can/should go in 2.6.1?\nLet's wait a bit. I am interested to see if this really works well. Also the decision to convert to sRGB might be debatable with e.g. AdobeRGB being an alternative.. > Ulrich, so what about 2.6?\nIt's fine to cherry-pick into 2.6 (see discussion in darktable-users).. See comments in PR1999. Is it visible now?. Yep, I also experienced this problem. Should be fixed now in master.\nUlrich\nAm 16.02.19 um 16:13 schrieb Christian Kanzian:\n\nDescribe the bug\ndarktable version: 2.7.0+493~ged0ced2e0\nOpenCl starts to fail on export as soon as you use blending with this \nerror message:\n[opencl_blendop] couldn't enqueue kernel! -38\n[opencl_pixelpipe] could not run module 'exposure' on gpu. falling back \nto cpu path\nTo Reproduce\n\nOpen an image in darkroom\nActivate a module and turn on a blend mode - no matter which one\nExport the image\nSee error [opencl_blendop] couldn't enqueue kernel! -38 of the\n    module with active blending\n\n. > Can give a slight performance boost. All hardware since 2012 should be supported now.\n\nAny proof for that? I am interested to see. If not this is just a deliberate reduction of interoperability.\n. Am 21.02.19 um 20:45 schrieb Aur\u00e9lien PIERRE:\n\n    Can give a slight performance boost. All hardware since 2012\n    should be supported now.\n\nAny proof for that? I am interested to see. If not this is just a\ndeliberate reduction of interoperability.\n\nI have just benchmarked it on my system with a development history using \nintensive GPU IOPs (denoise profile, retouch, wavelets, local \nlaplacian). OpenCL 2.0 is the slowest, OpenCL 1.1 is average, OpenCL 1.2 \nis the best, and OpenCL 2.2 is not compatible since it relies on C++.\nAny numbers?\n. I clearly prefer demosaic_other.cl.\n. mat3mul() etc. should go static and print_roi() should finally go away when development is finished.\n. OTOH it's more simple now to reset to default by just dt_bauhaus_slider_set_callback(widget, NULL).\n. Anybody working to bring the demosaic changes to the OpenCL codepath? If not, I could do it.\n. maybe \"target\" is a suitable name to not get into too much logical conflict with the kernel's name (\"slice_to_output\").\n. Yepp, absolutely. It's crucial that _all work items reach the barrier call. Else barrier will wait for them .... forever.\n. There is no direct correlation between (x, y) and the coordinate that the individual work item does sample (see the for loop). Additionally, sampling out of the width/height constraints is of no concern. That's one of the main advantages of image objects compared to float buffers. The sampler defines how coordinates out of the image are handled. Later we make sure that a) no pixels are written outside of width/height (the main reason for x >= width || y >= height), and b) we handle borders separately.\n. I'd probably phrase it a little bit more politely not really knowing what the developers of beignet and pocl claim or not.\n\nLike: not all opencl implementations are fully-functional, there are at least two, which are not production-quality yet: pocl and beignet; therefore at this point in time, it is better to explicitly blacklist them by default. .... I'll have a look at that.. Main problem with MIN()/MAX() is that they are not NAN safe in the way they are typically implemented as macros. I.e.:\nMIN(x, NAN) != MIN(NAN, x) -> either x or NAN\nReason is that any comparison with a NAN always  returns FALSE. \nWhereas\nfminf(x, NAN) -> x\nAnd we know that the lensfun code tends to produce NANs occasionally. BTW I have not noticed any problems with the reduction.\nIn terms of speed: the original code would iterate over like 1.000.000 coordinates while the new one only visits like 4.000, so using fminf()/fmaxf() should not play a role.. The nice thing about MIN and MAX macros is their simplicity which allows them to work with any numerical input, regardless of type. In order to catch NANs we would need to give up type independence. . > #pragma omp barrier is not needed here?\nprobably yes. Won't work. We write to buf.. show me. Agreed.. Good point.. No issue. Neither with NVIDIA nor AMD. In fact size does not seem to be a determining factor when it comes to OpenCL compiler bugs. I have seen the biggest problems with kernels of just a few lines.. Well, we would need several no-op inlines for different color spaces RGB/Lab vs. RAW and for clamping and non-clamping blend modes. A multitude of inlines wouldn't improve things IMHO.. No sure if I got the point. Can you elaborate?. Oops. That should have read GDK_CONTROL_MASK | GDK_SHIFT_MASK. Let's see: we make it very simple as anyhow these code parts should never be called unless we get a garbled history stack.. If it were only process() and process_sse2() I'd agree to put this into a central place. However, we also have process_cl(). If we would want a central dt_iop_alpha_copy_cl() this function would require one temporary buffer in addition to input and output (copy output to tmp, then copy xyz from tmp and w from input to output). This would put an additional requirement on tiling (memory is short on the GPU): not very good.\nIdeally (and that is how things are handled in all OpenCL modules) each module takes care by itself to transfer the alpha channel with the buffers that it anyhow has reserved. This is the most efficient way in OpenCL.\nNow this would also be the ideal case in process() and process_sse2(). But this tends to be forgotten by the module authors sometimes. Then typically we need to fix it (e.g. see ticket #11601) and I normally don't want to interfere too much with the original code. That's the reason why dt_iop_alpha_copy() has been added.. > so it seems to be always done in the kernel\nYes\n\nBut dt_iop_alpha_copy() is pretty much always the case for cpu codepath...\n\nThis should ideally be handled without the need of dt_iop_alpha_copy() just by the processing code like in the OpenCL kernels. But several modules don't do it like that. They need dt_iop_alpha_copy(). That's not a big deal. Let's leave it at that, especially to keep some identity to what a process_cl() does versus process()/process_sse2().. What's the rationale for this change?. I suggest to use M_PI_F as a floating point constant at these places.. I suggest to replace the initialization value of lmin to float (here and in the subsequent code parts).. This looks a bit strange to me. Can you please elaborate on the logic?. I tested it and it works fine for me.. s/smooths/smoothens/. Relating to \"The feathering ...\": I would express this limitation in a positive way: \"The feathering is sensitive to this choice especially if ...\". That's very difficult to understand. I would consider to look at this parameter from a user perspective. What does it mean if the user increases or decreases the value.. Readers will have forgotten what opacity means when they reach this part. Better to explain that this effects the strength of the module's effect.. Playing a bit around with this feature it looks to me that you can only change custom order if the lighttable view is in file manager mode. When in zoomable lighttable mode you only pan the whole set of images.. Out of curiosity: in a typical Linux environment where is the web browser defined? In my case for some strange reason this features opens up the eric6 Python IDE :). > Try putting in your ~/.bashrc something like export BROWSER=firefox\nDid not help. In the end I needed to edit ~/.local/share/applications/mimeapps.list to get it working with firefox.. Only a side question: any plans to have temporary view also when zoomed into the image?. Please use  itemizedlist and listitem.. Oops, xmllint still complaining. The content of each listitem needs to be enclosed in <para></para>.. Out of own experience I'd be very cautious with any changes to that module shortly before a release. IMHO it's better to allow for intensive testing in the development branch.. For consistency with the rest of the manual please replace starting/leading double quotes with <quote></quote>.. s/allow/allows/. OpenCL machines are heavily affected by branch divergence. For that reason - and to not hide this fact in the code - I would prefer to have the (slow) read_imagef() functions be executed unconditionally and make only the calculation of dist conditional. . suggestion:\nfloat4 u1_pq = wpq ? read_imagef(in, sampleri, (int2)(x, y) + q) : (float4)0.0f;. Out of bounds access is another issue of OpenCL.\nThe problem with branch divergence is a bit different. All work group items need to process all branches. So in an if() statement the TRUE branch gets calculated as well as the FALSE branch in all work group items. . Oops, pay attention: in OpenCL the logical TRUE value is -1, not +1 as expected from C programmers.\nYou will need to do something like:\ndist *= (logical term) ? 1.0f : 0.0f;. see above. I suggest to use int constants here.. ",
    "sk1p": "I don't see any way to distinguish a zero-rating from no-rating. The tag is present and '0' in both cases... \n. I updated the patch to map both 0 and 1 to a one-star rating as per @parafin's remark\n. oh, right :)\n. ",
    "parafin": "I can confirm that there's no distinction between not touching the rating and setting it to zero. I suggest that zero rating should be treated as no rating and so default rating setting in DT should be applied to imported photo. First of all when rating is set to zero in camera, no icon is displayed in playback mode, so IMHO it's intended meaning is undefined rating, not zero-rating. Secondly that way there would be no change of DT's behaviour for users who don't use ratings in camera, and users who want ratings preserved can always change \"initial import rating\" setting to zero. I personally probably won't use in-camera ratings and I want my photos to have 1-star initial rating, but this patch as it is will make it impossible\n. darktable.gtkrc is definitely found, I made sure. This is most likely GTK-Quartz bug, I'll try to find and contact its developer for comments. \n. \"unrejected\" sounds to me like \"something that was rejected and then it was accepted again\", I would suggest \"all but rejected\" phrasing.\nAlso this whole star filtering system seems confusing to me, I propose to make it more flexible and just allow user to choose lowest and highest rating for the filter (rejected being the lowest possible obviously). Though this will require more work, for the time being this patch probably should be accepted.\n. path length should be fixed in my recent commit too then: https://github.com/darktable-org/darktable/commit/dd4ec899762fa9c2f0b2ff2ab1011417d8454c16\n. .DS_Store directory stores folder settings in OS X, it must go for sure. I was going to add it to .gitignore myself.\n. All such queries should be rewritten, not just this one (though I'm not sure how many are there), see http://darktable.org/redmine/issues/9140\n. That's not exactly a bug, upstream considers it just as change of undocumented behaviour which won't be reverted. So we must fix this. Basicly I agree that using rowid at all (even in simple queries) wasn't a very bright idea.\n. Last time this change was proposed (by me), consensus was that it's the wrong thing to do. Just adding -Wno-unused-local-typedefs might get a little more support.\n. of course, why wouldn't it be\n. There are more issues with this code, see http://darktable.org/redmine/issues/9550\nSo IMHO this code should be rewritten\n. well, it was tested on stable branch, not master, and it was some time ago. My point about 32 vs 64 bit is that it makes no sense to switch one part of the code to 64 bit integer while limit it to 32 bits in another.\n. Package maintainers (at least in case of Gentoo) require the way to forcibly disable optional dependencies even if they are present in the system, so please add an option for webp\n. it's a not so big change to cmake files, not changes to actual code (which i think in this case you yourself did) and cmake option is there for every other optional dependency, so why webp is different? Anyway it only means that webp will have to be non-optional for Gentoo, so no bigigie really, just strange.\nWhat to make optional and what not is another discussion and I have no strong opinions on that subject.\n. Another option is to include ciso646 (maybe not needed) and check for defined(__LIBCPP_VERSION) to detect libc++. The question remains how this will work with other compilers/C++ runtime libraries.\n. went with LIBCPP_VERSION solution\n. If you're building a package you can't use -march=native. Adding it everywhere will break my current OS X workflow for example, I will have to use CUSTOM_CFLAGS and some other magic.\n. You're probably right about BINARY_PACKAGE_BUILD, I just mean that your change isn't quite innocent, it may require some changes.\nAbout OSX: I didn't mean OS X doesn't support -march, I meant I'm the one building OS X package. So do not add that check.\n. How about adding explicit #include <cmath> to exif.cc and using std::isnan; directive right after that? Should work on both systems..\n. works for me on OS X and Linux.\n. Or move all #include'd files into separate dir and take their checksum or mtime into consideration when deciding to recompile (src/common/opencl.c around line 899). Since existence of common.h and colorspaces.cl already broke the logic under opencl caching, this PR itself isn't a problem IMHO.\n. MI introduced ambiguity about pasting some module to an image which has this module already enabled. Before MI it could only mean \"overwrite the settings of module\". Now there are several possibilities, but I would propose to leave the convention as it were before (granted, it will somewhat limit usefulness of MI) - if user pastes (applies a style) with any number of instances of some module DT should replace current settings while adding needed instances and disabling extra ones when number of existing and number of pasted instances don't match. This solution at least avoids the question where to put new instances - before or after existing ones, and I'm sure there could be usecases for both, especially if one considers how blendif comes into this picture;) Ideally of course there should be a separate switch of how to handle this - replace, add after, add before.\n. I don't know how MI names are handled exactly, the best is probably to leave the names as they are, but that will only work if there is no limitation on whether the instance with empty MI name must exist. Instance numbers (if they start with some fixed number - 1 or 0) of course have to be recalculated with order saved.\n. yes, that's what I meant.\nI didn't look at the code or tested it though yet.\n. Hmm... I see one problem with instance names:\nFor example we have an image with 2 instances - \"module \" and \"module 1\", in that order in both history and pipe. Then we paste let's say 1 instance with name \"module 2\". What would be the resulting names of instances and which one will be enabled and which one is off? If we change the name of one existing module, then it will have to be changed in history stack too, which sounds very messy to me... I suggest then to just forget about the name of pasted module and use whatever is there in the pipe already (or generate a new one when we run out of already created instances). Since names aren't editable ATM, they IMHO don't contain much value anyway.\n. Currently this PR doesn't do exactly what I suggested. Specifically if you copy 2 instances onto an image with 3 instances enabled the result will have 3 instances enabled, not 2 as it should. Also the name problem does exist, you can end up with 2 instances having the same name with no possibility to distinguish between them in history stack.\n. Yes, I suggest to disable them in a new history item.\nName problem is indeed may be considered a separate bug, I just noted it for your information.\n. If we are talking about OS X, then these changes won't work and will actually break compilation (linking to be more precise) when these dependencies get found. See commit f8e89dcd5fd2a1d7247b004b37dfec58a84e8d09 to how to correctly fix this.\n. I don't know the reason they exist. If we're gonna change them, we should make them support OS X, not just exclude it from supported platforms.\n. i've already done that in commit 96fb29e, though I didn't convert pkg_check_modules to libfind_pkg_check_modules. Is there any difference between them?\n. Which strings there are translated? I thought that none of those will get to .po files...\n. It is not exposed in GUI\n. probably related to discussion in PR #732\n. Seriously? DT will link against full-blown browser engine?\n. If this PR is the only solution, then +1 from me.\n. The error message you posted and your explanation for it don't match. ld definitely doesn't require to list indirect dependencies (unless it's a static lib of course).\n. IMHO, the actual problem is that we do actually directly use libintl (e.g. bindtextdomain function), so removing gettext detection was just plain wrong.\n. https://developer.gnome.org/glib/stable/glib-I18N.html doesn't include bindtextdomain as provided function, so we are using gettext directly even if we also use some glib wrappers around it. It just happens that on Linux gettext seems to be included into libc, so linking doesn't fail.\n. I would vote for using normal and not combined characters, don't see why any text editor would prefer the latter, it doesn't make any sense. While incorrect rendering of combined characters is definitely a bug in font engine, its existence is an argument for normal characters;)\n. What about clang from Xcode? Does it support __builtin_cpu_supports or __has_builtin(__builtin_cpu_supports) is false there?\nWouldn't it make more sense to guard against compiler version and not platform? To me current PR looks a little bit too generic (same with FreeBSD probably). On the other hand this check is probably pointless on OS X, since I guess all Apple hardware supports SSE3.\nP.S.\nModifications in macports.conf are needed for backwards compatibility with older OS X versions and has little to do with used compiler (though it's impossible to use Xcode clang for deployment target 10.6, only 10.7 is possible for DT in that case).\n. I like compiler check better because it's more to the point - #ifdef is needed because of compiler bug, not because we just decided to skip the check on OS X. Also let's not forget about Hackintoshes - there are people running OS X on non-standard hardware even with CPUs that don't support all the necessary features.\n. By compiler version I didn't necessary mean specific clang version, it may as well be as simple as gcc vs clang. If latest clang is 3.8 and it still doesn't support this feature, then maybe just check for clang with no specific version.\n. Is it specific to FreeBSD and OS X? Did someone test clang-3.[78] on Linux for this bug? I think someone (@LebedevRI ?) do test clang builds on Linux, but I want to confirm, after all it's only the latest versions which have this quirk.\n. OK, so if no one has a problem with current version, I'm for merging it.\n. They mentioned libgcc, I think, because GCC implemented it, I don't think they meant clang would/should use it. So what's your point?\n. Ah, OK, didn't know that clang can use libgcc in some configurations. So do we do here then? It's probably impossible to tell if libgcc is used using just macros.\n. Works fine on OS X except one line in packaging/macosx/make-app-bundle script needs to be changed:\non line 9 change @loader_path/../lib/darktable to /usr/local/lib/darktable.\nAlso when changing Gentoo ebuild you must re-create the manifest, but I will need to update that stuff anyway, it's not up to date.\n. Your changes introduce absolute paths in rpath, but that script depends on particular setup anyway. I'm just telling you what needs to be changed so that nothing breaks when this PR gets merged.\nAs for Gentoo - radhermit and me communicate when needed, there is no problem here. Some time before I created this ebuild to track git master (there was no -9999 and obviously time lag exists between updates of code and ebuild in portage tree), but due to absence of time on my part it's out-of-date now and in-tree version is better.\n. $ORIGIN in rpath on OSX doesn't have a special meaning, it needs to be replaced with @loader_path like it was before.\nSo NACK in current form.\n. That's correct, yes.\n. 1). OS X does not define __GLIBC__, some other systems probably either, so I suggest to just remove ifdef in pthread part (I assume it won't hurt), not sure what to do with openmp though, why it doesn't work with musl?\n2). in src/common/camera_control.c I guess you should remove lines 29-31\n3). I agree with dt_pthread_create idea\n. Not sure if testing for specific number is robust enough solution - who's to say musl won't change it in future releases or maybe there's another libc that has small default stack size too, but a different one? I would just check that it's less than SAFESTACKSIZE, not equal to MUSLSTACKSIZE.\nAnd the question about openmp still remains - I don't think we can accept current solution (check for GLIBC).\n. macosx_version seems to be used only in _aligned_malloc where it is checked whether it's at least 10.6. Since darktable never supported OSX versions < 10.6 (and now supports only 10.7+) I'm not sure if this code should be there at all. On the other hand rawspeed is an external library (but still the PR is for darktable repo)...\n. These libraries you mention are not plugins, and therefore aren't needed in the package. You can take a look at https://github.com/darktable-org/darktable/blob/master/packaging/macosx/make-app-bundle and https://github.com/darktable-org/darktable/blob/master/packaging/macosx/darktable.bundle as the reference - gtk-mac-bundler does something very similar to BundleUtilities and you can see which extra files I have to add to Mac bundle.. Hmm, and what doesn't work without these files? Because I might have to adjust Mac packaging too then.. By plugins I meant for example gphoto drivers, those are separate dynamic libraries and indeed are needed.. Merged manually with 7eb11afe0eae3cb023601b8b7255358cfe99b996\nThanx @brxxm and @flannelhead!\nOriginal paths to portfiles work for me, so I chose more generic approach.\nAs for llvm clarification - I think current verbosity level of this document is enough, it's intended for developers who understand what happens when these commands are run. Blindly following the instructions won't achieve much, this is not a script for a build machine and never was intended as such.. The following functions deal with similar case (re-ordering of multi-instances):\ndt_iop_gui_delete_callback\ndt_iop_gui_movedown_callback\ndt_iop_gui_moveup_callback\nSee https://github.com/darktable-org/darktable/blob/cb0e56198ccc2a3b1ff7b90a349065f59dd5c486/src/develop/imageop.c#L497\nLooks like they silently rewrite history without adding new entries. I think this PR either should do the same, or solve this problem globally, including mentioned functions.. Changing the order won't fix mentioned functions. They probably break history semantic ATM (you can't go back to previous state).. So there is visible change? Then it breaks previously processed images. It doesn't matter if the change is for the better.\n. I think the way forward was already explained - create a new module lens2 in the right place while fixing other bugs old lens has.. > I don't care about XMP order, mathematically, it's the same. Even with masks and parametric blending, it's still safe on 85 % of the picture at least.\nI think we have different understanding of what mathematics is. You can't say that it's safe to say 2 * 2 = 4 at least in 85% of cases...\n. You can check how it's done for relocatable DT on MacOS and Windows:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/file_location.c\nBut I think there's a problem - the directory structures in build and install dirs aren't the same, so this use-case (running DT from build dir) might require custom code. It's probably not the best idea - why increase the amount of code if you could just install DT to some temporary directory (writable by user) and run it from there?. Or maybe one can get away with passing --moduledir and --noiseprofiles arguments (and optionally --localedir) without changing any code.. red frame was intended, because different css were needed because of gtk update. It was obviously broken, users complained to packagers and they fixed their packages. Alternative was to be broken in subtle way, which would stay undetected for longer time. Same goes for custom darktable.css. You are right, that more clear message would be better, so why not do it instead of hiding the issue?\nSo I would say this \"fixes\" an intended feature by removing it instead of making it more user-friendly.. The issue is the following (and it can repeat itself in the future, though it's unlikely now):\n- darktable is built against older gtk (< 3.19) and uses special css file\n- GTK package is updated\n- darktable needs to be rebuilt to use newer css file, until it's done GUI is obviously broken (red frame) instead of subtly broken\nI guess we went this way, because you can't have css style compatible between those GTK versions. The only way is to complain about incompatible style (either default or user-supplied in ~/.config/darktable). This is more about forward compatibility, then backwards.\nAnyway, I'm not sure what is the right approach here, just pointing out that you missed original intention of that code.. And if we are talking about better backwards compatibility with user styles, I think it should be allowed for user to change in user config just the colors he wants, not copy the whole darktable.css. That should fix the use-case you have in mind, without breaking the logic I described.. OK, I see, the lines you're touching were added after the change I'm describing. You just shouldn't have mentioned red frames issue, because it's not the same case;). Of course more cleaner solution would have been if DT just @import's both system config and user config without user explicitly adding @import to his darktable.css file. This way there won't be duplication of the same values in code and in default darktable.css.. 3.18->3.20 update is the one that broke stylesheets.. macOS package uses latest stable release (0.3.2) with latest lensfun database, updated at the moment of the build.. lensfun db is inside app bundle: darktable.app/Contents/Resources/share/lensfun\nI think the one in user's home directory is not used. Try copying it over.. I will consider upgrading lensfun for 2.6.1 release.. @pick2510, just letting you know that I won't update lensfun for next release. I tried it, but currently darktable and lensfun alpha release are incompatible - a lot of crashes and code changes are required in DT.. This PR also disables sharpen by default.. Why have you chosen \"contrast equalizer\" name? It doesn't affect just the contrast, so the reasoning is not obvious.. From where I'm sitting it looks like a more or less complete re-write of darkroom backend, but instead of doing it cleanly from the scratch it is merged in small steps that are masked as \"improvements\" and ignoring any notices about changes being incompatible with original design choices. I understand that it's much easier to write a new module and declare old one obsolete (instead of writing legacy_params code) and break old histories by changing iop order as one sees fit instead of thinking about compatibility. Yes, some of the old decisions in DT core are bad, but changing them requires careful and thought-through approach. Just re-writing code to fit a new idea will result in stuff breaking all over the place.\nI'm not against the underlying idea of recent changes, but the way they are presented IMHO needs much work.. Why then have you already changed order of some modules if the goal is to have it configurable? Just leave old defaults as is and work on the new system. Which BTW you should describe somewhere in full, then anyone can compare it with current one and have his own conclusion on how compatible they are. Doing incremental changes just hides how much you want/need to change.. This is how one goes round doing re-design of such size:\n\nWrite up some text describing flaws of the current code, goals of the re-design, etc.\nDiscuss it.\nCome up with steps how new system will be integrated.\nDiscuss them.\nPrepare a PR for each step, test the new code, merge it after a review.\nThink about which changes can be harmlessly backported to old history stacks and apply them after careful consideration.\n\nI think we're going about it in a reverse direction. You say you want to trigger design discussions, but you completely skipped steps 1-4 (or have I missed something here?) and we're stuck discussing technical details of each new change instead of the whole picture. You obviously know the way you want DT to work, but don't you think it shouldn't be one man's decision? For one other people know DT internals much better.\nMy fear here that the way this is going after everything gets merged we end up with completely unmanageable, untested and subtly broken code, much worse than we have now (which is already not good). Any new big feature needs to be cleanly designed, so that overall quality of the DT's code improves, not degrade further.\nThat's just my opinion, and given that I don't spend any considerable time developing DT it can be completely ignored. Just maybe give it some thought. I'm not going to comment further on these changes.. Shouldn't it be kept in LAB and just set LAB colorspace in colorin iop? Is conversion LAB->sRGB->LAB lossless?. Obviously it's not. You need to include CA bundle file into package and point curl to it like that:\nhttps://github.com/darktable-org/darktable/blob/4f9203a65a64b9bb3aa73eb18f9f048179e602f3/packaging/macosx/start#L44. That sounds wrong, if we are talking about Linux, then system curl should be able to validate SSL certificates without any action from darktable. So no need to bundle anything. I would strongly advice to remove those CURLOPT_SSL_VERIFYPEER FALSE lines, it is a security issue.. @techexo: As far as I can tell nominatim.openstreetmap.org correctly sends that intermediate Let's Encrypt CA certificate, so it needn't be in system's trusted CA list and in fact on Linux that's exactly the case. So it seems that Schannel doesn't trust any CAs by default (doesn't use system ones).. @TurboGit, I see that validation of SSL certificates is turned off in those storage modules for all platforms, not just Windows. That's why I'm speaking about Linux - we must remove those lines, this is an existing security issue.. @techexo, that's strange then, I guess Schannel SSL implementation is lacking in functionality, maybe switching to another SSL backend library for libcurl is actually a better approach. On the other hand other implementations will probably require that ca-bundle file anyway.. @techexo, does it work if just DST Root CA X3 is in CURLOPT_CAPATH? Because curl-ca-bundle.crt probably doesn't include Let's Encrypt CA.. One should also consider this when talking about AVX performance: https://blog.cloudflare.com/on-the-dangers-of-intels-frequency-scaling/. I don't think that we should include curl-ca-bundle.crt in darktable repo. I think it should be instead copied into Windows package from some system location like it's done for macOS package. The reason being that someone has to regularly update curl-ca-bundle.crt in our repo if we choose to add it.\nAbout the changes to the code - you specify relative path for CURLOPT_CAINFO, are you sure it works like that? Most likely it's relative to current directory, which can be anywhere. I think absolute path has to be constructed and probably tested for existence so that we don't break default system path for this file.. About curl_easy_setopt calls I would say construct absolute path using dt_loc_init_datadir function and then check it for existence - I think this logic is platform-independent.. My suggestion covers MacOS case and is at least harmless for Linux. I'm too busy right now to make a PR, just look for examples of dt_loc_init_datadir usage in dt sources.. Set screen_dpi_overwrite setting to something like 72 in ~/.config/darktable/darktablerc.. Just a little comment about fonts: there isn't an \"ugly Sans\" font, because it's just an alias for some other font (say Roboto, because it's also sans-serif), which is configurable through fontconfig.\nBTW, what happens if user doesn't have Roboto font installed? Will it fallback correctly to default Sans font?. The difference is that changes in fontconfig affects the whole system, so you will have the same font everywhere by default, which is nice. But I don't have any real arguments against using specific font for DT, I think it's a valid approach.. > When the left panel is collapsed, or the navigation is hidden, and the histogram is hidden too, computing the preview pixelpipe becomes useless so we disable it to spare the overall performance.\nI think some iops depend on preview pipe being present for their computations. E.g. does zone preview in zone system iop still work?. I don't get why we need another colorspace profile setting - there is already output profile (not display) in colorout. The fact that it can be overridden when exporting doesn't matter.. I guess it makes sense in case of CMYK printer profile, which I think can't be used as output profile. Otherwise I don't see why it should be different either.\nYou select output profile and develop with it in mind, so it makes sense to see histogram/overexposed in that colorspace, why would it need to be different? What workflow do you imagine where 3 separate settings for colorspace (4 if you count display profile) is needed?. @aurelienpierre, my comment is based on current system in DT. With what you're doing \"output profile\" should be just changed to some working space RGB color profile like ProPhoto or whatever is chosen. I don't see a need to see histogram in any other profile than that, and from the comments I see that it's like that in other software too. Having overexposed indicator work differently than histogram is IMHO misleading. I'm yet to see the scenario where it's needed, just because some people asked for it doesn't mean it's useful (unless they explain why they want it and it makes sense). Adding option for every possible thing you can change in the code is not the right way to design software. In this case it will also make things hard to use, since user will have to change the same setting in many places instead of one (and it's easy to forget this).. So how many colorspace settings do you think are needed (aside from display/output which shouldn't affect the processing at all)? I see only 2:\n1. working space RGB profile, probably non-configurable or at least not in bottom panel, currently it's display profile;\n2. gamut check profile - as an idea: when gamut check is active - recompute histogram and overexposed in that profile instead of working space.\nAgain I don't see the need for a separate setting just for overexposed, it doesn't make any sense.. 1. @aurelienpierre, I didn't comment on how overexposed (both ordinary and raw) should work and whether it's broken now, because I haven't looked at the code. It should be defined what is considered overexposure, and looking at DT user manual I guess you are correct that current implementation is broken. Raw overexposure on the other hand shouldn't be affected by any module at all, since it's described as working on raw input.\n2. @edgardoh, as for profile settings - I'm not convinced either that export and print profiles should be separated. And I didn't understand where do you want to put these preferences (view, export. print). Also I don't think it's useful to see overexposed areas or gamut check for display profile - display profile is only for displaying stuff, nothing else.. @edgardoh, so I'll ask again - where do you propose to put UI controls for selecting each of those profiles? colorout IOP? gamut check menu? What would to be the steps for user to see gamut check for, say, \"view\" profile?. It's more clear now, thanx. Some notes:\n1. you are moving display profile from colorout iop to bottom panel, might be a little hard to do currently;\n2. print profile is just a helper for user so he doesn't have to look for it in the whole list of out profiles, I guess it might be useful;\n3. on the other hand there's no such helper for \"view\" profile (working profile) - say user wants histogram in ProPhoto space, but after he selects print profile in view combobox in order to get back to ProPhoto he will have to browse through whole list of out profiles to find his choice of \"view\" profile;\n4. also you are complicating soft-proofing/gamut-check - right now user selects gamut check profile once and then can toggle gamut check with just one click, with your suggestion he will have to select another profile in view profile combobox, then switch on gamut check (and reverse procedure for turning it off) - it's a lot more time-consuming.\n3 might not need fixing if 4 is fixed. 4 can be fixed by leaving alone gamut check profile and switching view profile to that setting automatically when user switches on soft-proofing or gamut check. This will result in us having these settings for color out profiles:\n1. display - needed\n2. view/working - useful for fixing histogram until real fix gets merged\n3. export - needed\n4. print - just a helper for faster switching between export and print profile in gamut check\n5. gamut check - just a setting for gamut-check/soft-proofing, will be set to one of the 2-4 most of the time\n~~My question is the following - can't this PR wait until real fix for RGB working space is merged? It will change the meaning of view/working colorspace somewhat and make most of the code in this PR obsolete (aside from UI changes).~~ Actually I take back that question - if we want to see histogram in export profile we will still need to convert colorspaces. The only thing that will change is what view/working profile setting is affecting.. >> 1. you are moving display profile from colorout iop to bottom panel, might be a little hard to do currently;\n\nNot sure I get this, colorout don't have an option \"display profile\", it uses it internally while in darkroom, but I'm not changing that, the image displayed will still be in display profile. What may be in a different profile are the color picket, etc..\n\nRight, sorry, it has already been moved some time ago, nevermind about that point.\n\n\n\nprint profile is just a helper for user so he doesn't have to look for it in the whole list of out profiles, I guess it might be useful;\n\n\nCorrect\n\n\non the other hand there's no such helper for \"view\" profile (working profile) - say user wants histogram in ProPhoto space, but after he selects print profile in view combobox in order to get back to ProPhoto he will have to browse through whole list of out profiles to find his choice of \"view\" profile;\n\n\nCorrect, its a limitation. PR 1841 introduces a working profile, until then it will be hand picked.\n\n\nalso you are complicating soft-proofing/gamut-check - right now user selects gamut check profile once and then can toggle gamut check with just one click, with your suggestion he will have to select another profile in view profile combobox, then switch on gamut check (and reverse procedure for turning it off) - it's a lot more time-consuming.\n\n\nI don't see it as a lot more time consuming, is just a click more. If I want to gamut check then I select print profile (or any other profile) and click on gamut check, to disable gamut check I click again on gamut check and depending on what I want I select another profile on the view profile combobox. Note that you don't need to be on a specific view profile to do your edits, this setting only affects the color picker, histogram, etc, so you may do your edits with view profile=printer and the only difference is that you'll see the histogram and colorpicker values on the printer profile. And maybe that's what you want. I'm proposing it like this because people may want to gamut check things in profiles other than print. Let's say I send an image for printing, I want to gamut check the image I send (with export profile) and the printed image (with print profile).\n\nI disagree here. First of all it's more than one more click - you also need to find where to click. Secondly I don't think always seeing histogram in print color profile is a good idea - I assume histogram is useful to look at during picture development, so it should be output-independent. Printers are interchangeable, user can have several choices of printers, so while it makes sense to check how it will look on specific output device once in a while, one doesn't develop pictures just for that device IMHO. Basically if user wants to develop the picture like that he will just keep soft-proofing on all the time, which will switch histogram to that color profile. As for last point about gamut checking - it's resolved by keeping separate gamut check profile setting.\n\n\n3 might not need fixing if 4 is fixed. 4 can be fixed by leaving alone gamut check profile and switching view profile to that setting automatically when user switches on soft-proofing or gamut check. This will result in us having these settings for color out profiles:\n1. display - needed\n2. view/working - useful for fixing histogram until real fix gets merged\n3. export - needed\n4. print - just a helper for faster switching between export and print profile in gamut check\n5. gamut check - just a setting for gamut-check/soft-proofing, will be set to one of the 2-4 most of the time\n\nNot sure I'm following this, gamut profile no longer exits, it has been replaced by print profile. And by switching the view profile when gamut checking is selected I will be limiting the gamut check to one profile.\n\nIt exists in my proposal to keep it;) So no limitations if it stays.\n\n\nMy question is the following - can't this PR wait until real fix for RGB working space is merged? It will change the meaning of view/working colorspace somewhat and make most of the code in this PR obsolete (aside from UI changes).\n\nI don't know if you have a specific development in mind, but I'm doing this taken into account PR 1841, it will work just fine with it.\n\nI retracted that question.. @edgardoh, I'm confused about your scenario, because you say 4 is the first time you have to change view profile, but it's not, you have to change it for 2 and 3 to get gamut checking in needed color space (in your description you changed only output colorspace). Secondly what exactly are you tuning in steps 2 and 3? Changing output color profile won't change anything visible in darkroom unless you change \"view\" profile or enable soft-proofing. The problem with your described workflow is that it will become broken after RGB working color space gets implemented, then changing \"view\" profile will affect also the processing and output of the pipe. That's not what you want. And the idea is to not have yet another one color space setting. You get histogram/color picker in the working colorspace unless you enable soft-proofing/gamut check.. I think I misunderstand the idea then. I thought that after working colorspace fix is merged we would want to have histogram in that working space, so taken before final transform to display/output profile. I think that's what other software like Lightroom is doing, isn't it? And your proposal is to have a separate setting for histogram/colorpicker/etc which by default is set to output profile?\nAbout my proposal - yes. main idea is for gamut check/soft-proofing to override (when active) histogram/colorpicker colorspace with its setting.. I agree in general, at least for now. It can be revised later.. > Why cant we use the system CA store?\n\nEven more Why ... WHY is this on for all platforms? If windows needs it ... guard it accordingly.\n\nIt's also useful on macOS and shouldn't hurt on Linux either.. Interestingly enough that article doesn\u2019t consider all lowercase text;). Where do you want to add capital letters? I assume/hope it's not everywhere? German screenshot is not awful, but I don't like it.. I guess I'll reformulate the question - where do you want to keep all lower-case letters?. I\u2019m using the default build type which I think is RelWithDebInfo that uses just -O2 flag.. sscanf is no better than strtod, it's also affected by locale setting. I know a fix in C++, but not for pure C. You probably need to re-implement this function by yourself.. Here's a solution in C++, which we can for example put in separate .cpp file and use through a header with extern \"C\":\n```\ninclude \ninclude \nstatic const std::locale& c_locale = std::locale(\"C\");\nint scan_str_to_float(char string, float output_value)\n{\n        float val = 0;\n        std::istringstream istring(string);\n        istring.imbue(c_locale);\n        istring >> val;\n        if(istring.fail())\n                return 0;\n        *output_value = val;\n        return 1;\n}\n``. This might be relevant:\nhttps://redmine.darktable.org/issues/12568#note-13. Bug tracker is not a user support forum. Use mailing list or discuss.pixls.us forum for that. But first read documentation, specifically https://www.darktable.org/about/faq/ covers this problem. Yes, you are supposed to read documentation if you encounter a problem. The fact that you don't want to do it is not a darktable's problem/bug. You're just wasting (limited) time of developers and maintainers.. Try putting in your~/.bashrcsomething likeexport BROWSER=firefox`. ",
    "minusdreidb": "great, i'm glad the move feature made it into dt.\nafter i've found the copy \"file format\" in the export module that also copies selected images and their xmps to a given folder, i'm not so sure about the copy feature myself. the only difference is, that the destination folder isn't imported as a film roll automatically like my implementation (which makes sense, as it is an export after all).\nbecause i wasn't so sure about the copy feature myself at the time, i didn't add a config option allowing to disable the confirm dialog for the copy operation. originally i wanted to discuss the following on irc, but you were faster with your merge than i expected :) :\nDepending on whether you want to keep the copy feature, i'd\n- add the missing config option for the sake of completeness , or\n- remove the copy feature\nand open another pull request.\n. english wiktionary [1] says that \"unrejected\" = \"not rejected\", so i left it at that. but it really sounds like \"something that was rejected and then it was accepted again\", as parafin remarked. so i'll change the label to the proposed \"all but rejected\".\n[1] http://en.wiktionary.org/wiki/unrejected\n. You're welcome!\n. ",
    "ante316": "I would concur in that \"all but rejected\" would make more sense for most people rather than \"unrejected\".\n. ",
    "McBofh": "On 15/08/12 05:19 AM, minusdreidb wrote:\n\nenglish wiktionary [1] says that \"unrejected\" = \"not rejected\", so i\nleft it at that. but it really sounds like \"something that was\nrejected and then it was accepted again\", as parafin remarked. so\ni'll change to the proposed label \"all but rejected\".\n[1] http://en.wiktionary.org/wiki/unrejected\n\nAh, semantics in English ... they're lovely ;-)\nI'm in favour of removing ambiguity, especially when we have\nto be cognizant of non-English locales. Just because I speak\nEnglish (fluently, I hope!) does not mean that any other user\nor developer does, let alone to the same degree.\nI think having \"all but rejected\" is good, but perhaps having\n\"all except rejected\" would be better. The phrase is clearer\nand reflects the mathematical reality of what you're presenting\nto the user.\nJames C. McPherson\nSolaris kernel software engineer, system admin and troubleshooter\n               http://www.jmcpdotcom.com/blog\n. [Solaris package maintainer] - I'm fine with this change.\n. Not every OS' /bin/sh behaves the same way as /bin/bash or /usr/bin/bash. For example, on Solaris 11, /bin/sh is actually ksh93. I am unsure what Mac OS X has in this regard.\nIn earlier revisions of git master scripts, there have been occasions where bash behaviour (not extensions) was assumed, causing the scripts to fail on Solaris and preventing dt from building.\nChanging \"#!/bin/bash\" to \"#!/usr/bin/env bash\" would be safer in general than your proposal.\n. @boucman: sorry, I can't test on Mac OSX; don't have a mac. \n. Please do not remove comments from files. It is even more important to keep comments in PO files than in code, because (as Richard pointed out) you need to give you translators every possible advantage to make their task easier. \nAbsolute file size decrease should not be a goal here. \n. On  1/10/14 04:22 AM, Roman Lebedev wrote:\n\n@boucman https://github.com/boucman again no, because i have used\nPATH_MAX only in runtime, and there any PATH_MAX value will be fine.\n\nHaving had a quick check of\nhttp://pubs.opengroup.org/onlinepubs/009695399/basedefs/limits.h.html\nit might be better to use\n_XOPEN_PATH_MAX\nwhich is defined as 1024 bytes in the standard - any Unix(r) or\nUnix-alike which claims adherence to\nIEEE Std 1003.1(2004)\nwhich is an updated version of _XPG6 or XOPEN_SOURCE = 600\nJames C. McPherson\nSolaris kernel software engineer, system admin and troubleshooter\n               https://www.jmcpdotcom.com/blog\nFind me on LinkedIn @ http://www.linkedin.com/in/jamescmcpherson\n. The latest version of cups available for Solaris 11.x is 1.4.5, so I agree with Roman's suggestion about CMake disabling printing if a suitable version is not found.\nRequiring DT users to upgrade their installation of a system-delivered package like cups rests on the assumption that (a) there is a newer packaged version available for them, (b) that they have admin rights to install it, as well as (c) that they can roll their own if there is no package. Not user-friendly.\n. Both open() and fopen() are part of POSIX (see http://pubs.opengroup.org/onlinepubs/009695399/functions/open.html and http://pubs.opengroup.org/onlinepubs/009695399/functions/fopen.html), so any platform claiming POSIX adherence will have them.\nI don't think your proposed change is necessary - do we really need to have buffered I/O for this lockfile?\n. I also vote for the second option.\n. aarggh, please ignore; not what I was trying to achieve\n. On 26/02/14 08:58 PM, Boucman wrote:\n\nIn src/libs/masks.c:\n\n@@ -995,7 +995,7 @@ static int tree_button_pressed (GtkWidget treeview, GdkEventButton event, dt\n           }\n           if (nbuse != -1)\n           {\n-            if (nbuse>0) strcat(str,\" )\");\n-            if (nbuse>0) g_strlcat(str, \") \", sizeof(str));\n\nyou added a whitespace here\n\nI don't see a problem with that. To my way of thinking, it\nimproves readability. I'd put the g_strlcat(..) on a separate\nline, but apart from that I have no issues with it.\nJames C. McPherson\nSolaris kernel software engineer, system admin and troubleshooter\n               https://www.jmcpdotcom.com/blog\nFind me on LinkedIn @ http://www.linkedin.com/in/jamescmcpherson\n. Have you checked that this change works correctly on a Solaris system?\n. If you're going to make dt complain about a low value here, then you should return the detected value from dt_openmp_init_stacksize() so that you can provide the user with information about how far off the minimum they are. \nis SAFESTACKSIZE a minimum or a maximum? This information should also be provided to the user.\n. Given the info about this environment variable found in  https://gcc.gnu.org/onlinedocs/libgomp/OMP_005fSTACKSIZE.html and http://www.openmp.org/mp-documents/openmp-4.5.pdf (section 4.7 on page 298), it seems to me that whichever function retrieves this environment variable MUST process B/K/M/G suffixes as well as non-suffixed values.\nSomething along these lines:\nchar *pval = NULL;\nuint64_t value = 0;\nif ((pval = getenv(\"OMP_STACKSIZE\")) == NULL) {\n    value = MINIMUM_SAFESTACKSIZE;\n} else {\n    if (isascii(pval[strlen(pval)])) {\n        /* modifier processing required */\n        ...\n    } else {\n        value = atol(pval);\n    }\n}\nreturn (value);\nand then use the returned value in setting pthread_attrs.\n. Why is the   && defined(GLIBC)   necessary?\n. You appear to be missing the point: whatever \"value\" you get from the environment variable MUST be sanitised AND translated into a kilobyte-based variable. Your change does not do that at this point. \n. Am I correct in assuming that you believe the #include  should be valid for every OS which dt builds on? How many people running dt on the non-linux OSes have you confirmed this with?\n. On my Solaris system, 'ulimit -Ss' returns   8192 as the default, ie, 8Mb.\nLinux != Solaris != FreeBSD != NetBSD != MacOS\nWhat problem are you really trying to solve with this change?\n. As best I'm aware, this block was working fine with the various flavours of linux that the core team use. Those flavours all use glib, and if they had a problem with that block I would expect them to note it and fix it. \n. Erik: To avoid yelling from the compiler, you need to either cast this call to (void), or handle the error condition. I prefer handling the error:\nif (getrlimit(RLIMIT_STACK, &rlim) < 0) {\n        /* handle the error case, by using some sane defaults */\n}\n. I get yelling from the compiler when a non-void function's return value is not handled. This has been standard behaviour in gcc/g++ and the Solaris Studio compilers for a very long time. It's also standard practice to handle this rather than ignoring the return. \nhttp://pubs.opengroup.org/onlinepubs/009695399/functions/getrlimit.html  doesn't specify a value for the max, but if you check the description here:\nhttp://docs.oracle.com/cd/E36784_01/html/E36872/getrlimit-2.html#scrolltoc then you'll get quite a good description.\n. On  8/01/16 10:31 AM, Pedro C\u00f4rte-Real wrote:\n\nIn src/external/lua/CMakeLists.txt https://github.com/darktable-org/darktable/pull/1039#discussion_r49145862:\n\n@@ -1,4 +1,4 @@\n-cmake_minimum_required(VERSION 2.6)\n\nThe current Ubuntu LTS (14.04) still has 2.8.12 so it would be nice if we could keep compatibility for that until the next LTS (16.04) is out.\n\nSolaris 11.3 still has 2.8.6. Yes, not a primary development\ntarget, but I do have users (apart from me) of this build.\nI'd prefer to not have to maintain my own copy of cmake as\nwell as all the gnome bits :)\nthanks,\nJames C. McPherson\nSolaris kernel software engineer, system admin and troubleshooter\n               https://www.jmcpdotcom.com/blog\nFind me on LinkedIn @ http://www.linkedin.com/in/jamescmcpherson\n. ",
    "franz": "rebased to master (21556383b74b63530b1559bc2669c9e5a4f29772)\n. rebased to master, plus changed to dt_get_wtime()\n. Hi Ulrich,\nOn Sun, 9 Sep 2012 08:39:04 -0700\nUlrich Pegelow notifications@github.com wrote:\n\nsorry for being so late in testing. Looks really good. I will commit\nto master. One small thing. There seems to be no clean-up of the\ncache. So the cache might fill up quickly with pre-compiled opencl\nbinaries, especially for developers. Maybe you should at some time\nadd a clean-up function.\n\nThat's pretty much why i came up with link-to-md5sum way of doing this.\nI didn't want to store the md5s somewhere, and i didn't want to\ntake care of cache clean up.\nExample, lets have:\n~/.cache/darktable/cached_kernels_for_bla/basic.cl.bin -> 4a7543cb4...\nthen we update driver. Both the basic.cl.bin link, and 4a7543cb4 cache\nfile should be deleted; then new ones are created\n~/.cache/darktable/cached_kernels_for_bla/basic.cl.bin -> 790a90609...\nThis way, there should always be same count of cached files as there\nis .cl files in DT :)\nCheers,\n  -- mb\n. Uhhoh, good catch, that's just a temporary file from my playing with blendop.cl :-)  fixed\n. I had no idea something like dt_get_wtime exists :) I can take a look & rebase to current master\n. ",
    "fgrollier": "This patch may look a little bit hackish. Maybe a better solution would be to add another proxy function to modulegroup (eg refresh) that would do the same thing, but allow the code to look \"cleaner\" ?\n. Hmmm, right. This PR was fixing a symptom but not the true bug, which lies in range selection of images. I'm closing this and will do another more appropriate PR.\n. Superseded by 829048e81b6289a8f2302f81788aaefcba4a9590, closing.\n. Mmm, maybe I don't understand you correctly, by I don't think this will be a solution.\nMy understanding of the bug is that we need a way to tell darktable that the image below the cursor as changed without the mouse actually moving. And as far as I can tell the proper way to do this in dt is to use DT_CTL_SET_GLOBAL(lib_image_mouse_over_id, ...) \u2014 because the metadatas updating code reads what's in this global variable to update itself \u2014 and it's this macro that triggers the mouse_moved signal as part of its job.\nSo, apart from duplicating the functionality of DT_CTL_SET_GLOBAL while stripping its \"raise signal\" part, I can't find another solution right now. But maybe I'm not intimate enough with darktable's code to handle this properly :)\n. Well, if I understand correctly the code both solutions of modifying select_this_image or dt_dev_change_image should work the same way (the first is called by the later). The only time select_this_image is called without dt_dev_change_image is at darkroom's initialization time, but it's not of interest here. So I think there's no \"real\" difference in the case we're involved here.\nThat said, select_this_image looks more like a database oriented function, while dt_dev_change_image is more general, so I chose the second one. As I said before I'm not yet familiar enough with dt's internals, so these remarks may be irrelevant.\n. ",
    "dumbbell": "libintl is provided by gettext.\nI see that on Debian, there's /usr/lib/preloadable_libintl.so, installed by the gettext package. I guess it has the same symbols, though I can't confirm that because the file is stripped. I don't know how it works on Linux unfortunately and I can't quickly find any explanation about this.\n. christte, I followed your advice and limited -lintl to *BSD systems.\n. I just updated this branch with a forced push to fix a typo in the commit message (s/ineger/integer/). The new commit is dumbbell/darktable@e455f4b2a26b31966d03e32a3f75e8b6b233f84d).\n. I made a new branch called use-sh-instead-of-bash and will make an associated pull request in a couple of minutes. Therefore, I close this pull request.\nThis new branch changes scripts to use /bin/sh. Only minor changes are needed.\nNote that I only tested tools/create_release.sh.\n. I don't assume /bin/sh to be Bash: *BSD systems ships Bash as /usr/local/bin/bash. I assume /bin/sh to be Bourne shell compatible. For instance:\n- Debian ships Dash as /bin/sh\n- Mac OS X (at least 10.5) ships Bash 3.2 as /bin/sh\nI don't know ksh, but the official site states that it's compatible with Bourne shell. I tried tools/create_release.sh with ksh93 and it worked.\nI proposed what you suggest in a previous pull request: #88.\nMy only goal is to stop referring to Bash as /bin/bash, because it's not portable. boucman asked about /bin/sh and I thought it would be ok too, considering the current scripts. Thus, this new pull request. But I'm fine with whatever pull request (or none) you choose :-)\n. I already checked the usage of Bash extensions \"by hand\", but I didn't know about checkbashisms(1), thanks for the hint!\nThis tool reports the same problems I fixed in this pull request, plus this kind of warning:\n``` bash\npossible bashism in common.sh line 10 (alias):\nalias ReadLink='greadlink -f'\n```\nBut I don't see what's wrong here.\nRegarding Dash, I tested the most \"complicated\" scripts:\n- tools/create_release.sh\n- tools/update_wb_presets_from_ufraw.sh\nThey both work, once changed like in this pull request.\nFor ksh, another fix was needed (IFS=\"\\n\" instead of IFS='\\n' in tools/update_wb_presets_from_ufraw.sh). This branch was updated accordingly.\n. Thanks for this pull-request!\nThe script was handling Exif.NikonIi already, and now Exif.Nikon3. That looks like some versionning to me (\"Nikon2\", \"Nikon3\"). I'll move your changes up to read Nikon3 first, then NikonIi.\n. Matthieu, I saw your comment to the FreeBSD ticket about Lua 5.2 pkgconfig filename. Could you please split your commits into two pull requests? This would allow the Lua fix to be merged independantly.\nAbout the USE_WEBP option, I agree with parafin and pmdebruijn that such an option helps packagers. For FreeBSD, I submitted a patch [1] to the maintainer of the darktable package to update to 1.4.0 and WebP is enabled by default (though I don't know what he'll decide in the end). But if we decide to not support USE_WEBP, we must remember to remove it from CMakeLists.txt (top of the file).\n[1] For reference, the ticket on the FreeBSD side about 1.4.0 update:\nhttp://www.freebsd.org/cgi/query-pr.cgi?pr=ports%2F185647\n. Hi!\nI confirm that using using namespace std; above the extern \"C\" block in exif.cc fixes the build with GCC 4.8 on FreeBSD:\n``` c++\nusing namespace std;\nextern \"C\"\n{\n```\n. Works for me on FreeBSD as well. Thanks!\n. Hi!\nThis works perfectly on FreeBSD. Thanks for this patch, it's much better!\n. @LebedevRI: I confirm the problem with cropped thumbnails is fixed with latest master. Thank you!\n. ",
    "chubinou": "\nI fixed the crash you encountered, It happened when you have a photo with no title but a description\nI fixed the no album scenario: my function which retrieve the album list were returning NULL when the request fails or a GList .... which is NULL when empty :-)\nI removed the trace from curl (I forgot this one)\n\nHowever I think I've found another bug, I'll try to look at it this evening\n. I think it should be ok now\n. rebase done\n. 1) parse response error: I didn't encounter this issue, it looks like a bad response from the server (or perhaps a network problem), I added trace for curl with the macro FACEBOOK_EXTRA_VERBOSE, it might be useful for getting more details if we encounter this problem again\n2) title/description export error : I don't think this is related to the content of theses fields, I tried to upload some photos with fields like &\u00e9#\"([\u00f6*\u00e2\u2122 without any issue\n3) \"Failed to get parameters from storage module. Aborting export\" : actually this behavior is consistent with other exporter. \n4) crash in ui_reset_albums_creation: I fixed some stuff in my management of combox models, I think it should be better\nand, ... I think I've made too much tests with this web app (especially authorizing/deauthorizing the application) and it seems that the application is now being taged as phishing/spam, each time I log (no matter what account) I have a beautiful  \"SECURITY WARNING: The above URL is NOT NOT VALID FOR A CASH CARD OR GIFT CARD. Giving away the URL may result in your account being HIJACKED.\"   yay  \\o/\nI think I should recreate the app on facebook side to get one with a clean state, but I'll do it once it is stabilized enough\nI had some difficulty reproducing the bugs you found, so I hope theses change will be enough. I didn't notice anything particular using a fresh configdir/cachedir.\n. Oh, I compile darktable without the openmp support, because I have some issues with it (the export crash in pixelpipe_hb.c, but it works fine with the ppa version) but it's not related to my exporter as it crash as well with the other exporters. It might be the reason I didn't see the problems you had\nI added the guards to the function but I can't test it. \n. great \\o/ \nI'll look at this issue as soon as possible\n. I don't know why it worked when I tested my patch or if there is some subtleties I didn't see.\n. ",
    "hean01": "This is fixed upstream using signals.\n. Ill take a look at the last parts..\n2012/10/19 simonspa notifications@github.com\n\nthank you! Maybe you can talk to Henrik/dinamic or Christian/christte on\nhow to translate the missing bits...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/63#issuecomment-9597251.\n. 2013/2/2 Richard Levitte notifications@github.com\nI'd like to say a few words here, and I think it's mainly from a\nvisual/photography point of view...\nClutter: this is a thing not just having to do with low resolution\ndisplays, but also with general distraction from the main thing, the photos\nthemselves. Of course, there's always the possibility to press tab and have\nall the panels removed, but still, access to some tools through the GUI\nmakes the software more usable (even for a keyboard junkie like myself)...\nThat said, I really like what this change does in terms of visual\nfeedback, and I very much like it as a toggable thing rather than a\npreference (I might want to see all the stars when I need it, but not ALL\nthe time (see clutter)).\nHowever, as someone else said, the increased contrast is distracting (see\nclutter). The same thing goes for the multicolored fram background thingie\n(see clutter, worse than the colored dots in my opinion).\nSo if it was me, I'd opt for a single button that toggled all-stars,\nall-dots, all-reject-cross, and possibly a preference where the user could\nsay exactly which ones should be toggled or not.\n+2\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/171#issuecomment-13035784.\n. One earlier idea was to draw a trashbin overlay in a corner of the map were\nuser could drop to wipe gps location info..\n\n/H\n2013/2/5 Boucman notifications@github.com\n\nit would make sense if the image was removed from the filmroll when moved\nto the map...\nbut since the image is already in the fimroll, I think that either a\ndedicated target or no target at all is what makes most sense...\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/175#issuecomment-13125039.\n. I disagree with you, trashbin should just be shown while dragging which\nwould make more sense\nthen a hidden feature by dropping outside the map.. Its not obvious and I\nwouldn't even \"try\" that\nto \"see\" if i could remove gps information that way..\n\n2013/2/5 Pascal Obry notifications@github.com\n\nI would avoid the trashbin as it will clutter the screen for not much.\nMoving outside the map seems a comprehensible gesture to say \"please remove\nthis image from the map\".\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/175#issuecomment-13128056.\n. PLEASE, if we introduce UNDO to darktable follow the command pattern!!!\n\nhttp://en.wikipedia.org/wiki/Command_pattern\n/H\n2013/2/7 Pascal Obry notifications@github.com\n\nJose,\n\nIn a first moment I thought that having the undo per view would the best,\nbut I have doubts when you can do lighttable operations in darkroom\n(stars,\ncolor labels,...)\n\nHum... good point! I'll create something more generic then.\n\nPascal Obry / Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\nhttp://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/176#issuecomment-13264894.\n. 2013/2/8 Pascal Obry notifications@github.com\nHenrik,\nPLEASE, if we introduce UNDO to darktable follow the command pattern!!!\nSure.\nOne question, do we want unlimited undo?\nUnlimited per context, eg. in darkroom, working on a image yes, when\nswitching to another reset undo stack and start over.\nin lighttable and map it can be unlimited per instance eg. switching away\nfrom lighttable will reset undo stack..\n\nJust my thoughts..\n/H\n\nPascal.\n\nPascal Obry / Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\nhttp://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/176#issuecomment-13283788.\n. You should rename udata to self for some consistency with the rest of the\ncode of darktable,\nalso you should use the self pointer instead of darktable.undo, there are\nalot of mixed code\nthere were you work on udata and darktable.undo which should be the same..\nWith other words,\ndo not access darktable.undo withing the api, only work on passed self\npointer..\n\n/H\n2013/2/18 hanatos notifications@github.com\n\nhey, just a quick heads-up, i really like this to be in 1.2 (and feature\nfreeze for a release immediately after a merge). the only thing i could\nspot so far is your constructor _init() seems to take an argument, but the\ndestructor _cleanup() doesn't? that way it can't be used to do multiple\ninstances easily ;) but it's really minor. if i get a couple of minutes at\nsome point i'll merge.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/176#issuecomment-13746214.\n. Pascal, can you describe the usecase for this ? and why you cant use the current position approach ?\n. So this is a fix only useful for when exporting images that has a frame iop enabled to prevent watermark begin place on border ? \n\nWhat you really want is to align watermark within the actual image (excluding border witdths) ?\n. Can't we just make watermark to be aligned & positioned within the actual image roi and not use the extended roi that frame iop adds ? I dont remeber actually how it would be done but im pretty sure it can be done, @hanatos  might have some pointers to this issue... ?\n. Actually, i think absolute positioning of watermarks is totally wrong\nespecially if its not scale independent!\nand it should definitly NOT be default!!!\n2013/3/6 Pascal Obry notifications@github.com\n\nBut in fact more I think about this and more I'm persuaded that the\nabsolute mode should be the default. So removing the new absolute GUI\noption and not adding a string. The only problem is that this won't be\ncompatible with previous watermark positioning. I'm not sure how easy it\nwould be to compute the new X and Y offsets to make it compatible with\nprevious version...\nDo you think this is a viable solution, should I invest some time into\nthis?\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/188#issuecomment-14499404\n.\n. First off, what is 6000 ??? assumtion about max resolutions ? my photos have \nbetween 7k - 15k pixels wide and height..\n\nSecond off, with your patch, if you place watermark down at right corner,\nin roi scale this would be be let say 500x500 as an example\nwhen full roi (export to file at full res) is processed 500x500 is more at\ntop-left aligned then bottom-right that was intended on a export of\n5000x5000 size,\nthen export same image as 400x400 and you have clipped away the half of the\nwatermark...\nThis is NOT what a enduser wants to have, undesireable result depending on\nexport resolutions.\nAlso this is a hard things to solve without changing default behaviour\nwhich i designed to be as scaleindependen as it can.\n. Then i have definlty overlooked something, let me pull and test it out..\n. I just tried watermark in master and its broken without your changes, alignment is not working as it used to do...\nsoo. let me sum up, do whatever fits you i dont care...\n. You can take another more proper approach to this issue: \nuse gt_widget_set_name(label, \"panel_label\") for the heading label, then add gtkrc properties to match the named widget and set text color in gtkrc.\nWidget \"*.panel_label\" style \"clearlooks-header-panel-label\"\nand it will be customizable trough the darktable.gtkrc\n. Pascal, don't reference something i said that is unrelated to this.. The\nimplementation worked were i left it\nbut last i tried it didnt work so i didnt mind. This change on the other\nhand is something whole different..\n2013/3/14 Pascal Obry notifications@github.com\n\nIf there is no objection I'll commit. The implementation was boken anyway\n(see discussion Henrik here: #188https://github.com/darktable-org/darktable/issues/188\n).\nSo better to start new version 1.2 with an implementation that will be\nstable and will be the base of new support.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/193#issuecomment-14914748\n.\n. Then my suggestion are, revert your previous \"fix\" and identify the\nactualyl problem than trying to patching up in layers..\n\n2013/3/14 Pascal Obry notifications@github.com\n\nYes I understand. That's what I meant. It is broken and I want to take the\nopportunity to make this on the right track for 1.2. My previous fix is not\nthat good after all. It is kind of patching something that is lot more\nbroken than I thought.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/193#issuecomment-14919467\n.\n. This PR got broken due to recent changes in TIFF, i will fix this as a new PR.\n. \n",
    "michalfabik": "\nthe two dot ellipsis is on purpose, a third would be wasteful.\nyou're showing crop size in what units? relative or pixels? will have to check it out :)\n\nSorry about the dot, I had no idea you were so strict about not wasting resources.\nPixels.\n. ",
    "guitorri": "Yes and no. The version merged has some typos. I make another PR only with the changes.\n. Ok, now I see that I can merge pull requests... Nice. Thanks!\n. ",
    "AlicVB": "Thanks.\n. 1- yes, I'll change that\n2- I'll check\n3- unfortunately, that would be very difficult, as you can't assume image borders are still linear (and they are not)\n4-5 : no ideas here... but it would be difficult to let keystoning work like cropping, otherwise, as you may want to have keystoning applied to set crop\nAnyway, thanks\n. not dragging the lock icon (would be confuse with the mouse click), but dragging the entire line would be feasible and not so difficult.\n. ok thanks,\nfor commit 846dd29, it was just that g->k_show is set to 2 once keystone applied. so you just need to check that g->k_show is not 1 in mouse_move. See commit 6e79111.\nFor the 3d thing, I'm not sure what you mean here... I think you want to emulate a \"fake\" 3d, right ? If so I've no idea haw to do that...\n. Ok, this new alogorithm is way better, imho. Thanks hanatos !\nThis may need some tests, but i've just changed the algorithm...\nThis commit integrate some minor changes hanatos made on the keystone branch from the main repo.\n. For the first point : imho, it's the normal behavior for a keystone correction system... I think the undercorrection as to be done by the user himself.\nFor the second point, once module will take care of distortions, we will avoid the rotation off/on... when I'll find some time, I'll add this to the branch where I'm working on that\n. commit dd2db79\n- you can set the horizon with right-click + dragging the line\n- you can move the line too, but it's not intuitive if the offset is not at 50% and rotation not 0\u00b0 or 90\u00b0\nWe will have to choose between both concept.\nThe first one is much robust, intuitive and consistency with what we do for rotation, imho\nAnyway, once we have decided, I will remove the other one and do some cleanup (remove offset slider, etc...)\n. Ok, after a night, you always get better ideas.\nYou can test it, I think it works well now imho.\nNow you can draw a new line with right click or just move one of the extremity of the existing one.\nI have 1 small bug, thought but I have no clue how to avoid it : when you open a image with gnd already set, the line is not draw, you have to change a parameter to show it.\n. Find a workaround to avoid all this gtk criticals warnings :)\n. hi,\nthis is a great work.\nJust to let you know, I've enhance your concept a little bit in the branch zoom-indicator in the main repo.\n. ok your change + mines are now in master, so I close the PR\n. Fair enought :)\nBut there's still a \"real\" bug  if you exit dt once you finish the work on an image in darkroom (without coming back to lighttable), next time you open dt, all the panel have disappear.\nIf you agree, I can remove the \"exit preview\" from this PR and keep the \"don't write panel states to darktablerc when entering full preview\" (as it's designed to be a \"temporary\" state after all)\nThanks\n. ok, let's do it slowly... I'm just back to dt dev ;)\nI'll provide a fix for 1 ASAP and one for 2-3 after (shouldn't be too difficult)\n. hi,\nI'm currently do lot of cleanup in the collect module. I plan to add this kind of features after that, but maybe in a more universal way (range selection can apply to other numerics entries too).\nFYI my work is in the \"collect_rework\" branch (WIP)\n. Thanks for the review. But I'm not sure to follow you here...\nThe main pb with what you say is that you speak in terms of instance name, instead of instance number. The name of the instance can be anything. It's initialised with a number, but it's just a convention. You can't rely on them, only instance number (multi_priority) is relevant to define the order of the instance in the pipe.\nso for the 2 problematic cases you mention : \n4- if one just copy the instance numbered \"1\", we can assume that it means that he want to apply just 1 instance of the module, so we renumber it to \"0\". This imply that any previous instance of the module in the destination image will be override. This can be discussed thought... We can check if there's already one activated instance of the module and in that case let the number to \"1\", which will add an instance. But what if you paste to multiple image, some with the module activated, some not ? It will not be consistent, imho.\n5- If you look at the resulting pipe (which is the only way to see the instance order), I think that everything is correctly applied.\nLast point, my proposition works like styles partial copying, so if we change somethings here, we'll have to change it in styles too...\nAny thought ?\n. parafin, boucman : this is what this PR do actually. if I have not done anything wrong ;)\n. ok, what I propose, is to merge this, once some confirm that it works ok. So the bug is solved.\nLast parafin remark about instance names will stay, but imho it's a more \"low\" problem as it doesn't affect how image is display, and it can be treated separately once we find a consensus.\n. Well, it's quite tricky... If I understand what you propose, when you copy less instance than the destination image have is to restreint the final image instance to the nb of instance copied. An example : you copy 1 instance of m : mx in an image with 2 instances of m : ma + mb, you want the result to be an image with just 1 instance of m : mx, replacing ma. I'm right ?\nIf so, I'm not sure that this is what we can expect from an \"append\" paste... another problem is what to do with history items related to the instance mb ? drop them (weird) ? disable them (in a new history item ?) ? Hope that what I've written is understandable...\nimho, we see here the limits of the association of partial copy/paste (and styles) with MI.\nAny thought ??\nFor the name pb, I have to investigate a little more, but it may be an unrelated problem.\n. Hmm... not sure that I really like the idea to add even more complexity here... but well, I don't see any other solution atm. Will have a try asap... Note that this last change, if implemented, should be port in styles too...\n. Well, I was waiting for gtk3 to land to propose my collect rework. I'm currently rebasing the branch, and I think it will be ready today or tomorow.\nSo, if you don't mind, I would prefer you to wait a little before merging (of course, I'll help you rebasing the PR, if needed) thks\n. ok, rebasing finished (was painfull). you can find it here : https://github.com/AlicVB/darktable/tree/collect_rework2\nThere's still one gui point point to discuss with devs, esp. @houz before doing the PR, thought...\n. following hanatos advice on IRC, it's much simpler to reuse dev->history_mutex for that, so I close this and will do a new pull request.\n. seems I missed your comment :(\nunreachable filmrolls/folders are now marked with an icon and not stroked anymore.\n. New try using just a different text color. It's less readable here, but it's certainly due to gtk3 theming...\nAnd some missing features re-added.\n. I'm closing this PR, as there has been too much changes in master since last commit. It would be messy to rebase it.\nPlan is to redo it in smaller pieces, easier to review and discuss.\nstep 1 : cleanup https://github.com/darktable-org/darktable/pull/1098\nstep 2 : core change (no major gui change)\nstep 3 : changes in common/collections.c\nstep 4 : gui enhancement (to be discussed)\n. @pedrocr well, I tend to agree if what you have in mind is just to \"hide\" window decoration, but I don't think it's a good idea to switch to \"fullscreen\" as defined in dt actually, especially for those who don't run dt maximized (ultra-wide screens, etc...)\nAnyway, as you say, if we decide to go this way, it has to be done separately with a more universal scope than this PR\n. @TurboGit done. But not with css, as nothing like that is done in css atm.\nBorders are darker, like in lighttable now.\n. I've had a quick look at the code, and everything seems fine for me.\nI've tested it with different sort of path, and didn't find changes or crashes.\nSo for me it's ok to be merged.\n. closed in favour of PR #1111 with better coding style (clang-formated)\n. Replaced NOTHERE by UNREACHABLE. I hope this is more meaningful...\nFix the root for folders\n. As discussed on irc, I've \"securised\" also all acces to preview pipe use to draw element on canvas, using dev->preview_pipe_mutex, in order to be sure that the preview pipe computing is finished.\n. @hanatos I've reverted all the \"preview_mutex\", and I've locked backbuf_mutex instead, and let input sizes unlocked.\n. fixed \"space tolerance\" and tooltips for operators and date format\n\n\nIt only accepts date in format 2015:01:01, not 2015:1:01, not 2015:01:1, not 2015:1:1\n\n\nSadly, date are store as strings in db, so we have not really the choice (apart to make complex date readers) maybe one day we'll have to change date in db...\n\n\nWith some range set, e.g. [2012:01:01; 2013:12:31], some images are shown in lt, but no dates are shown in collect\n\n\nThis can be added in the future, but I have plan to change the gui for date-time and numeric values\n. at least now, it use the same coding as in the other iop which draw on canvas (and as masks)\nand it reduce the need to store a partial copy of the pipe (which is not the right approach imho)\n. it's supposed to look like that : \n\n\nFor the strings, my English is pretty bad ;) How would you call them ? \"lower\", \"lower than\" ?\n. well...\nMain goal is to have a more easy way to deal with numeric values. imho numeric values are mainly useful if used with operators like >, < or [;]. So actually the steps are : \n- finding the right value in the list (can be quite tedious, as the list can be very very long for focal_length or dates)\n- double-click to select it\n- click on the right place inside the top entry box (tedious too, as it's tiny, and often content of the entry is larger than the physical size of the box, esp for dates)\n- add the operator\n  (and here, I don't speak about setting a range operator for dates...)\n. oh... and the only context menu is the built-in gtk one (with copy/paste...)\nSo I guess you are speaking of the autocompletion ?\nIt's here to let user know what values are actually present in the db, like we do when displaying the list actually. I've just added a \"calendar...\" line for dates, so user can pick up a date without going thought all the list or typing manually...\n. ok, let's tag this as incomplete until we find a better way to display/select numeric/dates and ranges. That's the main point ;)\n. Following houz and hanatos comments about this ui, with messy entries, let's close this pr.\nalthought it doesn't resolve all, pr #1172 can be a solution to avoid the \"infinite\" list of dates.\n. thks for the comments.\n- 'virgin' duplicates now include auto-applied history, like every non-developped image\n- added a remove btn\n- put the lib just under history\nFor the other points : \n- the duplicate nb is useful to have a ref, if you don't set any captions\n- about the thumbnail display, it's a limitation of the actual api. it's quite easy to change, but will require some thinking about what options to expose. I think it's better to postpone this, and let this code independent from the rest of dt\n. thks for your comments, they should be fixed now.\n. Hmm yes seems required in this case.\njust to know, have you tried to do the backtransform in 2 steps (one with pmax=liquify-1, one with pmin=liquify+1) ? I don't think it'll have a real perf cost, and it's less invasive.\n. tooltip fixed. Thks for the review\n. done for aspect ratio :)\nOne little glitch I've found is that with single click, it's now impossible to expand a node without selecting it. I've not managed to determine if the click append on the arrow or in the text.... oops... should be fixed in #2084 . >     * The zoom in/out has a too big step I found. I have 15 years in the timeline. A single zoom-in with the scroll and I get one year a 2 months displayed.\nFor instance, the zoom level are defined so a \"block\" (~120px) represent one year/month/day/... we can split them in 2 (3 ?) something like 3 years/years/6months/month/...\n\n* When changing collection it would be nice to have an indicator of the covered period in the timeline (not like the selection which is sync with date/time on collect module.\n\nHmm not sure how to get that dates without redoing all the sql manually, but I will have a look\n    * I agree that the scroll on the side of the timeline is not very nice. First we scroll once and then we need to move the cursor. And the move is a bit too slow I think.\nI find this particularly useful when you want to scroll the timeline when doing a selection with the mouse.\n* I think the timeline should be deactivated in \"expos\u00e9\" mode. In the current version the timeline is displayed on the left of the filmstrip. I really don't think the timeline is of any use while in \"expos\u00e9\" mode anyway.\n\nSo there's a bug somewhere, it should be disabled (and it works for me...). @cryptomilk : No need of sortable dates. Ideally the dates should be displayed in whatever format used usually in UI language. Example : for French peoples, it's more readable to display the date like 29/06/2014, but I know it's not the case for other languages. I'll see if I manage to take care of that point.. now the timeline is keep in sync with the actual collection. Bar graphs have 2 \"colors\" to show the number of existing/collected images.\nWhen you have some collect rules defined,\n- selection in the timeline either add a new datetime rule or modify the last rule if it's of datetime type\n- selection with shift press remove all existing rules and replace them with a datetime one\n\nThere's still some bugs I have to fix, and the datetime translation too.. My TODO list for this lib is now empty :)\n...except for the datetime translation : \nThe pb is for date range, example : (21-31)/05/2008 (We don't have enough space to show full dates like 21/05/2008-31/05/2008, so we can't use strftime with %x like in metadata viewer)\nMaybe we can stay with the current untranslated datetimes, as we just use numeric formats.\n. > > it support multilines by using the $(NL) variable\n\nThis seems equivalent to entering directly \\n, right?\n\nFor some reason, \\n doesn't work if entered \"manually\". It's removed at some point in the variable replacement process, and as I fear to break something for the export, I've preferred to do it like that.. ok, finally, I've just set views to none if position is set to \"hidden\". I just integrate scale_out*ci.x+0.5 upstream to reduce the number of parameters passed to kernels (line 720 in process_cl)\n. ah ok, will change that\n. Unfortunately, that's a lot more complex.\nThe keystone is applied to an area anywhere in the image. The old system apply the keystone on the borders. Here, you define 4 points and the process transform them so each borders of this quadrilateral become horizontal (or vertical).\nfurthermore, points can be set almost as you want, so one may move just one point, for ex.\nYou can see, that the backtransform function is a lot more complex, not to speak about the transform one !\n. Here, I think git as been a little abused.\ngui_reset is still here with this lines. The corresponding diff modif is just 15 lines above. Don't know why git add and remove this in the same diff thought... Maybe a error from my one ?\n. not your fault here (but mine) : this line should better go inside each \"if(old_version==x && new_version==5)\" conditions, so next version upgrades will not reset the values.\nOtherwise, this seems ok for me, and this will solve presets/styles upgrade too.\n. oops... and same in the next fct...\nfixed\n. oh... leap seconds, even 61 for double leap seconds.\nbut I don't think we should care, the probability is really quite low, and I'm not sure how systems will handle 60/61 values in \"normal\" cases (and not sure that all systems are consistent...)\n. and sqlite seems to accept values only in [0-59] : http://www.sqlite.org/lang_datefunc.html\nnot that we care atm, as anyway we only do string comparisons ;)\n. fixed\n. yep... fixed :)\n. fixed\n. iirc no because it reuse the preview stored in mipmaps (the same used in lighttable for the full screen). To display zoomed preview, you need to 'compute' all the image : creating new pixelpipes etc.... ",
    "pmjdebruijn": "On Wed, Dec 12, 2012 at 10:36 AM, Jose Carlos Garcia Sogo \nnotifications@github.com wrote:\n\nCan't we consider sh as the minumun standad? I usually thought that all\nshells were compatible with sh, as it was defining the minimun set. If\nthat\nis true, and if our scripts can work with it, it will be ok to assume\nthat.\n\nA good start is typically to run checkbashisms (devscripts pkg) on them,\nand checking if they will run with dash.\nRegards,\nPascal de Bruijn\n. An example with regard to darktableconfig.xml:\nhttps://github.com/darktable-org/darktable/commit/3d0673b6d352734a46f87734413b1c489bb3d208\n. I've cherry-picked the two commits to our darktable-1.1.x tree as well, so it'll turn up in 1.1.2.\n17e8da18465d869eedb77e41213e39ea6524d438 and d01b73e3cf8234e0105b4b06ac70fc44c5dc4d11\n. I've cherry-picked d2e34ef19763c6d961fa154acb2cc67527b9fc99 and 0ae2d330a34b91f3fdd6090f73619ae92e36528b to our darktable-1.1.x branch.\n. Hmmmr, though call, technically it wouldn't be okay, but I'll talk this over with the other guys, see what we can do.\n. So this would break other translations, and we can't count on all of them being fixed before release, so while I do appreciate your effort, I'm afraid I can't merge it due to the announced string freeze.\n. In theory it could be done after 1.1.2, but there very likely will not be a 1.1.3.\n. I've forwarded this to the UFRaw folks too. And I'll cherry-pick it for 1.1.2 :)\n. While I highly appreciate the effort, this could really complicate darktable-1.2.x maintenance...\nWhich brings us to the question, does this also at least cleanly apply to 1.2.x ?\nSplitting up the patch into several subsystems might be a good idea...\n. That's not a real solution at all...\nMaintenance of 1.2.x works by cherry-picking patches from git master, which means diffs need to remain compatible. And diffs depend on surrounding text to recognize positioning.\nChanges like this (also like source beautification), should ideally be done, just before a major release, not at a random intermediate point.\n. Splitting up the patch between master and 1.2.x would be good... \nBut then I'm still also trying to maintain 1.1.x, though that is of a lesser concern than 1.2.x...\n. I'm not so sure about the \"ISO\" bit, we mis lots of capitals because of a preferred \"style\" by some... Only capitalizing ISO would seem totally weird to me...\n. Changing this default behavior post-major-release sounds rather suboptimal as well... So I wonder if it makes sense to make an exception here... But yes I know... slippery slope...\n. I'm not sure what you mean to illustrate with the first screenshot?\nThe second screenshot looks cool, scaling the snapshot would be quite nice... Does it only work for zooming out (which of course is quite an improvement :)? I tried applying the patch in the 1.1.x branch, where zooming in didn't seem to work yet...\n. A general note: Both libraries have local changes, so that's something to keep in mind.\nAnother note is that we might not want to update LibRaw at all, as having an up to date LibRaw will mask missing entries from RawSpeed, leaving us more dependent on LibRaw.\nSo there are quite a few caveats at updating these.\n. As I said, we're intentionally NOT updating LibRaw.\nRawSpeed should be fairly close to upstream, as I regularly sync. Sometimes we're even slightly ahead, since I add new cameras and contribute them back.\nThe problem with many Fuji camera's has nothing to do with either LibRaw or RawSpeed, we use them only to read the sensor data, and that works just fine in most cases.\nThe root problem is that Fuji has many cameras that don't use a classic bayer style sensor (like 99% of all other cameras). Fuji has a tendency to make up a new hard to support sensor types every other year or so. We've basically decided not to waste time on supporting that, as it would likely require very pervasive changes throughout our codebase. To add support for these few cameras someone would likely have to sacrifice a vacation to work on it, so it might happen one day, though not very likely any time soon.\n. One of our users, beowulf just tested this branch, and he reports that it seems to fix the issue.\n. Seems to work for me as well....\nI did insert some printf's for event->area.x, event->area.y, but it would seem they are 0/0 all the time :(\n. Well, to be honest, I don't think webp should ever be mandatory though... It's a fairly obscure format...\n. I'd sortof agree with parafin. Especially with ever increasing set of fairly obscure features in Darktable, I'd very much appreciate the possibility to build a lean and mean version of Darktable (even if some dependencies are present).\nI'm toying with the idea of building a darktable-full and darktable-light version from a single package source, which means all build dependencies are going to be installed for the -full build, and will be still present for the -light build, so I'd need a way to force stuff off too.\n. I'm not so sure about this one. I think we had loose matching before, and if I recall correctly it created bogus matches as well, which is worse than not having a match at all.\nMaybe we can handle this more intelligently? If all the Exiv2-Lensfun names are similarly structured, we could cut off \"Nikon AF-S Zoom-\" from all Nikon lens names before passing them to Lensfun for example.\n. I'm not so sure about the approach, this definately requires some additional thought...\nFor the short run, I cherry-picked this from 1.4.1:\nhttps://github.com/darktable-org/darktable/commit/34e5f73faca2e9333236aa283ac08428930e617b\n. Having an online comparison gallery (PPG vs AMaZE vs IGV) would be rather nice to evaluate the benefit in different use-cases.\nBut more generally speaking...\nKeep in mind that once we add another demosaicing algo, we can't easily drop it again (since that would break history stacks), so every added algo adds an eternal maintenance burden.\nWe already have this problem with AMaZE, which isn't that much better than PPG, is silly slow due to lack of SSE optimization IIRC, and isn't being maintained (no code resyncs with RawTherapee, since the original contributor/porter isn't around anymore).\nFor the future I think any demosaicing algo we add should at the very least provide in these areas:\n- Significantly better output than PPG in a fairly common use-case (without pixel peeping)\n- Have SSE and OpenMP optimization\n- Come with a contributors/porters agreement to stick around and maintain the code for the foreseeable future.\n. Sorry for the glacial response... but...\nI just gave it a spin, and it seems to work at least as well as the old code. I do still see a small difference in saturation though, but that happened with the old code as well.\nI hope someone else has some time to review the code soon.\n. I've already independently committed support for the ILCE-6000 a few days ago:\n0c6319e8de5b0ee3f22cdce9a20a8c8fcf8b5fd6\n4e68c9c57d933a785d564401bba2871d582afb97\nd7e3fdcf347ac4d05134a307febecd9d79c6a40a\n(As a general note, if you try to submit something please mind surrounding code style, the stuff you submitted for camera.xml was quite blatantly misformatted)\nSo only the noiseprofiles are missing, if you resubmit for those, we'll be able to pull.\n. This isn't a valid change. Since the advertised image size is not reliable, since sensors often have unusable area's which need to be cropped off. These aren't generally \"detectable\", and they have to be visually assessed.\n. Looks okay mostly, would you mind tab aligning the actual multipliers?\n. The indentation isn't fixed yet...\n. Ubuntu 14.04 LTS ships libsecret-1-0 0.16, and I'd like to support 14.04 for the next two years with a full feature set, so ideally including libsecret if reasonably feasible...\nWhich brings me to my question, how difficult would it be to support 0.16 as well?\n. I've gave this a test run, but it seems to make darktable crash more easily, when zooming in-out a lot. Also zooming to 200% with Markestijn 3pass seems broken.\n. No worries, just drop by on IRC again when you're back. Enjoy your travel in the meantime :)\n. Awesome. Thanks!\n. Would you mind splitting this pull request up? Because I'm not so sure about the channel mixer presets, they may be very cool indeed, but might be construed as trademark infringements. So I don't think something like that belongs in our core. \nAnother concern would be (too) long preset lists... Essentially we ideally don't want to ship more than say 5 presets per plugin out of the box. Which is exactly why the wiki (and for that matter dtstyle.net, thanks to andabata) is there.\n. Thanks!\n. On a sidenote, I see rawsamples.ch doesn't have samples for the D750 either, please do considering submitting them there too.\n. Just a quick question, the 9/-9 presets are exclusively on the yellow/blue scale right?\n. Please see: http://www.darktable.org/redmine/issues/10382\n. Nothing, all critical parts are already in our development version.\n. I'd recommend against hopping on master \"just like that\" as your database will be upgraded, and there will be no way back. Almost everything will be available fairly soon in a new point release.\n. @rawspeed, generally speaking we'd prefer negative width/height notation (which just means pixels to crop from right/bottom). Would you mind adjusting that?\n. I like the new ratio sorting... \nBut I don't think these cinema aspect ratios belong in darktable at all. Our presets should be whatever most people would use for photography purposes. Cluttering the menu up with irrelevant aspect ratios isn't an improvement. Keep in mind that people who want these aspect ratio can still enter them manually.\n. Thanks!\n. Thanks!\n. We can't automatically merge this request now... But it's easy enough to manually pick, so nevermind, committed:\n4d73c5b53ab7f349279c4f132e3816a785f28133\n541a7f9a229e044b0e9865aa6d50fe3e81d91da1\nSo effectively this request is merged now.\n. Thanks!\n. Thanks. However it's not yet complete. We would still be missing the rather critical adobe_coeffs. They can be extract from a PEF converted to DNG, using Adobe DNG Converter. (see tools/dngmeta.sh).\n. Final nitpick, due to historical reasons, more specific names in adobe_coeff should be listed first.\nSo \"Pentax K-3 II\" should be above \"Pentax K-3\", otherwise lossy matching will match Pentax K-3 first, since the matrices are identical it's not a problem in this case. And in master we don't do lossy matching anymore. However we still do to some extent in 1.6.x.\n. Thanks!\n. Thanks!\n. I think we should probably consider keeping our internal copy of pugixml as a fallback for the time being. That would at least making cherry-picking this change to 1.6.x less of an issue.\n. My reasoning was the other way around, we're not quite sure we're 100% fine with completely unbundling in all cases, thus we leave choice. We do the same with Lua, it's available on most platforms, but for convenience (and potentially weird platform) we do offer a bundled fallback.\n. If we're not cherrypicking it, it's less of the issue, since we have ample time for testing before the next major release.\n. Thanks!\n. ",
    "levitte": "Regarding alias: it isn't normally present in Bourne Shell, it's an extension introduced in Korn Shell and C Shell.  In Bourne Shell, functions were used instead.\n. hurrrm could you helt me by telling me exactly how to do it?  git is really not my forte, and I get confused by all the different ways to do things.\nWhat I did was this:\ngit checkout darktable-1.1.x \nsh build.sh      # silly, but...\n(cd po; intltool-update sv)\nemacs po/sv.po &     # did the commit from inside emacs\ngit push origin darktable-1.1.x\nSo I wonder where I went wrong...\n. I figured it out a few moments ago, thank you.  Github thing rather than git thing...\nDone (as you have probably already seen by now)\nI tried git-cherry-pick...  and considering there are a lot of unrelated changes (file references and such), it was actually more work than doing a simple diff.  But for the future, this might be a good idea...\n. Ok.  Is that applicable to this branch as a whole, or would it be appropriate do redo this pull request after 1.1.2 is released?\n. Just a comment from the sideline: as a user, I've avoided the LaTeX book and web gallery options so far, precisely because they seem hard coded.  It's easier for me just to produce the images and generate those on the side...  I'm thinking that a possibility to have user generated templates might be a win in this case.\n. Nope, emacs requires that mode lines to be on several lines as I gave it.\nThe alternative is to have this kind of comment at the FIRST line:\n// -- mode:C++; c-file-style: \"bsd\"; c-basic-offset: 2; indent-tabs-mode: nil --\nIf that is preferred, I can certainly hack that together instead.  I was thinking, though, that having the modelines spread to both top and bottom of the file might not be the prettiest.\nYour call ;-)\n. You're thinking .el (list) files, aren't you?  Yeah, of course, and it's possible to create your own c-style and have that separately.  However, it means each emacs user will have to load it, and it still would mean having something like this at the end of each source file:\n// Local Variables:\n// mode: \"darktable\"\n// End:\nor this at the beginning:\n// -- mode: darktable --\nSo in my mind, it wouldn't give much and would mean more hassle for emacs users.\n. Oooh, I didn't know about that one.  Yeah, that seems like a simpler solution.\n. Please close my previous attempt.\n. heh :-)\n. For custom aspect ratios, it actually saves it (it didn't before, so you'd end up with 1.5:1 when coming back into develop mode because that is the installed default).  It also saves it in the form that the user typed it in, so it can shown back the same way later on, instead of {fraction}:1.\nAlso, it saves the flipped state of aspect ratio presets, something it didn't do before (which means that when you came back into develop mode, your flip is suddenly unflipped).\n9151: http://darktable.org/redmine/issues/9151\n9143: http://darktable.org/redmine/issues/9143\n. Yup. It'll be a couple of days before you see the rest happening, though.\n. [change of mind] please merge this pull if you see it fit, as it's a unit of its own, independent enough from what I'm working on now.\n. Yup, I noticed his fixes, and I like.  I'll simply delete this branch.\n. I'd like to say a few words here, and I think it's mainly from a visual/photography point of view...\nClutter: this is a thing not just having to do with low resolution displays, but also with general distraction from the main thing, the photos themselves.  Of course, there's always the possibility to press tab and have all the panels removed, but still, access to some tools through the GUI makes the software more usable (even for a keyboard junkie like myself)...\nThat said, I really like what this change does in terms of visual feedback, and I very much like  it as a toggable thing rather than a preference (I might want to see all the stars when I need it, but not ALL the time (see clutter)).\nHowever, as someone else said, the increased contrast is distracting (see clutter).  The same thing goes for the multicolored fram background thingie (see clutter, worse than the colored dots in my opinion).\nSo if it was me, I'd opt for a single button that toggled all-stars, all-dots, all-reject-cross, and possibly a preference where the user could say exactly which ones should be toggled or not.  And I'd opt for reverting the unrelated changes (contrast of extension, form of star).  All this in favor of a balance between desired information and minimum of clutter.\n. Thanks.  Yeah, someone else pointed it out to me shortly after the commit...\n. I hope this effort will reappear.\n. Don't do this.  Those comments provide useful information anytime you wonder what you're really trying to translate (there are cases where you may want to find the original string in the source).\nFurthermore, I believe that next time you do 'intltool.update fr', those comments till reappear...\n. You are correct, of course.  And in reality, it's not me who says it, it's https://wiki.gnome.org/Initiatives/GnomeGoals/DesktopFileKeywords .  I just copy-pasted that comment.\n. I'll have you note that they also say that this should be added in desktop.in.in.  There's a whole process behind this, where developers/maintainers write in desktop.in.in, translators do their thing, this gets processed into desktop.in, which is then processed further into the actual .desktop file.\nThere's no such process with darktable that I know of.  Instead, it seems we hack directly into darktable.desktop, where no underscore should be present (it has no support in the specs given on freedesktop.org).  Please correct me if I'm wrong about this!\n. I do know something about translation, and already had a pull ready...  I've just updated and regenerated it, https://github.com/darktable-org/darktable/pull/473\n. Okiedoke...  that means the translations that currently exist in darktable.desktop will, well, get lost.\n. Well, linguistically, I think verb vs. noun is better, it's easier on the translators that need to understand what's what...  it's just that I noticed that the word \"import\" comes with module names as context, among other in the modules affected by this change.  So, I was thinking that in the name of consistency, I'd better follow what's already in use.\nHowever, if I still have the option, I would prefer to use the \"verb\" and \"noun\" where applicable and issue a new pr.  Your call.\n. Great.  This will happen in the next couple of days.\n. Well, there IS a way, to move them all to their respective file in po/...  I'm told it's a sure way to annoy translators, though...\n. It doesn't crash, it stops with the error \"failed to create film roll for destination directory, aborting move..\", precisely because the filmroll is NULL when creating the job in dt_control_move_images and dt_control_copy_images.  Yes, that's the flaw that was found, and it renders moving and copying images useless.\nSee the comments I left in the issue comments.\n. Ah, yeah, I see the change that does the same thing.  No need for my change then, I'll just close it.\n. Changed my mind, automerge was fine.\n. Thank you @gernberg \n. Evidence for my claim:\n: ; for x in _DSF01*.RAF; do echo \"===== $x\"; exiftool '-WB_*' -WhiteBalance -WhiteBalance2 -Whitepoint -Make -Model $x; done\n===== _DSF0184.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 514 689\nWB GRB Levels                   : 302 589 560\nWhite Balance                   : Daylight\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0185.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 518 679\nWB GRB Levels                   : 302 647 481\nWhite Balance                   : Cloudy\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0186.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 510 695\nWB GRB Levels                   : 302 751 492\nWhite Balance                   : Daylight Fluorescent\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0187.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 514 688\nWB GRB Levels                   : 302 629 599\nWhite Balance                   : Day White Fluorescent\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0188.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 511 686\nWB GRB Levels                   : 302 591 773\nWhite Balance                   : White Fluorescent\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0189.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 518 678\nWB GRB Levels                   : 302 384 855\nWhite Balance                   : Incandescent\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F\n===== _DSF0190.RAF\nWB GRB Levels Standard          : 302 384 855 17 302 681 497 21\nWB GRB Levels Auto              : 302 528 678\nWB GRB Levels                   : 302 589 560\nWhite Balance                   : Underwater\nWhite Point                     : 0.313 0.329\nMake                            : FUJIFILM\nCamera Model Name               : X100F. > and no, apparently there won't be any further 2.2.x releases, so no point in cherry-picking.\nAh!  Good to know, thank you.. Oh, so that's where those files are coming from...\n. Okie, done.. Does this mean that bringing X-T3 to the 2.4.x series is impossible? BTW, all I did was update the submodule revision, does that count as \"change rawspeed\"? . > BTW, all I did was update the submodule revision, does that count as \"change rawspeed\"?\nYeahok, I guess it does.\n. According to digicamdb.com, the crop factor for the X-T3 should be 1.534 (you have to calculate it yourself, as they show the value rounded to two decimals).\nI submitted a merge request a few minutes ago.... I can understand left-aligning the section names.  However, would it be possible to make them different from the labels somehow, by default?  The way they look in the images shown above, they look the same as the labels, the underlining helps only marginally, at least to my eyes.. nit pick: end the string with \\n\n. ",
    "TurboGit": "I have just pushed an updated version after resolving conflicts due to recent merge on master.\nPlease have a look and tell me what you think. When many modules are opened I find it hard to see where it starts and ends because the module label is not different from the other text. With this minor change it is far easier to see the module structure. At least to me...\nWaiting for feedback!\n. Hanatos,\n\ni'll take your word for the testing.. pushed, thx :)\n\nThanks. Let me know if you want me to attach the .tar.gz with the PDF\nfile for validation.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Ok done except for the script failing if no ISO found has it has been designed to ignore files without Exif (not an image). Should be ok to be merged, let me know.\n. Please wait for updated data with proper blue channel (see discussion on the devel mailing-ling).\nThe updated profiles should be available soon.\n. Ok, this is now ready for merging. The graph looks clean and testing shows that the profiles are working good.\nThanks a lot for this great peace of software.\n. Ok, new version pushed without the version mismatch. I consider this version ok for merging if you are ok.\n. Interesting, I had named it last_radius and renamed it default_radius as it is more a default to me. The value is not kept when darktable is restarted for example.\nYes, the min is probably to be able to handle it. And anyway it probably makes no sense to have a tiny spot. I have tested my patch on a 10Mpix image and it works ok.\n. New version available, this version keep the spot size across session.\nOk to merge?\n. Good point, I think it will be better to be dependent on the screen (really view) size. But with the proposed patch here it minors a bit this point. Maybe we should open a ticket on redmine?\nAlso the min value may be better expressed in number of pixels I think.\n. No I'm not working on this specific issue, you can review and merge. Thanks.\n. Thanks a lot!\n. What do I need to put in there?\nA response message on the mailing-list seemed to imply that I need to do this only if I use it... But I'm not sure what does this mean! I'm quite new on darktable dev...\n. I have a new pull request for this.\n. But \"ui_last/spot_size\" is the name found in darktablerc! I'm lost :)\n. I'm on it... Will propose a fix soon.\n. Ok, see TurboGit:fix-spots-size-prefs pull request. Will close this one.\n. Le 25/12/2012 21:40, hanatos a \u00e9crit :\n\nnice, looks almost as i would have imagined it.\n\nCool!\n\ni would probably have\nput the style* into the global export parameters:\ndt_imageio_module_data_t (src/common/imageio_module.h:41) and probably\nthen as a `const char style[256]' or whatever fixed size so the derived\nparameter structs know where to append their data and to avoid possible\nmemory leaks due to dynamic allocation.\nthat way you won't have to pass style* everywhere (but would need to\nadjust all the param structs in all format/ storage/ modules to match\nthe same prefix as dt_imageio_module_data_t, not terribly great design,\ncould have been a sub-struct).\none advantage of this approach is that it'll be stored in your presets.\noh, also the image viewer src/dtview/main.c doesn't compile anymore with\nthe changes to dt_imageio_export() (needs one more NULL).\n\nHum... strange it was compiling on my side and still is!\n\ngui wise: i would put the style after color profile/intent, and maybe it\ncould need a more descriptive tooltip (reassuring the user that it'll\nnot apply the style permanently but just for export).\n\nI have just pused a new branch the the above changes/fixes. Can you tell\nme what you think at this point?\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Hum... strange... Looks like my style is not used on the exported image\nanymore... I'm sure I had tested it... Let me have a look...\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Ok, my branch export-style is pushed again with a fixed version. I have\ntested jpeg, tiff export with a style. All seems fine. Can you review now?\nThanks.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Le 27/12/2012 01:22, hanatos a \u00e9crit :\n\nre: compilation: you probably don't have libsdl, so the viewer isn't\ncompiled at all for you. no big deal, was a 5-char patch :)\n\nHum, this is really puzzling, I have libsdl, and looks like I have\neverything except inotify and still I build without problem:\n<<<<<\n-- mutliarch triplet detected: x86_64-linux-gnu\n-- Determining version\n-- checking for module 'Gettext'\n--   package 'Gettext' not found\n-- Found Gettext\n-- Found msgfmt to convert language file. Translation enabled\n-- Found xsltproc\n-- Found Glib\n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found suitable\nversion \"2.8.0\", required is \"2.6\")\n-- Could NOT find INOTIFY (missing:  INOTIFY_INCLUDE_DIR)\n-- Found GIO\n-- Found Cairo\n-- Found GDK-PixBuf\n-- Found LibXml2: /usr/lib/x86_64-linux-gnu/libxml2.so (found version\n\"2.8.0\")\n-- checking for module 'Gettext'\n--   package 'Gettext' not found\n-- Internationalization: Enabled\n-- checking for module 'json-glib-1.0'\n--   found json-glib-1.0, version 0.14.2\n-- Found JsonGlib\n-- OpenJPEG version 1.3.0 found. Only 1.5 and newer support reading of\nicc profiles.\n-- Found GraphicsMagick\n-- Checking for -march=native support\n-- checking for one of the modules 'libsoup-2.2;libsoup2'\n-- Map mode: enabled\n-- Installing experimental iop plugins\n-- No saxon XSLT processor found.\nMissing fop\nXslt processor saxon not found. HTML usermanual will be built with xsltproc;\nexpect usermanual with inconsistent screenshot and image dimensions.\nCan NOT build usermanual\n-- Configuring done\n-- Generating done\nCMake Warning:\n  Manually-specified variables were not used by the project:\nINSTALL_IOP_LEGACY\n-- Build files have been written to:\n/home/obry/dev/builds/darktable/x86_64-linux-gnu\nI'm probably missing something, but I fail to see what...\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Le 27/12/2012 23:08, hanatos a \u00e9crit :\n\nnice, your new version doesn't pass style*, so the export() function has\nthe same signature. no more additional patch needed. oh, you need\nlibsdl-dev of course. can you `make darktable-viewer' and it does something?\n\nYes, I have the darktable-viewer executable built! This is puzzling!\n\none more thing:\n- char *style = dt_conf_get_string(\"plugins/lighttable/export/style\");\n- dt_control_export(max_width, max_height, format_index,\n  storage_index, high_quality, style);\n(style will be the result of a g_strdup() here and would need a g_free()).\nand just storing a pointer to that string in the job system is a memory\nleak (as far as i can tell it's not cleaned up after the job finishes..\nand even if it was, it would be messy because it's unclear how it was\nallocated. statically? on the stack? g_malloc?). again, i'd just store\nthe same char[128] as you do on the params on the job as well. it's a\nmultithreaded system with a job queue, the pointer might not even be\nvalid any more by the time the job starts execution.\n\nAll fixed, new branch pushed.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Ok, nice to see this merged now :)\n. Slight modification, since we have a button \"select all\" which select all the iop and close the dialog the iop are now not selected by default. Anyway all this needs discussion...\n. Yep, on fire :)\nYes it is currently only for the filmstrip, will add it to lighttable no problem.\n. Sure, let's start with this one which is very annoying. We can revert when the upstream bug is fixed, but before this gets to every distribution...\n. Looks like there is 3 of them... 2 remaining, let me have a look!\n. Ok, new branch push fixing all issues in Darktable. Note that I have taken the opportunity to factorize out the code.\nOk to merge?\n. Yes, a loop over, probably what SQLite was doing. I don't have that many images on my Darktable, can you do the testing on your side?\n. Good to hear that! Thanks for merging.\n. Now support for partial paste and also use accel as discussed on the mailing-list.\n. Well esc key like all dialog. But I think Jeremy has a point when he says that the dialog should have /select all/select none/validate/ buttons. No need for the current /copy all/ (and close) has we now have the full copy back, so this little optimization is not worth it I would say. I'll propose a new dialog soon.\n. Ok new dialog in place. Feel free to review and merge. I think this version will please more people :)\n. Boucman, I don't really understand your point. I have added no GUI stuff in common/style., right? I'm calling an action from common/style to display a GUI which is in libs/styles.c. What do you propose then? Should most of common/style. be moved in gui/style.* for example?\n. Ok, no more action on my part for this patch. Feel free to merge if it looks correct. Thanks.\n. At this point, and after the discussion I think this should be merged. I'll do that in the coming days if there is no strong objections.\n. Closing as now merged with an additional message when no images are selected.\n. I need to rebase against master I suppose...\n. Well this patch is to get consistency with the buttons. I'm ok to change /copy/copy all/ to the inverse /copy \"parts\"/copy/ but I think it should be part of another commit and needs discussion first as we have already done changes in both directions :)\n. If there is no hard objection I'll merge this branch. It is really going in the right direction.\n. Ok, this new patch should be better as it does not use hard coded width but ellipsization instead. I have taken the opportunity to share some code and I have removed some hard coded width.\nPlease comment and merge if ok. Thanks.\n. Ok, will fix the \"create preset\" not updating the string, this is definitely a usability issue.\n. Yes I agree, this should be closed.\n. Good to hear but no one ever said something about the proposal made quite some time ago! So who are those numerous people? What is the cons for this? How can we improve that? Note that this feature has zero impact if you have no Lightroom .xmp around... Let's discuss this.\n. I'm not sure what is supposed to do. Can you clarify what is changed? I have applied this patch and at the GUI point of view I do not see changes.\nWhat are #9151 and #9143 numbers? I do not see them in Redmine.\n. Sure. Richard said on the mailing-list that he was working on an updated version IIRC. Richard?\n. I would only add a single button to trigger the display of decorations\nand not one button for each kind (stars/color labels...).\nI agree that the shapes were fine before.\nI would add this single button at the bottom/right. In the darkroom we\nhave a button there to display or not the clipped highlights/shadows,\nlooks like a good place to add this button to display the decorations.\nThoughts?\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. > The file type in the background should be removed - the information is available in \"Image information\"\nNo please. Looking on the side to see if we are on a JPG or NEF or whatever is distracting.\n\nThe toggles should be moved to the \"Preferences\"\n\nI don't agree, this is multiple clicks instead of one.\n. On Lightroom these are always visible, so I expect to have them visible. But let's say most of the time as at some point these are not really useful and the big difference is that Lr does not put the stars over the image. So in Dt I really do expect to hide those decorations.\nWhat about my proposal to have a button on the bottom as done in darkroom for the highlight/shadow? These seems quite similar in usage, no?\n. get_lr_data is run once.\nthen sync_dt must be run multiple time generally after an import to feed the Dt database with the rating, geo-tagging, colors... for the new images.\nThat's why I have put that into tools. Just helper scripts that can be useful.\nI have updated the README to make this clearer.\n. Back to this, it is probably not needed after all, I just saw that the rating and GPS-tagging are in the .xmp... For some reasons I did miss last time I looked :(\nSo this process will be moved into lightroom.c and imported at the same time tags are imported.\n. Yes, I'm closing this PR.\n. I would avoid the trashbin as it will clutter the screen for not much. Moving outside the map seems a comprehensible gesture to say \"please remove this image from the map\".\n. Ok, question how to darw something on the map? Remember, I'm no expert on Gtk nor cairo....\n. I've been looking at this, I have zero idea about the way to have a drop signals on the filmstrip from the map view and even less (yes less than zero :) about a way to draw on the map. If a Gtk expert can shed some light... or otherwise this ticket can be closed.\n. I'm waiting for feedback on how to add a DnD event on the filmstrip from the map view.\nAnd yes this is fully separate of the work done on the undo.\n. I'd like to have this in 1.2, can someone help me finding the best way to attach a dnd action on the filmstrip from the map view?\n. Thanks for the info. It helped! New patch proposed which only remove an image from the map when dropped into the filmstrip.\nIf you agree, please merge this one before the map-undo branch as I need to add undo for removed images.\n. I can also handle the merge! Just let me know.\n. @houz, thanks for your comments! Looks like some of your comments have been lost... Anyway, I think that I have fixed all issues in my new patch. As you can see I'm no expert in Gtk :)\n. New version with the support for undo after removing from the map.\nAgain I think it is ready for integration after all the reviews.\nWill commit tomorrow if there is no objection.\n. More generic I understand. But \"global undo\" I'm not sure. We don't want to be able to undo a move on the map when we are back into the develop or lighttable module. It seems to me that the undo should be per module, no?\n. Jose,\n\nIn a first moment I thought that having the undo per view would the best,\nbut I have doubts when you can do lighttable operations in darkroom (stars,\ncolor labels,...)\n\nHum... good point! I'll create something more generic then.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Henrik,\nPLEASE, if we introduce UNDO to darktable follow the command pattern!!!\nSure.\nOne question, do we want unlimited undo?\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. New patchset proposed. This implements an unlimited undo generic module. The undo list is (for now) cleared when switching module. The map undo is now based on this undo module. Please review. Thanks.\n. Fix now pushed.\n. For the thread safety, should I reuse a mutex already present in darktable (to ensure mutual exclusion with other parts of darktable) or create a new one? I'm not sure as I don't really know what kind of threading model is used by dt yet...\n. @hanatos, I was ok when you said the the GList object should be static to not be visible outside. Now you propose to expose the internal state of the uno module to the whole darktable code making this global! I don't see the point of breaking so badly the encapsulation. What do we gain?\nI agree that the current API is polluting the namespace, will prefix the routine with dt_undo_.\n. Le 10/02/2013 21:35, hanatos a \u00e9crit :\n\noops. sorry for the big font. didn't know i was using official markup.\nno offense intended.. :(\n\nNo problem. I'll try to come with a darktable oriented design then. I\nhope you don't mind me asking this and that about the design, I'm just\ntrying to understand and to be sure we are considering the pro and cons.\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Please review. The undo struct moved in darktable struct and mutex added.\n. BTW, not sure we want to keep the filter now that we can have multiple undo objects.\n. Ok, noted I'll propose a fix in a moment. Thanks.\n. All comments taken into account.\n. Thanks, will merge later today if there is objection then.\n. merged. thanks for all comments.\n. I have renamed unum to update_num.\nFor the \"long int\" I agree with you, but this is how the \"num\" is passed into the data structure at the moment. I'll change that to int32_t as we are speaking about num for a specific image, I doubt that we will have more than int32_t! But again I cannot change that in my code only I need to change that in many places.\nI'll propose a patch on top of mine to fix that.\n. G_TYPE_INT why not, but well the point is that we use a Gtk list store and an object here is an address.\nThat is list->data is an address so \"long int\" was used as the same size of an address in Linux (32 and 64 bits). Not sure for other architecture. See 0540cd7 which seems a bit clearer in this respect.\n. A little update to make the gui cleaner. I think it is ready for integration. If no objection I'll merge this tomorrow.\n. With this new feature I've been able to upload a Picasa album with 50 pictures and the watermark is indeed always at the same position. Do you think it is still time for v1.2 or the freeze is over?\n. This one is too late for 1.2 as it adds a string.\n. Sure, with the current implementation the position of the watermark depends on the size of the exported image. I export for different target Picasa, home drive at home... So I do not place the watermark on each image but I export with a given style (this is why I have implemented style support in export some time ago). Problem is that since the watermark position depends on the exported image size it is not always in the same position, sometime it even get into the border. Indeed some images maybe exported 6000x4000 in size, and some cropped to 3000x2000 or even square 3000x3000.\nMy patch \"fix\" this by computing the x and y offset for the watermark independently of the exported image size. So when I export with a style that adds a watermark the watermark is always at the same position (x, y offset) for all images.\nHope this is clear enough?\nDo you think there is a chance for this to be in 1.2?\n. Not only to avoid it to be placed on the border, without border the watermark is still changing position as computing is based on export image size. So even when there is no border it is needed. If the crop is important the watermark will get close to the border of the image.\n. But in fact more I think about this and more I'm persuaded that the absolute mode should be the default. So removing the new absolute GUI option and not adding a string. The only problem is that this won't be compatible with previous watermark positioning. I'm not sure how easy it would be to compute the new X and Y offsets to make it compatible with previous version...\nDo you think this is a viable solution, should I invest some time into this?\n. Ok, but to make progress it would be nice to know why you are thinking it is totally wrong. I gave counter arguments without saying that relative positioning is totally wrong :)\nSo what's wrong to you?\nWhat should be done?\n. 6000x6000 is \"some\" scale, nothing to do with the actual size of the photo. The offset is a percentage of this.\nI don't understand the second part :(\n\nThis is NOT what a enduser wants to have, undesireable result depending on export resolutions.\n\nBut it is not the case! I have exported the same image with an absolute watermark at 1000x1000, 100x100 and 500x500 and the watermark is always at the same position and is scaled proportionally.\nNote that my patch only apply to the offset which is then projected into the cairo space with the scale set just above the cairo_translate() call. That's why it works as expected.\nDid you test it?\n. Maybe \"absolute\" is not the best label for this new feature... What I meant is that it is independent on the crop and export size.\n. Ok, that was also my feeling that watermarks was broken somehow. So let me do that: I'll remove the absolute GUI and will push to master the new version which to me works fine. I have used this new version to export multiple filmroll without problem.\n. Ok, pushed, the current behavior seems far better for the release.\n. Le 03/03/2013 21:19, hanatos a \u00e9crit :\n\ndidn't test yet, but did you play with the font size? i have a copy of\ndarktable.gtkrc (from /usr/share/darktable) in ~/.config/darktable\n(will be picked up automatically) and increased font size by setting\nfont_name = \"Sans 10\"\nsomewhere on the top. with the default 8 i have the same problems\nfinding stuff you describe.\n\nGood to hear I'm not alone.\n\nthe above will also make the controls\nthemselves larger and thus easier to hit with the mouse.\n\nYes I played with the size, but french labels are longer than the\nenglish ones so with a bigger font some are cut on the right :(\nWould be nice to be able to change the color from gtkrc, but I didn't\nfind a solution hence my pull-request.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Ok, closing this pull-request. I have another one using set name and configurable using gtkrc. Thanks for the feedback.\n. I'd like to merge this into master, ok for 1.2?\n. Done.\n. If there is no objection I'll commit. The implementation was boken anyway (see discussion Henrik here: https://github.com/darktable-org/darktable/pull/188).\nSo better to start new version 1.2 with an implementation that will be stable and will be the base of new support.\n. Yes I understand. That's what I meant. It is broken and I want to take the opportunity to make this on the right track for 1.2. My previous fix is not that good after all. It is kind of patching something that is lot more broken than I thought.\n. I think we have misunderstanding! That's exactly what this patch propose. I have identified the problem and instead of patching the code which was somewhat hard to maintain I have restarted at the root of the problem and I'm proposing a new implementation. This is the work of a whole week-end not some patching party :)\nSo, I see two solutions at this point:\n1. revert my previous patch and keep this for after 1.2\n   This fix was not quite right because the issue on borders now fixed (commit dc6f548)\n2. install this patch right now as I do feel it to be far better (quite some testing on my side now).\nThe goal of this work is to be able to use a preset with borders and watermark on images in landscape and portrait mode. And yes I can says that the new implementation proposed here has reached this goal as I have tested on 2 series of about 40 pictures comprising pictures in landscape, portrait and cropped in 1:1.\n. I did some more testing with dt 1.1.x, the broken part is because the offset depends on the scaling. This is wrong and it is exactly what my patch here is fixing. Reviewing the code in 1.1.x I see that my proposal is in fact very close to the 1.1.x implementation except that it handles correctly the scaling. All this is clearer in my mind now and my previous attempt to fix this issue was half-backed and misguided by the bug in border now fixed.\nSo I'm confident that this is going in the right direction and it is something we want in 1.2 so I'll merge this will let other building from master some time to test.\nAs I said above I'll only commit the core part and not the GUI one (which support different scaling mode) to respect the string freeze.\n. It won't affect history stack. It just change a little bit the border size for portrait picture.\n. Ok no problem, I'll propose an upgrade path then and move this module to v2.\n. New version with upgrade path from v2 to v3. The new computation has no GUI. We keep the previous way to compute the border. To get the new way just click on the \"reset parameter\" button.\nIf there is no objection I'll merge this tomorrow.\n. Oups closed by mistake :(\n. No, this is just a minor UI fix. But as said above it is not complete as the GUI is not properly refreshed. So it is not ready for merging at this point.\n. Now that I think more about it you were probably confused with 09d3f7b5 which should be reverted after 1.2.\n. And what is the way to fix this? Do you agree that it would be nice to have this feedback (like for all other control in dt)?\n. I found this bug while testing multi-instance and for this I was using a jpeg and denoiseprofile. Indeed it makes no sense to use denoiseprofile on jpeg and I cannot reproduce the crash with a RAW.\nWould it be possible to disable this module for jpeg image? Even when applying a style? Not sure how important and easy to do this is though... feel free to close this ticket.\n. Good catch! Will fix and merge then thanks.\n. Now merged.\n. Ok, fine with me. I'll add another preference for circle masks and I'll merge. Thanks for the feedback.\n. Done.\n. Indeed, I missed this report, it would have save me quite some time :(\n. I think that we a better title it would have been merged since long time. Not really a dead-lock but an obvious bug trying to finalize a not initialized SQL statement!\n. New version ready. This is simpler and I have reused the strings in atrous.c, so no new translations are needed.\n. If there is no objection I'll plan to merge this over the week-end.\n. I just pushed a new version where the arrow should be a bit more visible at all scale level. Yet, this is not so important now that the line does not go into the center of the dest area. It is then clear now what is the source and what is the dest.\nLet me know if this looks better to you.\n. If there is no objection I'll merge this early next week.\n. Le 04/05/2013 20:17, pmjdebruijn a \u00e9crit :\n\nWhile I highly appreciate the effort, this could really complicate\ndarktable-1.2.x maintenance...\nWhich brings us to the question, does this also at least cleanly apply\nto 1.2.x ?\nSplitting up the patch into several subsystems might be a good idea...\n\nOr just don't apply this to 1.2, we have lived with those misspelling\nsince some time we can wait a bit longer :)\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Le 04/05/2013 21:26, pmjdebruijn a \u00e9crit :\n\nThat's not a real solution at all...\n\nThat's why it is far better to avoid all massive changes and to commit\nthose changes by small incremental commit when a developer found them.\nIt is then possible and easier to just cherry pick the\nformatting/spelling commit and the fix commit.\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. If there is no objection I'll merge this soon.\n. merged.\n. No problem, we are all in the same boat :)\n. Ok, since many people are talking about this issue I've just compiled 1.2.1+57~g2342d06 from Git repository's darktable-1.2.x branch.\nAnd I have all the presets active. So I'm still not sure what we are after :( Sadly I won't be able to debug that anyway.\n. I see, it is fixed already, and your patch is just for the version and as Simon as said it is wrong. Let's close this ticket.\n. Looks fine to me. I'll say that this should be merged.\n. I was expecting also glib to support that, but I've looked and found nothing. As I said this code looks good. Let's merge it.\n. 2013/6/28 houz notifications@github.com\n\nI don't like that for several reasons:\n1. ctrl-s is used to save in most applications, so we shouldn't use it for\nsomething completely different.\nSure, what do you propose?\n1. there has been work to do similar things in a more complete way, we\n   should see if that has made some progress.\nNo progress AFAIK, the original proposed patch has even been removed the\nmerged-request at GitHub for lack of\nsupport. The solution was far too complex for something as simple as\nthat... Best is enemy of good!\n\nPascal.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Closed?\nWell seems quite difficult to contribute to dt. Look at the story about this feature. We have had this feature request since months. A proposal was made, it was complex and the dev just left it as it this. Now I come with a simple proposal and you just closed it because ctrl-s is not good (which I agree BTW).\nLet's try a way to make progress.\nI'll reopen this ticket.\nI'd like to have more comments about others and get feedback about the key accel for example.\nFor the global feature, this one is simple (~ 30 lines of code). If someone (and possibly myself) needs a more powerful way to handle that we'll can work around this initial work. Right?\nI think moving step by step is better than nothing. I'm ready to do my load of work (and I think I have demonstrated that), but please let's discuss a bit more.\nThanks.\n. IRC is not easy for me, sorry. Maybe in the mailing-list?\n\nI disagree. We have seen in the past that simple hacks that solve big parts of a problem make people not care\nenough about the real problem to fix it.\n\nWhat the real problem here? I'll continue this on the ml...\n. New version pushed based on discussion on the ml, x is now the key accel.\n. Just pushed a new version. The modification is only to disable the statuses on the filmstrip when on the darkroom module. In this case the statuses are cluttering the view and it is not really useful there to me. Again this is only a proposal, waiting for feedback or the ok to merge. Thanks.\n. It is possible to write the .xmp for cached files in ~/.cache/darktable. I have disabled this as I'm not sure what we can do with this second xmp but it could be a way to backup the edit if the database got corrupted. What do you think?\n. Hum, not a cut&paste error, looking again at the code it is a comment I put while working on this. I'm not sure what happen here. It seems that we are building an URI and now it is based on the cached image. I'm not expert on the DnD stuff to really know the implication of this.\n. Ok, here is a new version, since last time:\n- I have verified that moving a picture (local copy) in the map works fine\n- I have enabled the writing of .xmp for local copies\n- I have disabled removing a file if some modification on the local copy has been made and the original is not online\n- likewise for film roll (cannot delete a film roll if it contains a modified local copy and original not online)\n- The .xmp (if any) are now sync at startup if needed\nAt this point I feel that this needs some external review and testing.\nI think it is in a state ready to be merged.\n. As discussed on IRC. This is merged!\n. Memory leak is trivial and correct. I would have merged it, but I'm not sure for the other part as I'm no expert in this area.\n. Merged.\n. Thanks, merged!\n. I've done that because we had a script to purge missing images but indeed doing that in lua makes more sense I would say. Would be nice to have the first \"official\" lua script in darktable as an example. So yes please go ahead :) Thanks.\n. Ok, so I'll just merge this ticket to add the script into the source code.\n. I think it is still working. I'm using quite a bit the tag. And for the maintenance I can say that it is far easier to maintain the triggers (I've done that in another project quite extensively!). I'll do the maintenance of this stuff if needed anyway.\n. I think we should move forward here. If I'm the only one to see this as a nice enhancement it should be closed otherwise please can someone review and give me the ok to merge? Thanks.\n. Done. Thanks.\n. Strange, this is not what I'm seeing. It is said in the ticket that using 2Gb or 4Gb trigger cache regeneration. I have memory_size set to 2Gb without issue. Moreover the like quoted src/common/mipmap_cache.c:640 is:\nuint32_t max_mem = CLAMPS(dt_conf_get_int(\"cache_memory\"), 100u<<20, 2u<<30);\nWhich is an unsigned 32bit integer so supports number up to 4gb without problem.\n. This is not 64bits just 32bit unsigned. Or I'm missing something?\nAnyway, I have another fix for this and it turns out that there is 2 issues on fixed here and another that seems to be on the preference circuitry. I'm on it.\n. Ok, now the preference setting is also working fine.\nThis pull-request fixes #9550 (http://darktable.org/redmine/issues/9550).\nThe upper limit for the cache size is then now 4gb. For more we will have to change the code to use 64bits integer. I think that this is at least sufficient for even large users (> 250 000 thumbnails). Not that bad.\n. Ok, I see that you have applied part of my patch. Will apply the remaining then. I've just rebased.\n. @hatanos, ok with your code I don't see the issue either. So it means that my testing was somehow wrong yesterday! Thanks for straightening the code!\n. This code seems so wrong that I may be missing something. But testing shows that sorting on tagxtag count gives better output on the tag suggestion dialog.\n. Merging, this has been reported in #9088 with the exact same fix.\n. Thanks!\n. Closing this one. Clean path proposed in #405.\n. Looks invalid to me also. I'll close for now. @mlq, feel free to reopen if we missed something.\n. This comes from a discussion with Ulrich but this is tricky area and it seemed better to me to ask for a review before merging so close from the release.\n. Better to merge this sooner than later. After a new review and some testing all seems working.\n. Since we are in string freeze this (at least tiff support) will have to wait for after the release.\n. Please review, if this looks safe to you we may want to integrate this into master for 1.4. Let me know.\n. Ok, I'll merge this one. Thanks.\n. I've tried to have a patchset readable with small & incremental commits.\n. New version proposed which fixes all issues reported in #9704.\n. Great thanks for testing.\n. Should I go ahead and merge this for rc2? Do we plan an rc2 BTW?\n. Tested and look good to me. Indeed the jumpiness was somewhat annoying. While testing I found one case where the lighttable was not properly layout when changing collection but going with the mouse over the lighttable had refreshed properly. Sadly I was not able to reproduce and propose a scenario...\nAnyway this seems a very nice improvement to me.\n. But after all the drawn masks are not saved with the presets in all modules, so is this really good? I mean the fix here if working should probably be seen as a temporary solution. The proper fix would be to be able to save the masks with the presets and with the styles.\nIs there a consensus about this?\n. Yes some more discussion. I think the proper solution may be to be able to save also the drawn masks with the presets. Not sure if this is easy or even feasible actually. So as I said my patch here is ok and should be merged only if we agreed that having the masks saved with the presets is not desirable.\nI'd like some more feedback.\n. Old and abandoned, closing.. This is not clear to me indeed!\nThe question is: do we want the preset to be only for RAW (vs LDR) or RAW+HDR (vs LDR)?\nIf the later I think my patch does that.\n. Ok, so to start with something what about keeping the current code and adjust the dropdowns to read:\nall formats\nRAW\nothers\n?\nWould that work for you?\n. Works for me. Will do that.\n. Ok, here is a new version which does what we agreed. I'm very tempted to rename the isldr presets table field to format at this stage. What do you think?\n. Sure and there was another instance. I love those typos especially it was for HDR, the only case where I had no images for testing :( Anyway fixed.\n. Ok, will do that then and I'll then merge this for good. Thanks for the review.\n. Merged.\n. Great thanks!\n. What do you mean by this?\n. @boucman I'm not the original author, I'm not sure of the usefulness, don't remember all the details. I propose to close this one in some days if the author does not come here to explain why this is needed.\n. Ok, given the comments here and on the mailing-list it is clear that this is a bad idea and moreover solved on latest and greatest version of lensfun.\n. This looks just fine to me. I think we should merge it sooner than later. Ok?\n. Ok, thanks.\n. Le vendredi 14 mars 2014 \u00e0 16:24 -0700, Gert van der Plas a \u00e9crit :\n\nI've added igv demosiac from rawtherapee to darktable. It out performs\nat high noise levels amaze and ppg. Yielding better resolution on the\nSony NEX-C3 and other cameras. At low noise levels zipper-artifacts\nmay occur. I've added an hidden example demosaic code called stagger\nbut which is invisible from the gui. \nAt some point it will be replaced by better code.\n\nI've tested it but found no difference between this algo and the\ncurrently support Amaze. Switching from Amaze to IGV give me the very\nsame image, at least close enough to not see any change on screen.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Le samedi 15 mars 2014 \u00e0 12:13 -0700, pmjdebruijn a \u00e9crit :\n\nHaving an online comparison gallery (PPG vs AMaZE vs IGV) would be\nrather nice to evaluate the benefit in different use-cases.\nBut more generally speaking...\nKeep in mind that once we add another demosaicing algo, we can't\neasily drop it again (since that would break history stacks), so every\nadded algo adds an eternal maintenance burden.\nWe already have this problem with AMaZE, which isn't that much better\nthan PPG,\n\nTo me AMaZE gives far better results on my side.\n\nis silly slow due to lack of SSE/OpenMP optimization IIRC, and isn't\nbeing maintained (no code resyncs with RawTherapee, since the original\ncontributor/porter isn't around anymore).\n\nRight.\n\nFor the future I think any demosaicing algo we add should at the very\nleast provide in these areas:\n\nI agree with all the points.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Looks good to me. I'm all for it to be integrated.\n. Makes sense in general. Indeed 640x480 looks sufficient for thumbnails. I'll let the core developers comment on this.\nI have one question. Does this means that the current cache will be invalidated and recompute?\nI asked this because many have large collections (I'm one of them) and recomputing the cache is a pain since it happens only for \"visible\" images. So if the cache is indeed invalidated and need to be recreated for all images under dt I'd like to see a way to let dt recreate the whole cache for all images without any user interaction. So even if this needs 2h or more it won't be a big problem.\n. Closed.\n. Done!\n. New version proposed. Ok to merge?\n. @LebedevRI I had not noticed this ticket! I see that you tried also to have the rotation done using the center of the svg, right? I tried that but did no succeed, after all rotating from the top-left corner is ok for my usage and easy to use.\n. Found a way to rotate from svg center! Thanks, now pushed.\n. Good catch! I have fixed the rotation.\n. Bug n\u00b01: this is a feature, we rotate from center. It would be terrible is by rotating the watermark will move around. In your example, say you start rotating 1\u00b0 by 1\u00b0, the watermark will move on the right a little bit each time.\n. And please, avoid \"big\", a bug is a bug... nothing crash!\n. For n\u00b02 I suppose you are using a landscape picture? This is the same feature as n\u00b01. We rotate in-pace and do not rescale or change position. This also ensure that a watermark wiil keep the same size over multiple images with different sizes. A feature we want to keep otherwise a watermark is not usable with a style.\n. Ok, that's what I said above. No resize. Set the scale on \"smaller border\" and will stay inside the image. Again this is very important to not resize here, we want the watermark to keep it's size.\n. Merged.\n. The real issue is that we also control the casing.\n. Indeed, good catch! Now fixed.\n. Not sure what you mean. Which icons? I have attached the before/after screenshot, I only have the label casing changed:\n\n\n. And that was only those few buttons with the icons. For uniformity probably better without.\n. After some more use it is really better with this patch. Merging.\n. > 1. Implement magic button that will (semi-manually) recover masks created with DT version between \n\n0a3a557 and this pr merge commit.\n\nI'm not sure about 3, dt from master is not stable and not recommended for daily use and we do not guarantee that the features there will be preserved as-is or not. So I won't bother about this recover path.\n. Merged! Thanks.\n. Thanks!\n. For some reasons the cache are not upward compatible. I have been tracing this down, but it seems related to the new alignment and the dead images static buffer.\nWith I read old mipmap I have a clean output (lot of debug output added here), but while writing I have: \n[mipmap_cache] serialization to `/home/obry/.cache/darktable/mipmaps-62d87cbcad56aa2b4a21cd680776714d70e93ef6' failed!\nAnd this is because the following code in _write_buffer():\nconst int32_t length = compressed_buffer_size(d->compression_type, dsc->width, dsc->height);\nprintf (\"  length %d (%d x %d)\\n\", length, dsc->width, dsc->height);\nprints:\nlength -92419976 (-1536119632 x 2147396266)\nBut if you rebuild the cache with current master there is no more issue.\nI'm still not sure what is causing this, but it looks like the mipmap cache needs to be invalidated. Or maybe there is a bigger issue...\n. But I agree I do not see in the code where the mipmap cache could be invalidated with recent changes! Really puzzling!\n. Not needed after all, see resolution of the mipmap issue in eea1989.\n. merged!\n. The name of the local copies are img--.. the base image is imgid and this is what is group_id is actually. So for a duplicate the actual base image is found by using the group_id otherwise there is a message \"image blabla is not available\". I just found this out as it is the first time I try to work away from home on local copies with duplicates.\n. This fix also avoid copying multiple time the same RAW under different name when there is duplicate images.\n. Ok, what is the way to find the master image for a duplicate?\n. Let's N be the image id we are handling, would something be ok:\nselect i1.id from film_rolls,images i1, images i2 where film_rolls.id=i1.film_id and i2.id= and i1.group_id=i2.group_id and i1.version=0;\n?\n. You mean there is no 'master' for a group?\nFor a duplicate we do have a single picture (which I call master, maybe not the right name) and multiple .xmp.\n. This imgid into the name of the local-copy was for debugging purpose. But is causing problem as seen here, so I'll propose a new patch which removes this id from the cached file.\n. New patch proposed. Should be cleaner and don't mess with group_id.\n. Yes, indeed changing the filename we will fail to remove the cached files. That's an issue. But the current situation is not very better as we also copy the cache for every \"duplicate\" but only remove one.\nThat is, for a picture and a single duplicate we have one image and two xmp. The action local cache on them will copy into the cache 2 copies of the image. Working with them off-line will create two xmp into the local cache.\nResync the local cache when online will remove a single image and a single xmp.\nMy patch above fixes that.\nFor the name changing we have 2 solutions:\n- tell users to remove all local cache when updating to 1.6\n- add some code to do that (not sure this is safe as it must be done once)!\n- any other idea?\n. Ok, I'll propose another version ASAP. We really want to fix that for the release.\nMy idea is to use the older name if the cache file already exists and the new one otherwise. This should give a smooth transition to the new scheme supporting duplicate. How does that sounds?\n. I've just pushed a new patch. I've tested it (especially the upward compatibility path when using the old naming scheme and moving to the new one) quite a bit.\n. Le dimanche 26 octobre 2014 \u00e0 09:20 -0700, Michel Leblond a \u00e9crit :\n\n@simonspa It was a great pleasure to contribute to the French\ntranslation of the user manual for that open source software ! I will\ncontinue this contribution.\n\nGreat indeed! You've made a huge amount of work. Congrats!\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Le dimanche 09 novembre 2014 \u00e0 07:50 -0800, Michel Leblond a \u00e9crit :\n\nMany thanks Ulrich !\n\nThanks a lot for the hard work Michel!\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. This does not work properly. It is a quite tricky area, but first we probably want to settle on what to do exactly.\nLet's try to see the different cases.\nWe have 2 images Is (source), Id (dest) with a module m having possibly multiple instances. m, m1, m2. (m is the first instance, so no number). We want to copy from Is to Id.\n1. Is has m and Id too. We copy m from Is and paste into Id, we end-up (expect) with module m into Id.\n   Is / m --(m)--> Id / m = Id / m\n   => OK\n2. Same but Id does not have m already used\n   Is / m --(m)--> Id = Id / m\n   => OK\n3. Is has 2 instances, we copy m from Is\n   Is / m m1 --(m)--> Id / m = Id / m\n   => OK\n4. Is has 2 instances, we copy m1 from Is\n   Is / m m1 --(m1)--> Id / m = Id / m m1\n   => NOK with your patch we get Id / m1 m1 (so one is renamed m1 even if the actual iop correspond to m).\n5. We copy m and m1\n   Is / m m1 --(m, m1)--> Id / m = Id / m m1\n   => NOK, we get Id / m1 m m1\n6. We copy m and m1, Id has no module activated\n   Is / m m1 --(m, m1)--> Id = Id / m m1\n   OK\nSo, on the 6 cases above we still have 2 buggy cases.\n. I also like this idea!\n2014-11-10 15:48 GMT+01:00 Boucman notifications@github.com:\n\n@parafin https://github.com/parafin if I understand your idea, you\ngeneralize the previous way of handling things (replace old parameters) by\nsaying that all the instances of an IOP should be seen as one chunk, and\nyou replace the whole chunk with the new chunks, including MI names, number\nof MI and of course MI parameters...\nI like that, it's pretty simple to explain and understand...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/732#issuecomment-62393606\n.\n\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. What the status about this? Is there some progress from AlicVB? Should this be closed? Does it still apply to master after all the changes since then?\n. post 1.6 of course!\n. Not really as when you copy/paste the semantics can be either replace or append. But when applying a style at the export stage the \"only\" interesting semantic is append to me. This is closer to a bug fix than a new feature BTW. I'm the author of the apply style during export feature, don't remember and did not check but I suppose this has been implemented before the support for multiple instances. That's explain the current behavior as at the time there was no easy way to support appending a style. Now it is possible and this new behavior is certainly what I had in mind at the time.\n. Ok, to keep the previous behavior we need a way to append or replace.\n. New version with control for replacing (default as before) or appending to the history pushed.\n. I see, there is support for legacy_params added by Tobias recently.\n. No, this is not possible as those params must match the definition in dt_imageio_module_data_t struc declared in src/common/imageio_module.h.\n. Just pushed a new version that update the presets properly.\n. Any more comments on this?\n. Indeed! I was pretty sure to have pushed a second implementation correcting this. Will do in a moment.\n. New implementation now pushed.\n. Do you think this is ready to merge? Any more comments?\n. Ok, I think I got this part correctly now. Hope all is clean now :)\n. Ok, thanks again for your throughout review. At this stage I'll merge soon as I need this for the print-module.\n. Just merged, thanks again!\n. Tested and look fine to me. I cannot reproduce the jumping anymore. I'll merge if there is no objection.\n. So, hanatos if I read correctly your message it should be merged, right?\n. ok merged then.\n. Thanks for all the comments. I have integrated all of them and pushed a new version.\n. Now merged. Thanks for looking at this. I'll continue working on the print-module after.\n. Le dimanche 04 janvier 2015 \u00e0 08:23 -0800, Boucman a \u00e9crit :\n\nok, @hanatos meant to merge master into print-module, not the other\nway round\nI have reverted the merge and rebased the print-module branch,\nhopefully I got it right.\nfeel free to reopen the PR and continue discussion there\n\nAh! ok, sorry :( Thanks for reverting.\n\nPascal Obry /  Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\n  http://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n. Note that to my defense the message said \"merge in master\" and I thought it was fine because one can always disable this module.\nAnyway, I don't see a way to reopen this PR?\n. This is a good candidate for dt 1.6.x\n. closing, will open a new one with latest code Gtk3 + PDF\n. would be strange that identical definitions are there for real... But at least this would deserve a comment. Let me separate this from the slider update.\n. ok. fine then.\n. I have adjusted the commit as it depended on the commit not merged from this PR.\n. Should be ok now.\n. Another attempt at this. This time I have kept the native GtkDialog which looks nice after all.\n. Rebased on master. I'll merge very soon as it is painful to handle merge conflicts.\n. Now merged. I'm sure we can still improve all this, but it is getting better.\n. Indeed didn't noticed, but it looks more readable now to me. No?\n. Which version of Gtk?\nTo be sure we are seeing the same thing. Here is a copy of my tool-tips. Looks nice no? Do you have the same on your side?\nThe preset menu is the same color for the background/foreground. Cannot take a snapshot while it is opened.\n\n. Which Gtk version?\nI don't have this display at all. As I said I have the same display for preset than for tool-tip.\nI'll find a way to fix that but please do not revert! We are making progress this is just a \"small\" side effect if you compare the unusable dialogs we had before.\n. @BTW, you're sure you don't have any local CSS in ~/.config/darktable/darktable.css?\n. For me in fact I'm now following the color as set for the theme at the top of our CSS file:\n@define-color tooltip_bg_color #000000;\n@define-color tooltip_fg_color #ffffff;\nAnd this has not changed since the first version.\n. Debian sid, gtk+-3.14.5 ... same version here. I'll check how to override the tool-tip CSS. \n. should be fixed. let me know.\n. Good to hear!\nFor the tooltip I have introduced a rule to make it easy to change them. I'm not sseing the white double outline, so I suppose that's again some missing CSS directives in .tooltip.\n. I see, settings is a GtkDialog so now it is using the native look. Is that not acceptable? After all it does not look like before but I find the layout quite nice. If not it should be possible to give it a flat look as it has a special name, but this will make the CSS heavier....\n. ok, will do the necessary changes to get back to a flat look.\nNote that I agree for the different bg colors.The buttons looks ok to me.\n. How does it looks to you know?\n. The button should be flat now. I agree that it would have probably be better to not specialized the GtkDialog, I tried (hard) but felt to have something usable. I may try again at some point...\n. Ok, at this point let's face it... I failed :( I'll revert.\n. Reverted.\n. Jo was faster than me and fixed this with a very similar patch, see 70dd638cc47b587b5826df0d8754b7821c2dc527.\nSo closing.\n. would be nice to have some timing for the speed up if possible.\n. Ok, not lot faster but those little CPU cycles saved are always welcomed :)\n. better to merge sooner than later to know if there is regressions :)\n. Just tested and one comment. In the list I have many labels which are stroked. Is that because they are not accessible (external drive)? I find this difficult to read, maybe using a grey for the text color will be better?\n. I've tested this new version, I'm not convinced by the cross at the start of each text. I find it heavy, maybe smaller and with one more space between the cross and the text. I think this will make it clearer? Another option is to use a different text color? But this is not what dt does today as all text has the same color. To be discussed.\n. Thanks, to me it is better this way and we can always adjust the color of off-line collection with a CSS.\nI have a question though, when I enter say \"%studio%\" and hit enter I do get only the photos from the matching collection in the lightable. But I would also have expected the list in the collection module to be restricted to the matching ones. No?\n. Ping?\n. Also would be nice to rebase to continue testing against git master.\n. Working fine on my side and I like the idea.\nAnd I have no comment on the implementation which is simple and looks good to me.\n. I think we should merge this. If there is no objection I'll do in the coming days.\n. @AlicVB, what would be nice is to darken everything and just display the picture. do you think this is possible with CSS?\n. Perfect! Thanks, I have merged.\n. I did not know, better to use standard keys as long it is configurable anyway.\n. New version using [ and ] pushed.\n. merged! thanks.\n. I can also report that the color-management for printer profile is working. Tested today.\n. Thanks for all the review! Will merge now. I'm now ready for bug fixes from the field :)\n. I have done a standard:\n$ git merge --log print-module\n. new version pushed.\n. Ok, le me know if there is anything I need to fix or need to do for this to be merged. Thanks.\n. Note also that one option could be to allow upscaling only for the print module.\n. Thanks a lot Tobias!\n. New patch proposed. The mouse_over_id is set to -1 before calling dt_control_set_mouse_over_id.\n. I've merged it. Should be ok in v2.\n. If \"Bug introduced with arrows support.\" is referring to #888 I think it would be better to merge both patches. All this is not yet merged, so better avoiding merging a bug and fixing it just after!\n. No difference as in fact there is no more IO involved, just reversed check.\n. Also, there is loose just wins in this. No slow-down and potential huge speed up by using the cached images on SSD or standard drive instead of slow remote drives like NAS.\n. Yes a review would be nice.\n. @pedrocr : Sorry I disagre, dt does not support moving around images outside of it's interface. It can be blamed if people insist on playing bad trick with it. Do you have a proposal to avoid such situation?\n. @pedrocr, I see but this is actually fixed by this patch that's why I did not really understand the concern about this issue. Indeed as we now first look for the local copy, the last check is done for the original image and so the error message properly reference it.\n. Ok, let's review it and merge it ok.\n. I like this new sorting.\n. This fixes an issue discussed on the mailing-list.\n. You can see that the history is not continuous by running:\nsqlite> select imgid,count(num),max(num) from history group by imgid;\n. Even better a new version with code refactoring to avoid duplicated code.\n. Ok, I understand. But don't we have something to do if the history stack has hole? I mean this will happen for every users with hole in the history.\nI've looked at a way to have an SQL command to remove hole, but it seems that this is impossible with SQLite which is missing some commands like row_number() and dense_rank() and more over it does not support \"\"OVER(partition by ...)\".\nDo you see a solution to fix that?\n. Any news? Or should this be closed?\n. Tested these last days, and fixing a bug. Will merge. \n. @houz, ok I look at this.\nFor the first point I'm not sure we have a problem since we are looking for the top operation with the higher num. Won't that work with multi-instance?\n. @houz, exactly my thinking, not sure why I did that :) Maybe because with the old bug some random history item were selected and I was highly confused! Anyway I have prepared a new branch this morning. I create a pull request in a moment. Please review. Thanks.\n. Maybe a missing entry in the file to translate. What is the untranslatable text?\n. Thanks for the review. Will do and merge.\n. I agree, I don't see the need for dealing with history stack in this case.\n. So is it better? Also you'll need to rebase this pull-request.\n. This is not the proper fixes, on Gtk 3.16 it makes the button with 2 different colors.\n. Can you send a screen shot to see exactly which area is transparent. I suppose we want to apply your fix only to some widgets in the GtkDialog only.\n. I  have just pushed a version with fix for the buttons. closing.\n. Ok, will fix the points raised. Thanks for the review.\n. New version pushed.\n. Indeed, not quit ready :)\n. > I really do not like using dt_conf_get_* ()/dt_conf_get_set_*() there.\n\nAlso, you need to add set default values for those new dt_iop_watermark_params_t fields in init(), \nand just use those in gui_init().\n\nBut this is done to keep record of the default font/color the user as selected as there is good chance that these values be reused for other images. Or is there another mean for that I'm missing?\n. Merged! Thanks.\n. Just pushed a new version which should be really asynchronous.\n. New version pushed with fixes for both reported memory leak.\n. The visual feedback was missing before, so a separate issue. I'll open a redmine ticket for this.\n. Ok to merge at this point?\n. Thanks Roman. Merged.\n. cupsEnumDest() was added in 1.6, current CUPS version is 1.7. Your version is quite old, can you upgrade?\n. I did not force the upgrade, I was asking!\nOk, so if no upgrade possible I'll see if a too old CUPS version present we can fold back to standard (non async) code.\n. Compilation issue with old CUPS should now be fixed.\n. Ready to be merged.\n. Do you have figures to share about the speed-up?\n. Not sure this is useful. You can always strore your first curve into a preset to get it back, wouldn't that work? Alternatively a better long term solution would be to support undo for the darkroom.\n. Indeed s/now/not/. Will fix and merge. Thanks for the review.\n. It is not the fact that it looks nicer just that it let more space to the UI. And I'm just asking a way to get them. My patch let's the default to be no overlay scroolbar but users can get the overlay using the environment variable.\nAnd no the overlay are ok to me, I've probably taken the habit of them :)\n. Thanks :)\n. @pedrocr: but if I'm not mistaken this reduce the size of the image by using a line on top? Right? I'm not really fond of that either if it is the case. I think having it over but only if a preference or key is pressed will be better. Thoughts?\n. @pedrocr do you still want to work on this or is the latest metadata work is sufficient?\n. Ok, you'll need to fix conflicts then.\n. Should we try to revive this or close this PR? For the record I like the original idea.... I'll close this for now. Feel free to reopen if something is to be done about this PR.. I'm using 300 by default and it is indeed ok with the English text but not with the French translation. And French is probably not the most verbose language.\n. @houz, I can work on this. Let me know if you have not started.\n. Grid added, this is now fixed. Thanks for the tip!\n. I'd vote for:\n\nOur per-camera basecurves are broken but are the best we have right now. We'll keep accepting new ones with minimal quality testing and will very likely rework them in the future.\n. Is that still needed? If so, can this be rebased and retested on current master? Thanks.\n\nOtherwise let me know and I'll close this PR. Thanks.. Merged manually fixing the conflicts. Tested and working as expected. Thanks.. This idea behind the icon is that rawprepare is about setting a black/white dot. The icon has a black dot inside a white dot.\nI have added the png.\n. I mean (point not dot :) that the rawprepare iop is about setting the black/white point. So the icon has a white and black dot/point. This is the meaning. I found it better than no icon at all. What do you think?\n. Ok, will merge. Thanks.\n. Indeed most of the time you need to zoom, that's a bit like for the mask. It is sometime difficult to setup properly without zooming in the right area.\nFor the information this is the way \"hint\" messages are displayed in darktable.\nAnd yes blending can give strange result has you are moving part of the image depending on the channel selected.\nThanks for the comments!\n. New version pushed without all commits to fix the iop. This should make the reviewer job easier.\n. Just rebased to clear conflics (with VNG OpenCL support) on master. \n. New version with all modifications (hope I did not forget one :) discussed on IRC. That is:\n- use float and not double\n- no more serialization code, just use a static array as in spots.c\n- remove some part of code not used\n- remove one-liner cairo routines\n- remove javadoc style comments\nAdded:\n- allow max 100 nodes, stop when limit reached\n- display number of nodes/warps\nThis new implementation is 15k smaller than the original one :)\n. Fixed.\n. Hum... This is a bug I have introduced in my reworked version as zoom in and out was working in the initial implementation. I've justed tested again with the original code and all is fine.\nAnd yes this does work (actually the first implementation) as I have been using it :)\nI need to review the recent changes...\n. Yes, you've already said that to me and I agree. I'll do that for my next push here.\n. Just pushed a new version with initial commit from Marcello and then my modifications. These version is fixed and works as expected.\n. Hanatos and Roman are ok for merging after review. Tobias, we'd like your review before merging. If ok, let me know.\n. Ok, sorry Roman. That's what I meant. We just need another reviewer.\n. If there is no more objection I'll merge this at the end of the week-end.\n. Again some more testing an a minor issue fixed.\n. Thanks Roman. I'll try to fix all those. Since I'm not building with clang I cannot guarantee that it will build on clang when merging. I hope a good will with a clang compiler will help :)\n. clang issue should be fixed. easy, all in the same code.\n. complex is C99 standard and very handy for the computation in liquify. this has been discussed in IRC. the code will get messy without it.\n. BTW, what is the procedure to build using clang?\n. Liquify does use interpolation.c. It just redefine two small routines that are static in interpolation.c (bicubic and lanczos).\n. For the other part in apply_global_distortion_map_cl() it follows the same principle as in lenc.c and clipping.c.\n. Ok, not sure I follow :) I've asked Ulrich to have a look and will wait for his feedback before merging.\n. I've discussed this with Ulrich. The current implementation is fine. Apart from an unused routine that Ulrich spotted in liquify.cl all is ok. So I've fixed this and will now merge this PR!\n. Never run this... Will fix.\n. @LebedevRI should be fixed. Thanks.\n. Nice to see this project moving forward! One general comment, what are you supporting? I mean what are the Gtk libraries used? Do you support gphoto? As darktable is uslng lot of external libraries it would be nice to know what is the current scope for this patch.\n. New version fixed as discussed above.\n. Fixed.\n. Outch!!! The only solution I see is to add a signal when a module is destroyed and to invalidate all undo/redo data. Will come to discuss this in IRC. Maybe tomorrow.\nThanks for the testing Roman!\n. This latest version handles the multi-instance.\n. @LebedevRI : you had made a quite comment on IRC about the creation of the module. Can you elaborate on this? Thanks.\n. I've just rebase this PR. I have also removed the types from undo.h so that actual undo/redo data manipulated are actually only known by the module using them.\nPlease review. \n. I have just fixed a case were history with default parameters was removed.\n. Ok fixed. Thanks Roman.\n. Should I merge it then?\n. So given latest comment I plan to merge this later today. Thanks all!\n. Done.\n. Any comment on this one? Quite simple. I've tagged it bug/enhancement because it is somewhat a bug (not obeying the no-metadata flag) and an enhancement because it let see the picture zoom==1 without metadata overlay.\n. Fine with me to activate on the whole area if everyone agree.\n. merged.\n. The metadata appears when we are on the top half of the image. I did not take the whole image otherwise there is no way to remove the metadata. On my case I do not have borders around the image. And so there is no event between \"I'm in the image\" and \"I'm out of the image\". As soon as I'm outside and not anymore on the image area.\nAnyway, let's see how this works.\n. @pedrocr : no in this case you do not get an event when going out with a certain speed (and no need to go fast) and so the metadata stays displayed.\n. @pedrocr: I found a way to expose on whole image but I wont' commit because having half top active only means that you can put your mouse on the top part and use the mouse-wheel to move to next/previous picture with the metadata or move to the bottom part and use the mouse-wheel to go next/previous without the  metadata which avoid moving the mouse outside the image each time to avoid the metadata. All in all I do prefer as it is today.\n. Yes, closed as I have committed from my local tree with a very slight modification. \n. merged.\n. Works great! Just a minor issue. The module is too large and does not fit into the right panel. I'll add a link with a picture asap...\n. Here it is: https://drive.google.com/file/d/0B_w_CWtzkwW0S3c0OHp3blptSFU/view?usp=sharing\n. Looks very good now! The GUI is clean and it works fine. I would merge it soon for a wider testing audience.\n. This patch has been tested with more than 20 captures in a RAW without lock.\n. It helps, but not sufficient! After 50 captures I had the locking again :(\n. With this patch, after 100 captures no lock and no other issue found.\n. Indeed! Really strange... I'll keep an eye open on this. I still do not understand why it locks this way.\n. merged.\n. After discussion on IRC this looks ok and there was no objection. Will merge.\n. Looking at the code I suppose the int was really intended here. I think the real fix is to cast the float to int.\n. But at the same time\n\n```\n  for (int i ...)\nif(isnan(yy)) break; // that means we have to skip the end of the border path\n  i = yy - 1;\n```\n\nLooks strange if yy is a float!\n. Nice and working fine to me. The UI looks ok, I would probably put less space between the lines operator and value, but that's a very minor point.\n. Ok, lot better now as the masks are properly distorted. Will consider merging that after some more testing.\n. First of all great to see this. I have just tested it and found this quite nice, a very good idea filling a missing feature!\nNot sure for caption but looks ok to me.\nI would certainly put the duplicate module under the history. I don't think it is ok to separate the history and snapshot as both libs are really to be used together (comparing images at different stage).\nIn the UI side I would put some space horizontally between the thumb the caption and the number. BTW, is the number bringing any useful information here? No strong opinion but I would not put it here. Instead of the number I would put a small trash to remove the duplicate.\n. Also I would not display the stars on the selected thumb. Small, difficult to read and cannot be changed... So not really useful to me.\n. The 'virgin' duplicate creation does not even have the base-curve not the sharpen module. Is that expected for RAW image? That's not the way it works from the lighttable and so found this a bit misleading.\n. @AlicVB Thanks, I have merged this and ported to recent darktable API for this lib to compile. A very nice addition for 2.6.. I have just tested this PR and it indeed fixes #10928 and #10963. Should be merged.\n. @AlicVB: do you plan updating? Ot should we close this PR. Thanks.. Should we revisit and update this PR? I'm all for it do be integrated. Thanks.\nOr let me know if you prefer closing this PR.. Too many things to change from this old PR. This will need a full rewrite.. Maybe because liquify is the only module which distort and has OSD at specific location in the image?\n. Indeed, I thought that a more generic solution could be reused later by other IOP, but this is very specific and more probably better to do it in two passes in liquify. Will do that. Thanks both for your feedbacks.\n. @AlicVB: I'm closing as the new PR #1581 does just that and more.. This PR has lot of conflicts. Do you plan to update it or should it be closed?. What the status on this?. Should we close this PR then?. Indeed! Thanks for catching this.\n. @LebedevRI hum... strange it works on my side.\nWhat's your testing procedure?\nHere is what I did:\n- open a picture on darkroom\n- select the orientation module and played with [ and ], the picture is rotated\n- I have selected another iop (crop or exposure)\n- then back to orientation and playing with [ and ] is still working\nThis is the last step that was not working before as nothing happened. Maybe there is a case where this is still not working... So please let me know how to reproduce. Thanks.\n. Really strange I have tested again... all is working fine for me with the scenario you described :(\nI have tested again from current master and I can reproduce the issue. When I build with my proposed path all is working fine on my side.\nI have double/triple checked by removing my install and build directory completely.\n. Really strange indeed! So in your case the local accels are never working. Looks like another issue? Maybe due to the WM used?\n. Ok I tried again and again. No matter how if the orientation iop is open or closed it works for me. I have also tested with landscape and portrait picture, it works for me. I have also tested with picture with orientation already in the history or not and the iop open or closed when entering the darkroom. For me it still works! I'm out of idea.\nWithout my patch it fails most of the time, so this patch definitely makes things far better on my side. Maybe an issue with the Gtk+ version used or the WM? I'm using GNOME Shell with 3.20.2-1.\n. kde may be the explanation here... not sure. if it is not worth on your side and better on mine I'll probably merge this, we will have more testers.\n. Let's merge this to have more feedbacks. I'll try to go to the bottom of this!\n. Any news on this? Have someone tried it?\n. I understand, yet my proposal above is that this subset should be larger as using far less rules, the rules are more generic. Not sure if it is the best solution but at least the CSS looks easier to maintain this way (size of the CSS divided by 4, not that bad :)\n. Closing this as no use for now.. Sounds good!. Same for me, all is fine with current master version.\n. Indeed DRYRUN is better than DO. Changed now.\n. Of course :( My bad, now fixed.\n. Thanks. Merged.\n. I have to agree with Roman. The Windows port is long story and we do not want only a port but a group of highly motivated people around to fix issues specific to this platform.\nThis is the third, fourth, fifth... I don't count anymore... Windows port from different people. Let's try to create a group, come discuss on IRC, stay around...\n. To be even clearer, we do not want a build today and nothing tomorrow. This will be very bad for darktable reputation. Do you see all those users left in the void with an old buggy version?\n. Thanks, I have merged this.\n. I have changed roundf by lroundf and tested that all was ok too.\n. Noted!\n. Nice! This is really a fix and I think it should be in 2.2.\nWorking fine for all forms except pencil. It seems that for the pencil the shift-scroll still change the size of the object and not the feather. Do you confirm that?\n. Will look at this but not before Monday.\nPascal Obry / Magny les Hameaux\nLe 19 nov. 2016 9:51 AM, \"Ulrich Pegelow\" notifications@github.com a\n\u00e9crit :\n\n@TurboGit https://github.com/TurboGit: knowing that French text tends\nto be longer than the English one, could you please have a look if we get\ninto issues with the changed hinter messages? The one for the ellipse shape\nis probably the longest one.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1354#issuecomment-261702035,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAcgfbMUDgUF_Pi2l80sqshhOoA9AyY0ks5q_rh7gaJpZM4K0Uci\n.\n. @upegelow : the french text looks fine to me. I've just updated it and tried to minimize it.\n. I've tested it but I cannot see a difference when using the midtone-bias slider. I've looked at the image closely in different location. It seems that the image is not changed. The histogram moves a bit, so I suppose that there is some changes done to the image. Where should I looked? How this slider is working? Thanks.. Indeed! Thanks Tobias now I see it. Not a strong effect but nice.. Yes, per-shortcut is a possibility to have two records in less than 500ms, I forgot this case!\n\nIt is certainly possible to check for the actual module, that is < 500ms and for the same iop. In fact that's what my first implementation did, and I have removed this check because it seemed superfluous to me. But again you're right, with shortcut we can have this case.. A better proposal is in: https://github.com/darktable-org/darktable/pull/1398. NOTE THAT THIS IS STILL WIP. Good new the new implementation makes it easier to support undo/redo and is working for masks now.\nThe bad news is that won't be for 2.2 as I had to change/fix many things in the undo support to be able to implement properly undo/redo for masks.\nAnyway at this stage this is ready for review & integration.. I'm closing this PR. After IRC discussion it appears that this is too much for a single PR. I will split it and I will:\n- commit the fixes\n- create a PR for mask support\n- create a PR for group support\n- create a PR for smoothing record (dragging mask or curve should not record too many intermediate steps).\nWe will then discuss each feature separately.\n. Thanks Matthieu.. Yes, done!. Thanks!. Merged thanks.. To me the initial text is fine no? It says that additional controls are displayed. That's true. Then clicking again hide the control.. I'd like Ulrich to comment on this as it is on the user's manual. I'll ping him.. Some comment on this usability patch? I'm using it now and seems to be a nice improvement when tracing with the brush.. This is working, but it is painful as the changes are committed very often in darktable. Good as we do not loose edits, but difficult for the undo on mask to be useful. For example, create a mask on exposure, change the size with the mouse wheel, change the size of the feather with the mouse wheel... Do undo... You'll need lot of them to get rid of the mask.\nWe have the same issue when dragging curves in iop like \"tone curve\".\nA solution has to be discussed.. I'd like to move forward on this (and #1419) which are really meant to work together. Can someone review this? I'd like to have this merged sooner than later to allow fixing potential issues before next major release. . If there is no more objection I'll merge at the end of the week.. This is one solution for issue described in #1418 \n. This is a proposal and to initiate discussion about what I want to fix. Maybe there is better solution.. Your analysis is not quite correct as the recording is not done only on the timestamp but also on some id (e.g. mask id). But this imply a distributed complexity as it imposes some coding from all user of the undo feature.\nNow, I like your proposal better as it avoid the distributed complexity as all the computation of what should be undone will be in the undo module itself. Lot better I would say... I'll take this route and propose a patch ASAP.\nThanks for the review houz. . Likewise, if there is no more objection I'll merge at the end of the week.. This one does not apply cleanly but anyway it should be worked after #1418 and #1419 are merged. So for the moment do not spend time reviewing this one.. I'm not really sure what to do with that at this stage.. Closing, this has been rebased in #2114 .. Tested on my side and working fine. Indeed it gives more control to the fusion mode. I like it.. Thanks.. I'll merge this as I badly need it and it is really a bug.. Here is what I propose. Let's change the CSS to give a full opaque brush. That is, something that is exactly what we have today. And we will merge this as it will not disturb people already using darktable. Then people wanting some transparency will be able to configure this directly in ~/.config/darktable/darktable.css. How does that sounds?. Ok, I've merged this with a little adjustment to the opacity. At least now everyone can change the default. Thanks.. I've just tested that and to me it sounds quite interesting. Having a way to see the actual channel a or b corresponding values on the picture help a lot. Great work.\nOn the usability side I feel we could do better. For example if I'm already over the channel slider and click shit or control nothing happen. I need to leave the slider and to enter it again. Can we avoid that and just trigger the display when keying shift or control?. @upegelow, sorry I was sure I had answered to you. I was thinking that we could just use some standard keys (letting users the possibility to change the binding) to activate the modes?. And we can activate two modes when over the whole blend UI and not only when over the sliders, would be quite handy. What do you think? . @upegelow, I don't have an answer to you. Let's move forward, we can merge this new feature and we'll see if the user experience can be improved somehow after getting more feedbacks.. I've tested it. I think it should be merged. No issue on my side.. Jeremy, what do you think?. \nI have a PR to smooth those undo.\nSee https://github.com/darktable-org/darktable/pull/1419\nThe idea is indeed to avoid recording too many intermediate state for a module. Please try it and tell me how it works on your side.\n. Tested, seems to work great and give me a bit more responsiveness with my Quadro M1000M. Great work!. A simple usability fix that I had in mind since some time now.. Changes done. Will merge tomorrow. Thanks.. merged.. What is the status of this PR? Is that still needed/wanted?\nLet me know, or I'll close this PR. Thanks.. @peterbud, is that still of actuality or should we close this PR?. Sounds good to me. Thanks.. Could you rebase and fix conflics? It would be nice to have this in. Thanks.. @vacaboja : hold on as a quite extensive rewrite of the lighttable is being worked on, see #1973 . You're correct. I'll check that soon then. Thanks.. Sounds good now! Thanks.. Sounds like this is better that the current situation. Going in the right direction. Let's merge. Thanks.. Indeed no more crash. This looks good to me, I'll merge thanks.. All good to me! Working as advertised :) Thanks for fixing that.. I have tried it but I could not make it to work. Maybe some bugs? But most of all it does not seems to be obvious to use... Many buttons... At some point during my testing I had lost all visible shape to control the forms and did not find a way to get them back. Anyway, first step would be to ensure that the iop does work almost in all cases and maybe add here some notes about way to use it.. Ok, I have been able to have the clone tool working. I have been able to have the heal tool working and it is indeed quite good as the result is clean and there is no halo or whatever. That's great!\nFor the decompose, well I just still don't understand how to use it. I have tried it given your instructions, but well...\nFirst what is it supposed to do?\nAlso, the set of options cannot be applied to a selected shape, it makes the tools difficult to test.. @themes: thanks, but now what are the steps to achieve the same with the retouch module. I mean to create all the masks with different scale? And work with them... I'll try again, but the usage is not obvious to me!. Some progress, looks like I have some result with the clone/heal tool and scale. Is that possible to use scale with blur tool? Looks like it does nothing on my side.... BTW, I do think that the simple heal tool should be also copied into the current spots removal IOP. I would even make it the default algorithm.. Thanks, I'm starting to understand how it is working. Well I must say that the work is a bit tedious but the result is nice. I have been able to work on a portrait with good result indeed.. I have played with the module on two images for real. No crash, working great so far. That's a really nice module!. Thanks for this new feature. Do not worry about backward compatibility, this is not merged yet. I'll test this new feature.. @edgardoh, I'm wondering now that there is the possibility to apply shapes on multiple scales at once if a visual feedback of the scales being worked on wouldn't be nice.\nI'm thinking at a widget like in the zones iop, that is, a set of boxes all the same color, each box represent a scale, and the current scales being colored (yellow?). If multiples scales are selected, multiples boxes are being colored. This would help to see the selected scales.\nAnd maybe even better, use two cursor under the set of boxes to select the current scales. And then just remove the two current sliders. What do you think?. About the slider here is what I have in mind.\n\n\nselected scales are yellow\nmouse wheel to control the number of scales (as done in zones)\nmoving the top arrow to select a range of scales\nmoving the bottom arrow to change scale selection, it also moves the top scale to keep the number of selected scales.\n\nThis way you replace 3 sliders by a single GUI widget.\nWhat do you think?. @edgardoh, agreed a label will come handy. for the gtk part look at how the zone module is done. it has everything except the top arrow. And sure your plan sounds good.\nI'm really interested by this iop as I do lot of studio / portrait :)\nThanks for you work on this.. @edgardoh: I may have some spare cycle over the end of year, I could work on the widget if you agree.. @edgardoh , great news and thanks!. @edgardoh Nice! I think we should also add a double-click on a scale select this scale only. That is current scale and merged scale are all reset to only work on the selected scale.. @edgardoh : I see the double-click as a reset so no scale merging should happen anymore. We just go back to working on the current selected scale only.. For the GUI, to make it clearer I would also change:\n#\u00a0scales: 11 current: 5 merge from: 1 \nto\n# current: 5 merged into 1 .. 11\nAnd if there is no merging scales = 0 and merge from = 0 I would simple display:\n# current: 5\nWhat do you think?\n. Testing I also see that the mouse scroll does not change the number of scales. Is that expected? I cannot change the number of scale now.. @edgardoh : something wrong then I think. with the current gui the merge scale always goes from the bottom arrow to the to arrow. this confuses me as I did not see that bottom arrow is the number of scale. i would have preferred to have the number of scale represented by the number of gray patches in the GUI. And the top bottom arrow for the scale merging. and the selected patch for the current scale.\nAs it is today it looks confusing to me. Or there is something I do not get :). @edgardoh : ok I better understand now I think. Let's just let things this way and see how it works. I'll try it during the coming days and I'll see.\nSo at this stage maybe just update the display of the labels adding the # scales as you proposed. . Nice improvement indeed! I need to properly use/test this now :) Thanks.. An annoying bug, to reproduce:\n1. open Retouch, add on shape (whatever)\n2. activate any other module\n3. go back to Retouch and click the reset button\nAt this point the history has:\n8 retouch\n7 exposure\n6 retouch\nFine, 8 is empty but if you go back to 6 in the history stack then the shapes added there have also been removed.\nI would have expected to be able to go back to 6 and get the state of this module as it was,  that is with one shape.. Otherwise I have played on a RAW and I must say that the result is very very good. I have been able to get far better result than just using the Equalizer. I already love this module :). @edgardoh : ok the bug I reported above also occurs with the spots module. nothing to do with retouch but the way masks are handled for those modules.. If it is done in the existing code all good, but I have reviewed the code as pushed today in you latest retouch branch. So are you saying that you have uncommitted changes? Also I'm not sure to understand the \"keep consistent\", to me it is always better to have const when possible as during review it state clearly that the variable is not changed.. @edgardoh : I think the new slider is ok this way. for me it works fine and with the mouse-wheel you can adjust different parameters, this is handy and easy. so I would start with that, for me its ok.. @edgardoh : I forgot to report one point. the slider in retouch goes on the left from fine details to coarse one on the right. The equalizer goes on the opposite, coarse on the left, fine details on the right. would it makes sense to use the same order? . @edgardoh : which is indeed a strong point (being consistent with other wavelet decompose programs), so fine with me.. I'm wondering but I found out that the speed does not improve when only working on a zone. I have made a mask (blur) on a whole image (close-up portrait), it takes around 2 seconds to update the display. When I zoom in the image I would have expected the performance to improve as only a specific zone needs updates, but I found that about the same 2 seconds are needed to update the display. I would have expected less. Do you reproduce this?  . I think this is expected as I have a single brush stroke and modify_roi_in() exclude only forms outside of the display.. @edgardoh : for your DT_SIGNAL_DEVELOP_UI_PIPE_FINISHED issue I don't have idea.. @edgardoh : yes the contrast and brightness can be removed.. Maybe a small enhancement, when you select the blur mode have the blue default value set to 10 or 20 instead of 0?. @edgardoh : I agree heal tool makes more sense I think and you can put it in front or not, if it is the default selected one I don't think the order matters too much.\nFor me the level sliders has always given better result than contrast+brightness quickly. I bet one can get the same output with c+b but it seems difficult for one thing the contrast slider is very sensitive and past 0.10 all is way to dark anyway on most images.. @edgardoh : this branch does not apply cleanly on top of current master, there is conflicts. can you rebase and fix them? thanks.. @edgardoh : I'll do another pass to test it. Thanks.. This 'small fix\" looks like a speed-up, right? Is that much?. There is conflicts now. Can you rebase? Thanks.\nBTW, I think we should merge this sooner than later as a larger field testing will be nice.. Ok thanks! To help merging that you may talk to Tobias on IRC. On my side I have no more question about the code. The GUI is ok, not sure we can do better for this first iteration but sooner it is merged sooner will have field testing and report. The module is complex and so the UI seems good to me.\nAnd yes, I'd like this merged soon as I've been testing it on many pictures and the result of the split-frequency on skin is very nice. I do not want to use this in production as long it is not merged.. > IRC doesn't really work for me, I know is not the same but here or mail is better for me.\nI understand, IRC is not my preferred channel either as I prefer asynchronous work. At least if you can e-mail Tobias or ping him or IRC about this PR it would be nice to get this going.. > the wavelet scales are not 100% scale independent, so result will vary depending on the export size.\nExpect if the option \"do high quality resampling during export\"  is selected, right?. I'll do another path on this soon. If no more issues found on my side I'll merge. We are four months away  from next release, this needs some more tests base.. Just a comment that I did not forget about this. I had no time to do another full test until now. I hope to be able to test and merge before september.\nIn any case I think that the \"heal\" tool should be an option also available in the \"sport removal\" module. Using the full retouch module just for that is no good, the simple spot removal should support the healing mode to me.. It is quite a complex module just for removing a spot. When the only goal is to remove a spot from the sensor on the sky I feel that it would be better to be able to use the simple \"spot removal\" module. The Retouch module is quite advanced and will not be easy for some people. My feeling.... Ok, I have reviewed again and did a quite intensive testing. All is working good to me, so it is time to let this go in and have a more widely field testing before the next release.\nThanks again for this very nice addition. . Sorry I may be missing some context. What dependencies are you talking about? A PR for what?. I see, you've manually coded the priority into retouch.c so fine on this side.\nBut we should update iop_dependencies.py by placing retouch module into the graph. Can you do that?\nThen, we don't need to run iop_dependencies.py but in case we want to recompute the priority values based on a new graph this can be done anytime.. BTW, you've put 176 as value, the same as spot :) I suppose it should come after spot? Then please update to 180 which is a free slot after spot. Thanks.. @edgardoh : can you comment on https://github.com/darktable-org/darktable/pull/1754\nThanks.. > -add a preview when creating a circle\nwould be nice to do the same for ellipse I would say. this preview is helpful.. @edgardoh : I would just show the ellipse and let the mouse wheel adjust the size only. When placed the user can change radius and feather and orientation. I think this would be good enough to help user place the ellipse at the right place with the right size.. @edgardoh : thanks! I really do think this is better than nothing :). That's just perfect thanks!. This patch set does not apply on top of retouch branch. There is conflict in develop.h, trivial to fix. Not sure what the best option, rebase this branch on top of retouch or wait for the first branch to be merged and adjust the other. I think this last option is best, nothing to do for now. I just wanted to raise this point.. Would be nice to rebase and fix conflicts on this one. A nice addition... Thanks.. Can you describe what are all the changes in the drawn masks behavior? I'll try to do some more testing soon. Thanks.. Ok, alll this is sounds to me. Even the change of the feather requiring the SHIFT, I had found also that sometimes it was difficult to select just the shape and not the feather.\nDo you think we can split the PR in two. I see:\n- 1) one commit with the preview for circle & ellipse\n- 2) one commit with the behavioral change\nThis will ease merging, at least I would merge 1 right now. Then will see how 2 looks for others. What do you think?. Yes, sounds good to me!. The preview of the shapes are not working on my side with the latest changes. A missing chunk in a commit?. I have merged it locally on master and it does not work for me :( I had all this working with previous version of the PR. I'll try again.... Still no luck on my side. I have removed my darktable install and build directory. I have merged this PR into my local master (which is exactly origin/master). And I still don't have the preview of the shapes.. BTW, your new PR mask_behavior has conflicts if applied on to of this one. This may indicate that something was broken when you've separated both PR?. Really mysterious! I have built also directly from your branch and it does not work for me :(\nI don't have explanation for now. But it doesn't seem to be due to the merge on master.. Found... A stupid issue on my side :) I'll check this and merge if all good.. All good and now merged. Thanks.\nPlease be prepared to write the documentation for the new retouch IOP BTW. You just need to write this as plain text in whatever editor you like. The doc maintainer (Ulrich Pegelow) will ask for this for the next release.. Hello Aur\u00e9lien,\nMaybe not what you are looking for but for point 1 above it is possible to use the same masks on a set of layer by using the top slider control. When used, the masks in the \"yellow\" range of layers are used in all layers. So starting from the first one where it is applied and up where the \"noise\" is bigger (larger details).. @edgardoh, it looks sounds to me, I would try Aur\u00e9lien proposal. And yes it is perfect time to do that now, I have merged well ahead of the release to have field testing & feedback. So better trying to implement good idea before the next release I would say.. I have made the French translation, so the translation is present :) Maybe you need to update :\n$ intltool-update -pot\n?. @edgardoh : I'll have time to review the new PR early next week only.. Sounds nice!. This needs a rebase and merge conflict resolution. I'll then try to have a look for 2.8.. I'll close, feel free to reopen if something is to be done on this PR.. Replaced by #1565 . Indeed :). I'll close, a better turboprint integration will be proposed.. A fix anyway.. @garrett no city or country import. this is just a fix for the new Lr 7.x format. No new feature at this stage.. @garrett and moreover there is no city or country field in darktable, so I'm not sure how this would fit anyway.. I don't follow you. dt does import GPS location. But you were talking about city and country. There is no such field in dt, yet with the GPS data the location is quite precise. So now I'm not sure to understand your need.. Merged.. Nice! I had started to work on the count for a collection but never finish, this is really a neat new feature. I've not look at the code yet but I found an issue. If you select a collection and then reset the module (click on the small circle on the right of the module) then the lightable is reset properly but not the content of the module itself (the previously selected collection is still there).. I would do the hierarchical view for date/time tag too. Maybe just on the date?. Works great now! The date-time is lot more useful as it is now.\nA small issue, select a tag based on a color label. Remove the corresponding color label on one of the picture. The count on the collection module is not updated. A minor issue but if we can fix this it would be nice.\nAlso, If you select a collection AND NOT (exclude) those that have the tag exported (darktable|exported), exporting one of the picture will remove the picture from the lightable but the count won't be updated. Would be nice to fix that too.. Looks good to me now. The two scenario I had tested are now working fine and the count is properly updated. Thanks!. @oexler : The list now only gets filtered when something is typed in the entry box.\nI really like this, indeed you can click on different collections quickly. One annoying thing is that when you click on a collection it always move the collection tree to the top. This is very annoying when you are low on the list, you need to scroll down again and again to select another collection. When double clicking on a collection the tree should not reset to top but kept as-is.. @oexler: yes rebasing and adding the local copy support would be nice.\nBest way to proceed next is to go to IRC and talk with the core devs for integration. I'll talk about this module on IRC tonight if you want.. @oexler : wonderful! Indeed better to not squash as it makes it easier to review I think. I have raised the awareness of this PR on IRC. It is nice to see some refresh on this area for darktable, the filter is quite better this was to me. thanks again.. Just wondering if it would be possible to make the collapsable tree used to display date and datetime for example as a separate widget? It would probably help implementing https://redmine.darktable.org/issues/9323. Does this makes sense here? What do you think?. Any new on this? If my request does not makes sense I'd like to merge this at this stage, it will get used by more people.. @houz, and you want to fix this when it is merged? or before?. > Adding A|B|C will add A, A|B and A|B|C\nI'm certainly not for this. It will just add noise in the list of tags. And I'm not sure what it is supposed to fix?. I'm not sure we want to mess darktable for the sake of fixing digikam. frankly having all those unneeded tags in dt tag view is not something I want to see.. Ok, I'll close the PR we can reopen at anytime if needed anyway. Thanks.. Right, I have moved the uselocal() after the check for Lr XMP and there is no more return after. Is that better?. Any update on this? Or should this PR be closed?. I'll close, feel free to reopen if something is to be done on this PR.. can you rebase this on current master? there is merge conflicts. thanks.. why not (on the lighttable) but do not force it. I use to use overly scrollbar on dt but those cannot be made overlay they are always present. In the darkroom they take some place and we are loosing real estate, not sure this is worth in darkroom anyway.. screenshot for the lighttable. on the darkroom we have both vertical and horizontal ones but I don't think we want scrollbars on darktable.\n\n. Just tested the three modes (lt, lt + dr and none) all working fine. Can be merged for me. Thanks.. Indeed, no way to remove those edges. I think this is fine as-is.. On the top/bottom we also have the show/hide panels (filmstrip and header).. I think the space on the left of the scrollbar is the one around the lighttable center view.. @oexler , indeed this has broken the map view. In the map view we are dealing with gtk_widget_get_parent() (see map.c:794). The parent is now a grid and not a box.\nCan you have a look as soon as possible? This is a bad regression. Thanks.. Done. Thanks.. I agree, in the fixed version it would be nice to remove this space when the scrollbar is displayed.. No, you just have to force push your branch here.\nSame command you used to create the branch but with -f.\nIf that still doesn't work, yes create a new PR. Thanks.. Indeed reproduced. Thanks for fixing that.. manually merged.. Thanks, merged now.. Looks good. Thanks.. I feel that this won't be merged given the last comments. Should it be closed or do you have more idea as to what could be done?. What is the status for this PR? Is it still actual? Do you think we should have it in 2.6? Thanks.. Ok, the code looks a nice clean-up indeed.. Not really fan of that, but if there is a preference to disable it why not if this fill a need for others.. Alternatively this could be displayed only when dt is full screen on the primary screen.. Should this PR be pursued? Or should this PR be closed?. I'll close for now as no answer. This can be reopened at any time if needed.. You have added rawspeed into the commit. Need some clean-up. Thanks.. I'll merge manually. For the submodule (they are tricky to handle), you need to do from your branch on top of your commit:\n$ git reset HEAD^ src/external/rawspeed\n$ git ci --amend\n$ git submodule update. Indeed, thanks for the reminder.. Merged manually.. Closing, those do not apply anymore. Seems like the code is somehow broken.. It does not compile when rebased on master. If you want this, please rebase, fix and force push on this PR. Thanks.. Let's do that then. You can force push here is changes. Thanks.. Any news on this?. Please as discussed before only add the noise profile in this PR. Also, looking at the curves it seems that the values are not really good in the high luma value. I'll ask confirmation. Also this is missing the noise_result.pdf. Maybe because it was not generated back in 2016.. Confirmed, the curves are not very clean. As a first solution redoing the computation (with the same pictures) but with the recent tool would be nice? If the curves are still not clean I fear that you'll need to redo the shot, and restart the whole process.. Ok, at this stage I'll close. Feel free to open a new PR with corrected curves and with only the noise profile. Thanks.. Let's close this for now. Fell free to reopen when ready or motivated to get this included; Thanks.. Thanks.. I think this is OK as is. If we want to feed more exif data into the database I think that this should be done in a separate patch and discussed before. I'm not sure we want to do this. Feel free to open a new redmine ticket if you'd like to pursue this. thanks.. The drag&drop in the filmstrip is for the map view. It is finished and working properly in this view. . Any news on this or should this PR be closed?. Thanks working fine to me.. Looks good. Thanks.. If I'm not mistaken this is now implemented in dt, right?. Ok, so please can you rebase this to current master and resolve the conflicts? Thanks. And add some notes of what is PR adds to previous implementation.. Sounds good. I'll test iti.. Not working on all cases on my side. When I double click on some entries like (1/5000 or 1/2000) the lightable stays empty as if nothing match. In fact none of the 1/n values are working.For some other values 5.0\" it is ok, it seems like all x.y\" are working except if x=0 (0.77\") is not working.\nCan you reproduce?. Here are the data for three pictures not working:\n1:\nExposure Time                   : 1/1250\nShutter Speed                   : 1/1250\n2:\nExposure Time                   : 1/1250\nShutter Speed                   : 1/1250\n3:\nExposure Time                   : 1/100\nShutter Speed                   : 1/100. I see in the database that 1/100 is stored as 0.0099999 and 1/1250 as 0.00079999. You probably want to look at the way the exposure is computed. Maybe using single precision float?. Any news on this? There is conflicts to be resolved anyway. Also if we want to have a chance to integrate this into the next release we really need to make progress. Let me know.. Closing, I have created a new PR based on this PR:\nhttps://github.com/darktable-org/darktable/pull/1775. I'm not a german speaker but this looks ok.. Given your last message, I'm closing.. Thanks.. Looking good to me. Thanks.. Thanks.. Thanks for the code clean-up.. I don't remember having seen this issue, can you tell me how to reproduce? Thanks.. Right, just safe anyway. Thanks.. Using the system I get:\n<content_rating type=\"oars-1.0\">\n    <content_attribute id=\"social-location\">intense</content_attribute>\n  </content_rating>\n. I see, I tend to agree indeed. Let's this go in. At the time of the shot we don't have automatic upload of picture anyway.. I've read the corresponding Redmine issue and it seems that there is no consensus about this. We probably need more discussion before including this.. You seem to have integrated a rawspeed submodule change in the commits. Also, not at this stage that it would be nice to squash all the commits together (into a single commit).. Merged, thanks. Note that there were still some bool in your patch that I have fixed.. Manually merged.. > lowercase at the beginning of the sentence\nNot sure for the german translation but lowercase at the beginning of the sentence is a darktable style which is far more readable on the UI.. Closing, no answer to my question. File is in conflicts and many changes have been done in the translation.. the new layout is using lot more horizontal spaces, I do not like this so I'll let other take a decision about this.. But vertical space is very important on our screen. Maybe for a better visibility we could have an option to make the slider indicator of a different color. I'm sure if you put the indicator in yellow, or red it will be more visible. But this must be an option as I know some people don't like to be distracted by UI colors when working on pictures. What do you think?. No I have a monitor with 2K (2560 x 1440) resolution but I also work on a full HD laptop. In both case the vertical space is very important to me. . Why closing? I gave my point of view but I'm not alone. Maybe others will have another point of view on this or some other proposal to improve this!. Indeed not :) Open Source is about being Open Mind too. So I cast my vote but we need more discussion to get a definite conclusion before accepting or rejecting a patch. Note also that I'm only a part of the development team, so others will comment I'm sure.. Sounds like a nice enhancement to me.. All good now. Thanks.. Ok, reading again the code I agree that the current circuitry is wrong. This patch is a step forward and fixes the Redmine issue. So merging. Thanks.. Ok, I like this but it does not handle the local-copy (white) dot which was displayed just after the last color label. We need to find the best way to integrate it into this new display.\nAs the local-copy white dot is not really a color label for classification we do not need to add it with the others, at least not as six possible colors.\nMaybe a large white dot under the color labels as displayed in this PR?\nOr a white dot just between the X (reject button) and first star?\nWhat do you think?. I think I prefer my second proposal, and while we are at it why not change from white circle to white square? Or something that looks like a disk bigger white circle with a black dot in the center to convey the fact that we are talking about a local-copy. . I just like your proposal best! Very nice indeed. Looking forward to it.. Lot better this way. The color labels are not over the picture anymore on most cases (only when the picture is square). The local-copy color label is now also more distinguishable. Very good work. Thanks. . I very much like this. But as this is changing a quite visible part of the UI I'd like more testing and feedback from others.. I agree, a preference  to enable/disable this extended display could be nice.. All good to me now. Thanks.. Sounds good, Thanks.. As Roman I'm not convinced about this. I do see that the readability may be affected but the solution here are not right. Option 1 will cut the label far too more, in French the labels tends to be a bit longer and so the slider becomes ridiculously short.\nMaybe a solution (I think I have discussed that already) is to have a different color for the sliders. It may even be configurable right now with a CSS?. Any update regarding the last comments? Or should this be closed?. Thanks!. Thanks.. Thanks.. I really like this. Just need a bit more time for testing and more feedback would be nice.. Been using this and looks good to me. Indeed this make it possible to more easily select a mask when lot of them are close to each others. Time for a wider field testing. Thanks.. Sounds fine to me. Thanks.. All good, Thanks.. Thanks, nice clean-up and working fine.. Looks good. Thanks.\nI think there is something broken with the retouch IOP, the blending is not working on it.\n\nuse a parametric mask and try to display the mask (no yellow on display)\nuse uniform biending and change opacity, it seems to have no effect\n\nDo you reproduce on your side?. Ok, I found a reproducer, but now I'm wondering if this is a feature or a bug.\n\ngo to darkroom\nactivate retouch\nactivate the parametric mask\n\nactivate the display scales\n=> try to display the mask (yellow) -> not working\n\n\ndisable the display scales\n\nactivate the display mask, it is working\n=> try to display the scales -> not working\n\nIt seems that you can have either the masks or the scales but not both.\nThis has been tested with current master and with this branch.. Yes, that makes lot of sense, but in that case I think we should have a log message sent to user about this using dt_control_log(). That is when clicking on mask when scales are active and vice-versa. Possible?. Anyway, this is not an issue due to this PR. Will merge. Thanks.. Well a log message will appear only if you click on the non effective button. It should probably happen once or twice before a user stop try that :) So I would that a log message would be nice if not too difficult to implement in this case, but having a message in the tooltip is also a good idea.. Sounds good, there is a missing message though. When clicking on the \"display wavelet scale\" button we should also have a message. This is not working and what I had reported before.. I would write:\n\"display scales cannot be set when mask is being displayed on blend module\"\n. All good, thanks.. Send a message on the -dev (maybe -user) mailing list? We need people compiling dt at this stage.. I definitely think that  &  should be taken into account.. Well I have surrounded the \"enter\" and \"esc\" with symbols sup and inf and it seems that that has been interpreted as HTML tags :( So the full sentence is:\nI definitely think that \"enter\" & \"esc\" should be taken into account.\n. Alternatively don't use a dialog.\n\nuse a simple entry as done for ctrl-t (adding tags) from the lighttable\nwhen double-click on the module name, let edit the module name in-place (the current name label becomes an entry)\n. Sounds good to me. Thanks.. Thanks, looks good to me now.. Thanks.. What do you mean Aur\u00e9lien? Yes, that's it, the support was there for all power of 2, only the entries to select those zoom levels were not wired.. Tested to death :) working as expected on my side.. Aur\u00e9lien, when you have some time can you fix the merge conflicts? I'll have a look, all those nice comments push me to see more about it. Thanks.. Still some merge conflicts? Have't you forgotten to push some modifications?. Yes, but you need to push in aurelienpierre:color-grading. The conflict is still there.. Aur\u00e9lien, I will close this PR. There is 60 commits, many merges with master, it is possible to merge locally but impossible to rebase due to conflicts.\n\nI have squashed all those commits into a single one and will propose a new PR with this. A cleaner start for the integration. . Tested a bit. Something broken it seems that the \"copy\" history dialog presents the history of the selected image and not the history of the image under the mouse pointer. To reproduce:\n\non the lighttable\nselect a picture (click on it)\nctrl-shit-c, the dialog present the history of the selected picture all fine here\nmove the mouse pointer over another image, do not select and do ctrl-shift-click\nthe history presented is the one from the previous picture, that is the one selected and not the one under the mouse.\n . > -if (operation, multi_name) already exists on dest image, it replaces it\n\nCan you clarify this. Does it means that this takes into account the module renaming? . Hum, looks like the behavior I described above was there before your patch. So, not a regression but a feature :) Sorry for the noise.. One issue found:\n- on image A add exposure + 4, rename module to \"xyz\"\n- on image B add exposure +1, add a second exposure instance and set black level to -.1\n- copy B history (ctrl-shift-c), select both exposure modules (\"exposure\" and \"exposure 1\")\n- paste on A (ctrl-v)\n- open A, the history is wrong:\n7 - exposure 1\n   6 - exposure\n   5 - exposure xyz\n   4 exposure xyz\n4 is ok, the it exposure +4 added on A\n5 is wrong it is a second exposure instance with +4 expo making the image expo to +8!\n6 & 7 are ok and are the modules copied from B\n. But instead of duplicating the (exposure 0) why not change the priority of copied exposure history for them to go on top of the existing one?\nyou have (dest):\nexposure 0\nyou've copied (from):\nexposure 0\nexposure 1\nLet's change the copied history to:\nexposure 1\nexposure 2\nPaste them into the destination, so we have:\nexposure 0\nexposure 1\nexposure 2\nWould that work?. I'm not really following. I don't see why I'm proposing a \"merge\" instead of an \"append\". In my point of view my proposal is really an append. I just want the two copied exposure instances to be added.\nWhat I still don't see is why do you have/need a duplicated \"xyz\" exposure in:\n7 - exposure 1\n6 - exposure\n5 - exposure xyz\n4 - exposure xyz\nOr maybe because 6 is *replacing\" 5 ? Maybe we should do a step back and try to write down what the semantic we want in all cases:\nsingle instance\n\nthe copied IOP does not exists on the target\n=> just paste the IOP as-is\n\nbefore:\nexpo +1                 |\nafter:\nexpo +1                 |         expo +1\n\nthe copied IOP exists on the target\n=> append new on top of the other, replacing the values (same instance)\n\nbefore:\nexpo +1                 |         expo +2\nafter:\n|         expo +1\nexpo +1                 |         expo +2\nmultiple instances\n\nthe copied IOP does not exists on the target\n=> just paste the IOP as-is\n\nbefore:\nexpo-1 +2                 | \nexpo-0 +1                 |\nafter:\nexpo-1 +2                 |      expo-1 +2\nexpo-0 +1                 |      expo-0 +1\nThis makes the new expo on dest to be +3\n\nthe copied IOP exists on the target\n\nbefore:\nexpo-1 +2                 | \nexpo-0 +1                 |     expo-0 +3\nafter:\n|      expo-1 +2 \nexpo-1 +2                 |      expo-0 +1\nexpo-0 +1                 |      expo-0 +3\nThat is, final expo is +3 as expo-0 on target is replaced by expo-0 from source.\n\nthe copied IOP exists on the target, copy first instance  only\n\nbefore:\nexpo-1 +2                 | \nexpo-0 +1                 |     expo-0 +3\nafter:\nexpo-1 +2                 |      expo-0 +1\nexpo-0 +1                 |      expo-0 +3\nThat is, final expo is +1 as expo-0 on target is replaced by expo-0 from source.\n\nthe copied IOP exists on the target, copy second instance  only\n\nbefore:\nexpo-1 +2                 | \nexpo-0 +1                 |     expo-0 +3\nafter:\nexpo-1 +2                 |      expo-1 +2\nexpo-0 +1                 |      expo-0 +3\nThat is, final expo is +5 as expo-1 is appended on target.\nWhat do you think? Do you see another case missing?. > I think that we both agree that the history on the dest image should not be modified,\nI 100% agree.\n\nso as I see it the question is, what do we do about the order and position on the pipe for the pasted instances?\n\nRight. Your version is right and I don't want to change the final result/semantic.\nMy point is only of the duplicated instance. You do that to avoid a pasted instance to replace a current existing one. The goal is 100% correct, but I'm questioning the way it is done. I would like to avoid this duplicated instance if possible. My idea was to change the multi_priority values of the pasted instances to achieve the same goal (not replacing a current instance) but without the duplicating which makes the history wrong at some point. In my example (https://github.com/darktable-org/darktable/pull/1731#issuecomment-423454255) if you click on 5 in the history you get the double exposure of the 4 history.\nMaybe my proposed solution is wrong, but again if we can avoid this duplication it would be good.\nDo you see a solution to this? Or was your proposal the only solution?. I did some testing on the database (using my first example), on the destination picture the history looked like this with your current version:\n(select num,operation,enabled,multi_priority,multi_name from history where imgid=XXX and module=5)\n\nnum   operation  enabled  multi_priority  multi_name\n3        exposure   1            0                    xyz\n4        exposure   1            2                    xyz\n5        exposure   1            1                 \n6        exposure   1            0                    1\n\nI have hacked it to be:\n\nnum   operation  enabled  multi_priority  multi_name\n3        exposure   1            0                    xyz\n4        exposure   1            2\n5        exposure   1            1                    1\n\nThat is renaming multi_priority to 1, 2 instead of 0, 1 to be on top of the current instance.\nBut this is wrong indeed as it change the pipe, the xyz original operation now come AFTER the pasted ones. Wrong :(\nSo the only option to achieve my goal would be to change xyz instance multi_priority:\n\nnum   operation  enabled  multi_priority  multi_name\n3        exposure   1            2                    xyz\n4        exposure   1            1\n5        exposure   1            0                    1\n\nBut this defeat the first agreed point : do not change the original history!\n. > This way we have a cleaner history that now, and more information on what's going on. \n\nWhat do you think?\n\nThis sounds like a quite big change. We need to think more about this before starting, I mean I don't want to loose your time if this cannot be integrated!\nYour proposal need a change in the database schema for example.. > Not sure what you mean by this cannot be integrated.\nWhat I mean is that such a large, intrusive and user visible change must be more generally discussed with other developers. I cannot take the decision to merge this myself. So if some are not ok with this it won't be merged even if working. So be warned :). Right, or change the multi_priority for the order to be from 0 to max instead of the opposite. Then we can just copy on top of the existing history. Not sure how difficult this could be.... Frankly more I think about this and more I think that we should just \"change\" the multi_priority (I know we said that we don't want to change the existing history). But I don't think it is better to add a new field just for the sake of fixing this case.\nThe more important point to me is that the history stays fully correct. That is, we can click on any item in the history and get a proper \"expected\" rendering (and not a duplicate effect as the current implementation has).\nSo just changing the multi_priority of the existing history items to have them placed before the copied one. So making the multi_priority of the existing items > than the copied ones. Seems like only this is needed to have a quite better copy/paste experience on your current PR.. @edgardoh, well be careful we still want to support the following scenario:\n1. apply a module (exposure +1 for example) to a picture\n2. copy this exposure to say 100 pictures\n3. finally change the value of the module in step 1 (exposure was too high, let's use +0.5)\n4. copy this new exposure to the same 100 pictures\nThis is a very common scenario where 4 must replace the value set in 2. Going back to the 100 pictures (and sometime far more) is not an option here.. Looks good now to me. All the cases exposed above are covered.. I have done many tests and it works as expected to me. I will merge this now as this require more field testing.. Doing a copy of 5 module in an history and applying to a set of 100 images takes a very long time. Maybe we can improve that before the release?. @edgardoh  : Exactly, thanks for pointing this out, I have put in place a fix.. Sounds harmless to me. Thanks.. I'm not sure I see the point of this PR.\nBetween 1.01 and 1.02 only a little issue about time zone has been fixed. So nothing about WB. And as seen on this PR the values are very very close. So what the point? Am I missing something?. Ok, nothing new here so nothing to merge.. Good job Aur\u00e9lien. I'm probably not the right person to merge this PR, but it looks good to me and works as expected. I expect houz or hanatos to have a deeper look. Thanks.. You need to remove the rawspeed submodule from here.\nAlso there is a small conflict to be resolved.\nI think also that it should be better to rebase all this and maybe even squash all the commits together at this stage. No need to see all the \"fix\" steps now.. Ok, let me know when ready. We are approaching the code freeze I suppose. So if we want this in the next release (and I think it would be really nice) I need to review and merge soon. Thanks.. One issue found:\n- open module, select \"both\" for \"color control sliders\"\n- click on the color picker IN the color picker module on the left\n- the color balance module is reset to \"HSL\" mode only instead of both. Another one:\n- open a new picture\n- activate color balance\n- let all default value\n- click on the picker for the factor in offset\n- draw an area\n=> nothing happens\nIs that expected? Maybe a wrong procedure on my side?. Hi Aur\u00e9lien, testing under gdb I get many crashes, one example:\n```\n0  0x00007fffb57c0239 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\n1  0x00007fffb57c3df7 in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\n2  0x00007fffb57bbe5a in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\n3  0x00007fffb57bbf7f in ?? ()\nfrom /usr/lib/x86_64-linux-gnu/libnvidia-opencl.so.1\n4  0x00007ffff7dc3523 in dt_opencl_enqueue_kernel_2d_with_local (\ndev=dev@entry=0, kernel=59, sizes=0x7fffb77e64d0, local=local@entry=0x0)\nat /home/obry/dev/OpenSource/builds/darktable/build/src/src/common/opencl.c:1931\n\n5  0x00007ffff7dc3557 in dt_opencl_enqueue_kernel_2d (dev=dev@entry=0,\nkernel=<optimized out>, sizes=<optimized out>)\nat /home/obry/dev/OpenSource/builds/darktable/build/src/src/common/opencl.c:1915\n\n6  0x00007fffb40e4edb in process_cl (self=,\npiece=<optimized out>, dev_in=<optimized out>, dev_out=<optimized out>, \nroi_in=<optimized out>, roi_out=<optimized out>)\nat /home/obry/dev/OpenSource/builds/darktable/build/src/src/iop/colorbalance.c:525\n\n7  0x00007ffff7e3e251 in dt_dev_pixelpipe_process_rec (\npipe=pipe@entry=0x5555573d9210, dev=dev@entry=0x555557407890, \noutput=output@entry=0x7fffb77e7468, \ncl_mem_output=cl_mem_output@entry=0x7fffb77e7470, \nout_format=out_format@entry=0x7fffb77e7478, \nroi_out=roi_out@entry=0x7fffb77e6990, modules=0x5555572eb9a0, pos=31, \npieces=<optimized out>, pieces=<optimized out>)\nat /home/obry/dev/OpenSource/builds/darktable/build/src/src/develop/pixelpipe_hb.c:958\n\n8  0x00007ffff7e3b68f in dt_dev_pixelpipe_process_rec (\npipe=pipe@entry=0x5555573d9210, dev=dev@entry=0x555557407890, \noutput=output@entry=0x7fffb77e7468, \ncl_mem_output=cl_mem_output@entry=0x7fffb77e7470, \nout_format=out_format@entry=0x7fffb77e7478, \nroi_out=roi_out@entry=0x7fffb77e6d40, modules=0x5555572ec840, pos=32, \npieces=<optimized out>, pieces=<optimized out>)\nat /home/obry/dev/OpenSource/builds/darktable/build/src/src/develop/pixelpipe_hb.c:599\n\n```\n. Sorry I missed the more important, it reproduces only when using the optimizer. Set the 3 factors, click optimize luma got to lighttable and quit darktable. In most cases I get a crash.. Seems like the crash is fixed. Cannot reproduce, same on your side now?. And related to OpenCL, I cannot reproduce with standard code path.. And when I replace colorbalance_cdl() implementation with a simple call to colorbalance (in extended.cl) I don't have the crash (the image is not correct of course). So it looks like the issue is in the CL code in colorbalance_cdl(). Now I'm far from expert in OpenCL :(. When I'm leaving dt I get segmentation violation ini different part of the application (not always the same). This seems to indicate that there is some memory corruption somewhere.. Ok, no more crashes!\nAnd indeed valgrind (I run a session last night, very very slow under valgrind!) told me that d->luma_patches_flags[GAIN] = 1; was writing 4 bytes out of bound!\nSo you've found the offenders :). No more crashes but I cannot run the optimizer.. Yes, all good now! Thanks.. If I agree that this can be useful for the retouch module it is also the case for the spot removal module. But there I'm using a key to add circle and I find that having a handle on the keyboard and one to place the spot with the mouse is just good. So all in all I'm not sure the extra complexity here is really needed. Better to add a key binding for the different tools? Have you tried?  . I tied it, and found the view of the source not easy to use. I do prefer the click on the dest and drag to the source the mouse.\nI would certainly split this in two PR. The first for the keep adding and one for the view of the cross (source created).\nNote that the cross in the relative position does not seems to be correctly placed when using the relative mode. The absolute mode looks ok. Trying again to see if we can found a pattern... but now I cannot reproduce.\nIf we go with that we probably want the very same behavior in the spot removal module (keep adding).\nBTW, I'd love to have feedback from more people, so if you are reading this... :). I did a second pass and I'm starting to understand and appreciate the usage.\nTo me here is what is missing:\n- indeed the point 2 above, trace for the brush would be nice\n\nif I'm not mistaken the only other place where we have a clone is on the \"spot removal\" module and I would like to have the same behavior here. It would be a shame to have two cloning tools working differently and not supporting the same level of usage. As you already have the cross and relative/absolute position of the source in \"spot removal\" it just remains the continuous add support.\n\nI did a first pass on the code and don't have comment, sounds just correct to me.. I see your point. I always thought that retouch is for retouching skin and you do imply that the retouch module is for everything (spot removal + skin retouch...). And I start thinking alike. So let's forget about the spot removal for now. Thanks again for your hard work.. The brush continuous mode seems to be always activated, to reproduce:\n- open a picture\n- open retouch iop\n- do not change any default\n- click on brush\n- click on blur\n- apply a brush\nwhen releasing the mouse the brush is still selected. BTW, I have the same behavior with the circle  tool, probably with others (not tested).. No more comments. All good now. Thanks.. That's strange I have never crashed the module. I'll try with more masks overlapping. Please do not hesitate to give more information to reproduce if possible.. BTW, Is that only since the continuous add implementation in this PR?. Closing as integrated.. Thanks, merged now.. For me this always place the mask at the center of the picture and not at the center of the current view (piece). So if if the center of the picture is not visible you won't see the mask.\nIn liquify I have the masks always at the center of the current view.. Working thanks!\nOne question I thought you had also implemented the mouse_leave action to draw the current mask on the center of the screen when leaving the darkroom. This is not working anymore.... Any news? I'm closing this ticket. Just speak up and we'll reopen. Thanks.. Code looks good but I cannot reproduce the issue. Do you have a step by step way to check this? Thanks.. Reproduced. Thanks.. Please see : #1776\nThis should make everybody happy hopefully :) . Closing, I have merged the other PR. Thanks Aur\u00e9lien for starting the discussion about this, this has sparkled interest about this reconfiguration.. There is a dead-lock if you use the aspect-ratio filter while importing new pictures. To be fixed.. Cannot reproduce this lock, looks like a transient issue not relation to this PR.. I'd like some testing, if you read this and build darktable. Please test and report here. Thanks.. Should be fixed! Thanks for reporting this case.. Ok, let's merge for a wider audience then. Thanks for the feedback.. Still some issues on the diaporama view now. Each time I enter I get 5 times the following message:\n(darktable:6174): GLib-CRITICAL **: 23:17:37.145: g_strlcpy: assertion 'src != NULL' failed\nI'll try to test the capture view tomorrow. But I suppose it also needs some fixes.. Just noticed... \"diaporama\" in my first comment is the French for slideshow :). Indeed! So all good there.. Sounds good! Thanks.. We still have issues with this, it crashes darktable-generate-cache tool.\nAnd I see here, 2 calls:\n_unregister_custom_image_order_drag_n_drop(self);\n_register_custom_image_order_drag_n_drop(self);\nWhy is that needed? You unregister and register the same actions! I have removed those calls on my side the drag&drop seems to be working. Is that really needed?  . I'll revert this part for now, a crash is too bad.. > The unregister removes all connections (if there are any) whereas the register, connects only\n\nif we are in light table and sort by custom order.\n\nOk, but do we need to do that every time we updade the collected images? In all case this should probably only happen in GUI mode, no? This could explain why darktable-generate-cache is crashing?. But my question is why do we need to unregister and register again. This seems independent on the actual sorting, the actions are all for drag&drop on the gui. So what is the scenario where this is needed? I'm asking as after removing the 2 calls to fix the crash, the \"custom sort\" seems to still be working. I may be missing some corner case.... I see, so it is probably more appropriate to move those unregister/register in _view_lighttable_collection_listener_callback as _update_collected_images is called in more cases.. Thanks!. I think that this has broken the \"zoomable light table\". It is not possible to drag&drop the pictures on this view. Can you have a look?. Sorry I wasn't clear. The issue is not about the reordering, what I suspect is that the reordering (hence this commit and others about \"custom sort\") have broken the \"zoomable light table\".\n\non the light table\nselect the zoomable light table (combo box bottom - center)\nselect sort by filename\nclick on an image and try to move the zoomanble light table.\n\nThis last step won't work. It was possible to move around the content of this lightable. I suspect that the new drag&drop support added has broken this part. But I may be wrong, just a suspicion.\nLet me know if you can reproduce.. Ok, I did a bisect to be sure about the point of regression, the culprit is:\n886fab099ea629cdd8160abad204144adfa56147 is the first bad commit\ncommit 886fab099ea629cdd8160abad204144adfa56147\nAuthor: monsieurmona monsieur.mona@gmail.com\nDate:   Mon Oct 8 20:56:49 2018 +0200\nStarting with this commit it is not possible to move the content of the \"zoomable lighttable\".\nSo my suspicion was correct :). No, disabling reordering from the \"zoomable lighttable\" is ok to me.. Same remark here (see #1753), without tweaking the graphic, do we get the same result than before?. I've tested it, this is really nice. But please if you read this test it before it is merged. I'd like to have this in 2.6, so more testing would be nice.. All good now too. Thanks.. Do you confirm that without touching the GUI to adjust all or R, G, B channels individually the actual result is exactly the same as before? That is, the wavelet strength is working as in the previous implementation. I'm asking, because a very important point here is to keep a simple usage for this module while allowing some more tweaking on the channels. . Forgot to say, I've tested that on a quite noisy picture and I'm impressed by the results!. I've tested it, this is really nice. But please if you read this test it before it is merged. I'd like to have this in 2.6, so more testing would be nice.. All good now for a wider audience! Thanks.. The other modifier can be : GDK_MOD1_MASK (corresponding to ALT key). . Working for me, you need to also add the support for it in masks.c\nin dt_masks_set_source_pos_initial_state:\nif(state & GDK_MOD1_MASK)\n    gui->source_pos_type = DT_MASKS_SOURCE_POS_ABSOLUTE;\n  else if(state & GDK_SHIFT_MASK)\n    gui->source_pos_type = DT_MASKS_SOURCE_POS_RELATIVE_TEMP;\n  else\n    fprintf(stderr, \"unknown state for setting masks position type\\n\");\n. @edgardoh : ok, I let you handle this and yes the ctrl-shift sounds good. Thanks.\nI'm closing this.. Previous PR was here #1730. BTW, Aur\u00e9lien better to no commit the fr.po in a PR as this file is almost fully changed every time and so there is big chance that we get conflicts.. This is now open to a wider audience for testing purpose.. Good thanks.. @edgardoh : I think I have fixed this issue.. Cannot reproduce either on my side. All works for me, I have tried with the smallest brush possible.. I have it set to medium. Maybe related to memory???. Just saw your reply Aur\u00e9lien, strange indeed !. Good thanks!. See https://github.com/TurboGit/darktable/tree/piwigo\nIt's done :). Yes, but not 2.6 as we are in feature freeze. So, it will be merged in 2019 and available on the dev version soon.. > So, now it's somewhat frustrating to hear, that this work was all done. ;-)\nNo, you're now ready to implement some others like SmugMug or any other services around :). I'm not sure why the \"legacy\" should be proposed as a thrid option?\nFor sure we need to keep history and not break it. But in such a case I would just keep the legacy code \"hidden\" and used for old history using the colorbalance. Can this be done here?. I see, yes some other name will be better I think:\n- lift/gamma/gain (legacy)\n- lift/gamma/gain (ProphotoRGB)\nOt some better name in parentheses you could propose?. I would just remove \"legacy\" in the last at this point since you have sRGB.. Let me do that, I can handle it :) Thanks again for the contribution.. Thanks for reporting. Point 1 and 2 should be fixed now. I have also fixed the case where we copy/paste history as we possibly change the aspect ratio too.\nFor point 3, this is expected I think. Computing the aspect for all pictures currently in the db could take a very long time. This is so done in chunk of 5s. If we time-out when end-up with a mixed order in the lighttable. The next time the remaining pictures will be handled. And this possibly 2, 5 or 10 times. Then when all the aspect ratio are computed we are fine as we update when needed aspect for touched pictures only (leaving darkroom, changing orientation on the lighttable, using copy/paste or discard history on the lighttable).\nFor the record, and as noted in my log message, on my computer I needed a bit less than 20s to update 50k pictures.. Thanks!. Thanks!. I have a better solution.. I have a better solution.. I have a better solution.. Just found out that changing the grey-fulcrum does nothing until we have changed contrast too. Is that expected? That's not a regression due to this patch as it is already the behavior on master. Just checking.... Perfect then, thanks.. I can reproduce indeed! Really strange the bad interaction between both modules.. I'm no Windows expert, nor do I use Windows but I trust you :) Will merge. Thanks.. All good now thanks for the quick fix.. Indeed, not even a warning.. The \"mavx2\" option is supported by GCC version 4.7 and higher. Are we sure all distribs are ready for that? I kind of remember a discussion about this on the mailing-list where some distribs were really lagging behind and I don't remember what is the oldest GCC version dt is supporting.. Ok, safe on the darktable page here (https://www.darktable.org/install/) it is said that the GCC must be >= 5.0!. Ok, so let's go for it.. Thanks Roman. So I guess the only option would be to check for the availability on the CPU at configuration time.. I'm not sure about this one. We don't have a single color option in the preference actually. And the solution is to change the CSS to setup a color. So can you clarify why this is needed here? Why not change from a CSS? I can't imagine a preference entry for every single configurable color :). @maf : exactly what I said, it is so important than having preference for a single color is not a good solution. We can do that properly in CSS, or we need to provide a full preference tab to be able to change ALL colors.. Nice! One question do you think it is possible to always open in the same tab? I tested and after 30 clicks or so I had 30 tab opened in Firefox. I'm not sure we can control the tab when opening a new URL from outside... But just in case.\nI'll look at the code soon. Thanks.. One point that could not work except in some countries is the dot vs coma returned by atof(). In France we use coma, but SQLite3 ask for dot. And as I said there was also precision issues and some pictures were not displayed (10 in the count(*) in the collection and only 8 in the lighttable for example).. An alternate solution for #1745 . @aurelienpierre, yes it will be quite a bit of work, 3 or 4 times the time to implement this PR. My idea with this configurable layout is to be able to create a script to select different layout if needed. We change very rarely the iop layout.. Note that I have just pushed an easy to use script to allow configuration of the darkroom.. @aurelienpierre : thanks for the preferences. see my script tools/iop-layout.sh you can probably adapt it and we can commit it.. @aurelienpierre : no problem! have a good night!. Should be fixed in another commit.. Indeed, I missed that during my review :( We don't want to use bool! Thanks.. Good! Thanks.. Looks ok.. But there is little chance that the patch will fix the issue if any. Even if I agree, as long as we don't know how to reproduce and what is the actual issue there is no possible fix.. Well, I agree with all of what you said (I know what an overflow is and the security issue it can bring) but yet the issue is unknown and probably not solved by your patch. I'm sure you'll be able to reproduce with it. So we need more information, more check, more  backtrace and a way to reproduce if possible.. Obviously good! Thanks.. Looks good. Thanks.. Do you have a usage of this or is that just for the challenge :) ?. Ok, let's see what others think about this. Not a large piece of code, so probably not disruptive, but yet I do want to be sure it is useful enough to be integrated.. Oki, let's plan this for 2.8.. manually merged.. When I saw this I said why not! But I'm wondering if we want to introduce some random/artistic effects like this we could have lot and lot of IOP at the end. So I'm wondering if we don't want to have a generic effect like IOP and a combobox to select the effect. Not sure, just starting a discussion in this direction. What would be the pros and the cons? . @edgardoh : sorry I didn't intend to say that you've randomly chosen a GIMIC filter, only that such filter and many in GMIC are kind of random in the sense of you do not use it to achieve some precise goal as you can't really guess what will happen on the picture before hand really. With this module for example you drag some sliders and some effect are coming and passing and even at some point you seem to have globally the same effect with different values of the same slider. That's why I call this random. Hope this clarifies my thinking :). @edgardoh : otherwise yes I guess a generic module won't fit the current architecture.. Sounds good. Thanks.. Thanks! That's nice to fix all those small details that make a real difference!. This need quite a lot of testing and I fear it will break the history. The issue is with the back-transform, if one has put a mask on some IOP it needs to follows the transformation. IIRC we had some issues with the liquify module for example. There is some corner cases where the transform/back-transform is not accurate and then the mask is slightly moved around. I'll try to find the discussion and the example I had at that time.. This is a very delicate PR for the transform and back-transform. I had no time to check that all is right with the masks when put before and after in the pixelpipe.. Ok, I have found back my test image with the issue of transform/back-transform. This was due to the lens correction module which do not properly keep the mask position in monochrome module. I have also tested with the exposure module which comes before lens-correction and crop&rotate (now) and the masks position is \"broken\" the same with or without this PR.\nSo, all in all, I'll merge now. Thanks.. BTW, I'll do a manual merge with conflicts resolved.. Thanks!. For 3 I found that there is less details in the new version. The image is smoother, less noise but not as sharp.. Tested, effect looks good and indeed the time is never a problem with this implementation. Let's go for integration and have more field testing. Thanks for the contribution.. @rawfiner , this gives lot of troubles I'll revert today until the issue is resolved.. @rawfiner : we need to be more cautious this tine.\nIn 1 I read \"similar visual effect\" is that similar or identical? Won't that break also the old history too? If it is faster and identical I would say yes, we want this.\nFor 3, it seems sound to me to go for it.. @rawfiner : Ok, I understand that there was no radius slider before. but there was an hard-coded value in the code. My question is then, with your proposal do the default gives the identical result? This was the case with the slider @hanatos has merged recently, it was just exposing the hard coded value with a default being identical.. Nice code clean-up. Thanks.. Sounds good. Thanks.\nOne question, do you foresee a fix for the LittleCMS case?. Looking at the code I see that raw_ [ch_L] are two order of magnitude larger than the corresponding Y_picker_.\nAlso, I'm not sure why you set the raw_[ch_L] but this is what cause the trouble with the picker. What's the point, since the picker will reset those values, no? And you well get them back on next iteration:\nraw_mean = self->picked_color;\nraw_min = self->picked_color_min;\nraw_max = self->picked_color_max;\n\nBut I don't know well this part of the code.. I have I think the explanation for the why:\n1. you get the picked L\n2. you convert to XYZ and Y is a bit less that L on the raw_[ch_L]\n3. you stuff this lower value into raw_[ch_L]\n4. the mouse move over the tone curve, each mouse-move you redraw\n5. you get back to 1, read the now lower L value, redo the computation L becomes lower and lower\nAt the end it is 0.\nYou can see that sometime the colorpicker red area on the tone curve gets moved to the left.\nSo the actual circuitry in your code is wrong. Hope this helps.\n . @aurelienpierre : what about this branch? do you plan something for 2.6? thanks.. Again really nice! Thanks Aur\u00e9lien.. @aurelienpierre : testing more today I found a quite annoying issue! The colorpicker zone displayed in the tone-curve is wrong and seems to not match the actual selected area. Indeed, changing the curve in the area does not change the color-picker zone. Can you have a look?. @aurelienpierre : some more testing shows that all is fine for the two Lab color-space. But completely off for RGB and XYZ.. @aurelienpierre : really not sure about this, but here is a possible fix and my thinking to come with that.\n1833 . Thanks!. Good catch! Thanks.. Perfect! Fixes a recent(?) regression as I'm sure I had tested that not so long ago.. I see hat in redmine #11956 you're talking about a version without copy. What happened to this? Was there still issues with it? . I'm sure it was not a good solution since you've deleted the branch. I just wanted to know more about this issues. Complex? Not stable? Was not fixing all cases?. BTW, I'm just asking as I think it could help understand this PR and help the review.. Forgot to say, there is conflicts to be resolved. Thanks.. Indeed. Better thanks.. Works fine. Thanks.. Thanks fantastic work! I'll test... To tell the truth I'm a bit nervous about this one which is touching some delicate part of the code. We need to test, I'll do that right away.. Ok, tested and working fine. I did not spot issues on the code, let's merge this for a wider field testing.. Looks good to me.. This is not ready. We get again lot of structured lines (grid) when the cursor for coarse-grain changed.\n\nI don't have this with current module. Sure if you push the cursor it may be quite CPU hungry, but at least not artifacts.. I forgot to say that my screenshot was done when dt was at a zoom of 160%, we don't get the same effect at different zoom level.. Well testing again but we still get some wrong results. See the screen shot. We have two options:\n- use current version, it use lot of CPU when moving search radius\n- use your version, fast but tends to produce some random results\nNo local-means, just chroma denoise:\n\nLocal-means, zoom at 157%:\n\nLocal-means, zoom at 193%:\n\n. @rawfiner : no moving does not seems to change the issue. I'm on GPU. Yes it is somehow visible at 100%, but a bit more difficult to see.\n\nI did not understand that the artefacts were a preview issue\n\nI don't understand this one.. This is frightening :) I can't reproduce the issue now with or without OpenCL, but the screen shot are there, I have set the very same value... No grid, no banding issue... Frightening! There is something wrong going on.. Ok, tested again with different picture and seems better to me now. I had no grid-like pattern. I want to test it again later today with another picture. If all goes well I'll merge today.. @rawfiner : this is still not working, on my side I have a large band of blur at the bottom of the image (bottom of the lighttable view). See screenshot above.\n\nAt this stage I'm not sure it is safe to have this included into 2.6. Maybe next cycle?. @rawfiner : #2000 is now integrated. let me know if this is ready or not. thanks.. Tested and I cannot reproduce the issues we had before. Seems like this is good to go in. Thanks.\nI'll just use  \"scattering (coarse-grain noise)\" for label instead of \"scattering (coarse-grain noise reduction)\" which is too long and mangle the values at the end of the slider. Hope this is fine with you.. It happens, rebase if possible and push again. Anyway I'm having a look at this at the moment.\nHave you tested this to death ? :) This is again a tricky part, thanks a lot for looking at those difficult issues!. I've tested that, it works great on my side. That's a very nice enhancement/fix. Thanks.. I see, this makes sense but is a very delicate part. I'll merge now, hopefully this wont break the different builds.. @LebedevRI : as said above I fear that this was a delicate issue and would broke some platforms. if I see no solution I will revert.. Ok, let's revert this. I don't have Open Suse to test anyway.. Can you give a bit more information about the way to use it? It will help testing... Thanks.. Also as we are very close from the feature freeze, can you describe more the actual algorithm behind this? To be clear my fear is that is not full ready and if we want to improve later we'll break history or we would have to support multiple algorithm on the blend layer. Not something we have at the moment. I would have like to see that earlier to have more field testing. Now if the algorithm are safe or state of the art I think it can go. All in all I'm seeking more background information about this. Thanks.. @rabauke : and what about the feathered mode which seems not working with parametric masks? Can you describe the way to use it?. @Kabouik : if you can test it it would be great.. @rabauke : I can't make this working... sorry I really need more information about the way it is supposed to be used. Do you have an example?. Ok, thanks for the example and the code fix! I'll have a look again.. @rabauke : please can you remove rawspeed update from the following commit: e953a6. @rabauke : not sure you've seen but I have request some changes.. Another question, with the default parameters the blend is 100% identical to previous version. Right?. @rabauke : my question was more to ensure that the current implementation does not break history and that the default behavior without the two new sliders is 100% equal to the current implementation. That's what I think from reading the code, but just wanted to be sure.. Ok, thanks! Let's go with it and have more field testing. Thanks!. Sound good! We had discussed that with Aur\u00e9lien some time ago and were surprised that the const was accepted here.. It was a compilation issue.. @aurelienpierre : the \"balance shadows-highlights\" seems working on the opposite order. It says give more room to shadows or highlight. When I push to the right to 33%, I would have expected to make more room by 33% to highlight, but it turn out that the shadows was more present in the picture.. Just wonderful work! Thanks a lot Aur\u00e9lien for your work on this.. Great to see this fixed. Thanks. . Thanks!. I understand, we are very close from feature freeze.. @cryptomilk : done, make sure to update the faster-lighttable branch as I have fixed a refresh when changing collection. TIA for testing.. On a 4k display?. Also, what should be really faster is the mouse over and the follow of the highlighting of the picture under the mouse pointer. If think this is more visible when you have more than 10 images per row.. Ok, 1s is not good but how much time did it take before? About the same time? If so I'll just close and forget this PR :). Ok, too bad I had hoped :) Closing. Thanks for testing on a 4k.. Another attempt here: https://github.com/darktable-org/darktable/pull/1973\nIf someone can test and report the perf.. Thanks!. Sounds good! Thanks.. A nice one! Thanks.. I think this is the first time I see GUI code in process(). This must be avoided to me it is wrong to do that.. In exposure() what is done is use a callback on the \"draw\" signal for the widget to get the picked color if I'm reading the code correctly. Can't this be done here?. @moy : see #1819 I still have an icon status issue, minor but annoying, but at least nothing done in process(). I'm not sure to be able to fix that today. If you have an idea?. There is a GUI issue on my side. Click on one picker, click again on the same picker. It says with an active state.. BTW, isn't the callback just before process() the routine commit_params()? Would it work better to use this instead of draw()?. \n\nIs there a documentation about all this somewhere?\n\nNot that I know.. > Both work for me. Can you give more details on what you did so that I can see what's going on? When you say \"active\", do you mean the picker is active (drag on image draws the rectangle) or just the icon is still white?\nYes, that the picker stays white.\nI can reproduce on all pickers:\n1. click a picker\n2. the area appear on the picture\n3. click again on the same picker\n4. the area disappear from the picture\n5. this picker icon is still white as if selected\n6. click on the image and the picker is not white anymore, meaning only the icon was not refreshed. This is very strange, I still have the same issue.. Yes, this is called, it seems that there is no redraw of the widget. As I said as soon as I click on the image I do have a draw signal (tested by adding a printf() in the draw() callback) and the icon are properly refreshed. So all this is just a refresh issue!. I have a solution. No time for now. I'll propose a patch over this PR.. Merged with my fix. It was a nice case :) Yet I think we should have a better support for colorpicker and code sharing for all modules. It is quite painful to have to deal with all those details in all modules :(. @moy : I'm on that. Should have something by tonight. The factoring of code is done for filmic.. @moy : done, if you have a chance to do some testing do not hesitate.. > The \"auto tune\" button in profile_gamma.c, and \"optimize luma\" / \"neutralize colors\" in color balance are still broken the same way as the old \"auto tune\" in filmic. Using the color picker API there like filmic should solve this.\nI don't follow, profile_gamma and colorbalance are now using the color picker API.. > Changing mode in color balance should probably deactivate the picker.\nDone. Also resetting picker status when changing controls.. @moy : yes looks like running from build-tree is not working. Right! Good catch, will fix.. I saw that. Just don't know why yet.. I think we are facing a Gtk bug. This is just a redraw of the icon issue.. I have restored the label, sorry a cut&paste error :(\nFor the colorpicker in color balance I think I have kept the previous behavior (using the selected region if any).. Maybe we should change the label of the color picker when the 3 luma patches (or color patches) have been selected from : \n- \"optimize luma\" to \"optimize luma from patches\"\n- \"neutralize colors\" to \"neutralize colors from patches\"\nWhat do you think?. Do you want to work on that? Or should I go with this.... Done. Also, I think I have fixed the redraw issue. Was due to some missing redraw in the bauhaus widgets. . Obviously correct to me. Thanks.. @LebedevRI : this looks like it works, are you ok for a second try? We'll revert if it breaks things again.. Ok, let's merge and see what happen!. Note that this does not work as expected. Running dt from the build directory still uses the IOP module from the install directory. Any chance to fix that, or should I revert? Thanks.. Sounds good. Thanks.. just force push on the same branch:\n$ git push -f nach master. Sound ok. I'll do some reformatting, please make sure to follow the dt style. . I have a scenario where this does not work:\n- with 3 pictures\n- open the first one\n- with exposure create two circle mask (push exposure to see the effect)\n- go to lighttable\n- copy the exposure from this image\n- paste it on the second and third image\n- open first image remove the two circles from the exposure module\n- open the second do the same\n- open the third, when you remove the first circle the effect is still on the image . If it happens already let's open a new PR and I'll merge this one. Thanks.. The curve is only a view and cannot be controlled directly. This makes the curve a bit less fun but why not. Otherwise when I change the grey slider the curve does not change as for the black and white slider. . @aurelienpierre : ok, thanks for the feedback. Not sure but I find the saturation slider less effective. Even pushed to max the saturation is slightly pushed on the image. I kind of remember that it was more effective in previous version. No?. Again thanks for the feedback. I'm asking just to be sure there is no issue before merging as this module is very new to me :). Ok, sounds good!. This does not compile:\n```\n...darktable/src/develop/blend.c: In function \u2018dt_develop_blend_process\u2019:\n...darktable/src/develop/blend.c:3005:11: error: \u2018guide\u2019 not specified in enclosing \u2018parallel\u2019\n           memcpy(guide + oindex, (float )ivoid + iindex, sizeof(guide) * owidth * ch);\n           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n...darktable/src/develop/blend.c:2999:9: error: enclosing \u2018parallel\u2019\n #pragma omp parallel for default(none)\n```. Breaking edits with current Git is not a problem. Until 2.6 is not out we can break anything :). Note that the feature freeze is tomorrow. Do you plan to have those new features ready tomorrow or will it come at an addition on next development cycle?. Nice! I'll have a look asap!. Sounds good thanks.. @rabauke : understood! all this will become clear with the documentation.. This last one is quite bad!. @upegelow : I agree that there is quite a lot of controls, the idea to have a combo with two options (just blur as before and guider filter).. @upegelow : I have fixed the blending legacy support, a cut&paste issue!. This is strange. I have just rebuilt an old darktable and then with current master I have:\n\n[imageop_init_presets] updating 'exposure' preset 'testblend' from blendop version 7 to version 8\n\nAlso the old edits are now correctly upgraded. The preset testblend is a parametric on hue and with a blur mask, everything is properly upgraded on my side.. @upegelow : do you restored data.db and this time all was properly migrated to latest version? does that means that there was a transient issue?. Ok, thanks for the feedback, we have a big issue to fix then.\n@rabauke : hope you'll find time to work on this.. > Whatever happened: all settings which have been converted recently to this version are screwed.\nI confirm. But I took a data.db backup and started again darktable. All my presets have been migrated properly with the blendop parameters. So to me it looks like a transient issue that has been fixed in current master. That's sad, but always possible for us working on master :( As dev we really need to have a backup, you had one and I had one too.\nYet, we need to double check that all is under control now.. Ok, here is what is happening:\n1.  in c94173f9 we have the first new blend version 8. the legacy is working\n2. in 0b073023 the params change but we keep version 8\nSo every edit done with 1 are lost and preset migration are also broken.\nTo me all is fine on master. And the issue is a transient one that can occurs on master.\n@rabauke : can you confirm that? . Hum... Indeed and this is missing from many migrations :( From v5 and v6 and possible others. Will fix that right away.. @upegelow : the best is to use your backup data.db (as you've explained above) to restore the preset. or maybe I did not fully understood the question?. Nice going! Let's see if @upegelow can get back the 70 edits.... @rabauke : the documentation has always been handled by @upegelow. . Sounds really good! Thanks.. I confirm, probably an issue with the saturation slider. On my side, tested on 2 pictures. The saturation does nothing (tested with a snapshot, no visible diff between 10% and 1000%).. I see, indeed very light change and expected as discussed in a previous PR. The two pictures where I tested before had very little lowligh.. Great! I had that on my TODO list :) Will check ASAP. Thanks.. Working as expected. Thanks.. This is better. But still using lot of space.\nWe have:\n- feature guide\n- feathering radius\n- mask blur\n- mask brightness\n- mask contrast\nWe could have:\n- mask tool (combo with blur, full)\nWhen blur selected:\n- mask tool   blur\n- mask blur\nWhen full selected:\n- mask tool   full\n- feature guide\n- feathering radius\n- mask blur\n- mask brightness\n- mask contrast\nAt the end, in full mode we have one more line :( Maybe we can find something better.. Which version? I have fixed that in commit 15ebdaaa.. A difficult discussion. I agree with Aur\u00e9lien. It would be terrible to simplify the UI to please beginners and to make expert loose time having to open multiple drop-down to find the good option. The balance is delicate to find.\nAbout the novice vs expert view... Why not having a preference for this. A simple boolean that will remove many options like the fusion algorithm, the masks blur and feathering, the log view of the tone curve... etc. This sounds like a better choice than having multiple drop down in my point of view. So maybe, just do nothing for this PR and let's plan something more challenging for 2.8.. Indeed \"safety factor\" is maybe more correct. But as you I'm not native English :). Thanks Aur\u00e9lien.\n@moy : ok so let's go with \"safety factor\" then.. I have conflicts!. Perfect thanks!. Close, see #1836. Thanks! I should have seen that :(. Working great now! Thanks.. manually merged. . Thanks!. Thanks!. You must not change rawspeed.. Because rawspeed has probably been updated since then and we will coordinate with Roman to cut a stable branch in rawspeed for the release. So, until then we do not want to update rawspeed submodule.. @edgardoh, sounds like another very nice move forward ! that's of course for 2019, looking forward to a stable PR about this. Something not clear (to me) on the description, is it possible and easy to define a new pipe module order or does that means recompilation? Also does all this means that for current edit the old order is kept to ensure history backward compatibility?. Hum, how much pictures to update? Maybe some missing index on some table?. Ok, I did build it for the first time, I wanted to see if it works on my side before going into a deeper testing. Some issues:\n\nopen tone curve\nselect RGB independant channels\nselect [b] \n\nBUG: see that the [g] and [b] channels have no histogram in background (red does)\n\non the [b] tab and move the curve\nselect scale : log-log\n\nBUG: the scale is not changed\nThe mask history is great! Masks feel first class citizen now! More later.... We have two big features in there: mask history and module order.\nDo you think it could be possible create 2 PR?\nThis would certainly help testing and integration.. Also, rgbcurve is crashing as soon as you try to move the curve.. I think that the rgbcurve, rgblowpass and basicadj modules should be removed from this PR. Let's have them part of a new PRs (one for each module).. In old edits with masks a \"mask manager\" entry is displayed in the history? Is that expected? I think yes reading the code, but I prefer asking. Also, why is this not needed for new edits?. The mask_history table is updated only when switching images or quitting darktable. This means that if a crash occurs we loose precious edits. Maybe we can write the masks history when switching modules? But this is already the behavior for standard history, so maybe better to do that part of a new PR.. @edgardoh : I'm not against the module, I think the basicadj is nice for begginner and I'd like to have it. But I would really prefer to have all those modules in separate PR.\nIt will make this PR smaller. If we need to revert this PR temporarily we will keep the iop. And all the dummy for for testing should just do in a specific branches. I don't want to have this in the master.. Ok, so please remove them now. I have tested this a lot, I have make many reviews so I think it is time to bit the bullet and merge this. Better sooner than later for this to be more widely tested now.. Ok, this is now merged. I have added a commit on top of this as the migration was not done after 40 minutes on my side on my full database (~ 55k pictures). With the new index it is done in 10 seconds.\nThanks again for the hard work! This is a really nice move.. For undo any procedure to reproduce? I had tested that yesterday and it was working fine a quick test this morning shows that it still works for me.. I see the undo issue now! ctrl-z does not work until ctrl-y is used, then all seems fine... I'll look at this.. This has broken the perspective correction, see:\nhttps://github.com/darktable-org/darktable/issues/2201. Thanks.. Thanks!. Sounds good and to me the last point is more like a fix than an enhancement. I'm one having trouble add saturation and with this new slider I get the result I want easily. Thanks for the work on this Aur\u00e9lien.. With this last version the 2 remaining presets are not working. It just does nothing.. Ok, Thanks!. If no more comment it should be merged to be part of RC0.. Please go ahead! I've been using a lot recently as I have moved to Piwigo :). Yes, I expect this to be in a minor release, maybe 2.6.1.. For the tree I understand, but the combo box does not support trees AFAIK. I'm no expert in Gtk! Maybe just by adding padding in front of the album names?. Hierarchical display of albums now implemented. Do not hesitate to test, it should help a lot when lot of albums are displayed.. I don't know how to fix your last report as it seems we have no callback when the actual storage kind is changed. What I have done is that after an upload is done the new album section is hidden. Hope it will somewhat makes the issue bearable :). manually merged.. I have libcurl4 installed on my machine and have no warnings. . Really strange! Maybe you also have libcurl3 and this is the one picked during build?. I have libcurl4 7.62 on my machine. So maybe a more recent version is needed. . Yes,, I working on that indeed, we cannot break builds on old machines. . @upegelow : can you test this https://github.com/darktable-org/darktable/pull/1940\n. Thanks. Merged! . Looks good now. Thanks.. @aurelienpierre, see my fix it was indeed the params itself the issue using wrong version and not the blend params which were properly handled.. Thanks.. We may add an assert() sure. I still don't understand how this can happen though :(. Thanks.. This introduces another issue. When you use the mouse wheel the ratio strength vector is not kept. Create a point, set strength vector to be about 50% of the radius. Use the wheel.\nSo better initialize the CONF_RADIUS at start if not set.. Probably in btn_make_radio_callback() at the end where we check if the key exists.. Yes, the patch above looks like what I was thinking about and yes probably the same is needed for r and phi. (be sure to move the { at the start of new line to follow dt style). Thanks.. Just perfect now! Thanks.. Thanks!. But fact is that the documentation will come a bit later than RC0 which I'll create this week-end if all goes well. So what's your take? Should we merge and adjust if needed?. Sounds good! Thanks.. In Debian experimental we still have 0.27 so maybe this can wait for the 2.7 dev release and possibly one of the corrective 2.6.x releases?. Ok, it makes sense to integrate this in 2.6 then. I'll check and merge if possible.. Let's this be in RC1 then. Thanks.. Sounds like a good idea indeed. Thanks.. Any news on this? Thanks.. Should I close this or do you plan to work on this PR?. No feedback. Closing for now.. @edgardoh ok with this?. Agreed. Makes senses and will certainly help usability. Will do that right away.. Done. It indeed makes things clearer to me.. @edgardoh : the most important point is having the tools and the tools options close to each other. So another option is to move the tools options above the wavelet decompose section. Would this be ok?\nFor the tools I'm using the brush more often :). > If that's the case, I place it last because the only algorithms that have a property are the blur and fill with color\nNo, there is also always the opacity. And for me I'm using the blur a lot as this is a good way to remove artefacts from the skin on different scales.. Ok, so let's go for this. It is actually what I have done in this PR.. I did some test and found that the lossless mode is now probably 20x slower.\nI took a RAW, exported lossless, 95%. It took 10s or so with previous version and more than 3 minutes with this version.\nCould this be because of the alpha encoding to \"exact\"? Is that even necessary for pictures?. Ok, thanks. Merged to master.. Roman, nothing fun to me. This has been rebase and merged manually to allow merging into the darktable-2.6.x release branch if needed. And in this case GitHub do not detect that the PR is merged.\nAlso, it is not broken. I do test every commit :) It is broken in one platform and probably because the webp library is too old here. I'll comment out the exact field for now.. Right, just check this. So I'll remove this field. I'm currently testing this works ok with recent webp.. was fixed manually for 2.6.. Working fine for me! Thanks.. Thanks will be part of RC1!. Thanks.. Just perfect now! Thanks!. Tested on many pictures that were causing trouble before and the result of the auto-tunner is far better now. I never get a strange curve! Great work.\nFor the nodes to me it is ok but I have no strong opinion. To avoid the issue Ulrich is describing maybe instead of nodes we can display small vertical lines? This will make clear that those are separators. What do you think?. Also, this version does not keep history! My previously edited pictures are all off! Or did I mess with something else.... Maybe, let's go with plain circle. A bar could be barely visible on some slope of the curve. . @moy : it is too late for the tooltip for 2.6.0.. Thanks that's a nice clean-up.I too find the curve welcomed, I also think that such a curve is well-known by the photographers as it is the very same we have on the tone curve for example. So to me the added value is clear. We can always revisit this later.. Sounds good! Thanks.. I have something very strange with this PR. Take as an example the image you've used at some point. When I used the auto-tuner I get a curve all against the left side of the display. See screen shot:\n\nAnd in many cases the image with the auto-tuner is full of strange color. See second screenshot:\n\n. But that's not my parameters. That's the parameters of the auto-tuner :). Thanks for the notes. I have tested the auto-tuner on more than 20 pictures. It always works great on landscape pictures. I have some problems as described above but globally it works in more cases to me. So, that's a good move forward and a nice stabilization effort for 2.6. Thanks. . Yes, in that case you need to manually set the black/middle/white points. The auto-tuner cannot guess all the time the good values. Note that it works fine on HDR images and landscapes for example. On low-key, high-key and noisy pictures it may not be the right tool. Aur\u00e9lien will correct me if I'm wrong.. Indeed posix semantics says that if x is 0 then sqrtf(x) returns 0. But is that true on all platforms?\nFor example on Windows it does not seems to be the case, at least with a quick search I was not able to find this explicitly documented. . Sorry... sometime I need to sleep more :(. Aur\u00e9lien, this is a HUGE improvement. I have tested on my set of pictures. No more strange colors, the auto-tuner seems to really work in lot more cases. This is day and night, really. Thanks.. Is that a validation only issue or it makes the profiles denoise module unusable?. Ok, so let's merge this.. Looks good, let this in RC1. Thanks.. Ok, this new version just disable deleting the last clone and when it is the case the X is not visible anymore.. Do you have an updated backtrace?. I have created multiple clone and deleted always the first one. No crash and all this running under gdb!. Ok, so let's go with this. Hopefully it is fixed or we will get better bt next time. Thanks.. Merged with a little edit.. I'll have a look.. A guess, a possible race condition. Can you test #1885 ?. Good, thanks for testing, those race conditions are very hard to fix as it may or may not be reproduced. As in this case, I don't have crashes.. Thanks!. Good point! I'll add that, consistency is a very strong argument to me.. manually merged.. I'd like also this to be rebased on master to avoid all the merges in the history. Can you please do on your branch:\n$ git checkout lp-fulcrum\n$ git fetch origin\n$ git rebase origin/master\n$ git push -f phweyland lp-fulcrum\nThanks.. Ok,not sure what is happening. I'll clean-up before merging.. Closing then. Thanks.. Well we've been discussed that! At least Ulrich and I agreed for the current ordering. IIRC you had no strong opinion. So to revert we will need a poll :) We cannot satisfy everyone. I have myself used the new layout extensively recently to develop portraits and must say that I much prefer the current layout. Note that I have a strong opinion for having the brush first for consistency reasons.\nSo, yes a poll... I cannot go one way and another. But I can assure you that if we have many people asking for this PR to go in with good arguments, it will.. @edgardoh : I suppose this won't change at this point. I'll close this PR. If you want this to be re discussed fell free to reopen. I'm ready to change my mind if a majority if for the previous layout.. > Input dialog can only be canceled via ESC key.\nOr enter without entering a value. This works for me and if it fixes the issue on all DE all good. Thanks.. Manually committed as there was some conflicts! Please double check that there is no issue. Thanks.. Sounds good thanks.. Looks good! Thanks.. Code is sounds and working fine on my side. Thanks. I really hope we are done with the auto-tuner code stabilization for a maybe final RC2. . Perfect thanks!. @wpferguson : wondering if the following fix is not better as it should avoid this issue for all modules.\nhttps://github.com/darktable-org/darktable/pull/1899\nCould you test this branch to see if it fixes also this issue? Thanks.. Working fine thanks.. Sounds good now! I plan to merge in 2.6.1, ok for you? . conflict resolved and manually merged.. Perfect !. Thanks for testing. I'll commit that for 2.6.0rc3 as potentially fixing crashes in other modules.. manually merged.. Thanks! Merging then. Just ready for rc2!. Sounds good to me! Thanks.. Perfect! Safe and looks a bit more pronounced effect now with presets.. Sounds very promising!. Just tested, quite nice indeed. The transitions are \"smoothed\" and so the tonality are pleasant. Nice work.. > darktable/src/iop/toneequal.c:818:11: error: no member\n\nnamed 'priority' in 'struct dt_iop_module_t'\nmodule->priority = 158; // module order created by iop_dependencies.py...\n\nThis is due to yesterday merge. The module must be adapted to new API.. Merged.. Merged manually. Better sooner than later, but this new version seems correct to me. Thanks.. Thanks, manually merged.. manually merged.. Thanks!. All good, thanks!. Thanks!. Merged manually with fix for all translations.. Do we want this in 2.6?. This sounds very safe and UI only, so I'd say yes.. Sounds like we also want this in 2.6.. manually merged.. manually merged.. Thanks!. Perfect! Thanks.. Looks good now to me and I agree that it is a good move forward. Having those weird colors is quite disturbing.. Thanks!. manually merged.. I'm not sure about the module you're using maybe \"global tonemap\" and so the behavior is correct. When you activate it the tone in the image are remapped, this is a complex algorithm that do change lot of value in the image. And it is also expected that the histogram changes to correspond to the new tone in the image.. Looking closer it seems yes, but then there is a missing slider at the end! Not sure what is this version!. @stilicrafter : can you tell us where you have downloaded this version and which actual version it is?. All done, thanks!. But some people are using it, I do use it from time to time and it is quite handy to be able to develop immediately as it is imported automatically. Sure it lacks features, but well for my use (and probably others) I suppose it is enough.. Forgot this one for 2.6 :( Well, it will be part of 2.6.1.. manually merged.. Note that this is supported by GCC 6.0 and above and current dt still supports GCC 5.0.. @darix, since the compiler will select whatever is available on the target, won't this be nop on ppc64ie and aarch64.. Manually merged. Thanks.. Note that in the retouch module we have something similar. A ctrl-click on the tool activate the continuous mode. And we just click back on the tool when finished. I'm wondering if for consistency reasons we should not do the same here.. @Lirein : Any news on this? Do you agree with the approach proposed above to get consistent behavior?. Ok, no comment, no feedback, closing for now.. Tested by different people and myself. No problem. So there is something with the environment.. > I would disagree.\nNot sure to what you disagree... I said it seems to be due to an environment difference and it works for me and many other people.\nNow what is your Windows version?. Nice demonstration, now how do you explain that it works for me and some other people?. Sure, closed. Thanks Peter for looking at this.. What is you graphic card?\nCan you try with OpenCL disabled:\n\n$ darktable --disable-opencl. Closing as resolved.. Sounds harmless to me.. Thanks.. Yes, expected as I did not sign the release.. Indeed an intended change in 2.6.. Ok, looking at the doc it seems that this was added in 7.56.0. So indeed quite restrictive change. Let's adjust this now.. Manually merged in master and darktable-2.6.x branch. Thanks.. Manually merged. Thanks.. Maybe we want this in 2.6.1? Sounds quite safe.. Sound good to me now. Thanks. Manually merged.. No, not only bug fixes for 2.6.1 but bug fixes and ultra-safe enhancements. What's your take?. @aurelienpierre : see my fix just pushed. I have removed the autoapply from D7200 and setting the pref auto_apply_percamera_presets to true I have been able to have the D7200 base curve applied automatically. So to me all is fine now. Can you double check? If ok I'll merge this in darktable-2.6.x. Thanks.. Probably because autoapply is set to 1 in data.db because of the wrong code just fixed.. Confirmed, I've just reset the autoapply in data.db for some cameras and now the setting is honored.. Hum... My bad, it is already reset but you need to exit and restart darktable and init_presets() is called once when starting darktable and just changing the pref won't help.. So to me current committed version is ok.. Do we really want to deprecate \"spot removal\" ? It is easier to use than retouch, it has been used since years by many people. I would keep it but have it not selected by default. But I have no string opinion on this.. I'm not really for having the lens correction module enabled by default. This will \"hide\" most details on the border of the image by default and it is always possible to have it enabled by default using an auto-preset.. Also, please make separate PR for each changes as some may be merged now and some need more discussion. The risk is having nice enhancement stopped because of some part are more delicate. Thanks.. \nNikon has removed the LPF for every camera from the D800E (2012), D7100 (2013), D3300 (2014), D5300 (2013), D5 (2016). All the full frame Sony don't have them since the alpha 7 (2013). Fuji don't need them at all with their XTrans sensors. Pentax has a digital LPF on K1 and K5 that can be disabled in the firmware and the 645 doesn't seem to have one. Hasselblad X1D (2016) doesn't have it. Same for Phase One since at least IQ2 (2014). Same for Leica with the S2 (2016) and the M range since at least the M9 (2012). Panasonic has gone LPF-less tlast year for the first time, with the GH5, and this year with GX7. Only Canon is trapped in Middle-Age with only the 5DR having an optical correction for the LPF (2015).\n\nYou can add D850 (2017). I see your point and indeed maybe at this stage we should not activate the sharpen module by default.\n. @LebedevRI : we are still discussing, right?. > I have always been strongly advocating for consistency and keeping all history stacks valid even from day one. If we give up that part I am out.\nI'm also advocating for this. But here we are not talking about breaking the history which is BTW already broken in a far worst way that what Aur\u00e9lien propose. Just think about the different process we have plain CPU, OpenCL, SSE. The three are certainly not giving the same results. So a user going from computer 1 on a CPU to a new computer with a GPU won't have the same result when exporting picture. And we don't know what in the future the processor factory will come with.\nSo as Aur\u00e9lien said we don't want to break history but inevitably we may have a small shift when changing the computing environment or the way the algorithm is used on the pixel-pipe.. @parafin : if I agree with you in general it is also clear that there is not enough energy around to discuss and review everything. This makes PR staying for years on GitHub (see the duplicate module case, 2 years sitting there). So we also want to ensure dt is moving forward (yes as Aur\u00e9lien said with the possibility to have temporary some breakage), a soft not moving is a dead one! We do also want to not discourage contributors.\nWe have a great user based and this is a chance that most little issues introduced are detected quite fast.\nThat's also a good incentive to merge sooner, this year release everything was done starting on Sept. Far too late, I have put far too much energy to have something for this Christmas.\nThat's my thinking and trade-off today. I'd love to see 50 or more devs around to review and discuss everything, but that's not the case.\nAfter all, we are doing well, no? The current state of darktable is great, I'm using almost daily to produce wonderful images.. I suppose this could be closed now?. I think that the renaming of the equalizer will make sense in the tone-equalizer PR. I suppose that these are related? To have a \"contrast equalizer\" and a \"tone equalizer\" and avoid confusion, right?. Issue reproduced and this fix works. Thanks.. Any news on this? Do you agree with the soft bound approach?. Too bad, it could have been interesting for others!. Sounds good. Thanks.. Manually merged.. This would be wonderful, but I'm not sure it is possible with Gtk+, if an expert pass by can you comment on the feasibility?. Will merge this one in master which is quite delicate. Should go in 2.6.1 but we need more field testing.. You mean to disable it by default for all camera without low-pass filter? I don't see how this could be done, this list is probably long and won't fit our filtering circuitry. And we do not have the list of future camera without a low-pass filter, so we will need to adjust this all the time.\nOr do you have something better in mind?. @upegelow : I see, this case is still covered. the pref is for the default but you can always activate the sharpen module based on preset with a corresponding filter. So, what is changed here is a global pref, then user can activate or disable based on camera, model, iso and the like.. Exactly! With the slight advantage that if disabled this way sharpen won't even appear in the history . I must say that I'm not fond of the \"+\", \"+++\"... not easy to find a better alternative.\nLet's try... we have from 1 to 4 plus, what about : delicate, light, strong, extreme?\nWhat do you think?. Ok, in that case, to avoid the alpha sorting, juste \"force 1\", \"force 2\"...\nOr maybe that's just me who don't like the \"+++\" :) Would be nice to have more feedback.. Perfect! And strength is far better in English than force :). Thanks!. You may want to adjust as two typos have been fixed and makes some mismatch in the translation.. Good catch! Thanks.. Common issue with lensfun database not being updated or missing the camera+lens in the database. You can contribute this to the lensfun project. Thanks.. Manually merged.. Manually merged.. Hum... Quite a big mess :) 37 commits, 53 files touched and not sure your change is there.\nYou also want to merge into darktable-2.6.x which is not correct your patch must be prepared from current master branch.\nCan clean up of your side and force push?\nIf you prefer we can close this PR.\nBefore pushing you can see what is to be merged by using:\n$ git fetch\n$ git log HEAD ^origin/master\nIf this looks ok to you, just push.. Ok, added this. Thanks.. Hi, the announce for the translation was made in darktable-dev, I could send a mail to all translators if needed.. Like the idea, but...\n/home/obry/dev/builds/darktable/build/src/src/views/lighttable.c: In function \u2018expose_expose\u2019:\n/home/obry/dev/builds/darktable/build/src/src/views/lighttable.c:1455:3: error: label \u2018failure\u2019 defined but not used [-Werror=unused-label]\n   failure:\n   ^~~~~~~. Fixing the failure above I was able to look at this.\nMy first impression is that we want the filmstrip activated only in expos\u00e9 mode and not have it in other modes.. Apart from that, it is a very nice tool to select pictures. I've been using in Lr long time ago. You want of course to be able to rate and reject pictures in this mode and ensure rejected images are automatically removed from the expos\u00e9 view.\nPlease keep up the nice work on this! Thanks.. I would suggest also that when in grouped mode, selecting the group leader would display all pictures in the group.. > My first impression is that we want the filmstrip activated only in expos\u00e9 mode and not have it in other modes.\nI see that this is what you have coded, but exit dt in file navigator mode. Restart dt and the filmstrip will be displayed.. There is conflicts due to the lighttable rework to speed it up. Do not hesitate to rebase on master and ask if you have questions. I'm eager to see this in action :) Thanks.. > The compile error is fixed and the filmstrip should be hidden when you restart dt in file navigatior mode.\nNo, not here. I have applied this patch locally. Started dt and I have the filmstrip under the lighttable in file navigator mode. Can you reproduce?. When moving over a picture there is no visual feedback that this picture is selected. Maybe add a border?. I'm wondering if we don't want to add stars and reject icons under each image. This was there in Lr IIRC.\n. I'm really happy to see this going! Waiting to have it in dt for real!. Note that for the rating with the mouse you can use what is done on the single/full expose. In this case the stars/reject is displayed on the top-left corner. It is probably needed to \"fix\" it to know about the expose mode where you have multiple images, but I think this is the most promising path.\nLet me know if not clear.. Did I say I love this mode :)\nSee:\nhttps://github.com/darktable-org/darktable/pull/2039\nIt remains the circuitry when you click on a star/reject to actually do the rating.. I also have done a first pass on the style.. I have fixed the staring/rejecting on the expos\u00e9 mode. Please see my PR. I think we should continue on this PR. Feel free to test this branch. Let me know what you think?. I have just merged my branch with your work. Thanks again! A very nice mode.\nYou can trigger the Expos\u00e9 mode with key x.\nI have tested lot of things, looks like it works fine. Anyway, now on master it will get tested more.. Reading the comment I'm not sure you expect this to be merged now or if you prefer fixing the other issues you mentioned before? Let me know. Thanks.. Merged then, thanks!. @aurelienpierre : I'm leaning toward upegelow point of view. I would prefer to see the tooltip changed only. I understand that dt is for advanced users, but most of them won't understand \"unclip negative values\"... And I'm one of those :). @aurelienpierre : I would see a warning in the tooltip in this case as it is done for the sliders in the \"target/display\" section of filmic. We could also rename \"black\" to \"black level\" if this helps? With is an indication that we are talking a level and not a simple adjustment of the dark tones. Hope this compromise will be ok to you.. @aurelienpierre : to me yes.. To me it sounds good. That's clear, precise and should be clear to anyone. But please also makes the necessary comments in the tooltip as discussed above.. Thanks, sounds good to me!. A bit vague. Was it on a 4k screen? Was it quite unusable before and do you feel that with this patch it makes the lightable bearable or even usable? Somehow as fast as on a full HD screen?. Here report that there is no change:\nhttps://redmine.darktable.org/issues/10764#note-18\nThat's my second attempt, looks like it fails again :)\nMaybe there is some other events that take CPU cycle... I don't own a 4k display, so this will probably have to wait.. @cryptomilk : can you test the new version I just pushed? Thanks.. Ah ah... Is that fast now? How usable?. Right, this is fixed in the new version, I'll push now.. I've just pushed a new version that should fix most issues and handle also the zoomable lighttable.. What do you mean by borders of the thumbs? Can you send a screenshot? Thanks.. Are the borders there during first display and disappear after? Or are they never there? I cannot reproduce that. But this will get fixed and should not degrade the perfs.. Ok, don't really know what is happening :( I'll sleep on that.. @nilsholle : this should be fixed.. @aurelienpierre : yes the lag is there because when reordering we need to redraw everything. So I do expect some lag for some actions and have this at least \"usable\" in 4k or 5k display.. @cryptomilk : about the borders, do you see the yellow ones when you have a group selected?. I would love to see a screenshot of this together with some borders around the yellow ones.. And just to be sure, the borders were visible without this patch?\nAlso, are you using a tuned CSS or the default darktable theme?. I'm asking as on @nilsholle screenshot above we do have borders. And I do have them on my side.. As I write in Redmine:\n\nFor 2.6.1, maybe will see but then this needs a quite extensive testing phase. Even if the patch is not that big, it is quite delicate and in a part that we cannot break (think about all filtering settings, the stars, local copies...). So please do as much testing as possible (and any dev around). It will be easier when merged to master, and report issues preferably in GitHub. Thanks.\n. $ git fetch origin\n$ git checkout faster-lighttable-2\n\nand yes,\n./build.sh\nplus the command to install the compiled version as displayed after the compilation succeeds.. @nilsholle : thanks a lot for testing. I have pushed fixes for both issues. and I have finally also found the issue where some of the thumbs border was keeping the mouse-over color when entering fast from the bottom of the lighttable.. @aurelienpierre : thanks I can reproduce the redraw issue with keyboard. will fix.. I consider this last version as usable and should be working fine. I have made many tests. Please try it and report issues. Again, this is a very delicate part with many many possible interactions.. @aurelienpierre  : I can reproduce the first two points. Not the others.. No, for now the filmstrip is still slow. This is next step.. @nilsholle : the filmstrip should now be fast too.. @cryptomilk : just checking... you've tested the last version with the filmstrip?. @homer3018: this is now merged. I cannot help you with building on MacOS. You'll probably get helps on the mailing-list.. Sounds good to me. Thanks.. We already have this in adobe_coef.c and with the exact same values. Closing.. Just plain correct! Thanks Matthieu.. Oh! I just missed the fact that you had targeted this commit for darktable-2.6.x branch! Please never do that, we need to merge in master. I do test there before manually merging in the release branch. Thanks.. Thanks! Looks good.. All good thanks!. Please you need to provide translation for master. I'll merge to master later for 2.6.1. Thanks.. I will close this one. On dt 2.6 branch we have only merges from master, so the translation from master will be taken for 2.6.1. Thanks.. Manually merged.. Thanks, it is merged.. Thanks, https://github.com/darktable-org/dtorg/pull/41. Typo fixed!. So merging. Thanks for the review Ulrich.. Confirmed!. Second point is fixed.. And can you still reproduce the first point? Looks like it could be fixed too by my change.... Perfect, thanks!. Thanks for reporting. This is now fixed.. Sounds good! Do you think this can/should go in 2.6.1?. Ulrich, so what about 2.6?. Thanks Stefan for testing. Let's merge then for wider testing.. I'll be happy to test. Can you remind me the precise scenario to reproduce the issue and what should I be looking for? Thanks.. Yes please, this would be nice! Thanks. You have 1 week before the 2.6.1.. Manually merged with a code clean-up.. Can you tell me what behavior is fixed exactly? I have tested with and without your patch and I have the same behavior on my side. The preference dialog stays at the center of the window and follows it when moving the dt main window.... I see, for me it change nothing, but well... if the behavior is correct on others envs. Let's merge.. We have \n\ncurl_easy_setopt(ctx->curl_ctx, CURLOPT_SSL_VERIFYPEER, FALSE);\n\nIn all storage, see piwigo, facebook, picasa.\nSo to me, it's fine to go with that. Indeed, not the best option. But we are not ready to have a CA bundle in dt AFAIK.. @peterbud : this is another possibility. it means that we have to include it in dt repository? and adjust the path to the ca bundle based on dt install directory.. @parafin : that's the point, we are not speaking about Linux only but Windows. And this bug is about Windows.. Ok, thanks for the update. Note that the solution put in place for Windows should be generic enough to be able to reuse it in all other places like external storage.. @parafin : I see you were proposing to remove them with #ifndef WINDOWS.\nBut let's wait for the solution here as it would be even better to remove those lines completely.. This generally happen when having a module activated with an old version of the module and then using it. The blend version has changed in master and I suspect that this is the culprit. Not really a bug. Just compress the history and this won't happen again on this image.\nCan you check that?. Right, only those was was edited with a prior version.. Nothing we can do really. Let's close.. Fixed. Thanks for reporting.. Ok, closed. Thanks.. Sounds like a nice improvement to me!. I'm no good at designing icons :)\nCan you describe the icons from left to right?\nNote that we have a new entry in the combo for raster mask.. Closing as now done/merged.. Thanks!. I'm closing. The values are exactly the same as previous one up to last digits. You did not removed the old entries anyway, so this cannot be applied. And your WB set is lot smaller than the current one. All in all, nothing new in there.. Thanks. Will merge.. Looks promising indeed! I found a little issue, it is almost impossible to trigger the list of module used in the history which happen when over the little icon top-right of the thumbs. I get it some times, but very rarely.. For the code duplicate that's nice! I was about to raise this issue and to at least have a comment saying that if the layout change your new function to detect sensitive elements! It is even better to see this done in the same code now.\nFor the ying-yang and zoomable lighttable, don't know. Maybe an old issue, I would say better to have it handled here if possible. This can be done in a separate PR if you like. . Really nice clean-up! Thanks. All working fine and the maintenance will be easier.. @phweyland : no if there is no new parameter and if the current edit are 100% compatible with this new version you do not have to change the version.\nWhat I understand from your comment (I didn't look at the code yet) is that this PR is only about a new GUI interface which are actually triggering the current parameters in a different way. Right?. To resolve conflict:\n$ git checkout land:tc-LCh2\n$ git fetch\n$ git rebase origin/master\nThen, look at the code and resolve the conflict line by editing the corresponding files.\n$ git add <fixed files>\n$ git rebase --continue\nAnd if all is fine, force push here:\n$ git push -f origin land:tc-LCh2. This is strange, what if you force push the rollabck commit:\n$ git push -f origin tc-LCh2\nIf this does not work, something is quite messed up on your side. In that case you may want to start over master:\n$ git branch -m tc-LCh2 tc-LCh2-old\n$ git checkout tc-LCh2\n$ git reset --hard origin/master\nAnd get current sources from you current tc-LCh2 branch:\n$ git show tc-LCh2-old:src/iop/tonecurve.c  > src/iop/tonecurve.c\n$ git show tc-LCh2-old:data/kernel/basic.cl > data/kernel/basic.cl\nAnd then commit this single commit for the current implementation:\n$ git commit -a -m \"Add LCh curve mode to tonecurve\"\nDouble check that all is ok and then, force push to this branch:\n$ git push -f origin tc-LCh2\nHope this will solve the mess :). You should avoid merging with upstream/master.\nFor a long lived topic branch like yours you should favor the rebase workflow.\n$ git rebase upstream/master\nThis will avoid the merge conflicts or at least restrict them to the ones from your changes.. No, sorry no opinion on this. This is far from my expertise at this point!. @phweyland :\nThe issue is with clang only in the external rawspeed submodule.\nI have noticed that you have changed the rawspeed submodule here. It should not be done, please make sure the submodule is not touched. Note that this is not the issue anyway, as current master fails with clang.. No, before commit you should always run (to be sure) \"git submodule update\". This will ensure that the module is set to the proper history before the commit. In this way there is \"no change\" for this module in your history and then the commit won't contains it.\nThe issue you have is probably that you have moved to master, did a submodule update (or was done as part of the git pull maybe?) and then back to your branch. Then the module was not back to the point it was on your branch, and so some modifications (change from master) have been committed.. @phweyland : you still need to remove rawspeed from the commit here. this will certainly makes testing easier. thanks.. Also on your branch remove all the merge commits. You can do that by rebasing your branch:\n\ngit rebase origin/master \n. Ok, I did the clean-up. Please do a git fetch origin to get all branches from the official repository. And in your branch do:\n\n$ git reset --hard origin/po/tc-LCh2\nThen if all is well just force push your branch here.\n . Great no more rawspeed in sight :). @phweyland : what is the status? do you fell this to be done? should it be considered for review/merging at this stage? thanks.. A clear bug! Thanks.. IIRC, the parsing does warn if a ISO value is outside of the range. So maybe 1 just remove all checks? Maybe go with 10 if there is a camera with such ISO?. I'm not convinced (loosing check for bad values), but well that a quite minor issue. Thanks.. Seems to work fine, and I like it. Some feedback;\n\nI have many critical warnings on the console\n(darktable:4468): Gtk-CRITICAL **: 19:39:44.169: gtk_toggle_button_set_active: assertion 'GTK_IS_TOGGLE_BUTTON (toggle_button)' failed\n\n(darktable:4468): GLib-GObject-WARNING **: 19:39:44.169: invalid cast from 'GtkDarktableButton' to 'GtkToggleButton'\n\nMaybe some improvements for the icons. I find the drawn+param one not readable. Some proposals:\n\nfor the uniform, use a simple empty circle (I'm not fond of the shade)\nfor the drawn, use the pencil in the wantermark module (extract it)\nfor drawn+param use the one in watemark module\nfor raster use the one in dither module.\nSee proposal here:\n\n. Good news!. I think for uniform, the first is better. The third for me looks more like a parametric mask, the arrow being the \"setting\" parameter for the mask.. But yet, the gradient does not convey well the fact that it is uniform to me.. Based on your prototypes, why not:\n\na complete/close circle full grey for uniform\na partial circle with gradient (and possibly arrow) for parametric\nand from there add the little pencil for drawn+parametic\n\n? . Which button icons?\nFor the module, the reset and preset icons are in paint.c, and they are draw with:\nbtn = dtgtk_button_new(dtgtk_cairo_paint_reset, CPF_STYLE_FLAT | CPF_DO_NOT_USE_BORDER, NULL);\nWhere dtgtk_cairo_paint_reset is the draw routine in paint.c.\n. Ah, ok those are indeed svg.. That's really nice! Like it!. Really nice indeed! Icons are readable and this save some clicks! Nice usability fix to me.. I have found another place where lot of space was added at the bottom of the iop UI. This is now reduce to the minimum. Lot of vertical spaces gained!. Sounds good and working. Thanks!. BTW, see my related PR here:\nhttps://github.com/darktable-org/darktable/pull/2025. To me on an i7-4710MQ @ 2.50GHz the new version is slower.\nMost timing were around 0.35s with current version and with this PR most timing are around 0.4s.. @aurelienpierre : this was with a landscape picture.. This affects OpenCL only.. Do you think this can be fixed for 2.6.1? It remains 15 more days for integration.. Also adds a hierarchy (a single one) for the menu in the darkroom. This also will help managing the styles.. Manually merged in master and 2.6.1.. This has always worked for me with nvidia! Any explanation why this is need on your side?. @kxv : I know, I did blacklist it.\nBut you have not answered my question. I'm just trying to understand why this is needed for NEO whereas it is not for AMD and NVIDIA. Maybe the issue is somewhere else? I just want to have at least some idea of what a PR is about before merging. That's all.. On, reviewed and tested. This works fine and is generally useful even outside of the Intel neo driver. Thanks.. The segfault is probably in the SSE2 code path because you cast the float to _m128 but those are probably not properly aligned. You need to use _mm_set1_ps() I think.. For the color picker next to the graph you need a hbox. I can give a hand on this if you like.. @aurelienpierre : ok I will do this.. > @aurelienpierre : ok I will do this.\nDone. You can fetch the branch filmic-autotune\nAnd pick the top commit to put it on your branch:\n$ git cherry-pick origin/filmic-autotune. > Find where the modules GUI titles are coded and remove the font-size which is probably hard-coded there (would be nice to use \"Roboto Condensed Light\" there, because some modules name are too long to fit). 11 pt seems enough.\nIt is not hard coded, there are named panel_label, you can change them with: \n```\npanel_label\n{\n    font-size: 0.85em;\n}\n```\n. Fact is that the iop panels are using more vertical spaces. I suppose this is configurable (due to font size?) because people with small screens won't like this :) I already have \"bad\" feedback about this.. And BTW, good to see you deep into the amazing world of GTK :). For me 10.5pt is a bit big. 9pt seems to be what we had before. Maybe use 10pt?. This PR seems sane as it removes lot of hard coded setting that can be placed into the CSS. So at the end everyone will be able to tweak the UI as they like.. @parafin : yes, Aur\u00e9lien has put a list of fonts to select. See the CSS.. For reference:\n\nfont: 10.5pt \"Roboto Light\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif;. Yes, 1em is good, and probably better for HDPI screen. To be tested.. The G and ? icons next to prefs are very small.. I'd like to see this done in two steps if possible. It is always easier to review/merge multiple small steps than a big one. The large clean-up removing the hard coded fonts should be first and this will be easy to integrate as this won't change the UI a lot.\n\nAs a second step we can tweak the CSS to change the UI to make it cleaner.\nWould that work for you?. Yes, I agree also that the height is an issue to be taken into account. But keep in mind that you can also hide the filmstrip to gain height, pass in full screen mode, etc...\nI have seen people complaining about height during a course session I was given and they had the filmstrip and also the Windows task bar :) If you care about space you at least need to remove superfluous widgets on the screen.. AFAIK, Aur\u00e9lien is removing most hard-coded values. So at the end I suppose we can have propose a compact theme. Note that in the dev version we have the ability to change the theme on-the-fly via the pref dialog.. I've tested this quickly today. Found that it is making progress. Just noted that the entry has the height far too important. Also all buttons for the IOP (toggle active, preset...) are too big compared to the labels of the module.. @aurelienpierre : for the entries:\n```\n /opt/darktable/share/darktable/themes/darktable.css 2019-02-06 12:23:07.000000000 +0100\n--- themes/new.css  2019-02-06 12:39:51.414141404 +0100\n**\n 142,147 ***\n--- 142,149 ----\n    border: 0;\n    outline-style:none;\n    background-image: none;\n+   min-width: 0;\n+   min-height: 0;\n  }\n/ Reset GTK defaults /\n\n 606,613 *\n/ Modules buttons /\n\n\ndt-button,\n\n\ndt-toggle-button,\n#dt-icon\n  {\n    font-size: 14pt;\n--- 608,613 ----\n**\n 616,621 \n--- 616,629 ----\n    padding: 1pt;\n  }\n\n\ndt-button,\n\n\ndt-toggle-button\n\n{\nfont-size: 8pt;\nmin-height: 10pt;\nmin-width: 10pt;\n}\n#module-preset-button,\n  #module-reset-button,\n  #module-spacer,\n\n```. Also the icons for selecting the fusion modes are too big for me.. I have edited my patch above to also makes the fusion buttons a bit smaller.. With you latest version there is no highlight for the current module. That is, \"table lumineuse\" or \"chambre noire\" at the top when selected does not change.. In this new version I have removed a bit of padding in the button which made the + - button in export dialog too large.\n```\n /opt/darktable/share/darktable/themes/darktable.css 2019-02-06 12:23:07.000000000 +0100\n--- themes/new.css  2019-02-06 12:44:35.843714347 +0100\n**\n 142,147 ***\n--- 142,149 ----\n    border: 0;\n    outline-style:none;\n    background-image: none;\n+   min-width: 0;\n+   min-height: 0;\n  }\n/ Reset GTK defaults /\n\n 237,243 \n  {\n    border-radius: 1em;\n    margin: 1pt 0.5pt;\n!   padding: 2pt 4pt;\n    border: 0.5pt solid @button_border;\n    background-color: @button_bg;\n    color: @button_fg;\n--- 239,245 ----\n  {\n    border-radius: 1em;\n    margin: 1pt 0.5pt;\n!   padding: 2pt;\n    border: 0.5pt solid @button_border;\n    background-color: @button_bg;\n    color: @button_fg;\n**\n 606,613 *\n/ Modules buttons /\n\n\ndt-button,\n\n\ndt-toggle-button,\n#dt-icon\n  {\n    font-size: 14pt;\n--- 608,613 ----\n**\n 616,621 \n--- 616,629 ----\n    padding: 1pt;\n  }\n\n\ndt-button,\n\n\ndt-toggle-button\n\n{\nfont-size: 8pt;\nmin-height: 10pt;\nmin-width: 10pt;\n}\n#module-preset-button,\n  #module-reset-button,\n  #module-spacer,\n\n```. Making good progress and almost finished. I have noted some parts to fix (in case you didn't notice them):\n- no highlight (mouse over) when over the collections\n- module buttons not aligned (see screenshot)\n\n- buttons in duplicate module too big\n- color picker combos (when selecting items) have no background\n- color picker combos have very small arrows on the right\n\n- highlight for the current view selected is hardly visible and the lighter text is the non selected view, in the screenshot I'm in the darkroom:\n\n. On your point above I find 3 a real issue. The other, not really. For example, for 5 one could say that only IOP module have icons. For 2, the touch of color and icons helps find the proper IOP.\nSo we have to balance the pro & cons. For me, 3 is a real issue indeed, especially for French translation (and maybe other languages) where the text is often longer than the English ones. So I would agree with you that it is \"better\" without.. This is getting better and better, we are close to the final version. Two issues found:\n\nthe buttons are not aligned in the lighttable (as I have reported for the darkroom now fixed)\nno visual indication in the collection for the selected item\nno visual indication in the history for the selected item\nno visual indication of the current selected view\n\nThe font used now is definitely more readable to me.. Sure, as long as the panel title is will distinguishable when opened. And the module background is with different color. How does it looks with your latest version?. Ok, works for me. Indeed you have the module \"pipette\"' deployed and it is visible. If the IOP module are using also a distinguishable color, all good to me.. For the treeview selected items (my point 2 above), I have separated the CSS rules:\n\ntreeview :active,\ntreeview :checked\n{\n  background-color: @button_checked_bg;\n  color: @button_checked_fg;\n}\ntreeview *:selected\n{\n  background-color: @plugin_bg_color;\n}\n\nHope this helps!. I have a CSS error, you need to remove \"incensitive\" which is deprecated since long time now.\n\n*:insensitive\n\nJust keep the *:disabled.. Here is my proposal:\n```\nFrom 1805a41ea9b162498e6772d7d0add5d3292d8dfc Mon Sep 17 00:00:00 2001\nFrom: Pascal Obry pascal@obry.net\nDate: Thu, 14 Feb 2019 17:31:03 +0100\nSubject: [PATCH] css: align module content with label using CSS only.\n\ndata/darktable.css.in | 6 ++++++\n src/develop/imageop.c | 8 +-------\n src/libs/lib.c        | 8 +-------\n 3 files changed, 8 insertions(+), 14 deletions(-)\ndiff --git a/data/darktable.css.in b/data/darktable.css.in\nindex 2fbfea002..2ea64ac3a 100644\n--- a/data/darktable.css.in\n+++ b/data/darktable.css.in\n@@ -454,6 +454,12 @@ entry *\n   margin: 12pt 0 6pt 0;\n }\n+#iop-plugin-ui-main,\n+#lib-plugin-ui-main\n+{\n+    padding: 2pt 2pt 2pt 12pt;\n+}\n+\n #lib-modulelist\n {\n }\ndiff --git a/src/develop/imageop.c b/src/develop/imageop.c\nindex a49e53125..65ed4a629 100644\n--- a/src/develop/imageop.c\n+++ b/src/develop/imageop.c\n@@ -1954,13 +1954,7 @@ GtkWidget dt_iop_gui_get_expander(dt_iop_module_t module)\n   gtk_box_pack_start(GTK_BOX(iopw), module->widget, TRUE, TRUE, 0);\n   dt_iop_gui_init_blending(iopw, module);\n\n/* add empty space around module widget\n\n\nthis cannot be set in CSS because the module collapsing is badly handled\n\n\n\n\n*/\n\n\ngtk_widget_set_margin_start(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_end(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_top(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_bottom(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_name(module->widget, \"iop-plugin-ui-main\");\n   gtk_widget_hide(iopw);\n\nmodule->expander = expander;\ndiff --git a/src/libs/lib.c b/src/libs/lib.c\nindex e56faefd4..7d40a4e34 100644\n--- a/src/libs/lib.c\n+++ b/src/libs/lib.c\n@@ -1010,13 +1010,7 @@ GtkWidget dt_lib_gui_get_expander(dt_lib_module_t module)\n   gtk_widget_set_halign(hw[DT_MODULE_LABEL], GTK_ALIGN_START);\n   gtk_widget_set_halign(hw[DT_MODULE_RESET], GTK_ALIGN_END);\n\n/* add empty space around module widget\n\n\nthis cannot be set in CSS because the module collapsing is badly handled\n\n\n\n\n*/\n\n\ngtk_widget_set_margin_start(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_end(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_top(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_margin_bottom(module->widget, DT_PIXEL_APPLY_DPI(16));\ngtk_widget_set_name(module->widget, \"lib-plugin-ui-main\");\n   gtk_widget_show_all(module->widget);\n   gtk_widget_set_name(pluginui_frame, \"lib-plugin-ui\");\n   module->expander = expander;\n-- \n2.20.1\n\n```. In last version I have lot of:\n(darktable:18228): GLib-GObject-WARNING **: 08:42:21.305: invalid cast from 'GtkDarktableButton' to 'GtkDarktableIcon'\nAnd I really don't like the open when activated behavior.. One proposal for the activate + open action. We already have a combined action for the middle click (like apply preset in the instance). I would use the same here, that is middle-click to activate and open and keep the current behavior for the left click.. > The middle-click is a good idea, but I would use it to enable without expanding\nThat would not be very consistent. As I said we already have combined action with middle-click. (like preset as said previously but also to create a new instance with the multi-instance button). So with the current state I think we should respect this behavioral choice.. Just found also that in the lighttable the inactive buttons in the \"history stack\" module are not visible.. > I understand, but how do you advertise the expandable nature of the modules then ?\nIn the documentation that nobody reads :) This will be discovered in forums discussion (like many things already when users ash questions). And at some point it will be known :)\n\nIs it useful to have disabled controls visible ? (their colors are just declared transparent in CSS).\n\nYes, not very visible but shadowed somehow as in the previous version. They are invisible in some context but this \"advertise\" that some actions exists. It is strange to have empty spaces anyway.. >  Also, 90 % of the time, when you enable a module\nYes that was my initial thinking. But most of the time I enable/disable it just to see the before/after effect. This is very common and I do that lot more than activating the module once.. @aurelienpierre : I think both views are valid so in the end we will need a preference for the left vs middle click behavior.. The panel scrollbars should be always visible (or at least a pref option) because it is annoying to have the module adjusted in width each time a module is opened and the scrollbar is activated (because the height of the module becomes too high).. For the disabled elements, a proposal:\n```\n /opt/darktable/share/darktable/themes/darktable.css 2019-02-16 10:18:35.000000000 +0100\n--- new.css 2019-02-16 10:45:55.269596224 +0100\n**\n 221,230 *\n  / General properties /\n! *:disabled {\n    background-color: transparent;\n!   color: @bg_color;\n!   color: transparent;\n    border-color: transparent;\n  }\n--- 221,230 ----\n  / General properties /\n! *:disabled\n! {\n    background-color: transparent;\n!   color: shade(@fg_color, .7);\n    border-color: transparent;\n  }\n```\n. A bit more spaces around the entries:\nentry\n{\n    border-radius: 2pt;\n    border: 0.5pt solid @border_color;\n    padding: 2pt;\n   margin: 4pt;\n    color: @field_fg;\n    background-color: @field_bg;\n  }\n. Don't know why but the lighttable display on my side is broken with the current version. If I move the mouse over the lighttable I have some big grey squares drawn under the mouse.. I think it is wrong to do all that here. This PR will be a nightmare to review :) I would keep only the UI redesign here and would move the all other side projects in different PR (I'm thinking at the lighttable reconstruction, the histogram edit, the yellow persistence,...). One point is that we need simple a iterative commit, here we already have more than 100 commits!\nPlease help me here! Thanks.. Here is the screenshot:\n\n. Also, my point is not only for me. But adding more and more things into a PR is nice but will delay for a long time the integration (I have also experience where at some point integration is just not possible anymore). This will require maintenance and energy on your side to resolve conflicts. All in all, in my experience it is always a very painful way of working. . @aurelienpierre : Thanks a lot! Yes this definitely looks easier to review! This will find its way to master sooner :). Just tested it a bit. I see at least four things to work on:\n- add a pref for the enable/disable & collapse/expand working together\n- add a pref to always show the panel scrollbar (otherwise when they get activated the panel's module move)\n- the tabs on the pref dialog (actually all tabs) when hovering are not visible (black text fg)\n- The history list items have too much padding/margin the height of the dialog is using lot of space\nFor the prefs, I can add them if you like.. Found out also that the expos\u00e9 mode is broken. Displayed images are full black.. I'll add the preferences.. Both prefs added. The control for the scrollbars added to in the current code. So you can just remove your commit be44c77. . Ok, this last version is really nice. Three minor issues and we can merge:\n- in the color picker module the arrows for the combobox are very very small\n- in the color picker, the picker itself is huge :)\n- In the more module we don't have visual info about the module already selected, this makes this list very hard to use.\n. Aur\u00e9lien, I see that you have added back the image information in the histogram, look at #2181, I think that we can clean up the histogram. What do you think?. I see that you have updated the branch since my last comments but it does not addresses the issues I have raised, is that normal? Or did you forget some commits? Thanks.. I have just tested this again and found out that the expos\u00e9 view does not display correctly. The images are full black. I think I have already reported this, but since I was not able to find the reference I prefer reporting again. Sorry if this is already known and in the TODO list.. Ok. If you like you can fix the gui stuff already reported and I can have a look at the full preview before merging. Let me know . Thanks! Looks good to me.. @oexler : indeed, for the layout not sure now. maybe because you did set the filmstrip visible and then hide it. Not sure.\nWhat's the issue with the hotkeys?. @oexler : new version for the bug on filmstrip pushed. in enter() I have added a call to hide to ensure the filmstrip is initially hidden. Looks like this works fine.. > Wait a moment, how is it that both 0 and 1 get replaced by DT_LAYOUT_ZOOMABLE? Shouldn't 0 be DT_LAYAOUT_FILEMANAGER?\nIndeed! cut&paste error :( fixed. good catch, thanks.. @oexler : I think all issues (especially accels) are now fixed.. Yes, and I can reproduce. Really strange behavior :) Will fix. Would have been good to open an issue.. This is now fixed. Can you try again?. I see, now fixed too.. Not complete, it seems that there is some state non initialized!. I think I found the issue. A mistake of mine in the picker proxy!. For the exif on the histogram why not display it only when mouse is over?. So add this into the hint message when opening a new picture and/or closing/opening a new module?. There is many places where we can display this information:\n- we already have a hint message area\n- we can add a status area on top of the image, between sort and G symbol\n- we can add a status area on bottom of the image, between style button and the raw overexpose\nWhat about this?. Indeed! Thanks.. I agree to remove this.. Looks ok to me. Thanks.. Have you tried with OpenCL disabled?. Closing.. Sounds good! Thanks Matthieu.. Thanks.. > We will suddenly see that all the images are showing (except the 1 raw we starred), this includes the jpg's and the raw's (although the G button is still active).\nMaybe I don't understand. But this is the expected behavior, no? You star the RAW then it not shown (filter unstarred only) and giving a start to a group leader (G active) will set one start to all picture in the group.\nSo, I've not been able to reproduce or understand the issue here.. To me, your code:\nid IN\n  (SELECT id FROM\n     (SELECT id, MIN(ABS(id-group_id)*2 + CASE WHEN (id-group_id) < 0 THEN 1 ELSE 0 END)\n      FROM main.images WHERE %s GROUP BY group_id)\n  )\nIs equivalent to:\nid IN\n  (SELECT id FROM\n     (SELECT id FROM main.images WHERE %s GROUP BY group_id)\n  )\nWhich is equivalent to:\nid IN (SELECT id FROM main.images WHERE %s GROUP BY group_id)\nAnd seems not correct. Or am I reading this wrongly?\n. Ah ah! I failed to see that in the MIN() id is used. Indeed, sorry for the noise the select are not equivalents at all. I'll review again with this in mind.. Looks ok to me. Thanks.. Yes, no crash just back to lighttable as expected on a double click.. We are transitioning.\n. Quote : \"High-Performance Denoising Library for Ray Tracing \"\nNot sure it applies to pictures.. Have you tested the shadows&highlight dt module? If so, what's wrong? What is better with rawtherapee? What do you expect from dt?\nPlease, stay a bit more focused otherwise we won't make progress and we won't be able to follow every issue. Have quite generic issue report like this may waste lot of our time. Thanks.. Try using a bilateral filter instead of the default gaussian one to avoid the halos.. Thanks!. You have updated the translation this morning, but I have another proposal:\nhttps://github.com/darktable-org/darktable/pull/2060\nCan you comment? Is that ok to be merged? Thanks.. Sounds good!. Can you comment about why this is needed? A DE update was integrated this morning. Thanks.. Ok, thanks. Note that I didn't say that you've done something wrong, I'm not speaking German so I cannot tell that's why I've been asking.. Ok, better. Thanks.. Looks good and works fine. Thanks for reviving this, it is lot better to use the single click here. Do you think it would be possible to add aspect ratio ranges?. A glitch or a feature. Clicking on the line open the children and select the parent. I find this ok.\nThanks a lot for handling the apsect filter.\nAnd, yes almost 3 years after your first PR on this it will get merged right now!. Just found an issue with this. You cannot open a folder in the folder view in the single click mode.\nCan you have a look? Thanks.. Looks good to me! Thanks.. Looks good and a nice code refactoring! Thanks.. Can you add a description as to what this is fixing (how to reproduce)? Otherwise it makes review/testing quite difficult. Thanks.. @rabauke : ok, most of this patch is about refactoring. as already discussed please do separate commits. to review a code clean-up or refactoring I have nothing really to \"check\". for a fix I really need to review each lines. here we have in a long diff with only two definite changes. thanks for my time :). Thanks, far easier to review.. Working fine! Nice fix. Thanks.. Won't this be better under the softproof & gammut  buttons? We already have here the screen profile. It seems awkward to me to have this under the over/under expose. Can you comment on this choice? Thanks.. I'm speaking about the location of the new setting you have added. The new selection is done in the over/under expose dialog. I think it would be better if placed into the softproof & gamut dialog.\nI've just built and tested and I see that the name for the new profile is \"overexposed profile\". So it looks like it is in the right place. But... then I fail to see a relation between the new \"overexposed profile\" and the picker or histogram. Can you clarify?. I'm just trying to understand. You did not answered one of my question.\nWhy the new profile is named \"overexposed profile\"? As I understand it works for picker and histogram, so I don't see the relationship.. Ok I'm starting to understand now.\nAnother question if you don't mind (and possibly a stupid question as I'm no expert in this area), is this a kind of \"working\" profile? I mean, is that needed because most of the pixelpipe is Lab? I'm trying to understand why there is no such profile in other software?\n. What I don't like in this is that we have now:\n- output profile\n- profile set in the export module\n- and the overexposed profile\nAnd if I'm not mistaken those are all connected together and ideally the same profile should be used in the 3. This is not appealing :( Or am I wrong.. > Printing and exporting profiles are just output profiles for files. I don't think we need to split the feature, they work the same, but for different outputs.\nThis sounds awkward to me. A print profile expect a file exported with a specific profile. That is, when creating the printer profile you need to specify the profile for the file that will be printed. That's why in the print module we have the export profile and the printer profile.\nThe TurboPrint module also expect that. So we can't say that this is dt specific.. Ok, I've reread most of the comments here. I can't say that I understand all the details but I agree that option 2 is a good compromise for now.\nMy feeling also that this will certainly not be easy to grasp for most users.\nOne side question. What will be the default for the picker/histogram profile? Will it be \"same as gamut/softproof\"? Something else? In other words, what would be a good default?\n. Looks good to me at this stage. I have tested it and all seems working as expected. It is indeed good to see the histogram adjusted when activating the softproof. Thanks!. Works fine! Thanks.. As promised :) You're welcome and thanks for the translation.. Thanks!. In fact it was based on 2.6.1 branch. Can you do a PR for master? Thanks.. Thanks. Note that you should have only proposed a PR against the current master as the translations in master are copied as-is in the release branches. All strings in the 2.6.x branch are compatible with master. I have a script to do that before the release. . Something wrong with this PR!\n87 files changed! Not just the translation and many many conflicts.. To help I have merge your 2.6.x version into master. Here is the status:\n$ intltool-update es\n2589 translated messages, 3 fuzzy translations, 5 untranslated messages.\nHope this helps!. I'm closing this PR. Please reopen a new one. Thanks.. @peterbud : I understand for not changing blindly, but we are disable SSL check for the export module for now, so it works.\nNow I'd like to fix this for better security. So I'll do the change, I'll check that all is well with picasa and piwigo (I have account). I'll change blindly for Facebook. And then I'll try to check that on Windows when 2.6.1 is released.. @daris: the CA is only installed on Windows for now. So no problem. And if needed Linux and MacOS user could put a CA file at the right place. So all in all, currently it is a no-op expect on Windows.. Yes, it should be in 2.6.1. I'm waiting for more tests on Linux to ensure nothing is broken.. Looks good. Thanks.. Thanks.. Oh no please! This makes the text unreadable to me. Capital letters are higher and if the line are too close it is just hard to read or you have to use big font. I'd like to have a poll on this, of course if the majority prefer this we can revisit.. Just to clarify, my statement above is about the labels for the sliders or combos. For tooltip why not. But adding a capital letter to a label which is 2 or 3 words will not bring anything to me.. Thanks.. Thanks for starting this! I have two quick comments:\n\n\nI'd like dt_image_copy_r() to be renamed dt_image_copy_rename() more explicit. \"r\" here may means reverse (like in g_strrstr) or whatever.\n\n\nYou've not handled the renaming of the XMP xmpMM:DerivedFrom tag which reference the RAW file. As it is now renamed you need to rename it in all XMP (main one and all duplicates).. What about the XMP references? Do you plan to work on that or should I close this PR?. Just to be sure. This does not add renaming on dt but will provide this ability to Lua, right? And you plan to add such plug-in?. @schwerdf : sorry for the late reply. so let's do this in two steps. I'll merge this when the conflicts will be resolved. And then please can you open an issue to discuss the design for the renaming? Thanks.. As discussed in mailing-list this will be integrated when 2.6.1 is out to not break all translations just before merging them in 2.6 branch.. Perfect! Thanks.. Should be fixed now.. I'm not sure to understand the goal here. Only 64 bits systems are supported at this point.. What is the status here? Also you never answered my question above. Thanks.. @rabauke : the qestion above:\n\n\nhttps://github.com/darktable-org/darktable/pull/2088#issuecomment-462453892\nI'm not clear about what is this solving.. That's my point indeed. We claim that we do not support 32bit architecture since some year now. We have a message saying \"run at your own risk\" IIRC. I'm think that at this stage we can remove the 32bit code path. Please let's do that in a single commit. If we need to revert it will be easier. Thanks.. Let's this in, we don't test 32bit systems. We don't want to support them. So better to disable it. Thanks.. Forgot to add:\npro:\n- it is now possible to create albums\ncons:\n- the photo api can only add pictures in album created by itself. Very very suspicious... as this would mean that nobody would be able to use 2.6 on Windows :) I have no idea of what could be wrong though as I'm not using Windows.. Remove your luarc and try again. This can't be the export module as it works for many people.. Good catch! Thanks. Should be fixed now.. Sounds good. Thanks.. Thanks! Working better indeed.. Thanks.. Looks good. Thanks.. Looks good. Thanks.. No it is not supported on any platform as far as I know.. Manually merged. Thanks.. Next step is the metadata.. metadata are now handled.. no more WIP, can be tested.. >     * how about date localization. I use dd/mm/yy hh:mm:ss is it different in other language ? (and how to deal with that in that case ?)\nI think you can look at the image information module which does that.. Some comments;\n- The zoom in/out has a too big step I found. I have 15 years in the timeline. A single zoom-in with the scroll and I get one year a 2 months displayed.\n- When changing collection it would be nice to have an indicator of the covered period in the timeline (not like the selection which is sync with date/time on collect module.\n- I agree that the scroll on the side of the timeline is not very nice. First we scroll once and then we need to move the cursor. And the move is a bit too slow I think.. I think the timeline should be deactivated in \"expos\u00e9\" mode. In the current version the timeline is displayed on the left of the filmstrip. I really don't think the timeline is of any use while in \"expos\u00e9\" mode anyway.. I forget that I really like this new lib. Very handy. Thanks.. > Hmm not sure how to get that dates without redoing all the sql manually, but I will have a look\nI was think about using a callback on COLLECTION_CHANGE. Then you have all the images in the collected_images in-memory table. From there you can get the starting and ending dates and display some indicator on the timeline.. > So there's a bug somewhere, it should be disabled (and it works for me...)\nEven if you do a ctrl-f to enable it while in expos\u00e9 mode?. @cryptomilk : if I agree with the comment I'm not sure it applies here. The dates are only displayed at the bottom of the timeline only. These are somehow already sorted for you anyway :). Nice, for me the zoom factor and the scroll are ok now.. Let me fill the todo list then :)\nWhen you close the timeline the lighttable is not properly refreshed. I suppose a call to dt_control_queue_redraw_center() is missing.. Looks good now. I have merged (manually and resolved the conflicts with my lighttable undo support) it on master to get more testing. Thanks again for the nice contribution.. Thanks. I'll add the const.. Looks good. Thanks.. I cannot reproduce this issue. Any simple way to reproduce?. The risk is high indeed and since the quality of the final result is definitely the main goal I'll approve this PR. Thanks.. As far as I know this is only for testing CL kernels for the CI builder. It is not used by dt itself.\nThe kernels are compile in src/common/opencl.c. I'll merge this anyway. It won't bring speed, but at least we will check the kernel against OpenCL 1.2.. Sounds like a good move to me. Let's try this for master.. Do you have timing to compare the perfs?. No problem. There is no hard string freeze of minor release. You can update the translation. All strings in 2.6 should be fixed at this stage.. Perfect thanks!. So you mean that this is ready for review/integration?. @rawfiner : I don't like the backward compatibility GUI section. I understand that you need to keep that with a values FALSE for both boolean for previous edits. What I would do:\n\nsolution 1:\nfor old edits display the backward compatibility section with both values not selected\nthis make it possible for users to tick both options (fix ascomb, fix patch)\n\nwhen both options are selected do not display this section at all, I don't think someone would want to uncheck the fix (at least we certainly don't want to encourage this).\n\n\nsolution 2:\n\nThe other solution is to never show those options. Both are FALSE for old edit and we set them to TRUE automatically for new edit or when the module is reset.\n\nIf we go with solution 1, I would even have a single tick:\n [ ] fix ascom transform and patch normalisation\nFor old edit andf again do not display that if it has already been selected by users.. I will go for 2 and if the option is named:\n[  ] migrate to new algorithm\nAnd in the tooltip message you can have a longer explanation about the ascomb and patch fix and the fact that when selected it won't be possible to go back later.\nIt will not be confusing to not see this in new edits I would say.. > I added this in the fix_anscombe_and_nlmeans_norm_callback, I think it makes more sense than in the mode callback.\nI don't think this is correct. A user may want to activate and deactivate it multiple time at different zoom level to asses the changes and if he want to keep the previous algorithm or not.. > Do you think we should do it when the user change mode however?\nWhen changing mode we should probably keep the current status of the fix boolean.. Exactly. And not shown if not shown.. Ok, UI fixed now, thanks. But the presets are not working on my side now.. Really nice indeed! Great work rawfiner. Thanks.. I don't see that on my side.. You have again committed rawspeed in commit :\ne1f7fb686bc75f49171012e74196381d1ff7c10d\nOf course :\n\n$ git submodule update\n\nSays nothing since you have committed rawspeed, so now nothing to update from your branch.\nYou want to always run \"git submodule update\" before committing (or at least everytime you swicth branches).\nNow, well I suppose I'll have to do the clean-up.. You need to play with rebase --interactive and ask for editing the commit with rawspeed.. I think you should have done:\n\n$ git commit --amend\n(to commit the staged rawspeed revert)\n\nAnd then:\n\n$ git reset --hard\n(to discard the wrong rawspeed)\n\nAnd then:\n\n$ git rebase --continue\n. I think the LUT files should be placed into a dedicated places in dt (like icc, watermakrs). I would choose a \"lut\" directory for this. And in the interface you'll want to only display the base name.. > It would be excellent to have a global setting to define this root folder. I'll look at that. If any tip to \ndo it please tell me.\n\nWhy not! That's one more config option where as a dedicated dir as for watermark would not need that. But I'm not opposed to a new pref.\nFor the 3 parts I would certainly simplify. The root (dedicated or selected in pref) as discussed above and the base name. Why sub-folders? Do we really expect to have many LUT files? Bear with me I have never use one :). There is no folder selection in the preferences. But you can create a references to store a string (a folder or whatever). But as you are doing all in the module itself you don't need a preference all will be stored into the module params.. This is not good. If the folder is saved in preferences it should not be seen here. So of you want to handle multiple possible folders (as already discussed) I think both the folder and the lut file should be in params. Acutally I think only the full filename should be in params. And only the base name should be displayed here.. > Agreed. But I've to find the way to put this part in preferences.\nI see, and then the folder won't be displayed in the iop then. For the prefs just use a simple string, I don't think there is circuitry to have a file selector there.. @rabauke : good point, yes the edit becomes broken. this also applies to watermark using external svg.. But it should be enabled :) We don't want to have spaces at end of line.. Looks good thanks.. Indeed, let's plan that for 2.6.1.. Now merged in 2.6.. Thanks!. All good to me now. Thanks.. All good to me. Thanks for doing this, every little details count at the end.. Good clean-up. Looks good to me.. And it is not possible as I have pushed this AFTER you reported the issue. The commit was done before but I did pushed later.. Looks good to me!. @edgardoh : I made a tentative fix for this.. Should now be fixed, this is a false positive from clang. Not very clever analysis!. Nice fix. Thanks.. Ok, looks good now. Time to let this in. Thanks.. Thanks.. Ok, I agree that the behavior makes sense. But in that case why only the selection apply to the first change of tab?. Ok, looks better now. A little issue still. When the range is selected in any blend channel, the 4 values (just above the slider) are not updated to correspond to the actual selected area.. Also I find that the feather between the cursor (2 steps actually) is a bit small and creates by default some scale. Of course having a wider feather will select more than the selected area... But maybe 2 steps inside the computer range and 2 steps outside (for a total of 4) will alleviate a bit this issue.\nWhat do you think?. For each slider we have 4 handles to select the start and end of the selection. Two for the start and the distance between them is a \"feathered\" area where the mask goes for %0 opacity to 100% opacity. Same of the right side for the end.\nMy point is that the distance (or feathered area range) is of 2 values and this creates hard/abrupt transitions. I'm wondering if a distance of 4 wont be better. Hope this is clearer :). Our messages crossed :)\nYes, I suppose 0.02f will be better in more cases.. > I don't understand this one... \nThe 4 values representing the selected range in the sliders are not updated.. Let's look at the screenshot, I have marked in red the values not updated.\n\n. Perfect! Looks good now to me. Thanks.. \nGood idea! I was thinking alike just this morning. I suppose the new features can be documented into the RELEASE_NOTES.md  file.\nJust list that in [New Features And Changes] section. Works for you?. And BTW, not sure the obvious reasons are so obvious :) Is that because you're not a native English? I'm not but we have nice people on the project that will review the text to ensure the wording is correct.. Please rebase on master branch. I do the synch to 2.6 myself. Thanks.. I'm sorry I mixup things :(. But this breaks the release mode on my side. It is not good since most of us are using the debug mode and when a release will be prepared will have lot of errors. So I would be more in favor of adding this switch for the dev build and make it non fatal (warning and not error).. Yes, strange. I'll try to understand. But still don't you think this should be done for the dev build and not the release one? It is too late to display that when building a release.. That would be too easy :) This does not work. Go to rawspeed, checkout master and go back to dt root. Do a git status and you'll see that rawspeed IS considered for the commit. Do the commit and you'll see that it has been added.. I think I have the fix for this:\nhttps://github.com/darktable-org/darktable/commit/c336ce136e3ad6d7439fd3214b1aacaff8a27818\n. Noted! Thanks.. This is not correct and does not corresponds to the intent. A darktable|changed tag is only applied when an image has been selected into the darkroom. Copying some history does not count as changed (as in this file has been handled, edited so developed).\nThe only part to be fixed is as commented into the TODO to only add the tag if the image has been actually changed into the darkroom and not only viewed.. Hum, I'm not sure this cover a use case for many users. It is certainly quite rare to not have to crop a bit a picture for example.\nWe have currently:\ndarktable|changed\ndarktable|exported\ndarktable|format|%s\ndarktable|local-copy\ndarktable|printed|%s\ndarktable|style|%s\nThe \"changed\" read more like what you are proposing I agree. If we had a \"darktable|edited\" it would have been easier, but we cannot change that. At this point I'm not sure what tag name could be used.. I wen't back to the documentation and there is nothing said about \"darktable|changed\" so your first proposal may be as correct as my view on this. So after all let's keep your first proposal (I'm sorry) and ensure that darktable|changed is set whenever there is a change in the history.\nI think I'm going to add then darktable|edited when a user has actually done some changes in the darkroom.\nWhat do you think?. Ok, thanks. I'll squash the 3 commits to avoid the commit+revert.. So closing.. Thanks!. Thanks!. Thanks!. In original implementation it was easier to select a dedicated color (with the sliders) and the area-of-control based on the size of the circle for moving points. Do you plan to add the same level of support in this implementation?. I also prefer the old backgrounds.. I like this last version. Yet, I would move the GUI options \"edit by areas\" and \"draw background mixed\" as first options just below the graph.. Yes, better. Thanks.\nWhen \"draw by area\" is selected, leaving the graph should clear the area display on the graph.. Looks all good to me. One more question, it seems that the \"mix\" slider and the \"process mode\" (strong smooth) are quite related. Maybe have them next to each other? (\"mix\" just below \"process mode\"). What do you think?. Maybe or at least just above the \"process mode\" ?. Yes I would remove the other backgrounds.. No more comments. Looks ok. Thanks again for the energy you put on all those PR!. Sounds good! I'll test this one.\nAt some point I feel that we should have a \"beginner\" module group and this IOP should be part of this group.. Maybe use a % for sliders contrast, brightness and saturation.\nFor exposure 4 digits are too much, 2 will be certainly enough (as in exposure module). This will make this simple module even more beginner friendly.\nIf you agree and don't have time I can handle this?. Just that I did not visit this PR since some time. Not wip, so I'll remove the flag. BTW, this needs a conflict resolution.. @edgardoh : also Aur\u00e9lien's comment about pixel vectorization does not seem to have been taken into account. Any issue with that?. Thanks! Looks good merged.. We really want to have a clear idea of what to do with this and #2017. Those seems duplicate, right?. I see! I think @aurelienpierre had said something along these lines. I'd like to have his point of view on this.\nAur\u00e9lien?. I understand arguments on both side I think. Yet, we need to remember that in dt it is not because we have a module that we need to use it even see it. We can just disable it.\nSo the point I see that we need a clear idea about is:\n- do we want to add more code into each module to have an RGB mode\n- do we prefer a simple approach (and simpler UI)) and have new modules dedicated to RGB mode\n?\nPersonally I have no strong opinion. I think I could live with both.. New modules are migrating toward an RGB working mode. Fine. But I'm not certain to understand the relationship with the UI. We can have a curve in Lab and RGB, both actually tweaking the module in RGB mode with proper color conversion, right? Or are the color conversion the problem? Not conservative enough? For example the colorbalance can have RGB or HSL sliders and both are actually tweaking the same circuitry in the module with proper conversions.. @aurelienpierre : I agree that limiting ourselves to SSE2 is no good. I'm not a hardware guy, what will be good is to know since when SSE3 is well supported in all CPU. Same for SSE4. . Here is my new thinking. Nothing committed and to be discussed with all knowledgeable people on image algorithm.\nI'm leaning toward having this module in and separated from the current tone curve. Have new module working in rgb mode seems to be the way to go. Then we will be able to have \"module list\" preset for a full rgb oriented pixel-pipe using those new modules and exclusively those that are better at avoiding hue deviations if I understand correctly.\nI think you'll agree and this is also Aur\u00e9lien point of view. Right?\nAgain this discussion is still opened of course, but that's my current decision on this.. Just tested it and got:\n\n[rgbcurve process] rgb curve must be between input color profile and output color profile\n\nAnd all the colors are psychedelic :). > I'll work on that after this is promoted.\nWhat do you mean by promoted here?. > By promoted I mean merged.\nBut I cannot merge something that I cannot test :) This is a chicken and eggs problem! Or can you give me a quick patch to make it working? Or a PR? What do you suggest?. Ok, thanks I missed in your previous message that it should be ok on new edits!\nJust a minor issue. When I used the color picker to define an area I get the area on the curve. Good. I have points on the curve on each side of the area. Fine. But I have two points (very close to each others) defined in the middle. I would have expected a single one to be able to smoothly move the curve inside the area up or down. As it is it is not possible to edit the curve, when you move one of the inner point you create a cusp.. Also it seems the it is not possible to create a positive or negative curve. It is always flat for me.. I see for the middle vs average point. I suppose that with a good documentation (and in the hint message) it is fine.\nFor the positive/negative curve, yes please add support for that to match the others implementation of this kind of color picker. I find this useful.. I'll go for the simple brighten curve for now. . Ok, looks ok. Thanks again for the hard work!. Forgot about a point I wanted to raise. This module is in the CORRECT group by default. Maybe better in the tonality one?. My bad! I have a non default layout and the iop-layout scripts were not updated. Done now for the new rgb curve and the basic adjustment iops.. You've built it yourself? See #2173 . Please delete: /usr/local/lib/darktable/plugins/imageio/storage/libgphoto.so\nIt was renamed /usr/local/lib/darktable/plugins/imageio/storage/libgooglephoto.so\nBest to completely clean the install directory.. You've built it yourself?\nYou may try to run:\n$ darktable --version\nTo get the actual version. And maybe display all messages to see if something useful is displayed:\n$ darktable -d all. Ok.. Now support styles too.. It was marked in 2.8 :(. Now merged! Will be in 2.6.2.. Sadly not possible. There is nothing like a quick release at this point. We need an announce, to create a new tag for this new release, attach the sources, ask the Windows and MacOS maintainer to create a new release, download them on the release page... etc.... Since you are building from source, can you try by reverting:\na9ce955a7d8b75927cda1eaf80cc8c2f497f6db4\n?\n. This commit is fixing:\nhttps://redmine.darktable.org/issues/12576\nThat's the only commit that could explain this issue I think.. Ok, but then the other issues arise. It would be hard to keep the compatibility here.. Ok, let's try that. Please revert to current 2.6.1 and apply the attached patch over 2.6.1. Test again and let me know if the proper profile is found. Thanks.\n0001-Add-backward-compatibility-when-looking-for-a-profil.patch.txt\n. Perfect! Thanks for testing.\nNo need to change in other places as this was exactly what was done in a9ce955. So new edits are handed by the strcmp() and old edits with strstr(). Will commit that.. Ok, reopened.. Sure strcmp() is not sufficient that's why I have used strstr() to check for basename. Note that p->filename is always a full pathname in new version. Only the filename parameter can be a basename when coming from older versions. So at then end I do think that I was not almost correct but fully correct :) My current patch should be equivalent to you code and far simpler actually.. There seem to have some confusions. In your first step you checkout 2.6.1 and apply my patch. That's not possible since my patch is already on 2.6.1. So you may have reverted it? Don't know what you are doing, but I can see a proper conclusion from what you've written above.\nPlease do print the p->filename and filename parameter using 2.6.1 and whether the profile is found or not.. You are pulling from the tag! You should pull the branch darktable-2.6.x, there is 5 more commits on top of this one. Top is:\n```\ncommit b6075487c98c51aa7e33d0a208c3eccca7e9cea6 (origin/darktable-2.6.x, darktable-2.6.x)\nAuthor: Pascal Obry pascal@obry.net\nDate:   Sun Mar 10 18:34:19 2019 +0100\nAdd backward compatibility when looking for a profile.\n\nThis is to ensure that with the change a9ce955 we still get the\nproper profile for old edits.\n\nsrc/common/colorspaces.c | 15 ++++++++++++++-\n 1 file changed, 14 insertions(+), 1 deletion(-)\n```\n. BTW, do you have a simple way to reproduce? An XMP maybe? Or is that require a db entry?. Ok, so looks like colorin.c does need a change too. Can you try the following patch? You need to apply it from current darktable-2.6.x branch. Please report if it works, thanks for your help on this.\n0001-Add-backward-compatibility-when-looking-for-a-profil.patch.txt\n. Ok, thanks I have applied this. Can you double check that the branch darktable-2.6.x works ok for you now as-is? And then I close this for good. And BTW, thanks for the testing and help on this!. Sounds good and so we can certainly remove the image information from the histogram as discussed in #2037.. > it support multilines by using the $(NL) variable\nThis seems equivalent to entering directly \\n, right?. Ok, fine with me anyway. That was more a question to understand.. Yep, agreed with Aur\u00e9lien, you just have to hide it.. Thanks ! Looks good.. Probably because it now properly report information given the export profile whereas before it was given some \"information\" not fully correct. Not sure if the speed can be improved.. This should be fixed now. Thanks Edgardoh.. No since dt is 99% C and not C++.. Try disabling OpenCL you have many errors reported.. Not found good practice or on my side either. Maybe just add an int (used as a boolean since an OpenCL true is -1) to indicate that the profile_info is set or not? Not sure it is better, a NULL pointer is 0 anyway.. Agreed, let's go with this then. Thanks.. Can you test the attached patch?And report if it works. Thanks.\n0001-denoiseprofile-fix-build-on-OSX.patch.txt\n. Cannot reproduce either:\n[dev_pixelpipe] module `point noir/blanc raw' min: (-0.008601) max: (1.000075) [export]\n[dev_pixelpipe] module `balance des blancs' min: (-0.016078) max: (1.362228) [export]\n[dev_pixelpipe] module `reconstruire hautes lumi\u00e8res' min: (-0.016078) max: (1.000000) [export]\n[dev_pixelpipe] module `d\u00e9matri\u00e7age' min: (0.010517; 0.000000; 0.000000) max: (0.703251; 0.694982; 0.467954) [export]\n[dev_pixelpipe] module `r\u00e9duction bruit (profil)' min: (0.010632; 0.000000; 0.000000) max: (0.703252; 0.694983; 0.467953) [export]\n[dev_pixelpipe] module `r\u00e9duction bruit (profil) 1' min: (0.010632; 0.000000; 0.000000) max: (0.703252; 0.694983; 0.467953) [export]\n[dev_pixelpipe] module `exposition' min: (0.025340; 0.000000; 0.000000) max: (1.676106; 1.656398; 1.115304) [export]\n[dev_pixelpipe] module `correction des objectifs' min: (0.025340; 0.000000; 0.000000) max: (1.676106; 1.656398; 1.115304) [export]\n[dev_pixelpipe] module `profil de couleur d'entr\u00e9e' min: (27.110384; -40.538998; -11.837816) max: (126.343163; 1.676023; 47.711552) [export]\n[dev_pixelpipe] module `balance couleur' min: (25.359760; -37.577957; -11.061406) max: (139.806412; 1.322940; 42.473339) [export]\n[dev_pixelpipe] module `renforcer la nettet\u00e9' min: (24.874491; -37.577957; -11.061406) max: (150.433334; 1.322940; 42.473339) [export]\n[dev_pixelpipe] module `profil de couleur de sortie ' min: (-0.108992; 0.000000; 0.000000) max: (1.460245; 1.667390; 1.235941) [export]\n[dev_pixelpipe] module `filigrane' min: (-0.108992; 0.000000; 0.000000) max: (1.460245; 1.667390; 1.235941) [export]\n[dev_pixelpipe] module `filigrane 1' min: (-0.108992; 0.000000; 0.000000) max: (1.460245; 1.667390; 1.235941) [export]\n7.567019 [dev_process_export] pixel pipeline processing took 1.390 secs (2.940 CPU)\n. This is not working on my side. Either I have a full blue output (under exposed) or almost full red (over exposed) central view. I have tested with and without OpenCL. And tried with a CR2 and NEF. Really strange. . In fact this is not an issue in this PR but it is already in master. To reproduce:\n- activate overexpose\n- select in display profile AND histogram profile the same profile (for whatever profile)\nAnd in this case you have either full blue or full red output.\n. Ok, and since this PR is ok I'll merge it. I have opened an issue for the overexpose:\nhttps://github.com/darktable-org/darktable/issues/2192. Thanks.. Looks good to me! Thanks for the quick resolution.. Working fine but it takes some space and I'm not sure I will have a use for it. So I'd prefer having this widget controlled by a preference. You already have one to select the search context, I would add \"none\" to disable this widget if not needed.. BTW, it works fine with the translated text.. Looks good to me. Thanks.. I see, sorry don't run it then as dt seems to not follow the full clang style then.. This will have to be sorted out.. Looks good! Thanks.. Looks good to me. Thanks.. Looks good! Thanks.. I've been testing it :) I'll continue. Thanks for the quick fix.. Tested, working fine. Thanks.. Looks good! Thanks.. Looks nice but the zoom is inverted. A scroll up zoom-in for the center area whereas it zoom-out in colorzones. \nAnd BTW, instead that could the zoom be triggerred while over the little bar just below the curve? And a double click on this are would reset the zoom (which is not possible over the curve as a double click reset the curve). And doing that on the little bar won't need to use the \"pan&zoom while editing mask\".. Forget the zoom in the \"little bar\", we need to keep the reference point (mouse pos) for the zoom. Yet, we may still have:\n- double click on little bar to reset zoom\n- fix zoom up/down for consistency. For me the way mask are working is fine: Augment size of circle with a scroll-down and decrease size with scroll-up. This is natural, scroll-up is like zoom on image, you concentrate on a zone so zoom-in on image or reduce size of circle.\nSo I'll fix (invert) the colorzone zoom in/out.. When you zoom-in you have a strange band on the right witch does not have proper display.. Something fishy, I have hard time to reproduce. It did happen again to me... But cannot reproduce now. But I see something that may explain the issue.\nThe histogram seems to be broken, change mode from string to smooth things seems to go wrong at some point.. I confirm that the issue seems to be with the histogram. Without this patch the background histogram looks correct. But with this PR it is different and seems really wrong.. Ok, it seems to happen on some images and not others. Take the following picture:\nhttps://drive.google.com/file/d/1Mm0zP_AD8Gi_Patd9op5KE0bWRADibLo/view?usp=sharing\nOpen in darkroom. Activate the colorzone and you'll see no histogram but the whole curve area is greyed as part of the histogram seems to be cover all the area.. Indeed frustrating... I have put all my profiles (softproof, screen, histogram) to sRGB. Still the same issue:\nNot activated:\n\nActivated;\n\nAs you can see, the second one when activated the area is far less colorful and I don't have the histogram (well I suppose it is over the whole area).\nNote that you need to fly over the curve for the histogram to be refreshed.. And my history is clean. No base curve, but I have tested with a base curve and still have the same issue.. With my image?\nThis is the histogram on my side (without this PR, with previous version):\n\n. And I have just recompiled with your patch and get the view as described in \"Activated\" second of my previous message... Something fishy here. Probably some non initialized variables.. And I have tested with and without OpenCL. Very same issue on both.. Would be nice to have someone else testing this!. Found the issue by looking at the code. This works fine as long as the main histogram is using the linear view. If set to log or waveform it is not working.. Yes on the tonecurve and level the histogram is fine. When in waveform the log view is used but otherwise when in linear or log the histogram in the tonecurve and level are correct and matching the main histogram.\nBut it looks like even in linear view the histogram in colorzone does not match the main histogram:\nI have this with colorzone:\n\nAnd this with tonecurve:\n\n. Yes it is hue. So the only issue is when main histogram is not linear. This does not work on colorzones for some reasons.. Found and fixed the issue. You were requesting the histogram in log but displaying it in linear form.\nSee #2214 \nIf you agree I'll merge.. Thanks for testing. I have just added a fix to avoid negative values in log mode which could makes wrong histogram when zooming.. I have this on A key and it works for me.. Thanks!. Should be fixed in master.. All good now! Thanks.. The files to reproduce:\ndistmask.jpg.xmp.txt\n\n. @edgardoh : given your recent work on the pixel-pipe and mask you may have an idea?. Looks good thanks!. Could this have been fixed by #2242 ?. Looks good to me. Thanks.. All this is normal. Please read the doc.\nAlso which version? And please a reported issue should have a single issue described. Here you are mixing expos\u00e9, zoomable view, arrow use.... Thanks!. I'll open an issue with an image with artifacts just to be sure there is nothing broken.. Indeed, this is due to my change to clean-up the geoloc support over all the base code.\nluaA_struct_member(L, dt_image_t, geoloc.longitude, protected_double); // set to NAN if value is not set\nluaA_struct_member(L, dt_image_t, geoloc.latitude, protected_double); // set to NAN if value is not set\nluaA_struct_member(L, dt_image_t, geoloc.elevation, protected_double); // set to NAN if value is not set\nBecause on the image struct the longitude, latitude and elevation are now in a struct.\nIs there a way to map those lua field into a specific name? I mean keep the new struct but have them referenced as before on Lua side?. BTW, how to reproduce? I may have a fix? Or you can try the attached patch? Thanks.\n0001-New-version-of-Lua-struct-binding-with-takes-a-speci.patch.txt\n. Merged, thanks.. Thanks!. Yes there is advantage at least in readability. When you see a gboolean you know that it is a 2 states variables. And this is also important for consistency as all dt code do use gboolean when possible. I'm sure there is case where this is not done, but they should be fixed when possible.. Thanks!. That's the way it has been done by the original author.. No, a fading is a loss of time.. GUI redesign.. Will be in the GUI redesign.. Not sure. The lighttable redesign has been done to be able to work on 4k or 5k monitor. The smooth whatever will certainly slow things down.. So please before opening a zillion of issues, read the manual :) You'll certainly discover lot of things!. You want to see the original over the current thumbnail? Right? That would be handy indeed.. Well let me be clear. I'll close all your tickets as I don't have time answering all the questions that are already in the manual.\nNow, please read the manual, from first page to last one. And come back with some real issues.. Can you double check your preference when editing this file?\nAll the references have now a full pathname:\n-#: ../build/doc/usermanual/po/darktable-usermanual_profiled.xml:290(para)\n+#: /home/nico/Projets/darktable/build/doc/usermanual/po/darktable-usermanual_profiled.xml:290(para)\n. Strange, poedit does not do that for me on GUI translation file.. Thanks, will squash & merge now.. Looks good to me. One minor comment, please be sure to add a little description into the comment message to what was done. It may be useful when reading log message. Of course the ref to the issue is important, just that a little description too may help especially for me reading log message to check against the release-notes and looking for potential commit to merge, etc. Thanks.. In the commit log of each commit. The first line should be a short description, followed by an empty line then a longer description when needed and then the issue ref if it exists. See for example: 38006e5f. You cannot do that on GitHub. This must be done at commit time for each commit. You can also do an interactive rebase and reword each commit if necessary in your topic branch (this is advanced, but I do that all the time). . Thanks!. This is very worrisome, but I cannot reproduce! Are you able to reproduce this issue each time? A precise sequence maybe?. Should be fixed now. Thanks a lot for reporting.. To me the second version makes no sense! I bet it just does nothing on the file.. Show the doc please, as I said the fix makes no sense to me.. Thanks!. Looks good thanks!. Thanks!. Thanks!. Indeed! Good catch. Thanks.. Oups, a left over of a previous version. Will fix.\n. No, here we are no talking about the view, but the object being inserted into the undo module. A view could have many undo data type to record.\n. No, the point here is to be able to have a configurable undo as described by jcsogo. The idea is to let the possibility to undo a rating from lighttable into darkroom. Not used at the moment, but the desing here make this possible.\nNot sure either for the darktable global variable. Here the state is abstract (it is an ASM) and not an ADT (so no visible type to manipulate).\n. Not sure. I've copied this part from code in dt. The idea is that filter can be a set of dt_undo_type_t:\ndo_undo (DT_UNDO_GEOTAG|DT_UNDO_WHATEVERELSE|DO_UNDO_SOMETHINGELSE);\nSee another example view in dt_view_t struct returns an uint32_t which is in fact a value in dt_view_type_flags_t.\nIn fact we return the value of the enum and not the enum itself.\n. Declaring it in darktable.* would break encapsulation so everyone would be able to call g_free() on the list. I will of course declare it static, a mistake indeed.\n. More precisions won't hurt! Will do that.\n. Agreed, I had thought about this! Far better indeed. Will do.\n. Don't know, what was the problem? I see many use of \"%.02f\" in the actual code.\n. It was also the case when the style was added.\nIs there a way to avoid that?\n. Indeed :( Good catch! Thanks will fix in a moment.\n. indeed, a french spelling! fixed.\n. right, fixed here and in other places.\n. good catch, %s of course here. fixed.\n. Sure, fixed.\n. Right, cut&paste error. Fixed.\n. Fixed.\n. Fixed.\n. Fixed too.\n. Fixed.\n. Fixed.\n. Good catch! Fixed.\n. Fixed.\n. Fixed.\n. I'll let the expert convert to GTK3. houz has proposed to do that.\n. Fixed.\n. Indeed, fixed too.\n. Right, I have used fprintf on stderr with \"error:\" as prefix as in many places already. will help dev to track down errors.\n. Now fixed also, I had forgotten it in the first batch of fixes.\n. I know, to accommodate different Gtk+ version. I didn't push the right version. Will fix that in a moment.\n. Indeed, harmless but fixed. Thanks.\n. Fixed!\n. Not needed anymore indeed! Good catch. Removed locally.\n. I did that at first and it makes the dt_view_image_expose() even more unreadable. So to me it's a compromise between readability and code duplication. Would be good to have other point of view as I've no strong opinion and both solutions have pro and cons.\n. Yet, I'll see tomorrow if I can put the common code in a specific procedure. I don't remember all the details as this was done long time ago now.\n. @LebedevRI, I have refactored the code, what do you think? I find that the routine is a bit complex now but no strong opinion.\n. Indeed, it is reporting the size in 1/72 inch.\n. Right, we will have to move to IPP in the future. There is not enough doc or code sample to move to IPP now, some parts are really not clear. This has been deprecated very recently.\n. Indeed a copy is passed, actually a symlink in /tmp to the corresponding PPD.\n. Ok, fixed.\n. Indeed, fixed.\n. Good catch!\n. Fixed.\n. Only 8 bpp as this is what the CUPS print driver can actually handle. So in input we have either 8bit or 16bit but in all cases the output is 8bit.\n. Right :) All this should have been removed in version based on PDF. Fixed.\n. Hum, all this is left over from old implementation. Will remove an squash it!\n. Removed.\n. Indeed, I suppose that's some left-over of testing.\n. That's fine, the image is always on the same orientation on screen. I was puzzled when I implemented that but it is correct.\n. Fixed.\n. Comment fixed;\n. Indeed, fixed.\n. Fixed.\n. Fixed.\n. Fixed.\n. Not sure to understand what you mean here?\n. Done.\n. Done.\n. Fixed.\n. Fixed.\n. Indeed, fixed.\n. Done.\n. Right but here we just need the aspect more than the actual size. To display on-screen we just need to computer the origin. The comment is maybe not explicit enough?\n. fixed.\n. Indeed, lot better!\n. I see, didn't know that dt_print() exists! Fixed.\n. This is not what I'm seeing. This is used to get the proper displayed image on the print module and it works. I have just added a printf for buf.width/buf.height and I get different values.\n. Is there any other way to get the image aspect ratio?\n. I've changed that too.\n. Great! Working like a charm! Thanks.\n. left over of previous implementation. Now fixed.\n. Ok! Thanks.\n. Indeed, fixed. I missed that in my first batch of fixes.\n. Fixed.\n. Fixed.\n. Indeed. Fixed too. I'll do a final pass and will merge.\n. Yep, this call was missing indeed!\n. done.\n. done.\n. that was my thinking too.\n. Indeed, but it was not working because the signal is raised only if the image_id is different that what is already recorded. It was recorded by the darkroom module. New patch in a moment.\n. I'll check. k is not needed here as shared() never include the loop variable.\n. Argg!!! Indeed, I won't get this right :)\n. No, don't want nor need font-size here. This is important as we need the half value of font-size in the y parameter. And sine anyway the svg is scaled to the whole image there is no need to make the code more complex here.\n. $(WATERMARK_FONT_FAMILY) never contain font size.\n. Yes but this is the font-name. The family is retrieved specifically:\ng_snprintf(buffer, sizeof(buffer), \"%s\", pango_font_description_get_family(font));\n. Will use clamp() as gdk_rgba_to_string() returns a format \"rgb(r,g,b)\" not supported by svg.\n. Strange! A procedural error on my side then !\n. Ok, I'll commit my version and I'll let you push your fix.\n. Indeed. Should be fixed.\n. Sorry I miss interpreted \"Nah, just commit your version of this fix into this branch.\"\n. No, this is true since now this is done on a dt background job. cupsEnumDests() won't help as it returns only when all dest have been found. there is no support in cups for asynchronous printer discovery.\n. I see what you mean now. I agree that cupsEnumDests is probably a better choice here.\n. Just a thinko. Fixed.\n. No it is freed in undo.c. See _free_undo_date. This routine is only for freeing any internal data if needed. It is not needed in map.c for example.\n. fixed.\n. Better indeed. Fixed.\n. Indeed! Let's default to Ctrl-Y.\n. Agreed again!\n. I don't think so, this is freed in _free_undo_data. All memory should be freed when leaving the map view.\n. I see, not really we need:\n\nif (item->free_data) item->free_data(item->data);\nfree(item->data);\ng_free(item);\n\nShould be fixed now.\n. comment fixed.\n. @pedrocr what about my latest proposal? This is not changing the place of the metadata but it makes it possible to hide them (using the current option) and have them appear when overing in the zone. This does not loose space for the image and at the same time it let the user view the image without the overlay. Seems like the best options to me.\nSee:\nhttps://github.com/darktable-org/darktable/pull/1124\n. Please, I can understand that you prefer having them on top. We all have different views, but do not call the overlay hiding a kludge. Hiding overlays is something done since long time in many softwares.\n. Apart that I have no objection for merging as this is a preference.\n. Indeed a nice big leak :) Fixed.\n. This is a bit mask. I really want DT_UNDO_ALL to be DT_UNDO_GEOTAG | DT_UNDO_HISTORY.\n. ok\n. ok\n. Indeed, fixed in latest version.\n. You mean as default? I don't have a strong opinion, this can always be changed in the preference. It is indeed the case that ctrl-y or ctrl--shif-z are both used. GIMP is using ctrl-y that's why I've used this.\n. Ok, noted.\n. _WIN32 is the implementor name. The WIN32 is one defined that can be redefined by users. So the preferred way is _WIN32 to use the Microsoft definition.. To me _WIN32 should be fine with MS compiler and MingW compiler. For WIN32 we never now, it may or may not be present. Now I don't have enough experience with Microsoft compiler if WIN32 is defined every time _WIN32 is defined. To be checked with MingW compiler too. This is Windows World Roman :) . It is not because it compiles that it is correct. @Inicola: yes I think we should use _WIN32 only.. No we don't want 3 line hints messages. In some DE there is not enough room at the top and this makes the whole darkroom to be resized and so move when hovering the corresponding item. Maybe keeping the two first on the same line?. ok. good catch!. Sounds good to me!. exbias_callback -> exposure_bias_callback. well, we already have exstep_callback, frankly I would rename this too to: exposure_step_callback. Right.. An oversight. Now fixed (and rebased on master).. Hum... embarrassing :) I did not notice this routine which seems to be what I need. I'll fix.. No, this won't happen. The new XMP I've seen are fully converted to new format.. Ok, will do and test.. Indeed, better. Fixing.. Also I don't think there is change on the stack usage, the variables were there before.. @LebedevRI houz said that a single \"{ 0 }\" was ok and on my side I have no warnings. Maybe a different compiler? I'm using GCC 7.2.. Ok, otherwise using \"{ { 0 } }\" works fine. But I'll use one memset().. Yes, I had this on my todo list for some time now. I plan to propose a patch in this direction for 2.6.. Just plain mistake on my side. I'm fixing.. I want to say: \"color management done on the server side\", but with a smaller string.\nMaybe \"server side color management\", it should fit into the dialog. Do you have a better proposal?. You're plain right, I should have used _(\"none\") here.. It fits, let's use this. thanks!. spaces after colon.. spaces after colons. you probably want to remove this commented out code.. superfluous empty line. superfluous empty line. superfluous empty line. superfluous empty line. likewise. likewise. likewise. likewise. likewise. all the units need at least some comments. fprintf(stderr, \"..\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. superfluous empty line. superfluous empty line. sounds like yy and xx could be const.. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. fprintf(stderr, \"...\");. superfluous empty line. Why not use DT_MASKS_UNMANAGED as this is to avoid the mask to be added into the mask manager. I would at the same time using this bit for the DT_MASKS_CLONE and using only DT_MASKS_UNMANAGED when we check for the type to see if we want it into the mask manager. Seems like it is cleaner and convey what we are trying to do. What do you think?. I see, sure the spot healing could be ported into the spot removal iop, but it seems handy to me to have the retouch iop with the spot integrated otherwise we will have lot of back and forth between those two iop while working on a portrait. That's to be discussed indeed!. could be const. const?. const?. sounds like days, times could be set const too?. const. const. const. const. const. const. const. const. const. const, likewise  for \"formid\" and \"form\" just below.. const. const. const. const. const. const. const. const. const. const. const. const. I would remove the code or add a comment about why it will be used later. This is large code and it will certainly ease the integration if retouch.c get smaller.. I would remove the code or add a comment about why it will be used later. This is large code and it will certainly ease the integration if retouch.c get smaller.. to be removed ?. likewise?. do you want to keep this code?. to be removed?. to be removed?. to be removed?. to be removed?. to be removed?. to be removed?. to be removed?. to be removed?. no space before '('. no space before '('\nsame for next line.. style is to put {\u00a0on it own line. Not sure about SQL injections since this is a system command. What you would do?. fixed.. No I don't need more link. I know that a system call is not safe but I'm questioning the SQL injections. And yes we already have some system() calls. darktable is not a highly secure embedded control code for whatever life critical application :). No it is not, of course and I'm aware of that. Many applications are using system() or exec() to spawn external process. We do in different places and have no alternatives, do we?. Indeed, lot better.. Great, so I'll merge. Thanks.. This is in legacy param and the value was stored as _(\"none\") so we need to check for this value here. It has been discussed with houz, see comment above.. Indeed, it was leaking.. Done, cleaner anyway.. the brace should be on its own line. I would pass directly a \"dt_lib_print_job_t p\" and then ends with free(p); *p=NULL;\nTo ensure that the passed parameter do not keep an address to a released memory chunk.. I see that this is a callback passed to the job control. Not possible I suppose then.. No, job->params is not released in dt_control_job_dispose(). So you code is correct and we don't have a dangling reference indeed as the top-level struct (_dt_jot_t) is freed. All good I suppose.. would be nice to do this before merging.. I've done this on my side. Will merge and apply this commit. Thanks.. I'm not sure at this stage. In fact the ellipsis should be done based on the whole string length an more over taking into account the final translated string. So at this stage i would be more leaning toward dt_control_log doing the ellipsis if needed:\n- get final string\n- compute length, if > to a LIMIT, then\n- compute the number of %s (NS)\n- divide the number of chars above LIMIT by NS\n- ellipsize the %s accoringly\n- get final ellipsized string and display it\nI'll try to discuss this with houz in IRC when I get a chance.\nBut doing this job in many places into the code looks wrong to me.. Ok, let's go the simple way then. And we'll see how it works and adjust if necessary.. this empty line is not needed.. sounds like there is indentation issues. please do not use tabulations. more issues like this below.. then we do not need this section. just add a clear comment in the commit log that there is no published in lr. or an alternative solution is to have publisher use the creator if present?. no tabulations please.. and why it is not currently done? maybe add some comment?. and why it is not currently done? maybe add some comment?. Ok, fine with me. I just wanted to be sure this was not some leftover or forgotten part.. this is superfluous to me.. I would keep \"local copy\" last so putting grouping just before as \"local copy\" is different to others to me.. maybe change this for consistency reasons with message above to:\n\"cannot display masks when the blending mask is displayed\"\nIt is also shorter.. superfluous empty line. style is no space after ( and before ). this is not correct as it checks the original orientation. take a landscape picture, use crop&rotate and create a portrait composition. You'll see that the format will be hidden under the picture. You should use the height and width as cropped.. no spaces around ( ). likewise. likewise. no spaces around if, should be if(...). please keep the DT_COLLECTION_SORT_NONE as the last alternative.. maybe this should be out of this patch-set as only reformatting.. likewise, all this looks like reformatting.. likewise, just reformatting. Again I'm not against it, but it makes the actual patch more difficult to read. . likewise.. likewise.. just a code clean-up?. likewise. I'll stop read from here. Please remove all the reformatting out of the actual patch doing the real work.\nthanks.. That's not what I was told and what I heard. We have a reformatting script that we do run from time to time. Having all those reformatting into a PR is just noise and makes it hard to read. As-is I won't approve it anyway as I cannot see exactly what has been really changed. Too much work, sorry.. And to be clear, I'm not against the reformatting as long as it is on a separate commit to ease the review.. Is that because it will introduce a bug? it may be interesting to rename to give a hint of what this module is used for on the history?. this is redundant as the g_strlcpy() doc makes it clear that dest is guaranteed to be null terminated.. No, that's fine. I'm just trying to be sure we do not oversee something. We can always add this later if necessary.. That's it, so you've disable the move at the center when moving the mouse out of the darkroom. I have done just the opposite in liquify. I find it better to have the mask at the center instead of staying on the border and sometime not very visible.. I think consistency if very important. I must say that I have no string opinion on this. The only thing is that we must choose one option had have the masks, the retouch and the liquify works the same. Any opinion on that? We need to agree on one behavior :). If you really like better to have the preview stays on the border I'm ok with that and will change liquify accordingly. Just to be sure we agree on this.. Fine, I'll adjust liquify then.. Done.. I think LAST should stays in last position, no?. A comment added, but I don't see why? If there is noting to say about it, better remove this line otherwise can you add a blurb about what it is about?. Bear with me, I'm no expert. But is it ok to have a Prophoto RGB color space into the list of matrix? I mean we don't have Adobe RGB here for example.. In all color picker callback routines you want to activate the module if not already the case:\nif(self->off) gtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(self->off), 1);. The control flow is a bit complex and seems to be equivalent to:\n```\nif(self->request_color_pick == DT_REQUEST_COLORPICK_OFF)\n{\n    dt_iop_request_focus(self);\n    self->request_color_pick = DT_REQUEST_COLORPICK_MODULE;\n}\nelse\n{\n    dt_iop_colorbalance_params_t p = (dt_iop_colorbalance_params_t )self->params;\n    dt_iop_colorbalance_gui_data_t g = (dt_iop_colorbalance_gui_data_t )self->gui_data;\ndt_dev_reprocess_all(self->dev);\n\n...\n\n}\n```\nAgain, this must be done in all color picker related callbacks.. I'm not sure those 2 calls are really necessary.. 4 floats\nfloat color_patches_lift[CHANNEL_SIZE];\n3 floats:\nfloat RGB[3] = { 0.0f };\nSo not sure the \"left = right\" is correct. There may be some other wrong copy like this.. Sorry I'm speaking of dt_iop_request_focus() and dt_control_queue_redraw();. Of course not :) C is stupid. That's a quite old language at this stage and with lot of pitfall for us to kill ourselves:) . Is that still correct?\nI mean you're mapping RGB to  CHANNEL_FACTOR, CHANNEL_RED, CHANNEL_GREEN.\nMaybe: d->color_patches_gain[c+1] = RGB[c];\nBut this means CHANNEL_FACTOR is not set.\n. I did not spot that, there is a 2 added at the end of the first value! Sounds like a typo, Aur\u00e9lien?. I have reverted this part now.. for consistency please { under typedef. float ...;\nfloat ...;\nI don't remember having seen a single field declaration on 2 lines in dt. . This is not true for v4! You have two different structs. So you'll need a special case for v4 with a decl in the form:\ntypedef struct dt_iop_denoiseprofile_params_v1_t\n{\n...\n}\ndt_iop_denoiseprofile_params_v1_t o = (dt_iop_denoiseprofile_params_v1_t )old_params;\ndt_iop_denoiseprofile_params_t n = (dt_iop_denoiseprofile_params_t )new_params;\nAnd do the appropriate copy.. this is wrong (and crash probably) as old does not have the same size as new.. All entries should be capitalize:\nDENOISEPROFILE_ALL = 0,\n.... could probably be : const int ch = .... See exposure.c for inspiration for example.. The {\u00a0should be under typedef.\nAll entries should be capitalized and with DT_ as prefix:\nDT_RAWDENOISE_ALL = 0,\n.... See comment about legacy_param in #1753 . This one is lot simpler to solve as this new version is only the second one!. This is highly suspicious as you don't actually reset the module params anymore.\nYou need to setup tmp fully and then keep the memcpy() at the end.. Same code you have below in init() for initializing tmp.. Yes it is necessary! That's the only way to passe the params between pixelpipe and module params.. can probably be made const?. No, fine I read as if you were copying the would struct with memcpy() and that you were reading past the old struct. I don't this that now! Good to me, you are copying the field one by one.. return TRUE;. return FALSE.. can be removed with proposed change below. Perfect! Thanks.. I would certainly use a case statement. And possibly with the following scheme:\n```\nint handled = 1;\nswitch()\n{\n     case:\n     ...\n     default:\n        handled = 0;\n}\nreturn handled;\n```. Please { on next line.. I'll do that in profle_gamma.c. Yes, I know but that's not dt style (and that's not a style I have chosen, I wasn't dev at the start of the project, but consistency is important). Will fix :). the matching issue is probably because you are converting to float here (in C) and later you just convert back to float (in SQL) for the matching... No surprise you have rounding issues, and so matching issues.. I doubt this is working. The problem is probably than in collect.c we have < 0.5 instead of <= 0.5 here. Moving to 0.4 is not the proper fix.. Note that I'm testing with a DB of 50k images, and I'm probably checked 10k or such image by ensuring that the number of images displayed on the lighttable equal the count on the collect module.. Can you test with latest fix I just pushed? If not working, can you provide the image showing the issue? Thanks.. Likewise, no capital letters on log messages.. No capital letters on log messages.. I would certainly terminate the array with \\0 and stop at the end. Having two coupled variables is not good I think.. should be gboolean (not sure bool is supported on all GCC version and CLang). I could be wrong, but in dt we do use gboolean.. Well 0.4 is 2/5 so we can't display it as fraction which are all \"1/n\".\nMy question remains, have you tried this image with the last dt version where I have pushed a possible fix?. I see, 0.4 is kind of pathological case as we don't have a 1/n close enough for 0.4. I have pushed a fix for collection.c and collect.c (both must be synchronized) which fixes this case. Can you test?. Can you add a set of comments at the start of the script about the setup before starting the script. From where it should be run? What are the db to copy before starting... etc. A bit of context for first time users.\nAnd also what it does. As I understand it, it creates a tag for each Capture One collection? All this must be clearly described. Thanks.. No, we need to call dt_iop_get_group() now to let the possibility to reorganize the IOP.. should be all upper-case : DT_IOP_FBW_BW_MIX_DST. do not use bool it breaks some compilers, use gboolean.. true -> TRUE. false -> FALSE. @aurelienpierre : I suppose all the changes below are not expected. right?. Yes, \"git reset -p HEAD^\" but this is not on the top commit so you also need to play with git rebase -i I suppose. I can handle this in less than a minute, so I can do it if you don't feel messing with Git. Just let me know.. Done, please double check that I haven't mess anything. Thanks.. the name was wrong, cut&paste... I have fixed that.. And there was a missing include, seems like you didn't even test to compile the code!. You should have said so upfront I would have paid more attention to the code. Anyway all under control and working now.. isn't here picker_ expected instead of the raw_?. Why the underscore just after [? Is that a dt style, I never paid attention to that.. same question here about the underscore. I don't see where. It is refreshed later in the routine. In any case I would certainly remove those commented out code if it is not necessary. And add a hint where the pipe is recreated.. Understood. Then better moving the message indeed.. Is the comment here still actual?. Ok, let me just try an assertion to check I'm reading this correctly.\n\nbefore nbhood was 7 and we are looking at the 7 neighborhood.\nnow nbhood is 0, and the coordinate_offsets is \"coordinate_offsets[v] = v\" so we are also looking at the same 7 neighborhood.\nif nbhood is changed then we have 7 more spread points to look at (for catching coarse grain).\n\nAre all this right?\nIf so, indeed we just break history with recent change and this is not an issue since it was only on a dev release. So waiting for your comment before merging.\n. I'm stupid, I just saw your second comment explaining exactly that. So I have my answer, and it is good to see that I got it right :). can't we have multiple cleanup() for a module? this is done also just in the loop above.. can't parse this one. \"with form is the same formid\" should it be \"with form with the same formid\"?. \"with is id\" -> \"with its id\"?\nSame typo below, you're not the culprit here, but if you can fix it too.. { should be at the start of a new line. we have two section identical, the code above is the same as this one.. No capital letters in UI label (G -> g).. Please keep old string \"auto tune source\", sounds better.. Yes it means \"tune source image\". That's the way I understand it and the way Aur\u00e9lien wrote it. To me it is clear. Maybe we can come up with something better: \"auto tune levels\" ?. Should we switch the feathering radius slider and the blur radius slider?\nMy idea is to have the bur radius first as this is the current slider we have and so it will be easier for people to use just this one (as in 2.4)? What do you think?. this is wrong, please do not rename as the curve-tool can handle basecurve and tonecurve.. All this sounds ok to me. If @upegelow is ok I'll merge.. Thanks, will merge then.. Right. Will update the doc.. you are missing black_point_source. Too bad :( I've not followed the discussion, but the blendop legacy support does not work?. I mean we have the same circuitry in denoisprofile for example where it seems to work, no?. self->version() here seems strange, it means that the version of the param is always set to be the latest version of the module. It should be the version of the param at the time the preset param was created I think?. The code in denoiseprofile do use version which is passed to the add_preset().. Ok, I was indeed asking myself about the / 200 ! I'll integrate your change in this PR. Thanks for the review.. Yes, done. I'll try to merge this in 2.6.0rc1 if no more comment.. is that expected or a left over of some debugging? OpenMP is deactivated now.. Note that all this is equivalent to:\np->interpolator = combo;. Understood.. The preset name should be \"contrast fulcrum\" or something more readable.. What about:\n\"duplicate image without its history\" -> \"duplicate image with pristine history stack\". default cfulcrum is 50.. But then the algorithm does not keep history as here : 50/100 is not equal to 1. . This is ok, but below.... Right I missed that!. Just that 50 is ok as a default value and to introduce my next comments.. I'm wondering if this is the right option. Maybe we should also match the L channel to have the correct color and let user adjust if necessary? It seems easier this way than letting the user try to adjust the L channel to match the color.. I don't think this is correct, it may or may not work as gtk_style_context_lookup_color() does not say that the color is not changed if not found. In dt we currently do:\nif(!gtk_style_context_lookup_color(ctx, \"thumbnail_bg_color\", &c[DT_GUI_COLOR_THUMBNAIL_BG]))\n   c[DT_GUI_COLOR_THUMBNAIL_BG] = (GdkRGBA){ 0.4, 0.4, 0.4, 1.0 };. ok, but I would keep the comment for the readers:\nelse // case cpp == 3 or 4. Indeed, looks like a code after refactoring :). And as we are at it, make imgwd a const to make it clear that it does not change.. I'm not sure to understand, maybe too tired, can you tell me more about 0x99 / 255? This is 0 right in int arithmetic?. Ok, but then not cast but maybe 255.0 (we do write .8 but I've never seen a float without a digit after the dot).. Are you sure about this one?\nWe have:\nif(p->k_type == 4)\nelse if(p->k_type >= 0 && p->k_apply == 1)\nelse if(p->k_type == 0)\nelse\nSo the else part can be taken if p->k_type > 0 and p->k_apply == 0.. dt_dev_add.... dt_dev_add_. No worries Ulrich, this won't go in 2.6.0. Maybe in 2.6.1 or later.. superfluous change, braces not needed here.. please space before &&. can you clarify which state this boolean captures?. I see, not fully obvious from code reading, maybe adding some comments will help.. Just spotted this mistake. The index i start to 0, first item name is \"darkroom_bg_color\" but it is set into the c[0] which is actually DT_GUI_COLOR_BG. And since the loop is going up to DT_GUI_COLOR_LAST-1 then we read last element in the struct which is not set.\nCan you have a look?. Fixed in 46b1d457e4d5d9. I suppose \"git\" should have been put in the console :). That's my point too, as for Aur\u00e9lien, we need to assume all is correct and if dt cannot guess right there is lot of chance that the user won't be able to get closer.. you've removed the transaction to ensure atomic commit.. end of transaction was here.. you've changed the semantic. to me the pointer was correct and the line above we to be read:\n\nif force_autoapply is not null\n   => for apply if force_autoapply is 1 (*force_autoapply)\n   => otherwise apply if preset.autoapply is set.\n\nOf course we can do the same with a standard int or even better a gboolean and this is probably better than having this pointer.. all those changes are not correct I think. The autoaplly should be 0 (deactivated) for the  built-in basecurve. The way to autoapply them is to create let the user create a preset based on it and then set the autoapply with possibly conditions from within dt. . Sure the pointer is not needed. We can use a gboolean (better than int here) as I said. Maybe we can start with that (code clean-up) and try to understand the other issue after?. The transaction ensure that every changes in the DB  between the BEGIN / COMMIT (or ROLLBACK) is either fully committed or nothing is changed.. Do you want me to do the clean-up?. this can't be correct, your second force_autoapply is always 0 so this is equivalent to:\nforce_autoapply ? 1 : 0\n. What are the numbers meaning here? \"0.\" above then \"1.\"... \"I.\", \"II.\" ?\nIs that needed? Sounds like noise to me.. All \");\" should be on the previous line ending the code.. This is a decision (and a good one I think) made at the start of darktable.  A RAW is always a bit sharpened by all RAW software and so darktable do so. Again I suppose that one can create a preset to disable this module by default if needed.. So maybe use the same numbering? Why using roman number for the last 2?. I see, let me try this then.. Sorry don't like the number because they do not fit well with others preset like all or none activated.\nWhat about:\ntoolbox : all purpose\ntoolbox : portrait & beauty\n...\nsubset: creative only\nsubset: technical only\nand the current presets:\nsubset: all\nsubset: none\nsubset: default\nWe have now two groups, sorted and named.. So if ok with you, let's go this way. Thanks.. we are talking about pixels here. 250 seems quite large already, maybe add a soft bounds? See for example exposure, the slider goes to 3 but can be expanded to 18 EV.. I withdraw my objection about this one.. should be %%. should be 18%%. Sorry my bad, in tooltip there is no need to have double or quoted %. I'm about to commit a fix with this patchset. I have also removed spaces around \\n.. @rabauke : not sure to understand. a soft bound is a standard slider with a default bound set for example to 250 for the featuring radius today. The soft boundary just let the user enter a numerical value bigger than the 250 of the default bound and from there it is possible to adjust between the new bounds. So I don't see what problems you are referring too...\nCan you clarify? Thanks.. this change is not ok, dt style is to have curly-brace on a new line.. Why removed that? Is that expected?. Force push will be better. Thanks. Indeed, I don't see why this was needed! And it seems that it has been added long time ago.. should be an dt_view_image_over_t instead of int.. You need to:\n1. remove the old D850 entries\n2. do not add the D500 in the same commit\n3. rename the entries from \"\"NIKON CORPORATION\" to \"Nikon\" and \"NIKON D850\" to \"D850\".\nI have done 3 for the D500.\nThanks.. const __m128 f = _mm_set1_ps(filter[(ii)] * filter[(jj)]);.         w[0] = _mm_set1_ps(filter_jj[0]) * weight_sse2(px, pix[0], sharpen);\n        w[1] = _mm_set1_ps(filter_jj[1]) * weight_sse2(px, pix[1], sharpen);\n        w[2] = _mm_set1_ps(filter_jj[2]) * weight_sse2(px, pix[2], sharpen);\n        w[3] = _mm_set1_ps(filter_jj[3]) * weight_sse2(px, pix[3], sharpen);\n        w[4] = _mm_set1_ps(filter_jj[4]) * weight_sse2(px, pix[4], sharpen);\n. Hum... Where? I can't see one... Although I could have missed one.... since sum is sse _m128 I think the we need to keep this line.. And this one too.. Again, I'm not sure about using - instead of _mm_sub_ps. This is loading threshold not in the same order as original. Likewise for boost.. My bad, sorry :). @heckflosse : thanks for the input. indeed the float * _m128 is not supported by clang, we had just fixed this in filmic.. style:\n}\nelse\n{. Please remove all commented out code. This will be part of the commit anyway.. I would separate both font family and font size. This will be easier for people to change one or the other.\n```\nfont-familly: \"Roboto Light\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif;\nfont-size: 1em;\n. style:\n{\n...\n}\nelse\n{\n...\n}\n```. BTW, there is many style like that to fix.. You want to do that in expose() and not here. The switch_layout_to() is called only when changing the mode but the first time we open dt we do want this to happen so in expose() we are sure that the proper action will be taken each time.. why this? any bug with it?. likewise, why is this needed?. I just notice that... \"does not affect execution time\", using this slider I had quickly a large slowdown with values like 15. Is this comment still valid?. Forget this question, I was using another slider! This one indeed does not increase the execution time.. as we are at it: this can be a const. likewise, can be a const. if not modified maybe can be made a const?. Nice one :) with model being empty the strlen() was a no-op!. I would prefer the const to be removed here.... and so (gpoiner) cast won't be needed.. same here :) no const. and no gpointer. thanks.. I find this is loosing quite some space around the modules. I prefer to keep 4.. Likewise, far too much space lost.. On my side I have a noticable change!\nBefore:\n\nNow:\n\n. > the reason for this is it keeps the content aligned on the module title\nI don't see that. This is the margin (inside) so keeping 4 will just makes the borders left and top of button [tout] smaller.. Ok, but this defeat the goal to allow all config in CSS and won't make it possible to have a compact theme.\nYou can remove the hard coded padding (just remove the libe) in the code (imageop.c and lib.c) and add the box in CSS:\n```\n/ border in module widget, 9pt allows the alignment with module label. /\niop-plugin-ui box\n{\n    padding: 5pt 5pt 5pt 9pt;\n}\n```. Ok, so we need to put the margin in a lower box. Let me check.. Why don't you CLAMP the values here? As done in line 181. Seems like it is needed here too, no?. But that's what happen here no? You queue the update for the color_patch just below. Those are for the live samples which happen also to have a widget to display the color for the given area.. const. const. const. const. const. const. const. can be set const. No strong opinion here but I'll keep a single empty line.. const dt_iop_colorspace_type_t cst_to. const dt_iop_colorspace_type_t cst_to. const dt_iop_colorspace_type_t cst_to. const dt_iop_colorspace_type_t image_cst, const dt_iop_colorspace_type_t cst_to. dt_iop_colorspace_type_t picker_cst. const dt_iop_colorspace_type_t image_cst, const dt_iop_colorspace_type_t cst_to. static dt_iop_colorspace_type_t _blendop_blendif_get_picker_colorspace(...). dt_iop_colorspace_type_t picker_cst;. Good catch!. We have a picker_scale in tonecurve.c, the implementation is quite different even if somehow similar. Is that expected? Is that because we have two different CS?. I suppose that ideally we'd want to move this definition into imageop_common.h and include this here and in imageop.c.. looks suspicious that table_r and coeffs_r is used for the x, y & z values.. current max for an operation name is 16, 20 seems ok but a bit short maybe?. what is dummy1 and dummy2? was this for debugging? if it is the case shouldn't it be removed?. maybe remove this commented out code?. this looks stange, better to check dont_move at call point and not actually call this.\nif(!dont_move)\n{\n   ioppr_move_iop...();\n}\nAnd we save one parameter.. \nthis looks stange, better to check dont_move at call point and not actually call this.\nif(!dont_move)\n{\nioppr_move_iop...();\n}\nAnd we save one parameter.\n. if would do:\nif(!dont_move)\n{\n  ...\n}\nAnd remove dont_move param. See comments below.. is that expected that this is self->default_coulorspace and not self->input_colorspace().\nlikewise for the two others implementations below (->blend_colorspace() and ->output_colorspace()). We probably want to delete this file since the module->priority has been removed from all iop, right?. I would remove all those commented out lines.. int -> dt_iop_colorspace_type_t ?. To be removed. It is commented out in CMakeList.txt.\nThe same apply to amm dummy?.c. this is really rgb and not RAW?. A single boolean here:\nv7->fixed_algo\n?. float norm;\nif(d->fixed_algo)\n   norm = .045f / ((2 * P + 1) * (2 * P + 1));\nelse\n   norm = .015f / (2 * P + 1);\n. if(d->fixed_algo)\n{\n}\nelse\n{\n}. if(d->fixed_algo)\n.... Replace all this by a single boolean option and only displayed if (d->fixed_alfo is FALSE). Do we really need this context so low-level? Having a context name for each module seems wrong to me.\nHere we are talking about \"options\" or a \"choice\" and we can select \"both\" of those. In colorreconstruction.c just below we have \"none\" (same context to me, options or choice).. Here the context is more \"color\", we are talking about hue, saturation or lightness in the \"color\" context.. Here the context is \"options\" or \"choice\".. Changing LINGUAS here is not needed. Better to keep this in a separate commit with the et.po translation.. Have you changed name? :). It is not good to add RELASE_NOTES unrelated to current PR because if there is troubles and we revert it will also revert an needed information. And if we need to merge in a branch a feature and not the other this will require editing the commits before merging.\nSo, please in the future keep this in mind. Thanks.. The memcpy() parameters seems to have been inverted. Bug?. typo: 'sperator', I propose:\n\n...using the pipe symbol \\|\\ as a separator. For example \\...\\ will create.... And \\ is not supported, you need to use \\.. This should fix the travis check.. const. const. { should be on new line. const. const int e = .... const double m = .... const. const ?. shouldn't this be a gboolean?. can be removed. likewise. likewise. can be removed. likewise. likewise. const gboolean ?. should be a gboolean. cntrl -> ctrl (for consistency this is was we currently use everywhere).. and you talk about ctrl+r .... ... but here we have ctrl+a. sorry again this :)\n\n{ should be at start of line. You mean that clang compiler is changing that? Don't know I'm using emacs and gcc? But I do compile with clang to check PR and don't have this issue.. C_(\"file format\", \"format\") ?. > C_(\"preferences, button\", \"default\")\nMaybe just button?\nC_(\"button\", \"default\")\nWe really want to find the simplest context and mre generic one. I don't thins a \"preference button\" would be handled differently than a \"button\" anywhere in the interface.. likewise. \"file format\". \"pdf pages\" -> \"count\" ? we are counting something?. \"pdf placeholder\" -> is that a name? a title? maybe just \"name\" or \"title\"?. \"button\" ?. \"title\" ?. \"direction\" ? \"orientation\"?. Why? Would that work for you? Maybe the context is not even needed here? Do you need it?. Other languages, which one? Do you need it? I really want to have a minimal change at this stage. The minimum for you to get a clean translation and as I said with the more generic context as possible otherwise we'll just end up with lot of more translated string to do and this in all languages.. Maybe I can't tell for your language, but I'm concerned. Will we have:\n(\"select by\", \"hue\")\n   (\"choose\", \"hue\")\n   _(\"button\", \"hue\")\n   ...\nHere it seems to me that \"hue\" is used in the context/theme of color. The context in C_(\"\")  macro is really the context/theme of the term used not an action \"select by\". Again I don't know much about languages structure, but I want the translation to stay at a minimum level for maintenance.. just \"direction\" maybe or \"orientation\"?. Not needed g_free(NULL) does nothing.. likewise. ",
    "houz": "Oh, that's wrong. No idea who reviewed that, but IOPs should keep their stuff under their plugins/darkroom// namespace.\n. Stupid github, eating parts of comments.\nit's plugins/darkroom/<name>/\n. Wasn't there a way to have the emacs stuff in a separate file?\n. merged, the commit message alone was worth it ^^\n. Am Freitag, 15. Februar 2013, 12:10:11 schrub Pascal Obry:\n\nI'd like to have this in 1.2, can someone help me finding the best way to\nattach a dnd action on the filmstrip from the map view?\n\nThat is quite simple:\nin lib/tools/filmstrip.c you have to gtk_drag_dest_set() the filmstrip (it's \nalready a drag source), and add corresponding handlers (look at views/map.c \nhow that should look like). Then look at gui/drag_and_drop.h to check what \ndrag types you want to support.\nIf you need to know more just come to IRC and ping me.\nTobias\n. Instead of adding undo functionality to map mode we should think about a global undo buffer where different modes/modules can add entries. In general it could probably follow your approach, just a little generalized.\n. Am Donnerstag, 7. Februar 2013, 18:55:00 schrub Pascal Obry:\n\nMore generic I understand. But \"global undo\" I'm not sure. We don't want to\nbe able to undo a move on the map when we are back into the develop or\nlighttable module. It seems to me that the undo should be per module, no?\n\nProbably per view. If every undo entry had the module that created it it would \nbe easy to pass the undo data to a callback of that module.\n. Am Dienstag, 5. M\u00e4rz 2013, 15:58:51 schrub Pascal Obry:\n\nI'd like to merge this into master, ok for 1.2?\n\nGo ahead!\n. This is the wrong way to fix it. Our toggle buttons lack visual feedback in general, so we should fix them instead of adding some local workaround.\n. Shouldn't we just port that thing to use pkg-config? That would give us the version in ${Gphoto_PKGCONF_VERSION}. However, I don't know if pkg-config is portable to OSX, ...\n. This removes code, so it's approved in general. However, we are in feature freeze right now, so this will be reviewed and tested after the 1.4 release. It can probably go into 1.4.1 then. I hope.\n. I don't like that for several reasons:\n1. ctrl-s is used to save in most applications, so we shouldn't use it for something completely different.\n2. there has been work to do similar things in a more complete way, we should see if that has made some progress.\nSo, please don't merge.\n. Am Freitag, 28. Juni 2013, 08:32:22 schrieb Pascal Obry:\n[...]\n\nFor the global feature, this one is simple (~ 30 lines of code). If someone\n(and possibly myself) needs a more powerful way to handle that we'll can\nwork around this initial work. Right?\nI think moving step by step is better than nothing. I'm ready to do my load\nof work (and I think I have demonstrated that), but please let's discuss a\nbit more.\n\nI disagree. We have seen in the past that simple hacks that solve big parts of \na problem make people not care enough about the real problem to fix it.\nBtw, for these discussions we have IRC. Github is a version control system, \nnot a new communication channel. Posting PRs and thinking that anyone agrees \njust because there was no voice against it is not how this works. Most people \ndon't even see these PRs.\n\nThanks.\n\nTobias\n. I don't like that you use the new function everywhere. I would agree that on import it makes sense, but when resetting collect or on similar occasions we should keep the old logic.\n. Just translate darktable in en_GB.po (or whatever the appropriate file name would be) and set your environment variables accordingly. For darktable, which is (supposed to be) using Internet^WUS English, this is just some other translation to another language. No idea why this was reverted and stuff ...\n. Since we are in feature freeze right now this will have to wait to be reviewed and eventually merged.\nBesides, we are not entirely sure if this is the way we want to handle things. But let's discuss that once 1.4 is released.\n. Spoiler: rebasing isn't enough, you have to rewrite the code that changes the DB since it now resides in common/database.c and requires a bump in the db version and a clean upgrade path.\n. Since this is a bugfix and not a new feature it should be reviewed for 1.4.\n. What you want is \"cd po/; intltool-update -m\".\n. Please, don't go through the config to pass options to the export process. This will not be merged as it currently is.\n. Since we are in feature freeze right now this will have to wait to be reviewed and eventually merged.\n. There are some unrelated changes to other files. Could you maybe clean that up?\n. Since we are in feature freeze right now this will have to wait to be reviewed and eventually merged.\n. Sorry, clicked the wrong button.\n. We aren't in string freeze anyway :)\n. We are in feature freeze right now. This can be looked at after the upcoming release.\n. I just looked at the patch and I have to admit that I don't like how you do things. If you want this to be merged you should make sure to construct a SQL query that does the selection instead of doing the filtering yourself as a first step. Once that is done we can see what else needs fixing.\n. Have a look at the geo_query you removed. Also look at the code removed in 29acfe6c26f43f04eeba09599248e2d2253d1195 where the collection query is used inside the geo_query.\n. Actually it might be even simpler nowadays: you could try to just use the table collected_images. If you want to get some help or ask for details you should bump me in IRC (#darktable on FreeNode).\n. This looks better indeed, just two remarks:\n- Instead of explicitly calling a proxy function in preferences.c I would prefer to introduce a new signal that gets raised whenever the preferences were changed, and that other code can connect to. that way you could connect it when entering maps mode and disconnecting when leaving and also get the current settings on entering.\n- You are nesting three levels of queries in your geo_query. I am sure that a little SQL magic can bring that down. Especially since the query optimizer of sqlite isn't exactly the best.\n. How can buffer be NULL and buffer_size > 0?\n. Could you please split this up into two PRs? It's not only that we are in string freeze, but more importantly we are also in feature freeze. The tonecurve one I would like to merge though (and give you the credit of fixing it).\n. I wouldn't like to see this in dt. There is no reason to add these options, it just makes our code harder to read and maintain. I would rather remove some of the other cmake options.\n. Agreed, it shouldn't be required, however it isn't already. All these dependencies should be detected at compile time and if they are missing the features should just be disabled. I really don't see a use case where someone has the dependencies installed and doesn't want to make use of them.\n. I seriously hate to clutter our code base for the sake of some obscure distribution. I wouldn't even like this for the major ones.\n. Looks good to me.\n. Merged and legacy_params added. I get some GTK warning and sporadic crashes when selecting a preset using exr, but we will sort that out outside of here.\n. Caution, RAW and HDR isn't the same thing. I haven't looked at the code to see what actually happens when that flag is set, but we probably want to distinguish that a little more.\n. Checkboxen are frowned upon in darktable. Please stick to dropdowns.\n. Now that our database has proper version updates it would be quite simple.\n. I am working on this and will merge later\n. I would agree to merge the lua part, the webp commit however was already discussed in PR 377 and i still don't like the idea.\n. I haven't tried what the resulting .desktop files would look like, but you may not change .po files in your PR. Please remove that commit and make sure that intltool-update takes care of that.\n. Copied over from the other, now closed PR:\nI haven't tried what the resulting .desktop files would look like, but you may not change .po files in your PR. Please remove that commit and make sure that intltool-update takes care of that.\n. If you prefer to have the separation verb ./. noun then that is ok, too. Just tell us if you want this one to be merged or if you want to do a different pr.\n. Probably not, but it's only 2 or 3 lines that can be easily grabbed from git log. So maybe just writing a mail to the list would be enough.\n. If you look at that CMakeLists.txt you will notice that not every compile is done with -march=native. And I don't care what others do. Builds that are stripped and/or don't have debug symbols don't get support when bugs happen. I have seen too many useless backtraces already so I am ignoring people that think they know it better or use distributions that are clever.\n. I am a little confused here \u2013 we already set -Werror since forever, and libraw compiles, since that is C++ code, not C.\n. No, we don't. We couldn't do anything about it anyway since we have no interest in forking these projects or putting lots of work into reporting stuff upstream. We just ship them because distributions don't have them or in old versions only.\n. This is a quite special use case that I would prefer to see being added as a Lua script.\nThat being said, please don't mess with .po files. Translators usually have local edits to them and they are hard to merge from git.\n. Elsewhere we use gboolean, maybe stick to that.\n. Since you don't seem to be willing to maintain your IOP in the future I don't think that this should be merged. Just throwing some half finished code in our general direction and expecting us to incorporate it is not how things work in darktable.\n. You guys are rejecting contributions because of indentation? Seriously? In the time it took to write your comment here you could have merged and fixed yourself. o_0\n. About the typographical side, at least I prefer an ndash with spaces, the first being a protected one (&nbsp;&ndash;). If Docbook doesn't like those (it should be possible to make it usable somehow using entities) you can still just enter the UTF8 character \u2013.\n. AFAIK the emdash is in wider use in the US while the endash is preferred in England as well as the German and French speaking world. When the emdash is used it should however be used without (regular) spaces around, a thin space might be used. The endash however is used with spaces. At least that's what they are normally used. Of course there are no rules without exceptions, so while I personally prefer the spaced endash for aesthetical reasons I could live with an unspaced emdash, too. :) \n. Supporting libsecret (which we should) is independent from fixing compiles for newer libgnomekeyring versions (which we should, too). I wonder if older versions which didn't deprecate the symbols also support the new required g_hash_table way, or if we have to #ifdef it.\n. I disabled the use of GnomeKeyring >= 3.12.0 and will review this in depth (and try to test it) in the next days.\n. I didn't read your changes, but since you seem to misunderstand quite a lot about how histories and sidecars work (at least that's what I learned from your corresponding bug report) I would like to ask anyone reviewing this to make sure it is correct.\n. This should indeed be changed.\n. Could you bring back the icons please? Or did you leave them out on purpose?\n. That's the beauty of using GTK: it uses the defaults of your desktop environment. IIRC it can even reorder the buttons (ok, cancel, ...) in dialogs.\nSeeing the screenshots side by side I am not even sure that the icon is needed or even pretty any more. Maybe we should just leave it as it is now.\n. I am also against such a button. There is no need to carry some strange GUI element forever to just fix a short lived bug from a development version. People have been warned that using git master can break their stuff and eat kittens, so they should just deal with it.\n. Since that is a bug that is actively used by many people (there were even discussions about it on the mailing lists) we should not fix it. Pressing&releasing 'z' should bring you back to the normal view.\n. build.sh is already a messy pile of bloat, no need to add more on top. If someone wants to use something else than make they just have to call cmake manually.\n. What has the group id to do with local copies?\n. group_id is used for, well, grouping images. You can't derive the original of a local copy from that.\n. There is no \"master\" for a duplicate. They are completely independent.\n. There seems to be some confusing wrt. names.\n- A \"group\" is a bunch of images grouped together on lighttable, they share the same group_id (which is the image_id of the group's master). You can group together whatever you want, spanning file types, film rolls, ...\n- A \"duplicate\" is an image that only exists as db entry and XMP file, it uses the same image file as the image it got duplicated from. However, there is no master, all instances of one image file are treated equally, just one of them happens to have the \"image version\" 0. By default duplicates get grouped together, but that is something the user can undo.\n- A \"local copy\" is a cache of an image file together with the XMP in the user's cache directoy.\n. About your latest changes, you are changing the filename of the cached copy. Doesn't that mean that people potentially have a bunch of copied over raw files that dt no longer sees, won't delete (wasting disk space) and also can't access when the user tries to open the file? And wouldn't that also break the db as the local_copy flag in the images table no longer represents the truth?\n. The location of those entries were in the import window once, but then someone thought it was a good idea to rip them out and put them into the preferences. I would have left them were they were \u2026\n. For what it's worth, there won't be any NULL folders any more.\n. Has this been approved by the people responsible for these translations?\n. Good enough? Last time I checked it would be dropped because it lacked too many translations.\n. This has been added manually since our file format changed in the mean time. Sorry for the delay.\n. Hi, could you fix the issues addressed and rebase on current master? We are freezing for 2.2 soonish and I would really like to have this finally merged.\n. I did some cleanup myself and merged it. Finally. After almost 2 years. I feel sorry for taking so long. Thank you again for your work.\n. Could you merge in master so that I can see what I actually have to port to GTK3?\n. Standard keyboard shortcuts to change the brush size in other applications like GIMP and mypaint are [ and ].\n. I wouldn't know how to do that without a Facebook account and access to the app settings.\n. No longer needed, we have an HTTP server now.\n. Great, I think we are in a state where you can bring this to a mergeable state so we can bring this to wider testing.\n. I have no idea what you did to the git history, but to me it looks really strange. I can hardly do any bisecting on the resulting tree and your commit dates look off, too. How did you merge the branch into master?\n. Please remove the .mo file, that gets generated when compiling darktable.\n. Since this will allow exporting upscaled images it's not ready for merge until we came to a conclusion if we want to allow that. We should keep this open and once we decided if we want to allow normal upscaled exports I will merge this PR and fix according to the intended mode of operation.\n. For the time being I am adding a new option to allow upscaling to the export lib. Provided hanatos agrees I will push that. You don't have to do anything.\n. Merged manually.\n. I tried to remove gettext from cmake alltogether, please see if that is allowing you to compile darktable. These tests should have been unused anyway.\n. I reverted 8d26343af849f3d2ab2e6e032fcf8161c496f76e even though I don't understand the problem, either Glib's i18n stuff pulls in what is needed, or it shouldn't compile.\nNext time please say that a patch is for fixing BSD so people knowing about obscure platforms can have a look instead of me.\n. We don't use gegl.\n. Indeed, I added it to the stable branch but somehow forgot master. Fixed.\n. Just for the record, gamma.c doesn't do gamma correction. The file name is just a historical curiosity that's not worth fixing (leaving old libgamma.so in people's installations, requiring a bump of the iop version, ...).\n. Just to chime in, adding aspect ratios to the config is mostly there as a backend, a nice GUI to manage those can still be added.\n. I didn't have time to look at the style details yet but I would guess that it should purge whatever is in the history stack above history_end first. Similar to what copy&pasting does. I will try really hard to find some time this weekend.\n. There were some more bugs in the affected code (and probably a missing +1 in your patch) so I cleaned that up in one go.\n. That is wrong, it has to be max+1.\n. I see several problems with that patch.\n- You are just looking for operation, that will most likely fail when multi instances are used.\n- You are using the result from sqlite in g_strclpy without checking if sqlite3_step worked.\nInstead I would do the delete query, then count how many entries are left with num < history_end and use that as the new history_end after removing the holes in num.\n. Why do you need the operation at all? You are deleting everything above history_end, so the biggest num + 1 is what you need. Do I miss anything?\n. ACK, 1 pixel is a bug.\n. I don't like these global LICENSE files. You have to keep them in sync, they don't say that it's not GPL3 but GPL3+, and some files in git are not GPL at all.\n. As a general comment, I didn't add altitude data to dt on purpose as that data has some computational problems. Just using the GPS value can be wrong by MANY meters if the software that wrote them doesn't account for some problems with the underlying geoid and compensates for it. The math is ugly and requires a dataset to account for.\n. I am currently in the process of merging this manually. I played around a bit with making the color conversions static inline in the .h file but couldn't measure any significant speedup. Do you have some benchmark that's showing something different?. This was merged manually.. Let's just merge, see what breaks and then think about reverting if we have to.\n. Thanks for an overview of what you changed, but I have better fixes for most of them locally already and will eventually merge mine. I'm keeping this open to remind me to not forget them.\n. Before merging this we have to get the OK from Richard as he \"owns\" the Swedish translation. The reason being that it sucks when you have big changes to a .po file that are not committed and someone else changes the file. It's extremely hard to merge those back together.\n. I don't know about Richard, but I (responsible for de.po) so have local changes all the time. I am not aware of any easy way to work on translations with several people with a consistent result, but in darktable every language team is free to organize as they want.\n. Is there a platform that requires these changes or is it just \"because\"? And even if there is, this most likely breaks the whole purpose of the code as it doesn't prevent using the database twice.\n. So, since this is not really needed for any supported platform and using fopen here is just wrong I am closing. I don't think that this could be made to work.\n. Besides the =0 it's fine and should be merged.\n. Besides the confusing comment it looks ok to me.\n. Sorry, I already added it to LINGUAS before seeing your PR.\n. 16x is basically dead and will most likely not see any more releases. So feel free to fix bugs there, but it's basically a waste of time I suppose.\n. 1. parsing_tk should be called parsing_trk.\n2. doesn't your code leak memory when there are trkpt outside of a trk?\n3. formatting is off, please remove spaces between if and (.\n4. you should also init parsing_trk to FALSE.\n. Same.\n. Did you communicate with Du\u0161an Kazik prescott66@gmail.com before changing the Slovak translation?\n. So for you the scrollbar doesn't block part of the gui? like the '+' buttons of spinboxen in prefs? Or the last filmroll when you have one with a long name so that an horizontal scrollbar gets added? Or the last mask when you have one with a long name and enough to fill the mask manager box? For me the overlay scrollbars are a nightmare to use and I would like to see a screenshot that it's better on other systems before even considering such an option. Even if it looks nicer.\n. Well, if you like it that much ... :)\n. Krijn has sent me a mail, some phrases are better others not, up to now commits are set 'on hold' \nGer Siemerink g.siemerink@gmail.com should review this please.\n. I also said that I don't like the info pushed to the border and the asymmetric look of it. I think it's ugly.\n. Yes, I still don't like it.\n. At least make the strings translatable. In the German translations I am always using correct typography, so I will definitely use the second sign here.\n. The whole strings containing the \\\" which you snprintf().\n. As I said, the German translation always used correct typography, so i would use the second sign and not the \". I also change all quotes.\n. We used to not have empty space in the top row, that was added on purpose when zooming was made to keep the image under the mouse unchanged. I strongly dislike it.\nAbout the zoomable light table, I never use it (which is why it lacks some grouping features), but others love it and don't use the file manager mode. I guess we have to keep it.\n. Currently we rely on cmake 2.6 which doesn't have GNUInstallDirs yet. I would like to push that dependency so we can merge this and do other things. I don't know if we will do this before the 2.0 release or rather try to stick with what we know is working for now.\n. I don't know who ships what, but I don't want to find out right now, We just released rc3 and the next thing might already be the final release. Having that broken on some distribution would suck.\n. We should keep enough special casing to make typical compilation easy without the need to specify any variables when calling cmake (besides CMAKE_INSTALL_PREFIX).\n. > that they do not respect ownership and rebrand your changes without even\n\nasking for permission.\n\nWhat do you mean?\n. Why did you make the rpath absolute? I expect that to break distribution packages.\n. Hint: Just leave the rpath as it was.\n. I don't think that setting this to any fixed size is the right thing to do. I'll investigate and report back.\n. So, what I would suggest: As we put the entry into a grid which is expanding to use all the space it gets we should maybe just set the width to 0 chars. That way it will always be as small as possible while still stretching.\n. Not only is the code you wrote wrong, I also think it's not needed and probably even harder to understand than what we currently have.\n. Oh, please don't use default_params in legacy_params(), i will remove those from other modules in the future anyway to eventually get rid of the self parameter to that function completely. It  doesn't work well with manipulating params from outside the pipe via introspection (creating a module instance just to update params is ugly).\n. What about a checkbox \"remember the choice\" or \"don't ask again\" (or something like that) which just remembers whatever you click for that job. It would allow deleting them all, but also to just remove all of them from the collection. Or whatever someone wants.\n. 1. Does that work on OSX where we don't use GLIBC (IIRC)?\n2. Wouldn't it be better to add dt_pthread_create() instead of initing attr and use that? I am certain that once we add pthread_create in other places in the future we will not remember to use non-standard atttr.\n. Is there any idea behind the icon? I know that it's hard to come up with something for these generic iops.\nShould we merge this (I am not totally opposed, I'd just like to know if there is any meaning to it) we also need the PNG version.\n. What do you mean, it's setting a black/white dot?\n. I guess there is some language thing involved, the \"point\" part of white/black point has nothing to do with a dot. So if it's a pun I'm all for it, but as a literal meaning it's not working i guess. Anyway, feel free to merge, it won't hurt and if we think that the icon should be changed later we can still do that. We might even hide the iop from the general gui some day.\n. Hi Pascal, I will have time tomorrow to review it.\n. I don't think users should even be allowed to decide that. Besides undocumented flags we can use for testing and developing (environment variable or config option).\n. Looks good, but please change \"unknown\" to \"none\" so it's the same as the others.\n. Looks good, I will test it tomorrow. About the rest of the files, don't change it for things like the G in paint.c, there the easy cairo function is fine.\n. If you insist.\n. Some problems:\n- One of the lines on lighttable is starting at the wrong position now.\n- The labels on left/right in equalizer are too far down and not aligned (they used to be right aligned).\n- The numbers in tonecurve are too far down now.\n. Thanks. Next time just push new commits please and never merge several into one.\n. Roman is currently working on adding more process_*() variants and we thought about some automated benchmarking and picking the fastest code path on an IOP level. Maybe that can be used for OpenCL, too?\n. I just noticed some small problems with the way you handle pango. As they are also present in the last PR I will just clean it up and merge this afterwards.\n. I don't have a camera handy to test, but from looking at the code I don't see how this would help with tethering. dt_camctl_import seems to be only used for importing pictures (i.e., copying over to the hdd) in the import lib.\n. Maybe you could instead change the set_white and get_white hooks to set_exposure and get_exposure so you keep the calculations in exposure.c.\n. Could you please show a screenshot how it's supposed to look? For me it's widgets all over the place, strings that don't make sense (p.e. \"inferior\") and the 2nd entry \"value\" is confusing and lacks an obvious reason to be there.\n. And how does the other entry box fit into that scheme? To me that looks terrible. And the context menu \u2026\n. I don't question that selecting ranges is a good thing. But the UI you came up with just doesn't work. And I don't think it could be fixed by moving things around a bit.\n. No, using caption is not ok. While it's one of the old, now unused, fields I wouldn't assume that nothing is in there. If it's something the user can enter then maybe just use Xmp.dc.title?\n. Looks good to me.\n. > Since that's unsigned you need to change those back to int or maybe int32_t\nOr use ssize_t.\n. Thanks for noticing, I mailed the translator. Merging .po files is always a problem when there are local changes on the translator's side.\n. The change was added manually.\n. What is the state of this PR?\n. Yeah, sorry, copy&paste error.\n. What is the state of this PR?\n. This is no longer needed, is it?\n. Merged manually\n. No, it would have to go into dt proper as it's a means to tie the Lua repo into dt.\nI didn't look at the code or try it, it's just a general remark.\n. Just as a random remark: I kind of like how Blender handles scripts. It doesn't fetch them from the web for you, but it recognizes those you put into the directory it scans and offers them to be enabled/disabled in the settings. With a search box.\n. Yeah, getting rid of all the crazy things cameras add to the files sounds like a good idea and it actually what we are trying already. Thanks for adding those.\n. I don't know how often rawspeed allocs memory, but since I don't assume that the OS version changes while running it might be a good idea to cache that result. Just saying.\n. Only if the rest worked out. If no version could be gotten (for example because the syscall failed) then it will retry over and over again.\n. This is such a big improvement with the touch friendliness. And it fixes a locking issue, so it's a bugfix, right?\n. I didn't look at the changes in this PR (yet) but I would like to state some general things, all of which are my personal view, not representative of the darktable team and I might change my mind anytime I feel like it. So here we go:\n- In general I am for a Windows port. There, I said it. That's also why I worked on that in the past.\n- I do understand that there are people with fundamental problems of porting Free software to a non-free system like Windows is. I however am not a dogmatic person (even if i claim to be every now and then).\n- Over the past few weeks I had mails exchanged with another person working on a Windows port, Jan Ingwer Baer. We tackled some of the problems like the fseek() (hint: it's the r mode instead of rb when opening the file which results in problems on Windows due to line endings and makes seeking impossible there, so reading until the newline is found is the right fix. Opening in binary mode isn't as it would break once someone edits the file in an editor with Windows line endings).\n- I see that both of them (Jan Ingwer and peterbud) spent quite some time and effort on their changes which sets them apart from earlier \"#ifdef everything out that doesn't compile for me\" approaches.\nSo as my personal conclusion barring a look at the actual changes is that a joint effort of the two would make me more or less happy with the prerequisites for approving a Windows port. Even if it's just something handed to a few people we know at the beginning as a closed test phase to see what bugs surface and how our then-windows-maintainers handle them.\n. Could you please sync the PR with master? I picked a few smaller changes already, and there is the issue of the rawspeed changes that now have to go into their own repository.. More changes picked in ef45705b5ab6f47eb317a473b33dfe38f2f03b09.. With the current setup the components selectable in the installer are named \"DTApplication\" and suchlike. That should be nicer strings.. I can confirm that building an installer package now works. However, when starting it and trying to import a folder dt immediately crashes when opening the file selector. Shouldn't there be some crash handler coming up? It seems there is something printed on the terminal window being opened with dt but it closes too quickly to see anything.\nGot it now. The error message is:\n(darktable.exe:2700): GLib-GIO-\u2190[1;31mERROR\u2190[0m **: No GSettings schemas are installed on the system\n\n. That error message was not in a backtrace but in the cmd window shown when launching darktable. As I wrote, I expected to see some sort of crash handler, I was not aware that any backtrace gets written. Where is that put?. Yep, works now.. I had a look into not hard coding the DLLs to be bundled. I currently don't have the time to finish that task but if anyone wants to give it a try, these two look useful: https://cmake.org/cmake/help/latest/module/BundleUtilities.html and https://cmake.org/cmake/help/latest/module/GetPrerequisites.html. Please update your branch again, I picked most things now. I will add comments for the few that are still missing once you updated \u2013 the GitHub page is quite messy otherwise.. A quick remark: I wanted to try the installer created from this and ran into a problem: I built in a VM running Win7, built a package without CPU specific optimizations and installed that on a Win8/10 (no idea, something modern which no longer looks like Windows). When starting the program it just sits there, consumes some CPU cycles and doesn't even create a GUI. Some config files are written though. Is there a way to debug that on Windows? Even if I managed to get a copy of gdb onto that computer I wouldn't know how to interrupt the process as ctrl-c doesn't work on Windows for that. And I don't get any debug prints on the cmd shell.. If you tried that you would know that cmd doesn't show what gets printed to stdout. \ud83d\ude44. > Try this version - https://olgabatalina.ru/dt/darktable-2.3.0-win64-generic.exe (All processors)\nOr this (Xeon and top Core i7 CPU models) - https://olgabatalina.ru/dt/darktable-2.3.0-win64.exe\nThe best way to get debug output is run darktable like this:\ndarktable -d all > debug.log\nThanks for the offer, but I am not really interested in using darktable on Windows but getting this PR merged. And in order to do that I need to find the problems and help figuring out where they come from and how to fix them.. @peterbud that's good news. Having some special cases hard coded in the cmake files to be installed is fine. I am mostly worried about constantly chasing after specific DLL names, scripts breaking with every update of msys, \u2026\nAs a test I commented out the -mwindows -Wl,-subsystem,windows lines to get the terminal window. That way I am able to see debug output. I will try to get my hands on the Windows laptop next weekend and see if I can find out where it hangs.\nPS: I guess for now we should comment out these two lines in git, too, to make initial debugging feasible. Would that be ok for you? Final releases can have it reintroduced.. They are not dt plugins, but still needed at runtime by things we link against. Maybe we can use some wildcards and glob from cmake to get the files we want? That would at least make our scripts somewhat robust against system updates.. I just tried your latest changes, however, when trying to build the installer package it fails with an error about the filename of one file being too long. The interesting bit being that it's something not needed at all. a regular make install doesn't try to add dumpbin.exe btw.\n```\n[...]\nRun CPack packaging tool...\nCPack: Create package using NSIS\nCPack: Install projects\nCPack: - Run preinstall target for: darktable\nCPack: - Install project: darktable\nCPack: -   Install component: DTApplication\nCMake Error at C:/msys64/mingw64/share/cmake-3.7/Modules/GetPrerequisites.cmake:816 (message):\n  C:/Program Files (x86)/Microsoft Visual Studio 12.0/VC/bin/dumpbin.exe\n  failed: Der Dateiname oder die Erweiterung ist zu lang\nCall Stack (most recent call first):\n  C:/msys64/mingw64/share/cmake-3.7/Modules/GetPrerequisites.cmake:943 (get_prerequisites)\n  C:/msys64/mingw64/share/cmake-3.7/Modules/GetPrerequisites.cmake:943 (get_prerequisites)\n  C:/msys64/mingw64/share/cmake-3.7/Modules/GetPrerequisites.cmake:943 (get_prerequisites)\n  C:/msys64/mingw64/share/cmake-3.7/Modules/BundleUtilities.cmake:575 (get_prerequisites)\n  C:/msys64/mingw64/share/cmake-3.7/Modules/BundleUtilities.cmake:848 (get_bundle_keys)\n  C:/Users/houz/Desktop/darktable-win/build/packaging/cmake_install.cmake:36 (fixup_bundle)\n  C:/Users/houz/Desktop/darktable-win/build/cmake_install.cmake:36 (include)\nCPack Error: Error when generating package: darktable\nmake: *** [Makefile:84: package] Error 1\n``. I'll have access to the Windows 8/10 laptop this weekend for further tests. If that doesn't show major issues I will merge then.. After some more tests I think this is good to go. I have some local fixes ontop of this, and some more issues to tackle afterwards, but keeping these few changes left over in a PR won't help anyone.. Such an elaborated description of a feature belongs in the usermanual and not the release notes. Please feel free to add things to the file though.\n. I agree that we should have a nice overview of new features with explanations. I liked the one Inkscape had a while ago with animated GIFs showcasing things. But those don't belong in a changelog going with the release.\n. The changelog also gets added to packages, for example in/usr/share/doc/darktable/changelog.gzon Debian. That file is intended to be a short and concise list. The fact that we use the same list on the website is because no one cared enough to write more so far. If you want to do that: great! But that's for the final release's announcement post.\n. Thanks. Currently we lack EDID parsing as I don't expect to see anything relevant in there.\n. We still need to maintain the old mess for legacy history stacks. Or deprecate c&r and write a new crop tool. However, from a user's point of view I wouldn't like to need to switch modules for cropping and rotating. So this isn't straight forward at all.. I didn't try it yet, but the code looks ok to me.. Look in black and white parts of the image. The grain should get less there.. Thank you, I like the result much more than the old grain.. I see some problems with the use of timestamps as done here \u2013 unless I am misunderstanding the code, I only looked over it once.\nYou are discarding undo entries if they have the same tag as the last one in the list. What if the undo step was important? Think about adding undo for image rating. The user rates an image A to 2 stars, then within the same time slot (thus with the same tag) he rates another image B as 3 stars. The undo list would discard the latter. So when pressing ctrl-z only image A would be reset. Of course the rating-undo could always use tag 0, but still, it feels like a race condition.\nInstead of these tags I would suggest something like this: Add a timestamp field todt_undo_item_tso that every entry has that. Set it todt_get_wtime()` when recording the undo step. Record every step. Then when undoing something take the latest undo item, remember its timestamp and type and undo everything from the top of the list until you reach something with a different type or that is more than SOME_TIME_PERIOD older than the first entry. That way you can guarantee that everything gets reverted, you no longer need to worry about creating meaningful tags in the users of the undo api.\nAt least that's my suggestion after looking at the PR. \ud83d\ude04. Thanks for starting to work on this! It has been bugging me forever, just not enough to start doing anything about it. \ud83d\ude04\nSince there are hardcoded colors used in the expose functions (i.e., drawing the gui) that are called quite often I would prepare the infrastructure to load the known colors at startup into a GHashTable in dt_gui_gtk.h and just look them up at runtime.. Sure, an array of colors, together with an enum that maps human readable names to array indices would work, too.. This looks good. Just one thing: there is that repetition of code like\nGdkRGBA bc = darktable.gui->colors[DT_GUI_COLOR_DARKROOM_BG];\ncairo_set_source_rgb(cr, bc.red, bc.green, bc.blue);\n\nwhich should probably be put into an inlineable function like dt_gui_gtk_set_source_rgb(cairo_t *cr, dt_gui_color_t color) (and please come up with a shorter name for it \ud83d\ude03).. The _rgb is important. Maybe drop the _gtk and make it dt_gui_set_source_rgb(). Otoh, I like that the function names make it (in general) clear in which file the code is. Which brings us back to dt_gui_gtk_set_source_rgb(). It seems we need some input from others. @LebedevRI, @hanatos?. No, the rgb part isn't to differentiate from rgba but to make it clear that we are not wrapping cairo_set_source (https://www.cairographics.org/manual/cairo-cairo-t.html#cairo-set-source).. Thanks a lot. About the naming of the function, if we want to hide the fact that it's loading an RGB value via cairo we should probably also hide the _source_ part. But for now it works and we can think about naming it differently another day. There are more places where names are suboptimal. \ud83d\ude03. Even if the compiler doesn't optimize the gboolean away (I would be surprised if it didn't) it shouldn't matter. We allocate gigabytes of memory, 4 bytes on the stack should be fine. Especially in code that isn't used recursively.. What is the state of this PR? The changes I can see look suspiciously minimal .... I'd prefer right click to delete a node so it works the same as masks and zone system.. The he.po hasn't any (relevant) changes in it.. Instead of hardcoding guides for such a special case I'd use a Lua script looking something like this:\n```lua\ndt = require \"darktable\"\ndt.guides.register_guide(\"ePass\",\n-- draw\nfunction(cr, x, y, w, h, zoom_scale)\n  local _w, _h\n-- get the max 35x45 rectangle\n  local aspect_ratio = 45 / 35\n  if w * aspect_ratio > h then\n    _w = h / aspect_ratio\n    _h = h\n  else\n    _w = w\n    _h = w * aspect_ratio\n  end\ncr:save()\ncr:translate(x + (w - _w) / 2, y + (h - _h) / 2)\n  cr:scale(_w / 35, _h / 45)\n-- the outer rectangle\n  cr:rectangle( 0, 0, 35, 45)\n-- eyes\n  cr:draw_line(0, 13, 35, 13)\n  cr:draw_line(0, 23, 35, 23)\n-- nose\n  cr:draw_line(15.5, 13, 15.5, 45)\n  cr:draw_line(19.5, 13, 19.5, 45)\n-- TODO: chin line\ncr:restore()\nend,\n-- gui\nfunction()\n  return dt.new_widget(\"label\"){label = \"this is based on the German passport specs\", halign = \"start\"}\nend\n)\n-- kate: tab-indents: off; indent-width 2; replace-tabs on; remove-trailing-space on; hl Lua;\n``. I'd prefer that file to be inpackaging/nixos/so it follows the other linux distros.. Sorry, I had some free time and you were not around, so I quickly fixed it. \ud83d\ude04. Merged manually.. No idea what this is about. No explanations whatsoever, just a link to some random website. @LebedevRI deal with this as you like.. Thank you. That patch turned out smaller than what I anticipated. :-). I didn't add such a check originally as I am not convinced that we can rely on this working. However, in almost all cases it's probably fine, so why the heck not.\nOne general remark: Please fix your formatting, add no space afterifand put{` in their own line.. I found some time to look at the FFTW3 docs. To me it seems that reusing a plan is ONLY allowed with the \"guru\" interface and ONLY when array sizes, stride, ... don't change. That is obviously not the case for us so I am wondering if the lack of crashes and bad results is just luck so far. But maybe it just results in non-ideal runtimes. No idea. [0]\nAlso, the docs clearly say that the in and out arrays used for plan creation must be allocated, so NULL is not a valid argument. [1]\n[0] http://www.fftw.org/fftw3_doc/New_002darray-Execute-Functions.html\n[1] http://www.fftw.org/fftw3_doc/Complex-DFTs.html#Complex-DFTs. >  I apply them to tiles, and due to this, array sizes, stride, ... don't change. The conditions of [0] are met.\nBorder tiles or small images can differ in size. The latter might not be a big problem for demosaic of course.. After discussing this a little more with @LebedevRI  and @hanatos we came to the conclusion that dropping FFTW3 is the best approach here. That way we can avoid a lot of potential bugs.. > On  success, the number of bytes written is returned (zero indicates nothing was written).  It is not an error\n       if this number is smaller than the number of bytes requested; this may happen for  example  because  the  disk\n       device was filled.\nThis sounds as if 0 could be returned.. Fair enough, no 0 then. \ud83d\ude04. This looks sane. We just have to decide if it would make sense to delete files that were only partially copied.. Just a small remark: that script is not bash but sh! I didn't try your changes and don't know if they are portable.. The portable part of this had been added in a2231149c467ce9ed19e305de2b236cc9d89b08e already so there is nothing left here it seems. Thank you anyway.. I guess the problem is that none of us use the zoomable lighttable so we tend to forget about the problems it has. And at the moment we are in feature freeze. However, this looks like a bugfix to me, so I wouldn't be opposed to merging.. b78d8c27c988cc565784833874b475eaa778b345 adds this, and more.. I don't think that there is a real reason to discard some patches, it's most likely just a bug.. I fixed the \"offest\". Once you got that into your translation I will merge.. Isn't this just test compiles? In how far does the state of the external lensfun db matter for that?. @LebedevRI just told me that your appveyor thing builds installers.. > A down side is that print settings now must catch a couple more signals, and it processes these even when not in print view. The latter should be fixable.\nYou can probably connect in enter() and disconnect in leave().. Just a quick comment from my side: I didn't look at the code yet, didn't try it and didn't even read all the UI discussion in here, but if the results are nice, the computation is quick and the UI can be made really simple I am all for getting this into the existing spot removal tool. I understand that it will take some time before we are getting there. So for the time being it might make sense to break some of the small improvements (allowing to pan&zoom while editing masks for example) out into a separate PR as it sounds useful independent from this work.. While developing I guess it's ok to break backwards compatibility, so just keep the version at 1. Once something is merged that may no longer happen of course.. Superseded by commit 8e401e7f098d9e4cbd7852e95cf2a224326a411e.. Please update the rawspeed submodule in your fork. Hopefully it will get rid of the merge problems.. We are currently in feature freeze. I will have a look at this once we got the release out.. Do we need to document that in the api docs?. Ich hab mal angefangen Korrektur zu lesen. Hier meine Anmerkungen f\u00fcr die ersten paar Seiten:\n- _D_arktable -> Grunds\u00e4tzlich wird darktable IMMER \"darktable\" geschrieben.\n- \"mit Entwickelt\" -> klein und zusammen (?)\n- \"modifizieren werden\" -> \"modifiziert werden\"\n- Voreinstellungen:\n    - \"Benutzerhandbuch Version\" -> zusammenschreiben oder durchkoppeln\n    - \"Darktable Version\" -> durchkoppeln\n- \"RAW\" -> das ist keine Abk\u00fcrzung sondern ein normales englisches Wort. Entweder als \"Raw\" eindeutschen oder \"Rohdatenformat\". Ich w\u00fcrde \"Raw\" nehmen.\n- \"zoombarern\"\n- \"Flie\u00dfkomma-Pixel Puffer\" -> durchkoppeln\n- \"Tats\u00e4chlich ben\u00f6tigt darktable\" -> Ich w\u00fcrde das \"Tats\u00e4chlich\" weg lassen. Klingt im Deutschen doof.\n- \"dem menschlichen Auge\" -> \"des menschlichen Auges\"\n- \"Vollfarbdisplay\" -> es geht um Farbmanagement\n- \"linear RGB\" -> \"lineares RGB\"\n- \"Collect-Modul\" -> \"Sammlungs-Modul\"?\n- \"Farbbeschriftung\" -> \"Farbmarkierung\"\n- \"innerhalb der Basisabfrage\" -> klingt seltsam, kann man das umformulieren?\n- \",...\" -> da kommt ein Leerzeichen hinters Komma: \", ...\"\n- \"Plattenspeicher\" -> Das klingt wie eine Technologie aus den 70ern. Eventuell \"Speicherung auf der Festplatte\"?\n- \"html-basierte\" -> \"HTML-basierte\"\n- \"Dynamikbereich\" -> \"Dynamikumfang\"\n- \"XMP-Sidecar-Dateien\" -> \"XMP-Begleitdateien\"\n- \"Grundoperationen\" -> \"einfachen Anpassungen\"\n- \"als mehrere Instanzen\" -> \"in mehreren Instanzen\"\n- \"Zusammen mit der Maskenfunktion k\u00f6nnen ...\" -> \"Zusammen mit der Maskenfunktion kann eine Funktion so verschiedene Auswirkungen auf unterschiedliche Bildbereiche haben\"\n- \"Single-Click-Denoiser\" -> \"Ein-Klick-Entrauschen\"\n- \"der just works\u2122\" -> \"der einfach immer funktioniert\"\n- \"Diaschau-Funktion die ihre\" -> \"Diaschau-Funktion, die Ihre\"\n- \"Ihre Bild an einen\" -> \"Ihre Bilder an einen\"\n- \"Kommandozeilen-Schnittstellenvariante\" -> \"Kommandozeilenvariante\"\n- \"Bin\u00e4rprogramm\" -> Ich w\u00fcrde nur \"Programm\" schreiben.\n- F\u00fcr die Kommandozeilenparamter kann die \u00dcbersetzung aus den man-pages genommen werden.. * man /opt/darktable/share/man/de/man1/darktable.1 zeigt hier die deutsche Version. Du kannst aber auch doc/man/po/de.po im git-Checkout ansehen.\n* Ja, \u201edarktable\u201c wird immer klein geschrieben.. > Anbei ein paar Begriffe die ich nicht \u00fcbersetzen kann, da ich die korrekte Bedeutung nicht kenne.\nIm Zweifel sollte alles genau so \u00fcbersetzt werden, wie es in darktable selber angezeigt wird. Also einfach mal das Programm starten und dort nachsehen \u2026\n\n\nkeystone\n\n\nTrapezkorrektur\n\n\nmatch greens (Kapitel 3.4.1.8 Seite 82)\n\n\nGr\u00fcn anpassen\n\n\nLuma\n\n\nLuminanz\n\n\nShiftN\ndcraw\n\n\nDas sind Namen, nicht \u00fcbersetzen.\n\n\nprimary, was ist das f\u00fcr eine Taste (siehe Kapitel 8.4 des englischen Handbuch)\n\n\nStrg\n\n\nWas ist die \"period\"-Taste?\n\n\nPunkt\n\n\nAus diesem Grund ist ab Darktable 2.0 die 32-Bit-Unterst\u00fctzung soft-deprecated. --> was ist soft-deprecated bzw. wie kann der Satz korrekt \u00fcbersetzt werden?\n\n\n\ndarktable\nIch w\u00fcrde das etwas umschreiben, es gibt keine 1:1-\u00dcbersetzung daf\u00fcr. \"Aus diesem Grund werden 32-Bit-Systeme ab darktable 2.0 nur noch eingeschr\u00e4nkt unterst\u00fctzt.\"\n\n\n\npre-demosaiced camera raws\n\n\nGute Frage. Das kommt zwei mal vor, einmal ist es schwer verst\u00e4ndlich und einmal ist es falsch benutzt. Ich werde mit Ulrich sprechen. Was gemeint ist sind Daten, die noch nicht entrastert wurden, also noch Bayer (oder X-Trans oder was auch immer) sind.\n\n\nAdditionally, darktable supports a special demosaicing algorithm \u2013 passthrough (monochrome)\n\n\nAu\u00dferdem unterst\u00fctzt darktable einen speziellen Modus zum Entrastern \u2013 durchschleifen (monochrom). Thanks for going through these. There are some merge conflicts, could you resolve those please? I will merge then.. Is there a reason for having this in  7 commits instead of a single one?. Sorry, we are in string freeze right now. If you split this up we would accept all changes that are either source/comments or user manual.. There are still a few things open that I didn't like. I am a little short on time right now so I can't go through all the code and come up with better solutions myself.. Before. We have too much code that got merged prematurely and never fixed. @oexler came to IRC earlier and we had a very brief talk.. I like the new way to work with collect. Thank you a lot. The numbers are a little distracting though. We'll see if they are too distracting in the long run.. Thank you a lot!. What purpose does adding all the intermediate parts as individual tags serve?. General remark: I personally wouldn't make the arrow keys for navigating around configurable.. I just tried it. A few remarks:\n\nusing the arrow keys on lighttable selects images while moving around.\nin darkroom mode I would make the step size when using arrow keys much smaller. After playing with is a bit these numbers felt good to me: normal factor: 0.2, ctrl factor: 1.0 and alt factor: 0.02.\n\nApart from that I really like it!. Right, the bug with selecting images is there in master, too. I can always reproduce it when starting dt with a clean config dir, hitting ctrl-shift-i and import a directory. Then, without clicking anywhere, the arrow keys select images. But it's unrelated to your changes.\nAbout the smaller factors, I didn't like the default step size to be a whole screen. When moving around I think it's crucial to keep some context visible to see where one moved to. If 0.2 feels too small we can still increase that to 0.5 or something like that.. That is not a safe thing to do. There are early return in the code which will leave the locale in its temporary state. Instead we should fix the parsing code by not using scanf.. Why do / pose problems on Windows?. Well, yes, but that string isn't shown to the user, right? Besides the text box in prefs.. I'd say we expect users to deal with escaping correctly when entering anything. We'd still need to use \\\\ to join the parts. Alternatively we can tell users to use / even on Windows when they don't want to deal with escaping. Everything else sounds like too much work, extremely error prone and hard to get right.. We can't replace / with \\, at least not with a simple string replace.\nHaving the variable replacement on the individual parts sounds good, but we don't have the required values in _import_session_path_pattern to expand the variables, but as it's only called in one place and doing only minimal stuff we can probably get away with inlining it into the parent function and doing all the magic there.. How sure are we that no file system allows / in a file name? I'd prefer if we fixed this properly by keeping the path the way it is and stop doing silly things like creating an empty film roll. Can't we just copy the file to the computed destination and the use the regular import functions to open it? That way we should get filmrolls created automatically and paths get normalized.. I suppose yes. I'd have to look through the code to get some understanding of what it's doing and why. It's old code, longer with the project than me (I think). And since I never used that feature I never felt the need to look at the code so far.. Sorry, I was mistaken. Github confused me with the replaced email addresses in the commit.. I like the idea to have a quick way to scroll through the collection. But we have to be careful that the scrollbars can't be confused with the side panel ones. An alternative would be to make the current indicators draggable.\nDoes anyone have a screenshot of the proposed change? I don't feel like compiling and testing it right now.. Thanks for the image.\nI also don't think that we want scroll bars in darkroom. But on lighttable they might work. We'll discuss that with the others.. I personally don't use iop accels so I am not familiar with how they are used, but maybe we can just not update the accels to affect the new module and keep them for the base module only?. Thanks, that looks good.. Thank you!. Sorry, I don't remember why it was added.. I'll trust your review and decision. :-). Is this supposed to be a pull request? Or just chatting?. No worries. The Mac dmg will be done when it's done. All I can tell you is that there is only a single contributor that even uses a Mac, and we have to rely on him making the package. Until then there is nothing we can do to speed things up. Sorry.. I can't comment on the changes you did, but shouldn't this go to the master branch?. The flashing window isn't ideal, but it's much better than what we had before. Thank you for looking into this.. Thanks, good catch!. The .po was malformed. I fixed it in 330af2428f968f696730c0c8d6f304ac577fd96e. Please verify that it's correct that way.. Manually merged. It still uses the initial way of getting the level, better approaches and maybe some working on other platforms may be added in separate PRs.. Thanks for spotting that. However, I'd prefer to leave the comment as it was so it actually explains what is happening. We don't add a final \\0, that's there already.. Something went wrong there. What is the PR about?. One remark in general: Please state in the commit messages what they are doing. \"fixed typo\" is not good. At least mention that it's about the Italian translation. Otherwise it's a PITA to go through the commit logs when assembling release notes later.. No worries, just try to have better commit messages in the future. \ud83d\ude04. Thanks a lot for looking into this! Allowing to style darktable properly is definitely nice to have.. Thanks, I will take it from there and work ontop of what you did. I will merge later when my changes are ready.. Why did you close this? It looks good to me.\nEdit: Nevermind, I saw the other PR only after I commented here.. I had a look at the curve and it looks quite extreme in the highlights. Is it really supposed to push them so much?\n. Let's see how it works out.. Let's see how that turns out. And if it's a good idea to have tags behave different than folders in that regard.. I think this PR makes sense and should be merged. dt itself doesn't write the time stamp to the sidecar, so it's the user's responsibility to deal with that.. Is there a reason why you are fixing things like these all over the free software world?. Fair enough. :smile:. You can try building the website version with make darktable-usermanual-dtorg and see what it generates.. The build target darktable-usermanual-dtorg no longer works with this.. That's a good idea!. That should be fine.. @upegelow: Do we want to merge these new things into master already? Maybe we should pick the current state to the stable 2.4.x branch so we can fix stuff there for the website?. Looking at the questions I am not sure if your patch is correct. You can geotag images and thus share the location. Uploading images to the Internet might count as multimedia messaging. It's also information sharing. I'd prefer to not state anything over giving wrong information.. He probably meant the changed string, \" )\" vs. \") \".\n. Since that setting doesn't show up in the preferences a description is nice to have, but not essential. Just saying.\n. That sentence no verb.\n. the name of the script misses an 'l'.\n. it's \"raw\", not \"RAW\".\n. JPEG, raw\n. grep -r \\#if src/ | grep SSE returns not a single result in our code, just external stuff copied into our tree.\n. That should probably be a float.\n. Instead of strlen(slot)==0 you should check !*slot. A similar check is further down, too.\n. Why the +6? That's a NOP when doing %6 afterwards.\n. Unneeded +6 again.\n. Guess what :)\n. better make that a calloc so that the tests in dt_pwstorage_libsecret_destroy() don't get triggered by accident in the error cases below.\n. If calloc gets used in _new() then use free() here.\n. You probably should g_free(label); here? The libsecret docs are not saying that it is freeing that for you. Same for secret_value and secret_attributes I guess.\n. the above block could be rewritten as return item != NULL;, however you also have to unref item, so something like this would work:\nif(item == NULL)\n  return FALSE;\ng_object_unref(item);\nreturn TRUE;\n. Accordign to docs you should use SECRET_SEARCH_LOAD_SECRETS, otherwise secret_service_get_collections will always return NULL.\n. I am not 100% sure but I guess you have to free collections here.\n. you have to put the result of secret_collection_get_label(item) into a variable and g_free() it afterwards.\n. Should collections be freed below you have to make a copy here. Please research the docs and how others use that API.\n. why did you remove the else?\n. also set it to NULL\n. This leaks memory\n. Leak, again.\n. I don't see why this lock is needed at all. It is never initialized, can deadlock in the error case and only guards sequential code.\n. I don't think that you should be using dt_pdf_point_to_mm here, or is CUPS reporting the margings in PDF points (1/72 inch)?\n. According to the docs the PPD API is deprecated and will be removed in the future: https://www.cups.org/documentation.php/doc-2.0/api-ppd.html\n. Do you really have to unlink the PPD file? Do you get a custom copy passed instead of the system file?\n. all these error messages should be fprintf(stderr, ...) instead.\n. Better use sizeof().\n. Move that into the if() to not leak it when the paper already exists.\n. Better use dt_print(DT_DEBUG_PRINT, ...)\n. Better write (pt)\n. Shouldn't there be bpp be used somehow? Or do you intend to print 8bpp only?\n. Just put a dt_control_export_t in the beginning then to be future proof.\n. That sounds like a terrible idea.\n. that's #include <gtk/gtk.h> I guess? But since it gets pulled in by gui/gtk.h you can just omit it.\n. dt_print() again\n. I would prefer if those would be handed over in self. I know that we go throught he conf in many places, but that is not really a good design.\n. That's the same as setting border to 0. :)\n. Better use tempnam() to not get in trouble when printing the same image twice.\n. What if you use portrait orientation and a landscape image?\n. You leak printer_profile, pdf_image and pdf_page.\n. You say 20 here but use 15 below.\n. it's not const and you are leaking it.\n. Better use a bauhaus combobox\n. printer_profile is leaking.\n. Use a bauhaus combobox instead, label \"orientation\" and the two options \"landscape\" and \"portrait\".\n. bauhaus again\n. Leak\n. Leak\n. That could be a single cairo_move_to() and two cairo_line_to().\n. That should be g_list_free_full(printers, free);\n. you never free that (using g_list_free_full(..., free);)\n. To not use normal printf, guarded by an if, but just using dt_print().\n. this file misses the modelines.\n. Why did you rename them? It would make more sense to move the intent definition from the two places (librhtoom.c + color.h) to a single place like common/colorspaces.h and use it everywhere.\n. This is not going to work, mipmap 3 has a fixed size that you can't get the image size from.\n. returning here will leak ps->buf which got allocated in write_image().\n. the g_strdup should be removed, dt_conf_get_string() already returns a newly allocated string.\n. shouldn't that be g_strdup'ed?\n. default_printer is leaking\n. slideshow is not optional, it will always be built.\n. I would call it black_point_compensation so it doesn't get confused with bit per channel.\n. Adding it with the default TRUE to data/darktableconfig.xml.in would be better.\n. This is going to invalidate old presets. I don't think that it is a problem right now since it's a new and unreleased module (and not an iop), but soonish you should think about doing that with legacy_params.\n. No need for that, dt_control_set_mouse_over_id already raises that signal.\n. We already have d65_color_matrix so you are duplicating things here.\n. I would use IFNULL(MAX(num)+1, 0), even if it probably doesn't matter here.\n. Don't you mean 1<<1?\n. I don't think that demosaic_ppg.cl should contain anything but PPG.\n. that include should probably be in debug.h.\n. If you feel fancy you can use get_f() from the introspection to find out what value DT_IOP_DEMOSAIC_PASSTHROUGH_MONOCHROME has.\n. You have to gfree() pctl.\n. I would make them static const char * ... = N_(\"\"); so they can be translated.\n. _(c)\n. maybe use one function for all 3 values to avoid one locking step? Not sure if it's worth it.\n. why const?\n. no need to, it's calloced.\n. the function is void and shouldn't return anything.\n. don't return anything.\n. missing \\n.\n. this was >0 before. probably doesn't matter?\n. You want to prefetch them backwards as these jobs are added to a stack, so the last one added gets run first.\n. I wouldn't add it to the prefs gui though.\n. No need to init with 0, clang would probably complain about a dead assignment.\n. better use pthread_equal()\n. pthread_equal() again i guess\n. why the __sync variants? this code is inside a write lock already, isn't it?\n. pthread_equal()\n. That looks wrong. Just because the params are the same the jobs don't have to be. For example different callbacks might both just have an integer as params which can easily be the same.\n. Thanks for catching that missing !. :-)\n. why did you move that down? just curious.\n. I don't think this is possible. pthread_t just happens to be an int on Linux, but that is not the case on other platforms.\n. Actually, this seems unused. Just a debug leftover?\n. Ah, you are right, it's not an issue with normal builds, and debug builds should indeed be extra careful.\n. Fair enough.\n. s/DT/dt/ or s/DT/darktable/\n. s/No/no/ :)\n. You should create a new sqlite_stmt* (we normally call it inner_stmt) and not reuse stmt. Don't forget to finalize both.\n. You are already doing that 10 lines above.\n. This should probably be moved to the same check above.\n. s/now/not/?\n. Maybe call it something else, these target names are going to the global namespace, and something like api could be needed for other things. And it's not that obvious what it does. How about apimanual instead?\n. darktable-lua-api.pdf might be better, one day we might add a C API, or finally document the internal one ...\n. Should also be rephrased.\n. Does your API doc need the images of the usermanual?\n. Oh, and you only add the translated docs to the api target, I guess the regular ones should be built there, too?\n. We no longer use dbus-glib (since commit acf9329921e662efcc158211fe0654b3913ab6ca).\n. That's for darktable-viewer, not slideshow view.\n. Lua 5.2 can also be used from a system install. To use the copy we ship you have to tell cmake.\n. s/P/p/\n. Why not one memcpy? That way you won't forget fields if anything new gets added in the future.\n. Even Debian/stable has 3.0.2. Where do we need 2.6?\n. Ok, Solaris I understand, but an Ubuntu LTS is no reason for me in this case as we will release way after that LTS got unsupported.\n. You have to pass desc to pango_font_description_free() in the end.\n. You have to pass layout to g_object_unref().\n. You have to pass desc to pango_font_description_free() in the end.\n. You have to pass layout to g_object_unref() in the end.\n. Why the two variables x and y? And why the + ink.height in x if you subtract it again?\n. You have to pass desc to pango_font_description_free() in the end.\n. You have to pass layout to g_object_unref() in the end.\n. needs to be static\n. needs to be static.\n. pango_font_description_free(desc) and g_object_unref(layout).\n. Seconds can go to 60. Not sure if that is important here.\n. That is interesting, as man date says that seconds can go to 60. But you are probably right and we can ignore it.\n. tex_t_box\n. Better reuse the string from elsewhere so translations stay in sync.\n. In general darktable doesn't use context menus. Just saying.\n. You probably also want to listen to DT_SIGNAL_COLLECTION_CHANGED or whatever gets raised when a new image gets loaded to update your list.\n. I guess that should have some path, like the next one, and like we use #include in the code?\n. Does the build still fail when the XML is not valid?\n. Don't use that, it has side effects, like writing stuff to database. Instead add something like dt_exif_get_datetime() to common/exif.cc which does things similar to dt_exif_get_color_space().\n. You should gp_file_free(camfile) first.\n. You should gp_file_free(camfile) first.\n. This might be a good place to g_file_free(camfile).\n. That should go into HINTS, not PATHS\n. Again, HINTS, not PATHS.\n. Good catch. :)\n. Better use something like this:\nstd::string needle = \"Exif.SubImage\";\nif(i->key().compare(0, needle.length(), needle) == 0)\n  ...\n. This is leaking module.\n. So we want ctrl-y or ctrl-shift-z for redo? Both is commonly used.\n. Eventually I would like to get rid of dt_undo_type_t as that hardcodes the possible undo users in the core. But that is something for the future, for now I'm fine with it.\n. I'd prefer fixing the parsing of the file to ignore the line endings. People might edit it in an editor later and then all bets are off anyway.\n. What is missing for Flickr support? No flickcurl?\n. I'd prefer extra if(WIN32) sections where the CMAKE_CXX_FLAGS are set. Using CUSTOM_CFLAGS means that all the optimization flags, CPU tuning, \u2026 are not used.\n. Newline\n. Better fix parsing the rc file to accept both line endings.\n. Did you see that there is already doc/Windows.txt? Maybe try merging both into one file \u2013 I don't care which place to use.\n. Then add an export of those to the commands given later.\n. Is a system wide install necessary? I wouldn't like to tell people to manually copy files to system locations.\n. Again, can't that be elsewhere?\n. And again \u2026\n. That should have a space between the $ prompt and the source . like for all other comands. And why do you have the prompt in some places while others don't have it?\n. This looks like you are compiling natively on Windows and not cross compiling? That should be mentioned at the very top of the file.\n. Please use build/ as that's what we have in all our documentation. Also, put it into darktable/ please.\n. Why do you set the version? Overwriting the real one is bad when trying to find bugs later as we would be assuming different code version.\n. s/Pls/Please/. We can afford those three extra bytes.\n. That is a bug in conf.h. I know that I remarked that elsewhere already, but here it seems like a good place, too. \ud83d\ude03\n. Even worse: they don't work on all Windows file systems.\n. Can't you just pass DONT_USE_INTERNAL_LUA=Off to cmake and be done? That way you should be safe wrt. updated Lua requirements in darktable, for example a potential bump to 5.3.\n. That would probably require using the glib main loop and querying the file status every iteration.\n. Colord won't work on Windows. It's only used to get the display color profile which should already work on Windows. At least there is code in colorspaces.c.\n. What is that about? A GUI issue? Can you show a screenshot?\n. Right, stripping should be avoided, especially in these early stages where debugging crashes will be important.\n. For now that's fine. But eventually fixing warnings should be at least tried.\n. Why did you change LANG to LANGUAGE?\n. A general remark, you are using _WIN32, elsewhere we already have __WIN32__ and WIN32 and G_OS_WIN32. Would it be possible to find out in how far all those differ and change the code to only use one, provided that's possible and there aren't subtle differences when each of those are defined and relevant in the places they are used?\n. This is overwriting the previous g_strlcpy().\n. Changes to everything under external need to be pushed upstream so keeping them to a minimum is better. Thus my question, is there a problem with the old version of the check?\n. Yes, Windows has some ugly global things.\n. Just removing the select will probably break the function.\n@boucman: Do you have any insight what that function is used for and if removing the select is bad?\n. Shouldn't we finally change our codebase to use #pragma once? These defines are so last century ...\n. Great, thanks for your efforts.\n. That is ugly, use GPOINTER_TO_INT(selected_imgids->data) instead.\n. At least in the second case you have to keep using ngettext as cs might also be 0. To be safe I would even keep it in both cases.\n. Make dt_collection_image_offset() just be return dt_collection_image_offset_with_collection(darktable.collection, imgid); so that the implementation of the two won't diverge.\n. Since you only use that function internally in collection.c I would prefer to make it static and not expose it in the header file.\n. I personally would use if(selected_imgids) and not use g_list_length() at all. But that is just me trying to limit function calls. \ud83d\ude04\n. Are those errors shown constantly or just at startup? Maybe during setup the collection string is still empty (but not NULL) or something like that?\n. I wonder if it's worth to use dt_fast_expf() everywhere?. Why don't you push the 100.0 * into the LUT? It's not much, but would save a few cycles. Or would that give different results? I haven't really tried to understand the logic yet.. The other GUI callbacks do the scaling of the slider values here already.. Instead of scaling here you should do it in midtones_bias_callback().. The current strength slider is in percent, so this one should behave the same.. Maybe add a sentence about what low/high values do. Not critical, but who reads the manual \u2026 \ud83d\ude04. What about it? The rest of that IOP scales in the other place already.. This case is missing the translation.. I think it's safe to ignore Microsoft compilers. They are not capable of compiling darktable anyway.. That should be \"darktable\".. Can those two be https instead? And please add a closing /.. Did you try if saxon9 works? At least for the usermanual Ulrich mentioned that only version 6 is usable.. Just as a general remark, is there any way to automatically get those dependencies instead of hardcoding them?. \"darktable\" please.. I'd drop the \"Darktable \" part and just call it \"Documentation and help files\".. I am not convinced that rb is a good idea. That will work with the files shipped with darktable, but once the user edits them with a Windows text editor he will have Windows line endings in the file and it will break again. Instead you could add checks for \\r next to then \\n checks and properly skip them.. If reading is robust wrt. line endings you can keep it as w.. No need to check for NULL.. A simple g_strdup is fine.. Fair enough.. Master now uses Lua 5.3. In general, those dll have to respect the build options. Otherwise missing files might be referenced and the installation will fail.. you also need to pacman -S mingw-w64-x86_64-nsis. There are also some DLLs missing in the final NSIS package. After libwinpthread-1.dll and libgcc_s_seh-1.dll I stopped, there are potentially more.. I'd keep the /, unless you can find documentation that guarantees that gphoto's string is always ending in a /.. Do these result in https:\\\\www.darktable.org/? That would be wrong.. I'd like to look into this some more as I think I had some (half) automated approach for that myself a long time ago. Maybe I can dig it up again. For now hardcoding is probably fine.. Those .mo files are the translation of dt and not documentation.. For the final shipped version we want to disable the cmd window.. The read feature already got disabled under Windows, no need for those if/endif any more.. Yes, some places prefer xsltproc, however the usermanual code looks for saxon first. And as far as I remember that one doesn't work with saxon9.. Why are you looking in HOME? That is a very unusual place. Better add HINTS ENV SAXON_INSTALL_DIR and set that environment variable when compiling. Same below.. Just for reference, GTK has a \\n hardcoded when writing accel maps: https://git.gnome.org/browse/gtk+/tree/gtk/gtkaccelmap.c#n736. We want that to be \"master\" i suppose? Or remove the limitation alltogether?. We already use a dedicated environment variable in some places (FLICKCURL, LCMS2, LensFun and OpenEXR) so just adding that should do the trick.. At least for me ninja has some problems with building dt on Windows: It opens some popups, asking about how to open .sh files (scripts in tools/ we run during compilation).. Actually, addign bash is wrong, it has to be sh as that's what the shell scripts request. And IMO it's really ugly and bad style to hard code those in the cmake files. I'd rather stick with make than do that.. Yes, it's working. I am not sure if there is anything to fix from upstream. Actually I hope they don't change that as it might introduce bugs for us.. You can drop the changes to this function, I changed the way the files are read and tested it on Linux and Windows with both kinds of line endings. Please check and verify that what is currently in master works for you.. I am fine with that. Actually, I did that on purpose to make it easy/feasible to share the config file between computers running different operating systems.. The current (inverted) behaviour is on purpose as it's what hanatos prefers. Please keep it that way in this PR. Re-evaluating that decision is something for another day.. Please don't reformat random places, just indent.. Keep this aligned to the left.. Good point actually.. I'd reword it like this: \"You can replace widgets at a specific index by a simple assignment\".. gtk_container_remove() may destroy the widget, so call g_object_ref() on the widget first.. After adding the old widget back you have to g_object_unref() it again.. The problem I see is having some other script inside the darktable folder which is running with that PID. It would trigger the test (\"darktable\" is in the directory name). However, that is such a fringe corner case that we can ignore it.\nIf we wanted to do the right thing we would have to check /proc/<pid>/fd/* and see if any one of those is pointing to the sqlite file. That's just a remark, please don't add code like that. :-). Why this function? Isn't that the same as g_list_free_full(forms, dt_masks_free_form);?. s/is/if/?. Why are you not using dt_get_wtime()?. Would it make sense to record the x/y position in button_pressed and compare that to the final one in button_released instead of handling mouse movement here? That way one could easily allow tiny movements which might be impossible to avoid with some touch devices, pens or touchpads.. Why is it messed up? The PR is that old .... No idea, I didn't try to understand the code to see what ranges it's working on.. Thanks, I missed that one it seems.. And I missed that one, too. I fixed it in other places, but here I left it in. Thanks for noticing.. The first sounds good, but I would have to see it in action to get a feel for how annoying it is when the view doesn't move at first. Maybe the 2nd will turn out to be the better approach after all. Instead of using a fixed distance we should pass the (say) 5px through DT_PIXEL_APPLY_DPI() to make it a real world distance on the screen.. What do you need the mutex for? Is libfftw3 not thread safe?. I don't want to read the whole document now, but that section sounds as if the plan was something specific for the processed image at hand. Won't that break horribly when dt is processing two images in parallel, first creating the plan for image 1, releasing the lock, then creating the 2nd plan, then executing the plans. I expect both images working on the plan from the 2nd image. Or is the plan independent from the actual data and just some administrative data structures?. Well, that's exactly what init_global() and cleanup_global() are for. Having a mutex seems more confusing than setting things up once properly.. Yes, those are single threaded and called during dt initialization when loading the shared objects or closing dt.. Please use fprintf(stderr, ...). Why all the memset instead of a single lr_data_t data = {0};?\nAlso, I hope it's not too big for the stack. @LebedevRI might know.. Those should be NAN.. Can a Lr Xmp contain both 6.0 attributes and newer ones? If yes, it might make sense to check the old ones first and let the new ones overwrite them afterwards.\nIf they are mutually exclusive then ignore this comment.. Well, just to be safe we should use memset then.. Please don't touch .po files.. Yes, that is fine.. This is a translatable string. It may not be changed. Please move that line to another PR that can be merged next year.. Other PR please.. Other PR. I suppose that was meant to be \"with\". You should init pr. Otherwise values like is_turboprint might be random. Or make sure that all values get set in dt_get_printer_info().. Why don't you pass a pointer?. Please replace med with some proper word that people can understand without looking at the code.. Again, why no pointer?. A general remark: The PPD api in CUPS is deprecated. Maybe we should switch to the newer one eventually?\nhttps://www.cups.org/doc/api-ppd.html. Please use sizeof() so the values can't get out of sync.. Please use g_mkstemp() or g_file_open_tmp() instead of trying to come up with a unique name. This is opening us up for race conditions.. What does that mean? Maybe reword that string?. If you are reusing the string here you should have it as a global static const char*. Besides, you are adding it as a translated string so I am not sure this will ever work when not using an English GUI.\nAnother point: you are looking at legacy params here. How should those ever contain the new string you just introduced? Shouldn't you keep checking for the old none?. Are users even aware that CUPS is a client/server system? Wouldn't they just assume it's a printer attached to their computer, and be confused by reading about a server being involved?\nMaybe \"color management in printer driver\"?. Does that also work with normal + and - keys or just the key pad ones?. Should ctrl make the steps bigger and alt make them smaller?. No need to pass error and then free it. Just use NULL as the 2nd argument to gdk_pixbuf_loader_close() and check its return value.. Nope, that is the wrong logic. The rotation has to be done when getting the thumbnail. You disabled it for when the first attempt worked out.\nCalling gdk_pixbuf_new_from_file_at_size() has to happen iff the previous block failed, and the rotation logic has to be independent from that. It has to be determined if the rotation logic needs to be used when opening the whole file, too.. When not having a preview (have_preview == FALSE) we have to go into this, no matter what no_preview_fallback says.. Well, I don't even have a numblock. So I would prefer to see normal +/- being used. That's also what other applications like web browsers default to.. Looking at the git log it seems that passing a DNG to gdk_pixbuf_new_from_file_at_size() is error prone: a56251caa00f4d73056672db42b441ca043d47e9. Changing patch files is probably breaking them.. AFAICT there is only one system call in dt that counts. The one from Lua is just wrapping what the user feeds it. And the rest it test code or external libs.\nThat being said, just use g_spawn_* as it's done in src/views/lighttable.c, maybe sync, maybe async.. This got fixed by the subsequent memset. All good now.. Maybe make body a char* and use g_strconcat() to assemble the string. That way we can't overflow and won't truncate.. While you are at it, I have the feeling that we are leaking attachment->file. Either free that or use it directly in argv.. That shouldn't be part of the -d option as it affects all output, not just the debug log.. What is logdir created for?. And this allows printing to the cmd.exe console while not showing a console when starting the program?. I must be blind, I don't see it being used anywhere.. @LebedevRI We could default ${LLVM_INSTALL_PREFIX} to /usr/ when not set.. Yes. :-). I just tried on Windows 7. When double clicking darktable.exe in the explorer I get the dreaded terminal window.. Why 0 for inner nodes?. This seems expensive. You are iterating the tree in tree_count_childsum, too. Can't that be done in one pass over the tree?. This just adds the count column's value to the text column. For tags that information is already there when constructing the tree, and for the others it feels wrong to do that, too.\nCan't you gather all those numbers in this function and set the correct text when creating the tree? Maybe by splitting the loop, first going over all db results, processing them, then going over the list, counting, then creating the gui?\nAlternatively you could derive a new GtkCellRenderer from the text renderer that takes the COUNT column into account so you only have to update that column and not care about the text at all.. What is the reason for this flag? Is dt_collection_update_query emitting a signal that in turn causes this module to rebuild its list? If that's the reason, then instead of having this flag and risking to run into a race condition when other parts of dt might cause the signal to be emitted at the same time, just disconnect from the signal, call dt_collection_update_query and connect again (using g_signal_handlers_block_by_func).. DT_COLLECTION_PROP_{DAY,TIME} are no longer handled. Is the default case working for those?. I don't like comparing translated strings. Instead you should store the mode in the menuitem, similar to https://github.com/darktable-org/darktable/blob/master/src/gui/presets.c#L723 and then retrieve it here (https://github.com/darktable-org/darktable/blob/master/src/gui/presets.c#L582) \u2013 just with int instead of char.. I would even argue that worse interpolation done by cairo, namely nearest neighbour, would be the best approach. At least if we can guarantee that we are displaying the image at 200% and not some float factor.. Please add a note about where that function is from, why it's there and under what circumstances we can remove it again. Apart from that it's a necessary evil i suppose.. The result of dt_conf_get_string() needs to be g_free()ed.. See above, you are leaking.. If you leave this in you shouldn't have the problem of figuring out if it's a new configuration or an old one lacking the setting.. .792 is CA.\nThat being said, why do you allocate memory, parse the color, and then overwrite it with what we have in the CSS file? That will leak the g_malloc0 result and be useless.. That's #252525. And again the value isn't even used.. Why pointers? Make it GdkRGBA bg_normal; and you no longer have to care about freeing it later.. The comment is no longer true. And you don't need to initialize the variable either. scan-build will complain about that.. Some typos in that string. Fixed version:\n\nWe have an updated performance configuration logic - executing that might improve the performance of darktable.\\nThis will potentially overwrite some of your existing settings - especially in case you have manually modified them to custom values.\\nWould you like to execute this update of the performance configuration?\\n. No need for g_markup_printf_escaped, you don't use markup in the string. Just pass _(\"...\") to dt_gui_show_standalone_yes_no_dialog() instead of label_text.. That part is fine, you have to free what you get back from gtk_style_context_get(). But you will leak the g_malloc0 result by using the same pointer.. You don't need to set the help text in this function, just do it once in gui_init() when the widgets are created.. Again, only set the help text once when creating a widget.. Shouldn't you release img first?. You are right, film_id = -1 is probably a thing of the past when we still had the special single image film roll.. @TurboGit wants to add smart ellipsizing of strings that leave the fixed parts alone and only ellipsize the variables that are added via %s. I'd assume that for strings that are too big while not containing any variable, or that are not shrunken enough even though the variables are basically replaced by ... the whole string has to be ellipsized instead.\n\nAbout offloading the work to GTK, that won't be possible as the message isn't a GTK widget. Instead we can probably use something like this:\nhttps://github.com/darktable-org/darktable/blob/master/src/bauhaus/bauhaus.c#L77-L78. I tend to agree.. You probably want spaces and a + here, too.. Spaces and +. Spaces and +. Spaces and +. Spaces, caps and +. Spaces and +. Spaces and +. Spaces and +. Spaces and +. I am not sure about capitalizing letter keys. That might make people think they have to press shift, too.. Spaces and +. Spaces and +. The key is called space and not space bar. That's as if you added key to all other keys.. Same as above.. No need to check for NULL, g_free handles that already.. I would use image->flags instead, that should be a little faster. Have a look at metadata_view.c to see how the rating is stored in there.. Good point. Let's have them as capital letters then.. It also has https://en.wikipedia.org/wiki/Alt_key and https://en.wikipedia.org/wiki/Control_key.. Those need to be char *. My point was, that we should just use \"space\" when showing shortcuts.\nThat other sentence could also be written as \"Fully zoomed-in image view while holding down Ctrl + Z with indication of the sharp areas in focus.\". I am not a native speaker though.. Why do you create a new project?. Why another project?. You can just add \"m\" to the target_link_libraries call. dt proper does the same, so it should work here, too.. It's \"darktable\" and not \"dt\" in executable names.. I guess we can move the whole content of the file into this check. Why would we install a helper tool when the main program is missing?\nThat being said, UNIX AND NOT WIN32 sounds wrong.. s/dt/darktable/. What is that good for? To have the main script in people's $PATH?. Drop the Makefile if you add a CMakeLists.txt that does the same thing.. Just don't link the script to /usr/bin/ and you don't need this.. That tool will never be in PATH.. Why?. Did you try if that actually works? Is the value pointer still valid after the next entry was found?. I agree with @rabauke, mentioning the hex number of the EXIF field gives no added information to users and looks more like a garbled file than actually intended content.. Don't assemble your query like that. Use prepared statements like everywhere else in dt.. No ; needed in those sqlite3 calls.. Again, use prepared statements.. No ;. No ;. This time you use a prepared statement. But why do you duplicate the string?. No ;. No need to duplicate strings.. No ;. strdup is not needed.. No ;. Aren't the positions unique? Maybe a UNIQUE INDEX would make sense?. That's 32, right?. You also have to create your index here.. if it's a function only used in this file then make it static.. strdup. Make it static, too.\nAnd please, no camelCase.. Does that mean that duplicates are always added at the end, instead of next to the original image?. Generating the next image position like that isn't thread safe. When adding several images in parallel it might break. Would it be possible to use a subquery to determine the right value on the fly?. What is this for?. You have to free the string afterwards.. ",
    "rpoisel": "Hej! Thanks for your quick reply. Yes, it works this way. Maybe there is a way to inform the user that it is using the command-line utility instead of the saxon extension (in case). One more suggestion: could you please include the now necessary package in the usermanual/README? Thx again!\n. ",
    "oliviertoulouse": "Well to be honest, \"all\" was convenient  because it eats less pixel than \n\"special\", especially for the French translation....\nLe 04/01/2013 23:08, Boucman a \u00e9crit :\n\nhmm, I didn't react on the ML discussion but the \"common names\" for\nthese type of action are\n- copy\n- paste\n- paste special (\"collage sp\u00e9cial\" in french and we probably need to\n  add copy special for the last one\nI think we should try to keep the usual names here...\n(i'm afk next week, so feel free to discuss/get it merged by other devs)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/133#issuecomment-11902046.\n. \n",
    "bluesceada": "Hm yeah, however like I commented in the script, the best would probably be to be able to use the code behind exiv2's \"fixiso\" option.\nDarktable itself already seems to use something like that, that works, and shows the ISOs correcty for me inside darktable.\n. Yeah I have seen this, but the previous code did also use Exiv2::isoSpeed(..) already, like the fixiso function (and the exiv2 cmd output), but interpreted the data differently (in some way I don't exactly get how exiv2 works there..).\nSo checking what you say, other non-standard ISO tags would also be read the new way, but probably still an improvement to be regression save. I just pushed it to the branch for this pull request...\nHowever, still without this, I tested Canon Powershot S90, Nikon D200, Nikon D7000 and Sony NEX-C3 raw files now with higher and lower ISOs, which all reported the correct ISO inside darktable :-)\nFor the Record: Only using:\nimg->exif_iso = (float) std::atof( pos->toString().c_str() );\ndoes NOT produce the desired results, even if it also looks like just converting it to a string, it will also just take the first field (as far as I understand that..) and produce the same wrong results as the old way!\nBTW about the strange colors in the image: You can reduce them if you use \"hotpixels\" and select \"detect by 3 neigbors\", but that would mean your camera really has that many hotpixels at 25600, so maybe this would just hide some other bug ...\n. Ok, I can't merge, one of the main devs has to do this...\n. I just pushed it into this branch.\nI intentionally put them into the params first, to be able to work further on them another time. But I see that they are also kept in gui_data if I switch around modules in one editing session of the picture (I was not aware how far gui_data gets preserved), so this is probably already enough, in a following session one probably has something else on the mind anyway.\nAbout deadlocks, how will it be more critical to deadlocks if I put it in gui_data instead of params? Shouldn't it be exactly the same or even less prone to deadlocks (does not have to be saved back to db)? Please comment if you think that something could result in deadlocks now. (I don't completely know what kind of concurrency I have to expect across all the module functions)\nPlease also tell me any other remarks. Thanks!\n. This is only based on the clang analysis. I checked the code and tried to compile and tested it, but no idea if this is really correct. After thinking about the camera_control.c this seems strange, but I could not find detailed enough documentation about gp_file_set_data_and_size. Please review carefully.\n. Ok I was probably wrong, taking down the pull request for now, I think this clang analysis brings quite some false positives (I also looked at some other things that seemed so).\n. Don't get it merged, I hope I will have time to work on this soon again.\nEdit: I will definitely get some time in the next 4 weeks and then try to get a version that can be merged for the time being. I will discuss this on IRC then.\nI hope to be able to get it into the next release, but I am still not really happy with the UI parameters -> actual parameters for the code and how color biasing works overall.\nOpenCL will also be a 'todo' after the rest is fixed, but maybe that is still OK after a release.\n. OK thanks for all your comments, they should be handled by the last commit now\n. I will do 1,2,3 in some minutes, examples will be added during the next days/next weekend with some screenshots (I will also have examples for using multi instance and blending for certain cases)\n. I removed the strength slider description. We discussed on IRC, and this slider will be removed, because it is quite similar to using blending instead.\n. This pull request is ready, the missing \"strength\" does just not reflect the current state of master where there is still a strength slider. But you can still wait a while until I also add the examples, otherwise they would come with a new PR.\n. I specifically decided against this, as it will be saved in the database, this might too easily get changed, invalidating the database.\n. ok then let's use an enum...\n. from the GUI the minimum possible radius is 0,5 but I can add these changes anyway.\n. ",
    "gapato": "This seems to work, thanks!\nMaybe it would better to also add the check which avoids doing this if the \"good\" tag is already present.\nDoing that we may safely merge without worrying too much about a regression.\nThis is from exiv2/actions.cpp (almost, markdown doesn't like brackets):\n\nif (strcmp(md->key().c_str(), \"Exif.Photo.ISOSpeedRatings\") == 0) {\n    // Standard Exif ISO tag exists; not modified\n    return 0;\n}\n\n. Well, do as you see fit, I clearly lack experience here :)\nFor the false colors, this is a darktable bug, this file displays fine in rawtherapee/ufraw (see this bug: http://www.darktable.org/redmine/issues/9177).\n. Agreed on your first point, that was too hasty and unfinished.\nThere's a issue with refusing the pattern outright right now since it is read from the darktablerc, so a experienced user who would know what to do would have to restart darktable, and a beginner would probably have a hard time figuring what to do.\nSo I will try adding a text box under 'session' for the user to input his pattern, and refuse to shoot (with a message) if $(SEQUENCE) is not there.\nOn other, easier option would be to have the pattern hardcoded, but that's not very satisfactory.\n. Ok so this commit add the functionality I've described above.\n@Jesper this should address half the issue you filed. Since this changes is pretty orthogonal to yours, there should not be too much merging trouble.\n. ",
    "cornergraf": "Oh how embarrassing. I was going to test that, but I came up with some other things to test as well and then it slipped my mind again. Should not be hard to fix though.\n. It should be fixed now :)\n. I have now fixed two of the issues mentioned by hanatos. I have not yet addressed the performance issue yet, but my performance numbers are way different anyway and I cannot determine a significant difference between vanilla DT and my version. I will try to investigate further, but for the time being I hope that these two fixes are good enough.\n. 1) The contrast change between file type and background was more accidental than intended, but I liked it well enough to leave it be. I have no problem turning it down again though.\n2) The change of shape for the stars was also unintentional. I can try to bring back the old shape, no problem. I will also implement a dark gray version of the stars, let's see if you like that one :)\n3) Has the pref button really become smaller? If that one changed I would seriously be surprised.\nAs for where/if to have the buttons I will create a new branch tonight where things are only toggleable in the preferences dialog, but with keyboard shortcuts.\n4) The background color label thing is something I myself like, but I have not yet heard anyone else comment positively on it. I wanted to include it as just another option, and if you don't like it you don't have to use it. But if even that is going too far, I would not have a problem removing it again.\n5) more like switch on, by default they are all off (unless hovering over an image).\n. boucman: I do expect to toggle them on and off, but a keyboard shortcut for that would be good enough.\nIdeally I would want to have the buttons, but I fully understand and somewhat agree with concerns over clutter and not having enough space for them, especially on lower resolutions. One could argue that lower resolution displays should not be used for photo management, but I don't really want to make that decision for everybody else.\nI also believe more people would be happy having them as preferences than not having them at all, which could be the case if we require them to be buttons.\n. Yes I am sorry, I have not been very active lately - right now I am travelling for my company and have little spare time.\nI do intend to finish this somehow, but I am still considering what the exact implementation should be like. I have started experimenting with the preferences window, and I have decided to merge the ratings/reject button functionality as was suggested above, but other than that I am still considering exactly what this should look like if it is going to be accepted.\nThis week probably won't see much progress, but on the weekend I will hopefully be able to do some more work.\n. ",
    "bremner": "I guess houz refers to .dir-locals.el\nThat would be a less intrusive solution for non-emacs users, if a bit more magical for emacs users.\n. ",
    "calca": "4) i like background color more than circle ;) I will like the option on the preference to show color label as circle or background color\n. ",
    "jonleighton": "@hanatos I don't understand your comment about blue? Are there any of the profiles that would benefit from being done again?\n. ",
    "josefwells": "Originally I was going to add it under the \"working..\" line that pops up while rendering and then disappear.\nHantos suggested in IRC that the preview/thumbnail thing would be a better place.\nFor a while I had it drawn over the preview window just above the zoom box.. but it was very hard to get the scale/font right for all image sizes.\nThe more I think about it, the more I think having it appear/disappear with \"working...\" might be reasonable.. although I don't really know how that works... I'd have to dig a bit.\n. ",
    "LebedevRI": "Pascal Obry committed his own vision of this in dda79a84d8dc8dcc77bea8ad957c378ef56f685d\n. Also related to my bugreport: http://darktable.org/redmine/issues/9348\n. Alternative implementation of this has been committed: f496fbdca2bbfedd55cd2899f3334bc48b29c2f9\n. How about 2-step patch:\n) First will contain strings common for both branches - 1.2.x and master, and will be committed to both branches.\n) And second will contain all other master-only strings and will be committend to master only?\n. Well, i guess, i can just redo this spelling correction for all 3 branches (master, 1.2.x, 1.1.x).\nWill not that be sufficient to avoid any problems for cherry-picking?\n. Stale, no free time to update.\nMaybe next time...\n. Testing has not revealed any issues with PR, so i think that it is fine.\nSince v1.4 is released, so this can be finally get merged.\nSorry for so big delay.\n. Rebased, fixed all merge rejects and updated.\nPlease, test and finally merge this for good.\n. What is the status of this?\nThe http://www.darktable.org/redmine/issues/9541 have status of fixed, but the PR is still here, now with conflicts and looks like it is stale.\n. I do not see the reason to keep this PR open.\nOnce you've updated your work, you can send new PR.\n. Yes i did. So far they referred me to this 2 links, but they was unhelpful so far:\nhttps://developer.gnome.org/gdk3/stable/GdkDevice.html#gdk-device-get-axis-use\nhttps://developer.gnome.org/gdk3/stable/GdkDevice.html#gdk-device-get-axis\n. http://stackoverflow.com/questions/18349754/gtk3-porting-gdkdeviceaxis\n. I have successfully tested my PR on Gentoo testing and Debian testing with positive results.\nOutput on both systems, master branch:\n...\nXslt processor saxon not found. HTML usermanual will be built with xsltproc;\nexpect usermanual with inconsistent screenshot and image dimensions.\n-- Configuring done\n...\nOutput on both systems, PR:\n...\n-- Configuring done\n...\n. Please, double-check everything because this time not all of changes are trivial.\n. I have debootstrap'ed debian stable, and there seems to be no issues in building this branch there.\n. Build tested both on Gentoo testing and (debootstrap) Debian Stable\n. I have not spotted any issues after using it for 2 days.\nI'll merge this, and if any regressions will be found, i will fix them.\n. This is a new iop, so i'll mark this as Post-1.4\n. @jakeprobst you need to rebase this branch, we can not merge it as it is.\n. @jakeprobst I'm sorry to hear that.\nWhen you will eventually have time, feel free to resubmit PR.\n. @rkahl any news? please spend some more time on this so we can finally merge it for good.\nPS: i really like the idea behind this PR\n. How about 32-bit float TIFF output? (src/imageio/format/tiff.c)\nAnyway, i'm looking forward for this!\n. So, 1.4 has been released.\nI think it is time to discuss this and make a decision about this.\n. PR updated.\n. png and tiff used to be mandatory and are now optional\n@boucman I believe you misread diff: they are still mandatory. You can check that by temporarily removing (e.g.) libpng-dev package:\n$ cmake ../\n...\nCMake Error at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:108 (message):\n  Could NOT find PNG (missing: PNG_PNG_INCLUDE_DIR)\nCall Stack (most recent call first):\n  /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:315 (_FPHSA_FAILURE_MESSAGE)\n  /usr/share/cmake/Modules/FindPNG.cmake:105 (find_package_handle_standard_args)\n  src/CMakeLists.txt:167 (find_package)\n-- Configuring incomplete, errors occurred!\n. Tested.\nIt seems to fix all issues reported in #9704. No regressions was found.\nThis is not a new feature, so it should be merged before releasing 1.4.\n. Currently my DE is broken, so please add it for me after merge.\n. Merged to master manually.\n. First issue is fixed.\nHowever, i do not understand why the second issue is happening, or how to fix it.\nAny help would be appreciated.\n. You have broken GCC-4.6 and clang build by merging this.\n. > GCC 4.8 never reported this. Otherwise the -Werror would have catched it.\nYes, i was not able to reproduce this on any of my compilers also.\n\nInitial report is just about signed unsigned comparison, why did you disable the loop instead of just turning the k value to unsigned int ?\n\n/home/mauro/darktable/src/iop/tonecurve.c: In function \u2018init_presets\u2019:\n/home/mauro/darktable/src/iop/tonecurve.c:438:3: error: comparison of unsigned expression < 0 is always false [-Werror=type-limits]\n   for (int k=0; k<sizeof(presets_from_basecurve)/sizeof(presets_from_basecurve[0]); k++)\n   ^\nsizeof() is unsigned. i believe even if k would be unsigned also, it would not have fixed it.\nBut anyway, since presets_from_basecurve is empty, that code will anyway do nothing.\nGCC - from 4.6 to current stable (4.8 ATM)\nClang - latest available version (i am not sure is this official requirement, but this is highly recommended at least by me)\n. Fixed whitespace.\nAcc. to @hean01 memcpy is ok (this line is obsolete now)\n. As discussed with @hanatos this is good to go.\n. @boucman i already did in a639dda, no?\n. Reasoning:\n0. CMAKE_C_FLAGS is a base flag, if CMAKE_BUILD_TYPE is set, CMAKE_C_FLAGS_${CMAKE_BUILD_TYPE} is appended to CMAKE_C_FLAGS.\n1. -msse2 is enabled by -march=native, why should we re-enable -msse2 manually?\n2. Yes, i removed -g, but only from RELEASE build type. Why - with -O3 it is not really usable, and RELEASE build is supposed to be best optimised for speed; if you want speed AND debug symbols - CMAKE_C_FLAGS_RELWITHDEBINFO is there for such purpose, that is common practicle.\n. Ok, i agree on -g part.\nBut why shouldn't all bulids have march/mtune?\nI assumed it wasn't intentional, but if it was intentional, i'd like to add a comment with the reason there to resolve any further confusion.\n. If you are building a package you should set BINARY_PACKAGE_BUILD, which will force ${MARCH} to \"-mtune=generic\", no?\nAbout OSX: what if before set(CMAKE_C_FLAGS ...  we add something like:\nif(APPLE)\n  set(MARCH \"-msse2\") #OSX does not like -march/mtune\nendif(APPLE)\nWill that be ok for OSX?\n. Ok, i moved -g to CMAKE_C_FLAGS, now it is set for ALL build.\nSo, is there any more reasons not to use -march=native, excluding package building (set BINARY_PACKAGE_BUILD to on) and OSX?\n. Correct.\nWhat i meant to say is: if we set CFLAGS to -Werror BEFORE building external deps, osm-gps-map will not compile (with clang and -Werror), and that is C code.\nSo the question would be: do we really need to build src/external with -Werror?\n. Did you send bug report to cmake about this?\nI'd say that this should rather be fixed in cmake.\n. @upegelow right. fixed.\n. @mazhe do you still want this to be merged?\n. No activity in 3 months.\nIf you really need this, feel free to answer to our questions.\n. @sgimenez if you still believe that this is ready to be merged AND you want us to eventually merge it, you need to rebase it, and fix issues that we commented.\n. @sgimenez if you want your PR to be merged you need to fix the issues we pointed-out to you.\n. @sgimenez there is too much formatting-only changes, so it is to difficult to see functionality changes. maybe some other time.\n. Be careful when reviewing - i did once get \"double free or corruption\", but was not able to reproduce it again...\n. @fingerle not that i do not want/like my code to be reviewed, but this PR mostly needs preview of it's functionality - i.e. what is working and what is not; \"coding style\" is secondary in this case, and i'm sure we can handle it internally.\n. > Aren't the parameters that show up in the GUI, the ones which were recorded in the preset, possibly completely different from the ones that will be applied?\n@sgimenez nope. correct ones are displayed in gui\n. > Some darktable users disable separately TCA or lens distortion or vignetting (I'm one of them) and the current patchset is useless to them.\n\nAlmost. Since one of my lens lacks EXIF data for the focus distance, I also set it to a custom value different from the hard-coded 1000.0.\n\n@sgimenez I still do not completely understand the reasoning.\nExpected workflow:\n1. Enable Lens IOP.\n2. Click \"Reset parameters\"\n3. Do NOT change anything!\n4. Create auto-appliable preset\n5. Change whatever you want in current image and any next images, that have this automatic preset applied.\nFocus distance is specific for any image, so you would anyhow have to set it for each image manually.\n. @sgimenez you might have a point.\nBut i will not change that functionality in this PR.\nIf i will indeed find that behavior better, i'll implement it in next PR.\nWhy - i want to have something that covers most of the usecases and known to be working in master, before i fix it for most of the rest usecases.\nIn the mean time you can help us by testing this PR.\n. @upegelow please create new issue in redmine with full BT\n. @upegelow i tried everything i could think of and i just can not reproduce such crash here.\nPlease, give me full backtrace, else i'm stuck.\n. @upegelow i committed f6129f8a352dd99037d98d5f8c51680ffb889ada, so now it should not crash anymore, but i still need BT!\n. @upegelow Crash reproduced and [hopefully] proper fix committed.\n. I must mention that i have implemented exactly the same idea in earlier PR #548\n. @phedders indentation is still not fixed.\nI'll close this PR, and once you've fixed indentation you may resend PR.\n. src/common/imageio_module.c, line 224:\nif(!g_module_symbol(module->module, \"export_dispatched\",      (gpointer)&(module->export_dispatched)))      module->export_dispatched = _default_storage_nop;\nSo i'm not sure export_dispatched can be null.\nMaybe this should be rather fixed in lua code?\n. Apparently, this PR is required on Debian sid as of now:\n[ 29%] Building C object src/CMakeFiles/lib_darktable.dir/common/pwstorage/backend_gkeyring.c.o\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c: In function \u2018dt_pwstorage_gkeyring_set\u2019:\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:71:3: error: \u2018gnome_keyring_attribute_list_append_string\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:145): Use 'g_hash_table_replace' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_append_string (attributes,\"magic\",PACKAGE_NAME);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:72:3: error: \u2018gnome_keyring_attribute_list_append_string\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:145): Use 'g_hash_table_replace' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_append_string (attributes,\"slot\",slot);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:76:3: error: \u2018gnome_keyring_find_items_sync\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:321): Use 'secret_service_search_sync' instead [-Werror=deprecated-declarations]\n   gnome_keyring_find_items_sync (GNOME_KEYRING_ITEM_GENERIC_SECRET,attributes,&items);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:84:5: error: \u2018gnome_keyring_attribute_list_append_string\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:145): Use 'g_hash_table_replace' instead [-Werror=deprecated-declarations]\n     gnome_keyring_attribute_list_append_string (attributes,key,value);\n     ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:89:5: error: \u2018gnome_keyring_item_set_attributes_sync\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:407): Use 'secret_item_set_attributes_sync' instead [-Werror=deprecated-declarations]\n     gnome_keyring_item_set_attributes_sync(DARKTABLE_KEYRING,f->item_id,attributes);\n     ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:95:5: error: \u2018gnome_keyring_item_create_sync\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:340): Use 'secret_item_create_sync' instead [-Werror=deprecated-declarations]\n     result = gnome_keyring_item_create_sync(DARKTABLE_KEYRING,\n     ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:104:3: error: \u2018gnome_keyring_attribute_list_free\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:155): Use 'g_hash_table_unref' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_free(attributes);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c: In function \u2018dt_pwstorage_gkeyring_get\u2019:\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:118:3: error: \u2018gnome_keyring_attribute_list_append_string\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:145): Use 'g_hash_table_replace' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_append_string (attributes,\"magic\",PACKAGE_NAME);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:119:3: error: \u2018gnome_keyring_attribute_list_append_string\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:145): Use 'g_hash_table_replace' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_append_string (attributes,\"slot\",slot);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:120:3: error: \u2018gnome_keyring_find_items_sync\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:321): Use 'secret_service_search_sync' instead [-Werror=deprecated-declarations]\n   gnome_keyring_find_items_sync (GNOME_KEYRING_ITEM_GENERIC_SECRET,attributes,&items);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:121:3: error: \u2018gnome_keyring_attribute_list_free\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:155): Use 'g_hash_table_unref' instead [-Werror=deprecated-declarations]\n   gnome_keyring_attribute_list_free(attributes);\n   ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:129:5: error: \u2018gnome_keyring_item_get_attributes_sync\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:396): Use 'secret_item_get_attributes' instead [-Werror=deprecated-declarations]\n     gnome_keyring_item_get_attributes_sync (DARKTABLE_KEYRING,f->item_id,&attributes);\n     ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:143:5: error: \u2018gnome_keyring_attribute_list_free\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:155): Use 'g_hash_table_unref' instead [-Werror=deprecated-declarations]\n     gnome_keyring_attribute_list_free(attributes);\n     ^\n/home/lebedevri/darktable/src/common/pwstorage/backend_gkeyring.c:144:5: error: \u2018gnome_keyring_found_free\u2019 is deprecated (declared at /usr/include/gnome-keyring-1/gnome-keyring.h:172) [-Werror=deprecated-declarations]\n     gnome_keyring_found_free (items->data);\n     ^\ncc1: all warnings being treated as errors\nsrc/CMakeFiles/lib_darktable.dir/build.make:2073: recipe for target 'src/CMakeFiles/lib_darktable.dir/common/pwstorage/backend_gkeyring.c.o' failed\nmake[2]: *** [src/CMakeFiles/lib_darktable.dir/common/pwstorage/backend_gkeyring.c.o] Error 1\nCMakeFiles/Makefile2:1049: recipe for target 'src/CMakeFiles/lib_darktable.dir/all' failed\nmake[1]: *** [src/CMakeFiles/lib_darktable.dir/all] Error 2\nMakefile:136: recipe for target 'all' failed\nmake: *** [all] Error 2\nAlternatively, we could turn deprecation errors for that specific module into warnings.\n. @jcsogo well, i'd say yes, just like it is already enabled by: demosaic, temperature, colorin, colorout.\n. No additional notes from me.\nPS: @TurboGit, set http://www.darktable.org/redmine/issues/9967 to fixed after this gets merged :)\n. @TurboGit \nIt is really bad to report such issues at this point, but rotation works incorrectly:\nRotate +30 degrees should rotate by 30 degrees CCW;\nRotate -30 degrees should rotate by 30 degrees CW;\nAnd now it does completely opposite thing.\n. @TurboGit \nIt is really bad to report such issues at this point, but rotation works incorrectly:\nRotate +30 degrees should rotate by 30 degrees CCW;\nRotate -30 degrees should rotate by 30 degrees CW;\nAnd now it does completely opposite thing.\n. And now it is time to report big bug \u21161: alignment is working uncorrectly with rotation != 0:\nOpen some image, reset watermark iop, select darktable.svg, set scale to 50%, set alignment to \"right border\".\nWatermark is now touches image's right border with it's right border.\nSet rotation to 90 degrees: bottom of the watermark is floating in some distance away from right border.\nExpected result: bottom of the watermark should touch image's right border.\n. big bug \u21162: scale on = image is working uncorrectly with rotation != 0:\nOpen some image, reset watermark iop, select darktable.svg.\nWatermark is now occupies entire image (horizontally).\nSet rotation to 90 degrees: vertical size of watermark is bigger than image (only part of watermark is visible)\nExpected result: watermark is supposed to occupy entire image (vertically).\n. @TurboGit \nrotation = 0 - http://picpaste.de/pics/step1-HibwZshI.1402414507.png\nrotation = 90 - http://picpaste.de/pics/step2-dHJwAAAq.1402414550.png\n. @upegelow are you fine with the fact that usermanual changes are bundled into this PR? \n. @dtorop done.\nI'll try to look into merging bayer and x-trans codepaths in IOPs, and in using SSE and OpenCL there.\n(except probably demosaic algos)\n. I do not see any regressions and this does not touch history stacks, so i'll merge this.\n. Well, that is not what we saw.\n\n. PR was getting too big, so i split it.\nThis PR is ready for review and merging!\n. Ok, this PR is going to land soon with minimal changes planned, so better post comments about code now :)\n. We do not want this to be implemented in the core.\nOnce Lua can deal with IOPs, it will certainly be Lua territory.\n. This is going to be merged soon.\nSo if anyone have any objections, now is the time.\n. @rwh86 \nActually, maybe yes, but i'm not sure for 100%.\n. @rwh86 @boucman\nDarkroom:\n\nExported result:\n\nSo it works, but there are some issues.\nNOTE: this is not part of this PR! But avaliable in https://github.com/LebedevRI/darktable/tree/iop-temperature-mi-blending\n. @rwh86 \nNo :)\nThumbnail in DR's top left corner is completely wrong and there are glitches when moving/zooming main view.\n. IRC: <hanatos> i see no problem with that one (624)\nSo i will merge this in +48 hours if no one objects.\n. @edgomez Oops. Fixed in a73f4750f231c0aea03bbf8a099a0533c3fb6cf3\nNo idea why it builded for me without that...\nThanks for testing!\n. Ok.\n. @upegelow thank you for testing this.\nSo far it confirms my tests.\nThe important thing is whether it will still work after i fix @houz note (TODO 1.) \n. @upegelow\n\nSmall recommendation: you should move the masks version number as a makro definition into masks.h.\n\nI'm not sure that i understand, why would this be better?\n. @dtorop i do not think this is likely.\nThere is more code using omp_get_num_procs() in DT (histogram code, lens.c), so it would have crashed earlier.\n. @dtorop \nBasically, that was false alarm.\nThere is nothing wrong with you code.\nIt is a known longstanding issue.\nAs you can read there, it happens only when zoom > 100% and flip != no.\n. @dtorop \nI \"found\" what causes crashes, at least for me.\nThis fixes crash, and garbage is being displayed like for the plain Bayer.\nI have no idea how wrong is this diff.\nI also have not a single idea why garbage is displayed, but that is not new issue :/\nI found it using AddressSanitizer.\n. @dtorop \nMake sure to test it on portrait images (in other words, orientation iop MUST be on, and it MUST be not a no-op)\nOr ping me in IRC.\n. @dtorop \nHm...\nGCC-4.9.1 here (looks like at least 4.8 is needed)\nrm -rf * && LDFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CXXFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CC=gcc CXX=g++ cmake ../ && make -j9 && sudo make -j9 install && darktable\nThen open Portrait X-Trans image, zoom in 200% and move zoomed-in view a bit, and:\n```\n==26248==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60300021208f at pc 0x7ff041b2c578 bp 0x7ff0a504bb40 sp 0x7ff0a504bb38\nWRITE of size 1 at 0x60300021208f thread T12\n    #0 0x7ff041b2c577 in vng_interpolate /home/lebedevri/darktable/src/iop/demosaic.c:1175\n    #1 0x7ff041b3c692 in process /home/lebedevri/darktable/src/iop/demosaic.c:1566\n    #2 0x7ff0cf8e3d9f in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:1430\n    #3 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #4 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #5 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #6 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #7 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #8 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #9 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #10 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #11 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #12 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #13 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #14 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #15 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #16 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #17 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #18 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #19 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #20 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #21 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #22 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #23 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #24 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #25 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #26 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #27 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #28 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #29 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #30 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #31 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #32 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #33 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #34 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #35 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #36 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #37 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #38 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #39 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #40 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #41 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #42 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #43 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #44 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #45 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #46 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #47 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #48 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #49 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #50 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #51 0x7ff0cf8db839 in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:690\n    #52 0x7ff0cf8dc06a in dt_dev_pixelpipe_process_rec /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:815\n    #53 0x7ff0cf8e730f in dt_dev_pixelpipe_process_rec_and_backcopy /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:2147\n    #54 0x7ff0cf8e730f in dt_dev_pixelpipe_process /home/lebedevri/darktable/src/develop/pixelpipe_hb.c:2231\n    #55 0x7ff0cf8bbfd6 in dt_dev_process_image_job /home/lebedevri/darktable/src/develop/develop.c:343\n    #56 0x7ff0cf8afb88 in dt_dev_process_image_job_run /home/lebedevri/darktable/src/control/jobs/develop_jobs.c:40\n    #57 0x7ff0cf8a4ba2 in dt_control_run_job_res /home/lebedevri/darktable/src/control/jobs.c:188\n    #58 0x7ff0cf8a4ba2 in dt_control_work_res /home/lebedevri/darktable/src/control/jobs.c:434\n    #59 0x7ff0cbfc00a3 in start_thread (/lib/x86_64-linux-gnu/libpthread.so.0+0x80a3)\n    #60 0x7ff0c8a9604c in clone (/lib/x86_64-linux-gnu/libc.so.6+0xe604c)\nAddressSanitizer can not describe address in more detail (wild memory access suspected).\nSUMMARY: AddressSanitizer: heap-buffer-overflow /home/lebedevri/darktable/src/iop/demosaic.c:1175 vng_interpolate\nShadow bytes around the buggy address:\n  0x0c068003a3c0: fa fa 00 00 00 00 fa fa 00 00 00 fa fa fa 00 00\n  0x0c068003a3d0: 00 00 fa fa 00 00 00 fa fa fa fa fa fa fa fa fa\n  0x0c068003a3e0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a3f0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a400: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n=>0x0c068003a410: fa[fa]fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a420: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a430: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a440: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a450: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c068003a460: fa fa fa fa fd fd fd fd fa fa 00 00 00 fa fa fa\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07 \n  Heap left redzone:       fa\n  Heap right redzone:      fb\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack partial redzone:   f4\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Contiguous container OOB:fc\n  ASan internal:           fe\nThread T12 created by T0 here:\n    #0 0x7ff0cff43b0a in pthread_create (/usr/lib/x86_64-linux-gnu/libasan.so.1+0x23b0a)\n    #1 0x7ff0cf8a600f in dt_control_jobs_init /home/lebedevri/darktable/src/control/jobs.c:512\n    #2 0x7ff0cf89b88d in dt_control_init /home/lebedevri/darktable/src/control/control.c:317\n    #3 0x7ff0cf7f3f19 in dt_init /home/lebedevri/darktable/src/common/darktable.c:728\n    #4 0x400b6f in main /home/lebedevri/darktable/src/main.c:24\n    #5 0x7ff0c89d1b44 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x21b44)\n==26248==ABORTING\n```\n. @dtorop \nHere i can reproduce it with 100% reliability (each test reports that issue)\nI can reproduce:\n1. With VNG4 on X-Trans image - http://img.photographyblog.com/reviews/fujifilm_x100s/sample_images/fujifilm_x100s_09.raf [didn't tried other images]\n2. With VNG4 on Bayer image - http://www.rawsamples.ch/raws/canon/RAW_CANON_EOS_5DMARK3.CR2 [e.g., but it crashed on all images i tried]\n3. With Amaze on Bayer image\n\nCould the memory crash be caused by something outside of the VNG code -- due to the output buffer for 200% view being allocated too small?\nPPG for Bayer and all except VNG4 for X-Trans does not exhibit such crash, so i would say no.\n. @jwagner there should be a tarball with the following name: dt-noiseprofile-$(date +'%Y%m%d').tar.gz\nIt should contain pdfs that we use to check validity of the profile.\nDoes it still exist, and if it does, could you please upload it so that we can finally merge this?\n. Apparently, alternative version was merged manually by @hanatos: e384ea76491379d55836e6cc08a4337a8a09bcc3\n. After brief discussion with @hanatos, it was agreed that there is no point in having second version of noiseprofile (e.g. for future averaging) because it is extremely unlikely we will implement that.\nSo thank you for creating this noise profile, and i'm sorry for such a long wait.\n. It is X-Trans-specific, and nothing seems broken after quick test, so i'll merge it.\n. @Messie1 there should be a tarball with the following name: dt-noiseprofile-$(date +'%Y%m%d').tar.gz\nCould you please upload it so we can verify validity of the profile?\n. > As my answer don't show up in Github, I will send it to you this way, too. Please apologize any inconvinience. Matthias\n\nI received dt-noiseprofile-20141022.tar.gz from @Messie1 by e-mail:\nhttps://drive.google.com/file/d/0B0f1NIO0-n9AbEVObHRnY3V5TVowcjBVbVZhVGVBMHdLMEgw/view?usp=sharing\n. @mneumann \nWhat is the issue that you were trying to fix?\nMaybe you can show us compiler error message?\n. @mneumann \nWell, if using namespace std; in in exif.cc really works, then you should replace you commit with that.\n. @dtorop \nOne more issue: look at the very bottom of [rotated] image.\nWhen you move view, displayed area is bigger, and when you release, area \"jumps\" up, so very bottom of image is not visible, but only when zoomed-in.\nHere happens only on 200% zoom.\n. @dtorop \nFrom the testing i've done so far, i think, this fixes all symptoms of Issue 10025.\nSo, if this fixes all symptoms for you too, let me know and i'll merge and close ^.\n. Awesome work!\n. This breaks Linux build:\n[ 26%] Building CXX object src/CMakeFiles/lib_darktable.dir/common/exif.cc.o\n/home/lebedevri/darktable/src/common/exif.cc: In function \u2018int dt_exif_read_blob(uint8_t*, const char*, int, int, int, int, int)\u2019:\n/home/lebedevri/darktable/src/common/exif.cc:1182:32: error: call of overloaded \u2018isnan(const double&)\u2019 is ambiguous\n       if(!isnan(cimg->longitude) && !isnan(cimg->latitude))\n                                ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:32: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n          [ 26%] Building CXX object src/CMakeFiles/lib_darktable.dir/common/exif.cc.o\n/home/lebedevri/darktable/src/common/exif.cc: In function \u2018int dt_exif_read_blob(uint8_t*, const char*, int, int, int, int, int)\u2019:\n/home/lebedevri/darktable/src/common/exif.cc:1182:32: error: call of overloaded \u2018isnan(const double&)\u2019 is ambiguous\n       if(!isnan(cimg->longitude) && !isnan(cimg->latitude))\n                                ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:32: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:58: error: call of overloaded \u2018isnan(const double&)\u2019 is ambiguous\n       if(!isnan(cimg->longitude) && !isnan(cimg->latitude))\n                                                          ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:58: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc: In function \u2018void dt_exif_xmp_read_data(Exiv2::XmpData&, int)\u2019:\n/home/lebedevri/darktable/src/common/exif.cc:1772:22: error: call of overloaded \u2018isnan(double&)\u2019 is ambiguous\n   if(!isnan(longitude) && !isnan(latitude))\n                      ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:22: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:42: error: call of overloaded \u2018isnan(double&)\u2019 is ambiguous\n   if(!isnan(longitude) && !isnan(latitude))\n                                          ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:42: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\nsrc/CMakeFiles/lib_darktable.dir/build.make:322: recipe for target 'src/CMakeFiles/lib_darktable.dir/common/exif.cc.o' failed\nmake[2]: *** [src/CMakeFiles/lib_darktable.dir/common/exif.cc.o] Error 1\nCMakeFiles/Makefile2:1046: recipe for target 'src/CMakeFiles/lib_darktable.dir/all' failed\nmake[1]: *** [src/CMakeFiles/lib_darktable.dir/all] Error 2\nMakefile:133: recipe for target 'all' failed\nmake: *** [all] Error 2       from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:58: error: call of overloaded \u2018isnan(const double&)\u2019 is ambiguous\n       if(!isnan(cimg->longitude) && !isnan(cimg->latitude))\n                                                          ^\n/home/lebedevri/darktable/src/common/exif.cc:1182:58: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc: In function \u2018void dt_exif_xmp_read_data(Exiv2::XmpData&, int)\u2019:\n/home/lebedevri/darktable/src/common/exif.cc:1772:22: error: call of overloaded \u2018isnan(double&)\u2019 is ambiguous\n   if(!isnan(longitude) && !isnan(latitude))\n                      ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:22: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:42: error: call of overloaded \u2018isnan(double&)\u2019 is ambiguous\n   if(!isnan(longitude) && !isnan(latitude))\n                                          ^\n/home/lebedevri/darktable/src/common/exif.cc:1772:42: note: candidates are:\nIn file included from /usr/include/features.h:374:0,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/os_defines.h:39,\n                 from /usr/include/x86_64-linux-gnu/c++/4.9/bits/c++config.h:430,\n                 from /usr/include/c++/4.9/iostream:38,\n                 from /home/lebedevri/darktable/src/common/exif.cc:27:\n/usr/include/x86_64-linux-gnu/bits/mathcalls.h:234:1: note: int isnan(double)\n __MATHDECL_1 (int,isnan,, (_Mdouble_ __value)) __attribute__ ((__const__));\n ^\nIn file included from /usr/include/c++/4.9/random:38:0,\n                 from /usr/include/c++/4.9/bits/stl_algo.h:66,\n                 from /usr/include/c++/4.9/algorithm:62,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/lebedevri/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.9/cmath:626:3: note: constexpr bool std::isnan(long double)\n   isnan(long double __x)\n   ^\n/usr/include/c++/4.9/cmath:622:3: note: constexpr bool std::isnan(double)\n   isnan(double __x)\n   ^\n/usr/include/c++/4.9/cmath:618:3: note: constexpr bool std::isnan(float)\n   isnan(float __x)\n   ^\nsrc/CMakeFiles/lib_darktable.dir/build.make:322: recipe for target 'src/CMakeFiles/lib_darktable.dir/common/exif.cc.o' failed\nmake[2]: *** [src/CMakeFiles/lib_darktable.dir/common/exif.cc.o] Error 1\nCMakeFiles/Makefile2:1046: recipe for target 'src/CMakeFiles/lib_darktable.dir/all' failed\nmake[1]: *** [src/CMakeFiles/lib_darktable.dir/all] Error 2\nMakefile:133: recipe for target 'all' failed\nmake: *** [all] Error 2\n. @mneumann @parafin \nI merged and fixed Linux build after that.\nPlease verify that BSD and OSX builds are fine now.\n. And which glitch is that?\nAfter a quick test, i still see some \"jumpiness\" of zoomed-in image in DR even with this PR.\n. @upegelow\nOk, i did not though about such issue because there already was common.h (so i thought it was fine).\nSo in other words, as i understood it: if header is changed, but *.cl that includes it is not, *.cl will not be recompiled., correct?\nIf so, i have a possible solution: in each *.cl, replace#include \"*.h\"with content of *.h atcmake installstep.\nWhat do you think about it?\n. I do not think this breaks anything, so unless there is any comment, i'm planning on merging this in +~24h\n. @Beowulf0\nYou did something wrong, my commit 063cc7693d71db71aab4d8e0a3b31b7a7c746b3e is not supposed to be in this PR (65adfe8).\n. Alright, i guess it's time..\n@Beowulf0 \nThank you for your contribution!\nHowever, we have no means of checking the validity of the these custom base/tone curves, and we do not think it's a good idea to merge them as is, because IIRC we have already seen broken curves.\nOnce we do, we will announce it.\n. We'll assume this pr is superseded by #759\n. That should help with old mipmaps, yes, but are you sure?\nI have already asked @hanatos about this explicitly, and he said that it is not needed (or at least this is how i interpreted the transfer).\nSame part from IRC log:\n<LebedevRI> hanatos: hello. i have a question about on-disc mipmap cache, struct dt_mipmap_buffer_dsc and DT_MIPMAP_CACHE_FILE_VERSION\n<LebedevRI> in short, after each change to struct dt_mipmap_buffer_dsc, DT_MIPMAP_CACHE_FILE_VERSION should be bumped, right?\n...\n<hanatos> LebedevRI: that's about the incompatible thumbnail caches?\n<LebedevRI> yes\n* markus-j (~markus-j@p54AD0F59.dip0.t-ipconnect.de) has joined\n<hanatos> it's my impression we write only some individual metadata as well as jpg thumbs/dxt compressed thumbs\n<hanatos> so that struct should not end up on disk\n<hanatos> the version is about the file\n<hanatos> did you test without bumping whether it still works?\n<hanatos> i think it should\n<LebedevRI> when i have initially read that code (before changing dt_mipmap_buffer_dsc) i was under the impression that dt_mipmap_buffer_dsc is not writen no disc\n...\n<hanatos> so why did you bump the version?\n<hanatos> anything else i'm missing there?\n<LebedevRI> i did not bump version, i changed  struct dt_mipmap_buffer_dsc\n<LebedevRI> and yes, old mipmap are working fine here (compression = slow) :/\n...\n<hanatos> so but why was pobry's mipmap cache invalidated then? another issue?\n<LebedevRI> that is a really good question indeed\n* hanatos pulls and loads some old images\n<hanatos> i don't think mine was invalidated recently\n<hanatos> nope, i have old thumbs\n<LebedevRI> are you thums compressed (squish) or uncompressed\n<LebedevRI> ?\n<hanatos> ah. uncompressed\n<hanatos> but is that the reason?\n<LebedevRI> i'm not sure. i can not trigger not cache invalidation nor squish crash\n. @hanatos, @pmjdebruijn are okay with this, @houz does not veto.\nSamples were studied (i and @hanatos), and there is no reason for \"blue mapping\" to stay alive.\nIt does not fix issues like this, yet gamut clipping does fix them.\n. @boucman because it is not guaranteed to be same across all compilers and systems.\n[18:16:41] <houz> LebedevRI: are you positive that PATH_MAX is the same on all systems and across compilers? keeping the library with its presets should be possible\n[18:17:30] <bremner> some systems don't define PATH_MAX\n[18:18:44] <bremner> for example: https://buildd.debian.org/status/package.php?p=darktable&suite=sid\n[18:18:56] <bremner> whether you care about such systems is another question.\n[18:20:00] <houz> for those systems we could define it ourselves\n[18:20:27] <houz> but if it ever changes, even across compilers or systems, it will break the db\n[18:20:33] <houz> and possibly make dt crash\n[18:21:43] <houz> LebedevRI: you have to adapt params_size, or change legacy_params to omit the pointer, too\n[18:22:09] <houz> pointers should never be part of params, as those can change in size, too\n[18:22:47] <LebedevRI> for linux as far as i can tell it is defined in /usr/include/linux/limits.h, so i do not think it is a subject to change\n[18:23:52] <houz> but is it part of any standard? or can it differ between bsd, osx, linux, ...?\n[18:24:02] * houz doesn't like depending on opaque system defines\n[18:28:59] <LebedevRI> apparently no, it can be different for different systems, e.g. bsd has 1024 - http://lists.freebsd.org/pipermail/freebsd-bugs/2013-November/054530.html\n[18:29:19] <houz> then i would not make the params size depend on it\n[18:29:32] <houz> using it at runtime is fine, but not for data structures that are passed along\n[18:30:25] <LebedevRI> ok, then i think i'll substitute it with 4096\n[18:30:35] <houz> fair enough\n. @boucman again no, because i have used PATH_MAX only in runtime(as far as i an aware), and in there, any PATH_MAX value will be fine.\n. @McBofh\nThank you for your input, but\n1. 4096 is still better than any constant, even defined by standard.\n2. I have no information on the following subject: \"will or will not be DT used on systems that do/do not claim adherence to IEEE Std 1003.1(2004)\"\n@kanru\n\nHowever, for application and kernel robustness, it's actually much better to have fixed limits as long as they're sufficiently large (as the Linux limits are).\n\nI don't see how that would help with binary compatibility issue - if PATH_MAX/pathconf(\"/\", _PC_PATH_MAX) will change at some point, old presets (created with different PATH_MAX) will break.\nNot even saying about stack vs. heap allocation due to PATH_MAX vs. pathconf(3)\n. @boucman\nI do not really like it (easy to break everything with 1 change), but done.\nCode looks a bit cleaner.\n. @bocadillodeatun ATM - no. it is being run sometimes (1-2 times/year).\nI'm hoping, someday \"./tools/beautify_style.sh\" will be part of pre-commit hook (or something else).\n. It looks ok.\nIn the future maybe i'll redo it, but for now it is good enough.\n. What will happen in some rare cases of really small input images and big radius values?\nSome other iops do have this special case handling: (from sharpen.c)\n// special case handling: very small image with one or two dimensions below 2*rad+1 => no sharpening\n  // avoids handling of all kinds of border cases below\n  if(roi_out->width < 2*rad+1 || roi_out->height < 2*rad+1)\n  {\n    memcpy(ovoid, ivoid, (size_t)sizeof(float)*ch*roi_out->width*roi_out->height);\n    return;\n  }\n. library.db from my DT version compiled from git master have a format field, but not a isldr.\nI'm guessing, isldr was renamed to format after 1.4, which you are using, and that is why you see that it fails for you.\n. After merge, if this causes too many issues, it is to be reverted.\n. @hanatos @upegelow if no new regressions were found, i think it is time to merge to extend testing coverage.\n. @upegelow with lens iop, in preview (DR) only, i sometimes see some garbage pixels outside of the image.\nI do not see them without OpenCL. Without this PR, i do not see them at all.\n\n. Git tip: since you have fix in a new commit (and even if you would have squeezed those 2 commits into 1), there was no need to close old PR and open new one.\n. Was merged manually by hanatos: f3d635228aa256b384d7f05e254fb6e97a0145ea\n. Ok, we'll assume this pr has superseded #675\nBut it needs to be rebased ontop of master\n. @upegelow could you take a look please?\n. @upegelow any iop before demosaic that has uniform blend mode. so right now \"raw denoise\" is the only one affected\n. @upegelow maybe overflow of 3*sizeof(float) after buffer is not sufficient to cause segfault.\nBuild with AddressSanitizer, and it will show you same output as i put into the commit message of 37590880d898006044bbbc4fc3c32c38949b4775\nMy build command: LDFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CXXFLAGS=\"-fsanitize=address -fno-omit-frame-pointer\" CC=gcc CXX=g++ cmake -DUSE_OPENCL=OFF ../ && make -j9 && sudo make -j9 install && darktable\n. @upegelow re \"blend mode \"difference\" in raw denoise with an opacity of 100%\" confirmed.\nI'll look at those problems...\n. @upegelow well aparently all that is happening because all blend* functions jump 4 float's:\nhttps://github.com/darktable-org/darktable/blob/master/src/develop/blend.c#L788\nso for raw, only 1 in 4 rows(columns?) will be processed.\nIf i replace that 4 with 1, it looks correct.\nSo i will probably need to come up with a way to pass piece->colors into blend* and use it instead of 4.\n. @upegelow agreed, but that will require much more changes to the code, but it might be a bit faster, so it will have to happen after 1.6.\nFor now, i did a minimal version - put cst,stride and ch into a strut and pass a pointer to it instead of passing each of those values.\nIt appears to fix all 3 issues you have pointed out.\nPS: without this(git master), with blend mode \"difference\" in raw denoise with an opacity of 100% and some mask, i get extremely distorted mask:\n\n. @upegelow thank you!\n. @levitte and what is that flaw?\nThat it crash on those filmrolls with NULL folders?\n. Second commit looks like a new feature to me, so i would say that second commit should wait for post-1.6\nThough, first commit is a cleanup + bugfix, so it might land before that. (except src/iop/rawdenoise.c part, which looks like should be a part of that second commit)\n. @upegelow i tested first commit a bit more, and it fixes those thumbnail issues i was having (see https://github.com/darktable-org/darktable/pull/624#issuecomment-49007480) with https://github.com/LebedevRI/darktable/tree/iop-temperature-mi-blending !\n. This should fix Feature #10128: Support for HiDPI displays on OS X OS X\n. @imarsv you forgot to update Last-Translator and Project-Id-Version in po/ru.po\n. I don't like it.\nPreviously, for example, i was able to enable some watermark by default when editing images, and then, if i need different watermark / do not need watermark at all, i was able to apply style with different watermark / disabled watermark. And this PR will break that workflow.\nIf this new behaviour is indeed needed in some cases (i'm not saying it is not), there needs to be some way to switch between this two behaviours, either like in history stack module: combobox: append / replace, or, as discussed in #732 (see also: feature reques #9779)\n. Alternatively, i would have thought about moving\nint max_width, max_height;\n  int width, height;\n  char style[128];\nout of that structs.\nThough i'm not sure if that makes 100% sense, and if it is doable.\n. Well, dt_imageio_*t are still changed, and i do not see any changes to DT_MODULE()/legacy_params(), so i think it still breaks presets.\n. No further notes from me.\nBut maybe someone else has something to say?\n. It _might also fix my issue #9984\n. @pmjdebruijn we discussed that on IRC with him before this PR, i did told him to do only Amber-Blue scale, not Green-Purple.\n. @CaptainSifff as i have already said, you must also provide PDF's that were generated gen-profile script.pt.\n. [17:29:46]  LebedevRI: I'm fine with ignoring the changes to the scripts. Since the pictures are essentially the same, the numbers almost don't change. I just thought I'd share this change.\n[17:38:11]  CaptainSifff: so, that specific noiseprofile was averaged or not?\n[17:38:25]  It was averaged.\n. Was merged manually: 69cd74636d9e7bab95641d81221c8d99474b6457\n. Since we are already in freeze, it definitely won't be merged at least until after 2.0 release :(\nAs for confirmation, you'd need to \"stalk\" :) us in IRC channel some time after 2.0 release, so that it does not get forget...\n. We really must merge this PR before next major release :)\n. Looks good to me, but i agree with @hanatos\nThere must be another way, to just completely skip redrawing when we are not ready to draw.\n. I have looked at other approaches to fixing this issue, and i do not think i can do anything workable right now, although i do believe i know how to fix it.\nSo yes, @upegelow rebase and we'll merge it as it is for now.\n. Looks better than now, does not seem to break anything.\n. I have cherry-picked relevant changes that seem fit to me in 2cb86dfd8f942ebf9d120a725abd6b6ab82be07d.\n. To be rebased.\nIMHO, while proposed version looks a bit better in some parts, in other it looks even worse.\n\n\n. Regression: tooltips now look different.\n. @TurboGit lib/iop preset menu is severely regressed too.\nIf this is not fixed soon, i'm reverting.\n. @TurboGit\nI have said preset. That is completely unreadable to me:\n\n. Debian sid, gtk+-3.14.5\n$ ls -lah ~/.config/darktable/darktable.css\nls: cannot access /home/lebedevri/.config/darktable/darktable.css: No such file or directory\nIf i change gtk theme, that unreadable text color/bgcolor changes, so you are clearly not overriding enough colors from theme defaults.\nIf i revert 6233506d62f12441a528881cdda9c7649bb7710e, that preset menu always looks the same, no matter the gtk+ theme, so it is a regression.\n. Preset menu seems to look as before 6233506d62f12441a528881cdda9c7649bb7710e.\nNot sure we like that tooltips now have a solid white double outline.\n. @TurboGit settings look wrong too.\nI strongly suggest you to look at ALL widgets and make them look as they were.\n. @TurboGit That didn't fix all the buttons, e.g. the ones in lens iop are still not flat.\n. @TurboGit sure, i have already shown it in IRC, but not here: (summary on Sheet3)\nhttps://docs.google.com/spreadsheets/d/1vwkMtgfxHLwwsZjJlE7mloq2yHPeiflhnKOwns0hydI/edit?usp=sharing\nThat was loading of 44 biggest jpeg thumbs from new cache.\n. Hope that does not break too many things.\n. For the record, i highly do not like this at all.\nI vote for just dropping fb export.\n. So is there another way?\n. What about this PR?\n@mazhe Are the changes still needed?\nIf yes, could you please update the pr?\n. @pedrocr No, that is not an issue with defaulting to the user supplied matrices.\nExactly the same thing happens if one used ICC within colorin/colorout, and then that ICC is gone - no message that it is gone, matrix is silently used.\nSo this argument is wrong.\n. > We don't ship ICC profiles but we do ship standard matrices and sometimes user submitted ones.\nYes.\n\nBy starting with just a standard matrix and later adding a user submitted one we change the default \n\nAgain yes.\n\nwithout warning the user.\n\nThat is the problem, IMHO we maybe should refuse to load that image, like when history stack item is newer than the iop version.\n\nWe don't do the same with ICC profiles since users have to actively enable those.\n\nWhat happens with ICC's:\nSteps to reproduce: \n$ mkdir -p ~/.config/darktable/color/in\n$ cp /usr/share/dispcalGUI/presets/resolve.icc ~/.config/darktable/color/in    (use any ICC)\n$ select that ICC in colorin\n$ rm ~/.config/darktable/color/in/resolve.icc\n$ start dt, image looks different, the only messages are on console:\n[colorin] could not find requested profile `resolve.icc'!                                                                                                                                                                        \n[colorin] could not find requested profile `resolve.icc'!\nTell me, how is that different from what happens with matrices?\n. > In the case I'm describing the standard matrix is always there, you've just silently changed the default for new images without the user noticing.\n\nSo users may be used to the output with the standard matrix, upgrade to a newer version of darktable with a user supplied matrix and find that their new images now look different than the older ones without any warning. That seems quite user-unfriendly.\n\nUgh, well, of course, i have missed the word new in there :)\nI have read that as if we were changing the user-selected standard matrix to enhanced matrix in already-created history stacks.\n. Please do not merge until i remove that flag.\n. Tested, i think i really like it.\n. Indeed we don't, but there is still some outdated || invalid || legacy code that is not being built that looks like a wrapper for gegl.\n. Apparently that was committed in 12bfa75b04ca2afa49f76fc13eee243f8654ee49, eaf2428a8b22be6f5f43e3464b93e9aa8c48ef72 and 30bb4cfd0abad177ae8c54988ee8ebe68d56acc8.\n. @upegelow ok, thanks for your opinion!\nI have redone PR, and this is how i think it'll get merged.\n. Yeah, not sure about that.\nI have previously looked into travis-ci.org, and i wasn't convinced about doing it.\nPlus, they have rather old compiler versions, so it really wasn't interesting.\n. @sieben lighttable?\nOn a local jenkins instance, i do a semi-daily builds of master and current stable branch (darktable-1.6.x ATM) with gcc-4.6 through gcc-4.9 and clang-3.4 through clang-3.7 in all 3 build types (release, relwithdebinfo, debug)\n(and, there is git master build by openSUSE OBS)\nSo locally, we're more or less covered...\n. Just wanted to point out that in the end it was implemented.\nDo not know whether we will keep it or not, but so far looks okay-ish.\n. @edgomez well, in git master, in hq case, rescaling happens after the pipe, and gamma is applied at the end of the pipe.\nWith this PR, the order of modules will be following:\n1000 gamma\n983 dither\n967 watermark\n951 borders\n935 finalscale\n919 overexposed\n...\nIn other words, gamma will always be applied after rescaling.\n. Though, i should add that in git master, \"after-pipe scaling\" is only done after dt_dev_pixelpipe_process_no_gamma() call, which means, the data is not gamma-corrected in the first place.\n. I must say, personally, i'm not convinced about this yet.\nWhat about performance penalty? Any measurable difference?\n. Why isn't this merged yet? What is missing, a review?\n. @bronger\n\nI actually don't like all those \"auto\" all over the place very much. They provide no information.\n\nI partially agree, but unfortunately, i do not see any other meaningful way to represent \"use autodetected or manually set value\" (redmine 10425), which is widely requested feature and actually is the biggest goal here...\n\nAlso, if automatic correction is unavailable, the respective selection should be \"off\" instead of \"auto\". \n\nHmm, not sure.\nThough, i guess it can be done with simply checking that e.g. lens->CalibTCA is not NULL in reload_defaults()\n\nIf you switch scaling to \"manual\", the starting value is 1 (or the latest manual factor) instead of the\nlatest autoscaling value. I think it is more comfortable to have the latter.\n\nMakes sense, will bring back old functionality.\n. @bronger yes, it does, that is the point.\nWithout explicit \"auto/manual\" switch, there is no way for a user to say: i want to use autodetected camera, but e.g. lens = $(manual samyang lens that does not show up in EXIF) and focal = 24.\nMaybe i have misunderstood your initial comment, weren't you talking about all of the \"auto\", but only for TCA/etc?\n. Some other time.\nI guess it will be more of cp src/iop/lens.c src/iop/lensfun.c, and then adding support for all the lensfun's new shiny features (perspective correction, rotation).\nAnd then rewriting scary src/iop/clipping.c as just cropping.c (i.e. with just the crop tool)\n. @jktjkt\n\nCherry-picking jktjkt@8ef272e (with a better error message) is probably a good idea for portability, though.\n\nDone: 7cfd53ae861e42b6671ab963e595b76dc7336fd7\nThanks for pointing those out.\n. Since this turns all of the partial matches we currently have into proper matches, it regresses all those history stacks for those cameras that are currently are partial matches.\nTherefore, it should not be merged as-is right now, but instead it is a part of more generic fix, and should be merged at the same moment as the other parts of the fix.\n. @markfeit \n\nIdeally, which of the built-in ratios included in the menu would be a configuration item and the user could add custom items directly from the UI and have them stored in the per-user config. Maybe I'll take that on as my next project.\n\nYou can already do that: ae36f035e1496b8b8befeb74ce81edf3be588801\n. Gcc-4.9, Debian sid:\n[ 26%] Building C object src/CMakeFiles/lib_darktable.dir/control/jobs/control_jobs.c.o\n/home/lebedevri/darktable/src/control/jobs/control_jobs.c: In function \u2018dt_control_export_job_run\u2019:\n/home/lebedevri/darktable/src/control/jobs/control_jobs.c:996:11: error: \u2018stderr\u2019 not specified in enclosing parallel\n           fprintf(stderr, \"image `%s' is currently unavailable\", imgfilename);                                                                                                                                                 \n           ^\n/home/lebedevri/darktable/src/control/jobs/control_jobs.c:943:9: error: enclosing parallel\n #pragma omp parallel default(none) private(imgid)                                                            \\                                                                                                                 \n         ^\nsrc/CMakeFiles/lib_darktable.dir/build.make:1242: recipe for target 'src/CMakeFiles/lib_darktable.dir/control/jobs/control_jobs.c.o' failed                                                                                     \nmake[2]: *** [src/CMakeFiles/lib_darktable.dir/control/jobs/control_jobs.c.o] Error 1                                                                                                                                           \nCMakeFiles/Makefile2:864: recipe for target 'src/CMakeFiles/lib_darktable.dir/all' failed                                                                                                                                       \nmake[1]: *** [src/CMakeFiles/lib_darktable.dir/all] Error 2                                                                                                                                                                     \nMakefile:137: recipe for target 'all' failed                                                                                                                                                                                    \nmake: *** [all] Error 2\n. Also, wrong branch - it should be master, not some darktable-z.y.x\n. So, aside from those 2 caveats i noted in the first comment, this should be all good...\n. Only cache issue is left, but it is not obvious what is the best way to handle it...\n. \n\n. Ok, so:\n- The cache issue is still there\n- It is not obvious why WB is actually needed there\n- There are only handful of users for this feature\n=>\n1. I will merge it as it is\n2. We will not be giving our traditional \"guarantee\" that this will produce the same output in the future. (It might be even dropped entirely)\n3. Cache issue should still be fixed, if anyone knows how :)\n. @boucman initially that was said by @pmjdebruijn, i have no real opinion here\nThough, right now i do not see what could get changed so that the output will be different. (for export at least)\n. Something is wrong about this PR WRT rebasing - there shouldn't be e.g. my commits.\n. I really do not like using dt_conf_get_* ()/dt_conf_get_set_() there.\nAlso, you need to add set default values for those new dt_iop_watermark_params_t fields in init(), and just use those in gui_init().\n. Also, gui_update() needs to display all those values stored in p.\n. Comment https://github.com/darktable-org/darktable/pull/936#issuecomment-115343040 is still valid.\n. Tested with cups-pdf, printing from DT seems to be [still] working fine.\nOne thing missing IMO - the only indication that i did press \"print\" button is the output of -d perf, there is no visual confirmation like with normal export.\n. At this point i* can not find anything anything obviously wrong here.\nSo i guess, looks good to me.\n. Do not know if upgrading is the solution we want to enforce here, but in any case it really should not cause a build-failure.\nIf it is, then CMake should disable printing if version is too old; if it is not, such code should be #if'ed, like in dt_get_papers()\nJust my opinion.\n. Tested, better than no message.\nIs this WIP or it can be merged?\n. Yes, there are certainly big issues with altitude data from GPS.\n(One could also remove  elements from track, and use some software to get somewhat more accurate data out of DEM/STRM, i belive gpsprune can do that)\nWhy i want it to be in dt is because if dt_control_gpx_apply_job_run() does not store it, the other way to get it into EXIF would be to re-run geotagging on exported images, and that would be tedious.\nSo yeah, questionable stuff, but IMHO it is better to do it than do not.\n. Fixed.\n. [13:41:58] <LebedevRI> hey. so about that jobs fixes, any changes?\n[13:46:57] <houz> looks good now\n[13:50:02] <LebedevRI> can it be merged?\n[14:05:48] <houz> i'd say yes\n. I'll merge, though i'm pretty sure that it is not the last function that lacks format attribute.\n. Seems to be fine on debian sid.\nThis is not exactly required, but is really nice:\n```\nFrom 839f8638adee10ce5712ac5b320bd1abfc1bc7a5 Mon Sep 17 00:00:00 2001\nFrom: Roman Lebedev lebedev.ri@gmail.com\nDate: Sat, 11 Jul 2015 19:06:36 +0300\nSubject: [PATCH] If pugixml.hpp is not a local header anymore, s/\"\"/<>/\n\nsrc/external/rawspeed/RawSpeed/StdAfx.h | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\ndiff --git a/src/external/rawspeed/RawSpeed/StdAfx.h b/src/external/rawspeed/RawSpeed/StdAfx.h\nindex 14da93e..94b91b1 100644\n--- a/src/external/rawspeed/RawSpeed/StdAfx.h\n+++ b/src/external/rawspeed/RawSpeed/StdAfx.h\n@@ -96,7 +96,7 @@ extern \"C\" {\n #include \n using namespace std;\n-#include \"pugixml.hpp\"\n+#include \n #include \n//My own\n2.1.4\n```\n. +1, so far no one has come up with a real issues this would cause.\n. @pedrocr \nThis should be noted in https://github.com/darktable-org/darktable/blob/master/src/external/rawspeed/update_rawspeed.sh\nAside from that let's merge.\n. I would personally say that it is a bug in whatever font and/or rendering engine that fail to render it correctly.\n. I guess we decided to keep combined cyrillic letters, no point in keeping this open.\n. I recommend reading some manuals, e.g. https://help.github.com/articles/syncing-a-fork/\n. Ok, bad karma: here i come :)\nTl;dr: join irc.freenode.net, channel #darktable and talk to us.\nhttp://article.gmane.org/gmane.comp.graphics.darktable.devel/6920/\n```\nSo, what exactly do we mean by a maintainer?\n0. Be actively involved with darktable for some time.\n< CURRENT SITUATION: pr #1086, well, not nope. >\nAt least half a year.\n< CURRENT SITUATION: nope >\nThat means:\n) Stick with us in IRC.\n< CURRENT SITUATION: REALLY BIG NOPE* - really important point. >\n) actually know the code.\n) actively examine bugreports, fix bugs.\n1. Be reliable and trustworthy [over that time], and more importantly,\nmake us believe in that.\n```\nGuys, just force-feeding some random diff into us will not work.\nEven https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md says that you need to talk to us :(\nAs for $indows-related changes: my mail was 100% correct: until those conditions are met, NOTHING will happen.\nAnd that includes even the changes that are needed to make dt compile on that [currently unsupported] platform.\nBecause they are the changes to help building on unsupported platform.\n. What does that flag change actually change?\nNote: it is likely to \"break\" presets for such 32-bit tiffs due to the fact that now they will be HDR and not LDR.\n. @mgehre\nMy comment is valid.\nReproduction:\n1. Choose image\n2. Discard it's history stack\n(assuming there is no additional auto-appliable presets besides defailts)\n3. Open image, last operation in history stack is base curve\n4. Dramatically change base curve, e.g. make it look like f(x) = 0.0\n5. Compress history stack (!)\nNow, in DR your image looks completely black\n6. Switch to LT -> LT thumbnail for that image did not change, it is not completely black.\nI do like the idea behind this PR though...\n. @mgehre thanks for looking into it, but given https://github.com/darktable-org/darktable/pull/959#issuecomment-136349295, and no activity, i guess it is best to close this for now...\n. The night (4 hours) from saturday to sunday can not be expected as a sufficient window to let others view the changes and leave comments.\nDid this actually get reviewed by someone?\n. @kwokyinc http://redmine.darktable.org/projects/darktable/issues/new + attach dt-noiseprofile-20150812.tar.gz\n. @kwokyinc Thank you.\nIf you have any more cameras without noiseprofile, feel free to profile them :)\nHowever, the version from http://redmine.darktable.org/issues/10783 was merged...\nI guess this was simply forgotten.\nAs per https://github.com/darktable-org/darktable/pull/637#issuecomment-63232344, i'll just close this...\n. Also, in the beginning of dt_control_delete_images_job_run():\nsnprintf(message, sizeof(message), ngettext(\"deleting %d image\", \"deleting %d images\", total), total);\nThat should also depend on \"send_to_trash\" setting.\n. @beedaddy well, yes, certainly looks better to me, BUT.\nNow i do not like that we pass some version, and then use a magical number (5.3).\nMaybe it is better to pass 5.3 too, or compute it from 5.2...\n@boucman what do you think?\nThough, maybe i'm just too picky :)\n. Notes fixed.\n. As @houz said in IRC, we definitely want @hanatos to look at it.\n. How does this relate to Redmine issue #10682 ?\nDoes it fix it?\n. @edgomez \nHint: adding e.g. \"Fixes #10682\" into PR name or commit message would automatically fix the issue when that commit hits git master.\nPlease close that bug as fixed if this indeed fixed it.\n. I haven't thoroughly reviewed this, but the changes do look sane to me.\n. BTW, have you reported this upstream (probably to llvm)?\nWhat do they say?\nThis is most likely the same as with FreeBSD, though.\n. @parafin yes, i'm pretty sure that with all standard clang's from Debian, this works just fine.\nProbably, as that upstream bug suggests, because they link to (use) libgcc, so this is even worse than just simple \"disable if apple or freebsd\"...\nSomething for ./configure to check i'd say, but no idea if CMake can do it.\n. I can be totally wrong, but:\n(compiled dt with CC=clang-3.7 CXX=clang++-3.7 cmake ../)\n$ ldd /usr/local/bin/darktable | grep gcc\n        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f86456ca000)\n$ nm -D /lib/x86_64-linux-gnu/libgcc_s.so.1 | grep -i cpu\n0000000000002c30 T __cpu_indicator_init\n0000000000215910 B __cpu_model\nMy though:\nOn FreeBSD and OSX, i think, clang does not use gcc, thus does not link to libgcc_s.so.1.\nAnd since the required runtime support isn't currently in compiler-rt, it only exists in libgcc right now for the appropriate platforms,  when clang is self-contained, we have that issue.\nI.e. if we compile self-contained clang on linux, we will get the same issue, AFAIU.\n. My idea would be to add some obscure check to cmake that would compile that testcase, run it, and see whether we get Undefined symbols when running it.\nAnd based on that, add some define and check that define similarly to proposed changes.\nBut this might be too obscure.\n. I'm not seeing any critique to my cmake suggestion, so.\n@pope if you want, please try to implement the approach i have suggested in previous comment.\nThat stupid defined(__clang__) && (defined(__FreeBSD__) || defined(__APPLE__)), while it works, is not cool and does not cover all cases.\n. @dumbbell please check whether this works for you.\n. Why it should not be switched at 1s:\n| actual in-camera setting | displayed as |\n| --- | --- |\n| 1/4 | 1/4 |\n| 0\"3 | 1/3 |\n| 0\"4 | 1/2 |\n| 0\"5 | 1/2 |\n| 0\"6 | 1/2 |\n| 0\"8 | 1/1 |\n| 1\" | 1\" |\n. Looking at the commit that introduced that code, 5dce13102d41e3ab85a5c88559cbfc85c0ad8be5, i'm not even sure why it was changed to not touch existing entries...\n. /*!\n          @brief Add an Exifdatum from the supplied key and value pair.  This\n                 method copies (clones) key and value. No duplicate checks are\n                 performed, i.e., it is possible to add multiple metadata with\n                 the same key.\n         */\n        void add(const ExifKey& key, const Value* pValue);\nI see..\n. Not sure whether it's still needed with 01adb9eb2992cb8d91ab6edf0d34e3d6e673d7ae?\n. It might be a really bad approach, but if we really need, i guess we could just import https://github.com/Kitware/CMake/blob/master/Modules/GNUInstallDirs.cmake into https://github.com/darktable-org/darktable/tree/master/cmake/modules ?\n. @berniyh a rebase on top of current git master is definitely in order. and then please double check all the cmake code, so that all the cmakefiles is updated. \nI did not thoroughly review it, but i do like it.\nHaving (and using) some common ground (GNUInstallDirs) is good.\nAnd not using it just because it bumps cmake dependency from 2.6 would be just strange, 2.6 is rather old, just like 2.8...\n. @parafin those RPATH changes, are they ok with you, or does the RPATH needs to be apple-specific?\n. @berniyh otherwise looks good.\nI'll wait for @parafin's confirmation and merge.\n. @berniyh \nDon't bother :)\ndt does not compile there, not without patches anyway\n. @berniyh from irc:\n[00:32:39] <LebedevRI> parafin: thank you for looking at the pr\n[00:33:19] <parafin> LebedevRI, np\n[00:33:59] <parafin> when special handling for apple is brought back you can merge\n[00:36:23] <LebedevRI> $ORIGIN and @loader_path is some kind of ld variables? i wonder if $ORIGIN can be replaced with some $ORIGIN2222 which is either $ORIGIN or @loader_path\n[00:36:56] <LebedevRI> s/$ORIGIN2222/${ORIGIN2222}/\n[00:38:11] <parafin> yes, $ORIGIN and @loader_path are for interpretation by loader\n[00:38:37] <parafin> ${ORIGIN} is a good idea\n[00:38:39] <LebedevRI> i'll copy-paste that as a comment then\n[00:39:21] <parafin> though just ORIGIN as a name will be easy to confuse\n[00:40:55] <parafin> smth like ${ORIGIN_PATH} would be better\n. Okay, thank you!\nSeems to work fine here, let's see what more obscure distros broke :)\n. For future reference, to point packagers at: (from darix, from opensuse dt.spec)\n-DCMAKE_INSTALL_DATAROOTDIR=\"%{_datadir}\" -DCMAKE_INSTALL_LIBDIR=\"%{_lib}\" \n and %{_lib} is the *relative* path to prefix\n. Which sidepanel size?\nIIRC it looks just fine on default 350 width\n. > I rely on calculations done in modify_roi_in (x_scale and y_scale) for process (should be fine as that's always run after) but also for the transforms. Is that ok or can the transforms be called before modify_roi_in?\nI think (better check yourself) clipping.c (crop & rotate) also does that, so i guess it is fine this way.\n\ncommit_params had a strange pattern where the data being copied was the params passed to the function but for the piece->enabled test self->params was being used. I used self->params for everything but maybe that's wrong?\n\nDo not understand the question.\nIn commit_params(), everything is fine.\n\nI now use a dt_iop_scalepixels_data_t that isn't just an alias for dt_iop_scalepixels_params_t since I need to keep around x_scale and y_scale. Hopefully there are no mistakes in that code\n\ni'm pretty sure i have used dt_iop_scalepixels_data_t where need, and i do not see any wrong(params instead of data or the other way around) usage.\n. @pedrocr \nAside from these two notes, I see no obvious issues.\nI also do not have time/interest in extensively testing this side case of a iop.\nSo if you honestly believe it's good to go, feel free to merge it yourself :)\n. Random thought:\nOh, and while we are at it, maybe we should add \"CONTRIBUTING.md\" file that is automatically shown on \"Create new PR\" page.\nNot sure we need it, but maybe something \"have you talked to us first, before doing all this work?\" :)\n. @simonspa: @boucman had a question about wordpress part of #1012 \n. > Remove the old auto mode\nThat was kind of planned, and is possible once i finally implement area selection.\nThough, (a while back) i think @boucman wanted to still have the old auto mode.\n\nAdd the option for deflicker to only sample a given area of the image\n\nDefinitely on my todo.\n\nRemove the mode selection at the top of exposure and instead have the following options:\n\nThat is how it was initially implemented, and it was horrible. Really do not want to go back to that \"UI\".\nTry some commit before fd134a7a8a67ff476c7665bdddd56664b33487d8\n. > Remove the old auto mode\n\n(it produces the same results as setting deflicker to 0EV and adjusting the percentile slider to 100%-\"clipping threshold)\n\nWithout checking, i think only for images with zero clipping.\n. @upegelow please do note that i have removed \"histogram of\" selection.\nI'm sorry to change ui this late, but it was needed. Now i'm reasonably confident that we can release this feature.\n. Also, we do not expect to actually configure anything in darktableconfig.dtd\nAnd ${CMAKE_CURRENT_SOURCE_DIR} != ${CMAKE_CURRENT_BINARY_DIR}\nSo i'm not sure there is a point in renaming darktableconfig.dtd -> darktableconfig.dtd.in\nAnd please add COPYONLY.\n. @bronger \nCould you please add a bit more context?\nDoes this fix some issue with lens lookup?\nWith default lens autodetection?\nIs this something we should want in 2.0, or it should wait for 2.1?\n. Okay I hope this does not cause any regressions :)\n. legacy_params() is missing\n. Ok, haven't tested or anything, but since we are still in feature freeze, it will have to wait for 2.1\n. @caioss please fix the problems listed above. i think, aside from those issues, it should be good to do...\n. We should also remember that there has been some thought about changes needed to deprecate \"always-on\" basecurve, and apply *curve by default later in pipe.\n. This is basically the same shadow zone as enhanced curves, minus #10345\nBut if one comes up with a proper way to verify their quality, then i bet no one will vote them to be removed.\n. See #1063\n. Alright, i guess it's time..\n@TurboGit\nThank you for your contribution!\nHowever, we have no means of checking the validity of the these custom base/tone curves, and we do not think it's a good idea to merge them as is, because IIRC we have already seen broken curves.\nOnce we do, we will announce it.\n. 601de8bfb649ea9ff6ed8f7125359c187e71d3db was manually merged\n. > Make the 1-channel and 3-channel sraw code simpler by having a single code path and pushing the conditional into the inner loop.\nWe have had concerns about if() in inner loops in other parts of code (blend.c IIRC)\nI specifically unrolled this inner if() into 2 separate codepaths - b6db0f410c4baaf58bbf7c90c275e6625e66b0e1\nIf it's easy to avoid conditionals in inner loop, best to do so...\n\nAny sensible CPU will predict that branch 100% of the time so there shouldn't really be any performance impact.\n\nIIRC i did some profiling on this code, and this version seemed a bit better.\nSo, is there any actual issue?\n. This duplication is intentional. The difference is small. The duplicates are right next to each other.\nI do not like code duplication myself, but in this case, i believe, it is better this way.\n. 1. Still no \"extensions\", even for new files\n2. No license is specified, in ANY of your scripts...\n. > > Still no \"extensions\", even for new files\n\nSeveral of the files have extensions just not the ones that are runnable scripts for the reason I've already explained.\n\nFor the reason I've already explained, i would highly prefer all of the scripts to follow same pattern.\nAll(?) of the scripts before that do have extensions, so to be consistent, new ones should have it too.\n\n\nNo license is specified, in ANY of your scripts...\n\nThat's not common in scripts, are we supposed to do that for every file in the repo?\n\nThis has been discussed in IRC some time back, no license => problem waiting to happen.\nI hope you would want to avoid that...\n. > > This has been discussed in IRC some time back, no license => problem waiting to happen.\n\n\nI hope you would want to avoid that...\n\nI don't recall the discussion, may have been before my time. Should I prepare a PR to add them to all the scripts?\n\nThe one i can find in backlog was on Apr 30 2014.\n\nShould I prepare a PR to add them to all the scripts?\n\nYes.\n. Adds new string, probably a feature(?) => will have to wait until after 2.0\n. @TurboGit how do you build darktable?\n[ 70%] Building C object src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o\nIn file included from /home/lebedevri/darktable/build/src/iop/introspection_liquify.c:15:0:\n/home/lebedevri/darktable/src/iop/liquify.c: In function \u2018alloc_move_to\u2019:\n/home/lebedevri/darktable/src/iop/liquify.c:2334:10: error: return from incompatible pointer type [-Werror=incompatible-pointer-types]\n   return m;\n          ^\n/home/lebedevri/darktable/src/iop/liquify.c: In function \u2018alloc_line_to\u2019:\n/home/lebedevri/darktable/src/iop/liquify.c:2348:10: error: return from incompatible pointer type [-Werror=incompatible-pointer-types]\n   return l;\n          ^\n/home/lebedevri/darktable/src/iop/liquify.c: In function \u2018alloc_curve_to\u2019:\n/home/lebedevri/darktable/src/iop/liquify.c:2362:10: error: return from incompatible pointer type [-Werror=incompatible-pointer-types]\n   return c;\n          ^\ncc1: all warnings being treated as errors\nsrc/iop/CMakeFiles/liquify.dir/build.make:67: recipe for target 'src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o' failed\nmake[2]: *** [src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o] Error 1\nCMakeFiles/Makefile2:4770: recipe for target 'src/iop/CMakeFiles/liquify.dir/all' failed\nmake[1]: *** [src/iop/CMakeFiles/liquify.dir/all] Error 2\nMakefile:149: recipe for target 'all' failed\nmake: *** [all] Error 2\n. IMHO the first commit should be The original vanilla commit from @MarcelloPerathoner(?).\nBecause this code in pr is some variation of that original code.\nWill be much easier to think about issues like those @hanatos pointed out.\n. Does this module have any assumptions about it's working color space, does it need to work in camera rgb? lab?\nAlso, is it safe to assume that lens correction will be applied in direct direction (i.e. correct), not in reverse (i.e. distort)\nBased on answers to these questions i see 3 possible places for liquify place in pipe:\n1. before spot removal, like now\n2. before lens correction\n3. after lens correction, before input color profile\n4. after crop and rotate?\nPersonally, 3. seems like the best place to me.\nOr, at least comment in tools/iop_dependencies.py needs fixing :)\n. > where is that assumption? it will evaluate the transforms of controls to\n\npixels via the respective distortion callbacks in lens.c, right? using\nwhatever parameters you set there?\n\nNo, i meant \"in most cases users will apply lens correction in direct direction\"\n\nand as disucssed in irc, i don't see a particular requirement. maybe if it\ncomes late in the workflow it should be later in the pipe (speed reasons),\nbut i can't judge liquify workflows.\n\nAgreed.\n. (i did not say \"i'm ok\", i did say \"i'm not against, after a brief look\", there is a difference)\n. Does not build with clang-3.8:\n[ 70%] Building C object src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o\nIn file included from /home/lebedevri/darktable/build/src/iop/introspection_liquify.c:15:\n/home/lebedevri/darktable/src/iop/liquify.c:1290:7: error: variable 'dev_roi_out' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_in == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1331:7: note: uninitialized use occurs here\n  if (dev_roi_out   ) dt_opencl_release_mem_object (dev_roi_out);\n      ^~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_in == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1292:3: note: variable 'dev_roi_out' is declared here\n  cl_mem_t dev_roi_out = dt_opencl_copy_host_to_device_constant (\n  ^\n/home/lebedevri/darktable/src/iop/liquify.c:1294:7: error: variable 'dev_map' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_out == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1330:7: note: uninitialized use occurs here\n  if (dev_map       ) dt_opencl_release_mem_object (dev_map);\n      ^~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_out == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:7: error: variable 'dev_map' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_in == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1330:7: note: uninitialized use occurs here\n  if (dev_map       ) dt_opencl_release_mem_object (dev_map);\n      ^~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_in == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1296:3: note: variable 'dev_map' is declared here\n  cl_mem_t dev_map = dt_opencl_copy_host_to_device_constant (\n  ^\n/home/lebedevri/darktable/src/iop/liquify.c:1298:7: error: variable 'dev_map_extent' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_map == NULL) goto error;\n      ^~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1329:7: note: uninitialized use occurs here\n  if (dev_map_extent) dt_opencl_release_mem_object (dev_map_extent);\n      ^~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1298:3: note: remove the 'if' if its condition is always false\n  if (dev_map == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:7: error: variable 'dev_map_extent' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_out == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1329:7: note: uninitialized use occurs here\n  if (dev_map_extent) dt_opencl_release_mem_object (dev_map_extent);\n      ^~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_out == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:7: error: variable 'dev_map_extent' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_in == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1329:7: note: uninitialized use occurs here\n  if (dev_map_extent) dt_opencl_release_mem_object (dev_map_extent);\n      ^~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_in == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1300:3: note: variable 'dev_map_extent' is declared here\n  cl_mem_t dev_map_extent = dt_opencl_copy_host_to_device_constant (\n  ^\n/home/lebedevri/darktable/src/iop/liquify.c:1302:7: error: variable 'dev_kdesc' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_map_extent == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1328:7: note: uninitialized use occurs here\n  if (dev_kdesc     ) dt_opencl_release_mem_object (dev_kdesc);\n      ^~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1302:3: note: remove the 'if' if its condition is always false\n  if (dev_map_extent == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1298:7: error: variable 'dev_kdesc' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_map == NULL) goto error;\n      ^~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1328:7: note: uninitialized use occurs here\n  if (dev_kdesc     ) dt_opencl_release_mem_object (dev_kdesc);\n      ^~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1298:3: note: remove the 'if' if its condition is always false\n  if (dev_map == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:7: error: variable 'dev_kdesc' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_out == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1328:7: note: uninitialized use occurs here\n  if (dev_kdesc     ) dt_opencl_release_mem_object (dev_kdesc);\n      ^~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_out == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:7: error: variable 'dev_kdesc' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_in == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1328:7: note: uninitialized use occurs here\n  if (dev_kdesc     ) dt_opencl_release_mem_object (dev_kdesc);\n      ^~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_in == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1304:3: note: variable 'dev_kdesc' is declared here\n  cl_mem_t dev_kdesc = dt_opencl_copy_host_to_device_constant (\n  ^\n/home/lebedevri/darktable/src/iop/liquify.c:1306:7: error: variable 'dev_kernel' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_kdesc == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1327:7: note: uninitialized use occurs here\n  if (dev_kernel    ) dt_opencl_release_mem_object (dev_kernel);\n      ^~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1306:3: note: remove the 'if' if its condition is always false\n  if (dev_kdesc == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1302:7: error: variable 'dev_kernel' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_map_extent == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1327:7: note: uninitialized use occurs here\n  if (dev_kernel    ) dt_opencl_release_mem_object (dev_kernel);\n      ^~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1302:3: note: remove the 'if' if its condition is always false\n  if (dev_map_extent == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1298:7: error: variable 'dev_kernel' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_map == NULL) goto error;\n      ^~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1327:7: note: uninitialized use occurs here\n  if (dev_kernel    ) dt_opencl_release_mem_object (dev_kernel);\n      ^~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1298:3: note: remove the 'if' if its condition is always false\n  if (dev_map == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:7: error: variable 'dev_kernel' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_out == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1327:7: note: uninitialized use occurs here\n  if (dev_kernel    ) dt_opencl_release_mem_object (dev_kernel);\n      ^~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1294:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_out == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:7: error: variable 'dev_kernel' is used uninitialized whenever 'if' condition is true [-Werror,-Wsometimes-uninitialized]\n  if (dev_roi_in == NULL) goto error;\n      ^~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1327:7: note: uninitialized use occurs here\n  if (dev_kernel    ) dt_opencl_release_mem_object (dev_kernel);\n      ^~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1290:3: note: remove the 'if' if its condition is always false\n  if (dev_roi_in == NULL) goto error;\n  ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n/home/lebedevri/darktable/src/iop/liquify.c:1308:3: note: variable 'dev_kernel' is declared here\n  cl_mem_t dev_kernel = dt_opencl_copy_host_to_device_constant (\n  ^\n15 errors generated.\nsrc/iop/CMakeFiles/liquify.dir/build.make:67: recipe for target 'src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o' failed\nmake[2]: *** [src/iop/CMakeFiles/liquify.dir/introspection_liquify.c.o] Error 1\nCMakeFiles/Makefile2:4770: recipe for target 'src/iop/CMakeFiles/liquify.dir/all' failed\nmake[1]: *** [src/iop/CMakeFiles/liquify.dir/all] Error 2\nMakefile:149: recipe for target 'all' failed\nmake: *** [all] Error 2\n. And the best question: what about float complex?\nNo other code does that.\nWhy?\n. Hmm, why does this reimplement interpolation.c, especially for opencl codepath?\n@upegelow have you looked at this?\n. Hm?\nLens.c has a kernel per interpolation function, and does not re-implement interpolation functions.\nLiquify.c does re-implement interpolation functions, and apply_global_distortion_map_cl() has only one kernel.\nTo me that seems like 2 exactly the opposite principles\n. @TurboGit \nI feel like i should point out that tools/iop_dependencies.py places liquify into completely different place of pipe from where it is placed now, manually:\n$ ../tools/iop_dependencies.py \n1000 gamma\n984 dither\n968 watermark\n952 borders\n936 finalscale\n920 overexposed\n904 clahe\n888 splittoning\n873 vignette\n857 velvia\n841 soften\n825 channelmixer\n809 colorout\n793 colorcontrast\n777 grain\n761 highpass\n746 lowpass\n730 sharpen\n714 colorcorrection\n698 relight\n682 levels\n666 tonecurve\n650 zonesystem\n634 colisa\n619 monochrome\n603 lowlight\n587 colorzones\n571 bilat\n555 atrous\n539 shadhi\n523 globaltonemap\n507 nlmeans\n492 bloom\n476 colormapping\n460 colortransfer\n444 colorize\n428 clipping\n412 colorbalance\n396 equalizer\n380 defringe\n365 colorreconstruction\n349 colorin\n333 profile_gamma\n317 bilateral\n301 basecurve\n285 graduatednd\n269 flip\n253 liquify\n238 lens\n222 scalepixels\n206 rotatepixels\n190 spots\n174 exposure\n158 tonemap\n142 denoiseprofile\n126 demosaic\n111 rawdenoise\n95 hotpixels\n79 cacorrect\n63 highlights\n47 temperature\n31 invert\n15 rawprepare\n0 rawspeed\n. Colorin can not throw away fourth channel because demosaic, which comes before colorin, has already demosaiced 4-pixel CYGM/Bayer pattern into 4 pixels with 4 channels - RGBA.\n. Incorrect.\nAlpha channel is already used for masks.\nIt can not be used for anything else.\n. Again no :)\nThat alpha channel is used to view all the pixels that are affected by a specific mask - https://www.darktable.org/usermanual/ch03s02s05.html.php#d0e3568 - and is only used for all the modules that are after demosaic (== 4-ch RGBA buffer, not 1-ch, like before demosaic) and can have blending.\nSo i think you can see that even the right next iop after demosaic - tone mapping - has that functionality.\n. Also, looks like i should note that if we are to use all four channels for data, and not 3 channels + alpha, \nevery single iop between demosaic and colorin will have to be modified (yet another codepath) too.\nThat is a lot of changes for dead (not currently manufactured) sensor format...\n. So you are proposing copying colorin into demosaic (and displaying its ui) for that sensor?\n. Oh, BTW, and what about needed changes to the iops before demosaic?\n. 1. you should have talked to us in #darktable first :)\n2. it looks strange. there should be no need to merge those 2 iops into 1.\n   I'm pretty sure that you can do just that in Equalizer already...\n. @edgardoh last mail in darktable-dev was on Jan 4 2016.\nWhile IRC is the best option, darktable-dev will do too :)\nBut 30+ mails per day is definitely not darktable-dev, but darktable-users.\n(IIRC What would be cool and is more or less meaningful is frequency-based blend mode, maybe some day. but it will be slow...)\nI'll close it then...\n. Ok, bad karma: here i come :)\nTl;dr: join irc.freenode.net, channel #darktable and talk to us.\nhttp://article.gmane.org/gmane.comp.graphics.darktable.devel/6920/\n```\nSo, what exactly do we mean by a maintainer?\n0. Be actively involved with darktable for some time.\n< CURRENT SITUATION: pr #1086, well, not nope. >\nAt least half a year.\n< CURRENT SITUATION: nope >\nThat means:\n) Stick with us in IRC.\n< CURRENT SITUATION: REALLY BIG NOPE* - really important point. >\n) actually know the code.\n) actively examine bugreports, fix bugs.\n1. Be reliable and trustworthy [over that time], and more importantly,\nmake us believe in that.\n```\nGuys, just force-feeding some random diff into us will not work.\nEven https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md says that you need to talk to us :(\nAs for $indows-related changes: my mail was 100% correct: until those conditions are met, NOTHING will happen.\nAnd that includes even the changes that are needed to make dt compile on that [currently unsupported] platform.\nBecause they are the changes to help building on unsupported platform.\n. Ok, bad karma: here i come :)\nTl;dr: join irc.freenode.net, channel #darktable and talk to us.\nhttp://article.gmane.org/gmane.comp.graphics.darktable.devel/6920/\n```\nSo, what exactly do we mean by a maintainer?\n0. Be actively involved with darktable for some time.\n< CURRENT SITUATION: pr #1086, well, not nope. >\nAt least half a year.\n< CURRENT SITUATION: nope >\nThat means:\n) Stick with us in IRC.\n< CURRENT SITUATION: REALLY BIG NOPE* - really important point. >\n) actually know the code.\n) actively examine bugreports, fix bugs.\n1. Be reliable and trustworthy [over that time], and more importantly,\nmake us believe in that.\n```\nGuys, just force-feeding some random diff into us will not work.\nEven https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md says that you need to talk to us :(\nAs for $indows-related changes: my mail was 100% correct: until those conditions are met, NOTHING will happen.\nAnd that includes even the changes that are needed to make dt compile on that [currently unsupported] platform.\nBecause they are the changes to help building on unsupported platform.\n. Ok, bad karma: here i come :)\nTl;dr: join irc.freenode.net, channel #darktable and talk to us.\nhttp://article.gmane.org/gmane.comp.graphics.darktable.devel/6920/\n```\nSo, what exactly do we mean by a maintainer?\n0. Be actively involved with darktable for some time.\n< CURRENT SITUATION: pr #1086, well, not nope. >\nAt least half a year.\n< CURRENT SITUATION: nope >\nThat means:\n) Stick with us in IRC.\n< CURRENT SITUATION: REALLY BIG NOPE* - really important point. >\n) actually know the code.\n) actively examine bugreports, fix bugs.\n1. Be reliable and trustworthy [over that time], and more importantly,\nmake us believe in that.\n```\nGuys, just force-feeding some random diff into us will not work.\nEven https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md says that you need to talk to us :(\nAs for $indows-related changes: my mail was 100% correct: until those conditions are met, NOTHING will happen.\nAnd that includes even the changes that are needed to make dt compile on that [currently unsupported] platform.\nBecause they are the changes to help building on unsupported platform.\n. @AlicVB welcome back, i guess :)\n. @pedrocr\nI don't care. That was my last attempt as rawspeed contribution.\nAll those CVE's will stay there until someone else re-discovers them again.\nOh, and leaks too :)\n. On Sun, Feb 7, 2016 at 10:36 PM, Pedro C\u00f4rte-Real notifications@github.com\nwrote:\n\n@LebedevRI https://github.com/LebedevRI No clue why you're doing that\nbut it's your call.\nAre you also not going to submit upstream what you've already changed?\nCorrect. You may revert those commits if you wish so.\n\n\u2014\n\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1099#issuecomment-181090920\n.\n. Looks like just a cleanup, my limited testing did not reveal any issues.\n. @TurboGit how do you build darktable?\nThere are multiple warnings in this pr, and it does not compile here, as expected.\nDoes it compile for you? Why?\n. So, here is the thing...\ndt_dev_history_item_t contains struct dt_iop_module_t *module, which is a pointer, unique for each module instance.\n\nSteps:\n1. new image, with empty/default history stack.\n2. set some exposure correction\n3. duplicate exposure iop\n4. set some exposure correction in new iop\n5. delete second exposure iop instance\n6. Press undo:\n```\n==27429==ERROR: AddressSanitizer: heap-use-after-free on address 0x618000034c88 at pc 0x7fabae79b44b bp 0x7ffe157667d0 sp 0x7ffe15765f80\nREAD of size 9 at 0x618000034c88 thread T0\n    #0 0x7fabae79b44a in strlen (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x6d44a)\n    #1 0x7faba9d0d9c0  (/usr/lib/x86_64-linux-gnu/libsqlite3.so.0+0x2f9c0)\n    #2 0x7faba9d1ad69  (/usr/lib/x86_64-linux-gnu/libsqlite3.so.0+0x3cd69)\n    #3 0x7fabae246266 in dt_dev_write_history_item /home/lebedevri/darktable/src/develop/develop.c:534\n    #4 0x7fabae249cee in dt_dev_write_history /home/lebedevri/darktable/src/develop/develop.c:822\n    #5 0x7fab890cae85 in pop_undo /home/lebedevri/darktable/src/libs/history.c:225\n    #6 0x7fabae3fb997 in dt_undo_do_undo /home/lebedevri/darktable/src/views/undo.c:118\n    #7 0x7fab85c4b403 in _darkroom_undo_callback /home/lebedevri/darktable/src/views/darkroom.c:2237\n    #8 0x7fabad839882  (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x213882)\n    #9 0x7fababd2df44 in g_closure_invoke (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0xff44)\n    #10 0x7fababd3ff90  (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x21f90)\n    #11 0x7fababd487c8 in g_signal_emit_valist (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x2a7c8)\n    #12 0x7fababd4905e in g_signal_emit (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x2b05e)\n    #13 0x7fabad71db6e in gtk_accel_group_activate (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0xf7b6e)\n    #14 0x7fabad71f49c in gtk_accel_groups_activate (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0xf949c)\n    #15 0x7fabad998c20 in gtk_window_activate_key (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x372c20)\n    #16 0x7fabad998d40  (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x372d40)\n    #17 0x7fabad8389cb  (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x2129cb)\n    #18 0x7fababd2df44 in g_closure_invoke (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0xff44)\n    #19 0x7fababd4053d  (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x2253d)\n    #20 0x7fababd487c8 in g_signal_emit_valist (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x2a7c8)\n    #21 0x7fababd4905e in g_signal_emit (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0x2b05e)\n    #22 0x7fabad975f1b  (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x34ff1b)\n    #23 0x7fabad835ee8  (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x20fee8)\n    #24 0x7fabad837bdb in gtk_main_do_event (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x211bdb)\n    #25 0x7fabad3ae961  (/usr/lib/x86_64-linux-gnu/libgdk-3.so.0+0x58961)\n    #26 0x7fababa57fd6 in g_main_context_dispatch (/lib/x86_64-linux-gnu/libglib-2.0.so.0+0x49fd6)\n    #27 0x7fababa5822f  (/lib/x86_64-linux-gnu/libglib-2.0.so.0+0x4a22f)\n    #28 0x7fababa58551 in g_main_loop_run (/lib/x86_64-linux-gnu/libglib-2.0.so.0+0x4a551)\n    #29 0x7fabad836db4 in gtk_main (/usr/lib/x86_64-linux-gnu/libgtk-3.so.0+0x210db4)\n    #30 0x7fabae3a2fd5 in dt_gui_gtk_run /home/lebedevri/darktable/src/gui/gtk.c:956\n    #31 0x400d30 in main /home/lebedevri/darktable/src/main.c:25\n    #32 0x7faba64ce86f in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x2086f)\n    #33 0x400bf8 in _start (/usr/local/bin/darktable+0x400bf8)\n0x618000034c88 is located 8 bytes inside of 896-byte region [0x618000034c80,0x618000035000)\nfreed by thread T0 here:\n    #0 0x7fabae7c1bfa in __interceptor_free (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x93bfa)\n    #1 0x7fabae258ecc in dt_iop_gui_delete_callback /home/lebedevri/darktable/src/develop/imageop.c:537\n    #2 0x7fababd2df44 in g_closure_invoke (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0xff44)\npreviously allocated by thread T0 here:\n    #0 0x7fabae7c2001 in __interceptor_calloc (/usr/lib/x86_64-linux-gnu/libasan.so.2+0x94001)\n    #1 0x7fabae250e40 in dt_dev_module_duplicate /home/lebedevri/darktable/src/develop/develop.c:1483\n    #2 0x7fabae25ae33 in dt_iop_gui_duplicate /home/lebedevri/darktable/src/develop/imageop.c:718\n    #3 0x7fabae25bc55 in dt_iop_gui_copy_callback /home/lebedevri/darktable/src/develop/imageop.c:823\n    #4 0x7fababd2df44 in g_closure_invoke (/usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0+0xff44)\nSUMMARY: AddressSanitizer: heap-use-after-free ??:0 strlen\nShadow bytes around the buggy address:\n  0x0c307fffe940: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe950: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe960: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe970: fd fd fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c307fffe980: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n=>0x0c307fffe990: fd[fd]fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe9a0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe9b0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe9c0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe9d0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\n  0x0c307fffe9e0: fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd fd\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07 \n  Heap left redzone:       fa\n  Heap right redzone:      fb\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack partial redzone:   f4\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Container overflow:      fc\n  Array cookie:            ac\n  Intra object redzone:    bb\n  ASan internal:           fe\n==27429==ABORTING\n```\n. (If undo can not undo all MI-related cases, why have it at all? :)\nThere should be some other way.\n. Yes, please.\nSince we have agreed that it is ok, the sooner it is merged, the more time\nit is there to catch all the bugs that are still lurking.\nOn Mon, Oct 10, 2016 at 7:27 PM, Pascal Obry notifications@github.com\nwrote:\n\nSo given latest comment I plan to merge this later today. Thanks all!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1103#issuecomment-252671327,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAFaGHFpXLRIQTo7nn-2IA9LpTuey4oiks5qymdegaJpZM4G-Y7g\n.\n. Current status:\nAll essential iops are now converted, pipe is 'fully' functional without SSE.\n\nNot converted are only 5:\n- src/iop/atrous.c\n- src/iop/denoiseprofile.c\n- src/iop/dither.c\n- src/iop/graduatednd.c\n- src/iop/nlmeans.c\nAlso, i'm not really sure about src/common/points.h\n. So i guess the solution is to store pointer to process() in module->process_plain, and make default_process() always fallback to module->process_plain in the end, if it is there.\n. I tend to agree with @houz, ordinary users probably should not be able to (easily?) select one of CPU codepaths.\nThose 2 config options i have added i need for development/testing. Are they undocumented-enough? \nCurrently, if any codepath other that SSE2 is to be run, a warning(s) will be printed on DT startup, see dt_init() and dt_codepaths_init().\nMaybe it makes sense to also show in -d perf which process() implementation was run, not sure yet...\n. Updated.\n(Previous branch is https://github.com/LebedevRI/darktable/tree/openmp-simd-before-review)\nSo now iops should have process() and maybe process_sse2().\nI wanted to avoid changing pixelpipe_hb.c, so process_plain() is still in dt_iop_module_t and dt_iop_module_so_t so that default_process() can call it.\nElse i'd have to s/process()/default_process()/ in pixelpipe_hb.c, would it be better?\n. Seems ok\n. Ok, looks good, only one thing:\nLet's image that db only has images from /home/lebedevri/*\nNow, when \"folders\" are selected, lebedevri will be the first-level folder.\nAnd in this pr, home will be the first-level folder...\n. [14:28:27] <houz> maybe write down a small spec in a few lines that describes how it _should_ behave? so we have something simple to discuss/agree on and later test against?\n[14:29:19] <LebedevRI> in library you have /foo/bar/12.jpg /foo/bar/baz/34.CR2\n[14:29:41] <LebedevRI> git master shows it as: bar/12.jpg bar/baz/34.CR2\n[14:29:58] <LebedevRI> #1112 initially showed it as /foo/bar/12.jpg /foo/bar/baz/34.CR2\n[14:30:19] <LebedevRI> now #1112 shows it as 12.jpg baz/34.CR2\n[14:30:35] <LebedevRI> ^ which behavior do we want?\n[14:31:04] <houz> i somehow agree that you want bar/so you have a single point to collapse, while not having foo/ because that would just be an empty level that might be annoying\n[14:31:28] <LebedevRI> that is what i'm saying too\n[14:32:05] <houz> LebedevRI: then we should write it down, so the next person rewriting collect in a few years can just read it up\n. This will need a better description :)\n. Yes, that we can see, but the description should ideally say why that is needed, exactly.\n. @MRIG could you please learn how to push stuff into git master without a PR, please?\n. There is no need to create a pull request and merge it, you can just push into darktable-org:master from git, since you have commit rights.\n$ git push upstream should be the all you need\nhttps://help.github.com/articles/pushing-to-a-remote/\n. Based on my limited testing, seems to work.\n. @upegelow \n(yes, i have looked at this only now :)\nThis block is bothering me: https://github.com/darktable-org/darktable/blob/385801d7e6643790f3fddf437856e8c759b41dd2/src/iop/demosaic.c#L3256-LL3263\nhttps://github.com/darktable-org/darktable/blob/385801d7e6643790f3fddf437856e8c759b41dd2/src/iop/demosaic.c#L3527-L3532\nShouldn't those 2 cases incommit_params() also check darktable.opencl->enable_markesteijn, and if it is 0, do piece->process_cl_ready = 0; ?\nElse i think we are risking to see that \"[opencl_demosaic] Markesteijn demosaicing with OpenCL not enabled (see 'opencl_enable_markesteijn')\\n\" when user zooms-in close-enough, no?\n. > Then when zoomed in darktable falls transparently back to CPU code: besides of the speed no user visible difference.\nAh, that was the piece i was missing.\nThen it is ok indeed.\n. This, and #1135 are good to go as far as i can tell.\n. For history, i want to quote a few things:\nhttp://article.gmane.org/gmane.comp.graphics.lensfun/384\nhttp://wilson.bronger.org/lensfun/perspective-correction.html\nIn future, we would like to move all the functionality that requires interpolation (that is: keystone correction and rotation) from c&r into lens iop.\nThat way, it is less interpolation steps (faster, better quality?, probably more control)\nBut since that functionality is not yet in lensfun git master (and not in 0.3.2), it will be a while before that will be possible.\n. src/iop/ashift_lsd.c and src/iop/ashift_nmsimplex.c - are there any changes in them from the 'downloaded' original versions?\nI would probably recommend to put them into src/external/\n. github really cripples ability to comment on such big pr's..\nmodify_roi_out() and modify_roi_in(): you can easily parallelize those, see https://github.com/darktable-org/darktable/blob/50b7d19/src/iop/lens.c#L889 + add collapse(2)\n. > Therefore we only need to visit those four corners to get the roi's.\nOh, right :)\nIn all other iops similar problems were solved using get_corner() and adjust_aabb(), i did not see those functions called and did not notice that it was only checking the 4 points.\nDefinitely not worth parallelizing it :)\nBTW: IIRC there are some other places in dt that might be better with that \"flip detection using backtransform\", namely gradient mask, graduated ND - they are kind-of wrong if flip != off.\n. [ 49%] Building C object src/iop/CMakeFiles/ashift.dir/introspection_ashift.c.o\nIn file included from /home/lebedevri/darktable/build/src/iop/introspection_ashift.c:24:\n/home/lebedevri/darktable/src/iop/ashift.c:997:47: error: duplicate 'const' declaration specifier [-Werror,-Wduplicate-decl-specifier]\nstatic void ransac(const dt_iop_ashift_line_t const* lines, int *index_set, int *inout_set,\n                                              ^\n1 error generated.\nsrc/iop/CMakeFiles/ashift.dir/build.make:67: recipe for target 'src/iop/CMakeFiles/ashift.dir/introspection_ashift.c.o' failed\nmake[2]: *** [src/iop/CMakeFiles/ashift.dir/introspection_ashift.c.o] Error 1\nmake[2]: Target 'src/iop/CMakeFiles/ashift.dir/build' not remade because of errors.\nCMakeFiles/Makefile2:3329: recipe for target 'src/iop/CMakeFiles/ashift.dir/all' failed\nmake[1]: *** [src/iop/CMakeFiles/ashift.dir/all] Error 2\n. Rotation slider is rotating clockwise for positive values, and counterclockwise for negative...\nI do see that it is not labelled as degrees, so i understand that it is kind-of not a bug, but still seems wrong.\nAlso, because we have other rotation sliders, which IIRC correctly rotate (clockwise for negative values), it will be confusing.\n. So i have tried it, overall looks good, looking forward to it.\nAbout those 0.5 hard limits for shift - are they really hardcoded deep down in code, or can they be easily changed to something bigger? I would prefer for them to be bigger.\n. > > About those 0.5 hard limits for shift - are they really hardcoded deep down in code, or can they be easily changed to something bigger? I would prefer for them to be bigger.\n\nI orignally had a value of 1.0 here but then I found that all cases where you still can extract a reasonably sized rectangular image have a lower shift value. So let's see what users report. We can at any time increase this value if needed.\n\nYes, that is exactly why bauhaus supports soft limits, see exposure iop, black level:\n- 1\n- 2\n. This looks important.\nSince we are practically free of leaks, and other issues that ASan can find, i will be switching to TSan next.\nSo i'll handle this...\n. <rant>in c++, we could simply use thread-safety annotations to automatically find all such things</rant>\nI do agree that it is likely needed, but should be fixed more properly.\nI.e. with thread-sanitizer, one commit per problem, with proper commit messages (containing TSAN traces). So\n1. It only accepts date in format 2015:01:01, not 2015:1:01, not 2015:01:1, not 2015:1:1.\n2. No tooltip of which format one should actually input.\n3. With some range set, e.g. [2012:01:01; 2013:12:31], some images are shown in lt, but no dates are shown in collect. I expected all the dates that fit current filter to be listed there.\nNow, for ISO:\n1. Filter: [0; 800]. no images displayed in lt, all the iso's are still listed in collect images\n2. Filter: [0;800] (just removed a space - ) - all good, like i expected - images displayed in lt, matching iso's are showed up in the list. It should be much more tolerable to spaces :)\n. This, and #1126 are good to go as far as i can tell.\n. @avsmal yes, please try modifying set_white and get_white hooks.\nAlso, while there, it should make it easy to fix https://redmine.darktable.org/issues/10073\n. Okay, looks about right.\nI will increase step of exposure change when scrolling histogram though.\n. @avsmal yeah, i think it is not too intrusive. i wanted to wait some time, and so far no complaints.\nSo i will look into cherry-picking it before 2.0.3\n. Yeah, no way isnan(int) is really what was meant.\nThere is this similarly-looking piece of code, maybe it is just one another copy-paste issue https://github.com/darktable-org/darktable/blob/ed50588/src/develop/masks/path.c#L2517-L2528\n. Please point to the X-Trans sample raw file (from camera with removed CFA) you used to verify that it works.\n. How does this affect the iops before demosaic in MIP_F pipe?\n. I do not consider my questions to be answered.\n. Get someone else to merge it or i will revert it.\n. No, just a statement.\nI am the author and (still) the maintainer of that monochrome demosaic code.\nAnd i neither like proposed changes nor did you managed to convince me that they are correct/right.\nThus, get someone else to merge it.\n. There is also a CropFactor field in lensfun camera description, not sure that it can/worth to be used here though.\n. Nothing seems broken on the first glance.\nFailed to break it during short testing.\n. > > Not sure there is anything here to review, but just to be sure...\n\nLooks good.\n\nOkay, thank you.\nI'll merge it then and go to the last 3 places :)\n. (and yes, all those non-sse codepaths i have added will currently result in horrible performance, profiling + openmp simd vectorization will be the next step..)\n. (was discussed, good to go)\n. I think i still have the very same question, unanswered:\nWe have had iop's that that display some OSD for a while.\nWe have seen no crashes related to that.\nWhat does liquify do so specially (read: differently, wrongly, since it causes all these crashes) to need such workarounds?\nAs far as i can see, there is no reason why liquify would be any different from what we already had.\nSo shouldn't it be \"just\" fixed to do what all other IOP's do?\n. Hm, might be, though c&r is close to that, not sure to what extent.\n. Hm, well, i can agree that the current code looks wrong.\nHowever i can not say right away what should be used there - module->color_picker_box or dev->gui_module->color_picker_box...\nHave you tried using the other one?\n. So i'm currently looking at this, and i feel like reminding that this issue is still there.\nBut yes, with the changes, result looks a lot less broken than with git master.\n. Also a tooltip in collect.c needs changing\nhttps://github.com/darktable-org/darktable/blob/0b74cbd7a448073ab849730c24f0577772d8375c/src/libs/collect.c#L1255\n. Seems ok to me.\n. I think, CK''s spinlock does not have this pthread limitation:\nAttempting to unlock the mutex if it was not locked by the calling thread results in undefined behaviour. Attempting to unlock the mutex if it is not locked results in undefined behaviour.\nhttp://pubs.opengroup.org/onlinepubs/007908775/xsh/pthread_mutex_lock.html\nThat would make lua locking a bit nicer (c970025045a26776b193d438a59a92f15a49eb13)\n. @sbahra no, this did not get end up merged. but not because of some CK problems.. Yeah, unfortunately :(\nEach time we run tools/iop_dependencies.py, the positions of all the iops are recomputed and in each iop, it's position is stored (init() function, field priority in dt_iop_module_t).\nAnd in case of vibrance, that priority was never written to the vibrance.c, thus it freely drifted (is freely drifting) amongs other iops, probably changing it's place (it's neighbours)...\n. So i looked at the different versions:\n[12:45:08] <LebedevRI> right now it is after CLUT and before defringe\n[12:57:19] <LebedevRI> in 20x, vibrance is after defringe, and before color balance\n[13:01:36] <LebedevRI> in 16x, vibrance is after defringe, and before color balance, same as with 20x\n[13:07:54] <LebedevRI> in 14x, vibrance is after c&r, and before colorize\n[13:10:06] <houz> re vibrance: let's use the 20x location so there are less breaks in the history of the module\n[13:11:31] <LebedevRI> in 12x, vibrance is after c&r, and before colorize, same as with 14x\n[13:17:50] <LebedevRI> can not build 10x right away, but i believe  in 10x, vibrance is after c&r, and before colorize, same as with 14x and 12x\nCurrent diff puts it:\n1000 gamma\n985 dither\n970 watermark\n955 borders\n940 rawoverexposed\n925 overexposed\n910 finalscale\n895 clahe\n880 velvia\n865 splittoning\n850 vignette\n835 soften\n820 channelmixer\n805 colorout\n791 colorcontrast\n776 grain\n761 highpass\n746 lowpass\n731 sharpen\n716 colorcorrection\n701 relight\n686 levels\n671 tonecurve\n656 zonesystem\n641 colisa\n626 monochrome\n611 lowlight\n597 colorzones\n582 bilat\n567 atrous\n552 shadhi\n537 globaltonemap\n522 nlmeans\n507 bloom\n492 colormapping\n477 colortransfer\n462 colorize\n447 clipping\n432 colorbalance\n417 vibrance\n402 equalizer\n388 defringe\n373 colorchecker\n358 colorreconstruction\n343 colorin\n328 profile_gamma\n313 bilateral\n298 basecurve\n283 graduatednd\n268 flip\n253 scalepixels\n238 rotatepixels\n223 liquify\n208 ashift\n194 lens\n179 spots\n164 exposure\n149 tonemap\n134 denoiseprofile\n119 demosaic\n104 rawdenoise\n89 hotpixels\n74 cacorrect\n59 highlights\n44 temperature\n29 invert\n14 rawprepare\n0 rawspeed\nSo more or less where it should be.\n. Discussed with @hanatos, he thinks it is at least not worse than it is now.\nI guess, opencl can come later.\n. @dtorop feel free to rebase on top of current git master.\nI guess it is up to you to pick 3x3 vs. 2x2 sampling.\nFeel free to ping me once you think this is good to go.\nOn an unrelated note, i am planning (well, hoping to) work on proper pre-demosaic highlight inpainting iop sometime next.\nAnd i only have Bayer sample raws with highlight clipping.\n@dtorop, maybe you have some good x-trans raws with interestingly-clipped highlights that you can give me? Then i might be able to also at least try to make it work not just for Bayer...\n. Tested on my limited supply of x-trans files, looks awesome, much better than 'mode = clip', and better than current git master.\nIf nothing pops up, i'm ready to merge this in +24h from this comment.\n. Thanks!\n. This is about those accels created with dt_accel_connect_iop() - e.g [ and ] in flip.c\n. @TurboGit i do acknowledge that the bug exists.\nBut the code does not fix it for me.\nChecked with [ and ] in orientation iop.\nPlease double-check :)\n. > What's your testing procedure?\n- open a picture on darkroom\n- (basecurve iop is selected)\n- select the orientation module\n- [ and ] are not working\n- selected another iop (grad density)\n- back to orientation\n- [ and ] is still not working\nIf i switch to dr when orientation module is selected, then [ and ] are working until i switch away to other module\nTLDR: i see no difference compared to git master...\nThis is on empty dt setup, starting with rm -fr ~/.config/darktable ~/.cache/darktable\n(and yes, i'm 100% sure that i'm testing the dt built from from this pr)\n. Did some more digging.\ndt_accel_connect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CCW\"\ndt_accel_connect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CW\"\ndt_accel_disconnect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CCW\"\ndt_accel_disconnect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CW\"\ndt_accel_connect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CCW\"\ndt_accel_connect_locals_iop: \"flip\" \"<Darktable>/image operations/flip/rotate 90 degrees CW\"\nSo local accels are indeed reconnected, even weirder.\n. No, like i said in https://github.com/darktable-org/darktable/pull/1192#issuecomment-209475027, they work if orientation iop is opened when entering darkroom.\nOnce i close it, no matter what i do, they no longer work.\n. Gtk+-3.18, kde\nI'm not saying that it is definitely a bug in dt, but i guess until someone else tests this we won't know that...\n. Looks about consistent with usage in other projects.\n. The bigger problem with gtk and theming is that in any case, our css only overrides some subset of the gtk theme\n. I have in my todo to look at doing all this theming more properly, using native gtk theme base, with auto-generation and whatnot. Will see if i get to work on that...\nhttps://github.com/GNOME/gtk/blob/gtk-3-22/gtk/theme/Adwaita/README. @mazhe i assume this still is an issue. Let's try this again...\nI guess this is related to https://redmine.darktable.org/issues/11022\nWas the sample sent to rawspamples.ch too?\n. > Ok, I have cleared up my issue with black PEF\nWhat exactly was the issue?\nThere is some kind of race condition when entering darkroom when image is not loaded yet, so darkroom opens, but the image is displayed black.\nRe-entering darkroom fixes that.\n. The only questionable thing here is crop, so please take a fully clipped (!) image - fully open aperture, iso100, 30 sec exposure, and upload it somewhere.\n. Can you upload that to some sane location, like dropbox?\nThat one is blocked for me, and i do not understand how to download from\nthere.\nOn Thu, Aug 11, 2016 at 7:11 PM, Matthieu Volat notifications@github.com\nwrote:\n\nHere are the samples, PEF & DNG:\n- http://dl.free.fr/iommjlg1L\n- http://dl.free.fr/im9v4GQA8\n\u2014\nYou are receiving this because you modified the open/close state.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1201#issuecomment-239209814,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAFaGKE7BBh_NJb89phFh8H_GyTQCzDWks5qe0mtgaJpZM4IaV0a\n.\n. Thanks, merged manually.\nPlease do send a sample to rawsamples.ch\n. @mazhe Hi!\nCould you please help us with raw samples for this camera for https://raw.pixls.us/?\n\nThere are total of 6 samples. The camera needs to be stable (tripod), and the scene needs to be as static as possible (so some daylight nature landscape would be best), and all the samples must have the same content/scene:\n\n35mm Full-Frame:\npixelshift OFF\nPEF\nDNG\n\n\npixelshift ON\n    (i.e. one with motion correction and one without)\nPEF (motion correction either ON or OFF)\nDNG (motion correction either OFF or ON)\n\n\nAPS-C crop, pixelshift OFF\nPEF\nDNG\n. So far we've failed to find any 645D/645Z owner willing to contribute the samples.\nPerhaps someone with K1 could still help.. (In the mean time, the 645[zd] samples were received)\n\n\nThere are already entries for the K1\n\nJust upload all of those your shot.. > i was noting some issue with the blackpoint not being picked up in the\n\npreview pipeline though. so the navigation view still has the green cast :/\n\nBecause preview pipeline is demosaiced, https://redmine.darktable.org/issues/10978, so that is totally expected.\nOne more pin into the coffin of pre-demosaicing, should be gone in my wip MIP_F rework branch.\n. Can not reproduce pre - 8e859e9b890203eba7dae77bc9f61ab134c4d81e behaviour with those changes.\nAnd the code looks cleaner.\n. @dtorop thank you.\n. @HansVanpee as it was (IIRC) said, without some documentation saying otherwise, our current approach, now that it actually works, is no better or worse than this. (meaning: if no docs say that this is the right way, we should probably keep what we already have)\nAlso, why there is 2 PR's? #1214 #1215\n. Feel free to re-open if it is still needed.\n. @HansVanpee as it was (IIRC) said, without some documentation saying otherwise, our current approach, now that it actually works, is no better or worse than this. (meaning: if no docs say that this is the right way, we should probably keep what we already have)\nAlso, why there is 2 PR's? #1214 #1215\n. In any case, this PR is bogus - no changes, originates from master branch, and has lot's of \"Merge remote-tracking branch 'upstream/master'\"\nFor master branch, one should use git rebase upstream/master master, not git merge\n. A few questions i have on my mind:\n-  How does the basecurve affect further exposure fusion?\n  -  Will it work with linear basecurve? (e.g. some people like to use tonecurve)\n  -  If if will work with linear basecurve, can't exposure fusion be placed in a new iop just before basecurve?\n. Please split wb presets into separate pr, i will merge it. (also, you may want to add comment about firmware version before each camera presets)\nAs for raw support, matrix matches the one in dcraw, so i guess it is ok.\nBut did you actually check <Crop> values in gimp?\n. @upegelow feel free to do so at any moment.\nAny further fixes will just go into Part 2\n. @upegelow thank you!\n. @schenlap thanks!\nIf there will be more things like this, i think i will merge those.\n. > 1) Why does dngmeta.sh give a wrong color order?\nI'm not the author but i have a pretty good guess:\nIn dng, maybe CFA colors are specified starting from (0,0) pixel of the sensor,\nWhile in cameras.xml, the  CFA colors (for bayer) are specified from (0,0) pixel of the cropped image(!)\n. > 2) do you want to merge also 1:1 is missing?\nI think 4:3 is also missing. No, this is not urgent, so let's wait until there are all the samples.\n(also, when replying to Camera Support issues, please do say that reporter should also send the raws to rawsamples.ch)\n. Ok, thanks. Will try to look at this and merge.\nRelated: i'm doing some math on the rawspeed output buffer in attempt to produce a script to automagically compute best guess values for <crop>.\nIt is nowhere near completion, but seems to compute the \"x\" crop already.\nhttps://github.com/LebedevRI/darktable/blob/tools/tools/guess_optimal_rawspeed_crop.py\n. @schenlap thank you!\n. @schenlap thank you.\nI'm noticing that there is no wb presets.\nDo you know about tools/extract_wb ?\nFor many models, even any single raw contains all the wb presets.\n. @schenlap thank you!\n. @upegelow thank you!\n. Note that this works with Bayer and X-Trans, for uint16_t buffers.\nIt does not work as of now for 4COLOR sensors, and for non-uint16_t buffers (pre-demosaiced s/m-RAW, PFM, EXR)\n. Those 2 images are fully zoomed-out, \"fit to screen\", with all sidepanels collapsed, on 1920x1080 monitor.\n. Added iop_deps and POTFILES stuff, should be ready to go.\n. Added blind attempt at opencl kernels for rawoverexposed. Do not know whether opencl is right since i have no opencl setup working.\nAlso, not sure about tiling_callback()\n. > 1) [1] names wb_presets: Daylight, Shade, Cloudy, Tungsten light, White fluorescent light, Flash, extrat_wb names it as in the pr. Rename CoolWhiteFluorescent to White fluorescent?\nHm.\nNot sure this can be done automatically, i guess different models mean different things under \"Fluorescent\"\nBut since user manual states that it is \"White Fluorescent\", yes, i guess changing is ok.\n\n2) Sort them as for EOS M3?\n\nYes, the position seems correct to me.\n\n3) Coding Style: which one prefer here? This is coding style from extract_wb. I like it best (not tabs after characters and good to read and compare) but is not used often in wb_presets.c\n\nwb_presets.c is a formatting mess, without some auto-formatting for it, i do not feel like enforcing any style for that file..\n. @schenlap thank you!\n. @schenlap thank you.\nAs for #11032, i'm not sure, but those garbage pixels should not be there.\n. Please also, if at all possible, prefix commits with the area of code/tree they touch.\nElse git cherry get's rather unreadable over time.\n. Are those from adobe dng converter?\nOur general idea is:  ideally, once a change in cameras.xml and adobe_coeff are made, it is best to not change that camera.\nBecause that would result in dt producing slightly different output for the same history stack, and we generally try to avoid that.\nThe fact that the camera definition (matrix, black/white levels, crop) are not saved in history stack is a bug though, will be fixed one day.\n. Can not download the samples, \"403 Forbidden\"\n. @schenlap thank you!\nAll seems good based on those samples, so i merged.\n. So short answer to \"buffer descriptors on each piece and on the full pipeline \" would be: because i essentially just wrapped filters and processed_max into a struct.\nI think, in the end, the piece version should be actually used, and it should be properly adapted to tiling/zoom to not need code like +roi_in->x.\nAnd the pipe version should just be used to transfer the description of the full buffer.\n. That should probably go into https://github.com/darktable-org/lua-scripts\n. Reading dt_exif_read_blob(), i guess it should contain *buf = NULL at the very top, before try.\nAnd catch{} should probably free(*buf) and *buf = NULL\n. Hm, not too sure about catch{} part though.\n. [exiv2] .../IMGP0385.jpg: Size of Exif JPEG segment is larger than 65535 bytes\nNice, much better :)\n. Thank you.\n. Theses may be a good candidates to filter out:\nhttps://www.adobe.com/content/dam/Adobe/en/products/photoshop/pdfs/dng_spec_1.4.0.0.pdf\nPage 15, \"Camera Profiles\"\nThe set of tags belonging to a camera profile includes the following:\n\u2022 BaselineExposureOffset\n\u2022 CalibrationIlluminant1\n\u2022 CalibrationIlluminant2\n\u2022 ColorMatrix1\n\u2022 ColorMatrix2\n\u2022 DefaultBlackRender\n\u2022 ForwardMatrix1\n\u2022 ForwardMatrix1\n\u2022 ProfileCalibrationSignature\n\u2022 ProfileCopyright\n\u2022 ProfileEmbedPolicy\n\u2022 ProfileHueSatMapData1\n\u2022 ProfileHueSatMapData2\n\u2022 ProfileHueSatMapDims\n\u2022 ProfileHueSatMapEncoding\n\u2022 ProfileLookTableData\n\u2022 ProfileLookTableDims\n\u2022 ProfileLookTableEncoding\n\u2022 ProfileName\n\u2022 ProfileToneCurve\n\u2022 ReductionMatrix1\n\u2022 ReductionMatrix2\n. I do like the changes, but as i have attempted to explain in\nhttps://github.com/darktable-org/darktable/pull/1256#discussion_r78277567 this should be moved into this block, to the end of it: https://github.com/darktable-org/darktable/blob/97868783c1d53672ef1a5b2acfe7f3b3d0abd851/src/common/exif.cc#L1194\n. Some people think C++ Throw is a graceful error propagation...\nI'm not sure i agree with those\nOn Sat, Sep 10, 2016 at 10:00 PM, Matthieu Volat notifications@github.com\nwrote:\n\nYou are right, I was working on the assumption that the findKey would fail\nmore gracefully in case of error.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1259#issuecomment-246129597,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAFaGLPjUBRs1_ZewTCFBytenCA8JCOqks5qov5YgaJpZM4J5uKS\n.\n. > Speaking of soft error management, I wonder if it's necessary to keep displaying an error message when we use a non-existant (for now) tagname.\n\nNo, definitely no need to output an error message.\n. Looks good, probably last 2 notes.\n. The static is not nessesary, but that string will not/should not be changed, so i think there is no reason to tell that via const; maybe static will also allocate the string better\n. Based on disscussion in irc, it is probably better to not do that, at least for now.\n. @schenlap thank you!\n. Are you sure this does not also need\ninclude_directories(SYSTEM ${JPEG_INCLUDE_DIRS})\n  include_directories(SYSTEM ${Pugixml_INCLUDE_DIRS})\n  add_definitions(${JPEG_DEFINITIONS})\n?\n. Ah right.\n. @mazhe i hope you are not on osx 10.6, because i'm about to break it by hard-requiring C++11.\n. @dtorop \nSurprisingly, even without sub-sampling, X-Trans does not result it too bad preview.\nIf you happen to have time, i'm even more interested in getting rid of those confetti colours, as @hanatos called them. Because they affect Bayer too...\n(We are looking at the preview, but displayed instead of the full image, i.e. when zoomed-in and moving the viewport.)\n. LGTM.\nI can not check whether it works as intended, so i'll just assume that you would not propose intentionally-bad patch.\n. @parafin do note that the code is in rawspeed.\nWe are kinda half-upstream for rawspeed based on the upstream's git log.\nAnd having incompatible changes that won't get upstreamed is not good.\nSo i still think all is fine here.\n. static int ver = 0; // cached\nif (0 == ver && ...\nLooks cached to me?\n. @upegelow any thoughts on this? :)\n. So do i merge it? Or will you?\n. Ok.\n. Please do understand what you are doing, don't just open pull requests for random branches.\n. @schenlap thank you!\n. Where is the tarball with PDF's?\nWe do need those to verify the validity of profile.\n. Needs rebase.\n. There is some deadlock, looks like in last commit in src/iop/invert.c changes\nTrying to figure it out...\n\nThe \"manual\" mode in white balance still does not work with OpenCL.\n\nNot sure what that is about, but since you used word \"still\", i'm guessing it is not a regression, so i can skip it.\n. > > Not sure what that is about, but since you used word \"still\", i'm guessing it is not a regression, so i can skip it.\n\nIt's certainly a regression. Just checked and it works in the 2.0.x branch. Will need to bisect to find the point where it got lost.\n\nWhat \"manual\" mode in white balance do you mean?\n. > It's \"spot\" mode in preset. Special case here is: I am running also the preview pipe on GPU (a different one than the full pipe). I will try to bisect tomorrow.\nAh, ok.\nThen just read pixelpipe_picker_cl() in src/develop/pixelpipe_hb.c and make sure that it makes sense.\nIndeed, i can not test opencl things...\nhttps://github.com/darktable-org/darktable/pull/1279/files#diff-8ea5aadb7471f5d0f720787aeea12288R496\nThe cpu part does work.\n. @upegelow \n(hint: spot whitebalance and spot invert is broken in git master since the un-demosaicing of preview pipe. this commit fixes that. but i guess i missed something in opencl part)\n. Functions in color_picker.c should be static, so they will not clutter libdarktable namespace.\n. @schenlap \n1. Nice to see this!\n2. I'm not seeing any deletion of erroneous entries added by be. Not all cameras can write compressed/uncompressed. Not all 14bit cameras can write 12bit too. Have you cross-checked it with the camera's PDF usermanuals?\n3. While there, it is imperative to also take care of https://github.com/darktable-org/darktable/blob/master/tools/rawspeed-check-nikon-modes.rb\n. And, just want to point out the obvious thing: you better be 100% sure about those changes, i will not have a nerve/patience to go through them again, disable, and check samples...\n. @schenlap yes, both of these modes internally do the same thing, so \"mode=??bit-compressed\" is the only one needed for both of them.\nBTW, if you want to help out with these last few nikon cameras, which would be truly awesome, i think i would prefer to have one PR per camera, to simplify things.\n. @schenlap we may do 2.0.7 in a few weeks, hopefully some more samples will appear before then..\nIn this PR, anything to merge?\n. > BTW: I would reenable compressed and uncompressed mode even if we only have one image. Is that okay for you?\nWell, i believe, so far all the white levels are the same for all compression modes, so it should be fine.\n\nShould I add a note if e.g 14bit mode is missing were we only got samples for 12bit?\n\nTo where?\nBut yes, we can enable modes separately, once we have the samples at least for just one.\n. I believe this has been fully merged in the separate pr's.\nWe will ask for the last 4 samples in 2.0.7 release notes, with any luck that will help...\n@schenlap thank you once more.\n. Not that it answers the question, but https://www.khronos.org/registry/cl/specs/opencl-1.x-latest.pdf#page=39\nclGetDeviceInfo returns <...> CL_INVALID_VALUE <...> or if size in bytes\nspecified by param_value_size is < size of return type as specified\nin table 4.3 and param_value is not a NULL value.\n. Okay, makes sense, i'll adjust the proposed code.\n. @upegelow \nOk, revised.\nI'm not too sure about guessing and allocating e.g. 4096 bytes if we did not error-out, but if you insist..\n. Ok, hopefully final version.\nIf ok, please do merge.\nThe conversion of existing calls to this function [i think] will require splitting that per-device loop into separate function, which anyaway makes sense due to the LOC, but is really needed to have sane leak-free memory handling. That is for next pr...\n. @upegelow thank you!\n. @schenlap thank you!\nLooks good.\n. @schenlap thank you!\n. Yep, seems to be all that is needed.\n. @schenlap thank you!\n. LGTM.\n\nshould i create a ticket for this to inform other users about fix of D1X?\n\nHmm, may be a good idea, yes.\n. @schenlap thank you!\n. Thank you for your contribution.\nHowever, i'm not really sure what to do here.\nThe PR #1032, that changed it, had some reasoning for the change.\nDoes this undo the changes, or actually just fix the code?\nI do not know\nOther opinions will be needed.\n. Ok, i found the images i used to test the original pr.\n| actual in-camera setting | displayed as (pr) |\n| --- | --- |\n| 1/4 | 1/4 |\n| 0\"3 | 1/3 |\n| 0\"4 | 1/2 |\n| 0\"5 | 1/2 |\n| 0\"6 | 1/2 |\n| 0\"8 | 1/1 |\n| 1\" | 1\" |\nThis may mean many things:\n- we are trying to display the actual exposure time, and not the one that was set in camera (there are multiple 'exposure time' fields in Exif)\n- It may differ between camera manufacturers\n- ???\n. @holomorph it's your lucky day :)\nThank you for your contribution!\n. Oops, a bit too much error handling :)\n```\ndiff --git a/src/common/opencl.c b/src/common/opencl.c\nindex 2da6688..e199fcf 100644\n--- a/src/common/opencl.c\n+++ b/src/common/opencl.c\n@@ -373,49 +373,58 @@ static int dt_opencl_device_init(dt_opencl_t cl, const int dev, cl_device_id d\n   {\n while(!feof(f))\n {\n   int prog = -1;\n   gchar *confline_pattern = g_strdup_printf(\"%%%zu[^\\n]\\n\", sizeof(confentry) - 1);\n   int rd = fscanf(f, confline_pattern, confentry);\n   g_free(confline_pattern);\n\n\nif(rd != 1) continue;\nif(rd != 1)\n{\nres = -1;\ngoto end;\n}\n       // remove comments:\n       size_t end = strlen(confentry);\n       for(size_t pos = 0; pos < end; pos++)\n         if(confentry[pos] == '#')\n         {\n           confentry[pos] = '\\0';\n           for(int l = pos - 1; l >= 0; l--)\n           {\n             if(confentry[l] == ' ')\n               confentry[l] = '\\0';\n             else\n               break;\n           }\n           break;\n         }\nif(confentry[0] == '\\0') continue;\nif(confentry[0] == '\\0')\n{\nres = -1;\ngoto end;\n\n}\nconst char programname = NULL, programnumber = NULL;\n   gchar **tokens = g_strsplit_set(confentry, \" \\t\", 2);\n   if(tokens)\n   {\n     programname = tokens[0];\n     if(tokens[0])\n       programnumber = tokens[1]; // if the 0st wasn't NULL then we have at least the terminating NULL in [1]\n   }\nprog = programnumber ? strtol(programnumber, NULL, 10) : -1;\nif(!programname || programname[0] == '\\0' || prog < 0)\n   {\n     dt_print(DT_DEBUG_OPENCL, \"[opencl_init] malformed entry in programs.conf `%s'; ignoring it!\\n\", confentry);\n+        continue;\n-        res = -1;\n-        goto end;\n   }\nsnprintf(filename, sizeof(filename), \"%s/kernels/%s\", dtpath, programname);\n   snprintf(binname, sizeof(binname), \"%s/%s.bin\", cachedir, programname);\n   dt_print(DT_DEBUG_OPENCL, \"[opencl_init] compiling program `%s' ..\\n\", programname);\n   int loaded_cached;\n   char md5sum[33];\n   if(dt_opencl_load_program(dev, prog, filename, binname, cachedir, md5sum, includemd5, &loaded_cached)\n\n\n```\n. Thankfully, at least for this, pocl works.\n. Like with #1281, i'm obviously leaving it up to you to decide and merge it.\n. @upegelow \nWhile i'm near opencl code, i have observed a very painful pattern:\nif(dev_mem != NULL) dt_opencl_release_mem_object(dev_mem);\nIt is painful because practically all free() functions take NULL ptrs, and handle them internally just fine.\nSo having one that does not, is error prone.\nWhat do you think about extending dt_opencl_release_mem_object() to just immediately return if NULL is passed, and maybe automatically brush the calls to dt_opencl_release_mem_object() (dropping null check, where it is just the null check)?\nOr is there a deeper reason for this?\n. @upegelow just checking that last comment was not lost\n. In either case, after dt_opencl_release_mem_object() learns to handle NULL, i'll follow-up with a clean-up patch to not check for NULL.\nThankfully, we use C and such semantic patch is trivial.\n. We do not provide nor do we want to provide any binary builds.\n. Thank you for your contribution!\n~~Can you also check, does the Canon EOS 7D Mark II have this same format?~~\nhttps://redmine.darktable.org/issues/10235\nEdit: aside from white levels, the 7D Mark II sraw's are already fine.\n. @stloeffler thank you!\n. You did check that with just the uncompressed mode, darktable still can open that sample?\nIf there is no mode selection, i would expect it to write just the compressed-one.\n. @schenlap thank you!\n. @schenlap thank you!\n. @schenlap thank you!\n. @schenlap thank you!\n. @schenlap thank you!\n. What i do not understand: why is it multiplied by the some white balance multipliers? \nIs that still actually needed?\nFWIW i saw no difference in the output image with old and new color matrixes.\n. Looking at this in more detail, the only difference i see is the Kelvin temperature that is displayed in white balance module.\nThe output image looks identical to me.\nAlso, camera neutral preset, with git master it results in ugly red tint.\nIt was kinda hard to find.\n. @schenlap thank you!\n. @schenlap thank you!\nThough, based purely on that rawsamples.ch sample, i wonder if ADC has wrong white level here, the image looks kinda dull.\nMust be due to the camera's age...\n. @schenlap thank you!\n. @schenlap thank you!\n. @schenlap thank you!\n. Huuh, why does it try to fetch http://docbook.sourceforge.net/release/xsl/*\n. @upegelow \nam i missing some packages? \nwhy does it try to get xsl from the internet?\nhttps://travis-ci.org/darktable-org/darktable/jobs/168018281\n. Hmm, well there is docbook-xsl let's see what happens if i add it into dockerimage..\n. @upegelow yep, adding docbook-xsl fixed it, apparently.\n. It works, but what i don't like is that the build process just stalls for a few minutes on\nBuilt target target_media_images\n. Update: it seems the command that takes this long is\n[292/294] cd /build/darktable/doc/usermanual && xsltproc --xinclude --output /build/darktable-build/doc/usermanual/darktable_profile.xml xsl/darktable_profile.xsl darktable.xml\nNot exactly surprising though :(\n. @upegelow before i even try to dig it any further, there isn't newer, more modern xsltproc that is fast?\n. @peterbud for stylesheets, install docbook-xsl, see https://github.com/darktable-org/darktable/blob/master/Dockerfile#L78-L79\nPS: unless we manage to bring time make darktable-usermanual to under 5 minutes (3-4 min is ok), there won't be CI for usermanual.\n. Hm, yes, that could work for now.\nBut the final point of this pr is to build the usermanual, so that the current version (git master) can be automatically uploaded somewhere on dt.org\n. Ok, validity check for usermanual is good-enough for now i'd say :)\n. Does not warn about missing files referenced by <graphic fileref=\"name.jpg\" /> :(\n. So i take it most old-ish 12-bit cameras indeed have white level of 4095, seems realistic.\n. @schenlap thank you!\n. @schenlap thank you!\n. In light of all the comments, could you please just open a new issue (Tracker = camera support) https://redmine.darktable.org/projects/darktable/issues/new and attach the raw image (pef, + dng if camera can write it natively).\n. @nijel thank you!\n. I will merge this.\nThat is a separate issue, feel free to open new bugreport to track it.\n. ~~The actual problem here, i think, is the seemingly different black levels though.~~\nI rechecked, and based on the current samples you are right, only the 12bit raws from D5 have blacklevel of 100, all 14bit have blacklevel of 400.\n. @schenlap thank you!\n. So clReleaseMemObject() is okay with NULL, and checking for non-NULL before calling dt_opencl_release_mem_object() is completely unneeded?\n. Ok, just checking because i see no if(ptr == null) return; in dt_opencl_release_mem_object() yet, and no NULL checks here.\n. I'm guessing 5d96d761ef283fc8ef28e6c6905047f2973e637e caused merge conflicts here.\n. @schenlap thank you!\n. Yep, seems ok even with no crop. Must be to mimic camera jpg, which may not do proper border handling.\n@schenlap thank you!\n. Can you show some actual errors that happen without this?\nBecause i'm mostly sure that CMAKE_REQUIRED_FLAGS is internal to that specific macros, and should not overlap between C/C++.\n. > This is because a previous call to CHECK_COMPILER_FLAG_AND_ENABLE_IT() set CMAKE_REQUIRED_FLAGS from CMAKE_CXX_FLAGS, and CHECK_C_COMPILER_FLAG that is called afterwards inherit it.\nDoes it? I'm sorry, but i do not see where that happens.\nAlso, which cmake version is that?\n. Right, sorry, initial explanation was not obvious.\nTested, reproduced, seems to work.\n. LGTM.\n@schenlap thank you!\n. @schenlap thank you!\n. @schenlap thank you!\n. > nikon_override_auto_black is ignored for this camera (checked with debug output in NefDecoder.c:577), so remove it.\nOk, i have checked with a simple script, and it seems that all the nikon cameras with black != 0 were added by us during this mode check.\nrawspeed-check-drop-hint.rb\nI.e. after i have 'changed' the meaning of that hint.\nSo i'll directly proceed to simply dropping that hint altogether.\n. @schenlap thank you!\n. @schenlap thank you!\n. @schenlap \nE8400 sample - https://redmine.darktable.org/issues/8479 - \"12bit-uncompressed\" is the only mode acc. to PDF usermanual\n. Ugh, i thought i checked.\n@schenlap i guess we are done with the white levels then (until the owners of last 4 cameras surface), thank you very much!\n. Looks good. Any other places like this?\n. $noiseprofile is also used on the line 183 of that same file.\n. Or, i could just merge this as it is :)\n. It's hard to keep disscussion constructive when the questions are being ignored :)\n\nFinally I'm planning to create a decent installer package using cmake and NSIS later, as users are expecting a binary distribution format.\n\nSince you will ignore our words anyway, i'm gonna go forward right now and state the same as with, parta: you must specify really clearly that that is not darktable and is not related to the darktable in any way, and no one should report anything about it's brokenness to us.\nLet's try this again.\nThis mail did state the view on the subject of at least some of the developers: https://www.mail-archive.com/darktable-dev%40lists.darktable.org/msg00344.html\nNow, tell us: how exactly does this not go exactly against the points raised there,\nin particular, about new pile of bugs and no developer to handle it?\n. Just want to point out that from our point of view the code changes to build on windows, the windows port and \"darktable\" for windows is the same thing. And we have already stated our view on the latter.\nIt may be better to go help out some other free software project that already had the misfortune of working on that platform, from what i gather gimp is seriously lacking help and they are much more friendly and welcoming :)\nOtherwise, the 'last' part of the mail explained the way quite clearly.\n. @peterbud \n\nDear Roman and Pascal, this is my first contribution to the darktable community, so I don't have any history of ignoring words.\n\nRight, now that i have actually checked, in https://github.com/darktable-org/darktable/pull/1327#issuecomment-255797911 \"It's hard to keep disscussion constructive when the questions are being ignored :)\" was said because i just assumed you were the same person who started last thread about this https://www.mail-archive.com/darktable-dev@lists.darktable.org/msg01242.html\nAs you see, i did ask the same question, and IIRC did not get an answer..\nSorry.\nBut as others said, the mail more or less summed up the steps (at the end of the mail), not sure there is anything for me to add right now.\nDo talk to us, do help with the normal issues, and maybe with some time..\n. In BUILD.txt, i'd simply link to the relevant section of appveyor.yml\nIt should be:\nSET \"PATH=C:\\msys64\\mingw64\\bin;C:\\msys64\\usr\\bin;%PATH%\"\nC:\\msys64\\usr\\bin\\pacman --noconfirm -Syyuu\nC:\\msys64\\usr\\bin\\pacman -S --noconfirm mingw-w64-x86_64-{stuff}. Keeping the exact same commands to install deps in two places (appveyor.yml and /packaging/windows/BUILD.txt) makes it necessary to keep them in sync, and opens up issues like that. I'd just link. > Try this version - https://olgabatalina.ru/dt/darktable-2.3.0-win64-generic.exe (All processors)\nWhere can we see the code diff? :). As i hope you understand, that did not answer my question.. > You answer for this one?\n\nhttps://olgabatalina.ru/dt/rawspeed.patch\n\nThat if you C++-ify the code, and add a unittest; which fails without, and passes with the patch, i'd consider merging it.\nPS: once there is 'official' win build, everyone who wants to help with that (currently by providing their own build), ideally, should cooperate. In other words, 3rd party builds would be, ... unwanted?.\nThankfully, so far @peterbud appears to fully qualify to all the ridiculous criteria which were specified in the Mail / first few comments of this PR.. yep, look good.\n@schenlap thank you!\n. No, they were properly merged into our git master.\nIf the only changes in your local git master are these translation changes, then i'd do:\n$ git checkout -f master && git reset --hard upstream/master\nIn future, this is exactly why it is better to make changes in branches, and keep git master branch in sync (i.e. no commit on-top of) with the upstream/master.\n. @schenlap thank you!\n. @sbraitbart you will now again have the same issuse as in #1331\nBetter commit not into master branch in your local clone.\n. git fetch --all -p\ngit checkout master && git reset --hard upstream/master\ngit push origin master\ngit checkout -b translation\ngit commit\ngit push origin translation\nAnd then just create pr to merge your translation branch into darktable-org/darktable, branch master\nThe reason being, not all the git merges result in the commits being added to the branch with the same commit id's.\nAnd if commit id changed, git may be not smart enough to automatically handle it.\n. It indeed appears to be faster. Not sure which -jN it should be.\n. Oh, and commit msg is useless :)\n. Tested, works.\n. Thanks!\nPlease start the first line of commit message with saying what area of code it changes, e.g. this should have been something like Liquify iop: modify_roi_in(): calc pipe_rect in doubles. Fixes #11271.\nElse cherry-picking is a major PITA :(\n. Summon @bronger \n. @bronger: sorry, i should have asked the question right away: \"from the lens distortion correction standpoint, and the geometry change, just checking the edges (top row, bottom row, left column, right column, i.e. all four edges of rectangle) of image is really enough?\"\nI.e. i think i'm asking, there can't be some brain-dead transform that would put the pixels from the center of image at the edge of the image?\n. Someone else who does export to fb should test this.\n. I got @patdavid to try it, and it did not work for him.\n@chubinou you are sure that it is currently working, and no other changes are needed?\n. @chubinou thanks.\n. @schenlap thank you!\n. No, we are NOT in a string freeze, yet. :)\n. @moy thank you.\nPlease do send more fixes like this, before we go into string freeze.\n. If you want buggy, you have certainly added the tooltip to the correct area of dt code :(\n. Typo fix picked though a1985d4762941b991a7d6ad6b43fb656bcb1c266\n. @moy i do like such write-ups, but i also mostly agree with @houz, they just don't seem to fit into RELEASE_NOTES, \"TL;DR\"\nAlso, they may be of some interest for other than the RELEASE_NOTES, maybe usermanual should have some kind of overview of dt releases, and it should be there?\n. 1. There are other format(printf left in the code.\n2. What about printf(3), etc? Is it defined with gnu_printf? Because if not, changing just the our wrappers is just part of the problem, which may it is the wrong solution.\n. Hm, clang does not support it? Strange.\n/build/darktable/src/external/rawspeed/RawSpeed/AriDecoder.cpp\nIn file included from /build/darktable/src/external/rawspeed/RawSpeed/AriDecoder.cpp:2:\nIn file included from /build/darktable/src/external/rawspeed/RawSpeed/AriDecoder.h:25:\nIn file included from /build/darktable/src/external/rawspeed/RawSpeed/RawDecoder.h:4:\n/build/darktable/src/external/rawspeed/RawSpeed/RawDecoderException.h:28:53: error: 'format' attribute argument not supported: gnu_printf [-Werror,-Wignored-attributes]\nvoid ThrowRDE(const char* fmt, ...) __attribute__ ((format (gnu_printf, 1, 2)));\n                                                    ^\nUnless it does, i guess we can not use it.\n. Yep, not supported even by clang git master, https://llvm.org/bugs/show_bug.cgi?id=15847, while we say we should be fine with clang-3.3+\nSo this won't work for us, unfortunately.\n. Yeah, i think some branches are mixed up here :)\n. @derknipser just mail me the updated extract_wb\n. > black levels look strange, but i got this results....\nThat is actually more plausible than single black level for all ISO's\n. Btw, since there is no crop, there is obiviously no black areas, so it means there must be some exif tag that rawspeed decoder should read and use as proper blacklevel.\n. @schenlap thank you.\n. Seems to be finally working.\nIt looks for the same clang version as the LLVM found, so it works even if CC is not clang.\nOptionally, we could split it into separate travis job, if wanted.\n(i did not because 2x make testcompile_opencl_kernels takes less time than the current container startup time overhead, i.e. there wouldn't be any serous time difference.)\n. When i start dt with these changes, i get:\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1252, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1253, function dt_collection_image_offset_with_collection(): bind or column index out of range\n. BTW, i wanted something like this, but specifically for darkroom view.\nSo if this works in the end, i'd take it.\nAlso, do note that we are in feature freeze, so if it is going to be merged, it probably won't happen until after we release 2.2.0\n. > Please ignore the extra commit messages (and please let me know if there is a better way to sync forks?).\n$ git checkout -f master  # switch to the master branch, in clean state\n$ git fetch --all -p # get all the changes from all the remotes\n$ git rebase upstream/master master  # rebase your local branch on top of our git master. this *should* be no op, because you should not have any changes in master branch\n$ git push origin master # update the master branch in your github repo fork\n$ git rebase upstream/master <yourbranch>  # now, the fun begins :D rebase your local branch on top of our git master. this is likely to report conflicts. you must fix them locally. maybe use something like meld tool\n$ git push -f origin <yourbranch>  # *force* push updated branch to your github repo fork. Last-minute new feature addition into masks(!) is the worst.\nJust saying.\n. > Well, and now?\nDon't know.\n\"Just saying.\" was supposed to convey that i'm not completely against merging this now, but rather just not happy about it.\n. > Not being happy is not a call for action.\nNow you got it :) That was the point.\n. BTW, we want rc1 soon (preferably by the end of this week), and i think we will also hard-string-freeze at the same time.\nSo if you are certain about merging, better sooner than later.\n. https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md#code\n. I was specifically linking to:\n\nCode\nBefore you spend a lot of time working on a new feature, it's always best to discuss your proposed changes with us first. The best place to do that is in our IRC channel on irc.freenode.net, channel #darktable or the development mailing list, see here for more information. This will dramatically improve your chances of having your code merged, especially if we think you'll hang around to maintain it.\n. @itinerarium thanks, merged manually. commit messages are rather useless tbn :). Can't even agree on a variable name :(\nThanks for bringing this up, i do not really need that (NSIG) value, just the code seemed better with it.. @mazhe thank you.. > all in all the clipping module is totally screwed and needs a major/full rewrite.\n\nYep. lensfun-0.4.0 will have perspective correction stuff we need, so i think at this point it is best to simply wait until it is released, and do not even attempt reworking c&r.. For that exact reason, splitting clipping.c into just the crop tool, and doing a clean re-implementation of perspective correction/keystone/rotation features from the scratch using lensfun PC stuff may result in not-so-disastrous code.. > We still need to maintain the old mess for legacy history stacks. Or deprecate c&r and write a new crop tool.\nExactly. Current clipping.c would be deprecated, and new cropping.c would be added.\n\nHowever, from a user's point of view I wouldn't like to need to switch modules for cropping and rotating. So this isn't straight forward at all.\n\nTrue, will not argue there.\nThis is not set in stone, but there are really good reasons to do it this way.. > Let's also first see if lensfun brings enough to the table.\nI want to revamp current lens.c anyway, and change it's place in pipe.\nSo it wouldn't even be a modification of lens.c, that iop would get deprecated too.\n\nAfter all rotation and perspective correction are not directly lens bound\n\nGenerally true, but depends whether you want to get better results or not.\nI think, e.g. if you want to straighten horizon, it needs to be bound to lens, @bronger can correct.\n\nand can be implemented in a straightforward way with homographic conversions\n\nNot arguing there. However so far the lensfun-based lens.c managed to not get overly bloated/complicated/broken. Therefore i do not think that moving interpolation stuff from clipping.c into it would make it worse.\n\n(like in ashift). \n\nI'm hoping to re-use it's ui/sampling as an input for perspective correction.\n\nI am a bit concerned to rely on a fresh implementation in an external library as any incompatible changes in that library will put the burden on us to guarantee legacy behavior.\n\nIt for sure has much more tests than we do have :)\nhttps://github.com/lensfun/lensfun/tree/master/tests\nBTW, http://wilson.bronger.org/lensfun/perspective-correction.html. > Travis reports errors on MacOS but I don't think they are related to this PR.\nIndeed they are not, #1365. I'm gonna close and immediately reopen this just to re-trigger ci.... Yeah, something is strange, i'm thinking pugixml-1.8 homebrew formula is borked, but i have no way to prove it, or to check, really. Not sure why else it worked with 1.7 and fails with 1.8 (for homebrew only)\nhttps://github.com/Homebrew/homebrew-core/commit/556a412cad8d1e2b9ac3b5b449551da2a40d0d18. > PKGCONFIG\nYes, and this pr changes FindPugixml.cmake to actually use that pkg-config.\nSo i'm not sure why we end up with Pugixml_LIBRARY that contains invalid(?) lib, according to cmake:\n+cmake --build /Users/travis/build/darktable-org/darktable/build -- -j2 -v\nninja: error: '/usr/local/Cellar/pugixml/1.8/lib/pugixml-1.8/libpugixml.a', needed by 'src/libdarktable.dylib', missing and no known rule to make it\n+cmake --build /Users/travis/build/darktable-org/darktable/build -- -j1 -v -k0\nninja: error: '/usr/local/Cellar/pugixml/1.8/lib/pugixml-1.8/libpugixml.a', needed by 'src/libdarktable.dylib', missing and no known rule to make it\n. > Hmm pugixml/1.8/lib/pugixml-1.8/libpugixml.a ?\n\nNormally the static library is installed ${PREFIX}/lib/pugixml-1.8/libpugixml.a\nseems pugixml/1.8/ at the beginning like an error.\n\nTrue, but it seems consistent for all the homebrew-provided formulas\n\nBut I have 0 experience on homwbrew/osx\n\nMe too :). The file timestamp is the culprit, apparently.. I guess it does make sense from deterministic/reproducible builds, as @houz suggested in IRC.. @peterbud though the more important lesson here is what such null timestamps to to ninja and ld.. @schenlap thank you!\n(did not read the pdf graphs). @schenlap thank you!. @schenlap thank you!. @schenlap thank you!. @upegelow thank you.. > but doesn't eliminate edge artifacts.\nBriefly discussed in IRC, not for release.\nThe final version can always be cherry-picked for next point release.\n@dtorop thank you for looking into this!. Very good description of the problem.. > we are deep in RC territory.\nIn fact, we already had the last RC before the release. @boucman feel free to merge this one if you think it makes sense.. po/uk.mo should not be here.. no, just remove it as a new commit in this branch. @alkhimmikk thanks, squash-merged in order to avoid that .mo from appearing in history.... travis really does not like when there is a branch and a pr, and i do not see an option to make it build only one :/\n@TurboGit thanks, merged.. @TurboGit oh, one more thing while i remember,\nyou could say \"Fixes #redminebugid\" in commit message, and once that commit is in master branch, the issue will be automatically properly closed by redmine.. BTW, i do think that CMake's FindThread (or any std module) should be used if possible. > Should I try to deprecate the internal FindPthread.cmake module in that case?\nI think we should try that, yes.\n\nI'll have a look at the functionality it provides over CMake's FindThreads\n\nChecking that we indeed found pthreads after find_package(Threads REQUIRED) + doing this -pthread flag magic (is it actually needed though, i'd think that cmake would handle it internally..) should be equivalent to what we currently have.. Ok, so github does not recognize that pr has been merged db0f0ee9535464709a15893616d79d435a67379a if it was squashed locally.\nGood to know :/\n@mazhe thank you!. @dtorop Re\n*outc = (uint16_t)((float)col / (float)num);\nAll three variables are integers here. So without explicit casts, that would be an integer division, which is not nice. I'm not 100% sure float division is needed here, but i also really doubt that it is the biggest hotspot in this function.. > As dt_iop_clip_and_zoom_mosaic_third_size_xtrans() is only in the preview path, calculating uint16_t and throwing away the fractional result should be acceptable?\nHmm, wait, the fractional part after col / num is always < 1.0, right?\nThen yes, probably no need for floats...\nIn sub-pixel sampling/SSE case however, it will probably be simpler to cast the input value to float upon loading, do everything in floats too, and only then cast back to uint16_t for output.. > It may turn out a better option would be to downsample X-Trans images by a factor which is a multiple of 3 in @_init_f()@ (and Bayer images by a factor which is a multiple of 2)\nActually, that was my initial implementation, see https://github.com/darktable-org/darktable/commit/188613940e9e985868e823ffd1b26ec6c99fc02d and https://github.com/darktable-org/darktable/commit/341c5746ce78b1363482970e85f8c4114c88346a\nIt was producing unsaticfactory results, so as git log tells, i ended up with the current approach.\n\n, then scale them down by a non-integer factor as needed during the mosaic iop, when they become 4-channel.. > fast results\n\nDo note that MIP_F is generated only once, when entering darkroom, and then it is cached.\nSo speed is not /too/ much of a problem.\n\nBut I am curious why your binning implementation wasn't good enough\n\nJust checkout 3f8ca970bd290f2e52c9b2d2d800f3446a84c004 and look at the thumbnail.\nIt is worse than what we have now i'd say. For bayer, lacks sub-pixel sampling.\n\nintuitively that seems the cleanest plan.\n\nIndeed, that is why it was my first attempt.\n\nI'll plow ahead and make the best version I can of that\nI'll take another look at that as well.\n\nI'm hoping that i simply had some stupid error there, and it will work otherwise...\n. > I had no luck getting 3f8ca97 to run -- lots of complaints about 0 param size in raw overexposure module, but didn't spend too much time on it.\nYou need to rm -rf /opt/darktable or whereever you install . I do agree with @hanatos, the results are promising.\nBut. There are still some artefacts, on high-contrast edges, e.g. see https://www.dropbox.com/s/x5msf9n8rs1u70m/fujifilm_x100s_09.raf?dl=0\nAnd, it looks way too blurry, almost as if out of focus.\nI'm sure i would not like that on bayer codepath..\nSo i guess it is going in the right direction, but some changes to blur are needed.\n. With #1382 merged, it does not look as bad. But there are artifacts still.\nSo @hanatos if you want to merge as-is, i'd be ok since this is X-Trans only.. This is for 2.2.x branch, the same should probably be done for master too. @schenlap thank you!. @TurboGit could you please either merge this or close the pr :). @TurboGit TurboGit was assigned by upegelow on Jan 7. @mcaimi thanks!\nThis was the first time with camera support in two parts/repos. \nI guess the approach is right, 2 separate pr's to two repos, which then will be manually merged.. 1. I have tested this on Linux, with KDE. It does not seem to break anything\n2. But, is there no desktop effect that darkens the parent window when there is a modal window opended/selected? I suspect that would be a issue.. > On macOS, there is no optical difference in the parent windows.\nNeither do i see it here. But if it happens (the optical difference), it can happen on any platform.. Is this for integration as-is, or is this incomplete?. And it of course re-introduced bug #11340. We don't have a stable release manager, hopefully someone will pick it.. @schenlap thank you!. @schenlap thank you.. @schenlap thank you!. not before #1420. What about using native styling abilities, like with #iop-plugin-ui?. For me the rgb part is there to tell what the function expects as a parameter, the color? pattern? kitten?\nSo rgb should stay.. By default, https://github.com/darktable-org/darktable/blob/48fae49e683f0fc1141677f07059796c6cd30984/src/libs/tools/filmstrip.c#L180-L181, while some image is selected and/or highlighted in filmstrip. And, it is always a good idea to test all the changes :). @shoffmeister anything up to ~64bytes i'd consider to be really ok :)\nMore specifically, i agree with the GTK_RESPONSE_OK part.\nI've been meaning to post that myself, but did't. @schenlap thank you!. > I do understand that this PR makes the Markesteijn code diverge yet more from what is in dcraw\nI'm not sure that is a bad thing at all :). \"biais\", is that a word? maybe \"bias\"?. @schenlap thank you!. @codingdave you really should work on a branch, and keep master branch of your clone completely equal with master branch of the upstream. See https://github.com/darktable-org/darktable/pull/1333#issuecomment-256901492\nBasically, at this moment you should do:\n```\ngit fetch --all -p\ngit checkout master && git checkout -b issue-11484\ngit checkout master && git reset --hard upstream/master\ngit push origin master -f\ngit checkout issue-11484\n\nsee edit below <\n```\nAnd then create a pr from origin/issue-11484 to upstream/master\n\nAlso, better commit messages are really welcomed, especially the first line.\nAnd, if the commit fixes a bug, say \"Fixes #bug\" in commit msg.\nEDIT:\ngit checkout issue-11484\ngit rebase upstream/master issue-11484\ngit push origin issue-11484. Doing any kind of demosaic and then throwing away data seems unnecessarily computationally-intensive... I'd love to see the @hanatos idea in code :). @schenlap thank you.. I suspect the final handling maybe should more generic, not per-iop.. Not much for me to review, since i can not reproduce the initial problem.. Aha, okay, then will test.\nThanks for the tip.. Ugh, keep forgetting to take a look at this..\nHopefully tomorrow.. Sorry, unable to reproduce even with dt_iop_nap(500000); in dt_dev_invalidate()\nI won't be of any help here.. That last clang-format commit, don't do that.\nAlso, commit messages are rather useless, and that is very common for github :/. It formats the whole file, which is rather irrelevant for this pr\nAnd it turns the diff into pure unreadable garbage.. @theres\nok, desync seems to be gone.\nBut, did you change the way draw node coordinates on tonecurve chart are printed?\nThey look different now, in right-bottom corner (which always will have histogram, unlike top-left corner), with same dark color as the underlying histogram. Rather unreadable i'd say.. @schenlap thank you!\nschema needed updating, fixed when merging.. So it is done in camera rgb colorspace.\nCan it be done in Lab?. Also, commits are dubious.\nIf the history is important, then they should have much better commit messages;\nIf it is not important, there should be just one commit\n. > temporary storage of about 6 times the size of the input image.\nThat is HUGE. Even the equalizer may be sometimes less hungry.\n\nThe problem is that the algorithm has to estimate the global background light from the whole image first.\n\nDoes it need all that memory to estimate the value, or the memory is only needed later on to process?\n\n(I adapted this mechanism from the globaltonemapping module.)\n\nColorreconstruction / ashift is probably a much better, modern example.\n\nThis, however, does not work in the EXPORT pipeline because it does not have access to the gui data. \n\nSome time ago i played with the idea of adding a sample() callback, which would be run before the process(), and with the full input buffer. As long as the sampling itself is not too memory-hungry, that would be the solution. I never finished that code though.\n\nAt the moment I think the only possible solution to reduce the memory footprint is to implement a tiling algorithm within the process function.\n\nIIRC in colorreconstruction module, which also has this problem, the tiling is simply disabled.\n(Do note that tiling issue and PREVIEW issue are similar but different). > \"auxiliary\" pixelpipe\nYou mean, it would process downscaled version of the image before processing the full version through the export pipeline?\nThat could work, but it has obvious downsides: the image needs to be downscaled, and the additional pipe needs to be run, with all the problems that come with that.\nThe sample() callback approach would not need any of that. Since we already always have full input buffer (at least when processing on CPU?), it'd just work.... What did the release notes say? If you git log release-2.2.5, can you find anything about this module?. That is why there are release notes, to be able to find out if something is in the release or not :)\nThis is a major feature, and 2.2.5 was just a point release. Thus it will be in the next major release (2.4.0?). https://redmine.darktable.org/issues/11854. @schenlap thank you.. To https://redmine.darktable.org/projects/darktable/issues/new\nWe need to see the plots. Else it is impossible to say whether the profile is good or not.. @DawidLoubser Hi!\nDo you still have Olympus OM-D E-M1 Mk.II camera?\nI'd love to get the full sample set from that camera for RPU.\nIf you can help, it would be awesome if you could take all the following shots, and upload them to RPU\nLooking at the pdf usermanual, it seems it can produce more than one different raw output (Record mode and file size/ number of storable still pictures).\nThe camera needs to be stable (tripod), in the landscape orientation, and the scene should be as static as possible (i.e. all the raws must contain the same content)\nRecord mode that are interesting:\n RAW - should produce one .ORF raw\n 25M F+RAW - not sure what to expect, might produce 4x.ORI and then 1x.ORF\n* 50M F+RAW - not sure what to expect, might produce 8x.ORI and then 1x.ORF\nI do NOT care for the jpeg's it will produce, just ignore them, but do upload all the raws.\nI will weed-out the uninteresting duplicates.\nPreferably, rename them appropriately before uploading :). @atarijedi please upload each separate image excluding JPG's to the https://raw.pixls.us/ !\n(i.e. not as one archive). @atarijedi thanks, but i'm afraid that is not quite what i need :(\nThe normal raw (Olympus_EM1mk2_Standard_20MP_ColorChecker.ORF) has different content from the other raws :( I need all the raws to have exact the same content.\nSo if you could, please redo all 5 shots :/\n(it might be better if it is some outside nature landscape, but this is good too.). Ok then, thank you, validated!. Why do you think it would use X-T2/X-Pro2 color matrix, while both Fujifilm X100S an Fujifilm X100T use the same matrix, which is not the same as for X-T2/X-Pro2?. > The X100F uses the 3rd gen. sensor (https://en.wikipedia.org/wiki/Fujifilm_X-Trans_sensor#List_of_X-Trans_sensors) which it shares with the X-T2/X-Pro2, so more likely its characteristics align with those than X100S/X100T.\nAha, okay\n\nIt looks like Adobe DNG Converter doesn't currently support the X100F (see https://helpx.adobe.com/camera-raw/kb/camera-raw-plug-supported-cameras.html#Fujifilm), and dcraw doesn't have an entry.\n\nYeah, all that i have already checked before commenting :/\n\nIs there any other way to figure out a matrix?\n\nThe adobe matrix - not that i know of.\nBut one can of course shoot color target and compute color matrix for himself.\n\nleave this open/incomplete until a proper matrix is published, so in the meantime anyone who needs a quick fix of X100F support can pull it in by hand?\n\nThis, i think.\nOnce the matrix is known, this is to be updated and merged.\n\nPresumably any images edited with a wrong matrix will need to be re-edited?\n\nYeah, currently the color matrix is not stored in history stack, so any changes (i.e. if we replace matrix) essentially destroys the history stack\nThanks for verbose reply.. @dtorop i think the matrix has arrived.. @dtorop, @schenlap: thank you both!. But the bugs seem to be in Gtk, not in darktable, correct?. @dtorop, @schenlap: thank you both!. Waiting for rawspeed part :). @sbraitbart i would recommend reading some articles/tutorials about git, it indeed takes some time/thought to get used to/understand...\nRelevant:\n. /me has just noticed that he is requested to review this\n@upegelow leave a comment summoning me once you are done making changes :). @upegelow i will attempt to review this on the upcoming week.. Right, i guess i'm expected to actually test this as a next step... So i have finally tried this (cpu only).\nAll blend modes seem to work (as in, do not crash, do not so some bad stuff like buffer overflow).\nIt seems that they do what they should.\nThe \"display channel\" feature is interesting!\nBut the discoverability of that feature it even lower than usual for dt features :). Perhaps someone else should try this first too\nBut otherwise i'm not really seeing anything worse than we already have.\nI.e. probably ok to merge.. Not commenting about smooth scrolling at the moment.\n\n(say either dt_ui_get_scroll_delta_y() or dt_iop_gui_get_scroll_delta_y() and then another to get/accumulate integral scroll values) to cull out a bunch of this repetitive code.\n\nYeah, it does make sense. Duplication is not good.. Sorry, i keep meaning to re-review this pr, and then get carried away. Will try to look at it tomorrow.. @dtorop see https://redmine.darktable.org/issues/11594. @magicgoose i accidentally butchered make/model reading in 2.0.6(?)\nIt is fixed in git master/2.2.x branch, but the fix is not in any of the released versions.\nWe really need to release 2.2.4. @schenlap thank you.. i say many things, but in this case i certainly did not insist\n[18:54:54] <LebedevRI> very obviously misleading indentation\n[18:55:18] <m-a> the question is, weasel out early, or add { } and indent? \n[18:55:38] <m-a> and if we indent, to we want an \"else\" branch?or will we just leave the \"couldn't locate primary CRTC!\" message?\n[18:55:52] <m-a> ouch, my spelink\n[18:55:54] <LebedevRI> i'd move the code into separate functions, for starters (https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md#coding-style may help) \n[18:56:52] <m-a> thanks for the pointer\n[18:57:13] <houz> i'd just add {} and indent and be done\nthat's @houz's code, so he has the final say. @schenlap thank you!. > * Pressing ESCAPE now closes the floating window.\n\n\nClicks outside of a bauhaus combobox will close the combobox.\n\n\n\ud83d\udc4d. So i have finally just tested it, i think this is good.\nI think it's best if @houz / @hanatos could try this first.. @schenlap thank you!. @peterbud thank you.. @schenlap thank you!. [16:57:42] <hanatos> LebedevRI: yes, sounds like a good idea to replace that profile then. @schenlap thank you.. @schenlap thank you!. Forgot to close. The pdf graphs will be needed anyway, to be able to actually review the profile.. Best to open new redmine issue, and attach it there\nWill not get deleted after some time, too. @thorenx in future, it is much better to branch, and submit a pr not from master branch.\n@schenlap thank you.. @amueller\nThank you for your contribution!\nHowever, we have no means of checking the validity of the these custom base/tone curves, and we do not think it's a good idea to merge them as is, because IIRC we have already seen broken curves.\nOnce we do, we will announce it.. The most important part of each and every PR is not the changes (diff) but the commit message, pr description, etc. Just dumping some random changes, no matter if they allow to create gold from thin air, or something, is still just some random changes. The need for the changes needs to be explained, the benefit of the changes needs to be explained, the consequences need to be explained. Ideally, choice of the implementation approach should be explained, too.\nI'm not seeing any of that in here. And even more, any mass automatic code changes are best done by someone with commit right, because then there is less of a need to re-read all the changes.\nSo i'll just close this.... @schenlap thank you and the original author.. @schenlap thank you.. Does this some issue listed in redmine?\nCC @boucman . @theres while not directly a feedback about these changes, but still\nPlease, write meaningful commit messages. First line should be under ~70 symbols,\nand must fully describe the commit, and ideally should start with some prefix to\ndifferentiate general area of the code that commit is about.\nE.g. these commits should have a subject of something like \nLua: container widget: fix access to children by index\nIf the commit messages are not meaningful, it is really painful to do cherry-picking to stable branch. @schenlap thank you!\nPicked to 2.2.x, too. As soon as someone who can read those plots verifies them (hint: that is not me). Sounds like it's fixed :). @schenlap thank you!\nAlso, wow, #1500 .... @schenlap thank you!. I will not be able to review this, partially due to the lack of opencl.\nIf it builds, and the results make more sense than they currently do, feel free to merge.. @schenlap thank you!. It's not that we don't see the profiles in redmine/maillists.\nIt's that someone knowledgeable needs to review the plots and PDF and veto whether this profile is good to go or not.\nAt this moment in time i think only two persons both know how to do that and actually do that (@hanatos & @schenlap), and everyone has only so much free time.... > Why not move issues to GitHub?\nHow does it help anything? If there is one mouth, it does not matter whether you drink your tea/coffe/water/etc from red cup or from white cup.\n\nThen why have all profiles submitted to GitHub over the past year been merged\nPR here definitively get more attention than submission on Redmine.\n\nI guess the logical answer is right on the surface. As you can see, majority of these noiseprofile PR's from the last year have come from a @schenlap who has demonstrated an ability to validate noiseprofiles, thus once such a pr is up, i pretty much merge it right away.\nI'm not sure what other answer you wanted to hear.. @schenlap thank you!. Please learn git :)\nThere is practically never any reason to close a pullrequest.\nPullrequest is characterized only by two things - origin branch, that you want to be merged, and the target branch, into which you want to merge. As long as the origin branch exists, the pr will simply show any content that it has compared to the target branch.\nSo you can do any operations whatsoever on that branch, and it will just work.. > Not addressed yet is the transitioning to modern cmake with imported targets, as this would be more a darktable-wide topic...\nThat was not a review note, just a generic observation.. > With FDC demozaicing, highlight recovery doesn't work very well.\nProbably because of the CLIP(). Is it really needed?\nBTW i just feel like noting that we are in a feature freeze for 2.4.0 since Oct 4.. Regardless, you probably want to rebase it and make sure than none of the commits changes e.g. src/external/rawspeed\n\n@aurelienpierre \nOn a side note, @edgardoh and I will need FFTW3 too for the RL deconvolution module\n\nNot sure we like the trend of using some external libraries as hard dependencies for the whole modules.. > We (including @kubrickfr) have done quite some testing, without crashes.\nHave you used ASAN?. > Assuming we drop it for now, which seems to be the way this is going, what needs to happen in order for it to be accepted in the future?\nIt wasn't discussed as a temporary drop. >>> We (including @kubrickfr) have done quite some testing, without crashes.\n\n\nHave you used ASAN?\n\nMe not, @kubrickfr used Valgrind.\n\nIt would seem i need to further clarify on the downvote.\nThe downvote is not because @kubrickfr used Valgrind..\nThe downvote is because it seems you did not use anything.\nMost importantly, the downvote is because you [both?] still didn't use AddressSanitizer, at the end of 2017.\nThere is pretty much no reason to not use it other than either i don't know what that is or i'm maliciously/intentionally writing broken code.\nPlease waste some of your precious time, and learn about it.\nWith any luck you will be scared shitless that you weren't using it before then...\nHope that clarified it...\n(Note: since threading was discussed here, it would make sense to use threadsanitizer, but my previous expirience shows that getting it to work requires a lot of preparation.)\n. > I became sceptical and ran an ldd darktable and did not see lib asan explicitly.\nIt's linked statically by default, i'm not sure it will show up in ldd output.\n\nThen I ran and expected some output on the shell, but nothing appeared.\n\nI'm not sure what this means, did darktable not start? If it started, then just use it as usual, if an error is detected, it will crash and you will see the output in console.. Is this on a 32-bit or 64-bit systems?. > On 32-bit systems this will work for <4GB files. This is because the gphoto library uses unsigned long int to represent file sizes, which will be 32 bits in 32-bit systems.\n\nOn 64-bit system this fixes the file truncation problem, because a unsigned long int will have 64 bits (well, the C standard only says \"at least 32 bits\", but in practice compilers use 64 bits).\n\nFact: gphoto provides correct file size info, else nothing will work.\nWhat i was really asking is, what about -D_FILE_OFFSET_BITS=64 and it's friends?\n\nA way to fully solve this, as well as avoiding high memory consumption (since files are completely loaded into memory), is to not depend on gphoto to read files.\n\nDo you propose to implement all the camera operations ourselves?\nBecause currently libgphoto does all the talking and we can simply use it to get the data.\n\nIt does load the entire file in memory just to get the exiv2 \"datetime taken\",\n\nThe file is already in the memory, because we are going to write it onto disk.\nOr does the libgphoto provide a functionality to not read the file into memory, but directly save it into provided filename? But still, i bet internally it will still fullly read it into the memory.\n\nwhich could be done by reading it directly from the file (the exiv2 library supports that).\n\nSure.\n\nWe can then copy the file ourselfs and avoid the limitations of gphoto.\n\nCopy from where? How?\n\nI will take a shot at this approach and if everything goes well I will update the PR.\n\nYou are talking about two (three?) different issues here:\n1. darktable truncates large files when copying them from gphoto\n2. gphoto fully reads the file into memory, we then parse that buffer for the timestamps, and save onto disc\n   * If gphoto can save the file directly, and avoid huge memory usage, then and only then we could use exiv2 to get the timestamps from the file from disc.\nDo note *If** gphoto can save the file directly. If it can not, then the second part of your comment is a moot point.. > Nevermind. We need gphoto to read the file from the camera, since the camera fs doesn't need to be mounted.\nThat is the whole point of import from camera :). 1. 32-bit systems are practically not supported anyway.\n2. Let's not mix apples and parrots here. If this is about file truncation, then don't turn it into something else\n3. Using that functionality to import something that is completely unrelated to darktable (videos) is a total abuse.\n   We should either implement black/white -lists of file extensions / MIME types.\n   Or kill that whole functionality completely.\n   Seriously.. > Anyway, this how data should be written with write(). We always have to check and loop if there is still stuff that wasn't written.\nYes.. Right, sorry.\nI'm not really familiar with multi-gb file writing.\nSo what about _LARGEFILE_SOURCE / _LARGEFILE64_SOURCE / _FILE_OFFSET_BITS macros?\nAre they unrelated? Or is the current diff the right fix?. Some additional considerations to be had, from irc:\n[20:49:12] <LebedevRI> (what about the pr though)\n[20:53:26] <houz> reading man 2 write i see some more cases that we might want to deal with, for example ret == -1 and errno == EINTR -- should we try again?\n[20:54:47] <houz> and if i understand the man page correctly, on a full disk write may reutrn 0 which will send dt into an infinite loop\n[20:55:04] <houz> not sure if we can handle that though\n[20:55:49] <houz> and if we got an error, should we unlink the file we wrote to?. (BTW, we can detect infinite loops, by checking some bool flag, and if not set, setting it, and only then writing.). > If the input data is not given in this particular sorted order a wrong tonecurve is calculated.\nYes but. What is the actual problem?\nAre there color charts with such random order? From where does this unsorted problem comes from?\n\nThis means two of the gray input colors are actually discarded (the two brightest input colors are not used assuming the ordering mentioned above)\n\nI would guess it is a precausion against clipped colors that would throw off the fit, but then i don't know the real reasons... On Thu, Sep 14, 2017 at 11:34 AM, Heiko Bauke notifications@github.com\nwrote:\n\n@rabauke commented on this pull request.\nIn src/chart/main.c\nhttps://github.com/darktable-org/darktable/pull/1532#discussion_r138829190\n:\n\nstatic void process_data(dt_lut_t self, double target_L, double target_a, double target_b,\n                          double colorchecker_Lab, int N, int num_tonecurve, int sparsity)\n {\n-  if (num_tonecurve < 2)\n-    num_tonecurve = 2;\n+  // sort all gray patches according to the L channel of the source colors\n+  double grays = malloc(sizeof(double) * 6 *num_tonecurve);\n\nI configured git-clang-format and revised the code. It should comply with\nthe darktable coding style now.\nThanks, it does help. However when working on rather mis-formatted code,\nthe results may wary :/\n\nRoman.\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1532#discussion_r138829190,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAFaGFG92ZIi1HU1S3X9mbk9TXxrygImks5siOULgaJpZM4PVJkk\n.\n. This broke ./tools/create_release.sh and who knows what else.. https://github.com/darktable-org/darktable/commit/a598128c2f86990ef52f3d6802a53f6fd40934e3 did fix the problem. Yes, this is the correct protocol, and no, apparently there won't be any further 2.2.x releases, so no point in cherry-picking.. Nah, the exact names do not matter\nJust sync the changes back from rawspeed (e.g. [1]) if you really want to. And reverted, something broke.. And it's back.. This is the third pr, and both the previous two were closed by you.\nAll of them had a pretty large diffs, but zero communications.\nJust trowing code at us is not how it works, depending on the endgoal of course.\n\nSo i guess i have to ask, what is your agenda?. > This is my first pr and I don't know how things work, so my apologies if everything is not ok.\nThe first thing to do is to talk to us first, as it was suggested quite some time ago in the first pr\nhttps://github.com/darktable-org/darktable/pull/1090#issuecomment-167540635\nUnless somehow you are not the same gh user as ^ ?. I guess i will just squash-merge manually.. You may want to add some screenshots to better show what you are talking about.. will merge manually. Looking a bit more:\n$ dpkg -L clang-6.0 | grep -i cmake\n/usr/share/llvm-6.0/cmake\n/usr/share/llvm-6.0/cmake/ClangConfig.cmake\n/usr/share/llvm-6.0/cmake/ClangTargets-relwithdebinfo.cmake\n/usr/share/llvm-6.0/cmake/ClangTargets.cmake\nSo theoretically we could just do find_package(Clang ${version} CONFIG), and use \"$<TARGET_FILE:clang>\" and ${CLANG_INSTALL_PREFIX}.\nBut in practice however at least with the debian package, out-of-the-box cmake does not see those ClangConfig.cmake, probably because they are in the wrong place.\nWhen i was initially adding this opencl test-compiling, a bugreport was required to get get LLVMConfig.cmake installed into the proper place.. \nIs it me or this is super ugly?\nWhy does the \"scrollbar\" occupy only the right half of the space?\nOr, why is there so much space for the scrollbar?. > I think the space on the left of the scrollbar is the one around the lighttable center view.\nThat doesn't really make it less ugly, unfortunately. Think of all the OCD people this might hurt ):. > __WIN32__ is not defined with clang builds, I have replaced them with _WIN32\nI have not a single clue what the gore details are behind each of these name variants, but _WIN32/WIN32 (and not __WIN32__) is being used in rawspeed, and so far so good.\n\nI had to replace labs() with llabs() in one instance\n\nI think this is safe.\nThe g_build_filename() NULL termination is interesting, and not mentioned here.\n\nmms_bitfields\n\nMaybe @houz can chime in and tell why it was added in the first place in https://github.com/darktable-org/darktable/commit/a985f086a176de7d3c8b84afd3fa65d0cb83750e#diff-95e351a3805a1dafa85bf20b81d086e6R382\n  . Also, @peterbud, github does not know that commit identity, the email is not associated with github account.. So, good to go then?. It's not me who is unfortunate enough to use that system.. @pmjdebruijn isn't really involved with dt nowadays, other than PPA's.. > It appears the white balance module gets messed up when switching from a monochrome image -> a colour one in darkroom mode. \nThere is a long-known(?) problem that input color profile gets messed when switching from normal raw to e.g. JPG. This might be related.. > In this case, I just fixed reload_defaults to un-hide the enabled button.\nDid you push the updated commit? I can't tell from the diff and github does not seem to list the pr as updated.. > @LebedevRI @dtorop both default_enabled and hide_enable_button keep their old values when switching images in the darkroom view, that was the bug I was trying to fix.\nOh, uh. And looking at temperature.c, reload_defaults() does not do everything it should.. I'm guessing https://github.com/dtorop/darktable/blob/4f6bf45bc5b4eccd27a577dce7aa1866e4c62ef1/src/iop/temperature.c#L948 should contain\nc\nmodule->default_enabled = 0;\nmodule->hide_enable_button = 0;. @kelvie please confirm that it fixes the regression caused by #1631, so the things are back to the good #1621 state :). [unless something has changed] we don't merge those curves and custom color profiles\nNo methodology to verify them, no volunteer[s] to check the new submissions. > I looked back at the dcraw source and it's actually a right-shift in a correction function. So I really have no idea why the RAW files are so dark by default...maybe the back is just designed to leave a lot of headroom by default?\nCould be wrong white level that is being used by us, could be the broken decoding/correction.\nBut >>= 2U does not sound like the correct/sane solution.. Please don't touch the submodule, and don't use git commit -a :). Also, do open the issue in the redmine, please, so it can be referenced.. Also see https://redmine.darktable.org/issues/10569 (Not about this tag specifically)\n\nTL DR: yes, the fix is right, but it would break usecase of single XMP for multiple different(not duplicated) images, so until next big metadata handling overhaul, it will have to stay as it is.\n\nTLDR: can't be fixed.. In \n\nusecase of single XMP for multiple different(not duplicated) images\n\ni of course was talking not about dt proper, but dt-cli, where you can specify the sidecar to be used.. The base/tone curves aren't being merged (globally, not in just this pr)\nYou probably want to move white balance presets to a different pr\nSo this pr should only be left with noiseprofile. > Is it a requirement, to separate the white balance PR from the \"new camera support\" or just \"noise profile\" PR or what is the intention? Please shed some light about the workflow, because I am a bit confused.\nwb presets can be just merged, while noiseprofiles needs review.. What about X-Trans?. The mapping is: \n------------------| Column & 1 == 0 | Column & 1 == 1\n----------------- | --------------------- | ---------------------\nRow & 1 == 0 | black level 0        | black level 1      \nRow & 1 == 1 | black level 2        | black level 3        \nI'm not quite sure it is possible to express that in short nice words.. I hear you, but i still believe that being any more specific here will either result in overly long lines,\nor it will convey the wrong idea. It's not really related to the pattern, but to this 2x2 pattern grid.. > The slider rendering has 3 tiny issues.\n\n\nCharacters with descenders (like g, j, p...) overwrite the slider line.\n\n\nReally don't like this. It results in way more vertical space usage, for not much gain.\n\n\nThe slider indicator is overwritten by characters with descenders.\nThe bottom black outline of the indicator is missing\n\n\nI think these can be solved separately from 1.. These should be fine.. > @LebedevRI Have you thought of a fix like this in your post?\nDunno, i simply commented that increase in display real estate consumption is nearly-unacceptable.\nI can't compare these two images, since the background color is different.\nIs the iop highlighted in one but not another?. > Edit : And you'll even save more height space as bonus :)\nAnd either consume much more precious horizontal space (the sidepanel will have to be wider),\nor significantly reduce the length of the slider.. As i have said in the previous/original pr, i don't really feel this.\nOption 2.3 is probably a bug-to-be-fixed anyway.\nOption 2 1,2  - i'm not sure what this affects. OCD?\nOption 1 - i personally just don't see it.\nPlus, more options that no one will ever fully use, and more importantly, test.. Would be great to have.. This isn't a review, but i have a rather strong opinion on the location of this code.\nThe existing unbreak input profile module is 'designed' just for that - to cope with\nsome existing broken ICC color profiles.\nPlacing some new functionality to arbitrarily/artistically change the image into that module\nis just wrong.\nThey have nothing in common.\nAlso, i find it kind-of misleading to compare this with video encoding Log profiles (S-log, N-log, etc.).\nThe in-camera log profiles are only(?) there to preserve as much of the data as possible,\ngiven the (very constrained) storage throughput.\nI can't really definitively talk about the video post-processing in the same context,\nbut the same problem remains even in post, huge amounts of the footage, limited throughput.\nAlso, rangecheck: the code needs to cope with any input.\nI saw there is some handling for negative values, but i have no clue if that is sufficient.. > Now, the input values are clamped neat and straight to [2^-dynamic_range, 99999]\nThat is quite literally the opposite from what should be done / what is being done by all the other modules from what i remember :/\nYou have seen how the usual dt's basecurve/tonecurve modules handle the values outside [0.0, 1.0] range?. > > You have seen how the usual dt's basecurve/tonecurve modules\n\nThe gamma version of the unbreak profile\n\n:/\n\na lookup table contructed somehow with integers for inputs < 1, I have no idea what's going on in there and there are no comments.\n\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/profile_gamma.c#L245-L251\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/profile_gamma.c#L157-L161\nWhat comment would you want to see there ^ ?\n\nI don't even understand how you end up with negative numbers at that point\u2026 That makes no sense. The black point should be adjusted to avoid that.\n\nYou are aware that dt's modules (as far i'm aware) don't arbitrarily clamp the processed values, right?\nThe black point subtraction - no clamping:\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/rawprepare.c#L285-L372\nArtistic black level subtraction in exposure module - no clamping:\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/exposure.c#L391-L411\nProbably and so on.\nIf you do clamp (even ignoring the //actual// HDR data), those pixels will all have solid color,\nso if some later module touches them again (shadows & highlights, local contrast, ...),\nthe results will look unpleasant.. > > What comment would you want to see there ^ ?\n\nThat's what is run. But the coef that are put in the d->table look-up table are constructed like this :\n\nCorrect, some look-up-table for the normal values in [0.0, 1.0] range, with resolution of 0x10000 (65536) samples.\n\nSo I don't get where the gamma function does clamp its input\n\nFrom my previous comment\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/profile_gamma.c#L157-L161\n\"if the pixel value is less than 1.0, then multiply it by the resolution of the look-up-table (0x10000 (65536)), lossy convert to integer, clamp to [0, size of LUT-1], look up in LUT in that column, and set the pixel to that value. else, if the pixel is > 1.0, evaluate some equation with x = pixel value to get the approximate curve value\"\nNow, i have to agree, i'm not sure why, but i was rather sure that /some/ modules were doing this special handling not just for the >1.0 pixels, but for <0.0 too, but i'm not seeing it.. @edgardoh @TurboGit do note that such a merge results in empty commit message,\nbecause github is dumb. (well, and the general clue level is not high on github)\nEither @edgardoh needs to bother to write an actual commits messages,\nor @TurboGit needs to squash merge and copy-paste the PR description in there.. Enable some module in between the old lens correction and exposure, and compare pfm exports.. What about parametric blending in the spot removal module?. It doesn't really matter if 0.1% of all the processed shots will break or 1000%.\nIt's aready intentional breakage.\nThis can't be done by the very reason this is wanted, and is the correct thing\nto do - these operations are not commutative. Order matters.\nIf you have exposure correction with parametric blend on channel's value,\nand you change the modules before this module, the parametric blend will\nnow cover different pixels...\nYou can even see that without the patch:\n1. reset history stack\n2. enable exposure module\n    1. set exposure to +18\n    2. set blend to parametric mask\n    3. switch to L tab\n    4. set input range to 25..100 (i.e. only lower the low bar)\n3. click on \"display mask and/or channel\" (the icon in the bottom-right corner of the module's blend panel)\n4. Note the blend mask:\n\n5. In raw black/white levels, lower the white level. That will roughly have the same effect as vignetting correction, just with, well, not so flat shape.\n6. Note the new blend mask:\n\nI think the results are self-explanatory.\nI'm not saying this new order isn't correct.\nI'm only saying that the existing modules can't be moved around.\nIt could be done by simply copying existing lens.c to lens2.c, with the correct place in the pipe.\nBut that is so ugly and intrusive, so it would be great to rewrite the module while there,\ngetting right the ui this time, and all of the param autodetection.. > The only modules that could be affected by this change are those between exposure and lens correction, namely the spots and retouch modules. \nFactually wrong, all the modules between exposure and lens correction,\nnamely the exposure, spots and retouch modules.\nBecause you are moving lens correction before exposure. Isn't that the whole purpose?\n\n...\n\nDid you just completely skip everything i wrote about different input => different parametric blend => different mask ==> different output image?. > I did not. But test it in real life, e.g. not at 18 EV and with the real vignetting correction. The difference it makes is numerically insignificant and visually unnoticeable.\nPlease explain, if in the real world, this reordering is not noticeable, why do you want to reorder then?. > I think you don't understand.\nWhich part of \"given history stack (XMP) should produce the same image going forward\" \nare we missing?\nIn it's current form, this is a breaking change, as i have tried to repeatedly demonstrate.\n. I have already explained the way forward here:\nhttps://github.com/darktable-org/darktable/pull/1740#issuecomment-427550182\n\nI'm not saying this new order isn't correct.\nI'm only saying that the existing modules can't be moved around.\nIt could be done by simply copying existing lens.c to lens2.c, with the correct place in the pipe.\nBut that is so ugly and intrusive, so it would be great to rewrite the module while there,\ngetting right the ui this time, and all of the param autodetection.\nthere should be a way to change it without breaking old images.\nIs it feasible at all to make it flexible at runtime?\n\nBoth of these would require the module priorities (i.e. absolute) order to be stored in the sidecar.\nQuestion that raises:\n1. it is currently not being done, it's not stored in sidecars.\n2. Even if it is implemented, the order will be stored only the next time the image is loaded\n3. If the module order changes before the 'current' module order is stored,\n    the factual module order for the image will be wrong.\n    So you'd need to hardcode the current module priorities somewhere,\n    and store them when the image is first loaded?\n4. Great, all that works.\n    Now, a new module is added.\n    What happens for the 'old' history stacks, that have old module priorities?\n    It is possible that the new module, due to the absolute priorities, will end up\n    between some two different modules, as compared to the pristine order.\n5. To be continued?. Sorry, i don't really work on this repo anymore, and i certainly didn't ever work on noiseprofiles.. Don't touch the submodule, please.. Uhm :). Don't touch means don't touch.\nRebase your branch, and make sure that none of the commits touches (changes the version, deletes) the submodule.\nNot 'nah just drop it'.. Also, pardon me that i yet again comment on a pr in the repo i no longer develop,\nbut all this has worrying amount of justification/reasoning, basically no commits messages,\nand while the pr talks about adding another colorspace,\nalso some random (no reasons given) module regrouping is also stashed here :/. You can't arbitrarily enable -m flags.\nIt forces the compiler to use those instruction sets\nhttps://godbolt.org/z/JbX5_e\nNow, what happens if the cpu does not support that instruction set?. -march=native, which is already specified by default (see -- Checking for -march=native support in the cmake output, and in the actually-used buildflags), should already do it.\n(unless the compiler authors [intentionally] incorrectly specified the supported cpu features for that cpu)\nAnd both compilers are smart enough to produce avx even when the sse intrinsics were used\nhttps://godbolt.org/z/AeESmf\nSo i don't know what you were seeing / what is the question.. > That's strange, because, from what you say, compiling a Release build should already use AVX instructions\nif -match=native is used, if it says that AVX2 is to be available for that cpu.\nAlso, while i can not comment on the performance change you are seeing,\nthis isn't generically true for everything.\ne.g. AVX performance is pretty bad for AMD cpu's of e.g. bulldozer generation.. Looks like the shiny days has passed, and the time of breakage has come.\nThis broke openSUSE_Leap_42.3 x86_64 build\nhttps://build.opensuse.org/package/live_build_log/graphics:darktable:master/darktable/openSUSE_Leap_42.3/x86_64\nI really like this, but does this actually work though,\nwith all the loadable plugins and such being loaded from build dir, and not from some install?. Something about RPATH. I don't know where to look for previous build logs.\nhttps://build.opensuse.org/packages/darktable/job_history/graphics:darktable:master/openSUSE_Leap_42.3/x86_64. Uh, no?\nhttps://build.opensuse.org/package/live_build_log/home:gladiac:branches:graphics:darktable:master/darktable/openSUSE_Leap_42.3/x86_64\n[  537s] CMake Error at src/cmake_install.cmake:45 (file):\n[  537s]   file RPATH_CHANGE could not write new RPATH:\n[  537s] \n[  537s]     $ORIGIN/../lib64/darktable\n[  537s] \n[  537s]   to the file:\n[  537s] \n[  537s]     /home/abuild/rpmbuild/BUILDROOT/darktable-2.5.0~git852.71efab7eb-494.1.x86_64/usr/lib64/darktable/libdarktable.so\n[  537s] \n[  537s]   No valid ELF RPATH or RUNPATH entry exists in the file;\n[  537s] Call Stack (most recent call first):\n[  537s]   cmake_install.cmake:38 (include). This broke aarch64 build.\nhttps://build.opensuse.org/package/live_build_log/graphics:darktable:master/darktable/openSUSE_Tumbleweed_ARM/aarch64\nPlease either fix quickly, or revert.. aarch64 is not x86 architecture, and does not have sse/avx, and naturally that header does not exist there.. No idea, it's your code, you should know how it works.\nhttps://build.opensuse.org/package/binaries/graphics:darktable:master/darktable/openSUSE_Tumbleweed_ARM\ncontains 2.5.0~git814.ddddb759c as the last successful build, that was ddddb759c\nThe next build was https://build.opensuse.org/package/rdiff/graphics:darktable:master/darktable?linkrev=base&rev=475 2.5.0~git828.c3d3dce22\nc3d3dce22. Sweet, that did it, thanks.. You really might want to start using git rebase :/. Looks ok, maybe helps, thanks.. > @LebedevRI : this looks like it works, are you ok for a second try? We'll revert if it breaks things again.\nNo opinion. > Or is it supposed to be updated by someone in particular, and other devs should not update it?\nBasically, yeah.\n\ncut a stable branch in rawspeed for the release. \n\nSo far there were no \"stable rawspeed branches\".\nI think in upcoming cycle it will be possible to avoid to branching it too.\n@darix did bring up the idea of \"lensfun-update-db for darktable\",\nbut most of the changes would need to be on dt side.\n\nSo, until then we do not want to update rawspeed submodule.\n\nIt probably can be updated, but i bet there are more changes that need\nto be cherry-picked on the dt side (or else you will break the 2.4.x).\nMostly because 2.6 is near i'm not sure it's worth it.\n'Everyone' should be testing master :). I have twice now typed a comment for this pr, and discarded it. (posted into wrong pr just now)\nTLDR: i don't think i get to comment on the feature itself, but i would like to very strongly highlight\nthat this has the potential to be the third case (previous were masks, multi-instances)\nthat was merged [potentially too soon] in a horrible/disgusting state (thus discouraging anyone\nand everyone from even touching it, fixing bugs in it), as usual with no tests whatsoever,\nand the echo in the form of bugs will be there for a very long time.\nGiven the nature of this change, i suspect this may end up being the most destructive of all three.... By tests i didn't meant the dt's standard approach of give it to 1000's of monkeys and see what broke,\nbut the more proper approach of actually writing tests that are actually automatically run.\nSince there aren't any of these (who needs those anyway, everyone's code is perfect, can't have bugs, won't break any pre-existing stuff/features), i'd guess you would want to triple check all of the new [re-]ordering logic (will be sad if it is subtly broken), all of the migration code (actually verify that the module order will still remain correct), try most of the re-orderings to see that nothing obvious breaks.\n(obviously all that should be done under asan; i have not built dt under asan for some time,\nso i can't tell if there are some changes needed.). Is there even any point in supporting that arch, are there modern powerful machines?\nI really strongly dislike the set(CMAKE_*_EXTENSIONS ON) change.\n\nthe CXX change is needed in rawspeed\n\nHow so? It builds just fine on that arch.\nhttps://build.opensuse.org/package/live_build_log/graphics:darktable:master/rawspeed/openSUSE_Tumbleweed_PowerPC/ppc64le. > I have a Raptor Talos system, which is indeed a modern powerful machine. (https://raptorcs.com/)\nOk, datapoint accepted.\n\nThe problems I was encountering appear to be related to altivec.h being included from CL/cl_platform.h even when openCL is disabled.\n\nDisabled with cmake -DUSE_OPENCL=OFF ../?\nPerhaps that is the actual bug?\n\nappeared to get darktable to build without issues.\n\nBest to somehow branch the https://build.opensuse.org/package/show/graphics:darktable:master/darktable package, make it use your repo, to show that.. > > The problems I was encountering appear to be related to altivec.h being included from CL/cl_platform.h even when openCL is disabled.\n\nDisabled with cmake -DUSE_OPENCL=OFF ../?\nPerhaps that is the actual bug?\n\nI just checked, and with that flag, and with all opencl headers removed, it still builds (on amd64, granted).\nSo i'm not sure what you are seeing?. > Disabled with cmake -DUSE_OPENCL=OFF, yes. There appears to be an include path from a couple of files that unconditionally includes CL/cl_platform.h.\nCan you be more specific?\nI just tried, and it builds just fine with that file completely removed.\n. I see, hold on.... Yes, fixed already, will push in a sec.. Rebase please. Is points.h change still needed?. Waiting for https://build.opensuse.org/project/monitor/graphics:darktable:master to reanimate,\nso i can see that (i did that change in https://build.opensuse.org/package/view_file/graphics:darktable:master/darktable/darktable.spec?expand=0). > It's building for me now with -DUSE_OPENCL=OFF, but I am getting the following error at launch:\n\n./src/darktable: symbol lookup error: /opt/darktable/lib64/darktable/plugins/libborders.so: undefined symbol: dt_opencl_create_kernel\n\nWhoops, and loadable modules stink again. Let's see..\n. > > It's building for me now with -DUSE_OPENCL=OFF, but I am getting the following error at launch:\n\n\n./src/darktable: symbol lookup error: /opt/darktable/lib64/darktable/plugins/libborders.so: undefined symbol: dt_opencl_create_kernel\n\nWhoops, and loadable modules stink again. Let's see..\n\nCan't reproduce. Did you purge your builddir beforehand?. Indeed, that is sufficient to build.\n@TurboGit i'm not seeing a \"feature freeze for 2.6\" mail, so i'll assume that it will happen with rc0?\nNot sure if this is a feature or not.. Done for the OBS: https://build.opensuse.org/package/binaries/graphics:darktable:master/darktable/openSUSE_Tumbleweed_PowerPC\nThis pr is up to @TurboGit.. This is so fun, pr is closed, yet it is actually merged, and the commit has no mention of the PR :)\nAnyways, this is broken:\n[  238s] Scanning dependencies of target exr\n[  238s] make[2]: Leaving directory '/home/abuild/rpmbuild/BUILD/darktable-2.7.0~git78.fe7a2f997/build'\n[  238s] /home/abuild/rpmbuild/BUILD/darktable-2.7.0~git78.fe7a2f997/src/imageio/format/webp.c:149:9: error: 'WebPConfig {aka struct WebPConfig}' has no member named 'exact'\n[  238s]    config.exact = !!(config.lossless);\n[  238s]          ^\nhttps://build.opensuse.org/public/build/graphics:darktable:master/openSUSE_Leap_42.3/x86_64/darktable/_log. > It is broken in one platform and probably because the webp library is too old here. I'll comment out the exact field for now.\nLooks like it, exact first appeared in https://github.com/webmproject/libwebp/blob/v0.5.0/src/webp/encode.h#L139-L142, it was not in https://github.com/webmproject/libwebp/blob/v0.4.4/src/webp/encode.h\n(i would guess either the libwebp version check in cmake should be bumped, or the field should only be used if libwebp is v0.5.0 or newer). LG. I'm not sure this isn't invalid.\n\nWhen configurable colors were not found in the CSS file, hardcoded\ndefaults are used instead. It does happen in practice for users who\ncopied a darktable.css in their ~/.config/darktable/ directory with dt\n2.4, and then upgraded to 2.6. Before this patch, a missing colors was\nresulting in magenta sliders for these users for example.\n\nThat is very intentional, to signal that the css is broken.. > A message displayed to the user that would tell there is an issue with css instead would be great.\nThat would be better.\nAlso, given \"a dep should be ~3 year old\", as per https://github.com/GNOME/gtk/releases?after=3.19.7 i think the required gtk version can be bumped up to 3.18\nThat will obviously not stop these issues, but maybe they didn't break css after that release (haha who am i kidding, i bet they did).\nThought that is a bit too late now for that.. > > Do we really want to deprecate \"spot removal\" ? It is easier to use than retouch, it has been used since years by many people. I would keep it but have it not selected by default. But I have no string opinion on this.\n\nThe spot removal might have a simpler UI, but it is actually more tedious to find a clean area with no details and exact same luminance to sample. In practice, you have to fiddle with opacities and blending modes to get it to work properly, if you ever do. In the other hand, using the healing tool in retouch, even on the first layer (without enabling the wavelets decomposition), is fast and gives nice results, even if the UI is more loaded.\n\nTo me that does not answer the question of \"why should the existing simple module be deprecated?\"\nNo one is forcing anyone to only use the less powerful \"spot removal\" module,\nbut this does look like trying to force to use the more powerful module.\n\n\nThis PR also disables sharpen by default.\n\nYes, I forgot that. The motivation is there are 4 different ways in darktable to do fake sharpening (aka local contrast enhancement). The sharpen method is not the best, although it's the fastest, and the preset provided is too heavy for modern prime lenses + full frames, and too light for point-and-shoots and entry-level zooms. So, if you really want an auto-preset, you would have to profile lenses and make it dependent.\n\nThe defaults aren't meant to be best.\ndt should not try to have a magical set of auto-tuned modules enabled by default.\n. > > To me that does not answer the question of \"why should the existing simple module be deprecated?\"\n\nBecause you duplicate the feature and clutter the UI with a limited and flawed version of something else that works better.\n\n.. and the second part?\n(also, you are well aware of the more modules module, i think? so i'm not sure how it clutters it even)\n\nNo one is forcing anyone to only use the less powerful \"spot removal\" module,\nbut this does look like trying to force to use the more powerful module.\n\nAlso, let's take step back. Is that new module fully functionally equivalent of the old one?\nI have just tried it, and already stumbled into very obvious bugs (have you tried zooming in on the dst replacement area? that is a rc bug; though something tells me 2.6.0 may or may not be more full of these than usual)\n\n\ndt should not try to have a magical set of auto-tuned modules enabled by default.\n\nSo why the auto-activation of the sharpening then ? Especially with an arbitrary preset that is not universal ?\n\nCould be because the physical low-pass filter softens the image, or because the default demosaic kind-of results in softer image than the other mode, dunno.. > > Could be because the physical low-pass filter softens the image, or because the default demosaic kind-of results in softer image than the other mode, dunno.\n\n50 % of the sensors post-2012 don't have a low-pass filter anymore. Post-2016, it would be like 75 % or so.\n\ncitation needed i guess.\nThe point about demosaic still remains.\n\nWe have to settle this :\u00a0do we want a straight-away-good-looking picture when the user opens the darkroom, or a do-it-from-scratch picture ? Because both ways, I'm fine. But for now, it seems the first option has been chosen for base curves and sharpening, while the second one has been chosen for lens correction. I'm just asking for consistency.\n\nIf you don't put it like that, i'd go with \"do-it-from-scratch picture\".\nBut then, why do we need orientation, demosaic, wb, highlight recovery one will say.\nSo if you do put it like that i'd go with \"let's just not touch the defaults\".\n\nThe sharpen preset is not, by any means, a one-size-fits all thing. On any recent 36+ Mpx, you need to disable it because it's overcooked. On any point-and-shoot or DSLR + kit lens, it's not enough but you can't push it too far without messing it up, because it's a good old unsharp masking (halos much ?). When it's enabled by default, you send a message to the user : \"use it, it's standard\". It's not. It's 1972 stuff we used before being able to deconvolve properly.\n\nSimilarly, default PPG demosaic is very simple, amaze may or may not give you better results.\nDefault highlight recovery method is bad, reconstruct in lch is better (i never got around implementing proper inpainting method, oh well)\nAnd so on.\nSince dt intentionally does not have any of the pipe module hidden, one can change everything\nthat isn't nailed to it's place with nails, so i do not believe that that message is being sent.\n\n\n(also, you are well aware of the more modules module, i think? so i'm not sure how it clutters it even)\n\nI know. It's where I hide all of dt's nonsense and geeks playtoys in garbage Lab.\n\nDo you believe darktable should get rid of it's Lab section of the pipeline, and do everything in [whatever] RGB?\n\n\nAlso, let's take step back. Is that new module fully functionally equivalent of the old one?\nI have just tried it, and already stumbled into very obvious bugs (have you tried zooming in on the dst replacement area? that is a rc bug; though something tells me 2.6.0 may or may not be more full of these than usual)\n\nI have abused that module for 4 months, there are some rough edges but nothing unusable.\n\nThat is a non-answer. \n1. Does that module has a mode in which it can act just like the old spot removal module, with no extra freq/wavelet stuff forced down one's throat?\n2. Do you see the bug i just reported? (it seems i tried on 2.7.0+44~gc2ecb03f5-dirty, maybe it was fixed already). I see.\nI no longer recognize the direction in which darktable is moving.\nI guess i should finish jumping ship at some point, or at the very least stop wondering into these PR here.\n@TurboGit good luck.. Thanks.\nI have a fix for decoding (ended up being idiotically simple, it was supposed to just work already),\nbut i'm now not sure yet how to detect this situation.. Duh, come on :) No, that is too obvious even to me,\ni'm looking for something more elaborate, with less hardcoding.. > Duh, come on :) No, that is too obvious even to me,\n\ni'm looking for something more elaborate, with less hardcoding.\n\nTo put some context into \n\nbut i'm now not sure yet how to detect this situation.\n\nYou'd think that any compressed raw would have smaller file size than uncompressed raw.\nWould make a lot of sense, wouldn't it, why else waste all that time compressing\nBut no, this is nikon. (i'd guess mostly because they hardcoded the 6 huffman tables to be used?)\nEven just out of all the RPU samples (yay test coverage), this is not true in 5 (sic) cases:\n(expected input size is the byte size that image would take as uncompressed packed)\n ./Nikon/Coolpix P330/DSCN0138.NRW\narea 12192768 bpp 12 input size 24385536 expected input size 18289152\n ./Nikon/Coolpix P7800/DSCN2039.NRW\narea 12192768 bpp 12 input size 24385536 expected input size 18289152\n ./Nikon/D100/RAW_NIKON_D100.NEF\narea 6140816 bpp 12 input size 9844736 expected input size 9211224\n ./Nikon/D4S/FU9_3802.NEF\narea 4040960 bpp 12 input size 12122880 expected input size 6061440\n* ./Nikon/D810/DSC_1888.NEF\narea 9038080 bpp 12 input size 27114240 expected input size 13557120\nUsing some heuristics over the STRIPBYTECOUNTS is so fragile here :/\nEven just the current equality-comparison could fail i guess.\nYet, i'm presently not seeing any obvious formula between the image dimensions,\nexpected/actual buffer sizes and the padding for the Z {6,7} uncompressed raws in question.\nAnd there does not seem to be some other this image is really uncompressed EXIF tag.\n(It also is just great that they continue to lie in the Compression EXIF tag :)\nOr well, i see the correlation, but i can't really formulate it - count trailing zeros(actual input pitch) > count trailing zeros(expected input pitch).\nSo yeah, just 'accepting' some small per-row padding (16 bytes?) might be the path of least resistance :/. Ok, done. https://github.com/darktable-org/rawspeed/commit/84eabd77e8d134fab1669f73382e44b4805e5e7e\nWill propagate to darktable sometime later.. (Have i already said that having more than one issue tracker is idiotic?)\nForgot to close this, fixed in https://github.com/darktable-org/darktable/commit/4645a8b725eca6dee71ae5b549c61cea65148c42. > @LebedevRI Those updates appear to have originated in darktable-org/rawspeed. I didn't touch them.\nI would advise you to read about git submodules.\nDon't git add src/extermal/rawspeed into commits,\nunstage it from the commits you have already added it into.\n(or in other words, don't use git add -a). The full sample set should go to https://raw.pixls.us/. @sgimenez c99 has bool type. what compiler are you using?\n. When i wrote that part it was needed. Seems to be no longer needed since 3d92212\n. Then i'd have to add \"dt_iop_lensfun_params_t p = (dt_iop_lensfun_params_t )self->params;\" there too...\n1 line is better than 2 :)\n. Not sure about those two, so i'll leave them as it is.\n. I believe so: (from darktable/build/src/iop/introspection_exposure.c)\n/*                                                                                                                                                                                                                                \n * this code is auto generated. do not edit. change the sources in tools/introspection/ instead.                                                                                                                                  \n *                                                                                                                                                                                                                                \n * the parse tree:                                                                                                                                                                                                                \n *                                                                                                                                                                                                                                \n * typedef                                                                                                                                                                                                                        \n *   struct dt_iop_exposure_params_t                                                                                                                                                                                              \n *     enum dt_iop_exposure_mode_t                                                                                                                                                                                                \n *       EXPOSURE_MODE_MANUAL                                                                                                                                                                                                     \n *       EXPOSURE_MODE_DEFLICKER                                                                                                                                                                                                  \n *     mode                                                                                                                                                                                                                       \n *                                                                                                                                                                                                                                \n *     float [-G_MAXFLOAT .. 0.0 .. G_MAXFLOAT] :                                                                                                                                                                                 \n *     black                                                                                                                                                                                                                      \n *                                                                                                                                                                                                                                \n *     float [-G_MAXFLOAT .. 0.0 .. G_MAXFLOAT] :                                                                                                                                                                                 \n *     exposure                                                                                                                                                                                                                   \n *                                                                                                                                                                                                                                \n *     float [-G_MAXFLOAT .. 0.0 .. G_MAXFLOAT] :                                                                                                                                                                                 \n *     deflicker_percentile                                                                                                                                                                                                       \n *                                                                                                                                                                                                                                \n *     float [-G_MAXFLOAT .. 0.0 .. G_MAXFLOAT] :                                                                                                                                                                                 \n *     deflicker_level                                                                                                                                                                                                            \n *                                                                                                                                                                                                                                \n *     enum dt_iop_exposure_deflicker_histogram_source_t                                                                                                                                                                          \n *       DEFLICKER_HISTOGRAM_SOURCE_THUMBNAIL                                                                                                                                                                                     \n *       DEFLICKER_HISTOGRAM_SOURCE_SOURCEFILE                                                                                                                                                                                    \n *     deflicker_histogram_source                                                                                                                                                                                                 \n *                                                                                                                                                                                                                                \n * dt_iop_exposure_params_t                                                                                                                                                                                                       \n *\n */\n. Fixed.\nI made same change in histogram_collect and histogram_collect_cl, please verify that it applies there too.\n. Done.\nFeel free to correct my variant.\n. Actually, i just forgot this.\nWIll put it back for consistency reasons (with the rest of the IOPs)\n. Agree, this is missing #else.\nBut, since DT will not build without SSE3 at all, you need to just drop all #if __SSEx__\n. What is this? I do not see where any of those are being set.\n. Ack, i undersood that after i turned my computer off.\nBut: https://github.com/darktable-org/darktable/blob/master/src/common/darktable.c#L386\n```\nifndef SSE3\n#error \"Unfortunately we depend on SSE3 instructions at this time.\"\n  #error \"Please contribute a backport patch (or buy a newer processor).\"\nelse\n#if (__GNUC_PREREQ(4,8) || __has_builtin(__builtin_cpu_supports))\n  //FIXME: check will work only in GCC 4.8+ !!! implement manual cpuid check !!!\n  //NOTE: _may_i_use_cpu_feature() looks better, but only avaliable in ICC\n  if (!__builtin_cpu_supports(\"sse3\"))\n  {\n    fprintf(stderr, \"[dt_init] unfortunately we depend on SSE3 instructions at this time.\\n\");\n    fprintf(stderr, \"[dt_init] please contribute a backport patch (or buy a newer processor).\\n\");\n    return 1;\n  }\n  #else\n  //FIXME: no way to check for SSE3 in runtime, implement manual cpuid check !!!\n  #endif\nendif\n```\nAs i said yearlier, If SSE is not avaliable, DT will not build/work anyway, so drop #if __SSE2__\n. Last time i checked, DT can export non-raw images (e.g. jpeg's), so this is wrong.\n. Maybe we should stick to -180..180 degrees here.\nUsable range is the same.\n. Minor issue: comment looks ugly.\nEither add braces for if, or move comment to the end of return, or something else.\n. Braces should be on new line\n. While i agree that original code had no braces, but new code with all it's if's would probably look better with braces (at least outermost - if(image->filters!=9) {} else {})\n. Idea: make xtrans really const and remove it from shared()\n. Hm, maybe ceil/floor ?\n. This function(and probably others, didn't check yet) is not supposed to be used outside of this file, so it should be marked as static.\n. I believe in,xtrans,roi_in can be made really const and be removed from shared()\n. Seems like good place for OpenMP\n. State that 1/3 is for X-Trans, e.g:\nsample half-size raw (Bayer), or 1/3 (X-Trans)\n. I saw some strange output here, but can not reproduce it, maybe you should replace with (as in the rest of dt_bauhaus_slider_set_format):\ndt_bauhaus_slider_set_format(g->rotate, \"%.2f\u00b0\");\n. Nevermind, looks like it is one of Debian sid joys. (random text and random things in gui sometimes completely disappear)\n. http://picpaste.de/pics/46d44-ATZqvAKI.1402412125.png - that's 46.44 degrees\n. s/maks/mask/\n. Much better, but i should have stated that clearer in the first place: openmp shared() should contain only buffers that you write. Buffers that are only being read should be const.\nIn this case, you write to out in the end of the function:\nfloat *outc = out + 4*(out_stride*y);\n...\noutc[0] = sum[0] / 65535.0f / num[0];\n. I would recommend defining function something like this:\ninline uint8_t\nFCxtrans(const uint8_t (*const xtrans)[6]), size_t x, size_t y)\n{\n  return xtrans[x % 6][y % 6];\n}\nAnd use it everywhere (like we use FC already):\nconst uint8_t c = FCxtrans(xtrans, j+jj+roi_in->y, i+ii+roi_in->x);\n. memcpy (rgb+=4, buffer, 4*sizeof *rgb);\n/me didn't parse that\n. (Might be wrong) shouldn't this coeffs be different for xtrans?\n. typeof max = float\nGenerally, floats can not be compared using ==\n(And also not 0, but 0.0f)\n. One more sizeof *fimg\n. This would do it too, but whatever\nc++\nstatic const UTF32 __attribute__((__unused__)) halfMask = 0x3FFUL;\n. You also need to change IOP version in the following line:\nc\n DT_MODULE_INTROSPECTION(1, dt_iop_cacorrect_params_t)\n. No, i believe that commit_params() should be called here, at least because this is how it's done in all other IOPs.\n. Minor: free(NULL) is perfectly fine, no need to check.\nAlso see dfa494e9fdaebc6fb8d23032654ed55c5502481d\n. Still valid.\n. Please put a brace on a new line, to be consistent with the rest of our code.\n. Ok, last thing and i'm merging: drop this brace pair (the outermost in\n```\nelse\n// Check SSE3 support \"manually\"\n  // (see http://stackoverflow.com/questions/6121792/how-to-check-if-a-cpu-supports-the-sse3-instruction-set)\n  { <- this\n    ...\n  } <- this\nendif\nif (!sse3_supported))\n```\nand reindent.\n. This needs to be\nDT_MODULE_INTROSPECTION(1, dt_iop_defringe_params_t)\n. not that it matters much, but enum is better:\ntypedef enum dt_iop_defringe_mode_t\n{\n  MODE_GLOBAL_AVERAGE,\n  MODE_LOCAL_AVERAGE,\n  MODE_STATIC\n}\ndt_iop_defringe_mode_t;\n. If enum, then\ndt_iop_defringe_mode_t op_mode;\nIt does not matter much now, but in the debugger it looks better.\nIt might also be needed for upcoming IOP Introspection. \n. You do not need to copy alpha: (next note)\n. After last cycle, add:\nif(piece->pipe->mask_display)\ndt_iop_alpha_copy(i, o, roi_out->width, roi_out->height);\n. If any call to allocate memory fails, the application is terminated. This also means that there is no need to check if the call succeeded.\nAs said by houz, use malloc/calloc.\n. Maybe (some iops do, some do not):\nmemcpy(o, i, (size_t)sizeof(float)*ch*roi_out->width*roi_out->height);\n. replace const float sigma = p->radius * roi_in->scale / piece->iscale; with\nconst float sigma = fmax(0.1f, fabs(p->radius)) * roi_in->scale / piece ->iscale;\n(all other users of dt_gaussian_init() seem to do it this way)\n. You already free it in gui_cleanup()\n. You do not use histogram, so this line should be deleted.\n. Also add\n// modelines: These editor modelines have been set for all relevant files by tools/update_modelines.sh\nbefore vim\n. Like houz said, modelines, like the rest of the files.\n. scalepixels.c\n. not 1024, but sizeof(hi->op)\n. same\n. You need to include glib/gprintf.h:\nThe recommended way of using GLib has always been to only include the toplevel headers glib.h, glib-object.h, gio.h. Starting with 2.32, GLib enforces this by generating an error when individual headers are directly included.\nhttps://developer.gnome.org/glib/stable/glib-compiling.html\n. You are breaking all presets by doing this.\n. See: a83845392e33e82a700d4bdb8c9380c3b5680de6 1db2794246b132d03cd08e6e0fe0e63d56b34242\n. I suspect that all the memcpy in this legacy_params() are invalid now.\nE.g. sizeof(dt_imageio_exr_t) > old_params_size, so you need to use old_params_size or it will read out-of-bounds.\nAlso, since style_append was added, compression is lost here.\n. Are you sure you need to pass 1 and not orientation or ORIENTATION_NONE here?\n. I'm guessing here too (ORIENTATION_NONE)\n. Maybe dt_mipmap_size_t?\n. dt_mipmap_size_t?\n. sizeof(filename), for consistency with the rest of the code\n. https://developer.gnome.org/glib/stable/glib-File-Utilities.html#g-mkdir-with-parents\n0 if the directory already exists, or was successfully created. Returns -1 if an error occurred, with errno set.\n. dt_mipmap_size_t?\n. sizeof()?\n. dt_mipmap_size_t?\n. sizeof()?\n. if(!blob)\n. if(!tmp)\n. That if makes no sense since imgid is unsigned.\n. That if makes no sense since imgid is unsigned.\n. char filename[PATH_MAX] = { 0 };\n. sizeof()\n. char filename[PATH_MAX] = { 0 };\n. sizeof()\n. char filename[PATH_MAX] = { 0 };\n. sizeof()\n. sizeof()\n. if(!blob)\n. dt_mipmap_size_t?\n. dt_mipmap_size_t?\n. char filename[PATH_MAX] = { 0 };\n. sizeof()\n. dt_mipmap_size_t\n. char filename[PATH_MAX] = { 0 };\n. sizeof()\n. dt_mipmap_size_t\n. char path[PATH_MAX] = { 0 }; ?\n. In all other cases after calling g_mkdir_with_parents()\nyou do if(!mkd)\n. Right, i have probably read that as >=.\nBut them maybe it should be == 0.\n. I think it should be BUILD_PRINT, just like BUILD_SLIDESHOW\n. I do not see where this is being freed (what was allocated in dt_get_printer_info())\n. You do not need __ there, dt_paper_info_t should work just fine.\n. Why not use printf() directly?\nAlternatively, maybe you should call dt_control_log()\n.  = { 0 }\n. sizeof(pp->filename)\n. sizeof(filename)\n. sizeof(tag)\n. sizeof()\n. if(!data)\n.  = {0};\n. sizeof()\n. GTK3: grid\n. GTK3: grid\n. = { 0 };\n. #ifdef HAVE_PRINT\n         \"print\", \nendif\n. Note that this is dt_imageio_open_rawspeed_sraw(), not dt_imageio_open_rawspeed_raw()\nWe load them as 4x sizeof(float) - as any other non-raw image, like e.g. jpeg.\n. Unfortunately, yes. I haven't really had time to thought about the fact that there will be v2->v3, and that doing it in separate function would have been cleaner when i was in the rush of fixing flip regression (v1 >v2).\n. Yes, that is hardcoded 4-ch. That is exactly how RawSpeed does it now.\n. This looks like a dirty hack to me, i'm afraid there are more issues caused by same cause as this one.\nSo i'd sat, deeper investigation is required...\n. Why do you think there was ${GTK_CSS_CLASS} ?\n. I have noticed this only now, this should be dt_imageio_jpeg_v1_t, not dt_imageio_jpeg_t.\n. Is this include needed? That is the only line with tiff substring in this file.\n. #include  ?\n. Unrelated, but probably slideshow should be guarded by ifdefs too\n. I do not really like this.\nIf this is really needed, i would prefer if you would add/pass another param to dt_view_image_expose() that would force-disable display of meta-data.\n. Fixed.\n. Well, at least this way that code is not duplicated. This looks better, at least to me.\n. mipmap 3 has a fixed size, so you will always get the same aspect ratio, and it is not guaranteed to be be equal to the actual aspect ratio of the image.\n. dt_dev_pixelpipe_get_dimensions()\n. Right, i have seen\noption(BUILD_SLIDESHOW \"Build the opengl slideshow viewer\" ON)\n(https://github.com/darktable-org/darktable/blob/5d7890b9cdf01a92a5755749e1537eec3a4d6229/CMakeLists.txt#L17)\nand thought that was about slideshow view, and not about that old dtview thingy\n. That doesn't feel completely safe to me...\nAre you completely sure it isn't better to just verbosely default it to whatever the default/legacy-safe value?\n. That was my thought too, but i believe we want to maintain full identity with cpu path.\n@upegelow, opinion?\n. (I noticed this only now.)\nHere, and in else branch, something like this (list in shared() might need correctio)\n```\nifdef _OPENMP\npragma omp parallel for schedule(static) default(none) shared(ptr_in, ptr_out, hTransform, height, k, width)\nendif\n```\ncould be added before for.\nThat would result in faster color transform, since LCMS, internally, does not do any parallelization.\n. This should rather be\nchar lc_pathname[PATH_MAX] = { 0 };\n_image_local_copy_full_path(imgid, lc_pathname, sizeof(lc_pathname));\n. We need to review those PDF graphs generated while creating this profile.\nPlease upload resulting dt-noiseprofile-XXXXXXXX.tar.gz \n. It is used, otherwise it wouldn't compile...\n. Probably\nif (img->raw_maker[0] != '\\0' && img->raw_model[0] != '\\0')\n. Just use g_strlcpy()\n. Safer to just use g_strlcpy()\n. Might as well specify font-size while there\nAlso, what happens if $(WATERMARK_FONT_FAMILY) contains font size?\n. Later on you use GdkRGBA.\nFrom https://developer.gnome.org/gdk3/stable/gdk3-RGBA-Colors.html:\nAll values are in the range from 0.0 to 1.0 inclusive. So the color (0.0, 0.0, 0.0, 0.0) represents transparent black and (1.0, 1.0, 1.0, 1.0) is opaque white. Other values will be clamped to this range when drawing.\nSo there is no way you should be specifying 127 here and in other places...\n. I would clamp (p->color[x]*255) to 0 and 255\n. A space was there correctly\n. Better idea, use gdk_rgba_to_string()\n. What is the point of storing _(\"text\") in updated legacy entry?\nI do understand that it will not show that line on each upgraded image, but plain \"\" would be enough IMO.\n. I was mostly asking because later on you:\ng_strlcpy(n->font, \"DejaVu Sans 10\", sizeof(n->font));\n10 is not the font size there?\n. Well, you're wrong, this works just fine over here:\n```\nFrom 996b1ce5b560733f73cd93d17bb2b878a7d2c3f4 Mon Sep 17 00:00:00 2001\nFrom: Roman Lebedev lebedev.ri@gmail.com\nDate: Thu, 25 Jun 2015 22:56:36 +0300\nSubject: [PATCH] watermark: use gdk_rgba_to_string()\n\ndata/watermarks/simple-text.svg | 2 +-\n src/iop/watermark.c             | 5 +++--\n 2 files changed, 4 insertions(+), 3 deletions(-)\ndiff --git a/data/watermarks/simple-text.svg b/data/watermarks/simple-text.svg\nindex 127fd77..5d944bd 100644\n--- a/data/watermarks/simple-text.svg\n+++ b/data/watermarks/simple-text.svg\n@@ -4,7 +4,7 @@\n      y=\"0\">\n<text x=\"0\" y=\"5px\" text-anchor=\"start\"\n-        fill=\"#$(WATERMARK_COLOR)\"\n+        fill=\"$(WATERMARK_COLOR)\"\n         font-family=\"$(WATERMARK_FONT_FAMILY)\"\n         font-style=\"$(WATERMARK_FONT_STYLE)\"\n         font-weight=\"$(WATERMARK_FONT_WEIGHT)\"\ndiff --git a/src/iop/watermark.c b/src/iop/watermark.c\nindex 8237ecf..0c1b12b 100644\n--- a/src/iop/watermark.c\n+++ b/src/iop/watermark.c\n@@ -383,8 +383,9 @@ static gchar _watermark_get_svgdoc(dt_iop_module_t self, dt_iop_watermark_data\n         svgdata = svgdoc;\n       }\n\ng_snprintf(buffer, sizeof(buffer), \"%02x%02x%02x\",\n(unsigned)(p->color[0]255), (unsigned)(p->color[1]255), (unsigned)(p->color[2]*255));\nGdkRGBA c = { p->color[0], p->color[1], p->color[2], 1.0f };\ng_snprintf(buffer, sizeof(buffer), \"%s\", gdk_rgba_to_string(&c));\nprintf(\"\\\"%s\\\"\\n\", buffer);\n       svgdoc = _string_substitute(svgdata, \"$(WATERMARK_COLOR)\", buffer);\n       if(svgdoc != svgdata)\n       {\n-- \n2.1.4\n```\n. Well, you're wrong, this works just fine over here:\n\n```\nFrom 996b1ce5b560733f73cd93d17bb2b878a7d2c3f4 Mon Sep 17 00:00:00 2001\nFrom: Roman Lebedev lebedev.ri@gmail.com\nDate: Thu, 25 Jun 2015 22:56:36 +0300\nSubject: [PATCH] watermark: use gdk_rgba_to_string()\n\ndata/watermarks/simple-text.svg | 2 +-\n src/iop/watermark.c             | 5 +++--\n 2 files changed, 4 insertions(+), 3 deletions(-)\ndiff --git a/data/watermarks/simple-text.svg b/data/watermarks/simple-text.svg\nindex 127fd77..5d944bd 100644\n--- a/data/watermarks/simple-text.svg\n+++ b/data/watermarks/simple-text.svg\n@@ -4,7 +4,7 @@\n      y=\"0\">\n<text x=\"0\" y=\"5px\" text-anchor=\"start\"\n-        fill=\"#$(WATERMARK_COLOR)\"\n+        fill=\"$(WATERMARK_COLOR)\"\n         font-family=\"$(WATERMARK_FONT_FAMILY)\"\n         font-style=\"$(WATERMARK_FONT_STYLE)\"\n         font-weight=\"$(WATERMARK_FONT_WEIGHT)\"\ndiff --git a/src/iop/watermark.c b/src/iop/watermark.c\nindex 8237ecf..0c1b12b 100644\n--- a/src/iop/watermark.c\n+++ b/src/iop/watermark.c\n@@ -383,8 +383,9 @@ static gchar _watermark_get_svgdoc(dt_iop_module_t self, dt_iop_watermark_data\n         svgdata = svgdoc;\n       }\n\ng_snprintf(buffer, sizeof(buffer), \"%02x%02x%02x\",\n(unsigned)(p->color[0]255), (unsigned)(p->color[1]255), (unsigned)(p->color[2]*255));\nGdkRGBA c = { p->color[0], p->color[1], p->color[2], 1.0f };\ng_snprintf(buffer, sizeof(buffer), \"%s\", gdk_rgba_to_string(&c));\nprintf(\"\\\"%s\\\"\\n\", buffer); // prints \"rgb(255,0,0)\"\n       svgdoc = _string_substitute(svgdata, \"$(WATERMARK_COLOR)\", buffer);\n       if(svgdoc != svgdata)\n       {\n-- \n2.1.4\n``\n. font?\n. Nah, just commit your version of this fix into this branch.\n. Completely bogus check sincep->fontis not a pointer but an array.\nThis broke clang build.\n. Wouldn't have happened if you didn't merged unready branch. Again.\nAnd i call it \"unready\" because no-one (not even i, after that review, which wasn't final/finished), have said \"can not find any more issues there, looks good to merge\".\nNot cool.\n. Just comparing against a constant seems like a bad idea, but i also did not like the idea of \"find out what value DT_IOP_DEMOSAIC_PASSTHROUGH_MONOCHROME\".\nSo i came up with this version.\n. Yeah, but since it compiles without this include i have just dropped this line.\n. But where then,basic.cl, newdemosaic_other.cl?\n@upegelow, opinion?\n. ok, will do.\nthanks for a fast reply!\n. Fixed.\n. I think pr should befree()d after being passed intopctl->cb(). Yep, fixed.\n. there will still need to be 2 function (lat/lon and lat/lon/ele), but sure, why not, fixed\n. Fixed and noted.\n. it was mostly a temporary solution to find allfree(params);because it would fail to compile with a warning.\nI have no preference here, if you say so i will drop const.\n. Makes sense, but, why%ld?\nClang suggests%zu`, and IIRC that is what is used elsewhere to print size_t.\nE.g.:\n\n/home/lebedevri/darktable/src/develop/tiling.c:1824:103: error: format specifies type 'int' but the argument has type 'size_t' (aka 'unsigned long') [-Werror,-Wformat]\n               \"[default_process_tiling_cl_roi] tile (%d, %d) with %d x %d at origin [%d, %d]\\n\", tx, ty,\n                                                          ~~                                          ^~\n                                                          %zu\n. include(LibFindMacros)\neb076375b4c8ea4321a668073764a76a7d719999\n. pugixml does not install PC file that can be used with libfind_pkg_check_modules()?\n. And not in debian sid either, apparently. Strange.\n. Since there is no *.PO so libfind_pkg_check_modules() can not be used to replace that handwritten version parsing, i guess it won't be needed.\n. message is used later on...\n. Will not work when count of history items does not change.\nhttps://github.com/darktable-org/darktable/pull/959/files#diff-79a3db631cb5ea0369a221a5c31a9eddL598\n. s/0/NULL/\n. From mail:\n- when trashing fails, you silently revert to deleting. That's a bad idea. Please do a modal dialog with a message asking the user if he wants to delete or cancel instead\n. I think, this should be a config option.\nSee #975 for an example on how to add one...\n. Yes, absolutely.\n. s/  / / ? (2 spaces)\n. if HAND is found and HAND is not a FOOT :)\n. pthread_rwlock_wrlock() can still fail with EINVAL or EDEADLK, so it is better to preventively use __sync variants here.\nNOTE: our wrappers are used only when _DEBUG is defined (i.e. -DCMAKE_BUILD_TYPE=Debug ).\n. It was meant to just stay there and show up in gdb bt's, but i'm not really sure how useful that would be.\nI can as well just drop it.\n. Oh right, i should basically reuse the same comparison as the previous one (the one with description), but replace g_strcmp0 description with memcmp params.\n(Though right now only thumbnails job do actually set params_size.)\n. job is not in queue, so it shouldn't need locking access to it with queue_mutex.\nSince job disposal will be slower than not job disposing, and there does not seem to be any reason to keep queue_mutex locked for disposing.\nSince now i need to lock queue_mutex in dt_control_run_job() (to unset job from array of running jobs), this might slightly help, but i did not do any mutex performance measurements yet.\n. Probably s/''/\u2033/\n(double ' vs. single \u2033)\n. Or:\nhttps://en.wikipedia.org/wiki/Prime_(symbol)\nThe double prime (\u2033) represents inches (in), arcseconds (as), and seconds (s). However, for convenience, a (\") (double quotation mark) is commonly used.\n. +pugixml\n. gnome-keyring is gone, upstream fully deprecated it in favor of libsecret, which we do support\n. proprietary drivers aren't exactly required\nit's just that there is still no open opencl drivers that support all the stuff\n. Maybe\nCOMMENT \"Building Lua API\" VERBATIM\n?\n. Same\n. Same\n. Shouldn't it be under e.g. wp_lua_api ?\n. set(xmllangfile \"${CMAKE_CURRENT_BINARY_DIR}/darktable-lua-api-${language}.xml\")\n. e1cf99537a2a2759ff8b22be8d5a33398563e688\nI guess piece->iheight * 1.0f should be piece->buf_in.height and so on.\n. Oh, that.\nHm, i guess params passed as function argument should be used.\nBut i can not tell whether  dt_iop_scalepixels_params_t *p = self->params; is wrong.\n. Better make that const dt_iop_scalepixels_data_t * const d = piece->data; rather than adding it into shared()\n. MIN() is not needed.\nBecause, i believe, dt_interpolation_compute_pixel4c() won't sample out of buffer.\nAnd i think because that would hide the issue with wrong d->*_scale\n. Some time ago, the concerns about using bool were raised.\nBetter not use bool/boolean/gboolean in params.\nJust use int.\n. https://github.com/darktable-org/darktable/blob/bfa5ad5c5a19587cc377d233709852df84ed82e1/src/iop/exposure.c#L196-L200\n. The idea behind legacy_params() is that old v1 channelmixer params should produce exactly the same output after converting into v2 !!!\nSo all this should rather be: (note n.luminosity[i] = 0;)\n+    dt_iop_channelmixer_params_v1_t *o = (dt_iop_channelmixer_params_v1_t *)old_params;\n+    dt_iop_channelmixer_params_t *n = (dt_iop_channelmixer_params_t *)new_params;\n+    dt_iop_channelmixer_params_t *d = (dt_iop_channelmixer_params_t *)self->default_params;\n+\n+    *n = *d; // start with a fresh copy of default parameters\n+\n+    for (int i = 0; i < 7; i++) // Better not use CHANNEL_SIZE for further compatibility\n+    {\n+      n.red[i] = o->red[i];\n+      n.green[i] = o->green[i];\n+      n.blue[i] = o->blue[i];\n+      n.luminosity[i] = 0;\n+    }\n+\n+    return 0;\n+  }\n+\n+  return 1;\n. Yes, but with default values at the time code was written.\nI.e. we change default params for luminosity to 1, and then ald history stack will be upgraded => the results will be different...\nYes, there is very little to none difference, but please just follow the pattern.\n. (after re-reading from the scratch)\nYes, your legacy_params() look ok, and should work fine.\nThe only thing i'm questioning that they look different from (most?) other our legacy_params().\nIt would be best to keep all our legacy_params() to follow the same code pattern - the one i showed in one of previous comments.\nlegacy_params()*.\nIt would be best to keep all our \n. Err, TIFF EXIF is meaningless/wrong.\nIt should really be something like TIFF-encoded EXIF thumbnails\n. Can it be fetched from web, not keeped in tree?\n. On Sun, Dec 13, 2015 at 1:43 PM, Pedro C\u00f4rte-Real notifications@github.com\nwrote:\n\nIn tools/regression_tests/src/web/assets/jquery.js\nhttps://github.com/darktable-org/darktable/pull/1073#discussion_r47442950\n:\n\n@@ -0,0 +1,5 @@\n+/! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license /\n\nIt can but it's very unsafe and leads to issues if you don't have a\nnetwork connection for some reason. We already ship a few others in\ndata/js/ for the same reasons I assume.\nWhich leads to issues like this: https://redmine.darktable.org/issues/10767\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1073/files#r47442950.\n. Why second param to dt_accel_register_iop(), local is FALSE here?\nSo that it is not local to the module?\n. Oh, wrong approah.\nYou should put float weights[CHANNEL_SIZE] into dt_iop_channelmixer_data_t, and compute it in commit_params()\nAnd then probably remove data->luminosity from dt_iop_channelmixer_data_t\n\n(that way you will have code to compute it in only one function, not in two like now)\n. No point in checking, just set.\n. No point in checking, just set.\n. s/false/FALSE/\nNo clue if it really matters.\n. s/false/FALSE/\n. s/(\"Preserve luminosity\")/(_(\"Preserve luminosity\"))/\n. In all other places return value of gp_camera_file_get() is checked\n. Same\n. In your new version of the function, dt_exif_apply_global_overwrites() is not called.\nSince _dt_exif_read() calls dt_exif_apply_global_overwrites() only after reading exif, but not IPTC and XMP data, it probably changes the output.\n. Must contain same copyright comment as all the other files.\n. Looks strange.\nRemove one openmp_stacksize_env from that line.\n. I did not test, but i would guess that you should parse a number from openmp_stacksize_env  and compare it with SAFESTACKSIZE, and not compare strings.\n. And you have got yourself alloc-dealloc-mismatch\nBetter to just stick to non-glib memory allocation functions everywhere.\n. What about data? Seems like it is leaking.\n. GETRLIMIT(2)\nRETURN VALUE\n       On success, these system calls return 0.  On error, -1 is returned, and errno is set appropriately.\n. // modelines: These editor modelines have been set for all relevant files by tools/update_modelines.sh\n// vim: shiftwidth=2 expandtab tabstop=2 cindent\n// kate: tab-indents: off; indent-width 2; replace-tabs on; indent-mode cstyle; remove-trailing-space on;\n. Can't change this one.\n. Can't change this one.\n. I should use more verbose comments :)\nWhat i meant is: that file is under src/external/ -> probably all the changes would get overridden when updating bundled copy.\nBut as i now see, it looks like those 2 CMakeLists.txt are not from bundled libs, but was manually added like with rawspeed.\nSo all good, false alarm.\n. This is the first time i see redo to default as Ctrl+R.\nI think, in all cases i have seen, it is either Ctrl+Y or Ctrl+Shift+Z.\n. So now that ^ accel user can change will be ignored and default value will be just assumed?\n. I'm pretty sure that you should just add second _darkroom_undo_callback, and just make those call appropriate dt_undo_do_undo/dt_undo_do_redo\n. s/NULL/free/ ?\n. (i think it might/should fix the memory leak i was observing with undo in map view)\n. Pardon my ignorance, but then where item is being freed? (also, it is allocated with g_malloc())\nAnd isn't that a double-free?\nThat looks really strange, shouldn't it be something like:\nif (item->free_data) item->free_data(item->data);\nfree(item);\n?\n. Does not even build:\n[ 35%] Building C object src/views/CMakeFiles/map.dir/map.c.o\n/home/lebedevri/darktable/src/views/map.c: In function \u2018_push_position\u2019:\n/home/lebedevri/darktable/src/views/map.c:882:93: error: passing argument 6 of \u2018dt_undo_record\u2019 from incompatible pointer type [-Werror=incompatible-pointer-types]\n   dt_undo_record(darktable.undo, self, DT_UNDO_GEOTAG, (dt_undo_data_t *)geotag, &pop_undo, free);\n                                                                                             ^\nIn file included from /home/lebedevri/darktable/src/views/map.c:28:0:\n/home/lebedevri/darktable/src/views/undo.h:61:6: note: expected \u2018void (*)(void **)\u2019 but argument is of type \u2018void (*)(void *)\u2019\n void dt_undo_record(dt_undo_t *self, dt_view_t *view, dt_undo_type_t type, dt_undo_data_t *data,\n      ^\ncc1: all warnings being treated as errors\nsrc/views/CMakeFiles/map.dir/build.make:62: recipe for target 'src/views/CMakeFiles/map.dir/map.c.o' failed\nmake[2]: *** [src/views/CMakeFiles/map.dir/map.c.o] Error 1\nCMakeFiles/Makefile2:1537: recipe for target 'src/views/CMakeFiles/map.dir/all' failed\nmake[1]: *** [src/views/CMakeFiles/map.dir/all] Error 2\nMakefile:149: recipe for target 'all' failed\nmake: *** [all] Error 2\n. [ 39%] Building C object src/libs/CMakeFiles/history.dir/history.c.o\n/home/lebedevri/darktable/src/libs/history.c: In function \u2018pop_undo\u2019:\n/home/lebedevri/darktable/src/libs/history.c:217:20: error: assignment discards \u2018const\u2019 qualifier from pointer target type [-Werror=discarded-qualifiers]\n     hist->snapshot = current_params;\n                    ^\n/home/lebedevri/darktable/src/libs/history.c: In function \u2018_history_undo_data_free\u2019:\n/home/lebedevri/darktable/src/libs/history.c:232:30: error: passing argument 2 of \u2018g_list_free_full\u2019 from incompatible pointer type [-Werror=incompatible-pointer-types]\n   g_list_free_full(snapshot, dt_dev_free_history_item);\n                              ^\nIn file included from /usr/include/glib-2.0/glib/ghash.h:33:0,\n                 from /usr/include/glib-2.0/glib.h:50,\n                 from /home/lebedevri/darktable/src/common/dtpthread.h:29,\n                 from /home/lebedevri/darktable/src/common/darktable.h:37,\n                 from /home/lebedevri/darktable/src/libs/history.c:19:\n/usr/include/glib-2.0/glib/glist.h:56:10: note: expected \u2018GDestroyNotify {aka void (*)(void *)}\u2019 but argument is of type \u2018void (*)(dt_dev_history_item_t *) {aka void (*)(struct dt_dev_history_item_t *)}\u2019\n void     g_list_free_full               (GList            *list,\n          ^\n/home/lebedevri/darktable/src/libs/history.c: In function \u2018_lib_history_change_callback\u2019:\n/home/lebedevri/darktable/src/libs/history.c:259:38: error: passing argument 2 of \u2018dt_undo_record\u2019 from incompatible pointer type [-Werror=incompatible-pointer-types]\n       dt_undo_record(darktable.undo, self, DT_UNDO_HISTORY, (dt_undo_data_t *)hist, &pop_undo, _history_undo_data_free);\n                                      ^\nIn file included from /home/lebedevri/darktable/src/libs/history.c:26:0:\n/home/lebedevri/darktable/src/views/undo.h:61:6: note: expected \u2018dt_view_t * {aka struct dt_view_t *}\u2019 but argument is of type \u2018dt_lib_module_t * {aka struct dt_lib_module_t *}\u2019\n void dt_undo_record(dt_undo_t *self, dt_view_t *view, dt_undo_type_t type, dt_undo_data_t *data,\n      ^\n/home/lebedevri/darktable/src/libs/history.c:259:85: error: passing argument 5 of \u2018dt_undo_record\u2019 from incompatible pointer type [-Werror=incompatible-pointer-types]\n       dt_undo_record(darktable.undo, self, DT_UNDO_HISTORY, (dt_undo_data_t *)hist, &pop_undo, _history_undo_data_free);\n                                                                                     ^\nIn file included from /home/lebedevri/darktable/src/libs/history.c:26:0:\n/home/lebedevri/darktable/src/views/undo.h:61:6: note: expected \u2018void (*)(dt_view_t *, dt_undo_type_t,  void **) {aka void (*)(struct dt_view_t *, enum dt_undo_type_t,  void **)}\u2019 but argument is of type \u2018void (*)(dt_lib_module_t *, dt_undo_type_t,  void **) {aka void (*)(struct dt_lib_module_t *, enum dt_undo_type_t,  void **)}\u2019\n void dt_undo_record(dt_undo_t *self, dt_view_t *view, dt_undo_type_t type, dt_undo_data_t *data,\n      ^\ncc1: all warnings being treated as errors\nsrc/libs/CMakeFiles/history.dir/build.make:62: recipe for target 'src/libs/CMakeFiles/history.dir/history.c.o' failed\nmake[2]: *** [src/libs/CMakeFiles/history.dir/history.c.o] Error 1\nmake[2]: Target 'src/libs/CMakeFiles/history.dir/build' not remade because of errors.\nCMakeFiles/Makefile2:2295: recipe for target 'src/libs/CMakeFiles/history.dir/all' failed\nmake[1]: *** [src/libs/CMakeFiles/history.dir/all] Error 2\n. {\n  g_free(text);\n  return FALSE;\n}\n. It means that the file is missing from the current file system?\nNot sure about the name, it took me some time to parse\n. DT_DEBUG_SQLITE3_PREPARE_V2() + DT_DEBUG_SQLITE3_BIND_TEXT() is better\n. And what if this function (_lib_history_change_callback()) is called only once, so d->prev.snapshot will not get stored in dt_undo_record()?\nIt will leak.\nSo one of the solutions is to add this into gui_cleanup():\ndt_lib_history_t *d = (dt_lib_history_t *)self->data;\ng_list_free_full(d->prev.snapshot, dt_dev_free_history_item);\n(before g_free(self->data);)\n. \n. draw() callback seems like a very bad place for this.\n. Not 100% if that actually initializes all the elements to 0.0f.\nBetter to do it explicitly.\n. Not 100% if that actually initializes all the elements to 0.0f.\nBetter to do it explicitly.\n. Now this is completely wrong.\nLook what is being done for X-Trans in commit_params() and do the same.\n. I'm not sure we can/should use global data for that, it it global, so there are likely to be some problems..\nI would recommend storing it in dt_iop_demosaic_data_t in commit_params()\n. I'm not sure we can/should use global data for that, it it global, so there are likely to be some problems..\nI would recommend storing it in dt_iop_temperature_data_t in commit_params()\n. Typo, it should be intrinsics\n. TLDR: So i guess the answer is: yes, but it is so to keep it similar with other *_plain() functions.\nThere is a really deep thought behind it..\nSo there is a function dt_interpolation_compute_pixel4c(), which is a virtual, and calls some implementation, i.e. dt_interpolation_compute_pixel4c_sse() if there is SSE, or dt_interpolation_compute_pixel4c_plain().\nBUT, *_sse() variant has some vectorization, right?\nSo we can add some #pragma openmp magic into *_plain() variant, to put vectorization back, but automatically, compiler-driven.\nNote: this may be wrong for this particular case, but it is the idea for all this virtual functions like this dt_interpolation_compute_pixel4c().\n. The root cause was that it was the easiest solution to make pixelpipe call this function to call correct implementation, and not IOP-implemented process*().\nI'm not sure i like it either, is there a better way?\n. Hmm, yeah, i think i may have to factor out all alignments into some define and use it everywhere.\nBut this particular change just seemed more readable at the moment of commit, i'll drop it..\n. > Ope_n_MP\nTypos :)\n\nokay, so the logic is there is a stray process() if you want to, and a more restricted process_plain() and a rogue process_sse() where you can use inline assembly. but why keep process() and process_plain() ? sounds like making things overly complicated and inviting people to write both at the same time?\n\nThat whole mess of process() and process_plain() is because i place default_process() into function pointer where process() normally would be and do call process_plain() vs. process_sse() from there, see dt_iop_load_module_so() in src/develop/imageop.c https://github.com/darktable-org/darktable/pull/1107/files#diff-2c39561107e06b0530706f865a77eabaR288\nIf you can suggest a better way i'm all in for it :)\nWill look into it...\n. > a crazy lot of code. cool stuff, i'm sure it introduces subtle bugs :)\nI definitely did not check all the code, but for colorin/colorout the converted code produces exactly the same values.\n\nso the modules you didn't touch yet don't do anything at all?\n\nNo\n\nif we were just treating process() as process_sse() because it potentially contains sse?\n\nNo\n\nthen it would just fail for the case that the user explicitly requested omp simd/plain or has limited cpu capabilities?\n\nNo\n\nor how does that currently work with the three versions of process()?\n\nBasically it is as follows:\n1. IOP loading time:\n1.1. Does the iop provide process()? Yes - set module->process to it; No - set module->process to default_process()\n1.2. Does the iop provide process_sse2()? Yes - set module->process_sse2 to it\n1.3. Does the iop provide process_plain()? Yes - set module->process_plain;\nIf no Check whether we have other process() implementations and we can use them, if no - fail to load.\n2. Pipe running:\n2.1 Call module->process() as usual\n2.1.1 If it is a normal iop callback - process() - and it has e.g. SSE2 and e.g. current cpu does not support it - we crash :)\n2.1.2 If it is default_process() - depending on parameters, call right process*() implementation provided by iop.\ndt_iop_load_module_so() in src/develop/imageop.c https://github.com/darktable-org/darktable/pull/1107/files#diff-2c39561107e06b0530706f865a77eabaR288\n. All my commits are formatted using our .clang-format, so i seriously doubt that :)\n. layout of metadata != random changes to the colors used to draw stuff\nAnd that kinda defeats \"the default stays the same\"\n. And this actually shows 2 issues:\n1. What if iop only provides process_plain(), and openmp simd codepath is not enabled? should e.g. default_process() always fallback to module->process_plain, if it is there?\n2. If iop provides process() and e.g. process_sse2() - only process() will be run, always.\n. Well, i'm sure they can, but we will still need to place #if defined(__SSE__) around process_sse2() (and similar) functions, so i do not see any point in that..\n. @hanatos \n\noh, and about points.h. i vote for just replacing it by a 5-loc random number generator. it won't be pixel-identical, but random, too. my hope is that nobody was using random for pixel-precise artwork..\n\nHmm, currently we fall-back to drand48(). is that bad/not enough?\n. Wrong formatting\n. static\n. are there any other users for this other than temperature.c?\nand in future?\nif no better to just inline it there\n. s/four bayer/four-bayer/\n. g_regex_unref(regex);\nbefore this line\n. and g_match_info_free(match_info);\n. Here and next:\nexposure level is kinda meaningless to me.\nMaybe either just exposure or exposure compensation\n. You are sure that you want them in that specific order p1 p2 p4 p3\nNot  p1 p2 p3 p4?\n. Is there any alternative, custom manually added target?\nThat will probably even worse than this?\nAnyway, maybe add COPYONLY?\n. Hm, it seems to me that the buffer is leaking.\n. could you please not use sprintf() (at all, if possible), but use snprintf()\nsome time ago i have converted all/most sprintf to snprintf..\n. i feel like this 0..6 should be a enum\n. This also probably needs _()\n. i just wanted to visually separate this element from others in this struct.\n(all others are supposed to be intrinsics sets, this - if any of those is available)\n. I would just add a linear default callback.\nWould save one the trouble of thinking whether there is a callback.\n. So where does that * 2.0f come from?\nAnd what about X-Trans, it is not RGGB?\n. (it will be s/modules_api.h/module_api.h/)\nnot sure, i placed it in src/modules_api.h, and src/ is definitely in include path\n. Now it is fixed.\nNot sure about moving other api headers into src/common/.\n. Yes\n. One caveat i'm aware of - that validate_darktableconfig_xml target will be run always and not when xml is changed, that is, twice during normal build.\nIs that unwanted?\n. Rawprepare iop already clamps at 0.\nhttps://github.com/darktable-org/darktable/blob/90d0a0811ca00c98c587c24e350cfc4382b8f17c/src/iop/rawprepare.c#L248\n. Looks wrong. What about data->clip ?\n. Yes please, misleading comments are the worst.\n. In either case, data->clip * fminf() is the actual upper clipping threshold.\nhttps://github.com/darktable-org/darktable/blob/90d0a0811ca00c98c587c24e350cfc4382b8f17c/src/iop/highlights.c#L549-L551\n. Uh, yes, i knew that, i was only talking about data->clip multiplier :)\n. g_malloc0_n(), because you use dt_util_dstrcat(), which uses g_realloc()\n. size_t\n. { on a new line\n. If we are really going for the speed, i wonder if just computing all three values + outputting just one will be faster, less branching? (like in process_lch_bayer())\n. Did not do any profiling, but like with process_lch_bayer(), schedule(dynamic) might be better.\n. Yes, i think it just means it was able to parallelize it better, so more threads were actually running => in summary it took more time.\n. What's up with sometimes adding / and sometimes not?\nI guess for consistency it is better to have no / at the end.\n. Some of this lines are still not tab-indented only.\nOn first position is a space. \n. The only place where INSTALL_RPATH is conditional. [1/2]\n. The only place where INSTALL_RPATH is conditional. [2/2]\n. maybe in2 would be a better name..\n. I like it :)\nHowever i would prefer if those functions would just accept dt_iop_hotpixels_data_t* as it's first parameter.\nThen you'd need to pass just 1 parameter, and not 3 (data->threshold, data->multiplier, data->markfixed).\n. Setting temperature to 5500K in the temperature iop should nowadays result in very close values\n. Not Tungsten ?\n. Hm, https://www.sony.com/electronics/interchangeable-lens-cameras/ilce-6300-body-kit/specifications says Incandescent indeed, ok...\n. You did check that the color matrix for this camera in src/external/adobe_coeff.c is the right one?\nIt is the same for 2 more cameras.\n. Okay.\nI guess either all those cameras have exactly the same sensor and part of the firmware, or adobe f-ed up\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. i'd use for(size_t k=0;k<(size_t)wd*ht*4;k++)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. (size_t)\n. finally, the one that will not overflow :)\n. (size_t)\n. i'd use for(size_t k=0;k<(size_t)4*wd*ht;k+=4)\n. Based on recent changes in multiple process() variants, i believe turning this if() into a function process_exposure_fusion() and then conditionally calling it from process() would look cleaner.\n. I think this one still have 1 or 2 garbled rows.\nI.e. try y=\"52\"\n. sizeof() is size_t,\nbut i can not tell whether it will be computed in max(typeof(wd), typeof(ht), typeof(4), typeof(sizeof)), or the typeof(wd), and then just cast to the bigger storage size\nbut if we cast wd to size_t first, it won't matter\n. Looking at the origin of the entry for that camera+mode, i guess it was added without sample\n. missing newline at the end of the file\n. @mazhe\nWhy does it check length?\nBoth other dt_exif_write_blob() invocations don't\nexiv2 does throw if there are any issues, so i'm not sure what harm it could cause\n. After reading http://dev.exiv2.org/issues/1221#note-1, i'm no longer sure what to do.\nMaybe let's keep this as it is now\n. (http://dev.exiv2.org/issues/1221#note-1 happens with the old, jpeg-native way of writing metadata too, i have already checked that)\n. There is no problems with reading exif, the problem is with writing it.\nThe warning should be in dt_exif_write_blob()\n. Huh, why is it rejected in a read function, that is so strange\n. My guess would be that dt_exif_read_blob() should have first parameter uint8_t **blob\nAllocate enough memory with malloc(), and set *blob to the allocated memory.\n. Reading that memcpy() later on, i guess you need to allocate length+6 \n. Right now it is still as dependant as piece->pipe->filters was.\n. Well, right now it is there for 2 main reasons\n- I thought you suggested putting it there\n- And, right now, with processed_max (and filters), all the iops modify the object in this struct\nAs for tiling, right now it works exactly like it did without the change.\nprocessed_max is averaged when leaving tiling.\nBut filters are problematic indeed.\nThere is this tiling->xalign and tiling->xalign, and it currently set to 2, so for bayer we should be good.\nBut for X-Trans...\n. @mazhe\nUh, now that i actually read this, shouldn't it go into dt_exif_read_blob(), into if(!dng_mode) {} ?\n. That's the thing, if you unconditionally remove those tags here, they can never be used by anything.\nThis is almost alway a good thing BUT.\nOur HDR creator writes DNG.\nAnd those dng's are basically only exposure-joined, still in camera color space, not demosaiced.\nSo theoretically one could use our HDR creator to create HDR DNG from several DNG's (which had those \\/ tags), and then process that new DNG in some other software.\nSo i think these tags should be dropped not when reading, but when writing not into DNG.\n. See my reply https://github.com/darktable-org/darktable/pull/1259#issuecomment-246118716\n. Actually, we do not know which exiv2 version the darktable will be linked against.\nIt might now know about some of the tags listed here.\nSo it is safe to list any string here, but the code that deletes the tags should be safeguarded to not fail on unknown tags.\n. I think the code in dt_remove_exif_keys() should be wrapped into try {} catch () {} like in dt_exif_read_xmp_tag()\n. And uncomment these\n. Hm, now i'm not sure whether this too should be moved into dt_exif_read_blob() (but not into if(!dng_mode){})\nWhy? Because this function first reads the final written image, and then overrides the tags from blob\nI.e. i'm not sure that it is guaranteed there won't ever be valid Exif.SubImage* tags here.\ndt_exif_read_blob() only reads the original input file, so it should be safe (safer?) there...\n. I'm not sure about which function you are talking about.\ndt_exif_read_blob() is only called to get the exif blob to immediately write it into output image via dt_exif_write_blob().\nSo the blob that dt_exif_read_blob() returns is never actually used by dt.\n. All those functions with similar but not the same names are very confusing, yes :)\n. Exif can have duplicate tags, i.e. multiple tags with the same name but different values.\nSo this should be more like:\nExiv2::ExifData::iterator pos;\nwhile((pos = exif.findKey(Exiv2::ExifKey(keys[i]))) != exif.end()) exif.erase(pos);\nNo, i'm not just picking on the changes, the changes expose faults and while there, i'd like to get rid of the most obvious-ones.\n. Probably does not matter, but i'd prepend static const before std::string\n. But what if the string does not contain ., e.g. if the string is just \\0?\nPlease rewrite it to first find the . in a safe manner, checking for strsize, and then if it is there in the string bounds, replacing with \\0.\n. I think memchr() should be used, since it also takes std::size_t num, i.e. strsize\nAnd then just check whether it returned not NULL and change the character \n. At least one manufacturer seems to have one whitelevel for all raws :)\n. @johnnyrun \nI highly suspect that lib->collection_count is wrong thing to check here and in other places:\n```\n==29685==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6040005f6e4c at pc 0x7fffdbf441de bp 0x7fffffffc660 sp 0x7fffffffc650\nREAD of size 4 at 0x6040005f6e4c thread T0\n    #0 0x7fffdbf441dd in expose_filemanager /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:719\n    #1 0x7fffdbf441dd in expose /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:1418\n    #2 0x7ffff69c2f72 in dt_view_manager_expose /tmp/makepkg/darktable-git/src/darktable/src/views/view.c:521\n    #3 0x7ffff685d3ed in dt_control_expose /tmp/makepkg/darktable-git/src/darktable/src/control/control.c:297\n    #4 0x7ffff697cd26 in draw /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:447\n    #5 0x7ffff4a48830  (/usr/lib/libgtk-3.so.0+0x222830)\n    #6 0x7ffff4b885fe  (/usr/lib/libgtk-3.so.0+0x3625fe)\n    #7 0x7ffff35d91b3  (/usr/lib/libgobject-2.0.so.0+0x101b3)\n    #8 0x7ffff35f33c0 in g_signal_emit_valist (/usr/lib/libgobject-2.0.so.0+0x2a3c0)\n    #9 0x7ffff35f3fde in g_signal_emit (/usr/lib/libgobject-2.0.so.0+0x2afde)\n    #10 0x7ffff4b951b9  (/usr/lib/libgtk-3.so.0+0x36f1b9)\n    #11 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #12 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #13 0x7ffff493cf83  (/usr/lib/libgtk-3.so.0+0x116f83)\n    #14 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #15 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #16 0x7ffff493f920  (/usr/lib/libgtk-3.so.0+0x119920)\n    #17 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #18 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #19 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #20 0x7ffff4a05503  (/usr/lib/libgtk-3.so.0+0x1df503)\n    #21 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #22 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #23 0x7ffff4a06510  (/usr/lib/libgtk-3.so.0+0x1e0510)\n    #24 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #25 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #26 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #27 0x7ffff493cf83  (/usr/lib/libgtk-3.so.0+0x116f83)\n    #28 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #29 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #30 0x7ffff493f920  (/usr/lib/libgtk-3.so.0+0x119920)\n    #31 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #32 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #33 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #34 0x7ffff4ba2940  (/usr/lib/libgtk-3.so.0+0x37c940)\n    #35 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #36 0x7ffff4b954b8 in gtk_widget_send_expose (/usr/lib/libgtk-3.so.0+0x36f4b8)\n    #37 0x7ffff4a478a4 in gtk_main_do_event (/usr/lib/libgtk-3.so.0+0x2218a4)\n    #38 0x7ffff457e754  (/usr/lib/libgdk-3.so.0+0x30754)\n    #39 0x7ffff458d447  (/usr/lib/libgdk-3.so.0+0x3f447)\n    #40 0x7ffff458e59b  (/usr/lib/libgdk-3.so.0+0x4059b)\n    #41 0x7ffff458e752  (/usr/lib/libgdk-3.so.0+0x40752)\n    #42 0x7ffff35d91b3  (/usr/lib/libgobject-2.0.so.0+0x101b3)\n    #43 0x7ffff35f38ec in g_signal_emit_valist (/usr/lib/libgobject-2.0.so.0+0x2a8ec)\n    #44 0x7ffff35f3fde in g_signal_emit (/usr/lib/libgobject-2.0.so.0+0x2afde)\n    #45 0x7ffff45866e0  (/usr/lib/libgdk-3.so.0+0x386e0)\n    #46 0x7ffff4574ab7  (/usr/lib/libgdk-3.so.0+0x26ab7)\n    #47 0x7ffff5151792  (/usr/lib/libglib-2.0.so.0+0x4a792)\n    #48 0x7ffff5150d19 in g_main_context_dispatch (/usr/lib/libglib-2.0.so.0+0x49d19)\n    #49 0x7ffff51510cf  (/usr/lib/libglib-2.0.so.0+0x4a0cf)\n    #50 0x7ffff51513f1 in g_main_loop_run (/usr/lib/libglib-2.0.so.0+0x4a3f1)\n    #51 0x7ffff4a46a64 in gtk_main (/usr/lib/libgtk-3.so.0+0x220a64)\n    #52 0x7ffff6982664 in dt_gui_gtk_run /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:981\n    #53 0x400890 in main /tmp/makepkg/darktable-git/src/darktable/src/main.c:25\n    #54 0x7ffff60e5290 in __libc_start_main (/usr/lib/libc.so.6+0x20290)\n    #55 0x4008e9 in _start (/usr/bin/darktable+0x4008e9)\n0x6040005f6e4c is located 4 bytes to the left of 36-byte region [0x6040005f6e50,0x6040005f6e74)\nallocated by thread T0 here:\n    #0 0x7ffff6eff020 in __interceptor_calloc /build/gcc/src/gcc/libsanitizer/asan/asan_malloc_linux.cc:70\n    #1 0x7fffdbf3fc0a in expose_filemanager /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:616\n    #2 0x7fffdbf3fc0a in expose /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:1418\n    #3 0x7ffff69c2f72 in dt_view_manager_expose /tmp/makepkg/darktable-git/src/darktable/src/views/view.c:521\n    #4 0x7ffff685d3ed in dt_control_expose /tmp/makepkg/darktable-git/src/darktable/src/control/control.c:297\n    #5 0x7ffff697cd26 in draw /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:447\n    #6 0x7ffff4a48830  (/usr/lib/libgtk-3.so.0+0x222830)\nSUMMARY: AddressSanitizer: heap-buffer-overflow /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:719 in expose_filemanager\nShadow bytes around the buggy address:\n  0x0c08800b6d70: fa fa fa fa fa fa fa fa fa fa fd fd fd fd fd fa\n  0x0c08800b6d80: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fd\n  0x0c08800b6d90: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fa\n  0x0c08800b6da0: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fd\n  0x0c08800b6db0: fa fa fd fd fd fd fd fd fa fa fd fd fd fd fd fd\n=>0x0c08800b6dc0: fa fa fd fd fd fd fd fa fa[fa]00 00 00 00 04 fa\n  0x0c08800b6dd0: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fd\n  0x0c08800b6de0: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fa\n  0x0c08800b6df0: fa fa fd fd fd fd fd fa fa fa fd fd fd fd fd fa\n  0x0c08800b6e00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c08800b6e10: fa fa fa fa fa fa fa fa fa fa fd fd fd fd fd fa\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07\n  Heap left redzone:       fa\n  Heap right redzone:      fb\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack partial redzone:   f4\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Container overflow:      fc\n  Array cookie:            ac\n  Intra object redzone:    bb\n  ASan internal:           fe\n  Left alloca redzone:     ca\n  Right alloca redzone:    cb\n==29685==ABORTING\n```\nand \n```\n==30312==ERROR: AddressSanitizer: heap-buffer-overflow on address 0x6040006659b4 at pc 0x7fffdbf404fb bp 0x7fffffffc660 sp 0x7fffffffc650\nREAD of size 4 at 0x6040006659b4 thread T0\n    #0 0x7fffdbf404fa in expose_filemanager /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:693\n    #1 0x7fffdbf404fa in expose /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:1418\n    #2 0x7ffff69c2f72 in dt_view_manager_expose /tmp/makepkg/darktable-git/src/darktable/src/views/view.c:521\n    #3 0x7ffff685d3ed in dt_control_expose /tmp/makepkg/darktable-git/src/darktable/src/control/control.c:297\n    #4 0x7ffff697cd26 in draw /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:447\n    #5 0x7ffff4a48830  (/usr/lib/libgtk-3.so.0+0x222830)\n    #6 0x7ffff4b885fe  (/usr/lib/libgtk-3.so.0+0x3625fe)\n    #7 0x7ffff35d91b3  (/usr/lib/libgobject-2.0.so.0+0x101b3)\n    #8 0x7ffff35f33c0 in g_signal_emit_valist (/usr/lib/libgobject-2.0.so.0+0x2a3c0)\n    #9 0x7ffff35f3fde in g_signal_emit (/usr/lib/libgobject-2.0.so.0+0x2afde)\n    #10 0x7ffff4b951b9  (/usr/lib/libgtk-3.so.0+0x36f1b9)\n    #11 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #12 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #13 0x7ffff493cf83  (/usr/lib/libgtk-3.so.0+0x116f83)\n    #14 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #15 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #16 0x7ffff493f920  (/usr/lib/libgtk-3.so.0+0x119920)\n    #17 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #18 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #19 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #20 0x7ffff4a05503  (/usr/lib/libgtk-3.so.0+0x1df503)\n    #21 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #22 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #23 0x7ffff4a06510  (/usr/lib/libgtk-3.so.0+0x1e0510)\n    #24 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #25 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #26 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #27 0x7ffff493cf83  (/usr/lib/libgtk-3.so.0+0x116f83)\n    #28 0x7ffff498d2ec  (/usr/lib/libgtk-3.so.0+0x1672ec)\n    #29 0x7ffff4991f4f  (/usr/lib/libgtk-3.so.0+0x16bf4f)\n    #30 0x7ffff493f920  (/usr/lib/libgtk-3.so.0+0x119920)\n    #31 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #32 0x7ffff498823f in gtk_container_propagate_draw (/usr/lib/libgtk-3.so.0+0x16223f)\n    #33 0x7ffff4988321  (/usr/lib/libgtk-3.so.0+0x162321)\n    #34 0x7ffff4ba2940  (/usr/lib/libgtk-3.so.0+0x37c940)\n    #35 0x7ffff4b94fda  (/usr/lib/libgtk-3.so.0+0x36efda)\n    #36 0x7ffff4b954b8 in gtk_widget_send_expose (/usr/lib/libgtk-3.so.0+0x36f4b8)\n    #37 0x7ffff4a478a4 in gtk_main_do_event (/usr/lib/libgtk-3.so.0+0x2218a4)\n    #38 0x7ffff457e754  (/usr/lib/libgdk-3.so.0+0x30754)\n    #39 0x7ffff458d447  (/usr/lib/libgdk-3.so.0+0x3f447)\n    #40 0x7ffff458e59b  (/usr/lib/libgdk-3.so.0+0x4059b)\n    #41 0x7ffff458e752  (/usr/lib/libgdk-3.so.0+0x40752)\n    #42 0x7ffff35d91b3  (/usr/lib/libgobject-2.0.so.0+0x101b3)\n    #43 0x7ffff35f38ec in g_signal_emit_valist (/usr/lib/libgobject-2.0.so.0+0x2a8ec)\n    #44 0x7ffff35f3fde in g_signal_emit (/usr/lib/libgobject-2.0.so.0+0x2afde)\n    #45 0x7ffff45866e0  (/usr/lib/libgdk-3.so.0+0x386e0)\n    #46 0x7ffff4574ab7  (/usr/lib/libgdk-3.so.0+0x26ab7)\n    #47 0x7ffff5151792  (/usr/lib/libglib-2.0.so.0+0x4a792)\n    #48 0x7ffff5150d19 in g_main_context_dispatch (/usr/lib/libglib-2.0.so.0+0x49d19)\n    #49 0x7ffff51510cf  (/usr/lib/libglib-2.0.so.0+0x4a0cf)\n    #50 0x7ffff51513f1 in g_main_loop_run (/usr/lib/libglib-2.0.so.0+0x4a3f1)\n    #51 0x7ffff4a46a64 in gtk_main (/usr/lib/libgtk-3.so.0+0x220a64)\n    #52 0x7ffff6982664 in dt_gui_gtk_run /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:981\n    #53 0x400890 in main /tmp/makepkg/darktable-git/src/darktable/src/main.c:25\n    #54 0x7ffff60e5290 in __libc_start_main (/usr/lib/libc.so.6+0x20290)\n    #55 0x4008e9 in _start (/usr/bin/darktable+0x4008e9)\n0x6040006659b4 is located 0 bytes to the right of 36-byte region [0x604000665990,0x6040006659b4)\nallocated by thread T0 here:\n    #0 0x7ffff6eff020 in __interceptor_calloc /build/gcc/src/gcc/libsanitizer/asan/asan_malloc_linux.cc:70\n    #1 0x7fffdbf3fc0a in expose_filemanager /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:616\n    #2 0x7fffdbf3fc0a in expose /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:1418\n    #3 0x7ffff69c2f72 in dt_view_manager_expose /tmp/makepkg/darktable-git/src/darktable/src/views/view.c:521\n    #4 0x7ffff685d3ed in dt_control_expose /tmp/makepkg/darktable-git/src/darktable/src/control/control.c:297\n    #5 0x7ffff697cd26 in draw /tmp/makepkg/darktable-git/src/darktable/src/gui/gtk.c:447\n    #6 0x7ffff4a48830  (/usr/lib/libgtk-3.so.0+0x222830)\nSUMMARY: AddressSanitizer: heap-buffer-overflow /tmp/makepkg/darktable-git/src/darktable/src/views/lighttable.c:693 in expose_filemanager\nShadow bytes around the buggy address:\n  0x0c08800c4ae0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c08800c4af0: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c08800c4b00: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c08800c4b10: fa fa fa fa fa fa fa fa fa fa 00 00 00 00 00 00\n  0x0c08800c4b20: fa fa fa fa fa fa fa fa fa fa 00 00 00 00 00 00\n=>0x0c08800c4b30: fa fa 00 00 00 00[04]fa fa fa fd fd fd fd fd fa\n  0x0c08800c4b40: fa fa fd fd fd fd fd fa fa fa fa fa fa fa fa fa\n  0x0c08800c4b50: fa fa 00 00 00 00 00 00 fa fa fa fa fa fa fa fa\n  0x0c08800c4b60: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\n  0x0c08800c4b70: fa fa fa fa fa fa fa fa fa fa 00 00 00 00 00 fa\n  0x0c08800c4b80: fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa fa\nShadow byte legend (one shadow byte represents 8 application bytes):\n  Addressable:           00\n  Partially addressable: 01 02 03 04 05 06 07\n  Heap left redzone:       fa\n  Heap right redzone:      fb\n  Freed heap region:       fd\n  Stack left redzone:      f1\n  Stack mid redzone:       f2\n  Stack right redzone:     f3\n  Stack partial redzone:   f4\n  Stack after return:      f5\n  Stack use after scope:   f8\n  Global redzone:          f9\n  Global init order:       f6\n  Poisoned by user:        f7\n  Container overflow:      fc\n  Array cookie:            ac\n  Intra object redzone:    bb\n  ASan internal:           fe\n  Left alloca redzone:     ca\n  Right alloca redzone:    cb\n==30312==ABORTING\n.\nint query_ids = (int )calloc(max_rows * max_cols, sizeof(int));\n```\nidx < lib->collection_count\nI'm pretty sure i can have selection bigger than what fits on one screen. (assuming that is what that code asserts)\n. Move DT_UNDO_ALL into dt_undo_type_t\n. Sure this should be g_free()?\nIf we manage it, malloc()/free() is much better.\n. malloc()\n. Hm, then it should be like this:\ntypedef enum dt_undo_type_t\n{\n  DT_UNDO_GEOTAG = 1 << 0,\n  DT_UNDO_HISTORY = 1 << 1,\n  DT_UNDO_ALL = DT_UNDO_GEOTAG | DT_UNDO_HISTORY\n} dt_undo_type_t;\nI'd be surprised to learn that it does not work...\n. Sure all the sampling above should not be done after this check?\n. I mean, if x >= width || y >= height, we do need to do that sampling too, just doing barrier will result in garbage?\n. Ugh :(\n. @upegelow \nhmm, so you propose:\nif(err == CL_SUCCESS)\n{\n  for(size_t i = 0; i < infoint; i++) printf(\"%zd \", infointtab[i]);\n  free(infointtab);\n  infointtab = NULL;\n}\nelse\n{\n  dt_print(DT_DEBUG_OPENCL, \"[opencl_init] could query CL_DEVICE_MAX_WORK_ITEM_SIZES: %d\\n\", err);\n  goto finally;\n}\nand so on?\n. Nitpicking: new line before // Fix for Canon 80D mraw format.\n. Nitpicking: newline before // Fix for Canon 80D mraw format.\n. And before the loop\n. same here\n. and here\n. and here\n. and here\n. Tested, works.\nOk, so either camera indeed writes uncompressed raw, or rawspeed's detection is borked in this case.\n. To be honest, i see no difference on the images with old and new color matrix.\n. I had that, it's some caching issue.\nRemove that image from your library.db, and re-import it.\nThen it will stop thinking it is DT_IMAGE_4BAYER, will only look for 3 coeffs, and it should be back to normal.\n. Please just use https://github.com/darktable-org/darktable/blob/master/tools/dngmeta.sh or https://github.com/darktable-org/darktable/blob/master/tools/dngmeta.rb\n. Are you sure?\n. These come from Adobe DNG Converter?\n. i.e. it should be 8113, ...\n. Hm, it's Pentax, don't they natively write DNG? Is it from that dng?\n. Ah, even better then\n. Wrong crop. But i'll fix that manually\n. Hm, indeed, sorry.\nI suppose it means i need to finish migrating dngmeta.sh into dngmeta.rb and drop dngmeta.sh.\n. In general i think it does indeed make sense.\nOne small remark, DO variable name sounds kinda generic.\nPersonally i'd use something somewhat resembling dry-run, from git clean.\n(And yes, the default should be to NOT do anything.)\nI did not test the changes though.\n. I left it out of my comment, but DRYRUN also implies that the logic needs to be inversed, else DRYRUN=no implies that it should purge, but the code will actually imply that it should NOT purge\nDRYRUN == dry run, i.e. empty run, i.e. with no changes.\n. Hm, so what happens if it is NULL?\n. Hm, how do we know that DMC-G8 is DMC-G80?\nhttp://www.photographyblog.com/reviews/panasonic_lumix_dmc_g80_review/ says \"DMC-G80 (also known as the Panasonic G85)\"\n. Ah, i see, ADC release notes say: Panasonic DMC-G8 (DMC-G80, DMC-G81, DMC-G85)\n. Uh, oh, so it had intentionally-wrong white level set..\n. Hmm.\nI guess i \"broke\" it in 6810787e316f3a29af2b32d63529c34efec57e36, essentially deprecated it.\nNow, will need to check which cameras have  black != \"0\" and no nikon_override_auto_black (as of before that commit ^) :/\nIf there are any, i suspect they will now have wrong black level.\nAnd then drop all <Hint name=\"nikon_override_auto_black\" value=\"\"/>\n. Based on these samples, it seems it's really just ISO160.\nI'd use iso_list=\"\" in this case, like ~/darktable/tools/dngmeta.rb *.DNG suggests:\n<Camera make=\"NIKON CORPORATION\" model=\"NIKON 1 AW1\">\n                <ID make=\"\" model=\"\">Nikon 1 AW1</ID>\n                <Sensor black=\"0\" white=\"4095\"/>                                                                                                                                                                                                                               \n                <Sensor black=\"0\" white=\"3300\" iso_list=\"160\"/>                                                                                                                                                                                                                \n        </Camera>\n. Oh, nice catch :/\n. I'd be surprized to learn that you can not pass that to normal configure_file() call.\nI.e. this should be done when configuring ${CMAKE_CURRENT_BINARY_DIR}/darktablerc\n. Intel? So no amd?\n. Spaces before #if.\nYou really  should follow https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md, in particular https://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md#coding-style\nJust set up clang-format hook and never worry about it again.\n. What is this about?\n. Newline, modelines\n. header, Newline, modelines\n. modelines\n. header\n. Newline, modelines\n. header\n. Newline, modelines\n. Newline, modelines\n. Newline, modelines\n. Newline, modelines\n. header\n. Newline, modelines\n. header\n. Ugh, ok.\nBut even then, it creates kinda-circular dependency chain for ${CMAKE_CURRENT_BINARY_DIR}/darktablerc.\nI really doubt having 2 different targets providing the same output file is correct.\n. it's only darktable.\nnot Darktable, not DarkTable, not Dark Table, etc.\n. > Shadow warnings, like warning: declaration of 'data' shadows a previous local [-Wshadow] const uchar8 *data = mFile->getData(key_off, 1);\nThey are in rawspeed, and for rawspeed, i keep errors for -Wshadow disabled.\nIf they are errors for you, something is wrong.\n. When in doubt, check on proper system :)\nThat is exactly how it should be, all that is intentional and is done by dt, not gtk.\n. > Where is the -Wshadow disabled? If I remove the -Werror definition from CmakeList.txt, rawspeed gives me these shadow warnings still. I see -Wshadow ignore pragmas in the code elsewehere (like masks.c), but for Rawspeed I could not find.\nSo are these warnings or errors? Please be specific.\nThey are supposed to be warnings.\n. If there is no SOURCE_PACKAGE, then there is no -Werror at all.\nMaybe i'm missing something, which -Werror does turn them into errors for you? The one that you pass manually?\n. Ok, let's take one step back.\nhttps://github.com/darktable-org/darktable/pull/1327#discussion_r85093849 - he is talking about the warnings in general, i.e. the ones that are errors without this change.\nhttps://github.com/darktable-org/darktable/pull/1327#discussion_r85102258 - in src/external/rawspeed/, -Wshadow is a warning, not a error, no matter if -Werror is set here or not - https://github.com/darktable-org/darktable/blob/7c4eb199d3f95937e4d18ed25504f2c1f788f2dc/src/external/rawspeed/CMakeLists.txt#L3\nThat is the only thing i was saying.\n. Do check whether https://cmake.org/cmake/help/v3.0/module/FindThreads.html just works.\nI wanted to switch to that from this module, but did not.\n. > clears the end-of-file indicator for the stream\nCan't you cache it before calling fseek() and check the cached value for EOF after calling fseek()?\nDid not read the code though.\n. Still here\n. SIZE_T (uppercase), is that a win-specific thing?\n. i may be wrong, but it might be better to add some suffixes to 1024 here, else maybe the wrong type will be used?\nOr explicitly cast both operands to some big type.\n. does not matter too much, but since you asked, the .clang-format should have formatted that as GetModuleFileNameW(NULL, fn, G_N_ELEMENTS(fn));, i.e. without spaces before the brace.\n. still here\n. Nothing _WIN32-specific, why conditional?\n. A word of caution about defines like that, __*__ define pattern is generally reserved for system headers.\nI really don't like that even now we are using things like this internally.\n```\n7.1.3 Reserved identifiers\nEach header declares or defines all identifiers listed in its associated subclause, and optionally declares or\ndefines identifiers listed in its associated future library directions subclause and identifiers which are always\nreserved either for any use or for use as file scope identifiers.\n\nAll identifiers that begin with an underscore and either an uppercase letter or another underscore are always\n  reserved for any use.\nAll identifiers that begin with an underscore are always reserved for use as identifiers with file scope in both\n  the ordinary and tag name spaces.\nEach macro name in any of the following subclauses (including the future library directions) is reserved for\n  use as specified if any of its associated headers is included; unless explicitly stated otherwise (see 7.1.4).\nAll identifiers with external linkage in any of the following subclauses (including the future library directions)\n  are always reserved for use as identifiers with external linkage.154\nEach identifier with file scope listed in any of the following subclauses (including the future library directions)\n  is reserved for use as a macro name and as an identifier with file scope in the same name space if any of\n  its associated headers is included.\n```\n\nhttps://stackoverflow.com/questions/228783/what-are-the-rules-about-using-an-underscore-in-a-c-identifier/228797#228797\n. The CI will tell you :) But i do not expect it to cause issues.\n. Makes sense, but maybe lround() since we want an integer.\n. Not missing for here? Or else i'm not sure why this #pragma is here..\n. \"successive\" looks strange there, i even had to google it\nsubsequent?\n. Yeah, i think i expected to see word consecutive here.\n. @karlstevens please separate them into separate pr.\nWb presets i can just merge.\n. As CI tells you, that is not the right way to include noiseprofile.\nYou need to find already existing \"maker\": \"Pentax\", section,\nand insert inner model ({ \"comment\": \"k-1 contributed b ... ]) e.g. before \"model\": \"K-S2\" entry.\n. And, the noise profile is already a pr https://github.com/darktable-org/darktable/pull/1275/files\n. +CHECK_COMPILER_FLAG_AND_ENABLE_IT(-Wformat)\nYes, i know that it is part of -Wall.\n. YES.\nNow that it does CHECK_COMPILER_FLAG_AND_ENABLE_IT(-Wall), it may be redundant, but better safe than sorry.\nIf you want, also look at https://redmine.darktable.org/attachments/2583/CMakeError.log#L49 (from https://redmine.darktable.org/issues/11199)\n. darktable is unable to get a list of albums.\n. while i won't touch on having separate ci for windows/having ci for windows at this moment in time, ci-build.sh script name will be confusing.\nit should be ci-script-windows.sh\n. Maybe PATH_MAX ?\n. http://en.cppreference.com/w/cpp/string/multibyte/mbstowcs\nlen -   number of wide characters available in the array pointed to by dst\nSo it should be more like\nmbstowcs(filen, filename, sizeof(filen) / sizeof(wchar_t));\n. > So mbstowcs(filen, filename, MAX_PATH); because sizeof(filen) / sizeof(wchar_t) == MAX_PATH.\nWhich is different from mbstowcs(filen, filename, sizeof(filen) / sizeof(wchar_t)); how?\n. mbstowcs() needs len only to know how big output array (filen) is. \nSo if you just properly pass either MAX_PATH or equivalent sizeof(filen) / sizeof(wchar_t) (latter is preferred.), it should be just fine, no?\n. > There are lot of other code pieces which are enclosed in some shape or form in conditional compiles like _WIN32 or __WIN32__or G_OS_WIN32. First I need to unify them using at least the same conditional, and then carefully review all as these code parts, as most likely they were not (fully) tested.\nI think it should not be done in this pr, but after. Let's keep this as small as it can be.\n. Yep, better, now this will not overflow.\nBut still, don't pass len into mbstowcs() call.\nEverywhere else, in such cases we pass the actual destination size.\n. I believe http://www.imaging-resource.com/PRODS/panasonic-lx10/panasonic-lx10A.HTM says that LX9, LX10 and LX15 are the same camera. And that page has DMC-LX10 sample.\n. Something is wrong here, i get different results, especially for ISO80, especially for ISO80 whitelevel.\n```\n../tools/dngmeta.rb lx15/*.DNG\ninvsensors {[142, 2095]=>[80], [142, 3400]=>[100], [142, 4095]=>[125], [143, 4095]=>[160, 200, 250, 320, 400], [144, 4095]=>[640, 800], [145, 4095]=>[1250, 1600], [149, 4095]=>[3200], [154, 4095]=>[6400], [166, 4095]=>[12800], [167, 4095]=>[25600]}\nsensors [[80, [142, 2095]], [100, [142, 3400]], [125, [142, 4095]], [160, [143, 4095]], [200, [143, 4095]], [250, [143, 4095]], [320, [143, 4095]], [400, [143, 4095]], [640, [144, 4095]], [800, [144, 4095]], [1250, [145, 4095]], [1600, [145, 4095]], [3200, [149, 4095]], [6400, [154, 4095]], [12800, [166, 4095]], [25600, [167, 4095]]]\nmostfrequent [[143, 4095], [160, 200, 250, 320, 400]]\ninvsensors {[142, 2095]=>[80], [142, 3400]=>[100], [142, 4095]=>[125], [144, 4095]=>[640, 800], [145, 4095]=>[1250, 1600], [149, 4095]=>[3200], [154, 4095]=>[6400], [166, 4095]=>[12800], [167, 4095]=>[25600]}\n    <Camera make=\"Panasonic\" model=\"DMC-LX15\">\n            <ID make=\"\" model=\"\">Panasonic DMC-LX9</ID>\n            <Sensor black=\"143\" white=\"4095\"/>\n            <Sensor black=\"142\" white=\"2095\" iso_list=\"80\"/>\n            <Sensor black=\"142\" white=\"3400\" iso_list=\"100\"/>\n            <Sensor black=\"142\" white=\"4095\" iso_list=\"125\"/>\n            <Sensor black=\"144\" white=\"4095\" iso_list=\"640 800\"/>\n            <Sensor black=\"145\" white=\"4095\" iso_list=\"1250 1600\"/>\n            <Sensor black=\"149\" white=\"4095\" iso_list=\"3200\"/>\n            <Sensor black=\"154\" white=\"4095\" iso_list=\"6400\"/>\n            <Sensor black=\"166\" white=\"4095\" iso_list=\"12800\"/>\n            <Sensor black=\"167\" white=\"4095\" iso_list=\"25600\"/>\n    </Camera>\n\n``\n. libglade and SDL are not used at all and not needed.\nnot sure about gtk-engines.\n. Yes,dngmeta.rbis non-deterministic in that regard, https://github.com/darktable-org/darktable/blob/62416056d956a05f891846dc78fc11033d3c699b/tools/dngmeta.rb#L89-L92\nIf you changeBLACKDIFF_MAXto0, the script then should fail with an error message.\nI'm not 100% sure whatdngmeta.rb` should do else if there is more than one black level for a given ISO.\n. > For one file it should return the same value as dngmeta.sh, or?\nYes, i expect that when called for a single DNG, it should provide the same output as dngmeta.sh\nBTW: i plan on eventually dropping dngmeta.sh, once dngmeta.rb fully supersedes it. So if dngmeta.rb has any bugs, better raise them in redmine.\n. > it does not fail with BLACKDIFF_MAX to 0.\nHm, i did not check before writing. It does not fail, but it does warn and produce intentionally-wrong results:\n```\nISO 125 has multiple variants with too different black levels: [[141, 4095], [142, 4095]]\nISO 160 has multiple variants with too different black levels: [[142, 4095], [143, 4095]]\nISO 250 has multiple variants with too different black levels: [[142, 4095], [143, 4095]]\nISO 400 has multiple variants with too different black levels: [[142, 4095], [143, 4095]]\nISO 800 has multiple variants with too different black levels: [[142, 4095], [144, 4095]]\nISO 1600 has multiple variants with too different black levels: [[141, 4095], [145, 4095]]\ninvsensors {[142, 2095]=>[80], [142, 3400]=>[100], [-1, -1]=>[125, 160, 250, 400, 800, 1600], [143, 4095]=>[200, 320], [144, 4095]=>[640], [145, 4095]=>[1250], [149, 4095]=>[3200], [154, 4095]=>[6400], [166, 4095]=>[12800], [167, 4095]=>[25600]}\nsensors [[80, [142, 2095]], [100, [142, 3400]], [125, [-1, -1]], [160, [-1, -1]], [200, [143, 4095]], [250, [-1, -1]], [320, [143, 4095]], [400, [-1, -1]], [640, [144, 4095]], [800, [-1, -1]], [1250, [145, 4095]], [1600, [-1, -1]], [3200, [149, 4095]], [6400, [154, 4095]], [12800, [166, 4095]], [25600, [167, 4095]]]\nmostfrequent [[-1, -1], [125, 160, 250, 400, 800, 1600]]\ninvsensors {[142, 2095]=>[80], [142, 3400]=>[100], [143, 4095]=>[200, 320], [144, 4095]=>[640], [145, 4095]=>[1250], [149, 4095]=>[3200], [154, 4095]=>[6400], [166, 4095]=>[12800], [167, 4095]=>[25600]}\n    <Camera make=\"Panasonic\" model=\"DMC-LX15\">\n            <ID make=\"\" model=\"\">Panasonic DMC-LX9</ID>\n            <Sensor black=\"-1\" white=\"-1\"/>\n            <Sensor black=\"142\" white=\"2095\" iso_list=\"80\"/>\n            <Sensor black=\"142\" white=\"3400\" iso_list=\"100\"/>\n            <Sensor black=\"143\" white=\"4095\" iso_list=\"200 320\"/>\n            <Sensor black=\"144\" white=\"4095\" iso_list=\"640\"/>\n            <Sensor black=\"145\" white=\"4095\" iso_list=\"1250\"/>\n            <Sensor black=\"149\" white=\"4095\" iso_list=\"3200\"/>\n            <Sensor black=\"154\" white=\"4095\" iso_list=\"6400\"/>\n            <Sensor black=\"166\" white=\"4095\" iso_list=\"12800\"/>\n            <Sensor black=\"167\" white=\"4095\" iso_list=\"25600\"/>\n    </Camera>\n\n```\nNote the black=\"-1\" white=\"-1\"\n. sqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1252, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1253, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1252, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1253, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1252, function dt_collection_image_offset_with_collection(): bind or column index out of range\nsqlite3 error: /home/lebedevri/darktable/src/common/collection.c:1253, function dt_collection_image_offset_with_collection(): bind or column index out of range\n. Tried, and with 5 images in db (all shown) from 2 filmstrips, there seems to be off-by-one somewhere here.\n. Yes.\n. It looked as off-by-one.\nFor first image, \"#1\", press space and for second image,  it still says \"#1\", press space and for third image it says \"#2\".\nThen press back-space, and for second image it says \"#3\", press back-space, and for first image it says \"#2\",\n. @houz no, all the time.\n. I'm specifically interested in darkroom with space/backspace navigation.\n. spaces\n. put all this into new function, and just call it here. let's try to not make this shiny new file unnecessary messy :). if dt is being compiled without GM, this function is only called once.\nis there any harm in just setting this stuff twice? i'd guess no\nI would drop the conditional. And if it succeeded, when saving backtrace, does it notify where did it save it to?. [00:24:53]  can you call SetUnhandledExceptionFilter() from src/common/system_signal_handling.c?\n[00:24:56]  saving it in the first place and then restore?\n[00:24:59]  yeah\n[00:25:19]  whoo, indeed good idea!\n[00:29:57]  i think it should be like this  0. call dt_set_unhandled_exception_handler_win(), ALWAYS  1. if(1 == _times_handlers_were_set) call SetUnhandledExceptionFilter(), and save the result  2. immediately call SetUnhandledExceptionFilter() with the saved result\n[00:30:15]  assuming you can call SetUnhandledExceptionFilter(), that should work?. So does anything bad happen if this is called second time?\nIf not, i think we should just do it.\nReason: gm already does some dumb shit with signal handlers. even if it currently does not call ExcHndlSetLogFileNameA() by itself, there is absolutely zero guarantee that it will not do so in the future...\nOtherwise replace if(...) ... with if(!...) return;   .... why not MAX(0, ...) ?\n. There is also fmax(), but since these are integers, glib-provided MAX()/MIN() macro definitely should be enough.. @ArchangeGabriel Indeed, thank you.. @upegelow done.. Change to\nDT_MODULE_INTROSPECTION(2, dt_iop_grain_params_t). Add:\n```\nint legacy_params(dt_iop_module_t self, const void const old_params, const int old_version, void *new_params,\n                  const int new_version)\n{\n  if(old_version == 1 && new_version == 2)\n  {\n    typedef struct dt_iop_grain_params_v1_t\n    {\n      _dt_iop_grain_channel_t channel;\n      float scale;\n      float strength;\n    } dt_iop_grain_params_v1_t;\ndt_iop_grain_params_v1_t *o = old_params;\ndt_iop_grain_params_t *n = new_params;\n\nn->channel = o->channel;\nn->scale = o->scale;\nn->strength = o->strength;\nn->midtones_bias = 0.0; // ??? _must_ produce the same results as before this pr\n\nreturn 0;\n\n}\n  return 1;\n}\n. `static`. `static`. `static`. *maybe*\nifdef _OPENMP\npragma omp parallel for default(none) collapse(2)\nendif\n``\n.100 * dt_lut_lookup_2d_1c(..., in[0] / 100)`\nMove that 100 into curve, to avoid dividing, and then multiplying. / 100\nhere and everywhere, isn't that an integer division?. Also, this does not seem nice, it is better to make p->midtones_bias contain the same scale as the slider, and if needed, let the commit_params() do the scaling.. I would guess that the new default behavior should be to produce the grain that makes use of this pr.\nI.e. that default should not be 0.0.. $ man 3 log :\n```\nLOG(3)                                                                                                                  Linux Programmer's Manual                                                                                                                 LOG(3)\nNAME\n       log, logf, logl - natural logarithmic function\nSYNOPSIS\n       #include \n   double log(double x);\n\n``\nI'm not sure you intended it to actually use double versions. All these suffix-less constants seem scary, too easy to unintentionally do int-based operation i'd say.\nAppend.0f. Same as forpaper_resp(). All the power of peer review did not notice that this can't possibly work, it should bestrstr()`.\nClearly, i somehow missed a combination of parameters that would expose this.... Most importantly, you changed the size of params struct, so old history stacks, with params struct of old size are now broken.\nBumping version (1->2) at least prevents them from being broken silently.\nAs for DT_MODULE_INTROSPECTION(), it is just a magic word for introspection generator to create varous functions to be able to generate/modify the params from code easily.. Same applies to exp(), it should probably be expf(). Same applies to exp(), it should probably be expf(). Hm, or you could make that slider have 0..1 range.\nI'm not sure whether it is better or worse than percents though.. Corresponding doc/man/po/it.po needs to be added at the same time as this line.. Makes sense.. No.\nWhat about introspection?. If for consistency with the old code in this IOP, then yes, probably better to handle it in callbacks.\nBut i think in new code it should be done in commit_params() if needed at all.\nEdit: because displaying parameter with one range (0..100%) in gui, and with another rande in params and introspection (0..1) will probably be confusing for someone who tries to use introspection.. Why do you need this helper function?\nIt's definition is completely equivalent to the one of dt_masks_free_form() - \nvoid dt_masks_free_form(dt_masks_form_t *form);\ndt_masks_form_t or void does not matter, and casting is unneeded in C.. Could you please collapse it all into one #pragma omp parallel section with multiple #pragma omp for sections inside, please?\nElse, i will have to do as part of upcoming cleanup.. fminf()/fminf() are slower than MIN()/MAX().\nback then i specifically had to use those macros, else IIRC reduction() had no effect.\nDoes it still matter, or the dramatic decrease of workarea reduces pressure here?. That way, bufptr, will probably not need to appear in shared(). THREADS_PREFER_PTHREAD_FLAG is not in cmake-3.0, which we depend on.. Also, we specifically want pthreads, and this will not fail if it does not find pthreads, but finds something else.\nSomething like this is needed https://github.com/darktable-org/rawspeed/blob/5db36ca57ede56829cb90ec68a528d593ebf4cdc/RawSpeed/CMakeLists.txt#L4-L6. Looks ugly :/. Later on, we look for pthreads using our own findpthreads.cmake module.\nhttps://github.com/mazhe/darktable/blob/8787f60969496381032b5bb1a1e0d8bbdf28e910/src/CMakeLists.txt#L240\nhttps://github.com/mazhe/darktable/blob/8787f60969496381032b5bb1a1e0d8bbdf28e910/cmake/modules/FindPThread.cmake\nI guess it should be dropped.. Basically the only argument against using CMake's FindThread is that there is no way to tell it to only look for pthreads, but that is fixable, see rawspeed link. > Ho, you were meaning to drop part of the code, not the whole pull request.\nUhm, yes :). Looking at https://github.com/Kitware/CMake/blob/v3.1.3/Modules/FindThreads.cmake, i guess THREADS_PREFER_PTHREAD_FLAG + Threads::Threads import target would simplify it.\nBut we depend on cmake-3.0, and that would require bumping dep to 3.1;\nCan not say whether it would be ok or not. And i think it is in the visibility scope of that module, so i'm not sure it can even be used here.. Nice!\n\nthe only configuration I cannot test is win64.\n\ndarktable does not work on windows anyway, it would not even compile there.\n(there is a wip pr, but it is a pr)\n. Hm, yes, but where does libdarktable recieve CMAKE_THREAD_LIBS_INIT?\nI think you want to add here:\nlist(APPEND LIBS ${CMAKE_THREAD_LIBS_INIT}). CMAKE_THREAD_LIBS_INIT. No need, It is possible to merge the pr one commit through github.. @itinerarium please commit a fix and post a link to the commit here, i'll pick.. ```\nif defined (WIN32)\nWorks just fine. So what are the reasons for using `_WIN32`. Let me reword. We don't define either one of those (or do we?)\nWhat does work with `_WIN32` that doesn't work with `WIN32`?. https://ci.appveyor.com/project/LebedevRI/rawspeed/build/66/job/sa02r2rpebugwmg0#L1122\n^ that does not fail to compile, and it uses `WIN32`, not `_WIN32`. Illegal how? Against standard - yes. Does any compiler with default settings say anything about definition of such a define? No, only (?) clang has non-default warning. So user manipulation with these defines should be classified as broken build environment, surely nothing we can do anything about.\nAnd yes, if this is specific to Microsoft compilers, then we should not worry..\n/home/lebedevri/darktable/src/common/locallaplacian.c:545:0: error: ignoring #pragma omp parallel [-Werror=unknown-pragmas]\n #pragma omp parallel for default(none) schedule(static) collapse(2) shared(w,h,buf,output,l,gamma,padded)\n.\n/home/lebedevri/darktable/src/common/locallaplacian.c:563:0: error: ignoring #pragma omp parallel [-Werror=unknown-pragmas]\n #pragma omp parallel for default(none) schedule(dynamic) collapse(2) shared(w,output,buf)\n. Nope, won't take that.. I'm going to merge everything but that commit. We don't take custom base/tone curves. And custom color matrices. Because we have no means (and hands) to verify their validity.. No, that is strictly only about custom base/tone curves and custom color matrices.. For noiseprofile, better open new issue on redmine with the results attached. Can't we `#undef MIN` and `#undef MAX` and define our own, NAN-safe versions?. You can `#define` them just before this block of code, and add some suffix to them (`_FLTS`), and `#undef` right after..diff\nfloat *\n+const\n buf = dt_alloc_align(16, nbpoints * 2 * 3 * sizeof(float));\nanddiff\nshared(modifier\n-, buf\n)\n. Hmm,c\npragma omp barrier\nis not needed here?. We write to `*buf`, not `buf`.. Show what? That it compiles? Sure: (yes, this is with OpenMP enabled)\n~/darktable/build$ make lens\n[  0%] Built target validate-cameras.xml\n[ 31%] Built target rawspeed\n[ 31%] Built target lautoc\n[ 31%] Updating version string (git checkout)\nVersion string: 2.3.0+204~g7ba90c95b-dirty\n[ 31%] Built target create_version_gen\n[ 31%] Built target generate_version\n[ 31%] Built target generate_metadata\n[ 31%] Checking validity of data/darktableconfig.xml\n[ 31%] Built target validate_darktableconfig_xml\n[ 31%] Built target generate_preferences\n[ 31%] Built target rawspeed_static\n[ 95%] Built target lib_darktable\n[100%] Built target lens\n~/darktable/build$ git --no-pager diff -p -U8\ndiff\n$ git --no-pager diff -p -U8\ndiff --git a/src/iop/lens.c b/src/iop/lens.c\nindex 26c15d853..0350ffa25 100644\n--- a/src/iop/lens.c\n+++ b/src/iop/lens.c\n@@ -878,20 +878,20 @@ void modify_roi_in(struct dt_iop_module_t self, struct dt_dev_pixelpipe_iop_t \n     const int height = roi_in->height;\n     const int awidth = abs(width);\n     const int aheight = abs(height);\n     const int xstep = (width < 0) ? -1 : 1;\n     const int ystep = (height < 0) ? -1 : 1;\n const size_t nbpoints = 2 * awidth + 2 * aheight;\n\n\nfloat *buf = dt_alloc_align(16, nbpoints * 2 * 3 * sizeof(float));\nfloat *const buf = dt_alloc_align(16, nbpoints * 2 * 3 * sizeof(float));\n\n#ifdef _OPENMP\n-#pragma omp parallel default(none) shared(modifier, buf) reduction(min : xm, ym) reduction(max : xM, yM)\n+#pragma omp parallel default(none) shared(modifier) reduction(min : xm, ym) reduction(max : xM, yM)\n #endif\n     {\n #ifdef _OPENMP\n #pragma omp for schedule(static)\n #endif\n       for(int i = 0; i < awidth; i++)\n         lf_modifier_apply_subpixel_geometry_distortion(modifier, xoff + i * xstep, yoff, 1, 1, buf + 6 * i);\n ``\nNow you please show me where we changebuf` variable :)\nIf we do change it, then how do we free it afterwards?\nhttps://computing.llnl.gov/tutorials/openMP/#SHARED\n```\nSHARED Clause\nPurpose:\nThe SHARED clause declares variables in its list to be shared among all threads in the team.\nThe `SHARED()` is **only** about the variable itself, not about the buffer it points to.\nThis already works everywhere in darktable.. I thought that `nowait` keyword was the default. It is not. So indeed not needed.. I'm pretty sure this `{}` is not needed.. Right :). first leica noiseprofile, schema needed updating, but i fixed it locally.. Oh, are those tabs?\nWhich editor are you using, that the modelines didn't take any effect?. Please use `g_strlcpy()`, it makes sure that there is no overflow, and the string is zero-terminated in all cases.. I'd also try to avoid `if() if()` by inverting the check and returning early.. Since `  ` (2 spaces) were replaced with `   ` (tab), i'm not sure what is actually changed here.... this is meaningless assignment. I must say the explicit additional `/` looks better, and is harmless. hmm, i do agree that this line is not too useful\nBut, i also do not think it should be just removed\nchange it to:\ndt_print(DT_DEBUG_LIGHTTABLE, \"[exiv2] couldn't find thumbnail for %s\", path);\n(yes, without `\\n`)\nThese embedded thumbs are mostly specific to lighttable, so i guess this is the best place.. The fix does look sane, and is basically the same as i expected.\nI'm sure that you have thoroughly tested this, and it fixes the bug you encountered and does not seem to introduce any new issues.. Add the `<SHIFT>` modifier too.. Something is rather broken with this math.\nWithout modifiers, when moving the point with mouse, it is clearly moving out-of-sync with the mouse.. Oh, there is also `darkroom/ui/scale_step_multiplier`\nJust copy-paste it from `_move_point_internal()` :)\nOr, better idea, call that function from here.. Ok, last thing.\nFor a/b channels, it is in `-128..128` range, not `0..100`. So it looks like you just moved the function up?\nJust add `static gboolean _move_point_internal(dt_iop_module_t *self, GtkWidget *widget, float dx, float dy, guint state);` here, and keep the function where it was.. @schenlap thanks for checking!. Could you please use ninja like all other CI builds?\nmingw-w64-x86_64-ninja, `-G\"Ninja\"`. newline. Right, i remember disscussing that.\nAnd it does not happen with usual make?\nIIRC the agreement was that we need to prepend `bash` before each script we call from cmake\nI.e. `#!/bin/bash` does not work because the script is not being handed to the proper shell in the first place.. do we really not have this in some header already?. why `MIN()`/`MAX()` macros can not be used?\nwhat is the need for these functions. Here and everywhere, why is `w` in `shared()`?\nIt is certainly not modified.\n. Also, please add explicit `default(none)`, like in every other `#pragma omp parallel`. Did you actually profile which schedule is best here?\nIf not, add here and everywhere `schedule(static)`, like in every other `#pragma omp`. Array reduction is a nice trick!\nHowever it was added in `OpenMP 4.5`, which is only supported in `GCC 6.1+`\nCurrently we depend on `GCC 4.8`, i.e. only `OpenMP 3.1` can be unconditionally used.\nhttp://www.openmp.org/resources/openmp-compilers/\nhttps://godbolt.org/g/a6v33Y. just typedef `dt_iop_hazeremoval_data_t` to be `dt_iop_hazeremoval_params_t`, and drop `commit_params()`. As far as darktable sources are concerned, they are defined in glib:\n[ 79%] Building C object src/iop/CMakeFiles/exposure.dir/introspection_exposure.c.o\nIn file included from /home/lebedevri/darktable/build/src/iop/introspection_exposure.c:29:0:\n/home/lebedevri/darktable/src/iop/exposure.c:52:0: error: \"MAX\" redefined [-Werror]\n #define MAX MIN\nIn file included from /usr/lib/x86_64-linux-gnu/glib-2.0/include/glibconfig.h:9:0,\n                 from /usr/include/glib-2.0/glib/gtypes.h:32,\n                 from /usr/include/glib-2.0/glib/galloca.h:32,\n                 from /usr/include/glib-2.0/glib.h:30,\n                 from /home/lebedevri/darktable/src/common/introspection.h:21,\n                 from /home/lebedevri/darktable/src/iop/iop_api.h:28,\n                 from :0:\n/usr/include/glib-2.0/glib/gmacros.h:288:0: note: this is the location of the previous definition\n #define MAX(a, b)  (((a) > (b)) ? (a) : (b))\nIn file included from /home/lebedevri/darktable/build/src/iop/introspection_exposure.c:29:0:\n/home/lebedevri/darktable/src/iop/exposure.c:53:0: error: \"MIN\" redefined [-Werror]\n #define MIN MAX\nIn file included from /usr/lib/x86_64-linux-gnu/glib-2.0/include/glibconfig.h:9:0,\n                 from /usr/include/glib-2.0/glib/gtypes.h:32,\n                 from /usr/include/glib-2.0/glib/galloca.h:32,\n                 from /usr/include/glib-2.0/glib.h:30,\n                 from /home/lebedevri/darktable/src/common/introspection.h:21,\n                 from /home/lebedevri/darktable/src/iop/iop_api.h:28,\n                 from :0:\n/usr/include/glib-2.0/glib/gmacros.h:291:0: note: this is the location of the previous definition\n #define MIN(a, b)  (((a) < (b)) ? (a) : (b))\n```\n/usr/include/glib-2.0/glib/gmacros.h contains\n```\nundef  MAX\ndefine MAX(a, b)  (((a) > (b)) ? (a) : (b))\nundef  MIN\ndefine MIN(a, b)  (((a) < (b)) ? (a) : (b))\n```\nSo unless those don't suit your code, please just use them.. And what about the second part of my question, why is w shared?. default(none). default(none). default(none). default(none). default(none). just s/module/self/ and drop this line. in C, this cast is a NOP, so you can drop all such casts. Also, shared() is about the variable itself, not about something it points to.\nYou do not modify img1/img2, you only modify img?.data\nSo i believe you do not even need to specify shared() at all. stride should be size_t.. c\nreturn ((float *)img.data) + (size_t)i * img.stride;. c\nsize_t size = (size_t)img1.height * img1.width;\nwould be enough. c\nsize_t size = (size_t)img1.height * img1.width;\nwould be enough. It will be really easy to miss some mistake in the rest of the code of this function :/. ah wait, stride is count of channels?\nwhy introduce yet another name, if ch is used everywhere?. these 6 var_imgg_* variables only differ by 1-2 last symbols.\nthis is the best place to hide a problem that may never be found.\nI.e. it's a horrible mess, even though i understand why it is the way it is.. Okay, looks like it indeed.. > will also be declared shared implicitly when the shared declaration is removed.\nif default(none) is removed too. if this is a hint to the reader, then please write it as a comment :)\nThough this would be the only place where such comment exists, thus it will only create confusion.\nSo just drop shared() unless they are really needed.\nIf they are needed, try marking img1 / img2 as const first.. it looks like the dt proper uses following tags:\n\"Exif.Photo.ISOSpeedRatings\", \"Exif.Photo.RecommendedExposureIndex\",\n    \"Exif.Photo.StandardOutputSensitivity\", \"Exif.Nikon3.ISOSpeed\",\n    \"Exif.Nikon3.ISOSettings\", \"Exif.NikonIi.ISO\"\nhttps://github.com/darktable-org/darktable/blob/62416056d956a05f891846dc78fc11033d3c699b/tools/dngmeta.rb#L40-L42\nI wonder if this also should read them all . > which tag should be created\nI guess you meant \"in which order should the tags be evaluated\".\nBut  yeah, for this, probably safe approach is better.. In basecurve module, when placing the mouse over a point on the curve, and using mousewheel to scroll, the scroll direction is inverted compared to the git master.. In tonecurve module, when placing the mouse over a point on the curve, and using mousewheel to scroll, the scroll direction is inverted compared to the git master.\n. Ok. > It feels right, when possible, for touch scrolling to move the point in the direction of the scrolll...\nYep, same is valid for mouse scroolwheel/etc. align the 0, 0 at the end. Please properly rebase this pr, neither noiseprofile nor rawspeed changes should not be here.. are you sure about these deps? e.g. libgnome_keyring is dead. libglade, SDL are not deps.\nand libpthreadstubs looks strange, is it not handled by std library?. Perhaps this should be an enum.. It took me 5 minutes to actually find out why offs indeed should only be applied to a, this should be explained in a comment.. That is a big kernel..\namd drivers are ok with this?. seemingly-useless duplication.\ni would factor these no-op blocks into three inline functions, and would simply call them\n. So now the exact same logic would have to be kept in sync between two places?\nMaybe factor it out into helper function?. That is just \nc\nif((event->state & modifiers) == GDK_CONTROL_MASK). That is so in dt-style :)\nI'll be surprised if we can not deliver proper keypress here, after some modifications.. c\nreturn v1;. This exact block is added in 5 different places even in just this pr,\nAre you seriously telling me that 64 extra lines of duplication is that much better than a call?. even simply naming it offs_a would do it.. Is there any particular reason why this line should be in the each and every process()/process_sse2()?\nHow about simply putting it here: https://github.com/darktable-org/darktable/blob/b0fa66a7b16f1502dfc38e35d96e66fdccc5a75d/src/develop/imageop.c#L189. Yes, i understand all those reasons, but, in opencl kernels case i don't remember seeing dt_iop_alpha_copy() calls in the process_cl(), so it seems* to be always done in the kernel.\nBut dt_iop_alpha_copy() is pretty much always the case for cpu codepath.... That is from ADC, right?. Why is this w+, and not just w i wonder.\nWe only write, do not read.... So i guess this will either enable point-picker and set it to the center of the image,\nor area picker, covering the center half of the image. But here, if the point picker is selected, where will it be placed?\nI didn't try it, but this may be confusing.. char cmdline[PATH_MAX];. What is the max value of pid in linux, 32bit?. snprintf(filename, sizeof(filename), \"/proc/%d/cmdline\", pid);. size = fread(cmdline, sizeof(char), sizeof(cmdline), f);. That will work as long the original dt executable contained that case-sensitive sub-string in the full path to the argv[0].\nI'm wondering if that is a safe assumption? Seems like it?. Also,\n/build/darktable/src/common/database.c:1383:15: error: attempt to use poisoned \"fopen\"\n     FILE* f = fopen(filename, \"r\");\n               ^\nI believe g_fopen is supposed to be used.. Here and everywhere: I don't think we are ready to make that switch just yet.. no uppercase.\ndiff\n-+  dt_bauhaus_combobox_add(g->demosaic_method_xtrans, _(\"Frequency Domain Chroma (slow)\"));\n++  dt_bauhaus_combobox_add(g->demosaic_method_xtrans, _(\"frequency domain chroma (slow)\"));. We really need to migrate to modern cmake with imported targets.\nThis is fscking horrible.. Please use FindPugixml.cmake as an example.\nThis should be more like\n```\n- Try to find FFTW3\nOnce done, this will define\n\nFFTW3_FOUND - system has FFTW3\nFFTW3_INCLUDE_DIRS - the FFTW3 include directories\nFFTW3_LIBRARIES - link these to use FFTW3\ninclude(LibFindMacros)\nlibfind_pkg_detect(FFTW3 fftw3\n  FIND_PATH fftw3.h\n  FIND_LIBRARY fftw3f libfftw3f\n)\nSet the include dir variables and the libraries and let libfind_process do the rest.\nNOTE: Singular variables for this library, plural for libraries this this lib depends on.\nset(FFTW3_PROCESS_INCLUDES FFTW3_INCLUDE_DIR)\nset(FFTW3_PROCESS_LIBS FFTW3_LIBRARY)\nlibfind_process(FFTW3)\n. Why `4`, this is not a bitmask?. Yes, here, uppercase is ok.. I really do hope you formatted this with `clang-format` with our `.clang-format`.. We already have `CLIP()`. Why is `(qual_flags & DEMOSAIC_XTRANS_FULL_MARKESTEIJN)` needed here?. I guess this is clipping, if somehow we have a too big method id.\nStill, i think it is better to fallback to old good `DT_IOP_DEMOSAIC_MARKESTEIJN`.. So in `tools/noise/subr.sh`, if `pdftk` is installed, then `pdfcat` bash function will call it, else it will call `gs`?. right, k. separate by newline. Heh, yeah. Never run clang-format over the whole file...\nUse clang-format post-commit hook to format the diff.\nhttps://github.com/darktable-org/darktable/blob/master/CONTRIBUTING.md#coding-style. I posted that to the previous pr.... Please provide the sample with the problem.. (it's impossible to say anything without seeing exactly that same sample where you have observed the issue.). I'm gonna bet the crop is wrong. Will check later.. Yep, pretty clearly, i'm right, will adjust.. Pushed, hopefully that fixed the issue you were observing. Please remove that clipping..c++\nstatic int compare_L_source(const void x_, const void y_) {\n  const double x = x_;\n  const double y = y_;\n  return x < y ? -1 : (x > y ? +1 : 0);\n}\n.\ndouble grays = malloc(sizeof(double) * 6 * num_tonecurve);\n. Ah well :)\nSo eitherc++\nstatic int compare_L_source(const void x_, const void y_) {\n  const double x = (const double)x_;\n  const double y = (const double*)y_;\n  return x < y ? -1 : (x > y ? +1 : 0);\n}\n```\nor\nc++\nstatic int compare_L_source(const double *x_, const double *y_) {\n  const double x = *x_;\n  const double y = *y_;\n  return x < y ? -1 : (x > y ? +1 : 0);\n}\n...\n  qsort(grays, num_tonecurve, sizeof(double) * 6, (int (*)(const void *, const void *))compare_L_source);\n. diff\n-+  double *grays = malloc(sizeof(double) * 6 *num_tonecurve);\n++  double *grays = malloc(sizeof(double) * 6 * num_tonecurve);\nIn other words, what is *num_tonecurve?\nIs num_tonecurve a pointer?\nAnd then you have 6 and \"dereferenced\" pointer which wouldn't even compile.\nTLDR: .git/hooks/pre-commit. copyright looks messed up. [-0.5, 0.5] probably?. - __m128 tmp = (((rgb - one) * lift) + one) * gain;\n+ __m128 tmp = _mm_mul_ps(_mm_add_ps(_mm_mul_ps(_mm_sub_ps(rgb, one), lift), one), gain);. I'm not 100% sure whether such initialization of __m128 not using _mm_set_ps() is standard. So what happens if during refresh the previously-selected album is now on the different position in the combobox?\nI think that can happen?. Uhm, this does look like a clip, does it not?. github is showing the wrong diff, see screenshot.\n\n. Seriously guys, you wanted us to break feature freeze and merge this code, despite that it apparently crashes during normal usage, without even mentioning that it  crashes during normal usage? As far as Ctrl+F can tell, this is the first mention.\nEdit: i really hope you meant \"crashing without that current lock\"?. So \ndiff\n+// Preparations for fftw\n+#ifdef HAVE_FFTW3\n+  dt_pthread_mutex_lock(fftw_lock);\n+  fftwf_complex *in_src = NULL, *out_src = NULL, *out_kernel = NULL, *in_kernel = NULL, *Cm = NULL;\n+  // Initialization of the plans\n+  fftwf_plan p_forw_src\n+      = fftwf_plan_dft_2d(TS, TS, in_src, out_src, FFTW_FORWARD, FFTW_ESTIMATE); // real to complex\n+  fftwf_plan p_forw_kernel = fftwf_plan_dft_2d(TS, TS, in_kernel, out_kernel, FFTW_FORWARD, FFTW_ESTIMATE);\n+  fftwf_plan p_back = fftwf_plan_dft_2d(TS, TS, out_kernel, Cm, FFTW_BACKWARD, FFTW_ESTIMATE);\n+  dt_pthread_mutex_unlock(fftw_lock);\n+#endif\n1. Does it actually depend on anything other than TS define?\n2. Can you please replace that define with static const int.\n3. Can the exact same plan be created once, and then used everywhere for everything, without creating it each time  in xtrans_fdc_interpolate()?. @kubrickfr that is orthogonal to my question. 1. static, for all of these tables.\n2. As discussed with @houz in IRC, surely, you did not come up with these tables by hand? There is an algorithm, right?. The simplest/dumbest code is usually the best one.\nAs far as i can tell there is no difference whatsoever between {} vs memset().\nhttps://godbolt.org/g/qMc46p\nBut the memset() is worse because that is much more lines, symbols; and you need to specify sizes, offsets.\nTLDR: just do what @houz suggested lr_data_t data = {0};. Okay, yeah, except the warnings.\nI think one memset() over the entire struct should be fine still.. https://travis-ci.org/darktable-org/darktable/builds/312355224?utm_source=github_status&utm_medium=notification. Pretty sure you should not be changing this.. Why is this file even here?\nIt's completely out-of-date.. git conflict resolution is no fun even for knowledged developers.\nand usually translators are less knowledged than the developers.\nso for them it might mean \"drop all your local changes and re-translate from the scratch\". This is beginning to look quite crowded :)\nI'm wondering if there is some other better/proper approach to locate that header, an approach that i missed.. As discussed in #gtk+, this is known broken.. So what happens if this is not called?. Typo. const. Uh, why did this work in the first place?\nAre there more occurrences? . Just delete it. If prepare_matrices() isn't called.\n\nMonochrom raws don't have colour matrices anyway, so all prepare_matrices does for monochrom raws is write an error messas.\n\nAh, now that i checked, the temperature/tint slider is already non-functional.\n  . newline before/after. I'm wondering if the \"enable\" button should be disabled for these monochrome raws, especially since it can't work at all for them.\n. Right sidepanel, from bottom to top :). BTW, by hidden i mean https://github.com/kelvie/darktable/blob/a05f425020e03ab1d9e6942d86775ec3df23f2b8/src/iop/demosaic.c#L4659. Welcome to the wonderful world of SQL injections.. Not checking that it all did fit into the buffer.. https://codereview.stackexchange.com/questions/6435/c-system-function-vulnerability\nhttps://wiki.sei.cmu.edu/confluence/pages/viewpage.action?pageId=87152177\nNeed more links?\nIt appears we already have a few system(3) calls, and this is disgusting :(. Note how you are printing tmpfile (which is PATH_MAX, i.e. 4096) into tpcmd, which is just 1024.\nIt might be better to use g_strdup_printf() or something from the start.. e.g. pinfo->printer.name roughly of ; rm -rf ~/, when printed to, will delete your homedir.\nYou think this is ok?. \n\nMany applications are using system() or exec*() to spawn external process. \n\n.. many applications leak memory, many applications contain UB, etc.\nThis isn't false, it just doesn't mean that because of that, it is good to follow the trend.\n\nand have no alternatives, do we?\n\nOr do we not?\n```\nSYSTEM(3)                                                                                                               Linux Programmer's Manual                                                                                                              SYSTEM(3)\nNAME\n       system - execute a shell command\nSYNOPSIS\n       #include \n   int system(const char *command);\n\nDESCRIPTION\n       The system() library function uses fork(2) to create a child process that executes the shell command specified in command using execl(3) as follows:\n       execl(\"/bin/sh\", \"sh\", \"-c\", command, (char *) 0);\n\n```\nBasically we just need to remove the \"/bin/sh\", \"sh\", \"-c\", from the equation, that's it.\nI.e. we know what command we want to call, so let's call it, and not use shell to call it.\n. These still can easily overflow their destinations.. This is just\npinfo->is_turboprint = strstr(attr->value, \"TurboPrint\") != NULL;. This will be a new translation string, which is not guaranteed to be translated exactly as the string you are trying to match. In other words: how is this not broken?. o_O This is kinda smells funny.. Resetting this module apparently enables it, and it can't be disabled back. Resetting this module apparently enables it, and it can't be disabled back\n. When starting dt i'm now seeing (darktable:27766): Gtk-WARNING **: Child name 'disabled' not found in GtkStack warning.. To be honest, i'm not sure what the fix should be.\nAt least, i think, you should edit commit_params(), and add\nif(dt_image_is_monochrome(img)) {piece->enabled = false; return;}\n(for all three modules (invert, temperature, cacorrect)). > However, after resetting, (this was the case before), this adds a history item, and it doesn't say (off); is that a bug?\nThis is consistent with all the previous behavior.\nIn the current context it highlights just how ad-hoc hack all these \"this module is not supported for this image\" implementations are.\nI guess you should modify _reset_label_callback() to not enable module if it is not enabled by default AND the toggle button is hidden. At least that would make sense to me. But i have no clue whatsoever what will get broken by that.. We certainly could, though that would not help at all given the PR description.\nThe problem is not that LLVM_INSTALL_PREFIX is not set, the problem is that clang install prefix does not match the llvm install prefix.. So it will produce less pixels, and leave upscaling up to cairo, if i'm reading this right?. .. and since we pass 8-bit integers to cairo, the scaling will be kinda horrible.\nI fail to see how is this better.. Even so, cairo scaling will be worse quality-wise.. It will be clamped to 8 anyway, so the previous code is at least as good. Even for non-native english speaker these description look like gibberish. All this reads very strange, something like\ndt_conf_set_int(\"host_memory_limit\", MAX(mem >> 11, dt_conf_get_int(\"host_memory_limit\"));\nwould be immensely better. See https://github.com/darktable-org/darktable/blob/b630b911e917b8d4b546537ba6a8fbc1a7c7ceba/src/iop/exposure.c#L270-L283\nand\nhttps://github.com/darktable-org/darktable/blob/b630b911e917b8d4b546537ba6a8fbc1a7c7ceba/src/iop/exposure.c#L314-L315\nEither all this stuff is fully auto-detectable, or all this is mislabelled.. Most of the defaults for these sliders in\"camera & signal properties\".\nYou should be able to get most of that from the actual black/white levels.\nElse i suspect the name is unrepresentable.. > You were actually right, looking again at the maths, these parameters are dependent of the dynamic range so I just removed them throm the UI.\n... are you still confident that dynamic range won't be auto-calculatable the way i suggested in the first comment in this thread?. In general, if you have to repeat the exact same snippet in more than two places, you are doing it wrong.. You can't change that. It is an upstream opencl header,. Similarly, this is appears to be a copy-paste from some upstream header.\nThe change probably needs to be done upstream first.. diff\n- #error \"Unfortunately we only work on amd64/x86 (64-bit and maybe 32-bit) and ARMv8-A (64-bit only).\"\n+ #error \"Unfortunately we only work on amd64/x86 (64-bit and maybe 32-bit) and ARMv8-A, PPC64 (64-bit little-endian only).\". This code (and it's position (after the upper/lower)) appears to be correct.. This code (that i wrote) is incorrect though.\nIt should be\nc++\n    else if(Exiv2::testVersion(0,25,0) && FIND_EXIF_TAG(\"Exif.CanonFi.FocusDistanceUpper\"))\n    {\n      float FocusDistanceUpper = pos->toFloat();\n      if(FocusDistanceUpper <= 0.0f || FocusDistanceUpper >= 0xffff)\n      {\n        img->exif_focus_distance = 0.0f;\n      }\n      else\n      {\n        img->exif_focus_distance = FocusDistanceUpper / 100.0;\n        if(FIND_EXIF_TAG(\"Exif.CanonFi.FocusDistanceLower\"))\n        {\n          float FocusDistanceLower = pos->toFloat();\n          if(FocusDistanceLower > 0.0f && FocusDistanceLower < 0xffff))\n          {\n            img->exif_focus_distance += FocusDistanceLower / 100.0;\n          }\n        }\n      }\n    }\n. Actually, wait, this is almost correct.\nWe still need to average, so \nc++\nimg->exif_focus_distance += FocusDistanceLower / 100.0;\nimg->exif_focus_distance /= 2.0;. No.. Likewise, no.. What @parafin said, this is not really correct; as it is evident from the presets, the module is not limited to contrast.. 1. \"user request\" is simply not a reason-enough. auto-applied presets work for this module, for those who need it. i'm not observing any other arguments in favor of this change being presented here.\n2. the module will now be always-enabled-by-default in the pipeline, that is, unless it is disabled in the history stack. and with that, pretty much all the existing history stacks get broken (if they did not explicitly disable/enable the module already), for obvious reasons...\n. > I thought auto-presets were applied only when the initial history stack was created, not when there is already a previous history.\nQuiz: do you believe this change is about a preset, or not?. ",
    "MRIG": "+1\n2013/5/5 Pascal Obry notifications@github.com\n\nIf there is no objection I'll merge this early next week.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/223#issuecomment-17449141\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. I would be nice to have en_GB as language favourite! So I do hope there\nwill a new PR\n2013/10/26 Lebedev Roman notifications@github.com\n\nClosed #276 https://github.com/darktable-org/darktable/pull/276.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/276\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Edouard,\nMay I ask you. Do I have to checkout to a branch to test your script?\n$ git checkout ???\nThe script, better, the output makes me curious.I would like to test it.\nJust a small note, I have read the README file on the web, JPG and RAW\nshould be of same size? This is not mentioned as far as I read.\nregards Ger\n2014-03-01 0:05 GMT+01:00 Edouard Gomez notifications@github.com:\n\nOn 02/26/2014 09:21 AM, Boucman wrote:\n\na README in the tool directory can be updated if we update the tools,\nwhich is a nice thing.\n\nDone.\nPlease review and give me your feedback.\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36403927\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Edouard,\nI tried but couldn't make the tool.\nAn error with the make file??? Any idea what's is wrong?\n$ ~/darktable/tools/basecurve# make BUILD_TYPE=Release\nMakefile:6: *** ontbrekend scheidingsteken.  Gestopt.\ndcraw worked\n$~/darktable/tools/basecurve# dcraw -6 -W -g 1 1 -w IMG_6007.CR2\nand\n$ ~/darktable/tools/basecurve# ls\nbasecurve.c           IMG_6007.CR2       Makefile        README\ndt-curve-tool.c       IMG_6007-jpeg.ppm  plot\ndt-curve-tool-helper  IMG_6007.JPG       plot.basecurve\nexif-wrapper.cpp      IMG_6007-raw.ppm   plot.tonecurve\nregards Ger\n2014-03-02 13:50 GMT+01:00 Edouard Gomez notifications@github.com:\n\nOn 03/01/2014 05:24 PM, Ger wrote:\n\nEdouard,\nMay I ask you. Do I have to checkout to a branch to test your script?\n$ git checkout ???\n\nI'm not a git expert when it comes to deal w/ multiple repositories, but\nsomething along the lines:\n$ git remote add edgomez https://github.com/edgomez/darktable.git\n$ git fetch edgomez\n$ git checkout -b tool_basecurve_improvements\nedgomez/tool_basecurve_improvements\nshould give you an opportunity to test my work.\n\nThe script, better, the output makes me curious.I would like to test it.\nJust a small note, I have read the README file on the web, JPG and RAW\nshould be of same size? This is not mentioned as far as I read.\n\nNot exactly the same size, but at least the same orientation. It takes\ncare of this, like it used to do, i get no credit here. Ah, don't forget\nabout the JPEG being sRGB.\nRegards\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36453345\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Edouard,\nCould this be the issue why Make file gives an error?\nIf you use spaces instead of a single TAB character for indentation inside\nyour Makefile, you'll get the following error:\nMakefile:6: *** missing separator.  Stop.\nregards Ger\n2014-03-02 15:54 GMT+01:00 Ger Siemerink g.siemerink@gmail.com:\n\nEdouard,\nI tried but couldn't make the tool.\nAn error with the make file??? Any idea what's is wrong?\n$ ~/darktable/tools/basecurve# make BUILD_TYPE=Release\nMakefile:6: *** ontbrekend scheidingsteken.  Gestopt.\ndcraw worked\n$~/darktable/tools/basecurve# dcraw -6 -W -g 1 1 -w IMG_6007.CR2\nand\n$ ~/darktable/tools/basecurve# ls\nbasecurve.c           IMG_6007.CR2       Makefile        README\ndt-curve-tool.c       IMG_6007-jpeg.ppm  plot\ndt-curve-tool-helper  IMG_6007.JPG       plot.basecurve\nexif-wrapper.cpp      IMG_6007-raw.ppm   plot.tonecurve\nregards Ger\n2014-03-02 13:50 GMT+01:00 Edouard Gomez notifications@github.com:\nOn 03/01/2014 05:24 PM, Ger wrote:\n\n\nEdouard,\nMay I ask you. Do I have to checkout to a branch to test your script?\n$ git checkout ???\n\nI'm not a git expert when it comes to deal w/ multiple repositories, but\nsomething along the lines:\n$ git remote add edgomez https://github.com/edgomez/darktable.git\n$ git fetch edgomez\n$ git checkout -b tool_basecurve_improvements\nedgomez/tool_basecurve_improvements\nshould give you an opportunity to test my work.\n\nThe script, better, the output makes me curious.I would like to test it.\nJust a small note, I have read the README file on the web, JPG and RAW\nshould be of same size? This is not mentioned as far as I read.\n\nNot exactly the same size, but at least the same orientation. It takes\ncare of this, like it used to do, i get no credit here. Ah, don't forget\nabout the JPEG being sRGB.\nRegards\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36453345\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. make is installed in synaptic\n???\nRegards Ger\n2014-03-03 22:51 GMT+01:00 Edouard Gomez notifications@github.com:\n\nOn 03/02/2014 03:54 PM, Ger wrote:\n\nEdouard,\nI tried but couldn't make the tool.\nAn error with the make file??? Any idea what's is wrong?\n$ ~/darktable/tools/basecurve# make BUILD_TYPE=Release\nMakefile:6: *** ontbrekend scheidingsteken. Gestopt.\nWhat make program are you using ?\n\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36564505\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. or  cmake see http://www.darktable.org/install/\n2014-03-03 23:15 GMT+01:00 Ger Siemerink g.siemerink@gmail.com:\n\nmake is installed in synaptic\n???\nRegards Ger\n2014-03-03 22:51 GMT+01:00 Edouard Gomez notifications@github.com:\nOn 03/02/2014 03:54 PM, Ger wrote:\n\n\nEdouard,\nI tried but couldn't make the tool.\nAn error with the make file??? Any idea what's is wrong?\n$ ~/darktable/tools/basecurve# make BUILD_TYPE=Release\nMakefile:6: *** ontbrekend scheidingsteken. Gestopt.\nWhat make program are you using ?\n\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36564505\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. the same\nGNU Make 3.81\nCopyright (C) 2006  Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nThis program built for x86_64-pc-linux-gnu\n2014-03-04 0:42 GMT+01:00 Edouard Gomez notifications@github.com:\n\nIt seems your make program behaves quite differently than mine, first it\ncomplains on line 6 which has neither leading spaces or tabs, and\nsecondly the Makefile works on my debian machine w/o any kind of\ntrickery :-D\nSo i'm trying to clear out what's different on yours.\nMine:\n$ make --version\nGNU Make 3.81\nCopyright (C) 2006 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.\nThere is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A\nPARTICULAR PURPOSE.\nThis program built for x86_64-pc-linux-gnu\nYours ?\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36575471\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Edouard, or Jeremy\nI stuck on this step: sh mycameracurves.sh\nthis returns an error\nmycameracurves.sh: 4: mycameracurves.sh: Syntax error: \")\" unexpected\nany idea what is wrong???\nand see second question and the end of the text.\nregards Ger\n** some terminal info\n$ ~/darktable/tools/basecurve#  LANG=C\n$ ~/darktable/tools/basecurve# sh mycameracurves.sh\nmycameracurves.sh: 4: mycameracurves.sh: Syntax error: \")\" unexpected\n$~/darktable/tools/basecurve# gnuplot -e ${dt\nsrc}/tools/basecurve/gnuplot.basecurve\nbash: ${dt src}/tools/basecurve/gnuplot.basecurve: bad substitution\n$ ~/darktable/tools/basecurve# gnuplot -e ${dt\nsrc}/tools/basecurve/gnuplot.tonecurve\nbash: ${dt src}/tools/basecurve/gnuplot.tonecurve: bad substitution\n$ ~/darktable/tools/basecurve# ls\n1-jpeg.ppm  Makefile           dt-curve-tool         dt-curve-tool.o\nplot.basecurve\n1-raw.ppm   README             dt-curve-tool-helper  exif-wrapper.cpp\nplot.tonecurve\n1.CR2       basecurve.dat      dt-curve-tool.bin     exif-wrapper.o\ntonecurve.dat\n1.JPG       basecurve.fit.dat  dt-curve-tool.c       mycameracurves.sh\ntonecurve.fit.dat\nroot@laptop:~/darktable/tools/basecurve#\nand can you explain how to get this into darktable? shell ????\n!/bin/sh\nto test your new basecurve, copy/paste the following line into your shell.\nnote that it is a smart idea to backup your database before messing with\nit on this level.\n(you have been warned :) )\necho \"INSERT INTO presets VALUES('Canon EOS\n60D','','basecurve',2,X'0000000000000000e3f3443a00000000e3f3c43b00000000c72da63c00000000e3f3443d000000002c56c03d00000000c72d263e0000000061f1833e00000000e3f3c43e00000000a0360c3f000000002c56403f000000000000803f000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000c0000000000000000000000020000000000000000000000',1,X'00000000180000000000C842000000000000000000000000000000000000000000000000000000000000000000000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F',7,0,'','%','%','%',0.0,51200.0,0.0,10000000.0,0.0,100000000.0,0.0,1000.0,0,0,0,0,2);\"\n| sqlite3 ~/.config/darktable/library.db\n0\n!/bin/sh\nto test your new tonecurve, copy/paste the following line into your shell.\nnote that it is a smart idea to backup your database before messing with\nit on this level.\necho \"INSERT INTO presets VALUES('Canon EOS\n60D','','tonecurve',4,X'0000000000000000e3f3443a00000000e3f3c43b00000000c72da63c00000000e3f3443d000000002c56c03d00000000c72d263e0000000061f1833e00000000e3f3c43e00000000a0360c3f000000002c56403f000000000000803f00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000abaaaa3dabaaaa3dabaa2a3eabaa2a3e0000803e0000803eabaaaa3eabaaaa3e5555d53e5555d53e0000003f0000003f5555153f5555153fabaa2a3fabaa2a3f0000403f0000403f5555553f5555553fabaa6a3fabaa6a3f000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000abaaaa3dabaaaa3dabaa2a3eabaa2a3e0000803e0000803eabaaaa3eabaaaa3e5555d53e5555d53e0000003f0000003f5555153f5555153fabaa2a3fabaa2a3f0000403f0000403f5555553f5555553fabaa6a3fabaa6a3f000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000c0000000c0000000c000000020000000200000002000000010000000000000000000000',1,X'00000000180000000000C842000000000000000000000000000000000000000000000000000000000000000000000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F',7,0,'','%','%','%',0.0,51200.0,0.0,10000000.0,0.0,100000000.0,0.0,1000.0,0,0,0,0,2);\"\n| sqlite3 ~/.config/darktable/library.db\nif it pleases you, then in iop/tonecurve.c append the following line to\nthe array presets_from_basecurve and modify its name\n{\"Canon EOS 60D\", {{{{0.000000, 0.000000}, {0.000751, 0.000000},\n{0.006011, 0.000000}, {0.020286, 0.000000}, {0.048084, 0.000000},\n{0.093914, 0.000000}, {0.162284, 0.000000}, {0.257701, 0.000000},\n{0.384673, 0.000000}, {0.547709, 0.000000}, {0.751315, 0.000000},\n{1.000000, 0.000000}, },{{0.000000, 0.000000}, {0.083333, 0.083333},\n{0.166667, 0.166667}, {0.250000, 0.250000}, {0.333333, 0.333333},\n{0.416667, 0.416667}, {0.500000, 0.500000}, {0.583333, 0.583333},\n{0.666667, 0.666667}, {0.750000, 0.750000}, {0.833333, 0.833333},\n{0.916667, 0.916667}, },{{0.000000, 0.000000}, {0.083333, 0.083333},\n{0.166667, 0.166667}, {0.250000, 0.250000}, {0.333333, 0.333333},\n{0.416667, 0.416667}, {0.500000, 0.500000}, {0.583333, 0.583333},\n{0.666667, 0.666667}, {0.750000, 0.750000}, {0.833333, 0.833333},\n{0.916667, 0.916667}, },}, {12, 12, 12}, {2, 2, 2}, 0, 0, 0}},\n2014-03-02 13:50 GMT+01:00 Edouard Gomez notifications@github.com:\n\nOn 03/01/2014 05:24 PM, Ger wrote:\n\nEdouard,\nMay I ask you. Do I have to checkout to a branch to test your script?\n$ git checkout ???\n\nI'm not a git expert when it comes to deal w/ multiple repositories, but\nsomething along the lines:\n$ git remote add edgomez https://github.com/edgomez/darktable.git\n$ git fetch edgomez\n$ git checkout -b tool_basecurve_improvements\nedgomez/tool_basecurve_improvements\nshould give you an opportunity to test my work.\n\nThe script, better, the output makes me curious.I would like to test it.\nJust a small note, I have read the README file on the web, JPG and RAW\nshould be of same size? This is not mentioned as far as I read.\n\nNot exactly the same size, but at least the same orientation. It takes\ncare of this, like it used to do, i get no credit here. Ah, don't forget\nabout the JPEG being sRGB.\nRegards\n\nEdouard Gomez\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-36453345\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. /bin/sh\nregards Ger\n. if tried and retried but get weird curves up to know, see attached\nscreenshot\n2014-03-10 13:56 GMT+01:00 Boucman notifications@github.com:\n\nmy guess is that mycameracurves.sh contains some bashism...\nit's hard to say becauseI don't have the file around @edgomezhttps://github.com/edgomez: did you look into it ?\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37178848\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. and this one for tonecurve\n2014-03-10 13:59 GMT+01:00 Ger Siemerink g.siemerink@gmail.com:\n\nif tried and retried but get weird curves up to know, see attached\nscreenshot\n2014-03-10 13:56 GMT+01:00 Boucman notifications@github.com:\nmy guess is that mycameracurves.sh contains some bashism...\n\nit's hard to say becauseI don't have the file around @edgomezhttps://github.com/edgomez: did you look into it ?\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37178848\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. retry, will this be visible?\n2014-03-10 14:02 GMT+01:00 Robert William Hutton notifications@github.com:\n\n@MRIG https://github.com/MRIG Not sure the attachments are working.\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37179400\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. ASAP I'm in hospital now for a few days :-((  don't know how to call in\nenglish \"blindedarm ontsteking\", nothing serious shit happens regards ger\nOp 11 mrt. 2014 17:45 schreef \"Boucman\" notifications@github.com het\nvolgende:\n\n@MRIG https://github.com/MRIG can you retest ? that would be awesome...\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37318643\n.\n. Indeed very interesting statement which I will test ASAP anyway thanks for\ndoing such research\n\nOp woensdag 12 maart 2014 heeft Edouard Gomez notifications@github.com\nhet volgende geschreven:\n\nAttention here, I'm absolutely not pushing for basecurve replacement.\nThis is very sensitive change as it used by default, all the time. Except\n\"power\" users that decided to start w/ an empty default style.\nI'm just trying to help in tooling and informing the project for a later\ndecision by darkatble devs community.\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37423087\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Edouard,\nWell, I have retried your approach Edouard and I'm not completely satisfied.\nI enjoyed playing with the script.\nCheck out the picture,\nhttp://www.flickr.com/photos/gersiemerink/13213590374/lightbox/\nfor a comparison\nAs you can see tone curves looks nearly good after two tests.\nThe base curve is similar to that determined at the time by a method of\nTorsten\nand the Darktable's one.\nFor now I stop testing it.\nRegards Ger\n2014-03-12 22:15 GMT+01:00 Edouard Gomez notifications@github.com:\n\n@bronger https://github.com/bronger\nwell the tonecurve/basecurve discussion is more about when to apply a\ncurve that breaks linearity of input data, early in the pipe (basecurve) or\nlate in the pipe (tonecurve).\nI've been informed that devs meeting at LGM will discuss these matters\nlooking at accuracy of colors, accuracy of maths, possibility to\napproximate the in camera engine look etc...\nThis PR is totally disconnected from that discussion.\nThis PR is about improving an existing tool that is currently shipped in\nthe source package and that is way too limited to give good results even\nfor basecurve.\nNow of course, I hope that the tool will be useful whatever decision and\nprobably new IOP comes out of DT devs meeting. But I can't predict the\nfuture ;-D\nI also try to give some feedback about tonecurve being more accurate for\nthe D7000. Plain fact, no hidden agenda beyond that.\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/467#issuecomment-37466222\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n.  your update is from yesterday???\nI can do it but i used to do only merge 'nl.po'\nregards Ger\n2014-04-06 13:46 GMT+02:00 bartokk notifications@github.com:\n\nIs there anybody out there? :-)\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/513#issuecomment-39666281\n.\n\nhttp://www.gersiemerink.net\n. +1\n2014-06-08 10:05 GMT+02:00 Pascal Obry notifications@github.com:\n\nWith this patch it is possible to rotate a watermark. This is convenient\nand avoid having to prepare different watermarks just because we want them\naligned in different borders.\nYou can merge this Pull Request by running\ngit pull https://github.com/darktable-org/darktable rotate-watermarks\nOr view, comment on, or merge it at:\nhttps://github.com/darktable-org/darktable/pull/586\nCommit Summary\n- Add support for rotating the wattermark.\n- Minor reformatting.\nFile Changes\n- M src/iop/watermark.c\n  https://github.com/darktable-org/darktable/pull/586/files#diff-0\n  (74)\nPatch Links:\n- https://github.com/darktable-org/darktable/pull/586.patch\n- https://github.com/darktable-org/darktable/pull/586.diff\n\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/586.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. typo scalepixels/c must be scalepixels.c\n. request has been updated!\n. okay, but I might merge pull request now?\n. strange, several phrases, who start with a dash are not added as new or untranslated phrases, but are translated as English phrases\n. Pascal, for me strange, some phrases were already translated, for instance;\npo file phrase  was _Save and already translated into _Save,hope this isn't\ncase for other languages regards Ger\nOp woensdag 13 mei 2015 heeft Pascal Obry notifications@github.com het\nvolgende geschreven:\n\nMaybe a missing entry in the file to translate. What is the untranslatable\ntext?\n\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/912#issuecomment-101814729\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Robert, question, how does this work?\nIf I import EOS60D pictures, are the white balance options in the\nmodule/menu automatic EOS60D white balance options or do I have to select\nor enable something???\nregards Ger\n2015-06-22 13:29 GMT+02:00 Robert William Hutton notifications@github.com:\n\nRemove old version of 60D white balance presets (firmware version unknown)\nand replace with a full set including fine tuning, with latest firmware\nversion of 1.1.1.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/darktable-org/darktable/pull/933\nCommit Summary\n- Add full set of 60D white balance presets with fine tuning.\nFile Changes\n- M src/external/wb_presets.c\n  https://github.com/darktable-org/darktable/pull/933/files#diff-0\n  (121)\nPatch Links:\n- https://github.com/darktable-org/darktable/pull/933.patch\n- https://github.com/darktable-org/darktable/pull/933.diff\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/933.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Krijn and I have discussed the pull request, we have agreed to another method, this pull is rejected\n. first impression: meaningful tool\ncomment: when using line tool, the arrows on the line do look somewhat strange,like dots or smudge\nthe image must be increased to see that these are arrows that indicate the direction\nanother comment: the balloon explanation appears at the top of the image which is okay but\nthere you need to get used to it \nalso de blending tool gives a strange effect when using parametric mask\n. please explain what you mean?\n2016-01-12 19:45 GMT+01:00 Roman Lebedev notifications@github.com:\n\n@MRIG https://github.com/MRIG could you please learn how to push stuff\ninto git master without a PR, please?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1117#issuecomment-171008978\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. Peterbud, I do appreciate your commitment. I tried the release from Jan\nIngbar. Hope you two will bring a windows release soon!\nAs translator for dutch qui, heavy ubuntu user I do like to have a windows\nrelease on my dual boot machine!\nregards Ger\n2016-10-24 18:34 GMT+02:00 peterbud notifications@github.com:\n\nFirst of all I know the question of a Windows build has been\ncontroversial, and generated a lot of emotion in the past. All I'm asking\nis to look into this PR in an objective way, setting emotions aside.\nIn the last 2 months I have been working on creating a decent Windows port\nof darktable. I believe this software is brilliant, and would deserve to\nreach a broader (but less fortunate) audience who are still only familiar\nwith Windows.\nFor the port I have used the MSYS2 http://msys2.github.io/ Mingw64\nenvironment, which enabled to use the existing build system without any\nmajor change. The resulting code is native 64-bit, no dependency on\npropriatery libraries, only what comes with Windows.\nTo see the whole effort, please note that first I had to port to Windows\nthe following libraries (as no ports were available on MSYS2 or on Windows\nat all):\n- PugiXML\n  https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-pugixml\n- osm-gps-map\n  https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-osm-gps-map\n- libgd\n  https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-libgd\n- libgphoto2\n  https://github.com/Alexpux/MINGW-packages/tree/master/mingw-w64-libgphoto2\n- LUA was available, but a newer version, so I had to build the 5.2\n  version myself\nThe other libraries have been already ported and were available.\nAlso I have realized that there is no decent GTK3 binary distribution so I\nhave also contributed to a project\nhttps://github.com/tschoonj/GTK-for-Windows-Runtime-Environment-Installer\nwhich now can deliver a solid binary distribution for GTK3\nAlong the way I have added all the necessary Windows specific code, where\nI have tried to make as few surgical changes as possible, and not\ninterfering with the existing code. During the port I had to add a few\nfunctions which were missing from MSCRT. I have tested the current PR is\nstill building properly on Ubuntu.\nI have documented the necessary steps to prepare the Windows build in the\n/packaging/windows/BUILD.txt file in detail.\nThe current version is a fully functional darktable which runs nicely on\nWindows, supports all basic lighttable and darkroom functionality + OpenCL,\nlensfun, tethering, slideshow and map.\nWhat is missing is the printing and color management functionality, that\nis more complex and requires more time.\nFinally I'm planning to create a decent installer package using cmake and\nNSIS later, as users are expecting a binary distribution format.\nAny constructive feedback is welcome.\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/darktable-org/darktable/pull/1327\nCommit Summary\n- Initial changes to make a Windows build with MSYS2\n- merged conflicts\n- Adding openmap & lua & libgphoto fixing opencl\n- Merge branch 'master' of https://github.com/darktable-org/darktable\n  into windows-build\n- Added getrlimits support, adjusting fro gphoto2\n- Added getline support\n- Tidy up the code\n- Merge branch 'master' of https://github.com/darktable-org/darktable\n  into windows-build\n- Added Windows support to dt_print_mem_usage\n- Fixed statvfs\n- Cleaning up CMakeList.txt\n- Cleaning up BUILD.txt for Windows/MSYS2\nFile Changes\n- M .gitignore\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-0\n  (1)\n- M CMakeLists.txt\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-1\n  (17)\n- M build.sh\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-2\n  (2)\n- M cmake/modules/FindPThread.cmake\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-3\n  (49)\n- M cmake/modules/FindPugixml.cmake\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-4\n  (5)\n- M cmake/modules/FindSaxon.cmake\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-5\n  (4)\n- M data/CMakeLists.txt\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-6\n  (6)\n- A packaging/windows/BUILD.txt\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-7\n  (106)\n- M src/CMakeLists.txt\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-8\n  (33)\n- M src/common/camera_control.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-9\n  (6)\n- M src/common/collection.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-10\n  (6)\n- M src/common/darktable.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-11\n  (18)\n- M src/common/darktable.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-12\n  (37)\n- M src/common/dlopencl.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-13\n  (4)\n- M src/common/dtpthread.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-14\n  (4)\n- M src/common/file_location.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-15\n  (30)\n- M src/common/mipmap_cache.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-16\n  (6)\n- M src/common/opencl.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-17\n  (76)\n- M src/common/resource_limits.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-18\n  (4)\n- M src/common/tags.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-19\n  (4)\n- M src/common/utility.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-20\n  (7)\n- M src/dtview/main.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-21\n  (15)\n- M src/external/CL/cl_platform.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-22\n  (4)\n- M src/external/rawspeed/RawSpeed/Common.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-23\n  (2)\n- M src/external/rawspeed/rawspeed-identify.cpp\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-24\n  (4)\n- M src/gui/camera_import_dialog.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-25\n  (4)\n- M src/iop/ashift_lsd.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-26\n  (8)\n- M src/iop/spots.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-27\n  (4)\n- M src/lua/call.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-28\n  (6)\n- A src/win/getdelim.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-29\n  (143)\n- A src/win/getdelim.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-30\n  (7)\n- M src/win/getrusage.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-31\n  (256)\n- M src/win/getrusage.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-32\n  (38)\n- A src/win/rlimit.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-33\n  (211)\n- A src/win/rlimit.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-34\n  (39)\n- A src/win/statvfs.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-35\n  (64)\n- A src/win/statvfs.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-36\n  (50)\n- A src/win/strptime.c\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-37\n  (597)\n- A src/win/strptime.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-38\n  (8)\n- M src/win/win.h\n  https://github.com/darktable-org/darktable/pull/1327/files#diff-39\n  (6)\nPatch Links:\n- https://github.com/darktable-org/darktable/pull/1327.patch\n- https://github.com/darktable-org/darktable/pull/1327.diff\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1327, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B1Xwg635TUPYLh-kdBrEwb53leijks5q3N35gaJpZM4KfAh3\n.\n\n\nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. respect your persistence!\n2017-02-24 21:30 GMT+01:00 Heiko Bauke notifications@github.com:\n\nI have rewritten the hazeremoval module. It consumes much less temporary\nmemory now. It requires\n2 * sizeof(float) * number_of_pixel bytes of temporary memory plus 17 MB\nper OpenMP-Thread. Thus it is now able to deal with very large images, too.\nI hope the module is acceptable for integration into darktable with these\nimprovements. Heiko\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1447#issuecomment-282396584,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B1gBIyglredE4yPDrB5yFtgAFOaQks5rfz3ZgaJpZM4MGngc\n.\n\n\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. edgardoh,\nretouch is not in potfiles.in\ndid you plan it? will the iop soon be available for translators?\nregards Ger\nOp wo 5 sep. 2018 om 16:22 schreef edgardoh notifications@github.com:\n\nI just rebased and done a clean build and still works for me. What I've\ndone is:\nclone my fork\ncheckout retouch_gui branch\nbuild\nWhen adding a shape on any module, the shape preview is there.\nI don't know how the local merge is done, but if you guide me through your\nsteps I can try it. Or if you can compare your local files against the\nretouch_gui branch that can give us some info.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1550#issuecomment-418749313,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B1YYNM__vh3qsNUOFnabu6MKQTjwks5uX95CgaJpZM4QVYWo\n.\n. Thanks Pascal,\n\nmy mistake, I dit $ intltool-update -pot but forgot to update in poedit\nfrom pot file  ;-(\nOp vr 7 sep. 2018 om 21:00 schreef Pascal Obry notifications@github.com:\n\nI have made the French translation, so the translation is present :) Maybe\nyou need to update :\n$ intltool-update -pot\n?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1550#issuecomment-419533646,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48Bx4_sNGNkRzkGZ6JTfoyt3IS2Lb5ks5uYsI2gaJpZM4QVYWo\n.\n\n\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com\n. Tobias,\nsomething wrong here, see below, compile failed   grrrrr\nVersion string: 2.5.0+153~ge97133136\n/home/ger/darktable/po/it.po:8808: format specifications in 'msgid_plural'\nand 'msgstr[0]' for argument 1 are not the same\n/usr/bin/msgfmt: found 2 fatal errors\n[  3%] Building ca locale\n2292 translated messages.\npo/CMakeFiles/locale_it.dir/build.make:60: recipe for target 'po/it.mo'\nfailed\nmake[2]:  [po/it.mo] Error 1\nmake[2]:  Deleting file 'po/it.mo'\n[  3%] Building hu locale\nCMakeFiles/Makefile2:1302: recipe for target\n'po/CMakeFiles/locale_it.dir/all' failed\nmake[1]:  [po/CMakeFiles/locale_it.dir/all] Error 2\nmake[1]:  Waiting for unfinished jobs....\n[  3%] Built target create_version_gen\n[  3%] Building zh_CN locale\n/home/ger/darktable/po/gl.po:2: warning: header field 'Language' still has\nthe initial default value\n398 translated messages, 591 fuzzy translations, 629 untranslated messages.\n/home/ger/darktable/po/th.po:6: warning: header field 'Language' still has\nthe initial default value\n530 translated messages, 2 fuzzy translations, 1098 untranslated messages.\n[  3%] Built target locale_gl\n2277 translated messages.\n[  3%] Built target locale_th\n[  3%] Built target locale_ca\n2287 translated messages.\n2281 translated messages, 1 untranslated message.\n1518 translated messages[  3%] Built target locale_he\n, 74 fuzzy translations, 26 untranslated messages.\n[  3%] Built target locale_hu\n[  3%] Built target locale_zh_CN\nMakefile:151: recipe for target 'all' failed\nmake: *** [all] Error 2\n2018-01-21 10:23 GMT+01:00 Tobias Ellinghaus notifications@github.com:\n\nMerged #1632 https://github.com/darktable-org/darktable/pull/1632.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1632#event-1433991769,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B_kbenNTftwU7qfke85GYrwY6XAJks5tMwINgaJpZM4RleMK\n.\n\n\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. thanks for your quick respond\nand yes it\u2019s fixed. :-)\nOp zo 21 jan. 2018 om 21:10 schreef Tobias Ellinghaus \nnotifications@github.com\n\nThe .po was malformed. I fixed it in 330af24\nhttps://github.com/darktable-org/darktable/commit/330af2428f968f696730c0c8d6f304ac577fd96e.\nPlease verify that it's correct that way.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1633#issuecomment-359276691,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B907ubEzP8P-kVzIvbrnKjbZ72Hhks5tM5mrgaJpZM4Rl2gs\n.\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com website: www.gersiemerink.net\n. nice and welcome entry, I suppose \"rename\" will be translatable. is it possible that it will be, can you do that? the entry is a very welcome add. to be precise, this sentence \"enter the new name for the module\"should be translatable. as release candidates I don\u2019t have problems, all works fine for me\n\nOp ma 24 dec. 2018 om 17:11 schreef Philip Schwartz \nnotifications@github.com\n\nThe file failing on only the Release installer is\nC:\\Windows\\System32\\ntdll.dll Confirmed same on 1 of the other systems,\nso not digging there more.\nThat is a system based dll and is present on the systems (in 1803 -\n10.0.17134.228 (WinBuild.160101.0800)).\nIt is also accessed correctly by all of the 2.6.0 RC's and the previous\n2.4.4 release.\nTo have multiple systems fail on the same file with the same error points\nto the issue being the installer.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/1933#issuecomment-449750782,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B11d9yy07XiQmDzR-SMm_mWs57_Sks5u8Py-gaJpZM4ZghZY\n.\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com\n. looks promising, nice!!!\n\nOp do 3 jan. 2019 om 18:39 schreef Rikard \u00d6xler notifications@github.com:\n\nThis is the first draft of a new lighttable layout to show multiple\nselected images like e.g. survey mode in lightroom.\nCurrently it has a few limitations. For example the aspect ratio is not\ncalculated for all images (sort by ratio only calculates on demand)\nWith ctrl+click you can unselect images.\nFor the calculation I mainly used code from an old task manager skippy,\nbut adapted for non-rectangular windows. There probably is a better way.\nWhat do you think?\nYou can view, comment on, or merge this pull request online at:\nhttps://github.com/darktable-org/darktable/pull/1968\nCommit Summary\n\nadd filmstrip to lighttable\nadd first draft of expose view mode\nhide zoom slider\nraise collection changed on changed selection\n\nFile Changes\n\nM src/common/selection.c\n   https://github.com/darktable-org/darktable/pull/1968/files#diff-0\n   (14)\nM src/libs/tools/filmstrip.c\n   https://github.com/darktable-org/darktable/pull/1968/files#diff-1\n   (10)\nM src/libs/tools/lighttable.c\n   https://github.com/darktable-org/darktable/pull/1968/files#diff-2\n   (15)\nM src/views/lighttable.c\n   https://github.com/darktable-org/darktable/pull/1968/files#diff-3\n   (249)\n\nPatch Links:\n\nhttps://github.com/darktable-org/darktable/pull/1968.patch\nhttps://github.com/darktable-org/darktable/pull/1968.diff\n\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1968, or mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AB48B7JZeUfdPOwW4kZWJAwiD7THkyjjks5u_kBYgaJpZM4Zof8N\n.\n\n\n-- \nmet vriendelijke groet / kind regards Ger\nmailto:g.siemerink@gmail.com\n. ",
    "adsr303": "FYI: 1.2.x was updated during 1.2.1 string freeze, 1.1.x was updated by previous translator.\n. ",
    "jktjkt": "OK. While I disagree with the capitalization and find it unreadable, it is definitely your call to make (I can easily carry such patches on my own).\nChanged to include just the two \"reasonable\" changes.\n. Can I help to get this pull request merged? I've just rebased it on top of the current master, it works well.\n. So given that some of these changes are factually incorrect (the FP math for ICC in particular) and that I don't see a big performance difference with ICC anyway, I think that it's probably best to close this.\nCherry-picking https://github.com/jktjkt/darktable/commit/8ef272ef05eb1aca61d4bb8a8edf88e5487724a0 (with a better error message) is probably a good idea for portability, though.\n. Please see patch v2 (not sure if GitHub liked my force-push).\n. This statement is now executed even if offset == 0, while previously it was only hit if offset != 0. So we have to handle a zero offset somehow, and by default this new version of the code is going to assume that the user will be moving forward.\n. done\n. done\n. Please correct me if I'm wrong -- while it does have a cost, the job queue is a stack, so this cost is \"only\" in terms of potentially wasted energy and clogged cache, not in terms of latency. If you move \"too quickly\", the old jobs won't be executed until all newer requests have been processed. At that time, you're decoding an image that isn't going to be needed anymore.\nOn the other hand, having a higher number of items for preload means that you have a buffer of stuff you can show immediately, without slowing the user down. That's a big improvement to me.\nBut anyway, your preference is as good as mine. Number three is just a random pick -- it was my first choice and it's worked well for me. If there's a consensus for changing this, I don't really care, it's configurable after all.\n. done\n. I'm on a train with a 1600x900 screen, not my 2560x1600 that I have at home, and therefore everything is much faster right now. The numbers which I had at home, however, were between 3 and 10 seconds for rendering a full-size preview with no preload. Whether a longer buffer helps or doesn't help is going to depend on both the processing speed (and therefore the number of active image operations), the time you spend with each image in the preview, and on other aspects of your workflow, for example whether you're previewing large continuous series or not. Furthermore, these previews are actually stored in the disk cache as well, so their improvement is \"eternal\" -- once they're generated, you're going to benefit from them forever, or at least until you open darkroom for them once again. That's why I disagree with you on the \"as low as possible\" evaluation, but I understand your point -- you probably do not browse through previews so heavily, so for you it's wasted CPU time, even though it only affects energy, not the user experience. Fair enough -- if I was only using the full preview every now and then, I wouldn't have a use for this preload, either.\nSo if it's going to help upstream this patch, I'll be fine with preloading just one image :).\n. That's a leftover from a previous version of this patch. Fixed, thanks.\n. s/buidl/build/. ",
    "pryds": "Btw, would it be better to do this in a new branch on my fork, or wouldn't that matter to you?\n. ",
    "bartokk": "Please merge only the file from commit 53f4e2b293455d0b88f577e6ca7318a067841372.\n. I updated the file two times in a while of time, please merge it, and sorry for the annoiance.\n. You are welcome :-)\n. Hi Ulrich, how to use this in real world? In which module?\nMauro from Android\nGpg public key: 0x73E5AEA3\nIl 25/gen/2014 17:44 \"Ulrich Pegelow\" notifications@github.com ha scritto:\n\nThere have been reports on color problems which occur with certain camera\nmodels especially when an image shows highly saturated light sources like\nin stage photography. A typical symptom are black pixels or areas in the\nimage if modules like levels or monochrome are activated. Issue #9479 gives\na good example.\nThe technical cause lies in the color transfer from camera RGB to Lab\nwhich under special circumstances may result in unbound values, e.g. pixels\nwith negative L values. Most of our modules deal properly with unbound Lab\nbut some don't have any chance to give a reasonable output - hence the\nblack pixels.\nThis pull request adds an option to the colorin module which on activation\nconfines the Lab output of that module to some user selectable gamut. One\ncan choose \"sRGB\" and \"linear RGB\" for a more restricted color space or\n\"Adobe RGB\" and \"Beta RGB\" for a broader gamut. You need to test what fits\nbest to avoid artifacts and at the same time leave colors as un-damped as\npossible.\nIt is important to mention that this gamut clipping option is not\nrestricting modules further down the pixelpipe to produce Lab values\noutside of the chosen gamut. Therefore the selected color space is not to\nbe mistaken as a \"working color space\".\nWould be great some of the other devs could review before merging.\nYou can merge this Pull Request by running\ngit pull https://github.com/upegelow/darktable normalize\nOr view, comment on, or merge it at:\nhttps://github.com/darktable-org/darktable/pull/443\nCommit Summary\n- gradientsliders: use NAN as value to disable display of color picker\n  value\n- colorin: add option to normalize Lab values to real, ie. non-virtual\n  colors\n- colorin: extended version: fix shortcomings; enable selection of\n  clipping profiles; implement SSE and OpenCL codepaths\n- colorin: some code cleanup\nFile Changes\n- M data/kernels/basic.clhttps://github.com/darktable-org/darktable/pull/443/files#diff-0(70)\n- M src/common/colorspaces.chttps://github.com/darktable-org/darktable/pull/443/files#diff-1(60)\n- M src/common/colorspaces.hhttps://github.com/darktable-org/darktable/pull/443/files#diff-2(3)\n- M src/develop/blend_gui.chttps://github.com/darktable-org/darktable/pull/443/files#diff-3(4)\n- M src/dtgtk/gradientslider.chttps://github.com/darktable-org/darktable/pull/443/files#diff-4(13)\n- M src/iop/colorin.chttps://github.com/darktable-org/darktable/pull/443/files#diff-5(324)\n- M src/iop/colorin.hhttps://github.com/darktable-org/darktable/pull/443/files#diff-6(36)\n- M src/iop/relight.chttps://github.com/darktable-org/darktable/pull/443/files#diff-7(2)\nPatch Links:\n- https://github.com/darktable-org/darktable/pull/443.patch\n- https://github.com/darktable-org/darktable/pull/443.diff\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/443\n.\n. Please guys, let's merge the commit.\n. Il 21/feb/2014 09:00 \"Boucman\" notifications@github.com ha scritto:\nI copy/pasted manually because of merge conflict, but it's in\n\nReply to this email directly or view it on GitHub.\n\nOK, thanks.\nMauro from Android\nGpg public key: 0x73E5AEA3\n. It's fine for me. I often have the same problem with film rolls containing\na lot of images.\nMauro from Android\nGpg public key: 0x73E5AEA3\nIl 03/apr/2014 17:38 \"Pedro C\u00f4rte-Real\" notifications@github.com ha\nscritto:\n\nHere's a quick hack that made darktable work much better in my current\nsetup (limited memory, large screen). I set the DT_MIPMAP_3 size to 640x480\nmax, whatever the max_width and max_height was set to in the preferences.\nThis gave me a larger number of slots for thumbnails while at the same time\nletting me fill the screen in darkroom and lighttable Z mode (partially\nfixing #9884).\nCurious why this couldn't be the default. It seems creating very large\nthumbnails doesn't make much sense past a certain point. Even at 4K\nresolutions 640x480 would give you 6x4 thumbnails if you filled the whole\nspace. Since the lighttable ads borders it will give you even more\nYou can merge this Pull Request by running\ngit pull https://github.com/pedrocr/darktable clipcachesizes\nOr view, comment on, or merge it at:\nhttps://github.com/darktable-org/darktable/pull/512\nCommit Summary\n- Limit the thumbnail cache sizes to 640x480 max\nFile Changes\n- M src/common/mipmap_cache.chttps://github.com/darktable-org/darktable/pull/512/files#diff-0(4)\nPatch Links:\n- https://github.com/darktable-org/darktable/pull/512.patch\n- https://github.com/darktable-org/darktable/pull/512.diff\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/512\n.\n. Is there anybody out there? :-)\n. I updated it yesterday.\n\nMauro from Android\nGpg public key: 0x73E5AEA3\nIl 06/apr/2014 13:59 \"Ger\" notifications@github.com ha scritto:\n\nyour update is from yesterday???\nI can do it but i used to do only merge 'nl.po'\nregards Ger\n2014-04-06 13:46 GMT+02:00 bartokk notifications@github.com:\n\nIs there anybody out there? :-)\n\nReply to this email directly or view it on GitHub<\nhttps://github.com/darktable-org/darktable/pull/513#issuecomment-39666281>\n.\n\nhttp://www.gersiemerink.net\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/513#issuecomment-39666518\n.\n. Drink one more beer for me!\n\nMauro from Android\nGpg public key: 0x73E5AEA3\nIl 06/apr/2014 19:53 \"simonspa\" notifications@github.com ha scritto:\n\nWe were all still in Leipzig spending another day after LGM...\n:)\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/513#issuecomment-39674907\n.\n. Hi guys, please merge the commit.\nThanks \u263a\n. Thank you, Pascal.\n\nMauro from Android\nGpg public key: 0x73E5AEA3\nIl 31/mag/2014 15:48 \"Pascal Obry\" notifications@github.com ha scritto:\n\nDone!\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/574#issuecomment-44748757\n.\n. Up :-)\n. \n",
    "bencahill": "@houz These are the only three places the function is used:\n1. Importing a single image\n2. Importing a folder\n3. Showing darktable the new location of an existing filmroll using 'collect images' > 'folders' > right-click > 'search filmroll...'\nFrom my viewpoint, it makes sense to implement this for all three of those. Since there were no other uses of the function, I just renamed the old one.\nWhat do you think?\n. @jcsogo Okay, that makes sense. I'll fix it up when I get a chance.\n. @boucman Yes. I got quite busy after my last post; I prioritized things yesterday, and I have a due date of today for this. We'll see how that goes. :-P\n. Okay, I finally got this fixed up.\nPlease take a look and see if there is anything I did wrong, because this is the first time I've dabbled in any C code at all.\nIt did compile and work, though.\n. ",
    "bruceg": "I've modified the code to use mm*_ps functions instead of the overloaded operators as requested.\n. You would be right. A quick grep reveals other public variadic functions that are likely to use printf formats. I'll get them too.\n. I used %ld because that is what GCC suggested and I didn't know about %z until just now. I will fix that.\n. I see that now. I'll fix\n. ",
    "wgoetz": "example with prefences: GUI options:maximum width/height of image drawing area both 400\n\n. :-)\n\n. Pascal, did you ever used the 'snasphots' module in darkroom upper left?\nnothing to do with zoom, just the hard limitation of maximum picture size!\nthe global variables: darktable.thumbnail_width/height\n- have a picture displayed in darkroom\n- select a lower history part (here:0)\n- klick 'take snapshot'\n- select topmost history item (here:2)\n- klick onto history item in snapshot box above the 'take snapshot' button \n- watch for the splitline , act with mousepointer \n- klick middle line (cirle): splitline rotates\n- drag outside the middle: move the border\nno problems if your picture is less than the preferences maximum values.\nto see the effect:\n--> get a big screen (sigh...)\n--> reduce the max values (here : 400 in darktabel preferences:GUI options:maximum ...drawing area)\ngreets\nWolfgang\n. @boucman : you have mail!\nin short: changes only for  src/libs/snapshots.c\n1st picture: original behaviour, misplaced snapshot data, mouseevents\n2nd picture:  patch attached. snap data+mousevents ok\n. found some history for the git branching/rebasing thing:\non branch master i keep upstream untouched:\n1290  git fetch upstream\n1292  git merge upstream/master\nworking branch is snapfix:\n1300  git checkout snapfix\n1303  git rebase master\nfor me looked like 'snapfix' has now all items from master \nwondering on this blog: 5+real messages and a lot of automated garbage. \ni will keep things more the simple way in future...\n. Hello Pascal, in general you're right even when there are lots of changes to external code.\nNevertheless the used code base is fairly old, it will be more and more impossible to follow upstream.\nrawstudio svn uses different files than the svn ones mentioned in src/external/rawspeed/update_rawspeed.sh\ni'm confused.\nwell:\ncd darktable\ntools/update_librawspeed.sh\nchecking some files, build, install\ncompiles.runs.decodes my digcams as before. (where's the beef?)\nNOK for the Fuji S5Pro. (as before)  rawstudio and ufraw are OK. \n2morrow more... \n. in which other control/module does a user have to say explicitely to store a result?\nchanging sliders and stopping the move means.. persistence. not for crop borders.\non the other hand behaviour is buggy: get a picture. move clip borders. store them.\nchange to lighttable. change to darkroom. switch module on/off..\nmove borders and go immediately to lighttable. come back. on/off module \n\nit drives me crazy. \n. \nthe picture from above comment.  (unblocking s3.amazonws.com) \n. discussion snippet in usenet newsgroup de.rec.fotografie... (archive via google groups:)\nhttps://groups.google.com/d/msg/de.rec.fotografie/oOPxfTkwd30/tlMs36GXSC8J\n. joined.. using same nick as here!\nwhere to place such an update function? i found gui_post_expose to be called on every mouse event when inside the picture. (via poor man's debug using printf output). The state of mouse button 1 is memorized in static variable between two calls of function. the 1->0 transition is catched by the else path where commit_box is called.\nthus releasing the mouse button always gives updated state of cropping.\nkey accel: ohoh.. holding down mouse moving crop border and simultaneuosly pressing 'l' will loose crop setting, \nhow to block key accel when in active mouse action...  there should be a oneandonly destructor.\nanyway history is not happy at all. having  to step one back and forward again to activate.\n. just seen: no update of history when leaving crop via 'l'. preview is ok, coming back to 'd' one has to activate crop again. doubleclick to change to 'l' is working for history\n. Pedro C\u00f4rte-Real wrote:\n\nMerged #1099.\n\nblack output!   nikon d800 and 1j5\n[rawspeed] FileMap: Attempting to read file out of bounds.\n[rawspeed] FileMap: Attempting to read file out of bounds.\nlast working commit:\nfbede70edd0abdd05080191ce3652c8f0ab1ac92 rawspeed: add a\nzero_is_not_bad for future use\n\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/1099#event-542301137\n. yes. this is what (inactive) in commit comment tries to communicate.\n\nthis was the first try to find a place/event where to store clipping result.\ndoesnt work for all items. pls forget about changes in darkroom.c\n. ",
    "angryziber": "This is what I want to fix (technical filenames displayed to users):\nhttps://picasaweb.google.com/117440562642491680332/Argentina\nThis is what it has to look like (some photos are explicitly with a title, while some are not):\nhttps://picasaweb.google.com/117440562642491680332/RockyMountains\n. I did test it myself, of course.\n. Guys, please, is there a problem with the patch? Should I make a smaller one?\n. ",
    "VictorLamoine": "I don't understand what you ask me, on git on the \"files changed\" tab I only have 1 file modified :\nShowing 1 changed file with 13,412 additions and 2,580 deletions\nI'm waiting for more detailled instructions as I'm totally new to git. Thanks !\n. Hello,\nI don't get what's wrong.\nHow am I suppose to solve the problem ?\n. I don't know what to do.\nHere are some terminal outputs :\nvictor@X301A1:~/darktable$ git remote -v\norigin    git@github.com:VictorLamoine/darktable.git (fetch)\norigin    git@github.com:VictorLamoine/darktable.git (push)\nTo update the file this is what I usually do:\ngit pull git@github.com:darktable-org/darktable.git\ncd ~/darktable/doc/usermanual/po/ && git add fr.po\ngit commit -m 'Small manual update'\ngit push origin master\nvictor@X301A1:~/darktable$ git pull git@github.com:\ndarktable-org/darktable.git\nFrom github.com:darktable-org/darktable\n- branch            HEAD       -> FETCH_HEAD\n  Already up-to-date.\nIf I compile and run darktable the version shown is :\n1.3+1928gd87e8d9\nI don't even understand what's wrong.\n2014/1/19 simonspa notifications@github.com\n\nHi Victor,\nyou need to go into your repo and run\n$ git merge upstream master\n$ git push origin master\n(or whatever the names of your remotes are)\nin order to update your repository with the changes applied to our master.\nSomething was in there making the merging non-fast-forward why you have to\ndo it by hand.\nCheers,\nSimon\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/420#issuecomment-32711912\n.\n. These are corrections from the file in the usermanual branch. After discussions we decided to use this translation as a basis. It is the most complete and best translation at the moment.\n. Je pense que le mieux est de merger; la traduction est d\u00e9j\u00e0 tr\u00e8s compl\u00e8te.\nUne fois que cette version sera en ligne les pull request ne seront plus\nque des am\u00e9liorations/corrections.\nLa traduction actuellement sur le master c'est la mienne; elle est tr\u00e8s\nincompl\u00e8te (environ 30% de traduit). Jean-Luc m'a envoy\u00e9 un mail pour me\nsignifier qu'il avait d\u00e9j\u00e0 une version compl\u00e8te.\n\nDonc on aimerait que la traduction de Jean-Luc soit sur le master pour\ncommencer les am\u00e9liorations/modifications.\n2014-03-04 12:20 GMT+01:00 Boucman notifications@github.com:\n\nok, dois-je fermer cette PR ? je crois que vous pouvez le faire\nvous-m\u00eame... sinon, dois-je la merger ?\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/485#issuecomment-36614663\n.\n. By the way, building the user manual reveals a missing file:\n\nImage not found. URI: darkroom/modules/color/images/darkroom_module_icon_picker.png. (No context info available)\n. Fixed :wink: \n. @michleb The pull request is automatically synced with the branch. It's fine now.\n. ",
    "jakeprobst": "what do you mean by resurrect?\n. All that section does is try to be efficient and not read the info twice if not needed, I can just remove it completely if you would prefer. I think I just sort of looked at something similar to what I needed in the code and copy/pasted it.\n. And Im not too keen on putting the reading of the image in _camera_request_image_filename and _camera_request_image_path as that would be multiple reads and that sounds inefficient (it already is sort of inefficient though, as it still reads twice (optimally, I would read the file, get the exif, make the filename, then write what I previously read)).\nWorking on a solution possibly\n. If youre looking for the place to set the filename patterns, it was moved to session options in the main preference window (it really should be moved back, people expect it to be in the import window).\n. sorry busy with school and life and havn`t had time to work on this\n. I am bad at git and possibly messed stuff up.\nbut anyway, I fixed the exif time overwriting the local time. couldnt figure out why the .jpgs gave bad exif info, and the .cr2 files didnt even register as existing on my camera when I tried to import them (I have a nikon).\n. you can close this,I probably wont be attending to it anytime soon.\n. > i have no idea if the last issue (problems with RAW) was fixed.\nI dont recall there being a problem with RAW, the issue was I could not get exif data out of jpegs. I couldn`t ever figure out why which is kinda why I abandoned working on it.\n. try upgrading to gphoto 2.5, I recall needing to upgrade to make it work.\nEDIT:\nactually, does it matter? I do believe it just uses gphoto2 to copy the file into memory then uses darktable's internal functions to get the exif data.\n. Another point about this: I feel the text entries where you specify the file pattern for import should be part of the camera import window under settings. It is currently in the general settings under session options. This seems unobvious.\nUnsure if I should make it part of this or do it as a separate request (it feels related enough to this I think?).\nAnd yeah this happened last time, I guess I just like programming when you like to freeze features. It works for me right now so I`m not really in any sort of rush to get it in.\n. Ok I am hilariously bad at git.\nI was trying to merge the stuff but it is miserable so I just nuked the branch and just started over but then I ended up deleting the branch and I figured if I named it the same thing it would magically work but that is not the case. And it also seems I am unable to change the branch to import from on a request.\n. It was never merged as far as I know. \nI'll update this pull request if I can get some confirmation that it'll actually be merged.\n. well, someone post in this thread when I should work on this so I get an email to remind me.\n. Ok it should be good to merge now.\n. updated\n. updated\nturns out _camera_change_exif_time wasn't even used.\n. ",
    "rwh86": "Seems to be broken on git head for me, I'm getting this, with the PR applied or not:\n\n. Seems to work so far, though I had to revert 573ef413 or I got a build error on tiff.c.  Will continue playing around when I have some more time, hopefully this afternoon.\n. I think I have some funky test cases here.  I've put together some (admittedly rather challenging) images, copied them to my camera's memory card, put it back in my camera, and tried to import them.  The images I chose were with various dates 2005-2008 taken on my old camera (350D) plus a couple of photos I took this morning.  I did this with 1.4.1 (which successfully imported them all into a single folder with today's date).  I then tried the git head without 573ef411 and with this PR on top.  Started out by removing ~/.config/darktable directory.\nImporting images:\n\nAfter import one of the images seems to be missing (although it seems to be on the filesystem, and darktable knows where it is in the image information:\n\nDarktable then crashes.  Info on the terminal was:\n\n[defaults] found a 64-bit system with 12296712 kb ram and 8 cores (0 atom based)\n[defaults] setting high quality defaults\n[mipmap_cache] database is new, dropping old cache `/home/rwh/.cache/darktable/mipmaps-89b8ed5923711056de68706c94c651f9d81fe5a2'\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0001.JPG.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0002.JPG.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0003.JPG.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0004.JPG.\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140226_0005.CR2.\n[exiv2] Directory Image3, entry 0x0111: Strip 0 is outside of the data area; ignored.\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140227_0006.CR2.\n[exiv2] Directory Image3, entry 0x0111: Strip 0 is outside of the data area; ignored.\n[exiv2] Directory Image3, entry 0x0111: Strip 0 is outside of the data area; ignored.\n[rawspeed] LJpegDecompressor::getSOF: Start offset plus size is longer than file. Truncated file.\n[imageio] '/home/rwh/Pictures/Darktable/20140227_noname/20140227_0006.CR2' blacklisted extension passed to libraw\n\nResulting directories were:\n\nNow that I come to think of it, perhaps the problem is that the images were taken with a different camera than the one that I'm using to import, or perhaps it's related to the images being JPGs?  I'll pull together some other example images and try again.  Let me know if you'd like a copy of my test images.\n. One other thing to note is that this is with all-default configuration.  Shouldn't this behave the same as the unpatched darktable until you change the file naming scheme to use $(EXIF_YEAR), $(EXIF_MONTH) etc. instead of $(YEAR), $(MONTH) etc.?\n. Test photos here: https://www.dropbox.com/sh/t8q7r1voxmxsje8/Q7Fp65nlc8\n. I didn't touch the defaults:\nbase directory naming pattern: $(PICTURES_FOLDER)/Darktable\nsub directory naming pattern: $(YEAR)$(MONTH)$(DAY)_$(JOBCODE)\nfile naming pattern: $(YEAR)$(MONTH)$(DAY)_$(SEQUENCE).$(FILE_EXTENSION)\nSo I should retest after changing the sub directory naming pattern to $(JOBCODE) or something?\nAny ideas on why exiv2 is treating the JPEGs as TIFFS and therefore failing to read the EXIF tags?  Maybe it's because I copied them to the 5d3 and they were actually 350D files... what I'll do is re-test using the 350D, assuming I can find the cable.\n. @edgomez Thanks for that, I've updated to git head and the tiff.c build errors are fixed.  Test cases:\n- 5d mark 3, 6 files taken over 3 days, some RAW, some JPG:\n``\nrwh@monster:~$ rm -r .config/darktable .cache/darktable Pictures/Darktable\nrwh@monster:~$ /opt/darktable/bin/darktable\n[defaults] found a 64-bit system with 12296712 kb ram and 8 cores (0 atom based)\n[defaults] setting high quality defaults\n[mipmap_cache] cache is empty, file/home/rwh/.cache/darktable/mipmaps-89b8ed5923711056de68706c94c651f9d81fe5a2' doesn't exist\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140228_0001.CR2.\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140301_0002.CR2.\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140301_0003.CR2.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0004.JPG.\n[exiv2] Ignoring XMP information encoded in the Exif data.\n[import_session] Using filename 20140301_0005.CR2.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0006.JPG.\n```\nResulting file structure:\nrwh@monster:~/Pictures/Darktable$ find\n.\n./20140302_noname\n./20140228_noname\n./20140228_noname/20140228_0001.CR2.xmp\n./20140228_noname/20140228_0001.CR2\n./20140301_noname\n./20140301_noname/20140301_0005.CR2.xmp\n./20140301_noname/20140301_0002.CR2\n./20140301_noname/20140301_0002.CR2.xmp\n./20140301_noname/20140301_0005.CR2\n./20140301_noname/20140301_0003.CR2.xmp\n./20140301_noname/20140301_0003.CR2\n./-00011130_noname\n./-00011130_noname/-00011130_0006.JPG.xmp\n./-00011130_noname/-00011130_0004.JPG.xmp\n./-00011130_noname/-00011130_0004.JPG\n./-00011130_noname/-00011130_0006.JPG\n- Result: the raw files seem to import into separate directories and film rolls.  The JPG files are all imported into a directory with a bogus date.\n- Comments: $(YEAR)$(MONTH)$(DAY) have been overridden by those values from EXIF, but only in RAW files.  Is this desirable, or should there be $(EXIF_YEAR)$(EXIF_MONTH)$(EXIF_DAY) versions so that users can still get the old behaviour if they want it?\n. - 350D. 5 files taken over 3 days, some RAW some JPG:\n``\nrwh@monster:~$ rm -r .config/darktable .cache/darktable Pictures/Darktable\nrwh@monster:~$ /opt/darktable/bin/darktable\n[defaults] found a 64-bit system with 12296712 kb ram and 8 cores (0 atom based)\n[defaults] setting high quality defaults\n[mipmap_cache] cache is empty, file/home/rwh/.cache/darktable/mipmaps-89b8ed5923711056de68706c94c651f9d81fe5a2' doesn't exist\n0000:  49 49 2a 00 10 00 00 00 43 52 02 00 0a 7e 09 00  II*.....CR...~..\n0010:  0e 00 00 01 03 00 01 00 00 00 00 06 ff ff 01 01  ................\n0000:  ff d8 ff c4 01 a2 00 00 01 05 01 01 01 01 01 01  ................\n0010:  00 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08  ................\n0000:  49 49 2a 00 10 00 00 00 43 52 02 00 e7 a1 0a 00  II*.....CR......\n0010:  0e 00 00 01 03 00 01 00 00 00 00 06 ff ff 01 01  ................\n0000:  ff d8 ff c4 01 a2 00 00 01 05 01 01 01 01 01 01  ................\n0010:  00 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08  ................\n0000:  49 49 2a 00 10 00 00 00 43 52 02 00 e7 bb 09 00  II*.....CR......\n0010:  0e 00 00 01 03 00 01 00 00 00 00 06 ff ff 01 01  ................\n0000:  ff d8 ff c4 01 a2 00 00 01 05 01 01 01 01 01 01  ................\n0010:  00 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08  ................\n0000:  49 49 2a 00 10 00 00 00 43 52 02 00 7d d1 44 00  II*.....CR..}.D.\n0010:  0e 00 00 01 03 00 01 00 00 00 80 0d ff ff 01 01  ................\n0000:  ff d8 ff c4 01 a2 00 00 01 05 01 01 01 01 01 01  ................\n0010:  00 00 00 00 00 00 00 00 01 02 03 04 05 06 07 08  ................\n[exiv2] Directory (Last IFD item) with 11372 entries considered invalid; not read.\n[import_session] Using filename 20140217_0001.CR2.\n[exiv2] Directory (Last IFD item) with 11372 entries considered invalid; not read.\n[exiv2] Directory (Last IFD item) with 43162 entries considered invalid; not read.\n[import_session] Using filename 20140217_0002.CR2.\n[exiv2] Directory (Last IFD item) with 43162 entries considered invalid; not read.\n[exiv2] Directory (Last IFD item) with 32773 entries considered invalid; not read.\n[import_session] Using filename 20140228_0003.CR2.\n[exiv2] Directory (Last IFD item) with 32773 entries considered invalid; not read.\n[exiv2] Directory (Last IFD item) with 36129 entries considered invalid; not read.\n[import_session] Using filename 20140301_0004.CR2.\n[exiv2] Directory (Last IFD item) with 36129 entries considered invalid; not read.\n[exiv2] This does not look like a TIFF image\n[import_session] Using filename -00011130_0005.JPG.\n```\nResulting file structure:\nrwh@monster:~/Pictures/Darktable$ find\n.\n./20140302_noname\n./20140217_noname\n./20140217_noname/20140217_0001.CR2.xmp\n./20140217_noname/20140217_0001.CR2\n./20140217_noname/20140217_0002.CR2\n./20140217_noname/20140217_0002.CR2.xmp\n./20140228_noname\n./20140228_noname/20140228_0003.CR2\n./20140228_noname/20140228_0003.CR2.xmp\n./20140301_noname\n./20140301_noname/20140301_0004.CR2\n./20140301_noname/20140301_0004.CR2.xmp\n./-00011130_noname\n./-00011130_noname/-00011130_0005.JPG.xmp\n./-00011130_noname/-00011130_0005.JPG\n- Result: the raw files import into separate directories and film rolls.  The JPG files are imported into the same bogus date directory as for the 5d3.  There was an empty directory created with today's date despite no photos having been taken today.\n. @MRIG Not sure the attachments are working.\n. What's the best approach for benchmarking? darktable -d opencl -d perf?  And then the same thing with opencl disabled in the global config?\n. with opencl enabled: http://pastebin.com/ubYm8ScB\nwith opencl disabled: http://pastebin.com/NE33Y7hY\n. Does this mean it might be possible to enable multiple instances as well?\n. Cool!  What's the issue?  The fact that it's possible to mask out parts of the image, leaving the white balance there as a no-op?\n. Ah! :)\n. I've done a few tests.  Let me know if there's anything else specific you'd like me to try.\nTest methodology:\n- Take some folders of photos shot at different times in the past on different cameras\n- Find some previously corrected photos if possible\n- Open in DT 1.6.6 and DT 1.7+pr892\n- Compare UI\n- Export image with both versions and compare\n- Make some comments.  These are just observations, not requests for changes or value judgements; these need to be evaluated by someone more qualified.\nLensfun version 0.2.8-2 is installed.\nRWH_0936.CR2\n- Canon 5d3 with 24-105 f/4 L\n- original xmp created on March 4th 2015 in dt 1.6.3\n- See screenshots of the two versions of the module\n- Old lens correction module shows camera, lens, focal length, f stop, and distance to subject\n- New lens correction module shows everything simply as \"auto\" \n  - Can't immediately tell if the camera/lens have been successfully detected or any of the parameters\n  - However, eventually discovered that mouseover text identifies camera and lens\n- New module claims to be correcting both distortion and scale, old module only claims distortion\n- The output images appear the same but have slightly different file sizes so are not identical\n  - compare RWH_0936_1.6.6.jpg RWH_0936_1.7+pr892.jpg -compose src diff.png\n    - shows extensive pixel-level differences\n- Setting each option to \"manual\" results in display of the same values as from dt1.6.6\n- Mouseover of the option labels and values in 1.6.6 shows descriptive tooltips, however you can only mouseover the values in 1.7+pr892: the labels (mm, f/ and d) no longer have a tooltip\n- geometry claims to be \"rectilinear\" in 1.6.6 and \"off\" in 1.7+pr892 by default\nRWH_7706.CR2\n- Canon 5d3 with 16-35 f/2.8 L II\n- Camera/Lens combo not found (despite me submitting samples to bronger over a year ago and it being listed as supported in http://lensfun.sourceforge.net/lenslist/).  Assume old lensfun or something.\n- In 1.7pr892, mouseover tooltip shows the camera/lens info that's displayed in the drop down list in 1.6.6.\n- Both versions have most options greyed out.  Therefore, to discover that there's a new mode \"distort\" you'd have to select a lens supported by lensfun first.\nIMG_2821.CR2\n- Canon 60D with 70-200 f/4 L IS USM\n- Also not detected despite being in supported list.\nIMG_0574.CR2\n- Canon 350D with 18-55 f/3.5-5.6 IS II\n- Lens/body combo not detected, lens listed as 65535 in mouseover text, perhaps due to the lens being newer than the body and thus the body being unable to identify it.  EXIF of CR2 lists \"Lens Type\" as \"(65535)\" but \"Lens\" as \"18.0 - 55.0 mm\".  Perhaps this slightly more informative value could be used in the tooltip?\n- Manually selecting the lens seems to work fine in both 1.7+pr892 and 1.6.6\n- Once manually selected, the tooltips for mm, f and d list show their values with six digits after the decimal point: 18.000000, 7.100000 and 1000.000000 in the tooltips in 1.7+pr892.  In 1.6.6 these are listed as 18, 7.1 and 1000, respectively.\n. The presets are available in the white balance module (in the basic group) in the darkroom.  The preset pulldown list contains daylight, shade, cloudy, tungsten, fluorescent and flash.  Once you select one of those, you can drag the finetune slider, which is the equivalent of changing the white balance fine tune on the camera, along the blue/amber axis.\nThe values for this were loaded from images taken from the camera itself, the method used for this generation step is here: http://www.darktable.org/2012/10/whats-involved-with-adding-support-for-new-cameras/ under the \"White balance presets\" section.\n. OK, I'll see if I can pull some content from elsewhere into a CONTRIBUTING.md.\n. @simonspa: where is that content from?  Googling suggests it's from here, which is AFAICT doesn't have an explicit open-source license, in fact I can't tell what license it's under.\n. Closing this pull request as it was on my master branch.  Moved to its own branch, new pull request is #1058.\n. @edgardoh For contacting the developers, the IRC channel is definitely the best, but the darktable-dev mailing list is still in use and most of the devs are subscribed to it.\nThe mailing list that you're thinking of that has 30+ mails per day is probably the user list, see: https://github.com/darktable-org/darktable/blob/master/README.md#mailing-lists\n. I found while I was testing the build on multiple platforms that I used the included Lua 5.2 more often than not, and I didn't have to tell cmake to do anything differently (I generally build with build.sh).\n. ",
    "rkahl": "I can understand your objections, but looking at src/libs/tools/filmstrip.c it seems to me that this is exactly the way to do the filtering (see _lib_filmstrip_imgid_in_collection). Please correct me if I'm wrong.\n. The collected_images table led to a simpler and way more elegant solution now, thanks for the hint.\n. @supertobi: Thank you for your feedback... To your questions:\n\nAs mentioned before, the location ist stored in the data.db after successful lookup. This means that the lookup is performed once for each image when its location changed. I also thought about further caching, especially to avoid a lookups for coordinated that have been looked up before (with other images), but I couldn't find the ideal solution yet (though didn't put much effort into that subject - how many images do you have with exactly the same coordinates).\nMy favourite is to also store the timestamp when a location was set. This way it's possible to ask the images table if these coordinates have been looked up before.\nYes, it's working the same way in the collection module as the tags mode. But if you mean a function like \"find images nearby POI...\": that would be a completely different story.\nNot yet, but I will add that.\nI will have a closer look at that.. \n",
    "saro": "Hi all,\nis there any update regarding this issue? It would be really handy for me to have this feature available.. ",
    "steinsag": "Just tested it, looks fine to me!\n. ",
    "bronger": "I should add: You see an effect only with SVN lensfun.\n. Lensfun may return more than one lens even if the lens model name passed to it leads to a unique lookup.  This is because for one lens, there may be multiple calibrations, and a \"lens\" in lensfun is actually a calibration measurement rather than a lens per se.  However, more than one search result irritates the darktable code, so it refuses to do something with the result.\nBy using LF_SEARCH_SORT_AND_UNIQUIFY, lensfun really retuns only one lens object, if the lens model name was complete.\n. If tonecurves replace basecurves for some camera models, I wonder how those are then applied to the pictures.  Presets are a kludge.\n. edgomez, fair enough.  I didn't want to (and don't have competence to) preclude this PR from merging.\nHowever, things are changing for the basecurve module anyway.  So, I think it is good to take your tonecurve/basecurve observations into account for these changes.  In particular, I would think that having tonecurve presets as \"poor man's basecurve\" on the long run is not a good situation.\n. - The new module is too wide for my screen.  I see a horizontal scroll bar.\n- I actually don't like all those \"auto\" all over the place very much.  They provide no information.  I prefer having the camera model and lens model, and the EXIF parameters in the fields instead.  Besides, manual selection of EXIF values looks rather cumbersome with the two dropdowns per parameter.\n- Also, if automatic correction is unavailable, the respective selection should be \"off\" instead of \"auto\".  This way, the information provided by the very last line is already contained in the selection menus above.\n- If you switch scaling to \"manual\", the starting value is 1 (or the latest manual factor) instead of the latest autoscaling value.  I think it is more comfortable to have the latter.\n. I cannot see the issue report #10425 at the moment (Redmine is down) but doesn't adding \"auto\" to the selection lists (camera, lens, focal length etc) make it unambiguous?\n. I think I see the problem now.  We have three possible states: \"auto\", \"manually selected\", and \"detection failed\".  Is this correct?\n. The option LF_SEARCH_SORT_AND_UNIQUIFY sorts by focal length, and it collapses entries with the same lens model name, keeping the one that has the higher matching score.  Instead, if you pass \"0\", all matching lenses are returned sorted by decreasing matching score.  The first mode is best if you want to generate a nice-look selection list, the latter mode is best if you want to lookup a particular lens.\nThen why do we use LF_SEARCH_SORT_AND_UNIQUIFY everywhere currently?  Because formely, DT insisted on uniqueness of the search result when doing a lens lookup.  This was bad because Lensfun quite often finds more than one matching lens, e.g. different crops of the same lens.  So I added LF_SEARCH_SORT_AND_UNIQUIFY.  After that, I found out that Lensfun may still return more than one entry, namely if there is a lens model name slightly longer than the requested one, e.g. \"Olympus Zuiko ...\" and \"Olympus M.Zuiko\".  So, I removed the uniqueness checks completely.\nNow, we have a problem in Git Lensfun with images taken with \"Olympus Zuiko Digital ED 9-18mm f/4.0-5.6\".  DT insists on using \"Olympus M.Zuiko Digital ED 9-18mm f/4.0-5.6\", even if you manually select the first lens!  This is because \"M\" is before \"Z\" in the alphabet, and LF_SEARCH_SORT_AND_UNIQUIFY sorts by focal length, then lens name.\nThus, this PR changes back to ordinary \"sort by matching score\" in places where DT just wants to lookup a lens, and keeps LF_SEARCH_SORT_AND_UNIQUIFY where DT builds actually a list.\n. I am not really competent to comment on this, I'm afraid.\n. It is possible that inner pixels are placed outside the rim.  This is a pathological case without photographic application.  If this may destroy data or kill the DT process, you must be able to handle this case.  If this only leads to funny screens, I would ignore this possibility.\n. Lensfun's coordinate transformations may place a pixel lookup for a certain output pixel in the original image outside the rim in the original image.  These areas become black in DT.  Again, this only happens with broken profiles.\nLensfun uses polynomials for the mapping.  For every lens in existence, they are monotonic.  But of course, with bogus coefficients, you can make them oscillating.\nGeometry transformations (e.g. fisheye -> rectilinear) are not affected AFAICS.  These mappings are always monotonic.\n. Since nobody can assure that the ordering is bug-free (or can never be improved, for that matter), there should be a way to change it without breaking old images. Is it feasible at all to make it flexible at runtime?. In more recent LensFun versions, LensFun itself sets LF_SEARCH_SORT_AND_UNIQUIFY.  See http://svn.berlios.de/wsvn/lensfun?op=comp&compare[]=/trunk/@331&compare[]=/trunk/@332\n. If this check is true, rx and ry in lines 790 and 791 get \"NaN\" or \"Inf\", line 792 assigns a NAN, and line 818 assigns (float4)0.0f.  So I think these checks are superfluous, but I assume that these kernels follow the same rules as ordinary C code.  I'm not an OpenCL user.\n. The \"isfinite\" is not necessary.\n. ",
    "ghost": "So this means since Feb 2014 MFT lens corrections should come out fine? Then I am clearly doing something wrong, my lenses are not corrected, auto correct just does a bit of correction... How can I make it work properly? Or where can I find how to do that?\n. Hello Jan Niklas Fingerle,\nThank you for your answer. It made me very hopeful. Until I noticed the word [darktable] in this message. I understand that I got lost in the GitHub world, because I was looking for issues with Rawtherapee (which doens't seem to be able to read the lensfun database). \nOf course I could install Darktable, but that would mean the computer I share with my wife needs to run on a different OS. Seems a bit you may need some developers' skills to work with Darktable (and I'm just a plain user that could only be able find some bugs, but never deliver any patches...). \nThank you, greetings\nDate: Mon, 19 Oct 2015 14:14:14 -0700\nFrom: notifications@github.com\nTo: darktable@noreply.github.com\nCC: baarlezander@hotmail.com\nSubject: Re: [darktable] Use Exif.OlympusEq.LensType for Olympus FT lenses (#449)\n@BertdeV Well, yes and no. There've been some hick-ups inbetween, but a current version should work fine, if you've got a current version of lensfun (or: the lensfun database). In other words: I'm on the stable ubuntu packages and everything is fine for me.\nCould you give further details on what versions you are on et al.?\n(JFTR: I'm only a user that provided a few small patches, I'm not part of the dev team.)\n\u2014\nReply to this email directly or view it on GitHub.\n. OK, will consider it. \nDate: Tue, 20 Oct 2015 02:01:37 -0700\nFrom: notifications@github.com\nTo: darktable@noreply.github.com\nCC: baarlezander@hotmail.com\nSubject: Re: [darktable] Use Exif.OlympusEq.LensType for Olympus FT lenses (#449)\nYou can alway use a dual boot setup. There are many happy \"plain users\" of darktable. But, if you try that and need further assistance, I'd recommend the darktable users mailinglist.\n\u2014\nReply to this email directly or view it on GitHub.\n. Sure. Sorry. Done.\nI just also found out about \"./tools/beautify_style.sh\". I tried to execute it but it changed many files in addition to mine. Are we supposed to still use it? Thanks.\n. ",
    "jnfingerle": "@BertdeV Well, yes and no. There've been some hick-ups inbetween, but a current version should work fine, if you've got a current version of lensfun (or: the lensfun database). In other words: I'm on the stable ubuntu packages and everything is fine for me.\nCould you give further details on what versions you are on et al.?\n(JFTR: I'm only a user that provided a few small patches, I'm not part of the dev team.)\n. You can alway use a dual boot setup. There are many happy \"plain users\" of darktable. But, if you try that and need further assistance, I'd recommend the darktable users mailinglist.\n. @sgimenez I'm just a user, but this override-per-control seems over-engineered to me. It's more for the computer scientist minded than for normal users. But then, I'm not a darktable developer.\n. @LebedevRI So, as requested in #550 I'll try and review the code. I'll hopefully be able for a real review tomorrow night, but there's one thing I've already got: In his obsoleted comment @hanatos suggested an int instead of a gbool. You've changed it to a bool and still use TRUE and FALSE throughout the code. \nI see, how this is in a way the \"better\" way to do things, and in a completely new project I'd support this. But in the same struct there is another struct member used with boolean semantics, namely tca_override, that is declared as an int and used this \"Standard C\" an-int-for-a-bool constructs (set to 0 or 1 and directly use it as boolean value). From a maintainablity standpoint I think (read: believe very strongly) these two styles shouldn't be mixed, and since you're late to the party I'd suggest you conform to the already existing style. This is, in my opinion, more important than the better style of declaring a value-with-boolean-semantics as bool.  \nBut then, I don't know what the core developers think about it, maybe they disagree. If you stick to the bool, please do not write \"if(some_bool == FALSE)\" but \"if(!some_bool)\". This is more concise and exactly what a boolean is meant to be used for. This may not be true in languages like perl or php that, if you're not careful enough, will interpolate your dead great-grandmother into a boolean, but here it's better style; especially when looking around and keeping in style with the rest of the code.\nAgain, this was only my first comment; everything else looks good at first glance, but I will look in detail within the next 24 hours.\n. Sorry, I didn't want to tread on your toes. This was just something that I could say on first glance, on a machine without my build tools and without the time to really dig into the code. As I wrote before, I will give the code a real review shortly.\n. As requested by @boucman in the last comment on #550 I've done a review of this PR. My lengthy remarks on boolean as well as a handfull of line notes can be seen above. Additional comments:\nCode-wise I don't see a reason why it shouldn't work. \nRegarding functionality I would have liked, that changing modify_flags doesn't count as \"modification\", meaning everything else woulll still be autodetected. Just in case someone does only want part of the functionality for his style. But this would mean to copy many values wherever at the moment only the p pointer gets changed to the default parms. (On the other hand, it nothing that I need myself ;-) )\nThe legacy structs have beent moved to legacy_parms. This is inconsistent already (see basecurve.c vs. borders.c) and it seems cleaner this way. It irritated me in the diff, but when reading the whole file I like it. ;-)\nSo, that's everything that I wrote down reviewing, so, I'll start with the requested testing ...\n. So, ok, I've tried everything to make the change behave badly, but with what I've tried it seems to work (as was my expectation after looking at the code). I'll continue the next few days and test some more, but from my point of view it's ok to use for the wider public.\n. @sgimenez So, your use case would be handled with the current patch set, if modify_flags were retained through auto-detection and wouldn't count as user change?\n. @sgimenez \n\"[...] lacks EXIF data [...]\" => Ok, that's another use case (partly missing exif data). I can understand that.\n\"But be careful, if you withhold the actual state of parameters to users [...]\" => You're right with this general statement, but in this case the applied parameters are the ones shown to the user. The only possible confusion is when copying parameters (through copy&paste or styles), since the gui doesn't show beforehand if defaults will be used at the target, or if the parameters will be overwritten. But I think that this kind of confusion is more theoretical in nature.\n\"It seems you don't even want to consider the other approach. What's wrong?\" => I'm not part of the darktable dev team, so I can't speak for them. I'm only here, because I proposed a similar change to this one and was asked to come along and help. And as such I try and ask if there are ways to accomodate your needs within this change. From my experience in requirements engineering, for every proposed change my first question is \"what does it try to fix?\" (i. e.: what are the use cases?) Now we've established two use cases: Select individual modify_flags (set of correction types) and provide own defaults for missing exif data. The first one would be easily included in this change, the second may be reason to favour your approach. Having said all this: This is just my analysis and my private opinion. It's up to the darktable team to decide.\n. @LebedevRI from what I understand @sgimenez has two use cases:\nuse case 1:\n1. Enable Lens IOP.\n2. Click \"Reset parameters\"\n3. Change what corrections are to be done (e. g. vignettiing only)\n4. Create auto-appliable preset\n5. Change whatever you want in current image and any next images, that have this automatic preset applied.\nuse case 2:\n1. Enable Lens IOP.\n2. Click \"Reset parameters\"\n3. Change missing exif data to a more plausible default that works for this lens in more cases\n4. Create auto-appliable preset\n5. Change whatever you want in current image and any next images, that have this automatic preset applied.\nWhere presets may be replaced by styles or simple copy&paste.\n\nFocus distance is specific for any image, so you would anyhow have to set it for each\nimage manually.\n\nYes and no. Maybe you have found a different default, that's \"good enough\" for most cases. ~~Or you've got a series of shots from the same session where you know the focus distance hasn't changed, and you want to copy & paste.~~ [Edit: Strike the last sentence, the rest of the parameters shouldn't have changed either under those circumstances.]\n. I think @sgimenez has a point here. If darktable is supposed to implement his functionality within short time after this PR, it would be less confusing in the long run to not have an additional deprecated set of parameters. If, on the other hand, this isn't planned, this objection doesn't hold.\n. I thought a new struct member to be cleaner. Yet, if you want, I could retain the old dt_iop_lensfun_params_t v3 structure, rename tca_override to something like override and use it as a bit field (so far it has only values 0 or 1, so there is room). Then, again, this wouldn't make the code easier to read.\nRegarding testing: I've done some limited testing on my installation and will do more in days to come. Is there any resource with old styles / side car files that I can use to test with regards to dt_iop_lensfun_params_t v2 compatibility?\n. Regarding #548 - at a first look it seems to be quite related. I should have seen this earlier. :-( Anyway, I don't really care whose code may or may not end up in master, as long as this becomes a feature.\n. I got it to compile and re-did the testing. On my machine and in my settings everything works as expected. \n. From what I understand, this (using defaults instead of self->params) isn't needed at this point, at least I cannot figure out, what it's needed for. But even if it's unnecessary, it shouldn't be harmful, either.\n. Throughout the file p->modified is set before the call to dt_dev_add_history_item - I'd move this to camera_menu_select.\n. typo ... did not modify ... (+ later occurences)\n. From simple pattern matching (throughout the file modified is set together mit the history item) this looks like this should be inside the following if. If this is indeed the case, the same holds for  camera_menu_select.\n. I understand that, but I'd really do that. It's one well-known line vs. something new to grasp for someone who's new to the code. However, both versions are working.\n. ",
    "kriomant": "Yes.\n. ",
    "mazhe": "Sorry, I did not follow previous discussions about the options, this was more to fix a perceived \"bug\" where I saw an option which wasn't used. Please ignore the first one in that case.\n. I have the impression the best I could do was to add another commit to the pull request that reverts the changes relating to WebP usage, would that be ok?\n. Sorry, comment seems to have been lost: this is a re-submit of part of an earlier series of proposal. This fixes lua pkgconfig detection on the freebsd platform.\n. I've encountered the problem with FreeBSD (using the default makefile generator), but it would apply in any setting in which liblua is not in the default libdirs (/lib(64), /usr/lib(64)).\nWhen the module FindLua52.cmake looks for Lua, it calls pkg-config which returns something like \"-llua-5.2\" as LUA52_LIBRARIES (opposed to the likes of /usr/local/lib/liblua-5.2.so that find_library would return in cmake).\nSo when linking, the library, found at cmake configuration, won't be found when calling the linker because the absolute path was not informed. link_directories() is used to set the -L option to fix that (according to the information returned separately by pkg-config as LUA52_LIBRARIES_DIRS).\n(please note that this does not affect many packages systems that would enforce -L${packages_prefix}/lib as part of their defaults... but I wanted to build myself the git version of darktable in hope of finding a way to workaround problems arising in FreeBSD 10 when using gcc to have openmp support but the system is build against the new c++ runtime)\n. Sorry, I went under a lot of work and it seems that my answer in july went nowhere: I went the way of manualy specifiying LDFLAGS, and can continue to do so. You can close this report.\n. Ho, so the problem is that those pkg-config exists and are broken on darwin? I work only occasionaly on my mac and this was primarily tested on my FreeBSD desktop, in that case, would it be ok to rework them with conditionals like \"if (PKG_CONFIG_FOUND AND NOT CMAKE_SYSTEM_NAME STREQUAL \"Darwin\")\" ?\n. True, I booted my macbook and I will check that and come back with something better based on, like you said, https://github.com/darktable-org/darktable/commit/f8e89dcd5fd2a1d7247b004b37dfec58a84e8d09\n. Argh, not fast enough: there is no signifiiant difference I guess, it seems it was added to better handle previous versions of cmake and guessed it would be better to respect the developpers environment, but to be fair, I haven't seen cmake 2.4 installations since a while.\n. Maybe this is just overthinking, but maybe you'd want to include something like https://github.com/mazhe/darktable/commit/795a3461ba252e039c8dfad4855d9b80959dbe7b to be still able to run the script without installing?\n. Actualy, it break build on my system (FreeBSD 10.1, clang 3.3, GNU ld 2.17.50):\n\nLinking C executable darktable-cli\ncd /home/mazhe/Devel/graphics/darktable2/build/src/cli && /usr/local/bin/cmake -E cmake_link_script CMakeFiles/darktable-cli.dir/link.txt --verbose=1\n/usr/bin/cc   -std=c99 -Wall -fno-strict-aliasing -pthread -march=native -msse3 -g -Werror -Werror=type-limits -O2 -g -DNDEBUG -O2   CMakeFiles/darktable-cli.dir/main.c.o  -o darktable-cli  ../libdarktable.so ../external/rawspeed/librawspeed.a ../external/LuaAutoC/liblautoc.a /usr/local/lib/libgtk-3.so /usr/local/lib/libgdk-3.so /usr/local/lib/libpango-1.0.so /usr/local/lib/libcairo.so /usr/local/lib/libgdk_pixbuf-2.0.so /usr/local/lib/libatk-1.0.so /usr/local/lib/libxml2.so /usr/local/lib/libIlmImf.so /usr/local/lib/libImath.so /usr/local/lib/libIex.so /usr/local/lib/libIlmThread.so /usr/local/lib/liblensfun.so /usr/local/lib/libgio-2.0.so /usr/local/lib/libglib-2.0.so /usr/local/lib/libgthread-2.0.so /usr/local/lib/libgmodule-2.0.so /usr/local/lib/libpangocairo-1.0.so -lpthread /usr/local/lib/librsvg-2.so /usr/local/lib/libsqlite3.so /usr/local/lib/libexiv2.so /usr/local/lib/libcurl.so /usr/local/lib/libpng.so -lz /usr/local/lib/libjpeg.so /usr/local/lib/libtiff.so /usr/local/lib/liblcms2.so /usr/local/lib/libjson-glib-1.0.so /usr/local/lib/libopenjpeg.so -L/usr/local/lib -llua-5.2 -lm /usr/local/lib/libcups.so -Wl,-rpath,/home/mazhe/Devel/graphics/darktable2/build/src:/usr/local/lib: \n/usr/bin/ld: /usr/local/lib/libintl.so.8: invalid DSO for symbol `libintl_bindtextdomain' definition\n/usr/local/lib/libintl.so.8: could not read symbols: Bad value\ncc: error: linker command failed with exit code 1 (use -v to see invocation)\n\nI understand this is kinda a GNU ld \"feature\" that requires explicit linking against all dependencies, including those coming from other shared libraries (this was the bug that prompted me to rewrite the FindGettext module in the first place)...\nI guess I could use something like -DCMAKE_C_STANDARD_LIBRARIES=\"/usr/local/lib/libintl.so\" at cmake invocation, which is quite annoying with since I always have to then re-find it the next time I have to wipe and rebase my workdir against upstream...\n. Ok, this one is kinda weird, but not new : it seems there were already traces of a freebsd-specific libintl linking in src/cli/CMakeLists.txt... Except it was supposely confined to gcc < 4.3 (I have not been able to build darktable with gcc/g++ since freebsd switched to libc++).\nIf you have any idea, I could test them, but the dirty workaround would be to link regardless on the compiler on the *BSD platforms, would not it? (despite working without that two weeks ago).\n. Sorry for bringing my obscure platform problems, I never noticed gettext functions were inside the glibc before.\nI've updated the pull request taking account that.\n. Sorry for the delay, I had to review the issue and the changes over last year.\nSeems OK on the platforms I manage daily (FreeBSD/OSX): pkgconfig for the former, cmake find_library for the latter. I am closing the issue, thanks for your hard work!\n. In fact, I closed the request (silently) to take time to understand a few issues (I was getting black images from PEF format, DNG was fine).\nI'll send two samples to rawsamples.ch indeed, that could be helpful.\nI still have noise profiles ready, that I did not found to be faulty in my everyday usage, but I did not formally test every iso setting yet...\n. Ok, I have cleared up my issue with black PEF : it seems to be a regression in rawspeed when build with clang 3.8 and -O3, not something coming from this patchset. I'll investigate this later.\nSamples were sent to  rawsamples.ch (both PEF and DNG).\nI still have to extract whitebalance presets and check the noiseprofiles.\n. Thanks for the info about the race condition, I'll check that a bit later.\nI'll do the sample picture when I'm back home (the crop was obtained from information in the DNG if I remember, and set because there was garbage lines at the begining of the PEF pictures).\n. Here are the samples, PEF & DNG:\n- http://dl.free.fr/iommjlg1L\n- http://dl.free.fr/im9v4GQA8\n. gdrive should serve you better:\n- https://drive.google.com/open?id=0B0J6-mibfIUEVjdjMXZuZnhZUTQ\n- https://drive.google.com/open?id=0B0J6-mibfIUEZlBSZ1kzSFlvNEk\n. Yes, I can and will do ASAP (tried from my appartment, but view is a bit trouble and light is changing too much due to cloud moving in and out).\nI'll also put some 1:1 crop raw for good measure.\n(I'm also working on providing better noise profiles, but high ISOs are really hard to calibrate... I've been working on smoothing the data with interpolation with good results in my eye...). Sorry, I was a bit overwhelmed by events last weeks (moving to another town, new job), I'll get back on this ASAP. Ok, sorry for the delay, but at least a bright and nice day. I took PEF/DNG with all FF/APSC and PS variations.\nThere are already entries for the K1, but not all variations, should I fill or overwrite all images?. Ok, https://github.com/darktable-org/darktable/pull/1255/commits/ecbd879f18ffd5fb484df5952cc7740dd5ec310f looks good, but a review would not be bad considering it touches sensitive stuff :)\nI've tested it with my own images without any issue, and removing the test in the jpeg exporter, it give a nice \"[exiv2] /home/mazhe/tmp/foo_02.jpg: Size of Exif JPEG segment is larger than 65535 bytes\" message with the images that reaches the limit.\n. I also ensured the blob pointer would be initialized to NULL in case there's nothing to read.\n. I thought that too for the catch() part, it's not necessary, but may be more safe and readable.\n. Ok, looks better now.\n. Yes, this does not solve the issue, more exif tags should be filtered, but it allows to detect it in a cleaner way!\nThanks for having to patience to review and fix this pull request!\n. Addendum: this should fix issue #11130 (https://redmine.darktable.org/issues/11130) and some other \"exif missing\" issues.\n. There, I merged the tags in the list of tags to be removed, no need to create two lists and call the remove function two times, right?\n. You are right, I was working on the assumption that the findKey would fail more gracefully in case of error. \n. Speaking of soft error management, I wonder if it's necessary to keep displaying an error message when we use a non-existant (for now) tagname. This may be a bit misleading in the text output and a bit spammy when, for example, using darktable-cli in a loop...\n. It's removed, sorry: took a bit of time, I wanted to see if I could test a bit more the exception, but is only a Exiv2::BasicError exception, and the only information we could use to be sure it's an unkown tag is the code error \"7\", which seemed a bit weak to test against...\n. Done, out of curiosity, is the static necessary? I'm not sure I see the purpose of static'ing this one (it's neither in a loop, nor the has to be reused in another call...)\n. (This should fix https://redmine.darktable.org/issues/11133)\n. It seems this is not necessary because it's done in the CMakeList.txt file in src... but that could not hurt maybe?\n. Not a problem at all, when I'm on my macbook, I also tend to use the best available llvm package from macports (if only to get openmp support). There however an issue with another osx specific function (the one that retrieve the version), but I need to test my fix a bit more.\n. Ok, here is my case, so I have to run g++ with (llvm) c++ runtime to link against the rest of my dependencies that are also linked against it, basicly, I have to set CXXFLAGS and C++ library by hand:\n```\nCC=gcc6\nCXX=g++6\nINCLUDES=\nCFLAGS=\nCXXFLAGS=\"-nostdinc++ -I/usr/include/c++/v1\"\nLINKER_FLAGS=\"-Wl,-rpath,/usr/local/lib/gcc6 -lc++ -lm -lc -lgcc_s -lgcc\"\ncmake \\\n    -DCMAKE_REQUIRED_INCLUDES=\"$INCLUDES\" -DCMAKE_REQUIRED_LIBRARIES=\"$LINKER_FLAGS\" \\\n    -DCMAKE_C_COMPILER=\"$CC\" -DCMAKE_C_FLAGS=\"$CFLAGS\" -DCMAKE_CXX_COMPILER=\"$CXX\" -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DCMAKE_EXE_LINKER_FLAGS=\"$LINKER_FLAGS\" -DCMAKE_MODULE_LINKER_FLAGS=\"$LINKER_FLAGS\" -DCMAKE_SHARED_LINKER_FLAGS=\"$LINKER_FLAGS\" \\\n    [...]   ..\n```\nThis gives me the following cmake output:\n```\n-- The CXX compiler identification is GNU 6.2.0\n-- The C compiler identification is GNU 6.2.0\n-- Check for working CXX compiler: /usr/local/bin/g++6\n-- Check for working CXX compiler: /usr/local/bin/g++6 -- works\n-- Detecting CXX compiler ABI info\n-- Detecting CXX compiler ABI info - done\n-- Detecting CXX compile features\n-- Detecting CXX compile features - done\n-- Check for working C compiler: /usr/local/bin/gcc6\n-- Check for working C compiler: /usr/local/bin/gcc6 -- works\n-- Detecting C compiler ABI info\n-- Detecting C compiler ABI info - done\n-- Detecting C compile features\n-- Detecting C compile features - done\n-- Performing Test MSSE2\n-- Performing Test _MSSE2 - Success\n-- Building SSE2-optimized codepaths: ON\n-- Check if the system is big endian\n-- Searching 16 bit integer\n-- Looking for sys/types.h\n-- Looking for sys/types.h - found\n-- Looking for stdint.h\n-- Looking for stdint.h - found\n-- Looking for stddef.h\n-- Looking for stddef.h - found\n-- Check size of unsigned short\n-- Check size of unsigned short - done\n-- Using unsigned short\n-- Check if the system is big endian - little endian\n-- Found little endian system. Good.\n-- Performing Test IS_SUPPORTED_PLATFORM\n-- Performing Test IS_SUPPORTED_PLATFORM - Success\n-- Is the target platform supported: 1\n-- Performing Test C_COMPILER_UNDERSTANDS-Wall\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wall - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wall\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wall - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-fno-strict-aliasing\n-- Performing Test C_COMPILER_UNDERSTANDS_-fno-strict-aliasing - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-fno-strict-aliasing\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-fno-strict-aliasing - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wformat\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wformat - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wformat\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wformat - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wformat-security\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wformat-security - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wformat-security\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wformat-security - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wshadow\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wshadow - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wshadow\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wshadow - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wtype-limits\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wtype-limits - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wtype-limits\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wtype-limits - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wvla\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wvla - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wvla\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wvla - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wold-style-declaration\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wold-style-declaration - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wold-style-declaration\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wold-style-declaration - Failed\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wno-error=varargs\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wno-error=varargs - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wno-error=varargs\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wno-error=varargs - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wno-error=address-of-packed-member\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wno-error=address-of-packed-member - Failed\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wno-error=address-of-packed-member\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wno-error=address-of-packed-member - Failed\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wframe-larger-than=32768\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wframe-larger-than=32768 - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wframe-larger-than=32768\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wframe-larger-than=32768 - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wstack-usage=32768\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wstack-usage=32768 - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wstack-usage=32768\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wstack-usage=32768 - Success\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wlarger-than=1048576\n-- Performing Test C_COMPILER_UNDERSTANDS_-Wlarger-than=1048576 - Success\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wlarger-than=1048576\n-- Performing Test CXX_COMPILER_UNDERSTANDS_-Wlarger-than=1048576 - Success\n-- Looking for external programs\n-- Found perl\n-- Found intltool-merge\n-- Found desktop-file-validate\n-- Missing appstream-util, problems in darktable.appdata.xml might go unnoticed\n-- Missing jsonschema, problems in noiseprofiles.json might go unnoticed\n-- Found xsltproc\n-- Found xmllint\n-- All external programs found\n-- Performing Test COMPILER_SUPPORTS_C99\n-- Performing Test COMPILER_SUPPORTS_C99 - Failed\nCMake Error at src/CMakeLists.txt:122 (message):\n  The compiler /usr/local/bin/gcc6 has no C99 support.  Please use a\n  different C compiler.\n-- Configuring incomplete, errors occurred!\nSee also \"/home/mazhe/Devel/graphics/darktable/build/CMakeFiles/CMakeOutput.log\".\nSee also \"/home/mazhe/Devel/graphics/darktable/build/CMakeFiles/CMakeError.log\".\n```\nAnd here's the end of CMakeError.log:\n```\nPerforming C SOURCE FILE Test COMPILER_SUPPORTS_C99 failed with the following output:\nChange Dir: /home/mazhe/Devel/graphics/darktable/build/CMakeFiles/CMakeTmp\nRun Build Command:\"/usr/bin/make\" \"cmTC_f31d6/fast\"\n/usr/bin/make -f CMakeFiles/cmTC_f31d6.dir/build.make CMakeFiles/cmTC_f31d6.dir/build\nBuilding C object CMakeFiles/cmTC_f31d6.dir/src.c.o\n/usr/local/bin/gcc6    -Wall -fno-strict-aliasing -Wformat -Wformat-security -Wshadow -Wtype-limits -Wvla -Wold-style-declaration -Wno-error=varargs -Wframe-larger-than=32768 -Wstack-usage=32768 -Wlarger-than=1048576 -DCOMPILER_SUPPORTS_C99 -nostdinc++ -I/usr/include/c++/v1 -Wall -fno-strict-aliasing -Wformat -Wformat-security -Wshadow -Wtype-limits -Wvla -Wno-error=varargs -Wframe-larger-than=32768 -Wstack-usage=32768   -std=c99 -o CMakeFiles/cmTC_f31d6.dir/src.c.o   -c /home/mazhe/Devel/graphics/darktable/build/CMakeFiles/CMakeTmp/src.c\ncc1: warning: command line option '-nostdinc++' is valid for C++/ObjC++ but not for C\nLinking C executable cmTC_f31d6\n/usr/local/bin/cmake -E cmake_link_script CMakeFiles/cmTC_f31d6.dir/link.txt --verbose=1\n/usr/local/bin/gcc6   -Wall -fno-strict-aliasing -Wformat -Wformat-security -Wshadow -Wtype-limits -Wvla -Wold-style-declaration -Wno-error=varargs -Wframe-larger-than=32768 -Wstack-usage=32768 -Wlarger-than=1048576 -DCOMPILER_SUPPORTS_C99 -nostdinc++ -I/usr/include/c++/v1 -Wall -fno-strict-aliasing -Wformat -Wformat-security -Wshadow -Wtype-limits -Wvla -Wno-error=varargs -Wframe-larger-than=32768 -Wstack-usage=32768    CMakeFiles/cmTC_f31d6.dir/src.c.o  -o cmTC_f31d6  -Wl,-rpath,/usr/local/lib/gcc6 -lc++ -lm -lc -lgcc_s -lgcc\nSource file was:\nint main(void) { return 0; }\n```\nSo this fails at CHECK_C_COMPILER_FLAG(\"-std=c99\" COMPILER_SUPPORTS_C99) in src/CMakeLists.txt because cc1: warning: command line option '-nostdinc++' is valid for C++/ObjC++ but not for C. \nThis is because a previous call to CHECK_COMPILER_FLAG_AND_ENABLE_IT() set CMAKE_REQUIRED_FLAGS from CMAKE_CXX_FLAGS, and CHECK_C_COMPILER_FLAG that is called afterwards inherit it.\nHope it helps clarify? The use case is not very friendly, but basically, it may happen each time a C++ only flag is set in CMAKE_CXX_FLAGS\n. In the toplevel CMakeLists.txt (line 256), there's an include to compiler-warnings.cmake which use a darktable CHECK_COMPILER_FLAG_AND_ENABLE_IT() macro. The sub-macro it uses leave the CMAKE_REQUIRED_FLAGS either set to CMAKE_C_FLAGS or CMAKE_CXX_FLAGS.\nLater, in src/CMakeList.txt (line 120), the cmake provided CHECK_C_COMPILER_FLAG() macro is used to test if the C compiler supports -std=c99 argument. This macro inherits CMAKE_REQUIRED_FLAGS from the previous CHECK_COMPILER_FLAG_AND_ENABLE_IT().\nAnother solution would be to reset this variable before testing if the C/CXX compilers accept -std=c99/c++11...\nPS. A very simple, albeit aimless, test would be to use -DCMAKE_CXX_FLAGS=\"-std=c++14\" in a cmake call to easily reproduce the problem\nPPS. cmake version is 3.6.2\n. Should I try to deprecate the internal FindPthread.cmake module in that case? I'll have a look at the functionality it provides over CMake's FindThreads. It was done like that before. Initialy I thought it would make sense to keep the test, but then, I found some case (working on jpegs and exporting them) where darktable lenght test would be OK when exiv2 internal one would not, so this is indeed superfluous.\nDo you want me to make a pull request to track the issue?\n. I'm having a look at this issue (since I feel responsible), but it seems that there's something wrong at the level of the data itself: the loop over tags ( src/common/exif.cc:1081) do not even do a single iteration.\nThere's an exception apprently, which I don't have on my own Pentax files:\n[exiv2] /home/mazhe/tmp/foo.jpg: This does not look like a TIFF image\n. In that case, maybe we could let the data blob be set regardless of size and wait for failure at write? The issue here is that it's quite hard to track absence of exif data since it's rejected in a read function...\n. Probably because the destination buffer is allocated from outside this function and received as an argument... I did not track this allocation yet, but maybe the function could allocate the buffer as needed?\n. Actually, it's a static array. Maybe this could be allocated with more space, as darktable will not inflate the array by too much, or switch to malloc'ed arrays...\n. Okay, I'll update my request!\n. Indeed!\n. I was thinking that maybe it would be useful to have access to this information if somebody wanted to implement using curves provided in the raw files?\nPS. size before write is not an issue as exiv2 is more than able to manage data >= 65kB (which is actually a jpeg format limitation)\n. Agreed, I can do another fix for this. What would be the prefered approach: adding a new \"dng_mode\" argument to the function like for read, or determining the output format from the initial exif/metadata retrieved from the image?\n. would not these information be useful to read hdr DNG files? (I was planning to test those at some point, when my camera gets back from service)\n. Oh, now I understand, thanks!\n. While rewriting the code, I thought it would even be better to use memchr() to ensure the result is really a string and then use sscanf() to validate the string syntax (ie if it's not X.Y.Z, there must be something fishy).\nWhat do you think of this?\nc\nif (memchr(str, '\\0', strsize) != NULL) {\n  int major, minor, patch;\n  if (sscanf(str, \"%d.%d.%d\", &major, &minor, &patch) == 3) {\n    ver = 0x1000 + major*10;\n  }\n}\n. Hmm, okay, I guess I should extend the test around the -pthread addition to c(xx)flags rather than use this module (also, I did not see that there was an internal module to detect it).\nThanks, I'll retract this PR.. Ho, you were meaning to drop part of the code, not the whole pull request. Yes, this should be improvable, I'll arrange things to be more in line with what is done in rawspeed.. Sadly, this is a bit necessary: we either can get a compiler flag or a library, and travis catched a few errors due to that. I'll try a bit to find a better way to manage this.. Ok, removed this one, it just tell cmake to prefer using the -pthread flag over \"simply\" linking with a thread library (libpthreads).. Yeah, I'm not sure on how to improve things: there's a non-documented CMAKE_HAVE_THREADS_LIBRARY variable that would be better than comparing CMAKE_THREAD_LIBS_INIT... but since it's not exposed in doc.... Indeed, I was quite sure that (strangely) the default variable scope was global, given the behavior of Find* modules, but the doc indeed states that it's the current directory/macro.. Ha! it seems I was confused by errors reported by travis, and that adding -pthread to LIBS is well managed by cmake (the issue was that darktable-rs-identify must be explicitely linked with thread library/flag as it does not use LIBS).\nSo this ugly test is now removed, and travis seems happy with the regular branch, and a test branch that use the cmake 3.1 option to use the flag to also test this case (https://travis-ci.org/mazhe/darktable/builds/186924244). My FreeBSD system is also happy with this code, the only configuration I cannot test is win64.. Damnit, you're right! How did this even compiled? Must have been shadowed by the latter use of glib's threading libraries.. Wow, not my best day. End of year festivities must be taking their toll :/. If you'd like, I could overwrite branch as a single commit not to pollute the project history with such commits.. Exactly, even if the output should be identical for simple concatenation, I'd rather not change the tool for those who are used to have pdftk. ",
    "roggan87": "Thanks for the feedback!\nYes those things mentioned (user manual, keyword module etc.) were in some way included in the commit when I tried to rebase. I'm no git guru, so I wasn't sure how to not include that. This feature shouldn't modify that.\nHowever, at the moment I haven't got the time or motivation to keep working on this, and the server side platform is probably not ready enough for going public.\nIf anybody else want to pick up the work on this branch, please go ahead...\n. ",
    "michleb": "D\u00e9sol\u00e9 de t'importuner mais est-ce que mes modifications ont \u00e9t\u00e9 prises en\ncompte ? Je dois avouer que je m'y perd un peu !\nJ'ai \"commit\u00e9\" sur le* master* dans mon fork.\n2014-03-04 8:54 GMT+01:00 Victor Lamoine notifications@github.com:\n\nThese are corrections from the file in the usermanual branch. After\ndiscussions we decided to use this translation as a basis. It is the most\ncomplete and best translation at the moment.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/485#issuecomment-36599807\n.\n\n\nMichel Leblond\ncourriel : michel.leblond62@gmail.com\n. @boucman En fait mon message s'adressait \u00e0 @VictorLamoine et Jean-Luc Coulon. Je d\u00e9bute avec GitHub et je cafouille quelque peu. J'ai \"commit\u00e9\" dans la branche master de mon fork michleb/darktable et non dans la branche usermanual.  Je pense avoir r\u00e9par\u00e9 mon erreur.\nNous allons discuter Victor, Jean-Luc et moi. Puis nous \"mergerons\".\n. Thank you houz\n. Thank you simonspa  and boucman\n. Faut-il refaire la pull request ?\n2014-10-25 13:44 GMT+02:00 Victor Lamoine notifications@github.com:\n\nFixed [image: :wink:]\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/714#issuecomment-60480071\n.\n\n\nMichel Leblond\ncourriel : michel.leblond62@gmail.com\n. @simonspa It was a great pleasure to contribute to the French translation of the user manual for that open source software ! I will continue this contribution.\n. I attempted to introduce French screenshots of the French version of the GUI in the usermanual.\nI added _en.png, _fr.png in the right places.\nThen I chose to come back to the official master repository of darktable. I deleted all these files and replaced them with .png from darktable master.\nI can say that only \"darktable-usermanual.pot\" and \"fr.po\" are modified.\nI apologize to not have used a branch.\n. I agree simonspa !\n. Many thanks Ulrich !\n. I introduced myself .xcf in the file .gitignore and I delete it now.\n. Thank you Ulrich.\n. Thank you Ulrich.\n. Thanks a lot @TurboGit !\n. Many thanks @upegelow  !\n. Many thanks @upegelow \n. Many thanks @upegelow \n. Many thanks @upegelow \n. Thanks @upegelow \n. Thanks @upegelow \n. Thank you @upegelow \n. Thank you @upegelow \n. I updated the French translation of the user manual taking into account commit 80ac7f3\n. I added screenshots of different views of darktable related to version 2.0.\nI also updated the usermanual (English version) taking into account a mail from Colin Adams.\n. I took into account the remarks of @upegelow \n. ",
    "digitalmole": "Hi Pascal,\nThanks for testing. Admittedly it's not a huge difference, pixelpeeping is\na must. However on occasion it is sufficient to be able to select it. How\ndid you test it? For my camera I get better results at 3200 iso and 6400\niso above. I can send some image crops if you want. I also find that igv\ngives me a finer grained output, more pleasing in some way to me when\nprinter larger. Otherwise I have create some shots if you want some raw's.\nBest examples are from my toddler at 6400 iso peeping from behind a tree\nnot really an image to share. Sharable pictures are usually are taken at\n'good' light.\nBest,\nGert\nOn Sat, Mar 15, 2014 at 11:56 AM, Pascal Obry notifications@github.comwrote:\n\nLe vendredi 14 mars 2014 \u00e0 16:24 -0700, Gert van der Plas a \u00e9crit :\n\nI've added igv demosiac from rawtherapee to darktable. It out performs\nat high noise levels amaze and ppg. Yielding better resolution on the\nSony NEX-C3 and other cameras. At low noise levels zipper-artifacts\nmay occur. I've added an hidden example demosaic code called stagger\nbut which is invisible from the gui.\nAt some point it will be replaced by better code.\n\nI've tested it but found no difference between this algo and the\ncurrently support Amaze. Switching from Amaze to IGV give me the very\nsame image, at least close enough to not see any change on screen.\n\nPascal Obry / Magny Les Hameaux (78)\nThe best way to travel is by means of imagination\nhttp://v2p.fr.eu.org\nhttp://www.obry.net\ngpg --keyserver keys.gnupg.net --recv-key F949BD3B\n\nReply to this email directly or view it on GitHubhttps://github.com/darktable-org/darktable/pull/494#issuecomment-37722916\n.\n\n\nPanta Rhei -- Life is a dance\n. Hi,\nI already shared some example files through the mailing-lists. If there is\na online gallery for darktable where I can upload my examples that would be\nnice ;-)\nI'd also like to point out that though igv gives better performance at\n3200+ iso for my camera. However AMaZE works better at 3200 iso for a D700.\nI seriously doubt if one demosaic algorithm suits all camera sensors, noise\ntypes and images best. Having several with different basic principles seems\nwise.\n\nWe already have this problem with AMaZE, which isn't that much better\nthan PPG, is silly slow due to lack of SSE/OpenMP optimization IIRC, and\nisn't being maintained (no code resyncs with RawTherapee, since the\noriginal contributor/porter isn't around anymore).\n\nCurrent daktable AMaZE has actually OpenMP support,  though the current\nRawTherapee version has also SSE support.  IGV also has OpenMP support.\nWith the exception of SSE code in RT that's not in DT the code seems up to\ndate enough. And for now that's it.\n\nHave SSE and OpenMP optimization\n\nFor now you got 50% of that and it work fast enough on a 4 years old laptop.\nPPG: [dev_pixelpipe] took 0,584 secs (0,428 CPU) processing `demosaic'\n[export]\nAMAZE: [dev_pixelpipe] took 1,848 secs (11,616 CPU) processing\nIGV: [dev_pixelpipe] took 0,763 secs (0,403 CPU) processing `demosaic'\n[export]\nNo clue what the number actually mean. But IGV is pretty fast. And processors\nget faster not slower. Nor do I think speed shoud the end all\n\nCome with a contributors/porters agreement to stick around and maintain\nthe code for the foreseeable future.\n\nI think you are better served with proper code sufficiently documentedso\nanyone can take over and maintain, because good intentions don't last. And\ncode that works, works.\nIf anyone thinks there is a better high noise, high iso demosaic which is\nbetter. Let me know ;-)\nCheers\n. Thanks for the feedback and resubmit in time. I'll  close this pull-request and perhaps we can discuss high noise demosaic algorithms in the devel-list?\n. I wanted a better high noise solution for precious family pictures and supported current algos were not enough for me. I've been running dt sinds two+ years now under Ubuntu and Unix/Linux sinds the 90's and Windows is used mostly for required firmware updates. \nHence it was a simple choice to extend dt for my own purposes, as wel as wanting to share the work afterwards. Still, it will be while before I can commit spare time for others needs on a regular base. Any case, the port is here, test it and tell me if should send another pull request at all. It takes time to do that. I think I can code it that my private demosiac algos don't not clash with your future releases. It's easy enough to branch my own version and fix minor issues  ;-).\n. When time allows to invest more time into the Darktable project I will have another go at it. \n. ",
    "pedrocr": "It has to invalidate the cache yes. As for recreating the cache in bulk my hack to darktable-cli for cache testing could be polished up for that, but the user would need to run it from a terminal. Alternatively there could be a GUI option somewhere to do that.\nNote that with current cache design if your collection doesn't all fit in memory cache you're already recreating the cache for images that have been dropped and that running through the whole collection recreating thumbnails generates a lot of useless work.\n. I suppose you could just lookup what's in cache right now and recreate those. Maybe that's what you meant. That makes more sense as this patch would make the cache have the same or more slots at the same level.\n. I was there but this is a good place to leave notes:\n1. Having a fixed value doesn't make sense but having a config option would\n2. The config option should default to the current behavior (the same size set for the thumbnail size in the existing config)\n3. It could make sense to make other fine-grained settings configurable (different mip sizes, memory space for each mip size, etc)\nOn 3 it would seem to me that it would make more sense to auto-set these based on usage. It's much harder for the user to optimize this. And if you want to be really clever you could have more MIP sizes and auto-adjust their relative cache sizes so you don't actually need this setting at all. You'd just set the current settings and darktable would figure out which actual thumbnail sizes are used and spend the cache space on those.\n. It should be harmless. Unless there's a bug I'm not seeing it just means something was removed from cache before it had hit disk at any point. It should happen pretty frequently after editing a picture in darkroom that was just viewed in lighttable for the first time, invalidating the thumbnail. I'll have to silence the warning or better yet only run the unlink when the file exists, that way actual file removal errors are not silenced.\n. Ok, just pushed a commit to fix this.\n. This is missing a couple of improvements before merging:\n- Checking to see if there's free space on disk before writing so as to not cause disk full problems\n- Adding a config option to disable it\n. I've fixed the blackpoint problems by using BlackAreas in cameras.xml\n. Thanks for this @LebedevRI. Just for documentation there's also an issue of the darkroom view having poor quality. The exports are fine though. The darkroom view poor quality seems consistent with half-size demosaic, probably done by the mipmap cache.\n. I'm not sure this is a complete fix. I've seen at least rotatepixels fail to get new settings with a slightly older version of the patch. It may even be that this just changed the timing on my system enough for a different branch to win the race and didn't actually change anything?\n. Yeah, this isn't a fix, I can now reproduce the issue reliably by deleting the xmp files before starting darktable. If I do that the issue happens every time.\n. Turns out the original fix only applied to the little preview image on top left of the darkroom. This is the same fix for the full pipe.\n. According to the discussion on IRC this should be pretty ready to merge in its current form. I've moved the dt_image_t reloading and reload_defaults calling into dt_dev_pixelpipe_set_input, hiding that away from the calling code. After this two cleanups can be done:\n- Removing unneeded calls to reload_defaults: I wasn't quite sure which were now redundant so I didn't touch them\n- Removing the fields from the images table that are no longer needed. I assume raw_parameters, color_matrix, colorspace, raw_black and raw_maximum can be removed. I guess crop and orientation could be removed as well. And I assume width and height can't be removed because we use them in other contexts?\n. As discussed on IRC I've added locking and a new field to develop_t to make sure we only run update_defaults once. I've also looked around the code and eliminated unneeded calls to reload_defaults and gui_update. For export gui_update is not run at all of course and reload_defaults runs only once (yay). In the darkroom reload_defaults and gui_update run twice. That's hard to change because gui_update needs to run before the image is loaded and some modules don't like it when we run gui_update without reload_defaults having been ran.\nI also looked at the colorin bug. It should be fixed now, as the second run of reload_defaults and gui_update should setup everything correctly. There's still a spurious warning because of the order in which they are run. Adding some printfs to colorin.c I get:\n```\nI started darktable and opened a D1x NEF\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\nI pressed space to move to a darktable JPG export of the same NEF\n4 Running gui_update for colorin\n3 Running reload_defaults for colorin\n4 Running reload_defaults for colorin\n4 Running gui_update for colorin\nI pressed backspace to go back to the NEF\n3 Running gui_update for colorin\n[colorin] could not find requested profile `eprofile'!\n4 Running reload_defaults for colorin\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\n```\nThat warning is happening because we run gui_update before reload_defaults on the second run through. It should be harmless now as the second run through should fix everything up. It's not clear to me how to fix the order though. I think gui_update is called on expose() and reload_defaults on dt_dev_change_image(), both in darkroom.c.\n. The broken ordering is now gone:\n```\nI started darktable and opened a D1x NEF\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\nI pressed space to move to a darktable JPG export of the same NEF\n4 Running reload_defaults for colorin\n4 Running gui_update for colorin\n3 Running reload_defaults for colorin\n4 Running reload_defaults for colorin\n4 Running gui_update for colorin\nI pressed backspace to go back to the NEF\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\n4 Running reload_defaults for colorin\n3 Running reload_defaults for colorin\n3 Running gui_update for colorin\n```\nThis fixes the colorin strange message. However when switching images reload_defaults is being ran an extra time with the wrong image (3 is the NEF, 4 is the JPG). I'm not sure why that is happening.\n. Rebased and retested against current master. Everything looks to be the same.\n. The apparently extra reload_defaults seems to be another develop_t used to update the filmstrip of the previous image. So right now we should be solid in terms of reload_defaults/gui_update. For 1.6 we could perhaps special case temperature.c so it doesn't open the raw file twice. When we land rawspeed whitebalance handling that issue will just go away.\n. Not sure what's happening with this PR but it's showing a bunch of already in master commits before your last two. You should probably do your work in new branches and keep your master branch identical to darktable master.\n. Are you sure the uncompressed modes are not valid on the 750? These newer Nikon fullframes seem to have a bunch of pointless raw modes that are a mix of bit depth, compressed/uncompressed and APS crop. Here's the list for the D4s:\nhttp://updates.rawdigger.com/data/D4s/D4s_Modes.txt\nIf you could figure out in the settings if those modes also exist in the 750 and submit example files for all modes to rawsamples that would be awesome.\n. Development continues in the cache2 branch:\nhttps://github.com/darktable-org/darktable/tree/cache2\n. Do you have an example file? We also need the color matrix to get the basic camera support.\n. Thanks for the examples the camera does seem to be the same as the 3000. I've added the matrix settings so it should work now. 1.6.2 when it comes out should have this as well.\nIf you want to add more support you could shoot one raw image for each of the white balance presets (cloudy, sunny, etc) so that we can provide the same presets the camera has in darktable.\n. The current setup, both of collect and of preset application is very closely linked with the underlying database. A potential other way of doing it would be to have a search language like gmail does where you can more easily specify AND/OR and precedence (use parentheses). Then the GUI would either be similar to what we have now but allow an expert mode where editing the search string is possible or just do as gmail and have the search string be the main interface. To implement this properly we'd probably need a proper parser->AST->SQLgeneration path.\n. I haven't tested it yet but from your description you keep the window around the image. It would make more sense if Z (both here and in the lighttable) would do an actual fullscreen image with no application around it.\n. Agree on both counts. I meant fullscreen as in \"fill in all the dt window currently enabled\" and the behavior should change in both places so right now what you are doing is consistent.\n. I agree with dropping if we have to do this. As discussed on IRC asking the user to input his facebook user/password into a window we control is completely broken when it comes to security.\nWhat was discussed on IRC was that we could do something nicer by doing the redirect to http://localhost:$SOMEPORT and use that page to capture the data we need and tell the user \"This is all done please close this tab and go back to dt\". This would require us to add a HTTP endpoint to dt which is just a few lines of libsoup (which apparently we already depend on).\n. @houz was interested in looking into the localhost redirect method, don't know if he actually tried it though...\n. To summarize the IRC discussion on this here's what we have rough consensus on:\n- The user-supplied matrices are probably better than the standard ones in several cases and in at least some cases are broken, in general we don't know which are which\n- The standard ones are probably more consistent and unlikely to be broken yet they're probably suboptimal in some cases (e.g., less saturated)\nGiven this I'd say the standard should be the default so we have reasonable results by default and give the user the option to try out the other options.\n. There's another issue with defaulting to the user supplied matrices. Because we don't always have one between darktable versions the default can change. So users may be used to the output with the standard matrix, upgrade to a newer version of darktable with a user supplied matrix and find that their new images now look different than the older ones without any warning. That seems quite user-unfriendly.\n. > Exactly the same thing happens if one used ICC within colorin/colorout, and then that ICC is gone - no message that it is gone, matrix is silently used.\nWe don't ship ICC profiles but we do ship standard matrices and sometimes user submitted ones. By starting with just a standard matrix and later adding a user submitted one we change the default without warning the user. We don't do the same with ICC profiles since users have to actively enable those.\n. > That is the problem, IMHO we maybe should refuse to load that image, like when history stack item is newer than the iop version.\nI think you're thinking about the opposite situation (removing a user supplied matrix). I agree we could refuse to load the image in that case. But that's not what I'm describing.\n\nTell me, how is that different from what happens with matrices?\n\nIt's precisely the opposite. In that case you used to have the ICC profile and now don't. In the case I'm describing the standard matrix is always there, you've just silently changed the default for new images without the user noticing.\n. This is replaced by #899 \n. This code doesn't seem too easy to follow and has unfixed bugs:\nhttp://redmine.darktable.org/issues/10602\nI think there's some room for refactoring and even redesign of the feature instead of piling on more stuff.\n. That's not the bug, the bug is that the warning should never be about the local copy but the original. If the original exists there's no issue and if the original and the copy don't exist the problem should be the original not existing. Caches should be deletable with no issues. The bug is minor it just made me look at the code a little time ago.\n. @TurboGit I haven't looked at this code so if it fixes that issue as well all the better.\n. I want to merge this as soon as possible. The partial matching stuff can be made to not regress with this code if we really think that's needed, there's no reason to wait for other stuff.\n. :) I love it that now that we found the potential for error we are so hung up on never breaking history stacks. Before we just added matrices and were done with it :) \nAnyway, no point arguing about this anymore, I've written the code to fix this and I'll do a new script to create the definitive list of partial matchers.\n. After these last few commits this should be ready to merge. The caveat of no name munging for TIFF/DNG is now fixed using rawspeed to help us out and have the single source of name matching.\nI've ran pretty extensive regression testing. 422 files covering most brands and models were tested against a default xmp file as well as one where standard, embedded or enhanced color matrix was set. Everything is producing identical output, with the exception of cameras that exiv2 doesn't support where we now are able to apply the matrix.\nIf there are no objections I'll go ahead and merge this in soon.\n. I'm not sure this is the right way to go anymore. This can be implemented without the database fields. We would just have to do the filtering (the \"like\" in sql) on the darktable side by doing the following:\n- Always select unique maker/model with no filtering\n- Convert all maker/model values to sanitized values with the existing code and make them unique as well (some exif values map to the same output, like the SLT-A99V and SLT-A99)\n- Apply the filter to downselect to the ones we actually care about\nThis would make the code more complex (this kind of text wrangling in C usually sucks) but wouldn't require db changes and would allow us to change the name munging in the future and see it be automatically apply.\n. I've sketched out how to do this like I described above and will be finishing it soon I hope. No need for this anymore.\n. You don't need to open new PRs when you make changes. If you are just adding new commits you can just push and if you are rebasing or starting over you can just push with --force to replace what is here.\n. Don't we have one already in doc/LICENSE?\n. The reason I didn't do the \"\" to <> change was to stay the same as rawspeed upstream. Otherwise we need to keep that diff around forever.\n. Have we identified a situation where bundling helps us? pugixml should be available on most platforms. I also don't really see the need for cherrypicking this. I think we cherrypick way too much into the stable branch already. I'd much prefer if we did only bug fixes and camera support.\n. We can just remove update_rawspeed.sh. We carry local changes to rawspeed so it doesn't make sense anymore to just import whatever is in the rawspeed develop branch.\n. As it stands this isn't really mergeable, the code is quite buggy and won't even work since the WIN32 ifdef is still there (so all this code would still be disabled under Windows anyway) and it still calls umask which is also POSIX.\n. I've also fixed a bug in colorin where it would try to fetch an embedded color profile from a .TIF file even if that file wasn't actually a TIFF but a RAW instead.\n. Merged manually\n. @LebedevRI It was discussed on IRC with hanatos and houz, since no real objections came up I just merged. I didn't even think this was PR-worthy but did it anyway.\n. In this case it may make more sense to submit this to @klauspost/rawspeed so that klaus can have a look at it. Could you do a PR there?\n. Cool, thanks. 15% sounds incredibly high considering rawspeed is only a part of the runtime of darktable-cli. Great work.\n. Thanks for doing this work. I've pushed your commit manually:\nhttps://github.com/darktable-org/darktable/commit/843f4223ab7692e3a61e24a836683d8224cb1d5d\nBTW I also ran my regression testing suite and the output is exactly the same for all files.\n. Thanks for these. It would be great if you submitted the original files to rawsamples.ch so we can do regression testing in the future.\n. This was merged manually in master\n. Merged manually in https://github.com/darktable-org/darktable/commit/94c4d1121726930dff451132b14c0d18b3695aff\n. What's asymmetric about it? I've done a few minor tweaks since the version you saw by the way.\n. I've tried adding a dark bar behind the metadata, clearly separating the info from the image. I think it helps a bit visually:\nhttp://scratch.corujas.net/prettify-fullscreen-metadata2.png\n. Since I think this is a real improvement but it's clearly not consensual I've tried adding an option to select between overlay/top/bottom. The code needed for that wasn't too bad either.\n. Now that we've branched off 2.1.0 I'd like to merge this. Any opinions against it?\n. @houz I'm sure you still don't like the look but do you dislike having the option? With this PR the default stays the same. I wouldn't normally advocate for more options but I find the default really bad.\n. @TurboGit This is already a GUI preference, the default stays the same as what it is now.\n. Given that this is an option and off by default can I just merge it or are there objections to that as well?\n. No one replied so I'm planning on merging this this weekend.\n. I'd still like to merge this, yes.\n. Yeah, I should have just merged it before. Now there's all this pango stuff to adapt.\n. I had a look at how the cameras I had around do it and implemented the following cases:\n- As long as it is as fast or faster that 0.3s use 1/N\n- From 0.4s up to 3.9s use N\"M\n- From 4s up use just N\"\nThis looks good to me but the 0.3s can be done either way really (0\"3 and 1/3 are equally as good I'd say).\n. @houz what do you want to make translatable? Besides the values we only have \"/mm/iso\n. @houz but why would we translate those? There's nothing there that's language specific. Let's just find something we like and stay with it.\n. Ok, this now uses the double prime symbol and I've tested it's correct in 0.1s increments from 0.1s to 4.5s which covers all the cases. As far as I know this is ready to merge.\n. I've tested this from 0.01s to 4.50s in 0.01s increments now and fixed an error where we could end up displaying 0\"10 instead of 1\"0.\n. I've now reworked the fullscreen logic extensively and implemented the fullscreen button. In a nutshell the changes are:\n- Hitting fullscreen focus while fullscreen (and vice versa) no longer disables fullscreen but instead enables/disables focus detection\n- There are now default keybindings for everything. F is for sticky fullscreen, Z for momentary fullscreen and Ctrl-F/Ctrl-Z for the focus versions.\n- Fullscreen now works even if the mouse isn't over an image. In that case it defaults to the first visible image currently on the lighttable\nSo far this looks quite usable to me. We only have one mode that does fullscreen (so no more confusion between Alt-1/StickyZ) while keeping all the flexibility we had before and making the fullscreen mode more discoverable (GUI button for it). The only still non discoverable part in it is how to leave fullscreen (pressing F) but we could easily add GUI for it. That's particularly easy to do cleanly using PR #1031 (just add a close button at the end of the top metadata line for example).\nThe code should be reasonably clean already. The only big sore point I know about is that I'm using dt_conf_get_bool and set_bool as a poor man's callback to get the button press from tools/lighttable to view->lighttable. I'm sure there's a more direct way of doing it though.\n. After discussions on IRC I have half a plan to make something better:\n- Have only a single code path to display the lighttable at whatever zoom level is selected\n- Implement Z and StickyZ as just temporary overrides of the zoom level (so that when you move back you end up at the same original place)\n- Keep the same logic of using for Z and Sticky Z the image that's hovered over or failing that the image that's currently selected\nI've also considered two changes that will need discussion:\n- Review the way zooming is being calculated to try and not end up with a view that has the first line with missing images on the left\n- Possibly remove the zoomable light table mode and just have the file manager one (I don't really see the appeal but maybe someone does and can comment)\n. @LebedevRI this is a followup to exactly that. That commit made the gui a button not a checkbox. This makes the behavior so that all presses active auto instead of a toggle.\n. We've discussed this on IRC and are keeping the behavior, possibly showing the toggle state by changing the color of the button.\n. This is not needed anymore as it's been fixed properly in #1044.\n. I've now implemented the transform functions but the issue is still the same with the image taking up a quarter of the screen. Not sure how to proceed now.\n. Ok, this should all now be fixed properly. Setting the scale fixed it. I just need to cleanup the code a bit and it should be ready to merge.\n. Ok, so as far as I know this is working properly. Functionally everything seems to be working fine:\n- Export at full resolution works fine\n- The darkroom works fine at all resolutions and is no longer blurry\n- The thumbnails work fine (and are slightly blurry like all our thumbnails)\n- The transforms are correct (spot removal works correctly for example)\nThe only doubts I have are small code issues that may not be issues at all:\n- I rely on calculations done in modify_roi_in (x_scale and y_scale) for process (should be fine as that's always run after) but also for the transforms. Is that ok or can the transforms be called before modify_roi_in?\n- commit_params had a strange pattern where the data being copied was the params passed to the function but for the piece->enabled test self->params was being used. I used self->params for everything but maybe that's wrong?\n- I now use a dt_iop_scalepixels_data_t that isn't just an alias for dt_iop_scalepixels_params_t since I need to keep around x_scale and y_scale. Hopefully there are no mistakes in that code\n@LebedevRI this is your code so you're probably best qualified to review these and other issues the code may still have. If you could find some time to look at it I'd appreciate it.\n. I've now also tested this with low_quality_thumbnails and upscaling on export. Both work fine. My only doubts about this are the minor things in the code I've detailed in the previous comment.\n. I've now fixed those two issues (commit_params and transforms) so this should be ready to merge.\n. Ok, I've done the changes you've suggested. I'll merge this now.\n. This looks fine to be but I'd use camera_alias for MODEL instead of camera_model. That way when the camera uses a market specific alias we show that instead. It's what's physically written on the camera so it makes more sense for the user. This mostly only makes a difference for low-end Canon DSLRs.\n. The deflicker calculations look good to me. Trying it out I think we could simplify the GUI and the implementation of the other exposure modes:\n- Remove the old auto mode (it produces the same results as setting deflicker to 0EV and adjusting the percentile slider to 100%-\"clipping threshold)\n- Add the option for deflicker to only sample a given area of the image\n- Remove the mode selection at the top of exposure and instead have the following options:\n  - black slider: same as now\n  - exposure slider: same as now\n  - area selection toggle: enables/disables using only the given area of the image\n  - deflicker enable toggle: enables the deflicker mode\n  - white percentile: same as deflicker percentile\n  - target level: same as deflicker\n- To get the deflicker behavior just press the button or fiddle with either white percentile or target level. When you do that the exposure slider changes to indicate the computed EC\n- To go back to manual behavior just press the button or fiddle with the exposure slider\n. > Try some commit before fd134a7\nYeah, I like that quite a bit more than the current UI. It makes it obvious what is happening. Compared to this I'd:\n- remove the old auto mode (the same can be obtained with deflicker) and just rename deflicker auto\n- add another toggle to enable/disable area selection \n. Actually the math looks exactly like setting percentile to 100% and then adjusting the EV to negative value. I think there is an f(clipping_threshold) = EV function that makes the old auto mode exactly like deflicker. Either way functionally it's the same thing, adjusting the exposure by comparing the highlights in reference to the clipping level so there's no need to have two ways of doing it.\n. > Yeah, I like that quite a bit more than the current UI. It makes it obvious what is happening.\nA simple way to bridge these two UI concepts would be to move the mode dropdown to below black and exposure sliders. That way the GUI would work almost like it does now but it would be obvious that the parameters are just black/exposure and everything else are just ways to adjust it (or not) automatically.\n. Could you please open a bug report and attach a sample file? It's hard to verify if the fix is correct without a sample. It's too bad you didn't tell us when you found it, I'm sure we could have fixed it quickly had we known.\n. Thanks again for this. I committed a slightly different fix as we may as well not do the same madness Canon has gone with and just call all these variations consistently \"EOS 350D\".\n. The code is indeed broken and it's a good thing @houz caught it as it is subtly broken. It also uses bool which we don't use. All in all it's a waste of developer time and a risk to quality to be messing with working code like this. \nPS: You are going around opening PRs like these with pre-formatted messages and then replying with other pre-formatted messages which seems kind of fishy in itself.\n. @edgomez @LebedevRI you guys are both absolutely correct in saying that there's a big chance we'll rework the way we do base curves in the future. That issue though is orthogonal to the one I'm bringing up. To restate our options in that context, we can tell users:\n- Our per-camera basecurves are broken and unfit by our quality standards so we've removed them until we can find a new way of doing it.\n- Our per-camera basecurves are broken but are the best we have right now. We'll keep accepting new ones with minimal quality testing and will very likely rework them in the future.\nI've already done the work for the first option (this PR) and am willing to do the work for the second (merge the few curves that show up because some user has decided to do one). \nAt least some users are finding the curves useful and since PR #998 these curves aren't even used by default so the quality issue should be minimal. I'd just not publicize the curves but accept them if they show up.\n. I haven't seen anyone actually want to remove these curves. Should I just close this and start taking the curves users have submitted?\n. > This is basically the same shadow zone as enhanced curves, modulo #10345\nIt doesn't have that problem because unlike colorin this doesn't break history stacks as we save the actual curve.\n\nBut if one comes up with a proper way to verify their quality, then i bet no one will vote them to be removed.\n\nThe situation we have now is that we don't really know how to validate the new ones just like we didn't know how to validate the old ones. We don't enable them by default either, which is why my opinion is option 2 above:\n- Our per-camera basecurves are broken but are the best we have right now. We'll keep accepting new ones with minimal quality testing and will very likely rework them in the future.\nOtherwise we keep having users asking \"but my FOO camera has them why can't I add them to my BAR camera\".\n. > IIRC i did some profiling on this code, and this version seemed a bit better. So, is there any actual issue?\n@LebedevRI it's just a code maintenance thing as the code is duplicated. I wonder if unrolling the loop by hand (like I did for the monochrome case) is enough for the performance to be the same.\n. This was discussed on IRC and both @houz and @LebedevRI were not in favor. I still don't like the duplication but it's a minor issue anyway.\n. > Still no \"extensions\", even for new files\nSeveral of the files have extensions just not the ones that are runnable scripts for the reason I've already explained.\n\nNo license is specified, in ANY of your scripts...\n\nThat's not common in scripts, are we supposed to do that for every file in the repo?\n. > For the reason I've already explained, i would highly prefer all of the scripts to follow same pattern.\nI agree with being consistent but I'd just remove the extensions from the others.\n\nThis has been discussed in IRC some time back, no license => problem waiting to happen.\nI hope you would want to avoid that...\n\nI don't recall the discussion, may have been before my time. Should I prepare a PR to add them to all the scripts?\n. I'd like to merge this as is and keep working it on master. The issues discussed here were argued to death on IRC with no conclusion. They're also not specific to this code and common to most of tools/.\n. Unless anyone objects I'll be merging this this weekend.\n. The noise is almost surely the result of colorin throwing away the fourth channel and just using the first three. I had a look at colorin and am not sure it won't be too much work to make it support 4x3 matrices.\n. @LebedevRI I mean that colorin currently uses a 3x3 matrix so it only ever uses the first three channels and not the fourth to generate RGB. In this case it's not an alpha channel but an actual color channel so colorin would have to use it to generate RGB.\nFor this to work though it would have to be ok for demosaic to produce CYGM instead of RGBA. As far as I can tell demosaic just passes garbage in the alpha channel so this shouldn't be an issue.\n. In that case demosaic breaks it and gets away with it:\nhttps://github.com/darktable-org/darktable/blob/master/src/iop/demosaic.c#L1147-L1152\nThat just averages the two greens and then leaves the fourth channel as it is. Are masks even used before colorin or is this a hypothetical future issue?\n. In that case if this is to work the best option is to just do the transformation in demosaic itself. It was going to need a specific code path in colorin anyway. I'll see how ugly that turns out.\n. Something much simpler of course. In demosaic convert CYGM to RGB in one of the linear colorspaces we already have. That way the rest of the pipe works the same and there are no GUI changes. It would just be some extra code at the end of vng_interpolate just like we do G1/G2 averaging and then a tweak to colorin so it defaults to that linear colorspace for these cameras.\n. I've done only very light checking but the iops before demosaic should work the same. If any of the non-essential ones don't work properly with it we can probably just check for these cameras and not enable it.\nYou seem to be very worried about this, but I'm just testing to see if supporting these isn't too much hassle. If it doesn't work nobody really cares so just relax :)\n. Just pushed a proof of concept for the Canon G1. Seems to work fine. There are still two issues to solve though:\nThe first is that I hardcoded the matrix and it needs to be calculated instead. That should be easy enough using some dcraw code or possibly stuff we already have in colorspaces.c.\nThe second is that the WB is applied before demosaic so it tries to use RGB multipliers on CYGM data which doesn't work well... So far I've just disabled WB and hardcoded the multipliers in demosaic as well. A solution would be to have temperature.c save the multipliers in dt_image_t and then have demosaic apply them. Another would be to somehow invert the matrix, calculate CYGM multipliers and then apply them in demosaic as well. That seems cleaner even if it's probably actually slower.\nAll in all this doesn't look too bad. It's just a few added isolated code paths in places where we already fork for xtrans anyway. I was expecting it to be quite a big uglier.\n. All the needed changes in temperature, demosaic and colorin are in place. The diff doesn't look too scary either and everything seems to work just fine. The only thing missing is doing the color conversion in the preview pipe. I grepped around a bit but couldn't find what to change. Hopefully it's as simple as adding a dt_colorspaces_cygm_to_rgb() call somewhere.\n. Seems like the MIPF creation was also fairly simple. To be complete all that's really needed now is to validate the math is correct. In particular I'm wondering if the matrix used for WB should also include Rec2020.\n. After going through the WB math I realized these cameras actually have WB multipliers for the four channels and all the math we do for 3x3 is also valid for 4x3. I've generalized the code for 4x3 and it now works in both cases. There are still a few things to fix though. The following is mostly a note to self:\n- ~~For CYGM cameras the preview pipe has wrong WB~~\n- ~~Also for CYGM cameras spot WB doesn't work~~\n- ~~Demosaic now has 4 coeffs instead of 3 so the module version will have to be bumped and legacy params handling added (simply adding an extra NAN coeff will do)~~\n- ~~The matrix code is duplicated between demosaic and colorspaces and can probably just be shared~~\n. The code now is feature complete. Everything works including spot WB and WB of the preview pipe. To do WB of the preview pipe I kept the MIPF as CYGM and then converted to RGB only in temperature after applying the WB. This works fine but assumes nothing is using masks before temperature. We had said there was no possibility of masks before demosaic but both invert and temperature include code to copy the alpha channel if it's there. For example:\nhttps://github.com/darktable-org/darktable/blob/master/src/iop/temperature.c#L475\nMaybe this was just copy paste and using the fourth channel is fine. If it's not I'll have to do RGB->CYGM->RGB for the WB application which is not ideal but is also fine.\nOther than this I need to cleanup the matrix code to eliminate duplication and this becomes ready to merge.\n. This should be in good shape now. All outstanding issues are fixed and the code is no longer duplicated between temperature.c and colorspaces.c. \nI've detected a weird and inconsistent bug (probably locking) when switching images  in the darkroom film strip where the output will end up greenish. I have a sequence of images that triggers it easily. It's probably not CYGM specific though.\n. This should now be pretty much ready to merge. @hanatos had a look and didn't seem to have any major objections. I've since done a few more cleanups and improvements. The current state is pretty good:\n- Both CYGM (Canon G1, Nikon E5700 and a few others) and RGBE (only the Sony F828) are supported\n- The pipe works and outputs valid color for all these cameras\n- The preview pipe works and outputs color that matches the full pipe (after much head scratching)\n- The GUI works mostly like with any other cameras. The only differences are that temperature shows CYGM/RGBE color sliders and that colorin defaults to Rec709 as that's what the image gets converted to after demosaic or in init_f for the preview pipe\nThe code is mostly straightforward without anything really scary:\n- All of the heavier lifting is contained in specific functions in colorspaces.c and has ended up being quite straightforward\n- iop/temperature was reworked to use 4 coeffs so there's a lot of code churn but it's just straightforward changes. The matrix math that temperature used for Kelvin and for camera neutral WB was extended to 3x4 instead of 3x3 matrices. That code was already adapted from the dcraw one which was originally 3x4, so there's nothing really new there.\n- iop/demosaic was tweaked so that the VNG interpolation is always used and  G1/G2 averaging isn't done for these images. It also does the CYGM->RGB conversion so we can keep the pipe 3channel\n- colorin was tweaked to default to Rec709 and not enable the standard matrix for these cameras\n- half-size demosaic was tweaked to also work with 4 color images so that init_f can work fine\n- init_f was tweaked so it does CYGM->RGB right after demosaic so that the MIPF is also 3channel\n- rawspeed needed some tweaks to support 4 WB coeffs and the Sony F828 required a new decoding method\n- I disabled OpenCL in demosaic and WB for these cameras. There's nothing particularly hard in enabling it (particularly since demosaic recently got an OpenCL VNG) but since I don't have the hardware to test it and these cameras have small images anyway it doesn't seem worth the potential headaches in the future.\nI only know of two minor issues that may very well be the same thing:\n- ~~For some reason the Sony F828 (the only RGBE) doesn't match color between preview and full pipe~~\n- When working with 1 channel per pixel (pre-demosaic) processed_maximum is probably not being properly updated as we actually have 4 channels. I'm not sure what this may cause or how to fix it. ~~It may be the cause of the F828 color issues~~. It's either that or differences between VNG and half-size demosaic (bingo).\nGiven how feature complete this is and since the code hasn't ended up particularly invasive I propose we merge this.\n. @LebedevRI I've only tested this very lightly but it should go a long way to helping reduce the out of bounds accesses you've found in a more robust way than trying to whack-a-mole everywhere. The next step would probably be to require a size parameter in TiffEntry::getData() to do similar checks.\n. @LebedevRI can I update this and merge or do you still want to do some other changes before?\n. @LebedevRI No clue why you're doing that but it's your call. Are you also not going to submit upstream what you've already changed?\n. This is the current diff between darktable and rawspeed upstream:\nhttps://gist.github.com/pedrocr/3c8231de996fa1f330af\nThose are all from your commits @LebedevRI.\n. @wgoetz master should work fine again. Could you please submit a 1J5 file to rawsamples.ch so we have something to do regression testing against? Thanks\n. Tested this a moment ago. It seems to work fine and is indeed more consistent with that setting. To be completely consistent with the setting it would make more sense to activate on the whole lighttable area, just like in zoomed out modes it activates in all the area of that image's square on the grid. The activation on the top left square is a bit strange to use at least initially. It might also be more consistent to in grid view only show the CR2/ARW/JPG/etc overlay with the same logic.\n. > On my case I do not have borders around the image. And so there is no event between \"I'm in the image\" and \"I'm out of the image\".\nSure there is, there's all the area outside the lighttable.\n. @TurboGit It may not be possible in dt_view_image_expose but it should be possible anyway.\n. Yeah, it seems to work fine.\n. Please open a bug report with an attached sample file. It's actually quite rare that two cameras use the same color matrix. I'm sure this works but may not be correct.\n. I've tested this with normal x-trans files and it works fine. There's no reason to think a x-trans camera with CFA removed doesn't work like any other. It's a fringe/experimental thing anyway.\nThe iops before demosaic should be more consistent now. Just like in the regular pipe the monochrome step is only done after them. So if you change temperature or invert the image the two pipes should match now. RIght now we're doing the monochrome step at init_f so there's no way for temperature for example to match what the regular pipe will do.\n. If there are no other objections I'll be merging this this weekend.\n. But I did answer them, so what is still not clear or what do you disagree with?\n. Should be ready to merge now. Did a rebase on current master to take care of the imageop/imageop_math split and also a build failure because of new const usage in demosaic.\n. @LebedevRI I'm still planning on merging this today unless you have an objection you want to actually point out.\n. > Get someone else to merge it or i will revert it.\nThat's not an objection, just a threat...\n. Here's a more extensive explanation of what is here then:\n- We currently do demosaic in two different places, right at the beginning of the pipe in previews, after a few iops in the full pipe. This requires special handling in all the iops before demosaic because sometimes they deal with 1-channel data and sometimes with 3-channel data. This often leads to broken code. For example currently rawprepare is broken and returns different results in the two pipes (which is not usually evident because most sensors have very similar black points for all channels).\n- The existing code is implemented as a demosaic step in the normal places (the demosaic iop for full preview) and the init_f code for the preview code. This requires extra hairy code in init_f (looking up demosaic iops settings), and breaks the init_f assumption that the MIPF is immutable. So to make it actually work properly (without restarting darktable for every change) the MIPF cache would need to be reworked.\n- What this code does instead is very simple. Leave the MIPF just as is and do the monochrome conversion always in the same place (demosaic.c). The pipe all the way up to demosaic stays exactly the same and caching works just as before. The way that's implemented is to activate demosaic.c whenever we are in the preview pipe and the demosaic option is monochrome. In those cases we just average the RGB values into a single grey value. Those RGB values meanwhile have gone through the pipe the same as before so have been transformed in equivalent ways as the 1-channel values in the full pipe.\n- Since it's now trivial to do I've also enabled the code for xtrans where it works just the same.\nDoing it like this has quite a few advantages and no disadvantages I can see:\n- The code is much simpler. The diff is net minus ~150 lines even including the code to activate this for xtrans as well. Everything is concentrated in demosaic.c too and the init_f complexity is completely gone.\n- Even with simpler code the preview update now works with no other changes to the caching.\n- The iops before demosaic actually work the same way for the preview and the full pipe. This is completely unworkable in the current solution as the monochrome conversion is done before those iops for preview. We get away with that normally because we have the special RGB modes to those iops designed to match the 1-channel pipe. By going monochrome we throw that away. So if for some reason your monochrome converted sensor needs a blackpoint adjustment to just the red pixels (they have a different gain for example) the preview and full pipe won't match.\n. Closed in favor of #1156\n. Sounds good to me. I've closed the other PR then. A few comments that may be helpful:\n- You mention +18 is enough but there was at least one location in your code that did +24\n- I recently changed FCxtrans() to take size_t for row/col. Since that's unsigned you need to change those back to int or maybe int32_t\n- I didn't add roi to FCxtrans() it was just defined that way in other places so when I consolidated I used the API with the most features and adjusted the other places\n. > @houz Or use ssize_t.\nThat would work too but why use size_t for something that isn't a memory offset? row/col are image dimensions and we even use int for them (should probably be int32_t) in our internal pipe structures. \n. @dtorop good to know you've checked that 18 was enough but it would seem safer to just set 36 or even the 600 I set before to be really safe and not have a weird bug in the future, no? Is there any disadvantage to having larger values?\n. This looks fine but I'd like to have a look at the source files. Could you upload them somewhere and link them here?\nBy the way you can use the script in tools/extract_wb to generate the presets. It should format them a bit better.\n. Thanks. Note that's not the output of extract_wb it's wb_extract.pl from ufraw. Our extract_wb should produce better output in most cases although it doesn't support these images yet for some reason.\n. Seems like I just had a too old exiftool. The script works mostly fine as is. Just need to fix up a bug or two.\n. extract_wb in master now deals with these files properly. Do you want to push a commit with the output yourself or should I do it now that I have the file?\n. The diff looks fine. Could you just squash the 4 commits into a single one?\n. The easiest way to do it is probably to just reset the branch back to master, add a single new commit and then force push to the same remote branch.\n. We were trying to get a release out so I pushed a single commit with you as author with these changes:\nhttps://github.com/darktable-org/darktable/commit/842546a3a569131aa63c8cd4dd52fb5245b60977\nhttps://github.com/darktable-org/darktable/commit/c2f7fdb1fce2d1206cb6b86d19a2de03f71e2448\nHope that's ok with you.\n. This is probably not the correct fix. If these files really have different black levels per channel those are probably encoded in the metadata itself and just need to be read. Specifying blackpoints in cameras.xml is only for formats that don't have it in metadata. We had a report in the past of a file that needed blackpoint as 0 in a very high-iso and low light shot but normal blackpoints for normal shots. That was in my backlog somewhere.\nIf there is a format that actually does this (having fixed blackpoints that are different per channel) it can just be implemented the same place where the rest of Sensor is done to apply to all formats. The only reason RAF fiddles with these at all is that because of the rotation code it ended up not using the normal code path and having to reimplement these bits.\n. > hm. i'm now reading the metadata from the raw file.\nThe code looks fine to me, pretty much what I'd have written too.\n\njust a note on this specific raw (x100): it's a bayer pattern (non-rotated,\nnon-xtrans, no-bs). i still don't know what you mean by the regular place\nwhere this should be done, i'm just grabbing the exif tag entry where the\nblack point is set (also gave it a probably nonsensical name in the list of\ntags).\n\nAlmost all decoders call RawDecoder::setMetadata() at the end of\nXDecoder::decodeMetaDataInternal(). As is documented in RAF that's not\npossible because we often need to rotate the image:\ncpp\n// This is where we'd normally call setMetaData but since we may still need\n// to rotate the image for SuperCCD cameras we do everything ourselves\nWhich is why the blackpoint stuff gets reimplemented there. For this though you'd always need decoder specific code just like the one you wrote. In all the other decoders it would just be done after setMetadata(). Here it needs to be done after the reimplementation of setMetadata().\n\ni was noting some issue with the blackpoint not being picked up in the\npreview pipeline though. so the navigation view still has the green cast :/\n\nProbably this bug:\nhttps://redmine.darktable.org/issues/10978\nTo fully fix it the preview pipe needs to demosaic into\nRGGB/CYGM/RGBE, which according to discussions during the CYGM stuff\nis not allowed because the fourth channel is for alpha.\n. It's ok to merge as long as rawprepare is already saving the blackpoints to the history stack for all images, even old ones, which I'm not sure is the case. If not this will break history stacks although hopefully by not much. Actually for old history stacks before rawprepare we will definitely regress them as there's nothing there.\nRunning the regression testing scripting would show the differences although it will show differences even if rawprepare is already doing the right thing (as it's not reusing the xmps from one run to the next). To run it:\n``` sh\n$ cd tools/regression_tests/\n$ ./fetch-samples\nGo get your favorite beverage while it downloads the full rawsamples.ch archive for the first time (the next times are incremental)\n$ ./compare master rawspeed-raf-blacks Fujifilm\nDrink your beverage as it compiles both versions and then runs each file through darktable-cli from both versions and compares them\nI added Fujifilm as an argument so it doesn't run through the whole collection\n$ cd comparison/\n$ firefox index.html # or whichever browser you prefer\nThis will show you a nice summary of the run like the ones at http://darktable.pedrocr.pt/\n```\n. It should be ORIENTATION_NONE indeed. Fixed\n. Yep, fixed. Thanks again!\n. It's probably the same thing on most platforms but the code is actually correct because those values are initialized with memset(0).\n. This will break on older exiv2 versions. It probably needs a version check like we do with Exif.CanonFi.FocusDistanceUpper.\n. Did you check that this will only be available in the 0.25? If 0.24 already has it we can use that instead.\n. Cool, thanks\n. I think you mentioned different ISOs having different black or white points. That can also be set, just see the Samsung NX1 for example. However judging by the color matrix the sensor is the same as the original K-3 and we didn't do that for that one so maybe it's not really relevant. How big are the differences?\n. Ok, just ignore it then. Seems ready to merge then.\n. Is this really true? Won't we still block on cupsGetDests until all printers are discovered? Ideally we'd have some form of async way of getting printers from cups itself so that one slow printer doesn't block the discovery of all others. If I'm reading the diff correctly we won't get a single printer until all printers are discovered. That's still much better than before, at least we don't freeze the whole app.\n. Looking at the cups API what we probably need is cupsEnumDests: \nhttps://www.cups.org/documentation.php/doc-2.0/api-cups.html#cupsEnumDests\nThat works with a callback so should allow us to add printers as they become available. I also wonder if we need to launch that job every time we open the print module in case printers have shown up or disappeared. Long gone are the times when the printer config was static.\n. That's not how I read your code and the cups api docs. Both cupsEnumDests and cupsGetDests only return when they have fully enumerated the printers. So your current code won't block the app (because it's run in a background job) but it won't show up any printers until all printers are enumerated. What cupsEnumDests does differently than cupsGetDests is that it will call a callback every time a printer is enumerated, so while it will only still return after all are enumerated it will call a callback of your choice on every printer while it's doing it. If you make that callback add a new printer you'll have available printers right away even though cupsEnumDests has not finished yet.\nEither this solution or some other one exists because the gnome printer dialog is capable of listing printers and stay responsive even before being able to show all printer options. Our best bet is to find a way to generate a test case, probably by creating a network printer that doesn't exist so that cups tries to connect to it until timeout.\n. What does this do? Seems to work fine without it\n. Not in the Ubuntu 12.04 package at least.\n. Is this really what you want? The lockfile hasn't failed to open, it failed to close.\n. Should we also return NULL here, or is the other point wrong?\n. This can also fail, should we check this one as well?\n. This is wrong, fprintf returns negative values (which evaluate to true) on error\n. Yeah this is definitely wrong, if this triggers we would print something to stdout and then try the next line doing fprintf(NULL, ...)\n. No it's not, there's a comment explaining why just above the line\n. Did you test lower defaults? This has a cost so I wonder if 1 or 2 aren't better.\n. Yep, you're right on the cost which is why I asked if you had tried 1 or 2. The number should be as low as possible while still getting fluid previews. 3 sounds fine too though if that's what's needed.\n. > That's why I disagree with you on the \"as low as possible\" evaluation\nShould we make it 1000 then? I think doing preload is great and 3 may very well be a good default but since apparently it's just the first number that came to mind testing some lower numbers to see if they give similar results would be nice. Making the number larger than it needs to be gives no benefit. As soon as you move to the next image a new preload will happen anyway, and it does have a cost as it will do processing and disk space that may never be needed.\n. The notation for seconds is '' (two), just one means minutes:\nhttp://english.stackexchange.com/questions/114205/english-notation-for-hour-minutes-and-seconds\nI didn't touch that but I guess that was the rationale behind it.\n. Sounds fine to me\n. I think iheight is correct. We're calculating the reduction ratio based on what the original image is not the buffer we are getting.\n. Ah, I see what you mean. It doesn't seem to make a difference, even with low_quality_thumbs. I've pushed the change now.\n. @LebedevRI this is the bit I mean about commit_params. Before we were using \"params\" passed as argument to the function to copy into piece->data. Now I'm using self->params to copy into piece->data. Everything seems to work fine, I just thought it strange that before we used \"params\" for one thing and \"self->params\" for another (the check below).\n. It can but it's very unsafe and leads to issues if you don't have a network connection for some reason. We already ship a few others in data/js/ for the same reasons I assume.\n. That issue is unavoidable. If you don't update the code it will be using old versions whether they are fetched from the network or from disk.\n. The current Ubuntu LTS (14.04) still has 2.8.12 so it would be nice if we could keep compatibility for that until the next LTS (16.04) is out.\n. I use LTS to develop in, so if we merged this as is I'd not be able to compile master. Once 16.04 is released I'll upgrade so that's why I was suggesting we wait until that happens.\n. These ifdefs around xmmintrin.h could probably be factored out into a common header file.\n. According to the standard it does but I guess we can make it more explicit.\n. Thanks! that actually fixes an intermittent bug I was seeing when switching images.\n. I think I saw another iop do that but that makes more sense indeed.\n. Where would you do it? Note this isn't doing color conversion on images, it's just converting the spot WB RGB coeffs to CYGM coeffs.\n. Our default for fullscreen was different between zoom==1 and Z-mode so I fixed it while I was looking at this.\n. I saw it, thanks. But I do want to see metadata I just don't want to see it over my image. I want to rate the image, add colors, etc and have the metadata right there while I do it without it blocking my view of the image I am rating. Having it hover in and out is a kludge.\n. There may be in the future, and it's best if all that similar code is in a single place instead of scattered about.\n. The order seems to be the correct one for CYGM. But thanks for pointing it out as that could be why there's a difference in the RGBE case between full-pipe and MIPF. This branch may need to be three way, splitting the 0xb4 and 0x9c cases.\n. Turns out this was correct for all cases, the bug was actually that dt_iop_adjust_filters_to_crop() only knew how to adjust RGGB filters. That was only needed because we're now doing our own crops instead of letting rawspeed do it. Since rawspeed already has all the code to do dt_iop_adjust_filters_to_crop() correctly for all cases I just used that instead and removed our own implementation.\n. Right. I only implemented a CPU code path for that. There's nothing stopping an OpenCL code path but it probably doesn't make sense for such small images.\n. I'll have to read up about it, I just copied that line from an equivalent loop without understanding it.\n. That may be needed if the input size isn't always the same as the output. I had assumed (and asserted) that was the case but maybe it's not?\n. Equal weights works fine too but since almost all sensors (including x-trans) have twice as many green pixels than red or blue it makes sense to weigh green twice as much.\n. @dtorop demosaic is the only place we're still doing these increments. Wouldn't it be better to just change the FCxtrans() function to just do +36 or something safely high like that and not need these magic numbers all throughout the code?\n. @dtorop this was the only case where the increment wasn't a multiple of 6. Is it a typo or as intended?\n. ",
    "jerdna-regeiz": "Oh well I wasn't aware of the Lua support, I'll have to look into that.\nDidn't thought about it being so special, as even before the change I missed that feature some times, when I wanted to change the leadership of some groups and had to click on every group symbol...\nSorry I didn't know about the .po files, I rather greped for some translated string and added mine.\n. I want to change the leader of multiple groups at the same time.\nThus I want to select images and tell them to change the leader of their groups to the next one found.\nI had a quick look at the Lua api and think as well that it is doable (with a shortcut), but had no free time so far to look into Lua itself again (WoW-scripting is way in the past now...).\nAs far as I can see I could use \n \"gui.selection\" \nto get the current selection, \n \"types.dt_lua_image_t.get_group_members\"\nto get the group members and thus find the next possible leader and\n \"types.dt_lua_image_t.make_group_leader\"\nto set it.\nBut first I have to look up again how to code in Lua, as it's been a while since I used it and only remember strange things like string concatination with \"..\".\nOh well and I have to see how to hook a shortcut, but I already saw downloadable scripts which do that, so it should be easy to copy and paste.\nIt could very well be closed, I think I can handle it. Is there a way to give it back to the community when I'm done?\n. ",
    "sgimenez": "I receive some messages occasionally:\n\nFilebacked cache: Couldn't remove /home/gim/.cache/darktable/DT_MIPMAP_0/3529, error No such file or directory\nFilebacked cache: Couldn't remove /home/gim/.cache/darktable/DT_MIPMAP_2/1073745353, error No such file or directory\n\nI think they should be silenced if this is normal behaviour.\n. Solves: #8318, #8745, #9024\nMost probably solves #8746, #8923 too.\n. @pmjdebruijn There is (and should be) a little saturation correction when color layers are aligned. It may slightly reduce saturation, or it may increase saturation as well. But this should be barely noticeable. Previously a general saturation loss was easily noticeable.\n. @PolarFox: Indeed the last commits broke the allocation logic. Thanks for the report! Fix coming soon. \n. Too late. Not my job any more. Sorry, but I don't want to lose time.\n. Clean rebase, needs some testing in case some errors were introduced during the merge.\nX-trans support could be added with some work (optimized computation of gradients and gradient-difference maps needs to be adjusted).\n. In case it is still not clear, I'm not interested in the kind of coding style trivialities that seem to bother you. Do whatever you want or not with the code. Of course, if something really doesn't work I'll be glad to help fix it.\n. You might be interested in my unpublished version of lens.c, it allows toggling \"auto\" separately for all the lens controls. Not thoroughly tested, but I believe this is the only way to make it intuitive to the user. Differentiating between \u201cnothing changed\u201d and \u201csomething change\u201d makes it very hard for the user to understand what's going on underneath (and also it's not as flexible as the other approach).\nHowever these are not the only changes I made. I could extract a patch that contains only these.\nhttps://github.com/sgimenez/darktable/commit/cfd78d058007be604015bfc4d8671a68c1269c0d (fetch and cherry-pick if you're interested).\n. I know, and I'm very sorry for that. But the approach is much better and worth investigation. I'll try to come up with a cleaned-up version.\n. In reply to my previous comment, here is the cleaned patch: http://github.com/sgimenez/darktable/tree/lens-autoconf\nSorry for the original mess. This approach doesn't require an update of the module version. And the users understand what they do.\n. May I have feedback? Some darktable users disable separately TCA or lens distortion or vignetting (I'm one of them) and the current patchset is useless to them. \n. Almost. Since one of my lens lacks EXIF data for the focus distance, I also set it to a custom value different from the hard-coded 1000.0.\nBut be careful, if you withhold the actual state of parameters to users, they will not understand what's going on (since the actual parameters do not show up in the GUI) and they will report bugs or ask for help or support. Or is it even worse (I don't have time to check now)? Aren't the parameters that show up in the GUI, the ones which were recorded in the preset, possibly completely different from the ones that will be applied?\nIt seems you don't even want to consider the other approach. What's wrong? Maybe should also ask the mailing list about this? (There might be use cases that none of us has thought of.)\n. Changing the parameters version multiple times is not a good idea, and will add even more confusion. That said, personally I'll continue to use the implementation I suggested and I can only regret that other users that could improve their workflows with these functionalities are not given the chance. I believe you should ask on the mailing list before making such decisions (updating the version), though it's your choice. \n. The jumpiness in the first or second zoom step is due to adjustment of image boundaries to fill the screen. It's a bit annoying, but there is a reason for that. After that it now goes smooth.\nThe jumpiness in the last step to get to 100% zoom was unjustified and fixed by this patch.\n(It also seems there's a slight offset amount for every step which makes the picture slide a little bit, but this is less annoying. I don't know yet where it comes from, maybe the display does not match exactly the requested scale. This is a minor and different problem.)\n. >    colorout.c:423:3: error: unknown type name \u2018bool\u2019\n\nbool force_alpha_copy = false;\n\nI guess you should not introduce c++ code in a file named .c :-)\n. gcc (Gentoo 4.8.2 p1.3r1, pie-0.5.8r1) 4.8.2\nbool requires #include <stdbool.h>\n. Kind notice: commit_params may be called more than once; this introduces a memory leak.\n. Legitimate question, but if SSE is not available, just \"do nothing\" is fine, since the next loop is the \"unvectorized\" version that was only used for the \"remainder\" when SSE is present.\n. The default values to those parameters is what works best. We could easily add configuration widgets, but I'm not sure it's a good idea since there's barely any point in configuring these except for testing. Those are the degrees of the polynomials used for the fit. \n. I don't think it makes any harm, and it helps to read the code and to search for SSE-related instructions inside the code. Those markers are found in other parts of Darktable, and I'm thankful to whoever left them there, because reading the code is easier that way. It's also helpful if you want to voluntarily disable SSE to check that incurred numerical inaccuracies are negligible. \n. Why?\n. ",
    "aurelienpierre": "More accurate profile provided on dev mailing-list with plots and thumbnails.\n. Anyway, basecurves are useless if you are using proper camera color profiles, right ?\nI never used them : if you make photographs in RAW format, I\u00a0guess it's not to replicate camera/manufacturer presets in your editor.\n. That's a bummer, I discovered your soft today, I love the idea of using PDE of chemical diffusion to process digital RAW. What was your problem ?. Why do you use sRGB ? I will see if I can help.. On a side note, @edgardoh and I will need FFTW3 too for the RL deconvolution module.  @edgardoh Thanks a lot for this beautiful piece of code. It works flawlessly for me, I will test it further in the next days. It's a much needed feature, the result is awesome.\nI would be happy to help for the doc.. @edgardoh I see 2 missing features already:\n\nwe can cut/paste masks from layer to layer, it would be great to be able to reuse the same mask on multiple layers\nthe histogram correction in the single layer preview could be automatic so that we don't lose time adjusting white and black levels\n\nI'm still amazed by the abilities of that module though.. Hello Pascal and Edgardo !\n\nall the shapes of a scale on other scales there's the option described by Pascal above: set the merge from slider and all the edits of a particular scale will be applied on the range [merge from .. scale where the shape belongs to] (sorry, I find very difficult to explain what this option does)\n\nBut then, all the shapes are shared between the selected layers, aren't they ? Is it possible to only use some of the shapes on the range ?\n\nYes, is very annoying to set the display wavelet scale button and see a\nblack image, but I couldn't find a condition that I like. Probably the best\none is:\n\nI just would like to map the min intensity of the previewed layer (aka wavelet scale) to 0 and the max to 1.. Ok I see. \nFor the histogram adjustement on layers, maybe I haven't been clear enough. If you record the min value of the luminance over the desired wavelet scale (called min) and the then max value (called max), you can remap the lumimance channel such as L = (L - min) / (max - min). Then, you will automatically get an output between 0 and 1. You don't need default values, it's adaptable.\nAlso, is there a mean to rotate the sample patch without rotating the destination patch ? It could be usefull to retouch hair for example.. > When to do the calculations? Each time the display wavelet scale button is pressed\nYes, as it's just a preview, you could do it anytime for each level, right after the scale computation and just before the displaying on screen. It would make it more readable without having an extra slider. It is a quite standard normalization in signal processing.\nAs for the rotation, I understand. I wonder if the source code of the cropping module could be used \"as is\" here.. Thanks !\nI have retouched a dozen of pictures now, it works very well, the real problem I have is I don't always have a piece of clean texture in the same orientation than the original texture to patch. I think the sample mask rotation would be the last feature to add to have this module work 100 % of the time.. I tested it and I was expecting someting like that for a long time. Although now the scroller on the right edge is redundant.. >  Do you think they should be removed, when the corresponding scrollbar is shown?\nI have neven found the elge indicators usefull, especially since they are not draggable. They just waste 15-20 pix on the edge of the screen.. > The space is used anyway, as this is also where you show/hide the side panels.\nOn the lift and right, I agree, but not on the top and bottom I think.. > On the top/bottom we also have the show/hide panels (filmstrip and header).\nWell, it's not a big deal anyway :-). This gave me 2 errors today:\n(darktable:27863): GLib-GObject-WARNING **: 01:54:56.481: invalid cast from 'GtkGrid' to 'GtkBox'\n(darktable:27863): Gtk-CRITICAL **: 01:54:56.481: gtk_box_pack: assertion 'GTK_IS_BOX (box)' failed\nand, whith scrollbars active in the darkroom, while zooming in, the preview is sometimes swiped under the left panel (shifted), and while zooming out, the picture stays shifted to the left in its frame and leaves a black border on the right (between the edge of the preview frame and the edge of the shifted picture). \nThe behavior in the darkroom is fixed by disabling the scrollbars, while the errors are solved by reverting the commit, so it's specific.. I don't know anybody who uses IOP accels/keyboard shortcuts for modules.\nThey make sense for views and general things, and kind of made sense for modules before multi-instanciation was added. But now, with instances, whatever behavior you choose (apply them on the first on last instance only) defeats their purpose. Besides, in the preferences, it seems there are more accels than keys combinations on a keyboard.\nIf you tell they cause crashes, in addition, and nobody is here to maintain them, why not ditch them at all ? Users will still have presets and views accels.. I have been running this for 2 weeks, no issues. There are some maths changes I\u00a0don't understand in the Anscombe transform, but I guess it's factorization.. I have been running that for 2 weeks, no issues.. I think the font size is a bit too big by default.. I have been using that for 1 week or so, and I don't like it. The text is too big, and overlaps too much on the image whereas it brings nothing new to the UI. The EXIFs can be shown in the left panel if needed, and they rarely are when I'm browsing the lighttable. Sorry.. That sounds sensible.. Everything looks good except for the harder edge of the circle mask : it creates aliasing on the edge, even with lanczos 3 interpolation. I tested it in the exposure module. Does that change only affects the retouch module ?. Some things are broken after this commit. \n\nWhen displaying individual previews of wavelets scales, the black/white levels are not updated when you select another scale,\nThe first higher scale of wavelets shows nothing in the preview at zoom factor < 100 % (no texture, only flat grey). The second higher scale shows nothing at zoom factor < 50 %. Same for the third < 33 %. If this is a feature (or most likely a limitation of the algos), maybe the zoom factor should updated with the wavelet scale preview.. Ok I didn't got the gray bar. Maybe just add an error message when displaying the scale preview at a wrong zoom level ?\n\nSo I would say, for now, the only thing I'm missing in your module is a copy/paste function to duplicate masks from one scale to another (ideally, I would like to share masks without duplication, but I feel it might need more work).\nAn another matter, I would display the mask opacity in % instead of between 0-1, just to stay consistent with the blending modes UI.\n[EDIT] Well, just to be entirely French, thus annoying, it would be nice to be able to edit the tool (healing/clone/blur/fill) associated with a mask after having drawn it. Changing tools regularly makes it easy to set the wrong tool and we have to delete/recreate the mask when it happens. Again\u2026 depending on the amount of work it represents\u2026 \nThanks again !. I'm using it on skin retouch, in portrait photography. Say you have a spot on the face, you want to remove it but not smooth the skin texture too much and you want to keep (some of) the noise to blend it better if you are at high ISO. To do that, I find that using the global scale blending is not accurate enough, so I do it in an iterative way, using the relevant scales (usually, between the scales number 3 to 6). So, basically, I duplicate the same mask on 3-4 non necessarily contiguous scales, sometimes with different opacities. . I did a short video to show you my workflow : https://youtu.be/SenONuZIq2Q. It saves a lot of time if you need to repeat it a lot, depending on the state of what you clean.\nYou can download the RAW + XMP from here :\u00a0https://www.dropbox.com/sh/8wbgbj1tq9dnr7d/AAC7ZBampOELIZRgso5jlKdva?dl=1 Please don't put it into the wild since it's still production work.. Someone is on fire these days\u2026 Nice work Edgardo, again.. That's it ?. Ok, I thought this would lead to some interpolation updates as well. . I did nothing here @PaoloAst. I don't know for the mouse, I'm really not a GUI guy. I'm only playing with equations, that's all I understand.. Please find a full step-by-step tutorial of this module with examples here : https://discuss.pixls.us/t/solving-dynamic-range-problems-in-a-linear-way/9006/63?u=aurelienpierre. OpenCL is now working. > The existing unbreak input profile module is 'designed' just for that - to cope with\n\nsome existing broken ICC color profiles.\n\nAn ICC profile is calibrated on a color chart. These semi-reflective charts have patches with L values ranging from 18 (black) to 96 (white). What happens between L = 0 and L = 18 are extrapolations. In a modern RAW file, from a 10-14 EV of dynamic range sensor, exposed to not clip the highlights, you get 75 to 90 % of your pixels below L = 18. When you feed that to the input ICC correction, you are practically hoping for the best, because at least 75 % of the pixels are outside its validity boundaries. So, yes, you are unbreaking it. The beauty of the log method is you can specifically tweak it to have the average luminance of the non-corrected RAW remapped to the center of the histogram, hence the center of the validity domain of the ICC profile. It consistently gives symmetrical histograms centered on 50 %.\nBesides, here is the current gamma transfer function for gamma = 2.2 (linearity = 0) :\n\nand here is the log version transfer function (dynamic range = 6.7 EV, grey = 1)\n\nIt's not like day and night, nor it is an artistic transformation. It's similar to what you see in the basecurve module, except this is parametric and doesn't give highlights over-saturation. Actually, my first approach was to try reproducting this curve in the basecurve module, and that blew away the highlights.\n\nAlso, i find it kind-of misleading to compare this with video encoding Log profiles (S-log, N-log, etc.).\n\nWell, it's the same function for the exact same purpose : compressing the dynamic range. Ok, there is no destructive encoding in the next step, but that's anecdotal.\n\nAlso, rangecheck: the code needs to cope with any input.  I saw there is some handling for negative values, but i have no clue if that is sufficient.\n\nThe handling of out-of-boundaries values is as follow: \n\n\nfor any input > 2^(-dynamic range), typically that is in [0.00006 ; 0.002], process (input + 0.000061035) and subtract 0.000061035 on the output.\n\n\nfor any input =< 2^(-dynamic range), process 2^(-dynamic range).. Now, the input values are clamped neat and straight to [2^-dynamic_range, 99999]. The gamma version of the unbreak profile uses a lookup table contructed somehow with integers for inputs < 1, I have no idea what's going on in there and there are no comments. Anyway, since no one can take A^b where A < 0 and b < 1, what happens out of these boundaries cannot be the gamma correction advertised in the module. \n\n\nI don't even understand how you end up with negative numbers at that point\u2026 That makes no sense. The black point should be adjusted to avoid that.\nAfter many tests, if I don't clamp the input, I get harsh noise in low-lights. I can tweak it with an offset, but it has to be either a static one leading to side-effects, or a user input basically redondant with the black level from the exposure module.\nThis answer sums it up better : https://discuss.pixls.us/t/solving-dynamic-range-problems-in-a-linear-way/9006/88?u=aurelienpierre. > What comment would you want to see there ^ ?\nThat's what is run. But the coef that are put in the d->table look-up table are constructed like this :\nhttps://github.com/darktable-org/darktable/blob/d99df3190faffffb0c66f813d5d5461ff6b89d37/src/iop/profile_gamma.c#L200-L243\nwhat's going on in there ? I feel this is some kind of interpolation, but I have never seen that before. So I don't get where the gamma function does clamp its input but it has to since the f(x) = x ^(1/gamma) = powf(x, 1/gamma) = NaN for all x < 0. Or maybe it just returns the untouched input where it is negative. But seeing the result it gives in a real image where the black level has been adjusted to produces negatives values, I can tell you it clamps neat and straight.\nThe unclamped example of the exposure module is not relevant here since it is a linear operation defined for all x in R. The same mathematical limitations don't apply.\nThe log profile reproduces the behavior of human vision with the input assumed to be the physical photons energy. It doesn't make sense that this input will be negative or zero, except if we live in anti-matter or in a dark hole. This energy has to be at least small but non-zero. Besides, a sensor records 14-bits integers, and discard the 600 first values or so, so nothing is supposed to be negative or zero in here.\nI have to clamp the input of the log or I get NaN at the output. And if I still return the negative input untouched in the output, I get a discontinuity gap of at least 4 EV between pixels with input =< 0 and pixels with input > 0. These negative values should be corrected prevously in the exposure module, using the black level.\nI tried not to clamp, it made the noise burst :\u00a0https://discuss.pixls.us/t/solving-dynamic-range-problems-in-a-linear-way/9006/83?u=aurelienpierre. The best results I\u00a0got were with the clamping.\nNote that only the input is clamped, for mathematical reasons, not the output. \nAt this point, I would just ask you to compile and test it for yourself and see how it works. I have tested it, other people have tested it, the only problem that arises is a poorly set black point, which is easy to fix in the exposure module.\n. > Now, i have to agree, i'm not sure why, but i was rather sure that /some/ modules were doing this special handling not just for the >1.0 pixels, but for <0.0 too, but i'm not seeing it.\nSo we are on the same page here. A lossy conversion from a negative float to a 16-bit integer seems to be 0\u2026\nHere is comparison between 2 edits I have done on the same picture. First, with the edit with the regular modules from master:\n\nThen a joint use of this module mode and #1734:\n\n. Hi Edgardo,\nThanks for your test. I'm a bit surprised, since I get that module to work in just a few steps. What sort fo artefacts do you get ? Have you followed the tutorial here: https://discuss.pixls.us/t/solving-dynamic-range-problems-in-a-linear-way/9006/63?u=aurelienpierre\n\n\nI managed to get rid of the artifacts, now I can play, but is not that easy to restore the contrast/saturation. OK, that is maybe because of my editing skills, but at least in part I think is because all the things I have done to get rid of the artifacts.\n\n\nKeep in mind that my other PR #1734 is intended to be exactly the next step to this module. With the fulcrum contrast and the power (mid-tones) adjustement, I do 80 % of the editing in 30 s with just 2 modules.. If these out-of-gamut issues happen in low-lights, you need to decrease the black level in the exposure module. That's a drawback of the log, very low luminance values get lowered even more, so you need to add an offset at the input. Which is the black level.. > maybe a label \"you have x pixels out-of-gamut, decrease the black level\nThat would suppose to count the underexposed pixels during the processing loop. I see how to do that in pure C but, in OpenCL, it would need to parse the whole image before or after the processing, so it would defeat the purpose of vectorizing for performance. I have to think about that\u2026\n\nAlso the auto button will be nice\n\nI tried to do that at first, the problem is, as the black level auto-detection is super sensitive to noise (no algo can guess if a low value is noise or a true black), I often ended up tweaking the \"optimized\" auto-computed parameters anyway, so I just removed the full auto mode and went for a trade-off where you give the algo hints of what is black and what is grey. I feel it's better to give that responsibility to the user rather than creating frustration with a partially-working auto mode.\nIn an efficient worflow, you can just drag the left part of the histogram to fix the black point while you are in the unbreak profile module. \nIn a more general scheme and workflow approach, when I did events/weddings photography, everytime I tried to copy/paste basic auto-settings (like exposure and levels) from one picture to another, it never worked well and I always ended up fine-tuning manually every picture. So I rather have an assisted manual mode (with color picker and hints on an head-up display) helping to do individual corrections real fast than an automatic thing that fails, even 30 % of the time.. I have added a full auto button, for the better and the worse.\nI still have to find out in which structure is hidden the roi_in piece so that I can parse it in commit_params function.. I think I have fixed the auto-optimizer. Provided that there is not too much noise, it should consistently remap the Lab luminance between 18 and 96. Could you test it ?. @TurboGit done !. It was src/common/colorspaces_inline_conversions.h that was in conflict, right ? It should be fixed, I have rebased.. Warning : with DNG files, changing the main power value gives either a green or a magenta color cast. Tested with NEF, RAF, ARW and CR2 files, it works as expected.. DNG files work now as expected. I have added the fulcrum contrast and master saturation options.\nIn the pure C variant, just enabling the module gives an unexpected exposure boost. Something is wrong with the Lab <-> ProphotoRGB conversion in C, I can't find what. (I have checked the conversion matrices from 3 sources). Using sRGB fixes the problem for the pure C version (I suspect the gamma conversion does the trick).\nSSE and OpenCL versions behave as expected with Prophoto RGB conversion and everything.\nI have done a bit of lib refactoring. I think rewriting the SSE and OpenCL color conversions as native dot products would give a boost in performance at some point.. Thanks Pascal ! If you compile my master branch, you will get it along with the Log unbreak profile, and both together work really well to recover high dynamic range images.. I have added HSL sliders in addition to the RGB ones, as I requested here https://redmine.darktable.org/issues/11959.\nThis doesn't change the data structure (parameters are still RGB). Editing RGB sliders updates HSL ones, and the other way around.\nI still have a problem of slight magenta shift with the SSE ProphotoRGB conversion, OpenCL and pure C behave as expected.\nI have rewritten SSE color conversion function in algebraic notation instead of SSE intrinsics to improve readability.. > Maybe add a combo with lift/gamma/gain/(all) so it doesn't take so much space on the UI?\nYou mean on the text label ?\n\nAlso, is it possible to have a new group for the entire range (not only shadows/highlights/midtones)?\n\nLike a master hue setting ?. > I mean to add a combo box with those entries that show/hide each group (or all of them if (all) is selected)\nI still don't understand :grin: You want to selectively enable/disable the RGB set of sliders and the HSL ones ? \n\nExactly. It can be added to the combo box above, maybe as a default.\n\nThe problem with that is it would change the maths behind and lose the compatibility with the ACL Color Decision List standard. Technically-speaking, the slope is sort of the master (it's the linear factor), and the first parameter you should set in your workflow. Then, you can come back a bit on it by setting the offset, which, again applies to the whole range but, numerically, weighs more on the low-lights. And as the last step, you fix the power. That's why the mode is called slope/offset/power, in the order you are supposed to adjust the settings.. I have added neutralization color-pickers on each hue slider. The idea is to select a color that should be neutral (grey) and compute the right parameters in the color balance to invert its current hue and neutralize it. The saturation is not always on point though. It's still useful to remove indesirable color casts, due to several lighting sources at different color temperature.. Another improvement here : I have bounded the RGB sliders and corrected them according to the luminance.\nNow, when you edit a RGB channel, the 2 others are updated so that the luminance is not affected. So, the RGB channels control only the saturation and hue, making them fully independant from the factor (which is a luma correction).\nI think that's pretty cool.. Isn't rawspeed listed in the gitignore that it keeps showing up in the commits ?\nI will fix that, maybe add color-pickers for lift and gain factors, and I think we wil be good.. I think it's clean ?\nSo, last changes:\n\nI added a load of comments to explain the maths happening in the optimizers\nI added the optimizer for luma distribution, as promised\nthese optimizers should be a tad more robust in difficult cases (I added constraints)\nI removed the RGB sliders bound (for luma normalization) for the legacy lift/gamma/gain, so people can continue to use it as before. It's still there for the \nI cherry-picked the common lib colorspaces_inline_conversions.h that I optimized, corrected, and made more readable by replacing the SS2 special functions by algebraic operations (following the advice of one Rawtherapee dev, because it seems algebraic operations can be more optimized by the compilator).\nI added the SIMD() parameter for openmp loops\nI added some more info to the labels.\n\nScreenshots:\nHSL sliders:\n\nRGB sliders:\n\nBoth sliders:\n\nDirections to test:\n\nAlways set-up the slope, then lift, then gamma in this order.\nAlways set-up the luma (factors) before the color (RGB/hue/saturation).\nThe factor color-pickers take the max luma in the zone for the slope, the min luma in the zone for the offset, the average luma for the power. Choose your zones accordingly. Once you have set 3 samples (slope/offset/power), you can trigger the \"optimize luma\" optimizer. It will fit the histogram inside the whole dynamic range [0-100 %] and normalize the average luma to 50 %, similarly to the levels but in RGB.\nThe hue color-pickers aim at reverting the color of the samples you give them to neutralize color casts. They take the average color of the zone. Once you have set the 3 samples (slope/offset/gamma), you can trigger the \"neutralize color\" optimizer. The samples should have a neutral color (grey-ish) in real life in low/mid/high-lights (if you take real saturated colors, I don't garantee the result). That's usefull when you have several white balances due to several light sources in the same picture.\nSet the master saturation and contrast in last\nThe grey fulcrum is the luma value that is non-affected by the contrast adjustement. In portrait, use the color-picker to select the whole face and get its average value. Then, the contrast you will add will enhance the shape and features. 18 % Luma = 50 % L(ab) so you should always get 18 % if the gamma/power factor was set properly.\n\nNote that the color-pickers are designed for the slope/offset/power version, as well as the HSL -> RGB conversion and the RGB luma normalization. But they still work fairly for lift/gamma/gain.\nYou will notice that if you try RGB -> HSL -> RGB' conversions on the sliders, for primaries, you will always have an error : RGB = RGB' \u00b1 0.005. That's expected, due to the conversion of color shiftts between a cylindric and a cartesian vectorial space. However, ping me if you get errors >= 0.01, it shouldn't happen.\nEnjoy !. The first issue is a real issue. For the second, you need to click once on the color picker, draw the area, then click again on the color picker icon to validate the color. . The first issue is solved @TurboGit . Actually, it still breaks and I have no clue. The faulty lines are:\nhttps://github.com/darktable-org/darktable/blob/68ca31eb79edb3a6324e1ad19fe5b7516022704c/src/iop/colorbalance.c#L1469-L1472\nThey occur in every color-picker callback and are intended to store the RGB values in a private data structure to be fetched later by the optimizer:\nhttps://github.com/darktable-org/darktable/blob/68ca31eb79edb3a6324e1ad19fe5b7516022704c/src/iop/colorbalance.c#L107-L118\nCommenting these lines fixes the problem, and I absolutely don't see why. It doesn't seem to be an out-of-bound error while indexing the arrays.\nThe errors that arise in gdb always affect other modules (basecurve) or OpenCL kernels cleanups, so I suspect some memory shift.\nHoping it would help, I have added: \nhttps://github.com/darktable-org/darktable/blob/68ca31eb79edb3a6324e1ad19fe5b7516022704c/src/iop/colorbalance.c#L641-L651\nbut it does not.. It depends how I build. With cmake, it seems to work. With build.sh, it fails sometimes.. still outputs, when closing :\n```\nThread 1 \"darktable\" received signal SIGSEGV, Segmentation fault.\n(gdb) bt full\n0  0x00007ffff3e8234c in g_module_close () at /usr/lib/x86_64-linux-gnu/libgmodule-2.0.so.0\n1  0x00007ffff7a7e1af in dt_view_unload_module (view=0x555557817470)\nat /home/aurelien/Documents/Programmes/darktable/src/views/view.c:228\n    iter = 0x555557772580\n\n2  0x00007ffff7a7e1af in dt_view_manager_cleanup (vm=)\nat /home/aurelien/Documents/Programmes/darktable/src/views/view.c:101\n    iter = 0x555557772580\n\n3  0x00007ffff796be61 in dt_cleanup ()\nat /home/aurelien/Documents/Programmes/darktable/src/common/darktable.c:1066\n    init_gui = 1\n\n4  0x00007ffff7a55b41 in dt_gui_gtk_run (gui=)\nat /home/aurelien/Documents/Programmes/darktable/src/gui/gtk.c:1201\n    widget = <optimized out>\n    allocation = {x = 362, y = 12, width = 401, height = 601}\n\n5  0x0000555555554830 in main (argc=, argv=)\nat /home/aurelien/Documents/Programmes/darktable/src/main.c:83\n\n. So it was because I had\ncodepaths/openmp_simd=true\ncodepaths/sse2=true\n```\nin darktablerc. Seems to work now.\n. I don't understand : what crash do you get with colorbalance_cdl() OpenCL ? Both versions work with no error on my side, with the last commit.. @TurboGit I have commented out the faulty lines that store the current color into the private data structure, like that:\n```\nifdef OPTIM\ndt_iop_colorbalance_data_t *d = (dt_iop_colorbalance_data_t *)self->data;\nd->luma_patches[GAIN] = XYZ[1];\nd->luma_patches_flags[GAIN] = 1;\n\nendif\n```\nCan you confirm everything works that way so that we ensure these are the true offenders ?. I think I have found it.\nThe private data structure (dt_iop_colorbalance_data_t *)  is stored in (dt_dev_pixelpipe_t *)pipe->data. Here, I'm writing in (dt_iop_module_t *)self->data which is something else, hence the memory corruption.\nBut thanks to the barely-commented and non-documented sourcecode of dt, I have not found how to access the pixelpipe from the module structure.. > So you've found the offenders :)\nThat only took 18h :roll_eyes: \n\nNo more crashes but I cannot run the optimizer.\n\nthat's normal, it's disabled for debugging. I still need to figure out how to reach the pipe data from the module.. Ok, now I store the data in dt_iop_colorbalance_gui_data_t so it should be clean !!! :smile: . Hi,\nI don't know if this is this commit or my OpenCL settings, but it seems that the retouch module is crashing sometimes in OpenCL mode.\nWhat seems to be the source is having several masks overlapping, mixing correcting and blurring masks makes it worse. It doesn't happen everytime, but when it does, the terminal says could net enqueue kernel [retouch] : -4. Also this error makes the whole desktop UI freeze hard (hard reboot needed).\nNo problem in CPU mode.. I'm still figuring it out, it's not systematic. The kernel fails only after several minutes of adustments in the darkroom, and the big freeze happens only during picture export.. > BTW, Is that only since the continuous add implementation in this PR?\nIt's only since I have merged this PR with my dt's master fork that I have had this error, but I haven't used the Retouch module enough before to be 100 % sure it wasn't there already.\n\n-4 means out of resources, that can happen, but for a given image it should happen every time it is exported,\n\nThe -4 error happens only during the darkroom edits and after some time, so the memory thing is the first thing I thought of. But this is a non-blocking error (the pixelpipe fallbacks on CPU, everything is slower but works). I have a 4 GB vRAM GPU and 32 GB of RAM, so I reset the OpenCL settings in darktable.rc first, and saw it didn't change things. \n\nAlso that message don't necessarily means that the retouch is crashing dt,\n\nYes, removing one of the 2 retouch instances I used fixed the crash during export. \n\nI take that a backtrace is not being generated, so try to generate one.\n\nI will try, but as it makes the whole OS crash (even the consoles), I'm not sure what I will be able to do. I will try to reproduce a faulty editing first.\n. I haven't been able to reproduce so far and I didn't kept the faulty XMP file as I needed to edit the picture asap. It happened only on 36 Mpx Nikon RAW files with a heavy stack of edits, so this might have been bad luck while pushing the hadware too far. But it still seems odd since I have a beast of a computer.. Well, there is something I don't understand here. I have tested it on previously edited pictures, I didn't see anything weird.. The current stack is:\n202 lens\n188 retouch\n173 spots\n159 exposure\n144 tonemap\n130 denoiseprofile\nThe proposed one is:\n202 exposure\n188 tonemap\n173 lens\n159 denoiseprofile\n144 retouch\n130 spots\nThe retouch module has been merged 3 weeks ago, so I doubt a lot of people will be affected with a lot of edits. And both modules rely on dynamic patches, so their exposure will be updated similarly on the source and target patches.\nNonetheless, I tried editing the same picture with retouch, spots, and tonemap modules and diff the old and new PFM files with Image Magick:\ncompare -metric RMSE -verbose old.pfm new.pfm -compose src diff.png\nThe RAW file is a 36 Mpix NEF from a Nikon D810 and the lens is a Nikkor AFS 85mm F1.8G fully corrected (vignetting, CA, distortion), at ISO 180.\nWith tonemapping enabled:\nChannel distortion: RMSE\n    red: 3778.72 (0.0576596)\n    green: 3155.78 (0.0481542)\n    blue: 2879.02 (0.0439311)\n    all: 3292.74 (0.0502441)\nWith tonemapping disabled:\nChannel distortion: RMSE\n    red: 177.957 (0.00271545)\n    green: 255.788 (0.00390308)\n    blue: 253.788 (0.00387255)\n    all: 232.023 (0.00354045)\nLooking at the position of the absolute error, the most affected pixels are in blown highlights (hair on this picture), noisy/black areas, and with tonemapping disabled, at the very center of the picture (which might have to do with the lens correction). The patched areas or not affected at all (either with spots or retouch modules):\nDiff mask with tonemapping:\n\nWithout tonemapping:\n\nSo, seing the RMSE error magnitude (0.3 %) and distribution without the tonemapping, I think we are mainly dealing with rounding errors here. I don't get the difference between tonemapped/non-tonemapped versions though, but it's still a valid option to force it before the lens correction for retro-compatibility.. Well, it's difficult to test every configuration there, but I blended the spot removal on the input g channel so that some spots are partially masked, some totally masked and some unmasked at all.\nThe RMSE stats increase a bit and the diff mask shows no difference at all on the spot-corrected areas.\nChannel distortion: RMSE\n    red: 186.214 (0.00284144)\n    green: 267.298 (0.0040787)\n    blue: 264.81 (0.00404074)\n    all: 242.382 (0.00369852)\n\nAgain, the error seems to increase only on blown highlights (hair with chromatic aberrations).\nI feel like holding this change would penalize the majority of users and pictures for the sake of preserving a retro-compatibility that could be compromised only on some corner-cases.. I understand what you mean, but I hardly see how it is relevant here. The only modules that could be affected by this change are those between exposure and lens correction, namely the spots and retouch modules. The lens correction doesn't perform any static thresholding (as you show here with the white level, that's an input-independant operation), but only proportionnal local corrections (input-dependant), and at a magnitude of 1.5 EV max. I have shown that the RMSE are neglictible and the differences are not even on the masked areas.\nThe exposure module performs a static operation: the black level is an offset, independant from the input. That's why it should be put at last. But if you take the block { lens ; spots ; retouch ; tonemap }, no static offset is applied in it (exposure correction -> multiplications -> distributive and commutative), so the modules are mutable inside that block. Besides, the vignetting correction only flattens the exposure on the edges, so whatever blending mask comes after will just have a more even input.. > Did you just completely skip everything i wrote about different input => different parametric blend => different mask ==> different output image?\nI did not. But test it in real life, e.g. not at 18 EV and with the real vignetting correction. The difference it makes is numerically insignificant and visually unnoticeable.. Because the black level in the exposure module is messing with the vignetting correction, and the gamma correction in the unbreak input profile module makes it blow, resulting in positive vignetting. The only problem in this stack is the exposure module and its only static setting in this part of the pixelpipe. The lens correction is harmless.. I think you don't understand. But sure, keep it like that for another decade : the more you wait, the easier it is to fix. Have a nice time with you pet software, I'm actually doing photography, and my fork works, so I'm out of here.. >  In it's current form, this is a breaking change, as i have tried to repeatedly demonstrate.\njust fucking look at the maths going on in these modules, you will understand that the only immutable part is the black level because it's a static offset. I don't care about XMP order, mathematically, it's the same. Even with masks and parametric blending, it's still safe on 85 % of the picture at least.. I think using one of mine's or rawfiner's denoising styles will produce this issue quite consistently. Copy/pasting the editing from one image to another with such modules is almost garanteed to produce it.. Sorry, I didn't notice this one got trapped in the commit. Now, it's clean\u2026 I hate git.. I will close that for now. I think I am re-inventing the wheel here. It would be more relevant to clean-up the hard-coded standard spaces in dt (Adobe RGB, sRGB, REC 709 / 2020), replace them by ICC profiles with ICC v4 support. I will try to add https://github.com/ellelstone/elles_icc_profiles.git as a submodule and ship her profiles instead.. So far:\n\n. I have run it for 2 days, no issue.. I'm playing with it as well. Works great so far.. @rawfiner you can use 3 ` to enclose the code blocks.. It crashes when using old presets and usually doesn't display the existing profile when available (the combobox is empty) in wavelet and non-local means :\n```\n(gdb) bt full\n0  0x00007ffff7963415 in catmull_rom_val (n=7, x=, xval=, y=0x7fffffffd4c0, tangents=0x0) at /home/aurelien/Documents/Programmes/darktable/src/common/curve_tools.c:567\n    ival = <optimized out>\n    m0 = Python Exception <class 'gdb.MemoryError'> Cannot access memory at address 0x14:\n\n1  0x00007fff80426ef1 in dt_draw_curve_calc_value (x=0.000273924117, c=0x555559258b80) at /home/aurelien/Documents/Programmes/darktable/src/gui/draw.h:214\n    xa = {-1, 0, 0, 0, 0, 0, 1, 0, 1.99384797e+13, 3.0611365e-41, 0, 0, 1.99384797e+13, 3.0611365e-41, -1.74169807e+32, 4.59163468e-41, 2.04745789e+13, 3.0611365e-41, -1.76523422e+32, 4.59163468e-41}\n    ya = {0, 0, 0, 0, 0, 0, 0, -3.8272803e-31, -nan(0x7fd5d0), 4.59163468e-41, 0, 0, 0, 0, 4.35041532e+14, 3.0611365e-41, -1.0507078e+33, 4.59163468e-41, 2.80259693e-45, 0}\n    val = <optimized out>\n    ypp = 0x0\n    inset = <optimized out>\n    allocation = {x = 0, y = 32, width = 303, height = 227}\n    height = 215\n    width = <optimized out>\n    self = <optimized out>\n    c = <optimized out>\n    ch = <optimized out>\n\n2  0x00007fff80426ef1 in denoiseprofile_button_press (widget=, event=0x7fff4c0030c0, user_data=) at /home/aurelien/Documents/Programmes/darktable/src/iop/denoiseprofile.c:2498\n    inset = <optimized out>\n    allocation = {x = 0, y = 32, width = 303, height = 227}\n    height = 215\n    width = <optimized out>\n    self = <optimized out>\n    c = <optimized out>\n    ch = <optimized out>\n\n3  0x00007ffff653d15b in  () at /usr/lib/x86_64-linux-gnu/libgtk-3.so.0\n4  0x00007ffff509810d in g_closure_invoke () at /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n5  0x00007ffff50aafce in  () at /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n6  0x00007ffff50b301f in g_signal_emit_valist () at /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n7  0x00007ffff50b409f in g_signal_emit () at /usr/lib/x86_64-linux-gnu/libgobject-2.0.so.0\n8  0x00007ffff6684b04 in  () at /usr/lib/x86_64-linux-gnu/libgtk-3.so.0\n9  0x00007ffff653a1ce in  () at /usr/lib/x86_64-linux-gnu/libgtk-3.so.0\n10 0x00007ffff653c2a8 in gtk_main_do_event () at /usr/lib/x86_64-linux-gnu/libgtk-3.so.0\n11 0x00007ffff604d765 in  () at /usr/lib/x86_64-linux-gnu/libgdk-3.so.0\n12 0x00007ffff607df82 in  () at /usr/lib/x86_64-linux-gnu/libgdk-3.so.0\n13 0x00007ffff6c5f287 in g_main_context_dispatch () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n14 0x00007ffff6c5f4c0 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n15 0x00007ffff6c5f7d2 in g_main_loop_run () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n16 0x00007ffff653b385 in gtk_main () at /usr/lib/x86_64-linux-gnu/libgtk-3.so.0\n17 0x00007ffff7a5518a in dt_gui_gtk_run (gui=) at /home/aurelien/Documents/Programmes/darktable/src/gui/gtk.c:1242\n    widget = <optimized out>\n    allocation = {x = 369, y = 19, width = 375, height = 575}\n\n18 0x0000555555554830 in main (argc=, argv=) at /home/aurelien/Documents/Programmes/darktable/src/main.c:83\n```. What would be sick here would be to compute the location of the same-sized patch that has the maximum similarity with the destination patch. I'm dreaming out loud but\u2026\nIs right-clic already assigned ? It seems indeed more practical, since not all mouses are born with a middle button.. > BTW, Aur\u00e9lien better to no commit the fr.po in a PR as this file is almost fully changed every time and so there is big chance that we get conflicts.\nOk, I thought it would help. Thanks for the merging.. Thanks @edgardoh !\n\nbut it would be nicer if values are updated when the user finish drawing the area\n\nI don't know, I really don't like having values updated as soon as I draw stuff and before I'm done drawing, especially with huge RAWs. But state buttons are a good idea, I have to check how to do that.. > Now if I'm not happy with the results I have to push the button again, draw the area again and push the button once again, and so on... what I propose is to draw the area, values are updated, if I draw another area values are updated again, etc.\nhmm I have no idea how to do that.. > If you don't mind I can give it a try, I'll probably have some time until I get an answer to my question on pixl.us\nno problem. Thank you !. I'm testing that right now, how/where is it supposed to work ?. I see now. It's really nice :grinning: . I don't know where to dump that (maybe we should enable Github issues tracker), but I have a small problem with the drawn masks in the retouch module, in healing mode:\n1. request the brush tool\n1. adjust the size of the brush to be really small\n1. begin to paint : the size is automatically increased as soon as we click. The only way to get very fine brush lines is to resize the mask (Shift + Scroll) after the drawing.\nAlso, the option \"show masks\" in the retouch module doesn't display the drawn masks. That's strange. I get that output:\nrt_process_forms: missing form=1867975264 from array\nrt_process_forms: missing form=1867975360 from array\nrt_process_forms: missing form=1867975808 from array\nrt_process_forms: missing form=1867976032 from array\nrt_process_forms: missing form=1867976544 from array\nrt_process_forms: missing form=1867976992 from array\nrt_process_forms: missing form=1867979936 from array\nrt_process_forms: missing form=1867980384 from array\nrt_process_forms: missing form=1867980704 from array\nrt_process_forms: missing form=1867981056 from array\nrt_process_forms: missing form=1867981152 from array\nrt_process_forms: missing form=1867981344 from array\nand also:\n[opencl_retouch] couldn't enqueue kernel! -4\nbut I'm pretty sure the OpenCL error is not related.\n. Ok, I found the culprit: the brush gets resized when \"smoothing of the brush strokes\" is set at medium or high, in the preferences.. But changing back from low to medium seems to solve the issue. Weird. So it was something in the settings.. speaking of which, @edgardoh, I have another editing stack that makes the whole OS crash with OpenCL at export time:\nPicture: https://www.dropbox.com/s/jijut3baqifvhe5/mckayla-keiferhunnifordphotography.NEF?dl=0\nXMP: mckayla-keiferhunnifordphotography.NEF.zip\nExported without OpenCL:\n\nDisabling the 2nd instance of retouch fixes the crash. Also I always get an OpenCL error -4, which is weird with 4GB of GPU RAM whereas all the others kernels work.\n. > You'll have to be more specific on how to duplicate it.\nJust export the picture in JPEG on the disk, with the XMP stack provided.. It seems that the crash was related to the OpenCL masking thing you mentionned elsewhere and solved by #1770. \nHowever, on the first retouch module (with gaussian blur patches), I always get:\n340,530509 [dev_pixelpipe] took 0,165 secs (0,210 CPU) processed `retouche 1' on GPU, blended on GPU [export]\n[opencl_retouch] couldn't enqueue kernel! -4\n347,314161 [dev_pixelpipe] took 6,784 secs (14,076 CPU) processed `retouche' on CPU, blended on CPU [export]\nThe retouch 1 instance only contains healing spots.. > But to the point, -4 is out of resources, so it depends on the resources\nI know. I wonder if others get the same error on the same picture + XMP. Out of ressource on a Nvidia Quadro with 4 GB RAM seems suspicious to me, that's all.\nI don't know exactly what the memory footprint of the IOP is, but 36 Mpx \u00d7 4 channels \u00d7 32bits \u00d7 6 wavelets levels = 3456 MB. + 300 MB of headroom (set in darktablerc), it's still < 4043 MB.. Ok I have found it.\nI run Ubuntu 18.04 with Gnome desktop. Using Gnome + Xorg, Xorg takes at least 1066 MiB of vRAM by itself and dt exports this picture in 23 s, due to the fallback on CPU for retouch and equalizer.\nRunning Gnome + Wayland takes barely 71 MiB or vRAM, dt doesn't fallback on CPU and exporting this pictures takes 13 s.\nSo, Xorg + Gnome + Ubuntu 18.04 are a big pile of garbage with a lot of caching and overhead.\nIf I remember correctly, you run XFCE desktop, so I think it explains why you don't get the same issue.. I named it \"legacy\", not to discard it, but because \"/lift/gamma/gain sRGB\" may not fit in every UI. I don't think it should be abandonned. It is still usefull, with the HSL sliders, to quickly grade an image. Prophoto RGB handles the saturation differently, especially in the reds. Maybe you want me to change the name to something more appealing ?. So I have changed the modes to:\ndt_bauhaus_combobox_add(g->mode, _(\"lift, gamma, gain (ProPhotoRGB)\"));\n  dt_bauhaus_combobox_add(g->mode, _(\"slope, offset, power (ProPhotoRGB)\"));\n  dt_bauhaus_combobox_add(g->mode, _(\"lift, gamma, gain (legacy, sRGB)\"));\nIs that ok ?. Yes, it's normal. When adding contrast, what it does actually is lighting greys > fulcrum and darkening greys < fulcrum. The fulcrum is the grey that is not affected by the correction, and sets the transition point. . I know what's happening. I will fix that. Thanks for the report.. Does it fix the crashes during building on windows ? \nTested on Linux, doesn't seem to break anything.. The original code of the colorbalance used the const that way, and I found that strange too. When you define const float4 o, if you later do o = whatever, it throws an error. But if you use the channels of o like o.x = whatever or o.xyz = whatever, it's ok. I don't understand either.\nAnyway, writing OpenCL is very close to writing pure maths: I have only seen this level of abstraction in linear algebra programs (Matlab or Python Numpy), so I guess C is only an interface to call Assembly or something.. What's the option to politely suggest GCC to use AVX if available ?. That's strange, because, from what you say, compiling a Release build should already use AVX instructions, and yet, adding the -mavx2 gives me a 17 % speedboost. . It would be good to have it on other distros as well.. I have already thought about that, but I think it would be better to ship 2 or 3 different CSS templates (dark, neutral, light), and be able to select them from the preferences, rather than to hack just the background color value from the code. Last year, the hardcoded GTK colors were specifically removed from the source code.. I have nothing against it, but having to edit hidden options, one by one, in darktablerc defeats the purpose of #1745, which aims at making things easier for non-technical people.\nWould it be difficult to expose the settings in the modules GUI ?. Here is the order I proposed in #1745 translated in this approach :+1: \nplugins/darkroom/group/base curve=1\nplugins/darkroom/group/bloom=2\nplugins/darkroom/group/channel mixer=3\nplugins/darkroom/group/chromatic aberrations=4\nplugins/darkroom/group/color balance=2\nplugins/darkroom/group/color contrast=3\nplugins/darkroom/group/color correction=3\nplugins/darkroom/group/color look up table=3\nplugins/darkroom/group/color mapping=3\nplugins/darkroom/group/color reconstruction=4\nplugins/darkroom/group/color transfer=3\nplugins/darkroom/group/color zones=3\nplugins/darkroom/group/colorize=3\nplugins/darkroom/group/contrast brightness saturation=2\nplugins/darkroom/group/crop and rotate=1\nplugins/darkroom/group/defringe=4\nplugins/darkroom/group/demosaic=1\nplugins/darkroom/group/denoise (non-local means)=4\nplugins/darkroom/group/denoise (profiled)=4\nplugins/darkroom/group/dithering=4\nplugins/darkroom/group/equalizer=2\nplugins/darkroom/group/exposure=1\nplugins/darkroom/group/fill light=2\nplugins/darkroom/group/framing=5\nplugins/darkroom/group/global tonemap=2\nplugins/darkroom/group/graduated density=1\nplugins/darkroom/group/grain=5\nplugins/darkroom/group/haze removal=4\nplugins/darkroom/group/highlight reconstruction=4\nplugins/darkroom/group/highpass=5\nplugins/darkroom/group/hot pixels=4\nplugins/darkroom/group/input color profile=1\nplugins/darkroom/group/invert=1\nplugins/darkroom/group/lens correction=1\nplugins/darkroom/group/levels=2\nplugins/darkroom/group/liquify=5\nplugins/darkroom/group/local contrast=2\nplugins/darkroom/group/lowlight vision=3\nplugins/darkroom/group/lowpass=5\nplugins/darkroom/group/monochrome=3\nplugins/darkroom/group/orientation=1\nplugins/darkroom/group/output color profile=1\nplugins/darkroom/group/perspective correction=1\nplugins/darkroom/group/raw black/white point=1\nplugins/darkroom/group/raw denoise=4\nplugins/darkroom/group/retouch=5\nplugins/darkroom/group/rotate pixels=1\nplugins/darkroom/group/scale pixels=1\nplugins/darkroom/group/shadows and highlights=2\nplugins/darkroom/group/sharpen=5\nplugins/darkroom/group/soften=5\nplugins/darkroom/group/split toning=3\nplugins/darkroom/group/spot removal=5\nplugins/darkroom/group/tone curve=2\nplugins/darkroom/group/tone mapping=1\nplugins/darkroom/group/unbreak input profile=1\nplugins/darkroom/group/velvia=3\nplugins/darkroom/group/vibrance=3\nplugins/darkroom/group/vignetting=5\nplugins/darkroom/group/watermark=5\nplugins/darkroom/group/white balance=1\nplugins/darkroom/group/zone system=2\nplugins/darkroom/group_order/4=2\nplugins/darkroom/group_order/3=4\nplugins/darkroom/group_order/2=3. @TurboGit I'm exhausted for now, I will see that later.. Please hold on, before merging, I think I just found a more efficient way to color-grade. I might update the styles accordingly.. All good now.. Even if there is no reproductible bug, that PR is just good practice : iterable indexers should be of type size_t, for all the reasons stated above and also for performance. I see nothing harmless here.. I can actually see a use for that.. The crop and rotate will still be after liquify though. That PR is not critical but could make the edge-preservation of pictures better.. @rawfiner I'm assuming the central pixel was the top of a gaussian distribution. Since you put it at a null weight, did you normalize the gaussian window so the sum of its elements is still 1 ?. @rawfiner inside a patch, the pixels don't have a varying weight depending on their position from the center ? Usually the patches are 2D gaussian windows convolved on the picture as a correlation method. Convolutions need normalized kernels. I don't have the brainpower to look at that yet, but I think the patches need to be normalized to account for the loss of the central pixel to avoid numeric instabilities.. > One question, do you foresee a fix for the LittleCMS case?\nYes, I'm working on it too, but it won't be that easy.. > So the actual circuitry in your code is wrong. Hope this helps.\nYes it does, thank you very much !\n. as of now, the XYZ conversions are fixed, in the graph and in the labels. The histograms are still not log and always Lab even when using XYZ or RGB. Everything should be working now. I have removed the histograms from the view in RGB and XYZ mode since they are valid only for Lab. Also, they won't be shown in log-log and log (x) scales, because they need to be rescaled. But these 2 issues are non-trivial to solve, and the linear modes work as before.. @edgardoh there are 3 color pickers variants : module input, module output, pipe output. In-module default is to take the input of the module, that's what colorbalance and log do.. @rawfiner I don't have time to follow all your adjustments (too busy working in my own features, sorry), but non-local means are intended to work on textures (repetable patterns), so providing examples of plain surfaces images doesn't help much to evaluate the efficiency of the code. . @TurboGit It comes as an addition to gaussian blur within the blending parameters, and works when you have semi-transparent masks (parametric and/or drawn). Using ligthness, contrast, and blur radius, it allows you to refine masks edges. It's quite awesome actually.. @TurboGit \nthe feathered mode only works with semi-transparent regions (opacity < 100 %).\n\nthe mask blur controls the spread of the edge detection\nthe mask brightness controls how much you retain or exclude the outside of the mask\nthe mask contrast controls the sharpness/feathering of the edges of the mask.\n\n@rabauke I'm not sure the sliders labels are super clear there. I would to go for:\n\nmask edge detection radius\nmask edge offset\nmask edge contrast\n\nI tested it today, works perfectly. Thanks !. Thanks @cryptomilk . Just out of curiosity, what was broken ? @cryptomilk . @rabauke as you see, tone equalizer was my first idea (and the name of the branch). But it is not really an equalizer (which implies having a setting for each frequency). Filmic curves are a well-known thing in the imaging industry (just google it, 72600 results) so I would prefer to keep it that way.. @TurboGit if you give more room to highlights, that means you have to compress the shadows, isn't it ? What it does is moving all the control points of the curve on the x axis. Positive % is moving to the left (compress the shadows, decompress the highlights), and the other way around. The effect of the decompression is not obvious if you have set the white point in the log tone-mapping too far (being over-conservative). Also, that's the behaviour you get with monotonic and centripetal splines, but cubic spline blow in your face once in a while, and you get sometimes the opposite of what you asked (that sayed, the contrast is gorgeous when set right).. So I get the error is:\n[  537s] In file included from /home/abuild/rpmbuild/BUILD/darktable-2.5.0~git844.47c68b30b/src/iop/filmic.c:25,\n[  537s]                  from /home/abuild/rpmbuild/BUILD/darktable-2.5.0~git844.47c68b30b/build/src/iop/introspection_filmic.c:51:\n[  537s] /home/abuild/rpmbuild/BUILD/darktable-2.5.0~git844.47c68b30b/src/common/sse.h:17:10: fatal error: xmmintrin.h: No such file or directory\n[  537s]  #include <xmmintrin.h>\n[  537s]           ^~~~~~~~~~~~~\n[  537s] compilation terminated.\n[  537s] make[2]: *** [src/iop/CMakeFiles/filmic.dir/build.make:71: src/iop/CMakeFiles/filmic.dir/introspection_filmic.c.o] Error 1\n[  537s] make[2]: Leaving directory '/home/abuild/rpmbuild/BUILD/darktable-2.5.0~git844.47c68b30b/build'\n[  537s] make[1]: *** [CMakeFiles/Makefile2:4190: src/iop/CMakeFiles/filmic.dir/all] Error 2\n[  537s] make[1]: *** Waiting for unfinished jobs....\nThe library  seems to be missing on you system, which is super weird because that dependency was introduced in d99df3190f (Tobias Ellinghaus 2017-09-12 22:39:39 +0200  17) and is used also in common/inline_colorspaces.h, which is used multiple times in IOPs.. So how did that not break before ? I didn't add that lib.. ahhhh my bad, precompiler stuff:\n```\nifdef SSE2\ninclude \"common/sse.h\"\ninclude \n``` \nI fix that in 5 min.. It's my code, and thanks to darktable extensive documentation, I manage to make it work on my system, thanks. \nPlease see #1817.. I'm equipped to test 4K, but the timeframe is becoming narrow.. I think it's the same in the color balance and in the profile_gamma. That's new.. The intended use-case of the auto-tune buttons is to have a one-click setting to get a readable picture, while being able to retake full manual control if needed. Having a color-picker for that is redundant with the separate color pickers and defeats the purpose of an all-in-one quick optimizer.\nI noticed the issue with the image turning white, that's only since a couple of days, so maybe someting was changed in the color-picker API.. > It's not: the color-picker would chose the whole image and be OK by default. There would be no need (but a possibility) to actually chose an area of the picture. It'd also be a 1-click setting.\nok then.\n\nActually, currently it's already a 2-clicks settings since you get \"wait for the preview to be updated\" on first click.\n\nI really don't understand what's going on with the dt_dev_reprocess_all(self->dev). Is that an asynchronous function ? Why aren't we able to force it to execute and finish before grabbing the picker's reading ?. >  I tried putting the rest of the code in process but it depends on the pipeline used (SSE Vs normal Vs OpenCL). It should work if you duplicate the call in all the process variants. If we switch to a real colorpicker this won't be needed anyway.\nWhat code did you put there ? process() functions should not contain any GUI stuff nor parameters settings. process can be called from darktable-cli with no graphic environnement, and it's not good to set parameters in there. If you need to compute intermediate parameters, that should be done in commit_params().. > You really might want to start using git rebase :/\nI know, but you got your fix in 8 minutes.. > Actually, in color balance, I think the optimizers are a bit more complex: they were using previously selected areas using the 3 pickers. So it was probably to keep them as normal buttons. No time to investigate more, sorry.\nYes indeed. What have you done to my baby ? :rofl: . it seems to work on my side.\n\nNot sure it's really a good idea from the UI point of view, it's really hard to understand how the buttons work without looking at the code :-\n\nthat's because there is still no doc on that. The way I designed it was: have a quick fallback for 80 % of the easy cases, then unclutch the auto mode when it fails. So, the button triggers a full-picture guess when user lazy, and gets whatever the user feeds it otherwise.. The grey slider does not control the curve, it's a pre-amplification of the signal. The whole interface is just intended to control put the nodes on the graph in a parametric way, it would be redundant to control the nodes graphically and would mess up the parameters.. Just to give some more details, the purpose of this module is to build automatically a tonecurve with parameters precomputed from the output of the log and some \"human-readable\" inputs in order to remap the grey level to a precise value and compress the bounds of the dynamic range.\n\nI kind of remember that it was more effective in previous version. No?\n\nIt's actually more effective although the effect is less dramatic.  :grinning:  Previously, the saturation affected the whole luminance range, which is bad because we don't want to touch the linear part of the curve (where the saturation is ok). Now, it only affects the extreme luminance, by pushing them towards pure black and pure white, as film does. This is arguably more pleasant, but more importantly avoids any gamut clipping (saturated and very bright/dark areas are the first to clip). So you need to test on very bright skin tones, for example, it will look a bit like Kodak Portra 160 NC.. @TurboGit No problem.. \n@TurboGit, on the left, saturation at 1000 % (max). On the right, at 150 % (almost minimum). Notice how the shadow under the chin is less redish and the skin tone more natural (less yellow) in highlights on the right. On the left, it feels as if the woman had put too much fundation. You would need to apply Adobe RGB profile on the pic to have true colors though.\nWhole image at 150%:\n\nSame at 1000%:\n\n. @moy you should try using more dynamic range by pushing the black to the left, or push the saturation te the right to desaturate less. This effect is to be expected sometimes, that's why the desaturation is not automatic.. could you send me the RAW to contact \u00e0 aurelienpierre point com ?. @moy ok, I have to find a more robust estimator for the second order derivative upper bound. It's a normalization issue.. > Hmm, not sure that this has worked out. I still cannot see the parametric masks. Legacy parametric masks seem to be gone also when importing legacy history stacks. I don't want to test it too much with my work as I fear to lose all edits.\nsame here. The drawn masks are in the list, but the modules don't use them and the blending options are reset. I understand. Film has non-trivial effects for users used to digital. It depends a lot on the image, really. Some have no visible effects until you get below 5-10 %, for some others you have to get around 20-50 %. The most important part is it should follow the log dynamic range and desaturates progressively at the bounds.. @TurboGit and @moy you have to use color pickers in lowlights and check the a and b values.. I don't know which commit is messing up here, but I have lost all the masks and blending options done with previous versions of dt.. > Which version? I have fixed that in commit 15ebdaa.\nAh. Seems to work now but I have lost the editing history on one picture, and I'm unable to reimport it from the XMP embedded in the JPEG file.\n[edit] nevermind, for some reason the XMP was not included in the JPEG (weird). Just my 2 cents here, but we have to draw a clear distinction between an efficient UI (= allowing quick setup) and a clear UI (= allowing easy understanding of what's going on).\nHaving hidden sliders in drop-down, toogle boxes or sub-menus might seem nice to declutter the interface, however, it adds more steps to access the settings. It's the metaphor of the aircraft cockpit\u2026 Yes, you have a lot of knobs but they are immediately accessible. It took me less time to set up an autopilot in an A-340 than what it takes me to set up a consumer GPS.\nAt the end, I believe in documentation, not in simplification.\n\nWhile they will understand what \"blur\" means the complete set of options is so much that many will not even dare to tes\n\nLet's not take users for dumb numbs. They will understand what is explained to them.. > There are probably good reasons for the way how cockpits are designed and how consumer GPS devices are designed.\nYes, they are designed for lazy fools who don't want to read the manual. So it has to be \"intuitive\", but intuitive for whom ? I dislike intuitive, it's how you end up with the ribbon menu in Microsoft Office. By trying to make complicated things more simple, they ended up making simple things more complicated.\ndarktable is complicated, there are lots of options, advanced features, so just make it rational, don't even try to make it simple, and write a full documentation instead. It's Linux, not Windows.. No problem.. That's very interesting, I was working on the color spaces API to allow the modules to work in ACES RGB (https://github.com/aurelienpierre/darktable/tree/next-gen) so I will merge my branch with yours and continue the color sanitization.\nAlso, a few notes: \n\ngamma-corrected RGB are bad working spaces to push pixels,\nwhat is the RGB space you name \"linear RGB\" ?\nRGB spaces should be merged between colorspaces.c and colorspaces_inline_conversions.h but I propose to take over from here (I have merged white points already).\nI plan on adding ACES P0, P1, ACEScc, ACESgc, and CIE RGB.\n\nalso, if you look at my branch, I have made stupid things with Lab that need to be reverted before going further.. @edgardoh I will focus on the next release (doc and stuff) for now. As soon as it's done, I will take a look at your work and merge it with mine. \nIn an ideal case, colorin and colorout take whatever is fed to them, and could even act as a pass-through (although editing in camera RGB space sounds like a bad idea, I'm still curious to try it).\nAt some point, it would help to have an option to reset the pipe order as the legacy, for example to apply presets.\n\n-It is very difficult to add a new colorspace, something more generic should be done here.\n\nGenerally speaking, color spaces conversions are matrix products. Except for Lab and derivatives which do a piece-wise x\u00b3 function on top. So, RGB and XYZ transformations can use a generic matrix product, using a general API that takes the right matrix as an input, but the Lab conversions will be a pain and likely suck all the performance. I still wonder if BLAS could be a good option to optimize the RGB transforms/matrix products decided at user level (stuff you can't optimize at compilation time).\nAny way, it seems very promising.\nAlso, for some doc on color workflow: https://acescentral.com/t/aces-primer-glossary-and-quick-start-guides-get-up-and-running-with-aces/1433. What would be useful here is to know what in particular could break, and what to specifically test.. I tested it today, it's awesome ! Although the database update took 1h30 and did not finish (the CPU running at 12 % , so I guess SQLite is not multithreaded\u2026). . I have like 30000 pictures I think, about 3.6 MB of DB. I have retried several times from different backups.. No crash, no message, it just went on for a long time with dt running in background but not showing any window.. Histogram in log will be a nightmare to implement (you need to log-encode the image before you count the pixels and put them in the bins).\nAlso, the RGB curves have their LUT built assuming they are Lab (so UI 50 % = middle grey), and then, the LUT are converted to RGB (so middle grey = 18 % internally). Indeed, the behaviour is as expected but the controls are weird. I think the other softwares I have tested put the middle grey at 50 % also for the RGB curves, so I think it works.. Sounds good to me, thanks !. Yes, I saw the issue. I will fix that today hopefully. Good idea.. I will try to find a better option. The thing is some real users have asked to see the nodes. So I don't know if @upegelow is speaking of real users-expressed expectations or of what he thinks they might expect, but it seems we have a choice to make here. (And I would be very careful when imagining what users want, because we don't have a marketing service to collect user surveys\u2026)\nWhen the parameter are properly set, 5 nodes are available on the graph. When the parameters are inconsistent, the software removes the 1 to 2 invalid nodes. So, the nodes are yet another debugging tool to understand how the parameters affect the curve.\nAs for the representation of the nodes, what about filled/plain circles instead of the hollow ones ? So that hollow = edit, plain = read-only.. > If possible, a tooltip when hovering the curve with the mouse saying e.g. \"transformation applied to the image, use the cursors below to edit\" would be cool too. I don't think we need much to convince the user that this curve shouldn't be edited, but I can imagine the frustration of a user trying to edit the curve and trying to understand where the \"bug\" comes from.\nSee my last commit.. Careful here, you don't know what UI background color are in use. It's bad enough that the colors are hard-coded, overdoing the read/write vs. read--only separation could harm the readibility more than anything else. i think keeping the nodes the same color as the curve is the less bad option. We will add a toolitp for the next minor-release, meanwhile users will have to RTFM or send emails to report \"un-intuitive behaviour\" until they get it.. This is what the editable nodes in tone curve and equalizers do, so we are back to problem number 1. On the contrary, here, I made them brighter (same as the curve). That makes them look \"part of the curve\", which seems more intuitive to me than having them look different, because the curve is never editable anyway.. XYZ derivates from the physiological cone response of the CIE standard observer (the sensors in the eyes). In block diagram that would translates:\n( spectral vector : wavelengths, intensities ) -> [ eyes ] -> ( tristimulus vector : intensities ) -> [ brain ] -> ( perception )\nThe (classic, old, flawed, inaccurate) mathematical model to describe that is :\n( spectral vector or camera RGB ) -> [ XYZ conversion ] -> ( tristimulus vector : intensities ) -> [ Lab conversion ] -> ( perception )\nSo, there is no contradiction in that: XYZ is the first layer of the model, simulating the eye, whereas Lab is the second layer, simulating (more or less) the brain.. that's not weird at all, your parameters are bad, so the curve breaks. With white at + 6EV, black should be at -4 EV top. In this setup, the grey should be adjusted at 4 % or so, in order to center the dynamic range around 0. \nThinking about it, maybe I should put the max of the black range at - 2EV.. Yeah, the auto-tuner is not super reliable. You need a good demosaicing and a good denoising (if needed) to have it work properly. I could add some sanitization checks on that too, but I kind of prefer having some obvious clue that it broke instead of having it silently half-correct stuff.\nNotice that the same auto-tuner works better in profilegamma IOP, probably because it works in non-converted RGB. Filmic works in the Lab pipe, so it converts back to RGB, and that seems destructive at some point, regarding the black/noise level.. @junkyardsparkle that's because the the UI ensures the shadows range is always at least as large as the highlights range (condition 1), and the grey slider is sliding white and black exposures accordingly to the grey correction (condition 2). So, the black/white ratio stays accurate until your grey value is such that black = - white. After that, if you keep sliding the grey down, the condition 1 supersedes the condition 2, and you lose you original black/grey ratio. Consequently, when you slide back the grey, you won't get the original black and white exposures, so you need to redo the setting.\nI could store and preserve the original ratio and try to apply it whenever the grey value satisfies the condition 1, but I fear it might cause other problems. In my experience, when you have slided the grey up to the point that black = - white, you already have a dynamic range of 14-16 EV, e.g. camera maximum, so you should stop there because you can't hope for better results past that point.. >  Is it possible there's a more elegant way to make this case \"resilient\"? That is, to conditionally not have the condition 1 supersede the condition 2 at this point? If going into that range doesn't really produce useful results, then its purpose is more as a \"bumper zone\" anyway, right?\nI will have to think about that. The problem is users may edit something else than regular camera raw: X-rays, 3D renders/CGI, whatever\u2026 I don't want to lock skilled users in an UI that thinks for them and limit them, for the sake of preventing unskilled users from doing bad things. \nSo, even if I have not had useful results passed that point, on raw pictures, I'm not confident enough to say it will never give good results on some pictures, and lock the feature for everyone in order to avoid to the majority the trouble to read the doc, and get some sense of what they are doing.. Nice ! Putting together the maths to get the algo working is one thing, but designing an easy interface to control it is a lot more work. It took a fair amount of iterations, but I'm glad it's finally working.. Notice that this should not happen anymore. The straicasing happens only with bad parameters, e.g. with black level > - white level. That case leads to poor curves, and the UI should prevent it to arise by correcting the values straight in the sliders since my last PR on filmic.. You did not update the OpenCL version of the processing. Do you need help on that part ?. You are right, my bad.. > The second one gives the difference with the grey. It's the pivot of blending mechanism. Below grey the value is substracted from image, above it is added.\nwhat blending ? The parametric blending ?. But the blendings are no concern of yours at this stage of the process. All you do here is increasing/reverting contrast with a transfer function, which happens to add also lightness in your modification. The blending is external to this IOP.. I'm currently testing your code. If I sample an area (using the color-picker) before the lowpass, and set its average luminance as the fulcrum, using contrast = 1 and lightness = 0, the output average luminance over this area becomes 50 % (as I planned). It should not do that (otherwise, it's not a grey fulcrum), the average luminance should not change when average luminance == fulcrum.\nThe proper behaviour is obtained with:\ndiff --git a/src/iop/lowpass.c b/src/iop/lowpass.c\nindex 2feadcf89..cc6ff9cc1 100644\n--- a/src/iop/lowpass.c\n+++ b/src/iop/lowpass.c\n@@ -562,7 +562,7 @@ void commit_params(struct dt_iop_module_t *self, dt_iop_params_t *p1, dt_dev_pix\n   if(fabs(d->contrast) <= 1.0f)\n   {\n     // linear curve for contrast up to +/- 1\n-    for(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + 50.0f;\n+    for(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + d->cfulcrum;\n   }\n   else\n   {\n@@ -577,7 +577,7 @@ void commit_params(struct dt_iop_module_t *self, dt_iop_params_t *p1, dt_dev_pix\n     for(int k = 0; k < 0x10000; k++)\n     {\n       float kx2m1 = 2.0f * ((float)k / 0x10000 - d->cfulcrum / 100.0f);\n-      d->ctable[k] = 50.0f * (contrastscale * kx2m1 / sqrtf(1.0f + contrastm1sq * kx2m1 * kx2m1) + 1.0f);\n+      d->ctable[k] = d->cfulcrum * (contrastscale * kx2m1 / sqrtf(1.0f + contrastm1sq * kx2m1 * kx2m1) + 1.0f);\n     }\n   }\nTo deal with the blending thresholds, one should use the lightness correction. The masking case you describe is an overlay mode, you cannot prepare the parameters of an IOP using a fixed assumption on the output blending it will use: other modes can be used. Otherwise, you fall into what shadows/highlights does and build a specialized IOP.. > If constrast = 0 (brightness and saturation = 0), the image should be full grey, right ?\n\nIf you change the fulcrum, there is no reason to affect the image, right ?\nIf, in the formula you add fulcrum instead of 50, changing fulcrum will change the image.\n\nA fulcrum means you roll the contrast around that value, without affecting that value. So, for contrast = 0, the image should be == fulcrum everywhere.. No, that does not work. Your are not supposed to change the lightness at all with contrast = 0, no matter the fulcrum, the output lightness is the fulcrum lightness anytime, not an arbitrary 50 % designed to help with a particular blending. As of now, the fulcrum was hard-set at 50%, fine, but if you want to make is dynamic, you have to stay consistent.\nFrom a Fourier spectrum point of view, \"no change\" means conservation of energy, and no contrast means you have a single frequency = 0 Hz which intensity is the average input energy. Output means output of the IOP with no blending. Null contrast means no luminance variation in the picture  (no frequency > 0 Hz), that does not trigger any assumption on the average output value in general (the intensity of the 0 Hz frequency).\nAgain, you are pushing the assumption that the module will always be used blended in overlay mode, where 50 % is the threshold value, so grey = 50 % means indeed the blended output is unchanged (identity). But if you blend in multiply mode, 50 % means 50 %, not darken/lighten threshold, and in this case, your contrast setting is changing the lightness too, and it's bad. If you have a fulcrum at 30 % and want a 50%-normalized output, convolve a lightness correction of 20 % / contrast on top of the contrast. That's the right way to do it.\nYou need to forget the blending here. What this IOP does is a blur, on which several corrections are applied. What happens after the IOP is accessory. For each pixel == fulcrum, output = input for all contrast value. That's what a fulcrum is. That's not what your algo does. What you call fulcrum is a pre-overlay blending normalization shift that works only if lowpass is blended in overlay. . > I'm afraid the lowpass module doesn't work as you describe neither. The hard-set 50% value cannot be a fulcrum because for contrast = 0 the current output is a flat grey image, then the sentence For each pixel == fulcrum, output = input for all contrast value. is not verified.\nyes it is. For each (input pixel == fulcrum), output pixel = fulcrum. If contrast == 0, all output pixels = fulcrum. If contrast != 0, only (input pixel == fulcrum) give output pixel = fulcrum. Thus for all (input pixel == fulcrum), input pixel = output pixel == fulcrum.\n\nSo what about changing the name ? normalization shift ? contrast slider pivot ?\n\nJust use the shadows/highlights module, because that shift is exactly what its \"compress\" slider does, and it blurs the same way with gaussian and bilateral, with separated controls of luminance and saturation for shadows and highlights, and performs a built-in overlay blending.. > One point which is sure, the fulcrum slider influences only the behaviour of the contrast slider. It has no effect on brightness and saturation sliders.\nNo, your version of the fulcrum is affecting the lightness as well, that's the point I'm trying to make since yesterday. Whatever value used as a fulcrum gets remapped to 50 % lightness. Just check the maths.\n\nBut this module provides an image of contrast, which by definition is grey for contrast = 0, whatever the intensity.\n\nThis module provides a low-pass filter. A such filter retains the energy of the signal, otherwise it's not a frequential filter anymore. I don't know if you have a background in harmonic analysis, but I find it easier to understand from a spectral point of view. Contrast means non-constant image. Constant image does not implies middle grey image (that's only a particular case).\n\nTherefore \u201ccontrast fulcrum\u201d seems to be the correct name as a fulcrum is nothing else than a pivot point, here the intensity pivot point, around which rounds the contrast (delta intensity) but not the intensity itself.\n\nI'm sorry, but I cannot agree with you. You don't only roll around the pivot here, you slide the pivot to 50 % lightness too.\n\nStill a doubt. I haven't been able to find the way to use the pure \"fulcrum\" slider (like with your formula).\nDo you have any idea in mind on that way (from usage point of view) ?\n\nWhen fulcrum = 50 %, with my formula, it changes nothing, compared to the current implementation. When fulcrum < 50 % and you are using an overlay blending (so 50 % L means threshold), you need to increase the lightness to remap the fulcrum value to 50 % (exactly what your formula does without advertising it). The other way around, when fulcrun > 50 %, you need to decrease the lightness.\nAgain, what you do is ok in a setup where the lowpass is only blended in overlay mode, to perform a dodge and burn. The problem is your contrast fulcrum affects the lightness as well, which is supposed to be controlled separately. My pure fulcrum slider makes them completely independant (as they should), but in the other hand, needs another lightness adjustement. That's why I don't like the lowpass filter to perform dodging and burning : it is a low-level technical filter that has much nicer and more specialized interfaces in shadows/highlights or even in equalizer and local-contrast. I know Shane Milton has a love affair with this module, but I suspect it's only because he doesn't understand what equalizer does (wavelets are not trivial, but they are nothing more than stacked low-pass filters with increasing scales).\nIf I were you, I would just add the pure contrast fulcrum in lowpass, then add a sigmoidal contrast correction in shadows/highlights with the fulcrum defined by the compression parameter. That way, you have a consistent (yet trickier to set) low-pass for technical users, and a more powerfull shadows/highlights module to do at once what you are doing with 2 instances of low-pass.\nOr even better, use the exposure module to increase the lightness linearly, with parametric blending in multiply mode to isolate shadows/highlights, and a blurred/feathered mask to reproduce your low-pass. That way, you retain the RGB ratios and avoid hue shifts. Because low-pass happens too late in the pipe, and do non-linear things on top of non-linear data.. I like the UI\u00a0as it is but I don't really care, both ways are good with me.. I hope so too. It has been quite an adventure.. Works fine with me, soooooo much quicker\u2026 Many thanks @TurboGit !. Thanks ! I have yet to squeeze in there either a laplacian pyramid or a wavelet decomposition to affect only the low frequencies, because I find it flattens a bit too much the local contrast.. > Just tested and liked it :-)\n\nIt is probably already on your todolist, but it would be nice to have soft bounds on the sliders\nVery nice addition Aur\u00e9lien, thanks !\n\nNice ! Soft bounds could quickely backfire. Given that each channel is separated from the others by 2 EV, pushing is beyond will move it to another channel, and the local contrast will suffer beyond repair. \nBut, increasing the channels around a third one will have the same effect as pushing it beyond/over \u00b1 2 EV while preserving details.\nI just stabilized the laplacian filter, I think it works great. There is only one scale for now, so the difference is only visible fully zoomed.. @rawfiner \nWhat the algo does is several band-pass filters between 0 and - 14 EV:\n\nEach band-pass filter is defined by a gaussian window so that for every pixel, the sum of the weights of all windows are constant (= 1.77).\nEach band is associated with an exposure compensation, which is a factor (+2 EV \"=\" \u00d7 4). Say you want to add 2 EV\u00a0on the - 4 EV band, and remove 2 EV on the -2 EV and 0 EV bands, your parameters translate like this:\n\nFor every pixel, we then compute the sum of all the channels at the pixel's luminance and use the result as a correction factor (between 0.125 and 4):\n\nSee here, at -4 EV, the correction factor is only ~ 2.5 (+1.30 EV) because the neighbouring channels have some weight to avoid breaking the local contrast. So we can increase the -6 EV channel as well:\n\nNow, the -4 EV band gets a factor of ~ 3 (+1.5 EV)\nOnce you multiply the RGB vectors by the factor corresponding to their exposure, you get something very similar to a tone curve:\n\nThis approach shows none of the interpolation artifacts (cusps) of the splines interpolation, gives a smooth curve no matter what, and deal with pixels as full RGB vectors (not separating their components). But you see here how the operation is mildly damaging the local contrast near whites (oscillation) ? That can be made less problematic by using a laplacian pyramid (for now, there are only 2 scales), but still, you don't want to force exposure oscillations.\n. I have an error double free or corruption (!prev) affecting the line 508:\nC\ndt_free_align(luma_in);\nIt happens when using the laplacian mode with the power weighted norm (you can also see the thumbnail is wrong). I have spent 3h trying to troubleshot it, if someone has an idea ;-). > In process_scale, if memory allocation failed, you will goto clean and free the 3 pointers while you just checked that one of them is NULL, hence you will free a NULL pointer. The error maybe comes from here?\nNo, that part was already an attempt to fix this problem, it arised before (and also freeing a pointer set to NULL is supposed to be harmless).. Thanks @ff2000 and @edgardoh, that's very helpful :slightly_smiling_face: . Weird. Could you try again @ff2000 with the latest commit ?. Could you provide more info on your CPU @MStraeten ? I suspect this has something to do with the autovectorization, but I have no idea at this point.. > Please drop me a note when you think the documentation is ready. You don't need to pay attention to typos and minor language issues, that's something I will fix when proofreading. Just make sure the content is well understandable.\nI will, thanks for the answer. I have had problems again with my Linux boot, so more fun to debug.. it's done for me @upegelow @rawfiner @TurboGit . Yes please :-). Could it be a cache refresh issue ? (crop and rotate just force a cache regeneration or something ?). the cache is cleaned when you zoom in/out.\nCould you provide the list of the modules you are using ?. Does the tethering work on Windows with dt though ?. Ok then, let's keep it.. > the attribute() thing should be in a define and only be enabled on x86_64\nHow so ? (I'm definitely not a low-level guy). @darix could you show me a complete example ? I have tested that further, and the perf boost is really worth it (up to \u00d72 at virtually no cost).. I have acquired new knowledge on that so I\u00a0will close that and do one PR/module.. Awesome !. Either deinstall Beignet (Intel OpenCL library) on your system or blacklist it in ./config/darktable/darktablrc:\nopencl=TRUE\nopencl_device_priority=*/!0,*/*/*\nopencl_disable_drivers_blacklist=intel,beignet,neo64\nopencl_use_cpu_devices=false\nYou can also input manually the Nvidia OpenCL lib path here:\nopencl_library=. > Thanks @TurboGit and @aurelienpierre. Disabling opencl did it. I have a regular integrated Intel graphics chip (HD Graphics 620) and have the intel-opencl drivers installed. I will try installing the Beignet drivers and see if I can use opencl with those.\nNo, don't. You don't need OpenCL if you don't have a graphic card. darktable doesn't work with Intel OpenCL for some reason, but OpenCL won't improve the performance on Intel CPU anyway. OpenCL is intended only to output computations on GPU, which is way faster when there is a GPU available. But the regular code is already optimized for CPUs so you don't need to to anything in that case.. Closing. The 2D filter is not separable, this does not work.. > Maybe we want this in 2.6.1? Sounds quite safe.\nYes, I think so.. Would it be possible to have it in 2.6.1 ? Or the policy is to have only bug fixes in minor releases ?. This looks safe to me. I'll shake it and try to break it in the next days, then I will confirm that..                                                                                       \u200eIf you have time, yes. Thanks !\u00a0                                                                                                                                                                                                                De: Pascal ObryEnvoy\u00e9: samedi 29 d\u00e9cembre 2018 12:24\u00c0: darktable-org/darktableR\u00e9pondre \u00e0: darktable-org/darktableCc: Aur\u00e9lien PIERRE; AuthorObjet: Re: [darktable-org/darktable] basecurve: BUGFIX (#1944)@TurboGit commented on this pull request.\nIn src/iop/basecurve.c:\n\n@@ -329,7 +329,7 @@ static void set_presets(dt_iop_module_so_t self, const basecurve_preset_t pres\n     dt_gui_presets_update_ldr((presets[k].name), self->op, self->version(), FOR_RAW);\n     // make it auto-apply for matching images:\n     dt_gui_presets_update_autoapply((presets[k].name), self->op, self->version(),\n-                                    force_autoapply ? *force_autoapply : presets[k].autoapply);\n+                                    force_autoapply && presets[k].autoapply);\n\nDo you want me to do the clean-up?\n\u2014You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or mute the thread.\n{\"api_version\":\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"GitHub\"},\"entity\":{\"external_key\":\"github/darktable-org/darktable\",\"title\":\"darktable-org/darktable\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https://github.githubassets.com/images/email/message_cards/header.png\",\"avatar_image_url\":\"https://github.githubassets.com/images/email/message_cards/avatar.png\",\"action\":{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/darktable-org/darktable\"}},\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@TurboGit commented on #1944\"}],\"action\":{\"name\":\"View Pull Request\",\"url\":\"https://github.com/darktable-org/darktable/pull/1944#discussion_r244504176\"}}}\n[\n{\n\"@context\": \"http://schema.org\",\n\"@type\": \"EmailMessage\",\n\"potentialAction\": {\n\"@type\": \"ViewAction\",\n\"target\": \"https://github.com/darktable-org/darktable/pull/1944#discussion_r244504176\",\n\"url\": \"https://github.com/darktable-org/darktable/pull/1944#discussion_r244504176\",\n\"name\": \"View Pull Request\"\n},\n\"description\": \"View this Pull Request on GitHub\",\n\"publisher\": {\n\"@type\": \"Organization\",\n\"name\": \"GitHub\",\n\"url\": \"https://github.com\"\n}\n}\n]. It seems that your change is not fixing the problem\u2026 The base curve is still applied no matter the setting. We really need to check both conditions : the auto_apply flag AND the global setting.. Yeah but do we expect users to reset their database ? Could it be possible to force the db regeneration for these presets ?. > Do we really want to deprecate \"spot removal\" ? It is easier to use than retouch, it has been used since years by many people. I would keep it but have it not selected by default. But I have no string opinion on this.\nThe spot removal might have a simpler UI, but it is actually more tedious to find a clean area with no details and exact same luminance to sample. In practice, you have to fiddle with opacities and blending modes to get it to work properly, if you ever do. In the other hand, using the healing tool in retouch, even on the first layer (without enabling the wavelets decomposition), is fast and gives nice results, even if the UI is more loaded.\n\nThis PR also disables sharpen by default.\n\nYes, I forgot that. The motivation is there are 4 different ways in darktable to do fake sharpening (aka local contrast enhancement). The sharpen method is not the best, although it's the fastest, and the preset provided is too heavy for modern prime lenses + full frames, and too light for point-and-shoots and entry-level zooms. So, if you really want an auto-preset, you would have to profile lenses and make it dependent.\n\nWhy have you chosen \"contrast equalizer\" name? It doesn't affect just the contrast, so the reasoning is not obvious.\n\nWhen you look at the code, the equalizer adds or removes contrast on Lab channels at different wavelet scales. So it's always a color contrast or luminance contrast adjustment. Then it does a thresholding, as a denoising (which is not really the right place in the pipe, and is fully redundant with the denoiseprofile wavelet, if you ask me), which is nothing more than a local contrast clipping, if you think about it. So the equalizer is all about local contrast, and having it named unclearly leads user to emulate its effect with several highpass filters for no reason at all.\n\nI'm not really for having the lens correction module enabled by default. This will \"hide\" most details on the border of the image by default and it is always possible to have it enabled by default using an auto-preset.\n\nI agree that it can be a preset, but it's to be consistent with the base curve auto apply. Why the base curve and not the lens ? I think it should be both or none.\n\nAlso, please make separate PR for each changes as some may be merged now and some need more discussion. The risk is having nice enhancement stopped because of some part are more delicate. Thanks.\n\nI will branch the toolboxes, as it seems nobody is complaining about them. The rest is part of the same discussion about the design of the soft, I think.. > To me that does not answer the question of \"why should the existing simple module be deprecated?\"\nBecause you duplicate the feature and clutter the UI with a limited and flawed version of something else that works better.\n\ndt should not try to have a magical set of auto-tuned modules enabled by default.\n\nSo why the auto-activation of the sharpening then ? Especially with an arbitrary preset that is not universal ?. > Could be because the physical low-pass filter softens the image, or because the default demosaic kind-of results in softer image than the other mode, dunno.\n50 % of the sensors post-2012 don't have a low-pass filter anymore. Post-2016, it would be like 75 % or so.\nWe have to settle this :\u00a0do we want a straight-away-good-looking picture when the user opens the darkroom, or a do-it-from-scratch picture ? Because both ways, I'm fine. But for now, it seems the first option has been chosen for base curves and sharpening, while the second one has been chosen for lens correction. I'm just asking for consistency.\nThe sharpen preset is not, by any means, a one-size-fits all thing. On any recent 36+ Mpx, you need to disable it because it's overcooked. On any point-and-shoot or DSLR + kit lens, it's not enough but you can't push it too far without messing it up, because it's a good old unsharp masking (halos much ?). When it's enabled by default, you send a message to the user : \"use it, it's standard\". It's not. It's 1972 stuff we used before being able to deconvolve properly.\n\n(also, you are well aware of the more modules module, i think? so i'm not sure how it clutters it even)\n\nI know. It's where I hide all of dt's nonsense and geeks playtoys in garbage Lab.\n\nAlso, let's take step back. Is that new module fully functionally equivalent of the old one?\nI have just tried it, and already stumbled into very obvious bugs (have you tried zooming in on the dst replacement area? that is a rc bug; though something tells me 2.6.0 may or may not be more full of these than usual)\n\nI have abused that module for 4 months, there are some rough edges but nothing unusable.. > citation needed i guess.\n\nThe point about demosaic still remains.\n\nJust browse dxomark.com database\u2026 Nikon has removed the LPF for every camera from the D800E (2012), D7100 (2013), D3300 (2014), D5300 (2013), D5 (2016). All the full frame Sony don't have them since the alpha 7 (2013). Fuji don't need them at all with their XTrans sensors. Pentax has a digital LPF on K1 and K5 that can be disabled in the firmware and the 645 doesn't seem to have one. Hasselblad X1D (2016) doesn't have it. Same for Phase One since at least IQ2 (2014). Same for Leica with the S2 (2016) and the M range since at least the M9 (2012). Panasonic has gone LPF-less tlast year for the first time, with the GH5, and this year with GX7. Only Canon is trapped in Middle-Age with only the 5DR having an optical correction for the LPF (2015). Overall, only Canon and low/mid-range Sony still have them as of now.\nSo\u2026 yes, the point about the demosaicing remains, but unsharp masking to revert it is like putting a trailer behind your Ferrari. I mean, it's ok if you run an Intel Atom 1.4 Ghz, but for everything else, use the equalizer and do yourself a favour.\n\nBut then, why do we need orientation, demosaic, wb, highlight recovery one will say.\nSo if you do put it like that i'd go with \"let's just not touch the defaults\".\n\nThe difference is orientation and wb read the EXIF to adapt their preset. Highlight recovery is a clipping that goes with ICC v2 output constraints. Demoisaic is obviously needed to create an image. Sharpen, on the contrary, is an arbitrary choice with arbitrary settings that don't care if you have a file from a 100 Mpx LPF-less medium-format with a pristine 90 mm f/2.8 or a 10 Mpx micro 4/3 with the 18-200mm \"my-lens-does-it-all\".\n\nDo you believe darktable should get rid of it's Lab section of the pipeline, and do everything in [whatever] RGB?\n\nGetting rid of them is no option at this point of history, but yes\u2026 No serious pixel-pusher ever pushes pixels in Lab. That's a space where exposure compensation is not a multiplication anymore and where large corrections of luminance actually desaturate the colors, even if they are not supposed to. It's not even that good as a connexion space for ICC profiles, now CIECAM02 tends to replace it slowly. The Lab nonsense of darktable is the main reason I have mainly done B&W photography in the past years and why I hacked the color balance module, which is the only module allowing to correct colors in RGB (but in gamma corrected sRGB, seriously\u2026 :man_facepalming: ).\n\n\nDoes that module has a mode in which it can act just like the old spot removal module, with no extra freq/wavelet stuff forced down one's throat?\n\n\nYes. Use the clone tool on the first (black) default layer.\n\n\nDo you see the bug i just reported? (it seems i tried on 2.7.0+44~gc2ecb03f5-dirty, maybe it was fixed already)\n\n\nI'm not able to reproduce with today's master.\n. >  I guess i should finish jumping ship at some point, or at the very least stop wondering into these PR here.\nThat would be a shame. \nI'm trying here to think the workflow of dt from a photographer perspective. My regret is that for now, it's a plugin collection more than a photo workflow software. The qualities I expect from a such software are efficiency, consistency and predictibility. That PR is about improving the consistency part.. A lot of legacy_params have been written and obsolete modules are not removed, they are just flagged so they won't show up in the UI for fresh developments.\nAs for breaking compatibility, I think there is a line to draw between \"old developments can't be open anymore\" and \"we have 0.2 % RMSE in the image between the new version and the old one\".\nThe only thing that truely concerns me is how masks coordinates will be moved when modules will be reordered, especially around the geometric distortions (perspective, liquify, retouch). Apart from that, it's mostly an hard-coded constant that becomes exposed to the user. Sure, the color spaces will need to be fitted between contiguous modules, but some modules already do internal color-spaces conversions (tone curve, color balance), it's just a matter of spreading it.\nIt might be the opportunity to merge \"small\" modules too (velvia + vibrance, colorize + splittoning, etc.) because OpenCL overhead and I/O latencies are really damaging for performance when not much is done in the kernels. It often ends-up with 60 % of the running time lost in buffers copies.\nA complete rewriting seems to me the most efficient way to kiss compatibility good-bye.. And if anyone has doubts, I have 7 years of archives in dt DB, I'm not ready to lose them just yet either.\nThe goal is to overcome bad or locked design step by step by making hard-coded decisions user-configurable, so add options and make the legacy configuration only one of the available options (module order, with legacy order by default, or more RGB modes in modules in addition of legacy Lab). That way, you retain the ability to process old edits (hard-coded stuff just moves to database preferences) but don't get locked into past choices. Rawtherapee does that: many modules have a Lab and a RGB mode, and several RGB spaces for the pipeline, consistent with the state of the art (ACES and such).\nBut, apart from that, I would really like to trigger design and ergonomics discussions. Like what is the using path we want to draw for users so their editings are efficient, predictible and reproductible. I have edited weddings in dt, that was my worst experience ever. It's nearly impossible to truly duplicate history stacks, too many modules have bad side-effects when you push them, so you end up doing manual case-by-case edits because it's faster than trying to adjust not-so-generic average presets. Working on linearly encoded, scene-referred RGB would have been so much easier\u2026. > I think we're going about it in a reverse direction. You say you want to trigger design discussions, but you completely skipped steps 1-4 (or have I missed something here?) and we're stuck discussing technical details of each new change instead of the whole picture. You obviously know the way you want DT to work, but don't you think it shouldn't be one man's decision? For one other people know DT internals much better.\nYou are unfair, I have been discussing that for 3 months on IRC with @hanatos and @houz, I have shown the benefits of the linear RGB scene-referred workflow many times on pixls.us, along with the added value of my changes in color balance, filmic and unbreak color profile in videos and tutorials\u2026 I have discussed the pipeline vs. UI order of modules for 2 weeks on the dev mailing list. I have produced a comparison of filmic vs. base curve results, and shown that 2 out of 3 global tonemapping operators are broken, because they were designed in RGB and implemented in dt in Lab\u2026  So far, no dev has commented on the results and the functionnal aspect, only users seem to care. \nAll the feedback I have had from devs on the changes I propose is technical objections, no discussion has ever lead to the added value and benefits for the workflow. Yes\u2026 I get it\u2026 It might break the soft. But a soft that never breaks is a code graveyard. The modules were originally designed to be moved around (otherwise the modular approach is only overhead), but that was abandonned at some point. \n\nWhy then have you already changed order of some modules if the goal is to have it configurable? Just leave old defaults as is and work on the new system. Which BTW you should describe somewhere in full, then anyone can compare it with current one and have his own conclusion on how compatible they are. Doing incremental changes just hides how much you want/need to change.\n\nSo far, only the crop and rotate modue has been moved sooner in the pipe, after perspective correction, and the reasons are documented in the PR #1791. This is safe from the image processing point of view and the cropping was trapped in the middle of the color adjustements for no reason. \n\nMy fear here that the way this is going after everything gets merged we end up with completely unmanageable, untested and subtly broken code, much worse than we have now (which is already not good). Any new big feature needs to be cleanly designed, so that overall quality of the DT's code improves, not degrade further.\n\nSeriously, we support a soft on Windows, Mac, Linux \u00d7 (Gnome + KDE + zillions of derivatives), on architectures like x86_64, ARM and other I have never heard of\u2026 We don't have enough testers to proof-read everything on exotic hardware + distros, at some point if you don't take a chance to release subtly broken code, just take your Adobe Cloud subscription, it's a lost cause.. What remains in this PR is renaming the equalizer and deprecation of the spot removal.. > To have a \"contrast equalizer\" and a \"tone equalizer\" and avoid confusion, right?\nYes.\n\nI think that the renaming of the equalizer will make sense in the tone-equalizer PR\n\nOk then.. Hmm I should write the doc about that. The thing is the luma optimization tries to remap the max RGB to 100 % luminance, the min RGB to 0 % and the average RGB to 50 %, over the selected area. So, if you select a dark area to do the auto-optimization, what happens is normal.\nBut, I have found that there is a \u00d7100 error in the UI when the auto-optimizer is run (the value displayed is a ratio between [0; 1] but it should be a %). So that explain why, when you scroll after the optmization, the values are actually remapped closer to 0. I must correct that.. > is that normal behavior and I should wait for the documentation and close this or it's a potential bug?\nIt really depends which area you sample for the auto-tuning. Also, I see you are using it with filmic, so what you see is a double up : both filmic and color balance are raising the mid-tones. Just stick with filmic to fix the lightness. Your first image is quite good, add a bit of contrast in colorbalance and you are good to go.\nIf you want to ensure the auto-tuner is working properly, disable filmic, spot an area with the color-picker, trigger the optimization, and ensure, with the global color picker that the average luminance over the zone is 45 - 50 % (it should be 50 %, but the measure is done in the display RGB, so it measures what you see after the output RGB conversion, and not the actual data).. > here still seems to be an interface bug, clicking on \"optimize luma from patches\" optimizes over the whole image, with seemingly no way to select a patch\nTo select the patches, you have to use each of the 3 slope/offset/power factors color-pickers in this order. Then hit the optimization button.\n\nit selects the minimum value, getting it to work usually involves deactivating the lens correction, rotating by 0.25degrees, or a slight crop\n\nThere is not much I can do here. All of your fixes involve interpolation so that means you have bad noise that gets blured this way. The thing is the optimizer works assuming the min RGB is black, but has no way to ensure it's not actually noise or demosaicing artifacts.\nOr maybe I could blur the picture slightly before measuring the minimum, but I have to check how to do that from the UI.\nGood luck for your exam !. > I must say that I'm not fond of the \"+\", \"+++\"... not easy to find a better alternative.\nI have tried different labelling approaches, the problem is always the same : the labels are long in English, even longer in French or German, and displayed alphabetically when they should be displayed by size. So, enforcing the order would require using numbers (we already discussed about that), and ensuring the labels size in every language is difficult.\nAnyway, I\u00a0think these presets are temporary. Ideally, I will/would code an alternative UI for that module, that would build the gain for each level with a gaussian window, but users will input the average (position), standard deviation (width) and amplitude (strength) of the gaussian distribution instead of building a band-pass filter without knowing it.\n\nLet's try... we have from 1 to 4 plus, what about : delicate, light, strong, extreme?\n\nI have nothing against it, but it might not solve the problem.. So I went for \"deblur: fine|medium|large blur, strength 1|2|3|4\". Have you tried http://lensfun.sourceforge.net/manual/v0.3.2/lensfun-update-data.html. I\u00a0like that !. This is all I can do for now, so it can be merged. The rest is mostly documentation to explain where we sit. \nI'm not sure the HSL <-> RGB sliders conversion has a solution, as the legacy controls are RGB+L. Since RGB channels already hold the luminance information, adding the L/factor control was redundant, especially since nothing was done to ensure the RGB parameters were luminance-corrected. So, now, if I normalize their luminance, I either break compatibility if I do it backend or introduce back the GUI glitch that made RGB sliders difficult to control, if I do it frontend. Doing HSL <-> simple RGB (no L) would have been straight-forward though.\nThe HSL normalization for the auto-neutralization is a non trivial maths problem, so I will have to sleep more and drink less before I'm able to solve it. Not going to happen in the next week :rofl: . I\u00a0think @rawfiner has something like that in the pipe, using the downsampling to denoise.. > If I adjust sharpen first and then activate scaling early in the pixel pipe, the parameters (e.g. radius) will not change accordingly, such that the result is different afterwards.\nActually, it's a good thing. Say you sharpen with a radius of 2 px or less, and then resize to half the original dimension: your sharpening will be useless. Worse, depending the interpolation algorithm, it can create staircasing effects (interpolation artifacts), that's why it's customary to apply a slight blur before resizing, and a slight sharpening after.. The good thing is the resizing happening first. Scaling means interpolation which means sharpness loss. So you should sharpen a bit after scaling (that's what Photoshop does). And sharpening before can be at best useless, at worse, damaging. \n\nResult will be sharpening of the rescaled picture with radius 2 px, which means compared to the original image a radius of 4 px, and probably not a good resulting picture.\n\nNot exactly. Don't forget we are in a discretized space, so scales are not completely proportional because of the pixels gaps. Also, sharpening is a frequential thing, not a spatial one (that's a highpass filter on which you increase the contrast). Downscaling can also be described as a discrete lowpass filter, in frequential domain. So, increasing the radius of the deblurring by the inverse of the scaling ratio is at best a rough approximation (especially using gaussian blur).\nBottom line, using the same radius on full and resized scales could not be as bad as it sounds overall. Generally speaking, I see the effects of sharpening in dt only zoomed at more than 50 %, and I don't use it at more than 2 px, if I use it at all. 50 % means at least 6K resolution on 24 Mpx, when I export at 2K max (HD 1080). So, overall, I suspect any 1-2 px sharpening at full resolution becomes completely useless in practice.. > is obscure from a user perspective.\nBut that is exactly the purpose: obfuscate the name so people will need to read at least the tooltip, if not the doc, before they start messing up things without knowing it.\n\"black\" suggests it's you average friendly slider, that can help you get more/less density, and in that sense, it's redundant with the levels module, except this variant can backfire badly. \n\"unclip negative values\" suggests \"don't use that unless it's to fix an issue and you know what you are doing\". \nThe goal is actually to prevent most users to use it, because there are safer way to do the same thing in the software, and the fact that most modules deal silently with negative values makes it super difficult to track down the clipping issues to the exposure module when you don't know the guts of dt. \nI have had multiple users reporting that either filmic or colorbalance clipped lowlights, and when they sent me the XMP, they all had their black level cranked like crazy, outputting negative values that nor log or gamma functions know to handle. So the problem they created before in exposure showed later in other modules. And now that this bad habit has been taken, it needs harsh measures to be reversed.. Could \"black/noise level\" be an option ?. So \"black level correction\" then ?. Good! I'll make the change. Sounds like a CSS rule gone.. Wow ! Just tested, indeed the borders are gone in the lighttable (not the zoomable version though), but that's some blazing speed-up !. Also, when we delete pictures, there is a sort of lag before the thumbnails are updated and reordered. Rating them with stars is still a bit random (needs to be done twice), and laggy too (there is some sort of delay between the click and the actual stars update).. Now, navigating with keyboard arrows is broken, only the active thumbnail in the lighttable is updated, not the full rows.. >  yes the lag is there because when reordering we need to redraw everything. So I do expect some lag for some actions and have this at least \"usable\" in 4k or 5k display.\nThe lag was on HD 1080 screen. I did not have it before (even on 4K).. Ok that fixes it.\nStill broken:\n- rating from keyboard in file manager\n- browsing with arrow keys in zoomable lighttable\n- zooming from keyboard arrows in file manager (after you have clicked on the zoom slider)\n- thumbnails borders in file manager (they work in the zoomable lighttable, for some reason). The spanish translation was incomplete, and it's darktable politics to remove partial translations.. Note that @houz has something like that working, but not it dt. > The corresponding file size is above 7Mb.\nAre you sure ? The LUTs I have tested weight 970 kB max. Given that they are only text files, 7 MB seems quite heavy. Also, we don't have to store them in the database, they can be retrieved from the files like ICC profiles when needed.. >  Is it possible to look at the@houz work ?\nI don't think it's commited somewhere yet.. >  Then which RGB space the LUT should be applied to ?\nOnly in the RGB space in which the LUT has been generated. Usually, it's REC2020 or ACES P0.. > I haven\u2019t the answer, but I think it may be more complex than referring automatically to REC2020 or ACES P0, though they could be the default space.\nThat piece of information is to be provided by the LUT maker.\n\nDepending on the rgb space used the rendering will be different, won\u2019t it be?\n\nIndeed, if you think of an RGB space as a vector sub-space of XYZ, different RGB primaries means different base vector length, so distances are scaled differently. Given that the LUT essentially shifts the RGB coordinates, the shifts have different meanings in XYZ, depending on the RGB space used.. Great !. Seems all good now, indeed.. which modules are affected ?. How bad is the length issue ? What is the size of your screen ? Because that sounds like a lot of GUI rewriting for a a small benefit, from where I sit. (as in: do we want a preference for all IOPs, or for each one ?). Also, if you don't use the default presets and yours are better, maybe share them to see if we can merge them ?. > > Sounds good! Do you think this can/should go in 2.6.1?\n\nLet's wait a bit. I am interested to see if this really works well. Also the decision to convert to sRGB might be debatable with e.g. AdobeRGB being an alternative.\n\nAs a working space, linear RGB spaces like REC2020 are most secure due to the proximity with pure spectral primaries. If it's an achival space, ACES P0 is the best, Prophoto RGB works too.. @upegelow could we merge for 2.6.1 ?. > this happens also on newly imported photos with no previous \"history\" in Darktable (I understood from \nThe culprit might be an automatic presets built with previous API and not updated. Or sometime, when you go back to older versions of dt, your presets database still has the newer API.. I don't understand why the hue gets involved in the chroma correction. The chroma is the colorfulness, more or less equivalent to the saturation, you usually want to keep it separated from the hue (that's the whole purpose of the Lch space). Hues shifts are nearly impossible to handle with curves, hence the color zones module, so I think you should keep only the L and C channels, keep C away from any interaction with H, and let the hue handling for the color zones module.. > I've noticed an issue on data shifts. I'm unsure how to handle that.\n\nThe goal of LCh is to make changes on L and C letting the other channels untouched.\nThis never happens ...\nSome screen captures here:\ntonecurve_calculation_issues.docx\n* Changing Luminance shifts a & b on color picker (same for LAB independant channels).\n\n* Changing Chroma shifts Luminance and Hue.\n\nThat may be a normal behaviour but that's disturbing to have a measure (color picker) which contradicts what we try to do ... :-)\nWhere and when color picker does make the measure (before or after output color profile) ?\nWhat do you think ?\nIs it possible to improve this ?\n\nThat's a flaw of Lch/Lab (1976) color space itself\u2026 it's not really hue-invariant nor chroma-invariant.\nA solution would be to use another color space like IPT-HDR (2011), and I'm working on just that these days.. On another note, if you don't affect the hue, you don't need sinf() or cosf() and you can speed things up:\n\ncompute the chroma (aka euclidian distance, aka radius): C = (a^2 + b^2)^0.5\ncompute and store as constant the cosinus = a / C\ncompute and store as constant the sinus = b / C\ncompute and store as constant the hue (aka the angle):\neither atan2(b, a)\nor sign(sinus) * sign(cosinus) * atan(sinus / cosinus) (probably faster, since atan2 will compute cos and sin on its own, but not store them, and we have them already)\n\n\nchange C = funct(hue)\nrestore a = cosinus * C\nrestore b = sinus * C. > But maths on Lab<->LCh do not say that ... what does happen ?\n\nHold on. Do you mean Lab -> Lch -> Lab is not an identity (ie Lab input \u2260 Lab output), or Lab -> Lch -> c = funct(hue) -> Lab (ie chroma adjustement) does not retain the a and b values (or ratios) ?\n. what you see seems normal to me. First of all, the global color picker works after the output color profile and the possible gamut compression it does, at the far end of the pipe, by converting back output RGB to Lab. So, don't bother to compare the values with the local color picker in tone curve, which works between the input and output of the module : too many things happen in-between.\nThen, Lab is a crappy non-linear old attempt to separate color and luminance in a perceptual way. Keeping the numeric hue (as the angle betwen (a, b)) unchanged doesn't mean the color you actually see won't change (especially around blue). Convolve that with an RGB color profile conversion, and you get unpredictible results. So, overall I think you are just hitting the limits of the Lab space.. >  So it would very interesting to be able to choose where in the modules chain the color picker picks ....\nIt would be very interesting to fix the color-management chain in dt at all.. What is RGB luminance coefficients ?. > @aurelienpierre. RGB luminance from my standpoint is something like:\n\n0.2126f * inl[0] + 0.7152f * inl[1] + 0.0722f * inl[2]; // luminance RGB\nI use that to provide the sample value for the L channel of LRGB, but it should be also necessary for the corresponding histogram.\n\nOk, that's exactly how we compute the Y channel of XYZ space, so it's redundant.. > > > @aurelienpierre. RGB luminance from my standpoint is something like:\n\n\n\n0.2126f * inl[0] + 0.7152f * inl[1] + 0.0722f * inl[2]; // luminance RGB\nI use that to provide the sample value for the L channel of LRGB, but it should be also necessary for the corresponding histogram.\n\nOk, that's exactly how we compute the Y channel of XYZ space, so it's redundant.\n\nI see some difference between XYZ and RGB on the image (dt 2.6 and 2.7) and on the color picker value (dt 2.7 with the same correction and this PR). I've not checked the matrix RGB<->XYZ transformation against the the above formula (I should, shouldn't I ? :-) ) but I'm afraid that's not quite the same.\nThen if XYZ and RGB luminances were the same we should not keep both modules, correct ?\n\nThe coefficients you use for the luma computation assume a REC709 RGB color space (D65 illuminant) but you apply them in Prophoto RGB space (D50 illuminant), so the luma you compute is wrong in the first place. The RGB <-> XYZ matrices in darktable are right, and adjusted for a D50 illuminant, which is the standard inside dt's pipe.\nThen, the XYZ mode of the tone curve is bugged, because the curve is applied on the 3 XYZ channels (which makes no sense from a color perspective), and shift the color toward green/yellow. The correct way to do it would be to use xyY color space, and affect only the Y channel, then convert back to XYZ. In xyY, x and y are the chromaticy coordinates at given luminance Y. In XYZ, Y reprents roughly the green response of the eye (which is equivalent to the relative luminance, since we are more sensible to green), X the ~ red and Z the ~ blue. But XYZ makes sense only to link radiometric coordinates (wavelengths and intensities) to human eye cone-response. It is a connexion space, not a physically-meaningful color space, so nobody should mess-up with it, except to adjust illuminants (Bradford and von Kries transforms) and switch between RGB spaces.\nTL;DR don't mess up with RGB luminance and leave the xyY fix to me, I have it in another PR :slightly_smiling_face: . Ok you need to separate the view and the data.\nNo matter the color space, the curve sets the middle grey at 50 % of the graph view. In commit_params(), the coordinates of the curve's LUT\u00a0are then properly remapped in 1D to the target color space, meaning 50 % -> 18.45 % in RGB and XYZ modes:\nhttps://github.com/darktable-org/darktable/blob/5b7b2f1b6abc7a52c98cc7f35d075fab24909cf8/src/iop/tonecurve.c#L583-L595\n(But @phweyland, you have removed that part.)\nThen, in process() the LUT mapping happens in the right color space.\nSo I think we are spinning around a non-issue. It's not a \"Lab\" or \"RGB\" curve, it's a curve drawn in a space where the middle grey is 50 % so the graph is centered (which happens to be Lab, but we don't care in that particular case. Could have been a simple ^2.35 too).. Although having a Lab histogram is not super intuitive, it is consistent with the rest of the UI. For chroma-based channels, you can leave that linear, but you will need a special histogram. If you want an RGB histogram, you can convert each channel to Lab as if they were grey to build the histogram like that:\n```\nint histogram_bins[3][255] = { 0 }; // RGB histogram bins\npragma openmp parallel for simd reduction(+:histogram_bins)\nfor( size_t k = 0; k < width * height * channels; k += channels)\n{\n    float Lab = (float const)roi_in + k;\n    float RGB[3];\n    dt_Lab_to_prophotorgb(Lab, RGB);\nfloat fake_R[3] = { RGB[0], RGB[0], RGB[0] }; // red \u00d7 3\nfloat fake_G[3] = { RGB[1], RGB[1], RGB[1] }; // green \u00d7 3\nfloat fake_B[3] = { RGB[2], RGB[2], RGB[2] }; // blue \u00d7 3\n\n// convert colors to pseudo-Lab for UI:\n// only the [0] element of the vector is relevant (pseudo-L)\ndt_prophotorgb_to_Lab(fake_R, ui_R);\ndt_prophotorgb_to_Lab(fake_G, ui_G);\ndt_prophotorgb_to_Lab(fake_B, ui_B);\n\n// RGB corrected in UI space:\nuint8_t UI_RGB[3] = { (uint8_t)ui_R[0], (uint8_t)ui_G[0], (uint8_t)ui_B[0] };\n\n// histogram_RGB can be put to 255 bins to process an histogram\nhistogram_bins[0][ UI_RGB[0] ] += 1;\nhistogram_bins[1][ UI_RGB[1] ] += 1;\nhistogram_bins[2][ UI_RGB[2] ] += 1;\n\n}\n```\nBut of course, it's not super efficient from a performance point of view.. Also, sRGB is crap, because it has 2 different gamma depending the range of the input, so you have to branch stuff and the code is not vectorizable. If this is the path you want to take, just use a ^(1/2.45). So what you call LRGB is the same curve applied on all RGB channels ? \nNice job for integrating the separate (manual) RGB channels ! I was planning to do it at some point, that's definitely helpful. I will have a look at the color spaces conversions in the next few days.. >  In fact we could propose several of these norms which control in some the behavior of the S curve.\nThese fall into chrominance preservation modes. In filmic, the only mode used for now is the max(RGB), hence the L infinite norm. I have thought about making it more general and using other norms as well, so that could end up in a general API:\n```\ninline float norm_vec(float RGB[4], float norm)\n{ \n  // ensure (norm >= 0.0f) in GUI controls for better perf\n// no RGB value shall be < 0 until we discover negative light energy\n  // because of this, we can avoid to fabsf(RGB) and speed thins up\n  if((RGB[0] < 0.0f || RGB[1] < 0.0f || RGB[2] < 0.0f)) return -1;\n// norm L infinite = max\n  if(norm == 0.0f) return fmaxf(RGB[0], fmaxf(RGB[1], RGB[2]); \n// norm L1 - bypass the powf for performance\n  else if(norm == 1.0f) return RGB[0) + RGB[1] + RGB[2];\n// norm L2 = euclidian norm - bypass the powf for performance\n  else if(norm == 2.0f) return sqrtf( RGB[0] * RGB[0] + RGB[1] * RGB[1] + RGB[2] * RGB[2]);\n// general Lp norm (pseudo-norm if p < 1) - slow variant\n  else \n  {\n    return powf( powf(RGB[0], norm) + powf(RGB[1], norm) + powf(RGB[2], norm), 1.0f/norm); \n  }\n}\n```. > > so that could end up in a general API:\n\nInteresting. In the article you've indicated the 2 norms are:\nBasic power norm: (R^3+G^3+B^3)/(R^2+G^2+B^2)\nWeighted yellow power norm: 0.83743219(1.22R^5+1.20G^5+0.58B^5)/(1.22R^4+1.20G^4+058B^4)\nIs the routine you've given above already merged ? Of course we could put together all valuable ones.\nComment: as a lut is applied on the output, it should be scaled to [0,1], right ?\n\nThe routine above is just a project for now, nothing done yet. The L1, L2, Lp norms are algebraic vector norms (\"real\" vector maths), but the power and yellow weighted norms are only empiric ad-hoc formulas, so I'm very suspicious with that.\nAs for the LUT, theoritically yes, but the curve processing has an exponential interpolation branching for values above 1, and below 0 in some cases (which is idiotic if you ask me, but here we are\u2026).. > In fact I\u2019m afraid our calculations are exactly the same :-)\n\nRgb = rgb * lut(norm) / norm\n\nah. Indeed. So it is mostly a problem of readability, when you overwrite the variable norm again and again, it's easy to lose if we are referring to the new or the old. So I just split steps in the most stupid simple way, and the code becomes easier to read.. > I thought you were advertising this ... :-).\nNo, I shared the video because it enlightens the core problem of pixel processing in a color-managed way, an issue that few FOSS developers are aware of (proof being nothing in dt tries to address it). But to me, every equation that does not derive from a vector field integral looks like fake science.\n. Maybe we could loose the \"blending option\" label and put the mask icons under a line or on a slightly different background, because it comes in every module and waste some space. Also, the margin underneath the icons is too big.. > I saw a commit today that removed this big unused space at the bottom.\nStrange, I don't seem to have it. The commit is in git log, but the UI is the same.\n\nhowever I also though that the section and the verbose tooltip that comes with it may be helpful to novice users.\n\nSince it's a systematic/recurring option available in all the IOPs, I think it's not a problem. People will need to open the manual and look at the tooltip, but it would declutter the UI a bit.. > I don't know how this kind of choices are made within the Darktable developers, is there a guideline or something like that for choices that just depends on the targeted users ?\nThe most angry dev usually wins the argument :rofl: . The dev mailing-list is under-used for that kind of matter, it's the only place where you can reach (some) devs and (power) users.. Hold on, I just found an error on pointers shifting in the wavelet decomposition. I need help to understand what makes CLANG fail. Still something that doesn't agree with CLANG :roll_eyes: . > All those SSE circuitry are giving me headache :)\nI know right ? Did you benchmark it ?. > I'll have to actually test this. Is that a final version?\nI think so. Maybe we can let it sit for a while, to see if I have more ideas to speed-up the computations.. > Most timing were around 0.35s with current version and with this PR most timing are around 0.4s.\nNice :rofl: \nDid you test on portrait and landscape pictures ? I found that, at similar resolution, portrait-oriented pics process faster than landscapes.. Also please note that I compile with -O3.. My reference for this was the local contrast module, because it does essentially the same things but on only 1 channel instead of 3. Zoomed at screen size, this PR makes atrous run just a bit faster than local contrast, which was clearly not the case before, and zoomed at 100 %, atrous runs twice as fast, which is good since it does 3 times as many operations.. No, is that an LLVM option ?. clang complained here ? I missed that.. something is broken in SSE version. denoise profile means : if there is a noise profile for your sensor, use it, otherwise, fallback to a generic statistical method.\nIf you don't have access to custom profiles in the UI, it means there are none for your camera. So, please, contribute with pictures.\n\nHowever, I still believe that the dropdown should show similar models of cameras or all models of cameras, as it would at least show the feature working.\n\nThe feature works by using a generic method. Using a different profile from another sensor entirely defeats the purpose of having profiles (aka customized algorithm built for the specific noise stats of your particular sensor + ADC).\nSo, everything works as planned, but you might need to read the manual to get a sense of what's going on.. Indeed. fixed with #2030 . As for Neo, it breaks on Windows with dt, but @rawfiner is using it to debug OpenCL with success on Linux Mint or something. Maybe just blacklist it for Windows ?. I think the CZ translation has been disabled in dt 2.6 because it is not complete. So you got the legacy translation at first, but then the option was removed. I think you can revert that in darktablerc. Or maybe contribute a translation for darktable 2.6.1.. > For the color picker next to the graph you need a hbox. I can give a hand on this if you like.\ngladly :-)\n\n_mm_load_ps() is probably what you mean. but swizzling data from float to sse registers may well eat up any performance benefit you might get here. did you feed this code in a minimal main.c or similar to clang and look at the disassembly? sometimes it uses vector code already. in a float[3][3] case it may be hard to cast it to a __m128[4] block automatically though.\n\nI have not yet checked that, I'm just benchmarking the running times for now. I have some background with ARM Cortex assembly, but not with X86, so the dissassembly won't be super useful info for me.. Thanks @TurboGit !. Incoming ! See #2037 . > For me 10.5pt is a bit big. 9pt seems to be what we had before. Maybe use 10pt?\nWhat about 1em ? So it should be you OS size (maybe ?). So, I tried to compact things a bit:\n\n. > Would that work for you?\nI understand, but it's really tricky to split that in small chunks since the goal is to unify the look of several bits. So it's a lot of small changes here and there to build something consistent and join the 2 ends of the bridge.\nThe last commits make the histogram CSS-theme-able, align it on the modules and remove the EXIF info.\nThen, I have aligned the tonecurve on it, using the same CSS properties, and cleaning stuff like putting the histogram behind the curves, and using a true gradient in the background, even for the L mode. Said gradient uses the \"true\" RGB values which Lab coordinate are \u00b1128 at L = 75, and the grey gradient adjusts itself to match the log scale. See :\n\n\n\n\nI have not forgotten your code reviews @TurboGit , they are coming.\nNext are the other curve-like modules, then the equalizers.. I can confirm, at least on Gnome, that putting the default font size at 1em follows the OS font size. Need to check when the DPI changes.. > for macbook retina 1em is quite big (like 12 pt; 8pt or 9pt is quite better), maybe it could be customizable via preferences dialog\nHave you check it ? 1em is not a hard size, it's supposed to use whatever font size is OS-wide defined. Every pt size will assume a DPI, 1em assumes nothing and just adapts to the environment (usually).. ok, the thing is the DPI setting affects the font and the drawings (curves, borders, etc.). So I think it's more generic and versatile to let users adjust the DPI overwrite, and not touch the font size.. > within one of the last changes \"void dt_ui_border_show(dt_ui_t *ui, gboolean show)\" was removed from gtk.c resulting in an error in slideshow.c\nthanks ! I didn't see that. It should be fixed with the last commit.. > Using generic name like Sans is fine. It can be redefined via fontconfig.\nthere is no fontconfig on Windows and Mac OS. What would be the best option then ?\n\nE.g. select filename - text background remains the same, text color barely changed.\n\nyes, it's planned. Every active area (buttons, menus, text areas) will be emphasized.. > default desktop font will be substituted (which is the best IMO)\nOn Linux Gnome, the default \"Sans\" font is quite ugly and doesn't use the system-defined preference. I don't know how to tweak fontconfig, but I would go for something that works out of the box and looks nice. I think packagers could then add the Roboto packages as dependencies. . > > On Linux Gnome, the default \"Sans\" font is quite ugly and doesn't use the system-defined preference.\n\nlocal.zip\nAdjust it to your taste and copy to $XDG_CONFIG_HOME/fontconfig/fonts.conf or /etc/fonts/local.conf Roboto is not everybody's font of choice.\n\nSo, at the end, it falls back to asking users to edit config files. I think the default setting should be predictible and immediatly ready. If you don't like it, you will be able to change that using your own CSS stylesheet, which is the same as editing fontconfig but with support of the 3 OS. Roboto has been choosen because it has appropriate kerning for normal, light and condensed variants, and also has been design with high-DPI UIs in mind. So all in all, it seems the best choice, regardless of the aesthetics.\n\nHi i just found this PR and i just want to say that on basic screens like fullHD 24\" is current UI size ok and making bigger spaces will just stretch everything, making it less convenient because sometimes single module wont fit on screen and i would have to scroll back and forth\n\nHaving to scroll is something you will have to do at some point anyway. The way sliders and controls are force-fitted to squeeze the maximum into the screen height is currently barely legible, especially for people with disabilities. See how the slider triangle overlaps the label ? My opinion is legibility is more important than avoiding scrolling. But I noticed that scrolling sidebars with arrows keys is currently not possible, so that is something to fix.\nI'm currently designing the UI\u00a0on both 24'' 1080p and 15.4'' 4K screens, and I can confirm the DPI scaling works properly. In case you are not happy with it, you will be able to scale every space/text/drawing at once using the globabl dpi_overwrite setting in darktablerc.. > Have you tried option number 1 and rely on default GUI font? It does work in Linux (both Gnome and KDE) and Macos.\n\n\nIf font-family definition is removed at all (just font-size left), default desktop font will be substituted (which is the best IMO).\n\n\nThat's the current state of the code. dt takes the default GUI font already. But I would rather have it managed internally with \"clean\" default than rely on whatever 1990's font is set in fontconfig.. I know, I'm trying to find out why.\nThese parts of the code were handled with nasty workarounds, I have removed them and try to have everything working in an unified fashion.. > I thought you said Macos and Windows is the issue here. But they use their own font settings/substitution systems. GTK+ settings relies on fonts specified via gsettings/dconf and fontconfig is not used unless you specify some generic font name.\nYes, I meant MacOS and Windows have no fontconfig, so what GTK uses as a default is kind of a black box. But even on Linux, it seems fontconfig is not aware of Gnome system font, so what it uses is some basic default font. The font is configurable anyway in darktable's CSS stylesheet, so my point was: configuring fontconfig through an XML file doesn't make it easier for the regular user than changing the font name in the CSS stylesheet. So I would rather have a safe predictible fallback for most users, and the ones not happy with it will only have to change one line of CSS.. > found a warning in the command line output:\n\nTheme parsing error: darktable.css:145:26: The style property GtkRange:slider-width is deprecated and shouldn't be used anymore. It will be removed in a future version\n\nWelcome in my nightmare. I don't have it with GTK 3.24, so I suppose you use a more recent version of GTK than I do. Anyway, that part is not critical, so it will get removed. Thanks for the report !\n\nQuite radical statement :) I believe Cantarell is the one you refer to?\n\nJeez you are right ! Quite possibly the most ugly \"trying-hard\" font I ever stumbled upon\u2026 There is not much I ask from a font\u2026 Having harmonious metrics, proper kerning and ligatures. Well, Cantarell makes every label look like a line of fat midgets having an erection. Well done Gnome ! Finally a free software that delivers what it promises. :slightly_smiling_face::gun: \n\nHelvetica Neue? scream Why discriminating Windows users then, add whatever they use these days (Segoe UI?) too smiley\nBTW, is it San Francisco font what they use now in Macos, not Helvetica?\n\nFixed, I have added San Francisco and Segoe UI. What do you have against Helvetica now ? :-P\n\nAnd don't forget about localization. The World is bigger than LGC, e.g. what Japanese or Chinese users should do? Why treating them like special needs users?\n\nI have tested Japanese, Chinese, Greek, Hebrew and Russian, everything seems to behave on Gnome.\n. > I've tested this quickly today. Found that it is making progress. Just noted that the entry has the height far too important. Also all buttons for the IOP (toggle active, preset...) are too big compared to the labels of the module.\nI know, I have a hard time finding out why darkroom and lighttable modules behave so differently, I'm unable to have a consistent behaviour between both. It's probably related to #2051. It's all a grep big adventure and walls held together by coats of painting. . This what we have now : \nFrench:\n\nJapanese:\n\nChinese:\n\nRussian:\n\nGreek:\n\nHebrew:\n\nNow, the icons (preferences, gamut check, enable/disable modules, etc.) can be resized from the CSS and don't use hard-coded sizes.\nI have changed the function called when the overexposition/gamut-check/etc. are called, so only the central view is regenerated, and not the thumbnail, so it's a bit more snappy.\nStill TODO:\n make the color-picker bigger, and their active area as well\n figure out why the entry boxes are that high (I'm still clueless)\n* propagate the tone curve color parameters (taken from the CSS) to basecurve, equalizer, levels, denoise profile wavelet.. > > \n\nI've always wondered why there is extra space right before lens name in some languages... notice how Nikon AF-S is not aligned with the line above. Or \"Creative Commons...\" below.\n\nThere is half a space in some languages, which becomes a full space in others. I'm not sure, this part of the code only extracts the EXIF and such, it's not supposed to add anything. Thanks @timur-davletshin \n@TurboGit I haven't touched the masks icons for now, but I\u00a0think I will remove the label and just put them in a box with a different background. Thanks for the diffs.. #2064 should be fixed by commit 294b2cd. dt_dev_invalidate(dev); seems to be enough to trigger a redraw and raise a PIPE_DIRTY signal, so dt_control_queue_redraw() was redundant.. ok, the menus background, comboboxes and icons alignment in darkroom are restored.\nNow, I have removed the icons of the modules in the darkroom. Before everybody yells at me, allow me to make my case:\n\nevery icon in the UI is a button, except for modules icons, so it's an design inconsistency\nthey add a touch of color which is not necessarily welcome, and holds no informative meaning (alike gradient sliders or histogram, for example)\nthey steal a fair amount of text width for modules and instances names\nall in all, the modules names are more significant than their icons, yet they get truncated sometimes, because of the icons,\nmodules on the left-panel don't have icons, so it's another inconsistency.\n\nSee how it looks:\n\nI still have details to fix, like the blending options.\nAlso, I have redrawn some icons to make them lighter, square and ensure they all have the same dimensions.. ok, the menus background, comboboxes and icons alignment in darkroom are restored.\nNow, I have removed the icons of the modules in the darkroom. Before everybody yells at me, allow me to make my case:\n\nevery icon in the UI is a button, except for modules icons, so it's an design inconsistency\nthey add a touch of color which is not necessarily welcome, and holds no informative meaning (alike gradient sliders or histogram, for example)\nthey steal a fair amount of text width for modules and instances names\nall in all, the modules names are more significant than their icons, yet they get truncated sometimes, because of the icons,\nmodules on the left-panel don't have icons, so it's another inconsistency.\n\nSee how it looks:\n\nI still have details to fix, like the blending options.\nAlso, I have redrawn some icons to make them lighter, square and ensure they all have the same dimensions.. Noted, thanks !. > Yes, but I'd love to be change this background per-photo, as not all of my walls are middle-grey. Lightroom for example, has simple button that open color chooser. Also, change this in filmstrip in the darkroom is (IMHO) just ugly and what's more important: distracting.\nWhy do you want to change the background per photo ? \nThe surround color suitable for color editing and proofing is well studied, and the standard is a light grey (70 %) : https://xritephoto.com/documents/literature/en/StandardViewingNTK_EN.pdf\nThis is well beyond aesthetics, and constrained by the optical illusions that can result from using a dark background. So, the whole dt UI should be medium grey at least, but I have kept the dark one for compatibility reasons, and since @TurboGit has added support for themes, a proper grey theme is to come right after.\n\neven now, you can end up with truncated name, you get maybe 2-3 letters?\n\nthat depends of course of you font size and sidebar width\n\n* you enlarge all buttons in the module bar - you loose about the same number of letters you get by removing icons. I've never had problem with those buttons, so I hope I'd have chance to bring it back via css.\n\n\nthe buttons have been made the same size as the lowercase text (x-height) to produce an optically continuous line. I could try to squeeze horizontal margins though, but I'm pretty sure it's a bad idea for those using touchscreens. There is no option to make it re-appear in CSS, they were hard-coded.\n\nthere is always tooltip with full name\n\nrelying on a hover event to get the full label is bad design.\n\n* most important, it gives me a huge speedup in finding proper module (most of modules I use have icons). Adding icon/glyph is not only visual thing, this is quite common technique to improve UX.\n\n\nThat would have been true if the icon had been on the left of the label. Having it on the right (in left to right languages), it means you have already read the label when your eyes fall on the icon. So this is not a common technique in UI at all (icons are always on the left of the label). Does the lack of icon prevent you from finding modules in the lighttable ?. in the last commit, I removed the gtk_widget_set_size_request on the module's expander arrows. For some reasons, that made it disappear, even forcing it with gtk_widget_show_all. If anyone has an idea why\u2026. \nactually, I\u00a0wonder if it's not better without the arrows\u2026. > Sure, as long as the panel title is will distinguishable when opened. And the module background is with different color. How does it looks with your latest version?\nsee the screenshot above. > with latest commits i got a segmentation fault on 'compress history stack' on osx\n\nto reproduce: open rawfile in darkroom and click compress history stack\nmessage:\nMagick: abort due to signal 11 (SIGSEGV) \"Segmentation Fault\"...\nAbort trap: 6\n\noops, I\u00a0fixed that this morning and forgot to push the commit.\n\n\nI'm not sure it's a good ideas to remove them. I'm afraid, some new users could be lost without seeing them. It's a way to quickly know that options are hidden besides the module title.\n\n\nThat's my fear too, but on the other hand, all the modules work the same, so I think they will catch it fast. I have looked at what Lightroom and Capture One do, they have arrows, but no icons and fewer buttons on the header line. So all in all, I'm not sure. What I'm sure of is they can't be tweaked in CSS easily, and removing their hard-coded size make them disappear at all. \nI would be careful to not multiply the options, because that makes the maintainance more difficult, and the work I'm doing now is just a maintainance cleanup to make different pieces of code written at different times by different people homogeneous in appearance and in API. For example, the code for the lighttable modules is not the same as the darkroom ones, so it's twice as much work to keep them on sync. That makes me want to have simple things doing simple tasks robustly, and not pile up too many GUI options, because what I'm doing now will have to be redone when GTK 4.0 is out, and not sure somebody will have enough time and patience for that. So, let's make future-proof decisions here and keep the job easy for the future.\n\nI want to compare it against wall color too. Now I'm doing this by using framing module, but It feels like workaround for common case.\n\nHmmm, not sure it usefull though, since your wall doesn't emit light as your LCD screen does. But that would be for another PR.\n\nExperienced user shouldn't have to look at the full name at all except multi instance case. But even then the custom name is what user need. I don't know how this looks in other languages, but even with renaming I've got too long names almost only with denoising modules - the problem is that it hide the center part of the label, so the denoising module type. With proper* icon I could still distinguish modules easily.\n\nBut experienced users will also have memorized the place of the module, the approximative length of the label and its first letter, so the concern is mostly new users here\u2026 who might end up with a truncated text not saying much (and maybe not expecting a tooltip to be there to tell them). Looking at Lightroom and Capture One (assuming many users will be familiar with at least one of them), none have informative icons, but only buttons (= controls). I'm myself a bit lost in modules without icons, but let's see how we/I adapt to that, because it's mostly a matter of habit after all and it has never been an issue with lighttable modules. From a personal taste point of view, I also think these colorful icons look childish and harm the percieved credibility of the soft, and I would very much like to have darktable not seen all the time as Lightroom's trying-hard poorer sibling.   \n\nBug report:\nthere is problem with instance renaming: you need go to lighttable and back to darkroom to see new name of instance.\n\nHmm, strange, I can't reproduce. Maybe fixed in my latest commits ?\n\ntheres also an issue with an ampersand in style names:\n(darktable:61582): Gtk-WARNING **: 23:50:00.127: Failed to set text 'Emulation based on B&W film Ilford HP5 Plus 400 (http://bit.ly/t3mujinpack, v0.5.0)\ntone curve (on)\nchannel mixer (on)' from markup due to error parsing markup: Error on line 1: Entity did not end with a semicolon; most likely you used an ampersand character without intending to start an entity \u2014 escape ampersand as &\n\nI didn't touch that I think, styles strings are handled in GTK menus. But I think @rabauke has done changes recently on strings, maybe it is linked ?. > theres also an issue with an ampersand in style names:\n\n(darktable:61582): Gtk-WARNING **: 23:50:00.127: Failed to set text 'Emulation based on B&W film Ilford HP5 Plus 400 (http://bit.ly/t3mujinpack, v0.5.0)\ntone curve (on)\nchannel mixer (on)' from markup due to error parsing markup: Error on line 1: Entity did not end with a semicolon; most likely you used an ampersand character without intending to start an entity \u2014 escape ampersand as &\n\ncan't reproduce either. Could you check with the latest commit ?. > One proposal for the activate + open action. We already have a combined action for the middle click (like apply preset in the instance). I would use the same here, that is middle-click to activate and open and keep the current behavior for the left click.\nThe purpose of this behavior by default is to notify new users that modules are collapsed and expandable, because their arrow gets replaced by the ON/OFF\u00a0button to save space, so they might not get the clue. The middle-click is a good idea, but I would use it to enable without expanding, as it would be something only documented users might want to speed-up the process in some particular cases.\nAlso the invalid casting should be fixed.. > > \n\nThat would not be very consistent. As I said we already have combined action with middle-click. (like preset as said previously but also to create a new instance with the multi-instance button). So with the current state I think we should respect this behavioral choice.\n\nI understand, but how do you advertise the expandable nature of the modules then ?\n\nJust found also that in the lighttable the inactive buttons in the \"history stack\" module are not visible.\n\nIs it useful to have disabled controls visible ? (their colors are just declared transparent in CSS).. > Don't know why but the lighttable display on my side is broken with the current version. If I move the mouse over the lighttable I have some big grey squares drawn under the mouse.\nCould you send a screenshot ? The lighttable is under reconstruction, I would like to push the overlays outside of the picture frame, like Capture One and the new Lightroom do it.. > Also, my point is not only for me. But adding more and more things into a PR is nice but will delay for a long time the integration (I have also experience where at some point integration is just not possible anymore). This will require maintenance and energy on your side to resolve conflicts. All in all, in my experience it is always a very painful way of working.\nI know, but the scattered UI design is also a consequence of trying to keep PR small. Trying to merge style rules and GUI behavior between different programming layers makes for a big PR, since general rules have often unexpected effects in some parts of the code handled with local workarounds. \nWe can review the code on Skype at some point if that makes it less painful. \nI will check the lighttable, it doesn't reproduce on my side.. @Turbogit I have reverted the histogram changes and the lighttable things, and also squashed a lot of commits, so I propose to finish the work on the CSS + bauhaus + graphs (equalizer, basecurve, etc.) and that will be all for that PR. \nWell, there is still the collapse on enable feature on IOP modules, and a new button in lighttable to compress the history (that one was long needed).. > For the prefs, I can add them if you like.\nThat would be great, since you have more experience than me on that part. I will continue the bug hunt on the CSS then.. The latest commit add more key accels in darkroom:\n\nCtrl + Shift + N shows/hide the navigation thumbnail\nCtrl + Shift + H shows/hide the histogram\n\n~~When the left panel is collapsed, or the navigation is hidden, and the histogram is hidden too, computing the preview pixelpipe becomes useless so we disable it to spare the overall performance.~~ reverted.\nAlso, I have added accels to show/hide the panels in every view\n Ctrl + T : top panel\n Ctrl + B : bottom panel\n Ctrl + L : left panel\n Ctrl + R :\u00a0right panel.\nNote that the collapsed state of the panels is saved per view in darktblerc. The accels are user-configurable.\nBecause the panels can now be handled from the keyboard, I have added a last accel (B)  that allows to hide/show the outer border containing the collapsing arrows for panels, so we save 10 pixels \u00d7 DPI on each border. This will be usefull for desktop users willing to get a full-screen experience, but touch-screen users may want to keep the arrows.\nDefault UI:\n\nHide the histogram:\n\nHide the histogram and the navigation (stop refreshing the preview pixelpipe):\n\nHide the outer border and callapsing arrows:\n\nSwitch to full-screen mode with no borders:\n\nThat one should look stunning on DELL thin-bezel screens.. > I think some iops depend on preview pipe being present for their computations. E.g. does zone preview in zone system iop still work?\nGood catch. I\u00a0think it will end up with a manual kill-switch then.. The preview bypass is reverted.. I will fix the conflicts tomorrow and that will be all for that PR @TurboGit, unless someone finds more issues.\nI will propagate the CSS templating from the tone curve from the other graph modules in another PR.. >     * in the color picker module the arrows for the combobox are very very small\n\n* in the color picker, the picker itself is huge :)\n\n* In the more module we don't have visual info about the module already selected, this makes this list very hard to use.\n\n\nok. \n\nAur\u00e9lien, I see that you have added back the image information in the histogram, look at #2181, I think that we can clean up the histogram. What do you think?\n\nI'm all for this.. I'm still working on it. I have discovered some other bugs.. > I have just tested this again and found out that the expos\u00e9 view does not display correctly. The images are full black. I think I have already reported this, but since I was not able to find the reference I prefer reporting again. Sorry if this is already known and in the TODO list.\nYes, expos\u00e9, lighttable at full-size zoom level, and focus preview are broken, I'm on them since yesterday with no luck so far.. It looks like an ugly hack. In which case is the latitude not initialized ?. Actually, my bad, the exposure steps are hard-coded and not configurable.\n\nLeft panel is most of the time collapsed in my case.\n\nThe real question is: are the EXIF info useful in the histogram ? My feeling is I don't care about the camera settings at all during retouch. But I really like a clean UI to focus on the picture.\n\nI use this quite frequently as it is much faster than searching for the exposure module. Would be nice to have more of this easy access features in dt.\n\nAnd using it in a blind fashion does not bother you ? If so, did you consider setting a keyboard shortcut\n? I'm asking because, everytime I'm \"using\" the histogram to set the exposure, it's a touchpad accident while reaching for the color channels or waveform. So, it annoys me more than anything.. hmmm I really hate duplicating features, it's bad design and twice as much maintenance. Especially when said feature makes use of garbage GTK wizardry. \nAllow me to reformulate this question: what would be a better way to make the exposure settings more accessible in its module ? And the ISO setting more readable/reachable in the panel ?\nI tested it, and you cannot set shortcuts with key + arrow up/down or mouse wheel up/down. Imagine you have assign the key E to exposure, and page up/down for coarse increment, arrow up/down for precise increment. So, you have one letter by setting to remember. Would that do it ?. what if we move the exposure settings at the beginning of the EXIF widget ? Even small, this text makes the waveform histogram practically impossible to read in many cases.. > A status area on top of the image would be perfect for me :-)\nSame here.\nI will reorder the EXIF metadata in the module too, maybe use categories (exposure / date / file). Also, I think having a shortcut to show/hide the exif module would help.. I will see if I manage to make the histogram resizable. As for the quick edit, I believe, long-term speaking, the best would be just a simple key + up/down (either with arrow keys or mouse wheel). What really sucks with the histogram is you don't have feedback.. Imagine you get a shortcut, like E + ArrowUp to set the exposure, could you give up on the histogram ? Or even E + PageUp for coarse tuning, and E + ArrowUP for fine tuning. Better ?. >     1. Feedback, i.e. show the current value of exposure and black level compensation while scrolling or dragging. You can see this information in real-time now if you have the exposure module open, but it defeats the purpose.\n\n2. Modifiers - if normal scrolling is in 0.15EV steps, holding Shift while scrolling could switch to e.g. 0.05EV steps.\n\n\nSo why not directly use a keyboard shortcut, which would give the focus to the module ? That would make use of the existing UI without having to overlay more shit on top of an already hard to read graph. \nHonestly, I have spend the last 24 days full-time, cleaning 10 years of rough GUI code and discovering undocumented features (there are VIM shortcuts hidden in the soft, for example, try typing : ), I think adding more options in the GUI will just add more spaghetti in the code and increase the maintainance overhead for the years to come.\nI'm a big fan of keeping things stupid simple. I know most you like this half-baked feature, but it is half-baked nonetheless and I\u00a0would rather make the real exposure module more (cleverly) accessible from the keyboard than pile up more shit code on the histogram. There will always be readability problems when you overlay text on top of colorful graphs, let alone issues with touchscreens and touchpad (what is a scrolling step when the scrool is continuous, from a touchpad ?). \nSo, the more I'm digging in it, the more I'm convinced that scopes should be read-only, and poor accessibility of the settings should be adressed at the source, in the controls, not by duplicating controls somewhere else in the GUI.\nIf modules had proper keyboard shortcuts, we could even do basic editing directly from the lighttable.. > I do greatly appreciate the work you're putting into darktable, but please be careful not to descend into the \"users are stupid and devs know better\" mode of thinking (your words :-)). Someone has put effort into implementing this feature, it works, it's liked by many, so removing it because one of the devs does not like it or need it may not be the wisest decision.\nIt doesn't work well, not in a reliable way, and not for touchpads and touchscreens, that's my point. Let's not forget the core problem it tries to solve (exposure being hidden in modules lists), and address it directly at its source, instead of creating more problems like the scrollable histogram does. In every kind of design, duplicating features always says something has been missed at the beginning.\nFor your information, you can already set up keyboard shortcuts for every module slider in the preferences (reset, increase, decrease, modify). So you can already have Shift+E to increase, Ctrl+E to decrease exposure, for example. That can be improved by having coarse/fine tuning, and giving focus to the module + unfold it when the shortcuts are triggered. And could be reused at some point to get darktable to work with MIDI keyboards/retouching consoles.\nThe other point here is the histogram is a custom-made GTK widget. GTK lib changes very often, and tend to deprecate things carelessly. That mean every GUI part of the code has to get some love every once in a while and wil never be stable, at least to manage GTK versions issues. Sticking to the GTK standard and avoiding customized things is only avoiding maintainance overhead, long-term speaking.\nAlso the number of // TODO: fix this case in the code is alarming, and some have been there from 9 years. Time to clean.. I have added a shortcut to hide/show the histogram in #2037 . Are you sure nothing can be done ?. That might create more problems than the one it tries to solve, e.g. preview inconsistencies, weird corner cases and such. For example, that would require some sort of head-up display to monitor wether or not said modules are applied. Where do we fit this in the (already cluttered) UI ?\nI\u00a0think it might be better to just bake yourself a style and apply it manually when you are done editing, instead of using auto presets.. Your \"when module is expanded\" column is linked to GUI code and the state of the GTK widget. We already have a hard time ensuring the \"open only one module at the time\" global option is respected in the GUI, relying more heavily on it is taking odds at this time. Not that it's a bad idea, but dt's code is not stable enough at this time.. You are welcome. I have something pending for blues and out-of-gamut issues : #2035 But it's bugged for now.. I guess that falls back into U-points, because you would need an extra inclusion/exclusion radius to drive the limits and blending of the parametric range.\nIt's definitely a good idea, but it needs some thinking, because there is no ready-to-use way to do that already.. sounds like non-thread-safe GUI code being reset before completion, possibly resulting in double free on pointers.. > It filters out the Monte Carlo noise inherent to stochastic ray tracing methods like path tracing\nCamera noise is a combination of gaussian and poissonian noise. Monte Carlo noise is not what we deal with in natural images. You can close @TurboGit . darktable's H&S is wrong from the beginning. It's not just a matter of gaussian/bilateral/guided masking, it's the colorspace where it works. I plan on adding a tone equalizer, which would be a S/H module on steroids, with more channels, and using a laplacian pyramid as local contrast does. Stay tuned with #1904 . Think about it\u2026 What are highlights ? -1 EV under pure white ? -2 EV ? At -2.45 EV, you have mid-grey already.\nSame applies for shadows, with a huge difference: black does not exist. So you would have to decide if your black is -8 or -10 or -12 EV from pure white, then how far from black the shadows begin.\nWhatever you answer, it's a developer arbitrary choice. So, having a full equalizer with channels spaced evenly by 2 EVs is just making underlying choices accessible to the user. The logic is the same, you just get more control over the full range of luminance.\nThe current module is flawed from its core. The proper way to do that is using log-encoded RGB or xyY space at the beginning of the pipe, after exposure module, but it works in Lab at the end of the pipe. So don't hope a quick fix, it needs to be re-written.. > At the end of the day most users use several basic modules and we need to make sure they are the best possible.\nI will never understand why users go on the raw path to take control on the pictures, while just wanting simple basic modules that just work. It's a paradox to me.\nLightroom and Capture One have users trapped in their engineering decisions. They have decided for you what \"shadows\" and \"highlights\" mean in terms of luminance values. Problem: these meanings assume you work in clipped display-referred RGB space, in an ICC workflow. That's rather restrictive.\nIf you work in HDR scenes, you are screwed, because that doesn't fall into the \"correct\" use-case they designed for you, on the assumption you will work on camera raws in an ICC workflow. So, that sums up to a very simple design dilemma: do we want a fixed tool, simple but limited in use because of all the underlying assumptions it makes without telling you, or an all-purpose tool, adaptable but with more parameters ?\nThe ICC workflow is not well-suited for HDR work, and we have to think of future-proof workflows that can use ICC but don't rely on it. In these setups, \"highlights\" can have very different meanings.\nHaving a tone equalizer is not much more complicated than a simple shadow/highlights. You will have whites, highlights, mid-tones, shadows, deep-shadows, blacks and deep blacks instead. More controls, but the same use principles apply, and nobody will decide for you how large the highlights range is.. > When a photographer wants to achieve a higher dynamic range than his camera allows, the only way is to shoot raw and work on it in an image processing software.\nThe point is not to achieve higher dynamic range than the camera offers (that's not possible), but take full advantage of what the camera has in its guts. Now, having more than 14 EV of dynamic range at 100 ISO is standard, and it's HDR already, since JPEG and most displays have only 8 EV available.\nThe whole ICC color-management chain was built assuming 100 % luminance was diffuse white, and everything above was clipped. So, middle-grey was at 18 %, and, with older cameras and color-film, black was at -8 EV from diffuse white. So, everything below 0.4 % luminance was assumed black. All in all, you exposed for mid-tones, got your grey at roughly 18 %, and there was not much variability in pictures, so you could just decide that highlights were above 50 % luminance, and shadows below 0.8 %, and that was about it.\nNow, with 14-EV cameras, 100 % luminance can be direct sun-light, but since everything above is still clipped, you exposed to the right and recover shadows later in software. Meaning the actual mid-grey can be as low as 4 % luminance. Meaning your \"physical\" highlights can actually range from 12.5 % to 50 %, up to 100 %. And that depends on your scene, camera, ISO setting, etc. Because at 3200 ISO, most cameras have barely 8 EV of dynamic range remaining.\nSo, I understand that users love having 2 cursors doing magic for them without the need to understand what's going on, but how do you expect me to know, at the time I code, what is the luminance range of highlights for today's, yesterday's and tomorrow's cameras, at the current ISO ?\nIt's not even about having pro vs. basic options, is just about having physically-meaningful options. And the thing is \"highlights\" (as in LR or C1) can actually mean \"whites\", \"highlights\" or \"midtones\" depending on the picture base exposure. Is that reliable, systematic and reproductible ? Nope.\nThe only thing I know is cameras have a top dynamic range bounded at 16 EV, because they use up to 16 bits integer encoding. So I split the dynamic range in 8 evenly-spaced channels, every 2 EV, from 0 (white) to - 16 (black), I give you a cursor to manage each channel, and you will be able to adapt to every possible exposure scenario without having stupid devs making stupid choices for you, assuming you are more stupid than them and too lazy to read a manual. \nSorry, but in this case, reliability and simplicity cannot be achieved at the same time. Or you get a half-baked shadows-highlights module, that is simple to use (maybe) and messes up you colors at the same time.. Don't apologize, it's ok. Different points of view are to be expected between devs and users. I'm just trying to explain that what seems simple from an user-perspective is not necessarily future-proof and trying to replicate front-end features without undestanding the underlying assumptions they make can blow up in your face.\n\n\nzone system works too late in the pipe, and in a way that need to take from one zone what you give to another. It can be also damaging for color preservation and local contrast preservation. What I propose is fully independant channels, working early in the pipe, like simple selective exposure adjustments, in a way that preserve both colors and local contrast.\n\n\nBe extra careful with \"simple\". It's not because large companies are behind the soft that everything is clean under the hood. Especially when design choices have been made 25 years ago, for 25-years-old gear, and force-forwarded for today's workflow. Don't underestimate the power of habits and legacy. \n\n\nMy design politics rely on the ACES, which is a modern & future-proof standard. Basically the whole cinema industry is switching to that since 2014, but photography holds on legacy workflows because they \"just work\". How long do you think we will be able to afford things that just work ? \nImage processing is hard. \"Simple\" solutions often fallbacks to limiting the features, making the code more rigid, and restricting the use. I find that it's sometimes better to not hide the intrinsic complexity of what's going on under the hood, and just educate users instead. That results in more efficient workflows, even if the UI might seem more impressive, because the tool can be adapted to various uses. Otherwise, you might end up fighting against the software to overcome its limitations, and get locked in its design choices, which is somewhat acceptable in proprietary software, but certainly not in free/opensource.\nGood design is not things that just work now. It's things that are done the proper way so they work with as less side-effects as possible, and they keep working in the future, when cameras have maybe 24 EV of dynamic range. Because color-management in HDR setup is a serious and tricky issue.\n\nSee for yourself : https://discuss.pixls.us/t/a-tone-equalizer-in-darktable/10678. > How much longer will it reach users?\n\nASAP :slightly_smiling_face: . Bad idea. EVs units are actually quite explicit to state what's going on (perceptual logarithmic space), especially for those who are familiar with flashmeters (pretty much every professional photographer and old-school film shooter), and consistent with filmic and exposure settings. EV means it's a physical measurement you could acquire on set, using a lightmeter, so, again\u2026 making it \"simple\" will lose some accuracy and the link with the analog reality. \nActually, the labels are wrong in general, because they depend on the actual exposure setting/dynamic range. For example, in a 8 EV dynamic range scene, mid-tones are around -2.45 EV, so the -2 EV channel is high mid-tones already. But in a 12 EV one, the mid-tones are around -4.45 EV, so the -2 EV channel is truly highlights, and the -4 EV is indeed mid-tones. The only \"true\" part of the label is the EV measure, the rest is a \"general audience\" hint. Lose it, and it becomes a dumb software.\nAlso, a tone equalizer is something people already know: https://www.acdsee.com/en/lighteq That's far from a simple highlight/shadows module.\n\nI do not believe in educating the user.\n\nIf so, users are invited to shoot in-camera JPEGs\u2026 They are pretty good when the camera is set properly, and firmwares do sometimes a better job than any raw editor, because manufacturers know their sensors better.. You are welcome.\n\nI did not really understand whether the bottom line is that you are offering an alternative to the existing module.\n\nIt is an alternative than can do much more.\n\nthe question is which one does it best,\n\nDefine \"best\" and \"simple user\" first\u2026 I design for professionals. That is, people with understanding of what photography is, willing to have a reliable tool, working in a predictible way, giving reproductible results in a minimal number of steps, and grounded in the physics of light to have on-stage measurements transferable into software settings. In this context, for me, the best module is the one allowing luminance editing without affecting the color hue and saturation at all.\nThe modules that currently fail at this are : \n\nbasecurve (hue shifts, desaturation of highlights, oversaturation of shadows), \ntonecurve (hue shifts, desaturation of highlights, oversaturation of shadows), \nhighlights & shadows (hue shifts, haloing, desaturation, oversharpening), \nglobal tonemapping (oversaturation, unreproductible results between pictures and zoom level), \nlevels (de/over-saturation, depending on the grey adjustement)\nlocal contrast (desaturation, hue shift towards greyish-blueish).\n\nIncidentally, all of them perform non-linear operations, and all except basecurve work in Lab colorspace.\nThere is only one way to completely preserve color, while performing luminance adjustments: doing linear operations in a RGB linear space (that's what the exposure module does, and what the tone equalizer will do too). Some good trade-offs involve doing non-linear operations in normalized XYZ space (that is, xyY) or in a normalized RGB space (what filmic does). In Lab, the hue linearity is a lost cause from the beginning and there is nothing we can do, because this space has never been designed to be an editing colorspace.\nTo preserve colors, you have to keep things stupid simple and stick to multiplications of RGB values. If you can't (e.g. you want to apply contrast), you have to use a proper space and some sweeteners to deal with the mess you do on colors. Besides, using blurred masks in Lab does not make sense since you will get weird transitions between contrasted areas. See: https://www.youtube.com/watch?v=LKnqECcg6Gw\nand https://www.visualeffectssociety.com/sites/default/files/files/cinematic_color_ves.pdf. Here is a dynamic range compression:\nWith S&H:\n\nWith my tone equalizer:\n\nSee how the bush (right bottom corner) turns into magenta in the S&H version, while it remains green in the TE one ?\u00a0Also, S&H resharpen too much, whereas it's not its purpose.\n\nThe least I know technically is that saturated red that becomes dark, in our case because of lack of exposure, loses its saturation. Dark red will always be less saturated than normal red. So I do not know if a change of luminance alone will give us the original color of the picture.\nI'm wrong?\n\nNot sure what you mean here, it seems you mistake chroma with saturation. By definition, saturation is independent from luminance. But, if you move the luminance at a fixed chrominance, you might end pushing the color out of the gamut, which is a completely different issue.. So at which stage of the pipe do you pick the color now ?. Ok. Ideally, we would like to pick before the output color profile is applied too.. > You select output profile and develop with it in mind,\nNope, that's exactly what you don't want to do, and this is the typical display-referred ICC workflow I'm slowly reverting in dt.\nYou want to develop for the visible locus, in an output-agnostic fashion, the scene-referred data. Then, as a last step, deal with target profiles and gamut mapping. So whether you output in sRGB for the web, CMYK for print, or DCI P3 for your brand new Apple screen, you are good anyway, and you don't care.\nIn this context, you might need scopes or views on data, that are in a specific color space. But they should'nt affect the pipe, otherwise they are not scopes, and you are not in a space-agnostic pipe anymore.\nSo, I think what @edgardoh proposes goes in the right direction.\nBut, in the other hand, I wonder if just taking the overexposition in XYZ wouldn't be better. Because values above 255/255 in RGB might be overexposed or out of gamut, you don't know. In that case, that overlaps with the gamut check. Well, if the 3 RGB values are above, it's set then. So, the exposure alert should take the luminance instead (Y channel of XYZ space).. > I should think a bit more about it, but when checking for overexpose I want to know if an individual channel is overexposed, not only the luminance.\nIf an individual channel is clipped (not overexposed), it's actually out of gamut. The proof is: change your white balance or desaturate, and you will be able to get that channel back (that might get ugly, but it's not the point). You don't need to change the exposure. Think about it : exposure = log2(luminance). Right now, the overexposition preview overlaps with the out-of-gamut (gamut clipping) for that reason. Put you image in black and white, and your overexposure preview is not the same anymore. Exposure doesn't change when you switch to monochrome\u2026\n\nWhat I don't like in this is that we have now:\n* output profile\n\n* profile set in the export module\n\n* and the overexposed profile\n\nAnd if I'm not mistaken those are all connected together and ideally the same profile should be used in the 3. This is not appealing :( Or am I wrong.\n\nThey are not necessarily connected. I agree that the option in the output profile module is in fact useless, because the output profile of the pipe is actually your display profile as long as you are in the software, and you can select it again at export time. So this one is even misleading.. > Maybe we can consider merging the soft proof & gamut profile with the overexpose one, as I said before I created a new one so I don't introduce a limitation, but if everybody is OK with it I can do the change.\nI\u00a0don't think that's a good idea. Gamut has to do with chrominance/saturation. Exposure has to do with luminance.. >> Right now, the overexposition preview overlaps with the out-of-gamut\n\nWhat do you mean by overlaps?\n\nThe same feature is provided by 2 different options, because the overexposition is not limited to overexposed pixels, but shows anything clipped. \n\nSure, but when you check for those, do you use different profiles? Let's say you check overexposed/histogram/colorpick in linear rec 2020, do you check the gamut with other profile?\n\nThe gamut is related to the output color profile only. So we need to be able to get colors at the extreme end of the pipe, and check what is outside the [0, 255] range (gamut clipping). These output profiles/spaces will generally have a built-in gamma/OETF.\nThe histogram and colorpicks are related to the pipe, in which you control settings in Lab and various RGB spaces, and might need to pick colors in the same space as the one in which you input the settings. These RGB spaces will be linear, and different from the output profile.\nThe output color profile defined in the module is purely informative and possibly misleading since it is defined once again in the export box and does not affect the preview, which is taken care by the display profile. So I think that control should go.\nThe overexposition is color-space agnostic and should only deal with luminance, so overexposed areas are overexposed no matter if you thange the saturation. XYZ seems fine to do that.\nAll in all, we need 4 profiles:\n\ninput to pixelpipe:\nlinear matrice if linear raw input\nlinearization transfer function if gamma-encoded input (so the pixelpipe is linear)\n\n\npixelpipe to output file: used to export, softproof, gamut check - useless inside the darkroom except for softproof control, that could go outside the output profile and stay in the softproof/gamutcheck option)\nICC profile (possibly OCIO transform one day)\n\n\npixelpipe to display: used to send previews to screen\nICC profie (possibly OCIO transform one day)\n\n\npixelpipe to control view:\u00a0used for histograms, colorpickers, overexposure\nlinear matrice. @parafin forget about the output color profile. This thing has nothing to do in the darkroom, in fact changing the profile in the module does not change the preview at all, so that screams bad design. The output profile is relevant only during export, and everything before in the pipe should be fully output-agnostic.\n\n\n\nThe main colorspace in which you need to see the histogram is the one of your pipeline, e.g. of your raw data before they get messed up by gamma and silly ICC bits.\nBut\u2026 Once in a while, you need to keep an eye on the gamut repartition in a given color space. Nowadays, pictures are mainly used for print and display on screen on the web, so that makes at least 2 different color spaces to check. So you need a view on the gamut clipping.\nAbout that clipping\u2026 The gamut check screams where clipping occurs. Fine. Then what ? \nHaving the RGB histogram in the same space would allow to diagnose which channel is actually clipped in said space. So, instead of guessing and maybe desaturating everything, you could just have a look on the histogram in a different space and get a sense of what is clipping.\nThen\u2026 As of now, an overexposure indicator that only shows clipped RGB channel is mostly redundant with the gamut clipping indicator. Do this test : open a picture with clipped highlights, enable the overexposure, turn the pic into monochrome (desaturation is fine), and suddenly your image has far less clipped areas. That's not ok. The exposure of a picture does not change when you turn it B&W, so that tells you the overexposure is not really showing you overexposition, but any channel clipping. So you need to show it in an XYZ space, and show clipping only on the Y channel (the luminance).\nAs of softproofing, the whole concept is foolish and researches show that even the more complicated color-adjustments algorithms (CIECAM02 and derivative by Fairchild and al.) fail to give a good preview, mainly because a screen is back-lit and works in additive lights, whereas prints work in subtracting pigments.\nEven if some call that \"painting by the numbers\", and because softproofing is doomed by nature, the gamut clipping checks are super important, and I think the histogram is another scope on that issue.\nThat might be bad software design, but having a clean soft is something I care about when it's working as it should. Image quality first.. you need the working RGB space (which should be configurable, because every RGB space has different drawbacks when it comes to pixel pushing), the gamut check profile, and the display profile (which can be useful in multi-display setups).\n\nAgain I don't see the need for a separate setting just for overexposed, it doesn't make any sense.\n\nDid you understand the difference between channel clipping and overexposure ? Do you agree that, from a physical point of view, desaturation should not change the overexposed areas because color is different from luminance ?\nYou don't need a separate setting for overexposure, you just need to compute it in the right space.. Printing and exporting profiles are just output profiles for files. I don't think we need to split the feature, they work the same, but for different outputs. \nThen, again, using whatever RGB is foolish for overexposure.\nThe whole CIE system is built around the notion that 100 % luminance is 100 Cd/m\u00b2. Over-exposure is achieved when one pixel is above 100 % luminance. Luminance is computed from the RGB values like Y = 0.22 * R + 0.76 * G + 0.02 * B (coeffs from memory). So, overexposure is achieved when Y > 1. \nWhatever you show in RGB is not (only) overexposure, but also gamut clipping.. Sure, they work for different outputs, but it's just a label at that point. They are completely interchangeable, you could save a JPEG or a TIFF in printer space RGB as well as in sRGB or Adobe RGB, that wouldn't make any difference regarding the actual color correction.\nOr maybe you mean splitting CYMK and RGB output profiles ? \nI'm not entirely convinced CYMK profiles are useful in darktable, since all consumer printers drivers happily take RGB as input and convert internally to CYMK, possibly better than Little CMS. Maybe @TurboGit has another opinion here, after having done the printing UI.. 1 - checking gamut in Prophoto makes no sense, this space has imaginary colors that are out of the visible locus.\n2 - you really don't want to duplicate your edits depending you destination/output color space. That's the whole point of an output-agnostic pipeline. What you want is edit just once, and check that LittleCMS gamut mapping does its job properly in all the output spaces you need.\nPlease read https://github.com/darktable-org/darktable/wiki/Developer's-guide#understanding-color-and-color-management. The ideal workflow would not make use of gamut checking at all.\nICC profiles are numerical descriptions of the properties of color spaces (input and output). Using these descriptions, color management systems (Little CMS, Argyll CMS, etc.) perform automatic color mapping (basically, RGB coordinates rescaling) giving precedence to luminance (relative colorimetric intent) or color (saturation intent) or homogeneity (perceptual intent), depending on what the user wants. Usually, these strategies work good enough, and photographers don't need to worry about gamut.\nHowever, in some cases, they fail (for example, blue and magenta artificial spot lights, at events and concerts, are garanteed to fail big time). If the most part of the picture is out of gamut, they give unexpected results, and this means you need to take manual control. \"Out of gamut\" makes color geeks freak out, but that only means you might get a solid saturated color patch instead of a smooth color gradient (because we use a CMS). That is only a concern if the main subject of the picture is mostly out of gamut or if hard transitions (halos, rings, etc.) happen at the in/out-of-gamut boundaries. And that triggers the need for scopes to get a diagnostic.\nSo, a safe workflow would involve:\n\nchecking that the CMS gamut mapping works as expected,\nensuring most of the areas of interest (main subject) are in gamut,\ndiagnosing where you were reckless and caused damage in your retouch (skin tones are supposed to be contained in every color space, for example. If they are not, it's definitely your fault).\n\nThis affects only the fine-art people who are, generally, educated in these topics (sometimes mis-educated on the web, but that's another concern). Meaning this is a place where trying to make things simple will hurt more than it will help : settings should be transparent (e.g. no \"general audience\" simplified labels, use the accurate technical terms).\nUsing large gamut RGB spaces in the pipe is important only when said pipe is in 8-bits or 16-bits integers, meaning clipping happens out of the 0-255 or 0-65535 range. darktable works in 32 bits float unclipped, so any linear and well-behaved RGB space would do (REC709, REC2020, ACES P0, etc.). Besides, the true PhoPhoto RGB space has an OETF (gamma) of 1.8, whereas darktable's implementation is linear (so it's not a real ProPhoto RGB). But what matters is that the RGB space behaves consistently when you push pixels in it, meaning its primaries retain some spectral consistency (so REC2020 or ACES P0 seem to be the best choices here, for now). \nBack to the workflow\u2026 what you want to do on a picture is:\n\nadjust the exposure, contrast and lightness in a linear space while retaining the scene-referred colors. You want to check that you don't get overexposure, so you do it looking at a scope that shows the Y channel clipping.\nadjust the colors (hues, saturation) in a linear or log-encoded space, while staying in-gamut. At that point, the gamut is the visible locus, which is shorter than large RGB spaces like ProPhoto or ACES P0 or Lab. So, for now, checking for the gamut of the pipe space will do (with caution), but at some point, we will need some way to squeeze the human visible locus in that.\ncheck that the CMS does a proper job remapping colors from the pipe space/visible locus to the output profiles you need, and possibly tweaking it (there are very few gamut mapping options and output display transforms in dt for now, that is a way for improvement for the years to come). For now, if the gamut mapping fails in one particular output space, you need to adjust the saturation lower in the general pipe, which is not really clean since it affects all the possible outputs when there is no need to (I have a \"clever\" gamut-mapping in IPT-HDR space incoming).\nenjoy your 2 minutes of color-safe editing and have fun during the 8 additional minutes you would have wasted in darktable 2.6 recovering colors.. 2. looks fine to me too.. There is a problem with the circuitery for the over-exposed alert: the colors actually change in the image depending on the histogram profile when the alert is on. The image shown should be in display color space anytime. To compute the alert, the colorspace conversion should be done outside the pixelpipe (a dry-run, if you want), then, only the clipped pixels should be applied as an overlay on top of the image.\n\nAlso, changing the histogram profile while the gamut alert is on segfaults.. This is a screenshot of dt in German, where every noun takes a capital by grammar:\n\nIs it that bad ? I find that, once you have a capital to hook up and the lenght of the label, you don't really have to read that label, you can recognize it quickely by its length and initial letter.. I would like capitals at the beginning of sentences, labels, and sections. Just as regular grammar enforces it, really.. maybe in comboboxes menus, I guess.. Does it work if you use a directory that already exists ?. It works ! thanks !. Touchscreen events are supposed to work with GTK 4.0 which has no release ETA as of now (AFAIK). So we have no way to make that work until they do their job. . I have no idea, GTK4 does not even exist yet.. I'm working on that in #2037 . > > I see no reason to declare the inline functions as static.\n\ninline is only a compiler hint, but there's no guarantee that the inlining will occur. Defining a function in a .h file without static is invalid (link may fail with duplicate symbol error) as soon as the .h file is included from several compilation units. Actually, the cases where you want inline without static are very rare.\n\nNotice that inlining functions prevents them from being auto-vectorized when possible. Inlining vector operations doesn't seem a good idea.. For me, is appears after building with sh build.sh --build-type Release, running without OpenCL and using local contrast in laplacian mode.\nBut I also suspect the packagers for Win and Mac (@parafin and @peterbud) use the Release build, and the recent bunch of bugs affecting colors in darkroom vs. export (unreproductible on Linux) could be related to that. Basically, that flag triggers non-safe maths bypasses for the sake of performance, but you have to handle things properly in the code. \nThe risk/benefit of this flag is just not worth it: https://stackoverflow.com/a/22135559/7087604. > > Can give a slight performance boost. All hardware since 2012 should be supported now.\n\nAny proof for that? I am interested to see. If not this is just a deliberate reduction of interoperability.\n\nI have just benchmarked it on my system with a development history using intensive GPU IOPs (denoise profile, retouch, wavelets, local laplacian). OpenCL 2.0 is the slowest, OpenCL 1.1 is average, OpenCL 1.2 is the best, and OpenCL 2.2 is not compatible since it relies on C++.. It's up to 5 % speed-up. Nothing dramatic.. Actually, my bad\u2026 It seems that this particular option does not affect the real kernel building, and without cl-std argument, the compiler just takes the higher version available. The \u00b1 5 % should just be natural variability.. CLang keeps crashing on simd instructions he is not able to vectorize, while GCC can. I\u00a0think we need to modify the compilation flags to just ignore failed loop vectorizations, because it does not prevent the functionality to work as expected.. About 25 to 27 % faster with the last version. \nBasically, I don't understand why all RGB vector algebra in darktable are handled with raw (float *) pointers while we know beforehand they are float[3] or sometimes float[3][3]. Just using fixed-size arrays whenever possible gives the compiler a hint on auto-vectorization and memory management, it speed-ups things at no cost. \nI have only rewritten the trivial cases here, more care should be given to the mat3mul functions because some funky stuff happens to the matrices regarding indexing, and I don't understand it. (For God's sake just use float[3][3] arrays and don't be clever with pointers arithmetic\u2026).. Windows ? OpenCL ?. Sorry but that code is no good.\nThe interpolation of RGB triplets (3D vector) should use a tetrahedral interpolation, to retain the relationship between the RGB code values. See https://blogs.mathworks.com/steve/2006/11/24/tetrahedral-interpolation-for-colorspace-conversion/\nActually, you are right. I did some checking, and the Cube LUTs and such actually use gamma encoding, for legacy reasons. That's not a problem when you use a tetrahedral interpolation, \nBut here, the code uses a trilinear interpolation, and this is what will happen on non-linear data:\n\nBasically, the linear interpolation will put the intermediate points proportionaly to their distance to the closest samples, which is wrong when the spacing is not proportional itself.\nYou can try hacking the interpolation here with that: http://www.hpl.hp.com/techreports/98/HPL-98-95.pdf\nAlso, I think it should supports 16 bits LUTs as well, and maybe floating point too.. > But I don't see the relationship you make between linear or log/gamma and the interpolation method, tetrahedral or trilinear. Both are linear and will deal better with linear data, correct ?\nBoth are linear indeed, and near-perfect interpolations will only occur in linear spaces, so we will have to content ourselves with rough approximations anyway, for log or gamma encoded data. But the approach used in the tetrahedral interpolation is better fitted for what we do, and more widely used.\nThe paper you pointed out seems suspicious, since they don't measure the ability of the interpolation to fall back on previously known numeric values (build a test LUT, remove some lines, compute them from the interpolation, then see how close you get), but measure the screen display output (that's quite a lot of steps added in-between) and use the delta E as a metric. That's not really how you evaluate the performance of an interpolation, since they evaluate the performance of a whole chain, and that might explain why they find different results from everyone else.\nAnyway, I have found code to do that already : https://github.com/imageworks/OpenColorIO/commit/062d6a38a323190a2aebefb061d940be1729358d. Nice ! It looks like it could easily be vectorizable. On a side note, when you add/multiply/subtract/etc. constants in float, you should write + 1.0f instead of + 1. I think GCC treats them as double otherwise, so they are computed as double and then casted to float, which is slower. I'm not sure about that, but it can't hurt anyway.\nFor the visual difference, it's always the same\u2026 You need either need a protocol to test with charts (for exemple the HaldCLut), and compare the input/output, or ask veteran retouchers where to push to make it break. I will ask around.. > I've added the pyramid interpolation. It brings more  visible difference on the image and some more noise on histogram than  the others.\nIt's definitely good to have several options here.\n\nBut I'm not sure about the method. Where the priority of the module should be determined ?\n\nI\u00a0think that should go straight before the output color profile.\n\nI've not found any LUT to be applied on linear RGB so far. The same for Lab and XYZ. Any link would be appreciated.\n\nDaVinci Resolve is free and works on Linux (RH/Fedora/CentOS, and with some tweaking on Debian/Ubuntu), they ship several LUTs for Kodak emulsions, maybe you could see if you can strip them and input them in your module. If not, I can try for you (my TODO list is already packed though).\n\nRemains the case of LUT on LOG space. I can get some result tweaking exposure + unbreak + tonecurve and applying the LOG LUT on linear RGB. But that's far less straight forward.\n\nThat's the kind of specific workflow where the ability to reorder modules in the pipe would really help.  Otherwise, you could reuse the log in your module. I have added that function in src/develop/imageop_math.f in #2035 (not merged yet):\n```\n/ Logarithmic shaper / tone-mapping\n * from https://github.com/ampas/aces-dev/blob/master/transforms/ctl/utilities/ACESutil.Lin_to_Log2_param.ctl\n * /\nstatic inline void lin_to_log2f(float lin, const float middle_grey,\n                                    const float min_exposure, const float dynamic_range)\n{\n  const float logNorm = (dt_fast_log2f(*lin / middle_grey) - min_exposure) / dynamic_range;\nif( logNorm < 0.0f || lin <= 0.0f)\n  {\n    lin = 0.0f;\n  }\n  else\n  {\n    *lin = logNorm;\n  }\n}\nif defined(SSE)\ndefine zeros_sse _mm_setzero_ps()\ndefine ones_sse _mm_set1_ps(1.0f)\nstatic inline void lin_to_log2f_sse(__m128 lin, const __m128 middle_grey,\n                                    const __m128 min_exposure, const __m128 dynamic_range)\n{\n  __m128 positive = _mm_cmpgt_ps(lin, zeros_sse); // strictly positive\n  const __m128 logNorm = (_mm_log2_ps(*lin / middle_grey) - min_exposure)/dynamic_range;\npositive = _mm_and_ps(positive, _mm_cmpge_ps(logNorm, zeros_sse));\n*lin = _mm_or_ps(_mm_and_ps(positive, logNorm), _mm_andnot_ps(positive, zeros_sse));\n}\nundef zeros_sse\nundef ones_sse\nendif\n```. thanks !. What version of dt are you using ? A packaged 2.6.0 or a self-compiled master ? \nI run on Fedora 29 myself, I have never experienced such issues. If it affects a package, you should contact the packagers.. I\u00a0don't like the color wheels to be honest. You basically have 3 axes to control from the tip of your cursor, it's impossible to use them. In pro industries, they have wheel interfaces for color grading because they use physical wheels on hardware control panels: https://www.blackmagicdesign.com/products/davinciresolve/control\nBut emulating that in soft interfaces would just make things more complicated. Color zones separates your 3D polar nodes into 3 1D linear axes. I think it's the best we can do until we support actual MIDI consoles.. This bissects to commit 9820e3b9c1dbb7612f64becab075e1b18181c7b7 by @TurboGit \n```\nDate:   Wed Feb 27 22:43:48 2019 +0100\ngooglephoto: remove unsued field gphoto_ctx.\n\n:040000 040000 6be72abb734a9091ce8cc3a5989507fd16aaad94 023cfea0d76b3a3ed379ec409e92809fdc93d4d8 M  src\n```\n. Nevermind, it seems a reboot fixed it\u2026. Yes, I don't get what triggered that bug anyway. . It does not reproduce on my side. Sorry.. Ok, that was a quick fix because I'm working on FMA-able code. My version here requires only C99, then use C11 if available or falls back to C99.. It's not blocking on my side. It's supposed to only give info on the parts the compiler failed to vectorize, and hints. Strange\u2026. > But still don't you think this should be done for the dev build and not the release one? It is too late to display that when building a release.\nThere is no auto-vectorization in debug building, so I think it's pointless. The release build (with -O3 flag) needs to be used during development too.. \u2212_____\u2212\ndamit.. > When I create style and then apply it with --style option it will always use same fixed parameters for every image. Is it somehow doable?\nNo. That would need a rewrite. Also, the detection does not always succeed, so you need to check it manually anyway.. Sorry, I don't like that.\nExposure adjustments should come before the input color profile, but the color adjustments should come after. So you can't bundle them together in the same IOP.\nThen, the lightness adjustment is a simple gamma on decorrelated RGB channels, which is bad especially this early in the pipe.\nAlso, you are duplicating the fulcrum contrast and saturation from the color balance. I planned on adding a vibrance and chroma adjustments, maybe we could keep it the color hub of dt, as Capture One or Da Vinci Resolve do ?\nOn another note, when you write:\nC \n  // exposure\n  pixel.x = (pixel.x - black_point) * scale;\n  pixel.y = (pixel.y - black_point) * scale;\n  pixel.z = (pixel.z - black_point) * scale;\nyou should write full vectors operations, like:\nC\npixel = (pixel - black_point) * scale;\nbecause OpenCL is designed to be vectorized (and I don't know if the compiler is clever enough to detect you are working on vector coordinates and pack them).. As much as I like a RGB workflow, I think this duplicates the efforts of @phweyland on #2017. But the RGB blending is strong argument, actually blending in non-linear spaces is doomed from the basic theory of it. Is there now way to get an RGB blending for those Lab modules ?. So we will need to be clever on the UI side to avoid confusion then.. > New modules are migrating toward an RGB working mode. Fine. But I'm not certain to understand the relationship with the UI. We can have a curve in Lab and RGB, both actually tweaking the module in RGB mode with proper color conversion, right? Or are the color conversion the problem? Not conservative enough? For example the colorbalance can have RGB or HSL sliders and both are actually tweaking the same circuitry in the module with proper conversions.\nHaving the module work, internally, in Lab or RGB doesn't change the fact that the blending options still depend on the in/out space of the module, hence on its position in the pipe. The problem of blending is it uses alpha blending and possibly blur, and blurring colours in a non-linear spaces (Lab or gamma-encoded RGB) results in uneven transitions (see : https://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/#colour-blending). The whole concept of alpha blending is foolish in non-linear scenery (https://blog.johnnovak.net/2016/09/21/what-every-coder-should-know-about-gamma/#alpha-blending--compositing).\nThat's why I think even the Lab modules should get a linear RGB blending option. And if this becomes reality, there is no reason to duplicate the modules with Lab (with possible internal RGB conversions) and RGB flavours. But if it's too complicated, well fine with the duplication, although the argument of \"you don't have to see every module\" sounds like hiding dust under the carpet to me.\nAs for the code complexity, I can say there is a lot of code duplication in dt, first between modules (blur libs, graphs drawing, etc.), then inside the modules themselves (C + SSE\u00a0paths). I have tried to factorize code and build standard libs (for example, vector algebra and maths functions), but there is a lot of work to do. \nFor example, I think SSE codepaths are useless if proper C codepaths (with OpenMP SIMD) are written properly from the beginning (but they are not), so maybe we could start with progressively getting rid of the pure SSE pathes, refactor, clean and get auto-vectorizable code by default (see what I have done in #1904, I get \u00d76 speed-up with OpenMP SIMD compared to original naive C, with no SSE intrinsics whatsoever).\nIn design patterns, best practices involve writing small functions, doing only one thing at the time, with an average of 2.5 if branching by function. Such functions are easier to test and prepare with #pragma openmp declare simd for vectorization. They make the code more readable and re-usable. We are far from such practices in dt, with functions of hundreds of lines and duplicated stuff. \nTL;DR before concluding on the complexity of making old modules speak Lab and RGB at the same time, I would take this opportunity to split current modules into elementary functions, write stupid simple C pathes with OpenMP pragmas, get OpenMP SIMD to work on-par with the SSE2 pathes, then get rid of the SSE2 pathes, then share code between modules, then add the translating options LAB <-> RGB.\n\nDigression :\u00a0Also, the choice of limitating SSE features to SSE2 (2004) does not make sense anymore, because newer versions have other speed-ups like 256/512 bits vectors, hardware-accelerated fused multiply-add (FMA) etc., and limiting us to the SSE2 subset forbid us to use them for compatibility reasons, while using OpenMP and compiler auto-vectorization (with code written to be vectorizable) would allow the compiler to use all the fancier options available and adapt to whatever platform it's compiled on.. Also, while we are here, the tone curve is using a pre-computed look-up table with various spline interpolations between the nodes. That LUT is built between [0;1] and exponential extrapolations happen out of that range. Hence branching.\nThat was optimal with single-threaded scalar code, but my tests show that, with SSE2 (and OpenCL is a kind of highly paralellized SSE2), all the memory accesses it creates (LUT[CLAMP((uint16)x * 65536), 0, 65535)]) are often slower than asking the CPU/GPU to compile the exact interpolation in floating point for each pixel. So maybe it's worth it to get rid of the LUT now.\nYou can verify it in profilegamma (Unbreak color profile). The gamma option uses a pre-computed LUT, and the log computes the log in float for each pixel. There is no SSE2 code for CPU, so you would have to check that on OpenCL (for me, gamma : 11 ms, log : 9 ms).. or maybe a quick 2.6.1.1 ?. You might have a problem with Windows Clear Type : https://www.howtogeek.com/howto/28790/tweak-cleartype-in-windows-7/. that worked for me. Actually, there is another click-event to fix, for the reset button.. > No, the reset has two parameters, that's OK.\nfor now, yes, but the next dude who will try to extend the reset button with a special click will have to figure out why it doesn't behave like the other buttons, and given the noticeable lack of doc, we are not helping him by making a special case. I would just keep it uniform and be future-proof and dev-friendly.. > Also it would be good to have an option to set place to \"none\", but I've to find a nice way to not load libs (for now, you can set an empty template and place bottom or top center)\nJust set it wherever you want and use gtk_widget_set_visible(GTK_WIDGET(widget), FALSE). The problem of doing that is every module using the XYZ Y channel (luminance), for example saturation adjustments or curve color preservation, will get a wrong Y value before the input profile, because it's only this module that maps input RGB to standard XYZ D50 (and then to Lab).. What stuff ? What is mislabelled ? I don't understand what you mean. It's not black level as in the exposure module, it's the limit between black (signal) and noise. Using a log function, values very close to zero (thus noise) get amplified much more than correct values. We need a threshold to cut out very small values before sending them in the log. This depends on the sensor, ISO value, previous denoising and demosaicing, and exposure compensation (gain).\nThe linear factor helps to center the dynamic range such that black are at - DR / 2, white are at +DR / 2, and the target middle grey is at 0 EV, thus 50 %. It should be measured or estimated by optimization.. > Again, I'd leave things as a base log. You shouldn't be having any noise amplification at all, and if you are, the code is busted.\n\nBase logs have been around longer than DSLRs. They work.\n\nI'm sorry, but in dt, this module can take negative values which are going to output NaN or zero division errors. I trust DSLR manufacturer can normalize the values before the log, taking account of the noise level, but we have to take whatever crap the previous modules in the pixelpipe give us.\n\nMost of the defaults for these sliders in\"camera & signal properties\".\nYou should be able to get most of that from the actual black/white levels.\nElse i suspect the name is unrepresentable.\n\nYou were actually right, looking again at the maths, these parameters are dependent of the dynamic range so I just removed them throm the UI.. no, this dynamic range is the output dynamic range. You can see that as a target contrast. It can be optimized to fit the whole [0; 1]  range at the output, considering the input extrema (that's the purpose of the last slider + autofix_callback function), but there is no way you could guess it from hadrware properties (and, again, it depends on what you did n the previous modules).. I tried to use the same structure of code that is used for Adobe RGB, but none of these constants are actually used in the code, which is strange because we are supposed to correct the XYZ illuminant (D50 or D65) at some point when applying the conversion matrices between color spaces. So anyway, I dropped that here only for consistency, but they might come in handy at some point.. That's an error, it shouldn't be there, I will fix that.. It makes sense, I didn't wanted to change the order since I wasn't sure it would be safe.. if(self->dt->gui->reset) return; appears in every gui event callback. I'm stupid\u2026. Actually the code only uses the first 3 cells of the array, from 0, so the tags name don't matter much.\nLine 1671: \nfor (int c = 0; c < 3; ++c) \n  {\n    samples_lift[c] = CDL(d->color_patches_lift[c], p->gain[CHANNEL_FACTOR], p->lift[CHANNEL_FACTOR] - 1.0f, 1.0f / p->gamma[CHANNEL_FACTOR]);\n    samples_gamma[c] = CDL(d->color_patches_gamma[c], p->gain[CHANNEL_FACTOR], p->lift[CHANNEL_FACTOR] - 1.0f, 1.0f / p->gamma[CHANNEL_FACTOR]);\n    samples_gain[c] = CDL(d->color_patches_gain[c], p->gain[CHANNEL_FACTOR], p->lift[CHANNEL_FACTOR] - 1.0f, 1.0f / p->gamma[CHANNEL_FACTOR]);\n  }. dt_control_queue_redraw() seems mandatory to draw the frame of the color picker. yes, it is a typo. Thanks @edgardoh !. Merci beaucoup pour ton aide Pascal !. Indeed, I think my IDE didn't refresh the local file after the git pull. Is there any git magic to revert that part only ?. Ok I let you do it. Thank you !. Looks good. I will test later.. picker_ are the global pickers you set in the left panel. raw_ are the local ones you set in the module. We take care of the global at lines 1482-1503. Done. I don't get why the 3/8 appears here but I vaguely remember some matrix inversions algorithms involving that kind of trick, is that it ?. Nevermind, I'm just stupid.. Thanks. not for hard-coded presets it seems. Everytime the blendop API is updated, the presets become invalid and raise a size error. That might be the problem. Honestly, I just took that code from the denoiseprofile IOP, I didn't give it a lot of thought. anyway, the concept of having static blobs exported from somewhere else in the code is not the cleanest design.. Indeed, debugging leftover. I ran into weird bugs yesterday where formerly edited pictures raised segfaults errors while re-opened. It turned out that the interpolator saved in the parameters was non-valid, so probably some error during saving. This is to take extra care of that with a default fallback.. done. it should be good now. It should be d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + d->cfulcrum;. but then your function output is not properly bounded in [0; 1] for neutral parameters (contrast == 1) : https://www.wolframalpha.com/input/?i=1.+*+(x+-+0.25)+%2B+0.50,+x+%3D+%5B0,+1%5D. So you have no neutral parameters anymore.. > Makes the correction proportional to fulcrum, which is not what we look for.\nit does not, the fulcrum is an offset. It's proportional to the contrast.. imagine fulcrum = 0.25, the current function as you wrote it is not only adding contrast but also luminance, because it is shifted linearly by 0.25. That remaps the fulcrum to 0.5 no matter what.. done. Obviously ^^. > For example, if the target is not lit homogeneously\nIf so, the whole colorchecker profiling becomes useless. I think you have to assume in the code that the lighting has been done properly. That's user's responsibility.. I don't fully understand what this does, but other modules don't use that or have it commented, so I thought it was merely a debug thing. It doesn't seem to cause issues.. Well the output was always TRUE because the preset was applied no matter what, so the global preference was actually useless. That's what I know. What happens in the piping is still a bit unclear to me, but the pointer seemed unnecessary so this was the faster way to fix the bug I\u00a0found.. The logic I used was this:\n1. We have generic brand curves\n1. We have specific cameras curves.\nBoth can be auto-applied on user request, the specific curves superceding the generic brand ones. So, if the user requested it and the preset has an auto-apply flag, we auto-apply it, wether it's a specific or a generic preset. If the user requested to not do it, we discard the auto-apply no matter the preset. The thing is the specific presets did not have the auto-apply flag except for the D750. So, in my mind, that just makes the generic and specific presets consistent with each other.. Ok I\u00a0will restore that. Sounds good.. You are right and I need to wake-up. The last commit in master fixes it. Well done ! :+1: . why ?. Likewise, why ?. > 2. the module will now be always-enabled-by-default in the pipeline, that is, unless it is disabled in the history stack. and with that, pretty much all the existing history stacks get broken (if they did not explicitly disable/enable the module already), for obvious reasons...\nok, that's a good point. I thought auto-presets were applied only when the initial history stack was created, not when there is already a previous history. That's sounds like a bug though.. it's just to ensure the display order, sorted alphabetically in the GUI. done. The arabic numbers are for toolboxes, which are aimed at providing a complete workspace. The roman numbers are for modules subsets, which are aimed at exposing quickely some features (purely technical and purely creative modules), but are not full workspaces.. that's another option indeed. done. I wonder if the value shouldn't be expressed in % of the diagonal size for example. It seems to me that 250 can be quite small with modern crazy high-res. I increased the slider range for shadows-highlights and lowpass to 500 for the same reason.. done. done. I think my IDE is adding them back everytime I remove them. there is an atan2(y, x) function doing just that (computing atan(y/x) in the right quadrant). Please write a color conversion function in the lib  src/common/colorspaces_inline_conversion.h. so you are shifting input hue by the same amount you shift the chroma ? Don't you want to preserve the hue untouched ? I don't understand what's going on here.. I think you should handle hue shifts directly in radians to spare a few divisions and multiplications, if you really want to rotate the hue.. you might want to use Taylor-Young approximations instead of pure cos/sin to speed-up the computation. same, you might want to use atan2. pi is already set as a global constant M_PI I think. I have a SSE one in progress:\n```\nstatic inline __m128 dt_Lab_to_Lch_sse2(const __m128 Lab)\n{\n  __m128 Lch = Lab;\n  __m128 Lab2 = Lab * Lab;\n  Lch[1] = powf((Lab2[1] + Lab2[2]), 0.5f);\n  Lch[2] = atan2f(Lab[2], Lab[1]);\n  return Lch;\n}\nstatic inline __m128 dt_Lch_to_Lab_sse2(const __m128 Lch)\n{\n  __m128 Lab = Lch;\n  Lab[1] = cosf(Lch[2]) * Lch[1];\n  Lab[2] = sinf(Lch[2]) * Lch[1];\n  return Lab;\n}\n``. same here, I think building your curve LUT between 0 and 181.019 would spare one mul and one div by pixel (ie scale the LUT once, don't scale every pixel twice).. thanks ! That's odd though, because I use the samefloatscalar \u00d7__m128vector in colorbalance and filmic, and it never complained. done. seems like you found them :-) done in last commit. this is fully equivalent for the compiler but only more readable. same. you can ask @heckflosse about that. yes it does :-) the_mm_set_pstakes its arguments in reverse order, as the_mm_load_ps, the natural C order can be used with_mm_setr_psor_mm_loadr_ps. See https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm_set_ps&expand=4895. thanks for your input !. @heckflosse I'm not the author of that code, so I think @hanatos will answer better than me. I just made the loops a tad faster here.. damit ! you are right ! so easy to confuse_mm_sub_psand_mm_sub_ss\u2026 Thanks !. done. incoming. done. \"to move\". \"to copy\". the reason for this is it keeps the content aligned on the module title, and the optical margin it creates is clean. Also, I have removed the outer margin of the modules, so overall I\u00a0think the width of the actual content does not change.. See here:\n![capture d ecran du 2019-02-13 14-28-21](https://user-images.githubusercontent.com/2779157/52738336-707aa400-2f9c-11e9-904f-c9efda375796.png)\n. ok, but now the blending buttons can't be made full-width\u2026. this is not a norm, but a mean. You should not divide by 3. same here. also if you don't check the sign ofrgb.xetc., you should useabs(rgb.x)etc.. same here, and you really needabs(rgb)in casenorm < 1. You could also use thenative_powr` function instead of pow (much faster).. what you are computing here is 1.22\u2074 \u00d7 R\u2074. It looks wrong, are you sure about the formula ? I would expect 1.22 \u00d7 R\u2074.\nIf it is right, you could just do \n```C\nconst float coeff_R = pow(1.22f, 4);\nconst float coeff_G = \u2026 etc.\nconst float4 rgb_pow4 = rgb * rgb * rgb * rgb; // the multiplication on full vectors is faster (that's the point of OpenCL)\nconst float4 rga_pow5 = rgb_pow4 * rgb;\nreturn 0.83743219f * (1.22f * coeff_R * rgb_pow5.x + 1.20f * coeff_G * rgb_pow5.y + 0.58 * coeff_B * rgb_pow5.z ) / (coeff_R * rgb_pow4.x + coeff_G * rgb_pow4.y + coeff_B * rgb_pow4.z);\n``. not sure aboutcase 2andcase 3since they are particular cases ofcase 4(with values ofnorm_expnice enough to avoid slow calls topow). I would just merge them intocase 4and check thenorm_exp` to branch, or even completely ignore them in OpenCL since branches can make it super slow and it doesn't mind the load (so you just use the general case 4).. you got that wrong :-)\nC\nnorm = rgb_norm_vect( rgb, rgb_norm, 0.333333f); // compute the norm == luminance estimator\nconst float4 rgb_ratios = rgb /norm; // these ratios are the actual colors, independant from the luminance\nnorm = lookup_unbounded(table_0, norm, coeffs_0); // compute the curve on the luminance\nrgb.xyz = (norm * rgb_ratios).xyz; // restore the colors from the original ratios and the new luminance. Actually, the tonecurve (unbounded) is able to deal with values > 1 because of the exponential extrapolation. The norm is supposed to be the length of the vector.. Ok. Also, be carefull of the RGB space the formula expects, otherwise the coefficients will be wrong (I suspect they use ACES P0).. Lp norms can be different things. I have seen them used in conjunction with gradient vectors, to isolate noise for example. Maybe we could stick to p = [2 ; 3] for RGB vectors then. I would have to see what they produce to figure a possible use.. I\u00a0don't think there should be any LUT produced on gamma-encoded data. If this is the case, usually the LUT is used to linearize the input.. REC709 defines the RGB primaries used in sRGB but has no gamma itself, it's a linear, scene-referred space. Gamma sRGB is just sRGB. Gamma REC709 can be sRGB. Now, HDTVs use REC709 primaries upon which they add a gamma, but that's none of our business in image processing.\nYou can't do linear alegebra on non-linear data, so applying an sRGB/sRGB LUT makes no sense, you need to revert the gamma, apply the LUT, and apply the gamma back. But I don't know any corporate LUT maker dumb enough to use sRGB. Usually, you want very large RGB spaces to apply LUTs.\nSome LUTs can be applied on log-encoded video footage, and will therefore revert the log and remap the output to scene-referred. That's a particular way to bring back footage to scene-referred space for software that don't allow arbitrary transfer functions, but one should always prefer a proper analytical transfer function to linearize, then to the linear algebra on linear data.\nBut this does not affect us here, because picture RAWs are real RAWs, and more importantly, you don't want to correct colors on anything but linear. The LUT defines color samples for the remapping. For colors between the samples, an interpolation is used ; if it is a linear interpolation and you are in log/gamma encoded in and out, the interpolation error will increase because it assumes the patches are evenly spaced, when gamma compresses highlights and raise midtones.\nReally, we should remove any non-linear conversion from the pipeline and keep the gamma and stuff as the very last step before sending pixels to display. Gamma will mess-up every linear algebra you want to do: blur, rotation, color matching, etc.. I process 4 pixels at each loop step to vectorize the fmaxf(log2f(...)...) but, indeed, when the pixel number is not a multiple of 4, that could end out of bounds. ",
    "phedders": "Sorry for the lack of style in one of those commits - I did it twice (on a different machine) and also put the change in a slightly illogical place!\nI have created a new commit with just the noise profile 1ad2fb3bb49ce0dbd91c76a86e36766a6beaf434, so I'll close this and create a new PR.\nCheers!\nShould I submit a new \n. ",
    "cherrot": "Oh I've noticed that. Sorry  I'll rebase and update it soon :)\n. Thanks ! \n. ",
    "terrycloth": "Hm, there is currently discussion at the Redmine issue tracker about changing the name of the \"cache locally\" feature, so I may or may not need to update the name again.\n. Looks like we've agreed to stick with \"local copy\" and make that consistent with references elsewhere in the user manual. So I suppose we can close this pull request.\n. Oops, sorry. I work with HTML more often than DocBook or other flavors of XML.\nI'd thought before that XML always required the numerical character references instead of the character entities, but I saw things like &gt; and &lt; in the existing documentation, so I figured character entity references (like &mdash;) were okay after all.\n. @houz \nI've been following the rules/suggestions at practicaltypography.com, generally, more or less. So I agree with the nonbreaking spaces, and I can add those tonight or tomorrow. But the author at Practical Typography says en dashes are more for showing a range of numbers (e.g., \"1910 \u2013 1920\") and that sort of thing, rather than marking a parenthetical clause or other pause stronger than a comma but weaker than a full stop.\nA lot of the finer details of typography come down to personal preference, though. I happen to like the longer em dash, but I can work with whatever style guides we agree on.\n. Em dashes, I've seen it go both ways. Practical Typography says the spaces around an em dash are optional. The New York Times seems to use spaces around their em dashes.\nBut it's whatever. We can do spaced en dashes, with the first being a non-breaking space, unless or until other people chime in and come to a consensus on something else.\n. Sure. It's your project, so you can run things however you want. I'm not much of a programmer yet, but I like darktable, and I just thought I'd try to help however I could.\nMost of the affected files in this pull request had relatively minor changes; I thought the text would \"flow\" better after my edits, but in the end it wouldn't affect things too much to leave them the way they are. \nHowever, the edits to the section about the history stack panel were first motivated by my own confusion, even after discussing things on the Redmine issue tracker, and re-reading the manual entry. I went over this section several times, comparing details in the text to experiments I tried running in darktable itself. So if I'm still missing something, maybe that's a clue to how it should be rewritten, even if you don't like the edits I made.\n. @upegelow \nAs for using PDF annotations instead, that makes sense -- I think I'd also prefer something like that for editing prose -- except there is no PDF. The user manual on the website is obviously in HTML, and here in the git repository, it's in XML/DocBook. Are you asking that I compile PDFs of the manual entries too?\n. ",
    "bieber": "Sure thing.  Is there any particular column you want them aligned to, or just any one that gets them all off to the right of the other stuff in this set of presets?\n. Sorry, was traveling for a while there.  I guess it depends on how wide your editor considers a tab, but for Github's display settings (looks like eight columns) this lines up\n. Yep, I tried 'em out and they seem to do the right thing.  Although I will confess that I didn't take a submarine trip to test the underwater WB, so hopefully that was the right color tint I saw when testing ;). One interesting thing about this change is that while this curve is being automatically applied to images from my Credo 40 and the Aptus 22, it's not applying to the Credo 80 RAW that I downloaded.  What would cause that?  Could it be the capitalization of the manufacturer name in EXIF between different backs?. Believe it or not it's a very good fit.  When I was experimenting with the other built-in base curves previously, I regularly had to push exposure by about two stops to get an exposure that looked anything like the on-camera histogram, and this basically accomplishes that in the base curve.  I have a suspicion that we might actually be reading the input values a little bit off in rawspeed (dcraw's IIQ decoder seems to be left-shifting by two bits at some point, which would explain the dark exposures coming out of camera in DT), but when I tried doing the same thing in rawspeed it produced some really questionable results. Actually, scratch that, I looked back at the dcraw source and it's actually a right-shift in a correction function.  So I really have no idea why the RAW files are so dark by default...maybe the back is just designed to leave a lot of headroom by default?. Yeah, so I'm not sure exactly what the situation is.  Phase One/LEAF RAW files do come out pretty dark, but at the same time the quadrant corrections work perfectly with the values we're extracting (which seems to mean that at least at that point in the process we have the right numbers) and the images look great once the exposure is scaled with either this base curve or a tone curve I generated from a color checker chart. ",
    "mlq": "I've developed the patch against 0.18 which marks most of the API as stable and therefore I've now added a patch which checks for the correct libsecret version if libsecret has been detected.\nIt would be great if you could try and upgrade your libsecret installation to 0.18, because it works just fine with my setup and seahorse (3.12.2).\n. I've updated the pull request with some patches which hopefully should resolve the above mentioned problems: I've set a label for the libsecret collection, strlen is not used any more to check for empty strings and I've enabled support for libsecret version 0.16 (where the unstable API has to be enabled).\n. ",
    "archont00": "@simonspa: sorry, still learning git stuff. here is a new request:\nhttps://github.com/darktable-org/darktable/pull/589\n. I am not really a friend with git - using it once a year or so. I failed with rebasing, so started once again and created a new pull request.. Sure, I have opened a new pull request.. Hi,\nSending a direct email few weeks ahead would be nice.\nI used to read dev & user mail list few years ago, but I got too busy recently to be able to follow them regularly.\nThanks.. ",
    "dtorop": "Things should be pretty sound with this. Though a rawtherapee developer reports (https://code.google.com/p/rawtherapee/issues/detail?id=2415#c51) export of X-Trans images in darktable causing a segfault. Not something which I have observed, though. If anyone can document a segfault (and backtrace!) it would be much appreciated. Regardless, it looks like the rawtherapee people are doing some great work on X-Trans sensors, and it would be interesting to cross-pollinate more.\nNote also that https://github.com/dtorop/darktable/tree/xtrans2-dev has some more changes. This is to keep the xtrans2 branch frozen for review.\n. The tiling commit (a075735) fixes a potential segfault for small values of host_memory_limit. With luck that is the segfault reported by the RawTherapee user.\nNote that changes on xtrans2-dev not currently in this PR are:\n- VNG4 for Bayer sensors\n- remove \"linear\" demosaic for X-Trans in GUI as it is so low quality\n- some amazing optimizations to Markesteijn demosaic thanks to Ingo Weyrich of RawTherapee\n- noise profile for Fujifilm X100S\nAm keeping these out of this PR in the name of a feature freeze.\n. Just made some (final?) changes to the PR. It seems important to note that X-Trans CFA alignment currently behaves slightly differently from Bayer CFAs. Once #584 happens, it would be easier to make X-Trans and Bayer CFAs not diverge in shift handling.\nAlso, it seems important to hide linear demosaic in the GUI now, as it really is so inferior to other options and it would be a pity to have anyone trying this code have their history depend upon its presence.\n. Rebased to handle #584 and made one more commit as no longer need to pre-flip the X-Trans CFA.\n. Yes, totally exciting! Many thanks... And will look forward to hearing about issues. Also more fixes/improvements are lurking in xtrans2-dev, I'll work on filtering those through.\n. Note that this also fixes #9951 though perhaps that will require manual closing in redmine?\n. @LebedevRI Thank you and that would be great about merging bayer/x-trans codepaths. I was conservative about keeping them separate for the sake of a cleaner patch, but there's definitely overlap & it could happen in a way not to slow the Bayer path.\nThere are a bunch of speed-ups & memory reductions for Markesteijn demosaic which I'll package into a separate PR. Also there is a modification to VNG demosaic which lets it act as VNG4 for Bayer images, which could likewise be a separate PR. Only other pending code on my part is profiled denoise for Fujifilm X100S, again for a separate PR.\n. Great, and thank you!\n. @pmjdebruijn: Thank you for trying this out. More crashes and 200% failure are very worrisome! From here, 200% works, and I haven't seen crashes. I'm running this on Debian testing, so assume we have a similar build setup. I don't have any OpenCL capability here, and am curious if a bad OpenCL interaction (are you using OpenCL?) is tripping things up. Any other ideas most welcome. Also curious about a backtrace. How does 200% render there with Markesteijn 3-pass?\nHere am still traveling, won't be able to sit down in a stable way and look at this until the start of next week.\n. Sounds good to check in on IRC. Some debugging questions for next week:\n- are crashes with VNG or only with Markesteijn?\n- if also with VNG, are they also with VNG4 on Bayer images?\n- what is runtime environment\n- is OpenCL used?\n- does crash likelihood vary depending on the raw fle\n- does crash likelihood vary depending on iops enabled\n- is zooming done via alt-1, alt-2, alt-3 or in-between magnification via mouse wheel?\n- backtrace\n- what happens at 200%\n- how long it takes to create a crash\n- any other standard helpful dt debugging questions\nMy immediate fear is some out-of-bounds pointer is causing this.\n. More questions:\n- what is conf value \"plugins/darkroom/demosaic/quality\"\n- do crashes ever happen when exporting images\nWondering if the problem is in dt_iop_clip_and_zoom_demosaic_third_size_xtrans_f(), which probably needs more attention regardless.\n. The last commit came from looking for problems in dt_iop_clip_and_zoom_demosaic_third_size_xtrans_f(). Its code is now simplified. I'd be surprised, though, if this eliminates the cause of the crashes.\n. Another theory about @pmjdebruijn crashes is an OpenMP issue. The Markesteijn demosaic code allocates one buffer per thread based on the value of omp_get_num_procs(), which seems potentially fishy. Could it be that something goes awry and OpenMP produces more threads than expected?? Would be interesting to compile/run without OpenMP and see if there are still crashes.\n. @LebedevRI \nThat is great and thank you for merging! I'm really glad that these Markesteijn speed-ups and memory reductions are in master. As mentioned above and in the commit notes, much of this is thanks to Ingo Weyrich's code and generous correspondence while he implemented RawTherapee's X-Trans support (see https://code.google.com/p/rawtherapee/issues/detail?id=2415).\nI will work more on the downscale/demosaic code (dt_iop_clip_and_zoom_demosaic_third_size_xtrans) which I cleaned up a couple days ago and is in this PR. It's only used \"always bilinear\" for darkroom mode is configured, and is great because it is so fast (especially good feedback when doing white balance and exposure adjustments). But it (still) offsets the image slightly up/left compared to proper demosaic code, and I'm afraid its output may now be softer than before.\n. @LebedevRI \nInteresting! Commenting out those lines will make VNG revert to a straight linear interpolate.\nOn quick runthroughs, I can't reproduce Bug #10025 or get AddressSanitizer to report an error in VNG. More in a bit...\n. No go with a portrait image in reproducing Bug #10025. But I'm not getting things right with AddresSanitizer -- it's not catching even on-purpose out-of-bounds memory access. Any tips on getting it set up would be great!\nI'm yet again on the road the next few days, will check in on IRC after the weekend. With apologies will be scattershot at most before.\n. @LebedevRI \nI saw the AddressSanitizer error, as you did, but only once, and have not been able to replicate it since. It occurred using VNG4 on a Bayer image. This seems like what happened in your backtrace, as well. Have you been able to figure out a way to consistently reproduce the memory error?\nI do see consistently what may be bug # 10025. It happens as I navigate at 200% towards the right of a portrait image. I can go past what should be the right border (roi_in->y + roi_in->height exceeds image width), I can still move another roi_in->height/2 pixels to the right, which causes noise/banding in the display. And as I move to the right beyond the image boundary, roi_in->height decreases proportionally as roi_in->y increases. (I'm looking at y & height values in the demosaic iop, and these presumably become x & width once flip operates...)\nCould the memory crash be caused by something outside of the VNG code -- due to the output buffer for 200% view being allocated too small?\n. This is looking like a manifestation of Bug # 10025 which causes height to progressively reduce to 0. VNG & AMAZE fail when height is near 0, hence expose the problem more than PPG, which will just return without doing anything.\nTo reproduce, best bet seems to be to load a portrait image with iop flip enabled, set demosaic to VNG or AMAZE, zoom to 200%, then scroll to zoom out a notch to 191%. Should see crash right away or as move towards bottom of image.\n. @LebedevRI \nThank you! This should be a noticeable sharpness improvement in bilinear display in darkroom mode. And apologies for not getting to memory/crash issues yet. Been spread thin this week, but soon!\n. Checked dt 1.4.2, which also exhibits the shifting/interlacing on right side. To reproduce:\n- load a portrait aspect ratio image\n- enable flip iop\n- zoom to 200%\n- move view to right side of the image\nLikewise the noise at 191% due to flip's modify_roi_in CLAMPing to width/height without scaling them is also reproducible.\nSo this is a patch for a couple long-standing issues. I still need at least to fix the jumping at the bottom observed by @LebedevRI before this is pull-able. The issue with 200% zoom could go into a different PR if necessary.\n. @LebedevRI \nLet me know how these changes work for you? This seems to produce stable results on my side: no crashes/garbage, and edges work at 200%.\nThe down side is that dt_dev_check_zoom_bounds() may get called more times than necessary. It'd be possible to cull some of the extra calls, or maybe figure out how to limit the new call introduced in dt_dev_process_image_job() to only cases where dev->image_loading is true (a new image) or the pipeline has been changed (not sure how to check for this). In that case would need to reintroduce the check of zoom bounds when leaving closeup mode.\n. Latest commit should address some of the worries about the one before.\n. This is still incomplete. PR #1122 was clearly visible as a grid construction of deltas between the GPU and CPU path. But in this case, upegelow noticed a flaw in PR #869 via examining the code, not its output. The last few commits  should fix the problem for both 1-pass and 3-pass Markesteijn. The fix results in more accurate calculations (<2% better) on a thin strip at the edge of each tile.\nBut unlike #1122, it's not possible to test this against the GPU path, as there is enough variance between the CPU & GPU output (due to math error levels?) that it overshadows any minor errors in CPU path. This probably means I can leave well enough alone. But to test it more fully will:\n- make a version of Markesteijn with much larger tiles, and much larger padding at the edge of each tile\n- from this produce a \"canonical\" CPU-processed result (without errors at tile edges)\n- make sure that can produce identical results to the canonical version\nThere may still be errors at the edges of the image, but that's another question. A healthy side-effect of this will be to make the various padding values constants in the code, rather than hardcoded in for loops.\n. This is still not right -- there's errors at the edge of 3-pass Markesteijn results...\n. Found edge error, this should now work.\n. Note also some further work at https://github.com/dtorop/darktable/compare/markesteijn-margin-fix...dtorop:fcxtrans-rework which takes advantage of the new FCxtrans() for cleaner code. Right now this depends on this PR, but it could be peeled off into its own code.\n. Rebased so as to coalesce a fixup into a commit and make commit messages clearer.\n. Yes, was thinking this as well. I had https://github.com/darktable-org/darktable/compare/master...dtorop:fcxtrans-rework which was waiting on PR #1123, and goes a bit further than this PR. It's to the same effect, but I calculated out a guard amount and also took advantage of the new roi parameter you added to FCxtrans() and made a FCxtrans()-ish macro to add proper offsets/modulo to allhex[] access.\nIf you were to check in this PR, I could rebase my changes on top of this and make another PR?\nRegarding the +1 rather than multiple of 6 you note, that is meant, yes! See https://github.com/pedrocr/dcraw/blob/master/dcraw.c#L4747 for the original from dcraw.\n. I made PR #1156 to make it easier to see the code mentioned above. It goes a bit further, but is the same line of thinking... Easy to rebase it on top of this one...?\n. This is now rebased onto master (I hadn't pulled df97cb1), and hence one more commit to change size_t back to int, using int accord with @pedrocr's suggestion that int is currently generally used.\nRegarding the maximum offset being +18 now rather than +24, I reduced the offset in https://github.com/darktable-org/darktable/commit/6ca063a61fa7053dda35792b4ab0391c1680cbb6#diff-a001a1125b3a87d818accabc8b2f2751L602 because the the row/col in that loop will never be less than -17. Way back in https://github.com/darktable-org/darktable/commit/525183b185ab7d42625f17df2c405afa6bf6422e#diff-a001a1125b3a87d818accabc8b2f2751R548 I'd set the negative guard 6 higher than needed. No harm in the higher value, but seemed right to finally fix it.\nI tested this PR by putting some code in FCxtrans() to report the minimum input row/col, and hence feel secure both experimentally and from examining the code that +18 is enough.\n. @pedrocr It's a good point about not hardcoding 18, to not invite future bugs. I do worry that adding an larger number would include an arbitrary constant into the code and still risk FCxtrans() failing in some unexpected future case.\nAn alternative would be to define a modulo function which returned a positive result (so long as the divisor is positive), such as:\nc\nstatic inline int umod(const int a, const int n)\n{\n  const int r = a % n;\n  return (r >= 0) ? r : n + r;\n}\nAs FCxtrans() seems to be a bit of a hot spot, such a solution tests about 4% slower on my machine than adding in an offset (whether +18 or +600). I'll check in a commit with an unsigned modulo function, for the purposes of discussion/review, but do worry that none of these choices are ideal.\n. Checked in cac2a5c which has a more generalized mod function. Still feel very uncertain about this, as not only is it slower, but the unsigned mod function will produce unexpected results if called with a negative divisor (not that this would happen in foreseeable code), so it still is code which could produce unwelcome surprises. Would be very grateful for thoughts!\n. Offset at 600, as per @pedrocr's original plan, with asserts and comments added. Also made allhex[] lookup a function rather than macro. Thank you for the thoughts!\n. @upegelow: The allhex declaration should be fixed now... Not sure why my gcc (Debian's 5.3.1-8) doesn't mind...\n. @LebedevRI,\nThe results look great! I'll try to work out an x-trans equivalent. Certainly current x-trans code could be improved. I'll be in touch once I have anything, or if I hit a wall with the math...\nDan\n. #1189 should be an X-Trans equivalent of this algorithm. It certainly is a vast improvement! I think the version with a 2x2 sample is an improvement (despite a few artifacts), but I'm curious how it seems to others.\nIf/when #1188 goes in, I'd update #1189 to work with its SQRT3/SQRT12 constants.\n. Finally getting back to this. Think have fixed the edge problem. Will test more, may be able to optimize/refine. Will write a note when it is ready to go. Also rebased this on top of git master.\n@LebedevRI : apologies slow to get you a sample image for highlights. I've been using the RAF at https://app.box.com/s/cicmtfqnfny9iuqmh9d1nkt1gxa8kaw2 to test, with the xmp as given. It comes from http://www.dslr-forum.de/showpost.php?p=13800864&postcount=690. I sometimes turn on the cropping to output a particularly problematic area. Would be very excited for more work on highlights. I'm also happy to work on an X-Trans model using any Bayer code you write as a model.\n. Have gone over this more carefully and think the code is sound. Would be curious for thoughts and if it seems ready to merge, that would be great. Made one more fix (ssize_t rather than size_t). To my surprise, this PR appears to be 2x faster than the existing X-Trans Lch code in master, and should give notably better results.\nComparison of results from this PR with extant code in dt master: http://imgur.com/a/bJPA2\n. Thank you for testing. At the risk of complicating things, I added one more change: a ring buffer to watch for the likely case in which the majority of the image is not clipped. On a test image this increases iop speed from 0.27 to 0.17 sec., while not changing the output, hence this seems worth the added complexity.\n. Thank you for checking it over, and the greatly improved Lch algorithm! I have to admit not totally understanding the math of the RGB->Lch conversion (it seems like a shorthand version of a full conversion?) but it is such a vast improvement. Glad to have it in the X-Trans code now.\n. Ah, very interesting! Have never looked at ufraw code, good to trace the lineage...\n. @LebedevRI very welcome, and thank you for looking it over and merging it so quickly!\n. Indeed, that sounds right to me. The original code works for hotpixels on fairly neutral backgrounds, but does appalling things to saturated reds (and, probably, blues) for reasonable parameter settings.\n. I'll look into sub-sampling for x-trans. Next week, though, alas -- things too busy now. The current x-trans code was simpler to write than to match the Bayer subsampling, and worked. But I never looked out for aliasing. This PR certainly makes it a good time to work on this!\n. That sounds good, and good to know what to look for. I haven't tried any of the PR code yet, but will look forward to checking it out. I also remember not minding the non-sub-sampling preview, but if it can look better, match Bayer path, and not be slower or too complicated, then it's worth it...\n. @LebedevRI: sounds wise. Certainly not worth risking destabilizing the chain of RCs leading to a major version.\nI'll work up the sub-sampling for X-Trans, am curious if that helps with the edge artifacts. There are also further improvements to make along the lines of https://github.com/dtorop/darktable/tree/xtrans-better-downscale, well worth my working this up for all the X-Trans paths. I also found a way to slightly clean up the port of Markesteijn demosaic to dt, which should end up in a different PR, but again, that could be something for a point release.\nThings have been busy here, but look forward to spending time on this.. @upegelow It's a good point... I realize that I didn't update the description of the PR (or its title) to the current contents, which I just did. The PR no longer changes the size of the preview (that code wasn't working anyhow). It limits itself to forcing a quick downscale for previews (which should eliminate negative values in dark areas introduced by interpolation in a full demosaic) and refactoring into a single function some repeated logic about what sort of demosaic to perform. Apologies for the mis-described PR.\nIn dt 2.0, I think the previews were 720x450 right from the go (_init_f()) through the whole pipeline. In dt 2.2, they are (I believe) approx 1350x900 through the whole pipeline. Initially I thought it was good to return to the dt 2. behavior via shrinking them in demosaic. But it sounds like we need them 1350x900-ish through the whole pipeline.... RE @LebedevRI:\n\nSo without explicit casts, that would be an integer division, which is not nice.\n\nThere's no difference between *outc = (uint16_t)((float)col / (float)num); and *outc = col / num;, except the latter may perform better, yes? As dt_iop_clip_and_zoom_mosaic_third_size_xtrans() is only in the preview path, calculating uint16_t and throwing away the fractional result should be acceptable?\nI'll make a commit which just does a straight integer division, unless I'm missing something fundamental.... I was looking at src/common/interpolation.c which made me wonder if the better way to do this (rather than downsampling then blurring is to choose a more appropriate convolution kernel. This would be a bit tricky, as each point in the CFA needs its own kernel... Will experiment with this.. @hanatos: Current code should be a box blur on the separate CFA colors, with an unoptimized implementation (e.g. no ring buffer, no separate horizontal/vertical pass), see https://github.com/dtorop/darktable/blob/2483c3208c55ca56026a3b380b570695b032278d/src/develop/imageop_math.c#L972-L1023.\nIt's an interesting idea about blurring on the r-g and b-g planes. I'll try to think that out. Your laplacian pyramids code is helpful. The needed code will downscale RAW-sized images (12, 16, or 24MP these days) to a generally known size (MIP_F-ish), hence by a factor not 2 (or an integer). The proper way to do this is to interpolate, blur, then decimate?. Have been looking into this a bit more. The current code is something like a 9x9 box filter, which seems to be about the minimum size to avoid artifacts, due to the sparse reds and blues in the CFA. It's possible to use a nicer filter, something like Mitchell/Lanczos, but it has to be larger (say 13x13) to get good results (presumably because otherwise it underweights the distant reds/blues).\nThere seems to be no benefit on using a smaller filter for the less-sparse greens. I haven't worked out a way to blur along r-g and b-g color planes, but am still intrigued by that.\nBarring new insights, it looks like tuning/optimized the code currently in the PR is the best option.  I'd either add a ring buffer or a pre-calculated list of offsets for each CFA position. Also, I will change the filter width to not vary with the scale, as I think it should really only depend on the input CFA matrix.\nOn a larger scale, this is clearly not a common problem: to downsample a mosaiced image by a non-integer factor and output as a mosaiced image. It may turn out a better option would be to downsample X-Trans images by a factor which is a multiple of 3 in @_init_f()@ (and Bayer images by a factor which is a multiple of 2), then scale them down by a non-integer factor as needed during the mosaic iop, when they become 4-channel.. > Actually, that was my initial implementation\nInteresting... Certainly filtering a mosaiced->mosaiced downsample is producing results with few artifacts, so I'll plow ahead and make the best version I can of that. The main question I'm looking at now is what the smallest convolution kernel is which produces good/fast results (and whether something besides a box filter would be sufficiently fast and better quality).\nBut I am curious why your binning implementation wasn't good enough, as intuitively that seems the cleanest plan. I'll take another look at that as well.. > Do note that MIP_F is generated only once, when entering darkroom, and then it is cached.\n\nSo speed is not /too/ much of a problem.\n\nGood point. Current PR code is about 2x slower downsampling than what is in master. On my vintage 2012 laptop more like 0.1 sec. than 0.05. But even a simple preview processing pipeline is about .25 secs., so it's not a huge problem, especially given the caching.\nI worked a bit on optimizations, but everything I tried is either impractical or produces way too much hard to read (and buggy) code.\n\nJust checkout 3f8ca97 and look at the thumbnail.\nIt is worse than what we have now i'd say. For bayer, lacks sub-pixel sampling.\n\nI had no luck getting 3f8ca97 to run -- lots of complaints about 0 param size in raw overexposure module, but didn't spend too much time on it.\nCode in latest commit gives pretty good results for even fine-detail edges for X-Trans.. > You need to rm -rf /opt/darktable or whereever you install\nThanks! That works. It's true, it doesn't look promising. But I'll still look into it a bit more.\nIt turns out the latest commit works fine for 12MP and 16MP images but has artifacts for 24MP ones. It's an easy fix. I'll make sure before adding the fix that it works for other cases as well, in case a 36MP X-Trans sensor comes out next year...\n. Glad that it looks promising, and thank you for testing. I agree that it's an improvement on current master.\n@hanatos: I am blurring all three channels by the same amount. I tried reducing the blur for the green channel, in the belief that there was more information there and hence it could handle less blurring. But no go, the edge artifacts came back the moment I dropped the blur amount on the green. I'm still intrigued by your suggestion of blurring separately on R-G and G-B planes, but haven't grasped how to do that. I still see color fringes on small details or finely spaced alternating dark/light lines (see esp. second examples below). The only way I can see to get rid of these w/in the current code is to increase the blur, which, of course, has the downside that the blur increases for everything. I'm not sure if there is a smarter way to handle this.\n@LebedevRI: One other thing I experimented with was creating a convolution kernel weighted towards the center, or otherwise adjusting the filter in the hopes of sharpening, but I never found anything that produced anything sharper with fewer artifacts than a straight blur.\nTo me the code in this PR doesn't look like it loses information that is present in master, and the moment the full demosaic is calculated and replaces the preview, the blurriness goes away. (I'm using as my test the way the preview looks when it is temporarily shown in the main darkroom view area when moving around the image at 100%.) But I do understand that the blur is shocking, especially if one is used to some (very sharp) artifacts. Here is the test image at 100% from master:\n\nand from this PR:\n\nHere is another comparison of an X-Trans image:\nmaster:\n\nand this PR:\n\nIn PR #1382, @upegelow commented on the dangers of bad previews being used as input to modules such as perspective correction. I realize that any changes such as in this PR may change the behavior of existing history stacks in such modules.. Glad to see this merged, thank you @hanatos  for reviewing and rebasing.\n\ni think it should be related to the spacing of the respective colour channel (i.e. we could potentially blur colours way more and green a bit less). it should be designed to band limit the signal before sub-sampling it to the lower res CFA pattern (following the nyquist limit). \n\nThis is helpful guidance, I'll keep working on this.\nI'm embarrassed to say that I tested this without #1382, and of course, in combination it does look extremely blurry, as @LebedevRI observed. All the more reason to keep at this.. It's complete. It's to tie up some loose ends from the refactoring in #1382.. Though as https://redmine.darktable.org/issues/11167#note-22 mentions, some of demosaic's quality logic for previews is now wrong. Not sure whether to make a fresh PR to fix just that (which would conflict with this one) or to continue to update this PR with the appropriate fixes. Perhaps the latter is best, even if it results in more code to review?. Rebased onto master and changed to do full demosaic for previews, which should fix blurry previews.\nThere still is one more (smaller) problem, that the preview image does not exactly vertically align with the full pipeline image. I think this is an offset problem in dt_iop_clip_and_zoom_mosaic_third_size_xtrans(), and will look into this.. Actually the alignment problem between preview & full results seems to happen later in the pipeline in the crop iop. Not something to fix in this PR.. > And it of course re-introduced bug #11340\nOh no! Good point. Back to work on this. I think the solution is to fix the mosaiced->mosaiced downscaling of MIP_Fs.. I did a quick test of downsampling by an integral ratio (so an integral # of CFA squares go into one output CFA square). There are still unsightly artifacts. Hence either this PR is a workable improvement, or some better thought out signal processing is necessary.. > I'm not sure that is a bad thing at all :)\nIt does seem good to comment and expand the code a bit for dt's purposes! The original is so tightly written it becomes almost a domain-specific language for interpolation. Once it's clear which a step does, it is legible, but the trouble is first figuring out what the step does.... Great! Thank you for pointing out the problem.\nJust getting back to the bandlimited downsample code.... Yes... Trying to work backwards from output to input, to clean up proof-of-concept version. So that will only need to calculate the useful pixels. Also looking into highlight problem.... > Why do you think it would use X-T2/X-Pro2 color matrix, while both Fujifilm X100S an Fujifilm X100T use the same matrix, which is not the same as for X-T2/X-Pro2?\nThe X100F uses the 3rd gen. sensor (https://en.wikipedia.org/wiki/Fujifilm_X-Trans_sensor#List_of_X-Trans_sensors) which it shares with the X-T2/X-Pro2, so more likely its characteristics align with those than X100S/X100T.\nBut within generations there are divergences, e.g. for gen 2 16MP, X100S and X100T matrices match, but the matrices for X-T1, X-T10, X-E2 are different (and match each other), while the X70 is totally different.\n// 2nd gen. 16mp\n{ \"Fujifilm X100S\", { 10592,-4262,-1008,-3514,11355,2465,-870,2025,6386 } },\n{ \"Fujifilm X100T\", { 10592,-4262,-1008,-3514,11355,2465,-870,2025,6386 } },\n{ \"Fujifilm X-T10\", { 8458,-2451,-855,-4597,12447,2407,-1475,2482,6526 } },\n{ \"Fujifilm X-T1\", { 8458,-2451,-855,-4597,12447,2407,-1475,2482,6526 } },\n{ \"Fujifilm X-E2\", { 8458,-2451,-855,-4597,12447,2407,-1475,2482,6526 } },\n{ \"Fujifilm X70\", { 10450,-4329,-878,-3217,11105,2421,-752,1758,6519 } },\n// 3rd gen.\n{ \"Fujifilm X-Pro2\", { 11434,-4948,-1210,-3746,12042,1903,-666,1479,5235 } },\n{ \"Fujifilm X-T2\", { 11434,-4948,-1210,-3746,12042,1903,-666,1479,5235 } },\nThe relevant commit to LibRaw https://github.com/LibRaw/LibRaw/commit/7834056ad4ead68a8ad4ad6d1f8ffb89872ff54c is described as \"(temp)\". It looks like Adobe DNG Converter doesn't currently support the X100F (see https://helpx.adobe.com/camera-raw/kb/camera-raw-plug-supported-cameras.html#Fujifilm), and dcraw doesn't have an entry. Is there any other way to figure out a matrix?\nSo not sure what to do. This color matrix is workable, but judging from history, probably isn't right. Is it better to withdraw PR, merge a profile that may be wrong and fix it later, or leave this open/incomplete until a proper matrix is published, so in the meantime anyone who needs a quick fix of X100F support can pull it in by hand? Presumably any images edited with a wrong matrix will need to be re-edited?. > But the bugs seem to be in Gtk, not in darktable, correct?\nI'm not sure. I don't know much about Gtk/Gdk. I've been meaning to see if there is some sort of inspector tool so I can see what input events are getting fired and hence how scroll events are getting lost. There could be something about widgets grabbing and not releasing events which is only being exposed in Wayland. Though I'd find that surprising, as both X11 & Quartz are fine with the current code. I have no idea what could be causing the narrow drop-downs, unless there were some under-the-hood styling incompatibility?\nRegardless, this at least punts the problem down the road. I can say that darktable runs much better under XWayland than straight Wayland.. Regarding the narrow menu problem, it seems that calling gtk_widget_show_all(menu); before gtk_menu_popup_at_pointer()/gtk_menu_popup() will eliminate the problem under Wayland, and doesn't seem to break anything under X11. Some of the darktable code was already doing this.\nI started a branch https://github.com/dtorop/darktable/tree/wayland-fixup with this fix, and also eliminating what seems to be an extraneous positioning call for newer GTK. I'll see if there are other Wayland fixes which could be useful.\nStill not sure if Wayland is extra-finicky or exposing real bugs.. Made! https://github.com/darktable-org/rawspeed/pull/95. > The preset menu in left sidepanel is broken - they now align to the center, not the preset button. Look at collect lib.\nThis should be fixed now. Tested on debian stretch, gtk 3.22.8-1 and both X11 and Wayland.. Also rebased to master.. One question is whether, with so much boilerplate to handle UP/DOWN vs SMOOTH scrolling, if it makes sense to have functions (say either dt_ui_get_scroll_delta_y() or dt_iop_gui_get_scroll_delta_y() and then another to get/accumulate integral scroll values) to cull out a bunch of this repetitive code.. > Yeah, it does make sense. Duplication is not good.\nI'll do that for this PR. It'll cut some lines of code.... I coalesced the scroll handling into a couple functions, dt_gui_get_scroll_unit_deltas which returns whole-number deltas, dt_gui_get_scroll_deltas which returns fractional deltas. The former should produce the same scroll behavior as before this PR, except that trackpad scrolling will work under Wayland. The latter adds smooth scrolling for trackpads to both X11 and Wayland backends (and Quartz?). Behavior for scroll wheels should remain unchanged.\nAlso rebased to combine a couple earlier commits.\nIt would be possible to change all scroll handling to only call the unit-delta function, which would fix touchpad scrolling for Wayland but otherwise not change UI behavior. It would even be possible to be extremely conservative and via some conditionals/ifdefs only enable GDK_SMOOTH_SCROLL_MASK under Wayland, to leave other codepaths even more as-it-were. This is what the Scintilla developers did (https://sourceforge.net/p/scintilla/bugs/1901/).. > I will only be able to test mouse scrollwheel and keyboard arrows with X11.\n\nSo if someone with touchpad/etc. wayland/etc can test too, it would be nice.\n\n@LebedevRI: thank you for the thorough review! I'm in the opposite boat so far as testing. I don't have a good wheel mouse, but have been testing on Wayland and X11 with touchpad/trackpoint. My hope is to make the Wayland case not broken, with an added bonus of making touchpad interaction better. But clearly good not to break the X11/scrollwheel case, which must be what most people depend upon.. Incidentally, to cross-reference, https://bugzilla.mozilla.org/show_bug.cgi?id=958868 is also a wealth of information about the fine points of handling GDK_SCROLL_SMOOTH.. > Hm, this does not change anything here, unfortunately :(\n\nIn these two iops, scrolling up still moves the point down...\n\n@LebedevRI: I flipped it now! I was fuzzy until @houz wrote about what behavior is preferred. I amended the last commit (rewrote history) so that there wouldn't be a huge stack of commits fine-tuning this.. One more change to base/tonecurve: I eliminated x-axis scrolling behavior. This means scrolling in these iops should be unchanged compared to git master, excepting that it will now be smooth on trackpads and work on Wayland.\nI was using these modules today and realized that x-axis scrolling of points really adds nothing (though it feels sort of cool to scroll points side-to-side), and indeed loses something valuable: the ability to adjust y values of points without mucking up their x values.. I've been using darktable with this PR applied for a bit more. One unintended consequence of smooth scrolling in tonecurve/basecurve/levels etc. is that it adds a lot of extra undo items when one makes a scroll adjustment. This requires lots of crtl-z-tapping to get back to a prior state. I'm wondering if this is enough of a reason to turn scrolling in these cases back to accumulating a delta of 1 before making an adjustment. Certainly for tools such as tonecurve/basecurve, one case use a ctrl-modifier to make fine adjustments if needed.\nFor equalizer-style tools, where scrolling alters the size of adjustment cursor, accumulating too many undo events isn't a worry.. > The idea is indeed to avoid recording too many intermediate state for a module. Please try it and tell me how it works on your side.\n@TurboGit: I like working with #1419 applied. It makes undo much more useful for tonecurve/basecurve and gives me confidence to experiment a bit knowing that it is possible to pull back a change.\nWhen I got carried away and made a mistake, I did still find myself skipping back and forth a bit to find the actual place to which I wanted to undo. For example, I made a good correction to one point on basecurve followed by a bad correction to another point. One thought would be to force recording of undo state whenever the user changes the point which they are manipulating in an iop, while also increasing the undo-record interval to eliminate recording so many in-between positions for each point. I'm not sure if the additional code complexity would be worth it, but it would model one idea of what an undo should do.\nIf it seems likely that #1419 or some variant will go in, it would make me happy as I would feel better about leaving the smooth scrolling behavior enabled for iops such as basecurve and tonecurve.. > Sorry, i keep meaning to re-review this pr, and then get carried away. Will try to look at it tomorrow.\nThank you, would appreciate the re-review as there is time!. \n\n\n\nPressing ESCAPE now closes the floating window.\nClicks outside of a bauhaus combobox will close the combobox.\n\n\n\ud83d\udc4d\n\nThanks! Other behaviors remain the same:\n\nClicking outside of the floating window still closes it.\nMoving the mouse cursor more than 50 pixels out of a bauhaus combox or pressing ESCAPE still closes the combobox.\n\nAlso, I should mention that floating windows are now styled via CSS (within the constraints of what GtkPopover allows).. Exciting! It's definitely a risky/invasive change, but I hope worth it for the simplified code and simpler relationship to GTK. Will keep an ear out if problems arise. This does bring a Wayland-workable darktable much closer, for what that is worth.. A me-too note to say how exciting it is to so this show up in git master. I appreciate how nicely it handles fine detail without producing chroma noise. Much appreciation to all the work which went into its arriving.. I added a bunch more commits after the first to try to work out a fix to #11781 and generally make things more smooth.\nThe goal here is to have the print settings panel be the only one which figures out orientation of the current image. If the user navigates to a new image, the orientation combobox will be set to landscape or portrait based on that image's orientation. That information will be passed on to the print view, which will update the layout preview accordingly. The print view only cares about the orientation as set in the print settings.\nIf the image has a lot of iops enabled, and it takes a while to process these to determine its orientation, the print settings panel will repopulate its orientation combobox once that work is complete.\nA down side is that print settings now must catch a couple more signals, and it processes these even when not in print view. The latter should be fixable.\nStill a bunch of FIXMEs, and the numerous commits could be coalesced.. @houz: Thank you, using view_enter() and view_leave() now, which makes things better.. I rebased in order to squash some of the multitude of commits together. This version appears to work well, and simplifies the prior code.\nThe major change is that the print settings panel now does all the work of determining image orientation, and passes that information on to the print view. Previously the panel and center view both tried to do this, sometimes with differing results.. @TurboGit: Thank you for checking it! It's been a long-standing thing I've wanted to work out within an extremely useful part of the program. Speaking as someone who makes a lot of landscape format prints.... Thank you!. Somewhat related, but the goto gui (https://github.com/darktable-org/darktable/blob/master/src/iop/temperature.c#L956) doesn't seem ideal. It could make the logic clearer for reload_defaults to call a separate function which would return once tmp.coeffs was set as well as possible. But that would be a separate PR.. Yes, that looks right! I'll make a fix to the fix, and a PR.. @kelvie Thank you for testing!\nI went with Roman's suggestion (also setting default_enabled) as otherwise switching from a color raw to a JPEG/PNG/etc would leave the iop enabled. When I made PR #1631 I didn't understand that if reload_defaults() changed default_enabled and ilk in some cases, that it should reset them predictably in all cases.\nAs I understand it, the extant dt behavior to leave the temperature iop disabled (though enable-able) for non-raw files makes a lot of sense as, though the iop can work on those files, it has no idea what it is making the changes relative to, as it doesn't have the wb coeffs as they come in from the raw. And the real power of the iop is to get the RGB channels of a raw as nice as possible before they're all smooshed together in the demosaic step.. Glad to have it fixed w/the monochrome improvement. I somehow didn't process in #1631 that reload_defaults() should reload the defaults regardless of what else it does.\nI'll make another PR to move finding the wb coeffs into its own function.. I don't think it is vital. If my memory is right, this is in no way a functional change. It was an attempt to clean up the flow of some code which gave rise to a bug or two. But the actual current code works fine whether or not this PR is applied.. I was wondering, I couldn't remember if that went for basecurves or noise profiles (or both?). I'll close the PR, but leave the branch up, as I like the results with this curve.. I made a few obviously bad basecurves before making this one. This one appeared satisfactory because:\n\nIn basecurve.pdf and tonecurve.pdf the sample count histogram is fairly uniform across the brightness range and doesn't have any anomalous thick sections.\nThe JPEG RGB channel brightness curves are consistent with each other and don't have odd kinks, which make the curve hard to fit plus just plain look weird.\nBoth of which suggest that the sample images were sensibly made, unlike some bad choices I made in other source images, e.g. photographing a glossy black box in front of a window.\nThe resulting curve looks like a sensible basecurve: a slow rise in the toe, and leveling out in the shoulder.\nComparing a JPEG/raw pair, with the raw processed with the basecurve, the tonality between the two isn't too far off.\nThe basecurve looks similar to the curve generated by darktable-chart and an IT8.7 target.\nI like what the basecurve does when I use it day-to-day.\n\nBut I can't speak to how one would formally verify the curves.\nThe curve I made for the X100S a few years ago looks somewhat different, but that may be due not only to a different generation of sensor but that back then the I believe dt-curve-tool worked slightly less well, and I may have been even more naive about using it.\nI am curious if one is better of using the results of darktable-chart, as even if the curve is drawn from less tonal data, there is the benefit of a color LUT.. One other question: is there a good scheme about what to do about whether to pull settings from dt_lib_print_settings_t or via dt_conf_get_*()? Currently in _print_button_clicked() it's some of each:\nhttps://github.com/darktable-org/darktable/blob/019f4b08b7c9d7fb1799405b6e627ad457ef3f90/src/libs/print_settings.c#L440-L452\nThe two values should match, but pulling directly from the struct is presumably the lighter-weight alternative. I'm clear if there's a preferred way to do this across the dt code.. Indeed! If someone really loves smooth scrolling on X, they can switch to Wayland. I'll be curious for OS X and Windows results.. Pasting in from the mailing list:\n\nWhat if the user filters the images by tags places|beach and darktable|printed|%, and hand-sorts that collection. Then some other day the user reverses this filter (by darktable|printed|% and places|beach). The same images will display, but the sort order is lost.\nSimilarly, what if the user filters the images by places|beach and makes a good sequence. Then they sub-filter by narrowing down to darktable|printed|%. The sort order is now lost.\n\nShould each tag, film roll, etc. have its own potential custom sort order, and should successive filtering via \"collect images\" have no result on that order, hence only the first chosen filter (or the first chosen filter with a custom order) matter?\nPerhaps a simpler version is best: sort order associated not with a particular \"collect images\" filter but as another column in the images table. This would cause less worry about a lengthy join and indexing on a TEXT column in custom_image_order. And once places|beach is given a custom sequence, it will maintain that even if the collection is further filtered. And somewhat maintain that sequence for other collections which overlap it. This would also not leave \"ghost\" custom image orders laying order when a tag or film roll is deleted. On the other hand, it wouldn't allow for creating tags sequence|v1 and then sequence|v2 with utterly different orders.\n. Far fewer LOC is probably good! Good to do one thing well/predictably.\nI added a couple queries about how this would work for large image libraries. My wild guess is the re-order UPDATE would probably run in decent time, but the initial row-by-row update of all images could be slow. I wonder if there is a better but still easy data structure for re-ordering. Naive thought: a linked list (column id_next rather than position) would make re-ordering fast. But how would you order the SELECT (or its results) when showing a collection? Not to prematurely optimize and suggest adding back complexity.... You're welcome. Take anything I write about SQL with a grain of salt -- the last serious DB work I did was about 15 years ago.. Perhaps worth adding in as a comment some version of your note:\n\n\n\nThe sequence pictures come in (import) define now the initial sequence of custom order. This way I able to update at linear cost. I tried hard to find a better solutions but failed on that.\n\n\nI use now an int64 for the position index. The upper 31 bits are used to set the initial order. The lower 32bit are used to reorder images. That way only a small amount of images must be updated while reordering images.\n\n\nExample: (position values hex)\nInitial order:\nImg 1: 0000 0001 0000 0000\nImg 2: 0000 0002 0000 0000\nImg 3: 0000 0003 0000 0000\nImg 3: 0000 0004 0000 0000\nPutting Img 2 in front of Img 1. Would give\nImg 2: 0000 0001 0000 0000\nImg 1: 0000 0001 0000 0001\nImg 3: 0000 0003 0000 0000\nImg 4: 0000 0004 0000 0000\nImg 3 and Img 4 is not updated.\n\nAs I worry that otherwise the code in dt_collection_move_before() isn't necessarily intuitive and the data structure isn't readily recognizable.\nAny luck on #darktable IRC? I wouldn't get any deeper into this unless you bounce things off one of the core developers!. > IRC: Hanatos said that he liked this implementation, but wanted to ask Houz for his opinion.\nThat's great!\n\nI think that was on Wednesday. It seems that they didn't find the time yet\n\nPatience! It seems like a good solution. Curious what they say.. Congrats @monsieurmona, and thank you!. Calling images \"virgin\" is a bit loaded. I made another commit with simpler language.. Yes, I'm just sorting through confusion on this! When I declare out shared, the compiler complains:\nimageop.c:2316:48: error: \u2018out\u2019 is predetermined \u2018shared\u2019 for \u2018shared\u2019\n   #pragma omp parallel for default(none) shared(out) schedule(static)\n                                                ^\nHere out is declared float *const out. Does OpenMP only require the pointer itself to be declared shared() (if it is non-const), and not enforce anything about sharing of the pointed-to data?\nI was surprised that, when I made a bunch of pointers float *const, the compiler mandated dropping them from the omp parallel clauses. It doesn't seem sensible to declare them float * and put them back as shared() if the pointer itself doesn't change? Any experience on this is most welcome!\n. This is taken straight from dcraw and the fiendishly complicated mind of Dave Coffin (or the mysterious Frank Markesteijn?). Is it good to elucidate the succinct mysteries of dcraw via comments, or even to make this into a multi-line statement that reads more easily? It could become:\nc\n// bounce rgb data to second set of buffers on second pass\nmemcpy(rgb+4, rgb, 4*sizeof *rgb);\n// work in this second set of buffers\nrgb += 4;\nBut there's something amazing about the original dcraw code.\n. Good question. The wavelet denoise algorithm is originally from dcraw, which keeps the same coeffs for Bayer or X-Trans. The coeffs are used per channel in wavelet/hat-transformed space, as factored by threshold. The worst I can see here is that threshold parameter will have slightly different meaning in the x-trans case. Hard to see this from observation so far. Will look into this more.\n. This is a good point. A caveat is that the dcraw code is already somewhat refactored. The original dcraw only works on 16-bit ints, so there are some changes to make it work with floats and OpenMP (see SHA: 0a87cec66968cd6038bc24ee3d538bf26c2d933d and SHA: 11c3ba9237789fe7b69bd3ca068a18d43dce610d). There are other changes to make it in accord with dt coding style, and a big patch to change colorspace of homogeneity operation (SHA: ddee52ac515680b5b7e53c4f3ea5eb624b3445c0). Also a fix for cleaner edges (SHA: c9f46fc0c9a49df259d14cdc051825c5f6be5857). Hence it's already becoming a fork.\nI certainly agree that trying to clarify complicated code is a great way to introduce bugs.\nOne reason for importing that dcraw code just wrapped, then making commits to alter it, was in hopes that if dcraw changed, it would become clear how to keep this code in sync. As another case, dt's wavelet denoise code is also borrowed from dcraw, and has gone through quite a few permutations by now.\n. Am still skeptical about writing shared (out) which seems to share the pointer but not the underlying data. Not to mention that as out is declared float *const out, OpenMP doesn't allow sharing of it anyhow without dropping the const.\nThat said, declaring out as float *out and shared(out) is in keeping with the rest of the dt code. If this is questionable, better that I take it up overall sometime later. There seems to be no performance difference with shared() or without. As I'm new to OpenMP, I'm happy to defer here, rather than being (except in this note) pedantic.\n(Does sharing out create a critical section around writes to the memory to which out points? Not that that's necessary in this case, as each thread writes to its own section of memory.)\n. Thank you for the sharp eye on this! Checking if max==0.0f could be OK as it's really checking if 0.0f has been assigned to max somewhere else in the loop (as max is overloaded, serving both as a max vlaue and as a flag that it needs to be calculated)? But this whole section is awkward, due to my less-than-ideal conversion of dcraw's code to handle floats rather than ints. I'll work up an overall clean-up/clarification instead...\n. @hanatos: Indeed, #584 looks like a great change! The X-Trans CFA gets offset here according to the distance between raw and usable data, which can vary depending on which corner becomes top-left upon rotation. Once that is not a worry, it would also be possible to modify (as with Bayer sensors) the CFA data in cameras.xml to pre-offset it depending on the cropped usable raw area.\n. From some quick profiling on a Core i7, speed appears limited by memory access, and the modulo isn't a bottleneck. I can't figure out how to make a power of 2 sized array work with the modulo 6 CFA (either padded or by repeating each rows/cols). Is it a mathematical impossibility or am I being dense? Any advice most welcome.\nThere are also some fast modulo 6 divisions (based on a fast modulo 3 http://homepage.cs.uiowa.edu/~jones/bcd/mod.shtml, https://stackoverflow.com/questions/1697358/fast-modulo-3-or-division-algorithm, http://compilers.iecc.com/comparch/article/99-10-056). Knowing that row & column will not be that large also helps, and this would also make things nicer with the negative row/col values which happen in demosaicing. But is this worth the obscure code if it isn't really a bottleneck -- and the compiler and CPU architecture are already doing a good job?\nRegardless, as the CFA data is loaded into dt_image_t every time an image is read, and not stored in sidecar files or such, it should be possible to implement a changed format for it later if that becomes necessary.\n. Modulos don't look as slow as they used to be. The dtorop/darktable@1a67360 commit (to experimental xtrans2-dev branch) gets rid of modulos (though doesn't cleverly pack data) and gives an approx. 2% speed-up. Hence this doesn't seem worth dealing with in this PR.\n. Good to know. I can update the comment to reflect this without removing the assert? I don't think it actually bothers Markesteijn demosaic to have input outside of [0,processed_maximum] but as it will be clamped to [0,processed_maximum] at end of this demosaic, seems good to lay out an expected initial condition.\n. For \"clip highlights\", data->clip multiplier can matter, as iop output won't exceed data->clip * fminf(processed_maximum). But as the two reconstruct methods are just using data->clip to identify where the clipping starts, their maximum output depends on fmaxf(processed_maximum). Even in the case of \"clip highlights\", the output will never exceed fmaxf(processed_maximum) (which could even be less than data->clip * fminf(processed_maximum) in certain cases).\n. @upegelow Am happy to check in about any changes, but as @hanatos says should be pretty transparent -- especially as removing clipping was your idea in the first place... I've been using the new CPU-path code the last few days and feel happy with it.\n. Yes, does look better. On my machine avg. iop execution time goes from 0.31 to 0.27 secs. (CPU time is up from 0.78 to 1.02 sec., which is OK, yes?)\n. Seems to be marginally equivalent speed (or marginally faster) to compute & output just one, but it's more concise and matches process_lch_bayer() so seems worth changing.\n. Indeed, this must be the case. As some columns require way more work (have more highlights to reconstruct) it makes sense that with dynamic scheduling there was less chance of threads on non-clipped columns stalling out.\n. Thank you! Made a commit to do this. I also eliminated passing min_neighbors, as this is derived from dt_iop_hotpixels_data_t*, at the cost of building that logic into the process_*() functions.\n. I realize this bit is utterly wrong, and doesn't in fact halve the image size as hoped for. Still looking for the right way to do this.. I had to put the {} in to declare the qual variable within that case.. I added a commit to fix this in the mousewheel scrolling case, while trying when possible to keep the scrolling in the direction of any touch or trackpoint events. As comments note, the latter isn't always possible, so I'm erring on the side of keeping the mousewheel behavior consistent.\nIt feels right, when possible, for touch scrolling to move the point in the direction of the scrolll.... Fixed here as well... Neither of these convinces github I actually made the change requested, due to my having altered lines a bit later in the file.... >> It feels right, when possible, for touch scrolling to move the point in the direction of the scrolll...\n\nYep, same is valid for mouse scroolwheel/etc\n\nI don't have a scroll wheel mouse here to check what is right for it. I should make the scrolling for all cases as it is for touch/trackpad in latest commit, yes?. I went ahead and added a commit to make all scroll events be for base/tonecurve be handled the same, whether mouse scrollwheel or touch etc. This makes the code simpler, but does change behavior from what is in git master. But this is a more sensible behavior for scrollwheel mice as well as the other cases?. > The current (inverted) behaviour is on purpose as it's what hanatos prefers. Please keep it that way in this PR. Re-evaluating that decision is something for another day.\nThank you for clarification! I flipped it back.\nOne question is what to do about horizontal scrolls. Prior to this PR, they were just plain ignored. Now they are handled (presumably only from trackpad/trackpoint/touch) and their direction is inverted (to be consistent with vertical scrolling). Would it be better just to ignore them, such that scrolling would be used to fine-tune the y-value of points without messing up the x-axis? Alternately, some keyboard modifier (meta/alt?) could be used to switch from y-only scrolling to x and y scrolling? . Oh, good point. I'll fix it. I cargo-cult style check for (!img || img->film_id == -1), but is it enough to just check for !img? In which case dt_image_cache_read_release() is a NOP if there is no image.. OK! One more commit, to switch it back, with an explanatory comment why.. It looks like dt_control_job_dispose() keeps the last pointer to the job params, then it free()'s the job structure which includes the pointer. https://github.com/darktable-org/darktable/blob/afe30d62f550a6243e54088c2b8cf97e6fee62c3/src/control/jobs.c#L142-L152\nThe extant job code already deals with getting rid of the last reference to the released memory?. @TurboGit Thank you for fixing, and merging! There are a couple other spots where a run-on title or printer name could be ellipsized:\nhttps://github.com/darktable-org/darktable/blob/019f4b08b7c9d7fb1799405b6e627ad457ef3f90/src/libs/print_settings.c#L241\nhttps://github.com/darktable-org/darktable/blob/019f4b08b7c9d7fb1799405b6e627ad457ef3f90/src/libs/print_settings.c#L436\nDo you think these are worth fixing, even via putting a short version of the job title and printer name into dt_lib_print_job_t? I'm happy to do that work if you want -- I was away from the computer this weekend hence didn't catch your note until now.\n. Here is a commit which does this work in one place in print, but doesn't provide an overall fix via dt_control_log: f093decb8470c994d74d101a729488821c932425\nIt doesn't properly handle UTF8, though! Maybe there needs to be an overall dt_ellipsize routine, which does the right thing and allocates memory which must be freed later. I like unloading the work to GTK in ffb2d3dcf02259fbdda0525e904a87fbdaf7b4a0, but that would require lots of GUI work for displaying log messages.\nCurious what you and houz figure out. . This does sound like the right route. Is this something @TurboGit will code? I could look at it, but won't be fast at getting to it.\nIn the case of print, the message can appear via dt_control_log but also in dt_control_job_add_progress. The latter doesn't ellipsize long messages but at least crops them, so probably not so big a concern. As long as some of the title shows (which it does) the user can figure out which job is which, in case they want to cancel one.. Ah, I see 0a6a32ceebac46b1e74a09a39ab7bc616303ab36 does a better fix for the job labels, too.. Another way to handle this, on the model of\nhttps://github.com/darktable-org/darktable/blob/master/src/bauhaus/bauhaus.c#L77-L78\nis to just set PANGO_ELLIPSIZE_MIDDLE & width for the whole log message at\nhttps://github.com/darktable-org/darktable/blob/master/src/control/control.c#L263-L264\nIf the print messages get way to long the user will probably still see the start of the title and the end of the printer name. And this is really an edge case, seems better to handle simply rather than essentially (if I understand the alternative) making a customized printf.. I'm curious what the cost of this update is for someone with 100K+ images in their library (which some users will have). I've really no idea of the answer to this -- e.g. how will sqlite can handle this.. Likewise this could take even longer to run for the user with 100K+ images?. Here:\n> sqlite3 .config/darktable/library.db \"select count(*) from images\"\n55598\n\nFrom reading the dt list, I'd expect that someone has a library that exceeds this by an order of magnitude.. This works so long as the user has less than 2 billion or so images in the collection, yes?. That sounds good to me. I'll update this.... ",
    "xsdg": "On 07/14/2014 09:44 AM, hanatos wrote:\n\nMerged #588 https://github.com/darktable-org/darktable/pull/588.\n\nWoohoo! :o)\n--xsdg\n. A comment from the peanut gallery: I would definitely avoid refactoring \ncode like this.  For one, it's an easy way for someone to inadvertently \nadd bugs to the code.  And beyond that, by essentially making a fork of \nthe original, it becomes unnecessarily hard to import newer versions of \nthe code when the upstream version changes down the line.\nKeep in mind that future maintainers may not have as good of an idea of \nwhat this code does, and where in the dcraw codebase it came from, as \nyou do.\n--xsdg\n. ",
    "kanru": "woot!\n. Better to use pathconf at runtime\nFor example see http://stackoverflow.com/questions/4267390/path-max-not-declared-when-compiling-on-ubuntu-10-04\n. ",
    "jwagner": "@LebedevRI sure here it is: http://29a.ch/tmp/dt-noiseprofile-20140729.tar.gz\n. I'm not really familiar with SSE intrinsics but aren't you missing and else clause?\n. ",
    "Messie1": "On Monday, I'm in holiday now.\nAm 17. Oktober 2014 14:39:53 schrieb Roman Lebedev notifications@github.com:\n\n@Messie1 there should be a tarball with the following name: \ndt-noiseprofile-$(date +'%Y%m%d').tar.gz\nCould you please upload it so we can verify validity of the profile?\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/darktable-org/darktable/pull/641#issuecomment-59500904\n. \n",
    "mneumann": "I get the following errors when compiling the master branch of Darktable on DragonFlyBSD:\n```\n[ 56%] Building CXX object src/CMakeFiles/lib_darktable.dir/common/exif.cc.o\n[ 56%] Building C object src/CMakeFiles/lib_darktable.dir/gui/preferences.c.o\n[ 58%] Building C object src/CMakeFiles/lib_darktable.dir/metadata_gen.c.o\nIn file included from /home/mneumann/darktable/src/common/exif.cc:57:0:\n/home/mneumann/darktable/src/control/conf.h: In function 'int dt_conf_get_int(const char)':\n/home/mneumann/darktable/src/control/conf.h:148:21: error: 'isnan' was not declared in this scope\n/home/mneumann/darktable/src/control/conf.h:148:21: note: suggested alternative:\nIn file included from /usr/include/c++/4.7/random:38:0,\n                 from /usr/include/c++/4.7/bits/stl_algo.h:67,\n                 from /usr/include/c++/4.7/algorithm:63,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/mneumann/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.7/cmath:635:5: note:   'std::isnan'\nIn file included from /home/mneumann/darktable/src/common/exif.cc:57:0:\n/home/mneumann/darktable/src/control/conf.h: In function 'int64_t dt_conf_get_int64(const char)':\n/home/mneumann/darktable/src/control/conf.h:163:21: error: 'isnan' was not declared in this scope\n/home/mneumann/darktable/src/control/conf.h:163:21: note: suggested alternative:\nIn file included from /usr/include/c++/4.7/random:38:0,\n                 from /usr/include/c++/4.7/bits/stl_algo.h:67,\n                 from /usr/include/c++/4.7/algorithm:63,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/mneumann/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.7/cmath:635:5: note:   'std::isnan'\nIn file included from /home/mneumann/darktable/src/common/exif.cc:57:0:\n/home/mneumann/darktable/src/control/conf.h: In function 'float dt_conf_get_float(const char)':\n/home/mneumann/darktable/src/control/conf.h:178:15: error: 'isnan' was not declared in this scope\n/home/mneumann/darktable/src/control/conf.h:178:15: note: suggested alternative:\nIn file included from /usr/include/c++/4.7/random:38:0,\n                 from /usr/include/c++/4.7/bits/stl_algo.h:67,\n                 from /usr/include/c++/4.7/algorithm:63,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/mneumann/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.7/cmath:635:5: note:   'std::isnan'\n/home/mneumann/darktable/src/common/exif.cc: In function 'int dt_exif_read_blob(uint8_t, const char, int, int, int, int, int)':\n/home/mneumann/darktable/src/common/exif.cc:1180:32: error: 'isnan' was not declared in this scope\n/home/mneumann/darktable/src/common/exif.cc:1180:32: note: suggested alternative:\nIn file included from /usr/include/c++/4.7/random:38:0,\n                 from /usr/include/c++/4.7/bits/stl_algo.h:67,\n                 from /usr/include/c++/4.7/algorithm:63,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/mneumann/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.7/cmath:635:5: note:   'std::isnan'\n/home/mneumann/darktable/src/common/exif.cc: In function 'void dt_exif_xmp_read_data(Exiv2::XmpData&, int)':\n/home/mneumann/darktable/src/common/exif.cc:1770:22: error: 'isnan' was not declared in this scope\n/home/mneumann/darktable/src/common/exif.cc:1770:22: note: suggested alternative:\nIn file included from /usr/include/c++/4.7/random:38:0,\n                 from /usr/include/c++/4.7/bits/stl_algo.h:67,\n                 from /usr/include/c++/4.7/algorithm:63,\n                 from /usr/local/include/exiv2/types.hpp:49,\n                 from /usr/local/include/exiv2/metadatum.hpp:38,\n                 from /usr/local/include/exiv2/exif.hpp:34,\n                 from /usr/local/include/exiv2/easyaccess.hpp:33,\n                 from /home/mneumann/darktable/src/common/exif.cc:40:\n/usr/include/c++/4.7/cmath:635:5: note:   'std::isnan'\n--- src/CMakeFiles/lib_darktable.dir/common/exif.cc.o ---\n** [src/CMakeFiles/lib_darktable.dir/common/exif.cc.o] Error code 1\nmake[2]: stopped in /home/mneumann/darktable/build\n1 error\nmake[2]: stopped in /home/mneumann/darktable/build\n--- src/CMakeFiles/lib_darktable.dir/all ---\n*** [src/CMakeFiles/lib_darktable.dir/all] Error code 2\nmake[1]: stopped in /home/mneumann/darktable/build\n1 error\nmake[1]: stopped in /home/mneumann/darktable/build\n--- all ---\n*** [all] Error code 2\nmake: stopped in /home/mneumann/darktable/build\n1 error\nmake: stopped in /home/mneumann/darktable/build\n```\nThe problem here is that isnan() is defined in math.h. I can include it, then it works for some files. BUT conf.h is also included from C++ files which #include <cmath> in which case isnan() (which is a macro on DragonFly) is undefined, and instead one has to use std::isnan(). Ok, no problem, I can ifdef it with __cplusplus and use either isnan or std::isnan, but then I have to include cmath in all C++ files (I can't simply include it in conf.h because it's extern \"C\" and cmath is C++), otherwise std::isnan() in undefined. I tried to fix it this way, but the easiest and cleanest way is to not use inline functions. I don't think these funtions are performance critical at all and inlining them is neccessary. What this patch does is just moving all functions from conf.h into conf.c (remove static inline in front) and keep the prototypes in conf.h (I am sorry that github doesn't show that in a nice way).\n. The problem on DragonFlyBSD (and probably other BSDs) is that you can't have both math.h and cmath included. cmath always wins when it is getting included. That's why I had to use std::isnan in exiv.cc (C++).\n. @darix: jap, that works! :)\n. Replaced by #644.\n. Yeah, the problem now is that there is both isnan() and std::isnan() in the same scope. Btw, it compiles fine on DragonFlyBSD. It should work when you replace isnan() with std::isnan() in exif.cc and probably some other files (or my previous patch should work too). \n. ",
    "darix": "wouldnt it be enough to just use\nusing namespace std;\nin exif.cc?\n. if you want test master you can grab a package here:\nhttps://software.opensuse.org/download.html?project=graphics:darktable:master&package=darktable\n(we are a few commits behind master due to technical issues, but I hope those can be sorted tomorrow). woot woot!. the attribute() thing should be in a define and only be enabled on x86_64 ... it will break ppc64le and aarch64 builds otherwise. . Why keep the makefile at all? shouldnt the cmakelists.txt deprecate this?. Hmm question to houz and hanatos then if they want to keep this backwards compat now that this is properly intergrated.. ",
    "roumano": "Hi,\nThe main problem was : \ngphoto2 is not to be able to get EXIF data for Raw file (at least for the 2.4 version)\nI have contacted gphoto2 mailinglist at 12 octobre 2012  and Marcus Meissner marcus@jet.franken.de repond me : \nIt might not be able to do so, but perhaps we can implement it if not yet possible.\nThere is no general technical limit.\nBut i never got a answer\nMore information here : \nhttp://sourceforge.net/p/gphoto/mailman/gphoto-user/thread/1367825655.1542.3.camel@roumano/\nIf you want, you can try to contact gphoto maintener about it.\n. Very Nice, this pull request is linked to this feature request : \nFeature #10053  :  http://www.darktable.org/redmine/issues/10053#change-25618\nFeature #8587    :  http://www.darktable.org/redmine/issues/8587#change-25619\n. ",
    "mgehre": "There is still a problem with the code: The generated MIPMAPs have odd looking colors.\nCan one of the more knowledgeable developers have a look at the patch (its quite short), please? \n. Thanks for the hint! Which function would be the correct one to zoom the cache image?\n. I think this is not applicable anymore with the new cache system.\n. This feature would be really nice to have, because its exactly my workflow (storage on NAS, local copy for editing on local SSD)\n. darktable uses neither -fwhole-program nor -flto, thus the compiler won't be able to inline the function defined in a cpp file. Due to the fact that the colorspace functions are called in tight loops in colorbalance, I think that all your files should become header files to allow inlining.\nI saw quite some speed ups, see e.g. #968\n. I updated the patch; this works for me\n. The following cases exist\n1) If the last history item is changed (without changing the number of history items), dt_dev_add_history_item is called.\n2) If a new history item is added, dt_dev_add_history_item is called\n3) If history items are removed, dt_dev_pop_history_items with cnt != dev->history_end is called\n4) when the GUI needs to be refreshed (e.g. at the end of dt_dev_change_image), dt_dev_pop_history_items with cnt == dev->history_end is called\nCase 4) should not invalidate the mipmaps, thus we have the check you found. Can you tell me an example where this check will lead to a wrong result?\n. Done here: https://github.com/klauspost/rawspeed/pull/115\n. This was merged upstream. Now the current rawspeed needs to be merged into the darktable repo.\n. What does \"Three is just a random preference.\" refer to in this context?\n. ",
    "rgo": "I see, format is the new/current attribute name but stable release was released with old name (because I'm using Darktable 1.4.2)\nThanks @LebedevRI \n. ",
    "cyr123": "I had mixed up \"uncompressed\" with \"lossless\". In fact all D750 files are compressed, so I have removed the unused entries.\nAlso, for verification, I have uploaded samples in NEF and DNG format:\nhttps://www.dropbox.com/sh/zrfylwrbz1igty3/AACNRDAJS3LQUBVHM9gjK5Gba?dl=0\n. ",
    "josepvm": "You can merge it now, thanks, if it does not make any inconvenience for Darktable's developers team.\nI need several more weeks to finish the translation, I will push a new commit and pull request when finished.\n. I suppose that, when I start seeing a 1.6 branch in darktable's github repo, I should stop pushing translation updates to master branch, and continue the work in the 1.6 branch instead. If not, please let me know, this is my first contribution here. Thanks.\n. The old commits shown here are caused by using a dfferent computer to do this changes, sorry. I've done \"git fetch upstream\" and \"git merge upstream/master\" before starting to work in the \"ca.po\" file. The final \"ca.po\" looks fine to me.\n. I think 'doc/usermanual/po/darktable-usermanual.pot' should be added to '.gitignore' file. When a translator creates a new translation for the usermanual using 'make update-usermanual-XX' this .pot file is changed. Not the original strings, but the comments with paths to xml files get changed to local paths in the translator machine. I suppose it's not necessary to commit this changes, so this file could be excluded with '.gitignore'\n. I see now that there is no need to merge this pull request immediately. I can continue adding commits as my translation progresses, and keep my local 1.6.x branch up to date (I am slowly learning to understand GIT, sorry).\nSo merge it when you prefer, is up to you, I don't want to bother the developers. Thanks! \n. Ok, thanks, I will do it the way you suggest.\n. Ok, my intention was to provide both translations (that's the way I was requested to do it in previous Darktable versions). I have finished first the 2.6.x translation, and I am working now on translation for master. I will pull request it this afternoon.. Here is the translation for master branch:\nhttps://github.com/darktable-org/darktable/pull/1986\n. ",
    "imarsv": "@simonspa Done\n. @LebedevRI, I have updated Last-Translator and Project-Id-Version\n. Yes.What is PR?\n. ",
    "prokoudine": "\nContacting me first would be the right thing to do. I already started updating ru.po.\nI started reading your translation and found both grammar and stylistic mistakes. I would not recommend merging the ru.po update.\nI haven't checked the translation of the manual, so I can't say anything about its quality, but since there was none before, I think merging it would be fine.\n. For the record, I reused some of your translations and added you to the list of translators. Thank you!\n. How does it actually affect darktable? The lines you changed are non-searchable.\n. Ilya, I specifically asked how this affects darktable rather than a web bowser :)\n. I pressed keys on my keyboard. That's all I did :)\n. Of course I don't, it was probably done ages ago. But it was either poEdit or Gtranslator.\n. Windows 7 64-bit, works as expected. \n",
    "NuclearNemo": "By the way, those are the -9/+9 presets for the Magenta-Green scale, in case they become relevant at some time in the future:\nDaylight M- :\n2.1585 1.0000 1.8792 1.0000\nDaylight G+ :\n1.7132 1.0000 1.6717 1.0000\n\nCloudy M- :\n2.3170 1.0000 1.7208 1.0000\nCloudy G+ :\n1.8377 1.0000 1.5321 1.0000\n\nShade M- :\n2.4642 1.0000 1.6075 1.0000\nShade G+ :\n1.9585 1.0000 1.4302 1.0000<\n\nFlash M- :\n2.3887 1.0000 1.7736 1.0000\nFlash G+ :\n1.8981 1.0000 1.5774 1.0000\n\nIncandescent M- :\n1.4717 1.0000 2.9509 1.0000\nIncandescent G+ :\n1.1705 1.0000 2.6326 1.0000\n. ",
    "CaptainSifff": "Here's Your dropbox link: https://www.dropbox.com/s/wundalfmpqjedvl/dt-noiseprofile-20141215.tar.gz?dl=0\nI'm fine with ignoring the changes to the scripts.\n. Here's the unaveraged data:\nhttps://github.com/CaptainSifff/darktable-patches/blob/master/presets.txtfull\n. ",
    "hokieengr": "Did this ever get merged into master? I also have a vested interest in making this work as not having it really complicates my workflow. Thank you!\n. Thank you both for your quick responses. Jake: Any chance you could sync up your fork with the latest master so we can at least use your work until it actually gets merged? I pulled it tonight and did have to manually merge exif.cc with the latest version to get it all to build. The rest of the files appeared to merge without issue.\nThanks again.\n. Agreed!\nOn Thu, Dec 31, 2015 at 12:32 PM, Roman Lebedev notifications@github.com\nwrote:\n\nWe really must merge this PR before next major release :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/793#issuecomment-168226096\n.\n. Did this ever get merged?\n. \n",
    "bbinet": "I'm also very interested in this feature: too bad it cannot be merged for the upcoming 2.0 release.\n. @jakeprobst, as you had requested, if you want to update your pull request: darktable 2.0 has just been released with a bunch of great new features! https://www.darktable.org/2015/12/darktable-2-0-released/ \n. any chance this can be merged soon?\n. ",
    "Bad-ptr": "@pedrocr \nOh yes. I made 2 test photos by this camera https://drive.google.com/open?id=0B4579Xy2gwv8ZlYydzR0Y3gtTkk&authuser=0\nIf you need more photos with different settings or other conditions(i don't know much about how to calibrate these color matrices and so on) feel free to ask.\n. ",
    "thisnamewasnottaken": "Think that did it.\n. ",
    "sieben": "You can install new packages. I think it could be useful to have the status\nof a pull requests right on the github interface. If you have a Jenkins or\nother CI tools it can work as well.\n2015-03-22 17:38 GMT+01:00 Roman Lebedev notifications@github.com:\n\nYeah, not sure about that.\nI have previously looked into travis-ci.org, and i wasn't convinced about\ndoing it.\nPlus, they have rather old compiler versions, so it really wasn't\ninteresting.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/880#issuecomment-84650604\n.\n. @LebedevRI What's the current status of continuous integration with lighttable?\n. Ah ok so yes travis-ci might not be the best option here. That said maybe\ntesting the pull requests with this jenkins could be great\nhttp://blog.clinkerhq.com/automatically-building-github-pull-requests/\n\n2015-03-27 11:34 GMT+01:00 Roman Lebedev notifications@github.com:\n\n@sieben https://github.com/sieben lighttable?\nOn a local jenkins instance, i do a semi-daily builds of master and\ncurrent stable branch (darktable-1.6.x ATM) with gcc-4.6 through gcc-4.9\nand clang-3.4 through clang-3.7 in all 3 build types (release,\nrelwithdebinfo, debug)\n(and, there is git master build by openSUSE OBS\nhttp://download.opensuse.org/repositories/home:/toganm:/photography/)\nSo locally, we're more or less covered...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/880#issuecomment-86896287\n.\n. \n",
    "ralfbrown": "This is in response to Camera Support request #10382.\n. I hope I didn't just make things worse....  Is there a \"git rebasing for dummies\" guide anywhere? :-)\n. To clean things up, I'm going to close this pull request and open another one in its place.\n. I just discovered that the noise profiles have not been included in master.  Is there a problem with them?\n. ",
    "moy": "To remove a commit, use \"git rebase -i\", delete the line corresponding to this commit in the todo-list, and let git do the job. You'll need to do a force-push to overwrite your previous pull-request.\n. http://git-scm.com/book/en/v2/Git-Branching-Rebasing\nDo read the part http://git-scm.com/book/en/v2/Git-Branching-Rebasing#The-Perils-of-Rebasing\nThen read the \"interactive mode\" section from the manpage http://git-scm.com/docs/git-rebase (but you don't want to start with the manpage)\n. If I use module->color_picker_box, then the histogram does not depend at all on the position of the color picker (either point or area). Ticking or un-ticking \"restrict to histogram\" changes the histogram, but moving the color picker doesn't. I tested my fix on a contrasty image, with different zoom levels and using cropping to make sure the coordinate were actually the ones of the final image, and it all seems to work.\nBut I normally write explanatory commit message like \"the code was using module which was wrong before because ... and it now uses dev->gui_module which is the right thing because ...\" and I'm unable to fill in the \"...\" it here :-(.\n. Thanks for looking at this and merging my fix. Yes, bug 9194 is probably still there: as I read it, the histogram and color picker act at the output of the colorout module (the instances of if(...!strcmp(dev->gui_module->op, \"colorout\")...) in `src/develop/pixelpipe_hb.c), and they should act on its input. But that isn't going to be an easy fix.\n. Thanks for merging. You should write more buggy software if you want me to send more patches ;-).\n. > Such an elaborated description of a feature belongs in the usermanual and not the release notes.\nI strongly disagree. To me, the release notes' main audience is existing dt users (please correct me if this is not the case), which should already have read the manual (if not, you're not going to convince them by publishing cryptic release notes IMHO). For an example of release notes without cryptic message, see e.g. https://about.gitlab.com/2016/08/22/gitlab-8-11-released/. Is is really that bad for readers?\nTo them, a sentence like \"Add undo/redo support for the darkroom\" brings essentially no information. They don't get a hint about where to get further information (are you expecting them to re-read the complete manual to find out?), nor any on how to use the feature. For example, @TurboGit posted an announce on darktable-fr about his feature, and one day later the question \"what is it, how do I access it?\" was asked. The same question will rather obviously arise if the release notes get posted without any details. With my patch, the reader gets the basic info: what is it, why should I be happy about it, and how do I use it (shortcuts).\nNow, let me ask: what is the added value of not having these explanations in the release notes.\n. > I agree that we should have a nice overview of new features with explanations.\nFYI, I wrote such detailed text for previous releases on linuxfr.org: http://linuxfr.org/news/darktable-2-0-traitement-et-gestion-de-photographies and http://linuxfr.org/news/darktable-1-6-traitement-de-photos-developpement-d-images-raw. Understanding the release notes was not easy and this year I thought I'd try to tackle the problem upstream by making the release notes easier to understand, to make my task easier if I get time to write an article in french, and also make it easier for other people to write articles in other languages.\nI thought the short and sometimes cryptic release notes were this way because no one took time to make them better, hence I stepped in to try to help. I did not know it was deliberate, and I still disagree with it. If you agree that a nice overview is good, you're not helping to achieve the goal by refusing improvements to release notes.\n\nBut those don't belong in a changelog going with the release.\n\nI never got the concept of \"changelog\". You use Git, you already have the detailed changelog without having to write a text for this. You use redmine and you already have the list of bugs closed during a timeframe. The internal documentation of \"what changed\" is already there, you don't need RELEASE_NOTES for that.\nThe text for which I sent a patch is the one which is posted on the users mailing-list, and in the news section of the main website after the release and pre-releases. Typically places where final users expect to get explanations about new features IMHO.\nActually, you didn't answer my question: what is the downside of having the explanations I propose in the text?\n. > The changelog also gets added to packages, for example in /usr/share/doc/darktable/changelog.gz on Debian\nWell, first:\n$ cat /etc/debian_version \n8.5\n$ zcat /usr/share/doc/darktable/changelog.gz\nsee webpage: http://www.darktable.org/\nAnd honestly, I'm happy with that, I just never use these files.\nThen, assuming you actually have RELEASE_NOTES as /usr/share/doc/darktable/changelog.gz (which probably does happen on some packages), I still have the same question I already asked many times: what is the downside of having understandable explanations there? Maybe it's time to answer that question ...\n\nIf you want to do that: great!\n\nYour proposal is to duplicate the effort by witting twice the same text. Then, thanks for the proposal, but no thanks, I'm not going to do that.\n. OK, I applied the requested changes and rebased onto master. Should be all right now.. The original text is not strictly speaking incorrect, but in all other cases I can think of where the documentation documents two modes, going from one mode to the other, well, does go from one mode to the other ;-). Here, the doc for default doesn't say \"control circles are hidden, but the effect is whatever the circles were when they were displayed\", but \"Linear from the center to the radius.\". So reading this, I'd expect the effect to be \"Linear from the center to the radius\" whenever I leave the feathered mode.\nI submitted this and bug #11417 because I spent quite some time understanding what the expected behavior was, so while the additional note may seem useless to someone who knows liquify, it would have saved me quite some time. If you listen carfully to carafife's tuto, he probably made the same mistake as me (\"un clic dans le point me fait revenir au mode initial\").. Just a ping: I gave my arguments, if you're convinced then please merge. If not, feel free to close the issue, I can live without this change ;-).. #1420 is merged, so I did the CSS thing in #1443.\nI really like the new transparency. Testing this, I just have one minor issue: it's hard to tell whether the opacity is 100% (because in this case the cursor's opacity is 50%). In particular, when scrolling from fully transparent to 100% opacity, one doesn't get a visual feedback when 100% is reached.\nI'm wondering what can be done about it. One idea would be to return to the old transparency while the shift key is pressed. This way, one could position the cursor with the new \"50% transparency\", and when pressing the shift key to set the opacity of the brush, the visual feedback on opacity would become more apparent (and at this time, seeing through the cursor is probably less important).\nJust some thoughts, in any case I prefer the new behavior to the previous.. Do we need a GHashTable? We know statically which color will be loaded so a simple struct would be enough, no?\n(It's a real question, you obviously know dt's design much better than me!). OK, I pushed a new version which should be better. Actually, there was already a similar mechanism for bgcolor in gtk.c, my code now hooks at the same place.\nI didn't add a CSS key for DT_GUI_COLOR_BG because I don't understand where the color is supposed to appear, so I'm not sure it would be useful and what name would be appropriate. If needed, a CSS key can be added straightforwardly later.. Done, and indeed the patch looks much nicer now. I just removed the _rgb suffix from your dt_gui_gtk_set_source_rgb name suggestion.. About the name: the rgb part in cairo_set_source_rgb refers to the fact that the color is given as r, g and b, as opposed to cairo_set_source_rgba. Here we don't provide the values as r, g and b, but as an instance of an enum. The fact that rgb is used internally is an implementation detail, there's no need to expose it to the user.. > What about using native styling abilities, like with #iop-plugin-ui?\niop-plugin-ui is drawn in Gtk so the code lets Gtk do the styling. For background colors, the existing code draws them using Cairo. I don't think there's a way to let Cairo do the styling from CSS.\nI don't know if there's a good reason to use Cairo over Gtk here, but switching to Gtk would imply a rather intrusive change in the code, so my patch just went the simpler way: get the colors from Gtk and feed them to Cairo.. I still consider the fact that we use cairo_set_source_rgb internally as an implementation detail, we could very well use another cairo_set_source* function internally. The caller doesn't need to know which function is used internally to use dt_gui_gtk_set_source. I don't think the function name should reflect this implementation detail.. Since the argument is precisely not RGB, I don't really get the argument (I would consider that as a counter-argument actually, I find it really misleading to have a _rgb suffix for a function that doesn't take RGB colors). But I seem to be the only one to think like that, so let's re-add this _rgb suffix.. It was probably not clear from my previous message, but I pushed a version that should address all your comments. I think it's ready for merging. If not, let me know if I can do something.\nThanks,. > \"biais\", is that a word? maybe \"bias\"?\nIndeed, French spelling leaked to English, sorry. Fixed.. @hanatos : your feedback is particularly welcome as you created the original feature (thanks for that, BTW ;-) ).. OK, I've now polished the code a bit more and tested all cases I could think of. I dropped the \"work in progress\" tag from the title.. > in any case the opencl code path would need fixing before merging :)\nI don't think it does: the opencl code path computes the exposure increment on the host, and it's already dealt with here. Actually, I did the testing with OpenCL enabled.\nI may have missed something, though.\n\ni thought it was about merging priorities[...]. did you play around with that thing, too?\n\nNo, I didn't. It may be interesting too, but is probably orthogonal to what my patch does.. To illustrate better what flow the new slider allows, here's an example. Initial picture:\n\nActivating exposure fusion yields something interesting, but tends to overexpose the clouds, even though they are already part of highlights:\n\nI can adjust the bias to have the cloud's lightness match roughly before and after:\n\nNow, I can change the \"exposure shift\" slider to change the strength of the effect while keeping the cloud's lightness roughly constant:\n\n\nEven changing the number of exposures works:\n\nOf course, I could also expose for the trees before, and find the bias that keeps the trees unmodified (around -0.75 on this picture), and then play with exposure shift and number of exposures to find the best settings for the sky.\n. Perfect, thanks.\nBTW, talking about OpenCL, there's still a TODO in the code: // TODO: implement opencl version:. Is it still relevant or shall we remove it?. As long as we have a transparent trace, it's already an improvement. In any case, CSS customizeability is a good first step, we can add more transparency later if needed.. FWIW, I do use keyboard accels for modules (not many of them, but I have \u00ab\u00a0e\u00a0\u00bb for exposure and \u00ab\u00a0c\u00a0\u00bb for \u00ab\u00a0crop and rotate\u00a0\u00bb), and find them very handy. I don't care much about the behavior in the case of multiple instances: the point of the accels for me is just to get to the module quickly which works when I don't have multiple instances, and even if it selects the wrong one with multiple instances it selects the right tab and shows me a place close to the one I'm looking for in the middle of modules.\nI did experience crashes when using them though.. @hanatos: just a ping ... it should be rather straightforward and fixes a real issue.\nThanks,. In case you've missed it, @edgardoh, there's an issue with the cross showing the source of the clone in case of rotated image (orientation = portrait or crop and rotate): https://redmine.darktable.org/issues/12424. Other shapes are properly rotated.. This seems to work only for modules between the input and output color profile modules, see https://redmine.darktable.org/issues/12429\nCc: @rabauke, in case you're not subscribed to the bugtracker.. > I think it's the same in the color balance and in the profile_gamma. That's new.\nIndeed, and this probably explains why I had difficulty understanding the behavior of these buttons ;-). Re-testing and now it seems \"optimize luma\" turns most of my images into plain white unconditionally.\nSee my message on darktable.fr: I think these buttons should actually be actual color pickers too. If we go this way, this solves all UI problems at once.. > Having a color-picker for that is redundant with the separate color pickers and defeats the purpose of an all-in-one quick optimizer.\nIt's not: the color-picker would chose the whole image and be OK by default. There would be no need (but a possibility) to actually chose an area of the picture. It'd also be a 1-click setting.\nActually, currently it's already a 2-clicks settings since you get \"wait for the preview to be updated\" on first click.. > I really don't understand what's going on with the dt_dev_reprocess_all(self->dev). Is that an asynchronous function ?\nIn my understanding it is, but I still don't get all the logic behind the API (and I didn't really find much documentation :-().\n\nWhy aren't we able to force it to execute and finish before grabbing the picker's reading ?\n\nIn any case, it wouldn't be a good thing if you could. It's a bad idea to do anything non-trivial in a callback synchronously in a GUI: it would freeze the GUI.\nHere, what you'd want before doing the auto-tuning is not to re-launch the whole pipeline anyway: best would be to launch the part of the pipeline before the module, then get the result of the colorpicker on the input image, do the autotuning, and finally let the rest of the pipeline execute. I think (but may be wrong) this is what happens when using the colorpicker normally.\nWhat I tried yesterday was to let the button's callback just register the colorpicker, and catch the flow later in a callback. I tried putting the rest of the code in process but it depends on the pipeline used (SSE Vs normal Vs OpenCL). It should work if you duplicate the call in all the process variants. If we switch to a real colorpicker this won't be needed anyway.. I guess this comment was meant for #1818, I'll continue the discussion there.. > What code did you put there ? process() functions should not contain any GUI stuff nor parameters settings. process can be called from darktable-cli with no graphic environnement, and it's not good to set parameters in there. If you need to compute intermediate parameters, that should be done in commit_params().\nI'm not 100% satisfied with these calls in process() functions, but the part accessing the GUI is protected by if (g && ...) so it's tolerant to having no GUI.\n\"Just before starting the processing\" is really when you want the picker-related code to be executed, otherwise you need to run the pixelpipe twice (once to get the color, and once to apply the autotune). I was hoping for a picker-specific callback right before process() (which would be the right solution IMHO), but didn't find one.. #1819 is essentially my first commit here. It doesn't introduce the calls in process(), but it doesn't solve the problem my second commit is trying to solve:\n\n\nThe first click on the picker does not apply the optimization. You need to either re-click on the picker or start drawing. This is especially problematic for the \"auto-tune\" picker where the goal is really to save click and behave correctly at the first click.\n\n\nWhile dragging the mouse to select an area, the optimization is done only while releasing the mouse. I can leave with that, but it's inconsistent with exposure.\n\n\nI'll try catching the \"draw\" signal. Unless I missed something this is at least conceptually wrong (although exposure is a proof that it can work): it's called when the widget is redrawn, we want to call it when the pixelpipe reaches the module. But at least, being consistent with exposure means we can refactor all modules the same way if we ever find a better way.. After experimenting a bit, it seems that:\n\n\nThe draw signal is received right before the module is applied in the pipeline. This is good for us.\n\n\nIt's also received in many other places. It shouldn't be much of an issue for us, since the autotuning is relatively fast. At worse, we can protect it with \"if nothing changed, don't re-optimize\" or so.\n\n\nIt seems to be called both for the preview pipeline and for the full pipeline. Shouldn't be much of an issue either, but there might be cases where we run either for the preview or the full pipeline depending on which one runs fastest.. I just force-pushed a version that should be OK:\n\n\nNo more calls in process() functions.\n\n\nPicker applied ASAP, i.e. when pushing the button and as the picking area changes\n\n\nCode simpler than before (57 insertions(+), 82 deletions(-), and I added several comments :-) ).\n\n\nI'm still not happy with putting the code in the draw signal, it's called far too often and doesn't match what we want conceptually, but it's only called too often, and my code protects against useless calls (setting picked_color_max to -INFINITY), so it's OK.\nDetails in the commit messages.. > There is a GUI issue on my side. Click on one picker, click again on the same picker. It says with an active state.\nI can't reproduce. I tried:\n\n\n\"double click\", i.e. re-click before the effect is applied.\n\n\nclick, wait, click, i.e. re-click after the image is fully recomputed.\n\n\nBoth work for me. Can you give more details on what you did so that I can see what's going on? When you say \"active\", do you mean the picker is active (drag on image draws the rectangle) or just the icon is still white?. > BTW, isn't the callback just before process() the routine commit_params()? Would it work better to use this instead of draw()?\nIs there a documentation about all this somewhere?. Experimentally, it seems commit_params is called right before the module, but doesn't have the picked_color_*. I guess the colorpicker comes right after that.. I sill can't reproduce, but I guess I found the issue (a call to dt_control_queue_redraw before set_colorpick_state). Just force-pushed a fix. Can you test again?. Hmm, I guess I can't do more without being able to reproduce locally :-(.\nIn principle, the second click should execute\ndisable_colorpick(self);\n  }\n  set_colorpick_state(g, g->which_colorpicker);\n  dt_control_queue_redraw();\n(at the end of color_picker_callback)\nCan you check that the code actually goes this way (GDB or printf)?\nI really don't see what could go wrong in this piece of code .... Cool, thanks.. > Yet I think we should have a better support for colorpicker and code sharing for all modules.\nI fully agree. It's less painful now that there's less code to deal with it, but it should still be better factored.\nI won't have much time for this in the next few days, but we should:\n\n\nBefore the release, port this PR to profile_gamma and colorbalance\n\n\nFactor the common parts in libs/colorpicker. The \"auto tune\" button in profile_gamma.c, and \"optimize luma\" / \"neutralize colors\" in color balance are still broken the same way as the old \"auto tune\" in filmic. Using the color picker API there like filmic should solve this.\n\n\nChanging mode in color balance should probably deactivate the picker. Currently, you can activate the fulcrum picker, change mode to lift/gamma/gain where the picker disappears, and still have the picker activated (i.e. dragging within the picture grabs a color, and it seems to do weird things then). Same for the \"color control slider\" dropdown.\nOther pickers (exposure, levels, perhaps clut and white balance) could benefit from this, but this may wait until after the release (no need to risk breaking them now if they are not broken ...).\nTHANKS!\n@aurelienpierre : just a ping in case you didn't see this discussion (a bit hidden in a closed PR ...).. Hmm, I was using the darktable binary within the build tree (now that it's possible), but apparently I was getting half of the new version (eg. the Git commit id in the version string was the new one), but half of the old version (i.e. not all your changes).. auto-tune levels appears in \"unbreak input profile\" when the mode is \"gamma\". I think it should appear only in log mode.. clicking on the \"reset\" button in \"color balance\" doesn't disable the color picker icon if the selected icon is one of the \"autotune\" pickers. Weird.. You changed the text from \"neutralize colors\" to \"optimize color\". I think the old text was better, it's not really optimizing, but neutralizing.\nActually, in color balance, I think the optimizers are a bit more complex: they were using previously selected areas using the 3 pickers. So it was probably to keep them as normal buttons. No time to investigate more, sorry.. > clicking on the \"reset\" button in \"color balance\" doesn't disable the color picker icon if the selected icon is one of the \"autotune\" pickers. Weird.\nSame in profile_gamma, but not in filmic. I don't understand why.. > For the colorpicker in color balance I think I have kept the previous behavior (using the selected region if any).\nOK, the behavior is actually more complex than I thought. If 3 patches have been selected, it takes them, but otherwise it guesses from the whole image. Not sure it's really a good idea from the UI point of view, it's really hard to understand how the buttons work without looking at the code :-(.\nThis can be improved in several ways IMHO. Not all ideas are good, just thinking aloud:\n\n\nIf only 1 or 2 of the 3 patches have been selected, then the callback could use the ones selected and do the whole-image guessing only for the missing one.\n\n\nIf the 3 patches have been selected, then no need to activate the picker: the optimizer could run right away when clicking the button.\n\n\nCurrently, the first call to the callback disables the picker callback but keeps the picker active. I think the line self->request_color_pick = DT_REQUEST_COLORPICK_OFF; in apply_autoluma should either be removed or replaced with dt_iop_color_picker_reset.\n\n\nHaving the button be shaped like pickers when the user is more or less supposed to have picked the colors elsewhere before is confusing. I'd suggest using the picker API but not the picker button. If apply_autoluma disables the picker, it'll be transparent for the user that it's a picker (except for the fact that it'll draw the picker's rectangle temporarily).\n\n\n. Actually, on overall it seems the pickers in colorbalance are broken now. I already faced this before the last commits, but very often I use the pickers and get a full white image. . > So, the button triggers a full-picture guess when user lazy, and gets whatever the user feeds it otherwise.\nThe problem is that there's no feedback on what is done: there's no indication about which patch have already been selected, and no indication whether it's a full-picture guess or a 3-patches optimization. \nPerhaps just a dt_control_log(_(\"no patch selected, doing a full-picture guess.\")); (or \"not enough patches selected\") in the case of auto-guessing would help already. Ideally there would also be a visual indication on which patch have already been selected, but it'd be a much more involved change.. Good idea.. If you have time, go with it. I'm spending too much time on dt and not enough on other urgent stuff these days :-(.. It's getting better and better. I think it'd be better if the optimize/neutralize buttons were not color pickers (i.e. the new behavior with the old buttons), but I can leave with both.. I'm getting weird results with the saturation slider on highly saturated dark red. Just the saturation slider changes between the images. Surprisingly, the problematic one is the one with saturation = 100%.\n\n\nI'm still getting the artefact if I turn the image into black-and-white after filmic in the pipe (so it doesn't seem to be an out-of-display-gamut issue). It doesn't disapear when I activate gamut cliping in the input color profile.\nI can share the raw privately if needed.. The artefact I get are with the default parameters. Just one click to activate the filmic module and the artefacts are there :-(. I can reproduce on an RAW image with only filmic activated (no other module).\nIt seems to happen quite materialistically on saturated reds (even not-so-saturated, I get it on a child's lips).\nI don't understand why this is expected: desaturation shouldn't affect the luma, right?. I don't get the ugly artefacts anymore, but the \"saturation\" scale is surprising: the \"saturation\" slider does almost nothing between 10% and 100% (on the image I sent you privately, the effect starts being really visible at 1% only), and really gets a non-trivial effect only on the first percents. Not necessarily a problem, but as a user it's surprising. Perhaps you get something more useful in the range 10%-100% with a wide gamut display though.. The maths are probably right, but perhaps the UI can be improved by having a non-linear slider (e.g. apply x^2 or so to the saturation parameter between the UI and the maths) so that the whole range is useful.\nI haven't tested on enough pictures (and actually didn't do real-life tests where the goal was actually to get a nice image), so I can't say whether this is really a good idea yet.. Force-pushed a version that does security -> safety too.\nYou may want to omit the last commit (renaming of variables in the code) if you're afraid of conflicts, but I think it's better to be consistent between variable names and UI in the long run.. I'll rebase.. Rebased on origin/master.. About the \"after/before color in/out\", dithering should be after color out (it essentially does a clever rounding of float values to integers, so it must come after anything that change the float values). I can't think of any other module that really should be after color out.. I don't understand what you mean and I didn't manage to reproduce.\nSince warp is properly initialized before the first mouse action, it seems more consistent to me to reuse the existing values than to re-read from the configuration. So, more or less by construction, the radius *= factor; line does the right thing.\nIf there's a good reason to do otherwise, the patch should be along the lines of\n```\n--- a/src/iop/liquify.c\n+++ b/src/iop/liquify.c\n@@ -3314,8 +3314,14 @@ static void btn_make_radio_callback (GtkToggleButton btn, dt_iop_module_t modu\n   //  start with current saved size/strength\n\n\nconst float radius =\ndt_conf_key_exists(CONF_RADIUS) ? dt_conf_get_float(CONF_RADIUS) : GET_UI_WIDTH (DEFAULT_RADIUS);\nconst float radius;\nif (dt_conf_key_exists(CONF_RADIUS)) {\nradius = dt_conf_get_float(CONF_RADIUS);\n} else {\nradius = GET_UI_WIDTH(DEFAULT_RADIUS);\ndt_conf_set_float(CONF_RADIUS, radius);\n}\n+\n       const float r =\n         dt_conf_key_exists(CONF_STRENGTH) ? dt_conf_get_float(CONF_STRENGTH) : GET_UI_WIDTH (DEFAULT_STRENGTH);\n       const float phi =\n```\n\n(probably same for r and phi). Should be OK now.. Tested and approved.. I'm not getting the weird behavior I had anymore with this PR. I'm not sure adding the control points is a good idea as @upegelow noticed (no strong opinion on that).. I like the idea of showing the points with a different graphical representation. Cross marks or filled circles both look good to me.\nIf possible, a tooltip when hovering the curve with the mouse saying e.g. \"transformation applied to the image, use the cursors below to edit\" would be cool too. I don't think we need much to convince the user that this curve shouldn't be edited, but I can imagine the frustration of a user trying to edit the curve and trying to understand where the \"bug\" comes from.. I can't get dt to segfault anymore with this PR (i tested with the setup that caused the crash previously, i.e. my old library.db file).\nIdeally, we should be able to delete any duplicate, even the first one, until there's only one duplicate left. If one has two versions of the same image, one may want to remove the first version and keep only the second. In the short term I think your PR is good (better a lack of feature than a crash ...), though.\nI'm wondering whether it would be better to just remove the button instead of disabling it.\nAFAICT, there is now no way to delete the image file from disk from the duplicate module, which is a good thing. But the confirmation message should be reworded from \"send X selected images to trash\" to \"remove X selected images from the library\" (cf. the difference between \"trash\" and \"remove\" buttons in lighttable). After the release because we're in string freeze obviously.. I like the idea better, but now I'm getting the segfault again :-(. It's not just \"deleting a duplicate when there's only one available\" but really deleting the first one which triggers it.. Hmm, obviously, Heisenbug effect, I can't reproduce under gdb anymore :-(.. I just attached a new backtrace. I have a gdb open on the crash if needed.\n. It crashes in rawprepare, so I'm assuming that dt triggers the pipeline on the just deleted image, but that's just a guess.. It seems to make the situation better. I can still get a crash, but not in normal conditions: create many (5 or 10) clones, and delete them very quickly (i.e. delete one clone while others are still recomputing).\nI'm fine with merging this PR and stopping here. In a perfect world, even brute-forcing the deletions shouldn't lead to a crash, but .... Thanks. I'll open a new bug if I get the crashes again in real-life, but hopefully I won't.. Looks good to me. Note that it doesn't apply to lightroom modules (like \"export selected\"). It doesn't matter much because these modules don't have the \"multiple instances\" thing like darkroom, but since the button has the same shape it may make sense to have exactly the same behavior hence allow middle-click.. Tested on a handful of images, works well for me and does fix https://redmine.darktable.org/issues/12456#change-36418.\nThanks!. > I plan to merge in 2.6.1, ok for you?\nYes. It should be harmless change, but better resist the temptation to merge it before 2.6, just in case.. I've pushed a few more commits & rebased. All of them can wait for 2.6.1. The last 3 commits are not directly CSS-related, let me know if you prefer a separate PR.. Thanks for the fix. Looks good to me. . > red frame was intended, because different css were needed because of gtk update\nMaybe it was intended, but I don't remember ever seeing a user happy about it, while I do remember a lot of users complaining about it (some even thinking it was the intended new style of darktable !).\nI don't think you can expect any user to infer from flashy colors what they have to do to their CSS to fix the issue.. What is the \"intended feature\" you're talking about?\nWhat I'm doing here is to keep backward compatibility as much as possible. I didn't find a way to be fully backward compatible with dropdown menus, but I'm pretty sure it's possible too. Backward-compatibility is an important feature for many users.. My point about the red frames was just that it disturbed many users. At that time there seemed to be no way to keep compatibility. In our case, there is, and this is what my PR does.\nI still don't see any intended feature removed by my PR.. > And if we are talking about better backwards compatibility with user styles, I think it should be allowed for user to change in user config just the colors he wants, not copy the whole darktable.css. That should fix the use-case you have in mind,\nIt has always been possible by using @import. The point is: some users did copy their whole darktable.css. Maybe they were wrong to do that, but still, they did. I'm not talking about a hypothetical case, I've written this PR following a bunch of questions on darktable.fr's forum.. +1 for consistency. It does not necessarily prevent another complementary mechanism, but having the same behavior as retouch would be a good starting point IMHO. . > For the exif on the histogram why not display it only when mouse is over?\nThat would feel weird to me: it would sort of imply a relationship between the histogram and the exif data (\"I'm showing you this data because you have your mouse on the histogram, I guess this is when you need it\") which isn't true.\nI like having exposure+iso+aperture big enough (= not hidden within the ton of details of the left panel) when I'm processing/choosing multiple similar images taken with different settings. I don't care much that it's in the histogram, but the histogram is a place where having a big font doesn't harm: it doesn't really take any space in the screen. But the point of having it with big font is to have the data without effort, so if I needed to move the mouse to get it, that would defeat most of the purpose.\nI could certainly live without this text, though.. I only had a cursory look at the code and discussion, but if I understand correctly what the patch does is that it runs the whole pipeline, including conversion to display space, and then convert back to another space for picker and histogram. If so, this can be problematic in several ways:\n\n\nIf modules appear after the output profile application, then the histogram and picker are still wrong (probably less \"wrong\" than using the display profile as is the case currently).\n\n\nIf colors are out of the display profile's gamut, then they are clipped before being converted back to the picker&histogram profile, and therefore the end result can be wrong.\n\n\nThe \"clean\" approach would be to catch the image before the display profile, and then run it through the end of the pipeline using the picker&histogram profile. Obviously, the implementation of this would be much trickier.\nMy feeling is that this PR is a good step forward from the UI point of view (get the picker and histogram to be reasonably independent of the display is better than having them completely dependent of it), but I'm just wondering whether it's not a step backward from the internal architecture's point of view (i.e. if we get to the point where the clean approach can be implemented with reasonable effort, will the code from this PR make it harder?).\nAnyway, again: I only had a cursory look, I may have missed the obvious and/or be completely wrong ;-).. If we officially drop support for 32 bits (which is probably a good thing, anyway it dt seems heavily broken there, and clearly untested by developers), then the runtime check and warning should probably be dropped too:\nhttps://github.com/darktable-org/darktable/blob/master/src/views/view.c#L257-L290\nIdeally, there would be a compile-time check to prevent building for 32 bits platform.. I haven't tried a 32bits build myself since before the support was semi-dropped, but most feedback about 32bits I got was along the lines of \"there was a stupid warning which I ignored, and then nothing worked, I don't understand why\" ;-). And since no dev is testing on 32 bits, the situation can only get worse and worse.\nPerhaps the best trade-off would be to prevent the build, but to provide an override like\ncmake -DI_ACKNOWLEDGE_32_BITS_DT_IS_BROKEN=true\n\nor so for people who like to suffer.. > I see no reason to declare the inline functions as static.\ninline is only a compiler hint, but there's no guarantee that the inlining will occur. Defining a function in a .h file without static is invalid (link may fail with duplicate symbol error) as soon as the .h file is included from several compilation units. Actually, the cases where you want inline without static are very rare.. Not a native speaker, and I may well have added a french touch, but looking at a dictionary it seems \"successive\" is the right word here (for \"Coming one after the other in a series\"), while subsequent applies to one modification coming after another, not the set of modification. Perhaps \"consecutive\" is more common (synonym for successive)?\n. Fixed.\n. OK. While I'm there, maybe replace to with : to gain a few characters and for consistency with most other strings. That'd give:\n\"ctrl-click: add node, right click: remove path\\n\"\n\"ctrl-alt-click: toggle line/curve\". I followed the same pattern as elsewhere in the same file: name the callback after the name of the widget. Best is probably to rename both widgets and callbacks: I've just done that it 0885e55. Indeed I like the code better after than before: the same naming convention is used for internal data and for widgets now.. You understand correctly, yes.\nTo explain a bit further my motivation: my flow without my patch often looks like:\n1) Oh, the overall contrast is too strong, let's use exposure fusion. Adjust exposure and enable fusion. More often than not, I get incorrect overall lightness at this point:\n2) Adjust exposure in exposure module\n3) Hmm, the exposure is right but the global contrast is not\n4) Change the exposure shift in basecurve.\n5) Global contrast seems OK, but now the exposure is wrong: goto 2)\nAfter the patch, this is simplified in two ways: first, all steps can be done with the same module, but more importantly I find the bias setting which doesn't change the overall lightness (typically close to 0), and then play with the shift slider to see how much I want to compress global contrast. The important point is that the final setting is done with just one slider, so it's much easier to find the right point: change, see if it's better. With two sliders, I didn't have this immediate before/after comparison, I had to ply with history stack.\nWith bias=-1, you can also use the opposite flow of the one you suggest: expose for shadows, and then adjust the highlights using exposure fusion. Depending on the image and the expected effect, it can also make sense.. To me, it doesn't sound better. I don't understand what \"auto tune source\" was supposed to mean actually. I guess \"source\" means the source image, and the source image isn't autotuned. The parameters are.\nPerhaps \"auto tune grey/black/white\", to make it explicit that the 3 parameters are considered together?. I like auto tune levels indeed. Shorter than my \"auto tune grey/black/white\" but means essentially the same thing.. It is on purpose that you removed this <emphasis>shift+ctrl+scroll</emphasis>?. Likewise: did you remove this on purpose?. In practice it does work at least for me, but why not be more strict. We'll need to update the similar code right above too (I'm guilty for it too). Actually, I think it's time to introduce a helper function to make this a one-liner. Will do later.. Done.. suggestion\n          affect extreme luminances. It is usually better to keep it as large as possible, and adjust the contrast to avoid clipping.\n?. It's not 255, it's 255. ;-). I had an explicit cast (float)0x99 / 255. in a first version of the patch and I found it overkill. We can re-add it if you prefer.\nIt's just the color #999999 from the CSS converted to float in [0,1].. Done.. See CONTRIBUTING.md at the root of the repo. . Nitpick: no space before ! in english.. From the commit message, it seems you are confusing -Wno-strict-aliasing and -fno-strict-aliasing. The first silents warnings about strict aliasing, but the second allows the compiler to use strict aliasing rules for optimizations (https://gcc.gnu.org/onlinedocs/gcc-4.9.2/gcc/Optimize-Options.html).\nRemoving this option does not just activate warnings, it also enables potentially dangerous optimizations. Eliminating the warnings does not guarantee that other optimizations are safe. To me, the potential danger of activating strict aliasing is too high compared to the potential performance benefit (which is probably negligible actually, but without numbers this is pure speculation on my part). . The warnings have been fixed, but how can you be sure that all the issues have been fixed? Warnings are not meant to be exhaustive (the doc actually says explicitly \"The warning does not catch all cases\", https://gcc.gnu.org/onlinedocs/gcc-4.9.2/gcc/Warning-Options.html#Warning-Options). If the compiler could warn about all dangerous cases, it would mean that it would be able to do exact alias analysis, and there would be no point using the strict aliasing rule.. ",
    "piorekf": "What is blocking this? I would really love to see support for this camera in the next release.\n. Great to hear that. I'll try to build developer version then.\n. ",
    "nsrosenqvist": "+1, I use network based file storage as well\n. ",
    "digint": "@pmjdebruijn: As Panasonic reports different sensor size for different aspect ratios, I thought it was more comprehensible with the \"positive\" notation. You might have other considerations to take into account, so if you really wish I will change it to \"negative\" later tonight.\nEXIF (4:3):\nSensor Width                    : 4816\nSensor Height                   : 3464\nEXIF (3:2):\nSensor Width                    : 4816\nSensor Height                   : 3080\n. The file can be downloaded from here:\nhttp://dev.tty0.ch/dt-noiseprofile-20150425.tar.gz\n. ",
    "sebix": "To bring the discussion of the naming ISO 216, DIN 476, A4 up again: I would omit the 4. The ratio is the same for all A0 up to A10, it's not specific to A4.\nAlso, what about adding the ratio itself? ISO 216, DIN 476, A, \u221a2:1\nFor the golden mean, giving the ratio itself is not so easy.\n- cinemascope \u2192 cinemascope, 2.35:1\n- ISO 216, DIN 476, A4 \u2192 ISO 216, DIN 476, A, \u221a2:1\n- widescreen \u2192 widescreen, 1.85:1\n- anamorphic \u2192 anamorphic, 2.39:1\nI can't give a statement on the code changes.\n. ",
    "markfeit": "There are 11 each of DIN/ISO  A, B and C sizes, all based on different dimensions for the \"0\" size but having the same ratio.  I stuck A4 in there because it's familiar to the rest of the world as \"Letter\" is to Americans.  (Being American, I don't have a horse in this race other than getting this patch in.)  Anything that makes the entry easily recognizable to most people without cluttering it up is fine by me.\nThe change I made to the code calculates the aspect ratio as x:1 and appends the result formatted to two decimal places to every entry (see screenshot from older revision below).  This makes all of the entries uniform and prevents anyone adding to ratios in the code (which, honestly, should really be in a file distributed with DT instead of hardwired) or in their own personal list from having to calculate and format it.\n\nThe code works; I've been using it since before I submitted the patch.\n. Relevance is in the eye of beholder, and even that's getting blurry.  I have no clue why the \"10:8 in print\" ratio is there (much less why it's 1.2:1), but I also do a lot of crops at the CinemaScope and HDTV ratios.  The latter is starting to show up as a standard print and frame size, which makes it jump out of cinema and into photography.\nIdeally, which of the built-in ratios included in the menu would be a configuration item and the user could add custom items directly from the UI and have them stored in the per-user config.  Maybe I'll take that on as my next project.\nIn the mean time, what's a reasonable target number?  The menu stands at 19 including the two we can't get rid of (original and freehand).  I'd have called 20 too many but could be convinced to cut it back to a smaller number.  For my money, 10:8 in print and Golden Cut are easy to throw out the window, and I could be talked into cutting out a couple of the cinematic sizes if HDTV, Widescreen and Anamorphic stay.\n. Meant something a little more user-friendly than that.  At any rate, let's get this one done with.\n. The one remaining problem is src/chart/thinplate.c:\n/darktable/src/chart/thinplate.c\n/build/darktable/src/chart/thinplate.c: In function \u2018thinplate_match\u2019:\n/build/darktable/src/chart/thinplate.c:196:3: warning: ISO C90 forbids variable length array \u2018r\u2019 [-Wvla]\n   double(*r)[wd] = dt_malloc(dim * wd * sizeof(double));\n   ^~~~~~\nThe code in question:\n// XXX do we need these explicitly?                                                                                               \n  // residual = target vector                                                                                                       \n  double(*r)[wd] = dt_malloc(dim * wd * sizeof(double));\n  const double **b = dt_malloc(dim * sizeof(double *));\n  for(int k = 0; k < dim; k++) b[k] = target[k];\n  for(int k = 0; k < dim; k++) memcpy(r[k], b[k], wd * sizeof(double));\nHow was this passing muster before this change?. Format string:  Old habits die hard.  Fixed.  :-)\nCommit squeezing:  The squash and merge option when accepting the PR will take care of that with no rebase freebasing required.\nCasts:  I considered removing casts while I was doing this but elected to keep the number of changes to the code to the minimum required.\nStatic inline:  I'd advise leaving this as-is.  If the compiler elects to emit the function instead of inlining it (which it can, because inline is advisory-only), the symbol will be externally-visible and the linker will choke on the duplicates.  This is also the most-portable way to do it without a lot of preprocessor gymnastics; the only other alternative is extern inline, but its behavior is compiler-dependent.  I surveyed the symbol tables of a half-dozen random object files in the dt build and found the compiler was doing exactly what I expected.  There are a number of other inline functions in the source; addressing how they're dealt with should be a project-wide effort.\n. @LebedevRI  Those updates appear to have originated in darktable-org/rawspeed.  I didn't touch them.\n. ",
    "lemmi": "k, i'm looking into it\n. i won't be able to do this properly in the next few weeks, just close it, i'll open a new PR if i have time.\n. ",
    "tomtor": "One thing is not clear to me, the source DNG contains (exiftool -v output):\n\n| 34) MakerNotePentax (SubDirectory) -->\n | + [MakerNotes directory with 93 entries]\n | | 0)  PentaxVersion = 5 1 0 0\n | | 1)  PentaxModelType = 0\n | | 2)  PreviewImageSize = 640 480\n | | 3)  PreviewImageLength = 28978\n | | 4)  PreviewImageStart = 35758\n | | 5)  PentaxModelID = 77310\n\nbut on writing the jpeg I get this single message on stderr:\n\n[exiv2] Invalid tag name or ifdId PreviewImageSize', ifdId 84\n[export_job] exported to/home/tom/Desktop/darktable_exported/IMGP0752_04.jpg'\n\nThe other PreviewImage* tags are handled silently and the output jpeg is fine.\nEdit: the output is missing normal Exif info now, so this is obviously no right.\nI'll close the request\n. OK, thanks for the pointers, did that. The coeffs are identical to the S-3.\nIn cameras.xml I choose black and white for an ISO 800 PEF. The differences for other ISOs are minimal.\nI changed make from Ricoh to Pentax, as was also done for the K-3? I think this is needed\nfor selecting the default \"Pentax-like\" for base curve.\n. Fixed borders and naming in cameras.xml (similar to existing K-3)\n. Ok, fixed in:\nhttps://github.com/darktable-org/darktable/pull/930\n. Thanks, should be fixed now...\n. Yes, I did. 0.24 is from 02-Dec-2013 and the specific patch is from 8 months ago and has as target 0.25\n. minimal: black/white is 1/15865 for iso 800, 1/15866 (iso 1600),  2/15865 (iso 3200)\n. ",
    "superdachs": "I will collect more Data today and check if the curves even become better (thinking the color curve could be)\n. Don't know what you mean with \"rebase this pull-request\"\n. cool, thank you\n. ",
    "fulldecent": "Have tested, works decent. Recommend to merge.\n. ",
    "tuxflo": "Thanks a lot for the patch keep up the good work! I tested it using the snapshot feature and the difference is amazing. Just a little issue: I was not able to compile the masterbranch at a 32bit environment without a small change (cast a error message value to long int) Should I do a pull request for that here?\n. ",
    "empyrical": "Oh, I missed that. sorry!\n. ",
    "ilyapopov": "I found these during a total grep search of my computer after reading this http://habrahabr.ru/post/262679/ (in russian).\n. Not all the fonts and rendering engines render these letters correctly.\n. This is how my commit looks like on my system (Ubuntu 15.04, Firefox 39, Liberation Mono font)\n\n. Yes, most likely it is a problem in the font in this case. But it is a very common problem, many fonts have poor combining diacritics support. \nThe proposed workaround is trivial, but would make things better for many users. Why then not to do it? \nAnd in any case, every project has to use those consistently. If in every other case the solid letter is used, why use combining ones in these two strings?\n. Indeed, the bug is not seen darktable itself with my setup. But there is no guarantee it does not appear on someone else's setup. \nI just don't get your point. This trivial change makes no harm for anyone, but potentially prevents some problems. \nAnd what about the consistency?\n. And I am interested, how did you produce these combined symbols in the first place (I believe it was you from git blame)?\n. Do you remember a specific text editor used for these edits? (I am asking because in the other strings you used different symbols, maybe that is the editor which makes difference.)\n. ",
    "ValdikSS": "Hi, I'm the author of that article about combined characters.\nLiterally nobody ever used breved version of \u0438 and \u0435 with combined diaeresis on the internet. I never saw this in my life until half a year ago probably when some software updated and this bug has been introduced with the update.\nWhile using combined characters to write a grapheme is a standardized way to write it, not all fonts and font rendering engines shows said graphemes correctly and moreover almost all the software differs combined and non-combined version so you can't search a word if it has breved version of \u0439.\nI'd prefer \"usual\" versions of Cyrillic \u0439 and \u0451.\n. ",
    "drmaniac": "Oh sorry. \nMy mistake. I didn't noticed that i have executed the pull request. \n. ",
    "muggenhor": "I tested this and thought it changed some behaviour in the \"global tonemapping\" module, but I cannot reproduce this anymore. I guess I may have done something different instead.\n. ",
    "gernberg": "Thanks for the info :)\nDo you often have big uncommitted changes to the .po files / is there an easier way to contribute translation fixes than by making a pull-request?\n. ",
    "thatguystone": "I was approaching this more from usability than losing the original curve: with a preset curve (ie Canon EOS like), there are already a few points which exist on the curve, and if I want to edit the curve, I then have to fight with the existing points to get exactly what I want. By allowing multiple curves, I could leave the preset alone and add my own points in a new curve, where I could fine-tune it much easier.\nHonestly, though, after getting more comfortable with editing in Darktable, I would have to agree: I'm not sure this is useful.\n. ",
    "luisgf": "No, the behaviour to limit database access to one instance of darktable is preserved, but the patch is a correction to be more portable. open() is a unix syscall that return a file descriptor, but fopen() is an ANSI C function that simply work with all systems.\n. Yes @McBofh, both functions are part of POSIX but this limit the possibility of a program port to a Non-Posix system, like Windows.\n. ",
    "kwokyinc": "@LebedevRI I don't know why but I couldn't register with the redmine website. I have uploaded the file to dropbox with the link below. Please take a look. Thanks.\nhttps://www.dropbox.com/s/9qr5773eki80h2g/dt-noiseprofile-20150812.tar.gz?dl=0\n. ",
    "bennygui": "@LebedevRI The GTK documentation says that GUI should be on the main thread and when g_file_trash/g_file_delete is called, the code is in another thread. It's easy to call dt_control_log to pop a message when not on the main thread but asking a question is much more complicated. Is there something already in darktable to this kind of thing? Or should I roll my own?\n. I've added a dialog to ask what to do in case of error while deleting or sending a file to trash. Feel free to suggest better names for the buttons.\n. @boucman Just thought of something: if a file does not exist and we try to delete it with this pull request, an error will appear. It might be annoying while deleting a bunch of files. Should an error be displayed in this case or should the code just remove the file silently?\n. @boucman Hope everything is fixed now!\n. @LebedevRI I'm letting you decide what is best... but from the thread, the person who reported this said: \"As a person, who had to click the button 50+ times I would prefer having \nan untranslated string :)\"\nAnyway... It will probably not affect many users.\n. I'm not sure it's worth putting a lot of effort into: this dialog will almost never pop except if you have weird  file permissions or if trashing is disabled on the system or the filesystem.\n. ",
    "beedaddy": "@LebedevRI Does it look better now? :)\n. ",
    "maethor": "As discussed with @LebedevRI on IRC, this PR did fix some huge bugs on my install (preview and histogram disappearing, brush mask not working).\n. This PR fixes https://redmine.darktable.org/issues/9723 and half of http://redmine.darktable.org/issues/10145\n. ",
    "pope": "Built DT with patch and WB presets were present for my camera.\n. I tried to submit to rawsamples.ch. FTP wasn't working, and I haven't heard back from email.\n. @LebedevRI - I have not reported this upstream. Let me do that.\n@parafin - Xcode's clang returns false for __has_builtin(__builtin_cpu_supports). You're probably right about doing this check. I would need to get other versions of clang to try to make sure it's not borked across the board. I also like you're idea of just skipping this check if __i386__ and __x86_64__ and __APPLE__. Which one do you dig the most?\nLastly, I know the modifications in macports.conf are for backwards compatibility. With this setup, the earliest version I was able to compile with was 10.9 (without digging in much more). But I'm not doing releases :). For me, this is nice because I don't need to make the modifications because I use macports for more than just this. I also want to be able to use OpenMP. GCC49 didn't work for me because it wants all of the libraries compiled with libstdc++ and not libc++ (hence the cxx_stdlib settings to make that work). So I don't see this as a replacement, but a complement to the existing build instructions at the cost of supporting fewer OS versions.\n. Just got done testing clang-3.4, clang-3.5, and clang-3.6. All of those return false for __has_builtin(__builtin_cpu_supports). So I'm not sure if we're going to add much by checking for version since none of them support. And we would only want to check the version once it is supported.\nAnd yeah, this is the same problem that https://github.com/darktable-org/darktable/commit/081bc5823870918160fdd93d0157d56263add7d5 tried to solve. It's all donkus.\n. LLVM bug: https://llvm.org/bugs/show_bug.cgi?id=25510\n. I think we have GCC vs clang in that if cond already as we check for __GNUC_PREREQ(4, 8) first, and if that's false we check the __has_builtin (Clang only I believe), excluding FreeBSD and Apple from that. Granted, the check for clang is a bit indirect.\nAdded an explicit check and some context around this.\n. My linux box doesn't have clang-3.7 or 3.8. And clang-3.6 doesn't report to support it. Presumably it must work for some systems as it was added!\nLooks like @LebedevRI commited https://github.com/darktable-org/darktable/commit/e237027cfa1879a4629cba459f899441960dd8b8 that added this call.\n. I have just confirmed that this works on Linux. I tested on Ubuntu Trusty with the latest LLVM builds for 3.7. So FreeBSD and OSX do appear to be the ones left behind at this moment.\n. Yup. I'm working on adding a check_c_source_compiles to check that this works. My prototype proves it does, and now I'm just porting it over to DT.\n. Alright, done.\n. ",
    "marek-vanco": "Yes, he is aware. I talked with him. We are waiting to pull request.\nThanks you very much!\n. ",
    "DavidOliver": "Not sure if you want user opinions here, but I much prefer the meta info in one line out of the way of the preview.\nThoughts on the single-line version:\n- The darker background version doesn't quite seem to me to match the darktable look.\n- What about having the three groups which are currently left, centre and right in one left-aligned area, with suitable spacing between them? This would make it easier to read everything without the eyes having to flick right across the entire width. The overlay layout currently has this as an advantage over the strip layout.\n. When you say it's drifting, does this mean its place in the pipe is not set/consistent? (Interested user.)\n. I see. Thanks for explaining!\n. ",
    "berniyh": "Are there still distributions that require cmake 2.6 support? Most I've seen use at least 2.8.\nApart from that. For my distribution (Exherbo Linux), I created the patches solely for Darktable 2.0. So for me, it is ok if everything older stays as is.\n. Sounds reasonable. If I find time I'll add a few commits further pushing the use of GNUInstallDirs.\nIt should simplify things here and there.\n. I updated the branch, the changes are outlined in the specific commits. Basically, I tried to use the directories defined by GNUInstallDirs where applicable.\nI have yet to test this extensively, so please do not merge yet, I just wanted to have some feedback for now if this is going in the right direction.\nI also wasn't sure about whether GNUInstallDirs will work on Apple systems, some feedback here would be appreciated.\nEspecially I wasn't sure about this:\nif(APPLE)\n  set_target_properties(darktable-cli PROPERTIES INSTALL_RPATH @loader_path/../${LIB_INSTALL}/darktable)\nelse(APPLE)\n  set_target_properties(darktable-cli PROPERTIES INSTALL_RPATH ${CMAKE_INSTALL_FULL_LIBDIR}/darktable)\nendif(APPLE)\nWould the (currently) non-APPLE version work on APPLE as well?\nI also had a small chat about the install paths on BSD with someone from FreeBSD.\nAs long as variables can be overridden, it is ok, if no system-specific handling is done in the cmake files, so I'd suggest to remove all of it, unless there is a good reason to handle it there.\nGNUInstallDirs here provides the best way to extensively manipulate the paths wherever necessary and thus seems to be a good solution.\nBTW, do you want to have rebased or continuously merged branches? If the former, I can rebase the branch, but obviously it would break history of local clones.\n. All of the variables have default values. See here:\nhttps://cmake.org/cmake/help/v3.0/module/GNUInstallDirs.html\nThus it should not be necessary to specify more than just the prefix. Unless you want to do some non-standard stuff, of course.\nBasically nothing changed, it's just that the special cases are now handled in a standardized way by cmake.\nI'm still not sure about the situation on osx, though.\n. Ok, seems I was wrong and cmake 2.8 does understand GNUInstallDirs, see:\nhttps://cmake.org/cmake/help/v2.8.12/cmake.html#module:GNUInstallDirs\nRegarding the version: I can understand that Ubuntu LTS uses cmake 2.8.12 and from my point of view, it would be ok to set that as the minimum version. I'll change the tree accordingly.\n2.8.6 as used on Solaris seems pretty stupid to me though. Could set this as the minimum version, but I'd rather tell them to update their stuff.\nIn the end, I don't think that it matters too much here, because if that cmake version is used, I'd suspect that they use older version of libraries as well and the dependency tree will break at some other point where the changes are more significant. Both for Ubuntu as well as Solaris.\n. Would be possible, but it's not necessary, unless somebody comes up with a system that really needs cmake 2.6.\nThe change from cmake 2.8 to 3.0 was more severe than 2.6 to 2.8, so I don't think any distro/system still relies on the latter.\n. Updated the branch (rebased on current master).\nI went for cmake 2.8.5, since that is what introduced GNUInstallDirs, afaics.\n. On 12/01/16 20:54, parafin wrote:\n\nWorks fine on OS X except one line in packaging/macosx/make-app-bundle script\nneeds to be changed:\non line 9 change @loader_path/../lib/darktable to /usr/local/lib/darktable.\nHm, I wouldn't really like the idea of using absolute paths.\n\nIn the end it is obviously your decision, but wouldn't it be a better idea to \nuse cpack to replace such a script.\n\nAlso when changing Gentoo ebuild you must re-create the manifest, but I will\nneed to update that stuff anyway, it's not up to date.\nAgain, it's obviously not my decision, but given that gentoo seem to provide an \nebuild, I don't see the point in keeping that in the repository.\n\nAnyway, I will not make changes to Gentoo (anymore) for the simple reason that \nthey do not respect ownership and rebrand your changes without even asking for \npermission. So you will have to change that yourself when it is appropriate.\n. On 03/02/16 13:57, houz wrote:\n\nWhy did you make the rpath absolute? I expect that to break distribution packages.\nAfter the last comment by parafin, I suspected it might be, so it went onto my \ntodo list to check what rpath actually does and what proper handling would be there.\n\nHowever, so far I didn't get to it, so it's still a todo to fix that.\n. On 03/02/16 23:52, houz wrote:\n\nHint: Just leave the rpath as it was.\nNope. LIB_INSTALL needs to die. But that was not why I hesitated to change it.\n\nInstead, I'm wondering if the rpath thing is necessary at all. It shouldn't \nrequire distributions, because those rely on ld for finding the libs.\nThus, as long as ld can find the libs, everything should be fine.\nApart from that, there is no necessity for rpath to be relative, it's just a \nrecommendation. I am however not convinced, that assuming $libdir (whatever it \nis called) is in the same root as $bindir is a good assumption.\nIt actually sounds like potential breakage because there is always some distro \ndoing things different from everybody else \u2026\nSo that's why I want to have a deeper look at what is going on here to find out \nif there is a better solution.\n. Sorry for the delay, but I had to read up some things about RPATH.\nFirst as noted above: RPATH does not have to be relative, a full path does make sense.\nI myself can only see one reason for using a relative path: a portable install version\n(Which I haven't seen so far for darktable.)\nAs I don't know what the intention for the used RPATH settings were, I'll leave it to the project owners to decide what to do. Maybe there is something I'm not seeing here.\nOther than the above, I would always recommend using absolute paths in such cases.\nIf you agree, I can revert the above commit.\n. Any more comments on this? Can it be merged for the next version?\nShould I rebase it on master?\n. The / at the end wasn't intentional, so yeah I can remove that, no problem.\nI'll rebase it on top of master during the next days and then check back.\n. Sorry this took so long, but I finally came around to rebasing this on current master. Should now merge without conflicts.\nI also had a look for follow-up changes and squashed them into the respective commits.\nCompiles and runs fine for me.\n. @LebedevRI: I think what he meant is that I removed the special APPLE handling in other cases before and didn't do it here, which is because these were added afterwards and I missed it during rebasing.\nAnyway, removed it, should now be inline with the rest of the changes.\n. What I wasn't sure about is the WIN32 handling, there are still some hardcoded paths there, iirc.\nIn principle, GNUInstallDirs could be used there, but didn't really investigate.\nOnce it is in place, you might want to think about that.\n. Ok. I'll do that.\nJust to make sure I understood that right. The idea is to do in the root CMakeLists.txt:\nif(APPLE)\n  set(ORIGIN_DT @loader_path)\nelse(APPLE)\n  set(ORIGIN_DT $ORIGIN)\nendif(APPLE)\nand then replace the appropriate lines in the subdir cmake files with ${ORIGIN_DT}.\n(Going to use a differently named var to avoid confusion. And actually it might be necessary to use $$ORIGIN there, need to test.)\n. Should be good now.\nTested both the $ORIGIN and @loader_path strings and at least on my system they don't need escaping, the executables have the correct rpath stored.\n. Feel free to CC me if some issue comes up. ;)\n. ",
    "lcavalli": "I can confirm that the patch fixes the problem.\n. ",
    "sarunasb": "OK, changed to camera_alias. \n. ",
    "haukepetersen": "Yes, of course... Never seem to think of the obvious :-)\n. done: http://redmine.darktable.org/issues/10749\n. ",
    "wmarquesr": "I'm sorry but the code is note wrong, i verify again. You can recheck ?\nThe idea is always to encompass only complete/entire statements/expressions with preprocessor conditional directives. It is something that is getting popular in many different projects (started mainly on the Linux Kernel).\nWe agree totally that breaking statements with directives influences code quality, i.e., understanding, maintainability and error proneness. We found some evidence based on interviews with developers and an online survey regarding this negative effect on quality.\n- http://www.cs.cmu.edu/~ckaestne/pdf/ecoop15.pdf\nDon't you agree with that ?\n. This is part of a project about directives in C, for in the future to conduct an experiment. But if you do not agree with this kind of convention, it's okay.\n. I'm sorry, the patch really broken the code, but how you don't agree with this kind of convention, i will not submit the correction.\n. ",
    "caioss": "Here it is =)\n. Here are the modifications. I got rid of default_params as suggested by @houz.\n. After reading many e-mails on the mailing list I decided to stop writing code to Darktable. It's a purely personal decision. Sorry for spending your time.\n. Ok\n. That's exactly what the code does. On line 125 a struct with default values (including 0's for luminosity) is assigned to the params variable. The struct is updated with the old values inside the for and then it's copied to new_params. I completely missed self->default_params. I'll use it instead.\n. I think I didn't get it. The values I used are the default for version 1 plus the new option disabled. The same applies to self->default.\n. Now I understand! Soon I will commit all these changes\n. ",
    "ArchangeGabriel": "Just discovered this because of @aurelienpierre message. From my user perspective, I was going to look at adding Canon 760D curve some time next month, because currently it\u2019s really not good (in the sense that the default output is far from the JPEG one \u2014\u202fwhich, to be honest, is quite good in fact), while it wasn\u2019t that bad with my former 650D.\nAnd even if that\u2019s strange, what I expect as a beginner user is in fact that opening the RAW in DT make it looks like the JPEG issued from camera/manufacturer presets by default and then move things around. Especially, I avoid mangling with base curve at all, I\u2019m rather using DT for noise reduction or restoring over- and under-exposed shots. Not to be creative with the basecurve.\nSo, FWIW, I would prefer ability to have per camera basecurves rather than nothing, especially if their use is optional. Of course, the best would be a reworked basecurve process \u00e0 la denoising system.\n. Probably not the right place\u2026 Look here: https://redmine.darktable.org/issues/10868.\nI\u2019m redoing some right now too.\n. I think so, but also that it doesn\u2019t even matters.\n. @LebedevRI Then why have all profiles submitted to GitHub over the past year been merged while some are waiting for input on Redmine for more than one year (e.g. https://redmine.darktable.org/issues/10868)? I don\u2019t blame you, I now what lacking of free time is very well, but PR here definitively get more attention than submission on Redmine. Why not move issues to GitHub?. > How does it help anything? If there is one mouth, it does not matter whether you drink your tea/coffe/water/etc from red cup or from white cup.\nWell to keep the analogy it appears to me you\u2019re drinking coffee from both cups, which might not be as efficient as sticking to one. But that\u2019s your organization after all, and as you pointed out (see below) is not the real source of the issues at hand. So\u2026\n\nI guess the logical answer is right on the surface. As you can see, majority of these noiseprofile PR's from the last year have come from a @schenlap who has demonstrated an ability to validate noiseprofiles, thus once such a pr is up, i pretty much merge it right away.\nI'm not sure what other answer you wanted to hear.\n\nOK, mea culpa, I admit I\u2019ve never look at who was submitting the noise PRs (I mostly just look at email notifications), neither did I ever thought it could be the same person for most of them (I was assuming that those PRs where submitted by independent people using those DSLR). So as a matter of fact you gave a perfect explanation of why someone like me being subscribed to this repo but not to the whole Redmine was having the impression of near instantaneous acceptation of profile submitted here vs Redmine. I was plainly wrong, because I did not look closely enough.\nSo in the end my concern is mostly to see noise profiles being submitted to Redmine and then merged here in only some days (because after looking a bit further that\u2019s how @schenlap PR come from) while some tickets are open for months, without any explanation on them (even just a \u201cSorry, this profile is complicated to validate, and we lack time/people to do this right now, we\u2019ll come back to you later\u201d or \u201cThose files looks strange, could you try a new attempt so that we get files easier to validate\u201d if they actually are such kind of issues).\nThat being said, keep up you\u2019re good work on this amazing software!\u202f:). Small typo here, \u201cbeignet\u201d instead of \u201cbeigned\u201d.. ",
    "rahbek1": "I would like this improvement. \nAll my images are located on a NFS mount. Whenever I try to delete an image I get this message: \"Trashing on system internal mounts is not supported.\"\nI guess that more people will run into this issue since NFS and CIFS was added to the list of system internal filesystems\nhttps://gitlab.gnome.org/dsd/glib/commit/d1eaf72c001279aa15a2135a0749ef864c8edb42\nhttps://gitlab.gnome.org/dsd/glib/commit/0d69462f146071ee4ad1407f9d9ac56f65c9d485\n. ",
    "easdue": "1: It should work on OSX but I can't verify because I don't own a mac\n2: dt_pthread_create() is ok and then maybe mark pthread_create as poison?\n. Just commited the requested changes\n. I now only test if the default stacksize is < 8Mb. I also added a test in dt_init that checks the default stacksize and the OMP_STACKSIZE environment variable. If the default stacksize is < 8Mb and the OMP_STACKSIZE is not set to 8Mb it try to set the variable and if that fails a message is printed to stderr and darktable is exited. \n. I now only test pthread's stacksize against the systems soft stack limit. If pthread's default stacksize is smaller than i set it to the softlimit. This way the stacksize can be altered by the user by ulimit -Ss. Openmp can't be manipulated from within darktable, the user will have to define the OMP_STACKSIZE environment variable before starting darktable if problems occur.\n. Return value of getrlimit handled\n. Ok, here goes:\ngtk+3.18.6\ngdk-pixbuf-2.32.3\nglib-2.46.2\npango-1.38.1\natk-2.18.0\nlibxml2.9.2\nlibsoup-2.52.2\nlibwebp0.4.4\nlensfun-0.3.2.0\ngio-2.46.2\nlibgthread-2.0\nlibgmodule-2.0\nlibpangcairo-1.0\nlibwinpthread-4.0.4\nlibrsvg-2.40.12\nlibsqlite-3.8.4.3\nlibcurl-7.42.0\nlibz-1.2.8\nlibpng-1.6.19\nlibjpeg-turbo-1.3.1\nlibtiff-4.0.3\nliblcms-2.7.2\njson-glib-1.0.4\nexiv2-0.25\nlibiconv-0.0.6\nlibflickcurl-1.26\nlibopenjpeg1-1.5.2\nlibsecret-0.18.3\nGraphicsMagick-1.3.23\nlibSDL-1.2.15\nCUPS is not going to work i guess, will have to come up with something else\nCompiling with gphoto2 added failes with a mysterious error that I haven't been able to figure out yet will come back to that.\n. Check\n. Correct, It's time to call it a day!\n. OMP_STACKSIZE is a bit strange you can define 8Mb as \"8192\" or \"8388608B\" or \"8M\". I chose to define it as 8388608B and that is printed to stderr if the test failes\n. It's a correction for anything but SUNOS\n. Ok, maybe create a config variable? SAFESTACKSIZE is just defined to what ulimit -Ss is on my system (Fedorara 23). I've also seen 2M or 4M while googling! With musl libc's 80K darktable doesn't even start on my system.\n. Ok for omp but this variable does in no way influence libpthread. libpthread is normally influenced by ulimit but musl libc ignores this and has a hard defined 80k stacksize\n. Compiler complaining about stderr on line 2648. Why is stderr there? It's not used in the for loop! If I remove stderr it compiles just fine also on Fedora 23 \n. #include  is POSIX and LSB compliant see http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/fcntl.h.html. If there are developers using non posix compliant systems they should add #ifdef for those systems\n. I'll return to my original idea of using the ulimit softlimit as the default stacksize. If darktable segfaults because that's to low then users can change it by increasing that. The problem with musl is that they have a hardcoded 80K stack size. \n. removed\n. You get yelling from your compiler on this? I'll handle the case but what are sane defaults? On all systems I have its 8Mb!\n. ",
    "rofl0r": "hmm instead of assuming 8 MB to be a safe stacksize, why don't you test if i.e. 256KB works ? setting it explicitly on all platforms to the same value would have the benefit of not wasting tons of RAM that gets never used. usually huge objects get allocated on the heap, so this is no problem and 256KB is plenty (as an anecdote, on sabotage linux there's only one known application that needs more than 80KB stack, and that is dwarf fortress, which works fine with 128KB).\n. ",
    "edgardoh": "The equalizer works very well and does a very good job as a denoiser, but the results are a bit different  depending on the image.\nOf course, as I say already, the code is no good, and maybe is not worth the effort to rework it for a small difference on a particular type of pictures.\nI already have it locally, so I'm going to keep testing it, if I find a considerable difference then I'll come back.\n. You were right, there is no point in this, there are better ways to do it.\nHow do I get in touch the next time? IRC is not an option for me and I have subcribed to darktable-dev+subscribe@lists.darktable.org but haven't received any mails yet, seems that the list is inactive (I have readed that there should be +30 mails/day)\n. I was already subscribed to the users list, receiving mails on a daily basis. The dev list I'm talking about is described here: http://www.darktable.org/contact/#mailinglists as having a lot of movement (is the same list as in the link you provide)\nMaybe is just this time of the year, I'll wait and see, and also try to reach the IRC.\n. This is my first pr and I don't know how things work, so my apologies if everything is not ok.\nI had some build errors when pushing the pr, so I fixed & pushed again, I think that's the closed ones.\nI also thought that with the description on the first one was enough, so I'll try again:\nI have developed a new iop (that can also work as an enhancement), based on the spot removal, the wavelet decompose plug-in from GIMP and the healing from GIMP.\nIt performs a wavelet decompose and for each wavelet scale it allows to clone, heal, blur or fill.\nThe retouch.c is the new iop.\nI have created separate files for the wavelet decompose (dwt.c) and the heal (heal.c) on src/common, and they have the opencl versions too.\nThere is some modification on the base code, some are required and others are nice-to-have:\n-I created a new mask type, DT_MASKS_NON_CLONE (yep, not the best name). The new module uses clone masks (like the spot removal) and regular masks (for the blur and fill). The regular masks are added to the mask manager while the clone masks are not, so this new type is a mix of both, it acts like a regular mask but is not added to the mask manager.\n-the brush can act like a clone mask, this is nice when healing\n-the user can select a shape by clicking on it, this is the best way I can think of in order to allow to change the blur radius and the colour on a shape (and any other parameter that in time may be added)\n-I added a preview when creating a circle (like the brush does)\n-I added a short-cut to allow to skip mouse events on the shapes (or masks). Sometimes there is not too much room left to drag the image or zoom in/out, so it's nice to press a key and be able to drag the image or zoom even if the mouse is over a shape\n-I allow to resize a path even if the mouse in on a segment or a node \n-Some small changes on the default size of the shapes and the increase step, to make it more consistent or because I find it better when retouching. As an example, very often I needed a smaller circle than dt allows right now.\nI have designed it for retouching and with my worflow in mind, but of course all of the above is up for discussion.\n. >\n\nThe first thing to do is to talk to us first, as it was suggested quite\nsome time ago in the first pr\n1090 (comment)\nhttps://github.com/darktable-org/darktable/pull/1090#issuecomment-167540635\nUnless somehow you are not the same gh user as ^ ?\nOK, my second one. I don't count that one as it didn't go too far.\n\nI didn't discussed this one because I didn't know what I was going to get\nand if it will be release material. Now I think it will be a nice addition\nto dt, so here I am.\n. >\n\nI have tried it but I could not make it to work. Maybe some bugs? But most\nof all it does not seems to be obvious to use... Many buttons... At some\npoint during my testing I had lost all visible shape to control the forms\nand did not find a way to get them back. Anyway, first step would be to\nensure that the iop does work almost in all cases and maybe add here some\nnotes about way to use it.\nThat's strange, it works fine for me, but maybe because I'm familiar with\nit. Here is how it (is supposed to) work:\n\n-The first toolbar allows to select the type of shape you want (circle,\nellipse, etc). With the arrow you can show/hide them.\n-The second toolbar allows to select the algorithm (clone, heal, etc)\n-Next is a label that informs the selected shape. To select a shape click\non it. A shape needs to be selected in order to change the blur radius (in\ncase of blur algorithm) or the color (in case of fill algorithm)\n-Next is the scale (or number of scales), it controls the number of scales\nthe image will be decomposed. 0 means no decomposition, > 0 means it will\ndecomposed on n scales + residual scale. The 3 buttons to the right allows\nto display the reconstructed image, the current scale (only for preview, it\nwill display the reconstructed image when the iop looses focus) or to keep\nthe current scale (it will display the current scale even if the iop looses\nfocus)\n-Next is the current scale. 0 means original image, [1 to number of scales]\nare the detail scales, number of scales+1 is the residual. It controls in\nwhich scale the shapes are added (and which scale is displayed, depending\non the previous option). If shapes are visible, it will display only the\nshapes for this scale. The next 2 buttons allows to cut and paste from one\nscale to another. Cut on the current scale, change to another scale and\npaste it, all the shapes are moved from one scale to the other.\n-Blend factor is for display only, it adds the value selected to the detail\nscale so it can be preview, .128 usually works fine.\n-Masks opacity works on the selected mask. Is the opacity of the regular\nmask that is changed with cntrl-wheel, I just added a slider.\n-Masks display allows to switch off the shapes (so, not process it) and\ndisplay the masks (this only for the current scale). In this last case I\ncouldn't make it work when parametric masks are active, I'll keep working\non it.\nSo, the basic case is:\n-select an algorithm\n-select a shape type\n-click on the image\nwith scale=0 and current scale=0 is just like the spot removal, but you can\nchoose different algorithms\nTo use the wavelet decompose:\n-select a scale (this is the number of scales, I should change the label)\n-select the current scale\n-add a shape on it\n-change the current scale (the shapes are hided)\n-add more shapes\n-if you change back to the previous \"current scale\", the shapes for that\nscale will be displayed\nNow that I'm reading it it doesn't seems obvious at all, so thanks for\ntaking the time to try it and I hope that this will help.\n. I Dominik, thanks for your input, clearly the UI needs more work and some\nredesign, so I appreciate your feedback.\nLet me comment on this to see if it makes more sense:\n\n\nnew created shape should remain selected - I need to click once\n   again to eg. change blur radius\n\nYes, that's on the to-do list, but it's not so easy...\n\nif shape is selected, user may expected that change sliders will\n   affect given shape - this work for eg. blend factor, but not for current\n   scale - I need to cut/paste shape - unclear and unproductive\n\nThe only properties that can be changed on a shape are the blur radius for\nthe blur algorithm, the color for the fill algorithm (if not on erase mode)\nand the opacity for all (clone, heal, blur and fill). Those properties are\nshown/hidden when the corresponding algorithm is selected. So if you select\nthe blur algorithm the blur radius is displayed, if you select the fill\nthen the fill mode is displayed, etc.  I'm not sure how to make it clear on\nthe UI, maybe moving the \"shape selected:\" down, where the shape properties\nare?\n\nBlend factor is for display only and it works when a scale is displayed\n(with the button \"show current scale\", on the right of the \"scale\" slider).\nDetail scales are almost black, so it's common to add meddle gray to\ndisplay them. But this is used by the wavelet decompose, and it's a global\nproperty, not a property of a shape.\nRight now a shape belongs to a particular scale and the only way to change\nthat scale is by cut/paste. But the cut/paste works on all the shapes for a\ngiven scale, it can't be done for a single shape. I've added this feature\nbecause sometimes I want to see how an edit works on a different scale and\nthis is an easy way to do it.\nI'm not sure how to change the scale on a single shape, using the \"current\nscale\" slider may lead to mistakes: if a shape is selected and the user\nchanges the current scale to see or add shapes on another scale, the\nselected scale will be moved and the user may not even notice that. Maybe\nadding a new slider?\n\n\nI assume that the scale is common parameter for all shapes, so maybe\n   move it to the top - now it looks like each shape can have it's own number\n   of scales.\n\nI made it this way to make it similar to the spot removal (that has only\nthe shape types), assuming that it will make it easer for the user that is\nalready familiar with that tool. Seems that I was wrong.\n\nwhat's happen when current scale > scale?\n\nWhen current scale = scale + 1 it means the residual image (the blurred\nimage?). If current scale > scale + 1 then the module allows to add shapes\non it, but it is not processed, and if the user selects \"display current\nscale\" it will display the residual image (but it will not use the shapes\non the residual image to process this one)\nInternally the algorithm process all the shapes on the original image\n(current scale = 0), then performs a wavelet decompose and process each\nscale (and the residual), then it reconstruct the image.\nIf scale (that is, the number of scales) is greater than the maximum number\nof scales (that depends on the image size) it will decompose the image\nusing the maximum number of scales and will ignore all other scales, even\nif they have shapes, except for the residual scale in which case it will\nuse the shapes of current scale=scale+1 (even if scale>max number of\nscales)\n\nseems that sometimes I need to click current scale once again to see\n   shapes\n\nShapes are displayed based on the current scale (the scale where they\nbelong). I made it this way because there is no way for the user to know\nwhere a shape belongs to if all the shapes are displayed at once, and it\nwill be very confusing to see all the shapes for all the scales at the same\ntime.\n\na combobox with all created shapes to select would be a plus\n\nI thought about that but it seems confusing, at least to me. Shapes in\nthis module can't be renamed (they don't show on the mask manager), and\nhaving a combobox with +100 shapes with something like \"circle#34\" will not\nhelp to select a particular shape. +100 shapes may seem too much, but it\nnot so unusual when doing a retouch to reach that number.\n\nI'd consider the possibility of changing the algorithm for the\n   selected shape\n\nThis can be done, at least between clone and heal, I'll think about the\nuse case.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-340616332,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVpF81vMMQpCFZFLq6nvdL8gZJTJks5sxl1zgaJpZM4QKYV4\n.\n. @TurboGit , I made some UI changes and wrote a more detailed description. I'll post it when the build check finish (hopefully ok)\n\nThe blur algorithm has a default radius of zero, maybe that's why you don't see the effect? To change it, select the shape (by clicking on it), the blur radius will be displayed (if not already) and change it to taste.\nAnother way is to change the radius before adding the shape, it will take the new value.\nIf you are adding it on a low scale (like \"current scale\"=1) the result will be hard to see, you can use the display option \"display current scale\" to see the effect on the scale itself.\nAll combinations of shape type / algorithm can be added on any scale (current scale), even if it is > \"number of scales\"\nThis IOP can be an enhancement on the spot removal. With the default values it acts almost exactly like the spots, and I think that the only thing needed is to add the legacy_params(). But I feel that we are very far from this decision.. I made some changes to the UI, hopefully it is more clear now.\nHere is a more detailed description on how the module works:\n\"retouch tools\" section\n-The first toolbar allows to select the type of shape (circle, ellipse, path, brush). The arrow allow to show/hide them.\n-The second toolbar allows to select the algorithm (clone, heal, gaussian blur, fill)\nclone and heal does not have any properties\ngaussian blur has a radius\nfill has fill mode: erase or color\nerase is used to erase detail on a detail scale\ncolor fills the shape with the selected color, only useful in the original image (\"current scale\" = 0) or the residual image (\"current scale\" = \"number of scales\" + 1)\nThe properties are displayed on the \"shapes\" section and they show/hide depending on the algorithm selected.\n\"wavelet decompose\" section\n-\"number of scales\" controls the number of scales the image will be decomposed. 0 means no decomposition, > 0 means it will decomposed on \"number of scales\" + 1 (the residual image).\n-The 3 buttons to the right allows to: display the reconstructed image (\"show final image\"), the current scale (\"show current scale\", only for preview, it will display the reconstructed image when the iop looses focus) or to keep the current scale (\"keep current scale\", it will display the current scale even if the iop looses focus)\n-\"current scale\" controls in which scale the shapes are added and which scale is displayed, depending on the display option (the 3 buttons on the right of \"number of scales\").\n0 means original image, 1 to \"number of scales\" are the detail scales, \"number of scales\" + 1 is the residual image.\nIf shapes are visible, it will display only the shapes for this scale.\n-The next 2 buttons allows to cut and paste from one scale to another. Cut on the current scale, change to another scale and paste it, all the shapes are moved from one scale to the other. Right now there is no other way to change the scale where a shape belongs.\n-\"blend factor\" adds the value selected to the detail scale so it can be preview. This works only when the display options \"show current scale\" or \"keep the current scale\" are selected.\nIt is for display only and it has no effect on the final image, unless the display option \"keep the current scale\" is selected, in which case \"what you see is what you get\"\n0.128 usually works fine, but for bright or dark images it can be adjusted.\nThe maximum number of scales depend on the image size, but the module allows to select up to 15. If the user select a number of scale grater than the maximum, the program will process only the maximum number of scales.\nThe algorithm works like this: it process the shapes on the original image (\"current scale\" = 0), it decomposes the image by \"number of scales\" (or the maximum number of scales for this image) and process the shapes for each scale.\nIn the case where \"number of scales\" > maximum number of scales and there are shapes added to the residual image (\"current scale\" = \"number of scales\" + 1) it will process the new residual image (maximum number of scales + 1) using the shapes of the original residual image (\"current scale\" = \"number of scales\" + 1).\nI've done this because dt works very often with a scaled image, so the input for the algorithm may be very small (on thumbnails or when exporting to 100x100 pix and not in HQ). In this case the maximum number of scales may be smaller than the one on the preview, and with this method I get a closer look to the final image.\nIt's not a very common scenario, but it can happen.\n\"shapes\" section\n-\"shape selected\" is a label that informs the selected shape. To select a shape click on it. A shape needs to be selected in order to change it's properties: the blur radius (in case of blur algorithm) or the color (in case of fill algorithm)\nNext are the controls to change the shapes properties, depending on the algorithm selected.\nIf a shape is selected, an opacity slider is displayed, allowing to change the shape's opacity.\n-\"masks display\" allows to switch off the shapes (so, not process it) and display the masks (this only for the current scale). In this last case I couldn't make it work when parametric masks are active, I'll keep working on it.\nWhen adding a gaussian blur or a fill, the initial properties values are the ones displayed on the controls in the \"shapes\" section.\nWhen selecting a shape, the value of the properties controls is updated.\nThe opacity slider is not used as initial value for the shapes, dt \"remembers\" the last value used and I think is best to keep that functionality.\nThe most common scenario is to do a clone/heal on the original image, in order to remove sensor dust or to do a basic retouch.\nIn this case, with the default values the user selects the algorithm (usually clone or heal), a shape type (usually a circle) and clone/heal by clicking on the image.\nMore advanced editing will require the wavelet decompose, this allows to edit the image on different detail scales (frequencies?)\nIn this case the user selects a number of scales, a current scale, and do the healing/cloning. It may need to edit on several scales, depending on the image, editing, etc.\nTo help decide on which scale to edit, it may select the \"show current scale\" option to see the effect of the editing on the current scale instead of the final effect.\nIf the displayed scale is too dark or too bright it can be adjusted with the \"blend factor\"\nOn very noisy images the heal sometimes give some strange results. In this case healing on the residual image with 3 scales works fine for me. Select \"number of scales\" = 3 and \"current scale\" = 4 and do the healing in there.\nOn large areas, the healing can be slow and results not so good. In this case applying one heal over the other or using two instances of the retouch module give me good results, but again, it can be slow.\n. As suggested by @houz I have created a new branch (retouch_gui) with the optional GUI changes, details are on the new PR.\nI kept here:\n-brush as a clone mask\n-allow to select a shape inside an iop\nthis description is not accurate, the modifications allow the user to select a shape with left-click and informs the parent IOP about those changes\n-new mask type DT_MASKS_NON_CLONE\nI don't like this very much, but it has the advantage that there's no need to modify the spots IOP and worry about backward compatibility.\nA better option (for me) is a DT_MASKS_DONT_ADD_TO_MASK_MANAGER (with a shorter name) new mask type. Then a shape can be created with DT_MASKS_CLONE|DT_MASKS_DONT_ADD_TO_MASK_MANAGER or just DT_MASKS_DONT_ADD_TO_MASK_MANAGER.\n. I made a couple of changes:\n\n\na shape is now selected when is added, as suggested by @theres \nI also added the \"ready for drag\" feature from the circle to the ellipse. The path and brush are just highlighted.\n\n\nfixed an invalid memory access when dt is shutting down and there's a shape selected, dev->gui_module had an invalid memory address.\n\n\nI think that the modifications on step and size on the brush belongs here instead of the other branch, but I'll wait for your feedback on that.\n. @theres ,\nboth issues should be fixed now, thanks for reporting. Let me know if it doesn't work as expected.\nAbout your questions:\n\n\nI don't really use the blur, I just added because I know it is common to use it to soften the skin and I thought that the gaussian is the right tool for that, but if other blur types are better or can be used in another way it shouldn't be a problem to add it.\n\n\nI agree that depending on the image, and specially on low scales, is difficult (or impossible) to see the details, but I couldn't find a one-slider algorithm that give good results and I didn't want to add extra controls just for the preview, there's already the blend factor, and it usually gives good results on scales >= 3, and those are the most used scales. But if you have a specific algorithm in mind it should be easy to try it in GIMP and see if we like the results.. @theres ,\nI've been playing a bit with the preview and maybe I was too picky (is that the word?) before, so I added a contrast slider. It doesn't do any magic, but it improves the preview. I get better results with curves or levels, but not by much, and it will add too much complexity.\nSo now there's two sliders that control the scale preview: contrast & brightness. It only work on CPU for now, so to test it you have to disable OpenCL. If this is good enough I'll add GPU. \n\n\nJust a warning, I have modified the parameters but not the version, so you will loose any previous edits that you may have. I don't know the protocol on this cases, but I guess this won't be the last time that I need to modify the parameters. Should I update the version each time and when this goes to master revert it to version 1?. I have fixed some issues and as was there I also added the GPU side of the contrast and the bilateral filter. This last one break backwards compatibility again.\nThere's still a couple of issues that I couldn\u2019t fix:\n-previously I used the blend module for the display mask (the option at the bottom), but that didn't feel right, so I codded my own based on the gamma iop, so it has the same look. But this has its own issues, now the retouch iop return an image with the displayed mask, so any module that goes after this one will affect the mask. Since the retouch is very early on the pipe this leaves most of the modules, and that is not how the display mask is supposed to work.\n-something similar with the preview current scale option, any changes by an iop after the retouch will be applied over the detail scale. I also get some strange results if the blend module is used on the retouch iop.\nI don't think that there's something that I can do from inside the iop, and I don't want to keep modifying the base code, at least without a previous discussion, so this is just to let you know about this issues and see what you think about it. . I just added a new feature that allows to process several scales at once. There's a new slider \"merge from scale\" after \"current scale\". \nIf > 0, it will merge all the detail scales from this one up to current scale, including the edits, so it will be like performing the same edit on all those scales.\nIt can be a bit confusing at first, but with some practice I get better results with less work.\nThis broke backwards compatibility again, sorry about that.. @TurboGit , I like it (the slider), the only thing I'm not sure is to have to count by hand to see the number of scales, but we can add a label or something.\nI don't know much gtk, so this may take a while. I can start working on a separate branch and keep it low priority while working on other things, and when is ready we can see how it goes. This sounds ok to you?\nI've also made the modifications from your review, let me know if it is ok.. @TurboGit , I almost have it. You were right, the zone has almost everything, that made it easy.\nI think that today I can check in something.. @TurboGit , here is the first version. I kept the previous behaviour, so there's a fixed number of boxes and the user can select almost anything, the only restriction is that the merge scale cannot be gather than the number of scales.\nThe sliders works like a regular slider, values are changed with drag, scroll and click.\nCurrent scale is painted with yellow and can be changed with scroll and click (no drag)\nMerged scales are painted with a shade of yellow.\nThere's a red box that indicate if the mouse is over a box, if not then is over a slider.\nI also replaced the labels with the standard separator. It makes the UI a bit busy but I think is nicer this way. . @TurboGit , sorry but I don't think I understand. The user double-click on a box, that sets the current scale to that box (so far same as single click), but I don't see what values are assigned to number of scales and merged scale. . About the double-click, I think it may be confusing for the user. Double-click usually resets the control to the default values, so I would expect that double click on a box will set number of scales=0, merge scales=0 and current scale=0.\nBut sounds right to have the reset option, so I can also include a reset for the number of scales and merge scales, both individually will be set to 0 if double-click on it. Does this make sense?\nAbout the labels, yes, it sound nice, but I also would like to keep the # scales\nThe number of scales work for me, to scroll, the mouse must be on the bottom of the control, I see the entire bottom as a slider.\nOn the top, the scroll will change the merged scales, and in the middle the current scale.. @TurboGit , I see. Let me explain how it works now, so we are sure we're on the same page, then we can see where we go.\nRight now scales are merged from the \"merge from\" to the \"number of scales\" and is adjusted with the top slider. So if \"merge from\"=4 and \"#scales\"=8 it will always merge the detail scales 4..8. The user can edit each individual scale, so if shapes are added to scale 6 is like editing scales 4..6 together.\nBut there's no option to define merge range, so the user cannot merge scales 4..6 and then edit scales 7 and 8 as regular scales.\nThis is a new feature, so I can't say for sure, but it seems to me that most of the editing is done on the last scale when \"merge from\" is selected. At least I haven't had a case where I need to edit the last scale as a single scale when the merge is active.\nThe bar control presents all possible scales, right now 17, 0 is the original image, 15 is the max number of scales allowed by the module (regardless of the image size) and one more for the residual image.\nTo define the actual number of scales used to decompose the image is the bottom slider. The user can select as current scale any of the available boxes, but only scales in the range 0..#scales+1 will be processed.\nI get what you are saying, you would like this to behave like the zone iop and that the control only display the # scales, and use the scroll to change it.\nI like better this behaviour because it give more options when editing. \nSometimes, when deciding the number of scales, I set the current scale to the max value and then I increment the # scales, so I can see how it affects the residual image. When I find something that I like I keep that # scales. Of course this can also be done with the zone behaviour, but it's easer this way.\nI also do some edits with a number of scales, and the I want to try something with less scales, then I may go back to the original number of scales or keep trying. Again, this can also be done with the zone behaviour, but at least for me is easer this way.. I made some changes to the wd bar, just the look, the functionality is the same. I think this gives a better visual of what is going on.\nNow:\noriginal image is always black (box 0)\ndetail scales are all light grey\nresidual image is always white\nmerge from .. # scales scales are yellow/green-ish\nout-of-range scales are dark grey (same as the background)\ncurrent scale has a red box\na green line is displayed on top if a scale has shapes on it\nI don't like the original image black, but with solid colors is the best I can get. I'll try to display the actual image, but the box is too small so I don't expect much.. @TurboGit , that bug is indeed annoying, and on my tests it also occurs with the drawn masks on other modules. I'll take a look, I'm not going to fix it on this branch, but if I can find the problem we can discuss what to do.. I take that back, it seems that forms groups are not recorded into history, so more than a bug is an enhancement. Not much I can do about it.. @TurboGit , the commented code is for the new wd bar, I have yet to do some cleanup and optimizations, but I was waiting to be reasonably tested and that we agree on the functionality first.\nAbout the const(s) I'm not sure what you mean, if is to add const to the variable declaration, in most cases this is how it's done on the existing code, I would like to keep it consistent.. Maybe I haven't explain it clearly, please have in mind my english skills.\nMost (or some) of the code is based on already existing code, I have copied it and made modifications to adapt it to my needs, but I always try to keep it as close to the original code as possible, as I assume it follows dt standards. This is what I mean by existing code.\nDon't get me wrong, I agree with the const and I use it all the time, but in some cases I change my personal style when I see that somewhere else things are done different.\nAnyway, this was a general remark, I have't gone on all your points one-by-one yet. Let me know if/when you are ok with the new slider, I'll make a final version and we can take it from there.. @TurboGit : I didn't really think about it when I designed, I just did it this way, but I think that this is more intuitive. This is the usual way a wavelet decompose is presented, so users familiar with this will expect to be displayed from fine to coarse.\nThe equalizer is a different tool with different purposes, so I don't think it will be confusing for anyone if they are in opposite order, and this way we are in synch with other programs that have a wavelet decompose.. I just added a levels to the preview scale, in my tests it usually give better results than the contrast, and when it doesn't  it gives reasonably results with one click (the auto levels), I find that better than play with the contrast & brightness.\nIt has two differences with the levels iop:\n-with default values it does nothing\n-it works on the cropped image, I like this, is not uncommon to have a portrait with the background under/over exposed, and this way the user can zoom in to one feature and have the leves calculated just for this.\nOn the technical side, the auto button doesn't work like the levels iop, it calculate the stats on an intermediate image, so I can't use the histogram or color picker.\nRight now I'm updating the params & GUI on the DT_SIGNAL_DEVELOP_UI_PIPE_FINISHED, it works, but this doesn't seems right, so I can use some help here.. @TurboGit , that's correct, the module always process the entire mask if at least some part is visible. When zoomed-in it may be even slower, as the input image may be bigger. I don't think there's a way around it.. @theres , good to know! I'm not too happy about having 3 sliders, so if levels alone do the job I'll eventually remove the others.\nAbout the first two problems:\nOn fine scales, in order to see some details I have to zoom in (on scale 1 usually to 1:1), otherwise I get a black image. Something similar happens with the equalizer (not the black image, but the zoom to see details).\nSo I made a special case on the auto levels: if image is black turn it into grey. Now, I have no idea why the preview shows something different, but maybe is related to the next point.\nThe wavelet decompose returns different results depending on the image scale. I've done my best to make it scale independent, and it usually gives good results, but is not 100% accurate, so when the working area is bigger I assume that the input image will be bigger and the algorithm will give a different result.\nSame can happen with the preview, the thread may have a different image size, so result will be different.\nWith the auto levels even a very subtle difference in the image can make a big difference in the resulting levels, as it calculates the min, max and average of the image, so if the change in scale make just one pixel to be off the range the levels will change.\nI'm not sure this explains the problem you describe with the preview, I usually get some differences with the image in darkroom, but the preview has always less detail, not more. Maybe a refresh problem? If when having this issue you change the preview brightness things go back to normal?\nWith the slider yes, the drag is not very responsive, and I coudn't make the scroll work, so I can't say is the slider fault. I'll keep trying but with low priority, I'm focus on the auto levels issue now.. @theres , I'm not sure I understand what flickering is in this case, so I'll describe a known scenario that seems related. When I zoom in/out, sometimes the image needs to be reprocessed, in order to make the transition more pleasant the system displays a scaled image from another pipe (this is just a guess based on observation, I may be wrong here), if this image was generated using a source image with different scale, I'll see, for the time that the image is being processed, a slightly (or very) different image, and when the process is done things go back to normal.\nSimilar with the histogram, as it is not computed using the darkroom preview, so for fine scales if the source image (used to compute the histogram) is not large enough, the decompose algorithm will return a black image and the levels will turn it into grey, while the darkroom (at 1:1) has details.\nEven if those are known scenarios for me, I didn't bring them because I'm already familiar and I have learned to live with them, so I don't think of it as issues. But now I wonder if this is good enough for a release version. I hope so, because I don't think there's much I can do about it, and the preview scale is a must, so removing it is not an option. . @theres , shortcuts work for me, maybe is related to the selected key? I'm using a default installation (no shortcuts defined by me) and define in preferences->shortcuts->image operations->retouch: B for brush, C for circle, E for ellipse, P for path. It works fine this way.\nIf I only define B for brush, still works fine.. I see, you are pressing B without actually adding a shape in between. Good catch. The spot removal has the same issue, so if this isn't an upgrade we can port the fix to it.\nI'll also take a look at the other two issues and will let you know.. @theres , issues should be fixed now.\nI also added a grey line on top of the wd bar indicating if the scale is visible at the current zoom level.\nAbout the levels slider, I will replace it with a custom one, so don't pay attention to it for now.. @TurboGit , sure, I'll set the default to 10, if is still too small we can take it from there. Right now I'm in the middle of updating the levels slider, but I'll have it done on the next commit.. @TurboGit ,\nI just pushed the blur radius and the levels slider, other than the issue with the auto button it should be ready now.\nI have two issues left on my to-do list right now:\n-the algorithms toolbar has the clone as default, I've done it this way so with default values the module behaves like the spot removal, but probably the most used algorithm will be the heal, so maybe it make sense to change the order to: heal, clone, fill, blur and make the heal the default.\n-I would like to keep the brightness & contrast sliders until the levels is better tested so we are sure that it works for every image, and also because the auto button issue, I still can't find a better way to do it.\nWhat do you think?\n. I just:\n-removed brightness & contrast sliders\n-make heal the default algorithm\n-renamed shortcuts so they are displayed together\n-fixed a bug in modify_roi_in() when there's an overlap between clone/heal shapes\n. I just made two small updates:\n-reworked the way the alpha channel is build for the display mask. this is not a very used feature, but the code is cleaner this way.\n-moved the display toolbar to the wavelet decompose section, it makes more sense there and it saves a little space.\nI'm not sure what the next step is here but I have no issues left other than the already reported ones, so I'll wait to discuss it before make any further changes.. @TurboGit  : I have rebased this and retouch_gui branches, let me know if there is any more issues. @TurboGit , it should be ready now. The image was reprocessed each time the iop grab/loose the focus, and it shouldn't. I usually do the retouch as a first step, so I don't even notice it, but with heavy edits is really annoying.. I'll take a look at that.\nI agree, the sooner is merged the better it will be tested before the next release. Let me know if there's something I can do to help with that.. IRC doesn't really work for me, I know is not the same but here or mail is better for me.\nBefore the merge there's still this that needs to be addressed:\nhttps://github.com/darktable-org/darktable/pull/1548/files#diff-e3fe6a161b31cae7e75c7f5a8cd99ec2L40\nNot sure if I mentioned, but the retouch and the spot removal are not 100% compatible. The retouch work in-place, that is, all operations are done in the input image. The spot removal use as source always the input image and as destination the output image for the clone.\nThis shouldn't be an issue, I don't see why a user will set the source of a clone as the destination of a previous one, but in theory it can happen.\nAdding that it will probably be less confusing for the user I vote for this to be a new iop, but of course not really my call.\nonce this has been decided I can do the DT_MASKS_UNMANAGED change.. @hanatos , I work on a copy of the input buffer, ivoid is never modified.. Hi @houz , following is a list of known issues for this PR, I'm not sure what else is needed for this to be merged, so just let me know.\n-I think that the most urgent is the above discussion: should this be a new iop or an upgrade for the spot removal?\n-the auto levels button is saving the parameters on the event DT_SIGNAL_DEVELOP_UI_PIPE_FINISHED and I'm not sure that's correct. @TurboGit  and I have been using it for a while now and it seems to work fine, but better be safe than sorry.\nThis two are low priority, is a display issue on not-very-common scenarios:\n-the display masks option is not using the standard functionality, I wrote my own. It works fine, but since the mask is returned in ovoid it is affected by the next modules in the pipe. I would like to use  the standard one, but the blend module gets in the way.\n-something similar with the display scale, when the option is active and the blend is also active it affects the output, and that is not what I want, the display scale should display the wavelet scale without being affected by the blend module.\nNot an issue but a functionality thing,  the keep current scale option allows to set the current wavelet scale as the output. I never use this, I just added to try some effects with different blend modes but I didn't really like any of them. This probably has nothing to do in this module, as it is not used for any retouch operation and the wavelet scales are not 100% scale independent, so result will vary depending on the export size.\nAll this to say that I don't know if keep it or remove it. @TurboGit  has been using this module for a while, so maybe he can help with this.. >\n\nthe wavelet scales are not 100% scale independent, so result will vary\ndepending on the export size.\nExpect if the option \"do high quality resampling during export\" is\nselected, right?\nYes, in that case the input image will always have the same size, so the\noutput will be the same.\n. Why you think the full retouch is no good for that?\n\n2018-08-22 5:02 GMT-03:00 Pascal Obry notifications@github.com:\n\nJust a comment that I did not forget about this. I had no time to do\nanother full test until now. I hope to be able to test and merge before\nseptember.\nIn any case I think that the \"heal\" tool should be an option also\navailable in the \"sport removal\" module. Using the full retouch module just\nfor that is no good, the simple spot removal should support the healing\nmode to me.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-414947400,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pU6y2St4qJHA8BQIssWVa0zJpgyDks5uTRAXgaJpZM4QKYV4\n.\n. Maybe at first with all the controls, but with default parameters it acts\nexactly like the spot removal, so the user can just ignore the wavelet\ndecompose and add the shapes for a simple use.\nOf course I have designed and I've been using it for a while now, so\nprobably I'm not objective here. Let's see what feedback we have when\nmerged and if needed we can discuss what can be done.\n\n2018-08-22 14:34 GMT-03:00 Pascal Obry notifications@github.com:\n\nIt is quite a complex module just for removing a spot. When the only goal\nis to remove a spot from the sensor on the sky I feel that it would be\nbetter to be able to use the simple \"spot removal\" module. The Retouch\nmodule is quite advanced and will not be easy for some people. My feeling...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-415114795,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRMDJawYzl7wsXZ50RgXDfJrEYt1ks5uTZYSgaJpZM4QKYV4\n.\n. That's great, thanks!\n\nJust one question, how dependencies are handled? Should I create a new PR\nor there's someone in charge of that?\n2018-09-03 12:52 GMT-03:00 Pascal Obry notifications@github.com:\n\nOk, I have reviewed again and did a quite intensive testing. All is\nworking good to me, so it is time to let this go in and have a more widely\nfield testing before the next release.\nThanks again for this very nice addition.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-418150478,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pYEfVjrUINa97GHV0dajnPC2p21Bks5uXVA3gaJpZM4QKYV4\n.\n. As far as I know iop_dependencies.py needs to be updated/executed.\n\n2018-09-03 15:06 GMT-03:00 Pascal Obry notifications@github.com:\n\nSorry I may be missing some context. What dependencies are you talking\nabout? A PR for what?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-418171141,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pemnHIXYKiUaPateuynxoMM29harks5uXW-YgaJpZM4QKYV4\n.\n. ok, I'll do that.\n\n2018-09-03 15:28 GMT-03:00 Pascal Obry notifications@github.com:\n\nI see, you've manually coded the priority into retouch.c so fine on this\nside.\nBut we should update iop_dependencies.py by placing retouch module into\nthe graph. Can you do that?\nThen, we don't need to run iop_dependencies.py but in case we want to\nrecompute the priority values based on a new graph this can be done anytime.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1548#issuecomment-418173917,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSwmV5cfbGoVV53-D8U242p625MHks5uXXTjgaJpZM4QKYV4\n.\n. Yes, but I just don't know how to do it. The ellipse also has 2 radius, an angle and 2 types of feather, I don't know how to adjust all that with the mouse wheel and make it easy for the user.. ok, if you think that this is good enough I can do it.. @TurboGit , it's ready, I also added SHIFT + CNTRL to adjust the rotation, to keep it consisten it also works on edit mode.. I just rebased and fix conflicts.\n\nThis PR hasn't drawn too much attention and it makes some changes on the behaviour of the drawn masks on the blend module.\nI find that all the changes here help when working on the retouch, but maybe not everybody like it on the blend module, in particular how masks are resized and the minimum size, so I just want to highlight this new behaviour to make sure everybody is ok with it.. -resize don't care where the mouse is inside a shape\nRight now, to change the size of a shape, the mouse must be over the \"body\" of the shape, if it is over the feather, the feather is changed. The feather is also changed when pressing SHIFT, even if the mouse is over the body.\nI have changed this so now the size is changed even if the mouse is over the feather, and the feather can only be changed pressing SHIFT.\nWhen there's a lot of small shapes close to each other is difficult to select just the body of a shape, so sometimes I change the feather instead of the body, this change makes the work easer.\nChanges in size & step\nbrush:\nI have changed the step from:\n    float amount = 1.25f;\n    if(up) amount = 0.8f;\nto:\n      float amount = 1.03f;\n      if(up) amount = 0.97f;\nand the border from:\n        masks_border = MAX(0.005f, MIN(masks_border * amount, 0.5f));\nto:\n        masks_border = MAX(0.0005f, MIN(masks_border * amount, 0.5f));\nthis allows to have a smaller brush and more control over the size. For small details I sometimes have to use the path because the brush is not small enough, when the brush will be the right tool for the job.\ncircle:\nI have changed the minimum border size from:\n        if(up && circle->border > 0.001f)\nto:\n        if(up && circle->border > 0.0005f)\nthis allows to have a harder border.\nWhen the circle is created I have changed the minimum values from:\n      circle->radius = MAX(0.01f, circle_size);\n      circle->border = MAX(0.005f, circle_border);\nto:\n      circle->radius = MAX(0.001f, circle_size);\n      circle->border = MAX(0.0005f, circle_border);\nso the new created circle will have the same values as the last one, even if it is very small, otherwise I'm forced to change the size and feather of every new circle when working with small shapes.\npath:\nI have changed the minimum border size from:\n          masks_border = MAX(0.005f, MIN(masks_border * amount, 0.5f));\nto:\n          masks_border = MAX(0.0005f, MIN(masks_border * amount, 0.5f));\nthis allows to have a harder border.\nThere's also:\n-allow to pan & zoom while editing masks\npressing \"A\" (can be configured) will skip mouse events from the masks, so the image can be \"pan&zoom\" even if the mouse is over a shape\n-preview when creating a circle or ellipse\n-resize a path even if on a node or segment\nRight now if the mouse is on a path node or segment the mouse wheel will zoom the image, I have fixed that so the path is resized.\n. I can leave in this PR:\n-preview when creating a circle or ellipse\n-allow to pan & zoom while editing masks\n-resize a path even if on a node or segment\nI don't think that anyone will complain about those, and create a new PR\nwith:\n-resize don't care where the mouse is inside a shape\n-changes in size & step\nSounds ok to you?\n2018-09-04 13:10 GMT-03:00 Pascal Obry notifications@github.com:\n\nOk, alll this is sounds to me. Even the change of the feather requiring\nthe SHIFT, I had found also that sometimes it was difficult to select just\nthe shape and not the feather.\nDo you think we can split the PR in two. I see:\n-\n      1. one commit with the preview for circle & ellipse\n   -\n      1. one commit with the behavioral change\nThis will ease merging, at least I would merge 1 right now. Then will see\nhow 2 looks for others. What do you think?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1550#issuecomment-418427139,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pW6QjzO7ZRG6kQF_NZDw4SQe2NkNks5uXqYPgaJpZM4QVYWo\n.\n. > The preview of the shapes are not working on my side with the latest\nchanges. A missing chunk in a commit?\nStrange, it works fine for me with all the shapes on the blend module, the\nspot removal & the retouch.\n. I just rebased and done a clean build and still works for me. What I've done is:\nclone my fork\ncheckout retouch_gui branch\nbuild\n\nWhen adding a shape on any module, the shape preview is there.\nI don't know how the local merge is done, but if you guide me through your steps I can try it. Or if you can compare your local files against the retouch_gui branch that can give us some info.\n. > BTW, your new PR mask_behavior has conflicts if applied on to of this one.\n\nThis may indicate that something was broken when you've separated both PR?\nThat's expected, there is some overlap on the code, but even if there is\nsome problem there, at least the preview should be seen.\n. Are the other features working? The pan&zoom and the path resize with the\nmouse over a segment or node...\n\n2018-09-05 12:39 GMT-03:00 Pascal Obry notifications@github.com:\n\nReally mysterious! I have built also directly from your branch and it does\nnot work for me :(\nI don't have explanation for now. But it doesn't seem to be due to the\nmerge on master.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1550#issuecomment-418777724,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZnhffVmOr6rrThrX2-7SGfP6xuaks5uX_BMgaJpZM4QVYWo\n.\n. Hi Aur\u00e9lien,\n@edgardoh https://github.com/edgardoh I see 2 missing features already:\n\nwe can cut/paste masks from layer to layer, it would be great to be\n   able to reuse the same mask on multiple layers\n\nI'm not sure I understand what you are looking for, but if you want to use\nall the shapes of a scale on other scales there's the option described by\nPascal above: set the merge from slider and all the edits of a particular\nscale will be applied on the range [merge from .. scale where the shape\nbelongs to] (sorry, I find very difficult to explain what this option does)\n\nthe histogram correction in the single layer preview could be\n   automatic so that we don't lose time adjusting white and black levels\n\nYes, is very annoying to set the display wavelet scale button and see a\nblack image, but I couldn't find a condition that I like. Probably the best\none is:\nif in the current session the levels hasn't been used and has default\nvalues, when display wavelet scale is pressed auto levels are executed. But\nstill I'm not very sure about this.\n. > But then, all the shapes are shared with the selected layers, aren't they ?\n\n\nThe program works like this:\na detail scale is generated\nall edits are applied to this scale\nthe scale is saved somewhere\nanother scale is generated\nall edits are applied to this scale\nthe scale is merged to the previous scale (both scales already has the\nedits applied before they are merge)\nif merge from is >= than the scale being generated, then\nthe scale is generated\nit is saved somewhere else\nthen edits are applied\nnext scale is generated\nit is merged to all previous scales (that has been saved somewhere else)\nthen edits are applied, so they are applied to all the scales >= merge from\nuntil it reaches the residual image, that it is not affected by this setting\nSo, in a sense, yes, shapes are shared between wavelet scales (or layers),\nbut what really happens is that scales are first merged to the previous one\nand then the edits are applied.\nMaybe you can have a better feeling by just using this feature, the display\nwavelet scale option reflect this setting, so what you see in the preview\nare the merged scales if current scale > merge from.\nI just would like to map the min intensity of the previewed layer (aka\n\nwavelet scale) to 0 and the max to 1.\n\n\nI have done some experiments with default values for the levels, but it\ndepends too much on the image. [0, 1] usually don't give good results, at\nleast on the images I have used, that's why I think that the best solution\n(that I can think of) is the one described above.\n. I think I get it now, but if we are going to do some calculations let's use the auto levels, that seems to work fine for all the images so far. \nBut the issue with the condition still remains, When to do the calculations? Each time the display wavelet scale button is pressed? Using the condition I have mentioned?\nMaybe instead of wait for the perfect condition I could implement what I already have, if any issues are found I will probably be able to fix it.\n@TurboGit , what do you think? Also, is this the right time to introduce this or should we wait after the next release?\nAbout the rotation, no, it can't be done. But this will be a too big change to even try it, we are too close to the next release.. I just added PR #1720. I've been using it a bit and it works great on the lighttable, but on the darkroom I've found a couple of issues:\n-the filmstrip allows to drag but not drop, I'm not sure if it shouldn't allow to drag or if it should allow to drop.\n-sometimes in the darkroom area when dragging the image the sort order cursor is displayed:\non lighttable select sort by filename\ngo to darkroom\nselect custom sort\ndrag the image\nit also happens if:\n-already in custom sort on lighttable\n-go to darkroom\n-change image without leaving darkroom (double click on filmstrip)\n-drag the image\n. I have no idea about that implementation, so I can't really say anything,\nbut from an end-user point of view if find that the custom order on the\nlighttable is more than enough, so if is not available on the filmstrip\nthat's ok with me.\nEl jue., 11 oct. 2018 a las 18:05, Mario L\u00fcder (notifications@github.com)\nescribi\u00f3:\n\nThanks for your feedback.\nMh, I wonder, I haven't done any changes for the film strip. I saw some (i\nthought not finished) drag and drop implementation there, but I avoided to\ntouch this. Maybe my implementation has some side effects on the film strip.\nI'll find out and get back on this by Saturday.\nWhat I am not sure is how to deal with that implementation. I would just\nremove that for now. What do you think?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1677#issuecomment-429118226,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pf8_31mQLyXlZFKl67vz9Yp7F18fks5uj7J_gaJpZM4TW_bm\n.\n. > The drag&drop in the filmstrip is for the map view. It is finished and\nworking properly in this view.\nYou're right, I've never noticed that. The only issue then is with the drag\non the image on the darkroom.\n. Just to be clear, because I don't know the code, but the issue is in the\ndarkroom area, when the image is dragged. The issue with the filmstrip is\nnot an issue after all.\n\nEl s\u00e1b., 13 oct. 2018 a las 16:17, Mario L\u00fcder (notifications@github.com)\nescribi\u00f3:\n\nI am sorry, I am not able to change this. The drag&drop source is set in\nthe initialization function of the filmstrip.\nSetting the source at a later point depending on the selected module\n(darktable or map) seems not possible - what already the comment says:\n/ allow drag&drop of images from the filmstrip. this has to come before\nthe other callbacks are registered! /\nI wonder way. So, someone who has more GTK insights might fix this.\nAs I assumed, this behaviour is independent from the change I made here.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1677#issuecomment-429568036,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWj4U0Qzy7cci_CKvEnSkw838ZESks5ukjwagaJpZM4TW_bm\n.\n. > Everything looks good except for the harder edge of the circle mask : it\ncreates aliasing on the edge, even with lanczos 3 interpolation\nWhere, the heal, clone, fill, blur?\n. > I tested it in the exposure module. Does that change only affects the\nretouch module ?\nNo, but that's how draw masks work, you can duplicate it on the current\nversion.\n. Auto levels are executed only the first time the display wavelet scale button is used, and only if levels have default settings. Otherwise it will affect performance and may not be what the user wants. Once the levels are set they usually work fine for all the scales. If not the auto levels button can be used.\n\nThat's how the algorithm works, there's a gray line on top of each scale indicating if the scale is visible at current zoom level.\n. Is not really about the amount of work, I just don't find the share/copy\nuseful. Different scales have different size/shape for the same feature, so\nthe same mask won't do it. And when using the merge from option I do all\nthe edits on a single scale, so no share/copy are needed.\nMaybe is my workflow or editing stile, can you describe a scenario where\nthis can be useful?\n2018-09-10 17:35 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nOk I didn't got the gray bar.\nSo I would say, for now, the only thing I'm missing in your module is a\ncopy/paste function to duplicate masks from one scale to another (ideally,\nI would like to share the mask without duplication, but I feel it might\nneed more work).\nThanks again !\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1720#issuecomment-420051663,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pazDQqGx6so4DgqOzZBtGQ892nKSks5uZs0YgaJpZM4We2J_\n.\n. I'm assuming that by global scale blending you mean merge from option.\n\nOn 4 scales range the size of the feature will be very different, so the\nmask will need some adjustment, so the share is out of the question. Based\non the amount of work that you describe, copy-resize a mask instead of\ncreate a new one doesn't save much work, even for complex shapes, much less\nfor a spot, at least that's my experience using the cut/paste.\nLet's see what other people say, maybe a copy option is more useful that I\nthink.\n2018-09-10 18:55 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nI'm using it on skin retouch, in portrait photography. Say you have a spot\non the face, you want to remove it but not smooth the skin texture too much\nand you want to keep (some of) the noise to blend it better if you are at\nhigh ISO. To do that, I find that using the global scale blending is not\naccurate enough, so I do it in an iterative way, using the relevant scales\n(usually, between the scales number 3 to 6). So, basically, I duplicate the\nsame mask on 3-4 non contiguous scales, sometimes with different opacities.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1720#issuecomment-420074383,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peMDY7NovZ6WCN4SQu6bvd7BonJ2ks5uZt_ggaJpZM4We2J_\n.\n. I understand your workflow (and I know what this editing technique is\nabout), that's not what I'm talking about, my point is that the copy option\ndon't save a lot of work/time.\n\nAbout the merge option vs single scale, if you share your raw I can play a\nbit with it and see what I can do. If you can't upload here maybe create a\npost on pixl.us?\n2018-09-10 21:38 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nI did a short video to show you my workflow : https://youtu.be/SenONuZIq2Q\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1720#issuecomment-420106681,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcan-Q17QV4yLdGFzFNo0uwZKmsSks5uZwYLgaJpZM4We2J_\n.\n. Is working fine for me, can you give me more details on how to duplicate it?\n\n2018-09-12 4:16 GMT-03:00 Pascal Obry notifications@github.com:\n\nLooks good. Thanks.\nI think there is something broken with the retouch IOP, the blending is\nnot working on it.\n\nuse a parametric mask and try to display the mask (no yellow on\n   display)\nuse uniform biending and change opacity, it seems to have no effect\n\nDo you reproduce on your side?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1723#issuecomment-420539077,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQLQ8JEusCPFCwAjBEx7QbUk_J1eks5uaLTcgaJpZM4WkQL0\n.\n. This is (not sure how to say it...) on purpose. When display wavelet scale\nis active the blend module is disabled. That's because when I set this\noption I want to see the details, not the blended version.\nWhen the display wavelet scale is not active, the display mask on the\nretouch and the one on the blend module are mutually exclusive, if one is\nset the other one cannot be set.\n\nThis make sense?\n2018-09-12 13:55 GMT-03:00 Pascal Obry notifications@github.com:\n\nOk, I found a reproducer, but now I'm wondering if this is a feature or a\nbug.\n-\ngo to darkroom\n   -\nactivate retouch\n   -\nactivate the parametric mask\n   -\nactivate the display scales\n   => try to display the mask (yellow) -> not working\n   -\ndisable the display scales\n   -\nactivate the display mask, it is working\n   => try to display the scales -> not working\nIt seems that you can have either the masks or the scales but not both.\nThis has been tested with current master and with this branch.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1723#issuecomment-420721239,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZ6AV29QL6vMEXDPZG4q7pshshFWks5uaTyPgaJpZM4WkQL0\n.\n. A log message can be distracting, how about adding it to the tooltip?\n\n2018-09-12 14:18 GMT-03:00 Pascal Obry notifications@github.com:\n\nYes, that makes lot of sense, but in that case I think we should have a\nlog message sent to user about this using dt_control_log(). That is when\nclicking on mask when scales are active and vice-versa. Possible?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1723#issuecomment-420728425,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pc7erjCMclaF2LDee1szlmPT0kc5ks5uaUHxgaJpZM4WkQL0\n.\n. the log message shouldn't be too difficult, I'll give it a try.\n\n2018-09-12 15:16 GMT-03:00 Pascal Obry notifications@github.com:\n\nWell a log message will appear only if you click on the non effective\nbutton. It should probably happen once or twice before a user stop try that\n:) So I would that a log message would be nice if not too difficult to\nimplement in this case, but having a message in the tooltip is also a good\nidea.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1723#issuecomment-420747141,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVW2S5Jyud-17CmOjYK-u23UfrQRks5uaU96gaJpZM4WkQL0\n.\n. > When clicking on the \"display wavelet scale\" button we should also have a\nmessage.\nwhat message?\n. I completely forgot about this. Done.\n\n2018-09-13 9:21 GMT-03:00 Pascal Obry notifications@github.com:\n\nI would write:\n\"cannot display scales when the blending mask is displayed\"\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1724#issuecomment-420986905,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQ-_-Z2mEAchSABqW2EKdQT0Ubsgks5uak2tgaJpZM4Wmb87\n.\n. BTW, based on the amount of feedback it seems that not too many people is\nusing it, is there a way to get more people involved in the testing?\n\n2018-09-13 10:11 GMT-03:00 Pascal Obry notifications@github.com:\n\nAll good, thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1724#issuecomment-421001461,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSn966TcRidvYRyYKPx4pZvGULfBks5ualmPgaJpZM4Wmb87\n.\n. OK, I'm already working on the documentation, so I can send a mail with\nwhat I already have.\n\n2018-09-13 11:36 GMT-03:00 Pascal Obry notifications@github.com:\n\nSend a message on the -dev (maybe -user) mailing list? We need people\ncompiling dt at this stage.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1724#issuecomment-421029708,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXrYpvkNIpAv9ipBFLbIf7MDrzroks5uam1ugaJpZM4Wmb87\n.\n. It is not? Can you point me where the problem is?. it is surrounded by _(), so it should be. but if its not I'll fix it.\n\n2018-09-15 9:57 GMT-03:00 Ger notifications@github.com:\n\nto be precise, this sentence \"enter the new name for the module\"should be\ntranslatable\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1725#issuecomment-421566523,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcAuaoIkP-Nq4oM5g2M1-hUKbPLWks5ubPlBgaJpZM4WqV7u\n.\n. Thanks Dominik.\n\nI agree and I'm working on that, but it will be on a different PR. Same\nhappens when copy/paste history, is kind of random for the user how it\nworks.\nAbout the enter, this is how dialog box behaves on dt, I don't want to do\nanything different. But again, I agree that enter/escape will be nice.\n2018-09-18 18:08 GMT-03:00 Dominik Markiewicz notifications@github.com:\n\n@edgardoh https://github.com/edgardoh great change again!\nOne thing I'd want to discuss is how it should behave for styles. Right\nnow, when I modify instance name, save this as a style and then restore on\nother photo it will replace instance with the same index. To be honest I'm\nnot sure it's something I'd expect. For me more intuitive is to replace\ninstance with the same name, and when there is none, create new one.\nAdditional minor change to consider: hit enter after type name could apply\nchange (i.e. call rename module response callback with response_id ==\naccept).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1725#issuecomment-422555482,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRuTnHeCNoQ2hGdsAaMfMTtaruWJks5ucWDHgaJpZM4WqV7u\n.\n. > I definitely think that & should be taken into account.\nSorry, I don't follow, what should be taken into account?\n. If it is fine that this is the only dialog box with this feature I can work\non that.\n\n2018-09-21 9:49 GMT-03:00 Pascal Obry notifications@github.com:\n\nWell I have surrounded the \"enter\" and \"esc\" with symbols sup and inf and\nit seems that that has been interpreted as HTML tags :( So the full\nsentence is:\nI definitely think that \"enter\" & \"esc\" should be taken into account.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1725#issuecomment-423519777,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pW3ZOiCH8wxc_cw7bsgLexQRRKC9ks5udOBtgaJpZM4WqV7u\n.\n. I like that! I'll look into it.\n\n2018-09-21 10:03 GMT-03:00 Pascal Obry notifications@github.com:\n\nAlternatively don't use a dialog.\n\nuse a simple entry as done for ctrl-t (adding tags) from the\n   lighttable\nwhen double-click on the module name, let edit the module name\n   in-place (the current name become an entry)\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1725#issuecomment-423523454,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcLvF5IPGLSXBcp3GqeJf67IOa2xks5udOOMgaJpZM4WqV7u\n.\n. I couldn't make the double-click, the mouse down expand the module, so double-click get a strange behaviour. I just left the menu option.. > Is that completely independent of the copy history PR? Has this any effect\non the current behavior of the copy ?\nIt is independent from the copy history, and no, it does not have any\neffect.\n. I have removed the one-instance check, it doesn't do anything right now anyway.. Hi,\n\nI've been playing a bit and here are my first impressions:\n\nIs not that easy to get good results, with well exposed images I usually get artefacts, so I have to go to the exposure, make some changes, go back here, adjust it, etc.\nOnce I get a flat image with no artifacts, sometimes when using the tone curve or the contr-brigh-sat I get artifacts again, so I have to go back to the beginning.\nI managed to get rid of the artifacts, now I can play, but is not that easy to restore the contrast/saturation. OK, that is maybe because of my editing skills, but at least in part I think is because all the things I have done to get rid of the artifacts.\n\nNow, having done all that, the end result is nicer than I could get with the base curve, and it give me a better base to continue my edits. So, is there anything that can be done about the artifacts? Have in mind that I see this as an end user, I don't know the first thing about the subject.\n  . I did follow it. BTW, great tutorial, I've couldn't done it without it.\nI'll see if I can find an image that I can share with those issues, so you\nhave a better idea, but by artifacts I mean red/blue/green pixels usually\non dark areas. Even if they are not present in this module the show by just\nenabling the levels or the contr-brigh-sat, so maybe (and this is a wild\nguess) something is out of gamut.\nI get that this is my first interaction with the module, with practice\nthings will go faster and results better. And since I already manage to get\ngood results there is no doubt that this module has potential.\nWhat I would like is to minimize the chance of those artifacts and an even\neasier way to get nice results.\nMaybe this is how the algorithm works and there is nothing you can do about\nit, but if you can identify the problem maybe a message or warning \"there\nare pixels out of gamut (or whatever the problem is)\" so we don't need to\ncheck the entire image each time.\nThe other thing is to go to the exposure and back here, so maybe is\npossible to make this a new module, place it (on the pipe) before the\nexposure, and add the black point/exposure here. This way you have control\nover it, and an auto button can be created that sets the black\npoint/exposure, uses the entire image for the middle grey and dynamic\nrange, and the darker area for the black exposure. This should give nice\nresults.\n2018-09-29 14:07 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nHi Edgardo,\nThanks for your test. I'm a bit surprised, since I get that module to work\nin just a few steps. What sort fo artefacts do you get ? Have you followed\nthe tutorial here: https://discuss.pixls.us/t/solving-dynamic-range-\nproblems-in-a-linear-way/9006/63?u=aurelienpierre\n3. I managed to get rid of the artifacts, now I can play, but is not that easy to restore the contrast/saturation. OK, that is maybe because of my editing skills, but at least in part I think is because all the things I have done to get rid of the artifacts.\nKeep in mind that my other PR #1734\nhttps://github.com/darktable-org/darktable/pull/1734 is intended to be\nexactly the next step to this module. With the fulcrum contrast and the\npower (mid-tones) adjustement, I do 80 % of the editing in 30 s with just 2\nmodules.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1730#issuecomment-425660377,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUkmuX3SkmIiscLMK2FxCBrfsXxrks5uf6jhgaJpZM4WxJG5\n.\n. I did some more testing and it is a gamut issue.\n\nOn an image with no clipped nor out-of-gamut areas I select the entire image for middle grey and dynamic range and the darkest area for black exposure.\nI get some out-of-gamut areas.\nI can't say if this is a problem or not, you know more than me on this subject, but if I use the levels, contr-brigh-sat or tone curve in lab I get artifacts. I have used those modules with out-of-gamut input with no artifacts, so something is different here.\nI also know that those modules make assumptions on the input data and they shouldn't, so maybe a rgb mode should be added to them (the tone curve already has it)\n . OK, but a warning will be nice, maybe a label \"you have x pixels out-of-gamut, decrease the black level\". \nAlso the auto button will be nice, I'll probably use the same workflow for most images, so if it can be automated it will be great. And it will free the exposure for other uses, right now if I create a new instance it will mess with the edits.\n. -The label should be updated only when a setting has changed, and run only\non the preview pipe, so performance won't be an issue. You can have a CPU\nfunction that go though all the image and count the pixels, since there's\nuser interaction it won't probably be noticed.\n-For the auto button, maybe decreasing the black level until there's no\nout-of-gamut pixels? That's my goal anyway. Or having a slider with a\npercent of out-of-gamut pixels allowed. This is again user interaction, so\nperformance is not an issue.\n-The position in the pipe is more important to me anyway, this forces me to\nhave only one instance of the exposure and to use it only to set the black\nlevel. That's a big restriction.\n2018-09-29 21:52 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nmaybe a label \"you have x pixels out-of-gamut, decrease the black level\nThat would suppose to count the underexposed pixels during the processing\nloop. I see how to do that in pure C but, in OpenCL, it would need to parse\nthe whole image before or after the processing, so it would defeat the\npurpose of vectorizing for performance. I have to think about that\u2026\nAlso the auto button will be nice\nI tried to do that at first, the problem is, as the black level\nauto-detection is super sensitive to noise (no algo can guess if a low\nvalue is noise or a true black), I often ended up tweaking the \"optimized\"\nauto-computed parameters anyway, so I just removed the full auto mode and\nwent for a trade-off where you give the algo hints of what is black and\nwhat is grey. I feel it's better to give that responsibility to the user\nrather than creating frustration with a partially-working auto mode.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1730#issuecomment-425685050,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pV78UmCd1SxHrVfuusomM7JLKiXuks5ugBXZgaJpZM4WxJG5\n.\n. The idea of the auto button was based on this module to be moved before the\nexposure, and the black and exposure setting added to this very module, so\nthe can also be optimized. That's obviously not going to happen, and with\nthis current version, as you already said, results can be not good, so\nnever mind.\n\n2018-09-30 3:10 GMT-03:00 Aur\u00e9lien PIERRE notifications@github.com:\n\nI have added a full auto button, for the better and the worse.\nI still have to find out in which structure is hidden the roi_in piece so\nthat I can parse it in commit_params function.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1730#issuecomment-425697480,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1paHLefMF9aQbQv8YkqBIo_HVd99zks5ugGBigaJpZM4WxJG5\n.\n. @theres , if you have the time to check it, let me know if this is the expected behaviour for you.. > -if (operation, multi_name) already exists on dest image, it replaces it\nCan you clarify this. Does it means that this takes into account the\nmodule renaming?\nYes, the name enter by the user and the one generated by dt when creating a\nnew instance.\n. Is working fine for me, on my test 5 is not a second instance, the modules\nlist show only one instance of xyz, and if I create the 3 instances on a\nfresh image I get the same result in terms of exposure.\n\n2018-09-21 5:21 GMT-03:00 Pascal Obry notifications@github.com:\n\nOne issue found:\n\non image A add exposure + 4, rename module to \"xyz\"\non image B add exposure +1, add a second exposure instance and set\n   black level to -.1\ncopy B history (ctrl-shift-c), select both exposure modules\n   (\"exposure\" and \"exposure 1\")\npaste on A (ctrl-v)\nopen A, the history is wrong:\n\n7 - exposure 1\n   6 - exposure\n   5 - exposure xyz\n   4 exposure xyz\n4 is ok, the it exposure +4 added on A\n5 is wrong it is a second exposure instance with +4 expo making the image\nexpo to +8!\n6 & 7 are ok and are the modules copied from B\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423454255,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfM8JDU7-yVdj_0MQxbPEwJjuOCzks5udKF2gaJpZM4WzZfr\n.\n. OK, I didn't understand what @TurboGit https://github.com/TurboGit was\nsaying, but yes, if you go to entry 5, the module is duplicated. I don't\nsee any other way to do it if we want to be able to go back in history (and\nnot modify the existing history)\n\nLet me give you and example of how it works, it may help with the test.\noperation, multi_priority and multi_name are the fields on the main.history.\n-operation is the name of the module, like exposure or shadi\n-multi_priority identifies an instance of the operation, it starts at zero\nand is read in reverse order, so multi_priority zero is last on the pipe\n-multi_name is a string that is displayed with the module name, internally\ndt don't care about it.\nlet's say we have an image with (operation, multi_name, multi_priority) =\n(exposure, 'xyz', 0), and we paste it into an image that has (exposure, '',\n1) (exposure, '1', 0)\nIf we only copy (exposure, 'xyz', 0), it will replace (exposure, '1', 0),\nbecause both have the same multi_priority. That's not what we want, so,\nbefore inserting the copied history I duplicate (exposure, '1', 0) but with\na new multi_priority, so it says (exposure, '1', 2).\nRight now we have a duplicated instance of 'exposure 1', and yes, is not\npretty.\nWhen I insert the copied entries, (exposure, 'xyz', 0) will replace\n(exposure, '1', 0), so we no longer have duplicated instances.\nI agree that the history gets confusing, but the alternative is to modify\nthe multi_priority in the existing history, in the example: to change\n(exposure, '1', 0) with (exposure, '1', 2). But then this can't be undone.\n2018-09-21 19:44 GMT-03:00 Dominik Markiewicz notifications@github.com:\n\n@edgardoh https://github.com/edgardoh nice once again!\nI've test it only roughly and I'll do some more testing in next couple of\ndays. It seems to work as I would expect in principle, although issue found\nby @TurboGit https://github.com/TurboGit exists. To be more\ndescriptive: you don't have doubled module if you are on top of history\nstack. But If you in this scenario select entry 5, you can see that you\nhave two modules xyz and doubled exposure. So this entry seems to be a\nbit suspicious ;)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423689917,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdoH_kvBvemTESMJNyMF9Ij3gCYqks5udWvEgaJpZM4WzZfr\n.\n. Yes, but this changes the definition. Pasted instances will go first on the\npipe, and won't be together, the ones that replaces an instance will keep\nthe current position on the pipe.\n\nThe option on the copy/paste says \"append\", that's what my version does.\nYours is more like a \"merge\", if you check the code that's the name of the\nvariable!\nMaybe add a new option \"merge\" on the copy/paste and have both behaviors?\n2018-09-22 4:16 GMT-03:00 Pascal Obry notifications@github.com:\n\nBut instead of duplicating the (exposure 0) why not change the priority of\ncopied exposure history for them to go on top of the existing one?\nyou have (dest):\nexposure 0\nyou've copied (from):\nexposure 0\nexposure 1\nLet's change the copied history to:\nexposure 1\nexposure 2\nPaste them into the destination, so we have:\nexposure 0\nexposure 1\nexposure 2\nWould that work?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423723258,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pTESYpt8WCGDsIMxJ3mLqBsZPlhbks5udePWgaJpZM4WzZfr\n.\n. > I'm not really following. I don't see why I'm proposing a \"merge\" instead\nof an \"append\". In my point of view my proposal is really an append. I just\nwant the two copied exposure instances to be added.\nWhat I still don't see is why do you have/need a duplicated \"xyz\" exposure\nin:\n7 - exposure 1\n6 - exposure\n5 - exposure xyz\n4 - exposure xyz\nOr maybe because 6 is *replacing\" 5 ?\nExactly that! In my version, if I don't insert 5 - exposure xyz, then\nexposure (or exposure 1, not really sure now) will replace exposure xyz.\n\nThe difference, in terms of end result, between my version and yours, is\nthe position on the pipe and the order of the pasted instances.\nWith your example and my version, if you check the modules list you will see\nexposure 1\nexposure\nexposure xyz\nsince the pipe reads it from the bottom, exposure and exposure 1 are last\non the pipe.\nOn your version you will get (still on the module list)\nexposure xyz\nexposure\nexposure 1\nHere exposure and exposure 1 are before on the pipe than exposure xyz\nYou can try it by playing with the database:\nINSERT INTO main.history (imgid,num,module,operation,\nop_params,enabled,blendop_params,blendop_version,multi_priority,multi_name)\nSELECT 189,num,module,operation,op_params,enabled,blendop_params,blendop_version,1,multi_name\nFROM main.history hist1 where hist1.imgid=190 and hist1.num=3\nINSERT INTO main.history (imgid,num,module,operation,\nop_params,enabled,blendop_params,blendop_version,multi_priority,multi_name)\nSELECT 189,num,module,operation,op_params,enabled,blendop_params,blendop_version,2,multi_name\nFROM main.history hist1 where hist1.imgid=190 and hist1.num=4\nhere 189 is the destination image id and 190 is the source image id\nStill on your version, when an instance already exists in the destination\nimage, it will be replaced but it will keep the multi_priority, and since\nthe multi_priority gives the order to process the pipe, the pasted\ninstances won't be together, that's why I say it behaves like a merge.\nOn my version, pasted instances are together, but for that to happen I have\nto modify the multi_priority, and since I don't want to modify the history,\nI insert the duplicated instance with the new multi_priority.\nI think that we both agree that the history on the dest image should not be\nmodified, so as I see it the question is, what do we do about the order and\nposition on the pipe for the pasted instances?\n. I don't think we can avoid creating the duplicated instances, or at least I\ndon't see how it can be done. If we don't do that the result will be\nsimilar to the current behavior.\nOf course I see your point, but I don't object the creation of the extra\ninstances as much as the display. The history get really confusing and\nthere's really no way to tell where the pasted instances start (or what the\nhell the extra instances are doing there!)\nSo my proposal is this: how if we add the option to group the entries on\nthe history? This way when pasting/applying a style we'll have a single\nentry \"pasted from image xxx\" or \"style xxx\". We can also have a group\ninside that group with the extra instances, all disabled, so they don't\naffect the image even if they are selected. If the user want to see what\nwas pasted the group can be expanded.\nThis way we have a cleaner history that now, and more information on what's\ngoing on.\nWhat do you think?\n2018-09-24 9:01 GMT-03:00 Pascal Obry notifications@github.com:\n\nI think that we both agree that the history on the dest image should not\nbe modified,\nI 100% agree.\nso as I see it the question is, what do we do about the order and position\non the pipe for the pasted instances?\nRight. Your version is right and I don't want to change the final\nresult/semantic.\nMy point is only of the duplicated instance. You do that to avoid a pasted\ninstance to replace a current existing one. The goal is 100% correct, but\nI'm questioning the way it is done. I would like to avoid this duplicated\ninstance if possible. My idea was to change the multi_priority values of\nthe pasted instances to achieve the same goal (not replacing a current\ninstance) but without the duplicating which makes the history wrong at some\npoint. In my example (#1731 (comment)\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423454255)\nif you click on 5 in the history you get the double exposure of the 4\nhistory.\nMaybe my proposed solution is wrong, but again if we can avoid this\nduplication it would be good.\nDo you see a solution to this? Or was your proposal the only solution?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423951267,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcuOo3odXvPypxmDJLn-aWfoOLR6ks5ueMmfgaJpZM4WzZfr\n.\n. Yes, it affects the database, xmp, pipe. All very sensitive places.\n\nNot sure what you mean by this cannot be integrated. If I cannot make it\nwork for any reason, I can take that chance, won't be the first time I try\nsomething that eventually don't work.\n2018-09-24 9:59 GMT-03:00 Pascal Obry notifications@github.com:\n\nThis way we have a cleaner history that now, and more information on\nwhat's going on.\nWhat do you think?\nThis sounds like a quite big change. We need to think more about this\nbefore starting, I mean I don't want to loose your time if this cannot be\nintegrated!\nYour proposal need a change in the database schema for example.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423965839,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pY9PMRlJRQzlXQqqakrhIpJDSEYBks5ueNc0gaJpZM4WzZfr\n.\n. OK, in that case we can leave this in stand by until a decision is made.\n\nJust to start the discussion, all this is because the multi_priority field\nis used to ID an instance and also to give the order in the pipe. If we had\nseparate fields for that we probably won't need the extra instances in the\npaste, and will also give a cleaner code/implementation in other places.\nThis is a even bigger change, but maybe is worth to think about it.\n2018-09-24 10:26 GMT-03:00 Pascal Obry notifications@github.com:\n\nNot sure what you mean by this cannot be integrated.\nWhat I mean is that such a large, intrusive and user visible change must\nbe more generally discussed with other developers. I cannot take the\ndecision to merge this myself. So if some are not ok with this it won't be\nmerged even if working. So be warned :)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423973477,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peHtJRFCGlDTXjPkeyCvvSPwPjkDks5ueN1vgaJpZM4WzZfr\n.\n. Splitting multi_priority into instance_id and instance_order (with\nascending order) will make:\n\nOn the copy/paste:\nif the instance is a new one, just add it with a new instance:id and\ninstance_order=MAX(existing instance_order)\nif it replaces an existing instance, just replace instance_order (and all\nthe module values)\nOn delete an instance:\nif there's more than one instance, just delete it\nif is the only instance, disable it and default all the parameters\nwe still need to reflect this in the history, if history_type is added, we\ncan define a HISTORY_TYPE_IOP_DELETED\nOn add an instance\njust add it with a new instance_id and instance_order=MAX(existing\ninstance_order)\nOn move up and down\nthis still need two actions, as it change the instance_order on two\ndifferent instance, so even if we add two entries in history, if the user\ngo to the first one it will result on two instances with the same order. we\nshould think more about this case.\n2018-09-24 11:11 GMT-03:00 parafin notifications@github.com:\n\nChanging the order won't fix mentioned functions. They probably break\nhistory semantic ATM (you can't go back to previous state).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-423988614,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pf5ZYyh63h5BBI29hvZc-jQ9Vfwmks5ueOgqgaJpZM4WzZfr\n.\n. Splitting the multi_priority will also allow to go back in history in all other re-ordering functions, but I get that is a very intrusive change, and may not be worth for this.\n\nChanging the history will make this consistent with the other re-ordering functions, as pointed by @parafin , so fine with me.\nBut we are changing the history, so before doing anything let's make sure everybody agrees with it.\n. Actually, giving it more thoughts, I like your proposal better.\nBy just shifting the multi_priority of the history we'll make all the copied entries a new instance, and the current history is not re-ordered.\nI sometimes want the existing modules to be replaced when copy/paste or apply a style, but far more often I want a new instance to be created, or in other words, I want to apply an effect on top of my edits, not to replace some of them.\nAnd since the history is no re-ordered, the user can go back in history to the previous state without the auto-generated instances of my current approach. \nSo for me is a win-win.\n. I was just agreeing with your proposal, no idea still what's going to be\ndecided. But we can't have both, either always replace the instances by\nmulti_name or always create new instances.\nOK, we can create a new entry in lighttable copy/paste mode: \"append\",\n\"merge\", \"replace\"\nEl s\u00e1b., 6 oct. 2018 a las 3:51, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh, well be careful we still want to\nsupport the following scenario:\n\napply a module (exposure +1 for example) to a picture\ncopy this exposure to say 100 pictures\nfinally change the value of the module in step 1 (exposure was too\n   high, let's use +0.5)\ncopy this new exposure to the same 100 pictures\n\nThis is a very common scenario where 4 must replace the value set in 2.\nGoing back to the 100 pictures (and sometime far more) is not an option\nhere.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-427551445,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRnHTiZW5TsvSQ53HuhNHgTcHjw0ks5uiFLbgaJpZM4WzZfr\n.\n. This last commit should be the closest possible to what we have now. I have updated the first post to reflect the changes.\n. It seems to be related to this:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/history.c#L580\n\nThe paste is obviously slower than before (you've seen the code), but it\ntakes a long time on the dt_image_set_aspect_ratio(), maybe that can be\ncalled after the paste, asynchronously somehow?\nEl vie., 9 nov. 2018 a las 8:45, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nDoing a copy of 5 module in an history and applying to a set of 100 images\ntakes a very long time. Maybe we can improve that before the release?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1731#issuecomment-437336280,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVTAKwj3lsOOTtK3znLhdUMn8jSzks5utWrEgaJpZM4WzZfr\n.\n. I've playing with this as well, very nice! Results are very good and is very easy to get them.\nMaybe add a combo with lift/gamma/gain/(all) so it doesn't take so much space on the UI?\nAlso, is it possible to have a new group for the entire range (not only shadows/highlights/midtones)? Sometimes I like to create a color cast and then play with each range in particular.\n. > Maybe add a combo with lift/gamma/gain/(all) so it doesn't take so much\nspace on the UI?\nYou mean on the text label ?\nI mean to add a combo box with those entries that show/hide each group (or\nall of them if (all) is selected)\nAlso, is it possible to have a new group for the entire range (not only\nshadows/highlights/midtones)?\nLike a master hue setting ?\nExactly. It can be added to the combo box above, maybe as a default.\n. > I mean to add a combo box with those entries that show/hide each group (or\nall of them if (all) is selected)\nI still don't understand \ud83d\ude01 You want to selectively enable/disable the\nRGB set of sliders and the HSL ones ?\nNot disable but hide it, kind of what the channel mixer does, but with the\noption of displaying them all. But if you're not going to add the master\nhue, I can live with all the sliders visible, they fit in my screen anyway.\n. May I point that this can break backwards compatibility?\n\nhttps://github.com/darktable-org/darktable/pull/1734/files#diff-66d4f98e149ad915383f3c1cd14d7a46R213\nEl mar., 16 oct. 2018 a las 10:45, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nMerged #1734 https://github.com/darktable-org/darktable/pull/1734 into\nmaster.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1734#event-1906855498,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pT90fhLTUPbWT9MvH1tFqK6GLhEiks5uleL0gaJpZM4W1fED\n.\n. I have shortcuts for each shape and I use them to add the masks, but I like\nthis feature more. I like being able to see where the source will be\ncreated and being able to change the position if needed, and having my left\nhand free and not need to press a key for each add makes a difference to me.\n\nThis feature has been requested several times, so I'm sure I'm not the only\none that find it useful.\n2018-09-25 4:16 GMT-03:00 Pascal Obry notifications@github.com:\n\nIf I agree that this can be useful for the retouch module it is also the\ncase for the spot removal module. But there I'm using a key to add circle\nand I find that having a handle on the keyboard and one to place the spot\nwith the mouse is just good. So all in all I'm not sure the extra\ncomplexity here is really needed. Better to add a key binding for the\ndifferent tools? Have you tried?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1735#issuecomment-424233039,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVHeflXatZYg3T3CRZYZ2kscMVkEks5uedhFgaJpZM4W3UCT\n.\n. I made only one PR for both because the keep adding without the possibility\nof selecting the source position don't make much sense with the path and\nbrush, those cannot be drag, and adding multiple shapes and then change the\nsource for each one is not practical.\n\nFor me the cross works fine indicating the position where the source will\nbe created, but I forget to comment on the following issue:\nTo define the position one has to place the mouse pointer on the desired\nposition, not the cross. It feels more natural and also with the circle and\nbrush it gives an idea of the area covered by the future mask. But the\ncross remains in the same position, and I would like it to be under the\nmouse, but I couldn't do it. I can't read the keyboard state when only the\nshift or control are pressed. It seems that gtk sends a different code than\nthe shift or control, and dt filter that codes, so a zero is propagated on\nthe events. I couldn't find a way around this.\n2018-09-25 11:34 GMT-03:00 Pascal Obry notifications@github.com:\n\nI tied it, and found the view of the source not easy to use. I do prefer\nthe click on the dest and drag to the source the mouse.\nI would certainly split this in two PR. The first for the keep adding and\none for the view of the cross (source created).\nNote that the cross in the relative position does not seems to be\ncorrectly placed when using the relative mode. The absolute mode looks ok.\nTrying again to see if we can found a pattern... but now I cannot reproduce.\nIf we go with that we probably want the very same behavior in the spot\nremoval module (keep adding).\nBTW, I'd love to have feedback from more people, so if you are reading\nthis... :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1735#issuecomment-424367748,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pehi6kAH94WKLObI7zSeW0h_nAeXks5uej7ugaJpZM4W3UCT\n.\n. Hi,\n\n\nI didn't draw the source because I thought it will be distracting, and I\ndidn't want to change the interface that much, but I don't use GIMP, so if\nin your experience is better and everybody agrees I can add it.\nI can do that.\nI cannot duplicate this. The continuous mode is exited with right-click,\nclick on the shapes toolbar or with the shortcuts, maybe you hit some of\nthat by accident?\n\nNo idea how LR works but before deciding on this healing I have tested some\nothers that do not require a source and I liked this one better. Maybe some\nother algorithm can be added, but finding one with good performance/results\nratio won't be easy.\nBut before doing any work let's first be sure that this will be accepted.\nI'm not sure I understand, you are saying that shortcuts don't work well\nwith multiple instances in general or just on the retouch module?\n2018-09-25 17:31 GMT-03:00 Dominik Markiewicz notifications@github.com:\n\nHi, I'd like to put my two cents.\n\nGimp shows outline of source shape with cross in the middle, I like\n   this a bit more, because cross is not always good visible.\nWhen using brush tool in absolute mode cross stays in the same\n   place while drawing. In Gimp it follows a mouse and return to the initial\n   position after button release - this also is a bit user friendly imho.\nIt sometimes escape continuous add mode, not sure when, seems like\n   a bug.\n\nAnyway, I personally like it. Quite useful for skin retouch and spot\nremoval when background is uniform (like sky). Similar to what Gimp and\nPhotoshop do for clone and heal tools.\nFor simple spot removal/heal, I'd love to see something more like in\nLightroom - it just tries to automatically find best matching source spot\n(could be probably realized by something similar to searching in\nPatchMatch, at least for small spots)\nPS. module shortcuts do not work well with multiple module instances now,\nso usage may be limited.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1735#issuecomment-424490933,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUD3E1PmxZ-ftlEo4DbrHuuAWCgCks5uepKugaJpZM4W3UCT\n.\n. Great, I'll start working on point 2, and leave point 1 until I have more\nfeedback.\n\nAbout the spot removal, we seem to have different views on that. For me is\nnot a good idea to duplicate code/functionality, and thre's no real\nadvantage here, if the user wants a feature that is not present on the spot\nremoval he/she can always use the retouch.\nThe easiest to do the port it is to copy the retouch.c into the spots.c and\nremove the wavelet decompose (and maybe the blur and fill), but again, it\ndoesn't seems right to have that duplicated.\nThat being said, I don't mind doing that work, but in that case let's wait\nuntil the retouch is better tested and we are confident that there's no\nmore functionality added (I may have a couple on my todo list) . I don't\nwant to copy it over and over.\n2018-09-27 10:45 GMT-03:00 Pascal Obry notifications@github.com:\n\nI did a second pass and I'm starting to understand and appreciate the\nusage.\nTo me here is what is missing:\n-\nindeed the point 2 above, trace for the brush would be nice\n   -\nif I'm not mistaken the only other place where we have a clone is on\n   the \"spot removal\" module and I would like to have the same behavior here.\n   It would be a shame to have two cloning tools working differently and not\n   supporting the same level of usage. As you already have the cross and\n   relative/absolute position of the source in \"spot removal\" it just remains\n   the multiple clone support.\nI did a first pass on the code and don't have comment, sounds just correct\nto me.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1735#issuecomment-425098139,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQq6Odhpglo2K8uuOEcmYs68o10aks5ufNZggaJpZM4W3UCT\n.\n. Now the cross follow the mouse while adding in absolute mode\n. When in continuous add if the shape type is changed the cross will go to what seems a random position until the mouse is moved, then it returns to the correct position.\nThis is because the mouse position in the masks module is reset each time a mask is created. This last commit fixes it.\nAlso, when a mask is created, the preview is always displayed on the center of the image until the mouse is moved. Now it will be displayed under mouse, if the mouse is outside the darkroom area it will be in the center as it is now.\n. Fixed. It happens when selecting/changing the algorithm.\n. -4 means out of resources, that can happen, but for a given image it should\nhappen every time it is exported, and dt should fallback to CPU and things\ngo normal from there. If it is only after a while of using dt it could mean\na memory leak somewhere.\nOne way to try it is to copy that same edits on a large number of images\nand export them several times.\n\nAlso that message don't necessarily means that the retouch is crashing dt,\ncan be any other module. I take that a backtrace is not being generated, so\ntry to generate one. You can find how to do it in:\nHow to produce a backtrace\nhttps://www.darktable.org/development/\nIf you share the xmp that get you the error I can do some tests myself.\nEl mar., 2 oct. 2018 a las 2:49, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nHi,\nI don't know if this is this commit or another, but it seems that the\nretouch module is crashing sometimes in OpenCL mode.\nWhat seems to be the source is having several masks overlapping, mixing\ncorrecting and blurring masks makes it worse. It doesn't happen everytime,\nbut when it does, the terminal says could net enqueue kernel [retouch] :\n-4. Also this error makes the whole desktop UI freeze hard (hard reboot\nneeded).\nNo problem in CPU mode.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1735#issuecomment-426156503,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peOuGxVMFJRVd71Z2tXfPGpXZZqqks5ugv5egaJpZM4W3UCT\n.\n. >\nIt's only since I have merged this PR with my dt's master fork that I have\nhad this error,\nTry to duplicate the issue with the official version, not your fork.\n. Works good to me.. It should be possible to define the priorities at run time instead of having it hard-coded, this way, at least for advanced users, the position of a module on the pipe can be changed (at user risk, of course).\nIt probably also allow to re-use the iop source files. Right now we can't create another instance of a module because it will have the same priority, but if the priority is defined at run time we can just add another instance on a different position.. You're right, this should fix it.\nI also fixed a bug, I edited my first post with it.\n. -Add 3 instances of exposure on any image.\n-While in darkroom go to another image (double click on film strip)\n-enable exposure\n-go back to the first image\n-demosaic is between the exposure instances\n-change images several times and it makes a mess\n\nif you go to lighttable and back to darkroom the order is restored.\nEl jue., 11 oct. 2018 a las 4:14, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nCode looks good but I cannot reproduce the issue. Do you have a step by\nstep way to check this? Thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1743#issuecomment-428846575,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pbW6-ydOdBMcZnJtOHwIf11Jlimjks5uju-_gaJpZM4XMFgi\n.\n. I tested a bit and it works ok to me. The only issue I've found is when changing the orientation on lighttable the order is not updated.\nIf I change the orientation or crop on darkroom and then go to lighttable the order is updated. If I discard changes on lighttable the order is also updated.. All good now.. And is getting in the way even when creating the path, not only for the first node. Too bad, I like the cntrl+click for this.\n\nThe middle click doesn't feel comfortable to me, maybe lack of use or maybe my mouse.\nI did make a quick try with the GDK_MOD1_MASK but it has no effect, maybe the alt key is reserved for something?\nIf not the alt key maybe we can use the right-click + cntrl | shift, but since the right-click alone is used for cancel the add it can be kind of confusing.\nClearly we are running out of keys!. I did, but if it works for you I can investigate later what happen here.\nFor me is either the Alt or the right-click, what do you think?\nEl mar., 16 oct. 2018 a las 19:04, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWorking for me, you need to also add the support for it in masks.c\nin dt_masks_set_source_pos_initial_state:\nif(state & GDK_MOD1_MASK)\n    gui->source_pos_type = DT_MASKS_SOURCE_POS_ABSOLUTE;\n  else if(state & GDK_SHIFT_MASK)\n    gui->source_pos_type = DT_MASKS_SOURCE_POS_RELATIVE_TEMP;\n  else\n    fprintf(stderr, \"unknown state for setting masks position type\\n\");\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1754#issuecomment-430417474,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXBkbamydf_FfYfkSw33jV6UqSugks5ullf4gaJpZM4Xh5PB\n.\n. @aurelienpierre , now right-click, with or without modifiers, cancel the add, but that can be fixed. \nThat feature has already been requested, and yes,  it would be great, but there's a couple of issues:\n-when adding a shape we don't have access to the image, so the calculation should be done asych, not sure how to achieve that.\n-the \"best\" source needs to be a clean area with a texture that is good to cover the destination area, I don't know how to define that, is quite different as how denoise algorithms select a patch.\n\nYet another option is cntrl+shift, so shift set the relative source and cntrl+shift the absolute one. It can work.\n@TurboGit , BTW this was my mistake, if you want I can work on it.\n. I've been playing with this and the new color balance and they work very nice, thanks @aurelienpierre !\nThe only thing is the color pickers, I assume that they work like this for performance reasons, but it would be nicer if values are updated when the user finish drawing the area. Also the buttons could be state buttons instead of push button, to have a visual clue of what is being defined. This will be more user-friendly and closer to how other modules work.\n. I think we are saying the same thing, what I want is the values to be\nupdated only when I have finished drawing the rectangle, but without the\nneed of pushing the button again.\nNow if I'm not happy with the results I have to push the button again, draw\nthe area again and push the button once again, and so on... what I propose\nis to draw the area, values are updated, if I draw another area values are\nupdated again, etc.\nEl s\u00e1b., 20 oct. 2018 a las 15:28, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nThanks @edgardoh https://github.com/edgardoh !\nbut it would be nicer if values are updated when the user finish drawing\nthe area\nI don't know, I really don't like having values updated as soon as I draw\nstuff and before I'm done drawing, especially with huge RAWs. But state\nbuttons are a good idea, I have to check how to do that.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1755#issuecomment-431606846,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pepgD-1nid-OgA5F6EKzyW0K76Erks5um2tdgaJpZM4XkNY0\n.\n. If you don't mind I can give it a try, I'll probably have some time until I\nget an answer to my question on pixl.us\n\nEl s\u00e1b., 20 oct. 2018 a las 17:16, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nNow if I'm not happy with the results I have to push the button again,\ndraw the area again and push the button once again, and so on... what I\npropose is to draw the area, values are updated, if I draw another area\nvalues are updated again, etc.\nhmm I have no idea how to do that.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1755#issuecomment-431614747,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUZtOMEb6V2T29NCDvM8KnsiozVKks5um4SsgaJpZM4XkNY0\n.\n. I'm also having a gtk assertion here:\nhttps://github.com/darktable-org/darktable/blob/master/src/iop/rawdenoise.c#L958\nnot sure why. > @edgardoh https://github.com/edgardoh : I think I have fixed this issue.\nYes, I can't replicate it anymore. Thanks.\n. It should only affect the clone masks and the absolute position. When\ncreating a clone mask on the retouch, to set the absolute position\nSHIFT+CONTROL - click on the desired position. From that moment all new\nclone masks will have the source at that position.\n\nEl s\u00e1b., 20 oct. 2018 a las 17:18, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nI'm testing that right now, how/where is it supposed to work ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-431614858,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peNWWcgLMG1jmXAihM6P36rkNNv1ks5um4UOgaJpZM4XroC5\n.\n. I forget, with only SHIFT pressed it should set a relative position. From\nthen, all masks will have the source at the same relative position than the\nfirst one.\n\nEl s\u00e1b., 20 oct. 2018 a las 17:28, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nI see now. It's really nice \ud83d\ude00\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-431615583,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZEObF8w_MCanpsvvtCJC8KFTpN2ks5um4dhgaJpZM4XroC5\n.\n. Works fine for me.\n\nEl mar., 23 oct. 2018 a las 16:09, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nI don't know where to dump that (maybe we should enable Github issues\ntracker), but I have a small problem with the drawn masks in the retouch\nmodule, in healing mode:\n\nrequest the brush tool\nadjust the size of the brush to be really small\nbegin to paint : the size is automatically increased as soon as we\n   click. The only way to get very fine brush lines is to resize the size\n   (Shift + Scroll) after the drawing.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-432380157,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSpU7fssNrV92JFj8pZYEqrrgrPvks5un2mBgaJpZM4XroC5\n.\n. You'll have to be more specific on how to duplicate it.\n\nEl mar., 23 oct. 2018 a las 18:34, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nspeaking of which, @edgardoh https://github.com/edgardoh, I have\nanother editing stack that makes the whole OS crash:\nPicture:\nhttps://www.dropbox.com/s/jijut3baqifvhe5/mckayla-keiferhunnifordphotography.NEF?dl=0\nXMP:\nmckayla-keiferhunnifordphotography.NEF.zip\nhttps://github.com/darktable-org/darktable/files/2508086/mckayla-keiferhunnifordphotography.NEF.zip\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-432428963,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUo8ZBR6qyginfhu3IEdcOBknih5ks5un4t9gaJpZM4XroC5\n.\n. Works fine for me.\n\nEl mi\u00e9., 24 oct. 2018 a las 0:40, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nYou'll have to be more specific on how to duplicate it.\nJust export the picture in JPEG on the disk, with the XMP stack provided.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-432501429,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXZF7mP1nDzZwkud0HRVp61Qtmzcks5un-EZgaJpZM4XroC5\n.\n. The retouch have a printf() to display that error, other modules have\ndt_print(DT_DEBUG_OPENCL...), so it may happen on other modules and its not\ndisplayed.\nThis is just to get some feedback, I'll change it eventually with the\nproper dt_print().\n\nBut to the point, -4 is out of resources, so it depends on the resources\navailable and how much is needed by the retouch, nothing I can do about it.\nMost modules use a tiling process that consumes less memory, but the\nhealing cannot be tiled, so that is not an option.\nWhat I would like to do is to tell dt how much memory is needed so if\nthere's not enough it can fall back to cpu without the error message,\nthere's something like that for tiling, but I don't know if it can be used\non non-tiled operations.\nEl mi\u00e9., 24 oct. 2018 a las 20:03, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nIt seems that the crash was related to the OpenCL masking thing you\nmentionned elsewhere and solved by #1770\nhttps://github.com/darktable-org/darktable/pull/1770.\nHowever, on the first retouch module (with gaussian blur patches), I\nalways get:\n340,530509 [dev_pixelpipe] took 0,165 secs (0,210 CPU) processed retouche 1' on GPU, blended on GPU [export]\n[opencl_retouch] couldn't enqueue kernel! -4\n347,314161 [dev_pixelpipe] took 6,784 secs (14,076 CPU) processedretouche' on CPU, blended on CPU [export]\nThe retouch 1 instance only contains healing spots.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-432857260,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pR-C9YFGR1Sp-m0ihLv6FOrmK2gFks5uoPGugaJpZM4XroC5\n.\n. I exported the last picture you send on full res with no errors, but I'm no\nexpert on opencl so I can't say what to check.\n\nEl mi\u00e9., 24 oct. 2018 a las 21:10, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nBut to the point, -4 is out of resources, so it depends on the resources\nI know. I wonder if others get the same error on the same picture + XMP.\nOut of ressource on a Nvidia Quadro with 4 GB RAM seems suspicious to me,\nthat's all.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-432869345,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pS9SRMZc1VOE48pZ-4X8UUv72NJuks5uoQFsgaJpZM4XroC5\n.\n. Thanks, I didn't see it.\n\nEl mi\u00e9., 28 nov. 2018 a las 14:53, Matthieu Moy (notifications@github.com)\nescribi\u00f3:\n\nIn case you've missed it, @edgardoh https://github.com/edgardoh,\nthere's an issue with the cross showing the source of the clone in case of\nrotated image (orientation = portrait or crop and rotate):\nhttps://redmine.darktable.org/issues/12424. Other shapes are properly\nrotated.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1756#issuecomment-442542288,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pd6BkxxY24nqG8-BCRbU3nNLWI1lks5uzs2ogaJpZM4XroC5\n.\n. I've found a couple of issues, \n\n-if I go to darkroom, change orientation and go back to lighttable the order is not updated, but if I go again to darkroom, do nothing and go back to lighttable the order is updated.\n-if I discard the history the order is not updated, but if I go to darkroom, do nothing and go back to lighttable the order is updated.\n-when I first selected the aspect ratio order it did something, but I'm not sure what, I had mixed orientation in random positions. I have removed all the images and re-imported and now it works fine, I'm not sure if this is an issue or something wrong with my database.\n. All good now, thanks.. There's an issue with the display mask:\n-activate color balance\n-with opencl active set a parametric mask on base curve\n-display mask\nwith cpu seems to work fine\n. The base curve was just an example, it can be reproduced with any other,\nlike exposure.\nProbably the opencl version is messing with the mask channel, but I haven't\nchecked the code.\nEl mi\u00e9., 24 oct. 2018 a las 12:03, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI can reproduce indeed! Really strange the bad interaction between both\nmodules.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1767#issuecomment-432695726,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcWu7SmpZ2ZlcsosL_X627Iz3bYHks5uoIFbgaJpZM4Xz2Nz\n.\n. OpenCl don't complain about changing a const?\n\nhttps://github.com/darktable-org/darktable/blob/master/data/kernels/basic.cl#L2192\n. Kind of defeats the purpose of using a const.\nEl jue., 25 oct. 2018 a las 9:56, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nIndeed, not even a warning.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1770#issuecomment-433039806,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVV5gQjbWsklyUHm-iN8fGgkRrMuks5uobUZgaJpZM4X4s1X\n.\n. I don't get segfaults when creating a path (or any other mask), can you describe how to duplicate it?. >  some random/artistic effects\nI didn't close my eyes and flip a coin to decide which GMIC filter to\nport, much less if share it or not. I've been using it for a while and I\nfind it very useful, and I'm running under the assumption that there's\nsomeone out there with similar editing styles/taste than me.\nif we don't want to have a generic effect like IOP and a combobox to\nselect the effect. Not sure, just starting a discussion in this direction.\nWhat would be the pros and the cons?\nDifferent filters may need different places in the pipe, so only one IOP\nwon't do it. Also, dt only allow a fixed number of controls, so probably a\nredesign will be needed there.\n. > @edgardoh https://github.com/edgardoh : sorry I didn't intend to say\nthat you've randomly chosen a GIMIC filter, only that such filter and many\nin GMIC are kind of random in the sense of you do not use it to achieve\nsome precise goal as you can't really guess what will happen on the picture\nbefore hand really. With this module for example you drag some sliders and\nsome effect are coming and passing and even at some point you seem to have\nglobally the same effect with different values of the same slider. That's\nwhy I call this random. Hope this clarifies my thinking :)\nNon taken ;), I'm sure that by now you know that I don't share things just\nfor the fun of it, I just wanted to be clear for a casual reader, sorry if\nit sounded harsh.\n\nIn a way you're right, the effect is unpredictable, and it very much\ndepends on the image (and the crop), that's why I have 6 modes. But the,\nlet's say, effect of each slider is well defined: given the default effect,\none can anticipate what a change in the rgb sliders will do. The same with\nthe oddness, once you are familiar with it.\n. Here are a couple of examples of the most common use (for me). Please don't share the one with people.\nIn this I have several images and I need a quick edit so I can share them. Light is very bad and I shoot with very high ISO, so I just care about capturing the right moment. If I get one that I really like I'll take more time later.\nOne is with the freaky b&w with default parameters and some exposure/contrast, the other same setting but with the monochrome. The difference here is subtle, that depends on the image.\n\n\nIn this I sometimes have an image that I like but again very noisy, this transform the noise on some texture that, depending the image & personal taste, is nice.\nThis two are with and without the freaky b&w and just the base curve.\n\n\n. I should also show the difference regarding image scale:\n\n\n. I'm having second thoughts about this. \nMy first thought was: if its useful for me it may be useful for others, but that is not good enough, it also needs to be a good fit for darktable.\nObviously I have nothing against having artistic filters in dt, but the image scale is a problem, and I don't think that anything can be done here about it.\nThe only option I can think of is to force all the pipes to process the image at the same size. Maybe is not that difficult and all it takes is a new setting on an existing module or a new iop, but for just one filter it doesn't seem to make sense. If the GMIC plugin is implemented this will be something to think about.\nI'm closing this for now, if the time comes when it makes more sense I can always reopen it.\n. That was not a good solution, I deleted the branch.\nEl dom., 4 nov. 2018 a las 14:14, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI see hat in redmine #11956 you're talking about a version without copy.\nWhat happened to this? Was there still issues with it?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1800#issuecomment-435687715,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUbuOxCo5HR8vuianI_NHwun0Ygxks5uryCQgaJpZM4YNTxV\n.\n. It was only for the modules and it was working, but it freeze dt while\nwaiting for the pipe to finish. On heavy edits that may seem forever, but\neven on light edits dt seem lees responsive.\nThis approach is better for me, locks should be the last option, and this\nI'm sure covers more scenarios and is less intrusive that adding locks\neverywhere.\n\nIn order for this to be 100% safe some locks should be added anyway, I get\nthat, but with this alone I didn't have any crashes since I'm using it.\nEl dom., 4 nov. 2018 a las 14:38, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'm sure it was not a good solution since you've deleted the branch. I\njust wanted to know more about this issues. Complex? Not stable? Was not\nfixing all cases?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1800#issuecomment-435689687,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pS2Vv6EqxJ-ZbJQnamYwfW-EXJePks5uryYEgaJpZM4YNTxV\n.\n. To give more context, this may seem very intrusive because it mess with\nvery sensitive areas, but is really not. What it does is, instead of the\npipe to process the original list now it process a copy of it, so as long\nas the copy works fine that shouldn't be a problem.\nWith the modules, also, instead of delete it I add it to another list and\ndelete it on exit (like the masks do). Worst case scenario we'll have a\nmemory leak (we have none).\n\nSo the issues can be if the list are copied/deleted on the right place.\nThe modules are copied when the nodes are created and free with them, and\nthe pipe is informed when to rebuild itself, so that should be fine.\nThe masks are tricky, we don't have an event to inform that the masks have\nchanged, and adding such an event will be truly intrusive, so I took the\nsafe path and copy the masks each time the pipe is processed. There aren't\nthat many masks for this to be a performance issue and even if it is not a\ntrue picture of the state of the edit, the pipe will be reprocessed anyway,\nso it should be fine.\nHope this helps.\nEl dom., 4 nov. 2018 a las 14:38, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nBTW, I'm just asking as I think it could help understand this PR and help\nthe review.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1800#issuecomment-435689743,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRAOYOoh-qxh9TPHrYpk7x94Sr_Lks5uryYugaJpZM4YNTxV\n.\n. Rebased.. @aurelienpierre , out of curiosity, when the color picker is called from a module, does it return the value from the input image of the module or the final image? And what is the expected behaviour for the profile log and color balance?. Thanks.\n\nEl lun., 5 nov. 2018 a las 18:43, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh there are 3 color pickers\nvariants : module input, module output, pipe output. In-module default is\nto take the input of the module, that's what colorbalance and log do.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1803#issuecomment-436046165,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdQln2DMlFZwBEsQiengs2aCywEeks5usLDjgaJpZM4YNvnU\n.\n. BTW, delete several instances, undo/redo fast, dt will crash.. Just fixed the last memory leak.. Travis CI is running for a day now, I don't what's going on.... Thanks.\n\nA bit late, but here is my testing:\nAdd a bunch of multi-instances with parametric mask, reorder them, delete\nthem all, go crazy with the cntrl+z / cntrl+y\nSame with drawn mask and the retouch\nAdd some style and go back and forward in history.\nNo crashes and the values are restored ok.\nI can't say that I have tested every single scenario, and to keep track of\nthe values while modules are being reordered, deleted and added is not\neasy, but as far as I can tell it works ok.\nEl jue., 8 nov. 2018 a las 14:33, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI've tested that, it works great on my side. That's a very nice\nenhancement/fix. Thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1807#issuecomment-437088355,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pY19zNCs3fNkRZBNDDDRmaPwCcwuks5utGrwgaJpZM4YSi18\n.\n. gui->posx=-1.000000 shouldn't happen here, this is set on the dt_masks_events_mouse_leave but it records the position of the mouse while in the image, and when the mask is dragged the mouse must be on the image.\n\nJust pushed a new commit, let's try again, same scenario.\n. Yes, I'm not fixing anything, just trying to see what's going on.\nFor some reason, dt thinks that the mouse is leaving the image right before the mouse button is pressed, that's what this sequence means:\n[dt_masks_events_mouse_leave]\n[dt_circle_events_button_pressed]  form_selected before start the form dr...\nworst, it thinks that the mouse is not returning to the image before the mouse button is pressed.\nJust pushed another commit, let's try again, same scenario.\nAlso, when creating a mask a preview is displayed, that is working fine? The preview is always under the mouse?\nOn the spot removal shortcuts can be defined, when creating a mask with a shortcut, the preview is displayed ok?\n. This is what I get when I go to darkroom, display the masks for the exposure module, then drag it:\n[center_enter]\n[button_pressed]\n[button_pressed]\n[button_pressed]\n[dt_masks_init_form_gui]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1,000000, gui->posy=-1,000000\n[center_leave]\n[dt_masks_events_mouse_leave]\n[center_enter]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1,000000, gui->posy=-1,000000\n[button_pressed]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=434,120270, gui->posy=796,871399, gui->dx=0,000000, gui->dy=0,000000\n[dt_circle_events_button_pressed] form_selected start the form dragging gui->posx=434,120270, gui->posy=796,871399, gpt->points[0]=405,685364, gpt->points[1]=807,304260, gui->dx=-28,434906, gui->dy=10,432861\n[center_leave]\n[dt_masks_events_mouse_leave]\nNotice that gui->posx is not -1.0, that's because there's a [dt_masks_events_mouse_moved] event before [button_pressed] that sets the position.\nIn your case, for some reason, there's a:\n[center_leave]\n[center_enter]\n[button_pressed]\n[center_leave]\n[dt_masks_events_mouse_leave]\n[center_enter]\nbefore the [dt_circle_events_button_pressed], and no [dt_masks_events_mouse_moved], so the mouse position is not updated.\nSo, in your environment, for some reason, darktable thinks that you are doing the following:\n-enter the image\n[center_enter]\n-move the mouse\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n-leave the image\n[center_leave]\n-enter the image\n[center_enter]\n-press the mouse button\n[button_pressed]\n-leave the image\n[center_leave]\n[dt_masks_events_mouse_leave]\n-enter the image again\n[center_enter]\n-press the mouse button (whithout moving the mouse!!!)\n[button_pressed]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gui->dx=0.000000, gui->dy=0.000000\ngtk is not my thing, so I can't say if this is a gtk or a darktable implementation problem, what doesn't seem correct is to have a [center_leave] before the mouse is pressed, even if we get a [mouse_move] event after that.\nI'm afraid that this is as far as I can go, sorry we were not able to fix the problem, but at least we got more info, so if someone with more knowledge of gtk and your environment take an interest in this he/she will have more data to work with.\n . keyboard shortcuts can be defined in preferences->shortcuts->image operations\nThere's shortcuts for almost any module, I don't really use them, but I do find them useful for the retouch and spot removal modules.\n. Nothing else I can do here, I'm closing it.. Confirmed! Thanks for reporting it.\nBut it also happens on the current version. Seems to be a display thing, if\nI go to lighttable things go back to normal.\nDo you think is better to fix it here or create a new PR?\nEl mar., 13 nov. 2018 a las 5:37, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI have a scenario where this does not work:\n\nwith 3 pictures\nopen the first one\nwith exposure create two circle mask (push exposure to see the\n   effect)\ngo to lighttable\ncopy the exposure from this image\npaste it on the second and third image\nopen first image remove the two circles from the exposure module\nopen the second do the same\nopen the third, when you remove the first circle the effect is still\n   on the image\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1825#issuecomment-438181143,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXWrrk1tuiSAXWseujBILtEGl1YDks5uuoTCgaJpZM4Yaljc\n.\n. It seems to me that mask_combine is missing from the migration. At the bottom I describe, seems that not very well, how to add new modules\nto the pipe. It is easy, but it needs recompilation. Essentially you add a\nnew version to the priorities, pretty much like for a new module version.\nThis ensure backwards compatibility, and less important but nice to have,\nnew modules are on the right order on the pipe, even for old versions.\n\nEl mi\u00e9., 21 nov. 2018 a las 15:05, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh, sounds like another very nice\nmove forward ! that's of course for 2019, looking forward to a stable PR\nabout this. Something not clear (to me) on the description, is it possible\nand easy to define a new pipe module order or does that means\nrecompilation? Also does all this means that for current edit the old order\nis kept to ensure history backward compatibility?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-440760119,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1paTFIdXV3aBXZNHAosoh_O4UlXJpks5uxZXbgaJpZM4YtoLi\n.\n. I have updated the first post with a couple a features I forget about. . As I stated somewhere else, color is not my thing, so please be gentle.\n\nIts not my goal on this PR to redesign how color is handled by dt, I'm not\nsaying is not important, just not my goal here. It will take someone with\nstrong color knowledge, if you are that person then great. And if you are\nplanning on base your branch on mine, I expect some redesign on my side\nwill be needed.\nWhat I've done is as follows:\nI have split the iop_cs_rgb into iop_cs_linear_rgb and iop_cs_gamma_rgb\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/develop/imageop.h#L550\nSo demosaic is returning iop_cs_linear_rgb\ncolorin expects iop_cs_linear_rgb and returns iop_cs_Lab\ncolorout expects iop_cs_Lab and returns iop_cs_gamma_rgb\ngamma expects iop_cs_gamma_rgb\nEach module still have a default colorspace that depends on his relative\ndefault position on the pipe regarding demosaic, colorin and colorout, but\nnow they can ask for a particular colorspace and inform the output\ncolorspace, that is done like this:\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/iop/levels.c#L567\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/iop/tonecurve.c#L806\nThe pipe handles the color transformation, so before call the process() it\ntransform to the expected colorspace by the module, like this:\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/develop/pixelpipe_hb.c#L1357\nTransformation is done here (yes, yes, not the right place for this\nfunction):\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/common/iop_priorities.c#L1101\ncolor picker and histogram are working fine like this.\nA note on histogram, it seem to work with unsigned ints, I didn't look at\nit very deep as I'm not planning on doing anything about it, but if that's\nso, there should be some rounding errors on the modules that uses histogram\nfor calculations.\nThe blend module is another thing, now it expects both input and out images\nto have the same colorspace, and it must be the default colorspace for the\nparent module, so before calling the blend module I have to transform both\nimages:\nhttps://github.com/edgardoh/darktable/blob/mask_iop/src/develop/pixelpipe_hb.c#L1444\nThe blend module should be redesigned:\n-to accept any colorspace on both images\n-the math should be checked, it seems that it uses the transform function\nfor linear and gamma rgb on some places.\n-It is very difficult to add a new colorspace, something more generic\nshould be done here.\n-all blend modes and blend if should be available on any colorspace, at\nleast different than raw\nI don't know this interact with your feature, by just looking at the code\nit seems that there are no conflicts, so let me know if something should be\ndone on my side.\nEl jue., 22 nov. 2018 a las 5:17, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nThat's very interesting, I was working on the color spaces API to allow\nthe modules to work in ACES RGB (\nhttps://github.com/aurelienpierre/darktable/tree/next-gen) so I will\nmerge my branch with yours and continue the color sanitization.\nAlso, a few notes:\n\ngamma-corrected RGB are bad working spaces to push pixels,\nwhat is the RGB space you name \"linear RGB\" ?\nRGB spaces should be merged between colorspaces.c and\n   colorspaces_inline_conversions.h but I propose to take over from here\n   (I have merged white points already).\nI plan on adding ACES P0, P1, ACEScc, ACESgc, and CIE RGB.\n\nalso, if you look at my branch, I have made stupid things with Lab that\nneed to be reverted before going further.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-440947917,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfiL-TtYmIe-jLf5IUFun3ughd4xks5uxl2UgaJpZM4YtoLi\n.\n. I just fixed some minor bugs and added drag & drop for the module list, it works with SHIFT + click.. Indeed, I like the equalizer for denoising, and it does a far better job before the base curve.\n\nDid you try it on new edits or have you migrated old ones?. Great, I just wanted to know the scenario you were testing. Testing this won't be easy, so I'll try to keep track of this things.\nThanks for trying it!. That's complicated, right now I'm preserving the current behavior: on copy\nall / paste all with overwrite mode an exact duplicate of the source\nimage's history is created, on any other case only the last entry in\nhistory for each instance is copied, and is placed right after the last\ninstance on the destination image.\nI haven't found a good definition to what to do to preserve the order that\nthe modules have on the original image. The order in the pipe is not\nabsolute, it depends on the relative position of each module to each other,\nso let's say on the source image I have 3 instances of the tone curve,\nmoved after the colorout, and a lowpass after those tone curves. I copy the\nlowpass and paste it into an image that have no tone curve. This means that\nthe tone curve exists on the destination image, but it is disabled and on\nthe default order, so where do I place the copied lowpass?\nSomething similar happens with the styles, so until I find a better way it\nuses the same definition as the copy/paste.\nEl lun., 26 nov. 2018 a las 17:34, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nIt seems that when copy/pasting and styles do not preserve the custom\nmodule order yet, is it normal in current state of development or should\nthe order be already preserved?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-441788075,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdMf_puV8qHQHhj866fsNhGC7a0sks5uzFA_gaJpZM4YtoLi\n.\n. El lun., 26 nov. 2018 a las 18:08, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n@edgardoh https://github.com/edgardoh I will focus on the next release\n(doc and stuff) for now. As soon as it's done, I will take a look at your\nwork and merge it with mine.\nIn an ideal case, colorin and colorout take whatever is fed to them, and\ncould even act as a pass-through (although editing in camera RGB space\nsounds like a bad idea, I'm still curious to try it).\nAt some point, it would help to have an option to reset the pipe order as\nthe legacy, for example to apply presets.\n-It is very difficult to add a new colorspace, something more generic\nshould be done here.\nGenerally speaking, color spaces conversions are matrix products. Except\nfor Lab and derivatives which do a piece-wise x\u00b3 function on top. So, RGB\nand XYZ transformations can use a generic matrix product, using a general\nAPI that takes the right matrix as an input, but the Lab conversions will\nbe a pain and likely suck all the performance. I still wonder if BLAS could\nbe a good option to optimize the RGB transforms/matrix products decided at\nuser level (stuff you can't optimize at compilation time).\n\n\nWhat I meant here is that in order to add a new colorspace to the blend\nmodule (HSL, XYZ, etc) all the blend modes routines have to be modified. It\nwould be better if they all have the form:\n-transform forward\n-do their thing..\n-transform backwards\nso the new colorspace will be only a parameter.\n. I have changed the copy/paste behaviour, now when an instance is replaced the order is not changed. I think is a more common scenario to just want to change the values of a module when pasting it and not the order on the pipe.. @rawfiner , you can disable the dummy modules on CMakeLists.txt or you can add a priority to them, i.e: you can copy iop_priorities to your config directory\nhttps://github.com/edgardoh/darktable/blob/mask_iop/iop_priorities\n. Not sure I understand. Right now, on master, priority is an int,\nhard-coded, and can change between version. In this implementation priority\nis an int and is dynamic, what controls the order of the pipe is iop_order,\na float, that behaves like you described, if module1 is moved between\nmodule2 and module3, then module1 = module2 + (module3 - module2) / 2.f\nWhat you are proposing is to have priority changed to float and hard-coded,\nI'm not sure if you mean to have all modules hard-coded or just some, and\nthen calculate the priorities for the rest, and how it relates to the\niop_order.\nEl dom., 16 dic. 2018 a las 10:27, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nIndeed, this worked :-)\nApart of that, I thought about the copy pasting issue across images, to\nkeep the order when copy pasting. Here is an idea I have, I do not know if\nit is realistic regarding the way you handle the order:\nThe principle is to have an hybrid order system, where the order is both\nrelative and absolute.\nEach module would have a number indicating its number in the pipe (like it\nwas with previously in darktable), but this number would be a float instead\nof an int, and it would be changed depending on the order of pipeline.\nSome modules have a number that can't be changed, for instance:\n\n0 for beginning of pipe\n100 for input color profile\n200 for output color profile\n300 for end of pipe\n   The numbers of the other modules are initialized by values defined by\n   the developers, that should never change, even across versions.\n   If a new module is added in darktable, it takes the value\n   (module_after-module_before)/2.\n   When moving the modules, we do the same: if module2 is moved before\n   module1, it takes the value (module1-module_before_module1)/2, this way, it\n   is set as in between module1 and the module before module1.\n   When copy pasting, these absolute values are used to make the fusion\n   of original modules and new ones: if there is a collision of values, we can\n   say that the new module is set to be after the original one in pipeline for\n   instance (this remains the same problem as with current implementation).\n   I hope it can help!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-447643363,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfvryKexAiIDCGeQpMZuY3vRC1-tks5u5kpagaJpZM4YtoLi\n.\n. Right now the iop_order can be different on different versions, so using\njust its value can make a big mess. I had a reason to do it this way, but I\ncan't remember it now.\nYour proposal makes sense, so let's say any issues the iop_order may have\ncan be handled in a different way and I make it to be the same across\nversions, then I can use the iop_order value and modules, when pasted, will\nkeep the order on the pipe. That would be great, I don't like the current\nbehavior when modules have been moved. But there's still the problem when\nthere's a conflict with the iop_order, let's say I create 3 instances of\nexposure and I paste it into an image with 3 instances of exposure but with\ndifferent names, with the current version I'll get:\n\nexposure 3\nexposure 2\nexposure 1\nexposure c\nexposure b\nexposure a\nwith the new behavior I'll get:\nexposure 3\nexposure c\nexposure 2\nexposure b\nexposure 1\nexposure a\nprobably not what the user expects.\nStill, I like better the idea that if I have the equalizer near the\ndemosaic, when pasted it will be near the demosaic, not after the colorin,\nso its just a matter of finding a better way to handle the conflicts of the\niop_order.\nEl dom., 16 dic. 2018 a las 14:40, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nAlright. I did not understand that you were using already a mecanism with\nthis formula. You can forget about my proposition then, which seems\nequivalent to what you have already done ;-)\nI think that with such a formula, copy pasting can be done by simply\n\"merging\" the modules of the source and the destination based on the\niop_priority values? Or am I missing something?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-447661725,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pbrsTS-SQBHSRdooqmpSQSvY3QIqks5u5oWMgaJpZM4YtoLi\n.\n. @rawfiner , I've done only a very basic test but seems to be working. This still is not ideal but for a first version maybe is good enough, I'll use for a while and see how it goes.. @aurelienpierre , the sql is heavy but I have tested it with +10.000 images and it was in the order of 10 minutes, not hours. It can probably be optimized but that's not a priority right now, first the design must be validated.. Probably is not linear, so that seems about right. I don't know what you mean by did not finish. It crashes? Do you have an error message?. That's normal, you won't see any window until the migration finish. Maybe it just need more time, like I said the sql is heavy.. I can't duplicate the first issue, all 3 histograms are displayed fine.\nCheck that the log scale is not active, histograms are not displayed with\nlog scale.\nConfirmed second issue, seems that log scale works only on the first tab,\nvery reasonable for lab, not so much for rgb.\n\nMy goal with the tone curve and the levels was mainly to add the new\nfunctionality so it can be tested. Now modules can ask for a specific\ncolorspace, so I want to make sure that the transformation is correct (both\nmodules ask for a prophotoRGB image), the histogram represents the image on\nthat colorspace on that point of the pipe, the colorpicker return the\ncorrect values and the blend module keep working as usual. If all that\nworks then I'm happy.\nIf we look at the modules itself then I'm not so happy. The histogram and\nthe edit is done in linear rgb, that is not intuitive for the user and\nprobably not what is expected. If a linear curve (from the presets) is\napplied the middle gray is shifted. That's because the middle gray on\nlinear rgb is around .18 and not .5, so the math seems correct, but not the\nfunctionality.\nNot sure what to do about it.\nEl mar., 22 ene. 2019 a las 13:34, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, I did build it for the first time, I wanted to see if it works on my\nside before going into a deeper testing. Some issues:\n\nopen tone curve\nselect RGB independant channels\nselect [b]\n\nBUG: see that the [g] and [b] channels have no histogram in background\n(red does)\n\non the [b] tab and move the curve\nselect scale : log-log\n\nBUG: the scale is not changed\nThe mask history is great! Masks feel first class citizen now! More\nlater...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-456467012,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVJEllDHOLcAJoGZijIcOrFuaurKks5vFz2CgaJpZM4YtoLi\n.\n. I started it as two developments, but at some point they started to overlap, I don't remember exactly where, so I continue as a single development. Right now they cannot be split without breaking things.. I just added a new module \"basic adjustments\", it adjusts exposure, contrast, brightness and saturation, and it has an auto option based on RT auto levels. It is mainly to test how a new module works with this PR, but it seems to give nice results, so maybe we can keep it.. I'll start re-working how colorspaces transform are handled, this can probably wait, but then backwards compatibility will be more difficult to handle. What I'm planing to do is:\n1) move colorin right after demosaic\n2) move colorout at the end of the pipe\n3) add an option to colorin to select the work colorspace\n\nThis way all RGB modules will work on the working colorspace, that seems to be the accepted workflow, and I won't have to deal with transforms from/to camera RGB.\n. > @edgardoh https://github.com/edgardoh If I understand correctly,\n\ncolorin would have a fixed place in the pipe?\nYes, so colorout, at least on a first version. Its a limitation, but if\nsome module gives better results before colorin or after colorout that can\nbe handled. The user won't be able to move it, but again, is a limitation.\nI am not confident in the fact that denoise profile results would remain\nthe same if denoise profile is done after colorin, thus we should test this\nand see how to handle backward compatibility if the results are differents.\nBackward compatibility will be handled, previous edits will have\ncolorin/colorout at the same place in the pipe. As for the different\nresults, that's expected, right now color denoise behaves different\nbefore/after colorin, I can't tell if better or worst, that's probably\nsubjective.\nApart of that, it seems a good idea to me, even though I am clearly not an\nexpert about colorspaces :-)\nMe neither, but there's seems to be a consent that is better to do the\nedits on the working colorspace, and it should RGB linear, so this is a\nfirst step on that direction.\n. I just pushed the working colorspace feature and updated the first post with the new changes.\n\nI didn't lock colorin and colorout so they can still be moved to get the current pipe order, but is user responsability not to move Lab modules outside colorin-colorout range (see the first post).. Just added the working profile to the histogram profile and the sse and opencl version of the colortransforms, so that's it for the main features, what's left is to test it to the dead.. @TurboGit , all new modules are for testing the new features and while in testing better to keep them, removing them is easy.\nThe basic adjustments I like and I want to keep it.\nThe rgb lowpass I don't like and I'll eventually delete it.\nThe rgb curve I like, we can discuss if keep it or merge it with the tone curve. For me is better to keep it.\nI haven't test the rgb curve since the last rebase, there's probably some issues. I'm working on the color zones now, I'll check as soon as I can.\nThe mask manager entry is used when a mask without a module is modified but also on some other cases where a single module is not available, like the migration, compress history, and a couple more that I don't remember.\n. > @edgardoh https://github.com/edgardoh : I'm not against the module, I\n\nthink the basicadj is nice for begginner and I'd like to have it. But I\nwould really prefer to have all those modules in separate PR.\nIt will make this PR smaller. If we need to revert this PR temporarily we\nwill keep the iop. And all the dummy for for testing should just do in a\nspecific branches. I don't want to have this in the master.\nSure, I'm not saying to promote this with all those modules, just to keep\nthem while testing, then I'll remove them all and add a new PR for the ones\nI care about.\n. > Ok, so please remove them now. I have tested this a lot, I have make many\nreviews so I think it is time to bit the bullet and merge this. Better\nsooner than later for this to be more widely tested now.\nUps, I just pushed a WIP version of the color zones! I'll revert it, do\nsome cleanup and let you know.\n. @TurboGit , should be ready now, please check it.. @TurboGit , there's a couple of items on my todo list:\n\n\n\ncolorin and colorout can be moved. I'm not really sure about this, I don't see the point of having modules before/after them, but since up till now it was possible I let it like this. The problem is that this generates some special cases and if it won't be used better to have them fixed.\n\n\ncolor routines don't belong in iop_order.c, we should define some library for this, but colorspaces.c doesn't seem the right place either. Something similar with opencl.\n\n\nundo is not working in master, I tried to follow it but I have no idea what's going on. Does not seem to be related to this PR, but I can't be sure.. I didn't give too much thoughts to the module order, but there are more than a few that can be changed. The channel mixer should not be last, the denoise(s) should be first, the levels and tone curve should be swapped.\nMaybe some rules should be added too, I'm not sure if some distord modules need a specific order.\nI'm working on other things now and keeping an eye on the bug reports and I don't want to add any more, but maybe the best way to handle this is to create a PR to centralize the discussion there.\nMy two cents.\n. > modules now ask for the input colorspace and informs the output one. This\n\ncan be dynamic, so Lab modules with an RGB option can ask for an RGB input\nimage\nbeside the common default_colorspace() we have the 2 routines:\n\ninput_colorspace()\noutput_colorspace()\n\nWhen are they triggered ?\nDon't really remember, but when the calling program need to know the input\nor output colorspace for a module, for sure in the pipe.\n\n\n\n\nThe background of the question is that, depending on user settings in a\nmodule, the needed colorspace can be different. For example in old fashion\ntonecurve, I want to call RGB only if the user select the rgb mode. For\nlut3d I have a similar need depending of the type of lut.\nHow should I do ?\nYou add those functions on the iop, like the default_colorspace(), only\ndifference is that you'll return the colorspace based on the parameters (I\nguess). Notice that pipe and piece can be NULL, so you have to handle that\nscenario.\nTalking about lut3d, you cover already the sRGB colorspace. Would it be\neasy to add the the gamma REC709 ? Same question, but I guess it's more\ndifficult, for LOG RGB ? What do you recommend ?\nThere's a limitation on the work profile, only those that can be used by\nthe internal transform function are accepted. This is for performance,\nlcms2 is slow. You can check here how this is determined:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/colorspaces.c#L137\n\nThis is for profiles from file, the ones in-memory must be added by hand,\non that same colorspaces.c\n. That's correct, the input image is either Lab or RGB with the work profile\napplied, that's the point of the work profile. If you want a particular RGB\ncolorspace the module has to do the transformation.\nI have no idea what you need to do, but having this transforms hard-coded\ndoesn't seem a good idea, is there a way to do it dynamic? If you create\nin-memory profiles it should be possible (and not too difficult).\nEl lun., 18 mar. 2019 a las 10:08, Philippe (notifications@github.com)\nescribi\u00f3:\n\nYou add those functions on the iop, like the default_colorspace(), only\ndifference is that you'll return the colorspace based on the parameters\nin fact input_colorspace() just let you choose between iop_cs_lab and\niop_cs_rgb. In case of iop_cs_rgb it uses the rgb working profile selected\nin colorin.\nIf that's right, a module (like lut3d) cannot choose real time between\nsRGB, rec709, prophotorgb or whatever. Is my understanding correct ?\nThen I've to provide somewhere transforms between prophotorgb and the\nother rgb colorspaces. Is colorspaces_inline_conversions.h still the right\nplace ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-473902453,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSg5IImZymB0dG7oj-TgS65c07Uwks5vX4_BgaJpZM4YtoLi\n.\n. What I call in-memory profiles are hard-coded profiles defined in\ncolorspaces.c. The sRGB, linear rec2020, etc that you see in the profiles\nlist are such profiles. They are added here:\n\nhttps://github.com/darktable-org/darktable/blob/master/src/common/colorspaces.c#L1185\nyou can check on the same file how they are defined.\nSo, if you create your profiles on the same way they can be added to a list\nso the user can select them or you can have them hard-coded, depending on\nyour needs. Then, the same routines that I have created to do the\ntransforms can be used.\nEl lun., 18 mar. 2019 a las 10:26, Philippe (notifications@github.com)\nescribi\u00f3:\n\nIf you create in-memory profiles it should be possible (and not too\ndifficult).\nSorry I don't get that. Could you develop a little bit ? Is there already\nan example of that ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-473908535,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSNIJZbaa-TTVVseUha0piOKcrp2ks5vX5PogaJpZM4YtoLi\n.\n. Have in mind that all this work only if the module is between the colorin\nand colorout, as it needs a profile that describes the image (that's what\nthe colorin does). If you also want your module to work before the colorin\nyou'll have to define a transform between camera RGB and the colorspace of\nyour choice.\n\nEl lun., 18 mar. 2019 a las 10:36, Edgardo Hoszowski (\nedgardo.hoszowski@gmail.com) escribi\u00f3:\n\nWhat I call in-memory profiles are hard-coded profiles defined in\ncolorspaces.c. The sRGB, linear rec2020, etc that you see in the profiles\nlist are such profiles. They are added here:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/colorspaces.c#L1185\nyou can check on the same file how they are defined.\nSo, if you create your profiles on the same way they can be added to a\nlist so the user can select them or you can have them hard-coded, depending\non your needs. Then, the same routines that I have created to do the\ntransforms can be used.\nEl lun., 18 mar. 2019 a las 10:26, Philippe (notifications@github.com)\nescribi\u00f3:\n\nIf you create in-memory profiles it should be possible (and not too\ndifficult).\nSorry I don't get that. Could you develop a little bit ? Is there already\nan example of that ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-473908535,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSNIJZbaa-TTVVseUha0piOKcrp2ks5vX5PogaJpZM4YtoLi\n.\n\n\n. You have more function to perform transforms on iop_order.c, the RGB <-->\nRGB is already defined, so if you create an in-memory profile you don't\nhave to worry about that, but first you have to decide if you'll create\nsuch profiles.\n\nEl lun., 18 mar. 2019 a las 13:19, Philippe (notifications@github.com)\nescribi\u00f3:\n\nIn colorspaces.c I can see the creation of several colorspaces. They end\nup into a list of lcms profiles.\nSome of them are considered by iop_order.c (colorspaces transform) which\nprepares the data to transform iop_cs_lab <-> iop_cs_rgb. Pixelpipe uses\ndt_ioppr_transform_image_colorspace() to execute this transformation.\nAs from module standpoint we have only the below choices (but only raw,\nlab and rgb are implemented if I understand properly):\n/* colorspace enums /\ntypedef enum dt_iop_colorspace_type_t\n{\n  iop_cs_NONE = -1,\n  iop_cs_RAW = 0,\n  iop_cs_Lab = 1,\n  iop_cs_rgb = 2,\n  iop_cs_LCh = 3,\n  iop_cs_HSL = 4\n} dt_iop_colorspace_type_t;\nI cannot use this mechanic (dt_ioppr_transform_image_colorspace()) to\ntransform prophotorgb into gamma rec709 for example.\nCould I use instead cmsCreateTransform, cmsDoTransform and\ncmsDeleteTransform ? I've also seen that in pixelpipe for color picker and\nhistogram stuff. It seems that's the only way to use colorspaces.c lcms\ncolor profiles directly from iop module ... but maybe not fast enough ...\nOtherwise I'm back to hard-coded transforms in\ncolorspaces_inline_conversions.h...\nI'm a bit concerned to have several ways / places to make colorspaces\ntransform.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-473986217,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pYcLUlcEjaIg4ghznh1IRApeK2JAks5vX7yUgaJpZM4YtoLi\n.\n. This one transforms the entire image RGB <--> RGB:\n\nhttps://github.com/darktable-org/darktable/blob/master/src/common/iop_order.h#L145\nBut it needs the from/to profiles, that can be in-memory or from file\nprofiles, in both cases the matrix should be available as I described\nearlier (not sure if it was in this thread). It can work with lcms2, but it\nwill be too slow.\nThe per-pixel version is not exposed, but if you need it I can add it.\nI still don't know what you want to do, so I can't recommend anything, but\nthis way if you want to add a new colorspace you only need to create the\nin-memory profile, and it can also work with user defined profiles (from\nfile).\nEl lun., 18 mar. 2019 a las 13:36, Philippe (notifications@github.com)\nescribi\u00f3:\n\nbut first you have to decide if you'll create such profiles.\nIf this is the recommended way I'll do this.\non iop_order.c, the RGB <--> RGB is already defined\nI've missed that ... could you help me ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-473995013,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVZZCgi7d12D91MIxhK6uR_TRmtEks5vX8CpgaJpZM4YtoLi\n.\n. If you place it before colorin and change the colorspace the you'll have to\nchange the colorin as well, because it expects camera RGB. Or maybe just\ndisable it, but in any case it should be carefully considered, colorin is a\nvery sensitive module, and a lot of things are based on that.\n\nIf you place it after the colorin, maybe you can use the work profile as\ninput, and just display the luts that can work with that profile. Or if the\nlut just accept one profile then there's no need for the user to select it,\nthere's only one option. But I don't know the design, so take this just as\nwild ideas.\nAgain, in any case, if you place it after the colorin and change the\ncolorspace you'll have to set the work profile so the rest of the pipe can\nhandle it, and for that the profile matrix is needed.\nEl lun., 18 mar. 2019 a las 14:36, Philippe (notifications@github.com)\nescribi\u00f3:\n\niop_order.h\nOoops, I haven't visited this one. Thanks.\nI still don't know what you want to do\nFor the time being I try to implement the module to apply 3D lut on image.\nBut these luts are valid for a given colorspace, which can be sRGB, gamma\nREC709 and LOG. So before applying the lut the user has to select the\ncorresponding colorspace (it may not come with the lut).\nThe LOG is a particular case. In film production it can come out the\ncamera and can be a work profile. So I'll try to place the module before\ncolorin, transform the raw data into log and apply the luts which work in\nLOG profile. That should work if the module gives as output profile, an\nexisting colorin profile.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1841#issuecomment-474023138,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXaRxg372xrdZ7DR0rI__BcG-wzKks5vX86OgaJpZM4YtoLi\n.\n. @moy , should be fixed now, please test it.. Hi, \n\nMy thinking when I designed this was to order the sections based on how often they are used. The shapes and algorithms toolbars are used all the time, from simple dust removal to complex retouching, for me makes sense to be first.\nAs for the order of the tools on the toolbar, I wanted to make it the same as on the spot removal. Also, and this may be personal, I use the circle far more often than the brush, so I like it to be first.\nFor the select tool and the fill I don't really have a preference, so is OK with me. . > @edgardoh https://github.com/edgardoh : the most important point is\n\nhaving the tools and the tools options close to each other. So another\noption is to move the tools options above the wavelet decompose section.\nWould this be ok?\nBy tool options you mean the shapes properties, so you want to bring those\ntwo sections together? If that's the case, I place it last because the only\nalgorithms that have a property are the blur and fill with color, and they\nare not used very often, so again the order of the sections reflect how\noften they are used.\nFor the tools I'm using the brush more often :)\nWell, probably there's no way to make every one happy ;)\n\nI've been using this tool for a long time time now, from very basic sensor\ndust clean to heavy retouching and I'm comfortable with the GUI, but that\nmay very well be because I'm use to it, there's no way for me to tell other\nthan try something different.\nFrom the use-case perspective, with the current functionality, there's no\nmuch interaction with the GUI, I use the continuous add and focus on the\nimage, and when I use the wd I focus on the wd bar, so it doesn't really\nmatters where it is placed. Same goes for the order of the shapes and\nalgorithm buttons. So if you have a strong conviction that this changes\nwill make things better, go for it.\nI still have the feeling that the order of the sections is OK the way it,\nbut again, what I say above.\n. Just one more note, the properties section show/hide some fields based on the selected shape, so if a section is below it, it will be 'moved' each time a shape is selected. If you want the shapes and properties section together, the best option probably is what @upegelow suggested and make the wd section first.. I just tested it with overlay and softlight, it doesn't seem to have much difference than playing with the brightness. I didn't a full test, but by setting brightness = -1 I get almost the same as with fulcrum 75.\nMaybe I'm missing something?. The retouch does not work with a tablet?. It seems like a non-local means denoise issue, this happens only with\nopencl, so until is fixed you can disable opencl for export.\nEl lun., 7 ene. 2019 a las 15:16, pierre-guillot (notifications@github.com)\nescribi\u00f3:\n\nHello guys.\nI updated darktable to 2.6 on my Archlinux (directly from official repo)\nand now I have a problem with the equalizer module.\nI usualy apply the style \"EQ+Denoise+HotP - Matt Eastwood\" (you can found\nit on https://dtstyle.net/) on my high ISO picture to denoise it but\nsince the last version, some \"black square\" are presents on the picture\nwhen I use this style : https://framapic.org/7x6tOxMTPuEV/MhcL4XAH5zY1.png\nIf I export this picture, the problem is still present.\nUsed camera : DMC G7 and RAW file. Tested with a RAW downloaded here and\nsame result : http://www.mamiyaleaf.com/samples_credo_80.html\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/1980, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQnDpBqE3On22FA6ZSj1RiZRUrfJks5vA47fgaJpZM4Zz_Hq\n.\n. Stefan, could you please test it? This can affect all the shapes on the mask manager, blend module, spot removal and retouch, so the more scenarios are tested the better.\nThanks.\n. Works fine for me, I can't duplicate the issue here. With PR 2000 on the other hand the issue is still present.. > If I understand your comment correctly, you see bug 12490 with PR2000.\nPR2000 affects only the nlmeans implementation of denoise profiled, not\nthe implementation of denoise non local, so it is normal that you see the\nissue 12490 (black squares and blue image when using denoise non local)\nwith PR2000.\nUps, I just went and test it, forget I said something about it.\n. This will introduce conflicts with PR 1841, maybe it will be better to wait until it is merged.. PR 1841 adds rgb curves, so more or less the same lines has been modified. But more important, it adds the ability for the modules to ask for a specific colorspace, so the transform must be done outside the iop. This allows the module to have a LCh histogram, but for that the curve will have to be modified, so strange things will have to be done to keep backwards compatibility. . @phweyland , is not really up to me when it will be merged, but don't expect it for next week.\nI'm not sure I understand you question, right now we have Lab, XYZ and RGB curves, independent or linked, each one has a different behaviour and that's hard-coded. . @phweyland , if you are planing on continue with this then you can disregard my comment, my current approach don't work like I would like to so I'll have to change it and I don't know how long it will take, and I don't want to hold you back.\nIn fact, I want to do something as generic as possible, so having also LCh will help.\n. I added the rgb curve mainly to test some of the new functionality introduced on that PR, and what would take to add it to any module, so I just added it on top of the existent code, I did not have any redesign in mind.\nThings seems to work fine, but there's the issue I describe on that PR, right now rgb/xyz curve display a lab histogram, that doesn't seem right. With my changes, xyz/linear rgb display a xyz/linear rgb histogram, I don't like that either.\nThe solution is probably independent of PR 1841, but maybe is related, and I think that any redesign of the tc should have it in mind. Your input is welcome on that, on any thread you choose.\n\nAbout the 3 or 4 tabs, I just added a new option \"rgb independent channels\" to keep it consistent with the lab mode, also I didn't want to add another LUT, but is really the same to me.. Sounds ok to me. Also, depending on what's decided about the histogram, my PR may not be needed at all. For instance, you can add the option for the modules to ask for a histogram on a specific colorspace and ready to display, in this case the module can still have the input image in Lab and display the histogram on all the colorspaces.. > That sounds great but how can I ask for an histogram on a specific\n\ncolorspace ?\nBy add I meant it has to be added (coded)\n\nSecond point. Your mode RGB linked channel doesn't behave as the normal\n\none, as the later shows a different histogram (same as Lab in fact). This\nmay be a problem for backward compatibility (nodes at different positions).\nAny thought ?\nThat's the issue I have described with my version, maybe its not clear, so\nlet's forget about my PR for a moment.\nRight now a Lab histogram is displayed for all the curves, including XYZ\nand RGB linked. I don't like it, but is an option. If you decide to keep\nthe current behavior then you can display a L(ab) histogram on L(Ch) and\nnothing on (L)Ch. For the RGB independent channels you can display L(ab)\nfor each channel (doesn't seem to be reasonable) or display nothing.\nIf you want to display a histogram for each channel on every colorspace the\nonly option I see is to generate a histogram for each one, but when the\ncolorspace don't have a 50% grey an S curve will cause a shift on the\nmiddle grey (that's what my version on my PR is doing), I don't think that\nthis is correct.\nAnother option is to generate a histogram for each colorspace but somehow\nwith 50% grey, That's what I mean by \"histogram ready for display\",\nobviously this has to be better defined.\nDepending on what you decide to do are the next steps to take.\n\nI hope this makes sense.\n. @phweyland , I don't know what you're planning to do, so I can't tell.. @phweyland , in my last message I give some options on how to display the histogram and how the curves can behave, what I don't know is which one (if any) you will choose. Will it have the same behaviour as my PR (shifting the 50% gray with an S curve)? Something different?. > Ok, I've missed this one : when the colorspace don't have a 50% grey an S\n\ncurve will cause a shift on the middle grey , I don't think that this is\ncorrect..\nI would not agree on this, I think this is correct. I'm happy with those\nyou have produced. Whatever the colorspace (Lab or RGB), applying a manual\nS-curve (or whatever change) may change the grey point, ie, move it out of\n18% or 50%.\nWell, I don't find it intuitive and I don't think that's how other programs\nbehave, but not my call. But since this will change how the tone curve\nbehaves now, you should check with the dev team to see if they are OK with\nthis change.\nThe histogram which is shown is the module input histogram. There is no\nmodule output histogram. The general histogram shows the output of the\noutput module if I'm right. It can be very different of the tonecurve\nmodule output one, especially the linear ones.\nSo maybe it could be interesting to show both the input and output\nhistograms of tonecurve (overlapped drawing)...\nNow the linear colorspaces show most of the points on the left handside of\ngraph. That's where the log histogram helps the user to better control his\nchanges on this part.\nMy PR won't do any changes on the histogram and will handle only Lab and\nRGB, anything else should be handled by the modules, so XYZ, prophotoRGB,\nLCh histograms won't be automatically generated, in order to display it\nsome work is required.\n. I did some testing and RawTherapee and PhotoFlow don't shift the middle grey, RawTherapee works on prophotoRGB (as far as I know) and PhotoFlow allows to select the working colorspace. No idea internally how they handle the curve and the histogram, but the code and authors are there.\n\nMy main concern is that the meaning of the curve should remain the same, no matter the colorspace. And a standard S curve is not supposed to shift the middle grey, as shown by the current presets \"contrast * (linear)\"\nI'm not saying that we should do exactly the same as other programs, if we find something better then great, but by changing colorspaces there should be a way of having the same curve with the same meaning.\nTake for instance the contrast, changing the colorspace will shift the middle grey, so in my \"basic adjustments\" I have added a fulcrum so it can be corrected when changing from a linear to a non-linear RGB (is a WIP, so is far from perfect), maybe something similar can be done with the curves and histogram.\nMaybe @TurboGit  has an opinion on this.\n. This is what I'm saying, but we still don't know what to do with the\nhistograms. Do we transform to some gamma corrected colorspace? Apply some\ngamma function?\nEl jue., 7 feb. 2019 a las 4:00, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nOk you need to separate the view and the data\nhttps://en.wikipedia.org/wiki/View_model.\nNo matter the color space, the curve sets the middle grey at 50 % of the\ngraph view. In commit_params(), the coordinates of the curve's LUT are\nthen properly remapped in 1D to the target color space, meaning 50 % ->\n18.45 % in RGB and XYZ modes:\nhttps://github.com/darktable-org/darktable/blob/5b7b2f1b6abc7a52c98cc7f35d075fab24909cf8/src/iop/tonecurve.c#L583-L595\n(But @phweyland https://github.com/phweyland, you have removed that\npart.)\nThen, in process() the LUT mapping happens in the right color space.\nSo I think we are spinning around a non-issue. It's not a \"Lab\" or \"RGB\"\ncurve, it's a curve drawn in a space where the middle grey is 50 % so the\ngraph is centered (which happens to be Lab, but we don't care in that\nparticular case. Could have been a simple ^2.35 too).\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2017#issuecomment-461308716,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQRw8g6Z408CoiwxZoGI3VCa6sidks5vK88cgaJpZM4aJPvb\n.\n. Backwards compatibility will be guarantee, so there's nothing for you to\nworry about.\n\nEl vie., 22 feb. 2019 a las 4:53, Philippe (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh\nSo far I haven't made nothing specific to converge towards your PR. Is\nthere anything I should look at or do to facilitate the integration with\nyour PR ?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2017#issuecomment-466307005,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQvJT-H3xJZpgSKrhCu5mBW9EFDwks5vP6INgaJpZM4aJPvb\n.\n. >\nThere is now some conflicts with tonecurve.c\nThere will be more, I'm making some more changes to it. They all are\nrelated to the color picker so it should be easy to resolve.\n... I understand we don't merge something which is not 100% finished. But\non the other hand there is no way to get user feedback if we don't merge\nsomewhere in a kind of sandbox or quality space for testing. How will\nthings go forward ?\nThis is an issue for large developments. Ideally I would like to have an\nintermediate branch 'dev' where things are merged when they are stable\nenough, and have regular builds for all systems so users that can't build\nare able to test it. When OK it will be merged to master.\nNo idea how to implement it, maybe github has some feature that make it\neasy?\n. The same, but I use the input image instead of the output one.. Are you talking about the location of the combo box for the overexposed\nprofile or the fact that there's a different setting for it and the\nsoftproof?\n\nEl jue., 7 feb. 2019 a las 11:37, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWon't this be better under the softproof & gammut buttons? We already have\nhere the screen profile. It seems awkward to me to have this under the\nover/under expose. Can you comment on this choice? Thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-461445539,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXe7Tjtsl4euOE7Hd0jRbTbprMoMks5vLDpAgaJpZM4anMx-\n.\n. Regarding the position of the combo, what's wrong for me is the display\nprofile under the gamut & softproof, it should have an independent button,\nlike the lighttable, but that's for another PR.\n\nThe overexposed/color picker/histogram is a matter of choice. I think they\nare related and should work with the same profile, having a profile for\neach one is overkill. But maybe this is not what you are asking...\nEl jue., 7 feb. 2019 a las 11:56, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'm speaking about the location of the new setting you have added. The new\nselection is done in the over/under expose dialog. I think it would be\nbetter if placed into the softproof & gamut dialog.\nI've just built and tested and I see that the name for the new profile is\n\"overexposed profile\". So it looks like it is in the right place. But...\nthen I fail to see a relation between the new \"overexposed profile\" and the\npicker or histogram. Can you clarify?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-461454213,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfyqtNcWNBMYEY0_fK8lYX5GwSgnks5vLD6LgaJpZM4anMx-\n.\n. It works for the over/under exposed too, that's why is under that button.\n\nIt was requested many times to have a setting for the profile for the\nhistogram & color picker, I never heard about the overexposed, which is\nstrange to me because as I said, they are related, so I use the same\nprofile for the 3 features. Otherwise, you can check the histogram for\nover/under exposed areas, use the colorpicker to see the exact value, but\nwhen using the overexpose button you will get different results.\nI agree that is not clear that the setting works for the 3 features, the\nuser that see this for the first time will think that it applies only for\nthe overexposed button. But this is just UI, and I thought that is better\nto have this promoted as soon as possible so it can be tested and in time\nmake the UI more clear.\nRight now the only options that I see are to add a combo on the colorpicker\nsection (in synch with the current one) and/or some text on the overexposed\nprofile. I don't really like any of those.\nDoes this makes sense?\nEl jue., 7 feb. 2019 a las 12:34, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'm just trying to understand. You did not answered one of my question.\nWhy the new profile is named \"overexposed profile\"? As I understand it\nworks for picker and histogram, so I don't see the relationship.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-461472417,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXeNhm5NSMaSWwnhBXsUBB3fGpWQks5vLEeIgaJpZM4anMx-\n.\n. The working profile is where the edits are performed, in dt is mostly lab,\nbut also happens in camera rgb, prophotoRGB and the thing that colorout\nreturns.\n\nThis is independent from the working profile and the display profile, and\nthat's the point. One of the scenarios is that the user wants to check the\npixel values/overexposed areas/histogram on the image as it will be when\nexported. The colorout returns an image in display profile, so that can't\nbe used, and the profile in colorout can be overwrite on export, so that\nsetting can't be used, so we add this new setting.\nYou can also check why people ask for it here:\nhttps://www.mail-archive.com/darktable-user@lists.darktable.org/msg06952.html\nNo idea if other programs have something similar or if they don't have it\nwhy.\nEl jue., 7 feb. 2019 a las 13:16, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk I'm starting to understand now.\nAnother question if you don't mind (and possibly a stupid question as I'm\nno expert in this area), is this a kind of \"working\" profile? I mean, is\nthat needed because most of the pixelpipe is Lab? I'm trying to understand\nwhy there is no such profile in other software?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-461493044,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pT5TFLJ13lZ4KUJsLInO4jK9etNDks5vLFFygaJpZM4anMx-\n.\n. > I don't get why we need another colorspace profile setting - there is\nalready output profile (not display) in colorout. The fact that it can be\noverridden when exporting doesn't matter.\nIt does matter. Is the same concept as the gamut check, why it makes sense\nto have a profile for the gamut but not for\noverexposed/histogram/colorpicker?\n. > I guess it makes sense in case of CMYK printer profile, which I think\ncan't be used as output profile. Otherwise I don't see why it should be\ndifferent either.\nYou select output profile and develop with it in mind, so it makes sense\nto see histogram/overexposed in that colorspace, why would it need to be\ndifferent? What workflow do you imagine where 3 separate settings for\ncolorspace (4 if you count display profile) is needed?\nI don't, this is based on some requests and I thought it was a good\nsolution. The problem with the output profile, as I said, is that can be\noverwrite, to check with that other profile you'll need to change the\nsetting on the output profile.\nI have also considered to use the softproof profile, but it doesn't have\nthe display profile option (I don't know why, so I won't change it without\nknowing) and also I'm not sure if there's a scenario where it makes sense\nto have separate settings for  softproof and overexposed, and I didn't want\nto introduce a limitation.\n\nMy main goal here is to have a way to configure the profile for the\noverexposed/histogram/colorpicker, If the problem with this feature is only\nthe extra profile that's easy to change, I can use any of the already\nexisting profiles (as long as the display option is available), but as long\nas I'm playing with this I would like to make it useful for as many users\nas possible.\n. I'm discussing this in two threads and that's never a good idea, but it seems that there are many different uses for this, and more generic means not-as-easy-to-use.\nWhat I take so far is that some people want to check things with the printer profile to know that when printed everything will be OK.\nOthers with the export profile, because the same reason.\nOthers before the export profile is applied, because what @aurelienpierre  says.\nI don't want to tell people what or how they should do things and I do want that dt provides the tools so each one can do their edits.\nI think that this approach allows for all the scenarios, it adds a couple of clicks more than an automatic thing, but I don't see a way around it.\n@aurelienpierre , I should think a bit more about it, but when checking for overexpose I want to know if an individual channel is overexposed, not only the luminance.. Don't forget about the soft proof profile!\nIt does seems like an overkill and maybe we should rethink the entire\nprofile thing.\nThe output profile is obviously needed.\nThe overwrite profile (on the export module) is a nice thing to have.\nThe soft proof & gamut check are very common.\nMaybe we can consider merging the soft proof & gamut profile with the\noverexpose one, as I said before I created a new one so I don't introduce a\nlimitation, but if everybody is OK with it I can do the change.\nEl jue., 7 feb. 2019 a las 18:37, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWhat I don't like in this is that we have now:\n\noutput profile\nprofile set in the export module\nand the overexposed profile\n\nAnd if I'm not mistaken those are all connected together and ideally the\nsame profile should be used in the 3. This is not appealing :( Or am I\nwrong.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-461605101,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pW2Z6R_iBpJvYM6bv90ilYOAPtR-ks5vLJyEgaJpZM4anMx-\n.\n. > I don't think that's a good idea. Gamut has to do with\nchrominance/saturation. Exposure has to do with luminance.\nSure, but when you check for those, do you use different profiles?\nLet's say you check overexposed/histogram/colorpick in linear rec 2020, do\nyou check the gamut with other profile?\n. > Right now, the overexposition preview overlaps with the out-of-gamut\nWhat do you mean by overlaps?\n. Let's try another approach,\n\nIn any workflow we have the following profiles:\ninput\nworking\nexport\ndisplay\nprint\nSome programs may have it hard-coded, others configurable, but they're always there.\ndt don't have a working profile, that's added on PR 1841, until then the user will have to select it manually.\nWhat I suggest is:\n-rename the softproof (or gamut) profile with print profile\n-rename my new overexposed profile with view profile (or some better name)\n-create two new categories in addition to DT_COLORSPACE_DISPLAY: DT_COLORSPACE_PRINT and DT_COLORSPACE_EXPORT\n-the profile view combo box will have:\ndisplay profile\nexport profile\nprint profile\n(all the user selected profiles from out)\nThis way the design is more clean, and the user is a one click away from viewing the data in any point of the workflow he wants.. > Printing and exporting profiles are just output profiles for files. I\n\ndon't think we need to split the feature, they work the same, but for\ndifferent outputs.\nBecause they work for different outputs is why we need to split it.\n. I think we are talking about different things, so let's first try to be on\nthe same page.\n\nThis PR is about allowing the user to see the data at any point of the\nworkflow (as described above). Right now this is hard-coded, and that is a\nbad design, things should never be hard-coded if can be avoided. That's why\nthey are working on the UI refactor, dt is a raw developer, how we see the\ndata is far more important than the UI, so there should be no discussion\nabout this.\nWith my last proposal, if I want to see the how the data will look like\nwhen printed I select print profile from the profile view combobox.\nif I want to see the how the data will look like when exported I select\nexport profile from the profile view combobox.\nif I want to see the how the data look like before any profile is applied\n(that will be the concept of the working profile) right now I have to\nselect it manually from the list on the profile view combobox, Eventually\nwe will have a working profile entry.\nThe view profile will affect the histogram, color picker, overexposed,\ngamut and soft proof. I propose this because is reasonable to assume that\nif I'm checking the gamut in one profile I'll want to check the pixel\nvalues for areas out-of-gamut on that same profile, and probably the\nhistogram too.\nI'm sure that there are people out there that will prefer to have separate\nsetting for the gamut, and others may want individual setting for each one.\nBut this design is cleaner, easy to use, and probably work for most users.\nAnd changing from one profile to another is very easy, just select it from\nthe view profile. We do the same when editing, we search for the module,\nexpand it, and adjust the setting, and that happens far more often than\nchanging the view profile.\nEl s\u00e1b., 9 feb. 2019 a las 8:45, parafin (notifications@github.com)\nescribi\u00f3:\n\n\n@aurelienpierre https://github.com/aurelienpierre, I didn't\n   comment on how overexposed (both ordinary and raw) should work and whether\n   it's broken now, because I haven't looked at the code. It should be defined\n   what is considered overexposure, and looking at DT user manual I guess you\n   are correct that current implementation is broken. Raw overexposure on the\n   other hand shouldn't be affected by any module at all, since it's described\n   as working on raw input.\n@edgardoh https://github.com/edgardoh, as for profile settings -\n   I'm not convinced either that export and print profiles should be\n   separated. And I didn't understand where do you want to put these\n   preferences (view, export. print). Also I don't think it's useful to see\n   overexposed areas or gamut check for display profile - display profile is\n   only for displaying stuff, nothing else.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-462037568,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pccZVWnX6kZ56qLsFFXjZeoLU4tYks5vLrTkgaJpZM4anMx-\n.\n. @TurboGit , not sure I understand, I don't know the print module and maybe I'm thinking at the naive version. If I want to generate the pixel values that are sent to the printer (for display on the colorpicker for instance), if not enough to apply to the image (whatever the colorspace of the image) the print profile? There's some intermediate steps required?. > @edgardoh https://github.com/edgardoh, so I'll ask again - where do you\npropose to put UI controls for selecting each of those profiles? colorout\nIOP? gamut check menu? What would to be the steps for user to see gamut\ncheck for, say, \"view\" profile?\nMy first thought on the UI will be:\n-add the view profile combobox on the darkroom, to the left of the\nrawoverexpose button\n-remove the right-click popup on the gamut and soft proof buttons\n-add a new, dedicated button, like the one on the lighttable, with the\ncombobox for display profile and print profile\n\nThe view profile combobox will have the following entries:\n-display profile: it will take the value from the display profile combobox.\nThis is just for backward compatibility, the default will be export anyway.\n-export profile: if selected it will take the value from the colorout\nmodule (the value selected on the output color profile combobox, not the\nactual profile applied to the image)\n-print profile: if selected it will take the value from the print profile\ncombobox.\n-a list of profiles taken from out, like the gamut check is doing right now.\nGamut, soft proof, histogram, color picker, they all will work with the\nprofile select on the view profile combobox.\nIf I want to gamut check using the print profile, I select print profile\nfrom the view profile combobox and click on the gamut check button.\nSame if I want to soft proof.\nWhile the view profile combobox has print profile selected the color picker\nand histogram will display the data using that profile.\nThis makes the bottom of darkroom a bit more busy, but will make more\nobvious the profile the user is working with and easier to change it if\nneeded.\n. > It's more clear now, thanx. Some notes:\n\n\nyou are moving display profile from colorout iop to bottom panel,\n   might be a little hard to do currently;\n\nNot sure I get this, colorout don't have an option \"display profile\", it\nuses it internally while in darkroom, but I'm not changing that, the image\ndisplayed will still be in display profile. What may be in a different\nprofile are the color picket, etc..\n\nprint profile is just a helper for user so he doesn't have to look\n   for it in the whole list of out profiles, I guess it might be useful;\n\nCorrect\n\non the other hand there's no such helper for \"view\" profile\n   (working profile) - say user wants histogram in ProPhoto space, but after\n   he selects print profile in view combobox in order to get back to ProPhoto\n   he will have to browse through whole list of out profiles to find his\n   choice of \"view\" profile;\n\nCorrect, its a limitation. PR 1841 introduces a working profile, until\nthen it will be hand picked.\n\nalso you are complicating soft-proofing/gamut-check - right now\n   user selects gamut check profile once and then can toggle gamut check with\n   just one click, with your suggestion he will have to select another profile\n   in view profile combobox, then switch on gamut check (and reverse procedure\n   for turning it off) - it's a lot more time-consuming.\n\nI don't see it as a lot more time consuming, is just a click more. If I\nwant to gamut check then I select print profile (or any other profile) and\nclick on gamut check, to disable gamut check I click again on gamut check\nand depending on what I want I select another profile on the view profile\ncombobox.\nNote that you don't need to be on a specific view profile to do your edits,\nthis setting only affects the color picker, histogram, etc, so you may do\nyour edits with view profile=printer and the only difference is that you'll\nsee the histogram and colorpicker values on the printer profile. And maybe\nthat's what you want.\nI'm proposing it like this because people may want to gamut check things in\nprofiles other than print. Let's say I send an image for printing, I want\nto gamut check the image I send (with export profile) and the printed image\n(with print profile)\n3 might not need fixing if 4 is fixed. 4 can be fixed by leaving alone\ngamut check profile and switching view profile to that setting\nautomatically when user switches on soft-proofing or gamut check. This will\nresult in us having these settings for color out profiles:\n\ndisplay - needed\nview/working - useful for fixing histogram until real fix gets\n   merged\nexport - needed\nprint - just a helper for faster switching between export and print\n   profile in gamut check\ngamut check - just a setting for gamut-check/soft-proofing, will be\n   set to one of the 2-4 most of the time\n\nNot sure I'm following this, gamut profile no longer exits, it has been\nreplaced by print profile. And by switching the view profile when gamut\nchecking is selected I will be limiting the gamut check to one profile.\nMy question is the following - can't this PR wait until real fix for RGB\nworking space is merged? It will change the meaning of view/working\ncolorspace somewhat and make most of the code in this PR obsolete (aside\nfrom UI changes).\nI don't know if you have a specific development in mind, but I'm doing this\ntaken into account PR 1841, it will work just fine with it.\n. Let's try the following scenario: I have a picture that I want to post on\nfacebook, my personal web page, and also print, so\n\nFirst I do a generic edit on some wide gamut profile, let's say prophoto\n1-I set the output color profile to prophoto and do all may edits. When I'm\nhappy I check gamut, I do this in prophoto, right now I don't have any\nother profile, so I don't need to change anything\n2-I create a duplicate to work on my facebook version. I set the output\ncolor profile to sRGB, fine tune it until I'm happy and again check gamut.\nI want this in sRGB because that's what I'll use to output.\n3-Same for my personal web page, but instead of sRGB I use a custom\nprofile. All the steps are the same.\n4-I'll work on my print version now, I don't own a printer so I will\ngenerate a tiff that I'll to print. I set the output color profile to\nprophoto and the print profile to the one that will be used to print. I\nfine tune the image and check the gamut. I didn't change anything so the\ngamut will be checked on the output profile, and that's what I want.\nWhen I'm happy I'll check how it will look like when printed, so I change\n(for the first time) the view profile to print, check the gamut and fine\ntune again if there is any out-of-gamut issue. This last fine tune I want\nto do it in print profile, so I can check the data and histogram on the\nsame profile.\nThis seems very reasonable to me.\nBut also, my current implementation has the gamut and histogram separate,\nand no one seem to like it, so I have to ask, why my current implementation\nis not OK?\nEl s\u00e1b., 9 feb. 2019 a las 16:53, parafin (notifications@github.com)\nescribi\u00f3:\n\n\nyou are moving display profile from colorout iop to bottom panel,\n   might be a little hard to do currently;\n\nNot sure I get this, colorout don't have an option \"display profile\", it\nuses it internally while in darkroom, but I'm not changing that, the image\ndisplayed will still be in display profile. What may be in a different\nprofile are the color picket, etc..\nRight, sorry, it has already been moved some time ago, nevermind about\nthat point.\n\nprint profile is just a helper for user so he doesn't have to look\n   for it in the whole list of out profiles, I guess it might be useful;\n\nCorrect\n\non the other hand there's no such helper for \"view\" profile\n   (working profile) - say user wants histogram in ProPhoto space, but after\n   he selects print profile in view combobox in order to get back to ProPhoto\n   he will have to browse through whole list of out profiles to find his\n   choice of \"view\" profile;\n\nCorrect, its a limitation. PR 1841 introduces a working profile, until\nthen it will be hand picked.\n\nalso you are complicating soft-proofing/gamut-check - right now\n   user selects gamut check profile once and then can toggle gamut check with\n   just one click, with your suggestion he will have to select another profile\n   in view profile combobox, then switch on gamut check (and reverse procedure\n   for turning it off) - it's a lot more time-consuming.\n\nI don't see it as a lot more time consuming, is just a click more. If I\nwant to gamut check then I select print profile (or any other profile) and\nclick on gamut check, to disable gamut check I click again on gamut check\nand depending on what I want I select another profile on the view profile\ncombobox. Note that you don't need to be on a specific view profile to do\nyour edits, this setting only affects the color picker, histogram, etc, so\nyou may do your edits with view profile=printer and the only difference is\nthat you'll see the histogram and colorpicker values on the printer\nprofile. And maybe that's what you want. I'm proposing it like this because\npeople may want to gamut check things in profiles other than print. Let's\nsay I send an image for printing, I want to gamut check the image I send\n(with export profile) and the printed image (with print profile).\nI disagree here. First of all it's more than one more click - you also\nneed to find where to click. Secondly I don't think always seeing histogram\nin print color profile is a good idea - I assume histogram is useful to\nlook at during picture development, so it should be output-independent.\nPrinters are interchangeable, user can have several choices of printers, so\nwhile it makes sense to check how it will look on specific output device\nonce in a while, one doesn't develop pictures just for that device IMHO.\nBasically if user wants to develop the picture like that he will just keep\nsoft-proofing on all the time, which will switch histogram to that color\nprofile. As for last point about gamut checking - it's resolved by keeping\nseparate gamut check profile setting.\n3 might not need fixing if 4 is fixed. 4 can be fixed by leaving alone\ngamut check profile and switching view profile to that setting\nautomatically when user switches on soft-proofing or gamut check. This will\nresult in us having these settings for color out profiles:\n\ndisplay - needed\nview/working - useful for fixing histogram until real fix gets\n   merged\nexport - needed\nprint - just a helper for faster switching between export and print\n   profile in gamut check\ngamut check - just a setting for gamut-check/soft-proofing, will be\n   set to one of the 2-4 most of the time\n\nNot sure I'm following this, gamut profile no longer exits, it has been\nreplaced by print profile. And by switching the view profile when gamut\nchecking is selected I will be limiting the gamut check to one profile.\nIt exists in my proposal to keep it;) So no limitations if it stays.\nMy question is the following - can't this PR wait until real fix for RGB\nworking space is merged? It will change the meaning of view/working\ncolorspace somewhat and make most of the code in this PR obsolete (aside\nfrom UI changes).\nI don't know if you have a specific development in mind, but I'm doing\nthis taken into account PR 1841, it will work just fine with it.\nI retracted that question.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-462074138,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWGDE_lNYcdvezayNo9EIv71PFdUks5vLycggaJpZM4anMx-\n.\n. This is not my workflow but an example that I have manufactured because it\nseems complex.\n\nIf you want, you can describe your typical workflow and see how my proposal\nfits into it.\nEl s\u00e1b., 9 feb. 2019 a las 19:28, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\n1 - checking gamut in Prophoto makes no sense, this space has imaginary\ncolors that are out of the visible locus.\n2 - you really don't want to duplicate your edits depending you\ndestination/output color space. That's the whole point of an\noutput-agnostic pipeline. What you want is edit just once, and check that\nLittleCMS gamut mapping does its job properly in all the output spaces you\nneed.\nPlease read\nhttps://github.com/darktable-org/darktable/wiki/Developer's-guide#understanding-color-and-color-management\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-462085176,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pabepKZGFXjFOxqtpM94TZnD8Cr7ks5vL0upgaJpZM4anMx-\n.\n. >\n@edgardoh https://github.com/edgardoh, I'm confused about your\nscenario, because you say 4 is the first time you have to change view\nprofile, but it's not, you have to change it for 2 and 3 to get gamut\nchecking in needed color space (in your description you changed only output\ncolorspace).\nI don't need to change anything until 4 because the output profile is the\ndefault profile on the view profile, so by changing the output profile I'm\nalso changing the view profile\nSecondly what exactly are you tuning in steps 2 and 3? Changing output\ncolor profile won't change anything visible in darkroom unless you change\n\"view\" profile or enable soft-proofing.\nIf view profile is set to output profile, changing output profile will\nchange histogram, color picker, gamut, etc.\nThe problem with your described workflow is that it will become broken\nafter RGB working color space gets implemented, then changing \"view\"\nprofile will affect also the processing and output of the pipe. That's not\nwhat you want. And the idea is to not have yet another one color space\nsetting. You get histogram/color picker in the working colorspace unless\nyou enable soft-proofing/gamut check.\nThe working colorspace, no matter how is implemented, should affect things\nonly up to the output colorspace, once the image is transformed for output\n(display, export or print) it shouldn't be affected by the working profile\nanymore. Everything I'm doing here works on the final image (final\nhistogram, global color picker, gamut and soft proof) so the working\nprofile has nothing to do with it.\n\nI give some more thoughts to your proposal, and for what follows you'll\nhave to check how the current implementation works, but it seems to me that\nby adding the following to what's already done we get what you propose:\n1-add to the overexposed profile the new categories output profile, gamut\nprofile\n2-make gamut check take priority over overexposed profile, that is, when\ngamut check is active color picker and histogram will work on the profile\nselected on gamut\n3-re-arrenge the UI to make it more user-friendly\nIf this is what you are suggesting I'm OK with it.\n. Let's take a couple of steps back. Right now the histogram and color picker collect the data from the image that is sent to the display, for short I call that the data is in display profile. We all agree that this isn't right. I also think that what's not right is that the profile is hard-coded, is not a good idea to hard-code things, so if the working profile is implemented and the histogram is always displayed in working profile that will be just wrong. I want to be able to check the data not only before the output profile is applied but also after, and for any export profile (file or print).\nI'm sure that you want that too, you said that you edit with the output in mind, so you'll probably want to check things with the output profile, maybe not all the time, but I'm sure that you want the option (I know I do)\nIn order to do this we have (at least) this options\n1-histogram, color picker, gamut and soft proof all work with the same profile\n2-histogram and color picker work with one profile and gamut and soft proof work with another profile\n3-there's an independent profile for each one of them\nMy current implementation is option 2 and that's also your proposal, so I say go with that. If at some point it is decided that histogram and color picker should have their own setting it will be some work, but for now this seems reasonable and is already an improvement on what we currently have.\nWhen working profile is implemented it should be added to the list of options for the histogram and color picker because, again, hard-code it will be wrong.\nIf you agree with this we can continue fine tuning the design. . @TurboGit , your call.. In the case of this settings the default actually is what is used in case\nsomething goes wrong, if the user selects a profile from file that\neventually dt can't read, it will fall back to the default, otherwise the\nsetting is \"remembered\".\nRight now we don't have a working profile, so the output profile is\nprobably a good choice.\nEl lun., 11 feb. 2019 a las 18:17, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, I've reread most of the comments here. I can't say that I understand\nall the details but I agree that option 2 is a good compromise for now.\nMy feeling also that this will certainly not be easy to grasp for most\nusers.\nOne side question. What will be the default for the picker/histogram\nprofile? Will it be \"same as gamut/softproof\"? Something else? In other\nwords, what would be a good default?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-462497938,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRWstL_-iMX_rHm9nO8Si6AaHUzdks5vMd3-gaJpZM4anMx-\n.\n. New version is ready.\n\nI have moved the overexposed profile to the softproof popup and renamed it as histogram profile (tooltip says histogram and color picker).\nI have also renamed the output profile on the output color profile iop as export profile, it does seems more accurate.\nHere is how it works:\nWhen in soft proof or gamut check, the histogram and color picker use the soft proof profile.\nIn any other case they use the option selected on histogram profile.\nThe histogram profile has this entries:\n-export profile, if selected the profile selected on the output color profile iop is used\n-softproof profile, if selected the softproof profile is used\n-system display profile, idem\n-a list of profiles from \"out\"\nThe overexposed always uses the histogram profile, is not mentioned anywhere in the GUI in case what @aurelienpierre suggest is ever implemented.\nI don't print, so it will be helpful is someone that does can test it with an actual print profile and his own workflow.\n. Color picker uses uint8 for the rgb values, so for clipped channels results are incorrect. I'll deal with that in a separate PR after this one.. I know, check the dev-list.\nEl mi\u00e9., 20 feb. 2019 a las 5:01, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nThere is a problem with the circuitery for the over-exposed alert: the\ncolors actually change in the image depending on the histogram profile. The\nimage shown should be in display color space anytime. To compute the alert,\nthe colorspace conversion should be done outside the pixelpipe (a dry-run,\nif you want), then, only the clipped pixels should be applied as an overlay\non top of the image.\nAlso, changing the histogram profile while the gamut alert is on segfaults.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2069#issuecomment-465466477,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pct-ujWrLsNyPKZH9igBKWkv2d-yks5vPQDmgaJpZM4anMx-\n.\n. Confirmed.. The same rgb value you see on screen is what's sent to the widget, is that value correct?. This is amazing! I have never been able to get good results with this denoise until now, thanks soooo much!. I'm having an issue, when exporting downscaled is like the module is disabled, there's no effect at all, if I export in HQ then things go back to normal. Is this expected?. OK, thanks for the explanation.\n\nEl vie., 15 mar. 2019 a las 6:04, rawfiner (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh This issue was already here in\n2.6 (and before).\nThe module still has some effect, but the effects are different than the\nones we could expect: for instance there is undersmoothing.\nThe problem is that it is hard to adapt the algorithms to downsampling.\nIf we note I the original image, D the downsampling, f the denoising\nfunction, p its parameters, it is hard to find parameters p' such as:\nD(f(I,p)) = f(D(I),p')\nFor now, the parameters p' which are estimated are not good enough.\nIf you want the result to be accurate with what you see at 100% zoom, you\nhave to select the option \"do high quality resampling during export\", so\nthat downsampling is down at the end of the pipe and not at the beginning.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2127#issuecomment-473209526,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRisscLjF-Ju5xtkRrlJC1hq-1W6ks5vW2ItgaJpZM4bN-XY\n.\n. If no one is picking on this I'll start working on it.. I get the following travis errors generated:\n\n/lib_darktable.dir/common/undo.c.o   -c /build/darktable/src/common/undo.c\n/build/darktable/src/common/undo.c:61:1: error: mutex 'self->mutex' is not held on every path through here [-Werror,-Wthread-safety-analysis]\n}\n^\n/build/darktable/src/common/undo.c:57:5: note: mutex acquired here\n    dt_pthread_mutex_lock(&self->mutex);\n    ^\n/build/darktable/src/common/undo.c:67:5: error: releasing mutex 'self->mutex' that was not held [-Werror,-Wthread-safety-analysis]\n    dt_pthread_mutex_unlock(&self->mutex);\n    ^\n2 errors generated.\n. @TurboGit , I still get the error.\nI'm not saying that the fix does not work, just that travis is complaining. And I'm bringing this up just so when you see the error here you'll have an idea of what's going on, unlike travis I'm not complaining.. This is by design, the regular color picker is not deactivated when\nchanging tabs so I don't deactivate this one. If the user changes tabs\nwhile active probably he wants to select the range for that tab.\nThe other option is to deactivate the picker, but since we don't \"remember\"\nthe area I think this is better.\nRemembering the are is in my to-do list, but right now I have no idea how\nto do it.\nAll other fixes are ready.\nEl lun., 4 mar. 2019 a las 10:43, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@TurboGit requested changes on this pull request.\nNice, really nice! Some comments on the code, also:\n\nwe should deactivate the blend pickers when the blend params are\n   reset\na bug with the range selection color picker:\nselect exposure\nselect parametric mask\nselect channel H\nselect range selection picker, draw an area\nthe range is selected ok\nselect channel B, a range is also set in this channel which is\n  wrong\nselect channel G, no range selected\n\n\n\nIt seems that the first channel change still do a range selection.\nIn src/common/color_picker.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262047611\n:\n\n#include \"develop/format.h\"\n #include \"develop/imageop.h\"\n #include \"develop/imageop_math.h\"\n\nstatic void color_picker_helper_4ch_seq(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                         const dt_iop_roi_t roi, const int const box, float const picked_color,\n-                                        float const picked_color_min, float const picked_color_max)\n+                                        float const picked_color_min, float *const picked_color_max,\n+                                        const int cst_to)\nconst dt_iop_colorspace_type_t cst_to\nIn src/common/color_picker.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262047664\n:\n\n }\n\n}\n }\n\nstatic void color_picker_helper_4ch_parallel(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                              const dt_iop_roi_t roi, const int const box,\n                                              float const picked_color, float const picked_color_min,\n-                                             float const picked_color_max)\n+                                             float const picked_color_max, const int cst_to)\nconst dt_iop_colorspace_type_t cst_to\nIn src/common/color_picker.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262047721\n:\n\n@@ -129,14 +135,14 @@ static void color_picker_helper_4ch_parallel(const dt_iop_buffer_dsc_t *dsc, con\n\nstatic void color_picker_helper_4ch(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                     const dt_iop_roi_t roi, const int const box, float const picked_color,\n-                                    float const picked_color_min, float const picked_color_max)\n+                                    float const picked_color_min, float *const picked_color_max, const int cst_to)\nconst dt_iop_colorspace_type_t cst_to\nIn src/common/color_picker.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262048329\n:\n\n@@ -395,10 +401,14 @@ static void color_picker_helper_xtrans(const dt_iop_buffer_dsc_t *dsc, const flo\n\nvoid dt_color_picker_helper(const dt_iop_buffer_dsc_t dsc, const float const pixel, const dt_iop_roi_t roi,\n                             const int const box, float const picked_color, float const picked_color_min,\n-                            float const picked_color_max)\n+                            float const picked_color_max, const int image_cst, const int picker_cst)\nconst dt_iop_colorspace_type_t image_cst, const dt_iop_colorspace_type_t\ncst_to\n\nIn src/develop/imageop.h\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262048826\n:\n\n@@ -280,6 +281,12 @@ typedef struct dt_iop_module_t\n   float picked_color[4], picked_color_min[4], picked_color_max[4];\n   / place to store the picked color of module output (before blending). */\n   float picked_output_color[4], picked_output_color_min[4], picked_output_color_max[4];\n+  / requested colorspace for the color picker, valid options are:\n+   * -1: module colorspace\n+   * iop_cs_LCh: for Lab modules\n+   * iop_cs_HSL: for RGB modules\n+   */\n+  int picker_cst;\n\ndt_iop_colorspace_type_t picker_cst\nIn src/common/color_picker.h\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262049968\n:\n\n@@ -23,7 +23,8 @@ struct dt_iop_roi_t;\n\nvoid dt_color_picker_helper(const struct dt_iop_buffer_dsc_t dsc, const float const pixel,\n                             const struct dt_iop_roi_t roi, const int const box, float const picked_color,\n-                            float const picked_color_min, float const picked_color_max);\n+                            float const picked_color_min, float *const picked_color_max,\n+                            const int image_cst, const int picker_cst);\nconst dt_iop_colorspace_type_t image_cst, const dt_iop_colorspace_type_t\ncst_to\n\nIn src/develop/blend_gui.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262051106\n:\n\n@@ -547,41 +527,101 @@ static void _blendop_blendif_polarity_callback(GtkToggleButton *togglebutton, dt\n   dt_dev_add_history_item(darktable.develop, data->module, TRUE);\n }\n\n-\n-static void _blendop_blendif_tab_switch(GtkNotebook notebook, GtkWidget page, guint page_num,\n-                                        dt_iop_gui_blend_data_t data)\n+static int _blendop_blendif_get_picker_colorspace(dt_iop_gui_blend_data_t bd)\nstatic dt_iop_colorspace_type_t _blendop_blendif_get_picker_colorspace(...)\nIn src/develop/blend_gui.c\nhttps://github.com/darktable-org/darktable/pull/2151#discussion_r262051315\n:\n\n{\n-  data->tab = page_num;\n-  dt_iop_gui_update_blendif(data->module);\n-}\n+  int picker_cst = -1;\n\ndt_iop_colorspace_type_t picker_cst;\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#pullrequestreview-210125931,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWAIHaVrkVVA45d5u7jKvYAIQrc4ks5vTSL8gaJpZM4bbnMw\n.\n. That was a bug, should be fixed now.\n\nEl lun., 4 mar. 2019 a las 12:20, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, I agree that the behavior makes sense. But in that case why only the\nselection apply to the first change of tab?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469290849,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZX10ILmEUo2jKCfwgG5y5pi58BYks5vTTm0gaJpZM4bbnMw\n.\n. I don't understand this one...\n\nEl lun., 4 mar. 2019 a las 14:44, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, looks better now. A little issue still. When the range is selected in\nany blend channel, the 4 values (just above the slider) are not updated to\ncorrespond to the actual selected area.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469346541,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcFlvCUUGWVncPJX-qOVfuVcNvY5ks5vTVtpgaJpZM4bbnMw\n.\n. The feather is hard-coded to 0.01f (both left and right), the cursors in\nthe middle are exactly the range values. I don't like hard-coded things but\nI can't find a formula that gives good results on all scenarios.\nI haven't used it enough to say what the best values may be, but for now I\nthink is best to leave the cursors in the middle to have the exact range\nvalue (that's the difficult part to achieve by hand). I can increase the\nfeather if you find it too small, 0.02f will be OK?\nThis is an auto feature anyway, so we can change it at any point if we find\nsomething better without having to worry about backward compatibility.\n\nEl lun., 4 mar. 2019 a las 14:46, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nAlso I find that the feather between the cursor (2 steps actually) is a\nbit small and creates by default some scale. Of course having a wider\nfeather will select more than the selected area... But maybe 2 steps inside\nthe computer range and 2 steps outside (for a total of 4) will alleviate a\nbit this issue.\nWhat do you think?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469347579,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWmAgEPMyM60J3R-kDPvscNgUeYbks5vTVwRgaJpZM4bbnMw\n.\n. >\nI don't understand this one...\nThe 4 values representing the selected range in the sliders are not\nupdated.\nI have updated the 0.02f, but either I can't duplicate this or I still\ndon't get it. When I draw an area the slider is updated, on any of the\ntabs.\n. Oh! The labels!\n\nEl lun., 4 mar. 2019 a las 15:32, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nLet's look at the screenshot, I have marked in red the values not updated.\n[image: capture d ecran de 2019-03-04 19-30-17]\nhttps://user-images.githubusercontent.com/467069/53754440-3a9e5080-3eb4-11e9-83f7-469b53690166.png\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469364422,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pR2D-l6vPcQLgFPXIHGx83tOwm0rks5vTWa8gaJpZM4bbnMw\n.\n. Its ready, I have also:\n\n-take your suggestion and made the feather around the selected values,\nseems nicer this way\n-reset the color picker if slider values are changed, it makes strange\nthings otherwise. This is only for the set values, the regular color picker\nis not reset.\nEl lun., 4 mar. 2019 a las 15:32, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nLet's look at the screenshot, I have marked in red the values not updated.\n[image: capture d ecran de 2019-03-04 19-30-17]\nhttps://user-images.githubusercontent.com/467069/53754440-3a9e5080-3eb4-11e9-83f7-469b53690166.png\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469364422,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pR2D-l6vPcQLgFPXIHGx83tOwm0rks5vTWa8gaJpZM4bbnMw\n.\n. @TurboGit , we should do something about the documentation. I won't update the user manual for obvious reasons, but if you ask me by the end of the year what I have done I probably won't remember half of it.\nMaybe something as simple as a text file somewhere that can be updated with each feature, so when someone wants to update the manual we can be sure that everything is there.\nYou can even force to have some description with each new feature.\nWhat do you think?\n. Seems OK to me, let's give it a try. I'll start with the color picker and\nwe can take from there.\n\nEl mar., 5 mar. 2019 a las 15:57, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nGood idea! I was thinking alike just this morning. I suppose the new\nfeatures can be documented into the RELEASE_NOTES.md file.\nJust list that in [New Features And Changes] section. Works for you?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2151#issuecomment-469814161,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pYTmLCfRZL8QZghC5kIkGMMWYtmQks5vTr4ngaJpZM4bbnMw\n.\n. > And BTW, not sure the obvious reasons are so obvious :) Is that because\nyou're not a native English? I'm not but we have nice people on the project\nthat will review the text to ensure the wording is correct.\nNot just I'm not native but my english skills s*ks, I'm not comfortable\nwriting in english and will be probably more work for everyone involved to\nreview and re-write than just do it right from the beginning.\n. The picker here returns LCh (now), on the tone curve Lab. I have taken this\nfrom this iop, but the blend_gui does something different, no idea which\none is correct, but because of backward compatibility better not to change\nit.\n\nEl mar., 5 mar. 2019 a las 15:42, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@TurboGit commented on this pull request.\nIn src/iop/colorzones.c\nhttps://github.com/darktable-org/darktable/pull/2157#discussion_r262636892\n:\n\n@@ -568,12 +569,19 @@ static void dt_iop_colorzones_get_params(dt_iop_colorzones_params_t *p, const in\n   }\n }\n\n+static void picker_scale(const float const in, float out)\nWe have a picker_scale in tonecurve.c, the implementation is quite\ndifferent even if somehow similar. Is that expected? Is that because we\nhave two different CS?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2157#pullrequestreview-210853624,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcUEdsLJMd12ac5svBnZK_raTLpAks5vTrqMgaJpZM4bfD4H\n.\n. Added opencl.. >\n   - it would be nice, in \"hue\" selection mode, to have these hues\n   represented in the background of the curve, like it was in the old\n   colorzone module\nNot sure if I get this. Right now the histogram, bottom bar and color\npicker use the \"select by\" channel. The background use the modified channel\n(the tabs). If the color picker is active, the selected color is used to\ndraw things, if not, a hard-coded blue color is used.\n. >\nYet, wouldn't it make sense to have a shade of hues instead of using the\n\"blue\" value when the color picker is not used?\nSorry but still I don't get it. The background display only the modified\nchannel (the tabs), if I don't have a base color (i.e. the color picker is\nnot active) I have to use something for the lightness and saturation, then\nthe hard-coded color. For the hue I display all the combinations, so for\neach x you know the destination color by looking at the y.\nMaybe if you describe exactly the active tab/select by/color picker status\nI'll get a better understanding of the issue.\n. @rawfiner , the dragging issue should be fixed now, thanks for reporting it!. OK, I get it now, I'm displaying only the modified channel and you like\nbetter to have both the modified & select by channels.\n\nI made it this way because on some combinations I find the mix confusing.\nFor instance, on lightness by saturation I don't really know what I'm\nlooking at, so I always display the modified channel and I added the bottom\nbar for the select by channel. I do it for all the combinations so it is\nconsistent, otherwise it will be even more confusing.\nLet's give it a try to this, if in the end we decide that the previous was\nbetter it can always be changed back, this is only GUI.\nEl vie., 8 mar. 2019 a las 13:29, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nSorry but still I don't get it. The background display only the modified\nchannel (the tabs), if I don't have a base color (i.e. the color picker is\nnot active) I have to use something for the lightness and saturation, then\nthe hard-coded color. For the hue I display all the combinations, so for\neach x you know the destination color by looking at the y. Maybe if you\ndescribe exactly the active tab/select by/color picker status I'll get a\nbetter understanding of the issue.\nWhen the color picker is active, I like the backgrounds of your\nimplementation.\nWhen the color picker is not active, I would prefer to have backgrounds\nsimilar to the ones of the 2.6 version.\nFor instance, on the lightness tab, if I select by hue, I see this:\n[image: colorzone]\nhttps://user-images.githubusercontent.com/34063828/54040327-60ce3400-41c5-11e9-87b2-6712701c3cc8.png\nWhat I like with this representation is that I can see easily which part\nof the curve impacts the greens, which one impacts the red, etc.\nWith the uniform blue gradient of your curve, I am forced to look at the\nhue gradient which is shown bellow, and I find it much less convenient.\nI would like backgrounds to be similar to this when I select by hue\nwithout color picker.\nFor instance, this would give backgrounds like that (these are examples\nmade quickly, not perfect examples, just to show the idea)\nlightness tab:\n[image: colorzone_light]\nhttps://user-images.githubusercontent.com/34063828/54041152-472dec00-41c7-11e9-81a2-a52a6771f51a.png\nsaturation tab:\n[image: colorzone_saturation]\nhttps://user-images.githubusercontent.com/34063828/54041165-4c8b3680-41c7-11e9-97ec-b1c3d7860e2a.png\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-470989768,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pa5gH1NWHf6upcqFk3P44GjLma8Yks5vUpACgaJpZM4bkRx0\n.\n. Its fixed now, thanks.\n\nEl vie., 8 mar. 2019 a las 13:51, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nThanks for fixing the dragging issue, much better now :-)\nAnother little GUI bug:\nonly the curve of the \"active\" channel is reset when we click on the\n\"reset parameters\" button, until we click on other channel:\nbefore clicking on reset parameters:\n[image: colorzone1]\nhttps://user-images.githubusercontent.com/34063828/54042528-a17c7c00-41ca-11e9-888c-b7d30dacfc84.png\nafter:\n[image: colorzone2]\nhttps://user-images.githubusercontent.com/34063828/54042535-a6d9c680-41ca-11e9-9ca2-761de2ffa6e1.png\nthe curve of active channel is correctly flattened, but not the ones of\nthe inactive channels\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-470997289,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pVjhhCzTFKzfrJ1UHgOJkMOiLBXpks5vUpUkgaJpZM4bkRx0\n.\n. > In original implementation it was easier to select a dedicated color (with\nthe sliders) and the area-of-control based on the size of the circle for\nmoving points. Do you plan to add the same level of support in this\nimplementation?\nNot really, but I did this because I don't find the original implementation\nconvenient at all, this is much easy to me, if you want two nodes around a\nhue you just have to cntrl + click to add them, and for moving you have the\nmouse and keyboard + cntrl and shift to select the step. Maybe is just me?\n. I just added the old edit mode back, there's a check box at the bottom.\n\nThere's also a combo to choose between the old process and the new one: smooth=old process, strong=new process.\n@rawfiner , I've been playing with the background and the gradients hue-lightness  / hue-saturation don't look good on this resolution.\nWith the knots close to the bottom bar is now easier to see the select by hue. You can also use the color picker by range and the second color picker to create a curve, so there are a number of options to play with.\nIf you still like better the old background I don't mind adding it back, but it will have to be the big squares with lines and I don't know how to handle the GUI, the only option I can think of is to have another check box to switch between backgrounds.\n. > @edgardoh https://github.com/edgardoh I get again the same issue with\n\ndragging out of the zone when I get out of the zone by dragging toward the\nleft or toward the right (top and bottom are ok)\nI'll check this, if you are talking about the left and right nodes, they\nare tricky, any other on the middle should be removed if dragged to the\nleft.\nConcerning the background:\n\nwhen color picker is activated, I would prefer not to have the\n   histogram shown, so that I can easily see what \"output\" I want and directly\n   drag the curve at the point I want. The histogram makes this harder to do,\n   I think. Maybe an option to display it/hide it would be nice?\n\nI can hide it when the color picker is active, you're right, is not very\nuseful then.\n\nI still prefer the \"idea\" of the old backgrounds when color picker\n   is not activated for lightness and saturation tabs, but if possible without\n   the big squares with lines: the \"hue\" tab background you made is perfect\n   for use with select by hue for instance. Note that I do not know at all how\n   these backgrounds are implemented in the code and if that is something\n   possible to do without too much effort, don't hesitate to tell me if I ask\n   for impossible things.\n\nIs not about the effort, I don't mind doing it, but it does not look nice\nwith the current resolution (the size of the squares) I'll work on a\nprototype so you can see it for yourself.\nAlso, this is only my humble opinion, I do not know what other users would\nthink :-)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-471201408,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pY2NCcAaJP864AIQ0r7jHVzvAryuks5vU-pogaJpZM4bkRx0\n.\n. > I also prefer the old backgrounds.\nWell, that settle it, I'll work on a prototype and we'll take it from\nthere.\n. There's a new option now to switch between backgrounds, let me know what you think.. Just pushed another version\n\n@TurboGit , something like this?\n@rawfiner , not sure how to do that, the issue is here:\nhttps://github.com/darktable-org/darktable/pull/2167/files#diff-43d0368000c0c0077befff968dec18c5R937\nbut it get clipper no matter what I do.... @TurboGit , right, is fixed now.\n@rawfiner , this last version is darker but it doesn't clip, check if you like it better.. > Looks all good to me. One more question, it seems that the \"mix\" slider\n\nand the \"process mode\" (strong smooth) are quite related. Maybe have them\nnext to each other? (\"mix\" just below \"process mode\"). What do you think?\nI agree.\nI'm not sure if I like the 'select by' at the bottom, maybe it should be\nthe first after the graph? On the other hand, probably is not something\nthat will be changed a lot.\n. Done.\n\nI'm thinking about removing the other background, seems that I'm the only one that like it and we'll save one control on the UI and some code, partially duplicated, that will make more difficult to maintain it, what do you think?\n. @TurboGit , should be ready now.. You need to release the mouse button, is not updating while dragging.\nEl lun., 11 mar. 2019 a las 20:52, Paolo Astengo (notifications@github.com)\nescribi\u00f3:\n\nAwesome!\nJust one thing. When I move the eyedropper around the picture, I don't see\nthe vertical line updated on the iop.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-471787308,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pYLRU6skpXJxsYzAhYbcikiHDMICks5vVuwsgaJpZM4bkRx0\n.\n. Very often I work with a particular color, to change the hue and/or\nsaturation, and I find difficult to create by hand a small range. With this\nnew picker I select the color I want to work with and it creates a curve\nwith 5 point, 3 for the max, min and average and 2 for the feather. With\nonly this I can see the effect on the image and if not what I expect I keep\nplaying with the picker until I get something close enough, then I tweak it\nby hand, usually I delete some of the middle nodes, but that depends on the\nimage.\n\nStill, this is not perfect, for small areas is not easy to get the right\ncurve. I would like to have a zoom feature, but I'm still deciding how to\nhandle the GUI.\nEl mar., 12 mar. 2019 a las 3:12, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nAlso, could you give an exemple of the way you use the \"curve create\"\ncolor picker and for what purpose please?\nI like a lot this new interface, thanks for your work!\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-471870520,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1paKgc7qL6AAshpJISNokePXS7TLsks5vV0VAgaJpZM4bkRx0\n.\n. The behavior is the same as in the tone curve (minus bugs, of course), so\nyou can add nodes by cntrl+click, is that what you expect?\n\nThe nodes are deleted when node1.x > node2.x, so no matter if you move it\nto the right or left, if nodes overlap one is deleted. You can try the same\non the tone curve.\nI could make this to work different than the tone curve, but if I stop the\nnode from being moved I'm not sure how to delete it.\nEl mar., 12 mar. 2019 a las 15:17, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nVery often I work with a particular color, to change the hue and/or\nsaturation, and I find difficult to create by hand a small range. With this\nnew picker I select the color I want to work with and it creates a curve\nwith 5 point, 3 for the max, min and average and 2 for the feather. With\nonly this I can see the effect on the image and if not what I expect I keep\nplaying with the picker until I get something close enough, then I tweak it\nby hand, usually I delete some of the middle nodes, but that depends on the\nimage. Still, this is not perfect, for small areas is not easy to get the\nright curve. I would like to have a zoom feature, but I'm still deciding\nhow to handle the GUI.\nOk, thanks for your answer. I tested it a bit more, and liked it.\nWould it be possible to have a mode were the nodes are added on the x-axis\nbut were the curve remains flat? It is not always easy to edit the curve\nfastly when the nodes are already at different y-positions, while when they\nare on a flat curve, we can easily and fastly move them were we want using\nthe \"edit by area\" feature.\nApart of that, a little GUI issue:\nwhen we drag a node towards the right while there is another node at the\nright, the node we drag is deleted when we go too much to the right. I\nwould expect the node to stop going to the right, but not to be deleted.\n(there is this same behavior when we drag the node toward the left, I just\nchoose the right for explaining)\nExample in the image bellow, pushing the node indicated by the arrow\ntowards the right will make it disapear\n[image: colorzone_node]\nhttps://user-images.githubusercontent.com/34063828/54224636-34365700-44fa-11e9-82d5-2e15e973ebd1.png\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-472121955,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWIdjCCLogevCzxlvM2D5OqfMj1Wks5vV-9MgaJpZM4bkRx0\n.\n. I see, plain click create a positive curve and cntrl+click a negative one.\nI like that. Will it work for you if shift+click creates flat one? Or maybe\nplain click creates a flat and with modifiers either positive or negative?\n\nEl mar., 12 mar. 2019 a las 15:33, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nOk, I did not notice that it was the case with tone curve, and indeed it\nis the case!\nLet's keep the behaviors consistent with the tone curve then.\nThanks for the quick answer :-)\nRegarding the first part of my comment, to clarify, I was referring to the\n\"curve create\" tool. My question was if it would be possible that this\npicker, instead of creating a curve, only adds nodes on a flat curve at the\npositions of max, min, average, and feather points?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-472128372,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdrtg2vRnjKsgCHpmsu79qlA1MT1ks5vV_MMgaJpZM4bkRx0\n.\n. > My two cents: This interface is different enough from the old one that it\nmight be upsetting to some users... making it a new module instead would\nfree you from constraints and allow for improving it in whatever other ways\nmight occur to you. :)\nThat said, the only problem I'm having with it so far is that\nright-clicking to add a spline immediatly adds it at the y=0 position,\nregardless of where I clicked. This could be an issue with my somewhat old\nGTK3 version (3.18.9) if nobody else is seeing it.\nCntrl+click add a node to the existing y, not to y=0.\n. Have you ever user the tone curve?\n\nEl jue., 14 mar. 2019 a las 19:47, junkyardsparkle (\nnotifications@github.com) escribi\u00f3:\n\nCntrl+click add a node to the existing y, not to y=0.\nSo it's the intended behavior? It seems \"unexpected\" compared to any other\ncurve tool I've ever used.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-473094868,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pbPRQbaQya8KnUWCshA-VHCvyVcPks5vWtFzgaJpZM4bkRx0\n.\n. dt tone curve work like this. Actually, this works like the tone curve.\n\nEl jue., 14 mar. 2019 a las 19:56, junkyardsparkle (\nnotifications@github.com) escribi\u00f3:\n\nHave you ever user the tone curve?\nThe one in darktable, yes, and many other ones over the last 20 years.\nNone of them exhibit this behavior.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-473097008,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQXSj8DQbzSHyrHXDQvi1GthIMgxks5vWtOrgaJpZM4bkRx0\n.\n. It still works the same as the tone curve for me, the node is created where\nthe mouse is, if you place it over the curve you'll get a node at y=0, if\nyou place it on the top, the node is created on the top.\n\nEl jue., 14 mar. 2019 a las 21:58, junkyardsparkle (\nnotifications@github.com) escribi\u00f3:\n\nOk, I have more time now, maybe I can explain better now what's happening.\nIf darktable's tone curve module, if you left-click ~on the existing curve,\nthen move the mouse even slightly, a node is created at the position of the\nmouse. This is the expected behavior. In this module, if I do the same\nthing, I get this:\n[image: screenshot-1552610640]\nhttps://user-images.githubusercontent.com/4522189/54400750-9d94a200-4681-11e9-9090-b48e25026def.png\nThe node is created at the top of the grid, instead of at the mouse\npointer in the center. Maybe y=0 wasn't the best way to describe this, but\nhopefully the screenshot makes it clear.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2167#issuecomment-473120363,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pYY4jqy1V6CfeQYKzvMAFopMvXDhks5vWvA0gaJpZM4bkRx0\n.\n. I'm ok with 2 digits for exposure, but I'm not sure about the %, the\ncurrent contrast, brightness saturation don't use a %, shouldn't this be\nthe same?\n\nEl vie., 8 mar. 2019 a las 5:11, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nMaybe use a % for sliders contrast, brightness and saturation.\nFor exposure 4 digits are too much, 2 will be certainly enough (as in\nexposure module). This will make this simple module even more beginner\nfriendly.\nIf you agree and don't have time I can handle this?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2168#issuecomment-470842900,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pU_MeiQz8Fn62g_mcQ637SYApWlVks5vUhspgaJpZM4bkVXS\n.\n. I just moved all to 2 digits, seems nice this way.\n\nEl vie., 8 mar. 2019 a las 5:11, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nMaybe use a % for sliders contrast, brightness and saturation.\nFor exposure 4 digits are too much, 2 will be certainly enough (as in\nexposure module). This will make this simple module even more beginner\nfriendly.\nIf you agree and don't have time I can handle this?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2168#issuecomment-470842900,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pU_MeiQz8Fn62g_mcQ637SYApWlVks5vUhspgaJpZM4bkVXS\n.\n. @TurboGit , this has the wip label but I'm not sure what's expected to change here.. Thanks, I did not mean to rush you, just an FYI.\n\nI'll upgrade this.\nEl vie., 15 mar. 2019 a las 6:32, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh : also Aur\u00e9lien's comment about\npixel vectorization does not seem to have been taken into account. Any\nissue with that?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2168#issuecomment-473217802,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQp5PFuGVsKLyi2aeLlnL23fFYF0ks5vW2i5gaJpZM4bkVXS\n.\n. @TurboGit , all fixed.. Review changes ready.. Thanks.\n\nThe middle grey works with the contrast slider, it defines the lightness\nthat is not modified by the contrast. The default is the middle grey for\nthe work rgb colorspace. If the work profile changes, the default will\nchange too, but you'll need to reset it by hand.\nEl dom., 17 mar. 2019 a las 13:33, Paolo Astengo (notifications@github.com)\nescribi\u00f3:\n\nGreat job! I don't see any effect of \"middle grey\" slider...\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2168#issuecomment-473682135,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pTPV615E2Y8jpbmkLL1NaQdY_wQuks5vXm5kgaJpZM4bkVXS\n.\n. I can't speak about #2017, but I've been working for a while on this, I\nlike it, so I decided to share it.\n\nHaving a new module or merge it into the current one is part of a larger\ndiscussion. One of my goals while doing what I'm doing is to have an RGB\nworkflow, for this some Lab modules need to be ported to RGB and we have\nthe same question for all of them, add the RGB option or create a new one.\nI think is better to create a new one, it make the code simpler an easier\nto maintain, and a native RGB module use RGB for the blend, while a Lab use\nLab.\nEl vie., 8 mar. 2019 a las 4:58, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWe really want to have a clear idea of what to do with this and #2017\nhttps://github.com/darktable-org/darktable/pull/2017. Those seems\nduplicate, right?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-470839723,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZLdeCb0fEg-JubafeJhAtoZEfOHks5vUhgogaJpZM4bkcym\n.\n. No, there's not.\n\nEl vie., 8 mar. 2019 a las 15:50, Aur\u00e9lien PIERRE (notifications@github.com)\nescribi\u00f3:\n\nAs much as I like a RGB workflow, I think this duplicates the efforts of\n@phweyland https://github.com/phweyland on #2017\nhttps://github.com/darktable-org/darktable/pull/2017. But the RGB\nblending is strong argument, actually blending in non-linear spaces is\ndoomed from the basic theory of it. Is there now way to get an RGB blending\nfor those Lab modules ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-471035229,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXVocVjYRA2uEGZbgqioifZdhudXks5vUrEJgaJpZM4bkcym\n.\n. Can you share the xmp?\n\nEl s\u00e1b., 9 mar. 2019 a las 9:42, Martin Straeten (notifications@github.com)\nescribi\u00f3:\n\nOSX:\nthere seems to be a segfault on rgb curve being activated with a former\nprocessed raw.\nscenario: history stack contains: rotate, crop&rotate, perspective\ncorrection, demosaic (amaze)\nactivating rgb --> segfault:\nconsole.txt\nhttps://github.com/darktable-org/darktable/files/2948356/console.txt\ntrace: trace2.txt\nhttps://github.com/darktable-org/darktable/files/2948357/trace2.txt\ndoing the same starting from scratch, first applying perspective\ncorrection, crop&rotate, demosaic, and then activing rgb works fine\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-471173824,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUFHHXcs938iPzufDAUb3BbeUEtoks5vU6w1gaJpZM4bkcym\n.\n. @MStraeten , should be fixed now, thanks for reportig it. \n\nThe module must be between input color profile and output color profile, you'll have to move it by hand, until you do so you'll get a random image and an error on the console.. I already say where I stand, but to make my case consider the levels. We all agree that it should work on RGB, if we add it to the current module we'll have a Lab mode that we'll strongly suggest not to use, a blend mode in Lab and the code will be more difficult to maintain.\nWith the tone curve we'll have a RGB mode hard-coded in prophotoRGB, a \"work profile RGB\" mode, in addition of all existent modes, and the blend will also work in Lab (not to mention the code)\nRegarding the LCh I have no strong opinion, but LCh is close to Lab, so at least it should be considered to add it to the tone curve (is already there anyway). > New modules are migrating toward an RGB working mode. Fine. But I'm not\n\ncertain to understand the relationship with the UI. We can have a curve in\nLab and RGB, both actually tweaking the module in RGB mode with proper\ncolor conversion, right? Or are the color conversion the problem? Not\nconservative enough? For example the colorbalance can have RGB or HSL\nsliders and both are actually tweaking the same circuitry in the module\nwith proper conversions.\nNot sure if I get this, I don't have a problem with the UI, and this\nimplementation display the curve in RGB or Lab (with the 'compensate middle\ngrey' checkbox). My problem is with the functionality (offering more\noptions than needed) and the code (that gets more complex and difficult to\nmaintain)\n. It scale the curve and histogram so the middle grey is at 50%. In order to\ndo that it transform things to Lab, and for that, since the input can be\nany RGB colorspace it uses the work profile.\n\nIf you switch it with an S curve and the work profile on something linear\nyou'll see how the curve changes, but the image remains the same.\nEl jue., 14 mar. 2019 a las 15:03, Philippe (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh\nto learn how to use the new pixelpipe I've installed your rgbcurve branch.\nThere is the option called compensate middle grey.\nHave you already explained somewhere what are the principles of this\noption ? How does that work (it seems that it involves colorprofile, trc,\nlab) ? If not could you present it a little bit ?\nThanks\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-472992328,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRpdaSvkculGvNsfJxFD2gjuQVt6ks5vWo7ggaJpZM4bkcym\n.\n. @TurboGit , I'll resume working on this now, let me know if there's anything you need (other than time) to make a desition about it.. Great! I'm still working on it, I'll let you know when is ready for review.\n\nEl dom., 17 mar. 2019 a las 6:36, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nHere is my new thinking. Nothing committed and to be discussed with all\nknowledgeable people on image algorithm.\nI'm leaning toward having this module in and separated from the current\ntone curve. Have new module working in rgb mode seems to be the way to go.\nThen we will be able to have \"module list\" preset for a full rgb oriented\npixel-pipe using those new modules and exclusively those that are better at\navoiding hue deviations if I understand correctly.\nI think you'll agree and this is also Aur\u00e9lien point of view. Right?\nAgain this discussion is still opened of course, but that's my current\ndecision on this.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473649028,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfsBvK-4kItG0BbNINOVs2tbu8jPks5vXgyVgaJpZM4bkcym\n.\n. Ready for test & review.. Yes, same as with the basic adjustments. I'll work on that after this is\npromoted.\n\nEl lun., 18 mar. 2019 a las 7:01, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nJust tested it and got:\n[rgbcurve process] rgb curve must be between input color profile and\noutput color profile\nAnd all the colors are psychedelic :)\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473844359,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdf_bNtmX91QtJ8Q6Z5LUuK-ZJP0ks5vX2PsgaJpZM4bkcym\n.\n. Sorry, I should explain better.\n\nBy promoted I mean merged.\nBoth this modules work with the work profile, and before the colorin\nthere's no work profile available, so some features will not work. The idea\nbehind this is to have them after the colorin, but because of backward\ncompatibility that's not something we can enforce, so I'll have to do\nsomething about it.\nI want to have both modules available before working on this because they\nhave different scenarios, this way I can work on something that include all\nof them.\nUntil then, if the module is before colorin, is not even processed and the\nerror message that you saw is displayed, so it should be moved by hand\nafter the colorin.\nOn new edits it should be after the colorin by default, so I assume that\nyou have tested it on an old edit.\nEl lun., 18 mar. 2019 a las 11:34, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'll work on that after this is promoted.\nWhat do you mean by promoted here?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473935420,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pX1hCvoWpJrwRQ1NW75ABPPH0xApks5vX6QEgaJpZM4bkcym\n.\n. If you move the module after the colorin or start a new edit it should work\nfine. If not it means that there's a bug, so let me know and I'll fix it.\n\nEl lun., 18 mar. 2019 a las 12:27, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nBy promoted I mean merged.\nBut I cannot merge something that I cannot test :) This is a chicken and\neggs problem! Or can you give me a quick patch to make it working? Or a PR?\nWhat do you suggest?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473959587,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcEIMRj5Rc-3mlVcNs4WzIqe6sTMks5vX7BugaJpZM4bkcym\n.\n. I have moved it after the levels, so even if the user enables it on an old edit things should work fine.. This is up for discussion, I add one in the middle and one in the average\n(the color picker show the average), so the user can choose one (and delete\nthe other).\n\nEl lun., 18 mar. 2019 a las 13:04, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, thanks I missed in your previous message that it should be ok on new\nedits!\nJust a minor issue. When I used the color picker to define an area I get\nthe area on the curve. Good. I have points on the curve on each side of the\narea. Fine. But I have two points (very close to each others) defined in\nthe middle. I would have expected a single one to be able to smoothly move\nthe curve inside the area up or down. As it is it is not possible to edit\nthe curve, when you move one of the inner point you create a cusp.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473978168,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdHSJsY5eI9K1e7SwuteoOVZEsLlks5vX7kTgaJpZM4bkcym\n.\n. The option is not available, but if you find it useful I can add it. We\nshould define how it should work, in the color zones we have two more nodes\nthat act like feather, here we haven't, but I can add them.\n\nEl lun., 18 mar. 2019 a las 13:05, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nAlso it seems the it is not possible to create a positive or negative\ncurve. It is always flat for me.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473978920,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSToWVFyXa2ctElTwHUfn4ZnLyBlks5vX7lmgaJpZM4bkcym\n.\n. How this should work? I usually define two types of curves, one for\ncontrast and another to brighten / darken the image. The contrast curve may\nrequire more nodes (we can have the feather or not, not sure), the brighten\n/ darken should only move the middle / average node.\n\nEl lun., 18 mar. 2019 a las 13:11, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI see for the middle vs average point. I suppose that with a good\ndocumentation (and in the hint message) it is fine.\nFor the positive/negative curve, yes please add support for that to match\nthe others implementation of this kind of color picker. I find this useful.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473982151,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdaqfvAP1QI2kxD7of-18cU3d4dqks5vX7rMgaJpZM4bkcym\n.\n. OK\n\nEl lun., 18 mar. 2019 a las 13:21, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'll go for the simple brighten curve for now.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-473986968,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pSA2RWOf70vsTHTAjrd1dBx0En5_ks5vX70CgaJpZM4bkcym\n.\n. Ready the new curves.. I have this in the code:\n\nint default_group()\n{\n  return IOP_GROUP_TONE;\n}\nEl lun., 18 mar. 2019 a las 14:58, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nForgot about a point I wanted to raise. This module is in the CORRECT\ngroup by default. Maybe better in the tonality one?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2169#issuecomment-474032643,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdEMUFCJwvB3DJfO8DVDopL92wSLks5vX9PBgaJpZM4bkcym\n.\n. I can't duplicate on my system, but I'm using the master from this morning. If you haven't already try a fresh build and then start dt with a new database and we'll see from there.. With fresh build I mean, before compiling, delete the build directory and the install directory. I you haven't done it please do.. Never mind, I can duplicate it.. I have entered PR #2182, please test it.. No, the reset has two parameters, that's OK.. Clicked is the right event for the reset.. There are some improvements that can be made, I'll be working on that.\n\nEl dom., 10 mar. 2019 a las 11:52, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nProbably because it now properly report information given the export\nprofile whereas before it was given some \"information\" not fully correct.\nNot sure if the speed can be improved.\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2183#issuecomment-471313103,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUakilE1yhL3ReDMZ0H36O5v5BOXks5vVRw_gaJpZM4bnRkp\n.\n. I will need help with OpenCL here, according to the documentation is OK to pass NULL arguments, but inside opencl there is not a NULL or null, so I'm comparing to zero:\n\nhttps://github.com/darktable-org/darktable/pull/2187/files#diff-826ecc2c60510d2905cd5ed0e104d4d4R232\nI haven't found any reference to good practices regarding this scenario.\n. > Not found good practice or on my side either. Maybe just add an int (used\n\nas a boolean since an OpenCL true is -1) to indicate that the profile_info\nis set or not? Not sure it is better, a NULL pointer is 0 anyway.\nA flag is not pretty but is safer. Let's wait for a while, maybe someone\nknows something. If not I'll change it, better not pretty than risk having\na buid error on some systems, or worst, some random issues.\n. I just added the flag, if we find a better way to do this we can change it.. Can you share the xmp?\n\nEl mar., 12 mar. 2019 a las 14:55, Pascal LACROIX (notifications@github.com)\nescribi\u00f3:\n\nAn unusual comment now appears when export to jpg :\n_[dt_ioppr_check_iop_order] gamma is not the last iop, last is\ndenoiseprofile 1(10,500000) image 0 (dt_dev_modules_update_multishow)\n[dt_ioppr_check_iop_order] module denoiseprofile 1(10,500000) should be\nafter gamma (71,000000) image 0 (dt_dev_modules_update_multishow)\n[export_job] exported to\n`/home/pascalou/Images/2019-03-03/darktable_exported/IGP9814.jpg'\nPerhaps this bug is in relation ?\ndt : 2.7.0+656~gef50c0556\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2190#issuecomment-472112512,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQ2bMBs-Wi9ynucJ0KPtb1OOTB0Vks5vV-n4gaJpZM4bpRzC\n.\n. Works fine for me. to confirm you can run darktable with -d perf and check\non the console that the modules are on the right order.\n\nEl mar., 12 mar. 2019 a las 16:03, Pascal LACROIX (notifications@github.com)\nescribi\u00f3:\n\nYes !\n_IGP9814.PEF.xmp.tar.gz\nhttps://github.com/darktable-org/darktable/files/2958359/_IGP9814.PEF.xmp.tar.gz\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2190#issuecomment-472139166,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pexETMSFkrolXyFuexm9fPXvq3LZks5vV_oVgaJpZM4bpRzC\n.\n. I'm not sure here, maybe someone else can confirm, but I don't see the\ngamma here:\n\n95,409639 [dev_pixelpipe] took 0,012 secs (0,012 CPU) processed filigrane'\non CPU, blended on CPU [export]\n95,422555 [dev_pixelpipe] took 0,013 secs (0,013 CPU) processedfiligrane\n1' on CPU, blended on CPU [export]\n95,422594 [dev_process_export] pixel pipeline processing took 5,664 secs\n(47,931 CPU)\nI don't remember if gamma is executed on export.\nEl mar., 12 mar. 2019 a las 18:00, Pascal LACROIX (notifications@github.com)\nescribi\u00f3:\n\nLook working fine and quick: no unusual comment now\nDt-d perf.txt.tar.gz\nhttps://github.com/darktable-org/darktable/files/2958765/Dt-d.perf.txt.tar.gz\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2190#issuecomment-472178900,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcLXdu01tplq07_E8T5ZfGXyLS2pks5vWBVqgaJpZM4bpRzC\n.\n. This is just a guess, but maybe you edited this image and when saved things\ngo back to normal. If happens again (on export), before editing copy the\nxmp from disk, this message should not happen and with an example I'll try\nto fix it.\n\nEl mar., 12 mar. 2019 a las 18:00, Pascal LACROIX (notifications@github.com)\nescribi\u00f3:\n\nLook working fine and quick: no unusual comment now\nDt-d perf.txt.tar.gz\nhttps://github.com/darktable-org/darktable/files/2958765/Dt-d.perf.txt.tar.gz\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2190#issuecomment-472178900,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pcLXdu01tplq07_E8T5ZfGXyLS2pks5vWBVqgaJpZM4bpRzC\n.\n. This is ready now for test/review.. @TurboGit , it is already controled by preference, see my first post, you can show it alone, with the groups or hide it.. > Working fine but it takes some space and I'm not sure I will have a use\nfor it.\nThis probably depends on your workflow and editing style, I move the\nmodules a lot, the best for this is to be on the active pipe group, and\nchanging groups to add new modules is annoying. This makes it easier.\nSo I'd prefer having this widget controlled by a preference. You already\nhave one to select the search context, I would add \"none\" to disable this\nwidget if not needed.\n. clang-format is doing this, as defined in contributing.md / coding style\n\nEl dom., 17 mar. 2019 a las 15:02, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@TurboGit commented on this pull request.\nIn src/libs/modulegroups.c\nhttps://github.com/darktable-org/darktable/pull/2195#discussion_r266251309\n:\n\n} dt_lib_modulegroups_t;\n\n+typedef enum dt_lib_modulegroup_iop_visibility_type_t {\nYou mean that clang compiler is changing that? Don't know I'm using emacs\nand gcc? But I do compile with clang to check PR and don't have this issue.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2195#discussion_r266251309,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdBCIPYnHaYRZ9WxcPpI-2HLW2Bfks5vXoM_gaJpZM4bq7IH\n.\n. No idea how this module works, someone familiar with it should test it.\n. @rawfiner , you were right, deleting nodes while moving them is extremely annoying, so I have removed the feature and now nodes can only be deleted by right click while not in edit area mode.. @rawfiner , you were right, deleting nodes while moving them is extremely annoying, so I have removed the feature and now nodes can only be deleted by right click while not in edit area mode.. For the zoom consistency, I have noticed that, but the circle already works\nthis way in the color zones, so I kept the same. We 'zoom' works different\non the image, the masks, the sliders, etc. and I agree, we should something\nabout that.\n\nEl jue., 14 mar. 2019 a las 5:27, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nForget the zoom in the \"little bar\", we need to keep the reference point\n(mouse pos) for the zoom. Yet, we may still have:\n\ndouble click on little bar to reset zoom\nfix zoom up/down for consistency\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-472750525,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pX7cSBXCTBDM9UZdlBQ82DE2EV96ks5vWgf1gaJpZM4byrEo\n.\n. Ready the reset zoom.. Just checked, seems that the masks are the problem, so I'll revert it here and we can decide what to do with the masks on a different PR.. Seems that dt_gui_get_scroll_deltas() is returning the wrong value:\n\nhttps://github.com/darktable-org/darktable/blob/master/src/gui/gtk.c#L299\nso modules multiply it by -1:\nhttps://github.com/darktable-org/darktable/blob/master/src/iop/basecurve.c#L1826\nI'm tempted to leave things as they are here and fix that, what do you think?. Done.. Can't duplicate, any particular setting?\nEl jue., 14 mar. 2019 a las 11:56, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWhen you zoom-in you have a strange band on the right witch does not have\nproper display.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-472901940,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peVHkZAIo0WlZshRUgDzEdiT9j8Bks5vWmMggaJpZM4byrEo\n.\n. I'm comparing it against master and it looks the same to me. Can you take a\nsnapshot of both right and wrong? Or maybe is a setting I'm missing?\n\nEl jue., 14 mar. 2019 a las 14:06, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI confirm that the issue seems to be with the histogram. Without this\npatch the background histogram looks correct. But with this PR it is\ndifferent and seems really wrong.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-472966671,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdPBlUlCHm4i54rNEbjzJ1OjnlbDks5vWoGWgaJpZM4byrEo\n.\n. OK, this is frustrating, I'm still get the correct result. With and without\nopencl.\n\nMaybe something with the work profile? Or some other active module?\nEl jue., 14 mar. 2019 a las 15:10, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nOk, it seems to happen on some images and not others. Take the following\npicture:\nhttps://drive.google.com/file/d/1Mm0zP_AD8Gi_Patd9op5KE0bWRADibLo/view?usp=sharing\nOpen in darkroom. Activate the colorzone and you'll see no histogram but\nthe whole curve area is greyed as part of the histogram seems to be cover\nall the area.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-472995170,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWMCvlLOjRSRjpO0toKJdVGtoWi6ks5vWpCVgaJpZM4byrEo\n.\n. Yes, you have to move the mouse over the graph to refresh it when enable\nthe module, no way around that. But when I do I get the histogram.\n\nIt seems that you have a light grey square around the module that I don't\nhave, maybe some CSS issue?\nEl jue., 14 mar. 2019 a las 15:30, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nAnd my history is clean. No base curve, but I have tested with a base\ncurve and still have the same issue.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-473002727,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pV7sukHLxk8Fs-t_EvRtf9AC2COkks5vWpVBgaJpZM4byrEo\n.\n. This what I get by just going to darkroom and enable the module:\n\n\n. This doesn't seem right, or at least is not what I get with the current\nmaster version. Others histograms work fine? Tone curve, levels, etc..\nEl jue., 14 mar. 2019 a las 15:58, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nWith my image?\nThis is the histogram on my side (without this PR, with previous version):\n[image: Capture d\u2019\u00e9cran de 2019-03-14 19-56-29]\nhttps://user-images.githubusercontent.com/467069/54383959-7a72ee00-4693-11e9-845b-e62163a45722.png\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-473013509,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pWIQphEQFFXxWL6bYQotQOD1muXZks5vWpvCgaJpZM4byrEo\n.\n. That seems correct, the histogram is based on the 'select by' channel, and\nmy french is not very good but it seems that is by hue.\n\nEl jue., 14 mar. 2019 a las 16:31, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nYes on the tonecurve and level the histogram is fine. When in waveform the\nlog view is used but otherwise when in linear or log the histogram in the\ntonecurve and level are correct and matching the main histogram.\nBut it looks like even in linear view the histogram in colorzone does not\nmatch the main histogram:\nI have this with colorzone:\n[image: Capture d\u2019\u00e9cran de 2019-03-14 20-30-24]\nhttps://user-images.githubusercontent.com/467069/54385932-17378a80-4698-11e9-88be-f2e955426a81.png\nAnd this with tonecurve:\n[image: Capture d\u2019\u00e9cran de 2019-03-14 20-28-13]\nhttps://user-images.githubusercontent.com/467069/54385937-1d2d6b80-4698-11e9-8347-f28f85246cac.png\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-473025408,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pQNk2HNN5WKOizFFegYjXorPWDc-ks5vWqOMgaJpZM4byrEo\n.\n. The histogram works only in LCh, there's no option right now to transform\nit according the work profile.\n\nEl jue., 14 mar. 2019 a las 17:51, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nYes it is hue. So the only issue is when main histogram is not linear.\nThis does not work on colorzones for some reasons.\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-473056892,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pctZBaOaLXW-Vux2VOpP6jjdQBQ3ks5vWrZSgaJpZM4byrEo\n.\n. @TurboGit , look goo to me, thanks.. I'll look into this on a new PR so 2214 can be merged.\n\nEl vie., 15 mar. 2019 a las 8:06, rawfiner (notifications@github.com)\nescribi\u00f3:\n\nOh, I was pressing the key once instead of pushing it continuously!\nIt works great :-)\nHowever, when zoomed in, modifying the curve with \"edit by area\" does not\nwork as expected on my side. To reproduce:\n\nadd 3 nodes close to each other\nzoom in to this zone\ntry to move up the central node using the \"edit by area\" option\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2205#issuecomment-473245833,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pXVzp1d1Yg9l4Eb8NRUe8d4w5i43ks5vW36sgaJpZM4byrEo\n.\n. When updating the iop's I have noticed that the liquify and perspective\ncorrection work different than the other distord modules (and it was more\ndifficult to port!), probably because the position on the pipe.\n\nNow that modules can be re-ordered we should check if distord modules need\na particular order, but it will be nice if they can be moved anywhere. I'll\ntake a look at this, maybe there's something generic that can be made.\nEl jue., 14 mar. 2019 a las 11:03, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\n@edgardoh https://github.com/edgardoh : given your recent work on the\npixel-pipe and mask you may have an idea?\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2210#issuecomment-472869504,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pTBELNcGdUnoJihp3eioKjcMA7Fqks5vWlajgaJpZM4b0N3q\n.\n. I've been playing with the distord modules and everything seems fine, there's some issues but they seem module related.\n\nFor this specific one I don't know the code so I can't really follow it, but it seems that the liquify don't like when a distord module is before in the pipe.\nThe crop & rotate with an angle or the lens correction show the same problem as the perspective correction, but between them things are OK, so I'm taking a wild guess and assume is the liquify.\nIt seems that the liquify is not applying the same distortion on the process() than in _distort_xtransform(), so modules that follow and use a mask get the mask with the incorrect distortion. \nMaybe _distort_xtransform() is not applying the distortion from the previous modules?\nAs a side note, the process() and process_cl() should use MIN(roi_in->width, roi_out->width), MIN(roi_in->height, roi_out->height), as the input image can be larger or smaller than the output (I had a few crashes)\nI hope this helps.. Confirmed.. @junkyardsparkle , it seems that we don't understand each other.\nThere are two ways to add a node:\n-click and drag: the node is added at mouse position and then it follows the mouse\n-cntrl+click: the node is added at x=mouse position, y=curve position\nhave you found a 3rd way?. If you're getting this by click+drag it won't be easy to fix, it is working fine for me. \nI have an open PR #2217 with some fixes for the color zone, if you can build it then try that, if still not working let me know and we can work together to try to debug it.. > @TurboGit requested changes on this pull request.\n\nJust a minor comment. An int used as a boolean.\nA question, I found that a slight move of the luminence curve in strong\nmode gives very quickly artifacts. Do you reproduce that? As soon as I\nchange for the smooth mode all is correct. It seems that the strong mode\ncreates some cusp.\nCan be, according to the comments on the code there's a mask used to avoid\nartifacts, but is used only on hue, the lightness and chroma should work\nthe same. But the side effect of that mask is that it can produce a shift\non the destination hue, so sometimes you may not get the desired effect.\nHaving this two modes give the user the choice, if there's artifacts on the\nimage one can always change to the smooth method.\nActually I haven's seen any artifacts, but that may depend on the\ndefinition of artifact, on very noisy images it brings the noise quite a\nlot, that can be considered as artifacts?\n\n\n\nIn src/iop/colorzones.c\nhttps://github.com/darktable-org/darktable/pull/2217#discussion_r266197454\n:\n\n@@ -1239,15 +1224,19 @@ static gboolean _bottom_area_button_press_callback(GtkWidget *widget, GdkEventBu\n\nstatic int _sanity_check(const float x, const int selected, const int nodes, const dt_iop_colorzones_node_t *curve)\n {\n-  int point_valid = 1;\n+  int point_valid = TRUE;\nshould be a gboolean\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2217#pullrequestreview-215310352,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pS8VNvudw-V4UjwN1MpcXGb8Wq1jks5vXM15gaJpZM4b3E_S\n.\n. Ready.. If you're gonna be playing with it and you find the time check how nodes\nare added when edit by area is selected. I don't use that mode so for me is\nOK like it is, but you never know.\n\nEl s\u00e1b., 16 mar. 2019 a las 14:30, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nI'll open an issue with an image with artifacts just to be sure there is\nnothing broken.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2217#issuecomment-473567847,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pdQbaL-1CiaBOrktqa8sfdFe83cfks5vXSoegaJpZM4b3E_S\n.\n. @TurboGit , as I said before I don't really know this module, so a full test should be done on this.. > @TurboGit requested changes on this pull request.\nI'm impressed! Congrats this works just fine. I have some minor comments.\nOne question, would this have been possible before your work on the pixel\npipe? I lost track of the implementation back when I worked on this iop.\nThanks. And yes, I haven't changed the way the pipe or the distord works,\nso this should work even without the module order changes. And the pipe and\nthe distord works very well, seems that all the distord modules can have\nany order, that's really nice.\n\nA couple of remarks/questions:\n-I think is better to leave the original code commented in this 2\nfunctions, makes sense to me as they must be an exact copy of the original\n(minus the lock)\n-You also requested to use gboolean on my other PR. I always use int for\nbool expressions, is standard C and is used this way all over dt. Is there\nany advantage of using gboolean?\n\n\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197226\n:\n\n@@ -512,6 +575,7 @@ typedef struct\n   float from_scale;\n   float to_scale;\n   int transf_direction;\n+  int from_distort_transform;\n\nshouldn't this be a gboolean?\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197228\n:\n\n@@ -443,6 +443,69 @@ static void path_delete (dt_iop_liquify_params_t p, dt_liquify_path_data_t thi\n   node_gc (p);\n }\n\n+int _dev_distort_transform_plus(dt_develop_t dev, dt_dev_pixelpipe_t pipe, const double iop_order, const int transf_direction,\n+                                  float *points, size_t points_count)\n+{\n+  // this is called from the dt_dev_distort_transform_plus(), so the history is already locked\n+//  dt_pthread_mutex_lock(&dev->history_mutex);\ncan be removed\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197231\n:\n\n@@ -443,6 +443,69 @@ static void path_delete (dt_iop_liquify_params_t p, dt_liquify_path_data_t thi\n   node_gc (p);\n }\n\n+int _dev_distort_transform_plus(dt_develop_t dev, dt_dev_pixelpipe_t pipe, const double iop_order, const int transf_direction,\n+                                  float points, size_t points_count)\n+{\n+  // this is called from the dt_dev_distort_transform_plus(), so the history is already locked\n+//  dt_pthread_mutex_lock(&dev->history_mutex);\n+  GList modules = g_list_first(pipe->iop);\n+  GList *pieces = g_list_first(pipe->nodes);\n+  while(modules)\n+  {\n+    if(!pieces)\n+    {\n+//      dt_pthread_mutex_unlock(&dev->history_mutex);\nlikewise\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197232\n:\n\n\n}\ndt_iop_module_t module = (dt_iop_module_t )(modules->data);\ndt_dev_pixelpipe_iop_t piece = (dt_dev_pixelpipe_iop_t )(pieces->data);\nif(piece->enabled && ((transf_direction == DT_DEV_TRANSFORM_DIR_ALL)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_FORW_INCL && module->iop_order >= iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_FORW_EXCL && module->iop_order > iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_BACK_INCL && module->iop_order <= iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_BACK_EXCL && module->iop_order < iop_order)) &&\n!(dev->gui_module && dev->gui_module->operation_tags_filter() & module->operation_tags()))\n{\nmodule->distort_transform(module, piece, points, points_count);\n}\nmodules = g_list_next(modules);\npieces = g_list_next(pieces);\n}\n+//  dt_pthread_mutex_unlock(&dev->history_mutex);\n\n\nlikewise\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197235\n:\n\n\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_BACK_EXCL && module->iop_order < iop_order)) &&\n!(dev->gui_module && dev->gui_module->operation_tags_filter() & module->operation_tags()))\n{\nmodule->distort_transform(module, piece, points, points_count);\n}\nmodules = g_list_next(modules);\npieces = g_list_next(pieces);\n}\n+//  dt_pthread_mutex_unlock(&dev->history_mutex);\nreturn 1;\n+}\n+int _dev_distort_backtransform_plus(dt_develop_t dev, dt_dev_pixelpipe_t pipe, const double iop_order, const int transf_direction,\nfloat *points, size_t points_count)\n+{\n// this is called from the dt_dev_distort_backtransform_plus(), so the history is already locked\n+//  dt_pthread_mutex_lock(&dev->history_mutex);\n\n\ncan be removed\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197237\n:\n\n\n}\n+//  dt_pthread_mutex_unlock(&dev->history_mutex);\nreturn 1;\n+}\n+int _dev_distort_backtransform_plus(dt_develop_t dev, dt_dev_pixelpipe_t pipe, const double iop_order, const int transf_direction,\nfloat *points, size_t points_count)\n+{\n// this is called from the dt_dev_distort_backtransform_plus(), so the history is already locked\n+//  dt_pthread_mutex_lock(&dev->history_mutex);\nGList *modules = g_list_last(pipe->iop);\nGList *pieces = g_list_last(pipe->nodes);\nwhile(modules)\n{\nif(!pieces)\n{\n+//      dt_pthread_mutex_unlock(&dev->history_mutex);\n\n\nlikewise\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197241\n:\n\n\n}\ndt_iop_module_t module = (dt_iop_module_t )(modules->data);\ndt_dev_pixelpipe_iop_t piece = (dt_dev_pixelpipe_iop_t )(pieces->data);\nif(piece->enabled && ((transf_direction == DT_DEV_TRANSFORM_DIR_ALL)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_FORW_INCL && module->iop_order >= iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_FORW_EXCL && module->iop_order > iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_BACK_INCL && module->iop_order <= iop_order)\n|| (transf_direction == DT_DEV_TRANSFORM_DIR_BACK_EXCL && module->iop_order < iop_order)) &&\n!(dev->gui_module && dev->gui_module->operation_tags_filter() & module->operation_tags()))\n{\nmodule->distort_backtransform(module, piece, points, points_count);\n}\nmodules = g_list_previous(modules);\npieces = g_list_previous(pieces);\n}\n+//  dt_pthread_mutex_unlock(&dev->history_mutex);\n\n\nlikewise\nIn src/iop/liquify.c\nhttps://github.com/darktable-org/darktable/pull/2220#discussion_r266197258\n:\n\n@@ -619,9 +696,10 @@ static void _distort_paths (const struct dt_iop_module_t module,\n static void distort_paths_raw_to_piece (const struct dt_iop_module_t module,\n                                         dt_dev_pixelpipe_t pipe,\n                                         const float roi_in_scale,\n-                                        dt_iop_liquify_params_t p)\n+                                        dt_iop_liquify_params_t *p,\n+                                        const int from_distort_transform)\n\nconst gboolean ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2220#pullrequestreview-215310085,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pZPgUGOqptewQ6Bn0ME-lqCHQaAmks5vXMsSgaJpZM4b3qLz\n.\n. I really don't agree but I will assume that this has already been discussed\nand I missed, so too bad for me. I'll fix both PR.\n\nEl s\u00e1b., 16 mar. 2019 a las 13:54, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nYes there is advantage at least in readability. When you see a gboolean\nyou know that it is a 2 states variables. And this is also important for\nconsistency as all dt code do use gboolean when possible. I'm sure there is\ncase where this is not done, but they should be fixed when possible.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2220#issuecomment-473564678,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peEjqoasfErbG2ULUNRMO9ob3a7Gks5vXSHbgaJpZM4b3qLz\n.\n. Ready. Does this happens only on darkroom or on export too?\n\nIf you import the original xpm, can you still reproduce the issue?\nEl dom., 17 mar. 2019 a las 9:16, Martin Straeten (notifications@github.com)\nescribi\u00f3:\n\nDescribe the bug\nafter database conversion 2.6.1 --> 2.7.0 the module retouch is misordered:\n[dt_ioppr_transform_image_colorspace] module retouch must be between input\ncolor profile and output color profile\nTo Reproduce\nSteps to reproduce the behavior:\n\nclean .config/darktable\nopen file in darkroom and apply retouch in dt.2.6.1\nclick display wavelet scale --> fine\nclose dt2.6.1. open dt 2.7.0, confirm db conversion\nopen file in darkroom expand module retouch, click display wavelet\n   scale\nmessed up display\n\nPlatform (please complete the following information):\n\nOS: OSX\nVersion:\n   `this is darktable 2.7.0+753~gb320074dc\n   copyright (c) 2009-2019 johannes hanika\n   darktable-dev@lists.darktable.org\n\ncompile options:\nbit depth is 64 bit\nnormal build\nSSE2 optimized codepath enabled\nOpenMP support enabled\nOpenCL support enabled\nLua support enabled, API version 5.0.1\nColord support disabled\ngPhoto2 support enabled\nGraphicsMagick support enabled\nOpenEXR support enabled\n`\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2238, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APq1pUdUbglyLWL2WNwfyr7N0gQiUG2uks5vXjI0gaJpZM4b4WKg\n.\n. Can you share the xmp?\n\nEl dom., 17 mar. 2019 a las 9:45, Martin Straeten (notifications@github.com)\nescribi\u00f3:\n\nonly if clicking display wavelet scale --> the image turns red\nexport --> the retouch is applied as expected\nsame misbehaviour with discard history stack and reload xmp as written by\n2.6.1\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2238#issuecomment-473662143,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pV-QD-9qP5jqQ89gGleTwlHyM7rcks5vXjjugaJpZM4b4WKg\n.\n. The problem was not the db conversion, so you don't need to convert it again.. Do you mean in the first post or in the commit?\n\nEl dom., 17 mar. 2019 a las 13:02, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nLooks good to me. One minor comment, please be sure to add a little\ndescription into the comment message to what was done. It may be useful\nwhen reading log message. Of course the ref to the issue is important, just\nthat a little description too may help especially for me reading log\nmessage to check against the release-notes and looking for potential commit\nto merge, etc. Thanks.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2239#issuecomment-473679549,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pRcoGgr1wa-l05B9P_wFW6vvJKE5ks5vXmcygaJpZM4b4cR6\n.\n. I'm trying to do it for the search box but I have no idea where I can edit\nthe commit message...\n\nEl dom., 17 mar. 2019 a las 13:16, Pascal Obry (notifications@github.com)\nescribi\u00f3:\n\nIn the commit log of each commit. The first line should be a short\ndescription, followed by an empty line then a longer description when\nneeded and then the issue ref if it exists. See for example: 38006e5\nhttps://github.com/darktable-org/darktable/commit/38006e5f743a163d7725c9c52eacc3c2ccf102a1\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2239#issuecomment-473680678,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pY6wjMskF71_q7EH9FANmxpA8D_dks5vXmpIgaJpZM4b4cR6\n.\n. This is a current limitation, see the error message on the command line.\n\nI'll eventually do something about it, but I'm working on other things right now.. Can you share the original xmp and this one?\nEl lun., 18 mar. 2019 a las 14:47, Andreas Schneider (\nnotifications@github.com) escribi\u00f3:\n\nDescribe the bug\nI've just worked on a photo from last year, then I noticed that one photo\nin my collection is too bright now. When checking what is causing this it I\nfound that the haze removel shifts the histogram to the right see here:\nI'm running git sha: 195f5a3\nhttps://github.com/darktable-org/darktable/commit/195f5a3b23cd43ca57d7ab25ac3247eb7aaed513\nHaze removal on:\nhttps://camo.githubusercontent.com/75c8a029ec4fde98be8c607c85615b5e4e58e10a/68747470733a2f2f786f722e63727970746f6d696c6b2e6f72672f706963732f782f6461726b7461626c655f68617a655f72656d6f76616c5f6f6e2e706e67\nHaze removal off:\nhttps://camo.githubusercontent.com/228d30662f6ed6245756e14f0f4f00048afc7dbe/68747470733a2f2f786f722e63727970746f6d696c6b2e6f72672f706963732f782f6461726b7461626c655f68617a655f72656d6f76616c5f6f66662e706e67\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2243, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APq1peAAgDg8im5FzOzydMWX1O15rsULks5vX9E0gaJpZM4b6Z4F\n.\n. For now yes.\n\nEl lun., 18 mar. 2019 a las 14:54, Andreas Schneider (\nnotifications@github.com) escribi\u00f3:\n\nOnly the XMP?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2243#issuecomment-474031044,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1peK4bTZKuIvGq0y0cmtXEjhDl_78ks5vX9LMgaJpZM4b6Z4F\n.\n. Is this the original one?\n\nEl lun., 18 mar. 2019 a las 14:56, Andreas Schneider (\nnotifications@github.com) escribi\u00f3:\n\nYou can find it here:\nhttps://xor.cryptomilk.org/pics/x/2018-07-25__7M33756.ARW.xmp\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2243#issuecomment-474031989,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pT5gb4vwdECjdiFgpyyHYIJhWINSks5vX9NbgaJpZM4b6Z4F\n.\n. I don't get it, I though this was an old edit that when migrated looks\ndifferent. Is not that the case?\n\nEl lun., 18 mar. 2019 a las 15:02, Andreas Schneider (\nnotifications@github.com) escribi\u00f3:\n\nI can roll back to the version I edited with an older darktable version,\nif you want that ...\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2243#issuecomment-474034330,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pTf6qRQp-ygZhOWtVfI8IfAhbkq4ks5vX9SvgaJpZM4b6Z4F\n.\n. With a random image I can't duplicate, but to be sure can you try it with a\n2.6 release? Doesn't seem to be related to the module order as the haze\nremoval is before the colorin.\n\nEl lun., 18 mar. 2019 a las 15:10, Andreas Schneider (\nnotifications@github.com) escribi\u00f3:\n\nDo you want the RAW file too to reproduce it?\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2243#issuecomment-474037467,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pfjR1Vburh40Ck5znRJPXfcO_lukks5vX9Z_gaJpZM4b6Z4F\n.\n. I can't find anything that explain this. \nThe haze removal and white balance seem to have commits that are not included in 2.6, you can try with a previous commit, at least to see where the problem is.. I'm working on this, until then do not use the rgb curve or the basic\nadjustments before the input color profile.\n\nEl lun., 18 mar. 2019 a las 18:20, Martin Straeten (\nnotifications@github.com) escribi\u00f3:\n\nDescribe the bug\napplying a mask in rgbcurve results in a segmentation fault if\n\nopencl ist activated and\na mask within a different module is already defined\nand input profile is set via applied style .\n   i found it not beeing reproducible if the colorin section of the\n   attached xmp file is deleted\n\nTo Reproduce\nSteps to reproduce the behavior:\n\nopen file\nadd 'exposure' and apply a gradient mask\nadd 'rgb curve' and apply a gradient mask\nadd style Canon M6 Neutral.dtstyle.txt\n   https://github.com/darktable-org/darktable/files/2980421/Canon.M6.Neutral.dtstyle.txt\n\nresulting xmp file: 20190223-IMG_5937.CR2.xmp.txt\nhttps://github.com/darktable-org/darktable/files/2980445/20190223-IMG_5937.CR2.xmp.txt\n58,034366 [dev_pixelpipe] took 0,275 secs (0,752 CPU) processed Entrastern'\non GPU with tiling, blended on CPU [thumbnail] [dev_pixelpipe] module Entrastern'\nmin: (0,000512; 0,000000; 0,000000) max: (0,620160; 0,617545; 0,618875)\n[thumbnail]\n58,034740 [opencl memory] device 0: 290400 bytes (0,3 MB) in use\n58,035256 [opencl memory] device 0: 580800 bytes (0,6 MB) in use\n58,036358 [opencl memory] device 0: 581056 bytes (0,6 MB) in use\n58,036382 [opencl memory] device 0: 653656 bytes (0,6 MB) in use\n58,036457 [masks Verlauf #1\nhttps://github.com/darktable-org/darktable/pull/1] gradient draw took\n0,0001 sec\n58,036472 [masks Verlauf #1\nhttps://github.com/darktable-org/darktable/pull/1] gradient transform\ntook 0,0000 sec\n58,036564 [masks Verlauf #1\nhttps://github.com/darktable-org/darktable/pull/1] gradient fill took\n0,0001 sec\n58,036612 [masks 0] combine took 0,0002 sec\n58,036618 [masks] render all masks took 0,0002 sec\n58,036631 [opencl memory] device 0: 726256 bytes (0,7 MB) in use\nMagick: abort due to signal 11 (SIGSEGV) \"Segmentation Fault\"...\nAbort trap: 6\nfull console output: opencl_mask_rgbcurve.txt\nhttps://github.com/darktable-org/darktable/files/2980451/opencl_mask_rgbcurve.txt\nPlatform (please complete the following information):\n\nOS: OSX\nVersion\n   this is darktable 2.7.0+769~gb311cd37c-dirty\n   copyright (c) 2009-2019 johannes hanika\n   darktable-dev@lists.darktable.org\n\ncompile options:\nbit depth is 64 bit\nnormal build\nSSE2 optimized codepath enabled\nOpenMP support enabled\nOpenCL support enabled\nLua support enabled, API version 5.0.1\nColord support disabled\ngPhoto2 support enabled\nGraphicsMagick support enabled\nOpenEXR support enabled\n\u2014\nYou are receiving this because you are subscribed to this thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2245, or mute the\nthread\nhttps://github.com/notifications/unsubscribe-auth/APq1pajiq8PQelivTA1mXGZ9lvhhEEjSks5vYAM4gaJpZM4b6zg0\n.\n. And that's why those modules are after colorin, this is for backward\ncompatibility, I'm not forcing anyone to move the modules before colorin.\n\nEl mar., 19 mar. 2019 a las 17:00, Aur\u00e9lien PIERRE (\nnotifications@github.com) escribi\u00f3:\n\nThe problem of doing that is every module using the XYZ Y channel\n(luminance), for example saturation adjustments or curve color\npreservation, will get a wrong Y value before the input profile, because\nit's only this module that maps input RGB to standard XYZ D50 (and then to\nLab).\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2248#issuecomment-474555082,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/APq1pf_q0mtoes3JXXhYSPStdyuK0PYKks5vYUHygaJpZM4b8OKp\n.\n. I agree, but then the spots iop should be modified to change the type of the masks and the version incremented.\nOn the other hand, I still don't know if this will be a new module or an upgrade for the spots, in this last case there will be no need to modify it.. because I'm lazy, but I don't want to write that down on the code...\nNow seriously, I wanted to make sure it works first and then I just forget, I'll do it on the next commit.. Done.. Not at all, but the menu entry is in the multi-instance menu, so on one-instance modules it won't be available anyway.. But if you like the feature I can move it to the right-click menu.\nWhat do you like best for the entry?\nrename\nrename module\nrename instance\n(any other)\n. I've done this so when the mask or a node/segment is dragging and the mouse get out of the darkroom it doesn't move to the left-top corner.\nIn creation, I like better the preview to stay at the edge instead of jump to the middle, but that's a matter of taste. To change it back I think that the only thing needed is to remove the gui->creation from the if(). Let me know if you want that.. I agree that consistency is important. And I do like this behaviour better. When I move the mouse outside the darkroom area my eyes are on the destination and I find distracting to see with the corner of my eyes the preview jumping to the center.. This is clang-format, on enums it works like this.. I tried several places in the pipe, this is what I find to be the best.. I use it mostly for the BW conversion, that's why I place it there, but its really the same to me. . Sure, but let's first work on the description of the 6 modes, I really don't have a clue what text to use so it makes some sense for the user, not everyone is familiar with the fourier or sine transform and the laplacian, and the user shouldn't even care about it.. Is the name of the function.\nNo idea if there's a standard for function naming, woudn't hurt to have one. As far as the printf, if this isn't a standard for errors that just can't happen it should be, it make it easy to see where it comes from when reported.. Idem.. I left this just for the review, I'll remove it later.\nWhere it says refreshed, the effect is the same.. My bad, I didn't explain it right. dev->alliop don't work exactly like dev->allforms. For the masks, dev->allforms has ALL forms, and they are free() on exit, dev->alliop has only the modules that has been removed from dev->iop, and it assumes that dt_iop_cleanup_module() hasn't been called.\nThis is done here:\nhttps://github.com/darktable-org/darktable/pull/1800/files#diff-2c39561107e06b0530706f865a77eabaR580\n\nThe idea is: the user delete a module, but the pipe may still need it, so, instead of physically delete it, it is removed from dev->iop (that's not an issue since the pipe works on a copy of dev->iop) and is added to dev->alliop, where it is free() on exit.. Also\nfloat kx2m1 = 2.0f * (float)k / 0x10000 - 1.0f;\nis not the same as\nfloat kx2m1 = 2.0f * ((float)k / 0x10000 - 1.0f);. You're right, my bad!. I'm clamping only when I assign it to the color widget, I want to display the actual pixel values, even when out of range.. Ups, you're right, its fixed now. Thanks!. Should this be k += ch.... Yes, all color things should be somewhere else, but I'm not sure exactly where, we can discuss it.. This is the linked mode, all rgb use one curve.. this is a\nhttps://github.com/darktable-org/darktable/blob/master/src/control/settings.h#L35\nseems that this is new, I'll change it.. The idea is to have only one line in the caller to hide the implementation. The more logic we have, more prone to errors.. See previous.... Idem.. default_colorspace is mandatory, the other are optional and the default_colorspace is the default (if they are not implemented). OK. This happens a lot, I'll fix it as I find them.. Yes, this is after the colorout, so the input is an rgb image.. I didn't thought about that, I'll move this to another PR.. We still have this clang issue, even if I change it, clang will change it back.. I don't know what to do about this, I use clang and is doing it like this. clang is the recommended way to go, so it should be modified to format it the way you like it. Otherwise I'll have to disable for this and enable for the rest.. ",
    "klauspost": "I like it. There are no expensive checks, and it makes the code cleaner a lot of places.\nA PR upstream is welcome!\n. ",
    "kael-shipman": "Done!\n. ",
    "asmaAL-Bahanta": "I have modified some files so that it will render text using Pango instead of Cairo which does not support complex texts .\n. It will add support for languages that requires complex text layout such as Arabic, Hebrew ...etc. \n. I modified the commit message and added more explanation.\n. I have addressed all the comments and made the changes. Still waiting for developers approval to change the remaining files which use cairo_show_text()\n. I have made the changes and modified the positions.\n. This pull request is  for the other files where  cairo toy text API is used.\n. I have addressed all the comments. I hope you can test my patch and see if there is an issue especially in text positions in the GUI. \n. ",
    "khaledhosny": "\nAbout the rest of the files, don't change it for things like the G in paint.c, there the easy cairo function is fine.\n\nI think even for single letters using Caito toy text API is bad, as for example it does not do font fallback. My default UI font happens to lack any Latin letters, but it works just fine everywhere because font fallback is used, but when I opened Darktable for the first time I was greeted with tofu boxes for what appeared to be some help messages. So I think it is better overall to just use Pango everywhere like GTK does and not have to worry about any of this.\n. ",
    "avsmal": "Sure. http://redmine.darktable.org/issues/10897\n. I'm not sure whether it is a good idea to duplicate definition of white2exposure and exposure2white from iop/exposure.c to libs/histogram.c, but I don't know what header file is suitable for these two macroses.\n. @houz @LebedevRI OK, I'll see what I can do.\n. @houz I changed hooks to keep all calculations in exposure.c. #10073 is also fixed. @LebedevRI\n. @LebedevRI that's true. I've changed to \"exposure\".\n. @LebedevRI is it possible to merge it into darktable-2.0.x?\n. ",
    "Iambecomeroot": "Any updates on this?. ",
    "jnegre": "extract_wb was used, but it had a hard time on my files.\nThe files I used have been deleted since my patch, I will upload new ones ASAP.\n. You'll find the raws + the ouput of extract_wb at http://jnegre.org/tmp-pullrequest-darktable/\n. Here it is.\nSorry for having several commits, running extract_wb wasn't straightforward on my system. If you feel like rejecting this pull request and want to make your own, clean commit, I won't be mad.\n. Will try.\n. That's perfectly fine with me, I was making a mess of my local repository :-(\nThanks for your work.\n. ",
    "sbahra": "Super cool!\n. Correct. Concurrency Kit does not have this limitation. Did this end up getting merged down @LebedevRI? . ",
    "tatica": "Thank you for noticing. I do believe it's a better translation (more accurate). Will adjust it ASAP.\n. ",
    "jeffersonfr": "Hello,\nI removed all conflicts and dependencies from c++ of the module filmulate.c. The version without conflicts is available in:\nhttps://www.dropbox.com/s/qpid3hux1o3zmlr/filmulate.c?dl=0\nBest regards.. Hi,\nI love this idea ! I changed your code a little to make that more portable and simple ...\n// paint.c\nvoid dtgtk_cairo_paint_battery(cairo_t *cr, gint x, gint y, gint w, gint h, gint flags)\n{\n  cairo_translate(cr, x, y);\n  cairo_scale(cr, w, h);\nFILE *fd;\n  int percentage = 0;\nfd = popen(\"upower -i $(upower -e | grep 'BAT') | grep '%' | head -1 | sed -e 's/^.*:\\s*//g' | sed -e 's/%//g'\", \"r\");\n  if(fd)\n  {\n    if (fscanf(fd, \"%d\", &percentage) <= 0) {\n      percentage = 0;\n    } \n    fclose(fd);\n  } \ncairo_set_source_rgb(cr, 0.75, 0.75, 0.75);\n  cairo_rectangle(cr, 0.0, 0.0, 1.0, 1.0);\n  cairo_fill(cr);\nif(percentage < 20) {\n    cairo_set_source_rgb(cr, 0.8, 0.0, 0.0);\n  } else if(percentage < 50) {\n    cairo_set_source_rgb(cr, 0.8, 0.8, 0.0);\n  } else {\n    cairo_set_source_rgb(cr, 0.0, 0.8, 0.0);\n  }\ncairo_rectangle(cr, 0.0, 0.0, percentage/100.0, 1.0);\n  cairo_fill(cr);\nPangoLayout layout;\n  PangoRectangle ink;\n  // grow is needed because ink. are int and everything gets rounded to 1 or so otherwise,\n  // leading to imprecise positioning\n  static const float grow = 10.0;\n  PangoFontDescription *desc = pango_font_description_from_string(\"sans-serif bold\");\n  pango_font_description_set_absolute_size(desc, .48 * grow * PANGO_SCALE);\n  layout = pango_cairo_create_layout(cr);\n  pango_layout_set_font_description(layout, desc);\n  cairo_scale(cr, 1.0 / grow, 1.0 / grow);\nchar text[100];\n  snprintf(text, sizeof(text), \"%d\", (int)roundf(percentage));\n  pango_layout_set_text(layout, text, -1);\n  pango_layout_get_pixel_extents(layout, &ink, NULL);\n  cairo_move_to(cr, 0.5grow - ink.x - ink.width / 2.0, 0.5grow - ink.y - ink.height / 2.0);\n  cairo_set_source_rgb(cr, 0, 0, 0); \n  pango_cairo_show_layout(cr, layout);\n  pango_font_description_free(desc);\n  g_object_unref(layout);\n}\n// global_toolbox.c\n  / battery indicator /\n  GtkWidget *w = dtgtk_button_new(dtgtk_cairo_paint_battery, CPF_STYLE_FLAT|CPF_DO_NOT_USE_BORDER);\n  gtk_widget_set_size_request(w, DT_PIXEL_APPLY_DPI(18), DT_PIXEL_APPLY_DPI(18));\n  gtk_box_pack_start(GTK_BOX(self->widget), w, FALSE, FALSE, 2);\n  gtk_widget_set_tooltip_text(w, _(\"battery indicator\"));\n. ",
    "CarVac": "Last time I tried to compile darktable it didn't work. I'll try fixing this up and getting it into a mergable state.. It's pretty much abandoned. I never got it to give results quite like Filmulator itself.. Yeah, I'll close it.. I'm not sure why it didn't result in the same appearance.\nThe filmulation process in Filmulator takes in linear data and spits out data that's intended to be interpreted with the sRGB tone curve, but even though I tried to make it behave that way in the darktable pipeline, it always looked dramatically different.. I use sRGB out of convenience in Filmulator but in the darktable module I think I used Rec.2020.\nThe narrower the color space, the more the algorithm accentuates colors (within the color space).. ",
    "topfs2": "Should I close this then?\n. ",
    "dabbill": "Basic Canon 80D support still needs some work done\n. Put files in wrong location\n. Added crop for Canon 80D\n. Added the black area for Canon 80D, seems to have fixed the pink hue\n. Should be ready to merge with main branch. From what i can tell the black area and crop are now correct. \n. I deleted all spaces in front of each line, and only used tab to get the space correct. Hope it sticks this time. :) \n. This should be ready to be merged. mRAW is the only thing that is not working, but I am not sure if that is something fixed in DT or another library. \n. Not what was intended\n. @LebedevRI I can confirm that this does fix DT for sRAW and mRAW for the Canon 80D. \n. ",
    "HansVanpee": "I think it works perfectly fine now (for my use case: Gnome\nShell/libsecret): by default passwords go to the \"login\" collection just\nlike with any other software package. It is completely transparent to the\nuser and storage is persistent.\nThe second PR came after some exchanges with Tobias Ellinghaus about this\nmatter. Both can be discarded now.\n2016-07-23 21:09 GMT+02:00 Roman Lebedev notifications@github.com:\n\n@HansVanpee https://github.com/HansVanpee as it was (IIRC) said,\nwithout some documentation saying otherwise, our current approach, now that\nit actually works, is no better or worse than this. (meaning: if no docs\nsay that this is the right way, we should probably keep what we already\nhave)\nAlso, why there is 2 PR's? #1214\nhttps://github.com/darktable-org/darktable/pull/1214 #1215\nhttps://github.com/darktable-org/darktable/pull/1215\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1215#issuecomment-234734822,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AAkOVfcZfVYtRqBqk_vSHP6vzOiNqDC7ks5qYmbwgaJpZM4IyLsq\n.\n. Don't rely on Gnome Keyring's \"Login\" collection anymore.\n. \n",
    "schenlap": "I'll create pr's for wb changes, removed it from this pr now.\nYes, crop values are checked and ok\n. 4:3 is already in git, so only 1:1 is missing\n. I don't think camera supports 1:1.\nAccording to the manual [1] page 75 and 76 1:1 is not supported.\nSo changes can be merged.\nhttp://www.manualslib.com/manual/360835/Panasonic-Lumix-Dmc-Fz18.html?page=75#manual\n. Maybe a little fuzzy. I changed it to 52. Better?\n. Yes, I konw extract_wb. But I did not know that one image can contain all wb presets, so I added wb_presets only if requested in the issue and files attached for every preset. I will add wb_presets as EOS M10 contains all preset in CR2 file :-)\n. Yes, coeffs are from adobe dng converter.\n. Ok, it seems that you have to go to\nhttp://www.photographyblog.com/previews/fujifilm_x_t2_photos/\nto download the images. I also get 403 from the direct link.\n. Some cameras (D7100) hat \"Lossless Compressed\" and \"Compressed\".\nCan Darktable handle both modes with the \"mode=??bit-compressed\" setting?\n. @LebedevRI \nNo, nothing to merge.\nI will ask on german dslr forum for help.\nBTW: I would reenable compressed and uncompressed mode even if we only have one image. Is that okay for you?\nShould I add a note if e.g 14bit mode is missing were we only got samples for 12bit?\n. > add a comment about missing in cameras.xml? Ok, it should be not necessary, rawspeed check should show missing modes.\nI see no point in that, rawspeed-check-nikon-modes.rb is supposed to do just that.\n. should i create a ticket for this to inform other users about fix of D1X? \n. yes, it opend the sample with only uncompressed mode.\nIt did not open it with just  compressed mode enabled.\nIt looked strange to me as this is the first camera that only has uncompressed mode but it worked.\n. I don't know why this is done, so I would not change it.\n. I don't know if we should merge this, as the samples in the ticket produce a warning.\n. @LebedevRI \nServer mention in  https://redmine.darktable.org/issues/8479 is not reachable.\n. black levels look strange, but i got this results....\n. @magicgoose \nPlease upload dt-noiseprofile-*.tar.gz file, this is necessary to check the noise profile data.. @LebedevRI \nDon't know if we can replace old data without destroying work on images created with old data. Feel free to merge or close this PR.\nIf the other topics in ticket are useless for darktable please close the ticket.. graphs looks ok, i think it can be merged\n11608. #11610 is already fixed (28 days ago). Do you have any problems with merged noise profile?\n. with both samples (Software : ILCE-6500 v1.04) of raw.pixls.us i get\n`\n  { \"Sony\", \"ILCE-6500\", Unknown             , 0, { 2.6171875, 1, 1.7421875, 0 } },\n{ \"Sony\", \"ILCE-6500\", Daylight            , 0, { 2.6171875, 1, 1.75, 0 } },\n  { \"Sony\", \"ILCE-6500\", Shade               , 0, { 3.08984375, 1, 1.44140625, 0 } },\n  { \"Sony\", \"ILCE-6500\", Cloudy              , 0, { 2.81640625, 1, 1.60546875, 0 } },\n  { \"Sony\", \"ILCE-6500\", Tungsten            , 0, { 1.64453125, 1, 3.15625, 0 } },\n  { \"Sony\", \"ILCE-6500\", WarmWhiteFluorescent, 0, { 1.9140625, 1, 3.109375, 0 } },\n  { \"Sony\", \"ILCE-6500\", CoolWhiteFluorescent, 0, { 2.44140625, 1, 2.5703125, 0 } },\n  { \"Sony\", \"ILCE-6500\", DayWhiteFluorescent , 0, { 2.54296875, 1, 1.84765625, 0 } },\n  { \"Sony\", \"ILCE-6500\", DaylightFluorescent , 0, { 2.8359375, 1, 1.6796875, 0 } },\n  { \"Sony\", \"ILCE-6500\", Flash               , 0, { 2.94140625, 1, 1.6015625, 0 } },\n  { \"Sony\", \"ILCE-6500\", \"2500K\"             , 0, { 1.43359375, 1, 3.80859375, 0 } },\n  { \"Sony\", \"ILCE-6500\", \"3200K\"             , 0, { 1.83203125, 1, 2.734375, 0 } },\n  { \"Sony\", \"ILCE-6500\", \"4500K\"             , 0, { 2.37109375, 1, 1.97265625, 0 } },\n  { \"Sony\", \"ILCE-6500\", \"6000K\"             , 0, { 2.79296875, 1, 1.62109375, 0 } },\n  { \"Sony\", \"ILCE-6500\", \"8500K\"             , 0, { 3.2421875, 1, 1.3671875, 0 } },\n`\nAre your values constant or do they change from image to image? Please upload ONE sample image to redmine issue #122201. Please amend your commits to avoid a non buildable commit.. Why didn't you use\nhttps://github.com/darktable-org/darktable/blob/master/tools/extract_wb ?. I am not happy with the soft bound as it is not visible in the gui and the user does not know on which parameter a soft bound is implemented. It is ok for me to stay on 250px, when you think it is enough. For the few time I use it, I can draw a finer mask.. Yes they are the same. Output of tools/dngmeta.sh\n`\nDNG created by : Adobe DNG Converter 9.6 (Windows)\nDNG Illuminant : 21 (should be 21)\n$ nano -w src/external/adobe_coeff.c\n{ \"Sony DSLR-A380\", { 6038,-1484,-579,-9145,16746,2512,-875,746,7218 } },\n`\n. @LebedevRI \nDarktable did not open the image without this change. I wanted to test if this change is really useless than I would revert. \nBut there is something strange going on. Today it does not open the image anymore, even with my nikon_d1 branch.\nIn https://github.com/darktable-org/darktable/blob/master/src/iop/temperature.c#L942\n```\n    // Only check the first three values, the fourth is usually NAN for RGB\n    int num_coeffs = (module->dev->image_storage.flags & DT_IMAGE_4BAYER) ? 4 : 3;\n    for(int k = 0; k < num_coeffs; k++)\n    {\n      if(!isnormal(module->dev->image_storage.wb_coeffs[k]) || module->dev->image_storage.wb_coeffs[k] == 0.0f)\n      {\n        found = 0;\n        break;\n      }\n    }\n```\n4 coeffs are checked, but the 4th is NaN.\n```\ncoeff[0] = 0.960152\ncoeff[1] = 1.000000\ncoeff[2] = 1.041009\ncoeff[3] = nan\n```\nand I get\n[temperature] failed to read camera white balance information fromRAW_NIKON_D1.NEF'!`\n. Ok, whitelevels are my error, but:\nwith ISO1600 samples i get different results depending on the tool i use:\ndngmeta.sh panasonic_lumix_dmc_lx15_68.dng: Sensor black=\"146\" white=\"4095\"/\ndngmeta.rb panasonic_lumix_dmc_lx15_68.dng: \n```\nsensors [[1600, [145, 4095]]]\nmostfrequent [[145, 4095], [1600]]\ninvsensors {}\n    <Camera make=\"Panasonic\" model=\"DMC-LX15\">\n            <ID make=\"\" model=\"\">Panasonic DMC-LX9</ID>\n            <Sensor black=\"145\" white=\"4095\"/>\n    </Camera>\n\n```\n. This is for more files.\nFor  one file it should return the same value as dngmeta.sh, or?\nIs this a rounding issue?\n. it does not fail with BLACKDIFF_MAX to 0.\n. please remove extra newline. Afterward PR can be merges, noise profile looks ok.. I thought about it. I did not find any information which tag should be created  on http://www.exiv2.org/tags.html \nI'd say keep it and if there are same images which only write these tags we can add them.. i added a space here to match YI M1 maker name. Please review changes in .schema. This breaks all other Ricoh cameras. please create a ticket on https://redmine.darktable.org/projects/darktable/issues/new and add dt-noiseprofile-.tar.gz\nof noise profile. This is necessary to check the profile.. I thought about which value makes sense. 250 is too small, it takes too much time to draw the mask. The feathering works really great so there is no need to draw accurate masks. For my camera (24MPx)500px is ok, i decided to go up to 1000 for hi res cameras.\nwith soft bound:\n-> longest side = 6048px -> 500 / 6048 * 100% = 8.3% -> a soft bound of 10% of the longest side seems pretty good for me. I don't thin calculating the diagonal is needed.. ",
    "Hodapp87": "Thanks, I will try to remember to do that in the future.\n. I can put it there, but is there a better place, given that this has nothing to do with packaging darktable on NixOS (nixpkgs already handles that), but rather is about creating the dev environment there?. I took these from the Nixpkgs derivation, which I didn't write in the first place. However, it seems you're right, as I was able to remove all the ones you said and the build appeared fine to me.. ",
    "supertobi": "I have a little bit mixed feeling about lua script management.\n1. It is better and easier to use for the user then the luarc file.\n2. I don't like the UI, but I don't think it's not possible to make a better one with Lua at the moment. This UI will not work very  if we get more scripts. It would be nice to have a tree structure, and a search field... Or perhaps move it into the Preferences with checkboxes. \n3. And I'm not sure if our structure of the scripts is in a fixed state. \n4. What about the yeald.lua, we need it for some of the other scripts. Do we need special handling here?\n5. Do we want the Lua script examples in there?\n6. And the really bad think, is that I don't have to much time at the moment... So please don't wait to long for comments from me and move this forward.\n. Please make a PR to lua-scripts, we can improve it there. And feel free to advertise it everywhere you want. \n. Disclaimer: I'm \"just\" an interested user and haven't looked into your.\nFirst of all I'd like that I really would like to see this in dt.\nSome comments/questions to this topic:\n1. There is a feature request about reverse geocoding in the dt bug tracker with a small Lua prototype I wrote to do the geocoding with mapbox:\nhttps://redmine.darktable.org/issues/10798\n2. Do you do come caching?\nIn the Nominatim usage policy this is a requirement:\nhttps://operations.osmfoundation.org/policies/nominatim/\n3. Do you have some kind of tree for filtering the images with something like:\ncountry, region, place, poi\n4. Is it possible to deactivate the function?\nI can think of some people like to do this for different reasons. (e.g. privacy, costs)\n5. Does the job start if the coordinates are changed by a Lua script?\nI wrote this Lua scripts, that lets you amongst other things change the coordinates. (e.g. in the function copy_gps()):\nhttps://github.com/darktable-org/lua-scripts/blob/master/contrib/geoToolbox.lua\n6. @jbvoelker has written a Lua script that does reverse geocoding, perhaps he is interested in this topic to:\nhttps://github.com/jbvoelker/lua-scripts/blob/geolocation_tag/contrib/geolocation_tag.lua\n. > how many images do you have with exactly the same coordinates\nA lot. I usually do more then one picture (different settings, panorama, ...) at one place. \nI thing the solution could be quit simple. Just add lon and lat to locations table, then you can do first a simple select and then ask the web service.\n. First time I've resolved merge conflicts in github. I hope it's OK.. packaging/opensuse/darktable.spec will be deleted, so I close this PR. Undone the changes in the po file.\n\nIs there a reason for having this in 7 commits instead of a single one?\n\nYes, I used the online editor from github and made the changes there. And then every file changed is a commit.. That sounds very useful. Do you have any measurements how much faster this is?. You are right.. ",
    "wpferguson": "I'm not sure if this is bad form, commenting on a closed PR.  If it is, I apologize in advance.  \nI agree that the lua-scripts infrastructure needs to progress some before adding this in.  I'll offer @supertobi whatever assistance I can with that.\nIn the meantime, does anyone object if I throw script-manager out on the darktable-user list as a drop in replacement for the user's luarc file?  That way the users have something better than the luarc file, we get some testing, and maybe someone will have a better idea after using it.\nAnd, last and least, I guess I'm now in the lead for the \"Ugliest UI Element of the Year\" contest?  :-D\n. Where should I put this?  Should it go into contrib or do we want to put it\nin a different directory (tools, later, hold, in.work)?  In it's current\nform it's not \"self-aware\" so if a user cloned the repository and enabled\nall the scripts it might try and include itself and set up an endless\nloop.  Lua may be smart enough to see that it's already loaded and not\nallow this to happen.\nOn Wed, Sep 7, 2016 at 4:04 AM, supertobi notifications@github.com wrote:\n\nPlease make a PR to lua-scripts, we can improve it there. And feel free to\nadvertise it everywhere you want.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1254#issuecomment-245205946,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABjySwIQftGsKznjmDoI3h4mf98TBWKPks5qnnABgaJpZM4J0tPX\n.\n. That's pretty much how I'm using it now.  I have lua linked to my\ndevelopment directory and then when I fire up DT script controller scans\nwhat's there and I turn stuff on and off as needed.  I could kludge\ntogether a search box using an entry and a button.  I'll have to think\nabout how to return results\n\nOn Thu, Sep 8, 2016 at 5:40 AM, houz notifications@github.com wrote:\n\nJust as a random remark: I kind of like how Blender handles scripts. It\ndoesn't fetch them from the web for you, but it recognizes those you put\ninto the directory it scans and offers them to be enabled/disabled in the\nsettings. With a search box.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1254#issuecomment-245546426,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABjyS5DLjkrjDbOCj_NJ776aLh5JSU3Iks5qn9gNgaJpZM4J0tPX\n.\n. In my case I have 422,294 images in the library. rename-tags.lua probably\nprocesses around 3 images per second, so at that rate it would take 39.1\nhours to find all the images with a specific tag, versus a second or two\nfor the database query.\n\nI did have a thought on rename-tags.lua.  If we rewrote it to work on\ndt.gui.action_images, and used the collect module to collect images by the\noffending tag (as a manual get_tagged_images()), we could realize a\nsignificant speedup.\nOn Mon, Sep 3, 2018 at 11:25 AM supertobi notifications@github.com wrote:\n\nThat sounds very useful. Do you have any measurements how much faster this\nis?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1716#issuecomment-418145000,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABjySz661Y0-YFGrHEUciqkjIre0WXoEks5uXUnkgaJpZM4WQsyV\n.\n. @TurboGit , tested and it works.  And, it's a much more elegant solution than mine.  I thought about other modules being effected, but my understanding of the GUI code is rather limited at this point.. On Thu, Feb 7, 2019 at 9:09 PM Yusuf Olokoba notifications@github.com\nwrote:\nIs this verified to work? I have manually built and tested master and\n2.6.0 and when using --style, the export fails:\n$ darktable-cli one.CR2  one1.jpg --style deraw.dtstyle\n\n[imageio_storage_disk] could not export to file: `one1.jpg'!\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1908#issuecomment-461666085,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/ABjyS848s2wgZMUpxAwt5yNTE9CZwdc8ks5vLNxDgaJpZM4ZVrOk\n.\nThe style argument uses the styles you have defined in darktable.  So,\nyour command should be\n\ndarktable-cli one.CR2  one1.jpg --style deraw\n. ",
    "DeadMetaler": "https://redmine.darktable.org/issues/11068\ntarball on GoogleDrive\n. ",
    "Oblomov": "For what it's worth: all Get*Info APIs in OpenCL are designed to always return the parameter size via value_size_ret (unless an error occurs, of course), so the double-call with the first being..., 0, NULL, &size_ret is the standard way of handling dynamic return values (modulo bugs in the specific platform, of course). Initializing the ret value to 0 is a good idea, but of course it's good to always check the return value of the API anyway (which the proposed patch does).\nDo beware with the use of realloc() though, remember that it can fail leading to a leak of the previous allocation \u2014always 'back up' the pointer before calling it. Also, if realloc fails, you want to set the error to CL_OUT_OF_HOST_MEMORY probably.\n. ",
    "holomorph": "\nDoes this undo the changes, or actually just fix the code?\n\nIt undoes the part of the code that displays a certain range of exposures as N\u2033M\n. just for the record: I compared floats from exif to what's displayed in your sample files, and my camera\n| exif (s) | d3200 | 550d |\n| --- | --- | --- |\n| 1.3 | 1.3\u2033 | 1\u20333 |\n| 0.8 | - | 0\u20338 |\n| 1/1.3 \u2248 0.77 | 1/1.3 | - |\n| 0.625 | 1/1.6 | - |\n| 0.6 | - | 0\u20336 |\n| 0.4 | 1/2.5 | 0\u20334 |\n| 1/3 | 1/3 | - |\n| 0.3 | - | 0\u20333 |\nso the cases are roughly that exposure can be expressed:\n- in tenths of a second from 0.3\u2033 to 2.5\u2033\n- an inverse of a number by tenths; e.g. 1/1.3\n- both; e.g. 0.4\u2033 = 1/2.5 = 0\u20334\n- integral above 1.0\u2033 with some exceptions; e.g. 1.3\u2033, 2.5\u2033\n- integral denominator below 0.3\u2033; e.g. 1/4, 1/5, \u2026, 1/250, \u2026\nfun times\n. The latest commit shows the correct exposure for your test images, and images on my Nikon.  The way the cases are written, though, 1/2.5 will be shown instead of 0.4\u2033. Same value, different way of showing it.\nYuck, at this point I'd want just a separate function for formatting the exposure.\n. ",
    "peterbud": "@LebedevRI  when I built the usermanual it was also extremely slow. The whole darktable build takes 3-4 minutes on my machine, and the usermanual took alone 30 mins+(!) to build. the xsltproc was using only 1% of the CPU, so I have no clue what it was doing. And yes, it was constantly downloading the stylesheets from the internet.\n. Dear Roman and Pascal, this is my first contribution to the darktable community, so I don't have any history of ignoring words.\nI clearly see the risks you mentioned, and I trust your experience. I was thinking hard before submitting this PR (You saw the first sentence...): Nobody knows how many bugs will surface. Nobody knows how many people would contribute and maintain this part of the code. I don't have a team and I can only speak for myself. As you have seen in the last two months I have spent quite some time to understand the code and the software, and put a lot of energy to build a foundation and reach this state. I would happy to do that in the future as well, as it was fun and rewarding.\nIt's a collaborative effort, and we need to start somewhere. I believe all software (I guess also darktable) started small with a lot of bugs, and with a few people to participate. But with the time bugs are getting less and more people are joining. I'm happy to continue discussing it on IRC or some other forum in a smaller group.\nPeter\n. Hi @boucman , thanks for the reply. Actually it makes a lot of sense: I'm happy to keep it on a separate branch, which we can merge/rebase from time to time. Also you have a point with the binary release, anyhow it will be a longer shot to do it properly.\n. Thanks @boucman , it makes life easier, indeed. Thanks @houz - I'm happy that the installer is now working (well, almost). I know the crash on import, we have discussed that with @LebedevRI  at the weekend. Unfortunately in my bt I have not found the above mentioned error message. Few questions:\n\nShall we add a message box on crash to notify the user on the location of the backtrace?\nWhere did you find the above error message? It was not in my bt :(\nApparently I need to add to the installer the compiled GTK schemas, I have now found a pointer to that here. The backtrace is being written to the directory which the g_file_open_tmp is using. Based on the documentation of g_get_tmp_dir on Windows this is where the TEMPenvironment variable is pointing, by default %USERPROFILE%\\AppData\\Local\\Temp\n\nWith LebedvRI we have discussed earlier that we'll add this location to the documentation specifically.. BTW I have just tested: if I copy the content of /share/glib-2.0/schemas to the darktable directory, there is no more crash - I'll update the installler shortly!. Thanks @houz, this looks promising indeed, will look into that! I have merged, let me know what else should I look into.. @Lirein thanks for that, as rawspeedis an external module, it should be pushed in the upstream project. Also we had an earlier discussion on MultiByte filenames here - in essence these are requiring further efforts, and we agreed to try to scope this PR to contain the most important things to make the Windows build working, then we can identify, fix and test all those issues step by step.. I'll have more time later today, I'll check on running DT on VMs. Surely I have a Win 10 VM somewhere (but so far have not tried running DT on that), and will check on a Windows 7 VM, but will take more time (as I don't have it at hand)., My gut feeling it has to do something with OpenCL, but one never knows.. @houz : also a short update on an earlier suggestion of you:  have been testing the cmake BundleUtilities, and it is working (almost) perfectly. Actually when I have called fixup_bundleon the plugins directory, it has detected additional dependencies which I was not aware of before! Nevertheless we'll need to keep parts of the cmake scripts which are installing pixbuf libraries, adwaita, gphoto cameralibs etc. as these are not detected by fixup_bundle, and they have to be a specific location and not just in a bin directory. This approach will simplify things definitely.. @houz: On Windows 10 VM (Hyper-V) darktable just installs fine, and starts properly.\n\n. @houz : I have managed to install darktablealso on Windows 7 VM. In fact these are the very same debug builds which I have in my windows-build branch, just a week old (since then I'm trying to massage the BundleUtilities to make it work). So the bottom line is that I have not changed any CPU specific optimizations just used what we already have in the source. Later I might look into installing a release build on these VMs to see whether there is any difference.\n\n. @houz : now I have finished the first pass with cmake BundleUtilities. Here is my summary and questions:\n\nIt works passing by an executable or folder plus the names of plugins. I'm passing darktable binfolder, plus the lib/darktable/plugins library. It detects all the shared libraries which either the executables or the plugin libraries linking to, and adds them to the bin folder, and installs them along with the dt binaries. BTW the fixup process is very time consuming, alone that has doubled (!) the build time, on a pretty powerful machine. Also it packs these shared libaries together into the installer package nicely.\nfixup_bundle works only if all files are installed. In cmake its rather difficult to force something to run after install (ideas are welcome), at the end I have added a CMakeLists.txt into a packagingdirectory, and the fixup_bundle code is in that file.\nThe problem is that if a shared libary is using another shared libary in a plugin style, as those are not detected. Example: libGraphicsMagick-3.dll is detected as a dependency, and is being added, but neither libGraphicsMagick++-12.dll nor libGraphicsMagickWand-2.dll. Maybe these two are not used by darktable, but those are part of the GraphicsMagick package. So I guess we still need to install them if we want to make sure that darktableworks properly. Similar example is libharfbuzz-0.dll is detected, but neither libharfbuzz-gobject-0.dll nor libharfbuzz-icu-0.dll\n\nDo you have any suggestion for these? So far I can keep them on the manual list as before which I have compiled by hand using package dependency tree and package content list.. Strange, I have not had similar problem, but I don't have Visual Studio installed on my machine :) \nI did a bit of google, and found this\n\nBundleUtilities looks for a suitable tool and on Windows prefers dumpbin over MinGW \nobjdump. In my case even though I am using MinGW for builds, I have MSVC \ninstalled too. \n\nIt looks like it can be forced to use objdump, will try later.. @houz is there anything needed from my side to merge the remaining changes and close this PR?. 1. Indeed there are other formt(printin the code, but they are not using formatting characters which are gnu_printf specific like %zor %llu Should we change all of them even though they are not using these extended formating characters?\n2. I did not get that part about printf (3), apologies\n. Works well as well in Windows with 1.8. As I see they have turned on the new build flag BUILD_PKGCONFIG (which is good!)\nhttps://github.com/Homebrew/homebrew-core/commit/556a412cad8d1e2b9ac3b5b449551da2a40d0d18#diff-a466161cd94499914fec86537d914681R22\nThat new flag is creating for the header files and for the static library a separate subdir, and also generates a PKGCONFIG file. The old FindPugi.cmake was not using pkg-conf at all, and tried to find the header files in the include dir with brute force.. Hmm pugixml/1.8/lib/pugixml-1.8/libpugixml.a ?\nNormally the static library is installed ${PREFIX}/lib/pugixml-1.8/libpugixml.a\nseems pugixml/1.8/ at the beginning like an error. \nBut I have 0 experience on homwbrew/osx. Nice catch. So homebrew takes the timestamp in the tarball to mark the compiled binaries? Learning every day.. I see there is a better solution by @houz !. Perfect!. What shall we do with this? Any better idea how to notify the use on the location of the bt file?. Pls don't merge, it looks like I have a better solution. Let's close it. I was not able to find a good solution.. Yes, it builds the installer as well. In theory it can be even used for deployments eg for GitHub. I have tried how that works with BinTray. Actually its nice that it could also provide statistics etc.. Is there anything else needed here to change?. * arrow keys select images in lighttable: I have not experienced that behavior. Also I have checked and there has no arrow key handling been added to the lighttable view code, so I'm wondering how that would alter existing behavior. Can you maybe help with a more detailed repro, please?\n* zoom steps: these factors are always interpreted as multiply of one screen at the current zoom. So factor 1 means that with one arrow click will move the current view by one screen left/right/up/down. If we change that to 0.2, it means it will take 5 arrow key clicks to move the current view by one screen. So this is really dependent on the size of the picture, size of your screen available in darkroom (without the sidepanels) and you current zoom level. With the existing settings you have 2 magnitude of scale from 0.01 to 10 (100x multiply). With this change we limit that to certain extent, as it will go from 0.02 to 1 (50x multiply), so it will take more clicks to navigate. My images are around 12 MP, and it is still OK, I'm wondering how bigger resolution images would behave, ie would it be still convenient to navigate around with arrow keys only. Nevertheless, I will do the change.. IIRC we discussed that we should strive to have uniform path delimiters always on each platform to avoid surprises.. Yes, these parameters are shown only in the Preferences dialog box, and users are free to overwrite whatever they want.\nI was thinking further, and I realized that this is not a perfect solution yet. \nConsider this: the default value for session/base_directory_pattern is $(PICTURES_FOLDER)/Darktable, but user can overwrite to $(PICTURES_FOLDER)\\Darktable or $(PICTURES_FOLDER)\\$(YEAR) or $(PICTURES_FOLDER)\\$(YEAR/19/) or $(PICTURES_FOLDER)\\\\($(YEAR/19/)\\) or even $(PICTURES_FOLDER)\\$(YEAR:-2) or even more crazy stuff.\nNow we have to accomplish the following things after reading these parameters:\n Step 1: On Windows we need to replace directory separator / characters while preserving variable related / characters both in base_directory_pattern and in sub_directory_pattern\n Step 2: We need to concatenate base_directory_pattern with sub_directory_pattern using platform specific directory separator character\n Step 3: We need to escape directory separator \\ characters, otherwise variable expansion fails\n Step 4: we need to do the variable expansion\nAm I reading it correctly? What would be the best way to achieve Step 1? Cases like $(PICTURES_FOLDER)\\\\($(YEAR/19/)\\) looks difficult to solve. Or rather skip step 1, do step 2-4, and do the replacement of / to \\ at the very end?\n  . So based on the discussions on IRC:\n session/base_directory_pattern and session/sub_directory_pattern are now concatenated with \\\\\n Therefore subsequent variable expansion works fine\n Added dt_util_normalize_path() but as the files are not existing a that time, this function cannot fix the filename if those are containing '/'. I'd remove those line TBH. Please advise.\n In dt_import_session_path() added a section for WIN32 platform to replace remaining '/' with '\\' before creating the new filmrolls. I have another idea: What if we would move the variable expansion to the _import_session_path_pattern()?\nWe would do separate variable expansion on session/base_directory_pattern and session/sub_directory_pattern directly in _import_session_path_pattern(), then we can safely join them with the G_DIR_SEPARATOR_S, and finally before returning we could replace any '/' (which might come from the original session parameter) with G_DIR_SEPARATOR_S (which would not change anything on Linux, but would work on Windows. . > We can't replace / with \\, at least not with a simple string replace.\nWhat is the danger in replacing / with G_DIR_SEPARATOR_S after variable expansion and g_build_path()?. That would mean a more substantial change in the whole import process and philosophy, right?. Thanks, I have fixed and squashed. I'd love to have a discussion on what is the best solution from the end user perspective.\nI clearly remember how confused I was when I first saw two scroll bars on the right (at least I thought they are), and then it turned out that you cannot really use the outer one, as when you try to click on that and drag, actually it hides the right panel.\nI find it more natural to have a real scroll bar next to container which you can actually move with the scroll bar - I believe this is what @oexler was trying to achieve.. Any comment on this?. This PR has been opened 10 months ago. So let's close it.. I'll look later what would it take in the opposite direction, ie no console by default, and then for --help, --version add a console by hand.. I was thinking about whether maybe we can create a \"strategy\" or guiding principles with regards to the UI? I mean currently the \"top row\" (I'm not sure that's the right name) mainly contains UI elements which are controlling the lighttable layout/content:\n star filter drop-down\n sort by drop-down\n grouping toggle button\n image overlay toggle button\nI believe that is consistent and somehow follows a logic which a user can easily understand.\nIn the bottom row we have the controls which changing the star rating and labels for the selected images, so those are not changing the lighttable layout/content, but changing image attributes - that makes also sense.\nOn the other hand, in the \"bottom row\" we also have UI elements which control the lighttable UI/content:\n filemanager/zoomable lighttable drop down (BTW anybody felt that it could be replaced with a toggle button as well?)\n zoom slider\nCan we maybe streamline these UI elements, saying \"top row\" is primarily for controlling lighttable layout/content, \"bottom row\" is only for image manipulation?\nAnd back to the PR at hand: I'm not sure which category the battery indicator might belong in this strategy.. According to IRC, I have made additional changes: mainly enabling the user to decide whether he/she would like to run this performance tuning or not. Also added the suggestions from @LebedevRI .\nWhat bothers me is that at the very first run after a new install we should not present this dialog (but simply silently configure as before), but currently this check will prevent showing the dialog even for existing installs, as I cannot decide whether it is really the very first run after a new install, or just a new version installed over an existing one where this code is being introduced. Maybe I could use dt_conf_init() to figure out and return whether there was no darktablerc at all (meaning really a new install) and act accordingly?. @phweyland : can you clarify whether you don't see these particular messages in the log file, or you don't see the log file at all?. No, this PR does not fix the crash, I'm looking into that one as well. These changes just fix the building process.. It's only a stupid validation error, because the latest MSYS2 version of jsonschema recently cannot cope with these special characters, and results validation error (hence stopping the build), where the json file is perfectly valid. Once you replace these '\u0109' with 'c' validation is successful, and build succeeds.. He is using the crop and rotate module as I see on the video. Also Entangle is not available on Windows, it's last release is also 1+ year.\nI agree tethering is indeed not the most polished part of dt, but based on that we could also deprecate many other things.. Yes, it works, there is a short description how to make it work in the FAQ:\nhttps://www.darktable.org/about/faq/#faq-tethering\n. Considering that nothing has changed on the installer side and methods for the last year, it's difficult to provide more help.\n@pschwartz could you run a system information on your system:\nmsinfo32 /report C:\\Users\\[YOUR USER NAME]\\Documents\\syssummary.txt /categories +systemsummary\nAnd share the results, pls?. @pschwartz Any update?. @JIPG2 Pls open a separate issue describing your problem. @TurboGit : could you pls close this issue due to lack of response? If we get more information from @pschwartz we can re-open it.. Confirmed. I'll look into this. What I see during debugging is that the curl curl_easy_perform call here returns with CURLE_SSL_CACERT_BADFILE, so it seems this is a libcurl problem on the MSYS2/MINGW.\nI'll keep researching.. Thanks.\nAdding:\ncurl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, FALSE);\nsolves the problem, and search is working,  but I'm not yet sure this is the right approach. I need to understand how curl is trying to locate the CA file.. I did further investigation and would be interested in your views.\nI have tried the CURL_CA_BUNDLEsetting , and it does not work. Looking at the source, it clearly says, that CURL_CA_BUNDLEis NOT considered when the backend is Schannel (WinSSL)\nhttps://github.com/curl/curl/blob/master/lib/url.c#L493\nNow the MINGW version of the libcurl has unfortunately a WinSSL backend:\n$ curl -V\ncurl 7.63.0 (x86_64-w64-mingw32) libcurl/7.63.0 OpenSSL/1.1.1a (WinSSL) zlib/1.2.11 brotli/1.0.7 libidn2/2.1.0 libpsl/0.20.2 (+libidn2/2.1.0) nghttp2/1.35.1\nRelease-Date: 2018-12-12\nProtocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtsp smtp smtps telnet tftp\nFeatures: AsynchDNS IDN IPv6 Largefile SSPI Kerberos SPNEGO NTLM SSL libz brotli TLS-SRP HTTP2 HTTPS-proxy MultiSSL PSL Metalink\nSo that leaves the not too many option, I have tested this:\ncurl_easy_setopt(curl, CURLOPT_CAINFO, \"../share/curl/curl-ca-bundle.crt\");\nand is working properly assuming copying the file to the install location.\nAny other ideas/options?. Currently I think the best solution so far is to package this CRT file to dt, install it somewhere [dt install dir]/share/curl, and add this line:\ncurl_easy_setopt(curl, CURLOPT_CAINFO, \"../share/curl/curl-ca-bundle.crt\");\nIt will be similar to the OSX solution, and will work also with Windows.\nHappy to hear back if @techexo figures out something more sleek solution.. @coderine  thanks for the submission.\nThis description does not quailify for a minimal working example. Pls be specific (avoid vague descriptions like \"few tools\", \"few files\"), and try to find the very minimal environment/setup which leads to the issue in a reproducible way.\n. @TurboGit , I think we can close the case.\nIf we hear back a more specific repro scenario e can reopen the case. @parafin is right, no need to add the crt file to the repo. We just need to package this file into the installer in Windows (in MacOS @parafin  is already including that file into the bundle). I'll do that.. @techexo  Your repo is not up-to-date with the master, so it would be painful to open a PR there.\nHere you can find the change you need to add to include the curl-ca-bundle.crt file into the install\nhttps://github.com/peterbud/darktable/commit/4f9078088055835dfcfb7e8b29653f9ba9723d53\nAlso all these lines:\ncurl_easy_setopt(ctx->curl_ctx, CURLOPT_CAINFO, \"../share/curl/curl-ca-bundle.crt\");\nwill work only if the file will be there, and neither the MacOS, nor the Linux versions will copy there this file, so until there is an agreement how to handle this on those platforms you should wrap these calls with WIN32 conditionals IMHO.. I'll look into this latest at the weekend.. Confirmed. based on my experience a simple double-click on the rotation symbol is enough to being thrown back to lighttable. However the program does not crash (at least there was no crash for me), but behaves erroneously.. I have no problem with exporting to an existing or non-existing folder. Would be interested in others as well.\nA few questions:\n what is the -d traces switch? for me this command line does nothing:\n\"c:\\Program Files\\darktable\\bin\\darktable.exe\" -d traces\n with -d controlI got the following trace:\n[run_job-] 08 259401445.790393 23.675839 \nload image 100 mip 1 | queue: 1 | priority: 423.676838 \n23.676838 [run_job-] 04 259401445.791894 23.677339 load image 98 mip 1 | queue: 1 | priority: 423.677841 \n31.674014 [add_job] 0 | 31.674509 export | queue: 3 | priority: 031.674509 \n31.675008 [run_job+] 08 259401453.790064 31.675519 export | queue: 3 | priority: 031.676011 \n[export_job] exported to `C:\\Users\\peterbud\\Pictures\\lakas/test/DSC_0068.jpg'\n```\n How do you specify the output folder? Typing in the folder by hand or by using the directory selection button?\n Do you have LUA scripts enabled and if yes which one? Is LUA configured properly?\nEdit: I'm using 2.6.0. I'd suggest to scope the problem first for an existing published version, and make sure that is working. We can tackle current master version later.. Disable LUA. It's very confusing to locate the issue, and my guess is that this is your problem.\nAlso I have noticed on one of the screenshot your path begins with C:\\\\Users (note the double \\), on the other screenshot it begins with C:\\Users.\nSo disable LUA (e.g no luarc file in your config directory), start with a clean darktable. Import an image. Select the export folder with the directory selection button. Pls note that if you select a folder this way the folder name will contain double \\\\ as separators, because houz's variable replacement works only that way.... 4 times \\? How?\nWhen I select D:\\Test\\test2 using the button I get this:\n\nFor the without lua scenario: can you send the log pls? The one you have attached before is full of lua messages\nHere is my log you can compare:\ndarktable-log.txt\nEdit:\nthe easiest way to start a clean dt is to rename the existing config folder, like \nC:\\Users\\peterbud\\AppData\\Local\\darktable -> C:\\Users\\peterbud\\AppData\\Local\\darktable.bak\nand then restart dt, That way you wont' have luarc, and all your setting will be reset to default. Later on you can revert the renaming to get back your original db/settings.. And one more thing:\n\n2.192547 LUA ERROR : cannot open C:\\Users\\Philippe\\AppData\\Local\\darktable\\luarc : No such file or directory\n\nIs perfectly normal as far as I know.. Based on my experience having 2 \\ or 4 \\ is independent of whether you have images in the folder or not. The per-requisite for having 4 \\ is that the existing export folder on the UI should contain already a drive letter. If that's the case you will get 4 \\ after selecting a different folder even if you have no image in the folder.\nAt the same time whether 4 or 2 \\, the export always works, as you have also stated. \nI have also tried with \"system\" folders like Documents etc, and for me those are working as well.\nSo first thing to fix : folder selection should be fixed to avoid 4 \\, even better would be good to avoid even double \\, because it's rather ugly and confusing. But this is cosmetics, and does not stop the export.\nSecond thing to fix: What is interesting is that when during export the file is written, and if that is unsuccessful, the return value is not being evaluated, and export will try to add exif data even in case the file creation at the first place was unsuccessful.\nhere is when the file is created:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/imageio.c#L913\nand here is when independent of the success/failure of the file creation, exif data is being added:\nhttps://github.com/darktable-org/darktable/blob/master/src/common/imageio.c#L929\nSo based on this I believe for you the file creation fails silently in write_image(), and then export tries to add an exif data to a non-existing file, and that what you see in the log.\nBut this still does not explains your problem, and does not help me to repro it still.\nPhilippe, can you check the permissions for those folders where the export fails? Which accounts have write access to that folder? Can you launch darktable as admin (right click on the stat menu, More.../Run as administrator, and then try to export to those problematic folders?. Confirmed, same here. I'll try to look into this. I have tested with the latest master and the latest gtk, and it does not crash anymore (both debug and release version was working and did not crash upon keyboard layout change)\nSo I suggest to test with the upcoming 2.6.1 release.. @asmigala have you had a chance to test this with the 2.6.1 release?. It does show this erroneous behaviour on the Windows version. I'll look into this. You can check it by \"echo $CAMLIBS\". I made a note here as normal MSYS2 packages do not like to add env variables, but libgphoto2 needs that. So for the current mingw-w64-x86_64-libgphoto2 I have included a script which adds this to the MSYS2 environment, but this comment is more of a reminder for later that the installer needs to take care of this aspect.\n. As I see these flags were used only when it was built for WIN32. The only change I made is to remove the -s flag. I guess nobody noticed that there are no debug symbols are available in the debug version, maybe there was no debug done on those early cross-compiling versions at all.\n. fseek is there, just the original code went to an infinite loop, as the condition \nif(c != EOF) was never true. \nThis particular code as I see is creating your default keyboardrc file if you don't have one from a template, but due to never reaching EOF condition, it has created 90MB+ size keyboardrc file until I killed the process :)\nI'm not an expert, but in the fseek documentation I see that \" A successful call to the fseek() function clears the end-of-file indicator for the stream\" For that reason I have decided not to use here the fseek().\nThe updated code above was safely creating for me the keyboardrc file from the template, and I have tested that functionalty also on Ubuntu and worked well.\n. rad1 and rad2 are unfortunately already defined numeric constants in dlgs.h - this change is basically a naming collision fix\n. I have now installed clang, and I'll make a change to getdelim.c and getdelim.h to see that the format is OK (will also add header comments). If yes, I'll update the other files I have modified. \n. Actually no intel specific there, should work both, will update.\n. My understanding is that darktablerc is a result of an xsltproc custom command. \nadd_custom_command(\n    DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/../tools/generate_darktablerc.xsl ${CMAKE_CURRENT_BINARY_DIR}/darktableconfig.dtd ${CMAKE_CURRENT_BINARY_DIR}/darktableconfig.xml\n    OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/darktablerc\n    COMMAND ${Xsltproc_BIN} ${CMAKE_CURRENT_SOURCE_DIR}/../tools/generate_darktablerc.xsl ${CMAKE_CURRENT_BINARY_DIR}/darktableconfig.xml > ${CMAKE_CURRENT_BINARY_DIR}/darktablerc\n  )\nI tried to change the xsl file to make sure darktablerc have LF only at the line ends but did not find a good solution, and ended always with CRLF line ends. Any suggestion would be helpful here.\n. I'm not a cmake guru, so I might be wrong, but the added section is not interfering with the darktablerc output or creating circular reference.\nFor the configure_file there is the parameter called COPYONLY, which according to the documentation, \"Copy the file without replacing any variable references or other content\". So I beleive thats the reason that we have only one target (the original), the added configure_file is not defining any additional target IMHO\n. Not available - yet, but I'm working on it. flickcurl has been compiled without any major problem, I need however to test it. The package is ready, just I don't want to add to the MINGW-packages until I test the flickcurl library properly. So first step; I need to create a Flickr account, as I'm not using it.\n. Makes sense. I saw the doc/windows.txt actually, it seems to me describing how to do a cross-compile. What would be the best location of the merged file: /doc/windows.txt or the packaging/windows/BUILD.txt?\n. I think as long as the CLASSPATH points to the right directory it can be anywhere I guess.\n. Yes it is a native compile.\n. :)\n. Basically I have 2 major types of warning during compile:\n- Shadow warnings, like \n  warning: declaration of 'data' shadows a previous local [-Wshadow]\n     const uchar8 *data = mFile->getData(key_off, 1);\n- printf format warnings, due to the fact that C runtime (MSVCRT) does not have all the format strings, like z. Example:\n  warning: unknown conversion type character 'z' in format [-Wformat=]\n  ThrowRDE(\"Out of memory, failed to allocate %zu bytes\", size*sizeof(int));\n. I have used only _WIN32 , the others were already there. Agree that it should be unified, and I believe the _WIN32 is the good, based on this article:\n_WIN32 or WIN32\n. 2 weeks ago it was not necessary, but with the latest merge I saw changes in CMakelist.txt, which now runs a shell script to get the version number, and that specific shell script (I believe get_git_version_string.sh is not yet working in this environment. So this is only needed until I figure out how that shell script works.\n. OK, I have fixed this, no need to specify the version\n. Seems to me a GUI issue. So I have now all the modules, like tethering, map, slideshow, but instead of showing them aligned to the right, as always, it adds a dropbox called \"other\", and then you can select the modules. COuld not figure out yet why. See the two screenshots below\n\n\n. Admittedly I have never worked with lua before. Is this select () an async I/O waiting for the fd to be available for reading a file? For async I/O I believe we can find a solution. Or when the read_cb()is called?\n. Wow, I remembered all views/modules were in one line, aligned to right, and I was looking for what is wrong :)\n. I had the impression that the usage of the published LUA library is the preferred way over compiling LUA into darktable. Actually the first compiles were using the internal LUA, and I was working on getting an old compiled/installed 5.2 LUA version...\n. Where is the -Wshadow disabled? If I remove the -Werror definition from CmakeList.txt, rawspeed gives me these shadow warnings still. I see -Wshadow ignore pragmas in the code elsewehere (like masks.c), but for Rawspeed I could not find.\nAnd I have a few additional shadow warnings I guess beacuse of windows specific declarations, like this:\n/darktable/src/imageio/format/exr.cc:246:14: warning: declaration of 'UINT' shadows a global declaration [-Wshadow]\nUINT = 0,      // unsigned int (32 bit)\nI'll look into them as well.\n. Those are warnings in Rawspeed. Just the -Werror makes them an error. Is it not turning the warning to errors for you? Maybe because of the SOURCE_PACKAGE variable?\n. Copy-paste mistake - fixing it.\n. done\n. The original condition is the following in the /src/CMakeList.txt:\nif(NOT SOURCE_PACKAGE AND NOT APPLE)\n  # apple build fails on deprecated warnings..\n  add_definitions(-Werror)\nendif()\nFor me SOURCE_PACKAGE = 0 , its not an APPLE build, and therefore the condition is evaluated as TRUE, so -Werror is added, and then all warnings turn to an error. Is there anything I'm doing wrong here?\n. OK, I get it now!\n. These headers were not in the original source, and I tried to avoid adding headers which might interfere with the existin Linux or OSX build. Math.hwas needed because of modff, fabsfunctions, and gi18n.h was needed for N_ and _ . Do you think if I removed the conditional that would cause no problem on Linux build?\n. I see - I will update and use as in other places I have seen like DT_GETDELIM_H\n. @houz I have built the flickcurl, and tested the command line flickcurl.exeworks fine, I can access Flickr and photos. However only a static library is built (libflickcurl.a), and no shared library version is being produced (despite I set ./configure --enable-shared). So that results if I switch on USE_FLICKR in the CMakeList file, it compiles nicely, but cannot link :( yet.\n. @houz Managed to compile the flickcurl library with a proper shared library, and it links now properly with darktable . I have pushed that to the MING-packages repository. As soon as they merge it there, I'll commit the darktable changes as well.\n. I have followed your suggestions:\n- reverted back the CMakeLists.txt to the original\n- updated dakrtablerc habdling. Actually it was much simpler than I thought: opening with \"r\" instead of \"rb\" fif the trick. Also saving darktablerc has been updated from \"wb\" to \"w\". On linux there s no difference, but on Windows this was the trick.\n. Should I add explicitely even though its part of -Wall?\n. Done.\n. I know it sounds strange, but in WIN32 its called MAX_PATH. As far as I know there is no cross-platform equivalent: MAX_PATH\n. @LebedevRI : I agree that this piece needs to be reviewed. The change above was merely removing a compiler warning. There are lot of other code pieces which are enclosed in some shape or form in conditional compiles like _WIN32 or __WIN32__or G_OS_WIN32. First I need to unify them using at least the same conditional, and then carefully review all as these code parts, as most likely they were not (fully) tested.\nThe code mbstowcs(filen, filename, len); has been there for a while. I believe even sizeof(filen) / sizeof(wchar_t) would not be OK, as multibyte character set may consist of both one-byte and two-byte characters (see here), so if filename is really a multi-byte string (which I'm not fully convinced), then the best is to get the size is using first a call to determine the size: requiredSize = mbstowcs(NULL, filename, 0);\nThis particular code block is in the function called dt_imageio_open_rawspeed I have also noticed that sibling functions like dt_imageio_open_jpeg or dt_imageio_open_png or dt_imageio_open_exr have no similar conditional code blocks handling MB to WC conversions, so we might need an approach which would work also for all these functions, if filename is indeed a MB string.\n. I guess, my lack of experience.. max() failed, I was not sure it is defined. As far as I understood this part fo the code is using the default keymap file which is the result of the gtk_accel_map_save call. That result is always binary (unix style line endings), the file name is keyboardrc_default. Subsequently the code uses gtk_accel_map_load and gtk_accel_map_save libary functions to process the file. I'm not sure whether those GTK library functions can handle Windows line endings.. Indeed a lot of dependencies were missing. I have added many of them (see next commit), but still: for GraphicsMagick, libgphoto2, gdk-pixbuf, adwaita-icon-theme I need to find a way to install additional files and config files which those libraries are using. Unfortunately I'm not aware of any easy way to install the automatically with the Windows installer, its not so smart like the package managers in unix.. CMake has found saxon9, that's not a problem. However as I see if there is xsltrpocand saxon, cmake script will prefer xsltproc\n```\ncreate config docs\nif(NOT ${Xsltproc_BIN} STREQUAL \"Xsltproc_BIN-NOTFOUND\")\n  add_custom_command(\n    DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/../tools/generate_darktablerc_doc.xsl ${CMAKE_CURRENT_BINARY_DIR}/../data/darktableconfig.dtd ${CMAKE_CURRENT_BINARY_DIR}/../data/darktableconfig.xml\n    OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/darktablerc.html\n    COMMAND ${Xsltproc_BIN} --nonet ${CMAKE_CURRENT_SOURCE_DIR}/../tools/generate_darktablerc_doc.xsl ${CMAKE_CURRENT_BINARY_DIR}/../data/darktableconfig.xml > ${CMAKE_CURRENT_BINARY_DIR}/darktablerc.html\n  )\nelse(NOT ${Xsltproc_BIN} STREQUAL \"Xsltproc_BIN-NOTFOUND\")\n  if(NOT ${Saxon_BIN} STREQUAL \"Saxon_BIN-NOTFOUND\")\n...\n```\nAm I reading it right?. We can remove that limitation. There is no Saxon package (yet) inder Windows MSYS2, therefore Saxon can be installed at this moment only manually. As we have discussed earlier  best is to install Saxon and other manual stuff NOT in a system directory - however then cmakewont find them... What would be the best place to install manually, which would cause the least problem at build time?. I did a thorough check, and altough cmakecan find saxon jars, ultimately I could not make it work (saxon9he and saxon65.jar docbook extensions) xsltproc works though. I'll look at ninja build - so far I have not tried.. So actually @LebedevRI is right. In order to make ninja work custom shell script command needs a bashbefore the script name, plus the few perl script we have (like intltool-merge) needs a perl command before the script name. I guess these changes are not intrusive and would not do any harm on Linux build either.\nSo with a minimal modifications I was able to use the ninja build system as well to compile dt.\nWould you like me to add those changes to this PR?. There was only one warning during genarating ninja files with cmake:\n```\n  Policy CMP0058 is not set: Ninja requires custom command byproducts to be\n  explicit.  Run \"cmake --help-policy CMP0058\" for policy details.  Use the\n  cmake_policy command to set the policy and suppress this warning.\nThis project specifies custom command DEPENDS on files in the build tree\n  that are not specified as the OUTPUT or BYPRODUCTS of any\n  add_custom_command or add_custom_target:\ndata/darktable.desktop.in\n   data/darktableconfig.dtd\n   data/darktableconfig.xml\n``\nI'm not familiar with that part of the build process - should we make some efforts to fix this warning?. So it means thatrbis a good solution until it will be fixed upstream, right?. Hi @houz, yes, that is also working. However the resultingdarktablercfile has now always unix style endings (\\n) upon program exit, I guess because of [this](https://github.com/darktable-org/darktable/blob/master/src/control/conf.h#L272). I don't mind as my editor can handle both line endings, but default Notepad would be challanged. Are you OK with that or should we find a solution?. OK, now I get it. \nStill not clear though the case of DNG files: if we try to open a DNG file,no_preview_fallbackwill be TRUE. \n* is it OK to read the DNG file withgdk_pixbuf_new_from_file_at_size()and **only** the thumbnail reading should be prevented, or\n* both the thumbnail reading **and**gdk_pixbuf_new_from_file_at_size()` call should be blocked for those files?. No, the default just works with the keypad ones, I believe that's the most common to use case, as many keyboard layouts put + and - accessible only with a SHIFT key, ie the US QUERTY keyboard, so using that for a common task like zooming would require an octopus...\nThe good news is that you can redefine these accelerators to simple + and - keys, I gave a try with my German keyboard and it was working (on Gemran keyboard these keys do not require SHIFT). BTW Interestingly when you change a global accelerator it only works if you restart dt?. OK, the latest commit does not call gdk_pixbuf_new_from_file_at_size() for DNG files.\nAs this comment is from 5 years ago, it might be that since then this has been fixed in libtiff(?) - but I cannot test it as I don't have hdr DNG file at hand.. Fair enough, let me change it by default to GDK_KEY_plus and GDK_KEY_minus.. clang gave me a proper error message here (sorry I have not mentioned it above):\nerror: missing sentinel in function call [-Werror,-Wsentinel]\n            files = g_list_append(files, g_build_filename(dirname, xmp_filename));\nThis is the only instance I have found. Interesting that travis' clang did not captured that.. OK. Yes :) You can give a try. To be able to print out later where the user can find the logfile, as its pretty hidden.. I can move it to the end of the usage text, no problem.. Next line is using that logdir\nchar *logfile = g_build_filename(*logdir*, \"darktable-log.txt\", NULL);\nActually I have copied that from here\nYou mean maybe to use only one g_build_filename()?. Indeed. There was no terminal windows when I was launching from command prompt. I have a solution, I'll push it shortly.. This is also done with the latest commit. So I have added the FreeConsole() call to the part when we decide to use log to file, and hence no more console is needed. This results that at startup you see a console window flash for a second, then disappears, and darktable's main window will appear, and only that window will be visible.\nI have tested the following scenarios:\n Launching w/o arguments from command prompt: works, only dt's main window will be visible\n Launching with --help from command prompt: works, you see in the console the usage text\n Launching w/o arguments from explorer by double click: works, only dt's main window will be visible\n I have even tested launching with --help from explorer by creating a shortcut and double click on that: that is rather useless, but it displays only a console window, with a usage text, but then it closes, so not too much point IMHO.. Rookie mistake, sorry. OK, thank you!. OK, makes sense. Let me restructure. The basic question here is: Can we guarantee that the CSS will always provide something? I'm not an expert on that. There were default values for these colors originally, although they were different than the default in the darktable.css:\ndarktable.bauhaus->bg_normal = 0.145098f;\ndarktable.bauhaus->bg_focus = 0.207843f;\ndarktable.bauhaus->text = .792f;\nSo at the end I decided to keep at least some defaults, in case the CSS does not provide. I can remove it easily, let me know.. And I thought gdk_rgba_free() is freeing up the memory which has been allocated earlier. Is that a wrong assumption?. As discussed on IRC, I have removed the default colors, together with the memory allocations. Also corrected two UI elements which were using hard-coded colors: the \"compress history stack\" button, and the darktable label itself is now using @fg_color values.\nFor proper theme handling we need a strategy and additional work, different UI elements are following different ways to use (and sometimes not use) certain style components defined in the CSS file.. ",
    "nijel": "There is also https://github.com/klauspost/rawspeed/pull/162\n. PEF and DNG are attached to https://redmine.darktable.org/issues/11243\n. I've updated the commit and added WB presets as well.\n. It's from camera DNG.\n. This really shouldn't be in this commit, but it fixes color output from the script.\n. This is actually what I've used:\n```\n$ ./tools/dngmeta.sh /tmp/wb/IMGP0768.DNG \nDNG created by : PENTAX K-70 Ver. 1.10 \nDNG Illuminant : 21 (should be 21)\n$ nano -w src/external/adobe_coeff.c\n{ \"PENTAX K-70\", { 53173/65536,-13613/65536,-8351/65536,-28565/65536,84891/65536,9926/65536,-7148/65536,12814/65536,39610/65536 } },\n$ git commit -a -m \"adobe_coeff: RICOH IMAGING COMPANY, LTD. PENTAX K-70 support\" --author \"Michal Cihar nijel@nutt\"\n$ nano -w src/external/rawspeed/data/cameras.xml (mind the tabs)\n<Camera make=\"RICOH IMAGING COMPANY, LTD.  \" model=\"PENTAX K-70        \">\n    <ID make=\"Ricoh\" model=\"PENTAX K-70        \">PENTAX K-70</ID>\n    <CFA width=\"2\" height=\"2\">\n        <Color x=\"0\" y=\"0\">RED</Color>\n        <Color x=\"1\" y=\"0\">GREEN</Color>\n        <Color x=\"0\" y=\"1\">GREEN</Color>\n        <Color x=\"1\" y=\"1\">BLUE</Color>\n    </CFA>\n    <Crop x=\"0\" y=\"0\" width=\"0\" height=\"0\"/>\n    <Sensor black=\"64\" white=\"16319\"/>\n</Camera>\n\nNOTE: The default crop exposes the full sensor including garbage pixels, which need to be visually inspected. (negative width/height values are right/bottom crops, which are preferred)\nNOTE: Sensor black and white levels sometimes vary based on ISO, please run this tool on raws for each of the camera's supported ISOs\n```\n. ",
    "hknaack": "I just stepped over this one.\nApart from that, the comparison of the darktable version around line 495 chokes in my case on the string (\"git\") in my version string (using a current development version). But this doesn't hurt overall functionality.\n. Well, I have a hard time figuring what should be included into darktable, if on the camera support page [1] base curves and color matrices are mentioned. Also, dt-curve-tool.c still recommends to add the preset to iop/basecurve.c and iop/tonecurve.c [2]. This should all be comunicated more clearly.\nIs it a requirement, to separate the white balance PR from the \"new camera support\" or just \"noise profile\" PR or what is the intention? Please shed some light about the workflow, because I am a bit confused.\n[1] https://www.darktable.org/2012/10/whats-involved-with-adding-support-for-new-cameras/\nhttps://github.com/darktable-org/darktable/blob/master/tools/basecurve/dt-curve-tool.c#L1066. OK, moved Whitebalance presets to a separate PR and did noise profiles with recent scripts (dropped images for ISO400-ISO1600, because shots were not enough out of focus).\nEdit: Took a bit longer, but now these changes are in this PR.. > Closing, those do not apply anymore. Seems like the code is somehow broken.\nCould you elaborate a bit more on this? Which code is broken, how can I help? Do I need to profile again?. OK, I did a local rebase and compile failed due to some of my profiles ISO were below 31 and for whatever reason, such ISO values are not supported any more? Well, fine, I can drop those.\nOther than that, it complained about my model string being too long. Yet, with any shorter string, the denoise module will not be able to match my noise profile with my photos.\nSo, I would propose to only adjust my PR to drop the noise profile's ISO values below 31. Is that OK with you?. It seems the model string was checked to be no more than 23 characters, which was the model string length of somebody else's camera. The code actually dealing with those strings doesn't need a length restriction. I just increased it to 32 characters, but that is also just a random value, which might be enough for a long time, or not.. Now that the lower ISO values are no problem any more, I updated this PR to contain the noise profiles for down to ISO 10. I hope there are no more other issues.. The article on wikipedia [1] indicates, that the lowest ISO value for traditional film has been ISO 0.8, and the conversion formula indicates 0 to be the lowest value.\nSo what are the pros and cons for:\n10 as lowest value: works with my camera (+), doesn't cause problems with existing code (probably +), check for sane values (+), additional work if someone has got a camera with lower ISO (-)\n1 as lowest value: works with my camera (+), doesn't cause problems with existing code (probably +), check for sane values (+), most likely nobody will come up with a camera with lower ISO (+)\ndropping this check: works with my camera (+), doesn't cause problems with existing code (probably +), no check for sane values (-), no trouble with new cameras with whatever lowest ISO (+)\nSo, from my perspective, using 1 would be the best choice in the long term.\n[1] https://en.wikipedia.org/wiki/Film_speed. ",
    "AlphaJuliettOmega": "Wow, I was about to start attempting a build on Windows but there's much I didn't know that I'd have to take into account, thank you Peterbud for your hard work.\nI will try my best to contribute when I've caught up, If I can.. ",
    "cullub": "Specifically for the windows BUILD.txt.  I mostly use a mac for DT (sorry, I know - not open source), but I figured I'd go ahead and try going through the build for my PC to see where this is at.  Could we insert at line 13 that you have to run pacman -Syu a few times to download the available package list, and update?  I ran into this problem (hence the question).  \nThat'd be helpful for users/programmers like me who are comfortable programming in C, but not familiar with MSYS2.\nCase in point: Windows 10 x64.. That sounds like it should work fine. Although those paths assume something that didn't happen for my system (I don't know exactly what, but it might be partially because I didn't install msys2 directly in my C drive)\nAlso, the curly-braces on lines 18 and 21 aren't necessary (and, in fact, have to be removed to run the lines). If we could edit those braces out that would also be cool.\nWould it be helpful if I just made a pull request with a working build.txt for me? . Hmm, yes that makes sense.  But before the first build (i.e where I'm at right now :) ) you need to install some stuff that doesn't have to be redone each time.... Maybe there should be a PREBUILD.txt and then a BUILD.sh ... ?\n. Also,  JAVA_HOME (line 57, Windows BUILD.txt) is going to depend on the version of java you have installed. Could we add a comment on that line to that extent?\nAnd @peterbud thanks for updating the build.txt with my previous changes.\nFor whatever reason I'm also getting ': not a valid identifierline 88: export:dashlessprepended to anygit submodule` commands.  It doesn't seem like it's breaking anything; it's just weird. Per this, it sounds like an variable somewhere is misset, but I checked all the the vars I set, and those all look fine.\nUpdate: finished the build, and it's amazing!  TBH I was expecting a bug-ridden functionless program, and while I didn't extensively test it, it honestly seems to work better than the copy of DT on my Mac (!).  Anyway, the error above doesn't seem to be affecting anything.\n. Oh, I just got to the build and found out that lua was missing.  Could we add that to the list on line 17?\nAaand we're missing a dash before target usermanual on line 86. . I just tried the other way around (built installer on 10, installed on 7), and got about the same thing. It seemed to install fine, but when I started it (I tried cmd, as well as double clicking), it showed up in Task Manager, then disappeared. No GUI. I'm not at home right now so I can't test the -d all, but when I started it in cmd it gave no output whatsoever.  If I remember, I'll test it when I get home.\nI don't remember whether I tried the installer on my original machine or just the program itself but it worked there. Maybe some libraries are not getting ported.\nRe something modern: my feelings exactly \ud83d\ude12. 8 is worse though :). \nThe installer works on the Windows 10 machine I built in on, but not on my Windows 7 machine. (Rephrase: the installer works on Windows 7 but not DT itself.)  \n@Lirein 's generic build works on my Windows 10 machine as well (the i7 build didn't work).\n\nOh, and that red circle: there seems to be a bug in the rounded corner for that side - it is mostly rounded, but has a ~2px square jutting out from the corner.\nHis generic build also works on my Windows 7 machine.\n\nMaybe it has to do with compilation flags for CPU optimization...\n. ",
    "Lirein": "Excellent, but here a one bug in librawspeed.\nIn files ip/FileReader.cpp\nLine 66 must support UTF-8 encoding from darktable, to do this write this code:\n```c++\n  int nLenWide = MultiByteToWideChar(CP_UTF8, 0, mFilename,\n        strlen(mFilename), nullptr, 0);\nwchar_t wFilename = (wchar_t)malloc(nLenWide*2+2);\n  if (MultiByteToWideChar(CP_UTF8, 0, mFilename,\n        strlen(mFilename), wFilename, nLenWide) != nLenWide) {\n    free(wFilename);\n    ThrowFIE(\"Could not convert filename %s.\", mFilename);\n  }\nHANDLE file_h;  // File handle\n  file_h = CreateFileW(wFilename, GENERIC_READ, FILE_SHARE_READ, nullptr,\n                      OPEN_EXISTING, FILE_FLAG_SEQUENTIAL_SCAN, nullptr);\n  free(wFilename);\n```\nFileWriter.cpp has this issue too.\nI'll do best to search where is another issue with EXIF reading from non-latin filenames.. Start darktable.exe with -d all switch from cmd shell. Try this version  - https://olgabatalina.ru/dt/darktable-2.3.0-win64-generic.exe (All processors)\nOr this (Xeon and top Core i7 CPU models) - https://olgabatalina.ru/dt/darktable-2.3.0-win64.exe\nThe best way to get debug output is run darktable like this:\ndarktable -d all > debug.log\nOf cource, your Video Driver may has partial support of OpenCL, and darktable crashes, for workaround this run with additional flag:\ndarktable.exe --disable-opencl. The main difference in this versions are compilation flags (native or generic) for CPU optimisations and Multibyte code character sets (see code snippet in my post above).\nSorry for my English.. You answer for this one?\nhttps://olgabatalina.ru/dt/darktable.patch\nhttps://olgabatalina.ru/dt/rawspeed.patch\n. Well, I will remove this brackets. Do you have a code style guide in Wiki or other documentation source?. This boolean state help keep track when left mouse button released, but CTRL key has been pressed, to continue mask creation mode, but don't add any additional points when mouse pointer moves. After the secondary left button pressed - mask points are started to adding. After releasing left button and before pressing - there are two additional points added - with zero line (mask) size.. If there are some other state that we can use to track this kind of event, without breaking current experience - it will be the best to use such state, but I can't find anything for similar action.. ",
    "peci1": "If you'd appreciate more testing on real Windows, I offer one machine with Win 10 and one with Win 7 64 bit (both Intel Core i7).\nFor sure I can test pre-built binaries. If it'd help a lot, I can also try to prepare the build environment on these machines.. ",
    "sbraitbart": "I did commit to the local master as far as I know. I did as you suggested:\ngit checkout master && git reset --hard upstream/master\nthen:\ngit pull\nI resolved the conflict and did:\ngit commit -a\nTo sync my github account I did:\ngit push origin master\nAnd then made the pull request.\nWhere did I go wrong?\n. I did make changes. I will try the git flow again to try and find what went wrong.. I am sorry but I need some help here. I don't know what went wrong but I can't fix the git. I did the following:\nshlomi@avia:~/darktable2/darktable$ git fetch --all -p\nFetching origin\nFetching upstream\nshlomi@avia:~/darktable2/darktable$ git submodule update -f\nshlomi@avia:~/darktable2/darktable$ git checkout master && git reset --hard upstream/master\nAlready on 'master'\nYour branch and 'origin/master' have diverged,\nand have 395 and 6 different commits each, respectively.\n  (use \"git pull\" to merge the remote branch into yours)\nHEAD is now at 11e8cec Merge remote-tracking branch 'upstream/pr/1456'\nshlomi@avia:~/darktable2/darktable$ git pull\nCONFLICT (file/directory): There is a directory with name src/external/rawspeed in 7249eb1ff9f06e6395bbc56b6aa2bed4e920b519. Adding src/external/rawspeed as src/external/rawspeed~HEAD\nAuto-merging po/he.po\nCONFLICT (content): Merge conflict in po/he.po\nAutomatic merge failed; fix conflicts and then commit the result.\nI resolved the he.po file and went on:\nshlomi@avia:~/darktable2/darktable$ git add po/he.po\nshlomi@avia:~/darktable2/darktable$ git commit -m 'git fix'\nU   src/external/rawspeed\nerror: commit is not possible because you have unmerged files.\nhint: Fix them up in the work tree, and then use 'git add/rm '\nhint: as appropriate to mark resolution and make a commit, or use\nhint: 'git commit -a'.\nfatal: Exiting because of an unresolved conflict.\nWhat should I do now?\nThanks\nShlomi. I forced update my origin master and I will update the translation again and initiate a new pull request.. ",
    "patdavid": "Signed in ok. The message on attempting to export:\n\n. ",
    "derknipser": "sorry did something wrong. Ignore the request. Will try to close it.\n. ",
    "itinerarium": "Please ignore the extra commit messages (and please let me know if there is a better way to sync forks?).\nIt appears that in certain circumstances, perhaps, related to timing as someone suggested, (collection->params.query_flags & COLLECTION_QUERY_USE_LIMIT) ? \" \" LIMIT_QUERY : \"\"); in src/common/collection.c will evaluate to not include the LIMIT clause, resulting in the bind error. The code has been revised to check for the number of bind parameters and attempt to bind only when the count is 2 (i.e., the limit and offset values).. Commit history should be cleaner now. Thanks!. Did the most recent commit address the coding style issue?\n. Got it. Will try IRC for this item.\n. As in the number shown in the parentheses not matching sequence position of the selected item (starting from 1)?\n. The error appears to only show up in the lighttable view, but the dumped stmt content using sqlite3_sql appears to be identical in both the lighttable and darkroom views. The sqlite3_expanded_sql function does not appear to be available and there does appear to be two bind targets:\nbind output: SELECT DISTINCT id FROM main.images WHERE   (flags & 256) != 256 AND (flags & 7) == 0 AND ((film_id IN (SELECT id FROM main.film_rolls WHERE folder LIKE '/directory'))) ORDER BY datetime_taken, filename, version LIMIT ?1, ?2\nAny suggestions?\n. What is shown instead/any replication instructions?\n. For localization? Will do.\n. Looking at the console, the errors appears to be consistent, but does not appear to affect the determination of the offset.\n. Looks like the hint message update is being called late/before the state is updated. Will look into it. (Previous testing was using a mouse to navigate.)\n. Should be in the next update to this pull request.\n. Should be in the next update to this pull request.\n. Should be in the next update to this pull request.\n. Should be in the next update to this pull request.\n. Should be in the next update to this pull request.\n. Should be working now. (dt_dev_change_image did not appear to trigger a call to update the hint message and the call was added to dt_dev_change_image, the function that appears to process the actual image load).\n. Removed.\n. Commit: https://github.com/itinerarium/darktable/commit/44119236b984a50892443c4c27c41bd56864cffd. Thanks!. ",
    "beku": "btw. for parsing EDID one can use libXcm  https://github.com/oyranos-cms/libxcm\n. ",
    "arctee": "What remains to be done in your opinion?. Thank you all for helping and reviewing the code.. Thanks for the fast comments to the code. What does DT_MODULE_INTROSPECTION do?. It is definitely a good idea.. It is not an integer division. So I should add .0f.\nOk nice, I'll move the scaling of the parameter in commit_params().. Makes sense to me, also.. Yes, no problem, it can be moved into the LUT.. ",
    "alkhimmikk": "how to remove it? another pull request?. I hope now is ok.. ",
    "porst17": "On macOS, there is no optical difference in the parent windows. Should I guard this with #if defined(__APPLE__) || defined(__MACOSX)?\nBut maybe I just found a better solution that's more in line with the pre Gtk 3.20 approach. I'll report back later today.. The pre-3.20 code path only grabs GDK_KEY_PRESS_MASK | GDK_KEY_RELEASE_MASK and has owner_events set to FALSE. The 3.20+ code path grabs everything and has owner_events set to TRUE. Changing\nc\n  gdk_seat_grab (\n      gdk_display_get_default_seat(gtk_widget_get_display(w)),\n      gtk_widget_get_window(w),\n      GDK_SEAT_CAPABILITY_ALL, FALSE, 0,0,0,0);\nto\nc\n  gdk_seat_grab (\n      gdk_display_get_default_seat(gtk_widget_get_display(w)),\n      gtk_widget_get_window(w),\n      GDK_SEAT_CAPABILITY_KEYBOARD, FALSE, 0,0,0,0);\nshould do something similar to the pre-3.20 approach, i.e. not touching mouse events at all.\nIt works well on macOS, even without making the window modal. I can prepare a proper patch later today or you can add the relevant changes yourself, whatever you prefer.\nI think, this is also why @hanatos ran into issues with https://github.com/darktable-org/darktable/commit/63a4ff165732c82a9cee0a5cb42f424ebb1de5ea#diff-d35332046fb48137f2a7ff0ad2af9792. His 3.20+ port did something else as the pre-3.20 version. He tried to work around it in d4f79bba3409c3b218faedd7deb95b224fb8b4ba, but this broke keyboard support for the popup on macOS.. I'll open a new pull request containing just the new fix, not the modal window workaround.. I actually also checked, if grabbing all events (not just keyboard) in the pre-GtK 3.20 code path leads to the same broken behavior and it turns out it does! Hence, it is really the GTK 3.20+ code path that introduces the bug by doing something different then the pre-GTK 3.20 code path.. Yes, I tested on macOS.\nCould you please add this commit on top of the 2.2.x branch as well? I don't like to use master in production and I am sure, other macOS users will also be happy about this fix once the next 2.2.x release is out.. ",
    "theres": "How about moving brush color out to the darktable.css? It will be easier to customize for end user.. Sure, totally agree. Just indicate some users (me;)) would like to have all color/styles configs in css.. Sure, how about simply sqash and rebase + force push with full description before merge? I like this way quite a bit.. Sure!\n- clang formats on irrelevant lines reverted\n- right click instead of middle one  (why I don't do that in the first place...?)\n- I'll improve commit messages & push with force if you will recognize this PR as merge-capable. . Nop, I just add this that way. I've darken the color and change font weight to make this a bit more visible now. This is however matter of taste how it should look like so I'm open for suggestions. \nBtw. I've some PoC with moving this away to css (with gtk_render_* methods). However code is still far from perfect and I'm not sure if it's the way. . This is why I proposed to make this configurable. In my workflow I very often create new module, not duplicate (I've duplicated maybe one or twice only...). With duplicate it's useless for me, because i still need two clicks instead one to add new instance, so I save nothing ;)\nThis maybe sound a little bit silly why I want to save one click. However this is not the only place where for my common action additional clicks/movements are required, just the first one. This distract me and at the end this make UX a bit less pleasant.\nIn this situation I'd just close this PR and preserve patch for my own ;). I've not found any redmine issue for this. Shoud I create one?. Iteration with pairs will return all key/value pairs (numeric + attributes). ipairs start with 0 and try to retrive element at position greater by 1 until get nil. This is why it try to access out-of-bound element. It would be enough to return nil for key == length+1 and an error for other access - I can do that this way if you want to, I just prefer current behaviour.\nI've removed part of PR with containers children replacement, I'll add this in separate PR.\n. @LebedevRI I hope it's better. @TurboGit Imho yes.\n@boucman could you take a look again? All request should be fulfilled.. Hi @edgardoh, \nI've tested your iop a bit. I missed these functions a lot!\nA few comments from the user point of view to consider:\n- new created shape should remain selected - I need to click once again to eg. change blur radius\n- if shape is selected, user may expected that change sliders will affect given shape - this work for eg. blend factor, but not for current scale -  I need to cut/paste shape - unclear and unproductive\n- I assume that the scale is common parameter for all shapes, so maybe move it to the top - now it looks like each shape can have it's own number of scales.\n- what's happen when current scale > scale?\n- seems that sometimes I need to click current scale once again to see shapes\n- a combobox with all created shapes to select would be a plus\n- I'd consider the possibility of changing the algorithm for the selected shape\n. @TurboGit you can use this eg. for skin retouch (similar method to https://www.youtube.com/watch?v=81yxqfHNElE). @edgardoh \nTwo small bugs reports. \nScenario 1:\n1) select any shape creator (eg. circle)\n2) select clone or healing algorithm\n3) add shape -> two  shape outlines visible, source & destination -> ok\n4) select tool once again\n5) select blur or fill tool\n6) add shape -> two outlines for new shape -> nok.\nif you start with blur/fill and then heal/clone it will result the opposite  behavior.\nScenario 2:\n1) select any shape & algorithm, add shape\n2) cut shape \n3) change current scale\n4) paste shape -> it is moved to new scale, but outline is not visible, you need to do something eg, click on current scale slider or show shapes to see shapes again.\nTwo additional questions:\n1) did you consider/tested other filters - especially bilateral or guided filter? It potentially can give quite good results.\n2) did you consider to extend/equalize histogram of scale preview a bit? For less pronounced features the preview is just gray and it's quite hard  see anything.. @edgardoh thanks! I've tested out the changes, everything works great.\nAbout the contrast slider - I've some idea with the histogram equalization, not sure if it will work. I'll try patch the code and see what's happen as soon as I find a couple of minutes.. @edgardoh yeah, levels seems to be a lot better idea. Auto works just great for almost all of my cases besides problems described below. I've no need for using brightness/contrast sliders anymore.\nI've three problems, The first two of them seems to be related. I'm not sure if any of them is related explicite to your code and can be handled in this MR. \n- for fine scales (up to 2-3 in my case) when my image fits to screen or is zoomed out even more the whole image is grey. But the preview (the one above snapshots) shows some details. Looks like some kind of anti aliasing problem maybe?\n- assume my image is not cropped (fit to screen again) and I press auto levels - it adjust levels parameters. Now, fold left & bottom panels - working area is bigger, image preview also, but shows the same region - whole image. Now when I click auto levels it changes parameters again to the different values, even if it should work on the same, whole image. \n- using markers on levels widget is really crappy. It's near to impossible for me to simply drag & drop. I assume it's problem with GtkDarktableGradientSlider (?).. > I'm not too happy about having 3 sliders, so if levels alone do the job I'll eventually remove the others.\n:+1: \n\nI played with this preview issues a bit more\n\nThe wavelet decompose returns different results depending on the image scale.\n\nthat might be a reason. However, it is a bit suspicious that I see some flickering with quite good scale preview when zooming in/out. Then this disappear in a second and I see gray image again. Same when I fold one of the side panels. The use of brightness/contrast sliders do not fix this in any way. \nMoreover, at scale 3 histogram looks good - is equalized and correspond to what I see (when zoomed in enough to see anything).\nFor scale 2 and 1 histogram shows always single pick, even if there is a lot of contrast.  \n. ok, understood, this seems to be exactly the case. I can definitely live with this also, this IoP do a great job for me. I just found this a bit irritating and I was not sure if it's related to your code or the way DT processing pipe works.\nAnother minor bug report:\n1. add shortcut for any of shape tool eg. brush tool\n2. press shortcut -> tool is selected, I can create a shape, ok\n3. press shortcut again -> tool is deselected partially, i.e. I cannot use tool, but button in the module gui is highlighted. Also, any further press of this shortcut won't work until I change tool or click on the tool button.. It enable tool for the first time, but I'm pretty sure it's not deactivate tool properly. Please press B three times -> first one will activate brush tool for you, the second one should deactivate this tool (it will do this partially, as described before) and the last one will do nothing, when it should activate tool again.  \nPlease see the _add_*_key_accel functions. You invoke code like this:\nC\ngtk_toggle_button_set_active(GTK_TOGGLE_BUTTON(g->bt_*), TRUE);\nat the end of the functions. So this will leave the button in active state after each shortcut release. I believe it should toggle the state just like simple click on the button.\nMoreover, there is a few more funny behaviours:\n- show and edit shapes at current scale enabled -> all current shapes visible -> ok\n- activate any tool (e.g. brush) -> tool is active, shapes are invisible -> ok\n- deactivate tool -> tools is inactive, show and edit.. is enabled,  but shapes are still invisible\nand the second one:\n- show and edit shapes at current scale enabled\n- activate any tool (eg. brush) \n- disable show and edit shapes at current scale -> tool button is active, but tool adding itself is not. Also the show and edit shapes at current scale is disabled. \n. @edgardoh confirm, no issues right now :) :+1: . @edgardoh great change again!\nOne thing I'd want to discuss is how it should behave for styles. Right now, when I modify instance name, save this as a style and then restore on other photo it will replace instance with the same index. To be honest I'm not sure it's something I'd expect. For me more intuitive is to replace instance with the same name, and when there is none, create new one.\nAdditional minor change to consider: hit enter after type name could apply change (i.e. call rename module response callback with response_id == accept).. @edgardoh nice once again!\nI've test it only roughly and I'll do some more testing in next couple of days. It seems to work as I would expect in principle, although issue found by @TurboGit  exists. To be more descriptive: you don't have doubled module if you are on top of history stack. But If you in this scenario select entry  5, you can see that you have two modules xyz and doubled exposure. So this entry seems to be a bit suspicious ;) . Hi, I'd like to put my two cents.\n1. Gimp shows outline of source shape with cross in the middle, I like this a bit more, because cross is not always good visible. \n2. When using brush tool in absolute mode cross stays in the same place while drawing. In Gimp it follows a mouse and return to the initial position after button release - this also is a bit user friendly imho.\n3. It sometimes escape continuous add mode, not sure when, seems like a bug.\nAnyway, I personally like it. Quite useful for skin retouch and spot removal when background is uniform (like sky). Similar to what Gimp and Photoshop do for clone and heal tools. \nFor simple spot removal/heal, I'd love to see something more like in Lightroom - it just tries to automatically find best matching source spot (could be probably realized by something similar to searching in PatchMatch, at least for small spots)  \nPS. module shortcuts do not work well with multiple module instances now, so usage may be limited.. > 3. I cannot duplicate this. The continuous mode is exited with right-click,\nclick on the shapes toolbar or with the shortcuts, maybe you hit some of\nthat by accident?\nMaybe, not sure yet. I've got something like this maybe 3-4 times while testing without clear reason.\n\nI'm not sure I understand, you are saying that shortcuts don't work well\nwith multiple instances in general or just on the retouch module?\n\nIn general. As example, add shortcut for increase exposure in exposure module, then shortcut will always add exposure to the first instance of this module, not to the active one. In retouch on the other hand, if you add shortcut for circle tool, it will add it to the last added instance.. hi @aurelienpierre \nI'm big fan of moving more configuration to CSS. Although there are some opinionated changes I don't like.\n\n8. use a middle-grey background (yes, it's not sexy, but it's good for color perception)\n\nYes, but I'd love to be change this background per-photo, as not all of my walls are middle-grey. Lightroom for example, has simple button that open color chooser. Also, change this in filmstrip in the darkroom is (IMHO) just ugly and what's more important: distracting.\n\nNow, I have removed the icons of the modules in the darkroom.\n\nAgree with @TurboGit  that the problem might be with point 3 (especially in some languages). \nHowever:\n- even now, you can end up with truncated name, you get maybe 2-3 letters?\n- you enlarge all buttons in the module bar - you loose about the same number of letters you get by removing icons. I've never had problem with those buttons, so I hope I'd have chance to bring it back via css. \n- there is always tooltip with full name\n- most important, it gives me a huge speedup in finding proper module (most of modules I use have icons). Adding icon/glyph is not only visual thing, this is quite common technique to improve UX.. > Why do you want to change the background per photo ?\n\nThe surround color suitable with color editing and proofing is well analyzed, and the standard it a light grey (70 %) : https://xritephoto.com/documents/literature/en/StandardViewingNTK_EN.pdf\n\nI'm aware of this, I agree that this is best choice for most cases. But when I know where may photo will hang, I want to compare it against wall color too. Now I'm doing this by using framing module, but It feels like workaround for common case.\n\nrelying on a hover event to get the full label is bad design.\n\nThere is no really good decision here if you have really long label. Experienced user shouldn't have to look at the full name at all except multi instance case. But even then the custom name is what user need. I don't know how this looks in other languages, but even with renaming I've got too long names almost only with denoising modules - the problem is that it hide the center part of the label, so the denoising module type.  With proper* icon I could still distinguish modules easily.\n*not all modules have icons,  that's shame.\n\nThat would have been true if the icon had been on the left of the label. Having it on the right (in left to right languages), it means you have already read the label when your eyes fall on the icon. So this is not a common technique in UI at all (icons are always on the left of the label). \n\nMaybe it's just me, but I read text a lot slower then recognize icon. Moreover, Icons are not part of the text, their are always in the same column, I don\u2019t have to read text at all. Agree that icon on left would be a lot better choice though.  \n\nDoes the lack of icon prevent you from finding modules in the lighttable ?\n\nNo, but it's completely different case for me: there is a lot smaller number of modules, they have fixed order and I cannot hide any of them so the number of them is fixed. I'm using import, export and collections modules 99% of the time. Same for left panel of darkroom.\nIn darkroom IOP modules list however I\u2019ve dynamically change list of modules by presets, I need sometimes to scroll, I can have multiple instances. reading all labels to find out that my module is at the end of list isn't very effective. \n\nBug report:\nthere is problem with instance renaming: you need go to lighttable and back to darkroom to see new name of instance. \n. Hi @aurelienpierre \nPersonally, I almost never use left panel EXIF settings. Contrary, I look at EXIF data on histogram for almost every photo. It show me the most important information and is just a lot more convenient to look at. So big no from my side for this one.\nAbout read-only histogram - I'm not using this quite often, but I do sometimes. Not for real exposure adjustments ofcourse, but to quick see if photo have any potential. It's just faster then look for the exposure (or any other module that allow to adjust exposure). So even if I'm not as super oponent as above, not sure what's the gain here.\nTo the smaller height - I agree this is generally a good idea, but I'd rather try to make it configurable, because for people with bigger screen this might not be an improvement.\n. > The real question is: are the EXIF info useful in the histogram ? My feeling is I don't care about the camera settings at all during retouch. But I really like a clean UI to focus on the picture.\nIn my case I've a few luma noise removal presets that are ISO dependent but  I don't want to apply them automatically (often I've a few for the same ISO). So it's a lot easier to quick look at the histogram to get this info.\nAnother thing is that I mostly shot landscapes and night sky. Often the same composition with slightly different settings. I like to know which one is which when choosing candidates to work on.\nI'm a big fan of making things configurable, so how about setting this text transparency via CSS? That should make happy both sides. \nCheers. > what if we move the exposure settings at the beginning of the EXIF widget ? Even small, this text makes the waveform histogram practically impossible to read in many cases.\nThe key feature is to have this in the same place as @rawfiner pointed out. Not necessary over the histogram. EXIF panel is pushed down by all panels above and change position every time user do any photo manipulation. Moreover, I prefer to have open history stack and mask manager and even on my 4K 42\" display, when exif panel is open, I need to scroll the left panel. So I simply keep this panel closed.\nHowever, it's quite easy to add custom Lua plugin to show the value eg. above the photo. So even if I like these values over histogram, I've workaround that do not require to maintain fork to bring this feature back... > And hey, what exactly can I do with the vim commands\nUnfortunately nothing interesting now. You can quit darktable with :q. I had an idea to make this extendable via LUA (just like in vimscript), but time.... done. I think it's more consistent with regular lua behaviour - you can for example use ipair just like in regular table.\nAnd this is the part of commit message for this:\n\ncombobox fix: for with ipairs over combobox widget cause an error\n\nHowever, I'll change this to be more accurate.. The old code doesn't work for me (see example file I prepared) - I just got nil instead lua_widget. But I'll check this once again.. and the same answer :) \nEven more, the old code for container doesn't raise an error, so behaviour of container and combobox was a bit inconsistent.. Ok, so you are totally right, my code is working just by accident. I've found the problem: https://github.com/darktable-org/darktable/commit/0edd2f429b905e86ce5dbc6cbd3db1beea5d4c1f\nYou've changed child_added/child_remove handlers to setting: \ncontainer->uservalue[lua_widget] = lua_widget;\nso the container->uservalue[searched_widget] return nil. . I'm pretty sure it's not functionnaly equivalent. Here we use raw gtk_widget instead of lua_widget as a key in uservalue. So as a result container uservalue contains mapping gtk_widget -> lua_widget. At the end we can easly look up for child lua_widget by gtk searched_widget, i.e. return container->user_value[searched_widget]\n See the end of container_numindex function\nc\n static int container_numindex(lua_State*L)\n {\n//...\n   } else {\n     GtkWidget *searched_widget = g_list_nth_data(children,index);\n     g_list_free(children);\n     lua_getuservalue(L,1);\n     lua_pushlightuserdata(L,searched_widget);\n     lua_gettable(L,-2);\n     return 1;\n   }\n} \nSo this is just a fix of the regression introduced by 0edd2f429b905e86ce5dbc6cbd3db1beea5d4c1f, I'm open to fix this other way if you have another proposition.. ",
    "catlee": "How do I get to that dialog from the UI?. Yeah, it makes sense to make the return value of this function clearer. I'll rework the patch.. Huh, I think cancelling this dialog is broken already. If I select an image and press Shift-Ctrl-C, and then click Cancel, and then select another image and press Ctrl-V, the stack from the initial image is copied.. ",
    "shoffmeister": "Just a random note: \nc\n    if(dt_gui_hist_dialog_new(&(strip->dg), strip->history_copy_imgid, TRUE) == GTK_RESPONSE_CANCEL)\n      return FALSE;\nis not a good pattern in general for a call site. The better approach for these dialogs is to monitor strictly for only the \"positive\" items, e.g.\nc\n    if(dt_gui_hist_dialog_new(&(strip->dg), strip->history_copy_imgid, TRUE) == GTK_RESPONSE_OK)\n      return TRUE;\nThis pattern is much more robust towards change such as introducing handling of the Esc key. I personally would be tempted to (also) rewrite that specific call site to\n```c\n  gboolean result = FALSE;\nif(_lib_filmstrip_copy_history_key_accel_callback(accel_group, aceeleratable, keyval, modifier, data))\n  {\n    dt_lib_filmstrip_t strip = (dt_lib_filmstrip_t )data;\n    if(dt_gui_hist_dialog_new(&(strip->dg), strip->history_copy_imgid, TRUE) == GTK_RESPONSE_OK)\n      result = TRUE;\n  }\nreturn result;\n```\nbut that then is a matter of personal preference, too (and it consumes sizeof(gboolean) on the stack).. I have been watching @LebedevRI diligently chopping away stack usage ;) (Granted, he converted from stack to heap)\nThe compiler cannot optimize the gboolean away, because of the call, with C calling convention; IIRC, C calling convention on Linux does not make any guarantees on the state of registers on return, so the gboolean would have to be pushed before invocation. But my memory is ... what was the word again? (Yeah, and it's an academic discussion). Two remarks:\n wouldn't it be helpful to move the URL into a configuration file, such that changes in a URL do not require a full redeployment?\n CURLOPT_REDIR_PROTOCOLS could be useful for setting up curl (because that would take care of the 301). Worse. Potential buffer overflow iff len > MAX_PATH.\nSo mbstowcs(filen, filename, MAX_PATH); because sizeof(filen) / sizeof(wchar_t) == MAX_PATH.\n. - actviate\n+ activate. ",
    "advancingu": "@TurboGit Both mentioned commits have been merged some time ago. Would you be able to look at this issue again? Changing curve values still causes non-atomic undos in 2.4.2 for me.. @TurboGit What do you mean? The merge conflicts could be resolved and the patch merged (assuming it fixes the undo issue).. ",
    "rabauke": "I dropped changes from *.po files. I hope the pull request can be merged now.. Dear Roman,\n\nSo it is done in camera rgb colorspace.\nCan it be done in Lab?\n\nthis I also asked myself.  But I cannot answer this question \nconclusively though I am not a expert in color spaces.\nAt the moment I would argue that RGB color space is most appropriate for \nthe particular algorithm.  Haze is detected by looking for regions with \na color spectrum that has at least some intensity in the red, green as \nwell as the blue channel.  Colorful non hazy regions are usually dark in \nat lest one of the three RGB color channels.\nHeiko\n\n. Dear Ulrich,\n\nPlease consider to use variable names |width| and |height| rather than\n|N0| and |N1|. We use the former ones throughout the code in darktable.\n\nI renamed the variables and also consolidated everything into a single \ncommit.\nHeiko\n\n. @upegelow Indeed the modules uses some temporary memory. I estimated the amount of temporary storage for a 30 mega pixel image to about 2GB. In my opinion this is not an mayor issue considering todays hardware. Nevertheless, I can understand your concerns. \nHow does tiled image processing work in detail? To avoid artifacts I will have to process overlapping (input) tiles. What happens, when I set overlap>0 in the tiling_callback()? Will the sizes of the input and output regions of interest that are processed in the process function differ by (twice of) this amount?\nHeiko. The (current implementation of the) haze removal module uses temporary storage of about 6 times the size of the input image. I would still call this a moderate memory footprint. Considering the typical pixel count of modern digital cameras and the memory size of current desktop computers and laptops this is really not a problem. \nNevertheless, I also agree with the opinion that darktable should be able to deal also with the exceptional cases of very large images as best as possible. Thus, I implemented the tiling_callback. However, the tiling mechanism of darktable and the hazeremoval module do not play nicely together. The problem is that the algorithm has to estimate the global background light from the whole image first. This can only be done reliably in the pipeline PREVIEW (or in EXPORT without tiling). Thus this quantity is determined in the PREVIEW pipeline and stored in the gui data for later use in the FULL pipeiline. (I adapted this mechanism from the globaltonemapping module.) This, however, does not work in the EXPORT pipeline because it does not have access to the gui data. Consequently, the global background light is computed for every tile yielding different estimates of this quantity in each tile resulting in strong blocking artifacts in the exported image. With tiling enabled I was not able to find a way to determine the global background light in the EXPORT pipeline.\nAt the moment I think the only possible solution to reduce the memory footprint is to implement a tiling algorithm within the process function.\nHeiko\n. >     temporary storage of about 6 times the size of the input image.\n\nThat is HUGE. Even the equalizer may be sometimes less hungry.\nThe problem is that the algorithm has to estimate the global\nbackground light from the whole image first.\n\nDoes it need all that memory to /estimate/ the value, or the memory is\nonly needed later on to process?\n\nThe huge amount of temporary memory is required only in later process. \nTemporary memory for estimating the global background light is one float \nper pixel.\n\n(I adapted this mechanism from the globaltonemapping module.)\n\nColorreconstruction / ashift is probably a much better, modern example.\n\nI will also have a look at these modules.\n\nThis, however, does not work in the EXPORT pipeline because it does\nnot have access to the gui data.\n\nSome time ago i played with the idea of adding a |sample()| callback,\nwhich would be run before the |process()|, and with the full input\nbuffer. As long as the sampling itself is not too memory-hungry, that\nwould be the solution. I never finished that code though.\n\nAs a quick solution, I will implement a process_tiling callback.\nHeiko\n. I have rewritten the hazeremoval module. It consumes much less temporary memory now. It requires\n2 * sizeof(float) * number_of_pixel bytes of temporary memory  plus 17 MB per OpenMP-Thread. Thus it is now able to deal with very large images, too. I hope the module is acceptable for integration into darktable with these improvements. Heiko. Since I published the revised version of the hazeremoval module with reduced memory consumption I got not further response. Apparently there has also not been any attempt to merge the module into the official darktable source. Therefore, I wonder is there still any technical issue that needs to be resolved first or is there really no interest in a haze removal tool? \nI have written this module mainly because I saw a need for my editings and it has proven to be useful for me. (The results that one gets look very similar to those that the haze removal tool in Affinity Photo yields, see this video. Though, I do not know which algorithm Affinity Photo uses, it might be a different one.) If the darktable community has another point of view I will just continue to build my own patched version of darktable to suit my needs. But I would love to see the darktable module in darktable officially and I would be surprised if other darktable users have not need for such thing.\nRegards, Heiko\n. @upegelow : I completely agree with your thoughts and suggestions. Originally, the threshold parameter was just introduced to avoid possible artifacts in very hazy image regions and it should be close to zero when one wants to remove as much haze as possible. However, I realized that the threshold parameter can be translated into some more intuitive distance parameter by a nonlinear transformation. Thus, I replaced the threshold parameter by this distance parameter. It can be understood as follows: If this parameter is less than 1, then only the haze in the foreground of the image is removed. If it is zero, no haze is removed at all. The effect of the new distance is best seen in images with almost no haze in the foreground, more haze in the background and a smooth increase of haze in between.\nWhen applying the hazeremoval module, one has to tune the parameters such that the haze is eliminated as much as possible, while the image still keeps a natural look. These optimal parameters are quite image dependent. However, I have chosen some more conservative default values now.\nFurthermore, I doubt that one can get similar good results by applying a combination of tone curve and some black point correction and other modules, at least not without very sophisticated masking. However, other modules (especially the equalizer, tone curve and black point correction) are valuable to improve the image further after the hazeremoval module has been applied.. > I suggest to move the descriptive part of the module code higher up in\n\nhazeremoval.c.\n\nI have moved this part to the top of the file to make the source code \nmore accessible to other developers.\nHeiko\n. > process_tiling(): not sure why this function is there in the first\n\nplace. As far as I understand you anyhow apply a tiling mechanism in\nprocess() to reduce memory overhead. Therefore process_tiling() is not\nneeded and should be removed.\n\nI removed process_tiling() as well as tiling_callback().  I agree \nthey are not necessary because  process() implements its own tiling \nmechanism.\nHeiko\n. > About pixelpipe synchronization. We already talked about that. Meanwhile\n\na working principle has been implemented and haze removal should apply\nthe same mechanism. Take the code in global tonemap as a reference.\n\nI revised the code for pixelpipe synchronization following the global \ntonemap module.\nHeiko\n. I rebased the pr. Furthermore, I realized that there was an issue in the tiled processing that might lead to artifacts due to the tiled processing. Although I have never actually observed such artifacts, this has been fixed now.. I applied clang-format as requested to format according to darktable standards.\nHeiko. @upegelow I would highly appreciate if you care for the screenshot. Not only the font also the icons look slightly smaller on my system compared to the screenshots in the rest of the documentation.\nI slightly updated the documentation. I contains the following statement: Setting both controls to unity maximizes the amount of haze removal but this is also likely to produce some artifacts. Removing the atmospheric light entirely may render the image flat and may result in an unnatural looking style. Optimal values are typically slightly below unity and are rather image dependent but are also a matter of personal aesthetic preferences. I think this should be warning enough. The former version did contain a similar but weaker wording.\nHeiko. @upegelow As I already wrote, it is also a matter of personal aesthetic preferences. Nevertheless, I think the word slightly may be inappropriate here. It has been removed.\nHeiko. According to https://www.shellcheck.net the $(...) syntax for command substitution should be supported by every POSIX compatible shell. However, there are subtle differences between the back-quotes syntax and the $(...) syntax, see http://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html\nHere strings and the <<< syntax are not defined in the POSIX standard. \nThus, the proposed changes will break/reduce POSIX compatibility. In particular, proposed changes render the script incompatible with the dash shell, which is the default shell on Debian and Ubuntu. Note that  https://www.shellcheck.net hints to further issues, which are also present in the original script.. Dear Roman,\n\nYes but. What is the actual problem?\nAre there color charts with such random order? From where does this unsorted problem comes from?\n\nI came across this problem (and was not aware of this particular required ordering) when I used darktable-chart with csv files (as input) which have not been generated by darktable-chart. The option to feed directly LAB color values to darktable-chart via csv files allows to use this tool beyond creating styles out of pairs of images such as RAW+JPEG with in-camera processing.  E. g., this is extremely useful go generate color looks/color gradings. Furthermore, color checker with a more general ordering of gray patches exist. The Video ColorChecker Passport by Xrite has two rows of grays, one with a gray scale ramp through the middle section of the tonal scale, one with shadows and highlighs.\n\nI would guess it is a precausion against clipped colors that would throw off the fit, but then i don't know the real reasons..\n\nMany color checkers have only 6 gray patches. I do not think that it is a good idea to discard one third of them when building the tonecurve (without knowing that these will cause problems). If there is actually a good reason to do so, I would be curious to learn why.\nHeiko\n.  > This broke |./tools/create_release.sh| and who knows what else.\nCan you be more verbose, please.   What is precisely broken?  I\nevaluated the pull request.  Line 17 looks suspicious.  Does\ndt_decoration=$(git describe --tags \"$branch\"| sed -e 's,^release-,,;s,-,+,;s,-,~,;' -e 's/rc/~rc/')\nfix the problem?\nHeiko\n. No review for this trivial patch?. @LebedevRI : I do not think that the suggested text \nset the camera specific black level %i of the RGGB Bayer pattern\nimplies that there would be a specific mapping between the sliders 1 to 4 to particular pixels of the RGGB pattern. It just implies that there is a mapping of the sliders 1 to 4 to particular pixels of the RGGB pattern, which is not specified. In order to avoid the false impression of a particular mapping, one might change the tooltip text to \nset one camera specific black level of the RGGB Bayer pattern\nWhat do you suggest?. @LebedevRI : I do not think that it is necessary (or even possible) to describe the pattern shown in your table in a tooltip text. This might be, however, an issue for the user manual. Regarding the tooltips, I still think we should be more specific here. Considering that Bayer patterns are not used exclusively, a suitable text might be\nset one camera specific black level of the camera sensor pattern\nBtw: The user manual gives the impression that the module would work with Bayer patterns only.\n. Although I find the current tooltip text unsatisfactory, I agree. It's difficult to come up with a better text for the tooltips. I am going to remove the PR until I have an idea for a more useful description.. Actually, the math should not change. This PR is mainly about performance.. I updated the pull request to solve conflicts.. Regarding the constant 3/8 see https://en.wikipedia.org/wiki/Anscombe_transform and reference [1] therein.. I revised my PR to fix the following UI bug: Exposure step and exposure bias sliders are not always hidden when exposure fusion is turned off, e.g., when a new module instance is created. This bug is fixed in the function gui_init.. I have tried to remove pure formatting changes as much as possible.. Thanks for reviewing.. > When I saw this I said why not! But I'm wondering if we want to introduce some random/artistic effects like this we could have lot and lot of IOP at the end. So I'm wondering if we don't want to have a generic effect like IOP and a combobox to select the effect. Not sure, just starting a discussion in this direction. What would be the pros and the cons?\nI have done something into this direction by writing a GMIC module for darktable. It implements some selected GMIC filters for darktable (see my posts on the mailing list). I like this extension very much and use it often. However, there is a major problem with such a multi-effects-filter module. The module has a specific place in the pixel pipeline. There are always some effect-filters for which this is not the appropriate place.\nRegarding the freaky BW filter: I am unsure if one should include it into darktable as it has a more artistic character. Furthermore, I would expect problems in the preview, in particular when the preview shows only parts of the image as the module utilizes a DFT, which in a non-local operation.. The algorithm is described in detail in the references given in the sources, see also http://kaiminghe.com/eccv10/index.html\nThe suggested mask filtering is based on a so-called guided filter, which is also employed in the haze removal module. More testing and feedback would be highly appreciated.. > @rabauke : and what about the feathered mode which seems not working with parametric masks? Can you describe the way to use it?\nThere was an issue in the OpenCL code path. Now it works also with parametric masks (and OpenCL).. > @rabauke I'm not sure the sliders labels are super clear there. I would to go for:\n\n* mask edge detection radius\n\n* mask edge offset\n\n* mask edge contrast\n\n\nI agree, the meaning of the sliders may not be obvious to the user. Basically a tone curve is applied to the mask, which is now explained in the revised tool tips. Note that this mask tone curve is completely unrelated to the edge-sensitive feathering algorithm. Thus I would not mention the word edge here. \n@TurboGit One might consider to add further parameters, e.g. white and black points, to adjust the tone curve, giving even more flexibility but also cluttering the UI.. @turbogit Issues have already been solved, the rawspeed issue will be fixed soon.. @TurboGit : There have not been any recent parameter changes. Do you have any specific in mind. Furthermore, I removed the rawspeed sources from the pull request. It was not intended to include any rawspeed stuff. . > @rabauke : my question was more to ensure that the current implementation does not break history and that the default behavior without the two new sliders is 100% equal to the current implementation. \nIt was always my aim not to break history when implementing this new feature. It's crucial indeed.\n. @moy Thanks for the bug report. Can reproduce the behavior. Will fix it as soon as possible. . Also the module has its roots in a program called filmic (as far as I understand) I would prefere to give the module a more significant name which gives the user a hint what the module is good for. What about tone equalizer?. > This does not compile:\n\n...darktable/src/develop/blend.c: In function \u2018dt_develop_blend_process\u2019:\n...darktable/src/develop/blend.c:3005:11: error: \u2018guide\u2019 not specified in enclosing \u2018parallel\u2019\n           memcpy(guide + oindex, (float *)ivoid + iindex, sizeof(*guide) * owidth * ch);\n           ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n...darktable/src/develop/blend.c:2999:9: error: enclosing \u2018parallel\u2019\n #pragma omp parallel for default(none)\n\n@TurboGit  Thanks for the hint. Has been fixed now. Because of the default(none) declaration I am surprised that it did compile before with any compiler before.\n. @TurboGit Side note: I plan to implement also two other modifications: \n\nInstead of applying either the guided filter or the Gaussian blur filter to the mask it should be possible to apply both.\nThe user should be able to choose the input image or the module's output as a guide.\n\n. @TurboGit  I have also included the mentioned modifications now into this PR.. @TurboGit This order has been chosen intentionally. Feathering comes first in the mask refinement, Gaussian blur afterwards. This is to match typical workflows which involve both kinds of mask adjustments. Feathering may yield masks with too hard edges, which may be smoothed by the Gaussian filter.. I created fresh installations of darktale 2.4.4 and current git master (commit 0515f4cc8eb4f5184135665d09702e13027101ba). I did some very simple edits involving drawn masks in dt 2.4.4. No problems opening these in current git master. Hope problem has been fixed now. Please report if problem pops up again and describe which versions have been used.. @DottieUnderwood  Thanks for your contribution! Minor refinement of our great suggestion (untested):\n```\nif(old_version == 1 && new_version == 8)\n  {\n    / he he /\n    if(length != sizeof(dt_develop_blend_params8a_t)) return 1;\ndt_develop_blend_params8a_t *o = (dt_develop_blend_params8a_t *)old_params;\ndt_develop_blend_params_t *n = (dt_develop_blend_params_t *)new_params;\ndt_develop_blend_params_t *d = (dt_develop_blend_params_t *)module->default_blendop_params;\n\n*n = *d; // start with a fresh copy of default parameters\nn->mask_mode = o->mask_mode;\nn->blend_mode = o->blend_mode;\nn->opacity = o->opacity;\nn->mask_combine = o->mask_combine;\nn->mask_id = o->mask_id;\nif (o->mask_blur_mode==1) {\n   n->blur_radius = o->radius;\n   n->feathering_radius = 0;\n} else {\n   n->blur_radius = 0;\n   n->feathering_radius = o->radius;\n}\nn->blendif = o->blendif;\nn->brightness = o->brightness;\nn->contrast = o->contrast;\nmemcpy(n->blendif_parameters, o->blendif_parameters, 4 * DEVELOP_BLENDIF_SIZE * sizeof(float));\nreturn 0;\n\n}\n```\n. I am going to draft some documentation, possibly I will try mackmd. (Never heard of that before.) Please also consider https://github.com/darktable-org/darktable/pull/1674 . > We could have:\n\n* mask tool (combo with blur, full)\n\n\nI agree that the UI has become quite a lot of options and (new) users might be overwhelmed by the possibilities. I am not sure if an additional combo box would be the solution. Possibly a step forward. Where would one maintain the value of the toggle box. Would this be an additional blend parameter? Is just a parameter that modifies the appearance of the UI, thus one might store this information somewhere else.. @upegelow Comments, corrections or any other suggestions are always welcome but I can't see any.. @upegelow Thanks for your suggestions, which I have tried to incorporate into my revised version.. Note that the variable d is always non-negative, see line of code before. No need to double check. The zero argument case is also well defined, even on Windows, see https://docs.microsoft.com/en-us/cpp/c-runtime-library/reference/sqrt-sqrtf-sqrtl?view=vs-2017 A sqrt function that is undefined for zero should be considered seriously broken.. Requested changes applied, plus some further minor fixes.. I have reduced changes to a minimum to fix the bug in the convergence check and to exclude refactoring work. I will open a further pull request for refactoring as soon as this has been merged.. I agree CMAKE_SIZEOF_VOID_P might be a better solution if cmake is employed. Will update the patch.. I revised my pull request to employ CMAKE_SIZEOF_VOID_P to set up config.h.. @TurboGit Which question? I am willing to improve the patch, but currently I have no clue where there might be a problem.. Currently, the code in darktable.c checks at run-time if the program runs on a 32-bit architecture or on a 64-bit architecture. Depending on this check different code paths are taken. This mean that there is some dead code path that will never be taken depending on the architecture. My patch excludes these dead code paths by a compile-time check.\nA good optimizer might remove unreachable code paths. Nevertheless, I think one should avoid unreachable code.\nIf only 64-bit architectures are currently supported, I would prefer to remove the code 32-bit specific code completely.\n. I removed the 32bit code path.. I also removed the code mentioned by @moy . I have not yet implemented a compile-time check to prevent building for 32-bit platforms, although I have considered this before. I am aware of at least one Linux distro (Mageia), which ships DT 2.6.0 for i586. Nevertheless, I would not hesitate to do so if there I a consensus to push users and distros harder into the direction of 64 bit.. I removed the const specifier.. Oh, I missed this. Has been fixed too now.. Looks good. Some minor issues:\n\nThe format string of size_t is \"%zu\", afaik.\nI would like to suggest to squeeze all commits into a single one, see git rebase.\nI would also remove all the casts of the return values of the memory allocation functinons. These cast are K&R C style and not required in ANSI C (but in C++, albeit for a different reason).. I see no reason to declare the inline functions as static..  @markfeit Regarding the inline functions: I thought the static specifier might be omitted because I am more conversant with C++, where inline has a slightly different meaning. After reading the corresponding sections in the C99 standard, I agree, however. Declaring the inline functions as static inline is a good idea. (Although, I think, the rationale is a bit different from your explanation.)\n\n. Added const qualifiers, applied some further clean-up, fixed a memory leak in _string_escape.. I downloaded sources from https://github.com/phweyland/darktable today and compiled the lut3d branch. The new module does not work for me. Essentially I get pictures with more or less random colors (mainly black), no matter which options (color space, etc.) are chosen. I employed some *.cube files, which work fine in Gmic. See https://www.rocketstock.com/free-after-effects-templates/35-free-luts-for-color-grading-videos/\n. Also random colors with PNG-luts from http://gmic.eu/color_presets/index.shtml .. Is the LUT included into to xmp file? What happens if LUT file is removed? Becomes the xmp file unusable?. @phweyland I was able to get the module working, at least with hald cluts given by a PNG file. The problem was that your implementation of calculate_clut_haldclut assumes that the PNG file has 8 bit bit-depth. A PNG file, however, might have a bit-depth of 1, 2, 4, 8 or 16 bits. Here a quick fix: fix.txt\nI assume there is also an issue with reading cube files, which still does not work on my Linux system.. strtod might be a problem. It assumes/requires that the float is given as specified by the current locale. The representation in the lut file is, however, fix, eg. uses a decimal \u201c.\u201d rather than a \u201c,\u201d as required by my German locale. sscanf might be more appropriate here.. I can confirm that cube luts work as expected as soon as I switch to the \"C\" locale, which uses decimal points rather than decimal commas as the German locale which is the default on my system. As parafin mentioned, we  have to come up with our own implementation of an atof-like functions because all string conversion functions of the C library are locale sensitive.\n. Here another locale-agnostic implementation of atof for parsing floating point numbers. Unlike the C standard implementation it does not recognize numbers in hexadecimal format. (Just an ad hoc implementation, with some basic testing.)\natof.txt\n. @phweyland What kind of editor or IDE do you use? Some editors can be configured to remove spaces at the end of each line when the file is saved. Look into the configuration of your editor and turn this behavior off or switch temporarily to another editor, preferably a dumb one.. Ok, this simplifies the code of course. I will apply this change.. MIN()/MAX() macros are not defined at any place of the darktable sources nor by the C programming language. Save implementations without possible undesirable side effects of these macros are only possible by using some compiler specific extensions. Relying on the existence of MIN()/MAX() macros make code not portable and potentially harmful.. I am not aware of such function. . According to the rules of the OpenMP standard these variables are shared no matter if the data-sharing attribute is explicitly given or not. See Sec. 2.15.1.1 of the OpenMP 4.5 Standard. Here, the data-sharing attribute shared(img1, img2, w) is mainly a hint to the programmer, who reads the code. If desired I can remove these redundant data-sharing attributes.. Ok, done.. I did not give explicit schedule modifiers in order to give more freedom to the compiler for optimizations. For very simple for loops, however, a static schedule is likely to give best results. Thus, I added schedule(static).. Ok, I replaced array of three by thee scalars to conform with OpenMP 3.1.. Ok, done.. Ok, fixed.. Pardon?. Ok, fixed.. Ok, fixed.. Ok, fixed.. It was mainly meant as a hint to the reader of the source code. Without the default(none), the shared would be redundant. I can, however, not add default(none) as requested and remove the shared declaration.. Note that the shared declaration is not (only) about writing to a variable. As I already noted the variables img1, img2 and w will also be declared shared implicitly when the shared declaration is removed.. The variable i is already of type size_t. No cast required.. Ok, done.. I can remove this cast, no problem. I my opinion, however, this is not a brilliant idea. self->parameter is of type dt_iop_params_t *. Removing the cast in the code above is only valid because dt_iop_params_t is actually a typedef for void. I think, one should treat dt_iop_params_t as an opaque type and not rely on some implementation details of this type. Otherwise, the additional layer of abstraction that is gained by introducing the type dt_iop_params_t is immediately lost. A possible future change in the implementation of dt_iop_params_t will break the code if the explicit pointer cast is removed.. As darktable is written in C99, I replaced min/max functions for floats by fminf and fmaxf. However, I would prefer to use hand crafted inline functions for integers, rather than macros, in order to avoid double-evaluation of macro arguments.. I agree, declaring these variables as constant is a better approach. Thus, I declared all variables as const that are only read in a parallel region. This saves us from shared declarations and signals that there is no competing (write) access to these variables.. This implementation of the comparison function is more easy to read, indeed.. ... but this is not valid C. A type cast needs to be applied before dereferencing the pointers.. Both variants will do the job. Personally I would prefer the 1st one. Function pointer casts are difficult to read (for some people).. I am unsure if I understand your comment. Please increase verbosity level.. I configured git-clang-format and revised the code. It should comply with the darktable coding style now.. Both algorithms have asymptotically the same complexity. Furthermore, the system that has be solved here has about a few dozen unknowns. Such a system can be solved in less than 1ms on recent CPUs. But I must say that I did not perform any explicit benchmarks. \nI tested, however, several numerical algorithms for the particular kind of linear equations that appear in the color lookup module and the Gaussian elimination turned out to be quite stable. Although one can construct particular problems where Gaussian elimination fails spectacularly, it is quite stable in many real world problems. The advantage of the SVD approach is not so much its numerical stability. Rather, it allows to decide if the linear system has no or several solution if the coefficient matrix is singular, see \u00bbNumerical Recipes\u00ab for details.. Changing the kernel function by some non-zero factor just causes a change of the expansion coefficients (solutions of the linear system) by the inverse of this factor. Thus, it is completely irrelevant. The additional factor of two saves us the calculation of a square root and a multiplication if the kernel is implemented as  r2 * ln(r2), where r2 is the given square of r.. I completely agree, we should keep this reference. I will fix this soon.. Fixed.. Revised code to employ image->flags.. I wonder if this additional explanation is too technical. Why not just:\nThe description of the image. Note: some cameras allow to write write user-specified text to the picture's metadata. When images are imported to darktabe, the image description is read from the exif data if present.\nor something similar?. I think mentioning Exif.Photo.UserComment will provide a useful information for some users and is well justified. However, exif field 0x9286 a.k.a. 37510 or \"User Comment\" (\"Exif.Photo.UserComment\" as per exif2) is a kind of wording that I would expect to find in a developer's manual rather than in a user manual.. I would like to suggest to rename the functions  _zoom_preset_1 to _zoom_preset_3 to something more significant, e.g., _zoom_preset_100percent and so on.. This long chain of if-else-if statements may be replaced by a case statement.. I reformulated the code slightly and added some comments to clarify the rather tricky index arithmetic.. The variable var_H is negative in the else of if(var_H > 0.0f). Therefore, 1.0f - fabs(var_H)/ (2.0f * M_PI) is equivalent to 1.0f + var_H / (2.0f * M_PI) in this particular context.. Although, the macro M_PI_F is commonly used in the darktable OpenCL sources. It is not defined in any C source file. Note that not even M_PI is defined by any standard C header.\nPossibly, one should add a new header file to the darktable sources, which defines new macros as DT_M_PI, DT_M_PI_F etc. for single and double precision representations of common mathematical constants. . I replaced the numerical value 3.141592654f by the new macro DT_M_PI_F, which has been defined in the new header common/math.h and may be useful in other source code files as well.. This has been fixed too, now.. Reformatting is a result of clang-format, which has reformatted the code according to the darktable formatting style. I was required to integrate clang-format into git by the darktable developers in the past. I have not applied these reformatting by hand.. Possibly the effects group is more appropriate.. I wonder, if this is the right place in the pixel pipe. Isn't this too early? I had expect to find it much later, e.g., after the 'monochrome' module, in particular after exposure and basecurve.. No. Probably something went wrong during merge. The pull request should only contain the additional paragraph and the corresponding figures but not touch other sections. This will be corrected asap. . Merge error/conflict should have been fixed now.. I revised my edit. The semantics of the code should not change now by the PR.. A soft bound is a reasonable option for the feathering radius. Note that all arguments for a feathering radius soft bound also apply to the gaussian blur radius. For consistency both parameters should be treated in the same way.\nIn order not to break old edits, I would suggest the following bound:\nmax(250, round_to_multiples_of_50 (0.1 * image diagonal))\nand similarly for the Gaussian blur radius:\nmax(100, round_to_multiples_of_50 (0.1 * image diagonal))\n. Hitch with the soft bound approach: A particular value for a freathering/blur radius may become out-of-bound by resizing (shrinking) the image in an editing step that comes later in the history stack. Possibly the image diagonal of the imported image (the size after demosaic) should be taken as a reference.. @TurboGit : Thanks for the clarification about the soft bound sliders. Please ignore my last comment as it is based on a misunderstanding.. Here is the bug-fix.. Here we had a problem, was always false without fix above.. ",
    "codingdave": "@LebedevRI I will reset --hard to origin/master in the evening, replay my work on top of it and do a second pr. Would that solve the issue?. - Overflow situation improved\n- more easy to read by coding with clear intention\n- comments where needed\n- The code is working again\nIn contrast to https://gist.github.com/LebedevRI/99d6d9753f2f02e5937fbea663307a45 the code has the idea to walk along the complete string with 2 pointers: char* string is always pointing to the next subtoken in the input string as input for the function. From here \"( and ) are being looked for. The position after ) needs to be the return value of the function because it will be string input for the next iterative function call. The range including $( and ) is copied to the resulting variable and is used for variable expansion.  \n@LebedevRI I think the function was not easy to grasp and this is a useful comment. Whether I add this, however, is up to you. . I think path always starts with a /. Please see. I have removed that commit. done. sure. ",
    "mandree": "I've seen some effects that I haven't seen before, this is a very preliminary feedback since I cannot easily provide ways to reproduce this reliably yet, and some issues are gone after a restart of darktable for now - note that I permit OpenCL for all pipes, and I won't have \"you can't have OpenCL for the preview\" because it's like 15 x faster than my quadcore. There is only one NVidia 1060 6GB as OpenCL engine.   This is with high-ISO images (8000...25600) from a Sony A7II, so yes it's stretching it for a few photos in a very dimly lit room.\nI'm not even sure if it's caused by this merge/pull request, because I haven't yet had the time to back out this specific change, but it's the most prominent change that might cause it.\n\n\nI have seen some issues when playing with manual exposure correction and the pipette (picker): the black point is set way too low (-0.02, sometimes even -0.11) causing the whole image to go mushy bright grey. If I reset just the black to 0, I get a short status popup \"inconsistent result\", it must be from globaltonemap (levels and colorreconstruction are not enabled) - this happens very frequently.\n\n\nOnce, darktable (the computer was woken up from suspend) complained about OpenCL issues and ended up disabling it for the session. Restarting darktable (not the computer) appears to have cleared this glitch, but not the item above.. Well, we're comparing a 2.5 GHz 4-core CPU (AMD Phenom II X4) to a 1.9 GHz 1280-CUDA-core GPU (NVidia GeForce 1060 6 GB). Of course, the CPU will lose. I often also need to add raw denoise (for which we don't appear to have an OpenCL kernel) when going beyond ISO 6400 which apparently aggravates the situation. Find a sample export timing from the same image set, just to show you the sheer horsepower and because I can control it.\n\n\nHow can I force darktable to always dispatch everything to OpenCL device 0, serially (i. e. preview before full, looking at your latest comment)? That would really help narrowing down things.\n--disable-opencl:\n[dev] took 0.000 secs (0.000 CPU) to load the image.\n[export] creating pixelpipe took 0.185 secs (0.296 CPU)\n[pixelpipe_process] [export] using device -1\n[dev_pixelpipe] took 0.031 secs (0.044 CPU) initing base buffer [export]\n[dev_pixelpipe] took 0.064 secs (0.144 CPU) processed `raw black/white point' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.030 secs (0.060 CPU) processed `white balance' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.016 secs (0.064 CPU) processed `highlight reconstruction' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.733 secs (2.088 CPU) processed `demosaic' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 58.500 secs (200.652 CPU) processed `denoise (profiled)' on CPU with tiling, blended on CPU [export]\n[dev_pixelpipe] took 0.140 secs (0.464 CPU) processed `exposure' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 7.348 secs (24.760 CPU) processed `lens correction' on CPU with tiling, blended on CPU [export]\n[dev_pixelpipe] took 0.388 secs (0.964 CPU) processed `base curve' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.453 secs (1.568 CPU) processed `input color profile' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.531 secs (1.516 CPU) processed `sharpen' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 1.287 secs (3.408 CPU) processed `output color profile' on CPU, blended on CPU [export]\n[dev_pixelpipe] took 0.496 secs (1.664 CPU) processed `scale into final size' on CPU, blended on CPU [export]\n[dev_process_export] pixel pipeline processing took 70.021 secs (237.404 CPU)\nOpenCL enabled:\n[dev] took 0.000 secs (0.000 CPU) to load the image.\n[export] creating pixelpipe took 0.176 secs (0.204 CPU)\n[pixelpipe_process] [export] using device 0\n[dev_pixelpipe] took 0.042 secs (0.040 CPU) initing base buffer [export]\n[dev_pixelpipe] took 0.028 secs (0.024 CPU) processed `raw black/white point' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.005 secs (0.000 CPU) processed `white balance' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.003 secs (0.000 CPU) processed `highlight reconstruction' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.060 secs (0.028 CPU) processed `demosaic' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 2.599 secs (2.244 CPU) processed `denoise (profiled)' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.051 secs (0.116 CPU) processed `exposure' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 2.292 secs (6.488 CPU) processed `lens correction' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.015 secs (0.004 CPU) processed `base curve' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.015 secs (0.000 CPU) processed `input color profile' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.027 secs (0.016 CPU) processed `sharpen' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.030 secs (0.008 CPU) processed `output color profile' on GPU, blended on GPU [export]\n[dev_pixelpipe] took 0.052 secs (0.044 CPU) processed `scale into final size' on GPU, blended on GPU [export]\n[dev_process_export] pixel pipeline processing took 5.278 secs (9.056 CPU). Also note that\n\nI specifically permit the preview on the OpenCL device, with opencl_device_priority=*/*/*/* - in such situations we may need to make sure that the requisite pipe (the producer, i. e. preview) is launched first, before the consumer (i. e. full)\nany fixed timeout value is doomed to fail on other configurations than yours, or perhaps if some background daemon starts thrashing the disk, or a bus, or whatever.. @LebedevRI insisted on clang-format per the contribution guide... and these are side effects (w/ clang-format 3.8). I have force updated my branch and rebased a revised fix on top of the current master as of d97f205e02.. This goes a long way but isn't sufficient, see attached a snippet from the attached -> build log.\n\n../src/libs/tools/global_toolbox.c: In function '_main_do_event':\n../src/libs/tools/global_toolbox.c:249:46: error: 'false' undeclared (first use in this function); did you mean 'fabsl'?\n             gboolean is_language_supported = false;\n                                              ^~~~~\n                                              fabsl\n../src/libs/tools/global_toolbox.c:249:46: note: each undeclared identifier is reported only once for each function it appears in\n../src/libs/tools/global_toolbox.c:255:41: error: 'true' undeclared (first use in this function); did you mean 'trunc'?\n                 is_language_supported = true;\n                                         ^~~~\n                                         trunc\n. I need another patch:\n0001-Further-fix-to-use-gboolean-TRUE-FALSE-instead-of-no.patch.txt\n```\nFrom 032ba4010d46f4b2f1aa0dccea5d5bc625fdbcd0 Mon Sep 17 00:00:00 2001\nFrom: Matthias Andree matthias.andree@gmx.de\nDate: Sun, 28 Oct 2018 12:39:55 +0100\nSubject: [PATCH] Further fix to use gboolean TRUE/FALSE instead of\n non-standard true/false.\n\nsrc/libs/tools/global_toolbox.c | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\ndiff --git a/src/libs/tools/global_toolbox.c b/src/libs/tools/global_toolbox.c\nindex c3526d034..238d52659 100644\n--- a/src/libs/tools/global_toolbox.c\n+++ b/src/libs/tools/global_toolbox.c\n@@ -246,13 +246,13 @@ static void _main_do_event(GdkEvent event, gpointer data)\n             // array of languages the usermanual supports.\n             // NULL MUST remain the last element of the array\n             const char supported_languages[] = { \"en\", \"fr\", \"it\", \"es\", NULL };\n-            gboolean is_language_supported = false;\n+            gboolean is_language_supported = FALSE;\n             int i = 0;\n             while(supported_languages[i])\n             {\n               if(!strcmp(lang, supported_languages[i]))\n               {\n-                is_language_supported = true;\n+                is_language_supported = TRUE;\n                 break;\n               }\n               i++;\n-- \n2.17.2\n```\n. In case it helps, here is my CMakeCache.txt that fails on upstream's f0ad51b3382ea9d62df49d1007d59d8ad82beacb\n. ",
    "anilgulecha": "It looks liek there was a release post this merge on 28th May -- is dehaze part of this release?. Looks like it is not -- perhaps my question was not asked right? As a darktable user, I only wanted to find out if it's already out as part of a current release, or waiting for some future release. Regards.. ",
    "DawidLoubser": "Done. ",
    "atarijedi": "I have an EM1.2, and I took some raw photos in the various modes.\nIn terms of what kinds of images it can output, there is the standard RAW .ORF. In both the HIRES modes it creates an 80MP RAW file (.ORF) as well as a .ORI file, then either a 50MP JPG, or a 25MP JPG, the 25MP JPG is like Pentaxs sensor shift, in that each image pixel has real RGB values from each sensor pixel.\nI know you said ignore the JPGs, but I included them in the zip file anyways, just in case. I also included a photo of an XRite Color Checker, just in case you wanted to do some colour stuff. \nI am new to github, I tried to include the file in this comment, but its rather large (230MB). I signed up to that redmine page, but I don't know where to go from there?\nLet me know where to put the files, and if you want more.\n. Okay, I uploaded 5 files. One standard raw photo of an XRite colour checker, and then 2 raw files for the 50M mode, and 2 raw files for the 25M mode. The HiRes are of a autoparts box and some chart for bicycle parts. If you'd like HiRes photos of something else, like the colour checker, let me know.. I just added a standard 20MP raw that is the same as the HiRes files. ",
    "magicgoose": "@schenlap \nNot sure why, but after I added this to \u2026/darktable.app/Contents/Resources/share/darktable/noiseprofiles.json, and tried to test it inside darktable, the profile is not being detected. (However, profiles for an other camera I have work okay)\nMaybe this is related to the following:\n\"Image Information\" inside darktable shows some really strange values for shots from Nexus 5X:\nmodel: Credo 40\nmaker: Leaf\nHowever, exiv2 print shows correct values for the same file:\nCamera make     : LGE\nCamera model    : Nexus 5X\nOr I should try building darktable from latest commit and test with it?. @schenlap  plots.tar.gz from the first post contains the same files except jpegs.\nAnyways, I found the whole thing too, here it is \ndt-noiseprofile-20170415.tar.gz\n. hopefully it's going to be disabled by default, or at least asking the user before doing a network request for the first time.\nunconditionally sending location data to some third party without asking would be quite bad.. but why, are they auto-generated? (I'm not the author, just curious). ",
    "khampf": "Thanks for the comment! I was in a rush and not aware of that cropping guides could be implemented in Lua so when looking for the source of exisiting guides I found only hardcoded implementations, so I did mine quick in C in the same manner and later gave it defined constants and uploaded to github. I'll take a look at implementing it in lua. ```lua\nlocal dt = require \"darktable\"\ndt.configuration.check_version(...,{2,0,0},{3,0,0},{4,0,0})\ndt.guides.register_guide(\"passport\",\n-- draw\nfunction(cr, x, y, w, h, zoom_scale)\n  local _w, _h\n-- get the max 36x47 rectangle\n  local aspect_ratio = 47 / 36\n  if w * aspect_ratio > h then\n    _w = h / aspect_ratio\n    _h = h\n  else\n    _w = w\n    _h = w * aspect_ratio\n  end\ncr:save()\ncr:translate(x + (w - _w) / 2, y + (h - _h) / 2)\n  cr:scale(_w / 36, _h / 47)\n-- the outer rectangle\n  cr:rectangle( 0, 0, 36, 47)\n-- vertical bars\n  cr:draw_line(16.5, 8, 16.5, 36)\n  cr:draw_line(19.5, 8, 19.5, 36)\n-- long horisontal bars\n  cr:draw_line(6, 4, 30, 4)\n  cr:draw_line(6, 40, 30, 40)\n-- short horisontal bars\n  cr:draw_line(9, 6, 27, 6)\n  cr:draw_line(9, 38, 27, 38)\ncr:restore()\nend,\n-- gui\nfunction()\n  return dt.new_widget(\"label\"){label = \"based on the ISO 19794-5/ICAO 9309 passport specs\", halign = \"start\"}\nend\n)\n-- kate: tab-indents: off; indent-width 2; replace-tabs on; remove-trailing-space on; hl Lua;\n-- vim: shiftwidth=2 expandtab tabstop=2 cindent syntax=lua\n```. ",
    "thorenx": "You can find the complete .tar.gz with the pdf graphs at this adress\n[link deleted]. ",
    "amueller": "I just realized that this is the curve applied for \"vivid\". The standard one is somewhat less contrasty. I imagine you would want to add the standard one instead?\nNeutral is\necho \"INSERT INTO presets (name,description,operation,op_version,op_params,enabled,blendop_params,blendop_version,multi_priority,multi_name,model,maker,lens,iso_min,iso_max,exposure_min,exposure_max,aperture_min,aperture_max,focal_length_min,focal_length_max,writeprotect,autoapply,filter,def,format) VALUES('ILCE-7RM2-neutral','','basecurve',2,X'0000000000000000b8580f3bc565a73a2ff7073c2e61be3bbb5b753c386b683c2381263d21058c3d7c49733d1534023e288fc33d7915773ebdcce73d6263963e4c113b3ee0b9f93e0f72833e7f43203ffb50a43ee9fe383f0cf6eb3e68b8593fb7890e3f29ff643f576b343f02cd6f3fc689663f4d257b3f0000803f0000803f00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000100000000000000000000000020000000000000000000000',1,X'00000000180000000000C842000000000000000000000000000000000000000000000000000000000000000000000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F00000000000000000000803F0000803F',7,0,'','%','%','%',0.0,340282346638528859812000000000000000000,0.0,10000000.0,0.0,100000000.0,0.0,1000.0,0,0,0,0,2);\" | sqlite3 ~/.config/darktable/data.db. Thanks. Is there a way I could provide the data that generated the curve?. ",
    "WalterS": "@houz Rubocop is a linting tool for Ruby, how is their homepage a \"random\" website? I thought every Ruby developer is familiar with this tool and its benefits.... ",
    "rrenomeron": "The additional entries were due to extra shots I'd taken, I've reviewed and removed the excess.. ",
    "drhaynes": "Thanks @rrenomeron for doing this.\n@LebedevRI can this be merged now? Keen to get M5 support in. Thanks!. Ah, what is involved? Is it something I could help with?. ",
    "ILiebhardt": "I looked at several alternatives for squashing, and the most practical in this case seems to be to close this pull request and to make an entirely new one. I will proceed like this.. You're right. I was still running into trouble with the most commonly used git rebase -i approach. In any case what I have now looks a lot cleaner.. On the modern cmake as generic observation, you're right though. With all the dependencies, it would be a topic worth addressing ;-). OK, to begin with, I applied the clang formatting to the differences selectively, instead of to the whole file. This should make the pull request much more readable again. I'll try to address the remaining topics one by one to take it further from here. @kubrickfr was and is a great help and contributor to me. . OK, corrected the last one. Please let me know if you find something more. As to the mentioning of contributors (see also message from @kubrickfr), I'll leave it to the project maintainers, depending on what's preferred. I know that there's normally a 3 commits rule, but what was larger for this one isn't so much the commit itself but more the r&d effort that was behind. Unfortunately, with this exotic sensor, there is no conference paper saying: 'this is the perfect way, do it like this' ;-). Hi, I already removed the clipping in question with my commit from 2 September. \nAs to the feature freeze, I had a PR in place before the closing date, so maybe it could still be taken up? Just let me know how you'd like to proceed.. @kubrickfr : could you maybe provide me with the raw concerning the highlight recovery, such that I could try to investigate in more detail? Thx.. OK, I removed the clipping from the output stage entirely and I shifted the intermediary clipping to the chroma domain (it's only useful here). Results look much better now and highlight reconstruction should work properly.\n@kubrickfr : thanks for the sample.\n@LebedevRI : I'd be glad to have this taken up for 2.4.0 if still possible. This PR was in place well before the feature freeze; thus far I addressed all your review comments. Just let me know what you'd require from me. Thx.. Hi @LebedevRI and @houz ,\nI removed the mutex and the fftw plans are now in init_global() and cleanup_global(). It works fine, thanks again to @houz for the hint.\nFurthermore, I rebased everything, cleaned up, and squashed all commits into a single one. I also made sure that none of the commits changes src/external/rawspeed. The only minor change that I was unable to do, unfortunately, is the tile size as static const. It is used in various places (also in the original Markesteijn) for defining array sizes and C doesn't allow for variable size arrays.\nFor everything else, all review comments were addressed.\nIf you find anything else, please just let me know.. And one comment on the dependency on FFTW3: it is optional. There are code paths working without FFTW3 and delivering exactly the same image output. They are around 30% to 40% slower (depending on the machine), so FFTW3 is still highly recommended. . Reusing a plan is not so much a matter of using the guru interface, but rather a matter of using the new array execute functions. This particular implementation hinges around the new array execute functions, they are key. I apply them to tiles, and due to this, array sizes, stride, ... don't change. The conditions of [0] are met.\nAs to [1], this is a bit more tricky. I found out in 'dry exercises' that NULL pointers in plan creation work if, and only if, you use the new array functions for execution, otherwise it fails. Now the question is: is the documentation a bit sparse on this matter (after all, the part on new array functions is a bit small) or is it working merely by coincidence?\nWe (including @kubrickfr) have done quite some testing, without crashes.\nBut if you find the use of FFTW3 too risky, I could also remove it completely and just go for the normal C implementation path without FFTW3 dependency. After all, the difference in speed is not that pronounced on stronger machines.\nJust tell me if you prefer the latter and I'll quickly implement the changes.. Me not, @kubrickfr used Valgrind.. As said, the option without FFTW3 is absolutely viable for me, too. . Ah, and by the way for the tiles I used padding, so border tiles and small images are no problem.. OK, I entirely removed the FFTW3 part, changed the const occurrences to static const, as requested by @LebedevRI and squashed all into one commit.\nI would now really like to give it a thorough check with asan. (for sure I'm not writing maliciously broken code, come on, I just would like to contribute)\nI am not sure, though, if I'm checking properly. \nI built using build.sh --asan. \nThen I ran and expected some output on the shell, but nothing appeared.\nI became sceptical and ran an ldd darktable and did not see lib asan explicitly.\nI ran an apt-get install libasan4, but it's already installed.\ngcc --version gives me 7.2.0.\nclang --version gives me 4.0.1-6 \nIndependently of toolchain, any of the two should be new enough.\nWhat could I be doing wrong? Or is it right and there's no memory bug?\nThanks for any help.. Hmm, it started as usual.\nIt works as usual, albeit a little bit more slowly.\nI used it a lot, particularly demosaicing with fdc, tiles, complete images, all...\nNo crash, no output.\nSo all appears to be fine.\nLet me know if you still find something on your side. From my side, I think I addressed all.\nCheers, i. Ah, hold on a sec, not really all, one last minor stupid thing, I forgot the conditional include of FFTW3 on top. Commit coming.. Ok, now really all.. hi hanatos, thx for merging, and my pleasure to contribute. I have less intrusive ideas for making it faster using sse, and I could also make an openCL version of it. That's for next year - after all it's good to have a nice project in the pipeline ;-). Hi, I just re-based this. It is an improvement of the existing frequency domain chroma approach for demosaicing the files from the X-Trans sensors. It is quite a bit cleaner than the original approach, see here. For comparison, this was the original approach. I also checked with asan. I would be glad if this could be taken up - if I can help in any way, just let me know.. Hi @TurboGit thanks a lot for letting me know, and my apologies for the inconvenience. Maybe my approach wasn't good from the start? I forked darktable on github, then cloned this forked repository locally (with a git submodule init / git submodule update), then made the changes locally, committed and pushed. I finally created the pull request out of my own darktable fork. I must admit that I'm rather stuck - whatever I try to remove the submodule from the pull request seems to have unwanted side effects. In the end, my pull request concerns only two files. Could you please let me know what would be the best approach here? If you think it would be better I could also make a new PR from scratch. At least I did a rebase to begin with. Many thanks for your help.. It seems that 3 is already reserved for \"passthrough (monochrome) (experimental)\", the fourth demosaicking option for xtrans.. Perfect, thanks. Changed, pull request coming up once I have more changes consolidated.. To be honest, I would also still be conservative at this point and not make FDC the default yet. My impression is also that this must be clipping due to too big method id. I'll investigate and let you know.. It appears that I get values out of the expected range [0.f ... 1.f] back from 'in'. If you take the raw file here and process it with fdc demosaicking and remove the CLIPs, then you will see a green border on the right hand side. This is only for X-T2 images, X-Pro 1 images don't have this issue. \nThe following code also remedies the issue:\n`#ifdef HAVE_FFTW3\n            *(i_src + TS * (row - top) + (col - left)) = ( (in[roi_in->width * row + col] < 0.f) ? 0.f : in[roi_in->width * row + col] )\n                                                         + 0.f * _Complex_I;\nendif`\nHence my conclusion that negative values must be the problem. I did the same check for greater than one, for isna() and for isinf(), without results. So negative values appear to be the reason.. As to the question of upstream, I am not sufficiently the expert to know what processing sits between rawspeed itself and the data at this point, but I'll try to investigate further.. Thanks @LebedevRI .. Cool, thanks a lot. Then I'll remove the CLIPs from my side.. OK, I synced my fork back to upstream, taking your commit dc32f19 into account. I removed the CLIPping. Bad news: the issue isn't fully gone. Green border on the right hand side is still there, unfortunately.. Hold on, my apologies. My bad. My eyes had been looking at too much code yesterday ;-)\n<Crop x=\"0\" y=\"0\" width=\"-132\" height=\"0\"/>\ndid the trick! 1000times thanks.. OK, I corrected this one, too. It wasn't strictly speaking the general default, it was the fallback for invalid values delivered back from the combobox. In any case, Markesteijn is now always default. On the way, I also spotted a minor error in the existing code: ' | DEMOSAIC_XTRANS' was missing once, I think.. This is just part of the Markesteijn approach, which I merely took over. This is part of your codebase for a little while already, so I doubt that it makes the difference here. Actually, if you look at your initial review comments, you'll see that the clipping in question was at the input stage, and there, I removed it with my commit from 2 September.. Ah, thx for clarifying. \nBut this is also not the clipping we discussed before, which was really at the input stage. (and that one, sorry, I removed it)\nThis clipping here is after chroma estimation. It's there to avoid values going out of range in areas of high color variations. As such, this is pretty much common practice in demosaicing and all other algorithms also have it in one form or the other. We could have a look how the demosaicing behaves removing it, but I remember that I put this one for a very specific reason.. Hi, \nThe most relevant part of libfftw, the plan execution, is thread safe. But the plan creation and plan destruction are not. Performance wise, this is not a problem, because the plan execution is the really significant portion. If you'd like to dive more into the details, you could have a look in the doc on page 51, subsection 5.4. Cheers, Ingo. And to add, I only use the mutex for plan creation at the very beginning and for plan destruction & cleanup at the end.. It's the latter, only administrative data structures, depending exclusively on the tile size, which is constant. The plan is completely independent of the image content, so no worries in this respect. In theory it would even be possible to create a plan on darktable start-up and destroy it upon exit, but that would be at the expense of code readability in my opinion. . @houz : thanks for the hint, I'll look into it! Why I was not too enthusiastic about it: in demosaic.c, we define the tile size locally as #define TS 122. If you look at the plan creation, the only real dependency is on this tile size, as I said above. Now, if we move the plan creation to init_global(), this is not so ideal. If you have a nice suggestion for me, I'm more than open.. @kubrickfr : I don't think we would break parallel processing. In the present structure, the plan creation is in static void xtrans_fdc_interpolate, but before the actual OpenMP parallelism for the tiles starts. So now there is one single plan creation per demosaic, and then parallel use of the one plan for the multiple tiles. So I see little risk here.... OK, I think we can live with alternatives concerning the TS definition. One important question for @houz is: is single-threaded execution of init_global() and cleanup_global() guaranteed? Otherwise, we're still confronted with the need for a mutex.. @LebedevRI : to answer your three questions:\n1. No, the only dependency is on TS, as I already said above.\n2. Yes, I can make such replacement if you prefer that, no problem. I took over the #define from the existing code above.\n3. I am pretty sure that the exact same plan be created once, and then used everywhere for everything, without creating it each time in xtrans_fdc_interpolate(). Already now, it is created once and used multiple times for all the tiles, and one roi can have hundreds of tiles. Busy day for me today, but I'll make the modifications tomorrow or on Friday and let you know.. I removed the mutex and placed the plan creation and plan destruction in init_global() and cleanup_global(), respectively, as suggested by @houz . It doesn't crash on my machine, and following FFTW's documentation, I don't expect it to. I will follow this u with a rebase, and cleanup, as suggested by @LebedevRI . As said, I always addressed all your review comments thus far, and if you find something else, just let me know.. 1. Ok, no problem, I\u2019ll drop FFTW3, much easier than adding it ;-)\n2. I\u2019ll make them static.\n3. Sure there\u2019s an algorithm. I sent @hanatos a rough overall description a while ago where it was also mentioned how these filters are made. It's basically training on reference images and then finding the least minimum square error. I implemented that in matlab, but it works also under gnu octave. Dirty code though, because it runs only once...\n4. I can also give it a last check with asan, no problem. In any case dropping FFTW3 really reduces risks.\n. I\u2019ll do the above stuff tomorrow and let you know.. OK, done and squashed into single commit.. ",
    "kubrickfr": "@ILiebhardt With FDC demozaicing, highlight recovery doesn't work very well.\nWith makesteijn: \n\nWith FDC (same settings):\n\n. @ILiebhardt sure, https://drive.google.com/open?id=0ByPjAhK7ObclLVVrT2tQZ2hCeG8. Yes, I remember putting this lock in place. If you remove it it crashes frequently. . For what it's worth, the implementation with FFTW3 has been extensively tested with thousands of my own pictures (and @ILiebhardt has a different camera model so I assume we have quite a bit of coverage). Assuming we drop it for now, which seems to be the way this is going, what needs to happen in order for it to be accepted in the future?. @LebedevRI I guess the comments here refer to the green edge issue. Any case, these comments are not helpful without context and your workaround works well. Does the issue need to be investigated upstream though (rawspeed)?. All these formatting changes should be removed from this pull request, don't you think? There's a lot of them and it makes the pull look unnecessarily big IMHO.. It needs to be discussed if FDC is to be made default or not as it changes the existing behaviour.. creating \"the plan\" on darktable start-up would break parallel processing, wouldn't it?. From my experience, that's the reason why it was crashing : when zooming in and out,  the demozaic function was being called before the previous call finished/was cancelled , which is what was causing the crashes. If you move plan memory allocation outside of the function, maybe you'll avoid the crashes but you'll get some corruption / glitches I bet. . @LebedevRI, yes indeed I meant  \"crashing without that current lock\" :) sorry if my comment was misleading.\nI have been using this patch for months now with thousands of pictures, frequently rebased against the master branch and it has been very stable.\nThe point I was trying to make is that I think moving memory allocation outside the function would break things. Anyway, what's so problematic with having a mutex here?. @LebedevRI 3) as I mentioned before when zooming in and out (for example) interpolation functions such as xtrans_fdc_interpolate() get called before the previous cancelled call is finished. I do not believe this is specific to xtrans_fdc_interpolate() \n. @LebedevRI Indeed, therefore no, I haven't tried, but I don't think you can uses the exact same plan created once. ",
    "orium": "\nIs this on a 32-bit or 64-bit systems?\n\nOn 32-bit systems this will work for <4GB files.  This is because the gphoto library uses unsigned long int to represent file sizes, which will be 32 bits in 32-bit systems.\nOn 64-bit system this fixes the file truncation problem, because a unsigned long int will have 64 bits (well, the C standard only says \"at least 32 bits\", but in practice compilers use 64 bits).\nA way to fully solve this, as well as avoiding high memory consumption (since files are completely loaded into memory), is to not depend on gphoto to read files.  It does load the entire file in memory just to get the exiv2 \"datetime taken\", which could be done by reading it directly from the file (the exiv2 library supports that).  We can then copy the file ourselfs and avoid the limitations of gphoto.\nI will take a shot at this approach and if everything goes well I will update the PR. . > A way to fully solve this, as well as avoiding high memory consumption (since files are completely loaded into memory), is to not depend on gphoto to read files. It does load the entire file in memory just to get the exiv2 \"datetime taken\", which could be done by reading it directly from the file (the exiv2 library supports that). We can then copy the file ourselfs and avoid the limitations of gphoto.\n\nI will take a shot at this approach and if everything goes well I will update the PR.\n\nNevermind.  We need gphoto to read the file from the camera, since the camera fs doesn't need to be mounted.\n. If we accept that \"gphoto provides correct file size info\" then we accept that 32-bit system truncate file sizes to 4GB and this is the candidate PR.\nThe memory consumption problem however could be solved in a couple ways:\n\nGphoto has a way to read chucks of a camera file, so this could be used to solve the memory problem and the 4GB file size problem on 32bit (the gp_camera_file_read() that can read parts of a file uses uint64_t).\nHowever, the final filename depends of the exiv \"datetime taken\", so we would need to copy it somewhere first, then read the exiv \"datetime taken\", then move the file to right place.\nAlternatively I can (maybe?) implement a Exiv2::BasicIo that actually knows how to read from a camfile, again by using gp_camera_file_read(), and with this we can read the exiv data directly from the camfile.  (atfer a quick looking at the Exiv2::BasicIo interface some stuff doesn't map very nicely...)\n\nEither way, we can ignore the memory problem for now.... > Using that functionality to import something that is completely unrelated to darktable (videos) is a total abuse.\n\nWe should either implement black/white -lists of file extensions / MIME types.\n\nI'm happy with that.  Anyway, this is how data should be written with write().  We always have to check and loop if there is still stuff that wasn't written.. Anything needed to be done to merge this?. > So what about _LARGEFILE_SOURCE / _LARGEFILE64_SOURCE / _FILE_OFFSET_BITS macros?\nThese macros allow you to use a 64-bit interface for writing/reading/etc in 32-bit systems.  In 64-bit system they will do nothing.  However, in 32-bit system we already have the gphoto limitation of using a 32-bit var to hold the size, so it doesn't help there.\n(However even if these macros helped we would still need to write() to the file in the way that this PR does.  See below.)\n\nAre they unrelated? Or is the current diff the right fix?\n\nYou can see this PR as a \"fix for write()ing to files correctly\".  It also fixing the 2GB limit on 64-bit systems is a side-effect.  In practice the write() worked fine before because the linux kernel is nice enough to make write() not return prematurely (e.i. without writing everything) for chunks of data less than 2GB, but it could do so and still be POSIX complient.\nMaybe it is even possible for write() to only write, say, a few bytes, if it gets a interrupt in the wrong time or something like that.  If that is possible than darktable might truncate small files if you are really unlucky.\n. >  reading man 2 write i see some more cases that we might want to deal with, for example ret == -1 and errno == EINTR -- should we try again?\nYes, we  should.  Will update PR.\n\n and if i understand the man page correctly, on a full disk write may reutrn 0 which will send dt into an infinite loop\n\nIt will not return zero in this case.  It will return <0 and set errno to ENOSPC:\n\nIf  a  write()  requests  that more bytes be written than there is room for (for\nexample, the file size limit of the process or the physical end  of  a  medium), \nonly  as  many bytes as there is room for shall be written. For example, suppose \nthere is space for 20 bytes more in a file before reaching a limit. A  write  of \n512  bytes  will  return  20. The next write of a non-zero number of bytes would \ngive a failure return (except as noted below).\nERRORS\n   ENOSPC There was no free space remaining on the device containing the file.\n\n\nIn fact, write() should not return zero for non-zero sized write()s. . > On success, the number of bytes written is returned (zero indicates nothing was written).\nI think this only happens if we ask write() to write 0 bytes.\n\nIt is not an error if this number is smaller than the number of bytes requested; this may happen for example because the disk device was filled.\n\nI think this is talking about >0 number of bytes.  As I said in the quote in my previous comment if there is only 100 free bytes in the FS and you ask write() to write 200 bytes it will return 100 and subsequent calls to write() will return <0 and errno will be set to ENOSPC.\nSee the SO link in my previous comment.. From what I can see write() returning zero is not a thing in POSIX-compliant system (see this and this).\nAlso, if we look at the gnulib full_rw(), which is the code used by the GNU coreutils cp, we can see that they handle the case where write() returns zero but only because:\n/* Some buggy drivers return 0 when one tries to write beyond\n   a device's end.  (Example: Linux 1.2.13 on /dev/fd0.)\n   Set errno to ENOSPC so they get a sensible diagnostic.  */\n. Alright!\nAnything else before landing this puppy?. > We just have to decide if it would make sense to delete files that were only partially copied.\nMaybe we should.  Updating PR.... Ping.\n(Note that travis didn't build on macOS for some reason...). Just a reminder to close https://redmine.darktable.org/issues/11689. ",
    "graudeejs": "I can confirm, that <<< will break on FreeBSD where /bin/sh is not bash. ",
    "vacaboja": "The travis check has failed because of an internal error they have with Mac OS X builds\nhttps://www.traviscistatus.com/incidents/4qylrqvy50gy\nIs there a way to reschedule the tests when they sort out this problem?. Did a rebase.. This comment references the following discussion, taken from the review by houz above.\n\nhouz:\nWould it make sense to record the x/y position in button_pressed and compare that to the final one in button_released instead of handling mouse movement here? That way one could easily allow tiny movements which might be impossible to avoid with some touch devices, pens or touchpads.\nvacaboja:\nWhat you say makes sense to me. I see two ways to proceed:\n1 - We do not pan the view until the mouse pointer exits the UI element which is activated. If the button is released before leaving, then it counts as a click. As soon as the pointer leaves we start to pan.\n2 - Quick and dirty: if the pointer moves less than, say, 5px it's a click.\nI would go for the first option, but if you prefer the second I can also implement that one. What's your opinion?\nhouz:\nThe first sounds good, but I would have to see it in action to get a feel for how annoying it is when the view doesn't move at first. Maybe the 2nd will turn out to be the better approach after all. Instead of using a fixed distance we should pass the (say) 5px through DT_PIXEL_APPLY_DPI() to make it a real world distance on the screen.\n\nI implemented a bit of each: when the button press is on a star or reject, the first option, when the click is on an image (so we need to differentiate between pan and select), the second. Please tell me if you find anything annoying.\nIdeas:\n(a) Do not delay pan in the most obvious case, namely click on image and drag.\n(b) Stars etc. behave similarly to normal buttons.\n(c) When the user sees the hand pointer, he can be sure that releasing the mouse button will not cause any action.\nAlgorithm: when button press is on star or reject, we do not pan until the pointer leaves the element activated, at which point we begin to pan, set the mouse icon to the grabbing hand, and cancel the activation. When button press is on an image we begin to pan immediately, however we don't set the icon to the hand, and if the button is released within l_1 distance DT_PIXEL_APPLY_DPI(5) we take it as a click. In this case, when the pointer moves more than DT_PIXEL_APPLY_DPI(5), the pointer is converted to the hand to signal that now we won't take the button release as a click any more. \nOther changes:\n(a) Now click in file manager mode does not display the hand pointer. I think it makes sense, as that is usually the signal for pan or drag. If undesired it's easy to revert.\n(b) Fixed pre-existing glitch whereby when the pointer exited the window during pan, sometimes, the lighttable jumped in a unpredictable position.\n(c) Deleted apparently dead code in src/gui/gtk.c.. MacOS build fails again for no apparent reason (probably it timed out). Must be a problem in travis. Is it possible to re-schedule the build?. Dear developers,\nI am bit uncertain about the state of my pull requests. I do understand that everyone is busy, but, on this request, I have been explicitly engaged into a discussion by houz on September 15. I modified my code accordingly in a matter of days. And, two months later, I didn't even get an acknowledgment that my reply was noticed.\nI do not want to intrude on your process, but I must say that this had a negative impact on my enthusiasm with contributing. Nevertheless, may I ask about a little update? Is my code satisfactory now?. Thanks, I understand the feature freeze (yet I submitted well before). Trouble is that last time I updated, I noticed a new (and quite annoying) bug with the zoomable lighttable. I wanted to look into it, but having already two bugfixes outstanding, I felt a bit discouraged...\nThe new bug: (under xfce on linux) in zoomable lighttable the star rating of any image is not displayed until I hover with the mouse on the image. It wasn't like that a couple of months ago, so I suspect that this has been introduced in one of the latest commits.. Little update. I investigated that other bug and fixed it. I made a pull request with bug description and fix.\nI do understand that the dev team is not interested in zoomable light table, and I don't want to be insistent. If you prefer not to be bothered with zoomable lt, just let me know. That would probably save time for all involved.. > Could you rebase and fix conflics? It would be nice to have this in. Thanks.\nI will try to do it in the next few days.. Before I upload the the rebase, could you please take a look at #1993 : the new logic in lighttable, it seems to me, has a little bug that needs to be fixed, lest I mess it up further.. I did the rebase. Subjectively, it seems to work as intended, but I cannot say that I understand what really goes on in lighttable.c. In particular, please check that I didn't break the file manager view (in the processing of click events).. > Generally I'm wondering if it won't be easier to change the rating/color-labels/reject on button release unconditionally for the filemanager or zoomable lighttable. Won't this make the code cleaner?\nIt would not work. This is not the typical behaviour of buttons, and, in fact, it might have unpleasant consequences in some situations.\nExample 1. The user presses the mouse button in the middle of nowhere, then moves the pointer to a UI element (inadvertently), then releases the button. The typical beaviour of most UI, in this situation, is not to activate the control. Observe that even thumbnails are UI elements, because activating them means changing the selection.\nExample 2. The user presses the button while the pointer is on a UI element, then he realizes that this was a mistake, so he moves the pointer away from the element. In most UI, in this situation, the element is not activated. What will happen if we activate elements unconditionally on release? Possibly, as soon as the user moves the pointer away, the entire lighttable will begin to scroll following the mouse, hence he will never escape the control element that keeps following the pointer. And even if, how could he be sure?\nNotice that in the current implementation the shape of the pointer gives to the user a clear indication of what will happen.\n- When the pointer is a arrow, then a UI element might be activated (if under the arrow).\n- When the pointer is a hand, then a UI element will not activate.\n- The pointer will never change from hand to arrow unless the button is released (necessarily without activating anything).\nAs far as I could observe this is the usual behaviour of most programs, and it effectively prevents inadvertent activation of UI elements (which is the whole point of this PR).. Fixed style + type of activate_on_release.. The ying-yang thing: yes I totally forgot about that. I'll look into it, thanks.. Thanks, I fixed the bug.\nAlso, I took the opportunity to do a bit of refactoring of the dt_view_image_expose() function in view.c. This function is almost a thousand lines long and does everything needed to draw a thumbnail and all the associated paraphernalia. I separated the logic that deals with the active elements, such as stars etc., into a new function called dt_view_process_image_over(). The new function also checks if an element is activated by the mouse pointer, and a parameter can be used to tell it to skip the drawing and only do this check. So the code related to the positioning of control elements is not duplicated (it was in my initial PR). Finally, dt_view_process_image_over() is called also by dt_view_guess_image_over() to check whether the some element might activate and, ultimately, if a redraw is required.\nBesides, I noticed that the tooltip associated with the ying-yang icon is there only in the file manager view, and not in the zoomable lighttable. Is it so by design?. What you say makes sense to me. I see two ways to proceed:\n1 - We do not pan the view until the mouse pointer exits the UI element which is activated. If the button is released before leaving, then it counts as a click. As soon as the pointer leaves we start to pan.\n2 - Quick and dirty: if the pointer moves less than, say, 5px it's a click.\nI would go for the first option, but if you prefer the second I can also implement that one. What's your opinion?. This and the following half a dozen lines are essentially dead code (actually it runs, but it merely wastes cpu cycles). Specifically, it defines local variables x and y, then it fetches the pointer position into x and y, then, finally, it does return FALSE.. Well, I thought so, but I tried and clang-format refused my commit.. If I change to the intended style, viz. with the brace on the following line, an then I try to commit, this happens\n$ git commit -a\nCommit did not match clang-format\nRunning git clang-format-3.8 --diff on the command line, I get the following.\n````\n$ git clang-format-3.8 --diff\ndiff --git a/src/views/view.h b/src/views/view.h\nindex bb1afb7c5..acb63293f 100644\n--- a/src/views/view.h\n+++ b/src/views/view.h\n@@ -120,8 +120,7 @@ typedef struct dt_view_t\n   GSList *accel_closures;\n } dt_view_t;\n-typedef enum dt_view_image_over_t\n-{\n+typedef enum dt_view_image_over_t {\n   DT_VIEW_ERR = -1,\n   DT_VIEW_DESERT = 0,\n   DT_VIEW_STAR_1 = 1,\n````\nShould I update something? Or should I force the commit?. ",
    "cryptomilk": "I will leave for vacation on Friday. This means you wont hear anything from me from Friday till mid October!\nIf the patchset is not in a good state by Friday, feel free to modify the patches.. Updated .... Ping. @TurboGit . I will fix it.\n. I've updated the branch .... I think dcraw should be replaced by darktable-cli!. I've just updated the values. Feel free to drop the PR.. This doesn't fully work. We need to fix cmake first as it messes with C and CXX flags which it shouldn't do. Those should not be touched. See https://cliutils.gitlab.io/modern-cmake/. Closing, I will try to improve cmake and switch to a modern cmake.. That's why we created:\nhttps://build.opensuse.org/package/show/home:darix:darktable:master/darktable\nThe you can choose the right build for your CPU .... The background color changes how you perceive the colors in the image. A darker background and your image is brighter, a white background and your image is less colorful. Depending what you are developing for you want to change that background color. If you developer a picture for your white wall, you want to use a white background ...\nIt would be better to have directly as a small button in the darkroom ui to switch it without requiring a restart or editing a file. However my darktable skills are not the best :-). Closing as this needs to be implemented differently. I'm happy to work on this but I need a helping hand or some pair-programming.. I've started to draw a path an it segfaulted, I can't reliably reproduce this, but also fixing size types here makes the code more reliable and the optimizer can do a better job. Also you should build the source with UndefinedSanitizer but I think we need to do some cmake cleanup for that.. * overflow is undefined (https://port70.net/~nsz/c/c11/n1570.html#3.4.3p3)\n unsigned never overflows - it is defined as modulu arithmetic (https://port70.net/~nsz/c/c11/n1570.html#6.2.5p9)\n since overflow is undefined, the compiler is free to assume it does not occur, because if it did occur, the compiler would be allowed to do anything (undefined behavior)\nFor pointer arithmetic, array access, loops which are only operate on positive number use size_t and do proper overflow checking (else it can also lead to security issues).. Yes, I'm not there yet. The PR is marked as WIP.\nHowever if you CLAMP() then you might access the array position at the wrong postion. Is that what we want? Should we \"return\" if we haven an invalid array access?. Rebase needed. Someone neeed to retrigger the travis build, it has been stuck pulling a docker image.. If I'm selecting in Lab, independent channels then I get the a and b channels. However if you close the tone curve maybe add another and then reopen it again. It only shows the L channel and a and b are hidden. I need to reselect Lab, independent channels to get the a and b channel again!. I can confirm that it is fixed :-). @LebedevRI What was the error? The build log has been overwritten.. Ok, I will clone it and build again with the patch to see what is going on.. I've applied the patch to the packet but it builds just fine for me:\nhttps://build.opensuse.org/package/show/home:gladiac:branches:graphics:darktable:master/darktable. Question:\nWhy is this needed in the first place?\nAnd for which binary is that needed exactly? Only for the darktable executable?. I guess we want this:\nhttps://github.com/cryptomilk/darktable/commit/f89a5fb356fb2f9f3697a2c7aa306fe233e17fe2. @aurelienpierre . I can build and test. Could you look at my cmake fix to run darktable in the build directory?. I've fetched your latest branch and built darktable:\n\nScrolling and moving the mouse around doesn't look like there is a difference to master\n\nCurrently I don't see any huge improvement.. I have an Eizo 4K Monitor (3840 x 2160 resolution)\nIf I move the mouse (showing 12 images per row) it takes ~1sec till the selection follows.. If I make the window much smaller, it is almost instant.. And it is faster with your patch than with master. However only in a small window. It doesn't feel like there is any improvement if I make it fullscreen.. You can put all libraries in one directory in the build dir using:\nset(CMAKE_LIBRARY_OUTPUT_DIRECTORY \"${CMAKE_BINARY_DIR}/lib\")\n\nHowever, the code needs to try to first dlopen() the library from the build dir and fall back to the system directory. I guess it would work if we pass the path where to look for modules to:\ndt_module_load_modules() and have the build dir locations of the modules in config.h. Then we can first try to load from the build dir and if that fails go to the system dir.. I just wanted to export an image and and I just got a gray image. When checking the history, I see that all blend modes, drawn masks and parametric masks are gone!\nHowever if I open the XMP file with an editor I can still see mask information in there, but they don't work. The blendop verison is set to 8.. I will try that soon.\nAs a reminder, documentation for the new features are needed! For the filmic module we use hackmd for collaborative editing.\nhttps://hackmd.io/s/HyqqZQdaX#. The recovery from above doesn't work for me at least.. I think that 0.27 will be released on Christmas too, so it should be supported. Else exiv2 will be updated and darktable will not build any more. The fix seems to work with older and newer versions. However for distribution we could also apply this patch, but we have it in time and the changes are pretty minimal.. I think for this stuff we need some configure tests. I can work on a cmake cleanup but it will take some time.. It is not perfect yet, but definitely an improvement!. * Yes, I have a 4K display\n Yes, this is a small improvement but not as snappy as it could be.\n No, it is not perfect yet.. 2b24086bdcae7b9a988f081ea7825862ee22ea75 seems to work!. Moving the mouse is fast, the selection follows instantly However scrolling is broken with 2b24086bdcae7b9a988f081ea7825862ee22ea75. Only two thumbnails are changing. If I scroll more it is refreshed after some time .... Now scrolling works again but the borders for the thumbnails are gone :-). Scrolling works, it is super fast but the borders of the thumbnails are gone, we are close :-). https://xor.cryptomilk.org/darktable/darktable.png. They are gone on startup.. 29caefec7d8d83ce424cfaf3fc35104f90e8a6b9 doesn't fix it ... :-). @TurboGit Yes, if I hover a group I get the yellow group selection border.. Ups, I moved my custom css and it looks like everything works now.\nI've tested 81df11a862caa39ef60ca6548ffaa8c329d84a93. As soon as I use a custom darktable.css it stops working. It looks like the darkroom_bg_color gets applied to the lighttable.. Ah ok, I see I need to change the lightable background color to be different form my darkroom backround color.. We are good to go. Just looking at the patch it looks like a few things should be size_t like max_cols and max_rows and then some rows and cols variables dealing with it. But such cleanup could be done later .... @TurboGit I will test this asap, probably tomorrow morning. I have to edit some pictures.. This looks good, I didn't find any issue when testing.. Yes, I did. @rabauke . Have you ever built darktable with \"UndefinedSanitizer\", this normally also reveals quite some issues.. See: https://gitlab.com/cmocka/cmocka/blob/master/cmake/Modules/DefineCompilerFlags.cmake#L38\nand https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html\nworks also with gcc.. Normally you do that checking CMAKE_SIZEOF_VOID_P and then put it into config.h. For dates and time please use ISO 8601. If someone starts to argue, tell them we use a standard which is sortable :-). The errors in src/common/undo.c seem to be in new code introduced by @TurboGit. @TurboGit did you run this with helgrind?. This got a few more patches ... I've grepped through the source to detect patterns which people use to hide strict aliasing issues and found a few.. I'm only rebasing this on top of master. No changes made since March 5th.. I've fixed the issue.. @aurelienpierre I'm already working to clean up this mess, see:\nhttps://github.com/cryptomilk/darktable/tree/master-cmake\nHowever this needs a lot more work.. If we require C11 we should really require it and not fall back to C99, this doesn't really work .... We should choose one, if one uses features of C11 they wont work in a C99 fallback!. Only the XMP?. You can find it here: https://xor.cryptomilk.org/pics/x/2018-07-25__7M33756.ARW.xmp. I can roll back to the version I edited with an older darktable version, if you want that .... https://xor.cryptomilk.org/pics/x/ now has new and orig. I've did the edit of that picture last year. Today I've opened the collection and noticed that the image is too bright now. Then I clicked through the history stack and when I deactivated the haze removal, it went back to normal. Then I just turned the haze removal on and off and saw that the module shifts the histogram to the right (see screenshots).. This is the untouched file, I just checked out from my git tree: https://xor.cryptomilk.org/pics/x/2018-07-25__7M33756.ARW.xmp.orig\nWith that file I get a too bright image cause by the haze removal.. Do you want the RAW file too to reproduce it?. With 2.6.1 everything is fine: https://xor.cryptomilk.org/pics/x/darktable_2.6.1_haze_removal.png. OK, in darktable from master, if I go back in the history stack and click around at one point it is fine. But then as soon as white balance is activated (which comes after haze removal in the history) it is going mad.. Ok, I can reproduce it.\nGo back in the history to 6 and apply 7 and 8. Then haze removal is working. Now apply 9 and 10 (white balance) and it is going to bright.\nThe tone curve in 6 seems to reset it to a normal state, and the white balance in 10 seems to mess it up.. I can send you the RAW it might be dependent on that data.. I can try doing a git bisect. It normally works fine as long as you don't use merge commits.. If you run the script out of the directory and nothing is installed in the system, dt-gen-noiseprfile will compile the tool automatically, see subr.sh. I did want to break running the code as it was before, it is called backwards compatibility ;-). Yes, I want backward compatibility. These changes will not be release before Christmas this year and I have to tell people how to do it in my tutorial. I don't want to describe 20 different ways. It should be easy as it was an easier in future.. Normally I always do that. project() gives you some nice variables _SOURCE_DIR and _BINARY_DIR which are quite handy if you have headers in that directory and you need to include them somewhere else. However we don't use it so I can remove it.. Normally I always do that. project() gives you some nice variables _SOURCE_DIR and _BINARY_DIR which are quite handy if you have headers in that directory and you need to include them somewhere else. However we don't use it so I can remove it.. Nope, MinGW is UNIX and WIN32 ;-). I can remove that if you don't want that.. Ok, will remove it.. I wanted to keep backwards compatibility, but then I will remove it.. I did not see that there a < 0 check in the code for those values. If such a check is missing then I might be wrong ...\nHowever the xmin,xmax,ymin,ymax only seem to be positive numbers or 0.. The casting should be fixed here.\nCLAMP((int)(255.0f * logf(k/255.0 * (base_log - 1.0f) + 1.0f)), ...). As the strict aliasing issues have been fixed, we can turn that on. I've fixed the commit message.. But how should we find and fix the issues in the source if we hide/disable it?. Ouch. Yes, you're right. Fix pushed.. Fixed, thanks!. Fixed, lets see.. ",
    "sjjh": "\nWe are currently in feature freeze. I will have a look at this once we got the release out.\n\n@houz I know, it's feature freeze again. Nevertheless I'd love if you could look into it in January maybe. :) Thx!. ",
    "zaltysz": "@boucman. Use Process Monitor (https://docs.microsoft.com/en-us/sysinternals/downloads/procmon) to capture and log what the installer does and on which path it exactly fails.. ",
    "scit2010": "\n. ",
    "mepi0011": "Vielen Dank f\u00fcr deine R\u00fcckmeldung,\ndie Anmerkungen werden umgehend einarbeiten!\nIm Letzen \u201ecommit\u201c hatte ich vermerkt, dass es sich um eine grobe \u00dcbersetzung handelt.\nLeider ist dies nicht sofort ersichtlich. Besser w\u00e4re gewesen, dies in der Bemerkung des Pull-Request zu beschreiben. Muss mich noch in den Ablauf von GitHub vertraut machen.\nMein Vorgehen w\u00e4re nun den Rest noch weiter so zu \u00fcbersetzten und dann den Text St\u00fcck f\u00fcr St\u00fcck zu korrigieren.\n. F\u00fcr die \u00dcbersetzung habe ich noch Fragen:\n- Die Ausgabe meiner man-pages (man darktable) ist Englisch, daher kann ich diese nicht f\u00fcr die \u00dcbersetzung verwenden. Gibt es dies auch auf deutsch? Muss ich unter Linux etwas nach installieren?\n- darktable auch am Satzanfang klein schreiben? (Ich w\u00fcrde es dann Gro\u00df schreiben)\n. Anbei ein paar Begriffe die ich nicht \u00fcbersetzen kann, da ich die korrekte Bedeutung nicht kenne. \n\n\nkeystone\n\n\nmatch greens (Kapitel 3.4.1.8 Seite 82)\n\n\nLuma\n\n\nShiftN\n\n\ndcraw\n\n\nprimary, was ist das f\u00fcr eine Taste (siehe Kapitel 8.4 des englischen Handbuch)\n\n\nWas ist die \"period\"-Taste?\n\n\nAus diesem Grund ist ab Darktable 2.0 die 32-Bit-Unterst\u00fctzung soft-deprecated. --> was ist soft-deprecated bzw. wie kann der Satz korrekt \u00fcbersetzt werden?\n\n\npre-demosaiced camera raws\n\n\nAdditionally, darktable supports a special demosaicing algorithm\u00a0\u2013 passthrough (monochrome). Hilfe beim Korrekturlesen ist w\u00fcnschenswert, da ich Teilweise meine Probleme mit den englischen Fachausdr\u00fccken habe (z.B. Pixelpipe). F\u00fcrs Erste w\u00fcrde ein Feedback bis Seite 71 gen\u00fcgen, damit ich die Korrekturen einpflegen kann.. @chrik5, vielen Dank f\u00fcr die Unterst\u00fctzung. Gerne kannst du die Anmerkungen direkt ins PDF eintragen. Alternativ kannst du auch die Korrekturen in der Datei de.po im Verzeichnis /darktable/doc/usermanual/po/ eintragen. Zum Bearbeiten der po Datei einfach ein Programm wie poedit verwenden. Die ge\u00e4nderte po-Datei bereitstellen und ich mach einen Vergleich mit meiner po-Datei. \n\n\nMfG\nPierre. @chrik5 Deine Anmerkungen habe eingearbeitet. Leider hatte ich in den letzten Tagen wenig Zeit weiter am Dokument zu arbeiten. Gibt es von deiner Seite weitere Anmerkungen?. @chrik5 Danke f\u00fcr die Anmerkungen, diese werde ich die n\u00e4chsten Tage einpflegen. Kannst du mir deine ge\u00e4nderte po-Datei bereitstellen, ggf. kann ich diesen. \nPS: In meinem Github-Profil findest du meine E-Mail Adresse.. @chrik5, die Zeilenumbr\u00fcche spielen in der po-Datei keine Rolle. Beim Komilieren des User Manual werden diese automatisch gesetzt, \u00e4hnlich wie bei Latex. Zum Bearbeiten der po-Datei verwende ich Lokalize, dies unterst\u00fctzt die Funktion eine zweite po-Datei zu laden und mit der \"Haupt\"-Datei zu vergleichen. Unterschiede k\u00f6nnen einfach \u00fcbernommen werden. Du kannst mir gerne zum Test deine po-Datei senden.. Welche Fehler meldet dir 'make darktable-usermanual-de?\nWenn ich commits / branches zusammenf\u00fchre, l\u00f6sche ich immer den Ordner build und erstelle diesen neu (mkdir build / cd build / cmake .. / make darktable-usermanual-de).\nIm commit (26fd20a) habe ich bereis an einigen Stellen RAW in Raw und LW in EV ge\u00e4ndert.\nZum Thema der Schreibweise Raw vs. RAW hatte ich es vor einiger Zeit bereits mit @houz.\nDie korrekte Schreibweise ist Raw-Format, Raw-Datei, Raw-Foto, etc. , allerdings w\u00fcrde ich an einigen Stellen eine Ausnahme machen (siehe  Bild).\nBez\u00fcglich EV w\u00fcrde ich mich an die darktable GUI halten und die gleiche Schreibweise wie dort verwenden.. Hallo @chrik5, \ndein Comment bez\u00fcglich des Moduls Belichtung und automatik Mode verstehe ich leider nicht. Du beziehst dich zwei mal auf das Modul Belichtung.\nWenn im Modul Belichtung der Modus automatisch ausgew\u00e4hlt wird, \u00e4ndert sich bei meiner verwendeten Version 2.4.2 wohl die Belichtung (zu erkennen im Histogramm). Hier findest du einen Bild des automatik Mode.\n. Hallo @thraemos,\nUnterst\u00fctzung bei der \u00dcbersetzung ist herzlich Willkommen!\nDa die deutsche \u00dcbersetzung  noch nicht in darktable-org/darktable \u00fcbernommen wurde, ist es am besten du machst ein Forg meines Repostitory und \u00e4nderst dort. Wenn du Hilfe ben\u00f6tigst oder Fragen hast z.B. welche Dateien zu \u00e4ndern sind oder wie das \u00fcbersetzte Handbuch erstellt wird, kannst du mich auch direkt kontaktieren. Meine E-Mail Adresse findest du hier.. Pull request includes other files then de.po! New Pull Request will be started with only the relevant file.. Since a few days I am learning DocBook for a better understanding of process and syntax.\nI noticed the commands keysym, keycap and keycombo. These commands can be used to mark key combinations, keys and their labels in the text.\nAn Example can be found here: https://tdg.docbook.org/tdg/5.1/keycombo.html\nThe display of the key combination and keys is then defined by the stylesheet.\nI can't predict which effects this has on the online html documentation.\nWould this be a way to identify the keys and keyboard shortcuts? If ok I can update the documents.. @houz : make darktable-usermanual-dtorg ends in following error:\nFehler: Hauptklasse com.icl.saxon.StyleSheet konnte nicht gefunden oder geladen werden\nmake[3]: *** [doc/usermanual/CMakeFiles/darktable-usermanual-dtorg-en.dir/build.make:62: doc/usermanual/dtorg/en/index.html] Fehler 1\nmake[2]: *** [CMakeFiles/Makefile2:8425: doc/usermanual/CMakeFiles/darktable-usermanual-dtorg-en.dir/all] Fehler 2\nmake[1]: *** [CMakeFiles/Makefile2:8158: doc/usermanual/CMakeFiles/darktable-usermanual-dtorg.dir/rule] Fehler 2\nmake: *** [Makefile:2656: darktable-usermanual-dtorg] Fehler 2\n\nAny ideas?\n. @houz: make darktable-usermanual-dtorg works now!\nThe commands keysym, keycap and keycombo are used without error messages when creating the PDF manual as well as in the HTML output.\nAn Example of a docbook with these commands can be found here: https://tdg.docbook.org/tdg/5.1/keycombo.html. What exactly doesn't work?\nCan you be more specific, please?\nI can't recreate the error, because the build process on my PC runs without error messages, I just tested it again. Please see my comment of 1 May.. too many conflicts at the moment. Maybe in future when docbook 5  is more common.. I'm not sure how to spell it. Suggestion: Ctr + right-click. In the whole books the letters of keyboard shortcuts are always written in capital letters. In addition, these are also shown as uppercase letters on the keyboard. Here are a some examples:\nWindows: https://support.microsoft.com/en-ca/help/12445/windows-keyboard-shortcuts\nGnome: https://wiki.gnome.org/Design/OS/KeyboardShortcuts\nKDE:   https://docs.kde.org/trunk5/en/applications/fundamentals/kbd.html\nMacOS: https://support.apple.com/en-ca/HT201236`\nCross Platform documentation example: Adobe: https://helpx.adobe.com/photoshop/using/select-mask.html. The English Wikipedia distinguishes between the space key (spacebar) and the space character\nhttps://en.wikipedia.org/wiki/Space_(punctuation)\nhttps://en.wikipedia.org/wiki/Space_bar. Today I saw that in the darktable settings the shortcut keys for single keys are also capitalized. (german darktable version). Maybe I do not have a clue today.\nI think we're talking about different things. In the manual, we should replace space with spacebar, because we are talking about the key and not the character. According to wikipedia, space is the character that is written when the spacebar is pressed. \nThe keys Ctrl, Alt and Shift are function keys that do not write any characters but only make a function e.g. to write an character as capital.\nLong story short, in my opinion it is right when we write:\nIt is turned on/off with key accelerator Ctrl + F\n\nor\nMouse scrolling while holding the control key pressed gives an extended zoom range between 2:1 and 1:10.\n\nWhile writing this comment I noticed that sentences like these should be adapted (I can still adapt this):\nFully zoomed-in image view while holding down the Ctrl + Z key with indication of the sharp areas in focus.\n\nto\nFully zoomed-in image view while holding down the key sequence Ctrl + Z with indication of the sharp areas in focus..\n",
    "chrik5": "Hallo, \nIch bin noch nicht weit gekommen (Seite 1-8): https://wolke.fagetum.at/s/OaDUWoXEQu6bqaN\nW\u00fcrde das weiter so passen mit den Anmerkungen im PDF?\nChristian. @mepi0011 Geht mir genauso mit der Zeit und ich hab da noch direkt im .po weitere Korrekturen gemacht. Vor dem 15.2. kann ich aber nichts liefern. Ich muss noch schauen wie ich meine \u00c4nderungen \u00fcber github einpflegen kann. Ich komme immer nur 1-2 Stunden zum Durchschauen und da w\u00e4re es gut kleine Korrekturen/\u00c4nderungen gleich hier zu ver\u00f6ffentlichen um nicht doppelt zu arbeiten.. @mepi0011 So mit dem Editieren des de.po hatte ich keinen Erfolg. Die \u00c4nderungen lassen sich nicht richtig nachvollziehen, weil alle Eintr\u00e4ge durch den Editor ge\u00e4ndert wurden. \nHier die n\u00e4chsten Seiten 9-25 mit Anmerkungen. Schneller und mehr schaffe ich nicht ...\nseiten_9-25.pdf\n. @mepi0011 de.po habe nach ein paar Seiten und ersten Versuchen nicht mehr weiter aktualisiert. Der Editor poedit hat glaube ich alle Umbr\u00fcche neu gesetzt :-(. Keine Ahnung wie man *.po editieren kann ohne das gleich alles ver\u00e4ndert wird. Es gibt auch online Editoren. Vielleicht geht es mit denen leichter?. Hello @aurelienpierre,\nOrdinary user here with no programming skills, which really appreciates the time you spend for dt.\n\nCurrently, the histogram is an active area where one can drag the shadows and the highlights to quickely edit the exposure and black level. The thing is, the setting increments are rather coarse, not configurable (except in darktablerc, when you know it), and I discovered this feature by accident.\n\nI use this quite frequently as it is much faster than searching for the exposure module. Would be nice to have more of this easy access features in dt.\n\nI also would like to remove the EXIF settings display, because it's redundant with the EXIF box on the left panel.\n\nLeft panel is most of the time collapsed in my case.\n\nAny objection ?\n\nAsking here won't give you much feedback from users. \nI remember a few basic tutorials which mention this feature as nice addition. \n\n(except in darktablerc, when you know it)\n\nWell that rc's are linux style and I touch darktablerc very seldom. But since dt is avaliable for others OS an easier handling of settings in darktablerc might help user to find all this hidden features. Recently, more settings were added to the preferences dialog. Maybe it would make sense to expose most non critical darktablerc settings in some extended preferences/config dialog?\nThanks,\nChristian. > > Left panel is most of the time collapsed in my case.\n\nThe real question is: are the EXIF info useful in the histogram ? My feeling is I don't care about the camera settings at all during retouch. But I really like a clean UI to focus on the picture.\n\nThat is definitely true. I rarely look at that figures. But for others this might be different. What about those who do bracketing? Or beginners which disover all this relationships? You have a single place to see the values and histogramm.\n\n\nI use this quite frequently as it is much faster than searching for the exposure module. Would be nice to have more of this easy access features in dt.\n\nAnd using it in a blind fashion does not bother you ? \n\nNo, it is for quick adjustments as @theres already mentioned most of the time. Eg. If I have many images from a soccer game and some are maybe underexposed I can quickly check if the image will be a keeper or not. Using the mouse wheel increments are fine for me. \n\nIf so, did you consider setting a keyboard shortcut\n\nWell I use the common shortcuts all the time and lately started to assign them for specific modules. But you will run out of shortcuts soon, if you use shortcuts for all modules? \n\n? I'm asking because, everytime I'm \"using\" the histogram to set the exposure, it's a touchpad accident while reaching for the color channels or waveform. So, it annoys me more than anything.\n\nNow we are getting closer. Touchpads are a pain for me. Whenever possible I use a mouse with scroll wheel. So you are changing exposure accidentally. That is annoying of course. So this calls for another option to unlink histogramm and exposure module ;-).\noff topic: Working all day with PC requires some alternative input devices on the long run. My naive notion dreams from midi controller support. But for now the combination of mouse + mouse wheel and keyboard shortcuts is fine too.. Works now! Thanks!. short: The strange behaviour seems to start if I use ctrl+c and ctrl+v to copy a history stack from one image to another? \n\nAre you able to reproduce this issue each time? \n\nYes, after two or more reboots it is still there. Also removing the whole /opt/darktable dir, building from clean build dir and reinstalling makes no difference. \nI forgot to mention that I got skulls after removing images within darktable, closing and opening darktable again. It feels like if the database loses its memories. \nI startet to test this on another machine to exclude hardware issues using the same configs and database.\n\nA precise sequence maybe?\n\nI'm thinking on this, but I'm not aware of any specific order/sequence? \nAfter some back and forth on the other machine: \nIt seems to start if I use ctrl+c and ctrl+v to copy a history stack from one image to another? \nCopying the history stack works fine, but coming back to the images after some editing of other images resets the history stack to the previous state. This happens also for the image where the history stack has been copied from. Other edits not involving any copy and paste of history stacks are effected as well.\n. ",
    "Hofer-Julian": "Hallo!\nIch w\u00fcrde euch gerne bei der \u00dcbersetzung des Manuals helfen. . Sehr gut!\nWerd ich machen, danke! . ",
    "garrett": "Wow! Thanks! This will help me and a few friends who are all switching away from LR.\n(FWIW: It was long overdue for me; I kept around a proprietary OS just for LR; I use Linux and FOSS for everything else.)\nDoes this also import locations like city, country, etc.? When trying to bring over Lightroom data to Darktable via XMP, it seemed that some of my metadata, most notably the location, was ignored.. (I'm happy to contribute some of my XMP files somewhere if you'd like some examples.). Oh that's a shame. Locations are an important part of IPTC, which is integrated into EXIF and XMP, and I'm pretty sure most other photographers also like to tag where their photos were taken.\n(Ah well, sorry for being a bit off-topic. Thanks again for your contributions!). ",
    "luzpaz": "\nSorry, we are in string freeze right now. If you split this up we would accept all changes that are either source/comments or user manual.\n\nI will split up the PR. Closing PR in favor of #1577 and #1578 . please review. @houz it's my way of giving back. please review this revision. @houz is this a correct revision ? or shall i exclude it?. apologies. this one got past the goalie. Will remove and repush. . ",
    "oexler": "Thank you for your input. \nI tried to implement your remarks.. I tried a quick fix for the color labels, but noticed that it would need more changes.\nAs currently when you select a color label this filter is included in the darktable.collection->where_ext. So when I update the collection module it is limited to this color.\nIt is the same issue when you switch to a previously created rule.\nWhen I have more time perhaps I try to see if it is possible to split the current rule from where_ext.. I have changed where_ext from string to array of strings, so I can exclude the current rule from it.\nAlso the collect module should update every time the collection is updated.. I have made a small change to make the behaviour of the list more consistent with the tree view.\nThe list now only gets filtered when something is typed in the entry box.\nThis way it is easier to switch between different entries.. The problem was, that every change to the collection triggered an update for the collect list.\nI have added a boolean to prevent an update when an entry is activated.\nAdditionally I added a call to scroll to the selected entry when the collection is updated from somewhere else or when switching between rules.. What are the next steps to get this pr merged? \nShould I rebase or merge master to incorporate the changes for local copies? There seems to be no conflict but I could probably also show the image count.. I have rebased the pr. normally I would squash the changes to one commit, but I think it is easier to follow, as it incorporates different changes.\nIt would be nice if you talk about this pr on IRC.. Are there any open questions or comments?. I don't know how much of the functionality is reusable in a separate widget.\nCurrently a GtkTreeView widget is used to display the tree. The tree_view function from the collect module gets the strings and splits it depending on the type of data.. I have removed my skipnextupdate flag and instead disconnect from the signal.\nI have created dt_control_signal_(un)block_by_func(). I don't know whether a more generic (un)block_matched would be better.. I think I have completed the remaining change request.. I wouldn't make the current indicators draggable.\nWhen I first used darktable I didn't even find the current indicators as they are not were one would expect them. When I noticed them I thought they were for dragging the side panels. \nAlso when the borders are clicked the panels collapse. So I don't know how dragging should work.\nIn darkroom mode there currently is a grey border around the image. Perhaps it is possible to put the scrollbars there and only make them visible (perhaps by just changing colors) when hovering.. I have enabled scrollbars only for the lighttable now. As a consequence I've re-added the indicators.\nI still don't know how draggable scrollbars on the outside should work, at least if one still wants the functionality to hide the side panels by clicking on the arrows.\nAlso I think according to gestalt principles the scrollbars should be close to the subject.. I have made the scrollbars configurable for those of you who don't like having them.\nIn the GUI options there is now the setting for  'show scrollbars for center view':\n- 'no scrollbars'\n- 'lighttable'\n- 'lighttable + darkroom'. I already had the edge scroll indicators removed before I added the possibility the disabled the new scrollbars for the tables.\nDo you think they should be removed, when the corresponding scrollbar is shown? \nI thought they didn't bother me that way, and it's more consistent if you just enable them for lighttable.. The space is used anyway, as this is also where you show/hide the side panels.\nSome people wouldn't use the new scrollbars for darkroom mode as they don't want to lose those pixels.. I guess you should revert the merge for now. \nI will try to look into it at the weekend, but I don't have the packages currently installed to enable map view.. I commited some fixes to my branch, but they don't appear here. Probably because it is still marked as merged. Do I have to create another PR?. Nope that did't work. I think -f is only needed when the push gets rejected.\nDid you revert the pull request or the merge?. I have some ideas of what could be done. But I don't know which approach others like.\nBut I think a change is needed for HiDPI screens to prevent calculation of four times the number of pixels.\nDenoising should also be closer to the final result at over 100% zoom.. I get an error when trying to compile on windows.\nerror: left shift count >= width of type [-Werror=shift-count-overflow]\nI think both (1l << 32) should be (1ll << 32). I couldn't find any reference to the center widget in slideshow.c, so I just compiled darktable without my changes and I also get 6 times\n(darktable.exe:20340): GLib-CRITICAL **: g_strlcpy: assertion 'src != NULL' failed\nso I don't think this message has anything to do with this pull request.. \n. I have rebased on master and made small fixes.\nThe compile error is fixed and the filmstrip should be hidden when you restart dt in file navigatior mode.\nRated and rejected images are now filtered but this is probably hacky. The problem is, that when the filmstrip is active it uses the same keyboard shortcuts as lighttable. I don't know whether it would be better to disable these bindings or to find a way to use the same functions for both modes, so the code is not duplicated.. Do you have an idea how to deal with the hotkeys for lighttable/filmstrip?. > What's the issue with the hotkeys?\nLighttable and filmstrip use the same hotkeys. I think even when filmstrip is hidden, those functions are called e.g. for ranking.. Yes. At least this was what i was trying to accomplish.. Perhaps I don't understand it right. But is there any benefit to calculate all modules on an upsamples image, instead of applying it to the full (100%) resolution und then just scaling the output? \nI think there is no valuable information added by upscaling.. If there is better option for the final scaling I have no problem with it.\nBut applying filters on pixels that were not in the original images still makes no sense to me.\nimho at 200% zoom it should just display the pixels at twice the size and not necessarily smooth them out. The preview quality should not be better then the exported 100% image.. DT_COLLECTION_PROP_{DAY,TIME} are now handled by tree_view() instead of list_view(). When the signal is raised by other parts at the same time, the module should rebuilt its list.\nThe flag is just there to prevent it once, when something is selected from the list.\nIf I were to block the signal, there would be no update from another part calling the update concurrently, if I understood correctly.. Because I only know the count for the full path and the common path parts were already added to the tree before.\nI could also recursively set the count for the parents of the current leaf, but then this function would be even longer. The callback is doing exactly the same and I think by splitting the code is easier to understand.. What would be a better approach?\nSplit the current scaling to before and after the other modules?. switch_layout()_to is called in expose() if(lib->layout != new_layout). lib->layout is initialised to -1. So it is called the first time in expose.. It is not needed, but I thought it would be better to use control signals e.g. DT_SIGNAL_COLLECTION_CHANGED instead of  calling it by myself. So perhaps the number of redraws are reduced and I know whether all signals are raised properly.. ",
    "piterdias": "I used to work with digiKam and the tag filtering (right panel) only works properly if all nodes are added. If I add A|B|C to the sidecar, digiKam doesn't show any picture if I filter by A or A|B. I need to add A, A|B and A|B|C to make good use of tag filtering.\ndarktable tag filtering is much better, but I decided to add this feature to help using the sidecar files in digiKam.. Not a problem. Compiling darktable is so easy that I can keep the change for myself. \ud83d\ude0a\nShould I cancel the request to clean up the list of pull requests?. ",
    "eeadpi": "\n. \n",
    "Kabouik": "I hope this will get merged. I often have to review thousands of pictures (either parent directories when reviewing one full year, or astrophotography and time lapses which produce hundreds of pictures in just a couple minutes), and the Zoomable ligt table or Folder view with just PgUp/PgDn or mousewheel do not provide satisfactory ways to quickly navigate through. If the scrollbars where interactive and not just indicators, this would be a non issue.\nI like the scrollbars being located between the light table and the side panel, it makes sense and avoids any ambiguity with the panel's own scrollbar in my opinion.\nI'll keep an eye on this pull with fingers crossed!. I concur with this. My feeling is the scrollbar next to the content it scrolls is better and less\nambiguous. As stated by @oexler, it's also better for compatibility with the side panel toggle\nbutton.\nPeter Budai notifications@github.com wrote:\n\nI'd love to have a discussion on what is the best solution from the end user perspective. I\nclearly remember how confused I was when I first saw two scroll bars on the right (at least I\nthought they are), and then it turned out that you cannot really use the outer one, as when you\ntry to click on that and drag, actually it hides the right panel. I find it more natural to have a\nreal scroll bar next to container which you can actually move with the scroll bar - I believe this\nis what @oexler was trying to achieve.\n. Hope this will be merged soon, I'm really looking forward to having scrollbars in the lighttable. Thanks @oexler.. I have been waiting for this feature since I saw this message from @rabauke on the list a long time ago. Eagerly looking forward to trying this when it is merged, and quite happy to see that the project has not been abandoned. Thanks for your work, hope merging won't require too much additional sweat.. \n",
    "kelvie": "FYI I fixed the comments above (can't see my replies to the inline comments anymore it seems, when I fixup and re-push). Going to close this and put in all the other monochrom fixes in the same PR.... I also added a few strings that may need to be localized.... I've fixed it as far as I can see, invert and cacorrect no longer auto apply on reset.\nBy the way, thanks for all the hand-holding @LebedevRI, I really appreciate the helping, as this really helps make my monochrom workflow much more enjoyable!. It appears the white balance module gets messed up when switching from a monochrome image -> a colour one in darkroom mode. I'll try to fix that as well.. In this case, I just fixed reload_defaults to un-hide the enabled button. It appears that if we set anything in the module, it stays set when you browse to the next image.. (getting a bit side tracked here) but looking at reload_defaults() in colorin.c, it doesn't change anything in the module, and replaces all of the params and default_params with a fresh copy using memcpy(3), so I don't think it'll use one of the previous values.. Yeah, I pushed the commit (I just amended the last commit).\nWould it be better if I just added additional commits each time?. @LebedevRI  @dtorop both default_enabled and hide_enable_button keep their old values when switching images in the darkroom view, that was the bug I was trying to fix.\nWe need to set all values in reload_defaults to have switching between images work in the darkroom view.. That is, the test case is:\ngo to a monochrome raw in darkroom, then click on a non-monochrome raw, and the white balance will be turned off. @LebedevRI Yep, that fixed it. Just setting hide_enabled_button works too, but it's better to be safe.. Did you mean if reload_defaults isn't called, or if prepare_matrices isn't called?\nMonochrom raws don't have colour matrices anyway,  so all prepare_matrices does for monochrom raws is write an error messas.\nI'll fixup the other stuff.. Fixed. I personally think it should be disabled.\nWhere are the default module orders defined, so I can go through them? Is it develop/format.c?. Oh, found it, it's in iop_dependencies.py. Interesting, I'll fix this.. Hmm, I'll see what's going on here as well.. OK, I think I did this right; just setting the piece->enabled = 0 when the button is disabled in commit_params, which is what is done in cacorrect and rawdenoise for non-raw images.\nHowever, after resetting, (this was the case before), this adds a history item, and it doesn't say (off); is that a bug? It seems the history item is added in the _reset_label_callback for all iop modules, unless I'm mistaken.. Yeah the gui_updates was being called before all this was initialized, so I fixed this in the latest patch.. ",
    "ramuntcho": "Hello,\nSorry if I did not follow the rules, I didn't know how to ask about a Mac version.\nBest regards\nChristian\n\nChristian O\u00efh\u00e9nart\nSEM-Logistique\nEtat de Gen\u00e8ve - Service Ecoles-M\u00e9dias\nRue des Gazom\u00e8tres 3 - CP 241 - 1211 Gen\u00e8ve 8\nT\u00e9l. 022 388 63 76\nchristian.oihenart@edu.ge.chchristian.oihenart@edu.ge.ch\nLe 8 janv. 2018 \u00e0 15:31, Tobias Ellinghaus notifications@github.com<mailto:notifications@github.com> a \u00e9crit :\nIs this supposed to be a pull request? Or just chatting?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/darktable-org/darktable/pull/1620#issuecomment-355981762, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ACWTyRY3T3C4wWNBSaaIEbZL1igDZQnDks5tIibRgaJpZM4RWbRh.\n. Thanks for your answer.\n:-)) Christian\n\nChristian O\u00efh\u00e9nart\nSEM-Logistique\nEtat de Gen\u00e8ve - Service Ecoles-M\u00e9dias\nRue des Gazom\u00e8tres 3 - CP 241 - 1211 Gen\u00e8ve 8\nT\u00e9l. 022 388 63 76\nchristian.oihenart@edu.ge.chchristian.oihenart@edu.ge.ch\nLe 8 janv. 2018 \u00e0 16:32, Tobias Ellinghaus notifications@github.com<mailto:notifications@github.com> a \u00e9crit :\nNo worries. The Mac dmg will be done when it's done. All I can tell you is that there is only a single contributor that even uses a Mac, and we have to rely on him making the package. Until then there is nothing we can do to speed things up. Sorry.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/darktable-org/darktable/pull/1620#issuecomment-355999021, or mute the threadhttps://github.com/notifications/unsubscribe-auth/ACWTyY758ltPVV2m9ILDD2fSb8dagQE3ks5tIjUFgaJpZM4RWbRh.\n. ",
    "brxxm": "Indeed, corrected (I hope).. ",
    "fidergo-stephane-gourichon": "From what we discussed on IRC, this could cause problem in the past but is now supported. \"Raw denoise\" module has allowed blending for a while. More precisely since:\ncommit 54403ca368fbf7073035a8b49c3932fee0c202a9\nAuthor: Henrik Andersson hean01@users.sourceforge.net\nDate:   2011-03-24 21:25:45 +0100\nAdded blendop support to rawdenoise.\n\n. # Upside\n\nI think that at least the \"Exif.Photo.UserComment\" reference is great so that those who like to fiddle with their exif data know what goes where.\n\nYes! The rationale for including the technical name of exif field is to provide attract search engines when they are asked requests like \"darktable exif usercomment\".\nClearly, people interested in knowing where this field is available in darktable will be glad to find this information.\nAny downside ?\n\nI wonder if this additional explanation is too technical.\n\nThe fact is, Darktable is not for everyone, it already selects an audience interested in more than point-shoot-share.\nWhat would be an actual downside? Those using darktable and reading the manual, will they be driven off by the mention of an Exif field name?\nPrecedent: how Apple does it\n\nWhy not just: (long text which avoids to explicitly mention the exif field name)\n\nThis reminds me about Apple allowing SSH access to Mac OS X machine. Apple is very wary about feeling \"easy to use\" and \"not too technical\".\nVery first release of Mac OS X did not dare mention \"SSH\" in preference panel. Instead there was a circumlocution. That made things difficult for people who actually needed SSH, because they did not recognize it was indeed SSH.\nThen Apple figured out it was okay to call a spade a spade. From that time, SSH was always explicitly mentioned in \"Preferences\" panel, in firewall settings, in knowledge base.\nMac OS X preference panel image (courtesy stocksy.co.uk - Mac - SSH on Mac OS X):\n\nMentioned in macos - Configure OSX Firewall to Allow SSH Server? - Super User:\n\nFrom Apple knowledge base article: macOS Sierra: Allow a remote computer to access your Mac:\n\nIf you allow remote login, you can use Secure Shell (SSH) to log in to your Mac from another computer.\n\nConclusion\nI believe it's okay to mention \"Exif.Photo.UserComment\" in manual, as it will not drive off users, yet help people who needs this information in the manual.\nThank you for your attention.\n. Done, see new commit. Thanks Ulrich for notifying. Future contributions will have correct quote mechanism without asking.. ",
    "mpaglia0": "Thank you indeed\nIl 21 gen 2018 18:46, \"Tobias Ellinghaus\" notifications@github.com ha\nscritto:\n\nMerged #1633 https://github.com/darktable-org/darktable/pull/1633.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1633#event-1434138970,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AUQg1CVpYN_X6vVO4qInZ0ku3r_4hGRlks5tM3f-gaJpZM4Rl2gs\n.\n. In data luned\u00ec 5 febbraio 2018 15:17:20 CET, Tobias Ellinghaus ha scritto:\nSomething went wrong there. What is the PR about?\nSorry my mistake!\nI will send soon a PR for two .po files\n\n. In data luned\u00ec 5 febbraio 2018 15:36:23 CET, Tobias Ellinghaus ha scritto:\n\nOne remark in general: Please state in the commit messages what they are\ndoing. \"fixed typo\" is not good. At least mention that it's about the\nItalian translation. Otherwise it's a PITA to go through the commit logs\nwhen assembling release notes later.\nThank you, please apologize\nMaurizio\n\n. I will now stop waiting your approval for the changes done till now.\nThanks. ",
    "mchwalisz": "Created redmine bug at https://redmine.darktable.org/issues/12201. ",
    "teemodk": "Since custom (modified) profiles are not accepted, which is fair enough, I will just close this. Sorry for the time lost. . I don't think so, there is only GR besides this new GR II. As far as I know the maker entry is the same for both cameras. EXIF say \"RICOH IMAGING COMPANY, LTD.\"\nAre you sure the GR was ever tested? . I will do this. Am currently working on a better finetuned profile. . In case GR need the simple \"Ricoh\" header, I will have to add above as a separate entry, is that acceptable? . ",
    "jothalha": "I don't completely agree with you there, since a character isn't necessarily added, but it's a minor detail anyway.. ",
    "trougnouf": "Referenced on https://redmine.darktable.org/issues/12092. @LebedevRI Can you review and/or merge? I've been using it without issue.. Done. I added redirects with CURLOPT_FOLLOWLOCATION and tested for successful redirection with the old URL, and I made the search URL into a flexible config key (plugins/map/geotagging_search_url) which I tested as well (default setting, breaking it, restoring it).. @houz Done, thank you for your review. I also added a timeout because Darktable would otherwise freeze when the search server isn't responding (such as is the case when I try to test it now).\nedit: tested again now that the search server is responding, geo-search still works.. That does fix the scrolling behavior, thank you :)\nThe image still ends up very light, and I don't seem to be able to select a particular area when I click on optimize luma, is that normal behavior and I should wait for the documentation and close this or it's a potential bug?\n\n\n. Thank you, I got it to work well :) There still seems to be an interface bug, clicking on \"optimize luma from patches\" optimizes over the whole image, with seemingly no way to select a patch (though it often appears to work when I click on it and select an area before it's done \"working...\" the first time after a reset). The individual selectors (s.a. \"factor\") on the other hand remain in selection mode after performing their computation, allowing the user to select a different patch.\nThank you! That picture is my first experience with the filmic module and it's performing great! It's taking some used to and the help of your very helpful documentation and I don't think I could have gotten such results with my previous workflow.\nIts \"black relative exposure\" optimizer doesn't work on some of my (X-Trans) photos (such as this one), it selects the minimum value, getting it to work usually involves deactivating the lens correction, rotating by 0.25degrees, or a slight crop, I will file a separate bug report once I have a few different sample raws (not doing a lot of photo editing atm because I have an upcoming exam).. Thank you!\nI've uploaded the RAWs I already found to be affected on https://drive.google.com/open?id=12tB8HNLdznfKqd5Ip8SUwnw3BTs82yFZ , I noticed that clipping the input gammut to sRGB and demosaicing in frequency domain chroma could also work, but no workaround works consistently (and so far denoising / hot pixels / defringe hasn't been a fix). It works great, thank you @edgardoh !. It works great, thank you @edgardoh !. Your patch works, thank you for the quick fix! The error was produced in https://github.com/trougnouf/dtMediaWiki export.. ",
    "crepererum": "What could be done to verify these curves? I also own a x100f, so if there's anything I can do, please let me know.. ",
    "rawfiner": "This pull request should be closed. The commits have been integrated in pull request #1774, and have been integrated in master.\nThanks again for this work. Hi\nI am (for now) only a user of darktable, so I guess my opinion is less important than the ones of the main developers, but here it is.\nI have tested the latest version of this. I personally think that this pull request adds a great tool.\nCombined with the color balance modification, it makes the handling of complex images with backlight much easier.\nI previously struggled to get some correct results on images with wide dynamic. With these modifications, I managed to get nice results a lot faster, and the results were better.\nI think this particular pull request has improved a lot, and it is now very easy (and very efficient) to use the module, with all the color pickers and the autotune button.\nI tested it on raw images that were noisy as well, and the module succeeded to find good values despite of the noise.\nLong story short, in my humble opinion, as a user, this module is a very valuable addition.\nI also would like to suggest that people who tested it a while ago give it another chance, to take into account the changes that Aur\u00e9lien made recently.. \nHere is an example of what we can do with it. In both images, there is a denoise profile in wavelet mode and blendmode color. Left is with these changes, by playing with the curve, and right is without. As we can see, the noise is much more fine grain on the left, whereas on the right is is coarse.\nThe changes made allow to preserve fine grain details while reducing coarse grain noise if the user needs it.. > Same remark here (see #1753), without tweaking the graphic, do we get the same result than before?\nYes, we get the same result.\nThe way it works is the same as in #1753.\nThis part of the code handles the \"all\" curve:\nfor(int i = 0; i < DT_IOP_RAWDENOISE_BANDS; i++)\n{\n// scale the value from [0,1] to [0,16],\n// and makes the \"0.5\" neutral value become 1\nfloat threshold_exp_4 = data->force[rawdenoise_all][DT_IOP_RAWDENOISE_BANDS - i - 1];\nthreshold_exp_4 *= threshold_exp_4;\nthreshold_exp_4 *= threshold_exp_4;\nnoise_all[i] = noise_all[i] * threshold_exp_4 * 16.0;\n}\nThe point gathered from the curve is squared twice. Thus 0.5 (the neutral value of the curve) is mapped to 1/16. We multiply this by 16, which maps our 0.5 to 1.\nThen, this number is used to multiply the noise threshold of the scale, and thus, if the \"all\" curve is flat the noise threshold does not change.\nThe code bellow does the same thing for each \"channel\" (we do not really have channel before demosaic, but each pixel has one of the 3 channels. Thus we use the green curve on \"green\" pixels, red curve on \"red\" pixels etc..)\nfloat threshold_exp_4;\nswitch(c)\n{\ncase 0:\nthreshold_exp_4 = data->force[rawdenoise_R][DT_IOP_RAWDENOISE_BANDS - i - 1];\nbreak;\ncase 3:\nthreshold_exp_4 = data->force[rawdenoise_B][DT_IOP_RAWDENOISE_BANDS - i - 1];\nbreak;\ndefault:\nthreshold_exp_4 = data->force[rawdenoise_G][DT_IOP_RAWDENOISE_BANDS - i - 1];\nbreak;\n}\nthreshold_exp_4 *= threshold_exp_4;\nthreshold_exp_4 *= threshold_exp_4;\nnoise[i] = noise_all[i] * threshold_exp_4 * 16.0;\n}\nThe switch case is slightly different for xtrans code, as in bayer code c==1 an d c==2 both corresponds to green, whereas in xtrans code, c directly corresponds to the pixel channel (0 for R, 1 for G, and 2 for B)\n. Sorry for the code formatting in the quotes, I am not sure yet how to refer to code from https://github.com/darktable-org/darktable/pull/1752/files. I have just found a bug for bayer: the colors are not always with same index. This means that with current implementation, sometimes the blue slider modify the green, sometimes the blue, etc.\nI will fix this as soon as possible.. The bug should be fixed now. I misinterpreted a variable, thinking it was representing a color, whereas it represented \"somewhat\" a coordinate in the top left 2x2 square of pixels.. Thank you for the code review ! :-). > Do you confirm that without touching the GUI to adjust all or R, G, B channels individually the actual result is exactly the same as before? That is, the wavelet strength is working as in the previous implementation. I'm asking, because a very important point here is to keep a simple usage for this module while allowing some more tweaking on the channels.\nYes. See this part of the code:\nfloat adjt[3] = { 8.0f, 8.0f, 8.0f };\nint offset_scale = DT_IOP_DENOISE_PROFILE_BANDS - max_scale;\n// current scale number is s+offset_scale\n// for instance, largest scale is DT_IOP_DENOISE_PROFILE_BANDS\n// max_scale only indicates the number of scales to process at THIS\n// zoom level, it does NOT corresponds to the the maximum number of scales.\n// in other words, max_scale is the maximum number of VISIBLE scales.\n// That is why we have this \"s+offset_scale\"\nfloat band_force_exp_2 = d->force[denoiseprofile_all][DT_IOP_DENOISE_PROFILE_BANDS - (s + offset_scale + 1)];\nband_force_exp_2 *= band_force_exp_2;\nband_force_exp_2 *= 4; // scale to [0,4]. 1 is the neutral curve point\nfor(int ch = 0; ch < 3; ch++)\n{\nadjt[ch] *= band_force_exp_2;\n}\nband_force_exp_2 = d->force[denoiseprofile_R][DT_IOP_DENOISE_PROFILE_BANDS - (s + offset_scale + 1)];\nband_force_exp_2 *= band_force_exp_2;\nband_force_exp_2 *= 4; // scale to [0,4]. 1 is the neutral curve point\nadjt[0] *= band_force_exp_2;\nband_force_exp_2 = d->force[denoiseprofile_G][DT_IOP_DENOISE_PROFILE_BANDS - (s + offset_scale + 1)];\nband_force_exp_2 *= band_force_exp_2;\nband_force_exp_2 *= 4; // scale to [0,4]. 1 is the neutral curve point\nadjt[1] *= band_force_exp_2;\nband_force_exp_2 = d->force[denoiseprofile_B][DT_IOP_DENOISE_PROFILE_BANDS - (s + offset_scale + 1)];\nband_force_exp_2 *= band_force_exp_2;\nband_force_exp_2 *= 4; // scale to [0,4]. 1 is the neutral curve point\nadjt[2] *= band_force_exp_2;\nBasically, before, adjt was always equal to 8.0f. In the new code, adjt has 3 values, one per channel.\nWe take the point value in the curve, which is 0.5 is curve is not moved, square that value, which gives 0.25, and multiply by 4, which gives 1.\nadjt elements are multiplied by this value, so multiplied by 1 if the curve is flat.\nThe for loop multiplies the adjt elements of all channels by the value computed from the \"all\" curve, while the code which is after the for loop multiply the adjt elements channel by channel, considering the R, G, and B curve. Sorry for the code formatting in the quotes, I am not sure yet how to refer to code from https://github.com/darktable-org/darktable/pull/1753/files. Thanks a lot for the code review.\nConcerning legacy_param, I had made a mistake: the curve parameters were sometimes not initialized. That is why it was crashing on presets.\nI created a new type for the old set of param, but used it for all older versions, as it was done like this before this pull request.\nAs the new members in the struct have always been added at the end, the type defined by the struct can be used on old params as long as no access to new members are made.\nHowever, I can understand that this results in code harder to read (and more risky to modify), so tell me if you want me to change this and define different types for all 4 versions.. @aurelienpierre, could you tell me in which cases the combobox is empty?\nThe crash with presets should be fixed now.. I do not think that it is possible to always open the same tab. The call to gtk_show_uri is responsible to open the web browser, and I do not know how it could be configured.. Thanks for the code review :-)\nI will update the code soon. These commits add the changes requested, and add a section id for color balance in the user manual so that it can be referenced in the url. I have pulled master, and rebased the branch on master. I have tested it, it works very well. Thanks for these changes. I tried to fetch this, and it compiled successfully on my linux mint.\nThis PR solves mistakes I introduced previously due to a bad knowledge of gboolean.\nThank you again for the changes, and my apologies.. I thought it was ready, but it seems it is not ready yet. Closing the PR for the moment, and I will fix everything and reopen it later.. The problem with usermanual should be fixed by commit 76a8216.. By the way, issue https://redmine.darktable.org/issues/8660 should be closed. Thank you for the feedback. I updated the luma preset so that it better preserves the sharpness.. @aurelienpierre I am not sure I understand your comment. The patchs are all \"equal\" regarding to the non local means algorithm: a patch which is more far away accounts as much as a patch which is very close to the central point. The only thing which impacts the patches weights is their similarity to the central patch, which is computed by doing the sum of the squared differences, for each pixel of the patch.. @TurboGit Thank you for the tests :-). @aurelienpierre No, all pixels of a patch are used the same way to compute the patch similarity.\nThe implementation by sliding window makes it impossible to have a different weight for each pixel, yet it is a very efficient way to compute the algorithm. That's why sometimes you get much better results with a patch size of 1 or 2 (which gives squares of 3x3 pixels and 5x5 pixels) instead of a patch size of 4 (which gives a square of 7x7 pixels).\nTo compute the weighted sum, the algorithm go through a list of all patches L inside a neighborhood, compare them with the central patch, and use this comparison to compute weights.\nThe change (2) removes the central patch from the list L: the central patch was previously compared with itself (of course the similarity was perfect and the weight was 1 for the central patch, which resulted in the fact that some pixels were left visually undenoised even if they had other patches that could be used: their weights were too small compared to 1).\nIt does not remove the central pixel from the similarity computation: it is necessary to keep it for this.. I am afraid it is normal to get artifacts using non local means, especially\nfor big patch sizes. That's precisely the reason why I changed the luma\npreset to use wavelets instead even for the luma denoising.\nI did not have time to test your image yet though. Maybe tomorrow, or\nlatter in the week.\nMay I ask what parameters you used?\nI personaly use mostly patch sizes of 1 and 2, as 3 and 4 gives more\nartifacts.\nSo, let's see why are we getting artifacts with this algorithm.\nA patch is a square of pixels. A patch size of 1 means the patch is a 3x3\nsquare, of 2 means the patch is a 5x5 square, of 3 means it is a 7x7\nsquare, and of 4 means it is a 9x9 square.\nNon local means works by doing a weighted average for every pixel,\ncomputing the weights using a patch similarity measure: the more similar a\npatch is to the patch centered on the considered pixel, the higher the\nweight.\nFor each pixel of the image, 224 patches are considered to compute the\nweighted average.\nThe problem we have is related to the similarity measure: to compare 2\npatches, we do the sum of the squares of the pixel differences (and we\nnormalize this sum). Let's call this sdiff.\nThe lower it is, the better the similarity.\nWith this similarity measure, every pixels of the patches are involved the\nsame way: pixels which are far from the patch center are used the same way\nas pixels which are close to the patch center.\nWith a big patch size like 4, we have 9x9=81 pixels patch. This is 32\npixels more than a 7x7=49 pixels patch, and these 32 pixels can have A LOT\nof influence on the similarity.\nLet's take an example.\nSee the images here: https://drive.google.com/folderview?id=13l8EHxfgQeJj25-wNtiXP5GFzsYGo3Us\nThe image \"Patch-original.png\" represents the patch\nwe are considering: its center is the pixel we are denoising.\nThe images \"Patch-candidate-1.png\" and \"Patch-candidate-2.png\" are patches\nwe compare with the original patch.\nFor a human, it is obvious that candidate 1 is better than candidate 2.\nYet, considering black is 0, white is 1, and grey is 0.5, we get a sdiff of\n30 for candidate 1, and 7.75 for candidate 2, thus the candidate 2 is said\nto be more similar to the original patch by our similarity measure!\nThis will give more weight to candidate 2 than to candidate 1 in the\nweighted average, and our central pixel will become grey instead of\nremaining white.\nWhereas if we take a patch size of 3, candidate 1 is perfectly similar to\nthe original patch (sdiff is 0).\nThe images \"diff\" represent these differences: blue is a 0.5 difference\n(sdiff of 0.25) and pink is a 1 difference (sdiff of 1).\nWith this example, we see why we can get artifacts and why bigger patch\nsize is not necessarily better than smaller ones.\nNow, why are we keeping this similarity measure? We could give more weights\nto pixels close to the center of the patch than to those who are far away\nfrom it?\nYes, we could do that.\nBut the fact that all pixels are considered the same way allows some\noptimisations which result in a very fast implementation of the algorithm,\nmuch faster that we could have if we had a weighted similarity measure.\nStill, it is not impossible to have a better similarity measure and keep\ngood performances.\nI have an idea of one measure that may lead to better results while being\ncompatible with the efficient implementation, but this won't be ready for\n2.6  . Ok @Turbogit\nI am afraid these problems are related to the core of the algorithm itself (which has not changed appart from the fact that we now ignore the central patch). If you want to revert only the \"ignoring central patch\" fix while keeping the rest (coarse grain noise reduction changes and presets), you can revert these commits:\n52b27a8dc067b014b5f25f5378b2a36fba6c9a52\na070f505ea9de47fa7a026eaa424286fc0784f77\neb8092620f84806f96798d9d90879fb2fa297370  . Alright, thank you for the tests.\nTo explain what happens: keeping the central patch acts like a varying opacity that changes pixel per pixel, sometimes low, sometimes high, which results in unprocessed zones when the patches available are not similar enough to the central patch. I considered it was preferable to always denoise the pixel, and let the user choose the global opacity, as this forces the user to increase the force to avoid these unprocessed pixels. But I am ok with keeping current behaviour if you prefer it and for the legacy reason.\n@Turbogit thanks for the revert.\nShould I reopen a pull request for points (1) and (3) (as only point (2) was the problem)?. @TurboGit (1) is similar but clearly not identical, there is no direct relation between it and the old radius (both have the effect of considering more widespread patches, but the way they do it is different). Yet, the \"radius\" slider it is supposed to replaced has never been in a release yet, it has been integrated in master very recently (if it had been in a release, it would have been too late to consider the replacement). So yes, it breaks the old history of people who used the master branch, but it does not break the old history of users of dt 2.4.4.. (Search radius slider was introduced in: becfd43a79b3387a9d238f93c02c7b53c315ea4e commit is old, but it was integrated in master recently (one week ago)) . @Turbogit , yes, the default gives an identical result as in 2.4.4.\nI will redo separated pull requests for this and for the preset (probably tonight), to make testing easier.. This is usable for testing but not ready for integration yet, I have to update the blobs as the current ones set the radius slider to 1 (this is visible when switching back to non local means).. Blobs updated ;-). Just a comment about how it works:\n- with radius, the algorithm iterated on [-nbhood, nbhood] interval on both axis to compare patches. The number of patches was nbhood*nbhood, thus the execution time increased with the square of nbhood.\n- with default radius to 7, this means it iterated in [-7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7]\n- with this PR, the algorithm iterates on [-7*7*nbhood-7, -6*6*nbhood-6, ..., 6*6*nbhood+6, 7*7*nbhood+7]. Note that it is no more a continuous interval, but an interval with gaps. With nbhood=0, we get the same list as previously. With nbhood higher, we look for patches more distant from the center than the \"normal\" ones. The number of patches is constant, equal to 7*7 and does not depend on nbhood.. Grids were \"normal\" considering the way the patches were chosen. The tooltip text indicated to reduce the slider value in that case.\nI updated the code with a different formula to determine which patches are considered, which should remove the grid effect.\nThe new formula still guarantees that with nbhood==0 we get the behaviour of 2.4.4\nFor testing, I worked on my portable computer this morning, thus I could not try to compile and run the opencl version.\nYet, I have been able to test both the updated normal and sse versions. . Previous formula:\n\nNew formula (same parameters):\n \nPlease look at these images on a bright screen, the grid effect is particularly visible on the dark area of the first image.. As you can see from the code, with the new formula it is no more obvious that a couple of coordinates is used only once.\nThus, I made a python script to test the formula: it checks that we never get twice the same couple of coordinates.\nIt tests this for all nbhood values in [0,1] with a step of 0.001.\nYou can find it here if needed:\nhttps://drive.google.com/open?id=1jFx7fdntX3HSiQnpbe4bP162nc1AMXmD. Another comparison for the formula, maybe easier to see the difference.\nOld formula (grid effect is very visible, it gives textures while the squares should not have texture):\n\nNew formula (same parameters. The grid effect is no more visible. Vertical and horizontal lines are less sharp though)\n\nPlease note that with the same parameters, we get patches that are more far away from the center with the new formula, which could explain partly the fact that the sharpness is lower on the second image.. Just a comment considering comparison\nI computed the average distance of the patches to the center with various values of the \"coarse grain noise\" slider.\nThese values have really close average distance of the patches to the center:\n- a value of 0.8 with the \"grid\" formula\n- a value of 0.64 with the new formula\n- a radius of 29 with the radius slider\nWith these values, here are some images:\nradius:\n\ngrid:\n\nnew:\n\n@TurboGit I saw your comment while I was writing this comment.\nDo you mean that you get artifacts when at zoom levels bigger than 100%? Are you using opencl code or the CPU one? Are they also visible at 100% zoom level and in exported image?\nI did not understand that the artefacts were a preview issue. @TurboGit, another question to help me understand, if you move slightly in the image, do the artifacts change completely?. @TurboGit I was wondering if it was a preview issue, or if it was the same thing for export.\nCould you try to reproduce with opencl disabled, so that I can know if the issue is with opencl implementation or if it is a general issue?\n. That's weird ;-(\nBy the way, I am trying to improve the formula to get better a better distribution of the patches.\nCurrently, the distribution is like this for 0.99 (it looks better for smaller values though):\n\n. I just changed the formula. The new one behaves better for high values (this image is for a value of 1):\n\nThis gif shows how the patches positions are affected when we increase the slider by steps of 0.01:\n\nThe new formula guarantees that no patch are used twice (this was also guaranteed by the old one).\nI tried to get a formula to have a shape more \"circle-like\" and less \"X-like\", but I did not manage to find one that guarantees that.\nBut I think it is not really a problem to have this X-shape.\nI have to test this on my fedora docker, I did not have time to do it yet. I tested sse and normal version on linux mint though (and the opencl one, but on cpu).   . @aurelienpierre The goal of the plain surface images is to check that the modification does not induce grid artifacts, which were very visible for high values of the parameter on plain surface, but much less visible on textured surface. That's why I used examples with plain surface images. Coarse grain noise is also easier to see on plain surfaces.. Here are some tests on a more textured image (with patch size = 4, force = 2)\noriginal with wavelets in color mode:\n\ndenoised without the coarse noise slider, nor the radius slider:\nexecution time: 1.9s on CPU\n\ndenoised with coarse noise slider set to maximum (note that we should have put it to a smaller value, a value of 0.3 is enough to remove coarse grain noise on this image, I set it to the maximum to try to stress the module, and to see potential effects of having less patches close to the center, see bellow for what we can have with smaller values):\nexecution time: 2.0s on CPU\n\ndenoised with radius slider, changed the force and radius to get close to the result of what I got with coarse noise slider (radius is 20, force is 1.2)\nexecution time: 15s on CPU\n\ndenoised with coarse noise slider again, trying to get closer to the result I had with radius slider (coarse slider set to 0.3 and force to 1.9)\nexecution time: 2s on CPU\n \nThe times of execution were as expected: very close to original with coarse noise slider, and close to 20*20/(7*7) times the original time when using radius slider.\nActually, the only thing which can impact execution time when using the coarse noise slider is tiling, as the overlapping zone between 2 tiles is increased when the slider value is increased. . @TurboGit thanks for the testing.\nI still need to test on fedora before the merge. @TurboGit I will take a look at this. I am ok for a possible integration later than 2.6 in a next cycle. This will give more time for testing, and it is probably wiser.. I have been able to reproduce this band of blur. It seems that it affects only the opencl version. Thank you for reporting this issue. This bug is already here in the current version\nI used patch size 0, radius 20 and force 4 on this image:\n\nHere is the result without opencl:\n\nHere is the result with opencl:\n\nHere is the difference (enhanced with gimp):\n\nAs you can see, the difference is not only on borders, but in fact it is also visible inside the image.\nI will try to find the cause of this. This is maybe caused by the loop on j which goes from -K to 0 on opencl code, it should maybe go from -K to K (did not have time to test this yet. I will test it as soon as possible). EDIT: it seems more complicated than that. I have to understand fully the opencl code to try to find the issue.. @upegelow thank you for this information. I will read the publication.\nThe fact that accumulating rounding errors leads to the small differences in the center perfectly makes sense, and I did not think about this. Then, the problem is only for borders.\nThis narrows the search space to be explored to find the source of the issue.\nThanks!. I opened a pull request here to fix this: https://github.com/darktable-org/darktable/pull/1834\nThanks again @TurboGit for finding the issue, and @upegelow for your advices.. I just rebased the changes, but I did not test it on gpu yet. I will do it soon. Tested again both on CPU and GPU. Note that testing on GPU will be easier once #2000 is integrated.. Thanks @TurboGit\nThis PR needs to be rebased on master, apart of that it is ready.. The less long name is perfectly ok for me :-)\nThanks for the testing and review ! :-). Thanks to both of you for the code review and testing. @TurboGit could you close the bug report on redmine ( https://redmine.darktable.org/issues/12400 )? It seems that I cannot do it, even if I was the person who opened the bug report ;-(. Unfortunately, it seems that this PR did not solve completely the issue, but made it only less visible... ;-(\nThe issue is still here, but borders are not oversmoothed anymore, they are undersmoothed. See https://redmine.darktable.org/issues/12400 for some images.. @TurboGit why is it not legit to update rawspeed here? It is the only way to be able to open new raw files in darktable... Or is it supposed to be updated by someone in particular, and other devs should not update it?\nOr I am missing something?. Alright, that makes sense. Thanks :-). I tested this this afternoon. This is awesome, thanks a lot!\nEspecially useful for denoising. As an exemple of use: I moved the sharpen module after a lowpass module that I used to denoise, and I moved the denoise bilateral before the basecurve.\nI love this. Thanks :-). I tried it on new edits. Though, I made these edits on images that I am used to edit, so I was able to compare the results with the older editings I made. It seems that when copy/pasting and styles do not preserve the custom module order yet, is it normal in current state of development or should the order be already preserved?. @edgardoh thank you for these explanations, I understand the problem now. Hi,\nFYI, I tried to test this again today, but I get these errors when trying to launch darktable:\n[dt_ioppr_check_so_iop_priorities] missing priority for module dummy3\n[dt_ioppr_check_so_iop_priorities] missing priority for module dummy2\n[dt_ioppr_check_so_iop_priorities] missing priority for module dummy1\nAnd darktable does not start after that. Ok thanks @edgardoh , I will try that :-). Indeed, this worked :-)\nApart of that, I thought about the copy pasting issue across images, to keep the order when copy pasting. Here is an idea I have, I do not know if it is realistic regarding the way you handle the order:\nThe principle is to have an hybrid order system, where the order is both relative and absolute.\nEach module would have a number indicating its number in the pipe (like it was with previously in darktable), but this number would be a float instead of an int, and it would be changed depending on the order of pipeline.\nSome modules have a number that can't be changed, for instance:\n- 0 for beginning of pipe\n- 100 for input color profile\n- 200 for output color profile\n- 300 for end of pipe\nThe numbers of the other modules are initialized by values defined by the developers, that should never change, even across versions.\nIf a new module is added in darktable, it takes the value module_before+(module_after-module_before)/2.\nWhen moving the modules, we do the same: if module2 is moved before module1, it takes the value module_before_module1+(module1-module_before_module1)/2, this way, it is set as in between module1 and the module before module1.\nWhen copy pasting, these absolute values are used to make the fusion of original modules and new ones: if there is a collision of values, we can say that the new module is set to be after the original one in pipeline for instance (this remains the same problem as with current implementation).\nI hope it can help!. Alright. I did not understand that you were using already a mecanism with this formula. You can forget about my proposition then, which seems equivalent to what you have already done ;-)\nI think that with such a formula, copy pasting can be done by simply \"merging\" the modules of the source and the destination based on the iop_priority values? Or am I missing something?. Cool, that seems promising! :-)\nI haven't thought about the conflict problem that you raise, that's a good point. In such a case, I agree we should check if there are consecutive instances of the same module, and in this case, paste after the latest instance of this sequence.\nConcerning the issue across versions, another approach could be to have a version number attached with the iop_priority list, and \"convert\" the numbers when we find an old list of iop_priorities. But I think this would be much harder to maintain that having frozen values that don't change across versions.\nAlso, if we use the \"frozen values\" method, we should think about which values to use so that we keep enough space for future module additions. As such, maybe (probably) all current values should be changed. We should get uniform intervals between all initial values, as we don't know where the new modules will be added (and 0 should be for the beginning of the pipe, not for the first module, as well as the maximum value which should be for the end of the pipe and not for the last module). To get uniform intervals, I think it would be easier to use an integer instead of a float for iop_order: we want the same number of possible values inside each interval.\nLet's do a quick computation of what this would imply, to see if having a frozen system is problematic. Currently, I think we have about 50 modules. Let's consider we currently need 64 intervals, for 62 modules and 2 for begin and end. With iop_priority in an uint32_t, this would make it possible to divide by 2 each interval 26 times in worst case (ln(2^32/64)/ln(2)). This is already quite a big number I think. If we want to take more margin, using an uint64_t, this would make it possible to divide by 2 each interval 58 times in worst case (ln(2^64/64)/ln(2)). So I think having \"frozen values\" is not a problem for future module additions. \nAnyway, whatever solution you choose, thanks for all the work :-) . Thank you @edgardoh,  I will test that soon :-). I made some tests with it, this is much better, thanks a lot! :smiley:. @edgardoh If I understand correctly, colorin would have a fixed place in the pipe?\nI am not confident in the fact that denoise profile results would remain the same if denoise profile is done after colorin, thus we should test this and see how to handle backward compatibility if the results are differents.\nApart of that, it seems a good idea to me, even though I am clearly not an expert about colorspaces :-). Thanks for the answer :-)\nSeems good to me.. I think denoiseprofile should always remain before colorin (at least if the user wants accurate profiles).\nOtherwise, we would need to make noise profiles for every input profile and every working profile.. Thank you for the review!. I think it is better to merge it only after documentation has come. Otherwise, users will have some \"link not found\" errors on their web browsers. I removed the commit that adds the url for filmic. I now think it is better to add the urls for the other features that already have a documentation without waiting for the filmic one. As such, even if filmic documentation arrives after 2.6, we will still have the contextual help links for retouch, duplicate, etc for 2.6.\nI will make a second pull request for filmic url when filmic documentation will be available.. I like the idea of seeing the nodes on the curve. Yet, I agree that having them drawn as circles could be confusing. I like TurboGit's idea of using small vertical lines instead, or maybe little cross marks. I don't have a strong opinon on this though.\nAnyway, thanks for the great work :-). These sentences sound a bit contradictory to me, though I do not have the knowledge to check this, could you please check them? \n\"XYZ is a linear technical color space designed to link the physiologic light response of human eyes to RGB spaces.\"\n\"it does so in a way that does NOT account for the role of the brain correction in human perceptions.\" . Ok, that makes sense :-)\nThanks for the explanation !. I tested it today, including on complicated pictures. I just wanted to say that I am finding the module much easier (and faster!) to use!\nThis is awesome. Thanks!. Just tested and liked it :-)\nIt is probably already on your todolist, but it would be nice to have soft bounds on the sliders\nVery nice addition Aur\u00e9lien, thanks !. Thanks for the answer :-)\nThat makes sense.\nI did not understand your remark about increasing the channels around a third one however, could you say it differently?. Thanks a lot for this detailed explanation :+1:\nThis makes everything clear :blush:. @aurelienpierre\nIn process_scale, if memory allocation failed, you will goto clean and free the 3 pointers while you just checked that one of them is NULL, hence you will free a NULL pointer. The error maybe comes from here?. I personally think that having weird colors is a very confusing way to tell the user that there is an issue with his css. Basically, several users that encountered this issue had no idea it was related to the css file.\nA message displayed to the user that would tell there is an issue with css instead would be great.. No problem, this is really not a big issue :-). Thanks :). Hi\nWhat I tried is a bit different: the purpose was make the downscaling used for preview earlier in the pipe. Right now, the image is downscaled during demosaic for the purpose of darkroom preview, and I wanted to downscale it before demosaic, as all modules before demosaic currently work on the full image even for darkroom preview, which makes it impossible to implement some noise reduction filters before demosaic. But I failed to modify demosaic code to do that (it supposes that it gets the full size image as input): it gave weird behaviors when zooming in and out. I did not find  the cause at that time, and it has been a while I did not tried again to understand were is the problem (even if I think I probably should, my understanding of roi_in and roi_out is better now than before)\nI also have in mind the idea of rescaling before demosaic, not only for preview but also to get a pixel bining effect, but I did not take time on this yet, and I don't know how good the results would be. This idea is closer to yours, the only difference is the pipe order (downsampling before demosaic in my case, or after demosaic in yours).. You are welcome @spaceChRiS :-)\nConcerning the position in the pixel pipe, I think it should be right after demosaic, and not at the end of the pipe.\nAs I explained above, the darkroom preview is computed on a downscaled image, were the downscaling is adapted to the zoom level.\nThe problem is, the preview computed on the downscaled image is not always perfectly accurate. For noise reduction for instance, you can get very different results after export than what you were seeing in the darkroom preview at \"zoom to fit\" zoom level, which forces us to look at the image at 100% zoom level to be sure of what we are doing to the image.\nWe should guarantee that 100% view remains exactly what we get after export.\nIn addition, downsizing just after demosaic will allow later modules to run faster at export, as they will have a smaller image to process.. Hi\nDo you still experience the bug on master?\nPR #1999 and #2000 that have been integrated today should have fixed the nlmeans issue. (rebased on master). This was tested with intel neo driver which is now blacklisted, it should be tested with another driver but unfortunately I do not have any other GPU than the intel one. This was tested with intel neo driver which is now blacklisted, it should be tested with another driver but unfortunately I do not have any other GPU than the intel one. I am afraid the issue is not always easy to reproduce, it is a random issue.\n@edgardoh has it quite frequently, while I experienced it only twice in about an hour of testing.\nThe issue is that the image randomly turned blue, or with black squares (in my case, it was only the thumbnail)\n@edgardoh gave some steps to reproduce here: https://redmine.darktable.org/issues/12490 but I was not very lucky with them. In the end, he found that the ifs in \"dist\" function were giving the issue.\nFixing this and #12400, I also realised that I made a mistake in the code of nlmeans_accu, so I fixed it too\n. @edgardoh cool, thanks for testing :-)\nIf I understand your comment correctly, you see bug 12490 with PR2000.\nPR2000 affects only the nlmeans implementation of denoise profiled, not the implementation of denoise non local, so it is normal that you see the issue 12490 (black squares and blue image when using denoise non local) with PR2000.. @upegelow I have made the code more constant time. Does that looks better to you?\nI also used your suggestion \"float4 u1_pq = wpq ? read_imagef(in, sampleri, (int2)(x, y) + q) : (float4)0.0f;\", but shouldn't I transform the if also here to get rid of the 2 branches?. (pushed force to fix an error in the commit message). Is there any more change I should do on this and #2000 ?. Thanks for testing and review :-). The effect of this change is subtle, and only visible on borders of the image. Before the PR, a band of some pixels is left undenoised on borders, while after this PR, the denoising result is similar to the CPU version even on borders. @upegelow I would be happy to read and take your comments into account, but I am afraid I can't see any comment of you in PR1999, maybe something went wrong?. Yes thanks :-). Pushed the same changes as in #1999\n. Thanks for testing and review :-). Thank you for the review and testing :-). @waterlubber maybe this behavior comes from the fact of using dng and not the \"real\" canon cr2 raw file?. Well, indeed I use neo to debug opencl on linux mint usually with success, but I use it almost exclusively to debug only a few modules (and I had some strange bugs that disapeared magically and I still don't know why), so I am not very confident about it.... I like to have the exif always visible on the histogram, especially the ISO value. It gives me a hint about how noisy the picture is when I open it, and I think it is more visible and convenient for me than using the exif box of the left panel. Having to put the mouse over the histogram to see that would annoy me, in this case I would probably stop looking at the histogram for that.\nApart of that, I never use the histogram to control exposure, so I don't mind if it is read-only.. Considering the ISO setting, I do not know what would be a better way :-/\nThe text in the exif panel is small, and its position varies if the history tab is kept opened, that's why I prefer looking at the histogram to get the ISO information when I go through my images.\nNote that I do not mind if this is no more on the histogram, as long as it remains visible at a fixed position (for instance it could be at the bottom right under the image instead). A status area on top of the image would be perfect for me :-)\nA status area on bottom of the image would be ok too, but probably a bit less convenient as it would be less close to the histogram, and I like to look both at the histogram and such exifs when I open an image. I updated the presets, rebased on master and force-pushed.\nI will make another PR later for the anscombe changes, they take more time and may be bigger that I first thought.. Yes, this is ready for review. Thank you for reviewing and testing.\nI don't mind removing the backward compatibility section, it will simplify the GUI.\nI do not know which solution is the best for the user:\n- if we hide completely the options the user may find it confusing that from one photo (which had already a denoise profile instance) to another (a new one) he gets very different results with similar settings.\n- if we show the option only in case of an old edit, the GUI code is a little bit more complicated, but the user can see something changes. Yet, it may be confusing too to see an option on an image and don't see it on another one?\nAs such, I do not know which solution to choose. Do you have a preference?. Ok, thanks for the idea, I will do that :-). @TurboGit , should be better now.\nYet, I have some GUI issues, I don't manage yet to make the option not appear on new instances. > In mode_callback you also need to hide the (fix anscomb...) after:\n\ngtk_stack_set_visible_child_name(GTK_STACK(g->stack), \"wavelets\");\n\nI added this in the fix_anscombe_and_nlmeans_norm_callback, I think it makes more sense than in the mode callback.\nBasically, it makes the button disapear when the user click on it.\nAnd your commit 1589f0d has solved my issue with new instances, many thanks! :-) \\o/. > > I added this in the fix_anscombe_and_nlmeans_norm_callback, I think it makes more sense than in the mode callback.\n\nI don't think this is correct. A user may want to activate and deactivate it multiple time at different zoom level to asses the changes and if he want to keep the previous algorithm or not.\n\nOk, I have removed the commit. Do you think we should do it when the user change mode however?. > > Do you think we should do it when the user change mode however?\n\nWhen changing mode we should probably keep the current status of the fix boolean.\n\nSorry, I am not sure I understand correctly.\nIf I understand correctly, you mean that changing mode we should not do anything, and keep the checkbox shown if it is shown?. > Exactly. And not shown if not shown.\nOk :-)\nI was confused with the remark about the mode_callback.\nThanks for clarifying\nLast pushed version should work as expected.. Good remark. I will update them again. The presets should be fixed\nI also updated one of the tooltip text, which was inaccurate. @edgardoh @TurboGit Thanks for the feedback :-)\nI am glad you like it !\nAnd thanks for the code reviews !. @TurboGit just to check, the modifications seem to appear twice in master history (all my commits + a \"merge\" commit that contains all the changes) is that normal?. @edgardoh This issue was already here in 2.6 (and before).\nThe module still has some effect, but the effects are different than the ones we could expect: for instance there is undersmoothing.\nThe problem is that it is hard to adapt the algorithms to downsampling.\nIf we note I the original image, D the downsampling, f the denoising function, p its parameters, it is hard to find parameters p' such as:\nD(f(I,p)) = f(D(I),p')\nFor now, the parameters p' which are estimated are not good enough.\nIf you want the result to be accurate with what you see at 100% zoom, you have to select the option \"do high quality resampling during export\", so that downsampling is down at the end of the pipe and not at the beginning.. Hi edgardoh\nHere is some feedback (even if I guess you already have some of these points on your todo list ;-) ) :\n\nwhen dragging the curve, if the pointer goes out of the area, the point goes back to its original place, which makes it hard to drag the curve down to the bottom for instance\nit would be nice, in \"hue\" selection mode, to have these hues represented in the background of the curve, like it was in the old colorzone module\n\nApart of that, I like the fact of having a bigger area, and I am looking forward to test this again when these points will be fixed.\nThanks for all the work!. Oh, I tested too quickly I did not try the picker, and did not see this feature!\nThis is really nice when the picker is used.\nYet, wouldn't it make sense to have a shade of hues instead of using the \"blue\" value when the color picker is not used? My issue is that I find it harder to spot where is each color on the curve than with previous version of colorzone, when the color picker is not activated. On the contrary, when the color picker is used I like your idea of having the background customized for this particular color, I find this nice to use.. > Sorry but still I don't get it. The background display only the modified channel (the tabs), if I don't have a base color (i.e. the color picker is not active) I have to use something for the lightness and saturation, then the hard-coded color. For the hue I display all the combinations, so for each x you know the destination color by looking at the y. Maybe if you describe exactly the active tab/select by/color picker status I'll get a better understanding of the issue.\nWhen the color picker is active, I like the backgrounds of your implementation.\nWhen the color picker is not active, I would prefer to have backgrounds similar to the ones of the 2.6 version.\nFor instance, on the lightness tab, if I select by hue, I see this:\n\nWhat I like with this representation is that I can see easily which part of the curve impacts the greens, which one impacts the red, etc.\nWith the uniform blue gradient of your curve, I am forced to look at the hue gradient which is shown bellow, and I find it much less convenient.\nI would like backgrounds to be similar to this when I select by hue without color picker.\nFor instance, this would give backgrounds like that (these are examples made quickly, not perfect examples, just to show the idea)\nlightness tab:\n\nsaturation tab:\n. Thanks for fixing the dragging issue, much better now :-)\nAnother little GUI bug:\nonly the curve of the \"active\" channel is reset when we click on the \"reset parameters\" button, until we click on other channel:\nbefore clicking on reset parameters:\n\nafter:\n\nthe curve of active channel is correctly flattened, but not the ones of the inactive channels. @edgardoh I get again the same issue with dragging out of the zone when I get out of the zone by dragging toward the left or toward the right (top and bottom are ok)\nConcerning the background:\n- when color picker is activated, I would prefer not to have the histogram shown, so that I can easily see what \"output\" I want and directly drag the curve at the point I want. The histogram makes this harder to do, I think. Maybe an option to display it/hide it would be nice?\n- I still prefer the \"idea\" of the old backgrounds when color picker is not activated for lightness and saturation tabs, but if possible without the big squares with lines: the \"hue\" tab background you made is perfect for use with select by hue for instance. Note that I do not know at all how these backgrounds are implemented in the code and if that is something possible to do without too much effort, don't hesitate to tell me if I ask for impossible things.\nAlso, this is only my humble opinion, I do not know what other users would think :-). I like the last version too. :-)\nThanks! :-)\nJust a remark: shouldn't the top right part of the lightness vs lightness background be completely white?. Thank you @edgardoh\nI won't be able to check today, but I will check asap :-). @edgardoh the lightness vs lightness background is very nice now, thanks :). Also, could you give an exemple of the way you use the \"curve create\" color picker and for what purpose please?\nI like a lot this new interface, thanks for your work!. > Very often I work with a particular color, to change the hue and/or saturation, and I find difficult to create by hand a small range. With this new picker I select the color I want to work with and it creates a curve with 5 point, 3 for the max, min and average and 2 for the feather. With only this I can see the effect on the image and if not what I expect I keep playing with the picker until I get something close enough, then I tweak it by hand, usually I delete some of the middle nodes, but that depends on the image. Still, this is not perfect, for small areas is not easy to get the right curve. I would like to have a zoom feature, but I'm still deciding how to handle the GUI. \nOk, thanks for your answer. I tested it a bit more, and liked it.\nWould it be possible to have a mode were the nodes are added on the x-axis but were the curve remains flat? It is not always easy to edit the curve fastly when the nodes are already at different y-positions, while when they are on a flat curve, we can easily and fastly move them were we want using the \"edit by area\" feature.\nApart of that, a little GUI issue:\nwhen we drag a node towards the right while there is another node at the right, the node we drag is deleted when we go too much to the right. I would expect the node to stop going to the right, but not to be deleted. (there is this same behavior when we drag the node toward the left, I just choose the right for explaining)\nExample in the image bellow, pushing the node indicated by the arrow towards the right will make it disappear\n\n. Ok, I did not notice that it was the case with tone curve, and indeed it is the case! \nLet's keep the behaviors consistent with the tone curve then.\nThanks for the quick answer :-)\nRegarding the first part of my comment, to clarify, I was referring to the \"curve create\" tool. My question was if it would be possible that this picker, instead of creating a curve, only adds nodes on a flat curve at the positions of max, min, average, and feather points?. > I see, plain click create a positive curve and cntrl+click a negative one. I like that. Will it work for you if shift+click creates flat one? Or maybe plain click creates a flat and with modifiers either positive or negative?\nYes, that would be awesome :-). Thank you for all this amazing work @edgardoh :-). I will try to find some time tomorrow morning for testing :-). I have just tested, I have been able to reproduce the issue.\nWith #2214 I do not see the issue anymore.. I did not find how to zoom however\nI tried shift-A (which is the shortcut for pan & zoom), and the mouse wheel.\nMaybe have I missed something?. Oh, I was pressing the key once instead of pushing it continuously!\nIt works great :-)\nHowever, when zoomed in, modifying the curve with \"edit by area\" does not work as expected on my side. To reproduce:\n- add 3 nodes close to each other\n- zoom in to this zone\n- try to move up the central node using the \"edit by area\" option. As long as the struct new members are added at the end of the struct, one can continue to use the same type, as long as no access to new elements are made. But I agree that code, even if correct, can be harder to understand.. I added a comment to explain how it works.\nI used this as I saw this was the way it was done in denoiseprofile and nlmeans for example.\nBut if you prefer, I can define a new struct so that the changes are more explicit.. Good point, it is deprecated. Thanks. Yes, you understand it right!\nThe problem with grids comes from the fact that we have grid gaps between the patches we consider: lines or columns without any patches, and lines or columns with a lot of patches. I updated the formula so that the patches are chosen in a way that makes the patches better distributed.. Yes of course. Thanks for taking time to look at the code.\nThe idea of all these tests is to prevent accesses to pixels that are outside the limits of the image.\nSee bellow, there is a memory access at (x,y)+q and another at (x,y)-q\nOne very important thing is that q.x and q.y can be negative.\nThus, if we have x=3 and q.x=-5 for instance, x+q.x will be negative, and thus outside the range of the line we are considering.\nThe test (x-q.x<width) checks one of the memory bounds for the access (x,y)-q\nThe test (x<-q.x) is equivalent to (x+q.x<0). It checks one of the bounds for the memory access (x,y)+q . I am afraid I don't know... the code calls gtk_show_uri or gtk_show_uri_on_window, which are supposed to open the right app depending on the uri (it should open the file browser if it is the uri of a file, the web browser if the uri is a url, etc...). Good idea :). Thanks for this comment, I am very new at opencl, and I did not know that.\nIsn't it an issue to do an out of bounds access if put the read outside any branch?\nOtherwise I guess we can still use max and min function to make an access that is always in bounds..\nAs a general rule, does this mean we should try to make opencl code as constant time as possible? What amount of variation in time of execution can we tolerate? (For instance replacing all ifs of nlmeans_accu by computations without branches to be constant time is possible, but would probably make the code a bit harder to understand). Ok, thanks for the explanation :-). Oh, ok, thank you, I will change that.\nThanks for the review :-). Oops, indeed.\nI perfectly agree, thanks!. No problem :-). ",
    "macrat": "Sorry my mistake. I made revert commit, please squash merge it. I'm sorry.\nI made an issue in the redmine ( https://redmine.darktable.org/issues/12081 ). Please check.. ",
    "mueller-physics": "I have seen the issue, but assumed the problem was only actively writing tags to the sidecar, not reading in existing ones (that would have been put into the side-car on purpose)? At least, other tags (Xmp.exif.GPS..., Xmp.exifEX.LensModel) already override EXIF data if darktable finds them in the XMP file.\nTo fix this, could there be a switch somewhere in config, to enable a \"one side-car file per image\" use-case? Or any other way to reliable store \"corrections\" to meta-data w/o touching the original files or relying on the darktable database (which is much harder to backup)?. Ah, thanks, I was wondering if I missed some case in the GUI where duplicated files could share a side-car. But for the dt-cli use-case:\n- why would someone reuse an xmp that has overrides in it (that have to be added manually, currently on the command line) if they do not indent to apply these overrides\n- why not offer a switch to ignore those overrides when using dt-cli (that might default to 'ignore')?\nThanks for your help, by the way, great community!. ",
    "phweyland": "I've fixed the char declaration (I hope), committed and pushed again.\nLet me know if I've to make a pull request again.\nThanks. I've built dt on windows to try to make some tests and udpated lightroom.c with changes. The build works and I can start dt and import images.\nBut I don't see the effect of the changes. I've tried to activate the logs (-d all) but I don't see anything like:\ndt_control_log(ngettext(\"%s has been imported\", \"%s have been imported\", n_import), imported);\nand any detailed information I was expecting to find (rating, colorlabel, gps).\nI'm not sure about what I should do to see the logs. \nIt seems I cannot have both information in the log (condition on dev):\n\nif(dev == NULL && data.has_colorlabel)\n  {\n    dt_colorlabels_set_label(imgid, data.color);\nif(imported[0]) g_strlcat(imported, \", \", sizeof(imported));\ng_strlcat(imported, _(\"color label\"), sizeof(imported));\nn_import++;\n\n}\nif(dev != NULL && refresh_needed && dev->gui_attached)\n  {\n    dt_control_log(ngettext(\"%s has been imported\", \"%s have been imported\", n_import), imported);\nAny advice would be welcome.\n. I see the log file but even with -d all I don\u2019t see any message from lightroom.c except for some database accesses (tagged \u201clightroom\u201d). Here is the log file : \ndarktable-log.txt\nThe first session is with -d all and the second one with -d control (import one image with lr xmp).\n. Hi, I've tested the changes on windows 10.\nActually this imports the metadata title, description, creatorand rights, while publisheris not imported because the field doesn't exist in Lightroom.\nCheers\n. Hi Pascal,\nI've made the fixes below.\n\nIt would be easy to ingest some more metadata like Location, City, State & Country.\nI know they would not be visible in dt without an update of the metadata widget, but at least the data would be in the database.\nIf I've understood properly, we have just to define the new correct names and add them into the file tools/metadata.txt and add the corresponding sections into \nlightroom.c.\nDoes that make sense ?\nWhat do you think ?\nRegards\nPhilippe\nMetadata.txt:\nXmp.dc.creator\nXmp.dc.publisher\nXmp.dc.title\nXmp.dc.description\nXmp.dc.rights\nIn xmp file we have these lines out of lr:\nIptc4xmpCore:Location=\"Rua da camara\"\nphotoshop:City=\"Tiradentes\"\nphotoshop:State=\"Minas Gerais\"\nphotoshop:Country=\"Brasil\"\n----- Mail original -----\nDe: \"Pascal Obry\" notifications@github.com\n\u00c0: \"darktable-org/darktable\" darktable@noreply.github.com\nCc: \"Philippe\" philippe.weyland@libertysurf.fr, \"Mention\" mention@noreply.github.com\nEnvoy\u00e9: Vendredi 10 Ao\u00fbt 2018 18:46:15\nObjet: Re: [darktable-org/darktable] Add dt metadata to LR import module (#1675)\n@TurboGit requested changes on this pull request. \nsome minor issues to fix. \nIn src/develop/lightroom.c : > @@ -429,6 +430,7 @@ typedef struct lr_data_t\n   float crop_roundness;        // from lightroom\n   int iwidth, iheight;         // image width / height\n   int orientation;\n+ \nthis empty line is not needed. \nIn src/develop/lightroom.c : > @@ -907,6 +909,78 @@ static void _lrop(const dt_develop_t dev, const xmlDocPtr doc, const int imgid,\n       tcNode = tcNode->next;\n     }\n   }\n+  else if(!xmlStrcmp(name, (const xmlChar )\"title\"))\n+  {\n+   xmlNodePtr ttlNode = node;\n+    while(ttlNode) \nsounds like there is indentation issues. please do not use tabulations. more issues like this below. \nIn src/develop/lightroom.c : > +  }\n+  else if(!xmlStrcmp(name, (const xmlChar )\"creator\"))\n+  {\n+   xmlNodePtr creNode = node;\n+    while(creNode)\n+    {\n+      if(!xmlStrncmp(creNode->name, (const xmlChar )\"li\", 2))\n+      {\n+       xmlChar cvalue = xmlNodeListGetString(doc, creNode->xmlChildrenNode, 1);\n+       dt_metadata_set(imgid, \"Xmp.dc.creator\", (char )cvalue);\n+        xmlFree(cvalue);\n+      }\n+      creNode = creNode->next;\n+    }\n+  }\n+  /* Publisher (Dublin Core Schema not supported by Lightroom \nthen we do not need this section. just add a clear comment in the commit log that there is no published in lr. or an alternative solution is to have publisher use the creator if present? \nIn src/develop/lightroom.c : > @@ -915,7 +989,13 @@ static int _has_list(char *name)\n   return !strcmp(name, \"subject\")\n     || !strcmp(name, \"hierarchicalSubject\")\n     || !strcmp(name, \"RetouchInfo\")\n-    || !strcmp(name, \"ToneCurvePV2012\");\n+    || !strcmp(name, \"ToneCurvePV2012\")\n+   || !strcmp(name, \"title\") \nno tabulations please. \n\u2014 \nYou are receiving this because you were mentioned. \nReply to this email directly, view it on GitHub , or mute the thread .\n. > modules now ask for the input colorspace and informs the output one. This can be dynamic, so Lab modules with an RGB option can ask for an RGB input image\nbeside the common default_colorspace() we have the 2 routines:\n- input_colorspace()\n- output_colorspace()\nWhen are they triggered ?\nThe background of the question is that, depending on user settings in a module, the needed colorspace can be different. For example in old fashion tonecurve, I want to call RGB only if the user select the rgb mode. For lut3d I have a similar need depending of the type of lut.\nHow should I do ?\nTalking about lut3d, you cover already the sRGB colorspace. Would it be easy to add the the gamma REC709 ? Same question, but I guess it's more difficult, for LOG RGB ? What do you recommend ?\n. > You add those functions on the iop, like the default_colorspace(), only difference is that you'll return the colorspace based on the parameters\nin fact input_colorspace() just let you choose between iop_cs_lab and iop_cs_rgb. In case of iop_cs_rgb it uses the rgb working profile selected in colorin. \nIf that's right, a module (like lut3d) cannot choose real time between sRGB, rec709, prophotorgb or whatever. Is my understanding correct ?\nThen I've to provide somewhere transforms between prophotorgb and the other rgb colorspaces. Is colorspaces_inline_conversions.h still the right place ?\n. > If you create in-memory profiles it should be possible (and not too difficult).\nSorry I don't get that. Could you develop a little bit ?  Is there already an example of that ?. In colorspaces.c I can see the creation of several colorspaces. They end up into a list of lcms profiles.\nSome of them are considered by iop_order.c (colorspaces transform) which prepares the data to transform iop_cs_lab <-> iop_cs_rgb. Pixelpipe uses dt_ioppr_transform_image_colorspace() to execute this transformation.\nAs from module standpoint we have only the below choices (but only raw, lab and rgb are implemented if I understand properly):\n/** colorspace enums */\ntypedef enum dt_iop_colorspace_type_t\n{\n  iop_cs_NONE = -1,\n  iop_cs_RAW = 0,\n  iop_cs_Lab = 1,\n  iop_cs_rgb = 2,\n  iop_cs_LCh = 3,\n  iop_cs_HSL = 4\n} dt_iop_colorspace_type_t;\nI cannot use this mechanic (dt_ioppr_transform_image_colorspace()) to transform prophotorgb into gamma rec709 for example.\nCould I use instead cmsCreateTransform, cmsDoTransform and cmsDeleteTransform ? I've also seen that in pixelpipe for color picker and histogram stuff. It seems that's the only way to use colorspaces.c lcms color profiles directly from iop module ... but maybe not fast enough ...\nOtherwise I'm back to hard-coded transforms in colorspaces_inline_conversions.h...\nI'm a bit concerned to have several ways / places to make colorspaces transform.\n. > but first you have to decide if you'll create such profiles.\nIf this is the recommended way I'll do this.\n\non iop_order.c, the RGB <--> RGB is already defined\n\nI've missed that ... could you help me ?\n. > iop_order.h\nOoops, I haven't visited this one. Thanks.\n\nI still don't know what you want to do\n\nFor the time being I try to implement the module to apply 3D lut on image. But these luts are valid for a given colorspace, which can be sRGB, gamma REC709 and LOG. So before applying the lut the user has to select the corresponding colorspace (it may not come with the lut).\nThe LOG is a particular case. In film production it can come out the camera and can be a work profile. So I'll try to place the module before colorin, transform the raw data into log and apply the luts which work in LOG profile. That should work if the module gives as output profile, an existing colorin profile.\n. In fact I haven't seen any OpenCL piece of code involved.\nThe fulcrum part is integrated in the ctable calculation (10000 points), that's all. I've understood, but I may be wrong, that's ctable which is the entry for OpenCL.\nEdit: thanks for the OpenCL help. If this part of code needs to be updated I'll ping you !. I'm sorry. I've done everything except I'm blocked on:\n```\n\n$ git push -f phweyland lp-fulcrum\nfatal: 'phweyland' does not appear to be a git repository\nfatal: Could not read from remote repositor\n```\nI've tried to understand the password issue but I'm afraid I've only added a bit of mess.\n\n. It seems I've wiped a conversation, sorry ...\nIs there any way to ressuscit it ?. > it does not, the fulcrum is an offset. It's proportionnal to the contrast. \nNo. In the initial formula, the first 50 is the pivot of the amplification ( * contrast).\nThe second one gives the difference with the grey. It's the pivot of blending mechanism. Below grey the value is substracted from image, above it is added.\nThe first one is replaced by the fulcrum because we want to change the pivot of the amplification.\nThe second remains constant, because the blending mechanism still works the same.\n----- Mail original -----\nDe: \"Aur\u00e9lien PIERRE\" notifications@github.com\n\u00c0: \"darktable-org/darktable\" darktable@noreply.github.com\nCc: \"Philippe\" philippe.weyland@libertysurf.fr, \"Author\" author@noreply.github.com\nEnvoy\u00e9: Dimanche 9 D\u00e9cembre 2018 18:42:20\nObjet: Re: [darktable-org/darktable] Lp fulcrum (#1888)\n@aurelienpierre commented on this pull request. \nIn src/iop/lowpass.c : > @@ -519,7 +562,7 @@ void commit_params(struct dt_iop_module_t self, dt_iop_params_t p1, dt_dev_pix\nif(fabs(d->contrast) <= 1.0f)\n{\n // linear curve for contrast up to +/- 1\n\n\n\nfor(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - 50.0f) + 50.0f;\n\n\nfor(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + 50.0f; \n\n\nMakes the correction proportional to fulcrum, which is not what we look for. \nit does not, the fulcrum is an offset. It's proportionnal to the contrast. \n\u2014 \nYou are receiving this because you authored the thread. \nReply to this email directly, view it on GitHub , or mute the thread .\n. > imagine fulcrum = 0.25, the current function as you wrote it is not only adding contrast but also luminance, because it is shifted linearly by 0.25.\nWith the initial formula, we get a deviation from grey proportionnal to Contrast and (Luminance - Grey).\nWith the new one, we get a deviation from grey proportionnal to Contrast and (Luminance - Fulcrum).\n----- Mail original -----\nDe: \"Aur\u00e9lien PIERRE\" notifications@github.com\n\u00c0: \"darktable-org/darktable\" darktable@noreply.github.com\nCc: \"Philippe\" philippe.weyland@libertysurf.fr, \"Author\" author@noreply.github.com\nEnvoy\u00e9: Dimanche 9 D\u00e9cembre 2018 18:53:06\nObjet: Re: [darktable-org/darktable] Lp fulcrum (#1888)\n@aurelienpierre commented on this pull request. \nIn src/iop/lowpass.c : > @@ -519,7 +562,7 @@ void commit_params(struct dt_iop_module_t self, dt_iop_params_t p1, dt_dev_pix\nif(fabs(d->contrast) <= 1.0f)\n{\n // linear curve for contrast up to +/- 1\n\n\n\nfor(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - 50.0f) + 50.0f;\n\n\nfor(int k = 0; k < 0x10000; k++) d->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + 50.0f; \n\n\nimagine fulcrum = 0.25, the current function as you wrote it is not only adding contrast but also luminance, because it is shifted linearly by 0.25. \n\u2014 \nYou are receiving this because you authored the thread. \nReply to this email directly, view it on GitHub , or mute the thread .\n. > what blending ? The parametric blending ?\nAll blendings.\nWithout blending, you get a more a less blurred grey image.\nWith blending, this blurred grey image is combined with the original one.\n. > The blending is external of this IOP.\nYou are right. As the current lowpass module works, at least for local contrast effect, a pure grey image (constrast = 0) doesn't affect the original image (overlay blending).\nThe more the grey image goes away from grey (contrast <> 0 and more the luminosity is far from grey), the more the effect is important.\nIn the current module, this difference is calculated by reference to grey (50).\nThe fulcrum gives the ability to change the reference to calculate the difference. With fulcrum = 25 for example, all points for which the luminosity is closed to 25 won't be affected. This gives a pivot point in the low light. On the opposite, fulcrum = 75 will not affect the high lights around 75. But in both case the contrast will boost the local difference, either in low or in high lights.\nA demo would be easier ... :-)\nIf constrast = 0 (brightness and saturation = 0), the image should be full grey, right ?\nIf you change the fulcrum, there is no reason to affect the image, right ?\nIf, in the formula you add fulcrum instead of 50, changing fulcrum will change the image.\n\n\n. > A fulcrum means you roll the contrast around that value, without affecting that value. So, for contrast = 0, the image should be == fulcrum everywhere.\nNo, I don't agree.  I think you don't get my point.\nThe \"no change\" is a full grey image (all points=50).\nThe driver of the change is the contrast. If contrast is null there is no change, whatever the fulcrum (the fulcrum is only the pivot of that contrast !). Then the image is still full grey. And that's the way I imagined it should work with overlay blending (I haven't tested other modes but I don't see why this wouldn't work the same way).\n\nThe proper behaviour is obtained with:\n\nI don't agree, neither. I've seen the behaviour of this in my tests and that was not what I expected. Nevertheless I'm curious to see the usage we could do of it, you have probably another idea. \n. > For each pixel == fulcrum, output = input for all contrast value. That's what a fulcrum is. That's not what your algo does. What you call fulcrum is a normalization shift\nI can agree on this.  \n\nAs of now, the fulcrum was hard-set at 50%,\n\nI'm afraid the lowpass module doesn't work as you describe neither. The hard-set 50% value cannot be a fulcrum because for contrast = 0 the current output is a flat grey image, then the sentence For each pixel == fulcrum, output = input for all contrast value. is not verified.\nSo what about changing the name ? normalization shift ? contrast slider pivot ?\n. > For each (input pixel == fulcrum), output pixel = fulcrum. If contrast == 0, all output pixels = fulcrum. If contrast != 0, only (input pixel == fulcrum) give output pixel = fulcrum. Thus for all (input pixel == fulcrum), input pixel = output pixel == fulcrum.\nMy bad, that's right.\n\nuse the shadows/highlights module\n\nI'll do it tonight.\nEDIT: stepping back. \nYour statement is correct when that\u2019s about \u201cintensity fulcrum\u201d.\nBut this module provides an image of contrast, which by definition is grey for contrast = 0, whatever the intensity. \nTherefore \u201ccontrast fulcrum\u201d seems to be the correct name as a fulcrum is nothing else than a pivot point, here the intensity pivot point, around which rounds the contrast (delta intensity) but not the intensity itself.\nWhat remains constant on that point is not the intensity but the contrast (giving a grey point 50% or contrast = 0)\n. Still a doubt. I haven't been able to find the way to use the pure \"fulcrum\" slider (like with your formula).\nDo you have any idea in mind on that way (from usage point of view) ?\n. > I just tested it with overlay and softlight, it doesn't seem to have much difference than playing with the brightness. I didn't a full test, but by setting brightness = -1 I get almost the same as with fulcrum 75\nNot sure to understand what your trying to do.\nOne point which is sure, the fulcrum slider influences only the behaviour of the contrast slider. It has no effect on brightness and saturation sliders.. I've some difficulty to reconcile all what @Aurelien says and what I see in the module, I need to learn more. I'll try to work on the @Aurelien suggestions.\nFor the time being I agree that if the change is only ok for overlay blending it's not worth to be implemented.\nOn the other hand the full fulcrum adds a step in the process, so at this stage it isn't more useful that the other (without saying the 2nd formula needs some rework because, as is, it creates some discontinuity at contrast = +-1).\nSo I guess we can close this PR.\nCheers.\n. > equalizer [] (wavelets are not trivial, but they are nothing more than stacked low-pass filters with increasing scales)\nYes, it works nicely in the way you can choose one or different sizes of patterns to contrast or to smooth. I've also the impression that the constrast is smoothed/amplified around the local luminosity (on the opposite of lowpass and local-constrast which have a fulcrum at 50%). But one cannot chose the lumosity where the effect applies. \nIn fact it would be nice to modulate also the local contrast on different luminosity levels (kind of stacked fulcrums ...).\n\nJust use the shadows/highlights module, because that shift is exactly what its \"compress\" slider does\n\nI don't understand this. With compress = 100%, ouput = input. With 0%, shadows and highlights effects just overlap/cross over. It seems to limit the luminosity extent of each slided. I don't see the relationship with fulcrum ...\n\nOr even better, use the exposure module to increase the lightness linearly, with parametric blending in multiply mode to isolate shadows/highlights, and a blurred/feathered mask to reproduce your low-pass.\n\nSounds interesting but I haven't succeed in getting a pleasant local contrast effect. Would you have any example available ?. Looking a bit at this, colorchecker is designed for 49 patches max and is a kind of 1D LUT file (while not RGB but Lab).\n3D LUT files can have 256x256x256 patches max. I've opened some with LUT_3D_SIZE 64 (64x64x64 patches). The corresponding file size is above 7Mb. That will impact seriously the preset size.\n\n\nNote that @houz has something like that working, but not it dt\n\n\nWhere we can find this ?\n. 970Kb is for a LUT size = 33 while 7Mb is for LUT size = 66. The one I've downloaded is SLog_WB_Blue.cube but I don't remember where I've got it from.\nIs it possible to look at the@houz work ?. What you describe in the initial post shows that usages are diverse and can be applied at different stages of the development.\nThen which RGB space the LUT should be applied to ?\n. > Usually, it's REC2020 or ACES P0.\nRT, using haldclut png files, checks and uses the lut color space. \nCube file doesn\u2019t contain any color space information.\nThe lut files can be used also for color space transformation, in fact for any transformation, including mimic a full dt style, for example.\nI haven\u2019t the answer, but I think it may be more complex than referring automatically to REC2020 or ACES P0, though they could be the default space. Depending on the rgb space used the rendering will be different, won\u2019t it be? \n. I would to start on this topic.\nI've found a module which have never been merged:  haldclut (png file) import (https://github.com/PkmX/darktable). I've tested it and it works.\nHaving a specific module seems to me more appropriate and simpler than deviating color checker which more an UI to manage color patches.\nStarting from there, I would rename it to something like lut3d, and add the following features:\n- select and open cube files\n- select application colorspace (sRGB, linear RGB, Lab, XYZ, ...).\nEDIT. I'm now able to open and apply a cube file as an haldclut (png) one. \nTo be noted: haldclut files are usually more accurate than cube files. The minimum haldclut level seems to be 8, which is equivalent to a cube size = 64. And of course the png file is more size efficient than a text cube one.\nI've now some questions.\n1- where to place this lut3d module in the pipe ? It is initially placed on the late sRGB section. Ideally the user should be able to choose the place, depending on the usage, camera profile or end grading tweaking.\n2- log. As you have mentioned a lot of cube files are designed to log input. We could rely on your unbreak log module. Or we could add an option to lut3d module. In that case we probably have to mimic the black point & dynamic range management too. What's the best ?\n. > I don't understand why the hue gets involved in the chroma correction.\n[..] so you are shifting input hue by the same amount you shift the chroma ? \nThe channels C(L) and C(h) do not modify L and h, but just apply correction on C for the selected L or h.\nPer default the value 0.5 means no correction.\nedit: for example, for this node a correction of -5.7% is made on C for the node's hue. For the color picker pixel, the C varies from 15.5 to 13.8 (correction cumulated with the C(L) channel is any).\n\nI look at the other comments and come back to you.\n. One question. \nAdding LCh doesn't change any parameter. From this standpoint there is no difference between version 4 and 5. Therefore is the version 5 necessary, desirable ?\n. >this PR is only about a new GUI interface which are actually triggering the current parameters in a different way. Right?\nExact.\n\nif there is no new parameter and if the current edit are 100% compatible with this new version you do not have to change the version.\n\nOK, I'll remove the corresponding code.\n. > This will introduce conflicts with PR 1841, maybe it will be better to wait until it is merged.\nWhich kind of conflict ?. @edgardoh, thanks for explanation. Do you have any idea when this merge is expected ?\nEdit: by principle tonecurve can use whatever color space Lab, rgb, LCh and why not any other.\nBut this is known only after the user choice. Is the new design (PR 1841) considering this ?\n. I've noticed an issue on data shifts. I'm unsure how to handle that.\nThe goal of LCh is to make changes on L and C letting the other channels untouched.\nThis never happens ...\nSome screen captures here:\ntonecurve_calculation_issues.docx\n- Changing Luminance shifts a & b on color picker (same for LAB independant channels).\n- Changing Chroma shifts Luminance and Hue.\nThat may be a normal behaviour but that's disturbing to have a measure (color picker) which contradicts what we try to do ... :-)\nWhere and when color picker does make the measure (before or after output color profile) ?\nWhat do you think ?\nIs it possible to improve this ?\n. >I'm not sure I understand you question\nNo problem, the question is maybe stupid. I'm looking forward to seeing the new code.\n. >  if you don't affect the hue, you don't need sinf() or cosf() \nExcellent ! I should have seen that. I'll do it.\n\nit's not really hue-invariant nor chroma-invariant.\n\nBut maths on Lab<->LCh do not say that ... what does happen ?\n. In fact the issue I see (maybe wrongly) is already visible in Lab independant channels.\nBefore L(Lab) change (L on color picker and local sample are almost the same):\n\nAfter L(Lab) change:\n- L on color picker is really different from new sample (should be the same)\n- a & b have changed while we are Lab independant channels mode ((a^2+b^2)^0.5=85,53->65,56 and b/a=0,707->0,728 <=> Chroma & Hue changes).\n\nThat sounds very strange for me I would like to understand.\n\nLab -> Lch -> c = funct(hue) -> Lab (ie chroma adjustement) does not retain the a and b values (or ratios) ?\n\nYes. Before change b/a = 0.707\n\nAfter C=funct(hue) change, b/a = 0.864 (=>hue change, also visible on the histogram vertical bars).\n\n. > the global color picker works after the output color profile\nThanks for confirming this. Good to know and that explains at least the mismatch.\nSo it would very interesting to be able to choose where in the modules chain the color picker picks ....\n. @edgardoh, are you talking about tc-rgb or PR1841 ?\nI was thinking about rgb too, kind of LRGB (4 tabs) independent mode. In that case the module should be a bit refactored (1 or 3 tabs are hard coded everywhere). Was it your idea too ? It could be interesting to share our views. But this is not the subject of that thread, we may talk about this in another place.  . @edgardoh. I've had a look at your code and effectively our code overlap everywhere.\nI suggest to introduce RGB independent mode along with LCh (taking your code where necessary).\nI think it would be better to transform RGB linked channels to RGB independent channels with 4 tabs (L, R, G, B). That's more work but I think it's better for the user to have the 4 tabs in the same module.\nIn that version I would exclude obviously the call to color space you are implementing and also histogram, but with your help, we can try to turn the next step (PR 1841) as easy as possible.\nWould that make sense ?\n. > you can add the option for the modules to ask for a histogram on a specific colorspace and ready to display, in this case the module can still have the input image in Lab and display the histogram on all the colorspaces\nThat sounds great but how can I ask for an histogram on a specific colorspace ?\nSecond point. Your mode RGB linked channel doesn't behave as the normal one, as the later shows a different histogram (same as Lab in fact). This may be a problem for backward compatibility (nodes at different positions). Any thought ?\nYours:\n\nThe normal one:\n\n. Added a mode for LRGB, without histogram.\nOpen cl not yet updated.\nIs there somewhere in dt some common definition for :\n- LCH colorspace\n- RGB luminance coefficients \n?\n. @TurboGit, There is one line conflict. What should I do ?\n@edgardoh, I'd a look at histogram code. I've not found the way to delude the system to make calculate the histogram in the needed color space. And coding all this seems to be a lot of work which will be useless as soon your PR is on. Is not better to wait for your PR to complete the histogram piece ?\n@aurelienpierre. RGB luminance from my standpoint is something like:\n0.2126f * inl[0] + 0.7152f * inl[1] + 0.0722f * inl[2];  // luminance RGB\nI use that to provide the sample value for the L channel of LRGB, but it should be also necessary for the corresponding histogram.\n. @TurboGit \nThanks for the instructions. I did it (at least I hope). In that process I've seen conflicts with changes made by other people but not the in file I had changed.  And after final push I got several new conflicts (still other people changes). However when I do \"git rebase origin/master\" everything it says  \"Current branch already up to date\". I'm missing something ... :-(\nEdit: I should say \"messing everything\" ... instead of 3 changed files I've now 184 ...\nEdit2: I've rolled back my local branch to my last commit (d791448) and I've checked that I've all my changes. When I do git push origin tc-LCh2 it tells me that everything is up to date ...\n. > This is strange, what if you force push the rollabck commit:\n\n$ git push -f origin tc-LCh2\n\nSame answer with or without -f\n\nIf this does not work, something is quite messed up on your side. In that case you may want to start over master:\n\nI did the rest and except git show which didn't do anything (but I had the kept the files somewhere else):\n\n$ git show tc-LCh2-old:src/iop/tonecurve.c  > src/iop/tonecurve.c\n$ git show tc-LCh2-old:data/kernel/basic.cl > data/kernel/basic.cl\nHope this will solve the mess :)\n\nYes ! Thank you so much :-)\nJust to check my normal workflow:\nTo update my local dt master:\n$ git fetch upstream\n$ git merge upstream/master\nTo create a new branch and update it on remote:\n$ git checkout -b <branch>\n$ git commit -a\n$ git push -u origin <branch> first time then $ git push origin <branch>\nSometimes to update the local branch against local master:\n$ git merge master but I've understood here I could use also $ git rebase master.\nAs an editor I use atom. Could the git command from atom introduce issues ?\nIs there anything I should avoid ?\n. > \n\n\n@aurelienpierre. RGB luminance from my standpoint is something like:\n0.2126f * inl[0] + 0.7152f * inl[1] + 0.0722f * inl[2]; // luminance RGB\nI use that to provide the sample value for the L channel of LRGB, but it should be also necessary for the corresponding histogram.\n\nOk, that's exactly how we compute the Y channel of XYZ space, so it's redundant.\n\nI see some difference between XYZ and RGB on the image (dt 2.6 and 2.7) and on the color picker value (dt 2.7 with the same correction and this PR). I've not checked the matrix RGB<->XYZ transformation against the the above formula (I should, shouldn't I ? :-) ) but I'm afraid that's not quite the same.\nThen if XYZ and RGB luminances were the same we should not keep both modules, correct ?\n. @edgardoh \n\nI don't know what you're planning to do, so I can't tell.\n\nNot sure understand this. I'm just proposing these two modes, LCh and (L)RGB. I've also tried to make easier the implementation of other future modes. Are still missing two items:\n- histogram for new modes\n- log histogram\nAs you have said displaying an histogram which is not related to the colorspace being used is weird. That's why I've removed them so far.\nBut the histograms are useful and we should provide them. I see two ways.\nThe first one is to wait for the selectable colorspace (your PR). In that case the histogram will be calculated automatically in the right colorspace by histogram.c (if I've\" understood properly) and I'll just have to enable them where needed in tonecurve.\nThe second way would be to write some code to simulate in \"tonecurve\" the histogram calculation as you suggested. Is that correct ? But from my standpoint that would be useless work if your PR is coming.\n. > @phweyland , in my last message I give some options on how to display the histogram and how the curves can behave, what I don't know is which one (if any) you will choose. Will it have the same behaviour as my PR (shifting the 50% gray with an S curve)? Something different?\nOk, I've missed this one : when the colorspace don't have a 50% grey an S curve will cause a shift on the middle grey , I don't think that this is correct..\nI would not agree on this, I think this is correct. I'm happy with those you have produced. Whatever the colorspace (Lab or RGB), applying a manual S-curve (or whatever change) may change the grey point, ie, move it out of 18% or 50%.\nThe histogram which is shown is the module input histogram. There is no module output histogram. The general histogram shows the output of the output module if I'm right. It can be very different of the tonecurve module output one, especially the linear ones.\nSo maybe it could be interesting to show both the input and output histograms of tonecurve (overlapped drawing)...\nNow the linear colorspaces show most of the points on the left handside of graph. That's where the log histogram helps the user to better control his changes on this part.  \n. >Well, I don't find it intuitive and I don't think that's how other programs behave, but not my call. But since this will change how the tone curve behaves now, you should check with the dev team to see if they are OK with this change.\nRight. . @TurboGit \nLooking at the way to add the waveform histogram I'm wondering where to put that code.\nA lot drawing routines are put in draw.h, which surprises me a bit because the code distributed in every file referencing it, using it or not. Shouldn't we setup a draw.c file ?. >  And a standard S curve is not supposed to shift the middle grey, as shown by the current presets \"contrast * (linear)\"\nYes because this particular preset sets a node on (x,y) = (50,50) given in Lab color space, which is weird because in the same time the preset sets the tonecurve mode to RGB ... \nThe other presets, which do not set a node on middle grey (50,50) (or (18,18) depending on the color space we use), do not preserve the middle grey.\nBut I agree we need a consistent method to display the histogram. \nToday, the pipe works on Lab and the main histogram is displayed on monitor RGB, the tonecurve one in Lab ...\nOn one hand we could say that the tone curve histogram should follow the main one (monitor or display RGB).\nBut on the other hand the tabs a & b for Lab , C & h for LCh, have nothing to do with RGB.\nCurrently the tonecurve mode selects the working color space (on which the curve is applied).\nWe could let the user choose also the tonecurve histogram color space, whatever the working color space.\nI see now that only one preset works with my change, the Lab one (Nikon 750). The others pretend to use RGB but provide Lab nodes...\nEdit: I've fixed the issue on the preset, but as the Lab nodes are read in the working color space, the result is not as expected (by the preset). Another principle to establish: are the preset nodes in the tonecurve working space or always in Lab ?\nYes, others standpoint would be very welcome.\n. > @aurelienpierre \n(But @phweyland, you have removed that part.)\nOK, I understand the purpose of this now. The current full tonecurve module UI (histogram, color picker, presets and saved values) is Lab based while some LUT operations are made on other color spaces (XYZ and RGB). Displaying the Lab luminance for RGB or XYZ is not really an issue (while counter intuitive from my stand point). I'll revert my changes on this (at least to keep the downward compatibility).\nWe could do the same (translate presets to Lab) for LCh and LRGB but some channels (C(L), C(h), R, G B) have nothing to do with Lab luminance. For these channels the Lab luminance is useless. We need to present to the user a meaningful histogram with the associated color picker and presets values.\nRemains, as @edgardoh pinpoints, to choose the correct RGB color space to be displayed (histogram, color picker, presets). Linear RGB (grey at 18%), the one that @edgardoh doesn't like too much ? the sRGB one as on the main histogram (not sure that grey is at 50%) ?\nsRGB would have the advantage to be homogeneus with the main histogram (linear, log and waveform when available).. > Although having a Lab histogram is not super intuitive, it is consistent with the rest of the UI.\nI'll make a try with this philosophy. Thanks for the piece of code. That enlightens the way the histogram is built.\n. I've updated LRGB with Lab UI (presets, color picker, histogram), but open_cl.\nThat doesn't simplify the code but as @aurelienpierre said the UI is consistent with the rest of the module.\nHowever, locally built histograms are still dancing.... @edgardoh \nAs @aurelienpierre suggested I find the Lab like histogram quite effective for R, G & B channels.\nThe problem is that the module is not the right place to make these calculations. I cannot get access to input buffer when executing dt_iop_tonecurve_draw(). On the other hand I cannot control the exclusion between process() and dt_iop_tonecurve_draw().\nIf I understand properly there are already histogram calculations for each module happening inside the pixelpipe execution. That would be the right place to do it, wouldn't be ? But we need to make the module able to choose the needed histogram. In some way that's what you are doing for the module's input/output colorspaces, but for the UI colorspace. What do you think ?\nEDIT: Finally I've found the cause of instability of histogram: process() is called twice, once for preview and once for development.  That's enough to get different data. So I think that the current way will work.\n. @turbogit, I think the current state is ok to be reviewed.\nBoth LCh and LRGB independent modes are added, showing histograms in LAB to be coherent with others modes. Open cl is also implemented.. > So what you call LRGB is the same curve applied on all RGB channels ?\nIn this mode, RGB independent channels, L is equivalent to RGB linked channels. R, G, B independent curves are applied just after.\nNB: I'm making some tests adding to RGB linked channels the weighted yellow power norm described in the link you have provided on darktable-dev message Color management in HDR setups. I find the results interesting (not yet in that PR).\nIn fact we could propose several of these norms which control in some the behavior of the S curve.\n@TurboGit. The build fails for some reason I don't understand. Any advice ?\n. > so that could end up in a general API:\nInteresting. In the article you've indicated the 2 norms are:\nBasic power norm: (R^3+G^3+B^3)/(R^2+G^2+B^2)\nWeighted yellow power norm: 0.83743219(1.22R^5+1.20G^5+0.58B^5)/(1.22R^4+1.20G^4+058B^4)\nIs the routine you've given above already merged ? Of course we could put together all valuable ones.\nComment: as a lut is applied on the output, it should be scaled to [0,1], right ? \n. > It should not be done, please make sure the submodule is not touched.\nOK. If I understand I should not execute  git submodule update, correct ?\nExcept maybe at each dt new release ? Otherwise how to know when I should do it ?\n. @aurelienpierre \nI've add the 2 norms I had plus yours to RGB linked channels. Please review the corresponding formulas. Of course we could remove the less relevant ones, but globally that seems promising. \n. In fact I\u2019m afraid our calculations are exactly the same :-)\nRgb = rgb * lut(norm) / norm\n. @aurelienpierre \nI've applied the suggested changes.\nIf you have the opportunity to build it, I've set open cl routine without normalization while I've inserted the per 3 division on openmp routine. So you can see the difference by enabling / disabling open cl.\n\nthe power and yellow weighted norms are only empiric ad-hoc formulas, so I'm very suspicious with that.\n\nI thought you were advertising this ... :-).\n. @edgardoh\nSo far I haven't made nothing specific to converge towards your PR. Is there anything I should look at or do to facilitate the integration with your PR ? . @TurboGit I'm sorry. I think I don't as I should. \n\n$ git rebase origin/master\nCurrent branch tc-LCh2 is up to date.\n\nThen I did try this:\n\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git fetch upstream\nremote: Enumerating objects: 899, done.\nremote: Counting objects: 100% (899/899), done.\nremote: Compressing objects: 100% (11/11), done.\nremote: Total 1362 (delta 888), reused 899 (delta 888), pack-reused 463\nReceiving objects: 100% (1362/1362), 1.48 MiB | 1.33 MiB/s, done.\nResolving deltas: 100% (1128/1128), completed with 225 local objects.\nFrom https://github.com/darktable-org/darktable\n   a9ce955a7..a3f7a6d24  darktable-2.6.x -> upstream/darktable-2.6.x\n * [new branch]          gphoto          -> upstream/gphoto\n * [new branch]          lighttable-undo -> upstream/lighttable-undo\n   3fedabc25..6b51ef1b8  master          -> upstream/master\n * [new branch]          po-ui-refactor  -> upstream/po-ui-refactor\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git submodule update\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git rebase upstream/master\nFirst, rewinding head to replay your work on top of it...\nFast-forwarded master to upstream/master.\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git checkout tc-LCh2\nM       src/external/rawspeed\nSwitched to branch 'tc-LCh2'\nYour branch is up to date with 'origin/tc-LCh2'.\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git rebase master\nFirst, rewinding head to replay your work on top of it...\nApplying: restrict metadata to lightable call\nUsing index info to reconstruct a base tree...\nM       src/develop/lightroom.c\nFalling back to patching base and 3-way merge...\nNo changes -- Patch already applied.\nApplying: Add LCh and RGB independent curve modes to tonecurve\nApplying: Fixed log histogram\nApplying: Restore automatic XYZ and RGB Lab LUT conversion\nApplying: LRGB UI changed to lab; Added RGB independent histogram\nApplying: Fixed the instability of R, G & B histograms\nApplying: Added Open cl\nApplying: Added rgb_norm combo to RGB linked channels\nApplying: improvements from review\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git submodule update\nSubmodule path '../src/external/rawspeed': checked out '0b91a7447ab33994dbb7dc9c249793218a2a4e00'\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git commit -a -m \"rebase and fix rawspeed update issue\"\nOn branch tc-LCh2\nYour branch and 'origin/tc-LCh2' have diverged,\nand have 97 and 24 different commits each, respectively.\n  (use \"git pull\" to merge the remote branch into yours)\nnothing to commit, working tree clean\nPhilippe@DESKTOP-JQ7D8F9 MINGW64 ~/dt-phi/build\n$ git push origin tc-LCh2\nUsername for 'https://github.com':\nPassword for 'https://phweyland@github.com':\nTo https://github.com/phweyland/darktable.git\n ! [rejected]            tc-LCh2 -> tc-LCh2 (non-fast-forward)\nerror: failed to push some refs to 'https://github.com/phweyland/darktable.git'\nhint: Updates were rejected because the tip of your current branch is behind\nhint: its remote counterpart. Integrate the remote changes (e.g.\nhint: 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\n\nI tried to rebase my local branch master on upstream, then to rebase the branch tc-LCh2 on local master.\nDoesn't work neither.\nDo I use correctly upsteam/master to my local branch master ?\n. I've made:\n$ git submodule update (and got a new commit #)\n$ git commit -a -m \"fix rawspeed update issue\" (tells me there is nothing to commit)\n$ git push origin tc-LCh2 --force (which worked this time)\nand rawspeed is still there as a changed file... (but commit history seems to be clean now). git fetch origin doesn't do anything.\nso I've done git fetch upstream (which brought the branch po/tc-LCh2)\nand then done git reset --hard upstream/po/tc-LCh2 on my local tc-LCh2 branch.\nI still see this rawspeed modified thing ....\nAt this stage should I git push origin tc-LCh2 ? (should not work with unstaged rawspeed change)\nRepeating things I've finally got rid of rawspeed change and was able to push to remote tc-LCh2 --force.\nI had to force my remote master too.\nThanks for help. I hope that will solve the travis build.\n. @TurboGit, I'm not an expert but I think that's all valuable. I'm done with what I wanted to do.\nFor me it's time for review and test by others. I would like to have their view. Useful or not ? Improvements ?\nMaybe two questions in particular:\n- RGB norms: we have the technical ones as @aurelienpierre suggested. What about some other experimental ones ? \n- Histogram implementation inside the module instead of the core histogram modules. Is that correct ?\nThanks\n. Having seen the tutorial 10 on https://3dlutcreator.com/3d-lut-creator---tutorials.html I thought it could be more useful to have these tabs on LCh mode: L, C(C), C(L) & L(C). \nAnd if this makes sense, it would be also interesting to be able to switch of colorspace with the same tabs.\nThere is now some conflicts with tonecurve.c ... I understand we don't merge something which is not 100% finished. But on the other hand there is no way to get user feedback if we don't merge somewhere in a kind of sandbox or quality space for testing. How will things go forward ?\n. I've checked with 2.7, with 2.6 with new database from scratch, I get the same result, for both creating a new folder and exporting for an existing folder (here my desktop).\n\n. -d traces for export to existing folder:\n``\n[dev_pixelpipe] modulepoint noir/blanc raw' min: (0.001072) max: (1.057842) [export]\n[dev_pixelpipe] module balance des blancs' min: (0.001311) max: (2.202460) [export]\n[dev_pixelpipe] modulereconstruire hautes lumi\u00e8res' min: (0.001311) max: (1.00 0000) [export]\n[dev_pixelpipe] module d\u00e9matri\u00e7age' min: (-0.048494; 0.000000; -0.009361) max:  (1.032105; 1.000000; 1.252111) [export]\n[dev_pixelpipe] modulecourbe de base' min: (0.000000; 0.000000; 0.000000) max:  (1.004701; 0.999985; 1.034031) [export]\n[dev_pixelpipe] module profil de couleur d'entr\u00e9e' min: (1.251348; -106.764259;  -79.662918) max: (102.092522; 87.188484; 182.408234) [export]\n[dev_pixelpipe] modulerenforcer la nettet\u00e9' min: (-2.761406; -106.764259; -79. 662918) max: (114.538879; 87.188484; 182.408234) [export]\n[dev_pixelpipe] module `profil de couleur de sortie ' min: (0.000000; 0.000000;  0.000000) max: (1.155800; 1.229580; 1.197575) [export]\n[xmp_attach] C:\\Users\\Philippe\\Desktop\\20180212_BH_001.jpg: caught exiv2 excepti on 'C:\\Users\\Philippe\\Desktop\\20180212_BH_001.jpg: Failed to open the data source: No such file or directory (errno = 2)'\n```\n-d traces for creation of a new folder folder:\n2.192547 LUA ERROR : cannot open C:\\Users\\Philippe\\AppData\\Local\\darktable\\luarc : No such file or directory\nEdit: The first error (export to existing folder) comes from exif.cc. It seems to be right as the file is not created.\nFor the second error (create folder) the unique place where I can find no such file or directory is there (database.c) :\n```\nstatic int import_images(lua_State L)\n{\n  char full_name = g_realpath(luaL_checkstring(L, -1));\n  int result;\nif(!full_name || !g_file_test(full_name, G_FILE_TEST_EXISTS))\n  {\n    g_free(full_name);\n    return luaL_error(L, \"no such file or directory\");\n  }\n```\nC:\\Users\\Philippe\\AppData\\Local\\darktable\\luarc doesn't exist actually.\nTraces from 2.7\n. >     * what is the -d traces switch?\n-d all sorry for not mentioning. But it works only for 2.7. With official 2.6 I don't get the messages on console, but in darktable-log.txt.\n\n\nHow do you specify the output folder? Typing in the folder by hand or by using the directory selection button?\n\n\nUsing the directory selection button.\n\n\nDo you have LUA scripts enabled and if yes which one? Is LUA configured properly?\n\n\nOn my normal dt installation I have lua configured and these scripts:\nrequire \"official/yield\"\nrequire \"dt-plugins/maintain-tags\"\nrequire \"dt-plugins/groupDerivedImages\"\nrequire \"dt-plugins/OpenInExplorer\"  Edit: under development. Not yet working\nrequire \"BzKevin/enfuseAdvanced\" Edit2: aligns but exits blending with error\nHowever only those which do not use files seem to work (but slowly apparently)...\nAnd I don't remember how I did configure LUA the first time.\nOn the testing dt, I often delete darktable local folder to start with a fresh database. On this one there is no lua(rc) file. \n\nIn both (2.6) cases I have the same errors both on folder creation and export into an existing folder.\n. Trying to troubleshot.\n1. deleted darktable folder. not luarc file => message:\n1,771488 LUA ERROR : cannot open C:\\Users\\Philippe\\AppData\\Local\\darktable\\luarc: No such file or directory\n2. adding luarc file + some scripts => message:\n1,875614 LUA ERROR : ...ppData\\Local\\darktable/lua/dt-plugins/OpenInExplorer.lua:31: module 'lib/dtutils.file' not found:\n    no field package.preload['lib/dtutils.file']\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\share\\lua\\5.3\\lib/dtutils\\file.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\share\\lua\\5.3\\lib/dtutils\\file\\init.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\lib/dtutils\\file.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\lib/dtutils\\file\\init.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\share\\lua\\5.3\\\\lib/dtutils\\file.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\share\\lua\\5.3\\\\lib/dtutils\\file\\init.lua'\n    no file '.\\lib/dtutils\\file.lua'\n    no file '.\\lib/dtutils\\file\\init.lua'\n    no file 'C:\\Program Files\\Darktable\\share\\darktable/lua/lib/dtutils\\file.lua'\n    no file 'C:\\Users\\Philippe\\AppData\\Local\\darktable/lua/lib/dtutils\\file.lua'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\lib/dtutils\\file.dll'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\..\\lib\\lua\\5.3\\\\lib/dtutils\\file.dll'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\loadall.dll'\n    no file '.\\lib/dtutils\\file.dll'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\lib/dtutils.dll'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\..\\lib\\lua\\5.3\\\\lib/dtutils.dll'\n    no file 'C:\\Program Files\\Darktable\\bin\\..\\lib\\lua\\5.3\\loadall.dll'\n    no file '.\\lib/dtutils.dll'\n\nadding lib folder for lua. Scripts start ok.\nWhen trying to export an image to an existing folder:\n[xmp_attach] C:\\Users\\Philippe\\Desktop\\20190121_Chartres_001_01.jpg: caught exiv2 exception 'C:\\Users\\Philippe\\Desktop\\20190121_Chartres_001_01.jpg: Failed to open the data source: No such file or directory (errno = 2)'\n[imageio_storage_disk] could not export to file: `C:\\Users\\Philippe\\Desktop\\20190121_Chartres_001_01.jpg'!\nWhen trying to create a new folder:\n\nHere is the trace: darktable-log.txt\n\nI guess that LUA issues are misleading here and export selected should work without lua installed, correct ?\n. Without luarc, same issue for both folder creation and export in existing folder.\nBut, by mistake I've created successfully a test folder on C:. And then export there does work.\nSo in fact any system folder, C:\\users, C:\\users\\Philippe\\desktop or D:\\Documents or D:\\Documents\\Images (that's where my images are), creates an issue.\nBut when I use a non system folder everything works fine (with or without luarc).\nAbout \\\\ or \\ here is what I have in a working case:\n\n\n. When there is no image in the folder I get the same as you. When there is already an image in the folder I get \\\\ or \\\\\\\\ depending the way I open the folder test2.\nBut that doesn't not prevent export to work.\nTwo:\n\nFour:\n\nHere I've played:\n1. failing folder creation (in D:\\Documents)\n2. failing export into D:Documents\n3. successful creation test and test2 on D:\\\n4. successful export into D:\\test\\test2\ndarktable-log.txt\n. > Is perfectly normal as far as I know\nWithout lua, that's right.\n. > can you check the permissions for those folders where the export fails?\nOn D:\\ all folders Documents as test\\test2 have write access for all authenticated users. I don't see any difference there.\n\nCan you launch darktable as admin ?\n\nThis produces the same effects as for a non admin user (authenticated user).\nIf you have other ideas to be tested don't hesitate to ask me. Meanwhile I'll have a look at the sources.\nPS: all this worked fine with 2.4.4.. > PS: all this worked fine with 2.4.4.\nTo be sure I've uninstalled 2.6.0 and installed again 2.4.4. .... which has the same issue now.\nSo the problem is on my system, for some reason I've to discover. Sorry for inconvenience. :-(\nPlease close the issue.\nEDIT: Setting some printf on jpeg.c I verify that:\ng_fopen D:\\test\\test2\\20190121_Chartres_011_02.jpg is OK\nbut \ng_fopen D:\\Documents\\20190121_Chartres_011_01.jpg  gives the error No such file or directory\nbut the extension _01 shows that it has detected the presence of 20190121_Chartres_011.jpg (which is correct).\nAm I drunk ?\nEDIT2: end of the story. I've reinstalled the OS and the issue has gone.\n. > PS: all this worked fine with 2.4.4.\nTo be sure I've uninstalled 2.6.0 and installed again 2.4.4. .... which has the same issue now.\nSo the problem is on my system, for some reason I've to discover. Sorry for inconvenience. :-(\nPlease close the issue.\nEDIT: Setting some printf on jpeg.c I verify that:\ng_fopen D:\\test\\test2\\20190121_Chartres_011_02.jpg is OK\nbut \ng_fopen D:\\Documents\\20190121_Chartres_011_01.jpg  gives the error No such file or directory\nbut the extension _01 shows that it has detected the presence of 20190121_Chartres_011.jpg (which is correct).\nAm I drunk ?\nEDIT2: end of the story. I've reinstalled the OS and the issue has gone.\n. I've placed the module on the lab part of the pixelpipe (before tonecure).\nI've moved the clut encoding from process() to commit() (in fact should have been the comment of last git commit).\nTo apply a log 3D Lut one has just to use unbreak module to provide a compatible input.\n. I've played a little with some free 3D lut files I've found on the web. That's sometime amazing.\nSome of them seem to work with gamma sRGB D50 (as converted from Lab in dt).\nBut a lot of them are specified for these colorspaces:\n- Generic log. Not sure that corresponds to unbreak log + prophotoRGB ...\n- REC709 \n- BMD Film Color Space\nIn any case white balance should be done before applying the lut.\n. @TurboGit \nI haven't escaped the rawspeed issue here:\n$ git diff lut3d master\ngives:\ndiff --git a/src/external/rawspeed b/src/external/rawspeed\nindex 0b91a7447..d761f50b1 160000\n--- a/src/external/rawspeed\n+++ b/src/external/rawspeed\n@@ -1 +1 @@\n-Subproject commit 0b91a7447ab33994dbb7dc9c249793218a2a4e00\n+Subproject commit d761f50b13a32448f9d8968794c75a2ef4860525\n$ git submodule update doesn't say anything (I guess it's ok).\nI haven't yet got what I'm doing wrong...\n. I'm sorry. I can try to do it.\n. I'm there but I don't figure out what to do ... \nshould I just remove the 2 lines mentioning rawspeed ?\n\nEDIT:\nI've exited & saved from editor without making change and run the following commands.\nI don't see rawspeed anymore in my commits (git show ) but rawspeed is still in the listed changes on github :-( .\nEDIT2: rawspeed has gone from the list of changes on github. Have you fixed it ? Or github took some time to update the list ? Anyway. Should solved for today ! :-)\n. I can believe that the tetrahedral interpolation respects better the color than trilinear one due to the interpolation along the grey axis. Some papers are not so affirmative : http://ijetch.org/papers/318-T860.pdf.\nI understand also your schemas making the difference of interpolation on linear data and log/gamma data.\nBut I don't see the relationship you make between linear or log/gamma and the interpolation method, tetrahedral or trilinear. Both are linear and will deal better with linear data, correct ?\nI haven't completely decoded yet the algo from eskil steenberg (quelsolaar) but I'll make a try for tetrahedral interpolation.\n\nAlso, I think it should supports 16 bits LUTs as well, and maybe floating point too.\n\nThe current implementation uses floating point values ([0.0,1.0]).. > imageworks/OpenColorIO\nGreat ! I\u2019ll have a look at it ASAP.. I've added tetrahedral mode. Interesting to dive into these lut interpolation methods. :-)\nBut side by side I've to admit I don't see any difference. I've probably to change my glasses ! :-)\n. I've added the pyramid interpolation. It brings more visible difference on the image and some more noise on histogram than the others. On histogram we can see some difference between the 3 methods.\nI've also moved the module toward the end of lab pixelpipe where I find the results more convincing (on REC709 or sRGB). But I'm not sure about the method. Where the priority of the module should be determined ?\nI've not found any LUT to be applied on linear RGB so far. The same for Lab and XYZ. Any link would be appreciated.\nRemains the case of LUT on LOG space. I can get some result tweaking exposure + unbreak + tonecurve and applying the LOG LUT on linear RGB. But that's far less straight forward.\nEDIT. Another point. I haven't implemented the feature of Domain min / Domain max. First because I haven't seen such LUTs, then because that brings a bit more calculation time.\n. > DaVinci Resolve is free and works on Linux\nOn windows too, but unfortunately it doesn't come with any lut and, worse, it doesn't uninstall properly. :-(\nI had already those which are on free download (only Log and rec709).\n\nyou could reuse the log\n\nI guess I haven't any other option than to follow LAB -> linear prophotorgb -> log. It's already a bit far from raw but I'll have a look at that.\n. > you could reuse the log in your module\nI did it, it works but the result is not consistent.\nOriginal image with only exposure.\n\nWith M31 REC709 applied on REC709\n\nWith M31 Log apply on log2 (log2 to lin alllows to disable the inverse transformation and tweak the log parameters with an identity LUT)\n\nSame with log2 to lin disabled.\n\nI've found a Fuji spec which gives their log formula (http://www.fujifilm.com/support/digital_cameras/software/lut/). I'll make a try to see if I can get something better.\n. With the Fuji log. \nEDIT: To be noted: the fuji formula domains are [0,1] on log side and [0, 7.28xxx] on linear side. I've normalized this to have [0,1] on both sides. But doing this I may screw the calibration of the Fuji Log formula.\n\nTo complete the comparison, here the REC709 LUT applied on gamma SRGB.\n\n. > I think the LUT files should be placed into a dedicated places in dt\nGood point. Dedicated, yes that helps. In dt file structure, I'm not sure as LUT files,  and ICC and watermark files as well, can be common to other tools. So I find useful to be able to set the folder somewhere, in dt default folders or elsewhere if needed.\nWe can already do this in darktablerc where there is a specific line for that: plugins/darkroom/lut3d/def_path=C:\\Documents\\Data. I've set it manually.\nIt would be excellent to have a global setting to define this root folder. I'll look at that. If any tip to do it please tell me.\n\nAnd in the interface you'll want to only display the base name.\n\nbase name ? we have 3 parts:\n- LUT folder root (global setting)\n- sub-folders\n- LUT file name\nSo if the chosen LUT file is under the root folder we should show only sub-folders/filename.ext. In other cases, root not defined, or LUT file not under LUT root, we display the full path. Correct ?\nAnd the same for saved parameters. Still ok ?. I've found that preferences have an automated process to generate the code but I haven't found any option to select a folder... while I have seen that lua plugins are able to do that ... still some search to do on that. Meanwhile I've that (folder saved as preference): \n\n. So far the folder is saved as a preference and the lut file is saved in params.\nThis way, if the root folder changes for some reason, the user has just to update it once to remap automatically all the images. If not he should update each image individually. This works as is but I would find more consistent to have the root folder managed in preferences. . > If the folder is saved in preferences it should not be seen here\nAgreed. But I've to find the way to put this part in preferences.\n\nSo of you want to handle multiple possible folders (as already discussed)\n\nThere is a misunderstanding here. The root folder is unique. But you can have several sub-folders of lut files below (at least png and cube ones).\n. @rabauke, thanks for testing this. \nI'm trying to solve the conflicts with master. I need a bit of time to do this hoping I won't break everything ...\nMy build on windows works. Are you on linux ? But I don't see where there can be a difference as soon as files are read properly. \nSo far open cl is not coded.\nI'm not sure if I do things properly to place the module in pixelpipe. On my side it works, but if the module is not on the lab part it cannot work.\nLast point I can think about is exposure which must be more or less correct before applying the lut but I'm sure you have done that.\nIf you start dt from console do you get any error message ?\nHere is a snapshot with one of the lut you talk about (The github version has not yet the split root folder and file)\n\n. @rabauke, great !\nThanks for the png fix. I'll try to reproduce the issue on windows and, in any case, make an update considering png depth.\nAbout cube,... it assumes float values between [0, 1] (default domain). \nI'm using the function strtod to convert ascii to float: lclut[i+j] = strtod(token[j], NULL)\nIs there any possibility to have different compiler behavior between linux and windows ?\nBTW. I haven't found the routine to pop an error message on UI to the user... any tip ? \n. > sscanf might be more appropriate here.\nI've replaced the first line by the second one. It still works for me. If it works for you too I'll push the change.\n//        for (int j=0; j < 3; j++) lclut[i+j] = strtod(token[j], NULL);\n        for (int j=0; j < 3; j++) sscanf(token[j], \"%f\", &lclut[i+j] );\n. Thanks @rabauke & @parafin for your help.\n@rabauke, the atof routine works perfectly (so far :-) ).\n. > \n\nsrc/common/iop_order.c has a lot of changes which just remove white space. Possibly, these changes should by reverted for this pull request. Then then change would reduce to an addition of a single line.\n\nI can do that, for sure. For my understanding what is the reason for that ? Is it not good to clean up as much as we can ?\n  . @rabauke, I've tried several times, copying the iop_order.c from master. Every time the spaces disappear.\nI see them in the master file, but I loose them somewhere... :-(\n. > What kind of editor or IDE do you use? \nI use atom. And yes, there is a setting which removes the trailing spaces and can be disabled.\nThanks !!\n. > But it should be enabled :) We don't want to have spaces at end of line.\nYes ... I've just disabled it not to pollute to much the iop_order.c file changes as @rabauke requested.\nBut ... at every addition of module ... this will be necessary. It may have been better to clean it up now.. If I can put my cent on this...\nI've understood that the new mode brought the possibility to choose the working colorspace inside each module. But to be complete that should including the blending mode. If not, the move is not finished yet, is it ? Otherwise we will have to duplicate all the modules ...\nThe multiplication of modules doing very similar things is a bit messy (some people want to turn dt yet more professional, right ?). It would be really better to make the existing modules work the right way (including tonecurve).\nNow, really, not having to convert lab to rgb  and having blending in the same colorspace sounds really good.\n. > Personally I have no strong opinion. I think I could live with both.\nI think that may be a strategic choice... \nBut whatever it is, I'm happy to contribute where possible.. > that gets more complex and difficult to maintain\nI share the concern of complexity, but I don't think it comes with the different options we could offer.\nThe actual complexity is to use a Lab design (module + environment) to work in rgb. In that design working on rgb doesn't come for free, we have to build everything:\n- color space, double conversion\n- color picker\n- histogram capture\n- without missing blending modes.\nIf a module can really choose the color space (with all items above aligned) the complexity has gone.\nIf we say that the new design enables the choice of color space it should include the above items. That would avoid unnecessary complexity. Otherwise, the possibility of choosing the color space is misleading. That's just a new color space segment (rgb) introduced into the pixelpipe. \nThat's where we come to the strategic choices.\nEither a new family of modules, working on rgb, are going to live beside (and could progressively substitute) the lab modules (In that case we cannot advertise the module can choose its color space).\nOr,  we let the module choose the best color space to make its operation. But the full environment must be available. Then, with few extra work it becomes possible to enhance the existing modules which would work better on rgb.\nFrom my standpoint, it is strategic to define clearly the targeted environment, whatever it is, where color picker, histogram, modules order are meaningful and reliable for the different usages which are offered. \nThe Lab design may have some drawbacks, but a lack of design is a disaster.\n. @edgardoh \nto learn how to use the new pixelpipe I've installed your rgbcurve branch.\nThere is the option called compensate middle grey.\nHave you already explained somewhere what are the principles of this option ? How does that work (it seems that it involves colorprofile, trc, lab) ? If not could you present it a little bit ?\nThanks\n. > since the input can be any RGB colorspace it uses the work profile.\nJust seen that we have to choose the work color profile in the module input color profile... :-)\nI guess we could add some log profile(s) to that list ... EDIT: I'm thinking to unbreak with log option which occur before input color profile. It could be recognized as such and kept as a working profile, couldn't it ? . This doesn't work with the build I've made.\nWhile it works for (line 796) :\nelse if(!xmlStrcmp(name, (const xmlChar *)\"Rating\"))\n   {\nint v = atoi((char *)value);\nI don't know if the value pointer is still valid and neither how to verify this, I'm afraid. That's why I was trying to see the dt_control_log messages, and start from there to understand what I'm doing using the log.. No, that was my first attempt but this doesn't work. Blending with the blurred layer works on grey, 50.\n\nd->ctable[k] = d->contrast * (100.0f * k / 0x10000 - d->cfulcrum) + d->cfulcrum;\n\nMakes the correction proportional to fulcrum, which is not what we look for.\n. > \n\nBut then the algorithm does not keep history as here : 50/100 is not equal to 1.\n\nYou're right, but multiplied by 2 it does.. > float kx2m1 = 2.0f * (float)k / 0x10000 - 1.0f;\n\nis not the same as\nfloat kx2m1 = 2.0f * ((float)k / 0x10000 - 1.0f);\n\nYou're right too, but\nfloat kx2m1 = 2.0f * ((float)k / 0x10000 - 0.50f);\ndoes.. > default cfulcrum is 50.\nYes. Can you explicit a bit more what you mean ?. ...\nhttps://www.wolframalpha.com/input/?i=1.+*+(x+-+0.5)+%2B+0.50,+x+%3D+%5B0,+1%5D\nWhy 0.25 ?\n. ok. done. Great ! Done.. Hue doesn't change. C is modified for the selected hue.. No hue shift. Hue is just used as an index in the C table (needs 0->1).\nDiv and mul saving done.\n. \nWhy not if the accuracy is enough. Order 7 seems ok, but is it worth for calculation time ? . LUT kept as is but saving done.. Need more time to understand this.. I've added open cl support as done in the module. It uses basic.cl and colorspaces.cl. \nIt doesn't use SSE. Could be interesting to improve that.. > this is not a norm, but a mean. You should not divide by 3\nI've done but doesn't work.\nAs an equivalent to luminance it cannot be equal to 3 ...\nHere 3 is not for average, but the max of the 3 values: rgb.x max + rgb.t max + rgb.z max.\nHow else to keep this inside [0,1] ? \nSame issue for the other cases.. I understand this (keep the true color) with norm calculation. \nBut in case of norms from your referred article, the goal is to fix some perceptual artefacts at the toe and shoulder of S curve. So the calculation I\u2019ve proposed may be more appropriate in that case. In any case I\u2019ll make some experiment for those. . I understand this (keep the true color) with norm calculation. \nBut in case of norms from your referred article, the goal is to fix some perceptual artefacts at the toe and shoulder of S curve. So the calculation I\u2019ve proposed may be more appropriate in that case. In any case I\u2019ll make some experiment for those. . It works.\nBut while, for a given curve, L infinite or weighted yellow power do not change the image luminance, Lp has a strong effect on the contrast of the image for values below 2 (I've set a slider for norm_exp).\nOn the other hand above 3 I barely see any effect.\nIs that what you expect ?\nFor norm_exp = 2, we have the length of the vector, I understand that. \nEdit: but highlights are blown up. I think a normalization is necessary to control the full effect. Which normalization would be acceptable ?\nBut what is the meaning of norm_exp = 1 ? \nWhat should be the range of norm_exp ?\n. Done. Yes the formula is the one from the article. Done.. test on negative values back and fall back on calculation without norm.. removed case 2 and 3. In tonecurve (openmp) detection of exp =1 or 2 and use of simplified formulas.. I don't understand here.\nGamma sRGB anf REC.709 are very close from each other. Same matrix, just the gamma curve is a bit different. A lot of LUT are given to be applied on REC.709 which is a gamma-encoded transformation by definition.\n. Our previous comments are related to display referenced LUT.\nFor those which are scene referenced, things are less clear for me. In particular for the log LUT. We have the option unbreak(log) + lut3d(prophotoregb). Is that the right option ? Any other way to rebuild the LOG colorspace ?. > REC709 defines the RGB primaries used in sRGB but has no gamma itself, it's a linear, scene-referred space.\nAll the references I've found associate REC709 to TV display and give the definition with gamma.  Could you please provide some links where I could find better reference ?\n. ",
    "monsieurmona": "Thanks a lot for your review. It is very helpful for me.  \nA linked list is not possible here, as it makes filtering if images difficult/slow. I will think about this a little and provide an update in a few hours.. I did some performance measurements on my machine just to see how it feels. The long story short: 100k Images are at the border of what a user may accept or even above. I might be more patient than others :-). \nMy changes:\n1. The sequence pictures come in (import) define now the initial sequence of custom order. This way I able to update at linear cost. I tried hard to find a better solutions but failed on that.\n\nI use now an int64 for the position index. The upper 31 bits are used to set the initial order. The lower 32bit are used to reorder images. That way only a small amount of images must be updated while reordering images.\n\nExample: (position values hex)\nInitial order:\nImg 1: 0000 0001 0000 0000 \nImg 2: 0000 0002 0000 0000 \nImg 3: 0000 0003 0000 0000\nImg 3: 0000 0004 0000 0000\nPutting Img 2 in front of Img 1. Would give \nImg 2: 0000 0001 0000 0000 \nImg 1: 0000 0001 0000 0001 \nImg 3: 0000 0003 0000 0000\nImg 4: 0000 0004 0000 0000\nImg 3 and Img 4 is not updated. \nThats it.. Sorry, I forgot the half. Good idea, I'll add this comment in the code.\nIRC: Hanatos said that he liked this implementation, but wanted to ask Houz for his opinion. I think that was on Wednesday.  It seems that they didn't find the time yet. squash and rebase. Moin Houz,\nThanks for the review. \nI have fixed all review points. Additionally, Reordering of images (drag n drop) is only possible, if custom order is selected in the sort drop down box. \nBest,\nMario. I fixed conflicts. :(. Thanks @hanatos for merging it. Please let me know, if there are any questions or bugs or whatever. I feel responsible for that work and will solve any issues as soon as I can. \nBest,\nMario. Thanks for your feedback. \nMh, I wonder, I haven't done any changes for the film strip. I saw some (i thought not finished) drag and drop implementation there, but I avoided to touch this. Maybe my implementation has some side effects on the film strip.\nI'll find out and get back on this by Saturday. \nWhat I am not sure is how to deal with that implementation. I would just remove that for now. What do you think?. I am sorry, I am not able to change this. The drag&drop source is set in the initialization function of the filmstrip. \nSetting the source at a later point depending on the selected module (darktable or map) seems not possible - what already the comment says:\n/* allow drag&drop of images from the filmstrip. this has to come before the other callbacks are registered!\n   */\nI wonder way. So, someone who has more GTK insights might fix this. \nAs I assumed, this behaviour is independent from the change I made here. . Sorry, I have not seen this seen this. And thanks for making this clear. I somehow could not think that the main image can be dragged. I have fixed this with a new pull request https://github.com/darktable-org/darktable/pull/1748. Thanks for finding that error. Yes, it should be (1ll << 32)\nI hope C++11 is ok?\nhttps://en.cppreference.com/w/cpp/language/integer_literal. I have updated pull request \nhttps://github.com/darktable-org/darktable/pull/1749 \nPlease see the comments there.. Thanks for your feedback. I wonder, this is almost as the same as before (the usual developer excuse). It works on my machine. Do you have a callstack? \nThe unregister removes all connections (if there are any) whereas the register, connects only if we are in light table and sort by custom order. \nI'll try to find the trouble. But if you could get me callstack of that crash, it would help me a lot. \n. Got the the callstack. I found the collection is updated every time the sorting was changed. So I put the un/registering there. I did not find any better place. My knowledge of the darktable architecture is still not worth to mention. So I would be happy to get advice. \nI have fixed the crash. Please see https://github.com/darktable-org/darktable/pull/1749. if you change the sorting to let's say by filename, you don't want that drag and drop anymore. If you change it to custom order it is must be registered again. You may use here a state varible that keep track of the last state and handle registering and unregistering accordingly. But the way I have done it here is a bit simpler. Like: Clean up and if needed register. (i found it less error prone) This is not called all so often and the calls are inexpensive (someone might teach me a lesson here as I am not Gtk experienced). I'll have a look in the evening. . I have moved the registering/unregistering of drag and drop for to _view_lighttable_collection_listener_callback()\nI have fixed the error reported by @oexler \nhttps://github.com/darktable-org/darktable/pull/1677#issuecomment-429950720\n\nI get an error when trying to compile on windows.\nerror: left shift count >= width of type [-Werror=shift-count-overflow]\nI think both (1l << 32) should be (1ll << 32) . I'll check.\n\nThanks for reporting this.\nPascal Obry notifications@github.com schrieb am Fr., 19. Okt. 2018, 18:11:\n\nI think that this has broken the \"zoomable light table\". It is not\npossible to drag&drop the pictures on this view. Can you have a look?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1749#issuecomment-431415861,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHrKeJg4O-Nb4PQRSW0Akx9JrfUyy6x4ks5umfmcgaJpZM4XbVOb\n.\n. Hi Pascal,\n\nI am sorry I have trouble to get this behavior.\nWhat I have tried so far:\nUse Case: Import Images by dragging an image into the lighttable. Sort\nMode: Filename\nWorks in File Manager and in Zoomable Light Table\nUse Case: Import Images by dragging an image into the lighttable. Sort\nMode: Custom Sort\nWorks in File Manager and in Zoomable Light Table\nUse Case: Reordering images by drag and drop. Sort Mode: Filename\nDoes not work in File Manager and in Zoomable Light Table. Which is\nintended.\nUse Case: Reordering images by drag and drop. Sort Mode: Custom Sort\nWorks in File Manager and in Zoomable Light Table\nI can't find your use-case. I am embarrassed to ask, but may you please\npush me a little to the right direction.\nI am on:\ncommit 475d2ff0989d238371b10b691acf9ac3e43ab6ee\nDate:   Fri Oct 19 20:22:13 2018 +1300\ndarktable-chart: what difference a space makes\nThanks for your help.\nMario\nAm Fr., 19. Okt. 2018 um 18:11 Uhr schrieb Pascal Obry \nnotifications@github.com:\n\nI think that this has broken the \"zoomable light table\". It is not\npossible to drag&drop the pictures on this view. Can you have a look?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1749#issuecomment-431415861,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHrKeJg4O-Nb4PQRSW0Akx9JrfUyy6x4ks5umfmcgaJpZM4XbVOb\n.\n. Thanks, that helped me. I didn't know that this feature existed. :-)\n\nI would remove the custom reordering also from the \"zoomable light table\",\nas that is a rival of the move operation. All solutions I can think of, are\nsomewhat inconsistent/inconvenient. So, does anyone have a better solution?\nAm Sa., 20. Okt. 2018 um 00:11 Uhr schrieb Pascal Obry \nnotifications@github.com:\n\nOk, I did a bisect to be sure about the point of regression, the culprit\nis:\n886fab0\nhttps://github.com/darktable-org/darktable/commit/886fab099ea629cdd8160abad204144adfa56147\nis the first bad commit\ncommit 886fab0\nhttps://github.com/darktable-org/darktable/commit/886fab099ea629cdd8160abad204144adfa56147\nAuthor: monsieurmona monsieur.mona@gmail.com\nDate: Mon Oct 8 20:56:49 2018 +0200\nStarting with this commit it is not possible to move the content of the\n\"zoomable lighttable\".\nSo my suspicion was correct :)\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1749#issuecomment-431514213,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHrKeJnToDBs0JM4xmAJdoWTpR9yThJSks5umk4FgaJpZM4XbVOb\n.\n. Hi Pascal,\n\nI think I found the issue. I have fixed it with\nhttps://github.com/darktable-org/darktable/pull/1761\nIs it possible to check if that works also for you?\nThanks a lot in advance,\nMario\nAm Sa., 20. Okt. 2018 um 15:57 Uhr schrieb Pascal Obry \nnotifications@github.com:\n\nNo, disabling reordering from the \"zoomable lighttable\" is ok to me.\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/1749#issuecomment-431584120,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/AHrKeL-4ju5VW5MXwvVDYjOBI_g1I_pGks5umyusgaJpZM4XbVOb\n.\n. Thanks for your help!. I didn't think of that many pictures. There is an index on positions, so the update can be done at linear cost. But still, you are right, that many updates are not needed. I'll fix this. . I'll think about this too. . yes. I aligned this with the image id type int32_t. So the image id limits already the size to 2 billion - which should be enough.  . Sorry, I don't get it. I have actually copied that style. Do you mean binding?. \n    sqlite3_stmt stmt = NULL;\n    gchar image_pos_query = NULL;\n    image_pos_query = dt_util_dstrcat(\n          image_pos_query,\n          \"SELECT position FROM main.images WHERE id = %i\",\n          image_id);\n\nDT_DEBUG_SQLITE3_PREPARE_V2(dt_database_get(darktable.db), image_pos_query, -1, &stmt, NULL);\n\nif(sqlite3_step(stmt) == SQLITE_ROW)\n\nI would say this is a prepared statement. . I think not. [sign bit][31bit initial order][32 bit custom order] as only int64 can be used. That is the code for inserting an image into the right place . Yes, they were. I have fixed that like you have recommended.. Done. Done. Done. Done. Done. Done. Done. Done. Done. Done. Done. Done. It is a unique index now. \nMy thoughts: I was torn on that. On one hand: it is the right way to model. On the other: we don't gain much with a unique index and in case of any error while position calculation we lose error handling. . Done. Done. Done. Switching programming languages :-) ..... Done. Done. Done \nI thought a while about this and found that this here is possible:\nINSERT INTO main.images (id, film_id, filename, caption, description, license, sha1sum, flags, version, \n    max_version, history_end, position) \nSELECT NULL, ?1, ?2, '', '', '', '', ?3, 0, 0, 0, (IFNULL(MAX(position),0) & (4294967295 << 32))  + (1 << 32)\nFROM images\n\n. Done. Done. Done. ",
    "mondoman712": "@rabauke Thanks for the comments, I've made the changes suggested.. @TurboGit The patch I posted to redmine got added but this includes a couple extra changes that just clean up the code a bit thanks to @rabauke 's suggestions. . So on closer inspection there's bin another commit since I wrote this that changes a few things in the same area so the only thing left here is changing an if to a case so I'm just going to close this PR. . I went through and tested all of the exposure values in my library and it seems that they are all working except a couple like 1/7 and 1/9. There's quite a bit of rounding going on to go from the float values stored in the database to the fractions shown and it seems that I didn't get it quite right. . @TurboGit So I've been doing some digging and while I've found a couple of other minor issues in my code I haven't found an obvious cause for your issue. Could you please tell me the Exposure Time and _Shutter Speed Value_s of a couple of your photos through something other than darktable (e.g exiftool). . Yeah I was rounding everything to 5 decimal places to get around that and it seems to work on my end so I'm not sure why it wouldn't for you. I'll see if I can get it to store the values properly though.. Hi so I've resolved the conflicts but I still don't know why it isn't working for you.. whoops, fixed now.. Still works for me, thanks for the help.. nvm apparently the last one was merged. I was just scrolling through my images looking for any pairs of visually similar images from different places and thought this would be a better way to find some, but also just an interesting way to look through a collection of images. Once I came up with the idea I did then just want to see if I could implement it and I thought I'd just do it and make a PR and we can discuss whether anyone else might find it useful here. . The problem is that it switches from fraction to decimals at 0.5, but 0.4 won't show up as a fraction. You need to switch at 0.4 instead. I have attached an image with shutter speed and exposure time set to 0.4\" although you could use\nexiftool -ExposureTime=\"0.4\" -ShutterSpeedValue=\"0.4\" x.jpg to create one.\n. Yes and there's no 0.4\" in the list.. ",
    "anarcat": "Note that I never knew we could change group heads, because I never actually notice the G icon because it shows up only when a group is expanded. This is confusing because groups are \"expanded\" when \"grouping mode\" is disabled as well, but in a different way: the G icon doesn't show up then. So it makes this procedure needlessly complicated. I understand this was done so that the G icon doesn't bother people that do not want to use the grouping mode, but it seems like a huge usability cost to pay for users who do use it.\nI have always thought that the \"grouping mode\" button was just a way to collapse and expand all groups at once. I never thought this was a \"mode\" that would go on and off, so I find this behavior a little confusing.... awesome, thanks for the speedy resolution! :). ",
    "hrosenfeld": "Ok, this is from memory as I've been running darktable with this patch since June:\nI open a picture in the darkroom view, in my case one that has already been cropped a bit. I hit Alt-2 for zoom fit, but instead I'll get a 100% zoom at 0,0 outside of the cropped part of the image. If I try to move grab the image to move the view to a different part of the image it'll just turn all black. Zoom fit is completely unusable.\nBut even if you can't reproduce it yourself, doing calculations with unitialized variables is wrong in any case. Please note those two variables are initialized in the previous case and not used at all in the following case, which is why it only affects zoom fit.. ",
    "nedrichards": "I don't believe either of those interpretations are entirely correct - but thanks for engaging with the process!\nThe multimedia messaging category is specifically about audio and video chat. Nothing in darktable is responsive to a previous event from a third party in any other than a very roundabout fashion (e.g. there isn't a threaded view, you can't view third parties photos from a service etc.).\nSimilarly the location sharing is about: \" Defined as sharing your physical real-time location.\" This one is more arguable, the only case I can think of in Darktable that encompasses this would be using the tethered shooting mode with a camera that has a GPS attachment. I think that is a stretch, but am very happy to modify the PR to declare the usage.. ",
    "Skrapion": "@TurboGit I agree with your review. When I get a chance, I'll fix and test the changes.\nAs for consensus, @houz is the only person unconvinced that rating a group should affect all images in that group. I'm hoping that he thinks the new grouping collection I added offers the best of both worlds, but we won't know until he sees this PR.\nI can say that I've been using this code for a while now, and it makes it much easier to review/reject RAW+JPG groups when I'm importing a film roll. I've also found it's nice that I can make an HDR group or a timelapse group, and then select all the images in that group with a single click and export the whole thing. And then when I actually make an HDR image out of a group (which might require exporting to Hugin) I can set the final image as the group header, and then set the collections to \"group leaders\" when I want only the final HDR images, or \"group followers\" when I want only the source images. It's great!. @TurboGit I applied your suggested changes, and also updated to it merges cleanly.. Okay, tracked down the rawspeed external (not sure why that didn't merge into my branch cleanly) and squashed commits.\nThanks for your patience.. Good change. Glad you're enjoying the patch. Cheers!. Awesome, thanks!. In principal I don't mind the extra vertical space, but it will exacerbate the fact that scrolling through modules is currently a little awkward, since you have to place your cursor precisely over that 10px scrollbar before the mouse wheel works. (This would be a separate feature, but it would be nice if you could middle-click-drag the modules window.)\nIf people are really concerned about vertical space, Blender-style sliders would be better. shrug. The only impact it has on vertical scrolling is that it will require more vertical scrolling, so if scrolling is awkward, this results in more awkwardness.\nAnd yes, scrolling works the same way on your computer as it does in mine. I just think it's unusual for the scroll wheel to only work in that 10px wide strip.\nMaybe if you only have one monitor it's not so bad, because you can just throw your cursor to the right edge of the screen, but it doesn't work for multi-monitor folks, which is true of an awful lot of photographers. Can you imagine how annoying it would be if Chrome only scrolled when your cursor was on the right edge of the screen?\nAnyway, like I said, that's a separate issue. My only concern with this patch is that scrolling modules is awkward in Darktable, and this patch requires more scrolling. Right now I'm 90% behind this patch, but if there was another pull request to make scrolling modules less awkward, I'd be 100% behind it.. That would be awesome, but make sure you do that as a separate pull request, in case other people don't agree with my scrolling qualms :)\n(Also, I have no clout on this project, so my +1 doesn't mean much :P ). I don't know that it was really that unlikely to get accepted. The two committers who've given their opinions are LebedevRI and TurboGit, and both of them just had problems with the extra vertical space the original pull request took up, and after your latest screenshot, LebedevRI just asked why the new screenshot looks brighter (both the background and text are brighter on the right side).\nThe pull request process tends to be very slow in many open source projects. This isn't unusual.\nNow, if you do go ahead and implement Fabien's proposal, one option is, instead of making it a configurable setting, just make it happen automatically whenever the modules panel is sufficiently wide. (Although I still think Blender's sliders are better if you want to make the most of your space: https://youtu.be/MzFIXwIyEMM?t=474 ). Fixed.. Fixed.. Done.. Done.. Done.. ",
    "grand-piano": "Yes of course, the fix needs a little more vertical space, but no additional space is required in the horizontal direction. I put both versions next to each other for comparison. For this I have chosen a module with a lot of sliders (\"shadow and highlights\"). It's about 15% more in height due to the fix. \n\n. I think you have monitors or laptops with lower resolution (1366x768 or 1920 x 1080) in mind. I hadn't thought of that. I wouldn't like a colored indicator. I would prefer an option in darktablerc so that it can be turned on/off according to personal taste. Default off. \nAnother solution would be to make it dependent on the monitor height resolution. Then the fix would only become visible from a height resolution of 1440p (or 1600p) upwards, where there is enough space in height.. Ok. I close the pull request. Sorry, I misunderstood, I am still inexperienced in the open source world, so I assumed the pull request would be rejected. . Then I repeat my first proposal:\n\"I would prefer an option in darktablerc so that it can be turned on/off according to personal taste/preference. Default off.\". The fix has no impact on the vertical scrolling of the modules. I don't have to hit the scrollbar exactly with the mouse, because the whole area from the scrollbar to the right edge of the window works with the mouse wheel (see red marked area in the picture). I am using the windows version, maybe it is different under linux.\n\n. Thank you for clarifying, now I understand the issue. I only have one monitor, but if I can emulate the behavior you described, I will try to improve the scrolling. \n. Since there are several concerns about the fact that the fix needs more space in the height, I have simplified the fix, so that the height remains the same.\nChanges:\n- The slider indicator overwrites characters with descenders.\n- The bottom black outline of the indicator is drawn\nPersonally, I don't like this simplified fix, but I will go along with the majority opinion.\n(I haven't uploaded (pushed) the new fix yet) \ndarktable 2.4.4.............................................................................. simplified fix..............................................................\n\n@LebedevRI  Have you thought of a fix like this in your post?. @LebedevRI  Sorry, it was a little late that night when I took the picture, I must have been a little tired ;-). I've re-done the comparison picture.. I like Fabiens proposal. It could be activated by an option and would even reduce the required height, which would also require less scrolling. As an option, the user has the choice. . Sorry guys, that I close this pull request, because I want to implement Fabiens proposal (of course only as choosable option).  I think this pull request has little chance of being accepted, so we shouldn't waste any more time with this pull request. \nThanks for your comments, they help me to make a better redesign of the slider.. I think only adaptations that match the darktable gui design have a chance to be accepted. The blender slider are good, but do not match the darktable gui design. I think your proposal to make the slider design dependent on the module panel width is good, but will probably be rejected by the core developers. Switching the slider design via an option will have a better chance of being accepted.\nI hope my other current pull requests get more acceptance ;-). @Skrapion I promised you I'd take care of your problem with the too thin scrollbar. I found a simple solution. No compilation and no pull request is needed. \nOpen the file darktable.css with a text editor. The file is located in the darktable installation directory under the subdirectory share/darktable. \nIn line 384 you will find the following code: \n\nadd the statemant \"min-width: XXpx;\" with XX as pixel width you want:\n\nResult: a wide scrollbar\n\nWorks for me under windows.\n. I didn't know the white dot as a marking for local copy. But here is my proposal. Clearly to distinguish from the color labels, at a place where it does not disturb and set off from the other symbols. Is already coded and looks like this:\n\n. I can resize the text and create an option to enable this extended display, then each user can decide for himself if he wants to use it.. The thumb overlay must now be enabled with an option so that the standard display is retained. The thumb overlay and the font size has been reduced.\nNew GUI option\n\nReduced thumb overlay\n\n\n. Something's gone wrong. Will delete the pull request and create a new one.. I didn't see that. I will fix it. Thanks, you're right.\nI've been trying to figure out img->crop_width and img->crop_height, but both are always 0. My new commit works for me.\n. ",
    "fabienengels": "I think more vertical space is more easy on the eyes IMHO :). A simple suggestion, why not simply put the text left to the slider ? (as other software do as Capture One, Lightroom, etc). I think the overlapping slider make the interface bloated and a bit difficult to read, for example the last slider can be a bit difficult to locate on the first sight.\nEdit : And you'll even save more height space as bonus :). ",
    "saknopper": "True! At some point you have to scroll anyway, doesn't matter much to me whether that's sooner or later.... Personally I feel all the items under option 2 are actually bug fixes, but that's just me.... ",
    "CChiappa": "Oops, simply because the most obvious result from my googling, https://www.darktable.org/2012/10/whats-involved-with-adding-support-for-new-cameras/, references it.  extract_wb gets a couple of more decimal places of precision, I have updated the pull request (I think?  I am a git neophyte). ",
    "PaoloAst": "Thank you @aurelienpierre, it works fine! In your opinion, could be possible to add the possibility to change the zoom level using the mouse wheel too,, like when the zoom is under 200%?. > But that's not my parameters. That's the parameters of the auto-tuner :)\nI had the same behavior, it's a GUI uncertainty matter. I clicked on the dropper twice. The first time it worked, the second time the click drove the the black exposition slider.  . Yes, I did a mess. Pls, close this PR.\nMaybe, you could apply the change to the preferences.c by yourself. I guess it could be the easiest way. Sorry for the mess I did.. I'd like to test this branch, but I don't know how to do it via git commands.\n$> git fetch\n$> git checkout \nand \n./build.sh\nAm I missing something?\n. Thanks, probably I forgot to call \"git config\". Now it works and it seems very faster than before. I'll make some test. I've tested this branch and, for me, it seems working fine. I didn't find any issue.. On my system (Ubuntu 18.10) if I start with dt smaller than my screen, the preferences window is displayed in the middle of the screen, not in the middle of the darktable windows, where I suppose it should be.\nHowever my change is just to solve a cosmetic issue, so it is not so important.. I've found some issue sorting images by: description, title, full path or color label. In these cases no images are displayed. @TurboGit did you test what I wrote? In the expose mode (very nice, indeed), if you sort by description, title, full path or color label, I'm not able to select any image. Ok. I'll do it\nSent from my mobile\nIl giorno dom 3 feb 2019, 12:54 Pascal Obry notifications@github.com ha\nscritto:\n\nYes, and I can reproduce. Really strange behavior :) Will fix. Would have\nbeen good to open an issue.\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/pull/2039#issuecomment-460045021,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Apf4JBmjoFr1u7iDlEKjk4tBXJu4BhZaks5vJs3_gaJpZM4aU4wC\n.\n. It works, thanks, but now shuffle sorting, starts running endless. Merci Aurelien !\n\nSent from my mobile\nIl mer 20 feb 2019, 20:15 Aur\u00e9lien PIERRE notifications@github.com ha\nscritto:\n\nI'm working on that in #2037\nhttps://github.com/darktable-org/darktable/pull/2037\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub\nhttps://github.com/darktable-org/darktable/issues/2117#issuecomment-465715731,\nor mute the thread\nhttps://github.com/notifications/unsubscribe-auth/Apf4JCTZsUTMfwqcDAMObr6PG_Q5_5JBks5vPZ7bgaJpZM4bFIWG\n.\n. Awesome! \n\nJust one thing. When I move the eyedropper around the picture, I don't see the vertical line updated on the iop.. Great job! I don't see any effect of \"middle grey\" slider.... Thanks @edgardoh !. This is the outuput of --version:\nthis is darktable 2.7.0+625~gaf997cb8e-dirty\ncopyright (c) 2009-2019 johannes hanika\ndarktable-dev@lists.darktable.org\ncompile options:\n  bit depth is 64 bit\n  normal build\n  SSE2 optimized codepath enabled\n  OpenMP support enabled\n  OpenCL support enabled\n  Lua support enabled, API version 5.0.1\n  Colord support enabled\n  gPhoto2 support enabled\n  GraphicsMagick support enabled\n  OpenEXR support enabled\n\nThose are the last two lines of -d all:\n29,348651 [sql] /home/paolo/darktable/src/common/image_cache.c:227, function dt_image_cache_write_release(): prepare \"UPDATE main.images SET width = ?1, height = ?2, maker = ?3, model = ?4, lens = ?5, exposure = ?6, aperture = ?7, iso = ?8, focal_length = ?9, focus_distance = ?10, film_id = ?11, datetime_taken = ?12, flags = ?13, crop = ?14, orientation = ?15, raw_parameters = ?16, group_id = ?17, longitude = ?18, latitude = ?19, altitude = ?20, color_matrix = ?21, colorspace = ?22, raw_black = ?23, raw_maximum = ?24 WHERE id = ?25\"\n29,348950 [run_job-] 03 261517252,869981 29,348958 load image 68687 mip 9 | queue: 1 | priority: 429,348962 \n. No way. I've tried to rebuild from scratch without success. It hangs after the display of a black window in the middle of the screen. We can close this issue, I deleted all the darktable related directories and rebuilt again. Now it works. Actually not, sorry. I'm not  experienced in DT and I didn't want to make something wrong. You're definitely right. I will. I promise. ",
    "jpg54": "As a user, I can't discuss programming considerations but I find that Aur\u00e9lien's algorithms present another way to process his RAW. Moreover, it does not prevent the use of old algorithms and leaves the user the choice a bit like in local contrast.\nI fully agree with RawFiner.. I have been using the new RawFiner feature in the Rawdenoise module for some time. I like that he introduced in darktable the experiments he did on noise processing with dtStyles and shared. I would like to see them in the next version 2.6.. I have been using the new RawFiner modifications in Denoise profile wavelets since the publication of the sources. I appreciate that he was able to include in darktable's sources the research and experiments (and the results he drew from them) that he did with the dtQStyles he shared. \nI would like to see them in the next version 2.6.. Thank you Aur\u00e9lien for the script that allows you to have your new interface. I'm testing.. ",
    "alenaksu": "Sure, you can grab it from the issue on redmine.\nI followed the guidelines from this article. Hope I did it well :). Hi @hanatos,\nany news about this pr? Did you had time to take a look at the pdfs?. ",
    "MenfinGIT": "Using Darktable since several years, I think this UI refactor is a great idea. Not only for new users but for the old ones too.\nAfter testing it, I think it's a great ergonomic improvement for Darktable.. ",
    "acogent": "Me, I am a new user and I do not master well the \"pixel pipe\".\nSo, if I am offered a logical order, I will assimilate much faster !\nThank you Aurelien. Trop bien ! \nPas si compliqu\u00e9 pour les n\u00e9ophites.\nSorry for my english ;-). ",
    "blonchkman": "Congratulations on this reorganization proposal to which I subscribe without reservation.\nAs an amateur and still rather beginner, I renew without ceases this little tango of reorganization of the history. Thus, it seems to me that this proposal to reorganize the modules according to the order imposed by the mathematical logic of their treatment in the stack will help me in my future editing work. Moreover, it forms a logical sequence perfectly understandable for the layman.\nI was amazed for a long time to see the order of treatment of modules move when manipulated. To avoid the side effects of these reclassifications, one could have imagined:\n\nan automatic solution by separating the view of the history (variable by nature), from the order in which the modules are executed (always fixed).\nor manual: by allowing a form of displacement of the order of the modules in the history after its compression.\n\nAur\u00e9lien's proposal seems to me to be a perfectly credible compromise with the great advantage of being probably the easiest to implement ;-). ",
    "strixaluco": "Thank you for taking efforts to implement Piwigo export, @Codekloeppler. Were there any objectives to get this merged?. Oh, I searched only in the darktable-org repo. That's amazing! Can we assume it will be merged into the master?. > Yes, but not 2.6 as we are in feature freeze.\nRight. Will be checking the dev version then. Thank you!. Hi. No worries!\nThank you so much for your contribution.. ",
    "Codekloeppler": "Am 2018-11-20 10:07, schrieb strixaluco: \n\n\nYes, but not 2.6 as we are in feature freeze.\n\nRight. Will be checking the dev version then. Thank you!\n\nHello, \nsorry for my late reply, I just saw these mails a minute ago. \nYesterday, I solved a problem on my implementation, that was bugging me\nfor a while.\nSo, now it's somewhat frustrating to hear, that this work was all done.\n;-) \nBut I'm really glad, that the piwigo plugin will be merged to master\nsoon. \nThank you all! \n . ",
    "maf": "@cryptomilk thank you for this PR.\nI opt for having the configuration in the CSS and choosing theme from UI. However making own theme or ability to modify exiting one using UI (like using GTK+ color picker) is in my opinion must have.\n@TurboGit Why? Dakrtable falls into color critical category and sits in the color management workfow. This starts with environment preparation (walls, desktop, lightning and so on) and later with calibration and profiling of the devices. Thus one can have custom workplace with specific lightning and may need to adjust background accordingly.  I myself modified theme because I print. Scan the linked thread for details. . ",
    "nach": "oups... just saw that I forgot a line in my commit...\n(I tried the online github edit instead of doing properly from my local fork... bad idea.). ",
    "s5k6": "I've cloned your repo, checked out\n$ git co bug_12387\n\ncompiled\n$ prefix=\"${HOME}/tmp/dt\"\n$ disable=(flickr libsecret kwallet unity tethering)\n$ git submodule init\n$ git submodule update --recursive\n$ ./build.sh -j \"$(nproc)\" --prefix \"$prefix\" \"${disable[@]/#/--disable-}\" --buildtype Release\n$ rm -rf \"$prefix\"\n$ cmake --build build --target install -- -j6\n\nrun\n$ \"${prefix}/bin/darktable\" --library \"${prefix}/dummy-library\" ~/tmp/DSC_3932.NEF 1>stdout.log 2>stderr.log\n\nResult:\n$ cat stderr.log \n$ cat stdout.log\n[dt_masks_init_form_gui]\n[dt_masks_events_mouse_leave]\n[dt_masks_events_mouse_leave]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gui->dx=0.000000, gui->dy=0.000000\n[dt_circle_events_button_pressed] form_selected start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gpt->points[0]=181.194595, gpt->points[1]=730.625732, gui->dx=182.194595, gui->dy=731.625732\n[dt_masks_events_mouse_leave]\n\n.     $ git up\n    ...\n    $ git pull\n    Updating fa7517bb8..2d42b46e9\n    Fast-forward\n     src/develop/masks/masks.c | 6 ++++++\n     1 file changed, 6 insertions(+)\ncompiling, retry\n$ \"${prefix}/bin/darktable\" --library \"${prefix}/dummy-library\" ~/tmp/DSC_3932.NEF 1>|stdout.log 2>|stderr.log\n\nthe bug is still there\n$ cat stderr.log \n$ cat stdout.log \n[dt_masks_init_form_gui]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[dt_masks_events_mouse_leave]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[dt_masks_events_mouse_leave]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gui->dx=0.000000, gui->dy=0.000000\n[dt_circle_events_button_pressed] form_selected start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gpt->points[0]=168.007751, gpt->points[1]=271.939087, gui->dx=169.007751, gui->dy=272.939087\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n\n. \n    $ git up\n    Fetching origin\n    remote: Enumerating objects: 8, done.\n    remote: Counting objects: 100% (8/8), done.\n    remote: Total 8 (delta 7), reused 8 (delta 7), pack-reused 0\n    Unpacking objects: 100% (8/8), done.\n    From github.com:edgardoh/darktable\n       2d42b46e9..53c1eb1ea  bug_12387  -> origin/bug_12387\n    $ git pull\n    Updating 2d42b46e9..53c1eb1ea\n    Fast-forward\n     src/develop/masks/masks.c | 2 ++\n     src/gui/gtk.c             | 3 +++\n     2 files changed, 5 insertions(+)\nThe preview is shown, and it is always under the shape, i.e., not the mouse.  I've made a screencast here:\nhttps://depot.s5k6.net/B53pnjQAHxnTgvTw/53c1eb1ea.mp4\n\nThe shape jumps away at 21\" into the video, that was when I started dragging the mouse, not when clicking on the shape. (mous down: shape still there.  move mouse: jumps).  Also, thwe preview is updated only when I release the buttom (mouse up).\nAt 28\", you'll see that while dragging the shape to the left, the shape stops a bit from the left border of the image, although I do not release the mouse button.  When moving right again, the shape starts to move again.\n$ cat stderr.log \n$ cat stdout.log \n[dt_masks_init_form_gui]\n[center_enter]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[center_leave]\n[center_enter]\n[button_pressed]\n[center_leave]\n[dt_masks_events_mouse_leave]\n[center_enter]\n[button_pressed]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gui->dx=0.000000, gui->dy=0.000000\n[dt_circle_events_button_pressed] form_selected start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gpt->points[0]=140.197723, gpt->points[1]=131.449463, gui->dx=141.197723, gui->dy=132.449463\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[center_leave]\n[dt_masks_events_mouse_leave]\n[center_enter]\n[button_pressed]\n[dt_circle_events_button_pressed] form_selected before start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gui->dx=141.197723, gui->dy=132.449463\n[dt_circle_events_button_pressed] form_selected start the form dragging gui->posx=-1.000000, gui->posy=-1.000000, gpt->points[0]=285.557678, gpt->points[1]=331.865051, gui->dx=286.557678, gui->dy=332.865051\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[center_leave]\n[center_enter]\n[center_leave]\n[center_enter]\n[center_leave]\n[center_leave]\n[dt_masks_events_mouse_leave]\n[center_enter]\n[dt_masks_events_mouse_moved] before set pos gui->posx=-1.000000, gui->posy=-1.000000\n[center_leave]\n[dt_masks_events_mouse_leave]\n\nI'll try the shortcuts in a minute.. Sorry, I maybe fail to do the \u201cshortcuts\u201d thing.  I do not know how to define shortcuts (I'm thinking of keyboard shortcuts?) in the spot removal module.  I also could not find it in the manual.\nIn case you mean the presets available in every module: Same effect.  If I store a spot removal as preset, then remove it from the history stack, compress that, go to lighttable, and back to darktable (same image), I can apply the preset.  Preview looks good.  I cannot modify that shape, unless I create an additional spot-removal-shape (another bug?).  Then I can move the original shape, but see the jumping effect again. \u2014 but you ment keyboard shortcuts, right?. Oh, too bad.  But thank you very much for the effort and time you've invested.  I'll point this out to the FVWM guys, maybe they have an idea.... I've run the following testes, and I did not observe jumping shapes:\n```\nSpot removal {\n  circle {create, moved {source, target}},\n  ellipse {created, moved {source, target}, rotated, resized, changed width},\n  path {created, moved, resized, nodes {moved, rotated, changed transition}},\n  circle deleted,\n  ellipse deleted,\n  path deleted\n}\nexposure > blend > drawn mask {\n  brush {created, moved, nodes {moved, rotated},\n  circle {created, moved, resized},\n  ellipse {created, moved, resized, changed transition, changed width, rotated},\n  gradient {created, created, moved, rotated},\n  gradient deleted,\n  circle deleted,\n  path deleted,\n  ellipse deleted\n}\n```. Pascal Obry (2019-Jan-13, excerpt):\n\nThanks Stefan for testing. Let's merge then for wider testing.\n\nGood!  I've just compiled and tested\n$ git describe\nrelease-2.7.0-222-g8467e4210\n\nand performed the same tests\nSpot removal {\n  circle {create, moved {source, target}},\n  ellipse {created, moved {source, target}, rotated, resized, changed width},\n  path {created, moved, resized, nodes {moved, rotated, changed transition}},\n  circle deleted,\n  ellipse deleted,\n  path deleted\n}\n\nexposure > blend > drawn mask {\n  brush {created, moved, nodes {moved, rotated},\n  circle {created, moved, resized},\n  ellipse {created, moved, resized, changed transition, changed width, rotated},\n  gradient {created, moved, rotated, changed transition},\n  gradient deleted,\n  circle deleted,\n  path deleted,\n  ellipse deleted\n}\n\nand the bug seems to be gone for good!\nThank you very much!\nStefan\n-- \nhttp://stefan-klinger.de                                        o/X\nI prefer receiving plain text messages, not exceeding 32kB.     /\\/\n                                                                  \\\n. ",
    "DottieUnderwood": "I created a hacked version of darktable that will convert v8 old to v8 new. Only needs minor edits to blend.c and blend.h. First you temporary \"convert\" the xmp files from v8 to v1. \nfor i in *.xmp; do sed s/blendop_version=\\\"8\\\"/blendop_version=\\\"1\\\"/g $i>$i; done\nThen run the modified darktable to convert \"v1\" to v8 new. Choose to reload the xmp files when asked.\nNOTE: Use this only to fix the \"dead end\" xmp files. Do not use on any other files. It cannot fix v8 old files that have already been loaded in an unmodified current version of darktable.\nThe new blend features are great btw! Good work @rabauke. Parametric masks are the really the killer feature of darktable and they are not even mentioned on the feature page WTF?\nAdd this to blend.h\n/* he he */\ntypedef struct dt_develop_blend_params8a_t\n{\n  uint32_t mask_mode;\n  uint32_t blend_mode;\n  float opacity;\n  uint32_t mask_combine;\n  uint32_t mask_id;\n  uint32_t blendif;\n  float radius;\n  float contrast;\n  float brightness;\n  uint32_t mask_blur_mode;\n  uint32_t reserved[4];\nfloat blendif_parameters[4 * DEVELOP_BLENDIF_SIZE];\n} dt_develop_blend_params8a_t;\nblend.c (This replaces the old v1 converter)\n```\n  if(old_version == 1 && new_version == 8)\n  {\n    / he he /\n    if(length != sizeof(dt_develop_blend_params8a_t)) return 1;\ndt_develop_blend_params8a_t *o = (dt_develop_blend_params8a_t *)old_params;\ndt_develop_blend_params_t *n = (dt_develop_blend_params_t *)new_params;\ndt_develop_blend_params_t *d = (dt_develop_blend_params_t *)module->default_blendop_params;\n\n*n = *d; // start with a fresh copy of default parameters\nn->mask_mode = o->mask_mode;\nn->blend_mode = o->blend_mode;\nn->opacity = o->opacity;\nn->mask_combine = o->mask_combine;\nn->mask_id = o->mask_id;\nn->blur_radius = o->radius;\nn->blendif = o->blendif;\nn->brightness = o->brightness;\nn->contrast = o->contrast;\nmemcpy(n->blendif_parameters, o->blendif_parameters, 4 * DEVELOP_BLENDIF_SIZE * sizeof(float));\nreturn 0;\n\n}\n```. ",
    "junkyardsparkle": "So... I just realized that it's now impossible to export the weird Lab pfm format needed by darktable-chart... any ideas for a workaround?. I wonder if making the node dots dark (darker than the background grid) and shown as behind the plotted curve would make them more obviously not for \"grabbing\"?. Good point. Could it be implemented by simply giving the dots a slightly lesser opacity than the curve?. I just tried this on a rc1 build, and found the experience mostly more intuitive and \"discoverable\" than on rc0... nice work! The only thing that I noticed that I would call an unexpected behavior is the following scenario:\nI load an image, click \"auto tune levels\", and get something pretty nice, with white and black relative exposures at something like 3.5 and -3.5 respectively, middle gray at ~8.5. I then move the middle gray slider up and down... moving it to the top of its range and back works fine - I can get back to what I started with.\nHowever, when lowering the value of the gray slider from its starting point, things are good until I then raise it again - when I do, the black relative slider continues to lower its value instead of raising it, and I can't return to starting values.  The tooltip for the gray slider obscured the ones below, making it a little harder to observe what was happening there... ;). I totally understand about the \"reasonable values\"... the problem, from the perspective of a naive user not paying attention to the numbers, is that they tend to discover the \"reasonable\" range by moving sliders a little bit beyond it. ;)\nTrying to remember/reapply the ratio does seem like it would get messy, though. Is it possible there's a more elegant way to make this case \"resilient\"? That is, to conditionally not have the condition 1 supersede the condition 2 at this point? If going into that range doesn't really produce useful results, then its purpose is more as a \"bumper zone\" anyway, right?\nSorry if I'm not making sense; I haven't looked at the code for this at all, still just trying to break it from the perspective of an excited new user... I appreciate that a bullet-proof UI for this kind of thing is really difficult.. I wouldn't want to see any potentially useful settings become unavailable either, but possibly that could be mitigated by manual adjustment of the other two sliders when desired? For what it's worth, I did RTFM, and I still found it a little uncomfortable to be unable to \"back out\" of a slider which I pushed a little too far; I'm sure there exist other examples of this UI behavior, but I think it's not what people normally expect. I'm just playing \"devil's advocate\" for what I imagine is a typical user... hopefully there will be a broader range of feedback before the release. :). You may be able to hack something workable with LUA, using one of the available forms of metadata (a color label, star rating, tag, etc) to indicate a certain maximum output size, and then conditionally check for it on export. I do something vaguely similar by using the copyright field in my camera to store a numeric value that gets mapped to a lens name on import (for old, \"dumb\" lenses).\nSince this lens field doesn't (actually, I haven't checked in 2.6 yet, but I think it's the same) get applied on export when set this way, the script also has to do the same check and mapping on export, and use exiftool to add the lens name to the output file. Yes, it's ugly... but the part that's relevant to your use case isn't, so much, :). I agree, it seems odd that there's such a sophistcated filtering system in place to keep lists uncluttered, but there's nothing you can do about the shipped presets. The graduated density module is one where I find this to be a bit of an annoyance (13 hard-coded presets). It would be less annoying if it was possible to get one's own presets to sort above these, but I don't think that's possible.. Many music players provide a user-configurable single-line information display somewhere in the GUI (or window titlebar). It would be really nice if some of the unused space described by @TurboGit could be dedicated to this, so that whatever little bits of info (datetime, ISO, whatever) which are important to a given user could be seen at a glance.\nFWIW, it seems to me that if anything should be displayed on the histogram, it should be the current exposure adjustments, given that it's used as an alternative exposure module. Also, I would personally like a smaller histogram, but agree that it should probably be an option, since many people are likely to disagree.. It does seem like the idea behind the current parallelism kind of falls apart in the real world, but it probably varies widely depending on hardware, so it might be worth trying to get some input from people as to whether anyone actually uses the thumbnail as a \"more responsive\" feedback while editing. For me, personally, using GPU for main image and CPU for thumbnail doesn't make it very useful in that regard, and I don't use it that way... but somebody, somewhere might.. My two cents: This interface is different enough from the old one that it might be upsetting to some users... making it a new module instead would free you from constraints and allow for improving it in whatever other ways might occur to you. :)\nThat said, the only problem I'm having with it so far is that left-clicking to add a spline immediatly adds it at the y=0 position, regardless of where I clicked. This could be an issue with my somewhat old GTK3 version (3.18.9) if nobody else is seeing it. . > Cntrl+click add a node to the existing y, not to y=0.\nSo it's the intended behavior? It seems \"unexpected\" compared to any other curve tool I've ever used.\n. > Have you ever user the tone curve?\nThe one in darktable, yes, and many other ones over the last 20 years. None of them exhibit this behavior.\n. Ok, I have more time now, maybe I can explain better what's happening. In darktable's tone curve module, if you left-click ~on the existing curve, then move the mouse even slightly, a node is created at the position of the mouse pointer. This is the expected behavior. In this module, if I do the same thing, I get this:\n\nThe node is created at the top of the grid, instead of at the mouse pointer in the center. Maybe y=0 wasn't the best way to describe this, but hopefully the screenshot makes it clear.. Ok, if nobody else reports it, then it's my problem, :) It's odd that it doesn't happen with any of the other modules with similar interfaces, though, and doesn't happen with ctrl+click in this one. I'll look into it further when I get a chance.. Interesting... after this, the issue I described in #2167 is reversed: now a newly added node appears at the bottom of the graph instead of the top.. I understand you, and I'm trying very hard to be understandable myself. The behavior I'm describing is with the first case you mention. When I click and drag, the node is not added at the mouse position, as you describe (and as I would expect). Peviously, it was being added at the top of the graph, and after this commit, it is now being added at the bottom. The x position is always correct. The ctrl+click behavior is also correct. \nBy now it's clear to me that I'm seeing a different behavior than you and others. This could be due to some old cairo bug, I don't know. It has never been the case with the other modules which present a \"curves\" interface, though (including the old color zones). If more people test this and don't get \"bitten\", it may be too obscure to worry about... there probably aren't too many people still using Slackware 14.2 at this point. ;) I wasn't planning to mention it again, except that the behavior changed at this point, which may be a clue.. I'm looking around too, but I don't have a good grasp of gtk. Probably the best thing at this point is to get as many people as possible to test the module. If it's broken for anyone else, we can \"triangulate\".. The y-offset issues I was having previously appear to be fixed in this branch. :). ",
    "sharkcz": "The main problem on ppc64le seems to be primarily with using -std=c++11/14 in CXXFLAGS while compiling with Altivec support on ppc needs -std=gnu++11/14 to avoid the type collisions for bool, pixel, etc. See https://bugzilla.redhat.com/show_bug.cgi?id=1394505#c2. ````\ndiff --git a/src/CMakeLists.txt b/src/CMakeLists.txt\nindex ec6e4f7c3..ff9223d15 100644\n--- a/src/CMakeLists.txt\n+++ b/src/CMakeLists.txt\n@@ -178,6 +178,10 @@ if(NOT COMPILER_SUPPORTS_C11)\n   message(FATAL_ERROR \"The compiler ${CMAKE_C_COMPILER} has no C11 support. Please use a different C compiler.\")\n endif()\n+set(CMAKE_C_STANDARD 11)\n+set(CMAKE_C_STANDARD_REQUIRED ON)\n+set(CMAKE_C_EXTENSIONS ON)\n+\n # yes, need to keep both the CMAKE_CXX_FLAGS and CMAKE_CXX_STANDARD.\n # with just the CMAKE_CXX_STANDARD, try_compile() breaks:\n #   https://gitlab.kitware.com/cmake/cmake/issues/16456\n@@ -195,7 +199,7 @@ endif()\nset(CMAKE_CXX_STANDARD 14)\n set(CMAKE_CXX_STANDARD_REQUIRED ON)\n-set(CMAKE_CXX_EXTENSIONS OFF)\n+set(CMAKE_CXX_EXTENSIONS ON)\nset(CMAKE_C_FLAGS \"${CMAKE_C_FLAGS} -std=c99\")\n set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11\")\ndoes the trick, the CXX change is needed in rawspeed (cmake/compiler-flags.cmake). There are modern and powerful ppc machines, I'm typing this on my Power9-based workstation, same CPU as the Sierra/Summit supercomputers.. And you are right about the rawspeed flags, it builds OK.. it breaks here for me with -DUSE_OPENCL=OFF\n[ 17%] Building C object src/CMakeFiles/lib_darktable.dir/common/color_picker.c.o\ncd /mnt/dan/darktable/build/src && /usr/bin/cc -DGDK_DISABLE_DEPRECATED -DGDK_VERSION_MIN_REQUIRED=GDK_VERSION_3_14 -DGLIB_VERSION_MAX_ALLOWED=GLIB_VERSION_MIN_REQUIRED -DGLIB_VERSION_MIN_REQUIRED=GLIB_VERSION_2_40 -DGTK_DISABLE_DEPRECATED -DGTK_DISABLE_SINGLE_INCLUDES -DHAVE_CONFIG_H -DHAVE_GPHOTO2 -DHAVE_GPHOTO_25_OR_NEWER -DHAVE_KWALLET -DHAVE_LENSFUN -DHAVE_OPENEXR -DUSE_LUA -D_XOPEN_SOURCE=700 -D__GDK_KEYSYMS_COMPAT_H__ -Dlib_darktable_EXPORTS -I/mnt/dan/darktable/src -isystem /mnt/dan/darktable/src/external -isystem /usr/include/glib-2.0 -isystem /usr/lib64/glib-2.0/include -isystem /usr/include/gtk-3.0 -isystem /usr/include/pango-1.0 -isystem /usr/include/fribidi -isystem /usr/include/cairo -isystem /usr/include/pixman-1 -isystem /usr/include/freetype2 -isystem /usr/include/libpng16 -isystem /usr/include/uuid -isystem /usr/include/harfbuzz -isystem /usr/include/gdk-pixbuf-2.0 -isystem /usr/include/gio-unix-2.0 -isystem /usr/include/libdrm -isystem /usr/include/atk-1.0 -isystem /usr/include/at-spi2-atk/2.0 -isystem /usr/include/at-spi-2.0 -isystem /usr/include/dbus-1.0 -isystem /usr/lib64/dbus-1.0/include -isystem /usr/include/libxml2 -isystem /usr/include/OpenEXR -isystem /usr/include/lensfun -isystem /usr/include/librsvg-2.0 -isystem /usr/include/json-glib-1.0 -I/mnt/dan/darktable/build/src -I/mnt/dan/darktable/src/external/LuaAutoC -I/mnt/dan/darktable/build/src/external/rawspeed/src -isystem /mnt/dan/darktable/src/external/rawspeed/src/external -I/mnt/dan/darktable/src/external/rawspeed/src/librawspeed  -Wall -Wformat -Wformat-security -Wshadow -Wtype-limits -Wvla -Wold-style-declaration -Wno-error=varargs -Wno-format-truncation -Wframe-larger-than=32768 -Wstack-usage=32768 -Wlarger-than=524288 -fno-strict-aliasing -std=c99 -fopenmp -mtune=native  -g -O2 -g -DNDEBUG -O2 -fPIC   -Werror -fopenmp -o CMakeFiles/lib_darktable.dir/common/color_picker.c.o   -c /mnt/dan/darktable/src/common/color_picker.c\n/mnt/dan/darktable/src/common/color_picker.c:25:92: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_4ch_seq(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                                                                            ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:57:97: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_4ch_parallel(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                                                                                 ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:82:22: error: expected end of line before \u2018default\u2019\n #pragma omp parallel default(none)\n                      ^~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:92:17: error: expected end of line before \u2018schedule\u2019\n #pragma omp for schedule(static) collapse(2)\n                 ^~~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:130:88: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_4ch(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                                                                        ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:142:100: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_bayer_seq(const dt_iop_buffer_dsc_t const dsc, const float const pixel,\n                                                                                                    ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:176:105: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_bayer_parallel(const dt_iop_buffer_dsc_t const dsc, const float const pixel,\n                                                                                                         ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:202:22: error: expected end of line before \u2018default\u2019\n #pragma omp parallel default(none)\n                      ^~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:213:17: error: expected end of line before \u2018schedule\u2019\n #pragma omp for schedule(static) collapse(2)\n                 ^~~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:255:90: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_bayer(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                                                                          ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:268:101: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_xtrans_seq(const dt_iop_buffer_dsc_t const dsc, const float const pixel,\n                                                                                                     ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:303:106: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_xtrans_parallel(const dt_iop_buffer_dsc_t const dsc, const float const pixel,\n                                                                                                          ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:329:22: error: expected end of line before \u2018default\u2019\n #pragma omp parallel default(none)\n                      ^~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:340:17: error: expected end of line before \u2018schedule\u2019\n #pragma omp for schedule(static) collapse(2)\n                 ^~~~~~~~\n/mnt/dan/darktable/src/common/color_picker.c:383:91: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n static void color_picker_helper_xtrans(const dt_iop_buffer_dsc_t dsc, const float const pixel,\n                                                                                           ^~~~~\n/mnt/dan/darktable/src/common/color_picker.c:396:80: error: expected \u2018;\u2019, \u2018,\u2019 or \u2018)\u2019 before \u2018unsigned\u2019\n void dt_color_picker_helper(const dt_iop_buffer_dsc_t dsc, const float const pixel, const dt_iop_roi_t roi,\n                                                                                ^~~~~\nmake[2]: ** [src/CMakeFiles/lib_darktable.dir/build.make:181: src/CMakeFiles/lib_darktable.dir/common/color_picker.c.o] Chyba 1\n````. it's fixed now, https://pasteboard.co/HPxXEAE.png. the only change in my git is in src/is_supported_platform.h. for the record I don't have this problem in my build. I would keep the first patch only and do git push --force to override the original PR. It should be a cleaner solution.. I consider forced push acceptable for PRs, but let's wait for the upstream guys.. ",
    "RobbieAB": "I have a Raptor Talos system, which is indeed a modern powerful machine. (https://raptorcs.com/)\nThe problems I was encountering appear to be related to altivec.h being included from CL/cl_platform.h even when openCL is disabled. setting -U__VEC__ -U ALTIVEC appeared to get darktable to build without issues.\nWould you be happy with a conditional setting of those C(XX)FLAGS for PPC64LE?. Disabled with cmake -DUSE_OPENCL=OFF, yes. There appears to be an include path from a couple of files that unconditionally includes CL/cl_platform.h. \nI think, from reading the code and comments, it's using it for the SSE vectors which PPC64 obviously wouldn't support.\nRawspeed itself is fine, as far as I can tell. I think the problems are mostly in crufty non-darktable originated code that is (trying) to support ppc64. \nThe problem with CL/cl_platform.h is if VEC is set, then it includes altivec.h which #defines pixel. This has nasty consequences elsewhere. This problem wouldn't appear on my amd64 as my amd64 machines don't have an altivec.h header to include.. color_picker.c includes imageop_math.h includes CL/cl.h includes CL/cl_platform.h without any conditionality (apart from not _  Apple _ ). It's building for me now with -DUSE_OPENCL=OFF, but I am getting the following error at launch:\n./src/darktable: symbol lookup error: /opt/darktable/lib64/darktable/plugins/libborders.so: undefined symbol: dt_opencl_create_kernel\nI don't think we need the points.h change, though the code is still hopelessly wrong and out of date. . I did clear the build directory, and am happy to try hunt down this one on my own. It looks like it may be something specific to my system.. With the commit making the inclusion of CL/cl.h conditional, the only requirements to actually build on POWER9 with openCL disabled is the patch for is_supported_platform.h, so I have reverted the other changes.\n. I dislike force-pushing over public repos. One too many bad experiences with it in my past. But if that is what is preferred here, I am happy to do so.. And I think I may have identified my problem... I was running it from the build directory, and I think it may have been trying to load libraries from a previous build. :-1. ",
    "leclercj": "As frequent darktable+piwigo user, I'm volunteering to test this new plug-in. I had a try with it yesterday. It works great!\nI see you marked it for 2.8. Any chance to have it included in 2.6 ?\nOne suggestion for improvement : As I've a large number of albums, I'd appreciate to select the target album in a tree, per Piwigo album hierarchy, rather than in a flat (and long) list.. Yes, a left-alignement in the list with indents reflecting Piwigo album hierarchy could be a good alternative.\nOne very great value of this module is the option to also export the tags to Piwigo.. Yes, that's much better indeed\nOne observation: When the target storage of expot module is changed to anything else and back to piwigo, the latest used album is proposed again (and that's good), but text and combo boxes specific to new album creation are also shown (and should not).\n\n. ",
    "ff2000": "Wanted to give it a try, for me it crashes in L.406:\n```\nThread 19 \"worker 1\" received signal SIGILL, Illegal instruction.\n[Switching to Thread 0x7fff6bd51700 (LWP 22899)]\n0x00007fffa0e37556 in process_image (luminance=, method=, factors=, \n    height=, width=, out=, in=)\n    at /home/karl/src/darktable/src/iop/toneequal.c:406\n406         for(int i = 0; i < 16; ++i) pixel_out[i] = correction[i / ch] * pixel_in[i];\n(gdb) bt full\n0  0x00007fffa0e37556 in process_image (luminance=, method=, factors=, height=, width=, out=, in=)\nat /home/karl/src/darktable/src/iop/toneequal.c:406\n    i = <optimized out>\n    i = <optimized out>\n    i = <optimized out>\n    i = <optimized out>\n    pixel_in = <optimized out>\n    correction = <optimized out>\n    pixel_in = 0x7fff686783c0\n    correction = {0.314601362, 0.314340442, 0.314838082, 0.314575702}\n    pixel_lum = <optimized out>\n    luma = <optimized out>\n    exposure = <optimized out>\n    pixel_lum = 0x7fff683bdd20\n    luma = {0.478164583, 0.479542047, 0.47692275, 0.478299618}\n    exposure = {-1.06442082, -1.06027079, -1.06817245, -1.06401348}\n    pixel_out = <optimized out>\n    pixel_out = 0x7fff684503c0\n    k = <optimized out>\n    k = 105696\n    ch = <optimized out>\n\n1  process_scale (method=, factors=, kernel=, height=, width=, out=, in=) at /home/karl/src/darktable/src/iop/toneequal.c:502\n    in_toned = <optimized out>\n    luma_in = <optimized out>\n    luma_toned = <optimized out>\n    ch = <optimized out>\n    ch = <optimized out>\n    in_toned = <optimized out>\n    luma_in = <optimized out>\n    luma_toned = <optimized out>\n\n2  process (self=, piece=, ivoid=, ovoid=, roi_in=, roi_out=) at /home/karl/src/darktable/src/iop/toneequal.c:739\n    sigma = <optimized out>\n    scale = <optimized out>\n    gauss_1D = {0, 0, 0, 0, 0, 0, 0}\n    gauss_kernel = {{0, 0, 0, 0, 0, 0, 0}, {0, 1.9748219e-40, 0, 0, 1.40129846e-45, 5.12985358e+26, 4.59163468e-41}, {3.72150149e+24, 4.59163468e-41, 3.51818148e+24, 4.59163468e-41, 4.37318806e+24, 4.59163468e-41, \n        1.48111642e-40}, {0, 5.1298831e+26, 4.59163468e-41, 5.12985949e+26, 4.59163468e-41, -1.06401348, 0}, {0.478164583, 0.479542047, 0.47692275, 0.478299618, -1.06442082, -1.06027079, -1.06817245}, {-1.06401348, \n        0.314601362, 0.314340442, 0.314838082, 0.314575702, 0.468128145, 6.01167674e-25}, {6.78136728e-19, 1.03526312e-13, 2.12414908e-09, 6.23464575e-06, 0.00226316601, 0.0872310847, 7.21254181e-32}}\n    width_padded = <optimized out>\n    height_padded = <optimized out>\n    ch = <optimized out>\n    in_padded = <optimized out>\n    out_padded = <optimized out>\n    d = <optimized out>\n    in = <optimized out>\n    out = <optimized out>\n\n3  0x00007ffff6dab89e in gomp_thread_start (xdata=) at /var/tmp/portage/sys-devel/gcc-8.2.0-r6/work/gcc-8.2.0/libgomp/team.c:120\n    team = 0x7fffc80127f0\n    task = 0x7fffc8012fa0\n    data = <optimized out>\n    thr = <optimized out>\n    pool = 0x7fffc8012720\n    local_fn = 0x7fffa0e37200 <process_image._omp_fn.0>\n    local_data = 0x7fffdd2639a0\n\n4  0x00007ffff772296a in start_thread (arg=0x7fff6bd51700) at pthread_create.c:463\n    pd = 0x7fff6bd51700\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140735002515200, -920184838796788664, 140736903705022, 140736903705023, 8396800, 140737337107936, 919877179956870216, 920201243785509960}, mask_was_saved = 0}}, priv = {pad = {\n          0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n5  0x00007ffff74571bf in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nNo locals.\n```\nCan't tell you my parameters currently.. Now I get this:\n```\nThread 6 \"worker 1\" received signal SIGILL, Illegal instruction.\n[Switching to Thread 0x7fffdd284700 (LWP 4166)]\n0x00007fffa2fb3b64 in commit_params (self=0x7fffc802da10, p1=0x7fffc802df50, pipe=0x7fffdd272490, piece=0x7fffc804f9f0)\n    at /home/karl/src/darktable/src/iop/toneequal.c:709\n709       float factors[PIXEL_CHAN]  attribute((aligned(64))) = {\n(gdb) bt full\n0  0x00007fffa2fb3b64 in commit_params (self=0x7fffc802da10, p1=0x7fffc802df50, pipe=0x7fffdd272490, piece=0x7fffc804f9f0)\nat /home/karl/src/darktable/src/iop/toneequal.c:709\n    p = 0x7fffc802df50\n    d = 0x7fffc8046ee0\n    factors = {-nan(0x7f1fa8), -nan(0x7fffff), 0, 0, 4.20389539e-45, 6.72623263e-44, 0, 0, 0, 0, 1.2751816e-43, 1.54142831e-43, 0, 0, \n      1.7376101e-43, 1.66754517e-43}\n\n1  0x00007ffff7a2f233 in dt_iop_init_pipe (module=0x7fffc802da10, pipe=0x7fffdd272490, piece=0x7fffc804f9f0) at ../src/develop/imageop.c:511\nNo locals.\n2  0x00007ffff7a7181e in dt_dev_pixelpipe_create_nodes (pipe=pipe@entry=0x7fffdd272490, dev=dev@entry=0x7fffdd272b30)\nat ../src/develop/pixelpipe_hb.c:274\n    module = 0x7fffc802da10\n    piece = 0x7fffc804f9f0\n    __func__ = \"dt_dev_pixelpipe_create_nodes\"\n    modules = 0x55555642f680\n\n3  0x00007ffff79d8043 in dt_imageio_export_with_flags (imgid=imgid@entry=4928, filename=filename@entry=0x7ffff7b5d986 \"unused\",\nformat=format@entry=0x7fffdd274530, format_params=format_params@entry=0x7fffdd274430, ignore_exif=ignore_exif@entry=1, \ndisplay_byteorder=display_byteorder@entry=0, high_quality=0, upscale=0, thumbnail_export=1, filter=0x0, copy_metadata=0, \nicc_type=DT_COLORSPACE_NONE, icc_filename=0x0, icc_intent=DT_INTENT_LAST, storage=0x0, storage_params=0x0, num=1, total=1)\nat ../src/common/imageio.c:720\n    dev = {gui_attached = 0, gui_leaving = 0, gui_synch = 0, focus_hash = 0, image_loading = 1, first_load = 0, image_force_reload = 0, \n      preview_loading = 1, preview_input_changed = 0, image_status = DT_DEV_PIXELPIPE_DIRTY, preview_status = DT_DEV_PIXELPIPE_DIRTY, \n      timestamp = 0, average_delay = 250, preview_average_delay = 50, gui_module = 0x0, preview_downsampling = 1, width = -1, height = -1, \n      pipe = 0x0, preview_pipe = 0x0, pipe_mutex = {mutex = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, \n            __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\\000' <repeats 39 times>, __align = 0}}, \n      preview_pipe_mutex = {mutex = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, __spins = 0, __elision = 0, \n            __list = {__prev = 0x0, __next = 0x0}}, __size = '\\000' <repeats 39 times>, __align = 0}}, image_storage = {exif_inited = 1, \n        orientation = ORIENTATION_NONE, exif_exposure = 0.25, exif_aperture = 7.0999999, exif_iso = 160, exif_focal_length = 14, \n        exif_focus_distance = 0, exif_crop = 2, exif_maker = \"Panasonic\", '\\000' <repeats 54 times>, \n        exif_model = \"DMC-G80\", '\\000' <repeats 56 times>, exif_lens = \"LUMIX G VARIO 12-60/F3.5-5.6\", '\\000' <repeats 99 times>, \n        exif_datetime_taken = \"2018:12:10 16:18:12\", camera_maker = \"Panasonic\", '\\000' <repeats 54 times>, \n        camera_model = \"DMC-G8\", '\\000' <repeats 57 times>, camera_alias = \"DMC-G80\", '\\000' <repeats 56 times>, \n        camera_makermodel = \"Panasonic DMC-G8\", '\\000' <repeats 111 times>, camera_legacy_makermodel = '\\000' <repeats 127 times>, \n        filename = \"P1140477.RW2\", '\\000' <repeats 243 times>, width = 4816, height = 3464, crop_x = 0, crop_y = 0, crop_width = 208, \n        crop_height = 0, num = 0, flags = 1601, film_id = 23, id = 4928, group_id = 3415, version = 1, loader = LOADER_RAWSPEED, buf_dsc = {\n          channels = 1, datatype = TYPE_UINT16, filters = 370546198, xtrans = {\"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \n            \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\"}, rawprepare = {raw_black_level = 0, \n            raw_white_point = 0}, temperature = {enabled = 0, coeffs = {0, 0, 0, 0}}, processed_maximum = {0, 0, 0, 0}}, d65_color_matrix = {\n          nan(0x400000), 4.57495923e-41, 0, 0, 0, 0, 1.67818607e-36, 4.57495923e-41, 1.67818751e-36}, profile = 0x0, profile_size = 0, \n        colorspace = DT_IMAGE_COLORSPACE_NONE, legacy_flip = {legacy = 0, user_flip = 0}, longitude = nan(0x8000000000000), \n        latitude = nan(0x8000000000000), elevation = nan(0x8000000000000), raw_black_level = 143, raw_black_level_separate = {143, 143, 143, 143},\n\n--Type  for more, q to quit, c to continue without paging--\n            raw_white_point = 4095, fuji_rotation_pos = 0, pixel_aspect_ratio = 1, wb_coeffs = {623, 256, 380, nan(0x400000)}, \n            cache_entry = 0x555557023180}, history_mutex = {mutex = {__data = {__lock = 0, __count = 0, __owner = 0, __nusers = 0, __kind = 0, \n                __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\\000' , __align = 0}}, \n          history_end = 41, history = 0x55555642f2e0, iop_instance = 71, iop = 0x55555642b300, alliop = 0x0, histogram = 0x0, \n          histogram_pre_tonecurve = 0x0, histogram_pre_levels = 0x0, histogram_max = 0, histogram_pre_tonecurve_max = 0, histogram_pre_levels_max = 0, \n          histogram_waveform = 0x0, histogram_waveform_width = 0, histogram_waveform_height = 0, histogram_waveform_stride = 0, \n          histogram_type = DT_DEV_HISTOGRAM_LOGARITHMIC, forms = 0x55555642cca0, form_visible = 0x0, form_gui = 0x0, allforms = 0x0, full_preview = 0, \n          full_preview_last_zoom = 0, full_preview_last_closeup = 0, full_preview_last_zoom_x = 0, full_preview_last_zoom_y = 0, \n          full_preview_last_module = 0x0, full_preview_masks_state = 0, proxy = {exposure = 0x0, modulegroups = {module = 0x0, set = 0x0, get = 0x0, \n              test = 0x0, switch_group = 0x0}, snapshot = {request = 0, filename = 0x0}, masks = {module = 0x0, list_change = 0x0, list_remove = 0x0, \n              list_update = 0x0, selection_change = 0x0}}, overexposed = {timeout = 0, floating_window = 0x0, button = 0x0, enabled = 0, \n            colorscheme = DT_DEV_OVEREXPOSED_REDBLUE, lower = 2, upper = 98.5899963}, rawoverexposed = {timeout = 0, floating_window = 0x0, \n            button = 0x0, enabled = 0, mode = DT_DEV_RAWOVEREXPOSED_MODE_MARK_CFA, colorscheme = DT_DEV_RAWOVEREXPOSED_RED, threshold = 1}, profile = {\n            timeout = 0, floating_window = 0x0, softproof_button = 0x0, gamut_button = 0x0}, mask_form_selected_id = 0, darkroom_skip_mouse_events = 0}\n        buf_is_downscaled = \n        buf = {size = DT_MIPMAP_FULL, imgid = 4928, width = 4816, height = 3464, iscale = 1, \n          buf = 0x7fff6002e060 \"\\266\\005\\320\\006\\231\\005\\320\\006\\214\\005\\350\\006\\247\\005\\370\\006\\272\\005\\360\\006\\335\\005\\372\\006\\271\\005*\\a\\261\\005\\344\\006\\266\\005\\371\\006\\320\\005\\r\\a\\324\\005\\373\\006\\272\\005\\005\\a\\264\\005\\025\\a\\342\\005\\t\\a\\327\\005\\066\\a\\326\\005a\\a\\273\\005.\\a\\322\\005.\\a\\300\\005\\065\\a\\354\\005&\\a\\303\\005C\\a\\352\\005X\\a\\365\\005@\\a\\332\\005J\\a\\357\\005S\\a\\375\\005T\\a\\356\\005\\\\a\\022\\006{\\a\\367\\005Q\\a\\361\\005C\\a\\366\\005A\\a\\374\\005\\225\\a-\\006}\\a\\017\\006O\\a\\350\\005_\\a\\f\\006I\\a\\f\\006_\\a\\030\\006h\\a\\021\\006[\\a\\025\\006z\\a\\364\\005\\210\\a \\006m\\a\\004\\006\\212\\a\\\"\\006\\221\\a\\034\\006\\244\\a\\020\\006\\214\\a\\035\\006\\220\\a9\\006\\223\\a.\\006o\\a%\\006~\\a\"..., color_space = DT_COLORSPACE_NONE, cache_entry = 0x555557025d80}\n        img = 0x7fffdd272be0\n        wd = \n        ht = \n        res = \n        start = {clock = 261162055.96414199, user = 1.4590829999999999}\n        pipe = {cache = {entries = 2, data = 0x7fffc8046800, size = 0x7fffc8046820, dsc = 0x7fffc8046fb0, hash = 0x7fffc8047070, \n            used = 0x7fffc8047090, queries = 0, misses = 0}, cache_obsolete = 0, input = 0x7fff6002e060, iwidth = 4816, iheight = 3464, iscale = 1, \n          processed_width = 0, processed_height = 0, dsc = {channels = 1, datatype = TYPE_UINT16, filters = 370546198, xtrans = {\n              \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \n              \"\\000\\000\\000\\000\\000\"}, rawprepare = {raw_black_level = 0, raw_white_point = 0}, temperature = {enabled = 0, coeffs = {0, 0, 0, 0}}, \n            processed_maximum = {0, 0, 0, 0}}, nodes = 0x55555642f780, changed = DT_DEV_PIPE_UNCHANGED, backbuf = 0x0, backbuf_size = 266921984, \n          backbuf_width = 0, backbuf_height = 0, backbuf_hash = 0, backbuf_mutex = {mutex = {__data = {__lock = 0, __count = 0, __owner = 0, \n                __nusers = 0, __kind = 0, __spins = 0, __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, __size = '\\000' , \n              __align = 0}}, busy_mutex = {mutex = {__data = {__lock = 1, __count = 0, __owner = 4166, __nusers = 1, __kind = 0, __spins = 0, \n                __elision = 0, __list = {__prev = 0x0, __next = 0x0}}, \n              __size = \"\\001\\000\\000\\000\\000\\000\\000\\000F\\020\\000\\000\\001\", '\\000' , __align = 1}}, processing = 0, shutdown = 0, \n          opencl_enabled = 0, opencl_error = 0, tiling = 0, mask_display = 0, input_timestamp = 0, type = DT_DEV_PIXELPIPE_THUMBNAIL, \n          levels = IMAGEIO_RGB, devid = -1, image = {exif_inited = 1, orientation = ORIENTATION_NONE, exif_exposure = 0.25, exif_aperture = 7.0999999, \n            exif_iso = 160, exif_focal_length = 14, exif_focus_distance = 0, exif_crop = 2, exif_maker = \"Panasonic\", '\\000' , \n--Type  for more, q to quit, c to continue without paging--\n            exif_model = \"DMC-G80\", '\\000' , exif_lens = \"LUMIX G VARIO 12-60/F3.5-5.6\", '\\000' , \n            exif_datetime_taken = \"2018:12:10 16:18:12\", camera_maker = \"Panasonic\", '\\000' , \n            camera_model = \"DMC-G8\", '\\000' , camera_alias = \"DMC-G80\", '\\000' , \n            camera_makermodel = \"Panasonic DMC-G8\", '\\000' , camera_legacy_makermodel = '\\000' , \n            filename = \"P1140477.RW2\", '\\000' , width = 4816, height = 3464, crop_x = 0, crop_y = 0, crop_width = 208, \n            crop_height = 0, num = 0, flags = 1601, film_id = 23, id = 4928, group_id = 3415, version = 1, loader = LOADER_RAWSPEED, buf_dsc = {\n              channels = 1, datatype = TYPE_UINT16, filters = 370546198, xtrans = {\"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \n                \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\", \"\\000\\000\\000\\000\\000\"}, rawprepare = {raw_black_level = 0, \n                raw_white_point = 0}, temperature = {enabled = 0, coeffs = {0, 0, 0, 0}}, processed_maximum = {0, 0, 0, 0}}, d65_color_matrix = {\n              nan(0x400000), 4.57495923e-41, 0, 0, 0, 0, 1.67818607e-36, 4.57495923e-41, 1.67818751e-36}, profile = 0x0, profile_size = 0, \n            colorspace = DT_IMAGE_COLORSPACE_NONE, legacy_flip = {legacy = 0, user_flip = 0}, longitude = nan(0x8000000000000), \n            latitude = nan(0x8000000000000), elevation = nan(0x8000000000000), raw_black_level = 143, raw_black_level_separate = {143, 143, 143, 143}, \n            raw_white_point = 4095, fuji_rotation_pos = 0, pixel_aspect_ratio = 1, wb_coeffs = {623, 256, 380, nan(0x400000)}, \n            cache_entry = 0x555557023180}, icc_type = DT_COLORSPACE_NONE, icc_filename = 0x7fffc8046840 \"\", icc_intent = DT_INTENT_LAST, \n          iop = 0x55555642fc20, forms = 0x0, store_all_raster_masks = 0}\n        sRGB = \n        high_quality_processing = \n        width = \n        height = \n        max_scale = \n        scalex = \n        scaley = \n        scale = \n        processed_width = \n        processed_height = \n        bpp = \n        outbuf = \n4  0x00007ffff79f0a50 in _init_8 (size=, imgid=4928, color_space=0x7fffdd275ac0, iscale=0x7fff80482048, height=0x7fff80482044,\nwidth=0x7fff80482040, buf=0x7fff80482060 \"\") at ../src/common/mipmap_cache.c:1221\n    format = {plugin_name = '\\000' <repeats 127 times>, module = 0x0, widget = 0x0, gui_data = 0x0, version = 0x0, name = 0x0, gui_init = 0x0, \n      gui_cleanup = 0x0, gui_reset = 0x0, init = 0x0, cleanup = 0x0, legacy_params = 0x0, params_size = 0x0, get_params = 0x0, free_params = 0x0, \n      set_params = 0x0, mime = 0x0, extension = 0x0, dimension = 0x0, bpp = 0x7ffff79ed610 <_bpp>, write_image = 0x7ffff79ed620 <_write_image>, \n      levels = 0x7ffff79ed600 <_levels>, flags = 0x0, read_image = 0x0, parameter_lua_type = 0}\n    dat = {head = {max_width = 360, max_height = 225, width = 0, height = 0, style = '\\000' <repeats 127 times>, style_append = 0}, \n      buf = 0x7fff80482060 \"\"}\n    ht = 225\n    altered = <optimized out>\n    cimg = <optimized out>\n    wd = 360\n    filename = \"/run/media/karl/1f252d49-56e8-4db7-8d09-ba896c2f49c7/Fotos/2018/12_10_Trescovat/P1140477.RW2\", '\\000' <repeats 4003 times>\n\n--Type  for more, q to quit, c to continue without paging--\n        from_cache = 0\n        res = \n        incompatible = \n        wd = \n        ht = \n        filename = \n        from_cache = \n        altered = \n        res = \n        cimg = \n        incompatible = \n        orientation = \n        c = \n        jpg = \n        tmp = \n        tmp = \n        thumb_width = \n        thumb_height = \n        k = \n        tmp = \n        format = \n        dat = \n5  dt_mipmap_cache_get_with_caller (cache=0x55555633a950, buf=buf@entry=0x7fffdd275aa0, imgid=4928, mip=,\nflags=flags@entry=DT_MIPMAP_BLOCKING, mode=mode@entry=114 'r', file=0x7ffff7b64120 \"../src/control/jobs/image_jobs.c\", line=35)\nat ../src/common/mipmap_cache.c:801\n    entry = 0x555557025d20\n    dsc = 0x7fff80482040\n    mipmap_generated = 1\n    key = 268440383\n\n6  0x00007ffff7a0f5e4 in dt_image_load_job_run (job=) at ../src/control/jobs/image_jobs.c:35\n    params = 0x5555570fc360\n    buf = {size = DT_MIPMAP_0, imgid = 0, width = 0, height = 0, iscale = 0, \n      buf = 0xffffffffffffffff <error: Cannot access memory at address 0xffffffffffffffff>, color_space = DT_COLORSPACE_FILE, \n      cache_entry = 0x555557025d20}\n\n7  0x00007ffff7a08b35 in dt_control_job_execute (job=job@entry=0x5555570e9510) at ../src/control/jobs.c:304\nNo locals.\n8  0x00007ffff7a09338 in dt_control_run_job (control=0x555555795000) at ../src/control/jobs.c:323\n    job = 0x5555570e9510\n    job = <optimized out>\n\n9  dt_control_work (ptr=) at ../src/control/jobs.c:568\n--Type  for more, q to quit, c to continue without paging--\n        params = \n        control = 0x555555795000\n        name = \"worker 1\\000\\000\\000\\000\\000\\000\\000\"\n10 0x00007ffff772296a in start_thread (arg=0x7fffdd284700) at pthread_create.c:463\n    pd = 0x7fffdd284700\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {140736903792384, 7402788489552943872, 140737488299646, 140737488299647, 8396800, 140737488299792, \n            -7402714206888830208, -7402772042438452480}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, \n          cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n11 0x00007ffff74571bf in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nNo locals.\nI'm on Gentoo Linux:\nLinux desktopkarl 4.19.19-gentoo #1 SMP PREEMPT Wed Feb 6 13:00:20 EET 2019 x86_64 Intel(R) Core(TM) i7-2600K CPU @ 3.40GHz GenuineIntel GNU/Linux\n```\nRunning gcc-8.2.0, glibc-2.27-r6\nAny more information you need?. Thank you, crashes are gone now. Also editing seems to be more responsive. And I can get a slightly better highlight contrast than with the checkout some days ago. Thx!. I also wanted to ask if DT could implement that tool in a similar way RT does.\nRT now uses a guided filter which prevents halos and keeps a natural look.\nFirst RT. Left is \"neutral\" profile which doesn't apply any curves etc., right is just the highlight slider pulled to 100:\n\nDT also dialed back to \"Original\" and pulled back the highlight slider so clouds don't pop too much. You already can see a big halo going on. Can be somewhat softened by a bigger radius, but I never can eliminate that over-the-top HDR-look.\n\n. ",
    "MStraeten": "found several errors like following during compilation on windows using mingw/msys as described in darktable/windows/BUILD.txt:\nC:/msys64/home/SHM/darktable/src/iop/toneequal.c:572:9: error: the call requires ifunc, which is not supported by this target\n #pragma omp parallel for simd collapse(3) schedule(dynamic,8) aligned(in,out:64)\nany ideas?. CPU is a Intel i5-6300U. additional error: \ndarktable/src/iop/toneequal.c:818:11: error: no member\n      named 'priority' in 'struct dt_iop_module_t'\n  module->priority = 158; // module order created by iop_dependencies.py...\n  ~~~~~~  ^\n(built with current master and  #1904)\n. for macbook retina 1em is quite big (like 12 pt; 8pt or 9pt is quite better), maybe it could be customizable via preferences dialog. yes, changed 1em to 8pt --> fine, changed 1em to 12 pt --> no difference visible, changed to 0.9em --> not useable.\nbut if setting an explicit dpi in darktablerc: screen_dpi_overwrite=93, 1em is fine ;)\nnow i have to figure out why osx doesn't use Roboto (even fresh installed ). within one of the last changes  \"void dt_ui_border_show(dt_ui_t *ui, gboolean show)\" was removed from gtk.c resulting in an error in slideshow.c. with latest commits the scaling of icons got weird. On my retina macbook i use a screen_overwrite_dpi setting of 72 to optimize remaining space for the image. Icons are now upscaled and too big for the intended space:\n\n\nformer behaviour:\n\n. found a warning in the command line output:\nTheme parsing error: darktable.css:145:26: The style property GtkRange:slider-width is deprecated and shouldn't be used anymore. It will be removed in a future version. for additional font fun : \nPango-WARNING : 17:07:39.788: couldn't load font \"Roboto Ultra-Light Extra-Condensed Not-Rotated 12\", modified variant/weight/stretch as fallback, expect ugly output. \nreplacing in Line 387: extra-condensed with condensed works fine as Robot doesnt have an Extra-Condensed font. with latest commits i got a segmentation fault on 'compress history stack' on osx\nto reproduce: open rawfile in darkroom and click compress history stack\nmessage: \nMagick: abort due to signal 11 (SIGSEGV) \"Segmentation Fault\"...\nAbort trap: 6. theres also an issue with an ampersand in style names:\n(darktable:61582): Gtk-WARNING : 23:50:00.127: Failed to set text 'Emulation based on B&W film Ilford HP5 Plus 400 (http://bit.ly/t3mujinpack, v0.5.0)\ntone curve (on)\nchannel mixer (on)' from markup due to error parsing markup: Error on line 1: Entity did not end with a semicolon; most likely you used an ampersand character without intending to start an entity \u2014 escape ampersand as &. I headed back to master and the ampersand-behaviour is the same, so i'll open a redmine ticket for this. when importing new directories and darktable starts with an directory containing a lot of files the filenames are invisible. Similar behaviour when exporting styles. from a developer's view that might make sense as a file ist not to be selected in that place ;)  but for a user it's important to be able to check, if the directory contains the exspected stuff ...\n\nEdit: The reccomendation of tubobit (color: shade(@fg_color, .7);) solves this behaviour - seems to be a side effect from hiding disabled stuff.. OSX:\nthere seems to be a segfault on rgb curve being activated with a former processed raw.\nscenario: history stack contains: rotate, crop&rotate, perspective correction, demosaic (amaze)\nactivating rgb --> segfault: \nconsole.txt\ntrace: trace2.txt\ndoing the same starting from scratch, first applying perspective correction, crop&rotate, demosaic, and then activing rgb works fine\n. with history stack: 20190223-IMG_5936.CR2.xmp.txt\nfrom scratch: 20190223-IMG_5937.CR2.xmp.txt\n. yes, i built it myself:\ndarktable --version\n```\nthis is darktable 2.7.0+617~g57b8955d0\ncopyright (c) 2009-2019 johannes hanika\ndarktable-dev@lists.darktable.org\ncompile options:\nbit depth is 64 bit\nnormal build\nSSE2 optimized codepath enabled\nOpenMP support enabled\nOpenCL support enabled\nLua support enabled, API version 5.0.1\nColord support disabled\ngPhoto2 support enabled\nGraphicsMagick support enabled\nOpenEXR support enabled\n```\ndarktable -d all > trace.txt: trace.txt\nafter deleting content in ~/.config/darktable:\ndarktable -d all > trace.txt: trace.txt\n.txt: . Thanksfor the solution. same behaviour with opencl activated or deactivated.\nscenario works fine with dt 2.6.1 (with opencl)\nmy last working build: darktable-2.7.0+575\\~g68849b1cf (with opencl)\nerror occurs since my first build requesting a database update (darktable-2.7.0+650~g1b8154372) . further information: after applying the first style (contains a tonecurve) adding a further toncurve by context menu is deactivated\n. recreated the styles with 2.6.1\nafter opening with 2.7 the database update is done with following messages:\n[imageop_init_presets] updating 'tonecurve' preset 'Canon 5DmIV Monochrome' from blendop version 8 to version 9\n[imageop_init_presets] updating 'tonecurve' preset 'Canon 5DmIV Neutral' from blendop version 8 to version 9\n--> the conversion of the styles seems to be weird. seems to be fixed with a former commit .... applied the patch --> compiling successful. seems to be fixed - thanks. only if clicking display wavelet scale --> the image turns red\nexport --> the retouch is applied as expected\nsame misbehaviour with discard history stack and reload xmp as written by 2.6.1. 20190223-IMG_5936.CR2.xmp.txt\n. thanks for the fix. fixed . are you using styles? i found similar behaviour in that case: #2212. on osx it reorders the iop modules - seems to be a bsd specific behaviour \nif it's nonsense for gnu sed, then it's not necessary to change it, so this issue for documentation only, so the next osx user doesnt need to search for a solution .... I found the workaround here: \nhttps://markhneedham.com/blog/2011/01/14/sed-sed-1-invalid-command-code-r-on-mac-os-x/\nNow i found also https://unix.stackexchange.com/a/131940 stating this is osx specific \nSo the issue can be closed. works fine, thanks for the fix. ",
    "olokobayusuf": "Is this verified to work? I have manually built and tested master and 2.6.0 and when using --style, the export fails:\n$ darktable-cli one.CR2  one1.jpg --style deraw.dtstyle\n[imageio_storage_disk] could not export to file: `one1.jpg'!. Ah I see. Tested ok!. ",
    "stilicrafter": "Hi.\nI am useing Version 2.4.4 (see below icon, but if there is a more detailed version info, could you tell me where to find?)\nThe System is Windows 10 PRO on a Surface PRO 15 512GB\nThis image is a freshly opened RAW (see YouTube link) with all the setting. (And for easy understand i switched the GUI Langue from German to englisch ):\nhttps://www.youtube.com/watch?v=irnAjWw9b_0&feature=youtu.be\nI think, you can also change the color whenn I open up or close the botom line (but i am not compleatly sure and it wasnt reproducable in the Video.\nI also uploaded the RAW image. (see below)\nDSC07441.zip\n. Setting s start in Youtube Video at Second 40.. And , expect for GUI: These are my settings: \nhttps://www.youtube.com/watch?v=5YMK6vP2lWA&feature=youtu.be. >           Could it be a cache refresh issue ? (crop and rotate just force a cache regeneration or something ?)\nHow can i clear the cache ?\nIn Darktable itself? But also image altering actions can cause this. (Like Color tone Curve)\n. >           the cache is cleaned when you zoom in/out.\nAlso when Zooming in and out the Colors can change itself\n\nCould you provide the list of the modules you are using ?\n\nOnly the default one.\n(Sharpen, base curve, orientation, highlight reconstruction, white balance)\nAnd then , if i zoom on and out, it will change the colors.. ",
    "pschwartz": "Confirmed that this only affects the 2.6.0 release build. The last RC and before work correctly.. I would disagree. I have now tested on 3 physical systems and a clean VM install. There is an issue with the release windows installer. All of the previous work without issue.. It is on 4 different installs. All Windows 10 Pro 2x 1803 1x 1709 and 1x 1703.\nFor it to not work on 4 different installs and 3 different versions would lean towards it definitely not being an environment problem. An environment problem would lead towards a single install of a single version. \nSo yes, I disagree that this is an environment problem and is in fact a problem with the installer.. The file failing on only the Release installer is C:\\Windows\\System32\\ntdll.dll Confirmed same on 1 of the other systems, so not digging there more. \nThat is a system based dll and is present on the systems (in 1803 - 10.0.17134.228 (WinBuild.160101.0800)). \nIt is also accessed correctly by all of the 2.6.0 RC's and the previous 2.4.4 release.\nTo have multiple systems fail on the same file with the same error points to the issue being the installer.. ",
    "agusmba": "Windows 10 Home (not Pro) here and it is working as expected.. Personally I like the technical explanation.\nIn addition I think that at least the \"Exif.Photo.UserComment\" reference is great so that those who like to fiddle with their exif data know what goes where.\n(just my 2c). The correct translation would be:\n\"mostrar siempre las barras de desplazamiento de los paneles\". Maybe add \". (necesita reinicio)\" at the end?. \"expandirlos\" was correct, \"expanderlo\" does not exist.. \"expandirlos\" was correct, \"expanderlo\" does not exist.. technically both are admisible here, but \"alrededor\" is more common nowadays than \"al rededor\".\nNot really necessary to change it back.. are the spaces (or lack of) relevant?. \"l\u00ednea de tiempo\" instead of \"l\u00ednea del tiempo\" for coherence with the rest of translations.. Even though I'm Spanish I have no idea about photography terminology, so I'm not sure about the \"lift\" -> \"elevaci\u00f3n\" translation, which sounds like a direct translation, but in my mind, \"realce\" sounds better\nI'm not asking for a change here (and everywhere else this appears) but for confirmation that this is indeed the right translation.. this has been translated differently elsewhere: \"interpolaci\u00f3n crom\u00e1tica\"?. 2\u00aa instancia. dispersi\u00f3n sounds better. ... Aumente .... I'm guessing these commented out lines shouldn't be here?. why remove the verb? \"incrementar\" seems necessary to understand this. why remove the verb? \"disminuir/decrementar\" seems necessary to understand this. Depends on how the \"filmic\" module name is translated. \"pel\u00edcula\" seems off. why?. spacing?. ",
    "JIPG2": "Windows 7 Home 64 bits working OK here with 2.6.0. \nOnly minor issue is that datetime in image info provides the week day in Slovenian, while the language selected in DT is English. All  language options in the PC are set in Spanish. Do you now about something that can be changed in Windows to make it working properly?. OK. ",
    "sguyader": "Thanks @TurboGit and @Aurelienpierre. Disabling opencl did it. I have a regular integrated Intel graphics chip (HD Graphics 620) and have the intel-opencl drivers installed. I will try installing the Beignet drivers and see if I can use opencl with those.. ",
    "elman22": "Yes, this seems to be bug for me as well. Especially when export exports both images as JPG and I have no idea which one was developed from RAW until I actually open the image and take a look at it. This behavior was not present in 2.4 series. \nI assume this has something to do with group rating which is feature I like. I used lua script for that in 2.4.\nAlso quick question. How it this new grouping handling geotagging? In 2.4 when I applied GPS to a group, only RAW image was tagged. JPG doesn't have GPS coordinates. It this behavior changed as well?. ",
    "Pointy": "I've learned since I opened this that the issue is indeed related to the desire to have ratings apply uniformly to group members. I have also gained understanding of the Lighttable images filter mechanism. In my own workflow I generally don't need camera JPG files in Darktable anyway, so I could solve my problems by simply not importing them in the first place. However now that I realize I can filter the Lighttable view by film roll and by group rank (\"leaders\"), things work out perfectly well for me.\nI won't retract my \"bug\" because I think it might be useful as evidence of a need for more clarity in some part of the GUI documentation, though of course I won't have my feelings hurt if it's closed as a \"works as intended\".. ",
    "pick2510": "Hmm.... \nBut it should look into .local/share/lensfun ?\nSomehow it doesn\u2018t work if I use the lensfun-convert-lcp. This script puts the additional data in .local/share/lensfun/version_2\nOn Linux everything is fine.\nDo I need to put this somewhere else?. So, I copied the new db to the appropriate directory and I found out, that lensfun 0.3.2 stable doesn't support the acm model in the database (model=\"acm\"). Since 0.3.2 stable is already three years old and I'm not sure if they release a stable version very often: Would it be possible to build against a newer version? A more recent version is 0.3.95-alpha\nI think Ubuntu packager do this but can't check at the moment since my linux notebook is at the office until the end of my vacation.\nI would try to do it, but I have installed homebrew and would probably mess up my system with an additional MacPorts installation.\nA lot of lenses, even a lot from major manufacturer like Canon, don't have complete lens profiles with TCA and vignetting in lensfun. \nUsage of converted Camera Raw profiles would help a lot to completely abandon Lightroom.. Homebrew provides the newer lensfun version as stable: https://formulae.brew.sh/formula/lensfun\nIf I build darktable with all the dependencies from homebrew I get random segfaults when starting the app.. Great! Thx. ",
    "LiranV": "I can confirm the same behavior.\nAlso happens with \"unstarred only\".. Opened a merge request with a fix #2052. @TurboGit \nJust to make sure, when I refer to the G button, it's the one that controls all groups and not a specific group.\nAfter these steps I've mentioned you should see:\n1. The JPG with the same group_id as the raw we starred, as it's now its own group representative (because its pair RAW was filtered out, which is the original representative).\n2. The JPG and RAW of each of the other groups.\nBut group collapsing is still on (G button is active`) so we would expect to see:\n1. same as 1 above\n2. All the rest of the RAW (no JPGs) images which are the rest of the representatives.\nIs it any clearer?. @TurboGit \nAlso, sorry, but I meant that you star only the RAW image and unstar the JPG if needed.\nThis mimics coming from older versions of DT where the starring was not effecting the entire group (which led me to experience the bug in the first place).. @TurboGit They are actually not equal.\nThe following SELECT output is a table with two columns where each row is an image that has the lowest MIN() value calculated. Which basically means that in the id column we have only representative images or the 'closest' (by our terms) image that can be used as the representative for the current filtration.\nSELECT id, MIN(ABS(id-group_id)*2 + CASE WHEN (id-group_id) < 0 THEN 1 ELSE 0 END) FROM main.images WHERE %s GROUP BY group_id\nSo now we want to do an IN operation to check if a given image is in this selection, but we need to have only one column for the IN operator to work, thus the additional (SELECT id FROM, just to get rid of the 2nd column that held the minimum values (all we care about are the IDs at this point).. ",
    "francoiscourt": "I added the following to mil-fujifilm.xml, and it works fine \n<camera>\n<maker>Fujifilm</maker>\n<model>X-T3</model>\n<mount>Fujifilm X</mount>\n<cropfactor>1.529</cropfactor>\n</camera>. ",
    "spaceChRiS": "Hm, I think you are referring to this: https://github.com/darktable-org/darktable/compare/master...rawfiner:rawfiner-denoise-profile-coarse-noise-reduction3, which seems to deal with noise reduction \u201conly\u201d. As a side effect, it may partially implement what I am suggesting above, but lack some of the aspects. Noise may not be the only reason to limit the output size, and therefore the possibility to give the output size as the (only) input parameter may be crucial. It would be great if we could pull @rawfiner into the discussion, maybe the approaches could be combined \u2026. Thanks @rawfiner, now I understand better. Thinking about the pixel pipe position, the two ideas are really very different, but maybe there would be some communication between them necessary if they both get implemented, i.e., using one of these locks the other and vice versa.\nThe position in the pixel pipe of my idea is very late, it would not even require an additional image operation at all. It's just that the limited output size is\n\ncommunicated to the export module such that the maximum output size follows this limitation, hq downsampling should still use the original image size, and\nit is communicated to everything affecting the display of the image in darkroom such that the 100% view represents the calculated downscaling.\n\nSo far, only the available image operations are used, but their control \u201cmetadata\u201d is altered.\nWhat to do about zoom levels above 100% I am not sure. For these, an additional, fast, downsampling at the end of the pixel pipe* could be required.. I have a reason to see it in my case at the end of the pipe: The output of every iop that uses convolution in one or the other way would require different input parameters for a scaled image. Take sharpening as an example. For the same kernel size, the result will be very different if I do it on the full scale image or on a scaled version. If I adjust sharpen first and then activate scaling early in the pixel pipe, the parameters (e.g. radius) will not change accordingly, such that the result is different afterwards. To avoid all such complications, my feature request should only work at the end of the pixel pipeline, and as I wrote, it would not even require an iop at all, just overwritten/scaled parameters for zoom level and the export modules, and some special treatment for zoom levels >100%. For the latter, I think, even a little overlay text that states that due to activated feature, the preview is not accurate, would be sufficient I think.. Hm, not sure what you refer to as a good thing. Yes, the sharpening would be useless in that case, but assume when resizing is early in the pixel pipe, but you set your parameters before activating rescaling:\n\nYou set sharpen to radius 2 px on full size image, and it results in a good result\nThen, you activate the rescaling to e.g. 50 %\n\nResult will be sharpening of the rescaled picture with radius 2 px, which means compared to the original image a radius of 4 px, and probably not a good resulting picture.\nIf resizing comes after, the result would be equivalent to what happens when I output the image at full size and rescale afterwards, or, what would happen when I limit the image output size in the export module with the hq option on.\nWhat do I miss?. I totally understand your point, and it tells me that sharpening was the worst example I could take. I think I found better ones:\n\nWhat about masks, if I e.g. draw a mask around a face and then activate early pipe scaling, the mask position and size will be wrong (at least if the masks are stored in absolute pixel coordinates).\nThere are other modules that may be affected as well, e.g. lens correction, perspective correction, \u2026\n\nMy feature request is just about setting a maximum output size for an image in the export module and store this decision in the xmp file and database. For convenience this should happen in the darkroom, and for even more convenience the image preview in darkroom should reflect this setting. But even only the first part would be great already, since one can also manually preview by setting the according zoom level (e.g., if I limit the export size to 50%, I could use the 50% zoom level to represent my exportet 100% view).\n. I don't think you do not get feedback. One of the reasons I prefer exposure setting in the histogram is that you get the feedback as a changing histogram. I see exposure as a correction operation and not a grading operation, therefore adjusting everything for a well used histogram is much easier when control and feedback are at the same position on the display. Especially for touchpads without mouse wheel, this is an enormous benefit over making the changes in the module.\nSpeaking about basic information display, I agree that a fix position on the screen is beneficial, I use this as well e.g. to decide about the noise reduction method I chose. Maybe this information could move to the left side, overlaid over the thumbnail image, or in one of the two information lines above the big image preview (e.g., left of the \u201cG\u201d symbol).. Hm, I don't know if it would work like that, maybe it's worth trying. But darktable already runs short of available keys. In my case, \u201ce\u201d is bound to the tag \u201cPeople|Family|Emil\u201d (my son) in the quicktag lua module, just to give an example. If it would be possible to temporarily override assigned keys from lua, one could in that case think of using a quicktag mode that reassigns the keys when active, but for now, lua hotkeys are even global.\nA more general view on that is, that one of the biggest strengths of darktable is also one of the biggest weaknesses. When I work on an image, I have to go through a lot of \u201cindependent\u201d modules just for the basic settings, which is great because of the flexibility (there are so many different approaches possible), but is as well a slow down for the basic workflow. And any approach to streamline the interface even more by getting rid of the little shortcuts that allow to bypass the longer way may make things worse if there's no equivalent replacement.\nTo solve this, what about the following idea: A module, that is user configurable in a way that controls of different iops can be added to the empty module (e.g. by a config file) which gives the user the possibility to configure his basic editing workflow into one module. This module would have one common mask (which may be implemented by the new pixel mask, the mask would be determined by the first involved module in the pipe and copied as pixel mask to all the other iops) and the involved modules would be initiated invisible in the background. The user could only chose, if the modules should be the first or last ones of their kind in the pipe. In the config file, the module settings that are not taken over as control could be set to fix values. I know, that's a bit weird, but it's the only solution I can see to maintain the flexibility and a fast access to oft-used modules. I would do the following configuration:\nFrom white balance, I would take temp and tint (temp first).\nFrom exposure, I would take black and exposure.\nFrom crop/rotate, I would take angle and aspect and would configure to have golden sections help lines.\nThe equalizer would also join my module.\nFrom shadhi, I would take shadows and highlights, and I would configure bilateral filter as default.\nA tone curve would be added as well.\n\nThese modules that are only available as one instance would not be invisible but the controls would just be doubled.\n\nHm, maybe better ignore my stupid thoughts of the configurable module, but about darktable's UI, I still balance between love and hate, but for sure with a bit more love ;) OK, it's much more love and only a little bit of hate \u2026. ",
    "nilsholle": "\nThis happens on zooming in/out using Ctrl+/Ctrl- (should be reproducible on standard 1080p displays).. Two things go wrong when showing a single image in lighttable:\n1. I think the image position is wrong. On the left, there is a small space (slightly lighter gray) that shouldn't be there.\n2. When switching to darkroom and back, the top of the lighttable should be redrawn.\n\n. Are the changes already implemented for the thumbnail view at the bottom of the darkroom? Feel like that is still a little slow.. ",
    "jhmos": "Thanks TurboGit. Happy to say the changes have made it usable on a 5K iMac too. Took me a while to create the build environment, but I can now do some testing for Mac OS.\n. ",
    "homer3018": "Hi guys,\nI'd be happy to assist and do some further testing on my newly bought iMac 5k, but as I'm new to mac I have some (possibly dumb) questions like is it ok to have the regular 2.6 DT installed along with the dev version ? If someone would be kind enough to guide me through that that'd be great. Once up and running I hope I can help further with some coding but we'll see to that at a later stage :)\nThanks and keep up the good work !. All good Pascal, thanks for assisting. . ",
    "pierre-guillot": "Yes I confirme : disable Opencl fix the problem. Thank you :). sorry for the late response, Can you explain to me exactly what I need to do? Lunch darktable with command line with the \"-d opencl\" parameter and copy/past the output?\n. Hi!\nre-enabled opencl and ran the command above. You can download output file here : \nhttps://framadrop.org/r/HVbD1nu4d7#2wfIxuY4Su4sYezduE9jsZJlSQ1gowuovzj4eczxtVk=. I confirme : With version 2.7.0+496~g38e361f28 there is no problem!. ",
    "0x783czar": "I for one would find this very useful, especially since I like to work with scans of some uncommon lenses. Profiles are great, but having the ability to fine-tune would make things even better.. ",
    "msdm": "\nwhich modules are affected ?\n\nActually this is a feature request and affects all iops. Personally I have lengthy presets lists for tone curve, equalizer, filmic, and channel mixer.. I don't think this feature needs a lot of GUI rewriting. There is already a presets section for iops in the preferences and even a hiding capability (based on specific criteria) for custom presets.\n\nAlso, if you don't use the default presets and yours are better, maybe share them to see if we can merge them ?\n\nMy presets are specific to my post processing style and also my equipment (camera, lenses, etc.). I don't think they are generally better than the default ones.. ",
    "matejvanco": "Same issue on o OSX 10.14.2 (18C54), 8 GB RAM, DT version 2.6.0\nerror.txt\n. ",
    "hellbuster": "I tested in 2.6.1 and it does not crash, but it instantly hangs. I activated local contrast (on default values) and levels.. I sent PR #2199 removing this.. ",
    "Nilvus": "And if it's ok for 2.6.1 and have time before 2.6.1, I could translate this part in french as I've just made it for filmic part.. Great works. The new UI is gorgeous and more minimalistic than one we use by now. Respect of UI guidelines darktable is even better as the place for the image is improved.\nI found that the four icons on top right of the image (group, help, preferences...) are way too big regards of the rest of the interface. Maybe just reduce their size to one or 2 pixels would be better.. > actually, I wonder if it's not better without the arrows\u2026\nI'm not sure it's a good ideas to remove them. I'm afraid, some new users could be lost without seeing them. It's a way to quickly know that options are hidden besides the module title.\nI think it will be better to have an option on preferences for example to hide or show the arrows. Like with some extensions on Gnome panel.. I'm using quite often actives functions of histogram, as it sometimes faster to adjust exposure. So I prefer to let this function active. But the Exif text on the histogram is not the better design and it disturb the view of Exif and histogram. That said, I like to see this information quickly when needed and without to open the image infos panel on the left.\nAs Turbogit said, there many places to move this information. We could put this info under the histogram or on the left of \"Group\", \"Help\", etc. icons. It could also be written on the bottom center (or even top center) of the image.\nWith that, reducing a little the height size of the histogram could be great to add space to modules. I think that reducing to 10% size the height would be sufficient and not too much.. I see that you put the 2.8 milestone. As it is about the filmic 2.6 version and not the master one, why not put this on 2.6.1 milestone ? The usermanual is always on 2.4 version on darktable.org. 2.6.1 could be the good version to submit the 2.6 updating version of the manual, both in english and french version (other languages if ready to go).. Great !. As if it is just minor corrections, could you put this on 2.6.1 milestone as first submit (and for same reason) ?. This PR with #2037 will make the new darktable interface really awesome ! Great work.. Hi, Simple and clear for me. Thanks. I've just see one error (corrected in bold):\nLine 17 : \"This works because all the shapes from the drawn mask\"\n. If we use darktable on the good way (i.e., manipulating files only darktable), we can't have skull graphics appear (or rarely). So I personnaly consider that developers have more important things to do than changing graphics.\nBut if you don't like that, you could search on source code where is the file contains this image and change it for you own use.. Please see that work in progress and react on it if necessary : https://github.com/darktable-org/darktable/pull/2037. Please search and read before posting issue. That's already known and it's possible to change the font size.\ndarktable is a Linux software on start. This font size is not the same on Linux and Mac. Font size could be changed by editing darktablerc file on your ~/.config/darktable folder. In that file, you just have to modify this line :\nscreen_dpi_overwrite=-1.0\nPut value like 110 instead of -1.0 by default should be good. You just have to increase or decrease to adjust which size you want. Be sure to modify this file with darktable closed.\nSo, this will probably change and be better suitable for all OS with darktable 2.8.. That's will normally not be necessary on darktable 2.8. See that PR to understand why : https://github.com/darktable-org/darktable/pull/2037\nAnd darktable 2.6 already make it possible to edit theme of darktable with css and make themes. You could see lots of ideas on the forum of darktable.fr website (in french but web translators could help. See the FAQ of the site for links about that.. I'm not sure to really understand what you mean but this is already possible. darktable have snapshots functions and you could split horizontally or vertically. Seriously, 1.6 ? 2.4 manual is here since a year and since few days, the 2.6 one is here. You don\u2019t seem to be used and good searching. And bug hunting start by be sure to knowing well a software and not posting bug issue that are not ones. And manuals are in PDF... Yes one file for the entire manual... and, wow, that makes a book.. This is possible in another way by cloning functions.. It is documented on manual yes. You could download the manual in PDF on darktable.org (resources). Searching is easy on PDF.. Read the manual, please, read the manual. One tap on one touch of your keyboard is also possible. And simple click is used for another useful function. So, please read the manual before posting issue that are not one. Not your first in just few hours.... I would not ! I prefer saving space for photos.. We already said that to you. Please read and stop using issues that are not ones or are already work in progress. This is not a forum but a place to post unknown issues. That's part of UI rework like a lot of graphics improvement.\nAnd like I said, the UI is already customisable with CSS.. Tanks, and not the first time I forgot to change that. Poedit change to full pathname automatically. I will update it now.. > Strange, poedit does not do that for me on GUI translation file.\nI don't know why it change that pathname. I've searched on the software and didn't find any options.. ",
    "techexo": "I don't know anything about that so don't take my word for it, but shouldn't there be somewhere where CA infos are stored to fetch OSM infos?\nIf I'm not mistaken, it was migrated from http:// to https:// (https://github.com/darktable-org/darktable/pull/1691) some time ago, maybe libcurl needs that the CURLOPT_CAINFO be explicitely defined on Windows to access CA root certificates? (https://curl.haxx.se/libcurl/c/CURLOPT_CAINFO.html)\nMaybe this and this could also be of interest (and more generally this curl help for TLS). @peterbud Great, it means at least the the problem is identified, and is just a TLS configuration issue. I support @parafin in that we should not skip certificate verification, but link to  ca-bundle. . OpenStreetMap uses Let's Encrypt as certificate provider. The issue is probably that the root certificate is in Windows' certificate repository (you can check in Internet Options -> Content ->  Certificates), but some Intermediate certificates are missing. As @peterbud said, libcurl used for dt on Windows is compiled with Schannel support, so Windows' certificates are used.\nWe are not the only one with this issue, as there is quite a number of issues opened with curl + Let's Encrypt, I am investing it right now. I'm replying again as soon as I think I figured it out.\n@parafin I think we're past the original suggestion to not verify certificates, no need to worry :) We just have to figure out how the complete certificate chain is supposed to work on Windows with libcurl.. Indeed, (recent) Windows repository has by default DST Root CA X3, the root authority giving certificates for Let's Encrypt. However, it does not contain the intermediate authority Let\u2019s Encrypt Authority X3 (see Let's Encrypt chain of trust here).\nI am trying to find the best way to indicate to curl the whole chain.. @peterbud ~I think that we can avoid shipping the whole bundle by using just fullchain.txt (to be renamed in letsencrypt_osm_fullchain.pem), which contains both Root and Intermediate Certificates for Let's Encrypt.~\nEdit: see comment below: if other websites have currently unverified https acces, it would make more sense to use the bundle than individual certs.\nIn command line, using\n./curl.exe --cacert letsencrypt_osm_fullchain.pem https://nominatim.openstreetmap.org/search/... \nallows for the connection with a bundle-free curl, we should thus try:\ncurl_easy_setopt(curl, CURLOPT_CAPATH, \"../share/curl/letsencrypt_osm_fullchain.pem\");\nCould you try and compile/test with this option? I don't have at all the config for it right now.\n@parafin It's probably true, I am not convinced with the doc of curl on this, as it is supposed to take into accound Windows' certs but don't do it when we add manually all needed certificates. That's why I think we could try what's described above.. @parafin I think you could open another issue for this problem, even if it's related. However, I did not understood that verification was not done for several external services in darktable; thus it could make more sense to use @peterbud suggestion to have the whole bundle, as it would be only one file to maintain (i.e. update from curl's website), instead of all individual certificates for external websites.. @parafin It does somehow, connection was successful using curl-ca-bundle.crt provided with the latest version of curl (7.63.0-win64-mingw) for Windows. I tested without the bundle and it failed.\nEdit: I'm working on a PR right now to help test it quickly. I can't compile however. I'll link it asap.\n. PR linked just above. There is stuff I have no idea how to do (where to put the bundle file, how it's supposed to be package, how to compile and such). I hope @peterbud will be able to help on that. I can give write permissions on my repository if it can help.. Oh OK, sorry \ud83d\ude4f Feel free to PR massively on techexo/darktable, I'll accept everything \ud83d\ude09. For information, direct link towards last export from curl teams is https://curl.haxx.se/ca/cacert.pem.\n@parafin, no I am not sure indeed for relative paths. I did them relative to bin/ to go in share/, but it may not be that. Feel free to PR on techexo:tls-fix the right thing.. @peterbud I rebased my branch on darktable/master and integrated your suggested change for the bundle in cmake/windows-macros.cmake.\n@parafin & @peterbud You're obviously more competent than me to solve this issue. If you think it's easier, do not hesitate one second to make another PR and I'll close that one.\nI'll try to rebase regularly, or I'll implement changes if you send me links to the patches. Whatever works to solve this issue :)\nEdit: If MacOS package also bundles these certs, we should try and find a solution at least common to those two platforms. However, we could package it also for Linux, even if it's useless ; it couldn't make any harm?. Rebased my repo, if it can help.\nEdit: rebased against darktable-2.6-x and I also changed the target branch for now. However, I think the changes will probably have to be cherry-picked into master for the future.. I think PR https://github.com/darktable-org/darktable/pull/2074 that was merged for 2.6.1 makes this PR useless. Thanks @peterbud for the work, this PR should be refused. . @TurboGit or\u00a0@peterbud Shouldn't this PR be in the 2.6.1 milestone, as #2028 was and it replaces it?. ",
    "aadm": "You're right. After compressing the history stack the issue goes away. I can live with that! Just to be clear (maybe I misunderstood), this happens also on newly imported photos with no previous \"history\" in Darktable (I understood from what you wrote that this misbehaviour should only occur in a photo that was edited with a prior version of DT then modified).\nThis checked on latest commit: d6d5b9a8d. ",
    "PetrGlad": "Some of documentation (e.g. https://www.darktable.org/usermanual/en/overview_chapter.html#darktable_cli_commandline_parameters) implies that source folder can be a directory. So one could process a bunch of files by grouping them into a separate folder.\nI tried this with darktable-cli 2.4.4 and it fails with program error:\n```\ndarktable-cli --width 3000 --height 3000 --hq true print 'print-exported/$(FILE_NAME).jpg'\n[New LWP 21461]\n[New LWP 21462]\n[New LWP 21504]\n[New LWP 21505]\n[Thread debugging using libthread_db enabled]\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\n0x00007f3eb66473ea in __GI___waitpid (pid=21506, stat_loc=0x0, options=0) at ../sysdeps/unix/sysv/linux/waitpid.c:30\n30  ../sysdeps/unix/sysv/linux/waitpid.c: No such file or directory.\nwarning: Currently logging to /tmp/darktable_bt_N5YAWZ.txt.  Turn the logging off and on to make the new setting effective.\n0  0x00007f3eb66473ea in __GI___waitpid (pid=21506, stat_loc=0x0, options=0) at ../sysdeps/unix/sysv/linux/waitpid.c:30\n1  0x00007f3eb70be150 in  () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n2  0x00007f3eb65aa100 in  () at /lib/x86_64-linux-gnu/libc.so.6\n3  0x00007f3eb70ddd7b in dt_control_progress_create () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n4  0x00007f3eb70d6bd7 in dt_control_job_add_progress () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n5  0x00007f3eb70dd7eb in dt_film_import1_create () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n6  0x00007f3eb7082250 in dt_film_import () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n7  0x000055e18ba369f4 in main ()\n=========\nId   Target Id                                         Frame \n* 1    Thread 0x7f3eac70ad40 (LWP 21450) \"darktable-cli\" 0x00007f3eb66473ea in __GIwaitpid (pid=21506, statloc=0x0, options=0) at ../sysdeps/unix/sysv/linux/waitpid.c:30\n  2    Thread 0x7f3eac0c0700 (LWP 21461) \"gmain\"         0x00007f3eb66776d9 in GIpoll (fds=0x55e18c0a3a90, nfds=1, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n  3    Thread 0x7f3eab8bf700 (LWP 21462) \"gdbus\"         0x00007f3eb66776d9 in _GI_poll (fds=0x55e18c0dd770, nfds=2, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n  4    Thread 0x7f3e9524e700 (LWP 21504) \"lua thread\"    0x00007f3eb66776d9 in __GI___poll (fds=0x55e18ccd6970, nfds=1, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n  5    Thread 0x7f3e94a4d700 (LWP 21505) \"pool\"          syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38\n=========\nThread 5 (Thread 0x7f3e94a4d700 (LWP 21505)):\n0  0x00007f3eb667d219 in syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38\n1  0x00007f3eb6f2675a in g_cond_wait_until () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n2  0x00007f3eb6eb2061 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007f3eb6f08c12 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n4  0x00007f3eb6f08135 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n5  0x00007f3eb6550164 in start_thread (arg=) at pthread_create.c:486\n    ret = <optimized out>\n    pd = <optimized out>\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {139906758530816, -6702681416690687067, 139906766861838, 139906766861839, 139906766861968, 139906758470080, 6667125718457656229, 6667058533091648421}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n6  0x00007f3eb6683def in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nThread 4 (Thread 0x7f3e9524e700 (LWP 21504)):\n0  0x00007f3eb66776d9 in __GI___poll (fds=0x55e18ccd6970, nfds=1, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n    resultvar = 18446744073709551100\n    sc_cancel_oldtype = 0\n\n1  0x00007f3eb6edfe46 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n2  0x00007f3eb6ee01d2 in g_main_loop_run () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007f3eb719f574 in  () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n4  0x00007f3eb6f08135 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n5  0x00007f3eb6550164 in start_thread (arg=) at pthread_create.c:486\n    ret = <optimized out>\n    pd = <optimized out>\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {139906766923520, -6702681416690687067, 140735212883358, 140735212883359, 140735212883488, 139906766862784, 6667122420459643813, 6667058533091648421}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n6  0x00007f3eb6683def in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nThread 3 (Thread 0x7f3eab8bf700 (LWP 21462)):\n0  0x00007f3eb66776d9 in __GI___poll (fds=0x55e18c0dd770, nfds=2, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n    resultvar = 18446744073709551100\n    sc_cancel_oldtype = 0\n\n1  0x00007f3eb6edfe46 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n2  0x00007f3eb6ee01d2 in g_main_loop_run () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007f3eb604a7b6 in  () at /usr/lib/x86_64-linux-gnu/libgio-2.0.so.0\n4  0x00007f3eb6f08135 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n5  0x00007f3eb6550164 in start_thread (arg=) at pthread_create.c:486\n    ret = <optimized out>\n    pd = <optimized out>\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {139907142776576, -6702681416690687067, 140735212861198, 140735212861199, 140735212861328, 139907142715840, 6667049101609804709, 6667058533091648421}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n6  0x00007f3eb6683def in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nThread 2 (Thread 0x7f3eac0c0700 (LWP 21461)):\n0  0x00007f3eb66776d9 in __GI___poll (fds=0x55e18c0a3a90, nfds=1, timeout=-1) at ../sysdeps/unix/sysv/linux/poll.c:29\n    resultvar = 18446744073709551100\n    sc_cancel_oldtype = 0\n\n1  0x00007f3eb6edfe46 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n2  0x00007f3eb6edff6c in g_main_context_iteration () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n3  0x00007f3eb6edffb1 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n4  0x00007f3eb6f08135 in  () at /usr/lib/x86_64-linux-gnu/libglib-2.0.so.0\n5  0x00007f3eb6550164 in start_thread (arg=) at pthread_create.c:486\n    ret = <optimized out>\n    pd = <optimized out>\n    now = <optimized out>\n    unwind_buf = {cancel_jmp_buf = {{jmp_buf = {139907151169280, -6702681416690687067, 140735212860798, 140735212860799, 140735212860928, 139907151108544, 6667037007518770085, 6667058533091648421}, mask_was_saved = 0}}, priv = {pad = {0x0, 0x0, 0x0, 0x0}, data = {prev = 0x0, cleanup = 0x0, canceltype = 0}}}\n    not_first_call = <optimized out>\n\n6  0x00007f3eb6683def in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\nThread 1 (Thread 0x7f3eac70ad40 (LWP 21450)):\n0  0x00007f3eb66473ea in __GI___waitpid (pid=21506, stat_loc=0x0, options=0) at ../sysdeps/unix/sysv/linux/waitpid.c:30\n    resultvar = 18446744073709551104\n    sc_cancel_oldtype = 0\n\n1  0x00007f3eb70be150 in  () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n2  0x00007f3eb65aa100 in  () at /lib/x86_64-linux-gnu/libc.so.6\n3  0x00007f3eb70ddd7b in dt_control_progress_create () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n4  0x00007f3eb70d6bd7 in dt_control_job_add_progress () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n5  0x00007f3eb70dd7eb in dt_film_import1_create () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n6  0x00007f3eb7082250 in dt_film_import () at /usr/bin/../lib/x86_64-linux-gnu/darktable/libdarktable.so\n7  0x000055e18ba369f4 in main ()\n[Inferior 1 (process 21450) detached]\nbacktrace written to /tmp/darktable_bt_N5YAWZ.txt\nSegmentation fault (core dumped)\n```\n. ",
    "flowernert": "Thanks @turbogit\nI mainly reused already existing icons defining code with a bit of tweaking, but I would appreciate suggestions for them if you or other people have some.\n. left to right\ndisable mask (cross), uniform (linear gradient), drawn mask (pencil), parametric mask (black/white circle), drawn+parametric (pencil+black/white circle), raster mask. Thanks for the feedback.\nI've set up a desktop launcher for my custom darktable so I didn't even noticed the warnings! Good thing you told me, I'll inspect to fix them. \nFor the icons I'm not sure the circle is representative or feels intuitive as a uniform mask, maybe a partial circle (like 300\u00b0) with progressive gradient would be better, kind of figuring an analog blending rotating button.\nFor the pencil and the raster mask it seems to figure pretty good the functionality, for drawn+parametric... Well I think it could be better, I'll try some other things if I feel inspired :-). I found the culprits for the GTK warnings, it should be ok yet.\nI'll do the buttons icons change next.. Ideas prototyping for uniform mask icons\npartial circle gradient (simpler, fits better in \"bauhaus\" style)\n\npartial circle gradient with outwards marker (more clear about functionnality but I like it less)\n\npartial circle gradient with inwards marker (same)\n\n. >     * a partial circle with gradient (and possibly arrow) for parametric\n\n* and from there add the little pencil for drawn+parametic\n\n\nSeems good to me\nI'm still not satisfied for uniform but a circle will probably be ok.\nThe gradient for uniform is here to figure the notion of opacity that is adjusted through the slider, however I agree that the B/W gradient can be misleading with other functionalities.\n. @TurboGit I'm starting to get familiar with how the project is organized, however I haven't been able to localize how the modules store their icons (not in paint.c that I used previously).\nI looked into dither.c and watermark.c (in case it's in the module code) but I saw not use of cairo to draw the main icon, only for buttons used in the modules.\nI looked too in develop/develop.c where the modules are loaded, in darktable.c and imageop.c but no more luck. \nJust in case you already have the knowledge, do you know where the modules main icon are defined ? \nOtherwise... well I'll search more :/. Thanks for the reply, I meant the icons of each modules (circled in red).\n\nI expected to see them drawn in the code through cairo in a dtgtk_cairo_paint_* function, but I realized they are separate png/svg icons loaded from the /$DARKTABLE_DIR/share/darktable/pixmaps/plugins/darkroom/ directory in imageop.c code.. It took me a bit of time to get to the result I wanted using Cairo but that's it, I'm finally done with the icons :) \n\nI did the raster round-shaped as we discussed but I now realize that maybe it makes more sense to have it square.. I'm glad you like and merged it ;) \nI hope other users will enjoy it too !. I thought the same will doing the toggle buttons instead of the combobox @aurelienpierre, however I also though that the section and the verbose tooltip that comes with it may be helpful to novice users.\nI saw a commit today that removed this big unused space at the bottom.\nhttps://github.com/darktable-org/darktable/commit/7c231ad917a0cea15bdd2809cd9d6716b3c07ad0. > Strange, I don't seem to have it. The commit is in git log, but the UI is the same.\nI just fetched and compiled it, indeed the lost space at the bottom is still here.\n\nSince it's a systematic/recurring option available in all the IOPs, I think it's not a problem. People will need to open the manual and look at the tooltip, but it would declutter the UI a bit.\n\nWell, based on my personal preference I would remove it too, I'm not sure of how to balance between the user-friendliness of having the blending label and its tooltip or the user-friendliness of saving space. \nI don't know how this kind of choices are made within the Darktable developers, is there a guideline or something like that for choices that just depends on the targeted users ?. ",
    "heckflosse": "\ni'm now not sure yet how to detect this situation\n\nZ7\nZ6. Well, If my hint got you closer to the solution, that would already be a progress ;-)\nI'm not saying the solution in Rawtherapee is perfect (it's far away from that). @TurboGit \n\nTo me on an i7-4710MQ @ 2.50GHz the new version is slower.\n\nDoes this CPU have one avx2 unit per core or one per hyperthread?\nI ask, because on my AMD FX8350 (8 cores, 8 128bit units, but only 4 256bit units)\nusing AVX on all cores in parallel also is slower than using SSE2 on all cores in parallel because each 256bit unit has to be shared among 2 cores.\nEdit: Maybe you can test adding a simdlen(4) clause to the omp simd statements. That should restrict the vectorization to 128bit vectors for this statements (just for test of course). @TurboGit \n\nMost timing were around 0.35s with current version and with this PR most timing are around 0.4s.\n\nI didn't measure. But I measure very often in RT when I optimize the code.\nIn my experience a reliable measure is the median of 7 measures. Anything below that (median of 5 measures for example) is not reliable in my experience.\nJust my 2 cents...\n. Using '-', '+', '*', '/', '-=' .... works fine with gcc and clang, increases readability and also (at least in my experience) gives sometimes faster code (for example a + b * c can give an fma (if supported) while '_mm_add_ps(a, _mm_mul_ps(b,c)' or vice versa in my tests was translated following exactly the intrinsics.\nThough I have to admit, that the last time I looked at the assembly is a while ago.\nAnyway, in RT I always use the more readable notation and try to avoid intrinsics and never experienced problems, neither with clang, nor with gcc.\nOne exception is the following, which is supported by gcc, but not by clang:\n```\n__m128 a;\nfloat b;\na = a * b;\n```\n. @aurelienpierre May I ask what this is for?\nIs this a trick for clipping small values of square2 to zero?\nSo for example 100000000 + 0.000001 - 100000000 = 0. @aurelienpierre Ok, I just was curious because at least on first sight calculating a = b + c - b does not make much sense. @aurelienpierre It's a bug. You can not subtract the whole vector. Look at the original code where _mm_sub_ss is used which only subtracts from first element of vector. \nEdit: your code does\na[0] = sq[0] + sq2[0] - sq[0];\na[1] = sq[1] + sq2[1] - sq[1];\na[2] = sq[2] + sq2[2] - sq[2];\na[3] = sq[3] + sq2[3] - sq[3];\nwhile the original code does\na[0] = sq[0] + sq2[0] - sq[0];\na[1] = sq[1] + sq2[1];\na[2] = sq[2] + sq2[2];\na[3] = sq[3] + sq2[3];\n. ",
    "waterlubber": "I was able to resolve the issue by changing the noiseprofile.json model name from \"PowerShot SX 170 IS\" to \"Canon PowerShot SX 170 IS.\" However, I still believe that the dropdown should show similar models of cameras or all models of cameras, as it would at least show the feature working. (or an error like \"json file with matching model not found\"). ",
    "kxv": "\nThis has always worked for me with nvidia! Any explanation why this is need on your side?\n\nPlease let me cite R from the linked darktable issue: \n\n\"I have been using the NEO drivers without issue on almost daily builds of master for quite sometime now. I ran into some issues like this before I discovered that you have to regenerate the opencl kernels sometimes after updating the neo drivers. Now, on archlinux, whenever the neo drivers get updated, I rm -rf ~/config/darktable/cached_kernels_for_IntelRGen9HDGraphicsNEO . Have not observed a problem since doing this.\"\n\nThis pull would automate the invalidation. The cached kernels are not supposed to work after a driver update of compute-runtime / NEO (see https://github.com/intel/compute-runtime/issues/125).. Because of these problems, NEO / compute-runtime is on the driver blacklist per https://github.com/darktable-org/darktable/commit/4788b382c8278fab0840866db761c40ef6612dcf right now\nThis also means, one needs to circumvent blacklisting for testing.. I understand.\nIt surprises me, that NVDIA/AMD drivers never caused such an issue before. I can only assume this is caused by compute-runtime being a newer driver and thus being subject to bigger changes.\nMaybe https://github.com/alalek can shed some more light on this.. ",
    "maruncz": "Ok, thanks. Hi i just found this PR and i just want to say that on basic screens like fullHD 24\" is current UI size ok and making bigger spaces will just stretch everything, making it less convenient because sometimes single module wont fit on screen and i would have to scroll back and forth\n\nand i presonaly like old font more\nand i would welcome redesigning those pop up dialogs like settings import picures and delete file dialog, they look ugly and when resizing they move over screen wierdly. > what if we move the exposure settings at the beginning of the EXIF widget ? Even small, this text makes the waveform histogram practically impossible to read in many cases.\nthis is IMO good idea and i would also move datetime, because when i shoot panorama i use datetime to find where panorama starts and ends (photos shot almost  consecutively) and as others said history stack and duplicate manager pushes those down\nas far as histogram exposure change, i almost never open exposure module beause it's faster for me to just hover mouse over histogram and roll mouse wheel. Step granuality is ok for me.. ",
    "bapBardas": "\nIncoming ! See #2037\n\nThanks for this commit Aur\u00e9lien, and for the improvement you bring to the product !. ",
    "Dpiximaj": "Font is still very thin and difficult to read even after increase in font size. version 2.60 &  2.61 Windows version.\n\n. Yep that was it! Never knew, Thanks.. ",
    "timur-davletshin": "Looks promising, but defining fonts like Roboto in CSS is not a good idea. Using generic name like Sans is fine. It can be redefined via fontconfig. I haven't seen this PR, but can you also fix text background in metainfo? E.g. select filename - text background remains the same, text color barely changed..  > there is no fontconfig on Windows and Mac OS. What would be the best option then ?\nIf font-family definition is removed at all (just font-size left), default desktop font will be substituted (which is the best IMO). At least in Gnome and KDE. I know very little about font substitution in GTK+ application running in non-native environments like Windows or Macos but failsafe fonts can be specified too.\n\nyes, it's planned. Every active area (buttons, menus, text areas) will be emphasized.\n\nGod bless you, man!\n. > On Linux Gnome, the default \"Sans\" font is quite ugly and doesn't use the system-defined preference.\nlocal.zip\nAdjust it to your taste and copy to $XDG_CONFIG_HOME/fontconfig/fonts.conf or /etc/fonts/local.conf Roboto is not everybody's font of choice.. Have you tried option number 1 and rely on default GUI font? It does work in Linux (both Gnome and KDE) and Macos.\n\nIf font-family definition is removed at all (just font-size left), default desktop font will be substituted (which is the best IMO). \n. > That's the current state of the code. dt takes the default GUI font already. But I would rather have it managed internally with \"clean\" default than rely on whatever 1990's font is set in fontconfig.\n\nI thought you said Macos and Windows is the issue here. But they use their own font settings/substitution systems. GTK+ settings relies on fonts specified via gsettings/dconf and fontconfig is not used unless you specify some generic font name.\nBTW, Duckduckgo offers in its' settings similar approach. You can choose font of your choice for UI. Probably it's not the worst idea ))) \n. > ... so what GTK uses as a default is kind of a black box...\nQuite radical statement :) I believe Cantarell is the one you refer to?\n\n... my point was: configuring fontconfig through an XML file doesn't make it easier for the regular user than changing the font name in the CSS stylesheet.\n\nEditing CSS is not easier. I made my choice (font, language) via GUI (forget about fontconfig) and I prefer applications to respect it. OK, dt (just like blender) has lots of controls and therefore needs smaller font size. OK, make it. And don't forget about localization. The World is bigger than LGC, e.g. what Japanese or Chinese users should do? Why treating them like special needs users?. > font: 10.5pt \"Roboto Light\", \"Oxygen\", \"Ubuntu\", \"Cantarell\", \"Fira Sans\", \"Droid Sans\", \"Helvetica Neue\", sans-serif;\nHelvetica Neue? \ud83d\ude31 Why discriminating Windows users then, add whatever they use these days (Segoe UI?) too \ud83d\ude03\nBTW, is it San Francisco font what they use now in Macos, not Helvetica?.  > Fixed, I have added San Francisco and Segoe UI. What do you have against Helvetica now ? :-P\nJust like you I have high expectations from font, and those you perceive as OK may seem not so OK for others. Even Helvetica, a well developed stable font, having troubles with kerning in Cyrillic script. Why? Probably because Cyrillic script was not supported in original font and it was added much later by someone else. Situation is even worse if I use it for Tatar language with odd shaped letters like \u0497, \u04a3, \u04e9, \u04bb, \u04d9 or optional stress marks. BTW, this is exactly the reason why Russian government paid development of PT Sans/Serif fonts. Bulgarian and Serbian written traditions are different from Russian hence letter forms differ a bit even if they have same origin.\nKerning in Latin/Cyrillic. Top line is in Cyrillic, bottom is in Latin, they have same shape but those in Latin are kerned differently. Some Cyrillic letters are not kerned at all.\n\n. I see you still insist on fonts of your preference. Let me criticize it a bit :)\n\nSan Francisco fonts, the one coming from https://developer.apple.com/fonts/ is distributed under the name \"SF Pro Display\" or \"SF Pro Text\" not \"San Francisco\".\nOxygen font right on the second position after beloved Roboto? It is not even multilingual.\nDroid fonts depreciated by Noto family. Droid is no longer available in many distributions (probably just Droid failsafe). Noto is based on Droid glyph shapes but with a bit different x-height.\nProbably giving priority to free fonts is the best practice in OSS.. > This what we have now :\n\nI've always wondered why there is extra space right before lens name in some languages... notice how Nikon AF-S is not aligned with the line above. Or \"Creative Commons...\" below.\nBut generally it looks really good!. > There is half a space in some languages, which becomes a full space in others. I'm not sure, this part of the code only extracts the EXIF and such, it's not supposed to add anything. Thanks @timur-davletshin\nNever knew that Greek or Russian typographic traditions used half spaces this way. Can they be stripped off somehow?\n. ",
    "dcendal": "Just a quick comment from my side.\nIn Darkroom, if I click on Quick access to presets and then choose any option of the menu, the submenu background is not visible. Here is a snapshot.\n\nPS: I like so much the new look and fits perfectly in my small 15\" monitor. Thanks\n. I'm using also the master (last commit af997cb8e942ba89e238e62c35c88b2711af7223).\nI delete the database, the current version of the database is 18 (select value from db_info)\nNow when the option \"multiple instances action\" is activated, the only option enabled is \"rename\", the rest of the options are disabled.\nIf I click on the option \"rename\", the situation is very similar to the described before.\ndarktable_bt_6V4HYZ.txt\nI install a new version on 2.6.1 in a new database, everything works OK. Then upgrade to the last master version. Where the UI ask to upgrade to the new database version, click OK. I got the same error as described.\nPlease, let me know if there is some additional test that I could do.\n. ",
    "mimoklepes": "Personally I like using the scrollweel over the histogram to set both the exposure and black point and it's one of my most-used features. Instead of removing it it would be great to improve it:\n1) Feedback, i.e. show the current value of exposure and black level compensation while scrolling or dragging. You can see this information in real-time now if you have the exposure module open, but it defeats the purpose.\n2) Modifiers - if normal scrolling is in 0.15EV steps, holding Shift while scrolling could switch to e.g. 0.05EV steps.\n. I don't have extremely strong feelings about this and for sure I will adapt my workflow if scrolling on histogram stops working, no biggie. That being said, I expect some surprised bugreports to appear when it's gone. I do greatly appreciate the work you're putting into darktable, but please be careful not to descend into the \"users are stupid and devs know better\" mode of thinking (your words :-)). Someone has put effort into implementing this feature, it works, it's liked by many, so removing it because one of the devs does not like it or need it may not be the wisest decision. Thanks for considering this. \nAs for the EXIF info - please leave the basic data clearly visible somewhere (doesn't have to be in the histogram), without having to scroll down to image information. I often quickly check the basic info (mainly ISO when working with noise). I'd like to see also the lens, so configurable fields would be great. But it's really minor. \nAnd hey, what exactly can I do with the vim commands? :)\n. For me personally, capitalized labels and text (basically like in any other software) would be much more readable. All lowercase, especially with combination with the right-justification of the module names really hurts my brain when quickly trying to find the correct module in the list. The eyes need to constantly jump left and right with nothing to anchor on. \nAll lowercase is a cool stylish choice for the name of the software and let's say the \"lighttable | darkroom | other\" tabs on the top-right. But having all text completely lowercase just gives the impression of trying too hard to look like a hacker-tool and in my opinion it impairs the usability. \n. ",
    "mrpanderson": "I would love to see a hide function added to the histogram.  See Lightroom for an example.  Clicking a triangle expands/collapses it.  There are many situations where I don't need to see it, and would much prefer to use this screen real estate for more vertical height on the modules.. Awesome, thanks!. ",
    "matze": "Drive-by comment: you will get much worse problems (and a few headaches) than the current performance issues. GTK+ is inherently single-threaded with its main loop and not thread-safe at all (just read the description in that link).. The current approach would be to prepare anything required for display asynchronously in a separate thread through the GTask API and display only when the result is ready. Here is a very old presentation (probably from the time this API was designed) that shows the basic workflow. I am not too familiar with the DT codebase so I have no clue how easy or difficult it would be to move to an asynchronous model though \u2026. \"A simple X\" is subjective taste.. ",
    "qosch": "About the preview inconsistencies I agree, I guess there is no real solution to it. Concerning the UI I had a table like this in a separate tab in the settings in mind:\n|                       | always | in 100% view | when module is expanded |\n|-----------------------|--------|--------------|-------------------------|\n| profiled denoise      |        | x            | x                       |\n| chromatic abberations |        | x            | x                       |\n| base curve            | x      |              |                         |\n| equaliser             | x      |              |                         |\n| ...                   |        |              |                         |. Okay, thanks for considering it anyway.\n(And to you personally: Thanks for your great work on filmic, I entirely replaced the bascurve with it in my workflow. The basecurve was the module that always gave me headaches with the weird blue tones that came out of it, as someone discussed in this thread: https://discuss.pixls.us/t/out-of-the-box-raw-rendering-not-up-to-jpegs/6669). ",
    "s7habo": "Ok. Thanks for feedback @aurelienpierre \nWould perhaps be possible a simplified version of the proposal above? To generate a parametric mask from only one selection area? \nIf you take the area for the color picker instead of the point, you get the limited (inclusion) radius of values for each channel on the sliders. \nFor example, for this area (red berry in the upper picture)...\n\n... the range looks like this:\nL channel:\n\na channel:\n\nb channel:\n\nNow, you need to manually move markers to that indicators to get your parametric mask.\nProposal:\n\n\nSelect a specific area using color picker (area)\n\n\nThe upper and lower triangular markers are automatically placed exactly on the edge of the indexed area for each channel:\n\n\n\nTo expand the area of the mask, press Shift + scroll mouse wheel to move all triangular markers outwards:\n\n\n\nOr, to expand only the edge of the mask, press Ctrl + scroll mouse wheel to move the lower triangular markers outwards:\n\n\n\nAll channels should be simultaneously affected by changes. \n\nIf you are not satisfied with your mask afterwards, move the triangular markers manually to the desired result.\n\n. @aurelienpierre \n\nI guess that falls back into U-points\n\nBTW, I remember you asking for the math behind that. I found something that might be of interest:\nhttp://chiakailiang.org/touchtone/\nThe paper from the site:\nhttp://chiakailiang.org/touchtone/touchtone.pdf. ",
    "vinzPRO73": "oh !   One more thing .... (thank you steve ) \ni would like to tell that i am using a (pretty f.....ing expensive) macbook pro \nrunning intel iris GPU .. \nsee you  ! \n. Hello Thanks a lot for your reply .. \nhere is what i have got , when running ... darktable --disable-opencl in a terminal. \n./darktable --disable-opencl\n(process:3867): GLib-GObject-CRITICAL **: 10:37:27.285: g_object_set: assertion 'G_IS_OBJECT (object)' failed\n(darktable-bin:3867): GLib-GObject-WARNING **: 10:37:27.509: invalid cast from 'GtkMenuBar' to 'GtkWindow'\n(darktable-bin:3867): Gtk-CRITICAL **: 10:37:27.509: gtk_window_add_accel_group: assertion 'GTK_IS_WINDOW (window)' failed\ndarktable-bin(3867,0x70000d125000) malloc:  error for object 0x7fb73971b398: incorrect checksum for freed object - object was probably modified after being freed.\n set a breakpoint in malloc_error_break to debug\n[1]    3867 abort      ./darktable --disable-opencl\ni will keep searching for ideas and options ..\nbecause i am very motivated in using this software .. \nbest regards \nVinz. any idea about what a \"freed object\" is ? \nproblem might come from this :\nmalloc: *** error for object 0x7f806a58d3f8: incorrect checksum for freed object - object was probably modified after being freed.. Ok big progress ! \ni think that when starting Darktable, it tries to load images from a default folder library  !! \nthere was a bug among one of those files (jpg format) due to the app first crash. \ni have moved images form this \" Starting folder\"  ... \nbut still launched darktable with openCl disabled ... \nand TADA ... now it runs .. \nyou may close this issue ... \nAgain thanks for your help .. \nyou are doing amazing job .. \nVinz  . ",
    "brigazvi": "@TurboGit  We need to update the links in the website.. In RT its more simple and easy and the result more natural.in DT the result  seems a little bit flat.. @aurelienpierre This direction is welcome, but it complicates things further.\nWhat needs to end up is a module called shadows and highlighs recovery that includes two bars: shadows, and highlights. It just needs to work well in terms of colors and a more natural look in relation to the current module.. @aurelienpierre I am very happy that you are working on a solution. I do not really understand the technological significance of things, I just know how it works in Lightroom and CaptureOne. There are not too many choices and yet it works amazing. Simple and amazing.\nAt the end of the day most users use several basic modules and we need to make sure they are the best possible.. @aurelienpierre I think people prefer simple modules because that's how they manage to get better results. Complex tools make them get lost.\nWhen a photographer wants to achieve a higher dynamic range than his camera allows, the only way is to shoot raw and work on it in an image processing software.\nI do not rule out the option of a simple default tool, with a hidden menu of optional professional options.. @aurelienpierre\n1. I feel the need to apologize if I sound too critical. I'm not a developer and I'm just trying to express my opinion. I greatly appreciate your work for Darktable.\n2. How much do you suggest differs from the zone system module?\n3. I am aware that it is not always possible to arrive at a simple solution. But I find it hard to believe that such large companies in the industry that millions of professional photographers use their software offer such a poor solution. I tend to believe that their solution (which is also very impressive) is pretty good.\n4. Who knows, I have not seen your solution yet, maybe it's much better than I imagine?. @aurelienpierre\nI still think it is important and worthwhile for things to be simple. I do not believe in educating the user. Still, it seems your idea is not so bad. The screenshots seem like a pretty simple tool. I hope it will really work well and replace the current module as default. Thank you very much for this amazing work. How much longer will it reach users?. @aurelienpierre\nI would recommend changing the name of the module to new shadows and highlights module. Only for the purpose of stating intentions. This should replace the existing module. It may also be useful in the interface of the module to give up EV values \u200b\u200band leave only the simple language of shadows and highlights. what are you saying?. Many developers thinking that many modules is better.  But sometimes it's just confusing. If the new module is better,  I think the old one need to go home. . @aurelienpierre\nThanks for your answers.\nI did not really understand whether the bottom line is that you are offering an alternative to the existing module. The simple user, when he wants to recover shadows, will go to Shadows and highlights. In practice, Darkroom has a lot of modules that can recover shadows, the question is which one does it best, and which one we, the developers, recommend and say is the shadow recovery tool.. @aurelienpierre \nI'm not really able to fully understand your technical explanations. I agree with you that we appeal to professional photographers. A good tool is a tool that brings better results. That was what I meant.\n\nfor me, the best module is the one allowing luminance editing without affecting the color hue and saturation at all.\n\nThe least I know technically is that saturated red that becomes dark, in our case because of lack of exposure, loses its saturation. Dark red will always be less saturated than normal red. So I do not know if a change of luminance alone will give us the original color of the picture.\nI'm wrong?\nThe examples cited in pixls do not show the function of the module in slightly more extreme situations.\nAnd again, thanks for your attention and investment in Darktable.. ",
    "Sturmflut": "If I didn't do anything wrong (this is my first take at translations for darktable), there where still lots of fuzzy/untranslated strings after commit e9b4ecc4831081d8cfd7f03fc93951c0d7304cec:\n$ intltool-update de\n........................................................................................................................................................................................................................................................................................................................................................ done.\n2473 translated messages, 59 fuzzy translations, 65 untranslated messages.\nThis pull request should fix most of them.\n. Looks like this pull request messes up some of the improved translations in commit  e9b4ecc4831081d8cfd7f03fc93951c0d7304cec. I'll close this pull request and try to merge both versions.. It was an unfortunate coincidence. I'm already half-through with the merge and will submit a new pull request soon.. ",
    "EdgarLux": "Of course.. I really appreciate that you made these observations. I will review them. It seems that there was a parallel correction and there are others that I will keep checking. @agusmba . Thank you! It was corrected.. Thank you! It was added.. It's a typo. Thanks!. It's a typo. Thanks!. Yes, indeed.. ",
    "mihkel-t": "Another option would be to just add an English pseudo-translation that makes use of capitals at the beginning of labels, sentences, etc. For instance \"en_AQ\" where the AQ stands for Antarctica :) (so it wouldn't be chosen by default in any \"normal\" locale).. Changed both. Btw is there a reason behind \"select as destination\" instead of \"move here\" and \"copy here\"?. Changed.. Come to think of it, I have probably chosen to add context to the wrong instance of \"both\" here - this one is quite fine as it is without any context at all, as the meaning is rather basic here, as opposed to the other instances of \"both\" where it actually means 'in both directions'. What do you think, would context like \"flip/rotation direction\" be OK for the other instances?. I only added context to these so as to avoid having the same string for the \"filmic\" module name and the tonemap operator of the same name - but again, come to think of it, might be better to add \"modulename\" context to the other \"filmic\" instead :). OK, done.. In a way you're right, of course, however the same \"color\" context would apply elsewhere as well, while \"select by\" wouldn't. The preceding label (\"select by\") was the reason for me wanting these here split, so I could translate \"hue\", etc. here to go nicely with \"select by\". (Other inflectional languages might appreciate having this option, too.). Won't that be misleading?. Neither RAW, LDR nor HDR is really a file format, as opposed to e.g. JPG or PDF. This is one example where English easily gets by using a rather broad term (\"format\"), but other languages might need to specify whether it is a \"file format\" (like JPG) or something to in the vein of \"image type\" (like HDR).. ",
    "schwerdf": "The xmpMM:derivedFrom attributes seem to be getting properly updated in commit 850e5a4, after I added the line to dt_image_rename() to trigger sidecar updates. Is there something else that needs to be done for that?. Yes, this only modifies the C and Lua APIs, not the Darktable GUI.\nAs to implementing this functionality in the GUI, I would be willing to take on the task, but it would require many more design decisions than this change, since batch renaming is a deal more complex than batch copying or batch moving.. I merged the most recent changes to eliminate the conflicts, and opened an issue (#2247) for discussion on the GUI question.. I took out the conditionals around the g_free calls, but I could not reproduce any instance of an image being moved in the database when its file did not exist on disk.\nMy understanding was that it is practically a necessity for the move function to fail silently in that case (as it currently does, only printing a line to the console) due to the way it handles moving multiple versions of an image.. ",
    "snipem": "Touchscreen and touchpad gestures are handled the same way with GTK 4.0?. ",
    "pixmin": "Adding scaled JPG for preview of the problem\n\n. Just to confirm, after installing Ubuntu with Darktable 2.6.1, I can confirm that exporting the same photo works just fine.\nI have tried to disable all modules but there is always a large portion of the photo that is only black (that black part isn't always the same). ",
    "gigatt5": "Thanks for the reply!\nI'm using Windows 7 64 bit, with\nSapphire Radeon R7 240 2GB DDR3 HDMI/DVI-D/VGA Graphics Card, and Intel Core 2 Quad Q9650 3 GHz 12 MB Cache Quad-Core CPU Processor.\nThank you!\nGet Outlook for iOShttps://aka.ms/o0ukef\n\nFrom: Aur\u00e9lien PIERRE notifications@github.com\nSent: Friday, February 22, 2019 10:28 PM\nTo: darktable-org/darktable\nCc: gigatt5; Author\nSubject: Re: [darktable-org/darktable] Exported jpeg is darker (#2126)\nWindows ? OpenCL ?\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHubhttps://github.com/darktable-org/darktable/issues/2126#issuecomment-466621956, or mute the threadhttps://github.com/notifications/unsubscribe-auth/AtsAtj0Vvo2D76CvQtKDog5DL3325cP9ks5vQN-PgaJpZM4bNjLa.\n. ",
    "tomaszg7": "I have a similar problem and I often have to alt-tab to image viewer to check if the file was already exported. It would be nice to have some UI indicator showing that (both in lighttable and darkroom mode). Another thing would be to just add \"unexported only\" to the collection filter.. As far as I know it is against master branch. I just didn't choose the most fortunate name for the branch in my repo ;). ",
    "JohnBeeR1": "I have also not had any problems running under 29 until this week, but I also can't see from the backtrace where the problem lies.\nI'm running the fedora package which is 2.6.0-2.  I've removed it and reinstalled.  I've tried running with the older Gnome boot that I was running last week, but still a problem.  It has to be a problem with another package that updated at the weekend, but no idea which one.. Sorry accidental close!. ",
    "Ablinne": "I did some digging into the code and it seems whether the \"edited\" icon is drawn or not is determined by https://github.com/darktable-org/darktable/blob/fbd48cd4c22c8384152c20a8957527d936f3ad13/src/common/image.c#L751 called here: https://github.com/darktable-org/darktable/blob/e0f9222eb5fa18d47ad3de507a5689e06754f81d/src/views/view.c#L1519 It looks at the list of activated modules and when anything other than basecurve, flip, sharpen, dither or highlights is activated, the image is considered \"altered\". Unfortunately the \"collecting images\" funcionality only checks whether any modules are enabled at all. This is clearly somewhat inconsistent.\nI think a proper method would be to store an additional flag for every image, whether it is altered or not. It is initilized \"false\" and left \"false\" when the initial set of modules is applied. Only when the history is changed by the user manually it is set to \"true\". This flag could be simply checked in both places to achieve a consistent behaviour.\nAny thoughts? I might just try to add that feature and post a PR if there is a chance it can get merged ;). I have found that there is not only the \"altered\" flag which does this, but the \"changed\" tag behaves mostly in the same way (apart from it being unset on exporting, which is also useful). There is actually a TODO note within the code, to make sure \"changed\" is only added, when the image is actually changed:\nhttps://github.com/darktable-org/darktable/blob/f920e14c4699e378685220d00e4cca3e5d8c8867/src/views/darkroom.c#L1944-L1947. > Copying some history does not count as changed (as in this file has been handled, edited so developed).\nBut doesn't this depend on the use case? I often have a series of pictures, that I want to develop using the exact same settings. I edit one of them in the darkroom and copy the history to the remaining pictures. To me, all of the pictures are  then developed. I want to use the \"changed\" tag to quickly select all pictures that I need to export and in this case I also want those images selected that I have copied the history to. Setting the tag manually after copying the history to the remaining images is something that could easily be forgotten.\nIs there maybe another tag that should be used for this purpose? Should I instead introduce a completely new tag?. In my case it's most of the times pictures that are going to be stitched to a panorama. The panorama will be cropped after stitching, so no need to crop/rotate the pictures before.\nHowever, if copied history does not account for darktable|changed, I will remove the call in dt_history_copy_and_paste_on_image().\nI will just have to remember to set the tag manually in this case or export the pictures immediately.\nIs the rest of the changes allright?. Ok, that seems reasonable. I have reverted my latest commit to reinstate my first proposal. Thanks for looking into this. . ",
    "lyonzy": "Another similar concept to my point (2) above is a Vectorscope:\n\nOnly they seem to be mostly read-only.. ",
    "elstoc": "I've managed to get the message to stop appearing by manually setting my display profile in the lighttable settings to use a custom icc profile. When I set it back to 'system display profile' (which is how it started after the upgrade) I can't get the popup to reappear. . Same issue on darktable 2.6.0. Sorry. All a little weird. Seems to have stopped happening!!. And back again. Sorry guys. Thought it was fixed. Worked ok for an image for a while. Issue reappeared now but can be worked around by navigating between images while in the darkroom, which seems to force the display to update with the revised haze removal settings. Just have to make haze removal the last thing I do for now.. ",
    "hpmickey": "\nSince you are building from source, can you try by reverting:\na9ce955  ?\n\nBingo!\nTried the src/common/colorspaces.c line 1105:\n          g_strlcpy(prof->filename, filename, sizeof(prof->filename));\nto rewrite back to:\n          g_strlcpy(prof->filename, d_name, sizeof(prof->filename));\nAnd DT works fine again after rebuild.\nMany thanks for the fast advice!\nSidenote: I also checked that sizeof(prof->filename)=512, because a buffer overflow was the first idea coming to my mind when I briefly looked at the code. However, not in this case - as my longest icc filename is 63 chars long. I attached the complete list, printf-ed just after the line 1105:\nICC-list.txt\nIf you would appreciate some more debugging output, feel free to let me know. Otherwise, thank you again, good job.\n. Hello, the patched src/common/colorspaces.c fails during compilation:\n[ 25%] Building C object src/CMakeFiles/lib_darktable.dir/common/colorspaces.c.o\n/home/m/build/dtbuild-2.6.1/src/common/colorspaces.c: In function \u2018_get_profile\u2019:\n/home/m/build/dtbuild-2.6.1/src/common/colorspaces.c:1518:82: error: expected \u2018:\u2019 before \u2018)\u2019 token\n                             || is_base_name ? strstr(p->filename, filename)!=NULL) ! !strcmp(p->filename, filename)))\n                                                                                  ^\ngmake[2]: *** [src/CMakeFiles/lib_darktable.dir/build.make:207: src/CMakeFiles/lib_darktable.dir/common/colorspaces.c.o] Error 1\ngmake[1]: *** [CMakeFiles/Makefile2:913: src/CMakeFiles/lib_darktable.dir/all] Error 2\ngmake: *** [Makefile:152: all] Error 2\n[m@localhost dtbuild-2.6.1]$\nI thought you had something like this in mind:\n(p->type == type && (type != DT_COLORSPACE_FILE\n                            || is_base_name ? strstr(p->filename, filename)!=NULL:!strcmp(p->filename, filename))))\nthere was some extra exclam. mark instead of colon, in the conditional expression, plus one bracket missing at the end of condition.\nFixed with this, plus with some debugging output added into the iteration loop, I can say that the _get_profile function now finds and returns correct dt_colorspaces_color_profile_t pointer. But still, there is a wrong profile \"standard color matrix\" selected in the input color profile module - see the attachment:\n\nI guess you need to have similar matching condition also at the place you set the color profile list selection. Unfortunately, I was not able to find, where it is.. > No need to change in other places\nWrong! As shown in the attachment to my previous post, SonyA7.icc was matched in the _get_profile function, but the input color profile module has the \"standard color matrix\" selected instead. Should be \"SonyA7\".\n\nas this was exactly what was done in a9ce955.\n\nNot exactly. This only loads full paths but does not set selection. Also, this already is a part of 2.6.1, and I used the a9ce955 code (did revert to current 2.6.1) prior to patch, as you requested.\n\nSo new edits are handed by the strcmp() and old edits with strstr().\n\nThis is definitely true (at least I believe that I confirmed it in my previous post), but somehow, this does not propagate into the correct selection in the input profiles module yet. I guess the _get_profile  was called several times, and I was lulled by the last printed match, or something alike...\nI am sorry, if my previous explanation was not sufficient enough, but the suggested fix still does not work. Could you perhaps reopen the bug (as I do not have rights to do it, probably) ?\nIn the meanwhile, I will try to look more into it.. Perfect, thank you.\nI think I've got it. When I shortened my debug output in the _get_profile function, I obtained:\n[m@localhost dtbuild-2.6.1]$ /usr/share/applications/darktable-ocl.sh\n---- matched: SonyA7.icc\n[colorin] could not find requested profile 'SonyA7.icc'!\n---- matched: SonyA7.icc\n[colorin] could not find requested profile 'SonyA7.icc'!\n---- matched: SonyA7.icc\nThe first match appears when opening DT (the Lighttable). The second two matches appear after the thumbnail doubleclick (going to the Darkroom). Note well, the [colorin] output is before each!\nThe [colorin] could not find requested profile output leads us to the src/iop/colorin.c into the void gui_update(struct dt_iop_module_t *self) function.\nThe same is_base_name ? strstr(p->filename, filename)!=NULL : !strcmp(p->filename, filename) trick or something alike should be used there, I believe.\nAt least, when I tried to replace the src/iop/colorin.c line 1606:\npp->type == p->type && (pp->type != DT_COLORSPACE_FILE || !strcmp(pp->filename, p->filename)))\nby\npp->type == p->type && (pp->type != DT_COLORSPACE_FILE || strstr(pp->filename, p->filename)!=NULL)), I have got the correct \"SonyA7\" profile selection in the input color profile module.\nConclusions:\n\nthe void gui_update(struct dt_iop_module_t *self) function is the place I was looking for. The profile list current selection is set there, hence the profile matching condition needs to be fixed there as well\nother places where the the match condition needs to be fixed (e.g. the colorout.c comes to mind) should be found and checked yet\nI think that strcmp does not need to be used anymore in the condition, because either strstr(\"/fullpath/profilename\", \"/fullpath/profilename\"), or strstr(\"/fullpath/profilename\", \"profilename\") cover both the new and old edits. I suggest to write a short compare_profile_names function to keep the profile matching condition at one place\nI should dust my gdb skills off, as debugging by printf is a nightmare ;)\n\nPlease, have a look at it, I think that we are on the right track now.. Did some debugging, and damn, you were right - almost ;)\nIt is enough to adapt the _get_profile, only you need to compare base names always. Pure strcmp (p->filename, filename), is not sufficient as the [p->filename, filename]!= [filename, p->filename].\nAs I am tather a svn guy, I did:\nsvn checkout https://github.com/darktable-org/darktable.git/tags/release-2.6.1,\nthen fixed what I thought was necessary, and here is my hpmickey-dt2.6.1-0002-chosing-the-color-profile.patch.txt to the DT2.6.1.\nI think this should work, but please, review it and doublecheck before you commit.\n. > I was not almost correct but fully correct :)\nI would really like to believe this, however your patch left me with wrong profile selected ;)\nOk, I will give your patch yet another try, before you close the issue.. First, sorry for a long post, please try to chew it ;)\nWell, just tried:\n- svn checkout https://github.com/darktable-org/darktable.git/tags/release-2.6.1\n- added src/external/rawspeed\n- changed DONT_USE_INTERNAL_LUA to OFF\n- applied your \n\n0001-Add-backward-compatibility-when-looking-for-a-profil.patch.txt\n- modified condition (as above - 3 days ago) just to be compilable\n- built with ./build.sh --build-type Release -j8 --install --sudo\n- run with /usr/share/applications/darktable-ocl.sh\n- doubleclicked thumbnail in the lightable, and got:\n[m@localhost dt-2.6.1-repo]$ /usr/share/applications/darktable-ocl.sh\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\nand wrong \"standard color matrix\" selected, in the module\n\nThen I:\n- reverted changes in colorspaces.c\n- applied my\n\nhpmickey-dt2.6.1-0002-chosing-the-color-profile.patch.txt\n- removed the build subdir\n- built with ./build.sh --build-type Release -j8 --install --sudo\n- run with /usr/share/applications/darktable-ocl.sh\n- doubleclicked thumbnail in the lightable, and guess what (!!!) :\n[m@localhost dt-2.6.1-repo]$ /usr/share/applications/darktable-ocl.sh\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\nand wrong \"standard color matrix\" selected, in the module again!\n\nHaving no better idea, I then tried:\n- removed the build subdir\n- built with ./build.sh --build-type RelWithDebInfo -j8 --install --sudo (because I thought that the debug info could somehow impact the processing)\n- run with /usr/share/applications/darktable-ocl.sh\n- doubleclicked thumbnail in the lightable, and the same like before:\n[m@localhost dt-2.6.1-repo]$ /usr/share/applications/darktable-ocl.sh\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\n[colorin] could not find requested profile 'Sony ILCE-7 Standard.icc'!\nand wrong \"standard color matrix\" selected\nAlso tried run DT directly with /opt/darktable/bin/darktable, so no LD_LIBRARY_PATH=/opt/amdgpu/lib64 exported - it did not help either. Then run DT in gdb - still wrong profile.\nAt this point I`d say that both our patches are awesome but do not solve anything :(\nThen I tried what I already described in some previous post:\n\nreplace the src/iop/colorin.c line 1606:\npp->type == p->type && (pp->type != DT_COLORSPACE_FILE || !strcmp(pp->filename, p->filename)))\nby\npp->type == p->type && (pp->type != DT_COLORSPACE_FILE || strstr(pp->filename, p->filename)!=NULL))\n\nDT suddenly behaves well, and the correct profile is selected.\nHaving written all this, I believe that I probably built DT some wrong way yesterday, and always used the modified colorin.c (which would explain why it worked).\nNote well, I used strstr(pp->filename, p->filename)!=NULL in colorin.c only due to my laziness. Correct fix need to use either your is_base_name + strstr, or my _base_profile_name + strcmp solution in colorin.c (and wherever else the profiles are compared).. Ok, I will do it tomorrow evening if you do not mind. Our dog is desperately watching the door, legs crossed. I must take him out, finally.. Just a short update:\n```\n[m@localhost dt-2.6.1-repo]$ svn info\nPath: .\nWorking Copy Root Path: /home/m/build/dt-2.6.1-repo\nURL: https://github.com/darktable-org/darktable.git/tags/release-2.6.1\nRelative URL: ^/tags/release-2.6.1\nRepository Root: https://github.com/darktable-org/darktable.git\nRepository UUID: 10fb27dc-61c8-7ba4-0501-ce57b7db7bff\nRevision: 26934\nNode Kind: directory\nSchedule: normal\nLast Changed Author: pascal.obry\nLast Changed Rev: 26921\nLast Changed Date: 2019-03-05 14:04:40 +0100 (Tue, 05 Mar 2019)\n[m@localhost dt-2.6.1-repo]$ svn log\nr26921 | pascal.obry | 2019-03-05 14:04:40 +0100 (Tue, 05 Mar 2019) | 2 lines\nrelease-notes: second pass for 2.6.1\n\n[m@localhost dt-2.6.1-repo]$ svn update\nUpdating '.':\nAt revision 26934.\n[m@localhost dt-2.6.1-repo]$ \n```\nSo nothing has changed in 2.6.1 tag since 2019-03-05 14:04:40\nAnd now I really must go :). Oh well, I was using the tag 2.6.1 in belief that it is identical to darktable-2.6.1.tar.xz. Then, for a while, I was a bit misled by your:\n\nmy patch is already on 2.6.1\n\nNow I see that it isn't, but it is on 2.6.x. So I switched to 2.6.x (btw, obtained src/common/colorspaces.c identical to 2.6.1 with your patch applied manually). And, as expected, it does not work. When I open a photo, it has an incorrect profile \"standard color matrix\" selected in the module, even though the _get_profile matches profile successfully. Please, see \nDT-r26835-sessinon.001.log. In adition to the requested [colorspaces] output, I added yet another [colorin] outputs which, I hope, bring your attention to the gui_update function in src/iop/colorin.c. That's the place (imo) where the profile should get selected in the input profile when the photo opens. And where should be (again imo) similar matching condition like in _get_profile.\nI was trying all this in hurry, after a busy day, so I rather attach full patch of my changes against 2.6.x\nhpmickey-dt2.6.x-0003-colorspaces-colorin-debuglog.patch.txt - just to avoid further confusions.\nHope this helps. If not, I will try to find some simple way to reproduce, as you asked. Or, could it be even easier, if you drop me your patch with debugging output that would suit you better?\n. Excellent, thank you. Your patch applied to freshly pulled darktable-2.6.x works for me.\nHowever, it might fail for others. If you still have a taste to discuss it, let's have a hypothetical list of profiles:\n[m@localhost tmp]$ ls -1\nAmbient-SonyA7.icc\nSonyA7.icc\nSonyA7-Landscape.icc\nNow, let's suppose that the SonyA7.icc was selected in the old DT version. Your solution will detect is_base_name, and strstr then returns a false positive either on Ambient-SonyA7.icc or on SonyA7-Landscape.icc, depending on the profile iteration direction. The solution is, in the case of is_base_name, you need to compare two basenames, like:\nis_base_name ? !strcmp(basename(fullname), filename) : !strcmp(fullname, filename);\nHere you have your dt_colorspaces_is_profile_equal function slightly rewritten:\n```\ngboolean dt_colorspaces_is_base_name(const char profile)\n{\n  char f = (char )profile;\n  while(f)\n  {\n    if(f == '/' || f == '\\') return FALSE;\n    f++;\n  }\n  return TRUE;\n}\nconst char dt_colorspaces_get_base_name(const char profile)\n{\n  const char f = profile + strlen(profile);\n  for (; f > profile; f--)\n  {\n    if(f == '/' || *f == '\\')\n      return ++f;   // path separator found - return the filename only, without the leading separator \n  }\n  return f;         // no separator found - consider profile_name to be a \"base\" one\n}\ngboolean dt_colorspaces_is_profile_equal(const char fullname, const char filename)\n{\n  // for backward compatibility we need to also ensure that we check\n  // for basename, indeed filename parameter may be in fact just a\n  // basename as recorded in an iop.\n  return dt_colorspaces_is_base_name(filename)\n    ? !strcmp(dt_colorspaces_get_base_name(fullname), filename)\n    : !strcmp(fullname, filename);\n}\n``\nAnd here you have a full patch to 2.6.x (your changes to colorin.c included): [hpmickey-dt2.6.x-0004-colorspaces-colorin.patch.txt](https://github.com/darktable-org/darktable/files/2973041/hpmickey-dt2.6.x-0004-colorspaces-colorin.patch.txt) - enjoy ;)\n. Damn, I was too fast - my previous code does not work for profiles placed in the root directory.\nThe linefor (; f > profile; f--)was wrong and should have been:for (; f >= profile; f--)`\nHere you have a fix - again a full patch to 2.6.x (your changes to colorin.c included): hpmickey-dt2.6.x-0005-colorspaces-colorin.patch.txt\nNow this should be all...\n. Ok, just pulled darktable-2.6.x into empty directory again, built and installed it (./build.sh --build-type Release -j8 --install --sudo).\nTried several directories and film rolls, two different cameras, various input profiles, and everything looks good to me. The issue can be closed imo.\nI am glad I was able to help somehow. DT is a great piece of software.\nHave a nice weekend.. ",
    "iq2luc": "Tested and looks good to me too.\nThank you both.. ",
    "elfring": "Can the situation be improved for components from the software \u201cImageStack\u201d?. ",
    "kikoucalou": "An unusual comment now appears when export to jpg : \n[dt_ioppr_check_iop_order] gamma is not the last iop, last is denoiseprofile 1(10,500000) image 0 (dt_dev_modules_update_multishow)\n[dt_ioppr_check_iop_order] module denoiseprofile 1(10,500000) should be after gamma (71,000000) image 0 (dt_dev_modules_update_multishow)\n[export_job] exported to `/home/pascalou/Images/2019-03-03/darktable_exported/_IGP9814.jpg'\nPerhaps this bug is in relation ?\ndt : 2.7.0+656~gef50c0556. Yes !\n_IGP9814.PEF.xmp.tar.gz\n. Look working fine and quick: no unusual comment now \nDt-d perf.txt.tar.gz\n. Ok, thanks\n. ",
    "johans3": "It's not and i teach you why, matze. \nX is minimal. A kind of space invaders skull for unreadable files is not minimal. Maybe you're still playing that kind of games and therefore you like this kind of \"pixel art\".\nIf this \"art\" wouldn't cause \"negative taste\" I wouldn't care about it and moreover, write a comment about it. . If that resource is available as simple file inside the application bundle OK. I'll take a look. \nAgree it's low priority. Mac is another Linux but still... I see that skull more often. Most files are visible the expected way fortunately. Thank you! \nWould be great to have it as configuration in preferences. I found the split screen. Better than to have 2 pictures on screen to compare after/before\n:). Don't worry I'm used with bug hunting ;) \nDid a lot of coding myself over a decade\nYes I downloaded the manual but it talks about an older version 1.6 to be exact\nThe HTML version online is better but we can't download the whole book but only the current displayed webpage . I don't write bugs to degrade darktable. \nIf your software isn't able to load import pictures from a well known camera i'm forced to do this trough other software. \nThe point is your software offers this feature but it doesn't work. I described above. \nI should read the manual to make it work? \nThat's ridiculous. It doesn't work on Mac that's the truth. \nTherefore what's the reason to close this report? Antipathy, because I send many reports in a short time? . Is this documented somewhere, please? \nWould be very useful to have a search field able to check the whole online user manual  :). Hmmm no \nI rather thought at a command able to reveal the original file on hard drive. Darktable is self sufficient I like that. \nThe easiest way could be to have an interactive path (a hyper link not just plain text path) in the picture information panel. Indeed - I've a relative powerful desktop Mac but the performance isn't butter smooth. I will try out your tips, thanks. It seems a not working pop-up is correct behavior in darktable. I don't think my text was unclear. \nThe bug I described should be a \"feature\"?\nSounds not very serious. The Mac users on this tracker aren't much so you can't understand what works fine because you're using Linux system. . I guess users writing on this bug tracker care about Darktable. Duplicates occur and some topics aren't repeated enough. \nThere is also a difference between platforms. Stuff perfectly working on one system may not, on another. Not sure how many of you use Macs. . @Nilvus\nI didn't say anything about a high resolution map. \nA very simple map with some zoom-able detail is suffice and won't kill Darktable \n. Closed without reason given. If you don't like to hear suggestions you should open a tracker for features only. ",
    "PolarFox": "Got a segfault right here for some reason... (cleanup_pipe)\n. ",
    "GHswitt": "The code is from src/libs/tagging.c, delete_button_clicked. dt_tag_remove only removes the tag from the database. The XMPs are not updated. The code collects all images with the tag before the tag is removed and syncs the XMPs after the tag is removed.. ",
    "lnicola": "I don't know what mingw does, but MSVC only documents _WIN32. @houz I'm sure WIN32 is fine in MinGW and will always be for compatibility reasons. However, the predefined macros should start with an underscore, as those names are implementation-reserved. WIN32 could be redefined by the user, but it's illegal to do that for _WIN32.\nSo they both work, but one is wrong in theory.. ",
    "mcaimi": "OK, can I fix it in some way?. Ok I understand, thanks.\nI assume the same holds for noise profiles, correct?. Ok thanks, i'll do that once I've gathered all data.. ",
    "juszczyn": "I think also that this can happen but I also assume this is the very rare case.\nIf current index is n and we still got at least n elements in list another album will be selected (that's what happens now - we arbitraly select 2nd album). If we've got less than n elements combobox will become empty.. ",
    "flannelhead": "Not a big deal, but could pass --recursive to git clone here - this would make the next two steps unnecessary.. ",
    "ssbssa": "Why is the plural (here and the later ones) not capitalized as well?. What do the changes in bauhaus.c have to do with the german translation?. ",
    "simon04": "Done. Previously went this way to avoid merge conflicts w/ #1726. Rebased now.. ",
    "sobotka": "Again, I'd leave things as a base log. You shouldn't be having any noise amplification at all, and if you are, the code is busted.\nBase logs have been around longer than DSLRs. They work.. ",
    "bobobo1618": "I've added a section at the start. Let me know if that's sufficient.. ",
    "bilddateien": "\nOk, I wasn't sure about that since somehow the number of entries differ. Will do that later. That's why I asked for review.\nE.g. what's happening to picture edits when someone used \"HighTempMercuryVaporFluorescent\" that isn't available any more?\nD500 was in #2012 - obviously I missed the fact that 2 tickets not necessarily mean 2 commits - corrected that.\nI just used the output of extract_wb and already wondered about the difference. Done.. \n"
}