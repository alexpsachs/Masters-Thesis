{
    "Kalyse": "Just rename the project to tesseract.js. \nTesseract is a perfect name for Square. \n. Just rename the project to tesseract.js. \nTesseract is a perfect name for Square. \n. ",
    "stevegraham": "+1 to renaming this project. Also merely appending js to the name suggests this is a js implementation of the Tesseract OCR engine. \n. @amoffat stay tuned for this new js library i'm working on. I'm going to call it \"Linux\" :P\n. +1 to renaming this project. Also merely appending js to the name suggests this is a js implementation of the Tesseract OCR engine. \n. @amoffat stay tuned for this new js library i'm working on. I'm going to call it \"Linux\" :P\n. ",
    "mindcrime": "+1 for renaming.  Tesseract (OCR)  is pretty well established with that name already.\n. +1 for renaming.  Tesseract (OCR)  is pretty well established with that name already.\n. ",
    "robraux": "Agreed. Interesting project, but definitely confused me immediately. \n. Agreed. Interesting project, but definitely confused me immediately. \n. ",
    "amoffat": "-1, leave it.  Tesseract is a fitting name.  We don't name people completely unique names, or insist that a person with a name already taken change it, why do it for software?  \"But there's already an established person with that name!\"\n. @stevegraham that's fine :)  To nerd out for a minute, this is kind of how I visualize it:\n```\nhow_fine = how_fitting * fitting_weight\nif has_name_collision:\n   how_fine -= audience_weight / collision_potential_audience_size\n   how_fine -= category_weight / collision_category_distance\nis_fine_name = how_fine > some_threshold\n```\nTesseract has a high how_fitting, because the name is pretty logical choice for the project and company.  collision_potential_audience_size is the ratio of this project's potential audience size to the existing audience size of the collision's project.  I think this is pretty high too (the audience of OCR guys is a lot smaller than data-slicing guys).  The collision_category_distance is pretty large too...OCR is in a pretty different space than data slicing.\nYour hypothetical js library...small how_fitting, small collision_potential_audience_size, and probably large collision_category_distance.  Probably doesn't meet the threshold, so \"Linux\" is a bad name :)\n. @terretta I know it's 100%...but I don't see how that changes my argument.  But I disagree on the audience size.\n. @terretta You're muddling things.  My point is that the potential audience size for data analysis software, which is huge, is larger than people who know about the Tesseract OCR package.  People who use OCR in general do not count, because \"Tesseract\" is not a name collision to them.  It's only a name collision to people who know Tesseract OCR.  We can agree to disagree.\nArguing about this is stupid though.  It's not up to us :)  I just disagree with the idea that someone should change a fitting name because the name is already used for something.  Maybe the math guys should demand that Tesseract (OCR) be renamed something that isn't already used as a geometric concept, because, shit, that's been used since 1888!  :)  Double-edged sword.\nThat said, it's not a big deal either way\n. > It is a big deal. ...failure to self regulate a namespace collision ... is what drives the continuing perception of a \"need\" for trademarks and patents.\nI agree, it is clear the creator should commit seppuku to restore his honor.\n. -1, leave it.  Tesseract is a fitting name.  We don't name people completely unique names, or insist that a person with a name already taken change it, why do it for software?  \"But there's already an established person with that name!\"\n. @stevegraham that's fine :)  To nerd out for a minute, this is kind of how I visualize it:\n```\nhow_fine = how_fitting * fitting_weight\nif has_name_collision:\n   how_fine -= audience_weight / collision_potential_audience_size\n   how_fine -= category_weight / collision_category_distance\nis_fine_name = how_fine > some_threshold\n```\nTesseract has a high how_fitting, because the name is pretty logical choice for the project and company.  collision_potential_audience_size is the ratio of this project's potential audience size to the existing audience size of the collision's project.  I think this is pretty high too (the audience of OCR guys is a lot smaller than data-slicing guys).  The collision_category_distance is pretty large too...OCR is in a pretty different space than data slicing.\nYour hypothetical js library...small how_fitting, small collision_potential_audience_size, and probably large collision_category_distance.  Probably doesn't meet the threshold, so \"Linux\" is a bad name :)\n. @terretta I know it's 100%...but I don't see how that changes my argument.  But I disagree on the audience size.\n. @terretta You're muddling things.  My point is that the potential audience size for data analysis software, which is huge, is larger than people who know about the Tesseract OCR package.  People who use OCR in general do not count, because \"Tesseract\" is not a name collision to them.  It's only a name collision to people who know Tesseract OCR.  We can agree to disagree.\nArguing about this is stupid though.  It's not up to us :)  I just disagree with the idea that someone should change a fitting name because the name is already used for something.  Maybe the math guys should demand that Tesseract (OCR) be renamed something that isn't already used as a geometric concept, because, shit, that's been used since 1888!  :)  Double-edged sword.\nThat said, it's not a big deal either way\n. > It is a big deal. ...failure to self regulate a namespace collision ... is what drives the continuing perception of a \"need\" for trademarks and patents.\nI agree, it is clear the creator should commit seppuku to restore his honor.\n. ",
    "carbocation": "This is a meaningful issue. I can already brew search tesseract or aptitude search tesseract to find the FOSS OCR software. It would be great for this project to have a different name, at least publicly.\n. This is a meaningful issue. I can already brew search tesseract or aptitude search tesseract to find the FOSS OCR software. It would be great for this project to have a different name, at least publicly.\n. ",
    "davidcelis": "Naming software is too hard of a problem to worry about collision like this.\n. Naming software is too hard of a problem to worry about collision like this.\n. ",
    "terretta": "Consider another name for the concept, such as cubicprism, that also conveniently enough helps convey what the project helps do: look at an OLAP cube in a different light.\n@amoffat \u2014 Wikipedia's http://en.wikipedia.org/wiki/Tesseract_(software) is not a disambiguation page. \"Collision potential\" = 100%.   And I doubt OCR has fewer users than data cubes.\n. @amoffat Most anyone I know with an Android or iOS phone has a smattering of document related apps with OCR, such as Evernote or JotNot.  Few have a data cube reporting visualizer, unless Google Analytics counts.  Same goes for desktop.  So I'm referencing the audience size of both devs and end users who may use tools or see project credits in their apps, and saying more use OCR.\nIn any case, with Google SERPs showing the number two link for the word Tesseract linking to the 25 year old project now funded by Google, seems like the discussion should already be over.\n. It is a big deal.  This kind of move by a well regarded player in the software community -- failure to self regulate a namespace collision with a highly regarded, well respected tool appearing under its own name in a decade of publications -- is what drives the continuing perception of a \"need\" for trademarks and patents.  Your argument that Square should be able to override the name regardless of history simply because this new tool may be more popular, is particularly graceless.\nBtw, it's not Tesseract OCR. It's just Tesseract.  Check out Linux Journal, July 2007, for example:\n\nRecently, I was looking again and found a project called Tesseract. Tesseract is the product of HP research efforts that occurred in the late 1980s and early 1990s. HP and UNLV placed it on SourceForge in 2005, and it is in the process of migrating to Google Code.\n. Consider another name for the concept, such as cubicprism, that also conveniently enough helps convey what the project helps do: look at an OLAP cube in a different light.\n\n@amoffat \u2014 Wikipedia's http://en.wikipedia.org/wiki/Tesseract_(software) is not a disambiguation page. \"Collision potential\" = 100%.   And I doubt OCR has fewer users than data cubes.\n. @amoffat Most anyone I know with an Android or iOS phone has a smattering of document related apps with OCR, such as Evernote or JotNot.  Few have a data cube reporting visualizer, unless Google Analytics counts.  Same goes for desktop.  So I'm referencing the audience size of both devs and end users who may use tools or see project credits in their apps, and saying more use OCR.\nIn any case, with Google SERPs showing the number two link for the word Tesseract linking to the 25 year old project now funded by Google, seems like the discussion should already be over.\n. It is a big deal.  This kind of move by a well regarded player in the software community -- failure to self regulate a namespace collision with a highly regarded, well respected tool appearing under its own name in a decade of publications -- is what drives the continuing perception of a \"need\" for trademarks and patents.  Your argument that Square should be able to override the name regardless of history simply because this new tool may be more popular, is particularly graceless.\nBtw, it's not Tesseract OCR. It's just Tesseract.  Check out Linux Journal, July 2007, for example:\n\nRecently, I was looking again and found a project called Tesseract. Tesseract is the product of HP research efforts that occurred in the late 1980s and early 1990s. HP and UNLV placed it on SourceForge in 2005, and it is in the process of migrating to Google Code.\n. \n",
    "audionerd": "Call it Tesseractor because it acts on tesseracts.\n. Call it Tesseractor because it acts on tesseracts.\n. ",
    "benatkin": "Of all the suggested names, I prefer tesseract. :trollface:\n. :+1:\n. Of all the suggested names, I prefer tesseract. :trollface:\n. :+1:\n. ",
    "ironclad-zz": "+1 How about changing to 8-cell, octachoron or tetracube?\n. +1 How about changing to 8-cell, octachoron or tetracube?\n. ",
    "jkuhnert": "Have to agree with @benatkin, the project name should be changed to tesseract. Kind of has a nice ring to it.\n. Have to agree with @benatkin, the project name should be changed to tesseract. Kind of has a nice ring to it.\n. ",
    "mbostock": "Renamed to Crossfilter, partly in homage to Chris Weaver's work on multidimensional visualization. It may not have the intrigue of \"tesseract\", but it does describe the library's function succinctly.\n. Related: Allow records to have multiple values for a single dimension, such as labels or tags.\nRelated: Allow independent filters on the same dimension. These could be intersected or unioned.\n. IE8- is not supported. Try IE9+, and make sure you have <!DOCTYPE html>.\n. They're there so that you can play with the tesseract in the console. I don't see any harm in the example? Although perhaps it's setting a bad precedent.\n. I decided to take your advice and add the var. It'll be in 1.0.2.\n. This is the expected behavior: the records are filtered, not the groups. In your example, the groups are returned in the expected order by descending value, including those groups whose value happens to be zero.\n. Correct. This would work:\njs\nlinks.top(Infinity).filter(function(d) { return d.value; })\nIf you have lots and lots of groups, you could also use bisection (tesseract.bisect) to find the first zero-group and cut the array there. Or, if you're planning on iterating over the groups, just stop iterating when the value is zero.\n. I'll fix the documentation re. group.all(). I don't recall exactly, but I think the behavior may have changed from an earlier (unreleased) version of Tesseract that did not use incremental update for groups.\nIt might be possible to filter zero-value groups from group.top, but that would either require tracking the count separately (which is a non-significant cost), or by comparing the top groups to the result of the reduceInitial function using the group's order accessor (using bisection, so it'd be fast). It's a bit tricky since the top groups are in descending order, and the bisection assumes ascending order, but in theory it's possible. And, I think it would improve the API.\n. No; group.top returns groups by descending value, whereas group.all returns groups by ascending key. The top method thus requires selecting + sorting, whereas the all method just returns the groups as-is. Another difference is that group.top returns a copy (of maximum size K), whereas group.all returns the internal array. I don't think it's a good idea to merge these into a single method, given that they do different things.\n. Sure, just set up dimensions on origin, destination, or route. For example, for flights from PHX:\njs\nvar origin = flight.dimension(function(d) { return d.origin; });\norigin.filterExact(\"PHX\");\nOr for flights from PHX to ONT:\njs\nvar route = flight.dimension(function(d) { return d.origin + \"-\" + d.destination; });\nroute.filterExact(\"PHX-ONT\");\n. Crossfilter only supports filtering contiguous ranges at the moment. For categorical dimensions (such as airport codes) I think it would make sense to implement a different type of filter can toggle arbitrary values rather than recording a contiguous range. So, I would fix that by adding a new feature. :)\n. The first part to better support categorical dimensions is deciding on an API, so you might consider that even if you don't feel comfortable tackling the implementation.\nI think the first decision is whether we want to support this as \"dimensions can have multiple filters\" (perhaps that can be intersected or unioned), or as \"dimensions can be either quantitative or ordinal\", in which case the filters on an ordinal dimension are tracked as a set of discrete values, rather than a contiguous range.\n. >  I guess all categorical dimensions can be considered ordinal by putting them in, e.g., alphabetical order.\nYep, that's all I meant.\n. The existing API already supports categorical dimensions, provided you only need a single exact match (use filterExact). This issue is about allowing multiple values to be selected. We could enable that specifically for categorical dimensions, in which case the filter API would allow you to get or set multiple selected values. Or, we could figure out how to do it more generally for both categorical and quantitative dimensions. My guess is that enabling a different filter API for categorical dimensions would be less work and more convenient for the common use case. But, the general solution might be more powerful.\n. Correct, and it's not needed with subtract, because there's no ambiguity with string concatentation; the - operator coerces to a number.\n. Yes, but you'll want to use an ordinal scale for the bottom axis. Also, brushing doesn't make a whole lot of sense with a categorical dimension such as origin, so you might want to just listen for click events on the bars rather than using a brush. But, it is possible to brush on ordinal axes if you like.\n. As shown in the \"brush on ordinal axis\" example I linked, the brush extent is different when you use an ordinal scale\u2014it's defined in terms of pixels rather than a range of ordinal values. So, you can't simply pass the brush extent to dimension.filterRange when using an ordinal scale. (And, like I said, brushing isn't a good affordance with ordinal scales anyway\u2014it'd probably be better if you let people click on the ordinal bars rather than brushing them.)\n. Interesting. Thanks for the suggestion!\n. Awesome. Thank you!\n. It LGTM, but I just haven't gotten around to pulling it yet. Probably need to rebuild crossfilter.min.js, create a new tag, npm publish, etc.\n. Sorry, I don't understand what you're asking. What's the difference between a running total and a sum?\n. Sure, you could do that. Use crossfilter to compute the sums, and then iterate over the sums at the end to compute the running total.\n. Easier to do it outside of crossfilter.\n. Please use Stack Overflow to post questions like this. As you can see from the documentation for group.size, it \"returns the number of distinct values in the group, independent of any filters; the cardinality.\" If you want to count the non-empty groups, then you want to do something like group.all().filter(function(d) { return d.length; }).length.\n. So, this is bottom(k)?\n. The record with the minimum value is returned by dimension.top(1). And #26 adds support for dimension.bottom, so you could use that to extract the maximum value, too. I could maybe see adding dimension.extent() to return a two-element array containing the minimum and maximum value, which would be slightly more convenient in this case. Although less parsimonious. :)\n. Exposing the value accessor on the dimension (and likewise the key accessor on the group) seems reasonable. It\u2019s a little dangerous in that it could be overwritten, but I don\u2019t see that being a problem.\nExposing dimension.topValues(k) and dimension.bottomValues(k) (note: plural) also sounds reasonable.\n. There's no reason this hasn't been merged other than time\u2026\n. Yikes. This looks tricky to debug.\n. Kudos, Jason!\n. Crossfilter doesn't do any rendering, so I'm assuming you copied the bar chart from the introduction page? Yes, you may need to change the code if you are presenting different data.\n. There are no asynchronous methods in Crossfilter, so there's no need for it to incorporate an event-listener model. The only time events would be sent are when your code changes the filters.\nIf you want to use event listeners, then I recommend adding an event listener framework to your code so that you can loosely-couple side-effects when filters change. For example, if you use D3.js, you can use d3.dispatch. There are likely other stand-alone libraries for creating custom events and notifying listeners if you'd prefer to use a different library.\nIn the provided example, the view is coordinated with the filters through D3's brush events.\n. Yup, GitHub revved their Markdown parser, and it broke much of the API reference in this project and others.\n. Discarding any references to the old crossfilter object should be sufficient to allow garbage collection.\n. Having different behavior for null vs. undefined is a bit surprising, since null == undefined and they are sometimes used ambiguously. More generally, dimension.filter is a convenience function for calling dimension.filterExact, dimension.filterRange or dimension.filterAll; so, if you want to be unambiguous, you should use those methods exclusively rather than dimension.filter.\n. You'll want to edit src/crossfilter.js, rather than the concatenated generated crossfilter.js. Also, would you mind adding tests for the same functionality?\n. Fixed by #3.\n. @jeroenooms I think it makes more sense to track that issue on #3.\n. I have added jasondavies and randometc as owners of crossfilter. Godspeed, chaps!\n. > There may be a slight performance\u2026\nThere are benchmarks, so you should be able to measure exactly what the performance cost is. (My guess is it\u2019s worth switching implementations when there are more than 32 dimensions.)\n. My 2\u00a2: keep the name db.remove, and rename dimension.remove and group.remove to dimension.dispose and group.dispose (or \u201cdestroy\u201d if you prefer) . The name db.remove should be symmetric with db.add, and I always prefer if you can use a one-word name over two.\n. I am no longer the maintainer of this repo, but I noticed that your pull request causes a ReferenceError: exports is not defined when trying to load crossfilter.js using in a browser via script tag.\n. Since I\u2019m here anyway: see array.reduce. The first argument p is the previous value, the second argument v is the current value.\n. Renamed to Crossfilter, partly in homage to Chris Weaver's work on multidimensional visualization. It may not have the intrigue of \"tesseract\", but it does describe the library's function succinctly.\n. Related: Allow records to have multiple values for a single dimension, such as labels or tags.\nRelated: Allow independent filters on the same dimension. These could be intersected or unioned.\n. IE8- is not supported. Try IE9+, and make sure you have <!DOCTYPE html>.\n. They're there so that you can play with the tesseract in the console. I don't see any harm in the example? Although perhaps it's setting a bad precedent.\n. I decided to take your advice and add the var. It'll be in 1.0.2.\n. This is the expected behavior: the records are filtered, not the groups. In your example, the groups are returned in the expected order by descending value, including those groups whose value happens to be zero.\n. Correct. This would work:\njs\nlinks.top(Infinity).filter(function(d) { return d.value; })\nIf you have lots and lots of groups, you could also use bisection (tesseract.bisect) to find the first zero-group and cut the array there. Or, if you're planning on iterating over the groups, just stop iterating when the value is zero.\n. I'll fix the documentation re. group.all(). I don't recall exactly, but I think the behavior may have changed from an earlier (unreleased) version of Tesseract that did not use incremental update for groups.\nIt might be possible to filter zero-value groups from group.top, but that would either require tracking the count separately (which is a non-significant cost), or by comparing the top groups to the result of the reduceInitial function using the group's order accessor (using bisection, so it'd be fast). It's a bit tricky since the top groups are in descending order, and the bisection assumes ascending order, but in theory it's possible. And, I think it would improve the API.\n. No; group.top returns groups by descending value, whereas group.all returns groups by ascending key. The top method thus requires selecting + sorting, whereas the all method just returns the groups as-is. Another difference is that group.top returns a copy (of maximum size K), whereas group.all returns the internal array. I don't think it's a good idea to merge these into a single method, given that they do different things.\n. Sure, just set up dimensions on origin, destination, or route. For example, for flights from PHX:\njs\nvar origin = flight.dimension(function(d) { return d.origin; });\norigin.filterExact(\"PHX\");\nOr for flights from PHX to ONT:\njs\nvar route = flight.dimension(function(d) { return d.origin + \"-\" + d.destination; });\nroute.filterExact(\"PHX-ONT\");\n. Crossfilter only supports filtering contiguous ranges at the moment. For categorical dimensions (such as airport codes) I think it would make sense to implement a different type of filter can toggle arbitrary values rather than recording a contiguous range. So, I would fix that by adding a new feature. :)\n. The first part to better support categorical dimensions is deciding on an API, so you might consider that even if you don't feel comfortable tackling the implementation.\nI think the first decision is whether we want to support this as \"dimensions can have multiple filters\" (perhaps that can be intersected or unioned), or as \"dimensions can be either quantitative or ordinal\", in which case the filters on an ordinal dimension are tracked as a set of discrete values, rather than a contiguous range.\n. >  I guess all categorical dimensions can be considered ordinal by putting them in, e.g., alphabetical order.\nYep, that's all I meant.\n. The existing API already supports categorical dimensions, provided you only need a single exact match (use filterExact). This issue is about allowing multiple values to be selected. We could enable that specifically for categorical dimensions, in which case the filter API would allow you to get or set multiple selected values. Or, we could figure out how to do it more generally for both categorical and quantitative dimensions. My guess is that enabling a different filter API for categorical dimensions would be less work and more convenient for the common use case. But, the general solution might be more powerful.\n. Correct, and it's not needed with subtract, because there's no ambiguity with string concatentation; the - operator coerces to a number.\n. Yes, but you'll want to use an ordinal scale for the bottom axis. Also, brushing doesn't make a whole lot of sense with a categorical dimension such as origin, so you might want to just listen for click events on the bars rather than using a brush. But, it is possible to brush on ordinal axes if you like.\n. As shown in the \"brush on ordinal axis\" example I linked, the brush extent is different when you use an ordinal scale\u2014it's defined in terms of pixels rather than a range of ordinal values. So, you can't simply pass the brush extent to dimension.filterRange when using an ordinal scale. (And, like I said, brushing isn't a good affordance with ordinal scales anyway\u2014it'd probably be better if you let people click on the ordinal bars rather than brushing them.)\n. Interesting. Thanks for the suggestion!\n. Awesome. Thank you!\n. It LGTM, but I just haven't gotten around to pulling it yet. Probably need to rebuild crossfilter.min.js, create a new tag, npm publish, etc.\n. Sorry, I don't understand what you're asking. What's the difference between a running total and a sum?\n. Sure, you could do that. Use crossfilter to compute the sums, and then iterate over the sums at the end to compute the running total.\n. Easier to do it outside of crossfilter.\n. Please use Stack Overflow to post questions like this. As you can see from the documentation for group.size, it \"returns the number of distinct values in the group, independent of any filters; the cardinality.\" If you want to count the non-empty groups, then you want to do something like group.all().filter(function(d) { return d.length; }).length.\n. So, this is bottom(k)?\n. The record with the minimum value is returned by dimension.top(1). And #26 adds support for dimension.bottom, so you could use that to extract the maximum value, too. I could maybe see adding dimension.extent() to return a two-element array containing the minimum and maximum value, which would be slightly more convenient in this case. Although less parsimonious. :)\n. Exposing the value accessor on the dimension (and likewise the key accessor on the group) seems reasonable. It\u2019s a little dangerous in that it could be overwritten, but I don\u2019t see that being a problem.\nExposing dimension.topValues(k) and dimension.bottomValues(k) (note: plural) also sounds reasonable.\n. There's no reason this hasn't been merged other than time\u2026\n. Yikes. This looks tricky to debug.\n. Kudos, Jason!\n. Crossfilter doesn't do any rendering, so I'm assuming you copied the bar chart from the introduction page? Yes, you may need to change the code if you are presenting different data.\n. There are no asynchronous methods in Crossfilter, so there's no need for it to incorporate an event-listener model. The only time events would be sent are when your code changes the filters.\nIf you want to use event listeners, then I recommend adding an event listener framework to your code so that you can loosely-couple side-effects when filters change. For example, if you use D3.js, you can use d3.dispatch. There are likely other stand-alone libraries for creating custom events and notifying listeners if you'd prefer to use a different library.\nIn the provided example, the view is coordinated with the filters through D3's brush events.\n. Yup, GitHub revved their Markdown parser, and it broke much of the API reference in this project and others.\n. Discarding any references to the old crossfilter object should be sufficient to allow garbage collection.\n. Having different behavior for null vs. undefined is a bit surprising, since null == undefined and they are sometimes used ambiguously. More generally, dimension.filter is a convenience function for calling dimension.filterExact, dimension.filterRange or dimension.filterAll; so, if you want to be unambiguous, you should use those methods exclusively rather than dimension.filter.\n. You'll want to edit src/crossfilter.js, rather than the concatenated generated crossfilter.js. Also, would you mind adding tests for the same functionality?\n. Fixed by #3.\n. @jeroenooms I think it makes more sense to track that issue on #3.\n. I have added jasondavies and randometc as owners of crossfilter. Godspeed, chaps!\n. > There may be a slight performance\u2026\nThere are benchmarks, so you should be able to measure exactly what the performance cost is. (My guess is it\u2019s worth switching implementations when there are more than 32 dimensions.)\n. My 2\u00a2: keep the name db.remove, and rename dimension.remove and group.remove to dimension.dispose and group.dispose (or \u201cdestroy\u201d if you prefer) . The name db.remove should be symmetric with db.add, and I always prefer if you can use a one-word name over two.\n. I am no longer the maintainer of this repo, but I noticed that your pull request causes a ReferenceError: exports is not defined when trying to load crossfilter.js using in a browser via script tag.\n. Since I\u2019m here anyway: see array.reduce. The first argument p is the previous value, the second argument v is the current value.\n. ",
    "jasondavies": "Hmm, this failing test case didn't actually reproduce the problem, because this quicksort implementation isn't stable.\nI've pushed a new test that demonstrates the issue; namely taking ages to sort an array with 50% NaNs (does the same thing for undefined values). I think the stack limit in browsers must be much lower than in Node.js.\n. Okay, here's a fix! The issue is occurring because !(NaN <= NaN || NaN >= NaN) (likewise for undefined).  Native sort moves these values to the end of the array, so for consistency it's simple enough to make a single pass and move such values to the end. Unfortunately it affects performance a bit, but perhaps it can be optimised by effectively performing this check on-the-fly elsewhere in the code.\nI also wondered if caching coerced values would be useful e.g. to avoid calling valueOf twice for every comparison for dates, but perhaps smart JS VMs already optimise for this.\n. My test data had a field that was undefined for a large number of cases, which has the same comparative qualities as NaN. It's simple enough to work around but I can imagine it happening a lot in practice as real-world data doesn't always have consistent fields.\n. @john-guerra Thank you for noticing this; I\u2019ve fixed the issue and included a test case for bisect.right, which was the underlying cause.  I\u2019ve also merged with the latest master, so that jsfiddle no longer works due to the name change (tesseract\u2192crossfilter).\n. @john-guerra Fixed.\n. Awesome. :)\n. Folded into #58.\n. Some workarounds for incomparable values were attempted in versions v1.1.1-v1.1.3 but they were reverted as they caused too many issues: see the v1.2.0 release notes.  Better to simply avoid using mixed types or incomparable values (undefined or NaN).\n. That would be awesome!  I have a dataset with a multi-valued field, and managed to make it filter on this field by generating a new record for each value in the field for each original record (thus making it ~10x larger).  Then I used a custom reduce function to ensure the counts and summations were only on unique records (keyed by a unique ID per original record).  I think this uniqueness checking hurt the performance quite a bit though so it would be great to do this efficiently internally.\nSomething like this might work:\njavascript\nt.dimension.multiple(function(d) { return d.multipleValues; });\nIndependent filters on the same dimension with union and intersection would solve my filterMultiple question; let me know if I can help with anything.\n. https://npmjs.org/package/crossfilter\n. Implemented in #85.\n. Folded into #60.\n. I guess a comment would make it clear for people copying and pasting, just in case it causes a problem.  Updated with a comment.\n. At the moment the only real workaround is to use dimension.filterFunction.\n. I think the performance penalty of iterating over the returned array again to transform each element is negligible.  Note that array.map creates a fresh array, so if you\u2019re worried about performance you might prefer to replace each element in-place:\njs\nvar a = d.top(k);\nfor (var i = 0, n = a.length; i < n; ++i) {\n  a[i] = accessor(a[i]);\n}\n. Nice!\n. You could keep a sorted array per group key, but then the overhead of maintaining this may be greater than simply recomputing the min/max per group key entirely from scratch.  Perhaps the lack of a reduceRemove function could force each group to be recomputed from scratch if anything is removed from that group, while still allowing incremental updates when records are added.\n. Fixed in #61.\n. On second thoughts, we can probably find a way to support this without having to recompute groups from scratch.\n. Making reduceRemove optional never made it into a release, as it would be preferable to avoid recomputing groups from scratch.\n. Ah, you need to pass null, e.g. .reduce(add, null, initial).\n. If you are referring to the optional reduceRemove in #61 then no, they are different.  Making reduceRemove optional means that removing records (due to filters) forces a full rebuild of the group index (using reduceAdd only).  Thus it will work correctly with filters, but we decided it would be preferable to find a performant solution instead for finding maxima (e.g. using a heap), since rebuilding the group index from scratch is slow.\n. This sounds like an issue involving undefined values. See #3.\nYou can avoid this by filtering them out, by using the patch in #3, or by replacing them with something else that can be sorted.\n. Folded into #58.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. This works fine with UglifyJS. Which minifier are you using?\n. Sounds like you're using a buggy version of jsmin: this was fixed in douglascrockford/JSMin@633d99205798c589eaec7b3d158319797dfcadb3.\nNo parentheses are necessary if the space is correctly retained.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. Thanks! I've successfully used bit vectors to represent multi-valued fields that only have up to 32 values. You can also simply use objects or arrays for more values.\n. Yes, this was a dangling global and I\u2019ve removed it now. Thanks.\n. Superseded by #64.\n. js\nvar query = [\"foo\", \"bar\"];\ndimension.filter(function(d) { return query.indexOf(d) >= 0; });\nSlightly faster but trickier if you want to create dynamic filters:\njs\ndimension.filter(function(d) { return d === \"foo\" || d === \"bar\"; });\n. @jaytjioe, Crossfilter uses semver, thus there have been no new features added in v1.1.x since v1.1.0 (these are called patch versions).  The next minor version will be v1.2.0, and will include filtering by arbitrary functions.  Efficient multi-range filtering will probably not be until v1.3.0.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. It can\u2019t handle NaN or undefined values at the moment. See #3 for a patch. One workaround is to replace missing values (NaN or undefined) with values that can be compared, e.g. zeroes or empty strings.\n. Unless you apply the patch from #3, NaNs and undefined values will break Crossfilter, since it cannot sort them properly. You either need to apply the patch, or replace them with something else prior to passing the data to Crossfilter.\n. If you want to ignore them everywhere, just don\u2019t pass them to Crossfilter in the first place. For example:\njs\nvar db = crossfilter(data.filter(function(d) { return d.foo > 0; }));\nThis will only include records with d.foo > 0.\nAlternatively, if you only want to ignore that particular group, just filter it out after performing the group calculation.\njs\nvar group = dimension.group();\n// Filter out the stuff we don\u2019t want,\n// assuming we are grouping by some numerical key.\nvar groups = group.all().filter(function(d) { return +d.key > 0; });\nStackOverflow would be a better forum for asking questions like this, since having one huge bar for zero is not a bug.\n. Issues with incomparable values (NaN and undefined) and grouping by such values are fixed in #3.\nYou still need to account for such values when visualising e.g. you might want to ignore the group representing missing values when computing the y-scale for your histogram, as mentioned above.\n. It could be this issue that I spotted in beta a while ago. It was only fixed in V8 recently, so I don't know how long it'll take to filter down. I'll see if I can get the fix backported.\n. Update: it looks like it's definitely the same issue, and it hasn't been merged into the release branches of V8 yet. I'll keep you updated.\n. Yes, the fix was merged into M23 a few days ago, but I think it\u2019s yet to be backported to M21 (stable).\n. M23 is now stable, so this issue should be resolved.\n. Interesting, thanks.  Since Crossfilter already works fine in both browsers and Node.js, I\u2019m not convinced there\u2019s any reason to change anything here.\n. Fixed by #36.\n. Thanks for the contribution!  I think it would be preferable to allow removal of all currently-selected records, reusing the existing fast filter logic, rather than a much slower table scan comparing object identities as in your implementation.  I have implemented this in #85, and would welcome feedback.\n. Thanks for the contribution.  Note that the equivalent can be achieved by creating a special dimension with a unique value for each possible combination of pivot groups:\njs\nvar pivotGroup = c\n    .dimension(function(d) { return d.gender + \"/\" + d.handed; })\n    .group(); // default groups use the dimension value\nThis requires somewhat careful choice of separator (\"/\" seems convenient here, but you could use any character, even something like \"\\0\").\nA special dimension is required because group keys can only be based on the dimension value.  Alternatively, perhaps arbitrary groups on a \u201cdummy dimension\u201d, similar to crossfilter.groupAll could be supported, that allow a group keys to be generated based on a record, e.g. c.group(function(d) { return d.gender + \"/\" + d.handed; }).\nI\u2019m inclined to keep the API simple and fast, and the use of a special dimension seems reasonable here.  The advantage over your pivotGroup implementation is that other standard group methods are also available, such as top and order, and the special dimension can also be removed when no longer needed.\nI\u2019m closing for now, but feel free to add comments if you think there\u2019s a problem with my approach, or an advantage to having a specialised API.\n. Why do they need to be zero-padded?  As long as you pick a suitable separator, no padding is necessary (, or / would work fine for numbers, or even \\0 as discussed above).\n. Right, the array of all groups as returned by group.all will be in ascending natural order, so I agree the order could be unexpected if you have variable-length keys.  However, the grouping behaviour and top-K groups will all work as expected, which is the main point of using a dummy dimension in this manner.\nI\u2019d be open to considering proper tuple support, but only if performance remains reasonably fast.  Though not ideal, you can always clone the returned group.all array and sort it afterwards if you really need it to be sorted differently.\n. The dummy dimension is really only intended as a way to group by multiple keys at once, rather than for filtering.  If you want to filter, you can use an individual dimension that has the correct ordering.  So for your example you could say:\njs\ndimension0.filterExact(1);\ndimension1.filterRange([1, 19]);\n. You\u2019re probably better off opening an issue at DefinitelyTyped. Thanks!\n. Fixed by #36.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. Are you passing a host object e.g. a DOM object to the worker?  Crossfilter doesn\u2019t rely on the DOM so it should work fine inside a worker provided you\u2019re aware of the constraints.\n. Not easily, no.\n. Fixed by #60.\n. Yes, it looks like it is incorrectly counting 10 for quantity=2, when it should be 8.  I\u2019ll look into it soon.  I think the code that updates groups needs adjusting slightly.\n. Fixed in #3.\n. Tally ho, me old china!\n. Tests added.\n. Folded into #63.\n. Folded into #63.\n. I\u2019ve updated src/package.js since package.json is auto-generated, and converted the author, contributors and maintainers to be hashes.\n. Folded into #58.\n. Staged in #63.\n. I\u2019m not sure it\u2019s worth the effort to support undefined or NaN group reduce values, because the concept of a \u201cmissing value\u201d doesn\u2019t make sense there.  However, it might be useful for reduceSum to ignore NaN values.\n. Closing this for now, since support for NaN values was reverted in 1.2.0.\n. The attempts to support unorderable values such as NaN or undefined were dropped in version 1.2.0.\n. If you convert incomparable values to -Infinity, they should appear last when calling dimension.top, so I don\u2019t see the problem there.  However, -Infinity should appear first when calling dimension.bottom, which might not be what you want.  Note that dimension.{bottom,top} respect the current filter on that dimension, so you could filter out values of -Infinity to avoid those records being returned.\n. I\u2019ll look into it.\n. Fixed in version 1.1.2; see b742be6146441195dd08d3f3b9f33601d1e175f8.\n. See also: mishoo/UglifyJS2#143.\n. Duplicate of #48.  You can achieve this by creating a dummy dimension with the value accessor being the multi-valued group key, then group using an identity function:\njs\nvar group = db\n    .dimension(function(d) { return d.week_date + \"/\" + d.target; })\n    .group();\nThere may be a case for adding a database-wide group, but it would amount to the same thing, e.g. db.group(function(d) { return d.week_date + \"/\" + d.target; }).\n. If you want to run the example locally, you may need a Web server to get around the strict security settings in Chrome.  If you have Python, you can simply say:\npython -mSimpleHTTPServer\nThen access the example via http://127.0.0.1:8000/.\nI\u2019ve also just pushed an update to use D3 version 3, which allows you to use Safari or Firefox locally without requiring a Web server.  For Chrome, the above still applies.\n. So effectively you want to say something like:\nsql\nSELECT AVG(value)\nFROM table\nWHERE\n  yearmo=\"Jan 13\" AND\n    (value1 BETWEEN 80 AND 100) AND \n    (value7 BETWEEN 80 AND 100) OR\n  yearmo<>\"Jan 13\"\n. Hmm. Would you want the trend line for each metric to ignore the filter on that metric?  This seems more in keeping with the way crossfilter approaches filters.  So in your example, the trend for value1 would ignore the value1 filter, but keep the value7 filter:\nsql\nSELECT yearmo, AVG(value1)\nFROM table\nWHERE (yearmo = 'Jan 13' AND value7 BETWEEN 80 AND 100) OR yearmo <> 'Jan 13'\nGROUP BY yearmo\nAnd similarly for value7, etc.\n. This is technically possible using the new custom filter function support coming in version 1.2.0, which is staged in #63.  One trick is to use a dummy dimension to perform the filtering (which will then be intersected across all dimensions, including the one that you are using to group your averages).\njs\nvar dummy = db.dimension(function(d) { return d; });\ndummy.filter(function(d) {\n  return d.yearmo !== \"Jan 13\" || 80 <= d.value1 && d.value1 < 100 && 80 <= d.value7 && d.value7 < 100;\n});\nA more ideal solution would be to allow independent range filters on dimensions that can then be combined in arbitrary ways, as this would be more efficient due to using binary search for range filtering rather than a full scan of all rows.  The above would still be reasonably efficient though, since the most time-consuming part is usually MapReduce, which remains incremental even for custom filter functions.\n. Yes.\n. Can you post a reproducible example somewhere, e.g. http://bl.ocks.org or http://jsfiddle.net ?\n. Crossfilter will sort according to the natural order of the values, so if they are strings, it will sort them as strings.  It sounds like you needed to coerce them to numbers in the value accessor, e.g.\njs\ndb.dimension(function(d) { return +d.myField; });\n. Related #65, #71.\n. On the other hand, it does seem convenient to support the concept of \u201cmissing values\u201d using undefined.  But the concept can already be implemented without much work: the value accessor should return a naturally-orderable value, such as 0 or Infinity, and if such values should be ignored the MapReduce functions can ignore them.\n. Reverted in #63.\n. I believe the approach (and eventual name!) was inspired by Chris Weaver\u2019s Multidimensional Visual Analysis Using Cross-Filtered Views.\nGitHub is not really the best place to ask for support; the issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. Yes, that seems wrong.  I\u2019m looking into it.\n. Thanks for the bug report.  There was no bug in Crossfilter or D3, but the example needed adjusting to return the top 40 flights by time as well as by day.\n. Strictly speaking, JSON is text-based encoding format, so I think you just want to retrieve the filtered records (as JavaScript objects), not JSON.\nTo retrieve all records intersected by the current filters, you can use dimension.top(Infinity), which will retrieve all records, sorted by that dimension (in descending order).  You can also use dimension.bottom(Infinity) to retrieve in ascending order.\n. I\u2019d need more information to reproduce this:\n- The dimension\u2019s value accessor.\n- The line number (in the unminified source) of the error.\n- The data in question (or a representative sample).\nEven better would be a working example on http://jsfiddle.net or http://bl.ocks.org.\n. Duplicate of #31; this is a bug in JSMin, which was fixed around 11 months ago, so updating your JSMin should fix it.\n. This is working as expected; the delay dimension is clamped to be between -60 and 149 inclusive:\njs\ndelay = flight.dimension(function(d) {\n  return Math.max(-60, Math.min(149, d.delay));\n}),\nAs a result, the first and last bars of the graph include delays smaller than -60 and larger than 149 respectively, therefore filtering works as expected.\nPerhaps the axes could be clearer, but I\u2019ll close this bug for now unless anyone has any suggestions for improving them.\n. Can you be a bit more specific about your requirements?  Crossfilter already allows you to create groups, e.g. based on time (hourly, daily, etc.), and you can then specify arbitrary reduce functions for groups to compute various aggregates.  In your example, you could do something like:\n``` js\nfunction reduceAdd(p, v) { if (v.success) ++p.success; else ++p.failure; }\nfunction reduceRemove(p, v) { if (v.success) --p.success; else --p.failure; }\nfunction reduceInitial(d) { return {failure: 0, success: 0}; }\nfunction orderValue(p) { return p.success / (p.success + p.failure); }\nvar transactionsByDay = transactions.dimension(function(d) { return d.day; }),\n    transactionSuccessByDay = transactionsByDay.group()\n      .reduce(reduceAdd, reduceRemove, reduceInitial)\n      .order(orderValue);\n```\nThis would create daily groups, ordered by success rate, so you could easily list the top ten days by success rate, for instance.\n. I agree about db.remove not being an ideal name.  I don\u2019t see the need for a separate method for removing all records, though, you can simply call db.removeRecords (or whatever we call it) with no filters applied.  The main reason I don\u2019t like db.remove is that it\u2019s inconsistent with dimension.remove and group.remove, and it implies removal of the whole database (dimensions and groups), not just records.\nIf there was a good reason for a separate call to remove all records, I\u2019d call it db.removeAll.\n. Yes, I wish I had named them \u201cdestroy\u201d now\u2026 :)\n. GitHub issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead, though your question sounds more generally related to using D3.\n. Thanks!  Fixed in version 1.3.3.\n. Note that you can already retrieve the filtered records using dimension.top (sorted by the dimension\u2019s natural order).  Is there a particular reason why that wouldn\u2019t be useful in your scenario?\n. > Using dimension.top doesn't work in this case as the filters come from different locations.\nCan you explain what you mean by the filters coming from different locations?  dimension.top(Infinity) does exactly the same as your patch, except that the records would be ordered by the dimension value (in descending order; dimension.bottom(Infinity) orders them in ascending order).  In other words, all filters are applied (including any on the dimension you\u2019re sorting by) before returning the records.\n. Perhaps you\u2019re confusing the behaviour of dimension.top with groups, which exclude their associated dimension\u2019s filter for computing reduce values.\n. @jdarling Read the documentation for dimension.top (or try it for yourself); you\u2019ll see that it returns the records, not the computed dimension values.\n. Thanks, I\u2019ve reproduced this and will submit a patch soon.\n. You could remove all records and then add new ones, though this would require resetting all filters (to select all records for removal).\n. The maximum number of dimensions is 32 at the moment.  There is a proposed fix in #75.\n. These issues are intended for bug reports and feature requests; please post questions like this on a forum like StackOverflow.\n(In answer to your question, see the custom function parseDate in the example, which constructs Date objects using the right portions of the input strings.)\n. I think this is related to Crossfilter\u2019s general limitation of only allowing one set of filters to be active at any time.  I would rather improve the API so that it supports independent sets of filters.  You could then have charts based on one filterset, and perform other operations using a different filterset.\n. I\u2019ve thought about it, but haven\u2019t had time to implement it yet.  Most likely it would be backwards-incompatible, but it would support more powerful queries e.g. union/intersection/exclusion.\n. As I mentioned above, I\u2019d prefer a more general solution; at the moment Crossfilter only allows one set of filters to be active at a time, so adding a separate filter argument for removal alone feels inconsistent.\n. I think we\u2019re talking about the same thing. :)  I wrote:\n\nadding a separate filter argument for removal alone feels inconsistent.\n\nBy \u201cfilter argument\u201d, I\u2019m referring to your \u201ctest function\u201d, i.e. .remove(filterFunction).  I\u2019m not disputing the usefulness of this, but I would prefer a more general solution as it would be more powerful and elegant.  The indexed filter types (filterExact and filterRange) are also much faster than filterFunction, though admittedly this isn\u2019t really important for removal of records.\n. The dimension value accessor must return naturally-orderable values.  If an accessor returns an array, then JavaScript\u2019s relational operations (<, <=, >, >=) will attempt to coerce the array to a number or a string.  I think this coercion will incur a performance penalty, particularly during the sort operation.\nI\u2019d recommend against using an array and returning an appropriate string instead if you really need a composite key.\n. I suggest reading up about how JavaScript performs relational comparisons.  If you want to create a composite key for example, then you need to ensure any numbers are zero-padded since the array would be coerced to a string with comma separators.  It\u2019s better to be explicit and return a string if you want to do this.\n. Closing as I think we\u2019d prefer to keep the API simple.  You can write your own helpers to generate particular map/reduce functions as necessary.\n. Thanks for the contribution, but this is a duplicate of #113, and I think we\u2019d prefer to keep the API simple.\n. Not as far as I know.  Are you saying the issue can be reproduced with the flight times example?  Can you give exact steps to reproduce?\n. Thanks!  Fixed in version 1.3.8.\n. Duplicate of #75.\n. Hello!  Thanks for the contribution.  However, I\u2019m afraid this is a duplicate of existing requests for the same feature: #113, #115, and related #102.  We\u2019ve taken the decision not to extend the API to support this, as we\u2019d prefer to keep it simple.  As noted in these tickets, it\u2019s possible to have a tiny helper function that unpacks an object and makes the appropriate reduce call, if that\u2019s something that you really need.\n. I think the main limitation of crossfilter at the moment is the types of queries it supports.  Essentially, you can only do A & B & C & \u2026 where A, B, C etc. are range queries on distinct ordered dimensions.  It was developed primarily for fast interactive filtering of this specific type of query.  The possibility of generalisation has been discussed elsewhere, and I will work on it when I have time (!), but I\u2019m not sure if there\u2019s really any advantage to adding a high-level query engine at the moment when the low-level primitives are somewhat limited.\nI\u2019m closing as this issue isn\u2019t specifically a bug or feature request for Crossfilter itself (though it is another use case for making the low-level primitives more powerful).\n. Good catch, thanks.  Have you signed the CLA?\n. Good catch.  I have a fix and I\u2019m just working on a test case now.  Thanks!\n. It sounds like @unwiredbrain has the right idea; you can create one dimension per column, and then use dimension.top(1) to retrieve each dimension\u2019s maximum value (while respecting filters applied to all dimensions).\nHowever, you\u2019ll want to grab the lengths:\njs\nvar column0 = data.dimension(function(d) { return d[0].length; });\nCrossfilter is not magical (OK, well just a little!) -- this won\u2019t be faster than looping over all your values and finding the maxima once-only.  However, it will be much faster when filtering is involved, hence the name!\nGitHub is not really the best place to ask for support; the issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. This is documented behaviour: incomparable values such as undefined and NaN are not supported and will cause problems.\n. Further information is required to reproduce and diagnose the issue:\n- What kind of data are you sorting?  Does it contain incomparable (NaN or undefined) or mixed types (these are not supported)?\n- Some example code would be helpful.\nFeel free to reopen with this information.\n. These GitHub issues are meant for reporting bugs and feature requests only. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. cnt.length is 4, because there are 4 groups when grouped by type.  However, two of the groups have value 0, indicating that two of the types have zero counts for the current filters.  Groups with zero counts are not excluded, which seems to be your expectation.\n. If you only want non-zero groups, you can simply filter the array of groups:\njs\ncountGroup.top(Infinity).filter(function(d) { return d.value > 0; });\n. As described in the documentation, group.top uses an ordering based on the group\u2019s value (in your example, the counts).  If you want all groups ordered by key, you can use group.all instead.\n. The objects representing groups are part of the API, but you can simply convert them to your own format after grouping, e.g.:\njs\nvalues.map(function(d) {\n  return {key: d.key, size: d.value.size, weight: d.value.weight};\n});\n. Internally, groups are represented as {key, value} objects, so if you want to represent groups differently, you\u2019d either have to modify the internals or simply create your own representation as I\u2019ve suggested above.\n. Seems to work fine for me, perhaps you should post a reproducible example somewhere?  Personally I think it would be simpler to use firstGrouping.top(Infinity) and regroup small groups into \"(other)\" yourself.\n. Ah, sorry about that, perhaps I didn\u2019t test on a large enough sample to reproduce.  You\u2019re right: the group order must be consistent with the dimension\u2019s value order.  This is primarily to allow fast updating of groups internally.  It\u2019s a bit restrictive, but I think it\u2019s best to treat Crossfilter as quite a low-level API rather than a flexible high-level API.  In your case, this is why it would be better to regroup into \u201c(other)\u201d outside of Crossfilter.\n. Thanks!  This went unnoticed for two years and five months.  I think you deserve a prize!\n. Rather than using gulp, since the build process is quite simple I suppose it might be preferable to have a pure Node-based build without relying on heavyweight dependencies.\nWhich new contributor license feature are you referring to?\n. Thanks for the suggested fix.  I opted for a more bitwise approach rather than a comparison operator.  Your fix works fine in this situation, since this branch isn\u2019t taken for more than 16 dimensions (32-bit values), but the comparison operator wouldn\u2019t have worked if the bitwise representation had produced a negative value, which it can do in the 32-bit cases.\n. It\u2019s hard to say without more information.  Any error messages?  What changed ~1 week ago to cause this to happen?\n. Hmm, this failing test case didn't actually reproduce the problem, because this quicksort implementation isn't stable.\nI've pushed a new test that demonstrates the issue; namely taking ages to sort an array with 50% NaNs (does the same thing for undefined values). I think the stack limit in browsers must be much lower than in Node.js.\n. Okay, here's a fix! The issue is occurring because !(NaN <= NaN || NaN >= NaN) (likewise for undefined).  Native sort moves these values to the end of the array, so for consistency it's simple enough to make a single pass and move such values to the end. Unfortunately it affects performance a bit, but perhaps it can be optimised by effectively performing this check on-the-fly elsewhere in the code.\nI also wondered if caching coerced values would be useful e.g. to avoid calling valueOf twice for every comparison for dates, but perhaps smart JS VMs already optimise for this.\n. My test data had a field that was undefined for a large number of cases, which has the same comparative qualities as NaN. It's simple enough to work around but I can imagine it happening a lot in practice as real-world data doesn't always have consistent fields.\n. @john-guerra Thank you for noticing this; I\u2019ve fixed the issue and included a test case for bisect.right, which was the underlying cause.  I\u2019ve also merged with the latest master, so that jsfiddle no longer works due to the name change (tesseract\u2192crossfilter).\n. @john-guerra Fixed.\n. Awesome. :)\n. Folded into #58.\n. Some workarounds for incomparable values were attempted in versions v1.1.1-v1.1.3 but they were reverted as they caused too many issues: see the v1.2.0 release notes.  Better to simply avoid using mixed types or incomparable values (undefined or NaN).\n. That would be awesome!  I have a dataset with a multi-valued field, and managed to make it filter on this field by generating a new record for each value in the field for each original record (thus making it ~10x larger).  Then I used a custom reduce function to ensure the counts and summations were only on unique records (keyed by a unique ID per original record).  I think this uniqueness checking hurt the performance quite a bit though so it would be great to do this efficiently internally.\nSomething like this might work:\njavascript\nt.dimension.multiple(function(d) { return d.multipleValues; });\nIndependent filters on the same dimension with union and intersection would solve my filterMultiple question; let me know if I can help with anything.\n. https://npmjs.org/package/crossfilter\n. Implemented in #85.\n. Folded into #60.\n. I guess a comment would make it clear for people copying and pasting, just in case it causes a problem.  Updated with a comment.\n. At the moment the only real workaround is to use dimension.filterFunction.\n. I think the performance penalty of iterating over the returned array again to transform each element is negligible.  Note that array.map creates a fresh array, so if you\u2019re worried about performance you might prefer to replace each element in-place:\njs\nvar a = d.top(k);\nfor (var i = 0, n = a.length; i < n; ++i) {\n  a[i] = accessor(a[i]);\n}\n. Nice!\n. You could keep a sorted array per group key, but then the overhead of maintaining this may be greater than simply recomputing the min/max per group key entirely from scratch.  Perhaps the lack of a reduceRemove function could force each group to be recomputed from scratch if anything is removed from that group, while still allowing incremental updates when records are added.\n. Fixed in #61.\n. On second thoughts, we can probably find a way to support this without having to recompute groups from scratch.\n. Making reduceRemove optional never made it into a release, as it would be preferable to avoid recomputing groups from scratch.\n. Ah, you need to pass null, e.g. .reduce(add, null, initial).\n. If you are referring to the optional reduceRemove in #61 then no, they are different.  Making reduceRemove optional means that removing records (due to filters) forces a full rebuild of the group index (using reduceAdd only).  Thus it will work correctly with filters, but we decided it would be preferable to find a performant solution instead for finding maxima (e.g. using a heap), since rebuilding the group index from scratch is slow.\n. This sounds like an issue involving undefined values. See #3.\nYou can avoid this by filtering them out, by using the patch in #3, or by replacing them with something else that can be sorted.\n. Folded into #58.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. This works fine with UglifyJS. Which minifier are you using?\n. Sounds like you're using a buggy version of jsmin: this was fixed in douglascrockford/JSMin@633d99205798c589eaec7b3d158319797dfcadb3.\nNo parentheses are necessary if the space is correctly retained.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. Thanks! I've successfully used bit vectors to represent multi-valued fields that only have up to 32 values. You can also simply use objects or arrays for more values.\n. Yes, this was a dangling global and I\u2019ve removed it now. Thanks.\n. Superseded by #64.\n. js\nvar query = [\"foo\", \"bar\"];\ndimension.filter(function(d) { return query.indexOf(d) >= 0; });\nSlightly faster but trickier if you want to create dynamic filters:\njs\ndimension.filter(function(d) { return d === \"foo\" || d === \"bar\"; });\n. @jaytjioe, Crossfilter uses semver, thus there have been no new features added in v1.1.x since v1.1.0 (these are called patch versions).  The next minor version will be v1.2.0, and will include filtering by arbitrary functions.  Efficient multi-range filtering will probably not be until v1.3.0.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. It can\u2019t handle NaN or undefined values at the moment. See #3 for a patch. One workaround is to replace missing values (NaN or undefined) with values that can be compared, e.g. zeroes or empty strings.\n. Unless you apply the patch from #3, NaNs and undefined values will break Crossfilter, since it cannot sort them properly. You either need to apply the patch, or replace them with something else prior to passing the data to Crossfilter.\n. If you want to ignore them everywhere, just don\u2019t pass them to Crossfilter in the first place. For example:\njs\nvar db = crossfilter(data.filter(function(d) { return d.foo > 0; }));\nThis will only include records with d.foo > 0.\nAlternatively, if you only want to ignore that particular group, just filter it out after performing the group calculation.\njs\nvar group = dimension.group();\n// Filter out the stuff we don\u2019t want,\n// assuming we are grouping by some numerical key.\nvar groups = group.all().filter(function(d) { return +d.key > 0; });\nStackOverflow would be a better forum for asking questions like this, since having one huge bar for zero is not a bug.\n. Issues with incomparable values (NaN and undefined) and grouping by such values are fixed in #3.\nYou still need to account for such values when visualising e.g. you might want to ignore the group representing missing values when computing the y-scale for your histogram, as mentioned above.\n. It could be this issue that I spotted in beta a while ago. It was only fixed in V8 recently, so I don't know how long it'll take to filter down. I'll see if I can get the fix backported.\n. Update: it looks like it's definitely the same issue, and it hasn't been merged into the release branches of V8 yet. I'll keep you updated.\n. Yes, the fix was merged into M23 a few days ago, but I think it\u2019s yet to be backported to M21 (stable).\n. M23 is now stable, so this issue should be resolved.\n. Interesting, thanks.  Since Crossfilter already works fine in both browsers and Node.js, I\u2019m not convinced there\u2019s any reason to change anything here.\n. Fixed by #36.\n. Thanks for the contribution!  I think it would be preferable to allow removal of all currently-selected records, reusing the existing fast filter logic, rather than a much slower table scan comparing object identities as in your implementation.  I have implemented this in #85, and would welcome feedback.\n. Thanks for the contribution.  Note that the equivalent can be achieved by creating a special dimension with a unique value for each possible combination of pivot groups:\njs\nvar pivotGroup = c\n    .dimension(function(d) { return d.gender + \"/\" + d.handed; })\n    .group(); // default groups use the dimension value\nThis requires somewhat careful choice of separator (\"/\" seems convenient here, but you could use any character, even something like \"\\0\").\nA special dimension is required because group keys can only be based on the dimension value.  Alternatively, perhaps arbitrary groups on a \u201cdummy dimension\u201d, similar to crossfilter.groupAll could be supported, that allow a group keys to be generated based on a record, e.g. c.group(function(d) { return d.gender + \"/\" + d.handed; }).\nI\u2019m inclined to keep the API simple and fast, and the use of a special dimension seems reasonable here.  The advantage over your pivotGroup implementation is that other standard group methods are also available, such as top and order, and the special dimension can also be removed when no longer needed.\nI\u2019m closing for now, but feel free to add comments if you think there\u2019s a problem with my approach, or an advantage to having a specialised API.\n. Why do they need to be zero-padded?  As long as you pick a suitable separator, no padding is necessary (, or / would work fine for numbers, or even \\0 as discussed above).\n. Right, the array of all groups as returned by group.all will be in ascending natural order, so I agree the order could be unexpected if you have variable-length keys.  However, the grouping behaviour and top-K groups will all work as expected, which is the main point of using a dummy dimension in this manner.\nI\u2019d be open to considering proper tuple support, but only if performance remains reasonably fast.  Though not ideal, you can always clone the returned group.all array and sort it afterwards if you really need it to be sorted differently.\n. The dummy dimension is really only intended as a way to group by multiple keys at once, rather than for filtering.  If you want to filter, you can use an individual dimension that has the correct ordering.  So for your example you could say:\njs\ndimension0.filterExact(1);\ndimension1.filterRange([1, 19]);\n. You\u2019re probably better off opening an issue at DefinitelyTyped. Thanks!\n. Fixed by #36.\n. Please use the crossfilter tag on Stack Overflow if you want help. These issues are for feature requests and bug reports only. Thanks.\n. Are you passing a host object e.g. a DOM object to the worker?  Crossfilter doesn\u2019t rely on the DOM so it should work fine inside a worker provided you\u2019re aware of the constraints.\n. Not easily, no.\n. Fixed by #60.\n. Yes, it looks like it is incorrectly counting 10 for quantity=2, when it should be 8.  I\u2019ll look into it soon.  I think the code that updates groups needs adjusting slightly.\n. Fixed in #3.\n. Tally ho, me old china!\n. Tests added.\n. Folded into #63.\n. Folded into #63.\n. I\u2019ve updated src/package.js since package.json is auto-generated, and converted the author, contributors and maintainers to be hashes.\n. Folded into #58.\n. Staged in #63.\n. I\u2019m not sure it\u2019s worth the effort to support undefined or NaN group reduce values, because the concept of a \u201cmissing value\u201d doesn\u2019t make sense there.  However, it might be useful for reduceSum to ignore NaN values.\n. Closing this for now, since support for NaN values was reverted in 1.2.0.\n. The attempts to support unorderable values such as NaN or undefined were dropped in version 1.2.0.\n. If you convert incomparable values to -Infinity, they should appear last when calling dimension.top, so I don\u2019t see the problem there.  However, -Infinity should appear first when calling dimension.bottom, which might not be what you want.  Note that dimension.{bottom,top} respect the current filter on that dimension, so you could filter out values of -Infinity to avoid those records being returned.\n. I\u2019ll look into it.\n. Fixed in version 1.1.2; see b742be6146441195dd08d3f3b9f33601d1e175f8.\n. See also: mishoo/UglifyJS2#143.\n. Duplicate of #48.  You can achieve this by creating a dummy dimension with the value accessor being the multi-valued group key, then group using an identity function:\njs\nvar group = db\n    .dimension(function(d) { return d.week_date + \"/\" + d.target; })\n    .group();\nThere may be a case for adding a database-wide group, but it would amount to the same thing, e.g. db.group(function(d) { return d.week_date + \"/\" + d.target; }).\n. If you want to run the example locally, you may need a Web server to get around the strict security settings in Chrome.  If you have Python, you can simply say:\npython -mSimpleHTTPServer\nThen access the example via http://127.0.0.1:8000/.\nI\u2019ve also just pushed an update to use D3 version 3, which allows you to use Safari or Firefox locally without requiring a Web server.  For Chrome, the above still applies.\n. So effectively you want to say something like:\nsql\nSELECT AVG(value)\nFROM table\nWHERE\n  yearmo=\"Jan 13\" AND\n    (value1 BETWEEN 80 AND 100) AND \n    (value7 BETWEEN 80 AND 100) OR\n  yearmo<>\"Jan 13\"\n. Hmm. Would you want the trend line for each metric to ignore the filter on that metric?  This seems more in keeping with the way crossfilter approaches filters.  So in your example, the trend for value1 would ignore the value1 filter, but keep the value7 filter:\nsql\nSELECT yearmo, AVG(value1)\nFROM table\nWHERE (yearmo = 'Jan 13' AND value7 BETWEEN 80 AND 100) OR yearmo <> 'Jan 13'\nGROUP BY yearmo\nAnd similarly for value7, etc.\n. This is technically possible using the new custom filter function support coming in version 1.2.0, which is staged in #63.  One trick is to use a dummy dimension to perform the filtering (which will then be intersected across all dimensions, including the one that you are using to group your averages).\njs\nvar dummy = db.dimension(function(d) { return d; });\ndummy.filter(function(d) {\n  return d.yearmo !== \"Jan 13\" || 80 <= d.value1 && d.value1 < 100 && 80 <= d.value7 && d.value7 < 100;\n});\nA more ideal solution would be to allow independent range filters on dimensions that can then be combined in arbitrary ways, as this would be more efficient due to using binary search for range filtering rather than a full scan of all rows.  The above would still be reasonably efficient though, since the most time-consuming part is usually MapReduce, which remains incremental even for custom filter functions.\n. Yes.\n. Can you post a reproducible example somewhere, e.g. http://bl.ocks.org or http://jsfiddle.net ?\n. Crossfilter will sort according to the natural order of the values, so if they are strings, it will sort them as strings.  It sounds like you needed to coerce them to numbers in the value accessor, e.g.\njs\ndb.dimension(function(d) { return +d.myField; });\n. Related #65, #71.\n. On the other hand, it does seem convenient to support the concept of \u201cmissing values\u201d using undefined.  But the concept can already be implemented without much work: the value accessor should return a naturally-orderable value, such as 0 or Infinity, and if such values should be ignored the MapReduce functions can ignore them.\n. Reverted in #63.\n. I believe the approach (and eventual name!) was inspired by Chris Weaver\u2019s Multidimensional Visual Analysis Using Cross-Filtered Views.\nGitHub is not really the best place to ask for support; the issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. Yes, that seems wrong.  I\u2019m looking into it.\n. Thanks for the bug report.  There was no bug in Crossfilter or D3, but the example needed adjusting to return the top 40 flights by time as well as by day.\n. Strictly speaking, JSON is text-based encoding format, so I think you just want to retrieve the filtered records (as JavaScript objects), not JSON.\nTo retrieve all records intersected by the current filters, you can use dimension.top(Infinity), which will retrieve all records, sorted by that dimension (in descending order).  You can also use dimension.bottom(Infinity) to retrieve in ascending order.\n. I\u2019d need more information to reproduce this:\n- The dimension\u2019s value accessor.\n- The line number (in the unminified source) of the error.\n- The data in question (or a representative sample).\nEven better would be a working example on http://jsfiddle.net or http://bl.ocks.org.\n. Duplicate of #31; this is a bug in JSMin, which was fixed around 11 months ago, so updating your JSMin should fix it.\n. This is working as expected; the delay dimension is clamped to be between -60 and 149 inclusive:\njs\ndelay = flight.dimension(function(d) {\n  return Math.max(-60, Math.min(149, d.delay));\n}),\nAs a result, the first and last bars of the graph include delays smaller than -60 and larger than 149 respectively, therefore filtering works as expected.\nPerhaps the axes could be clearer, but I\u2019ll close this bug for now unless anyone has any suggestions for improving them.\n. Can you be a bit more specific about your requirements?  Crossfilter already allows you to create groups, e.g. based on time (hourly, daily, etc.), and you can then specify arbitrary reduce functions for groups to compute various aggregates.  In your example, you could do something like:\n``` js\nfunction reduceAdd(p, v) { if (v.success) ++p.success; else ++p.failure; }\nfunction reduceRemove(p, v) { if (v.success) --p.success; else --p.failure; }\nfunction reduceInitial(d) { return {failure: 0, success: 0}; }\nfunction orderValue(p) { return p.success / (p.success + p.failure); }\nvar transactionsByDay = transactions.dimension(function(d) { return d.day; }),\n    transactionSuccessByDay = transactionsByDay.group()\n      .reduce(reduceAdd, reduceRemove, reduceInitial)\n      .order(orderValue);\n```\nThis would create daily groups, ordered by success rate, so you could easily list the top ten days by success rate, for instance.\n. I agree about db.remove not being an ideal name.  I don\u2019t see the need for a separate method for removing all records, though, you can simply call db.removeRecords (or whatever we call it) with no filters applied.  The main reason I don\u2019t like db.remove is that it\u2019s inconsistent with dimension.remove and group.remove, and it implies removal of the whole database (dimensions and groups), not just records.\nIf there was a good reason for a separate call to remove all records, I\u2019d call it db.removeAll.\n. Yes, I wish I had named them \u201cdestroy\u201d now\u2026 :)\n. GitHub issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead, though your question sounds more generally related to using D3.\n. Thanks!  Fixed in version 1.3.3.\n. Note that you can already retrieve the filtered records using dimension.top (sorted by the dimension\u2019s natural order).  Is there a particular reason why that wouldn\u2019t be useful in your scenario?\n. > Using dimension.top doesn't work in this case as the filters come from different locations.\nCan you explain what you mean by the filters coming from different locations?  dimension.top(Infinity) does exactly the same as your patch, except that the records would be ordered by the dimension value (in descending order; dimension.bottom(Infinity) orders them in ascending order).  In other words, all filters are applied (including any on the dimension you\u2019re sorting by) before returning the records.\n. Perhaps you\u2019re confusing the behaviour of dimension.top with groups, which exclude their associated dimension\u2019s filter for computing reduce values.\n. @jdarling Read the documentation for dimension.top (or try it for yourself); you\u2019ll see that it returns the records, not the computed dimension values.\n. Thanks, I\u2019ve reproduced this and will submit a patch soon.\n. You could remove all records and then add new ones, though this would require resetting all filters (to select all records for removal).\n. The maximum number of dimensions is 32 at the moment.  There is a proposed fix in #75.\n. These issues are intended for bug reports and feature requests; please post questions like this on a forum like StackOverflow.\n(In answer to your question, see the custom function parseDate in the example, which constructs Date objects using the right portions of the input strings.)\n. I think this is related to Crossfilter\u2019s general limitation of only allowing one set of filters to be active at any time.  I would rather improve the API so that it supports independent sets of filters.  You could then have charts based on one filterset, and perform other operations using a different filterset.\n. I\u2019ve thought about it, but haven\u2019t had time to implement it yet.  Most likely it would be backwards-incompatible, but it would support more powerful queries e.g. union/intersection/exclusion.\n. As I mentioned above, I\u2019d prefer a more general solution; at the moment Crossfilter only allows one set of filters to be active at a time, so adding a separate filter argument for removal alone feels inconsistent.\n. I think we\u2019re talking about the same thing. :)  I wrote:\n\nadding a separate filter argument for removal alone feels inconsistent.\n\nBy \u201cfilter argument\u201d, I\u2019m referring to your \u201ctest function\u201d, i.e. .remove(filterFunction).  I\u2019m not disputing the usefulness of this, but I would prefer a more general solution as it would be more powerful and elegant.  The indexed filter types (filterExact and filterRange) are also much faster than filterFunction, though admittedly this isn\u2019t really important for removal of records.\n. The dimension value accessor must return naturally-orderable values.  If an accessor returns an array, then JavaScript\u2019s relational operations (<, <=, >, >=) will attempt to coerce the array to a number or a string.  I think this coercion will incur a performance penalty, particularly during the sort operation.\nI\u2019d recommend against using an array and returning an appropriate string instead if you really need a composite key.\n. I suggest reading up about how JavaScript performs relational comparisons.  If you want to create a composite key for example, then you need to ensure any numbers are zero-padded since the array would be coerced to a string with comma separators.  It\u2019s better to be explicit and return a string if you want to do this.\n. Closing as I think we\u2019d prefer to keep the API simple.  You can write your own helpers to generate particular map/reduce functions as necessary.\n. Thanks for the contribution, but this is a duplicate of #113, and I think we\u2019d prefer to keep the API simple.\n. Not as far as I know.  Are you saying the issue can be reproduced with the flight times example?  Can you give exact steps to reproduce?\n. Thanks!  Fixed in version 1.3.8.\n. Duplicate of #75.\n. Hello!  Thanks for the contribution.  However, I\u2019m afraid this is a duplicate of existing requests for the same feature: #113, #115, and related #102.  We\u2019ve taken the decision not to extend the API to support this, as we\u2019d prefer to keep it simple.  As noted in these tickets, it\u2019s possible to have a tiny helper function that unpacks an object and makes the appropriate reduce call, if that\u2019s something that you really need.\n. I think the main limitation of crossfilter at the moment is the types of queries it supports.  Essentially, you can only do A & B & C & \u2026 where A, B, C etc. are range queries on distinct ordered dimensions.  It was developed primarily for fast interactive filtering of this specific type of query.  The possibility of generalisation has been discussed elsewhere, and I will work on it when I have time (!), but I\u2019m not sure if there\u2019s really any advantage to adding a high-level query engine at the moment when the low-level primitives are somewhat limited.\nI\u2019m closing as this issue isn\u2019t specifically a bug or feature request for Crossfilter itself (though it is another use case for making the low-level primitives more powerful).\n. Good catch, thanks.  Have you signed the CLA?\n. Good catch.  I have a fix and I\u2019m just working on a test case now.  Thanks!\n. It sounds like @unwiredbrain has the right idea; you can create one dimension per column, and then use dimension.top(1) to retrieve each dimension\u2019s maximum value (while respecting filters applied to all dimensions).\nHowever, you\u2019ll want to grab the lengths:\njs\nvar column0 = data.dimension(function(d) { return d[0].length; });\nCrossfilter is not magical (OK, well just a little!) -- this won\u2019t be faster than looping over all your values and finding the maxima once-only.  However, it will be much faster when filtering is involved, hence the name!\nGitHub is not really the best place to ask for support; the issues are meant for reporting bugs and feature requests. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. This is documented behaviour: incomparable values such as undefined and NaN are not supported and will cause problems.\n. Further information is required to reproduce and diagnose the issue:\n- What kind of data are you sorting?  Does it contain incomparable (NaN or undefined) or mixed types (these are not supported)?\n- Some example code would be helpful.\nFeel free to reopen with this information.\n. These GitHub issues are meant for reporting bugs and feature requests only. You can ask support questions using the crossfilter tag on StackOverflow instead.\n. cnt.length is 4, because there are 4 groups when grouped by type.  However, two of the groups have value 0, indicating that two of the types have zero counts for the current filters.  Groups with zero counts are not excluded, which seems to be your expectation.\n. If you only want non-zero groups, you can simply filter the array of groups:\njs\ncountGroup.top(Infinity).filter(function(d) { return d.value > 0; });\n. As described in the documentation, group.top uses an ordering based on the group\u2019s value (in your example, the counts).  If you want all groups ordered by key, you can use group.all instead.\n. The objects representing groups are part of the API, but you can simply convert them to your own format after grouping, e.g.:\njs\nvalues.map(function(d) {\n  return {key: d.key, size: d.value.size, weight: d.value.weight};\n});\n. Internally, groups are represented as {key, value} objects, so if you want to represent groups differently, you\u2019d either have to modify the internals or simply create your own representation as I\u2019ve suggested above.\n. Seems to work fine for me, perhaps you should post a reproducible example somewhere?  Personally I think it would be simpler to use firstGrouping.top(Infinity) and regroup small groups into \"(other)\" yourself.\n. Ah, sorry about that, perhaps I didn\u2019t test on a large enough sample to reproduce.  You\u2019re right: the group order must be consistent with the dimension\u2019s value order.  This is primarily to allow fast updating of groups internally.  It\u2019s a bit restrictive, but I think it\u2019s best to treat Crossfilter as quite a low-level API rather than a flexible high-level API.  In your case, this is why it would be better to regroup into \u201c(other)\u201d outside of Crossfilter.\n. Thanks!  This went unnoticed for two years and five months.  I think you deserve a prize!\n. Rather than using gulp, since the build process is quite simple I suppose it might be preferable to have a pure Node-based build without relying on heavyweight dependencies.\nWhich new contributor license feature are you referring to?\n. Thanks for the suggested fix.  I opted for a more bitwise approach rather than a comparison operator.  Your fix works fine in this situation, since this branch isn\u2019t taken for more than 16 dimensions (32-bit values), but the comparison operator wouldn\u2019t have worked if the bitwise representation had produced a negative value, which it can do in the 32-bit cases.\n. It\u2019s hard to say without more information.  Any error messages?  What changed ~1 week ago to cause this to happen?\n. ",
    "eventualbuddha": "Out of curiosity, why do you want to sort NaN values?\n. Thanks for the note. I believe this is simply a misunderstanding of the documentation. In your example, the links group definitely is filtered by tokens matching \"Jimmy\", but it contains empty groups (value == 0). That's why you're seeing three results. From the documentation:\n\nIf there are fewer than k groups according to all of the tesseract's filters, then an array smaller than k will be returned. If there are fewer than k non-empty groups, this method may also return empty groups (for example, those with a count of zero).\n\nIn your example, k is Infinity, so all the empty groups will be returned. Using this jsfiddle, I got these results:\n``` js\nlinks.top(Infinity) // no filters\n[\n  {\"key\":\"http://www.engadget.com/2012/03/17/us-navy-lasr-research-facility-builds-robots-not-ray-guns/\",\n   \"value\":20},\n  {\"key\":\"http://feedproxy.google.com/~r/oreilly/radar/atom/~3/VUnm8ikk8a4/encyclopaedia-britannica-copyright-paypal-censorship.html\",\n   \"value\":10},\n  {\"key\":\"http://feeds.arstechnica.com/~r/arstechnica/index/~3/_dcrXs9GTTo/ion-beam-manufacturing-halves-production-cost-of-pv-panels.ars\",\n   \"value\":9}\n]\nlinks.top(Infinity) // filtering token by \"Jimmy\"\n[\n  {\"key\":\"http://www.engadget.com/2012/03/17/us-navy-lasr-research-facility-builds-robots-not-ray-guns/\",\n   \"value\":0},\n  {\"key\":\"http://feedproxy.google.com/~r/oreilly/radar/atom/~3/VUnm8ikk8a4/encyclopaedia-britannica-copyright-paypal-censorship.html\",\n   \"value\":1},\n  {\"key\":\"http://feeds.arstechnica.com/~r/arstechnica/index/~3/_dcrXs9GTTo/ion-beam-manufacturing-halves-production-cost-of-pv-panels.ars\",\n   \"value\":0}\n]\n```\nNote that there are the same number of group results in each but the values are different. Also note that I used console.log(JSON.stringify(...)) because tesseract reuses the groups (I think) so inspecting their values after modifying them by filtering is misleading. If I completely misunderstood, please reopen this issue with a clarification. Thanks!\n. Just ignore the entries with value == 0.\n. I might be misunderstanding, but is there a difference between what you're proposing and simply post-processing the returned array?\njs\n// Array does not have .map in all browsers\ncf.top(k).map(accessor);\n. @gavinpaulkelly Ah, okay. Just checking. I'd encourage you to try out crossfilter as it is and with your proposed change over at http://jsperf.com/. It won't tell you much about the extra storage required by having a duplicate array (except for any GC-related slowdown), but it should be able to answer your question about any speed penalty you might incur by doing the loop twice.\n. This actually is intentional. The prefix + is a shortcut for getting the primitive numeric value of an object. So if, for example, f(v) returned a Date or a String then the + would turn it into a number. For example:\njs\n3 + '9' // '39'\n3 + (+'9') // 12\n. I'm having a hard time grokking the problem. Could you come up with something that doesn't use d3 (only crossfilter) and shows some numbers rather than bars? That might help identify the problem.\n. Seems like we should accept this. Did you just forget to press the big green button, @mbostock?\n. Nice! Might make sense to have tests around this, though I'm not sure exactly what behavior you'd be testing.\n. Out of curiosity, why do you want to sort NaN values?\n. Thanks for the note. I believe this is simply a misunderstanding of the documentation. In your example, the links group definitely is filtered by tokens matching \"Jimmy\", but it contains empty groups (value == 0). That's why you're seeing three results. From the documentation:\n\nIf there are fewer than k groups according to all of the tesseract's filters, then an array smaller than k will be returned. If there are fewer than k non-empty groups, this method may also return empty groups (for example, those with a count of zero).\n\nIn your example, k is Infinity, so all the empty groups will be returned. Using this jsfiddle, I got these results:\n``` js\nlinks.top(Infinity) // no filters\n[\n  {\"key\":\"http://www.engadget.com/2012/03/17/us-navy-lasr-research-facility-builds-robots-not-ray-guns/\",\n   \"value\":20},\n  {\"key\":\"http://feedproxy.google.com/~r/oreilly/radar/atom/~3/VUnm8ikk8a4/encyclopaedia-britannica-copyright-paypal-censorship.html\",\n   \"value\":10},\n  {\"key\":\"http://feeds.arstechnica.com/~r/arstechnica/index/~3/_dcrXs9GTTo/ion-beam-manufacturing-halves-production-cost-of-pv-panels.ars\",\n   \"value\":9}\n]\nlinks.top(Infinity) // filtering token by \"Jimmy\"\n[\n  {\"key\":\"http://www.engadget.com/2012/03/17/us-navy-lasr-research-facility-builds-robots-not-ray-guns/\",\n   \"value\":0},\n  {\"key\":\"http://feedproxy.google.com/~r/oreilly/radar/atom/~3/VUnm8ikk8a4/encyclopaedia-britannica-copyright-paypal-censorship.html\",\n   \"value\":1},\n  {\"key\":\"http://feeds.arstechnica.com/~r/arstechnica/index/~3/_dcrXs9GTTo/ion-beam-manufacturing-halves-production-cost-of-pv-panels.ars\",\n   \"value\":0}\n]\n```\nNote that there are the same number of group results in each but the values are different. Also note that I used console.log(JSON.stringify(...)) because tesseract reuses the groups (I think) so inspecting their values after modifying them by filtering is misleading. If I completely misunderstood, please reopen this issue with a clarification. Thanks!\n. Just ignore the entries with value == 0.\n. I might be misunderstanding, but is there a difference between what you're proposing and simply post-processing the returned array?\njs\n// Array does not have .map in all browsers\ncf.top(k).map(accessor);\n. @gavinpaulkelly Ah, okay. Just checking. I'd encourage you to try out crossfilter as it is and with your proposed change over at http://jsperf.com/. It won't tell you much about the extra storage required by having a duplicate array (except for any GC-related slowdown), but it should be able to answer your question about any speed penalty you might incur by doing the loop twice.\n. This actually is intentional. The prefix + is a shortcut for getting the primitive numeric value of an object. So if, for example, f(v) returned a Date or a String then the + would turn it into a number. For example:\njs\n3 + '9' // '39'\n3 + (+'9') // 12\n. I'm having a hard time grokking the problem. Could you come up with something that doesn't use d3 (only crossfilter) and shows some numbers rather than bars? That might help identify the problem.\n. Seems like we should accept this. Did you just forget to press the big green button, @mbostock?\n. Nice! Might make sense to have tests around this, though I'm not sure exactly what behavior you'd be testing.\n. ",
    "iros": "Major +1 to this. \nHere is an example of how the filtering breaks if there are NaNs in the data to begin with:\nhttp://jsfiddle.net/iros/wc8ba/3/\n. It might be nice to have a specific interface for that purpose. I find myself retrieving those two all the time and it would just make things that much cleaner.\n. Major +1 to this. \nHere is an example of how the filtering breaks if there are NaNs in the data to begin with:\nhttp://jsfiddle.net/iros/wc8ba/3/\n. It might be nice to have a specific interface for that purpose. I find myself retrieving those two all the time and it would just make things that much cleaner.\n. ",
    "john-guerra": "Thanks for this addition I really need it on my code, however I think there is still an error when you have half your numer of items or more NaNs in your data. I think this illustrates it (copying @iros jsfiddle)\nhttp://jsfiddle.net/wc8ba/53/\n. @jasondavies It seems that the problem persists if the number of NaNs is big enough, check this case:\nhttp://jsfiddle.net/wc8ba/94/\nAm I missing something?\nThanks for looking at this, it would be great to get this fixed, I need it desperately for my code, so I offer my help in whatever I can\n. @jasondavies you sir have just won a big thank you note in my PhD dissertation! hehehe Thanks a lot!\n. hehehe, yes I guess that is a better name :)\n. @jasondavies you were right, the problem is with the nan values\n. Thanks for this addition I really need it on my code, however I think there is still an error when you have half your numer of items or more NaNs in your data. I think this illustrates it (copying @iros jsfiddle)\nhttp://jsfiddle.net/wc8ba/53/\n. @jasondavies It seems that the problem persists if the number of NaNs is big enough, check this case:\nhttp://jsfiddle.net/wc8ba/94/\nAm I missing something?\nThanks for looking at this, it would be great to get this fixed, I need it desperately for my code, so I offer my help in whatever I can\n. @jasondavies you sir have just won a big thank you note in my PhD dissertation! hehehe Thanks a lot!\n. hehehe, yes I guess that is a better name :)\n. @jasondavies you were right, the problem is with the nan values\n. ",
    "jeroen": "Great, thank you so much! Hope to see this make its way into the master soon!\n. This would be great. The emit function is also used in mongo map/reduce. \nThe classic example is to use map/reduce for e.g. creating a wordcloud from records containing text sentences, so every sentence needs to get mapped to multiple words.\n. I tried this, and data.total.filter([0, 100], 190, [200, 300]); works as expected, however after adding this filter, the filters on the other dimensions didn't work anymore?\n. Ah Thanks. Hope it can be merged into the master branch soon.\n. @jasondavies @mbostock I updated the jsfiddle to use Jason's branch, but it still returns incorrect results?\nhttp://jsfiddle.net/Cr44L/\n. Thanks for looking at this. It seams that each of the fields is counted incorrectly. Can we reopen this issue  @mbostock?\n. Thanks for looking into this. I think putting some effort in making sure missing values are handled gracefully is worth wile and will pay off in the long run. Especially in javascript where there are no strong-typed structures, and data records might literally contain anything, null or NaN values can easily arise. \nI don't think it is very important to maintain top(Infinity).reverse() === bottom(Infinity). Actually, if this would be the case, there wouldn't be a need for both top() and bottom(). The sorting behavior of R has proven to make a good default, in the sense of the principle of least surprise. The behavior of putting null values at the top on the other hand is, I think, quite unexpected.  \nIn R, the sum function has an argument on how to deal with NA. The default in R is to be safe. Perhaps in javascript, ignoring missing values makes a better default.\nR> c(1,3,NA,5,6)\n[1]  1  3 NA  5  6\nR> sum(c(1,3,NA,5,6))\n[1] NA\nR> sum(c(1,3,NA,5,6), na.rm=TRUE)\n[1] 15\n. @jasondavies Could you explain how I can do the equivalent of top() on a dimension in order to get the largest non NA value?\n. Is there an alternative way or workaround to get the top n records for a given dimension, where unorderable values are treated as -Infinity?\n. Great, thank you so much! Hope to see this make its way into the master soon!\n. This would be great. The emit function is also used in mongo map/reduce. \nThe classic example is to use map/reduce for e.g. creating a wordcloud from records containing text sentences, so every sentence needs to get mapped to multiple words.\n. I tried this, and data.total.filter([0, 100], 190, [200, 300]); works as expected, however after adding this filter, the filters on the other dimensions didn't work anymore?\n. Ah Thanks. Hope it can be merged into the master branch soon.\n. @jasondavies @mbostock I updated the jsfiddle to use Jason's branch, but it still returns incorrect results?\nhttp://jsfiddle.net/Cr44L/\n. Thanks for looking at this. It seams that each of the fields is counted incorrectly. Can we reopen this issue  @mbostock?\n. Thanks for looking into this. I think putting some effort in making sure missing values are handled gracefully is worth wile and will pay off in the long run. Especially in javascript where there are no strong-typed structures, and data records might literally contain anything, null or NaN values can easily arise. \nI don't think it is very important to maintain top(Infinity).reverse() === bottom(Infinity). Actually, if this would be the case, there wouldn't be a need for both top() and bottom(). The sorting behavior of R has proven to make a good default, in the sense of the principle of least surprise. The behavior of putting null values at the top on the other hand is, I think, quite unexpected.  \nIn R, the sum function has an argument on how to deal with NA. The default in R is to be safe. Perhaps in javascript, ignoring missing values makes a better default.\nR> c(1,3,NA,5,6)\n[1]  1  3 NA  5  6\nR> sum(c(1,3,NA,5,6))\n[1] NA\nR> sum(c(1,3,NA,5,6), na.rm=TRUE)\n[1] 15\n. @jasondavies Could you explain how I can do the equivalent of top() on a dimension in order to get the largest non NA value?\n. Is there an alternative way or workaround to get the top n records for a given dimension, where unorderable values are treated as -Infinity?\n. ",
    "Mortimerp9": "this still seems to happen when using \ncrossfilter.dimension(function callback(pt) {\n    //return undefined\n});\nIt was a bug in my code that made this callback return undefined, but the stack overflow error is definitely not very helpful in finding out what's going on.\n. Sorry if I wasn't clear, I have code in that callback that sometimes\nreturns undefined, this makes the quicksort call go in a infinite recursion\nthat blows the stack.\nWhile the callback should avoid returning undefined, it would be good if\ncrossfilter guarded against it and threw a better error /warning as\ndebugging the stack overflow deep in quicksort is not the  most\nstraightforward thing.\nOn Apr 21, 2015 4:14 PM, \"Tom Neyland\" notifications@github.com wrote:\n\n@Mortimerp9 https://github.com/Mortimerp9\ncrossfilter.dimension(function callback(pt) {\n});\nReturning nothing causes the function to implicitly return 'undefined'\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/pull/3#issuecomment-94968958.\n. this still seems to happen when using \n\ncrossfilter.dimension(function callback(pt) {\n    //return undefined\n});\nIt was a bug in my code that made this callback return undefined, but the stack overflow error is definitely not very helpful in finding out what's going on.\n. Sorry if I wasn't clear, I have code in that callback that sometimes\nreturns undefined, this makes the quicksort call go in a infinite recursion\nthat blows the stack.\nWhile the callback should avoid returning undefined, it would be good if\ncrossfilter guarded against it and threw a better error /warning as\ndebugging the stack overflow deep in quicksort is not the  most\nstraightforward thing.\nOn Apr 21, 2015 4:14 PM, \"Tom Neyland\" notifications@github.com wrote:\n\n@Mortimerp9 https://github.com/Mortimerp9\ncrossfilter.dimension(function callback(pt) {\n});\nReturning nothing causes the function to implicitly return 'undefined'\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/pull/3#issuecomment-94968958.\n. \n",
    "TomNeyland": "@Mortimerp9 \ncrossfilter.dimension(function callback(pt) {\n});\nReturning nothing causes the function to implicitly return undefined\n. +1\n. @jasondavies @mbostock Can you chime in on how you feel about this? I'd be willing to put together a pull request if this feature sounds good to you.\n. @Rodeoclash It's certainly not an anti-pattern? I mean I don't know what you were doing personally but there is nothing fishy with reporting back the current state of the filter.\n. @Mortimerp9 \ncrossfilter.dimension(function callback(pt) {\n});\nReturning nothing causes the function to implicitly return undefined\n. +1\n. @jasondavies @mbostock Can you chime in on how you feel about this? I'd be willing to put together a pull request if this feature sounds good to you.\n. @Rodeoclash It's certainly not an anti-pattern? I mean I don't know what you were doing personally but there is nothing fishy with reporting back the current state of the filter.\n. ",
    "manojgn": "Hi guys, I am a great fan of crossfilter and have been using this in my app. I hit this exact same issue but I dont see the above fix in 1.3.12. Is it not merged or am I missing something ?\n. Hi guys, I am a great fan of crossfilter and have been using this in my app. I hit this exact same issue but I dont see the above fix in 1.3.12. Is it not merged or am I missing something ?\n. ",
    "wjbuys": "+1: This is essential for working with qualitative dimensions. Perhaps that should be a first-class concept: a dimension with a low cardinality and weakly ordered values.\n. +1: This is essential for working with qualitative dimensions. Perhaps that should be a first-class concept: a dimension with a low cardinality and weakly ordered values.\n. ",
    "michael": "Any updates on this? I need it! Very urgent :)\nIn terms of the API, why not allowing value accessing functions returning arrays?\n``` js\nvar countries = crossfilter([\n  {name: \"USA\", languages: [\"Spanish\", \"English\", \"Chinese\", \"French\"]},\n  {name: \"Canada\", languages: [\"French\", \"English\"]}\n]);\ncountriesByLanguage = countries.dimension(function(d) {return d.languages });\ncountriesByLanguage.filter('English');\ncountriesByLanguage.top(Infinity) // => [USA, Canada]\n```\nFYI: I'm currently stripping down Data.js, in order to make it fast and to remove unneeded complexity. I'm going to drop the Data.Hash datastructures in favor of native Javascript primitives (arrays, objects). At the end of the day it should no longer be a Data Manipulation Library, but a Data Representation Library, letting users use Crossfilter for the sake of filtering.\n. Any updates on this? I need it! Very urgent :)\nIn terms of the API, why not allowing value accessing functions returning arrays?\n``` js\nvar countries = crossfilter([\n  {name: \"USA\", languages: [\"Spanish\", \"English\", \"Chinese\", \"French\"]},\n  {name: \"Canada\", languages: [\"French\", \"English\"]}\n]);\ncountriesByLanguage = countries.dimension(function(d) {return d.languages });\ncountriesByLanguage.filter('English');\ncountriesByLanguage.top(Infinity) // => [USA, Canada]\n```\nFYI: I'm currently stripping down Data.js, in order to make it fast and to remove unneeded complexity. I'm going to drop the Data.Hash datastructures in favor of native Javascript primitives (arrays, objects). At the end of the day it should no longer be a Data Manipulation Library, but a Data Representation Library, letting users use Crossfilter for the sake of filtering.\n. ",
    "zackham": "Can someone more familiar with the codebase comment on the feasibility of doing this?\n. If you need IE7/8 support you can try my IE8 compatible fork.  Don't expect to use D3 though, but if you just need crossfilter check it out: https://github.com/zackham/crossfilter/tree/ie8compatible\n. This should work in IE7 I just haven't tested it yet.\n. I'm taking a stab at this right now.  Leaning toward the generic solution, but we'll see.  I don't think we need support for intersections? The result of an intersection is going to be something that can be passed directly to filterRange today.  Also, if we could enable a way to clone a dimension, you can perform intersections by applying the different filters to each dimension copy.\nFor the union of multiple filters, I'm just going to work on letting filter() take multiple arguments.\n. beefsoup,\nThanks for the second set of eyes.  I was not expanding the hi0/lo0 range to include the additional ranges.  This is fixed now and I also modified the test.\n. FYI just filled out the contributor agreement, didn't notice it until now.\n. Can someone more familiar with the codebase comment on the feasibility of doing this?\n. If you need IE7/8 support you can try my IE8 compatible fork.  Don't expect to use D3 though, but if you just need crossfilter check it out: https://github.com/zackham/crossfilter/tree/ie8compatible\n. This should work in IE7 I just haven't tested it yet.\n. I'm taking a stab at this right now.  Leaning toward the generic solution, but we'll see.  I don't think we need support for intersections? The result of an intersection is going to be something that can be passed directly to filterRange today.  Also, if we could enable a way to clone a dimension, you can perform intersections by applying the different filters to each dimension copy.\nFor the union of multiple filters, I'm just going to work on letting filter() take multiple arguments.\n. beefsoup,\nThanks for the second set of eyes.  I was not expanding the hi0/lo0 range to include the additional ranges.  This is fixed now and I also modified the test.\n. FYI just filled out the contributor agreement, didn't notice it until now.\n. ",
    "christophe-g": "+1, agree with wjbuys above.\nThe lib is fantastic, but it really need support multiple values for being used in most real-world cases dealing with qualitative dimension. \nIs there any chance this feature will be integrated one day ?\nCheers,\nC.\n. Hi Martin\nThanks for the feedback\n\nCrossfilter looks to work normally after this. Did you notice any issues after having remove an element from the initial crossfilter ?\n\nWell actually, I think I did - but I am not using this plugin anymore. From what I can remember, the problem lies withing groups. There should be a group level listener when data is removed.\nSomething like this might work: \nin dimension: \njs\n   onDataRemoveListeners = []\nin group: \n``` js\n...\n      filterListeners.push(update);\n      onDataRemoveListeners.push(onDataRemove);\n      indexListeners.push(add);\n...\n       // recompute the group when data is removed. \n       function onDataRemove() {\n           resetNeeded = true;\n           k = 0; \n           add(values, index,0,n)\n       };\n```\nI am pretty sure the renown owner of this repo will have a much better way to handle data removing ;) \nCheers\nC.\n. Pretty cool ;) \nWrote this https://github.com/NickQiZhu/dc.js/pull/91 to serve the same purpose !\nCheers,\nC.\n. +1, agree with wjbuys above.\nThe lib is fantastic, but it really need support multiple values for being used in most real-world cases dealing with qualitative dimension. \nIs there any chance this feature will be integrated one day ?\nCheers,\nC.\n. Hi Martin\nThanks for the feedback\n\nCrossfilter looks to work normally after this. Did you notice any issues after having remove an element from the initial crossfilter ?\n\nWell actually, I think I did - but I am not using this plugin anymore. From what I can remember, the problem lies withing groups. There should be a group level listener when data is removed.\nSomething like this might work: \nin dimension: \njs\n   onDataRemoveListeners = []\nin group: \n``` js\n...\n      filterListeners.push(update);\n      onDataRemoveListeners.push(onDataRemove);\n      indexListeners.push(add);\n...\n       // recompute the group when data is removed. \n       function onDataRemove() {\n           resetNeeded = true;\n           k = 0; \n           add(values, index,0,n)\n       };\n```\nI am pretty sure the renown owner of this repo will have a much better way to handle data removing ;) \nCheers\nC.\n. Pretty cool ;) \nWrote this https://github.com/NickQiZhu/dc.js/pull/91 to serve the same purpose !\nCheers,\nC.\n. ",
    "RandomEtc": "As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. #13 and #5 are currently in the 1.3 Milestone - organized by @jasondavies who has better idea of the dependencies than I do - that puts it a couple of releases off but no big API changes are in the way: https://github.com/square/crossfilter/issues/milestones\nWe both just took over maintenance of the project last week, so bear with us but things should be moving again soon!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Sorry @jasondavies!\n. Also worth trying an object if you have more/dynamic terms to match:\njavascript\nvar query = { foo: 1, bar: 1 };\ndimension.filter(function(d) { return d in query; });\n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. :+1: LGTM.\n@mbostock do you want to merge and bump versions, or add me and Jason to the npm package so we can take care of it?\n. Oh ha, good catch. Makes sense :)\n. I can confirm this is a bug as well. Crossfilter 1.1.1 shows the MSY-HOU flight with delay 29 when the filter is set to include the maximum delay of 150. If the filter is nudged down to 149.something then that flight is not shown any more. I note there are two MSY-HOU flights with delay 29 in the data-set, could that have something to do with it?\nI can look into this some more later this week - in the meantime @jasondavies any idea?\n. Update: the erroneous flight is the last row in the data. There is also a blank line at the end of the file. Removing the blank line fixes the bug.\nI assume this is something to do with the new null/NaN handling?\n. @asherkin the new release has different support for the handling of NaN and null values, so that must what is causing the issue. We'll figure it out :)\n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Check for blank lines, null values, undefined values and NaN values in your input?\n. Is your number column comma-separated?\n```\n\nvar a = '100'\nundefined\n+a\n100\nvar b = '1,000'\nundefined\n+b\nNaN\n```\n. It sounded like it wasn't just a performance problem - perhaps @optimuspaul can provide a failing test case for @sciyoshi to take a look at?\n. Thanks all for reviving this issue. I'm following along but don't have much bandwidth to contribute personally.\n\nI'm happy to review/merge/publish (ideally with +1 from Jason or Mike) once failing tests are provided and addressed. It's probably our most common feature request, and 5% slowdown for 1M items seems worth it if we can verify that on today's common browsers.\nThanks again!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. The results of a Cube query are delivered as JSON and the input to Crossfilter is JSON. I'm not sure there's anything more to it?\nRegardless, please post on Stack Overflow or the Cube Google Group for questions like this. If you try it and run into bugs feel free to post back here.\n. Apologies that nobody is responding to your commit. Sometimes things slip through, it's not personal. It's also reasonable to follow up and ask what's up :)\nLooking at the commit it's hard to tell what it does. Can you give an example of what it does and why it's needed?\nDigging in a bit (I'm not overly familiar with this code) it seems like you could just add accessor: value to the returned object, and you don't need a separate function. But since you pass value into the dimension yourself, I'm not sure why you need the dimension to give it back to you?\n. I'm confused...\nIn the API reference we create a crossfilter for payments:\njavascript\nvar payments = crossfilter([\n  {date: \"2011-11-14T16:17:54Z\", quantity: 2, total: 190, tip: 100, type: \"tab\"},\n  // ...\n  {date: \"2011-11-14T17:29:52Z\", quantity: 1, total: 200, tip: 100, type: \"visa\"}\n]);\nAnd then a dimension for total:\njavascript\nvar paymentsByTotal = payments.dimension(function(d) { return d.total; });\nBreaking things down...\nYou're saying you'd like to call paymentsByTotal.accessor(d) to return d.total - correct?\nThis would achieve the same as doing:\njavascript\nvar paymentTotal = function(d) { return d.total; };\nvar paymentsByTotal = payments.dimension(paymentTotal);\nAnd calling paymentTotal(d) - correct?\nSorry to de-rail, but I don't understand how paymentsByTotal.accessor = 1 would do anything other than replace the reference to the accessor function with 1. It wouldn't break paymentTotal. \nThis is where example code would be really helpful. Perhaps you have an interesting value function for your dimension?\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for missing this one too. I'm not the most familiar with the cross-filter internals, so I defer to @jasondavies @mbostock and others on the specific approach here.\nFrom a process perspective - thanks for adding a test, and yes please, an update to 1.3.x would make it much more likely the PR will be merged. We don't actively maintain old branches.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Speaking as a maintainer: \nI'd happily take a pull request, even a broken one, and help you try to fix it. Showing us what doesn't work can be helpful too :)\nCan you point me at a good tutorial or documentation for the component format so I can understand how it's used and if it would benefit crossfilter in addition to the existing package.json and npm packages?\n. Thanks for sharing - this is really helpful. We'll take a look!\n. @christopherobin  please can you rebase this PR against the current crossfilter master, sign our individual contributor license agreement, and fix the error @mbostock identified when loading the script in a browser? \nAlso, can you confirm that component.json needs to include index.js? I think that's just a convenience for node imports, but I'm not familiar with how components work.\n. Thanks! I think this is fine now, if it's not we'll fix it. I merged and published to npm as 1.3.7.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Sorry - your last comment seemed to be directing people to a new discussion so I didn't have anything else to add.\nSee #151 for discussion of future of Crossfilter. I've updated square/crossfilter's README to indicate that the crossfilter org will be actively maintaining a fork. I figured you were already aware since you linked to reductio. Apologies for misunderstanding.\n. Apologies for silence here. Please ask questions on http://stackoverflow.com/questions/tagged/crossfilter and note that as discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. What about:\njavascript\nfunction reduceAddAvg(attr) {\n  return function(p,v) {\n    ++p.count\n    p.sum += v[attr];\n    p.avg = p.sum/p.count;\n    return p;\n  };\n}\nfunction reduceRemoveAvg(attr) {\n  return function(p,v) {\n    --p.count\n    p.sum -= v[attr];\n    p.avg = p.sum/p.count;\n    return p;\n  };\n}\nfunction reduceInitAvg() {\n  return {count:0, sum:0, avg:0};\n}\nvar statesAvgGroup = statesAvgDimension.group().reduce(reduceAddAvg('savings'), reduceRemoveAvg('savings'), reduceInitAvg);\nvar statesAvgGroup = statesAvgDimension.group().reduce(reduceAddAvg('cost'), reduceRemoveAvg('cost'), reduceInitAvg);\n// ... and so on\nWould that work?\n. Great! I added a note linking here from https://github.com/square/crossfilter/wiki/API-Reference#wiki-group_reduce\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Neat! Thanks for trying this out. I think we can make it work. Do you have time for a small iteration?\nOn my screen, at around 800px wide, the Crossfilter heading is under the Time of Day chart. Can you adjust the font size when the screen is narrow?\nIf you're editing it, can you break the lines in the HTML file so it's easier to review? And please use spaces not tabs (sorry!).\nIf possible, at wider screen sizes it would be nice to have some margins on the sides so that the content can breathe a bit. Something a cross between what you have at https://drahmel.github.io/crossfilter/ and what we have today at https://square.github.io/crossfilter/ would be great - my monitor is 2560px wide, and I regularly browse at ~1800px :)\nLastly, can you sign our electronic contributor agreement so I can safely merge your changes without talking to a lawyer? https://spreadsheets.google.com/spreadsheet/viewform?formkey=dDViT2xzUHAwRkI3X3k5Z0lQM091OGc6MQ&ndplr=1\n. Great. I'm sometimes not able to respond this quickly, but I will try to keep it moving.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. @esjewett for folks still following along, I'm assuming discussion is continuing at crossfilter/crossfilter#6? Closing this out along with all others.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. @RandomInsano you don't need new there in your ReduceSum object, but you do need to return something from the factory, or attach those add/remove/init methods to the function's prototype. I would do:\njavascript\nfunction reduceSum(attr){\n  return {\n    add: function(p, v) {\n      return p += v[attr];\n    },\n    remove: function(p, v) {\n      return p -= v[attr];\n    },\n    init: function() {\n      return 0;\n    }\n  };\n}\nvar rs = reduceSum('value')\nvar statesAvgGroup = statesAvgDimension.group().reduce(rs.add, rs.remove, rs.init);\nThat should work - no modifications to crossfilter needed!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Support for WebWorkers is discussed in https://github.com/crossfilter/crossfilter/issues/22  \nPlease take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for these!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. (deleted my comment since @jasondavies already pointed at an equivalent ticket)\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Fair question, thanks for asking!\nTrue: nobody at Square is actively maintaining this library right now, and we don't use it in the Square Dashboard where it was originally deployed (we moved all computation server side again). \nThat doesn't mean nobody is using it. I'll ask around and see if someone is willing to help triage issues and merge down good PRs. If not, we'll look for a different solution (perhaps a couple more external maintainers to help Jason out!) \n. I'm the Square maintainer for crossfilter, and @jasondavies is also a maintainer who independently merges PRs and new releases. In 99% of cases over the last 2+ years I have just deferred to Jason.\nStill asking around internally at Square for volunteers (not opposed to more outside maintainers but it's more work to manage, so starting locally). Give us a day or two to figure it out.\n@gordonwoodhull I will also ask about the agreement in case there's room for an update there. Is any agreement an impediment, or something about our specific one? Understand either way, just curious if it can be fixed.\n. On #109 it seems like there was some support from Jason already, but no code. I would create a branch and try it, and get buy-in from other contributors. Forgiveness not permission. It would mean cutting a major release number if it breaks the API, but that shouldn't be an issue if the pay-off is worth it.\n92 certainly looks like cause for concern since I've ignored it for 18 months. Apologies for that. Folks who are following along, it would be helpful to review and test this PR if it's a strong candidate for merging. I have no opinion on it except what I already shared :)\n75 needs reviewing, verifying and benchmarking again following @sciyoshi's fixes. Please help.\n. I freely admit there is no active maintenance from Square on the project at this time. I'm able to drop-in to discussions like this quickly, and can provide stylistic and process guidance, but I can't commit to properly reviewing PRs if that's what it takes to unblock them.\nStill asking around internally, that will give us the info we need to decide what happens next. I'm open to \"blessing\" a fork as well, which is what we did with Cube when it became clear we weren't going to actively maintain that.\n. Many reasons. Some including: data volume, mobile performance, parity between results on different reporting platforms (web, app, email, etc).\n. No volunteers inside of Square. I'm not sure of the best steps forward, I'll find a time to swap notes with @jasondavies and see if we can identify one or two people to assist.\n. Aside: it sounds like a lot of contributors are finding crossfilter via dc.js? We've also had several issues filed here that turned out to be dc.js issues. Would the dc.js maintainers consider forking crossfilter for their purposes and accepting patches directly there?\n. Sorry for the delayed update here.\nI spoke with Jason and we're in agreement at a high level: as @gordonwoodhull speculated above, we consider crossfilter essentially \"finished\" at this point (being targeted at the use-case on the demo page: linked charts of dimensions from a simple flat dataset). I share this as plainly as possible so you know why Jason and I are not picking up the pace on PRs on this repo.\nWe completely agree that there are possible extensions and API improvements that would be worth putting into a \"crossfilter\" v2. But we also agree that if we were doing that we would probably write something from scratch using the lessons learned from v1. Neither of us is planning to start such a project.\nI am investigating if any of Square's other projects have ever spun out into a github org. I doubt that it will happen - it's difficult because of our requirement for contributor agreements. It's more likely we would encourage contributors to organize among themselves (something like \"crossfilter-contrib\" would make it clear it's not Square's thing, and could always be renamed in future). If the participants on this thread want to go ahead and do that, it's probably the best way to focus the energies and enthusiasms of the group.\n. Just closing the loop here... \nSelf-organizing an org makes sense. That's what I would have done. I would personally prefer it be called something else (add \"-contrib\" or something) but I'm not speaking for Square here. Speaking for Square - please unpublish http://crossfilter.github.io/crossfilter/ and/or remove the Square logo from it and make it clearer that it's a fork. It's probably best to remove the gh-pages branch from the fork until you're ready to cut a new release. Likewise please update the README to not be written as Square. Thanks!\nBefore linking from Square's crossfilter repo I'd like to ensure that meaningful additions/features are happening - the forks of Cube were significantly modified/enhanced before we linked to them. Keep me posted once the initial merges settle, I'll make it happen!\nThanks for understanding and keeping the energy going!\n. @derekperkins @tannerlinsley @gordonwoodhull et al - thank you for keeping the dream alive. I've chosen option 2 as the easiest for now, and added a note to the README on the square version at https://github.com/square/crossfilter/blob/master/README.md\nI have asked internally about unlocking/transferring the crossfilter npm and bower packages so that newer versions can be published there, and about transferring the repo itself to allow github to redirect everyone. But I make no promises about following through with this - please act as if it won't happen, I'll ping you if the situation changes :)\nHopefully it is clear that crossfilter/crossfilter is the home of active improvement. Thanks to all who weighed in on this thread. Please take further discussion to an issue there! :chart_with_upwards_trend: :raised_hands: \n. Don't thank me for sitting on it for 3 years followed by a flurry of copy-paste issue closing :grimacing: \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. Please ask questions on http://stackoverflow.com/questions/tagged/crossfilter and note that as discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. This repository is no longer maintained. Please ask in https://github.com/crossfilter/crossfilter or try http://stackoverflow.com/questions/tagged/crossfilter \u2014 thanks!\n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. #13 and #5 are currently in the 1.3 Milestone - organized by @jasondavies who has better idea of the dependencies than I do - that puts it a couple of releases off but no big API changes are in the way: https://github.com/square/crossfilter/issues/milestones\nWe both just took over maintenance of the project last week, so bear with us but things should be moving again soon!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Sorry @jasondavies!\n. Also worth trying an object if you have more/dynamic terms to match:\njavascript\nvar query = { foo: 1, bar: 1 };\ndimension.filter(function(d) { return d in query; });\n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. :+1: LGTM.\n@mbostock do you want to merge and bump versions, or add me and Jason to the npm package so we can take care of it?\n. Oh ha, good catch. Makes sense :)\n. I can confirm this is a bug as well. Crossfilter 1.1.1 shows the MSY-HOU flight with delay 29 when the filter is set to include the maximum delay of 150. If the filter is nudged down to 149.something then that flight is not shown any more. I note there are two MSY-HOU flights with delay 29 in the data-set, could that have something to do with it?\nI can look into this some more later this week - in the meantime @jasondavies any idea?\n. Update: the erroneous flight is the last row in the data. There is also a blank line at the end of the file. Removing the blank line fixes the bug.\nI assume this is something to do with the new null/NaN handling?\n. @asherkin the new release has different support for the handling of NaN and null values, so that must what is causing the issue. We'll figure it out :)\n. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Check for blank lines, null values, undefined values and NaN values in your input?\n. Is your number column comma-separated?\n```\n\nvar a = '100'\nundefined\n+a\n100\nvar b = '1,000'\nundefined\n+b\nNaN\n```\n. It sounded like it wasn't just a performance problem - perhaps @optimuspaul can provide a failing test case for @sciyoshi to take a look at?\n. Thanks all for reviving this issue. I'm following along but don't have much bandwidth to contribute personally.\n\nI'm happy to review/merge/publish (ideally with +1 from Jason or Mike) once failing tests are provided and addressed. It's probably our most common feature request, and 5% slowdown for 1M items seems worth it if we can verify that on today's common browsers.\nThanks again!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. The results of a Cube query are delivered as JSON and the input to Crossfilter is JSON. I'm not sure there's anything more to it?\nRegardless, please post on Stack Overflow or the Cube Google Group for questions like this. If you try it and run into bugs feel free to post back here.\n. Apologies that nobody is responding to your commit. Sometimes things slip through, it's not personal. It's also reasonable to follow up and ask what's up :)\nLooking at the commit it's hard to tell what it does. Can you give an example of what it does and why it's needed?\nDigging in a bit (I'm not overly familiar with this code) it seems like you could just add accessor: value to the returned object, and you don't need a separate function. But since you pass value into the dimension yourself, I'm not sure why you need the dimension to give it back to you?\n. I'm confused...\nIn the API reference we create a crossfilter for payments:\njavascript\nvar payments = crossfilter([\n  {date: \"2011-11-14T16:17:54Z\", quantity: 2, total: 190, tip: 100, type: \"tab\"},\n  // ...\n  {date: \"2011-11-14T17:29:52Z\", quantity: 1, total: 200, tip: 100, type: \"visa\"}\n]);\nAnd then a dimension for total:\njavascript\nvar paymentsByTotal = payments.dimension(function(d) { return d.total; });\nBreaking things down...\nYou're saying you'd like to call paymentsByTotal.accessor(d) to return d.total - correct?\nThis would achieve the same as doing:\njavascript\nvar paymentTotal = function(d) { return d.total; };\nvar paymentsByTotal = payments.dimension(paymentTotal);\nAnd calling paymentTotal(d) - correct?\nSorry to de-rail, but I don't understand how paymentsByTotal.accessor = 1 would do anything other than replace the reference to the accessor function with 1. It wouldn't break paymentTotal. \nThis is where example code would be really helpful. Perhaps you have an interesting value function for your dimension?\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for missing this one too. I'm not the most familiar with the cross-filter internals, so I defer to @jasondavies @mbostock and others on the specific approach here.\nFrom a process perspective - thanks for adding a test, and yes please, an update to 1.3.x would make it much more likely the PR will be merged. We don't actively maintain old branches.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Speaking as a maintainer: \nI'd happily take a pull request, even a broken one, and help you try to fix it. Showing us what doesn't work can be helpful too :)\nCan you point me at a good tutorial or documentation for the component format so I can understand how it's used and if it would benefit crossfilter in addition to the existing package.json and npm packages?\n. Thanks for sharing - this is really helpful. We'll take a look!\n. @christopherobin  please can you rebase this PR against the current crossfilter master, sign our individual contributor license agreement, and fix the error @mbostock identified when loading the script in a browser? \nAlso, can you confirm that component.json needs to include index.js? I think that's just a convenience for node imports, but I'm not familiar with how components work.\n. Thanks! I think this is fine now, if it's not we'll fix it. I merged and published to npm as 1.3.7.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Sorry - your last comment seemed to be directing people to a new discussion so I didn't have anything else to add.\nSee #151 for discussion of future of Crossfilter. I've updated square/crossfilter's README to indicate that the crossfilter org will be actively maintaining a fork. I figured you were already aware since you linked to reductio. Apologies for misunderstanding.\n. Apologies for silence here. Please ask questions on http://stackoverflow.com/questions/tagged/crossfilter and note that as discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. What about:\njavascript\nfunction reduceAddAvg(attr) {\n  return function(p,v) {\n    ++p.count\n    p.sum += v[attr];\n    p.avg = p.sum/p.count;\n    return p;\n  };\n}\nfunction reduceRemoveAvg(attr) {\n  return function(p,v) {\n    --p.count\n    p.sum -= v[attr];\n    p.avg = p.sum/p.count;\n    return p;\n  };\n}\nfunction reduceInitAvg() {\n  return {count:0, sum:0, avg:0};\n}\nvar statesAvgGroup = statesAvgDimension.group().reduce(reduceAddAvg('savings'), reduceRemoveAvg('savings'), reduceInitAvg);\nvar statesAvgGroup = statesAvgDimension.group().reduce(reduceAddAvg('cost'), reduceRemoveAvg('cost'), reduceInitAvg);\n// ... and so on\nWould that work?\n. Great! I added a note linking here from https://github.com/square/crossfilter/wiki/API-Reference#wiki-group_reduce\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Neat! Thanks for trying this out. I think we can make it work. Do you have time for a small iteration?\nOn my screen, at around 800px wide, the Crossfilter heading is under the Time of Day chart. Can you adjust the font size when the screen is narrow?\nIf you're editing it, can you break the lines in the HTML file so it's easier to review? And please use spaces not tabs (sorry!).\nIf possible, at wider screen sizes it would be nice to have some margins on the sides so that the content can breathe a bit. Something a cross between what you have at https://drahmel.github.io/crossfilter/ and what we have today at https://square.github.io/crossfilter/ would be great - my monitor is 2560px wide, and I regularly browse at ~1800px :)\nLastly, can you sign our electronic contributor agreement so I can safely merge your changes without talking to a lawyer? https://spreadsheets.google.com/spreadsheet/viewform?formkey=dDViT2xzUHAwRkI3X3k5Z0lQM091OGc6MQ&ndplr=1\n. Great. I'm sometimes not able to respond this quickly, but I will try to keep it moving.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. @esjewett for folks still following along, I'm assuming discussion is continuing at crossfilter/crossfilter#6? Closing this out along with all others.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. @RandomInsano you don't need new there in your ReduceSum object, but you do need to return something from the factory, or attach those add/remove/init methods to the function's prototype. I would do:\njavascript\nfunction reduceSum(attr){\n  return {\n    add: function(p, v) {\n      return p += v[attr];\n    },\n    remove: function(p, v) {\n      return p -= v[attr];\n    },\n    init: function() {\n      return 0;\n    }\n  };\n}\nvar rs = reduceSum('value')\nvar statesAvgGroup = statesAvgDimension.group().reduce(rs.add, rs.remove, rs.init);\nThat should work - no modifications to crossfilter needed!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Support for WebWorkers is discussed in https://github.com/crossfilter/crossfilter/issues/22  \nPlease take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for these!\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. (deleted my comment since @jasondavies already pointed at an equivalent ticket)\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please consider rebasing and opening your PR there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Thanks for your contributions and sorry for silence on this side. As discussed in #151 an active fork is being developed in a new Crossfilter Organization. Please take further discussion there (if you haven't already) where it should be warmly welcomed by the new maintainers. Cheers! \n. Fair question, thanks for asking!\nTrue: nobody at Square is actively maintaining this library right now, and we don't use it in the Square Dashboard where it was originally deployed (we moved all computation server side again). \nThat doesn't mean nobody is using it. I'll ask around and see if someone is willing to help triage issues and merge down good PRs. If not, we'll look for a different solution (perhaps a couple more external maintainers to help Jason out!) \n. I'm the Square maintainer for crossfilter, and @jasondavies is also a maintainer who independently merges PRs and new releases. In 99% of cases over the last 2+ years I have just deferred to Jason.\nStill asking around internally at Square for volunteers (not opposed to more outside maintainers but it's more work to manage, so starting locally). Give us a day or two to figure it out.\n@gordonwoodhull I will also ask about the agreement in case there's room for an update there. Is any agreement an impediment, or something about our specific one? Understand either way, just curious if it can be fixed.\n. On #109 it seems like there was some support from Jason already, but no code. I would create a branch and try it, and get buy-in from other contributors. Forgiveness not permission. It would mean cutting a major release number if it breaks the API, but that shouldn't be an issue if the pay-off is worth it.\n92 certainly looks like cause for concern since I've ignored it for 18 months. Apologies for that. Folks who are following along, it would be helpful to review and test this PR if it's a strong candidate for merging. I have no opinion on it except what I already shared :)\n75 needs reviewing, verifying and benchmarking again following @sciyoshi's fixes. Please help.\n. I freely admit there is no active maintenance from Square on the project at this time. I'm able to drop-in to discussions like this quickly, and can provide stylistic and process guidance, but I can't commit to properly reviewing PRs if that's what it takes to unblock them.\nStill asking around internally, that will give us the info we need to decide what happens next. I'm open to \"blessing\" a fork as well, which is what we did with Cube when it became clear we weren't going to actively maintain that.\n. Many reasons. Some including: data volume, mobile performance, parity between results on different reporting platforms (web, app, email, etc).\n. No volunteers inside of Square. I'm not sure of the best steps forward, I'll find a time to swap notes with @jasondavies and see if we can identify one or two people to assist.\n. Aside: it sounds like a lot of contributors are finding crossfilter via dc.js? We've also had several issues filed here that turned out to be dc.js issues. Would the dc.js maintainers consider forking crossfilter for their purposes and accepting patches directly there?\n. Sorry for the delayed update here.\nI spoke with Jason and we're in agreement at a high level: as @gordonwoodhull speculated above, we consider crossfilter essentially \"finished\" at this point (being targeted at the use-case on the demo page: linked charts of dimensions from a simple flat dataset). I share this as plainly as possible so you know why Jason and I are not picking up the pace on PRs on this repo.\nWe completely agree that there are possible extensions and API improvements that would be worth putting into a \"crossfilter\" v2. But we also agree that if we were doing that we would probably write something from scratch using the lessons learned from v1. Neither of us is planning to start such a project.\nI am investigating if any of Square's other projects have ever spun out into a github org. I doubt that it will happen - it's difficult because of our requirement for contributor agreements. It's more likely we would encourage contributors to organize among themselves (something like \"crossfilter-contrib\" would make it clear it's not Square's thing, and could always be renamed in future). If the participants on this thread want to go ahead and do that, it's probably the best way to focus the energies and enthusiasms of the group.\n. Just closing the loop here... \nSelf-organizing an org makes sense. That's what I would have done. I would personally prefer it be called something else (add \"-contrib\" or something) but I'm not speaking for Square here. Speaking for Square - please unpublish http://crossfilter.github.io/crossfilter/ and/or remove the Square logo from it and make it clearer that it's a fork. It's probably best to remove the gh-pages branch from the fork until you're ready to cut a new release. Likewise please update the README to not be written as Square. Thanks!\nBefore linking from Square's crossfilter repo I'd like to ensure that meaningful additions/features are happening - the forks of Cube were significantly modified/enhanced before we linked to them. Keep me posted once the initial merges settle, I'll make it happen!\nThanks for understanding and keeping the energy going!\n. @derekperkins @tannerlinsley @gordonwoodhull et al - thank you for keeping the dream alive. I've chosen option 2 as the easiest for now, and added a note to the README on the square version at https://github.com/square/crossfilter/blob/master/README.md\nI have asked internally about unlocking/transferring the crossfilter npm and bower packages so that newer versions can be published there, and about transferring the repo itself to allow github to redirect everyone. But I make no promises about following through with this - please act as if it won't happen, I'll ping you if the situation changes :)\nHopefully it is clear that crossfilter/crossfilter is the home of active improvement. Thanks to all who weighed in on this thread. Please take further discussion to an issue there! :chart_with_upwards_trend: :raised_hands: \n. Don't thank me for sitting on it for 3 years followed by a flurry of copy-paste issue closing :grimacing: \n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization - you might get better answers on their fork or on Stack Overflow.\n. Apologies for silence here. As discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. Apologies for silence here. Please ask questions on http://stackoverflow.com/questions/tagged/crossfilter and note that as discussed in #151 an active fork is being developed in a new Crossfilter Organization.\n. This repository is no longer maintained. Please ask in https://github.com/crossfilter/crossfilter or try http://stackoverflow.com/questions/tagged/crossfilter \u2014 thanks!\n. ",
    "notmatt": "In the mean time, you can install Tesseract with npm via tarball (provided by github automatically) or by git SHA:\nnpm install https://github.com/square/tesseract/tarball/master\nnpm install git://github.com/square/tesseract.git#master\nOr add to your package.json in a similar way:\n{\n  \"dependencies\" : {\n    \"tesseract\": \"git://github.com/square/tesseract.git#69a383dd7ed04c9407edad71f931c1c4ab75804a\"\n  }\n}\n(For some reason #master doesn't work for me via package.json, seems to need a SHA.)\n. I think the result you're looking for is entirely achievable via the existing API. The easiest way I can think of is to order the group by the absolute value of the sum.\n``` javascript\nvar data = [ { key : 1, value : 1 }, { key : 2, value : -2 }, { key : 3, value : 3 }, { key : 4, value : -4 } ]\nvar cf = crossfilter(data);\nvar key = cf.dimension(function(d) { return d.key });\nvar group = key.group().order(function(p) { return Math.abs(p) });\ngroup.reduceSum(function(d) { return d.value });\ngroup.top(2);\n// producing\n[ { key: 4, value: -4 },\n  { key: 3, value: 3 } ]\n```\nIt also possible to use group.reduce() to write your own reduction that finds the absolute value directly (and you wouldn't need to change the ordering).\n. In the mean time, you can install Tesseract with npm via tarball (provided by github automatically) or by git SHA:\nnpm install https://github.com/square/tesseract/tarball/master\nnpm install git://github.com/square/tesseract.git#master\nOr add to your package.json in a similar way:\n{\n  \"dependencies\" : {\n    \"tesseract\": \"git://github.com/square/tesseract.git#69a383dd7ed04c9407edad71f931c1c4ab75804a\"\n  }\n}\n(For some reason #master doesn't work for me via package.json, seems to need a SHA.)\n. I think the result you're looking for is entirely achievable via the existing API. The easiest way I can think of is to order the group by the absolute value of the sum.\n``` javascript\nvar data = [ { key : 1, value : 1 }, { key : 2, value : -2 }, { key : 3, value : 3 }, { key : 4, value : -4 } ]\nvar cf = crossfilter(data);\nvar key = cf.dimension(function(d) { return d.key });\nvar group = key.group().order(function(p) { return Math.abs(p) });\ngroup.reduceSum(function(d) { return d.value });\ngroup.top(2);\n// producing\n[ { key: 4, value: -4 },\n  { key: 3, value: 3 } ]\n```\nIt also possible to use group.reduce() to write your own reduction that finds the absolute value directly (and you wouldn't need to change the ordering).\n. ",
    "drewyeaton": "Got it. Can you include a section on browser support in the readme? Fantastic work BTW.\n. Got it. Can you include a section on browser support in the readme? Fantastic work BTW.\n. ",
    "Asgaroth": "OMG, you really need to add this to the README, now I have to migrate a project into native array stuff.\n. Thank you very much, but unfortunately we are still supporting IE7, we don't really have much of a laaarge dataset, so we might be just fine with native array sort and jquery.grep\n. OMG, you really need to add this to the README, now I have to migrate a project into native array stuff.\n. Thank you very much, but unfortunately we are still supporting IE7, we don't really have much of a laaarge dataset, so we might be just fine with native array sort and jquery.grep\n. ",
    "cqcallaw": "Thanks to you both for the clarification--I can see now that the behavior is expected. The jsfiddle results were particularly helpful.\nAny advice on how I might get obtain only the set of links that contain the token \"Jimmy\"? For my purposes, the empty groups are just noise.\n. Are you suggesting to post-processing of the result set (e.g. a simple iteration through the results of the group function)? I don't see any \"ignore entries\" function for the group results listed in the API reference.\n. Excellent, thanks.\nIn investigating why group.top(Infinity) was preferable to group.all(), I encountered this in the group.all() documentation:\n\nUnlike top, however, the returned array may contain empty groups, whose value is the return value from the group's reduce initial function.\n\nDoesn't this conflict with the statement (two or three lines above) that eventualbuddha referenced?\n\nIf there are fewer than k non-empty groups, this method may also return empty groups (for example, those with a count of zero).\n. I can't speak for others, but filtering zero-value groups would certainly be useful for my usage of the API. :) I can see the zero-value groups being useful in other cases, though, so I think you'd want to make the filter optional.\n\nOn the subject of API adjustments, have you considered aliasing top(Infinity) with an overload of the all function? Using group.all(Boolean clone) would be slightly less astonishing to me, compared to top(Infinity).\n. Arrr, I must be getting senile--I thought I read both result sets were in descending order. Sorry.\n. @mbostock do you have a recommendation for filtering on a non-continuous range (e.g. PHX and SMF but not SAN)? It seems like it'd be possible to do by assigning a dimension to each airport code, but I'm wondering if there's a Better Way.\n. Noted. In the meantime, this has worked well for me so far:\noriginPHX = crossfilter.dimension (function(d) { return d.origin == 'PHX' });\n//...\noriginPHX.filter(true); //use false to get all flights were the origin isn't PHX\nThis snippet seems quite susceptible to generalization, assuming there aren't performance concerns...\n. As an API consumer, I'm inclined to vote for Option B (ordinal dimensions) because I don't see a clean way to represent the union and intersection operations for Option A (multi-filter) without some sort of domain-specific query language or array messiness, particularly when the operations are mixed. It does seem possible--albeit awkard--to synthesize Option B's behavior with Option A by taking the union of a set of ranges that match the discrete boundaries plus or minus some tolerance.\nI must confess that I don't follow the description of @Sigfried's use case, so I can't say which option would fit that case better.\n. Thanks to you both for the clarification--I can see now that the behavior is expected. The jsfiddle results were particularly helpful.\nAny advice on how I might get obtain only the set of links that contain the token \"Jimmy\"? For my purposes, the empty groups are just noise.\n. Are you suggesting to post-processing of the result set (e.g. a simple iteration through the results of the group function)? I don't see any \"ignore entries\" function for the group results listed in the API reference.\n. Excellent, thanks.\nIn investigating why group.top(Infinity) was preferable to group.all(), I encountered this in the group.all() documentation:\n\nUnlike top, however, the returned array may contain empty groups, whose value is the return value from the group's reduce initial function.\n\nDoesn't this conflict with the statement (two or three lines above) that eventualbuddha referenced?\n\nIf there are fewer than k non-empty groups, this method may also return empty groups (for example, those with a count of zero).\n. I can't speak for others, but filtering zero-value groups would certainly be useful for my usage of the API. :) I can see the zero-value groups being useful in other cases, though, so I think you'd want to make the filter optional.\n\nOn the subject of API adjustments, have you considered aliasing top(Infinity) with an overload of the all function? Using group.all(Boolean clone) would be slightly less astonishing to me, compared to top(Infinity).\n. Arrr, I must be getting senile--I thought I read both result sets were in descending order. Sorry.\n. @mbostock do you have a recommendation for filtering on a non-continuous range (e.g. PHX and SMF but not SAN)? It seems like it'd be possible to do by assigning a dimension to each airport code, but I'm wondering if there's a Better Way.\n. Noted. In the meantime, this has worked well for me so far:\noriginPHX = crossfilter.dimension (function(d) { return d.origin == 'PHX' });\n//...\noriginPHX.filter(true); //use false to get all flights were the origin isn't PHX\nThis snippet seems quite susceptible to generalization, assuming there aren't performance concerns...\n. As an API consumer, I'm inclined to vote for Option B (ordinal dimensions) because I don't see a clean way to represent the union and intersection operations for Option A (multi-filter) without some sort of domain-specific query language or array messiness, particularly when the operations are mixed. It does seem possible--albeit awkard--to synthesize Option B's behavior with Option A by taking the union of a set of ranges that match the discrete boundaries plus or minus some tolerance.\nI must confess that I don't follow the description of @Sigfried's use case, so I can't say which option would fit that case better.\n. ",
    "Sigfried": "But I thought there were performance concerns.  There are limits to the number of dimensions and making dimensions, according to the documentation is expensive.  \nI was building a sizable piece of code on D3 and when I saw that crossfilter did a lot of stuff that I was building in my own data management code, I switched over, but this issue is really hitting me now.  I've been trying to figure out how to get this functionality, but it does look impossible without adding the feature to the software as Mike suggested, and that looks too hard for me to try.  \nIn my code there's going to be lots of turning on and off of various values of various categorical dimensions, so I probably made a mistake trying to use crossfilter, though I've learned a bunch by playing with it.\n. Just to check that I'm not missing something important: you're using the word ordinal now rather than categorical.  I guess all categorical dimensions can be considered ordinal by putting them in, e.g., alphabetical order.  If there are implications beyond that for the word choice, I'm not catching them.\nIt may be uncommon but certainly not impossible that someone will want multiple filters on a quantitative dimension, so the idea of allowing those to be intersected or unioned is nice.  But your suggestion above for filters that allow toggling of individual values is very appealing.  I don't have a clear sense of the performance implications.\nOne of my use cases is that I'd like to perform some calculation on the values of dimension X for all combinations of specific values for dimensions A, B and C, and allowing this to happen quickly as the user sets filters on dimensions B, C and D.  Right now it looks to me like I have to remember the filters on B, C and D (where each filter can have multiple values) while temporarily setting single-value filters on all the combinations of A, B and C.\nIs that kind of use case something that you'd like crossfilter to be able to support?  I'll think more about what might be a nice API and report back later.\n. Did that use case make sense?  Is it something you'd want to support?\nOn Mar 31, 2012 10:12 PM, \"Mike Bostock\" \nreply@reply.github.com\nwrote:\n\n\nI guess all categorical dimensions can be considered ordinal by putting\nthem in, e.g., alphabetical order.\n\nYep, that's all I meant.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/square/crossfilter/issues/13#issuecomment-4863417\n. Hi Mike,\n\nI'm not sure the best way to email you, but trying this.\nI was wondering if you'd be interested in/willing to have a brief phone\nconversation about the future of visualization frameworks built on top of\nD3?  My perspective is that I'm at a firm that does a lot of contracting\nwork on an impressive array of scientific and administrative projects for\nthe NIH, FDA, and other organizations in the public health and clinical\nscience arenas, and I'm trying to build something general on top of D3 to\nallow us to navigate a wide range of disparate data and incorporate these\nvisualizations into web apps.\nI'm working on some ideas, which, a few weeks ago, led me to take up and\nthen abandon Tesseract/Crossfilter as my way of managing and filtering data\nsets.  The approach that I'm taking would probably seem pretty ugly to you\n(it seems ugly to me quite often): OOP class hierarchies of UI elements and\ndata elements that allow me from the perspective of any piece of data to\naccess methods relating to how it wants to be displayed (colored, sized,\netc.), whether it's been filtered, who its parents and children are; also\nthings like: when a chunk of data results from the intersection of two\ndimension values, and it's display is partly based on methods related to a\nthird dimension value, the thing figures out what to do where.\nTo some degree, I think what I'm trying to make (unfortunately, without\nsufficient experience and background), is an API to let myself and others\nmake Spotfire/Tableau-like visualizations from RDBMS data.  So the initial\nhierarchy of any of this data (for purposes of letting users assign columns\nto visualization dimensions and stuff) is: table name (or query name) -->\ncolumn name --> column value --> result subset.  Clearly in Crossfilter\nyou're coming up with ways of addressing some of the same general issues.\nYour data models in D3 and Crossfilter are nice and flat and clean and tie\nthe data so closely to the visualization that all the logic about colors\nand inter-data-point calculations can be performed directly in the\nvisualization code.  That works well for making beautiful individual\nvisualizations.  In my case where I want to make more of a dashboard thing,\nwith various visualizations all tied to the same or related underlying\ndata, I think there are aspects of the data and its interrelationships that\nneed help from classes and methods that cross visualization boundaries.\nAnyway, I thought a conversation might be fruitful.  What do you think?\nThanks,\nSigfried\nGiven that\nOn Sat, Mar 31, 2012 at 8:48 PM, Mike Bostock <\nreply@reply.github.com\n\nwrote:\nThe first part to better support categorical dimensions is deciding on an\nAPI, so you might consider that even if you don't feel comfortable tackling\nthe implementation.\nI think the first decision is whether we want to support this as\n\"dimensions can have multiple filters\" (perhaps that can be intersected or\nunioned), or as \"dimensions can be either quantitative or ordinal\", in\nwhich case the filters on an ordinal dimension are tracked as a set of\ndiscrete values, rather than a contiguous range.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/square/crossfilter/issues/13#issuecomment-4863071\n\n\nSigfried Gold\nC: 301-202-4556\nH: 301-920-0530\nwww.sigfried.org\n. But I thought there were performance concerns.  There are limits to the number of dimensions and making dimensions, according to the documentation is expensive.  \nI was building a sizable piece of code on D3 and when I saw that crossfilter did a lot of stuff that I was building in my own data management code, I switched over, but this issue is really hitting me now.  I've been trying to figure out how to get this functionality, but it does look impossible without adding the feature to the software as Mike suggested, and that looks too hard for me to try.  \nIn my code there's going to be lots of turning on and off of various values of various categorical dimensions, so I probably made a mistake trying to use crossfilter, though I've learned a bunch by playing with it.\n. Just to check that I'm not missing something important: you're using the word ordinal now rather than categorical.  I guess all categorical dimensions can be considered ordinal by putting them in, e.g., alphabetical order.  If there are implications beyond that for the word choice, I'm not catching them.\nIt may be uncommon but certainly not impossible that someone will want multiple filters on a quantitative dimension, so the idea of allowing those to be intersected or unioned is nice.  But your suggestion above for filters that allow toggling of individual values is very appealing.  I don't have a clear sense of the performance implications.\nOne of my use cases is that I'd like to perform some calculation on the values of dimension X for all combinations of specific values for dimensions A, B and C, and allowing this to happen quickly as the user sets filters on dimensions B, C and D.  Right now it looks to me like I have to remember the filters on B, C and D (where each filter can have multiple values) while temporarily setting single-value filters on all the combinations of A, B and C.\nIs that kind of use case something that you'd like crossfilter to be able to support?  I'll think more about what might be a nice API and report back later.\n. Did that use case make sense?  Is it something you'd want to support?\nOn Mar 31, 2012 10:12 PM, \"Mike Bostock\" \nreply@reply.github.com\nwrote:\n\n\nI guess all categorical dimensions can be considered ordinal by putting\nthem in, e.g., alphabetical order.\n\nYep, that's all I meant.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/square/crossfilter/issues/13#issuecomment-4863417\n. Hi Mike,\n\nI'm not sure the best way to email you, but trying this.\nI was wondering if you'd be interested in/willing to have a brief phone\nconversation about the future of visualization frameworks built on top of\nD3?  My perspective is that I'm at a firm that does a lot of contracting\nwork on an impressive array of scientific and administrative projects for\nthe NIH, FDA, and other organizations in the public health and clinical\nscience arenas, and I'm trying to build something general on top of D3 to\nallow us to navigate a wide range of disparate data and incorporate these\nvisualizations into web apps.\nI'm working on some ideas, which, a few weeks ago, led me to take up and\nthen abandon Tesseract/Crossfilter as my way of managing and filtering data\nsets.  The approach that I'm taking would probably seem pretty ugly to you\n(it seems ugly to me quite often): OOP class hierarchies of UI elements and\ndata elements that allow me from the perspective of any piece of data to\naccess methods relating to how it wants to be displayed (colored, sized,\netc.), whether it's been filtered, who its parents and children are; also\nthings like: when a chunk of data results from the intersection of two\ndimension values, and it's display is partly based on methods related to a\nthird dimension value, the thing figures out what to do where.\nTo some degree, I think what I'm trying to make (unfortunately, without\nsufficient experience and background), is an API to let myself and others\nmake Spotfire/Tableau-like visualizations from RDBMS data.  So the initial\nhierarchy of any of this data (for purposes of letting users assign columns\nto visualization dimensions and stuff) is: table name (or query name) -->\ncolumn name --> column value --> result subset.  Clearly in Crossfilter\nyou're coming up with ways of addressing some of the same general issues.\nYour data models in D3 and Crossfilter are nice and flat and clean and tie\nthe data so closely to the visualization that all the logic about colors\nand inter-data-point calculations can be performed directly in the\nvisualization code.  That works well for making beautiful individual\nvisualizations.  In my case where I want to make more of a dashboard thing,\nwith various visualizations all tied to the same or related underlying\ndata, I think there are aspects of the data and its interrelationships that\nneed help from classes and methods that cross visualization boundaries.\nAnyway, I thought a conversation might be fruitful.  What do you think?\nThanks,\nSigfried\nGiven that\nOn Sat, Mar 31, 2012 at 8:48 PM, Mike Bostock <\nreply@reply.github.com\n\nwrote:\nThe first part to better support categorical dimensions is deciding on an\nAPI, so you might consider that even if you don't feel comfortable tackling\nthe implementation.\nI think the first decision is whether we want to support this as\n\"dimensions can have multiple filters\" (perhaps that can be intersected or\nunioned), or as \"dimensions can be either quantitative or ordinal\", in\nwhich case the filters on an ordinal dimension are tracked as a set of\ndiscrete values, rather than a contiguous range.\n\nReply to this email directly or view it on GitHub:\nhttps://github.com/square/crossfilter/issues/13#issuecomment-4863071\n\n\nSigfried Gold\nC: 301-202-4556\nH: 301-920-0530\nwww.sigfried.org\n. ",
    "kpascual": "I think option B (dimensions as ordinal/categorical) would have more practical usage than option A (multiple filters on dimension).\nWhile I'm sure there are cases where you'd want to apply multiple filters on a dimension (e.g. lunch hour and dinner hour on a time of day dimension), I think filtering by particular categorical values is a much more common use case.  Using the payments metaphor in the tutorial, I'd imagine a very common use case for a merchant would be to filter payments by multiple zip codes, states, or credit card types.\nJust throwing this out there, but I was imagining an API of an optional is_categorical flag on the dimension, while using the existing filter() APIs.\n. I think option B (dimensions as ordinal/categorical) would have more practical usage than option A (multiple filters on dimension).\nWhile I'm sure there are cases where you'd want to apply multiple filters on a dimension (e.g. lunch hour and dinner hour on a time of day dimension), I think filtering by particular categorical values is a much more common use case.  Using the payments metaphor in the tutorial, I'd imagine a very common use case for a merchant would be to filter payments by multiple zip codes, states, or credit card types.\nJust throwing this out there, but I was imagining an API of an optional is_categorical flag on the dimension, while using the existing filter() APIs.\n. ",
    "ghost": "Zackham,\nI've been testing your branch and I've noticed something strange to me, but perhaps this is the proper behavior? In your test you filter by the \"total\" dim, and then you get the data through the \"date\" dim. This gives you the right answer. But if you check through the \"total\" dim you get the wrong answer, it is still filtered by the first variable only and not the union. Is this by design?\n. Any plans to merge this into crossfilter mainline?  Looks like an important addition for crossfilter.\n. Zackham,\nI've been testing your branch and I've noticed something strange to me, but perhaps this is the proper behavior? In your test you filter by the \"total\" dim, and then you get the data through the \"date\" dim. This gives you the right answer. But if you check through the \"total\" dim you get the wrong answer, it is still filtered by the first variable only and not the union. Is this by design?\n. Any plans to merge this into crossfilter mainline?  Looks like an important addition for crossfilter.\n. ",
    "KobaKhit": "Is there any update on this? Seems like a must have feature, but no successful way of implementing it or a workaround online.\n. Hello jason,\nwould this filter be still active if I apply group().reduceCount() on the filtered dimension? Ex.g.\nvar XDimension = ndx.dimension(function (d) {return d.Name})\n   .filterFunction(function (d) {return d===\"Allyssa\" || d===\"Bob\";})\nYDimension = XDimesnion.group().reduceCount(function(d) {return d.Name;});\n...\ndc.renderAll();\nHere is my stackoverflow question for reference.\nThanks.\n. How come this is not yet implemented?! Here is a nice solution in the meantime.\n. Is there any update on this? Seems like a must have feature, but no successful way of implementing it or a workaround online.\n. Hello jason,\nwould this filter be still active if I apply group().reduceCount() on the filtered dimension? Ex.g.\nvar XDimension = ndx.dimension(function (d) {return d.Name})\n   .filterFunction(function (d) {return d===\"Allyssa\" || d===\"Bob\";})\nYDimension = XDimesnion.group().reduceCount(function(d) {return d.Name;});\n...\ndc.renderAll();\nHere is my stackoverflow question for reference.\nThanks.\n. How come this is not yet implemented?! Here is a nice solution in the meantime.\n. ",
    "jezekjan": "Hello,\nI'm strugling with multifiltering issue as well as I'm trying to build a more general spatial filter on my data. I'm trying to use the filterFunction but it is strange to me that it is triggered as many times as the total number of records even if there are just few unique dimension values. Is this a bug, or is there any workaround for that? What I'm trying to do is to implement a 'point in polygon' filter based on dimension derived from Z-curve ordering.\nThanks for any ideas.\n. Hello,\nI'm strugling with multifiltering issue as well as I'm trying to build a more general spatial filter on my data. I'm trying to use the filterFunction but it is strange to me that it is triggered as many times as the total number of records even if there are just few unique dimension values. Is this a bug, or is there any workaround for that? What I'm trying to do is to implement a 'point in polygon' filter based on dimension derived from Z-curve ordering.\nThanks for any ideas.\n. ",
    "dgerber": "@jezekjan this makes filterFunction(f) evaluate f once per unique dimension value. (It still loops over all records, though.)\n``` diff\n@@ -821,11 +821,13 @@ function crossfilter() {\n       var i,\n           k,\n           x,\n+          v = values.length && values[0];\n           added = [],\n           removed = [];\n   for (i = 0; i < n; ++i) {\n\n\nif (!(filters[k = index[i]] & one) ^ !!(x = f(values[i], i))) {\nif (values[i] !== v) x = f((v = values[i]), i);\nif (!(filters[k = index[i]] & one) ^ !!x) {\n           if (x) filters[k] &= zero, added.push(k);\n           else filters[k] |= one, removed.push(k);\n         }\n```\n\nupdated after #129\n. @jezekjan this makes filterFunction(f) evaluate f once per unique dimension value. (It still loops over all records, though.)\n``` diff\n@@ -821,11 +821,13 @@ function crossfilter() {\n       var i,\n           k,\n           x,\n+          v = values.length && values[0];\n           added = [],\n           removed = [];\n   for (i = 0; i < n; ++i) {\n\n\nif (!(filters[k = index[i]] & one) ^ !!(x = f(values[i], i))) {\nif (values[i] !== v) x = f((v = values[i]), i);\nif (!(filters[k = index[i]] & one) ^ !!x) {\n           if (x) filters[k] &= zero, added.push(k);\n           else filters[k] |= one, removed.push(k);\n         }\n```\n\nupdated after #129\n. ",
    "macroscian": "Brian, you're spot on there.  There's no difference, and that was what I was doing (although not using the map function, of which I was ignorant).  Just worrying about creating a large array that I'd mostly throw away, and an unnecessary loop through a large array when the 'top' method has a loop I could subvert for that purpose.  map mitigates the latter worry to some extent.\n. Brian, you're spot on there.  There's no difference, and that was what I was doing (although not using the map function, of which I was ignorant).  Just worrying about creating a large array that I'd mostly throw away, and an unnecessary loop through a large array when the 'top' method has a loop I could subvert for that purpose.  map mitigates the latter worry to some extent.\n. ",
    "flamebunny": "Thanks for the reply.\nIve been going through the documentation and I believe that\n\n```\nvar originArray = new Array();\nflights.map(function(d) { \noriginArray.push(d.origin); \n}); \noriginArray  = unique(originArray);\nbarChart()\n    .dimension(originid)\n    .group(originids)     \n .x(d3.scale.ordinal()\n    .domain(originArray)\n.rangeRoundBands([0, 900], 1))\n```\n\nshould be interchangeable with:\n\nbarChart()\n        .dimension(originid)\n        .group(originids)\n    .x(d3.scale.linear()\n        .domain([0, 30])\n        .rangeRound([0, 10 * 90]))\n\nhowever i cant seem to get it to work :(\nCan you tell me what i am missing?\nhttp://www.pixeltradr.com/crossfilter/\nhttp://www.pixeltradr.com/crossfilter/indexOrdinal.html\n. Tried again with a simple example\nI got the X axis to display the string values\nhttp://pixeltradr.com/crossfilter/indexName.html\nIn the example above there are 3 charts, the first 2 are the ones using ordinal scales and the third uses a linear scale.\nThe problem is that the charts using ordinal scales dont filter the charts when using the brush.\nThe linear scale example does what i need it to do, but i need string labels instead of numbers\n. Thanks again for the reply\nYea i think clicking on the bars would be alot better, ive seen a few examples that do that, ill work on that.\n. hey there, I think i narrowed it down, the problem isnt with reduceSum\nits to do with the y.domain([-100, group.top(1)[0].value]);\nwhich shows the key and value of the largest in the group\nThis works fine when all values in the y axis are positive:\n\n\nObject { key=3, value=300}   // selects correct value\n// key:[1] value:[90] \n// key:[2] value:[100] \n// key:[3] value:[300]                 // largest value\n\nhowever when you have negative values the largest number is the smallest negative.\n\n\nObject { key=1, value=-90}  // selects incorrect value\n// key:[1] value:[-90] \n// key:[2] value:[-100] \n// key:[3] value:[-300]              // largest negative value\n\nThe reason why the bars are exceeding the 0-100 y range is that the maximum value is based on an incorrect figure (of -90, when it should be based on -300)\ni wonder if it would be possible to create another function - that would return the top array sorted with absolute values\ny.domain([0, group.topAbs(1)[0].value]);\nI believe that using absolute values would solve this issue \n. I think i solved it, but dont know what the effects will be on the rest of the crossfilter plugin\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilter.html\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilterNegative.html\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilterPositive.html\nIve changed the crossfilter plugin in function heapselect() to include Math.abs() in three places:\n\n\nfunction heapselect(a, lo, hi, k) {\n    var queue = new Array(k = Math.min(hi - lo, k)),  min,   i,   x,   d;\n    for (i = 0; i < k; ++i) queue[i] = a[lo++];\n    heap(queue, 0, k);\n    if (lo < hi) {\n      min =  Math.abs(f(queue[0]));\n      do {\n        if (x = Math.abs(f(d = a[lo])) > min) {\n          queue[0] = d;\n          min = Math.abs(f(heap(queue, 0, k)[0]));\n        }\n      } while (++lo < hi);\n    }\n    return queue;\n  }\n\n\nAlso edited the html file itself and added Math.abs() to:\ny.domain([0, Math.abs(group.top(1)[0].value)]);\nand in function barPath(group)\n\n\nfunction barPath(groups) {\n        var path = [],    pathPositive = [], pathNegative = [], pathBoth = [], i = -1, n = groups.length, d;\n        while (++i < n) {\n                 d = groups[i];\n          if(d.value < 0 || d.key < 0){ \n            pathNegative.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n          }else{\n            pathPositive.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n          }\n          pathBoth.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n        }\n    path[0] = pathPositive.join(\"\")\n        path[1] = pathNegative.join(\"\")\n        path[2] = pathBoth.join(\"\")\n        return path;\n      }\n\n\nI think it would probably be better to create new functions like -  function heapselectAbs(a, lo, hi, k) {}\n for example to to handle this situation.\n. Decided to leave the old sort functions alone, and create new ones to handle this situation:\ninstead of:\ny.domain([0, group.top(1)[0].value]);\nits now \ny.domain([0, group.topAbs(1)[0].value]);\nNew crossfilter file:\nhttp://pixeltradr.com/crossfilter/crossfilter.v1.abs.js\nchanges:\n- function topAbs(k)\n- function heapselectAbs_by(f) \n  ----- function heapselectAbs(a, lo, hi, k) \nhttp://pixeltradr.com/crossfilter/crossfilter.v1.abs.js\n. Wow thats awesome!\nIt works, Thanks alot!\n. Hi Mike, a running total takes the previous x sum value and adds it to the next x sum value, then takes the combined um of those values and adds it to the following sum and so on till the end. In the image in the first post, the second chart contains the same info as the first chart but each value is added to the next creating a running total along the x axis. :D cheers\n. Compute the sums in the barpath function? That's how i managed to get it to work a little while ago, but i was wondering if it was possible within crossfilter itself?\n. :D thx\n. Thanks for the reply.\nIve been going through the documentation and I believe that\n\n```\nvar originArray = new Array();\nflights.map(function(d) { \noriginArray.push(d.origin); \n}); \noriginArray  = unique(originArray);\nbarChart()\n    .dimension(originid)\n    .group(originids)     \n .x(d3.scale.ordinal()\n    .domain(originArray)\n.rangeRoundBands([0, 900], 1))\n```\n\nshould be interchangeable with:\n\nbarChart()\n        .dimension(originid)\n        .group(originids)\n    .x(d3.scale.linear()\n        .domain([0, 30])\n        .rangeRound([0, 10 * 90]))\n\nhowever i cant seem to get it to work :(\nCan you tell me what i am missing?\nhttp://www.pixeltradr.com/crossfilter/\nhttp://www.pixeltradr.com/crossfilter/indexOrdinal.html\n. Tried again with a simple example\nI got the X axis to display the string values\nhttp://pixeltradr.com/crossfilter/indexName.html\nIn the example above there are 3 charts, the first 2 are the ones using ordinal scales and the third uses a linear scale.\nThe problem is that the charts using ordinal scales dont filter the charts when using the brush.\nThe linear scale example does what i need it to do, but i need string labels instead of numbers\n. Thanks again for the reply\nYea i think clicking on the bars would be alot better, ive seen a few examples that do that, ill work on that.\n. hey there, I think i narrowed it down, the problem isnt with reduceSum\nits to do with the y.domain([-100, group.top(1)[0].value]);\nwhich shows the key and value of the largest in the group\nThis works fine when all values in the y axis are positive:\n\n\nObject { key=3, value=300}   // selects correct value\n// key:[1] value:[90] \n// key:[2] value:[100] \n// key:[3] value:[300]                 // largest value\n\nhowever when you have negative values the largest number is the smallest negative.\n\n\nObject { key=1, value=-90}  // selects incorrect value\n// key:[1] value:[-90] \n// key:[2] value:[-100] \n// key:[3] value:[-300]              // largest negative value\n\nThe reason why the bars are exceeding the 0-100 y range is that the maximum value is based on an incorrect figure (of -90, when it should be based on -300)\ni wonder if it would be possible to create another function - that would return the top array sorted with absolute values\ny.domain([0, group.topAbs(1)[0].value]);\nI believe that using absolute values would solve this issue \n. I think i solved it, but dont know what the effects will be on the rest of the crossfilter plugin\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilter.html\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilterNegative.html\nhttp://www.pixeltradr.com/crossfilter/indexPaymentsCrossfilterPositive.html\nIve changed the crossfilter plugin in function heapselect() to include Math.abs() in three places:\n\n\nfunction heapselect(a, lo, hi, k) {\n    var queue = new Array(k = Math.min(hi - lo, k)),  min,   i,   x,   d;\n    for (i = 0; i < k; ++i) queue[i] = a[lo++];\n    heap(queue, 0, k);\n    if (lo < hi) {\n      min =  Math.abs(f(queue[0]));\n      do {\n        if (x = Math.abs(f(d = a[lo])) > min) {\n          queue[0] = d;\n          min = Math.abs(f(heap(queue, 0, k)[0]));\n        }\n      } while (++lo < hi);\n    }\n    return queue;\n  }\n\n\nAlso edited the html file itself and added Math.abs() to:\ny.domain([0, Math.abs(group.top(1)[0].value)]);\nand in function barPath(group)\n\n\nfunction barPath(groups) {\n        var path = [],    pathPositive = [], pathNegative = [], pathBoth = [], i = -1, n = groups.length, d;\n        while (++i < n) {\n                 d = groups[i];\n          if(d.value < 0 || d.key < 0){ \n            pathNegative.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n          }else{\n            pathPositive.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n          }\n          pathBoth.push(\"M\", x(d.key), \",\", height, \"V\", y(Math.abs(d.value)), \"h9V\", height);\n        }\n    path[0] = pathPositive.join(\"\")\n        path[1] = pathNegative.join(\"\")\n        path[2] = pathBoth.join(\"\")\n        return path;\n      }\n\n\nI think it would probably be better to create new functions like -  function heapselectAbs(a, lo, hi, k) {}\n for example to to handle this situation.\n. Decided to leave the old sort functions alone, and create new ones to handle this situation:\ninstead of:\ny.domain([0, group.top(1)[0].value]);\nits now \ny.domain([0, group.topAbs(1)[0].value]);\nNew crossfilter file:\nhttp://pixeltradr.com/crossfilter/crossfilter.v1.abs.js\nchanges:\n- function topAbs(k)\n- function heapselectAbs_by(f) \n  ----- function heapselectAbs(a, lo, hi, k) \nhttp://pixeltradr.com/crossfilter/crossfilter.v1.abs.js\n. Wow thats awesome!\nIt works, Thanks alot!\n. Hi Mike, a running total takes the previous x sum value and adds it to the next x sum value, then takes the combined um of those values and adds it to the following sum and so on till the end. In the image in the first post, the second chart contains the same info as the first chart but each value is added to the next creating a running total along the x axis. :D cheers\n. Compute the sums in the barpath function? That's how i managed to get it to work a little while ago, but i was wondering if it was possible within crossfilter itself?\n. :D thx\n. ",
    "martindaniel4": "Hi if you are still interested in implementing a filter based on an ordinal scale, I did it with the following principles : \n- I used svg:rect rather than path to allow a click on each element\n- I added an additional variable that allows me to draw either ordinal or continuous chart\n- I updated the 'render charts' part to trigger renderAll function \n- I added a background white path, that deselect the bar when clicked\nI am sure there is a better way to achieve this task, but I am pretty happy with the result !\nCheers,\nMartin\n. Hi Krikou,\nMany thanks for having developped this useful feature. \nYour remove function works fine for me when I pass the record as the object to remove. \nSince I mostly use the remove function based on a dimension (i.e : remove the flight named ORYJFK), I first filter with the corresponding dimension and pass the result to the remove function using top function i.e :\n// Init crossfilter\nvar flight = crossfilter(data),\n     flightName = flight.dimension(function(d) {return d.name;});\n// Filter the element to remove\nvar elementToBeRemoved = flightName.filterExact(\"ORYJFK\").top(1)[0];\n// Remove the element from Crossfilter\nflight.remove(elementToBeRemoved);\nI am pretty sure this is not the best way to achieve your task. It would be then great to have the remove function available for dimension as well. What do you think ?\nCrossfilter looks to work normally after this. Did you notice any issues after having remove an element from the initial crossfilter ? \nBest,\nMartin\n. Ok got you. I just had this error while trying to remove a record from the crossfilter :\n\nUncaught TypeError: Cannot read property 'value' of undefined \n\nI'll try to implement your code in the source file. I'll keep you posted. \nI agree with you, I am sure the owner will have a good way to achieve this task. Unfortunately it looks like this library is not maintained. \nCheers,\nMartin\n. Ok I'll try. Thanks Brandon. \n. Hi if you are still interested in implementing a filter based on an ordinal scale, I did it with the following principles : \n- I used svg:rect rather than path to allow a click on each element\n- I added an additional variable that allows me to draw either ordinal or continuous chart\n- I updated the 'render charts' part to trigger renderAll function \n- I added a background white path, that deselect the bar when clicked\nI am sure there is a better way to achieve this task, but I am pretty happy with the result !\nCheers,\nMartin\n. Hi Krikou,\nMany thanks for having developped this useful feature. \nYour remove function works fine for me when I pass the record as the object to remove. \nSince I mostly use the remove function based on a dimension (i.e : remove the flight named ORYJFK), I first filter with the corresponding dimension and pass the result to the remove function using top function i.e :\n// Init crossfilter\nvar flight = crossfilter(data),\n     flightName = flight.dimension(function(d) {return d.name;});\n// Filter the element to remove\nvar elementToBeRemoved = flightName.filterExact(\"ORYJFK\").top(1)[0];\n// Remove the element from Crossfilter\nflight.remove(elementToBeRemoved);\nI am pretty sure this is not the best way to achieve your task. It would be then great to have the remove function available for dimension as well. What do you think ?\nCrossfilter looks to work normally after this. Did you notice any issues after having remove an element from the initial crossfilter ? \nBest,\nMartin\n. Ok got you. I just had this error while trying to remove a record from the crossfilter :\n\nUncaught TypeError: Cannot read property 'value' of undefined \n\nI'll try to implement your code in the source file. I'll keep you posted. \nI agree with you, I am sure the owner will have a good way to achieve this task. Unfortunately it looks like this library is not maintained. \nCheers,\nMartin\n. Ok I'll try. Thanks Brandon. \n. ",
    "optimuspaul": "I need this too.  Finding it very frustrating to try and deal with a dimension where each object can have multiple values assigned.\n. totally agree.  I'm having a difficult time with the example code.\n. if I divide the values each by 10, so I have a range of 0-400 then it works fine.\n. It must be a data issue.  If I generate a similar dataset randomly it works as one would expect. I'm going to see if I can narrow it down. There must be something in the data that just happens to be at the 1000th group that is breaking it.  It seemed too convenient, but I'll validate the data and reopen this if I find there is a bug.\n. I wasn't casting the value to a Number in my dimension call.  Not exactly sure what that means.  Most places it was smart enough to convert the string to a numeric value as you would expect, but apparently after it got to 4 digits it broke down. Doesn't seem like a crossfilter bug to me.\n. None of my values have commas in them.  They come out of a CSV file.  I have verified that every value only contains numeric values. I had sorted the data as numbers in descending order, but it looks like the crossfilter sorted them as strings, I found the larger values lower in the list of values.  It seemed to exclude all the 0 values however.  It seems I need to clean up my data after I load the CSV.\n. yes, that is exactly what I did.\n. @sciyoshi, I was interested in this and applied your changes and found that it caused another issue.  I found that the filtered counts were all off after a filter was applied.  I haven't dug in yet to see why that is happening, but I thought I'd let you know that something doesn't seem right.\n. I will try and get a test case up soon. The issue I was seeing is some dimensions would get very wrong counts on them, sometimes counts larger than the total number of records.\n. I am unable to reproduce with a more limited dataset. I don't have access to the data I was using when I saw the problem before. It's possible it was not related to this.  If others are not having issues I don't see any reason to block this from going out.\n. sorry, github changed the interface and I did that wrong.\n. I need this too.  Finding it very frustrating to try and deal with a dimension where each object can have multiple values assigned.\n. totally agree.  I'm having a difficult time with the example code.\n. if I divide the values each by 10, so I have a range of 0-400 then it works fine.\n. It must be a data issue.  If I generate a similar dataset randomly it works as one would expect. I'm going to see if I can narrow it down. There must be something in the data that just happens to be at the 1000th group that is breaking it.  It seemed too convenient, but I'll validate the data and reopen this if I find there is a bug.\n. I wasn't casting the value to a Number in my dimension call.  Not exactly sure what that means.  Most places it was smart enough to convert the string to a numeric value as you would expect, but apparently after it got to 4 digits it broke down. Doesn't seem like a crossfilter bug to me.\n. None of my values have commas in them.  They come out of a CSV file.  I have verified that every value only contains numeric values. I had sorted the data as numbers in descending order, but it looks like the crossfilter sorted them as strings, I found the larger values lower in the list of values.  It seemed to exclude all the 0 values however.  It seems I need to clean up my data after I load the CSV.\n. yes, that is exactly what I did.\n. @sciyoshi, I was interested in this and applied your changes and found that it caused another issue.  I found that the filtered counts were all off after a filter was applied.  I haven't dug in yet to see why that is happening, but I thought I'd let you know that something doesn't seem right.\n. I will try and get a test case up soon. The issue I was seeing is some dimensions would get very wrong counts on them, sometimes counts larger than the total number of records.\n. I am unable to reproduce with a more limited dataset. I don't have access to the data I was using when I saw the problem before. It's possible it was not related to this.  If others are not having issues I don't see any reason to block this from going out.\n. sorry, github changed the interface and I did that wrong.\n. ",
    "baank": "Is there someone wrong with this commit ? .. it's a valuable feature and would be great to have in the main Square repo. \n. Is there someone wrong with this commit ? .. it's a valuable feature and would be great to have in the main Square repo. \n. ",
    "ppong": "This looks awesome! will this be merged in anytime soon?\n. This looks awesome! will this be merged in anytime soon?\n. ",
    "johnistan": "great feature. bump to merge.\n. great feature. bump to merge.\n. ",
    "tesseralis": "Maybe undesired behavior: dim.filter(1) (single argument) returns the dimension object, but dim.filter(1, 2) (multiple arguments) returns the last value.\nAlso, if you pass in the same value twice (like dim.filter(1, 1)) or any even number of times, it 'cancels out' and the dimension ignores filtering by that dimension.\n. Maybe undesired behavior: dim.filter(1) (single argument) returns the dimension object, but dim.filter(1, 2) (multiple arguments) returns the last value.\nAlso, if you pass in the same value twice (like dim.filter(1, 1)) or any even number of times, it 'cancels out' and the dimension ignores filtering by that dimension.\n. ",
    "denzo": "What is the status on this? Is there a plan to merge it any time soon?\n. That is truly awesome! You guys doing an amazing job!\n. Well, I have asked more than 10 days ago\nhttp://stackoverflow.com/questions/15492896/why-is-this-so-in-crossfilter\nOn Saturday, March 30, 2013, Jason Davies wrote:\n\nI believe the approach (and eventual name!) was inspired by Chris Weaver\u2019s Multidimensional\nVisual Analysis Using Cross-Filtered Viewshttp://www.purdue.edu/discoverypark/vaccine/assets/pdfs/publications/pdf/Multidimensional%20Visual%20Analysis.pdf\n.\nGitHub is not really the best place to ask for support; the issues are\nmeant for reporting bugs and feature requests. You can ask support\nquestions using the crossfilter tag on StackOverflowhttp://stackoverflow.com/questions/tagged/crossfilterinstead.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/issues/74#issuecomment-15673207\n.\n. What is the status on this? Is there a plan to merge it any time soon?\n. That is truly awesome! You guys doing an amazing job!\n. Well, I have asked more than 10 days ago\nhttp://stackoverflow.com/questions/15492896/why-is-this-so-in-crossfilter\n\nOn Saturday, March 30, 2013, Jason Davies wrote:\n\nI believe the approach (and eventual name!) was inspired by Chris Weaver\u2019s Multidimensional\nVisual Analysis Using Cross-Filtered Viewshttp://www.purdue.edu/discoverypark/vaccine/assets/pdfs/publications/pdf/Multidimensional%20Visual%20Analysis.pdf\n.\nGitHub is not really the best place to ask for support; the issues are\nmeant for reporting bugs and feature requests. You can ask support\nquestions using the crossfilter tag on StackOverflowhttp://stackoverflow.com/questions/tagged/crossfilterinstead.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/issues/74#issuecomment-15673207\n.\n. \n",
    "gsklee": "@jasondavies Are we doing anything to this one?\n. @wssbck :+1: thanks!\n. I think it's possible to add some checks and throw a warning on development mode, and strip the warning logics away on production mode if this feature impedes performance too much.\n. Just for the record, Facebook React leaves the warning logics (basically invariants per DbC terminology) intact even in production mode.\n. @wssbck This surely is a feasible workaround. Since the issue primarily revolves around data types, something like Flow integration may also prove to be helpful.\n. +1, hope to see this great project moving forward again.\n. Glad to hear this, kudos to everyone involved for moving this project forward!\n. @jasondavies Are we doing anything to this one?\n. @wssbck :+1: thanks!\n. I think it's possible to add some checks and throw a warning on development mode, and strip the warning logics away on production mode if this feature impedes performance too much.\n. Just for the record, Facebook React leaves the warning logics (basically invariants per DbC terminology) intact even in production mode.\n. @wssbck This surely is a feasible workaround. Since the issue primarily revolves around data types, something like Flow integration may also prove to be helpful.\n. +1, hope to see this great project moving forward again.\n. Glad to hear this, kudos to everyone involved for moving this project forward!\n. ",
    "robin900": "I'm finding the same problem, both with the flight dataset and with my own dataset that I adapted the example application to show.\n. Found a possible solution: stepbystep/timsort on github offers a JS implementation of timsort. I have a local modification of crossfilter working with the timsort. Plenty fast, and a stable sort. Only hack was need to provide slice() for the UintArray prototypes. I'll work on a pull request in next day or two.\n. I'm finding the same problem, both with the flight dataset and with my own dataset that I adapted the example application to show.\n. Found a possible solution: stepbystep/timsort on github offers a JS implementation of timsort. I have a local modification of crossfilter working with the timsort. Plenty fast, and a stable sort. Only hack was need to provide slice() for the UintArray prototypes. I'll work on a pull request in next day or two.\n. ",
    "cambridgemike": "I just wanted to check in and see if there is any suggestion on how to accomplish the above. I'm able to re-run the group/reduce but this is causing a performance nightmare. \nAre there any other avenues for developers to get support? There is an open question on SO, http://stackoverflow.com/questions/10509478/using-crossfilter-is-it-possible-to-track-max-min-when-grouping but that's all I could find.\n. I just wanted to check in and see if there is any suggestion on how to accomplish the above. I'm able to re-run the group/reduce but this is causing a performance nightmare. \nAre there any other avenues for developers to get support? There is an open question on SO, http://stackoverflow.com/questions/10509478/using-crossfilter-is-it-possible-to-track-max-min-when-grouping but that's all I could find.\n. ",
    "richardpoole": "Posted a possible solution on SO. Hopefully it's more efficient than re-running the group/reduce.\n. Posted a possible solution on SO. Hopefully it's more efficient than re-running the group/reduce.\n. ",
    "pdaems": "@jasondavies  \nIm currently calculating the maximum of my group like:\nvar barGroup = datedimension.group().reduce(\n                                 function (p, v) {\n                                     p.values.push(+v[6]);\n                                     if (p.max < +v[6]) {\n                                         p.max = +v[6];\n                                     }\n                                     return p;\n                                 },\n                                 function (p, v) {\n                                     var index = p.values.indexOf(+v[6]);\n                                     if (index >= 0) {\n                                         p.values.splice(index, 1);\n                                         p.values.sort(function (a, b) { return a - b });\n                                     }\n                                     if (p.values.length > 0) {\n                                         p.max = p.values[p.values.length - 1];\n                                     } else {\n                                         p.max = 0;\n                                     }\n                                     return p;\n                                 },\n                                 function () {\n                                     return { max: 0, values: new Array() };\n                                 }\n                                );\nHowever the reduceRemoval takes a long time to process each time i use a filter on a dimension.\nWhenever i try and use the group.reduce function without reduceRemoval i get the following error \n\nvar barGroup = datedimension.group().reduce(\n                                 function (p, v) {\n                                     p.values.push(+v[6]);\n                                     if (p.max < +v[6]) {\n                                         p.max = +v[6];\n                                     }\n                                     return p;\n                                 },\n                                 function () {\n                                     return { max: 0, values: new Array() };\n                                 }\n                                );\nAny idea's ? Thanks in advance !\n. @jasondavies  I get the same error by using the version with the optional reduceRemoval in it.\nhttps://raw.github.com/square/crossfilter/6c20e31090a6f96962f25bcedc891b9827777a8c/crossfilter.js\n. @jasondavies Alright, thanks works great now !\n. @jasondavies  \nIm currently calculating the maximum of my group like:\nvar barGroup = datedimension.group().reduce(\n                                 function (p, v) {\n                                     p.values.push(+v[6]);\n                                     if (p.max < +v[6]) {\n                                         p.max = +v[6];\n                                     }\n                                     return p;\n                                 },\n                                 function (p, v) {\n                                     var index = p.values.indexOf(+v[6]);\n                                     if (index >= 0) {\n                                         p.values.splice(index, 1);\n                                         p.values.sort(function (a, b) { return a - b });\n                                     }\n                                     if (p.values.length > 0) {\n                                         p.max = p.values[p.values.length - 1];\n                                     } else {\n                                         p.max = 0;\n                                     }\n                                     return p;\n                                 },\n                                 function () {\n                                     return { max: 0, values: new Array() };\n                                 }\n                                );\nHowever the reduceRemoval takes a long time to process each time i use a filter on a dimension.\nWhenever i try and use the group.reduce function without reduceRemoval i get the following error \n\nvar barGroup = datedimension.group().reduce(\n                                 function (p, v) {\n                                     p.values.push(+v[6]);\n                                     if (p.max < +v[6]) {\n                                         p.max = +v[6];\n                                     }\n                                     return p;\n                                 },\n                                 function () {\n                                     return { max: 0, values: new Array() };\n                                 }\n                                );\nAny idea's ? Thanks in advance !\n. @jasondavies  I get the same error by using the version with the optional reduceRemoval in it.\nhttps://raw.github.com/square/crossfilter/6c20e31090a6f96962f25bcedc891b9827777a8c/crossfilter.js\n. @jasondavies Alright, thanks works great now !\n. ",
    "esjewett": "Didn't see this and I think I've basically duplicated it in #92 . However, correct me if I'm wrong, but does this solution properly calculate a maximum if a group is created on a crossfilter that already has filters applied? I don't think so, but I'm not sure.\n. I see. Yes, that is a different use-case - finding filtered max/min vs my need in #92 for finding unfiltered max/min for new groups after a filter has already been applied.\n. I'd really like to see this functionality added one way or another. We're using CrossFilter to back a browser based visualization application that works on arbitrary data sets and it would be nice to be able to be more generous to users with regards to the number of dimensions that can be created when using certain visualization components that require large numbers of dimensions.\n. Sorry, don't mean to pester, but I'm not sure what the correct approach is here. We're making some additions to Crossfilter and I'm creating pull requests when it seems to make sense to push those changes upstream, but so far have not seen any response on either pull request. Is there a different way to get changes evaluated for addition to this repository?\nThanks, and again, sorry to bother.\n. Cool, glad this is the right approach :-) I know it's not personal, but also wasn't sure what the standard procedure was. Thanks! I will ping on my other pull request as well.\nRegarding your question: I didn't want to return value on it's own because if someone assigned something else to it (dimension.accessor = 1), then the entire dimension would go haywire. I figured it was safer to provide a function that takes a record d as input and returns the result of the value(d) function.\nThis change isn't strictly necessary, as we can keep track of our own accessor functions, but IIRC there was another issue asking for the same thing, it simplifies our code significantly, and it seems like it could be useful if dimensions are able to provide access to their accessor function after they were initially created.\n. You're right of course. I had a brain malfunction. It wouldn't break the dimension if you override the paymentsByTotal.accessor attribute. So I think you're right that this doesn't provide an advantage over just adding accessor: value to the returned object.\nYour example with an externally named accessor function is exactly what we were doing until we added the dimension accessor function in this pull request. It just becomes a pain to always pass around the dimension object and the accessor function together, when you know that function is in the object :-)\n. Sorry, this pull request is based on the 1.2 version. If that's a problem, I'll look into updating. We haven't tested our application with the 1.3.x versions yet.\n. @RandomEtc Thanks very much for taking a look. I will update to 1.3.x.\n. Update to current master branch complete.\n. You can certainly calculate averages using the custom reducer. Not sure how that would differ from moving averages? Not to speak for them, but in the past I believe the Crossfilter maintainers have said that specialized custom reducers should be maintained as separate projects and not baked into Crossfilter itself.\n. I see. You need to use the groupAll functionality to do this. It takes\narguments similar to reduce, but the functions are passed and must return\nall the groups. This allows you to do groupings where a single record is\nrelevant to multiple groups, like a moving average.\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_groupAll\nOn Fri, Jan 23, 2015 at 7:51 PM, Jack Stouffer notifications@github.com\nwrote:\n\nAccording to http://stackoverflow.com/a/21707254/923933 moving averages\nare not currently possible with the base api and would require new\nfunctionality.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/100#issuecomment-71294904.\n. I've just updated reductio to support arbitrary aggregations across arbitrarily defined windows as well as multi-value classification scenarios. The example is just a count aggregation, but it should work with average and the move complex aggregations as well. If you'd like to try it out: https://github.com/esjewett/reductio#aggregations-groupall-aggregations\n. Glad it sort of worked. How many records of this form are we talking about? If in the 1000s or low 10000s, we can probably optimize. I'm not sure Reductio does this as efficiently as possible, so if you have a test dataset I can look at it. Probably best to discuss that over in the Reductio issues. Over the low 10000s or records, it might just not be manageable.\n. Are you within an order of magnitude on performance? If you switch your data to use strings for the date dimension instead of Date objects and optimize the Reductio groupAll function, that might buy you a 10x improvement.\n. Interesting idea. Any thoughts on how this API would look - or is work already being done here? I'd be interested in working on it, but conceptually not sure how it would fit in to the existing API (could you define which filterset applies to a given dimension?).\n. You'd need to maintain multiple independent pre-calculations of each group based on each filterset and each union/intersection/exclusion, no? Sounds very interesting. Is there a good place to start to hash this out? Wiki page?\n. Two thoughts:\n1. Have thought a bit about a 'filterSet' API. Seems it should be possible to maintain multiple named filter set and allow all methods such as .filter and .top to take an optional filter set argument. This could keep the API backwards compatible. However, after noodling on the internals a bit, it seems to me that groupings would have to be maintained and calculated for each new filter set. In other words, it would be fairly computationally expensive, wouldn't it? Anyway, I like the idea.\n2. The more I think about it, the more I think the concept of crossfilter.remove() should be fairly independent of the filter set concept. Wouldn't it be more intuitive and efficient if we could figure out a way for crossfilter.remove() to drop records independent of filters that are currently applied? In any case, I will experiment with whether this is possible in the current structure of Crossfilter. I think it should be, but not sure.\n\nRelated thought: Would a separate function dimension.remove() taking arguments identical to dimension.filter() make more sense and be more intuitive? Seems to me like anything changing the underlying data should be on the crossfilter object, but it's a thought.\n. I've made a commit on a fork that I think gets this working. I need to write more tests and better ensure that it works in conjunction with filters, but wanted to check in (if someone has the time to look at it) and see if I'm completely misunderstanding how something is working on the internals. Commit is here: https://github.com/esjewett/crossfilter/commit/09d5ac158f0fc1bb6498fb26d73b0ca0cccbd36b\n. @jasondavies I definitely hear you, and I think that the more general solution you describe could be really good - I just didn't have time to work on defining it at the moment. I'd still like to get to that. I just wanted to clarify that the change I made in the fork doesn't add another filter argument, unless I'm misunderstanding what that is, but rather removes records regardless of the filter currently in place.\nIt seems to me that this fits a lot of use cases (see below) better than the creation of a new filter, and perhaps even a new dimension to drive the removal of a small number of records. Personally, I'd see it as complementary to a more general solution around filtering. However, I may very well be miscalculating some of the performance impacts of what I'm doing :-) As mentioned above, I'm not super-familiar with the Crossfilter internals.\nSome scenarios:\n- removing a small number of records\n- removing data that is pushed \"off the end\" in a streaming data scenario\n- in-place updates to drive multi-dimensional exploration of data sets too large for the browser (the use case driving my exploration here)\n. @amergin I'd recommend sticking with the standard Crossfilter rather than my exploratory fork where possible. Currently in Palladio we are using a private fork of Crossfilter with a couple of tweaks but will be switching back to the standard Crossfilter soon. It's a really solid library, and it's just so much easier not to have to worry about maintaining a change to it.\n. Fair enough.\nWRT to the more general solution, I was thinking of creating an optional 'filterSet' concept. Filters would, by default, belong to a default filterSet, but all functions based on filters could take an optional (n+1)th argument. So, dimension.filterExact(value, [filterSet]), dimension.filterAll([filterSet]), dimension.top(number, [filterSet]), group.all([filterSet]), crossfilter.remove([filterSet]). There would also need to be utility functions to create new named filterSets based on the union & intersection of existing filterSets. This would leave the existing API completely unchanged, but would require keeping track of a map of named filterSets, maintaining a separate filter array for each filterSet, and maintaining (and calculating) additional group values for each filterSet. Thoughts? Am I missing something? I was planning to get into implementing this later this year, but might as well start bouncing the idea around now, I guess.\nI think this would leave an open question as to whether to allow crossfilter.remove([filterFunction]). The question being if it allows a significant efficiency gain over scenarios where a new dimension and/or filterSet would need to be created to drive removal of records, and then subsequently destroyed.\n. I always push the wrong button :-/ Just wanted to clarify that there is no open PR currently. If we get the go-ahead, I'll put one together as soon as possible. Thanks!\n. @RandomEtc Correct indeed. The pull request is a work-in-progress unfortunately, but I'll be taking another stab at it soon, with a little more knowledge of the CF internals. Thanks!\n. I hope this comment doesn't re-open the issue. If it does, my apologies.\nIn any case, as part of a project I've been working on we have developed a bunch of different 'helper' functions. I'm looking at releasing these, but I'm trying to determine the best way to do this. I'm thinking of releasing it as a set of functions that take a group as an argument and modify the group by calling \"reduce(...)\" with various, often very complex, arguments. Does that sound reasonable?\n. @gordonwoodhull I've got to figure that out. I was thinking something like\nvar group = crossfilter.dimension(...).group();\nvar helper = cfhelpers.avg(function (d) { return d.total; })\n    .order(...)\n    .group(group);\nhelper.top(10);\n'helper' would expose the Crossfilter group API.\nRegarding making it part of dc-js, I think it probably makes the most sense to keep it separate as this kind of library of Crossfilter reducers would be really helpful in a lot of contexts. Of course, the first step is just to do it.\n. Here's a very basic start: https://github.com/esjewett/reductio\nIt only supports count, sum, and average at the moment, but it's easily extensible, and reducers are additive and can depend on each other (for example, 'average' requires that 'count' and 'sum' are both applied to the group as well - it doesn't track it's own running count and sum). I need to do some more thinking on how to incorporate exception aggregation, but I plan to do that as well, at least in some form.\nFair warning: there is currently very little error checking and there has been precious little testing. It's a work in progress :-)\nI think it should be possible to more or less directly address the request in this issue by adding a getReduceArguments method to the reducer to return an array of three functions, then one could say something like:\n```\nvar reduceCountSumAverage = reductio().count(true).sum(function(d) { return d.bar; }).avg(true);\n// The following two lines are equivalent.\ngroup.reduce.apply(reduceCountSumAverage.getReduceArguments());\nreduceCountSumAverage(group);\n```\n. It's not quite clear to me what you want the output of this function to be, but I do wonder if this is possible as a set of custom reduce functions rather than as a modification to Crossfilter itself. From your pull request, it looks like it should definitely be possible.\n. I don't see the description. I wonder - does it produce similar results to this? https://github.com/esjewett/reductio#aggregations-standard-aggregations-exception-aggregation\n. Scrolling through the changes in the pull request, I don't see any comment. Did you push it?\nThat said, if you just need support for multiple keys, you could have the Reductio exception accessor return a string concatenating the keys using a separator you know doesn't appear in either of them. I'll look into directly supporting the multiple key scenario though, as it is a useful one.\n. I see, interesting and useful. I'll think about adding that capability of arbitrary reduce methods to Reductio's exception aggregation capability.\n. I think the only way to do this would be to check every time the dimension accessor is evaluated, which happens a lot. Would result in some % slowdown, which could be evaluated using the performance tests. IMO, this is a rough edge, but performance is really paramount in a lot of use-cases.\n. Just for clarity, I'll point out that this is exactly the behavior to expect based on the documentation at https://github.com/square/crossfilter/wiki/API-Reference#dimension\nSpecifically, if we go into a console and do some experimentation, we'll see that the values \"A\" and 1 don't behave properly with respect to the Javascript inequality operators. \"A\" < 1 is false, \"A\" > 1 is false, and \"A\" == 1 is false. That's not a consistent result. However, in the case of strings \"A\" < \"1\"  is false, \"A\" > \"1\" is true, and \"A\" == \"1\" is false. That's consistent, which is why it works. Meanwhile, null < null is false, null > null is false, and null === null is true. That's consistent, meaning we should properly see a null group.\nIn general, the rule of thumb is that if you are not confident that all of your data will have a predictable dimension value (and really, are we ever confident of this?), then you need to coerce your dimension accessor return value like so:\nvar stringDim = xfilter.dimension(function(d) { return \"\" + d.value; });\nvar numDim = xfilter.dimension(function(d) { return +d.value; });\nvar boolDim = xfilter.dimension(function(d) { return d ? true : false; });\nIf we do this, we should never run into this problem. I've gotten tripped up by this plenty of times, but have managed to teach myself that I've always always got to coerce types like this. But Crossfilter can't really do it for us because there is no way for Crossfilter to know what data type the dimension should have. I'm thinking about how I might be able to add something like this to the Reductio API.\n. @wssbck Actually, I was a little too optimistic with my number coercion example. You need to account for null, undefined, and NaN if you want to cover all the JS non-value values (at least that I'm aware of), none of which are naturally ordered in the context of String or Number type data sets. Get this:\n``` console\n\n+null\n< 0\n+undefined\n< NaN\nnull == undefined\n< true\n+null == +undefined\n< false\n```\n\nJavascript is amazing :-/\n. For Reductio, I am considering adding some dimension-building capability. In that functionality, I will probably implement checks on dimension accessor functions to address this sort of issue. I'm thinking that at the time the accessor function is provided, I will check that it always returns naturally ordered values for a variety of data types including null, and throw a warning if it does not. This would notify people of possible issues while not forcing those who are sure that their data will be naturally ordered to carry a performance penalty.\nTheoretically this kind of test could be added to crossfilter.dimension(value) without a performance penalty because the provided function would be behaviorally tested when crossfilter.dimension is evaluated, not when value is evaluated. Basically, put this in the crossfilter.dimension function:\nfunction dimension(value) {\n  // ...\n  var testResults = [ null, 1, 'test' ].map(function(d) {\n    return typeof value(d);\n  });\n  if( !(testResults[0] === testResults[1] && testResults[1] === testResults[2]) ) {\n    console.warn(\"Dimension accessor returns values that may not be naturally ordered.\");\n  }\n  // ...\n}\n. Hi @RandomEtc and all. Thanks for discussing this. I'd be happy to help maintain if that would be helpful. \nI'm definitely on-board with the general philosophy of keeping Crossfilter as lean as possible and keeping complexity in helper libraries, but there are some things that it would be extremely helpful to address internally that have not been getting attention. I'm thinking here of issues like #109, #92, and #75. It would be great to have a small team of maintainers and major users of Crossfilter in place who could work together to review, improve, and merge these sorts of changes.\nAs far as I've seen, there's nothing else out there like Crossfilter. I'd like to see it thrive as I think it's a very important piece of any type of interactive visualization of more than a small amount of data.\n. #109 has code (see the linked branch), but since Jason wanted to take another approach I was trying to get buy-in before creating a pull request. I don't want to waste effort on this. It doesn't break the API, just extends it. If you (@RandomEtc) think you'd be OK with merging that code, I'll submit a pull request ASAP.\nOn the other two, it's a bit of a horse/cart problem. If there is not active maintenance of the project, it is difficult to justify putting significant effort into review that may never be looked at. I look forward to hearing what Square decides on that front. Sorry to be difficult on that, but I think that's the key issue to be resolved.\n. @RandomEtc No worries, we all know how it is with finding the time for these things! And I didn't mean to cast blame as far as ongoing maintenance, just to make clear that the issues of getting proper review and involvement from the maintainers is related in my mind.\nI'm wasn't familiar with what happened with Cube. Good to see there is some precedence for dealing with these types of projects.\n. Hi @RandomEtc, just checking in to see if there is any update from the internal discussion @ Square? Cheers, Ethan\n. Thanks for the update. I think @gordonwoodhull would be the key person to ask regarding the dc.js angle. I'd be up for helping maintain a dc.js organization fork or another fork - whatever is agreed.\n. @RandomEtc Thanks for closing the loop and the feedback. We're still getting things together and moving a bit slowly, but I've gone through and tried to update all the documents in the main repo and gh-pages to remove Square branding and \"point-of-view\" except for the copyright notices. I've also added a sentence in the first paragraph of the gh-pages site to indicate that it is a community fork and link back to the original project. Sorry for the slip there.\nRegarding the renaming, that is a bit difficult. In some ways, a new name would be ideal (for many reasons including reduced confusion, Bower/NPM registration, etc), but this is also meant to be a continuation of the same project. crossfilter-contrib, at least in my mind means additional components that work with the original Crossfilter library, and that's not what this is, or at least not only. So, I think it may be a slow process to rename. We'll talk about it and figure something out!\nThanks again for your understanding and guidance with this.\n. @dderiso I'd say that https://github.com/crossfilter/crossfilter is open to pull requests and issues. Probably best to first open an issue to discuss as we only want to make changes that are really required in the core library. We are working very slowly though. It's probably quite premature to say that it is the home for community development as that's the kind of thing I'd prefer to show rather than say, and I don't think we've shown that yet.\n. Sorry, got bitten by the Github fork/original pull request defaults :-/\n. Didn't see this and I think I've basically duplicated it in #92 . However, correct me if I'm wrong, but does this solution properly calculate a maximum if a group is created on a crossfilter that already has filters applied? I don't think so, but I'm not sure.\n. I see. Yes, that is a different use-case - finding filtered max/min vs my need in #92 for finding unfiltered max/min for new groups after a filter has already been applied.\n. I'd really like to see this functionality added one way or another. We're using CrossFilter to back a browser based visualization application that works on arbitrary data sets and it would be nice to be able to be more generous to users with regards to the number of dimensions that can be created when using certain visualization components that require large numbers of dimensions.\n. Sorry, don't mean to pester, but I'm not sure what the correct approach is here. We're making some additions to Crossfilter and I'm creating pull requests when it seems to make sense to push those changes upstream, but so far have not seen any response on either pull request. Is there a different way to get changes evaluated for addition to this repository?\nThanks, and again, sorry to bother.\n. Cool, glad this is the right approach :-) I know it's not personal, but also wasn't sure what the standard procedure was. Thanks! I will ping on my other pull request as well.\nRegarding your question: I didn't want to return value on it's own because if someone assigned something else to it (dimension.accessor = 1), then the entire dimension would go haywire. I figured it was safer to provide a function that takes a record d as input and returns the result of the value(d) function.\nThis change isn't strictly necessary, as we can keep track of our own accessor functions, but IIRC there was another issue asking for the same thing, it simplifies our code significantly, and it seems like it could be useful if dimensions are able to provide access to their accessor function after they were initially created.\n. You're right of course. I had a brain malfunction. It wouldn't break the dimension if you override the paymentsByTotal.accessor attribute. So I think you're right that this doesn't provide an advantage over just adding accessor: value to the returned object.\nYour example with an externally named accessor function is exactly what we were doing until we added the dimension accessor function in this pull request. It just becomes a pain to always pass around the dimension object and the accessor function together, when you know that function is in the object :-)\n. Sorry, this pull request is based on the 1.2 version. If that's a problem, I'll look into updating. We haven't tested our application with the 1.3.x versions yet.\n. @RandomEtc Thanks very much for taking a look. I will update to 1.3.x.\n. Update to current master branch complete.\n. You can certainly calculate averages using the custom reducer. Not sure how that would differ from moving averages? Not to speak for them, but in the past I believe the Crossfilter maintainers have said that specialized custom reducers should be maintained as separate projects and not baked into Crossfilter itself.\n. I see. You need to use the groupAll functionality to do this. It takes\narguments similar to reduce, but the functions are passed and must return\nall the groups. This allows you to do groupings where a single record is\nrelevant to multiple groups, like a moving average.\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_groupAll\nOn Fri, Jan 23, 2015 at 7:51 PM, Jack Stouffer notifications@github.com\nwrote:\n\nAccording to http://stackoverflow.com/a/21707254/923933 moving averages\nare not currently possible with the base api and would require new\nfunctionality.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/100#issuecomment-71294904.\n. I've just updated reductio to support arbitrary aggregations across arbitrarily defined windows as well as multi-value classification scenarios. The example is just a count aggregation, but it should work with average and the move complex aggregations as well. If you'd like to try it out: https://github.com/esjewett/reductio#aggregations-groupall-aggregations\n. Glad it sort of worked. How many records of this form are we talking about? If in the 1000s or low 10000s, we can probably optimize. I'm not sure Reductio does this as efficiently as possible, so if you have a test dataset I can look at it. Probably best to discuss that over in the Reductio issues. Over the low 10000s or records, it might just not be manageable.\n. Are you within an order of magnitude on performance? If you switch your data to use strings for the date dimension instead of Date objects and optimize the Reductio groupAll function, that might buy you a 10x improvement.\n. Interesting idea. Any thoughts on how this API would look - or is work already being done here? I'd be interested in working on it, but conceptually not sure how it would fit in to the existing API (could you define which filterset applies to a given dimension?).\n. You'd need to maintain multiple independent pre-calculations of each group based on each filterset and each union/intersection/exclusion, no? Sounds very interesting. Is there a good place to start to hash this out? Wiki page?\n. Two thoughts:\n1. Have thought a bit about a 'filterSet' API. Seems it should be possible to maintain multiple named filter set and allow all methods such as .filter and .top to take an optional filter set argument. This could keep the API backwards compatible. However, after noodling on the internals a bit, it seems to me that groupings would have to be maintained and calculated for each new filter set. In other words, it would be fairly computationally expensive, wouldn't it? Anyway, I like the idea.\n2. The more I think about it, the more I think the concept of crossfilter.remove() should be fairly independent of the filter set concept. Wouldn't it be more intuitive and efficient if we could figure out a way for crossfilter.remove() to drop records independent of filters that are currently applied? In any case, I will experiment with whether this is possible in the current structure of Crossfilter. I think it should be, but not sure.\n\nRelated thought: Would a separate function dimension.remove() taking arguments identical to dimension.filter() make more sense and be more intuitive? Seems to me like anything changing the underlying data should be on the crossfilter object, but it's a thought.\n. I've made a commit on a fork that I think gets this working. I need to write more tests and better ensure that it works in conjunction with filters, but wanted to check in (if someone has the time to look at it) and see if I'm completely misunderstanding how something is working on the internals. Commit is here: https://github.com/esjewett/crossfilter/commit/09d5ac158f0fc1bb6498fb26d73b0ca0cccbd36b\n. @jasondavies I definitely hear you, and I think that the more general solution you describe could be really good - I just didn't have time to work on defining it at the moment. I'd still like to get to that. I just wanted to clarify that the change I made in the fork doesn't add another filter argument, unless I'm misunderstanding what that is, but rather removes records regardless of the filter currently in place.\nIt seems to me that this fits a lot of use cases (see below) better than the creation of a new filter, and perhaps even a new dimension to drive the removal of a small number of records. Personally, I'd see it as complementary to a more general solution around filtering. However, I may very well be miscalculating some of the performance impacts of what I'm doing :-) As mentioned above, I'm not super-familiar with the Crossfilter internals.\nSome scenarios:\n- removing a small number of records\n- removing data that is pushed \"off the end\" in a streaming data scenario\n- in-place updates to drive multi-dimensional exploration of data sets too large for the browser (the use case driving my exploration here)\n. @amergin I'd recommend sticking with the standard Crossfilter rather than my exploratory fork where possible. Currently in Palladio we are using a private fork of Crossfilter with a couple of tweaks but will be switching back to the standard Crossfilter soon. It's a really solid library, and it's just so much easier not to have to worry about maintaining a change to it.\n. Fair enough.\nWRT to the more general solution, I was thinking of creating an optional 'filterSet' concept. Filters would, by default, belong to a default filterSet, but all functions based on filters could take an optional (n+1)th argument. So, dimension.filterExact(value, [filterSet]), dimension.filterAll([filterSet]), dimension.top(number, [filterSet]), group.all([filterSet]), crossfilter.remove([filterSet]). There would also need to be utility functions to create new named filterSets based on the union & intersection of existing filterSets. This would leave the existing API completely unchanged, but would require keeping track of a map of named filterSets, maintaining a separate filter array for each filterSet, and maintaining (and calculating) additional group values for each filterSet. Thoughts? Am I missing something? I was planning to get into implementing this later this year, but might as well start bouncing the idea around now, I guess.\nI think this would leave an open question as to whether to allow crossfilter.remove([filterFunction]). The question being if it allows a significant efficiency gain over scenarios where a new dimension and/or filterSet would need to be created to drive removal of records, and then subsequently destroyed.\n. I always push the wrong button :-/ Just wanted to clarify that there is no open PR currently. If we get the go-ahead, I'll put one together as soon as possible. Thanks!\n. @RandomEtc Correct indeed. The pull request is a work-in-progress unfortunately, but I'll be taking another stab at it soon, with a little more knowledge of the CF internals. Thanks!\n. I hope this comment doesn't re-open the issue. If it does, my apologies.\nIn any case, as part of a project I've been working on we have developed a bunch of different 'helper' functions. I'm looking at releasing these, but I'm trying to determine the best way to do this. I'm thinking of releasing it as a set of functions that take a group as an argument and modify the group by calling \"reduce(...)\" with various, often very complex, arguments. Does that sound reasonable?\n. @gordonwoodhull I've got to figure that out. I was thinking something like\nvar group = crossfilter.dimension(...).group();\nvar helper = cfhelpers.avg(function (d) { return d.total; })\n    .order(...)\n    .group(group);\nhelper.top(10);\n'helper' would expose the Crossfilter group API.\nRegarding making it part of dc-js, I think it probably makes the most sense to keep it separate as this kind of library of Crossfilter reducers would be really helpful in a lot of contexts. Of course, the first step is just to do it.\n. Here's a very basic start: https://github.com/esjewett/reductio\nIt only supports count, sum, and average at the moment, but it's easily extensible, and reducers are additive and can depend on each other (for example, 'average' requires that 'count' and 'sum' are both applied to the group as well - it doesn't track it's own running count and sum). I need to do some more thinking on how to incorporate exception aggregation, but I plan to do that as well, at least in some form.\nFair warning: there is currently very little error checking and there has been precious little testing. It's a work in progress :-)\nI think it should be possible to more or less directly address the request in this issue by adding a getReduceArguments method to the reducer to return an array of three functions, then one could say something like:\n```\nvar reduceCountSumAverage = reductio().count(true).sum(function(d) { return d.bar; }).avg(true);\n// The following two lines are equivalent.\ngroup.reduce.apply(reduceCountSumAverage.getReduceArguments());\nreduceCountSumAverage(group);\n```\n. It's not quite clear to me what you want the output of this function to be, but I do wonder if this is possible as a set of custom reduce functions rather than as a modification to Crossfilter itself. From your pull request, it looks like it should definitely be possible.\n. I don't see the description. I wonder - does it produce similar results to this? https://github.com/esjewett/reductio#aggregations-standard-aggregations-exception-aggregation\n. Scrolling through the changes in the pull request, I don't see any comment. Did you push it?\nThat said, if you just need support for multiple keys, you could have the Reductio exception accessor return a string concatenating the keys using a separator you know doesn't appear in either of them. I'll look into directly supporting the multiple key scenario though, as it is a useful one.\n. I see, interesting and useful. I'll think about adding that capability of arbitrary reduce methods to Reductio's exception aggregation capability.\n. I think the only way to do this would be to check every time the dimension accessor is evaluated, which happens a lot. Would result in some % slowdown, which could be evaluated using the performance tests. IMO, this is a rough edge, but performance is really paramount in a lot of use-cases.\n. Just for clarity, I'll point out that this is exactly the behavior to expect based on the documentation at https://github.com/square/crossfilter/wiki/API-Reference#dimension\nSpecifically, if we go into a console and do some experimentation, we'll see that the values \"A\" and 1 don't behave properly with respect to the Javascript inequality operators. \"A\" < 1 is false, \"A\" > 1 is false, and \"A\" == 1 is false. That's not a consistent result. However, in the case of strings \"A\" < \"1\"  is false, \"A\" > \"1\" is true, and \"A\" == \"1\" is false. That's consistent, which is why it works. Meanwhile, null < null is false, null > null is false, and null === null is true. That's consistent, meaning we should properly see a null group.\nIn general, the rule of thumb is that if you are not confident that all of your data will have a predictable dimension value (and really, are we ever confident of this?), then you need to coerce your dimension accessor return value like so:\nvar stringDim = xfilter.dimension(function(d) { return \"\" + d.value; });\nvar numDim = xfilter.dimension(function(d) { return +d.value; });\nvar boolDim = xfilter.dimension(function(d) { return d ? true : false; });\nIf we do this, we should never run into this problem. I've gotten tripped up by this plenty of times, but have managed to teach myself that I've always always got to coerce types like this. But Crossfilter can't really do it for us because there is no way for Crossfilter to know what data type the dimension should have. I'm thinking about how I might be able to add something like this to the Reductio API.\n. @wssbck Actually, I was a little too optimistic with my number coercion example. You need to account for null, undefined, and NaN if you want to cover all the JS non-value values (at least that I'm aware of), none of which are naturally ordered in the context of String or Number type data sets. Get this:\n``` console\n\n+null\n< 0\n+undefined\n< NaN\nnull == undefined\n< true\n+null == +undefined\n< false\n```\n\nJavascript is amazing :-/\n. For Reductio, I am considering adding some dimension-building capability. In that functionality, I will probably implement checks on dimension accessor functions to address this sort of issue. I'm thinking that at the time the accessor function is provided, I will check that it always returns naturally ordered values for a variety of data types including null, and throw a warning if it does not. This would notify people of possible issues while not forcing those who are sure that their data will be naturally ordered to carry a performance penalty.\nTheoretically this kind of test could be added to crossfilter.dimension(value) without a performance penalty because the provided function would be behaviorally tested when crossfilter.dimension is evaluated, not when value is evaluated. Basically, put this in the crossfilter.dimension function:\nfunction dimension(value) {\n  // ...\n  var testResults = [ null, 1, 'test' ].map(function(d) {\n    return typeof value(d);\n  });\n  if( !(testResults[0] === testResults[1] && testResults[1] === testResults[2]) ) {\n    console.warn(\"Dimension accessor returns values that may not be naturally ordered.\");\n  }\n  // ...\n}\n. Hi @RandomEtc and all. Thanks for discussing this. I'd be happy to help maintain if that would be helpful. \nI'm definitely on-board with the general philosophy of keeping Crossfilter as lean as possible and keeping complexity in helper libraries, but there are some things that it would be extremely helpful to address internally that have not been getting attention. I'm thinking here of issues like #109, #92, and #75. It would be great to have a small team of maintainers and major users of Crossfilter in place who could work together to review, improve, and merge these sorts of changes.\nAs far as I've seen, there's nothing else out there like Crossfilter. I'd like to see it thrive as I think it's a very important piece of any type of interactive visualization of more than a small amount of data.\n. #109 has code (see the linked branch), but since Jason wanted to take another approach I was trying to get buy-in before creating a pull request. I don't want to waste effort on this. It doesn't break the API, just extends it. If you (@RandomEtc) think you'd be OK with merging that code, I'll submit a pull request ASAP.\nOn the other two, it's a bit of a horse/cart problem. If there is not active maintenance of the project, it is difficult to justify putting significant effort into review that may never be looked at. I look forward to hearing what Square decides on that front. Sorry to be difficult on that, but I think that's the key issue to be resolved.\n. @RandomEtc No worries, we all know how it is with finding the time for these things! And I didn't mean to cast blame as far as ongoing maintenance, just to make clear that the issues of getting proper review and involvement from the maintainers is related in my mind.\nI'm wasn't familiar with what happened with Cube. Good to see there is some precedence for dealing with these types of projects.\n. Hi @RandomEtc, just checking in to see if there is any update from the internal discussion @ Square? Cheers, Ethan\n. Thanks for the update. I think @gordonwoodhull would be the key person to ask regarding the dc.js angle. I'd be up for helping maintain a dc.js organization fork or another fork - whatever is agreed.\n. @RandomEtc Thanks for closing the loop and the feedback. We're still getting things together and moving a bit slowly, but I've gone through and tried to update all the documents in the main repo and gh-pages to remove Square branding and \"point-of-view\" except for the copyright notices. I've also added a sentence in the first paragraph of the gh-pages site to indicate that it is a community fork and link back to the original project. Sorry for the slip there.\nRegarding the renaming, that is a bit difficult. In some ways, a new name would be ideal (for many reasons including reduced confusion, Bower/NPM registration, etc), but this is also meant to be a continuation of the same project. crossfilter-contrib, at least in my mind means additional components that work with the original Crossfilter library, and that's not what this is, or at least not only. So, I think it may be a slow process to rename. We'll talk about it and figure something out!\nThanks again for your understanding and guidance with this.\n. @dderiso I'd say that https://github.com/crossfilter/crossfilter is open to pull requests and issues. Probably best to first open an issue to discuss as we only want to make changes that are really required in the core library. We are working very slowly though. It's probably quite premature to say that it is the home for community development as that's the kind of thing I'd prefer to show rather than say, and I don't think we've shown that yet.\n. Sorry, got bitten by the Github fork/original pull request defaults :-/\n. ",
    "gordonwoodhull": "I provided an example here, which keeps a list of rows for each bin and then can compute min/max/median:\nhttp://dc-js.github.io/dc.js/examples/complex-reduce.html\nSource here:\nhttps://github.com/dc-js/dc.js/blob/develop/web/examples/complex-reduce.html\nIt would be more efficient if crossfilter provided access to the underlying rows for each bin, instead of having to track those externally. But other than that, I think it's an okay solution to this problem.\n. @hariDasu, note that NaN here might not be the constant but any comparison between a number and, say, a string. \nI believe the problem arises because it is hard to sort values with the following semantics:\n1<'a'\n=> false\n   'a'<1\n=> false\nTherefore your keys must be all numbers or all strings, and your reductions may produce only numbers. (If I understand correctly.)\n. Hi @jasondavies,\nOne problem with the string concatenation solution is that it's very messy to supply tuples that include numbers.  They have to be zero-padded.  I wonder if you would consider a PR for native support of tuple keys?\n. gordon$ cat commas\n1,1\n10,2\n2,3\n1,9\n11,15\ngordon$ sort commas\n1,1\n1,9\n10,2\n11,15\n2,3\n. Similar problem if the character code is greater than digits:\ngordon$ cat bars\n1|1\n10|2\n2|3\n1|9\n11|15\n1|11\n10|1\n11|1\n11|2\ngordon$ sort bars\n10|1\n10|2\n11|1\n11|15\n11|2\n1|1\n1|11\n1|9\n2|3\nI could be wrong, but I don't think lexicographical ordering ever works for tuples of variable length fields.\n. Yes, that almost works, but for example, I would want to be able to select the range [1,1] -> [1,19], but without native support [1,2] would be left out.\nI think it boils down to parameterizing the ordering function.  So there wouldn't be any extra logic during sorting.  I would hope this isn't worse than the valueOf() call that is already happening, and you'd pay for what you need.  I can benchmark it and find out.  Thanks for considering it.\n. Ah, right.  Thanks, got it.  And it would be very unlikely that one would want to filter by e.g. range [1,10] -> [2,9]\nI will see if I can make some wrappers to hide the mess.\n. I happen to have written something like this. Where would be a good place to post it for review?\n. Sure, let me revise it a bit more and then I'll do that.\nI was hoping to get some feedback before posting, in case it's, you know, Wrong, but I guess a wiki can serve that purpose too. Maybe I'll post it to the d3 mailing list first.\n. Note that you need to guard against a divide by zero in reduceRemove:\njs\n    p.avg = p.count ? p.sum/p.count : 0;\n. Thanks for the link, @jasondavies.\n. I think second-order functions can help you out here.  Check out the solution posted to the dc.js issue tracker for this issue.\n. @esjewett, this sounds really cool.  I don't know but it might be worth it to add another level of indirection, so that the helpers return functions which can then be applied to groups.. so that the helpers can themselves be reused.\nAny chance you'd like to contribute this to a new library on github.com/dc-js/?  I have been collecting examples of \"fake groups\" - a different kind of wrapper - and in the future I plan to create wrappers for pivots/series/etc.\n. Oh, that's neat to use the reusable chart pattern for configuring the helpers.  \nI meant, as part of a separate project hosted in the dc-js organization, not as part of the dc.js project itself.  But it doesn't really matter, the important thing is to actually release them!\n. Yep please file a dc.js issue. If you can repro in a jsFiddle that will be appreciated. Thanks!\n. @wssbck, you might look at the way Ethan Jewett's reductio library does this: by generating the helper function @jasondavies mentions.  https://github.com/esjewett/reductio\n. You might look at PourOver for more general boolean operations - my understanding is that the performance is nothing like crossfilter but it's more general.\n. Ref : #114\n. This is a feature, and documented.\n\nNote: a grouping intersects the crossfilter's current filters, except for the associated dimension's filter. Thus, group methods consider only records that satisfy every filter except this dimension's filter. So, if the crossfilter of payments is filtered by type and total, then group by total only observes the filter by type.\n\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_group\nIdea being that usually you don't want a chart's data to disappear when you are brushing that chart.\nThe standard workaround is to create an identical dimension and filter that one instead.\n. dc.js data tables do support groups as dimensions, pretty much by accident. (The coupling between dc.js and crossfilter is very light.)\nThere is a little bit of info here, and a link to a (complex) example, in this PR: https://github.com/dc-js/dc.js/pull/697. Please try it out and bring any issues to the appropriate dc forums.\n. @vmantese, if this works for you, you should close the ticket. It seems like more a dc.js (documentation) issue than crossfilter. \n. Does crossfilter have any bugs, besides people shooting themselves in the foot and getting stack overflows with NaNs? I think in a sense it is complete.\nI can't contribute due to the copyright assignment agreement. That's something that creates a sea of red tape in corporations.\n. > Maybe moving crossfilter to an official organization so that there could be additional plugins brought into the official crossfilter ecosystem.\nAn organization would be sweet, with copyright staying with the contributors, as we have done with dc.js. The only reason for copyright assignment is to make it easier to change the copyright later, and that is unlikely to be needed with crossfilter. \n. @jefffriesen, has anyone built up the same cross filtering functionality on top of lodash? That would not be trivial but would indeed be interesting. \n. @RandomEtc I would say in many organizations it is only moderately difficult to get internal approval for contributing to a project under some well known open source license. \nBut it is near impossible to get approval to sign some other agreement that lawyers would have to read.\n(Spoken from my limited understanding of IP and organizations.)\n. Thanks for the update, @RandomEtc. Yes, dc-js could host crossfilter, but it might be more appropriate to put it in its own organization as @derekperkins suggested.\nSince the dependency is really the other way and lots of people use crossfilter without dc.js. \nEither way I'll be glad to help maintain it, as long as there are few other maintainers and no contributor agreement.\n. Thanks @RandomEtc! \nThere is a wealth of information in the issues on this repo, so let's link back here when we continue these conversations. Looking forward to continuing the amazing work done here!\n. Groups don't observe the filters on their own dimension. This is by design: usually you only want the other charts to change when you filter on one.\nFrom the documentation:\n\nNote: a grouping intersects the crossfilter's current filters, except for the associated dimension's filter. Thus, group methods consider only records that satisfy every filter except this dimension's filter. So, if the crossfilter of payments is filtered by type and total, then group by total only observes the filter by type.\n\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_group\nThe workaround if you want a group that observes its own dimension, is to create two identical dimensions, and apply the filter to the other copy of the dimension.\n. You can create a dimension which uses multiple fields in its key, as described in #48, but I think you'd have trouble getting the sorting right, unless you're willing to zero-pad your numbers.\nSince the strength of crossfilter is really in speedy filtering, you might be better off just defining your dimensions based on the filtering needs, and then post-process the group output to get the right sorting order.\n. There is a dimension.bottom() function, but there is no dimension.order() function - could it be that .order() is the problem? \nOr, more likely, could it be that you have a group object, which supports group.order() group but not `group.bottom()?\n. Stack Overflow is a better place for asking support questions. \nBut yes, you can use data like this. Just supply an array of indices as your data to crossfilter. Then write your dimension and group accessors to use the index to fetch data from the original arrays.\nSomething like:\njs\nvar N = data.timestamp.length;\nvar r = _.range(N); // [0,1,2,...,N-1]\nvar ndx = crossfilter(r);\nvar V1dim = ndx.dimension(function(d) { return data.V1[d]; });\nvar sumV2perV1 = V1dim.group().reduceSum(function(d) { return data.V2[d];});\nDownside is that you won't find a lot of examples of people using crossfilter this way, so you'll have to translate everything. It might be easier to send your data over the wire as object of arrays, and then rotate it into an array of objects in JavaScript, and probably not too expensive unless your data is huge.\n. Hi @ebookoos, this sounds like more of a support question, and maybe more to do with dc.js than crossfilter. So you should probably ask on Stack Overflow with the dc.js tag, or on the dc.js user group.\nAlso, I'm not sure what \"foreach function\" you're referring to or what explanation of filtering and grouping for data tables, so when you post in one of those places, could you please expand your question and provide links?. I provided an example here, which keeps a list of rows for each bin and then can compute min/max/median:\nhttp://dc-js.github.io/dc.js/examples/complex-reduce.html\nSource here:\nhttps://github.com/dc-js/dc.js/blob/develop/web/examples/complex-reduce.html\nIt would be more efficient if crossfilter provided access to the underlying rows for each bin, instead of having to track those externally. But other than that, I think it's an okay solution to this problem.\n. @hariDasu, note that NaN here might not be the constant but any comparison between a number and, say, a string. \nI believe the problem arises because it is hard to sort values with the following semantics:\n1<'a'\n=> false\n   'a'<1\n=> false\nTherefore your keys must be all numbers or all strings, and your reductions may produce only numbers. (If I understand correctly.)\n. Hi @jasondavies,\nOne problem with the string concatenation solution is that it's very messy to supply tuples that include numbers.  They have to be zero-padded.  I wonder if you would consider a PR for native support of tuple keys?\n. gordon$ cat commas\n1,1\n10,2\n2,3\n1,9\n11,15\ngordon$ sort commas\n1,1\n1,9\n10,2\n11,15\n2,3\n. Similar problem if the character code is greater than digits:\ngordon$ cat bars\n1|1\n10|2\n2|3\n1|9\n11|15\n1|11\n10|1\n11|1\n11|2\ngordon$ sort bars\n10|1\n10|2\n11|1\n11|15\n11|2\n1|1\n1|11\n1|9\n2|3\nI could be wrong, but I don't think lexicographical ordering ever works for tuples of variable length fields.\n. Yes, that almost works, but for example, I would want to be able to select the range [1,1] -> [1,19], but without native support [1,2] would be left out.\nI think it boils down to parameterizing the ordering function.  So there wouldn't be any extra logic during sorting.  I would hope this isn't worse than the valueOf() call that is already happening, and you'd pay for what you need.  I can benchmark it and find out.  Thanks for considering it.\n. Ah, right.  Thanks, got it.  And it would be very unlikely that one would want to filter by e.g. range [1,10] -> [2,9]\nI will see if I can make some wrappers to hide the mess.\n. I happen to have written something like this. Where would be a good place to post it for review?\n. Sure, let me revise it a bit more and then I'll do that.\nI was hoping to get some feedback before posting, in case it's, you know, Wrong, but I guess a wiki can serve that purpose too. Maybe I'll post it to the d3 mailing list first.\n. Note that you need to guard against a divide by zero in reduceRemove:\njs\n    p.avg = p.count ? p.sum/p.count : 0;\n. Thanks for the link, @jasondavies.\n. I think second-order functions can help you out here.  Check out the solution posted to the dc.js issue tracker for this issue.\n. @esjewett, this sounds really cool.  I don't know but it might be worth it to add another level of indirection, so that the helpers return functions which can then be applied to groups.. so that the helpers can themselves be reused.\nAny chance you'd like to contribute this to a new library on github.com/dc-js/?  I have been collecting examples of \"fake groups\" - a different kind of wrapper - and in the future I plan to create wrappers for pivots/series/etc.\n. Oh, that's neat to use the reusable chart pattern for configuring the helpers.  \nI meant, as part of a separate project hosted in the dc-js organization, not as part of the dc.js project itself.  But it doesn't really matter, the important thing is to actually release them!\n. Yep please file a dc.js issue. If you can repro in a jsFiddle that will be appreciated. Thanks!\n. @wssbck, you might look at the way Ethan Jewett's reductio library does this: by generating the helper function @jasondavies mentions.  https://github.com/esjewett/reductio\n. You might look at PourOver for more general boolean operations - my understanding is that the performance is nothing like crossfilter but it's more general.\n. Ref : #114\n. This is a feature, and documented.\n\nNote: a grouping intersects the crossfilter's current filters, except for the associated dimension's filter. Thus, group methods consider only records that satisfy every filter except this dimension's filter. So, if the crossfilter of payments is filtered by type and total, then group by total only observes the filter by type.\n\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_group\nIdea being that usually you don't want a chart's data to disappear when you are brushing that chart.\nThe standard workaround is to create an identical dimension and filter that one instead.\n. dc.js data tables do support groups as dimensions, pretty much by accident. (The coupling between dc.js and crossfilter is very light.)\nThere is a little bit of info here, and a link to a (complex) example, in this PR: https://github.com/dc-js/dc.js/pull/697. Please try it out and bring any issues to the appropriate dc forums.\n. @vmantese, if this works for you, you should close the ticket. It seems like more a dc.js (documentation) issue than crossfilter. \n. Does crossfilter have any bugs, besides people shooting themselves in the foot and getting stack overflows with NaNs? I think in a sense it is complete.\nI can't contribute due to the copyright assignment agreement. That's something that creates a sea of red tape in corporations.\n. > Maybe moving crossfilter to an official organization so that there could be additional plugins brought into the official crossfilter ecosystem.\nAn organization would be sweet, with copyright staying with the contributors, as we have done with dc.js. The only reason for copyright assignment is to make it easier to change the copyright later, and that is unlikely to be needed with crossfilter. \n. @jefffriesen, has anyone built up the same cross filtering functionality on top of lodash? That would not be trivial but would indeed be interesting. \n. @RandomEtc I would say in many organizations it is only moderately difficult to get internal approval for contributing to a project under some well known open source license. \nBut it is near impossible to get approval to sign some other agreement that lawyers would have to read.\n(Spoken from my limited understanding of IP and organizations.)\n. Thanks for the update, @RandomEtc. Yes, dc-js could host crossfilter, but it might be more appropriate to put it in its own organization as @derekperkins suggested.\nSince the dependency is really the other way and lots of people use crossfilter without dc.js. \nEither way I'll be glad to help maintain it, as long as there are few other maintainers and no contributor agreement.\n. Thanks @RandomEtc! \nThere is a wealth of information in the issues on this repo, so let's link back here when we continue these conversations. Looking forward to continuing the amazing work done here!\n. Groups don't observe the filters on their own dimension. This is by design: usually you only want the other charts to change when you filter on one.\nFrom the documentation:\n\nNote: a grouping intersects the crossfilter's current filters, except for the associated dimension's filter. Thus, group methods consider only records that satisfy every filter except this dimension's filter. So, if the crossfilter of payments is filtered by type and total, then group by total only observes the filter by type.\n\nhttps://github.com/square/crossfilter/wiki/API-Reference#dimension_group\nThe workaround if you want a group that observes its own dimension, is to create two identical dimensions, and apply the filter to the other copy of the dimension.\n. You can create a dimension which uses multiple fields in its key, as described in #48, but I think you'd have trouble getting the sorting right, unless you're willing to zero-pad your numbers.\nSince the strength of crossfilter is really in speedy filtering, you might be better off just defining your dimensions based on the filtering needs, and then post-process the group output to get the right sorting order.\n. There is a dimension.bottom() function, but there is no dimension.order() function - could it be that .order() is the problem? \nOr, more likely, could it be that you have a group object, which supports group.order() group but not `group.bottom()?\n. Stack Overflow is a better place for asking support questions. \nBut yes, you can use data like this. Just supply an array of indices as your data to crossfilter. Then write your dimension and group accessors to use the index to fetch data from the original arrays.\nSomething like:\njs\nvar N = data.timestamp.length;\nvar r = _.range(N); // [0,1,2,...,N-1]\nvar ndx = crossfilter(r);\nvar V1dim = ndx.dimension(function(d) { return data.V1[d]; });\nvar sumV2perV1 = V1dim.group().reduceSum(function(d) { return data.V2[d];});\nDownside is that you won't find a lot of examples of people using crossfilter this way, so you'll have to translate everything. It might be easier to send your data over the wire as object of arrays, and then rotate it into an array of objects in JavaScript, and probably not too expensive unless your data is huge.\n. Hi @ebookoos, this sounds like more of a support question, and maybe more to do with dc.js than crossfilter. So you should probably ask on Stack Overflow with the dc.js tag, or on the dc.js user group.\nAlso, I'm not sure what \"foreach function\" you're referring to or what explanation of filtering and grouping for data tables, so when you post in one of those places, could you please expand your question and provide links?. ",
    "kannes": "I ended up here via Google and want to share the solution to my several hour brain-melt problem, I hope that's alright and not abusing the issue tracker.\nIf you are getting this error and you are certain that your data file does not have any \"bad\" lines with missing values or the like, make sure you are actually loading that specific data file...\nI tried using a column that did not exist in the tsv data file I had loaded but in the one I thought I was using.\n. I ended up here via Google and want to share the solution to my several hour brain-melt problem, I hope that's alright and not abusing the issue tracker.\nIf you are getting this error and you are certain that your data file does not have any \"bad\" lines with missing values or the like, make sure you are actually loading that specific data file...\nI tried using a column that did not exist in the tsv data file I had loaded but in the one I thought I was using.\n. ",
    "hariDasu": "i have no NaN or undefined values as i queried my databse to exclude all rows where any field contains them, and i still get this error. tried with 200k rows and reduced to 20k, 15k etc it only ever worked with 2k rows. the dataset only had 5 columns. its a great library but im not sure what else to use for visualizing large datasets.\n. ahh looks like that was my problem using string values for days rather than encoding them out to digits 0-6 or 1-7. thanks @gordonwoodhull \n. i have no NaN or undefined values as i queried my databse to exclude all rows where any field contains them, and i still get this error. tried with 200k rows and reduced to 20k, 15k etc it only ever worked with 2k rows. the dataset only had 5 columns. its a great library but im not sure what else to use for visualizing large datasets.\n. ahh looks like that was my problem using string values for days rather than encoding them out to digits 0-6 or 1-7. thanks @gordonwoodhull \n. ",
    "csymill26": "I am getting the error \"Uncaught RangeError: Maximum call stack size exceeded\" when I am using a subset of my data.  I have created a dashboard with multiple graphs with a very big data set.  I then created a smaller one with a subset of the data, but I am not getting this error message.  Any ideas?  I know there's not a Nan or infinite loop going on.\n. I am getting the error \"Uncaught RangeError: Maximum call stack size exceeded\" when I am using a subset of my data.  I have created a dashboard with multiple graphs with a very big data set.  I then created a smaller one with a subset of the data, but I am not getting this error message.  Any ideas?  I know there's not a Nan or infinite loop going on.\n. ",
    "kapadia": "I concur with @iros.  A convenience function on dimension would be useful.  By the way, this is a super useful library!\n. I concur with @iros.  A convenience function on dimension would be useful.  By the way, this is a super useful library!\n. ",
    "aaronaverill": "Assuming like me, the OP wants the min/max dimension value (not the fact row), this is a bit more of a pain than you make it out to be. And in fact is impossible to implement in a generic way because the dimension accessor function (passed into the dimension function) is not stored anywhere on the returned dimension.\nConsider how I would like the implementation to look:\ntopValue: function(dimension) {\n  var topFact = dimension.top(1);\n  if (topFact == null || topFact.length == 0) return null; // Handle no fact rows, just in case\n  return dimension.value(topFact[0]); // Whoops - value() doesn't exist!\n}\nA messy hack is to store the dimension accessor function and map to your dimensions, or reproduce the value accessor function. Not Very Dry. Rather I would like to see:\ndimension.topValue()\ndimension.bottomValue()\nThe use case for these functions is quite obvious - creating min/max range extents for slider controls to allow the user to dynamically filter based on a dimension.\n. Voila: https://github.com/square/crossfilter/pull/56\nNote this returns an array, so to get the min/max of a dimension you'll still need to check an array return of zero size and pick the first element.\nvar max = dimension.topValues(1);\nmax = max.length ? max[0] : null;\n. \"It is impossible for the dimension to know exactly what value you want back from the array.\"\nI think there is some confusion. Myself at least (maybe not the OP) - I am looking for the min/max of the actual dimension itself, eg - the value returned from the valueaccessor function parameter passed to crossfilter.dimension(value).\nUsing the test data as an example, say you have a dimension of payment date, these functions would allow you to find in a single call the earliest and latest payment date. \nWe're using these as the range for a jQuery slider that allows to filter on a dimension.\n. If you are doing anything sophisticated creating groups dynamically you might be running into the issue I reported here:\nhttps://github.com/square/crossfilter/issues/55\n. Are you willing to rewrite my code to accomodate this API change? :)\n. I'm no javascript expert, but I'm not certain deliberate use of undefined is a common idiom in js apis. I pose it as a question.\nThere may also be some precedent (expectations) based on null and three-state logic used in SQL.\nWe have a textbook case here in the difficulty of executing the principle of least astonishment. Honestly when I used filter(null) it seemed very natural. But again, my data does not contain nulls, so I never filter on a null value.\n. I'm not passionate about it either way, but FYI here is my typical use case.\nvar filter = someControlViewer.getTheFilter();\ndimension.filter(filter);\nSo.. the proposal means my control needs to return \"undefined\" rather than \"null\" to mean - there is no filter selected. As I mention previously, this is a bit of an odd idiom.\nAlternatively, I need intermediary controller logic which determines if the control's filter is empty, or selected, and calls concrete methods filterExact(filter) or filterAll(). By this logic, the filter() method is completely unnecessary and redundant.\nAs a convenience function filter() has the exact semantics I am looking for and follows \"null as empty\" conventions I am accustomed to. Rather than describe this as an \"inconsistency\", I would argue it is a very useful feature.\n. \"dimension.filter(filter||undefined);\"\nIf your goal with this bit of code is a more consistent, readable and easily understood API, you have failed, at least for me. Now we have not only added \"undefined\", but the null || idiom in passing function arguments. Pity the junior coder that comes along on the project and tries to unravel the reason for this, or the outsourced overseas agency that needs to make a quick change on a short term contract. \nI leave these kinds of gymnastics to the js minifiers but understand it is a personal preference to style. I guess we will have to disagree on this.\n. Addendum.\nI stumbled into this bug only by accident on seeing rogue reduce.add() / reduce.remove() calls - objects I thought had gone out of scope but were still alive. I think this is due to the symantics and naming:\ncrossfilter.group()\ndoesn't really indicate a new and connected object will be created (well... you could say the same about the dimension() call but its more apparent in the documentation that these are \"heavyweight\"). I would rather see this renamed \"crossfilter.addGroup()\", and the corresponding crossfilter.removeGroup().\n-or-\nreimplement these as flyweight closure classes that are truly compute on demand.\n. \"You'll want to edit src/crossfilter.js, rather than the concatenated generated crossfilter.js\"\nDone.\n. \"Also, would you mind adding tests for the same functionality?\"\nThis is going to be tough. Not familiar with vows or test data, and I don't have D3. So the test environment setup is a steep hill.\nIn theory, it should be easy to use the top() / bottom() tests, but pull out the dimension value.\n. Assuming like me, the OP wants the min/max dimension value (not the fact row), this is a bit more of a pain than you make it out to be. And in fact is impossible to implement in a generic way because the dimension accessor function (passed into the dimension function) is not stored anywhere on the returned dimension.\nConsider how I would like the implementation to look:\ntopValue: function(dimension) {\n  var topFact = dimension.top(1);\n  if (topFact == null || topFact.length == 0) return null; // Handle no fact rows, just in case\n  return dimension.value(topFact[0]); // Whoops - value() doesn't exist!\n}\nA messy hack is to store the dimension accessor function and map to your dimensions, or reproduce the value accessor function. Not Very Dry. Rather I would like to see:\ndimension.topValue()\ndimension.bottomValue()\nThe use case for these functions is quite obvious - creating min/max range extents for slider controls to allow the user to dynamically filter based on a dimension.\n. Voila: https://github.com/square/crossfilter/pull/56\nNote this returns an array, so to get the min/max of a dimension you'll still need to check an array return of zero size and pick the first element.\nvar max = dimension.topValues(1);\nmax = max.length ? max[0] : null;\n. \"It is impossible for the dimension to know exactly what value you want back from the array.\"\nI think there is some confusion. Myself at least (maybe not the OP) - I am looking for the min/max of the actual dimension itself, eg - the value returned from the valueaccessor function parameter passed to crossfilter.dimension(value).\nUsing the test data as an example, say you have a dimension of payment date, these functions would allow you to find in a single call the earliest and latest payment date. \nWe're using these as the range for a jQuery slider that allows to filter on a dimension.\n. If you are doing anything sophisticated creating groups dynamically you might be running into the issue I reported here:\nhttps://github.com/square/crossfilter/issues/55\n. Are you willing to rewrite my code to accomodate this API change? :)\n. I'm no javascript expert, but I'm not certain deliberate use of undefined is a common idiom in js apis. I pose it as a question.\nThere may also be some precedent (expectations) based on null and three-state logic used in SQL.\nWe have a textbook case here in the difficulty of executing the principle of least astonishment. Honestly when I used filter(null) it seemed very natural. But again, my data does not contain nulls, so I never filter on a null value.\n. I'm not passionate about it either way, but FYI here is my typical use case.\nvar filter = someControlViewer.getTheFilter();\ndimension.filter(filter);\nSo.. the proposal means my control needs to return \"undefined\" rather than \"null\" to mean - there is no filter selected. As I mention previously, this is a bit of an odd idiom.\nAlternatively, I need intermediary controller logic which determines if the control's filter is empty, or selected, and calls concrete methods filterExact(filter) or filterAll(). By this logic, the filter() method is completely unnecessary and redundant.\nAs a convenience function filter() has the exact semantics I am looking for and follows \"null as empty\" conventions I am accustomed to. Rather than describe this as an \"inconsistency\", I would argue it is a very useful feature.\n. \"dimension.filter(filter||undefined);\"\nIf your goal with this bit of code is a more consistent, readable and easily understood API, you have failed, at least for me. Now we have not only added \"undefined\", but the null || idiom in passing function arguments. Pity the junior coder that comes along on the project and tries to unravel the reason for this, or the outsourced overseas agency that needs to make a quick change on a short term contract. \nI leave these kinds of gymnastics to the js minifiers but understand it is a personal preference to style. I guess we will have to disagree on this.\n. Addendum.\nI stumbled into this bug only by accident on seeing rogue reduce.add() / reduce.remove() calls - objects I thought had gone out of scope but were still alive. I think this is due to the symantics and naming:\ncrossfilter.group()\ndoesn't really indicate a new and connected object will be created (well... you could say the same about the dimension() call but its more apparent in the documentation that these are \"heavyweight\"). I would rather see this renamed \"crossfilter.addGroup()\", and the corresponding crossfilter.removeGroup().\n-or-\nreimplement these as flyweight closure classes that are truly compute on demand.\n. \"You'll want to edit src/crossfilter.js, rather than the concatenated generated crossfilter.js\"\nDone.\n. \"Also, would you mind adding tests for the same functionality?\"\nThis is going to be tough. Not familiar with vows or test data, and I don't have D3. So the test environment setup is a steep hill.\nIn theory, it should be easy to use the top() / bottom() tests, but pull out the dimension value.\n. ",
    "Trakkasure": "It is impossible for the dimension to know exactly what value you want back from the array.  \nYou could just set it on the dimension itself.\n``` javascript\nvar dimAFunc = function(d){return d.field}\n  , d  = cf.dimension(dimAValue)\nd.value = dimAValue\nvar extent = [d.value(d.bottom(1)[0]),d.value(d.top(1)[0])]\n```\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 3:48 PM, aaronaverill wrote:\n\nAssuming like me, the OP wants the min/max dimension value (not the fact row), this is a bit more of a pain than you make it out to be. And in fact is impossible to implement in a generic way because the dimension accessor function (passed into the dimension function) is not stored anywhere on the returned dimension.\nConsider how I would like the implementation to look:\ntopValue: function(dimension) {\nvar topFact = dimension.top(1);\nif (topFact == null || topFact.length == 0) return null; // Handle no fact rows.\nreturn dimension.value(topFact); // Whoops - this doesn't exist!\n}\nA messy hack is to store the dimension accessor function and map to your dimensions, or reproduce the value accessor function. Not Very Dry. Rather I would like to see:\ndimension.topValue()\ndimension.bottomValue()  \n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/28#issuecomment-13520162).\n. I was probably thinking in a totally, and probably wrong, direction\u2026  \n\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 6:07 PM, aaronaverill wrote:\n\n\"It is impossible for the dimension to know exactly what value you want back from the array.\"\nI think there is some confusion. Myself at least (maybe not the OP) - I am looking for the min/max of the actual dimension itself, eg - the value returned from the valueaccessor function parameter passed to crossfilter.dimension(value).\nUsing the test data as an example, say you have a dimension of payment date, these functions would allow you to find in a single call the earliest and latest payment date.\nWe're using these as the range for a jQuery slider that allows to filter on a dimension.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/28#issuecomment-13526267).\n. @jasondavies:\nJust wondering what the scope of lo1 in src/crossfilter.js on line 287 should be.\nIt's being set in global scope.\nIf I comment it out, the tests still work fine.\nintroduced in commit 63d50a3\n. You might want to check with the jasondavies fork of cross filter. He has added some features recently, and might be a good place to send pull requests.  \n\n\nBrandon Myers\nOn Tuesday, January 15, 2013 at 7:47 AM, Martin Daniel wrote:\n\nOk got you. I just had this error while trying to remove a record from the crossfilter :\n\nUncaught TypeError: Cannot read property 'value' of undefined  \n\nI'll try to implement your code in the source file. I'll keep you posted.\nI agree with you, I am sure the owner will have a good way to achieve this task. Unfortunately it looks like this library is not maintained.\nCheers,\nMartin\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/pull/46#issuecomment-12267270).\n. In commit: e528105 there is an issue in that removeListeners becomes global since there is a ; on the line before.\nChange it to , and this should fix it.\n. This is more of a d3 question. Ask on stack overflow, tag d3, or the d3 google group.\n\n--Brandon\nOn Dec 1, 2012, at 4:19 AM, owenhaberf notifications@github.com wrote:\n\nThis may be simple - but I'm new to d3, but how can I modify the crossfilter example to add y-axes with updating axes values? I've managed to add y axes with the following additions to the chart function:\nvar yaxis = d3.svg.axis()\n.scale(y)\n.orient(\"left\")\n.ticks(5)\n.tickFormat(function (v) { return v / 2; });\nand\ng.append(\"g\")\n.attr(\"class\", \"yaxis\")\n.call(yaxis)\nThis works fine, I get get axes on all the chart with the correct initial values. However, when the data is filtered the y axis tick values are not updated to reflect the data on the filtered charts. Any help on this would be very much appreciated.\nThanks :-)\n\u2014\nReply to this email directly or view it on GitHub.\n. Yea.. never mind on that. I figured out my problem.\nIt was some of my code altering the result of .all() on a group because all() doesn't return a copy.\nFixed with a .slice(0) on the return.\nSo:\n\n``` javascript\nvar cf = crossfilter(myData)\n  , d1 = cf.dimension(function(d){return d.key1})\n  , d2 = cf.dimension(function(d){return d.key2})\n  , g1 = d1.group()\n  , g2 = d2.group()\n  , x = g.all()\n  , s = []\nwhile(x.length) s.push(x.shift())\npg = cf.pivotGroup([g1,g2]) // Error should occur here\n```\nThat is just an example to expose what is happening. It doesn't do anything interesting.\n. Use cross filter pull request https://github.com/square/crossfilter/pull/33  \nSupports filter unions.\nFor more specific needs, use https://github.com/square/crossfilter/pull/36\nThat supports custom filter functions.\n. Just to be sure, this includes the references to dimensions, and the embedded data within, correct?\nI think I may have a memory leak somewhere in my code that is causing the browser to not release large chunks of memory.\nI use D3 and Crossfilter to display a time series graph with multi-filtered dimensions. (I incorporated union filter code by @JasonDavies )\nIs there a memory profiling tool that you recommend that could help find the problem?  \nOn Thursday, January 17, 2013 at 3:00 PM, Mike Bostock wrote:\n\nDiscarding any references to the old crossfilter object should be sufficient to allow garbage collection.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/52#issuecomment-12391345).\n. Is your code open source?\n\nWell.. that's why I say should\nIt's a proposal for the next version.\nWhen unions, dimension removal, and group removal changes are, possibly, added.\nI took time to update my version of cross filter, and make the changes to my code.\nI posted this because it just seemed odd that for the execution to take that path.\nPass undefined as the parameter, then: update filter() to have if(range === undefined)\nThen, anywhere you call filter(null) update to filter() or filter(undefined).\ni may be oversimplifying things.\n. Actually, it's not deliberately using undefined as a parameter, more so the exclusion of parameters to the filter() function.\nThis should be enough to say that we wish to call filterAll() (which in itself expects no parameters)\nAll other filter handler functions expect one or more parameters.\n. simple change would be: dimension.filter(filter||undefined);\nIf filter is null, the undefined value is passed instead.\nAs a convenience function filter should be meant to filter on whatever is passed.\nIf you pass nothing, nothing is filtered (aka filterAll()) if null is passed, filter on null (as in the filterExact() test cases)\n\nBrandon Myers\nSent with Sparrow (http://www.sparrowmailapp.com/?sig)\nOn Wednesday, February 13, 2013 at 3:15 PM, aaronaverill wrote:\n\nI'm not passionate about it either way, but FYI here is my typical use case.\nvar filter = someControlViewer.getTheFilter();\ndimension.filter(filter);\nSo.. the proposal means my control needs to return \"undefined\" rather than \"null\" to mean - there is no filter selected. As I mention previously, this is a bit of an odd idiom.\nAlternatively, I need intermediary controller logic which determines if the control's filter is empty, or selected, and calls concrete methods filterExact(filter) or filterAll(). By this logic, the filter() method is completely unnessary and redundant.\nAs a convenience function filter() has the exact semantics I am looking for.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/54#issuecomment-13518526).\n. null == undefined\nbut\nnull !== undefined\n\nIn any case, it was just a suggestion since filterExact(null) actually performs a filter function, and I am using filter as a entry for multiple filter types on a common code path. So this would make sense for my case.\nBeing readable, I would indeed split into each filter function based on type\u2026 but I would be repeating the same work that filter already does.\nAdditionally, I use the union feature, which means, for my case, the filter variable as an array could be a union or a filterRange.\nfilter() already does the detection for me. I call dimension.filter.apply with the dimension and data array parameters.\nIf I have no values to filter, then filter() is called with no parameters, which means filterAll(), one value filterExact (even if null), etc\u2026.\nFrom the test cases, there are several values of \"null\" for tip. (which is suppose to convert to zero) for numeric values that is fine.\nBut for string or object values where null means null, this might be a problem. I don't know yet as I haven't hit that possibility.\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 4:22 PM, Mike Bostock wrote:\n\nHaving different behavior for null vs. undefined is a bit surprising, since null == undefined and they are sometimes used ambiguously. More generally, dimension.filter is a convenience function for calling dimension.filterExact, dimension.filterRange or dimension.filterAll; so, if you want to be unambiguous, you should use those methods exclusively rather than dimension.filter.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/54#issuecomment-13521941).\n. I could write them.  \n\nI won't be able to get to it until tomorrow.\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 6:03 PM, aaronaverill wrote:\n\n\"Also, would you mind adding tests for the same functionality?\"\nThis is going to be tough. Not familiar with vows or test data, and I don't have D3. So the test environment setup is a steep hill.\nIn theory, it should be easy to use the top() / bottom() tests, but pull out the dimension value.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/pull/56#issuecomment-13526130).\n. That's an excellent idea.  \n\nLet us know when you've completed it. :)  \n\nBrandon Myers\nOn Wednesday, March 20, 2013 at 9:49 AM, Ziggy Jonsson wrote:\n\nAfter few failed attempts to read the crossfilter code in one sitting, I realized that a \"Technical overview\" wiki page could be immensely helpful.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/70).\n. It is impossible for the dimension to know exactly what value you want back from the array.  \n\nYou could just set it on the dimension itself.\n``` javascript\nvar dimAFunc = function(d){return d.field}\n  , d  = cf.dimension(dimAValue)\nd.value = dimAValue\nvar extent = [d.value(d.bottom(1)[0]),d.value(d.top(1)[0])]\n```\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 3:48 PM, aaronaverill wrote:\n\nAssuming like me, the OP wants the min/max dimension value (not the fact row), this is a bit more of a pain than you make it out to be. And in fact is impossible to implement in a generic way because the dimension accessor function (passed into the dimension function) is not stored anywhere on the returned dimension.\nConsider how I would like the implementation to look:\ntopValue: function(dimension) {\nvar topFact = dimension.top(1);\nif (topFact == null || topFact.length == 0) return null; // Handle no fact rows.\nreturn dimension.value(topFact); // Whoops - this doesn't exist!\n}\nA messy hack is to store the dimension accessor function and map to your dimensions, or reproduce the value accessor function. Not Very Dry. Rather I would like to see:\ndimension.topValue()\ndimension.bottomValue()  \n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/28#issuecomment-13520162).\n. I was probably thinking in a totally, and probably wrong, direction\u2026  \n\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 6:07 PM, aaronaverill wrote:\n\n\"It is impossible for the dimension to know exactly what value you want back from the array.\"\nI think there is some confusion. Myself at least (maybe not the OP) - I am looking for the min/max of the actual dimension itself, eg - the value returned from the valueaccessor function parameter passed to crossfilter.dimension(value).\nUsing the test data as an example, say you have a dimension of payment date, these functions would allow you to find in a single call the earliest and latest payment date.\nWe're using these as the range for a jQuery slider that allows to filter on a dimension.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/28#issuecomment-13526267).\n. @jasondavies:\nJust wondering what the scope of lo1 in src/crossfilter.js on line 287 should be.\nIt's being set in global scope.\nIf I comment it out, the tests still work fine.\nintroduced in commit 63d50a3\n. You might want to check with the jasondavies fork of cross filter. He has added some features recently, and might be a good place to send pull requests.  \n\n\nBrandon Myers\nOn Tuesday, January 15, 2013 at 7:47 AM, Martin Daniel wrote:\n\nOk got you. I just had this error while trying to remove a record from the crossfilter :\n\nUncaught TypeError: Cannot read property 'value' of undefined  \n\nI'll try to implement your code in the source file. I'll keep you posted.\nI agree with you, I am sure the owner will have a good way to achieve this task. Unfortunately it looks like this library is not maintained.\nCheers,\nMartin\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/pull/46#issuecomment-12267270).\n. In commit: e528105 there is an issue in that removeListeners becomes global since there is a ; on the line before.\nChange it to , and this should fix it.\n. This is more of a d3 question. Ask on stack overflow, tag d3, or the d3 google group.\n\n--Brandon\nOn Dec 1, 2012, at 4:19 AM, owenhaberf notifications@github.com wrote:\n\nThis may be simple - but I'm new to d3, but how can I modify the crossfilter example to add y-axes with updating axes values? I've managed to add y axes with the following additions to the chart function:\nvar yaxis = d3.svg.axis()\n.scale(y)\n.orient(\"left\")\n.ticks(5)\n.tickFormat(function (v) { return v / 2; });\nand\ng.append(\"g\")\n.attr(\"class\", \"yaxis\")\n.call(yaxis)\nThis works fine, I get get axes on all the chart with the correct initial values. However, when the data is filtered the y axis tick values are not updated to reflect the data on the filtered charts. Any help on this would be very much appreciated.\nThanks :-)\n\u2014\nReply to this email directly or view it on GitHub.\n. Yea.. never mind on that. I figured out my problem.\nIt was some of my code altering the result of .all() on a group because all() doesn't return a copy.\nFixed with a .slice(0) on the return.\nSo:\n\n``` javascript\nvar cf = crossfilter(myData)\n  , d1 = cf.dimension(function(d){return d.key1})\n  , d2 = cf.dimension(function(d){return d.key2})\n  , g1 = d1.group()\n  , g2 = d2.group()\n  , x = g.all()\n  , s = []\nwhile(x.length) s.push(x.shift())\npg = cf.pivotGroup([g1,g2]) // Error should occur here\n```\nThat is just an example to expose what is happening. It doesn't do anything interesting.\n. Use cross filter pull request https://github.com/square/crossfilter/pull/33  \nSupports filter unions.\nFor more specific needs, use https://github.com/square/crossfilter/pull/36\nThat supports custom filter functions.\n. Just to be sure, this includes the references to dimensions, and the embedded data within, correct?\nI think I may have a memory leak somewhere in my code that is causing the browser to not release large chunks of memory.\nI use D3 and Crossfilter to display a time series graph with multi-filtered dimensions. (I incorporated union filter code by @JasonDavies )\nIs there a memory profiling tool that you recommend that could help find the problem?  \nOn Thursday, January 17, 2013 at 3:00 PM, Mike Bostock wrote:\n\nDiscarding any references to the old crossfilter object should be sufficient to allow garbage collection.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/52#issuecomment-12391345).\n. Is your code open source?\n\nWell.. that's why I say should\nIt's a proposal for the next version.\nWhen unions, dimension removal, and group removal changes are, possibly, added.\nI took time to update my version of cross filter, and make the changes to my code.\nI posted this because it just seemed odd that for the execution to take that path.\nPass undefined as the parameter, then: update filter() to have if(range === undefined)\nThen, anywhere you call filter(null) update to filter() or filter(undefined).\ni may be oversimplifying things.\n. Actually, it's not deliberately using undefined as a parameter, more so the exclusion of parameters to the filter() function.\nThis should be enough to say that we wish to call filterAll() (which in itself expects no parameters)\nAll other filter handler functions expect one or more parameters.\n. simple change would be: dimension.filter(filter||undefined);\nIf filter is null, the undefined value is passed instead.\nAs a convenience function filter should be meant to filter on whatever is passed.\nIf you pass nothing, nothing is filtered (aka filterAll()) if null is passed, filter on null (as in the filterExact() test cases)\n\nBrandon Myers\nSent with Sparrow (http://www.sparrowmailapp.com/?sig)\nOn Wednesday, February 13, 2013 at 3:15 PM, aaronaverill wrote:\n\nI'm not passionate about it either way, but FYI here is my typical use case.\nvar filter = someControlViewer.getTheFilter();\ndimension.filter(filter);\nSo.. the proposal means my control needs to return \"undefined\" rather than \"null\" to mean - there is no filter selected. As I mention previously, this is a bit of an odd idiom.\nAlternatively, I need intermediary controller logic which determines if the control's filter is empty, or selected, and calls concrete methods filterExact(filter) or filterAll(). By this logic, the filter() method is completely unnessary and redundant.\nAs a convenience function filter() has the exact semantics I am looking for.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/54#issuecomment-13518526).\n. null == undefined\nbut\nnull !== undefined\n\nIn any case, it was just a suggestion since filterExact(null) actually performs a filter function, and I am using filter as a entry for multiple filter types on a common code path. So this would make sense for my case.\nBeing readable, I would indeed split into each filter function based on type\u2026 but I would be repeating the same work that filter already does.\nAdditionally, I use the union feature, which means, for my case, the filter variable as an array could be a union or a filterRange.\nfilter() already does the detection for me. I call dimension.filter.apply with the dimension and data array parameters.\nIf I have no values to filter, then filter() is called with no parameters, which means filterAll(), one value filterExact (even if null), etc\u2026.\nFrom the test cases, there are several values of \"null\" for tip. (which is suppose to convert to zero) for numeric values that is fine.\nBut for string or object values where null means null, this might be a problem. I don't know yet as I haven't hit that possibility.\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 4:22 PM, Mike Bostock wrote:\n\nHaving different behavior for null vs. undefined is a bit surprising, since null == undefined and they are sometimes used ambiguously. More generally, dimension.filter is a convenience function for calling dimension.filterExact, dimension.filterRange or dimension.filterAll; so, if you want to be unambiguous, you should use those methods exclusively rather than dimension.filter.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/54#issuecomment-13521941).\n. I could write them.  \n\nI won't be able to get to it until tomorrow.\n\nBrandon Myers\nOn Wednesday, February 13, 2013 at 6:03 PM, aaronaverill wrote:\n\n\"Also, would you mind adding tests for the same functionality?\"\nThis is going to be tough. Not familiar with vows or test data, and I don't have D3. So the test environment setup is a steep hill.\nIn theory, it should be easy to use the top() / bottom() tests, but pull out the dimension value.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/pull/56#issuecomment-13526130).\n. That's an excellent idea.  \n\nLet us know when you've completed it. :)  \n\nBrandon Myers\nOn Wednesday, March 20, 2013 at 9:49 AM, Ziggy Jonsson wrote:\n\nAfter few failed attempts to read the crossfilter code in one sitting, I realized that a \"Technical overview\" wiki page could be immensely helpful.\n\u2014\nReply to this email directly or view it on GitHub (https://github.com/square/crossfilter/issues/70).\n. \n",
    "vladisac": "I trust this will get you along http://nickqizhu.github.com/dc.js/\n. I trust this will get you along http://nickqizhu.github.com/dc.js/\n. ",
    "LeonFedotov": "jsmin, but i guess that UglifyJS is just looking for these +[space]+p and adds the parentheses itself, i would suggest you to run your code trough jshint, jslint and get it cleaned up + spaced :)\n. jsmin, but i guess that UglifyJS is just looking for these +[space]+p and adds the parentheses itself, i would suggest you to run your code trough jshint, jslint and get it cleaned up + spaced :)\n. ",
    "ZJONSSON": "This is really helpful Jason! \n. I have been exploring Crossfilter on a node.js server with dynamic updating through Ajax (or websockets).  The main benefit is faster browser initiation speed since the filter is already prepared.    But this setup could also circumvent browser related javascript issues, provided the Node V8 engine on the server is sound?\nI forked a quick example here with the code split between node.js and index.html:\nhttps://github.com/ZJONSSON/crossfilter/tree/gh-pages-ajax\nThis code is live for a short time here: \nhttp://zjonsson.com:8888/\n. Another browser issue is data-size.  Chrome kills a page when memory use goes over 100mb.  I manage to avoid the problem by running the filter on a server instead.\nMoved the flights example to Heroku:  http://flights-ajax.herokuapp.com/\nAnd here is another example close to home: http://icequake.herokuapp.com/\n. Fantastic!\n. I'd be more than happy to put time into it, but still lack good understanding how the code ties together.   I was hoping a technical overview might benefit a wide audience.\n. That is fantastic @gordonwoodhull look forward reading it.   You should really post it on the Wiki as a new page (Technical overview)  https://github.com/square/crossfilter/wiki/_pages   You can state at the top that the document is a draft and ask for comments/modifications?\n. @gordonwoodhull, maybe you could post it to this thread for discussion?\n. This is really helpful Jason! \n. I have been exploring Crossfilter on a node.js server with dynamic updating through Ajax (or websockets).  The main benefit is faster browser initiation speed since the filter is already prepared.    But this setup could also circumvent browser related javascript issues, provided the Node V8 engine on the server is sound?\nI forked a quick example here with the code split between node.js and index.html:\nhttps://github.com/ZJONSSON/crossfilter/tree/gh-pages-ajax\nThis code is live for a short time here: \nhttp://zjonsson.com:8888/\n. Another browser issue is data-size.  Chrome kills a page when memory use goes over 100mb.  I manage to avoid the problem by running the filter on a server instead.\nMoved the flights example to Heroku:  http://flights-ajax.herokuapp.com/\nAnd here is another example close to home: http://icequake.herokuapp.com/\n. Fantastic!\n. I'd be more than happy to put time into it, but still lack good understanding how the code ties together.   I was hoping a technical overview might benefit a wide audience.\n. That is fantastic @gordonwoodhull look forward reading it.   You should really post it on the Wiki as a new page (Technical overview)  https://github.com/square/crossfilter/wiki/_pages   You can state at the top that the document is a draft and ask for comments/modifications?\n. @gordonwoodhull, maybe you could post it to this thread for discussion?\n. ",
    "enjalot": "This definitely saved me a lot of trouble! Thanks.\nHere is a simple example of using arrays: http://enjalot.com/tributary/3955491/\n. This definitely saved me a lot of trouble! Thanks.\nHere is a simple example of using arrays: http://enjalot.com/tributary/3955491/\n. ",
    "evenwestvang": "A great many thanks for authoring this Jason. I'm currently working on a project where this is very handy and I've set up a little regexp filter for a text dimension. It works great apart from one of the 6 dimensions simply not updating its group once an arbitrary filter has been set. Clearing the filter on the dimension with filterAll doesn't help.\nI've coerced it into behaving by exposing the resetMany call on group and calling it manually on the recalcitrant chart for every renderAll. I'll see if I can work up a negative test for this, but I'm wondering what's causing it since the other groups are updating fine.\n. I'd offer my time, but the internals of Crossfilter seem daunting. Scary, even. Substituting a firm grasp of reality with intuition I'd go with a change in the typed arrays. I'll check the dev and canary builds to see if help is on the way upstream.\n. Both 24.0.1284.2 dev and 24.0.1285.0 canary display the same behaviour.\n. Excellent, and well spotted. I'll be watching that thread.\n. Yes, as far as I can tell this has been resolved.\n. A great many thanks for authoring this Jason. I'm currently working on a project where this is very handy and I've set up a little regexp filter for a text dimension. It works great apart from one of the 6 dimensions simply not updating its group once an arbitrary filter has been set. Clearing the filter on the dimension with filterAll doesn't help.\nI've coerced it into behaving by exposing the resetMany call on group and calling it manually on the recalcitrant chart for every renderAll. I'll see if I can work up a negative test for this, but I'm wondering what's causing it since the other groups are updating fine.\n. I'd offer my time, but the internals of Crossfilter seem daunting. Scary, even. Substituting a firm grasp of reality with intuition I'd go with a change in the typed arrays. I'll check the dev and canary builds to see if help is on the way upstream.\n. Both 24.0.1284.2 dev and 24.0.1285.0 canary display the same behaviour.\n. Excellent, and well spotted. I'll be watching that thread.\n. Yes, as far as I can tell this has been resolved.\n. ",
    "sjzabel": "Thank you Jason... I'm using this in conjunction with the D3 geo library to filter data by state selection\n. I have the same question. Essentially, I'm working with a data set that has a dimension for US state code and a selection model that allows the user to select multiple states from a map. Is it possible to filter using crossfilter in this manner? \n. Thanks for the insight... I just pulled 36 and it looks like it works\n. Thank you Jason... I'm using this in conjunction with the D3 geo library to filter data by state selection\n. I have the same question. Essentially, I'm working with a data set that has a dimension for US state code and a selection model that allows the user to select multiple states from a map. Is it possible to filter using crossfilter in this manner? \n. Thanks for the insight... I just pulled 36 and it looks like it works\n. ",
    "kisielk": "Just wondering if there's a reason this hasn't been merged yet? We are looking at using this same functionality for custom regexp filters.\n. Just wondering if there's a reason this hasn't been merged yet? We are looking at using this same functionality for custom regexp filters.\n. ",
    "RoxanaTorre": "Should it be possible with #64 to filter two or more values of a (categorical) dimension? and if so, how?\nThanks\n. Thanks a lot!! I understand how this works now!\n. Should it be possible with #64 to filter two or more values of a (categorical) dimension? and if so, how?\nThanks\n. Thanks a lot!! I understand how this works now!\n. ",
    "jaytjioe": "Hi there! I've been a \"fan\" of Crossfilter for more than year now and I'm really excited with all the updates that have been implemented recently. Kudos to the contributors! However, I'm a lil confused with how Github works and I'm wondering what's the latest version of Crossfilter in accordance with @jasondavies repo - is it 1.1.3 or 1.1.2?\nApparently, 1.1.2 is able to have custom filter as mentioned above but 1.1.3 has no such capabilities yet?\nAlso, has the ability to filter multiple arguments as such \"dimension.filter([1,5],10,[13,16])\" been implemented? A solution was mentioned in #22 but I can't seem to do such filtering using Crossfilter 1.1.2. If it hasn't, then is there any way I could do such filtering using version 1.1.2?\nThanks for the help rendered!\n. Hi there! I've been a \"fan\" of Crossfilter for more than year now and I'm really excited with all the updates that have been implemented recently. Kudos to the contributors! However, I'm a lil confused with how Github works and I'm wondering what's the latest version of Crossfilter in accordance with @jasondavies repo - is it 1.1.3 or 1.1.2?\nApparently, 1.1.2 is able to have custom filter as mentioned above but 1.1.3 has no such capabilities yet?\nAlso, has the ability to filter multiple arguments as such \"dimension.filter([1,5],10,[13,16])\" been implemented? A solution was mentioned in #22 but I can't seem to do such filtering using Crossfilter 1.1.2. If it hasn't, then is there any way I could do such filtering using version 1.1.2?\nThanks for the help rendered!\n. ",
    "jlv100": "Thanks for your response, Jason-\nI had already considered issue #3.  I'm using the latest version, so NaN's are being sorted- the problem is they create a huge bar in my histograms that overshadows all others.  That's why I need the reduce function to ignore them entirely.  But, when I try to override the reduce function, I get all kinds of negative and erroneous bars.\nIn the example flight data, consider a situation where all flights to a certain subset of destinations have no flight distance value (it doesn't make sense in this context, but just go with it).  How would you get the example histograms to ignore those missing values?\nThanks again.\n. Thanks for your response, Jason-\nI had already considered issue #3.  I'm using the latest version, so NaN's are being sorted- the problem is they create a huge bar in my histograms that overshadows all others.  That's why I need the reduce function to ignore them entirely.  But, when I try to override the reduce function, I get all kinds of negative and erroneous bars.\nIn the example flight data, consider a situation where all flights to a certain subset of destinations have no flight distance value (it doesn't make sense in this context, but just go with it).  How would you get the example histograms to ignore those missing values?\nThanks again.\n. ",
    "niko": "I have the same issue. I applied the patch, but still the huge bar for the zero value overshadows all other bars in the graph. How can I ignore some values alltogether?\n. I have the same issue. I applied the patch, but still the huge bar for the zero value overshadows all other bars in the graph. How can I ignore some values alltogether?\n. ",
    "jacobsandlund": "I also found this issue when working on DataZooka. If you play around with it, you can see weird things going on. I noticed that sometimes it would throw a TypeError here in the updateMany routine.\n. I reduced the size even further by renaming the crossfilter/index module as crossfilter. That saved 13 bytes, to bring it down to 319 bytes (or 9.97%--hey, less than ten percent!) added overall.\nThe next commit removes src/version.js, and just builds it with the version parsed from package.json. This makes it so src/package.js is unnecessary, and saves another ten bytes (309, or 9.7% added). The downside being that crossfilter has no \"version\" property in node. If you removed \"version\" altogether (didn't build it in), that would save another 12 bytes (297, or 9.3% added).\n. This last commit doesn't change vaccine.js functionally, it just optimizes the require routine for minification. Down to 301 bytes (9.4%) added.\n. I also found this issue when working on DataZooka. If you play around with it, you can see weird things going on. I noticed that sometimes it would throw a TypeError here in the updateMany routine.\n. I reduced the size even further by renaming the crossfilter/index module as crossfilter. That saved 13 bytes, to bring it down to 319 bytes (or 9.97%--hey, less than ten percent!) added overall.\nThe next commit removes src/version.js, and just builds it with the version parsed from package.json. This makes it so src/package.js is unnecessary, and saves another ten bytes (309, or 9.7% added). The downside being that crossfilter has no \"version\" property in node. If you removed \"version\" altogether (didn't build it in), that would save another 12 bytes (297, or 9.3% added).\n. This last commit doesn't change vaccine.js functionally, it just optimizes the require routine for minification. Down to 301 bytes (9.4%) added.\n. ",
    "jnordberg": "I also ran in to this issue. It seems to be fixed in beta channel now (using 23.0.1271.26)\n. I also ran in to this issue. It seems to be fixed in beta channel now (using 23.0.1271.26)\n. ",
    "gkostov": "I just came to the same problem and #36 seems to be solving it. So you could do\njavascript\nvar matcher=/pattern/g;\ndim.filter(function (val, ind){\n    return matcher.test(val);\n});\n. I just came to the same problem and #36 seems to be solving it. So you could do\njavascript\nvar matcher=/pattern/g;\ndim.filter(function (val, ind){\n    return matcher.test(val);\n});\n. ",
    "strathmeyer": "I'll see what I can do!  :poodle: \n. I'll see what I can do!  :poodle: \n. ",
    "davidkbainbridge": "I am looking to leverage crossfilter for time series data, used mostly for graphing. Part of the need is for moving time window graphs. The ability to add data to a crossfilter works find for adding data, but removing data is needed as well, which is why I am interested in this fork. \nThe question I have is as opposed to, or rather in addition to, being about to specify the \"entity\" to be removed it would be interesting to be able to apply a \"filter function\" to a crossfilter where if the function returned \"true\" then the data point would be removed, else it would be left in the set (or the reverse). \nThis way, for time series data, i could use the filter to control the time amount of data in the cross filter based on a moving time window.\nI see this as an extension of this work, but curious on your thoughts.\n. I am seeing unexpected behavior when using the remove function, in that when adding elements to a crossfilter I see the dimensions and the groups get updated (i.e. their various accessor and filters are called), but when I remove records these methods are not called and the dimensions and groups associated with the crossfilter don't seem to be updated.\nI expected that I would see similar action when removing data as when adding it.\nAs a example, assuming data points of { key : , value :  } where key is [a..d]:\n1) create crossfilter of (a..d);\n2) create identity dimension\n3) create identity group\n4) reduceCount group (there are now 3 groups each with a value of 1)\n5) add data point 'd' to crossfilter (there are now 4 groups each with a value of 1)\n6) remove data point 'c' \n*) there are still 4 groups, 3 of which have a value of 1 and the other has a value of 0\nWhile this is technically correct, I suppose, I would expect to see 3 groups, i.e. a regrouping to occur on a delete. The symmetry would be that groups are added when values are added to the crossfilter, shouldn't they also be removed when data is removed?\n. I am looking to leverage crossfilter for time series data, used mostly for graphing. Part of the need is for moving time window graphs. The ability to add data to a crossfilter works find for adding data, but removing data is needed as well, which is why I am interested in this fork. \nThe question I have is as opposed to, or rather in addition to, being about to specify the \"entity\" to be removed it would be interesting to be able to apply a \"filter function\" to a crossfilter where if the function returned \"true\" then the data point would be removed, else it would be left in the set (or the reverse). \nThis way, for time series data, i could use the filter to control the time amount of data in the cross filter based on a moving time window.\nI see this as an extension of this work, but curious on your thoughts.\n. I am seeing unexpected behavior when using the remove function, in that when adding elements to a crossfilter I see the dimensions and the groups get updated (i.e. their various accessor and filters are called), but when I remove records these methods are not called and the dimensions and groups associated with the crossfilter don't seem to be updated.\nI expected that I would see similar action when removing data as when adding it.\nAs a example, assuming data points of { key : , value :  } where key is [a..d]:\n1) create crossfilter of (a..d);\n2) create identity dimension\n3) create identity group\n4) reduceCount group (there are now 3 groups each with a value of 1)\n5) add data point 'd' to crossfilter (there are now 4 groups each with a value of 1)\n6) remove data point 'c' \n*) there are still 4 groups, 3 of which have a value of 1 and the other has a value of 0\nWhile this is technically correct, I suppose, I would expect to see 3 groups, i.e. a regrouping to occur on a delete. The symmetry would be that groups are added when values are added to the crossfilter, shouldn't they also be removed when data is removed?\n. ",
    "chondl": "Thanks.  I had seen your fork as well, but for my project I was looking for an API where I wouldn't have to think about the pivot grouping when writing the reduce functions.  I haven't looked at how to tie this into one of the various charting components that use crossfilter since currently I'm using crossfilter inside node to create Excel and PDF tabular reports.  Hopefully there will be a future version of crossfilter with some version of pivot groups built in.\n. I'm not sure I understand the question Brandon asked about \"imagine trying\nto sum the values of a column in group A while counting the ones the group\nB\".   Perhaps you can send a simple example with a few records and the\nexpected results of the calculation?\nThe pivot group just supports grouping the records by the dimension and the\nreduce function has access to all records in the group as they are added\nand removed.\nOn Thu, Feb 7, 2013 at 10:21 AM, Brandon notifications@github.com wrote:\n\nI see the reduce methods in the pivot group, but imagine that I want to\nadjust the group to be used in the pivot before the pivot combines them.\nSo, imagine trying to sum the values of a column in group A while counting\nthe ones the group B\nThen, in the pivot, multiply the 2 values in the reduce.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/pull/48#issuecomment-13251495.\n. I've been using it within my node.js application for report generation for the past several months, but haven't heard from anyone else using it.\n. The alternative of creating a compound dimension using a separator is reasonable, and I've used it in other situations.  \n\nOne drawback is that I've encountered performance issues using the compound dimension technique in other situations due to the string manipulation.  That said, I don't have head-to-head benchmarks of the compound dimension technique against this pull request.\nWith crossfilter, I wanted something that took advantage of the existing group indexes and had an API expressed in terms of tuples as opposed to the compound strings.\n. Thanks.  I had seen your fork as well, but for my project I was looking for an API where I wouldn't have to think about the pivot grouping when writing the reduce functions.  I haven't looked at how to tie this into one of the various charting components that use crossfilter since currently I'm using crossfilter inside node to create Excel and PDF tabular reports.  Hopefully there will be a future version of crossfilter with some version of pivot groups built in.\n. I'm not sure I understand the question Brandon asked about \"imagine trying\nto sum the values of a column in group A while counting the ones the group\nB\".   Perhaps you can send a simple example with a few records and the\nexpected results of the calculation?\nThe pivot group just supports grouping the records by the dimension and the\nreduce function has access to all records in the group as they are added\nand removed.\nOn Thu, Feb 7, 2013 at 10:21 AM, Brandon notifications@github.com wrote:\n\nI see the reduce methods in the pivot group, but imagine that I want to\nadjust the group to be used in the pivot before the pivot combines them.\nSo, imagine trying to sum the values of a column in group A while counting\nthe ones the group B\nThen, in the pivot, multiply the 2 values in the reduce.\n\u2014\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/pull/48#issuecomment-13251495.\n. I've been using it within my node.js application for report generation for the past several months, but haven't heard from anyone else using it.\n. The alternative of creating a compound dimension using a separator is reasonable, and I've used it in other situations.  \n\nOne drawback is that I've encountered performance issues using the compound dimension technique in other situations due to the string manipulation.  That said, I don't have head-to-head benchmarks of the compound dimension technique against this pull request.\nWith crossfilter, I wanted something that took advantage of the existing group indexes and had an API expressed in terms of tuples as opposed to the compound strings.\n. ",
    "JDvorak": "Has anything been done with this in the last few months?\n. I would also be interested in this being made more official\n. Has anything been done with this in the last few months?\n. I would also be interested in this being made more official\n. ",
    "navr84": "Is it possible to return crossfilter objects from the worker to the main script. I tried serializing the objects and then deserialising them , but it doesnt work since it looks like crossfilter uses quite a lot of closures within the code. \n. Is it possible to return crossfilter objects from the worker to the main script. I tried serializing the objects and then deserialising them , but it doesnt work since it looks like crossfilter uses quite a lot of closures within the code. \n. ",
    "arunsoman": "any fixes planned in near future ?\n. +1\n. any fixes planned in near future ?\n. +1\n. ",
    "asherkin": "Removing the newline from the end of my CSV file does indeed seemed to have fixed both erroneous matches (which is even odder as one of them is in the middle of the file), thanks @RandomEtc.\n. Removing the newline from the end of my CSV file does indeed seemed to have fixed both erroneous matches (which is even odder as one of them is in the middle of the file), thanks @RandomEtc.\n. ",
    "jykim": "Works beautifully now. Thanks for the quick response!\n. Works beautifully now. Thanks for the quick response!\n. ",
    "neverfox": "That's close, yes. It would actually be:\nSQL\nSELECT yearmo, AVG(value1)... -- for each series included on the trend chart\nFROM table\nWHERE (yearmo = 'Jan 13'\n  AND (value1 BETWEEN 80 AND 100)\n  AND (value7 BETWEEN 80 AND 100))\n   OR yearmo <> 'Jan 13'\nGROUP BY yearmo\n. Unfortunately, no. The goal is to filter the set of entities down based on the selected month ranges and then view the trend lines for those entities. Putting that in terms of a simple, real-world use case, the user would request entities who are currently above some threshold (e.g. value1 and value7 >= 80) and then they could glance at the trend lines to see how that subset is trending. For the trendlines representing value1 and value7, they would essentially be constraining that point somewhere between 80 and 100.\n. Thank you. I will try this out and see how it goes. So if I use crossfilter.js from the 1.2.0 branch, it will contain this extra functionality?\n. Looking back on the SQL I posted, it's wrong for my purposes. In reality it would be this:\nSQL\nSELECT yearmo, AVG(value1), ...\n  FROM table\n WHERE id IN (SELECT DISTINCT id FROM table WHERE yearmo = 'Jan 13' AND value7 BETWEEN 80 AND 100)\n GROUP BY yearmo\nSo for the following data:\nid  yearmo  value1  value7\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n2  Nov 12  50  50\n2  Dec 12  60  60\n2  Jan 13  70  70\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\nI would get, which is what I want for the trend graph:\nid  yearmo  value1  value7\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\nThe old query would have given me:\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n2  Nov 12  50  50 <= No\n2  Dec 12  60  60 <= No\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\n. That's close, yes. It would actually be:\nSQL\nSELECT yearmo, AVG(value1)... -- for each series included on the trend chart\nFROM table\nWHERE (yearmo = 'Jan 13'\n  AND (value1 BETWEEN 80 AND 100)\n  AND (value7 BETWEEN 80 AND 100))\n   OR yearmo <> 'Jan 13'\nGROUP BY yearmo\n. Unfortunately, no. The goal is to filter the set of entities down based on the selected month ranges and then view the trend lines for those entities. Putting that in terms of a simple, real-world use case, the user would request entities who are currently above some threshold (e.g. value1 and value7 >= 80) and then they could glance at the trend lines to see how that subset is trending. For the trendlines representing value1 and value7, they would essentially be constraining that point somewhere between 80 and 100.\n. Thank you. I will try this out and see how it goes. So if I use crossfilter.js from the 1.2.0 branch, it will contain this extra functionality?\n. Looking back on the SQL I posted, it's wrong for my purposes. In reality it would be this:\nSQL\nSELECT yearmo, AVG(value1), ...\n  FROM table\n WHERE id IN (SELECT DISTINCT id FROM table WHERE yearmo = 'Jan 13' AND value7 BETWEEN 80 AND 100)\n GROUP BY yearmo\nSo for the following data:\nid  yearmo  value1  value7\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n2  Nov 12  50  50\n2  Dec 12  60  60\n2  Jan 13  70  70\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\nI would get, which is what I want for the trend graph:\nid  yearmo  value1  value7\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\nThe old query would have given me:\n1  Nov 12  60  60\n1  Dec 12  70  70\n1  Jan 13  80  80\n2  Nov 12  50  50 <= No\n2  Dec 12  60  60 <= No\n3  Nov 12  90  90\n3  Dec 12  70  70\n3  Jan 13  90  90\n. ",
    "tvinci": "Are you looking for a tutorial for using it or for a walk through on the actual source code? I've written a tutorial on crossfilter as a basis for using dc.js here:\nhttp://www.codeproject.com/Articles/693841/Making-Dashboards-with-Dc-js-Part-1-Using-Crossfil\n. Are you looking for a tutorial for using it or for a walk through on the actual source code? I've written a tutorial on crossfilter as a basis for using dc.js here:\nhttp://www.codeproject.com/Articles/693841/Making-Dashboards-with-Dc-js-Part-1-Using-Crossfil\n. ",
    "sciyoshi": "Running the benchmarks seems to show around a 5% slowdown for 1,000,000 size dataset. If this isn't acceptable, there might be a way to change the implementation in-place but not sure if that's worth the effort. It's working well enough for me as-is :)\n. @tannerlinsley I've updated the patch to work against the latest master. All the tests are passing, but if @optimuspaul can give a reproducible test case for that issue I can look into it again. It probably needs a bit more testing before it can be merged though.\n. There are still some outstanding issues that I'm aware of - I'll be pushing\na fix with some tests shortly.\nOn Sep 26, 2014 3:36 PM, \"Tanner Linsley\" notifications@github.com wrote:\n\nCould i get a href to the latest patch? I think I was using an older\nversion on my test\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/pull/75#issuecomment-57010067.\n. The latest commit includes fixes for a couple of glaring issues, along with previously-failing tests for filtering with more dimensions. At this point, it should be ready for more rigorous testing if anyone is interested in getting this merged.\n. Running the benchmarks seems to show around a 5% slowdown for 1,000,000 size dataset. If this isn't acceptable, there might be a way to change the implementation in-place but not sure if that's worth the effort. It's working well enough for me as-is :)\n. @tannerlinsley I've updated the patch to work against the latest master. All the tests are passing, but if @optimuspaul can give a reproducible test case for that issue I can look into it again. It probably needs a bit more testing before it can be merged though.\n. There are still some outstanding issues that I'm aware of - I'll be pushing\na fix with some tests shortly.\nOn Sep 26, 2014 3:36 PM, \"Tanner Linsley\" notifications@github.com wrote:\nCould i get a href to the latest patch? I think I was using an older\nversion on my test\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/pull/75#issuecomment-57010067.\n. The latest commit includes fixes for a couple of glaring issues, along with previously-failing tests for filtering with more dimensions. At this point, it should be ready for more rigorous testing if anyone is interested in getting this merged.\n. \n",
    "deanmalmgren": "+1 on this as well. catcorr.js would definitely benefit from >32 dimensions, too. Anything I can do to help? Is @sciyoshi's 5% slowdown ok or should we try to optimize?\nFor what its worth, 5% for me is fine but perhaps others have more stringent requirements.\n. +1 on this as well. catcorr.js would definitely benefit from >32 dimensions, too. Anything I can do to help? Is @sciyoshi's 5% slowdown ok or should we try to optimize?\nFor what its worth, 5% for me is fine but perhaps others have more stringent requirements.\n. ",
    "jefffriesen": "Any way to make this opt-in? So if we're willing to take a performance hit, we can opt-in to enable > 32 dimensions?\n. Yep, this works great.  Maybe a good one for the docs? It's obvious when I see it but wasn't obvious before!\nThanks\n. nice\n. Interesting. Thanks... I'll look into it.\n. I wonder if some people have moved onto other solutions for some reason. Lodash keeps getting faster and more functions. There are now lazy evaluated libraries (lazy.js and immutable.js) which are really performant for large data sets (I don't know if lazy evaluation would make a difference here). transducer.js is another approach that could be fast. \nIs there less activity in this library because it's pretty solid and mostly feature complete? Or is it because people are starting to use other options? Does anyone have a sense of that?\n(btw, It would be awesome to see some benchmarks between crossfilter and the equivalent operations in lazy-eval libs and lodash for small, medium and large datasets)\n. @gordonwoodhull I don't know if anyone has built up something like a .crossfilter() or some combinations of .reduce() and other things. I would be interested to know too.\n@derekperkins I agree with you that dc.js has made crossfilter more popular - that was when I first used it. \nI could imagine someone taking a step further in functionality like reductio. Or I could imagine performance gains for very large datasets or many dimensions, by offloading the computations in a web worker or doing lazy evaluation. But I don't know what's possible or what's out there.\nI am very fond of this library though...\n. Any way to make this opt-in? So if we're willing to take a performance hit, we can opt-in to enable > 32 dimensions?\n. Yep, this works great.  Maybe a good one for the docs? It's obvious when I see it but wasn't obvious before!\nThanks\n. nice\n. Interesting. Thanks... I'll look into it.\n. I wonder if some people have moved onto other solutions for some reason. Lodash keeps getting faster and more functions. There are now lazy evaluated libraries (lazy.js and immutable.js) which are really performant for large data sets (I don't know if lazy evaluation would make a difference here). transducer.js is another approach that could be fast. \nIs there less activity in this library because it's pretty solid and mostly feature complete? Or is it because people are starting to use other options? Does anyone have a sense of that?\n(btw, It would be awesome to see some benchmarks between crossfilter and the equivalent operations in lazy-eval libs and lodash for small, medium and large datasets)\n. @gordonwoodhull I don't know if anyone has built up something like a .crossfilter() or some combinations of .reduce() and other things. I would be interested to know too.\n@derekperkins I agree with you that dc.js has made crossfilter more popular - that was when I first used it. \nI could imagine someone taking a step further in functionality like reductio. Or I could imagine performance gains for very large datasets or many dimensions, by offloading the computations in a web worker or doing lazy evaluation. But I don't know what's possible or what's out there.\nI am very fond of this library though...\n. ",
    "tannerlinsley": "Has there been any more traction on this?  We are in love with crossfilter, but would like the ability for 32 + dimensions.  I realize this would come with performance hits, but all in all, if someone really wants to have that many dimension open, and filtering on those dimensions, I'm sure they would understand that performance will be affected.\nIs @sciyoshi 's PR functional? Has anyone tested it as of late?\n. This specific issue I had, was I was able to build more than 32 dimensions at one time, and that's great but as soon as I started filtering on those dimensions the add and remove functions for grouping were in accurate\n. Could i get a href to the latest patch? I think I was using an older version on my test \n. I think the use case for removeFilter is much needed.  We need to be able to fluidly add and flush rows of data from a crossfilter with ease.  The add functionality is there, but a better option than removing what is currently filtered on is much needed.\n. I agree.  Over at http://github.com/crossfilter/crossfilter (the successor to this repo), we already have some amazing new features, and are discussing some great new docs, a learning playground, and even more revolutionary features you'll want to look at over the next few weeks.  Stay tuned!\n. Not that it has bugs, or that it is incomplete. But there are some features\nthat have yet to be created for it. Simply we just want to make sure it's\ngetting the attention it deserves. Also I volunteer myself and @esjewett as\ncontributors.\nOn Wed, Apr 29, 2015 at 4:47 PM Gordon Woodhull notifications@github.com\nwrote:\n\nDoes crossfilter have any bugs, besides people shooting themselves in the\nfoot and getting stack overflows with NaNs? I think in a sense it is\ncomplete.\nI can't contribute due to the copyright assignment agreement\nhttps://github.com/square/crossfilter/blob/master/CONTRIBUTING.md.\nThat's something that creates a sea of red tape in corporations.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97608341.\n. At least to triage issues and give the repo a sense of activity.\nOn Wed, Apr 29, 2015 at 5:13 PM Tanner Linsley tannerlinsley@gmail.com\nwrote:\nNot that it has bugs, or that it is incomplete. But there are some\nfeatures that have yet to be created for it. Simply we just want to make\nsure it's getting the attention it deserves. Also I volunteer myself and\n@esjewett as contributors.\nOn Wed, Apr 29, 2015 at 4:47 PM Gordon Woodhull notifications@github.com\nwrote:\n\nDoes crossfilter have any bugs, besides people shooting themselves in the\nfoot and getting stack overflows with NaNs? I think in a sense it is\ncomplete.\nI can't contribute due to the copyright assignment agreement\nhttps://github.com/square/crossfilter/blob/master/CONTRIBUTING.md.\nThat's something that creates a sea of red tape in corporations.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97608341.\n. I second that\nOn Wed, Apr 29, 2015 at 5:28 PM Derek Perkins notifications@github.com\nwrote:\n\nI'd love to see some more activity. There are a few PRs that have been\nsubmitted that I'm very interested in, like adding support for more\ndimensions #75 https://github.com/square/crossfilter/pull/75 and one\nthat I can't find by @esjewett https://github.com/esjewett that allowed\nyou to remove rows that don't match the current filter.\n@esjewett https://github.com/esjewett also has\nhttps://github.com/esjewett/reductio that is a good place for a number of\nthings that might be useful but deemed out of the purview of core\ncrossfilter. Maybe moving crossfilter to an official organization so that\nthere could be additional plugins brought into the official crossfilter\necosystem.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97613401.\n. I love crossfilter and reductio and even the idea of having a crossfilter\necosystem for plugins or helpers like it. I'm already in development of a\ndimension and group management micro library that will integrate with both.\nIt would be great to have a home for it.\n\nWho is technically at the reigns right now?\nOn Wed, Apr 29, 2015 at 9:07 PM Jeff Friesen notifications@github.com\nwrote:\n\n@gordonwoodhull https://github.com/gordonwoodhull I don't know if\nanyone has built up something like a .crossfilter() or some combinations\nof .reduce() and other things. I would be interested to know too.\n@derekperkins https://github.com/derekperkins I agree with you that\ndc.js has made crossfilter more popular - that was when I first used it.\nI could imagine someone taking a step further in functionality like\nreductio. Or I could imagine performance gains for very large datasets or\nmany dimensions, by offloading the computations in a web worker or doing\nlazy evaluation. But I don't know what's possible or what's out there.\nI am very fond of this library though...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97646711.\n. I'm on board.\n\nOn Tue, May 12, 2015 at 12:00 PM Derek Perkins notifications@github.com\nwrote:\n\n@gordonwoodhull https://github.com/gordonwoodhull - Great minds think\nalike :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-101366448.\n. Also the great thing here is the crossfilter organization. Sure we don't\nknow if this is the home for anything yet, but at least there is room here\nfor not only new features but also plugins, and enhancements that fall\nunder the crossfilter umbrella.\nOn Thu, Aug 6, 2015 at 6:37 PM Ethan Jewett notifications@github.com\nwrote:\n@dderiso https://github.com/dderiso I'd say that\nhttps://github.com/crossfilter/crossfilter is open to pull requests and\nissues. Probably best to first open an issue to discuss as we only want to\nmake changes that are really required in the core library. We are working\nvery slowly though. It's probably quite premature to say that it is the\nhome for community development as that's the kind of thing I'd prefer to\nshow rather than say, and I don't think we've shown that yet.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-128548864.\n. Has there been any more traction on this?  We are in love with crossfilter, but would like the ability for 32 + dimensions.  I realize this would come with performance hits, but all in all, if someone really wants to have that many dimension open, and filtering on those dimensions, I'm sure they would understand that performance will be affected.\n\nIs @sciyoshi 's PR functional? Has anyone tested it as of late?\n. This specific issue I had, was I was able to build more than 32 dimensions at one time, and that's great but as soon as I started filtering on those dimensions the add and remove functions for grouping were in accurate\n. Could i get a href to the latest patch? I think I was using an older version on my test \n. I think the use case for removeFilter is much needed.  We need to be able to fluidly add and flush rows of data from a crossfilter with ease.  The add functionality is there, but a better option than removing what is currently filtered on is much needed.\n. I agree.  Over at http://github.com/crossfilter/crossfilter (the successor to this repo), we already have some amazing new features, and are discussing some great new docs, a learning playground, and even more revolutionary features you'll want to look at over the next few weeks.  Stay tuned!\n. Not that it has bugs, or that it is incomplete. But there are some features\nthat have yet to be created for it. Simply we just want to make sure it's\ngetting the attention it deserves. Also I volunteer myself and @esjewett as\ncontributors.\nOn Wed, Apr 29, 2015 at 4:47 PM Gordon Woodhull notifications@github.com\nwrote:\n\nDoes crossfilter have any bugs, besides people shooting themselves in the\nfoot and getting stack overflows with NaNs? I think in a sense it is\ncomplete.\nI can't contribute due to the copyright assignment agreement\nhttps://github.com/square/crossfilter/blob/master/CONTRIBUTING.md.\nThat's something that creates a sea of red tape in corporations.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97608341.\n. At least to triage issues and give the repo a sense of activity.\nOn Wed, Apr 29, 2015 at 5:13 PM Tanner Linsley tannerlinsley@gmail.com\nwrote:\nNot that it has bugs, or that it is incomplete. But there are some\nfeatures that have yet to be created for it. Simply we just want to make\nsure it's getting the attention it deserves. Also I volunteer myself and\n@esjewett as contributors.\nOn Wed, Apr 29, 2015 at 4:47 PM Gordon Woodhull notifications@github.com\nwrote:\n\nDoes crossfilter have any bugs, besides people shooting themselves in the\nfoot and getting stack overflows with NaNs? I think in a sense it is\ncomplete.\nI can't contribute due to the copyright assignment agreement\nhttps://github.com/square/crossfilter/blob/master/CONTRIBUTING.md.\nThat's something that creates a sea of red tape in corporations.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97608341.\n. I second that\nOn Wed, Apr 29, 2015 at 5:28 PM Derek Perkins notifications@github.com\nwrote:\n\nI'd love to see some more activity. There are a few PRs that have been\nsubmitted that I'm very interested in, like adding support for more\ndimensions #75 https://github.com/square/crossfilter/pull/75 and one\nthat I can't find by @esjewett https://github.com/esjewett that allowed\nyou to remove rows that don't match the current filter.\n@esjewett https://github.com/esjewett also has\nhttps://github.com/esjewett/reductio that is a good place for a number of\nthings that might be useful but deemed out of the purview of core\ncrossfilter. Maybe moving crossfilter to an official organization so that\nthere could be additional plugins brought into the official crossfilter\necosystem.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97613401.\n. I love crossfilter and reductio and even the idea of having a crossfilter\necosystem for plugins or helpers like it. I'm already in development of a\ndimension and group management micro library that will integrate with both.\nIt would be great to have a home for it.\n\nWho is technically at the reigns right now?\nOn Wed, Apr 29, 2015 at 9:07 PM Jeff Friesen notifications@github.com\nwrote:\n\n@gordonwoodhull https://github.com/gordonwoodhull I don't know if\nanyone has built up something like a .crossfilter() or some combinations\nof .reduce() and other things. I would be interested to know too.\n@derekperkins https://github.com/derekperkins I agree with you that\ndc.js has made crossfilter more popular - that was when I first used it.\nI could imagine someone taking a step further in functionality like\nreductio. Or I could imagine performance gains for very large datasets or\nmany dimensions, by offloading the computations in a web worker or doing\nlazy evaluation. But I don't know what's possible or what's out there.\nI am very fond of this library though...\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-97646711.\n. I'm on board.\n\nOn Tue, May 12, 2015 at 12:00 PM Derek Perkins notifications@github.com\nwrote:\n\n@gordonwoodhull https://github.com/gordonwoodhull - Great minds think\nalike :)\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-101366448.\n. Also the great thing here is the crossfilter organization. Sure we don't\nknow if this is the home for anything yet, but at least there is room here\nfor not only new features but also plugins, and enhancements that fall\nunder the crossfilter umbrella.\nOn Thu, Aug 6, 2015 at 6:37 PM Ethan Jewett notifications@github.com\nwrote:\n@dderiso https://github.com/dderiso I'd say that\nhttps://github.com/crossfilter/crossfilter is open to pull requests and\nissues. Probably best to first open an issue to discuss as we only want to\nmake changes that are really required in the core library. We are working\nvery slowly though. It's probably quite premature to say that it is the\nhome for community development as that's the kind of thing I'd prefer to\nshow rather than say, and I don't think we've shown that yet.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/151#issuecomment-128548864.\n. \n",
    "desingraj": "I used the very new version in my project, which is having more than 32 dimensions. I cant play with cross-filter if the dimension count exceeds 32. \nAny solutions on this. I need to  have more dimensions.\nThanks in advance.\n. I used the very new version in my project, which is having more than 32 dimensions. I cant play with cross-filter if the dimension count exceeds 32. \nAny solutions on this. I need to  have more dimensions.\nThanks in advance.\n. ",
    "toddpi314": "Where did this issue land?  \nI would like retrieve the entire data value for an event without explicitly identifying which fields to include in my response set. \nSomething like this is desired:\nhttp://localhost:1081/1.0/event?expression=eventtype(*).eq(subType,'yo')\n. Where did this issue land?  \nI would like retrieve the entire data value for an event without explicitly identifying which fields to include in my response set. \nSomething like this is desired:\nhttp://localhost:1081/1.0/event?expression=eventtype(*).eq(subType,'yo')\n. ",
    "jeffmaxwell": "Hi Jason, In preparing the jsfiddle I saw that the problem was in my use of top(k). So no issue requiring action.\n. Hi Jason, In preparing the jsfiddle I saw that the problem was in my use of top(k). So no issue requiring action.\n. ",
    "ajpiano": "Dreadfully sorry for the dupe, will pass it along, thanks @jasondavies \n. Dreadfully sorry for the dupe, will pass it along, thanks @jasondavies \n. ",
    "goetas": "sorry, wrong place here to add this issue. is related to dc.js\n. sorry, wrong place here to add this issue. is related to dc.js\n. ",
    "pangratz": ":heart_eyes: \n. :heart_eyes: \n. ",
    "theoreticaLee": "@jasondavies I like the idea, and I would additionally like to reserve the namespace for removing all records in crossfilter.\nSo what about naming it db.removeFiltered() ?\nI am actually having to write my own db.remove() method right now so I can re-add data that has another column worth of information. \nthoughts?\n. Good point about keeping db.remove symmetric w/ db.add.\nLet's just keep it as is then.\nthanks guys\n. @jasondavies I like the idea, and I would additionally like to reserve the namespace for removing all records in crossfilter.\nSo what about naming it db.removeFiltered() ?\nI am actually having to write my own db.remove() method right now so I can re-add data that has another column worth of information. \nthoughts?\n. Good point about keeping db.remove symmetric w/ db.add.\nLet's just keep it as is then.\nthanks guys\n. ",
    "jkleint": "+1; just got bitten by the same problem.  Thanks.\n. +1; just got bitten by the same problem.  Thanks.\n. ",
    "jdarling": "This scenario is actually related to my request to be able to retrieve only the filtered records.  We are using DC.js and thus CrossFilter to provide a dynamic reporting environment to our end users.  Once the users have filtered down their views we want to provide a CSV download to them of only the records they are looking at.\nIf I can get to the filtered record's only then I can extract out the record ID's, send them back to the server, and have it serve up the corresponding CSV file.\nUsing dimension.top doesn't work in this case as the filters come from different locations.  The crossfilter groupAll() method returns a proper group and the .all() method returns the correct # of records affected by all filters, but I can't find a dimension that would then return only those records.\nAnother solution would be to add an each operator to the groupAll() output group allowing iteration of affected records, thus providing a paged way of getting to each record.  This may possibly reduce the overhead, don't know.\nIf I'm wrong, please point me in the right direction :)\n. I thought the dimension only included a subset of the data associated with the root.\nUsing something similar to the follow structure:\n{\n  _id: <Identity>,\n  date: Date(),\n  state: <state text>,\n  ...\n}\nIE: If I have a dimension on \"date\" then I would only see the date column in the dimension.  So performing a top(Infinity) on that dimension wouldn't get me back the _id column as an example.\nIn the above I would have a group all to get the top.  And say I had a dimension on date and state.  Now if I filter based on a state of MO || KS and a date of > 3 days ago my all count goes down to whatever...\nSaying that my root crossfilter is called ndx, then my root ndx records value will have everything including the filtered out records.\nMy goal would be to get only the records that match the filters MO || KS > 3 days ago.  Of course I don't really know what the user has filtered to :)\n. Just tried it with our live data, and of course you are correct :).  I think it would be useful to have this documented explicitly though as I searched for an answer for quite some time before chasing this on GitHub.  Hopefully others find the thread if they run into the same problem.  Great work all over.\n. Yeah I worded that way wrong.\nWhat I am trying to do is build a simple dashboard using dc.js that shows a view of logging data.  My data isn't completely consistent as it is coming from logs.\nThe goal is to have a chart of each inbound call by duration, then another chart of all of the outbound calls by duration.\nI'm guessing that some how I need to create a group that rejects the inbounds for the outbound view and one that rejects the outbounds for the inbound view.  But I can't seem to figure out how exactly to achieve that.\n. Been kinda banging my head on how to create that fake group and push values to it.  Will keep digging, but thanks for the hint :).\n. Thanks Adam, that was exactly the pointer I needed.  Just in case someone\nelse runs into this, here is a GIST that shows how to do a basic example:\nhttps://gist.github.com/jdarling/fb701fcaead21168cb7a\nOn Thu, Jan 8, 2015 at 1:29 AM, Adam Reynolds notifications@github.com\nwrote:\n\nhttps://github.com/dc-js/dc.js/wiki/FAQ\nOn the page. Note I had to also create the top function. Creating just all\ncaused it to error.\nOn 8 Jan 2015 07:05, \"jdarling\" notifications@github.com wrote:\n\nBeen kinda banging my head on how to create that fake group and push\nvalues to it. Will keep digging, but thanks for the hint :).\n\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69143608.\n\n\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69145133.\n. This scenario is actually related to my request to be able to retrieve only the filtered records.  We are using DC.js and thus CrossFilter to provide a dynamic reporting environment to our end users.  Once the users have filtered down their views we want to provide a CSV download to them of only the records they are looking at.\n\nIf I can get to the filtered record's only then I can extract out the record ID's, send them back to the server, and have it serve up the corresponding CSV file.\nUsing dimension.top doesn't work in this case as the filters come from different locations.  The crossfilter groupAll() method returns a proper group and the .all() method returns the correct # of records affected by all filters, but I can't find a dimension that would then return only those records.\nAnother solution would be to add an each operator to the groupAll() output group allowing iteration of affected records, thus providing a paged way of getting to each record.  This may possibly reduce the overhead, don't know.\nIf I'm wrong, please point me in the right direction :)\n. I thought the dimension only included a subset of the data associated with the root.\nUsing something similar to the follow structure:\n{\n  _id: <Identity>,\n  date: Date(),\n  state: <state text>,\n  ...\n}\nIE: If I have a dimension on \"date\" then I would only see the date column in the dimension.  So performing a top(Infinity) on that dimension wouldn't get me back the _id column as an example.\nIn the above I would have a group all to get the top.  And say I had a dimension on date and state.  Now if I filter based on a state of MO || KS and a date of > 3 days ago my all count goes down to whatever...\nSaying that my root crossfilter is called ndx, then my root ndx records value will have everything including the filtered out records.\nMy goal would be to get only the records that match the filters MO || KS > 3 days ago.  Of course I don't really know what the user has filtered to :)\n. Just tried it with our live data, and of course you are correct :).  I think it would be useful to have this documented explicitly though as I searched for an answer for quite some time before chasing this on GitHub.  Hopefully others find the thread if they run into the same problem.  Great work all over.\n. Yeah I worded that way wrong.\nWhat I am trying to do is build a simple dashboard using dc.js that shows a view of logging data.  My data isn't completely consistent as it is coming from logs.\nThe goal is to have a chart of each inbound call by duration, then another chart of all of the outbound calls by duration.\nI'm guessing that some how I need to create a group that rejects the inbounds for the outbound view and one that rejects the outbounds for the inbound view.  But I can't seem to figure out how exactly to achieve that.\n. Been kinda banging my head on how to create that fake group and push values to it.  Will keep digging, but thanks for the hint :).\n. Thanks Adam, that was exactly the pointer I needed.  Just in case someone\nelse runs into this, here is a GIST that shows how to do a basic example:\nhttps://gist.github.com/jdarling/fb701fcaead21168cb7a\nOn Thu, Jan 8, 2015 at 1:29 AM, Adam Reynolds notifications@github.com\nwrote:\n\nhttps://github.com/dc-js/dc.js/wiki/FAQ\nOn the page. Note I had to also create the top function. Creating just all\ncaused it to error.\nOn 8 Jan 2015 07:05, \"jdarling\" notifications@github.com wrote:\n\nBeen kinda banging my head on how to create that fake group and push\nvalues to it. Will keep digging, but thanks for the hint :).\n\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69143608.\n\n\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69145133.\n. \n",
    "jrideout": "dimension.top is my current workaround. Although it seems odd to grab an arbitrary dimension and call .top(Infinity) on it just to retrieve all the filtered records. The semantic link between the operation and the output feels weak, but it certainly works.\n. dimension.top is my current workaround. Although it seems odd to grab an arbitrary dimension and call .top(Infinity) on it just to retrieve all the filtered records. The semantic link between the operation and the output feels weak, but it certainly works.\n. ",
    "pedroteixeira": "Is there any way to all filtered values, but mantaining original data order?\n. Is there any way to all filtered values, but mantaining original data order?\n. ",
    "wilzbach": "Would it be possible to have all as just an alias to Infinity?\nIt is very common and just costs line.\n. Would it be possible to have all as just an alias to Infinity?\nIt is very common and just costs line.\n. ",
    "kimalbrecht": "\nIs there any way to all filtered values, but mantaining original data order?\n\nI'm also interested in that. \nWhat I'm actually looking for is a way to return the filtered data and keeping the initial index of the dataset. So instead of removing the filtered rows setting them to blank (in csv: ,,,,).\nAny help, workaround would be appreciated.\nThanks\n. So I found a solution. But I could imagine that there are much better, simple, faster ways of doing this. Any improvements are welcome.\nFirst I created an Index for the loaded data before inputting the data into crossfilter (I'm working with CSV data):\ndata.forEach(function(d,i) {\n    d.index = i;\n    d.x = +d.x;\n    d.y = +d.y;\n    .....\n  });\nNow I'm calling this function each time crossfilter is used:\n```\n  function passValues() {\nvar infos = index.top(Infinity);\n\nvar len = data.length;\n\nvar nodes = [];\n\nwhile(len--){\n\n  if(typeof infos[len] != 'undefined') {\n\n    nodes.splice(infos[len].index, 0, infos[len]);\n\n  }\n  else {\n\n    nodes.push('');\n\n  }\n}\n\nraw_data_function(nodes);\n\n} \n```\nThis creates either an empty object (if it is filtered) or puts the data in the right spot through the .splice method. \nIt works well for me (I'm dealing with 25.000 objects)  but I'm sure there are better methods. \nBest, Kim\n. > Is there any way to all filtered values, but mantaining original data order?\nI'm also interested in that. \nWhat I'm actually looking for is a way to return the filtered data and keeping the initial index of the dataset. So instead of removing the filtered rows setting them to blank (in csv: ,,,,).\nAny help, workaround would be appreciated.\nThanks\n. So I found a solution. But I could imagine that there are much better, simple, faster ways of doing this. Any improvements are welcome.\nFirst I created an Index for the loaded data before inputting the data into crossfilter (I'm working with CSV data):\ndata.forEach(function(d,i) {\n    d.index = i;\n    d.x = +d.x;\n    d.y = +d.y;\n    .....\n  });\nNow I'm calling this function each time crossfilter is used:\n```\n  function passValues() {\nvar infos = index.top(Infinity);\n\nvar len = data.length;\n\nvar nodes = [];\n\nwhile(len--){\n\n  if(typeof infos[len] != 'undefined') {\n\n    nodes.splice(infos[len].index, 0, infos[len]);\n\n  }\n  else {\n\n    nodes.push('');\n\n  }\n}\n\nraw_data_function(nodes);\n\n} \n```\nThis creates either an empty object (if it is filtered) or puts the data in the right spot through the .splice method. \nIt works well for me (I'm dealing with 25.000 objects)  but I'm sure there are better methods. \nBest, Kim\n. ",
    "robertlevy": "+1\n. +1\n. ",
    "jmarca": "On Thu, Nov 14, 2013 at 10:09:55PM -0800, Tom Carden wrote:\n\nSpeaking as a maintainer: \nI'd happily take a pull request, even a broken one, and help you try to fix it. Showing us what doesn't work can be helpful too :)\n\nOkay I'll settle on my \"best try yet\" and push it, then send a pull\nrequest.  (I tend to assume that not working right === not worth a\npull request!)\nI was trying to model my efforts at component.json for crossfilter\nlooking at what was done with d3, but that failed.  Last night I made\nsome progress with directly including it as a file in my project's\ncomponent.json, so I'll try building on that.\n\nCan you point me at a good tutorial or documentation for the component format so I can understand how it's used and if it would benefit crossfilter in addition to the existing package.json and npm packages?\n\ncomponent is documented at https://github.com/component/component\nwith the spec documented at\nhttps://github.com/component/component/wiki/Spec\nAs to the benefit, crossfilter is a great utility library that does\none thing really well, without pulling in lots of other dependencies,\netc.  This fits well with my understanding of component.js---keep\nthings modular and build only what you need.\nThe package.json is great for including via npm, but npm doesn't\nreally help with deploying to a website.  With component.js, I just\ntype component install & component build and everything I need for\nthe webpage is wrapped up in a build subdirectory (build.js and\nbuild.css).  The trick is convincing component to actually pull in\nwhat you need (using component.json, in a way that allows one to write\nvar cf = require('crossfilter') and have that work properly in the\nbrowser..\nRegards, \nJames\n\nThis message has been scanned for viruses and\ndangerous content by MailScanner, and is\nbelieved to be clean.\n. Okay, I can't do it.  I don't know enough about how/why crossfilter is set up the way it is.  \nIn the crossfilter Makefile, there is this:\n%.js:\n    @rm -f $@\n    @echo '(function(exports){' > $@\n    @echo 'crossfilter.version = \"'$(shell node -p 'require(\"./package.json\").version')'\";' >> $@\n    cat $(filter %.js,$^) >> $@\n    @echo '})(this);' >> $@\n    @chmod a-w $@\nIf I copy the resulting crossfilter.js into my project, and then hack on the first and last lines above written by the Makefile, then it works.  Instead of \n(function(exports){\nI have in my project crossfilter.js:\nvar crossfilter =  (function(exports){\nand then at the bottom the corresponding \n})(this);\nis changed to \n})(module.exports)\nThen in the code I can use crossfilter by writing var crossfilter = require('./crossfilter').crossfilter.  \nThis is almost what is in index.js, but not quite.  The problem seems to be that when index.js is evaluated in the browser, sending this appears to be the wrong thing to do.  But I don't understand why this is being done and I can't find any documentation on it, so I can't intelligently change it.  Doing what I'm doing seems really wrong.  I'd rather someone who knows what is going on take a crack at doing this, or you can close the feature request.\n. On Thu, Nov 14, 2013 at 10:09:55PM -0800, Tom Carden wrote:\n\nSpeaking as a maintainer: \nI'd happily take a pull request, even a broken one, and help you try to fix it. Showing us what doesn't work can be helpful too :)\n\nOkay I'll settle on my \"best try yet\" and push it, then send a pull\nrequest.  (I tend to assume that not working right === not worth a\npull request!)\nI was trying to model my efforts at component.json for crossfilter\nlooking at what was done with d3, but that failed.  Last night I made\nsome progress with directly including it as a file in my project's\ncomponent.json, so I'll try building on that.\n\nCan you point me at a good tutorial or documentation for the component format so I can understand how it's used and if it would benefit crossfilter in addition to the existing package.json and npm packages?\n\ncomponent is documented at https://github.com/component/component\nwith the spec documented at\nhttps://github.com/component/component/wiki/Spec\nAs to the benefit, crossfilter is a great utility library that does\none thing really well, without pulling in lots of other dependencies,\netc.  This fits well with my understanding of component.js---keep\nthings modular and build only what you need.\nThe package.json is great for including via npm, but npm doesn't\nreally help with deploying to a website.  With component.js, I just\ntype component install & component build and everything I need for\nthe webpage is wrapped up in a build subdirectory (build.js and\nbuild.css).  The trick is convincing component to actually pull in\nwhat you need (using component.json, in a way that allows one to write\nvar cf = require('crossfilter') and have that work properly in the\nbrowser..\nRegards, \nJames\n\nThis message has been scanned for viruses and\ndangerous content by MailScanner, and is\nbelieved to be clean.\n. Okay, I can't do it.  I don't know enough about how/why crossfilter is set up the way it is.  \nIn the crossfilter Makefile, there is this:\n%.js:\n    @rm -f $@\n    @echo '(function(exports){' > $@\n    @echo 'crossfilter.version = \"'$(shell node -p 'require(\"./package.json\").version')'\";' >> $@\n    cat $(filter %.js,$^) >> $@\n    @echo '})(this);' >> $@\n    @chmod a-w $@\nIf I copy the resulting crossfilter.js into my project, and then hack on the first and last lines above written by the Makefile, then it works.  Instead of \n(function(exports){\nI have in my project crossfilter.js:\nvar crossfilter =  (function(exports){\nand then at the bottom the corresponding \n})(this);\nis changed to \n})(module.exports)\nThen in the code I can use crossfilter by writing var crossfilter = require('./crossfilter').crossfilter.  \nThis is almost what is in index.js, but not quite.  The problem seems to be that when index.js is evaluated in the browser, sending this appears to be the wrong thing to do.  But I don't understand why this is being done and I can't find any documentation on it, so I can't intelligently change it.  Doing what I'm doing seems really wrong.  I'd rather someone who knows what is going on take a crack at doing this, or you can close the feature request.\n. ",
    "christopherobin": "Agreed, that would be very nice to have as a component\n. @RandomEtc Here is an updated version of the commit, the error reported by @mbostock should be gone and indeed index.js was not needed and was removed from the component.json file. I also signed the CLA as required.\n. Agreed, that would be very nice to have as a component\n. @RandomEtc Here is an updated version of the commit, the error reported by @mbostock should be gone and indeed index.js was not needed and was removed from the component.json file. I also signed the CLA as required.\n. ",
    "bjornstar": "A gentle nudge.\nWe'd really like to use crossfilter as a component.\n. Thanks guys!\n. A gentle nudge.\nWe'd really like to use crossfilter as a component.\n. Thanks guys!\n. ",
    "stevemandl": "I have written an extension of crossfilter called updatingCrossfilter that integrates with dc's chart filtering. It overrides add() and remove() in order to keep track of which records are present in the crossfilter, and implements update functionality too. As Jason suggested, I typically lift all filters before doing any of these updates, then restore all of the filters afterwards before re-rendering the dc charts. \n    My extension also has functionality for getting updates using ajax from a web service delivering time series data, and merging the new data with the old. Because of this it might be much more complicated than you need, but nonetheless I'd be happy to share the code if you are willing to take a peek.\n. Here is a demo of the updatingCrrossfilter at work. I stripped out the ajax stuff which was specific to my application. Have fun with it, I would be happy to hear comments:\nhttp://bl.ocks.org/stevemandl/02febfc129131db79adf\n. Ari-\nI updated the issue with a link to my gist. Please let me know if it is useful.\n-Steve\n\nFrom: Ari notifications@github.com\nSent: Wednesday, October 28, 2015 9:25 PM\nTo: square/crossfilter\nCc: Steve J. Mandl\nSubject: Re: [crossfilter] How to replace the data in crossfilter (#99)\nThis is an old comment, but still relevant. @stevemandlhttps://github.com/stevemandl Think you'll be able to share it?\n[https://avatars2.githubusercontent.com/u/5465626?v=3&s=400]https://github.com/stevemandl\nstevemandl (Steve Mandl)\nstevemandl has 2 repositories written in CSS, Shell, and JavaScript. Follow their code on GitHub.\nRead more...https://github.com/stevemandl\n\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/issues/99#issuecomment-152047085.\n. I have written an extension of crossfilter called updatingCrossfilter that integrates with dc's chart filtering. It overrides add() and remove() in order to keep track of which records are present in the crossfilter, and implements update functionality too. As Jason suggested, I typically lift all filters before doing any of these updates, then restore all of the filters afterwards before re-rendering the dc charts. \n    My extension also has functionality for getting updates using ajax from a web service delivering time series data, and merging the new data with the old. Because of this it might be much more complicated than you need, but nonetheless I'd be happy to share the code if you are willing to take a peek.\n. Here is a demo of the updatingCrrossfilter at work. I stripped out the ajax stuff which was specific to my application. Have fun with it, I would be happy to hear comments:\nhttp://bl.ocks.org/stevemandl/02febfc129131db79adf\n. Ari-\nI updated the issue with a link to my gist. Please let me know if it is useful.\n-Steve\n\nFrom: Ari notifications@github.com\nSent: Wednesday, October 28, 2015 9:25 PM\nTo: square/crossfilter\nCc: Steve J. Mandl\nSubject: Re: [crossfilter] How to replace the data in crossfilter (#99)\nThis is an old comment, but still relevant. @stevemandlhttps://github.com/stevemandl Think you'll be able to share it?\n[https://avatars2.githubusercontent.com/u/5465626?v=3&s=400]https://github.com/stevemandl\nstevemandl (Steve Mandl)\nstevemandl has 2 repositories written in CSS, Shell, and JavaScript. Follow their code on GitHub.\nRead more...https://github.com/stevemandl\n\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/issues/99#issuecomment-152047085.\n. ",
    "r4j4h": "@stevemandl I would love to see your code, I am exploring some avenues where I would be doing almost that exact same thing!\n. @stevemandl I would love to see your code, I am exploring some avenues where I would be doing almost that exact same thing!\n. ",
    "motin": "@stevemandl +1 your extension sounds great! Do you have any idea when it will be available? Care to share the code even though it may not be documented yet?\n. @stevemandl +1 your extension sounds great! Do you have any idea when it will be available? Care to share the code even though it may not be documented yet?\n. ",
    "auser": "This is an old comment, but still relevant. @stevemandl Think you'll be able to share it?\n. @stevemandl it does. Quite a lot of work went into that gist\n. This is an old comment, but still relevant. @stevemandl Think you'll be able to share it?\n. @stevemandl it does. Quite a lot of work went into that gist\n. ",
    "JackStouffer": "+1 It would be great if this was a start to other statistical methods as well.\n. This library looks very useful, thanks. I will comment again when I have a working example of a moving average. \n. Here is the solution with the above library. Unfortunately, it proved far too slow with a large amount of records. I guess that's the limitations of working in js\nAlso, bonus support for dc.js\n```\n//this assumes your data is in the form of\ndata = [\n{value:1000, date: Date('2015-01-01')}\n...\n]\nvar date_array = [];\nvar mapped_date_array = [];\nvar dateDim = cs_data.dimension(function(d) {return d.date;});\nvar shipped = dateDim.group().reduceSum(dc.pluck('value'));\n// get a list of all of the dates used\nvar shipments_infinity = shipments.top(Infinity);\nvar i = 0;\nfor (i=0; i < shipments_infinity.length; i++) {\n    date_array.push(shipments_infinity[i].key);\n}\ndate_array.sort(function (date1, date2) {\n    if (date1 > date2) return 1;\n    if (date1 < date2) return -1;\n    return 0;\n})\n// this is needed for indexOf, as js returns false on all object comparisons \nmapped_date_array = date_array.map(function(e) { return e.toDateString(); });\nreducer = reductio().groupAll(function(record) {\n    var idx = mapped_date_array.indexOf(record.date.toDateString());\nif (record.date < date_array[30]) {\n      return [date_array[idx]];\n} else {\n      var i = 0;\n      var return_array = [];\n     // we are finding the 30 day moving avg \n     for (i = 30; i >= 0; i--) {\n           return_array.push(date_array[idx - i]);\n     }\n\n      return return_array;\n\n}\n}).count(true).sum(function(d) { return d.value; }).avg(true);\nvar shipments_moving_avg = dateDim.groupAll();\nreducer(shipments_moving_avg);\n// dc.js requires the all() function to exist, supplement this with underscore.js\n_.extend(shipments_moving_avg, {all: function () {return this.value()} })\nsomeChart.width(1000).height(300)\n                        .dimension(dateDim)\n                        .group(shipments)\n                        .stack(shipments_moving_avg, function (d) {return d.value.avg;})\n```\n. Yeah, unfortunately my data contains 110,353 records and grows by about 50-100 every day. I simplified the data for this example, but the real data has eight columns, which brings the total size to about 16 MB. \n. I created a new issue for this discussion https://github.com/esjewett/reductio/issues/12\n. Close with no comment?\n. +1 It would be great if this was a start to other statistical methods as well.\n. This library looks very useful, thanks. I will comment again when I have a working example of a moving average. \n. Here is the solution with the above library. Unfortunately, it proved far too slow with a large amount of records. I guess that's the limitations of working in js\nAlso, bonus support for dc.js\n```\n//this assumes your data is in the form of\ndata = [\n{value:1000, date: Date('2015-01-01')}\n...\n]\nvar date_array = [];\nvar mapped_date_array = [];\nvar dateDim = cs_data.dimension(function(d) {return d.date;});\nvar shipped = dateDim.group().reduceSum(dc.pluck('value'));\n// get a list of all of the dates used\nvar shipments_infinity = shipments.top(Infinity);\nvar i = 0;\nfor (i=0; i < shipments_infinity.length; i++) {\n    date_array.push(shipments_infinity[i].key);\n}\ndate_array.sort(function (date1, date2) {\n    if (date1 > date2) return 1;\n    if (date1 < date2) return -1;\n    return 0;\n})\n// this is needed for indexOf, as js returns false on all object comparisons \nmapped_date_array = date_array.map(function(e) { return e.toDateString(); });\nreducer = reductio().groupAll(function(record) {\n    var idx = mapped_date_array.indexOf(record.date.toDateString());\nif (record.date < date_array[30]) {\n      return [date_array[idx]];\n} else {\n      var i = 0;\n      var return_array = [];\n     // we are finding the 30 day moving avg \n     for (i = 30; i >= 0; i--) {\n           return_array.push(date_array[idx - i]);\n     }\n\n      return return_array;\n\n}\n}).count(true).sum(function(d) { return d.value; }).avg(true);\nvar shipments_moving_avg = dateDim.groupAll();\nreducer(shipments_moving_avg);\n// dc.js requires the all() function to exist, supplement this with underscore.js\n_.extend(shipments_moving_avg, {all: function () {return this.value()} })\nsomeChart.width(1000).height(300)\n                        .dimension(dateDim)\n                        .group(shipments)\n                        .stack(shipments_moving_avg, function (d) {return d.value.avg;})\n```\n. Yeah, unfortunately my data contains 110,353 records and grows by about 50-100 every day. I simplified the data for this example, but the real data has eight columns, which brings the total size to about 16 MB. \n. I created a new issue for this discussion https://github.com/esjewett/reductio/issues/12\n. Close with no comment?\n. ",
    "brandones": "Why isn't statesAvgGroup overwritten by the subsequent declarations?\n. Why isn't statesAvgGroup overwritten by the subsequent declarations?\n. ",
    "monfera": "Derived calculations, such as avg here, can be moved out of the the reducers, as they use extra CPU cycles. Non-numeric aggregations may even stress the GC, worst case, yielding janky crossfiltering.\nThe final reduction can be done at the end of an interaction, i.e. after applying a filter or adding an array of new elements. The aggregate is just a tuple of count and sum. On a project we even made a shallow abstraction for the final reduction of the aggregates.\nIt conveniently makes the user responsible for handling the degenerate case of the empty set (e.g. they can check count or use isNaN). A NaN is usually preferred over a zero avg because the value 0 implies a legit average where there isn't and typical crossfiltering aggregates on the empty set don't make sense (e.g. values that characterize distributions).\nWith some aggregates, non-empty sets of reasonable values can still lead to edge cases. E.g. computing the extent where all N numbers are of the same value. The user of the values can determine what to do with the edge case, e.g. just not rendering axis ticks, or adding 1 to max and using zero, or subtracting 1 from min for rendering some ticks, whatever makes sense.\nAs a more complicated, yet still incrementally computable aggregate, consider the standard deviation or its cousin, variance. The final reduction is division and taking the square root.\nA more challenging group aggregate, surprisingly, is the calculation of the extent (or just a minimum or maximum). The difficulty is updating the aggregate with items removed. A basic option is to maintain a sorted value vector but it gets expensive.\n. Derived calculations, such as avg here, can be moved out of the the reducers, as they use extra CPU cycles. Non-numeric aggregations may even stress the GC, worst case, yielding janky crossfiltering.\nThe final reduction can be done at the end of an interaction, i.e. after applying a filter or adding an array of new elements. The aggregate is just a tuple of count and sum. On a project we even made a shallow abstraction for the final reduction of the aggregates.\nIt conveniently makes the user responsible for handling the degenerate case of the empty set (e.g. they can check count or use isNaN). A NaN is usually preferred over a zero avg because the value 0 implies a legit average where there isn't and typical crossfiltering aggregates on the empty set don't make sense (e.g. values that characterize distributions).\nWith some aggregates, non-empty sets of reasonable values can still lead to edge cases. E.g. computing the extent where all N numbers are of the same value. The user of the values can determine what to do with the edge case, e.g. just not rendering axis ticks, or adding 1 to max and using zero, or subtracting 1 from min for rendering some ticks, whatever makes sense.\nAs a more complicated, yet still incrementally computable aggregate, consider the standard deviation or its cousin, variance. The final reduction is division and taking the square root.\nA more challenging group aggregate, surprisingly, is the calculation of the extent (or just a minimum or maximum). The difficulty is updating the aggregate with items removed. A basic option is to maintain a sorted value vector but it gets expensive.\n. ",
    "protobi": "Concur that text search, like a RegEx filter, would be great.  As a newbie looking at the code from the outside, it appears that dimensions are represented as sorted arrays of column values, and filters track the min and max index of values that satisfy it.  Thus it seems range filters like dictionary order (case sensitive) with upper and lower bounds would be easy (e.g. \"Bee_\" <= x < \"Bar_\") would match.  But text match could yield arbitrary subsets which would require rethinking how filters are applied. \n. Concur that text search, like a RegEx filter, would be great.  As a newbie looking at the code from the outside, it appears that dimensions are represented as sorted arrays of column values, and filters track the min and max index of values that satisfy it.  Thus it seems range filters like dictionary order (case sensitive) with upper and lower bounds would be easy (e.g. \"Bee_\" <= x < \"Bar_\") would match.  But text match could yield arbitrary subsets which would require rethinking how filters are applied. \n. ",
    "mtraynham": "You can use dimension.filterFunction(function(d) {...}).\nSee https://github.com/square/crossfilter/wiki/API-Reference#wiki-dimension_filterFunction\nAs an example:\n```\n// Match strings of length 5 or greater that only include letters and numbers.\nvar regex = /^([a-z0-9]{5,})$/; \nvar data = [{foo: \"abc1\"}, {foo: \"abc12\"}, {foo: \"abc123\"}]\nvar index = crossfilter(data);\nvar fooAccessor = function(d) { return d.foo; };\nvar dimension = index.dimension(fooAccessor);\n// d is the dimension value;  return false for exclude\ndimension.filterFunction(function(d) {\n    return regex.test(d);\n});\n```\nBased on the above example, this matches records 2 & 3.  This allows you to filter specific records based on something other than exact match or range match.  \nAlbeit this does not take advantage of Crossfilter's bisect functionality which can binary search the sorted data (as used in range filtering or exact match).  Thus, this can be much slower for larger data sets and/or execution complexity of the filter function.\nAs @gradualstudent aluded to, if you are prefix matching, then filterRange would be the way to go.  You would create a range that encompasses all values past the letters presented by the user.  For instance, if user typed 'Bee', you would set the start of the range to the entered text.  The range end would be the entered text, plus the lowest naturally sorted unicode character.  That would allow you to encompass all values that start with 'Bee'.\n['Bee', 'Bee\\uFFFF']\nI have not tried any of this before, so correct me if I'm wrong.\n. @jefffriesen Hey Jeff, I don't know how much code support you're going to get here in terms of a way to do this without a patch... but you'll want to check the listener arrays for references to the dimension or check the length.  In the dispose function:\n// Removes this dimension and associated groups and event listeners.\n    function dispose() {\n      dimensionGroups.forEach(function(group) { group.dispose(); });\n      var i = dataListeners.indexOf(preAdd);\n      if (i >= 0) dataListeners.splice(i, 1);\n      i = dataListeners.indexOf(postAdd);\n      if (i >= 0) dataListeners.splice(i, 1);\n      i = removeDataListeners.indexOf(removeData);\n      if (i >= 0) removeDataListeners.splice(i, 1);\n      for (i = 0; i < n; ++i) filters[i] &= zero;\n      m &= zero;\n      return dimension;\n    }\nLooks like dataListeners is 2x the size of the number of dimensions and removeDataListeners is 1:1 with the dimensions.\nSo you could add a method to dimensions and groups to check all of those for indexOf, or just have a method that returns the corresponding expected length (removeDataListeners.length)\n. You can use dimension.filterFunction(function(d) {...}).\nSee https://github.com/square/crossfilter/wiki/API-Reference#wiki-dimension_filterFunction\nAs an example:\n```\n// Match strings of length 5 or greater that only include letters and numbers.\nvar regex = /^([a-z0-9]{5,})$/; \nvar data = [{foo: \"abc1\"}, {foo: \"abc12\"}, {foo: \"abc123\"}]\nvar index = crossfilter(data);\nvar fooAccessor = function(d) { return d.foo; };\nvar dimension = index.dimension(fooAccessor);\n// d is the dimension value;  return false for exclude\ndimension.filterFunction(function(d) {\n    return regex.test(d);\n});\n```\nBased on the above example, this matches records 2 & 3.  This allows you to filter specific records based on something other than exact match or range match.  \nAlbeit this does not take advantage of Crossfilter's bisect functionality which can binary search the sorted data (as used in range filtering or exact match).  Thus, this can be much slower for larger data sets and/or execution complexity of the filter function.\nAs @gradualstudent aluded to, if you are prefix matching, then filterRange would be the way to go.  You would create a range that encompasses all values past the letters presented by the user.  For instance, if user typed 'Bee', you would set the start of the range to the entered text.  The range end would be the entered text, plus the lowest naturally sorted unicode character.  That would allow you to encompass all values that start with 'Bee'.\n['Bee', 'Bee\\uFFFF']\nI have not tried any of this before, so correct me if I'm wrong.\n. @jefffriesen Hey Jeff, I don't know how much code support you're going to get here in terms of a way to do this without a patch... but you'll want to check the listener arrays for references to the dimension or check the length.  In the dispose function:\n// Removes this dimension and associated groups and event listeners.\n    function dispose() {\n      dimensionGroups.forEach(function(group) { group.dispose(); });\n      var i = dataListeners.indexOf(preAdd);\n      if (i >= 0) dataListeners.splice(i, 1);\n      i = dataListeners.indexOf(postAdd);\n      if (i >= 0) dataListeners.splice(i, 1);\n      i = removeDataListeners.indexOf(removeData);\n      if (i >= 0) removeDataListeners.splice(i, 1);\n      for (i = 0; i < n; ++i) filters[i] &= zero;\n      m &= zero;\n      return dimension;\n    }\nLooks like dataListeners is 2x the size of the number of dimensions and removeDataListeners is 1:1 with the dimensions.\nSo you could add a method to dimensions and groups to check all of those for indexOf, or just have a method that returns the corresponding expected length (removeDataListeners.length)\n. ",
    "drahmel": "Sounds good. I'll try and make the changes tomorrow. Thanks for the\nresponse!\nDan\nOn Wed, Mar 12, 2014 at 2:01 PM, Tom Carden notifications@github.comwrote:\n\nNeat! Thanks for trying this out. I think we can make it work. Do you have\ntime for a small iteration?\nOn my screen, at around 800px wide, the Crossfilter heading is under the\nTime of Day chart. Can you adjust the font size when the screen is narrow?\nIf you're editing it, can you break the lines in the HTML file so it's\neasier to review? And please use spaces not tabs (sorry!).\nIf possible, at wider screen sizes it would be nice to have some margins\non the sides so that the content can breathe a bit. Something a cross\nbetween what you have at https://square.github.io/crossfilter/ and what\nwe have today at https://square.github.io/crossfilter/ would be great -\nmy monitor is 2560px wide, and I regularly browse at ~1800px :)\nLastly, can you sign our electronic contributor agreement so I can safely\nmerge your changes without talking to a lawyer?\nhttps://spreadsheets.google.com/spreadsheet/viewform?formkey=dDViT2xzUHAwRkI3X3k5Z0lQM091OGc6MQ&ndplr=1\n\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/pull/108#issuecomment-37464463\n.\n. Sounds good. I'll try and make the changes tomorrow. Thanks for the\nresponse!\n\nDan\nOn Wed, Mar 12, 2014 at 2:01 PM, Tom Carden notifications@github.comwrote:\n\nNeat! Thanks for trying this out. I think we can make it work. Do you have\ntime for a small iteration?\nOn my screen, at around 800px wide, the Crossfilter heading is under the\nTime of Day chart. Can you adjust the font size when the screen is narrow?\nIf you're editing it, can you break the lines in the HTML file so it's\neasier to review? And please use spaces not tabs (sorry!).\nIf possible, at wider screen sizes it would be nice to have some margins\non the sides so that the content can breathe a bit. Something a cross\nbetween what you have at https://square.github.io/crossfilter/ and what\nwe have today at https://square.github.io/crossfilter/ would be great -\nmy monitor is 2560px wide, and I regularly browse at ~1800px :)\nLastly, can you sign our electronic contributor agreement so I can safely\nmerge your changes without talking to a lawyer?\nhttps://spreadsheets.google.com/spreadsheet/viewform?formkey=dDViT2xzUHAwRkI3X3k5Z0lQM091OGc6MQ&ndplr=1\n\nReply to this email directly or view it on GitHubhttps://github.com/square/crossfilter/pull/108#issuecomment-37464463\n.\n. \n",
    "amergin": "@esjewett - excellent commit! I'm trying out your fork in a dc.js / crossfilter application and haven't seen any issues with this. When can we expect similar feature to be incorporated to crossfilter.js?\n. Any news/progress on this?\n. +1\n. @esjewett - excellent commit! I'm trying out your fork in a dc.js / crossfilter application and haven't seen any issues with this. When can we expect similar feature to be incorporated to crossfilter.js?\n. Any news/progress on this?\n. +1\n. ",
    "derekperkins": "Yes, we are incredibly interested in this functionality, specifically the removeFilter as implemented by @esjewett \n. @jasondavies Any thoughts on adding this functionality or on accepting @esjewett 's PR? \n. :+1:\n. I'd love to see some more activity. There are a few PRs that have been submitted that I'm very interested in, like adding support for more dimensions #75 and one that I can't find by @esjewett that allowed you to remove rows that don't match the current filter.\n@esjewett also has https://github.com/esjewett/reductio that is a good place for a number of things that might be useful but deemed out of the purview of core crossfilter. Maybe moving crossfilter to an official organization so that there could be additional plugins brought into the official crossfilter ecosystem.\n. @jefffriesen - I feel like dc.js and other libraries are making crossfilter more accessible and hence more popular. \nThe core functionality is awesome, so there aren't major core changes that need to be implemented. Mostly just some tweaks and a few feature additions. \n. @RandomEtc Thanks for being so responsive. \nFYI, crossfilter was available as an organization name, which I just registered on a whim the other day, when @tannerlinsley and @esjewett and I were talking about some extensions we'd like to make. It's available if there is interest in moving it outside of square.\n. @RandomEtc - I don't love the idea of forking crossfilter into dc.js or into that organization. Not that dc.js isn't great, but there are still plenty of people using crossfilter outside of that context, myself included. I'd love to have @gordonwoodhull and the dc.js team heavily involved, but I think crossfilter is big enough to warrant separate maintenance.\nMy vote would be to officially transfer this repo to a crossfilter organization. If square doesn't want to do that or there are other issues preventing that, then next best would be a blessed fork to that same organization.\nWhatever happens, I think a key thing would be to change the licensing to something more open so that we don't have any other contribution issues.\n. @gordonwoodhull - Great minds think alike :)\n. My vote for new collaborators would be @esjewett, @gordonwoodhull & @tannerlinsley.\n. @jasondavies : I'm very curious to hear your opinion on the matter, since you're the authority at this point. Are you interested in continuing to be the lead maintainer of the project? Do you have plans for future crossfilter development? \nWhile we are all interested in helping crossfilter grow, I think all of us would defer to your judgment at this point. I don't believe that any of us are looking to \"pollute\" the repo with a ton of feature requests. I think the vision is more about building the ecosystem around the core:\n- https://github.com/esjewett/reductio\n- https://github.com/dc-js/dc.js\n- @tannerlinsley has a library similar to dc.js that interacts with https://github.com/nnnick/Chart.js\nIn terms of core crossfilter changes, I think there are only a few outstanding issues that we'd like to see resolved.\nAll that being said, I really believe that the best solution is to transfer the existing repo to a crossfilter organization to legitimize some of these plugins and to aid in the discoverability. This should also allow for us to continue to support existing npm and other systems pointing at the existing url.\n@RandomEtc : Is there any resistance internally to pushing the repo out to an org?\n. Thanks for the consideration and the update @RandomEtc - we really appreciate everything that you've done. I don't think that anyone has plans at the moment to do a full v2 rewrite. The updates are more related to building out the ecosystem of plugins / extensions, and leaving the core API mostly unchanged.\nI definitely understand the legal difficulties associated with actually spinning it out. We went ahead and forked into the crossfilter organization https://github.com/crossfilter/crossfilter. We will make it very clear that the original code was written at Square, but that this is not an official project supported or maintained by Square. Once we get things set up on that end, do you have any concerns \"blessing\" that fork, similar to what you did with Cube?\n. @RandomEtc - We're reporting back after a lot of work has gone into the https://github.com/crossfilter organization.\n- crossfilter: @tannerlinsley & @esjewett added support for nested arrays https://github.com/square/crossfilter/issues/5\n- reductio: @esjewett & @nordfjord added grouped aggregations\n- universe: @tannerlinsley created a mongo-like query language + automatic dimension management\n- async: @esjewett has crossfilter working in a web worker #116\n@gordonwoodhull & @r4j4h have also been very helpful along the way.\nWe're all very committed to continuing to push the crossfilter ecosystem forwards. With @gordonwoodhull & dc.js onboard, a significant portion of active users will likely be seamlessly and silently migrated, and we'd love to be able to make the transition for them and all other crossfilter users as simple as possible. Here's what I think would be the best course of action moving forwards, and I'm more than open to other suggestions.\n1. If possible, transfer this repo to the crossfilter org (lawyers permitting)\n2. If not, post a deprecation notice similar to cube and point people at crossfilter/crossfilter\n3. Redirect npm & bower to the org version of crossfilter - We guarantee BC for 1.x.\n. @RandomEtc Thanks for following up! We'll keep our ears up in case something changes on the legal front, but we definitely understand the power of inertia at a big company. :)\nOur thanks go out to you, @mbostock, @jasondavies and everyone else involved with getting crossfilter to this point! \n. Yes, we are incredibly interested in this functionality, specifically the removeFilter as implemented by @esjewett \n. @jasondavies Any thoughts on adding this functionality or on accepting @esjewett 's PR? \n. :+1:\n. I'd love to see some more activity. There are a few PRs that have been submitted that I'm very interested in, like adding support for more dimensions #75 and one that I can't find by @esjewett that allowed you to remove rows that don't match the current filter.\n@esjewett also has https://github.com/esjewett/reductio that is a good place for a number of things that might be useful but deemed out of the purview of core crossfilter. Maybe moving crossfilter to an official organization so that there could be additional plugins brought into the official crossfilter ecosystem.\n. @jefffriesen - I feel like dc.js and other libraries are making crossfilter more accessible and hence more popular. \nThe core functionality is awesome, so there aren't major core changes that need to be implemented. Mostly just some tweaks and a few feature additions. \n. @RandomEtc Thanks for being so responsive. \nFYI, crossfilter was available as an organization name, which I just registered on a whim the other day, when @tannerlinsley and @esjewett and I were talking about some extensions we'd like to make. It's available if there is interest in moving it outside of square.\n. @RandomEtc - I don't love the idea of forking crossfilter into dc.js or into that organization. Not that dc.js isn't great, but there are still plenty of people using crossfilter outside of that context, myself included. I'd love to have @gordonwoodhull and the dc.js team heavily involved, but I think crossfilter is big enough to warrant separate maintenance.\nMy vote would be to officially transfer this repo to a crossfilter organization. If square doesn't want to do that or there are other issues preventing that, then next best would be a blessed fork to that same organization.\nWhatever happens, I think a key thing would be to change the licensing to something more open so that we don't have any other contribution issues.\n. @gordonwoodhull - Great minds think alike :)\n. My vote for new collaborators would be @esjewett, @gordonwoodhull & @tannerlinsley.\n. @jasondavies : I'm very curious to hear your opinion on the matter, since you're the authority at this point. Are you interested in continuing to be the lead maintainer of the project? Do you have plans for future crossfilter development? \nWhile we are all interested in helping crossfilter grow, I think all of us would defer to your judgment at this point. I don't believe that any of us are looking to \"pollute\" the repo with a ton of feature requests. I think the vision is more about building the ecosystem around the core:\n- https://github.com/esjewett/reductio\n- https://github.com/dc-js/dc.js\n- @tannerlinsley has a library similar to dc.js that interacts with https://github.com/nnnick/Chart.js\nIn terms of core crossfilter changes, I think there are only a few outstanding issues that we'd like to see resolved.\nAll that being said, I really believe that the best solution is to transfer the existing repo to a crossfilter organization to legitimize some of these plugins and to aid in the discoverability. This should also allow for us to continue to support existing npm and other systems pointing at the existing url.\n@RandomEtc : Is there any resistance internally to pushing the repo out to an org?\n. Thanks for the consideration and the update @RandomEtc - we really appreciate everything that you've done. I don't think that anyone has plans at the moment to do a full v2 rewrite. The updates are more related to building out the ecosystem of plugins / extensions, and leaving the core API mostly unchanged.\nI definitely understand the legal difficulties associated with actually spinning it out. We went ahead and forked into the crossfilter organization https://github.com/crossfilter/crossfilter. We will make it very clear that the original code was written at Square, but that this is not an official project supported or maintained by Square. Once we get things set up on that end, do you have any concerns \"blessing\" that fork, similar to what you did with Cube?\n. @RandomEtc - We're reporting back after a lot of work has gone into the https://github.com/crossfilter organization.\n- crossfilter: @tannerlinsley & @esjewett added support for nested arrays https://github.com/square/crossfilter/issues/5\n- reductio: @esjewett & @nordfjord added grouped aggregations\n- universe: @tannerlinsley created a mongo-like query language + automatic dimension management\n- async: @esjewett has crossfilter working in a web worker #116\n@gordonwoodhull & @r4j4h have also been very helpful along the way.\nWe're all very committed to continuing to push the crossfilter ecosystem forwards. With @gordonwoodhull & dc.js onboard, a significant portion of active users will likely be seamlessly and silently migrated, and we'd love to be able to make the transition for them and all other crossfilter users as simple as possible. Here's what I think would be the best course of action moving forwards, and I'm more than open to other suggestions.\n1. If possible, transfer this repo to the crossfilter org (lawyers permitting)\n2. If not, post a deprecation notice similar to cube and point people at crossfilter/crossfilter\n3. Redirect npm & bower to the org version of crossfilter - We guarantee BC for 1.x.\n. @RandomEtc Thanks for following up! We'll keep our ears up in case something changes on the legal front, but we definitely understand the power of inertia at a big company. :)\nOur thanks go out to you, @mbostock, @jasondavies and everyone else involved with getting crossfilter to this point! \n. ",
    "tehsenaus": "+1\nI need this to support the simple case of updating the last tick in a time series. Right now I have to recreate the whole crossfilter just to update a single value.\n. +1\nI need this to support the simple case of updating the last tick in a time series. Right now I have to recreate the whole crossfilter just to update a single value.\n. ",
    "pronix": "array in js is naturally-orderable\n. ok.thanks.\n. super. your advise save a lot time.\nstring as key faster that array.\nand parse this string to array realy faster then use array.\n. array in js is naturally-orderable\n. ok.thanks.\n. super. your advise save a lot time.\nstring as key faster that array.\nand parse this string to array realy faster then use array.\n. ",
    "RandomInsano": "Thanks for the help guys. I like the solution @RandomEtc.\nI should avoid asking for help at 3:00am. Always dangerous. I'll look for a mailing list next time. \n. Thanks for the help guys. I like the solution @RandomEtc.\nI should avoid asking for help at 3:00am. Always dangerous. I'll look for a mailing list next time. \n. ",
    "paulboone": "+1. I'm trying to get this working myself on a CrossFilter / DC / D3 stack using Twitter Flight and RequireJS. I don't know enough yet about AMD or I'd attempt to submit a patch myself.\n. +1. I'm trying to get this working myself on a CrossFilter / DC / D3 stack using Twitter Flight and RequireJS. I don't know enough yet about AMD or I'd attempt to submit a patch myself.\n. ",
    "reedspool": "I successfully used RequireJS's shim config:\nrequire.config({\n  paths: {\n    \"crossfilter\": \"/bower_components/crossfilter/crossfilter\"\n  },\n  shim: {\n    'crossfilter': {\n      deps: [],\n      exports: 'crossfilter'\n    }\n  }\n});\nHope this helps while we wait for this!\n. @lord-xeon I'm sorry that's happening. I am not familiar with dojo, but perhaps their version of require.js is older than the shim? I don't know what version shims came around, but I am sure they were not always part of the spec.\nAre you able to use other, sure-fire shims? Underscore.js is commonly shim'd like this, for example.\n. I successfully used RequireJS's shim config:\nrequire.config({\n  paths: {\n    \"crossfilter\": \"/bower_components/crossfilter/crossfilter\"\n  },\n  shim: {\n    'crossfilter': {\n      deps: [],\n      exports: 'crossfilter'\n    }\n  }\n});\nHope this helps while we wait for this!\n. @lord-xeon I'm sorry that's happening. I am not familiar with dojo, but perhaps their version of require.js is older than the shim? I don't know what version shims came around, but I am sure they were not always part of the spec.\nAre you able to use other, sure-fire shims? Underscore.js is commonly shim'd like this, for example.\n. ",
    "infacq": "+1\n. +1\n. ",
    "lord-xeon": "@reedspool \nI tried the shim config, and I keep getting \"not-a-module\" using the hacked together dojo version of require.js\n. Yes, other shims work, such as d3.\ndojo uses their own custom version of require.js which makes it just about impossible to use any \"AMD ready\" plugin I would like (moment.js, Pnotify, etc.)\n. @reedspool \nI tried the shim config, and I keep getting \"not-a-module\" using the hacked together dojo version of require.js\n. Yes, other shims work, such as d3.\ndojo uses their own custom version of require.js which makes it just about impossible to use any \"AMD ready\" plugin I would like (moment.js, Pnotify, etc.)\n. ",
    "rathko": "@reedspool Thanks very much, your solution works for me.\n. @reedspool Thanks very much, your solution works for me.\n. ",
    "dottedmag": "The whole idea was to simplify var rs = reducer(...); group.reduce(rs.add, rs.remove, rs.init) to group.reduce(reducer(...)), which is not easy outside of crossfilter itself, but oh well.\n. The whole idea was to simplify var rs = reducer(...); group.reduce(rs.add, rs.remove, rs.init) to group.reduce(reducer(...)), which is not easy outside of crossfilter itself, but oh well.\n. ",
    "gazal-k": "+1\n. +1\n. ",
    "Rodeoclash": "I don't have a requirement for this anymore so perhaps it was an anti-pattern in my implementation of Crossfilter.\nShould I vote a -1? ;)\n. I don't have a requirement for this anymore so perhaps it was an anti-pattern in my implementation of Crossfilter.\nShould I vote a -1? ;)\n. ",
    "Mr0grog": "I realize this is a pretty old issue, but I'd definitely love to have this ability. I'm working on a UI that has a separate filter control and list display for the same dimension of data, which means I have to manually keep track of the applied filters in order to manage the list display (otherwise users get a bit confused when the list shows counts for things they've filtered out).\n. I realize this is a pretty old issue, but I'd definitely love to have this ability. I'm working on a UI that has a separate filter control and list display for the same dimension of data, which means I have to manually keep track of the applied filters in order to manage the list display (otherwise users get a bit confused when the list shows counts for things they've filtered out).\n. ",
    "mlenda": "Actually, I take this one back. I was unable to reproduce with the flight times example, and after digging into tutorials figured out I was not accessing the filtered data set correctly. crossfilter is returning all the data properly for applied filters; it's the rendering component that is broken. Time to head over to the dc.js forums... and blame Nick!\nThanks for the quick response.\n. Actually, I take this one back. I was unable to reproduce with the flight times example, and after digging into tutorials figured out I was not accessing the filtered data set correctly. crossfilter is returning all the data properly for applied filters; it's the rendering component that is broken. Time to head over to the dc.js forums... and blame Nick!\nThanks for the quick response.\n. ",
    "wssbck": "OK, thanks for the tips, at first I will just focus on implementing as many reduction functions as possible.\n. @gsklee @esjewett I would like to expand on this point. The issue is present when a dimension contains values of different types, not only when nulls are returned from the dimension's accessor. However, not always. In the above example:\n1. Change null to 1. The result is the same.\n2. Change it to '1' - all dimension values are strings and reduction values are correct.\n3. Change all values to nulls - surprisingly, there is now a group with null key, correctly reduced to 6.\nI could not trace the cause in the code, hopefully I will be able to report more later.\n. @esjewett explains it all. I would still argue null should have a special place in Crossfilter but this is a subject for another issue I guess.\n. @esjewett Yes, it is easy to get lost in how JS handles implicit type conversion and extraordinary values and types :-) I will try to find time to open a pull request or at least an issue discussing the treatment of null, specifically, as it is a very useful construct.\n. I have spent a bit of time looking into how to deal with the issue. Solving it on the Crossfilter level would be too intrusive as core sorting functions of the library would have to be modified.\nAt the same time it would be great to have null recognized as a special, separate value. Null is neither 0 nor an empty string. While 0 or empty string are completely legitimate data values that can come from measurements, null is useful for designating entries which are problematic for some reason. For example, the data may be incomplete or impossible to obtain.\nAggregation functions can be made null-aware, skipping (or processing differently) rows containing nulls. The only thing we need is a correct accessor function for a given dimension:\n``` javascript\nvar data = [\n    {score: 100, name: 'A'},\n    {score: 200, name: 'B'},\n    {score: 110, name: 'A'},\n    {score: 43,  name: null},\n    {score: 100, name: 'B'},\n    {score: 100, name: 'A'}\n];\nvar all = crossfilter(data).dimension(\n    function(v){\n        var ret = v.name === null ? 'null' : v.name;\n        return ret;\n    }\n).group().all();\nconsole.log(all);\n```\nThe result:\njavascript\n[ { key: 'A', value: 3 },\n  { key: 'B', value: 2 },\n  { key: '__null__', value: 2 } ]\nWhat is nice about this approach is that aggregation functions are still going to have the whole original data row passed as parameters, so they can react to nulls the way we want.\nFor dimensions with numerical values we could use Infinity or -Inifity to keep the values returned in the accessor well behaving when it comes to > and <:\njavascript\n    function(v){\n        var ret = v.name === null ? Infinity : v.name;\n        return ret;\n    }\nOf course, this approach does not deal with every possible \"dirty\" value in JS but we should not throw low quality data at Crossfilter. Turning all questionable entries into nulls and then dealing with them on the accessor/reduction level is IMHO a good step in the process.\n. @RandomEtc Out of curiosity - can you share some details as to why you moved dashboard aggregations to the backend? The added interactivity of frontend calculations was not worth it after all?\n. OK, thanks for the tips, at first I will just focus on implementing as many reduction functions as possible.\n. @gsklee @esjewett I would like to expand on this point. The issue is present when a dimension contains values of different types, not only when nulls are returned from the dimension's accessor. However, not always. In the above example:\n1. Change null to 1. The result is the same.\n2. Change it to '1' - all dimension values are strings and reduction values are correct.\n3. Change all values to nulls - surprisingly, there is now a group with null key, correctly reduced to 6.\nI could not trace the cause in the code, hopefully I will be able to report more later.\n. @esjewett explains it all. I would still argue null should have a special place in Crossfilter but this is a subject for another issue I guess.\n. @esjewett Yes, it is easy to get lost in how JS handles implicit type conversion and extraordinary values and types :-) I will try to find time to open a pull request or at least an issue discussing the treatment of null, specifically, as it is a very useful construct.\n. I have spent a bit of time looking into how to deal with the issue. Solving it on the Crossfilter level would be too intrusive as core sorting functions of the library would have to be modified.\nAt the same time it would be great to have null recognized as a special, separate value. Null is neither 0 nor an empty string. While 0 or empty string are completely legitimate data values that can come from measurements, null is useful for designating entries which are problematic for some reason. For example, the data may be incomplete or impossible to obtain.\nAggregation functions can be made null-aware, skipping (or processing differently) rows containing nulls. The only thing we need is a correct accessor function for a given dimension:\n``` javascript\nvar data = [\n    {score: 100, name: 'A'},\n    {score: 200, name: 'B'},\n    {score: 110, name: 'A'},\n    {score: 43,  name: null},\n    {score: 100, name: 'B'},\n    {score: 100, name: 'A'}\n];\nvar all = crossfilter(data).dimension(\n    function(v){\n        var ret = v.name === null ? 'null' : v.name;\n        return ret;\n    }\n).group().all();\nconsole.log(all);\n```\nThe result:\njavascript\n[ { key: 'A', value: 3 },\n  { key: 'B', value: 2 },\n  { key: '__null__', value: 2 } ]\nWhat is nice about this approach is that aggregation functions are still going to have the whole original data row passed as parameters, so they can react to nulls the way we want.\nFor dimensions with numerical values we could use Infinity or -Inifity to keep the values returned in the accessor well behaving when it comes to > and <:\njavascript\n    function(v){\n        var ret = v.name === null ? Infinity : v.name;\n        return ret;\n    }\nOf course, this approach does not deal with every possible \"dirty\" value in JS but we should not throw low quality data at Crossfilter. Turning all questionable entries into nulls and then dealing with them on the accessor/reduction level is IMHO a good step in the process.\n. @RandomEtc Out of curiosity - can you share some details as to why you moved dashboard aggregations to the backend? The added interactivity of frontend calculations was not worth it after all?\n. ",
    "mehdi-cit": "Thanks Jason!\nI think I get it now, you can have an OR between values of a dimension but the query operator between dimensions themselves is implicitly an AND.\nIndeed, there's no point in building on top of crossfilter as of yet.\nCheers~\n. Thanks Jason!\nI think I get it now, you can have an OR between values of a dimension but the query operator between dimensions themselves is implicitly an AND.\nIndeed, there's no point in building on top of crossfilter as of yet.\nCheers~\n. ",
    "sAlexander": "Hey Jason, I signed it yesterday.\n. Hey Jason, I signed it yesterday.\n. ",
    "javiercejudo": "143 fixes this in a more general way\n. #143 fixes this in a more general way\n. #143 fixes this in a more general way\n. #143 fixes this in a more general way\n. ",
    "justinwp": "You need to clear your filter after remove(). It is still active.\n. You need to clear your filter after remove(). It is still active.\n. ",
    "madebydna": "Oh, ok. I added foo.filter(null) after the remove and now everything works as expected. Sorry!\n. Oh, ok. I added foo.filter(null) after the remove and now everything works as expected. Sorry!\n. ",
    "unwiredbrain": "I'm not sure whether this is strictly Crossfilter-related, but you can get away with it with a couple of higher-order functions:\n``` js\nvar data = [\n  ['ABC', 'ABCD', 'ABCDEF', 'abcd', 'a', 'Abcdef', 'Abcderfg', 'A', 'ABC'],\n  ['ABCD', 'ABC', 'ABCDEF', 'abc', 'AB', 'Abcdef', 'abcd', 'ABC', 'ABC'],\n  ['Abcderfg', 'ABC', 'ABCDEFGH', 'abc', 'A', 'ABCDEF', 'abcd', 'AB', 'ABC'],\n  [],\n  [''],\n  ['', 'A'],\n  ['AA', ''],\n  ['ABC', 'AB'],\n  ['ABCDE', '', 'ABCD']\n];\nvar max = data.map(function (record) {\n  return record.reduce(function (previous, current) {\n    return Math.max(previous, current.length);\n  }, 0);\n});\nconsole.log(max); // Outputs [8, 6, 8, 0, 0, 1, 2, 3, 5]\n```\nBeware that this approach is not 100% foolproof as by \"just\" looking at the length property you may get unexpected results.\n. Oh, okay, I think I see what you mean: you're scanning \"vertically\" rather than \"horizontally,\" right?\nAnd you're assuming that all the rows in such a rectangular matrix have the exact same number of columns, correct?\nGotta say that I'm not fluent with Crossfilter so I'm not sure if I can be of any help.\nI would call .dimension() on each column you want to inspect\n``` js\nvar column0 = data.dimension(function (d) {\n  return d[0];\n});\nvar column1 = data.dimension(function (d) {\n  return d[1];\n});\n```\nthen apply some reduce function on each of them.\n. I'm not sure whether this is strictly Crossfilter-related, but you can get away with it with a couple of higher-order functions:\n``` js\nvar data = [\n  ['ABC', 'ABCD', 'ABCDEF', 'abcd', 'a', 'Abcdef', 'Abcderfg', 'A', 'ABC'],\n  ['ABCD', 'ABC', 'ABCDEF', 'abc', 'AB', 'Abcdef', 'abcd', 'ABC', 'ABC'],\n  ['Abcderfg', 'ABC', 'ABCDEFGH', 'abc', 'A', 'ABCDEF', 'abcd', 'AB', 'ABC'],\n  [],\n  [''],\n  ['', 'A'],\n  ['AA', ''],\n  ['ABC', 'AB'],\n  ['ABCDE', '', 'ABCD']\n];\nvar max = data.map(function (record) {\n  return record.reduce(function (previous, current) {\n    return Math.max(previous, current.length);\n  }, 0);\n});\nconsole.log(max); // Outputs [8, 6, 8, 0, 0, 1, 2, 3, 5]\n```\nBeware that this approach is not 100% foolproof as by \"just\" looking at the length property you may get unexpected results.\n. Oh, okay, I think I see what you mean: you're scanning \"vertically\" rather than \"horizontally,\" right?\nAnd you're assuming that all the rows in such a rectangular matrix have the exact same number of columns, correct?\nGotta say that I'm not fluent with Crossfilter so I'm not sure if I can be of any help.\nI would call .dimension() on each column you want to inspect\n``` js\nvar column0 = data.dimension(function (d) {\n  return d[0];\n});\nvar column1 = data.dimension(function (d) {\n  return d[1];\n});\n```\nthen apply some reduce function on each of them.\n. ",
    "puppeteer701": "Yes but the list is really huge, and I thought you could do this with this library more efficient, or am I mistaken?\nAnd this is actually not what I wanted. Max represents the length of the word in the columns. \n```\n  var data = [\n    [\"1111\", \"44\"],\n    [\"222\", \"55555\"  ],\n    [\"33\", \"666\"  ],\n    ...\n ];\n\"1111\".length > \"222\".length > \"33\".length,\n\"55555\".length > \"666\".length > \"44\".length\n var max -> [4,5];\n```\n. THX, will give it a try.\n. Yes but the list is really huge, and I thought you could do this with this library more efficient, or am I mistaken?\nAnd this is actually not what I wanted. Max represents the length of the word in the columns. \n```\n  var data = [\n    [\"1111\", \"44\"],\n    [\"222\", \"55555\"  ],\n    [\"33\", \"666\"  ],\n    ...\n ];\n\"1111\".length > \"222\".length > \"33\".length,\n\"55555\".length > \"666\".length > \"44\".length\n var max -> [4,5];\n```\n. THX, will give it a try.\n. ",
    "awjreynolds": "My gut feel is that this is more of a stackoverflow question and feels more like a statement than a question. Crossfilter gives you good map/reduce functionality within javascript. However it has limitations ( suggest working with less than 300k data points). Yes it does lend itself to D3 and one library built on top of it (dc.js) specifically brings crossfrilter and d3 together in a very very good way. \n. You're dimensions create selections. So those 3 match both filters you\ncreated on each dimension. The result is the cross section of each dimension\nOn 7 Jan 2015 23:46, \"jdarling\" notifications@github.com wrote:\n\nTrying to use crossfilter where we need to filter data to create different\nviews of the same data set. As a simple example if I try and get a\ndimension that represents data with durations and data with a direction of\ninbound it doesn't work. Instead what I get is the same records in both\ndimensions:\nExample source:\nvar ndx = new crossfilter([\n      {\n        duration: 1,\n        direction: 'inbound'\n      },\n      {\n        duration: 1,\n        direction: 'outbound'\n      },\n      {\n        foo: 'bar'\n      },\n      {\n        duration: 2,\n        direction: 'inbound'\n      },\n      {\n        duration: 3,\n        direction: 'inbound'\n      },\n    ]);\nvar durationFilter = ndx.dimension(function(d){\n  return !!d.duration;\n}).filter(true);\nvar inboundFilter = ndx.dimension(function(d){\n  return d.direction === 'inbound';\n}).filter(true);\nconsole.log('all', ndx.size());\nconsole.log('duration', durationFilter.top(Infinity).length);\nconsole.log('inbound', inboundFilter.top(Infinity).length);\nExpected output:\nall: 5\nduration: 4\ninbound: 3\nActual output:\nall: 5\nduration: 3\ninbound: 3\nWhat am I doing wrong?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140.\n. Create a fake group that only pushes values you want into it. Use this in\nthe chart.\n\nNot near my code so can't give you an example.\nOn 8 Jan 2015 00:34, \"jdarling\" notifications@github.com wrote:\n\nYeah I worded that way wrong.\nWhat I am trying to do is build a simple dashboard using dc.js that shows\na view of logging data. My data isn't completely consistent as it is coming\nfrom logs.\nThe goal is to have a chart of each inbound call by duration, then another\nchart of all of the outbound calls by duration.\nI'm guessing that some how I need to create a group that rejects the\ninbounds for the outbound view and one that rejects the outbounds for the\ninbound view. But I can't seem to figure out how exactly to achieve that.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69118134.\n. https://github.com/dc-js/dc.js/wiki/FAQ\n\nOn the page. Note I had to also create the top function. Creating just all\ncaused it to error.\nOn 8 Jan 2015 07:05, \"jdarling\" notifications@github.com wrote:\n\nBeen kinda banging my head on how to create that fake group and push\nvalues to it. Will keep digging, but thanks for the hint :).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69143608.\n. My gut feel is that this is more of a stackoverflow question and feels more like a statement than a question. Crossfilter gives you good map/reduce functionality within javascript. However it has limitations ( suggest working with less than 300k data points). Yes it does lend itself to D3 and one library built on top of it (dc.js) specifically brings crossfrilter and d3 together in a very very good way. \n. You're dimensions create selections. So those 3 match both filters you\ncreated on each dimension. The result is the cross section of each dimension\nOn 7 Jan 2015 23:46, \"jdarling\" notifications@github.com wrote:\nTrying to use crossfilter where we need to filter data to create different\nviews of the same data set. As a simple example if I try and get a\ndimension that represents data with durations and data with a direction of\ninbound it doesn't work. Instead what I get is the same records in both\ndimensions:\nExample source:\nvar ndx = new crossfilter([\n      {\n        duration: 1,\n        direction: 'inbound'\n      },\n      {\n        duration: 1,\n        direction: 'outbound'\n      },\n      {\n        foo: 'bar'\n      },\n      {\n        duration: 2,\n        direction: 'inbound'\n      },\n      {\n        duration: 3,\n        direction: 'inbound'\n      },\n    ]);\nvar durationFilter = ndx.dimension(function(d){\n  return !!d.duration;\n}).filter(true);\nvar inboundFilter = ndx.dimension(function(d){\n  return d.direction === 'inbound';\n}).filter(true);\nconsole.log('all', ndx.size());\nconsole.log('duration', durationFilter.top(Infinity).length);\nconsole.log('inbound', inboundFilter.top(Infinity).length);\nExpected output:\nall: 5\nduration: 4\ninbound: 3\nActual output:\nall: 5\nduration: 3\ninbound: 3\nWhat am I doing wrong?\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140.\n. Create a fake group that only pushes values you want into it. Use this in\nthe chart.\n\nNot near my code so can't give you an example.\nOn 8 Jan 2015 00:34, \"jdarling\" notifications@github.com wrote:\n\nYeah I worded that way wrong.\nWhat I am trying to do is build a simple dashboard using dc.js that shows\na view of logging data. My data isn't completely consistent as it is coming\nfrom logs.\nThe goal is to have a chart of each inbound call by duration, then another\nchart of all of the outbound calls by duration.\nI'm guessing that some how I need to create a group that rejects the\ninbounds for the outbound view and one that rejects the outbounds for the\ninbound view. But I can't seem to figure out how exactly to achieve that.\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69118134.\n. https://github.com/dc-js/dc.js/wiki/FAQ\n\nOn the page. Note I had to also create the top function. Creating just all\ncaused it to error.\nOn 8 Jan 2015 07:05, \"jdarling\" notifications@github.com wrote:\n\nBeen kinda banging my head on how to create that fake group and push\nvalues to it. Will keep digging, but thanks for the hint :).\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/square/crossfilter/issues/140#issuecomment-69143608.\n. \n",
    "markehost": "+1\n. +1\n. ",
    "drarmstr": "I've noticed that as well with some Crossfilter functions in Chrome on Windows.  Browsers are always a moving target but it's a good question.\n. I've noticed that as well with some Crossfilter functions in Chrome on Windows.  Browsers are always a moving target but it's a good question.\n. ",
    "averas": "I have a use case where I need to create a new crossfilter now and then. I have also noticed that even when adding a quite small dataset (~2000 elements) a fair amount of CPU/time is spent on quicksort/add (it takes 1-2 seconds to add 2000 elements). Is this an overhead one should expect or is it related to the non V8-optimisations as described above? Once the data is there performance is good.\n. I have a use case where I need to create a new crossfilter now and then. I have also noticed that even when adding a quite small dataset (~2000 elements) a fair amount of CPU/time is spent on quicksort/add (it takes 1-2 seconds to add 2000 elements). Is this an overhead one should expect or is it related to the non V8-optimisations as described above? Once the data is there performance is good.\n. ",
    "ziyadsaeed": "Crossfilter needs a good tutorial. An Api reference isn't for beginners.\n. Crossfilter needs a good tutorial. An Api reference isn't for beginners.\n. ",
    "curran": "Are there any plans to merge this? I would also like to use crossfilter as an AMD module. Thank you.\n. Are there any plans to merge this? I would also like to use crossfilter as an AMD module. Thank you.\n. ",
    "micahstubbs": "+1 for this\n. +1 for this\n. ",
    "agrass": "@jdarling , check this #138.  I created a method \"pivotReduceCount(['key1' 'key2'])\" in this fork: https://github.com/agrass/crossfilter.  The method consist in the same reduceCount but with a hash to check if the object was already reduced. \nFor example: \ndata.id = data.dimension(function(d) { return d.duration; });\nvar group = data.id.group();\nvar test = group.pivotReduceCount([\"duration\"]).all();\n. Yes, I'm working on that. I already pushed a pivotReduce(keys, add, remove, init) method. It's not 100% tested yet, but this week I'm going to push that methods more officially.\n. I added the method pivotReduce, and in the description an example of output compared with a normal reduceCount\n. The example is in the first comment. The method you show me it's very similar, but with this one you can select the keys that make the object uniq.  In some cases I needed to use two or more keys.\n.  Yes, it looks that concatenating the keys with the exception accessor you get the same value of pivotReduceCount (I didn't knew the existence of your method when I created it). The other method, pivotReduce(keys, add, init, remove) is the same but you can use a custom method that 'll be call only if the keys you selected were not already reduced.  My bad, the example is in the first comment of the pull request. \n. @jdarling , check this #138.  I created a method \"pivotReduceCount(['key1' 'key2'])\" in this fork: https://github.com/agrass/crossfilter.  The method consist in the same reduceCount but with a hash to check if the object was already reduced. \nFor example: \ndata.id = data.dimension(function(d) { return d.duration; });\nvar group = data.id.group();\nvar test = group.pivotReduceCount([\"duration\"]).all();\n. Yes, I'm working on that. I already pushed a pivotReduce(keys, add, remove, init) method. It's not 100% tested yet, but this week I'm going to push that methods more officially.\n. I added the method pivotReduce, and in the description an example of output compared with a normal reduceCount\n. The example is in the first comment. The method you show me it's very similar, but with this one you can select the keys that make the object uniq.  In some cases I needed to use two or more keys.\n.  Yes, it looks that concatenating the keys with the exception accessor you get the same value of pivotReduceCount (I didn't knew the existence of your method when I created it). The other method, pivotReduce(keys, add, init, remove) is the same but you can use a custom method that 'll be call only if the keys you selected were not already reduced.  My bad, the example is in the first comment of the pull request. \n. ",
    "b-long": "@jasondavies I feel this ticket should probably be closed, since @agrass solved @jdarling 's problem.\n. @jasondavies I feel this ticket should probably be closed, since @agrass solved @jdarling 's problem.\n. ",
    "sdnetwork": "really good, do you think it is possbile to have pivotReduceSum or pivotReduce with custom function for the reduce ?\n. really good, do you think it is possbile to have pivotReduceSum or pivotReduce with custom function for the reduce ?\n. ",
    "attenzione": "nevermind, i searched for bower.json, but component.json is here\n. nevermind, i searched for bower.json, but component.json is here\n. ",
    "abuscom-leonhard": "Yes thats my expectation. In my real world example I calculate the sum of sales by country and I want to include only a certain sales representative. I try to exclude all groupings that do not match the filter. Can I do this?\n. Yes thats my expectation. In my real world example I calculate the sum of sales by country and I want to include only a certain sales representative. I try to exclude all groupings that do not match the filter. Can I do this?\n. ",
    "ANteiKA": "Thanks ! \nI had understood it was a feature, but was wondering how to modify this behavior. According forums posts, I think I am not the only one looking for a solution where the associated dimension of the filtered group should be also updated. May be a dimension.reset flag or function could be useful ?\nYour workaround works perfectly also, and it saved my day ! Many thanks.\nThe working solution can be seen here : http://jsfiddle.net/ewm76uru/30/\nIf it may helps.\n. Thanks ! \nI had understood it was a feature, but was wondering how to modify this behavior. According forums posts, I think I am not the only one looking for a solution where the associated dimension of the filtered group should be also updated. May be a dimension.reset flag or function could be useful ?\nYour workaround works perfectly also, and it saved my day ! Many thanks.\nThe working solution can be seen here : http://jsfiddle.net/ewm76uru/30/\nIf it may helps.\n. ",
    "simon-stealthbits": "oops - sorry - wrong tab - meant to log this aginst dc.js\n. oops - sorry - wrong tab - meant to log this aginst dc.js\n. ",
    "mortonfox": "Someone else already opened the same PR.\n. Someone else already opened the same PR.\n. ",
    "vmantese": "Here is the solution I used. Works like a charm.\n```\n//Prefilter\nfunction preFilter(dim,okey,oval){\n            return{\n\n                top:function(x1){\n                    var a1 = dim.top(x1).filter(function(v){\n                        return v[okey] === oval;\n                    });\n                    return a1;\n                },\n                filter:function(x2){\n                    dim.filter(x2);\n                },\n                filterAll:function(){\n                    dim.filterAll();\n                },\n                filterExact:function(x4){\n                    dim.filterExact(x4);\n                },\n                filterFunction:function(x5){\n                    dim.filterFunction(x5);\n                },\n                filterRange:function(x6){\n                    dim.filterRange(x6);\n                },\n                bottom:function(x7){\n                    dim.bottom(x7);\n                },\n                dispose:function(){\n                    dim.dispose();\n                },\n                group:function(x9){\n                    dim.group(x9);\n                },\n                groupAll:function(x10){\n                    dim.groupAll(x10);\n                },\n                remove:function(){\n                    dim.remove();\n                }\n            };\n        }\n\n```\nHope this helps someone.\n. Here is the solution I used. Works like a charm.\n```\n//Prefilter\nfunction preFilter(dim,okey,oval){\n            return{\n\n                top:function(x1){\n                    var a1 = dim.top(x1).filter(function(v){\n                        return v[okey] === oval;\n                    });\n                    return a1;\n                },\n                filter:function(x2){\n                    dim.filter(x2);\n                },\n                filterAll:function(){\n                    dim.filterAll();\n                },\n                filterExact:function(x4){\n                    dim.filterExact(x4);\n                },\n                filterFunction:function(x5){\n                    dim.filterFunction(x5);\n                },\n                filterRange:function(x6){\n                    dim.filterRange(x6);\n                },\n                bottom:function(x7){\n                    dim.bottom(x7);\n                },\n                dispose:function(){\n                    dim.dispose();\n                },\n                group:function(x9){\n                    dim.group(x9);\n                },\n                groupAll:function(x10){\n                    dim.groupAll(x10);\n                },\n                remove:function(){\n                    dim.remove();\n                }\n            };\n        }\n\n```\nHope this helps someone.\n. ",
    "sylvinus": "I'm just a user at this point, but very glad to see this happening!\n. I'm just a user at this point, but very glad to see this happening!\n. ",
    "dderiso": "@esjewett @RandomEtc Thanks for all the hard work! Is it correct to summarize this as Crossfilter's home for active community development is now: https://github.com/crossfilter/crossfilter ? If so, it might be good to put a note on the readme of this repo so devs know where to submit pull requests. Thanks again for everything, love this library.\n. @esjewett @RandomEtc Thanks for all the hard work! Is it correct to summarize this as Crossfilter's home for active community development is now: https://github.com/crossfilter/crossfilter ? If so, it might be good to put a note on the readme of this repo so devs know where to submit pull requests. Thanks again for everything, love this library.\n. ",
    "kathalye": "Sorry for late response. Thank you for your reply. I will use group.all instead of top.\n. Sorry for late response. Thank you for your reply. I will use group.all instead of top.\n. ",
    "ronakrrb": "Actually, the project i am working on is very data heavy. So, we are trying to reduce as many iterations as possible. With the .map() approach comes additional iteration. \nAlso, the number of aggregation function may be sometimes just 1 and sometimes more than one. Hence, we will have to add a check whether the value attribute is a primitive value or an object. To avoid such processing, how can we modify the API to return single level object instead of nested?\n. Interesting. I will probably have to check if i can modify the internals as this is gonna be a dynamic feature to the user whether to specify 1 or multiple aggregations. Thanks\n. Actually, the project i am working on is very data heavy. So, we are trying to reduce as many iterations as possible. With the .map() approach comes additional iteration. \nAlso, the number of aggregation function may be sometimes just 1 and sometimes more than one. Hence, we will have to add a check whether the value attribute is a primitive value or an object. To avoid such processing, how can we modify the API to return single level object instead of nested?\n. Interesting. I will probably have to check if i can modify the internals as this is gonna be a dynamic feature to the user whether to specify 1 or multiple aggregations. Thanks\n. ",
    "elmart": "\nSeems to work fine for me\n\nMmm, strange. It definitely doesn't for me.\n\nPersonally I think it would be simpler to use firstGrouping.top(Infinity) and regroup small groups into \"(other)\" yourself.\n\nI considered that, but this is part of a generic widget which depict groups generated by the passed grouping function. I wouldn't like to special-case that for my particular case.\n\nperhaps you should post a reproducible example somewhere? \n\nI'll try to post something executable, but I need some time to do it.\nIn the meantime, I have another question. From group() function doc:\nThe groupValue function is optional; if not specified, it defaults to the identity \nfunction. Like the value function, groupValue must return a naturally-ordered\nvalue; furthermore, this order must be consistent with the dimension's value function!\nI suspect my problem could be related with that last requirement (consistency between groupValue function and dimension value function). Could you expand on what would that mean?\nI'm interpreting it as \na <= b --> g(a) <= g(b), where a = v(recordA) and b = v(recordB)\nwhere v is dimension value function and g is group value function.\nThat doesn't hold in my case, precisely because of group \"(other)\". Is that really needed? Why?\nThanks.\n. Ok. I ended up doing as you adviced (making second grouping out of crossfilter). \nThanks. \n. > Seems to work fine for me\nMmm, strange. It definitely doesn't for me.\n\nPersonally I think it would be simpler to use firstGrouping.top(Infinity) and regroup small groups into \"(other)\" yourself.\n\nI considered that, but this is part of a generic widget which depict groups generated by the passed grouping function. I wouldn't like to special-case that for my particular case.\n\nperhaps you should post a reproducible example somewhere? \n\nI'll try to post something executable, but I need some time to do it.\nIn the meantime, I have another question. From group() function doc:\nThe groupValue function is optional; if not specified, it defaults to the identity \nfunction. Like the value function, groupValue must return a naturally-ordered\nvalue; furthermore, this order must be consistent with the dimension's value function!\nI suspect my problem could be related with that last requirement (consistency between groupValue function and dimension value function). Could you expand on what would that mean?\nI'm interpreting it as \na <= b --> g(a) <= g(b), where a = v(recordA) and b = v(recordB)\nwhere v is dimension value function and g is group value function.\nThat doesn't hold in my case, precisely because of group \"(other)\". Is that really needed? Why?\nThanks.\n. Ok. I ended up doing as you adviced (making second grouping out of crossfilter). \nThanks. \n. ",
    "HKochniss": "It's my first contribution to an OS project on Github, I'm feeling kind of good right now. :-)\nThe price would be easier ways to contribute..\nIt's pretty hard to contribute as a windows dev, would you accept pull requests for a gulpfile (a makefile is super windows-dev unfriendly, almost kept me from sending the PR)? An maybe use the new contributor license feature of Github instead of the google docs one (not nearly as big of an issue as the makefile)?\n. The feature I meant is somewhat different to what I found after some search (CONTRIBUTING.md, you already use it but I didn't notice the popup on the PR):  https://github.com/blog/1184-contributing-guidelines\nI thought there was support for actively agreeing to a contributors license on a PR, but that might have been on another platform.\nHrm, don't know about the pure node-based build, Grunt/gulp became widely used in many JS projects like a year ago (that's at least my perception), personally I never saw gulp as a \"fat\" dependency, but that's maybe a matter of taste. There are already dependencies on e.g. uglify, and I never had problems with gulp (and I use it a lot for my little spikes, which essentially use gulp for a simple livereload watch and minification/scss etc..)\nAnyways, if non-gulp is a must, I would look into the pure node.js script, even if it probably gets bigger without the grunt/gulp plugin ecosystem at hand, as long as it means windows-devs have a nice onramp experience with the project.\n. Ok, probably it was https://www.clahub.com/\nThis seems like a nicer way of doing it, even though it means a dependency on clahub.com instaed of on google docs. The integration in Github is really nice..\n. Ok, makes sense.. I like the fact that there's always another critical eye in the PR process, wouldn't have thought about that.\n. It's my first contribution to an OS project on Github, I'm feeling kind of good right now. :-)\nThe price would be easier ways to contribute..\nIt's pretty hard to contribute as a windows dev, would you accept pull requests for a gulpfile (a makefile is super windows-dev unfriendly, almost kept me from sending the PR)? An maybe use the new contributor license feature of Github instead of the google docs one (not nearly as big of an issue as the makefile)?\n. The feature I meant is somewhat different to what I found after some search (CONTRIBUTING.md, you already use it but I didn't notice the popup on the PR):  https://github.com/blog/1184-contributing-guidelines\nI thought there was support for actively agreeing to a contributors license on a PR, but that might have been on another platform.\nHrm, don't know about the pure node-based build, Grunt/gulp became widely used in many JS projects like a year ago (that's at least my perception), personally I never saw gulp as a \"fat\" dependency, but that's maybe a matter of taste. There are already dependencies on e.g. uglify, and I never had problems with gulp (and I use it a lot for my little spikes, which essentially use gulp for a simple livereload watch and minification/scss etc..)\nAnyways, if non-gulp is a must, I would look into the pure node.js script, even if it probably gets bigger without the grunt/gulp plugin ecosystem at hand, as long as it means windows-devs have a nice onramp experience with the project.\n. Ok, probably it was https://www.clahub.com/\nThis seems like a nicer way of doing it, even though it means a dependency on clahub.com instaed of on google docs. The integration in Github is really nice..\n. Ok, makes sense.. I like the fact that there's always another critical eye in the PR process, wouldn't have thought about that.\n. ",
    "nreese": "Will do. Thanks for the links\n. Will do. Thanks for the links\n. ",
    "Leooo": "Many thanks, yes that's what I did finally, a sorting function using multiple keys, 0 padding on numbers, converting everything to strings, maintaining string lengths constant, reverting alphabetically a string when I want to sort descending and joining every string at the end with a \"|\" separator.. But I'm not sure about the performance so I may actually finish by sorting everything outside of xfilter.\nL \n. Many thanks, yes that's what I did finally, a sorting function using multiple keys, 0 padding on numbers, converting everything to strings, maintaining string lengths constant, reverting alphabetically a string when I want to sort descending and joining every string at the end with a \"|\" separator.. But I'm not sure about the performance so I may actually finish by sorting everything outside of xfilter.\nL \n. ",
    "ppeer": "@gordonwoodhull the last suggestion, that's the case. \n. @gordonwoodhull the last suggestion, that's the case. \n. ",
    "yellow-sock": "Ahh .. excellent .. thanks a lot!\nOnce I have a question like this one in my mind  it sticks in there  and starts bothering me :) That's now answered :)\n. Ahh .. excellent .. thanks a lot!\nOnce I have a question like this one in my mind  it sticks in there  and starts bothering me :) That's now answered :)\n. "
}